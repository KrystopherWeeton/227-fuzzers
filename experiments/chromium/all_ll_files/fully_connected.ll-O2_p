; ModuleID = '../../third_party/tflite/src/tensorflow/lite/kernels/fully_connected.cc'
source_filename = "../../third_party/tflite/src/tensorflow/lite/kernels/fully_connected.cc"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"

%struct.TfLiteContext = type { i64, i32 (%struct.TfLiteContext*, %struct.TfLiteIntArray**)*, %struct.TfLiteTensor*, i8*, i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)*, void (%struct.TfLiteContext*, i8*, ...)*, i32 (%struct.TfLiteContext*, i32, i32*)*, i32 (%struct.TfLiteContext*, i32, %struct.TfLiteNode**, %struct.TfLiteRegistration**)*, i32 (%struct.TfLiteContext*, %struct.TfLiteRegistration*, %struct.TfLiteIntArray*, %struct.TfLiteDelegate*)*, i32, %struct.TfLiteExternalContext* (%struct.TfLiteContext*, i32)*, void (%struct.TfLiteContext*, i32, %struct.TfLiteExternalContext*)*, i8, i8*, i32 (%struct.TfLiteContext*, i64, i8**)*, i32 (%struct.TfLiteContext*, i64, i8**)*, i32 (%struct.TfLiteContext*, i64, i32*)*, i8* (%struct.TfLiteContext*, i32)*, i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, i32, i32*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteIntArray*, %struct.TfLiteDelegateParams**, i32*)* }
%struct.TfLiteIntArray = type { i32, [0 x i32] }
%struct.TfLiteTensor = type { i32, %union.TfLitePtrUnion, %struct.TfLiteIntArray*, %struct.TfLiteQuantizationParams, i32, i64, i8*, i8*, %struct.TfLiteDelegate*, i32, i8, i8, %struct.TfLiteQuantization, %struct.TfLiteSparsity*, %struct.TfLiteIntArray* }
%union.TfLitePtrUnion = type { i32* }
%struct.TfLiteQuantizationParams = type { float, i32 }
%struct.TfLiteDelegate = type { i8*, i32 (%struct.TfLiteContext*, %struct.TfLiteDelegate*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteDelegate*, i32, %struct.TfLiteTensor*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteDelegate*, i32, %struct.TfLiteTensor*)*, void (%struct.TfLiteContext*, %struct.TfLiteDelegate*, i32*)*, i64 }
%struct.TfLiteQuantization = type { i32, i8* }
%struct.TfLiteSparsity = type { %struct.TfLiteIntArray*, %struct.TfLiteIntArray*, %struct.TfLiteDimensionMetadata*, i32 }
%struct.TfLiteDimensionMetadata = type { i32, i32, %struct.TfLiteIntArray*, %struct.TfLiteIntArray* }
%struct.TfLiteNode = type { %struct.TfLiteIntArray*, %struct.TfLiteIntArray*, %struct.TfLiteIntArray*, %struct.TfLiteIntArray*, i8*, i8*, i8*, i32, %struct.TfLiteDelegate* }
%struct.TfLiteRegistration = type { {}*, void (%struct.TfLiteContext*, i8*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteNode*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteNode*)*, i8* (%struct.TfLiteContext*, %struct.TfLiteNode*)*, i32, i8*, i32 }
%struct.TfLiteExternalContext = type { i32, i32 (%struct.TfLiteContext*)* }
%struct.TfLiteDelegateParams = type { %struct.TfLiteDelegate*, %struct.TfLiteIntArray*, %struct.TfLiteIntArray*, %struct.TfLiteIntArray* }
%"struct.ruy::KernelParamsFloat" = type <{ float*, float*, float*, float*, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, float, float, i8, [3 x i8], [16 x float], [256 x float], [4 x i8] }>
%"struct.ruy::KernelParamsFloat.110" = type <{ float*, float*, float*, float*, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, float, float, i8, [3 x i8], [8 x float], [64 x float], [4 x i8] }>
%struct._IO_FILE = type { i32, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, %struct._IO_marker*, %struct._IO_FILE*, i32, i32, i64, i16, i8, [1 x i8], i8*, i64, %struct._IO_codecvt*, %struct._IO_wide_data*, %struct._IO_FILE*, i8*, i64, i32, [20 x i8] }
%struct._IO_marker = type opaque
%struct._IO_codecvt = type opaque
%struct._IO_wide_data = type opaque
%struct.TfLiteFullyConnectedParams = type { i32, i32, i8, i8 }
%"struct.tflite::ops::builtin::fully_connected::OpData" = type <{ i32, i32, i32, i32, i32, i8, [3 x i8] }>
%"struct.Eigen::internal::evaluator" = type { %"struct.Eigen::internal::unary_evaluator" }
%"struct.Eigen::internal::unary_evaluator" = type { %"class.Eigen::internal::unary_evaluator<Eigen::CwiseUnaryOp<Eigen::internal::scalar_tanh_op<float>, const Eigen::ArrayWrapper<Eigen::Map<Eigen::Matrix<float, -1, 1, 0, -1, 1>, 0, Eigen::Stride<0, 0> > > >, Eigen::internal::IndexBased, float>::Data" }
%"class.Eigen::internal::unary_evaluator<Eigen::CwiseUnaryOp<Eigen::internal::scalar_tanh_op<float>, const Eigen::ArrayWrapper<Eigen::Map<Eigen::Matrix<float, -1, 1, 0, -1, 1>, 0, Eigen::Stride<0, 0> > > >, Eigen::internal::IndexBased, float>::Data" = type { %"struct.Eigen::internal::evaluator.34" }
%"struct.Eigen::internal::evaluator.34" = type { %"struct.Eigen::internal::evaluator.35" }
%"struct.Eigen::internal::evaluator.35" = type { %"struct.Eigen::internal::unary_evaluator.36" }
%"struct.Eigen::internal::unary_evaluator.36" = type { %"struct.Eigen::internal::evaluator_wrapper_base" }
%"struct.Eigen::internal::evaluator_wrapper_base" = type { %"struct.Eigen::internal::evaluator.39" }
%"struct.Eigen::internal::evaluator.39" = type { %"struct.Eigen::internal::mapbase_evaluator" }
%"struct.Eigen::internal::mapbase_evaluator" = type { float*, %"class.Eigen::internal::variable_if_dynamic.21", %"class.Eigen::internal::variable_if_dynamic" }
%"class.Eigen::internal::variable_if_dynamic.21" = type { i8 }
%"class.Eigen::internal::variable_if_dynamic" = type { i64 }
%"class.Eigen::internal::generic_dense_assignment_kernel" = type { %"struct.Eigen::internal::evaluator.35"*, %"struct.Eigen::internal::evaluator"*, %"struct.Eigen::internal::assign_op"*, %"class.Eigen::ArrayWrapper"* }
%"struct.Eigen::internal::assign_op" = type { i8 }
%"class.Eigen::ArrayWrapper" = type { %"class.Eigen::Map" }
%"class.Eigen::Map" = type { %"class.Eigen::MapBase.base.22", %"class.Eigen::Stride", [5 x i8] }
%"class.Eigen::MapBase.base.22" = type { %"class.Eigen::MapBase.base" }
%"class.Eigen::MapBase.base" = type <{ float*, %"class.Eigen::internal::variable_if_dynamic", %"class.Eigen::internal::variable_if_dynamic.21" }>
%"class.Eigen::Stride" = type { %"class.Eigen::internal::variable_if_dynamic.23", %"class.Eigen::internal::variable_if_dynamic.23" }
%"class.Eigen::internal::variable_if_dynamic.23" = type { i8 }
%"class.Eigen::CwiseUnaryOp.42" = type { %"class.Eigen::ArrayWrapper", %"struct.Eigen::internal::scalar_logistic_op", [7 x i8] }
%"struct.Eigen::internal::scalar_logistic_op" = type { i8 }
%"class.tflite::CpuBackendContext" = type <{ %"class.tflite::TfLiteInternalBackendContext", %"class.std::__1::unique_ptr", %"class.std::__1::unique_ptr.2", i32, i8, [3 x i8] }>
%"class.tflite::TfLiteInternalBackendContext" = type { i32 (...)** }
%"class.std::__1::unique_ptr" = type { %"class.std::__1::__compressed_pair" }
%"class.std::__1::__compressed_pair" = type { %"struct.std::__1::__compressed_pair_elem" }
%"struct.std::__1::__compressed_pair_elem" = type { %"class.ruy::Context"* }
%"class.ruy::Context" = type { %"class.ruy::CtxImpl"* }
%"class.ruy::CtxImpl" = type opaque
%"class.std::__1::unique_ptr.2" = type { %"class.std::__1::__compressed_pair.3" }
%"class.std::__1::__compressed_pair.3" = type { %"struct.std::__1::__compressed_pair_elem.4" }
%"struct.std::__1::__compressed_pair_elem.4" = type { %"class.gemmlowp::GemmContext"* }
%"class.gemmlowp::GemmContext" = type { %"class.gemmlowp::MultiThreadGemmContext" }
%"class.gemmlowp::MultiThreadGemmContext" = type { %"class.gemmlowp::MultiThreadGemmContextBase", %"class.gemmlowp::WorkersPool" }
%"class.gemmlowp::MultiThreadGemmContextBase" = type { %"class.gemmlowp::SingleThreadGemmContext.base", i32 }
%"class.gemmlowp::SingleThreadGemmContext.base" = type <{ %"class.gemmlowp::Allocator", i32, i32, float }>
%"class.gemmlowp::Allocator" = type { i8, i64, i8*, i64, i64, [5 x i64], i64 }
%"class.gemmlowp::WorkersPool" = type { %"class.std::__1::vector", %"class.gemmlowp::BlockingCounter", %"class.gemmlowp::Allocator" }
%"class.std::__1::vector" = type { %"class.std::__1::__vector_base" }
%"class.std::__1::__vector_base" = type { %"class.gemmlowp::Worker"**, %"class.gemmlowp::Worker"**, %"class.std::__1::__compressed_pair.12" }
%"class.gemmlowp::Worker" = type { i64, %"struct.gemmlowp::Task"*, %union.pthread_cond_t, %union.pthread_mutex_t, %"struct.std::__1::atomic", %"class.gemmlowp::Allocator", %"class.gemmlowp::BlockingCounter"* }
%"struct.gemmlowp::Task" = type { i32 (...)**, %"class.gemmlowp::Allocator"* }
%union.pthread_cond_t = type { %struct.__pthread_cond_s }
%struct.__pthread_cond_s = type { %union.anon, %union.anon.5, [2 x i32], [2 x i32], i32, i32, [2 x i32] }
%union.anon = type { i64 }
%union.anon.5 = type { i64 }
%union.pthread_mutex_t = type { %struct.__pthread_mutex_s }
%struct.__pthread_mutex_s = type { i32, i32, i32, i32, i32, i16, i16, %struct.__pthread_internal_list }
%struct.__pthread_internal_list = type { %struct.__pthread_internal_list*, %struct.__pthread_internal_list* }
%"struct.std::__1::atomic" = type { %"struct.std::__1::__atomic_base" }
%"struct.std::__1::__atomic_base" = type { %"struct.std::__1::__cxx_atomic_impl" }
%"struct.std::__1::__cxx_atomic_impl" = type { %"struct.std::__1::__cxx_atomic_base_impl" }
%"struct.std::__1::__cxx_atomic_base_impl" = type { i32 }
%"class.std::__1::__compressed_pair.12" = type { %"struct.std::__1::__compressed_pair_elem.13" }
%"struct.std::__1::__compressed_pair_elem.13" = type { %"class.gemmlowp::Worker"** }
%"class.gemmlowp::BlockingCounter" = type { %"struct.std::__1::atomic.7" }
%"struct.std::__1::atomic.7" = type { %"struct.std::__1::__atomic_base.8" }
%"struct.std::__1::__atomic_base.8" = type { %"struct.std::__1::__atomic_base.9" }
%"struct.std::__1::__atomic_base.9" = type { %"struct.std::__1::__cxx_atomic_impl.10" }
%"struct.std::__1::__cxx_atomic_impl.10" = type { %"struct.std::__1::__cxx_atomic_base_impl.11" }
%"struct.std::__1::__cxx_atomic_base_impl.11" = type { i64 }
%"struct.Eigen::EigenBase.33" = type { i8 }
%"struct.tflite::FullyConnectedParams" = type { i32, i32, i32, i32, i32, i32, i32, float, float, i8, i8, i8 }
%"class.tflite::RuntimeShape" = type { i32, %union.anon.54 }
%union.anon.54 = type { i32*, [16 x i8] }
%"class.std::__1::vector.55" = type { %"class.std::__1::__vector_base.56" }
%"class.std::__1::__vector_base.56" = type { i32*, i32*, %"class.std::__1::__compressed_pair.57" }
%"class.std::__1::__compressed_pair.57" = type { %"struct.std::__1::__compressed_pair_elem.58" }
%"struct.std::__1::__compressed_pair_elem.58" = type { i32* }
%"class.tflite::optimize::sparsity::FormatConverter" = type { %"class.std::__1::vector.55", %"class.std::__1::vector.55", i64, %"class.std::__1::vector.55", %"class.std::__1::vector.62", %"class.std::__1::vector.55", %"class.std::__1::vector.55", %"class.std::__1::vector.69", %"class.std::__1::vector.76" }
%"class.std::__1::vector.62" = type { %"class.std::__1::__vector_base.63" }
%"class.std::__1::__vector_base.63" = type { i32*, i32*, %"class.std::__1::__compressed_pair.64" }
%"class.std::__1::__compressed_pair.64" = type { %"struct.std::__1::__compressed_pair_elem.65" }
%"struct.std::__1::__compressed_pair_elem.65" = type { i32* }
%"class.std::__1::vector.69" = type { %"class.std::__1::__vector_base.70" }
%"class.std::__1::__vector_base.70" = type { %"class.std::__1::vector.55"*, %"class.std::__1::vector.55"*, %"class.std::__1::__compressed_pair.71" }
%"class.std::__1::__compressed_pair.71" = type { %"struct.std::__1::__compressed_pair_elem.72" }
%"struct.std::__1::__compressed_pair_elem.72" = type { %"class.std::__1::vector.55"* }
%"class.std::__1::vector.76" = type { %"class.std::__1::__vector_base.77" }
%"class.std::__1::__vector_base.77" = type { float*, float*, %"class.std::__1::__compressed_pair.78" }
%"class.std::__1::__compressed_pair.78" = type { %"struct.std::__1::__compressed_pair_elem.79" }
%"struct.std::__1::__compressed_pair_elem.79" = type { float* }
%"class.std::__1::__vector_base_common" = type { i8 }
%"struct.tflite::cpu_backend_gemm::MatrixParams.429" = type <{ i32, i32, i32, i8, i8, [2 x i8] }>
%"struct.tflite::cpu_backend_gemm::GemmParams.431" = type <{ i32, i32, i32*, i32*, i32*, i8, i8, [6 x i8] }>
%"class.std::__1::vector.85" = type { %"class.std::__1::__vector_base.86" }
%"class.std::__1::__vector_base.86" = type { %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"*, %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"*, %"class.std::__1::__compressed_pair.87" }
%"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task" = type { %"struct.gemmlowp::Task", %struct.TfLiteSparsity*, %"struct.tflite::FullyConnectedParams"*, %"class.tflite::RuntimeShape"*, float*, %"class.tflite::RuntimeShape"*, float*, %"class.tflite::RuntimeShape"*, float*, %"class.tflite::RuntimeShape"*, float*, i32, i32, %"class.tflite::CpuBackendContext"* }
%"class.std::__1::__compressed_pair.87" = type { %"struct.std::__1::__compressed_pair_elem.88" }
%"struct.std::__1::__compressed_pair_elem.88" = type { %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* }
%"struct.tflite::cpu_backend_gemm::MatrixParams" = type <{ i32, i32, i32, float, i8, [3 x i8] }>
%"struct.tflite::cpu_backend_gemm::GemmParams" = type { float, i32, float*, i32*, float*, float, float }
%"class.std::__1::chrono::duration.98" = type { i64 }
%union.pthread_condattr_t = type { i32 }
%union.pthread_mutexattr_t = type { i32 }
%union.pthread_attr_t = type { i64, [48 x i8] }
%"struct.ruy::Mat" = type <{ %"class.ruy::detail::ConstCheckingPtr", %"struct.ruy::MatLayout", float, i8, [3 x i8] }>
%"class.ruy::detail::ConstCheckingPtr" = type { float* }
%"struct.ruy::MatLayout" = type <{ i32, i32, i32, i8, [3 x i8] }>
%"class.ruy::MulParams" = type { float*, float, i32, float*, i32*, float, float }
%"class.ruy::Ctx" = type { i8 }
%"struct.ruy::TrMulParams" = type { i8, %"class.ruy::SidePair", void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)*, %"class.ruy::SidePair.106", %"struct.ruy::EMat", %"class.ruy::SidePair.104", %"class.ruy::SidePair.107", i8* }
%"class.ruy::SidePair" = type { [2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*] }
%"struct.ruy::PEMat" = type <{ %"struct.ruy::Type", [5 x i8], i8*, %"struct.ruy::Type", [5 x i8], i8*, %"struct.ruy::PMatLayout", i32, [4 x i8] }>
%"struct.ruy::Type" = type { i8, i8, i8 }
%"struct.ruy::PMatLayout" = type { i32, i32, i32, i8, %"struct.ruy::KernelLayout" }
%"struct.ruy::KernelLayout" = type { i8, i8, i8 }
%"class.ruy::SidePair.105" = type { [2 x i32] }
%"class.ruy::SidePair.106" = type { [2 x %"struct.ruy::EMat"] }
%"struct.ruy::EMat" = type <{ %"struct.ruy::Type", [5 x i8], i8*, %"struct.ruy::MatLayout", i32, i8, [3 x i8] }>
%"class.ruy::SidePair.104" = type { [2 x %"struct.ruy::PEMat"] }
%"class.ruy::SidePair.107" = type { [2 x i8] }
%"class.ruy::PrepackedCache" = type { %"class.std::__1::unordered_map", i32, i32, i64 }
%"class.std::__1::unordered_map" = type { %"class.std::__1::__hash_table" }
%"class.std::__1::__hash_table" = type <{ %"class.std::__1::unique_ptr.112", %"class.std::__1::__compressed_pair.121", %"class.std::__1::__compressed_pair.126", %"class.std::__1::__compressed_pair.128", [4 x i8] }>
%"class.std::__1::unique_ptr.112" = type { %"class.std::__1::__compressed_pair.113" }
%"class.std::__1::__compressed_pair.113" = type { %"struct.std::__1::__compressed_pair_elem.114", %"struct.std::__1::__compressed_pair_elem.115" }
%"struct.std::__1::__compressed_pair_elem.114" = type { %"struct.std::__1::__hash_node_base"** }
%"struct.std::__1::__hash_node_base" = type { %"struct.std::__1::__hash_node_base"* }
%"struct.std::__1::__compressed_pair_elem.115" = type { %"class.std::__1::__bucket_list_deallocator" }
%"class.std::__1::__bucket_list_deallocator" = type { %"class.std::__1::__compressed_pair.116" }
%"class.std::__1::__compressed_pair.116" = type { %"struct.std::__1::__compressed_pair_elem.117" }
%"struct.std::__1::__compressed_pair_elem.117" = type { i64 }
%"class.std::__1::__compressed_pair.121" = type { %"struct.std::__1::__compressed_pair_elem.122" }
%"struct.std::__1::__compressed_pair_elem.122" = type { %"struct.std::__1::__hash_node_base" }
%"class.std::__1::__compressed_pair.126" = type { %"struct.std::__1::__compressed_pair_elem.117" }
%"class.std::__1::__compressed_pair.128" = type { %"struct.std::__1::__compressed_pair_elem.129" }
%"struct.std::__1::__compressed_pair_elem.129" = type { float }
%"struct.ruy::PMat" = type <{ float*, float*, %"struct.ruy::PMatLayout", i32, [4 x i8] }>
%"struct.ruy::Kernel" = type { i8 }
%"class.std::__1::vector.143" = type { %"class.std::__1::__vector_base.144" }
%"class.std::__1::__vector_base.144" = type { %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"*, %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"*, %"class.std::__1::__compressed_pair.145" }
%"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask" = type { %"struct.gemmlowp::Task", i8*, i8*, i32, i32, i32, i32, i32*, i32, i32, i16* }
%"class.std::__1::__compressed_pair.145" = type { %"struct.std::__1::__compressed_pair_elem.146" }
%"struct.std::__1::__compressed_pair_elem.146" = type { %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* }
%"struct.tflite::cpu_backend_gemm::MatrixParams.153" = type <{ i32, i32, i32, i8, i8, [2 x i8] }>
%"struct.tflite::cpu_backend_gemm::GemmParams.155" = type <{ i32, i32, i32*, i32*, i32*, i8, i8, [6 x i8] }>
%"struct.tflite::cpu_backend_gemm::MatrixParams.454" = type <{ i32, i32, i32, i16, i8, i8 }>
%"struct.tflite::cpu_backend_gemm::GemmParams.456" = type <{ i32, i32, i32*, i32*, i32*, i16, i16, [4 x i8] }>
%"struct.ruy::Mat.160" = type <{ %"class.ruy::detail::ConstCheckingPtr.158", %"struct.ruy::MatLayout", i8, i8, [6 x i8] }>
%"class.ruy::detail::ConstCheckingPtr.158" = type { i8* }
%"class.ruy::MulParams.159" = type <{ i32*, i32, i32, i32*, i32*, i8, i8, [6 x i8] }>
%"class.gemmlowp::VectorDup" = type { i32, i32 }
%"class.gemmlowp::VectorDup.194" = type { i32, i32 }
%"class.gemmlowp::MatrixMap" = type <{ i8*, i32, i32, i32, [4 x i8] }>
%"class.gemmlowp::MatrixMap.180" = type <{ i8*, i32, i32, i32, [4 x i8] }>
%"class.gemmlowp::MatrixMap.182" = type <{ i8*, i32, i32, i32, [4 x i8] }>
%"class.std::__1::tuple" = type { %"struct.std::__1::__tuple_impl" }
%"struct.std::__1::__tuple_impl" = type { %"class.std::__1::__tuple_leaf", %"class.std::__1::__tuple_leaf.184", %"class.std::__1::__tuple_leaf.185", [4 x i8] }
%"class.std::__1::__tuple_leaf" = type { %"struct.gemmlowp::OutputStageBiasAddition" }
%"struct.gemmlowp::OutputStageBiasAddition" = type { %"class.gemmlowp::VectorMap" }
%"class.gemmlowp::VectorMap" = type <{ i32*, i32, [4 x i8] }>
%"class.std::__1::__tuple_leaf.184" = type { %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent" }
%"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent" = type { i32, i32, i32 }
%"class.std::__1::__tuple_leaf.185" = type { %"struct.gemmlowp::OutputStageClamp" }
%"struct.gemmlowp::OutputStageClamp" = type { i32, i32 }
%"class.std::__1::tuple.187" = type { %"struct.std::__1::__tuple_impl.188" }
%"struct.std::__1::__tuple_impl.188" = type { %"class.std::__1::__tuple_leaf.189", %"class.std::__1::__tuple_leaf.190" }
%"class.std::__1::__tuple_leaf.189" = type { %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent" }
%"class.std::__1::__tuple_leaf.190" = type { %"struct.gemmlowp::OutputStageClamp" }
%"struct.ruy::KernelParams8bit" = type <{ i32*, i32*, i32*, i8*, i32*, i32*, i8*, i8*, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i8, i8, [2 x i8], [16 x i32], [1024 x i8], [16 x i32], [16 x i32], [4 x i8] }>
%"struct.ruy::PMat.161" = type <{ i8*, i32*, %"struct.ruy::PMatLayout", i32, [4 x i8] }>
%"struct.ruy::Kernel.162" = type { i8 }
%"struct.ruy::KernelParams8bit.167" = type <{ i32*, i32*, i32*, i8*, i32*, i32*, i8*, i8*, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i8, i8, [2 x i8], [8 x i32], [256 x i8], [8 x i32], [8 x i32], [4 x i8] }>
%"class.gemmlowp::MatrixMap.195" = type <{ i8*, i32, i32, i32, [4 x i8] }>
%"class.std::__1::tuple.197" = type { %"struct.std::__1::__tuple_impl.198" }
%"struct.std::__1::__tuple_impl.198" = type { %"class.std::__1::__tuple_leaf.199", %"class.std::__1::__tuple_leaf.184", %"class.std::__1::__tuple_leaf.185", [4 x i8] }
%"class.std::__1::__tuple_leaf.199" = type { %"struct.gemmlowp::OutputStageBiasAddition.200" }
%"struct.gemmlowp::OutputStageBiasAddition.200" = type { %"class.gemmlowp::VectorMap.201" }
%"class.gemmlowp::VectorMap.201" = type <{ i32*, i32, [4 x i8] }>
%"struct.gemmlowp::DefaultKernel" = type { %"struct.gemmlowp::DefaultKernelImpl" }
%"struct.gemmlowp::DefaultKernelImpl" = type { %"struct.gemmlowp::DefaultKernelImpl.204" }
%"struct.gemmlowp::DefaultKernelImpl.204" = type { %"struct.gemmlowp::ReferenceKernel" }
%"struct.gemmlowp::ReferenceKernel" = type { %"struct.gemmlowp::KernelBase" }
%"struct.gemmlowp::KernelBase" = type { i32 (...)** }
%"class.gemmlowp::SideMap" = type <{ i8*, i32, i32, i32, [4 x i8] }>
%"class.gemmlowp::PackSideBlockImpl" = type { %"class.gemmlowp::PackedSideBlock"*, %"class.gemmlowp::SideMap"* }
%"class.gemmlowp::PackedSideBlock" = type <{ %"struct.gemmlowp::SideBlockParams", %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator::Handle", %"class.gemmlowp::Allocator::Handle", i32, [4 x i8] }>
%"struct.gemmlowp::SideBlockParams" = type { i32, i32, i32, i32 }
%"class.gemmlowp::Allocator::Handle" = type <{ i8, [7 x i8], i64, i8, [7 x i8] }>
%"struct.gemmlowp::BlockParams" = type { i32, i32, i32, i32, i32, i32 }
%"class.std::__1::vector.205" = type { %"class.std::__1::__vector_base.206" }
%"class.std::__1::__vector_base.206" = type { %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"**, %"class.std::__1::__compressed_pair.207" }
%"class.std::__1::__compressed_pair.207" = type { %"struct.std::__1::__compressed_pair_elem.208" }
%"struct.std::__1::__compressed_pair_elem.208" = type { %"struct.gemmlowp::Task"** }
%"class.gemmlowp::SingleThreadGemmContext" = type <{ %"class.gemmlowp::Allocator", i32, i32, float, [4 x i8] }>
%"class.gemmlowp::ComputeImpl" = type { %"struct.gemmlowp::KernelBase"*, %"struct.gemmlowp::BlockParams"*, %"class.gemmlowp::PackedResult"*, %"class.gemmlowp::PackedSideBlock"*, %"class.gemmlowp::PackedSideBlock"* }
%"class.gemmlowp::PackedResult" = type { %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator::Handle", %"struct.gemmlowp::BlockParams"* }
%"struct.gemmlowp::MatrixBlockBounds" = type { i32, i32, i32, i32 }
%"struct.gemmlowp::RegisterBlock" = type { %"struct.gemmlowp::RegisterBuffer" }
%"struct.gemmlowp::RegisterBuffer" = type { [64 x i8] }
%"class.gemmlowp::MatrixMap.214" = type <{ i32*, i32, i32, i32, [4 x i8] }>
%"struct.gemmlowp::OutputPipelineExecutor" = type { %"struct.gemmlowp::OutputPipelineEvalImpl" }
%"struct.gemmlowp::OutputPipelineEvalImpl" = type { %"struct.gemmlowp::OutputStageEvalImpl", %"struct.gemmlowp::OutputPipelineEvalImpl.216" }
%"struct.gemmlowp::OutputStageEvalImpl" = type { %"struct.gemmlowp::OutputStageBiasAddition.200"* }
%"struct.gemmlowp::OutputPipelineEvalImpl.216" = type { %"struct.gemmlowp::OutputStageEvalImpl.217", %"struct.gemmlowp::OutputPipelineEvalImpl.218" }
%"struct.gemmlowp::OutputStageEvalImpl.217" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl" }
%"struct.gemmlowp::OutputStageEvalBufferImpl" = type { %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, i32, i32 }
%"struct.gemmlowp::OutputPipelineEvalImpl.218" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.219", %"struct.gemmlowp::OutputPipelineEvalImpl.221", [6 x i8] }>
%"struct.gemmlowp::OutputStageEvalImpl.219" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.220" }
%"struct.gemmlowp::OutputStageEvalBufferImpl.220" = type { %"struct.gemmlowp::OutputStageClamp"* }
%"struct.gemmlowp::OutputPipelineEvalImpl.221" = type { %"struct.gemmlowp::OutputStageEvalImpl.222", %"struct.gemmlowp::OutputPipelineEvalImpl.224" }
%"struct.gemmlowp::OutputStageEvalImpl.222" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.223" }
%"struct.gemmlowp::OutputStageEvalBufferImpl.223" = type { i8 }
%"struct.gemmlowp::OutputPipelineEvalImpl.224" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.226" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.227" }
%"struct.gemmlowp::OutputPipelineEvalImpl.227" = type { %"struct.gemmlowp::OutputStageEvalImpl.228", %"struct.gemmlowp::OutputPipelineEvalImpl.229" }
%"struct.gemmlowp::OutputStageEvalImpl.228" = type { %"struct.gemmlowp::OutputStageBiasAddition.200"* }
%"struct.gemmlowp::OutputPipelineEvalImpl.229" = type { %"struct.gemmlowp::OutputStageEvalImpl.230", %"struct.gemmlowp::OutputPipelineEvalImpl.232" }
%"struct.gemmlowp::OutputStageEvalImpl.230" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.231" }
%"struct.gemmlowp::OutputStageEvalBufferImpl.231" = type { %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, i32, i32 }
%"struct.gemmlowp::OutputPipelineEvalImpl.232" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.233", %"struct.gemmlowp::OutputPipelineEvalImpl.235", [6 x i8] }>
%"struct.gemmlowp::OutputStageEvalImpl.233" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.234" }
%"struct.gemmlowp::OutputStageEvalBufferImpl.234" = type { %"struct.gemmlowp::OutputStageClamp"* }
%"struct.gemmlowp::OutputPipelineEvalImpl.235" = type { %"struct.gemmlowp::OutputStageEvalImpl.236", %"struct.gemmlowp::OutputPipelineEvalImpl.239" }
%"struct.gemmlowp::OutputStageEvalImpl.236" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.237" }
%"struct.gemmlowp::OutputStageEvalBufferImpl.237" = type { i8 }
%"struct.gemmlowp::OutputPipelineEvalImpl.239" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.242" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.243" }
%"struct.gemmlowp::OutputPipelineEvalImpl.243" = type { %"struct.gemmlowp::OutputStageEvalImpl.244", %"struct.gemmlowp::OutputPipelineEvalImpl.245" }
%"struct.gemmlowp::OutputStageEvalImpl.244" = type { %"struct.gemmlowp::OutputStageBiasAddition.200"* }
%"struct.gemmlowp::OutputPipelineEvalImpl.245" = type { %"struct.gemmlowp::OutputStageEvalImpl.246", %"struct.gemmlowp::OutputPipelineEvalImpl.248" }
%"struct.gemmlowp::OutputStageEvalImpl.246" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.247" }
%"struct.gemmlowp::OutputStageEvalBufferImpl.247" = type { %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, i32, i32 }
%"struct.gemmlowp::OutputPipelineEvalImpl.248" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.249", %"struct.gemmlowp::OutputPipelineEvalImpl.251", [6 x i8] }>
%"struct.gemmlowp::OutputStageEvalImpl.249" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.250" }
%"struct.gemmlowp::OutputStageEvalBufferImpl.250" = type { %"struct.gemmlowp::OutputStageClamp"* }
%"struct.gemmlowp::OutputPipelineEvalImpl.251" = type { %"struct.gemmlowp::OutputStageEvalImpl.252", %"struct.gemmlowp::OutputPipelineEvalImpl.255" }
%"struct.gemmlowp::OutputStageEvalImpl.252" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.253" }
%"struct.gemmlowp::OutputStageEvalBufferImpl.253" = type { i8 }
%"struct.gemmlowp::OutputPipelineEvalImpl.255" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.258" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.259" }
%"struct.gemmlowp::OutputPipelineEvalImpl.259" = type { %"struct.gemmlowp::OutputStageEvalImpl.260", %"struct.gemmlowp::OutputPipelineEvalImpl.261" }
%"struct.gemmlowp::OutputStageEvalImpl.260" = type { %"struct.gemmlowp::OutputStageBiasAddition.200"* }
%"struct.gemmlowp::OutputPipelineEvalImpl.261" = type { %"struct.gemmlowp::OutputStageEvalImpl.262", %"struct.gemmlowp::OutputPipelineEvalImpl.263" }
%"struct.gemmlowp::OutputStageEvalImpl.262" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.231" }
%"struct.gemmlowp::OutputPipelineEvalImpl.263" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.264", %"struct.gemmlowp::OutputPipelineEvalImpl.265", [6 x i8] }>
%"struct.gemmlowp::OutputStageEvalImpl.264" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.234" }
%"struct.gemmlowp::OutputPipelineEvalImpl.265" = type { %"struct.gemmlowp::OutputStageEvalImpl.266", %"struct.gemmlowp::OutputPipelineEvalImpl.267" }
%"struct.gemmlowp::OutputStageEvalImpl.266" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.237" }
%"struct.gemmlowp::OutputPipelineEvalImpl.267" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.270" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.271" }
%"struct.gemmlowp::OutputPipelineEvalImpl.271" = type { %"struct.gemmlowp::OutputStageEvalImpl.272", %"struct.gemmlowp::OutputPipelineEvalImpl.273" }
%"struct.gemmlowp::OutputStageEvalImpl.272" = type { %"struct.gemmlowp::OutputStageBiasAddition.200"* }
%"struct.gemmlowp::OutputPipelineEvalImpl.273" = type { %"struct.gemmlowp::OutputStageEvalImpl.274", %"struct.gemmlowp::OutputPipelineEvalImpl.276" }
%"struct.gemmlowp::OutputStageEvalImpl.274" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.275" }
%"struct.gemmlowp::OutputStageEvalBufferImpl.275" = type { %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, i32, i32 }
%"struct.gemmlowp::OutputPipelineEvalImpl.276" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.277", %"struct.gemmlowp::OutputPipelineEvalImpl.279", [6 x i8] }>
%"struct.gemmlowp::OutputStageEvalImpl.277" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.278" }
%"struct.gemmlowp::OutputStageEvalBufferImpl.278" = type { %"struct.gemmlowp::OutputStageClamp"* }
%"struct.gemmlowp::OutputPipelineEvalImpl.279" = type { %"struct.gemmlowp::OutputStageEvalImpl.280", %"struct.gemmlowp::OutputPipelineEvalImpl.283" }
%"struct.gemmlowp::OutputStageEvalImpl.280" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.281" }
%"struct.gemmlowp::OutputStageEvalBufferImpl.281" = type { i8 }
%"struct.gemmlowp::OutputPipelineEvalImpl.283" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.286" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.287" }
%"struct.gemmlowp::OutputPipelineEvalImpl.287" = type { %"struct.gemmlowp::OutputStageEvalImpl.288", %"struct.gemmlowp::OutputPipelineEvalImpl.289" }
%"struct.gemmlowp::OutputStageEvalImpl.288" = type { %"struct.gemmlowp::OutputStageBiasAddition.200"* }
%"struct.gemmlowp::OutputPipelineEvalImpl.289" = type { %"struct.gemmlowp::OutputStageEvalImpl.290", %"struct.gemmlowp::OutputPipelineEvalImpl.292" }
%"struct.gemmlowp::OutputStageEvalImpl.290" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.291" }
%"struct.gemmlowp::OutputStageEvalBufferImpl.291" = type { %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, i32, i32 }
%"struct.gemmlowp::OutputPipelineEvalImpl.292" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.293", %"struct.gemmlowp::OutputPipelineEvalImpl.295", [6 x i8] }>
%"struct.gemmlowp::OutputStageEvalImpl.293" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.294" }
%"struct.gemmlowp::OutputStageEvalBufferImpl.294" = type { %"struct.gemmlowp::OutputStageClamp"* }
%"struct.gemmlowp::OutputPipelineEvalImpl.295" = type { %"struct.gemmlowp::OutputStageEvalImpl.296", %"struct.gemmlowp::OutputPipelineEvalImpl.299" }
%"struct.gemmlowp::OutputStageEvalImpl.296" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.297" }
%"struct.gemmlowp::OutputStageEvalBufferImpl.297" = type { i8 }
%"struct.gemmlowp::OutputPipelineEvalImpl.299" = type { i8 }
%"class.gemmlowp::PackingRegisterBlock" = type { %"class.gemmlowp::PackingRegisterBlockBase" }
%"class.gemmlowp::PackingRegisterBlockBase" = type { %"class.gemmlowp::SideMap", [64 x i8] }
%"struct.gemmlowp::RegisterBlock.302" = type { %"struct.gemmlowp::RegisterBuffer.303" }
%"struct.gemmlowp::RegisterBuffer.303" = type { [32 x i32] }
%"struct.gemmlowp::RegisterBlock.312" = type { %"struct.gemmlowp::RegisterBuffer.313" }
%"struct.gemmlowp::RegisterBuffer.313" = type { [16 x i32] }
%"struct.gemmlowp::RegisterBlock.304" = type { %"struct.gemmlowp::RegisterBuffer.305" }
%"struct.gemmlowp::RegisterBuffer.305" = type { [8 x i32] }
%"struct.gemmlowp::RegisterBlock.310" = type { %"struct.gemmlowp::RegisterBuffer.311" }
%"struct.gemmlowp::RegisterBuffer.311" = type { [32 x i8] }
%"struct.gemmlowp::GemmWithPackedRhsTask" = type { %"struct.gemmlowp::Task", %"class.gemmlowp::GemmContext"*, %"struct.gemmlowp::KernelBase"*, %"class.gemmlowp::MatrixMap", %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::MatrixMap.195", %"struct.gemmlowp::MatrixBlockBounds", %"class.gemmlowp::VectorDup.194"*, %"class.gemmlowp::VectorDup"*, %"struct.gemmlowp::BlockParams"*, %"class.std::__1::tuple.197"* }
%"struct.gemmlowp::OutputPipelineExecutor.329" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.330" }
%"struct.gemmlowp::OutputPipelineEvalImpl.330" = type { %"struct.gemmlowp::OutputStageEvalImpl.331", %"struct.gemmlowp::OutputPipelineEvalImpl.332" }
%"struct.gemmlowp::OutputStageEvalImpl.331" = type { %"struct.gemmlowp::OutputStageBiasAddition"* }
%"struct.gemmlowp::OutputPipelineEvalImpl.332" = type { %"struct.gemmlowp::OutputStageEvalImpl.217", %"struct.gemmlowp::OutputPipelineEvalImpl.333" }
%"struct.gemmlowp::OutputPipelineEvalImpl.333" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.219", %"struct.gemmlowp::OutputPipelineEvalImpl.334", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.334" = type { %"struct.gemmlowp::OutputStageEvalImpl.222", %"struct.gemmlowp::OutputPipelineEvalImpl.335" }
%"struct.gemmlowp::OutputPipelineEvalImpl.335" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.338" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.339" }
%"struct.gemmlowp::OutputPipelineEvalImpl.339" = type { %"struct.gemmlowp::OutputStageEvalImpl.340", %"struct.gemmlowp::OutputPipelineEvalImpl.341" }
%"struct.gemmlowp::OutputStageEvalImpl.340" = type { %"struct.gemmlowp::OutputStageBiasAddition"* }
%"struct.gemmlowp::OutputPipelineEvalImpl.341" = type { %"struct.gemmlowp::OutputStageEvalImpl.230", %"struct.gemmlowp::OutputPipelineEvalImpl.342" }
%"struct.gemmlowp::OutputPipelineEvalImpl.342" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.233", %"struct.gemmlowp::OutputPipelineEvalImpl.343", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.343" = type { %"struct.gemmlowp::OutputStageEvalImpl.236", %"struct.gemmlowp::OutputPipelineEvalImpl.344" }
%"struct.gemmlowp::OutputPipelineEvalImpl.344" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.347" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.348" }
%"struct.gemmlowp::OutputPipelineEvalImpl.348" = type { %"struct.gemmlowp::OutputStageEvalImpl.349", %"struct.gemmlowp::OutputPipelineEvalImpl.350" }
%"struct.gemmlowp::OutputStageEvalImpl.349" = type { %"struct.gemmlowp::OutputStageBiasAddition"* }
%"struct.gemmlowp::OutputPipelineEvalImpl.350" = type { %"struct.gemmlowp::OutputStageEvalImpl.246", %"struct.gemmlowp::OutputPipelineEvalImpl.351" }
%"struct.gemmlowp::OutputPipelineEvalImpl.351" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.249", %"struct.gemmlowp::OutputPipelineEvalImpl.352", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.352" = type { %"struct.gemmlowp::OutputStageEvalImpl.252", %"struct.gemmlowp::OutputPipelineEvalImpl.353" }
%"struct.gemmlowp::OutputPipelineEvalImpl.353" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.356" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.357" }
%"struct.gemmlowp::OutputPipelineEvalImpl.357" = type { %"struct.gemmlowp::OutputStageEvalImpl.358", %"struct.gemmlowp::OutputPipelineEvalImpl.359" }
%"struct.gemmlowp::OutputStageEvalImpl.358" = type { %"struct.gemmlowp::OutputStageBiasAddition"* }
%"struct.gemmlowp::OutputPipelineEvalImpl.359" = type { %"struct.gemmlowp::OutputStageEvalImpl.262", %"struct.gemmlowp::OutputPipelineEvalImpl.360" }
%"struct.gemmlowp::OutputPipelineEvalImpl.360" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.264", %"struct.gemmlowp::OutputPipelineEvalImpl.361", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.361" = type { %"struct.gemmlowp::OutputStageEvalImpl.266", %"struct.gemmlowp::OutputPipelineEvalImpl.362" }
%"struct.gemmlowp::OutputPipelineEvalImpl.362" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.365" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.366" }
%"struct.gemmlowp::OutputPipelineEvalImpl.366" = type { %"struct.gemmlowp::OutputStageEvalImpl.367", %"struct.gemmlowp::OutputPipelineEvalImpl.368" }
%"struct.gemmlowp::OutputStageEvalImpl.367" = type { %"struct.gemmlowp::OutputStageBiasAddition"* }
%"struct.gemmlowp::OutputPipelineEvalImpl.368" = type { %"struct.gemmlowp::OutputStageEvalImpl.274", %"struct.gemmlowp::OutputPipelineEvalImpl.369" }
%"struct.gemmlowp::OutputPipelineEvalImpl.369" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.277", %"struct.gemmlowp::OutputPipelineEvalImpl.370", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.370" = type { %"struct.gemmlowp::OutputStageEvalImpl.280", %"struct.gemmlowp::OutputPipelineEvalImpl.371" }
%"struct.gemmlowp::OutputPipelineEvalImpl.371" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.374" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.375" }
%"struct.gemmlowp::OutputPipelineEvalImpl.375" = type { %"struct.gemmlowp::OutputStageEvalImpl.376", %"struct.gemmlowp::OutputPipelineEvalImpl.377" }
%"struct.gemmlowp::OutputStageEvalImpl.376" = type { %"struct.gemmlowp::OutputStageBiasAddition"* }
%"struct.gemmlowp::OutputPipelineEvalImpl.377" = type { %"struct.gemmlowp::OutputStageEvalImpl.290", %"struct.gemmlowp::OutputPipelineEvalImpl.378" }
%"struct.gemmlowp::OutputPipelineEvalImpl.378" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.293", %"struct.gemmlowp::OutputPipelineEvalImpl.379", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.379" = type { %"struct.gemmlowp::OutputStageEvalImpl.296", %"struct.gemmlowp::OutputPipelineEvalImpl.380" }
%"struct.gemmlowp::OutputPipelineEvalImpl.380" = type { i8 }
%"struct.gemmlowp::GemmWithPackedRhsTask.328" = type { %"struct.gemmlowp::Task", %"class.gemmlowp::GemmContext"*, %"struct.gemmlowp::KernelBase"*, %"class.gemmlowp::MatrixMap", %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::MatrixMap.182", %"struct.gemmlowp::MatrixBlockBounds", %"class.gemmlowp::VectorDup"*, %"class.gemmlowp::VectorDup.194"*, %"struct.gemmlowp::BlockParams"*, %"class.std::__1::tuple"* }
%"struct.gemmlowp::OutputPipelineExecutor.393" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.394" }
%"struct.gemmlowp::OutputPipelineEvalImpl.394" = type { %"struct.gemmlowp::OutputStageEvalImpl.230", %"struct.gemmlowp::OutputPipelineEvalImpl.395" }
%"struct.gemmlowp::OutputPipelineEvalImpl.395" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.233", %"struct.gemmlowp::OutputPipelineEvalImpl.396", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.396" = type { %"struct.gemmlowp::OutputStageEvalImpl.236", %"struct.gemmlowp::OutputPipelineEvalImpl.397" }
%"struct.gemmlowp::OutputPipelineEvalImpl.397" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.400" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.401" }
%"struct.gemmlowp::OutputPipelineEvalImpl.401" = type { %"struct.gemmlowp::OutputStageEvalImpl.246", %"struct.gemmlowp::OutputPipelineEvalImpl.402" }
%"struct.gemmlowp::OutputPipelineEvalImpl.402" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.249", %"struct.gemmlowp::OutputPipelineEvalImpl.403", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.403" = type { %"struct.gemmlowp::OutputStageEvalImpl.252", %"struct.gemmlowp::OutputPipelineEvalImpl.404" }
%"struct.gemmlowp::OutputPipelineEvalImpl.404" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.407" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.408" }
%"struct.gemmlowp::OutputPipelineEvalImpl.408" = type { %"struct.gemmlowp::OutputStageEvalImpl.262", %"struct.gemmlowp::OutputPipelineEvalImpl.409" }
%"struct.gemmlowp::OutputPipelineEvalImpl.409" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.264", %"struct.gemmlowp::OutputPipelineEvalImpl.410", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.410" = type { %"struct.gemmlowp::OutputStageEvalImpl.266", %"struct.gemmlowp::OutputPipelineEvalImpl.411" }
%"struct.gemmlowp::OutputPipelineEvalImpl.411" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.414" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.415" }
%"struct.gemmlowp::OutputPipelineEvalImpl.415" = type { %"struct.gemmlowp::OutputStageEvalImpl.274", %"struct.gemmlowp::OutputPipelineEvalImpl.416" }
%"struct.gemmlowp::OutputPipelineEvalImpl.416" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.277", %"struct.gemmlowp::OutputPipelineEvalImpl.417", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.417" = type { %"struct.gemmlowp::OutputStageEvalImpl.280", %"struct.gemmlowp::OutputPipelineEvalImpl.418" }
%"struct.gemmlowp::OutputPipelineEvalImpl.418" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.421" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.422" }
%"struct.gemmlowp::OutputPipelineEvalImpl.422" = type { %"struct.gemmlowp::OutputStageEvalImpl.290", %"struct.gemmlowp::OutputPipelineEvalImpl.423" }
%"struct.gemmlowp::OutputPipelineEvalImpl.423" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.293", %"struct.gemmlowp::OutputPipelineEvalImpl.424", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.424" = type { %"struct.gemmlowp::OutputStageEvalImpl.296", %"struct.gemmlowp::OutputPipelineEvalImpl.425" }
%"struct.gemmlowp::OutputPipelineEvalImpl.425" = type { i8 }
%"struct.gemmlowp::GemmWithPackedRhsTask.385" = type { %"struct.gemmlowp::Task", %"class.gemmlowp::GemmContext"*, %"struct.gemmlowp::KernelBase"*, %"class.gemmlowp::MatrixMap", %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::MatrixMap.195", %"struct.gemmlowp::MatrixBlockBounds", %"class.gemmlowp::VectorDup.194"*, %"class.gemmlowp::VectorDup"*, %"struct.gemmlowp::BlockParams"*, %"class.std::__1::tuple.187"* }
%"struct.gemmlowp::GemmWithPackedRhsTask.428" = type { %"struct.gemmlowp::Task", %"class.gemmlowp::GemmContext"*, %"struct.gemmlowp::KernelBase"*, %"class.gemmlowp::MatrixMap", %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::MatrixMap.182", %"struct.gemmlowp::MatrixBlockBounds", %"class.gemmlowp::VectorDup"*, %"class.gemmlowp::VectorDup.194"*, %"struct.gemmlowp::BlockParams"*, %"class.std::__1::tuple.187"* }
%"struct.ruy::Mat.438" = type <{ %"class.ruy::detail::ConstCheckingPtr.435", %"struct.ruy::MatLayout", i8, i8, [6 x i8] }>
%"class.ruy::detail::ConstCheckingPtr.435" = type { i8* }
%"class.ruy::MulParams.436" = type <{ i32*, i32, i32, i32*, i32*, i8, i8, [6 x i8] }>
%"struct.ruy::PMat.164" = type <{ i8*, i32*, %"struct.ruy::PMatLayout", i32, [4 x i8] }>
%"struct.ruy::Kernel.439" = type { i8 }
%"struct.ruy::Mat.463" = type <{ %"class.ruy::detail::ConstCheckingPtr.460", %"struct.ruy::MatLayout", i16, i8, [5 x i8] }>
%"class.ruy::detail::ConstCheckingPtr.460" = type { i16* }
%"class.ruy::MulParams.461" = type <{ i32*, i32, i32, i32*, i32*, i16, i16, [4 x i8] }>
%"class.gemmlowp::MatrixMap.479" = type <{ i16*, i32, i32, i32, [4 x i8] }>
%"class.std::__1::tuple.481" = type { %"struct.std::__1::__tuple_impl.482" }
%"struct.std::__1::__tuple_impl.482" = type { %"class.std::__1::__tuple_leaf", %"class.std::__1::__tuple_leaf.184", %"class.std::__1::__tuple_leaf.185", [4 x i8] }
%"class.std::__1::tuple.485" = type { %"struct.std::__1::__tuple_impl.486" }
%"struct.std::__1::__tuple_impl.486" = type { %"class.std::__1::__tuple_leaf.189", %"class.std::__1::__tuple_leaf.190" }
%"struct.ruy::Kernel.464" = type { i8 }
%"class.gemmlowp::MatrixMap.489" = type <{ i16*, i32, i32, i32, [4 x i8] }>
%"class.std::__1::tuple.491" = type { %"struct.std::__1::__tuple_impl.492" }
%"struct.std::__1::__tuple_impl.492" = type { %"class.std::__1::__tuple_leaf.199", %"class.std::__1::__tuple_leaf.184", %"class.std::__1::__tuple_leaf.185", [4 x i8] }
%"struct.gemmlowp::RegisterBlock.559" = type { %"struct.gemmlowp::RegisterBuffer.560" }
%"struct.gemmlowp::RegisterBuffer.560" = type { [64 x i16] }
%"struct.gemmlowp::OutputPipelineExecutor.495" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.496" }
%"struct.gemmlowp::OutputPipelineEvalImpl.496" = type { %"struct.gemmlowp::OutputStageEvalImpl", %"struct.gemmlowp::OutputPipelineEvalImpl.497" }
%"struct.gemmlowp::OutputPipelineEvalImpl.497" = type { %"struct.gemmlowp::OutputStageEvalImpl.217", %"struct.gemmlowp::OutputPipelineEvalImpl.498" }
%"struct.gemmlowp::OutputPipelineEvalImpl.498" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.219", %"struct.gemmlowp::OutputPipelineEvalImpl.499", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.499" = type { %"struct.gemmlowp::OutputStageEvalImpl.500", %"struct.gemmlowp::OutputPipelineEvalImpl.503" }
%"struct.gemmlowp::OutputStageEvalImpl.500" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.501" }
%"struct.gemmlowp::OutputStageEvalBufferImpl.501" = type { i8 }
%"struct.gemmlowp::OutputPipelineEvalImpl.503" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.506" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.507" }
%"struct.gemmlowp::OutputPipelineEvalImpl.507" = type { %"struct.gemmlowp::OutputStageEvalImpl.228", %"struct.gemmlowp::OutputPipelineEvalImpl.508" }
%"struct.gemmlowp::OutputPipelineEvalImpl.508" = type { %"struct.gemmlowp::OutputStageEvalImpl.230", %"struct.gemmlowp::OutputPipelineEvalImpl.509" }
%"struct.gemmlowp::OutputPipelineEvalImpl.509" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.233", %"struct.gemmlowp::OutputPipelineEvalImpl.510", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.510" = type { %"struct.gemmlowp::OutputStageEvalImpl.511", %"struct.gemmlowp::OutputPipelineEvalImpl.514" }
%"struct.gemmlowp::OutputStageEvalImpl.511" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.512" }
%"struct.gemmlowp::OutputStageEvalBufferImpl.512" = type { i8 }
%"struct.gemmlowp::OutputPipelineEvalImpl.514" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.517" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.518" }
%"struct.gemmlowp::OutputPipelineEvalImpl.518" = type { %"struct.gemmlowp::OutputStageEvalImpl.244", %"struct.gemmlowp::OutputPipelineEvalImpl.519" }
%"struct.gemmlowp::OutputPipelineEvalImpl.519" = type { %"struct.gemmlowp::OutputStageEvalImpl.246", %"struct.gemmlowp::OutputPipelineEvalImpl.520" }
%"struct.gemmlowp::OutputPipelineEvalImpl.520" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.249", %"struct.gemmlowp::OutputPipelineEvalImpl.521", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.521" = type { %"struct.gemmlowp::OutputStageEvalImpl.522", %"struct.gemmlowp::OutputPipelineEvalImpl.525" }
%"struct.gemmlowp::OutputStageEvalImpl.522" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.523" }
%"struct.gemmlowp::OutputStageEvalBufferImpl.523" = type { i8 }
%"struct.gemmlowp::OutputPipelineEvalImpl.525" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.528" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.529" }
%"struct.gemmlowp::OutputPipelineEvalImpl.529" = type { %"struct.gemmlowp::OutputStageEvalImpl.260", %"struct.gemmlowp::OutputPipelineEvalImpl.530" }
%"struct.gemmlowp::OutputPipelineEvalImpl.530" = type { %"struct.gemmlowp::OutputStageEvalImpl.262", %"struct.gemmlowp::OutputPipelineEvalImpl.531" }
%"struct.gemmlowp::OutputPipelineEvalImpl.531" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.264", %"struct.gemmlowp::OutputPipelineEvalImpl.532", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.532" = type { %"struct.gemmlowp::OutputStageEvalImpl.533", %"struct.gemmlowp::OutputPipelineEvalImpl.534" }
%"struct.gemmlowp::OutputStageEvalImpl.533" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.512" }
%"struct.gemmlowp::OutputPipelineEvalImpl.534" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.537" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.538" }
%"struct.gemmlowp::OutputPipelineEvalImpl.538" = type { %"struct.gemmlowp::OutputStageEvalImpl.272", %"struct.gemmlowp::OutputPipelineEvalImpl.539" }
%"struct.gemmlowp::OutputPipelineEvalImpl.539" = type { %"struct.gemmlowp::OutputStageEvalImpl.274", %"struct.gemmlowp::OutputPipelineEvalImpl.540" }
%"struct.gemmlowp::OutputPipelineEvalImpl.540" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.277", %"struct.gemmlowp::OutputPipelineEvalImpl.541", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.541" = type { %"struct.gemmlowp::OutputStageEvalImpl.542", %"struct.gemmlowp::OutputPipelineEvalImpl.545" }
%"struct.gemmlowp::OutputStageEvalImpl.542" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.543" }
%"struct.gemmlowp::OutputStageEvalBufferImpl.543" = type { i8 }
%"struct.gemmlowp::OutputPipelineEvalImpl.545" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.548" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.549" }
%"struct.gemmlowp::OutputPipelineEvalImpl.549" = type { %"struct.gemmlowp::OutputStageEvalImpl.288", %"struct.gemmlowp::OutputPipelineEvalImpl.550" }
%"struct.gemmlowp::OutputPipelineEvalImpl.550" = type { %"struct.gemmlowp::OutputStageEvalImpl.290", %"struct.gemmlowp::OutputPipelineEvalImpl.551" }
%"struct.gemmlowp::OutputPipelineEvalImpl.551" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.293", %"struct.gemmlowp::OutputPipelineEvalImpl.552", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.552" = type { %"struct.gemmlowp::OutputStageEvalImpl.553", %"struct.gemmlowp::OutputPipelineEvalImpl.556" }
%"struct.gemmlowp::OutputStageEvalImpl.553" = type { %"struct.gemmlowp::OutputStageEvalBufferImpl.554" }
%"struct.gemmlowp::OutputStageEvalBufferImpl.554" = type { i8 }
%"struct.gemmlowp::OutputPipelineEvalImpl.556" = type { i8 }
%"struct.gemmlowp::RegisterBlock.563" = type { %"struct.gemmlowp::RegisterBuffer.564" }
%"struct.gemmlowp::RegisterBuffer.564" = type { [16 x i16] }
%"struct.gemmlowp::RegisterBlock.561" = type { %"struct.gemmlowp::RegisterBuffer.562" }
%"struct.gemmlowp::RegisterBuffer.562" = type { [32 x i16] }
%"struct.gemmlowp::GemmWithPackedRhsTask.494" = type { %"struct.gemmlowp::Task", %"class.gemmlowp::GemmContext"*, %"struct.gemmlowp::KernelBase"*, %"class.gemmlowp::MatrixMap", %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::MatrixMap.489", %"struct.gemmlowp::MatrixBlockBounds", %"class.gemmlowp::VectorDup.194"*, %"class.gemmlowp::VectorDup"*, %"struct.gemmlowp::BlockParams"*, %"class.std::__1::tuple.491"* }
%"struct.gemmlowp::OutputPipelineExecutor.574" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.575" }
%"struct.gemmlowp::OutputPipelineEvalImpl.575" = type { %"struct.gemmlowp::OutputStageEvalImpl.331", %"struct.gemmlowp::OutputPipelineEvalImpl.576" }
%"struct.gemmlowp::OutputPipelineEvalImpl.576" = type { %"struct.gemmlowp::OutputStageEvalImpl.217", %"struct.gemmlowp::OutputPipelineEvalImpl.577" }
%"struct.gemmlowp::OutputPipelineEvalImpl.577" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.219", %"struct.gemmlowp::OutputPipelineEvalImpl.578", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.578" = type { %"struct.gemmlowp::OutputStageEvalImpl.500", %"struct.gemmlowp::OutputPipelineEvalImpl.579" }
%"struct.gemmlowp::OutputPipelineEvalImpl.579" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.582" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.583" }
%"struct.gemmlowp::OutputPipelineEvalImpl.583" = type { %"struct.gemmlowp::OutputStageEvalImpl.340", %"struct.gemmlowp::OutputPipelineEvalImpl.584" }
%"struct.gemmlowp::OutputPipelineEvalImpl.584" = type { %"struct.gemmlowp::OutputStageEvalImpl.230", %"struct.gemmlowp::OutputPipelineEvalImpl.585" }
%"struct.gemmlowp::OutputPipelineEvalImpl.585" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.233", %"struct.gemmlowp::OutputPipelineEvalImpl.586", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.586" = type { %"struct.gemmlowp::OutputStageEvalImpl.511", %"struct.gemmlowp::OutputPipelineEvalImpl.587" }
%"struct.gemmlowp::OutputPipelineEvalImpl.587" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.590" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.591" }
%"struct.gemmlowp::OutputPipelineEvalImpl.591" = type { %"struct.gemmlowp::OutputStageEvalImpl.349", %"struct.gemmlowp::OutputPipelineEvalImpl.592" }
%"struct.gemmlowp::OutputPipelineEvalImpl.592" = type { %"struct.gemmlowp::OutputStageEvalImpl.246", %"struct.gemmlowp::OutputPipelineEvalImpl.593" }
%"struct.gemmlowp::OutputPipelineEvalImpl.593" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.249", %"struct.gemmlowp::OutputPipelineEvalImpl.594", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.594" = type { %"struct.gemmlowp::OutputStageEvalImpl.522", %"struct.gemmlowp::OutputPipelineEvalImpl.595" }
%"struct.gemmlowp::OutputPipelineEvalImpl.595" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.598" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.599" }
%"struct.gemmlowp::OutputPipelineEvalImpl.599" = type { %"struct.gemmlowp::OutputStageEvalImpl.358", %"struct.gemmlowp::OutputPipelineEvalImpl.600" }
%"struct.gemmlowp::OutputPipelineEvalImpl.600" = type { %"struct.gemmlowp::OutputStageEvalImpl.262", %"struct.gemmlowp::OutputPipelineEvalImpl.601" }
%"struct.gemmlowp::OutputPipelineEvalImpl.601" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.264", %"struct.gemmlowp::OutputPipelineEvalImpl.602", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.602" = type { %"struct.gemmlowp::OutputStageEvalImpl.533", %"struct.gemmlowp::OutputPipelineEvalImpl.603" }
%"struct.gemmlowp::OutputPipelineEvalImpl.603" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.606" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.607" }
%"struct.gemmlowp::OutputPipelineEvalImpl.607" = type { %"struct.gemmlowp::OutputStageEvalImpl.367", %"struct.gemmlowp::OutputPipelineEvalImpl.608" }
%"struct.gemmlowp::OutputPipelineEvalImpl.608" = type { %"struct.gemmlowp::OutputStageEvalImpl.274", %"struct.gemmlowp::OutputPipelineEvalImpl.609" }
%"struct.gemmlowp::OutputPipelineEvalImpl.609" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.277", %"struct.gemmlowp::OutputPipelineEvalImpl.610", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.610" = type { %"struct.gemmlowp::OutputStageEvalImpl.542", %"struct.gemmlowp::OutputPipelineEvalImpl.611" }
%"struct.gemmlowp::OutputPipelineEvalImpl.611" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.614" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.615" }
%"struct.gemmlowp::OutputPipelineEvalImpl.615" = type { %"struct.gemmlowp::OutputStageEvalImpl.376", %"struct.gemmlowp::OutputPipelineEvalImpl.616" }
%"struct.gemmlowp::OutputPipelineEvalImpl.616" = type { %"struct.gemmlowp::OutputStageEvalImpl.290", %"struct.gemmlowp::OutputPipelineEvalImpl.617" }
%"struct.gemmlowp::OutputPipelineEvalImpl.617" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.293", %"struct.gemmlowp::OutputPipelineEvalImpl.618", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.618" = type { %"struct.gemmlowp::OutputStageEvalImpl.553", %"struct.gemmlowp::OutputPipelineEvalImpl.619" }
%"struct.gemmlowp::OutputPipelineEvalImpl.619" = type { i8 }
%"struct.gemmlowp::GemmWithPackedRhsTask.573" = type { %"struct.gemmlowp::Task", %"class.gemmlowp::GemmContext"*, %"struct.gemmlowp::KernelBase"*, %"class.gemmlowp::MatrixMap", %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::MatrixMap.479", %"struct.gemmlowp::MatrixBlockBounds", %"class.gemmlowp::VectorDup"*, %"class.gemmlowp::VectorDup.194"*, %"struct.gemmlowp::BlockParams"*, %"class.std::__1::tuple.481"* }
%"struct.gemmlowp::OutputPipelineExecutor.631" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.632" }
%"struct.gemmlowp::OutputPipelineEvalImpl.632" = type { %"struct.gemmlowp::OutputStageEvalImpl.230", %"struct.gemmlowp::OutputPipelineEvalImpl.633" }
%"struct.gemmlowp::OutputPipelineEvalImpl.633" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.233", %"struct.gemmlowp::OutputPipelineEvalImpl.634", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.634" = type { %"struct.gemmlowp::OutputStageEvalImpl.511", %"struct.gemmlowp::OutputPipelineEvalImpl.635" }
%"struct.gemmlowp::OutputPipelineEvalImpl.635" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.638" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.639" }
%"struct.gemmlowp::OutputPipelineEvalImpl.639" = type { %"struct.gemmlowp::OutputStageEvalImpl.246", %"struct.gemmlowp::OutputPipelineEvalImpl.640" }
%"struct.gemmlowp::OutputPipelineEvalImpl.640" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.249", %"struct.gemmlowp::OutputPipelineEvalImpl.641", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.641" = type { %"struct.gemmlowp::OutputStageEvalImpl.522", %"struct.gemmlowp::OutputPipelineEvalImpl.642" }
%"struct.gemmlowp::OutputPipelineEvalImpl.642" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.645" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.646" }
%"struct.gemmlowp::OutputPipelineEvalImpl.646" = type { %"struct.gemmlowp::OutputStageEvalImpl.262", %"struct.gemmlowp::OutputPipelineEvalImpl.647" }
%"struct.gemmlowp::OutputPipelineEvalImpl.647" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.264", %"struct.gemmlowp::OutputPipelineEvalImpl.648", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.648" = type { %"struct.gemmlowp::OutputStageEvalImpl.533", %"struct.gemmlowp::OutputPipelineEvalImpl.649" }
%"struct.gemmlowp::OutputPipelineEvalImpl.649" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.652" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.653" }
%"struct.gemmlowp::OutputPipelineEvalImpl.653" = type { %"struct.gemmlowp::OutputStageEvalImpl.274", %"struct.gemmlowp::OutputPipelineEvalImpl.654" }
%"struct.gemmlowp::OutputPipelineEvalImpl.654" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.277", %"struct.gemmlowp::OutputPipelineEvalImpl.655", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.655" = type { %"struct.gemmlowp::OutputStageEvalImpl.542", %"struct.gemmlowp::OutputPipelineEvalImpl.656" }
%"struct.gemmlowp::OutputPipelineEvalImpl.656" = type { i8 }
%"struct.gemmlowp::OutputPipelineExecutor.659" = type { %"struct.gemmlowp::OutputPipelineEvalImpl.660" }
%"struct.gemmlowp::OutputPipelineEvalImpl.660" = type { %"struct.gemmlowp::OutputStageEvalImpl.290", %"struct.gemmlowp::OutputPipelineEvalImpl.661" }
%"struct.gemmlowp::OutputPipelineEvalImpl.661" = type <{ %"struct.gemmlowp::OutputStageEvalImpl.293", %"struct.gemmlowp::OutputPipelineEvalImpl.662", [6 x i8] }>
%"struct.gemmlowp::OutputPipelineEvalImpl.662" = type { %"struct.gemmlowp::OutputStageEvalImpl.553", %"struct.gemmlowp::OutputPipelineEvalImpl.663" }
%"struct.gemmlowp::OutputPipelineEvalImpl.663" = type { i8 }
%"struct.gemmlowp::GemmWithPackedRhsTask.623" = type { %"struct.gemmlowp::Task", %"class.gemmlowp::GemmContext"*, %"struct.gemmlowp::KernelBase"*, %"class.gemmlowp::MatrixMap", %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::MatrixMap.489", %"struct.gemmlowp::MatrixBlockBounds", %"class.gemmlowp::VectorDup.194"*, %"class.gemmlowp::VectorDup"*, %"struct.gemmlowp::BlockParams"*, %"class.std::__1::tuple.485"* }
%"struct.gemmlowp::GemmWithPackedRhsTask.666" = type { %"struct.gemmlowp::Task", %"class.gemmlowp::GemmContext"*, %"struct.gemmlowp::KernelBase"*, %"class.gemmlowp::MatrixMap", %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::MatrixMap.479", %"struct.gemmlowp::MatrixBlockBounds", %"class.gemmlowp::VectorDup"*, %"class.gemmlowp::VectorDup.194"*, %"struct.gemmlowp::BlockParams"*, %"class.std::__1::tuple.485"* }

$_ZN6tflite3ops7builtin15fully_connected10CheckTypesEP13TfLiteContextPK12TfLiteTensorS7_S7_PS5_P26TfLiteFullyConnectedParams = comdat any

$_ZN6tflite12tensor_utils23ApplyActivationToVectorEPKfi21TfLiteFusedActivationPf = comdat any

$_ZN6tflite3ops7builtin15fully_connected7PrepareILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode = comdat any

$_ZN6tflite3ops7builtin15fully_connected4EvalILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode = comdat any

$_ZN6tflite3ops7builtin15fully_connected7PrepareILNS2_10KernelTypeE1EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode = comdat any

$_ZN6tflite3ops7builtin15fully_connected4EvalILNS2_10KernelTypeE1EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode = comdat any

$_ZN6tflite3ops7builtin15fully_connected7PrepareILNS2_10KernelTypeE2EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode = comdat any

$_ZN6tflite3ops7builtin15fully_connected4EvalILNS2_10KernelTypeE2EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode = comdat any

$_ZN5Eigen8internal21dense_assignment_loopINS0_31generic_dense_assignment_kernelINS0_9evaluatorINS_12ArrayWrapperINS_3MapINS_6MatrixIfLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEEEEEENS3_INS_12CwiseUnaryOpINS0_14scalar_tanh_opIfEEKSB_EEEENS0_9assign_opIffEELi0EEELi3ELi0EE3runERSL_ = comdat any

$_ZN5Eigen8internal26call_dense_assignment_loopINS_12ArrayWrapperINS_3MapINS_6MatrixIfLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEEEENS_12CwiseUnaryOpINS0_18scalar_logistic_opIfEEKS9_EENS0_9assign_opIffEEEEvRT_RKT0_RKT1_ = comdat any

$_ZN6tflite3ops7builtin15fully_connected9EvalFloatILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_ = comdat any

$_ZN6tflite3ops7builtin15fully_connected21EvalShuffledQuantizedILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_SH_ = comdat any

$_ZN6tflite3ops7builtin15fully_connected13EvalQuantizedILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_ = comdat any

$_ZN6tflite13reference_ops26FullyConnectedSparseWeightERK14TfLiteSparsityRKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKfS9_SB_S9_SB_S9_Pf = comdat any

$_ZN6tflite8optimize8sparsity15FormatConverterIfED2Ev = comdat any

$_ZN6tflite13reference_ops22ShuffledFullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKiS6_PsPh = comdat any

$_ZN6tflite13reference_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKiS6_Ph = comdat any

$_ZN6tflite13reference_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKiS6_Ps = comdat any

$_ZN6tflite3ops7builtin15fully_connected9EvalFloatILNS2_10KernelTypeE1EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_ = comdat any

$_ZN6tflite3ops7builtin15fully_connected21EvalShuffledQuantizedILNS2_10KernelTypeE1EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_SH_ = comdat any

$_ZN6tflite3ops7builtin15fully_connected13EvalQuantizedILNS2_10KernelTypeE1EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_ = comdat any

$_ZN6tflite13optimized_ops26FullyConnectedSparseWeightERK14TfLiteSparsityRKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKfS9_SB_S9_SB_S9_Pf = comdat any

$_ZN6tflite13optimized_ops29FullyConnectedSparseWeight1x4ERK14TfLiteSparsityRKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKfS9_SB_S9_SB_S9_PfPNS_17CpuBackendContextE = comdat any

$_ZN6tflite13optimized_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfPNS_17CpuBackendContextE = comdat any

$_ZN6tflite13optimized_ops33FullyConnectedSparseWeight1x4TaskD0Ev = comdat any

$_ZN6tflite13optimized_ops33FullyConnectedSparseWeight1x4Task3RunEv = comdat any

$_ZN8gemmlowp4TaskD0Ev = comdat any

$_ZNSt3__16vectorIN6tflite13optimized_ops33FullyConnectedSparseWeight1x4TaskENS_9allocatorIS3_EEE24__emplace_back_slow_pathIJRK14TfLiteSparsityRKNS1_20FullyConnectedParamsERKNS1_12RuntimeShapeERPKfSG_SJ_SG_SJ_SG_RPfRiSM_RNS1_17CpuBackendContextEEEEvDpOT_ = comdat any

$_ZN8gemmlowp11WorkersPool7ExecuteIN6tflite13optimized_ops33FullyConnectedSparseWeight1x4TaskEEEviPT_ = comdat any

$_ZN8gemmlowp11WorkersPool13CreateWorkersEm = comdat any

$_ZN8gemmlowp6Worker10ThreadFuncEPv = comdat any

$_ZN8gemmlowp6Worker10ThreadFuncEv = comdat any

$_ZN6tflite16cpu_backend_gemm6detail16GemmImplUsingRuyIffffLNS0_18QuantizationFlavorE0EE3RunERKNS0_12MatrixParamsIfEEPKfS8_SA_S8_PfRKNS0_10GemmParamsIffLS3_0EEEPNS_17CpuBackendContextE = comdat any

$_ZN3ruy11DispatchMulILNS_4PathE26EfffNS_9MulParamsIffEEEEvRKNS_3MatIT0_EERKNS4_IT1_EERKT3_PNS_3CtxEPNS4_IT2_EE = comdat any

$_ZN3ruy22HandlePrepackedCachingEPNS_11TrMulParamsEPNS_3CtxE = comdat any

$_ZN3ruy7RunPackILNS_4PathE16ENS_17FixedKernelLayoutILNS_5OrderE1ELi1ELi16EEEffEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii = comdat any

$_ZN3ruy9RunKernelILNS_4PathE16EfffNS_9MulParamsIffEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE = comdat any

$_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEffEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii = comdat any

$_ZN3ruy9RunKernelILNS_4PathE2EfffNS_9MulParamsIffEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE = comdat any

$_ZN3ruy8PackImplILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEfffE3RunENS_6TuningERKNS_3MatIfEEPNS_4PMatIfEEii = comdat any

$_ZNK3ruy6KernelILNS_4PathE2EfffNS_9MulParamsIffEEE3RunERKNS_4PMatIfEES8_RKS3_iiiiPNS_3MatIfEE = comdat any

$_ZN3ruy27PathSearchOnlyCompiledPathsILNS_4PathE26ELb1ELi3EfffNS_9MulParamsIffEEE6SearchES1_PNS_11TrMulParamsE = comdat any

$_ZN3ruy19PopulateTrMulParamsILNS_4PathE8EfffNS_9MulParamsIffEEEEvPNS_11TrMulParamsE = comdat any

$_ZN3ruy7RunPackILNS_4PathE8ENS_17FixedKernelLayoutILNS_5OrderE1ELi1ELi8EEEffEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii = comdat any

$_ZN3ruy9RunKernelILNS_4PathE8EfffNS_9MulParamsIffEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE = comdat any

$_ZN6tflite13optimized_ops22ShuffledFullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKiS6_PsPhPNS_17CpuBackendContextE = comdat any

$_ZN6tflite13optimized_ops32ShuffledFullyConnectedWorkerImplEPKhPKaiiiiPKiiiPs = comdat any

$_ZN6tflite13optimized_ops32ShuffledFullyConnectedWorkerTaskD0Ev = comdat any

$_ZN6tflite13optimized_ops32ShuffledFullyConnectedWorkerTask3RunEv = comdat any

$_ZNSt3__16vectorIN6tflite13optimized_ops32ShuffledFullyConnectedWorkerTaskENS_9allocatorIS3_EEE24__emplace_back_slow_pathIJRPhPKaRKiiSD_SD_PSC_SD_SD_PsEEEvDpOT_ = comdat any

$_ZN8gemmlowp11WorkersPool7ExecuteIN6tflite13optimized_ops32ShuffledFullyConnectedWorkerTaskEEEviPT_ = comdat any

$_ZN6tflite13optimized_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKiS6_PhPNS_17CpuBackendContextE = comdat any

$_ZN6tflite13optimized_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKiS6_PsPNS_17CpuBackendContextE = comdat any

$_ZN6tflite16cpu_backend_gemm6detail16GemmImplUsingRuyIhhihLNS0_18QuantizationFlavorE1EE3RunERKNS0_12MatrixParamsIhEEPKhS8_SA_S8_PhRKNS0_10GemmParamsIihLS3_1EEEPNS_17CpuBackendContextE = comdat any

$_ZN6tflite16cpu_backend_gemm6detail21GemmImplUsingGemmlowpIhhihLNS0_18QuantizationFlavorE1EE3RunERKNS0_12MatrixParamsIhEEPKhS8_SA_S8_PhRKNS0_10GemmParamsIihLS3_1EEEPNS_17CpuBackendContextE = comdat any

$_ZN3ruy11DispatchMulILNS_4PathE26EhhhNS_9MulParamsIihEEEEvRKNS_3MatIT0_EERKNS4_IT1_EERKT3_PNS_3CtxEPNS4_IT2_EE = comdat any

$_ZN3ruy17CreateTrMulParamsILNS_4PathE26EhhhNS_9MulParamsIihEEEEvRKNS_3MatIT0_EERKNS4_IT1_EERKT3_PNS4_IT2_EES1_PNS_11TrMulParamsE = comdat any

$_ZN3ruy19PopulateTrMulParamsILNS_4PathE16EhhhNS_9MulParamsIihEEEEvPNS_11TrMulParamsE = comdat any

$_ZN3ruy7RunPackILNS_4PathE16ENS_17FixedKernelLayoutILNS_5OrderE0ELi4ELi16EEEhaEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii = comdat any

$_ZN3ruy9RunKernelILNS_4PathE16EaahNS_9MulParamsIihEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE = comdat any

$_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEhhEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii = comdat any

$_ZN3ruy9RunKernelILNS_4PathE2EhhhNS_9MulParamsIihEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE = comdat any

$_ZN3ruy8PackImplILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEhhiE3RunENS_6TuningERKNS_3MatIhEEPNS_4PMatIhEEii = comdat any

$_ZNK3ruy6KernelILNS_4PathE2EhhhNS_9MulParamsIihEEE3RunERKNS_4PMatIhEES8_RKS3_iiiiPNS_3MatIhEE = comdat any

$_ZN3ruy19PopulateTrMulParamsILNS_4PathE8EhhhNS_9MulParamsIihEEEEvPNS_11TrMulParamsE = comdat any

$_ZN3ruy7RunPackILNS_4PathE8ENS_17FixedKernelLayoutILNS_5OrderE0ELi4ELi8EEEhaEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii = comdat any

$_ZN3ruy9RunKernelILNS_4PathE8EaahNS_9MulParamsIihEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE = comdat any

$_ZN8gemmlowp17DispatchGemmShapeIhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENS7_IS8_LS9_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIS8_LS9_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSP_ISR_XT3_EEEPNSP_IT0_XT4_EEERKT5_RKT6_RKT7_ = comdat any

$_ZN8gemmlowp17DispatchGemmShapeIhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENS7_IS8_LS9_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIS8_LS9_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSP_ISR_XT3_EEEPNSP_IT0_XT4_EEERKT5_RKT6_RKT7_ = comdat any

$_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSZ_IS11_XT4_EEEPNSZ_IT1_XT5_EEERKT6_RKT7_RKT8_ = comdat any

$_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSZ_IS11_XT4_EEEPNSZ_IT1_XT5_EEERKT6_RKT7_RKT8_ = comdat any

$_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSY_IS10_XT4_EEEPNSY_IT1_XT5_EEERKT6_RKT7_RKT8_ = comdat any

$_ZN8gemmlowp11BlockParams4InitINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES7_EEEEviiiiiif = comdat any

$_ZN8gemmlowp9Allocator6CommitEv = comdat any

$_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIhLNS_8MapOrderE1EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE1EEENSC_ISD_LSE_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISD_LSE_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SZ_RKT2_RKT3_RKT4_ = comdat any

$_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev = comdat any

$_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE7PackRunEiiii = comdat any

$_ZN8gemmlowp24PackingRegisterBlockBaseINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE4PackEPSB_i = comdat any

$_ZN8gemmlowp11ComputeImplINS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEES7_NS_12PackedResultEE10ComputeRunEiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii = comdat any

$_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_13RegisterBlockIiLi8ELi4EEEE7ExecuteINS_9MatrixMapIhLNS_8MapOrderE0EEEEEvSE_PT_iiii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi1ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi3ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii = comdat any

$_ZN8gemmlowp20StoreFinalOutputImplINS_13RegisterBlockIhLi8ELi8EEENS_9MatrixMapIhLNS_8MapOrderE1EEEE3RunERKS2_PS5_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi0ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii = comdat any

$_ZN8gemmlowp16StoreFinalOutputINS_13RegisterBlockIhLi4ELi4EEENS_9MatrixMapIhLNS_8MapOrderE1EEEEEvT_PT0_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi2ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii = comdat any

$_ZNK8gemmlowp19OutputStageEvalImplINS_32OutputStageSaturatingCastToUint8ENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_13RegisterBlockIiLi1ELi4EEEE7ExecuteINS_9MatrixMapIhLNS_8MapOrderE1EEEEEvSE_PT_iiii = comdat any

$_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi4EEEE4EvalES3_ = comdat any

$_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_13RegisterBlockIiLi8ELi4EEEE7ExecuteINS_9MatrixMapIhLNS_8MapOrderE1EEEEEvSE_PT_iiii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi1ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalESE_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_13RegisterBlockIiLi4ELi1EEEE7ExecuteINS_9MatrixMapIhLNS_8MapOrderE1EEEEEvSE_PT_iiii = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEED2Ev = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEED0Ev = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEE3RunEv = comdat any

$_ZN8gemmlowp11WorkersPool28LegacyExecuteAndDestroyTasksERKNSt3__16vectorIPNS_4TaskENS1_9allocatorIS4_EEEE = comdat any

$_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSY_IS10_XT4_EEEPNSY_IT1_XT5_EEERKT6_RKT7_RKT8_ = comdat any

$_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIhLNS_8MapOrderE0EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE0EEENSC_ISD_LSE_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISD_LSE_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SZ_RKT2_RKT3_RKT4_ = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_13RegisterBlockIiLi8ELi4EEEE7ExecuteINS_9MatrixMapIhLNS_8MapOrderE0EEEEEvSE_PT_iiii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi1ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi3ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi0ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii = comdat any

$_ZN8gemmlowp16StoreFinalOutputINS_13RegisterBlockIhLi4ELi4EEENS_9MatrixMapIhLNS_8MapOrderE0EEEEEvT_PT0_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi2ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_13RegisterBlockIiLi1ELi4EEEE7ExecuteINS_9MatrixMapIhLNS_8MapOrderE0EEEEEvSE_PT_iiii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi1ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalESE_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_13RegisterBlockIiLi4ELi1EEEE7ExecuteINS_9MatrixMapIhLNS_8MapOrderE0EEEEEvSE_PT_iiii = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEED2Ev = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEED0Ev = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEE3RunEv = comdat any

$_ZNK8gemmlowp15ReferenceKernelINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEE4NameEv = comdat any

$_ZNK8gemmlowp15ReferenceKernelINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEE3RunEPimmPKhSB_mm = comdat any

$_ZN8gemmlowp13DefaultKernelINS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEEED0Ev = comdat any

$_ZN8gemmlowp10KernelBaseD2Ev = comdat any

$_ZN8gemmlowp17DispatchGemmShapeIhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENS7_IS8_LS9_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSL_ISN_XT3_EEEPNSL_IT0_XT4_EEERKT5_RKT6_RKT7_ = comdat any

$_ZN8gemmlowp17DispatchGemmShapeIhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENS7_IS8_LS9_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSL_ISN_XT3_EEEPNSL_IT0_XT4_EEERKT5_RKT6_RKT7_ = comdat any

$_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSV_ISX_XT4_EEEPNSV_IT1_XT5_EEERKT6_RKT7_RKT8_ = comdat any

$_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSV_ISX_XT4_EEEPNSV_IT1_XT5_EEERKT6_RKT7_RKT8_ = comdat any

$_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSU_ISW_XT4_EEEPNSU_IT1_XT5_EEERKT6_RKT7_RKT8_ = comdat any

$_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIhLNS_8MapOrderE1EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE1EEENSC_ISD_LSE_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SV_RKT2_RKT3_RKT4_ = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi0ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalES8_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi2ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalES8_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi1ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalES8_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi0ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalES8_ii = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEED2Ev = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEED0Ev = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEE3RunEv = comdat any

$_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSU_ISW_XT4_EEEPNSU_IT1_XT5_EEERKT6_RKT7_RKT8_ = comdat any

$_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIhLNS_8MapOrderE0EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE0EEENSC_ISD_LSE_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SV_RKT2_RKT3_RKT4_ = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEED2Ev = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEED0Ev = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEE3RunEv = comdat any

$_ZN6tflite16cpu_backend_gemm6detail16GemmImplUsingRuyIaaiaLNS0_18QuantizationFlavorE1EE3RunERKNS0_12MatrixParamsIaEEPKaS8_SA_S8_PaRKNS0_10GemmParamsIiaLS3_1EEEPNS_17CpuBackendContextE = comdat any

$_ZN3ruy11DispatchMulILNS_4PathE26EaaaNS_9MulParamsIiaEEEEvRKNS_3MatIT0_EERKNS4_IT1_EERKT3_PNS_3CtxEPNS4_IT2_EE = comdat any

$_ZN3ruy7RunPackILNS_4PathE16ENS_17FixedKernelLayoutILNS_5OrderE0ELi4ELi16EEEaaEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii = comdat any

$_ZN3ruy9RunKernelILNS_4PathE16EaaaNS_9MulParamsIiaEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE = comdat any

$_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEaaEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii = comdat any

$_ZN3ruy9RunKernelILNS_4PathE2EaaaNS_9MulParamsIiaEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE = comdat any

$_ZN3ruy8PackImplILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEaaiE3RunENS_6TuningERKNS_3MatIaEEPNS_4PMatIaEEii = comdat any

$_ZNK3ruy6KernelILNS_4PathE2EaaaNS_9MulParamsIiaEEE3RunERKNS_4PMatIaEES8_RKS3_iiiiPNS_3MatIaEE = comdat any

$_ZN3ruy27PathSearchOnlyCompiledPathsILNS_4PathE26ELb1ELi3EaaaNS_9MulParamsIiaEEE6SearchES1_PNS_11TrMulParamsE = comdat any

$_ZN3ruy19PopulateTrMulParamsILNS_4PathE8EaaaNS_9MulParamsIiaEEEEvPNS_11TrMulParamsE = comdat any

$_ZN3ruy7RunPackILNS_4PathE8ENS_17FixedKernelLayoutILNS_5OrderE0ELi4ELi8EEEaaEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii = comdat any

$_ZN3ruy9RunKernelILNS_4PathE8EaaaNS_9MulParamsIiaEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE = comdat any

$_ZN8gemmlowp4TaskD2Ev = comdat any

$_ZN6tflite16cpu_backend_gemm6detail16GemmImplUsingRuyIhhisLNS0_18QuantizationFlavorE1EE3RunERKNS0_12MatrixParamsIhEEPKhS8_SA_RKNS5_IsEEPsRKNS0_10GemmParamsIisLS3_1EEEPNS_17CpuBackendContextE = comdat any

$_ZN6tflite16cpu_backend_gemm6detail21GemmImplUsingGemmlowpIhhisLNS0_18QuantizationFlavorE1EE3RunERKNS0_12MatrixParamsIhEEPKhS8_SA_RKNS5_IsEEPsRKNS0_10GemmParamsIisLS3_1EEEPNS_17CpuBackendContextE = comdat any

$_ZN3ruy11DispatchMulILNS_4PathE26EhhsNS_9MulParamsIisEEEEvRKNS_3MatIT0_EERKNS4_IT1_EERKT3_PNS_3CtxEPNS4_IT2_EE = comdat any

$_ZN3ruy17CreateTrMulParamsILNS_4PathE26EhhsNS_9MulParamsIisEEEEvRKNS_3MatIT0_EERKNS4_IT1_EERKT3_PNS4_IT2_EES1_PNS_11TrMulParamsE = comdat any

$_ZN3ruy19PopulateTrMulParamsILNS_4PathE16EhhsNS_9MulParamsIisEEEEvPNS_11TrMulParamsE = comdat any

$_ZN3ruy9RunKernelILNS_4PathE16EaasNS_9MulParamsIisEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE = comdat any

$_ZN3ruy9RunKernelILNS_4PathE2EhhsNS_9MulParamsIisEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE = comdat any

$_ZNK3ruy6KernelILNS_4PathE2EhhsNS_9MulParamsIisEEE3RunERKNS_4PMatIhEES8_RKS3_iiiiPNS_3MatIsEE = comdat any

$_ZN3ruy19PopulateTrMulParamsILNS_4PathE8EhhsNS_9MulParamsIisEEEEvPNS_11TrMulParamsE = comdat any

$_ZN3ruy9RunKernelILNS_4PathE8EaasNS_9MulParamsIisEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE = comdat any

$_ZN8gemmlowp17DispatchGemmShapeIhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENS7_IS8_LS9_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIS8_LS9_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSP_ISR_XT3_EEEPNSP_IT0_XT4_EEERKT5_RKT6_RKT7_ = comdat any

$_ZN8gemmlowp17DispatchGemmShapeIhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENS7_IS8_LS9_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIS8_LS9_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSP_ISR_XT3_EEEPNSP_IT0_XT4_EEERKT5_RKT6_RKT7_ = comdat any

$_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSZ_IS11_XT4_EEEPNSZ_IT1_XT5_EEERKT6_RKT7_RKT8_ = comdat any

$_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSZ_IS11_XT4_EEEPNSZ_IT1_XT5_EEERKT6_RKT7_RKT8_ = comdat any

$_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSY_IS10_XT4_EEEPNSY_IT1_XT5_EEERKT6_RKT7_RKT8_ = comdat any

$_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIsLNS_8MapOrderE1EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE1EEENSC_ISD_LSE_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISD_LSE_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SZ_RKT2_RKT3_RKT4_ = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii = comdat any

$_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi8ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE0EEEEEvSE_PT_iiii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii = comdat any

$_ZN8gemmlowp20StoreFinalOutputImplINS_13RegisterBlockIsLi8ELi8EEENS_9MatrixMapIsLNS_8MapOrderE1EEEE3RunERKS2_PS5_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi8ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE1EEEEEvSE_PT_iiii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalESE_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalESE_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi4ELi1EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE1EEEEEvSE_PT_iiii = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED2Ev = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED0Ev = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEE3RunEv = comdat any

$_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSY_IS10_XT4_EEEPNSY_IT1_XT5_EEERKT6_RKT7_RKT8_ = comdat any

$_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIsLNS_8MapOrderE0EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE0EEENSC_ISD_LSE_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISD_LSE_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SZ_RKT2_RKT3_RKT4_ = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi8ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE0EEEEEvSE_PT_iiii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi1ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE0EEEEEvSE_PT_iiii = comdat any

$_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi8ELi1EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE0EEEEEvSE_PT_iiii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalESE_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalESE_ii = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED2Ev = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED0Ev = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEE3RunEv = comdat any

$_ZN8gemmlowp17DispatchGemmShapeIhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENS7_IS8_LS9_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSL_ISN_XT3_EEEPNSL_IT0_XT4_EEERKT5_RKT6_RKT7_ = comdat any

$_ZN8gemmlowp17DispatchGemmShapeIhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENS7_IS8_LS9_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSL_ISN_XT3_EEEPNSL_IT0_XT4_EEERKT5_RKT6_RKT7_ = comdat any

$_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSV_ISX_XT4_EEEPNSV_IT1_XT5_EEERKT6_RKT7_RKT8_ = comdat any

$_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSV_ISX_XT4_EEEPNSV_IT1_XT5_EEERKT6_RKT7_RKT8_ = comdat any

$_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSU_ISW_XT4_EEEPNSU_IT1_XT5_EEERKT6_RKT7_RKT8_ = comdat any

$_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIsLNS_8MapOrderE1EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE1EEENSC_ISD_LSE_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SV_RKT2_RKT3_RKT4_ = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalES8_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi4ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE1EEEEEvS8_PT_iiii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalES8_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalES8_ii = comdat any

$_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalES8_ii = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED2Ev = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED0Ev = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEE3RunEv = comdat any

$_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSU_ISW_XT4_EEEPNSU_IT1_XT5_EEERKT6_RKT7_RKT8_ = comdat any

$_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIsLNS_8MapOrderE0EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE0EEENSC_ISD_LSE_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SV_RKT2_RKT3_RKT4_ = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii = comdat any

$_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi4ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE0EEEEEvS8_PT_iiii = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED2Ev = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED0Ev = comdat any

$_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEE3RunEv = comdat any

$_ZN6tflite3ops7builtin15fully_connected21EvalShuffledQuantizedILNS2_10KernelTypeE2EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_SH_ = comdat any

$_ZN6tflite3ops7builtin15fully_connected13EvalQuantizedILNS2_10KernelTypeE2EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_ = comdat any

$_ZTVN6tflite13optimized_ops33FullyConnectedSparseWeight1x4TaskE = comdat any

$_ZTVN8gemmlowp4TaskE = comdat any

$_ZTVN6tflite13optimized_ops32ShuffledFullyConnectedWorkerTaskE = comdat any

$_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count = comdat any

$_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count = comdat any

$_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEE = comdat any

$_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEE = comdat any

$_ZTVN8gemmlowp13DefaultKernelINS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEEEE = comdat any

$_ZZNK8gemmlowp15ReferenceKernelINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEE4NameEvE3buf = comdat any

$_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEE = comdat any

$_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEE = comdat any

$_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEE = comdat any

$_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEE = comdat any

$_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEE = comdat any

$_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEE = comdat any

@.str = private unnamed_addr constant [23 x i8] c"%s:%d %s was not true.\00", align 1
@.str.3 = private unnamed_addr constant [72 x i8] c"../../third_party/tflite/src/tensorflow/lite/kernels/fully_connected.cc\00", align 1
@.str.4 = private unnamed_addr constant [51 x i8] c"node->inputs->size == 2 || node->inputs->size == 3\00", align 1
@.str.5 = private unnamed_addr constant [26 x i8] c"%s:%d %s != %s (%d != %d)\00", align 1
@.str.6 = private unnamed_addr constant [20 x i8] c"node->outputs->size\00", align 1
@.str.7 = private unnamed_addr constant [23 x i8] c"expected_outputs_count\00", align 1
@.str.8 = private unnamed_addr constant [22 x i8] c"NumDimensions(filter)\00", align 1
@.str.9 = private unnamed_addr constant [2 x i8] c"2\00", align 1
@.str.10 = private unnamed_addr constant [18 x i8] c"NumElements(bias)\00", align 1
@.str.11 = private unnamed_addr constant [27 x i8] c"SizeOfDimension(filter, 0)\00", align 1
@.str.12 = private unnamed_addr constant [25 x i8] c"input->params.zero_point\00", align 1
@.str.13 = private unnamed_addr constant [2 x i8] c"0\00", align 1
@.str.14 = private unnamed_addr constant [26 x i8] c"output->params.zero_point\00", align 1
@.str.15 = private unnamed_addr constant [41 x i8] c"input->dims->data[input->dims->size - 1]\00", align 1
@.str.16 = private unnamed_addr constant [27 x i8] c"SizeOfDimension(filter, 1)\00", align 1
@_ZZN6tflite3ops7builtin28Register_FULLY_CONNECTED_REFEvE1r = internal global { i8* (%struct.TfLiteContext*, i8*, i64)*, void (%struct.TfLiteContext*, i8*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteNode*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteNode*)*, i8* (%struct.TfLiteContext*, %struct.TfLiteNode*)*, i32, i8*, i32 } { i8* (%struct.TfLiteContext*, i8*, i64)* @_ZN6tflite3ops7builtin15fully_connected4InitEP13TfLiteContextPKcm, void (%struct.TfLiteContext*, i8*)* @_ZN6tflite3ops7builtin15fully_connected4FreeEP13TfLiteContextPv, i32 (%struct.TfLiteContext*, %struct.TfLiteNode*)* @_ZN6tflite3ops7builtin15fully_connected7PrepareILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode, i32 (%struct.TfLiteContext*, %struct.TfLiteNode*)* @_ZN6tflite3ops7builtin15fully_connected4EvalILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode, i8* (%struct.TfLiteContext*, %struct.TfLiteNode*)* null, i32 0, i8* null, i32 0 }, align 8
@_ZZN6tflite3ops7builtin36Register_FULLY_CONNECTED_GENERIC_OPTEvE1r = internal global { i8* (%struct.TfLiteContext*, i8*, i64)*, void (%struct.TfLiteContext*, i8*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteNode*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteNode*)*, i8* (%struct.TfLiteContext*, %struct.TfLiteNode*)*, i32, i8*, i32 } { i8* (%struct.TfLiteContext*, i8*, i64)* @_ZN6tflite3ops7builtin15fully_connected4InitEP13TfLiteContextPKcm, void (%struct.TfLiteContext*, i8*)* @_ZN6tflite3ops7builtin15fully_connected4FreeEP13TfLiteContextPv, i32 (%struct.TfLiteContext*, %struct.TfLiteNode*)* @_ZN6tflite3ops7builtin15fully_connected7PrepareILNS2_10KernelTypeE1EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode, i32 (%struct.TfLiteContext*, %struct.TfLiteNode*)* @_ZN6tflite3ops7builtin15fully_connected4EvalILNS2_10KernelTypeE1EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode, i8* (%struct.TfLiteContext*, %struct.TfLiteNode*)* null, i32 0, i8* null, i32 0 }, align 8
@_ZZN6tflite3ops7builtin28Register_FULLY_CONNECTED_PIEEvE1r = internal global { i8* (%struct.TfLiteContext*, i8*, i64)*, void (%struct.TfLiteContext*, i8*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteNode*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteNode*)*, i8* (%struct.TfLiteContext*, %struct.TfLiteNode*)*, i32, i8*, i32 } { i8* (%struct.TfLiteContext*, i8*, i64)* @_ZN6tflite3ops7builtin15fully_connected4InitEP13TfLiteContextPKcm, void (%struct.TfLiteContext*, i8*)* @_ZN6tflite3ops7builtin15fully_connected4FreeEP13TfLiteContextPv, i32 (%struct.TfLiteContext*, %struct.TfLiteNode*)* @_ZN6tflite3ops7builtin15fully_connected7PrepareILNS2_10KernelTypeE2EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode, i32 (%struct.TfLiteContext*, %struct.TfLiteNode*)* @_ZN6tflite3ops7builtin15fully_connected4EvalILNS2_10KernelTypeE2EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode, i8* (%struct.TfLiteContext*, %struct.TfLiteNode*)* null, i32 0, i8* null, i32 0 }, align 8
@.str.18 = private unnamed_addr constant [26 x i8] c"%s:%d %s != %s (%s != %s)\00", align 1
@.str.19 = private unnamed_addr constant [12 x i8] c"input->type\00", align 1
@.str.20 = private unnamed_addr constant [13 x i8] c"kTfLiteUInt8\00", align 1
@.str.21 = private unnamed_addr constant [13 x i8] c"filter->type\00", align 1
@.str.22 = private unnamed_addr constant [13 x i8] c"output->type\00", align 1
@.str.23 = private unnamed_addr constant [13 x i8] c"kTfLiteInt16\00", align 1
@.str.24 = private unnamed_addr constant [21 x i8] c"is_optional_bias_int\00", align 1
@.str.25 = private unnamed_addr constant [5 x i8] c"true\00", align 1
@.str.26 = private unnamed_addr constant [15 x i8] c"kTfLiteFloat32\00", align 1
@.str.27 = private unnamed_addr constant [23 x i8] c"is_optional_bias_float\00", align 1
@.str.28 = private unnamed_addr constant [89 x i8] c"input->type == kTfLiteUInt8 || input->type == kTfLiteInt8 || input->type == kTfLiteInt16\00", align 1
@.str.29 = private unnamed_addr constant [92 x i8] c"output->type == kTfLiteUInt8 || output->type == kTfLiteInt8 || output->type == kTfLiteInt16\00", align 1
@.str.30 = private unnamed_addr constant [163 x i8] c"params->activation == kTfLiteActNone || params->activation == kTfLiteActRelu || params->activation == kTfLiteActReluN1To1 || params->activation == kTfLiteActRelu6\00", align 1
@.str.31 = private unnamed_addr constant [41 x i8] c"Unhandled fully-connected weights format\00", align 1
@.str.32 = private unnamed_addr constant [45 x i8] c"Filter data type %s currently not supported.\00", align 1
@.str.34 = private unnamed_addr constant [21 x i8] c"Unexpected data type\00", align 1
@.str.35 = private unnamed_addr constant [71 x i8] c"Quantized FullyConnected expects output data type uint8, int8 or int16\00", align 1
@.str.36 = private unnamed_addr constant [50 x i8] c"Unsupported sparse fully-connected weight format.\00", align 1
@_ZTVN6tflite13optimized_ops33FullyConnectedSparseWeight1x4TaskE = linkonce_odr hidden unnamed_addr constant { [5 x i8*] } { [5 x i8*] [i8* null, i8* null, i8* bitcast (void (%"struct.gemmlowp::Task"*)* @_ZN8gemmlowp4TaskD2Ev to i8*), i8* bitcast (void (%"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"*)* @_ZN6tflite13optimized_ops33FullyConnectedSparseWeight1x4TaskD0Ev to i8*), i8* bitcast (void (%"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"*)* @_ZN6tflite13optimized_ops33FullyConnectedSparseWeight1x4Task3RunEv to i8*)] }, comdat, align 8
@_ZTVN8gemmlowp4TaskE = linkonce_odr hidden unnamed_addr constant { [5 x i8*] } { [5 x i8*] [i8* null, i8* null, i8* bitcast (void (%"struct.gemmlowp::Task"*)* @_ZN8gemmlowp4TaskD2Ev to i8*), i8* bitcast (void (%"struct.gemmlowp::Task"*)* @_ZN8gemmlowp4TaskD0Ev to i8*), i8* bitcast (void ()* @__cxa_pure_virtual to i8*)] }, comdat, align 8
@_ZZN3ruy8PackImplILNS_4PathE16ENS_17FixedKernelLayoutILNS_5OrderE1ELi1ELi16EEEfffE3RunENS_6TuningERKNS_3MatIfEEPNS_4PMatIfEEiiE7zerobuf = internal constant [16 x float] zeroinitializer, align 16
@__const._ZNK3ruy6KernelILNS_4PathE16EfffNS_9MulParamsIffEEE3RunERKNS_4PMatIfEES8_RKS3_iiiiPNS_3MatIfEE.params = private unnamed_addr constant %"struct.ruy::KernelParamsFloat" <{ float* inttoptr (i64 -6148914691236517206 to float*), float* inttoptr (i64 -6148914691236517206 to float*), float* inttoptr (i64 -6148914691236517206 to float*), float* inttoptr (i64 -6148914691236517206 to float*), i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, i8 -86, [3 x i8] c"\AA\AA\AA", [16 x float] [float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000], [256 x float] [float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000], [4 x i8] c"\AA\AA\AA\AA" }>, align 8
@_ZZN3ruy8PackImplILNS_4PathE8ENS_17FixedKernelLayoutILNS_5OrderE1ELi1ELi8EEEfffE3RunENS_6TuningERKNS_3MatIfEEPNS_4PMatIfEEiiE7zerobuf = internal constant [8 x float] zeroinitializer, align 16
@__const._ZNK3ruy6KernelILNS_4PathE8EfffNS_9MulParamsIffEEE3RunERKNS_4PMatIfEES8_RKS3_iiiiPNS_3MatIfEE.params = private unnamed_addr constant %"struct.ruy::KernelParamsFloat.110" <{ float* inttoptr (i64 -6148914691236517206 to float*), float* inttoptr (i64 -6148914691236517206 to float*), float* inttoptr (i64 -6148914691236517206 to float*), float* inttoptr (i64 -6148914691236517206 to float*), i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, i8 -86, [3 x i8] c"\AA\AA\AA", [8 x float] [float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000], [64 x float] [float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000], [4 x i8] c"\AA\AA\AA\AA" }>, align 8
@_ZTVN6tflite13optimized_ops32ShuffledFullyConnectedWorkerTaskE = linkonce_odr hidden unnamed_addr constant { [5 x i8*] } { [5 x i8*] [i8* null, i8* null, i8* bitcast (void (%"struct.gemmlowp::Task"*)* @_ZN8gemmlowp4TaskD2Ev to i8*), i8* bitcast (void (%"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"*)* @_ZN6tflite13optimized_ops32ShuffledFullyConnectedWorkerTaskD0Ev to i8*), i8* bitcast (void (%"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"*)* @_ZN6tflite13optimized_ops32ShuffledFullyConnectedWorkerTask3RunEv to i8*)] }, comdat, align 8
@_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count = linkonce_odr hidden global i32 0, comdat, align 4
@_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count = linkonce_odr hidden global i64 0, comdat, align 8
@.str.62 = private unnamed_addr constant [19 x i8] c"allocation failure\00", align 1
@stderr = external local_unnamed_addr global %struct._IO_FILE*, align 8
@.str.63 = private unnamed_addr constant [20 x i8] c"gemmlowp error: %s\0A\00", align 1
@_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEE = linkonce_odr hidden unnamed_addr constant { [5 x i8*] } { [5 x i8*] [i8* null, i8* null, i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEED2Ev to i8*), i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEED0Ev to i8*), i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEE3RunEv to i8*)] }, comdat, align 8
@_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEE = linkonce_odr hidden unnamed_addr constant { [5 x i8*] } { [5 x i8*] [i8* null, i8* null, i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask.328"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEED2Ev to i8*), i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask.328"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEED0Ev to i8*), i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask.328"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEE3RunEv to i8*)] }, comdat, align 8
@_ZTVN8gemmlowp13DefaultKernelINS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEEEE = linkonce_odr hidden unnamed_addr constant { [6 x i8*] } { [6 x i8*] [i8* null, i8* null, i8* bitcast (i8* (%"struct.gemmlowp::ReferenceKernel"*)* @_ZNK8gemmlowp15ReferenceKernelINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEE4NameEv to i8*), i8* bitcast (void (%"struct.gemmlowp::ReferenceKernel"*, i32*, i64, i64, i8*, i8*, i64, i64)* @_ZNK8gemmlowp15ReferenceKernelINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEE3RunEPimmPKhSB_mm to i8*), i8* bitcast (void (%"struct.gemmlowp::KernelBase"*)* @_ZN8gemmlowp10KernelBaseD2Ev to i8*), i8* bitcast (void (%"struct.gemmlowp::DefaultKernel"*)* @_ZN8gemmlowp13DefaultKernelINS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEEED0Ev to i8*)] }, comdat, align 8
@_ZZNK8gemmlowp15ReferenceKernelINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEE4NameEvE3buf = linkonce_odr hidden global [256 x i8] zeroinitializer, comdat, align 16
@.str.67 = private unnamed_addr constant [58 x i8] c"reference(Lhs: %d cells %dx%d %s, Rhs: %d cells %dx%d %s)\00", align 1
@.str.69 = private unnamed_addr constant [11 x i8] c"WidthMajor\00", align 1
@_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEE = linkonce_odr hidden unnamed_addr constant { [5 x i8*] } { [5 x i8*] [i8* null, i8* null, i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask.385"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEED2Ev to i8*), i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask.385"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEED0Ev to i8*), i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask.385"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEE3RunEv to i8*)] }, comdat, align 8
@_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEE = linkonce_odr hidden unnamed_addr constant { [5 x i8*] } { [5 x i8*] [i8* null, i8* null, i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask.428"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEED2Ev to i8*), i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask.428"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEED0Ev to i8*), i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask.428"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEE3RunEv to i8*)] }, comdat, align 8
@_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEE = linkonce_odr hidden unnamed_addr constant { [5 x i8*] } { [5 x i8*] [i8* null, i8* null, i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask.494"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED2Ev to i8*), i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask.494"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED0Ev to i8*), i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask.494"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEE3RunEv to i8*)] }, comdat, align 8
@_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEE = linkonce_odr hidden unnamed_addr constant { [5 x i8*] } { [5 x i8*] [i8* null, i8* null, i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask.573"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED2Ev to i8*), i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask.573"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED0Ev to i8*), i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask.573"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEE3RunEv to i8*)] }, comdat, align 8
@_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEE = linkonce_odr hidden unnamed_addr constant { [5 x i8*] } { [5 x i8*] [i8* null, i8* null, i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask.623"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED2Ev to i8*), i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask.623"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED0Ev to i8*), i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask.623"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEE3RunEv to i8*)] }, comdat, align 8
@_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEE = linkonce_odr hidden unnamed_addr constant { [5 x i8*] } { [5 x i8*] [i8* null, i8* null, i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask.666"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED2Ev to i8*), i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask.666"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED0Ev to i8*), i8* bitcast (void (%"struct.gemmlowp::GemmWithPackedRhsTask.666"*)* @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEE3RunEv to i8*)] }, comdat, align 8
@__const._ZN6tflite3ops7builtin15fully_connected13EvalQuantizedILNS2_10KernelTypeE2EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_.op_params = private unnamed_addr constant { i32, i32, i32, i32, i32, i32, i32, float, float, i8, i8, i8, [1 x i8] } { i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, i32 -1431655766, float 0xFFFFFFFFE0000000, float 0xFFFFFFFFE0000000, i8 -86, i8 -86, i8 -86, [1 x i8] c"\AA" }, align 4
@llvm.global_ctors = appending global [0 x { i32, void ()*, i8* }] zeroinitializer
@switch.table._ZN6tflite3ops7builtin15fully_connected9EvalFloatILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_ = private unnamed_addr constant [3 x float] [float 0.000000e+00, float -1.000000e+00, float 0.000000e+00], align 4
@switch.table._ZN6tflite3ops7builtin15fully_connected9EvalFloatILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_.73 = private unnamed_addr constant [3 x float] [float 0x47EFFFFFE0000000, float 1.000000e+00, float 6.000000e+00], align 4
@switch.table._ZN6tflite3ops7builtin15fully_connected9EvalFloatILNS2_10KernelTypeE1EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_ = private unnamed_addr constant [3 x i32] [i32 0, i32 -1082130432, i32 0], align 4
@switch.table._ZN6tflite3ops7builtin15fully_connected9EvalFloatILNS2_10KernelTypeE1EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_.74 = private unnamed_addr constant [3 x i32] [i32 2139095039, i32 1065353216, i32 1086324736], align 4

; Function Attrs: argmemonly nounwind
declare {}* @llvm.invariant.start.p0i8(i64 immarg, i8* nocapture) #0

; Function Attrs: nounwind ssp uwtable
define hidden nonnull i8* @_ZN6tflite3ops7builtin15fully_connected4InitEP13TfLiteContextPKcm(%struct.TfLiteContext*, i8* nocapture readnone, i64) #1 {
  %4 = tail call i8* @_Znwm(i64 24) #18
  %5 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 6
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %4, i8 0, i64 24, i1 false)
  %6 = load i32 (%struct.TfLiteContext*, i32, i32*)*, i32 (%struct.TfLiteContext*, i32, i32*)** %5, align 8
  %7 = getelementptr inbounds i8, i8* %4, i64 16
  %8 = bitcast i8* %7 to i32*
  %9 = tail call i32 %6(%struct.TfLiteContext* %0, i32 5, i32* %8) #19
  ret i8* %4
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #0

; Function Attrs: nobuiltin nofree
declare noalias nonnull i8* @_Znwm(i64) local_unnamed_addr #2

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #0

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #0

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN6tflite3ops7builtin15fully_connected4FreeEP13TfLiteContextPv(%struct.TfLiteContext* nocapture readnone, i8*) #1 {
  %3 = icmp eq i8* %1, null
  br i1 %3, label %5, label %4

4:                                                ; preds = %2
  tail call void @_ZdlPv(i8* nonnull %1) #18
  br label %5

5:                                                ; preds = %4, %2
  ret void
}

; Function Attrs: nobuiltin nounwind
declare void @_ZdlPv(i8*) local_unnamed_addr #3

; Function Attrs: nounwind ssp uwtable
define hidden i32 @_ZN6tflite3ops7builtin15fully_connected11PrepareImplEP13TfLiteContextP10TfLiteNode(%struct.TfLiteContext*, %struct.TfLiteNode* nocapture) local_unnamed_addr #1 {
  %3 = alloca double, align 8
  %4 = alloca i32, align 4
  %5 = alloca [1 x i32], align 4
  %6 = alloca [2 x i32], align 4
  %7 = alloca [1 x i32], align 4
  %8 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 5
  %9 = bitcast i8** %8 to %struct.TfLiteFullyConnectedParams**
  %10 = load %struct.TfLiteFullyConnectedParams*, %struct.TfLiteFullyConnectedParams** %9, align 8
  %11 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 4
  %12 = bitcast i8** %11 to %"struct.tflite::ops::builtin::fully_connected::OpData"**
  %13 = load %"struct.tflite::ops::builtin::fully_connected::OpData"*, %"struct.tflite::ops::builtin::fully_connected::OpData"** %12, align 8
  %14 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 0
  %15 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %14, align 8
  %16 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %15, i64 0, i32 0
  %17 = load i32, i32* %16, align 4
  %18 = and i32 %17, -2
  %19 = icmp eq i32 %18, 2
  br i1 %19, label %23, label %20

20:                                               ; preds = %2
  %21 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %22 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %21, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %22(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([72 x i8], [72 x i8]* @.str.3, i64 0, i64 0), i32 151, i8* getelementptr inbounds ([51 x i8], [51 x i8]* @.str.4, i64 0, i64 0)) #19
  br label %608

23:                                               ; preds = %2
  %24 = getelementptr inbounds %struct.TfLiteFullyConnectedParams, %struct.TfLiteFullyConnectedParams* %10, i64 0, i32 1
  %25 = load i32, i32* %24, align 4
  %26 = icmp eq i32 %25, 0
  %27 = select i1 %26, i32 1, i32 2
  %28 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 1
  %29 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %28, align 8
  %30 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %29, i64 0, i32 0
  %31 = load i32, i32* %30, align 4
  %32 = icmp eq i32 %31, %27
  br i1 %32, label %36, label %33

33:                                               ; preds = %23
  %34 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %35 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %34, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %35(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.5, i64 0, i64 0), i8* getelementptr inbounds ([72 x i8], [72 x i8]* @.str.3, i64 0, i64 0), i32 156, i8* getelementptr inbounds ([20 x i8], [20 x i8]* @.str.6, i64 0, i64 0), i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.7, i64 0, i64 0), i32 %31, i32 %27) #19
  br label %608

36:                                               ; preds = %23
  %37 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %15, i64 0, i32 1, i64 0
  %38 = load i32, i32* %37, align 4
  %39 = icmp slt i32 %38, 0
  br i1 %39, label %45, label %40

40:                                               ; preds = %36
  %41 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %42 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %41, align 8
  %43 = sext i32 %38 to i64
  %44 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %42, i64 %43
  br label %45

45:                                               ; preds = %36, %40
  %46 = phi %struct.TfLiteTensor* [ %44, %40 ], [ null, %36 ]
  %47 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %15, i64 0, i32 1, i64 1
  %48 = load i32, i32* %47, align 4
  %49 = icmp slt i32 %48, 0
  br i1 %49, label %55, label %50

50:                                               ; preds = %45
  %51 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %52 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %51, align 8
  %53 = sext i32 %48 to i64
  %54 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %52, i64 %53
  br label %55

55:                                               ; preds = %45, %50
  %56 = phi %struct.TfLiteTensor* [ %54, %50 ], [ null, %45 ]
  %57 = icmp eq i32 %17, 3
  br i1 %57, label %58, label %67

58:                                               ; preds = %55
  %59 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %15, i64 0, i32 1, i64 2
  %60 = load i32, i32* %59, align 4
  %61 = icmp slt i32 %60, 0
  br i1 %61, label %67, label %62

62:                                               ; preds = %58
  %63 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %64 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %63, align 8
  %65 = sext i32 %60 to i64
  %66 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %64, i64 %65
  br label %67

67:                                               ; preds = %62, %58, %55
  %68 = phi %struct.TfLiteTensor* [ null, %55 ], [ %66, %62 ], [ null, %58 ]
  %69 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %29, i64 0, i32 1, i64 0
  %70 = load i32, i32* %69, align 4
  %71 = icmp slt i32 %70, 0
  br i1 %71, label %77, label %72

72:                                               ; preds = %67
  %73 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %74 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %73, align 8
  %75 = sext i32 %70 to i64
  %76 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %74, i64 %75
  br label %77

77:                                               ; preds = %67, %72
  %78 = phi %struct.TfLiteTensor* [ %76, %72 ], [ null, %67 ]
  %79 = tail call i32 @_ZN6tflite3ops7builtin15fully_connected10CheckTypesEP13TfLiteContextPK12TfLiteTensorS7_S7_PS5_P26TfLiteFullyConnectedParams(%struct.TfLiteContext* %0, %struct.TfLiteTensor* %46, %struct.TfLiteTensor* %56, %struct.TfLiteTensor* %68, %struct.TfLiteTensor* %78, %struct.TfLiteFullyConnectedParams* %10)
  %80 = icmp eq i32 %79, 0
  br i1 %80, label %81, label %608

81:                                               ; preds = %77
  %82 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %46, i64 0, i32 2
  %83 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %82, align 8
  %84 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %83, i64 0, i32 0
  %85 = load i32, i32* %84, align 4
  %86 = icmp sgt i32 %85, 0
  br i1 %86, label %87, label %178

87:                                               ; preds = %81
  %88 = sext i32 %85 to i64
  %89 = icmp ult i32 %85, 8
  br i1 %89, label %90, label %93

90:                                               ; preds = %168, %87
  %91 = phi i64 [ 0, %87 ], [ %94, %168 ]
  %92 = phi i32 [ 1, %87 ], [ %176, %168 ]
  br label %185

93:                                               ; preds = %87
  %94 = and i64 %88, -8
  %95 = add nsw i64 %94, -8
  %96 = lshr exact i64 %95, 3
  %97 = add nuw nsw i64 %96, 1
  %98 = and i64 %97, 3
  %99 = icmp ult i64 %95, 24
  br i1 %99, label %145, label %100

100:                                              ; preds = %93
  %101 = sub nsw i64 %97, %98
  br label %102

102:                                              ; preds = %102, %100
  %103 = phi i64 [ 0, %100 ], [ %142, %102 ]
  %104 = phi <4 x i32> [ <i32 1, i32 1, i32 1, i32 1>, %100 ], [ %140, %102 ]
  %105 = phi <4 x i32> [ <i32 1, i32 1, i32 1, i32 1>, %100 ], [ %141, %102 ]
  %106 = phi i64 [ %101, %100 ], [ %143, %102 ]
  %107 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %83, i64 0, i32 1, i64 %103
  %108 = bitcast i32* %107 to <4 x i32>*
  %109 = load <4 x i32>, <4 x i32>* %108, align 4
  %110 = getelementptr inbounds i32, i32* %107, i64 4
  %111 = bitcast i32* %110 to <4 x i32>*
  %112 = load <4 x i32>, <4 x i32>* %111, align 4
  %113 = mul nsw <4 x i32> %109, %104
  %114 = mul nsw <4 x i32> %112, %105
  %115 = or i64 %103, 8
  %116 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %83, i64 0, i32 1, i64 %115
  %117 = bitcast i32* %116 to <4 x i32>*
  %118 = load <4 x i32>, <4 x i32>* %117, align 4
  %119 = getelementptr inbounds i32, i32* %116, i64 4
  %120 = bitcast i32* %119 to <4 x i32>*
  %121 = load <4 x i32>, <4 x i32>* %120, align 4
  %122 = mul nsw <4 x i32> %118, %113
  %123 = mul nsw <4 x i32> %121, %114
  %124 = or i64 %103, 16
  %125 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %83, i64 0, i32 1, i64 %124
  %126 = bitcast i32* %125 to <4 x i32>*
  %127 = load <4 x i32>, <4 x i32>* %126, align 4
  %128 = getelementptr inbounds i32, i32* %125, i64 4
  %129 = bitcast i32* %128 to <4 x i32>*
  %130 = load <4 x i32>, <4 x i32>* %129, align 4
  %131 = mul nsw <4 x i32> %127, %122
  %132 = mul nsw <4 x i32> %130, %123
  %133 = or i64 %103, 24
  %134 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %83, i64 0, i32 1, i64 %133
  %135 = bitcast i32* %134 to <4 x i32>*
  %136 = load <4 x i32>, <4 x i32>* %135, align 4
  %137 = getelementptr inbounds i32, i32* %134, i64 4
  %138 = bitcast i32* %137 to <4 x i32>*
  %139 = load <4 x i32>, <4 x i32>* %138, align 4
  %140 = mul nsw <4 x i32> %136, %131
  %141 = mul nsw <4 x i32> %139, %132
  %142 = add i64 %103, 32
  %143 = add i64 %106, -4
  %144 = icmp eq i64 %143, 0
  br i1 %144, label %145, label %102, !llvm.loop !2

145:                                              ; preds = %102, %93
  %146 = phi <4 x i32> [ undef, %93 ], [ %140, %102 ]
  %147 = phi <4 x i32> [ undef, %93 ], [ %141, %102 ]
  %148 = phi i64 [ 0, %93 ], [ %142, %102 ]
  %149 = phi <4 x i32> [ <i32 1, i32 1, i32 1, i32 1>, %93 ], [ %140, %102 ]
  %150 = phi <4 x i32> [ <i32 1, i32 1, i32 1, i32 1>, %93 ], [ %141, %102 ]
  %151 = icmp eq i64 %98, 0
  br i1 %151, label %168, label %152

152:                                              ; preds = %145, %152
  %153 = phi i64 [ %165, %152 ], [ %148, %145 ]
  %154 = phi <4 x i32> [ %163, %152 ], [ %149, %145 ]
  %155 = phi <4 x i32> [ %164, %152 ], [ %150, %145 ]
  %156 = phi i64 [ %166, %152 ], [ %98, %145 ]
  %157 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %83, i64 0, i32 1, i64 %153
  %158 = bitcast i32* %157 to <4 x i32>*
  %159 = load <4 x i32>, <4 x i32>* %158, align 4
  %160 = getelementptr inbounds i32, i32* %157, i64 4
  %161 = bitcast i32* %160 to <4 x i32>*
  %162 = load <4 x i32>, <4 x i32>* %161, align 4
  %163 = mul nsw <4 x i32> %159, %154
  %164 = mul nsw <4 x i32> %162, %155
  %165 = add i64 %153, 8
  %166 = add i64 %156, -1
  %167 = icmp eq i64 %166, 0
  br i1 %167, label %168, label %152, !llvm.loop !4

168:                                              ; preds = %152, %145
  %169 = phi <4 x i32> [ %146, %145 ], [ %163, %152 ]
  %170 = phi <4 x i32> [ %147, %145 ], [ %164, %152 ]
  %171 = mul <4 x i32> %170, %169
  %172 = shufflevector <4 x i32> %171, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %173 = mul <4 x i32> %171, %172
  %174 = shufflevector <4 x i32> %173, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %175 = mul <4 x i32> %173, %174
  %176 = extractelement <4 x i32> %175, i32 0
  %177 = icmp eq i64 %94, %88
  br i1 %177, label %178, label %90

178:                                              ; preds = %185, %168, %81
  %179 = phi i32 [ 1, %81 ], [ %176, %168 ], [ %190, %185 ]
  %180 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %56, i64 0, i32 2
  %181 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %180, align 8
  %182 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %181, i64 0, i32 0
  %183 = load i32, i32* %182, align 4
  %184 = icmp eq i32 %183, 2
  br i1 %184, label %196, label %193

185:                                              ; preds = %90, %185
  %186 = phi i64 [ %191, %185 ], [ %91, %90 ]
  %187 = phi i32 [ %190, %185 ], [ %92, %90 ]
  %188 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %83, i64 0, i32 1, i64 %186
  %189 = load i32, i32* %188, align 4
  %190 = mul nsw i32 %189, %187
  %191 = add nuw nsw i64 %186, 1
  %192 = icmp slt i64 %191, %88
  br i1 %192, label %185, label %178, !llvm.loop !6

193:                                              ; preds = %178
  %194 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %195 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %194, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %195(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.5, i64 0, i64 0), i8* getelementptr inbounds ([72 x i8], [72 x i8]* @.str.3, i64 0, i64 0), i32 177, i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.8, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.9, i64 0, i64 0), i32 %183, i32 2) #19
  br label %608

196:                                              ; preds = %178
  %197 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %181, i64 0, i32 1, i64 1
  %198 = load i32, i32* %197, align 4
  %199 = sdiv i32 %179, %198
  %200 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %181, i64 0, i32 1, i64 0
  %201 = load i32, i32* %200, align 4
  %202 = icmp eq %struct.TfLiteTensor* %68, null
  br i1 %202, label %356, label %203

203:                                              ; preds = %196
  %204 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %68, i64 0, i32 2
  %205 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %204, align 8
  %206 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %205, i64 0, i32 0
  %207 = load i32, i32* %206, align 4
  %208 = icmp sgt i32 %207, 0
  br i1 %208, label %209, label %278

209:                                              ; preds = %203
  %210 = sext i32 %207 to i64
  %211 = add nsw i64 %210, -1
  %212 = and i64 %210, 7
  %213 = icmp ult i64 %211, 7
  br i1 %213, label %262, label %214

214:                                              ; preds = %209
  %215 = sub nsw i64 %210, %212
  br label %216

216:                                              ; preds = %216, %214
  %217 = phi i64 [ 0, %214 ], [ %259, %216 ]
  %218 = phi i64 [ 1, %214 ], [ %258, %216 ]
  %219 = phi i64 [ %215, %214 ], [ %260, %216 ]
  %220 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %205, i64 0, i32 1, i64 %217
  %221 = load i32, i32* %220, align 4
  %222 = sext i32 %221 to i64
  %223 = mul nsw i64 %218, %222
  %224 = or i64 %217, 1
  %225 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %205, i64 0, i32 1, i64 %224
  %226 = load i32, i32* %225, align 4
  %227 = sext i32 %226 to i64
  %228 = mul nsw i64 %223, %227
  %229 = or i64 %217, 2
  %230 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %205, i64 0, i32 1, i64 %229
  %231 = load i32, i32* %230, align 4
  %232 = sext i32 %231 to i64
  %233 = mul nsw i64 %228, %232
  %234 = or i64 %217, 3
  %235 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %205, i64 0, i32 1, i64 %234
  %236 = load i32, i32* %235, align 4
  %237 = sext i32 %236 to i64
  %238 = mul nsw i64 %233, %237
  %239 = or i64 %217, 4
  %240 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %205, i64 0, i32 1, i64 %239
  %241 = load i32, i32* %240, align 4
  %242 = sext i32 %241 to i64
  %243 = mul nsw i64 %238, %242
  %244 = or i64 %217, 5
  %245 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %205, i64 0, i32 1, i64 %244
  %246 = load i32, i32* %245, align 4
  %247 = sext i32 %246 to i64
  %248 = mul nsw i64 %243, %247
  %249 = or i64 %217, 6
  %250 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %205, i64 0, i32 1, i64 %249
  %251 = load i32, i32* %250, align 4
  %252 = sext i32 %251 to i64
  %253 = mul nsw i64 %248, %252
  %254 = or i64 %217, 7
  %255 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %205, i64 0, i32 1, i64 %254
  %256 = load i32, i32* %255, align 4
  %257 = sext i32 %256 to i64
  %258 = mul nsw i64 %253, %257
  %259 = add nuw nsw i64 %217, 8
  %260 = add i64 %219, -8
  %261 = icmp eq i64 %260, 0
  br i1 %261, label %262, label %216

262:                                              ; preds = %216, %209
  %263 = phi i64 [ undef, %209 ], [ %258, %216 ]
  %264 = phi i64 [ 0, %209 ], [ %259, %216 ]
  %265 = phi i64 [ 1, %209 ], [ %258, %216 ]
  %266 = icmp eq i64 %212, 0
  br i1 %266, label %278, label %267

267:                                              ; preds = %262, %267
  %268 = phi i64 [ %275, %267 ], [ %264, %262 ]
  %269 = phi i64 [ %274, %267 ], [ %265, %262 ]
  %270 = phi i64 [ %276, %267 ], [ %212, %262 ]
  %271 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %205, i64 0, i32 1, i64 %268
  %272 = load i32, i32* %271, align 4
  %273 = sext i32 %272 to i64
  %274 = mul nsw i64 %269, %273
  %275 = add nuw nsw i64 %268, 1
  %276 = add i64 %270, -1
  %277 = icmp eq i64 %276, 0
  br i1 %277, label %278, label %267, !llvm.loop !8

278:                                              ; preds = %262, %267, %203
  %279 = phi i64 [ 1, %203 ], [ %263, %262 ], [ %274, %267 ]
  %280 = sext i32 %201 to i64
  %281 = icmp eq i64 %279, %280
  br i1 %281, label %356, label %282

282:                                              ; preds = %278
  %283 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %284 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %283, align 8
  br i1 %208, label %285, label %354

285:                                              ; preds = %282
  %286 = sext i32 %207 to i64
  %287 = add nsw i64 %286, -1
  %288 = and i64 %286, 7
  %289 = icmp ult i64 %287, 7
  br i1 %289, label %338, label %290

290:                                              ; preds = %285
  %291 = sub nsw i64 %286, %288
  br label %292

292:                                              ; preds = %292, %290
  %293 = phi i64 [ 0, %290 ], [ %335, %292 ]
  %294 = phi i64 [ 1, %290 ], [ %334, %292 ]
  %295 = phi i64 [ %291, %290 ], [ %336, %292 ]
  %296 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %205, i64 0, i32 1, i64 %293
  %297 = load i32, i32* %296, align 4
  %298 = sext i32 %297 to i64
  %299 = mul nsw i64 %294, %298
  %300 = or i64 %293, 1
  %301 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %205, i64 0, i32 1, i64 %300
  %302 = load i32, i32* %301, align 4
  %303 = sext i32 %302 to i64
  %304 = mul nsw i64 %299, %303
  %305 = or i64 %293, 2
  %306 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %205, i64 0, i32 1, i64 %305
  %307 = load i32, i32* %306, align 4
  %308 = sext i32 %307 to i64
  %309 = mul nsw i64 %304, %308
  %310 = or i64 %293, 3
  %311 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %205, i64 0, i32 1, i64 %310
  %312 = load i32, i32* %311, align 4
  %313 = sext i32 %312 to i64
  %314 = mul nsw i64 %309, %313
  %315 = or i64 %293, 4
  %316 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %205, i64 0, i32 1, i64 %315
  %317 = load i32, i32* %316, align 4
  %318 = sext i32 %317 to i64
  %319 = mul nsw i64 %314, %318
  %320 = or i64 %293, 5
  %321 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %205, i64 0, i32 1, i64 %320
  %322 = load i32, i32* %321, align 4
  %323 = sext i32 %322 to i64
  %324 = mul nsw i64 %319, %323
  %325 = or i64 %293, 6
  %326 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %205, i64 0, i32 1, i64 %325
  %327 = load i32, i32* %326, align 4
  %328 = sext i32 %327 to i64
  %329 = mul nsw i64 %324, %328
  %330 = or i64 %293, 7
  %331 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %205, i64 0, i32 1, i64 %330
  %332 = load i32, i32* %331, align 4
  %333 = sext i32 %332 to i64
  %334 = mul nsw i64 %329, %333
  %335 = add nuw nsw i64 %293, 8
  %336 = add i64 %295, -8
  %337 = icmp eq i64 %336, 0
  br i1 %337, label %338, label %292

338:                                              ; preds = %292, %285
  %339 = phi i64 [ undef, %285 ], [ %334, %292 ]
  %340 = phi i64 [ 0, %285 ], [ %335, %292 ]
  %341 = phi i64 [ 1, %285 ], [ %334, %292 ]
  %342 = icmp eq i64 %288, 0
  br i1 %342, label %354, label %343

343:                                              ; preds = %338, %343
  %344 = phi i64 [ %351, %343 ], [ %340, %338 ]
  %345 = phi i64 [ %350, %343 ], [ %341, %338 ]
  %346 = phi i64 [ %352, %343 ], [ %288, %338 ]
  %347 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %205, i64 0, i32 1, i64 %344
  %348 = load i32, i32* %347, align 4
  %349 = sext i32 %348 to i64
  %350 = mul nsw i64 %345, %349
  %351 = add nuw nsw i64 %344, 1
  %352 = add i64 %346, -1
  %353 = icmp eq i64 %352, 0
  br i1 %353, label %354, label %343, !llvm.loop !9

354:                                              ; preds = %338, %343, %282
  %355 = phi i64 [ 1, %282 ], [ %339, %338 ], [ %350, %343 ]
  tail call void (%struct.TfLiteContext*, i8*, ...) %284(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.5, i64 0, i64 0), i8* getelementptr inbounds ([72 x i8], [72 x i8]* @.str.3, i64 0, i64 0), i32 182, i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.10, i64 0, i64 0), i8* getelementptr inbounds ([27 x i8], [27 x i8]* @.str.11, i64 0, i64 0), i64 %355, i32 %201) #19
  br label %608

356:                                              ; preds = %278, %196
  %357 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %46, i64 0, i32 0
  %358 = load i32, i32* %357, align 8
  switch i32 %358, label %398 [
    i32 3, label %359
    i32 9, label %359
    i32 7, label %359
  ]

359:                                              ; preds = %356, %356, %356
  %360 = bitcast double* %3 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %360) #19
  store double 0.000000e+00, double* %3, align 8
  %361 = call i32 @_ZN6tflite32GetQuantizedConvolutionMultiplerEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_Pd(%struct.TfLiteContext* %0, %struct.TfLiteTensor* %46, %struct.TfLiteTensor* %56, %struct.TfLiteTensor* %68, %struct.TfLiteTensor* %78, double* nonnull %3) #19
  %362 = icmp eq i32 %361, 0
  br i1 %362, label %363, label %378

363:                                              ; preds = %359
  %364 = bitcast i32* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %364) #19
  store i32 -1431655766, i32* %4, align 4
  %365 = load double, double* %3, align 8
  %366 = getelementptr inbounds %"struct.tflite::ops::builtin::fully_connected::OpData", %"struct.tflite::ops::builtin::fully_connected::OpData"* %13, i64 0, i32 0
  call void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double %365, i32* %366, i32* nonnull %4) #19
  %367 = load i32, i32* %4, align 4
  %368 = getelementptr inbounds %"struct.tflite::ops::builtin::fully_connected::OpData", %"struct.tflite::ops::builtin::fully_connected::OpData"* %13, i64 0, i32 1
  store i32 %367, i32* %368, align 4
  %369 = getelementptr inbounds %struct.TfLiteFullyConnectedParams, %struct.TfLiteFullyConnectedParams* %10, i64 0, i32 0
  %370 = load i32, i32* %369, align 4
  %371 = getelementptr inbounds %"struct.tflite::ops::builtin::fully_connected::OpData", %"struct.tflite::ops::builtin::fully_connected::OpData"* %13, i64 0, i32 2
  %372 = getelementptr inbounds %"struct.tflite::ops::builtin::fully_connected::OpData", %"struct.tflite::ops::builtin::fully_connected::OpData"* %13, i64 0, i32 3
  %373 = call i32 @_ZN6tflite33CalculateActivationRangeQuantizedEP13TfLiteContext21TfLiteFusedActivationP12TfLiteTensorPiS5_(%struct.TfLiteContext* %0, i32 %370, %struct.TfLiteTensor* %78, i32* %371, i32* %372) #19
  %374 = icmp eq i32 %373, 0
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %364) #19
  br i1 %374, label %375, label %378

375:                                              ; preds = %363
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %360) #19
  %376 = load i32, i32* %357, align 8
  %377 = icmp eq i32 %376, 7
  br i1 %377, label %380, label %398

378:                                              ; preds = %363, %359
  %379 = phi i32 [ %373, %363 ], [ %361, %359 ]
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %360) #19
  br label %608

380:                                              ; preds = %375
  %381 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %78, i64 0, i32 0
  %382 = load i32, i32* %381, align 8
  %383 = icmp eq i32 %382, 7
  br i1 %383, label %384, label %572

384:                                              ; preds = %380
  %385 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %46, i64 0, i32 3, i32 1
  %386 = load i32, i32* %385, align 4
  %387 = icmp eq i32 %386, 0
  br i1 %387, label %391, label %388

388:                                              ; preds = %384
  %389 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %390 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %389, align 8
  call void (%struct.TfLiteContext*, i8*, ...) %390(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.5, i64 0, i64 0), i8* getelementptr inbounds ([72 x i8], [72 x i8]* @.str.3, i64 0, i64 0), i32 201, i8* getelementptr inbounds ([25 x i8], [25 x i8]* @.str.12, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.13, i64 0, i64 0), i32 %386, i32 0) #19
  br label %608

391:                                              ; preds = %384
  %392 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %78, i64 0, i32 3, i32 1
  %393 = load i32, i32* %392, align 4
  %394 = icmp eq i32 %393, 0
  br i1 %394, label %572, label %395

395:                                              ; preds = %391
  %396 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %397 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %396, align 8
  call void (%struct.TfLiteContext*, i8*, ...) %397(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.5, i64 0, i64 0), i8* getelementptr inbounds ([72 x i8], [72 x i8]* @.str.3, i64 0, i64 0), i32 202, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.14, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.13, i64 0, i64 0), i32 %393, i32 0) #19
  br label %608

398:                                              ; preds = %356, %375
  %399 = phi i32 [ %376, %375 ], [ %358, %356 ]
  %400 = icmp eq i32 %399, 1
  br i1 %400, label %401, label %572

401:                                              ; preds = %398
  %402 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %56, i64 0, i32 0
  %403 = load i32, i32* %402, align 8
  switch i32 %403, label %572 [
    i32 3, label %404
    i32 9, label %404
  ]

404:                                              ; preds = %401, %401
  %405 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 3
  %406 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %405, align 8
  call void @TfLiteIntArrayFree(%struct.TfLiteIntArray* %406) #19
  %407 = getelementptr inbounds %"struct.tflite::ops::builtin::fully_connected::OpData", %"struct.tflite::ops::builtin::fully_connected::OpData"* %13, i64 0, i32 5
  store i8 1, i8* %407, align 4
  %408 = call %struct.TfLiteIntArray* @TfLiteIntArrayCreate(i32 5) #19
  store %struct.TfLiteIntArray* %408, %struct.TfLiteIntArray** %405, align 8
  %409 = getelementptr inbounds %"struct.tflite::ops::builtin::fully_connected::OpData", %"struct.tflite::ops::builtin::fully_connected::OpData"* %13, i64 0, i32 4
  %410 = load i32, i32* %409, align 4
  %411 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %408, i64 0, i32 1, i64 0
  store i32 %410, i32* %411, align 4
  %412 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %405, align 8
  %413 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %412, i64 0, i32 1, i64 0
  %414 = load i32, i32* %413, align 4
  %415 = icmp slt i32 %414, 0
  br i1 %415, label %421, label %416

416:                                              ; preds = %404
  %417 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %418 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %417, align 8
  %419 = sext i32 %414 to i64
  %420 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %418, i64 %419
  br label %421

421:                                              ; preds = %404, %416
  %422 = phi %struct.TfLiteTensor* [ %420, %416 ], [ null, %404 ]
  %423 = load i32, i32* %402, align 8
  %424 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %422, i64 0, i32 0
  store i32 %423, i32* %424, align 8
  %425 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %422, i64 0, i32 4
  store i32 2, i32* %425, align 8
  %426 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %82, align 8
  %427 = call %struct.TfLiteIntArray* @TfLiteIntArrayCopy(%struct.TfLiteIntArray* %426) #19
  %428 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 4
  %429 = load i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)** %428, align 8
  %430 = call i32 %429(%struct.TfLiteContext* %0, %struct.TfLiteTensor* %422, %struct.TfLiteIntArray* %427) #19
  %431 = icmp eq i32 %430, 0
  br i1 %431, label %432, label %608

432:                                              ; preds = %421
  %433 = load i32, i32* %409, align 4
  %434 = add nsw i32 %433, 1
  %435 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %405, align 8
  %436 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %435, i64 0, i32 1, i64 1
  store i32 %434, i32* %436, align 4
  %437 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %405, align 8
  %438 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %437, i64 0, i32 1, i64 1
  %439 = load i32, i32* %438, align 4
  %440 = icmp slt i32 %439, 0
  br i1 %440, label %446, label %441

441:                                              ; preds = %432
  %442 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %443 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %442, align 8
  %444 = sext i32 %439 to i64
  %445 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %443, i64 %444
  br label %446

446:                                              ; preds = %432, %441
  %447 = phi %struct.TfLiteTensor* [ %445, %441 ], [ null, %432 ]
  %448 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %447, i64 0, i32 0
  store i32 1, i32* %448, align 8
  %449 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %447, i64 0, i32 4
  store i32 2, i32* %449, align 8
  %450 = bitcast [1 x i32]* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %450) #19
  %451 = getelementptr inbounds [1 x i32], [1 x i32]* %5, i64 0, i64 0
  store i32 %199, i32* %451, align 4
  %452 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %447, i64 0, i32 2
  %453 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %452, align 8
  %454 = call i32 @TfLiteIntArrayEqualsArray(%struct.TfLiteIntArray* %453, i32 1, i32* nonnull %451) #19
  %455 = icmp eq i32 %454, 0
  br i1 %455, label %456, label %464

456:                                              ; preds = %446
  %457 = call %struct.TfLiteIntArray* @TfLiteIntArrayCreate(i32 1) #19
  %458 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %457, i64 0, i32 1, i64 0
  store i32 %199, i32* %458, align 4
  %459 = load i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)** %428, align 8
  %460 = call i32 %459(%struct.TfLiteContext* %0, %struct.TfLiteTensor* %447, %struct.TfLiteIntArray* %457) #19
  %461 = icmp eq i32 %460, 0
  %462 = xor i1 %461, true
  %463 = zext i1 %462 to i32
  br i1 %461, label %464, label %568

464:                                              ; preds = %446, %456
  %465 = load i32, i32* %409, align 4
  %466 = add nsw i32 %465, 2
  %467 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %405, align 8
  %468 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %467, i64 0, i32 1, i64 2
  store i32 %466, i32* %468, align 4
  %469 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %405, align 8
  %470 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %469, i64 0, i32 1, i64 2
  %471 = load i32, i32* %470, align 4
  %472 = icmp slt i32 %471, 0
  br i1 %472, label %478, label %473

473:                                              ; preds = %464
  %474 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %475 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %474, align 8
  %476 = sext i32 %471 to i64
  %477 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %475, i64 %476
  br label %478

478:                                              ; preds = %464, %473
  %479 = phi %struct.TfLiteTensor* [ %477, %473 ], [ null, %464 ]
  %480 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %479, i64 0, i32 0
  store i32 2, i32* %480, align 8
  %481 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %479, i64 0, i32 4
  store i32 2, i32* %481, align 8
  %482 = bitcast [2 x i32]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %482) #19
  %483 = getelementptr inbounds [2 x i32], [2 x i32]* %6, i64 0, i64 0
  %484 = getelementptr inbounds [2 x i32], [2 x i32]* %6, i64 0, i64 1
  store i32 %201, i32* %483, align 4
  store i32 %199, i32* %484, align 4
  %485 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %479, i64 0, i32 2
  %486 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %485, align 8
  %487 = call i32 @TfLiteIntArrayEqualsArray(%struct.TfLiteIntArray* %486, i32 2, i32* nonnull %483) #19
  %488 = icmp eq i32 %487, 0
  br i1 %488, label %489, label %498

489:                                              ; preds = %478
  %490 = call %struct.TfLiteIntArray* @TfLiteIntArrayCreate(i32 2) #19
  %491 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %490, i64 0, i32 1, i64 0
  store i32 %201, i32* %491, align 4
  %492 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %490, i64 0, i32 1, i64 1
  store i32 %199, i32* %492, align 4
  %493 = load i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)** %428, align 8
  %494 = call i32 %493(%struct.TfLiteContext* %0, %struct.TfLiteTensor* %479, %struct.TfLiteIntArray* %490) #19
  %495 = icmp eq i32 %494, 0
  %496 = xor i1 %495, true
  %497 = zext i1 %496 to i32
  br i1 %495, label %498, label %565

498:                                              ; preds = %478, %489
  %499 = load i32, i32* %409, align 4
  %500 = add nsw i32 %499, 3
  %501 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %405, align 8
  %502 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %501, i64 0, i32 1, i64 3
  store i32 %500, i32* %502, align 4
  %503 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %405, align 8
  %504 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %503, i64 0, i32 1, i64 3
  %505 = load i32, i32* %504, align 4
  %506 = icmp slt i32 %505, 0
  br i1 %506, label %512, label %507

507:                                              ; preds = %498
  %508 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %509 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %508, align 8
  %510 = sext i32 %505 to i64
  %511 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %509, i64 %510
  br label %512

512:                                              ; preds = %498, %507
  %513 = phi %struct.TfLiteTensor* [ %511, %507 ], [ null, %498 ]
  %514 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %513, i64 0, i32 0
  store i32 2, i32* %514, align 8
  %515 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %513, i64 0, i32 4
  store i32 2, i32* %515, align 8
  %516 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %513, i64 0, i32 2
  %517 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %516, align 8
  %518 = call i32 @TfLiteIntArrayEqualsArray(%struct.TfLiteIntArray* %517, i32 1, i32* nonnull %451) #19
  %519 = icmp eq i32 %518, 0
  br i1 %519, label %520, label %528

520:                                              ; preds = %512
  %521 = call %struct.TfLiteIntArray* @TfLiteIntArrayCreate(i32 1) #19
  %522 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %521, i64 0, i32 1, i64 0
  store i32 %199, i32* %522, align 4
  %523 = load i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)** %428, align 8
  %524 = call i32 %523(%struct.TfLiteContext* %0, %struct.TfLiteTensor* %513, %struct.TfLiteIntArray* %521) #19
  %525 = icmp eq i32 %524, 0
  %526 = xor i1 %525, true
  %527 = zext i1 %526 to i32
  br i1 %525, label %528, label %565

528:                                              ; preds = %512, %520
  %529 = load i32, i32* %409, align 4
  %530 = add nsw i32 %529, 4
  %531 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %405, align 8
  %532 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %531, i64 0, i32 1, i64 4
  store i32 %530, i32* %532, align 4
  %533 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %405, align 8
  %534 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %533, i64 0, i32 1, i64 4
  %535 = load i32, i32* %534, align 4
  %536 = icmp slt i32 %535, 0
  br i1 %536, label %542, label %537

537:                                              ; preds = %528
  %538 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %539 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %538, align 8
  %540 = sext i32 %535 to i64
  %541 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %539, i64 %540
  br label %542

542:                                              ; preds = %528, %537
  %543 = phi %struct.TfLiteTensor* [ %541, %537 ], [ null, %528 ]
  %544 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %543, i64 0, i32 0
  store i32 2, i32* %544, align 8
  %545 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %543, i64 0, i32 4
  store i32 3, i32* %545, align 8
  %546 = bitcast [1 x i32]* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %546) #19
  %547 = getelementptr inbounds [1 x i32], [1 x i32]* %7, i64 0, i64 0
  store i32 %201, i32* %547, align 4
  %548 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %543, i64 0, i32 2
  %549 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %548, align 8
  %550 = call i32 @TfLiteIntArrayEqualsArray(%struct.TfLiteIntArray* %549, i32 1, i32* nonnull %547) #19
  %551 = icmp eq i32 %550, 0
  br i1 %551, label %552, label %561

552:                                              ; preds = %542
  %553 = call %struct.TfLiteIntArray* @TfLiteIntArrayCreate(i32 1) #19
  %554 = load i32, i32* %547, align 4
  %555 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %553, i64 0, i32 1, i64 0
  store i32 %554, i32* %555, align 4
  %556 = load i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)** %428, align 8
  %557 = call i32 %556(%struct.TfLiteContext* %0, %struct.TfLiteTensor* %543, %struct.TfLiteIntArray* %553) #19
  %558 = icmp eq i32 %557, 0
  %559 = xor i1 %558, true
  %560 = zext i1 %559 to i32
  br i1 %558, label %561, label %562

561:                                              ; preds = %542, %552
  br label %562

562:                                              ; preds = %552, %561
  %563 = phi i32 [ 0, %561 ], [ %560, %552 ]
  %564 = phi i32 [ 0, %561 ], [ %557, %552 ]
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %546) #19
  br label %565

565:                                              ; preds = %562, %520, %489
  %566 = phi i32 [ %497, %489 ], [ %563, %562 ], [ %527, %520 ]
  %567 = phi i32 [ %494, %489 ], [ %564, %562 ], [ %524, %520 ]
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %482) #19
  br label %568

568:                                              ; preds = %565, %456
  %569 = phi i32 [ %566, %565 ], [ %463, %456 ]
  %570 = phi i32 [ %567, %565 ], [ %460, %456 ]
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %450) #19
  %571 = icmp eq i32 %569, 0
  br i1 %571, label %572, label %608

572:                                              ; preds = %380, %391, %401, %568, %398
  %573 = getelementptr inbounds %struct.TfLiteFullyConnectedParams, %struct.TfLiteFullyConnectedParams* %10, i64 0, i32 2
  %574 = load i8, i8* %573, align 4, !range !10
  %575 = icmp eq i8 %574, 0
  br i1 %575, label %598, label %576

576:                                              ; preds = %572
  %577 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %82, align 8
  %578 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %577, i64 0, i32 0
  %579 = load i32, i32* %578, align 4
  %580 = add nsw i32 %579, -1
  %581 = sext i32 %580 to i64
  %582 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %577, i64 0, i32 1, i64 %581
  %583 = load i32, i32* %582, align 4
  %584 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %180, align 8
  %585 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %584, i64 0, i32 1, i64 1
  %586 = load i32, i32* %585, align 4
  %587 = icmp eq i32 %583, %586
  br i1 %587, label %591, label %588

588:                                              ; preds = %576
  %589 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %590 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %589, align 8
  call void (%struct.TfLiteContext*, i8*, ...) %590(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.5, i64 0, i64 0), i8* getelementptr inbounds ([72 x i8], [72 x i8]* @.str.3, i64 0, i64 0), i32 283, i8* getelementptr inbounds ([41 x i8], [41 x i8]* @.str.15, i64 0, i64 0), i8* getelementptr inbounds ([27 x i8], [27 x i8]* @.str.16, i64 0, i64 0), i32 %583, i32 %586) #19
  br label %608

591:                                              ; preds = %576
  %592 = call %struct.TfLiteIntArray* @TfLiteIntArrayCopy(%struct.TfLiteIntArray* %577) #19
  %593 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %592, i64 0, i32 0
  %594 = load i32, i32* %593, align 4
  %595 = add nsw i32 %594, -1
  %596 = sext i32 %595 to i64
  %597 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %592, i64 0, i32 1, i64 %596
  br label %602

598:                                              ; preds = %572
  %599 = call %struct.TfLiteIntArray* @TfLiteIntArrayCreate(i32 2) #19
  %600 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %599, i64 0, i32 1, i64 0
  store i32 %199, i32* %600, align 4
  %601 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %599, i64 0, i32 1, i64 1
  br label %602

602:                                              ; preds = %591, %598
  %603 = phi i32* [ %597, %591 ], [ %601, %598 ]
  %604 = phi %struct.TfLiteIntArray* [ %592, %591 ], [ %599, %598 ]
  store i32 %201, i32* %603, align 4
  %605 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 4
  %606 = load i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteIntArray*)** %605, align 8
  %607 = call i32 %606(%struct.TfLiteContext* %0, %struct.TfLiteTensor* %78, %struct.TfLiteIntArray* %604) #19
  ret i32 %607

608:                                              ; preds = %421, %378, %33, %193, %588, %568, %395, %388, %354, %77, %20
  %609 = phi i32 [ 1, %20 ], [ 1, %33 ], [ %79, %77 ], [ 1, %193 ], [ 1, %354 ], [ 1, %388 ], [ 1, %395 ], [ %570, %568 ], [ %379, %378 ], [ 1, %588 ], [ %430, %421 ]
  ret i32 %609
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden i32 @_ZN6tflite3ops7builtin15fully_connected10CheckTypesEP13TfLiteContextPK12TfLiteTensorS7_S7_PS5_P26TfLiteFullyConnectedParams(%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteFullyConnectedParams*) local_unnamed_addr #4 comdat {
  %7 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %2, i64 0, i32 0
  %8 = load i32, i32* %7, align 8
  %9 = icmp eq i32 %8, 3
  switch i32 %8, label %17 [
    i32 9, label %10
    i32 3, label %10
  ]

10:                                               ; preds = %6, %6
  %11 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1, i64 0, i32 0
  %12 = load i32, i32* %11, align 8
  %13 = icmp eq i32 %12, 1
  %14 = getelementptr inbounds %struct.TfLiteFullyConnectedParams, %struct.TfLiteFullyConnectedParams* %5, i64 0, i32 1
  %15 = load i32, i32* %14, align 4
  %16 = icmp eq i32 %15, 1
  br label %17

17:                                               ; preds = %6, %10
  %18 = phi i1 [ %13, %10 ], [ false, %6 ]
  %19 = phi i1 [ %16, %10 ], [ false, %6 ]
  %20 = icmp eq %struct.TfLiteTensor* %3, null
  br i1 %20, label %30, label %21

21:                                               ; preds = %17
  %22 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %3, i64 0, i32 0
  %23 = load i32, i32* %22, align 8
  %24 = icmp eq i32 %23, 1
  %25 = zext i1 %24 to i32
  %26 = icmp eq i32 %23, 2
  br i1 %26, label %30, label %27

27:                                               ; preds = %21
  %28 = icmp eq i32 %23, 4
  %29 = zext i1 %28 to i32
  br label %30

30:                                               ; preds = %17, %27, %21
  %31 = phi i32 [ %25, %21 ], [ %25, %27 ], [ 1, %17 ]
  %32 = phi i32 [ 1, %21 ], [ %29, %27 ], [ 1, %17 ]
  %33 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %1, i64 0, i32 0
  %34 = load i32, i32* %33, align 8
  switch i32 %8, label %100 [
    i32 9, label %35
    i32 3, label %35
  ]

35:                                               ; preds = %30, %30
  br i1 %19, label %36, label %63

36:                                               ; preds = %35
  %37 = icmp eq i32 %34, 3
  br i1 %37, label %43, label %38

38:                                               ; preds = %36
  %39 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %40 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %39, align 8
  %41 = tail call i8* @TfLiteTypeGetName(i32 %34) #19
  %42 = tail call i8* @TfLiteTypeGetName(i32 3) #19
  tail call void (%struct.TfLiteContext*, i8*, ...) %40(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.18, i64 0, i64 0), i8* getelementptr inbounds ([72 x i8], [72 x i8]* @.str.3, i64 0, i64 0), i32 104, i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.19, i64 0, i64 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.20, i64 0, i64 0), i8* %41, i8* %42) #19
  br label %128

43:                                               ; preds = %36
  br i1 %9, label %49, label %44

44:                                               ; preds = %43
  %45 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %46 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %45, align 8
  %47 = tail call i8* @TfLiteTypeGetName(i32 %8) #19
  %48 = tail call i8* @TfLiteTypeGetName(i32 3) #19
  tail call void (%struct.TfLiteContext*, i8*, ...) %46(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.18, i64 0, i64 0), i8* getelementptr inbounds ([72 x i8], [72 x i8]* @.str.3, i64 0, i64 0), i32 105, i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.21, i64 0, i64 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.20, i64 0, i64 0), i8* %47, i8* %48) #19
  br label %128

49:                                               ; preds = %43
  %50 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 0
  %51 = load i32, i32* %50, align 8
  %52 = icmp eq i32 %51, 7
  br i1 %52, label %58, label %53

53:                                               ; preds = %49
  %54 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %55 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %54, align 8
  %56 = tail call i8* @TfLiteTypeGetName(i32 %51) #19
  %57 = tail call i8* @TfLiteTypeGetName(i32 7) #19
  tail call void (%struct.TfLiteContext*, i8*, ...) %55(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.18, i64 0, i64 0), i8* getelementptr inbounds ([72 x i8], [72 x i8]* @.str.3, i64 0, i64 0), i32 106, i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.22, i64 0, i64 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.23, i64 0, i64 0), i8* %56, i8* %57) #19
  br label %128

58:                                               ; preds = %49
  %59 = icmp eq i32 %32, 1
  br i1 %59, label %128, label %60

60:                                               ; preds = %58
  %61 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %62 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %61, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %62(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.5, i64 0, i64 0), i8* getelementptr inbounds ([72 x i8], [72 x i8]* @.str.3, i64 0, i64 0), i32 107, i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.24, i64 0, i64 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.25, i64 0, i64 0), i32 %32, i32 1) #19
  br label %128

63:                                               ; preds = %35
  br i1 %18, label %64, label %85

64:                                               ; preds = %63
  %65 = icmp eq i32 %34, 1
  br i1 %65, label %71, label %66

66:                                               ; preds = %64
  %67 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %68 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %67, align 8
  %69 = tail call i8* @TfLiteTypeGetName(i32 %34) #19
  %70 = tail call i8* @TfLiteTypeGetName(i32 1) #19
  tail call void (%struct.TfLiteContext*, i8*, ...) %68(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.18, i64 0, i64 0), i8* getelementptr inbounds ([72 x i8], [72 x i8]* @.str.3, i64 0, i64 0), i32 109, i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.19, i64 0, i64 0), i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.26, i64 0, i64 0), i8* %69, i8* %70) #19
  br label %128

71:                                               ; preds = %64
  %72 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 0
  %73 = load i32, i32* %72, align 8
  %74 = icmp eq i32 %73, 1
  br i1 %74, label %80, label %75

75:                                               ; preds = %71
  %76 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %77 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %76, align 8
  %78 = tail call i8* @TfLiteTypeGetName(i32 %73) #19
  %79 = tail call i8* @TfLiteTypeGetName(i32 1) #19
  tail call void (%struct.TfLiteContext*, i8*, ...) %77(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.18, i64 0, i64 0), i8* getelementptr inbounds ([72 x i8], [72 x i8]* @.str.3, i64 0, i64 0), i32 110, i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.22, i64 0, i64 0), i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.26, i64 0, i64 0), i8* %78, i8* %79) #19
  br label %128

80:                                               ; preds = %71
  %81 = icmp eq i32 %31, 1
  br i1 %81, label %128, label %82

82:                                               ; preds = %80
  %83 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %84 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %83, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %84(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.5, i64 0, i64 0), i8* getelementptr inbounds ([72 x i8], [72 x i8]* @.str.3, i64 0, i64 0), i32 111, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.27, i64 0, i64 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.25, i64 0, i64 0), i32 %31, i32 1) #19
  br label %128

85:                                               ; preds = %63
  switch i32 %34, label %86 [
    i32 3, label %89
    i32 9, label %89
    i32 7, label %89
  ]

86:                                               ; preds = %85
  %87 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %88 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %87, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %88(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([72 x i8], [72 x i8]* @.str.3, i64 0, i64 0), i32 115, i8* getelementptr inbounds ([89 x i8], [89 x i8]* @.str.28, i64 0, i64 0)) #19
  br label %128

89:                                               ; preds = %85, %85, %85
  %90 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 0
  %91 = load i32, i32* %90, align 8
  switch i32 %91, label %92 [
    i32 3, label %95
    i32 9, label %95
    i32 7, label %95
  ]

92:                                               ; preds = %89
  %93 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %94 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %93, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %94(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([72 x i8], [72 x i8]* @.str.3, i64 0, i64 0), i32 118, i8* getelementptr inbounds ([92 x i8], [92 x i8]* @.str.29, i64 0, i64 0)) #19
  br label %128

95:                                               ; preds = %89, %89, %89
  %96 = icmp eq i32 %32, 1
  br i1 %96, label %128, label %97

97:                                               ; preds = %95
  %98 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %99 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %98, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %99(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.5, i64 0, i64 0), i8* getelementptr inbounds ([72 x i8], [72 x i8]* @.str.3, i64 0, i64 0), i32 119, i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.24, i64 0, i64 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.25, i64 0, i64 0), i32 %32, i32 1) #19
  br label %128

100:                                              ; preds = %30
  %101 = icmp eq i32 %34, 1
  br i1 %101, label %107, label %102

102:                                              ; preds = %100
  %103 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %104 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %103, align 8
  %105 = tail call i8* @TfLiteTypeGetName(i32 %34) #19
  %106 = tail call i8* @TfLiteTypeGetName(i32 1) #19
  tail call void (%struct.TfLiteContext*, i8*, ...) %104(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.18, i64 0, i64 0), i8* getelementptr inbounds ([72 x i8], [72 x i8]* @.str.3, i64 0, i64 0), i32 123, i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.19, i64 0, i64 0), i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.26, i64 0, i64 0), i8* %105, i8* %106) #19
  br label %128

107:                                              ; preds = %100
  %108 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 0
  %109 = load i32, i32* %108, align 8
  %110 = icmp eq i32 %109, 1
  br i1 %110, label %116, label %111

111:                                              ; preds = %107
  %112 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %113 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %112, align 8
  %114 = tail call i8* @TfLiteTypeGetName(i32 %109) #19
  %115 = tail call i8* @TfLiteTypeGetName(i32 1) #19
  tail call void (%struct.TfLiteContext*, i8*, ...) %113(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.18, i64 0, i64 0), i8* getelementptr inbounds ([72 x i8], [72 x i8]* @.str.3, i64 0, i64 0), i32 124, i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.22, i64 0, i64 0), i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.26, i64 0, i64 0), i8* %114, i8* %115) #19
  br label %128

116:                                              ; preds = %107
  %117 = icmp eq i32 %8, 1
  br i1 %117, label %123, label %118

118:                                              ; preds = %116
  %119 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %120 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %119, align 8
  %121 = tail call i8* @TfLiteTypeGetName(i32 %8) #19
  %122 = tail call i8* @TfLiteTypeGetName(i32 1) #19
  tail call void (%struct.TfLiteContext*, i8*, ...) %120(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.18, i64 0, i64 0), i8* getelementptr inbounds ([72 x i8], [72 x i8]* @.str.3, i64 0, i64 0), i32 125, i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.21, i64 0, i64 0), i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.26, i64 0, i64 0), i8* %121, i8* %122) #19
  br label %128

123:                                              ; preds = %116
  %124 = icmp eq i32 %31, 1
  br i1 %124, label %128, label %125

125:                                              ; preds = %123
  %126 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %127 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %126, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %127(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.5, i64 0, i64 0), i8* getelementptr inbounds ([72 x i8], [72 x i8]* @.str.3, i64 0, i64 0), i32 126, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.27, i64 0, i64 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.25, i64 0, i64 0), i32 %31, i32 1) #19
  br label %128

128:                                              ; preds = %123, %95, %80, %58, %125, %118, %111, %102, %97, %92, %86, %82, %75, %66, %60, %53, %44, %38
  %129 = phi i32 [ 1, %38 ], [ 1, %44 ], [ 1, %53 ], [ 1, %60 ], [ 1, %66 ], [ 1, %75 ], [ 1, %82 ], [ 1, %97 ], [ 1, %92 ], [ 1, %86 ], [ 1, %102 ], [ 1, %111 ], [ 1, %118 ], [ 1, %125 ], [ 0, %58 ], [ 0, %80 ], [ 0, %95 ], [ 0, %123 ]
  ret i32 %129
}

declare i32 @_ZN6tflite32GetQuantizedConvolutionMultiplerEP13TfLiteContextPK12TfLiteTensorS4_S4_PS2_Pd(%struct.TfLiteContext*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, double*) local_unnamed_addr #5

declare void @_ZN6tflite18QuantizeMultiplierEdPiS0_(double, i32*, i32*) local_unnamed_addr #5

declare i32 @_ZN6tflite33CalculateActivationRangeQuantizedEP13TfLiteContext21TfLiteFusedActivationP12TfLiteTensorPiS5_(%struct.TfLiteContext*, i32, %struct.TfLiteTensor*, i32*, i32*) local_unnamed_addr #5

declare void @TfLiteIntArrayFree(%struct.TfLiteIntArray*) local_unnamed_addr #5

declare %struct.TfLiteIntArray* @TfLiteIntArrayCreate(i32) local_unnamed_addr #5

declare %struct.TfLiteIntArray* @TfLiteIntArrayCopy(%struct.TfLiteIntArray*) local_unnamed_addr #5

declare i32 @TfLiteIntArrayEqualsArray(%struct.TfLiteIntArray*, i32, i32*) local_unnamed_addr #5

; Function Attrs: nounwind ssp uwtable
define hidden i32 @_ZN6tflite3ops7builtin15fully_connected7EvalPieEP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_(%struct.TfLiteContext* nocapture readnone, %struct.TfLiteNode* nocapture readnone, %struct.TfLiteFullyConnectedParams* nocapture readonly, %"struct.tflite::ops::builtin::fully_connected::OpData"* nocapture readnone, %struct.TfLiteTensor* readonly, %struct.TfLiteTensor* readonly, %struct.TfLiteTensor* readonly, %struct.TfLiteTensor* readonly) local_unnamed_addr #1 {
  %9 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 2
  %10 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %9, align 8
  %11 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 0
  %12 = load i32, i32* %11, align 4
  %13 = icmp sgt i32 %12, 0
  br i1 %13, label %14, label %105

14:                                               ; preds = %8
  %15 = sext i32 %12 to i64
  %16 = icmp ult i32 %12, 8
  br i1 %16, label %17, label %20

17:                                               ; preds = %95, %14
  %18 = phi i64 [ 0, %14 ], [ %21, %95 ]
  %19 = phi i32 [ 1, %14 ], [ %103, %95 ]
  br label %115

20:                                               ; preds = %14
  %21 = and i64 %15, -8
  %22 = add nsw i64 %21, -8
  %23 = lshr exact i64 %22, 3
  %24 = add nuw nsw i64 %23, 1
  %25 = and i64 %24, 3
  %26 = icmp ult i64 %22, 24
  br i1 %26, label %72, label %27

27:                                               ; preds = %20
  %28 = sub nsw i64 %24, %25
  br label %29

29:                                               ; preds = %29, %27
  %30 = phi i64 [ 0, %27 ], [ %69, %29 ]
  %31 = phi <4 x i32> [ <i32 1, i32 1, i32 1, i32 1>, %27 ], [ %67, %29 ]
  %32 = phi <4 x i32> [ <i32 1, i32 1, i32 1, i32 1>, %27 ], [ %68, %29 ]
  %33 = phi i64 [ %28, %27 ], [ %70, %29 ]
  %34 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 %30
  %35 = bitcast i32* %34 to <4 x i32>*
  %36 = load <4 x i32>, <4 x i32>* %35, align 4
  %37 = getelementptr inbounds i32, i32* %34, i64 4
  %38 = bitcast i32* %37 to <4 x i32>*
  %39 = load <4 x i32>, <4 x i32>* %38, align 4
  %40 = mul nsw <4 x i32> %36, %31
  %41 = mul nsw <4 x i32> %39, %32
  %42 = or i64 %30, 8
  %43 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 %42
  %44 = bitcast i32* %43 to <4 x i32>*
  %45 = load <4 x i32>, <4 x i32>* %44, align 4
  %46 = getelementptr inbounds i32, i32* %43, i64 4
  %47 = bitcast i32* %46 to <4 x i32>*
  %48 = load <4 x i32>, <4 x i32>* %47, align 4
  %49 = mul nsw <4 x i32> %45, %40
  %50 = mul nsw <4 x i32> %48, %41
  %51 = or i64 %30, 16
  %52 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 %51
  %53 = bitcast i32* %52 to <4 x i32>*
  %54 = load <4 x i32>, <4 x i32>* %53, align 4
  %55 = getelementptr inbounds i32, i32* %52, i64 4
  %56 = bitcast i32* %55 to <4 x i32>*
  %57 = load <4 x i32>, <4 x i32>* %56, align 4
  %58 = mul nsw <4 x i32> %54, %49
  %59 = mul nsw <4 x i32> %57, %50
  %60 = or i64 %30, 24
  %61 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 %60
  %62 = bitcast i32* %61 to <4 x i32>*
  %63 = load <4 x i32>, <4 x i32>* %62, align 4
  %64 = getelementptr inbounds i32, i32* %61, i64 4
  %65 = bitcast i32* %64 to <4 x i32>*
  %66 = load <4 x i32>, <4 x i32>* %65, align 4
  %67 = mul nsw <4 x i32> %63, %58
  %68 = mul nsw <4 x i32> %66, %59
  %69 = add i64 %30, 32
  %70 = add i64 %33, -4
  %71 = icmp eq i64 %70, 0
  br i1 %71, label %72, label %29, !llvm.loop !11

72:                                               ; preds = %29, %20
  %73 = phi <4 x i32> [ undef, %20 ], [ %67, %29 ]
  %74 = phi <4 x i32> [ undef, %20 ], [ %68, %29 ]
  %75 = phi i64 [ 0, %20 ], [ %69, %29 ]
  %76 = phi <4 x i32> [ <i32 1, i32 1, i32 1, i32 1>, %20 ], [ %67, %29 ]
  %77 = phi <4 x i32> [ <i32 1, i32 1, i32 1, i32 1>, %20 ], [ %68, %29 ]
  %78 = icmp eq i64 %25, 0
  br i1 %78, label %95, label %79

79:                                               ; preds = %72, %79
  %80 = phi i64 [ %92, %79 ], [ %75, %72 ]
  %81 = phi <4 x i32> [ %90, %79 ], [ %76, %72 ]
  %82 = phi <4 x i32> [ %91, %79 ], [ %77, %72 ]
  %83 = phi i64 [ %93, %79 ], [ %25, %72 ]
  %84 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 %80
  %85 = bitcast i32* %84 to <4 x i32>*
  %86 = load <4 x i32>, <4 x i32>* %85, align 4
  %87 = getelementptr inbounds i32, i32* %84, i64 4
  %88 = bitcast i32* %87 to <4 x i32>*
  %89 = load <4 x i32>, <4 x i32>* %88, align 4
  %90 = mul nsw <4 x i32> %86, %81
  %91 = mul nsw <4 x i32> %89, %82
  %92 = add i64 %80, 8
  %93 = add i64 %83, -1
  %94 = icmp eq i64 %93, 0
  br i1 %94, label %95, label %79, !llvm.loop !12

95:                                               ; preds = %79, %72
  %96 = phi <4 x i32> [ %73, %72 ], [ %90, %79 ]
  %97 = phi <4 x i32> [ %74, %72 ], [ %91, %79 ]
  %98 = mul <4 x i32> %97, %96
  %99 = shufflevector <4 x i32> %98, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %100 = mul <4 x i32> %98, %99
  %101 = shufflevector <4 x i32> %100, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %102 = mul <4 x i32> %100, %101
  %103 = extractelement <4 x i32> %102, i32 0
  %104 = icmp eq i64 %21, %15
  br i1 %104, label %105, label %17

105:                                              ; preds = %115, %95, %8
  %106 = phi i32 [ 1, %8 ], [ %103, %95 ], [ %120, %115 ]
  %107 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 2
  %108 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %107, align 8
  %109 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %108, i64 0, i32 1, i64 1
  %110 = load i32, i32* %109, align 4
  %111 = sdiv i32 %106, %110
  %112 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %108, i64 0, i32 1, i64 0
  %113 = load i32, i32* %112, align 4
  %114 = icmp eq %struct.TfLiteTensor* %6, null
  br i1 %114, label %164, label %123

115:                                              ; preds = %17, %115
  %116 = phi i64 [ %121, %115 ], [ %18, %17 ]
  %117 = phi i32 [ %120, %115 ], [ %19, %17 ]
  %118 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 %116
  %119 = load i32, i32* %118, align 4
  %120 = mul nsw i32 %119, %117
  %121 = add nuw nsw i64 %116, 1
  %122 = icmp slt i64 %121, %15
  br i1 %122, label %115, label %105, !llvm.loop !13

123:                                              ; preds = %105
  %124 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 1
  %125 = bitcast %union.TfLitePtrUnion* %124 to i8**
  %126 = load i8*, i8** %125, align 8
  %127 = icmp eq %struct.TfLiteTensor* %7, null
  br i1 %127, label %132, label %128

128:                                              ; preds = %123
  %129 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 1
  %130 = bitcast %union.TfLitePtrUnion* %129 to float**
  %131 = load float*, float** %130, align 8
  br label %132

132:                                              ; preds = %123, %128
  %133 = phi float* [ %131, %128 ], [ null, %123 ]
  %134 = icmp sgt i32 %111, 0
  br i1 %134, label %135, label %191

135:                                              ; preds = %132
  %136 = icmp eq i32 %113, 0
  %137 = sext i32 %113 to i64
  %138 = shl nuw nsw i64 %137, 2
  %139 = zext i32 %111 to i64
  %140 = add nsw i64 %139, -1
  %141 = and i64 %139, 3
  %142 = icmp ult i64 %140, 3
  br i1 %142, label %177, label %143

143:                                              ; preds = %135
  %144 = sub nsw i64 %139, %141
  br label %145

145:                                              ; preds = %218, %143
  %146 = phi i64 [ 0, %143 ], [ %219, %218 ]
  %147 = phi i64 [ %144, %143 ], [ %220, %218 ]
  br i1 %136, label %218, label %148

148:                                              ; preds = %145
  %149 = mul nsw i64 %146, %137
  %150 = getelementptr inbounds float, float* %133, i64 %149
  %151 = bitcast float* %150 to i8*
  tail call void @llvm.memmove.p0i8.p0i8.i64(i8* align 4 %151, i8* align 4 %126, i64 %138, i1 false) #19
  %152 = or i64 %146, 1
  %153 = mul nsw i64 %152, %137
  %154 = getelementptr inbounds float, float* %133, i64 %153
  %155 = bitcast float* %154 to i8*
  tail call void @llvm.memmove.p0i8.p0i8.i64(i8* align 4 %155, i8* align 4 %126, i64 %138, i1 false) #19
  %156 = or i64 %146, 2
  %157 = mul nsw i64 %156, %137
  %158 = getelementptr inbounds float, float* %133, i64 %157
  %159 = bitcast float* %158 to i8*
  tail call void @llvm.memmove.p0i8.p0i8.i64(i8* align 4 %159, i8* align 4 %126, i64 %138, i1 false) #19
  %160 = or i64 %146, 3
  %161 = mul nsw i64 %160, %137
  %162 = getelementptr inbounds float, float* %133, i64 %161
  %163 = bitcast float* %162 to i8*
  tail call void @llvm.memmove.p0i8.p0i8.i64(i8* align 4 %163, i8* align 4 %126, i64 %138, i1 false) #19
  br label %218

164:                                              ; preds = %105
  %165 = icmp eq %struct.TfLiteTensor* %7, null
  br i1 %165, label %170, label %166

166:                                              ; preds = %164
  %167 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 1
  %168 = bitcast %union.TfLitePtrUnion* %167 to i8**
  %169 = load i8*, i8** %168, align 8
  br label %170

170:                                              ; preds = %164, %166
  %171 = phi i8* [ %169, %166 ], [ null, %164 ]
  %172 = mul i32 %113, %111
  %173 = icmp sgt i32 %172, 0
  br i1 %173, label %174, label %191

174:                                              ; preds = %170
  %175 = zext i32 %172 to i64
  %176 = shl nuw nsw i64 %175, 2
  call void @llvm.memset.p0i8.i64(i8* align 4 %171, i8 0, i64 %176, i1 false)
  br label %191

177:                                              ; preds = %218, %135
  %178 = phi i64 [ 0, %135 ], [ %219, %218 ]
  %179 = icmp eq i64 %141, 0
  br i1 %179, label %191, label %180

180:                                              ; preds = %177, %187
  %181 = phi i64 [ %188, %187 ], [ %178, %177 ]
  %182 = phi i64 [ %189, %187 ], [ %141, %177 ]
  br i1 %136, label %187, label %183

183:                                              ; preds = %180
  %184 = mul nsw i64 %181, %137
  %185 = getelementptr inbounds float, float* %133, i64 %184
  %186 = bitcast float* %185 to i8*
  tail call void @llvm.memmove.p0i8.p0i8.i64(i8* align 4 %186, i8* align 4 %126, i64 %138, i1 false) #19
  br label %187

187:                                              ; preds = %183, %180
  %188 = add nuw nsw i64 %181, 1
  %189 = add i64 %182, -1
  %190 = icmp eq i64 %189, 0
  br i1 %190, label %191, label %180, !llvm.loop !14

191:                                              ; preds = %177, %187, %174, %170, %132
  %192 = icmp eq %struct.TfLiteTensor* %5, null
  br i1 %192, label %197, label %193

193:                                              ; preds = %191
  %194 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 1
  %195 = bitcast %union.TfLitePtrUnion* %194 to float**
  %196 = load float*, float** %195, align 8
  br label %197

197:                                              ; preds = %191, %193
  %198 = phi float* [ %196, %193 ], [ null, %191 ]
  %199 = icmp eq %struct.TfLiteTensor* %4, null
  br i1 %199, label %204, label %200

200:                                              ; preds = %197
  %201 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 1
  %202 = bitcast %union.TfLitePtrUnion* %201 to float**
  %203 = load float*, float** %202, align 8
  br label %204

204:                                              ; preds = %197, %200
  %205 = phi float* [ %203, %200 ], [ null, %197 ]
  %206 = icmp eq %struct.TfLiteTensor* %7, null
  br i1 %206, label %207, label %208

207:                                              ; preds = %204
  tail call void @_ZN6tflite12tensor_utils35MatrixBatchVectorMultiplyAccumulateEPKfiiS2_iPf(float* %198, i32 %113, i32 %110, float* %205, i32 %111, float* null) #19
  br label %213

208:                                              ; preds = %204
  %209 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 1
  %210 = bitcast %union.TfLitePtrUnion* %209 to float**
  %211 = load float*, float** %210, align 8
  tail call void @_ZN6tflite12tensor_utils35MatrixBatchVectorMultiplyAccumulateEPKfiiS2_iPf(float* %198, i32 %113, i32 %110, float* %205, i32 %111, float* %211) #19
  %212 = load float*, float** %210, align 8
  br label %213

213:                                              ; preds = %207, %208
  %214 = phi float* [ %212, %208 ], [ null, %207 ]
  %215 = getelementptr inbounds %struct.TfLiteFullyConnectedParams, %struct.TfLiteFullyConnectedParams* %2, i64 0, i32 0
  %216 = mul nsw i32 %113, %111
  %217 = load i32, i32* %215, align 4
  tail call void @_ZN6tflite12tensor_utils23ApplyActivationToVectorEPKfi21TfLiteFusedActivationPf(float* %214, i32 %216, i32 %217, float* %214)
  ret i32 0

218:                                              ; preds = %145, %148
  %219 = add nuw nsw i64 %146, 4
  %220 = add i64 %147, -4
  %221 = icmp eq i64 %220, 0
  br i1 %221, label %177, label %145
}

declare void @_ZN6tflite12tensor_utils35MatrixBatchVectorMultiplyAccumulateEPKfiiS2_iPf(float*, i32, i32, float*, i32, float*) local_unnamed_addr #5

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN6tflite12tensor_utils23ApplyActivationToVectorEPKfi21TfLiteFusedActivationPf(float* noalias, i32, i32, float* noalias) local_unnamed_addr #4 comdat {
  %5 = alloca float, align 4
  %6 = alloca float, align 4
  %7 = alloca %"struct.Eigen::internal::evaluator", align 8
  %8 = alloca %"struct.Eigen::internal::evaluator.35", align 8
  %9 = alloca %"class.Eigen::internal::generic_dense_assignment_kernel", align 8
  %10 = alloca %"struct.Eigen::internal::assign_op", align 1
  %11 = alloca %"class.Eigen::ArrayWrapper", align 8
  %12 = alloca float, align 4
  %13 = alloca float, align 4
  %14 = alloca %"struct.Eigen::internal::assign_op", align 1
  %15 = alloca %"class.Eigen::CwiseUnaryOp.42", align 8
  %16 = alloca %"class.Eigen::ArrayWrapper", align 8
  %17 = alloca float, align 4
  switch i32 %2, label %283 [
    i32 6, label %232
    i32 1, label %18
    i32 2, label %50
    i32 3, label %89
    i32 4, label %128
    i32 5, label %151
  ]

18:                                               ; preds = %4
  %19 = icmp sgt i32 %1, 0
  br i1 %19, label %20, label %283

20:                                               ; preds = %18
  %21 = zext i32 %1 to i64
  %22 = bitcast float* %17 to i8*
  %23 = and i64 %21, 1
  %24 = icmp eq i32 %1, 1
  br i1 %24, label %241, label %25

25:                                               ; preds = %20
  %26 = sub nsw i64 %21, %23
  br label %27

27:                                               ; preds = %27, %25
  %28 = phi i64 [ 0, %25 ], [ %47, %27 ]
  %29 = phi i64 [ %26, %25 ], [ %48, %27 ]
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %22)
  store float 0.000000e+00, float* %17, align 4, !noalias !15
  %30 = getelementptr inbounds float, float* %0, i64 %28
  %31 = load float, float* %30, align 4, !alias.scope !19, !noalias !20
  %32 = fcmp ogt float %31, 0.000000e+00
  %33 = select i1 %32, float* %30, float* %17
  %34 = bitcast float* %33 to i32*
  %35 = load i32, i32* %34, align 4, !noalias !20
  %36 = getelementptr inbounds float, float* %3, i64 %28
  %37 = bitcast float* %36 to i32*
  store i32 %35, i32* %37, align 4, !alias.scope !20, !noalias !19
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %22)
  %38 = or i64 %28, 1
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %22)
  store float 0.000000e+00, float* %17, align 4, !noalias !15
  %39 = getelementptr inbounds float, float* %0, i64 %38
  %40 = load float, float* %39, align 4, !alias.scope !19, !noalias !20
  %41 = fcmp ogt float %40, 0.000000e+00
  %42 = select i1 %41, float* %39, float* %17
  %43 = bitcast float* %42 to i32*
  %44 = load i32, i32* %43, align 4, !noalias !20
  %45 = getelementptr inbounds float, float* %3, i64 %38
  %46 = bitcast float* %45 to i32*
  store i32 %44, i32* %46, align 4, !alias.scope !20, !noalias !19
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %22)
  %47 = add nuw nsw i64 %28, 2
  %48 = add i64 %29, -2
  %49 = icmp eq i64 %48, 0
  br i1 %49, label %241, label %27

50:                                               ; preds = %4
  %51 = icmp sgt i32 %1, 0
  br i1 %51, label %52, label %283

52:                                               ; preds = %50
  %53 = zext i32 %1 to i64
  %54 = bitcast float* %12 to i8*
  %55 = bitcast float* %13 to i8*
  %56 = and i64 %53, 1
  %57 = icmp eq i32 %1, 1
  br i1 %57, label %253, label %58

58:                                               ; preds = %52
  %59 = sub nsw i64 %53, %56
  br label %60

60:                                               ; preds = %60, %58
  %61 = phi i64 [ 0, %58 ], [ %86, %60 ]
  %62 = phi i64 [ %59, %58 ], [ %87, %60 ]
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %54)
  store float -1.000000e+00, float* %12, align 4, !noalias !21
  %63 = getelementptr inbounds float, float* %0, i64 %61
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %55)
  store float 1.000000e+00, float* %13, align 4, !noalias !21
  %64 = load float, float* %63, align 4, !alias.scope !25, !noalias !26
  %65 = fcmp ogt float %64, 1.000000e+00
  %66 = select i1 %65, float* %13, float* %63
  %67 = load float, float* %66, align 4, !noalias !26
  %68 = fcmp ogt float %67, -1.000000e+00
  %69 = select i1 %68, float* %66, float* %12
  %70 = bitcast float* %69 to i32*
  %71 = load i32, i32* %70, align 4, !noalias !26
  %72 = getelementptr inbounds float, float* %3, i64 %61
  %73 = bitcast float* %72 to i32*
  store i32 %71, i32* %73, align 4, !alias.scope !26, !noalias !25
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %55)
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %54)
  %74 = or i64 %61, 1
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %54)
  store float -1.000000e+00, float* %12, align 4, !noalias !21
  %75 = getelementptr inbounds float, float* %0, i64 %74
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %55)
  store float 1.000000e+00, float* %13, align 4, !noalias !21
  %76 = load float, float* %75, align 4, !alias.scope !25, !noalias !26
  %77 = fcmp ogt float %76, 1.000000e+00
  %78 = select i1 %77, float* %13, float* %75
  %79 = load float, float* %78, align 4, !noalias !26
  %80 = fcmp ogt float %79, -1.000000e+00
  %81 = select i1 %80, float* %78, float* %12
  %82 = bitcast float* %81 to i32*
  %83 = load i32, i32* %82, align 4, !noalias !26
  %84 = getelementptr inbounds float, float* %3, i64 %74
  %85 = bitcast float* %84 to i32*
  store i32 %83, i32* %85, align 4, !alias.scope !26, !noalias !25
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %55)
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %54)
  %86 = add nuw nsw i64 %61, 2
  %87 = add i64 %62, -2
  %88 = icmp eq i64 %87, 0
  br i1 %88, label %253, label %60

89:                                               ; preds = %4
  %90 = icmp sgt i32 %1, 0
  br i1 %90, label %91, label %283

91:                                               ; preds = %89
  %92 = zext i32 %1 to i64
  %93 = bitcast float* %5 to i8*
  %94 = bitcast float* %6 to i8*
  %95 = and i64 %92, 1
  %96 = icmp eq i32 %1, 1
  br i1 %96, label %268, label %97

97:                                               ; preds = %91
  %98 = sub nsw i64 %92, %95
  br label %99

99:                                               ; preds = %99, %97
  %100 = phi i64 [ 0, %97 ], [ %125, %99 ]
  %101 = phi i64 [ %98, %97 ], [ %126, %99 ]
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %93)
  store float 0.000000e+00, float* %5, align 4, !noalias !27
  %102 = getelementptr inbounds float, float* %0, i64 %100
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %94)
  store float 6.000000e+00, float* %6, align 4, !noalias !27
  %103 = load float, float* %102, align 4, !alias.scope !31, !noalias !32
  %104 = fcmp ogt float %103, 6.000000e+00
  %105 = select i1 %104, float* %6, float* %102
  %106 = load float, float* %105, align 4, !noalias !32
  %107 = fcmp ogt float %106, 0.000000e+00
  %108 = select i1 %107, float* %105, float* %5
  %109 = bitcast float* %108 to i32*
  %110 = load i32, i32* %109, align 4, !noalias !32
  %111 = getelementptr inbounds float, float* %3, i64 %100
  %112 = bitcast float* %111 to i32*
  store i32 %110, i32* %112, align 4, !alias.scope !32, !noalias !31
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %94)
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %93)
  %113 = or i64 %100, 1
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %93)
  store float 0.000000e+00, float* %5, align 4, !noalias !27
  %114 = getelementptr inbounds float, float* %0, i64 %113
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %94)
  store float 6.000000e+00, float* %6, align 4, !noalias !27
  %115 = load float, float* %114, align 4, !alias.scope !31, !noalias !32
  %116 = fcmp ogt float %115, 6.000000e+00
  %117 = select i1 %116, float* %6, float* %114
  %118 = load float, float* %117, align 4, !noalias !32
  %119 = fcmp ogt float %118, 0.000000e+00
  %120 = select i1 %119, float* %117, float* %5
  %121 = bitcast float* %120 to i32*
  %122 = load i32, i32* %121, align 4, !noalias !32
  %123 = getelementptr inbounds float, float* %3, i64 %113
  %124 = bitcast float* %123 to i32*
  store i32 %122, i32* %124, align 4, !alias.scope !32, !noalias !31
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %94)
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %93)
  %125 = add nuw nsw i64 %100, 2
  %126 = add i64 %101, -2
  %127 = icmp eq i64 %126, 0
  br i1 %127, label %268, label %99

128:                                              ; preds = %4
  %129 = sext i32 %1 to i64
  %130 = ptrtoint float* %0 to i64
  %131 = bitcast %"class.Eigen::ArrayWrapper"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %131) #19, !noalias !33
  %132 = getelementptr inbounds %"class.Eigen::ArrayWrapper", %"class.Eigen::ArrayWrapper"* %11, i64 0, i32 0, i32 0, i32 0, i32 0
  store float* %3, float** %132, align 8, !noalias !33
  %133 = getelementptr inbounds %"class.Eigen::ArrayWrapper", %"class.Eigen::ArrayWrapper"* %11, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0
  store i64 %129, i64* %133, align 8, !noalias !33
  %134 = getelementptr inbounds %"struct.Eigen::internal::assign_op", %"struct.Eigen::internal::assign_op"* %10, i64 0, i32 0
  call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %134) #19, !noalias !33
  %135 = bitcast %"struct.Eigen::internal::evaluator"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %135) #19, !noalias !33
  %136 = getelementptr inbounds %"struct.Eigen::internal::evaluator", %"struct.Eigen::internal::evaluator"* %7, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1, i32 0
  %137 = bitcast i8* %136 to i64*
  store i64 -6148914691236517206, i64* %137, align 8, !noalias !33
  %138 = bitcast %"struct.Eigen::internal::evaluator"* %7 to i64*
  store i64 %130, i64* %138, align 8, !noalias !33
  %139 = getelementptr inbounds %"struct.Eigen::internal::evaluator", %"struct.Eigen::internal::evaluator"* %7, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 0
  store i64 %129, i64* %139, align 8, !noalias !33
  %140 = bitcast %"struct.Eigen::internal::evaluator.35"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %140) #19, !noalias !33
  %141 = getelementptr inbounds %"struct.Eigen::internal::evaluator.35", %"struct.Eigen::internal::evaluator.35"* %8, i64 0, i32 0, i32 0, i32 0, i32 0, i32 1, i32 0
  %142 = bitcast i8* %141 to i64*
  store i64 -6148914691236517206, i64* %142, align 8, !noalias !33
  %143 = ptrtoint float* %3 to i64
  %144 = bitcast %"struct.Eigen::internal::evaluator.35"* %8 to i64*
  store i64 %143, i64* %144, align 8, !noalias !33
  %145 = getelementptr inbounds %"struct.Eigen::internal::evaluator.35", %"struct.Eigen::internal::evaluator.35"* %8, i64 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 0
  store i64 %129, i64* %145, align 8, !noalias !33
  %146 = bitcast %"class.Eigen::internal::generic_dense_assignment_kernel"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %146) #19, !noalias !33
  %147 = getelementptr inbounds %"class.Eigen::internal::generic_dense_assignment_kernel", %"class.Eigen::internal::generic_dense_assignment_kernel"* %9, i64 0, i32 0
  %148 = getelementptr inbounds %"class.Eigen::internal::generic_dense_assignment_kernel", %"class.Eigen::internal::generic_dense_assignment_kernel"* %9, i64 0, i32 1
  %149 = getelementptr inbounds %"class.Eigen::internal::generic_dense_assignment_kernel", %"class.Eigen::internal::generic_dense_assignment_kernel"* %9, i64 0, i32 2
  %150 = getelementptr inbounds %"class.Eigen::internal::generic_dense_assignment_kernel", %"class.Eigen::internal::generic_dense_assignment_kernel"* %9, i64 0, i32 3
  store %"struct.Eigen::internal::evaluator.35"* %8, %"struct.Eigen::internal::evaluator.35"** %147, align 8, !noalias !33
  store %"struct.Eigen::internal::evaluator"* %7, %"struct.Eigen::internal::evaluator"** %148, align 8, !noalias !33
  store %"struct.Eigen::internal::assign_op"* %10, %"struct.Eigen::internal::assign_op"** %149, align 8, !noalias !33
  store %"class.Eigen::ArrayWrapper"* %11, %"class.Eigen::ArrayWrapper"** %150, align 8, !noalias !33
  call void @_ZN5Eigen8internal21dense_assignment_loopINS0_31generic_dense_assignment_kernelINS0_9evaluatorINS_12ArrayWrapperINS_3MapINS_6MatrixIfLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEEEEEENS3_INS_12CwiseUnaryOpINS0_14scalar_tanh_opIfEEKSB_EEEENS0_9assign_opIffEELi0EEELi3ELi0EE3runERSL_(%"class.Eigen::internal::generic_dense_assignment_kernel"* nonnull dereferenceable(32) %9) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %146) #19, !noalias !33
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %140) #19, !noalias !33
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %135) #19, !noalias !33
  call void @llvm.lifetime.end.p0i8(i64 1, i8* nonnull %134) #19, !noalias !33
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %131) #19, !noalias !33
  br label %283

151:                                              ; preds = %4
  %152 = icmp sgt i32 %1, 0
  br i1 %152, label %153, label %283

153:                                              ; preds = %151
  %154 = zext i32 %1 to i64
  %155 = icmp ult i32 %1, 8
  br i1 %155, label %220, label %156

156:                                              ; preds = %153
  %157 = and i64 %154, 4294967288
  %158 = add nsw i64 %157, -8
  %159 = lshr exact i64 %158, 3
  %160 = add nuw nsw i64 %159, 1
  %161 = and i64 %160, 1
  %162 = icmp eq i64 %158, 0
  br i1 %162, label %200, label %163

163:                                              ; preds = %156
  %164 = sub nuw nsw i64 %160, %161
  br label %165

165:                                              ; preds = %165, %163
  %166 = phi i64 [ 0, %163 ], [ %197, %165 ]
  %167 = phi i64 [ %164, %163 ], [ %198, %165 ]
  %168 = getelementptr inbounds float, float* %0, i64 %166
  %169 = bitcast float* %168 to <4 x i32>*
  %170 = load <4 x i32>, <4 x i32>* %169, align 4, !alias.scope !37, !noalias !40
  %171 = getelementptr inbounds float, float* %168, i64 4
  %172 = bitcast float* %171 to <4 x i32>*
  %173 = load <4 x i32>, <4 x i32>* %172, align 4, !alias.scope !37, !noalias !40
  %174 = icmp slt <4 x i32> %170, zeroinitializer
  %175 = icmp slt <4 x i32> %173, zeroinitializer
  %176 = uitofp <4 x i1> %174 to <4 x float>
  %177 = uitofp <4 x i1> %175 to <4 x float>
  %178 = getelementptr inbounds float, float* %3, i64 %166
  %179 = bitcast float* %178 to <4 x float>*
  store <4 x float> %176, <4 x float>* %179, align 4, !alias.scope !40, !noalias !37
  %180 = getelementptr inbounds float, float* %178, i64 4
  %181 = bitcast float* %180 to <4 x float>*
  store <4 x float> %177, <4 x float>* %181, align 4, !alias.scope !40, !noalias !37
  %182 = or i64 %166, 8
  %183 = getelementptr inbounds float, float* %0, i64 %182
  %184 = bitcast float* %183 to <4 x i32>*
  %185 = load <4 x i32>, <4 x i32>* %184, align 4, !alias.scope !37, !noalias !40
  %186 = getelementptr inbounds float, float* %183, i64 4
  %187 = bitcast float* %186 to <4 x i32>*
  %188 = load <4 x i32>, <4 x i32>* %187, align 4, !alias.scope !37, !noalias !40
  %189 = icmp slt <4 x i32> %185, zeroinitializer
  %190 = icmp slt <4 x i32> %188, zeroinitializer
  %191 = uitofp <4 x i1> %189 to <4 x float>
  %192 = uitofp <4 x i1> %190 to <4 x float>
  %193 = getelementptr inbounds float, float* %3, i64 %182
  %194 = bitcast float* %193 to <4 x float>*
  store <4 x float> %191, <4 x float>* %194, align 4, !alias.scope !40, !noalias !37
  %195 = getelementptr inbounds float, float* %193, i64 4
  %196 = bitcast float* %195 to <4 x float>*
  store <4 x float> %192, <4 x float>* %196, align 4, !alias.scope !40, !noalias !37
  %197 = add i64 %166, 16
  %198 = add i64 %167, -2
  %199 = icmp eq i64 %198, 0
  br i1 %199, label %200, label %165, !llvm.loop !42

200:                                              ; preds = %165, %156
  %201 = phi i64 [ 0, %156 ], [ %197, %165 ]
  %202 = icmp eq i64 %161, 0
  br i1 %202, label %218, label %203

203:                                              ; preds = %200
  %204 = getelementptr inbounds float, float* %0, i64 %201
  %205 = bitcast float* %204 to <4 x i32>*
  %206 = load <4 x i32>, <4 x i32>* %205, align 4, !alias.scope !37, !noalias !40
  %207 = getelementptr inbounds float, float* %204, i64 4
  %208 = bitcast float* %207 to <4 x i32>*
  %209 = load <4 x i32>, <4 x i32>* %208, align 4, !alias.scope !37, !noalias !40
  %210 = icmp slt <4 x i32> %206, zeroinitializer
  %211 = icmp slt <4 x i32> %209, zeroinitializer
  %212 = uitofp <4 x i1> %210 to <4 x float>
  %213 = uitofp <4 x i1> %211 to <4 x float>
  %214 = getelementptr inbounds float, float* %3, i64 %201
  %215 = bitcast float* %214 to <4 x float>*
  store <4 x float> %212, <4 x float>* %215, align 4, !alias.scope !40, !noalias !37
  %216 = getelementptr inbounds float, float* %214, i64 4
  %217 = bitcast float* %216 to <4 x float>*
  store <4 x float> %213, <4 x float>* %217, align 4, !alias.scope !40, !noalias !37
  br label %218

218:                                              ; preds = %200, %203
  %219 = icmp eq i64 %157, %154
  br i1 %219, label %283, label %220

220:                                              ; preds = %218, %153
  %221 = phi i64 [ 0, %153 ], [ %157, %218 ]
  br label %222

222:                                              ; preds = %220, %222
  %223 = phi i64 [ %230, %222 ], [ %221, %220 ]
  %224 = getelementptr inbounds float, float* %0, i64 %223
  %225 = bitcast float* %224 to i32*
  %226 = load i32, i32* %225, align 4, !alias.scope !37, !noalias !40
  %227 = icmp slt i32 %226, 0
  %228 = uitofp i1 %227 to float
  %229 = getelementptr inbounds float, float* %3, i64 %223
  store float %228, float* %229, align 4, !alias.scope !40, !noalias !37
  %230 = add nuw nsw i64 %223, 1
  %231 = icmp eq i64 %230, %154
  br i1 %231, label %283, label %222, !llvm.loop !43

232:                                              ; preds = %4
  %233 = sext i32 %1 to i64
  %234 = bitcast %"class.Eigen::CwiseUnaryOp.42"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %234) #19, !noalias !44
  %235 = getelementptr inbounds %"class.Eigen::CwiseUnaryOp.42", %"class.Eigen::CwiseUnaryOp.42"* %15, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store float* %0, float** %235, align 8, !noalias !44
  %236 = getelementptr inbounds %"class.Eigen::CwiseUnaryOp.42", %"class.Eigen::CwiseUnaryOp.42"* %15, i64 0, i32 0, i32 0, i32 0, i32 0, i32 1, i32 0
  store i64 %233, i64* %236, align 8, !noalias !44
  %237 = bitcast %"class.Eigen::ArrayWrapper"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %237) #19, !noalias !44
  %238 = getelementptr inbounds %"class.Eigen::ArrayWrapper", %"class.Eigen::ArrayWrapper"* %16, i64 0, i32 0, i32 0, i32 0, i32 0
  store float* %3, float** %238, align 8, !noalias !44
  %239 = getelementptr inbounds %"class.Eigen::ArrayWrapper", %"class.Eigen::ArrayWrapper"* %16, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0
  store i64 %233, i64* %239, align 8, !noalias !44
  %240 = getelementptr inbounds %"struct.Eigen::internal::assign_op", %"struct.Eigen::internal::assign_op"* %14, i64 0, i32 0
  call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %240) #19, !noalias !44
  call void @_ZN5Eigen8internal26call_dense_assignment_loopINS_12ArrayWrapperINS_3MapINS_6MatrixIfLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEEEENS_12CwiseUnaryOpINS0_18scalar_logistic_opIfEEKS9_EENS0_9assign_opIffEEEEvRT_RKT0_RKT1_(%"class.Eigen::ArrayWrapper"* nonnull dereferenceable(24) %16, %"class.Eigen::CwiseUnaryOp.42"* nonnull dereferenceable(32) %15, %"struct.Eigen::internal::assign_op"* nonnull dereferenceable(1) %14) #19
  call void @llvm.lifetime.end.p0i8(i64 1, i8* nonnull %240) #19, !noalias !44
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %237) #19, !noalias !44
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %234) #19, !noalias !44
  br label %283

241:                                              ; preds = %27, %20
  %242 = phi i64 [ 0, %20 ], [ %47, %27 ]
  %243 = icmp eq i64 %23, 0
  br i1 %243, label %283, label %244

244:                                              ; preds = %241
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %22)
  store float 0.000000e+00, float* %17, align 4, !noalias !15
  %245 = getelementptr inbounds float, float* %0, i64 %242
  %246 = load float, float* %245, align 4, !alias.scope !19, !noalias !20
  %247 = fcmp ogt float %246, 0.000000e+00
  %248 = select i1 %247, float* %245, float* %17
  %249 = bitcast float* %248 to i32*
  %250 = load i32, i32* %249, align 4, !noalias !20
  %251 = getelementptr inbounds float, float* %3, i64 %242
  %252 = bitcast float* %251 to i32*
  store i32 %250, i32* %252, align 4, !alias.scope !20, !noalias !19
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %22)
  br label %283

253:                                              ; preds = %60, %52
  %254 = phi i64 [ 0, %52 ], [ %86, %60 ]
  %255 = icmp eq i64 %56, 0
  br i1 %255, label %283, label %256

256:                                              ; preds = %253
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %54)
  store float -1.000000e+00, float* %12, align 4, !noalias !21
  %257 = getelementptr inbounds float, float* %0, i64 %254
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %55)
  store float 1.000000e+00, float* %13, align 4, !noalias !21
  %258 = load float, float* %257, align 4, !alias.scope !25, !noalias !26
  %259 = fcmp ogt float %258, 1.000000e+00
  %260 = select i1 %259, float* %13, float* %257
  %261 = load float, float* %260, align 4, !noalias !26
  %262 = fcmp ogt float %261, -1.000000e+00
  %263 = select i1 %262, float* %260, float* %12
  %264 = bitcast float* %263 to i32*
  %265 = load i32, i32* %264, align 4, !noalias !26
  %266 = getelementptr inbounds float, float* %3, i64 %254
  %267 = bitcast float* %266 to i32*
  store i32 %265, i32* %267, align 4, !alias.scope !26, !noalias !25
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %55)
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %54)
  br label %283

268:                                              ; preds = %99, %91
  %269 = phi i64 [ 0, %91 ], [ %125, %99 ]
  %270 = icmp eq i64 %95, 0
  br i1 %270, label %283, label %271

271:                                              ; preds = %268
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %93)
  store float 0.000000e+00, float* %5, align 4, !noalias !27
  %272 = getelementptr inbounds float, float* %0, i64 %269
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %94)
  store float 6.000000e+00, float* %6, align 4, !noalias !27
  %273 = load float, float* %272, align 4, !alias.scope !31, !noalias !32
  %274 = fcmp ogt float %273, 6.000000e+00
  %275 = select i1 %274, float* %6, float* %272
  %276 = load float, float* %275, align 4, !noalias !32
  %277 = fcmp ogt float %276, 0.000000e+00
  %278 = select i1 %277, float* %275, float* %5
  %279 = bitcast float* %278 to i32*
  %280 = load i32, i32* %279, align 4, !noalias !32
  %281 = getelementptr inbounds float, float* %3, i64 %269
  %282 = bitcast float* %281 to i32*
  store i32 %280, i32* %282, align 4, !alias.scope !32, !noalias !31
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %94)
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %93)
  br label %283

283:                                              ; preds = %222, %271, %268, %256, %253, %244, %241, %218, %151, %89, %50, %18, %128, %232, %4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @_ZN6tflite3ops7builtin15fully_connected10EvalHybridEP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_SE_SE_SE_SE_SE_(%struct.TfLiteContext*, %struct.TfLiteNode* nocapture readnone, %struct.TfLiteFullyConnectedParams* nocapture readonly, %"struct.tflite::ops::builtin::fully_connected::OpData"*, %struct.TfLiteTensor* readonly, %struct.TfLiteTensor* readonly, %struct.TfLiteTensor* readonly, %struct.TfLiteTensor* readonly, %struct.TfLiteTensor* readonly, %struct.TfLiteTensor* readonly, %struct.TfLiteTensor* readonly, %struct.TfLiteTensor* readonly, %struct.TfLiteTensor* readonly) local_unnamed_addr #1 {
  %14 = alloca float, align 4
  %15 = alloca float, align 4
  %16 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 2
  %17 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %16, align 8
  %18 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %17, i64 0, i32 0
  %19 = load i32, i32* %18, align 4
  %20 = icmp sgt i32 %19, 0
  br i1 %20, label %21, label %112

21:                                               ; preds = %13
  %22 = sext i32 %19 to i64
  %23 = icmp ult i32 %19, 8
  br i1 %23, label %24, label %27

24:                                               ; preds = %102, %21
  %25 = phi i64 [ 0, %21 ], [ %28, %102 ]
  %26 = phi i32 [ 1, %21 ], [ %110, %102 ]
  br label %122

27:                                               ; preds = %21
  %28 = and i64 %22, -8
  %29 = add nsw i64 %28, -8
  %30 = lshr exact i64 %29, 3
  %31 = add nuw nsw i64 %30, 1
  %32 = and i64 %31, 3
  %33 = icmp ult i64 %29, 24
  br i1 %33, label %79, label %34

34:                                               ; preds = %27
  %35 = sub nsw i64 %31, %32
  br label %36

36:                                               ; preds = %36, %34
  %37 = phi i64 [ 0, %34 ], [ %76, %36 ]
  %38 = phi <4 x i32> [ <i32 1, i32 1, i32 1, i32 1>, %34 ], [ %74, %36 ]
  %39 = phi <4 x i32> [ <i32 1, i32 1, i32 1, i32 1>, %34 ], [ %75, %36 ]
  %40 = phi i64 [ %35, %34 ], [ %77, %36 ]
  %41 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %17, i64 0, i32 1, i64 %37
  %42 = bitcast i32* %41 to <4 x i32>*
  %43 = load <4 x i32>, <4 x i32>* %42, align 4
  %44 = getelementptr inbounds i32, i32* %41, i64 4
  %45 = bitcast i32* %44 to <4 x i32>*
  %46 = load <4 x i32>, <4 x i32>* %45, align 4
  %47 = mul nsw <4 x i32> %43, %38
  %48 = mul nsw <4 x i32> %46, %39
  %49 = or i64 %37, 8
  %50 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %17, i64 0, i32 1, i64 %49
  %51 = bitcast i32* %50 to <4 x i32>*
  %52 = load <4 x i32>, <4 x i32>* %51, align 4
  %53 = getelementptr inbounds i32, i32* %50, i64 4
  %54 = bitcast i32* %53 to <4 x i32>*
  %55 = load <4 x i32>, <4 x i32>* %54, align 4
  %56 = mul nsw <4 x i32> %52, %47
  %57 = mul nsw <4 x i32> %55, %48
  %58 = or i64 %37, 16
  %59 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %17, i64 0, i32 1, i64 %58
  %60 = bitcast i32* %59 to <4 x i32>*
  %61 = load <4 x i32>, <4 x i32>* %60, align 4
  %62 = getelementptr inbounds i32, i32* %59, i64 4
  %63 = bitcast i32* %62 to <4 x i32>*
  %64 = load <4 x i32>, <4 x i32>* %63, align 4
  %65 = mul nsw <4 x i32> %61, %56
  %66 = mul nsw <4 x i32> %64, %57
  %67 = or i64 %37, 24
  %68 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %17, i64 0, i32 1, i64 %67
  %69 = bitcast i32* %68 to <4 x i32>*
  %70 = load <4 x i32>, <4 x i32>* %69, align 4
  %71 = getelementptr inbounds i32, i32* %68, i64 4
  %72 = bitcast i32* %71 to <4 x i32>*
  %73 = load <4 x i32>, <4 x i32>* %72, align 4
  %74 = mul nsw <4 x i32> %70, %65
  %75 = mul nsw <4 x i32> %73, %66
  %76 = add i64 %37, 32
  %77 = add i64 %40, -4
  %78 = icmp eq i64 %77, 0
  br i1 %78, label %79, label %36, !llvm.loop !48

79:                                               ; preds = %36, %27
  %80 = phi <4 x i32> [ undef, %27 ], [ %74, %36 ]
  %81 = phi <4 x i32> [ undef, %27 ], [ %75, %36 ]
  %82 = phi i64 [ 0, %27 ], [ %76, %36 ]
  %83 = phi <4 x i32> [ <i32 1, i32 1, i32 1, i32 1>, %27 ], [ %74, %36 ]
  %84 = phi <4 x i32> [ <i32 1, i32 1, i32 1, i32 1>, %27 ], [ %75, %36 ]
  %85 = icmp eq i64 %32, 0
  br i1 %85, label %102, label %86

86:                                               ; preds = %79, %86
  %87 = phi i64 [ %99, %86 ], [ %82, %79 ]
  %88 = phi <4 x i32> [ %97, %86 ], [ %83, %79 ]
  %89 = phi <4 x i32> [ %98, %86 ], [ %84, %79 ]
  %90 = phi i64 [ %100, %86 ], [ %32, %79 ]
  %91 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %17, i64 0, i32 1, i64 %87
  %92 = bitcast i32* %91 to <4 x i32>*
  %93 = load <4 x i32>, <4 x i32>* %92, align 4
  %94 = getelementptr inbounds i32, i32* %91, i64 4
  %95 = bitcast i32* %94 to <4 x i32>*
  %96 = load <4 x i32>, <4 x i32>* %95, align 4
  %97 = mul nsw <4 x i32> %93, %88
  %98 = mul nsw <4 x i32> %96, %89
  %99 = add i64 %87, 8
  %100 = add i64 %90, -1
  %101 = icmp eq i64 %100, 0
  br i1 %101, label %102, label %86, !llvm.loop !49

102:                                              ; preds = %86, %79
  %103 = phi <4 x i32> [ %80, %79 ], [ %97, %86 ]
  %104 = phi <4 x i32> [ %81, %79 ], [ %98, %86 ]
  %105 = mul <4 x i32> %104, %103
  %106 = shufflevector <4 x i32> %105, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %107 = mul <4 x i32> %105, %106
  %108 = shufflevector <4 x i32> %107, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %109 = mul <4 x i32> %107, %108
  %110 = extractelement <4 x i32> %109, i32 0
  %111 = icmp eq i64 %28, %22
  br i1 %111, label %112, label %24

112:                                              ; preds = %122, %102, %13
  %113 = phi i32 [ 1, %13 ], [ %110, %102 ], [ %127, %122 ]
  %114 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 2
  %115 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %114, align 8
  %116 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %115, i64 0, i32 1, i64 1
  %117 = load i32, i32* %116, align 4
  %118 = sdiv i32 %113, %117
  %119 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %115, i64 0, i32 1, i64 0
  %120 = load i32, i32* %119, align 4
  %121 = icmp eq %struct.TfLiteTensor* %6, null
  br i1 %121, label %171, label %130

122:                                              ; preds = %24, %122
  %123 = phi i64 [ %128, %122 ], [ %25, %24 ]
  %124 = phi i32 [ %127, %122 ], [ %26, %24 ]
  %125 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %17, i64 0, i32 1, i64 %123
  %126 = load i32, i32* %125, align 4
  %127 = mul nsw i32 %126, %124
  %128 = add nuw nsw i64 %123, 1
  %129 = icmp slt i64 %128, %22
  br i1 %129, label %122, label %112, !llvm.loop !50

130:                                              ; preds = %112
  %131 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 1
  %132 = bitcast %union.TfLitePtrUnion* %131 to i8**
  %133 = load i8*, i8** %132, align 8
  %134 = icmp eq %struct.TfLiteTensor* %12, null
  br i1 %134, label %139, label %135

135:                                              ; preds = %130
  %136 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %12, i64 0, i32 1
  %137 = bitcast %union.TfLitePtrUnion* %136 to float**
  %138 = load float*, float** %137, align 8
  br label %139

139:                                              ; preds = %130, %135
  %140 = phi float* [ %138, %135 ], [ null, %130 ]
  %141 = icmp sgt i32 %118, 0
  br i1 %141, label %142, label %198

142:                                              ; preds = %139
  %143 = icmp eq i32 %120, 0
  %144 = sext i32 %120 to i64
  %145 = shl nuw nsw i64 %144, 2
  %146 = zext i32 %118 to i64
  %147 = add nsw i64 %146, -1
  %148 = and i64 %146, 3
  %149 = icmp ult i64 %147, 3
  br i1 %149, label %184, label %150

150:                                              ; preds = %142
  %151 = sub nsw i64 %146, %148
  br label %152

152:                                              ; preds = %432, %150
  %153 = phi i64 [ 0, %150 ], [ %433, %432 ]
  %154 = phi i64 [ %151, %150 ], [ %434, %432 ]
  br i1 %143, label %432, label %155

155:                                              ; preds = %152
  %156 = mul nsw i64 %153, %144
  %157 = getelementptr inbounds float, float* %140, i64 %156
  %158 = bitcast float* %157 to i8*
  tail call void @llvm.memmove.p0i8.p0i8.i64(i8* align 4 %158, i8* align 4 %133, i64 %145, i1 false) #19
  %159 = or i64 %153, 1
  %160 = mul nsw i64 %159, %144
  %161 = getelementptr inbounds float, float* %140, i64 %160
  %162 = bitcast float* %161 to i8*
  tail call void @llvm.memmove.p0i8.p0i8.i64(i8* align 4 %162, i8* align 4 %133, i64 %145, i1 false) #19
  %163 = or i64 %153, 2
  %164 = mul nsw i64 %163, %144
  %165 = getelementptr inbounds float, float* %140, i64 %164
  %166 = bitcast float* %165 to i8*
  tail call void @llvm.memmove.p0i8.p0i8.i64(i8* align 4 %166, i8* align 4 %133, i64 %145, i1 false) #19
  %167 = or i64 %153, 3
  %168 = mul nsw i64 %167, %144
  %169 = getelementptr inbounds float, float* %140, i64 %168
  %170 = bitcast float* %169 to i8*
  tail call void @llvm.memmove.p0i8.p0i8.i64(i8* align 4 %170, i8* align 4 %133, i64 %145, i1 false) #19
  br label %432

171:                                              ; preds = %112
  %172 = icmp eq %struct.TfLiteTensor* %12, null
  br i1 %172, label %177, label %173

173:                                              ; preds = %171
  %174 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %12, i64 0, i32 1
  %175 = bitcast %union.TfLitePtrUnion* %174 to i8**
  %176 = load i8*, i8** %175, align 8
  br label %177

177:                                              ; preds = %171, %173
  %178 = phi i8* [ %176, %173 ], [ null, %171 ]
  %179 = mul i32 %120, %118
  %180 = icmp sgt i32 %179, 0
  br i1 %180, label %181, label %198

181:                                              ; preds = %177
  %182 = zext i32 %179 to i64
  %183 = shl nuw nsw i64 %182, 2
  call void @llvm.memset.p0i8.i64(i8* align 4 %178, i8 0, i64 %183, i1 false)
  br label %198

184:                                              ; preds = %432, %142
  %185 = phi i64 [ 0, %142 ], [ %433, %432 ]
  %186 = icmp eq i64 %148, 0
  br i1 %186, label %198, label %187

187:                                              ; preds = %184, %194
  %188 = phi i64 [ %195, %194 ], [ %185, %184 ]
  %189 = phi i64 [ %196, %194 ], [ %148, %184 ]
  br i1 %143, label %194, label %190

190:                                              ; preds = %187
  %191 = mul nsw i64 %188, %144
  %192 = getelementptr inbounds float, float* %140, i64 %191
  %193 = bitcast float* %192 to i8*
  tail call void @llvm.memmove.p0i8.p0i8.i64(i8* align 4 %193, i8* align 4 %133, i64 %145, i1 false) #19
  br label %194

194:                                              ; preds = %190, %187
  %195 = add nuw nsw i64 %188, 1
  %196 = add i64 %189, -1
  %197 = icmp eq i64 %196, 0
  br i1 %197, label %198, label %187, !llvm.loop !51

198:                                              ; preds = %184, %194, %181, %177, %139
  %199 = icmp eq %struct.TfLiteTensor* %4, null
  br i1 %199, label %204, label %200

200:                                              ; preds = %198
  %201 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 1
  %202 = bitcast %union.TfLitePtrUnion* %201 to float**
  %203 = load float*, float** %202, align 8
  br label %204

204:                                              ; preds = %198, %200
  %205 = phi float* [ %203, %200 ], [ null, %198 ]
  %206 = tail call zeroext i1 @_ZN6tflite12tensor_utils12IsZeroVectorEPKfi(float* %205, i32 %113) #19
  br i1 %206, label %207, label %218

207:                                              ; preds = %204
  %208 = icmp eq %struct.TfLiteTensor* %12, null
  br i1 %208, label %213, label %209

209:                                              ; preds = %207
  %210 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %12, i64 0, i32 1
  %211 = bitcast %union.TfLitePtrUnion* %210 to float**
  %212 = load float*, float** %211, align 8
  br label %213

213:                                              ; preds = %207, %209
  %214 = phi float* [ %212, %209 ], [ null, %207 ]
  %215 = getelementptr inbounds %struct.TfLiteFullyConnectedParams, %struct.TfLiteFullyConnectedParams* %2, i64 0, i32 0
  %216 = mul nsw i32 %120, %118
  %217 = load i32, i32* %215, align 4
  tail call void @_ZN6tflite12tensor_utils23ApplyActivationToVectorEPKfi21TfLiteFusedActivationPf(float* %214, i32 %216, i32 %217, float* %214)
  br label %431

218:                                              ; preds = %204
  %219 = icmp eq %struct.TfLiteTensor* %8, null
  br i1 %219, label %225, label %220

220:                                              ; preds = %218
  %221 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %8, i64 0, i32 1
  %222 = bitcast %union.TfLitePtrUnion* %221 to float**
  %223 = load float*, float** %222, align 8
  %224 = bitcast float* %223 to i8*
  br label %225

225:                                              ; preds = %218, %220
  %226 = phi i8* [ %224, %220 ], [ null, %218 ]
  %227 = phi float* [ %223, %220 ], [ null, %218 ]
  %228 = getelementptr inbounds %struct.TfLiteFullyConnectedParams, %struct.TfLiteFullyConnectedParams* %2, i64 0, i32 3
  %229 = load i8, i8* %228, align 1, !range !10
  %230 = icmp eq i8 %229, 0
  br i1 %230, label %242, label %231

231:                                              ; preds = %225
  %232 = icmp eq %struct.TfLiteTensor* %11, null
  br i1 %232, label %236, label %233

233:                                              ; preds = %231
  %234 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %11, i64 0, i32 1, i32 0
  %235 = load i32*, i32** %234, align 8
  br label %236

236:                                              ; preds = %231, %233
  %237 = phi i32* [ %235, %233 ], [ null, %231 ]
  %238 = icmp eq %struct.TfLiteTensor* %10, null
  br i1 %238, label %242, label %239

239:                                              ; preds = %236
  %240 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %10, i64 0, i32 1, i32 0
  %241 = load i32*, i32** %240, align 8
  br label %242

242:                                              ; preds = %239, %236, %225
  %243 = phi i32* [ null, %225 ], [ %237, %236 ], [ %237, %239 ]
  %244 = phi i32* [ null, %225 ], [ null, %236 ], [ %241, %239 ]
  %245 = icmp eq %struct.TfLiteTensor* %7, null
  br i1 %245, label %250, label %246

246:                                              ; preds = %242
  %247 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 1
  %248 = bitcast %union.TfLitePtrUnion* %247 to i8**
  %249 = load i8*, i8** %248, align 8
  br label %250

250:                                              ; preds = %242, %246
  %251 = phi i8* [ %249, %246 ], [ null, %242 ]
  %252 = icmp eq %struct.TfLiteTensor* %5, null
  br i1 %252, label %257, label %253

253:                                              ; preds = %250
  %254 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 1
  %255 = bitcast %union.TfLitePtrUnion* %254 to i8**
  %256 = load i8*, i8** %255, align 8
  br label %257

257:                                              ; preds = %250, %253
  %258 = phi i8* [ %256, %253 ], [ null, %250 ]
  br i1 %199, label %263, label %259

259:                                              ; preds = %257
  %260 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 1
  %261 = bitcast %union.TfLitePtrUnion* %260 to float**
  %262 = load float*, float** %261, align 8
  br label %263

263:                                              ; preds = %257, %259
  %264 = phi float* [ %262, %259 ], [ null, %257 ]
  %265 = icmp sgt i32 %118, 0
  br i1 %265, label %266, label %385

266:                                              ; preds = %263
  %267 = bitcast float* %14 to i8*
  %268 = bitcast float* %15 to i8*
  %269 = sext i32 %117 to i64
  %270 = zext i32 %118 to i64
  br label %271

271:                                              ; preds = %283, %266
  %272 = phi i64 [ 0, %266 ], [ %284, %283 ]
  %273 = mul nsw i64 %272, %269
  br i1 %230, label %279, label %274

274:                                              ; preds = %271
  %275 = getelementptr inbounds float, float* %264, i64 %273
  %276 = getelementptr inbounds i8, i8* %251, i64 %273
  %277 = getelementptr inbounds float, float* %227, i64 %272
  %278 = getelementptr inbounds i32, i32* %243, i64 %272
  call void @_ZN6tflite12tensor_utils24AsymmetricQuantizeFloatsEPKfiPaPfPi(float* %275, i32 %117, i8* %276, float* %277, i32* %278) #19
  br label %283

279:                                              ; preds = %271
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %267) #19
  store float 0xFFFFFFFFE0000000, float* %14, align 4
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %268) #19
  store float 0xFFFFFFFFE0000000, float* %15, align 4
  %280 = getelementptr inbounds float, float* %264, i64 %273
  %281 = getelementptr inbounds i8, i8* %251, i64 %273
  %282 = getelementptr inbounds float, float* %227, i64 %272
  call void @_ZN6tflite12tensor_utils23SymmetricQuantizeFloatsEPKfiPaPfS4_S4_(float* %280, i32 %117, i8* %281, float* nonnull %14, float* nonnull %15, float* %282) #19
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %268) #19
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %267) #19
  br label %283

283:                                              ; preds = %279, %274
  %284 = add nuw nsw i64 %272, 1
  %285 = icmp eq i64 %284, %270
  br i1 %285, label %286, label %271

286:                                              ; preds = %283
  br i1 %265, label %287, label %385

287:                                              ; preds = %286
  %288 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 3, i32 0
  %289 = zext i32 %118 to i64
  %290 = icmp ult i32 %118, 8
  br i1 %290, label %291, label %310

291:                                              ; preds = %383, %310, %287
  %292 = phi i64 [ 0, %310 ], [ 0, %287 ], [ %319, %383 ]
  %293 = xor i64 %292, -1
  %294 = add nsw i64 %293, %289
  %295 = and i64 %289, 3
  %296 = icmp eq i64 %295, 0
  br i1 %296, label %307, label %297

297:                                              ; preds = %291, %297
  %298 = phi i64 [ %304, %297 ], [ %292, %291 ]
  %299 = phi i64 [ %305, %297 ], [ %295, %291 ]
  %300 = load float, float* %288, align 8
  %301 = getelementptr inbounds float, float* %227, i64 %298
  %302 = load float, float* %301, align 4
  %303 = fmul float %300, %302
  store float %303, float* %301, align 4
  %304 = add nuw nsw i64 %298, 1
  %305 = add i64 %299, -1
  %306 = icmp eq i64 %305, 0
  br i1 %306, label %307, label %297, !llvm.loop !52

307:                                              ; preds = %297, %291
  %308 = phi i64 [ %292, %291 ], [ %304, %297 ]
  %309 = icmp ult i64 %294, 3
  br i1 %309, label %385, label %408

310:                                              ; preds = %287
  %311 = getelementptr float, float* %227, i64 %289
  %312 = getelementptr %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 3, i32 0
  %313 = bitcast float* %312 to i8*
  %314 = getelementptr i8, i8* %313, i64 1
  %315 = icmp ult i8* %226, %314
  %316 = icmp ult float* %288, %311
  %317 = and i1 %315, %316
  br i1 %317, label %291, label %318

318:                                              ; preds = %310
  %319 = and i64 %289, 4294967288
  %320 = add nsw i64 %319, -8
  %321 = lshr exact i64 %320, 3
  %322 = add nuw nsw i64 %321, 1
  %323 = and i64 %322, 1
  %324 = icmp eq i64 %320, 0
  br i1 %324, label %364, label %325

325:                                              ; preds = %318
  %326 = sub nuw nsw i64 %322, %323
  %327 = load float, float* %288, align 8, !alias.scope !53
  %328 = insertelement <4 x float> undef, float %327, i32 0
  %329 = shufflevector <4 x float> %328, <4 x float> undef, <4 x i32> zeroinitializer
  %330 = insertelement <4 x float> undef, float %327, i32 0
  %331 = shufflevector <4 x float> %330, <4 x float> undef, <4 x i32> zeroinitializer
  %332 = load float, float* %288, align 8, !alias.scope !53
  %333 = insertelement <4 x float> undef, float %332, i32 0
  %334 = shufflevector <4 x float> %333, <4 x float> undef, <4 x i32> zeroinitializer
  %335 = insertelement <4 x float> undef, float %332, i32 0
  %336 = shufflevector <4 x float> %335, <4 x float> undef, <4 x i32> zeroinitializer
  br label %337

337:                                              ; preds = %337, %325
  %338 = phi i64 [ 0, %325 ], [ %361, %337 ]
  %339 = phi i64 [ %326, %325 ], [ %362, %337 ]
  %340 = getelementptr inbounds float, float* %227, i64 %338
  %341 = bitcast float* %340 to <4 x float>*
  %342 = load <4 x float>, <4 x float>* %341, align 4, !alias.scope !56, !noalias !53
  %343 = getelementptr inbounds float, float* %340, i64 4
  %344 = bitcast float* %343 to <4 x float>*
  %345 = load <4 x float>, <4 x float>* %344, align 4, !alias.scope !56, !noalias !53
  %346 = fmul <4 x float> %329, %342
  %347 = fmul <4 x float> %331, %345
  %348 = bitcast float* %340 to <4 x float>*
  store <4 x float> %346, <4 x float>* %348, align 4, !alias.scope !56, !noalias !53
  %349 = bitcast float* %343 to <4 x float>*
  store <4 x float> %347, <4 x float>* %349, align 4, !alias.scope !56, !noalias !53
  %350 = or i64 %338, 8
  %351 = getelementptr inbounds float, float* %227, i64 %350
  %352 = bitcast float* %351 to <4 x float>*
  %353 = load <4 x float>, <4 x float>* %352, align 4, !alias.scope !56, !noalias !53
  %354 = getelementptr inbounds float, float* %351, i64 4
  %355 = bitcast float* %354 to <4 x float>*
  %356 = load <4 x float>, <4 x float>* %355, align 4, !alias.scope !56, !noalias !53
  %357 = fmul <4 x float> %334, %353
  %358 = fmul <4 x float> %336, %356
  %359 = bitcast float* %351 to <4 x float>*
  store <4 x float> %357, <4 x float>* %359, align 4, !alias.scope !56, !noalias !53
  %360 = bitcast float* %354 to <4 x float>*
  store <4 x float> %358, <4 x float>* %360, align 4, !alias.scope !56, !noalias !53
  %361 = add i64 %338, 16
  %362 = add i64 %339, -2
  %363 = icmp eq i64 %362, 0
  br i1 %363, label %364, label %337, !llvm.loop !58

364:                                              ; preds = %337, %318
  %365 = phi i64 [ 0, %318 ], [ %361, %337 ]
  %366 = icmp eq i64 %323, 0
  br i1 %366, label %383, label %367

367:                                              ; preds = %364
  %368 = load float, float* %288, align 8, !alias.scope !53
  %369 = insertelement <4 x float> undef, float %368, i32 0
  %370 = shufflevector <4 x float> %369, <4 x float> undef, <4 x i32> zeroinitializer
  %371 = insertelement <4 x float> undef, float %368, i32 0
  %372 = shufflevector <4 x float> %371, <4 x float> undef, <4 x i32> zeroinitializer
  %373 = getelementptr inbounds float, float* %227, i64 %365
  %374 = bitcast float* %373 to <4 x float>*
  %375 = load <4 x float>, <4 x float>* %374, align 4, !alias.scope !56, !noalias !53
  %376 = getelementptr inbounds float, float* %373, i64 4
  %377 = bitcast float* %376 to <4 x float>*
  %378 = load <4 x float>, <4 x float>* %377, align 4, !alias.scope !56, !noalias !53
  %379 = fmul <4 x float> %370, %375
  %380 = fmul <4 x float> %372, %378
  %381 = bitcast float* %373 to <4 x float>*
  store <4 x float> %379, <4 x float>* %381, align 4, !alias.scope !56, !noalias !53
  %382 = bitcast float* %376 to <4 x float>*
  store <4 x float> %380, <4 x float>* %382, align 4, !alias.scope !56, !noalias !53
  br label %383

383:                                              ; preds = %364, %367
  %384 = icmp eq i64 %319, %289
  br i1 %384, label %385, label %291

385:                                              ; preds = %307, %408, %383, %263, %286
  %386 = icmp eq %struct.TfLiteTensor* %9, null
  br i1 %386, label %390, label %387

387:                                              ; preds = %385
  %388 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %9, i64 0, i32 1, i32 0
  %389 = load i32*, i32** %388, align 8
  br label %390

390:                                              ; preds = %385, %387
  %391 = phi i32* [ %389, %387 ], [ null, %385 ]
  %392 = icmp eq %struct.TfLiteTensor* %12, null
  br i1 %392, label %400, label %393

393:                                              ; preds = %390
  %394 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %12, i64 0, i32 1
  %395 = bitcast %union.TfLitePtrUnion* %394 to float**
  %396 = load float*, float** %395, align 8
  %397 = getelementptr inbounds %"struct.tflite::ops::builtin::fully_connected::OpData", %"struct.tflite::ops::builtin::fully_connected::OpData"* %3, i64 0, i32 5
  %398 = call %"class.tflite::CpuBackendContext"* @_ZN6tflite17CpuBackendContext14GetFromContextEP13TfLiteContext(%struct.TfLiteContext* %0) #19
  call void @_ZN6tflite12tensor_utils35MatrixBatchVectorMultiplyAccumulateEPKaiiS2_PKfiPfS4_PKiPiS8_PbPNS_17CpuBackendContextE(i8* %258, i32 %120, i32 %117, i8* %251, float* %227, i32 %118, float* %396, float* null, i32* %243, i32* %391, i32* %244, i8* %397, %"class.tflite::CpuBackendContext"* %398) #19
  %399 = load float*, float** %395, align 8
  br label %403

400:                                              ; preds = %390
  %401 = getelementptr inbounds %"struct.tflite::ops::builtin::fully_connected::OpData", %"struct.tflite::ops::builtin::fully_connected::OpData"* %3, i64 0, i32 5
  %402 = call %"class.tflite::CpuBackendContext"* @_ZN6tflite17CpuBackendContext14GetFromContextEP13TfLiteContext(%struct.TfLiteContext* %0) #19
  call void @_ZN6tflite12tensor_utils35MatrixBatchVectorMultiplyAccumulateEPKaiiS2_PKfiPfS4_PKiPiS8_PbPNS_17CpuBackendContextE(i8* %258, i32 %120, i32 %117, i8* %251, float* %227, i32 %118, float* null, float* null, i32* %243, i32* %391, i32* %244, i8* %401, %"class.tflite::CpuBackendContext"* %402) #19
  br label %403

403:                                              ; preds = %400, %393
  %404 = phi float* [ %399, %393 ], [ null, %400 ]
  %405 = getelementptr inbounds %struct.TfLiteFullyConnectedParams, %struct.TfLiteFullyConnectedParams* %2, i64 0, i32 0
  %406 = mul nsw i32 %120, %118
  %407 = load i32, i32* %405, align 4
  call void @_ZN6tflite12tensor_utils23ApplyActivationToVectorEPKfi21TfLiteFusedActivationPf(float* %404, i32 %406, i32 %407, float* %404)
  br label %431

408:                                              ; preds = %307, %408
  %409 = phi i64 [ %429, %408 ], [ %308, %307 ]
  %410 = load float, float* %288, align 8
  %411 = getelementptr inbounds float, float* %227, i64 %409
  %412 = load float, float* %411, align 4
  %413 = fmul float %410, %412
  store float %413, float* %411, align 4
  %414 = add nuw nsw i64 %409, 1
  %415 = load float, float* %288, align 8
  %416 = getelementptr inbounds float, float* %227, i64 %414
  %417 = load float, float* %416, align 4
  %418 = fmul float %415, %417
  store float %418, float* %416, align 4
  %419 = add nuw nsw i64 %409, 2
  %420 = load float, float* %288, align 8
  %421 = getelementptr inbounds float, float* %227, i64 %419
  %422 = load float, float* %421, align 4
  %423 = fmul float %420, %422
  store float %423, float* %421, align 4
  %424 = add nuw nsw i64 %409, 3
  %425 = load float, float* %288, align 8
  %426 = getelementptr inbounds float, float* %227, i64 %424
  %427 = load float, float* %426, align 4
  %428 = fmul float %425, %427
  store float %428, float* %426, align 4
  %429 = add nuw nsw i64 %409, 4
  %430 = icmp eq i64 %429, %289
  br i1 %430, label %385, label %408, !llvm.loop !59

431:                                              ; preds = %403, %213
  ret i32 0

432:                                              ; preds = %152, %155
  %433 = add nuw nsw i64 %153, 4
  %434 = add i64 %154, -4
  %435 = icmp eq i64 %434, 0
  br i1 %435, label %184, label %152
}

declare zeroext i1 @_ZN6tflite12tensor_utils12IsZeroVectorEPKfi(float*, i32) local_unnamed_addr #5

declare void @_ZN6tflite12tensor_utils35MatrixBatchVectorMultiplyAccumulateEPKaiiS2_PKfiPfS4_PKiPiS8_PbPNS_17CpuBackendContextE(i8*, i32, i32, i8*, float*, i32, float*, float*, i32*, i32*, i32*, i8*, %"class.tflite::CpuBackendContext"*) local_unnamed_addr #5

declare %"class.tflite::CpuBackendContext"* @_ZN6tflite17CpuBackendContext14GetFromContextEP13TfLiteContext(%struct.TfLiteContext*) local_unnamed_addr #5

; Function Attrs: norecurse nounwind readnone ssp uwtable
define hidden %struct.TfLiteRegistration* @_ZN6tflite3ops7builtin28Register_FULLY_CONNECTED_REFEv() local_unnamed_addr #6 {
  ret %struct.TfLiteRegistration* bitcast ({ i8* (%struct.TfLiteContext*, i8*, i64)*, void (%struct.TfLiteContext*, i8*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteNode*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteNode*)*, i8* (%struct.TfLiteContext*, %struct.TfLiteNode*)*, i32, i8*, i32 }* @_ZZN6tflite3ops7builtin28Register_FULLY_CONNECTED_REFEvE1r to %struct.TfLiteRegistration*)
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i32 @_ZN6tflite3ops7builtin15fully_connected7PrepareILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode(%struct.TfLiteContext*, %struct.TfLiteNode*) #1 comdat {
  %3 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 5
  %4 = bitcast i8** %3 to %struct.TfLiteFullyConnectedParams**
  %5 = load %struct.TfLiteFullyConnectedParams*, %struct.TfLiteFullyConnectedParams** %4, align 8
  %6 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 0
  %7 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %6, align 8
  %8 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %7, i64 0, i32 1, i64 1
  %9 = load i32, i32* %8, align 4
  %10 = icmp slt i32 %9, 0
  br i1 %10, label %16, label %11

11:                                               ; preds = %2
  %12 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %13 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %12, align 8
  %14 = sext i32 %9 to i64
  %15 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %13, i64 %14
  br label %16

16:                                               ; preds = %2, %11
  %17 = phi %struct.TfLiteTensor* [ %15, %11 ], [ null, %2 ]
  %18 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %7, i64 0, i32 1, i64 0
  %19 = load i32, i32* %18, align 4
  %20 = icmp slt i32 %19, 0
  br i1 %20, label %26, label %21

21:                                               ; preds = %16
  %22 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %23 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %22, align 8
  %24 = sext i32 %19 to i64
  %25 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %23, i64 %24
  br label %26

26:                                               ; preds = %16, %21
  %27 = phi %struct.TfLiteTensor* [ %25, %21 ], [ null, %16 ]
  %28 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %17, i64 0, i32 0
  %29 = load i32, i32* %28, align 8
  switch i32 %29, label %34 [
    i32 9, label %30
    i32 3, label %30
  ]

30:                                               ; preds = %26, %26
  %31 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %27, i64 0, i32 0
  %32 = load i32, i32* %31, align 8
  %33 = icmp eq i32 %32, 1
  br i1 %33, label %41, label %34

34:                                               ; preds = %26, %30
  %35 = getelementptr inbounds %struct.TfLiteFullyConnectedParams, %struct.TfLiteFullyConnectedParams* %5, i64 0, i32 0
  %36 = load i32, i32* %35, align 4
  %37 = icmp ult i32 %36, 4
  br i1 %37, label %41, label %38

38:                                               ; preds = %34
  %39 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %40 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %39, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %40(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([72 x i8], [72 x i8]* @.str.3, i64 0, i64 0), i32 316, i8* getelementptr inbounds ([163 x i8], [163 x i8]* @.str.30, i64 0, i64 0)) #19
  br label %43

41:                                               ; preds = %34, %30
  %42 = tail call i32 @_ZN6tflite3ops7builtin15fully_connected11PrepareImplEP13TfLiteContextP10TfLiteNode(%struct.TfLiteContext* %0, %struct.TfLiteNode* %1)
  br label %43

43:                                               ; preds = %41, %38
  %44 = phi i32 [ %42, %41 ], [ 1, %38 ]
  ret i32 %44
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i32 @_ZN6tflite3ops7builtin15fully_connected4EvalILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode(%struct.TfLiteContext*, %struct.TfLiteNode*) #1 comdat {
  %3 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 5
  %4 = bitcast i8** %3 to %struct.TfLiteFullyConnectedParams**
  %5 = load %struct.TfLiteFullyConnectedParams*, %struct.TfLiteFullyConnectedParams** %4, align 8
  %6 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 4
  %7 = bitcast i8** %6 to %"struct.tflite::ops::builtin::fully_connected::OpData"**
  %8 = load %"struct.tflite::ops::builtin::fully_connected::OpData"*, %"struct.tflite::ops::builtin::fully_connected::OpData"** %7, align 8
  %9 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 0
  %10 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %9, align 8
  %11 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 0
  %12 = load i32, i32* %11, align 4
  %13 = icmp slt i32 %12, 0
  br i1 %13, label %19, label %14

14:                                               ; preds = %2
  %15 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %16 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %15, align 8
  %17 = sext i32 %12 to i64
  %18 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %16, i64 %17
  br label %19

19:                                               ; preds = %2, %14
  %20 = phi %struct.TfLiteTensor* [ %18, %14 ], [ null, %2 ]
  %21 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 1
  %22 = load i32, i32* %21, align 4
  %23 = icmp slt i32 %22, 0
  br i1 %23, label %29, label %24

24:                                               ; preds = %19
  %25 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %26 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %25, align 8
  %27 = sext i32 %22 to i64
  %28 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %26, i64 %27
  br label %29

29:                                               ; preds = %19, %24
  %30 = phi %struct.TfLiteTensor* [ %28, %24 ], [ null, %19 ]
  %31 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 0
  %32 = load i32, i32* %31, align 4
  %33 = icmp eq i32 %32, 3
  br i1 %33, label %34, label %43

34:                                               ; preds = %29
  %35 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 2
  %36 = load i32, i32* %35, align 4
  %37 = icmp slt i32 %36, 0
  br i1 %37, label %43, label %38

38:                                               ; preds = %34
  %39 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %40 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %39, align 8
  %41 = sext i32 %36 to i64
  %42 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %40, i64 %41
  br label %43

43:                                               ; preds = %38, %34, %29
  %44 = phi %struct.TfLiteTensor* [ null, %29 ], [ %42, %38 ], [ null, %34 ]
  %45 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 1
  %46 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %45, align 8
  %47 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %46, i64 0, i32 1, i64 0
  %48 = load i32, i32* %47, align 4
  %49 = icmp slt i32 %48, 0
  br i1 %49, label %55, label %50

50:                                               ; preds = %43
  %51 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %52 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %51, align 8
  %53 = sext i32 %48 to i64
  %54 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %52, i64 %53
  br label %55

55:                                               ; preds = %43, %50
  %56 = phi %struct.TfLiteTensor* [ %54, %50 ], [ null, %43 ]
  %57 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %30, i64 0, i32 0
  %58 = load i32, i32* %57, align 8
  switch i32 %58, label %90 [
    i32 1, label %59
    i32 3, label %61
    i32 9, label %81
  ]

59:                                               ; preds = %55
  %60 = tail call i32 @_ZN6tflite3ops7builtin15fully_connected9EvalFloatILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_(%struct.TfLiteContext* %0, %struct.TfLiteNode* %1, %struct.TfLiteFullyConnectedParams* %5, %"struct.tflite::ops::builtin::fully_connected::OpData"* %8, %struct.TfLiteTensor* %20, %struct.TfLiteTensor* %30, %struct.TfLiteTensor* %44, %struct.TfLiteTensor* %56)
  br label %94

61:                                               ; preds = %55
  %62 = getelementptr inbounds %struct.TfLiteFullyConnectedParams, %struct.TfLiteFullyConnectedParams* %5, i64 0, i32 1
  %63 = load i32, i32* %62, align 4
  switch i32 %63, label %78 [
    i32 1, label %64
    i32 0, label %76
  ]

64:                                               ; preds = %61
  %65 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %46, i64 0, i32 1, i64 1
  %66 = load i32, i32* %65, align 4
  %67 = icmp slt i32 %66, 0
  br i1 %67, label %73, label %68

68:                                               ; preds = %64
  %69 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %70 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %69, align 8
  %71 = sext i32 %66 to i64
  %72 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %70, i64 %71
  br label %73

73:                                               ; preds = %64, %68
  %74 = phi %struct.TfLiteTensor* [ %72, %68 ], [ null, %64 ]
  %75 = tail call i32 @_ZN6tflite3ops7builtin15fully_connected21EvalShuffledQuantizedILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_SH_(%struct.TfLiteContext* %0, %struct.TfLiteNode* %1, %struct.TfLiteFullyConnectedParams* %5, %"struct.tflite::ops::builtin::fully_connected::OpData"* %8, %struct.TfLiteTensor* %20, %struct.TfLiteTensor* %30, %struct.TfLiteTensor* %44, %struct.TfLiteTensor* %56, %struct.TfLiteTensor* %74)
  br label %94

76:                                               ; preds = %61
  %77 = tail call i32 @_ZN6tflite3ops7builtin15fully_connected13EvalQuantizedILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_(%struct.TfLiteContext* %0, %struct.TfLiteNode* %1, %struct.TfLiteFullyConnectedParams* %5, %"struct.tflite::ops::builtin::fully_connected::OpData"* %8, %struct.TfLiteTensor* %20, %struct.TfLiteTensor* %30, %struct.TfLiteTensor* %44, %struct.TfLiteTensor* %56)
  br label %94

78:                                               ; preds = %61
  %79 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %80 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %79, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %80(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([41 x i8], [41 x i8]* @.str.31, i64 0, i64 0)) #19
  br label %94

81:                                               ; preds = %55
  %82 = getelementptr inbounds %struct.TfLiteFullyConnectedParams, %struct.TfLiteFullyConnectedParams* %5, i64 0, i32 1
  %83 = load i32, i32* %82, align 4
  %84 = icmp eq i32 %83, 0
  br i1 %84, label %85, label %87

85:                                               ; preds = %81
  %86 = tail call i32 @_ZN6tflite3ops7builtin15fully_connected13EvalQuantizedILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_(%struct.TfLiteContext* %0, %struct.TfLiteNode* %1, %struct.TfLiteFullyConnectedParams* %5, %"struct.tflite::ops::builtin::fully_connected::OpData"* %8, %struct.TfLiteTensor* %20, %struct.TfLiteTensor* %30, %struct.TfLiteTensor* %44, %struct.TfLiteTensor* %56)
  br label %94

87:                                               ; preds = %81
  %88 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %89 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %88, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %89(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([41 x i8], [41 x i8]* @.str.31, i64 0, i64 0)) #19
  br label %94

90:                                               ; preds = %55
  %91 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %92 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %91, align 8
  %93 = tail call i8* @TfLiteTypeGetName(i32 %58) #19
  tail call void (%struct.TfLiteContext*, i8*, ...) %92(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([45 x i8], [45 x i8]* @.str.32, i64 0, i64 0), i8* %93) #19
  br label %94

94:                                               ; preds = %90, %87, %85, %78, %76, %73, %59
  %95 = phi i32 [ 1, %90 ], [ %86, %85 ], [ 1, %87 ], [ %75, %73 ], [ %77, %76 ], [ 1, %78 ], [ %60, %59 ]
  ret i32 %95
}

; Function Attrs: norecurse nounwind readnone ssp uwtable
define hidden %struct.TfLiteRegistration* @_ZN6tflite3ops7builtin36Register_FULLY_CONNECTED_GENERIC_OPTEv() local_unnamed_addr #6 {
  ret %struct.TfLiteRegistration* bitcast ({ i8* (%struct.TfLiteContext*, i8*, i64)*, void (%struct.TfLiteContext*, i8*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteNode*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteNode*)*, i8* (%struct.TfLiteContext*, %struct.TfLiteNode*)*, i32, i8*, i32 }* @_ZZN6tflite3ops7builtin36Register_FULLY_CONNECTED_GENERIC_OPTEvE1r to %struct.TfLiteRegistration*)
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i32 @_ZN6tflite3ops7builtin15fully_connected7PrepareILNS2_10KernelTypeE1EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode(%struct.TfLiteContext*, %struct.TfLiteNode*) #1 comdat {
  %3 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 5
  %4 = bitcast i8** %3 to %struct.TfLiteFullyConnectedParams**
  %5 = load %struct.TfLiteFullyConnectedParams*, %struct.TfLiteFullyConnectedParams** %4, align 8
  %6 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 0
  %7 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %6, align 8
  %8 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %7, i64 0, i32 1, i64 1
  %9 = load i32, i32* %8, align 4
  %10 = icmp slt i32 %9, 0
  br i1 %10, label %16, label %11

11:                                               ; preds = %2
  %12 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %13 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %12, align 8
  %14 = sext i32 %9 to i64
  %15 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %13, i64 %14
  br label %16

16:                                               ; preds = %2, %11
  %17 = phi %struct.TfLiteTensor* [ %15, %11 ], [ null, %2 ]
  %18 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %7, i64 0, i32 1, i64 0
  %19 = load i32, i32* %18, align 4
  %20 = icmp slt i32 %19, 0
  br i1 %20, label %26, label %21

21:                                               ; preds = %16
  %22 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %23 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %22, align 8
  %24 = sext i32 %19 to i64
  %25 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %23, i64 %24
  br label %26

26:                                               ; preds = %16, %21
  %27 = phi %struct.TfLiteTensor* [ %25, %21 ], [ null, %16 ]
  %28 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %17, i64 0, i32 0
  %29 = load i32, i32* %28, align 8
  switch i32 %29, label %34 [
    i32 9, label %30
    i32 3, label %30
  ]

30:                                               ; preds = %26, %26
  %31 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %27, i64 0, i32 0
  %32 = load i32, i32* %31, align 8
  %33 = icmp eq i32 %32, 1
  br i1 %33, label %41, label %34

34:                                               ; preds = %26, %30
  %35 = getelementptr inbounds %struct.TfLiteFullyConnectedParams, %struct.TfLiteFullyConnectedParams* %5, i64 0, i32 0
  %36 = load i32, i32* %35, align 4
  %37 = icmp ult i32 %36, 4
  br i1 %37, label %41, label %38

38:                                               ; preds = %34
  %39 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %40 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %39, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %40(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([72 x i8], [72 x i8]* @.str.3, i64 0, i64 0), i32 316, i8* getelementptr inbounds ([163 x i8], [163 x i8]* @.str.30, i64 0, i64 0)) #19
  br label %43

41:                                               ; preds = %34, %30
  %42 = tail call i32 @_ZN6tflite3ops7builtin15fully_connected11PrepareImplEP13TfLiteContextP10TfLiteNode(%struct.TfLiteContext* %0, %struct.TfLiteNode* %1)
  br label %43

43:                                               ; preds = %41, %38
  %44 = phi i32 [ %42, %41 ], [ 1, %38 ]
  ret i32 %44
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i32 @_ZN6tflite3ops7builtin15fully_connected4EvalILNS2_10KernelTypeE1EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode(%struct.TfLiteContext*, %struct.TfLiteNode*) #1 comdat {
  %3 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 5
  %4 = bitcast i8** %3 to %struct.TfLiteFullyConnectedParams**
  %5 = load %struct.TfLiteFullyConnectedParams*, %struct.TfLiteFullyConnectedParams** %4, align 8
  %6 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 4
  %7 = bitcast i8** %6 to %"struct.tflite::ops::builtin::fully_connected::OpData"**
  %8 = load %"struct.tflite::ops::builtin::fully_connected::OpData"*, %"struct.tflite::ops::builtin::fully_connected::OpData"** %7, align 8
  %9 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 0
  %10 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %9, align 8
  %11 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 0
  %12 = load i32, i32* %11, align 4
  %13 = icmp slt i32 %12, 0
  br i1 %13, label %19, label %14

14:                                               ; preds = %2
  %15 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %16 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %15, align 8
  %17 = sext i32 %12 to i64
  %18 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %16, i64 %17
  br label %19

19:                                               ; preds = %2, %14
  %20 = phi %struct.TfLiteTensor* [ %18, %14 ], [ null, %2 ]
  %21 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 1
  %22 = load i32, i32* %21, align 4
  %23 = icmp slt i32 %22, 0
  br i1 %23, label %29, label %24

24:                                               ; preds = %19
  %25 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %26 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %25, align 8
  %27 = sext i32 %22 to i64
  %28 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %26, i64 %27
  br label %29

29:                                               ; preds = %19, %24
  %30 = phi %struct.TfLiteTensor* [ %28, %24 ], [ null, %19 ]
  %31 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 0
  %32 = load i32, i32* %31, align 4
  %33 = icmp eq i32 %32, 3
  br i1 %33, label %34, label %43

34:                                               ; preds = %29
  %35 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 2
  %36 = load i32, i32* %35, align 4
  %37 = icmp slt i32 %36, 0
  br i1 %37, label %43, label %38

38:                                               ; preds = %34
  %39 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %40 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %39, align 8
  %41 = sext i32 %36 to i64
  %42 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %40, i64 %41
  br label %43

43:                                               ; preds = %38, %34, %29
  %44 = phi %struct.TfLiteTensor* [ null, %29 ], [ %42, %38 ], [ null, %34 ]
  %45 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 1
  %46 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %45, align 8
  %47 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %46, i64 0, i32 1, i64 0
  %48 = load i32, i32* %47, align 4
  %49 = icmp slt i32 %48, 0
  br i1 %49, label %55, label %50

50:                                               ; preds = %43
  %51 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %52 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %51, align 8
  %53 = sext i32 %48 to i64
  %54 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %52, i64 %53
  br label %55

55:                                               ; preds = %43, %50
  %56 = phi %struct.TfLiteTensor* [ %54, %50 ], [ null, %43 ]
  %57 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %30, i64 0, i32 0
  %58 = load i32, i32* %57, align 8
  switch i32 %58, label %90 [
    i32 1, label %59
    i32 3, label %61
    i32 9, label %81
  ]

59:                                               ; preds = %55
  %60 = tail call i32 @_ZN6tflite3ops7builtin15fully_connected9EvalFloatILNS2_10KernelTypeE1EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_(%struct.TfLiteContext* %0, %struct.TfLiteNode* %1, %struct.TfLiteFullyConnectedParams* %5, %"struct.tflite::ops::builtin::fully_connected::OpData"* %8, %struct.TfLiteTensor* %20, %struct.TfLiteTensor* %30, %struct.TfLiteTensor* %44, %struct.TfLiteTensor* %56)
  br label %94

61:                                               ; preds = %55
  %62 = getelementptr inbounds %struct.TfLiteFullyConnectedParams, %struct.TfLiteFullyConnectedParams* %5, i64 0, i32 1
  %63 = load i32, i32* %62, align 4
  switch i32 %63, label %78 [
    i32 1, label %64
    i32 0, label %76
  ]

64:                                               ; preds = %61
  %65 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %46, i64 0, i32 1, i64 1
  %66 = load i32, i32* %65, align 4
  %67 = icmp slt i32 %66, 0
  br i1 %67, label %73, label %68

68:                                               ; preds = %64
  %69 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %70 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %69, align 8
  %71 = sext i32 %66 to i64
  %72 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %70, i64 %71
  br label %73

73:                                               ; preds = %64, %68
  %74 = phi %struct.TfLiteTensor* [ %72, %68 ], [ null, %64 ]
  %75 = tail call i32 @_ZN6tflite3ops7builtin15fully_connected21EvalShuffledQuantizedILNS2_10KernelTypeE1EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_SH_(%struct.TfLiteContext* %0, %struct.TfLiteNode* %1, %struct.TfLiteFullyConnectedParams* %5, %"struct.tflite::ops::builtin::fully_connected::OpData"* %8, %struct.TfLiteTensor* %20, %struct.TfLiteTensor* %30, %struct.TfLiteTensor* %44, %struct.TfLiteTensor* %56, %struct.TfLiteTensor* %74)
  br label %94

76:                                               ; preds = %61
  %77 = tail call i32 @_ZN6tflite3ops7builtin15fully_connected13EvalQuantizedILNS2_10KernelTypeE1EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_(%struct.TfLiteContext* %0, %struct.TfLiteNode* %1, %struct.TfLiteFullyConnectedParams* %5, %"struct.tflite::ops::builtin::fully_connected::OpData"* %8, %struct.TfLiteTensor* %20, %struct.TfLiteTensor* %30, %struct.TfLiteTensor* %44, %struct.TfLiteTensor* %56)
  br label %94

78:                                               ; preds = %61
  %79 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %80 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %79, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %80(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([41 x i8], [41 x i8]* @.str.31, i64 0, i64 0)) #19
  br label %94

81:                                               ; preds = %55
  %82 = getelementptr inbounds %struct.TfLiteFullyConnectedParams, %struct.TfLiteFullyConnectedParams* %5, i64 0, i32 1
  %83 = load i32, i32* %82, align 4
  %84 = icmp eq i32 %83, 0
  br i1 %84, label %85, label %87

85:                                               ; preds = %81
  %86 = tail call i32 @_ZN6tflite3ops7builtin15fully_connected13EvalQuantizedILNS2_10KernelTypeE1EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_(%struct.TfLiteContext* %0, %struct.TfLiteNode* %1, %struct.TfLiteFullyConnectedParams* %5, %"struct.tflite::ops::builtin::fully_connected::OpData"* %8, %struct.TfLiteTensor* %20, %struct.TfLiteTensor* %30, %struct.TfLiteTensor* %44, %struct.TfLiteTensor* %56)
  br label %94

87:                                               ; preds = %81
  %88 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %89 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %88, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %89(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([41 x i8], [41 x i8]* @.str.31, i64 0, i64 0)) #19
  br label %94

90:                                               ; preds = %55
  %91 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %92 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %91, align 8
  %93 = tail call i8* @TfLiteTypeGetName(i32 %58) #19
  tail call void (%struct.TfLiteContext*, i8*, ...) %92(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([45 x i8], [45 x i8]* @.str.32, i64 0, i64 0), i8* %93) #19
  br label %94

94:                                               ; preds = %90, %87, %85, %78, %76, %73, %59
  %95 = phi i32 [ 1, %90 ], [ %86, %85 ], [ 1, %87 ], [ %75, %73 ], [ %77, %76 ], [ 1, %78 ], [ %60, %59 ]
  ret i32 %95
}

; Function Attrs: norecurse nounwind readnone ssp uwtable
define hidden %struct.TfLiteRegistration* @_ZN6tflite3ops7builtin28Register_FULLY_CONNECTED_PIEEv() local_unnamed_addr #6 {
  ret %struct.TfLiteRegistration* bitcast ({ i8* (%struct.TfLiteContext*, i8*, i64)*, void (%struct.TfLiteContext*, i8*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteNode*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteNode*)*, i8* (%struct.TfLiteContext*, %struct.TfLiteNode*)*, i32, i8*, i32 }* @_ZZN6tflite3ops7builtin28Register_FULLY_CONNECTED_PIEEvE1r to %struct.TfLiteRegistration*)
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i32 @_ZN6tflite3ops7builtin15fully_connected7PrepareILNS2_10KernelTypeE2EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode(%struct.TfLiteContext*, %struct.TfLiteNode*) #1 comdat {
  %3 = tail call i32 @_ZN6tflite3ops7builtin15fully_connected11PrepareImplEP13TfLiteContextP10TfLiteNode(%struct.TfLiteContext* %0, %struct.TfLiteNode* %1)
  ret i32 %3
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i32 @_ZN6tflite3ops7builtin15fully_connected4EvalILNS2_10KernelTypeE2EEE12TfLiteStatusP13TfLiteContextP10TfLiteNode(%struct.TfLiteContext*, %struct.TfLiteNode*) #1 comdat {
  %3 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 5
  %4 = bitcast i8** %3 to %struct.TfLiteFullyConnectedParams**
  %5 = load %struct.TfLiteFullyConnectedParams*, %struct.TfLiteFullyConnectedParams** %4, align 8
  %6 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 4
  %7 = bitcast i8** %6 to %"struct.tflite::ops::builtin::fully_connected::OpData"**
  %8 = load %"struct.tflite::ops::builtin::fully_connected::OpData"*, %"struct.tflite::ops::builtin::fully_connected::OpData"** %7, align 8
  %9 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 0
  %10 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %9, align 8
  %11 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 0
  %12 = load i32, i32* %11, align 4
  %13 = icmp slt i32 %12, 0
  br i1 %13, label %19, label %14

14:                                               ; preds = %2
  %15 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %16 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %15, align 8
  %17 = sext i32 %12 to i64
  %18 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %16, i64 %17
  br label %19

19:                                               ; preds = %2, %14
  %20 = phi %struct.TfLiteTensor* [ %18, %14 ], [ null, %2 ]
  %21 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 1
  %22 = load i32, i32* %21, align 4
  %23 = icmp slt i32 %22, 0
  br i1 %23, label %29, label %24

24:                                               ; preds = %19
  %25 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %26 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %25, align 8
  %27 = sext i32 %22 to i64
  %28 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %26, i64 %27
  br label %29

29:                                               ; preds = %19, %24
  %30 = phi %struct.TfLiteTensor* [ %28, %24 ], [ null, %19 ]
  %31 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 0
  %32 = load i32, i32* %31, align 4
  %33 = icmp eq i32 %32, 3
  br i1 %33, label %34, label %43

34:                                               ; preds = %29
  %35 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %10, i64 0, i32 1, i64 2
  %36 = load i32, i32* %35, align 4
  %37 = icmp slt i32 %36, 0
  br i1 %37, label %43, label %38

38:                                               ; preds = %34
  %39 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %40 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %39, align 8
  %41 = sext i32 %36 to i64
  %42 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %40, i64 %41
  br label %43

43:                                               ; preds = %38, %34, %29
  %44 = phi %struct.TfLiteTensor* [ null, %29 ], [ %42, %38 ], [ null, %34 ]
  %45 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 1
  %46 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %45, align 8
  %47 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %46, i64 0, i32 1, i64 0
  %48 = load i32, i32* %47, align 4
  %49 = icmp slt i32 %48, 0
  br i1 %49, label %55, label %50

50:                                               ; preds = %43
  %51 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %52 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %51, align 8
  %53 = sext i32 %48 to i64
  %54 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %52, i64 %53
  br label %55

55:                                               ; preds = %43, %50
  %56 = phi %struct.TfLiteTensor* [ %54, %50 ], [ null, %43 ]
  %57 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %30, i64 0, i32 0
  %58 = load i32, i32* %57, align 8
  switch i32 %58, label %90 [
    i32 1, label %59
    i32 3, label %61
    i32 9, label %81
  ]

59:                                               ; preds = %55
  %60 = tail call i32 @_ZN6tflite3ops7builtin15fully_connected7EvalPieEP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_(%struct.TfLiteContext* undef, %struct.TfLiteNode* undef, %struct.TfLiteFullyConnectedParams* %5, %"struct.tflite::ops::builtin::fully_connected::OpData"* undef, %struct.TfLiteTensor* %20, %struct.TfLiteTensor* %30, %struct.TfLiteTensor* %44, %struct.TfLiteTensor* %56) #19
  br label %94

61:                                               ; preds = %55
  %62 = getelementptr inbounds %struct.TfLiteFullyConnectedParams, %struct.TfLiteFullyConnectedParams* %5, i64 0, i32 1
  %63 = load i32, i32* %62, align 4
  switch i32 %63, label %78 [
    i32 1, label %64
    i32 0, label %76
  ]

64:                                               ; preds = %61
  %65 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %46, i64 0, i32 1, i64 1
  %66 = load i32, i32* %65, align 4
  %67 = icmp slt i32 %66, 0
  br i1 %67, label %73, label %68

68:                                               ; preds = %64
  %69 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %70 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %69, align 8
  %71 = sext i32 %66 to i64
  %72 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %70, i64 %71
  br label %73

73:                                               ; preds = %64, %68
  %74 = phi %struct.TfLiteTensor* [ %72, %68 ], [ null, %64 ]
  %75 = tail call i32 @_ZN6tflite3ops7builtin15fully_connected21EvalShuffledQuantizedILNS2_10KernelTypeE2EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_SH_(%struct.TfLiteContext* %0, %struct.TfLiteNode* %1, %struct.TfLiteFullyConnectedParams* %5, %"struct.tflite::ops::builtin::fully_connected::OpData"* %8, %struct.TfLiteTensor* %20, %struct.TfLiteTensor* %30, %struct.TfLiteTensor* %44, %struct.TfLiteTensor* %56, %struct.TfLiteTensor* %74)
  br label %94

76:                                               ; preds = %61
  %77 = tail call i32 @_ZN6tflite3ops7builtin15fully_connected13EvalQuantizedILNS2_10KernelTypeE2EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_(%struct.TfLiteContext* %0, %struct.TfLiteNode* %1, %struct.TfLiteFullyConnectedParams* %5, %"struct.tflite::ops::builtin::fully_connected::OpData"* %8, %struct.TfLiteTensor* %20, %struct.TfLiteTensor* %30, %struct.TfLiteTensor* %44, %struct.TfLiteTensor* %56)
  br label %94

78:                                               ; preds = %61
  %79 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %80 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %79, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %80(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([41 x i8], [41 x i8]* @.str.31, i64 0, i64 0)) #19
  br label %94

81:                                               ; preds = %55
  %82 = getelementptr inbounds %struct.TfLiteFullyConnectedParams, %struct.TfLiteFullyConnectedParams* %5, i64 0, i32 1
  %83 = load i32, i32* %82, align 4
  %84 = icmp eq i32 %83, 0
  br i1 %84, label %85, label %87

85:                                               ; preds = %81
  %86 = tail call i32 @_ZN6tflite3ops7builtin15fully_connected13EvalQuantizedILNS2_10KernelTypeE2EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_(%struct.TfLiteContext* %0, %struct.TfLiteNode* %1, %struct.TfLiteFullyConnectedParams* %5, %"struct.tflite::ops::builtin::fully_connected::OpData"* %8, %struct.TfLiteTensor* %20, %struct.TfLiteTensor* %30, %struct.TfLiteTensor* %44, %struct.TfLiteTensor* %56)
  br label %94

87:                                               ; preds = %81
  %88 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %89 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %88, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %89(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([41 x i8], [41 x i8]* @.str.31, i64 0, i64 0)) #19
  br label %94

90:                                               ; preds = %55
  %91 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %92 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %91, align 8
  %93 = tail call i8* @TfLiteTypeGetName(i32 %58) #19
  tail call void (%struct.TfLiteContext*, i8*, ...) %92(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([45 x i8], [45 x i8]* @.str.32, i64 0, i64 0), i8* %93) #19
  br label %94

94:                                               ; preds = %90, %87, %85, %78, %76, %73, %59
  %95 = phi i32 [ 1, %90 ], [ %86, %85 ], [ 1, %87 ], [ %75, %73 ], [ %77, %76 ], [ 1, %78 ], [ 0, %59 ]
  ret i32 %95
}

; Function Attrs: norecurse nounwind readnone ssp uwtable
define hidden %struct.TfLiteRegistration* @_ZN6tflite3ops7builtin24Register_FULLY_CONNECTEDEv() local_unnamed_addr #6 {
  ret %struct.TfLiteRegistration* bitcast ({ i8* (%struct.TfLiteContext*, i8*, i64)*, void (%struct.TfLiteContext*, i8*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteNode*)*, i32 (%struct.TfLiteContext*, %struct.TfLiteNode*)*, i8* (%struct.TfLiteContext*, %struct.TfLiteNode*)*, i32, i8*, i32 }* @_ZZN6tflite3ops7builtin36Register_FULLY_CONNECTED_GENERIC_OPTEvE1r to %struct.TfLiteRegistration*)
}

declare i8* @TfLiteTypeGetName(i32) local_unnamed_addr #5

; Function Attrs: argmemonly nounwind
declare void @llvm.memcpy.p0i8.p0i8.i64(i8* nocapture writeonly, i8* nocapture readonly, i64, i1 immarg) #0

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN5Eigen8internal21dense_assignment_loopINS0_31generic_dense_assignment_kernelINS0_9evaluatorINS_12ArrayWrapperINS_3MapINS_6MatrixIfLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEEEEEENS3_INS_12CwiseUnaryOpINS0_14scalar_tanh_opIfEEKSB_EEEENS0_9assign_opIffEELi0EEELi3ELi0EE3runERSL_(%"class.Eigen::internal::generic_dense_assignment_kernel"* dereferenceable(32)) local_unnamed_addr #7 comdat align 2 {
  %2 = getelementptr inbounds %"class.Eigen::internal::generic_dense_assignment_kernel", %"class.Eigen::internal::generic_dense_assignment_kernel"* %0, i64 0, i32 3
  %3 = bitcast %"class.Eigen::ArrayWrapper"** %2 to %"struct.Eigen::EigenBase.33"**
  %4 = load %"struct.Eigen::EigenBase.33"*, %"struct.Eigen::EigenBase.33"** %3, align 8
  %5 = getelementptr inbounds %"struct.Eigen::EigenBase.33", %"struct.Eigen::EigenBase.33"* %4, i64 8
  %6 = bitcast %"struct.Eigen::EigenBase.33"* %5 to i64*
  %7 = load i64, i64* %6, align 8
  %8 = bitcast %"struct.Eigen::EigenBase.33"* %4 to i64*
  %9 = load i64, i64* %8, align 8
  %10 = and i64 %9, 3
  %11 = icmp eq i64 %10, 0
  br i1 %11, label %12, label %18

12:                                               ; preds = %1
  %13 = lshr i64 %9, 2
  %14 = sub nsw i64 0, %13
  %15 = and i64 %14, 3
  %16 = icmp slt i64 %15, %7
  %17 = select i1 %16, i64 %15, i64 %7
  br label %18

18:                                               ; preds = %1, %12
  %19 = phi i64 [ %17, %12 ], [ %7, %1 ]
  %20 = sub nsw i64 %7, %19
  %21 = sdiv i64 %20, 4
  %22 = shl nsw i64 %21, 2
  %23 = add nsw i64 %22, %19
  %24 = icmp sgt i64 %19, 0
  br i1 %24, label %25, label %72

25:                                               ; preds = %18
  %26 = bitcast %"class.Eigen::internal::generic_dense_assignment_kernel"* %0 to %"struct.Eigen::internal::evaluator_wrapper_base"**
  %27 = getelementptr inbounds %"class.Eigen::internal::generic_dense_assignment_kernel", %"class.Eigen::internal::generic_dense_assignment_kernel"* %0, i64 0, i32 1
  %28 = bitcast %"struct.Eigen::internal::evaluator"** %27 to %"struct.Eigen::internal::unary_evaluator"**
  br label %29

29:                                               ; preds = %29, %25
  %30 = phi i64 [ 0, %25 ], [ %70, %29 ]
  %31 = load %"struct.Eigen::internal::evaluator_wrapper_base"*, %"struct.Eigen::internal::evaluator_wrapper_base"** %26, align 8
  %32 = getelementptr inbounds %"struct.Eigen::internal::evaluator_wrapper_base", %"struct.Eigen::internal::evaluator_wrapper_base"* %31, i64 0, i32 0, i32 0, i32 0
  %33 = load float*, float** %32, align 8
  %34 = getelementptr inbounds float, float* %33, i64 %30
  %35 = load %"struct.Eigen::internal::unary_evaluator"*, %"struct.Eigen::internal::unary_evaluator"** %28, align 8
  %36 = getelementptr inbounds %"struct.Eigen::internal::unary_evaluator", %"struct.Eigen::internal::unary_evaluator"* %35, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %37 = load float*, float** %36, align 8
  %38 = getelementptr inbounds float, float* %37, i64 %30
  %39 = load float, float* %38, align 4
  %40 = fcmp ogt float %39, 0x401F9F09E0000000
  %41 = select i1 %40, float 0x401F9F09E0000000, float %39
  %42 = fcmp olt float %41, 0xC01F9F09E0000000
  %43 = select i1 %42, float 0xC01F9F09E0000000, float %41
  %44 = tail call float @llvm.fabs.f32(float %39) #19
  %45 = fcmp olt float %44, 0x3F3A36E2E0000000
  %46 = select i1 %45, float 0xFFFFFFFFE0000000, float 0.000000e+00
  %47 = fmul float %43, %43
  %48 = fmul float %47, 0x3CB3E4B800000000
  %49 = fsub float 0x3D4C266FC0000000, %48
  %50 = fmul float %47, %49
  %51 = fadd float %50, 0xBDD7A6FFE0000000
  %52 = fmul float %47, %51
  %53 = fadd float %52, 0x3E6B800820000000
  %54 = fmul float %47, %53
  %55 = fadd float %54, 0x3EEF286940000000
  %56 = fmul float %47, %55
  %57 = fadd float %56, 0x3F44E1BDA0000000
  %58 = fmul float %47, %57
  %59 = fadd float %58, 0x3F740B3B80000000
  %60 = fmul float %43, %59
  %61 = fmul float %47, 0x3EB41A7B00000000
  %62 = fadd float %61, 0x3F1F12BAC0000000
  %63 = fmul float %47, %62
  %64 = fadd float %63, 0x3F629540A0000000
  %65 = fmul float %47, %64
  %66 = fadd float %65, 0x3F740B3BA0000000
  %67 = fdiv float %60, %66
  %68 = fcmp oeq float %46, 0.000000e+00
  %69 = select i1 %68, float %67, float %43
  store float %69, float* %34, align 4
  %70 = add nuw nsw i64 %30, 1
  %71 = icmp eq i64 %70, %19
  br i1 %71, label %72, label %29

72:                                               ; preds = %29, %18
  %73 = icmp sgt i64 %20, 3
  br i1 %73, label %74, label %78

74:                                               ; preds = %72
  %75 = bitcast %"class.Eigen::internal::generic_dense_assignment_kernel"* %0 to %"struct.Eigen::internal::evaluator_wrapper_base"**
  %76 = getelementptr inbounds %"class.Eigen::internal::generic_dense_assignment_kernel", %"class.Eigen::internal::generic_dense_assignment_kernel"* %0, i64 0, i32 1
  %77 = bitcast %"struct.Eigen::internal::evaluator"** %76 to %"struct.Eigen::internal::unary_evaluator"**
  br label %128

78:                                               ; preds = %128, %72
  %79 = icmp slt i64 %23, %7
  br i1 %79, label %80, label %127

80:                                               ; preds = %78
  %81 = bitcast %"class.Eigen::internal::generic_dense_assignment_kernel"* %0 to %"struct.Eigen::internal::evaluator_wrapper_base"**
  %82 = getelementptr inbounds %"class.Eigen::internal::generic_dense_assignment_kernel", %"class.Eigen::internal::generic_dense_assignment_kernel"* %0, i64 0, i32 1
  %83 = bitcast %"struct.Eigen::internal::evaluator"** %82 to %"struct.Eigen::internal::unary_evaluator"**
  br label %84

84:                                               ; preds = %84, %80
  %85 = phi i64 [ %23, %80 ], [ %125, %84 ]
  %86 = load %"struct.Eigen::internal::evaluator_wrapper_base"*, %"struct.Eigen::internal::evaluator_wrapper_base"** %81, align 8
  %87 = getelementptr inbounds %"struct.Eigen::internal::evaluator_wrapper_base", %"struct.Eigen::internal::evaluator_wrapper_base"* %86, i64 0, i32 0, i32 0, i32 0
  %88 = load float*, float** %87, align 8
  %89 = getelementptr inbounds float, float* %88, i64 %85
  %90 = load %"struct.Eigen::internal::unary_evaluator"*, %"struct.Eigen::internal::unary_evaluator"** %83, align 8
  %91 = getelementptr inbounds %"struct.Eigen::internal::unary_evaluator", %"struct.Eigen::internal::unary_evaluator"* %90, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %92 = load float*, float** %91, align 8
  %93 = getelementptr inbounds float, float* %92, i64 %85
  %94 = load float, float* %93, align 4
  %95 = fcmp ogt float %94, 0x401F9F09E0000000
  %96 = select i1 %95, float 0x401F9F09E0000000, float %94
  %97 = fcmp olt float %96, 0xC01F9F09E0000000
  %98 = select i1 %97, float 0xC01F9F09E0000000, float %96
  %99 = tail call float @llvm.fabs.f32(float %94) #19
  %100 = fcmp olt float %99, 0x3F3A36E2E0000000
  %101 = select i1 %100, float 0xFFFFFFFFE0000000, float 0.000000e+00
  %102 = fmul float %98, %98
  %103 = fmul float %102, 0x3CB3E4B800000000
  %104 = fsub float 0x3D4C266FC0000000, %103
  %105 = fmul float %102, %104
  %106 = fadd float %105, 0xBDD7A6FFE0000000
  %107 = fmul float %102, %106
  %108 = fadd float %107, 0x3E6B800820000000
  %109 = fmul float %102, %108
  %110 = fadd float %109, 0x3EEF286940000000
  %111 = fmul float %102, %110
  %112 = fadd float %111, 0x3F44E1BDA0000000
  %113 = fmul float %102, %112
  %114 = fadd float %113, 0x3F740B3B80000000
  %115 = fmul float %98, %114
  %116 = fmul float %102, 0x3EB41A7B00000000
  %117 = fadd float %116, 0x3F1F12BAC0000000
  %118 = fmul float %102, %117
  %119 = fadd float %118, 0x3F629540A0000000
  %120 = fmul float %102, %119
  %121 = fadd float %120, 0x3F740B3BA0000000
  %122 = fdiv float %115, %121
  %123 = fcmp oeq float %101, 0.000000e+00
  %124 = select i1 %123, float %122, float %98
  store float %124, float* %89, align 4
  %125 = add nsw i64 %85, 1
  %126 = icmp eq i64 %125, %7
  br i1 %126, label %127, label %84

127:                                              ; preds = %84, %78
  ret void

128:                                              ; preds = %74, %128
  %129 = phi i64 [ %19, %74 ], [ %169, %128 ]
  %130 = load %"struct.Eigen::internal::evaluator_wrapper_base"*, %"struct.Eigen::internal::evaluator_wrapper_base"** %75, align 8
  %131 = getelementptr inbounds %"struct.Eigen::internal::evaluator_wrapper_base", %"struct.Eigen::internal::evaluator_wrapper_base"* %130, i64 0, i32 0, i32 0, i32 0
  %132 = load float*, float** %131, align 8
  %133 = getelementptr inbounds float, float* %132, i64 %129
  %134 = load %"struct.Eigen::internal::unary_evaluator"*, %"struct.Eigen::internal::unary_evaluator"** %77, align 8
  %135 = getelementptr inbounds %"struct.Eigen::internal::unary_evaluator", %"struct.Eigen::internal::unary_evaluator"* %134, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %136 = load float*, float** %135, align 8
  %137 = getelementptr inbounds float, float* %136, i64 %129
  %138 = bitcast float* %137 to <4 x float>*
  %139 = load <4 x float>, <4 x float>* %138, align 1
  %140 = tail call <4 x float> asm "minps $1, $0", "=x,x,0,~{dirflag},~{fpsr},~{flags}"(<4 x float> %139, <4 x float> <float 0x401F9F09E0000000, float 0x401F9F09E0000000, float 0x401F9F09E0000000, float 0x401F9F09E0000000>) #10, !srcloc !60
  %141 = tail call <4 x float> asm "maxps $1, $0", "=x,x,0,~{dirflag},~{fpsr},~{flags}"(<4 x float> %140, <4 x float> <float 0xC01F9F09E0000000, float 0xC01F9F09E0000000, float 0xC01F9F09E0000000, float 0xC01F9F09E0000000>) #10, !srcloc !61
  %142 = bitcast <4 x float> %139 to <4 x i32>
  %143 = and <4 x i32> %142, <i32 2147483647, i32 2147483647, i32 2147483647, i32 2147483647>
  %144 = bitcast <4 x i32> %143 to <4 x float>
  %145 = fcmp uge <4 x float> %144, <float 0x3F3A36E2E0000000, float 0x3F3A36E2E0000000, float 0x3F3A36E2E0000000, float 0x3F3A36E2E0000000>
  %146 = fmul <4 x float> %141, %141
  %147 = fmul <4 x float> %146, <float 0xBCB3E4B800000000, float 0xBCB3E4B800000000, float 0xBCB3E4B800000000, float 0xBCB3E4B800000000>
  %148 = fadd <4 x float> %147, <float 0x3D4C266FC0000000, float 0x3D4C266FC0000000, float 0x3D4C266FC0000000, float 0x3D4C266FC0000000>
  %149 = fmul <4 x float> %146, %148
  %150 = fadd <4 x float> %149, <float 0xBDD7A6FFE0000000, float 0xBDD7A6FFE0000000, float 0xBDD7A6FFE0000000, float 0xBDD7A6FFE0000000>
  %151 = fmul <4 x float> %146, %150
  %152 = fadd <4 x float> %151, <float 0x3E6B800820000000, float 0x3E6B800820000000, float 0x3E6B800820000000, float 0x3E6B800820000000>
  %153 = fmul <4 x float> %146, %152
  %154 = fadd <4 x float> %153, <float 0x3EEF286940000000, float 0x3EEF286940000000, float 0x3EEF286940000000, float 0x3EEF286940000000>
  %155 = fmul <4 x float> %146, %154
  %156 = fadd <4 x float> %155, <float 0x3F44E1BDA0000000, float 0x3F44E1BDA0000000, float 0x3F44E1BDA0000000, float 0x3F44E1BDA0000000>
  %157 = fmul <4 x float> %146, %156
  %158 = fadd <4 x float> %157, <float 0x3F740B3B80000000, float 0x3F740B3B80000000, float 0x3F740B3B80000000, float 0x3F740B3B80000000>
  %159 = fmul <4 x float> %141, %158
  %160 = fmul <4 x float> %146, <float 0x3EB41A7B00000000, float 0x3EB41A7B00000000, float 0x3EB41A7B00000000, float 0x3EB41A7B00000000>
  %161 = fadd <4 x float> %160, <float 0x3F1F12BAC0000000, float 0x3F1F12BAC0000000, float 0x3F1F12BAC0000000, float 0x3F1F12BAC0000000>
  %162 = fmul <4 x float> %146, %161
  %163 = fadd <4 x float> %162, <float 0x3F629540A0000000, float 0x3F629540A0000000, float 0x3F629540A0000000, float 0x3F629540A0000000>
  %164 = fmul <4 x float> %146, %163
  %165 = fadd <4 x float> %164, <float 0x3F740B3BA0000000, float 0x3F740B3BA0000000, float 0x3F740B3BA0000000, float 0x3F740B3BA0000000>
  %166 = fdiv <4 x float> %159, %165
  %167 = select <4 x i1> %145, <4 x float> %166, <4 x float> %141
  %168 = bitcast float* %133 to <4 x float>*
  store <4 x float> %167, <4 x float>* %168, align 16
  %169 = add nsw i64 %129, 4
  %170 = icmp slt i64 %169, %23
  br i1 %170, label %128, label %78
}

; Function Attrs: nounwind readnone speculatable
declare float @llvm.fabs.f32(float) #8

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN5Eigen8internal26call_dense_assignment_loopINS_12ArrayWrapperINS_3MapINS_6MatrixIfLin1ELi1ELi0ELin1ELi1EEELi0ENS_6StrideILi0ELi0EEEEEEENS_12CwiseUnaryOpINS0_18scalar_logistic_opIfEEKS9_EENS0_9assign_opIffEEEEvRT_RKT0_RKT1_(%"class.Eigen::ArrayWrapper"* dereferenceable(24), %"class.Eigen::CwiseUnaryOp.42"* dereferenceable(32), %"struct.Eigen::internal::assign_op"* dereferenceable(1)) local_unnamed_addr #7 comdat {
  %4 = bitcast %"class.Eigen::CwiseUnaryOp.42"* %1 to i64*
  %5 = load i64, i64* %4, align 8
  %6 = bitcast %"class.Eigen::ArrayWrapper"* %0 to i64*
  %7 = load i64, i64* %6, align 8
  %8 = getelementptr inbounds %"class.Eigen::ArrayWrapper", %"class.Eigen::ArrayWrapper"* %0, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0
  %9 = load i64, i64* %8, align 8
  %10 = and i64 %7, 3
  %11 = icmp eq i64 %10, 0
  br i1 %11, label %12, label %18

12:                                               ; preds = %3
  %13 = lshr i64 %7, 2
  %14 = sub nsw i64 0, %13
  %15 = and i64 %14, 3
  %16 = icmp slt i64 %15, %9
  %17 = select i1 %16, i64 %15, i64 %9
  br label %18

18:                                               ; preds = %12, %3
  %19 = phi i64 [ %17, %12 ], [ %9, %3 ]
  %20 = sub nsw i64 %9, %19
  %21 = sdiv i64 %20, 4
  %22 = shl nsw i64 %21, 2
  %23 = add nsw i64 %22, %19
  %24 = icmp sgt i64 %19, 0
  br i1 %24, label %25, label %92

25:                                               ; preds = %18
  %26 = inttoptr i64 %7 to float*
  %27 = inttoptr i64 %5 to float*
  br label %28

28:                                               ; preds = %25, %88
  %29 = phi i64 [ %90, %88 ], [ 0, %25 ]
  %30 = getelementptr inbounds float, float* %26, i64 %29
  %31 = getelementptr inbounds float, float* %27, i64 %29
  %32 = load float, float* %31, align 4
  %33 = fcmp olt float %32, -9.000000e+00
  %34 = fcmp ogt float %32, 0x402F499C60000000
  %35 = select i1 %34, float 0x402F499C60000000, float %32
  %36 = fmul float %35, %35
  %37 = fmul float %36, 0x3DC806AA20000000
  %38 = fadd float %37, 0x3E7F09D960000000
  %39 = fmul float %36, %38
  %40 = fadd float %39, 0x3F0FE82760000000
  %41 = fmul float %36, %40
  %42 = fadd float %41, 0x3F816FAB00000000
  %43 = fmul float %36, %42
  %44 = fadd float %43, 0x3FCFC7E640000000
  %45 = fmul float %35, %44
  %46 = fmul float %36, 0x3D65789EA0000000
  %47 = fadd float %46, 0x3E38BE4F60000000
  %48 = fmul float %36, %47
  %49 = fadd float %48, 0x3EDA62FBA0000000
  %50 = fmul float %36, %49
  %51 = fadd float %50, 0x3F5BE2A7E0000000
  %52 = fmul float %36, %51
  %53 = fadd float %52, 0x3FBDE7C300000000
  %54 = fmul float %36, %53
  %55 = fadd float %54, 0x3FEFC7E680000000
  %56 = fdiv float %45, %55
  %57 = fadd float %56, 5.000000e-01
  br i1 %33, label %58, label %88, !prof !62

58:                                               ; preds = %28
  %59 = fcmp ogt float %32, 0x40561814C0000000
  %60 = select i1 %59, float 0x40561814C0000000, float %32
  %61 = fcmp olt float %60, 0xC0561814A0000000
  %62 = select i1 %61, float 0xC0561814A0000000, float %60
  %63 = fmul float %62, 0x3FF7154760000000
  %64 = fadd float %63, 5.000000e-01
  %65 = tail call float @llvm.floor.f32(float %64) #19
  %66 = fmul float %65, 0x3FE6300000000000
  %67 = fsub float %62, %66
  %68 = fmul float %65, 0x3F2BD01060000000
  %69 = fadd float %68, %67
  %70 = fmul float %69, %69
  %71 = fmul float %69, 0x3F2A0D2CE0000000
  %72 = fadd float %71, 0x3F56E879C0000000
  %73 = fmul float %69, %72
  %74 = fadd float %73, 0x3F81112100000000
  %75 = fmul float %69, %74
  %76 = fadd float %75, 0x3FA5553820000000
  %77 = fmul float %69, %76
  %78 = fadd float %77, 0x3FC5555540000000
  %79 = fmul float %69, %78
  %80 = fadd float %79, 5.000000e-01
  %81 = fmul float %70, %80
  %82 = fadd float %69, %81
  %83 = fadd float %82, 1.000000e+00
  %84 = fptosi float %65 to i32
  %85 = tail call float @ldexpf(float %83, i32 %84) #19
  %86 = fcmp olt float %85, %32
  %87 = select i1 %86, float %32, float %85
  br label %88

88:                                               ; preds = %58, %28
  %89 = phi float [ %87, %58 ], [ %57, %28 ]
  store float %89, float* %30, align 4
  %90 = add nuw i64 %29, 1
  %91 = icmp eq i64 %90, %19
  br i1 %91, label %92, label %28

92:                                               ; preds = %88, %18
  %93 = icmp sgt i64 %20, 3
  br i1 %93, label %94, label %169

94:                                               ; preds = %92
  %95 = inttoptr i64 %7 to float*
  %96 = inttoptr i64 %5 to float*
  br label %97

97:                                               ; preds = %94, %164
  %98 = phi i64 [ %167, %164 ], [ %19, %94 ]
  %99 = getelementptr inbounds float, float* %95, i64 %98
  %100 = getelementptr inbounds float, float* %96, i64 %98
  %101 = bitcast float* %100 to <4 x float>*
  %102 = load <4 x float>, <4 x float>* %101, align 1
  %103 = fcmp olt <4 x float> %102, <float -9.000000e+00, float -9.000000e+00, float -9.000000e+00, float -9.000000e+00>
  %104 = bitcast <4 x i1> %103 to i4
  %105 = icmp eq i4 %104, 0
  %106 = tail call <4 x float> asm "minps $1, $0", "=x,x,0,~{dirflag},~{fpsr},~{flags}"(<4 x float> %102, <4 x float> <float 0x402F499C60000000, float 0x402F499C60000000, float 0x402F499C60000000, float 0x402F499C60000000>) #10, !srcloc !60
  %107 = fmul <4 x float> %106, %106
  %108 = fmul <4 x float> %107, <float 0x3DC806AA20000000, float 0x3DC806AA20000000, float 0x3DC806AA20000000, float 0x3DC806AA20000000>
  %109 = fadd <4 x float> %108, <float 0x3E7F09D960000000, float 0x3E7F09D960000000, float 0x3E7F09D960000000, float 0x3E7F09D960000000>
  %110 = fmul <4 x float> %107, %109
  %111 = fadd <4 x float> %110, <float 0x3F0FE82760000000, float 0x3F0FE82760000000, float 0x3F0FE82760000000, float 0x3F0FE82760000000>
  %112 = fmul <4 x float> %107, %111
  %113 = fadd <4 x float> %112, <float 0x3F816FAB00000000, float 0x3F816FAB00000000, float 0x3F816FAB00000000, float 0x3F816FAB00000000>
  %114 = fmul <4 x float> %107, %113
  %115 = fadd <4 x float> %114, <float 0x3FCFC7E640000000, float 0x3FCFC7E640000000, float 0x3FCFC7E640000000, float 0x3FCFC7E640000000>
  %116 = fmul <4 x float> %106, %115
  %117 = fmul <4 x float> %107, <float 0x3D65789EA0000000, float 0x3D65789EA0000000, float 0x3D65789EA0000000, float 0x3D65789EA0000000>
  %118 = fadd <4 x float> %117, <float 0x3E38BE4F60000000, float 0x3E38BE4F60000000, float 0x3E38BE4F60000000, float 0x3E38BE4F60000000>
  %119 = fmul <4 x float> %107, %118
  %120 = fadd <4 x float> %119, <float 0x3EDA62FBA0000000, float 0x3EDA62FBA0000000, float 0x3EDA62FBA0000000, float 0x3EDA62FBA0000000>
  %121 = fmul <4 x float> %107, %120
  %122 = fadd <4 x float> %121, <float 0x3F5BE2A7E0000000, float 0x3F5BE2A7E0000000, float 0x3F5BE2A7E0000000, float 0x3F5BE2A7E0000000>
  %123 = fmul <4 x float> %107, %122
  %124 = fadd <4 x float> %123, <float 0x3FBDE7C300000000, float 0x3FBDE7C300000000, float 0x3FBDE7C300000000, float 0x3FBDE7C300000000>
  %125 = fmul <4 x float> %107, %124
  %126 = fadd <4 x float> %125, <float 0x3FEFC7E680000000, float 0x3FEFC7E680000000, float 0x3FEFC7E680000000, float 0x3FEFC7E680000000>
  %127 = fdiv <4 x float> %116, %126
  %128 = fadd <4 x float> %127, <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>
  br i1 %105, label %164, label %129, !prof !63

129:                                              ; preds = %97
  %130 = tail call <4 x float> asm "minps $1, $0", "=x,x,0,~{dirflag},~{fpsr},~{flags}"(<4 x float> %102, <4 x float> <float 0x40561814C0000000, float 0x40561814C0000000, float 0x40561814C0000000, float 0x40561814C0000000>) #10, !srcloc !60
  %131 = tail call <4 x float> asm "maxps $1, $0", "=x,x,0,~{dirflag},~{fpsr},~{flags}"(<4 x float> %130, <4 x float> <float 0xC0561814A0000000, float 0xC0561814A0000000, float 0xC0561814A0000000, float 0xC0561814A0000000>) #10, !srcloc !61
  %132 = fmul <4 x float> %131, <float 0x3FF7154760000000, float 0x3FF7154760000000, float 0x3FF7154760000000, float 0x3FF7154760000000>
  %133 = fadd <4 x float> %132, <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>
  %134 = tail call <4 x i32> @llvm.x86.sse2.cvttps2dq(<4 x float> %133) #19
  %135 = sitofp <4 x i32> %134 to <4 x float>
  %136 = fcmp olt <4 x float> %133, %135
  %137 = select <4 x i1> %136, <4 x float> <float 1.000000e+00, float 1.000000e+00, float 1.000000e+00, float 1.000000e+00>, <4 x float> zeroinitializer
  %138 = fsub <4 x float> %135, %137
  %139 = fmul <4 x float> %138, <float 0x3FE6300000000000, float 0x3FE6300000000000, float 0x3FE6300000000000, float 0x3FE6300000000000>
  %140 = fsub <4 x float> %131, %139
  %141 = fmul <4 x float> %138, <float 0xBF2BD01060000000, float 0xBF2BD01060000000, float 0xBF2BD01060000000, float 0xBF2BD01060000000>
  %142 = fsub <4 x float> %140, %141
  %143 = fmul <4 x float> %142, %142
  %144 = fmul <4 x float> %142, <float 0x3F2A0D2CE0000000, float 0x3F2A0D2CE0000000, float 0x3F2A0D2CE0000000, float 0x3F2A0D2CE0000000>
  %145 = fadd <4 x float> %144, <float 0x3F56E879C0000000, float 0x3F56E879C0000000, float 0x3F56E879C0000000, float 0x3F56E879C0000000>
  %146 = fmul <4 x float> %142, %145
  %147 = fadd <4 x float> %146, <float 0x3F81112100000000, float 0x3F81112100000000, float 0x3F81112100000000, float 0x3F81112100000000>
  %148 = fmul <4 x float> %142, %147
  %149 = fadd <4 x float> %148, <float 0x3FA5553820000000, float 0x3FA5553820000000, float 0x3FA5553820000000, float 0x3FA5553820000000>
  %150 = fmul <4 x float> %142, %149
  %151 = fadd <4 x float> %150, <float 0x3FC5555540000000, float 0x3FC5555540000000, float 0x3FC5555540000000, float 0x3FC5555540000000>
  %152 = fmul <4 x float> %142, %151
  %153 = fadd <4 x float> %152, <float 5.000000e-01, float 5.000000e-01, float 5.000000e-01, float 5.000000e-01>
  %154 = fmul <4 x float> %143, %153
  %155 = fadd <4 x float> %142, %154
  %156 = fadd <4 x float> %155, <float 1.000000e+00, float 1.000000e+00, float 1.000000e+00, float 1.000000e+00>
  %157 = fadd <4 x float> %138, <float 1.270000e+02, float 1.270000e+02, float 1.270000e+02, float 1.270000e+02>
  %158 = tail call <4 x i32> @llvm.x86.sse2.cvttps2dq(<4 x float> %157) #19
  %159 = shl <4 x i32> %158, <i32 23, i32 23, i32 23, i32 23>
  %160 = bitcast <4 x i32> %159 to <4 x float>
  %161 = fmul <4 x float> %156, %160
  %162 = tail call <4 x float> asm "maxps $1, $0", "=x,x,0,~{dirflag},~{fpsr},~{flags}"(<4 x float> %161, <4 x float> %102) #10, !srcloc !61
  %163 = select <4 x i1> %103, <4 x float> %162, <4 x float> %128
  br label %164

164:                                              ; preds = %97, %129
  %165 = phi <4 x float> [ %163, %129 ], [ %128, %97 ]
  %166 = bitcast float* %99 to <4 x float>*
  store <4 x float> %165, <4 x float>* %166, align 16
  %167 = add nsw i64 %98, 4
  %168 = icmp slt i64 %167, %23
  br i1 %168, label %97, label %169

169:                                              ; preds = %164, %92
  %170 = icmp slt i64 %23, %9
  br i1 %170, label %171, label %238

171:                                              ; preds = %169
  %172 = inttoptr i64 %7 to float*
  %173 = inttoptr i64 %5 to float*
  br label %174

174:                                              ; preds = %171, %234
  %175 = phi i64 [ %236, %234 ], [ %23, %171 ]
  %176 = getelementptr inbounds float, float* %172, i64 %175
  %177 = getelementptr inbounds float, float* %173, i64 %175
  %178 = load float, float* %177, align 4
  %179 = fcmp olt float %178, -9.000000e+00
  %180 = fcmp ogt float %178, 0x402F499C60000000
  %181 = select i1 %180, float 0x402F499C60000000, float %178
  %182 = fmul float %181, %181
  %183 = fmul float %182, 0x3DC806AA20000000
  %184 = fadd float %183, 0x3E7F09D960000000
  %185 = fmul float %182, %184
  %186 = fadd float %185, 0x3F0FE82760000000
  %187 = fmul float %182, %186
  %188 = fadd float %187, 0x3F816FAB00000000
  %189 = fmul float %182, %188
  %190 = fadd float %189, 0x3FCFC7E640000000
  %191 = fmul float %181, %190
  %192 = fmul float %182, 0x3D65789EA0000000
  %193 = fadd float %192, 0x3E38BE4F60000000
  %194 = fmul float %182, %193
  %195 = fadd float %194, 0x3EDA62FBA0000000
  %196 = fmul float %182, %195
  %197 = fadd float %196, 0x3F5BE2A7E0000000
  %198 = fmul float %182, %197
  %199 = fadd float %198, 0x3FBDE7C300000000
  %200 = fmul float %182, %199
  %201 = fadd float %200, 0x3FEFC7E680000000
  %202 = fdiv float %191, %201
  %203 = fadd float %202, 5.000000e-01
  br i1 %179, label %204, label %234, !prof !62

204:                                              ; preds = %174
  %205 = fcmp ogt float %178, 0x40561814C0000000
  %206 = select i1 %205, float 0x40561814C0000000, float %178
  %207 = fcmp olt float %206, 0xC0561814A0000000
  %208 = select i1 %207, float 0xC0561814A0000000, float %206
  %209 = fmul float %208, 0x3FF7154760000000
  %210 = fadd float %209, 5.000000e-01
  %211 = tail call float @llvm.floor.f32(float %210) #19
  %212 = fmul float %211, 0x3FE6300000000000
  %213 = fsub float %208, %212
  %214 = fmul float %211, 0x3F2BD01060000000
  %215 = fadd float %214, %213
  %216 = fmul float %215, %215
  %217 = fmul float %215, 0x3F2A0D2CE0000000
  %218 = fadd float %217, 0x3F56E879C0000000
  %219 = fmul float %215, %218
  %220 = fadd float %219, 0x3F81112100000000
  %221 = fmul float %215, %220
  %222 = fadd float %221, 0x3FA5553820000000
  %223 = fmul float %215, %222
  %224 = fadd float %223, 0x3FC5555540000000
  %225 = fmul float %215, %224
  %226 = fadd float %225, 5.000000e-01
  %227 = fmul float %216, %226
  %228 = fadd float %215, %227
  %229 = fadd float %228, 1.000000e+00
  %230 = fptosi float %211 to i32
  %231 = tail call float @ldexpf(float %229, i32 %230) #19
  %232 = fcmp olt float %231, %178
  %233 = select i1 %232, float %178, float %231
  br label %234

234:                                              ; preds = %204, %174
  %235 = phi float [ %233, %204 ], [ %203, %174 ]
  store float %235, float* %176, align 4
  %236 = add i64 %175, 1
  %237 = icmp eq i64 %236, %9
  br i1 %237, label %238, label %174

238:                                              ; preds = %234, %169
  ret void
}

; Function Attrs: nounwind readnone speculatable
declare float @llvm.floor.f32(float) #8

; Function Attrs: nofree nounwind
declare float @ldexpf(float, i32) local_unnamed_addr #9

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.x86.sse2.cvttps2dq(<4 x float>) #10

declare void @_ZN6tflite12tensor_utils24AsymmetricQuantizeFloatsEPKfiPaPfPi(float*, i32, i8*, float*, i32*) local_unnamed_addr #5

declare void @_ZN6tflite12tensor_utils23SymmetricQuantizeFloatsEPKfiPaPfS4_S4_(float*, i32, i8*, float*, float*, float*) local_unnamed_addr #5

; Function Attrs: argmemonly nounwind
declare void @llvm.memmove.p0i8.p0i8.i64(i8* nocapture, i8* nocapture readonly, i64, i1 immarg) #0

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i32 @_ZN6tflite3ops7builtin15fully_connected9EvalFloatILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_(%struct.TfLiteContext*, %struct.TfLiteNode*, %struct.TfLiteFullyConnectedParams*, %"struct.tflite::ops::builtin::fully_connected::OpData"*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*) local_unnamed_addr #1 comdat {
  %9 = alloca %"struct.tflite::FullyConnectedParams", align 4
  %10 = alloca %"class.tflite::RuntimeShape", align 8
  %11 = alloca %"class.tflite::RuntimeShape", align 8
  %12 = alloca %"class.tflite::RuntimeShape", align 8
  %13 = alloca %"class.tflite::RuntimeShape", align 8
  %14 = alloca %"class.tflite::RuntimeShape", align 8
  %15 = alloca %"class.tflite::RuntimeShape", align 8
  %16 = alloca %"class.tflite::RuntimeShape", align 8
  %17 = alloca %"class.tflite::RuntimeShape", align 8
  %18 = getelementptr inbounds %struct.TfLiteFullyConnectedParams, %struct.TfLiteFullyConnectedParams* %2, i64 0, i32 0
  %19 = load i32, i32* %18, align 4
  %20 = add i32 %19, -1
  %21 = icmp ult i32 %20, 3
  br i1 %21, label %22, label %29

22:                                               ; preds = %8
  %23 = sext i32 %20 to i64
  %24 = getelementptr inbounds [3 x float], [3 x float]* @switch.table._ZN6tflite3ops7builtin15fully_connected9EvalFloatILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_, i64 0, i64 %23
  %25 = load float, float* %24, align 4
  %26 = sext i32 %20 to i64
  %27 = getelementptr inbounds [3 x float], [3 x float]* @switch.table._ZN6tflite3ops7builtin15fully_connected9EvalFloatILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_.73, i64 0, i64 %26
  %28 = load float, float* %27, align 4
  br label %29

29:                                               ; preds = %8, %22
  %30 = phi float [ %25, %22 ], [ 0xC7EFFFFFE0000000, %8 ]
  %31 = phi float [ %28, %22 ], [ 0x47EFFFFFE0000000, %8 ]
  %32 = bitcast %"struct.tflite::FullyConnectedParams"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %32) #19
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 4 %32, i8* align 4 bitcast ({ i32, i32, i32, i32, i32, i32, i32, float, float, i8, i8, i8, [1 x i8] }* @__const._ZN6tflite3ops7builtin15fully_connected13EvalQuantizedILNS2_10KernelTypeE2EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_.op_params to i8*), i64 40, i1 false)
  %33 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %9, i64 0, i32 7
  store float %30, float* %33, align 4
  %34 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %9, i64 0, i32 8
  store float %31, float* %34, align 4
  %35 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 13
  %36 = load %struct.TfLiteSparsity*, %struct.TfLiteSparsity** %35, align 8
  %37 = icmp eq %struct.TfLiteSparsity* %36, null
  br i1 %37, label %214, label %38

38:                                               ; preds = %29
  %39 = bitcast %"class.tflite::RuntimeShape"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %39) #19
  %40 = icmp eq %struct.TfLiteTensor* %4, null
  br i1 %40, label %41, label %43

41:                                               ; preds = %38
  %42 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %10, i64 0, i32 0
  store i32 0, i32* %42, align 8, !alias.scope !64
  br label %71

43:                                               ; preds = %38
  %44 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 2
  %45 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %44, align 8, !noalias !64
  %46 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %45, i64 0, i32 0
  %47 = load i32, i32* %46, align 4, !noalias !64
  %48 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %45, i64 0, i32 1, i64 0
  %49 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %10, i64 0, i32 0
  store i32 %47, i32* %49, align 8, !alias.scope !64
  %50 = icmp sgt i32 %47, 5
  br i1 %50, label %51, label %58

51:                                               ; preds = %43
  %52 = sext i32 %47 to i64
  %53 = shl nsw i64 %52, 2
  %54 = tail call i8* @_Znam(i64 %53) #18, !noalias !64
  %55 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %10, i64 0, i32 1, i32 0
  %56 = bitcast i32** %55 to i8**
  store i8* %54, i8** %56, align 8, !alias.scope !64
  %57 = bitcast i8* %54 to i32*
  br label %63

58:                                               ; preds = %43
  %59 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %10, i64 0, i32 1
  %60 = bitcast %union.anon.54* %59 to i32*
  %61 = sext i32 %47 to i64
  %62 = shl nsw i64 %61, 2
  br label %63

63:                                               ; preds = %58, %51
  %64 = phi i64 [ %53, %51 ], [ %62, %58 ]
  %65 = phi i32* [ %57, %51 ], [ %60, %58 ]
  %66 = bitcast i32* %65 to i8*
  %67 = bitcast i32* %48 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %66, i8* align 4 %67, i64 %64, i1 false) #19
  %68 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 1
  %69 = bitcast %union.TfLitePtrUnion* %68 to float**
  %70 = load float*, float** %69, align 8
  br label %71

71:                                               ; preds = %41, %63
  %72 = phi float* [ %70, %63 ], [ null, %41 ]
  %73 = bitcast %"class.tflite::RuntimeShape"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %73) #19
  %74 = icmp eq %struct.TfLiteTensor* %5, null
  br i1 %74, label %75, label %77

75:                                               ; preds = %71
  %76 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 0
  store i32 0, i32* %76, align 8, !alias.scope !67
  br label %105

77:                                               ; preds = %71
  %78 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 2
  %79 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %78, align 8, !noalias !67
  %80 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %79, i64 0, i32 0
  %81 = load i32, i32* %80, align 4, !noalias !67
  %82 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %79, i64 0, i32 1, i64 0
  %83 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 0
  store i32 %81, i32* %83, align 8, !alias.scope !67
  %84 = icmp sgt i32 %81, 5
  br i1 %84, label %85, label %92

85:                                               ; preds = %77
  %86 = sext i32 %81 to i64
  %87 = shl nsw i64 %86, 2
  %88 = tail call i8* @_Znam(i64 %87) #18, !noalias !67
  %89 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 1, i32 0
  %90 = bitcast i32** %89 to i8**
  store i8* %88, i8** %90, align 8, !alias.scope !67
  %91 = bitcast i8* %88 to i32*
  br label %97

92:                                               ; preds = %77
  %93 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 1
  %94 = bitcast %union.anon.54* %93 to i32*
  %95 = sext i32 %81 to i64
  %96 = shl nsw i64 %95, 2
  br label %97

97:                                               ; preds = %92, %85
  %98 = phi i64 [ %87, %85 ], [ %96, %92 ]
  %99 = phi i32* [ %91, %85 ], [ %94, %92 ]
  %100 = bitcast i32* %99 to i8*
  %101 = bitcast i32* %82 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %100, i8* align 4 %101, i64 %98, i1 false) #19
  %102 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 1
  %103 = bitcast %union.TfLitePtrUnion* %102 to float**
  %104 = load float*, float** %103, align 8
  br label %105

105:                                              ; preds = %75, %97
  %106 = phi float* [ %104, %97 ], [ null, %75 ]
  %107 = bitcast %"class.tflite::RuntimeShape"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %107) #19
  %108 = icmp eq %struct.TfLiteTensor* %6, null
  br i1 %108, label %109, label %111

109:                                              ; preds = %105
  %110 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 0
  store i32 0, i32* %110, align 8, !alias.scope !70
  br label %139

111:                                              ; preds = %105
  %112 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 2
  %113 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %112, align 8, !noalias !70
  %114 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %113, i64 0, i32 0
  %115 = load i32, i32* %114, align 4, !noalias !70
  %116 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %113, i64 0, i32 1, i64 0
  %117 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 0
  store i32 %115, i32* %117, align 8, !alias.scope !70
  %118 = icmp sgt i32 %115, 5
  br i1 %118, label %119, label %126

119:                                              ; preds = %111
  %120 = sext i32 %115 to i64
  %121 = shl nsw i64 %120, 2
  %122 = tail call i8* @_Znam(i64 %121) #18, !noalias !70
  %123 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 1, i32 0
  %124 = bitcast i32** %123 to i8**
  store i8* %122, i8** %124, align 8, !alias.scope !70
  %125 = bitcast i8* %122 to i32*
  br label %131

126:                                              ; preds = %111
  %127 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 1
  %128 = bitcast %union.anon.54* %127 to i32*
  %129 = sext i32 %115 to i64
  %130 = shl nsw i64 %129, 2
  br label %131

131:                                              ; preds = %126, %119
  %132 = phi i64 [ %121, %119 ], [ %130, %126 ]
  %133 = phi i32* [ %125, %119 ], [ %128, %126 ]
  %134 = bitcast i32* %133 to i8*
  %135 = bitcast i32* %116 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %134, i8* align 4 %135, i64 %132, i1 false) #19
  %136 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 1
  %137 = bitcast %union.TfLitePtrUnion* %136 to float**
  %138 = load float*, float** %137, align 8
  br label %139

139:                                              ; preds = %109, %131
  %140 = phi float* [ %138, %131 ], [ null, %109 ]
  %141 = bitcast %"class.tflite::RuntimeShape"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %141) #19
  %142 = icmp eq %struct.TfLiteTensor* %7, null
  br i1 %142, label %143, label %145

143:                                              ; preds = %139
  %144 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 0
  store i32 0, i32* %144, align 8, !alias.scope !73
  br label %173

145:                                              ; preds = %139
  %146 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 2
  %147 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %146, align 8, !noalias !73
  %148 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %147, i64 0, i32 0
  %149 = load i32, i32* %148, align 4, !noalias !73
  %150 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %147, i64 0, i32 1, i64 0
  %151 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 0
  store i32 %149, i32* %151, align 8, !alias.scope !73
  %152 = icmp sgt i32 %149, 5
  br i1 %152, label %153, label %160

153:                                              ; preds = %145
  %154 = sext i32 %149 to i64
  %155 = shl nsw i64 %154, 2
  %156 = tail call i8* @_Znam(i64 %155) #18, !noalias !73
  %157 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 1, i32 0
  %158 = bitcast i32** %157 to i8**
  store i8* %156, i8** %158, align 8, !alias.scope !73
  %159 = bitcast i8* %156 to i32*
  br label %165

160:                                              ; preds = %145
  %161 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 1
  %162 = bitcast %union.anon.54* %161 to i32*
  %163 = sext i32 %149 to i64
  %164 = shl nsw i64 %163, 2
  br label %165

165:                                              ; preds = %160, %153
  %166 = phi i64 [ %155, %153 ], [ %164, %160 ]
  %167 = phi i32* [ %159, %153 ], [ %162, %160 ]
  %168 = bitcast i32* %167 to i8*
  %169 = bitcast i32* %150 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %168, i8* align 4 %169, i64 %166, i1 false) #19
  %170 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 1
  %171 = bitcast %union.TfLitePtrUnion* %170 to float**
  %172 = load float*, float** %171, align 8
  br label %173

173:                                              ; preds = %143, %165
  %174 = phi float* [ %172, %165 ], [ null, %143 ]
  call void @_ZN6tflite13reference_ops26FullyConnectedSparseWeightERK14TfLiteSparsityRKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKfS9_SB_S9_SB_S9_Pf(%struct.TfLiteSparsity* nonnull dereferenceable(32) %36, %"struct.tflite::FullyConnectedParams"* nonnull dereferenceable(40) %9, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %10, float* %72, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %11, float* %106, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %12, float* %140, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %13, float* %174)
  %175 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 0
  %176 = load i32, i32* %175, align 8
  %177 = icmp sgt i32 %176, 5
  br i1 %177, label %178, label %184

178:                                              ; preds = %173
  %179 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 1, i32 0
  %180 = load i32*, i32** %179, align 8
  %181 = icmp eq i32* %180, null
  br i1 %181, label %184, label %182

182:                                              ; preds = %178
  %183 = bitcast i32* %180 to i8*
  call void @_ZdaPv(i8* %183) #18
  br label %184

184:                                              ; preds = %173, %178, %182
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %141) #19
  %185 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 0
  %186 = load i32, i32* %185, align 8
  %187 = icmp sgt i32 %186, 5
  br i1 %187, label %188, label %194

188:                                              ; preds = %184
  %189 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 1, i32 0
  %190 = load i32*, i32** %189, align 8
  %191 = icmp eq i32* %190, null
  br i1 %191, label %194, label %192

192:                                              ; preds = %188
  %193 = bitcast i32* %190 to i8*
  call void @_ZdaPv(i8* %193) #18
  br label %194

194:                                              ; preds = %184, %188, %192
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %107) #19
  %195 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 0
  %196 = load i32, i32* %195, align 8
  %197 = icmp sgt i32 %196, 5
  br i1 %197, label %198, label %204

198:                                              ; preds = %194
  %199 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 1, i32 0
  %200 = load i32*, i32** %199, align 8
  %201 = icmp eq i32* %200, null
  br i1 %201, label %204, label %202

202:                                              ; preds = %198
  %203 = bitcast i32* %200 to i8*
  call void @_ZdaPv(i8* %203) #18
  br label %204

204:                                              ; preds = %194, %198, %202
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %73) #19
  %205 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %10, i64 0, i32 0
  %206 = load i32, i32* %205, align 8
  %207 = icmp sgt i32 %206, 5
  br i1 %207, label %208, label %540

208:                                              ; preds = %204
  %209 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %10, i64 0, i32 1, i32 0
  %210 = load i32*, i32** %209, align 8
  %211 = icmp eq i32* %210, null
  br i1 %211, label %540, label %212

212:                                              ; preds = %208
  %213 = bitcast i32* %210 to i8*
  call void @_ZdaPv(i8* %213) #18
  br label %540

214:                                              ; preds = %29
  %215 = bitcast %"class.tflite::RuntimeShape"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %215) #19
  %216 = icmp eq %struct.TfLiteTensor* %4, null
  br i1 %216, label %217, label %219

217:                                              ; preds = %214
  %218 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 0
  store i32 0, i32* %218, align 8, !alias.scope !76
  br label %247

219:                                              ; preds = %214
  %220 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 2
  %221 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %220, align 8, !noalias !76
  %222 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %221, i64 0, i32 0
  %223 = load i32, i32* %222, align 4, !noalias !76
  %224 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %221, i64 0, i32 1, i64 0
  %225 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 0
  store i32 %223, i32* %225, align 8, !alias.scope !76
  %226 = icmp sgt i32 %223, 5
  br i1 %226, label %227, label %234

227:                                              ; preds = %219
  %228 = sext i32 %223 to i64
  %229 = shl nsw i64 %228, 2
  %230 = tail call i8* @_Znam(i64 %229) #18, !noalias !76
  %231 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 1, i32 0
  %232 = bitcast i32** %231 to i8**
  store i8* %230, i8** %232, align 8, !alias.scope !76
  %233 = bitcast i8* %230 to i32*
  br label %239

234:                                              ; preds = %219
  %235 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 1
  %236 = bitcast %union.anon.54* %235 to i32*
  %237 = sext i32 %223 to i64
  %238 = shl nsw i64 %237, 2
  br label %239

239:                                              ; preds = %234, %227
  %240 = phi i64 [ %229, %227 ], [ %238, %234 ]
  %241 = phi i32* [ %233, %227 ], [ %236, %234 ]
  %242 = bitcast i32* %241 to i8*
  %243 = bitcast i32* %224 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %242, i8* align 4 %243, i64 %240, i1 false) #19
  %244 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 1
  %245 = bitcast %union.TfLitePtrUnion* %244 to float**
  %246 = load float*, float** %245, align 8
  br label %247

247:                                              ; preds = %217, %239
  %248 = phi i32 [ %223, %239 ], [ 0, %217 ]
  %249 = phi float* [ %246, %239 ], [ null, %217 ]
  %250 = bitcast %"class.tflite::RuntimeShape"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %250) #19
  %251 = icmp eq %struct.TfLiteTensor* %5, null
  br i1 %251, label %252, label %254

252:                                              ; preds = %247
  %253 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %15, i64 0, i32 0
  store i32 0, i32* %253, align 8, !alias.scope !79
  br label %282

254:                                              ; preds = %247
  %255 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 2
  %256 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %255, align 8, !noalias !79
  %257 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %256, i64 0, i32 0
  %258 = load i32, i32* %257, align 4, !noalias !79
  %259 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %256, i64 0, i32 1, i64 0
  %260 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %15, i64 0, i32 0
  store i32 %258, i32* %260, align 8, !alias.scope !79
  %261 = icmp sgt i32 %258, 5
  br i1 %261, label %262, label %269

262:                                              ; preds = %254
  %263 = sext i32 %258 to i64
  %264 = shl nsw i64 %263, 2
  %265 = tail call i8* @_Znam(i64 %264) #18, !noalias !79
  %266 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %15, i64 0, i32 1, i32 0
  %267 = bitcast i32** %266 to i8**
  store i8* %265, i8** %267, align 8, !alias.scope !79
  %268 = bitcast i8* %265 to i32*
  br label %274

269:                                              ; preds = %254
  %270 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %15, i64 0, i32 1
  %271 = bitcast %union.anon.54* %270 to i32*
  %272 = sext i32 %258 to i64
  %273 = shl nsw i64 %272, 2
  br label %274

274:                                              ; preds = %269, %262
  %275 = phi i64 [ %264, %262 ], [ %273, %269 ]
  %276 = phi i32* [ %268, %262 ], [ %271, %269 ]
  %277 = bitcast i32* %276 to i8*
  %278 = bitcast i32* %259 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %277, i8* align 4 %278, i64 %275, i1 false) #19
  %279 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 1
  %280 = bitcast %union.TfLitePtrUnion* %279 to float**
  %281 = load float*, float** %280, align 8
  br label %282

282:                                              ; preds = %252, %274
  %283 = phi i32 [ %258, %274 ], [ 0, %252 ]
  %284 = phi float* [ %281, %274 ], [ null, %252 ]
  %285 = bitcast %"class.tflite::RuntimeShape"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %285) #19
  %286 = icmp eq %struct.TfLiteTensor* %6, null
  br i1 %286, label %287, label %289

287:                                              ; preds = %282
  %288 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %16, i64 0, i32 0
  store i32 0, i32* %288, align 8, !alias.scope !82
  br label %317

289:                                              ; preds = %282
  %290 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 2
  %291 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %290, align 8, !noalias !82
  %292 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %291, i64 0, i32 0
  %293 = load i32, i32* %292, align 4, !noalias !82
  %294 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %291, i64 0, i32 1, i64 0
  %295 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %16, i64 0, i32 0
  store i32 %293, i32* %295, align 8, !alias.scope !82
  %296 = icmp sgt i32 %293, 5
  br i1 %296, label %297, label %304

297:                                              ; preds = %289
  %298 = sext i32 %293 to i64
  %299 = shl nsw i64 %298, 2
  %300 = tail call i8* @_Znam(i64 %299) #18, !noalias !82
  %301 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %16, i64 0, i32 1, i32 0
  %302 = bitcast i32** %301 to i8**
  store i8* %300, i8** %302, align 8, !alias.scope !82
  %303 = bitcast i8* %300 to i32*
  br label %309

304:                                              ; preds = %289
  %305 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %16, i64 0, i32 1
  %306 = bitcast %union.anon.54* %305 to i32*
  %307 = sext i32 %293 to i64
  %308 = shl nsw i64 %307, 2
  br label %309

309:                                              ; preds = %304, %297
  %310 = phi i64 [ %299, %297 ], [ %308, %304 ]
  %311 = phi i32* [ %303, %297 ], [ %306, %304 ]
  %312 = bitcast i32* %311 to i8*
  %313 = bitcast i32* %294 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %312, i8* align 4 %313, i64 %310, i1 false) #19
  %314 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 1
  %315 = bitcast %union.TfLitePtrUnion* %314 to float**
  %316 = load float*, float** %315, align 8
  br label %317

317:                                              ; preds = %287, %309
  %318 = phi i32 [ %293, %309 ], [ 0, %287 ]
  %319 = phi float* [ %316, %309 ], [ null, %287 ]
  %320 = bitcast %"class.tflite::RuntimeShape"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %320) #19
  %321 = icmp eq %struct.TfLiteTensor* %7, null
  br i1 %321, label %322, label %325

322:                                              ; preds = %317
  %323 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %17, i64 0, i32 0
  store i32 0, i32* %323, align 8, !alias.scope !85
  %324 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %17, i64 0, i32 1
  br label %402

325:                                              ; preds = %317
  %326 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 2
  %327 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %326, align 8, !noalias !85
  %328 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %327, i64 0, i32 0
  %329 = load i32, i32* %328, align 4, !noalias !85
  %330 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %327, i64 0, i32 1, i64 0
  %331 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %17, i64 0, i32 0
  store i32 %329, i32* %331, align 8, !alias.scope !85
  %332 = icmp sgt i32 %329, 5
  br i1 %332, label %333, label %340

333:                                              ; preds = %325
  %334 = sext i32 %329 to i64
  %335 = shl nsw i64 %334, 2
  %336 = tail call i8* @_Znam(i64 %335) #18, !noalias !85
  %337 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %17, i64 0, i32 1, i32 0
  %338 = bitcast i32** %337 to i8**
  store i8* %336, i8** %338, align 8, !alias.scope !85
  %339 = bitcast i8* %336 to i32*
  br label %345

340:                                              ; preds = %325
  %341 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %17, i64 0, i32 1
  %342 = bitcast %union.anon.54* %341 to i32*
  %343 = sext i32 %329 to i64
  %344 = shl nsw i64 %343, 2
  br label %345

345:                                              ; preds = %333, %340
  %346 = phi i64 [ %335, %333 ], [ %344, %340 ]
  %347 = phi i32* [ %339, %333 ], [ %342, %340 ]
  %348 = bitcast i32* %347 to i8*
  %349 = bitcast i32* %330 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %348, i8* align 4 %349, i64 %346, i1 false) #19
  %350 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 1
  %351 = bitcast %union.TfLitePtrUnion* %350 to float**
  %352 = load float*, float** %351, align 8
  %353 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %17, i64 0, i32 1, i32 0
  %354 = load i32*, i32** %353, align 8
  %355 = bitcast i32* %354 to i8*
  %356 = add nsw i32 %329, -1
  %357 = icmp sgt i32 %329, 5
  %358 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %17, i64 0, i32 1
  %359 = bitcast %union.anon.54* %358 to i32*
  %360 = select i1 %357, i32* %354, i32* %359
  %361 = icmp sgt i32 %329, 0
  br i1 %361, label %362, label %402

362:                                              ; preds = %345
  %363 = zext i32 %356 to i64
  %364 = zext i32 %329 to i64
  %365 = add nsw i64 %364, -1
  %366 = and i64 %364, 3
  %367 = icmp ult i64 %365, 3
  br i1 %367, label %383, label %368

368:                                              ; preds = %362
  %369 = sub nsw i64 %364, %366
  br label %370

370:                                              ; preds = %561, %368
  %371 = phi i64 [ 0, %368 ], [ %564, %561 ]
  %372 = phi i32 [ 1, %368 ], [ %563, %561 ]
  %373 = phi i64 [ %369, %368 ], [ %565, %561 ]
  %374 = icmp eq i64 %371, %363
  br i1 %374, label %378, label %375

375:                                              ; preds = %370
  %376 = getelementptr inbounds i32, i32* %360, i64 %371
  %377 = load i32, i32* %376, align 4
  br label %378

378:                                              ; preds = %375, %370
  %379 = phi i32 [ %377, %375 ], [ 1, %370 ]
  %380 = mul nsw i32 %379, %372
  %381 = or i64 %371, 1
  %382 = icmp eq i64 %381, %363
  br i1 %382, label %545, label %542

383:                                              ; preds = %561, %362
  %384 = phi i32 [ undef, %362 ], [ %563, %561 ]
  %385 = phi i64 [ 0, %362 ], [ %564, %561 ]
  %386 = phi i32 [ 1, %362 ], [ %563, %561 ]
  %387 = icmp eq i64 %366, 0
  br i1 %387, label %402, label %388

388:                                              ; preds = %383, %396
  %389 = phi i64 [ %399, %396 ], [ %385, %383 ]
  %390 = phi i32 [ %398, %396 ], [ %386, %383 ]
  %391 = phi i64 [ %400, %396 ], [ %366, %383 ]
  %392 = icmp eq i64 %389, %363
  br i1 %392, label %396, label %393

393:                                              ; preds = %388
  %394 = getelementptr inbounds i32, i32* %360, i64 %389
  %395 = load i32, i32* %394, align 4
  br label %396

396:                                              ; preds = %393, %388
  %397 = phi i32 [ %395, %393 ], [ 1, %388 ]
  %398 = mul nsw i32 %397, %390
  %399 = add nuw nsw i64 %389, 1
  %400 = add i64 %391, -1
  %401 = icmp eq i64 %400, 0
  br i1 %401, label %402, label %388, !llvm.loop !88

402:                                              ; preds = %383, %396, %322, %345
  %403 = phi %union.anon.54* [ %358, %345 ], [ %324, %322 ], [ %358, %396 ], [ %358, %383 ]
  %404 = phi i1 [ %357, %345 ], [ false, %322 ], [ %357, %396 ], [ %357, %383 ]
  %405 = phi i32 [ %356, %345 ], [ -1, %322 ], [ %356, %396 ], [ %356, %383 ]
  %406 = phi float* [ %352, %345 ], [ null, %322 ], [ %352, %396 ], [ %352, %383 ]
  %407 = phi i32* [ %354, %345 ], [ undef, %322 ], [ %354, %396 ], [ %354, %383 ]
  %408 = phi i8* [ %355, %345 ], [ undef, %322 ], [ %355, %396 ], [ %355, %383 ]
  %409 = phi i32 [ 1, %345 ], [ 1, %322 ], [ %384, %383 ], [ %398, %396 ]
  %410 = add nsw i32 %283, -2
  %411 = icmp sgt i32 %283, 5
  %412 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %15, i64 0, i32 1
  %413 = getelementptr inbounds %union.anon.54, %union.anon.54* %412, i64 0, i32 0
  %414 = load i32*, i32** %413, align 8
  %415 = sext i32 %410 to i64
  %416 = getelementptr inbounds i32, i32* %414, i64 %415
  %417 = bitcast %union.anon.54* %412 to [5 x i32]*
  %418 = getelementptr inbounds [5 x i32], [5 x i32]* %417, i64 0, i64 %415
  %419 = select i1 %411, i32* %416, i32* %418
  %420 = load i32, i32* %419, align 4
  %421 = sext i32 %405 to i64
  %422 = getelementptr inbounds i32, i32* %407, i64 %421
  %423 = bitcast %union.anon.54* %403 to [5 x i32]*
  %424 = getelementptr inbounds [5 x i32], [5 x i32]* %423, i64 0, i64 %421
  %425 = select i1 %404, i32* %422, i32* %424
  %426 = load i32, i32* %425, align 4
  %427 = icmp slt i32 %426, %420
  %428 = select i1 %427, i32 %426, i32 %420
  %429 = add nsw i32 %283, -1
  %430 = sext i32 %429 to i64
  %431 = getelementptr inbounds i32, i32* %414, i64 %430
  %432 = getelementptr inbounds [5 x i32], [5 x i32]* %417, i64 0, i64 %430
  %433 = select i1 %411, i32* %431, i32* %432
  %434 = load i32, i32* %433, align 4
  %435 = icmp sgt i32 %409, 0
  br i1 %435, label %436, label %513

436:                                              ; preds = %402
  %437 = icmp sgt i32 %428, 0
  %438 = icmp sgt i32 %434, 0
  %439 = icmp eq float* %319, null
  %440 = sext i32 %434 to i64
  %441 = sext i32 %428 to i64
  %442 = zext i32 %409 to i64
  %443 = zext i32 %434 to i64
  %444 = and i64 %443, 1
  %445 = icmp eq i32 %434, 1
  %446 = sub nsw i64 %443, %444
  %447 = icmp eq i64 %444, 0
  br label %448

448:                                              ; preds = %457, %436
  %449 = phi i64 [ 0, %436 ], [ %458, %457 ]
  br i1 %437, label %450, label %457

450:                                              ; preds = %448
  %451 = mul nsw i64 %449, %440
  %452 = mul nsw i64 %449, %441
  br label %453

453:                                              ; preds = %502, %450
  %454 = phi i64 [ 0, %450 ], [ %511, %502 ]
  br i1 %438, label %455, label %473

455:                                              ; preds = %453
  %456 = mul nsw i64 %454, %440
  br i1 %445, label %460, label %475

457:                                              ; preds = %502, %448
  %458 = add nuw nsw i64 %449, 1
  %459 = icmp eq i64 %458, %442
  br i1 %459, label %513, label %448

460:                                              ; preds = %475, %455
  %461 = phi float [ undef, %455 ], [ %495, %475 ]
  %462 = phi i64 [ 0, %455 ], [ %496, %475 ]
  %463 = phi float [ 0.000000e+00, %455 ], [ %495, %475 ]
  br i1 %447, label %473, label %464

464:                                              ; preds = %460
  %465 = add nsw i64 %462, %451
  %466 = getelementptr inbounds float, float* %249, i64 %465
  %467 = load float, float* %466, align 4
  %468 = add nsw i64 %462, %456
  %469 = getelementptr inbounds float, float* %284, i64 %468
  %470 = load float, float* %469, align 4
  %471 = fmul float %467, %470
  %472 = fadd float %463, %471
  br label %473

473:                                              ; preds = %464, %460, %453
  %474 = phi float [ 0.000000e+00, %453 ], [ %461, %460 ], [ %472, %464 ]
  br i1 %439, label %502, label %499

475:                                              ; preds = %455, %475
  %476 = phi i64 [ %496, %475 ], [ 0, %455 ]
  %477 = phi float [ %495, %475 ], [ 0.000000e+00, %455 ]
  %478 = phi i64 [ %497, %475 ], [ %446, %455 ]
  %479 = add nsw i64 %476, %451
  %480 = getelementptr inbounds float, float* %249, i64 %479
  %481 = load float, float* %480, align 4
  %482 = add nsw i64 %476, %456
  %483 = getelementptr inbounds float, float* %284, i64 %482
  %484 = load float, float* %483, align 4
  %485 = fmul float %481, %484
  %486 = fadd float %477, %485
  %487 = or i64 %476, 1
  %488 = add nsw i64 %487, %451
  %489 = getelementptr inbounds float, float* %249, i64 %488
  %490 = load float, float* %489, align 4
  %491 = add nsw i64 %487, %456
  %492 = getelementptr inbounds float, float* %284, i64 %491
  %493 = load float, float* %492, align 4
  %494 = fmul float %490, %493
  %495 = fadd float %486, %494
  %496 = add nuw nsw i64 %476, 2
  %497 = add i64 %478, -2
  %498 = icmp eq i64 %497, 0
  br i1 %498, label %460, label %475

499:                                              ; preds = %473
  %500 = getelementptr inbounds float, float* %319, i64 %454
  %501 = load float, float* %500, align 4
  br label %502

502:                                              ; preds = %499, %473
  %503 = phi float [ %501, %499 ], [ 0.000000e+00, %473 ]
  %504 = fadd float %474, %503
  %505 = fcmp olt float %504, %30
  %506 = select i1 %505, float %30, float %504
  %507 = fcmp ogt float %506, %31
  %508 = select i1 %507, float %31, float %506
  %509 = add nsw i64 %454, %452
  %510 = getelementptr inbounds float, float* %406, i64 %509
  store float %508, float* %510, align 4
  %511 = add nuw nsw i64 %454, 1
  %512 = icmp slt i64 %511, %441
  br i1 %512, label %453, label %457

513:                                              ; preds = %457, %402
  %514 = xor i1 %404, true
  %515 = icmp eq i32* %407, null
  %516 = or i1 %515, %514
  br i1 %516, label %518, label %517

517:                                              ; preds = %513
  tail call void @_ZdaPv(i8* %408) #18
  br label %518

518:                                              ; preds = %513, %517
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %320) #19
  %519 = icmp sgt i32 %318, 5
  br i1 %519, label %520, label %526

520:                                              ; preds = %518
  %521 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %16, i64 0, i32 1, i32 0
  %522 = load i32*, i32** %521, align 8
  %523 = icmp eq i32* %522, null
  br i1 %523, label %526, label %524

524:                                              ; preds = %520
  %525 = bitcast i32* %522 to i8*
  tail call void @_ZdaPv(i8* %525) #18
  br label %526

526:                                              ; preds = %518, %520, %524
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %285) #19
  %527 = xor i1 %411, true
  %528 = icmp eq i32* %414, null
  %529 = or i1 %528, %527
  br i1 %529, label %532, label %530

530:                                              ; preds = %526
  %531 = bitcast i32* %414 to i8*
  tail call void @_ZdaPv(i8* %531) #18
  br label %532

532:                                              ; preds = %526, %530
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %250) #19
  %533 = icmp sgt i32 %248, 5
  br i1 %533, label %534, label %540

534:                                              ; preds = %532
  %535 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 1, i32 0
  %536 = load i32*, i32** %535, align 8
  %537 = icmp eq i32* %536, null
  br i1 %537, label %540, label %538

538:                                              ; preds = %534
  %539 = bitcast i32* %536 to i8*
  tail call void @_ZdaPv(i8* %539) #18
  br label %540

540:                                              ; preds = %538, %534, %532, %212, %208, %204
  %541 = phi i8* [ %39, %204 ], [ %39, %208 ], [ %39, %212 ], [ %215, %532 ], [ %215, %534 ], [ %215, %538 ]
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %541) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %32) #19
  ret i32 0

542:                                              ; preds = %378
  %543 = getelementptr inbounds i32, i32* %360, i64 %381
  %544 = load i32, i32* %543, align 4
  br label %545

545:                                              ; preds = %542, %378
  %546 = phi i32 [ %544, %542 ], [ 1, %378 ]
  %547 = mul nsw i32 %546, %380
  %548 = or i64 %371, 2
  %549 = icmp eq i64 %548, %363
  br i1 %549, label %553, label %550

550:                                              ; preds = %545
  %551 = getelementptr inbounds i32, i32* %360, i64 %548
  %552 = load i32, i32* %551, align 4
  br label %553

553:                                              ; preds = %550, %545
  %554 = phi i32 [ %552, %550 ], [ 1, %545 ]
  %555 = mul nsw i32 %554, %547
  %556 = or i64 %371, 3
  %557 = icmp eq i64 %556, %363
  br i1 %557, label %561, label %558

558:                                              ; preds = %553
  %559 = getelementptr inbounds i32, i32* %360, i64 %556
  %560 = load i32, i32* %559, align 4
  br label %561

561:                                              ; preds = %558, %553
  %562 = phi i32 [ %560, %558 ], [ 1, %553 ]
  %563 = mul nsw i32 %562, %555
  %564 = add nuw nsw i64 %371, 4
  %565 = add i64 %373, -4
  %566 = icmp eq i64 %565, 0
  br i1 %566, label %383, label %370
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i32 @_ZN6tflite3ops7builtin15fully_connected21EvalShuffledQuantizedILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_SH_(%struct.TfLiteContext*, %struct.TfLiteNode*, %struct.TfLiteFullyConnectedParams*, %"struct.tflite::ops::builtin::fully_connected::OpData"*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*) local_unnamed_addr #1 comdat {
  %10 = alloca %"struct.tflite::FullyConnectedParams", align 4
  %11 = alloca %"class.tflite::RuntimeShape", align 8
  %12 = alloca %"class.tflite::RuntimeShape", align 8
  %13 = alloca %"class.tflite::RuntimeShape", align 8
  %14 = alloca %"class.tflite::RuntimeShape", align 8
  %15 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %8, i64 0, i32 0
  %16 = load i32, i32* %15, align 8
  %17 = icmp eq i32 %16, 3
  br i1 %17, label %21, label %18

18:                                               ; preds = %9
  %19 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %20 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %19, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %20(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.34, i64 0, i64 0)) #19
  br label %219

21:                                               ; preds = %9
  %22 = bitcast %"struct.tflite::FullyConnectedParams"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %22) #19
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 4 %22, i8* align 4 bitcast ({ i32, i32, i32, i32, i32, i32, i32, float, float, i8, i8, i8, [1 x i8] }* @__const._ZN6tflite3ops7builtin15fully_connected13EvalQuantizedILNS2_10KernelTypeE2EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_.op_params to i8*), i64 40, i1 false)
  %23 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %10, i64 0, i32 3
  %24 = bitcast %"struct.tflite::ops::builtin::fully_connected::OpData"* %3 to <4 x i32>*
  %25 = load <4 x i32>, <4 x i32>* %24, align 4
  %26 = bitcast i32* %23 to <4 x i32>*
  store <4 x i32> %25, <4 x i32>* %26, align 4
  %27 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 4
  %28 = load i32, i32* %27, align 8
  %29 = icmp eq i32 %28, 1
  %30 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %10, i64 0, i32 9
  %31 = zext i1 %29 to i8
  store i8 %31, i8* %30, align 4
  %32 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 4
  %33 = load i32, i32* %32, align 8
  %34 = icmp eq i32 %33, 1
  %35 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %10, i64 0, i32 10
  %36 = zext i1 %34 to i8
  store i8 %36, i8* %35, align 1
  %37 = bitcast %"class.tflite::RuntimeShape"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %37) #19
  %38 = icmp eq %struct.TfLiteTensor* %4, null
  br i1 %38, label %39, label %41

39:                                               ; preds = %21
  %40 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 0
  store i32 0, i32* %40, align 8, !alias.scope !89
  br label %69

41:                                               ; preds = %21
  %42 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 2
  %43 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %42, align 8, !noalias !89
  %44 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %43, i64 0, i32 0
  %45 = load i32, i32* %44, align 4, !noalias !89
  %46 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %43, i64 0, i32 1, i64 0
  %47 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 0
  store i32 %45, i32* %47, align 8, !alias.scope !89
  %48 = icmp sgt i32 %45, 5
  br i1 %48, label %49, label %56

49:                                               ; preds = %41
  %50 = sext i32 %45 to i64
  %51 = shl nsw i64 %50, 2
  %52 = tail call i8* @_Znam(i64 %51) #18, !noalias !89
  %53 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 1, i32 0
  %54 = bitcast i32** %53 to i8**
  store i8* %52, i8** %54, align 8, !alias.scope !89
  %55 = bitcast i8* %52 to i32*
  br label %61

56:                                               ; preds = %41
  %57 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 1
  %58 = bitcast %union.anon.54* %57 to i32*
  %59 = sext i32 %45 to i64
  %60 = shl nsw i64 %59, 2
  br label %61

61:                                               ; preds = %56, %49
  %62 = phi i64 [ %51, %49 ], [ %60, %56 ]
  %63 = phi i32* [ %55, %49 ], [ %58, %56 ]
  %64 = bitcast i32* %63 to i8*
  %65 = bitcast i32* %46 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %64, i8* align 4 %65, i64 %62, i1 false) #19
  %66 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 1
  %67 = bitcast %union.TfLitePtrUnion* %66 to i8**
  %68 = load i8*, i8** %67, align 8
  br label %69

69:                                               ; preds = %39, %61
  %70 = phi i8* [ %68, %61 ], [ null, %39 ]
  %71 = bitcast %"class.tflite::RuntimeShape"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %71) #19
  %72 = icmp eq %struct.TfLiteTensor* %5, null
  br i1 %72, label %73, label %75

73:                                               ; preds = %69
  %74 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 0
  store i32 0, i32* %74, align 8, !alias.scope !92
  br label %103

75:                                               ; preds = %69
  %76 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 2
  %77 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %76, align 8, !noalias !92
  %78 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %77, i64 0, i32 0
  %79 = load i32, i32* %78, align 4, !noalias !92
  %80 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %77, i64 0, i32 1, i64 0
  %81 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 0
  store i32 %79, i32* %81, align 8, !alias.scope !92
  %82 = icmp sgt i32 %79, 5
  br i1 %82, label %83, label %90

83:                                               ; preds = %75
  %84 = sext i32 %79 to i64
  %85 = shl nsw i64 %84, 2
  %86 = tail call i8* @_Znam(i64 %85) #18, !noalias !92
  %87 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 1, i32 0
  %88 = bitcast i32** %87 to i8**
  store i8* %86, i8** %88, align 8, !alias.scope !92
  %89 = bitcast i8* %86 to i32*
  br label %95

90:                                               ; preds = %75
  %91 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 1
  %92 = bitcast %union.anon.54* %91 to i32*
  %93 = sext i32 %79 to i64
  %94 = shl nsw i64 %93, 2
  br label %95

95:                                               ; preds = %90, %83
  %96 = phi i64 [ %85, %83 ], [ %94, %90 ]
  %97 = phi i32* [ %89, %83 ], [ %92, %90 ]
  %98 = bitcast i32* %97 to i8*
  %99 = bitcast i32* %80 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %98, i8* align 4 %99, i64 %96, i1 false) #19
  %100 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 1
  %101 = bitcast %union.TfLitePtrUnion* %100 to i8**
  %102 = load i8*, i8** %101, align 8
  br label %103

103:                                              ; preds = %73, %95
  %104 = phi i8* [ %102, %95 ], [ null, %73 ]
  %105 = bitcast %"class.tflite::RuntimeShape"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %105) #19
  %106 = icmp eq %struct.TfLiteTensor* %6, null
  br i1 %106, label %107, label %109

107:                                              ; preds = %103
  %108 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 0
  store i32 0, i32* %108, align 8, !alias.scope !95
  br label %136

109:                                              ; preds = %103
  %110 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 2
  %111 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %110, align 8, !noalias !95
  %112 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %111, i64 0, i32 0
  %113 = load i32, i32* %112, align 4, !noalias !95
  %114 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %111, i64 0, i32 1, i64 0
  %115 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 0
  store i32 %113, i32* %115, align 8, !alias.scope !95
  %116 = icmp sgt i32 %113, 5
  br i1 %116, label %117, label %124

117:                                              ; preds = %109
  %118 = sext i32 %113 to i64
  %119 = shl nsw i64 %118, 2
  %120 = tail call i8* @_Znam(i64 %119) #18, !noalias !95
  %121 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 1, i32 0
  %122 = bitcast i32** %121 to i8**
  store i8* %120, i8** %122, align 8, !alias.scope !95
  %123 = bitcast i8* %120 to i32*
  br label %129

124:                                              ; preds = %109
  %125 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 1
  %126 = bitcast %union.anon.54* %125 to i32*
  %127 = sext i32 %113 to i64
  %128 = shl nsw i64 %127, 2
  br label %129

129:                                              ; preds = %124, %117
  %130 = phi i64 [ %119, %117 ], [ %128, %124 ]
  %131 = phi i32* [ %123, %117 ], [ %126, %124 ]
  %132 = bitcast i32* %131 to i8*
  %133 = bitcast i32* %114 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %132, i8* align 4 %133, i64 %130, i1 false) #19
  %134 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 1, i32 0
  %135 = load i32*, i32** %134, align 8
  br label %136

136:                                              ; preds = %107, %129
  %137 = phi i32* [ %135, %129 ], [ null, %107 ]
  %138 = bitcast %"class.tflite::RuntimeShape"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %138) #19
  %139 = icmp eq %struct.TfLiteTensor* %7, null
  br i1 %139, label %140, label %142

140:                                              ; preds = %136
  %141 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 0
  store i32 0, i32* %141, align 8, !alias.scope !98
  br label %170

142:                                              ; preds = %136
  %143 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 2
  %144 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %143, align 8, !noalias !98
  %145 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %144, i64 0, i32 0
  %146 = load i32, i32* %145, align 4, !noalias !98
  %147 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %144, i64 0, i32 1, i64 0
  %148 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 0
  store i32 %146, i32* %148, align 8, !alias.scope !98
  %149 = icmp sgt i32 %146, 5
  br i1 %149, label %150, label %157

150:                                              ; preds = %142
  %151 = sext i32 %146 to i64
  %152 = shl nsw i64 %151, 2
  %153 = tail call i8* @_Znam(i64 %152) #18, !noalias !98
  %154 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 1, i32 0
  %155 = bitcast i32** %154 to i8**
  store i8* %153, i8** %155, align 8, !alias.scope !98
  %156 = bitcast i8* %153 to i32*
  br label %162

157:                                              ; preds = %142
  %158 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 1
  %159 = bitcast %union.anon.54* %158 to i32*
  %160 = sext i32 %146 to i64
  %161 = shl nsw i64 %160, 2
  br label %162

162:                                              ; preds = %157, %150
  %163 = phi i64 [ %152, %150 ], [ %161, %157 ]
  %164 = phi i32* [ %156, %150 ], [ %159, %157 ]
  %165 = bitcast i32* %164 to i8*
  %166 = bitcast i32* %147 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %165, i8* align 4 %166, i64 %163, i1 false) #19
  %167 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 1
  %168 = bitcast %union.TfLitePtrUnion* %167 to i16**
  %169 = load i16*, i16** %168, align 8
  br label %170

170:                                              ; preds = %140, %162
  %171 = phi i16* [ %169, %162 ], [ null, %140 ]
  %172 = icmp eq %struct.TfLiteTensor* %8, null
  br i1 %172, label %177, label %173

173:                                              ; preds = %170
  %174 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %8, i64 0, i32 1
  %175 = bitcast %union.TfLitePtrUnion* %174 to i8**
  %176 = load i8*, i8** %175, align 8
  br label %177

177:                                              ; preds = %170, %173
  %178 = phi i8* [ %176, %173 ], [ null, %170 ]
  call void @_ZN6tflite13reference_ops22ShuffledFullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKiS6_PsPh(%"struct.tflite::FullyConnectedParams"* nonnull dereferenceable(40) %10, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %11, i8* %70, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %12, i8* %104, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %13, i32* %137, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %14, i16* %171, i8* %178)
  %179 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 0
  %180 = load i32, i32* %179, align 8
  %181 = icmp sgt i32 %180, 5
  br i1 %181, label %182, label %188

182:                                              ; preds = %177
  %183 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 1, i32 0
  %184 = load i32*, i32** %183, align 8
  %185 = icmp eq i32* %184, null
  br i1 %185, label %188, label %186

186:                                              ; preds = %182
  %187 = bitcast i32* %184 to i8*
  call void @_ZdaPv(i8* %187) #18
  br label %188

188:                                              ; preds = %177, %182, %186
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %138) #19
  %189 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 0
  %190 = load i32, i32* %189, align 8
  %191 = icmp sgt i32 %190, 5
  br i1 %191, label %192, label %198

192:                                              ; preds = %188
  %193 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 1, i32 0
  %194 = load i32*, i32** %193, align 8
  %195 = icmp eq i32* %194, null
  br i1 %195, label %198, label %196

196:                                              ; preds = %192
  %197 = bitcast i32* %194 to i8*
  call void @_ZdaPv(i8* %197) #18
  br label %198

198:                                              ; preds = %188, %192, %196
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %105) #19
  %199 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 0
  %200 = load i32, i32* %199, align 8
  %201 = icmp sgt i32 %200, 5
  br i1 %201, label %202, label %208

202:                                              ; preds = %198
  %203 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 1, i32 0
  %204 = load i32*, i32** %203, align 8
  %205 = icmp eq i32* %204, null
  br i1 %205, label %208, label %206

206:                                              ; preds = %202
  %207 = bitcast i32* %204 to i8*
  call void @_ZdaPv(i8* %207) #18
  br label %208

208:                                              ; preds = %198, %202, %206
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %71) #19
  %209 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 0
  %210 = load i32, i32* %209, align 8
  %211 = icmp sgt i32 %210, 5
  br i1 %211, label %212, label %218

212:                                              ; preds = %208
  %213 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 1, i32 0
  %214 = load i32*, i32** %213, align 8
  %215 = icmp eq i32* %214, null
  br i1 %215, label %218, label %216

216:                                              ; preds = %212
  %217 = bitcast i32* %214 to i8*
  call void @_ZdaPv(i8* %217) #18
  br label %218

218:                                              ; preds = %208, %212, %216
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %37) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %22) #19
  br label %219

219:                                              ; preds = %218, %18
  %220 = phi i32 [ 1, %18 ], [ 0, %218 ]
  ret i32 %220
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i32 @_ZN6tflite3ops7builtin15fully_connected13EvalQuantizedILNS2_10KernelTypeE0EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_(%struct.TfLiteContext*, %struct.TfLiteNode*, %struct.TfLiteFullyConnectedParams*, %"struct.tflite::ops::builtin::fully_connected::OpData"*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*) local_unnamed_addr #1 comdat {
  %9 = alloca %"class.tflite::RuntimeShape", align 8
  %10 = alloca %"class.tflite::RuntimeShape", align 8
  %11 = alloca %"class.tflite::RuntimeShape", align 8
  %12 = alloca %"class.tflite::RuntimeShape", align 8
  %13 = alloca %"class.tflite::RuntimeShape", align 8
  %14 = alloca %"class.tflite::RuntimeShape", align 8
  %15 = alloca %"class.tflite::RuntimeShape", align 8
  %16 = alloca %"class.tflite::RuntimeShape", align 8
  %17 = alloca %"struct.tflite::FullyConnectedParams", align 4
  %18 = alloca %"class.tflite::RuntimeShape", align 8
  %19 = alloca %"class.tflite::RuntimeShape", align 8
  %20 = alloca %"class.tflite::RuntimeShape", align 8
  %21 = alloca %"class.tflite::RuntimeShape", align 8
  %22 = alloca %"class.tflite::RuntimeShape", align 8
  %23 = alloca %"class.tflite::RuntimeShape", align 8
  %24 = alloca %"class.tflite::RuntimeShape", align 8
  %25 = alloca %"class.tflite::RuntimeShape", align 8
  %26 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 0
  %27 = load i32, i32* %26, align 8
  %28 = icmp eq i32 %27, 1
  br i1 %28, label %29, label %83

29:                                               ; preds = %8
  %30 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 3
  %31 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %30, align 8
  %32 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %31, i64 0, i32 1, i64 0
  %33 = load i32, i32* %32, align 4
  %34 = icmp slt i32 %33, 0
  br i1 %34, label %40, label %35

35:                                               ; preds = %29
  %36 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %37 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %36, align 8
  %38 = sext i32 %33 to i64
  %39 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %37, i64 %38
  br label %40

40:                                               ; preds = %29, %35
  %41 = phi %struct.TfLiteTensor* [ %39, %35 ], [ null, %29 ]
  %42 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %31, i64 0, i32 1, i64 1
  %43 = load i32, i32* %42, align 4
  %44 = icmp slt i32 %43, 0
  br i1 %44, label %50, label %45

45:                                               ; preds = %40
  %46 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %47 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %46, align 8
  %48 = sext i32 %43 to i64
  %49 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %47, i64 %48
  br label %50

50:                                               ; preds = %40, %45
  %51 = phi %struct.TfLiteTensor* [ %49, %45 ], [ null, %40 ]
  %52 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %31, i64 0, i32 1, i64 2
  %53 = load i32, i32* %52, align 4
  %54 = icmp slt i32 %53, 0
  br i1 %54, label %60, label %55

55:                                               ; preds = %50
  %56 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %57 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %56, align 8
  %58 = sext i32 %53 to i64
  %59 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %57, i64 %58
  br label %60

60:                                               ; preds = %50, %55
  %61 = phi %struct.TfLiteTensor* [ %59, %55 ], [ null, %50 ]
  %62 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %31, i64 0, i32 1, i64 3
  %63 = load i32, i32* %62, align 4
  %64 = icmp slt i32 %63, 0
  br i1 %64, label %70, label %65

65:                                               ; preds = %60
  %66 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %67 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %66, align 8
  %68 = sext i32 %63 to i64
  %69 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %67, i64 %68
  br label %70

70:                                               ; preds = %60, %65
  %71 = phi %struct.TfLiteTensor* [ %69, %65 ], [ null, %60 ]
  %72 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %31, i64 0, i32 1, i64 4
  %73 = load i32, i32* %72, align 4
  %74 = icmp slt i32 %73, 0
  br i1 %74, label %80, label %75

75:                                               ; preds = %70
  %76 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %77 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %76, align 8
  %78 = sext i32 %73 to i64
  %79 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %77, i64 %78
  br label %80

80:                                               ; preds = %70, %75
  %81 = phi %struct.TfLiteTensor* [ %79, %75 ], [ null, %70 ]
  %82 = tail call i32 @_ZN6tflite3ops7builtin15fully_connected10EvalHybridEP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_SE_SE_SE_SE_SE_(%struct.TfLiteContext* %0, %struct.TfLiteNode* undef, %struct.TfLiteFullyConnectedParams* %2, %"struct.tflite::ops::builtin::fully_connected::OpData"* %3, %struct.TfLiteTensor* %4, %struct.TfLiteTensor* %5, %struct.TfLiteTensor* %6, %struct.TfLiteTensor* %41, %struct.TfLiteTensor* %51, %struct.TfLiteTensor* %61, %struct.TfLiteTensor* %81, %struct.TfLiteTensor* %71, %struct.TfLiteTensor* %7)
  ret i32 0

83:                                               ; preds = %8
  %84 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 3, i32 1
  %85 = load i32, i32* %84, align 4
  %86 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 3, i32 1
  %87 = load i32, i32* %86, align 4
  %88 = sub nsw i32 0, %87
  %89 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 3, i32 1
  %90 = load i32, i32* %89, align 4
  %91 = sub nsw i32 0, %90
  %92 = bitcast %"struct.tflite::FullyConnectedParams"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %92) #19
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 4 %92, i8* align 4 bitcast ({ i32, i32, i32, i32, i32, i32, i32, float, float, i8, i8, i8, [1 x i8] }* @__const._ZN6tflite3ops7builtin15fully_connected13EvalQuantizedILNS2_10KernelTypeE2EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_.op_params to i8*), i64 40, i1 false)
  %93 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %17, i64 0, i32 0
  store i32 %91, i32* %93, align 4
  %94 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %17, i64 0, i32 1
  store i32 %88, i32* %94, align 4
  %95 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %17, i64 0, i32 2
  store i32 %85, i32* %95, align 4
  %96 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %17, i64 0, i32 3
  %97 = bitcast %"struct.tflite::ops::builtin::fully_connected::OpData"* %3 to <4 x i32>*
  %98 = load <4 x i32>, <4 x i32>* %97, align 4
  %99 = bitcast i32* %96 to <4 x i32>*
  store <4 x i32> %98, <4 x i32>* %99, align 4
  %100 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 4
  %101 = load i32, i32* %100, align 8
  %102 = icmp eq i32 %101, 1
  %103 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %17, i64 0, i32 9
  %104 = zext i1 %102 to i8
  store i8 %104, i8* %103, align 4
  %105 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 4
  %106 = load i32, i32* %105, align 8
  %107 = icmp eq i32 %106, 1
  %108 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %17, i64 0, i32 10
  %109 = zext i1 %107 to i8
  store i8 %109, i8* %108, align 1
  %110 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 0
  %111 = load i32, i32* %110, align 8
  switch i32 %111, label %1151 [
    i32 3, label %112
    i32 9, label %287
    i32 7, label %668
  ]

112:                                              ; preds = %83
  %113 = bitcast %"class.tflite::RuntimeShape"* %18 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %113) #19
  %114 = icmp eq %struct.TfLiteTensor* %4, null
  br i1 %114, label %115, label %117

115:                                              ; preds = %112
  %116 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %18, i64 0, i32 0
  store i32 0, i32* %116, align 8, !alias.scope !101
  br label %145

117:                                              ; preds = %112
  %118 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 2
  %119 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %118, align 8, !noalias !101
  %120 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %119, i64 0, i32 0
  %121 = load i32, i32* %120, align 4, !noalias !101
  %122 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %119, i64 0, i32 1, i64 0
  %123 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %18, i64 0, i32 0
  store i32 %121, i32* %123, align 8, !alias.scope !101
  %124 = icmp sgt i32 %121, 5
  br i1 %124, label %125, label %132

125:                                              ; preds = %117
  %126 = sext i32 %121 to i64
  %127 = shl nsw i64 %126, 2
  %128 = tail call i8* @_Znam(i64 %127) #18, !noalias !101
  %129 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %18, i64 0, i32 1, i32 0
  %130 = bitcast i32** %129 to i8**
  store i8* %128, i8** %130, align 8, !alias.scope !101
  %131 = bitcast i8* %128 to i32*
  br label %137

132:                                              ; preds = %117
  %133 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %18, i64 0, i32 1
  %134 = bitcast %union.anon.54* %133 to i32*
  %135 = sext i32 %121 to i64
  %136 = shl nsw i64 %135, 2
  br label %137

137:                                              ; preds = %132, %125
  %138 = phi i64 [ %127, %125 ], [ %136, %132 ]
  %139 = phi i32* [ %131, %125 ], [ %134, %132 ]
  %140 = bitcast i32* %139 to i8*
  %141 = bitcast i32* %122 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %140, i8* align 4 %141, i64 %138, i1 false) #19
  %142 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 1
  %143 = bitcast %union.TfLitePtrUnion* %142 to i8**
  %144 = load i8*, i8** %143, align 8
  br label %145

145:                                              ; preds = %115, %137
  %146 = phi i8* [ %144, %137 ], [ null, %115 ]
  %147 = bitcast %"class.tflite::RuntimeShape"* %19 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %147) #19
  %148 = icmp eq %struct.TfLiteTensor* %5, null
  br i1 %148, label %149, label %151

149:                                              ; preds = %145
  %150 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %19, i64 0, i32 0
  store i32 0, i32* %150, align 8, !alias.scope !104
  br label %179

151:                                              ; preds = %145
  %152 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 2
  %153 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %152, align 8, !noalias !104
  %154 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %153, i64 0, i32 0
  %155 = load i32, i32* %154, align 4, !noalias !104
  %156 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %153, i64 0, i32 1, i64 0
  %157 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %19, i64 0, i32 0
  store i32 %155, i32* %157, align 8, !alias.scope !104
  %158 = icmp sgt i32 %155, 5
  br i1 %158, label %159, label %166

159:                                              ; preds = %151
  %160 = sext i32 %155 to i64
  %161 = shl nsw i64 %160, 2
  %162 = tail call i8* @_Znam(i64 %161) #18, !noalias !104
  %163 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %19, i64 0, i32 1, i32 0
  %164 = bitcast i32** %163 to i8**
  store i8* %162, i8** %164, align 8, !alias.scope !104
  %165 = bitcast i8* %162 to i32*
  br label %171

166:                                              ; preds = %151
  %167 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %19, i64 0, i32 1
  %168 = bitcast %union.anon.54* %167 to i32*
  %169 = sext i32 %155 to i64
  %170 = shl nsw i64 %169, 2
  br label %171

171:                                              ; preds = %166, %159
  %172 = phi i64 [ %161, %159 ], [ %170, %166 ]
  %173 = phi i32* [ %165, %159 ], [ %168, %166 ]
  %174 = bitcast i32* %173 to i8*
  %175 = bitcast i32* %156 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %174, i8* align 4 %175, i64 %172, i1 false) #19
  %176 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 1
  %177 = bitcast %union.TfLitePtrUnion* %176 to i8**
  %178 = load i8*, i8** %177, align 8
  br label %179

179:                                              ; preds = %149, %171
  %180 = phi i8* [ %178, %171 ], [ null, %149 ]
  %181 = bitcast %"class.tflite::RuntimeShape"* %20 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %181) #19
  %182 = icmp eq %struct.TfLiteTensor* %6, null
  br i1 %182, label %183, label %185

183:                                              ; preds = %179
  %184 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %20, i64 0, i32 0
  store i32 0, i32* %184, align 8, !alias.scope !107
  br label %212

185:                                              ; preds = %179
  %186 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 2
  %187 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %186, align 8, !noalias !107
  %188 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %187, i64 0, i32 0
  %189 = load i32, i32* %188, align 4, !noalias !107
  %190 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %187, i64 0, i32 1, i64 0
  %191 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %20, i64 0, i32 0
  store i32 %189, i32* %191, align 8, !alias.scope !107
  %192 = icmp sgt i32 %189, 5
  br i1 %192, label %193, label %200

193:                                              ; preds = %185
  %194 = sext i32 %189 to i64
  %195 = shl nsw i64 %194, 2
  %196 = tail call i8* @_Znam(i64 %195) #18, !noalias !107
  %197 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %20, i64 0, i32 1, i32 0
  %198 = bitcast i32** %197 to i8**
  store i8* %196, i8** %198, align 8, !alias.scope !107
  %199 = bitcast i8* %196 to i32*
  br label %205

200:                                              ; preds = %185
  %201 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %20, i64 0, i32 1
  %202 = bitcast %union.anon.54* %201 to i32*
  %203 = sext i32 %189 to i64
  %204 = shl nsw i64 %203, 2
  br label %205

205:                                              ; preds = %200, %193
  %206 = phi i64 [ %195, %193 ], [ %204, %200 ]
  %207 = phi i32* [ %199, %193 ], [ %202, %200 ]
  %208 = bitcast i32* %207 to i8*
  %209 = bitcast i32* %190 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %208, i8* align 4 %209, i64 %206, i1 false) #19
  %210 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 1, i32 0
  %211 = load i32*, i32** %210, align 8
  br label %212

212:                                              ; preds = %183, %205
  %213 = phi i32* [ %211, %205 ], [ null, %183 ]
  %214 = bitcast %"class.tflite::RuntimeShape"* %21 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %214) #19
  %215 = icmp eq %struct.TfLiteTensor* %7, null
  br i1 %215, label %216, label %218

216:                                              ; preds = %212
  %217 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %21, i64 0, i32 0
  store i32 0, i32* %217, align 8, !alias.scope !110
  br label %246

218:                                              ; preds = %212
  %219 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 2
  %220 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %219, align 8, !noalias !110
  %221 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %220, i64 0, i32 0
  %222 = load i32, i32* %221, align 4, !noalias !110
  %223 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %220, i64 0, i32 1, i64 0
  %224 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %21, i64 0, i32 0
  store i32 %222, i32* %224, align 8, !alias.scope !110
  %225 = icmp sgt i32 %222, 5
  br i1 %225, label %226, label %233

226:                                              ; preds = %218
  %227 = sext i32 %222 to i64
  %228 = shl nsw i64 %227, 2
  %229 = tail call i8* @_Znam(i64 %228) #18, !noalias !110
  %230 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %21, i64 0, i32 1, i32 0
  %231 = bitcast i32** %230 to i8**
  store i8* %229, i8** %231, align 8, !alias.scope !110
  %232 = bitcast i8* %229 to i32*
  br label %238

233:                                              ; preds = %218
  %234 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %21, i64 0, i32 1
  %235 = bitcast %union.anon.54* %234 to i32*
  %236 = sext i32 %222 to i64
  %237 = shl nsw i64 %236, 2
  br label %238

238:                                              ; preds = %233, %226
  %239 = phi i64 [ %228, %226 ], [ %237, %233 ]
  %240 = phi i32* [ %232, %226 ], [ %235, %233 ]
  %241 = bitcast i32* %240 to i8*
  %242 = bitcast i32* %223 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %241, i8* align 4 %242, i64 %239, i1 false) #19
  %243 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 1
  %244 = bitcast %union.TfLitePtrUnion* %243 to i8**
  %245 = load i8*, i8** %244, align 8
  br label %246

246:                                              ; preds = %216, %238
  %247 = phi i8* [ %245, %238 ], [ null, %216 ]
  call void @_ZN6tflite13reference_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKiS6_Ph(%"struct.tflite::FullyConnectedParams"* nonnull dereferenceable(40) %17, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %18, i8* %146, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %19, i8* %180, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %20, i32* %213, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %21, i8* %247)
  %248 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %21, i64 0, i32 0
  %249 = load i32, i32* %248, align 8
  %250 = icmp sgt i32 %249, 5
  br i1 %250, label %251, label %257

251:                                              ; preds = %246
  %252 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %21, i64 0, i32 1, i32 0
  %253 = load i32*, i32** %252, align 8
  %254 = icmp eq i32* %253, null
  br i1 %254, label %257, label %255

255:                                              ; preds = %251
  %256 = bitcast i32* %253 to i8*
  call void @_ZdaPv(i8* %256) #18
  br label %257

257:                                              ; preds = %246, %251, %255
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %214) #19
  %258 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %20, i64 0, i32 0
  %259 = load i32, i32* %258, align 8
  %260 = icmp sgt i32 %259, 5
  br i1 %260, label %261, label %267

261:                                              ; preds = %257
  %262 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %20, i64 0, i32 1, i32 0
  %263 = load i32*, i32** %262, align 8
  %264 = icmp eq i32* %263, null
  br i1 %264, label %267, label %265

265:                                              ; preds = %261
  %266 = bitcast i32* %263 to i8*
  call void @_ZdaPv(i8* %266) #18
  br label %267

267:                                              ; preds = %257, %261, %265
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %181) #19
  %268 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %19, i64 0, i32 0
  %269 = load i32, i32* %268, align 8
  %270 = icmp sgt i32 %269, 5
  br i1 %270, label %271, label %277

271:                                              ; preds = %267
  %272 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %19, i64 0, i32 1, i32 0
  %273 = load i32*, i32** %272, align 8
  %274 = icmp eq i32* %273, null
  br i1 %274, label %277, label %275

275:                                              ; preds = %271
  %276 = bitcast i32* %273 to i8*
  call void @_ZdaPv(i8* %276) #18
  br label %277

277:                                              ; preds = %267, %271, %275
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %147) #19
  %278 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %18, i64 0, i32 0
  %279 = load i32, i32* %278, align 8
  %280 = icmp sgt i32 %279, 5
  br i1 %280, label %281, label %1154

281:                                              ; preds = %277
  %282 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %18, i64 0, i32 1, i32 0
  %283 = load i32*, i32** %282, align 8
  %284 = icmp eq i32* %283, null
  br i1 %284, label %1154, label %285

285:                                              ; preds = %281
  %286 = bitcast i32* %283 to i8*
  call void @_ZdaPv(i8* %286) #18
  br label %1154

287:                                              ; preds = %83
  %288 = getelementptr inbounds %"struct.tflite::ops::builtin::fully_connected::OpData", %"struct.tflite::ops::builtin::fully_connected::OpData"* %3, i64 0, i32 0
  %289 = getelementptr inbounds %"struct.tflite::ops::builtin::fully_connected::OpData", %"struct.tflite::ops::builtin::fully_connected::OpData"* %3, i64 0, i32 3
  %290 = getelementptr inbounds %"struct.tflite::ops::builtin::fully_connected::OpData", %"struct.tflite::ops::builtin::fully_connected::OpData"* %3, i64 0, i32 2
  %291 = getelementptr inbounds %"struct.tflite::ops::builtin::fully_connected::OpData", %"struct.tflite::ops::builtin::fully_connected::OpData"* %3, i64 0, i32 1
  %292 = tail call %"class.tflite::CpuBackendContext"* @_ZN6tflite17CpuBackendContext14GetFromContextEP13TfLiteContext(%struct.TfLiteContext* %0) #19
  %293 = load i32, i32* %89, align 4
  %294 = load i32, i32* %86, align 4
  %295 = load i32, i32* %84, align 4
  %296 = load i32, i32* %288, align 4
  %297 = load i32, i32* %291, align 4
  %298 = load i32, i32* %290, align 4
  %299 = load i32, i32* %289, align 4
  %300 = bitcast %"class.tflite::RuntimeShape"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %300) #19
  %301 = icmp eq %struct.TfLiteTensor* %4, null
  br i1 %301, label %302, label %304

302:                                              ; preds = %287
  %303 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %9, i64 0, i32 0
  store i32 0, i32* %303, align 8, !alias.scope !113
  br label %332

304:                                              ; preds = %287
  %305 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 2
  %306 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %305, align 8, !noalias !113
  %307 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %306, i64 0, i32 0
  %308 = load i32, i32* %307, align 4, !noalias !113
  %309 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %306, i64 0, i32 1, i64 0
  %310 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %9, i64 0, i32 0
  store i32 %308, i32* %310, align 8, !alias.scope !113
  %311 = icmp sgt i32 %308, 5
  br i1 %311, label %312, label %319

312:                                              ; preds = %304
  %313 = sext i32 %308 to i64
  %314 = shl nsw i64 %313, 2
  %315 = tail call i8* @_Znam(i64 %314) #18, !noalias !113
  %316 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %9, i64 0, i32 1, i32 0
  %317 = bitcast i32** %316 to i8**
  store i8* %315, i8** %317, align 8, !alias.scope !113
  %318 = bitcast i8* %315 to i32*
  br label %324

319:                                              ; preds = %304
  %320 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %9, i64 0, i32 1
  %321 = bitcast %union.anon.54* %320 to i32*
  %322 = sext i32 %308 to i64
  %323 = shl nsw i64 %322, 2
  br label %324

324:                                              ; preds = %319, %312
  %325 = phi i64 [ %314, %312 ], [ %323, %319 ]
  %326 = phi i32* [ %318, %312 ], [ %321, %319 ]
  %327 = bitcast i32* %326 to i8*
  %328 = bitcast i32* %309 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %327, i8* align 4 %328, i64 %325, i1 false) #19
  %329 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 1
  %330 = bitcast %union.TfLitePtrUnion* %329 to i8**
  %331 = load i8*, i8** %330, align 8
  br label %332

332:                                              ; preds = %324, %302
  %333 = phi i32 [ %308, %324 ], [ 0, %302 ]
  %334 = phi i8* [ %331, %324 ], [ null, %302 ]
  %335 = bitcast %"class.tflite::RuntimeShape"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %335) #19
  %336 = icmp eq %struct.TfLiteTensor* %5, null
  br i1 %336, label %337, label %339

337:                                              ; preds = %332
  %338 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %10, i64 0, i32 0
  store i32 0, i32* %338, align 8, !alias.scope !116
  br label %367

339:                                              ; preds = %332
  %340 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 2
  %341 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %340, align 8, !noalias !116
  %342 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %341, i64 0, i32 0
  %343 = load i32, i32* %342, align 4, !noalias !116
  %344 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %341, i64 0, i32 1, i64 0
  %345 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %10, i64 0, i32 0
  store i32 %343, i32* %345, align 8, !alias.scope !116
  %346 = icmp sgt i32 %343, 5
  br i1 %346, label %347, label %354

347:                                              ; preds = %339
  %348 = sext i32 %343 to i64
  %349 = shl nsw i64 %348, 2
  %350 = tail call i8* @_Znam(i64 %349) #18, !noalias !116
  %351 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %10, i64 0, i32 1, i32 0
  %352 = bitcast i32** %351 to i8**
  store i8* %350, i8** %352, align 8, !alias.scope !116
  %353 = bitcast i8* %350 to i32*
  br label %359

354:                                              ; preds = %339
  %355 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %10, i64 0, i32 1
  %356 = bitcast %union.anon.54* %355 to i32*
  %357 = sext i32 %343 to i64
  %358 = shl nsw i64 %357, 2
  br label %359

359:                                              ; preds = %354, %347
  %360 = phi i64 [ %349, %347 ], [ %358, %354 ]
  %361 = phi i32* [ %353, %347 ], [ %356, %354 ]
  %362 = bitcast i32* %361 to i8*
  %363 = bitcast i32* %344 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %362, i8* align 4 %363, i64 %360, i1 false) #19
  %364 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 1
  %365 = bitcast %union.TfLitePtrUnion* %364 to i8**
  %366 = load i8*, i8** %365, align 8
  br label %367

367:                                              ; preds = %359, %337
  %368 = phi i32 [ %343, %359 ], [ 0, %337 ]
  %369 = phi i8* [ %366, %359 ], [ null, %337 ]
  %370 = bitcast %"class.tflite::RuntimeShape"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %370) #19
  %371 = icmp eq %struct.TfLiteTensor* %6, null
  br i1 %371, label %372, label %374

372:                                              ; preds = %367
  %373 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 0
  store i32 0, i32* %373, align 8, !alias.scope !119
  br label %401

374:                                              ; preds = %367
  %375 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 2
  %376 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %375, align 8, !noalias !119
  %377 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %376, i64 0, i32 0
  %378 = load i32, i32* %377, align 4, !noalias !119
  %379 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %376, i64 0, i32 1, i64 0
  %380 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 0
  store i32 %378, i32* %380, align 8, !alias.scope !119
  %381 = icmp sgt i32 %378, 5
  br i1 %381, label %382, label %389

382:                                              ; preds = %374
  %383 = sext i32 %378 to i64
  %384 = shl nsw i64 %383, 2
  %385 = tail call i8* @_Znam(i64 %384) #18, !noalias !119
  %386 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 1, i32 0
  %387 = bitcast i32** %386 to i8**
  store i8* %385, i8** %387, align 8, !alias.scope !119
  %388 = bitcast i8* %385 to i32*
  br label %394

389:                                              ; preds = %374
  %390 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 1
  %391 = bitcast %union.anon.54* %390 to i32*
  %392 = sext i32 %378 to i64
  %393 = shl nsw i64 %392, 2
  br label %394

394:                                              ; preds = %389, %382
  %395 = phi i64 [ %384, %382 ], [ %393, %389 ]
  %396 = phi i32* [ %388, %382 ], [ %391, %389 ]
  %397 = bitcast i32* %396 to i8*
  %398 = bitcast i32* %379 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %397, i8* align 4 %398, i64 %395, i1 false) #19
  %399 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 1, i32 0
  %400 = load i32*, i32** %399, align 8
  br label %401

401:                                              ; preds = %394, %372
  %402 = phi i32 [ %378, %394 ], [ 0, %372 ]
  %403 = phi i32* [ %400, %394 ], [ null, %372 ]
  %404 = bitcast %"class.tflite::RuntimeShape"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %404) #19
  %405 = icmp eq %struct.TfLiteTensor* %7, null
  br i1 %405, label %406, label %409

406:                                              ; preds = %401
  %407 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 0
  store i32 0, i32* %407, align 8, !alias.scope !122
  %408 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 1
  br label %442

409:                                              ; preds = %401
  %410 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 2
  %411 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %410, align 8, !noalias !122
  %412 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %411, i64 0, i32 0
  %413 = load i32, i32* %412, align 4, !noalias !122
  %414 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %411, i64 0, i32 1, i64 0
  %415 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 0
  store i32 %413, i32* %415, align 8, !alias.scope !122
  %416 = icmp sgt i32 %413, 5
  br i1 %416, label %417, label %424

417:                                              ; preds = %409
  %418 = sext i32 %413 to i64
  %419 = shl nsw i64 %418, 2
  %420 = tail call i8* @_Znam(i64 %419) #18, !noalias !122
  %421 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 1, i32 0
  %422 = bitcast i32** %421 to i8**
  store i8* %420, i8** %422, align 8, !alias.scope !122
  %423 = bitcast i8* %420 to i32*
  br label %429

424:                                              ; preds = %409
  %425 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 1
  %426 = bitcast %union.anon.54* %425 to i32*
  %427 = sext i32 %413 to i64
  %428 = shl nsw i64 %427, 2
  br label %429

429:                                              ; preds = %424, %417
  %430 = phi i64 [ %419, %417 ], [ %428, %424 ]
  %431 = phi i32* [ %423, %417 ], [ %426, %424 ]
  %432 = bitcast i32* %431 to i8*
  %433 = bitcast i32* %414 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %432, i8* align 4 %433, i64 %430, i1 false) #19
  %434 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 1
  %435 = bitcast %union.TfLitePtrUnion* %434 to i8**
  %436 = load i8*, i8** %435, align 8
  %437 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 1, i32 0
  %438 = load i32*, i32** %437, align 8
  %439 = bitcast i32* %438 to i8*
  %440 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 1
  %441 = getelementptr inbounds i32, i32* %438, i64 1
  br i1 %416, label %450, label %442

442:                                              ; preds = %429, %406
  %443 = phi %union.anon.54* [ %408, %406 ], [ %440, %429 ]
  %444 = phi i8* [ null, %406 ], [ %436, %429 ]
  %445 = phi i32* [ undef, %406 ], [ %438, %429 ]
  %446 = phi i8* [ undef, %406 ], [ %439, %429 ]
  %447 = bitcast %union.anon.54* %443 to [5 x i32]*
  %448 = bitcast %union.anon.54* %443 to i32*
  %449 = getelementptr inbounds [5 x i32], [5 x i32]* %447, i64 0, i64 1
  br label %450

450:                                              ; preds = %442, %429
  %451 = phi i32* [ %448, %442 ], [ %438, %429 ]
  %452 = phi i8* [ %446, %442 ], [ %439, %429 ]
  %453 = phi i32* [ %445, %442 ], [ %438, %429 ]
  %454 = phi i1 [ true, %442 ], [ false, %429 ]
  %455 = phi i8* [ %444, %442 ], [ %436, %429 ]
  %456 = phi i32* [ %449, %442 ], [ %441, %429 ]
  %457 = load i32, i32* %451, align 4
  %458 = load i32, i32* %456, align 4
  %459 = icmp sgt i32 %368, 5
  %460 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %10, i64 0, i32 1
  %461 = add nsw i32 %368, -1
  %462 = getelementptr inbounds %union.anon.54, %union.anon.54* %460, i64 0, i32 0
  %463 = load i32*, i32** %462, align 8
  %464 = sext i32 %461 to i64
  %465 = getelementptr inbounds i32, i32* %463, i64 %464
  %466 = bitcast %union.anon.54* %460 to [5 x i32]*
  %467 = getelementptr inbounds [5 x i32], [5 x i32]* %466, i64 0, i64 %464
  %468 = select i1 %459, i32* %465, i32* %467
  %469 = load i32, i32* %468, align 4
  %470 = icmp sgt i32 %457, 0
  br i1 %470, label %471, label %642

471:                                              ; preds = %450
  %472 = icmp sgt i32 %458, 0
  %473 = icmp sgt i32 %469, 0
  %474 = icmp eq i32* %403, null
  %475 = icmp sgt i32 %297, 0
  %476 = sub nsw i32 0, %297
  %477 = select i1 %475, i32 0, i32 %476
  %478 = shl i32 1, %297
  %479 = select i1 %475, i32 %478, i32 1
  %480 = sext i32 %296 to i64
  %481 = icmp eq i32 %296, -2147483648
  %482 = zext i32 %477 to i64
  %483 = shl nsw i64 -1, %482
  %484 = trunc i64 %483 to i32
  %485 = xor i32 %484, -1
  %486 = ashr i32 %485, 1
  %487 = sext i32 %469 to i64
  %488 = sext i32 %458 to i64
  %489 = zext i32 %457 to i64
  %490 = zext i32 %458 to i64
  %491 = zext i32 %469 to i64
  %492 = and i64 %491, 4294967292
  %493 = add nsw i64 %492, -4
  %494 = lshr exact i64 %493, 2
  %495 = add nuw nsw i64 %494, 1
  %496 = icmp ult i32 %469, 4
  %497 = and i64 %491, 4294967292
  %498 = insertelement <4 x i32> undef, i32 %294, i32 0
  %499 = shufflevector <4 x i32> %498, <4 x i32> undef, <4 x i32> zeroinitializer
  %500 = insertelement <4 x i32> undef, i32 %293, i32 0
  %501 = shufflevector <4 x i32> %500, <4 x i32> undef, <4 x i32> zeroinitializer
  %502 = and i64 %495, 1
  %503 = icmp eq i64 %493, 0
  %504 = sub nuw nsw i64 %495, %502
  %505 = icmp eq i64 %502, 0
  %506 = icmp eq i64 %497, %491
  br label %507

507:                                              ; preds = %582, %471
  %508 = phi i64 [ 0, %471 ], [ %583, %582 ]
  br i1 %472, label %509, label %582

509:                                              ; preds = %507
  %510 = mul nsw i64 %508, %487
  %511 = mul nsw i64 %508, %488
  br label %512

512:                                              ; preds = %623, %509
  %513 = phi i64 [ 0, %509 ], [ %640, %623 ]
  br i1 %473, label %514, label %585

514:                                              ; preds = %512
  %515 = mul nsw i64 %513, %487
  br i1 %496, label %516, label %519

516:                                              ; preds = %575, %514
  %517 = phi i64 [ 0, %514 ], [ %497, %575 ]
  %518 = phi i32 [ 0, %514 ], [ %581, %575 ]
  br label %587

519:                                              ; preds = %514
  br i1 %503, label %556, label %520

520:                                              ; preds = %519, %520
  %521 = phi i64 [ %553, %520 ], [ 0, %519 ]
  %522 = phi <4 x i32> [ %552, %520 ], [ zeroinitializer, %519 ]
  %523 = phi i64 [ %554, %520 ], [ %504, %519 ]
  %524 = add nsw i64 %521, %510
  %525 = getelementptr inbounds i8, i8* %334, i64 %524
  %526 = bitcast i8* %525 to <4 x i8>*
  %527 = load <4 x i8>, <4 x i8>* %526, align 1
  %528 = sext <4 x i8> %527 to <4 x i32>
  %529 = add nsw i64 %521, %515
  %530 = getelementptr inbounds i8, i8* %369, i64 %529
  %531 = bitcast i8* %530 to <4 x i8>*
  %532 = load <4 x i8>, <4 x i8>* %531, align 1
  %533 = sext <4 x i8> %532 to <4 x i32>
  %534 = sub <4 x i32> %533, %499
  %535 = sub <4 x i32> %528, %501
  %536 = mul nsw <4 x i32> %534, %535
  %537 = add nsw <4 x i32> %536, %522
  %538 = or i64 %521, 4
  %539 = add nsw i64 %538, %510
  %540 = getelementptr inbounds i8, i8* %334, i64 %539
  %541 = bitcast i8* %540 to <4 x i8>*
  %542 = load <4 x i8>, <4 x i8>* %541, align 1
  %543 = sext <4 x i8> %542 to <4 x i32>
  %544 = add nsw i64 %538, %515
  %545 = getelementptr inbounds i8, i8* %369, i64 %544
  %546 = bitcast i8* %545 to <4 x i8>*
  %547 = load <4 x i8>, <4 x i8>* %546, align 1
  %548 = sext <4 x i8> %547 to <4 x i32>
  %549 = sub <4 x i32> %548, %499
  %550 = sub <4 x i32> %543, %501
  %551 = mul nsw <4 x i32> %549, %550
  %552 = add nsw <4 x i32> %551, %537
  %553 = add i64 %521, 8
  %554 = add i64 %523, -2
  %555 = icmp eq i64 %554, 0
  br i1 %555, label %556, label %520, !llvm.loop !125

556:                                              ; preds = %520, %519
  %557 = phi <4 x i32> [ undef, %519 ], [ %552, %520 ]
  %558 = phi i64 [ 0, %519 ], [ %553, %520 ]
  %559 = phi <4 x i32> [ zeroinitializer, %519 ], [ %552, %520 ]
  br i1 %505, label %575, label %560

560:                                              ; preds = %556
  %561 = add nsw i64 %558, %515
  %562 = getelementptr inbounds i8, i8* %369, i64 %561
  %563 = bitcast i8* %562 to <4 x i8>*
  %564 = load <4 x i8>, <4 x i8>* %563, align 1
  %565 = sext <4 x i8> %564 to <4 x i32>
  %566 = sub <4 x i32> %565, %499
  %567 = add nsw i64 %558, %510
  %568 = getelementptr inbounds i8, i8* %334, i64 %567
  %569 = bitcast i8* %568 to <4 x i8>*
  %570 = load <4 x i8>, <4 x i8>* %569, align 1
  %571 = sext <4 x i8> %570 to <4 x i32>
  %572 = sub <4 x i32> %571, %501
  %573 = mul nsw <4 x i32> %566, %572
  %574 = add nsw <4 x i32> %573, %559
  br label %575

575:                                              ; preds = %556, %560
  %576 = phi <4 x i32> [ %557, %556 ], [ %574, %560 ]
  %577 = shufflevector <4 x i32> %576, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %578 = add <4 x i32> %576, %577
  %579 = shufflevector <4 x i32> %578, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %580 = add <4 x i32> %578, %579
  %581 = extractelement <4 x i32> %580, i32 0
  br i1 %506, label %585, label %516

582:                                              ; preds = %623, %507
  %583 = add nuw nsw i64 %508, 1
  %584 = icmp eq i64 %583, %489
  br i1 %584, label %642, label %507

585:                                              ; preds = %587, %575, %512
  %586 = phi i32 [ 0, %512 ], [ %581, %575 ], [ %601, %587 ]
  br i1 %474, label %608, label %604

587:                                              ; preds = %516, %587
  %588 = phi i64 [ %602, %587 ], [ %517, %516 ]
  %589 = phi i32 [ %601, %587 ], [ %518, %516 ]
  %590 = add nsw i64 %588, %510
  %591 = getelementptr inbounds i8, i8* %334, i64 %590
  %592 = load i8, i8* %591, align 1
  %593 = sext i8 %592 to i32
  %594 = add nsw i64 %588, %515
  %595 = getelementptr inbounds i8, i8* %369, i64 %594
  %596 = load i8, i8* %595, align 1
  %597 = sext i8 %596 to i32
  %598 = sub i32 %597, %294
  %599 = sub i32 %593, %293
  %600 = mul nsw i32 %598, %599
  %601 = add nsw i32 %600, %589
  %602 = add nuw nsw i64 %588, 1
  %603 = icmp eq i64 %602, %491
  br i1 %603, label %585, label %587, !llvm.loop !126

604:                                              ; preds = %585
  %605 = getelementptr inbounds i32, i32* %403, i64 %513
  %606 = load i32, i32* %605, align 4
  %607 = add nsw i32 %606, %586
  br label %608

608:                                              ; preds = %604, %585
  %609 = phi i32 [ %586, %585 ], [ %607, %604 ]
  %610 = mul nsw i32 %609, %479
  %611 = icmp eq i32 %610, %296
  br i1 %611, label %614, label %612

612:                                              ; preds = %608
  %613 = sext i32 %610 to i64
  br label %615

614:                                              ; preds = %608
  br i1 %481, label %623, label %615

615:                                              ; preds = %614, %612
  %616 = phi i64 [ %613, %612 ], [ %480, %614 ]
  %617 = mul nsw i64 %616, %480
  %618 = icmp sgt i64 %617, -1
  %619 = select i1 %618, i64 1073741824, i64 -1073741823
  %620 = add nsw i64 %619, %617
  %621 = sdiv i64 %620, 2147483648
  %622 = trunc i64 %621 to i32
  br label %623

623:                                              ; preds = %615, %614
  %624 = phi i32 [ %622, %615 ], [ 2147483647, %614 ]
  %625 = and i32 %624, %485
  %626 = lshr i32 %624, 31
  %627 = add nsw i32 %626, %486
  %628 = ashr i32 %624, %477
  %629 = icmp sgt i32 %625, %627
  %630 = zext i1 %629 to i32
  %631 = add i32 %628, %295
  %632 = add i32 %631, %630
  %633 = icmp slt i32 %632, %298
  %634 = select i1 %633, i32 %298, i32 %632
  %635 = icmp slt i32 %299, %634
  %636 = select i1 %635, i32 %299, i32 %634
  %637 = trunc i32 %636 to i8
  %638 = add nsw i64 %513, %511
  %639 = getelementptr inbounds i8, i8* %455, i64 %638
  store i8 %637, i8* %639, align 1
  %640 = add nuw nsw i64 %513, 1
  %641 = icmp eq i64 %640, %490
  br i1 %641, label %582, label %512

642:                                              ; preds = %582, %450
  %643 = icmp eq i32* %453, null
  %644 = or i1 %454, %643
  br i1 %644, label %646, label %645

645:                                              ; preds = %642
  tail call void @_ZdaPv(i8* %452) #18
  br label %646

646:                                              ; preds = %645, %642
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %404) #19
  %647 = icmp sgt i32 %402, 5
  br i1 %647, label %648, label %654

648:                                              ; preds = %646
  %649 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 1, i32 0
  %650 = load i32*, i32** %649, align 8
  %651 = icmp eq i32* %650, null
  br i1 %651, label %654, label %652

652:                                              ; preds = %648
  %653 = bitcast i32* %650 to i8*
  tail call void @_ZdaPv(i8* %653) #18
  br label %654

654:                                              ; preds = %652, %648, %646
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %370) #19
  %655 = xor i1 %459, true
  %656 = icmp eq i32* %463, null
  %657 = or i1 %656, %655
  br i1 %657, label %660, label %658

658:                                              ; preds = %654
  %659 = bitcast i32* %463 to i8*
  tail call void @_ZdaPv(i8* %659) #18
  br label %660

660:                                              ; preds = %658, %654
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %335) #19
  %661 = icmp sgt i32 %333, 5
  br i1 %661, label %662, label %1154

662:                                              ; preds = %660
  %663 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %9, i64 0, i32 1, i32 0
  %664 = load i32*, i32** %663, align 8
  %665 = icmp eq i32* %664, null
  br i1 %665, label %1154, label %666

666:                                              ; preds = %662
  %667 = bitcast i32* %664 to i8*
  tail call void @_ZdaPv(i8* %667) #18
  br label %1154

668:                                              ; preds = %83
  %669 = icmp eq i32 %27, 7
  br i1 %669, label %670, label %976

670:                                              ; preds = %668
  %671 = bitcast %"class.tflite::RuntimeShape"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %671) #19
  %672 = icmp eq %struct.TfLiteTensor* %4, null
  br i1 %672, label %673, label %675

673:                                              ; preds = %670
  %674 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 0
  store i32 0, i32* %674, align 8, !alias.scope !127
  br label %703

675:                                              ; preds = %670
  %676 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 2
  %677 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %676, align 8, !noalias !127
  %678 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %677, i64 0, i32 0
  %679 = load i32, i32* %678, align 4, !noalias !127
  %680 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %677, i64 0, i32 1, i64 0
  %681 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 0
  store i32 %679, i32* %681, align 8, !alias.scope !127
  %682 = icmp sgt i32 %679, 5
  br i1 %682, label %683, label %690

683:                                              ; preds = %675
  %684 = sext i32 %679 to i64
  %685 = shl nsw i64 %684, 2
  %686 = tail call i8* @_Znam(i64 %685) #18, !noalias !127
  %687 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 1, i32 0
  %688 = bitcast i32** %687 to i8**
  store i8* %686, i8** %688, align 8, !alias.scope !127
  %689 = bitcast i8* %686 to i32*
  br label %695

690:                                              ; preds = %675
  %691 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 1
  %692 = bitcast %union.anon.54* %691 to i32*
  %693 = sext i32 %679 to i64
  %694 = shl nsw i64 %693, 2
  br label %695

695:                                              ; preds = %690, %683
  %696 = phi i64 [ %685, %683 ], [ %694, %690 ]
  %697 = phi i32* [ %689, %683 ], [ %692, %690 ]
  %698 = bitcast i32* %697 to i8*
  %699 = bitcast i32* %680 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %698, i8* align 4 %699, i64 %696, i1 false) #19
  %700 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 1
  %701 = bitcast %union.TfLitePtrUnion* %700 to i16**
  %702 = load i16*, i16** %701, align 8
  br label %703

703:                                              ; preds = %695, %673
  %704 = phi i32 [ %679, %695 ], [ 0, %673 ]
  %705 = phi i16* [ %702, %695 ], [ null, %673 ]
  %706 = bitcast %"class.tflite::RuntimeShape"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %706) #19
  %707 = icmp eq %struct.TfLiteTensor* %5, null
  br i1 %707, label %708, label %710

708:                                              ; preds = %703
  %709 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 0
  store i32 0, i32* %709, align 8, !alias.scope !130
  br label %738

710:                                              ; preds = %703
  %711 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 2
  %712 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %711, align 8, !noalias !130
  %713 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %712, i64 0, i32 0
  %714 = load i32, i32* %713, align 4, !noalias !130
  %715 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %712, i64 0, i32 1, i64 0
  %716 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 0
  store i32 %714, i32* %716, align 8, !alias.scope !130
  %717 = icmp sgt i32 %714, 5
  br i1 %717, label %718, label %725

718:                                              ; preds = %710
  %719 = sext i32 %714 to i64
  %720 = shl nsw i64 %719, 2
  %721 = tail call i8* @_Znam(i64 %720) #18, !noalias !130
  %722 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 1, i32 0
  %723 = bitcast i32** %722 to i8**
  store i8* %721, i8** %723, align 8, !alias.scope !130
  %724 = bitcast i8* %721 to i32*
  br label %730

725:                                              ; preds = %710
  %726 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 1
  %727 = bitcast %union.anon.54* %726 to i32*
  %728 = sext i32 %714 to i64
  %729 = shl nsw i64 %728, 2
  br label %730

730:                                              ; preds = %725, %718
  %731 = phi i64 [ %720, %718 ], [ %729, %725 ]
  %732 = phi i32* [ %724, %718 ], [ %727, %725 ]
  %733 = bitcast i32* %732 to i8*
  %734 = bitcast i32* %715 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %733, i8* align 4 %734, i64 %731, i1 false) #19
  %735 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 1
  %736 = bitcast %union.TfLitePtrUnion* %735 to i8**
  %737 = load i8*, i8** %736, align 8
  br label %738

738:                                              ; preds = %730, %708
  %739 = phi i32 [ %714, %730 ], [ 0, %708 ]
  %740 = phi i8* [ %737, %730 ], [ null, %708 ]
  %741 = bitcast %"class.tflite::RuntimeShape"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %741) #19
  %742 = icmp eq %struct.TfLiteTensor* %6, null
  br i1 %742, label %743, label %745

743:                                              ; preds = %738
  %744 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %15, i64 0, i32 0
  store i32 0, i32* %744, align 8, !alias.scope !133
  br label %773

745:                                              ; preds = %738
  %746 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 2
  %747 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %746, align 8, !noalias !133
  %748 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %747, i64 0, i32 0
  %749 = load i32, i32* %748, align 4, !noalias !133
  %750 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %747, i64 0, i32 1, i64 0
  %751 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %15, i64 0, i32 0
  store i32 %749, i32* %751, align 8, !alias.scope !133
  %752 = icmp sgt i32 %749, 5
  br i1 %752, label %753, label %760

753:                                              ; preds = %745
  %754 = sext i32 %749 to i64
  %755 = shl nsw i64 %754, 2
  %756 = tail call i8* @_Znam(i64 %755) #18, !noalias !133
  %757 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %15, i64 0, i32 1, i32 0
  %758 = bitcast i32** %757 to i8**
  store i8* %756, i8** %758, align 8, !alias.scope !133
  %759 = bitcast i8* %756 to i32*
  br label %765

760:                                              ; preds = %745
  %761 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %15, i64 0, i32 1
  %762 = bitcast %union.anon.54* %761 to i32*
  %763 = sext i32 %749 to i64
  %764 = shl nsw i64 %763, 2
  br label %765

765:                                              ; preds = %760, %753
  %766 = phi i64 [ %755, %753 ], [ %764, %760 ]
  %767 = phi i32* [ %759, %753 ], [ %762, %760 ]
  %768 = bitcast i32* %767 to i8*
  %769 = bitcast i32* %750 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %768, i8* align 4 %769, i64 %766, i1 false) #19
  %770 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 1
  %771 = bitcast %union.TfLitePtrUnion* %770 to i64**
  %772 = load i64*, i64** %771, align 8
  br label %773

773:                                              ; preds = %765, %743
  %774 = phi i32 [ %749, %765 ], [ 0, %743 ]
  %775 = phi i64* [ %772, %765 ], [ null, %743 ]
  %776 = bitcast %"class.tflite::RuntimeShape"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %776) #19
  %777 = icmp eq %struct.TfLiteTensor* %7, null
  br i1 %777, label %778, label %781

778:                                              ; preds = %773
  %779 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %16, i64 0, i32 0
  store i32 0, i32* %779, align 8, !alias.scope !136
  %780 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %16, i64 0, i32 1
  br label %814

781:                                              ; preds = %773
  %782 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 2
  %783 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %782, align 8, !noalias !136
  %784 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %783, i64 0, i32 0
  %785 = load i32, i32* %784, align 4, !noalias !136
  %786 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %783, i64 0, i32 1, i64 0
  %787 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %16, i64 0, i32 0
  store i32 %785, i32* %787, align 8, !alias.scope !136
  %788 = icmp sgt i32 %785, 5
  br i1 %788, label %789, label %796

789:                                              ; preds = %781
  %790 = sext i32 %785 to i64
  %791 = shl nsw i64 %790, 2
  %792 = tail call i8* @_Znam(i64 %791) #18, !noalias !136
  %793 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %16, i64 0, i32 1, i32 0
  %794 = bitcast i32** %793 to i8**
  store i8* %792, i8** %794, align 8, !alias.scope !136
  %795 = bitcast i8* %792 to i32*
  br label %801

796:                                              ; preds = %781
  %797 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %16, i64 0, i32 1
  %798 = bitcast %union.anon.54* %797 to i32*
  %799 = sext i32 %785 to i64
  %800 = shl nsw i64 %799, 2
  br label %801

801:                                              ; preds = %796, %789
  %802 = phi i64 [ %791, %789 ], [ %800, %796 ]
  %803 = phi i32* [ %795, %789 ], [ %798, %796 ]
  %804 = bitcast i32* %803 to i8*
  %805 = bitcast i32* %786 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %804, i8* align 4 %805, i64 %802, i1 false) #19
  %806 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 1
  %807 = bitcast %union.TfLitePtrUnion* %806 to i16**
  %808 = load i16*, i16** %807, align 8
  %809 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %16, i64 0, i32 1, i32 0
  %810 = load i32*, i32** %809, align 8
  %811 = bitcast i32* %810 to i8*
  %812 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %16, i64 0, i32 1
  %813 = getelementptr inbounds i32, i32* %810, i64 1
  br i1 %788, label %822, label %814

814:                                              ; preds = %801, %778
  %815 = phi %union.anon.54* [ %780, %778 ], [ %812, %801 ]
  %816 = phi i16* [ null, %778 ], [ %808, %801 ]
  %817 = phi i32* [ undef, %778 ], [ %810, %801 ]
  %818 = phi i8* [ undef, %778 ], [ %811, %801 ]
  %819 = bitcast %union.anon.54* %815 to [5 x i32]*
  %820 = bitcast %union.anon.54* %815 to i32*
  %821 = getelementptr inbounds [5 x i32], [5 x i32]* %819, i64 0, i64 1
  br label %822

822:                                              ; preds = %814, %801
  %823 = phi i32* [ %820, %814 ], [ %810, %801 ]
  %824 = phi i8* [ %818, %814 ], [ %811, %801 ]
  %825 = phi i32* [ %817, %814 ], [ %810, %801 ]
  %826 = phi i1 [ true, %814 ], [ false, %801 ]
  %827 = phi i16* [ %816, %814 ], [ %808, %801 ]
  %828 = phi i32* [ %821, %814 ], [ %813, %801 ]
  %829 = load i32, i32* %823, align 4
  %830 = load i32, i32* %828, align 4
  %831 = icmp sgt i32 %739, 5
  %832 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 1
  %833 = add nsw i32 %739, -1
  %834 = getelementptr inbounds %union.anon.54, %union.anon.54* %832, i64 0, i32 0
  %835 = load i32*, i32** %834, align 8
  %836 = sext i32 %833 to i64
  %837 = getelementptr inbounds i32, i32* %835, i64 %836
  %838 = bitcast %union.anon.54* %832 to [5 x i32]*
  %839 = getelementptr inbounds [5 x i32], [5 x i32]* %838, i64 0, i64 %836
  %840 = select i1 %831, i32* %837, i32* %839
  %841 = load i32, i32* %840, align 4
  %842 = icmp sgt i32 %829, 0
  br i1 %842, label %843, label %950

843:                                              ; preds = %822
  %844 = icmp sgt i32 %830, 0
  %845 = icmp sgt i32 %841, 0
  %846 = icmp eq i64* %775, null
  %847 = extractelement <4 x i32> %98, i32 0
  %848 = add nsw i32 %847, 32768
  %849 = ashr i32 %848, 16
  %850 = extractelement <4 x i32> %98, i32 1
  %851 = sub nsw i32 15, %850
  %852 = sext i32 %849 to i64
  %853 = sub i32 14, %850
  %854 = zext i32 %853 to i64
  %855 = shl i64 1, %854
  %856 = zext i32 %851 to i64
  %857 = sext i32 %841 to i64
  %858 = sext i32 %830 to i64
  %859 = zext i32 %829 to i64
  %860 = zext i32 %830 to i64
  %861 = zext i32 %841 to i64
  %862 = and i64 %861, 1
  %863 = icmp eq i32 %841, 1
  %864 = sub nsw i64 %861, %862
  %865 = icmp eq i64 %862, 0
  %866 = extractelement <4 x i32> %98, i32 2
  %867 = extractelement <4 x i32> %98, i32 3
  br label %868

868:                                              ; preds = %877, %843
  %869 = phi i64 [ 0, %843 ], [ %878, %877 ]
  br i1 %844, label %870, label %877

870:                                              ; preds = %868
  %871 = mul nsw i64 %869, %857
  %872 = mul nsw i64 %869, %858
  br label %873

873:                                              ; preds = %935, %870
  %874 = phi i64 [ 0, %870 ], [ %948, %935 ]
  br i1 %845, label %875, label %897

875:                                              ; preds = %873
  %876 = mul nsw i64 %874, %857
  br i1 %863, label %880, label %899

877:                                              ; preds = %935, %868
  %878 = add nuw nsw i64 %869, 1
  %879 = icmp eq i64 %878, %859
  br i1 %879, label %950, label %868

880:                                              ; preds = %899, %875
  %881 = phi i64 [ undef, %875 ], [ %927, %899 ]
  %882 = phi i64 [ 0, %875 ], [ %928, %899 ]
  %883 = phi i64 [ 0, %875 ], [ %927, %899 ]
  br i1 %865, label %897, label %884

884:                                              ; preds = %880
  %885 = add nsw i64 %882, %876
  %886 = getelementptr inbounds i8, i8* %740, i64 %885
  %887 = load i8, i8* %886, align 1
  %888 = sext i8 %887 to i32
  %889 = sub i32 %888, %87
  %890 = add nsw i64 %882, %871
  %891 = getelementptr inbounds i16, i16* %705, i64 %890
  %892 = load i16, i16* %891, align 2
  %893 = sext i16 %892 to i32
  %894 = mul nsw i32 %889, %893
  %895 = sext i32 %894 to i64
  %896 = add nsw i64 %883, %895
  br label %897

897:                                              ; preds = %884, %880, %873
  %898 = phi i64 [ 0, %873 ], [ %881, %880 ], [ %896, %884 ]
  br i1 %846, label %935, label %931

899:                                              ; preds = %875, %899
  %900 = phi i64 [ %928, %899 ], [ 0, %875 ]
  %901 = phi i64 [ %927, %899 ], [ 0, %875 ]
  %902 = phi i64 [ %929, %899 ], [ %864, %875 ]
  %903 = add nsw i64 %900, %871
  %904 = getelementptr inbounds i16, i16* %705, i64 %903
  %905 = load i16, i16* %904, align 2
  %906 = sext i16 %905 to i32
  %907 = add nsw i64 %900, %876
  %908 = getelementptr inbounds i8, i8* %740, i64 %907
  %909 = load i8, i8* %908, align 1
  %910 = sext i8 %909 to i32
  %911 = sub i32 %910, %87
  %912 = mul nsw i32 %911, %906
  %913 = sext i32 %912 to i64
  %914 = add nsw i64 %901, %913
  %915 = or i64 %900, 1
  %916 = add nsw i64 %915, %871
  %917 = getelementptr inbounds i16, i16* %705, i64 %916
  %918 = load i16, i16* %917, align 2
  %919 = sext i16 %918 to i32
  %920 = add nsw i64 %915, %876
  %921 = getelementptr inbounds i8, i8* %740, i64 %920
  %922 = load i8, i8* %921, align 1
  %923 = sext i8 %922 to i32
  %924 = sub i32 %923, %87
  %925 = mul nsw i32 %924, %919
  %926 = sext i32 %925 to i64
  %927 = add nsw i64 %914, %926
  %928 = add nuw nsw i64 %900, 2
  %929 = add i64 %902, -2
  %930 = icmp eq i64 %929, 0
  br i1 %930, label %880, label %899

931:                                              ; preds = %897
  %932 = getelementptr inbounds i64, i64* %775, i64 %874
  %933 = load i64, i64* %932, align 8
  %934 = add nsw i64 %933, %898
  br label %935

935:                                              ; preds = %931, %897
  %936 = phi i64 [ %934, %931 ], [ %898, %897 ]
  %937 = mul nsw i64 %936, %852
  %938 = add nsw i64 %937, %855
  %939 = ashr i64 %938, %856
  %940 = trunc i64 %939 to i32
  %941 = icmp sgt i32 %866, %940
  %942 = select i1 %941, i32 %866, i32 %940
  %943 = icmp slt i32 %867, %942
  %944 = select i1 %943, i32 %867, i32 %942
  %945 = trunc i32 %944 to i16
  %946 = add nsw i64 %874, %872
  %947 = getelementptr inbounds i16, i16* %827, i64 %946
  store i16 %945, i16* %947, align 2
  %948 = add nuw nsw i64 %874, 1
  %949 = icmp eq i64 %948, %860
  br i1 %949, label %877, label %873

950:                                              ; preds = %877, %822
  %951 = icmp eq i32* %825, null
  %952 = or i1 %826, %951
  br i1 %952, label %954, label %953

953:                                              ; preds = %950
  tail call void @_ZdaPv(i8* %824) #18
  br label %954

954:                                              ; preds = %953, %950
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %776) #19
  %955 = icmp sgt i32 %774, 5
  br i1 %955, label %956, label %962

956:                                              ; preds = %954
  %957 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %15, i64 0, i32 1, i32 0
  %958 = load i32*, i32** %957, align 8
  %959 = icmp eq i32* %958, null
  br i1 %959, label %962, label %960

960:                                              ; preds = %956
  %961 = bitcast i32* %958 to i8*
  tail call void @_ZdaPv(i8* %961) #18
  br label %962

962:                                              ; preds = %960, %956, %954
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %741) #19
  %963 = xor i1 %831, true
  %964 = icmp eq i32* %835, null
  %965 = or i1 %964, %963
  br i1 %965, label %968, label %966

966:                                              ; preds = %962
  %967 = bitcast i32* %835 to i8*
  tail call void @_ZdaPv(i8* %967) #18
  br label %968

968:                                              ; preds = %966, %962
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %706) #19
  %969 = icmp sgt i32 %704, 5
  br i1 %969, label %970, label %1154

970:                                              ; preds = %968
  %971 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 1, i32 0
  %972 = load i32*, i32** %971, align 8
  %973 = icmp eq i32* %972, null
  br i1 %973, label %1154, label %974

974:                                              ; preds = %970
  %975 = bitcast i32* %972 to i8*
  tail call void @_ZdaPv(i8* %975) #18
  br label %1154

976:                                              ; preds = %668
  %977 = bitcast %"class.tflite::RuntimeShape"* %22 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %977) #19
  %978 = icmp eq %struct.TfLiteTensor* %4, null
  br i1 %978, label %979, label %981

979:                                              ; preds = %976
  %980 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %22, i64 0, i32 0
  store i32 0, i32* %980, align 8, !alias.scope !139
  br label %1009

981:                                              ; preds = %976
  %982 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 2
  %983 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %982, align 8, !noalias !139
  %984 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %983, i64 0, i32 0
  %985 = load i32, i32* %984, align 4, !noalias !139
  %986 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %983, i64 0, i32 1, i64 0
  %987 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %22, i64 0, i32 0
  store i32 %985, i32* %987, align 8, !alias.scope !139
  %988 = icmp sgt i32 %985, 5
  br i1 %988, label %989, label %996

989:                                              ; preds = %981
  %990 = sext i32 %985 to i64
  %991 = shl nsw i64 %990, 2
  %992 = tail call i8* @_Znam(i64 %991) #18, !noalias !139
  %993 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %22, i64 0, i32 1, i32 0
  %994 = bitcast i32** %993 to i8**
  store i8* %992, i8** %994, align 8, !alias.scope !139
  %995 = bitcast i8* %992 to i32*
  br label %1001

996:                                              ; preds = %981
  %997 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %22, i64 0, i32 1
  %998 = bitcast %union.anon.54* %997 to i32*
  %999 = sext i32 %985 to i64
  %1000 = shl nsw i64 %999, 2
  br label %1001

1001:                                             ; preds = %996, %989
  %1002 = phi i64 [ %991, %989 ], [ %1000, %996 ]
  %1003 = phi i32* [ %995, %989 ], [ %998, %996 ]
  %1004 = bitcast i32* %1003 to i8*
  %1005 = bitcast i32* %986 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %1004, i8* align 4 %1005, i64 %1002, i1 false) #19
  %1006 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 1
  %1007 = bitcast %union.TfLitePtrUnion* %1006 to i8**
  %1008 = load i8*, i8** %1007, align 8
  br label %1009

1009:                                             ; preds = %979, %1001
  %1010 = phi i8* [ %1008, %1001 ], [ null, %979 ]
  %1011 = bitcast %"class.tflite::RuntimeShape"* %23 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %1011) #19
  %1012 = icmp eq %struct.TfLiteTensor* %5, null
  br i1 %1012, label %1013, label %1015

1013:                                             ; preds = %1009
  %1014 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %23, i64 0, i32 0
  store i32 0, i32* %1014, align 8, !alias.scope !142
  br label %1043

1015:                                             ; preds = %1009
  %1016 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 2
  %1017 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %1016, align 8, !noalias !142
  %1018 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %1017, i64 0, i32 0
  %1019 = load i32, i32* %1018, align 4, !noalias !142
  %1020 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %1017, i64 0, i32 1, i64 0
  %1021 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %23, i64 0, i32 0
  store i32 %1019, i32* %1021, align 8, !alias.scope !142
  %1022 = icmp sgt i32 %1019, 5
  br i1 %1022, label %1023, label %1030

1023:                                             ; preds = %1015
  %1024 = sext i32 %1019 to i64
  %1025 = shl nsw i64 %1024, 2
  %1026 = tail call i8* @_Znam(i64 %1025) #18, !noalias !142
  %1027 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %23, i64 0, i32 1, i32 0
  %1028 = bitcast i32** %1027 to i8**
  store i8* %1026, i8** %1028, align 8, !alias.scope !142
  %1029 = bitcast i8* %1026 to i32*
  br label %1035

1030:                                             ; preds = %1015
  %1031 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %23, i64 0, i32 1
  %1032 = bitcast %union.anon.54* %1031 to i32*
  %1033 = sext i32 %1019 to i64
  %1034 = shl nsw i64 %1033, 2
  br label %1035

1035:                                             ; preds = %1030, %1023
  %1036 = phi i64 [ %1025, %1023 ], [ %1034, %1030 ]
  %1037 = phi i32* [ %1029, %1023 ], [ %1032, %1030 ]
  %1038 = bitcast i32* %1037 to i8*
  %1039 = bitcast i32* %1020 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %1038, i8* align 4 %1039, i64 %1036, i1 false) #19
  %1040 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 1
  %1041 = bitcast %union.TfLitePtrUnion* %1040 to i8**
  %1042 = load i8*, i8** %1041, align 8
  br label %1043

1043:                                             ; preds = %1013, %1035
  %1044 = phi i8* [ %1042, %1035 ], [ null, %1013 ]
  %1045 = bitcast %"class.tflite::RuntimeShape"* %24 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %1045) #19
  %1046 = icmp eq %struct.TfLiteTensor* %6, null
  br i1 %1046, label %1047, label %1049

1047:                                             ; preds = %1043
  %1048 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %24, i64 0, i32 0
  store i32 0, i32* %1048, align 8, !alias.scope !145
  br label %1076

1049:                                             ; preds = %1043
  %1050 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 2
  %1051 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %1050, align 8, !noalias !145
  %1052 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %1051, i64 0, i32 0
  %1053 = load i32, i32* %1052, align 4, !noalias !145
  %1054 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %1051, i64 0, i32 1, i64 0
  %1055 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %24, i64 0, i32 0
  store i32 %1053, i32* %1055, align 8, !alias.scope !145
  %1056 = icmp sgt i32 %1053, 5
  br i1 %1056, label %1057, label %1064

1057:                                             ; preds = %1049
  %1058 = sext i32 %1053 to i64
  %1059 = shl nsw i64 %1058, 2
  %1060 = tail call i8* @_Znam(i64 %1059) #18, !noalias !145
  %1061 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %24, i64 0, i32 1, i32 0
  %1062 = bitcast i32** %1061 to i8**
  store i8* %1060, i8** %1062, align 8, !alias.scope !145
  %1063 = bitcast i8* %1060 to i32*
  br label %1069

1064:                                             ; preds = %1049
  %1065 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %24, i64 0, i32 1
  %1066 = bitcast %union.anon.54* %1065 to i32*
  %1067 = sext i32 %1053 to i64
  %1068 = shl nsw i64 %1067, 2
  br label %1069

1069:                                             ; preds = %1064, %1057
  %1070 = phi i64 [ %1059, %1057 ], [ %1068, %1064 ]
  %1071 = phi i32* [ %1063, %1057 ], [ %1066, %1064 ]
  %1072 = bitcast i32* %1071 to i8*
  %1073 = bitcast i32* %1054 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %1072, i8* align 4 %1073, i64 %1070, i1 false) #19
  %1074 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 1, i32 0
  %1075 = load i32*, i32** %1074, align 8
  br label %1076

1076:                                             ; preds = %1047, %1069
  %1077 = phi i32* [ %1075, %1069 ], [ null, %1047 ]
  %1078 = bitcast %"class.tflite::RuntimeShape"* %25 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %1078) #19
  %1079 = icmp eq %struct.TfLiteTensor* %7, null
  br i1 %1079, label %1080, label %1082

1080:                                             ; preds = %1076
  %1081 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %25, i64 0, i32 0
  store i32 0, i32* %1081, align 8, !alias.scope !148
  br label %1110

1082:                                             ; preds = %1076
  %1083 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 2
  %1084 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %1083, align 8, !noalias !148
  %1085 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %1084, i64 0, i32 0
  %1086 = load i32, i32* %1085, align 4, !noalias !148
  %1087 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %1084, i64 0, i32 1, i64 0
  %1088 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %25, i64 0, i32 0
  store i32 %1086, i32* %1088, align 8, !alias.scope !148
  %1089 = icmp sgt i32 %1086, 5
  br i1 %1089, label %1090, label %1097

1090:                                             ; preds = %1082
  %1091 = sext i32 %1086 to i64
  %1092 = shl nsw i64 %1091, 2
  %1093 = tail call i8* @_Znam(i64 %1092) #18, !noalias !148
  %1094 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %25, i64 0, i32 1, i32 0
  %1095 = bitcast i32** %1094 to i8**
  store i8* %1093, i8** %1095, align 8, !alias.scope !148
  %1096 = bitcast i8* %1093 to i32*
  br label %1102

1097:                                             ; preds = %1082
  %1098 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %25, i64 0, i32 1
  %1099 = bitcast %union.anon.54* %1098 to i32*
  %1100 = sext i32 %1086 to i64
  %1101 = shl nsw i64 %1100, 2
  br label %1102

1102:                                             ; preds = %1097, %1090
  %1103 = phi i64 [ %1092, %1090 ], [ %1101, %1097 ]
  %1104 = phi i32* [ %1096, %1090 ], [ %1099, %1097 ]
  %1105 = bitcast i32* %1104 to i8*
  %1106 = bitcast i32* %1087 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %1105, i8* align 4 %1106, i64 %1103, i1 false) #19
  %1107 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 1
  %1108 = bitcast %union.TfLitePtrUnion* %1107 to i16**
  %1109 = load i16*, i16** %1108, align 8
  br label %1110

1110:                                             ; preds = %1080, %1102
  %1111 = phi i16* [ %1109, %1102 ], [ null, %1080 ]
  call void @_ZN6tflite13reference_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKiS6_Ps(%"struct.tflite::FullyConnectedParams"* nonnull dereferenceable(40) %17, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %22, i8* %1010, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %23, i8* %1044, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %24, i32* %1077, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %25, i16* %1111)
  %1112 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %25, i64 0, i32 0
  %1113 = load i32, i32* %1112, align 8
  %1114 = icmp sgt i32 %1113, 5
  br i1 %1114, label %1115, label %1121

1115:                                             ; preds = %1110
  %1116 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %25, i64 0, i32 1, i32 0
  %1117 = load i32*, i32** %1116, align 8
  %1118 = icmp eq i32* %1117, null
  br i1 %1118, label %1121, label %1119

1119:                                             ; preds = %1115
  %1120 = bitcast i32* %1117 to i8*
  call void @_ZdaPv(i8* %1120) #18
  br label %1121

1121:                                             ; preds = %1110, %1115, %1119
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %1078) #19
  %1122 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %24, i64 0, i32 0
  %1123 = load i32, i32* %1122, align 8
  %1124 = icmp sgt i32 %1123, 5
  br i1 %1124, label %1125, label %1131

1125:                                             ; preds = %1121
  %1126 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %24, i64 0, i32 1, i32 0
  %1127 = load i32*, i32** %1126, align 8
  %1128 = icmp eq i32* %1127, null
  br i1 %1128, label %1131, label %1129

1129:                                             ; preds = %1125
  %1130 = bitcast i32* %1127 to i8*
  call void @_ZdaPv(i8* %1130) #18
  br label %1131

1131:                                             ; preds = %1121, %1125, %1129
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %1045) #19
  %1132 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %23, i64 0, i32 0
  %1133 = load i32, i32* %1132, align 8
  %1134 = icmp sgt i32 %1133, 5
  br i1 %1134, label %1135, label %1141

1135:                                             ; preds = %1131
  %1136 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %23, i64 0, i32 1, i32 0
  %1137 = load i32*, i32** %1136, align 8
  %1138 = icmp eq i32* %1137, null
  br i1 %1138, label %1141, label %1139

1139:                                             ; preds = %1135
  %1140 = bitcast i32* %1137 to i8*
  call void @_ZdaPv(i8* %1140) #18
  br label %1141

1141:                                             ; preds = %1131, %1135, %1139
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %1011) #19
  %1142 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %22, i64 0, i32 0
  %1143 = load i32, i32* %1142, align 8
  %1144 = icmp sgt i32 %1143, 5
  br i1 %1144, label %1145, label %1154

1145:                                             ; preds = %1141
  %1146 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %22, i64 0, i32 1, i32 0
  %1147 = load i32*, i32** %1146, align 8
  %1148 = icmp eq i32* %1147, null
  br i1 %1148, label %1154, label %1149

1149:                                             ; preds = %1145
  %1150 = bitcast i32* %1147 to i8*
  call void @_ZdaPv(i8* %1150) #18
  br label %1154

1151:                                             ; preds = %83
  %1152 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %1153 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %1152, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %1153(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([71 x i8], [71 x i8]* @.str.35, i64 0, i64 0)) #19
  br label %1156

1154:                                             ; preds = %1149, %1145, %1141, %974, %970, %968, %666, %662, %660, %285, %281, %277
  %1155 = phi i8* [ %113, %277 ], [ %113, %281 ], [ %113, %285 ], [ %300, %660 ], [ %300, %662 ], [ %300, %666 ], [ %671, %968 ], [ %671, %970 ], [ %671, %974 ], [ %977, %1141 ], [ %977, %1145 ], [ %977, %1149 ]
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %1155) #19
  br label %1156

1156:                                             ; preds = %1151, %1154
  %1157 = phi i32 [ 0, %1154 ], [ 1, %1151 ]
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %92) #19
  ret i32 %1157
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN6tflite13reference_ops26FullyConnectedSparseWeightERK14TfLiteSparsityRKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKfS9_SB_S9_SB_S9_Pf(%struct.TfLiteSparsity* dereferenceable(32), %"struct.tflite::FullyConnectedParams"* dereferenceable(40), %"class.tflite::RuntimeShape"* dereferenceable(32), float*, %"class.tflite::RuntimeShape"* dereferenceable(32), float*, %"class.tflite::RuntimeShape"* dereferenceable(32), float*, %"class.tflite::RuntimeShape"* dereferenceable(32), float*) local_unnamed_addr #4 comdat {
  %11 = alloca %"class.std::__1::vector.55", align 8
  %12 = alloca %"class.tflite::optimize::sparsity::FormatConverter", align 8
  %13 = alloca %"class.std::__1::vector.76", align 8
  %14 = bitcast %"class.std::__1::vector.55"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %14) #19
  %15 = getelementptr inbounds %"class.std::__1::vector.55", %"class.std::__1::vector.55"* %11, i64 0, i32 0, i32 0
  %16 = getelementptr inbounds %"class.std::__1::vector.55", %"class.std::__1::vector.55"* %11, i64 0, i32 0, i32 1
  %17 = getelementptr inbounds %"class.std::__1::vector.55", %"class.std::__1::vector.55"* %11, i64 0, i32 0, i32 2, i32 0, i32 0
  %18 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %4, i64 0, i32 0
  %19 = load i32, i32* %18, align 8
  %20 = sext i32 %19 to i64
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %14, i8 0, i64 24, i1 false) #19
  %21 = icmp eq i32 %19, 0
  br i1 %21, label %51, label %22

22:                                               ; preds = %10
  %23 = icmp slt i32 %19, 0
  br i1 %23, label %24, label %26

24:                                               ; preds = %22
  %25 = bitcast %"class.std::__1::vector.55"* %11 to %"class.std::__1::__vector_base_common"*
  call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* nonnull %25) #20
  unreachable

26:                                               ; preds = %22
  %27 = shl nsw i64 %20, 2
  %28 = tail call i8* @_Znwm(i64 %27) #18
  %29 = bitcast i8* %28 to i32*
  %30 = bitcast %"class.std::__1::vector.55"* %11 to i8**
  store i8* %28, i8** %30, align 8
  %31 = getelementptr inbounds i32, i32* %29, i64 %20
  store i32* %31, i32** %17, align 8
  %32 = bitcast i32** %16 to i64*
  %33 = ptrtoint i8* %28 to i64
  %34 = add nsw i64 %20, -1
  %35 = getelementptr i32, i32* %29, i64 %34
  %36 = ptrtoint i32* %35 to i64
  %37 = sub i64 4, %33
  %38 = add i64 %37, %36
  %39 = and i64 %38, -4
  tail call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %28, i8 0, i64 %39, i1 false) #19
  %40 = ptrtoint i32* %31 to i64
  store i64 %40, i64* %32, align 8
  %41 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %4, i64 0, i32 1
  %42 = getelementptr inbounds %union.anon.54, %union.anon.54* %41, i64 0, i32 0
  %43 = bitcast %union.anon.54* %41 to [5 x i32]*
  %44 = icmp sgt i32 %19, 5
  %45 = load i32*, i32** %42, align 8
  %46 = bitcast %union.anon.54* %41 to i32*
  %47 = select i1 %44, i32* %45, i32* %46
  %48 = load i32, i32* %47, align 4
  store i32 %48, i32* %29, align 4
  %49 = load i32, i32* %18, align 8
  %50 = icmp sgt i32 %49, 1
  br i1 %50, label %262, label %51

51:                                               ; preds = %262, %26, %10
  %52 = bitcast %"class.tflite::optimize::sparsity::FormatConverter"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 200, i8* nonnull %52) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %52, i8 -86, i64 200, i1 false)
  call void @_ZN6tflite8optimize8sparsity15FormatConverterIfEC1ERKNSt3__16vectorIiNS4_9allocatorIiEEEERK14TfLiteSparsity(%"class.tflite::optimize::sparsity::FormatConverter"* nonnull %12, %"class.std::__1::vector.55"* nonnull dereferenceable(24) %11, %struct.TfLiteSparsity* dereferenceable(32) %0) #19
  %53 = call i32 @_ZN6tflite8optimize8sparsity15FormatConverterIfE13SparseToDenseEPKf(%"class.tflite::optimize::sparsity::FormatConverter"* nonnull %12, float* %5) #19
  %54 = bitcast %"class.std::__1::vector.76"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %54) #19
  %55 = getelementptr inbounds %"class.std::__1::vector.76", %"class.std::__1::vector.76"* %13, i64 0, i32 0, i32 1
  %56 = getelementptr inbounds %"class.std::__1::vector.76", %"class.std::__1::vector.76"* %13, i64 0, i32 0, i32 2, i32 0, i32 0
  %57 = getelementptr inbounds %"class.tflite::optimize::sparsity::FormatConverter", %"class.tflite::optimize::sparsity::FormatConverter"* %12, i64 0, i32 8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %54, i8 0, i64 24, i1 false) #19, !alias.scope !151
  %58 = getelementptr inbounds %"class.tflite::optimize::sparsity::FormatConverter", %"class.tflite::optimize::sparsity::FormatConverter"* %12, i64 0, i32 8, i32 0, i32 1
  %59 = bitcast float** %58 to i64*
  %60 = load i64, i64* %59, align 8, !noalias !151
  %61 = bitcast %"class.std::__1::vector.76"* %57 to i64*
  %62 = load i64, i64* %61, align 8, !noalias !151
  %63 = sub i64 %60, %62
  %64 = ashr exact i64 %63, 2
  %65 = icmp eq i64 %63, 0
  br i1 %65, label %86, label %66

66:                                               ; preds = %51
  %67 = icmp ugt i64 %64, 4611686018427387903
  br i1 %67, label %68, label %70

68:                                               ; preds = %66
  %69 = bitcast %"class.std::__1::vector.76"* %13 to %"class.std::__1::__vector_base_common"*
  call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* nonnull %69) #20
  unreachable

70:                                               ; preds = %66
  %71 = call i8* @_Znwm(i64 %63) #18
  %72 = bitcast i8* %71 to float*
  %73 = bitcast float** %55 to i8**
  store i8* %71, i8** %73, align 8, !alias.scope !151
  %74 = bitcast %"class.std::__1::vector.76"* %13 to i8**
  store i8* %71, i8** %74, align 8, !alias.scope !151
  %75 = getelementptr inbounds float, float* %72, i64 %64
  store float* %75, float** %56, align 8, !alias.scope !151
  %76 = bitcast float** %55 to i64*
  %77 = ptrtoint i8* %71 to i64
  %78 = icmp sgt i64 %63, 0
  br i1 %78, label %79, label %84

79:                                               ; preds = %70
  %80 = lshr exact i64 %63, 2
  %81 = inttoptr i64 %62 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 4 %71, i8* align 4 %81, i64 %63, i1 false) #19
  %82 = getelementptr inbounds float, float* %72, i64 %80
  %83 = ptrtoint float* %82 to i64
  br label %84

84:                                               ; preds = %79, %70
  %85 = phi i64 [ %83, %79 ], [ %77, %70 ]
  store i64 %85, i64* %76, align 8, !alias.scope !151
  br label %86

86:                                               ; preds = %51, %84
  %87 = phi i8* [ null, %51 ], [ %71, %84 ]
  %88 = phi float* [ null, %51 ], [ %72, %84 ]
  %89 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %1, i64 0, i32 7
  %90 = load float, float* %89, align 4
  %91 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %1, i64 0, i32 8
  %92 = load float, float* %91, align 4
  %93 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %8, i64 0, i32 0
  %94 = load i32, i32* %93, align 8
  %95 = load i32, i32* %18, align 8
  %96 = add nsw i32 %94, -1
  %97 = icmp sgt i32 %94, 5
  %98 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %8, i64 0, i32 1
  %99 = getelementptr inbounds %union.anon.54, %union.anon.54* %98, i64 0, i32 0
  %100 = load i32*, i32** %99, align 8
  %101 = bitcast %union.anon.54* %98 to i32*
  %102 = select i1 %97, i32* %100, i32* %101
  %103 = icmp sgt i32 %94, 0
  br i1 %103, label %104, label %144

104:                                              ; preds = %86
  %105 = zext i32 %96 to i64
  %106 = zext i32 %94 to i64
  %107 = add nsw i64 %106, -1
  %108 = and i64 %106, 3
  %109 = icmp ult i64 %107, 3
  br i1 %109, label %125, label %110

110:                                              ; preds = %104
  %111 = sub nsw i64 %106, %108
  br label %112

112:                                              ; preds = %296, %110
  %113 = phi i64 [ 0, %110 ], [ %299, %296 ]
  %114 = phi i32 [ 1, %110 ], [ %298, %296 ]
  %115 = phi i64 [ %111, %110 ], [ %300, %296 ]
  %116 = icmp eq i64 %113, %105
  br i1 %116, label %120, label %117

117:                                              ; preds = %112
  %118 = getelementptr inbounds i32, i32* %102, i64 %113
  %119 = load i32, i32* %118, align 4
  br label %120

120:                                              ; preds = %117, %112
  %121 = phi i32 [ %119, %117 ], [ 1, %112 ]
  %122 = mul nsw i32 %121, %114
  %123 = or i64 %113, 1
  %124 = icmp eq i64 %123, %105
  br i1 %124, label %280, label %277

125:                                              ; preds = %296, %104
  %126 = phi i32 [ undef, %104 ], [ %298, %296 ]
  %127 = phi i64 [ 0, %104 ], [ %299, %296 ]
  %128 = phi i32 [ 1, %104 ], [ %298, %296 ]
  %129 = icmp eq i64 %108, 0
  br i1 %129, label %144, label %130

130:                                              ; preds = %125, %138
  %131 = phi i64 [ %141, %138 ], [ %127, %125 ]
  %132 = phi i32 [ %140, %138 ], [ %128, %125 ]
  %133 = phi i64 [ %142, %138 ], [ %108, %125 ]
  %134 = icmp eq i64 %131, %105
  br i1 %134, label %138, label %135

135:                                              ; preds = %130
  %136 = getelementptr inbounds i32, i32* %102, i64 %131
  %137 = load i32, i32* %136, align 4
  br label %138

138:                                              ; preds = %135, %130
  %139 = phi i32 [ %137, %135 ], [ 1, %130 ]
  %140 = mul nsw i32 %139, %132
  %141 = add nuw nsw i64 %131, 1
  %142 = add i64 %133, -1
  %143 = icmp eq i64 %142, 0
  br i1 %143, label %144, label %130, !llvm.loop !154

144:                                              ; preds = %125, %138, %86
  %145 = phi i32 [ 1, %86 ], [ %126, %125 ], [ %140, %138 ]
  %146 = add nsw i32 %95, -2
  %147 = icmp sgt i32 %95, 5
  %148 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %4, i64 0, i32 1
  %149 = getelementptr inbounds %union.anon.54, %union.anon.54* %148, i64 0, i32 0
  %150 = load i32*, i32** %149, align 8
  %151 = sext i32 %146 to i64
  %152 = getelementptr inbounds i32, i32* %150, i64 %151
  %153 = bitcast %union.anon.54* %148 to [5 x i32]*
  %154 = getelementptr inbounds [5 x i32], [5 x i32]* %153, i64 0, i64 %151
  %155 = select i1 %147, i32* %152, i32* %154
  %156 = load i32, i32* %155, align 4
  %157 = sext i32 %96 to i64
  %158 = getelementptr inbounds i32, i32* %100, i64 %157
  %159 = bitcast %union.anon.54* %98 to [5 x i32]*
  %160 = getelementptr inbounds [5 x i32], [5 x i32]* %159, i64 0, i64 %157
  %161 = select i1 %97, i32* %158, i32* %160
  %162 = load i32, i32* %161, align 4
  %163 = icmp slt i32 %162, %156
  %164 = select i1 %163, i32 %162, i32 %156
  %165 = add nsw i32 %95, -1
  %166 = sext i32 %165 to i64
  %167 = getelementptr inbounds i32, i32* %150, i64 %166
  %168 = getelementptr inbounds [5 x i32], [5 x i32]* %153, i64 0, i64 %166
  %169 = select i1 %147, i32* %167, i32* %168
  %170 = load i32, i32* %169, align 4
  %171 = icmp sgt i32 %145, 0
  br i1 %171, label %172, label %249

172:                                              ; preds = %144
  %173 = icmp sgt i32 %164, 0
  %174 = icmp sgt i32 %170, 0
  %175 = icmp eq float* %7, null
  %176 = sext i32 %170 to i64
  %177 = sext i32 %164 to i64
  %178 = zext i32 %145 to i64
  %179 = zext i32 %170 to i64
  %180 = and i64 %179, 1
  %181 = icmp eq i32 %170, 1
  %182 = sub nsw i64 %179, %180
  %183 = icmp eq i64 %180, 0
  br label %184

184:                                              ; preds = %193, %172
  %185 = phi i64 [ 0, %172 ], [ %194, %193 ]
  br i1 %173, label %186, label %193

186:                                              ; preds = %184
  %187 = mul nsw i64 %185, %176
  %188 = mul nsw i64 %185, %177
  br label %189

189:                                              ; preds = %238, %186
  %190 = phi i64 [ 0, %186 ], [ %247, %238 ]
  br i1 %174, label %191, label %209

191:                                              ; preds = %189
  %192 = mul nsw i64 %190, %176
  br i1 %181, label %196, label %211

193:                                              ; preds = %238, %184
  %194 = add nuw nsw i64 %185, 1
  %195 = icmp eq i64 %194, %178
  br i1 %195, label %249, label %184

196:                                              ; preds = %211, %191
  %197 = phi float [ undef, %191 ], [ %231, %211 ]
  %198 = phi i64 [ 0, %191 ], [ %232, %211 ]
  %199 = phi float [ 0.000000e+00, %191 ], [ %231, %211 ]
  br i1 %183, label %209, label %200

200:                                              ; preds = %196
  %201 = add nsw i64 %198, %187
  %202 = getelementptr inbounds float, float* %3, i64 %201
  %203 = load float, float* %202, align 4
  %204 = add nsw i64 %198, %192
  %205 = getelementptr inbounds float, float* %88, i64 %204
  %206 = load float, float* %205, align 4
  %207 = fmul float %203, %206
  %208 = fadd float %199, %207
  br label %209

209:                                              ; preds = %200, %196, %189
  %210 = phi float [ 0.000000e+00, %189 ], [ %197, %196 ], [ %208, %200 ]
  br i1 %175, label %238, label %235

211:                                              ; preds = %191, %211
  %212 = phi i64 [ %232, %211 ], [ 0, %191 ]
  %213 = phi float [ %231, %211 ], [ 0.000000e+00, %191 ]
  %214 = phi i64 [ %233, %211 ], [ %182, %191 ]
  %215 = add nsw i64 %212, %187
  %216 = getelementptr inbounds float, float* %3, i64 %215
  %217 = load float, float* %216, align 4
  %218 = add nsw i64 %212, %192
  %219 = getelementptr inbounds float, float* %88, i64 %218
  %220 = load float, float* %219, align 4
  %221 = fmul float %217, %220
  %222 = fadd float %213, %221
  %223 = or i64 %212, 1
  %224 = add nsw i64 %223, %187
  %225 = getelementptr inbounds float, float* %3, i64 %224
  %226 = load float, float* %225, align 4
  %227 = add nsw i64 %223, %192
  %228 = getelementptr inbounds float, float* %88, i64 %227
  %229 = load float, float* %228, align 4
  %230 = fmul float %226, %229
  %231 = fadd float %222, %230
  %232 = add nuw nsw i64 %212, 2
  %233 = add i64 %214, -2
  %234 = icmp eq i64 %233, 0
  br i1 %234, label %196, label %211

235:                                              ; preds = %209
  %236 = getelementptr inbounds float, float* %7, i64 %190
  %237 = load float, float* %236, align 4
  br label %238

238:                                              ; preds = %235, %209
  %239 = phi float [ %237, %235 ], [ 0.000000e+00, %209 ]
  %240 = fadd float %210, %239
  %241 = fcmp olt float %240, %90
  %242 = select i1 %241, float %90, float %240
  %243 = fcmp ogt float %242, %92
  %244 = select i1 %243, float %92, float %242
  %245 = add nsw i64 %190, %188
  %246 = getelementptr inbounds float, float* %9, i64 %245
  store float %244, float* %246, align 4
  %247 = add nuw nsw i64 %190, 1
  %248 = icmp slt i64 %247, %177
  br i1 %248, label %189, label %193

249:                                              ; preds = %193, %144
  %250 = icmp eq float* %88, null
  br i1 %250, label %254, label %251

251:                                              ; preds = %249
  %252 = ptrtoint float* %88 to i64
  %253 = bitcast float** %55 to i64*
  store i64 %252, i64* %253, align 8
  call void @_ZdlPv(i8* %87) #18
  br label %254

254:                                              ; preds = %249, %251
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %54) #19
  call void @_ZN6tflite8optimize8sparsity15FormatConverterIfED2Ev(%"class.tflite::optimize::sparsity::FormatConverter"* nonnull %12) #19
  call void @llvm.lifetime.end.p0i8(i64 200, i8* nonnull %52) #19
  %255 = load i32*, i32** %15, align 8
  %256 = icmp eq i32* %255, null
  br i1 %256, label %261, label %257

257:                                              ; preds = %254
  %258 = ptrtoint i32* %255 to i64
  %259 = bitcast i32** %16 to i64*
  store i64 %258, i64* %259, align 8
  %260 = bitcast i32* %255 to i8*
  call void @_ZdlPv(i8* %260) #18
  br label %261

261:                                              ; preds = %254, %257
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %14) #19
  ret void

262:                                              ; preds = %26, %262
  %263 = phi i32 [ %274, %262 ], [ %49, %26 ]
  %264 = phi i64 [ %273, %262 ], [ 1, %26 ]
  %265 = load i32*, i32** %15, align 8
  %266 = icmp sgt i32 %263, 5
  %267 = load i32*, i32** %42, align 8
  %268 = getelementptr inbounds i32, i32* %267, i64 %264
  %269 = getelementptr inbounds [5 x i32], [5 x i32]* %43, i64 0, i64 %264
  %270 = select i1 %266, i32* %268, i32* %269
  %271 = load i32, i32* %270, align 4
  %272 = getelementptr inbounds i32, i32* %265, i64 %264
  store i32 %271, i32* %272, align 4
  %273 = add nuw nsw i64 %264, 1
  %274 = load i32, i32* %18, align 8
  %275 = sext i32 %274 to i64
  %276 = icmp slt i64 %273, %275
  br i1 %276, label %262, label %51

277:                                              ; preds = %120
  %278 = getelementptr inbounds i32, i32* %102, i64 %123
  %279 = load i32, i32* %278, align 4
  br label %280

280:                                              ; preds = %277, %120
  %281 = phi i32 [ %279, %277 ], [ 1, %120 ]
  %282 = mul nsw i32 %281, %122
  %283 = or i64 %113, 2
  %284 = icmp eq i64 %283, %105
  br i1 %284, label %288, label %285

285:                                              ; preds = %280
  %286 = getelementptr inbounds i32, i32* %102, i64 %283
  %287 = load i32, i32* %286, align 4
  br label %288

288:                                              ; preds = %285, %280
  %289 = phi i32 [ %287, %285 ], [ 1, %280 ]
  %290 = mul nsw i32 %289, %282
  %291 = or i64 %113, 3
  %292 = icmp eq i64 %291, %105
  br i1 %292, label %296, label %293

293:                                              ; preds = %288
  %294 = getelementptr inbounds i32, i32* %102, i64 %291
  %295 = load i32, i32* %294, align 4
  br label %296

296:                                              ; preds = %293, %288
  %297 = phi i32 [ %295, %293 ], [ 1, %288 ]
  %298 = mul nsw i32 %297, %290
  %299 = add nuw nsw i64 %113, 4
  %300 = add i64 %115, -4
  %301 = icmp eq i64 %300, 0
  br i1 %301, label %125, label %112
}

declare void @_ZN6tflite8optimize8sparsity15FormatConverterIfEC1ERKNSt3__16vectorIiNS4_9allocatorIiEEEERK14TfLiteSparsity(%"class.tflite::optimize::sparsity::FormatConverter"*, %"class.std::__1::vector.55"* dereferenceable(24), %struct.TfLiteSparsity* dereferenceable(32)) unnamed_addr #5

declare i32 @_ZN6tflite8optimize8sparsity15FormatConverterIfE13SparseToDenseEPKf(%"class.tflite::optimize::sparsity::FormatConverter"*, float*) local_unnamed_addr #5

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN6tflite8optimize8sparsity15FormatConverterIfED2Ev(%"class.tflite::optimize::sparsity::FormatConverter"*) unnamed_addr #4 comdat align 2 {
  %2 = getelementptr inbounds %"class.tflite::optimize::sparsity::FormatConverter", %"class.tflite::optimize::sparsity::FormatConverter"* %0, i64 0, i32 8, i32 0, i32 0
  %3 = load float*, float** %2, align 8
  %4 = icmp eq float* %3, null
  br i1 %4, label %10, label %5

5:                                                ; preds = %1
  %6 = ptrtoint float* %3 to i64
  %7 = getelementptr inbounds %"class.tflite::optimize::sparsity::FormatConverter", %"class.tflite::optimize::sparsity::FormatConverter"* %0, i64 0, i32 8, i32 0, i32 1
  %8 = bitcast float** %7 to i64*
  store i64 %6, i64* %8, align 8
  %9 = bitcast float* %3 to i8*
  tail call void @_ZdlPv(i8* %9) #18
  br label %10

10:                                               ; preds = %1, %5
  %11 = getelementptr inbounds %"class.tflite::optimize::sparsity::FormatConverter", %"class.tflite::optimize::sparsity::FormatConverter"* %0, i64 0, i32 7
  %12 = getelementptr inbounds %"class.std::__1::vector.69", %"class.std::__1::vector.69"* %11, i64 0, i32 0, i32 0
  %13 = load %"class.std::__1::vector.55"*, %"class.std::__1::vector.55"** %12, align 8
  %14 = icmp eq %"class.std::__1::vector.55"* %13, null
  br i1 %14, label %38, label %15

15:                                               ; preds = %10
  %16 = bitcast %"class.std::__1::vector.55"* %13 to i8*
  %17 = getelementptr inbounds %"class.tflite::optimize::sparsity::FormatConverter", %"class.tflite::optimize::sparsity::FormatConverter"* %0, i64 0, i32 7, i32 0, i32 1
  %18 = load %"class.std::__1::vector.55"*, %"class.std::__1::vector.55"** %17, align 8
  %19 = icmp eq %"class.std::__1::vector.55"* %18, %13
  br i1 %19, label %36, label %20

20:                                               ; preds = %15, %31
  %21 = phi %"class.std::__1::vector.55"* [ %22, %31 ], [ %18, %15 ]
  %22 = getelementptr inbounds %"class.std::__1::vector.55", %"class.std::__1::vector.55"* %21, i64 -1
  %23 = getelementptr inbounds %"class.std::__1::vector.55", %"class.std::__1::vector.55"* %22, i64 0, i32 0, i32 0
  %24 = load i32*, i32** %23, align 8
  %25 = icmp eq i32* %24, null
  br i1 %25, label %31, label %26

26:                                               ; preds = %20
  %27 = ptrtoint i32* %24 to i64
  %28 = getelementptr inbounds %"class.std::__1::vector.55", %"class.std::__1::vector.55"* %21, i64 -1, i32 0, i32 1
  %29 = bitcast i32** %28 to i64*
  store i64 %27, i64* %29, align 8
  %30 = bitcast i32* %24 to i8*
  tail call void @_ZdlPv(i8* %30) #18
  br label %31

31:                                               ; preds = %26, %20
  %32 = icmp eq %"class.std::__1::vector.55"* %22, %13
  br i1 %32, label %33, label %20

33:                                               ; preds = %31
  %34 = bitcast %"class.std::__1::vector.69"* %11 to i8**
  %35 = load i8*, i8** %34, align 8
  br label %36

36:                                               ; preds = %33, %15
  %37 = phi i8* [ %35, %33 ], [ %16, %15 ]
  store %"class.std::__1::vector.55"* %13, %"class.std::__1::vector.55"** %17, align 8
  tail call void @_ZdlPv(i8* %37) #18
  br label %38

38:                                               ; preds = %10, %36
  %39 = getelementptr inbounds %"class.tflite::optimize::sparsity::FormatConverter", %"class.tflite::optimize::sparsity::FormatConverter"* %0, i64 0, i32 6, i32 0, i32 0
  %40 = load i32*, i32** %39, align 8
  %41 = icmp eq i32* %40, null
  br i1 %41, label %47, label %42

42:                                               ; preds = %38
  %43 = ptrtoint i32* %40 to i64
  %44 = getelementptr inbounds %"class.tflite::optimize::sparsity::FormatConverter", %"class.tflite::optimize::sparsity::FormatConverter"* %0, i64 0, i32 6, i32 0, i32 1
  %45 = bitcast i32** %44 to i64*
  store i64 %43, i64* %45, align 8
  %46 = bitcast i32* %40 to i8*
  tail call void @_ZdlPv(i8* %46) #18
  br label %47

47:                                               ; preds = %38, %42
  %48 = getelementptr inbounds %"class.tflite::optimize::sparsity::FormatConverter", %"class.tflite::optimize::sparsity::FormatConverter"* %0, i64 0, i32 5, i32 0, i32 0
  %49 = load i32*, i32** %48, align 8
  %50 = icmp eq i32* %49, null
  br i1 %50, label %56, label %51

51:                                               ; preds = %47
  %52 = ptrtoint i32* %49 to i64
  %53 = getelementptr inbounds %"class.tflite::optimize::sparsity::FormatConverter", %"class.tflite::optimize::sparsity::FormatConverter"* %0, i64 0, i32 5, i32 0, i32 1
  %54 = bitcast i32** %53 to i64*
  store i64 %52, i64* %54, align 8
  %55 = bitcast i32* %49 to i8*
  tail call void @_ZdlPv(i8* %55) #18
  br label %56

56:                                               ; preds = %47, %51
  %57 = getelementptr inbounds %"class.tflite::optimize::sparsity::FormatConverter", %"class.tflite::optimize::sparsity::FormatConverter"* %0, i64 0, i32 4, i32 0, i32 0
  %58 = load i32*, i32** %57, align 8
  %59 = icmp eq i32* %58, null
  br i1 %59, label %65, label %60

60:                                               ; preds = %56
  %61 = ptrtoint i32* %58 to i64
  %62 = getelementptr inbounds %"class.tflite::optimize::sparsity::FormatConverter", %"class.tflite::optimize::sparsity::FormatConverter"* %0, i64 0, i32 4, i32 0, i32 1
  %63 = bitcast i32** %62 to i64*
  store i64 %61, i64* %63, align 8
  %64 = bitcast i32* %58 to i8*
  tail call void @_ZdlPv(i8* %64) #18
  br label %65

65:                                               ; preds = %56, %60
  %66 = getelementptr inbounds %"class.tflite::optimize::sparsity::FormatConverter", %"class.tflite::optimize::sparsity::FormatConverter"* %0, i64 0, i32 3, i32 0, i32 0
  %67 = load i32*, i32** %66, align 8
  %68 = icmp eq i32* %67, null
  br i1 %68, label %74, label %69

69:                                               ; preds = %65
  %70 = ptrtoint i32* %67 to i64
  %71 = getelementptr inbounds %"class.tflite::optimize::sparsity::FormatConverter", %"class.tflite::optimize::sparsity::FormatConverter"* %0, i64 0, i32 3, i32 0, i32 1
  %72 = bitcast i32** %71 to i64*
  store i64 %70, i64* %72, align 8
  %73 = bitcast i32* %67 to i8*
  tail call void @_ZdlPv(i8* %73) #18
  br label %74

74:                                               ; preds = %65, %69
  %75 = getelementptr inbounds %"class.tflite::optimize::sparsity::FormatConverter", %"class.tflite::optimize::sparsity::FormatConverter"* %0, i64 0, i32 1, i32 0, i32 0
  %76 = load i32*, i32** %75, align 8
  %77 = icmp eq i32* %76, null
  br i1 %77, label %83, label %78

78:                                               ; preds = %74
  %79 = ptrtoint i32* %76 to i64
  %80 = getelementptr inbounds %"class.tflite::optimize::sparsity::FormatConverter", %"class.tflite::optimize::sparsity::FormatConverter"* %0, i64 0, i32 1, i32 0, i32 1
  %81 = bitcast i32** %80 to i64*
  store i64 %79, i64* %81, align 8
  %82 = bitcast i32* %76 to i8*
  tail call void @_ZdlPv(i8* %82) #18
  br label %83

83:                                               ; preds = %74, %78
  %84 = getelementptr inbounds %"class.tflite::optimize::sparsity::FormatConverter", %"class.tflite::optimize::sparsity::FormatConverter"* %0, i64 0, i32 0, i32 0, i32 0
  %85 = load i32*, i32** %84, align 8
  %86 = icmp eq i32* %85, null
  br i1 %86, label %92, label %87

87:                                               ; preds = %83
  %88 = ptrtoint i32* %85 to i64
  %89 = getelementptr inbounds %"class.tflite::optimize::sparsity::FormatConverter", %"class.tflite::optimize::sparsity::FormatConverter"* %0, i64 0, i32 0, i32 0, i32 1
  %90 = bitcast i32** %89 to i64*
  store i64 %88, i64* %90, align 8
  %91 = bitcast i32* %85 to i8*
  tail call void @_ZdlPv(i8* %91) #18
  br label %92

92:                                               ; preds = %83, %87
  ret void
}

; Function Attrs: noreturn
declare void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"*) local_unnamed_addr #11

; Function Attrs: noreturn nounwind
declare void @abort() local_unnamed_addr #12

; Function Attrs: nobuiltin nounwind
declare void @_ZdaPv(i8*) local_unnamed_addr #3

; Function Attrs: nobuiltin nofree
declare noalias nonnull i8* @_Znam(i64) local_unnamed_addr #2

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN6tflite13reference_ops22ShuffledFullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKiS6_PsPh(%"struct.tflite::FullyConnectedParams"* dereferenceable(40), %"class.tflite::RuntimeShape"* dereferenceable(32), i8*, %"class.tflite::RuntimeShape"* dereferenceable(32), i8*, %"class.tflite::RuntimeShape"* dereferenceable(32), i32*, %"class.tflite::RuntimeShape"* dereferenceable(32), i16*, i8*) local_unnamed_addr #4 comdat {
  %11 = alloca [4 x i32], align 16
  %12 = alloca [4 x [4 x i32]], align 16
  %13 = bitcast [4 x [4 x i32]]* %12 to i8*
  %14 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 3
  %15 = load i32, i32* %14, align 4
  %16 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 4
  %17 = load i32, i32* %16, align 4
  %18 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 5
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 6
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %3, i64 0, i32 0
  %23 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %7, i64 0, i32 0
  %24 = load i32, i32* %23, align 8
  %25 = load i32, i32* %22, align 8
  %26 = add nsw i32 %24, -1
  %27 = icmp sgt i32 %24, 5
  %28 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %7, i64 0, i32 1
  %29 = getelementptr inbounds %union.anon.54, %union.anon.54* %28, i64 0, i32 0
  %30 = load i32*, i32** %29, align 8
  %31 = bitcast %union.anon.54* %28 to i32*
  %32 = select i1 %27, i32* %30, i32* %31
  %33 = icmp sgt i32 %24, 0
  br i1 %33, label %34, label %74

34:                                               ; preds = %10
  %35 = zext i32 %26 to i64
  %36 = zext i32 %24 to i64
  %37 = add nsw i64 %36, -1
  %38 = and i64 %36, 3
  %39 = icmp ult i64 %37, 3
  br i1 %39, label %55, label %40

40:                                               ; preds = %34
  %41 = sub nsw i64 %36, %38
  br label %42

42:                                               ; preds = %1401, %40
  %43 = phi i64 [ 0, %40 ], [ %1404, %1401 ]
  %44 = phi i32 [ 1, %40 ], [ %1403, %1401 ]
  %45 = phi i64 [ %41, %40 ], [ %1405, %1401 ]
  %46 = icmp eq i64 %43, %35
  br i1 %46, label %50, label %47

47:                                               ; preds = %42
  %48 = getelementptr inbounds i32, i32* %32, i64 %43
  %49 = load i32, i32* %48, align 4
  br label %50

50:                                               ; preds = %47, %42
  %51 = phi i32 [ %49, %47 ], [ 1, %42 ]
  %52 = mul nsw i32 %51, %44
  %53 = or i64 %43, 1
  %54 = icmp eq i64 %53, %35
  br i1 %54, label %1385, label %1382

55:                                               ; preds = %1401, %34
  %56 = phi i32 [ undef, %34 ], [ %1403, %1401 ]
  %57 = phi i64 [ 0, %34 ], [ %1404, %1401 ]
  %58 = phi i32 [ 1, %34 ], [ %1403, %1401 ]
  %59 = icmp eq i64 %38, 0
  br i1 %59, label %74, label %60

60:                                               ; preds = %55, %68
  %61 = phi i64 [ %71, %68 ], [ %57, %55 ]
  %62 = phi i32 [ %70, %68 ], [ %58, %55 ]
  %63 = phi i64 [ %72, %68 ], [ %38, %55 ]
  %64 = icmp eq i64 %61, %35
  br i1 %64, label %68, label %65

65:                                               ; preds = %60
  %66 = getelementptr inbounds i32, i32* %32, i64 %61
  %67 = load i32, i32* %66, align 4
  br label %68

68:                                               ; preds = %65, %60
  %69 = phi i32 [ %67, %65 ], [ 1, %60 ]
  %70 = mul nsw i32 %69, %62
  %71 = add nuw nsw i64 %61, 1
  %72 = add i64 %63, -1
  %73 = icmp eq i64 %72, 0
  br i1 %73, label %74, label %60, !llvm.loop !155

74:                                               ; preds = %55, %68, %10
  %75 = phi i32 [ 1, %10 ], [ %56, %55 ], [ %70, %68 ]
  %76 = add nsw i32 %25, -2
  %77 = icmp sgt i32 %25, 5
  %78 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %3, i64 0, i32 1
  %79 = getelementptr inbounds %union.anon.54, %union.anon.54* %78, i64 0, i32 0
  %80 = load i32*, i32** %79, align 8
  %81 = sext i32 %76 to i64
  %82 = getelementptr inbounds i32, i32* %80, i64 %81
  %83 = bitcast %union.anon.54* %78 to [5 x i32]*
  %84 = getelementptr inbounds [5 x i32], [5 x i32]* %83, i64 0, i64 %81
  %85 = select i1 %77, i32* %82, i32* %84
  %86 = load i32, i32* %85, align 4
  %87 = sext i32 %26 to i64
  %88 = getelementptr inbounds i32, i32* %30, i64 %87
  %89 = bitcast %union.anon.54* %28 to [5 x i32]*
  %90 = getelementptr inbounds [5 x i32], [5 x i32]* %89, i64 0, i64 %87
  %91 = select i1 %27, i32* %88, i32* %90
  %92 = load i32, i32* %91, align 4
  %93 = icmp slt i32 %92, %86
  %94 = select i1 %93, i32 %92, i32 %86
  %95 = add nsw i32 %25, -1
  %96 = sext i32 %95 to i64
  %97 = getelementptr inbounds i32, i32* %80, i64 %96
  %98 = getelementptr inbounds [5 x i32], [5 x i32]* %83, i64 0, i64 %96
  %99 = select i1 %77, i32* %97, i32* %98
  %100 = load i32, i32* %99, align 4
  %101 = icmp eq i32 %75, 1
  br i1 %101, label %102, label %213

102:                                              ; preds = %74
  %103 = icmp sgt i32 %100, 0
  br i1 %103, label %104, label %297

104:                                              ; preds = %102
  %105 = zext i32 %100 to i64
  %106 = icmp ult i32 %100, 32
  br i1 %106, label %171, label %107

107:                                              ; preds = %104
  %108 = getelementptr i8, i8* %9, i64 %105
  %109 = getelementptr i8, i8* %2, i64 %105
  %110 = icmp ugt i8* %109, %9
  %111 = icmp ugt i8* %108, %2
  %112 = and i1 %110, %111
  br i1 %112, label %171, label %113

113:                                              ; preds = %107
  %114 = and i64 %105, 4294967264
  %115 = add nsw i64 %114, -32
  %116 = lshr exact i64 %115, 5
  %117 = add nuw nsw i64 %116, 1
  %118 = and i64 %117, 1
  %119 = icmp eq i64 %115, 0
  br i1 %119, label %153, label %120

120:                                              ; preds = %113
  %121 = sub nuw nsw i64 %117, %118
  br label %122

122:                                              ; preds = %122, %120
  %123 = phi i64 [ 0, %120 ], [ %150, %122 ]
  %124 = phi i64 [ %121, %120 ], [ %151, %122 ]
  %125 = getelementptr inbounds i8, i8* %2, i64 %123
  %126 = bitcast i8* %125 to <16 x i8>*
  %127 = load <16 x i8>, <16 x i8>* %126, align 1, !alias.scope !156
  %128 = getelementptr inbounds i8, i8* %125, i64 16
  %129 = bitcast i8* %128 to <16 x i8>*
  %130 = load <16 x i8>, <16 x i8>* %129, align 1, !alias.scope !156
  %131 = xor <16 x i8> %127, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %132 = xor <16 x i8> %130, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %133 = getelementptr inbounds i8, i8* %9, i64 %123
  %134 = bitcast i8* %133 to <16 x i8>*
  store <16 x i8> %131, <16 x i8>* %134, align 1, !alias.scope !159, !noalias !156
  %135 = getelementptr inbounds i8, i8* %133, i64 16
  %136 = bitcast i8* %135 to <16 x i8>*
  store <16 x i8> %132, <16 x i8>* %136, align 1, !alias.scope !159, !noalias !156
  %137 = or i64 %123, 32
  %138 = getelementptr inbounds i8, i8* %2, i64 %137
  %139 = bitcast i8* %138 to <16 x i8>*
  %140 = load <16 x i8>, <16 x i8>* %139, align 1, !alias.scope !156
  %141 = getelementptr inbounds i8, i8* %138, i64 16
  %142 = bitcast i8* %141 to <16 x i8>*
  %143 = load <16 x i8>, <16 x i8>* %142, align 1, !alias.scope !156
  %144 = xor <16 x i8> %140, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %145 = xor <16 x i8> %143, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %146 = getelementptr inbounds i8, i8* %9, i64 %137
  %147 = bitcast i8* %146 to <16 x i8>*
  store <16 x i8> %144, <16 x i8>* %147, align 1, !alias.scope !159, !noalias !156
  %148 = getelementptr inbounds i8, i8* %146, i64 16
  %149 = bitcast i8* %148 to <16 x i8>*
  store <16 x i8> %145, <16 x i8>* %149, align 1, !alias.scope !159, !noalias !156
  %150 = add i64 %123, 64
  %151 = add i64 %124, -2
  %152 = icmp eq i64 %151, 0
  br i1 %152, label %153, label %122, !llvm.loop !161

153:                                              ; preds = %122, %113
  %154 = phi i64 [ 0, %113 ], [ %150, %122 ]
  %155 = icmp eq i64 %118, 0
  br i1 %155, label %169, label %156

156:                                              ; preds = %153
  %157 = getelementptr inbounds i8, i8* %2, i64 %154
  %158 = bitcast i8* %157 to <16 x i8>*
  %159 = load <16 x i8>, <16 x i8>* %158, align 1, !alias.scope !156
  %160 = getelementptr inbounds i8, i8* %157, i64 16
  %161 = bitcast i8* %160 to <16 x i8>*
  %162 = load <16 x i8>, <16 x i8>* %161, align 1, !alias.scope !156
  %163 = xor <16 x i8> %159, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %164 = xor <16 x i8> %162, <i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128, i8 -128>
  %165 = getelementptr inbounds i8, i8* %9, i64 %154
  %166 = bitcast i8* %165 to <16 x i8>*
  store <16 x i8> %163, <16 x i8>* %166, align 1, !alias.scope !159, !noalias !156
  %167 = getelementptr inbounds i8, i8* %165, i64 16
  %168 = bitcast i8* %167 to <16 x i8>*
  store <16 x i8> %164, <16 x i8>* %168, align 1, !alias.scope !159, !noalias !156
  br label %169

169:                                              ; preds = %153, %156
  %170 = icmp eq i64 %114, %105
  br i1 %170, label %296, label %171

171:                                              ; preds = %169, %107, %104
  %172 = phi i64 [ 0, %107 ], [ 0, %104 ], [ %114, %169 ]
  %173 = xor i64 %172, -1
  %174 = add nsw i64 %173, %105
  %175 = and i64 %105, 3
  %176 = icmp eq i64 %175, 0
  br i1 %176, label %187, label %177

177:                                              ; preds = %171, %177
  %178 = phi i64 [ %184, %177 ], [ %172, %171 ]
  %179 = phi i64 [ %185, %177 ], [ %175, %171 ]
  %180 = getelementptr inbounds i8, i8* %2, i64 %178
  %181 = load i8, i8* %180, align 1
  %182 = xor i8 %181, -128
  %183 = getelementptr inbounds i8, i8* %9, i64 %178
  store i8 %182, i8* %183, align 1
  %184 = add nuw nsw i64 %178, 1
  %185 = add i64 %179, -1
  %186 = icmp eq i64 %185, 0
  br i1 %186, label %187, label %177, !llvm.loop !162

187:                                              ; preds = %177, %171
  %188 = phi i64 [ %172, %171 ], [ %184, %177 ]
  %189 = icmp ult i64 %174, 3
  br i1 %189, label %296, label %190

190:                                              ; preds = %187, %190
  %191 = phi i64 [ %211, %190 ], [ %188, %187 ]
  %192 = getelementptr inbounds i8, i8* %2, i64 %191
  %193 = load i8, i8* %192, align 1
  %194 = xor i8 %193, -128
  %195 = getelementptr inbounds i8, i8* %9, i64 %191
  store i8 %194, i8* %195, align 1
  %196 = add nuw nsw i64 %191, 1
  %197 = getelementptr inbounds i8, i8* %2, i64 %196
  %198 = load i8, i8* %197, align 1
  %199 = xor i8 %198, -128
  %200 = getelementptr inbounds i8, i8* %9, i64 %196
  store i8 %199, i8* %200, align 1
  %201 = add nuw nsw i64 %191, 2
  %202 = getelementptr inbounds i8, i8* %2, i64 %201
  %203 = load i8, i8* %202, align 1
  %204 = xor i8 %203, -128
  %205 = getelementptr inbounds i8, i8* %9, i64 %201
  store i8 %204, i8* %205, align 1
  %206 = add nuw nsw i64 %191, 3
  %207 = getelementptr inbounds i8, i8* %2, i64 %206
  %208 = load i8, i8* %207, align 1
  %209 = xor i8 %208, -128
  %210 = getelementptr inbounds i8, i8* %9, i64 %206
  store i8 %209, i8* %210, align 1
  %211 = add nuw nsw i64 %191, 4
  %212 = icmp eq i64 %211, %105
  br i1 %212, label %296, label %190, !llvm.loop !163

213:                                              ; preds = %74
  %214 = icmp eq i32 %75, 4
  br i1 %214, label %215, label %1188

215:                                              ; preds = %213
  %216 = icmp sgt i32 %100, 0
  br i1 %216, label %217, label %523

217:                                              ; preds = %215
  %218 = sext i32 %100 to i64
  br label %219

219:                                              ; preds = %217, %223
  %220 = phi i64 [ 0, %217 ], [ %224, %223 ]
  %221 = phi i8* [ %9, %217 ], [ %293, %223 ]
  %222 = getelementptr inbounds i8, i8* %2, i64 %220
  br label %226

223:                                              ; preds = %226
  %224 = add nuw nsw i64 %220, 16
  %225 = icmp slt i64 %224, %218
  br i1 %225, label %219, label %296

226:                                              ; preds = %226, %219
  %227 = phi i64 [ 0, %219 ], [ %294, %226 ]
  %228 = phi i8* [ %221, %219 ], [ %293, %226 ]
  %229 = mul nsw i64 %227, %218
  %230 = getelementptr inbounds i8, i8* %222, i64 %229
  %231 = getelementptr inbounds i8, i8* %230, i64 1
  %232 = load i8, i8* %230, align 1
  %233 = xor i8 %232, -128
  %234 = getelementptr inbounds i8, i8* %228, i64 1
  store i8 %233, i8* %228, align 1
  %235 = getelementptr inbounds i8, i8* %231, i64 1
  %236 = load i8, i8* %231, align 1
  %237 = xor i8 %236, -128
  %238 = getelementptr inbounds i8, i8* %228, i64 2
  store i8 %237, i8* %234, align 1
  %239 = getelementptr inbounds i8, i8* %235, i64 1
  %240 = load i8, i8* %235, align 1
  %241 = xor i8 %240, -128
  %242 = getelementptr inbounds i8, i8* %228, i64 3
  store i8 %241, i8* %238, align 1
  %243 = getelementptr inbounds i8, i8* %239, i64 1
  %244 = load i8, i8* %239, align 1
  %245 = xor i8 %244, -128
  %246 = getelementptr inbounds i8, i8* %228, i64 4
  store i8 %245, i8* %242, align 1
  %247 = getelementptr inbounds i8, i8* %243, i64 1
  %248 = load i8, i8* %243, align 1
  %249 = xor i8 %248, -128
  %250 = getelementptr inbounds i8, i8* %228, i64 5
  store i8 %249, i8* %246, align 1
  %251 = getelementptr inbounds i8, i8* %247, i64 1
  %252 = load i8, i8* %247, align 1
  %253 = xor i8 %252, -128
  %254 = getelementptr inbounds i8, i8* %228, i64 6
  store i8 %253, i8* %250, align 1
  %255 = getelementptr inbounds i8, i8* %251, i64 1
  %256 = load i8, i8* %251, align 1
  %257 = xor i8 %256, -128
  %258 = getelementptr inbounds i8, i8* %228, i64 7
  store i8 %257, i8* %254, align 1
  %259 = getelementptr inbounds i8, i8* %255, i64 1
  %260 = load i8, i8* %255, align 1
  %261 = xor i8 %260, -128
  %262 = getelementptr inbounds i8, i8* %228, i64 8
  store i8 %261, i8* %258, align 1
  %263 = getelementptr inbounds i8, i8* %259, i64 1
  %264 = load i8, i8* %259, align 1
  %265 = xor i8 %264, -128
  %266 = getelementptr inbounds i8, i8* %228, i64 9
  store i8 %265, i8* %262, align 1
  %267 = getelementptr inbounds i8, i8* %263, i64 1
  %268 = load i8, i8* %263, align 1
  %269 = xor i8 %268, -128
  %270 = getelementptr inbounds i8, i8* %228, i64 10
  store i8 %269, i8* %266, align 1
  %271 = getelementptr inbounds i8, i8* %267, i64 1
  %272 = load i8, i8* %267, align 1
  %273 = xor i8 %272, -128
  %274 = getelementptr inbounds i8, i8* %228, i64 11
  store i8 %273, i8* %270, align 1
  %275 = getelementptr inbounds i8, i8* %271, i64 1
  %276 = load i8, i8* %271, align 1
  %277 = xor i8 %276, -128
  %278 = getelementptr inbounds i8, i8* %228, i64 12
  store i8 %277, i8* %274, align 1
  %279 = getelementptr inbounds i8, i8* %275, i64 1
  %280 = load i8, i8* %275, align 1
  %281 = xor i8 %280, -128
  %282 = getelementptr inbounds i8, i8* %228, i64 13
  store i8 %281, i8* %278, align 1
  %283 = getelementptr inbounds i8, i8* %279, i64 1
  %284 = load i8, i8* %279, align 1
  %285 = xor i8 %284, -128
  %286 = getelementptr inbounds i8, i8* %228, i64 14
  store i8 %285, i8* %282, align 1
  %287 = getelementptr inbounds i8, i8* %283, i64 1
  %288 = load i8, i8* %283, align 1
  %289 = xor i8 %288, -128
  %290 = getelementptr inbounds i8, i8* %228, i64 15
  store i8 %289, i8* %286, align 1
  %291 = load i8, i8* %287, align 1
  %292 = xor i8 %291, -128
  %293 = getelementptr inbounds i8, i8* %228, i64 16
  store i8 %292, i8* %290, align 1
  %294 = add nuw nsw i64 %227, 1
  %295 = icmp eq i64 %294, 4
  br i1 %295, label %223, label %226

296:                                              ; preds = %223, %187, %190, %169
  br i1 %101, label %297, label %523

297:                                              ; preds = %102, %296
  %298 = icmp sgt i32 %94, 0
  br i1 %298, label %299, label %1188

299:                                              ; preds = %297
  %300 = bitcast [4 x i32]* %11 to i8*
  %301 = icmp sgt i32 %100, 0
  %302 = icmp sgt i32 %17, 0
  %303 = sub nsw i32 0, %17
  %304 = select i1 %302, i32 0, i32 %303
  %305 = shl i32 1, %17
  %306 = select i1 %302, i32 %305, i32 1
  %307 = sext i32 %15 to i64
  %308 = icmp eq i32 %15, -2147483648
  %309 = mul nsw i64 %307, %307
  %310 = zext i32 %304 to i64
  %311 = shl nsw i64 -1, %310
  %312 = trunc i64 %311 to i32
  %313 = xor i32 %312, -1
  %314 = ashr i32 %313, 1
  %315 = sext i32 %100 to i64
  %316 = sext i32 %94 to i64
  %317 = getelementptr inbounds [4 x i32], [4 x i32]* %11, i64 0, i64 0
  %318 = getelementptr inbounds [4 x i32], [4 x i32]* %11, i64 0, i64 1
  %319 = getelementptr inbounds [4 x i32], [4 x i32]* %11, i64 0, i64 2
  %320 = getelementptr inbounds [4 x i32], [4 x i32]* %11, i64 0, i64 3
  br label %321

321:                                              ; preds = %299, %1266
  %322 = phi i64 [ 0, %299 ], [ %1281, %1266 ]
  %323 = phi i8* [ %4, %299 ], [ %328, %1266 ]
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %300) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %300, i8 0, i64 16, i1 false)
  br i1 %301, label %334, label %326

324:                                              ; preds = %487
  %325 = load i32, i32* %317, align 16
  br label %326

326:                                              ; preds = %324, %321
  %327 = phi i32 [ 0, %321 ], [ %325, %324 ]
  %328 = phi i8* [ %323, %321 ], [ %479, %324 ]
  %329 = getelementptr inbounds i32, i32* %6, i64 %322
  %330 = load i32, i32* %329, align 4
  %331 = add nsw i32 %330, %327
  %332 = mul nsw i32 %331, %306
  %333 = icmp eq i32 %332, %15
  br i1 %333, label %493, label %490

334:                                              ; preds = %321, %487
  %335 = phi i64 [ %488, %487 ], [ 0, %321 ]
  %336 = phi i8* [ %479, %487 ], [ %323, %321 ]
  %337 = getelementptr inbounds i8, i8* %9, i64 %335
  %338 = or i64 %335, 1
  %339 = getelementptr inbounds i8, i8* %9, i64 %338
  %340 = or i64 %335, 2
  %341 = getelementptr inbounds i8, i8* %9, i64 %340
  %342 = or i64 %335, 3
  %343 = getelementptr inbounds i8, i8* %9, i64 %342
  %344 = or i64 %335, 4
  %345 = getelementptr inbounds i8, i8* %9, i64 %344
  %346 = or i64 %335, 5
  %347 = getelementptr inbounds i8, i8* %9, i64 %346
  %348 = or i64 %335, 6
  %349 = getelementptr inbounds i8, i8* %9, i64 %348
  %350 = or i64 %335, 7
  %351 = getelementptr inbounds i8, i8* %9, i64 %350
  %352 = or i64 %335, 8
  %353 = getelementptr inbounds i8, i8* %9, i64 %352
  %354 = or i64 %335, 9
  %355 = getelementptr inbounds i8, i8* %9, i64 %354
  %356 = or i64 %335, 10
  %357 = getelementptr inbounds i8, i8* %9, i64 %356
  %358 = or i64 %335, 11
  %359 = getelementptr inbounds i8, i8* %9, i64 %358
  %360 = or i64 %335, 12
  %361 = getelementptr inbounds i8, i8* %9, i64 %360
  %362 = or i64 %335, 13
  %363 = getelementptr inbounds i8, i8* %9, i64 %362
  %364 = or i64 %335, 14
  %365 = getelementptr inbounds i8, i8* %9, i64 %364
  %366 = or i64 %335, 15
  %367 = getelementptr inbounds i8, i8* %9, i64 %366
  br label %368

368:                                              ; preds = %368, %334
  %369 = phi i64 [ 0, %334 ], [ %485, %368 ]
  %370 = phi i8* [ %336, %334 ], [ %479, %368 ]
  %371 = getelementptr inbounds [4 x i32], [4 x i32]* %11, i64 0, i64 %369
  %372 = load i8, i8* %337, align 1
  %373 = getelementptr inbounds i8, i8* %370, i64 1
  %374 = load i8, i8* %370, align 1
  %375 = sext i8 %374 to i32
  %376 = sext i8 %372 to i32
  %377 = mul nsw i32 %375, %376
  %378 = load i32, i32* %371, align 4
  %379 = add nsw i32 %377, %378
  store i32 %379, i32* %371, align 4
  %380 = load i8, i8* %339, align 1
  %381 = getelementptr inbounds i8, i8* %370, i64 2
  %382 = load i8, i8* %373, align 1
  %383 = sext i8 %382 to i32
  %384 = sext i8 %380 to i32
  %385 = mul nsw i32 %383, %384
  %386 = add nsw i32 %385, %379
  store i32 %386, i32* %371, align 4
  %387 = load i8, i8* %341, align 1
  %388 = getelementptr inbounds i8, i8* %370, i64 3
  %389 = load i8, i8* %381, align 1
  %390 = sext i8 %389 to i32
  %391 = sext i8 %387 to i32
  %392 = mul nsw i32 %390, %391
  %393 = add nsw i32 %392, %386
  store i32 %393, i32* %371, align 4
  %394 = load i8, i8* %343, align 1
  %395 = getelementptr inbounds i8, i8* %370, i64 4
  %396 = load i8, i8* %388, align 1
  %397 = sext i8 %396 to i32
  %398 = sext i8 %394 to i32
  %399 = mul nsw i32 %397, %398
  %400 = add nsw i32 %399, %393
  store i32 %400, i32* %371, align 4
  %401 = load i8, i8* %345, align 1
  %402 = getelementptr inbounds i8, i8* %370, i64 5
  %403 = load i8, i8* %395, align 1
  %404 = sext i8 %403 to i32
  %405 = sext i8 %401 to i32
  %406 = mul nsw i32 %404, %405
  %407 = add nsw i32 %406, %400
  store i32 %407, i32* %371, align 4
  %408 = load i8, i8* %347, align 1
  %409 = getelementptr inbounds i8, i8* %370, i64 6
  %410 = load i8, i8* %402, align 1
  %411 = sext i8 %410 to i32
  %412 = sext i8 %408 to i32
  %413 = mul nsw i32 %411, %412
  %414 = add nsw i32 %413, %407
  store i32 %414, i32* %371, align 4
  %415 = load i8, i8* %349, align 1
  %416 = getelementptr inbounds i8, i8* %370, i64 7
  %417 = load i8, i8* %409, align 1
  %418 = sext i8 %417 to i32
  %419 = sext i8 %415 to i32
  %420 = mul nsw i32 %418, %419
  %421 = add nsw i32 %420, %414
  store i32 %421, i32* %371, align 4
  %422 = load i8, i8* %351, align 1
  %423 = getelementptr inbounds i8, i8* %370, i64 8
  %424 = load i8, i8* %416, align 1
  %425 = sext i8 %424 to i32
  %426 = sext i8 %422 to i32
  %427 = mul nsw i32 %425, %426
  %428 = add nsw i32 %427, %421
  store i32 %428, i32* %371, align 4
  %429 = load i8, i8* %353, align 1
  %430 = getelementptr inbounds i8, i8* %370, i64 9
  %431 = load i8, i8* %423, align 1
  %432 = sext i8 %431 to i32
  %433 = sext i8 %429 to i32
  %434 = mul nsw i32 %432, %433
  %435 = add nsw i32 %434, %428
  store i32 %435, i32* %371, align 4
  %436 = load i8, i8* %355, align 1
  %437 = getelementptr inbounds i8, i8* %370, i64 10
  %438 = load i8, i8* %430, align 1
  %439 = sext i8 %438 to i32
  %440 = sext i8 %436 to i32
  %441 = mul nsw i32 %439, %440
  %442 = add nsw i32 %441, %435
  store i32 %442, i32* %371, align 4
  %443 = load i8, i8* %357, align 1
  %444 = getelementptr inbounds i8, i8* %370, i64 11
  %445 = load i8, i8* %437, align 1
  %446 = sext i8 %445 to i32
  %447 = sext i8 %443 to i32
  %448 = mul nsw i32 %446, %447
  %449 = add nsw i32 %448, %442
  store i32 %449, i32* %371, align 4
  %450 = load i8, i8* %359, align 1
  %451 = getelementptr inbounds i8, i8* %370, i64 12
  %452 = load i8, i8* %444, align 1
  %453 = sext i8 %452 to i32
  %454 = sext i8 %450 to i32
  %455 = mul nsw i32 %453, %454
  %456 = add nsw i32 %455, %449
  store i32 %456, i32* %371, align 4
  %457 = load i8, i8* %361, align 1
  %458 = getelementptr inbounds i8, i8* %370, i64 13
  %459 = load i8, i8* %451, align 1
  %460 = sext i8 %459 to i32
  %461 = sext i8 %457 to i32
  %462 = mul nsw i32 %460, %461
  %463 = add nsw i32 %462, %456
  store i32 %463, i32* %371, align 4
  %464 = load i8, i8* %363, align 1
  %465 = getelementptr inbounds i8, i8* %370, i64 14
  %466 = load i8, i8* %458, align 1
  %467 = sext i8 %466 to i32
  %468 = sext i8 %464 to i32
  %469 = mul nsw i32 %467, %468
  %470 = add nsw i32 %469, %463
  store i32 %470, i32* %371, align 4
  %471 = load i8, i8* %365, align 1
  %472 = getelementptr inbounds i8, i8* %370, i64 15
  %473 = load i8, i8* %465, align 1
  %474 = sext i8 %473 to i32
  %475 = sext i8 %471 to i32
  %476 = mul nsw i32 %474, %475
  %477 = add nsw i32 %476, %470
  store i32 %477, i32* %371, align 4
  %478 = load i8, i8* %367, align 1
  %479 = getelementptr inbounds i8, i8* %370, i64 16
  %480 = load i8, i8* %472, align 1
  %481 = sext i8 %480 to i32
  %482 = sext i8 %478 to i32
  %483 = mul nsw i32 %481, %482
  %484 = add nsw i32 %483, %477
  store i32 %484, i32* %371, align 4
  %485 = add nuw nsw i64 %369, 1
  %486 = icmp eq i64 %485, 4
  br i1 %486, label %487, label %368

487:                                              ; preds = %368
  %488 = add nuw nsw i64 %335, 16
  %489 = icmp slt i64 %488, %315
  br i1 %489, label %334, label %324

490:                                              ; preds = %326
  %491 = sext i32 %332 to i64
  %492 = mul nsw i64 %491, %307
  br label %494

493:                                              ; preds = %326
  br i1 %308, label %501, label %494

494:                                              ; preds = %493, %490
  %495 = phi i64 [ %492, %490 ], [ %309, %493 ]
  %496 = icmp sgt i64 %495, -1
  %497 = select i1 %496, i64 1073741824, i64 -1073741823
  %498 = add nsw i64 %497, %495
  %499 = sdiv i64 %498, 2147483648
  %500 = trunc i64 %499 to i32
  br label %501

501:                                              ; preds = %493, %494
  %502 = phi i32 [ %500, %494 ], [ 2147483647, %493 ]
  %503 = and i32 %502, %313
  %504 = lshr i32 %502, 31
  %505 = add nsw i32 %504, %314
  %506 = ashr i32 %502, %304
  %507 = icmp sgt i32 %503, %505
  %508 = zext i1 %507 to i32
  %509 = add nsw i32 %506, %508
  %510 = icmp slt i32 %509, %19
  %511 = select i1 %510, i32 %19, i32 %509
  %512 = icmp slt i32 %21, %511
  %513 = select i1 %512, i32 %21, i32 %511
  %514 = trunc i32 %513 to i16
  %515 = getelementptr inbounds i16, i16* %8, i64 %322
  store i16 %514, i16* %515, align 2
  %516 = load i32, i32* %318, align 4
  %517 = or i64 %322, 1
  %518 = getelementptr inbounds i32, i32* %6, i64 %517
  %519 = load i32, i32* %518, align 4
  %520 = add nsw i32 %519, %516
  %521 = mul nsw i32 %520, %306
  %522 = icmp eq i32 %521, %15
  br i1 %522, label %1192, label %1189

523:                                              ; preds = %215, %296
  %524 = icmp eq i32 %75, 4
  %525 = icmp sgt i32 %94, 0
  %526 = and i1 %524, %525
  br i1 %526, label %527, label %1188

527:                                              ; preds = %523
  %528 = icmp sgt i32 %100, 0
  %529 = icmp sgt i32 %17, 0
  %530 = sub nsw i32 0, %17
  %531 = select i1 %529, i32 0, i32 %530
  %532 = shl i32 1, %17
  %533 = select i1 %529, i32 %532, i32 1
  %534 = sext i32 %15 to i64
  %535 = icmp eq i32 %15, -2147483648
  %536 = mul nsw i64 %534, %534
  %537 = zext i32 %531 to i64
  %538 = shl nsw i64 -1, %537
  %539 = trunc i64 %538 to i32
  %540 = xor i32 %539, -1
  %541 = ashr i32 %540, 1
  %542 = sext i32 %94 to i64
  %543 = shl i32 %94, 1
  %544 = mul i32 %94, 3
  br label %545

545:                                              ; preds = %527, %1153
  %546 = phi i64 [ 0, %527 ], [ %1154, %1153 ]
  %547 = phi i8* [ %4, %527 ], [ %549, %1153 ]
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %13) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %13, i8 0, i64 64, i1 false)
  br i1 %528, label %550, label %548

548:                                              ; preds = %1138, %545
  %549 = phi i8* [ %547, %545 ], [ %1140, %1138 ]
  br label %1143

550:                                              ; preds = %545, %1138
  %551 = phi i32 [ %1141, %1138 ], [ 0, %545 ]
  %552 = phi i8* [ %1139, %1138 ], [ %9, %545 ]
  %553 = phi i8* [ %1140, %1138 ], [ %547, %545 ]
  %554 = getelementptr inbounds i8, i8* %552, i64 48
  %555 = getelementptr inbounds i8, i8* %552, i64 1
  %556 = getelementptr inbounds i8, i8* %552, i64 2
  %557 = getelementptr inbounds i8, i8* %552, i64 3
  %558 = getelementptr inbounds i8, i8* %552, i64 4
  %559 = getelementptr inbounds i8, i8* %552, i64 5
  %560 = getelementptr inbounds i8, i8* %552, i64 6
  %561 = getelementptr inbounds i8, i8* %552, i64 7
  %562 = getelementptr inbounds i8, i8* %552, i64 8
  %563 = getelementptr inbounds i8, i8* %552, i64 9
  %564 = getelementptr inbounds i8, i8* %552, i64 10
  %565 = getelementptr inbounds i8, i8* %552, i64 11
  %566 = getelementptr inbounds i8, i8* %552, i64 12
  %567 = getelementptr inbounds i8, i8* %552, i64 13
  %568 = getelementptr inbounds i8, i8* %552, i64 14
  %569 = getelementptr inbounds i8, i8* %552, i64 15
  %570 = getelementptr inbounds i8, i8* %552, i64 16
  %571 = getelementptr inbounds i8, i8* %552, i64 17
  %572 = getelementptr inbounds i8, i8* %552, i64 18
  %573 = getelementptr inbounds i8, i8* %552, i64 19
  %574 = getelementptr inbounds i8, i8* %552, i64 20
  %575 = getelementptr inbounds i8, i8* %552, i64 21
  %576 = getelementptr inbounds i8, i8* %552, i64 22
  %577 = getelementptr inbounds i8, i8* %552, i64 23
  %578 = getelementptr inbounds i8, i8* %552, i64 24
  %579 = getelementptr inbounds i8, i8* %552, i64 25
  %580 = getelementptr inbounds i8, i8* %552, i64 26
  %581 = getelementptr inbounds i8, i8* %552, i64 27
  %582 = getelementptr inbounds i8, i8* %552, i64 28
  %583 = getelementptr inbounds i8, i8* %552, i64 29
  %584 = getelementptr inbounds i8, i8* %552, i64 30
  %585 = getelementptr inbounds i8, i8* %552, i64 31
  %586 = getelementptr inbounds i8, i8* %552, i64 32
  %587 = getelementptr inbounds i8, i8* %552, i64 33
  %588 = getelementptr inbounds i8, i8* %552, i64 34
  %589 = getelementptr inbounds i8, i8* %552, i64 35
  %590 = getelementptr inbounds i8, i8* %552, i64 36
  %591 = getelementptr inbounds i8, i8* %552, i64 37
  %592 = getelementptr inbounds i8, i8* %552, i64 38
  %593 = getelementptr inbounds i8, i8* %552, i64 39
  %594 = getelementptr inbounds i8, i8* %552, i64 40
  %595 = getelementptr inbounds i8, i8* %552, i64 41
  %596 = getelementptr inbounds i8, i8* %552, i64 42
  %597 = getelementptr inbounds i8, i8* %552, i64 43
  %598 = getelementptr inbounds i8, i8* %552, i64 44
  %599 = getelementptr inbounds i8, i8* %552, i64 45
  %600 = getelementptr inbounds i8, i8* %552, i64 46
  %601 = getelementptr inbounds i8, i8* %552, i64 47
  %602 = getelementptr inbounds i8, i8* %552, i64 49
  %603 = getelementptr inbounds i8, i8* %552, i64 50
  %604 = getelementptr inbounds i8, i8* %552, i64 51
  %605 = getelementptr inbounds i8, i8* %552, i64 52
  %606 = getelementptr inbounds i8, i8* %552, i64 53
  %607 = getelementptr inbounds i8, i8* %552, i64 54
  %608 = getelementptr inbounds i8, i8* %552, i64 55
  %609 = getelementptr inbounds i8, i8* %552, i64 56
  %610 = getelementptr inbounds i8, i8* %552, i64 57
  %611 = getelementptr inbounds i8, i8* %552, i64 58
  %612 = getelementptr inbounds i8, i8* %552, i64 59
  %613 = getelementptr inbounds i8, i8* %552, i64 60
  %614 = getelementptr inbounds i8, i8* %552, i64 61
  %615 = getelementptr inbounds i8, i8* %552, i64 62
  %616 = getelementptr inbounds i8, i8* %552, i64 63
  br label %617

617:                                              ; preds = %617, %550
  %618 = phi i64 [ 0, %550 ], [ %1136, %617 ]
  %619 = shl i64 %618, 4
  %620 = getelementptr inbounds [4 x [4 x i32]], [4 x [4 x i32]]* %12, i64 0, i64 %618, i64 0
  %621 = load i32, i32* %620, align 16
  %622 = load i8, i8* %552, align 1
  %623 = getelementptr inbounds i8, i8* %553, i64 %619
  %624 = load i8, i8* %623, align 1
  %625 = sext i8 %624 to i32
  %626 = sext i8 %622 to i32
  %627 = mul nsw i32 %625, %626
  %628 = add nsw i32 %627, %621
  store i32 %628, i32* %620, align 16
  %629 = load i8, i8* %555, align 1
  %630 = or i64 %619, 1
  %631 = getelementptr inbounds i8, i8* %553, i64 %630
  %632 = load i8, i8* %631, align 1
  %633 = sext i8 %632 to i32
  %634 = sext i8 %629 to i32
  %635 = mul nsw i32 %633, %634
  %636 = add nsw i32 %635, %628
  store i32 %636, i32* %620, align 16
  %637 = load i8, i8* %556, align 1
  %638 = or i64 %619, 2
  %639 = getelementptr inbounds i8, i8* %553, i64 %638
  %640 = load i8, i8* %639, align 1
  %641 = sext i8 %640 to i32
  %642 = sext i8 %637 to i32
  %643 = mul nsw i32 %641, %642
  %644 = add nsw i32 %643, %636
  store i32 %644, i32* %620, align 16
  %645 = load i8, i8* %557, align 1
  %646 = or i64 %619, 3
  %647 = getelementptr inbounds i8, i8* %553, i64 %646
  %648 = load i8, i8* %647, align 1
  %649 = sext i8 %648 to i32
  %650 = sext i8 %645 to i32
  %651 = mul nsw i32 %649, %650
  %652 = add nsw i32 %651, %644
  store i32 %652, i32* %620, align 16
  %653 = load i8, i8* %558, align 1
  %654 = or i64 %619, 4
  %655 = getelementptr inbounds i8, i8* %553, i64 %654
  %656 = load i8, i8* %655, align 1
  %657 = sext i8 %656 to i32
  %658 = sext i8 %653 to i32
  %659 = mul nsw i32 %657, %658
  %660 = add nsw i32 %659, %652
  store i32 %660, i32* %620, align 16
  %661 = load i8, i8* %559, align 1
  %662 = or i64 %619, 5
  %663 = getelementptr inbounds i8, i8* %553, i64 %662
  %664 = load i8, i8* %663, align 1
  %665 = sext i8 %664 to i32
  %666 = sext i8 %661 to i32
  %667 = mul nsw i32 %665, %666
  %668 = add nsw i32 %667, %660
  store i32 %668, i32* %620, align 16
  %669 = load i8, i8* %560, align 1
  %670 = or i64 %619, 6
  %671 = getelementptr inbounds i8, i8* %553, i64 %670
  %672 = load i8, i8* %671, align 1
  %673 = sext i8 %672 to i32
  %674 = sext i8 %669 to i32
  %675 = mul nsw i32 %673, %674
  %676 = add nsw i32 %675, %668
  store i32 %676, i32* %620, align 16
  %677 = load i8, i8* %561, align 1
  %678 = or i64 %619, 7
  %679 = getelementptr inbounds i8, i8* %553, i64 %678
  %680 = load i8, i8* %679, align 1
  %681 = sext i8 %680 to i32
  %682 = sext i8 %677 to i32
  %683 = mul nsw i32 %681, %682
  %684 = add nsw i32 %683, %676
  store i32 %684, i32* %620, align 16
  %685 = load i8, i8* %562, align 1
  %686 = or i64 %619, 8
  %687 = getelementptr inbounds i8, i8* %553, i64 %686
  %688 = load i8, i8* %687, align 1
  %689 = sext i8 %688 to i32
  %690 = sext i8 %685 to i32
  %691 = mul nsw i32 %689, %690
  %692 = add nsw i32 %691, %684
  store i32 %692, i32* %620, align 16
  %693 = load i8, i8* %563, align 1
  %694 = or i64 %619, 9
  %695 = getelementptr inbounds i8, i8* %553, i64 %694
  %696 = load i8, i8* %695, align 1
  %697 = sext i8 %696 to i32
  %698 = sext i8 %693 to i32
  %699 = mul nsw i32 %697, %698
  %700 = add nsw i32 %699, %692
  store i32 %700, i32* %620, align 16
  %701 = load i8, i8* %564, align 1
  %702 = or i64 %619, 10
  %703 = getelementptr inbounds i8, i8* %553, i64 %702
  %704 = load i8, i8* %703, align 1
  %705 = sext i8 %704 to i32
  %706 = sext i8 %701 to i32
  %707 = mul nsw i32 %705, %706
  %708 = add nsw i32 %707, %700
  store i32 %708, i32* %620, align 16
  %709 = load i8, i8* %565, align 1
  %710 = or i64 %619, 11
  %711 = getelementptr inbounds i8, i8* %553, i64 %710
  %712 = load i8, i8* %711, align 1
  %713 = sext i8 %712 to i32
  %714 = sext i8 %709 to i32
  %715 = mul nsw i32 %713, %714
  %716 = add nsw i32 %715, %708
  store i32 %716, i32* %620, align 16
  %717 = load i8, i8* %566, align 1
  %718 = or i64 %619, 12
  %719 = getelementptr inbounds i8, i8* %553, i64 %718
  %720 = load i8, i8* %719, align 1
  %721 = sext i8 %720 to i32
  %722 = sext i8 %717 to i32
  %723 = mul nsw i32 %721, %722
  %724 = add nsw i32 %723, %716
  store i32 %724, i32* %620, align 16
  %725 = load i8, i8* %567, align 1
  %726 = or i64 %619, 13
  %727 = getelementptr inbounds i8, i8* %553, i64 %726
  %728 = load i8, i8* %727, align 1
  %729 = sext i8 %728 to i32
  %730 = sext i8 %725 to i32
  %731 = mul nsw i32 %729, %730
  %732 = add nsw i32 %731, %724
  store i32 %732, i32* %620, align 16
  %733 = load i8, i8* %568, align 1
  %734 = or i64 %619, 14
  %735 = getelementptr inbounds i8, i8* %553, i64 %734
  %736 = load i8, i8* %735, align 1
  %737 = sext i8 %736 to i32
  %738 = sext i8 %733 to i32
  %739 = mul nsw i32 %737, %738
  %740 = add nsw i32 %739, %732
  store i32 %740, i32* %620, align 16
  %741 = load i8, i8* %569, align 1
  %742 = or i64 %619, 15
  %743 = getelementptr inbounds i8, i8* %553, i64 %742
  %744 = load i8, i8* %743, align 1
  %745 = sext i8 %744 to i32
  %746 = sext i8 %741 to i32
  %747 = mul nsw i32 %745, %746
  %748 = add nsw i32 %747, %740
  store i32 %748, i32* %620, align 16
  %749 = getelementptr inbounds [4 x [4 x i32]], [4 x [4 x i32]]* %12, i64 0, i64 %618, i64 1
  %750 = load i32, i32* %749, align 4
  %751 = load i8, i8* %570, align 1
  %752 = getelementptr inbounds i8, i8* %553, i64 %619
  %753 = load i8, i8* %752, align 1
  %754 = sext i8 %753 to i32
  %755 = sext i8 %751 to i32
  %756 = mul nsw i32 %754, %755
  %757 = add nsw i32 %756, %750
  store i32 %757, i32* %749, align 4
  %758 = load i8, i8* %571, align 1
  %759 = or i64 %619, 1
  %760 = getelementptr inbounds i8, i8* %553, i64 %759
  %761 = load i8, i8* %760, align 1
  %762 = sext i8 %761 to i32
  %763 = sext i8 %758 to i32
  %764 = mul nsw i32 %762, %763
  %765 = add nsw i32 %764, %757
  store i32 %765, i32* %749, align 4
  %766 = load i8, i8* %572, align 1
  %767 = or i64 %619, 2
  %768 = getelementptr inbounds i8, i8* %553, i64 %767
  %769 = load i8, i8* %768, align 1
  %770 = sext i8 %769 to i32
  %771 = sext i8 %766 to i32
  %772 = mul nsw i32 %770, %771
  %773 = add nsw i32 %772, %765
  store i32 %773, i32* %749, align 4
  %774 = load i8, i8* %573, align 1
  %775 = or i64 %619, 3
  %776 = getelementptr inbounds i8, i8* %553, i64 %775
  %777 = load i8, i8* %776, align 1
  %778 = sext i8 %777 to i32
  %779 = sext i8 %774 to i32
  %780 = mul nsw i32 %778, %779
  %781 = add nsw i32 %780, %773
  store i32 %781, i32* %749, align 4
  %782 = load i8, i8* %574, align 1
  %783 = or i64 %619, 4
  %784 = getelementptr inbounds i8, i8* %553, i64 %783
  %785 = load i8, i8* %784, align 1
  %786 = sext i8 %785 to i32
  %787 = sext i8 %782 to i32
  %788 = mul nsw i32 %786, %787
  %789 = add nsw i32 %788, %781
  store i32 %789, i32* %749, align 4
  %790 = load i8, i8* %575, align 1
  %791 = or i64 %619, 5
  %792 = getelementptr inbounds i8, i8* %553, i64 %791
  %793 = load i8, i8* %792, align 1
  %794 = sext i8 %793 to i32
  %795 = sext i8 %790 to i32
  %796 = mul nsw i32 %794, %795
  %797 = add nsw i32 %796, %789
  store i32 %797, i32* %749, align 4
  %798 = load i8, i8* %576, align 1
  %799 = or i64 %619, 6
  %800 = getelementptr inbounds i8, i8* %553, i64 %799
  %801 = load i8, i8* %800, align 1
  %802 = sext i8 %801 to i32
  %803 = sext i8 %798 to i32
  %804 = mul nsw i32 %802, %803
  %805 = add nsw i32 %804, %797
  store i32 %805, i32* %749, align 4
  %806 = load i8, i8* %577, align 1
  %807 = or i64 %619, 7
  %808 = getelementptr inbounds i8, i8* %553, i64 %807
  %809 = load i8, i8* %808, align 1
  %810 = sext i8 %809 to i32
  %811 = sext i8 %806 to i32
  %812 = mul nsw i32 %810, %811
  %813 = add nsw i32 %812, %805
  store i32 %813, i32* %749, align 4
  %814 = load i8, i8* %578, align 1
  %815 = or i64 %619, 8
  %816 = getelementptr inbounds i8, i8* %553, i64 %815
  %817 = load i8, i8* %816, align 1
  %818 = sext i8 %817 to i32
  %819 = sext i8 %814 to i32
  %820 = mul nsw i32 %818, %819
  %821 = add nsw i32 %820, %813
  store i32 %821, i32* %749, align 4
  %822 = load i8, i8* %579, align 1
  %823 = or i64 %619, 9
  %824 = getelementptr inbounds i8, i8* %553, i64 %823
  %825 = load i8, i8* %824, align 1
  %826 = sext i8 %825 to i32
  %827 = sext i8 %822 to i32
  %828 = mul nsw i32 %826, %827
  %829 = add nsw i32 %828, %821
  store i32 %829, i32* %749, align 4
  %830 = load i8, i8* %580, align 1
  %831 = or i64 %619, 10
  %832 = getelementptr inbounds i8, i8* %553, i64 %831
  %833 = load i8, i8* %832, align 1
  %834 = sext i8 %833 to i32
  %835 = sext i8 %830 to i32
  %836 = mul nsw i32 %834, %835
  %837 = add nsw i32 %836, %829
  store i32 %837, i32* %749, align 4
  %838 = load i8, i8* %581, align 1
  %839 = or i64 %619, 11
  %840 = getelementptr inbounds i8, i8* %553, i64 %839
  %841 = load i8, i8* %840, align 1
  %842 = sext i8 %841 to i32
  %843 = sext i8 %838 to i32
  %844 = mul nsw i32 %842, %843
  %845 = add nsw i32 %844, %837
  store i32 %845, i32* %749, align 4
  %846 = load i8, i8* %582, align 1
  %847 = or i64 %619, 12
  %848 = getelementptr inbounds i8, i8* %553, i64 %847
  %849 = load i8, i8* %848, align 1
  %850 = sext i8 %849 to i32
  %851 = sext i8 %846 to i32
  %852 = mul nsw i32 %850, %851
  %853 = add nsw i32 %852, %845
  store i32 %853, i32* %749, align 4
  %854 = load i8, i8* %583, align 1
  %855 = or i64 %619, 13
  %856 = getelementptr inbounds i8, i8* %553, i64 %855
  %857 = load i8, i8* %856, align 1
  %858 = sext i8 %857 to i32
  %859 = sext i8 %854 to i32
  %860 = mul nsw i32 %858, %859
  %861 = add nsw i32 %860, %853
  store i32 %861, i32* %749, align 4
  %862 = load i8, i8* %584, align 1
  %863 = or i64 %619, 14
  %864 = getelementptr inbounds i8, i8* %553, i64 %863
  %865 = load i8, i8* %864, align 1
  %866 = sext i8 %865 to i32
  %867 = sext i8 %862 to i32
  %868 = mul nsw i32 %866, %867
  %869 = add nsw i32 %868, %861
  store i32 %869, i32* %749, align 4
  %870 = load i8, i8* %585, align 1
  %871 = or i64 %619, 15
  %872 = getelementptr inbounds i8, i8* %553, i64 %871
  %873 = load i8, i8* %872, align 1
  %874 = sext i8 %873 to i32
  %875 = sext i8 %870 to i32
  %876 = mul nsw i32 %874, %875
  %877 = add nsw i32 %876, %869
  store i32 %877, i32* %749, align 4
  %878 = getelementptr inbounds [4 x [4 x i32]], [4 x [4 x i32]]* %12, i64 0, i64 %618, i64 2
  %879 = load i32, i32* %878, align 8
  %880 = load i8, i8* %586, align 1
  %881 = getelementptr inbounds i8, i8* %553, i64 %619
  %882 = load i8, i8* %881, align 1
  %883 = sext i8 %882 to i32
  %884 = sext i8 %880 to i32
  %885 = mul nsw i32 %883, %884
  %886 = add nsw i32 %885, %879
  store i32 %886, i32* %878, align 8
  %887 = load i8, i8* %587, align 1
  %888 = or i64 %619, 1
  %889 = getelementptr inbounds i8, i8* %553, i64 %888
  %890 = load i8, i8* %889, align 1
  %891 = sext i8 %890 to i32
  %892 = sext i8 %887 to i32
  %893 = mul nsw i32 %891, %892
  %894 = add nsw i32 %893, %886
  store i32 %894, i32* %878, align 8
  %895 = load i8, i8* %588, align 1
  %896 = or i64 %619, 2
  %897 = getelementptr inbounds i8, i8* %553, i64 %896
  %898 = load i8, i8* %897, align 1
  %899 = sext i8 %898 to i32
  %900 = sext i8 %895 to i32
  %901 = mul nsw i32 %899, %900
  %902 = add nsw i32 %901, %894
  store i32 %902, i32* %878, align 8
  %903 = load i8, i8* %589, align 1
  %904 = or i64 %619, 3
  %905 = getelementptr inbounds i8, i8* %553, i64 %904
  %906 = load i8, i8* %905, align 1
  %907 = sext i8 %906 to i32
  %908 = sext i8 %903 to i32
  %909 = mul nsw i32 %907, %908
  %910 = add nsw i32 %909, %902
  store i32 %910, i32* %878, align 8
  %911 = load i8, i8* %590, align 1
  %912 = or i64 %619, 4
  %913 = getelementptr inbounds i8, i8* %553, i64 %912
  %914 = load i8, i8* %913, align 1
  %915 = sext i8 %914 to i32
  %916 = sext i8 %911 to i32
  %917 = mul nsw i32 %915, %916
  %918 = add nsw i32 %917, %910
  store i32 %918, i32* %878, align 8
  %919 = load i8, i8* %591, align 1
  %920 = or i64 %619, 5
  %921 = getelementptr inbounds i8, i8* %553, i64 %920
  %922 = load i8, i8* %921, align 1
  %923 = sext i8 %922 to i32
  %924 = sext i8 %919 to i32
  %925 = mul nsw i32 %923, %924
  %926 = add nsw i32 %925, %918
  store i32 %926, i32* %878, align 8
  %927 = load i8, i8* %592, align 1
  %928 = or i64 %619, 6
  %929 = getelementptr inbounds i8, i8* %553, i64 %928
  %930 = load i8, i8* %929, align 1
  %931 = sext i8 %930 to i32
  %932 = sext i8 %927 to i32
  %933 = mul nsw i32 %931, %932
  %934 = add nsw i32 %933, %926
  store i32 %934, i32* %878, align 8
  %935 = load i8, i8* %593, align 1
  %936 = or i64 %619, 7
  %937 = getelementptr inbounds i8, i8* %553, i64 %936
  %938 = load i8, i8* %937, align 1
  %939 = sext i8 %938 to i32
  %940 = sext i8 %935 to i32
  %941 = mul nsw i32 %939, %940
  %942 = add nsw i32 %941, %934
  store i32 %942, i32* %878, align 8
  %943 = load i8, i8* %594, align 1
  %944 = or i64 %619, 8
  %945 = getelementptr inbounds i8, i8* %553, i64 %944
  %946 = load i8, i8* %945, align 1
  %947 = sext i8 %946 to i32
  %948 = sext i8 %943 to i32
  %949 = mul nsw i32 %947, %948
  %950 = add nsw i32 %949, %942
  store i32 %950, i32* %878, align 8
  %951 = load i8, i8* %595, align 1
  %952 = or i64 %619, 9
  %953 = getelementptr inbounds i8, i8* %553, i64 %952
  %954 = load i8, i8* %953, align 1
  %955 = sext i8 %954 to i32
  %956 = sext i8 %951 to i32
  %957 = mul nsw i32 %955, %956
  %958 = add nsw i32 %957, %950
  store i32 %958, i32* %878, align 8
  %959 = load i8, i8* %596, align 1
  %960 = or i64 %619, 10
  %961 = getelementptr inbounds i8, i8* %553, i64 %960
  %962 = load i8, i8* %961, align 1
  %963 = sext i8 %962 to i32
  %964 = sext i8 %959 to i32
  %965 = mul nsw i32 %963, %964
  %966 = add nsw i32 %965, %958
  store i32 %966, i32* %878, align 8
  %967 = load i8, i8* %597, align 1
  %968 = or i64 %619, 11
  %969 = getelementptr inbounds i8, i8* %553, i64 %968
  %970 = load i8, i8* %969, align 1
  %971 = sext i8 %970 to i32
  %972 = sext i8 %967 to i32
  %973 = mul nsw i32 %971, %972
  %974 = add nsw i32 %973, %966
  store i32 %974, i32* %878, align 8
  %975 = load i8, i8* %598, align 1
  %976 = or i64 %619, 12
  %977 = getelementptr inbounds i8, i8* %553, i64 %976
  %978 = load i8, i8* %977, align 1
  %979 = sext i8 %978 to i32
  %980 = sext i8 %975 to i32
  %981 = mul nsw i32 %979, %980
  %982 = add nsw i32 %981, %974
  store i32 %982, i32* %878, align 8
  %983 = load i8, i8* %599, align 1
  %984 = or i64 %619, 13
  %985 = getelementptr inbounds i8, i8* %553, i64 %984
  %986 = load i8, i8* %985, align 1
  %987 = sext i8 %986 to i32
  %988 = sext i8 %983 to i32
  %989 = mul nsw i32 %987, %988
  %990 = add nsw i32 %989, %982
  store i32 %990, i32* %878, align 8
  %991 = load i8, i8* %600, align 1
  %992 = or i64 %619, 14
  %993 = getelementptr inbounds i8, i8* %553, i64 %992
  %994 = load i8, i8* %993, align 1
  %995 = sext i8 %994 to i32
  %996 = sext i8 %991 to i32
  %997 = mul nsw i32 %995, %996
  %998 = add nsw i32 %997, %990
  store i32 %998, i32* %878, align 8
  %999 = load i8, i8* %601, align 1
  %1000 = or i64 %619, 15
  %1001 = getelementptr inbounds i8, i8* %553, i64 %1000
  %1002 = load i8, i8* %1001, align 1
  %1003 = sext i8 %1002 to i32
  %1004 = sext i8 %999 to i32
  %1005 = mul nsw i32 %1003, %1004
  %1006 = add nsw i32 %1005, %998
  store i32 %1006, i32* %878, align 8
  %1007 = getelementptr inbounds [4 x [4 x i32]], [4 x [4 x i32]]* %12, i64 0, i64 %618, i64 3
  %1008 = load i32, i32* %1007, align 4
  %1009 = load i8, i8* %554, align 1
  %1010 = getelementptr inbounds i8, i8* %553, i64 %619
  %1011 = load i8, i8* %1010, align 1
  %1012 = sext i8 %1011 to i32
  %1013 = sext i8 %1009 to i32
  %1014 = mul nsw i32 %1012, %1013
  %1015 = add nsw i32 %1014, %1008
  store i32 %1015, i32* %1007, align 4
  %1016 = load i8, i8* %602, align 1
  %1017 = or i64 %619, 1
  %1018 = getelementptr inbounds i8, i8* %553, i64 %1017
  %1019 = load i8, i8* %1018, align 1
  %1020 = sext i8 %1019 to i32
  %1021 = sext i8 %1016 to i32
  %1022 = mul nsw i32 %1020, %1021
  %1023 = add nsw i32 %1022, %1015
  store i32 %1023, i32* %1007, align 4
  %1024 = load i8, i8* %603, align 1
  %1025 = or i64 %619, 2
  %1026 = getelementptr inbounds i8, i8* %553, i64 %1025
  %1027 = load i8, i8* %1026, align 1
  %1028 = sext i8 %1027 to i32
  %1029 = sext i8 %1024 to i32
  %1030 = mul nsw i32 %1028, %1029
  %1031 = add nsw i32 %1030, %1023
  store i32 %1031, i32* %1007, align 4
  %1032 = load i8, i8* %604, align 1
  %1033 = or i64 %619, 3
  %1034 = getelementptr inbounds i8, i8* %553, i64 %1033
  %1035 = load i8, i8* %1034, align 1
  %1036 = sext i8 %1035 to i32
  %1037 = sext i8 %1032 to i32
  %1038 = mul nsw i32 %1036, %1037
  %1039 = add nsw i32 %1038, %1031
  store i32 %1039, i32* %1007, align 4
  %1040 = load i8, i8* %605, align 1
  %1041 = or i64 %619, 4
  %1042 = getelementptr inbounds i8, i8* %553, i64 %1041
  %1043 = load i8, i8* %1042, align 1
  %1044 = sext i8 %1043 to i32
  %1045 = sext i8 %1040 to i32
  %1046 = mul nsw i32 %1044, %1045
  %1047 = add nsw i32 %1046, %1039
  store i32 %1047, i32* %1007, align 4
  %1048 = load i8, i8* %606, align 1
  %1049 = or i64 %619, 5
  %1050 = getelementptr inbounds i8, i8* %553, i64 %1049
  %1051 = load i8, i8* %1050, align 1
  %1052 = sext i8 %1051 to i32
  %1053 = sext i8 %1048 to i32
  %1054 = mul nsw i32 %1052, %1053
  %1055 = add nsw i32 %1054, %1047
  store i32 %1055, i32* %1007, align 4
  %1056 = load i8, i8* %607, align 1
  %1057 = or i64 %619, 6
  %1058 = getelementptr inbounds i8, i8* %553, i64 %1057
  %1059 = load i8, i8* %1058, align 1
  %1060 = sext i8 %1059 to i32
  %1061 = sext i8 %1056 to i32
  %1062 = mul nsw i32 %1060, %1061
  %1063 = add nsw i32 %1062, %1055
  store i32 %1063, i32* %1007, align 4
  %1064 = load i8, i8* %608, align 1
  %1065 = or i64 %619, 7
  %1066 = getelementptr inbounds i8, i8* %553, i64 %1065
  %1067 = load i8, i8* %1066, align 1
  %1068 = sext i8 %1067 to i32
  %1069 = sext i8 %1064 to i32
  %1070 = mul nsw i32 %1068, %1069
  %1071 = add nsw i32 %1070, %1063
  store i32 %1071, i32* %1007, align 4
  %1072 = load i8, i8* %609, align 1
  %1073 = or i64 %619, 8
  %1074 = getelementptr inbounds i8, i8* %553, i64 %1073
  %1075 = load i8, i8* %1074, align 1
  %1076 = sext i8 %1075 to i32
  %1077 = sext i8 %1072 to i32
  %1078 = mul nsw i32 %1076, %1077
  %1079 = add nsw i32 %1078, %1071
  store i32 %1079, i32* %1007, align 4
  %1080 = load i8, i8* %610, align 1
  %1081 = or i64 %619, 9
  %1082 = getelementptr inbounds i8, i8* %553, i64 %1081
  %1083 = load i8, i8* %1082, align 1
  %1084 = sext i8 %1083 to i32
  %1085 = sext i8 %1080 to i32
  %1086 = mul nsw i32 %1084, %1085
  %1087 = add nsw i32 %1086, %1079
  store i32 %1087, i32* %1007, align 4
  %1088 = load i8, i8* %611, align 1
  %1089 = or i64 %619, 10
  %1090 = getelementptr inbounds i8, i8* %553, i64 %1089
  %1091 = load i8, i8* %1090, align 1
  %1092 = sext i8 %1091 to i32
  %1093 = sext i8 %1088 to i32
  %1094 = mul nsw i32 %1092, %1093
  %1095 = add nsw i32 %1094, %1087
  store i32 %1095, i32* %1007, align 4
  %1096 = load i8, i8* %612, align 1
  %1097 = or i64 %619, 11
  %1098 = getelementptr inbounds i8, i8* %553, i64 %1097
  %1099 = load i8, i8* %1098, align 1
  %1100 = sext i8 %1099 to i32
  %1101 = sext i8 %1096 to i32
  %1102 = mul nsw i32 %1100, %1101
  %1103 = add nsw i32 %1102, %1095
  store i32 %1103, i32* %1007, align 4
  %1104 = load i8, i8* %613, align 1
  %1105 = or i64 %619, 12
  %1106 = getelementptr inbounds i8, i8* %553, i64 %1105
  %1107 = load i8, i8* %1106, align 1
  %1108 = sext i8 %1107 to i32
  %1109 = sext i8 %1104 to i32
  %1110 = mul nsw i32 %1108, %1109
  %1111 = add nsw i32 %1110, %1103
  store i32 %1111, i32* %1007, align 4
  %1112 = load i8, i8* %614, align 1
  %1113 = or i64 %619, 13
  %1114 = getelementptr inbounds i8, i8* %553, i64 %1113
  %1115 = load i8, i8* %1114, align 1
  %1116 = sext i8 %1115 to i32
  %1117 = sext i8 %1112 to i32
  %1118 = mul nsw i32 %1116, %1117
  %1119 = add nsw i32 %1118, %1111
  store i32 %1119, i32* %1007, align 4
  %1120 = load i8, i8* %615, align 1
  %1121 = or i64 %619, 14
  %1122 = getelementptr inbounds i8, i8* %553, i64 %1121
  %1123 = load i8, i8* %1122, align 1
  %1124 = sext i8 %1123 to i32
  %1125 = sext i8 %1120 to i32
  %1126 = mul nsw i32 %1124, %1125
  %1127 = add nsw i32 %1126, %1119
  store i32 %1127, i32* %1007, align 4
  %1128 = load i8, i8* %616, align 1
  %1129 = or i64 %619, 15
  %1130 = getelementptr inbounds i8, i8* %553, i64 %1129
  %1131 = load i8, i8* %1130, align 1
  %1132 = sext i8 %1131 to i32
  %1133 = sext i8 %1128 to i32
  %1134 = mul nsw i32 %1132, %1133
  %1135 = add nsw i32 %1134, %1127
  store i32 %1135, i32* %1007, align 4
  %1136 = add nuw nsw i64 %618, 1
  %1137 = icmp eq i64 %1136, 4
  br i1 %1137, label %1138, label %617

1138:                                             ; preds = %617
  %1139 = getelementptr inbounds i8, i8* %552, i64 64
  %1140 = getelementptr inbounds i8, i8* %553, i64 64
  %1141 = add nuw nsw i32 %551, 16
  %1142 = icmp slt i32 %1141, %100
  br i1 %1142, label %550, label %548

1143:                                             ; preds = %1363, %548
  %1144 = phi i64 [ 0, %548 ], [ %1380, %1363 ]
  %1145 = add nuw nsw i64 %1144, %546
  %1146 = getelementptr inbounds i32, i32* %6, i64 %1145
  %1147 = getelementptr inbounds [4 x [4 x i32]], [4 x [4 x i32]]* %12, i64 0, i64 %1144, i64 0
  %1148 = load i32, i32* %1147, align 16
  %1149 = load i32, i32* %1146, align 4
  %1150 = add nsw i32 %1149, %1148
  %1151 = mul nsw i32 %1150, %533
  %1152 = icmp eq i32 %1151, %15
  br i1 %1152, label %1159, label %1156

1153:                                             ; preds = %1363
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %13) #19
  %1154 = add nuw nsw i64 %546, 4
  %1155 = icmp slt i64 %1154, %542
  br i1 %1155, label %545, label %1188

1156:                                             ; preds = %1143
  %1157 = sext i32 %1151 to i64
  %1158 = mul nsw i64 %1157, %534
  br label %1160

1159:                                             ; preds = %1143
  br i1 %535, label %1167, label %1160

1160:                                             ; preds = %1159, %1156
  %1161 = phi i64 [ %1158, %1156 ], [ %536, %1159 ]
  %1162 = icmp sgt i64 %1161, -1
  %1163 = select i1 %1162, i64 1073741824, i64 -1073741823
  %1164 = add nsw i64 %1163, %1161
  %1165 = sdiv i64 %1164, 2147483648
  %1166 = trunc i64 %1165 to i32
  br label %1167

1167:                                             ; preds = %1159, %1160
  %1168 = phi i32 [ %1166, %1160 ], [ 2147483647, %1159 ]
  %1169 = and i32 %1168, %540
  %1170 = lshr i32 %1168, 31
  %1171 = add nsw i32 %1170, %541
  %1172 = ashr i32 %1168, %531
  %1173 = icmp sgt i32 %1169, %1171
  %1174 = zext i1 %1173 to i32
  %1175 = add nsw i32 %1172, %1174
  %1176 = icmp slt i32 %1175, %19
  %1177 = select i1 %1176, i32 %19, i32 %1175
  %1178 = icmp slt i32 %21, %1177
  %1179 = select i1 %1178, i32 %21, i32 %1177
  %1180 = trunc i32 %1179 to i16
  %1181 = getelementptr inbounds i16, i16* %8, i64 %1145
  store i16 %1180, i16* %1181, align 2
  %1182 = getelementptr inbounds [4 x [4 x i32]], [4 x [4 x i32]]* %12, i64 0, i64 %1144, i64 1
  %1183 = load i32, i32* %1182, align 4
  %1184 = load i32, i32* %1146, align 4
  %1185 = add nsw i32 %1184, %1183
  %1186 = mul nsw i32 %1185, %533
  %1187 = icmp eq i32 %1186, %15
  br i1 %1187, label %1286, label %1283

1188:                                             ; preds = %1153, %1266, %297, %523, %213
  ret void

1189:                                             ; preds = %501
  %1190 = sext i32 %521 to i64
  %1191 = mul nsw i64 %1190, %307
  br label %1193

1192:                                             ; preds = %501
  br i1 %308, label %1200, label %1193

1193:                                             ; preds = %1192, %1189
  %1194 = phi i64 [ %1191, %1189 ], [ %309, %1192 ]
  %1195 = icmp sgt i64 %1194, -1
  %1196 = select i1 %1195, i64 1073741824, i64 -1073741823
  %1197 = add nsw i64 %1196, %1194
  %1198 = sdiv i64 %1197, 2147483648
  %1199 = trunc i64 %1198 to i32
  br label %1200

1200:                                             ; preds = %1193, %1192
  %1201 = phi i32 [ %1199, %1193 ], [ 2147483647, %1192 ]
  %1202 = and i32 %1201, %313
  %1203 = lshr i32 %1201, 31
  %1204 = add nsw i32 %1203, %314
  %1205 = ashr i32 %1201, %304
  %1206 = icmp sgt i32 %1202, %1204
  %1207 = zext i1 %1206 to i32
  %1208 = add nsw i32 %1205, %1207
  %1209 = icmp slt i32 %1208, %19
  %1210 = select i1 %1209, i32 %19, i32 %1208
  %1211 = icmp slt i32 %21, %1210
  %1212 = select i1 %1211, i32 %21, i32 %1210
  %1213 = trunc i32 %1212 to i16
  %1214 = getelementptr inbounds i16, i16* %8, i64 %517
  store i16 %1213, i16* %1214, align 2
  %1215 = load i32, i32* %319, align 8
  %1216 = or i64 %322, 2
  %1217 = getelementptr inbounds i32, i32* %6, i64 %1216
  %1218 = load i32, i32* %1217, align 4
  %1219 = add nsw i32 %1218, %1215
  %1220 = mul nsw i32 %1219, %306
  %1221 = icmp eq i32 %1220, %15
  br i1 %1221, label %1225, label %1222

1222:                                             ; preds = %1200
  %1223 = sext i32 %1220 to i64
  %1224 = mul nsw i64 %1223, %307
  br label %1226

1225:                                             ; preds = %1200
  br i1 %308, label %1233, label %1226

1226:                                             ; preds = %1225, %1222
  %1227 = phi i64 [ %1224, %1222 ], [ %309, %1225 ]
  %1228 = icmp sgt i64 %1227, -1
  %1229 = select i1 %1228, i64 1073741824, i64 -1073741823
  %1230 = add nsw i64 %1229, %1227
  %1231 = sdiv i64 %1230, 2147483648
  %1232 = trunc i64 %1231 to i32
  br label %1233

1233:                                             ; preds = %1226, %1225
  %1234 = phi i32 [ %1232, %1226 ], [ 2147483647, %1225 ]
  %1235 = and i32 %1234, %313
  %1236 = lshr i32 %1234, 31
  %1237 = add nsw i32 %1236, %314
  %1238 = ashr i32 %1234, %304
  %1239 = icmp sgt i32 %1235, %1237
  %1240 = zext i1 %1239 to i32
  %1241 = add nsw i32 %1238, %1240
  %1242 = icmp slt i32 %1241, %19
  %1243 = select i1 %1242, i32 %19, i32 %1241
  %1244 = icmp slt i32 %21, %1243
  %1245 = select i1 %1244, i32 %21, i32 %1243
  %1246 = trunc i32 %1245 to i16
  %1247 = getelementptr inbounds i16, i16* %8, i64 %1216
  store i16 %1246, i16* %1247, align 2
  %1248 = load i32, i32* %320, align 4
  %1249 = or i64 %322, 3
  %1250 = getelementptr inbounds i32, i32* %6, i64 %1249
  %1251 = load i32, i32* %1250, align 4
  %1252 = add nsw i32 %1251, %1248
  %1253 = mul nsw i32 %1252, %306
  %1254 = icmp eq i32 %1253, %15
  br i1 %1254, label %1258, label %1255

1255:                                             ; preds = %1233
  %1256 = sext i32 %1253 to i64
  %1257 = mul nsw i64 %1256, %307
  br label %1259

1258:                                             ; preds = %1233
  br i1 %308, label %1266, label %1259

1259:                                             ; preds = %1258, %1255
  %1260 = phi i64 [ %1257, %1255 ], [ %309, %1258 ]
  %1261 = icmp sgt i64 %1260, -1
  %1262 = select i1 %1261, i64 1073741824, i64 -1073741823
  %1263 = add nsw i64 %1262, %1260
  %1264 = sdiv i64 %1263, 2147483648
  %1265 = trunc i64 %1264 to i32
  br label %1266

1266:                                             ; preds = %1259, %1258
  %1267 = phi i32 [ %1265, %1259 ], [ 2147483647, %1258 ]
  %1268 = and i32 %1267, %313
  %1269 = lshr i32 %1267, 31
  %1270 = add nsw i32 %1269, %314
  %1271 = ashr i32 %1267, %304
  %1272 = icmp sgt i32 %1268, %1270
  %1273 = zext i1 %1272 to i32
  %1274 = add nsw i32 %1271, %1273
  %1275 = icmp slt i32 %1274, %19
  %1276 = select i1 %1275, i32 %19, i32 %1274
  %1277 = icmp slt i32 %21, %1276
  %1278 = select i1 %1277, i32 %21, i32 %1276
  %1279 = trunc i32 %1278 to i16
  %1280 = getelementptr inbounds i16, i16* %8, i64 %1249
  store i16 %1279, i16* %1280, align 2
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %300) #19
  %1281 = add nuw nsw i64 %322, 4
  %1282 = icmp slt i64 %1281, %316
  br i1 %1282, label %321, label %1188

1283:                                             ; preds = %1167
  %1284 = sext i32 %1186 to i64
  %1285 = mul nsw i64 %1284, %534
  br label %1287

1286:                                             ; preds = %1167
  br i1 %535, label %1294, label %1287

1287:                                             ; preds = %1286, %1283
  %1288 = phi i64 [ %1285, %1283 ], [ %536, %1286 ]
  %1289 = icmp sgt i64 %1288, -1
  %1290 = select i1 %1289, i64 1073741824, i64 -1073741823
  %1291 = add nsw i64 %1290, %1288
  %1292 = sdiv i64 %1291, 2147483648
  %1293 = trunc i64 %1292 to i32
  br label %1294

1294:                                             ; preds = %1287, %1286
  %1295 = phi i32 [ %1293, %1287 ], [ 2147483647, %1286 ]
  %1296 = and i32 %1295, %540
  %1297 = lshr i32 %1295, 31
  %1298 = add nsw i32 %1297, %541
  %1299 = ashr i32 %1295, %531
  %1300 = icmp sgt i32 %1296, %1298
  %1301 = zext i1 %1300 to i32
  %1302 = add nsw i32 %1299, %1301
  %1303 = icmp slt i32 %1302, %19
  %1304 = select i1 %1303, i32 %19, i32 %1302
  %1305 = icmp slt i32 %21, %1304
  %1306 = select i1 %1305, i32 %21, i32 %1304
  %1307 = trunc i32 %1306 to i16
  %1308 = trunc i64 %1145 to i32
  %1309 = add i32 %94, %1308
  %1310 = sext i32 %1309 to i64
  %1311 = getelementptr inbounds i16, i16* %8, i64 %1310
  store i16 %1307, i16* %1311, align 2
  %1312 = getelementptr inbounds [4 x [4 x i32]], [4 x [4 x i32]]* %12, i64 0, i64 %1144, i64 2
  %1313 = load i32, i32* %1312, align 8
  %1314 = load i32, i32* %1146, align 4
  %1315 = add nsw i32 %1314, %1313
  %1316 = mul nsw i32 %1315, %533
  %1317 = icmp eq i32 %1316, %15
  br i1 %1317, label %1321, label %1318

1318:                                             ; preds = %1294
  %1319 = sext i32 %1316 to i64
  %1320 = mul nsw i64 %1319, %534
  br label %1322

1321:                                             ; preds = %1294
  br i1 %535, label %1329, label %1322

1322:                                             ; preds = %1321, %1318
  %1323 = phi i64 [ %1320, %1318 ], [ %536, %1321 ]
  %1324 = icmp sgt i64 %1323, -1
  %1325 = select i1 %1324, i64 1073741824, i64 -1073741823
  %1326 = add nsw i64 %1325, %1323
  %1327 = sdiv i64 %1326, 2147483648
  %1328 = trunc i64 %1327 to i32
  br label %1329

1329:                                             ; preds = %1322, %1321
  %1330 = phi i32 [ %1328, %1322 ], [ 2147483647, %1321 ]
  %1331 = and i32 %1330, %540
  %1332 = lshr i32 %1330, 31
  %1333 = add nsw i32 %1332, %541
  %1334 = ashr i32 %1330, %531
  %1335 = icmp sgt i32 %1331, %1333
  %1336 = zext i1 %1335 to i32
  %1337 = add nsw i32 %1334, %1336
  %1338 = icmp slt i32 %1337, %19
  %1339 = select i1 %1338, i32 %19, i32 %1337
  %1340 = icmp slt i32 %21, %1339
  %1341 = select i1 %1340, i32 %21, i32 %1339
  %1342 = trunc i32 %1341 to i16
  %1343 = add i32 %543, %1308
  %1344 = sext i32 %1343 to i64
  %1345 = getelementptr inbounds i16, i16* %8, i64 %1344
  store i16 %1342, i16* %1345, align 2
  %1346 = getelementptr inbounds [4 x [4 x i32]], [4 x [4 x i32]]* %12, i64 0, i64 %1144, i64 3
  %1347 = load i32, i32* %1346, align 4
  %1348 = load i32, i32* %1146, align 4
  %1349 = add nsw i32 %1348, %1347
  %1350 = mul nsw i32 %1349, %533
  %1351 = icmp eq i32 %1350, %15
  br i1 %1351, label %1355, label %1352

1352:                                             ; preds = %1329
  %1353 = sext i32 %1350 to i64
  %1354 = mul nsw i64 %1353, %534
  br label %1356

1355:                                             ; preds = %1329
  br i1 %535, label %1363, label %1356

1356:                                             ; preds = %1355, %1352
  %1357 = phi i64 [ %1354, %1352 ], [ %536, %1355 ]
  %1358 = icmp sgt i64 %1357, -1
  %1359 = select i1 %1358, i64 1073741824, i64 -1073741823
  %1360 = add nsw i64 %1359, %1357
  %1361 = sdiv i64 %1360, 2147483648
  %1362 = trunc i64 %1361 to i32
  br label %1363

1363:                                             ; preds = %1356, %1355
  %1364 = phi i32 [ %1362, %1356 ], [ 2147483647, %1355 ]
  %1365 = and i32 %1364, %540
  %1366 = lshr i32 %1364, 31
  %1367 = add nsw i32 %1366, %541
  %1368 = ashr i32 %1364, %531
  %1369 = icmp sgt i32 %1365, %1367
  %1370 = zext i1 %1369 to i32
  %1371 = add nsw i32 %1368, %1370
  %1372 = icmp slt i32 %1371, %19
  %1373 = select i1 %1372, i32 %19, i32 %1371
  %1374 = icmp slt i32 %21, %1373
  %1375 = select i1 %1374, i32 %21, i32 %1373
  %1376 = trunc i32 %1375 to i16
  %1377 = add i32 %544, %1308
  %1378 = sext i32 %1377 to i64
  %1379 = getelementptr inbounds i16, i16* %8, i64 %1378
  store i16 %1376, i16* %1379, align 2
  %1380 = add nuw nsw i64 %1144, 1
  %1381 = icmp eq i64 %1380, 4
  br i1 %1381, label %1153, label %1143

1382:                                             ; preds = %50
  %1383 = getelementptr inbounds i32, i32* %32, i64 %53
  %1384 = load i32, i32* %1383, align 4
  br label %1385

1385:                                             ; preds = %1382, %50
  %1386 = phi i32 [ %1384, %1382 ], [ 1, %50 ]
  %1387 = mul nsw i32 %1386, %52
  %1388 = or i64 %43, 2
  %1389 = icmp eq i64 %1388, %35
  br i1 %1389, label %1393, label %1390

1390:                                             ; preds = %1385
  %1391 = getelementptr inbounds i32, i32* %32, i64 %1388
  %1392 = load i32, i32* %1391, align 4
  br label %1393

1393:                                             ; preds = %1390, %1385
  %1394 = phi i32 [ %1392, %1390 ], [ 1, %1385 ]
  %1395 = mul nsw i32 %1394, %1387
  %1396 = or i64 %43, 3
  %1397 = icmp eq i64 %1396, %35
  br i1 %1397, label %1401, label %1398

1398:                                             ; preds = %1393
  %1399 = getelementptr inbounds i32, i32* %32, i64 %1396
  %1400 = load i32, i32* %1399, align 4
  br label %1401

1401:                                             ; preds = %1398, %1393
  %1402 = phi i32 [ %1400, %1398 ], [ 1, %1393 ]
  %1403 = mul nsw i32 %1402, %1395
  %1404 = add nuw nsw i64 %43, 4
  %1405 = add i64 %45, -4
  %1406 = icmp eq i64 %1405, 0
  br i1 %1406, label %55, label %42
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN6tflite13reference_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKiS6_Ph(%"struct.tflite::FullyConnectedParams"* dereferenceable(40), %"class.tflite::RuntimeShape"* dereferenceable(32), i8*, %"class.tflite::RuntimeShape"* dereferenceable(32), i8*, %"class.tflite::RuntimeShape"* dereferenceable(32), i32*, %"class.tflite::RuntimeShape"* dereferenceable(32), i8*) local_unnamed_addr #4 comdat {
  %10 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 0
  %11 = load i32, i32* %10, align 4
  %12 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 1
  %13 = load i32, i32* %12, align 4
  %14 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 2
  %15 = load i32, i32* %14, align 4
  %16 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 3
  %17 = load i32, i32* %16, align 4
  %18 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 4
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 5
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 6
  %23 = load i32, i32* %22, align 4
  %24 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %3, i64 0, i32 0
  %25 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %7, i64 0, i32 0
  %26 = load i32, i32* %25, align 8
  %27 = load i32, i32* %24, align 8
  %28 = add nsw i32 %26, -1
  %29 = icmp sgt i32 %26, 5
  %30 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %7, i64 0, i32 1
  %31 = getelementptr inbounds %union.anon.54, %union.anon.54* %30, i64 0, i32 0
  %32 = load i32*, i32** %31, align 8
  %33 = bitcast %union.anon.54* %30 to i32*
  %34 = select i1 %29, i32* %32, i32* %33
  %35 = icmp sgt i32 %26, 0
  br i1 %35, label %36, label %76

36:                                               ; preds = %9
  %37 = zext i32 %28 to i64
  %38 = zext i32 %26 to i64
  %39 = add nsw i64 %38, -1
  %40 = and i64 %38, 3
  %41 = icmp ult i64 %39, 3
  br i1 %41, label %57, label %42

42:                                               ; preds = %36
  %43 = sub nsw i64 %38, %40
  br label %44

44:                                               ; preds = %266, %42
  %45 = phi i64 [ 0, %42 ], [ %269, %266 ]
  %46 = phi i32 [ 1, %42 ], [ %268, %266 ]
  %47 = phi i64 [ %43, %42 ], [ %270, %266 ]
  %48 = icmp eq i64 %45, %37
  br i1 %48, label %52, label %49

49:                                               ; preds = %44
  %50 = getelementptr inbounds i32, i32* %34, i64 %45
  %51 = load i32, i32* %50, align 4
  br label %52

52:                                               ; preds = %49, %44
  %53 = phi i32 [ %51, %49 ], [ 1, %44 ]
  %54 = mul nsw i32 %53, %46
  %55 = or i64 %45, 1
  %56 = icmp eq i64 %55, %37
  br i1 %56, label %250, label %247

57:                                               ; preds = %266, %36
  %58 = phi i32 [ undef, %36 ], [ %268, %266 ]
  %59 = phi i64 [ 0, %36 ], [ %269, %266 ]
  %60 = phi i32 [ 1, %36 ], [ %268, %266 ]
  %61 = icmp eq i64 %40, 0
  br i1 %61, label %76, label %62

62:                                               ; preds = %57, %70
  %63 = phi i64 [ %73, %70 ], [ %59, %57 ]
  %64 = phi i32 [ %72, %70 ], [ %60, %57 ]
  %65 = phi i64 [ %74, %70 ], [ %40, %57 ]
  %66 = icmp eq i64 %63, %37
  br i1 %66, label %70, label %67

67:                                               ; preds = %62
  %68 = getelementptr inbounds i32, i32* %34, i64 %63
  %69 = load i32, i32* %68, align 4
  br label %70

70:                                               ; preds = %67, %62
  %71 = phi i32 [ %69, %67 ], [ 1, %62 ]
  %72 = mul nsw i32 %71, %64
  %73 = add nuw nsw i64 %63, 1
  %74 = add i64 %65, -1
  %75 = icmp eq i64 %74, 0
  br i1 %75, label %76, label %62, !llvm.loop !164

76:                                               ; preds = %57, %70, %9
  %77 = phi i32 [ 1, %9 ], [ %58, %57 ], [ %72, %70 ]
  %78 = add nsw i32 %27, -2
  %79 = icmp sgt i32 %27, 5
  %80 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %3, i64 0, i32 1
  %81 = getelementptr inbounds %union.anon.54, %union.anon.54* %80, i64 0, i32 0
  %82 = load i32*, i32** %81, align 8
  %83 = sext i32 %78 to i64
  %84 = getelementptr inbounds i32, i32* %82, i64 %83
  %85 = bitcast %union.anon.54* %80 to [5 x i32]*
  %86 = getelementptr inbounds [5 x i32], [5 x i32]* %85, i64 0, i64 %83
  %87 = select i1 %79, i32* %84, i32* %86
  %88 = load i32, i32* %87, align 4
  %89 = sext i32 %28 to i64
  %90 = getelementptr inbounds i32, i32* %32, i64 %89
  %91 = bitcast %union.anon.54* %30 to [5 x i32]*
  %92 = getelementptr inbounds [5 x i32], [5 x i32]* %91, i64 0, i64 %89
  %93 = select i1 %29, i32* %90, i32* %92
  %94 = load i32, i32* %93, align 4
  %95 = icmp slt i32 %94, %88
  %96 = select i1 %95, i32 %94, i32 %88
  %97 = add nsw i32 %27, -1
  %98 = sext i32 %97 to i64
  %99 = getelementptr inbounds i32, i32* %82, i64 %98
  %100 = getelementptr inbounds [5 x i32], [5 x i32]* %85, i64 0, i64 %98
  %101 = select i1 %79, i32* %99, i32* %100
  %102 = load i32, i32* %101, align 4
  %103 = icmp sgt i32 %77, 0
  br i1 %103, label %104, label %140

104:                                              ; preds = %76
  %105 = icmp sgt i32 %96, 0
  %106 = icmp sgt i32 %102, 0
  %107 = icmp eq i32* %6, null
  %108 = icmp sgt i32 %19, 0
  %109 = sub nsw i32 0, %19
  %110 = select i1 %108, i32 0, i32 %109
  %111 = shl i32 1, %19
  %112 = select i1 %108, i32 %111, i32 1
  %113 = sext i32 %17 to i64
  %114 = icmp eq i32 %17, -2147483648
  %115 = zext i32 %110 to i64
  %116 = shl nsw i64 -1, %115
  %117 = trunc i64 %116 to i32
  %118 = xor i32 %117, -1
  %119 = ashr i32 %118, 1
  %120 = sext i32 %102 to i64
  %121 = sext i32 %96 to i64
  %122 = zext i32 %77 to i64
  %123 = zext i32 %102 to i64
  %124 = icmp ult i32 %102, 8
  %125 = and i64 %123, 4294967288
  %126 = insertelement <4 x i32> undef, i32 %13, i32 0
  %127 = shufflevector <4 x i32> %126, <4 x i32> undef, <4 x i32> zeroinitializer
  %128 = insertelement <4 x i32> undef, i32 %13, i32 0
  %129 = shufflevector <4 x i32> %128, <4 x i32> undef, <4 x i32> zeroinitializer
  %130 = insertelement <4 x i32> undef, i32 %11, i32 0
  %131 = shufflevector <4 x i32> %130, <4 x i32> undef, <4 x i32> zeroinitializer
  %132 = insertelement <4 x i32> undef, i32 %11, i32 0
  %133 = shufflevector <4 x i32> %132, <4 x i32> undef, <4 x i32> zeroinitializer
  %134 = icmp eq i64 %125, %123
  br label %135

135:                                              ; preds = %187, %104
  %136 = phi i64 [ 0, %104 ], [ %188, %187 ]
  br i1 %105, label %137, label %187

137:                                              ; preds = %135
  %138 = mul nsw i64 %136, %120
  %139 = mul nsw i64 %136, %121
  br label %141

140:                                              ; preds = %187, %76
  ret void

141:                                              ; preds = %137, %228
  %142 = phi i64 [ 0, %137 ], [ %245, %228 ]
  br i1 %106, label %143, label %190

143:                                              ; preds = %141
  %144 = mul nsw i64 %142, %120
  br i1 %124, label %145, label %148

145:                                              ; preds = %180, %143
  %146 = phi i64 [ 0, %143 ], [ %125, %180 ]
  %147 = phi i32 [ 0, %143 ], [ %186, %180 ]
  br label %192

148:                                              ; preds = %143, %148
  %149 = phi i64 [ %178, %148 ], [ 0, %143 ]
  %150 = phi <4 x i32> [ %176, %148 ], [ zeroinitializer, %143 ]
  %151 = phi <4 x i32> [ %177, %148 ], [ zeroinitializer, %143 ]
  %152 = add nsw i64 %149, %138
  %153 = getelementptr inbounds i8, i8* %2, i64 %152
  %154 = bitcast i8* %153 to <4 x i8>*
  %155 = load <4 x i8>, <4 x i8>* %154, align 1
  %156 = getelementptr inbounds i8, i8* %153, i64 4
  %157 = bitcast i8* %156 to <4 x i8>*
  %158 = load <4 x i8>, <4 x i8>* %157, align 1
  %159 = zext <4 x i8> %155 to <4 x i32>
  %160 = zext <4 x i8> %158 to <4 x i32>
  %161 = add nsw i64 %149, %144
  %162 = getelementptr inbounds i8, i8* %4, i64 %161
  %163 = bitcast i8* %162 to <4 x i8>*
  %164 = load <4 x i8>, <4 x i8>* %163, align 1
  %165 = getelementptr inbounds i8, i8* %162, i64 4
  %166 = bitcast i8* %165 to <4 x i8>*
  %167 = load <4 x i8>, <4 x i8>* %166, align 1
  %168 = zext <4 x i8> %164 to <4 x i32>
  %169 = zext <4 x i8> %167 to <4 x i32>
  %170 = add nsw <4 x i32> %127, %168
  %171 = add nsw <4 x i32> %129, %169
  %172 = add nsw <4 x i32> %131, %159
  %173 = add nsw <4 x i32> %133, %160
  %174 = mul nsw <4 x i32> %170, %172
  %175 = mul nsw <4 x i32> %171, %173
  %176 = add nsw <4 x i32> %174, %150
  %177 = add nsw <4 x i32> %175, %151
  %178 = add i64 %149, 8
  %179 = icmp eq i64 %178, %125
  br i1 %179, label %180, label %148, !llvm.loop !165

180:                                              ; preds = %148
  %181 = add <4 x i32> %177, %176
  %182 = shufflevector <4 x i32> %181, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %183 = add <4 x i32> %181, %182
  %184 = shufflevector <4 x i32> %183, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %185 = add <4 x i32> %183, %184
  %186 = extractelement <4 x i32> %185, i32 0
  br i1 %134, label %190, label %145

187:                                              ; preds = %228, %135
  %188 = add nuw nsw i64 %136, 1
  %189 = icmp eq i64 %188, %122
  br i1 %189, label %140, label %135

190:                                              ; preds = %192, %180, %141
  %191 = phi i32 [ 0, %141 ], [ %186, %180 ], [ %206, %192 ]
  br i1 %107, label %213, label %209

192:                                              ; preds = %145, %192
  %193 = phi i64 [ %207, %192 ], [ %146, %145 ]
  %194 = phi i32 [ %206, %192 ], [ %147, %145 ]
  %195 = add nsw i64 %193, %138
  %196 = getelementptr inbounds i8, i8* %2, i64 %195
  %197 = load i8, i8* %196, align 1
  %198 = zext i8 %197 to i32
  %199 = add nsw i64 %193, %144
  %200 = getelementptr inbounds i8, i8* %4, i64 %199
  %201 = load i8, i8* %200, align 1
  %202 = zext i8 %201 to i32
  %203 = add nsw i32 %13, %202
  %204 = add nsw i32 %11, %198
  %205 = mul nsw i32 %203, %204
  %206 = add nsw i32 %205, %194
  %207 = add nuw nsw i64 %193, 1
  %208 = icmp eq i64 %207, %123
  br i1 %208, label %190, label %192, !llvm.loop !166

209:                                              ; preds = %190
  %210 = getelementptr inbounds i32, i32* %6, i64 %142
  %211 = load i32, i32* %210, align 4
  %212 = add nsw i32 %211, %191
  br label %213

213:                                              ; preds = %190, %209
  %214 = phi i32 [ %191, %190 ], [ %212, %209 ]
  %215 = mul nsw i32 %214, %112
  %216 = icmp eq i32 %215, %17
  br i1 %216, label %219, label %217

217:                                              ; preds = %213
  %218 = sext i32 %215 to i64
  br label %220

219:                                              ; preds = %213
  br i1 %114, label %228, label %220

220:                                              ; preds = %219, %217
  %221 = phi i64 [ %218, %217 ], [ %113, %219 ]
  %222 = mul nsw i64 %221, %113
  %223 = icmp sgt i64 %222, -1
  %224 = select i1 %223, i64 1073741824, i64 -1073741823
  %225 = add nsw i64 %224, %222
  %226 = sdiv i64 %225, 2147483648
  %227 = trunc i64 %226 to i32
  br label %228

228:                                              ; preds = %219, %220
  %229 = phi i32 [ %227, %220 ], [ 2147483647, %219 ]
  %230 = and i32 %229, %118
  %231 = lshr i32 %229, 31
  %232 = add nsw i32 %231, %119
  %233 = ashr i32 %229, %110
  %234 = icmp sgt i32 %230, %232
  %235 = zext i1 %234 to i32
  %236 = add i32 %233, %15
  %237 = add i32 %236, %235
  %238 = icmp slt i32 %237, %21
  %239 = select i1 %238, i32 %21, i32 %237
  %240 = icmp slt i32 %23, %239
  %241 = select i1 %240, i32 %23, i32 %239
  %242 = trunc i32 %241 to i8
  %243 = add nsw i64 %142, %139
  %244 = getelementptr inbounds i8, i8* %8, i64 %243
  store i8 %242, i8* %244, align 1
  %245 = add nuw nsw i64 %142, 1
  %246 = icmp slt i64 %245, %121
  br i1 %246, label %141, label %187

247:                                              ; preds = %52
  %248 = getelementptr inbounds i32, i32* %34, i64 %55
  %249 = load i32, i32* %248, align 4
  br label %250

250:                                              ; preds = %247, %52
  %251 = phi i32 [ %249, %247 ], [ 1, %52 ]
  %252 = mul nsw i32 %251, %54
  %253 = or i64 %45, 2
  %254 = icmp eq i64 %253, %37
  br i1 %254, label %258, label %255

255:                                              ; preds = %250
  %256 = getelementptr inbounds i32, i32* %34, i64 %253
  %257 = load i32, i32* %256, align 4
  br label %258

258:                                              ; preds = %255, %250
  %259 = phi i32 [ %257, %255 ], [ 1, %250 ]
  %260 = mul nsw i32 %259, %252
  %261 = or i64 %45, 3
  %262 = icmp eq i64 %261, %37
  br i1 %262, label %266, label %263

263:                                              ; preds = %258
  %264 = getelementptr inbounds i32, i32* %34, i64 %261
  %265 = load i32, i32* %264, align 4
  br label %266

266:                                              ; preds = %263, %258
  %267 = phi i32 [ %265, %263 ], [ 1, %258 ]
  %268 = mul nsw i32 %267, %260
  %269 = add nuw nsw i64 %45, 4
  %270 = add i64 %47, -4
  %271 = icmp eq i64 %270, 0
  br i1 %271, label %57, label %44
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN6tflite13reference_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKiS6_Ps(%"struct.tflite::FullyConnectedParams"* dereferenceable(40), %"class.tflite::RuntimeShape"* dereferenceable(32), i8*, %"class.tflite::RuntimeShape"* dereferenceable(32), i8*, %"class.tflite::RuntimeShape"* dereferenceable(32), i32*, %"class.tflite::RuntimeShape"* dereferenceable(32), i16*) local_unnamed_addr #4 comdat {
  %10 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 0
  %11 = load i32, i32* %10, align 4
  %12 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 1
  %13 = load i32, i32* %12, align 4
  %14 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 2
  %15 = load i32, i32* %14, align 4
  %16 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 3
  %17 = load i32, i32* %16, align 4
  %18 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 4
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 5
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 6
  %23 = load i32, i32* %22, align 4
  %24 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %7, i64 0, i32 0
  %25 = load i32, i32* %24, align 8
  %26 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %3, i64 0, i32 0
  %27 = load i32, i32* %26, align 8
  %28 = add nsw i32 %25, -1
  %29 = icmp sgt i32 %25, 5
  %30 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %7, i64 0, i32 1
  %31 = getelementptr inbounds %union.anon.54, %union.anon.54* %30, i64 0, i32 0
  %32 = load i32*, i32** %31, align 8
  %33 = bitcast %union.anon.54* %30 to i32*
  %34 = select i1 %29, i32* %32, i32* %33
  %35 = icmp sgt i32 %25, 0
  br i1 %35, label %36, label %76

36:                                               ; preds = %9
  %37 = zext i32 %28 to i64
  %38 = zext i32 %25 to i64
  %39 = add nsw i64 %38, -1
  %40 = and i64 %38, 3
  %41 = icmp ult i64 %39, 3
  br i1 %41, label %57, label %42

42:                                               ; preds = %36
  %43 = sub nsw i64 %38, %40
  br label %44

44:                                               ; preds = %277, %42
  %45 = phi i64 [ 0, %42 ], [ %280, %277 ]
  %46 = phi i32 [ 1, %42 ], [ %279, %277 ]
  %47 = phi i64 [ %43, %42 ], [ %281, %277 ]
  %48 = icmp eq i64 %45, %37
  br i1 %48, label %52, label %49

49:                                               ; preds = %44
  %50 = getelementptr inbounds i32, i32* %34, i64 %45
  %51 = load i32, i32* %50, align 4
  br label %52

52:                                               ; preds = %49, %44
  %53 = phi i32 [ %51, %49 ], [ 1, %44 ]
  %54 = mul nsw i32 %53, %46
  %55 = or i64 %45, 1
  %56 = icmp eq i64 %55, %37
  br i1 %56, label %261, label %258

57:                                               ; preds = %277, %36
  %58 = phi i32 [ undef, %36 ], [ %279, %277 ]
  %59 = phi i64 [ 0, %36 ], [ %280, %277 ]
  %60 = phi i32 [ 1, %36 ], [ %279, %277 ]
  %61 = icmp eq i64 %40, 0
  br i1 %61, label %76, label %62

62:                                               ; preds = %57, %70
  %63 = phi i64 [ %73, %70 ], [ %59, %57 ]
  %64 = phi i32 [ %72, %70 ], [ %60, %57 ]
  %65 = phi i64 [ %74, %70 ], [ %40, %57 ]
  %66 = icmp eq i64 %63, %37
  br i1 %66, label %70, label %67

67:                                               ; preds = %62
  %68 = getelementptr inbounds i32, i32* %34, i64 %63
  %69 = load i32, i32* %68, align 4
  br label %70

70:                                               ; preds = %67, %62
  %71 = phi i32 [ %69, %67 ], [ 1, %62 ]
  %72 = mul nsw i32 %71, %64
  %73 = add nuw nsw i64 %63, 1
  %74 = add i64 %65, -1
  %75 = icmp eq i64 %74, 0
  br i1 %75, label %76, label %62, !llvm.loop !167

76:                                               ; preds = %57, %70, %9
  %77 = phi i32 [ 1, %9 ], [ %58, %57 ], [ %72, %70 ]
  %78 = add nsw i32 %27, -2
  %79 = icmp sgt i32 %27, 5
  %80 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %3, i64 0, i32 1
  %81 = getelementptr inbounds %union.anon.54, %union.anon.54* %80, i64 0, i32 0
  %82 = load i32*, i32** %81, align 8
  %83 = sext i32 %78 to i64
  %84 = getelementptr inbounds i32, i32* %82, i64 %83
  %85 = bitcast %union.anon.54* %80 to [5 x i32]*
  %86 = getelementptr inbounds [5 x i32], [5 x i32]* %85, i64 0, i64 %83
  %87 = select i1 %79, i32* %84, i32* %86
  %88 = load i32, i32* %87, align 4
  %89 = sext i32 %28 to i64
  %90 = getelementptr inbounds i32, i32* %32, i64 %89
  %91 = bitcast %union.anon.54* %30 to [5 x i32]*
  %92 = getelementptr inbounds [5 x i32], [5 x i32]* %91, i64 0, i64 %89
  %93 = select i1 %29, i32* %90, i32* %92
  %94 = load i32, i32* %93, align 4
  %95 = icmp slt i32 %94, %88
  %96 = select i1 %95, i32 %94, i32 %88
  %97 = add nsw i32 %27, -1
  %98 = sext i32 %97 to i64
  %99 = getelementptr inbounds i32, i32* %82, i64 %98
  %100 = getelementptr inbounds [5 x i32], [5 x i32]* %85, i64 0, i64 %98
  %101 = select i1 %79, i32* %99, i32* %100
  %102 = load i32, i32* %101, align 4
  %103 = icmp sgt i32 %77, 0
  br i1 %103, label %104, label %141

104:                                              ; preds = %76
  %105 = icmp sgt i32 %96, 0
  %106 = icmp sgt i32 %102, 0
  %107 = icmp sgt i32 %19, 0
  %108 = sub nsw i32 0, %19
  %109 = select i1 %107, i32 0, i32 %108
  %110 = shl i32 1, %19
  %111 = select i1 %107, i32 %110, i32 1
  %112 = sext i32 %17 to i64
  %113 = icmp eq i32 %17, -2147483648
  %114 = zext i32 %109 to i64
  %115 = shl nsw i64 -1, %114
  %116 = trunc i64 %115 to i32
  %117 = xor i32 %116, -1
  %118 = ashr i32 %117, 1
  %119 = sub nsw i32 %21, %15
  %120 = sub nsw i32 %23, %15
  %121 = sext i32 %102 to i64
  %122 = sext i32 %96 to i64
  %123 = zext i32 %77 to i64
  %124 = zext i32 %102 to i64
  %125 = icmp ult i32 %102, 8
  %126 = and i64 %124, 4294967288
  %127 = insertelement <4 x i32> undef, i32 %11, i32 0
  %128 = shufflevector <4 x i32> %127, <4 x i32> undef, <4 x i32> zeroinitializer
  %129 = insertelement <4 x i32> undef, i32 %11, i32 0
  %130 = shufflevector <4 x i32> %129, <4 x i32> undef, <4 x i32> zeroinitializer
  %131 = insertelement <4 x i32> undef, i32 %13, i32 0
  %132 = shufflevector <4 x i32> %131, <4 x i32> undef, <4 x i32> zeroinitializer
  %133 = insertelement <4 x i32> undef, i32 %13, i32 0
  %134 = shufflevector <4 x i32> %133, <4 x i32> undef, <4 x i32> zeroinitializer
  %135 = icmp eq i64 %126, %124
  br label %136

136:                                              ; preds = %142, %104
  %137 = phi i64 [ 0, %104 ], [ %143, %142 ]
  br i1 %105, label %138, label %142

138:                                              ; preds = %136
  %139 = mul nsw i64 %137, %121
  %140 = mul nsw i64 %137, %122
  br label %145

141:                                              ; preds = %142, %76
  ret void

142:                                              ; preds = %218, %136
  %143 = add nuw nsw i64 %137, 1
  %144 = icmp eq i64 %143, %123
  br i1 %144, label %141, label %136

145:                                              ; preds = %138, %218
  %146 = phi i64 [ 0, %138 ], [ %235, %218 ]
  %147 = getelementptr inbounds i32, i32* %6, i64 %146
  %148 = load i32, i32* %147, align 4
  br i1 %106, label %149, label %203

149:                                              ; preds = %145
  %150 = mul nsw i64 %146, %121
  br i1 %125, label %151, label %154

151:                                              ; preds = %196, %149
  %152 = phi i64 [ 0, %149 ], [ %126, %196 ]
  %153 = phi i32 [ %148, %149 ], [ %202, %196 ]
  br label %237

154:                                              ; preds = %149
  %155 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %148, i32 0
  br label %156

156:                                              ; preds = %156, %154
  %157 = phi i64 [ 0, %154 ], [ %194, %156 ]
  %158 = phi <4 x i32> [ %155, %154 ], [ %192, %156 ]
  %159 = phi <4 x i32> [ zeroinitializer, %154 ], [ %193, %156 ]
  %160 = add nsw i64 %157, %139
  %161 = getelementptr inbounds i8, i8* %2, i64 %160
  %162 = bitcast i8* %161 to <4 x i8>*
  %163 = load <4 x i8>, <4 x i8>* %162, align 1
  %164 = getelementptr inbounds i8, i8* %161, i64 4
  %165 = bitcast i8* %164 to <4 x i8>*
  %166 = load <4 x i8>, <4 x i8>* %165, align 1
  %167 = zext <4 x i8> %163 to <4 x i32>
  %168 = zext <4 x i8> %166 to <4 x i32>
  %169 = add nsw <4 x i32> %128, %167
  %170 = add nsw <4 x i32> %130, %168
  %171 = add nsw i64 %157, %150
  %172 = getelementptr inbounds i8, i8* %4, i64 %171
  %173 = bitcast i8* %172 to <4 x i8>*
  %174 = load <4 x i8>, <4 x i8>* %173, align 1
  %175 = getelementptr inbounds i8, i8* %172, i64 4
  %176 = bitcast i8* %175 to <4 x i8>*
  %177 = load <4 x i8>, <4 x i8>* %176, align 1
  %178 = zext <4 x i8> %174 to <4 x i32>
  %179 = zext <4 x i8> %177 to <4 x i32>
  %180 = add nsw <4 x i32> %132, %178
  %181 = add nsw <4 x i32> %134, %179
  %182 = shl <4 x i32> %180, <i32 16, i32 16, i32 16, i32 16>
  %183 = shl <4 x i32> %181, <i32 16, i32 16, i32 16, i32 16>
  %184 = ashr exact <4 x i32> %182, <i32 16, i32 16, i32 16, i32 16>
  %185 = ashr exact <4 x i32> %183, <i32 16, i32 16, i32 16, i32 16>
  %186 = shl <4 x i32> %169, <i32 16, i32 16, i32 16, i32 16>
  %187 = shl <4 x i32> %170, <i32 16, i32 16, i32 16, i32 16>
  %188 = ashr exact <4 x i32> %186, <i32 16, i32 16, i32 16, i32 16>
  %189 = ashr exact <4 x i32> %187, <i32 16, i32 16, i32 16, i32 16>
  %190 = mul nsw <4 x i32> %184, %188
  %191 = mul nsw <4 x i32> %185, %189
  %192 = add nsw <4 x i32> %190, %158
  %193 = add nsw <4 x i32> %191, %159
  %194 = add i64 %157, 8
  %195 = icmp eq i64 %194, %126
  br i1 %195, label %196, label %156, !llvm.loop !168

196:                                              ; preds = %156
  %197 = add <4 x i32> %193, %192
  %198 = shufflevector <4 x i32> %197, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %199 = add <4 x i32> %197, %198
  %200 = shufflevector <4 x i32> %199, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %201 = add <4 x i32> %199, %200
  %202 = extractelement <4 x i32> %201, i32 0
  br i1 %135, label %203, label %151

203:                                              ; preds = %237, %196, %145
  %204 = phi i32 [ %148, %145 ], [ %202, %196 ], [ %255, %237 ]
  %205 = mul nsw i32 %204, %111
  %206 = icmp eq i32 %205, %17
  br i1 %206, label %209, label %207

207:                                              ; preds = %203
  %208 = sext i32 %205 to i64
  br label %210

209:                                              ; preds = %203
  br i1 %113, label %218, label %210

210:                                              ; preds = %209, %207
  %211 = phi i64 [ %208, %207 ], [ %112, %209 ]
  %212 = mul nsw i64 %211, %112
  %213 = icmp sgt i64 %212, -1
  %214 = select i1 %213, i64 1073741824, i64 -1073741823
  %215 = add nsw i64 %214, %212
  %216 = sdiv i64 %215, 2147483648
  %217 = trunc i64 %216 to i32
  br label %218

218:                                              ; preds = %209, %210
  %219 = phi i32 [ %217, %210 ], [ 2147483647, %209 ]
  %220 = and i32 %219, %117
  %221 = lshr i32 %219, 31
  %222 = add nsw i32 %221, %118
  %223 = ashr i32 %219, %109
  %224 = icmp sgt i32 %220, %222
  %225 = zext i1 %224 to i32
  %226 = add nsw i32 %223, %225
  %227 = icmp slt i32 %226, %119
  %228 = select i1 %227, i32 %119, i32 %226
  %229 = icmp slt i32 %120, %228
  %230 = select i1 %229, i32 %120, i32 %228
  %231 = add nsw i32 %230, %15
  %232 = trunc i32 %231 to i16
  %233 = add nsw i64 %146, %140
  %234 = getelementptr inbounds i16, i16* %8, i64 %233
  store i16 %232, i16* %234, align 2
  %235 = add nuw nsw i64 %146, 1
  %236 = icmp slt i64 %235, %122
  br i1 %236, label %145, label %142

237:                                              ; preds = %151, %237
  %238 = phi i64 [ %256, %237 ], [ %152, %151 ]
  %239 = phi i32 [ %255, %237 ], [ %153, %151 ]
  %240 = add nsw i64 %238, %139
  %241 = getelementptr inbounds i8, i8* %2, i64 %240
  %242 = load i8, i8* %241, align 1
  %243 = zext i8 %242 to i32
  %244 = add nsw i32 %11, %243
  %245 = add nsw i64 %238, %150
  %246 = getelementptr inbounds i8, i8* %4, i64 %245
  %247 = load i8, i8* %246, align 1
  %248 = zext i8 %247 to i32
  %249 = add nsw i32 %13, %248
  %250 = shl i32 %249, 16
  %251 = ashr exact i32 %250, 16
  %252 = shl i32 %244, 16
  %253 = ashr exact i32 %252, 16
  %254 = mul nsw i32 %251, %253
  %255 = add nsw i32 %254, %239
  %256 = add nuw nsw i64 %238, 1
  %257 = icmp eq i64 %256, %124
  br i1 %257, label %203, label %237, !llvm.loop !169

258:                                              ; preds = %52
  %259 = getelementptr inbounds i32, i32* %34, i64 %55
  %260 = load i32, i32* %259, align 4
  br label %261

261:                                              ; preds = %258, %52
  %262 = phi i32 [ %260, %258 ], [ 1, %52 ]
  %263 = mul nsw i32 %262, %54
  %264 = or i64 %45, 2
  %265 = icmp eq i64 %264, %37
  br i1 %265, label %269, label %266

266:                                              ; preds = %261
  %267 = getelementptr inbounds i32, i32* %34, i64 %264
  %268 = load i32, i32* %267, align 4
  br label %269

269:                                              ; preds = %266, %261
  %270 = phi i32 [ %268, %266 ], [ 1, %261 ]
  %271 = mul nsw i32 %270, %263
  %272 = or i64 %45, 3
  %273 = icmp eq i64 %272, %37
  br i1 %273, label %277, label %274

274:                                              ; preds = %269
  %275 = getelementptr inbounds i32, i32* %34, i64 %272
  %276 = load i32, i32* %275, align 4
  br label %277

277:                                              ; preds = %274, %269
  %278 = phi i32 [ %276, %274 ], [ 1, %269 ]
  %279 = mul nsw i32 %278, %271
  %280 = add nuw nsw i64 %45, 4
  %281 = add i64 %47, -4
  %282 = icmp eq i64 %281, 0
  br i1 %282, label %57, label %44
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i32 @_ZN6tflite3ops7builtin15fully_connected9EvalFloatILNS2_10KernelTypeE1EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_(%struct.TfLiteContext*, %struct.TfLiteNode*, %struct.TfLiteFullyConnectedParams*, %"struct.tflite::ops::builtin::fully_connected::OpData"*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*) local_unnamed_addr #1 comdat {
  %9 = alloca %"struct.tflite::FullyConnectedParams", align 4
  %10 = alloca %"class.tflite::RuntimeShape", align 8
  %11 = alloca %"class.tflite::RuntimeShape", align 8
  %12 = alloca %"class.tflite::RuntimeShape", align 8
  %13 = alloca %"class.tflite::RuntimeShape", align 8
  %14 = alloca %"class.tflite::RuntimeShape", align 8
  %15 = alloca %"class.tflite::RuntimeShape", align 8
  %16 = alloca %"class.tflite::RuntimeShape", align 8
  %17 = alloca %"class.tflite::RuntimeShape", align 8
  %18 = alloca %"class.tflite::RuntimeShape", align 8
  %19 = alloca %"class.tflite::RuntimeShape", align 8
  %20 = alloca %"class.tflite::RuntimeShape", align 8
  %21 = alloca %"class.tflite::RuntimeShape", align 8
  %22 = getelementptr inbounds %struct.TfLiteFullyConnectedParams, %struct.TfLiteFullyConnectedParams* %2, i64 0, i32 0
  %23 = load i32, i32* %22, align 4
  %24 = add i32 %23, -1
  %25 = icmp ult i32 %24, 3
  br i1 %25, label %26, label %33

26:                                               ; preds = %8
  %27 = sext i32 %24 to i64
  %28 = getelementptr inbounds [3 x i32], [3 x i32]* @switch.table._ZN6tflite3ops7builtin15fully_connected9EvalFloatILNS2_10KernelTypeE1EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_, i64 0, i64 %27
  %29 = load i32, i32* %28, align 4
  %30 = sext i32 %24 to i64
  %31 = getelementptr inbounds [3 x i32], [3 x i32]* @switch.table._ZN6tflite3ops7builtin15fully_connected9EvalFloatILNS2_10KernelTypeE1EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_.74, i64 0, i64 %30
  %32 = load i32, i32* %31, align 4
  br label %33

33:                                               ; preds = %8, %26
  %34 = phi i32 [ %29, %26 ], [ -8388609, %8 ]
  %35 = phi i32 [ %32, %26 ], [ 2139095039, %8 ]
  %36 = bitcast %"struct.tflite::FullyConnectedParams"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %36) #19
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 4 %36, i8* align 4 bitcast ({ i32, i32, i32, i32, i32, i32, i32, float, float, i8, i8, i8, [1 x i8] }* @__const._ZN6tflite3ops7builtin15fully_connected13EvalQuantizedILNS2_10KernelTypeE2EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_.op_params to i8*), i64 40, i1 false)
  %37 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %9, i64 0, i32 7
  %38 = bitcast float* %37 to i32*
  store i32 %34, i32* %38, align 4
  %39 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %9, i64 0, i32 8
  %40 = bitcast float* %39 to i32*
  store i32 %35, i32* %40, align 4
  %41 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 13
  %42 = load %struct.TfLiteSparsity*, %struct.TfLiteSparsity** %41, align 8
  %43 = icmp eq %struct.TfLiteSparsity* %42, null
  br i1 %43, label %420, label %44

44:                                               ; preds = %33
  %45 = getelementptr inbounds %struct.TfLiteSparsity, %struct.TfLiteSparsity* %42, i64 0, i32 2
  %46 = load %struct.TfLiteDimensionMetadata*, %struct.TfLiteDimensionMetadata** %45, align 8
  %47 = getelementptr inbounds %struct.TfLiteDimensionMetadata, %struct.TfLiteDimensionMetadata* %46, i64 0, i32 0
  %48 = load i32, i32* %47, align 8
  %49 = icmp eq i32 %48, 0
  br i1 %49, label %50, label %54

50:                                               ; preds = %44
  %51 = getelementptr inbounds %struct.TfLiteDimensionMetadata, %struct.TfLiteDimensionMetadata* %46, i64 1, i32 0
  %52 = load i32, i32* %51, align 8
  %53 = icmp eq i32 %52, 1
  br i1 %53, label %57, label %54

54:                                               ; preds = %50, %44
  %55 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %56 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %55, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %56(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([50 x i8], [50 x i8]* @.str.36, i64 0, i64 0)) #19
  br label %609

57:                                               ; preds = %50
  %58 = getelementptr inbounds %struct.TfLiteSparsity, %struct.TfLiteSparsity* %42, i64 0, i32 3
  %59 = load i32, i32* %58, align 8
  switch i32 %59, label %417 [
    i32 2, label %60
    i32 3, label %236
  ]

60:                                               ; preds = %57
  %61 = bitcast %"class.tflite::RuntimeShape"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %61) #19
  %62 = icmp eq %struct.TfLiteTensor* %4, null
  br i1 %62, label %63, label %65

63:                                               ; preds = %60
  %64 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %10, i64 0, i32 0
  store i32 0, i32* %64, align 8, !alias.scope !170
  br label %93

65:                                               ; preds = %60
  %66 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 2
  %67 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %66, align 8, !noalias !170
  %68 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %67, i64 0, i32 0
  %69 = load i32, i32* %68, align 4, !noalias !170
  %70 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %67, i64 0, i32 1, i64 0
  %71 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %10, i64 0, i32 0
  store i32 %69, i32* %71, align 8, !alias.scope !170
  %72 = icmp sgt i32 %69, 5
  br i1 %72, label %73, label %80

73:                                               ; preds = %65
  %74 = sext i32 %69 to i64
  %75 = shl nsw i64 %74, 2
  %76 = tail call i8* @_Znam(i64 %75) #18, !noalias !170
  %77 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %10, i64 0, i32 1, i32 0
  %78 = bitcast i32** %77 to i8**
  store i8* %76, i8** %78, align 8, !alias.scope !170
  %79 = bitcast i8* %76 to i32*
  br label %85

80:                                               ; preds = %65
  %81 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %10, i64 0, i32 1
  %82 = bitcast %union.anon.54* %81 to i32*
  %83 = sext i32 %69 to i64
  %84 = shl nsw i64 %83, 2
  br label %85

85:                                               ; preds = %80, %73
  %86 = phi i64 [ %75, %73 ], [ %84, %80 ]
  %87 = phi i32* [ %79, %73 ], [ %82, %80 ]
  %88 = bitcast i32* %87 to i8*
  %89 = bitcast i32* %70 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %88, i8* align 4 %89, i64 %86, i1 false) #19
  %90 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 1
  %91 = bitcast %union.TfLitePtrUnion* %90 to float**
  %92 = load float*, float** %91, align 8
  br label %93

93:                                               ; preds = %63, %85
  %94 = phi float* [ %92, %85 ], [ null, %63 ]
  %95 = bitcast %"class.tflite::RuntimeShape"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %95) #19
  %96 = icmp eq %struct.TfLiteTensor* %5, null
  br i1 %96, label %97, label %99

97:                                               ; preds = %93
  %98 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 0
  store i32 0, i32* %98, align 8, !alias.scope !173
  br label %127

99:                                               ; preds = %93
  %100 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 2
  %101 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %100, align 8, !noalias !173
  %102 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %101, i64 0, i32 0
  %103 = load i32, i32* %102, align 4, !noalias !173
  %104 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %101, i64 0, i32 1, i64 0
  %105 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 0
  store i32 %103, i32* %105, align 8, !alias.scope !173
  %106 = icmp sgt i32 %103, 5
  br i1 %106, label %107, label %114

107:                                              ; preds = %99
  %108 = sext i32 %103 to i64
  %109 = shl nsw i64 %108, 2
  %110 = tail call i8* @_Znam(i64 %109) #18, !noalias !173
  %111 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 1, i32 0
  %112 = bitcast i32** %111 to i8**
  store i8* %110, i8** %112, align 8, !alias.scope !173
  %113 = bitcast i8* %110 to i32*
  br label %119

114:                                              ; preds = %99
  %115 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 1
  %116 = bitcast %union.anon.54* %115 to i32*
  %117 = sext i32 %103 to i64
  %118 = shl nsw i64 %117, 2
  br label %119

119:                                              ; preds = %114, %107
  %120 = phi i64 [ %109, %107 ], [ %118, %114 ]
  %121 = phi i32* [ %113, %107 ], [ %116, %114 ]
  %122 = bitcast i32* %121 to i8*
  %123 = bitcast i32* %104 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %122, i8* align 4 %123, i64 %120, i1 false) #19
  %124 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 1
  %125 = bitcast %union.TfLitePtrUnion* %124 to float**
  %126 = load float*, float** %125, align 8
  br label %127

127:                                              ; preds = %97, %119
  %128 = phi float* [ %126, %119 ], [ null, %97 ]
  %129 = bitcast %"class.tflite::RuntimeShape"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %129) #19
  %130 = icmp eq %struct.TfLiteTensor* %6, null
  br i1 %130, label %131, label %133

131:                                              ; preds = %127
  %132 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 0
  store i32 0, i32* %132, align 8, !alias.scope !176
  br label %161

133:                                              ; preds = %127
  %134 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 2
  %135 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %134, align 8, !noalias !176
  %136 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %135, i64 0, i32 0
  %137 = load i32, i32* %136, align 4, !noalias !176
  %138 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %135, i64 0, i32 1, i64 0
  %139 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 0
  store i32 %137, i32* %139, align 8, !alias.scope !176
  %140 = icmp sgt i32 %137, 5
  br i1 %140, label %141, label %148

141:                                              ; preds = %133
  %142 = sext i32 %137 to i64
  %143 = shl nsw i64 %142, 2
  %144 = tail call i8* @_Znam(i64 %143) #18, !noalias !176
  %145 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 1, i32 0
  %146 = bitcast i32** %145 to i8**
  store i8* %144, i8** %146, align 8, !alias.scope !176
  %147 = bitcast i8* %144 to i32*
  br label %153

148:                                              ; preds = %133
  %149 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 1
  %150 = bitcast %union.anon.54* %149 to i32*
  %151 = sext i32 %137 to i64
  %152 = shl nsw i64 %151, 2
  br label %153

153:                                              ; preds = %148, %141
  %154 = phi i64 [ %143, %141 ], [ %152, %148 ]
  %155 = phi i32* [ %147, %141 ], [ %150, %148 ]
  %156 = bitcast i32* %155 to i8*
  %157 = bitcast i32* %138 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %156, i8* align 4 %157, i64 %154, i1 false) #19
  %158 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 1
  %159 = bitcast %union.TfLitePtrUnion* %158 to float**
  %160 = load float*, float** %159, align 8
  br label %161

161:                                              ; preds = %131, %153
  %162 = phi float* [ %160, %153 ], [ null, %131 ]
  %163 = bitcast %"class.tflite::RuntimeShape"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %163) #19
  %164 = icmp eq %struct.TfLiteTensor* %7, null
  br i1 %164, label %165, label %167

165:                                              ; preds = %161
  %166 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 0
  store i32 0, i32* %166, align 8, !alias.scope !179
  br label %195

167:                                              ; preds = %161
  %168 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 2
  %169 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %168, align 8, !noalias !179
  %170 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %169, i64 0, i32 0
  %171 = load i32, i32* %170, align 4, !noalias !179
  %172 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %169, i64 0, i32 1, i64 0
  %173 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 0
  store i32 %171, i32* %173, align 8, !alias.scope !179
  %174 = icmp sgt i32 %171, 5
  br i1 %174, label %175, label %182

175:                                              ; preds = %167
  %176 = sext i32 %171 to i64
  %177 = shl nsw i64 %176, 2
  %178 = tail call i8* @_Znam(i64 %177) #18, !noalias !179
  %179 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 1, i32 0
  %180 = bitcast i32** %179 to i8**
  store i8* %178, i8** %180, align 8, !alias.scope !179
  %181 = bitcast i8* %178 to i32*
  br label %187

182:                                              ; preds = %167
  %183 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 1
  %184 = bitcast %union.anon.54* %183 to i32*
  %185 = sext i32 %171 to i64
  %186 = shl nsw i64 %185, 2
  br label %187

187:                                              ; preds = %182, %175
  %188 = phi i64 [ %177, %175 ], [ %186, %182 ]
  %189 = phi i32* [ %181, %175 ], [ %184, %182 ]
  %190 = bitcast i32* %189 to i8*
  %191 = bitcast i32* %172 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %190, i8* align 4 %191, i64 %188, i1 false) #19
  %192 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 1
  %193 = bitcast %union.TfLitePtrUnion* %192 to float**
  %194 = load float*, float** %193, align 8
  br label %195

195:                                              ; preds = %165, %187
  %196 = phi float* [ %194, %187 ], [ null, %165 ]
  call void @_ZN6tflite13optimized_ops26FullyConnectedSparseWeightERK14TfLiteSparsityRKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKfS9_SB_S9_SB_S9_Pf(%struct.TfLiteSparsity* nonnull dereferenceable(32) %42, %"struct.tflite::FullyConnectedParams"* nonnull dereferenceable(40) %9, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %10, float* %94, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %11, float* %128, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %12, float* %162, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %13, float* %196)
  %197 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 0
  %198 = load i32, i32* %197, align 8
  %199 = icmp sgt i32 %198, 5
  br i1 %199, label %200, label %206

200:                                              ; preds = %195
  %201 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 1, i32 0
  %202 = load i32*, i32** %201, align 8
  %203 = icmp eq i32* %202, null
  br i1 %203, label %206, label %204

204:                                              ; preds = %200
  %205 = bitcast i32* %202 to i8*
  call void @_ZdaPv(i8* %205) #18
  br label %206

206:                                              ; preds = %195, %200, %204
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %163) #19
  %207 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 0
  %208 = load i32, i32* %207, align 8
  %209 = icmp sgt i32 %208, 5
  br i1 %209, label %210, label %216

210:                                              ; preds = %206
  %211 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 1, i32 0
  %212 = load i32*, i32** %211, align 8
  %213 = icmp eq i32* %212, null
  br i1 %213, label %216, label %214

214:                                              ; preds = %210
  %215 = bitcast i32* %212 to i8*
  call void @_ZdaPv(i8* %215) #18
  br label %216

216:                                              ; preds = %206, %210, %214
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %129) #19
  %217 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 0
  %218 = load i32, i32* %217, align 8
  %219 = icmp sgt i32 %218, 5
  br i1 %219, label %220, label %226

220:                                              ; preds = %216
  %221 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 1, i32 0
  %222 = load i32*, i32** %221, align 8
  %223 = icmp eq i32* %222, null
  br i1 %223, label %226, label %224

224:                                              ; preds = %220
  %225 = bitcast i32* %222 to i8*
  call void @_ZdaPv(i8* %225) #18
  br label %226

226:                                              ; preds = %216, %220, %224
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %95) #19
  %227 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %10, i64 0, i32 0
  %228 = load i32, i32* %227, align 8
  %229 = icmp sgt i32 %228, 5
  br i1 %229, label %230, label %607

230:                                              ; preds = %226
  %231 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %10, i64 0, i32 1, i32 0
  %232 = load i32*, i32** %231, align 8
  %233 = icmp eq i32* %232, null
  br i1 %233, label %607, label %234

234:                                              ; preds = %230
  %235 = bitcast i32* %232 to i8*
  call void @_ZdaPv(i8* %235) #18
  br label %607

236:                                              ; preds = %57
  %237 = getelementptr inbounds %struct.TfLiteDimensionMetadata, %struct.TfLiteDimensionMetadata* %46, i64 2, i32 1
  %238 = load i32, i32* %237, align 4
  %239 = icmp eq i32 %238, 4
  br i1 %239, label %240, label %417

240:                                              ; preds = %236
  %241 = bitcast %"class.tflite::RuntimeShape"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %241) #19
  %242 = icmp eq %struct.TfLiteTensor* %4, null
  br i1 %242, label %243, label %245

243:                                              ; preds = %240
  %244 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 0
  store i32 0, i32* %244, align 8, !alias.scope !182
  br label %273

245:                                              ; preds = %240
  %246 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 2
  %247 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %246, align 8, !noalias !182
  %248 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %247, i64 0, i32 0
  %249 = load i32, i32* %248, align 4, !noalias !182
  %250 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %247, i64 0, i32 1, i64 0
  %251 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 0
  store i32 %249, i32* %251, align 8, !alias.scope !182
  %252 = icmp sgt i32 %249, 5
  br i1 %252, label %253, label %260

253:                                              ; preds = %245
  %254 = sext i32 %249 to i64
  %255 = shl nsw i64 %254, 2
  %256 = tail call i8* @_Znam(i64 %255) #18, !noalias !182
  %257 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 1, i32 0
  %258 = bitcast i32** %257 to i8**
  store i8* %256, i8** %258, align 8, !alias.scope !182
  %259 = bitcast i8* %256 to i32*
  br label %265

260:                                              ; preds = %245
  %261 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 1
  %262 = bitcast %union.anon.54* %261 to i32*
  %263 = sext i32 %249 to i64
  %264 = shl nsw i64 %263, 2
  br label %265

265:                                              ; preds = %260, %253
  %266 = phi i64 [ %255, %253 ], [ %264, %260 ]
  %267 = phi i32* [ %259, %253 ], [ %262, %260 ]
  %268 = bitcast i32* %267 to i8*
  %269 = bitcast i32* %250 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %268, i8* align 4 %269, i64 %266, i1 false) #19
  %270 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 1
  %271 = bitcast %union.TfLitePtrUnion* %270 to float**
  %272 = load float*, float** %271, align 8
  br label %273

273:                                              ; preds = %243, %265
  %274 = phi float* [ %272, %265 ], [ null, %243 ]
  %275 = bitcast %"class.tflite::RuntimeShape"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %275) #19
  %276 = icmp eq %struct.TfLiteTensor* %5, null
  br i1 %276, label %277, label %279

277:                                              ; preds = %273
  %278 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %15, i64 0, i32 0
  store i32 0, i32* %278, align 8, !alias.scope !185
  br label %307

279:                                              ; preds = %273
  %280 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 2
  %281 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %280, align 8, !noalias !185
  %282 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %281, i64 0, i32 0
  %283 = load i32, i32* %282, align 4, !noalias !185
  %284 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %281, i64 0, i32 1, i64 0
  %285 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %15, i64 0, i32 0
  store i32 %283, i32* %285, align 8, !alias.scope !185
  %286 = icmp sgt i32 %283, 5
  br i1 %286, label %287, label %294

287:                                              ; preds = %279
  %288 = sext i32 %283 to i64
  %289 = shl nsw i64 %288, 2
  %290 = tail call i8* @_Znam(i64 %289) #18, !noalias !185
  %291 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %15, i64 0, i32 1, i32 0
  %292 = bitcast i32** %291 to i8**
  store i8* %290, i8** %292, align 8, !alias.scope !185
  %293 = bitcast i8* %290 to i32*
  br label %299

294:                                              ; preds = %279
  %295 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %15, i64 0, i32 1
  %296 = bitcast %union.anon.54* %295 to i32*
  %297 = sext i32 %283 to i64
  %298 = shl nsw i64 %297, 2
  br label %299

299:                                              ; preds = %294, %287
  %300 = phi i64 [ %289, %287 ], [ %298, %294 ]
  %301 = phi i32* [ %293, %287 ], [ %296, %294 ]
  %302 = bitcast i32* %301 to i8*
  %303 = bitcast i32* %284 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %302, i8* align 4 %303, i64 %300, i1 false) #19
  %304 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 1
  %305 = bitcast %union.TfLitePtrUnion* %304 to float**
  %306 = load float*, float** %305, align 8
  br label %307

307:                                              ; preds = %277, %299
  %308 = phi float* [ %306, %299 ], [ null, %277 ]
  %309 = bitcast %"class.tflite::RuntimeShape"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %309) #19
  %310 = icmp eq %struct.TfLiteTensor* %6, null
  br i1 %310, label %311, label %313

311:                                              ; preds = %307
  %312 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %16, i64 0, i32 0
  store i32 0, i32* %312, align 8, !alias.scope !188
  br label %341

313:                                              ; preds = %307
  %314 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 2
  %315 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %314, align 8, !noalias !188
  %316 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %315, i64 0, i32 0
  %317 = load i32, i32* %316, align 4, !noalias !188
  %318 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %315, i64 0, i32 1, i64 0
  %319 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %16, i64 0, i32 0
  store i32 %317, i32* %319, align 8, !alias.scope !188
  %320 = icmp sgt i32 %317, 5
  br i1 %320, label %321, label %328

321:                                              ; preds = %313
  %322 = sext i32 %317 to i64
  %323 = shl nsw i64 %322, 2
  %324 = tail call i8* @_Znam(i64 %323) #18, !noalias !188
  %325 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %16, i64 0, i32 1, i32 0
  %326 = bitcast i32** %325 to i8**
  store i8* %324, i8** %326, align 8, !alias.scope !188
  %327 = bitcast i8* %324 to i32*
  br label %333

328:                                              ; preds = %313
  %329 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %16, i64 0, i32 1
  %330 = bitcast %union.anon.54* %329 to i32*
  %331 = sext i32 %317 to i64
  %332 = shl nsw i64 %331, 2
  br label %333

333:                                              ; preds = %328, %321
  %334 = phi i64 [ %323, %321 ], [ %332, %328 ]
  %335 = phi i32* [ %327, %321 ], [ %330, %328 ]
  %336 = bitcast i32* %335 to i8*
  %337 = bitcast i32* %318 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %336, i8* align 4 %337, i64 %334, i1 false) #19
  %338 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 1
  %339 = bitcast %union.TfLitePtrUnion* %338 to float**
  %340 = load float*, float** %339, align 8
  br label %341

341:                                              ; preds = %311, %333
  %342 = phi float* [ %340, %333 ], [ null, %311 ]
  %343 = bitcast %"class.tflite::RuntimeShape"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %343) #19
  %344 = icmp eq %struct.TfLiteTensor* %7, null
  br i1 %344, label %345, label %347

345:                                              ; preds = %341
  %346 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %17, i64 0, i32 0
  store i32 0, i32* %346, align 8, !alias.scope !191
  br label %375

347:                                              ; preds = %341
  %348 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 2
  %349 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %348, align 8, !noalias !191
  %350 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %349, i64 0, i32 0
  %351 = load i32, i32* %350, align 4, !noalias !191
  %352 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %349, i64 0, i32 1, i64 0
  %353 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %17, i64 0, i32 0
  store i32 %351, i32* %353, align 8, !alias.scope !191
  %354 = icmp sgt i32 %351, 5
  br i1 %354, label %355, label %362

355:                                              ; preds = %347
  %356 = sext i32 %351 to i64
  %357 = shl nsw i64 %356, 2
  %358 = tail call i8* @_Znam(i64 %357) #18, !noalias !191
  %359 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %17, i64 0, i32 1, i32 0
  %360 = bitcast i32** %359 to i8**
  store i8* %358, i8** %360, align 8, !alias.scope !191
  %361 = bitcast i8* %358 to i32*
  br label %367

362:                                              ; preds = %347
  %363 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %17, i64 0, i32 1
  %364 = bitcast %union.anon.54* %363 to i32*
  %365 = sext i32 %351 to i64
  %366 = shl nsw i64 %365, 2
  br label %367

367:                                              ; preds = %362, %355
  %368 = phi i64 [ %357, %355 ], [ %366, %362 ]
  %369 = phi i32* [ %361, %355 ], [ %364, %362 ]
  %370 = bitcast i32* %369 to i8*
  %371 = bitcast i32* %352 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %370, i8* align 4 %371, i64 %368, i1 false) #19
  %372 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 1
  %373 = bitcast %union.TfLitePtrUnion* %372 to float**
  %374 = load float*, float** %373, align 8
  br label %375

375:                                              ; preds = %345, %367
  %376 = phi float* [ %374, %367 ], [ null, %345 ]
  %377 = tail call %"class.tflite::CpuBackendContext"* @_ZN6tflite17CpuBackendContext14GetFromContextEP13TfLiteContext(%struct.TfLiteContext* %0) #19
  call void @_ZN6tflite13optimized_ops29FullyConnectedSparseWeight1x4ERK14TfLiteSparsityRKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKfS9_SB_S9_SB_S9_PfPNS_17CpuBackendContextE(%struct.TfLiteSparsity* nonnull dereferenceable(32) %42, %"struct.tflite::FullyConnectedParams"* nonnull dereferenceable(40) %9, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %14, float* %274, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %15, float* %308, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %16, float* %342, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %17, float* %376, %"class.tflite::CpuBackendContext"* %377)
  %378 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %17, i64 0, i32 0
  %379 = load i32, i32* %378, align 8
  %380 = icmp sgt i32 %379, 5
  br i1 %380, label %381, label %387

381:                                              ; preds = %375
  %382 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %17, i64 0, i32 1, i32 0
  %383 = load i32*, i32** %382, align 8
  %384 = icmp eq i32* %383, null
  br i1 %384, label %387, label %385

385:                                              ; preds = %381
  %386 = bitcast i32* %383 to i8*
  call void @_ZdaPv(i8* %386) #18
  br label %387

387:                                              ; preds = %375, %381, %385
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %343) #19
  %388 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %16, i64 0, i32 0
  %389 = load i32, i32* %388, align 8
  %390 = icmp sgt i32 %389, 5
  br i1 %390, label %391, label %397

391:                                              ; preds = %387
  %392 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %16, i64 0, i32 1, i32 0
  %393 = load i32*, i32** %392, align 8
  %394 = icmp eq i32* %393, null
  br i1 %394, label %397, label %395

395:                                              ; preds = %391
  %396 = bitcast i32* %393 to i8*
  call void @_ZdaPv(i8* %396) #18
  br label %397

397:                                              ; preds = %387, %391, %395
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %309) #19
  %398 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %15, i64 0, i32 0
  %399 = load i32, i32* %398, align 8
  %400 = icmp sgt i32 %399, 5
  br i1 %400, label %401, label %407

401:                                              ; preds = %397
  %402 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %15, i64 0, i32 1, i32 0
  %403 = load i32*, i32** %402, align 8
  %404 = icmp eq i32* %403, null
  br i1 %404, label %407, label %405

405:                                              ; preds = %401
  %406 = bitcast i32* %403 to i8*
  call void @_ZdaPv(i8* %406) #18
  br label %407

407:                                              ; preds = %397, %401, %405
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %275) #19
  %408 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 0
  %409 = load i32, i32* %408, align 8
  %410 = icmp sgt i32 %409, 5
  br i1 %410, label %411, label %607

411:                                              ; preds = %407
  %412 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 1, i32 0
  %413 = load i32*, i32** %412, align 8
  %414 = icmp eq i32* %413, null
  br i1 %414, label %607, label %415

415:                                              ; preds = %411
  %416 = bitcast i32* %413 to i8*
  call void @_ZdaPv(i8* %416) #18
  br label %607

417:                                              ; preds = %57, %236
  %418 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %419 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %418, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %419(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([50 x i8], [50 x i8]* @.str.36, i64 0, i64 0)) #19
  br label %609

420:                                              ; preds = %33
  %421 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 4
  %422 = load i32, i32* %421, align 8
  %423 = icmp eq i32 %422, 1
  %424 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %9, i64 0, i32 9
  %425 = zext i1 %423 to i8
  store i8 %425, i8* %424, align 4
  %426 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 4
  %427 = load i32, i32* %426, align 8
  %428 = icmp eq i32 %427, 1
  %429 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %9, i64 0, i32 10
  %430 = zext i1 %428 to i8
  store i8 %430, i8* %429, align 1
  %431 = bitcast %"class.tflite::RuntimeShape"* %18 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %431) #19
  %432 = icmp eq %struct.TfLiteTensor* %4, null
  br i1 %432, label %433, label %435

433:                                              ; preds = %420
  %434 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %18, i64 0, i32 0
  store i32 0, i32* %434, align 8, !alias.scope !194
  br label %463

435:                                              ; preds = %420
  %436 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 2
  %437 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %436, align 8, !noalias !194
  %438 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %437, i64 0, i32 0
  %439 = load i32, i32* %438, align 4, !noalias !194
  %440 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %437, i64 0, i32 1, i64 0
  %441 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %18, i64 0, i32 0
  store i32 %439, i32* %441, align 8, !alias.scope !194
  %442 = icmp sgt i32 %439, 5
  br i1 %442, label %443, label %450

443:                                              ; preds = %435
  %444 = sext i32 %439 to i64
  %445 = shl nsw i64 %444, 2
  %446 = tail call i8* @_Znam(i64 %445) #18, !noalias !194
  %447 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %18, i64 0, i32 1, i32 0
  %448 = bitcast i32** %447 to i8**
  store i8* %446, i8** %448, align 8, !alias.scope !194
  %449 = bitcast i8* %446 to i32*
  br label %455

450:                                              ; preds = %435
  %451 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %18, i64 0, i32 1
  %452 = bitcast %union.anon.54* %451 to i32*
  %453 = sext i32 %439 to i64
  %454 = shl nsw i64 %453, 2
  br label %455

455:                                              ; preds = %450, %443
  %456 = phi i64 [ %445, %443 ], [ %454, %450 ]
  %457 = phi i32* [ %449, %443 ], [ %452, %450 ]
  %458 = bitcast i32* %457 to i8*
  %459 = bitcast i32* %440 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %458, i8* align 4 %459, i64 %456, i1 false) #19
  %460 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 1
  %461 = bitcast %union.TfLitePtrUnion* %460 to float**
  %462 = load float*, float** %461, align 8
  br label %463

463:                                              ; preds = %433, %455
  %464 = phi float* [ %462, %455 ], [ null, %433 ]
  %465 = bitcast %"class.tflite::RuntimeShape"* %19 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %465) #19
  %466 = icmp eq %struct.TfLiteTensor* %5, null
  br i1 %466, label %467, label %469

467:                                              ; preds = %463
  %468 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %19, i64 0, i32 0
  store i32 0, i32* %468, align 8, !alias.scope !197
  br label %497

469:                                              ; preds = %463
  %470 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 2
  %471 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %470, align 8, !noalias !197
  %472 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %471, i64 0, i32 0
  %473 = load i32, i32* %472, align 4, !noalias !197
  %474 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %471, i64 0, i32 1, i64 0
  %475 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %19, i64 0, i32 0
  store i32 %473, i32* %475, align 8, !alias.scope !197
  %476 = icmp sgt i32 %473, 5
  br i1 %476, label %477, label %484

477:                                              ; preds = %469
  %478 = sext i32 %473 to i64
  %479 = shl nsw i64 %478, 2
  %480 = tail call i8* @_Znam(i64 %479) #18, !noalias !197
  %481 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %19, i64 0, i32 1, i32 0
  %482 = bitcast i32** %481 to i8**
  store i8* %480, i8** %482, align 8, !alias.scope !197
  %483 = bitcast i8* %480 to i32*
  br label %489

484:                                              ; preds = %469
  %485 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %19, i64 0, i32 1
  %486 = bitcast %union.anon.54* %485 to i32*
  %487 = sext i32 %473 to i64
  %488 = shl nsw i64 %487, 2
  br label %489

489:                                              ; preds = %484, %477
  %490 = phi i64 [ %479, %477 ], [ %488, %484 ]
  %491 = phi i32* [ %483, %477 ], [ %486, %484 ]
  %492 = bitcast i32* %491 to i8*
  %493 = bitcast i32* %474 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %492, i8* align 4 %493, i64 %490, i1 false) #19
  %494 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 1
  %495 = bitcast %union.TfLitePtrUnion* %494 to float**
  %496 = load float*, float** %495, align 8
  br label %497

497:                                              ; preds = %467, %489
  %498 = phi float* [ %496, %489 ], [ null, %467 ]
  %499 = bitcast %"class.tflite::RuntimeShape"* %20 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %499) #19
  %500 = icmp eq %struct.TfLiteTensor* %6, null
  br i1 %500, label %501, label %503

501:                                              ; preds = %497
  %502 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %20, i64 0, i32 0
  store i32 0, i32* %502, align 8, !alias.scope !200
  br label %531

503:                                              ; preds = %497
  %504 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 2
  %505 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %504, align 8, !noalias !200
  %506 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %505, i64 0, i32 0
  %507 = load i32, i32* %506, align 4, !noalias !200
  %508 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %505, i64 0, i32 1, i64 0
  %509 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %20, i64 0, i32 0
  store i32 %507, i32* %509, align 8, !alias.scope !200
  %510 = icmp sgt i32 %507, 5
  br i1 %510, label %511, label %518

511:                                              ; preds = %503
  %512 = sext i32 %507 to i64
  %513 = shl nsw i64 %512, 2
  %514 = tail call i8* @_Znam(i64 %513) #18, !noalias !200
  %515 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %20, i64 0, i32 1, i32 0
  %516 = bitcast i32** %515 to i8**
  store i8* %514, i8** %516, align 8, !alias.scope !200
  %517 = bitcast i8* %514 to i32*
  br label %523

518:                                              ; preds = %503
  %519 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %20, i64 0, i32 1
  %520 = bitcast %union.anon.54* %519 to i32*
  %521 = sext i32 %507 to i64
  %522 = shl nsw i64 %521, 2
  br label %523

523:                                              ; preds = %518, %511
  %524 = phi i64 [ %513, %511 ], [ %522, %518 ]
  %525 = phi i32* [ %517, %511 ], [ %520, %518 ]
  %526 = bitcast i32* %525 to i8*
  %527 = bitcast i32* %508 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %526, i8* align 4 %527, i64 %524, i1 false) #19
  %528 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 1
  %529 = bitcast %union.TfLitePtrUnion* %528 to float**
  %530 = load float*, float** %529, align 8
  br label %531

531:                                              ; preds = %501, %523
  %532 = phi float* [ %530, %523 ], [ null, %501 ]
  %533 = bitcast %"class.tflite::RuntimeShape"* %21 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %533) #19
  %534 = icmp eq %struct.TfLiteTensor* %7, null
  br i1 %534, label %535, label %537

535:                                              ; preds = %531
  %536 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %21, i64 0, i32 0
  store i32 0, i32* %536, align 8, !alias.scope !203
  br label %565

537:                                              ; preds = %531
  %538 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 2
  %539 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %538, align 8, !noalias !203
  %540 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %539, i64 0, i32 0
  %541 = load i32, i32* %540, align 4, !noalias !203
  %542 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %539, i64 0, i32 1, i64 0
  %543 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %21, i64 0, i32 0
  store i32 %541, i32* %543, align 8, !alias.scope !203
  %544 = icmp sgt i32 %541, 5
  br i1 %544, label %545, label %552

545:                                              ; preds = %537
  %546 = sext i32 %541 to i64
  %547 = shl nsw i64 %546, 2
  %548 = tail call i8* @_Znam(i64 %547) #18, !noalias !203
  %549 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %21, i64 0, i32 1, i32 0
  %550 = bitcast i32** %549 to i8**
  store i8* %548, i8** %550, align 8, !alias.scope !203
  %551 = bitcast i8* %548 to i32*
  br label %557

552:                                              ; preds = %537
  %553 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %21, i64 0, i32 1
  %554 = bitcast %union.anon.54* %553 to i32*
  %555 = sext i32 %541 to i64
  %556 = shl nsw i64 %555, 2
  br label %557

557:                                              ; preds = %552, %545
  %558 = phi i64 [ %547, %545 ], [ %556, %552 ]
  %559 = phi i32* [ %551, %545 ], [ %554, %552 ]
  %560 = bitcast i32* %559 to i8*
  %561 = bitcast i32* %542 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %560, i8* align 4 %561, i64 %558, i1 false) #19
  %562 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 1
  %563 = bitcast %union.TfLitePtrUnion* %562 to float**
  %564 = load float*, float** %563, align 8
  br label %565

565:                                              ; preds = %535, %557
  %566 = phi float* [ %564, %557 ], [ null, %535 ]
  %567 = tail call %"class.tflite::CpuBackendContext"* @_ZN6tflite17CpuBackendContext14GetFromContextEP13TfLiteContext(%struct.TfLiteContext* %0) #19
  call void @_ZN6tflite13optimized_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfPNS_17CpuBackendContextE(%"struct.tflite::FullyConnectedParams"* nonnull dereferenceable(40) %9, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %18, float* %464, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %19, float* %498, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %20, float* %532, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %21, float* %566, %"class.tflite::CpuBackendContext"* %567)
  %568 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %21, i64 0, i32 0
  %569 = load i32, i32* %568, align 8
  %570 = icmp sgt i32 %569, 5
  br i1 %570, label %571, label %577

571:                                              ; preds = %565
  %572 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %21, i64 0, i32 1, i32 0
  %573 = load i32*, i32** %572, align 8
  %574 = icmp eq i32* %573, null
  br i1 %574, label %577, label %575

575:                                              ; preds = %571
  %576 = bitcast i32* %573 to i8*
  call void @_ZdaPv(i8* %576) #18
  br label %577

577:                                              ; preds = %565, %571, %575
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %533) #19
  %578 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %20, i64 0, i32 0
  %579 = load i32, i32* %578, align 8
  %580 = icmp sgt i32 %579, 5
  br i1 %580, label %581, label %587

581:                                              ; preds = %577
  %582 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %20, i64 0, i32 1, i32 0
  %583 = load i32*, i32** %582, align 8
  %584 = icmp eq i32* %583, null
  br i1 %584, label %587, label %585

585:                                              ; preds = %581
  %586 = bitcast i32* %583 to i8*
  call void @_ZdaPv(i8* %586) #18
  br label %587

587:                                              ; preds = %577, %581, %585
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %499) #19
  %588 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %19, i64 0, i32 0
  %589 = load i32, i32* %588, align 8
  %590 = icmp sgt i32 %589, 5
  br i1 %590, label %591, label %597

591:                                              ; preds = %587
  %592 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %19, i64 0, i32 1, i32 0
  %593 = load i32*, i32** %592, align 8
  %594 = icmp eq i32* %593, null
  br i1 %594, label %597, label %595

595:                                              ; preds = %591
  %596 = bitcast i32* %593 to i8*
  call void @_ZdaPv(i8* %596) #18
  br label %597

597:                                              ; preds = %587, %591, %595
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %465) #19
  %598 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %18, i64 0, i32 0
  %599 = load i32, i32* %598, align 8
  %600 = icmp sgt i32 %599, 5
  br i1 %600, label %601, label %607

601:                                              ; preds = %597
  %602 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %18, i64 0, i32 1, i32 0
  %603 = load i32*, i32** %602, align 8
  %604 = icmp eq i32* %603, null
  br i1 %604, label %607, label %605

605:                                              ; preds = %601
  %606 = bitcast i32* %603 to i8*
  call void @_ZdaPv(i8* %606) #18
  br label %607

607:                                              ; preds = %605, %601, %597, %415, %411, %407, %234, %230, %226
  %608 = phi i8* [ %61, %226 ], [ %61, %230 ], [ %61, %234 ], [ %241, %407 ], [ %241, %411 ], [ %241, %415 ], [ %431, %597 ], [ %431, %601 ], [ %431, %605 ]
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %608) #19
  br label %609

609:                                              ; preds = %417, %54, %607
  %610 = phi i32 [ 0, %607 ], [ 1, %54 ], [ 1, %417 ]
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %36) #19
  ret i32 %610
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i32 @_ZN6tflite3ops7builtin15fully_connected21EvalShuffledQuantizedILNS2_10KernelTypeE1EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_SH_(%struct.TfLiteContext*, %struct.TfLiteNode*, %struct.TfLiteFullyConnectedParams*, %"struct.tflite::ops::builtin::fully_connected::OpData"*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*) local_unnamed_addr #1 comdat {
  %10 = alloca %"struct.tflite::FullyConnectedParams", align 4
  %11 = alloca %"class.tflite::RuntimeShape", align 8
  %12 = alloca %"class.tflite::RuntimeShape", align 8
  %13 = alloca %"class.tflite::RuntimeShape", align 8
  %14 = alloca %"class.tflite::RuntimeShape", align 8
  %15 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %8, i64 0, i32 0
  %16 = load i32, i32* %15, align 8
  %17 = icmp eq i32 %16, 3
  br i1 %17, label %21, label %18

18:                                               ; preds = %9
  %19 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %20 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %19, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %20(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.34, i64 0, i64 0)) #19
  br label %220

21:                                               ; preds = %9
  %22 = bitcast %"struct.tflite::FullyConnectedParams"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %22) #19
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 4 %22, i8* align 4 bitcast ({ i32, i32, i32, i32, i32, i32, i32, float, float, i8, i8, i8, [1 x i8] }* @__const._ZN6tflite3ops7builtin15fully_connected13EvalQuantizedILNS2_10KernelTypeE2EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_.op_params to i8*), i64 40, i1 false)
  %23 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %10, i64 0, i32 3
  %24 = bitcast %"struct.tflite::ops::builtin::fully_connected::OpData"* %3 to <4 x i32>*
  %25 = load <4 x i32>, <4 x i32>* %24, align 4
  %26 = bitcast i32* %23 to <4 x i32>*
  store <4 x i32> %25, <4 x i32>* %26, align 4
  %27 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 4
  %28 = load i32, i32* %27, align 8
  %29 = icmp eq i32 %28, 1
  %30 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %10, i64 0, i32 9
  %31 = zext i1 %29 to i8
  store i8 %31, i8* %30, align 4
  %32 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 4
  %33 = load i32, i32* %32, align 8
  %34 = icmp eq i32 %33, 1
  %35 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %10, i64 0, i32 10
  %36 = zext i1 %34 to i8
  store i8 %36, i8* %35, align 1
  %37 = bitcast %"class.tflite::RuntimeShape"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %37) #19
  %38 = icmp eq %struct.TfLiteTensor* %4, null
  br i1 %38, label %39, label %41

39:                                               ; preds = %21
  %40 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 0
  store i32 0, i32* %40, align 8, !alias.scope !206
  br label %69

41:                                               ; preds = %21
  %42 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 2
  %43 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %42, align 8, !noalias !206
  %44 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %43, i64 0, i32 0
  %45 = load i32, i32* %44, align 4, !noalias !206
  %46 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %43, i64 0, i32 1, i64 0
  %47 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 0
  store i32 %45, i32* %47, align 8, !alias.scope !206
  %48 = icmp sgt i32 %45, 5
  br i1 %48, label %49, label %56

49:                                               ; preds = %41
  %50 = sext i32 %45 to i64
  %51 = shl nsw i64 %50, 2
  %52 = tail call i8* @_Znam(i64 %51) #18, !noalias !206
  %53 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 1, i32 0
  %54 = bitcast i32** %53 to i8**
  store i8* %52, i8** %54, align 8, !alias.scope !206
  %55 = bitcast i8* %52 to i32*
  br label %61

56:                                               ; preds = %41
  %57 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 1
  %58 = bitcast %union.anon.54* %57 to i32*
  %59 = sext i32 %45 to i64
  %60 = shl nsw i64 %59, 2
  br label %61

61:                                               ; preds = %56, %49
  %62 = phi i64 [ %51, %49 ], [ %60, %56 ]
  %63 = phi i32* [ %55, %49 ], [ %58, %56 ]
  %64 = bitcast i32* %63 to i8*
  %65 = bitcast i32* %46 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %64, i8* align 4 %65, i64 %62, i1 false) #19
  %66 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 1
  %67 = bitcast %union.TfLitePtrUnion* %66 to i8**
  %68 = load i8*, i8** %67, align 8
  br label %69

69:                                               ; preds = %39, %61
  %70 = phi i8* [ %68, %61 ], [ null, %39 ]
  %71 = bitcast %"class.tflite::RuntimeShape"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %71) #19
  %72 = icmp eq %struct.TfLiteTensor* %5, null
  br i1 %72, label %73, label %75

73:                                               ; preds = %69
  %74 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 0
  store i32 0, i32* %74, align 8, !alias.scope !209
  br label %103

75:                                               ; preds = %69
  %76 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 2
  %77 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %76, align 8, !noalias !209
  %78 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %77, i64 0, i32 0
  %79 = load i32, i32* %78, align 4, !noalias !209
  %80 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %77, i64 0, i32 1, i64 0
  %81 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 0
  store i32 %79, i32* %81, align 8, !alias.scope !209
  %82 = icmp sgt i32 %79, 5
  br i1 %82, label %83, label %90

83:                                               ; preds = %75
  %84 = sext i32 %79 to i64
  %85 = shl nsw i64 %84, 2
  %86 = tail call i8* @_Znam(i64 %85) #18, !noalias !209
  %87 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 1, i32 0
  %88 = bitcast i32** %87 to i8**
  store i8* %86, i8** %88, align 8, !alias.scope !209
  %89 = bitcast i8* %86 to i32*
  br label %95

90:                                               ; preds = %75
  %91 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 1
  %92 = bitcast %union.anon.54* %91 to i32*
  %93 = sext i32 %79 to i64
  %94 = shl nsw i64 %93, 2
  br label %95

95:                                               ; preds = %90, %83
  %96 = phi i64 [ %85, %83 ], [ %94, %90 ]
  %97 = phi i32* [ %89, %83 ], [ %92, %90 ]
  %98 = bitcast i32* %97 to i8*
  %99 = bitcast i32* %80 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %98, i8* align 4 %99, i64 %96, i1 false) #19
  %100 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 1
  %101 = bitcast %union.TfLitePtrUnion* %100 to i8**
  %102 = load i8*, i8** %101, align 8
  br label %103

103:                                              ; preds = %73, %95
  %104 = phi i8* [ %102, %95 ], [ null, %73 ]
  %105 = bitcast %"class.tflite::RuntimeShape"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %105) #19
  %106 = icmp eq %struct.TfLiteTensor* %6, null
  br i1 %106, label %107, label %109

107:                                              ; preds = %103
  %108 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 0
  store i32 0, i32* %108, align 8, !alias.scope !212
  br label %136

109:                                              ; preds = %103
  %110 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 2
  %111 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %110, align 8, !noalias !212
  %112 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %111, i64 0, i32 0
  %113 = load i32, i32* %112, align 4, !noalias !212
  %114 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %111, i64 0, i32 1, i64 0
  %115 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 0
  store i32 %113, i32* %115, align 8, !alias.scope !212
  %116 = icmp sgt i32 %113, 5
  br i1 %116, label %117, label %124

117:                                              ; preds = %109
  %118 = sext i32 %113 to i64
  %119 = shl nsw i64 %118, 2
  %120 = tail call i8* @_Znam(i64 %119) #18, !noalias !212
  %121 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 1, i32 0
  %122 = bitcast i32** %121 to i8**
  store i8* %120, i8** %122, align 8, !alias.scope !212
  %123 = bitcast i8* %120 to i32*
  br label %129

124:                                              ; preds = %109
  %125 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 1
  %126 = bitcast %union.anon.54* %125 to i32*
  %127 = sext i32 %113 to i64
  %128 = shl nsw i64 %127, 2
  br label %129

129:                                              ; preds = %124, %117
  %130 = phi i64 [ %119, %117 ], [ %128, %124 ]
  %131 = phi i32* [ %123, %117 ], [ %126, %124 ]
  %132 = bitcast i32* %131 to i8*
  %133 = bitcast i32* %114 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %132, i8* align 4 %133, i64 %130, i1 false) #19
  %134 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 1, i32 0
  %135 = load i32*, i32** %134, align 8
  br label %136

136:                                              ; preds = %107, %129
  %137 = phi i32* [ %135, %129 ], [ null, %107 ]
  %138 = bitcast %"class.tflite::RuntimeShape"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %138) #19
  %139 = icmp eq %struct.TfLiteTensor* %7, null
  br i1 %139, label %140, label %142

140:                                              ; preds = %136
  %141 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 0
  store i32 0, i32* %141, align 8, !alias.scope !215
  br label %170

142:                                              ; preds = %136
  %143 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 2
  %144 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %143, align 8, !noalias !215
  %145 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %144, i64 0, i32 0
  %146 = load i32, i32* %145, align 4, !noalias !215
  %147 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %144, i64 0, i32 1, i64 0
  %148 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 0
  store i32 %146, i32* %148, align 8, !alias.scope !215
  %149 = icmp sgt i32 %146, 5
  br i1 %149, label %150, label %157

150:                                              ; preds = %142
  %151 = sext i32 %146 to i64
  %152 = shl nsw i64 %151, 2
  %153 = tail call i8* @_Znam(i64 %152) #18, !noalias !215
  %154 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 1, i32 0
  %155 = bitcast i32** %154 to i8**
  store i8* %153, i8** %155, align 8, !alias.scope !215
  %156 = bitcast i8* %153 to i32*
  br label %162

157:                                              ; preds = %142
  %158 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 1
  %159 = bitcast %union.anon.54* %158 to i32*
  %160 = sext i32 %146 to i64
  %161 = shl nsw i64 %160, 2
  br label %162

162:                                              ; preds = %157, %150
  %163 = phi i64 [ %152, %150 ], [ %161, %157 ]
  %164 = phi i32* [ %156, %150 ], [ %159, %157 ]
  %165 = bitcast i32* %164 to i8*
  %166 = bitcast i32* %147 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %165, i8* align 4 %166, i64 %163, i1 false) #19
  %167 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 1
  %168 = bitcast %union.TfLitePtrUnion* %167 to i16**
  %169 = load i16*, i16** %168, align 8
  br label %170

170:                                              ; preds = %140, %162
  %171 = phi i16* [ %169, %162 ], [ null, %140 ]
  %172 = icmp eq %struct.TfLiteTensor* %8, null
  br i1 %172, label %177, label %173

173:                                              ; preds = %170
  %174 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %8, i64 0, i32 1
  %175 = bitcast %union.TfLitePtrUnion* %174 to i8**
  %176 = load i8*, i8** %175, align 8
  br label %177

177:                                              ; preds = %170, %173
  %178 = phi i8* [ %176, %173 ], [ null, %170 ]
  %179 = tail call %"class.tflite::CpuBackendContext"* @_ZN6tflite17CpuBackendContext14GetFromContextEP13TfLiteContext(%struct.TfLiteContext* %0) #19
  call void @_ZN6tflite13optimized_ops22ShuffledFullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKiS6_PsPhPNS_17CpuBackendContextE(%"struct.tflite::FullyConnectedParams"* nonnull dereferenceable(40) %10, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %11, i8* %70, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %12, i8* %104, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %13, i32* %137, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %14, i16* %171, i8* %178, %"class.tflite::CpuBackendContext"* %179)
  %180 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 0
  %181 = load i32, i32* %180, align 8
  %182 = icmp sgt i32 %181, 5
  br i1 %182, label %183, label %189

183:                                              ; preds = %177
  %184 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 1, i32 0
  %185 = load i32*, i32** %184, align 8
  %186 = icmp eq i32* %185, null
  br i1 %186, label %189, label %187

187:                                              ; preds = %183
  %188 = bitcast i32* %185 to i8*
  call void @_ZdaPv(i8* %188) #18
  br label %189

189:                                              ; preds = %177, %183, %187
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %138) #19
  %190 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 0
  %191 = load i32, i32* %190, align 8
  %192 = icmp sgt i32 %191, 5
  br i1 %192, label %193, label %199

193:                                              ; preds = %189
  %194 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 1, i32 0
  %195 = load i32*, i32** %194, align 8
  %196 = icmp eq i32* %195, null
  br i1 %196, label %199, label %197

197:                                              ; preds = %193
  %198 = bitcast i32* %195 to i8*
  call void @_ZdaPv(i8* %198) #18
  br label %199

199:                                              ; preds = %189, %193, %197
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %105) #19
  %200 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 0
  %201 = load i32, i32* %200, align 8
  %202 = icmp sgt i32 %201, 5
  br i1 %202, label %203, label %209

203:                                              ; preds = %199
  %204 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 1, i32 0
  %205 = load i32*, i32** %204, align 8
  %206 = icmp eq i32* %205, null
  br i1 %206, label %209, label %207

207:                                              ; preds = %203
  %208 = bitcast i32* %205 to i8*
  call void @_ZdaPv(i8* %208) #18
  br label %209

209:                                              ; preds = %199, %203, %207
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %71) #19
  %210 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 0
  %211 = load i32, i32* %210, align 8
  %212 = icmp sgt i32 %211, 5
  br i1 %212, label %213, label %219

213:                                              ; preds = %209
  %214 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 1, i32 0
  %215 = load i32*, i32** %214, align 8
  %216 = icmp eq i32* %215, null
  br i1 %216, label %219, label %217

217:                                              ; preds = %213
  %218 = bitcast i32* %215 to i8*
  call void @_ZdaPv(i8* %218) #18
  br label %219

219:                                              ; preds = %209, %213, %217
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %37) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %22) #19
  br label %220

220:                                              ; preds = %219, %18
  %221 = phi i32 [ 1, %18 ], [ 0, %219 ]
  ret i32 %221
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i32 @_ZN6tflite3ops7builtin15fully_connected13EvalQuantizedILNS2_10KernelTypeE1EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_(%struct.TfLiteContext*, %struct.TfLiteNode*, %struct.TfLiteFullyConnectedParams*, %"struct.tflite::ops::builtin::fully_connected::OpData"*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*) local_unnamed_addr #1 comdat {
  %9 = alloca %"struct.tflite::cpu_backend_gemm::MatrixParams.429", align 4
  %10 = alloca %"struct.tflite::cpu_backend_gemm::MatrixParams.429", align 4
  %11 = alloca %"struct.tflite::cpu_backend_gemm::MatrixParams.429", align 4
  %12 = alloca %"struct.tflite::cpu_backend_gemm::GemmParams.431", align 8
  %13 = alloca %"class.tflite::RuntimeShape", align 8
  %14 = alloca %"class.tflite::RuntimeShape", align 8
  %15 = alloca %"class.tflite::RuntimeShape", align 8
  %16 = alloca %"class.tflite::RuntimeShape", align 8
  %17 = alloca %"class.tflite::RuntimeShape", align 8
  %18 = alloca %"class.tflite::RuntimeShape", align 8
  %19 = alloca %"class.tflite::RuntimeShape", align 8
  %20 = alloca %"class.tflite::RuntimeShape", align 8
  %21 = alloca %"struct.tflite::FullyConnectedParams", align 4
  %22 = alloca %"class.tflite::RuntimeShape", align 8
  %23 = alloca %"class.tflite::RuntimeShape", align 8
  %24 = alloca %"class.tflite::RuntimeShape", align 8
  %25 = alloca %"class.tflite::RuntimeShape", align 8
  %26 = alloca %"class.tflite::RuntimeShape", align 8
  %27 = alloca %"class.tflite::RuntimeShape", align 8
  %28 = alloca %"class.tflite::RuntimeShape", align 8
  %29 = alloca %"class.tflite::RuntimeShape", align 8
  %30 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 0
  %31 = load i32, i32* %30, align 8
  %32 = icmp eq i32 %31, 1
  br i1 %32, label %33, label %87

33:                                               ; preds = %8
  %34 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 3
  %35 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %34, align 8
  %36 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %35, i64 0, i32 1, i64 0
  %37 = load i32, i32* %36, align 4
  %38 = icmp slt i32 %37, 0
  br i1 %38, label %44, label %39

39:                                               ; preds = %33
  %40 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %41 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %40, align 8
  %42 = sext i32 %37 to i64
  %43 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %41, i64 %42
  br label %44

44:                                               ; preds = %33, %39
  %45 = phi %struct.TfLiteTensor* [ %43, %39 ], [ null, %33 ]
  %46 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %35, i64 0, i32 1, i64 1
  %47 = load i32, i32* %46, align 4
  %48 = icmp slt i32 %47, 0
  br i1 %48, label %54, label %49

49:                                               ; preds = %44
  %50 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %51 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %50, align 8
  %52 = sext i32 %47 to i64
  %53 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %51, i64 %52
  br label %54

54:                                               ; preds = %44, %49
  %55 = phi %struct.TfLiteTensor* [ %53, %49 ], [ null, %44 ]
  %56 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %35, i64 0, i32 1, i64 2
  %57 = load i32, i32* %56, align 4
  %58 = icmp slt i32 %57, 0
  br i1 %58, label %64, label %59

59:                                               ; preds = %54
  %60 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %61 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %60, align 8
  %62 = sext i32 %57 to i64
  %63 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %61, i64 %62
  br label %64

64:                                               ; preds = %54, %59
  %65 = phi %struct.TfLiteTensor* [ %63, %59 ], [ null, %54 ]
  %66 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %35, i64 0, i32 1, i64 3
  %67 = load i32, i32* %66, align 4
  %68 = icmp slt i32 %67, 0
  br i1 %68, label %74, label %69

69:                                               ; preds = %64
  %70 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %71 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %70, align 8
  %72 = sext i32 %67 to i64
  %73 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %71, i64 %72
  br label %74

74:                                               ; preds = %64, %69
  %75 = phi %struct.TfLiteTensor* [ %73, %69 ], [ null, %64 ]
  %76 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %35, i64 0, i32 1, i64 4
  %77 = load i32, i32* %76, align 4
  %78 = icmp slt i32 %77, 0
  br i1 %78, label %84, label %79

79:                                               ; preds = %74
  %80 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %81 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %80, align 8
  %82 = sext i32 %77 to i64
  %83 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %81, i64 %82
  br label %84

84:                                               ; preds = %74, %79
  %85 = phi %struct.TfLiteTensor* [ %83, %79 ], [ null, %74 ]
  %86 = tail call i32 @_ZN6tflite3ops7builtin15fully_connected10EvalHybridEP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_SE_SE_SE_SE_SE_(%struct.TfLiteContext* %0, %struct.TfLiteNode* undef, %struct.TfLiteFullyConnectedParams* %2, %"struct.tflite::ops::builtin::fully_connected::OpData"* %3, %struct.TfLiteTensor* %4, %struct.TfLiteTensor* %5, %struct.TfLiteTensor* %6, %struct.TfLiteTensor* %45, %struct.TfLiteTensor* %55, %struct.TfLiteTensor* %65, %struct.TfLiteTensor* %85, %struct.TfLiteTensor* %75, %struct.TfLiteTensor* %7)
  ret i32 0

87:                                               ; preds = %8
  %88 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 3, i32 1
  %89 = load i32, i32* %88, align 4
  %90 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 3, i32 1
  %91 = load i32, i32* %90, align 4
  %92 = sub nsw i32 0, %91
  %93 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 3, i32 1
  %94 = load i32, i32* %93, align 4
  %95 = sub nsw i32 0, %94
  %96 = bitcast %"struct.tflite::FullyConnectedParams"* %21 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %96) #19
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 4 %96, i8* align 4 bitcast ({ i32, i32, i32, i32, i32, i32, i32, float, float, i8, i8, i8, [1 x i8] }* @__const._ZN6tflite3ops7builtin15fully_connected13EvalQuantizedILNS2_10KernelTypeE2EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_.op_params to i8*), i64 40, i1 false)
  %97 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %21, i64 0, i32 0
  store i32 %95, i32* %97, align 4
  %98 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %21, i64 0, i32 1
  store i32 %92, i32* %98, align 4
  %99 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %21, i64 0, i32 2
  store i32 %89, i32* %99, align 4
  %100 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %21, i64 0, i32 3
  %101 = bitcast %"struct.tflite::ops::builtin::fully_connected::OpData"* %3 to <4 x i32>*
  %102 = load <4 x i32>, <4 x i32>* %101, align 4
  %103 = bitcast i32* %100 to <4 x i32>*
  store <4 x i32> %102, <4 x i32>* %103, align 4
  %104 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 4
  %105 = load i32, i32* %104, align 8
  %106 = icmp eq i32 %105, 1
  %107 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %21, i64 0, i32 9
  %108 = zext i1 %106 to i8
  store i8 %108, i8* %107, align 4
  %109 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 4
  %110 = load i32, i32* %109, align 8
  %111 = icmp eq i32 %110, 1
  %112 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %21, i64 0, i32 10
  %113 = zext i1 %111 to i8
  store i8 %113, i8* %112, align 1
  %114 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 0
  %115 = load i32, i32* %114, align 8
  switch i32 %115, label %1057 [
    i32 3, label %116
    i32 9, label %292
    i32 7, label %573
  ]

116:                                              ; preds = %87
  %117 = bitcast %"class.tflite::RuntimeShape"* %22 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %117) #19
  %118 = icmp eq %struct.TfLiteTensor* %4, null
  br i1 %118, label %119, label %121

119:                                              ; preds = %116
  %120 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %22, i64 0, i32 0
  store i32 0, i32* %120, align 8, !alias.scope !218
  br label %149

121:                                              ; preds = %116
  %122 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 2
  %123 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %122, align 8, !noalias !218
  %124 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %123, i64 0, i32 0
  %125 = load i32, i32* %124, align 4, !noalias !218
  %126 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %123, i64 0, i32 1, i64 0
  %127 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %22, i64 0, i32 0
  store i32 %125, i32* %127, align 8, !alias.scope !218
  %128 = icmp sgt i32 %125, 5
  br i1 %128, label %129, label %136

129:                                              ; preds = %121
  %130 = sext i32 %125 to i64
  %131 = shl nsw i64 %130, 2
  %132 = tail call i8* @_Znam(i64 %131) #18, !noalias !218
  %133 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %22, i64 0, i32 1, i32 0
  %134 = bitcast i32** %133 to i8**
  store i8* %132, i8** %134, align 8, !alias.scope !218
  %135 = bitcast i8* %132 to i32*
  br label %141

136:                                              ; preds = %121
  %137 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %22, i64 0, i32 1
  %138 = bitcast %union.anon.54* %137 to i32*
  %139 = sext i32 %125 to i64
  %140 = shl nsw i64 %139, 2
  br label %141

141:                                              ; preds = %136, %129
  %142 = phi i64 [ %131, %129 ], [ %140, %136 ]
  %143 = phi i32* [ %135, %129 ], [ %138, %136 ]
  %144 = bitcast i32* %143 to i8*
  %145 = bitcast i32* %126 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %144, i8* align 4 %145, i64 %142, i1 false) #19
  %146 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 1
  %147 = bitcast %union.TfLitePtrUnion* %146 to i8**
  %148 = load i8*, i8** %147, align 8
  br label %149

149:                                              ; preds = %119, %141
  %150 = phi i8* [ %148, %141 ], [ null, %119 ]
  %151 = bitcast %"class.tflite::RuntimeShape"* %23 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %151) #19
  %152 = icmp eq %struct.TfLiteTensor* %5, null
  br i1 %152, label %153, label %155

153:                                              ; preds = %149
  %154 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %23, i64 0, i32 0
  store i32 0, i32* %154, align 8, !alias.scope !221
  br label %183

155:                                              ; preds = %149
  %156 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 2
  %157 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %156, align 8, !noalias !221
  %158 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %157, i64 0, i32 0
  %159 = load i32, i32* %158, align 4, !noalias !221
  %160 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %157, i64 0, i32 1, i64 0
  %161 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %23, i64 0, i32 0
  store i32 %159, i32* %161, align 8, !alias.scope !221
  %162 = icmp sgt i32 %159, 5
  br i1 %162, label %163, label %170

163:                                              ; preds = %155
  %164 = sext i32 %159 to i64
  %165 = shl nsw i64 %164, 2
  %166 = tail call i8* @_Znam(i64 %165) #18, !noalias !221
  %167 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %23, i64 0, i32 1, i32 0
  %168 = bitcast i32** %167 to i8**
  store i8* %166, i8** %168, align 8, !alias.scope !221
  %169 = bitcast i8* %166 to i32*
  br label %175

170:                                              ; preds = %155
  %171 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %23, i64 0, i32 1
  %172 = bitcast %union.anon.54* %171 to i32*
  %173 = sext i32 %159 to i64
  %174 = shl nsw i64 %173, 2
  br label %175

175:                                              ; preds = %170, %163
  %176 = phi i64 [ %165, %163 ], [ %174, %170 ]
  %177 = phi i32* [ %169, %163 ], [ %172, %170 ]
  %178 = bitcast i32* %177 to i8*
  %179 = bitcast i32* %160 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %178, i8* align 4 %179, i64 %176, i1 false) #19
  %180 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 1
  %181 = bitcast %union.TfLitePtrUnion* %180 to i8**
  %182 = load i8*, i8** %181, align 8
  br label %183

183:                                              ; preds = %153, %175
  %184 = phi i8* [ %182, %175 ], [ null, %153 ]
  %185 = bitcast %"class.tflite::RuntimeShape"* %24 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %185) #19
  %186 = icmp eq %struct.TfLiteTensor* %6, null
  br i1 %186, label %187, label %189

187:                                              ; preds = %183
  %188 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %24, i64 0, i32 0
  store i32 0, i32* %188, align 8, !alias.scope !224
  br label %216

189:                                              ; preds = %183
  %190 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 2
  %191 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %190, align 8, !noalias !224
  %192 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %191, i64 0, i32 0
  %193 = load i32, i32* %192, align 4, !noalias !224
  %194 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %191, i64 0, i32 1, i64 0
  %195 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %24, i64 0, i32 0
  store i32 %193, i32* %195, align 8, !alias.scope !224
  %196 = icmp sgt i32 %193, 5
  br i1 %196, label %197, label %204

197:                                              ; preds = %189
  %198 = sext i32 %193 to i64
  %199 = shl nsw i64 %198, 2
  %200 = tail call i8* @_Znam(i64 %199) #18, !noalias !224
  %201 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %24, i64 0, i32 1, i32 0
  %202 = bitcast i32** %201 to i8**
  store i8* %200, i8** %202, align 8, !alias.scope !224
  %203 = bitcast i8* %200 to i32*
  br label %209

204:                                              ; preds = %189
  %205 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %24, i64 0, i32 1
  %206 = bitcast %union.anon.54* %205 to i32*
  %207 = sext i32 %193 to i64
  %208 = shl nsw i64 %207, 2
  br label %209

209:                                              ; preds = %204, %197
  %210 = phi i64 [ %199, %197 ], [ %208, %204 ]
  %211 = phi i32* [ %203, %197 ], [ %206, %204 ]
  %212 = bitcast i32* %211 to i8*
  %213 = bitcast i32* %194 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %212, i8* align 4 %213, i64 %210, i1 false) #19
  %214 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 1, i32 0
  %215 = load i32*, i32** %214, align 8
  br label %216

216:                                              ; preds = %187, %209
  %217 = phi i32* [ %215, %209 ], [ null, %187 ]
  %218 = bitcast %"class.tflite::RuntimeShape"* %25 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %218) #19
  %219 = icmp eq %struct.TfLiteTensor* %7, null
  br i1 %219, label %220, label %222

220:                                              ; preds = %216
  %221 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %25, i64 0, i32 0
  store i32 0, i32* %221, align 8, !alias.scope !227
  br label %250

222:                                              ; preds = %216
  %223 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 2
  %224 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %223, align 8, !noalias !227
  %225 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %224, i64 0, i32 0
  %226 = load i32, i32* %225, align 4, !noalias !227
  %227 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %224, i64 0, i32 1, i64 0
  %228 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %25, i64 0, i32 0
  store i32 %226, i32* %228, align 8, !alias.scope !227
  %229 = icmp sgt i32 %226, 5
  br i1 %229, label %230, label %237

230:                                              ; preds = %222
  %231 = sext i32 %226 to i64
  %232 = shl nsw i64 %231, 2
  %233 = tail call i8* @_Znam(i64 %232) #18, !noalias !227
  %234 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %25, i64 0, i32 1, i32 0
  %235 = bitcast i32** %234 to i8**
  store i8* %233, i8** %235, align 8, !alias.scope !227
  %236 = bitcast i8* %233 to i32*
  br label %242

237:                                              ; preds = %222
  %238 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %25, i64 0, i32 1
  %239 = bitcast %union.anon.54* %238 to i32*
  %240 = sext i32 %226 to i64
  %241 = shl nsw i64 %240, 2
  br label %242

242:                                              ; preds = %237, %230
  %243 = phi i64 [ %232, %230 ], [ %241, %237 ]
  %244 = phi i32* [ %236, %230 ], [ %239, %237 ]
  %245 = bitcast i32* %244 to i8*
  %246 = bitcast i32* %227 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %245, i8* align 4 %246, i64 %243, i1 false) #19
  %247 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 1
  %248 = bitcast %union.TfLitePtrUnion* %247 to i8**
  %249 = load i8*, i8** %248, align 8
  br label %250

250:                                              ; preds = %220, %242
  %251 = phi i8* [ %249, %242 ], [ null, %220 ]
  %252 = tail call %"class.tflite::CpuBackendContext"* @_ZN6tflite17CpuBackendContext14GetFromContextEP13TfLiteContext(%struct.TfLiteContext* %0) #19
  call void @_ZN6tflite13optimized_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKiS6_PhPNS_17CpuBackendContextE(%"struct.tflite::FullyConnectedParams"* nonnull dereferenceable(40) %21, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %22, i8* %150, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %23, i8* %184, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %24, i32* %217, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %25, i8* %251, %"class.tflite::CpuBackendContext"* %252)
  %253 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %25, i64 0, i32 0
  %254 = load i32, i32* %253, align 8
  %255 = icmp sgt i32 %254, 5
  br i1 %255, label %256, label %262

256:                                              ; preds = %250
  %257 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %25, i64 0, i32 1, i32 0
  %258 = load i32*, i32** %257, align 8
  %259 = icmp eq i32* %258, null
  br i1 %259, label %262, label %260

260:                                              ; preds = %256
  %261 = bitcast i32* %258 to i8*
  call void @_ZdaPv(i8* %261) #18
  br label %262

262:                                              ; preds = %250, %256, %260
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %218) #19
  %263 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %24, i64 0, i32 0
  %264 = load i32, i32* %263, align 8
  %265 = icmp sgt i32 %264, 5
  br i1 %265, label %266, label %272

266:                                              ; preds = %262
  %267 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %24, i64 0, i32 1, i32 0
  %268 = load i32*, i32** %267, align 8
  %269 = icmp eq i32* %268, null
  br i1 %269, label %272, label %270

270:                                              ; preds = %266
  %271 = bitcast i32* %268 to i8*
  call void @_ZdaPv(i8* %271) #18
  br label %272

272:                                              ; preds = %262, %266, %270
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %185) #19
  %273 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %23, i64 0, i32 0
  %274 = load i32, i32* %273, align 8
  %275 = icmp sgt i32 %274, 5
  br i1 %275, label %276, label %282

276:                                              ; preds = %272
  %277 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %23, i64 0, i32 1, i32 0
  %278 = load i32*, i32** %277, align 8
  %279 = icmp eq i32* %278, null
  br i1 %279, label %282, label %280

280:                                              ; preds = %276
  %281 = bitcast i32* %278 to i8*
  call void @_ZdaPv(i8* %281) #18
  br label %282

282:                                              ; preds = %272, %276, %280
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %151) #19
  %283 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %22, i64 0, i32 0
  %284 = load i32, i32* %283, align 8
  %285 = icmp sgt i32 %284, 5
  br i1 %285, label %286, label %1060

286:                                              ; preds = %282
  %287 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %22, i64 0, i32 1, i32 0
  %288 = load i32*, i32** %287, align 8
  %289 = icmp eq i32* %288, null
  br i1 %289, label %1060, label %290

290:                                              ; preds = %286
  %291 = bitcast i32* %288 to i8*
  call void @_ZdaPv(i8* %291) #18
  br label %1060

292:                                              ; preds = %87
  %293 = getelementptr inbounds %"struct.tflite::ops::builtin::fully_connected::OpData", %"struct.tflite::ops::builtin::fully_connected::OpData"* %3, i64 0, i32 0
  %294 = getelementptr inbounds %"struct.tflite::ops::builtin::fully_connected::OpData", %"struct.tflite::ops::builtin::fully_connected::OpData"* %3, i64 0, i32 3
  %295 = getelementptr inbounds %"struct.tflite::ops::builtin::fully_connected::OpData", %"struct.tflite::ops::builtin::fully_connected::OpData"* %3, i64 0, i32 2
  %296 = getelementptr inbounds %"struct.tflite::ops::builtin::fully_connected::OpData", %"struct.tflite::ops::builtin::fully_connected::OpData"* %3, i64 0, i32 1
  %297 = tail call %"class.tflite::CpuBackendContext"* @_ZN6tflite17CpuBackendContext14GetFromContextEP13TfLiteContext(%struct.TfLiteContext* %0) #19
  %298 = load i32, i32* %93, align 4
  %299 = load i32, i32* %90, align 4
  %300 = load i32, i32* %88, align 4
  %301 = load i32, i32* %293, align 4
  %302 = load i32, i32* %296, align 4
  %303 = load i32, i32* %295, align 4
  %304 = load i32, i32* %294, align 4
  %305 = bitcast %"class.tflite::RuntimeShape"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %305) #19
  %306 = icmp eq %struct.TfLiteTensor* %4, null
  br i1 %306, label %307, label %309

307:                                              ; preds = %292
  %308 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 0
  store i32 0, i32* %308, align 8, !alias.scope !230
  br label %337

309:                                              ; preds = %292
  %310 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 2
  %311 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %310, align 8, !noalias !230
  %312 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %311, i64 0, i32 0
  %313 = load i32, i32* %312, align 4, !noalias !230
  %314 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %311, i64 0, i32 1, i64 0
  %315 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 0
  store i32 %313, i32* %315, align 8, !alias.scope !230
  %316 = icmp sgt i32 %313, 5
  br i1 %316, label %317, label %324

317:                                              ; preds = %309
  %318 = sext i32 %313 to i64
  %319 = shl nsw i64 %318, 2
  %320 = tail call i8* @_Znam(i64 %319) #18, !noalias !230
  %321 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 1, i32 0
  %322 = bitcast i32** %321 to i8**
  store i8* %320, i8** %322, align 8, !alias.scope !230
  %323 = bitcast i8* %320 to i32*
  br label %329

324:                                              ; preds = %309
  %325 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 1
  %326 = bitcast %union.anon.54* %325 to i32*
  %327 = sext i32 %313 to i64
  %328 = shl nsw i64 %327, 2
  br label %329

329:                                              ; preds = %324, %317
  %330 = phi i64 [ %319, %317 ], [ %328, %324 ]
  %331 = phi i32* [ %323, %317 ], [ %326, %324 ]
  %332 = bitcast i32* %331 to i8*
  %333 = bitcast i32* %314 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %332, i8* align 4 %333, i64 %330, i1 false) #19
  %334 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 1
  %335 = bitcast %union.TfLitePtrUnion* %334 to i8**
  %336 = load i8*, i8** %335, align 8
  br label %337

337:                                              ; preds = %329, %307
  %338 = phi i32 [ %313, %329 ], [ 0, %307 ]
  %339 = phi i8* [ %336, %329 ], [ null, %307 ]
  %340 = bitcast %"class.tflite::RuntimeShape"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %340) #19
  %341 = icmp eq %struct.TfLiteTensor* %5, null
  br i1 %341, label %342, label %344

342:                                              ; preds = %337
  %343 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 0
  store i32 0, i32* %343, align 8, !alias.scope !233
  br label %372

344:                                              ; preds = %337
  %345 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 2
  %346 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %345, align 8, !noalias !233
  %347 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %346, i64 0, i32 0
  %348 = load i32, i32* %347, align 4, !noalias !233
  %349 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %346, i64 0, i32 1, i64 0
  %350 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 0
  store i32 %348, i32* %350, align 8, !alias.scope !233
  %351 = icmp sgt i32 %348, 5
  br i1 %351, label %352, label %359

352:                                              ; preds = %344
  %353 = sext i32 %348 to i64
  %354 = shl nsw i64 %353, 2
  %355 = tail call i8* @_Znam(i64 %354) #18, !noalias !233
  %356 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 1, i32 0
  %357 = bitcast i32** %356 to i8**
  store i8* %355, i8** %357, align 8, !alias.scope !233
  %358 = bitcast i8* %355 to i32*
  br label %364

359:                                              ; preds = %344
  %360 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 1
  %361 = bitcast %union.anon.54* %360 to i32*
  %362 = sext i32 %348 to i64
  %363 = shl nsw i64 %362, 2
  br label %364

364:                                              ; preds = %359, %352
  %365 = phi i64 [ %354, %352 ], [ %363, %359 ]
  %366 = phi i32* [ %358, %352 ], [ %361, %359 ]
  %367 = bitcast i32* %366 to i8*
  %368 = bitcast i32* %349 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %367, i8* align 4 %368, i64 %365, i1 false) #19
  %369 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 1
  %370 = bitcast %union.TfLitePtrUnion* %369 to i8**
  %371 = load i8*, i8** %370, align 8
  br label %372

372:                                              ; preds = %364, %342
  %373 = phi i32 [ %348, %364 ], [ 0, %342 ]
  %374 = phi i8* [ %371, %364 ], [ null, %342 ]
  %375 = bitcast %"class.tflite::RuntimeShape"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %375) #19
  %376 = icmp eq %struct.TfLiteTensor* %6, null
  br i1 %376, label %377, label %379

377:                                              ; preds = %372
  %378 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %15, i64 0, i32 0
  store i32 0, i32* %378, align 8, !alias.scope !236
  br label %406

379:                                              ; preds = %372
  %380 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 2
  %381 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %380, align 8, !noalias !236
  %382 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %381, i64 0, i32 0
  %383 = load i32, i32* %382, align 4, !noalias !236
  %384 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %381, i64 0, i32 1, i64 0
  %385 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %15, i64 0, i32 0
  store i32 %383, i32* %385, align 8, !alias.scope !236
  %386 = icmp sgt i32 %383, 5
  br i1 %386, label %387, label %394

387:                                              ; preds = %379
  %388 = sext i32 %383 to i64
  %389 = shl nsw i64 %388, 2
  %390 = tail call i8* @_Znam(i64 %389) #18, !noalias !236
  %391 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %15, i64 0, i32 1, i32 0
  %392 = bitcast i32** %391 to i8**
  store i8* %390, i8** %392, align 8, !alias.scope !236
  %393 = bitcast i8* %390 to i32*
  br label %399

394:                                              ; preds = %379
  %395 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %15, i64 0, i32 1
  %396 = bitcast %union.anon.54* %395 to i32*
  %397 = sext i32 %383 to i64
  %398 = shl nsw i64 %397, 2
  br label %399

399:                                              ; preds = %394, %387
  %400 = phi i64 [ %389, %387 ], [ %398, %394 ]
  %401 = phi i32* [ %393, %387 ], [ %396, %394 ]
  %402 = bitcast i32* %401 to i8*
  %403 = bitcast i32* %384 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %402, i8* align 4 %403, i64 %400, i1 false) #19
  %404 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 1, i32 0
  %405 = load i32*, i32** %404, align 8
  br label %406

406:                                              ; preds = %399, %377
  %407 = phi i32 [ %383, %399 ], [ 0, %377 ]
  %408 = phi i32* [ %405, %399 ], [ null, %377 ]
  %409 = bitcast %"class.tflite::RuntimeShape"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %409) #19
  %410 = icmp eq %struct.TfLiteTensor* %7, null
  br i1 %410, label %411, label %413

411:                                              ; preds = %406
  %412 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %16, i64 0, i32 0
  store i32 0, i32* %412, align 8, !alias.scope !239
  br label %489

413:                                              ; preds = %406
  %414 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 2
  %415 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %414, align 8, !noalias !239
  %416 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %415, i64 0, i32 0
  %417 = load i32, i32* %416, align 4, !noalias !239
  %418 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %415, i64 0, i32 1, i64 0
  %419 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %16, i64 0, i32 0
  store i32 %417, i32* %419, align 8, !alias.scope !239
  %420 = icmp sgt i32 %417, 5
  br i1 %420, label %421, label %428

421:                                              ; preds = %413
  %422 = sext i32 %417 to i64
  %423 = shl nsw i64 %422, 2
  %424 = tail call i8* @_Znam(i64 %423) #18, !noalias !239
  %425 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %16, i64 0, i32 1, i32 0
  %426 = bitcast i32** %425 to i8**
  store i8* %424, i8** %426, align 8, !alias.scope !239
  %427 = bitcast i8* %424 to i32*
  br label %433

428:                                              ; preds = %413
  %429 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %16, i64 0, i32 1
  %430 = bitcast %union.anon.54* %429 to i32*
  %431 = sext i32 %417 to i64
  %432 = shl nsw i64 %431, 2
  br label %433

433:                                              ; preds = %428, %421
  %434 = phi i64 [ %423, %421 ], [ %432, %428 ]
  %435 = phi i32* [ %427, %421 ], [ %430, %428 ]
  %436 = bitcast i32* %435 to i8*
  %437 = bitcast i32* %418 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %436, i8* align 4 %437, i64 %434, i1 false) #19
  %438 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 1
  %439 = bitcast %union.TfLitePtrUnion* %438 to i8**
  %440 = load i8*, i8** %439, align 8
  %441 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %16, i64 0, i32 1, i32 0
  %442 = load i32*, i32** %441, align 8
  %443 = bitcast i32* %442 to i8*
  %444 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %16, i64 0, i32 1
  %445 = bitcast %union.anon.54* %444 to i32*
  %446 = select i1 %420, i32* %442, i32* %445
  %447 = icmp sgt i32 %417, 0
  br i1 %447, label %448, label %489

448:                                              ; preds = %433
  %449 = add nsw i32 %417, -1
  %450 = zext i32 %449 to i64
  %451 = zext i32 %417 to i64
  %452 = add nsw i64 %451, -1
  %453 = and i64 %451, 3
  %454 = icmp ult i64 %452, 3
  br i1 %454, label %470, label %455

455:                                              ; preds = %448
  %456 = sub nsw i64 %451, %453
  br label %457

457:                                              ; preds = %1083, %455
  %458 = phi i64 [ 0, %455 ], [ %1086, %1083 ]
  %459 = phi i32 [ 1, %455 ], [ %1085, %1083 ]
  %460 = phi i64 [ %456, %455 ], [ %1087, %1083 ]
  %461 = icmp eq i64 %458, %450
  br i1 %461, label %465, label %462

462:                                              ; preds = %457
  %463 = getelementptr inbounds i32, i32* %446, i64 %458
  %464 = load i32, i32* %463, align 4
  br label %465

465:                                              ; preds = %462, %457
  %466 = phi i32 [ %464, %462 ], [ 1, %457 ]
  %467 = mul nsw i32 %466, %459
  %468 = or i64 %458, 1
  %469 = icmp eq i64 %468, %450
  br i1 %469, label %1067, label %1064

470:                                              ; preds = %1083, %448
  %471 = phi i32 [ undef, %448 ], [ %1085, %1083 ]
  %472 = phi i64 [ 0, %448 ], [ %1086, %1083 ]
  %473 = phi i32 [ 1, %448 ], [ %1085, %1083 ]
  %474 = icmp eq i64 %453, 0
  br i1 %474, label %489, label %475

475:                                              ; preds = %470, %483
  %476 = phi i64 [ %486, %483 ], [ %472, %470 ]
  %477 = phi i32 [ %485, %483 ], [ %473, %470 ]
  %478 = phi i64 [ %487, %483 ], [ %453, %470 ]
  %479 = icmp eq i64 %476, %450
  br i1 %479, label %483, label %480

480:                                              ; preds = %475
  %481 = getelementptr inbounds i32, i32* %446, i64 %476
  %482 = load i32, i32* %481, align 4
  br label %483

483:                                              ; preds = %480, %475
  %484 = phi i32 [ %482, %480 ], [ 1, %475 ]
  %485 = mul nsw i32 %484, %477
  %486 = add nuw nsw i64 %476, 1
  %487 = add i64 %478, -1
  %488 = icmp eq i64 %487, 0
  br i1 %488, label %489, label %475, !llvm.loop !242

489:                                              ; preds = %470, %483, %433, %411
  %490 = phi i1 [ %420, %433 ], [ false, %411 ], [ %420, %483 ], [ %420, %470 ]
  %491 = phi i8* [ %440, %433 ], [ null, %411 ], [ %440, %483 ], [ %440, %470 ]
  %492 = phi i32* [ %442, %433 ], [ undef, %411 ], [ %442, %483 ], [ %442, %470 ]
  %493 = phi i8* [ %443, %433 ], [ undef, %411 ], [ %443, %483 ], [ %443, %470 ]
  %494 = phi i32 [ 1, %433 ], [ 1, %411 ], [ %471, %470 ], [ %485, %483 ]
  %495 = add nsw i32 %373, -2
  %496 = icmp sgt i32 %373, 5
  %497 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 1
  br i1 %496, label %498, label %506

498:                                              ; preds = %489
  %499 = getelementptr inbounds %union.anon.54, %union.anon.54* %497, i64 0, i32 0
  %500 = load i32*, i32** %499, align 8
  %501 = sext i32 %495 to i64
  %502 = getelementptr inbounds i32, i32* %500, i64 %501
  %503 = add nsw i32 %373, -1
  %504 = sext i32 %503 to i64
  %505 = getelementptr inbounds i32, i32* %500, i64 %504
  br label %513

506:                                              ; preds = %489
  %507 = bitcast %union.anon.54* %497 to [5 x i32]*
  %508 = sext i32 %495 to i64
  %509 = getelementptr inbounds [5 x i32], [5 x i32]* %507, i64 0, i64 %508
  %510 = add nsw i32 %373, -1
  %511 = sext i32 %510 to i64
  %512 = getelementptr inbounds [5 x i32], [5 x i32]* %507, i64 0, i64 %511
  br label %513

513:                                              ; preds = %506, %498
  %514 = phi i32* [ %505, %498 ], [ %512, %506 ]
  %515 = phi i32* [ %502, %498 ], [ %509, %506 ]
  %516 = load i32, i32* %515, align 4
  %517 = load i32, i32* %514, align 4
  %518 = bitcast %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %518) #19
  %519 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %9, i64 0, i32 0
  %520 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %9, i64 0, i32 1
  %521 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %9, i64 0, i32 2
  %522 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %9, i64 0, i32 3
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %518, i8 -86, i64 16, i1 false) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %518, i8 0, i64 14, i1 false) #19
  store i32 %516, i32* %520, align 4
  store i32 %517, i32* %521, align 4
  store i32 1, i32* %519, align 4
  %523 = trunc i32 %299 to i8
  store i8 %523, i8* %522, align 4
  %524 = bitcast %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %524) #19
  %525 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %10, i64 0, i32 0
  %526 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %10, i64 0, i32 1
  %527 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %10, i64 0, i32 2
  %528 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %10, i64 0, i32 3
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %524, i8 -86, i64 16, i1 false) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %524, i8 0, i64 14, i1 false) #19
  store i32 %517, i32* %526, align 4
  store i32 %494, i32* %527, align 4
  store i32 0, i32* %525, align 4
  %529 = trunc i32 %298 to i8
  store i8 %529, i8* %528, align 4
  %530 = bitcast %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %530) #19
  %531 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %11, i64 0, i32 0
  %532 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %11, i64 0, i32 1
  %533 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %11, i64 0, i32 2
  %534 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %11, i64 0, i32 3
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %530, i8 -86, i64 16, i1 false) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %530, i8 0, i64 14, i1 false) #19
  store i32 %516, i32* %532, align 4
  store i32 %494, i32* %533, align 4
  store i32 0, i32* %531, align 4
  %535 = trunc i32 %300 to i8
  store i8 %535, i8* %534, align 4
  %536 = bitcast %"struct.tflite::cpu_backend_gemm::GemmParams.431"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %536) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %536, i8 -86, i64 40, i1 false) #19
  %537 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.431", %"struct.tflite::cpu_backend_gemm::GemmParams.431"* %12, i64 0, i32 5
  %538 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.431", %"struct.tflite::cpu_backend_gemm::GemmParams.431"* %12, i64 0, i32 2
  %539 = bitcast i32** %538 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %539, i8 0, i64 16, i1 false) #19
  %540 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.431", %"struct.tflite::cpu_backend_gemm::GemmParams.431"* %12, i64 0, i32 6
  %541 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.431", %"struct.tflite::cpu_backend_gemm::GemmParams.431"* %12, i64 0, i32 4
  store i32* %408, i32** %541, align 8
  %542 = trunc i32 %303 to i8
  store i8 %542, i8* %537, align 8
  %543 = trunc i32 %304 to i8
  store i8 %543, i8* %540, align 1
  %544 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.431", %"struct.tflite::cpu_backend_gemm::GemmParams.431"* %12, i64 0, i32 0
  store i32 %301, i32* %544, align 8
  %545 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.431", %"struct.tflite::cpu_backend_gemm::GemmParams.431"* %12, i64 0, i32 1
  store i32 %302, i32* %545, align 4
  call void @_ZN6tflite16cpu_backend_gemm6detail16GemmImplUsingRuyIaaiaLNS0_18QuantizationFlavorE1EE3RunERKNS0_12MatrixParamsIaEEPKaS8_SA_S8_PaRKNS0_10GemmParamsIiaLS3_1EEEPNS_17CpuBackendContextE(%"struct.tflite::cpu_backend_gemm::MatrixParams.429"* nonnull dereferenceable(16) %9, i8* %374, %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* nonnull dereferenceable(16) %10, i8* %339, %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* nonnull dereferenceable(16) %11, i8* %491, %"struct.tflite::cpu_backend_gemm::GemmParams.431"* nonnull dereferenceable(40) %12, %"class.tflite::CpuBackendContext"* %297) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %536) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %530) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %524) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %518) #19
  %546 = xor i1 %490, true
  %547 = icmp eq i32* %492, null
  %548 = or i1 %547, %546
  br i1 %548, label %550, label %549

549:                                              ; preds = %513
  call void @_ZdaPv(i8* %493) #18
  br label %550

550:                                              ; preds = %549, %513
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %409) #19
  %551 = icmp sgt i32 %407, 5
  br i1 %551, label %552, label %558

552:                                              ; preds = %550
  %553 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %15, i64 0, i32 1, i32 0
  %554 = load i32*, i32** %553, align 8
  %555 = icmp eq i32* %554, null
  br i1 %555, label %558, label %556

556:                                              ; preds = %552
  %557 = bitcast i32* %554 to i8*
  call void @_ZdaPv(i8* %557) #18
  br label %558

558:                                              ; preds = %556, %552, %550
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %375) #19
  br i1 %496, label %559, label %565

559:                                              ; preds = %558
  %560 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 1, i32 0
  %561 = load i32*, i32** %560, align 8
  %562 = icmp eq i32* %561, null
  br i1 %562, label %565, label %563

563:                                              ; preds = %559
  %564 = bitcast i32* %561 to i8*
  call void @_ZdaPv(i8* %564) #18
  br label %565

565:                                              ; preds = %563, %559, %558
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %340) #19
  %566 = icmp sgt i32 %338, 5
  br i1 %566, label %567, label %1060

567:                                              ; preds = %565
  %568 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 1, i32 0
  %569 = load i32*, i32** %568, align 8
  %570 = icmp eq i32* %569, null
  br i1 %570, label %1060, label %571

571:                                              ; preds = %567
  %572 = bitcast i32* %569 to i8*
  call void @_ZdaPv(i8* %572) #18
  br label %1060

573:                                              ; preds = %87
  %574 = icmp eq i32 %31, 7
  br i1 %574, label %575, label %881

575:                                              ; preds = %573
  %576 = bitcast %"class.tflite::RuntimeShape"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %576) #19
  %577 = icmp eq %struct.TfLiteTensor* %4, null
  br i1 %577, label %578, label %580

578:                                              ; preds = %575
  %579 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %17, i64 0, i32 0
  store i32 0, i32* %579, align 8, !alias.scope !243
  br label %608

580:                                              ; preds = %575
  %581 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 2
  %582 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %581, align 8, !noalias !243
  %583 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %582, i64 0, i32 0
  %584 = load i32, i32* %583, align 4, !noalias !243
  %585 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %582, i64 0, i32 1, i64 0
  %586 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %17, i64 0, i32 0
  store i32 %584, i32* %586, align 8, !alias.scope !243
  %587 = icmp sgt i32 %584, 5
  br i1 %587, label %588, label %595

588:                                              ; preds = %580
  %589 = sext i32 %584 to i64
  %590 = shl nsw i64 %589, 2
  %591 = tail call i8* @_Znam(i64 %590) #18, !noalias !243
  %592 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %17, i64 0, i32 1, i32 0
  %593 = bitcast i32** %592 to i8**
  store i8* %591, i8** %593, align 8, !alias.scope !243
  %594 = bitcast i8* %591 to i32*
  br label %600

595:                                              ; preds = %580
  %596 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %17, i64 0, i32 1
  %597 = bitcast %union.anon.54* %596 to i32*
  %598 = sext i32 %584 to i64
  %599 = shl nsw i64 %598, 2
  br label %600

600:                                              ; preds = %595, %588
  %601 = phi i64 [ %590, %588 ], [ %599, %595 ]
  %602 = phi i32* [ %594, %588 ], [ %597, %595 ]
  %603 = bitcast i32* %602 to i8*
  %604 = bitcast i32* %585 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %603, i8* align 4 %604, i64 %601, i1 false) #19
  %605 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 1
  %606 = bitcast %union.TfLitePtrUnion* %605 to i16**
  %607 = load i16*, i16** %606, align 8
  br label %608

608:                                              ; preds = %600, %578
  %609 = phi i32 [ %584, %600 ], [ 0, %578 ]
  %610 = phi i16* [ %607, %600 ], [ null, %578 ]
  %611 = bitcast %"class.tflite::RuntimeShape"* %18 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %611) #19
  %612 = icmp eq %struct.TfLiteTensor* %5, null
  br i1 %612, label %613, label %615

613:                                              ; preds = %608
  %614 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %18, i64 0, i32 0
  store i32 0, i32* %614, align 8, !alias.scope !246
  br label %643

615:                                              ; preds = %608
  %616 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 2
  %617 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %616, align 8, !noalias !246
  %618 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %617, i64 0, i32 0
  %619 = load i32, i32* %618, align 4, !noalias !246
  %620 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %617, i64 0, i32 1, i64 0
  %621 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %18, i64 0, i32 0
  store i32 %619, i32* %621, align 8, !alias.scope !246
  %622 = icmp sgt i32 %619, 5
  br i1 %622, label %623, label %630

623:                                              ; preds = %615
  %624 = sext i32 %619 to i64
  %625 = shl nsw i64 %624, 2
  %626 = tail call i8* @_Znam(i64 %625) #18, !noalias !246
  %627 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %18, i64 0, i32 1, i32 0
  %628 = bitcast i32** %627 to i8**
  store i8* %626, i8** %628, align 8, !alias.scope !246
  %629 = bitcast i8* %626 to i32*
  br label %635

630:                                              ; preds = %615
  %631 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %18, i64 0, i32 1
  %632 = bitcast %union.anon.54* %631 to i32*
  %633 = sext i32 %619 to i64
  %634 = shl nsw i64 %633, 2
  br label %635

635:                                              ; preds = %630, %623
  %636 = phi i64 [ %625, %623 ], [ %634, %630 ]
  %637 = phi i32* [ %629, %623 ], [ %632, %630 ]
  %638 = bitcast i32* %637 to i8*
  %639 = bitcast i32* %620 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %638, i8* align 4 %639, i64 %636, i1 false) #19
  %640 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 1
  %641 = bitcast %union.TfLitePtrUnion* %640 to i8**
  %642 = load i8*, i8** %641, align 8
  br label %643

643:                                              ; preds = %635, %613
  %644 = phi i32 [ %619, %635 ], [ 0, %613 ]
  %645 = phi i8* [ %642, %635 ], [ null, %613 ]
  %646 = bitcast %"class.tflite::RuntimeShape"* %19 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %646) #19
  %647 = icmp eq %struct.TfLiteTensor* %6, null
  br i1 %647, label %648, label %650

648:                                              ; preds = %643
  %649 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %19, i64 0, i32 0
  store i32 0, i32* %649, align 8, !alias.scope !249
  br label %678

650:                                              ; preds = %643
  %651 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 2
  %652 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %651, align 8, !noalias !249
  %653 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %652, i64 0, i32 0
  %654 = load i32, i32* %653, align 4, !noalias !249
  %655 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %652, i64 0, i32 1, i64 0
  %656 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %19, i64 0, i32 0
  store i32 %654, i32* %656, align 8, !alias.scope !249
  %657 = icmp sgt i32 %654, 5
  br i1 %657, label %658, label %665

658:                                              ; preds = %650
  %659 = sext i32 %654 to i64
  %660 = shl nsw i64 %659, 2
  %661 = tail call i8* @_Znam(i64 %660) #18, !noalias !249
  %662 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %19, i64 0, i32 1, i32 0
  %663 = bitcast i32** %662 to i8**
  store i8* %661, i8** %663, align 8, !alias.scope !249
  %664 = bitcast i8* %661 to i32*
  br label %670

665:                                              ; preds = %650
  %666 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %19, i64 0, i32 1
  %667 = bitcast %union.anon.54* %666 to i32*
  %668 = sext i32 %654 to i64
  %669 = shl nsw i64 %668, 2
  br label %670

670:                                              ; preds = %665, %658
  %671 = phi i64 [ %660, %658 ], [ %669, %665 ]
  %672 = phi i32* [ %664, %658 ], [ %667, %665 ]
  %673 = bitcast i32* %672 to i8*
  %674 = bitcast i32* %655 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %673, i8* align 4 %674, i64 %671, i1 false) #19
  %675 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 1
  %676 = bitcast %union.TfLitePtrUnion* %675 to i64**
  %677 = load i64*, i64** %676, align 8
  br label %678

678:                                              ; preds = %670, %648
  %679 = phi i32 [ %654, %670 ], [ 0, %648 ]
  %680 = phi i64* [ %677, %670 ], [ null, %648 ]
  %681 = bitcast %"class.tflite::RuntimeShape"* %20 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %681) #19
  %682 = icmp eq %struct.TfLiteTensor* %7, null
  br i1 %682, label %683, label %686

683:                                              ; preds = %678
  %684 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %20, i64 0, i32 0
  store i32 0, i32* %684, align 8, !alias.scope !252
  %685 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %20, i64 0, i32 1
  br label %719

686:                                              ; preds = %678
  %687 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 2
  %688 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %687, align 8, !noalias !252
  %689 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %688, i64 0, i32 0
  %690 = load i32, i32* %689, align 4, !noalias !252
  %691 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %688, i64 0, i32 1, i64 0
  %692 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %20, i64 0, i32 0
  store i32 %690, i32* %692, align 8, !alias.scope !252
  %693 = icmp sgt i32 %690, 5
  br i1 %693, label %694, label %701

694:                                              ; preds = %686
  %695 = sext i32 %690 to i64
  %696 = shl nsw i64 %695, 2
  %697 = tail call i8* @_Znam(i64 %696) #18, !noalias !252
  %698 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %20, i64 0, i32 1, i32 0
  %699 = bitcast i32** %698 to i8**
  store i8* %697, i8** %699, align 8, !alias.scope !252
  %700 = bitcast i8* %697 to i32*
  br label %706

701:                                              ; preds = %686
  %702 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %20, i64 0, i32 1
  %703 = bitcast %union.anon.54* %702 to i32*
  %704 = sext i32 %690 to i64
  %705 = shl nsw i64 %704, 2
  br label %706

706:                                              ; preds = %701, %694
  %707 = phi i64 [ %696, %694 ], [ %705, %701 ]
  %708 = phi i32* [ %700, %694 ], [ %703, %701 ]
  %709 = bitcast i32* %708 to i8*
  %710 = bitcast i32* %691 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %709, i8* align 4 %710, i64 %707, i1 false) #19
  %711 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 1
  %712 = bitcast %union.TfLitePtrUnion* %711 to i16**
  %713 = load i16*, i16** %712, align 8
  %714 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %20, i64 0, i32 1, i32 0
  %715 = load i32*, i32** %714, align 8
  %716 = bitcast i32* %715 to i8*
  %717 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %20, i64 0, i32 1
  %718 = getelementptr inbounds i32, i32* %715, i64 1
  br i1 %693, label %727, label %719

719:                                              ; preds = %706, %683
  %720 = phi %union.anon.54* [ %685, %683 ], [ %717, %706 ]
  %721 = phi i16* [ null, %683 ], [ %713, %706 ]
  %722 = phi i32* [ undef, %683 ], [ %715, %706 ]
  %723 = phi i8* [ undef, %683 ], [ %716, %706 ]
  %724 = bitcast %union.anon.54* %720 to [5 x i32]*
  %725 = bitcast %union.anon.54* %720 to i32*
  %726 = getelementptr inbounds [5 x i32], [5 x i32]* %724, i64 0, i64 1
  br label %727

727:                                              ; preds = %719, %706
  %728 = phi i32* [ %725, %719 ], [ %715, %706 ]
  %729 = phi i8* [ %723, %719 ], [ %716, %706 ]
  %730 = phi i32* [ %722, %719 ], [ %715, %706 ]
  %731 = phi i1 [ true, %719 ], [ false, %706 ]
  %732 = phi i16* [ %721, %719 ], [ %713, %706 ]
  %733 = phi i32* [ %726, %719 ], [ %718, %706 ]
  %734 = load i32, i32* %728, align 4
  %735 = load i32, i32* %733, align 4
  %736 = icmp sgt i32 %644, 5
  %737 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %18, i64 0, i32 1
  %738 = add nsw i32 %644, -1
  %739 = getelementptr inbounds %union.anon.54, %union.anon.54* %737, i64 0, i32 0
  %740 = load i32*, i32** %739, align 8
  %741 = sext i32 %738 to i64
  %742 = getelementptr inbounds i32, i32* %740, i64 %741
  %743 = bitcast %union.anon.54* %737 to [5 x i32]*
  %744 = getelementptr inbounds [5 x i32], [5 x i32]* %743, i64 0, i64 %741
  %745 = select i1 %736, i32* %742, i32* %744
  %746 = load i32, i32* %745, align 4
  %747 = icmp sgt i32 %734, 0
  br i1 %747, label %748, label %855

748:                                              ; preds = %727
  %749 = icmp sgt i32 %735, 0
  %750 = icmp sgt i32 %746, 0
  %751 = icmp eq i64* %680, null
  %752 = extractelement <4 x i32> %102, i32 0
  %753 = add nsw i32 %752, 32768
  %754 = ashr i32 %753, 16
  %755 = extractelement <4 x i32> %102, i32 1
  %756 = sub nsw i32 15, %755
  %757 = sext i32 %754 to i64
  %758 = sub i32 14, %755
  %759 = zext i32 %758 to i64
  %760 = shl i64 1, %759
  %761 = zext i32 %756 to i64
  %762 = sext i32 %746 to i64
  %763 = sext i32 %735 to i64
  %764 = zext i32 %734 to i64
  %765 = zext i32 %735 to i64
  %766 = zext i32 %746 to i64
  %767 = and i64 %766, 1
  %768 = icmp eq i32 %746, 1
  %769 = sub nsw i64 %766, %767
  %770 = icmp eq i64 %767, 0
  %771 = extractelement <4 x i32> %102, i32 2
  %772 = extractelement <4 x i32> %102, i32 3
  br label %773

773:                                              ; preds = %782, %748
  %774 = phi i64 [ 0, %748 ], [ %783, %782 ]
  br i1 %749, label %775, label %782

775:                                              ; preds = %773
  %776 = mul nsw i64 %774, %762
  %777 = mul nsw i64 %774, %763
  br label %778

778:                                              ; preds = %840, %775
  %779 = phi i64 [ 0, %775 ], [ %853, %840 ]
  br i1 %750, label %780, label %802

780:                                              ; preds = %778
  %781 = mul nsw i64 %779, %762
  br i1 %768, label %785, label %804

782:                                              ; preds = %840, %773
  %783 = add nuw nsw i64 %774, 1
  %784 = icmp eq i64 %783, %764
  br i1 %784, label %855, label %773

785:                                              ; preds = %804, %780
  %786 = phi i64 [ undef, %780 ], [ %832, %804 ]
  %787 = phi i64 [ 0, %780 ], [ %833, %804 ]
  %788 = phi i64 [ 0, %780 ], [ %832, %804 ]
  br i1 %770, label %802, label %789

789:                                              ; preds = %785
  %790 = add nsw i64 %787, %781
  %791 = getelementptr inbounds i8, i8* %645, i64 %790
  %792 = load i8, i8* %791, align 1
  %793 = sext i8 %792 to i32
  %794 = sub i32 %793, %91
  %795 = add nsw i64 %787, %776
  %796 = getelementptr inbounds i16, i16* %610, i64 %795
  %797 = load i16, i16* %796, align 2
  %798 = sext i16 %797 to i32
  %799 = mul nsw i32 %794, %798
  %800 = sext i32 %799 to i64
  %801 = add nsw i64 %788, %800
  br label %802

802:                                              ; preds = %789, %785, %778
  %803 = phi i64 [ 0, %778 ], [ %786, %785 ], [ %801, %789 ]
  br i1 %751, label %840, label %836

804:                                              ; preds = %780, %804
  %805 = phi i64 [ %833, %804 ], [ 0, %780 ]
  %806 = phi i64 [ %832, %804 ], [ 0, %780 ]
  %807 = phi i64 [ %834, %804 ], [ %769, %780 ]
  %808 = add nsw i64 %805, %776
  %809 = getelementptr inbounds i16, i16* %610, i64 %808
  %810 = load i16, i16* %809, align 2
  %811 = sext i16 %810 to i32
  %812 = add nsw i64 %805, %781
  %813 = getelementptr inbounds i8, i8* %645, i64 %812
  %814 = load i8, i8* %813, align 1
  %815 = sext i8 %814 to i32
  %816 = sub i32 %815, %91
  %817 = mul nsw i32 %816, %811
  %818 = sext i32 %817 to i64
  %819 = add nsw i64 %806, %818
  %820 = or i64 %805, 1
  %821 = add nsw i64 %820, %776
  %822 = getelementptr inbounds i16, i16* %610, i64 %821
  %823 = load i16, i16* %822, align 2
  %824 = sext i16 %823 to i32
  %825 = add nsw i64 %820, %781
  %826 = getelementptr inbounds i8, i8* %645, i64 %825
  %827 = load i8, i8* %826, align 1
  %828 = sext i8 %827 to i32
  %829 = sub i32 %828, %91
  %830 = mul nsw i32 %829, %824
  %831 = sext i32 %830 to i64
  %832 = add nsw i64 %819, %831
  %833 = add nuw nsw i64 %805, 2
  %834 = add i64 %807, -2
  %835 = icmp eq i64 %834, 0
  br i1 %835, label %785, label %804

836:                                              ; preds = %802
  %837 = getelementptr inbounds i64, i64* %680, i64 %779
  %838 = load i64, i64* %837, align 8
  %839 = add nsw i64 %838, %803
  br label %840

840:                                              ; preds = %836, %802
  %841 = phi i64 [ %839, %836 ], [ %803, %802 ]
  %842 = mul nsw i64 %841, %757
  %843 = add nsw i64 %842, %760
  %844 = ashr i64 %843, %761
  %845 = trunc i64 %844 to i32
  %846 = icmp sgt i32 %771, %845
  %847 = select i1 %846, i32 %771, i32 %845
  %848 = icmp slt i32 %772, %847
  %849 = select i1 %848, i32 %772, i32 %847
  %850 = trunc i32 %849 to i16
  %851 = add nsw i64 %779, %777
  %852 = getelementptr inbounds i16, i16* %732, i64 %851
  store i16 %850, i16* %852, align 2
  %853 = add nuw nsw i64 %779, 1
  %854 = icmp eq i64 %853, %765
  br i1 %854, label %782, label %778

855:                                              ; preds = %782, %727
  %856 = icmp eq i32* %730, null
  %857 = or i1 %731, %856
  br i1 %857, label %859, label %858

858:                                              ; preds = %855
  tail call void @_ZdaPv(i8* %729) #18
  br label %859

859:                                              ; preds = %858, %855
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %681) #19
  %860 = icmp sgt i32 %679, 5
  br i1 %860, label %861, label %867

861:                                              ; preds = %859
  %862 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %19, i64 0, i32 1, i32 0
  %863 = load i32*, i32** %862, align 8
  %864 = icmp eq i32* %863, null
  br i1 %864, label %867, label %865

865:                                              ; preds = %861
  %866 = bitcast i32* %863 to i8*
  tail call void @_ZdaPv(i8* %866) #18
  br label %867

867:                                              ; preds = %865, %861, %859
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %646) #19
  %868 = xor i1 %736, true
  %869 = icmp eq i32* %740, null
  %870 = or i1 %869, %868
  br i1 %870, label %873, label %871

871:                                              ; preds = %867
  %872 = bitcast i32* %740 to i8*
  tail call void @_ZdaPv(i8* %872) #18
  br label %873

873:                                              ; preds = %871, %867
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %611) #19
  %874 = icmp sgt i32 %609, 5
  br i1 %874, label %875, label %1060

875:                                              ; preds = %873
  %876 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %17, i64 0, i32 1, i32 0
  %877 = load i32*, i32** %876, align 8
  %878 = icmp eq i32* %877, null
  br i1 %878, label %1060, label %879

879:                                              ; preds = %875
  %880 = bitcast i32* %877 to i8*
  tail call void @_ZdaPv(i8* %880) #18
  br label %1060

881:                                              ; preds = %573
  %882 = bitcast %"class.tflite::RuntimeShape"* %26 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %882) #19
  %883 = icmp eq %struct.TfLiteTensor* %4, null
  br i1 %883, label %884, label %886

884:                                              ; preds = %881
  %885 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %26, i64 0, i32 0
  store i32 0, i32* %885, align 8, !alias.scope !255
  br label %914

886:                                              ; preds = %881
  %887 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 2
  %888 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %887, align 8, !noalias !255
  %889 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %888, i64 0, i32 0
  %890 = load i32, i32* %889, align 4, !noalias !255
  %891 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %888, i64 0, i32 1, i64 0
  %892 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %26, i64 0, i32 0
  store i32 %890, i32* %892, align 8, !alias.scope !255
  %893 = icmp sgt i32 %890, 5
  br i1 %893, label %894, label %901

894:                                              ; preds = %886
  %895 = sext i32 %890 to i64
  %896 = shl nsw i64 %895, 2
  %897 = tail call i8* @_Znam(i64 %896) #18, !noalias !255
  %898 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %26, i64 0, i32 1, i32 0
  %899 = bitcast i32** %898 to i8**
  store i8* %897, i8** %899, align 8, !alias.scope !255
  %900 = bitcast i8* %897 to i32*
  br label %906

901:                                              ; preds = %886
  %902 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %26, i64 0, i32 1
  %903 = bitcast %union.anon.54* %902 to i32*
  %904 = sext i32 %890 to i64
  %905 = shl nsw i64 %904, 2
  br label %906

906:                                              ; preds = %901, %894
  %907 = phi i64 [ %896, %894 ], [ %905, %901 ]
  %908 = phi i32* [ %900, %894 ], [ %903, %901 ]
  %909 = bitcast i32* %908 to i8*
  %910 = bitcast i32* %891 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %909, i8* align 4 %910, i64 %907, i1 false) #19
  %911 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 1
  %912 = bitcast %union.TfLitePtrUnion* %911 to i8**
  %913 = load i8*, i8** %912, align 8
  br label %914

914:                                              ; preds = %884, %906
  %915 = phi i8* [ %913, %906 ], [ null, %884 ]
  %916 = bitcast %"class.tflite::RuntimeShape"* %27 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %916) #19
  %917 = icmp eq %struct.TfLiteTensor* %5, null
  br i1 %917, label %918, label %920

918:                                              ; preds = %914
  %919 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %27, i64 0, i32 0
  store i32 0, i32* %919, align 8, !alias.scope !258
  br label %948

920:                                              ; preds = %914
  %921 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 2
  %922 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %921, align 8, !noalias !258
  %923 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %922, i64 0, i32 0
  %924 = load i32, i32* %923, align 4, !noalias !258
  %925 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %922, i64 0, i32 1, i64 0
  %926 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %27, i64 0, i32 0
  store i32 %924, i32* %926, align 8, !alias.scope !258
  %927 = icmp sgt i32 %924, 5
  br i1 %927, label %928, label %935

928:                                              ; preds = %920
  %929 = sext i32 %924 to i64
  %930 = shl nsw i64 %929, 2
  %931 = tail call i8* @_Znam(i64 %930) #18, !noalias !258
  %932 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %27, i64 0, i32 1, i32 0
  %933 = bitcast i32** %932 to i8**
  store i8* %931, i8** %933, align 8, !alias.scope !258
  %934 = bitcast i8* %931 to i32*
  br label %940

935:                                              ; preds = %920
  %936 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %27, i64 0, i32 1
  %937 = bitcast %union.anon.54* %936 to i32*
  %938 = sext i32 %924 to i64
  %939 = shl nsw i64 %938, 2
  br label %940

940:                                              ; preds = %935, %928
  %941 = phi i64 [ %930, %928 ], [ %939, %935 ]
  %942 = phi i32* [ %934, %928 ], [ %937, %935 ]
  %943 = bitcast i32* %942 to i8*
  %944 = bitcast i32* %925 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %943, i8* align 4 %944, i64 %941, i1 false) #19
  %945 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 1
  %946 = bitcast %union.TfLitePtrUnion* %945 to i8**
  %947 = load i8*, i8** %946, align 8
  br label %948

948:                                              ; preds = %918, %940
  %949 = phi i8* [ %947, %940 ], [ null, %918 ]
  %950 = bitcast %"class.tflite::RuntimeShape"* %28 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %950) #19
  %951 = icmp eq %struct.TfLiteTensor* %6, null
  br i1 %951, label %952, label %954

952:                                              ; preds = %948
  %953 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %28, i64 0, i32 0
  store i32 0, i32* %953, align 8, !alias.scope !261
  br label %981

954:                                              ; preds = %948
  %955 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 2
  %956 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %955, align 8, !noalias !261
  %957 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %956, i64 0, i32 0
  %958 = load i32, i32* %957, align 4, !noalias !261
  %959 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %956, i64 0, i32 1, i64 0
  %960 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %28, i64 0, i32 0
  store i32 %958, i32* %960, align 8, !alias.scope !261
  %961 = icmp sgt i32 %958, 5
  br i1 %961, label %962, label %969

962:                                              ; preds = %954
  %963 = sext i32 %958 to i64
  %964 = shl nsw i64 %963, 2
  %965 = tail call i8* @_Znam(i64 %964) #18, !noalias !261
  %966 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %28, i64 0, i32 1, i32 0
  %967 = bitcast i32** %966 to i8**
  store i8* %965, i8** %967, align 8, !alias.scope !261
  %968 = bitcast i8* %965 to i32*
  br label %974

969:                                              ; preds = %954
  %970 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %28, i64 0, i32 1
  %971 = bitcast %union.anon.54* %970 to i32*
  %972 = sext i32 %958 to i64
  %973 = shl nsw i64 %972, 2
  br label %974

974:                                              ; preds = %969, %962
  %975 = phi i64 [ %964, %962 ], [ %973, %969 ]
  %976 = phi i32* [ %968, %962 ], [ %971, %969 ]
  %977 = bitcast i32* %976 to i8*
  %978 = bitcast i32* %959 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %977, i8* align 4 %978, i64 %975, i1 false) #19
  %979 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 1, i32 0
  %980 = load i32*, i32** %979, align 8
  br label %981

981:                                              ; preds = %952, %974
  %982 = phi i32* [ %980, %974 ], [ null, %952 ]
  %983 = bitcast %"class.tflite::RuntimeShape"* %29 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %983) #19
  %984 = icmp eq %struct.TfLiteTensor* %7, null
  br i1 %984, label %985, label %987

985:                                              ; preds = %981
  %986 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %29, i64 0, i32 0
  store i32 0, i32* %986, align 8, !alias.scope !264
  br label %1015

987:                                              ; preds = %981
  %988 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 2
  %989 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %988, align 8, !noalias !264
  %990 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %989, i64 0, i32 0
  %991 = load i32, i32* %990, align 4, !noalias !264
  %992 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %989, i64 0, i32 1, i64 0
  %993 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %29, i64 0, i32 0
  store i32 %991, i32* %993, align 8, !alias.scope !264
  %994 = icmp sgt i32 %991, 5
  br i1 %994, label %995, label %1002

995:                                              ; preds = %987
  %996 = sext i32 %991 to i64
  %997 = shl nsw i64 %996, 2
  %998 = tail call i8* @_Znam(i64 %997) #18, !noalias !264
  %999 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %29, i64 0, i32 1, i32 0
  %1000 = bitcast i32** %999 to i8**
  store i8* %998, i8** %1000, align 8, !alias.scope !264
  %1001 = bitcast i8* %998 to i32*
  br label %1007

1002:                                             ; preds = %987
  %1003 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %29, i64 0, i32 1
  %1004 = bitcast %union.anon.54* %1003 to i32*
  %1005 = sext i32 %991 to i64
  %1006 = shl nsw i64 %1005, 2
  br label %1007

1007:                                             ; preds = %1002, %995
  %1008 = phi i64 [ %997, %995 ], [ %1006, %1002 ]
  %1009 = phi i32* [ %1001, %995 ], [ %1004, %1002 ]
  %1010 = bitcast i32* %1009 to i8*
  %1011 = bitcast i32* %992 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %1010, i8* align 4 %1011, i64 %1008, i1 false) #19
  %1012 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 1
  %1013 = bitcast %union.TfLitePtrUnion* %1012 to i16**
  %1014 = load i16*, i16** %1013, align 8
  br label %1015

1015:                                             ; preds = %985, %1007
  %1016 = phi i16* [ %1014, %1007 ], [ null, %985 ]
  %1017 = tail call %"class.tflite::CpuBackendContext"* @_ZN6tflite17CpuBackendContext14GetFromContextEP13TfLiteContext(%struct.TfLiteContext* %0) #19
  call void @_ZN6tflite13optimized_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKiS6_PsPNS_17CpuBackendContextE(%"struct.tflite::FullyConnectedParams"* nonnull dereferenceable(40) %21, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %26, i8* %915, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %27, i8* %949, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %28, i32* %982, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %29, i16* %1016, %"class.tflite::CpuBackendContext"* %1017)
  %1018 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %29, i64 0, i32 0
  %1019 = load i32, i32* %1018, align 8
  %1020 = icmp sgt i32 %1019, 5
  br i1 %1020, label %1021, label %1027

1021:                                             ; preds = %1015
  %1022 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %29, i64 0, i32 1, i32 0
  %1023 = load i32*, i32** %1022, align 8
  %1024 = icmp eq i32* %1023, null
  br i1 %1024, label %1027, label %1025

1025:                                             ; preds = %1021
  %1026 = bitcast i32* %1023 to i8*
  call void @_ZdaPv(i8* %1026) #18
  br label %1027

1027:                                             ; preds = %1015, %1021, %1025
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %983) #19
  %1028 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %28, i64 0, i32 0
  %1029 = load i32, i32* %1028, align 8
  %1030 = icmp sgt i32 %1029, 5
  br i1 %1030, label %1031, label %1037

1031:                                             ; preds = %1027
  %1032 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %28, i64 0, i32 1, i32 0
  %1033 = load i32*, i32** %1032, align 8
  %1034 = icmp eq i32* %1033, null
  br i1 %1034, label %1037, label %1035

1035:                                             ; preds = %1031
  %1036 = bitcast i32* %1033 to i8*
  call void @_ZdaPv(i8* %1036) #18
  br label %1037

1037:                                             ; preds = %1027, %1031, %1035
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %950) #19
  %1038 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %27, i64 0, i32 0
  %1039 = load i32, i32* %1038, align 8
  %1040 = icmp sgt i32 %1039, 5
  br i1 %1040, label %1041, label %1047

1041:                                             ; preds = %1037
  %1042 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %27, i64 0, i32 1, i32 0
  %1043 = load i32*, i32** %1042, align 8
  %1044 = icmp eq i32* %1043, null
  br i1 %1044, label %1047, label %1045

1045:                                             ; preds = %1041
  %1046 = bitcast i32* %1043 to i8*
  call void @_ZdaPv(i8* %1046) #18
  br label %1047

1047:                                             ; preds = %1037, %1041, %1045
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %916) #19
  %1048 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %26, i64 0, i32 0
  %1049 = load i32, i32* %1048, align 8
  %1050 = icmp sgt i32 %1049, 5
  br i1 %1050, label %1051, label %1060

1051:                                             ; preds = %1047
  %1052 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %26, i64 0, i32 1, i32 0
  %1053 = load i32*, i32** %1052, align 8
  %1054 = icmp eq i32* %1053, null
  br i1 %1054, label %1060, label %1055

1055:                                             ; preds = %1051
  %1056 = bitcast i32* %1053 to i8*
  call void @_ZdaPv(i8* %1056) #18
  br label %1060

1057:                                             ; preds = %87
  %1058 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %1059 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %1058, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %1059(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([71 x i8], [71 x i8]* @.str.35, i64 0, i64 0)) #19
  br label %1062

1060:                                             ; preds = %1055, %1051, %1047, %879, %875, %873, %571, %567, %565, %290, %286, %282
  %1061 = phi i8* [ %117, %282 ], [ %117, %286 ], [ %117, %290 ], [ %305, %565 ], [ %305, %567 ], [ %305, %571 ], [ %576, %873 ], [ %576, %875 ], [ %576, %879 ], [ %882, %1047 ], [ %882, %1051 ], [ %882, %1055 ]
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %1061) #19
  br label %1062

1062:                                             ; preds = %1057, %1060
  %1063 = phi i32 [ 0, %1060 ], [ 1, %1057 ]
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %96) #19
  ret i32 %1063

1064:                                             ; preds = %465
  %1065 = getelementptr inbounds i32, i32* %446, i64 %468
  %1066 = load i32, i32* %1065, align 4
  br label %1067

1067:                                             ; preds = %1064, %465
  %1068 = phi i32 [ %1066, %1064 ], [ 1, %465 ]
  %1069 = mul nsw i32 %1068, %467
  %1070 = or i64 %458, 2
  %1071 = icmp eq i64 %1070, %450
  br i1 %1071, label %1075, label %1072

1072:                                             ; preds = %1067
  %1073 = getelementptr inbounds i32, i32* %446, i64 %1070
  %1074 = load i32, i32* %1073, align 4
  br label %1075

1075:                                             ; preds = %1072, %1067
  %1076 = phi i32 [ %1074, %1072 ], [ 1, %1067 ]
  %1077 = mul nsw i32 %1076, %1069
  %1078 = or i64 %458, 3
  %1079 = icmp eq i64 %1078, %450
  br i1 %1079, label %1083, label %1080

1080:                                             ; preds = %1075
  %1081 = getelementptr inbounds i32, i32* %446, i64 %1078
  %1082 = load i32, i32* %1081, align 4
  br label %1083

1083:                                             ; preds = %1080, %1075
  %1084 = phi i32 [ %1082, %1080 ], [ 1, %1075 ]
  %1085 = mul nsw i32 %1084, %1077
  %1086 = add nuw nsw i64 %458, 4
  %1087 = add i64 %460, -4
  %1088 = icmp eq i64 %1087, 0
  br i1 %1088, label %470, label %457
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN6tflite13optimized_ops26FullyConnectedSparseWeightERK14TfLiteSparsityRKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKfS9_SB_S9_SB_S9_Pf(%struct.TfLiteSparsity* dereferenceable(32), %"struct.tflite::FullyConnectedParams"* dereferenceable(40), %"class.tflite::RuntimeShape"* dereferenceable(32), float*, %"class.tflite::RuntimeShape"* dereferenceable(32), float*, %"class.tflite::RuntimeShape"* dereferenceable(32), float*, %"class.tflite::RuntimeShape"* dereferenceable(32), float*) local_unnamed_addr #4 comdat {
  %11 = bitcast float* %9 to i8*
  %12 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %1, i64 0, i32 7
  %13 = load float, float* %12, align 4
  %14 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %1, i64 0, i32 8
  %15 = load float, float* %14, align 4
  %16 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %8, i64 0, i32 0
  %17 = load i32, i32* %16, align 8
  %18 = icmp sgt i32 %17, 5
  %19 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %8, i64 0, i32 1
  br i1 %18, label %20, label %23

20:                                               ; preds = %10
  %21 = getelementptr inbounds %union.anon.54, %union.anon.54* %19, i64 0, i32 0
  %22 = load i32*, i32** %21, align 8
  br label %26

23:                                               ; preds = %10
  %24 = bitcast %union.anon.54* %19 to i32*
  %25 = icmp sgt i32 %17, 0
  br i1 %25, label %26, label %129

26:                                               ; preds = %23, %20
  %27 = phi i32* [ %22, %20 ], [ %24, %23 ]
  %28 = zext i32 %17 to i64
  %29 = icmp ult i32 %17, 8
  br i1 %29, label %115, label %30

30:                                               ; preds = %26
  %31 = and i64 %28, 4294967288
  %32 = add nsw i64 %31, -8
  %33 = lshr exact i64 %32, 3
  %34 = add nuw nsw i64 %33, 1
  %35 = and i64 %34, 3
  %36 = icmp ult i64 %32, 24
  br i1 %36, label %82, label %37

37:                                               ; preds = %30
  %38 = sub nsw i64 %34, %35
  br label %39

39:                                               ; preds = %39, %37
  %40 = phi i64 [ 0, %37 ], [ %79, %39 ]
  %41 = phi <4 x i32> [ <i32 1, i32 1, i32 1, i32 1>, %37 ], [ %77, %39 ]
  %42 = phi <4 x i32> [ <i32 1, i32 1, i32 1, i32 1>, %37 ], [ %78, %39 ]
  %43 = phi i64 [ %38, %37 ], [ %80, %39 ]
  %44 = getelementptr inbounds i32, i32* %27, i64 %40
  %45 = bitcast i32* %44 to <4 x i32>*
  %46 = load <4 x i32>, <4 x i32>* %45, align 4
  %47 = getelementptr inbounds i32, i32* %44, i64 4
  %48 = bitcast i32* %47 to <4 x i32>*
  %49 = load <4 x i32>, <4 x i32>* %48, align 4
  %50 = mul nsw <4 x i32> %46, %41
  %51 = mul nsw <4 x i32> %49, %42
  %52 = or i64 %40, 8
  %53 = getelementptr inbounds i32, i32* %27, i64 %52
  %54 = bitcast i32* %53 to <4 x i32>*
  %55 = load <4 x i32>, <4 x i32>* %54, align 4
  %56 = getelementptr inbounds i32, i32* %53, i64 4
  %57 = bitcast i32* %56 to <4 x i32>*
  %58 = load <4 x i32>, <4 x i32>* %57, align 4
  %59 = mul nsw <4 x i32> %55, %50
  %60 = mul nsw <4 x i32> %58, %51
  %61 = or i64 %40, 16
  %62 = getelementptr inbounds i32, i32* %27, i64 %61
  %63 = bitcast i32* %62 to <4 x i32>*
  %64 = load <4 x i32>, <4 x i32>* %63, align 4
  %65 = getelementptr inbounds i32, i32* %62, i64 4
  %66 = bitcast i32* %65 to <4 x i32>*
  %67 = load <4 x i32>, <4 x i32>* %66, align 4
  %68 = mul nsw <4 x i32> %64, %59
  %69 = mul nsw <4 x i32> %67, %60
  %70 = or i64 %40, 24
  %71 = getelementptr inbounds i32, i32* %27, i64 %70
  %72 = bitcast i32* %71 to <4 x i32>*
  %73 = load <4 x i32>, <4 x i32>* %72, align 4
  %74 = getelementptr inbounds i32, i32* %71, i64 4
  %75 = bitcast i32* %74 to <4 x i32>*
  %76 = load <4 x i32>, <4 x i32>* %75, align 4
  %77 = mul nsw <4 x i32> %73, %68
  %78 = mul nsw <4 x i32> %76, %69
  %79 = add i64 %40, 32
  %80 = add i64 %43, -4
  %81 = icmp eq i64 %80, 0
  br i1 %81, label %82, label %39, !llvm.loop !267

82:                                               ; preds = %39, %30
  %83 = phi <4 x i32> [ undef, %30 ], [ %77, %39 ]
  %84 = phi <4 x i32> [ undef, %30 ], [ %78, %39 ]
  %85 = phi i64 [ 0, %30 ], [ %79, %39 ]
  %86 = phi <4 x i32> [ <i32 1, i32 1, i32 1, i32 1>, %30 ], [ %77, %39 ]
  %87 = phi <4 x i32> [ <i32 1, i32 1, i32 1, i32 1>, %30 ], [ %78, %39 ]
  %88 = icmp eq i64 %35, 0
  br i1 %88, label %105, label %89

89:                                               ; preds = %82, %89
  %90 = phi i64 [ %102, %89 ], [ %85, %82 ]
  %91 = phi <4 x i32> [ %100, %89 ], [ %86, %82 ]
  %92 = phi <4 x i32> [ %101, %89 ], [ %87, %82 ]
  %93 = phi i64 [ %103, %89 ], [ %35, %82 ]
  %94 = getelementptr inbounds i32, i32* %27, i64 %90
  %95 = bitcast i32* %94 to <4 x i32>*
  %96 = load <4 x i32>, <4 x i32>* %95, align 4
  %97 = getelementptr inbounds i32, i32* %94, i64 4
  %98 = bitcast i32* %97 to <4 x i32>*
  %99 = load <4 x i32>, <4 x i32>* %98, align 4
  %100 = mul nsw <4 x i32> %96, %91
  %101 = mul nsw <4 x i32> %99, %92
  %102 = add i64 %90, 8
  %103 = add i64 %93, -1
  %104 = icmp eq i64 %103, 0
  br i1 %104, label %105, label %89, !llvm.loop !268

105:                                              ; preds = %89, %82
  %106 = phi <4 x i32> [ %83, %82 ], [ %100, %89 ]
  %107 = phi <4 x i32> [ %84, %82 ], [ %101, %89 ]
  %108 = mul <4 x i32> %107, %106
  %109 = shufflevector <4 x i32> %108, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %110 = mul <4 x i32> %108, %109
  %111 = shufflevector <4 x i32> %110, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %112 = mul <4 x i32> %110, %111
  %113 = extractelement <4 x i32> %112, i32 0
  %114 = icmp eq i64 %31, %28
  br i1 %114, label %126, label %115

115:                                              ; preds = %105, %26
  %116 = phi i64 [ 0, %26 ], [ %31, %105 ]
  %117 = phi i32 [ 1, %26 ], [ %113, %105 ]
  br label %118

118:                                              ; preds = %115, %118
  %119 = phi i64 [ %124, %118 ], [ %116, %115 ]
  %120 = phi i32 [ %123, %118 ], [ %117, %115 ]
  %121 = getelementptr inbounds i32, i32* %27, i64 %119
  %122 = load i32, i32* %121, align 4
  %123 = mul nsw i32 %122, %120
  %124 = add nuw nsw i64 %119, 1
  %125 = icmp eq i64 %124, %28
  br i1 %125, label %126, label %118, !llvm.loop !269

126:                                              ; preds = %118, %105
  %127 = phi i32 [ %113, %105 ], [ %123, %118 ]
  %128 = bitcast %union.anon.54* %19 to i32*
  br label %129

129:                                              ; preds = %126, %23
  %130 = phi i32* [ %128, %126 ], [ %24, %23 ]
  %131 = phi i32 [ %127, %126 ], [ 1, %23 ]
  %132 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %4, i64 0, i32 0
  %133 = load i32, i32* %132, align 8
  %134 = add nsw i32 %17, -1
  %135 = getelementptr inbounds %union.anon.54, %union.anon.54* %19, i64 0, i32 0
  %136 = load i32*, i32** %135, align 8
  %137 = select i1 %18, i32* %136, i32* %130
  %138 = icmp sgt i32 %17, 0
  br i1 %138, label %139, label %179

139:                                              ; preds = %129
  %140 = zext i32 %134 to i64
  %141 = zext i32 %17 to i64
  %142 = add nsw i64 %141, -1
  %143 = and i64 %141, 3
  %144 = icmp ult i64 %142, 3
  br i1 %144, label %160, label %145

145:                                              ; preds = %139
  %146 = sub nsw i64 %141, %143
  br label %147

147:                                              ; preds = %366, %145
  %148 = phi i64 [ 0, %145 ], [ %369, %366 ]
  %149 = phi i32 [ 1, %145 ], [ %368, %366 ]
  %150 = phi i64 [ %146, %145 ], [ %370, %366 ]
  %151 = icmp eq i64 %148, %140
  br i1 %151, label %155, label %152

152:                                              ; preds = %147
  %153 = getelementptr inbounds i32, i32* %137, i64 %148
  %154 = load i32, i32* %153, align 4
  br label %155

155:                                              ; preds = %152, %147
  %156 = phi i32 [ %154, %152 ], [ 1, %147 ]
  %157 = mul nsw i32 %156, %149
  %158 = or i64 %148, 1
  %159 = icmp eq i64 %158, %140
  br i1 %159, label %350, label %347

160:                                              ; preds = %366, %139
  %161 = phi i32 [ undef, %139 ], [ %368, %366 ]
  %162 = phi i64 [ 0, %139 ], [ %369, %366 ]
  %163 = phi i32 [ 1, %139 ], [ %368, %366 ]
  %164 = icmp eq i64 %143, 0
  br i1 %164, label %179, label %165

165:                                              ; preds = %160, %173
  %166 = phi i64 [ %176, %173 ], [ %162, %160 ]
  %167 = phi i32 [ %175, %173 ], [ %163, %160 ]
  %168 = phi i64 [ %177, %173 ], [ %143, %160 ]
  %169 = icmp eq i64 %166, %140
  br i1 %169, label %173, label %170

170:                                              ; preds = %165
  %171 = getelementptr inbounds i32, i32* %137, i64 %166
  %172 = load i32, i32* %171, align 4
  br label %173

173:                                              ; preds = %170, %165
  %174 = phi i32 [ %172, %170 ], [ 1, %165 ]
  %175 = mul nsw i32 %174, %167
  %176 = add nuw nsw i64 %166, 1
  %177 = add i64 %168, -1
  %178 = icmp eq i64 %177, 0
  br i1 %178, label %179, label %165, !llvm.loop !270

179:                                              ; preds = %160, %173, %129
  %180 = phi i32 [ 1, %129 ], [ %161, %160 ], [ %175, %173 ]
  %181 = add nsw i32 %133, -2
  %182 = icmp sgt i32 %133, 5
  %183 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %4, i64 0, i32 1
  %184 = getelementptr inbounds %union.anon.54, %union.anon.54* %183, i64 0, i32 0
  %185 = load i32*, i32** %184, align 8
  %186 = sext i32 %181 to i64
  %187 = getelementptr inbounds i32, i32* %185, i64 %186
  %188 = bitcast %union.anon.54* %183 to [5 x i32]*
  %189 = getelementptr inbounds [5 x i32], [5 x i32]* %188, i64 0, i64 %186
  %190 = select i1 %182, i32* %187, i32* %189
  %191 = load i32, i32* %190, align 4
  %192 = sext i32 %134 to i64
  %193 = getelementptr inbounds i32, i32* %136, i64 %192
  %194 = bitcast %union.anon.54* %19 to [5 x i32]*
  %195 = getelementptr inbounds [5 x i32], [5 x i32]* %194, i64 0, i64 %192
  %196 = select i1 %18, i32* %193, i32* %195
  %197 = load i32, i32* %196, align 4
  %198 = icmp slt i32 %197, %191
  %199 = select i1 %198, i32 %197, i32 %191
  %200 = add nsw i32 %133, -1
  %201 = sext i32 %200 to i64
  %202 = getelementptr inbounds i32, i32* %185, i64 %201
  %203 = getelementptr inbounds [5 x i32], [5 x i32]* %188, i64 0, i64 %201
  %204 = select i1 %182, i32* %202, i32* %203
  %205 = load i32, i32* %204, align 4
  %206 = getelementptr inbounds %struct.TfLiteSparsity, %struct.TfLiteSparsity* %0, i64 0, i32 2
  %207 = load %struct.TfLiteDimensionMetadata*, %struct.TfLiteDimensionMetadata** %206, align 8
  %208 = getelementptr inbounds %struct.TfLiteDimensionMetadata, %struct.TfLiteDimensionMetadata* %207, i64 0, i32 1
  %209 = load i32, i32* %208, align 4
  %210 = getelementptr inbounds %struct.TfLiteDimensionMetadata, %struct.TfLiteDimensionMetadata* %207, i64 1, i32 2
  %211 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %210, align 8
  %212 = getelementptr inbounds %struct.TfLiteDimensionMetadata, %struct.TfLiteDimensionMetadata* %207, i64 1, i32 3
  %213 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %212, align 8
  %214 = icmp sgt i32 %131, 0
  br i1 %214, label %215, label %218

215:                                              ; preds = %179
  %216 = zext i32 %131 to i64
  %217 = shl nuw nsw i64 %216, 2
  call void @llvm.memset.p0i8.i64(i8* align 4 %11, i8 0, i64 %217, i1 false)
  br label %218

218:                                              ; preds = %215, %179
  %219 = icmp sgt i32 %180, 0
  br i1 %219, label %220, label %329

220:                                              ; preds = %218
  %221 = icmp sgt i32 %209, 0
  %222 = sext i32 %199 to i64
  %223 = sext i32 %205 to i64
  %224 = zext i32 %180 to i64
  %225 = zext i32 %209 to i64
  %226 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %211, i64 0, i32 1, i64 0
  br label %227

227:                                              ; preds = %253, %220
  %228 = phi i64 [ 0, %220 ], [ %254, %253 ]
  br i1 %221, label %229, label %253

229:                                              ; preds = %227
  %230 = mul nsw i64 %228, %223
  %231 = mul nsw i64 %228, %222
  %232 = load i32, i32* %226, align 4
  br label %256

233:                                              ; preds = %253
  br i1 %219, label %234, label %329

234:                                              ; preds = %233
  %235 = icmp sgt i32 %199, 0
  %236 = sext i32 %199 to i64
  %237 = zext i32 %180 to i64
  %238 = getelementptr float, float* %7, i64 %236
  %239 = icmp ult i32 %199, 8
  %240 = and i64 %236, -8
  %241 = insertelement <4 x float> undef, float %13, i32 0
  %242 = shufflevector <4 x float> %241, <4 x float> undef, <4 x i32> zeroinitializer
  %243 = insertelement <4 x float> undef, float %13, i32 0
  %244 = shufflevector <4 x float> %243, <4 x float> undef, <4 x i32> zeroinitializer
  %245 = insertelement <4 x float> undef, float %15, i32 0
  %246 = shufflevector <4 x float> %245, <4 x float> undef, <4 x i32> zeroinitializer
  %247 = insertelement <4 x float> undef, float %15, i32 0
  %248 = shufflevector <4 x float> %247, <4 x float> undef, <4 x i32> zeroinitializer
  %249 = icmp eq i64 %240, %236
  br label %285

250:                                              ; preds = %268, %256
  %251 = phi i32 [ %261, %256 ], [ %282, %268 ]
  %252 = icmp eq i64 %259, %225
  br i1 %252, label %253, label %256

253:                                              ; preds = %250, %227
  %254 = add nuw nsw i64 %228, 1
  %255 = icmp eq i64 %254, %224
  br i1 %255, label %233, label %227

256:                                              ; preds = %250, %229
  %257 = phi i32 [ %232, %229 ], [ %251, %250 ]
  %258 = phi i64 [ 0, %229 ], [ %259, %250 ]
  %259 = add nuw nsw i64 %258, 1
  %260 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %211, i64 0, i32 1, i64 %259
  %261 = load i32, i32* %260, align 4
  %262 = icmp slt i32 %257, %261
  br i1 %262, label %263, label %250

263:                                              ; preds = %256
  %264 = add nsw i64 %258, %231
  %265 = getelementptr inbounds float, float* %9, i64 %264
  %266 = sext i32 %257 to i64
  %267 = load float, float* %265, align 4
  br label %268

268:                                              ; preds = %263, %268
  %269 = phi float [ %267, %263 ], [ %280, %268 ]
  %270 = phi i64 [ %266, %263 ], [ %281, %268 ]
  %271 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %213, i64 0, i32 1, i64 %270
  %272 = load i32, i32* %271, align 4
  %273 = getelementptr inbounds float, float* %5, i64 %270
  %274 = load float, float* %273, align 4
  %275 = sext i32 %272 to i64
  %276 = add nsw i64 %230, %275
  %277 = getelementptr inbounds float, float* %3, i64 %276
  %278 = load float, float* %277, align 4
  %279 = fmul float %274, %278
  %280 = fadd float %269, %279
  store float %280, float* %265, align 4
  %281 = add nsw i64 %270, 1
  %282 = load i32, i32* %260, align 4
  %283 = sext i32 %282 to i64
  %284 = icmp slt i64 %281, %283
  br i1 %284, label %268, label %250

285:                                              ; preds = %330, %234
  %286 = phi i64 [ 0, %234 ], [ %331, %330 ]
  %287 = mul i64 %286, %236
  %288 = getelementptr float, float* %9, i64 %287
  %289 = add i64 %287, %236
  %290 = getelementptr float, float* %9, i64 %289
  br i1 %235, label %291, label %330

291:                                              ; preds = %285
  %292 = mul nsw i64 %286, %236
  br i1 %239, label %293, label %295

293:                                              ; preds = %328, %295, %291
  %294 = phi i64 [ 0, %295 ], [ 0, %291 ], [ %240, %328 ]
  br label %333

295:                                              ; preds = %291
  %296 = icmp ult float* %288, %238
  %297 = icmp ugt float* %290, %7
  %298 = and i1 %296, %297
  br i1 %298, label %293, label %299

299:                                              ; preds = %295, %299
  %300 = phi i64 [ %326, %299 ], [ 0, %295 ]
  %301 = add nsw i64 %300, %292
  %302 = getelementptr inbounds float, float* %9, i64 %301
  %303 = bitcast float* %302 to <4 x float>*
  %304 = load <4 x float>, <4 x float>* %303, align 4, !alias.scope !271, !noalias !274
  %305 = getelementptr inbounds float, float* %302, i64 4
  %306 = bitcast float* %305 to <4 x float>*
  %307 = load <4 x float>, <4 x float>* %306, align 4, !alias.scope !271, !noalias !274
  %308 = getelementptr inbounds float, float* %7, i64 %300
  %309 = bitcast float* %308 to <4 x float>*
  %310 = load <4 x float>, <4 x float>* %309, align 4, !alias.scope !274
  %311 = getelementptr inbounds float, float* %308, i64 4
  %312 = bitcast float* %311 to <4 x float>*
  %313 = load <4 x float>, <4 x float>* %312, align 4, !alias.scope !274
  %314 = fadd <4 x float> %304, %310
  %315 = fadd <4 x float> %307, %313
  %316 = fcmp olt <4 x float> %314, %242
  %317 = fcmp olt <4 x float> %315, %244
  %318 = select <4 x i1> %316, <4 x float> %242, <4 x float> %314
  %319 = select <4 x i1> %317, <4 x float> %244, <4 x float> %315
  %320 = fcmp ogt <4 x float> %318, %246
  %321 = fcmp ogt <4 x float> %319, %248
  %322 = select <4 x i1> %320, <4 x float> %246, <4 x float> %318
  %323 = select <4 x i1> %321, <4 x float> %248, <4 x float> %319
  %324 = bitcast float* %302 to <4 x float>*
  store <4 x float> %322, <4 x float>* %324, align 4, !alias.scope !271, !noalias !274
  %325 = bitcast float* %305 to <4 x float>*
  store <4 x float> %323, <4 x float>* %325, align 4, !alias.scope !271, !noalias !274
  %326 = add i64 %300, 8
  %327 = icmp eq i64 %326, %240
  br i1 %327, label %328, label %299, !llvm.loop !276

328:                                              ; preds = %299
  br i1 %249, label %330, label %293

329:                                              ; preds = %330, %218, %233
  ret void

330:                                              ; preds = %333, %328, %285
  %331 = add nuw nsw i64 %286, 1
  %332 = icmp eq i64 %331, %237
  br i1 %332, label %329, label %285

333:                                              ; preds = %293, %333
  %334 = phi i64 [ %345, %333 ], [ %294, %293 ]
  %335 = add nsw i64 %334, %292
  %336 = getelementptr inbounds float, float* %9, i64 %335
  %337 = load float, float* %336, align 4
  %338 = getelementptr inbounds float, float* %7, i64 %334
  %339 = load float, float* %338, align 4
  %340 = fadd float %337, %339
  %341 = fcmp olt float %340, %13
  %342 = select i1 %341, float %13, float %340
  %343 = fcmp ogt float %342, %15
  %344 = select i1 %343, float %15, float %342
  store float %344, float* %336, align 4
  %345 = add nuw nsw i64 %334, 1
  %346 = icmp slt i64 %345, %236
  br i1 %346, label %333, label %330, !llvm.loop !277

347:                                              ; preds = %155
  %348 = getelementptr inbounds i32, i32* %137, i64 %158
  %349 = load i32, i32* %348, align 4
  br label %350

350:                                              ; preds = %347, %155
  %351 = phi i32 [ %349, %347 ], [ 1, %155 ]
  %352 = mul nsw i32 %351, %157
  %353 = or i64 %148, 2
  %354 = icmp eq i64 %353, %140
  br i1 %354, label %358, label %355

355:                                              ; preds = %350
  %356 = getelementptr inbounds i32, i32* %137, i64 %353
  %357 = load i32, i32* %356, align 4
  br label %358

358:                                              ; preds = %355, %350
  %359 = phi i32 [ %357, %355 ], [ 1, %350 ]
  %360 = mul nsw i32 %359, %352
  %361 = or i64 %148, 3
  %362 = icmp eq i64 %361, %140
  br i1 %362, label %366, label %363

363:                                              ; preds = %358
  %364 = getelementptr inbounds i32, i32* %137, i64 %361
  %365 = load i32, i32* %364, align 4
  br label %366

366:                                              ; preds = %363, %358
  %367 = phi i32 [ %365, %363 ], [ 1, %358 ]
  %368 = mul nsw i32 %367, %360
  %369 = add nuw nsw i64 %148, 4
  %370 = add i64 %150, -4
  %371 = icmp eq i64 %370, 0
  br i1 %371, label %160, label %147
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN6tflite13optimized_ops29FullyConnectedSparseWeight1x4ERK14TfLiteSparsityRKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKfS9_SB_S9_SB_S9_PfPNS_17CpuBackendContextE(%struct.TfLiteSparsity* dereferenceable(32), %"struct.tflite::FullyConnectedParams"* dereferenceable(40), %"class.tflite::RuntimeShape"* dereferenceable(32), float*, %"class.tflite::RuntimeShape"* dereferenceable(32), float*, %"class.tflite::RuntimeShape"* dereferenceable(32), float*, %"class.tflite::RuntimeShape"* dereferenceable(32), float*, %"class.tflite::CpuBackendContext"*) local_unnamed_addr #4 comdat {
  %12 = alloca float*, align 8
  %13 = alloca float*, align 8
  %14 = alloca float*, align 8
  %15 = alloca float*, align 8
  %16 = alloca %"class.std::__1::vector.85", align 8
  %17 = alloca i32, align 4
  %18 = alloca i32, align 4
  store float* %3, float** %12, align 8
  store float* %5, float** %13, align 8
  store float* %7, float** %14, align 8
  store float* %9, float** %15, align 8
  %19 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %8, i64 0, i32 0
  %20 = load i32, i32* %19, align 8
  %21 = icmp sgt i32 %20, 5
  %22 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %8, i64 0, i32 1
  %23 = bitcast float* %9 to i8*
  br i1 %21, label %24, label %27

24:                                               ; preds = %11
  %25 = getelementptr inbounds %union.anon.54, %union.anon.54* %22, i64 0, i32 0
  %26 = load i32*, i32** %25, align 8
  br label %30

27:                                               ; preds = %11
  %28 = bitcast %union.anon.54* %22 to i32*
  %29 = icmp sgt i32 %20, 0
  br i1 %29, label %30, label %135

30:                                               ; preds = %27, %24
  %31 = phi i32* [ %26, %24 ], [ %28, %27 ]
  %32 = zext i32 %20 to i64
  %33 = icmp ult i32 %20, 8
  br i1 %33, label %119, label %34

34:                                               ; preds = %30
  %35 = and i64 %32, 4294967288
  %36 = add nsw i64 %35, -8
  %37 = lshr exact i64 %36, 3
  %38 = add nuw nsw i64 %37, 1
  %39 = and i64 %38, 3
  %40 = icmp ult i64 %36, 24
  br i1 %40, label %86, label %41

41:                                               ; preds = %34
  %42 = sub nsw i64 %38, %39
  br label %43

43:                                               ; preds = %43, %41
  %44 = phi i64 [ 0, %41 ], [ %83, %43 ]
  %45 = phi <4 x i32> [ <i32 1, i32 1, i32 1, i32 1>, %41 ], [ %81, %43 ]
  %46 = phi <4 x i32> [ <i32 1, i32 1, i32 1, i32 1>, %41 ], [ %82, %43 ]
  %47 = phi i64 [ %42, %41 ], [ %84, %43 ]
  %48 = getelementptr inbounds i32, i32* %31, i64 %44
  %49 = bitcast i32* %48 to <4 x i32>*
  %50 = load <4 x i32>, <4 x i32>* %49, align 4
  %51 = getelementptr inbounds i32, i32* %48, i64 4
  %52 = bitcast i32* %51 to <4 x i32>*
  %53 = load <4 x i32>, <4 x i32>* %52, align 4
  %54 = mul nsw <4 x i32> %50, %45
  %55 = mul nsw <4 x i32> %53, %46
  %56 = or i64 %44, 8
  %57 = getelementptr inbounds i32, i32* %31, i64 %56
  %58 = bitcast i32* %57 to <4 x i32>*
  %59 = load <4 x i32>, <4 x i32>* %58, align 4
  %60 = getelementptr inbounds i32, i32* %57, i64 4
  %61 = bitcast i32* %60 to <4 x i32>*
  %62 = load <4 x i32>, <4 x i32>* %61, align 4
  %63 = mul nsw <4 x i32> %59, %54
  %64 = mul nsw <4 x i32> %62, %55
  %65 = or i64 %44, 16
  %66 = getelementptr inbounds i32, i32* %31, i64 %65
  %67 = bitcast i32* %66 to <4 x i32>*
  %68 = load <4 x i32>, <4 x i32>* %67, align 4
  %69 = getelementptr inbounds i32, i32* %66, i64 4
  %70 = bitcast i32* %69 to <4 x i32>*
  %71 = load <4 x i32>, <4 x i32>* %70, align 4
  %72 = mul nsw <4 x i32> %68, %63
  %73 = mul nsw <4 x i32> %71, %64
  %74 = or i64 %44, 24
  %75 = getelementptr inbounds i32, i32* %31, i64 %74
  %76 = bitcast i32* %75 to <4 x i32>*
  %77 = load <4 x i32>, <4 x i32>* %76, align 4
  %78 = getelementptr inbounds i32, i32* %75, i64 4
  %79 = bitcast i32* %78 to <4 x i32>*
  %80 = load <4 x i32>, <4 x i32>* %79, align 4
  %81 = mul nsw <4 x i32> %77, %72
  %82 = mul nsw <4 x i32> %80, %73
  %83 = add i64 %44, 32
  %84 = add i64 %47, -4
  %85 = icmp eq i64 %84, 0
  br i1 %85, label %86, label %43, !llvm.loop !278

86:                                               ; preds = %43, %34
  %87 = phi <4 x i32> [ undef, %34 ], [ %81, %43 ]
  %88 = phi <4 x i32> [ undef, %34 ], [ %82, %43 ]
  %89 = phi i64 [ 0, %34 ], [ %83, %43 ]
  %90 = phi <4 x i32> [ <i32 1, i32 1, i32 1, i32 1>, %34 ], [ %81, %43 ]
  %91 = phi <4 x i32> [ <i32 1, i32 1, i32 1, i32 1>, %34 ], [ %82, %43 ]
  %92 = icmp eq i64 %39, 0
  br i1 %92, label %109, label %93

93:                                               ; preds = %86, %93
  %94 = phi i64 [ %106, %93 ], [ %89, %86 ]
  %95 = phi <4 x i32> [ %104, %93 ], [ %90, %86 ]
  %96 = phi <4 x i32> [ %105, %93 ], [ %91, %86 ]
  %97 = phi i64 [ %107, %93 ], [ %39, %86 ]
  %98 = getelementptr inbounds i32, i32* %31, i64 %94
  %99 = bitcast i32* %98 to <4 x i32>*
  %100 = load <4 x i32>, <4 x i32>* %99, align 4
  %101 = getelementptr inbounds i32, i32* %98, i64 4
  %102 = bitcast i32* %101 to <4 x i32>*
  %103 = load <4 x i32>, <4 x i32>* %102, align 4
  %104 = mul nsw <4 x i32> %100, %95
  %105 = mul nsw <4 x i32> %103, %96
  %106 = add i64 %94, 8
  %107 = add i64 %97, -1
  %108 = icmp eq i64 %107, 0
  br i1 %108, label %109, label %93, !llvm.loop !279

109:                                              ; preds = %93, %86
  %110 = phi <4 x i32> [ %87, %86 ], [ %104, %93 ]
  %111 = phi <4 x i32> [ %88, %86 ], [ %105, %93 ]
  %112 = mul <4 x i32> %111, %110
  %113 = shufflevector <4 x i32> %112, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %114 = mul <4 x i32> %112, %113
  %115 = shufflevector <4 x i32> %114, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %116 = mul <4 x i32> %114, %115
  %117 = extractelement <4 x i32> %116, i32 0
  %118 = icmp eq i64 %35, %32
  br i1 %118, label %130, label %119

119:                                              ; preds = %109, %30
  %120 = phi i64 [ 0, %30 ], [ %35, %109 ]
  %121 = phi i32 [ 1, %30 ], [ %117, %109 ]
  br label %122

122:                                              ; preds = %119, %122
  %123 = phi i64 [ %128, %122 ], [ %120, %119 ]
  %124 = phi i32 [ %127, %122 ], [ %121, %119 ]
  %125 = getelementptr inbounds i32, i32* %31, i64 %123
  %126 = load i32, i32* %125, align 4
  %127 = mul nsw i32 %126, %124
  %128 = add nuw nsw i64 %123, 1
  %129 = icmp eq i64 %128, %32
  br i1 %129, label %130, label %122, !llvm.loop !280

130:                                              ; preds = %122, %109
  %131 = phi i32 [ %117, %109 ], [ %127, %122 ]
  %132 = bitcast %union.anon.54* %22 to i32*
  %133 = sext i32 %131 to i64
  %134 = shl nsw i64 %133, 2
  br label %135

135:                                              ; preds = %130, %27
  %136 = phi i32* [ %132, %130 ], [ %28, %27 ]
  %137 = phi i64 [ %134, %130 ], [ 4, %27 ]
  tail call void @llvm.memset.p0i8.i64(i8* align 4 %23, i8 0, i64 %137, i1 false)
  %138 = getelementptr inbounds %"class.tflite::CpuBackendContext", %"class.tflite::CpuBackendContext"* %10, i64 0, i32 3
  %139 = load i32, i32* %138, align 8
  %140 = load i32, i32* %19, align 8
  %141 = add nsw i32 %140, -1
  %142 = icmp sgt i32 %140, 5
  %143 = getelementptr inbounds %union.anon.54, %union.anon.54* %22, i64 0, i32 0
  %144 = load i32*, i32** %143, align 8
  %145 = select i1 %142, i32* %144, i32* %136
  %146 = icmp sgt i32 %140, 0
  br i1 %146, label %147, label %187

147:                                              ; preds = %135
  %148 = zext i32 %141 to i64
  %149 = zext i32 %140 to i64
  %150 = add nsw i64 %149, -1
  %151 = and i64 %149, 3
  %152 = icmp ult i64 %150, 3
  br i1 %152, label %168, label %153

153:                                              ; preds = %147
  %154 = sub nsw i64 %149, %151
  br label %155

155:                                              ; preds = %429, %153
  %156 = phi i64 [ 0, %153 ], [ %432, %429 ]
  %157 = phi i32 [ 1, %153 ], [ %431, %429 ]
  %158 = phi i64 [ %154, %153 ], [ %433, %429 ]
  %159 = icmp eq i64 %156, %148
  br i1 %159, label %163, label %160

160:                                              ; preds = %155
  %161 = getelementptr inbounds i32, i32* %145, i64 %156
  %162 = load i32, i32* %161, align 4
  br label %163

163:                                              ; preds = %160, %155
  %164 = phi i32 [ %162, %160 ], [ 1, %155 ]
  %165 = mul nsw i32 %164, %157
  %166 = or i64 %156, 1
  %167 = icmp eq i64 %166, %148
  br i1 %167, label %413, label %410

168:                                              ; preds = %429, %147
  %169 = phi i32 [ undef, %147 ], [ %431, %429 ]
  %170 = phi i64 [ 0, %147 ], [ %432, %429 ]
  %171 = phi i32 [ 1, %147 ], [ %431, %429 ]
  %172 = icmp eq i64 %151, 0
  br i1 %172, label %187, label %173

173:                                              ; preds = %168, %181
  %174 = phi i64 [ %184, %181 ], [ %170, %168 ]
  %175 = phi i32 [ %183, %181 ], [ %171, %168 ]
  %176 = phi i64 [ %185, %181 ], [ %151, %168 ]
  %177 = icmp eq i64 %174, %148
  br i1 %177, label %181, label %178

178:                                              ; preds = %173
  %179 = getelementptr inbounds i32, i32* %145, i64 %174
  %180 = load i32, i32* %179, align 4
  br label %181

181:                                              ; preds = %178, %173
  %182 = phi i32 [ %180, %178 ], [ 1, %173 ]
  %183 = mul nsw i32 %182, %175
  %184 = add nuw nsw i64 %174, 1
  %185 = add i64 %176, -1
  %186 = icmp eq i64 %185, 0
  br i1 %186, label %187, label %173, !llvm.loop !281

187:                                              ; preds = %168, %181, %135
  %188 = phi i32 [ 1, %135 ], [ %169, %168 ], [ %183, %181 ]
  %189 = icmp slt i32 %139, %188
  %190 = select i1 %189, i32 %139, i32 %188
  %191 = icmp slt i32 %190, 2
  br i1 %191, label %192, label %311

192:                                              ; preds = %187
  %193 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %1, i64 0, i32 7
  %194 = load float, float* %193, align 4
  %195 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %1, i64 0, i32 8
  %196 = load float, float* %195, align 4
  %197 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %4, i64 0, i32 0
  %198 = load i32, i32* %197, align 8
  %199 = icmp sgt i32 %198, 5
  %200 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %4, i64 0, i32 1
  %201 = getelementptr inbounds %union.anon.54, %union.anon.54* %200, i64 0, i32 0
  %202 = load i32*, i32** %201, align 8
  %203 = bitcast %union.anon.54* %200 to [5 x i32]*
  %204 = add nsw i32 %198, -2
  %205 = sext i32 %204 to i64
  %206 = getelementptr inbounds i32, i32* %202, i64 %205
  %207 = getelementptr inbounds [5 x i32], [5 x i32]* %203, i64 0, i64 %205
  %208 = select i1 %199, i32* %206, i32* %207
  %209 = load i32, i32* %208, align 4
  %210 = sext i32 %141 to i64
  %211 = getelementptr inbounds i32, i32* %144, i64 %210
  %212 = bitcast %union.anon.54* %22 to [5 x i32]*
  %213 = getelementptr inbounds [5 x i32], [5 x i32]* %212, i64 0, i64 %210
  %214 = select i1 %142, i32* %211, i32* %213
  %215 = load i32, i32* %214, align 4
  %216 = icmp slt i32 %215, %209
  %217 = select i1 %216, i32 %215, i32 %209
  %218 = getelementptr inbounds %struct.TfLiteSparsity, %struct.TfLiteSparsity* %0, i64 0, i32 2
  %219 = load %struct.TfLiteDimensionMetadata*, %struct.TfLiteDimensionMetadata** %218, align 8
  %220 = getelementptr inbounds %struct.TfLiteDimensionMetadata, %struct.TfLiteDimensionMetadata* %219, i64 1, i32 2
  %221 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %220, align 8
  %222 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %221, i64 0, i32 1, i64 0
  %223 = getelementptr inbounds %struct.TfLiteDimensionMetadata, %struct.TfLiteDimensionMetadata* %219, i64 1, i32 3
  %224 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %223, align 8
  %225 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %224, i64 0, i32 1, i64 0
  %226 = getelementptr inbounds i32, i32* %202, i64 1
  %227 = bitcast %union.anon.54* %200 to i32*
  %228 = getelementptr inbounds [5 x i32], [5 x i32]* %203, i64 0, i64 1
  %229 = select i1 %199, i32* %202, i32* %227
  %230 = select i1 %199, i32* %226, i32* %228
  %231 = load i32, i32* %229, align 4
  %232 = load i32, i32* %230, align 4
  tail call void @_ZN6tflite12tensor_utils44SparseMatrixBatchVectorMultiplyAccumulate1x4EPKfPKiS4_iiS2_iPf(float* %5, i32* %222, i32* %225, i32 %231, i32 %232, float* %3, i32 %188, float* %9) #19
  %233 = icmp sgt i32 %188, 0
  br i1 %233, label %234, label %409

234:                                              ; preds = %192
  %235 = icmp sgt i32 %217, 0
  %236 = sext i32 %217 to i64
  %237 = sext i32 %188 to i64
  %238 = getelementptr float, float* %7, i64 %236
  %239 = icmp ult i32 %217, 8
  %240 = and i64 %236, -8
  %241 = insertelement <4 x float> undef, float %194, i32 0
  %242 = shufflevector <4 x float> %241, <4 x float> undef, <4 x i32> zeroinitializer
  %243 = insertelement <4 x float> undef, float %194, i32 0
  %244 = shufflevector <4 x float> %243, <4 x float> undef, <4 x i32> zeroinitializer
  %245 = insertelement <4 x float> undef, float %196, i32 0
  %246 = shufflevector <4 x float> %245, <4 x float> undef, <4 x i32> zeroinitializer
  %247 = insertelement <4 x float> undef, float %196, i32 0
  %248 = shufflevector <4 x float> %247, <4 x float> undef, <4 x i32> zeroinitializer
  %249 = icmp eq i64 %240, %236
  br label %250

250:                                              ; preds = %294, %234
  %251 = phi i64 [ 0, %234 ], [ %295, %294 ]
  %252 = mul i64 %251, %236
  %253 = getelementptr float, float* %9, i64 %252
  %254 = add i64 %252, %236
  %255 = getelementptr float, float* %9, i64 %254
  br i1 %235, label %256, label %294

256:                                              ; preds = %250
  %257 = mul nsw i64 %251, %236
  br i1 %239, label %258, label %260

258:                                              ; preds = %293, %260, %256
  %259 = phi i64 [ 0, %260 ], [ 0, %256 ], [ %240, %293 ]
  br label %297

260:                                              ; preds = %256
  %261 = icmp ult float* %253, %238
  %262 = icmp ugt float* %255, %7
  %263 = and i1 %261, %262
  br i1 %263, label %258, label %264

264:                                              ; preds = %260, %264
  %265 = phi i64 [ %291, %264 ], [ 0, %260 ]
  %266 = add nsw i64 %265, %257
  %267 = getelementptr inbounds float, float* %9, i64 %266
  %268 = bitcast float* %267 to <4 x float>*
  %269 = load <4 x float>, <4 x float>* %268, align 4, !alias.scope !282, !noalias !285
  %270 = getelementptr inbounds float, float* %267, i64 4
  %271 = bitcast float* %270 to <4 x float>*
  %272 = load <4 x float>, <4 x float>* %271, align 4, !alias.scope !282, !noalias !285
  %273 = getelementptr inbounds float, float* %7, i64 %265
  %274 = bitcast float* %273 to <4 x float>*
  %275 = load <4 x float>, <4 x float>* %274, align 4, !alias.scope !285
  %276 = getelementptr inbounds float, float* %273, i64 4
  %277 = bitcast float* %276 to <4 x float>*
  %278 = load <4 x float>, <4 x float>* %277, align 4, !alias.scope !285
  %279 = fadd <4 x float> %269, %275
  %280 = fadd <4 x float> %272, %278
  %281 = fcmp olt <4 x float> %279, %242
  %282 = fcmp olt <4 x float> %280, %244
  %283 = select <4 x i1> %281, <4 x float> %242, <4 x float> %279
  %284 = select <4 x i1> %282, <4 x float> %244, <4 x float> %280
  %285 = fcmp ogt <4 x float> %283, %246
  %286 = fcmp ogt <4 x float> %284, %248
  %287 = select <4 x i1> %285, <4 x float> %246, <4 x float> %283
  %288 = select <4 x i1> %286, <4 x float> %248, <4 x float> %284
  %289 = bitcast float* %267 to <4 x float>*
  store <4 x float> %287, <4 x float>* %289, align 4, !alias.scope !282, !noalias !285
  %290 = bitcast float* %270 to <4 x float>*
  store <4 x float> %288, <4 x float>* %290, align 4, !alias.scope !282, !noalias !285
  %291 = add i64 %265, 8
  %292 = icmp eq i64 %291, %240
  br i1 %292, label %293, label %264, !llvm.loop !287

293:                                              ; preds = %264
  br i1 %249, label %294, label %258

294:                                              ; preds = %297, %293, %250
  %295 = add nuw nsw i64 %251, 1
  %296 = icmp eq i64 %295, %237
  br i1 %296, label %409, label %250

297:                                              ; preds = %258, %297
  %298 = phi i64 [ %309, %297 ], [ %259, %258 ]
  %299 = add nsw i64 %298, %257
  %300 = getelementptr inbounds float, float* %9, i64 %299
  %301 = load float, float* %300, align 4
  %302 = getelementptr inbounds float, float* %7, i64 %298
  %303 = load float, float* %302, align 4
  %304 = fadd float %301, %303
  %305 = fcmp olt float %304, %194
  %306 = select i1 %305, float %194, float %304
  %307 = fcmp ogt float %306, %196
  %308 = select i1 %307, float %196, float %306
  store float %308, float* %300, align 4
  %309 = add nuw nsw i64 %298, 1
  %310 = icmp slt i64 %309, %236
  br i1 %310, label %297, label %294, !llvm.loop !288

311:                                              ; preds = %187
  %312 = bitcast %"class.std::__1::vector.85"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %312) #19
  %313 = getelementptr inbounds %"class.std::__1::vector.85", %"class.std::__1::vector.85"* %16, i64 0, i32 0, i32 0
  %314 = getelementptr inbounds %"class.std::__1::vector.85", %"class.std::__1::vector.85"* %16, i64 0, i32 0, i32 1
  %315 = getelementptr inbounds %"class.std::__1::vector.85", %"class.std::__1::vector.85"* %16, i64 0, i32 0, i32 2, i32 0, i32 0
  %316 = sext i32 %190 to i64
  %317 = bitcast %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"** %315 to i64*
  %318 = bitcast %"class.std::__1::vector.85"* %16 to i64*
  %319 = bitcast %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"** %314 to i64*
  %320 = mul nsw i64 %316, 112
  %321 = tail call i8* @_Znwm(i64 %320) #18
  %322 = bitcast i8* %321 to %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"*
  %323 = ptrtoint i8* %321 to i64
  %324 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %322, i64 %316
  %325 = ptrtoint %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %324 to i64
  store i64 %323, i64* %318, align 8
  store i64 %323, i64* %319, align 8
  store i64 %325, i64* %317, align 8
  %326 = bitcast i32* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %326) #19
  store i32 0, i32* %17, align 4
  %327 = bitcast i32* %18 to i8*
  %328 = sdiv i32 %188, %190
  %329 = srem i32 %188, %190
  %330 = bitcast float** %12 to i64*
  %331 = bitcast float** %13 to i64*
  %332 = bitcast float** %14 to i64*
  %333 = bitcast float** %15 to i64*
  %334 = bitcast %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"** %314 to i64*
  br label %364

335:                                              ; preds = %402
  %336 = load i64, i64* %334, align 8
  %337 = load i64, i64* %318, align 8
  %338 = sub i64 %336, %337
  %339 = sdiv exact i64 %338, 112
  %340 = trunc i64 %339 to i32
  %341 = inttoptr i64 %337 to %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"*
  %342 = getelementptr inbounds %"class.tflite::CpuBackendContext", %"class.tflite::CpuBackendContext"* %10, i64 0, i32 2, i32 0, i32 0, i32 0
  %343 = load %"class.gemmlowp::GemmContext"*, %"class.gemmlowp::GemmContext"** %342, align 8
  %344 = getelementptr inbounds %"class.gemmlowp::GemmContext", %"class.gemmlowp::GemmContext"* %343, i64 0, i32 0, i32 1
  call void @_ZN8gemmlowp11WorkersPool7ExecuteIN6tflite13optimized_ops33FullyConnectedSparseWeight1x4TaskEEEviPT_(%"class.gemmlowp::WorkersPool"* %344, i32 %340, %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %341) #19
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %326) #19
  %345 = load %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"*, %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"** %313, align 8
  %346 = icmp eq %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %345, null
  br i1 %346, label %363, label %347

347:                                              ; preds = %335
  %348 = bitcast %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %345 to i8*
  %349 = load %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"*, %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"** %314, align 8
  %350 = icmp eq %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %349, %345
  br i1 %350, label %361, label %351

351:                                              ; preds = %347, %351
  %352 = phi %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* [ %353, %351 ], [ %349, %347 ]
  %353 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %352, i64 -1
  %354 = bitcast %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %353 to void (%"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"*)***
  %355 = load void (%"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"*)**, void (%"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"*)*** %354, align 8
  %356 = load void (%"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"*)*, void (%"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"*)** %355, align 8
  call void %356(%"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %353) #19
  %357 = icmp eq %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %353, %345
  br i1 %357, label %358, label %351

358:                                              ; preds = %351
  %359 = bitcast %"class.std::__1::vector.85"* %16 to i8**
  %360 = load i8*, i8** %359, align 8
  br label %361

361:                                              ; preds = %358, %347
  %362 = phi i8* [ %360, %358 ], [ %348, %347 ]
  store %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %345, %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"** %314, align 8
  call void @_ZdlPv(i8* %362) #18
  br label %363

363:                                              ; preds = %335, %361
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %312) #19
  br label %409

364:                                              ; preds = %406, %311
  %365 = phi %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* [ %324, %311 ], [ %408, %406 ]
  %366 = phi %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* [ %322, %311 ], [ %407, %406 ]
  %367 = phi i32 [ 0, %311 ], [ %403, %406 ]
  %368 = phi i32 [ 0, %311 ], [ %404, %406 ]
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %327) #19
  %369 = add nsw i32 %328, %367
  %370 = icmp slt i32 %368, %329
  %371 = zext i1 %370 to i32
  %372 = add nsw i32 %369, %371
  store i32 %372, i32* %18, align 4
  %373 = icmp ult %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %366, %365
  br i1 %373, label %374, label %400

374:                                              ; preds = %364
  %375 = load i64, i64* %330, align 8
  %376 = load i64, i64* %331, align 8
  %377 = load i64, i64* %332, align 8
  %378 = load i64, i64* %333, align 8
  %379 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %366, i64 0, i32 0, i32 0
  %380 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %366, i64 0, i32 0, i32 1
  store %"class.gemmlowp::Allocator"* null, %"class.gemmlowp::Allocator"** %380, align 8
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVN6tflite13optimized_ops33FullyConnectedSparseWeight1x4TaskE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %379, align 8
  %381 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %366, i64 0, i32 1
  store %struct.TfLiteSparsity* %0, %struct.TfLiteSparsity** %381, align 8
  %382 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %366, i64 0, i32 2
  store %"struct.tflite::FullyConnectedParams"* %1, %"struct.tflite::FullyConnectedParams"** %382, align 8
  %383 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %366, i64 0, i32 3
  store %"class.tflite::RuntimeShape"* %2, %"class.tflite::RuntimeShape"** %383, align 8
  %384 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %366, i64 0, i32 4
  %385 = bitcast float** %384 to i64*
  store i64 %375, i64* %385, align 8
  %386 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %366, i64 0, i32 5
  store %"class.tflite::RuntimeShape"* %4, %"class.tflite::RuntimeShape"** %386, align 8
  %387 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %366, i64 0, i32 6
  %388 = bitcast float** %387 to i64*
  store i64 %376, i64* %388, align 8
  %389 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %366, i64 0, i32 7
  store %"class.tflite::RuntimeShape"* %6, %"class.tflite::RuntimeShape"** %389, align 8
  %390 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %366, i64 0, i32 8
  %391 = bitcast float** %390 to i64*
  store i64 %377, i64* %391, align 8
  %392 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %366, i64 0, i32 9
  store %"class.tflite::RuntimeShape"* %8, %"class.tflite::RuntimeShape"** %392, align 8
  %393 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %366, i64 0, i32 10
  %394 = bitcast float** %393 to i64*
  store i64 %378, i64* %394, align 8
  %395 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %366, i64 0, i32 11
  store i32 %367, i32* %395, align 8
  %396 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %366, i64 0, i32 12
  store i32 %372, i32* %396, align 4
  %397 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %366, i64 0, i32 13
  store %"class.tflite::CpuBackendContext"* %10, %"class.tflite::CpuBackendContext"** %397, align 8
  %398 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %366, i64 1
  %399 = ptrtoint %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %398 to i64
  store i64 %399, i64* %334, align 8
  br label %402

400:                                              ; preds = %364
  call void @_ZNSt3__16vectorIN6tflite13optimized_ops33FullyConnectedSparseWeight1x4TaskENS_9allocatorIS3_EEE24__emplace_back_slow_pathIJRK14TfLiteSparsityRKNS1_20FullyConnectedParamsERKNS1_12RuntimeShapeERPKfSG_SJ_SG_SJ_SG_RPfRiSM_RNS1_17CpuBackendContextEEEEvDpOT_(%"class.std::__1::vector.85"* nonnull %16, %struct.TfLiteSparsity* dereferenceable(32) %0, %"struct.tflite::FullyConnectedParams"* dereferenceable(40) %1, %"class.tflite::RuntimeShape"* dereferenceable(32) %2, float** nonnull dereferenceable(8) %12, %"class.tflite::RuntimeShape"* dereferenceable(32) %4, float** nonnull dereferenceable(8) %13, %"class.tflite::RuntimeShape"* dereferenceable(32) %6, float** nonnull dereferenceable(8) %14, %"class.tflite::RuntimeShape"* dereferenceable(32) %8, float** nonnull dereferenceable(8) %15, i32* nonnull dereferenceable(4) %17, i32* nonnull dereferenceable(4) %18, %"class.tflite::CpuBackendContext"* dereferenceable(32) %10) #19
  %401 = load i32, i32* %18, align 4
  br label %402

402:                                              ; preds = %374, %400
  %403 = phi i32 [ %372, %374 ], [ %401, %400 ]
  store i32 %403, i32* %17, align 4
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %327) #19
  %404 = add nuw nsw i32 %368, 1
  %405 = icmp slt i32 %404, %190
  br i1 %405, label %406, label %335

406:                                              ; preds = %402
  %407 = load %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"*, %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"** %314, align 8
  %408 = load %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"*, %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"** %315, align 8
  br label %364

409:                                              ; preds = %294, %192, %363
  ret void

410:                                              ; preds = %163
  %411 = getelementptr inbounds i32, i32* %145, i64 %166
  %412 = load i32, i32* %411, align 4
  br label %413

413:                                              ; preds = %410, %163
  %414 = phi i32 [ %412, %410 ], [ 1, %163 ]
  %415 = mul nsw i32 %414, %165
  %416 = or i64 %156, 2
  %417 = icmp eq i64 %416, %148
  br i1 %417, label %421, label %418

418:                                              ; preds = %413
  %419 = getelementptr inbounds i32, i32* %145, i64 %416
  %420 = load i32, i32* %419, align 4
  br label %421

421:                                              ; preds = %418, %413
  %422 = phi i32 [ %420, %418 ], [ 1, %413 ]
  %423 = mul nsw i32 %422, %415
  %424 = or i64 %156, 3
  %425 = icmp eq i64 %424, %148
  br i1 %425, label %429, label %426

426:                                              ; preds = %421
  %427 = getelementptr inbounds i32, i32* %145, i64 %424
  %428 = load i32, i32* %427, align 4
  br label %429

429:                                              ; preds = %426, %421
  %430 = phi i32 [ %428, %426 ], [ 1, %421 ]
  %431 = mul nsw i32 %430, %423
  %432 = add nuw nsw i64 %156, 4
  %433 = add i64 %158, -4
  %434 = icmp eq i64 %433, 0
  br i1 %434, label %168, label %155
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN6tflite13optimized_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKfS6_S8_S6_S8_S6_PfPNS_17CpuBackendContextE(%"struct.tflite::FullyConnectedParams"* dereferenceable(40), %"class.tflite::RuntimeShape"* dereferenceable(32), float*, %"class.tflite::RuntimeShape"* dereferenceable(32), float*, %"class.tflite::RuntimeShape"* dereferenceable(32), float*, %"class.tflite::RuntimeShape"* dereferenceable(32), float*, %"class.tflite::CpuBackendContext"*) local_unnamed_addr #4 comdat {
  %11 = alloca %"struct.tflite::cpu_backend_gemm::MatrixParams", align 4
  %12 = alloca %"struct.tflite::cpu_backend_gemm::MatrixParams", align 4
  %13 = alloca %"struct.tflite::cpu_backend_gemm::MatrixParams", align 4
  %14 = alloca %"struct.tflite::cpu_backend_gemm::GemmParams", align 8
  %15 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %3, i64 0, i32 0
  %16 = load i32, i32* %15, align 8
  %17 = add nsw i32 %16, -1
  %18 = icmp sgt i32 %16, 5
  %19 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %3, i64 0, i32 1
  %20 = getelementptr inbounds %union.anon.54, %union.anon.54* %19, i64 0, i32 0
  %21 = load i32*, i32** %20, align 8
  %22 = sext i32 %17 to i64
  %23 = getelementptr inbounds i32, i32* %21, i64 %22
  %24 = bitcast %union.anon.54* %19 to [5 x i32]*
  %25 = getelementptr inbounds [5 x i32], [5 x i32]* %24, i64 0, i64 %22
  %26 = select i1 %18, i32* %23, i32* %25
  %27 = load i32, i32* %26, align 4
  %28 = bitcast %"struct.tflite::cpu_backend_gemm::MatrixParams"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 20, i8* nonnull %28) #19
  %29 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %11, i64 0, i32 1
  %30 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %11, i64 0, i32 2
  %31 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %11, i64 0, i32 4
  %32 = bitcast i8* %31 to i32*
  store i32 -1431655766, i32* %32, align 4
  %33 = bitcast %"struct.tflite::cpu_backend_gemm::MatrixParams"* %11 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %33, i8 0, i64 17, i1 false)
  store i32 %27, i32* %29, align 4
  %34 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %1, i64 0, i32 0
  %35 = load i32, i32* %34, align 8
  %36 = icmp sgt i32 %35, 5
  %37 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %1, i64 0, i32 1
  br i1 %36, label %38, label %41

38:                                               ; preds = %10
  %39 = getelementptr inbounds %union.anon.54, %union.anon.54* %37, i64 0, i32 0
  %40 = load i32*, i32** %39, align 8
  br label %48

41:                                               ; preds = %10
  %42 = bitcast %union.anon.54* %37 to i32*
  %43 = icmp sgt i32 %35, 0
  br i1 %43, label %48, label %44

44:                                               ; preds = %41
  %45 = add i32 %27, 1
  %46 = icmp ult i32 %45, 3
  %47 = select i1 %46, i32 %27, i32 0
  br label %151

48:                                               ; preds = %41, %38
  %49 = phi i32* [ %40, %38 ], [ %42, %41 ]
  %50 = zext i32 %35 to i64
  %51 = icmp ult i32 %35, 8
  br i1 %51, label %137, label %52

52:                                               ; preds = %48
  %53 = and i64 %50, 4294967288
  %54 = add nsw i64 %53, -8
  %55 = lshr exact i64 %54, 3
  %56 = add nuw nsw i64 %55, 1
  %57 = and i64 %56, 3
  %58 = icmp ult i64 %54, 24
  br i1 %58, label %104, label %59

59:                                               ; preds = %52
  %60 = sub nsw i64 %56, %57
  br label %61

61:                                               ; preds = %61, %59
  %62 = phi i64 [ 0, %59 ], [ %101, %61 ]
  %63 = phi <4 x i32> [ <i32 1, i32 1, i32 1, i32 1>, %59 ], [ %99, %61 ]
  %64 = phi <4 x i32> [ <i32 1, i32 1, i32 1, i32 1>, %59 ], [ %100, %61 ]
  %65 = phi i64 [ %60, %59 ], [ %102, %61 ]
  %66 = getelementptr inbounds i32, i32* %49, i64 %62
  %67 = bitcast i32* %66 to <4 x i32>*
  %68 = load <4 x i32>, <4 x i32>* %67, align 4
  %69 = getelementptr inbounds i32, i32* %66, i64 4
  %70 = bitcast i32* %69 to <4 x i32>*
  %71 = load <4 x i32>, <4 x i32>* %70, align 4
  %72 = mul nsw <4 x i32> %68, %63
  %73 = mul nsw <4 x i32> %71, %64
  %74 = or i64 %62, 8
  %75 = getelementptr inbounds i32, i32* %49, i64 %74
  %76 = bitcast i32* %75 to <4 x i32>*
  %77 = load <4 x i32>, <4 x i32>* %76, align 4
  %78 = getelementptr inbounds i32, i32* %75, i64 4
  %79 = bitcast i32* %78 to <4 x i32>*
  %80 = load <4 x i32>, <4 x i32>* %79, align 4
  %81 = mul nsw <4 x i32> %77, %72
  %82 = mul nsw <4 x i32> %80, %73
  %83 = or i64 %62, 16
  %84 = getelementptr inbounds i32, i32* %49, i64 %83
  %85 = bitcast i32* %84 to <4 x i32>*
  %86 = load <4 x i32>, <4 x i32>* %85, align 4
  %87 = getelementptr inbounds i32, i32* %84, i64 4
  %88 = bitcast i32* %87 to <4 x i32>*
  %89 = load <4 x i32>, <4 x i32>* %88, align 4
  %90 = mul nsw <4 x i32> %86, %81
  %91 = mul nsw <4 x i32> %89, %82
  %92 = or i64 %62, 24
  %93 = getelementptr inbounds i32, i32* %49, i64 %92
  %94 = bitcast i32* %93 to <4 x i32>*
  %95 = load <4 x i32>, <4 x i32>* %94, align 4
  %96 = getelementptr inbounds i32, i32* %93, i64 4
  %97 = bitcast i32* %96 to <4 x i32>*
  %98 = load <4 x i32>, <4 x i32>* %97, align 4
  %99 = mul nsw <4 x i32> %95, %90
  %100 = mul nsw <4 x i32> %98, %91
  %101 = add i64 %62, 32
  %102 = add i64 %65, -4
  %103 = icmp eq i64 %102, 0
  br i1 %103, label %104, label %61, !llvm.loop !289

104:                                              ; preds = %61, %52
  %105 = phi <4 x i32> [ undef, %52 ], [ %99, %61 ]
  %106 = phi <4 x i32> [ undef, %52 ], [ %100, %61 ]
  %107 = phi i64 [ 0, %52 ], [ %101, %61 ]
  %108 = phi <4 x i32> [ <i32 1, i32 1, i32 1, i32 1>, %52 ], [ %99, %61 ]
  %109 = phi <4 x i32> [ <i32 1, i32 1, i32 1, i32 1>, %52 ], [ %100, %61 ]
  %110 = icmp eq i64 %57, 0
  br i1 %110, label %127, label %111

111:                                              ; preds = %104, %111
  %112 = phi i64 [ %124, %111 ], [ %107, %104 ]
  %113 = phi <4 x i32> [ %122, %111 ], [ %108, %104 ]
  %114 = phi <4 x i32> [ %123, %111 ], [ %109, %104 ]
  %115 = phi i64 [ %125, %111 ], [ %57, %104 ]
  %116 = getelementptr inbounds i32, i32* %49, i64 %112
  %117 = bitcast i32* %116 to <4 x i32>*
  %118 = load <4 x i32>, <4 x i32>* %117, align 4
  %119 = getelementptr inbounds i32, i32* %116, i64 4
  %120 = bitcast i32* %119 to <4 x i32>*
  %121 = load <4 x i32>, <4 x i32>* %120, align 4
  %122 = mul nsw <4 x i32> %118, %113
  %123 = mul nsw <4 x i32> %121, %114
  %124 = add i64 %112, 8
  %125 = add i64 %115, -1
  %126 = icmp eq i64 %125, 0
  br i1 %126, label %127, label %111, !llvm.loop !290

127:                                              ; preds = %111, %104
  %128 = phi <4 x i32> [ %105, %104 ], [ %122, %111 ]
  %129 = phi <4 x i32> [ %106, %104 ], [ %123, %111 ]
  %130 = mul <4 x i32> %129, %128
  %131 = shufflevector <4 x i32> %130, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %132 = mul <4 x i32> %130, %131
  %133 = shufflevector <4 x i32> %132, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %134 = mul <4 x i32> %132, %133
  %135 = extractelement <4 x i32> %134, i32 0
  %136 = icmp eq i64 %53, %50
  br i1 %136, label %148, label %137

137:                                              ; preds = %127, %48
  %138 = phi i64 [ 0, %48 ], [ %53, %127 ]
  %139 = phi i32 [ 1, %48 ], [ %135, %127 ]
  br label %140

140:                                              ; preds = %137, %140
  %141 = phi i64 [ %146, %140 ], [ %138, %137 ]
  %142 = phi i32 [ %145, %140 ], [ %139, %137 ]
  %143 = getelementptr inbounds i32, i32* %49, i64 %141
  %144 = load i32, i32* %143, align 4
  %145 = mul nsw i32 %144, %142
  %146 = add nuw nsw i64 %141, 1
  %147 = icmp eq i64 %146, %50
  br i1 %147, label %148, label %140, !llvm.loop !291

148:                                              ; preds = %140, %127
  %149 = phi i32 [ %135, %127 ], [ %145, %140 ]
  %150 = sdiv i32 %149, %27
  br label %151

151:                                              ; preds = %148, %44
  %152 = phi i32 [ %47, %44 ], [ %150, %148 ]
  store i32 %152, i32* %30, align 4
  %153 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 10
  %154 = load i8, i8* %153, align 1, !range !10
  store i8 %154, i8* %31, align 4
  %155 = bitcast %"struct.tflite::cpu_backend_gemm::MatrixParams"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 20, i8* nonnull %155) #19
  %156 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %12, i64 0, i32 0
  %157 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %12, i64 0, i32 1
  %158 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %12, i64 0, i32 2
  %159 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %12, i64 0, i32 4
  %160 = bitcast i8* %159 to i32*
  store i32 -1431655766, i32* %160, align 4
  %161 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %12, i64 0, i32 1
  %162 = bitcast i32* %161 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %162, i8 0, i64 13, i1 false) #19
  store i32 1, i32* %156, align 4
  br i1 %18, label %163, label %165

163:                                              ; preds = %151
  %164 = load i32, i32* %23, align 4
  store i32 %164, i32* %158, align 4
  br label %169

165:                                              ; preds = %151
  %166 = load i32, i32* %25, align 4
  store i32 %166, i32* %158, align 4
  %167 = bitcast %union.anon.54* %19 to i32*
  %168 = icmp sgt i32 %16, 0
  br i1 %168, label %169, label %210

169:                                              ; preds = %163, %165
  %170 = phi i32* [ %21, %163 ], [ %167, %165 ]
  %171 = zext i32 %17 to i64
  %172 = zext i32 %16 to i64
  %173 = add nsw i64 %172, -1
  %174 = and i64 %172, 3
  %175 = icmp ult i64 %173, 3
  br i1 %175, label %191, label %176

176:                                              ; preds = %169
  %177 = sub nsw i64 %172, %174
  br label %178

178:                                              ; preds = %343, %176
  %179 = phi i64 [ 0, %176 ], [ %346, %343 ]
  %180 = phi i32 [ 1, %176 ], [ %345, %343 ]
  %181 = phi i64 [ %177, %176 ], [ %347, %343 ]
  %182 = icmp eq i64 %179, %171
  br i1 %182, label %186, label %183

183:                                              ; preds = %178
  %184 = getelementptr inbounds i32, i32* %170, i64 %179
  %185 = load i32, i32* %184, align 4
  br label %186

186:                                              ; preds = %183, %178
  %187 = phi i32 [ %185, %183 ], [ 1, %178 ]
  %188 = mul nsw i32 %187, %180
  %189 = or i64 %179, 1
  %190 = icmp eq i64 %189, %171
  br i1 %190, label %327, label %324

191:                                              ; preds = %343, %169
  %192 = phi i32 [ undef, %169 ], [ %345, %343 ]
  %193 = phi i64 [ 0, %169 ], [ %346, %343 ]
  %194 = phi i32 [ 1, %169 ], [ %345, %343 ]
  %195 = icmp eq i64 %174, 0
  br i1 %195, label %210, label %196

196:                                              ; preds = %191, %204
  %197 = phi i64 [ %207, %204 ], [ %193, %191 ]
  %198 = phi i32 [ %206, %204 ], [ %194, %191 ]
  %199 = phi i64 [ %208, %204 ], [ %174, %191 ]
  %200 = icmp eq i64 %197, %171
  br i1 %200, label %204, label %201

201:                                              ; preds = %196
  %202 = getelementptr inbounds i32, i32* %170, i64 %197
  %203 = load i32, i32* %202, align 4
  br label %204

204:                                              ; preds = %201, %196
  %205 = phi i32 [ %203, %201 ], [ 1, %196 ]
  %206 = mul nsw i32 %205, %198
  %207 = add nuw nsw i64 %197, 1
  %208 = add i64 %199, -1
  %209 = icmp eq i64 %208, 0
  br i1 %209, label %210, label %196, !llvm.loop !292

210:                                              ; preds = %191, %204, %165
  %211 = phi i32 [ 1, %165 ], [ %192, %191 ], [ %206, %204 ]
  store i32 %211, i32* %157, align 4
  %212 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 9
  %213 = load i8, i8* %212, align 4, !range !10
  store i8 %213, i8* %159, align 4
  %214 = bitcast %"struct.tflite::cpu_backend_gemm::MatrixParams"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 20, i8* nonnull %214) #19
  %215 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %13, i64 0, i32 1
  %216 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %13, i64 0, i32 2
  %217 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %13, i64 0, i32 4
  %218 = bitcast i8* %217 to i32*
  store i32 -1431655766, i32* %218, align 4
  %219 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %7, i64 0, i32 0
  %220 = bitcast %"struct.tflite::cpu_backend_gemm::MatrixParams"* %13 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %220, i8 0, i64 17, i1 false)
  %221 = load i32, i32* %219, align 8
  %222 = add nsw i32 %221, -1
  %223 = icmp sgt i32 %221, 5
  %224 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %7, i64 0, i32 1
  br i1 %223, label %225, label %231

225:                                              ; preds = %210
  %226 = getelementptr inbounds %union.anon.54, %union.anon.54* %224, i64 0, i32 0
  %227 = load i32*, i32** %226, align 8
  %228 = sext i32 %222 to i64
  %229 = getelementptr inbounds i32, i32* %227, i64 %228
  %230 = load i32, i32* %229, align 4
  store i32 %230, i32* %215, align 4
  br label %238

231:                                              ; preds = %210
  %232 = bitcast %union.anon.54* %224 to [5 x i32]*
  %233 = sext i32 %222 to i64
  %234 = getelementptr inbounds [5 x i32], [5 x i32]* %232, i64 0, i64 %233
  %235 = load i32, i32* %234, align 4
  store i32 %235, i32* %215, align 4
  %236 = bitcast %union.anon.54* %224 to i32*
  %237 = icmp sgt i32 %221, 0
  br i1 %237, label %238, label %279

238:                                              ; preds = %225, %231
  %239 = phi i32* [ %227, %225 ], [ %236, %231 ]
  %240 = zext i32 %222 to i64
  %241 = zext i32 %221 to i64
  %242 = add nsw i64 %241, -1
  %243 = and i64 %241, 3
  %244 = icmp ult i64 %242, 3
  br i1 %244, label %260, label %245

245:                                              ; preds = %238
  %246 = sub nsw i64 %241, %243
  br label %247

247:                                              ; preds = %318, %245
  %248 = phi i64 [ 0, %245 ], [ %321, %318 ]
  %249 = phi i32 [ 1, %245 ], [ %320, %318 ]
  %250 = phi i64 [ %246, %245 ], [ %322, %318 ]
  %251 = icmp eq i64 %248, %240
  br i1 %251, label %255, label %252

252:                                              ; preds = %247
  %253 = getelementptr inbounds i32, i32* %239, i64 %248
  %254 = load i32, i32* %253, align 4
  br label %255

255:                                              ; preds = %252, %247
  %256 = phi i32 [ %254, %252 ], [ 1, %247 ]
  %257 = mul nsw i32 %256, %249
  %258 = or i64 %248, 1
  %259 = icmp eq i64 %258, %240
  br i1 %259, label %302, label %299

260:                                              ; preds = %318, %238
  %261 = phi i32 [ undef, %238 ], [ %320, %318 ]
  %262 = phi i64 [ 0, %238 ], [ %321, %318 ]
  %263 = phi i32 [ 1, %238 ], [ %320, %318 ]
  %264 = icmp eq i64 %243, 0
  br i1 %264, label %279, label %265

265:                                              ; preds = %260, %273
  %266 = phi i64 [ %276, %273 ], [ %262, %260 ]
  %267 = phi i32 [ %275, %273 ], [ %263, %260 ]
  %268 = phi i64 [ %277, %273 ], [ %243, %260 ]
  %269 = icmp eq i64 %266, %240
  br i1 %269, label %273, label %270

270:                                              ; preds = %265
  %271 = getelementptr inbounds i32, i32* %239, i64 %266
  %272 = load i32, i32* %271, align 4
  br label %273

273:                                              ; preds = %270, %265
  %274 = phi i32 [ %272, %270 ], [ 1, %265 ]
  %275 = mul nsw i32 %274, %267
  %276 = add nuw nsw i64 %266, 1
  %277 = add i64 %268, -1
  %278 = icmp eq i64 %277, 0
  br i1 %278, label %279, label %265, !llvm.loop !293

279:                                              ; preds = %260, %273, %231
  %280 = phi i32 [ 1, %231 ], [ %261, %260 ], [ %275, %273 ]
  store i32 %280, i32* %216, align 4
  %281 = bitcast %"struct.tflite::cpu_backend_gemm::GemmParams"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %281) #19
  %282 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams", %"struct.tflite::cpu_backend_gemm::GemmParams"* %14, i64 0, i32 4
  %283 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams", %"struct.tflite::cpu_backend_gemm::GemmParams"* %14, i64 0, i32 5
  %284 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams", %"struct.tflite::cpu_backend_gemm::GemmParams"* %14, i64 0, i32 6
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %281, i8 0, i64 24, i1 false) #19
  store float* %6, float** %282, align 8
  %285 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 7
  %286 = bitcast float* %285 to i32*
  %287 = load i32, i32* %286, align 4
  %288 = bitcast float* %283 to i32*
  store i32 %287, i32* %288, align 8
  %289 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 8
  %290 = bitcast float* %289 to i32*
  %291 = load i32, i32* %290, align 4
  %292 = bitcast float* %284 to i32*
  store i32 %291, i32* %292, align 4
  %293 = getelementptr inbounds %"class.tflite::CpuBackendContext", %"class.tflite::CpuBackendContext"* %9, i64 0, i32 4
  %294 = load i8, i8* %293, align 4, !range !10
  %295 = icmp eq i8 %294, 0
  br i1 %295, label %297, label %296

296:                                              ; preds = %279
  call void @_ZN6tflite16cpu_backend_gemm6detail16GemmImplUsingRuyIffffLNS0_18QuantizationFlavorE0EE3RunERKNS0_12MatrixParamsIfEEPKfS8_SA_S8_PfRKNS0_10GemmParamsIffLS3_0EEEPNS_17CpuBackendContextE(%"struct.tflite::cpu_backend_gemm::MatrixParams"* nonnull dereferenceable(20) %12, float* %4, %"struct.tflite::cpu_backend_gemm::MatrixParams"* nonnull dereferenceable(20) %11, float* %2, %"struct.tflite::cpu_backend_gemm::MatrixParams"* nonnull dereferenceable(20) %13, float* %8, %"struct.tflite::cpu_backend_gemm::GemmParams"* nonnull dereferenceable(40) %14, %"class.tflite::CpuBackendContext"* %9) #19
  br label %298

297:                                              ; preds = %279
  call void @_ZN6tflite16cpu_backend_gemm6detail18GemmImplUsingEigen3RunERKNS0_12MatrixParamsIfEEPKfS6_S8_S6_PfRKNS0_10GemmParamsIffLNS0_18QuantizationFlavorE0EEEPNS_17CpuBackendContextE(%"struct.tflite::cpu_backend_gemm::MatrixParams"* nonnull dereferenceable(20) %12, float* %4, %"struct.tflite::cpu_backend_gemm::MatrixParams"* nonnull dereferenceable(20) %11, float* %2, %"struct.tflite::cpu_backend_gemm::MatrixParams"* nonnull dereferenceable(20) %13, float* %8, %"struct.tflite::cpu_backend_gemm::GemmParams"* nonnull dereferenceable(40) %14, %"class.tflite::CpuBackendContext"* %9) #19
  br label %298

298:                                              ; preds = %296, %297
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %281) #19
  call void @llvm.lifetime.end.p0i8(i64 20, i8* nonnull %214) #19
  call void @llvm.lifetime.end.p0i8(i64 20, i8* nonnull %155) #19
  call void @llvm.lifetime.end.p0i8(i64 20, i8* nonnull %28) #19
  ret void

299:                                              ; preds = %255
  %300 = getelementptr inbounds i32, i32* %239, i64 %258
  %301 = load i32, i32* %300, align 4
  br label %302

302:                                              ; preds = %299, %255
  %303 = phi i32 [ %301, %299 ], [ 1, %255 ]
  %304 = mul nsw i32 %303, %257
  %305 = or i64 %248, 2
  %306 = icmp eq i64 %305, %240
  br i1 %306, label %310, label %307

307:                                              ; preds = %302
  %308 = getelementptr inbounds i32, i32* %239, i64 %305
  %309 = load i32, i32* %308, align 4
  br label %310

310:                                              ; preds = %307, %302
  %311 = phi i32 [ %309, %307 ], [ 1, %302 ]
  %312 = mul nsw i32 %311, %304
  %313 = or i64 %248, 3
  %314 = icmp eq i64 %313, %240
  br i1 %314, label %318, label %315

315:                                              ; preds = %310
  %316 = getelementptr inbounds i32, i32* %239, i64 %313
  %317 = load i32, i32* %316, align 4
  br label %318

318:                                              ; preds = %315, %310
  %319 = phi i32 [ %317, %315 ], [ 1, %310 ]
  %320 = mul nsw i32 %319, %312
  %321 = add nuw nsw i64 %248, 4
  %322 = add i64 %250, -4
  %323 = icmp eq i64 %322, 0
  br i1 %323, label %260, label %247

324:                                              ; preds = %186
  %325 = getelementptr inbounds i32, i32* %170, i64 %189
  %326 = load i32, i32* %325, align 4
  br label %327

327:                                              ; preds = %324, %186
  %328 = phi i32 [ %326, %324 ], [ 1, %186 ]
  %329 = mul nsw i32 %328, %188
  %330 = or i64 %179, 2
  %331 = icmp eq i64 %330, %171
  br i1 %331, label %335, label %332

332:                                              ; preds = %327
  %333 = getelementptr inbounds i32, i32* %170, i64 %330
  %334 = load i32, i32* %333, align 4
  br label %335

335:                                              ; preds = %332, %327
  %336 = phi i32 [ %334, %332 ], [ 1, %327 ]
  %337 = mul nsw i32 %336, %329
  %338 = or i64 %179, 3
  %339 = icmp eq i64 %338, %171
  br i1 %339, label %343, label %340

340:                                              ; preds = %335
  %341 = getelementptr inbounds i32, i32* %170, i64 %338
  %342 = load i32, i32* %341, align 4
  br label %343

343:                                              ; preds = %340, %335
  %344 = phi i32 [ %342, %340 ], [ 1, %335 ]
  %345 = mul nsw i32 %344, %337
  %346 = add nuw nsw i64 %179, 4
  %347 = add i64 %181, -4
  %348 = icmp eq i64 %347, 0
  br i1 %348, label %191, label %178
}

declare void @_ZN6tflite12tensor_utils44SparseMatrixBatchVectorMultiplyAccumulate1x4EPKfPKiS4_iiS2_iPf(float*, i32*, i32*, i32, i32, float*, i32, float*) local_unnamed_addr #5

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN6tflite13optimized_ops33FullyConnectedSparseWeight1x4TaskD0Ev(%"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"*) unnamed_addr #4 comdat align 2 {
  %2 = bitcast %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %0 to i8*
  tail call void @_ZdlPv(i8* %2) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN6tflite13optimized_ops33FullyConnectedSparseWeight1x4Task3RunEv(%"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"*) unnamed_addr #1 comdat align 2 {
  %2 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %0, i64 0, i32 1
  %3 = load %struct.TfLiteSparsity*, %struct.TfLiteSparsity** %2, align 8
  %4 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %0, i64 0, i32 2
  %5 = load %"struct.tflite::FullyConnectedParams"*, %"struct.tflite::FullyConnectedParams"** %4, align 8
  %6 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %0, i64 0, i32 3
  %7 = load %"class.tflite::RuntimeShape"*, %"class.tflite::RuntimeShape"** %6, align 8
  %8 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %0, i64 0, i32 4
  %9 = load float*, float** %8, align 8
  %10 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %0, i64 0, i32 5
  %11 = load %"class.tflite::RuntimeShape"*, %"class.tflite::RuntimeShape"** %10, align 8
  %12 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %0, i64 0, i32 6
  %13 = load float*, float** %12, align 8
  %14 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %0, i64 0, i32 8
  %15 = load float*, float** %14, align 8
  %16 = bitcast float* %15 to i8*
  %17 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %0, i64 0, i32 9
  %18 = load %"class.tflite::RuntimeShape"*, %"class.tflite::RuntimeShape"** %17, align 8
  %19 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %0, i64 0, i32 10
  %20 = load float*, float** %19, align 8
  %21 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %0, i64 0, i32 11
  %22 = load i32, i32* %21, align 8
  %23 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %0, i64 0, i32 12
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %5, i64 0, i32 7
  %26 = load float, float* %25, align 4
  %27 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %5, i64 0, i32 8
  %28 = load float, float* %27, align 4
  %29 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %7, i64 0, i32 0
  %30 = load i32, i32* %29, align 8
  %31 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %18, i64 0, i32 0
  %32 = load i32, i32* %31, align 8
  %33 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 0
  %34 = load i32, i32* %33, align 8
  %35 = sub nsw i32 %24, %22
  %36 = add nsw i32 %34, -1
  %37 = add nsw i32 %30, -1
  %38 = icmp sgt i32 %34, 5
  %39 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 1
  %40 = icmp sgt i32 %30, 5
  %41 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %7, i64 0, i32 1
  %42 = getelementptr inbounds %union.anon.54, %union.anon.54* %39, i64 0, i32 0
  %43 = load i32*, i32** %42, align 8
  %44 = sext i32 %36 to i64
  %45 = getelementptr inbounds i32, i32* %43, i64 %44
  %46 = bitcast %union.anon.54* %39 to [5 x i32]*
  %47 = getelementptr inbounds [5 x i32], [5 x i32]* %46, i64 0, i64 %44
  %48 = select i1 %38, i32* %45, i32* %47
  %49 = load i32, i32* %48, align 4
  %50 = getelementptr inbounds %union.anon.54, %union.anon.54* %41, i64 0, i32 0
  %51 = load i32*, i32** %50, align 8
  %52 = sext i32 %37 to i64
  %53 = getelementptr inbounds i32, i32* %51, i64 %52
  %54 = bitcast %union.anon.54* %41 to [5 x i32]*
  %55 = getelementptr inbounds [5 x i32], [5 x i32]* %54, i64 0, i64 %52
  %56 = select i1 %40, i32* %53, i32* %55
  %57 = load i32, i32* %56, align 4
  %58 = icmp slt i32 %57, %49
  %59 = select i1 %58, i32 %57, i32 %49
  %60 = add nsw i32 %34, -2
  %61 = add nsw i32 %32, -1
  %62 = icmp sgt i32 %32, 5
  %63 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %18, i64 0, i32 1
  %64 = sext i32 %60 to i64
  %65 = getelementptr inbounds i32, i32* %43, i64 %64
  %66 = getelementptr inbounds [5 x i32], [5 x i32]* %46, i64 0, i64 %64
  %67 = select i1 %38, i32* %65, i32* %66
  %68 = load i32, i32* %67, align 4
  %69 = getelementptr inbounds %union.anon.54, %union.anon.54* %63, i64 0, i32 0
  %70 = load i32*, i32** %69, align 8
  %71 = sext i32 %61 to i64
  %72 = getelementptr inbounds i32, i32* %70, i64 %71
  %73 = bitcast %union.anon.54* %63 to [5 x i32]*
  %74 = getelementptr inbounds [5 x i32], [5 x i32]* %73, i64 0, i64 %71
  %75 = select i1 %62, i32* %72, i32* %74
  %76 = load i32, i32* %75, align 4
  %77 = icmp slt i32 %76, %68
  %78 = select i1 %77, i32 %76, i32 %68
  %79 = getelementptr inbounds %struct.TfLiteSparsity, %struct.TfLiteSparsity* %3, i64 0, i32 2
  %80 = load %struct.TfLiteDimensionMetadata*, %struct.TfLiteDimensionMetadata** %79, align 8
  %81 = getelementptr inbounds %struct.TfLiteDimensionMetadata, %struct.TfLiteDimensionMetadata* %80, i64 1, i32 2
  %82 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %81, align 8
  %83 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %82, i64 0, i32 1, i64 0
  %84 = getelementptr inbounds %struct.TfLiteDimensionMetadata, %struct.TfLiteDimensionMetadata* %80, i64 1, i32 3
  %85 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %84, align 8
  %86 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %85, i64 0, i32 1, i64 0
  %87 = getelementptr inbounds i32, i32* %43, i64 1
  %88 = bitcast %union.anon.54* %39 to i32*
  %89 = getelementptr inbounds [5 x i32], [5 x i32]* %46, i64 0, i64 1
  %90 = select i1 %38, i32* %43, i32* %88
  %91 = select i1 %38, i32* %87, i32* %89
  %92 = load i32, i32* %90, align 4
  %93 = load i32, i32* %91, align 4
  %94 = mul nsw i32 %59, %22
  %95 = sext i32 %94 to i64
  %96 = getelementptr inbounds float, float* %9, i64 %95
  %97 = mul nsw i32 %78, %22
  %98 = sext i32 %97 to i64
  %99 = getelementptr inbounds float, float* %20, i64 %98
  tail call void @_ZN6tflite12tensor_utils44SparseMatrixBatchVectorMultiplyAccumulate1x4EPKfPKiS4_iiS2_iPf(float* %13, i32* %83, i32* %86, i32 %92, i32 %93, float* %96, i32 %35, float* %99) #19
  %100 = icmp sgt i32 %24, %22
  br i1 %100, label %101, label %187

101:                                              ; preds = %1
  %102 = icmp sgt i32 %78, 0
  %103 = sext i32 %78 to i64
  %104 = sext i32 %22 to i64
  %105 = sext i32 %24 to i64
  %106 = mul nsw i64 %104, %103
  %107 = shl nsw i64 %104, 2
  %108 = add nsw i64 %107, 4
  %109 = mul i64 %108, %103
  %110 = getelementptr float, float* %15, i64 %103
  %111 = icmp ult i32 %78, 8
  %112 = and i64 %103, -8
  %113 = insertelement <4 x float> undef, float %26, i32 0
  %114 = shufflevector <4 x float> %113, <4 x float> undef, <4 x i32> zeroinitializer
  %115 = insertelement <4 x float> undef, float %26, i32 0
  %116 = shufflevector <4 x float> %115, <4 x float> undef, <4 x i32> zeroinitializer
  %117 = insertelement <4 x float> undef, float %28, i32 0
  %118 = shufflevector <4 x float> %117, <4 x float> undef, <4 x i32> zeroinitializer
  %119 = insertelement <4 x float> undef, float %28, i32 0
  %120 = shufflevector <4 x float> %119, <4 x float> undef, <4 x i32> zeroinitializer
  %121 = icmp eq i64 %112, %103
  br label %122

122:                                              ; preds = %169, %101
  %123 = phi i64 [ %172, %169 ], [ 0, %101 ]
  %124 = phi i64 [ %170, %169 ], [ %104, %101 ]
  %125 = mul i64 %123, %103
  %126 = add i64 %106, %125
  %127 = getelementptr float, float* %20, i64 %126
  %128 = getelementptr float, float* %20, i64 %125
  %129 = bitcast float* %128 to i8*
  %130 = getelementptr i8, i8* %129, i64 %109
  br i1 %102, label %131, label %169

131:                                              ; preds = %122
  %132 = mul nsw i64 %124, %103
  br i1 %111, label %133, label %135

133:                                              ; preds = %168, %135, %131
  %134 = phi i64 [ 0, %135 ], [ 0, %131 ], [ %112, %168 ]
  br label %173

135:                                              ; preds = %131
  %136 = icmp ult float* %127, %110
  %137 = icmp ugt i8* %130, %16
  %138 = and i1 %136, %137
  br i1 %138, label %133, label %139

139:                                              ; preds = %135, %139
  %140 = phi i64 [ %166, %139 ], [ 0, %135 ]
  %141 = add nsw i64 %140, %132
  %142 = getelementptr inbounds float, float* %20, i64 %141
  %143 = bitcast float* %142 to <4 x float>*
  %144 = load <4 x float>, <4 x float>* %143, align 4, !alias.scope !294, !noalias !297
  %145 = getelementptr inbounds float, float* %142, i64 4
  %146 = bitcast float* %145 to <4 x float>*
  %147 = load <4 x float>, <4 x float>* %146, align 4, !alias.scope !294, !noalias !297
  %148 = getelementptr inbounds float, float* %15, i64 %140
  %149 = bitcast float* %148 to <4 x float>*
  %150 = load <4 x float>, <4 x float>* %149, align 4, !alias.scope !297
  %151 = getelementptr inbounds float, float* %148, i64 4
  %152 = bitcast float* %151 to <4 x float>*
  %153 = load <4 x float>, <4 x float>* %152, align 4, !alias.scope !297
  %154 = fadd <4 x float> %144, %150
  %155 = fadd <4 x float> %147, %153
  %156 = fcmp olt <4 x float> %154, %114
  %157 = fcmp olt <4 x float> %155, %116
  %158 = select <4 x i1> %156, <4 x float> %114, <4 x float> %154
  %159 = select <4 x i1> %157, <4 x float> %116, <4 x float> %155
  %160 = fcmp ogt <4 x float> %158, %118
  %161 = fcmp ogt <4 x float> %159, %120
  %162 = select <4 x i1> %160, <4 x float> %118, <4 x float> %158
  %163 = select <4 x i1> %161, <4 x float> %120, <4 x float> %159
  %164 = bitcast float* %142 to <4 x float>*
  store <4 x float> %162, <4 x float>* %164, align 4, !alias.scope !294, !noalias !297
  %165 = bitcast float* %145 to <4 x float>*
  store <4 x float> %163, <4 x float>* %165, align 4, !alias.scope !294, !noalias !297
  %166 = add i64 %140, 8
  %167 = icmp eq i64 %166, %112
  br i1 %167, label %168, label %139, !llvm.loop !299

168:                                              ; preds = %139
  br i1 %121, label %169, label %133

169:                                              ; preds = %173, %168, %122
  %170 = add nsw i64 %124, 1
  %171 = icmp eq i64 %170, %105
  %172 = add i64 %123, 1
  br i1 %171, label %187, label %122

173:                                              ; preds = %133, %173
  %174 = phi i64 [ %185, %173 ], [ %134, %133 ]
  %175 = add nsw i64 %174, %132
  %176 = getelementptr inbounds float, float* %20, i64 %175
  %177 = load float, float* %176, align 4
  %178 = getelementptr inbounds float, float* %15, i64 %174
  %179 = load float, float* %178, align 4
  %180 = fadd float %177, %179
  %181 = fcmp olt float %180, %26
  %182 = select i1 %181, float %26, float %180
  %183 = fcmp ogt float %182, %28
  %184 = select i1 %183, float %28, float %182
  store float %184, float* %176, align 4
  %185 = add nuw nsw i64 %174, 1
  %186 = icmp slt i64 %185, %103
  br i1 %186, label %173, label %169, !llvm.loop !300

187:                                              ; preds = %169, %1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp4TaskD0Ev(%"struct.gemmlowp::Task"*) unnamed_addr #1 comdat align 2 {
  tail call void @llvm.trap() #20
  unreachable
}

declare void @__cxa_pure_virtual() unnamed_addr

; Function Attrs: cold noreturn nounwind
declare void @llvm.trap() #13

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZNSt3__16vectorIN6tflite13optimized_ops33FullyConnectedSparseWeight1x4TaskENS_9allocatorIS3_EEE24__emplace_back_slow_pathIJRK14TfLiteSparsityRKNS1_20FullyConnectedParamsERKNS1_12RuntimeShapeERPKfSG_SJ_SG_SJ_SG_RPfRiSM_RNS1_17CpuBackendContextEEEEvDpOT_(%"class.std::__1::vector.85"*, %struct.TfLiteSparsity* dereferenceable(32), %"struct.tflite::FullyConnectedParams"* dereferenceable(40), %"class.tflite::RuntimeShape"* dereferenceable(32), float** dereferenceable(8), %"class.tflite::RuntimeShape"* dereferenceable(32), float** dereferenceable(8), %"class.tflite::RuntimeShape"* dereferenceable(32), float** dereferenceable(8), %"class.tflite::RuntimeShape"* dereferenceable(32), float** dereferenceable(8), i32* dereferenceable(4), i32* dereferenceable(4), %"class.tflite::CpuBackendContext"* dereferenceable(32)) local_unnamed_addr #4 comdat align 2 {
  %15 = getelementptr inbounds %"class.std::__1::vector.85", %"class.std::__1::vector.85"* %0, i64 0, i32 0, i32 1
  %16 = bitcast %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"** %15 to i64*
  %17 = load i64, i64* %16, align 8
  %18 = bitcast %"class.std::__1::vector.85"* %0 to i64*
  %19 = load i64, i64* %18, align 8
  %20 = sub i64 %17, %19
  %21 = sdiv exact i64 %20, 112
  %22 = add nsw i64 %21, 1
  %23 = icmp ugt i64 %22, 164703072086692425
  br i1 %23, label %24, label %26

24:                                               ; preds = %14
  %25 = bitcast %"class.std::__1::vector.85"* %0 to %"class.std::__1::__vector_base_common"*
  tail call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* %25) #20
  unreachable

26:                                               ; preds = %14
  %27 = getelementptr inbounds %"class.std::__1::vector.85", %"class.std::__1::vector.85"* %0, i64 0, i32 0, i32 2, i32 0, i32 0
  %28 = bitcast %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"** %27 to i64*
  %29 = load i64, i64* %28, align 8
  %30 = sub i64 %29, %19
  %31 = sdiv exact i64 %30, 112
  %32 = icmp ult i64 %31, 82351536043346212
  br i1 %32, label %33, label %38

33:                                               ; preds = %26
  %34 = shl nsw i64 %31, 1
  %35 = icmp ult i64 %34, %22
  %36 = select i1 %35, i64 %22, i64 %34
  %37 = icmp eq i64 %36, 0
  br i1 %37, label %43, label %38

38:                                               ; preds = %26, %33
  %39 = phi i64 [ %36, %33 ], [ 164703072086692425, %26 ]
  %40 = mul i64 %39, 112
  %41 = tail call i8* @_Znwm(i64 %40) #18
  %42 = bitcast i8* %41 to %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"*
  br label %43

43:                                               ; preds = %33, %38
  %44 = phi i64 [ %39, %38 ], [ 0, %33 ]
  %45 = phi %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* [ %42, %38 ], [ null, %33 ]
  %46 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %45, i64 %21
  %47 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %45, i64 %44
  %48 = ptrtoint %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %47 to i64
  %49 = bitcast float** %4 to i64*
  %50 = load i64, i64* %49, align 8
  %51 = bitcast float** %6 to i64*
  %52 = load i64, i64* %51, align 8
  %53 = bitcast float** %8 to i64*
  %54 = load i64, i64* %53, align 8
  %55 = bitcast float** %10 to i64*
  %56 = load i64, i64* %55, align 8
  %57 = load i32, i32* %11, align 4
  %58 = load i32, i32* %12, align 4
  %59 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %46, i64 0, i32 0, i32 0
  %60 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %45, i64 %21, i32 0, i32 1
  store %"class.gemmlowp::Allocator"* null, %"class.gemmlowp::Allocator"** %60, align 8
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVN6tflite13optimized_ops33FullyConnectedSparseWeight1x4TaskE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %59, align 8
  %61 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %45, i64 %21, i32 1
  store %struct.TfLiteSparsity* %1, %struct.TfLiteSparsity** %61, align 8
  %62 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %45, i64 %21, i32 2
  store %"struct.tflite::FullyConnectedParams"* %2, %"struct.tflite::FullyConnectedParams"** %62, align 8
  %63 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %45, i64 %21, i32 3
  store %"class.tflite::RuntimeShape"* %3, %"class.tflite::RuntimeShape"** %63, align 8
  %64 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %45, i64 %21, i32 4
  %65 = bitcast float** %64 to i64*
  store i64 %50, i64* %65, align 8
  %66 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %45, i64 %21, i32 5
  store %"class.tflite::RuntimeShape"* %5, %"class.tflite::RuntimeShape"** %66, align 8
  %67 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %45, i64 %21, i32 6
  %68 = bitcast float** %67 to i64*
  store i64 %52, i64* %68, align 8
  %69 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %45, i64 %21, i32 7
  store %"class.tflite::RuntimeShape"* %7, %"class.tflite::RuntimeShape"** %69, align 8
  %70 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %45, i64 %21, i32 8
  %71 = bitcast float** %70 to i64*
  store i64 %54, i64* %71, align 8
  %72 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %45, i64 %21, i32 9
  store %"class.tflite::RuntimeShape"* %9, %"class.tflite::RuntimeShape"** %72, align 8
  %73 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %45, i64 %21, i32 10
  %74 = bitcast float** %73 to i64*
  store i64 %56, i64* %74, align 8
  %75 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %45, i64 %21, i32 11
  store i32 %57, i32* %75, align 8
  %76 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %45, i64 %21, i32 12
  store i32 %58, i32* %76, align 4
  %77 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %45, i64 %21, i32 13
  store %"class.tflite::CpuBackendContext"* %13, %"class.tflite::CpuBackendContext"** %77, align 8
  %78 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %46, i64 1
  %79 = ptrtoint %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %78 to i64
  %80 = getelementptr inbounds %"class.std::__1::vector.85", %"class.std::__1::vector.85"* %0, i64 0, i32 0, i32 0
  %81 = load %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"*, %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"** %80, align 8
  %82 = load %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"*, %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"** %15, align 8
  %83 = icmp eq %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %82, %81
  br i1 %83, label %84, label %86

84:                                               ; preds = %43
  %85 = ptrtoint %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %81 to i64
  br label %105

86:                                               ; preds = %43, %86
  %87 = phi %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* [ %100, %86 ], [ %46, %43 ]
  %88 = phi %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* [ %89, %86 ], [ %82, %43 ]
  %89 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %88, i64 -1
  %90 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %87, i64 -1, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVN8gemmlowp4TaskE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %90, align 8
  %91 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %87, i64 -1, i32 0, i32 1
  %92 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %88, i64 -1, i32 0, i32 1
  %93 = bitcast %"class.gemmlowp::Allocator"** %92 to i64*
  %94 = load i64, i64* %93, align 8
  %95 = bitcast %"class.gemmlowp::Allocator"** %91 to i64*
  store i64 %94, i64* %95, align 8
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVN6tflite13optimized_ops33FullyConnectedSparseWeight1x4TaskE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %90, align 8
  %96 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %87, i64 -1, i32 1
  %97 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %88, i64 -1, i32 1
  %98 = bitcast %struct.TfLiteSparsity** %96 to i8*
  %99 = bitcast %struct.TfLiteSparsity** %97 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %98, i8* align 8 %99, i64 96, i1 false) #19
  %100 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %87, i64 -1
  %101 = icmp eq %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %89, %81
  br i1 %101, label %102, label %86

102:                                              ; preds = %86
  %103 = load i64, i64* %18, align 8
  %104 = load %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"*, %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"** %15, align 8
  br label %105

105:                                              ; preds = %84, %102
  %106 = phi %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* [ %81, %84 ], [ %104, %102 ]
  %107 = phi %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* [ %46, %84 ], [ %100, %102 ]
  %108 = phi i64 [ %85, %84 ], [ %103, %102 ]
  %109 = ptrtoint %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %107 to i64
  store i64 %109, i64* %18, align 8
  store i64 %79, i64* %16, align 8
  store i64 %48, i64* %28, align 8
  %110 = inttoptr i64 %108 to %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"*
  %111 = icmp eq %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %106, %110
  br i1 %111, label %119, label %112

112:                                              ; preds = %105, %112
  %113 = phi %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* [ %114, %112 ], [ %106, %105 ]
  %114 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %113, i64 -1
  %115 = bitcast %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %114 to void (%"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"*)***
  %116 = load void (%"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"*)**, void (%"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"*)*** %115, align 8
  %117 = load void (%"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"*)*, void (%"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"*)** %116, align 8
  tail call void %117(%"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %114) #19
  %118 = icmp eq %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %114, %110
  br i1 %118, label %119, label %112

119:                                              ; preds = %112, %105
  %120 = icmp eq i64 %108, 0
  br i1 %120, label %123, label %121

121:                                              ; preds = %119
  %122 = inttoptr i64 %108 to i8*
  tail call void @_ZdlPv(i8* %122) #18
  br label %123

123:                                              ; preds = %119, %121
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp11WorkersPool7ExecuteIN6tflite13optimized_ops33FullyConnectedSparseWeight1x4TaskEEEviPT_(%"class.gemmlowp::WorkersPool"*, i32, %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"*) local_unnamed_addr #1 comdat align 2 {
  %4 = alloca %"class.std::__1::chrono::duration.98", align 8
  %5 = add nsw i32 %1, -1
  %6 = sext i32 %5 to i64
  tail call void @_ZN8gemmlowp11WorkersPool13CreateWorkersEm(%"class.gemmlowp::WorkersPool"* %0, i64 %6)
  %7 = getelementptr inbounds %"class.gemmlowp::WorkersPool", %"class.gemmlowp::WorkersPool"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %8 = load atomic i64, i64* %7 monotonic, align 8
  store atomic i64 %6, i64* %7 release, align 8
  %9 = icmp eq i32 %5, 0
  br i1 %9, label %12, label %10

10:                                               ; preds = %3
  %11 = getelementptr inbounds %"class.gemmlowp::WorkersPool", %"class.gemmlowp::WorkersPool"* %0, i64 0, i32 0, i32 0, i32 0
  br label %35

12:                                               ; preds = %46, %3
  %13 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %2, i64 %6, i32 0
  %14 = getelementptr inbounds %"class.gemmlowp::WorkersPool", %"class.gemmlowp::WorkersPool"* %0, i64 0, i32 2
  %15 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %2, i64 %6, i32 0, i32 1
  store %"class.gemmlowp::Allocator"* %14, %"class.gemmlowp::Allocator"** %15, align 8
  %16 = bitcast %"struct.gemmlowp::Task"* %13 to void (%"struct.gemmlowp::Task"*)***
  %17 = load void (%"struct.gemmlowp::Task"*)**, void (%"struct.gemmlowp::Task"*)*** %16, align 8
  %18 = getelementptr inbounds void (%"struct.gemmlowp::Task"*)*, void (%"struct.gemmlowp::Task"*)** %17, i64 2
  %19 = load void (%"struct.gemmlowp::Task"*)*, void (%"struct.gemmlowp::Task"*)** %18, align 8
  tail call void %19(%"struct.gemmlowp::Task"* %13) #19
  %20 = load atomic i64, i64* %7 acquire, align 8
  %21 = icmp eq i64 %20, 0
  br i1 %21, label %34, label %22

22:                                               ; preds = %12
  %23 = bitcast %"class.std::__1::chrono::duration.98"* %4 to i8*
  %24 = getelementptr inbounds %"class.std::__1::chrono::duration.98", %"class.std::__1::chrono::duration.98"* %4, i64 0, i32 0
  br label %25

25:                                               ; preds = %30, %22
  %26 = phi i32 [ 0, %22 ], [ %31, %30 ]
  call void asm sideeffect "nop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0A", "~{dirflag},~{fpsr},~{flags}"() #19, !srcloc !301
  %27 = add nsw i32 %26, 64
  %28 = icmp sgt i32 %27, 4000000
  br i1 %28, label %29, label %30

29:                                               ; preds = %25
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %23) #19
  store i64 1000000, i64* %24, align 8
  call void @_ZNSt3__111this_thread9sleep_forERKNS_6chrono8durationIxNS_5ratioILl1ELl1000000000EEEEE(%"class.std::__1::chrono::duration.98"* nonnull dereferenceable(8) %4) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %23) #19
  br label %30

30:                                               ; preds = %29, %25
  %31 = phi i32 [ 0, %29 ], [ %27, %25 ]
  %32 = load atomic i64, i64* %7 acquire, align 8
  %33 = icmp eq i64 %32, 0
  br i1 %33, label %34, label %25

34:                                               ; preds = %30, %12
  ret void

35:                                               ; preds = %10, %46
  %36 = phi i64 [ 0, %10 ], [ %54, %46 ]
  %37 = load %"class.gemmlowp::Worker"**, %"class.gemmlowp::Worker"*** %11, align 8
  %38 = getelementptr inbounds %"class.gemmlowp::Worker"*, %"class.gemmlowp::Worker"** %37, i64 %36
  %39 = load %"class.gemmlowp::Worker"*, %"class.gemmlowp::Worker"** %38, align 8
  %40 = getelementptr inbounds %"class.gemmlowp::Worker", %"class.gemmlowp::Worker"* %39, i64 0, i32 3
  %41 = tail call i32 @pthread_mutex_lock(%union.pthread_mutex_t* %40) #19
  %42 = getelementptr inbounds %"class.gemmlowp::Worker", %"class.gemmlowp::Worker"* %39, i64 0, i32 4, i32 0, i32 0, i32 0, i32 0
  %43 = load atomic i32, i32* %42 monotonic, align 4
  %44 = icmp ult i32 %43, 3
  br i1 %44, label %46, label %45

45:                                               ; preds = %35
  tail call void @abort() #20
  unreachable

46:                                               ; preds = %35
  %47 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %2, i64 %36, i32 0
  %48 = getelementptr inbounds %"class.gemmlowp::Worker", %"class.gemmlowp::Worker"* %39, i64 0, i32 5
  %49 = getelementptr inbounds %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task", %"struct.tflite::optimized_ops::FullyConnectedSparseWeight1x4Task"* %2, i64 %36, i32 0, i32 1
  store %"class.gemmlowp::Allocator"* %48, %"class.gemmlowp::Allocator"** %49, align 8
  %50 = getelementptr inbounds %"class.gemmlowp::Worker", %"class.gemmlowp::Worker"* %39, i64 0, i32 1
  store %"struct.gemmlowp::Task"* %47, %"struct.gemmlowp::Task"** %50, align 8
  store atomic i32 2, i32* %42 monotonic, align 4
  %51 = getelementptr inbounds %"class.gemmlowp::Worker", %"class.gemmlowp::Worker"* %39, i64 0, i32 2
  %52 = tail call i32 @pthread_cond_broadcast(%union.pthread_cond_t* %51) #19
  %53 = tail call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* %40) #19
  %54 = add nuw i64 %36, 1
  %55 = icmp ult i64 %54, %6
  br i1 %55, label %35, label %12
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp11WorkersPool13CreateWorkersEm(%"class.gemmlowp::WorkersPool"*, i64) local_unnamed_addr #1 comdat align 2 {
  %3 = alloca %"class.std::__1::chrono::duration.98", align 8
  %4 = getelementptr inbounds %"class.gemmlowp::WorkersPool", %"class.gemmlowp::WorkersPool"* %0, i64 0, i32 0, i32 0, i32 1
  %5 = bitcast %"class.gemmlowp::Worker"*** %4 to i64*
  %6 = load i64, i64* %5, align 8
  %7 = bitcast %"class.gemmlowp::WorkersPool"* %0 to i64*
  %8 = load i64, i64* %7, align 8
  %9 = sub i64 %6, %8
  %10 = ashr exact i64 %9, 3
  %11 = icmp ult i64 %10, %1
  br i1 %11, label %12, label %130

12:                                               ; preds = %2
  %13 = getelementptr inbounds %"class.gemmlowp::WorkersPool", %"class.gemmlowp::WorkersPool"* %0, i64 0, i32 1
  %14 = sub i64 %1, %10
  %15 = getelementptr inbounds %"class.gemmlowp::BlockingCounter", %"class.gemmlowp::BlockingCounter"* %13, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %16 = load atomic i64, i64* %15 monotonic, align 8
  store atomic i64 %14, i64* %15 release, align 8
  %17 = load i64, i64* %5, align 8
  %18 = load i64, i64* %7, align 8
  %19 = sub i64 %17, %18
  %20 = ashr exact i64 %19, 3
  %21 = icmp ult i64 %20, %1
  br i1 %21, label %22, label %115

22:                                               ; preds = %12
  %23 = getelementptr inbounds %"class.gemmlowp::WorkersPool", %"class.gemmlowp::WorkersPool"* %0, i64 0, i32 0, i32 0, i32 2, i32 0, i32 0
  %24 = bitcast %"class.gemmlowp::Worker"*** %23 to i64*
  %25 = getelementptr inbounds %"class.gemmlowp::WorkersPool", %"class.gemmlowp::WorkersPool"* %0, i64 0, i32 0, i32 0, i32 0
  br label %26

26:                                               ; preds = %22, %109
  %27 = tail call i8* @_Znwm(i64 208) #18
  %28 = getelementptr inbounds i8, i8* %27, i64 8
  %29 = bitcast i8* %28 to %"struct.gemmlowp::Task"**
  store %"struct.gemmlowp::Task"* null, %"struct.gemmlowp::Task"** %29, align 8
  %30 = getelementptr inbounds i8, i8* %27, i64 104
  %31 = bitcast i8* %30 to i32*
  store i32 0, i32* %31, align 4
  %32 = getelementptr inbounds i8, i8* %27, i64 112
  store i8 0, i8* %32, align 8
  %33 = getelementptr inbounds i8, i8* %27, i64 120
  %34 = getelementptr inbounds i8, i8* %27, i64 192
  %35 = bitcast i8* %34 to i64*
  store i64 0, i64* %35, align 8
  tail call void @llvm.memset.p0i8.i64(i8* align 8 %33, i8 0, i64 32, i1 false) #19
  %36 = getelementptr inbounds i8, i8* %27, i64 200
  %37 = bitcast i8* %36 to %"class.gemmlowp::BlockingCounter"**
  store %"class.gemmlowp::BlockingCounter"* %13, %"class.gemmlowp::BlockingCounter"** %37, align 8
  %38 = getelementptr inbounds i8, i8* %27, i64 16
  %39 = bitcast i8* %38 to %union.pthread_cond_t*
  %40 = tail call i32 @pthread_cond_init(%union.pthread_cond_t* %39, %union.pthread_condattr_t* null) #19
  %41 = getelementptr inbounds i8, i8* %27, i64 64
  %42 = bitcast i8* %41 to %union.pthread_mutex_t*
  %43 = tail call i32 @pthread_mutex_init(%union.pthread_mutex_t* %42, %union.pthread_mutexattr_t* null) #19
  %44 = bitcast i8* %27 to i64*
  %45 = tail call i32 @pthread_create(i64* nonnull %44, %union.pthread_attr_t* null, i8* (i8*)* nonnull @_ZN8gemmlowp6Worker10ThreadFuncEPv, i8* nonnull %27) #19
  %46 = ptrtoint i8* %27 to i64
  %47 = load %"class.gemmlowp::Worker"**, %"class.gemmlowp::Worker"*** %4, align 8
  %48 = load %"class.gemmlowp::Worker"**, %"class.gemmlowp::Worker"*** %23, align 8
  %49 = icmp ult %"class.gemmlowp::Worker"** %47, %48
  %50 = ptrtoint %"class.gemmlowp::Worker"** %48 to i64
  br i1 %49, label %51, label %55

51:                                               ; preds = %26
  %52 = bitcast %"class.gemmlowp::Worker"** %47 to i64*
  store i64 %46, i64* %52, align 8
  %53 = getelementptr inbounds %"class.gemmlowp::Worker"*, %"class.gemmlowp::Worker"** %47, i64 1
  %54 = ptrtoint %"class.gemmlowp::Worker"** %53 to i64
  store i64 %54, i64* %5, align 8
  br label %109

55:                                               ; preds = %26
  %56 = ptrtoint %"class.gemmlowp::Worker"** %47 to i64
  %57 = load i64, i64* %7, align 8
  %58 = sub i64 %56, %57
  %59 = ashr exact i64 %58, 3
  %60 = add nsw i64 %59, 1
  %61 = icmp ugt i64 %60, 2305843009213693951
  br i1 %61, label %62, label %64

62:                                               ; preds = %55
  %63 = bitcast %"class.gemmlowp::WorkersPool"* %0 to %"class.std::__1::__vector_base_common"*
  tail call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* %63) #20
  unreachable

64:                                               ; preds = %55
  %65 = sub i64 %50, %57
  %66 = ashr exact i64 %65, 3
  %67 = icmp ult i64 %66, 1152921504606846975
  br i1 %67, label %68, label %76

68:                                               ; preds = %64
  %69 = ashr exact i64 %65, 2
  %70 = icmp ult i64 %69, %60
  %71 = select i1 %70, i64 %60, i64 %69
  %72 = icmp eq i64 %71, 0
  br i1 %72, label %81, label %73

73:                                               ; preds = %68
  %74 = icmp ugt i64 %71, 2305843009213693951
  br i1 %74, label %75, label %76

75:                                               ; preds = %73
  tail call void @abort() #20
  unreachable

76:                                               ; preds = %73, %64
  %77 = phi i64 [ %71, %73 ], [ 2305843009213693951, %64 ]
  %78 = shl i64 %77, 3
  %79 = tail call i8* @_Znwm(i64 %78) #18
  %80 = bitcast i8* %79 to %"class.gemmlowp::Worker"**
  br label %81

81:                                               ; preds = %76, %68
  %82 = phi i64 [ %77, %76 ], [ 0, %68 ]
  %83 = phi %"class.gemmlowp::Worker"** [ %80, %76 ], [ null, %68 ]
  %84 = getelementptr inbounds %"class.gemmlowp::Worker"*, %"class.gemmlowp::Worker"** %83, i64 %59
  %85 = getelementptr inbounds %"class.gemmlowp::Worker"*, %"class.gemmlowp::Worker"** %83, i64 %82
  %86 = ptrtoint %"class.gemmlowp::Worker"** %85 to i64
  %87 = bitcast %"class.gemmlowp::Worker"** %84 to i64*
  store i64 %46, i64* %87, align 8
  %88 = getelementptr inbounds %"class.gemmlowp::Worker"*, %"class.gemmlowp::Worker"** %84, i64 1
  %89 = ptrtoint %"class.gemmlowp::Worker"** %88 to i64
  %90 = load %"class.gemmlowp::Worker"**, %"class.gemmlowp::Worker"*** %25, align 8
  %91 = load i64, i64* %5, align 8
  %92 = ptrtoint %"class.gemmlowp::Worker"** %90 to i64
  %93 = sub i64 %91, %92
  %94 = ashr exact i64 %93, 3
  %95 = sub nsw i64 0, %94
  %96 = getelementptr inbounds %"class.gemmlowp::Worker"*, %"class.gemmlowp::Worker"** %84, i64 %95
  %97 = ptrtoint %"class.gemmlowp::Worker"** %96 to i64
  %98 = icmp sgt i64 %93, 0
  br i1 %98, label %99, label %103

99:                                               ; preds = %81
  %100 = bitcast %"class.gemmlowp::Worker"** %96 to i8*
  %101 = bitcast %"class.gemmlowp::Worker"** %90 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %100, i8* align 8 %101, i64 %93, i1 false) #19
  %102 = load %"class.gemmlowp::Worker"**, %"class.gemmlowp::Worker"*** %25, align 8
  br label %103

103:                                              ; preds = %99, %81
  %104 = phi %"class.gemmlowp::Worker"** [ %90, %81 ], [ %102, %99 ]
  store i64 %97, i64* %7, align 8
  store i64 %89, i64* %5, align 8
  store i64 %86, i64* %24, align 8
  %105 = icmp eq %"class.gemmlowp::Worker"** %104, null
  br i1 %105, label %109, label %106

106:                                              ; preds = %103
  %107 = bitcast %"class.gemmlowp::Worker"** %104 to i8*
  tail call void @_ZdlPv(i8* %107) #18
  %108 = load i64, i64* %5, align 8
  br label %109

109:                                              ; preds = %51, %103, %106
  %110 = phi i64 [ %54, %51 ], [ %89, %103 ], [ %108, %106 ]
  %111 = load i64, i64* %7, align 8
  %112 = sub i64 %110, %111
  %113 = ashr exact i64 %112, 3
  %114 = icmp ult i64 %113, %1
  br i1 %114, label %26, label %115

115:                                              ; preds = %109, %12
  %116 = load atomic i64, i64* %15 acquire, align 8
  %117 = icmp eq i64 %116, 0
  br i1 %117, label %130, label %118

118:                                              ; preds = %115
  %119 = bitcast %"class.std::__1::chrono::duration.98"* %3 to i8*
  %120 = getelementptr inbounds %"class.std::__1::chrono::duration.98", %"class.std::__1::chrono::duration.98"* %3, i64 0, i32 0
  br label %121

121:                                              ; preds = %126, %118
  %122 = phi i32 [ 0, %118 ], [ %127, %126 ]
  call void asm sideeffect "nop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0A", "~{dirflag},~{fpsr},~{flags}"() #19, !srcloc !301
  %123 = add nsw i32 %122, 64
  %124 = icmp sgt i32 %123, 4000000
  br i1 %124, label %125, label %126

125:                                              ; preds = %121
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %119) #19
  store i64 1000000, i64* %120, align 8
  call void @_ZNSt3__111this_thread9sleep_forERKNS_6chrono8durationIxNS_5ratioILl1ELl1000000000EEEEE(%"class.std::__1::chrono::duration.98"* nonnull dereferenceable(8) %3) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %119) #19
  br label %126

126:                                              ; preds = %125, %121
  %127 = phi i32 [ 0, %125 ], [ %123, %121 ]
  %128 = load atomic i64, i64* %15 acquire, align 8
  %129 = icmp eq i64 %128, 0
  br i1 %129, label %130, label %121

130:                                              ; preds = %126, %115, %2
  ret void
}

; Function Attrs: nounwind
declare i32 @pthread_cond_init(%union.pthread_cond_t*, %union.pthread_condattr_t*) local_unnamed_addr #14

; Function Attrs: nounwind
declare i32 @pthread_mutex_init(%union.pthread_mutex_t*, %union.pthread_mutexattr_t*) local_unnamed_addr #14

; Function Attrs: nounwind
declare i32 @pthread_create(i64*, %union.pthread_attr_t*, i8* (i8*)*, i8*) local_unnamed_addr #14

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i8* @_ZN8gemmlowp6Worker10ThreadFuncEPv(i8*) #1 comdat align 2 {
  %2 = bitcast i8* %0 to %"class.gemmlowp::Worker"*
  tail call void @_ZN8gemmlowp6Worker10ThreadFuncEv(%"class.gemmlowp::Worker"* %2)
  ret i8* null
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp6Worker10ThreadFuncEv(%"class.gemmlowp::Worker"*) local_unnamed_addr #1 comdat align 2 {
  %2 = getelementptr inbounds %"class.gemmlowp::Worker", %"class.gemmlowp::Worker"* %0, i64 0, i32 3
  %3 = tail call i32 @pthread_mutex_lock(%union.pthread_mutex_t* %2) #19
  %4 = getelementptr inbounds %"class.gemmlowp::Worker", %"class.gemmlowp::Worker"* %0, i64 0, i32 4, i32 0, i32 0, i32 0, i32 0
  %5 = load atomic i32, i32* %4 monotonic, align 4
  %6 = icmp ult i32 %5, 3
  br i1 %6, label %8, label %7

7:                                                ; preds = %1
  tail call void @abort() #20
  unreachable

8:                                                ; preds = %1
  %9 = getelementptr inbounds %"class.gemmlowp::Worker", %"class.gemmlowp::Worker"* %0, i64 0, i32 1
  %10 = load %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %9, align 8
  %11 = icmp eq %"struct.gemmlowp::Task"* %10, null
  br i1 %11, label %17, label %12

12:                                               ; preds = %8
  %13 = bitcast %"struct.gemmlowp::Task"* %10 to void (%"struct.gemmlowp::Task"*)***
  %14 = load void (%"struct.gemmlowp::Task"*)**, void (%"struct.gemmlowp::Task"*)*** %13, align 8
  %15 = getelementptr inbounds void (%"struct.gemmlowp::Task"*)*, void (%"struct.gemmlowp::Task"*)** %14, i64 2
  %16 = load void (%"struct.gemmlowp::Task"*)*, void (%"struct.gemmlowp::Task"*)** %15, align 8
  tail call void %16(%"struct.gemmlowp::Task"* nonnull %10) #19
  store %"struct.gemmlowp::Task"* null, %"struct.gemmlowp::Task"** %9, align 8
  br label %17

17:                                               ; preds = %8, %12
  store atomic i32 1, i32* %4 monotonic, align 4
  %18 = getelementptr inbounds %"class.gemmlowp::Worker", %"class.gemmlowp::Worker"* %0, i64 0, i32 2
  %19 = tail call i32 @pthread_cond_broadcast(%union.pthread_cond_t* %18) #19
  %20 = tail call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* %2) #19
  %21 = getelementptr inbounds %"class.gemmlowp::Worker", %"class.gemmlowp::Worker"* %0, i64 0, i32 6
  br label %22

22:                                               ; preds = %61, %17
  %23 = load %"class.gemmlowp::BlockingCounter"*, %"class.gemmlowp::BlockingCounter"** %21, align 8
  %24 = getelementptr inbounds %"class.gemmlowp::BlockingCounter", %"class.gemmlowp::BlockingCounter"* %23, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %25 = atomicrmw sub i64* %24, i64 1 acq_rel
  %26 = load atomic i32, i32* %4 acquire, align 4
  %27 = icmp eq i32 %26, 1
  br i1 %27, label %28, label %46

28:                                               ; preds = %22, %31
  %29 = phi i32 [ %32, %31 ], [ 0, %22 ]
  %30 = icmp ult i32 %29, 4000000
  br i1 %30, label %31, label %35

31:                                               ; preds = %28
  tail call void asm sideeffect "nop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0A", "~{dirflag},~{fpsr},~{flags}"() #19, !srcloc !301
  %32 = add nuw nsw i32 %29, 64
  %33 = load atomic i32, i32* %4 acquire, align 4
  %34 = icmp eq i32 %33, 1
  br i1 %34, label %28, label %46

35:                                               ; preds = %28
  %36 = tail call i32 @pthread_mutex_lock(%union.pthread_mutex_t* %2) #19
  %37 = load atomic i32, i32* %4 acquire, align 4
  %38 = icmp eq i32 %37, 1
  br i1 %38, label %39, label %43

39:                                               ; preds = %35, %39
  %40 = tail call i32 @pthread_cond_wait(%union.pthread_cond_t* %18, %union.pthread_mutex_t* %2) #19
  %41 = load atomic i32, i32* %4 acquire, align 4
  %42 = icmp eq i32 %41, 1
  br i1 %42, label %39, label %43

43:                                               ; preds = %39, %35
  %44 = phi i32 [ %37, %35 ], [ %41, %39 ]
  %45 = tail call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* %2) #19
  br label %46

46:                                               ; preds = %31, %22, %43
  %47 = phi i32 [ %26, %22 ], [ %44, %43 ], [ %33, %31 ]
  switch i32 %47, label %64 [
    i32 2, label %48
    i32 3, label %65
  ]

48:                                               ; preds = %46
  %49 = tail call i32 @pthread_mutex_lock(%union.pthread_mutex_t* %2) #19
  %50 = load atomic i32, i32* %4 monotonic, align 4
  %51 = icmp ult i32 %50, 3
  br i1 %51, label %53, label %52

52:                                               ; preds = %48
  tail call void @abort() #20
  unreachable

53:                                               ; preds = %48
  %54 = load %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %9, align 8
  %55 = icmp eq %"struct.gemmlowp::Task"* %54, null
  br i1 %55, label %61, label %56

56:                                               ; preds = %53
  %57 = bitcast %"struct.gemmlowp::Task"* %54 to void (%"struct.gemmlowp::Task"*)***
  %58 = load void (%"struct.gemmlowp::Task"*)**, void (%"struct.gemmlowp::Task"*)*** %57, align 8
  %59 = getelementptr inbounds void (%"struct.gemmlowp::Task"*)*, void (%"struct.gemmlowp::Task"*)** %58, i64 2
  %60 = load void (%"struct.gemmlowp::Task"*)*, void (%"struct.gemmlowp::Task"*)** %59, align 8
  tail call void %60(%"struct.gemmlowp::Task"* nonnull %54) #19
  store %"struct.gemmlowp::Task"* null, %"struct.gemmlowp::Task"** %9, align 8
  br label %61

61:                                               ; preds = %53, %56
  store atomic i32 1, i32* %4 monotonic, align 4
  %62 = tail call i32 @pthread_cond_broadcast(%union.pthread_cond_t* %18) #19
  %63 = tail call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* %2) #19
  br label %22

64:                                               ; preds = %46
  tail call void @abort() #20
  unreachable

65:                                               ; preds = %46
  ret void
}

; Function Attrs: nounwind
declare i32 @pthread_mutex_lock(%union.pthread_mutex_t*) local_unnamed_addr #14

; Function Attrs: nounwind
declare i32 @pthread_cond_broadcast(%union.pthread_cond_t*) local_unnamed_addr #14

; Function Attrs: nounwind
declare i32 @pthread_mutex_unlock(%union.pthread_mutex_t*) local_unnamed_addr #14

declare i32 @pthread_cond_wait(%union.pthread_cond_t*, %union.pthread_mutex_t*) local_unnamed_addr #5

declare void @_ZNSt3__111this_thread9sleep_forERKNS_6chrono8durationIxNS_5ratioILl1ELl1000000000EEEEE(%"class.std::__1::chrono::duration.98"* dereferenceable(8)) local_unnamed_addr #5

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN6tflite16cpu_backend_gemm6detail16GemmImplUsingRuyIffffLNS0_18QuantizationFlavorE0EE3RunERKNS0_12MatrixParamsIfEEPKfS8_SA_S8_PfRKNS0_10GemmParamsIffLS3_0EEEPNS_17CpuBackendContextE(%"struct.tflite::cpu_backend_gemm::MatrixParams"* dereferenceable(20), float*, %"struct.tflite::cpu_backend_gemm::MatrixParams"* dereferenceable(20), float*, %"struct.tflite::cpu_backend_gemm::MatrixParams"* dereferenceable(20), float*, %"struct.tflite::cpu_backend_gemm::GemmParams"* dereferenceable(40), %"class.tflite::CpuBackendContext"*) local_unnamed_addr #1 comdat align 2 {
  %9 = alloca %"struct.ruy::Mat", align 8
  %10 = alloca %"struct.ruy::Mat", align 8
  %11 = alloca %"struct.ruy::Mat", align 8
  %12 = alloca %"class.ruy::MulParams", align 8
  %13 = getelementptr inbounds %"class.tflite::CpuBackendContext", %"class.tflite::CpuBackendContext"* %7, i64 0, i32 4
  %14 = load i8, i8* %13, align 4, !range !10
  %15 = icmp ne i8 %14, 0
  %16 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %0, i64 0, i32 0
  %17 = load i32, i32* %16, align 4
  %18 = icmp ne i32 %17, 0
  %19 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %0, i64 0, i32 1
  %20 = load i32, i32* %19, align 4
  %21 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %0, i64 0, i32 2
  %22 = load i32, i32* %21, align 4
  %23 = select i1 %18, i32 %22, i32 %20
  %24 = ptrtoint float* %1 to i64
  %25 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %0, i64 0, i32 3
  %26 = bitcast float* %25 to i32*
  %27 = load i32, i32* %26, align 4
  br i1 %15, label %28, label %35

28:                                               ; preds = %8
  %29 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %0, i64 0, i32 4
  %30 = load i8, i8* %29, align 4
  %31 = icmp eq i8 %30, 1
  %32 = zext i1 %31 to i8
  %33 = icmp eq i8 %30, 2
  %34 = select i1 %33, i8 3, i8 %32
  br label %35

35:                                               ; preds = %8, %28
  %36 = phi i8 [ %34, %28 ], [ 0, %8 ]
  %37 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %2, i64 0, i32 0
  %38 = load i32, i32* %37, align 4
  %39 = icmp ne i32 %38, 0
  %40 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %2, i64 0, i32 1
  %41 = load i32, i32* %40, align 4
  %42 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %2, i64 0, i32 2
  %43 = load i32, i32* %42, align 4
  %44 = select i1 %39, i32 %43, i32 %41
  %45 = ptrtoint float* %3 to i64
  %46 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %2, i64 0, i32 3
  %47 = bitcast float* %46 to i32*
  %48 = load i32, i32* %47, align 4
  br i1 %15, label %49, label %56

49:                                               ; preds = %35
  %50 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %2, i64 0, i32 4
  %51 = load i8, i8* %50, align 4
  %52 = icmp eq i8 %51, 1
  %53 = zext i1 %52 to i8
  %54 = icmp eq i8 %51, 2
  %55 = select i1 %54, i8 3, i8 %53
  br label %56

56:                                               ; preds = %35, %49
  %57 = phi i8 [ %55, %49 ], [ 0, %35 ]
  %58 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %4, i64 0, i32 0
  %59 = load i32, i32* %58, align 4
  %60 = icmp ne i32 %59, 0
  %61 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %4, i64 0, i32 1
  %62 = load i32, i32* %61, align 4
  %63 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %4, i64 0, i32 2
  %64 = load i32, i32* %63, align 4
  %65 = select i1 %60, i32 %64, i32 %62
  %66 = ptrtoint float* %5 to i64
  %67 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams", %"struct.tflite::cpu_backend_gemm::MatrixParams"* %4, i64 0, i32 3
  %68 = bitcast float* %67 to i32*
  %69 = load i32, i32* %68, align 4
  %70 = bitcast %"class.ruy::MulParams"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %70) #19
  %71 = getelementptr inbounds %"class.ruy::MulParams", %"class.ruy::MulParams"* %12, i64 0, i32 1
  %72 = getelementptr inbounds %"class.ruy::MulParams", %"class.ruy::MulParams"* %12, i64 0, i32 2
  %73 = getelementptr inbounds %"class.ruy::MulParams", %"class.ruy::MulParams"* %12, i64 0, i32 3
  %74 = getelementptr inbounds %"class.ruy::MulParams", %"class.ruy::MulParams"* %12, i64 0, i32 5
  %75 = getelementptr inbounds %"class.ruy::MulParams", %"class.ruy::MulParams"* %12, i64 0, i32 6
  %76 = bitcast %"struct.tflite::cpu_backend_gemm::GemmParams"* %6 to i32*
  %77 = load i32, i32* %76, align 8
  %78 = bitcast float* %71 to i32*
  store i32 %77, i32* %78, align 8
  %79 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams", %"struct.tflite::cpu_backend_gemm::GemmParams"* %6, i64 0, i32 1
  %80 = load i32, i32* %79, align 4
  store i32 %80, i32* %72, align 4
  %81 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams", %"struct.tflite::cpu_backend_gemm::GemmParams"* %6, i64 0, i32 2
  %82 = bitcast float** %81 to <2 x i64>*
  %83 = load <2 x i64>, <2 x i64>* %82, align 8
  %84 = bitcast float** %73 to <2 x i64>*
  store <2 x i64> %83, <2 x i64>* %84, align 8
  %85 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams", %"struct.tflite::cpu_backend_gemm::GemmParams"* %6, i64 0, i32 4
  %86 = bitcast float** %85 to i64*
  %87 = load i64, i64* %86, align 8
  %88 = bitcast %"class.ruy::MulParams"* %12 to i64*
  store i64 %87, i64* %88, align 8
  %89 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams", %"struct.tflite::cpu_backend_gemm::GemmParams"* %6, i64 0, i32 5
  %90 = bitcast float* %89 to i32*
  %91 = load i32, i32* %90, align 8
  %92 = bitcast float* %74 to i32*
  store i32 %91, i32* %92, align 8
  %93 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams", %"struct.tflite::cpu_backend_gemm::GemmParams"* %6, i64 0, i32 6
  %94 = bitcast float* %93 to i32*
  %95 = load i32, i32* %94, align 4
  %96 = bitcast float* %75 to i32*
  store i32 %95, i32* %96, align 4
  %97 = getelementptr inbounds %"class.tflite::CpuBackendContext", %"class.tflite::CpuBackendContext"* %7, i64 0, i32 1, i32 0, i32 0, i32 0
  %98 = load %"class.ruy::Context"*, %"class.ruy::Context"** %97, align 8
  %99 = bitcast %"struct.ruy::Mat"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %99) #19
  %100 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %9, i64 0, i32 1, i32 2
  %101 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %9, i64 0, i32 2
  %102 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %9, i64 0, i32 3
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %99, i8 -86, i64 24, i1 false) #19, !alias.scope !302
  %103 = bitcast i8* %102 to i32*
  store i32 -1431655936, i32* %103, align 4, !alias.scope !302
  %104 = bitcast %"struct.ruy::Mat"* %9 to i64*
  store i64 %24, i64* %104, align 8, !alias.scope !302
  %105 = zext i32 %23 to i64
  %106 = zext i1 %18 to i64
  %107 = shl nuw nsw i64 %106, 32
  %108 = or i64 %107, %105
  %109 = zext i32 %22 to i64
  %110 = shl nuw i64 %109, 32
  %111 = zext i32 %20 to i64
  %112 = or i64 %110, %111
  %113 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %9, i64 0, i32 1
  %114 = bitcast %"struct.ruy::MatLayout"* %113 to i64*
  store i64 %112, i64* %114, align 8, !alias.scope !302
  %115 = bitcast i32* %100 to i40*
  %116 = trunc i64 %108 to i40
  store i40 %116, i40* %115, align 8, !alias.scope !302
  %117 = bitcast float* %101 to i32*
  store i32 %27, i32* %117, align 8, !alias.scope !302
  store i8 %36, i8* %102, align 4, !alias.scope !302
  %118 = bitcast %"struct.ruy::Mat"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %118) #19
  %119 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %10, i64 0, i32 1, i32 2
  %120 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %10, i64 0, i32 2
  %121 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %10, i64 0, i32 3
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %118, i8 -86, i64 24, i1 false) #19, !alias.scope !305
  %122 = bitcast i8* %121 to i32*
  store i32 -1431655936, i32* %122, align 4, !alias.scope !305
  %123 = bitcast %"struct.ruy::Mat"* %10 to i64*
  store i64 %45, i64* %123, align 8, !alias.scope !305
  %124 = zext i32 %44 to i64
  %125 = zext i1 %39 to i64
  %126 = shl nuw nsw i64 %125, 32
  %127 = or i64 %126, %124
  %128 = zext i32 %43 to i64
  %129 = shl nuw i64 %128, 32
  %130 = zext i32 %41 to i64
  %131 = or i64 %129, %130
  %132 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %10, i64 0, i32 1
  %133 = bitcast %"struct.ruy::MatLayout"* %132 to i64*
  store i64 %131, i64* %133, align 8, !alias.scope !305
  %134 = bitcast i32* %119 to i40*
  %135 = trunc i64 %127 to i40
  store i40 %135, i40* %134, align 8, !alias.scope !305
  %136 = bitcast float* %120 to i32*
  store i32 %48, i32* %136, align 8, !alias.scope !305
  store i8 %57, i8* %121, align 4, !alias.scope !305
  %137 = bitcast %"struct.ruy::Mat"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %137) #19
  %138 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %11, i64 0, i32 1, i32 2
  %139 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %11, i64 0, i32 2
  %140 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %11, i64 0, i32 3
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %137, i8 -86, i64 24, i1 false) #19, !alias.scope !308
  %141 = bitcast i8* %140 to i32*
  store i32 -1431655936, i32* %141, align 4, !alias.scope !308
  %142 = bitcast %"struct.ruy::Mat"* %11 to i64*
  store i64 %66, i64* %142, align 8, !alias.scope !308
  %143 = zext i32 %65 to i64
  %144 = zext i1 %60 to i64
  %145 = shl nuw nsw i64 %144, 32
  %146 = or i64 %145, %143
  %147 = zext i32 %64 to i64
  %148 = shl nuw i64 %147, 32
  %149 = zext i32 %62 to i64
  %150 = or i64 %148, %149
  %151 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %11, i64 0, i32 1
  %152 = bitcast %"struct.ruy::MatLayout"* %151 to i64*
  store i64 %150, i64* %152, align 8, !alias.scope !308
  %153 = bitcast i32* %138 to i40*
  %154 = trunc i64 %146 to i40
  store i40 %154, i40* %153, align 8, !alias.scope !308
  %155 = bitcast float* %139 to i32*
  store i32 %69, i32* %155, align 8, !alias.scope !308
  %156 = tail call %"class.ruy::Ctx"* @_ZN3ruy7get_ctxEPNS_7ContextE(%"class.ruy::Context"* %98) #19
  call void @_ZN3ruy11DispatchMulILNS_4PathE26EfffNS_9MulParamsIffEEEEvRKNS_3MatIT0_EERKNS4_IT1_EERKT3_PNS_3CtxEPNS4_IT2_EE(%"struct.ruy::Mat"* nonnull dereferenceable(32) %9, %"struct.ruy::Mat"* nonnull dereferenceable(32) %10, %"class.ruy::MulParams"* nonnull dereferenceable(40) %12, %"class.ruy::Ctx"* %156, %"struct.ruy::Mat"* nonnull %11) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %137) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %118) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %99) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %70) #19
  ret void
}

declare void @_ZN6tflite16cpu_backend_gemm6detail18GemmImplUsingEigen3RunERKNS0_12MatrixParamsIfEEPKfS6_S8_S6_PfRKNS0_10GemmParamsIffLNS0_18QuantizationFlavorE0EEEPNS_17CpuBackendContextE(%"struct.tflite::cpu_backend_gemm::MatrixParams"* dereferenceable(20), float*, %"struct.tflite::cpu_backend_gemm::MatrixParams"* dereferenceable(20), float*, %"struct.tflite::cpu_backend_gemm::MatrixParams"* dereferenceable(20), float*, %"struct.tflite::cpu_backend_gemm::GemmParams"* dereferenceable(40), %"class.tflite::CpuBackendContext"*) local_unnamed_addr #5

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy11DispatchMulILNS_4PathE26EfffNS_9MulParamsIffEEEEvRKNS_3MatIT0_EERKNS4_IT1_EERKT3_PNS_3CtxEPNS4_IT2_EE(%"struct.ruy::Mat"* dereferenceable(32), %"struct.ruy::Mat"* dereferenceable(32), %"class.ruy::MulParams"* dereferenceable(40), %"class.ruy::Ctx"*, %"struct.ruy::Mat"*) local_unnamed_addr #1 comdat {
  %6 = alloca %"struct.ruy::TrMulParams", align 8
  %7 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %0, i64 0, i32 1, i32 1
  %8 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %0, i64 0, i32 2
  %9 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %1, i64 0, i32 2
  %10 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %4, i64 0, i32 2
  %11 = tail call zeroext i8 @_ZN3ruy3Ctx10SelectPathENS_4PathE(%"class.ruy::Ctx"* %3, i8 zeroext 26) #19
  %12 = bitcast %"struct.ruy::Mat"* %0 to i64*
  %13 = load i64, i64* %12, align 8
  %14 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %0, i64 0, i32 1, i32 0
  %15 = load i32, i32* %14, align 8
  %16 = load i32, i32* %7, align 4
  %17 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %0, i64 0, i32 1, i32 2
  %18 = load i32, i32* %17, align 8
  %19 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %0, i64 0, i32 1, i32 3
  %20 = load i8, i8* %19, align 4
  %21 = load float, float* %8, align 8
  %22 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %0, i64 0, i32 3
  %23 = load i8, i8* %22, align 4
  %24 = icmp eq i8 %20, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 0
  call void @llvm.lifetime.start.p0i8(i64 280, i8* nonnull %26) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %26, i8 -86, i64 272, i1 false)
  %27 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 1
  %28 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 0, i32 2
  %29 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 0, i32 4
  %30 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 0, i32 5
  %31 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1, i32 2
  %32 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1, i32 4
  store i32 0, i32* %32, align 8
  %33 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1, i32 5
  %34 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 4, i32 0, i32 0
  store i8 0, i8* %34, align 8
  %35 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 4, i32 0, i32 1
  store i8 0, i8* %35, align 1
  %36 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 4, i32 0, i32 2
  store i8 0, i8* %36, align 2
  %37 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 4, i32 2
  %38 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 4, i32 4
  store i32 0, i32* %38, align 8
  %39 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 4, i32 5
  store i8 0, i8* %39, align 4
  %40 = bitcast i8** %37 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %40, i8 0, i64 21, i1 false) #19
  %41 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 0, i32 0
  store i8 0, i8* %41, align 8
  %42 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 0, i32 1
  store i8 0, i8* %42, align 1
  %43 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 0, i32 2
  store i8 0, i8* %43, align 2
  %44 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 2
  %45 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 5
  %46 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 1
  %47 = bitcast i8** %44 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %47, i8 0, i64 11, i1 false) #19
  %48 = bitcast i8** %45 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %48, i8 0, i64 22, i1 false) #19
  %49 = bitcast %"class.ruy::SidePair"* %27 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %49, i8 0, i64 24, i1 false) #19
  store i8 1, i8* %46, align 1
  %50 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 2
  store i8 1, i8* %50, align 1
  %51 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 7
  store i32 0, i32* %51, align 8
  %52 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 0, i32 0
  store i8 0, i8* %52, align 8
  %53 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 0, i32 1
  store i8 0, i8* %53, align 1
  %54 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 0, i32 2
  store i8 0, i8* %54, align 2
  %55 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 2
  %56 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 5
  %57 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 1
  %58 = bitcast i8** %55 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %58, i8 0, i64 11, i1 false) #19
  %59 = bitcast i8** %56 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %59, i8 0, i64 22, i1 false) #19
  store i8 1, i8* %57, align 1
  %60 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 2
  store i8 1, i8* %60, align 1
  %61 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 7
  store i32 0, i32* %61, align 8
  %62 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 6, i32 0, i64 0
  store i8 0, i8* %62, align 8
  %63 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 6, i32 0, i64 1
  store i8 0, i8* %63, align 1
  %64 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 7
  %65 = fptosi float %21 to i32
  %66 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3
  %67 = bitcast %"class.ruy::SidePair.106"* %66 to i24*
  store i24 262401, i24* %67, align 8
  %68 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 0, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %68, i8 -86, i64 5, i1 false) #19
  %69 = bitcast i8** %28 to i64*
  store i64 %13, i64* %69, align 8
  %70 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 0, i32 3, i32 0
  store i32 %16, i32* %70, align 8
  %71 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 0, i32 3, i32 1
  store i32 %15, i32* %71, align 4
  %72 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 0, i32 3, i32 2
  store i32 %18, i32* %72, align 8
  %73 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 0, i32 3, i32 3
  store i8 %25, i8* %73, align 4
  %74 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 0, i32 3, i32 4, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %74, i8 -86, i64 3, i1 false) #19
  store i32 %65, i32* %29, align 8
  store i8 %23, i8* %30, align 4
  %75 = bitcast %"struct.ruy::Mat"* %1 to i64*
  %76 = load i64, i64* %75, align 8, !noalias !311
  %77 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %1, i64 0, i32 1
  %78 = bitcast %"struct.ruy::MatLayout"* %77 to i8*
  %79 = load float, float* %9, align 8, !noalias !311
  %80 = fptosi float %79 to i32
  %81 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %1, i64 0, i32 3
  %82 = load i8, i8* %81, align 4, !noalias !311
  %83 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1
  %84 = bitcast %"struct.ruy::EMat"* %83 to i24*
  store i24 262401, i24* %84, align 8
  %85 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %85, i8 -86, i64 5, i1 false) #19
  %86 = bitcast i8** %31 to i64*
  store i64 %76, i64* %86, align 8
  %87 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1, i32 3
  %88 = bitcast %"struct.ruy::MatLayout"* %87 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %88, i8* align 4 %78, i64 13, i1 false)
  %89 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1, i32 3, i32 4, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %89, i8 -86, i64 3, i1 false) #19
  store i32 %80, i32* %32, align 8
  store i8 %82, i8* %33, align 4
  %90 = bitcast %"struct.ruy::Mat"* %4 to i64*
  %91 = load i64, i64* %90, align 8, !noalias !314
  %92 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %4, i64 0, i32 1
  %93 = bitcast %"struct.ruy::MatLayout"* %92 to i8*
  %94 = load float, float* %10, align 8, !noalias !314
  %95 = fptosi float %94 to i32
  %96 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %4, i64 0, i32 3
  %97 = load i8, i8* %96, align 4, !noalias !314
  %98 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 4
  %99 = bitcast %"struct.ruy::EMat"* %98 to i24*
  store i24 262401, i24* %99, align 8
  %100 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 4, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %100, i8 -86, i64 5, i1 false) #19
  %101 = bitcast i8** %37 to i64*
  store i64 %91, i64* %101, align 8
  %102 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 4, i32 3
  %103 = bitcast %"struct.ruy::MatLayout"* %102 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %103, i8* align 4 %93, i64 13, i1 false)
  %104 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 4, i32 3, i32 4, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %104, i8 -86, i64 3, i1 false) #19
  store i32 %95, i32* %38, align 8
  store i8 %97, i8* %39, align 4
  %105 = bitcast i8** %64 to %"class.ruy::MulParams"**
  store %"class.ruy::MulParams"* %2, %"class.ruy::MulParams"** %105, align 8
  %106 = icmp eq i8 %11, 16
  br i1 %106, label %107, label %196

107:                                              ; preds = %5
  br i1 %24, label %116, label %108

108:                                              ; preds = %107
  %109 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1, i32 3, i32 3
  %110 = load i8, i8* %109, align 4
  %111 = icmp eq i8 %110, 0
  br i1 %111, label %112, label %116

112:                                              ; preds = %108
  %113 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 4, i32 3, i32 3
  %114 = load i8, i8* %113, align 4
  %115 = icmp eq i8 %114, 0
  br i1 %115, label %154, label %116

116:                                              ; preds = %107, %112, %108
  store i8 2, i8* %26, align 8
  %117 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0
  %118 = bitcast %"struct.ruy::PEMat"* %117 to i24*
  store i24 262401, i24* %118, align 8
  %119 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 3
  %120 = bitcast %"struct.ruy::Type"* %119 to i24*
  store i24 262401, i24* %120, align 8
  %121 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 3
  store i8 0, i8* %121, align 4
  %122 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 0
  store i32 %16, i32* %122, align 8
  %123 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 1
  store i32 %15, i32* %123, align 4
  %124 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 0
  store i8 0, i8* %124, align 1
  store i8 1, i8* %46, align 1
  store i8 1, i8* %50, align 1
  %125 = and i32 %16, 255
  %126 = icmp eq i32 %125, 0
  %127 = add nsw i32 %16, 64
  %128 = select i1 %126, i32 %127, i32 %16
  %129 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 2
  store i32 %128, i32* %129, align 8
  %130 = sitofp i32 %65 to float
  %131 = fptosi float %130 to i32
  store i32 %131, i32* %51, align 8
  %132 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1
  %133 = bitcast %"struct.ruy::PEMat"* %132 to i24*
  store i24 262401, i24* %133, align 8
  %134 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 3
  %135 = bitcast %"struct.ruy::Type"* %134 to i24*
  store i24 262401, i24* %135, align 8
  %136 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 3
  store i8 0, i8* %136, align 4
  %137 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1, i32 3, i32 0
  %138 = load i32, i32* %137, align 8
  %139 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 0
  store i32 %138, i32* %139, align 8
  %140 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1, i32 3, i32 1
  %141 = load i32, i32* %140, align 4
  %142 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 1
  store i32 %141, i32* %142, align 4
  %143 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 0
  store i8 0, i8* %143, align 1
  store i8 1, i8* %57, align 1
  store i8 1, i8* %60, align 1
  %144 = and i32 %138, 255
  %145 = icmp eq i32 %144, 0
  %146 = add nsw i32 %138, 64
  %147 = select i1 %145, i32 %146, i32 %138
  %148 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 2
  store i32 %147, i32* %148, align 8
  %149 = sitofp i32 %80 to float
  %150 = fptosi float %149 to i32
  store i32 %150, i32* %61, align 8
  %151 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 1, i32 0, i64 0
  %152 = bitcast void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)** %151 to <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*>*
  store <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*> <void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* @_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEffEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii, void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* @_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEffEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii>, <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*>* %152, align 8
  %153 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 2
  store void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)* @_ZN3ruy9RunKernelILNS_4PathE2EfffNS_9MulParamsIffEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE, void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)** %153, align 8
  br label %197

154:                                              ; preds = %112
  store i8 16, i8* %26, align 8
  %155 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0
  %156 = bitcast %"struct.ruy::PEMat"* %155 to i24*
  store i24 262401, i24* %156, align 8
  %157 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 3
  %158 = bitcast %"struct.ruy::Type"* %157 to i24*
  store i24 262401, i24* %158, align 8
  %159 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 3
  store i8 0, i8* %159, align 4
  %160 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 0
  store i32 %16, i32* %160, align 8
  %161 = add i32 %15, 15
  %162 = and i32 %161, -16
  %163 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 1
  store i32 %162, i32* %163, align 4
  %164 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 0
  store i8 1, i8* %164, align 1
  store i8 1, i8* %46, align 1
  store i8 16, i8* %50, align 1
  %165 = and i32 %16, 255
  %166 = icmp eq i32 %165, 0
  %167 = add nsw i32 %16, 64
  %168 = select i1 %166, i32 %167, i32 %16
  %169 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 2
  store i32 %168, i32* %169, align 8
  %170 = sitofp i32 %65 to float
  %171 = fptosi float %170 to i32
  store i32 %171, i32* %51, align 8
  %172 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1
  %173 = bitcast %"struct.ruy::PEMat"* %172 to i24*
  store i24 262401, i24* %173, align 8
  %174 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 3
  %175 = bitcast %"struct.ruy::Type"* %174 to i24*
  store i24 262401, i24* %175, align 8
  %176 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 3
  store i8 0, i8* %176, align 4
  %177 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1, i32 3, i32 0
  %178 = load i32, i32* %177, align 8
  %179 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 0
  store i32 %178, i32* %179, align 8
  %180 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1, i32 3, i32 1
  %181 = load i32, i32* %180, align 4
  %182 = add i32 %181, 15
  %183 = and i32 %182, -16
  %184 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 1
  store i32 %183, i32* %184, align 4
  %185 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 0
  store i8 1, i8* %185, align 1
  store i8 1, i8* %57, align 1
  store i8 16, i8* %60, align 1
  %186 = and i32 %178, 255
  %187 = icmp eq i32 %186, 0
  %188 = add nsw i32 %178, 64
  %189 = select i1 %187, i32 %188, i32 %178
  %190 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 2
  store i32 %189, i32* %190, align 8
  %191 = sitofp i32 %80 to float
  %192 = fptosi float %191 to i32
  store i32 %192, i32* %61, align 8
  %193 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 1, i32 0, i64 0
  %194 = bitcast void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)** %193 to <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*>*
  store <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*> <void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* @_ZN3ruy7RunPackILNS_4PathE16ENS_17FixedKernelLayoutILNS_5OrderE1ELi1ELi16EEEffEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii, void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* @_ZN3ruy7RunPackILNS_4PathE16ENS_17FixedKernelLayoutILNS_5OrderE1ELi1ELi16EEEffEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii>, <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*>* %194, align 8
  %195 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 2
  store void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)* @_ZN3ruy9RunKernelILNS_4PathE16EfffNS_9MulParamsIffEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE, void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)** %195, align 8
  br label %197

196:                                              ; preds = %5
  call void @_ZN3ruy27PathSearchOnlyCompiledPathsILNS_4PathE26ELb1ELi3EfffNS_9MulParamsIffEEE6SearchES1_PNS_11TrMulParamsE(i8 zeroext %11, %"struct.ruy::TrMulParams"* nonnull %6) #19
  br label %197

197:                                              ; preds = %154, %116, %196
  call void @_ZN3ruy22HandlePrepackedCachingEPNS_11TrMulParamsEPNS_3CtxE(%"struct.ruy::TrMulParams"* nonnull %6, %"class.ruy::Ctx"* %3)
  call void @_ZN3ruy5TrMulEPNS_11TrMulParamsEPNS_3CtxE(%"struct.ruy::TrMulParams"* nonnull %6, %"class.ruy::Ctx"* %3) #19
  call void @llvm.lifetime.end.p0i8(i64 280, i8* nonnull %26) #19
  ret void
}

declare %"class.ruy::Ctx"* @_ZN3ruy7get_ctxEPNS_7ContextE(%"class.ruy::Context"*) local_unnamed_addr #5

declare zeroext i8 @_ZN3ruy3Ctx10SelectPathENS_4PathE(%"class.ruy::Ctx"*, i8 zeroext) local_unnamed_addr #5

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy22HandlePrepackedCachingEPNS_11TrMulParamsEPNS_3CtxE(%"struct.ruy::TrMulParams"*, %"class.ruy::Ctx"*) local_unnamed_addr #4 comdat {
  %3 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 5
  %4 = load i8, i8* %3, align 4
  %5 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 1
  %6 = load i32, i32* %5, align 4
  %7 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 2
  %8 = load i8, i8* %7, align 1
  %9 = zext i8 %8 to i32
  switch i8 %4, label %31 [
    i8 2, label %10
    i8 3, label %15
    i8 1, label %13
  ]

10:                                               ; preds = %2
  %11 = shl nuw nsw i32 %9, 2
  %12 = icmp sgt i32 %6, %11
  br i1 %12, label %31, label %15

13:                                               ; preds = %2
  %14 = icmp sgt i32 %6, %9
  br i1 %14, label %31, label %15

15:                                               ; preds = %10, %13, %2
  %16 = tail call %"class.ruy::PrepackedCache"* @_ZN3ruy3Ctx17GetPrepackedCacheEv(%"class.ruy::Ctx"* %1) #19
  %17 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 2
  %18 = load i8*, i8** %17, align 8
  %19 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0
  %20 = tail call i32 @_ZN3ruy14PrepackedCache3GetEPKvPNS_5PEMatE(%"class.ruy::PrepackedCache"* %16, i8* %18, %"struct.ruy::PEMat"* %19) #19
  %21 = icmp eq i32 %20, 1
  br i1 %21, label %22, label %29

22:                                               ; preds = %15
  %23 = tail call i32 @_ZN3ruy3Ctx19GetMainThreadTuningEv(%"class.ruy::Ctx"* %1) #19
  %24 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 1
  %25 = load i32, i32* %24, align 4
  %26 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 1, i32 0, i64 0
  %27 = load void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*, void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)** %26, align 8
  %28 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0
  tail call void %27(i32 %23, %"struct.ruy::EMat"* dereferenceable(40) %28, %"struct.ruy::PEMat"* %19, i32 0, i32 %25) #19
  br label %29

29:                                               ; preds = %22, %15
  %30 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 6, i32 0, i64 0
  store i8 1, i8* %30, align 1
  br label %31

31:                                               ; preds = %10, %13, %2, %29
  %32 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 5
  %33 = load i8, i8* %32, align 4
  %34 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 1
  %35 = load i32, i32* %34, align 4
  %36 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 2
  %37 = load i8, i8* %36, align 1
  %38 = zext i8 %37 to i32
  switch i8 %33, label %60 [
    i8 2, label %41
    i8 3, label %44
    i8 1, label %39
  ]

39:                                               ; preds = %31
  %40 = icmp sgt i32 %35, %38
  br i1 %40, label %60, label %44

41:                                               ; preds = %31
  %42 = shl nuw nsw i32 %38, 2
  %43 = icmp sgt i32 %35, %42
  br i1 %43, label %60, label %44

44:                                               ; preds = %41, %39, %31
  %45 = tail call %"class.ruy::PrepackedCache"* @_ZN3ruy3Ctx17GetPrepackedCacheEv(%"class.ruy::Ctx"* %1) #19
  %46 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 2
  %47 = load i8*, i8** %46, align 8
  %48 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1
  %49 = tail call i32 @_ZN3ruy14PrepackedCache3GetEPKvPNS_5PEMatE(%"class.ruy::PrepackedCache"* %45, i8* %47, %"struct.ruy::PEMat"* %48) #19
  %50 = icmp eq i32 %49, 1
  br i1 %50, label %51, label %58

51:                                               ; preds = %44
  %52 = tail call i32 @_ZN3ruy3Ctx19GetMainThreadTuningEv(%"class.ruy::Ctx"* %1) #19
  %53 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 1
  %54 = load i32, i32* %53, align 4
  %55 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 1, i32 0, i64 1
  %56 = load void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*, void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)** %55, align 8
  %57 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1
  tail call void %56(i32 %52, %"struct.ruy::EMat"* dereferenceable(40) %57, %"struct.ruy::PEMat"* %48, i32 0, i32 %54) #19
  br label %58

58:                                               ; preds = %51, %44
  %59 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 6, i32 0, i64 1
  store i8 1, i8* %59, align 1
  br label %60

60:                                               ; preds = %58, %41, %39, %31
  ret void
}

declare void @_ZN3ruy5TrMulEPNS_11TrMulParamsEPNS_3CtxE(%"struct.ruy::TrMulParams"*, %"class.ruy::Ctx"*) local_unnamed_addr #5

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy7RunPackILNS_4PathE16ENS_17FixedKernelLayoutILNS_5OrderE1ELi1ELi16EEEffEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii(i32, %"struct.ruy::EMat"* dereferenceable(40), %"struct.ruy::PEMat"*, i32, i32) #1 comdat {
  %6 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 2
  %7 = bitcast i8** %6 to float**
  %8 = load float*, float** %7, align 8, !noalias !317
  %9 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3, i32 0
  %10 = load i32, i32* %9, align 4
  %11 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3, i32 2
  %12 = load i32, i32* %11, align 4
  %13 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 2
  %14 = bitcast i8** %13 to float**
  %15 = load float*, float** %14, align 8, !noalias !320
  %16 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 6, i32 2
  %17 = load i32, i32* %16, align 4
  %18 = icmp slt i32 %3, %4
  br i1 %18, label %19, label %38

19:                                               ; preds = %5
  %20 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = sext i32 %3 to i64
  %23 = sext i32 %4 to i64
  %24 = sext i32 %12 to i64
  br label %25

25:                                               ; preds = %19, %25
  %26 = phi i64 [ %22, %19 ], [ %36, %25 ]
  %27 = mul nsw i64 %26, %24
  %28 = getelementptr inbounds float, float* %8, i64 %27
  %29 = trunc i64 %26 to i32
  %30 = and i32 %29, -16
  %31 = mul nsw i32 %30, %17
  %32 = sext i32 %31 to i64
  %33 = getelementptr inbounds float, float* %15, i64 %32
  %34 = trunc i64 %26 to i32
  %35 = sub i32 %21, %34
  tail call void @_ZN3ruy15PackFloatAvx512EPKfS1_iiiPf(float* %28, float* getelementptr inbounds ([16 x float], [16 x float]* @_ZZN3ruy8PackImplILNS_4PathE16ENS_17FixedKernelLayoutILNS_5OrderE1ELi1ELi16EEEfffE3RunENS_6TuningERKNS_3MatIfEEPNS_4PMatIfEEiiE7zerobuf, i64 0, i64 0), i32 %12, i32 %35, i32 %10, float* %33) #19
  %36 = add i64 %26, 16
  %37 = icmp slt i64 %36, %23
  br i1 %37, label %25, label %38

38:                                               ; preds = %25, %5
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy9RunKernelILNS_4PathE16EfffNS_9MulParamsIffEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE(i32, %"class.ruy::SidePair.104"* dereferenceable(112), i8*, %"class.ruy::SidePair.105"* dereferenceable(8), %"class.ruy::SidePair.105"* dereferenceable(8), %"struct.ruy::EMat"*) #1 comdat {
  %7 = alloca %"struct.ruy::KernelParamsFloat", align 8
  %8 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 2
  %9 = bitcast i8** %8 to float**
  %10 = load float*, float** %9, align 8, !noalias !323
  %11 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 0
  %12 = load i32, i32* %11, align 4
  %13 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 1
  %14 = load i32, i32* %13, align 4
  %15 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 2
  %16 = load i32, i32* %15, align 4
  %17 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 2
  %18 = bitcast i8** %17 to float**
  %19 = load float*, float** %18, align 8, !noalias !326
  %20 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 6, i32 0
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 6, i32 2
  %23 = load i32, i32* %22, align 4
  %24 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 2
  %25 = bitcast i8** %24 to float**
  %26 = load float*, float** %25, align 8, !noalias !329
  %27 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 6, i32 2
  %28 = load i32, i32* %27, align 4
  %29 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %3, i64 0, i32 0, i64 0
  %30 = load i32, i32* %29, align 4
  %31 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %3, i64 0, i32 0, i64 1
  %32 = load i32, i32* %31, align 4
  %33 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %4, i64 0, i32 0, i64 0
  %34 = load i32, i32* %33, align 4
  %35 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %4, i64 0, i32 0, i64 1
  %36 = load i32, i32* %35, align 4
  %37 = bitcast %"struct.ruy::KernelParamsFloat"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1176, i8* nonnull %37) #19
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %37, i8* align 8 bitcast (%"struct.ruy::KernelParamsFloat"* @__const._ZNK3ruy6KernelILNS_4PathE16EfffNS_9MulParamsIffEEE3RunERKNS_4PMatIfEES8_RKS3_iiiiPNS_3MatIfEE.params to i8*), i64 1176, i1 false) #19
  %38 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 18, i64 0
  %39 = bitcast float* %38 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 4 %39, i8 0, i64 64, i1 false) #19
  %40 = mul nsw i32 %30, %23
  %41 = sext i32 %40 to i64
  %42 = getelementptr inbounds float, float* %19, i64 %41
  %43 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 0
  store float* %42, float** %43, align 8
  %44 = mul nsw i32 %32, %28
  %45 = sext i32 %44 to i64
  %46 = getelementptr inbounds float, float* %26, i64 %45
  %47 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 1
  store float* %46, float** %47, align 8
  %48 = mul nsw i32 %32, %16
  %49 = sext i32 %48 to i64
  %50 = getelementptr inbounds float, float* %10, i64 %49
  %51 = sext i32 %30 to i64
  %52 = getelementptr inbounds float, float* %50, i64 %51
  %53 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 2
  store float* %52, float** %53, align 8
  %54 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 3
  %55 = bitcast i8* %2 to float**
  %56 = load float*, float** %55, align 8
  %57 = icmp eq float* %56, null
  %58 = select i1 %57, float* %38, float* %56
  store float* %58, float** %54, align 8
  %59 = xor i1 %57, true
  %60 = zext i1 %59 to i8
  %61 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 16
  store i8 %60, i8* %61, align 8
  %62 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 4
  store i32 %30, i32* %62, align 8
  %63 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 5
  store i32 %32, i32* %63, align 4
  %64 = add nsw i32 %34, -16
  %65 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 6
  store i32 %64, i32* %65, align 8
  %66 = add nsw i32 %36, -16
  %67 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 7
  store i32 %66, i32* %67, align 4
  %68 = shl i32 %23, 2
  %69 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 10
  store i32 %68, i32* %69, align 8
  %70 = shl i32 %28, 2
  %71 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 11
  store i32 %70, i32* %71, align 4
  %72 = shl i32 %16, 2
  %73 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 12
  store i32 %72, i32* %73, align 8
  %74 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 13
  store i32 %21, i32* %74, align 4
  %75 = getelementptr inbounds i8, i8* %2, i64 32
  %76 = bitcast i8* %75 to i32*
  %77 = load i32, i32* %76, align 8
  %78 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 14
  %79 = bitcast float* %78 to i32*
  store i32 %77, i32* %79, align 8
  %80 = getelementptr inbounds i8, i8* %2, i64 36
  %81 = bitcast i8* %80 to i32*
  %82 = load i32, i32* %81, align 4
  %83 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 15
  %84 = bitcast float* %83 to i32*
  store i32 %82, i32* %84, align 4
  %85 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 8
  store i32 %12, i32* %85, align 8
  %86 = getelementptr inbounds %"struct.ruy::KernelParamsFloat", %"struct.ruy::KernelParamsFloat"* %7, i64 0, i32 9
  store i32 %14, i32* %86, align 4
  %87 = icmp eq i32 %14, 1
  br i1 %87, label %88, label %89

88:                                               ; preds = %6
  call void @_ZN3ruy26KernelFloatAvx512SingleColERKNS_17KernelParamsFloatILi16ELi16EEE(%"struct.ruy::KernelParamsFloat"* nonnull dereferenceable(1176) %7) #19
  br label %90

89:                                               ; preds = %6
  call void @_ZN3ruy17KernelFloatAvx512ERKNS_17KernelParamsFloatILi16ELi16EEE(%"struct.ruy::KernelParamsFloat"* nonnull dereferenceable(1176) %7) #19
  br label %90

90:                                               ; preds = %88, %89
  call void @llvm.lifetime.end.p0i8(i64 1176, i8* nonnull %37) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEffEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii(i32, %"struct.ruy::EMat"* dereferenceable(40), %"struct.ruy::PEMat"*, i32, i32) #1 comdat {
  %6 = alloca %"struct.ruy::Mat", align 8
  %7 = alloca %"struct.ruy::PMat", align 8
  %8 = bitcast %"struct.ruy::Mat"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %8) #19
  %9 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %6, i64 0, i32 2
  %10 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %6, i64 0, i32 3
  %11 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %6, i64 0, i32 1
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %8, i8 -86, i64 24, i1 false) #19, !alias.scope !332
  %12 = bitcast i8* %10 to i32*
  store i32 -1431655936, i32* %12, align 4, !alias.scope !332
  %13 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 2
  %14 = bitcast i8** %13 to i64*
  %15 = load i64, i64* %14, align 8, !noalias !332
  %16 = bitcast %"struct.ruy::Mat"* %6 to i64*
  store i64 %15, i64* %16, align 8, !alias.scope !332
  %17 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3
  %18 = bitcast %"struct.ruy::MatLayout"* %11 to i8*
  %19 = bitcast %"struct.ruy::MatLayout"* %17 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %18, i8* align 4 %19, i64 13, i1 false) #19
  %20 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 4
  %21 = load i32, i32* %20, align 8, !noalias !332
  %22 = sitofp i32 %21 to float
  store float %22, float* %9, align 8, !alias.scope !332
  %23 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 5
  %24 = load i8, i8* %23, align 4, !noalias !332
  store i8 %24, i8* %10, align 4, !alias.scope !332
  %25 = bitcast %"struct.ruy::PMat"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %25) #19
  %26 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %7, i64 0, i32 3
  %27 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 2
  %28 = bitcast i8** %27 to i64*
  %29 = bitcast %"struct.ruy::PMat"* %7 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %29, i8 -86, i64 40, i1 false)
  %30 = load i64, i64* %28, align 8, !noalias !335
  %31 = bitcast %"struct.ruy::PMat"* %7 to i64*
  store i64 %30, i64* %31, align 8, !alias.scope !335
  %32 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 5
  %33 = bitcast i8** %32 to i64*
  %34 = load i64, i64* %33, align 8, !noalias !335
  %35 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %7, i64 0, i32 1
  %36 = bitcast float** %35 to i64*
  store i64 %34, i64* %36, align 8, !alias.scope !335
  %37 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 6
  %38 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %7, i64 0, i32 2
  %39 = bitcast %"struct.ruy::PMatLayout"* %38 to i8*
  %40 = bitcast %"struct.ruy::PMatLayout"* %37 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %39, i8* align 4 %40, i64 16, i1 false) #19
  %41 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 7
  %42 = load i32, i32* %41, align 8, !noalias !335
  store i32 %42, i32* %26, align 8, !alias.scope !335
  call void @_ZN3ruy8PackImplILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEfffE3RunENS_6TuningERKNS_3MatIfEEPNS_4PMatIfEEii(i32 %0, %"struct.ruy::Mat"* nonnull dereferenceable(32) %6, %"struct.ruy::PMat"* nonnull %7, i32 %3, i32 %4)
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %25) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %8) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy9RunKernelILNS_4PathE2EfffNS_9MulParamsIffEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE(i32, %"class.ruy::SidePair.104"* dereferenceable(112), i8*, %"class.ruy::SidePair.105"* dereferenceable(8), %"class.ruy::SidePair.105"* dereferenceable(8), %"struct.ruy::EMat"*) #1 comdat {
  %7 = alloca %"struct.ruy::Kernel", align 1
  %8 = alloca %"struct.ruy::Mat", align 8
  %9 = alloca %"struct.ruy::PMat", align 8
  %10 = alloca %"struct.ruy::PMat", align 8
  %11 = bitcast %"struct.ruy::Mat"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %11) #19
  %12 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %8, i64 0, i32 2
  %13 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %8, i64 0, i32 3
  %14 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %8, i64 0, i32 1
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %11, i8 -86, i64 24, i1 false) #19, !alias.scope !338
  %15 = bitcast i8* %13 to i32*
  store i32 -1431655936, i32* %15, align 4, !alias.scope !338
  %16 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 2
  %17 = bitcast i8** %16 to i64*
  %18 = load i64, i64* %17, align 8, !noalias !338
  %19 = bitcast %"struct.ruy::Mat"* %8 to i64*
  store i64 %18, i64* %19, align 8, !alias.scope !338
  %20 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3
  %21 = bitcast %"struct.ruy::MatLayout"* %14 to i8*
  %22 = bitcast %"struct.ruy::MatLayout"* %20 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %21, i8* align 4 %22, i64 13, i1 false) #19
  %23 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 4
  %24 = load i32, i32* %23, align 8, !noalias !338
  %25 = sitofp i32 %24 to float
  store float %25, float* %12, align 8, !alias.scope !338
  %26 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 5
  %27 = load i8, i8* %26, align 4, !noalias !338
  store i8 %27, i8* %13, align 4, !alias.scope !338
  %28 = bitcast %"struct.ruy::PMat"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %28) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %28, i8 -86, i64 40, i1 false) #19, !alias.scope !341
  %29 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %9, i64 0, i32 3
  %30 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 2
  %31 = bitcast i8** %30 to i64*
  %32 = load i64, i64* %31, align 8, !noalias !341
  %33 = bitcast %"struct.ruy::PMat"* %9 to i64*
  store i64 %32, i64* %33, align 8, !alias.scope !341
  %34 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 5
  %35 = bitcast i8** %34 to i64*
  %36 = load i64, i64* %35, align 8, !noalias !341
  %37 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %9, i64 0, i32 1
  %38 = bitcast float** %37 to i64*
  store i64 %36, i64* %38, align 8, !alias.scope !341
  %39 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 6
  %40 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %9, i64 0, i32 2
  %41 = bitcast %"struct.ruy::PMatLayout"* %40 to i8*
  %42 = bitcast %"struct.ruy::PMatLayout"* %39 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %41, i8* align 4 %42, i64 16, i1 false) #19
  %43 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 7
  %44 = load i32, i32* %43, align 8, !noalias !341
  store i32 %44, i32* %29, align 8, !alias.scope !341
  %45 = bitcast %"struct.ruy::PMat"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %45) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %45, i8 -86, i64 40, i1 false) #19, !alias.scope !344
  %46 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %10, i64 0, i32 3
  %47 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 2
  %48 = bitcast i8** %47 to i64*
  %49 = load i64, i64* %48, align 8, !noalias !344
  %50 = bitcast %"struct.ruy::PMat"* %10 to i64*
  store i64 %49, i64* %50, align 8, !alias.scope !344
  %51 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 5
  %52 = bitcast i8** %51 to i64*
  %53 = load i64, i64* %52, align 8, !noalias !344
  %54 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %10, i64 0, i32 1
  %55 = bitcast float** %54 to i64*
  store i64 %53, i64* %55, align 8, !alias.scope !344
  %56 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 6
  %57 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %10, i64 0, i32 2
  %58 = bitcast %"struct.ruy::PMatLayout"* %57 to i8*
  %59 = bitcast %"struct.ruy::PMatLayout"* %56 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %58, i8* align 4 %59, i64 16, i1 false) #19
  %60 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 7
  %61 = load i32, i32* %60, align 8, !noalias !344
  store i32 %61, i32* %46, align 8, !alias.scope !344
  %62 = bitcast i8* %2 to %"class.ruy::MulParams"*
  %63 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %3, i64 0, i32 0, i64 0
  %64 = load i32, i32* %63, align 4
  %65 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %3, i64 0, i32 0, i64 1
  %66 = load i32, i32* %65, align 4
  %67 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %4, i64 0, i32 0, i64 0
  %68 = load i32, i32* %67, align 4
  %69 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %4, i64 0, i32 0, i64 1
  %70 = load i32, i32* %69, align 4
  %71 = getelementptr inbounds %"struct.ruy::Kernel", %"struct.ruy::Kernel"* %7, i64 0, i32 0
  call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %71) #19
  store i8 -86, i8* %71, align 1
  call void @_ZNK3ruy6KernelILNS_4PathE2EfffNS_9MulParamsIffEEE3RunERKNS_4PMatIfEES8_RKS3_iiiiPNS_3MatIfEE(%"struct.ruy::Kernel"* nonnull %7, %"struct.ruy::PMat"* nonnull dereferenceable(40) %9, %"struct.ruy::PMat"* nonnull dereferenceable(40) %10, %"class.ruy::MulParams"* dereferenceable(40) %62, i32 %64, i32 %66, i32 %68, i32 %70, %"struct.ruy::Mat"* nonnull %8) #19
  call void @llvm.lifetime.end.p0i8(i64 1, i8* nonnull %71) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %45) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %28) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %11) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy8PackImplILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEfffE3RunENS_6TuningERKNS_3MatIfEEPNS_4PMatIfEEii(i32, %"struct.ruy::Mat"* dereferenceable(32), %"struct.ruy::PMat"*, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %6 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %2, i64 0, i32 1
  %7 = load float*, float** %6, align 8
  %8 = icmp slt i32 %3, %4
  br i1 %8, label %9, label %33

9:                                                ; preds = %5
  %10 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %2, i64 0, i32 2, i32 0
  %11 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %1, i64 0, i32 1, i32 1
  %12 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %1, i64 0, i32 1, i32 0
  %13 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %2, i64 0, i32 3
  %14 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %1, i64 0, i32 0, i32 0
  %15 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %1, i64 0, i32 1, i32 3
  %16 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %1, i64 0, i32 1, i32 2
  %17 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %2, i64 0, i32 0
  %18 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %2, i64 0, i32 2, i32 4, i32 1
  %19 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %2, i64 0, i32 2, i32 4, i32 2
  %20 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %2, i64 0, i32 2, i32 3
  %21 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %2, i64 0, i32 2, i32 2
  %22 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %2, i64 0, i32 2, i32 4, i32 0
  %23 = icmp eq float* %7, null
  %24 = sext i32 %3 to i64
  %25 = sext i32 %4 to i64
  br label %26

26:                                               ; preds = %107, %9
  %27 = phi i64 [ %24, %9 ], [ %108, %107 ]
  %28 = load i32, i32* %10, align 8
  %29 = icmp sgt i32 %28, 0
  br i1 %29, label %30, label %34

30:                                               ; preds = %26
  %31 = trunc i64 %27 to i32
  %32 = trunc i64 %27 to i32
  br label %36

33:                                               ; preds = %107, %5
  ret void

34:                                               ; preds = %65, %26
  %35 = phi float [ 0.000000e+00, %26 ], [ %68, %65 ]
  br i1 %23, label %107, label %105

36:                                               ; preds = %30, %65
  %37 = phi i32 [ %102, %65 ], [ 0, %30 ]
  %38 = phi float [ %68, %65 ], [ 0.000000e+00, %30 ]
  %39 = load i32, i32* %11, align 4
  %40 = sext i32 %39 to i64
  %41 = icmp slt i64 %27, %40
  br i1 %41, label %42, label %62

42:                                               ; preds = %36
  %43 = load i32, i32* %12, align 8
  %44 = icmp slt i32 %37, %43
  br i1 %44, label %45, label %62

45:                                               ; preds = %42
  %46 = load float*, float** %14, align 8
  %47 = load i8, i8* %15, align 4
  %48 = load i32, i32* %16, align 4
  switch i8 %47, label %49 [
    i8 0, label %50
    i8 1, label %52
  ]

49:                                               ; preds = %45
  br label %50

50:                                               ; preds = %49, %45
  %51 = phi i32 [ 1, %45 ], [ %48, %49 ]
  br label %52

52:                                               ; preds = %45, %50
  %53 = phi i32 [ %51, %50 ], [ %48, %45 ]
  %54 = phi i32 [ %48, %50 ], [ 1, %45 ]
  %55 = mul nsw i32 %53, %37
  %56 = mul nsw i32 %54, %32
  %57 = add nsw i32 %56, %55
  %58 = sext i32 %57 to i64
  %59 = getelementptr inbounds float, float* %46, i64 %58
  %60 = load float, float* %59, align 4
  %61 = fadd float %60, 0.000000e+00
  br label %65

62:                                               ; preds = %42, %36
  %63 = load i32, i32* %13, align 8
  %64 = sitofp i32 %63 to float
  br label %65

65:                                               ; preds = %62, %52
  %66 = phi i32 [ %31, %62 ], [ %32, %52 ]
  %67 = phi float [ %64, %62 ], [ %61, %52 ]
  %68 = fadd float %38, %67
  %69 = load float*, float** %17, align 8
  %70 = load i8, i8* %18, align 1
  %71 = zext i8 %70 to i32
  %72 = sub nsw i32 0, %71
  %73 = and i32 %37, %72
  %74 = load i8, i8* %19, align 1
  %75 = zext i8 %74 to i32
  %76 = sub nsw i32 0, %75
  %77 = and i32 %66, %76
  %78 = load i8, i8* %20, align 4
  %79 = icmp eq i8 %78, 0
  %80 = load i32, i32* %21, align 4
  %81 = select i1 %79, i32 %75, i32 %80
  %82 = icmp eq i8 %78, 1
  %83 = select i1 %82, i32 %71, i32 %80
  %84 = mul nsw i32 %81, %73
  %85 = mul nsw i32 %83, %77
  %86 = sub nsw i32 %37, %73
  %87 = sub nsw i32 %66, %77
  %88 = load i8, i8* %22, align 1
  %89 = icmp eq i8 %88, 0
  %90 = select i1 %89, i8 1, i8 %74
  %91 = zext i8 %90 to i32
  %92 = icmp eq i8 %88, 1
  %93 = select i1 %92, i8 1, i8 %70
  %94 = zext i8 %93 to i32
  %95 = mul nsw i32 %86, %91
  %96 = mul nsw i32 %87, %94
  %97 = add i32 %84, %85
  %98 = add i32 %97, %96
  %99 = add i32 %98, %95
  %100 = sext i32 %99 to i64
  %101 = getelementptr inbounds float, float* %69, i64 %100
  store float %67, float* %101, align 4
  %102 = add nuw nsw i32 %37, 1
  %103 = load i32, i32* %10, align 8
  %104 = icmp slt i32 %102, %103
  br i1 %104, label %36, label %34

105:                                              ; preds = %34
  %106 = getelementptr inbounds float, float* %7, i64 %27
  store float %35, float* %106, align 4
  br label %107

107:                                              ; preds = %34, %105
  %108 = add nsw i64 %27, 1
  %109 = icmp eq i64 %108, %25
  br i1 %109, label %33, label %26
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK3ruy6KernelILNS_4PathE2EfffNS_9MulParamsIffEEE3RunERKNS_4PMatIfEES8_RKS3_iiiiPNS_3MatIfEE(%"struct.ruy::Kernel"*, %"struct.ruy::PMat"* dereferenceable(40), %"struct.ruy::PMat"* dereferenceable(40), %"class.ruy::MulParams"* dereferenceable(40), i32, i32, i32, i32, %"struct.ruy::Mat"*) local_unnamed_addr #1 comdat align 2 {
  %10 = alloca i32, align 4
  %11 = alloca float, align 4
  %12 = alloca float, align 4
  %13 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %8, i64 0, i32 1, i32 0
  %14 = load i32, i32* %13, align 4
  %15 = icmp slt i32 %14, %6
  %16 = select i1 %15, i32 %14, i32 %6
  %17 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %8, i64 0, i32 1, i32 1
  %18 = load i32, i32* %17, align 4
  %19 = icmp slt i32 %18, %7
  %20 = select i1 %19, i32 %18, i32 %7
  %21 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %1, i64 0, i32 2, i32 0
  %22 = load i32, i32* %21, align 8
  %23 = icmp sgt i32 %16, %4
  br i1 %23, label %24, label %63

24:                                               ; preds = %9
  %25 = icmp sgt i32 %20, %5
  %26 = bitcast i32* %10 to i8*
  %27 = icmp sgt i32 %22, 0
  %28 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %1, i64 0, i32 0
  %29 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %1, i64 0, i32 2, i32 4, i32 1
  %30 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %1, i64 0, i32 2, i32 4, i32 2
  %31 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %1, i64 0, i32 2, i32 3
  %32 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %1, i64 0, i32 2, i32 2
  %33 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %1, i64 0, i32 2, i32 4, i32 0
  %34 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %2, i64 0, i32 0
  %35 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %2, i64 0, i32 2, i32 4, i32 1
  %36 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %2, i64 0, i32 2, i32 4, i32 2
  %37 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %2, i64 0, i32 2, i32 3
  %38 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %2, i64 0, i32 2, i32 2
  %39 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %2, i64 0, i32 2, i32 4, i32 0
  %40 = bitcast i32* %10 to float*
  %41 = getelementptr inbounds %"class.ruy::MulParams", %"class.ruy::MulParams"* %3, i64 0, i32 0
  %42 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %1, i64 0, i32 3
  %43 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %2, i64 0, i32 1
  %44 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %2, i64 0, i32 3
  %45 = getelementptr inbounds %"struct.ruy::PMat", %"struct.ruy::PMat"* %1, i64 0, i32 1
  %46 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %8, i64 0, i32 2
  %47 = bitcast float* %11 to i8*
  %48 = getelementptr inbounds %"class.ruy::MulParams", %"class.ruy::MulParams"* %3, i64 0, i32 6
  %49 = bitcast float* %12 to i8*
  %50 = getelementptr inbounds %"class.ruy::MulParams", %"class.ruy::MulParams"* %3, i64 0, i32 5
  %51 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %8, i64 0, i32 0, i32 0
  %52 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %8, i64 0, i32 1, i32 3
  %53 = getelementptr inbounds %"struct.ruy::Mat", %"struct.ruy::Mat"* %8, i64 0, i32 1, i32 2
  %54 = sext i32 %5 to i64
  %55 = sext i32 %20 to i64
  %56 = sext i32 %4 to i64
  %57 = sext i32 %16 to i64
  br label %58

58:                                               ; preds = %24, %64
  %59 = phi i64 [ %56, %24 ], [ %65, %64 ]
  br i1 %25, label %60, label %64

60:                                               ; preds = %58
  %61 = trunc i64 %59 to i32
  %62 = trunc i64 %59 to i32
  br label %67

63:                                               ; preds = %64, %9
  ret void

64:                                               ; preds = %204, %58
  %65 = add nsw i64 %59, 1
  %66 = icmp slt i64 %65, %57
  br i1 %66, label %58, label %63

67:                                               ; preds = %60, %204
  %68 = phi i64 [ %54, %60 ], [ %214, %204 ]
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %26)
  store i32 0, i32* %10, align 4
  br i1 %27, label %69, label %120

69:                                               ; preds = %67
  %70 = load float*, float** %28, align 8
  %71 = load i8, i8* %29, align 1
  %72 = zext i8 %71 to i32
  %73 = sub nsw i32 0, %72
  %74 = load i8, i8* %30, align 1
  %75 = zext i8 %74 to i32
  %76 = sub nsw i32 0, %75
  %77 = and i32 %61, %76
  %78 = load i8, i8* %31, align 4
  %79 = icmp eq i8 %78, 0
  %80 = load i32, i32* %32, align 4
  %81 = select i1 %79, i32 %75, i32 %80
  %82 = icmp eq i8 %78, 1
  %83 = select i1 %82, i32 %72, i32 %80
  %84 = mul nsw i32 %83, %77
  %85 = sub nsw i32 %61, %77
  %86 = load i8, i8* %33, align 1
  %87 = icmp eq i8 %86, 0
  %88 = select i1 %87, i8 1, i8 %74
  %89 = zext i8 %88 to i32
  %90 = icmp eq i8 %86, 1
  %91 = select i1 %90, i8 1, i8 %71
  %92 = zext i8 %91 to i32
  %93 = mul nsw i32 %85, %92
  %94 = load float*, float** %34, align 8
  %95 = load i8, i8* %35, align 1
  %96 = zext i8 %95 to i32
  %97 = sub nsw i32 0, %96
  %98 = load i8, i8* %36, align 1
  %99 = zext i8 %98 to i32
  %100 = sub nsw i32 0, %99
  %101 = trunc i64 %68 to i32
  %102 = and i32 %101, %100
  %103 = load i8, i8* %37, align 4
  %104 = icmp eq i8 %103, 0
  %105 = load i32, i32* %38, align 4
  %106 = select i1 %104, i32 %99, i32 %105
  %107 = icmp eq i8 %103, 1
  %108 = select i1 %107, i32 %96, i32 %105
  %109 = mul nsw i32 %108, %102
  %110 = sub nsw i32 %101, %102
  %111 = load i8, i8* %39, align 1
  %112 = icmp eq i8 %111, 0
  %113 = select i1 %112, i8 1, i8 %98
  %114 = zext i8 %113 to i32
  %115 = icmp eq i8 %111, 1
  %116 = select i1 %115, i8 1, i8 %95
  %117 = zext i8 %116 to i32
  %118 = mul nsw i32 %110, %117
  br label %124

119:                                              ; preds = %124
  store float %148, float* %40, align 4
  br label %120

120:                                              ; preds = %119, %67
  %121 = phi float [ %148, %119 ], [ 0.000000e+00, %67 ]
  %122 = load float*, float** %41, align 8
  %123 = icmp eq float* %122, null
  br i1 %123, label %155, label %151

124:                                              ; preds = %124, %69
  %125 = phi float [ 0.000000e+00, %69 ], [ %148, %124 ]
  %126 = phi i32 [ 0, %69 ], [ %149, %124 ]
  %127 = and i32 %126, %73
  %128 = mul nsw i32 %81, %127
  %129 = sub nsw i32 %126, %127
  %130 = mul nsw i32 %129, %89
  %131 = add i32 %128, %84
  %132 = add i32 %131, %93
  %133 = add i32 %132, %130
  %134 = sext i32 %133 to i64
  %135 = getelementptr inbounds float, float* %70, i64 %134
  %136 = load float, float* %135, align 4
  %137 = and i32 %126, %97
  %138 = mul nsw i32 %106, %137
  %139 = sub nsw i32 %126, %137
  %140 = mul nsw i32 %139, %114
  %141 = add i32 %138, %109
  %142 = add i32 %141, %118
  %143 = add i32 %142, %140
  %144 = sext i32 %143 to i64
  %145 = getelementptr inbounds float, float* %94, i64 %144
  %146 = load float, float* %145, align 4
  %147 = fmul float %136, %146
  %148 = fadd float %125, %147
  %149 = add nuw nsw i32 %126, 1
  %150 = icmp eq i32 %149, %22
  br i1 %150, label %119, label %124

151:                                              ; preds = %120
  %152 = getelementptr inbounds float, float* %122, i64 %59
  %153 = load float, float* %152, align 4
  %154 = fadd float %153, %121
  store float %154, float* %40, align 4
  br label %155

155:                                              ; preds = %120, %151
  %156 = phi float [ %121, %120 ], [ %154, %151 ]
  %157 = load i32, i32* %42, align 8
  %158 = icmp eq i32 %157, 0
  br i1 %158, label %166, label %159

159:                                              ; preds = %155
  %160 = sitofp i32 %157 to float
  %161 = load float*, float** %43, align 8
  %162 = getelementptr inbounds float, float* %161, i64 %68
  %163 = load float, float* %162, align 4
  %164 = fmul float %163, %160
  %165 = fsub float %156, %164
  store float %165, float* %40, align 4
  br label %166

166:                                              ; preds = %155, %159
  %167 = phi float [ %156, %155 ], [ %165, %159 ]
  %168 = load i32, i32* %44, align 8
  %169 = icmp eq i32 %168, 0
  br i1 %169, label %183, label %170

170:                                              ; preds = %166
  %171 = sitofp i32 %168 to float
  %172 = load float*, float** %45, align 8
  %173 = getelementptr inbounds float, float* %172, i64 %59
  %174 = load float, float* %173, align 4
  %175 = fmul float %174, %171
  %176 = fsub float %167, %175
  store float %176, float* %40, align 4
  %177 = or i1 %158, %169
  br i1 %177, label %183, label %178

178:                                              ; preds = %170
  %179 = mul i32 %157, %22
  %180 = mul i32 %179, %168
  %181 = sitofp i32 %180 to float
  %182 = fadd float %176, %181
  store float %182, float* %40, align 4
  br label %183

183:                                              ; preds = %166, %170, %178
  %184 = phi float [ %176, %170 ], [ %182, %178 ], [ %167, %166 ]
  %185 = load float, float* %46, align 8
  %186 = fadd float %185, %184
  store float %186, float* %40, align 4
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %47)
  %187 = load float, float* %48, align 4
  store float %187, float* %11, align 4
  %188 = fcmp olt float %187, %186
  %189 = select i1 %188, float* %11, float* %40
  %190 = bitcast float* %189 to i32*
  %191 = load i32, i32* %190, align 4
  store i32 %191, i32* %10, align 4
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %47)
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %49)
  %192 = load float, float* %50, align 8
  store float %192, float* %12, align 4
  %193 = bitcast i32 %191 to float
  %194 = fcmp ogt float %192, %193
  %195 = select i1 %194, float* %12, float* %40
  %196 = bitcast float* %195 to i32*
  %197 = load i32, i32* %196, align 4
  store i32 %197, i32* %10, align 4
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %49)
  %198 = load float*, float** %51, align 8
  %199 = load i8, i8* %52, align 4
  %200 = load i32, i32* %53, align 4
  switch i8 %199, label %201 [
    i8 0, label %202
    i8 1, label %204
  ]

201:                                              ; preds = %183
  br label %202

202:                                              ; preds = %201, %183
  %203 = phi i32 [ 1, %183 ], [ %200, %201 ]
  br label %204

204:                                              ; preds = %183, %202
  %205 = phi i32 [ %203, %202 ], [ %200, %183 ]
  %206 = phi i32 [ %200, %202 ], [ 1, %183 ]
  %207 = mul nsw i32 %205, %62
  %208 = trunc i64 %68 to i32
  %209 = mul nsw i32 %206, %208
  %210 = add nsw i32 %209, %207
  %211 = sext i32 %210 to i64
  %212 = getelementptr inbounds float, float* %198, i64 %211
  %213 = bitcast float* %212 to i32*
  store i32 %197, i32* %213, align 4
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %26)
  %214 = add nsw i64 %68, 1
  %215 = icmp slt i64 %214, %55
  br i1 %215, label %67, label %64
}

declare void @_ZN3ruy15PackFloatAvx512EPKfS1_iiiPf(float*, float*, i32, i32, i32, float*) local_unnamed_addr #5

declare void @_ZN3ruy26KernelFloatAvx512SingleColERKNS_17KernelParamsFloatILi16ELi16EEE(%"struct.ruy::KernelParamsFloat"* dereferenceable(1176)) local_unnamed_addr #5

declare void @_ZN3ruy17KernelFloatAvx512ERKNS_17KernelParamsFloatILi16ELi16EEE(%"struct.ruy::KernelParamsFloat"* dereferenceable(1176)) local_unnamed_addr #5

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy27PathSearchOnlyCompiledPathsILNS_4PathE26ELb1ELi3EfffNS_9MulParamsIffEEE6SearchES1_PNS_11TrMulParamsE(i8 zeroext, %"struct.ruy::TrMulParams"*) local_unnamed_addr #1 comdat align 2 {
  switch i8 %0, label %57 [
    i8 8, label %3
    i8 2, label %4
  ]

3:                                                ; preds = %2
  tail call void @_ZN3ruy19PopulateTrMulParamsILNS_4PathE8EfffNS_9MulParamsIffEEEEvPNS_11TrMulParamsE(%"struct.ruy::TrMulParams"* %1)
  br label %57

4:                                                ; preds = %2
  %5 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 0
  store i8 2, i8* %5, align 8
  %6 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 0
  %7 = bitcast %"struct.ruy::PEMat"* %6 to i24*
  store i24 262401, i24* %7, align 8
  %8 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 0, i32 3
  %9 = bitcast %"struct.ruy::Type"* %8 to i24*
  store i24 262401, i24* %9, align 8
  %10 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 0, i32 6, i32 3
  store i8 0, i8* %10, align 4
  %11 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 3, i32 0, i64 0, i32 3, i32 0
  %12 = load i32, i32* %11, align 4
  %13 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 0, i32 6, i32 0
  store i32 %12, i32* %13, align 4
  %14 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 3, i32 0, i64 0, i32 3, i32 1
  %15 = load i32, i32* %14, align 4
  %16 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 0, i32 6, i32 1
  store i32 %15, i32* %16, align 4
  %17 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 0
  store i8 0, i8* %17, align 1
  %18 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 1
  store i8 1, i8* %18, align 1
  %19 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 2
  store i8 1, i8* %19, align 1
  %20 = and i32 %12, 255
  %21 = icmp eq i32 %20, 0
  %22 = add nsw i32 %12, 64
  %23 = select i1 %21, i32 %22, i32 %12
  %24 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 0, i32 6, i32 2
  store i32 %23, i32* %24, align 4
  %25 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 3, i32 0, i64 0, i32 4
  %26 = load i32, i32* %25, align 8
  %27 = sitofp i32 %26 to float
  %28 = fptosi float %27 to i32
  %29 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 0, i32 7
  store i32 %28, i32* %29, align 8
  %30 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 1
  %31 = bitcast %"struct.ruy::PEMat"* %30 to i24*
  store i24 262401, i24* %31, align 8
  %32 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 1, i32 3
  %33 = bitcast %"struct.ruy::Type"* %32 to i24*
  store i24 262401, i24* %33, align 8
  %34 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 1, i32 6, i32 3
  store i8 0, i8* %34, align 4
  %35 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 3, i32 0, i64 1, i32 3, i32 0
  %36 = load i32, i32* %35, align 4
  %37 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 1, i32 6, i32 0
  store i32 %36, i32* %37, align 4
  %38 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 3, i32 0, i64 1, i32 3, i32 1
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 1, i32 6, i32 1
  store i32 %39, i32* %40, align 4
  %41 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 0
  store i8 0, i8* %41, align 1
  %42 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 1
  store i8 1, i8* %42, align 1
  %43 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 2
  store i8 1, i8* %43, align 1
  %44 = and i32 %36, 255
  %45 = icmp eq i32 %44, 0
  %46 = add nsw i32 %36, 64
  %47 = select i1 %45, i32 %46, i32 %36
  %48 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 1, i32 6, i32 2
  store i32 %47, i32* %48, align 4
  %49 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 3, i32 0, i64 1, i32 4
  %50 = load i32, i32* %49, align 8
  %51 = sitofp i32 %50 to float
  %52 = fptosi float %51 to i32
  %53 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 1, i32 7
  store i32 %52, i32* %53, align 8
  %54 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 1, i32 0, i64 0
  %55 = bitcast void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)** %54 to <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*>*
  store <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*> <void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* @_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEffEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii, void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* @_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEffEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii>, <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*>* %55, align 8
  %56 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 2
  store void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)* @_ZN3ruy9RunKernelILNS_4PathE2EfffNS_9MulParamsIffEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE, void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)** %56, align 8
  br label %57

57:                                               ; preds = %2, %4, %3
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy19PopulateTrMulParamsILNS_4PathE8EfffNS_9MulParamsIffEEEEvPNS_11TrMulParamsE(%"struct.ruy::TrMulParams"*) local_unnamed_addr #1 comdat {
  %2 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 3
  %3 = load i8, i8* %2, align 4
  %4 = icmp eq i8 %3, 0
  br i1 %4, label %5, label %13

5:                                                ; preds = %1
  %6 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 3
  %7 = load i8, i8* %6, align 4
  %8 = icmp eq i8 %7, 0
  br i1 %8, label %9, label %13

9:                                                ; preds = %5
  %10 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 4, i32 3, i32 3
  %11 = load i8, i8* %10, align 4
  %12 = icmp eq i8 %11, 0
  br i1 %12, label %49, label %13

13:                                               ; preds = %1, %5, %9
  %14 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 0
  store i8 2, i8* %14, align 8
  %15 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0
  %16 = bitcast %"struct.ruy::PEMat"* %15 to i24*
  store i24 262401, i24* %16, align 8
  %17 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 3
  %18 = bitcast %"struct.ruy::Type"* %17 to i24*
  store i24 262401, i24* %18, align 8
  %19 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 3
  store i8 0, i8* %19, align 4
  %20 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 0
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 0
  store i32 %21, i32* %22, align 4
  %23 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 1
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 1
  store i32 %24, i32* %25, align 4
  %26 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 0
  store i8 0, i8* %26, align 1
  %27 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 1
  store i8 1, i8* %27, align 1
  %28 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 2
  store i8 1, i8* %28, align 1
  %29 = and i32 %21, 255
  %30 = icmp eq i32 %29, 0
  %31 = add nsw i32 %21, 64
  %32 = select i1 %30, i32 %31, i32 %21
  %33 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 2
  store i32 %32, i32* %33, align 4
  %34 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 4
  %35 = load i32, i32* %34, align 8
  %36 = sitofp i32 %35 to float
  %37 = fptosi float %36 to i32
  %38 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 7
  store i32 %37, i32* %38, align 8
  %39 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1
  %40 = bitcast %"struct.ruy::PEMat"* %39 to i24*
  store i24 262401, i24* %40, align 8
  %41 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 3
  %42 = bitcast %"struct.ruy::Type"* %41 to i24*
  store i24 262401, i24* %42, align 8
  %43 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 3
  store i8 0, i8* %43, align 4
  %44 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 0
  %45 = load i32, i32* %44, align 4
  %46 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 0
  store i32 %45, i32* %46, align 4
  %47 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 1
  %48 = load i32, i32* %47, align 4
  br label %89

49:                                               ; preds = %9
  %50 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 0
  store i8 8, i8* %50, align 8
  %51 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0
  %52 = bitcast %"struct.ruy::PEMat"* %51 to i24*
  store i24 262401, i24* %52, align 8
  %53 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 3
  %54 = bitcast %"struct.ruy::Type"* %53 to i24*
  store i24 262401, i24* %54, align 8
  %55 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 3
  store i8 0, i8* %55, align 4
  %56 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 0
  %57 = load i32, i32* %56, align 4
  %58 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 0
  store i32 %57, i32* %58, align 4
  %59 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 1
  %60 = load i32, i32* %59, align 4
  %61 = add i32 %60, 7
  %62 = and i32 %61, -8
  %63 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 1
  store i32 %62, i32* %63, align 4
  %64 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 0
  store i8 1, i8* %64, align 1
  %65 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 1
  store i8 1, i8* %65, align 1
  %66 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 2
  store i8 8, i8* %66, align 1
  %67 = and i32 %57, 255
  %68 = icmp eq i32 %67, 0
  %69 = add nsw i32 %57, 64
  %70 = select i1 %68, i32 %69, i32 %57
  %71 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 2
  store i32 %70, i32* %71, align 4
  %72 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 4
  %73 = load i32, i32* %72, align 8
  %74 = sitofp i32 %73 to float
  %75 = fptosi float %74 to i32
  %76 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 7
  store i32 %75, i32* %76, align 8
  %77 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1
  %78 = bitcast %"struct.ruy::PEMat"* %77 to i24*
  store i24 262401, i24* %78, align 8
  %79 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 3
  %80 = bitcast %"struct.ruy::Type"* %79 to i24*
  store i24 262401, i24* %80, align 8
  %81 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 3
  store i8 0, i8* %81, align 4
  %82 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 0
  %83 = load i32, i32* %82, align 4
  %84 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 0
  store i32 %83, i32* %84, align 4
  %85 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 1
  %86 = load i32, i32* %85, align 4
  %87 = add i32 %86, 7
  %88 = and i32 %87, -8
  br label %89

89:                                               ; preds = %49, %13
  %90 = phi i32 [ %88, %49 ], [ %48, %13 ]
  %91 = phi i8 [ 1, %49 ], [ 0, %13 ]
  %92 = phi i8 [ 8, %49 ], [ 1, %13 ]
  %93 = phi i32 [ %83, %49 ], [ %45, %13 ]
  %94 = phi void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* [ @_ZN3ruy7RunPackILNS_4PathE8ENS_17FixedKernelLayoutILNS_5OrderE1ELi1ELi8EEEffEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii, %49 ], [ @_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEffEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii, %13 ]
  %95 = phi void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)* [ @_ZN3ruy9RunKernelILNS_4PathE8EfffNS_9MulParamsIffEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE, %49 ], [ @_ZN3ruy9RunKernelILNS_4PathE2EfffNS_9MulParamsIffEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE, %13 ]
  %96 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 1
  store i32 %90, i32* %96, align 4
  %97 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 0
  store i8 %91, i8* %97, align 1
  %98 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 1
  store i8 1, i8* %98, align 1
  %99 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 2
  store i8 %92, i8* %99, align 1
  %100 = and i32 %93, 255
  %101 = icmp eq i32 %100, 0
  %102 = add nsw i32 %93, 64
  %103 = select i1 %101, i32 %102, i32 %93
  %104 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 2
  store i32 %103, i32* %104, align 4
  %105 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 4
  %106 = load i32, i32* %105, align 8
  %107 = sitofp i32 %106 to float
  %108 = fptosi float %107 to i32
  %109 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 7
  store i32 %108, i32* %109, align 8
  %110 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 1, i32 0, i64 0
  store void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* %94, void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)** %110, align 8
  %111 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 1, i32 0, i64 1
  store void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* %94, void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)** %111, align 8
  %112 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 2
  store void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)* %95, void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)** %112, align 8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy7RunPackILNS_4PathE8ENS_17FixedKernelLayoutILNS_5OrderE1ELi1ELi8EEEffEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii(i32, %"struct.ruy::EMat"* dereferenceable(40), %"struct.ruy::PEMat"*, i32, i32) #1 comdat {
  %6 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 2
  %7 = bitcast i8** %6 to float**
  %8 = load float*, float** %7, align 8, !noalias !347
  %9 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3, i32 0
  %10 = load i32, i32* %9, align 4
  %11 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3, i32 2
  %12 = load i32, i32* %11, align 4
  %13 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 2
  %14 = bitcast i8** %13 to float**
  %15 = load float*, float** %14, align 8, !noalias !350
  %16 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 6, i32 2
  %17 = load i32, i32* %16, align 4
  %18 = icmp slt i32 %3, %4
  br i1 %18, label %19, label %38

19:                                               ; preds = %5
  %20 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3, i32 1
  %21 = load i32, i32* %20, align 4
  %22 = sext i32 %3 to i64
  %23 = sext i32 %4 to i64
  %24 = sext i32 %12 to i64
  br label %25

25:                                               ; preds = %19, %25
  %26 = phi i64 [ %22, %19 ], [ %36, %25 ]
  %27 = mul nsw i64 %26, %24
  %28 = getelementptr inbounds float, float* %8, i64 %27
  %29 = trunc i64 %26 to i32
  %30 = and i32 %29, -8
  %31 = mul nsw i32 %30, %17
  %32 = sext i32 %31 to i64
  %33 = getelementptr inbounds float, float* %15, i64 %32
  %34 = trunc i64 %26 to i32
  %35 = sub i32 %21, %34
  tail call void @_ZN3ruy13PackFloatAvx2EPKfS1_iiiPf(float* %28, float* getelementptr inbounds ([8 x float], [8 x float]* @_ZZN3ruy8PackImplILNS_4PathE8ENS_17FixedKernelLayoutILNS_5OrderE1ELi1ELi8EEEfffE3RunENS_6TuningERKNS_3MatIfEEPNS_4PMatIfEEiiE7zerobuf, i64 0, i64 0), i32 %12, i32 %35, i32 %10, float* %33) #19
  %36 = add i64 %26, 8
  %37 = icmp slt i64 %36, %23
  br i1 %37, label %25, label %38

38:                                               ; preds = %25, %5
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy9RunKernelILNS_4PathE8EfffNS_9MulParamsIffEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE(i32, %"class.ruy::SidePair.104"* dereferenceable(112), i8*, %"class.ruy::SidePair.105"* dereferenceable(8), %"class.ruy::SidePair.105"* dereferenceable(8), %"struct.ruy::EMat"*) #1 comdat {
  %7 = alloca %"struct.ruy::KernelParamsFloat.110", align 8
  %8 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 2
  %9 = bitcast i8** %8 to float**
  %10 = load float*, float** %9, align 8, !noalias !353
  %11 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 0
  %12 = load i32, i32* %11, align 4
  %13 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 1
  %14 = load i32, i32* %13, align 4
  %15 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 2
  %16 = load i32, i32* %15, align 4
  %17 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 2
  %18 = bitcast i8** %17 to float**
  %19 = load float*, float** %18, align 8, !noalias !356
  %20 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 6, i32 0
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 6, i32 2
  %23 = load i32, i32* %22, align 4
  %24 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 2
  %25 = bitcast i8** %24 to float**
  %26 = load float*, float** %25, align 8, !noalias !359
  %27 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 6, i32 2
  %28 = load i32, i32* %27, align 4
  %29 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %3, i64 0, i32 0, i64 0
  %30 = load i32, i32* %29, align 4
  %31 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %3, i64 0, i32 0, i64 1
  %32 = load i32, i32* %31, align 4
  %33 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %4, i64 0, i32 0, i64 0
  %34 = load i32, i32* %33, align 4
  %35 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %4, i64 0, i32 0, i64 1
  %36 = load i32, i32* %35, align 4
  %37 = bitcast %"struct.ruy::KernelParamsFloat.110"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 376, i8* nonnull %37) #19
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %37, i8* align 8 bitcast (%"struct.ruy::KernelParamsFloat.110"* @__const._ZNK3ruy6KernelILNS_4PathE8EfffNS_9MulParamsIffEEE3RunERKNS_4PMatIfEES8_RKS3_iiiiPNS_3MatIfEE.params to i8*), i64 376, i1 false) #19
  %38 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.110", %"struct.ruy::KernelParamsFloat.110"* %7, i64 0, i32 18, i64 0
  %39 = bitcast float* %38 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 4 %39, i8 0, i64 32, i1 false) #19
  %40 = mul nsw i32 %30, %23
  %41 = sext i32 %40 to i64
  %42 = getelementptr inbounds float, float* %19, i64 %41
  %43 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.110", %"struct.ruy::KernelParamsFloat.110"* %7, i64 0, i32 0
  store float* %42, float** %43, align 8
  %44 = mul nsw i32 %32, %28
  %45 = sext i32 %44 to i64
  %46 = getelementptr inbounds float, float* %26, i64 %45
  %47 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.110", %"struct.ruy::KernelParamsFloat.110"* %7, i64 0, i32 1
  store float* %46, float** %47, align 8
  %48 = mul nsw i32 %32, %16
  %49 = sext i32 %48 to i64
  %50 = getelementptr inbounds float, float* %10, i64 %49
  %51 = sext i32 %30 to i64
  %52 = getelementptr inbounds float, float* %50, i64 %51
  %53 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.110", %"struct.ruy::KernelParamsFloat.110"* %7, i64 0, i32 2
  store float* %52, float** %53, align 8
  %54 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.110", %"struct.ruy::KernelParamsFloat.110"* %7, i64 0, i32 3
  %55 = bitcast i8* %2 to float**
  %56 = load float*, float** %55, align 8
  %57 = icmp eq float* %56, null
  %58 = select i1 %57, float* %38, float* %56
  store float* %58, float** %54, align 8
  %59 = xor i1 %57, true
  %60 = zext i1 %59 to i8
  %61 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.110", %"struct.ruy::KernelParamsFloat.110"* %7, i64 0, i32 16
  store i8 %60, i8* %61, align 8
  %62 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.110", %"struct.ruy::KernelParamsFloat.110"* %7, i64 0, i32 4
  store i32 %30, i32* %62, align 8
  %63 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.110", %"struct.ruy::KernelParamsFloat.110"* %7, i64 0, i32 5
  store i32 %32, i32* %63, align 4
  %64 = add nsw i32 %34, -8
  %65 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.110", %"struct.ruy::KernelParamsFloat.110"* %7, i64 0, i32 6
  store i32 %64, i32* %65, align 8
  %66 = add nsw i32 %36, -8
  %67 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.110", %"struct.ruy::KernelParamsFloat.110"* %7, i64 0, i32 7
  store i32 %66, i32* %67, align 4
  %68 = shl i32 %23, 2
  %69 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.110", %"struct.ruy::KernelParamsFloat.110"* %7, i64 0, i32 10
  store i32 %68, i32* %69, align 8
  %70 = shl i32 %28, 2
  %71 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.110", %"struct.ruy::KernelParamsFloat.110"* %7, i64 0, i32 11
  store i32 %70, i32* %71, align 4
  %72 = shl i32 %16, 2
  %73 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.110", %"struct.ruy::KernelParamsFloat.110"* %7, i64 0, i32 12
  store i32 %72, i32* %73, align 8
  %74 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.110", %"struct.ruy::KernelParamsFloat.110"* %7, i64 0, i32 13
  store i32 %21, i32* %74, align 4
  %75 = getelementptr inbounds i8, i8* %2, i64 32
  %76 = bitcast i8* %75 to i32*
  %77 = load i32, i32* %76, align 8
  %78 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.110", %"struct.ruy::KernelParamsFloat.110"* %7, i64 0, i32 14
  %79 = bitcast float* %78 to i32*
  store i32 %77, i32* %79, align 8
  %80 = getelementptr inbounds i8, i8* %2, i64 36
  %81 = bitcast i8* %80 to i32*
  %82 = load i32, i32* %81, align 4
  %83 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.110", %"struct.ruy::KernelParamsFloat.110"* %7, i64 0, i32 15
  %84 = bitcast float* %83 to i32*
  store i32 %82, i32* %84, align 4
  %85 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.110", %"struct.ruy::KernelParamsFloat.110"* %7, i64 0, i32 8
  store i32 %12, i32* %85, align 8
  %86 = getelementptr inbounds %"struct.ruy::KernelParamsFloat.110", %"struct.ruy::KernelParamsFloat.110"* %7, i64 0, i32 9
  store i32 %14, i32* %86, align 4
  %87 = icmp eq i32 %14, 1
  br i1 %87, label %88, label %89

88:                                               ; preds = %6
  call void @_ZN3ruy24KernelFloatAvx2SingleColERKNS_17KernelParamsFloatILi8ELi8EEE(%"struct.ruy::KernelParamsFloat.110"* nonnull dereferenceable(376) %7) #19
  br label %90

89:                                               ; preds = %6
  call void @_ZN3ruy15KernelFloatAvx2ERKNS_17KernelParamsFloatILi8ELi8EEE(%"struct.ruy::KernelParamsFloat.110"* nonnull dereferenceable(376) %7) #19
  br label %90

90:                                               ; preds = %88, %89
  call void @llvm.lifetime.end.p0i8(i64 376, i8* nonnull %37) #19
  ret void
}

declare void @_ZN3ruy13PackFloatAvx2EPKfS1_iiiPf(float*, float*, i32, i32, i32, float*) local_unnamed_addr #5

declare void @_ZN3ruy24KernelFloatAvx2SingleColERKNS_17KernelParamsFloatILi8ELi8EEE(%"struct.ruy::KernelParamsFloat.110"* dereferenceable(376)) local_unnamed_addr #5

declare void @_ZN3ruy15KernelFloatAvx2ERKNS_17KernelParamsFloatILi8ELi8EEE(%"struct.ruy::KernelParamsFloat.110"* dereferenceable(376)) local_unnamed_addr #5

declare %"class.ruy::PrepackedCache"* @_ZN3ruy3Ctx17GetPrepackedCacheEv(%"class.ruy::Ctx"*) local_unnamed_addr #5

declare i32 @_ZN3ruy14PrepackedCache3GetEPKvPNS_5PEMatE(%"class.ruy::PrepackedCache"*, i8*, %"struct.ruy::PEMat"*) local_unnamed_addr #5

declare i32 @_ZN3ruy3Ctx19GetMainThreadTuningEv(%"class.ruy::Ctx"*) local_unnamed_addr #5

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN6tflite13optimized_ops22ShuffledFullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKiS6_PsPhPNS_17CpuBackendContextE(%"struct.tflite::FullyConnectedParams"* dereferenceable(40), %"class.tflite::RuntimeShape"* dereferenceable(32), i8*, %"class.tflite::RuntimeShape"* dereferenceable(32), i8*, %"class.tflite::RuntimeShape"* dereferenceable(32), i32*, %"class.tflite::RuntimeShape"* dereferenceable(32), i16*, i8*, %"class.tflite::CpuBackendContext"*) local_unnamed_addr #4 comdat {
  %12 = alloca i8*, align 8
  %13 = alloca i32, align 4
  %14 = alloca i32, align 4
  %15 = alloca i32, align 4
  %16 = alloca i32, align 4
  %17 = alloca i32, align 4
  %18 = alloca %"class.std::__1::vector.143", align 8
  %19 = alloca i8*, align 8
  %20 = alloca i32, align 4
  %21 = alloca i32*, align 8
  %22 = alloca i16*, align 8
  store i8* %9, i8** %12, align 8
  %23 = bitcast i32* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %23) #19
  %24 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 3
  %25 = load i32, i32* %24, align 4
  store i32 %25, i32* %13, align 4
  %26 = bitcast i32* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %26) #19
  %27 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 4
  %28 = load i32, i32* %27, align 4
  store i32 %28, i32* %14, align 4
  %29 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %3, i64 0, i32 0
  %30 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %7, i64 0, i32 0
  %31 = load i32, i32* %30, align 8
  %32 = load i32, i32* %29, align 8
  %33 = bitcast i32* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %33) #19
  store i32 -1431655766, i32* %15, align 4
  %34 = add nsw i32 %31, -1
  %35 = icmp sgt i32 %31, 5
  %36 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %7, i64 0, i32 1
  %37 = getelementptr inbounds %union.anon.54, %union.anon.54* %36, i64 0, i32 0
  %38 = load i32*, i32** %37, align 8
  %39 = bitcast %union.anon.54* %36 to i32*
  %40 = select i1 %35, i32* %38, i32* %39
  %41 = icmp sgt i32 %31, 0
  br i1 %41, label %42, label %82

42:                                               ; preds = %11
  %43 = zext i32 %34 to i64
  %44 = zext i32 %31 to i64
  %45 = add nsw i64 %44, -1
  %46 = and i64 %44, 3
  %47 = icmp ult i64 %45, 3
  br i1 %47, label %63, label %48

48:                                               ; preds = %42
  %49 = sub nsw i64 %44, %46
  br label %50

50:                                               ; preds = %371, %48
  %51 = phi i64 [ 0, %48 ], [ %374, %371 ]
  %52 = phi i32 [ 1, %48 ], [ %373, %371 ]
  %53 = phi i64 [ %49, %48 ], [ %375, %371 ]
  %54 = icmp eq i64 %51, %43
  br i1 %54, label %58, label %55

55:                                               ; preds = %50
  %56 = getelementptr inbounds i32, i32* %40, i64 %51
  %57 = load i32, i32* %56, align 4
  br label %58

58:                                               ; preds = %55, %50
  %59 = phi i32 [ %57, %55 ], [ 1, %50 ]
  %60 = mul nsw i32 %59, %52
  %61 = or i64 %51, 1
  %62 = icmp eq i64 %61, %43
  br i1 %62, label %355, label %352

63:                                               ; preds = %371, %42
  %64 = phi i32 [ undef, %42 ], [ %373, %371 ]
  %65 = phi i64 [ 0, %42 ], [ %374, %371 ]
  %66 = phi i32 [ 1, %42 ], [ %373, %371 ]
  %67 = icmp eq i64 %46, 0
  br i1 %67, label %82, label %68

68:                                               ; preds = %63, %76
  %69 = phi i64 [ %79, %76 ], [ %65, %63 ]
  %70 = phi i32 [ %78, %76 ], [ %66, %63 ]
  %71 = phi i64 [ %80, %76 ], [ %46, %63 ]
  %72 = icmp eq i64 %69, %43
  br i1 %72, label %76, label %73

73:                                               ; preds = %68
  %74 = getelementptr inbounds i32, i32* %40, i64 %69
  %75 = load i32, i32* %74, align 4
  br label %76

76:                                               ; preds = %73, %68
  %77 = phi i32 [ %75, %73 ], [ 1, %68 ]
  %78 = mul nsw i32 %77, %70
  %79 = add nuw nsw i64 %69, 1
  %80 = add i64 %71, -1
  %81 = icmp eq i64 %80, 0
  br i1 %81, label %82, label %68, !llvm.loop !362

82:                                               ; preds = %63, %76, %11
  %83 = phi i32 [ 1, %11 ], [ %64, %63 ], [ %78, %76 ]
  store i32 %83, i32* %15, align 4
  %84 = bitcast i32* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %84) #19
  store i32 -1431655766, i32* %16, align 4
  %85 = add nsw i32 %32, -2
  %86 = icmp sgt i32 %32, 5
  %87 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %3, i64 0, i32 1
  %88 = getelementptr inbounds %union.anon.54, %union.anon.54* %87, i64 0, i32 0
  %89 = load i32*, i32** %88, align 8
  %90 = sext i32 %85 to i64
  %91 = getelementptr inbounds i32, i32* %89, i64 %90
  %92 = bitcast %union.anon.54* %87 to [5 x i32]*
  %93 = getelementptr inbounds [5 x i32], [5 x i32]* %92, i64 0, i64 %90
  %94 = select i1 %86, i32* %91, i32* %93
  %95 = load i32, i32* %94, align 4
  %96 = sext i32 %34 to i64
  %97 = getelementptr inbounds i32, i32* %38, i64 %96
  %98 = bitcast %union.anon.54* %36 to [5 x i32]*
  %99 = getelementptr inbounds [5 x i32], [5 x i32]* %98, i64 0, i64 %96
  %100 = select i1 %35, i32* %97, i32* %99
  %101 = load i32, i32* %100, align 4
  %102 = icmp slt i32 %101, %95
  %103 = select i1 %102, i32 %101, i32 %95
  store i32 %103, i32* %16, align 4
  %104 = bitcast i32* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %104) #19
  store i32 -1431655766, i32* %17, align 4
  %105 = add nsw i32 %32, -1
  %106 = sext i32 %105 to i64
  %107 = getelementptr inbounds i32, i32* %89, i64 %106
  %108 = getelementptr inbounds [5 x i32], [5 x i32]* %92, i64 0, i64 %106
  %109 = select i1 %86, i32* %107, i32* %108
  %110 = load i32, i32* %109, align 4
  store i32 %110, i32* %17, align 4
  switch i32 %83, label %351 [
    i32 1, label %113
    i32 4, label %111
  ]

111:                                              ; preds = %82
  %112 = icmp sgt i32 %110, 0
  br i1 %112, label %131, label %215

113:                                              ; preds = %82
  %114 = icmp sgt i32 %110, 0
  br i1 %114, label %115, label %215

115:                                              ; preds = %113
  %116 = load i8, i8* %2, align 1
  %117 = xor i8 %116, -128
  store i8 %117, i8* %9, align 1
  %118 = load i32, i32* %17, align 4
  %119 = icmp sgt i32 %118, 1
  br i1 %119, label %120, label %215

120:                                              ; preds = %115, %120
  %121 = phi i64 [ %127, %120 ], [ 1, %115 ]
  %122 = load i8*, i8** %12, align 8
  %123 = getelementptr inbounds i8, i8* %2, i64 %121
  %124 = load i8, i8* %123, align 1
  %125 = xor i8 %124, -128
  %126 = getelementptr inbounds i8, i8* %122, i64 %121
  store i8 %125, i8* %126, align 1
  %127 = add nuw nsw i64 %121, 1
  %128 = load i32, i32* %17, align 4
  %129 = sext i32 %128 to i64
  %130 = icmp slt i64 %127, %129
  br i1 %130, label %120, label %215

131:                                              ; preds = %111, %136
  %132 = phi i32 [ %138, %136 ], [ %110, %111 ]
  %133 = phi i64 [ %137, %136 ], [ 0, %111 ]
  %134 = phi i8* [ %210, %136 ], [ %9, %111 ]
  %135 = getelementptr inbounds i8, i8* %2, i64 %133
  br label %141

136:                                              ; preds = %141
  %137 = add nuw nsw i64 %133, 16
  %138 = load i32, i32* %17, align 4
  %139 = sext i32 %138 to i64
  %140 = icmp slt i64 %137, %139
  br i1 %140, label %131, label %215

141:                                              ; preds = %213, %131
  %142 = phi i32 [ %132, %131 ], [ %214, %213 ]
  %143 = phi i8* [ %134, %131 ], [ %210, %213 ]
  %144 = phi i32 [ 0, %131 ], [ %211, %213 ]
  %145 = mul nsw i32 %142, %144
  %146 = sext i32 %145 to i64
  %147 = getelementptr inbounds i8, i8* %135, i64 %146
  %148 = getelementptr inbounds i8, i8* %147, i64 1
  %149 = load i8, i8* %147, align 1
  %150 = xor i8 %149, -128
  %151 = getelementptr inbounds i8, i8* %143, i64 1
  store i8 %150, i8* %143, align 1
  %152 = getelementptr inbounds i8, i8* %148, i64 1
  %153 = load i8, i8* %148, align 1
  %154 = xor i8 %153, -128
  %155 = getelementptr inbounds i8, i8* %143, i64 2
  store i8 %154, i8* %151, align 1
  %156 = getelementptr inbounds i8, i8* %152, i64 1
  %157 = load i8, i8* %152, align 1
  %158 = xor i8 %157, -128
  %159 = getelementptr inbounds i8, i8* %143, i64 3
  store i8 %158, i8* %155, align 1
  %160 = getelementptr inbounds i8, i8* %156, i64 1
  %161 = load i8, i8* %156, align 1
  %162 = xor i8 %161, -128
  %163 = getelementptr inbounds i8, i8* %143, i64 4
  store i8 %162, i8* %159, align 1
  %164 = getelementptr inbounds i8, i8* %160, i64 1
  %165 = load i8, i8* %160, align 1
  %166 = xor i8 %165, -128
  %167 = getelementptr inbounds i8, i8* %143, i64 5
  store i8 %166, i8* %163, align 1
  %168 = getelementptr inbounds i8, i8* %164, i64 1
  %169 = load i8, i8* %164, align 1
  %170 = xor i8 %169, -128
  %171 = getelementptr inbounds i8, i8* %143, i64 6
  store i8 %170, i8* %167, align 1
  %172 = getelementptr inbounds i8, i8* %168, i64 1
  %173 = load i8, i8* %168, align 1
  %174 = xor i8 %173, -128
  %175 = getelementptr inbounds i8, i8* %143, i64 7
  store i8 %174, i8* %171, align 1
  %176 = getelementptr inbounds i8, i8* %172, i64 1
  %177 = load i8, i8* %172, align 1
  %178 = xor i8 %177, -128
  %179 = getelementptr inbounds i8, i8* %143, i64 8
  store i8 %178, i8* %175, align 1
  %180 = getelementptr inbounds i8, i8* %176, i64 1
  %181 = load i8, i8* %176, align 1
  %182 = xor i8 %181, -128
  %183 = getelementptr inbounds i8, i8* %143, i64 9
  store i8 %182, i8* %179, align 1
  %184 = getelementptr inbounds i8, i8* %180, i64 1
  %185 = load i8, i8* %180, align 1
  %186 = xor i8 %185, -128
  %187 = getelementptr inbounds i8, i8* %143, i64 10
  store i8 %186, i8* %183, align 1
  %188 = getelementptr inbounds i8, i8* %184, i64 1
  %189 = load i8, i8* %184, align 1
  %190 = xor i8 %189, -128
  %191 = getelementptr inbounds i8, i8* %143, i64 11
  store i8 %190, i8* %187, align 1
  %192 = getelementptr inbounds i8, i8* %188, i64 1
  %193 = load i8, i8* %188, align 1
  %194 = xor i8 %193, -128
  %195 = getelementptr inbounds i8, i8* %143, i64 12
  store i8 %194, i8* %191, align 1
  %196 = getelementptr inbounds i8, i8* %192, i64 1
  %197 = load i8, i8* %192, align 1
  %198 = xor i8 %197, -128
  %199 = getelementptr inbounds i8, i8* %143, i64 13
  store i8 %198, i8* %195, align 1
  %200 = getelementptr inbounds i8, i8* %196, i64 1
  %201 = load i8, i8* %196, align 1
  %202 = xor i8 %201, -128
  %203 = getelementptr inbounds i8, i8* %143, i64 14
  store i8 %202, i8* %199, align 1
  %204 = getelementptr inbounds i8, i8* %200, i64 1
  %205 = load i8, i8* %200, align 1
  %206 = xor i8 %205, -128
  %207 = getelementptr inbounds i8, i8* %143, i64 15
  store i8 %206, i8* %203, align 1
  %208 = load i8, i8* %204, align 1
  %209 = xor i8 %208, -128
  %210 = getelementptr inbounds i8, i8* %143, i64 16
  store i8 %209, i8* %207, align 1
  %211 = add nuw nsw i32 %144, 1
  %212 = icmp eq i32 %211, 4
  br i1 %212, label %136, label %213

213:                                              ; preds = %141
  %214 = load i32, i32* %17, align 4
  br label %141

215:                                              ; preds = %136, %120, %115, %111, %113
  %216 = phi i32 [ %110, %111 ], [ %110, %113 ], [ %118, %115 ], [ %128, %120 ], [ %138, %136 ]
  %217 = getelementptr inbounds %"class.tflite::CpuBackendContext", %"class.tflite::CpuBackendContext"* %10, i64 0, i32 3
  %218 = load i32, i32* %217, align 8
  %219 = load i32, i32* %16, align 4
  %220 = load i32, i32* %15, align 4
  %221 = icmp eq i32 %218, 1
  br i1 %221, label %238, label %222

222:                                              ; preds = %215
  %223 = sdiv i32 %219, 4
  %224 = icmp slt i32 %223, %218
  %225 = select i1 %224, i32 %223, i32 %218
  %226 = icmp sgt i32 %225, 1
  br i1 %226, label %227, label %238

227:                                              ; preds = %222
  %228 = sext i32 %219 to i64
  %229 = sext i32 %220 to i64
  %230 = mul nsw i64 %229, %228
  %231 = sext i32 %216 to i64
  %232 = mul i64 %230, %231
  %233 = lshr i64 %232, 16
  %234 = trunc i64 %233 to i32
  %235 = icmp sgt i32 %225, %234
  br i1 %235, label %236, label %242

236:                                              ; preds = %227
  %237 = icmp sgt i32 %234, 1
  br i1 %237, label %242, label %238

238:                                              ; preds = %222, %236, %215
  %239 = load i8*, i8** %12, align 8
  %240 = load i32, i32* %13, align 4
  %241 = load i32, i32* %14, align 4
  tail call void @_ZN6tflite13optimized_ops32ShuffledFullyConnectedWorkerImplEPKhPKaiiiiPKiiiPs(i8* %239, i8* %4, i32 %220, i32 %219, i32 %219, i32 %216, i32* %6, i32 %240, i32 %241, i16* %8)
  br label %351

242:                                              ; preds = %227, %236
  %243 = phi i32 [ %225, %227 ], [ %234, %236 ]
  %244 = bitcast %"class.std::__1::vector.143"* %18 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %244) #19
  %245 = getelementptr inbounds %"class.std::__1::vector.143", %"class.std::__1::vector.143"* %18, i64 0, i32 0, i32 0
  %246 = getelementptr inbounds %"class.std::__1::vector.143", %"class.std::__1::vector.143"* %18, i64 0, i32 0, i32 1
  %247 = getelementptr inbounds %"class.std::__1::vector.143", %"class.std::__1::vector.143"* %18, i64 0, i32 0, i32 2, i32 0, i32 0
  %248 = sext i32 %243 to i64
  %249 = bitcast %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"** %247 to i64*
  %250 = bitcast %"class.std::__1::vector.143"* %18 to i64*
  %251 = bitcast %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"** %246 to i64*
  %252 = mul nsw i64 %248, 72
  %253 = tail call i8* @_Znwm(i64 %252) #18
  %254 = bitcast i8* %253 to %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"*
  %255 = ptrtoint i8* %253 to i64
  %256 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %254, i64 %248
  %257 = ptrtoint %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %256 to i64
  store i64 %255, i64* %250, align 8
  store i64 %255, i64* %251, align 8
  store i64 %257, i64* %249, align 8
  %258 = add nsw i32 %243, -1
  %259 = add i32 %258, %219
  %260 = sdiv i32 %259, %243
  %261 = add nsw i32 %260, 3
  %262 = and i32 %261, -4
  %263 = bitcast i8** %19 to i8*
  %264 = bitcast i32* %20 to i8*
  %265 = bitcast i32** %21 to i8*
  %266 = bitcast i16** %22 to i8*
  %267 = bitcast i8** %12 to i64*
  %268 = bitcast %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"** %246 to i64*
  br label %298

269:                                              ; preds = %343
  %270 = load i64, i64* %268, align 8
  %271 = load i64, i64* %250, align 8
  %272 = sub i64 %270, %271
  %273 = sdiv exact i64 %272, 72
  %274 = trunc i64 %273 to i32
  %275 = inttoptr i64 %271 to %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"*
  %276 = getelementptr inbounds %"class.tflite::CpuBackendContext", %"class.tflite::CpuBackendContext"* %10, i64 0, i32 2, i32 0, i32 0, i32 0
  %277 = load %"class.gemmlowp::GemmContext"*, %"class.gemmlowp::GemmContext"** %276, align 8
  %278 = getelementptr inbounds %"class.gemmlowp::GemmContext", %"class.gemmlowp::GemmContext"* %277, i64 0, i32 0, i32 1
  call void @_ZN8gemmlowp11WorkersPool7ExecuteIN6tflite13optimized_ops32ShuffledFullyConnectedWorkerTaskEEEviPT_(%"class.gemmlowp::WorkersPool"* %278, i32 %274, %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %275) #19
  %279 = load %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"*, %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"** %245, align 8
  %280 = icmp eq %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %279, null
  br i1 %280, label %297, label %281

281:                                              ; preds = %269
  %282 = bitcast %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %279 to i8*
  %283 = load %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"*, %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"** %246, align 8
  %284 = icmp eq %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %283, %279
  br i1 %284, label %295, label %285

285:                                              ; preds = %281, %285
  %286 = phi %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* [ %287, %285 ], [ %283, %281 ]
  %287 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %286, i64 -1
  %288 = bitcast %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %287 to void (%"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"*)***
  %289 = load void (%"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"*)**, void (%"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"*)*** %288, align 8
  %290 = load void (%"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"*)*, void (%"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"*)** %289, align 8
  call void %290(%"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %287) #19
  %291 = icmp eq %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %287, %279
  br i1 %291, label %292, label %285

292:                                              ; preds = %285
  %293 = bitcast %"class.std::__1::vector.143"* %18 to i8**
  %294 = load i8*, i8** %293, align 8
  br label %295

295:                                              ; preds = %292, %281
  %296 = phi i8* [ %294, %292 ], [ %282, %281 ]
  store %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %279, %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"** %246, align 8
  call void @_ZdlPv(i8* %296) #18
  br label %297

297:                                              ; preds = %269, %295
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %244) #19
  br label %351

298:                                              ; preds = %346, %242
  %299 = phi %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* [ %256, %242 ], [ %350, %346 ]
  %300 = phi %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* [ %254, %242 ], [ %349, %346 ]
  %301 = phi i32 [ %216, %242 ], [ %348, %346 ]
  %302 = phi i32 [ %219, %242 ], [ %347, %346 ]
  %303 = phi i32 [ 0, %242 ], [ %344, %346 ]
  %304 = phi i32 [ 0, %242 ], [ %307, %346 ]
  %305 = add nsw i32 %304, %262
  %306 = icmp slt i32 %305, %302
  %307 = select i1 %306, i32 %305, i32 %302
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %263) #19
  %308 = mul nsw i32 %301, %304
  %309 = sext i32 %308 to i64
  %310 = getelementptr inbounds i8, i8* %4, i64 %309
  store i8* %310, i8** %19, align 8
  call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %264) #19
  %311 = sub nsw i32 %307, %304
  store i32 %311, i32* %20, align 4
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %265) #19
  %312 = sext i32 %304 to i64
  %313 = getelementptr inbounds i32, i32* %6, i64 %312
  store i32* %313, i32** %21, align 8
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %266) #19
  %314 = getelementptr inbounds i16, i16* %8, i64 %312
  store i16* %314, i16** %22, align 8
  %315 = icmp ult %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %300, %299
  br i1 %315, label %316, label %342

316:                                              ; preds = %298
  %317 = ptrtoint i16* %314 to i64
  %318 = ptrtoint i32* %313 to i64
  %319 = ptrtoint i8* %310 to i64
  %320 = load i64, i64* %267, align 8
  %321 = load i32, i32* %15, align 4
  %322 = load i32, i32* %13, align 4
  %323 = load i32, i32* %14, align 4
  %324 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %300, i64 0, i32 0, i32 0
  %325 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %300, i64 0, i32 0, i32 1
  store %"class.gemmlowp::Allocator"* null, %"class.gemmlowp::Allocator"** %325, align 8
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVN6tflite13optimized_ops32ShuffledFullyConnectedWorkerTaskE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %324, align 8
  %326 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %300, i64 0, i32 1
  %327 = bitcast i8** %326 to i64*
  store i64 %320, i64* %327, align 8
  %328 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %300, i64 0, i32 2
  %329 = bitcast i8** %328 to i64*
  store i64 %319, i64* %329, align 8
  %330 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %300, i64 0, i32 3
  store i32 %321, i32* %330, align 8
  %331 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %300, i64 0, i32 4
  store i32 %311, i32* %331, align 4
  %332 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %300, i64 0, i32 5
  store i32 %302, i32* %332, align 8
  %333 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %300, i64 0, i32 6
  store i32 %301, i32* %333, align 4
  %334 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %300, i64 0, i32 7
  %335 = bitcast i32** %334 to i64*
  store i64 %318, i64* %335, align 8
  %336 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %300, i64 0, i32 8
  store i32 %322, i32* %336, align 8
  %337 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %300, i64 0, i32 9
  store i32 %323, i32* %337, align 4
  %338 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %300, i64 0, i32 10
  %339 = bitcast i16** %338 to i64*
  store i64 %317, i64* %339, align 8
  %340 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %300, i64 1
  %341 = ptrtoint %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %340 to i64
  store i64 %341, i64* %268, align 8
  br label %343

342:                                              ; preds = %298
  call void @_ZNSt3__16vectorIN6tflite13optimized_ops32ShuffledFullyConnectedWorkerTaskENS_9allocatorIS3_EEE24__emplace_back_slow_pathIJRPhPKaRKiiSD_SD_PSC_SD_SD_PsEEEvDpOT_(%"class.std::__1::vector.143"* nonnull %18, i8** nonnull dereferenceable(8) %12, i8** nonnull dereferenceable(8) %19, i32* nonnull dereferenceable(4) %15, i32* nonnull dereferenceable(4) %20, i32* nonnull dereferenceable(4) %16, i32* nonnull dereferenceable(4) %17, i32** nonnull dereferenceable(8) %21, i32* nonnull dereferenceable(4) %13, i32* nonnull dereferenceable(4) %14, i16** nonnull dereferenceable(8) %22) #19
  br label %343

343:                                              ; preds = %316, %342
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %266) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %265) #19
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %264) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %263) #19
  %344 = add nuw nsw i32 %303, 1
  %345 = icmp eq i32 %344, %243
  br i1 %345, label %269, label %346

346:                                              ; preds = %343
  %347 = load i32, i32* %16, align 4
  %348 = load i32, i32* %17, align 4
  %349 = load %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"*, %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"** %246, align 8
  %350 = load %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"*, %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"** %247, align 8
  br label %298

351:                                              ; preds = %238, %297, %82
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %104) #19
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %84) #19
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %33) #19
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %26) #19
  call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %23) #19
  ret void

352:                                              ; preds = %58
  %353 = getelementptr inbounds i32, i32* %40, i64 %61
  %354 = load i32, i32* %353, align 4
  br label %355

355:                                              ; preds = %352, %58
  %356 = phi i32 [ %354, %352 ], [ 1, %58 ]
  %357 = mul nsw i32 %356, %60
  %358 = or i64 %51, 2
  %359 = icmp eq i64 %358, %43
  br i1 %359, label %363, label %360

360:                                              ; preds = %355
  %361 = getelementptr inbounds i32, i32* %40, i64 %358
  %362 = load i32, i32* %361, align 4
  br label %363

363:                                              ; preds = %360, %355
  %364 = phi i32 [ %362, %360 ], [ 1, %355 ]
  %365 = mul nsw i32 %364, %357
  %366 = or i64 %51, 3
  %367 = icmp eq i64 %366, %43
  br i1 %367, label %371, label %368

368:                                              ; preds = %363
  %369 = getelementptr inbounds i32, i32* %40, i64 %366
  %370 = load i32, i32* %369, align 4
  br label %371

371:                                              ; preds = %368, %363
  %372 = phi i32 [ %370, %368 ], [ 1, %363 ]
  %373 = mul nsw i32 %372, %365
  %374 = add nuw nsw i64 %51, 4
  %375 = add i64 %53, -4
  %376 = icmp eq i64 %375, 0
  br i1 %376, label %63, label %50
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN6tflite13optimized_ops32ShuffledFullyConnectedWorkerImplEPKhPKaiiiiPKiiiPs(i8*, i8*, i32, i32, i32, i32, i32*, i32, i32, i16*) local_unnamed_addr #4 comdat {
  %11 = alloca [4 x i32], align 16
  %12 = alloca [4 x [4 x i32]], align 16
  %13 = bitcast [4 x [4 x i32]]* %12 to i8*
  switch i32 %2, label %903 [
    i32 1, label %34
    i32 4, label %14
  ]

14:                                               ; preds = %10
  %15 = icmp sgt i32 %3, 0
  br i1 %15, label %16, label %903

16:                                               ; preds = %14
  %17 = icmp sgt i32 %5, 0
  %18 = icmp sgt i32 %8, 0
  %19 = sub nsw i32 0, %8
  %20 = select i1 %18, i32 0, i32 %19
  %21 = shl i32 1, %8
  %22 = select i1 %18, i32 %21, i32 1
  %23 = sext i32 %7 to i64
  %24 = icmp eq i32 %7, -2147483648
  %25 = mul nsw i64 %23, %23
  %26 = zext i32 %20 to i64
  %27 = shl nsw i64 -1, %26
  %28 = trunc i64 %27 to i32
  %29 = xor i32 %28, -1
  %30 = ashr i32 %29, 1
  %31 = sext i32 %3 to i64
  %32 = shl i32 %4, 1
  %33 = mul i32 %4, 3
  br label %260

34:                                               ; preds = %10
  %35 = icmp sgt i32 %3, 0
  br i1 %35, label %36, label %903

36:                                               ; preds = %34
  %37 = bitcast [4 x i32]* %11 to i8*
  %38 = icmp sgt i32 %5, 0
  %39 = icmp sgt i32 %8, 0
  %40 = sub nsw i32 0, %8
  %41 = select i1 %39, i32 0, i32 %40
  %42 = shl i32 1, %8
  %43 = select i1 %39, i32 %42, i32 1
  %44 = sext i32 %7 to i64
  %45 = icmp eq i32 %7, -2147483648
  %46 = mul nsw i64 %44, %44
  %47 = zext i32 %41 to i64
  %48 = shl nsw i64 -1, %47
  %49 = trunc i64 %48 to i32
  %50 = xor i32 %49, -1
  %51 = ashr i32 %50, 1
  %52 = sext i32 %5 to i64
  %53 = sext i32 %3 to i64
  %54 = getelementptr inbounds [4 x i32], [4 x i32]* %11, i64 0, i64 0
  %55 = getelementptr inbounds [4 x i32], [4 x i32]* %11, i64 0, i64 1
  %56 = getelementptr inbounds [4 x i32], [4 x i32]* %11, i64 0, i64 2
  %57 = getelementptr inbounds [4 x i32], [4 x i32]* %11, i64 0, i64 3
  br label %58

58:                                               ; preds = %36, %981
  %59 = phi i64 [ 0, %36 ], [ %996, %981 ]
  %60 = phi i8* [ %1, %36 ], [ %65, %981 ]
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %37) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %37, i8 0, i64 16, i1 false)
  br i1 %38, label %71, label %63

61:                                               ; preds = %224
  %62 = load i32, i32* %54, align 16
  br label %63

63:                                               ; preds = %61, %58
  %64 = phi i32 [ 0, %58 ], [ %62, %61 ]
  %65 = phi i8* [ %60, %58 ], [ %216, %61 ]
  %66 = getelementptr inbounds i32, i32* %6, i64 %59
  %67 = load i32, i32* %66, align 4
  %68 = add nsw i32 %67, %64
  %69 = mul nsw i32 %68, %43
  %70 = icmp eq i32 %69, %7
  br i1 %70, label %230, label %227

71:                                               ; preds = %58, %224
  %72 = phi i64 [ %225, %224 ], [ 0, %58 ]
  %73 = phi i8* [ %216, %224 ], [ %60, %58 ]
  %74 = getelementptr inbounds i8, i8* %0, i64 %72
  %75 = or i64 %72, 1
  %76 = getelementptr inbounds i8, i8* %0, i64 %75
  %77 = or i64 %72, 2
  %78 = getelementptr inbounds i8, i8* %0, i64 %77
  %79 = or i64 %72, 3
  %80 = getelementptr inbounds i8, i8* %0, i64 %79
  %81 = or i64 %72, 4
  %82 = getelementptr inbounds i8, i8* %0, i64 %81
  %83 = or i64 %72, 5
  %84 = getelementptr inbounds i8, i8* %0, i64 %83
  %85 = or i64 %72, 6
  %86 = getelementptr inbounds i8, i8* %0, i64 %85
  %87 = or i64 %72, 7
  %88 = getelementptr inbounds i8, i8* %0, i64 %87
  %89 = or i64 %72, 8
  %90 = getelementptr inbounds i8, i8* %0, i64 %89
  %91 = or i64 %72, 9
  %92 = getelementptr inbounds i8, i8* %0, i64 %91
  %93 = or i64 %72, 10
  %94 = getelementptr inbounds i8, i8* %0, i64 %93
  %95 = or i64 %72, 11
  %96 = getelementptr inbounds i8, i8* %0, i64 %95
  %97 = or i64 %72, 12
  %98 = getelementptr inbounds i8, i8* %0, i64 %97
  %99 = or i64 %72, 13
  %100 = getelementptr inbounds i8, i8* %0, i64 %99
  %101 = or i64 %72, 14
  %102 = getelementptr inbounds i8, i8* %0, i64 %101
  %103 = or i64 %72, 15
  %104 = getelementptr inbounds i8, i8* %0, i64 %103
  br label %105

105:                                              ; preds = %105, %71
  %106 = phi i64 [ 0, %71 ], [ %222, %105 ]
  %107 = phi i8* [ %73, %71 ], [ %216, %105 ]
  %108 = getelementptr inbounds [4 x i32], [4 x i32]* %11, i64 0, i64 %106
  %109 = load i8, i8* %74, align 1
  %110 = getelementptr inbounds i8, i8* %107, i64 1
  %111 = load i8, i8* %107, align 1
  %112 = sext i8 %111 to i32
  %113 = sext i8 %109 to i32
  %114 = mul nsw i32 %112, %113
  %115 = load i32, i32* %108, align 4
  %116 = add nsw i32 %114, %115
  store i32 %116, i32* %108, align 4
  %117 = load i8, i8* %76, align 1
  %118 = getelementptr inbounds i8, i8* %107, i64 2
  %119 = load i8, i8* %110, align 1
  %120 = sext i8 %119 to i32
  %121 = sext i8 %117 to i32
  %122 = mul nsw i32 %120, %121
  %123 = add nsw i32 %122, %116
  store i32 %123, i32* %108, align 4
  %124 = load i8, i8* %78, align 1
  %125 = getelementptr inbounds i8, i8* %107, i64 3
  %126 = load i8, i8* %118, align 1
  %127 = sext i8 %126 to i32
  %128 = sext i8 %124 to i32
  %129 = mul nsw i32 %127, %128
  %130 = add nsw i32 %129, %123
  store i32 %130, i32* %108, align 4
  %131 = load i8, i8* %80, align 1
  %132 = getelementptr inbounds i8, i8* %107, i64 4
  %133 = load i8, i8* %125, align 1
  %134 = sext i8 %133 to i32
  %135 = sext i8 %131 to i32
  %136 = mul nsw i32 %134, %135
  %137 = add nsw i32 %136, %130
  store i32 %137, i32* %108, align 4
  %138 = load i8, i8* %82, align 1
  %139 = getelementptr inbounds i8, i8* %107, i64 5
  %140 = load i8, i8* %132, align 1
  %141 = sext i8 %140 to i32
  %142 = sext i8 %138 to i32
  %143 = mul nsw i32 %141, %142
  %144 = add nsw i32 %143, %137
  store i32 %144, i32* %108, align 4
  %145 = load i8, i8* %84, align 1
  %146 = getelementptr inbounds i8, i8* %107, i64 6
  %147 = load i8, i8* %139, align 1
  %148 = sext i8 %147 to i32
  %149 = sext i8 %145 to i32
  %150 = mul nsw i32 %148, %149
  %151 = add nsw i32 %150, %144
  store i32 %151, i32* %108, align 4
  %152 = load i8, i8* %86, align 1
  %153 = getelementptr inbounds i8, i8* %107, i64 7
  %154 = load i8, i8* %146, align 1
  %155 = sext i8 %154 to i32
  %156 = sext i8 %152 to i32
  %157 = mul nsw i32 %155, %156
  %158 = add nsw i32 %157, %151
  store i32 %158, i32* %108, align 4
  %159 = load i8, i8* %88, align 1
  %160 = getelementptr inbounds i8, i8* %107, i64 8
  %161 = load i8, i8* %153, align 1
  %162 = sext i8 %161 to i32
  %163 = sext i8 %159 to i32
  %164 = mul nsw i32 %162, %163
  %165 = add nsw i32 %164, %158
  store i32 %165, i32* %108, align 4
  %166 = load i8, i8* %90, align 1
  %167 = getelementptr inbounds i8, i8* %107, i64 9
  %168 = load i8, i8* %160, align 1
  %169 = sext i8 %168 to i32
  %170 = sext i8 %166 to i32
  %171 = mul nsw i32 %169, %170
  %172 = add nsw i32 %171, %165
  store i32 %172, i32* %108, align 4
  %173 = load i8, i8* %92, align 1
  %174 = getelementptr inbounds i8, i8* %107, i64 10
  %175 = load i8, i8* %167, align 1
  %176 = sext i8 %175 to i32
  %177 = sext i8 %173 to i32
  %178 = mul nsw i32 %176, %177
  %179 = add nsw i32 %178, %172
  store i32 %179, i32* %108, align 4
  %180 = load i8, i8* %94, align 1
  %181 = getelementptr inbounds i8, i8* %107, i64 11
  %182 = load i8, i8* %174, align 1
  %183 = sext i8 %182 to i32
  %184 = sext i8 %180 to i32
  %185 = mul nsw i32 %183, %184
  %186 = add nsw i32 %185, %179
  store i32 %186, i32* %108, align 4
  %187 = load i8, i8* %96, align 1
  %188 = getelementptr inbounds i8, i8* %107, i64 12
  %189 = load i8, i8* %181, align 1
  %190 = sext i8 %189 to i32
  %191 = sext i8 %187 to i32
  %192 = mul nsw i32 %190, %191
  %193 = add nsw i32 %192, %186
  store i32 %193, i32* %108, align 4
  %194 = load i8, i8* %98, align 1
  %195 = getelementptr inbounds i8, i8* %107, i64 13
  %196 = load i8, i8* %188, align 1
  %197 = sext i8 %196 to i32
  %198 = sext i8 %194 to i32
  %199 = mul nsw i32 %197, %198
  %200 = add nsw i32 %199, %193
  store i32 %200, i32* %108, align 4
  %201 = load i8, i8* %100, align 1
  %202 = getelementptr inbounds i8, i8* %107, i64 14
  %203 = load i8, i8* %195, align 1
  %204 = sext i8 %203 to i32
  %205 = sext i8 %201 to i32
  %206 = mul nsw i32 %204, %205
  %207 = add nsw i32 %206, %200
  store i32 %207, i32* %108, align 4
  %208 = load i8, i8* %102, align 1
  %209 = getelementptr inbounds i8, i8* %107, i64 15
  %210 = load i8, i8* %202, align 1
  %211 = sext i8 %210 to i32
  %212 = sext i8 %208 to i32
  %213 = mul nsw i32 %211, %212
  %214 = add nsw i32 %213, %207
  store i32 %214, i32* %108, align 4
  %215 = load i8, i8* %104, align 1
  %216 = getelementptr inbounds i8, i8* %107, i64 16
  %217 = load i8, i8* %209, align 1
  %218 = sext i8 %217 to i32
  %219 = sext i8 %215 to i32
  %220 = mul nsw i32 %218, %219
  %221 = add nsw i32 %220, %214
  store i32 %221, i32* %108, align 4
  %222 = add nuw nsw i64 %106, 1
  %223 = icmp eq i64 %222, 4
  br i1 %223, label %224, label %105

224:                                              ; preds = %105
  %225 = add nuw nsw i64 %72, 16
  %226 = icmp slt i64 %225, %52
  br i1 %226, label %71, label %61

227:                                              ; preds = %63
  %228 = sext i32 %69 to i64
  %229 = mul nsw i64 %228, %44
  br label %231

230:                                              ; preds = %63
  br i1 %45, label %238, label %231

231:                                              ; preds = %230, %227
  %232 = phi i64 [ %229, %227 ], [ %46, %230 ]
  %233 = icmp sgt i64 %232, -1
  %234 = select i1 %233, i64 1073741824, i64 -1073741823
  %235 = add nsw i64 %234, %232
  %236 = sdiv i64 %235, 2147483648
  %237 = trunc i64 %236 to i32
  br label %238

238:                                              ; preds = %230, %231
  %239 = phi i32 [ %237, %231 ], [ 2147483647, %230 ]
  %240 = and i32 %239, %50
  %241 = lshr i32 %239, 31
  %242 = add nsw i32 %241, %51
  %243 = ashr i32 %239, %41
  %244 = icmp sgt i32 %240, %242
  %245 = zext i1 %244 to i32
  %246 = add nsw i32 %243, %245
  %247 = icmp sgt i32 %246, -32768
  %248 = select i1 %247, i32 %246, i32 -32768
  %249 = icmp slt i32 %248, 32767
  %250 = select i1 %249, i32 %248, i32 32767
  %251 = trunc i32 %250 to i16
  %252 = getelementptr inbounds i16, i16* %9, i64 %59
  store i16 %251, i16* %252, align 2
  %253 = load i32, i32* %55, align 4
  %254 = or i64 %59, 1
  %255 = getelementptr inbounds i32, i32* %6, i64 %254
  %256 = load i32, i32* %255, align 4
  %257 = add nsw i32 %256, %253
  %258 = mul nsw i32 %257, %43
  %259 = icmp eq i32 %258, %7
  br i1 %259, label %907, label %904

260:                                              ; preds = %16, %868
  %261 = phi i64 [ 0, %16 ], [ %869, %868 ]
  %262 = phi i8* [ %1, %16 ], [ %264, %868 ]
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %13) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %13, i8 0, i64 64, i1 false)
  br i1 %17, label %265, label %263

263:                                              ; preds = %853, %260
  %264 = phi i8* [ %262, %260 ], [ %855, %853 ]
  br label %858

265:                                              ; preds = %260, %853
  %266 = phi i32 [ %856, %853 ], [ 0, %260 ]
  %267 = phi i8* [ %854, %853 ], [ %0, %260 ]
  %268 = phi i8* [ %855, %853 ], [ %262, %260 ]
  %269 = getelementptr inbounds i8, i8* %267, i64 48
  %270 = getelementptr inbounds i8, i8* %267, i64 1
  %271 = getelementptr inbounds i8, i8* %267, i64 2
  %272 = getelementptr inbounds i8, i8* %267, i64 3
  %273 = getelementptr inbounds i8, i8* %267, i64 4
  %274 = getelementptr inbounds i8, i8* %267, i64 5
  %275 = getelementptr inbounds i8, i8* %267, i64 6
  %276 = getelementptr inbounds i8, i8* %267, i64 7
  %277 = getelementptr inbounds i8, i8* %267, i64 8
  %278 = getelementptr inbounds i8, i8* %267, i64 9
  %279 = getelementptr inbounds i8, i8* %267, i64 10
  %280 = getelementptr inbounds i8, i8* %267, i64 11
  %281 = getelementptr inbounds i8, i8* %267, i64 12
  %282 = getelementptr inbounds i8, i8* %267, i64 13
  %283 = getelementptr inbounds i8, i8* %267, i64 14
  %284 = getelementptr inbounds i8, i8* %267, i64 15
  %285 = getelementptr inbounds i8, i8* %267, i64 16
  %286 = getelementptr inbounds i8, i8* %267, i64 17
  %287 = getelementptr inbounds i8, i8* %267, i64 18
  %288 = getelementptr inbounds i8, i8* %267, i64 19
  %289 = getelementptr inbounds i8, i8* %267, i64 20
  %290 = getelementptr inbounds i8, i8* %267, i64 21
  %291 = getelementptr inbounds i8, i8* %267, i64 22
  %292 = getelementptr inbounds i8, i8* %267, i64 23
  %293 = getelementptr inbounds i8, i8* %267, i64 24
  %294 = getelementptr inbounds i8, i8* %267, i64 25
  %295 = getelementptr inbounds i8, i8* %267, i64 26
  %296 = getelementptr inbounds i8, i8* %267, i64 27
  %297 = getelementptr inbounds i8, i8* %267, i64 28
  %298 = getelementptr inbounds i8, i8* %267, i64 29
  %299 = getelementptr inbounds i8, i8* %267, i64 30
  %300 = getelementptr inbounds i8, i8* %267, i64 31
  %301 = getelementptr inbounds i8, i8* %267, i64 32
  %302 = getelementptr inbounds i8, i8* %267, i64 33
  %303 = getelementptr inbounds i8, i8* %267, i64 34
  %304 = getelementptr inbounds i8, i8* %267, i64 35
  %305 = getelementptr inbounds i8, i8* %267, i64 36
  %306 = getelementptr inbounds i8, i8* %267, i64 37
  %307 = getelementptr inbounds i8, i8* %267, i64 38
  %308 = getelementptr inbounds i8, i8* %267, i64 39
  %309 = getelementptr inbounds i8, i8* %267, i64 40
  %310 = getelementptr inbounds i8, i8* %267, i64 41
  %311 = getelementptr inbounds i8, i8* %267, i64 42
  %312 = getelementptr inbounds i8, i8* %267, i64 43
  %313 = getelementptr inbounds i8, i8* %267, i64 44
  %314 = getelementptr inbounds i8, i8* %267, i64 45
  %315 = getelementptr inbounds i8, i8* %267, i64 46
  %316 = getelementptr inbounds i8, i8* %267, i64 47
  %317 = getelementptr inbounds i8, i8* %267, i64 49
  %318 = getelementptr inbounds i8, i8* %267, i64 50
  %319 = getelementptr inbounds i8, i8* %267, i64 51
  %320 = getelementptr inbounds i8, i8* %267, i64 52
  %321 = getelementptr inbounds i8, i8* %267, i64 53
  %322 = getelementptr inbounds i8, i8* %267, i64 54
  %323 = getelementptr inbounds i8, i8* %267, i64 55
  %324 = getelementptr inbounds i8, i8* %267, i64 56
  %325 = getelementptr inbounds i8, i8* %267, i64 57
  %326 = getelementptr inbounds i8, i8* %267, i64 58
  %327 = getelementptr inbounds i8, i8* %267, i64 59
  %328 = getelementptr inbounds i8, i8* %267, i64 60
  %329 = getelementptr inbounds i8, i8* %267, i64 61
  %330 = getelementptr inbounds i8, i8* %267, i64 62
  %331 = getelementptr inbounds i8, i8* %267, i64 63
  br label %332

332:                                              ; preds = %332, %265
  %333 = phi i64 [ 0, %265 ], [ %851, %332 ]
  %334 = shl i64 %333, 4
  %335 = getelementptr inbounds [4 x [4 x i32]], [4 x [4 x i32]]* %12, i64 0, i64 %333, i64 0
  %336 = load i32, i32* %335, align 16
  %337 = load i8, i8* %267, align 1
  %338 = getelementptr inbounds i8, i8* %268, i64 %334
  %339 = load i8, i8* %338, align 1
  %340 = sext i8 %339 to i32
  %341 = sext i8 %337 to i32
  %342 = mul nsw i32 %340, %341
  %343 = add nsw i32 %342, %336
  store i32 %343, i32* %335, align 16
  %344 = load i8, i8* %270, align 1
  %345 = or i64 %334, 1
  %346 = getelementptr inbounds i8, i8* %268, i64 %345
  %347 = load i8, i8* %346, align 1
  %348 = sext i8 %347 to i32
  %349 = sext i8 %344 to i32
  %350 = mul nsw i32 %348, %349
  %351 = add nsw i32 %350, %343
  store i32 %351, i32* %335, align 16
  %352 = load i8, i8* %271, align 1
  %353 = or i64 %334, 2
  %354 = getelementptr inbounds i8, i8* %268, i64 %353
  %355 = load i8, i8* %354, align 1
  %356 = sext i8 %355 to i32
  %357 = sext i8 %352 to i32
  %358 = mul nsw i32 %356, %357
  %359 = add nsw i32 %358, %351
  store i32 %359, i32* %335, align 16
  %360 = load i8, i8* %272, align 1
  %361 = or i64 %334, 3
  %362 = getelementptr inbounds i8, i8* %268, i64 %361
  %363 = load i8, i8* %362, align 1
  %364 = sext i8 %363 to i32
  %365 = sext i8 %360 to i32
  %366 = mul nsw i32 %364, %365
  %367 = add nsw i32 %366, %359
  store i32 %367, i32* %335, align 16
  %368 = load i8, i8* %273, align 1
  %369 = or i64 %334, 4
  %370 = getelementptr inbounds i8, i8* %268, i64 %369
  %371 = load i8, i8* %370, align 1
  %372 = sext i8 %371 to i32
  %373 = sext i8 %368 to i32
  %374 = mul nsw i32 %372, %373
  %375 = add nsw i32 %374, %367
  store i32 %375, i32* %335, align 16
  %376 = load i8, i8* %274, align 1
  %377 = or i64 %334, 5
  %378 = getelementptr inbounds i8, i8* %268, i64 %377
  %379 = load i8, i8* %378, align 1
  %380 = sext i8 %379 to i32
  %381 = sext i8 %376 to i32
  %382 = mul nsw i32 %380, %381
  %383 = add nsw i32 %382, %375
  store i32 %383, i32* %335, align 16
  %384 = load i8, i8* %275, align 1
  %385 = or i64 %334, 6
  %386 = getelementptr inbounds i8, i8* %268, i64 %385
  %387 = load i8, i8* %386, align 1
  %388 = sext i8 %387 to i32
  %389 = sext i8 %384 to i32
  %390 = mul nsw i32 %388, %389
  %391 = add nsw i32 %390, %383
  store i32 %391, i32* %335, align 16
  %392 = load i8, i8* %276, align 1
  %393 = or i64 %334, 7
  %394 = getelementptr inbounds i8, i8* %268, i64 %393
  %395 = load i8, i8* %394, align 1
  %396 = sext i8 %395 to i32
  %397 = sext i8 %392 to i32
  %398 = mul nsw i32 %396, %397
  %399 = add nsw i32 %398, %391
  store i32 %399, i32* %335, align 16
  %400 = load i8, i8* %277, align 1
  %401 = or i64 %334, 8
  %402 = getelementptr inbounds i8, i8* %268, i64 %401
  %403 = load i8, i8* %402, align 1
  %404 = sext i8 %403 to i32
  %405 = sext i8 %400 to i32
  %406 = mul nsw i32 %404, %405
  %407 = add nsw i32 %406, %399
  store i32 %407, i32* %335, align 16
  %408 = load i8, i8* %278, align 1
  %409 = or i64 %334, 9
  %410 = getelementptr inbounds i8, i8* %268, i64 %409
  %411 = load i8, i8* %410, align 1
  %412 = sext i8 %411 to i32
  %413 = sext i8 %408 to i32
  %414 = mul nsw i32 %412, %413
  %415 = add nsw i32 %414, %407
  store i32 %415, i32* %335, align 16
  %416 = load i8, i8* %279, align 1
  %417 = or i64 %334, 10
  %418 = getelementptr inbounds i8, i8* %268, i64 %417
  %419 = load i8, i8* %418, align 1
  %420 = sext i8 %419 to i32
  %421 = sext i8 %416 to i32
  %422 = mul nsw i32 %420, %421
  %423 = add nsw i32 %422, %415
  store i32 %423, i32* %335, align 16
  %424 = load i8, i8* %280, align 1
  %425 = or i64 %334, 11
  %426 = getelementptr inbounds i8, i8* %268, i64 %425
  %427 = load i8, i8* %426, align 1
  %428 = sext i8 %427 to i32
  %429 = sext i8 %424 to i32
  %430 = mul nsw i32 %428, %429
  %431 = add nsw i32 %430, %423
  store i32 %431, i32* %335, align 16
  %432 = load i8, i8* %281, align 1
  %433 = or i64 %334, 12
  %434 = getelementptr inbounds i8, i8* %268, i64 %433
  %435 = load i8, i8* %434, align 1
  %436 = sext i8 %435 to i32
  %437 = sext i8 %432 to i32
  %438 = mul nsw i32 %436, %437
  %439 = add nsw i32 %438, %431
  store i32 %439, i32* %335, align 16
  %440 = load i8, i8* %282, align 1
  %441 = or i64 %334, 13
  %442 = getelementptr inbounds i8, i8* %268, i64 %441
  %443 = load i8, i8* %442, align 1
  %444 = sext i8 %443 to i32
  %445 = sext i8 %440 to i32
  %446 = mul nsw i32 %444, %445
  %447 = add nsw i32 %446, %439
  store i32 %447, i32* %335, align 16
  %448 = load i8, i8* %283, align 1
  %449 = or i64 %334, 14
  %450 = getelementptr inbounds i8, i8* %268, i64 %449
  %451 = load i8, i8* %450, align 1
  %452 = sext i8 %451 to i32
  %453 = sext i8 %448 to i32
  %454 = mul nsw i32 %452, %453
  %455 = add nsw i32 %454, %447
  store i32 %455, i32* %335, align 16
  %456 = load i8, i8* %284, align 1
  %457 = or i64 %334, 15
  %458 = getelementptr inbounds i8, i8* %268, i64 %457
  %459 = load i8, i8* %458, align 1
  %460 = sext i8 %459 to i32
  %461 = sext i8 %456 to i32
  %462 = mul nsw i32 %460, %461
  %463 = add nsw i32 %462, %455
  store i32 %463, i32* %335, align 16
  %464 = getelementptr inbounds [4 x [4 x i32]], [4 x [4 x i32]]* %12, i64 0, i64 %333, i64 1
  %465 = load i32, i32* %464, align 4
  %466 = load i8, i8* %285, align 1
  %467 = getelementptr inbounds i8, i8* %268, i64 %334
  %468 = load i8, i8* %467, align 1
  %469 = sext i8 %468 to i32
  %470 = sext i8 %466 to i32
  %471 = mul nsw i32 %469, %470
  %472 = add nsw i32 %471, %465
  store i32 %472, i32* %464, align 4
  %473 = load i8, i8* %286, align 1
  %474 = or i64 %334, 1
  %475 = getelementptr inbounds i8, i8* %268, i64 %474
  %476 = load i8, i8* %475, align 1
  %477 = sext i8 %476 to i32
  %478 = sext i8 %473 to i32
  %479 = mul nsw i32 %477, %478
  %480 = add nsw i32 %479, %472
  store i32 %480, i32* %464, align 4
  %481 = load i8, i8* %287, align 1
  %482 = or i64 %334, 2
  %483 = getelementptr inbounds i8, i8* %268, i64 %482
  %484 = load i8, i8* %483, align 1
  %485 = sext i8 %484 to i32
  %486 = sext i8 %481 to i32
  %487 = mul nsw i32 %485, %486
  %488 = add nsw i32 %487, %480
  store i32 %488, i32* %464, align 4
  %489 = load i8, i8* %288, align 1
  %490 = or i64 %334, 3
  %491 = getelementptr inbounds i8, i8* %268, i64 %490
  %492 = load i8, i8* %491, align 1
  %493 = sext i8 %492 to i32
  %494 = sext i8 %489 to i32
  %495 = mul nsw i32 %493, %494
  %496 = add nsw i32 %495, %488
  store i32 %496, i32* %464, align 4
  %497 = load i8, i8* %289, align 1
  %498 = or i64 %334, 4
  %499 = getelementptr inbounds i8, i8* %268, i64 %498
  %500 = load i8, i8* %499, align 1
  %501 = sext i8 %500 to i32
  %502 = sext i8 %497 to i32
  %503 = mul nsw i32 %501, %502
  %504 = add nsw i32 %503, %496
  store i32 %504, i32* %464, align 4
  %505 = load i8, i8* %290, align 1
  %506 = or i64 %334, 5
  %507 = getelementptr inbounds i8, i8* %268, i64 %506
  %508 = load i8, i8* %507, align 1
  %509 = sext i8 %508 to i32
  %510 = sext i8 %505 to i32
  %511 = mul nsw i32 %509, %510
  %512 = add nsw i32 %511, %504
  store i32 %512, i32* %464, align 4
  %513 = load i8, i8* %291, align 1
  %514 = or i64 %334, 6
  %515 = getelementptr inbounds i8, i8* %268, i64 %514
  %516 = load i8, i8* %515, align 1
  %517 = sext i8 %516 to i32
  %518 = sext i8 %513 to i32
  %519 = mul nsw i32 %517, %518
  %520 = add nsw i32 %519, %512
  store i32 %520, i32* %464, align 4
  %521 = load i8, i8* %292, align 1
  %522 = or i64 %334, 7
  %523 = getelementptr inbounds i8, i8* %268, i64 %522
  %524 = load i8, i8* %523, align 1
  %525 = sext i8 %524 to i32
  %526 = sext i8 %521 to i32
  %527 = mul nsw i32 %525, %526
  %528 = add nsw i32 %527, %520
  store i32 %528, i32* %464, align 4
  %529 = load i8, i8* %293, align 1
  %530 = or i64 %334, 8
  %531 = getelementptr inbounds i8, i8* %268, i64 %530
  %532 = load i8, i8* %531, align 1
  %533 = sext i8 %532 to i32
  %534 = sext i8 %529 to i32
  %535 = mul nsw i32 %533, %534
  %536 = add nsw i32 %535, %528
  store i32 %536, i32* %464, align 4
  %537 = load i8, i8* %294, align 1
  %538 = or i64 %334, 9
  %539 = getelementptr inbounds i8, i8* %268, i64 %538
  %540 = load i8, i8* %539, align 1
  %541 = sext i8 %540 to i32
  %542 = sext i8 %537 to i32
  %543 = mul nsw i32 %541, %542
  %544 = add nsw i32 %543, %536
  store i32 %544, i32* %464, align 4
  %545 = load i8, i8* %295, align 1
  %546 = or i64 %334, 10
  %547 = getelementptr inbounds i8, i8* %268, i64 %546
  %548 = load i8, i8* %547, align 1
  %549 = sext i8 %548 to i32
  %550 = sext i8 %545 to i32
  %551 = mul nsw i32 %549, %550
  %552 = add nsw i32 %551, %544
  store i32 %552, i32* %464, align 4
  %553 = load i8, i8* %296, align 1
  %554 = or i64 %334, 11
  %555 = getelementptr inbounds i8, i8* %268, i64 %554
  %556 = load i8, i8* %555, align 1
  %557 = sext i8 %556 to i32
  %558 = sext i8 %553 to i32
  %559 = mul nsw i32 %557, %558
  %560 = add nsw i32 %559, %552
  store i32 %560, i32* %464, align 4
  %561 = load i8, i8* %297, align 1
  %562 = or i64 %334, 12
  %563 = getelementptr inbounds i8, i8* %268, i64 %562
  %564 = load i8, i8* %563, align 1
  %565 = sext i8 %564 to i32
  %566 = sext i8 %561 to i32
  %567 = mul nsw i32 %565, %566
  %568 = add nsw i32 %567, %560
  store i32 %568, i32* %464, align 4
  %569 = load i8, i8* %298, align 1
  %570 = or i64 %334, 13
  %571 = getelementptr inbounds i8, i8* %268, i64 %570
  %572 = load i8, i8* %571, align 1
  %573 = sext i8 %572 to i32
  %574 = sext i8 %569 to i32
  %575 = mul nsw i32 %573, %574
  %576 = add nsw i32 %575, %568
  store i32 %576, i32* %464, align 4
  %577 = load i8, i8* %299, align 1
  %578 = or i64 %334, 14
  %579 = getelementptr inbounds i8, i8* %268, i64 %578
  %580 = load i8, i8* %579, align 1
  %581 = sext i8 %580 to i32
  %582 = sext i8 %577 to i32
  %583 = mul nsw i32 %581, %582
  %584 = add nsw i32 %583, %576
  store i32 %584, i32* %464, align 4
  %585 = load i8, i8* %300, align 1
  %586 = or i64 %334, 15
  %587 = getelementptr inbounds i8, i8* %268, i64 %586
  %588 = load i8, i8* %587, align 1
  %589 = sext i8 %588 to i32
  %590 = sext i8 %585 to i32
  %591 = mul nsw i32 %589, %590
  %592 = add nsw i32 %591, %584
  store i32 %592, i32* %464, align 4
  %593 = getelementptr inbounds [4 x [4 x i32]], [4 x [4 x i32]]* %12, i64 0, i64 %333, i64 2
  %594 = load i32, i32* %593, align 8
  %595 = load i8, i8* %301, align 1
  %596 = getelementptr inbounds i8, i8* %268, i64 %334
  %597 = load i8, i8* %596, align 1
  %598 = sext i8 %597 to i32
  %599 = sext i8 %595 to i32
  %600 = mul nsw i32 %598, %599
  %601 = add nsw i32 %600, %594
  store i32 %601, i32* %593, align 8
  %602 = load i8, i8* %302, align 1
  %603 = or i64 %334, 1
  %604 = getelementptr inbounds i8, i8* %268, i64 %603
  %605 = load i8, i8* %604, align 1
  %606 = sext i8 %605 to i32
  %607 = sext i8 %602 to i32
  %608 = mul nsw i32 %606, %607
  %609 = add nsw i32 %608, %601
  store i32 %609, i32* %593, align 8
  %610 = load i8, i8* %303, align 1
  %611 = or i64 %334, 2
  %612 = getelementptr inbounds i8, i8* %268, i64 %611
  %613 = load i8, i8* %612, align 1
  %614 = sext i8 %613 to i32
  %615 = sext i8 %610 to i32
  %616 = mul nsw i32 %614, %615
  %617 = add nsw i32 %616, %609
  store i32 %617, i32* %593, align 8
  %618 = load i8, i8* %304, align 1
  %619 = or i64 %334, 3
  %620 = getelementptr inbounds i8, i8* %268, i64 %619
  %621 = load i8, i8* %620, align 1
  %622 = sext i8 %621 to i32
  %623 = sext i8 %618 to i32
  %624 = mul nsw i32 %622, %623
  %625 = add nsw i32 %624, %617
  store i32 %625, i32* %593, align 8
  %626 = load i8, i8* %305, align 1
  %627 = or i64 %334, 4
  %628 = getelementptr inbounds i8, i8* %268, i64 %627
  %629 = load i8, i8* %628, align 1
  %630 = sext i8 %629 to i32
  %631 = sext i8 %626 to i32
  %632 = mul nsw i32 %630, %631
  %633 = add nsw i32 %632, %625
  store i32 %633, i32* %593, align 8
  %634 = load i8, i8* %306, align 1
  %635 = or i64 %334, 5
  %636 = getelementptr inbounds i8, i8* %268, i64 %635
  %637 = load i8, i8* %636, align 1
  %638 = sext i8 %637 to i32
  %639 = sext i8 %634 to i32
  %640 = mul nsw i32 %638, %639
  %641 = add nsw i32 %640, %633
  store i32 %641, i32* %593, align 8
  %642 = load i8, i8* %307, align 1
  %643 = or i64 %334, 6
  %644 = getelementptr inbounds i8, i8* %268, i64 %643
  %645 = load i8, i8* %644, align 1
  %646 = sext i8 %645 to i32
  %647 = sext i8 %642 to i32
  %648 = mul nsw i32 %646, %647
  %649 = add nsw i32 %648, %641
  store i32 %649, i32* %593, align 8
  %650 = load i8, i8* %308, align 1
  %651 = or i64 %334, 7
  %652 = getelementptr inbounds i8, i8* %268, i64 %651
  %653 = load i8, i8* %652, align 1
  %654 = sext i8 %653 to i32
  %655 = sext i8 %650 to i32
  %656 = mul nsw i32 %654, %655
  %657 = add nsw i32 %656, %649
  store i32 %657, i32* %593, align 8
  %658 = load i8, i8* %309, align 1
  %659 = or i64 %334, 8
  %660 = getelementptr inbounds i8, i8* %268, i64 %659
  %661 = load i8, i8* %660, align 1
  %662 = sext i8 %661 to i32
  %663 = sext i8 %658 to i32
  %664 = mul nsw i32 %662, %663
  %665 = add nsw i32 %664, %657
  store i32 %665, i32* %593, align 8
  %666 = load i8, i8* %310, align 1
  %667 = or i64 %334, 9
  %668 = getelementptr inbounds i8, i8* %268, i64 %667
  %669 = load i8, i8* %668, align 1
  %670 = sext i8 %669 to i32
  %671 = sext i8 %666 to i32
  %672 = mul nsw i32 %670, %671
  %673 = add nsw i32 %672, %665
  store i32 %673, i32* %593, align 8
  %674 = load i8, i8* %311, align 1
  %675 = or i64 %334, 10
  %676 = getelementptr inbounds i8, i8* %268, i64 %675
  %677 = load i8, i8* %676, align 1
  %678 = sext i8 %677 to i32
  %679 = sext i8 %674 to i32
  %680 = mul nsw i32 %678, %679
  %681 = add nsw i32 %680, %673
  store i32 %681, i32* %593, align 8
  %682 = load i8, i8* %312, align 1
  %683 = or i64 %334, 11
  %684 = getelementptr inbounds i8, i8* %268, i64 %683
  %685 = load i8, i8* %684, align 1
  %686 = sext i8 %685 to i32
  %687 = sext i8 %682 to i32
  %688 = mul nsw i32 %686, %687
  %689 = add nsw i32 %688, %681
  store i32 %689, i32* %593, align 8
  %690 = load i8, i8* %313, align 1
  %691 = or i64 %334, 12
  %692 = getelementptr inbounds i8, i8* %268, i64 %691
  %693 = load i8, i8* %692, align 1
  %694 = sext i8 %693 to i32
  %695 = sext i8 %690 to i32
  %696 = mul nsw i32 %694, %695
  %697 = add nsw i32 %696, %689
  store i32 %697, i32* %593, align 8
  %698 = load i8, i8* %314, align 1
  %699 = or i64 %334, 13
  %700 = getelementptr inbounds i8, i8* %268, i64 %699
  %701 = load i8, i8* %700, align 1
  %702 = sext i8 %701 to i32
  %703 = sext i8 %698 to i32
  %704 = mul nsw i32 %702, %703
  %705 = add nsw i32 %704, %697
  store i32 %705, i32* %593, align 8
  %706 = load i8, i8* %315, align 1
  %707 = or i64 %334, 14
  %708 = getelementptr inbounds i8, i8* %268, i64 %707
  %709 = load i8, i8* %708, align 1
  %710 = sext i8 %709 to i32
  %711 = sext i8 %706 to i32
  %712 = mul nsw i32 %710, %711
  %713 = add nsw i32 %712, %705
  store i32 %713, i32* %593, align 8
  %714 = load i8, i8* %316, align 1
  %715 = or i64 %334, 15
  %716 = getelementptr inbounds i8, i8* %268, i64 %715
  %717 = load i8, i8* %716, align 1
  %718 = sext i8 %717 to i32
  %719 = sext i8 %714 to i32
  %720 = mul nsw i32 %718, %719
  %721 = add nsw i32 %720, %713
  store i32 %721, i32* %593, align 8
  %722 = getelementptr inbounds [4 x [4 x i32]], [4 x [4 x i32]]* %12, i64 0, i64 %333, i64 3
  %723 = load i32, i32* %722, align 4
  %724 = load i8, i8* %269, align 1
  %725 = getelementptr inbounds i8, i8* %268, i64 %334
  %726 = load i8, i8* %725, align 1
  %727 = sext i8 %726 to i32
  %728 = sext i8 %724 to i32
  %729 = mul nsw i32 %727, %728
  %730 = add nsw i32 %729, %723
  store i32 %730, i32* %722, align 4
  %731 = load i8, i8* %317, align 1
  %732 = or i64 %334, 1
  %733 = getelementptr inbounds i8, i8* %268, i64 %732
  %734 = load i8, i8* %733, align 1
  %735 = sext i8 %734 to i32
  %736 = sext i8 %731 to i32
  %737 = mul nsw i32 %735, %736
  %738 = add nsw i32 %737, %730
  store i32 %738, i32* %722, align 4
  %739 = load i8, i8* %318, align 1
  %740 = or i64 %334, 2
  %741 = getelementptr inbounds i8, i8* %268, i64 %740
  %742 = load i8, i8* %741, align 1
  %743 = sext i8 %742 to i32
  %744 = sext i8 %739 to i32
  %745 = mul nsw i32 %743, %744
  %746 = add nsw i32 %745, %738
  store i32 %746, i32* %722, align 4
  %747 = load i8, i8* %319, align 1
  %748 = or i64 %334, 3
  %749 = getelementptr inbounds i8, i8* %268, i64 %748
  %750 = load i8, i8* %749, align 1
  %751 = sext i8 %750 to i32
  %752 = sext i8 %747 to i32
  %753 = mul nsw i32 %751, %752
  %754 = add nsw i32 %753, %746
  store i32 %754, i32* %722, align 4
  %755 = load i8, i8* %320, align 1
  %756 = or i64 %334, 4
  %757 = getelementptr inbounds i8, i8* %268, i64 %756
  %758 = load i8, i8* %757, align 1
  %759 = sext i8 %758 to i32
  %760 = sext i8 %755 to i32
  %761 = mul nsw i32 %759, %760
  %762 = add nsw i32 %761, %754
  store i32 %762, i32* %722, align 4
  %763 = load i8, i8* %321, align 1
  %764 = or i64 %334, 5
  %765 = getelementptr inbounds i8, i8* %268, i64 %764
  %766 = load i8, i8* %765, align 1
  %767 = sext i8 %766 to i32
  %768 = sext i8 %763 to i32
  %769 = mul nsw i32 %767, %768
  %770 = add nsw i32 %769, %762
  store i32 %770, i32* %722, align 4
  %771 = load i8, i8* %322, align 1
  %772 = or i64 %334, 6
  %773 = getelementptr inbounds i8, i8* %268, i64 %772
  %774 = load i8, i8* %773, align 1
  %775 = sext i8 %774 to i32
  %776 = sext i8 %771 to i32
  %777 = mul nsw i32 %775, %776
  %778 = add nsw i32 %777, %770
  store i32 %778, i32* %722, align 4
  %779 = load i8, i8* %323, align 1
  %780 = or i64 %334, 7
  %781 = getelementptr inbounds i8, i8* %268, i64 %780
  %782 = load i8, i8* %781, align 1
  %783 = sext i8 %782 to i32
  %784 = sext i8 %779 to i32
  %785 = mul nsw i32 %783, %784
  %786 = add nsw i32 %785, %778
  store i32 %786, i32* %722, align 4
  %787 = load i8, i8* %324, align 1
  %788 = or i64 %334, 8
  %789 = getelementptr inbounds i8, i8* %268, i64 %788
  %790 = load i8, i8* %789, align 1
  %791 = sext i8 %790 to i32
  %792 = sext i8 %787 to i32
  %793 = mul nsw i32 %791, %792
  %794 = add nsw i32 %793, %786
  store i32 %794, i32* %722, align 4
  %795 = load i8, i8* %325, align 1
  %796 = or i64 %334, 9
  %797 = getelementptr inbounds i8, i8* %268, i64 %796
  %798 = load i8, i8* %797, align 1
  %799 = sext i8 %798 to i32
  %800 = sext i8 %795 to i32
  %801 = mul nsw i32 %799, %800
  %802 = add nsw i32 %801, %794
  store i32 %802, i32* %722, align 4
  %803 = load i8, i8* %326, align 1
  %804 = or i64 %334, 10
  %805 = getelementptr inbounds i8, i8* %268, i64 %804
  %806 = load i8, i8* %805, align 1
  %807 = sext i8 %806 to i32
  %808 = sext i8 %803 to i32
  %809 = mul nsw i32 %807, %808
  %810 = add nsw i32 %809, %802
  store i32 %810, i32* %722, align 4
  %811 = load i8, i8* %327, align 1
  %812 = or i64 %334, 11
  %813 = getelementptr inbounds i8, i8* %268, i64 %812
  %814 = load i8, i8* %813, align 1
  %815 = sext i8 %814 to i32
  %816 = sext i8 %811 to i32
  %817 = mul nsw i32 %815, %816
  %818 = add nsw i32 %817, %810
  store i32 %818, i32* %722, align 4
  %819 = load i8, i8* %328, align 1
  %820 = or i64 %334, 12
  %821 = getelementptr inbounds i8, i8* %268, i64 %820
  %822 = load i8, i8* %821, align 1
  %823 = sext i8 %822 to i32
  %824 = sext i8 %819 to i32
  %825 = mul nsw i32 %823, %824
  %826 = add nsw i32 %825, %818
  store i32 %826, i32* %722, align 4
  %827 = load i8, i8* %329, align 1
  %828 = or i64 %334, 13
  %829 = getelementptr inbounds i8, i8* %268, i64 %828
  %830 = load i8, i8* %829, align 1
  %831 = sext i8 %830 to i32
  %832 = sext i8 %827 to i32
  %833 = mul nsw i32 %831, %832
  %834 = add nsw i32 %833, %826
  store i32 %834, i32* %722, align 4
  %835 = load i8, i8* %330, align 1
  %836 = or i64 %334, 14
  %837 = getelementptr inbounds i8, i8* %268, i64 %836
  %838 = load i8, i8* %837, align 1
  %839 = sext i8 %838 to i32
  %840 = sext i8 %835 to i32
  %841 = mul nsw i32 %839, %840
  %842 = add nsw i32 %841, %834
  store i32 %842, i32* %722, align 4
  %843 = load i8, i8* %331, align 1
  %844 = or i64 %334, 15
  %845 = getelementptr inbounds i8, i8* %268, i64 %844
  %846 = load i8, i8* %845, align 1
  %847 = sext i8 %846 to i32
  %848 = sext i8 %843 to i32
  %849 = mul nsw i32 %847, %848
  %850 = add nsw i32 %849, %842
  store i32 %850, i32* %722, align 4
  %851 = add nuw nsw i64 %333, 1
  %852 = icmp eq i64 %851, 4
  br i1 %852, label %853, label %332

853:                                              ; preds = %332
  %854 = getelementptr inbounds i8, i8* %267, i64 64
  %855 = getelementptr inbounds i8, i8* %268, i64 64
  %856 = add nuw nsw i32 %266, 16
  %857 = icmp slt i32 %856, %5
  br i1 %857, label %265, label %263

858:                                              ; preds = %1078, %263
  %859 = phi i64 [ 0, %263 ], [ %1095, %1078 ]
  %860 = add nuw nsw i64 %859, %261
  %861 = getelementptr inbounds i32, i32* %6, i64 %860
  %862 = getelementptr inbounds [4 x [4 x i32]], [4 x [4 x i32]]* %12, i64 0, i64 %859, i64 0
  %863 = load i32, i32* %862, align 16
  %864 = load i32, i32* %861, align 4
  %865 = add nsw i32 %864, %863
  %866 = mul nsw i32 %865, %22
  %867 = icmp eq i32 %866, %7
  br i1 %867, label %874, label %871

868:                                              ; preds = %1078
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %13) #19
  %869 = add nuw nsw i64 %261, 4
  %870 = icmp slt i64 %869, %31
  br i1 %870, label %260, label %903

871:                                              ; preds = %858
  %872 = sext i32 %866 to i64
  %873 = mul nsw i64 %872, %23
  br label %875

874:                                              ; preds = %858
  br i1 %24, label %882, label %875

875:                                              ; preds = %874, %871
  %876 = phi i64 [ %873, %871 ], [ %25, %874 ]
  %877 = icmp sgt i64 %876, -1
  %878 = select i1 %877, i64 1073741824, i64 -1073741823
  %879 = add nsw i64 %878, %876
  %880 = sdiv i64 %879, 2147483648
  %881 = trunc i64 %880 to i32
  br label %882

882:                                              ; preds = %874, %875
  %883 = phi i32 [ %881, %875 ], [ 2147483647, %874 ]
  %884 = and i32 %883, %29
  %885 = lshr i32 %883, 31
  %886 = add nsw i32 %885, %30
  %887 = ashr i32 %883, %20
  %888 = icmp sgt i32 %884, %886
  %889 = zext i1 %888 to i32
  %890 = add nsw i32 %887, %889
  %891 = icmp sgt i32 %890, -32768
  %892 = select i1 %891, i32 %890, i32 -32768
  %893 = icmp slt i32 %892, 32767
  %894 = select i1 %893, i32 %892, i32 32767
  %895 = trunc i32 %894 to i16
  %896 = getelementptr inbounds i16, i16* %9, i64 %860
  store i16 %895, i16* %896, align 2
  %897 = getelementptr inbounds [4 x [4 x i32]], [4 x [4 x i32]]* %12, i64 0, i64 %859, i64 1
  %898 = load i32, i32* %897, align 4
  %899 = load i32, i32* %861, align 4
  %900 = add nsw i32 %899, %898
  %901 = mul nsw i32 %900, %22
  %902 = icmp eq i32 %901, %7
  br i1 %902, label %1001, label %998

903:                                              ; preds = %868, %981, %14, %34, %10
  ret void

904:                                              ; preds = %238
  %905 = sext i32 %258 to i64
  %906 = mul nsw i64 %905, %44
  br label %908

907:                                              ; preds = %238
  br i1 %45, label %915, label %908

908:                                              ; preds = %907, %904
  %909 = phi i64 [ %906, %904 ], [ %46, %907 ]
  %910 = icmp sgt i64 %909, -1
  %911 = select i1 %910, i64 1073741824, i64 -1073741823
  %912 = add nsw i64 %911, %909
  %913 = sdiv i64 %912, 2147483648
  %914 = trunc i64 %913 to i32
  br label %915

915:                                              ; preds = %908, %907
  %916 = phi i32 [ %914, %908 ], [ 2147483647, %907 ]
  %917 = and i32 %916, %50
  %918 = lshr i32 %916, 31
  %919 = add nsw i32 %918, %51
  %920 = ashr i32 %916, %41
  %921 = icmp sgt i32 %917, %919
  %922 = zext i1 %921 to i32
  %923 = add nsw i32 %920, %922
  %924 = icmp sgt i32 %923, -32768
  %925 = select i1 %924, i32 %923, i32 -32768
  %926 = icmp slt i32 %925, 32767
  %927 = select i1 %926, i32 %925, i32 32767
  %928 = trunc i32 %927 to i16
  %929 = getelementptr inbounds i16, i16* %9, i64 %254
  store i16 %928, i16* %929, align 2
  %930 = load i32, i32* %56, align 8
  %931 = or i64 %59, 2
  %932 = getelementptr inbounds i32, i32* %6, i64 %931
  %933 = load i32, i32* %932, align 4
  %934 = add nsw i32 %933, %930
  %935 = mul nsw i32 %934, %43
  %936 = icmp eq i32 %935, %7
  br i1 %936, label %940, label %937

937:                                              ; preds = %915
  %938 = sext i32 %935 to i64
  %939 = mul nsw i64 %938, %44
  br label %941

940:                                              ; preds = %915
  br i1 %45, label %948, label %941

941:                                              ; preds = %940, %937
  %942 = phi i64 [ %939, %937 ], [ %46, %940 ]
  %943 = icmp sgt i64 %942, -1
  %944 = select i1 %943, i64 1073741824, i64 -1073741823
  %945 = add nsw i64 %944, %942
  %946 = sdiv i64 %945, 2147483648
  %947 = trunc i64 %946 to i32
  br label %948

948:                                              ; preds = %941, %940
  %949 = phi i32 [ %947, %941 ], [ 2147483647, %940 ]
  %950 = and i32 %949, %50
  %951 = lshr i32 %949, 31
  %952 = add nsw i32 %951, %51
  %953 = ashr i32 %949, %41
  %954 = icmp sgt i32 %950, %952
  %955 = zext i1 %954 to i32
  %956 = add nsw i32 %953, %955
  %957 = icmp sgt i32 %956, -32768
  %958 = select i1 %957, i32 %956, i32 -32768
  %959 = icmp slt i32 %958, 32767
  %960 = select i1 %959, i32 %958, i32 32767
  %961 = trunc i32 %960 to i16
  %962 = getelementptr inbounds i16, i16* %9, i64 %931
  store i16 %961, i16* %962, align 2
  %963 = load i32, i32* %57, align 4
  %964 = or i64 %59, 3
  %965 = getelementptr inbounds i32, i32* %6, i64 %964
  %966 = load i32, i32* %965, align 4
  %967 = add nsw i32 %966, %963
  %968 = mul nsw i32 %967, %43
  %969 = icmp eq i32 %968, %7
  br i1 %969, label %973, label %970

970:                                              ; preds = %948
  %971 = sext i32 %968 to i64
  %972 = mul nsw i64 %971, %44
  br label %974

973:                                              ; preds = %948
  br i1 %45, label %981, label %974

974:                                              ; preds = %973, %970
  %975 = phi i64 [ %972, %970 ], [ %46, %973 ]
  %976 = icmp sgt i64 %975, -1
  %977 = select i1 %976, i64 1073741824, i64 -1073741823
  %978 = add nsw i64 %977, %975
  %979 = sdiv i64 %978, 2147483648
  %980 = trunc i64 %979 to i32
  br label %981

981:                                              ; preds = %974, %973
  %982 = phi i32 [ %980, %974 ], [ 2147483647, %973 ]
  %983 = and i32 %982, %50
  %984 = lshr i32 %982, 31
  %985 = add nsw i32 %984, %51
  %986 = ashr i32 %982, %41
  %987 = icmp sgt i32 %983, %985
  %988 = zext i1 %987 to i32
  %989 = add nsw i32 %986, %988
  %990 = icmp sgt i32 %989, -32768
  %991 = select i1 %990, i32 %989, i32 -32768
  %992 = icmp slt i32 %991, 32767
  %993 = select i1 %992, i32 %991, i32 32767
  %994 = trunc i32 %993 to i16
  %995 = getelementptr inbounds i16, i16* %9, i64 %964
  store i16 %994, i16* %995, align 2
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %37) #19
  %996 = add nuw nsw i64 %59, 4
  %997 = icmp slt i64 %996, %53
  br i1 %997, label %58, label %903

998:                                              ; preds = %882
  %999 = sext i32 %901 to i64
  %1000 = mul nsw i64 %999, %23
  br label %1002

1001:                                             ; preds = %882
  br i1 %24, label %1009, label %1002

1002:                                             ; preds = %1001, %998
  %1003 = phi i64 [ %1000, %998 ], [ %25, %1001 ]
  %1004 = icmp sgt i64 %1003, -1
  %1005 = select i1 %1004, i64 1073741824, i64 -1073741823
  %1006 = add nsw i64 %1005, %1003
  %1007 = sdiv i64 %1006, 2147483648
  %1008 = trunc i64 %1007 to i32
  br label %1009

1009:                                             ; preds = %1002, %1001
  %1010 = phi i32 [ %1008, %1002 ], [ 2147483647, %1001 ]
  %1011 = and i32 %1010, %29
  %1012 = lshr i32 %1010, 31
  %1013 = add nsw i32 %1012, %30
  %1014 = ashr i32 %1010, %20
  %1015 = icmp sgt i32 %1011, %1013
  %1016 = zext i1 %1015 to i32
  %1017 = add nsw i32 %1014, %1016
  %1018 = icmp sgt i32 %1017, -32768
  %1019 = select i1 %1018, i32 %1017, i32 -32768
  %1020 = icmp slt i32 %1019, 32767
  %1021 = select i1 %1020, i32 %1019, i32 32767
  %1022 = trunc i32 %1021 to i16
  %1023 = trunc i64 %860 to i32
  %1024 = add i32 %1023, %4
  %1025 = sext i32 %1024 to i64
  %1026 = getelementptr inbounds i16, i16* %9, i64 %1025
  store i16 %1022, i16* %1026, align 2
  %1027 = getelementptr inbounds [4 x [4 x i32]], [4 x [4 x i32]]* %12, i64 0, i64 %859, i64 2
  %1028 = load i32, i32* %1027, align 8
  %1029 = load i32, i32* %861, align 4
  %1030 = add nsw i32 %1029, %1028
  %1031 = mul nsw i32 %1030, %22
  %1032 = icmp eq i32 %1031, %7
  br i1 %1032, label %1036, label %1033

1033:                                             ; preds = %1009
  %1034 = sext i32 %1031 to i64
  %1035 = mul nsw i64 %1034, %23
  br label %1037

1036:                                             ; preds = %1009
  br i1 %24, label %1044, label %1037

1037:                                             ; preds = %1036, %1033
  %1038 = phi i64 [ %1035, %1033 ], [ %25, %1036 ]
  %1039 = icmp sgt i64 %1038, -1
  %1040 = select i1 %1039, i64 1073741824, i64 -1073741823
  %1041 = add nsw i64 %1040, %1038
  %1042 = sdiv i64 %1041, 2147483648
  %1043 = trunc i64 %1042 to i32
  br label %1044

1044:                                             ; preds = %1037, %1036
  %1045 = phi i32 [ %1043, %1037 ], [ 2147483647, %1036 ]
  %1046 = and i32 %1045, %29
  %1047 = lshr i32 %1045, 31
  %1048 = add nsw i32 %1047, %30
  %1049 = ashr i32 %1045, %20
  %1050 = icmp sgt i32 %1046, %1048
  %1051 = zext i1 %1050 to i32
  %1052 = add nsw i32 %1049, %1051
  %1053 = icmp sgt i32 %1052, -32768
  %1054 = select i1 %1053, i32 %1052, i32 -32768
  %1055 = icmp slt i32 %1054, 32767
  %1056 = select i1 %1055, i32 %1054, i32 32767
  %1057 = trunc i32 %1056 to i16
  %1058 = add i32 %32, %1023
  %1059 = sext i32 %1058 to i64
  %1060 = getelementptr inbounds i16, i16* %9, i64 %1059
  store i16 %1057, i16* %1060, align 2
  %1061 = getelementptr inbounds [4 x [4 x i32]], [4 x [4 x i32]]* %12, i64 0, i64 %859, i64 3
  %1062 = load i32, i32* %1061, align 4
  %1063 = load i32, i32* %861, align 4
  %1064 = add nsw i32 %1063, %1062
  %1065 = mul nsw i32 %1064, %22
  %1066 = icmp eq i32 %1065, %7
  br i1 %1066, label %1070, label %1067

1067:                                             ; preds = %1044
  %1068 = sext i32 %1065 to i64
  %1069 = mul nsw i64 %1068, %23
  br label %1071

1070:                                             ; preds = %1044
  br i1 %24, label %1078, label %1071

1071:                                             ; preds = %1070, %1067
  %1072 = phi i64 [ %1069, %1067 ], [ %25, %1070 ]
  %1073 = icmp sgt i64 %1072, -1
  %1074 = select i1 %1073, i64 1073741824, i64 -1073741823
  %1075 = add nsw i64 %1074, %1072
  %1076 = sdiv i64 %1075, 2147483648
  %1077 = trunc i64 %1076 to i32
  br label %1078

1078:                                             ; preds = %1071, %1070
  %1079 = phi i32 [ %1077, %1071 ], [ 2147483647, %1070 ]
  %1080 = and i32 %1079, %29
  %1081 = lshr i32 %1079, 31
  %1082 = add nsw i32 %1081, %30
  %1083 = ashr i32 %1079, %20
  %1084 = icmp sgt i32 %1080, %1082
  %1085 = zext i1 %1084 to i32
  %1086 = add nsw i32 %1083, %1085
  %1087 = icmp sgt i32 %1086, -32768
  %1088 = select i1 %1087, i32 %1086, i32 -32768
  %1089 = icmp slt i32 %1088, 32767
  %1090 = select i1 %1089, i32 %1088, i32 32767
  %1091 = trunc i32 %1090 to i16
  %1092 = add i32 %33, %1023
  %1093 = sext i32 %1092 to i64
  %1094 = getelementptr inbounds i16, i16* %9, i64 %1093
  store i16 %1091, i16* %1094, align 2
  %1095 = add nuw nsw i64 %859, 1
  %1096 = icmp eq i64 %1095, 4
  br i1 %1096, label %868, label %858
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN6tflite13optimized_ops32ShuffledFullyConnectedWorkerTaskD0Ev(%"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"*) unnamed_addr #4 comdat align 2 {
  %2 = bitcast %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %0 to i8*
  tail call void @_ZdlPv(i8* %2) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN6tflite13optimized_ops32ShuffledFullyConnectedWorkerTask3RunEv(%"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"*) unnamed_addr #1 comdat align 2 {
  %2 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %0, i64 0, i32 1
  %3 = load i8*, i8** %2, align 8
  %4 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %0, i64 0, i32 2
  %5 = load i8*, i8** %4, align 8
  %6 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %0, i64 0, i32 3
  %7 = load i32, i32* %6, align 8
  %8 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %0, i64 0, i32 4
  %9 = load i32, i32* %8, align 4
  %10 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %0, i64 0, i32 5
  %11 = load i32, i32* %10, align 8
  %12 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %0, i64 0, i32 6
  %13 = load i32, i32* %12, align 4
  %14 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %0, i64 0, i32 7
  %15 = load i32*, i32** %14, align 8
  %16 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %0, i64 0, i32 8
  %17 = load i32, i32* %16, align 8
  %18 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %0, i64 0, i32 9
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %0, i64 0, i32 10
  %21 = load i16*, i16** %20, align 8
  tail call void @_ZN6tflite13optimized_ops32ShuffledFullyConnectedWorkerImplEPKhPKaiiiiPKiiiPs(i8* %3, i8* %5, i32 %7, i32 %9, i32 %11, i32 %13, i32* %15, i32 %17, i32 %19, i16* %21)
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZNSt3__16vectorIN6tflite13optimized_ops32ShuffledFullyConnectedWorkerTaskENS_9allocatorIS3_EEE24__emplace_back_slow_pathIJRPhPKaRKiiSD_SD_PSC_SD_SD_PsEEEvDpOT_(%"class.std::__1::vector.143"*, i8** dereferenceable(8), i8** dereferenceable(8), i32* dereferenceable(4), i32* dereferenceable(4), i32* dereferenceable(4), i32* dereferenceable(4), i32** dereferenceable(8), i32* dereferenceable(4), i32* dereferenceable(4), i16** dereferenceable(8)) local_unnamed_addr #4 comdat align 2 {
  %12 = getelementptr inbounds %"class.std::__1::vector.143", %"class.std::__1::vector.143"* %0, i64 0, i32 0, i32 1
  %13 = bitcast %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"** %12 to i64*
  %14 = load i64, i64* %13, align 8
  %15 = bitcast %"class.std::__1::vector.143"* %0 to i64*
  %16 = load i64, i64* %15, align 8
  %17 = sub i64 %14, %16
  %18 = sdiv exact i64 %17, 72
  %19 = add nsw i64 %18, 1
  %20 = icmp ugt i64 %19, 256204778801521550
  br i1 %20, label %21, label %23

21:                                               ; preds = %11
  %22 = bitcast %"class.std::__1::vector.143"* %0 to %"class.std::__1::__vector_base_common"*
  tail call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* %22) #20
  unreachable

23:                                               ; preds = %11
  %24 = getelementptr inbounds %"class.std::__1::vector.143", %"class.std::__1::vector.143"* %0, i64 0, i32 0, i32 2, i32 0, i32 0
  %25 = bitcast %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"** %24 to i64*
  %26 = load i64, i64* %25, align 8
  %27 = sub i64 %26, %16
  %28 = sdiv exact i64 %27, 72
  %29 = icmp ult i64 %28, 128102389400760775
  br i1 %29, label %30, label %35

30:                                               ; preds = %23
  %31 = shl nsw i64 %28, 1
  %32 = icmp ult i64 %31, %19
  %33 = select i1 %32, i64 %19, i64 %31
  %34 = icmp eq i64 %33, 0
  br i1 %34, label %40, label %35

35:                                               ; preds = %23, %30
  %36 = phi i64 [ %33, %30 ], [ 256204778801521550, %23 ]
  %37 = mul i64 %36, 72
  %38 = tail call i8* @_Znwm(i64 %37) #18
  %39 = bitcast i8* %38 to %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"*
  br label %40

40:                                               ; preds = %30, %35
  %41 = phi i64 [ %36, %35 ], [ 0, %30 ]
  %42 = phi %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* [ %39, %35 ], [ null, %30 ]
  %43 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %42, i64 %18
  %44 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %42, i64 %41
  %45 = ptrtoint %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %44 to i64
  %46 = bitcast i8** %1 to i64*
  %47 = load i64, i64* %46, align 8
  %48 = bitcast i8** %2 to i64*
  %49 = load i64, i64* %48, align 8
  %50 = load i32, i32* %3, align 4
  %51 = load i32, i32* %4, align 4
  %52 = load i32, i32* %5, align 4
  %53 = load i32, i32* %6, align 4
  %54 = bitcast i32** %7 to i64*
  %55 = load i64, i64* %54, align 8
  %56 = load i32, i32* %8, align 4
  %57 = load i32, i32* %9, align 4
  %58 = bitcast i16** %10 to i64*
  %59 = load i64, i64* %58, align 8
  %60 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %43, i64 0, i32 0, i32 0
  %61 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %42, i64 %18, i32 0, i32 1
  store %"class.gemmlowp::Allocator"* null, %"class.gemmlowp::Allocator"** %61, align 8
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVN6tflite13optimized_ops32ShuffledFullyConnectedWorkerTaskE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %60, align 8
  %62 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %42, i64 %18, i32 1
  %63 = bitcast i8** %62 to i64*
  store i64 %47, i64* %63, align 8
  %64 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %42, i64 %18, i32 2
  %65 = bitcast i8** %64 to i64*
  store i64 %49, i64* %65, align 8
  %66 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %42, i64 %18, i32 3
  store i32 %50, i32* %66, align 8
  %67 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %42, i64 %18, i32 4
  store i32 %51, i32* %67, align 4
  %68 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %42, i64 %18, i32 5
  store i32 %52, i32* %68, align 8
  %69 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %42, i64 %18, i32 6
  store i32 %53, i32* %69, align 4
  %70 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %42, i64 %18, i32 7
  %71 = bitcast i32** %70 to i64*
  store i64 %55, i64* %71, align 8
  %72 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %42, i64 %18, i32 8
  store i32 %56, i32* %72, align 8
  %73 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %42, i64 %18, i32 9
  store i32 %57, i32* %73, align 4
  %74 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %42, i64 %18, i32 10
  %75 = bitcast i16** %74 to i64*
  store i64 %59, i64* %75, align 8
  %76 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %43, i64 1
  %77 = ptrtoint %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %76 to i64
  %78 = getelementptr inbounds %"class.std::__1::vector.143", %"class.std::__1::vector.143"* %0, i64 0, i32 0, i32 0
  %79 = load %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"*, %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"** %78, align 8
  %80 = load %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"*, %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"** %12, align 8
  %81 = icmp eq %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %80, %79
  br i1 %81, label %82, label %84

82:                                               ; preds = %40
  %83 = ptrtoint %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %79 to i64
  br label %103

84:                                               ; preds = %40, %84
  %85 = phi %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* [ %98, %84 ], [ %43, %40 ]
  %86 = phi %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* [ %87, %84 ], [ %80, %40 ]
  %87 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %86, i64 -1
  %88 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %85, i64 -1, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVN8gemmlowp4TaskE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %88, align 8
  %89 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %85, i64 -1, i32 0, i32 1
  %90 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %86, i64 -1, i32 0, i32 1
  %91 = bitcast %"class.gemmlowp::Allocator"** %90 to i64*
  %92 = load i64, i64* %91, align 8
  %93 = bitcast %"class.gemmlowp::Allocator"** %89 to i64*
  store i64 %92, i64* %93, align 8
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVN6tflite13optimized_ops32ShuffledFullyConnectedWorkerTaskE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %88, align 8
  %94 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %85, i64 -1, i32 1
  %95 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %86, i64 -1, i32 1
  %96 = bitcast i8** %94 to i8*
  %97 = bitcast i8** %95 to i8*
  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %96, i8* align 8 %97, i64 56, i1 false) #19
  %98 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %85, i64 -1
  %99 = icmp eq %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %87, %79
  br i1 %99, label %100, label %84

100:                                              ; preds = %84
  %101 = load i64, i64* %15, align 8
  %102 = load %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"*, %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"** %12, align 8
  br label %103

103:                                              ; preds = %82, %100
  %104 = phi %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* [ %79, %82 ], [ %102, %100 ]
  %105 = phi %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* [ %43, %82 ], [ %98, %100 ]
  %106 = phi i64 [ %83, %82 ], [ %101, %100 ]
  %107 = ptrtoint %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %105 to i64
  store i64 %107, i64* %15, align 8
  store i64 %77, i64* %13, align 8
  store i64 %45, i64* %25, align 8
  %108 = inttoptr i64 %106 to %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"*
  %109 = icmp eq %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %104, %108
  br i1 %109, label %117, label %110

110:                                              ; preds = %103, %110
  %111 = phi %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* [ %112, %110 ], [ %104, %103 ]
  %112 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %111, i64 -1
  %113 = bitcast %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %112 to void (%"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"*)***
  %114 = load void (%"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"*)**, void (%"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"*)*** %113, align 8
  %115 = load void (%"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"*)*, void (%"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"*)** %114, align 8
  tail call void %115(%"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %112) #19
  %116 = icmp eq %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %112, %108
  br i1 %116, label %117, label %110

117:                                              ; preds = %110, %103
  %118 = icmp eq i64 %106, 0
  br i1 %118, label %121, label %119

119:                                              ; preds = %117
  %120 = inttoptr i64 %106 to i8*
  tail call void @_ZdlPv(i8* %120) #18
  br label %121

121:                                              ; preds = %117, %119
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp11WorkersPool7ExecuteIN6tflite13optimized_ops32ShuffledFullyConnectedWorkerTaskEEEviPT_(%"class.gemmlowp::WorkersPool"*, i32, %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"*) local_unnamed_addr #1 comdat align 2 {
  %4 = alloca %"class.std::__1::chrono::duration.98", align 8
  %5 = add nsw i32 %1, -1
  %6 = sext i32 %5 to i64
  tail call void @_ZN8gemmlowp11WorkersPool13CreateWorkersEm(%"class.gemmlowp::WorkersPool"* %0, i64 %6)
  %7 = getelementptr inbounds %"class.gemmlowp::WorkersPool", %"class.gemmlowp::WorkersPool"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %8 = load atomic i64, i64* %7 monotonic, align 8
  store atomic i64 %6, i64* %7 release, align 8
  %9 = icmp eq i32 %5, 0
  br i1 %9, label %12, label %10

10:                                               ; preds = %3
  %11 = getelementptr inbounds %"class.gemmlowp::WorkersPool", %"class.gemmlowp::WorkersPool"* %0, i64 0, i32 0, i32 0, i32 0
  br label %35

12:                                               ; preds = %46, %3
  %13 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %2, i64 %6, i32 0
  %14 = getelementptr inbounds %"class.gemmlowp::WorkersPool", %"class.gemmlowp::WorkersPool"* %0, i64 0, i32 2
  %15 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %2, i64 %6, i32 0, i32 1
  store %"class.gemmlowp::Allocator"* %14, %"class.gemmlowp::Allocator"** %15, align 8
  %16 = bitcast %"struct.gemmlowp::Task"* %13 to void (%"struct.gemmlowp::Task"*)***
  %17 = load void (%"struct.gemmlowp::Task"*)**, void (%"struct.gemmlowp::Task"*)*** %16, align 8
  %18 = getelementptr inbounds void (%"struct.gemmlowp::Task"*)*, void (%"struct.gemmlowp::Task"*)** %17, i64 2
  %19 = load void (%"struct.gemmlowp::Task"*)*, void (%"struct.gemmlowp::Task"*)** %18, align 8
  tail call void %19(%"struct.gemmlowp::Task"* %13) #19
  %20 = load atomic i64, i64* %7 acquire, align 8
  %21 = icmp eq i64 %20, 0
  br i1 %21, label %34, label %22

22:                                               ; preds = %12
  %23 = bitcast %"class.std::__1::chrono::duration.98"* %4 to i8*
  %24 = getelementptr inbounds %"class.std::__1::chrono::duration.98", %"class.std::__1::chrono::duration.98"* %4, i64 0, i32 0
  br label %25

25:                                               ; preds = %30, %22
  %26 = phi i32 [ 0, %22 ], [ %31, %30 ]
  call void asm sideeffect "nop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0A", "~{dirflag},~{fpsr},~{flags}"() #19, !srcloc !301
  %27 = add nsw i32 %26, 64
  %28 = icmp sgt i32 %27, 4000000
  br i1 %28, label %29, label %30

29:                                               ; preds = %25
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %23) #19
  store i64 1000000, i64* %24, align 8
  call void @_ZNSt3__111this_thread9sleep_forERKNS_6chrono8durationIxNS_5ratioILl1ELl1000000000EEEEE(%"class.std::__1::chrono::duration.98"* nonnull dereferenceable(8) %4) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %23) #19
  br label %30

30:                                               ; preds = %29, %25
  %31 = phi i32 [ 0, %29 ], [ %27, %25 ]
  %32 = load atomic i64, i64* %7 acquire, align 8
  %33 = icmp eq i64 %32, 0
  br i1 %33, label %34, label %25

34:                                               ; preds = %30, %12
  ret void

35:                                               ; preds = %10, %46
  %36 = phi i64 [ 0, %10 ], [ %54, %46 ]
  %37 = load %"class.gemmlowp::Worker"**, %"class.gemmlowp::Worker"*** %11, align 8
  %38 = getelementptr inbounds %"class.gemmlowp::Worker"*, %"class.gemmlowp::Worker"** %37, i64 %36
  %39 = load %"class.gemmlowp::Worker"*, %"class.gemmlowp::Worker"** %38, align 8
  %40 = getelementptr inbounds %"class.gemmlowp::Worker", %"class.gemmlowp::Worker"* %39, i64 0, i32 3
  %41 = tail call i32 @pthread_mutex_lock(%union.pthread_mutex_t* %40) #19
  %42 = getelementptr inbounds %"class.gemmlowp::Worker", %"class.gemmlowp::Worker"* %39, i64 0, i32 4, i32 0, i32 0, i32 0, i32 0
  %43 = load atomic i32, i32* %42 monotonic, align 4
  %44 = icmp ult i32 %43, 3
  br i1 %44, label %46, label %45

45:                                               ; preds = %35
  tail call void @abort() #20
  unreachable

46:                                               ; preds = %35
  %47 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %2, i64 %36, i32 0
  %48 = getelementptr inbounds %"class.gemmlowp::Worker", %"class.gemmlowp::Worker"* %39, i64 0, i32 5
  %49 = getelementptr inbounds %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask", %"struct.tflite::optimized_ops::ShuffledFullyConnectedWorkerTask"* %2, i64 %36, i32 0, i32 1
  store %"class.gemmlowp::Allocator"* %48, %"class.gemmlowp::Allocator"** %49, align 8
  %50 = getelementptr inbounds %"class.gemmlowp::Worker", %"class.gemmlowp::Worker"* %39, i64 0, i32 1
  store %"struct.gemmlowp::Task"* %47, %"struct.gemmlowp::Task"** %50, align 8
  store atomic i32 2, i32* %42 monotonic, align 4
  %51 = getelementptr inbounds %"class.gemmlowp::Worker", %"class.gemmlowp::Worker"* %39, i64 0, i32 2
  %52 = tail call i32 @pthread_cond_broadcast(%union.pthread_cond_t* %51) #19
  %53 = tail call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* %40) #19
  %54 = add nuw i64 %36, 1
  %55 = icmp ult i64 %54, %6
  br i1 %55, label %35, label %12
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN6tflite13optimized_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKiS6_PhPNS_17CpuBackendContextE(%"struct.tflite::FullyConnectedParams"* dereferenceable(40), %"class.tflite::RuntimeShape"* dereferenceable(32), i8*, %"class.tflite::RuntimeShape"* dereferenceable(32), i8*, %"class.tflite::RuntimeShape"* dereferenceable(32), i32*, %"class.tflite::RuntimeShape"* dereferenceable(32), i8*, %"class.tflite::CpuBackendContext"*) local_unnamed_addr #4 comdat {
  %11 = alloca %"struct.tflite::cpu_backend_gemm::MatrixParams.153", align 4
  %12 = alloca %"struct.tflite::cpu_backend_gemm::MatrixParams.153", align 4
  %13 = alloca %"struct.tflite::cpu_backend_gemm::MatrixParams.153", align 4
  %14 = alloca %"struct.tflite::cpu_backend_gemm::GemmParams.155", align 8
  %15 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 0
  %16 = load i32, i32* %15, align 4
  %17 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 1
  %18 = load i32, i32* %17, align 4
  %19 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 2
  %20 = load i32, i32* %19, align 4
  %21 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 3
  %22 = load i32, i32* %21, align 4
  %23 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 4
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 5
  %26 = load i32, i32* %25, align 4
  %27 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 6
  %28 = load i32, i32* %27, align 4
  %29 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %3, i64 0, i32 0
  %30 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %7, i64 0, i32 0
  %31 = load i32, i32* %30, align 8
  %32 = load i32, i32* %29, align 8
  %33 = icmp sgt i32 %31, 5
  %34 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %7, i64 0, i32 1
  %35 = getelementptr inbounds %union.anon.54, %union.anon.54* %34, i64 0, i32 0
  %36 = load i32*, i32** %35, align 8
  %37 = bitcast %union.anon.54* %34 to i32*
  %38 = select i1 %33, i32* %36, i32* %37
  %39 = icmp sgt i32 %31, 0
  br i1 %39, label %40, label %81

40:                                               ; preds = %10
  %41 = add nsw i32 %31, -1
  %42 = zext i32 %41 to i64
  %43 = zext i32 %31 to i64
  %44 = add nsw i64 %43, -1
  %45 = and i64 %43, 3
  %46 = icmp ult i64 %44, 3
  br i1 %46, label %62, label %47

47:                                               ; preds = %40
  %48 = sub nsw i64 %43, %45
  br label %49

49:                                               ; preds = %170, %47
  %50 = phi i64 [ 0, %47 ], [ %173, %170 ]
  %51 = phi i32 [ 1, %47 ], [ %172, %170 ]
  %52 = phi i64 [ %48, %47 ], [ %174, %170 ]
  %53 = icmp eq i64 %50, %42
  br i1 %53, label %57, label %54

54:                                               ; preds = %49
  %55 = getelementptr inbounds i32, i32* %38, i64 %50
  %56 = load i32, i32* %55, align 4
  br label %57

57:                                               ; preds = %54, %49
  %58 = phi i32 [ %56, %54 ], [ 1, %49 ]
  %59 = mul nsw i32 %58, %51
  %60 = or i64 %50, 1
  %61 = icmp eq i64 %60, %42
  br i1 %61, label %154, label %151

62:                                               ; preds = %170, %40
  %63 = phi i32 [ undef, %40 ], [ %172, %170 ]
  %64 = phi i64 [ 0, %40 ], [ %173, %170 ]
  %65 = phi i32 [ 1, %40 ], [ %172, %170 ]
  %66 = icmp eq i64 %45, 0
  br i1 %66, label %81, label %67

67:                                               ; preds = %62, %75
  %68 = phi i64 [ %78, %75 ], [ %64, %62 ]
  %69 = phi i32 [ %77, %75 ], [ %65, %62 ]
  %70 = phi i64 [ %79, %75 ], [ %45, %62 ]
  %71 = icmp eq i64 %68, %42
  br i1 %71, label %75, label %72

72:                                               ; preds = %67
  %73 = getelementptr inbounds i32, i32* %38, i64 %68
  %74 = load i32, i32* %73, align 4
  br label %75

75:                                               ; preds = %72, %67
  %76 = phi i32 [ %74, %72 ], [ 1, %67 ]
  %77 = mul nsw i32 %76, %69
  %78 = add nuw nsw i64 %68, 1
  %79 = add i64 %70, -1
  %80 = icmp eq i64 %79, 0
  br i1 %80, label %81, label %67, !llvm.loop !363

81:                                               ; preds = %62, %75, %10
  %82 = phi i32 [ 1, %10 ], [ %63, %62 ], [ %77, %75 ]
  %83 = add nsw i32 %32, -2
  %84 = icmp sgt i32 %32, 5
  %85 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %3, i64 0, i32 1
  br i1 %84, label %86, label %94

86:                                               ; preds = %81
  %87 = getelementptr inbounds %union.anon.54, %union.anon.54* %85, i64 0, i32 0
  %88 = load i32*, i32** %87, align 8
  %89 = sext i32 %83 to i64
  %90 = getelementptr inbounds i32, i32* %88, i64 %89
  %91 = add nsw i32 %32, -1
  %92 = sext i32 %91 to i64
  %93 = getelementptr inbounds i32, i32* %88, i64 %92
  br label %101

94:                                               ; preds = %81
  %95 = bitcast %union.anon.54* %85 to [5 x i32]*
  %96 = sext i32 %83 to i64
  %97 = getelementptr inbounds [5 x i32], [5 x i32]* %95, i64 0, i64 %96
  %98 = add nsw i32 %32, -1
  %99 = sext i32 %98 to i64
  %100 = getelementptr inbounds [5 x i32], [5 x i32]* %95, i64 0, i64 %99
  br label %101

101:                                              ; preds = %86, %94
  %102 = phi i32* [ %93, %86 ], [ %100, %94 ]
  %103 = phi i32* [ %90, %86 ], [ %97, %94 ]
  %104 = load i32, i32* %103, align 4
  %105 = load i32, i32* %102, align 4
  %106 = bitcast %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %106) #19
  %107 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %11, i64 0, i32 0
  %108 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %11, i64 0, i32 1
  %109 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %11, i64 0, i32 2
  %110 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %11, i64 0, i32 3
  %111 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %11, i64 0, i32 4
  %112 = bitcast %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %11 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %112, i8 -86, i64 16, i1 false)
  store i32 %104, i32* %108, align 4
  store i32 %105, i32* %109, align 4
  store i32 1, i32* %107, align 4
  %113 = trunc i32 %18 to i8
  %114 = sub i8 0, %113
  store i8 %114, i8* %110, align 4
  %115 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 9
  %116 = load i8, i8* %115, align 4, !range !10
  store i8 %116, i8* %111, align 1
  %117 = bitcast %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %117) #19
  %118 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %12, i64 0, i32 0
  %119 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %12, i64 0, i32 1
  %120 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %12, i64 0, i32 2
  %121 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %12, i64 0, i32 3
  %122 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %12, i64 0, i32 4
  %123 = bitcast %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %12 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %123, i8 -86, i64 16, i1 false)
  store i32 %105, i32* %119, align 4
  store i32 %82, i32* %120, align 4
  store i32 0, i32* %118, align 4
  %124 = trunc i32 %16 to i8
  %125 = sub i8 0, %124
  store i8 %125, i8* %121, align 4
  %126 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 10
  %127 = load i8, i8* %126, align 1, !range !10
  store i8 %127, i8* %122, align 1
  %128 = bitcast %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %128) #19
  %129 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %13, i64 0, i32 0
  %130 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %13, i64 0, i32 1
  %131 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %13, i64 0, i32 2
  %132 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %13, i64 0, i32 3
  %133 = bitcast %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %13 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %133, i8 -86, i64 16, i1 false)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %128, i8 0, i64 14, i1 false) #19
  store i32 %104, i32* %130, align 4
  store i32 %82, i32* %131, align 4
  store i32 0, i32* %129, align 4
  %134 = trunc i32 %20 to i8
  store i8 %134, i8* %132, align 4
  %135 = bitcast %"struct.tflite::cpu_backend_gemm::GemmParams.155"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %135) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %135, i8 -86, i64 40, i1 false)
  %136 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.155", %"struct.tflite::cpu_backend_gemm::GemmParams.155"* %14, i64 0, i32 6
  %137 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.155", %"struct.tflite::cpu_backend_gemm::GemmParams.155"* %14, i64 0, i32 2
  %138 = bitcast i32** %137 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %138, i8 0, i64 16, i1 false) #19
  %139 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.155", %"struct.tflite::cpu_backend_gemm::GemmParams.155"* %14, i64 0, i32 4
  store i32* %6, i32** %139, align 8
  %140 = trunc i32 %26 to i8
  %141 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.155", %"struct.tflite::cpu_backend_gemm::GemmParams.155"* %14, i64 0, i32 5
  store i8 %140, i8* %141, align 8
  %142 = trunc i32 %28 to i8
  store i8 %142, i8* %136, align 1
  %143 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.155", %"struct.tflite::cpu_backend_gemm::GemmParams.155"* %14, i64 0, i32 0
  store i32 %22, i32* %143, align 8
  %144 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.155", %"struct.tflite::cpu_backend_gemm::GemmParams.155"* %14, i64 0, i32 1
  store i32 %24, i32* %144, align 4
  %145 = getelementptr inbounds %"class.tflite::CpuBackendContext", %"class.tflite::CpuBackendContext"* %9, i64 0, i32 4
  %146 = load i8, i8* %145, align 4, !range !10
  %147 = icmp eq i8 %146, 0
  br i1 %147, label %149, label %148

148:                                              ; preds = %101
  call void @_ZN6tflite16cpu_backend_gemm6detail16GemmImplUsingRuyIhhihLNS0_18QuantizationFlavorE1EE3RunERKNS0_12MatrixParamsIhEEPKhS8_SA_S8_PhRKNS0_10GemmParamsIihLS3_1EEEPNS_17CpuBackendContextE(%"struct.tflite::cpu_backend_gemm::MatrixParams.153"* nonnull dereferenceable(16) %11, i8* %4, %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* nonnull dereferenceable(16) %12, i8* %2, %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* nonnull dereferenceable(16) %13, i8* %8, %"struct.tflite::cpu_backend_gemm::GemmParams.155"* nonnull dereferenceable(40) %14, %"class.tflite::CpuBackendContext"* %9) #19
  br label %150

149:                                              ; preds = %101
  call void @_ZN6tflite16cpu_backend_gemm6detail21GemmImplUsingGemmlowpIhhihLNS0_18QuantizationFlavorE1EE3RunERKNS0_12MatrixParamsIhEEPKhS8_SA_S8_PhRKNS0_10GemmParamsIihLS3_1EEEPNS_17CpuBackendContextE(%"struct.tflite::cpu_backend_gemm::MatrixParams.153"* nonnull dereferenceable(16) %11, i8* %4, %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* nonnull dereferenceable(16) %12, i8* %2, %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* nonnull dereferenceable(16) %13, i8* %8, %"struct.tflite::cpu_backend_gemm::GemmParams.155"* nonnull dereferenceable(40) %14, %"class.tflite::CpuBackendContext"* %9) #19
  br label %150

150:                                              ; preds = %148, %149
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %135) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %128) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %117) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %106) #19
  ret void

151:                                              ; preds = %57
  %152 = getelementptr inbounds i32, i32* %38, i64 %60
  %153 = load i32, i32* %152, align 4
  br label %154

154:                                              ; preds = %151, %57
  %155 = phi i32 [ %153, %151 ], [ 1, %57 ]
  %156 = mul nsw i32 %155, %59
  %157 = or i64 %50, 2
  %158 = icmp eq i64 %157, %42
  br i1 %158, label %162, label %159

159:                                              ; preds = %154
  %160 = getelementptr inbounds i32, i32* %38, i64 %157
  %161 = load i32, i32* %160, align 4
  br label %162

162:                                              ; preds = %159, %154
  %163 = phi i32 [ %161, %159 ], [ 1, %154 ]
  %164 = mul nsw i32 %163, %156
  %165 = or i64 %50, 3
  %166 = icmp eq i64 %165, %42
  br i1 %166, label %170, label %167

167:                                              ; preds = %162
  %168 = getelementptr inbounds i32, i32* %38, i64 %165
  %169 = load i32, i32* %168, align 4
  br label %170

170:                                              ; preds = %167, %162
  %171 = phi i32 [ %169, %167 ], [ 1, %162 ]
  %172 = mul nsw i32 %171, %164
  %173 = add nuw nsw i64 %50, 4
  %174 = add i64 %52, -4
  %175 = icmp eq i64 %174, 0
  br i1 %175, label %62, label %49
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN6tflite13optimized_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKiS6_PsPNS_17CpuBackendContextE(%"struct.tflite::FullyConnectedParams"* dereferenceable(40), %"class.tflite::RuntimeShape"* dereferenceable(32), i8*, %"class.tflite::RuntimeShape"* dereferenceable(32), i8*, %"class.tflite::RuntimeShape"* dereferenceable(32), i32*, %"class.tflite::RuntimeShape"* dereferenceable(32), i16*, %"class.tflite::CpuBackendContext"*) local_unnamed_addr #4 comdat {
  %11 = alloca %"struct.tflite::cpu_backend_gemm::MatrixParams.153", align 4
  %12 = alloca %"struct.tflite::cpu_backend_gemm::MatrixParams.153", align 4
  %13 = alloca %"struct.tflite::cpu_backend_gemm::MatrixParams.454", align 4
  %14 = alloca %"struct.tflite::cpu_backend_gemm::GemmParams.456", align 8
  %15 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 0
  %16 = load i32, i32* %15, align 4
  %17 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 1
  %18 = load i32, i32* %17, align 4
  %19 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 3
  %20 = load i32, i32* %19, align 4
  %21 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 4
  %22 = load i32, i32* %21, align 4
  %23 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 5
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 6
  %26 = load i32, i32* %25, align 4
  %27 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %3, i64 0, i32 0
  %28 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %7, i64 0, i32 0
  %29 = load i32, i32* %28, align 8
  %30 = load i32, i32* %27, align 8
  %31 = add nsw i32 %29, -1
  %32 = icmp sgt i32 %29, 5
  %33 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %7, i64 0, i32 1
  %34 = getelementptr inbounds %union.anon.54, %union.anon.54* %33, i64 0, i32 0
  %35 = load i32*, i32** %34, align 8
  %36 = bitcast %union.anon.54* %33 to i32*
  %37 = select i1 %32, i32* %35, i32* %36
  %38 = icmp sgt i32 %29, 0
  br i1 %38, label %39, label %79

39:                                               ; preds = %10
  %40 = zext i32 %31 to i64
  %41 = zext i32 %29 to i64
  %42 = add nsw i64 %41, -1
  %43 = and i64 %41, 3
  %44 = icmp ult i64 %42, 3
  br i1 %44, label %60, label %45

45:                                               ; preds = %39
  %46 = sub nsw i64 %41, %43
  br label %47

47:                                               ; preds = %169, %45
  %48 = phi i64 [ 0, %45 ], [ %172, %169 ]
  %49 = phi i32 [ 1, %45 ], [ %171, %169 ]
  %50 = phi i64 [ %46, %45 ], [ %173, %169 ]
  %51 = icmp eq i64 %48, %40
  br i1 %51, label %55, label %52

52:                                               ; preds = %47
  %53 = getelementptr inbounds i32, i32* %37, i64 %48
  %54 = load i32, i32* %53, align 4
  br label %55

55:                                               ; preds = %52, %47
  %56 = phi i32 [ %54, %52 ], [ 1, %47 ]
  %57 = mul nsw i32 %56, %49
  %58 = or i64 %48, 1
  %59 = icmp eq i64 %58, %40
  br i1 %59, label %153, label %150

60:                                               ; preds = %169, %39
  %61 = phi i32 [ undef, %39 ], [ %171, %169 ]
  %62 = phi i64 [ 0, %39 ], [ %172, %169 ]
  %63 = phi i32 [ 1, %39 ], [ %171, %169 ]
  %64 = icmp eq i64 %43, 0
  br i1 %64, label %79, label %65

65:                                               ; preds = %60, %73
  %66 = phi i64 [ %76, %73 ], [ %62, %60 ]
  %67 = phi i32 [ %75, %73 ], [ %63, %60 ]
  %68 = phi i64 [ %77, %73 ], [ %43, %60 ]
  %69 = icmp eq i64 %66, %40
  br i1 %69, label %73, label %70

70:                                               ; preds = %65
  %71 = getelementptr inbounds i32, i32* %37, i64 %66
  %72 = load i32, i32* %71, align 4
  br label %73

73:                                               ; preds = %70, %65
  %74 = phi i32 [ %72, %70 ], [ 1, %65 ]
  %75 = mul nsw i32 %74, %67
  %76 = add nuw nsw i64 %66, 1
  %77 = add i64 %68, -1
  %78 = icmp eq i64 %77, 0
  br i1 %78, label %79, label %65, !llvm.loop !364

79:                                               ; preds = %60, %73, %10
  %80 = phi i32 [ 1, %10 ], [ %61, %60 ], [ %75, %73 ]
  %81 = add nsw i32 %30, -2
  %82 = icmp sgt i32 %30, 5
  %83 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %3, i64 0, i32 1
  %84 = getelementptr inbounds %union.anon.54, %union.anon.54* %83, i64 0, i32 0
  %85 = load i32*, i32** %84, align 8
  %86 = sext i32 %81 to i64
  %87 = getelementptr inbounds i32, i32* %85, i64 %86
  %88 = bitcast %union.anon.54* %83 to [5 x i32]*
  %89 = getelementptr inbounds [5 x i32], [5 x i32]* %88, i64 0, i64 %86
  %90 = select i1 %82, i32* %87, i32* %89
  %91 = load i32, i32* %90, align 4
  %92 = sext i32 %31 to i64
  %93 = getelementptr inbounds i32, i32* %35, i64 %92
  %94 = bitcast %union.anon.54* %33 to [5 x i32]*
  %95 = getelementptr inbounds [5 x i32], [5 x i32]* %94, i64 0, i64 %92
  %96 = select i1 %32, i32* %93, i32* %95
  %97 = load i32, i32* %96, align 4
  %98 = icmp slt i32 %97, %91
  %99 = select i1 %98, i32 %97, i32 %91
  %100 = add nsw i32 %30, -1
  %101 = sext i32 %100 to i64
  %102 = getelementptr inbounds i32, i32* %85, i64 %101
  %103 = getelementptr inbounds [5 x i32], [5 x i32]* %88, i64 0, i64 %101
  %104 = select i1 %82, i32* %102, i32* %103
  %105 = load i32, i32* %104, align 4
  %106 = bitcast %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %106) #19
  %107 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %11, i64 0, i32 0
  %108 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %11, i64 0, i32 1
  %109 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %11, i64 0, i32 2
  %110 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %11, i64 0, i32 3
  %111 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %11, i64 0, i32 4
  %112 = bitcast %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %11 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %112, i8 -86, i64 16, i1 false)
  store i32 %99, i32* %108, align 4
  store i32 %105, i32* %109, align 4
  store i32 1, i32* %107, align 4
  %113 = trunc i32 %18 to i8
  %114 = sub i8 0, %113
  store i8 %114, i8* %110, align 4
  %115 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 9
  %116 = load i8, i8* %115, align 4, !range !10
  store i8 %116, i8* %111, align 1
  %117 = bitcast %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %117) #19
  %118 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %12, i64 0, i32 0
  %119 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %12, i64 0, i32 1
  %120 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %12, i64 0, i32 2
  %121 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %12, i64 0, i32 3
  %122 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %12, i64 0, i32 4
  %123 = bitcast %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %12 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %123, i8 -86, i64 16, i1 false)
  store i32 %105, i32* %119, align 4
  store i32 %80, i32* %120, align 4
  store i32 0, i32* %118, align 4
  %124 = trunc i32 %16 to i8
  %125 = sub i8 0, %124
  store i8 %125, i8* %121, align 4
  %126 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %0, i64 0, i32 10
  %127 = load i8, i8* %126, align 1, !range !10
  store i8 %127, i8* %122, align 1
  %128 = bitcast %"struct.tflite::cpu_backend_gemm::MatrixParams.454"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %128) #19
  %129 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.454", %"struct.tflite::cpu_backend_gemm::MatrixParams.454"* %13, i64 0, i32 0
  %130 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.454", %"struct.tflite::cpu_backend_gemm::MatrixParams.454"* %13, i64 0, i32 1
  %131 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.454", %"struct.tflite::cpu_backend_gemm::MatrixParams.454"* %13, i64 0, i32 2
  %132 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.454", %"struct.tflite::cpu_backend_gemm::MatrixParams.454"* %13, i64 0, i32 3
  %133 = bitcast %"struct.tflite::cpu_backend_gemm::MatrixParams.454"* %13 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %133, i8 -86, i64 16, i1 false)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %128, i8 0, i64 15, i1 false) #19
  store i32 %99, i32* %130, align 4
  store i32 %80, i32* %131, align 4
  store i32 0, i32* %129, align 4
  store i16 0, i16* %132, align 4
  %134 = bitcast %"struct.tflite::cpu_backend_gemm::GemmParams.456"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %134) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %134, i8 -86, i64 40, i1 false)
  %135 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.456", %"struct.tflite::cpu_backend_gemm::GemmParams.456"* %14, i64 0, i32 5
  %136 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.456", %"struct.tflite::cpu_backend_gemm::GemmParams.456"* %14, i64 0, i32 2
  %137 = bitcast i32** %136 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %137, i8 0, i64 16, i1 false) #19
  %138 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.456", %"struct.tflite::cpu_backend_gemm::GemmParams.456"* %14, i64 0, i32 6
  %139 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.456", %"struct.tflite::cpu_backend_gemm::GemmParams.456"* %14, i64 0, i32 4
  store i32* %6, i32** %139, align 8
  %140 = trunc i32 %24 to i16
  store i16 %140, i16* %135, align 8
  %141 = trunc i32 %26 to i16
  store i16 %141, i16* %138, align 2
  %142 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.456", %"struct.tflite::cpu_backend_gemm::GemmParams.456"* %14, i64 0, i32 0
  store i32 %20, i32* %142, align 8
  %143 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.456", %"struct.tflite::cpu_backend_gemm::GemmParams.456"* %14, i64 0, i32 1
  store i32 %22, i32* %143, align 4
  %144 = getelementptr inbounds %"class.tflite::CpuBackendContext", %"class.tflite::CpuBackendContext"* %9, i64 0, i32 4
  %145 = load i8, i8* %144, align 4, !range !10
  %146 = icmp eq i8 %145, 0
  br i1 %146, label %148, label %147

147:                                              ; preds = %79
  call void @_ZN6tflite16cpu_backend_gemm6detail16GemmImplUsingRuyIhhisLNS0_18QuantizationFlavorE1EE3RunERKNS0_12MatrixParamsIhEEPKhS8_SA_RKNS5_IsEEPsRKNS0_10GemmParamsIisLS3_1EEEPNS_17CpuBackendContextE(%"struct.tflite::cpu_backend_gemm::MatrixParams.153"* nonnull dereferenceable(16) %11, i8* %4, %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* nonnull dereferenceable(16) %12, i8* %2, %"struct.tflite::cpu_backend_gemm::MatrixParams.454"* nonnull dereferenceable(16) %13, i16* %8, %"struct.tflite::cpu_backend_gemm::GemmParams.456"* nonnull dereferenceable(40) %14, %"class.tflite::CpuBackendContext"* %9) #19
  br label %149

148:                                              ; preds = %79
  call void @_ZN6tflite16cpu_backend_gemm6detail21GemmImplUsingGemmlowpIhhisLNS0_18QuantizationFlavorE1EE3RunERKNS0_12MatrixParamsIhEEPKhS8_SA_RKNS5_IsEEPsRKNS0_10GemmParamsIisLS3_1EEEPNS_17CpuBackendContextE(%"struct.tflite::cpu_backend_gemm::MatrixParams.153"* nonnull dereferenceable(16) %11, i8* %4, %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* nonnull dereferenceable(16) %12, i8* %2, %"struct.tflite::cpu_backend_gemm::MatrixParams.454"* nonnull dereferenceable(16) %13, i16* %8, %"struct.tflite::cpu_backend_gemm::GemmParams.456"* nonnull dereferenceable(40) %14, %"class.tflite::CpuBackendContext"* %9) #19
  br label %149

149:                                              ; preds = %147, %148
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %134) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %128) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %117) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %106) #19
  ret void

150:                                              ; preds = %55
  %151 = getelementptr inbounds i32, i32* %37, i64 %58
  %152 = load i32, i32* %151, align 4
  br label %153

153:                                              ; preds = %150, %55
  %154 = phi i32 [ %152, %150 ], [ 1, %55 ]
  %155 = mul nsw i32 %154, %57
  %156 = or i64 %48, 2
  %157 = icmp eq i64 %156, %40
  br i1 %157, label %161, label %158

158:                                              ; preds = %153
  %159 = getelementptr inbounds i32, i32* %37, i64 %156
  %160 = load i32, i32* %159, align 4
  br label %161

161:                                              ; preds = %158, %153
  %162 = phi i32 [ %160, %158 ], [ 1, %153 ]
  %163 = mul nsw i32 %162, %155
  %164 = or i64 %48, 3
  %165 = icmp eq i64 %164, %40
  br i1 %165, label %169, label %166

166:                                              ; preds = %161
  %167 = getelementptr inbounds i32, i32* %37, i64 %164
  %168 = load i32, i32* %167, align 4
  br label %169

169:                                              ; preds = %166, %161
  %170 = phi i32 [ %168, %166 ], [ 1, %161 ]
  %171 = mul nsw i32 %170, %163
  %172 = add nuw nsw i64 %48, 4
  %173 = add i64 %50, -4
  %174 = icmp eq i64 %173, 0
  br i1 %174, label %60, label %47
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN6tflite16cpu_backend_gemm6detail16GemmImplUsingRuyIhhihLNS0_18QuantizationFlavorE1EE3RunERKNS0_12MatrixParamsIhEEPKhS8_SA_S8_PhRKNS0_10GemmParamsIihLS3_1EEEPNS_17CpuBackendContextE(%"struct.tflite::cpu_backend_gemm::MatrixParams.153"* dereferenceable(16), i8*, %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* dereferenceable(16), i8*, %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* dereferenceable(16), i8*, %"struct.tflite::cpu_backend_gemm::GemmParams.155"* dereferenceable(40), %"class.tflite::CpuBackendContext"*) local_unnamed_addr #1 comdat align 2 {
  %9 = alloca %"struct.ruy::Mat.160", align 8
  %10 = alloca %"struct.ruy::Mat.160", align 8
  %11 = alloca %"struct.ruy::Mat.160", align 8
  %12 = alloca %"class.ruy::MulParams.159", align 8
  %13 = getelementptr inbounds %"class.tflite::CpuBackendContext", %"class.tflite::CpuBackendContext"* %7, i64 0, i32 4
  %14 = load i8, i8* %13, align 4, !range !10
  %15 = icmp ne i8 %14, 0
  %16 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %0, i64 0, i32 0
  %17 = load i32, i32* %16, align 4
  %18 = icmp ne i32 %17, 0
  %19 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %0, i64 0, i32 1
  %20 = load i32, i32* %19, align 4
  %21 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %0, i64 0, i32 2
  %22 = load i32, i32* %21, align 4
  %23 = select i1 %18, i32 %22, i32 %20
  %24 = ptrtoint i8* %1 to i64
  %25 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %0, i64 0, i32 3
  %26 = load i8, i8* %25, align 4
  br i1 %15, label %27, label %34

27:                                               ; preds = %8
  %28 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %0, i64 0, i32 4
  %29 = load i8, i8* %28, align 1
  %30 = icmp eq i8 %29, 1
  %31 = zext i1 %30 to i8
  %32 = icmp eq i8 %29, 2
  %33 = select i1 %32, i8 3, i8 %31
  br label %34

34:                                               ; preds = %8, %27
  %35 = phi i8 [ %33, %27 ], [ 0, %8 ]
  %36 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %2, i64 0, i32 0
  %37 = load i32, i32* %36, align 4
  %38 = icmp ne i32 %37, 0
  %39 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %2, i64 0, i32 1
  %40 = load i32, i32* %39, align 4
  %41 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %2, i64 0, i32 2
  %42 = load i32, i32* %41, align 4
  %43 = select i1 %38, i32 %42, i32 %40
  %44 = ptrtoint i8* %3 to i64
  %45 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %2, i64 0, i32 3
  %46 = load i8, i8* %45, align 4
  br i1 %15, label %47, label %54

47:                                               ; preds = %34
  %48 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %2, i64 0, i32 4
  %49 = load i8, i8* %48, align 1
  %50 = icmp eq i8 %49, 1
  %51 = zext i1 %50 to i8
  %52 = icmp eq i8 %49, 2
  %53 = select i1 %52, i8 3, i8 %51
  br label %54

54:                                               ; preds = %34, %47
  %55 = phi i8 [ %53, %47 ], [ 0, %34 ]
  %56 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %4, i64 0, i32 0
  %57 = load i32, i32* %56, align 4
  %58 = icmp ne i32 %57, 0
  %59 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %4, i64 0, i32 1
  %60 = load i32, i32* %59, align 4
  %61 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %4, i64 0, i32 2
  %62 = load i32, i32* %61, align 4
  %63 = select i1 %58, i32 %62, i32 %60
  %64 = ptrtoint i8* %5 to i64
  %65 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %4, i64 0, i32 3
  %66 = load i8, i8* %65, align 4
  %67 = bitcast %"class.ruy::MulParams.159"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %67) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %67, i8 -86, i64 40, i1 false)
  %68 = getelementptr inbounds %"class.ruy::MulParams.159", %"class.ruy::MulParams.159"* %12, i64 0, i32 6
  %69 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.155", %"struct.tflite::cpu_backend_gemm::GemmParams.155"* %6, i64 0, i32 0
  %70 = load i32, i32* %69, align 8
  %71 = getelementptr inbounds %"class.ruy::MulParams.159", %"class.ruy::MulParams.159"* %12, i64 0, i32 1
  store i32 %70, i32* %71, align 8
  %72 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.155", %"struct.tflite::cpu_backend_gemm::GemmParams.155"* %6, i64 0, i32 1
  %73 = load i32, i32* %72, align 4
  %74 = getelementptr inbounds %"class.ruy::MulParams.159", %"class.ruy::MulParams.159"* %12, i64 0, i32 2
  store i32 %73, i32* %74, align 4
  %75 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.155", %"struct.tflite::cpu_backend_gemm::GemmParams.155"* %6, i64 0, i32 2
  %76 = getelementptr inbounds %"class.ruy::MulParams.159", %"class.ruy::MulParams.159"* %12, i64 0, i32 3
  %77 = bitcast i32** %75 to <2 x i64>*
  %78 = load <2 x i64>, <2 x i64>* %77, align 8
  %79 = bitcast i32** %76 to <2 x i64>*
  store <2 x i64> %78, <2 x i64>* %79, align 8
  %80 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.155", %"struct.tflite::cpu_backend_gemm::GemmParams.155"* %6, i64 0, i32 4
  %81 = bitcast i32** %80 to i64*
  %82 = load i64, i64* %81, align 8
  %83 = bitcast %"class.ruy::MulParams.159"* %12 to i64*
  store i64 %82, i64* %83, align 8
  %84 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.155", %"struct.tflite::cpu_backend_gemm::GemmParams.155"* %6, i64 0, i32 5
  %85 = load i8, i8* %84, align 8
  %86 = getelementptr inbounds %"class.ruy::MulParams.159", %"class.ruy::MulParams.159"* %12, i64 0, i32 5
  store i8 %85, i8* %86, align 8
  %87 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.155", %"struct.tflite::cpu_backend_gemm::GemmParams.155"* %6, i64 0, i32 6
  %88 = load i8, i8* %87, align 1
  store i8 %88, i8* %68, align 1
  %89 = getelementptr inbounds %"class.tflite::CpuBackendContext", %"class.tflite::CpuBackendContext"* %7, i64 0, i32 1, i32 0, i32 0, i32 0
  %90 = load %"class.ruy::Context"*, %"class.ruy::Context"** %89, align 8
  %91 = bitcast %"struct.ruy::Mat.160"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %91) #19
  %92 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %9, i64 0, i32 1, i32 2
  %93 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %9, i64 0, i32 2
  %94 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %9, i64 0, i32 3
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %91, i8 -86, i64 32, i1 false) #19
  %95 = bitcast %"struct.ruy::Mat.160"* %9 to i64*
  store i64 %24, i64* %95, align 8, !alias.scope !365
  %96 = zext i32 %23 to i64
  %97 = zext i1 %18 to i64
  %98 = shl nuw nsw i64 %97, 32
  %99 = or i64 %98, %96
  %100 = zext i32 %22 to i64
  %101 = shl nuw i64 %100, 32
  %102 = zext i32 %20 to i64
  %103 = or i64 %101, %102
  %104 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %9, i64 0, i32 1
  %105 = bitcast %"struct.ruy::MatLayout"* %104 to i64*
  store i64 %103, i64* %105, align 8, !alias.scope !365
  %106 = bitcast i32* %92 to i40*
  %107 = trunc i64 %99 to i40
  store i40 %107, i40* %106, align 8, !alias.scope !365
  store i8 %26, i8* %93, align 8, !alias.scope !365
  store i8 %35, i8* %94, align 1, !alias.scope !365
  %108 = bitcast %"struct.ruy::Mat.160"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %108) #19
  %109 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %10, i64 0, i32 1, i32 2
  %110 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %10, i64 0, i32 2
  %111 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %10, i64 0, i32 3
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %108, i8 -86, i64 32, i1 false) #19
  %112 = bitcast %"struct.ruy::Mat.160"* %10 to i64*
  store i64 %44, i64* %112, align 8, !alias.scope !368
  %113 = zext i32 %43 to i64
  %114 = zext i1 %38 to i64
  %115 = shl nuw nsw i64 %114, 32
  %116 = or i64 %115, %113
  %117 = zext i32 %42 to i64
  %118 = shl nuw i64 %117, 32
  %119 = zext i32 %40 to i64
  %120 = or i64 %118, %119
  %121 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %10, i64 0, i32 1
  %122 = bitcast %"struct.ruy::MatLayout"* %121 to i64*
  store i64 %120, i64* %122, align 8, !alias.scope !368
  %123 = bitcast i32* %109 to i40*
  %124 = trunc i64 %116 to i40
  store i40 %124, i40* %123, align 8, !alias.scope !368
  store i8 %46, i8* %110, align 8, !alias.scope !368
  store i8 %55, i8* %111, align 1, !alias.scope !368
  %125 = bitcast %"struct.ruy::Mat.160"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %125) #19
  %126 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %11, i64 0, i32 1, i32 2
  %127 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %11, i64 0, i32 2
  %128 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %11, i64 0, i32 3
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %125, i8 -86, i64 32, i1 false) #19
  %129 = bitcast %"struct.ruy::Mat.160"* %11 to i64*
  store i64 %64, i64* %129, align 8, !alias.scope !371
  %130 = zext i32 %63 to i64
  %131 = zext i1 %58 to i64
  %132 = shl nuw nsw i64 %131, 32
  %133 = or i64 %132, %130
  %134 = zext i32 %62 to i64
  %135 = shl nuw i64 %134, 32
  %136 = zext i32 %60 to i64
  %137 = or i64 %135, %136
  %138 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %11, i64 0, i32 1
  %139 = bitcast %"struct.ruy::MatLayout"* %138 to i64*
  store i64 %137, i64* %139, align 8, !alias.scope !371
  %140 = bitcast i32* %126 to i40*
  %141 = trunc i64 %133 to i40
  store i40 %141, i40* %140, align 8, !alias.scope !371
  store i8 %66, i8* %127, align 8, !alias.scope !371
  store i8 0, i8* %128, align 1, !alias.scope !371
  %142 = tail call %"class.ruy::Ctx"* @_ZN3ruy7get_ctxEPNS_7ContextE(%"class.ruy::Context"* %90) #19
  call void @_ZN3ruy11DispatchMulILNS_4PathE26EhhhNS_9MulParamsIihEEEEvRKNS_3MatIT0_EERKNS4_IT1_EERKT3_PNS_3CtxEPNS4_IT2_EE(%"struct.ruy::Mat.160"* nonnull dereferenceable(32) %9, %"struct.ruy::Mat.160"* nonnull dereferenceable(32) %10, %"class.ruy::MulParams.159"* nonnull dereferenceable(40) %12, %"class.ruy::Ctx"* %142, %"struct.ruy::Mat.160"* nonnull %11) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %125) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %108) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %91) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %67) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN6tflite16cpu_backend_gemm6detail21GemmImplUsingGemmlowpIhhihLNS0_18QuantizationFlavorE1EE3RunERKNS0_12MatrixParamsIhEEPKhS8_SA_S8_PhRKNS0_10GemmParamsIihLS3_1EEEPNS_17CpuBackendContextE(%"struct.tflite::cpu_backend_gemm::MatrixParams.153"* dereferenceable(16), i8*, %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* dereferenceable(16), i8*, %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* dereferenceable(16), i8*, %"struct.tflite::cpu_backend_gemm::GemmParams.155"* dereferenceable(40), %"class.tflite::CpuBackendContext"*) local_unnamed_addr #1 comdat align 2 {
  %9 = alloca %"class.gemmlowp::VectorDup", align 4
  %10 = alloca %"class.gemmlowp::VectorDup.194", align 4
  %11 = alloca %"class.gemmlowp::VectorDup", align 4
  %12 = alloca %"class.gemmlowp::VectorDup.194", align 4
  %13 = alloca %"class.gemmlowp::MatrixMap", align 8
  %14 = alloca %"class.gemmlowp::MatrixMap.180", align 8
  %15 = alloca %"class.gemmlowp::MatrixMap.182", align 8
  %16 = alloca %"class.std::__1::tuple", align 8
  %17 = alloca %"class.std::__1::tuple.187", align 4
  %18 = bitcast %"class.gemmlowp::MatrixMap"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %18) #19
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %13, i64 0, i32 0
  %20 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %13, i64 0, i32 1
  %21 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %13, i64 0, i32 2
  %22 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %13, i64 0, i32 3
  %23 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %0, i64 0, i32 1
  %24 = bitcast %"class.gemmlowp::MatrixMap"* %13 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %24, i8 -86, i64 24, i1 false)
  %25 = load i32, i32* %23, align 4
  %26 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %0, i64 0, i32 2
  %27 = load i32, i32* %26, align 4
  store i8* %1, i8** %19, align 8
  store i32 %25, i32* %20, align 8
  store i32 %27, i32* %21, align 4
  store i32 %27, i32* %22, align 8
  %28 = bitcast %"class.gemmlowp::MatrixMap.180"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %28) #19
  %29 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %14, i64 0, i32 0
  %30 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %14, i64 0, i32 1
  %31 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %14, i64 0, i32 2
  %32 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %14, i64 0, i32 3
  %33 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %2, i64 0, i32 1
  %34 = bitcast %"class.gemmlowp::MatrixMap.180"* %14 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %34, i8 -86, i64 24, i1 false)
  %35 = load i32, i32* %33, align 4
  %36 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %2, i64 0, i32 2
  %37 = load i32, i32* %36, align 4
  store i8* %3, i8** %29, align 8
  store i32 %35, i32* %30, align 8
  store i32 %37, i32* %31, align 4
  store i32 %35, i32* %32, align 8
  %38 = bitcast %"class.gemmlowp::MatrixMap.182"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %38) #19
  %39 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %15, i64 0, i32 0
  %40 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %15, i64 0, i32 1
  %41 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %15, i64 0, i32 2
  %42 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %15, i64 0, i32 3
  %43 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %4, i64 0, i32 1
  %44 = bitcast %"class.gemmlowp::MatrixMap.182"* %15 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %44, i8 -86, i64 24, i1 false)
  %45 = load i32, i32* %43, align 4
  %46 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %4, i64 0, i32 2
  %47 = load i32, i32* %46, align 4
  store i8* %5, i8** %39, align 8
  store i32 %45, i32* %40, align 8
  store i32 %47, i32* %41, align 4
  store i32 %45, i32* %42, align 8
  %48 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %4, i64 0, i32 3
  %49 = load i8, i8* %48, align 4
  %50 = zext i8 %49 to i32
  %51 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.155", %"struct.tflite::cpu_backend_gemm::GemmParams.155"* %6, i64 0, i32 0
  %52 = load i32, i32* %51, align 8
  %53 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.155", %"struct.tflite::cpu_backend_gemm::GemmParams.155"* %6, i64 0, i32 1
  %54 = load i32, i32* %53, align 4
  %55 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.155", %"struct.tflite::cpu_backend_gemm::GemmParams.155"* %6, i64 0, i32 5
  %56 = load i8, i8* %55, align 8
  %57 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.155", %"struct.tflite::cpu_backend_gemm::GemmParams.155"* %6, i64 0, i32 6
  %58 = load i8, i8* %57, align 1
  %59 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.155", %"struct.tflite::cpu_backend_gemm::GemmParams.155"* %6, i64 0, i32 4
  %60 = load i32*, i32** %59, align 8
  %61 = icmp eq i32* %60, null
  br i1 %61, label %92, label %62

62:                                               ; preds = %8
  %63 = ptrtoint i32* %60 to i64
  %64 = bitcast %"class.std::__1::tuple"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %64) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %64, i8 -86, i64 40, i1 false)
  %65 = bitcast %"class.std::__1::tuple"* %16 to i64*
  store i64 %63, i64* %65, align 8, !alias.scope !374
  %66 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %16, i64 0, i32 0, i32 0, i32 0, i32 0, i32 1
  store i32 %25, i32* %66, align 8, !alias.scope !374
  %67 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %16, i64 0, i32 0, i32 1, i32 0, i32 0
  store i32 %52, i32* %67, align 8
  %68 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %16, i64 0, i32 0, i32 1, i32 0, i32 1
  store i32 %54, i32* %68, align 4
  %69 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %16, i64 0, i32 0, i32 1, i32 0, i32 2
  store i32 %50, i32* %69, align 8
  %70 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %16, i64 0, i32 0, i32 2
  %71 = bitcast %"class.std::__1::__tuple_leaf.185"* %70 to i64*
  %72 = zext i8 %58 to i64
  %73 = shl nuw nsw i64 %72, 32
  %74 = zext i8 %56 to i64
  %75 = or i64 %73, %74
  store i64 %75, i64* %71, align 4, !alias.scope !374
  %76 = getelementptr inbounds %"class.tflite::CpuBackendContext", %"class.tflite::CpuBackendContext"* %7, i64 0, i32 2, i32 0, i32 0, i32 0
  %77 = load %"class.gemmlowp::GemmContext"*, %"class.gemmlowp::GemmContext"** %76, align 8
  %78 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %0, i64 0, i32 3
  %79 = load i8, i8* %78, align 4
  %80 = zext i8 %79 to i32
  %81 = sub nsw i32 0, %80
  %82 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %2, i64 0, i32 3
  %83 = load i8, i8* %82, align 4
  %84 = zext i8 %83 to i32
  %85 = sub nsw i32 0, %84
  %86 = bitcast %"class.gemmlowp::VectorDup"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %86) #19
  %87 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %9, i64 0, i32 0
  %88 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %9, i64 0, i32 1
  store i32 %81, i32* %87, align 4
  store i32 %25, i32* %88, align 4
  %89 = bitcast %"class.gemmlowp::VectorDup.194"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %89) #19
  %90 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %10, i64 0, i32 0
  %91 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %10, i64 0, i32 1
  store i32 %85, i32* %90, align 4
  store i32 %37, i32* %91, align 4
  call void @_ZN8gemmlowp17DispatchGemmShapeIhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENS7_IS8_LS9_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIS8_LS9_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSP_ISR_XT3_EEEPNSP_IT0_XT4_EEERKT5_RKT6_RKT7_(%"class.gemmlowp::GemmContext"* %77, %"class.gemmlowp::MatrixMap"* nonnull dereferenceable(24) %13, %"class.gemmlowp::MatrixMap.180"* nonnull dereferenceable(24) %14, %"class.gemmlowp::MatrixMap.182"* nonnull %15, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %9, %"class.gemmlowp::VectorDup.194"* nonnull dereferenceable(8) %10, %"class.std::__1::tuple"* nonnull dereferenceable(40) %16) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %89) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %86) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %64) #19
  br label %119

92:                                               ; preds = %8
  %93 = bitcast %"class.std::__1::tuple.187"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 20, i8* nonnull %93) #19
  %94 = getelementptr inbounds %"class.std::__1::tuple.187", %"class.std::__1::tuple.187"* %17, i64 0, i32 0, i32 0, i32 0, i32 0
  %95 = getelementptr inbounds %"class.std::__1::tuple.187", %"class.std::__1::tuple.187"* %17, i64 0, i32 0, i32 0, i32 0, i32 1
  %96 = getelementptr inbounds %"class.std::__1::tuple.187", %"class.std::__1::tuple.187"* %17, i64 0, i32 0, i32 0, i32 0, i32 2
  store i32 %52, i32* %94, align 4
  store i32 %54, i32* %95, align 4
  store i32 %50, i32* %96, align 4
  %97 = getelementptr inbounds %"class.std::__1::tuple.187", %"class.std::__1::tuple.187"* %17, i64 0, i32 0, i32 1
  %98 = bitcast %"class.std::__1::__tuple_leaf.190"* %97 to i64*
  %99 = zext i8 %58 to i64
  %100 = shl nuw nsw i64 %99, 32
  %101 = zext i8 %56 to i64
  %102 = or i64 %100, %101
  store i64 %102, i64* %98, align 4, !alias.scope !377
  %103 = getelementptr inbounds %"class.tflite::CpuBackendContext", %"class.tflite::CpuBackendContext"* %7, i64 0, i32 2, i32 0, i32 0, i32 0
  %104 = load %"class.gemmlowp::GemmContext"*, %"class.gemmlowp::GemmContext"** %103, align 8
  %105 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %0, i64 0, i32 3
  %106 = load i8, i8* %105, align 4
  %107 = zext i8 %106 to i32
  %108 = sub nsw i32 0, %107
  %109 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %2, i64 0, i32 3
  %110 = load i8, i8* %109, align 4
  %111 = zext i8 %110 to i32
  %112 = sub nsw i32 0, %111
  %113 = bitcast %"class.gemmlowp::VectorDup"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %113) #19
  %114 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %11, i64 0, i32 0
  %115 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %11, i64 0, i32 1
  store i32 %108, i32* %114, align 4
  store i32 %25, i32* %115, align 4
  %116 = bitcast %"class.gemmlowp::VectorDup.194"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %116) #19
  %117 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %12, i64 0, i32 0
  %118 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %12, i64 0, i32 1
  store i32 %112, i32* %117, align 4
  store i32 %37, i32* %118, align 4
  call void @_ZN8gemmlowp17DispatchGemmShapeIhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENS7_IS8_LS9_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSL_ISN_XT3_EEEPNSL_IT0_XT4_EEERKT5_RKT6_RKT7_(%"class.gemmlowp::GemmContext"* %104, %"class.gemmlowp::MatrixMap"* nonnull dereferenceable(24) %13, %"class.gemmlowp::MatrixMap.180"* nonnull dereferenceable(24) %14, %"class.gemmlowp::MatrixMap.182"* nonnull %15, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %11, %"class.gemmlowp::VectorDup.194"* nonnull dereferenceable(8) %12, %"class.std::__1::tuple.187"* nonnull dereferenceable(20) %17) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %116) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %113) #19
  call void @llvm.lifetime.end.p0i8(i64 20, i8* nonnull %93) #19
  br label %119

119:                                              ; preds = %92, %62
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %38) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %28) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %18) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy11DispatchMulILNS_4PathE26EhhhNS_9MulParamsIihEEEEvRKNS_3MatIT0_EERKNS4_IT1_EERKT3_PNS_3CtxEPNS4_IT2_EE(%"struct.ruy::Mat.160"* dereferenceable(32), %"struct.ruy::Mat.160"* dereferenceable(32), %"class.ruy::MulParams.159"* dereferenceable(40), %"class.ruy::Ctx"*, %"struct.ruy::Mat.160"*) local_unnamed_addr #1 comdat {
  %6 = alloca %"struct.ruy::Mat.160", align 8
  %7 = alloca %"struct.ruy::TrMulParams", align 8
  %8 = tail call zeroext i8 @_ZN3ruy3Ctx10SelectPathENS_4PathE(%"class.ruy::Ctx"* %3, i8 zeroext 26) #19
  %9 = bitcast %"struct.ruy::Mat.160"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %9) #19
  %10 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %6, i64 0, i32 1, i32 0
  %11 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %6, i64 0, i32 1, i32 1
  %12 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %6, i64 0, i32 1, i32 3
  %13 = bitcast %"struct.ruy::Mat.160"* %0 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %9, i8* align 8 %13, i64 32, i1 false)
  %14 = load i8, i8* %12, align 4
  %15 = icmp eq i8 %14, 0
  %16 = zext i1 %15 to i8
  store i8 %16, i8* %12, align 4
  %17 = load i32, i32* %10, align 8
  %18 = load i32, i32* %11, align 4
  store i32 %18, i32* %10, align 8
  store i32 %17, i32* %11, align 4
  %19 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 0
  call void @llvm.lifetime.start.p0i8(i64 280, i8* nonnull %19) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %19, i8 -86, i64 272, i1 false)
  %20 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 1
  %21 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 3, i32 0, i64 0, i32 2
  %22 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 3, i32 0, i64 0, i32 4
  store i32 0, i32* %22, align 8
  %23 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 3, i32 0, i64 0, i32 5
  store i8 0, i8* %23, align 4
  %24 = bitcast i8** %21 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %24, i8 0, i64 21, i1 false) #19
  %25 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 3, i32 0, i64 1, i32 0, i32 0
  store i8 0, i8* %25, align 8
  %26 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 3, i32 0, i64 1, i32 0, i32 1
  store i8 0, i8* %26, align 1
  %27 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 3, i32 0, i64 1, i32 0, i32 2
  store i8 0, i8* %27, align 2
  %28 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 3, i32 0, i64 1, i32 2
  %29 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 3, i32 0, i64 1, i32 4
  store i32 0, i32* %29, align 8
  %30 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 3, i32 0, i64 1, i32 5
  store i8 0, i8* %30, align 4
  %31 = bitcast i8** %28 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %31, i8 0, i64 21, i1 false) #19
  %32 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 4, i32 0, i32 0
  store i8 0, i8* %32, align 8
  %33 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 4, i32 0, i32 1
  store i8 0, i8* %33, align 1
  %34 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 4, i32 0, i32 2
  store i8 0, i8* %34, align 2
  %35 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 4, i32 2
  %36 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 4, i32 4
  store i32 0, i32* %36, align 8
  %37 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 4, i32 5
  store i8 0, i8* %37, align 4
  %38 = bitcast i8** %35 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %38, i8 0, i64 21, i1 false) #19
  %39 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 0, i32 0, i32 0
  store i8 0, i8* %39, align 8
  %40 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 0, i32 0, i32 1
  store i8 0, i8* %40, align 1
  %41 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 0, i32 0, i32 2
  store i8 0, i8* %41, align 2
  %42 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 0, i32 2
  %43 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 0, i32 5
  %44 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 1
  %45 = bitcast i8** %42 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %45, i8 0, i64 11, i1 false) #19
  %46 = bitcast i8** %43 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %46, i8 0, i64 22, i1 false) #19
  %47 = bitcast %"class.ruy::SidePair"* %20 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %47, i8 0, i64 27, i1 false) #19
  store i8 1, i8* %44, align 1
  %48 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 2
  store i8 1, i8* %48, align 1
  %49 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 0, i32 7
  store i32 0, i32* %49, align 8
  %50 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 1, i32 0, i32 0
  store i8 0, i8* %50, align 8
  %51 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 1, i32 0, i32 1
  store i8 0, i8* %51, align 1
  %52 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 1, i32 0, i32 2
  store i8 0, i8* %52, align 2
  %53 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 1, i32 2
  %54 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 1, i32 5
  %55 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 1
  %56 = bitcast i8** %53 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %56, i8 0, i64 11, i1 false) #19
  %57 = bitcast i8** %54 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %57, i8 0, i64 22, i1 false) #19
  store i8 1, i8* %55, align 1
  %58 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 2
  store i8 1, i8* %58, align 1
  %59 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 1, i32 7
  store i32 0, i32* %59, align 8
  %60 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 6, i32 0, i64 0
  store i8 0, i8* %60, align 8
  %61 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 6, i32 0, i64 1
  store i8 0, i8* %61, align 1
  %62 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 7
  store i8* null, i8** %62, align 8
  call void @_ZN3ruy17CreateTrMulParamsILNS_4PathE26EhhhNS_9MulParamsIihEEEEvRKNS_3MatIT0_EERKNS4_IT1_EERKT3_PNS4_IT2_EES1_PNS_11TrMulParamsE(%"struct.ruy::Mat.160"* nonnull dereferenceable(32) %6, %"struct.ruy::Mat.160"* dereferenceable(32) %1, %"class.ruy::MulParams.159"* dereferenceable(40) %2, %"struct.ruy::Mat.160"* %4, i8 zeroext %8, %"struct.ruy::TrMulParams"* nonnull %7)
  call void @_ZN3ruy22HandlePrepackedCachingEPNS_11TrMulParamsEPNS_3CtxE(%"struct.ruy::TrMulParams"* nonnull %7, %"class.ruy::Ctx"* %3)
  call void @_ZN3ruy5TrMulEPNS_11TrMulParamsEPNS_3CtxE(%"struct.ruy::TrMulParams"* nonnull %7, %"class.ruy::Ctx"* %3) #19
  call void @llvm.lifetime.end.p0i8(i64 280, i8* nonnull %19) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %9) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy17CreateTrMulParamsILNS_4PathE26EhhhNS_9MulParamsIihEEEEvRKNS_3MatIT0_EERKNS4_IT1_EERKT3_PNS4_IT2_EES1_PNS_11TrMulParamsE(%"struct.ruy::Mat.160"* dereferenceable(32), %"struct.ruy::Mat.160"* dereferenceable(32), %"class.ruy::MulParams.159"* dereferenceable(40), %"struct.ruy::Mat.160"*, i8 zeroext, %"struct.ruy::TrMulParams"*) local_unnamed_addr #1 comdat {
  %7 = alloca [13 x i8], align 8
  %8 = alloca [13 x i8], align 8
  %9 = alloca [13 x i8], align 8
  %10 = getelementptr inbounds [13 x i8], [13 x i8]* %9, i64 0, i64 0
  %11 = getelementptr inbounds [13 x i8], [13 x i8]* %8, i64 0, i64 0
  %12 = getelementptr inbounds [13 x i8], [13 x i8]* %7, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 13, i8* nonnull %12)
  %13 = bitcast %"struct.ruy::Mat.160"* %0 to i64*
  %14 = load i64, i64* %13, align 8, !noalias !380
  %15 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %0, i64 0, i32 1
  %16 = bitcast %"struct.ruy::MatLayout"* %15 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %12, i8* align 4 %16, i64 13, i1 false)
  %17 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %0, i64 0, i32 2
  %18 = load i8, i8* %17, align 8, !noalias !380
  %19 = zext i8 %18 to i32
  %20 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %0, i64 0, i32 3
  %21 = load i8, i8* %20, align 1, !noalias !380
  %22 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3
  %23 = bitcast %"class.ruy::SidePair.106"* %22 to i24*
  store i24 65536, i24* %23, align 8
  %24 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 0, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %24, i8 -86, i64 5, i1 false)
  %25 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 0, i32 2
  %26 = bitcast i8** %25 to i64*
  store i64 %14, i64* %26, align 8
  %27 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 0, i32 3
  %28 = bitcast %"struct.ruy::MatLayout"* %27 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %28, i8* nonnull align 8 %12, i64 13, i1 false)
  %29 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 0, i32 3, i32 4, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %29, i8 -86, i64 3, i1 false)
  %30 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 0, i32 4
  store i32 %19, i32* %30, align 8
  %31 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 0, i32 5
  store i8 %21, i8* %31, align 4
  call void @llvm.lifetime.end.p0i8(i64 13, i8* nonnull %12)
  call void @llvm.lifetime.start.p0i8(i64 13, i8* nonnull %11)
  %32 = bitcast %"struct.ruy::Mat.160"* %1 to i64*
  %33 = load i64, i64* %32, align 8, !noalias !383
  %34 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %1, i64 0, i32 1
  %35 = bitcast %"struct.ruy::MatLayout"* %34 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %11, i8* align 4 %35, i64 13, i1 false)
  %36 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %1, i64 0, i32 2
  %37 = load i8, i8* %36, align 8, !noalias !383
  %38 = zext i8 %37 to i32
  %39 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %1, i64 0, i32 3
  %40 = load i8, i8* %39, align 1, !noalias !383
  %41 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 1
  %42 = bitcast %"struct.ruy::EMat"* %41 to i24*
  store i24 65536, i24* %42, align 8
  %43 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 1, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %43, i8 -86, i64 5, i1 false)
  %44 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 1, i32 2
  %45 = bitcast i8** %44 to i64*
  store i64 %33, i64* %45, align 8
  %46 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 1, i32 3
  %47 = bitcast %"struct.ruy::MatLayout"* %46 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %47, i8* nonnull align 8 %11, i64 13, i1 false)
  %48 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 1, i32 3, i32 4, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %48, i8 -86, i64 3, i1 false)
  %49 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 1, i32 4
  store i32 %38, i32* %49, align 8
  %50 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 1, i32 5
  store i8 %40, i8* %50, align 4
  call void @llvm.lifetime.end.p0i8(i64 13, i8* nonnull %11)
  call void @llvm.lifetime.start.p0i8(i64 13, i8* nonnull %10)
  %51 = bitcast %"struct.ruy::Mat.160"* %3 to i64*
  %52 = load i64, i64* %51, align 8, !noalias !386
  %53 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %3, i64 0, i32 1
  %54 = bitcast %"struct.ruy::MatLayout"* %53 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %10, i8* align 4 %54, i64 13, i1 false)
  %55 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %3, i64 0, i32 2
  %56 = load i8, i8* %55, align 8, !noalias !386
  %57 = zext i8 %56 to i32
  %58 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %3, i64 0, i32 3
  %59 = load i8, i8* %58, align 1, !noalias !386
  %60 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 4
  %61 = bitcast %"struct.ruy::EMat"* %60 to i24*
  store i24 65536, i24* %61, align 8
  %62 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 4, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %62, i8 -86, i64 5, i1 false)
  %63 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 4, i32 2
  %64 = bitcast i8** %63 to i64*
  store i64 %52, i64* %64, align 8
  %65 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 4, i32 3
  %66 = bitcast %"struct.ruy::MatLayout"* %65 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %66, i8* nonnull align 8 %10, i64 13, i1 false)
  %67 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 4, i32 3, i32 4, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %67, i8 -86, i64 3, i1 false)
  %68 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 4, i32 4
  store i32 %57, i32* %68, align 8
  %69 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 4, i32 5
  store i8 %59, i8* %69, align 4
  call void @llvm.lifetime.end.p0i8(i64 13, i8* nonnull %10)
  %70 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 7
  %71 = bitcast i8** %70 to %"class.ruy::MulParams.159"**
  store %"class.ruy::MulParams.159"* %2, %"class.ruy::MulParams.159"** %71, align 8
  switch i8 %4, label %119 [
    i8 16, label %72
    i8 8, label %73
    i8 2, label %74
  ]

72:                                               ; preds = %6
  tail call void @_ZN3ruy19PopulateTrMulParamsILNS_4PathE16EhhhNS_9MulParamsIihEEEEvPNS_11TrMulParamsE(%"struct.ruy::TrMulParams"* %5) #19
  br label %119

73:                                               ; preds = %6
  tail call void @_ZN3ruy19PopulateTrMulParamsILNS_4PathE8EhhhNS_9MulParamsIihEEEEvPNS_11TrMulParamsE(%"struct.ruy::TrMulParams"* %5) #19
  br label %119

74:                                               ; preds = %6
  %75 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 0
  store i8 2, i8* %75, align 8
  %76 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 0
  %77 = bitcast %"struct.ruy::PEMat"* %76 to i24*
  store i24 65536, i24* %77, align 8
  %78 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 0, i32 3
  %79 = bitcast %"struct.ruy::Type"* %78 to i24*
  store i24 262145, i24* %79, align 8
  %80 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 0, i32 6, i32 3
  store i8 0, i8* %80, align 4
  %81 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 0, i32 3, i32 0
  %82 = load i32, i32* %81, align 4
  %83 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 0, i32 6, i32 0
  store i32 %82, i32* %83, align 4
  %84 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 0, i32 3, i32 1
  %85 = load i32, i32* %84, align 4
  %86 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 0, i32 6, i32 1
  store i32 %85, i32* %86, align 4
  %87 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 0
  store i8 0, i8* %87, align 1
  %88 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 1
  store i8 1, i8* %88, align 1
  %89 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 2
  store i8 1, i8* %89, align 1
  %90 = and i32 %82, 1023
  %91 = icmp eq i32 %90, 0
  %92 = add nsw i32 %82, 64
  %93 = select i1 %91, i32 %92, i32 %82
  %94 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 0, i32 6, i32 2
  store i32 %93, i32* %94, align 4
  %95 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 0, i32 7
  store i32 %19, i32* %95, align 8
  %96 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 1
  %97 = bitcast %"struct.ruy::PEMat"* %96 to i24*
  store i24 65536, i24* %97, align 8
  %98 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 1, i32 3
  %99 = bitcast %"struct.ruy::Type"* %98 to i24*
  store i24 262145, i24* %99, align 8
  %100 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 1, i32 6, i32 3
  store i8 0, i8* %100, align 4
  %101 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 1, i32 3, i32 0
  %102 = load i32, i32* %101, align 4
  %103 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 1, i32 6, i32 0
  store i32 %102, i32* %103, align 4
  %104 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 1, i32 3, i32 1
  %105 = load i32, i32* %104, align 4
  %106 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 1, i32 6, i32 1
  store i32 %105, i32* %106, align 4
  %107 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 0
  store i8 0, i8* %107, align 1
  %108 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 1
  store i8 1, i8* %108, align 1
  %109 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 2
  store i8 1, i8* %109, align 1
  %110 = and i32 %102, 1023
  %111 = icmp eq i32 %110, 0
  %112 = add nsw i32 %102, 64
  %113 = select i1 %111, i32 %112, i32 %102
  %114 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 1, i32 6, i32 2
  store i32 %113, i32* %114, align 4
  %115 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 1, i32 7
  store i32 %38, i32* %115, align 8
  %116 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 1, i32 0, i64 0
  %117 = bitcast void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)** %116 to <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*>*
  store <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*> <void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* @_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEhhEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii, void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* @_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEhhEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii>, <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*>* %117, align 8
  %118 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 2
  store void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)* @_ZN3ruy9RunKernelILNS_4PathE2EhhhNS_9MulParamsIihEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE, void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)** %118, align 8
  br label %119

119:                                              ; preds = %6, %74, %73, %72
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy19PopulateTrMulParamsILNS_4PathE16EhhhNS_9MulParamsIihEEEEvPNS_11TrMulParamsE(%"struct.ruy::TrMulParams"*) local_unnamed_addr #1 comdat {
  %2 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 3
  %3 = load i8, i8* %2, align 4
  %4 = icmp eq i8 %3, 0
  br i1 %4, label %5, label %13

5:                                                ; preds = %1
  %6 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 3
  %7 = load i8, i8* %6, align 4
  %8 = icmp eq i8 %7, 0
  br i1 %8, label %9, label %13

9:                                                ; preds = %5
  %10 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 4, i32 3, i32 3
  %11 = load i8, i8* %10, align 4
  %12 = icmp eq i8 %11, 0
  br i1 %12, label %60, label %13

13:                                               ; preds = %1, %5, %9
  %14 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 0
  store i8 2, i8* %14, align 8
  %15 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0
  %16 = bitcast %"struct.ruy::PEMat"* %15 to i24*
  store i24 65536, i24* %16, align 8
  %17 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 3
  %18 = bitcast %"struct.ruy::Type"* %17 to i24*
  store i24 262145, i24* %18, align 8
  %19 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 3
  store i8 0, i8* %19, align 4
  %20 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 0
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 0
  store i32 %21, i32* %22, align 4
  %23 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 1
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 1
  store i32 %24, i32* %25, align 4
  %26 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 0
  store i8 0, i8* %26, align 1
  %27 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 1
  store i8 1, i8* %27, align 1
  %28 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 2
  store i8 1, i8* %28, align 1
  %29 = and i32 %21, 1023
  %30 = icmp eq i32 %29, 0
  %31 = add nsw i32 %21, 64
  %32 = select i1 %30, i32 %31, i32 %21
  %33 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 2
  store i32 %32, i32* %33, align 4
  %34 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 4
  %35 = load i32, i32* %34, align 8
  %36 = and i32 %35, 255
  %37 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 7
  store i32 %36, i32* %37, align 8
  %38 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1
  %39 = bitcast %"struct.ruy::PEMat"* %38 to i24*
  store i24 65536, i24* %39, align 8
  %40 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 3
  %41 = bitcast %"struct.ruy::Type"* %40 to i24*
  store i24 262145, i24* %41, align 8
  %42 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 3
  store i8 0, i8* %42, align 4
  %43 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 0
  %44 = load i32, i32* %43, align 4
  %45 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 0
  store i32 %44, i32* %45, align 4
  %46 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 1
  %47 = load i32, i32* %46, align 4
  %48 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 1
  store i32 %47, i32* %48, align 4
  %49 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 0
  store i8 0, i8* %49, align 1
  %50 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 1
  store i8 1, i8* %50, align 1
  %51 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 2
  store i8 1, i8* %51, align 1
  %52 = and i32 %44, 1023
  %53 = icmp eq i32 %52, 0
  %54 = add nsw i32 %44, 64
  %55 = select i1 %53, i32 %54, i32 %44
  %56 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 2
  store i32 %55, i32* %56, align 4
  %57 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 4
  %58 = load i32, i32* %57, align 8
  %59 = and i32 %58, 255
  br label %119

60:                                               ; preds = %9
  %61 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 0
  store i8 16, i8* %61, align 8
  %62 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0
  %63 = bitcast %"struct.ruy::PEMat"* %62 to i24*
  store i24 65537, i24* %63, align 8
  %64 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 3
  %65 = bitcast %"struct.ruy::Type"* %64 to i24*
  store i24 262145, i24* %65, align 8
  %66 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 3
  store i8 0, i8* %66, align 4
  %67 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 0
  %68 = load i32, i32* %67, align 4
  %69 = add i32 %68, 3
  %70 = and i32 %69, -4
  %71 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 0
  store i32 %70, i32* %71, align 4
  %72 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 1
  %73 = load i32, i32* %72, align 4
  %74 = add i32 %73, 15
  %75 = and i32 %74, -16
  %76 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 1
  store i32 %75, i32* %76, align 4
  %77 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 0
  store i8 0, i8* %77, align 1
  %78 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 1
  store i8 4, i8* %78, align 1
  %79 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 2
  store i8 16, i8* %79, align 1
  %80 = and i32 %69, 1020
  %81 = icmp eq i32 %80, 0
  %82 = add nsw i32 %70, 64
  %83 = select i1 %81, i32 %82, i32 %70
  %84 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 2
  store i32 %83, i32* %84, align 4
  %85 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 4
  %86 = load i32, i32* %85, align 8
  %87 = shl i32 %86, 24
  %88 = ashr exact i32 %87, 24
  %89 = xor i32 %88, -128
  %90 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 7
  store i32 %89, i32* %90, align 8
  %91 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1
  %92 = bitcast %"struct.ruy::PEMat"* %91 to i24*
  store i24 65537, i24* %92, align 8
  %93 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 3
  %94 = bitcast %"struct.ruy::Type"* %93 to i24*
  store i24 262145, i24* %94, align 8
  %95 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 3
  store i8 0, i8* %95, align 4
  %96 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 0
  %97 = load i32, i32* %96, align 4
  %98 = add i32 %97, 3
  %99 = and i32 %98, -4
  %100 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 0
  store i32 %99, i32* %100, align 4
  %101 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 1
  %102 = load i32, i32* %101, align 4
  %103 = add i32 %102, 15
  %104 = and i32 %103, -16
  %105 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 1
  store i32 %104, i32* %105, align 4
  %106 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 0
  store i8 0, i8* %106, align 1
  %107 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 1
  store i8 4, i8* %107, align 1
  %108 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 2
  store i8 16, i8* %108, align 1
  %109 = and i32 %98, 1020
  %110 = icmp eq i32 %109, 0
  %111 = add nsw i32 %99, 64
  %112 = select i1 %110, i32 %111, i32 %99
  %113 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 2
  store i32 %112, i32* %113, align 4
  %114 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 4
  %115 = load i32, i32* %114, align 8
  %116 = shl i32 %115, 24
  %117 = ashr exact i32 %116, 24
  %118 = xor i32 %117, -128
  br label %119

119:                                              ; preds = %60, %13
  %120 = phi i32 [ %118, %60 ], [ %59, %13 ]
  %121 = phi void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* [ @_ZN3ruy7RunPackILNS_4PathE16ENS_17FixedKernelLayoutILNS_5OrderE0ELi4ELi16EEEhaEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii, %60 ], [ @_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEhhEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii, %13 ]
  %122 = phi void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)* [ @_ZN3ruy9RunKernelILNS_4PathE16EaahNS_9MulParamsIihEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE, %60 ], [ @_ZN3ruy9RunKernelILNS_4PathE2EhhhNS_9MulParamsIihEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE, %13 ]
  %123 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 7
  store i32 %120, i32* %123, align 8
  %124 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 1, i32 0, i64 0
  store void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* %121, void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)** %124, align 8
  %125 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 1, i32 0, i64 1
  store void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* %121, void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)** %125, align 8
  %126 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 2
  store void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)* %122, void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)** %126, align 8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy7RunPackILNS_4PathE16ENS_17FixedKernelLayoutILNS_5OrderE0ELi4ELi16EEEhaEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii(i32, %"struct.ruy::EMat"* dereferenceable(40), %"struct.ruy::PEMat"*, i32, i32) #1 comdat {
  %6 = alloca [32 x i8], align 16
  %7 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 2
  %8 = load i8*, i8** %7, align 8, !noalias !389
  %9 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3, i32 0
  %10 = load i32, i32* %9, align 4
  %11 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3, i32 1
  %12 = load i32, i32* %11, align 4
  %13 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3, i32 2
  %14 = load i32, i32* %13, align 4
  %15 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 2
  %16 = load i8*, i8** %15, align 8, !noalias !392
  %17 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 5
  %18 = bitcast i8** %17 to i32**
  %19 = load i32*, i32** %18, align 8, !noalias !392
  %20 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 6, i32 2
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 7
  %23 = load i32, i32* %22, align 8, !noalias !392
  %24 = getelementptr inbounds [32 x i8], [32 x i8]* %6, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %24) #19
  %25 = trunc i32 %23 to i8
  %26 = xor i8 %25, -128
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %24, i8 %26, i64 32, i1 false) #19
  %27 = icmp slt i32 %3, %4
  br i1 %27, label %28, label %47

28:                                               ; preds = %5
  %29 = icmp eq i32* %19, null
  %30 = sext i32 %3 to i64
  %31 = sext i32 %4 to i64
  %32 = sext i32 %14 to i64
  br label %33

33:                                               ; preds = %33, %28
  %34 = phi i64 [ %30, %28 ], [ %45, %33 ]
  %35 = getelementptr inbounds i32, i32* %19, i64 %34
  %36 = select i1 %29, i32* null, i32* %35
  %37 = mul nsw i64 %34, %32
  %38 = getelementptr inbounds i8, i8* %8, i64 %37
  %39 = trunc i64 %34 to i32
  %40 = sub nsw i32 %12, %39
  %41 = and i32 %39, -16
  %42 = mul nsw i32 %41, %21
  %43 = sext i32 %42 to i64
  %44 = getelementptr inbounds i8, i8* %16, i64 %43
  call void @_ZN3ruy14Pack8bitAvx512EPKaaS1_iiiPaPi(i8* %38, i8 signext -128, i8* nonnull %24, i32 %14, i32 %40, i32 %10, i8* %44, i32* %36) #19
  %45 = add nsw i64 %34, 16
  %46 = icmp slt i64 %45, %31
  br i1 %46, label %33, label %47

47:                                               ; preds = %33, %5
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %24) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy9RunKernelILNS_4PathE16EaahNS_9MulParamsIihEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE(i32, %"class.ruy::SidePair.104"* dereferenceable(112), i8*, %"class.ruy::SidePair.105"* dereferenceable(8), %"class.ruy::SidePair.105"* dereferenceable(8), %"struct.ruy::EMat"*) #1 comdat {
  %7 = alloca %"struct.ruy::KernelParams8bit", align 8
  %8 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 2
  %9 = load i8*, i8** %8, align 8, !noalias !395
  %10 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 0
  %11 = load i32, i32* %10, align 4
  %12 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 1
  %13 = load i32, i32* %12, align 4
  %14 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 2
  %15 = load i32, i32* %14, align 4
  %16 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 4
  %17 = load i32, i32* %16, align 8, !noalias !395
  %18 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 2
  %19 = load i8*, i8** %18, align 8, !noalias !398
  %20 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 5
  %21 = bitcast i8** %20 to i32**
  %22 = load i32*, i32** %21, align 8, !noalias !398
  %23 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 6, i32 0
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 6, i32 2
  %26 = load i32, i32* %25, align 4
  %27 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 7
  %28 = load i32, i32* %27, align 8, !noalias !398
  %29 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 2
  %30 = load i8*, i8** %29, align 8, !noalias !401
  %31 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 5
  %32 = bitcast i8** %31 to i32**
  %33 = load i32*, i32** %32, align 8, !noalias !401
  %34 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 6, i32 2
  %35 = load i32, i32* %34, align 4
  %36 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 7
  %37 = load i32, i32* %36, align 8, !noalias !401
  %38 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %3, i64 0, i32 0, i64 0
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %3, i64 0, i32 0, i64 1
  %41 = load i32, i32* %40, align 4
  %42 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %4, i64 0, i32 0, i64 0
  %43 = load i32, i32* %42, align 4
  %44 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %4, i64 0, i32 0, i64 1
  %45 = load i32, i32* %44, align 4
  %46 = bitcast %"struct.ruy::KernelParams8bit"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1352, i8* nonnull %46) #19
  %47 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 1
  %48 = bitcast i32** %47 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %48, i8 -86, i64 1344, i1 false) #19
  %49 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 27, i64 0
  %50 = bitcast i32* %49 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 4 %50, i8 0, i64 64, i1 false) #19
  %51 = mul nsw i32 %39, %26
  %52 = sext i32 %51 to i64
  %53 = getelementptr inbounds i8, i8* %19, i64 %52
  %54 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 3
  store i8* %53, i8** %54, align 8
  %55 = mul nsw i32 %41, %35
  %56 = sext i32 %55 to i64
  %57 = getelementptr inbounds i8, i8* %30, i64 %56
  %58 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 6
  store i8* %57, i8** %58, align 8
  %59 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 24
  store i8 0, i8* %59, align 8
  %60 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 0
  store i32* %49, i32** %60, align 8
  %61 = bitcast i8* %2 to i32**
  %62 = load i32*, i32** %61, align 8
  %63 = icmp eq i32* %62, null
  br i1 %63, label %65, label %64

64:                                               ; preds = %6
  store i32* %62, i32** %60, align 8
  store i8 1, i8* %59, align 8
  br label %65

65:                                               ; preds = %64, %6
  %66 = phi i8 [ 0, %6 ], [ 1, %64 ]
  %67 = icmp eq i32* %22, null
  br i1 %67, label %71, label %68

68:                                               ; preds = %65
  %69 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 1
  store i32* %22, i32** %69, align 8
  %70 = or i8 %66, 2
  store i8 %70, i8* %59, align 8
  br label %71

71:                                               ; preds = %68, %65
  %72 = phi i8 [ %66, %65 ], [ %70, %68 ]
  %73 = icmp eq i32* %33, null
  br i1 %73, label %77, label %74

74:                                               ; preds = %71
  %75 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 2
  store i32* %33, i32** %75, align 8
  %76 = or i8 %72, 4
  store i8 %76, i8* %59, align 8
  br label %77

77:                                               ; preds = %74, %71
  %78 = phi i8 [ %72, %71 ], [ %76, %74 ]
  %79 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 12
  store i32 %39, i32* %79, align 8
  %80 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 13
  store i32 %41, i32* %80, align 4
  %81 = add nsw i32 %43, -16
  %82 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 14
  store i32 %81, i32* %82, align 8
  %83 = add nsw i32 %45, -16
  %84 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 15
  store i32 %83, i32* %84, align 4
  %85 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 18
  store i32 %26, i32* %85, align 8
  %86 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 19
  store i32 %35, i32* %86, align 4
  %87 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 20
  store i32 %15, i32* %87, align 8
  %88 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 8
  store i32 %28, i32* %88, align 8
  %89 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 9
  store i32 %37, i32* %89, align 4
  %90 = and i32 %17, 255
  %91 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 10
  store i32 %90, i32* %91, align 8
  %92 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 21
  store i32 %24, i32* %92, align 4
  %93 = mul i32 %28, %24
  %94 = mul i32 %93, %37
  %95 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 11
  store i32 %94, i32* %95, align 4
  %96 = getelementptr inbounds i8, i8* %2, i64 16
  %97 = bitcast i8* %96 to i32**
  %98 = load i32*, i32** %97, align 8
  %99 = icmp eq i32* %98, null
  br i1 %99, label %110, label %100

100:                                              ; preds = %77
  %101 = ptrtoint i32* %98 to i64
  %102 = or i8 %78, 24
  store i8 %102, i8* %59, align 8
  %103 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 4
  %104 = bitcast i32** %103 to i64*
  store i64 %101, i64* %104, align 8
  %105 = getelementptr inbounds i8, i8* %2, i64 24
  %106 = bitcast i8* %105 to i64*
  %107 = load i64, i64* %106, align 8
  %108 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 5
  %109 = bitcast i32** %108 to i64*
  store i64 %107, i64* %109, align 8
  br label %147

110:                                              ; preds = %77
  %111 = getelementptr inbounds i8, i8* %2, i64 12
  %112 = bitcast i8* %111 to i32*
  %113 = load i32, i32* %112, align 4
  %114 = icmp sgt i32 %113, 0
  br i1 %114, label %115, label %117

115:                                              ; preds = %110
  %116 = or i8 %78, 16
  store i8 %116, i8* %59, align 8
  br label %117

117:                                              ; preds = %115, %110
  %118 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 29, i64 0
  %119 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 4
  store i32* %118, i32** %119, align 8
  %120 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 30, i64 0
  %121 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 5
  store i32* %120, i32** %121, align 8
  %122 = getelementptr inbounds i8, i8* %2, i64 8
  %123 = bitcast i8* %122 to i32*
  %124 = load i32, i32* %123, align 8
  %125 = insertelement <4 x i32> undef, i32 %124, i32 0
  %126 = shufflevector <4 x i32> %125, <4 x i32> undef, <4 x i32> zeroinitializer
  %127 = bitcast i32* %118 to <4 x i32>*
  store <4 x i32> %126, <4 x i32>* %127, align 4
  %128 = insertelement <4 x i32> undef, i32 %113, i32 0
  %129 = shufflevector <4 x i32> %128, <4 x i32> undef, <4 x i32> zeroinitializer
  %130 = bitcast i32* %120 to <4 x i32>*
  store <4 x i32> %129, <4 x i32>* %130, align 4
  %131 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 29, i64 4
  store i32 %124, i32* %131, align 4
  %132 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 30, i64 4
  store i32 %113, i32* %132, align 4
  %133 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 29, i64 5
  store i32 %124, i32* %133, align 4
  %134 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 30, i64 5
  store i32 %113, i32* %134, align 4
  %135 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 29, i64 6
  store i32 %124, i32* %135, align 4
  %136 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 30, i64 6
  store i32 %113, i32* %136, align 4
  %137 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 29, i64 7
  %138 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 30, i64 7
  %139 = bitcast i32* %137 to <4 x i32>*
  store <4 x i32> %126, <4 x i32>* %139, align 4
  %140 = bitcast i32* %138 to <4 x i32>*
  store <4 x i32> %129, <4 x i32>* %140, align 4
  %141 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 29, i64 11
  %142 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 30, i64 11
  %143 = bitcast i32* %141 to <4 x i32>*
  store <4 x i32> %126, <4 x i32>* %143, align 4
  %144 = bitcast i32* %142 to <4 x i32>*
  store <4 x i32> %129, <4 x i32>* %144, align 4
  %145 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 29, i64 15
  store i32 %124, i32* %145, align 4
  %146 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 30, i64 15
  store i32 %113, i32* %146, align 4
  br label %147

147:                                              ; preds = %100, %117
  %148 = getelementptr inbounds i8, i8* %2, i64 32
  %149 = load i8, i8* %148, align 8
  %150 = zext i8 %149 to i32
  %151 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 22
  store i32 %150, i32* %151, align 8
  %152 = getelementptr inbounds i8, i8* %2, i64 33
  %153 = load i8, i8* %152, align 1
  %154 = zext i8 %153 to i32
  %155 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 23
  store i32 %154, i32* %155, align 4
  %156 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 16
  store i32 %11, i32* %156, align 8
  %157 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 17
  store i32 %13, i32* %157, align 4
  %158 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 25
  store i8 1, i8* %158, align 1
  %159 = mul nsw i32 %41, %15
  %160 = sext i32 %159 to i64
  %161 = getelementptr inbounds i8, i8* %9, i64 %160
  %162 = sext i32 %39 to i64
  %163 = getelementptr inbounds i8, i8* %161, i64 %162
  %164 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 7
  store i8* %163, i8** %164, align 8
  %165 = icmp eq i32 %13, 1
  br i1 %165, label %166, label %167

166:                                              ; preds = %147
  call void @_ZN3ruy25Kernel8bitAvx512SingleColERKNS_16KernelParams8bitILi16ELi16EEE(%"struct.ruy::KernelParams8bit"* nonnull dereferenceable(1352) %7) #19
  br label %168

167:                                              ; preds = %147
  call void @_ZN3ruy16Kernel8bitAvx512ERKNS_16KernelParams8bitILi16ELi16EEE(%"struct.ruy::KernelParams8bit"* nonnull dereferenceable(1352) %7) #19
  br label %168

168:                                              ; preds = %166, %167
  call void @llvm.lifetime.end.p0i8(i64 1352, i8* nonnull %46) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEhhEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii(i32, %"struct.ruy::EMat"* dereferenceable(40), %"struct.ruy::PEMat"*, i32, i32) #1 comdat {
  %6 = alloca %"struct.ruy::Mat.160", align 8
  %7 = alloca %"struct.ruy::PMat.161", align 8
  %8 = bitcast %"struct.ruy::Mat.160"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %8) #19
  %9 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %6, i64 0, i32 2
  %10 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %6, i64 0, i32 3
  %11 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %6, i64 0, i32 1
  %12 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 2
  %13 = bitcast i8** %12 to i64*
  %14 = bitcast %"struct.ruy::Mat.160"* %6 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %14, i8 -86, i64 32, i1 false)
  %15 = load i64, i64* %13, align 8, !noalias !404
  %16 = bitcast %"struct.ruy::Mat.160"* %6 to i64*
  store i64 %15, i64* %16, align 8, !alias.scope !404
  %17 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3
  %18 = bitcast %"struct.ruy::MatLayout"* %11 to i8*
  %19 = bitcast %"struct.ruy::MatLayout"* %17 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %18, i8* align 4 %19, i64 13, i1 false) #19
  %20 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 4
  %21 = load i32, i32* %20, align 8, !noalias !404
  %22 = trunc i32 %21 to i8
  store i8 %22, i8* %9, align 8, !alias.scope !404
  %23 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 5
  %24 = load i8, i8* %23, align 4, !noalias !404
  store i8 %24, i8* %10, align 1, !alias.scope !404
  %25 = bitcast %"struct.ruy::PMat.161"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %25) #19
  %26 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %7, i64 0, i32 3
  %27 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 2
  %28 = bitcast i8** %27 to i64*
  %29 = bitcast %"struct.ruy::PMat.161"* %7 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %29, i8 -86, i64 40, i1 false)
  %30 = load i64, i64* %28, align 8, !noalias !407
  %31 = bitcast %"struct.ruy::PMat.161"* %7 to i64*
  store i64 %30, i64* %31, align 8, !alias.scope !407
  %32 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 5
  %33 = bitcast i8** %32 to i64*
  %34 = load i64, i64* %33, align 8, !noalias !407
  %35 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %7, i64 0, i32 1
  %36 = bitcast i32** %35 to i64*
  store i64 %34, i64* %36, align 8, !alias.scope !407
  %37 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 6
  %38 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %7, i64 0, i32 2
  %39 = bitcast %"struct.ruy::PMatLayout"* %38 to i8*
  %40 = bitcast %"struct.ruy::PMatLayout"* %37 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %39, i8* align 4 %40, i64 16, i1 false) #19
  %41 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 7
  %42 = load i32, i32* %41, align 8, !noalias !407
  store i32 %42, i32* %26, align 8, !alias.scope !407
  call void @_ZN3ruy8PackImplILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEhhiE3RunENS_6TuningERKNS_3MatIhEEPNS_4PMatIhEEii(i32 %0, %"struct.ruy::Mat.160"* nonnull dereferenceable(32) %6, %"struct.ruy::PMat.161"* nonnull %7, i32 %3, i32 %4)
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %25) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %8) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy9RunKernelILNS_4PathE2EhhhNS_9MulParamsIihEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE(i32, %"class.ruy::SidePair.104"* dereferenceable(112), i8*, %"class.ruy::SidePair.105"* dereferenceable(8), %"class.ruy::SidePair.105"* dereferenceable(8), %"struct.ruy::EMat"*) #1 comdat {
  %7 = alloca %"struct.ruy::Kernel.162", align 1
  %8 = alloca %"struct.ruy::Mat.160", align 8
  %9 = alloca %"struct.ruy::PMat.161", align 8
  %10 = alloca %"struct.ruy::PMat.161", align 8
  %11 = bitcast %"struct.ruy::Mat.160"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %11) #19
  %12 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %8, i64 0, i32 2
  %13 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %8, i64 0, i32 3
  %14 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %8, i64 0, i32 1
  %15 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 2
  %16 = bitcast i8** %15 to i64*
  %17 = bitcast %"struct.ruy::Mat.160"* %8 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %17, i8 -86, i64 32, i1 false)
  %18 = load i64, i64* %16, align 8, !noalias !410
  %19 = bitcast %"struct.ruy::Mat.160"* %8 to i64*
  store i64 %18, i64* %19, align 8, !alias.scope !410
  %20 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3
  %21 = bitcast %"struct.ruy::MatLayout"* %14 to i8*
  %22 = bitcast %"struct.ruy::MatLayout"* %20 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %21, i8* align 4 %22, i64 13, i1 false) #19
  %23 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 4
  %24 = load i32, i32* %23, align 8, !noalias !410
  %25 = trunc i32 %24 to i8
  store i8 %25, i8* %12, align 8, !alias.scope !410
  %26 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 5
  %27 = load i8, i8* %26, align 4, !noalias !410
  store i8 %27, i8* %13, align 1, !alias.scope !410
  %28 = bitcast %"struct.ruy::PMat.161"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %28) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %28, i8 -86, i64 40, i1 false) #19, !alias.scope !413
  %29 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %9, i64 0, i32 3
  %30 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 2
  %31 = bitcast i8** %30 to i64*
  %32 = load i64, i64* %31, align 8, !noalias !413
  %33 = bitcast %"struct.ruy::PMat.161"* %9 to i64*
  store i64 %32, i64* %33, align 8, !alias.scope !413
  %34 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 5
  %35 = bitcast i8** %34 to i64*
  %36 = load i64, i64* %35, align 8, !noalias !413
  %37 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %9, i64 0, i32 1
  %38 = bitcast i32** %37 to i64*
  store i64 %36, i64* %38, align 8, !alias.scope !413
  %39 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 6
  %40 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %9, i64 0, i32 2
  %41 = bitcast %"struct.ruy::PMatLayout"* %40 to i8*
  %42 = bitcast %"struct.ruy::PMatLayout"* %39 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %41, i8* align 4 %42, i64 16, i1 false) #19
  %43 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 7
  %44 = load i32, i32* %43, align 8, !noalias !413
  store i32 %44, i32* %29, align 8, !alias.scope !413
  %45 = bitcast %"struct.ruy::PMat.161"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %45) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %45, i8 -86, i64 40, i1 false) #19, !alias.scope !416
  %46 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %10, i64 0, i32 3
  %47 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 2
  %48 = bitcast i8** %47 to i64*
  %49 = load i64, i64* %48, align 8, !noalias !416
  %50 = bitcast %"struct.ruy::PMat.161"* %10 to i64*
  store i64 %49, i64* %50, align 8, !alias.scope !416
  %51 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 5
  %52 = bitcast i8** %51 to i64*
  %53 = load i64, i64* %52, align 8, !noalias !416
  %54 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %10, i64 0, i32 1
  %55 = bitcast i32** %54 to i64*
  store i64 %53, i64* %55, align 8, !alias.scope !416
  %56 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 6
  %57 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %10, i64 0, i32 2
  %58 = bitcast %"struct.ruy::PMatLayout"* %57 to i8*
  %59 = bitcast %"struct.ruy::PMatLayout"* %56 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %58, i8* align 4 %59, i64 16, i1 false) #19
  %60 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 7
  %61 = load i32, i32* %60, align 8, !noalias !416
  store i32 %61, i32* %46, align 8, !alias.scope !416
  %62 = bitcast i8* %2 to %"class.ruy::MulParams.159"*
  %63 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %3, i64 0, i32 0, i64 0
  %64 = load i32, i32* %63, align 4
  %65 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %3, i64 0, i32 0, i64 1
  %66 = load i32, i32* %65, align 4
  %67 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %4, i64 0, i32 0, i64 0
  %68 = load i32, i32* %67, align 4
  %69 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %4, i64 0, i32 0, i64 1
  %70 = load i32, i32* %69, align 4
  %71 = getelementptr inbounds %"struct.ruy::Kernel.162", %"struct.ruy::Kernel.162"* %7, i64 0, i32 0
  call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %71) #19
  store i8 -86, i8* %71, align 1
  call void @_ZNK3ruy6KernelILNS_4PathE2EhhhNS_9MulParamsIihEEE3RunERKNS_4PMatIhEES8_RKS3_iiiiPNS_3MatIhEE(%"struct.ruy::Kernel.162"* nonnull %7, %"struct.ruy::PMat.161"* nonnull dereferenceable(40) %9, %"struct.ruy::PMat.161"* nonnull dereferenceable(40) %10, %"class.ruy::MulParams.159"* dereferenceable(40) %62, i32 %64, i32 %66, i32 %68, i32 %70, %"struct.ruy::Mat.160"* nonnull %8) #19
  call void @llvm.lifetime.end.p0i8(i64 1, i8* nonnull %71) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %45) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %28) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %11) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy8PackImplILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEhhiE3RunENS_6TuningERKNS_3MatIhEEPNS_4PMatIhEEii(i32, %"struct.ruy::Mat.160"* dereferenceable(32), %"struct.ruy::PMat.161"*, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %6 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %2, i64 0, i32 1
  %7 = load i32*, i32** %6, align 8
  %8 = icmp slt i32 %3, %4
  br i1 %8, label %9, label %33

9:                                                ; preds = %5
  %10 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %2, i64 0, i32 2, i32 0
  %11 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %1, i64 0, i32 1, i32 1
  %12 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %1, i64 0, i32 1, i32 0
  %13 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %2, i64 0, i32 3
  %14 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %1, i64 0, i32 0, i32 0
  %15 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %1, i64 0, i32 1, i32 3
  %16 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %1, i64 0, i32 1, i32 2
  %17 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %2, i64 0, i32 0
  %18 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %2, i64 0, i32 2, i32 4, i32 1
  %19 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %2, i64 0, i32 2, i32 4, i32 2
  %20 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %2, i64 0, i32 2, i32 3
  %21 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %2, i64 0, i32 2, i32 2
  %22 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %2, i64 0, i32 2, i32 4, i32 0
  %23 = icmp eq i32* %7, null
  %24 = sext i32 %3 to i64
  %25 = sext i32 %4 to i64
  br label %26

26:                                               ; preds = %107, %9
  %27 = phi i64 [ %24, %9 ], [ %108, %107 ]
  %28 = load i32, i32* %10, align 8
  %29 = icmp sgt i32 %28, 0
  br i1 %29, label %30, label %34

30:                                               ; preds = %26
  %31 = trunc i64 %27 to i32
  %32 = trunc i64 %27 to i32
  br label %36

33:                                               ; preds = %107, %5
  ret void

34:                                               ; preds = %64, %26
  %35 = phi i32 [ 0, %26 ], [ %68, %64 ]
  br i1 %23, label %107, label %105

36:                                               ; preds = %30, %64
  %37 = phi i32 [ %102, %64 ], [ 0, %30 ]
  %38 = phi i32 [ %68, %64 ], [ 0, %30 ]
  %39 = load i32, i32* %11, align 4
  %40 = sext i32 %39 to i64
  %41 = icmp slt i64 %27, %40
  br i1 %41, label %42, label %61

42:                                               ; preds = %36
  %43 = load i32, i32* %12, align 8
  %44 = icmp slt i32 %37, %43
  br i1 %44, label %45, label %61

45:                                               ; preds = %42
  %46 = load i8*, i8** %14, align 8
  %47 = load i8, i8* %15, align 4
  %48 = load i32, i32* %16, align 4
  switch i8 %47, label %49 [
    i8 0, label %50
    i8 1, label %52
  ]

49:                                               ; preds = %45
  br label %50

50:                                               ; preds = %49, %45
  %51 = phi i32 [ 1, %45 ], [ %48, %49 ]
  br label %52

52:                                               ; preds = %45, %50
  %53 = phi i32 [ %51, %50 ], [ %48, %45 ]
  %54 = phi i32 [ %48, %50 ], [ 1, %45 ]
  %55 = mul nsw i32 %53, %37
  %56 = mul nsw i32 %54, %32
  %57 = add nsw i32 %56, %55
  %58 = sext i32 %57 to i64
  %59 = getelementptr inbounds i8, i8* %46, i64 %58
  %60 = load i8, i8* %59, align 1
  br label %64

61:                                               ; preds = %42, %36
  %62 = load i32, i32* %13, align 8
  %63 = trunc i32 %62 to i8
  br label %64

64:                                               ; preds = %61, %52
  %65 = phi i32 [ %31, %61 ], [ %32, %52 ]
  %66 = phi i8 [ %63, %61 ], [ %60, %52 ]
  %67 = zext i8 %66 to i32
  %68 = add nuw nsw i32 %38, %67
  %69 = load i8*, i8** %17, align 8
  %70 = load i8, i8* %18, align 1
  %71 = zext i8 %70 to i32
  %72 = sub nsw i32 0, %71
  %73 = and i32 %37, %72
  %74 = load i8, i8* %19, align 1
  %75 = zext i8 %74 to i32
  %76 = sub nsw i32 0, %75
  %77 = and i32 %65, %76
  %78 = load i8, i8* %20, align 4
  %79 = icmp eq i8 %78, 0
  %80 = load i32, i32* %21, align 4
  %81 = select i1 %79, i32 %75, i32 %80
  %82 = icmp eq i8 %78, 1
  %83 = select i1 %82, i32 %71, i32 %80
  %84 = mul nsw i32 %81, %73
  %85 = mul nsw i32 %83, %77
  %86 = sub nsw i32 %37, %73
  %87 = sub nsw i32 %65, %77
  %88 = load i8, i8* %22, align 1
  %89 = icmp eq i8 %88, 0
  %90 = select i1 %89, i8 1, i8 %74
  %91 = zext i8 %90 to i32
  %92 = icmp eq i8 %88, 1
  %93 = select i1 %92, i8 1, i8 %70
  %94 = zext i8 %93 to i32
  %95 = mul nsw i32 %86, %91
  %96 = mul nsw i32 %87, %94
  %97 = add i32 %84, %85
  %98 = add i32 %97, %96
  %99 = add i32 %98, %95
  %100 = sext i32 %99 to i64
  %101 = getelementptr inbounds i8, i8* %69, i64 %100
  store i8 %66, i8* %101, align 1
  %102 = add nuw nsw i32 %37, 1
  %103 = load i32, i32* %10, align 8
  %104 = icmp slt i32 %102, %103
  br i1 %104, label %36, label %34

105:                                              ; preds = %34
  %106 = getelementptr inbounds i32, i32* %7, i64 %27
  store i32 %35, i32* %106, align 4
  br label %107

107:                                              ; preds = %34, %105
  %108 = add nsw i64 %27, 1
  %109 = icmp eq i64 %108, %25
  br i1 %109, label %33, label %26
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK3ruy6KernelILNS_4PathE2EhhhNS_9MulParamsIihEEE3RunERKNS_4PMatIhEES8_RKS3_iiiiPNS_3MatIhEE(%"struct.ruy::Kernel.162"*, %"struct.ruy::PMat.161"* dereferenceable(40), %"struct.ruy::PMat.161"* dereferenceable(40), %"class.ruy::MulParams.159"* dereferenceable(40), i32, i32, i32, i32, %"struct.ruy::Mat.160"*) local_unnamed_addr #1 comdat align 2 {
  %10 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %8, i64 0, i32 1, i32 0
  %11 = load i32, i32* %10, align 4
  %12 = icmp slt i32 %11, %6
  %13 = select i1 %12, i32 %11, i32 %6
  %14 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %8, i64 0, i32 1, i32 1
  %15 = load i32, i32* %14, align 4
  %16 = icmp slt i32 %15, %7
  %17 = select i1 %16, i32 %15, i32 %7
  %18 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %1, i64 0, i32 2, i32 0
  %19 = load i32, i32* %18, align 8
  %20 = icmp sgt i32 %13, %4
  br i1 %20, label %21, label %60

21:                                               ; preds = %9
  %22 = icmp sgt i32 %17, %5
  %23 = icmp sgt i32 %19, 0
  %24 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %1, i64 0, i32 0
  %25 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %1, i64 0, i32 2, i32 4, i32 1
  %26 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %1, i64 0, i32 2, i32 4, i32 2
  %27 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %1, i64 0, i32 2, i32 3
  %28 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %1, i64 0, i32 2, i32 2
  %29 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %1, i64 0, i32 2, i32 4, i32 0
  %30 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %2, i64 0, i32 0
  %31 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %2, i64 0, i32 2, i32 4, i32 1
  %32 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %2, i64 0, i32 2, i32 4, i32 2
  %33 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %2, i64 0, i32 2, i32 3
  %34 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %2, i64 0, i32 2, i32 2
  %35 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %2, i64 0, i32 2, i32 4, i32 0
  %36 = getelementptr inbounds %"class.ruy::MulParams.159", %"class.ruy::MulParams.159"* %3, i64 0, i32 0
  %37 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %1, i64 0, i32 3
  %38 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %2, i64 0, i32 1
  %39 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %2, i64 0, i32 3
  %40 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %1, i64 0, i32 1
  %41 = getelementptr inbounds %"class.ruy::MulParams.159", %"class.ruy::MulParams.159"* %3, i64 0, i32 3
  %42 = getelementptr inbounds %"class.ruy::MulParams.159", %"class.ruy::MulParams.159"* %3, i64 0, i32 1
  %43 = getelementptr inbounds %"class.ruy::MulParams.159", %"class.ruy::MulParams.159"* %3, i64 0, i32 4
  %44 = getelementptr inbounds %"class.ruy::MulParams.159", %"class.ruy::MulParams.159"* %3, i64 0, i32 2
  %45 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %8, i64 0, i32 2
  %46 = getelementptr inbounds %"class.ruy::MulParams.159", %"class.ruy::MulParams.159"* %3, i64 0, i32 6
  %47 = getelementptr inbounds %"class.ruy::MulParams.159", %"class.ruy::MulParams.159"* %3, i64 0, i32 5
  %48 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %8, i64 0, i32 0, i32 0
  %49 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %8, i64 0, i32 1, i32 3
  %50 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %8, i64 0, i32 1, i32 2
  %51 = sext i32 %5 to i64
  %52 = sext i32 %17 to i64
  %53 = sext i32 %4 to i64
  %54 = sext i32 %13 to i64
  br label %55

55:                                               ; preds = %21, %113
  %56 = phi i64 [ %53, %21 ], [ %114, %113 ]
  br i1 %22, label %57, label %113

57:                                               ; preds = %55
  %58 = trunc i64 %56 to i32
  %59 = trunc i64 %56 to i32
  br label %61

60:                                               ; preds = %113, %9
  ret void

61:                                               ; preds = %57, %209
  %62 = phi i64 [ %51, %57 ], [ %218, %209 ]
  br i1 %23, label %63, label %116

63:                                               ; preds = %61
  %64 = load i8*, i8** %24, align 8
  %65 = load i8, i8* %25, align 1
  %66 = zext i8 %65 to i32
  %67 = sub nsw i32 0, %66
  %68 = load i8, i8* %26, align 1
  %69 = zext i8 %68 to i32
  %70 = sub nsw i32 0, %69
  %71 = and i32 %58, %70
  %72 = load i8, i8* %27, align 4
  %73 = icmp eq i8 %72, 0
  %74 = load i32, i32* %28, align 4
  %75 = select i1 %73, i32 %69, i32 %74
  %76 = icmp eq i8 %72, 1
  %77 = select i1 %76, i32 %66, i32 %74
  %78 = mul nsw i32 %77, %71
  %79 = sub nsw i32 %58, %71
  %80 = load i8, i8* %29, align 1
  %81 = icmp eq i8 %80, 0
  %82 = select i1 %81, i8 1, i8 %68
  %83 = zext i8 %82 to i32
  %84 = icmp eq i8 %80, 1
  %85 = select i1 %84, i8 1, i8 %65
  %86 = zext i8 %85 to i32
  %87 = mul nsw i32 %79, %86
  %88 = load i8*, i8** %30, align 8
  %89 = load i8, i8* %31, align 1
  %90 = zext i8 %89 to i32
  %91 = sub nsw i32 0, %90
  %92 = load i8, i8* %32, align 1
  %93 = zext i8 %92 to i32
  %94 = sub nsw i32 0, %93
  %95 = trunc i64 %62 to i32
  %96 = and i32 %95, %94
  %97 = load i8, i8* %33, align 4
  %98 = icmp eq i8 %97, 0
  %99 = load i32, i32* %34, align 4
  %100 = select i1 %98, i32 %93, i32 %99
  %101 = icmp eq i8 %97, 1
  %102 = select i1 %101, i32 %90, i32 %99
  %103 = mul nsw i32 %102, %96
  %104 = sub nsw i32 %95, %96
  %105 = load i8, i8* %35, align 1
  %106 = icmp eq i8 %105, 0
  %107 = select i1 %106, i8 1, i8 %92
  %108 = zext i8 %107 to i32
  %109 = icmp eq i8 %105, 1
  %110 = select i1 %109, i8 1, i8 %89
  %111 = zext i8 %110 to i32
  %112 = mul nsw i32 %104, %111
  br label %120

113:                                              ; preds = %209, %55
  %114 = add nsw i64 %56, 1
  %115 = icmp slt i64 %114, %54
  br i1 %115, label %55, label %60

116:                                              ; preds = %120, %61
  %117 = phi i32 [ 0, %61 ], [ %146, %120 ]
  %118 = load i32*, i32** %36, align 8
  %119 = icmp eq i32* %118, null
  br i1 %119, label %153, label %149

120:                                              ; preds = %120, %63
  %121 = phi i32 [ 0, %63 ], [ %147, %120 ]
  %122 = phi i32 [ 0, %63 ], [ %146, %120 ]
  %123 = and i32 %121, %67
  %124 = mul nsw i32 %75, %123
  %125 = sub nsw i32 %121, %123
  %126 = mul nsw i32 %125, %83
  %127 = add i32 %124, %78
  %128 = add i32 %127, %87
  %129 = add i32 %128, %126
  %130 = sext i32 %129 to i64
  %131 = getelementptr inbounds i8, i8* %64, i64 %130
  %132 = load i8, i8* %131, align 1
  %133 = zext i8 %132 to i32
  %134 = and i32 %121, %91
  %135 = mul nsw i32 %100, %134
  %136 = sub nsw i32 %121, %134
  %137 = mul nsw i32 %136, %108
  %138 = add i32 %135, %103
  %139 = add i32 %138, %112
  %140 = add i32 %139, %137
  %141 = sext i32 %140 to i64
  %142 = getelementptr inbounds i8, i8* %88, i64 %141
  %143 = load i8, i8* %142, align 1
  %144 = zext i8 %143 to i32
  %145 = mul nuw nsw i32 %144, %133
  %146 = add nuw nsw i32 %145, %122
  %147 = add nuw nsw i32 %121, 1
  %148 = icmp eq i32 %147, %19
  br i1 %148, label %116, label %120

149:                                              ; preds = %116
  %150 = getelementptr inbounds i32, i32* %118, i64 %56
  %151 = load i32, i32* %150, align 4
  %152 = add nsw i32 %151, %117
  br label %153

153:                                              ; preds = %116, %149
  %154 = phi i32 [ %117, %116 ], [ %152, %149 ]
  %155 = load i32, i32* %37, align 8
  %156 = icmp eq i32 %155, 0
  br i1 %156, label %163, label %157

157:                                              ; preds = %153
  %158 = load i32*, i32** %38, align 8
  %159 = getelementptr inbounds i32, i32* %158, i64 %62
  %160 = load i32, i32* %159, align 4
  %161 = mul nsw i32 %160, %155
  %162 = sub nsw i32 %154, %161
  br label %163

163:                                              ; preds = %153, %157
  %164 = phi i32 [ %154, %153 ], [ %162, %157 ]
  %165 = load i32, i32* %39, align 8
  %166 = icmp eq i32 %165, 0
  br i1 %166, label %178, label %167

167:                                              ; preds = %163
  %168 = load i32*, i32** %40, align 8
  %169 = getelementptr inbounds i32, i32* %168, i64 %56
  %170 = load i32, i32* %169, align 4
  %171 = mul nsw i32 %170, %165
  %172 = sub nsw i32 %164, %171
  %173 = or i1 %156, %166
  br i1 %173, label %178, label %174

174:                                              ; preds = %167
  %175 = mul i32 %155, %19
  %176 = mul i32 %175, %165
  %177 = add nsw i32 %172, %176
  br label %178

178:                                              ; preds = %163, %167, %174
  %179 = phi i32 [ %172, %167 ], [ %177, %174 ], [ %164, %163 ]
  %180 = load i32*, i32** %41, align 8
  %181 = icmp eq i32* %180, null
  %182 = getelementptr inbounds i32, i32* %180, i64 %56
  %183 = select i1 %181, i32* %42, i32* %182
  %184 = load i32, i32* %183, align 4
  %185 = load i32*, i32** %43, align 8
  %186 = icmp eq i32* %185, null
  %187 = getelementptr inbounds i32, i32* %185, i64 %56
  %188 = select i1 %186, i32* %44, i32* %187
  %189 = load i32, i32* %188, align 4
  %190 = tail call i32 @_ZN3ruy6detail29MultiplyByQuantizedMultiplierEiii(i32 %179, i32 %184, i32 %189) #19
  %191 = load i8, i8* %45, align 8
  %192 = zext i8 %191 to i32
  %193 = add nsw i32 %190, %192
  %194 = load i8, i8* %46, align 1
  %195 = zext i8 %194 to i32
  %196 = icmp sgt i32 %193, %195
  %197 = select i1 %196, i32 %195, i32 %193
  %198 = load i8, i8* %47, align 8
  %199 = zext i8 %198 to i32
  %200 = icmp slt i32 %197, %199
  %201 = select i1 %200, i32 %199, i32 %197
  %202 = trunc i32 %201 to i8
  %203 = load i8*, i8** %48, align 8
  %204 = load i8, i8* %49, align 4
  %205 = load i32, i32* %50, align 4
  switch i8 %204, label %206 [
    i8 0, label %207
    i8 1, label %209
  ]

206:                                              ; preds = %178
  br label %207

207:                                              ; preds = %206, %178
  %208 = phi i32 [ 1, %178 ], [ %205, %206 ]
  br label %209

209:                                              ; preds = %178, %207
  %210 = phi i32 [ %208, %207 ], [ %205, %178 ]
  %211 = phi i32 [ %205, %207 ], [ 1, %178 ]
  %212 = mul nsw i32 %210, %59
  %213 = trunc i64 %62 to i32
  %214 = mul nsw i32 %211, %213
  %215 = add nsw i32 %214, %212
  %216 = sext i32 %215 to i64
  %217 = getelementptr inbounds i8, i8* %203, i64 %216
  store i8 %202, i8* %217, align 1
  %218 = add nsw i64 %62, 1
  %219 = icmp slt i64 %218, %52
  br i1 %219, label %61, label %113
}

declare i32 @_ZN3ruy6detail29MultiplyByQuantizedMultiplierEiii(i32, i32, i32) local_unnamed_addr #5

declare void @_ZN3ruy14Pack8bitAvx512EPKaaS1_iiiPaPi(i8*, i8 signext, i8*, i32, i32, i32, i8*, i32*) local_unnamed_addr #5

declare void @_ZN3ruy25Kernel8bitAvx512SingleColERKNS_16KernelParams8bitILi16ELi16EEE(%"struct.ruy::KernelParams8bit"* dereferenceable(1352)) local_unnamed_addr #5

declare void @_ZN3ruy16Kernel8bitAvx512ERKNS_16KernelParams8bitILi16ELi16EEE(%"struct.ruy::KernelParams8bit"* dereferenceable(1352)) local_unnamed_addr #5

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy19PopulateTrMulParamsILNS_4PathE8EhhhNS_9MulParamsIihEEEEvPNS_11TrMulParamsE(%"struct.ruy::TrMulParams"*) local_unnamed_addr #1 comdat {
  %2 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 3
  %3 = load i8, i8* %2, align 4
  %4 = icmp eq i8 %3, 0
  br i1 %4, label %5, label %13

5:                                                ; preds = %1
  %6 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 3
  %7 = load i8, i8* %6, align 4
  %8 = icmp eq i8 %7, 0
  br i1 %8, label %9, label %13

9:                                                ; preds = %5
  %10 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 4, i32 3, i32 3
  %11 = load i8, i8* %10, align 4
  %12 = icmp eq i8 %11, 0
  br i1 %12, label %60, label %13

13:                                               ; preds = %1, %5, %9
  %14 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 0
  store i8 2, i8* %14, align 8
  %15 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0
  %16 = bitcast %"struct.ruy::PEMat"* %15 to i24*
  store i24 65536, i24* %16, align 8
  %17 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 3
  %18 = bitcast %"struct.ruy::Type"* %17 to i24*
  store i24 262145, i24* %18, align 8
  %19 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 3
  store i8 0, i8* %19, align 4
  %20 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 0
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 0
  store i32 %21, i32* %22, align 4
  %23 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 1
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 1
  store i32 %24, i32* %25, align 4
  %26 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 0
  store i8 0, i8* %26, align 1
  %27 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 1
  store i8 1, i8* %27, align 1
  %28 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 2
  store i8 1, i8* %28, align 1
  %29 = and i32 %21, 1023
  %30 = icmp eq i32 %29, 0
  %31 = add nsw i32 %21, 64
  %32 = select i1 %30, i32 %31, i32 %21
  %33 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 2
  store i32 %32, i32* %33, align 4
  %34 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 4
  %35 = load i32, i32* %34, align 8
  %36 = and i32 %35, 255
  %37 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 7
  store i32 %36, i32* %37, align 8
  %38 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1
  %39 = bitcast %"struct.ruy::PEMat"* %38 to i24*
  store i24 65536, i24* %39, align 8
  %40 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 3
  %41 = bitcast %"struct.ruy::Type"* %40 to i24*
  store i24 262145, i24* %41, align 8
  %42 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 3
  store i8 0, i8* %42, align 4
  %43 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 0
  %44 = load i32, i32* %43, align 4
  %45 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 0
  store i32 %44, i32* %45, align 4
  %46 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 1
  %47 = load i32, i32* %46, align 4
  %48 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 1
  store i32 %47, i32* %48, align 4
  %49 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 0
  store i8 0, i8* %49, align 1
  %50 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 1
  store i8 1, i8* %50, align 1
  %51 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 2
  store i8 1, i8* %51, align 1
  %52 = and i32 %44, 1023
  %53 = icmp eq i32 %52, 0
  %54 = add nsw i32 %44, 64
  %55 = select i1 %53, i32 %54, i32 %44
  %56 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 2
  store i32 %55, i32* %56, align 4
  %57 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 4
  %58 = load i32, i32* %57, align 8
  %59 = and i32 %58, 255
  br label %119

60:                                               ; preds = %9
  %61 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 0
  store i8 8, i8* %61, align 8
  %62 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0
  %63 = bitcast %"struct.ruy::PEMat"* %62 to i24*
  store i24 65537, i24* %63, align 8
  %64 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 3
  %65 = bitcast %"struct.ruy::Type"* %64 to i24*
  store i24 262145, i24* %65, align 8
  %66 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 3
  store i8 0, i8* %66, align 4
  %67 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 0
  %68 = load i32, i32* %67, align 4
  %69 = add i32 %68, 3
  %70 = and i32 %69, -4
  %71 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 0
  store i32 %70, i32* %71, align 4
  %72 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 1
  %73 = load i32, i32* %72, align 4
  %74 = add i32 %73, 7
  %75 = and i32 %74, -8
  %76 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 1
  store i32 %75, i32* %76, align 4
  %77 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 0
  store i8 0, i8* %77, align 1
  %78 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 1
  store i8 4, i8* %78, align 1
  %79 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 2
  store i8 8, i8* %79, align 1
  %80 = and i32 %69, 1020
  %81 = icmp eq i32 %80, 0
  %82 = add nsw i32 %70, 64
  %83 = select i1 %81, i32 %82, i32 %70
  %84 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 2
  store i32 %83, i32* %84, align 4
  %85 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 4
  %86 = load i32, i32* %85, align 8
  %87 = shl i32 %86, 24
  %88 = ashr exact i32 %87, 24
  %89 = xor i32 %88, -128
  %90 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 7
  store i32 %89, i32* %90, align 8
  %91 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1
  %92 = bitcast %"struct.ruy::PEMat"* %91 to i24*
  store i24 65537, i24* %92, align 8
  %93 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 3
  %94 = bitcast %"struct.ruy::Type"* %93 to i24*
  store i24 262145, i24* %94, align 8
  %95 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 3
  store i8 0, i8* %95, align 4
  %96 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 0
  %97 = load i32, i32* %96, align 4
  %98 = add i32 %97, 3
  %99 = and i32 %98, -4
  %100 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 0
  store i32 %99, i32* %100, align 4
  %101 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 1
  %102 = load i32, i32* %101, align 4
  %103 = add i32 %102, 7
  %104 = and i32 %103, -8
  %105 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 1
  store i32 %104, i32* %105, align 4
  %106 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 0
  store i8 0, i8* %106, align 1
  %107 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 1
  store i8 4, i8* %107, align 1
  %108 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 2
  store i8 8, i8* %108, align 1
  %109 = and i32 %98, 1020
  %110 = icmp eq i32 %109, 0
  %111 = add nsw i32 %99, 64
  %112 = select i1 %110, i32 %111, i32 %99
  %113 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 2
  store i32 %112, i32* %113, align 4
  %114 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 4
  %115 = load i32, i32* %114, align 8
  %116 = shl i32 %115, 24
  %117 = ashr exact i32 %116, 24
  %118 = xor i32 %117, -128
  br label %119

119:                                              ; preds = %60, %13
  %120 = phi i32 [ %118, %60 ], [ %59, %13 ]
  %121 = phi void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* [ @_ZN3ruy7RunPackILNS_4PathE8ENS_17FixedKernelLayoutILNS_5OrderE0ELi4ELi8EEEhaEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii, %60 ], [ @_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEhhEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii, %13 ]
  %122 = phi void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)* [ @_ZN3ruy9RunKernelILNS_4PathE8EaahNS_9MulParamsIihEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE, %60 ], [ @_ZN3ruy9RunKernelILNS_4PathE2EhhhNS_9MulParamsIihEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE, %13 ]
  %123 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 7
  store i32 %120, i32* %123, align 8
  %124 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 1, i32 0, i64 0
  store void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* %121, void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)** %124, align 8
  %125 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 1, i32 0, i64 1
  store void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* %121, void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)** %125, align 8
  %126 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 2
  store void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)* %122, void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)** %126, align 8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy7RunPackILNS_4PathE8ENS_17FixedKernelLayoutILNS_5OrderE0ELi4ELi8EEEhaEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii(i32, %"struct.ruy::EMat"* dereferenceable(40), %"struct.ruy::PEMat"*, i32, i32) #1 comdat {
  %6 = alloca [32 x i8], align 16
  %7 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 2
  %8 = load i8*, i8** %7, align 8, !noalias !419
  %9 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3, i32 0
  %10 = load i32, i32* %9, align 4
  %11 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3, i32 1
  %12 = load i32, i32* %11, align 4
  %13 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3, i32 2
  %14 = load i32, i32* %13, align 4
  %15 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 2
  %16 = load i8*, i8** %15, align 8, !noalias !422
  %17 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 5
  %18 = bitcast i8** %17 to i32**
  %19 = load i32*, i32** %18, align 8, !noalias !422
  %20 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 6, i32 2
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 7
  %23 = load i32, i32* %22, align 8, !noalias !422
  %24 = getelementptr inbounds [32 x i8], [32 x i8]* %6, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %24) #19
  %25 = trunc i32 %23 to i8
  %26 = xor i8 %25, -128
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %24, i8 %26, i64 32, i1 false) #19
  %27 = icmp slt i32 %3, %4
  br i1 %27, label %28, label %47

28:                                               ; preds = %5
  %29 = icmp eq i32* %19, null
  %30 = sext i32 %3 to i64
  %31 = sext i32 %4 to i64
  %32 = sext i32 %14 to i64
  br label %33

33:                                               ; preds = %33, %28
  %34 = phi i64 [ %30, %28 ], [ %45, %33 ]
  %35 = getelementptr inbounds i32, i32* %19, i64 %34
  %36 = select i1 %29, i32* null, i32* %35
  %37 = mul nsw i64 %34, %32
  %38 = getelementptr inbounds i8, i8* %8, i64 %37
  %39 = trunc i64 %34 to i32
  %40 = sub nsw i32 %12, %39
  %41 = and i32 %39, -8
  %42 = mul nsw i32 %41, %21
  %43 = sext i32 %42 to i64
  %44 = getelementptr inbounds i8, i8* %16, i64 %43
  call void @_ZN3ruy12Pack8bitAvx2EPKaaS1_iiiPaPi(i8* %38, i8 signext -128, i8* nonnull %24, i32 %14, i32 %40, i32 %10, i8* %44, i32* %36) #19
  %45 = add nsw i64 %34, 8
  %46 = icmp slt i64 %45, %31
  br i1 %46, label %33, label %47

47:                                               ; preds = %33, %5
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %24) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy9RunKernelILNS_4PathE8EaahNS_9MulParamsIihEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE(i32, %"class.ruy::SidePair.104"* dereferenceable(112), i8*, %"class.ruy::SidePair.105"* dereferenceable(8), %"class.ruy::SidePair.105"* dereferenceable(8), %"struct.ruy::EMat"*) #1 comdat {
  %7 = alloca %"struct.ruy::KernelParams8bit.167", align 8
  %8 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 2
  %9 = load i8*, i8** %8, align 8, !noalias !425
  %10 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 0
  %11 = load i32, i32* %10, align 4
  %12 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 1
  %13 = load i32, i32* %12, align 4
  %14 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 2
  %15 = load i32, i32* %14, align 4
  %16 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 4
  %17 = load i32, i32* %16, align 8, !noalias !425
  %18 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 2
  %19 = load i8*, i8** %18, align 8, !noalias !428
  %20 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 5
  %21 = bitcast i8** %20 to i32**
  %22 = load i32*, i32** %21, align 8, !noalias !428
  %23 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 6, i32 0
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 6, i32 2
  %26 = load i32, i32* %25, align 4
  %27 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 7
  %28 = load i32, i32* %27, align 8, !noalias !428
  %29 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 2
  %30 = load i8*, i8** %29, align 8, !noalias !431
  %31 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 5
  %32 = bitcast i8** %31 to i32**
  %33 = load i32*, i32** %32, align 8, !noalias !431
  %34 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 6, i32 2
  %35 = load i32, i32* %34, align 4
  %36 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 7
  %37 = load i32, i32* %36, align 8, !noalias !431
  %38 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %3, i64 0, i32 0, i64 0
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %3, i64 0, i32 0, i64 1
  %41 = load i32, i32* %40, align 4
  %42 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %4, i64 0, i32 0, i64 0
  %43 = load i32, i32* %42, align 4
  %44 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %4, i64 0, i32 0, i64 1
  %45 = load i32, i32* %44, align 4
  %46 = bitcast %"struct.ruy::KernelParams8bit.167"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 488, i8* nonnull %46) #19
  %47 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 1
  %48 = bitcast i32** %47 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %48, i8 -86, i64 480, i1 false) #19
  %49 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 27, i64 0
  %50 = bitcast i32* %49 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 4 %50, i8 0, i64 32, i1 false) #19
  %51 = mul nsw i32 %39, %26
  %52 = sext i32 %51 to i64
  %53 = getelementptr inbounds i8, i8* %19, i64 %52
  %54 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 3
  store i8* %53, i8** %54, align 8
  %55 = mul nsw i32 %41, %35
  %56 = sext i32 %55 to i64
  %57 = getelementptr inbounds i8, i8* %30, i64 %56
  %58 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 6
  store i8* %57, i8** %58, align 8
  %59 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 24
  store i8 0, i8* %59, align 8
  %60 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 0
  store i32* %49, i32** %60, align 8
  %61 = bitcast i8* %2 to i32**
  %62 = load i32*, i32** %61, align 8
  %63 = icmp eq i32* %62, null
  br i1 %63, label %65, label %64

64:                                               ; preds = %6
  store i32* %62, i32** %60, align 8
  store i8 1, i8* %59, align 8
  br label %65

65:                                               ; preds = %64, %6
  %66 = phi i8 [ 0, %6 ], [ 1, %64 ]
  %67 = icmp eq i32* %22, null
  br i1 %67, label %71, label %68

68:                                               ; preds = %65
  %69 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 1
  store i32* %22, i32** %69, align 8
  %70 = or i8 %66, 2
  store i8 %70, i8* %59, align 8
  br label %71

71:                                               ; preds = %68, %65
  %72 = phi i8 [ %66, %65 ], [ %70, %68 ]
  %73 = icmp eq i32* %33, null
  br i1 %73, label %77, label %74

74:                                               ; preds = %71
  %75 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 2
  store i32* %33, i32** %75, align 8
  %76 = or i8 %72, 4
  store i8 %76, i8* %59, align 8
  br label %77

77:                                               ; preds = %74, %71
  %78 = phi i8 [ %72, %71 ], [ %76, %74 ]
  %79 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 12
  store i32 %39, i32* %79, align 8
  %80 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 13
  store i32 %41, i32* %80, align 4
  %81 = add nsw i32 %43, -8
  %82 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 14
  store i32 %81, i32* %82, align 8
  %83 = add nsw i32 %45, -8
  %84 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 15
  store i32 %83, i32* %84, align 4
  %85 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 18
  store i32 %26, i32* %85, align 8
  %86 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 19
  store i32 %35, i32* %86, align 4
  %87 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 20
  store i32 %15, i32* %87, align 8
  %88 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 8
  store i32 %28, i32* %88, align 8
  %89 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 9
  store i32 %37, i32* %89, align 4
  %90 = and i32 %17, 255
  %91 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 10
  store i32 %90, i32* %91, align 8
  %92 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 21
  store i32 %24, i32* %92, align 4
  %93 = mul i32 %28, %24
  %94 = mul i32 %93, %37
  %95 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 11
  store i32 %94, i32* %95, align 4
  %96 = getelementptr inbounds i8, i8* %2, i64 16
  %97 = bitcast i8* %96 to i32**
  %98 = load i32*, i32** %97, align 8
  %99 = icmp eq i32* %98, null
  br i1 %99, label %110, label %100

100:                                              ; preds = %77
  %101 = ptrtoint i32* %98 to i64
  %102 = or i8 %78, 24
  store i8 %102, i8* %59, align 8
  %103 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 4
  %104 = bitcast i32** %103 to i64*
  store i64 %101, i64* %104, align 8
  %105 = getelementptr inbounds i8, i8* %2, i64 24
  %106 = bitcast i8* %105 to i64*
  %107 = load i64, i64* %106, align 8
  %108 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 5
  %109 = bitcast i32** %108 to i64*
  store i64 %107, i64* %109, align 8
  br label %139

110:                                              ; preds = %77
  %111 = getelementptr inbounds i8, i8* %2, i64 12
  %112 = bitcast i8* %111 to i32*
  %113 = load i32, i32* %112, align 4
  %114 = icmp sgt i32 %113, 0
  br i1 %114, label %115, label %117

115:                                              ; preds = %110
  %116 = or i8 %78, 16
  store i8 %116, i8* %59, align 8
  br label %117

117:                                              ; preds = %115, %110
  %118 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 29, i64 0
  %119 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 4
  store i32* %118, i32** %119, align 8
  %120 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 30, i64 0
  %121 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 5
  store i32* %120, i32** %121, align 8
  %122 = getelementptr inbounds i8, i8* %2, i64 8
  %123 = bitcast i8* %122 to i32*
  %124 = load i32, i32* %123, align 8
  %125 = insertelement <4 x i32> undef, i32 %124, i32 0
  %126 = shufflevector <4 x i32> %125, <4 x i32> undef, <4 x i32> zeroinitializer
  %127 = bitcast i32* %118 to <4 x i32>*
  store <4 x i32> %126, <4 x i32>* %127, align 4
  %128 = insertelement <4 x i32> undef, i32 %113, i32 0
  %129 = shufflevector <4 x i32> %128, <4 x i32> undef, <4 x i32> zeroinitializer
  %130 = bitcast i32* %120 to <4 x i32>*
  store <4 x i32> %129, <4 x i32>* %130, align 4
  %131 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 29, i64 4
  store i32 %124, i32* %131, align 4
  %132 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 30, i64 4
  store i32 %113, i32* %132, align 4
  %133 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 29, i64 5
  store i32 %124, i32* %133, align 4
  %134 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 30, i64 5
  store i32 %113, i32* %134, align 4
  %135 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 29, i64 6
  store i32 %124, i32* %135, align 4
  %136 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 30, i64 6
  store i32 %113, i32* %136, align 4
  %137 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 29, i64 7
  store i32 %124, i32* %137, align 4
  %138 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 30, i64 7
  store i32 %113, i32* %138, align 4
  br label %139

139:                                              ; preds = %100, %117
  %140 = getelementptr inbounds i8, i8* %2, i64 32
  %141 = load i8, i8* %140, align 8
  %142 = zext i8 %141 to i32
  %143 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 22
  store i32 %142, i32* %143, align 8
  %144 = getelementptr inbounds i8, i8* %2, i64 33
  %145 = load i8, i8* %144, align 1
  %146 = zext i8 %145 to i32
  %147 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 23
  store i32 %146, i32* %147, align 4
  %148 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 16
  store i32 %11, i32* %148, align 8
  %149 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 17
  store i32 %13, i32* %149, align 4
  %150 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 25
  store i8 1, i8* %150, align 1
  %151 = mul nsw i32 %41, %15
  %152 = sext i32 %151 to i64
  %153 = getelementptr inbounds i8, i8* %9, i64 %152
  %154 = sext i32 %39 to i64
  %155 = getelementptr inbounds i8, i8* %153, i64 %154
  %156 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 7
  store i8* %155, i8** %156, align 8
  %157 = icmp eq i32 %13, 1
  br i1 %157, label %158, label %159

158:                                              ; preds = %139
  call void @_ZN3ruy23Kernel8bitAvx2SingleColERKNS_16KernelParams8bitILi8ELi8EEE(%"struct.ruy::KernelParams8bit.167"* nonnull dereferenceable(488) %7) #19
  br label %160

159:                                              ; preds = %139
  call void @_ZN3ruy14Kernel8bitAvx2ERKNS_16KernelParams8bitILi8ELi8EEE(%"struct.ruy::KernelParams8bit.167"* nonnull dereferenceable(488) %7) #19
  br label %160

160:                                              ; preds = %158, %159
  call void @llvm.lifetime.end.p0i8(i64 488, i8* nonnull %46) #19
  ret void
}

declare void @_ZN3ruy12Pack8bitAvx2EPKaaS1_iiiPaPi(i8*, i8 signext, i8*, i32, i32, i32, i8*, i32*) local_unnamed_addr #5

declare void @_ZN3ruy23Kernel8bitAvx2SingleColERKNS_16KernelParams8bitILi8ELi8EEE(%"struct.ruy::KernelParams8bit.167"* dereferenceable(488)) local_unnamed_addr #5

declare void @_ZN3ruy14Kernel8bitAvx2ERKNS_16KernelParams8bitILi8ELi8EEE(%"struct.ruy::KernelParams8bit.167"* dereferenceable(488)) local_unnamed_addr #5

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17DispatchGemmShapeIhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENS7_IS8_LS9_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIS8_LS9_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSP_ISR_XT3_EEEPNSP_IT0_XT4_EEERKT5_RKT6_RKT7_(%"class.gemmlowp::GemmContext"*, %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.180"* dereferenceable(24), %"class.gemmlowp::MatrixMap.182"*, %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.std::__1::tuple"* dereferenceable(40)) local_unnamed_addr #1 comdat {
  %8 = alloca %"class.gemmlowp::MatrixMap.195", align 8
  %9 = alloca %"class.gemmlowp::MatrixMap", align 8
  %10 = alloca %"class.gemmlowp::MatrixMap.180", align 8
  %11 = alloca %"class.gemmlowp::VectorDup.194", align 4
  %12 = alloca %"class.gemmlowp::VectorDup", align 4
  %13 = alloca %"class.std::__1::tuple.197", align 8
  %14 = alloca %"struct.gemmlowp::DefaultKernel", align 8
  %15 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %3, i64 0, i32 1
  %16 = load i32, i32* %15, align 8
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %3, i64 0, i32 2
  %18 = load i32, i32* %17, align 4
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 2
  %20 = load i32, i32* %19, align 4
  %21 = icmp eq i32 %16, 0
  %22 = icmp eq i32 %18, 0
  %23 = or i1 %21, %22
  %24 = icmp eq i32 %20, 0
  %25 = or i1 %23, %24
  br i1 %25, label %101, label %26

26:                                               ; preds = %7
  %27 = icmp slt i32 %16, %18
  br i1 %27, label %28, label %97

28:                                               ; preds = %26
  %29 = bitcast %"class.gemmlowp::MatrixMap.195"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %29) #19
  %30 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %8, i64 0, i32 1
  %31 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %8, i64 0, i32 2
  %32 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %8, i64 0, i32 3
  %33 = bitcast %"class.gemmlowp::MatrixMap.182"* %3 to i64*
  %34 = bitcast %"class.gemmlowp::MatrixMap.195"* %8 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %34, i8 -86, i64 24, i1 false)
  %35 = load i64, i64* %33, align 8, !noalias !434
  %36 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %3, i64 0, i32 3
  %37 = load i32, i32* %36, align 8, !noalias !434
  %38 = bitcast %"class.gemmlowp::MatrixMap.195"* %8 to i64*
  store i64 %35, i64* %38, align 8, !alias.scope !434
  store i32 %18, i32* %30, align 8, !alias.scope !434
  store i32 %16, i32* %31, align 4, !alias.scope !434
  store i32 %37, i32* %32, align 8, !alias.scope !434
  %39 = bitcast %"class.gemmlowp::MatrixMap"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %39) #19
  %40 = bitcast %"class.gemmlowp::MatrixMap.180"* %2 to i64*
  %41 = load i64, i64* %40, align 8, !noalias !439
  %42 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %2, i64 0, i32 2
  %43 = load i32, i32* %42, align 4, !noalias !439
  %44 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %2, i64 0, i32 1
  %45 = load i32, i32* %44, align 8, !noalias !439
  %46 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %2, i64 0, i32 3
  %47 = load i32, i32* %46, align 8, !noalias !439
  %48 = bitcast %"class.gemmlowp::MatrixMap"* %9 to i64*
  store i64 %41, i64* %48, align 8, !alias.scope !439
  %49 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 1
  store i32 %43, i32* %49, align 8, !alias.scope !439
  %50 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 2
  store i32 %45, i32* %50, align 4, !alias.scope !439
  %51 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 3
  store i32 %47, i32* %51, align 8, !alias.scope !439
  %52 = bitcast %"class.gemmlowp::MatrixMap.180"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %52) #19
  %53 = bitcast %"class.gemmlowp::MatrixMap"* %1 to i64*
  %54 = load i64, i64* %53, align 8, !noalias !444
  %55 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 1
  %56 = load i32, i32* %55, align 8, !noalias !444
  %57 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 3
  %58 = load i32, i32* %57, align 8, !noalias !444
  %59 = bitcast %"class.gemmlowp::MatrixMap.180"* %10 to i64*
  store i64 %54, i64* %59, align 8, !alias.scope !444
  %60 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %10, i64 0, i32 1
  store i32 %20, i32* %60, align 8, !alias.scope !444
  %61 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %10, i64 0, i32 2
  store i32 %56, i32* %61, align 4, !alias.scope !444
  %62 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %10, i64 0, i32 3
  store i32 %58, i32* %62, align 8, !alias.scope !444
  %63 = bitcast %"class.gemmlowp::VectorDup.194"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %63) #19
  %64 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %11, i64 0, i32 0
  %65 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 0
  %66 = load i32, i32* %65, align 4, !noalias !449
  store i32 %66, i32* %64, align 4, !alias.scope !449
  %67 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %11, i64 0, i32 1
  %68 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 1
  %69 = load i32, i32* %68, align 4, !noalias !449
  store i32 %69, i32* %67, align 4, !alias.scope !449
  %70 = bitcast %"class.gemmlowp::VectorDup"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %70) #19
  %71 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %12, i64 0, i32 0
  %72 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %4, i64 0, i32 0
  %73 = load i32, i32* %72, align 4, !noalias !454
  store i32 %73, i32* %71, align 4, !alias.scope !454
  %74 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %12, i64 0, i32 1
  %75 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %4, i64 0, i32 1
  %76 = load i32, i32* %75, align 4, !noalias !454
  store i32 %76, i32* %74, align 4, !alias.scope !454
  %77 = bitcast %"class.std::__1::tuple.197"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %77) #19
  %78 = bitcast %"class.std::__1::tuple"* %6 to i64*
  %79 = load i64, i64* %78, align 8, !noalias !459
  %80 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %6, i64 0, i32 0, i32 0, i32 0, i32 0, i32 1
  %81 = load i32, i32* %80, align 8, !noalias !459
  %82 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %6, i64 0, i32 0, i32 1, i32 0
  %83 = bitcast %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %82 to i64*
  %84 = load i64, i64* %83, align 4, !noalias !470
  %85 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %6, i64 0, i32 0, i32 1, i32 0, i32 2
  %86 = load i32, i32* %85, align 4, !noalias !470
  %87 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %6, i64 0, i32 0, i32 2, i32 0
  %88 = bitcast %"struct.gemmlowp::OutputStageClamp"* %87 to i64*
  %89 = load i64, i64* %88, align 4, !noalias !470
  %90 = bitcast %"class.std::__1::tuple.197"* %13 to i64*
  store i64 %79, i64* %90, align 8, !alias.scope !471
  %91 = getelementptr inbounds %"class.std::__1::tuple.197", %"class.std::__1::tuple.197"* %13, i64 0, i32 0, i32 0, i32 0, i32 0, i32 1
  store i32 %81, i32* %91, align 8, !alias.scope !471
  %92 = getelementptr inbounds %"class.std::__1::tuple.197", %"class.std::__1::tuple.197"* %13, i64 0, i32 0, i32 1
  %93 = bitcast %"class.std::__1::__tuple_leaf.184"* %92 to i64*
  store i64 %84, i64* %93, align 8, !alias.scope !470
  %94 = getelementptr inbounds %"class.std::__1::tuple.197", %"class.std::__1::tuple.197"* %13, i64 0, i32 0, i32 1, i32 0, i32 2
  store i32 %86, i32* %94, align 8, !alias.scope !470
  %95 = getelementptr inbounds %"class.std::__1::tuple.197", %"class.std::__1::tuple.197"* %13, i64 0, i32 0, i32 2
  %96 = bitcast %"class.std::__1::__tuple_leaf.185"* %95 to i64*
  store i64 %89, i64* %96, align 4, !alias.scope !471
  call void @_ZN8gemmlowp17DispatchGemmShapeIhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENS7_IS8_LS9_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIS8_LS9_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSP_ISR_XT3_EEEPNSP_IT0_XT4_EEERKT5_RKT6_RKT7_(%"class.gemmlowp::GemmContext"* %0, %"class.gemmlowp::MatrixMap"* nonnull dereferenceable(24) %9, %"class.gemmlowp::MatrixMap.180"* nonnull dereferenceable(24) %10, %"class.gemmlowp::MatrixMap.195"* nonnull %8, %"class.gemmlowp::VectorDup.194"* nonnull dereferenceable(8) %11, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %12, %"class.std::__1::tuple.197"* nonnull dereferenceable(40) %13)
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %77) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %70) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %63) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %52) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %39) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %29) #19
  br label %101

97:                                               ; preds = %26
  %98 = bitcast %"struct.gemmlowp::DefaultKernel"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %98) #19
  %99 = getelementptr inbounds %"struct.gemmlowp::DefaultKernel", %"struct.gemmlowp::DefaultKernel"* %14, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [6 x i8*] }, { [6 x i8*] }* @_ZTVN8gemmlowp13DefaultKernelINS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %99, align 8
  %100 = getelementptr inbounds %"struct.gemmlowp::DefaultKernel", %"struct.gemmlowp::DefaultKernel"* %14, i64 0, i32 0, i32 0, i32 0, i32 0
  call void @_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSZ_IS11_XT4_EEEPNSZ_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::GemmContext"* %0, %"struct.gemmlowp::KernelBase"* nonnull dereferenceable(8) %100, %"class.gemmlowp::MatrixMap"* dereferenceable(24) %1, %"class.gemmlowp::MatrixMap.180"* dereferenceable(24) %2, %"class.gemmlowp::MatrixMap.182"* %3, %"class.gemmlowp::VectorDup"* dereferenceable(8) %4, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %5, %"class.std::__1::tuple"* dereferenceable(40) %6)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %98) #19
  br label %101

101:                                              ; preds = %7, %97, %28
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17DispatchGemmShapeIhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENS7_IS8_LS9_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIS8_LS9_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSP_ISR_XT3_EEEPNSP_IT0_XT4_EEERKT5_RKT6_RKT7_(%"class.gemmlowp::GemmContext"*, %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.180"* dereferenceable(24), %"class.gemmlowp::MatrixMap.195"*, %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.std::__1::tuple.197"* dereferenceable(40)) local_unnamed_addr #1 comdat {
  %8 = alloca %"class.gemmlowp::MatrixMap.182", align 8
  %9 = alloca %"class.gemmlowp::MatrixMap", align 8
  %10 = alloca %"class.gemmlowp::MatrixMap.180", align 8
  %11 = alloca %"class.gemmlowp::VectorDup", align 4
  %12 = alloca %"class.gemmlowp::VectorDup.194", align 4
  %13 = alloca %"class.std::__1::tuple", align 8
  %14 = alloca %"struct.gemmlowp::DefaultKernel", align 8
  %15 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %3, i64 0, i32 1
  %16 = load i32, i32* %15, align 8
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %3, i64 0, i32 2
  %18 = load i32, i32* %17, align 4
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 2
  %20 = load i32, i32* %19, align 4
  %21 = icmp eq i32 %16, 0
  %22 = icmp eq i32 %18, 0
  %23 = or i1 %21, %22
  %24 = icmp eq i32 %20, 0
  %25 = or i1 %23, %24
  br i1 %25, label %101, label %26

26:                                               ; preds = %7
  %27 = icmp slt i32 %16, %18
  br i1 %27, label %28, label %97

28:                                               ; preds = %26
  %29 = bitcast %"class.gemmlowp::MatrixMap.182"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %29) #19
  %30 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %8, i64 0, i32 1
  %31 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %8, i64 0, i32 2
  %32 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %8, i64 0, i32 3
  %33 = bitcast %"class.gemmlowp::MatrixMap.195"* %3 to i64*
  %34 = bitcast %"class.gemmlowp::MatrixMap.182"* %8 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %34, i8 -86, i64 24, i1 false)
  %35 = load i64, i64* %33, align 8, !noalias !474
  %36 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %3, i64 0, i32 3
  %37 = load i32, i32* %36, align 8, !noalias !474
  %38 = bitcast %"class.gemmlowp::MatrixMap.182"* %8 to i64*
  store i64 %35, i64* %38, align 8, !alias.scope !474
  store i32 %18, i32* %30, align 8, !alias.scope !474
  store i32 %16, i32* %31, align 4, !alias.scope !474
  store i32 %37, i32* %32, align 8, !alias.scope !474
  %39 = bitcast %"class.gemmlowp::MatrixMap"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %39) #19
  %40 = bitcast %"class.gemmlowp::MatrixMap.180"* %2 to i64*
  %41 = load i64, i64* %40, align 8, !noalias !479
  %42 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %2, i64 0, i32 2
  %43 = load i32, i32* %42, align 4, !noalias !479
  %44 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %2, i64 0, i32 1
  %45 = load i32, i32* %44, align 8, !noalias !479
  %46 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %2, i64 0, i32 3
  %47 = load i32, i32* %46, align 8, !noalias !479
  %48 = bitcast %"class.gemmlowp::MatrixMap"* %9 to i64*
  store i64 %41, i64* %48, align 8, !alias.scope !479
  %49 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 1
  store i32 %43, i32* %49, align 8, !alias.scope !479
  %50 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 2
  store i32 %45, i32* %50, align 4, !alias.scope !479
  %51 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 3
  store i32 %47, i32* %51, align 8, !alias.scope !479
  %52 = bitcast %"class.gemmlowp::MatrixMap.180"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %52) #19
  %53 = bitcast %"class.gemmlowp::MatrixMap"* %1 to i64*
  %54 = load i64, i64* %53, align 8, !noalias !484
  %55 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 1
  %56 = load i32, i32* %55, align 8, !noalias !484
  %57 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 3
  %58 = load i32, i32* %57, align 8, !noalias !484
  %59 = bitcast %"class.gemmlowp::MatrixMap.180"* %10 to i64*
  store i64 %54, i64* %59, align 8, !alias.scope !484
  %60 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %10, i64 0, i32 1
  store i32 %20, i32* %60, align 8, !alias.scope !484
  %61 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %10, i64 0, i32 2
  store i32 %56, i32* %61, align 4, !alias.scope !484
  %62 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %10, i64 0, i32 3
  store i32 %58, i32* %62, align 8, !alias.scope !484
  %63 = bitcast %"class.gemmlowp::VectorDup"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %63) #19
  %64 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %11, i64 0, i32 0
  %65 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %66 = load i32, i32* %65, align 4, !noalias !489
  store i32 %66, i32* %64, align 4, !alias.scope !489
  %67 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %11, i64 0, i32 1
  %68 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 1
  %69 = load i32, i32* %68, align 4, !noalias !489
  store i32 %69, i32* %67, align 4, !alias.scope !489
  %70 = bitcast %"class.gemmlowp::VectorDup.194"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %70) #19
  %71 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %12, i64 0, i32 0
  %72 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %4, i64 0, i32 0
  %73 = load i32, i32* %72, align 4, !noalias !494
  store i32 %73, i32* %71, align 4, !alias.scope !494
  %74 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %12, i64 0, i32 1
  %75 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %4, i64 0, i32 1
  %76 = load i32, i32* %75, align 4, !noalias !494
  store i32 %76, i32* %74, align 4, !alias.scope !494
  %77 = bitcast %"class.std::__1::tuple"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %77) #19
  %78 = bitcast %"class.std::__1::tuple.197"* %6 to i64*
  %79 = load i64, i64* %78, align 8, !noalias !499
  %80 = getelementptr inbounds %"class.std::__1::tuple.197", %"class.std::__1::tuple.197"* %6, i64 0, i32 0, i32 0, i32 0, i32 0, i32 1
  %81 = load i32, i32* %80, align 8, !noalias !499
  %82 = getelementptr inbounds %"class.std::__1::tuple.197", %"class.std::__1::tuple.197"* %6, i64 0, i32 0, i32 1, i32 0
  %83 = bitcast %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %82 to i64*
  %84 = load i64, i64* %83, align 4, !noalias !510
  %85 = getelementptr inbounds %"class.std::__1::tuple.197", %"class.std::__1::tuple.197"* %6, i64 0, i32 0, i32 1, i32 0, i32 2
  %86 = load i32, i32* %85, align 4, !noalias !510
  %87 = getelementptr inbounds %"class.std::__1::tuple.197", %"class.std::__1::tuple.197"* %6, i64 0, i32 0, i32 2, i32 0
  %88 = bitcast %"struct.gemmlowp::OutputStageClamp"* %87 to i64*
  %89 = load i64, i64* %88, align 4, !noalias !510
  %90 = bitcast %"class.std::__1::tuple"* %13 to i64*
  store i64 %79, i64* %90, align 8, !alias.scope !511
  %91 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %13, i64 0, i32 0, i32 0, i32 0, i32 0, i32 1
  store i32 %81, i32* %91, align 8, !alias.scope !511
  %92 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %13, i64 0, i32 0, i32 1
  %93 = bitcast %"class.std::__1::__tuple_leaf.184"* %92 to i64*
  store i64 %84, i64* %93, align 8, !alias.scope !510
  %94 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %13, i64 0, i32 0, i32 1, i32 0, i32 2
  store i32 %86, i32* %94, align 8, !alias.scope !510
  %95 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %13, i64 0, i32 0, i32 2
  %96 = bitcast %"class.std::__1::__tuple_leaf.185"* %95 to i64*
  store i64 %89, i64* %96, align 4, !alias.scope !511
  call void @_ZN8gemmlowp17DispatchGemmShapeIhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENS7_IS8_LS9_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIS8_LS9_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSP_ISR_XT3_EEEPNSP_IT0_XT4_EEERKT5_RKT6_RKT7_(%"class.gemmlowp::GemmContext"* %0, %"class.gemmlowp::MatrixMap"* nonnull dereferenceable(24) %9, %"class.gemmlowp::MatrixMap.180"* nonnull dereferenceable(24) %10, %"class.gemmlowp::MatrixMap.182"* nonnull %8, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %11, %"class.gemmlowp::VectorDup.194"* nonnull dereferenceable(8) %12, %"class.std::__1::tuple"* nonnull dereferenceable(40) %13)
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %77) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %70) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %63) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %52) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %39) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %29) #19
  br label %101

97:                                               ; preds = %26
  %98 = bitcast %"struct.gemmlowp::DefaultKernel"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %98) #19
  %99 = getelementptr inbounds %"struct.gemmlowp::DefaultKernel", %"struct.gemmlowp::DefaultKernel"* %14, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [6 x i8*] }, { [6 x i8*] }* @_ZTVN8gemmlowp13DefaultKernelINS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %99, align 8
  %100 = getelementptr inbounds %"struct.gemmlowp::DefaultKernel", %"struct.gemmlowp::DefaultKernel"* %14, i64 0, i32 0, i32 0, i32 0, i32 0
  call void @_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSZ_IS11_XT4_EEEPNSZ_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::GemmContext"* %0, %"struct.gemmlowp::KernelBase"* nonnull dereferenceable(8) %100, %"class.gemmlowp::MatrixMap"* dereferenceable(24) %1, %"class.gemmlowp::MatrixMap.180"* dereferenceable(24) %2, %"class.gemmlowp::MatrixMap.195"* %3, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %4, %"class.gemmlowp::VectorDup"* dereferenceable(8) %5, %"class.std::__1::tuple.197"* dereferenceable(40) %6)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %98) #19
  br label %101

101:                                              ; preds = %7, %97, %28
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSZ_IS11_XT4_EEEPNSZ_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::GemmContext"*, %"struct.gemmlowp::KernelBase"* dereferenceable(8), %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.180"* dereferenceable(24), %"class.gemmlowp::MatrixMap.182"*, %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.std::__1::tuple"* dereferenceable(40)) local_unnamed_addr #1 comdat {
  %9 = alloca %"class.gemmlowp::SideMap", align 8
  %10 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %11 = alloca %"struct.gemmlowp::BlockParams", align 4
  %12 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %13 = alloca %"class.std::__1::vector.205", align 8
  %14 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %4, i64 0, i32 1
  %15 = load i32, i32* %14, align 8
  %16 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %4, i64 0, i32 2
  %17 = load i32, i32* %16, align 4
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 2
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %"class.gemmlowp::GemmContext", %"class.gemmlowp::GemmContext"* %0, i64 0, i32 0, i32 0, i32 1
  %21 = load i32, i32* %20, align 4
  switch i32 %21, label %34 [
    i32 1, label %54
    i32 0, label %22
  ]

22:                                               ; preds = %8
  %23 = load atomic i8, i8* bitcast (i64* @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count to i8*) acquire, align 8
  %24 = icmp eq i8 %23, 0
  br i1 %24, label %25, label %32, !prof !514

25:                                               ; preds = %22
  %26 = tail call i32 @__cxa_guard_acquire(i64* nonnull @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count) #19
  %27 = icmp eq i32 %26, 0
  br i1 %27, label %32, label %28

28:                                               ; preds = %25
  %29 = tail call i64 @sysconf(i32 83) #19
  %30 = trunc i64 %29 to i32
  store i32 %30, i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count, align 4
  %31 = tail call {}* @llvm.invariant.start.p0i8(i64 4, i8* bitcast (i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count to i8*)) #19
  tail call void @__cxa_guard_release(i64* nonnull @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count) #19
  br label %32

32:                                               ; preds = %28, %25, %22
  %33 = load i32, i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count, align 4
  br label %34

34:                                               ; preds = %32, %8
  %35 = phi i32 [ %33, %32 ], [ %21, %8 ]
  %36 = add i32 %15, 15
  %37 = sdiv i32 %36, 16
  %38 = icmp slt i32 %37, %35
  %39 = select i1 %38, i32 %37, i32 %35
  %40 = icmp sgt i32 %39, 1
  br i1 %40, label %41, label %56

41:                                               ; preds = %34
  %42 = sext i32 %15 to i64
  %43 = sext i32 %17 to i64
  %44 = mul nsw i64 %43, %42
  %45 = sext i32 %19 to i64
  %46 = mul i64 %44, %45
  %47 = lshr i64 %46, 16
  %48 = trunc i64 %47 to i32
  %49 = icmp sgt i32 %39, %48
  %50 = select i1 %49, i32 %48, i32 %39
  %51 = icmp sgt i32 %50, 1
  br i1 %51, label %52, label %54

52:                                               ; preds = %41
  %53 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br label %61

54:                                               ; preds = %41, %8
  %55 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br label %59

56:                                               ; preds = %34
  %57 = icmp eq i32 %39, 1
  %58 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br i1 %57, label %59, label %61

59:                                               ; preds = %54, %56
  %60 = phi %"class.gemmlowp::SingleThreadGemmContext"* [ %55, %54 ], [ %58, %56 ]
  tail call void @_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSY_IS10_XT4_EEEPNSY_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::SingleThreadGemmContext"* %60, %"struct.gemmlowp::KernelBase"* dereferenceable(8) %1, %"class.gemmlowp::MatrixMap"* dereferenceable(24) %2, %"class.gemmlowp::MatrixMap.180"* dereferenceable(24) %3, %"class.gemmlowp::MatrixMap.182"* %4, %"class.gemmlowp::VectorDup"* dereferenceable(8) %5, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.std::__1::tuple"* dereferenceable(40) %7)
  br label %303

61:                                               ; preds = %52, %56
  %62 = phi %"class.gemmlowp::SingleThreadGemmContext"* [ %53, %52 ], [ %58, %56 ]
  %63 = phi i32 [ %50, %52 ], [ %39, %56 ]
  %64 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0
  %65 = getelementptr inbounds %"class.gemmlowp::GemmContext", %"class.gemmlowp::GemmContext"* %0, i64 0, i32 0, i32 1
  %66 = bitcast %"struct.gemmlowp::BlockParams"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %66) #19
  %67 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 1
  %68 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 2
  %69 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 4
  %70 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 5
  %71 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 1
  %72 = bitcast %"struct.gemmlowp::BlockParams"* %11 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %72, i8 -86, i64 24, i1 false)
  %73 = load i32, i32* %71, align 8
  %74 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 2
  %75 = load i32, i32* %74, align 4
  %76 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 3
  %77 = load float, float* %76, align 8
  call void @_ZN8gemmlowp11BlockParams4InitINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES7_EEEEviiiiiif(%"struct.gemmlowp::BlockParams"* nonnull %11, i32 %15, i32 %17, i32 %19, i32 %63, i32 %73, i32 %75, float %77)
  %78 = bitcast %"class.gemmlowp::PackedSideBlock"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %78) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %78, i8 -86, i64 80, i1 false)
  %79 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %64, %"class.gemmlowp::Allocator"** %79, align 8
  %80 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 4
  store i32 0, i32* %80, align 8
  %81 = load i32, i32* %67, align 4
  %82 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 0
  store i32 %81, i32* %82, align 8
  %83 = load i32, i32* %69, align 4
  %84 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 2
  store i32 %83, i32* %84, align 8
  %85 = load i32, i32* %68, align 4
  %86 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 1
  store i32 %85, i32* %86, align 4
  %87 = load i32, i32* %70, align 4
  %88 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 3
  store i32 %87, i32* %88, align 4
  %89 = mul nsw i32 %87, %83
  %90 = sext i32 %89 to i64
  %91 = add nsw i64 %90, 63
  %92 = and i64 %91, -64
  %93 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 4
  %94 = load i64, i64* %93, align 8, !noalias !515
  %95 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 3
  %96 = load i64, i64* %95, align 8, !noalias !515
  %97 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 5, i64 %96
  store i64 %94, i64* %97, align 8, !noalias !515
  %98 = trunc i64 %96 to i8
  %99 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 6
  %100 = load i64, i64* %99, align 8, !noalias !515
  %101 = load i64, i64* %95, align 8, !noalias !515
  %102 = add i64 %101, 1
  store i64 %102, i64* %95, align 8, !noalias !515
  %103 = load i64, i64* %93, align 8, !noalias !515
  %104 = add i64 %103, %92
  store i64 %104, i64* %93, align 8, !noalias !515
  %105 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 0
  store i8 %98, i8* %105, align 8
  %106 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %106, i8 -86, i64 7, i1 false) #19
  %107 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 2
  store i64 %100, i64* %107, align 8
  %108 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 3
  store i8 0, i8* %108, align 8
  %109 = sext i32 %83 to i64
  %110 = shl nsw i64 %109, 2
  %111 = add nsw i64 %110, 63
  %112 = and i64 %111, -64
  %113 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 5, i64 %102
  store i64 %104, i64* %113, align 8, !noalias !518
  %114 = trunc i64 %102 to i8
  %115 = load i64, i64* %99, align 8, !noalias !518
  %116 = bitcast i64* %95 to <2 x i64>*
  %117 = load <2 x i64>, <2 x i64>* %116, align 8, !noalias !518
  %118 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %112, i32 1
  %119 = add <2 x i64> %117, %118
  %120 = bitcast i64* %95 to <2 x i64>*
  store <2 x i64> %119, <2 x i64>* %120, align 8, !noalias !518
  %121 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 0
  store i8 %114, i8* %121, align 8
  %122 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %122, i8 -86, i64 7, i1 false) #19
  %123 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 2
  store i64 %115, i64* %123, align 8
  %124 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 3
  store i8 5, i8* %124, align 8
  call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %64)
  %125 = icmp sgt i32 %17, 0
  br i1 %125, label %126, label %150

126:                                              ; preds = %61
  %127 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 0
  %128 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 3
  %129 = bitcast %"class.gemmlowp::SideMap"* %9 to i8*
  %130 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 1
  %131 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 2
  %132 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 3
  %133 = bitcast %"class.gemmlowp::SideMap"* %9 to i64*
  %134 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %10 to i8*
  %135 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 0
  %136 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 1
  %137 = bitcast %"class.std::__1::vector.205"* %13 to i8*
  %138 = getelementptr inbounds %"class.std::__1::vector.205", %"class.std::__1::vector.205"* %13, i64 0, i32 0, i32 0
  %139 = getelementptr inbounds %"class.std::__1::vector.205", %"class.std::__1::vector.205"* %13, i64 0, i32 0, i32 1
  %140 = getelementptr inbounds %"class.std::__1::vector.205", %"class.std::__1::vector.205"* %13, i64 0, i32 0, i32 2, i32 0, i32 0
  %141 = icmp sgt i32 %63, 0
  %142 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 0
  %143 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 3
  %144 = bitcast %"class.gemmlowp::MatrixMap.182"* %4 to i64*
  %145 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %4, i64 0, i32 3
  %146 = bitcast %"struct.gemmlowp::Task"*** %139 to i64*
  %147 = bitcast %"class.std::__1::vector.205"* %13 to i64*
  %148 = bitcast %"struct.gemmlowp::Task"*** %140 to i64*
  %149 = load i32, i32* %69, align 4
  br label %155

150:                                              ; preds = %173, %61
  %151 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 0
  store i8 0, i8* %151, align 8
  %152 = load i64, i64* %99, align 8
  %153 = add i64 %152, 1
  store i64 %153, i64* %99, align 8
  %154 = bitcast i64* %95 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %154, i8 0, i64 16, i1 false) #19
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %78) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %66) #19
  br label %303

155:                                              ; preds = %126, %173
  %156 = phi i32 [ %149, %126 ], [ %174, %173 ]
  %157 = phi i32 [ 0, %126 ], [ %175, %173 ]
  %158 = sub nsw i32 %17, %157
  %159 = icmp slt i32 %158, %156
  %160 = select i1 %159, i32 %158, i32 %156
  %161 = load i8*, i8** %127, align 8, !noalias !521
  %162 = load i32, i32* %128, align 8, !noalias !521
  %163 = mul nsw i32 %162, %157
  %164 = sext i32 %163 to i64
  %165 = getelementptr inbounds i8, i8* %161, i64 %164
  %166 = ptrtoint i8* %165 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %129) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %129, i8 -86, i64 24, i1 false) #19
  store i64 %166, i64* %133, align 8
  store i32 %160, i32* %130, align 8
  store i32 %19, i32* %131, align 4
  store i32 %162, i32* %132, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %134) #19
  store %"class.gemmlowp::PackedSideBlock"* %12, %"class.gemmlowp::PackedSideBlock"** %135, align 8
  store %"class.gemmlowp::SideMap"* %9, %"class.gemmlowp::SideMap"** %136, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %10) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %134) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %129) #19
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %137) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %137, i8 0, i64 24, i1 false) #19
  br i1 %141, label %177, label %167

167:                                              ; preds = %297, %155
  call void @_ZN8gemmlowp11WorkersPool28LegacyExecuteAndDestroyTasksERKNSt3__16vectorIPNS_4TaskENS1_9allocatorIS4_EEEE(%"class.gemmlowp::WorkersPool"* %65, %"class.std::__1::vector.205"* nonnull dereferenceable(24) %13) #19
  %168 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %138, align 8
  %169 = icmp eq %"struct.gemmlowp::Task"** %168, null
  br i1 %169, label %173, label %170

170:                                              ; preds = %167
  %171 = ptrtoint %"struct.gemmlowp::Task"** %168 to i64
  store i64 %171, i64* %146, align 8
  %172 = bitcast %"struct.gemmlowp::Task"** %168 to i8*
  call void @_ZdlPv(i8* %172) #18
  br label %173

173:                                              ; preds = %167, %170
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %137) #19
  %174 = load i32, i32* %69, align 4
  %175 = add nsw i32 %174, %157
  %176 = icmp sgt i32 %17, %175
  br i1 %176, label %155, label %150

177:                                              ; preds = %155, %299
  %178 = phi i64 [ %302, %299 ], [ 0, %155 ]
  %179 = phi %"struct.gemmlowp::Task"** [ %301, %299 ], [ null, %155 ]
  %180 = phi %"struct.gemmlowp::Task"** [ %300, %299 ], [ null, %155 ]
  %181 = phi i32 [ %183, %299 ], [ 0, %155 ]
  %182 = phi i32 [ %189, %299 ], [ 0, %155 ]
  %183 = add nuw nsw i32 %181, 1
  %184 = mul nsw i32 %183, %15
  %185 = sdiv i32 %184, %63
  %186 = add i32 %185, 3
  %187 = and i32 %186, -4
  %188 = icmp slt i32 %187, %15
  %189 = select i1 %188, i32 %187, i32 %15
  %190 = sub nsw i32 %189, %182
  %191 = load i8*, i8** %142, align 8, !noalias !524
  %192 = load i32, i32* %143, align 8, !noalias !524
  %193 = mul nsw i32 %192, %182
  %194 = sext i32 %193 to i64
  %195 = getelementptr inbounds i8, i8* %191, i64 %194
  %196 = ptrtoint i8* %195 to i64
  %197 = call i8* @_Znwm(i64 208) #18
  %198 = bitcast i8* %197 to i32 (...)***
  %199 = getelementptr inbounds i8, i8* %197, i64 8
  %200 = bitcast i8* %199 to %"class.gemmlowp::Allocator"**
  store %"class.gemmlowp::Allocator"* null, %"class.gemmlowp::Allocator"** %200, align 8
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %198, align 8
  %201 = getelementptr inbounds i8, i8* %197, i64 16
  %202 = bitcast i8* %201 to %"class.gemmlowp::GemmContext"**
  store %"class.gemmlowp::GemmContext"* %0, %"class.gemmlowp::GemmContext"** %202, align 8
  %203 = getelementptr inbounds i8, i8* %197, i64 24
  %204 = bitcast i8* %203 to %"struct.gemmlowp::KernelBase"**
  store %"struct.gemmlowp::KernelBase"* %1, %"struct.gemmlowp::KernelBase"** %204, align 8
  %205 = getelementptr inbounds i8, i8* %197, i64 32
  %206 = bitcast i8* %205 to i64*
  store i64 %196, i64* %206, align 8
  %207 = getelementptr inbounds i8, i8* %197, i64 40
  %208 = bitcast i8* %207 to i32*
  store i32 %190, i32* %208, align 8
  %209 = getelementptr inbounds i8, i8* %197, i64 44
  %210 = bitcast i8* %209 to i32*
  store i32 %19, i32* %210, align 4
  %211 = getelementptr inbounds i8, i8* %197, i64 48
  %212 = bitcast i8* %211 to i32*
  store i32 %192, i32* %212, align 8
  %213 = getelementptr inbounds i8, i8* %197, i64 56
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %213, i8* nonnull align 8 %78, i64 80, i1 false) #19
  %214 = getelementptr inbounds i8, i8* %197, i64 136
  %215 = load i64, i64* %144, align 8
  %216 = bitcast i8* %214 to i64*
  store i64 %215, i64* %216, align 8
  %217 = getelementptr inbounds i8, i8* %197, i64 144
  %218 = bitcast i8* %217 to i32*
  %219 = load i32, i32* %14, align 8
  store i32 %219, i32* %218, align 8
  %220 = getelementptr inbounds i8, i8* %197, i64 148
  %221 = bitcast i8* %220 to i32*
  %222 = load i32, i32* %16, align 4
  store i32 %222, i32* %221, align 4
  %223 = getelementptr inbounds i8, i8* %197, i64 152
  %224 = bitcast i8* %223 to i32*
  %225 = load i32, i32* %145, align 8
  store i32 %225, i32* %224, align 8
  %226 = getelementptr inbounds i8, i8* %197, i64 160
  %227 = bitcast i8* %226 to i32*
  store i32 %182, i32* %227, align 8
  %228 = getelementptr inbounds i8, i8* %197, i64 164
  %229 = bitcast i8* %228 to i32*
  store i32 %157, i32* %229, align 4
  %230 = getelementptr inbounds i8, i8* %197, i64 168
  %231 = bitcast i8* %230 to i32*
  store i32 %190, i32* %231, align 8
  %232 = getelementptr inbounds i8, i8* %197, i64 172
  %233 = bitcast i8* %232 to i32*
  store i32 %160, i32* %233, align 4
  %234 = getelementptr inbounds i8, i8* %197, i64 176
  %235 = bitcast i8* %234 to %"class.gemmlowp::VectorDup"**
  store %"class.gemmlowp::VectorDup"* %5, %"class.gemmlowp::VectorDup"** %235, align 8
  %236 = getelementptr inbounds i8, i8* %197, i64 184
  %237 = bitcast i8* %236 to %"class.gemmlowp::VectorDup.194"**
  store %"class.gemmlowp::VectorDup.194"* %6, %"class.gemmlowp::VectorDup.194"** %237, align 8
  %238 = getelementptr inbounds i8, i8* %197, i64 192
  %239 = bitcast i8* %238 to %"struct.gemmlowp::BlockParams"**
  store %"struct.gemmlowp::BlockParams"* %11, %"struct.gemmlowp::BlockParams"** %239, align 8
  %240 = getelementptr inbounds i8, i8* %197, i64 200
  %241 = bitcast i8* %240 to %"class.std::__1::tuple"**
  store %"class.std::__1::tuple"* %7, %"class.std::__1::tuple"** %241, align 8
  %242 = ptrtoint i8* %197 to i64
  %243 = icmp ult %"struct.gemmlowp::Task"** %180, %179
  %244 = ptrtoint %"struct.gemmlowp::Task"** %179 to i64
  br i1 %243, label %245, label %249

245:                                              ; preds = %177
  %246 = bitcast %"struct.gemmlowp::Task"** %180 to i64*
  store i64 %242, i64* %246, align 8
  %247 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %180, i64 1
  %248 = ptrtoint %"struct.gemmlowp::Task"** %247 to i64
  store i64 %248, i64* %146, align 8
  br label %297

249:                                              ; preds = %177
  %250 = ptrtoint %"struct.gemmlowp::Task"** %180 to i64
  %251 = load i64, i64* %147, align 8
  %252 = sub i64 %250, %251
  %253 = ashr exact i64 %252, 3
  %254 = add nsw i64 %253, 1
  %255 = icmp ugt i64 %254, 2305843009213693951
  br i1 %255, label %256, label %258

256:                                              ; preds = %249
  %257 = bitcast %"class.std::__1::vector.205"* %13 to %"class.std::__1::__vector_base_common"*
  call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* nonnull %257) #20
  unreachable

258:                                              ; preds = %249
  %259 = sub i64 %244, %251
  %260 = ashr exact i64 %259, 3
  %261 = icmp ult i64 %260, 1152921504606846975
  br i1 %261, label %262, label %270

262:                                              ; preds = %258
  %263 = ashr exact i64 %259, 2
  %264 = icmp ult i64 %263, %254
  %265 = select i1 %264, i64 %254, i64 %263
  %266 = icmp eq i64 %265, 0
  br i1 %266, label %275, label %267

267:                                              ; preds = %262
  %268 = icmp ugt i64 %265, 2305843009213693951
  br i1 %268, label %269, label %270

269:                                              ; preds = %267
  call void @abort() #20
  unreachable

270:                                              ; preds = %267, %258
  %271 = phi i64 [ %265, %267 ], [ 2305843009213693951, %258 ]
  %272 = shl i64 %271, 3
  %273 = call i8* @_Znwm(i64 %272) #18
  %274 = bitcast i8* %273 to %"struct.gemmlowp::Task"**
  br label %275

275:                                              ; preds = %270, %262
  %276 = phi i64 [ %271, %270 ], [ 0, %262 ]
  %277 = phi %"struct.gemmlowp::Task"** [ %274, %270 ], [ null, %262 ]
  %278 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %277, i64 %253
  %279 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %277, i64 %276
  %280 = ptrtoint %"struct.gemmlowp::Task"** %279 to i64
  %281 = bitcast %"struct.gemmlowp::Task"** %278 to i64*
  store i64 %242, i64* %281, align 8
  %282 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %278, i64 1
  %283 = ptrtoint %"struct.gemmlowp::Task"** %282 to i64
  %284 = sub i64 %178, %251
  %285 = ashr exact i64 %284, 3
  %286 = sub nsw i64 0, %285
  %287 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %278, i64 %286
  %288 = ptrtoint %"struct.gemmlowp::Task"** %287 to i64
  %289 = icmp sgt i64 %284, 0
  br i1 %289, label %290, label %293

290:                                              ; preds = %275
  %291 = bitcast %"struct.gemmlowp::Task"** %287 to i8*
  %292 = inttoptr i64 %251 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %291, i8* align 8 %292, i64 %284, i1 false) #19
  br label %293

293:                                              ; preds = %290, %275
  store i64 %288, i64* %147, align 8
  store i64 %283, i64* %146, align 8
  store i64 %280, i64* %148, align 8
  %294 = icmp eq i64 %251, 0
  br i1 %294, label %297, label %295

295:                                              ; preds = %293
  %296 = inttoptr i64 %251 to i8*
  call void @_ZdlPv(i8* %296) #18
  br label %297

297:                                              ; preds = %245, %293, %295
  %298 = icmp eq i32 %183, %63
  br i1 %298, label %167, label %299

299:                                              ; preds = %297
  %300 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %139, align 8
  %301 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %140, align 8
  %302 = ptrtoint %"struct.gemmlowp::Task"** %300 to i64
  br label %177

303:                                              ; preds = %150, %59
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSZ_IS11_XT4_EEEPNSZ_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::GemmContext"*, %"struct.gemmlowp::KernelBase"* dereferenceable(8), %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.180"* dereferenceable(24), %"class.gemmlowp::MatrixMap.195"*, %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.std::__1::tuple.197"* dereferenceable(40)) local_unnamed_addr #1 comdat {
  %9 = alloca %"class.gemmlowp::SideMap", align 8
  %10 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %11 = alloca %"struct.gemmlowp::BlockParams", align 4
  %12 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %13 = alloca %"class.std::__1::vector.205", align 8
  %14 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %4, i64 0, i32 1
  %15 = load i32, i32* %14, align 8
  %16 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %4, i64 0, i32 2
  %17 = load i32, i32* %16, align 4
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 2
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %"class.gemmlowp::GemmContext", %"class.gemmlowp::GemmContext"* %0, i64 0, i32 0, i32 0, i32 1
  %21 = load i32, i32* %20, align 4
  switch i32 %21, label %34 [
    i32 1, label %54
    i32 0, label %22
  ]

22:                                               ; preds = %8
  %23 = load atomic i8, i8* bitcast (i64* @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count to i8*) acquire, align 8
  %24 = icmp eq i8 %23, 0
  br i1 %24, label %25, label %32, !prof !514

25:                                               ; preds = %22
  %26 = tail call i32 @__cxa_guard_acquire(i64* nonnull @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count) #19
  %27 = icmp eq i32 %26, 0
  br i1 %27, label %32, label %28

28:                                               ; preds = %25
  %29 = tail call i64 @sysconf(i32 83) #19
  %30 = trunc i64 %29 to i32
  store i32 %30, i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count, align 4
  %31 = tail call {}* @llvm.invariant.start.p0i8(i64 4, i8* bitcast (i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count to i8*)) #19
  tail call void @__cxa_guard_release(i64* nonnull @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count) #19
  br label %32

32:                                               ; preds = %28, %25, %22
  %33 = load i32, i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count, align 4
  br label %34

34:                                               ; preds = %32, %8
  %35 = phi i32 [ %33, %32 ], [ %21, %8 ]
  %36 = add i32 %15, 15
  %37 = sdiv i32 %36, 16
  %38 = icmp slt i32 %37, %35
  %39 = select i1 %38, i32 %37, i32 %35
  %40 = icmp sgt i32 %39, 1
  br i1 %40, label %41, label %56

41:                                               ; preds = %34
  %42 = sext i32 %15 to i64
  %43 = sext i32 %17 to i64
  %44 = mul nsw i64 %43, %42
  %45 = sext i32 %19 to i64
  %46 = mul i64 %44, %45
  %47 = lshr i64 %46, 16
  %48 = trunc i64 %47 to i32
  %49 = icmp sgt i32 %39, %48
  %50 = select i1 %49, i32 %48, i32 %39
  %51 = icmp sgt i32 %50, 1
  br i1 %51, label %52, label %54

52:                                               ; preds = %41
  %53 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br label %61

54:                                               ; preds = %41, %8
  %55 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br label %59

56:                                               ; preds = %34
  %57 = icmp eq i32 %39, 1
  %58 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br i1 %57, label %59, label %61

59:                                               ; preds = %54, %56
  %60 = phi %"class.gemmlowp::SingleThreadGemmContext"* [ %55, %54 ], [ %58, %56 ]
  tail call void @_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSY_IS10_XT4_EEEPNSY_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::SingleThreadGemmContext"* %60, %"struct.gemmlowp::KernelBase"* dereferenceable(8) %1, %"class.gemmlowp::MatrixMap"* dereferenceable(24) %2, %"class.gemmlowp::MatrixMap.180"* dereferenceable(24) %3, %"class.gemmlowp::MatrixMap.195"* %4, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %5, %"class.gemmlowp::VectorDup"* dereferenceable(8) %6, %"class.std::__1::tuple.197"* dereferenceable(40) %7)
  br label %303

61:                                               ; preds = %52, %56
  %62 = phi %"class.gemmlowp::SingleThreadGemmContext"* [ %53, %52 ], [ %58, %56 ]
  %63 = phi i32 [ %50, %52 ], [ %39, %56 ]
  %64 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0
  %65 = getelementptr inbounds %"class.gemmlowp::GemmContext", %"class.gemmlowp::GemmContext"* %0, i64 0, i32 0, i32 1
  %66 = bitcast %"struct.gemmlowp::BlockParams"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %66) #19
  %67 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 1
  %68 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 2
  %69 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 4
  %70 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 5
  %71 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 1
  %72 = bitcast %"struct.gemmlowp::BlockParams"* %11 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %72, i8 -86, i64 24, i1 false)
  %73 = load i32, i32* %71, align 8
  %74 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 2
  %75 = load i32, i32* %74, align 4
  %76 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 3
  %77 = load float, float* %76, align 8
  call void @_ZN8gemmlowp11BlockParams4InitINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES7_EEEEviiiiiif(%"struct.gemmlowp::BlockParams"* nonnull %11, i32 %15, i32 %17, i32 %19, i32 %63, i32 %73, i32 %75, float %77)
  %78 = bitcast %"class.gemmlowp::PackedSideBlock"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %78) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %78, i8 -86, i64 80, i1 false)
  %79 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %64, %"class.gemmlowp::Allocator"** %79, align 8
  %80 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 4
  store i32 0, i32* %80, align 8
  %81 = load i32, i32* %67, align 4
  %82 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 0
  store i32 %81, i32* %82, align 8
  %83 = load i32, i32* %69, align 4
  %84 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 2
  store i32 %83, i32* %84, align 8
  %85 = load i32, i32* %68, align 4
  %86 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 1
  store i32 %85, i32* %86, align 4
  %87 = load i32, i32* %70, align 4
  %88 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 3
  store i32 %87, i32* %88, align 4
  %89 = mul nsw i32 %87, %83
  %90 = sext i32 %89 to i64
  %91 = add nsw i64 %90, 63
  %92 = and i64 %91, -64
  %93 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 4
  %94 = load i64, i64* %93, align 8, !noalias !527
  %95 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 3
  %96 = load i64, i64* %95, align 8, !noalias !527
  %97 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 5, i64 %96
  store i64 %94, i64* %97, align 8, !noalias !527
  %98 = trunc i64 %96 to i8
  %99 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 6
  %100 = load i64, i64* %99, align 8, !noalias !527
  %101 = load i64, i64* %95, align 8, !noalias !527
  %102 = add i64 %101, 1
  store i64 %102, i64* %95, align 8, !noalias !527
  %103 = load i64, i64* %93, align 8, !noalias !527
  %104 = add i64 %103, %92
  store i64 %104, i64* %93, align 8, !noalias !527
  %105 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 0
  store i8 %98, i8* %105, align 8
  %106 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %106, i8 -86, i64 7, i1 false) #19
  %107 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 2
  store i64 %100, i64* %107, align 8
  %108 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 3
  store i8 0, i8* %108, align 8
  %109 = sext i32 %83 to i64
  %110 = shl nsw i64 %109, 2
  %111 = add nsw i64 %110, 63
  %112 = and i64 %111, -64
  %113 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 5, i64 %102
  store i64 %104, i64* %113, align 8, !noalias !530
  %114 = trunc i64 %102 to i8
  %115 = load i64, i64* %99, align 8, !noalias !530
  %116 = bitcast i64* %95 to <2 x i64>*
  %117 = load <2 x i64>, <2 x i64>* %116, align 8, !noalias !530
  %118 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %112, i32 1
  %119 = add <2 x i64> %117, %118
  %120 = bitcast i64* %95 to <2 x i64>*
  store <2 x i64> %119, <2 x i64>* %120, align 8, !noalias !530
  %121 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 0
  store i8 %114, i8* %121, align 8
  %122 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %122, i8 -86, i64 7, i1 false) #19
  %123 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 2
  store i64 %115, i64* %123, align 8
  %124 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 3
  store i8 5, i8* %124, align 8
  call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %64)
  %125 = icmp sgt i32 %17, 0
  br i1 %125, label %126, label %150

126:                                              ; preds = %61
  %127 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 0
  %128 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 3
  %129 = bitcast %"class.gemmlowp::SideMap"* %9 to i8*
  %130 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 1
  %131 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 2
  %132 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 3
  %133 = bitcast %"class.gemmlowp::SideMap"* %9 to i64*
  %134 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %10 to i8*
  %135 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 0
  %136 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 1
  %137 = bitcast %"class.std::__1::vector.205"* %13 to i8*
  %138 = getelementptr inbounds %"class.std::__1::vector.205", %"class.std::__1::vector.205"* %13, i64 0, i32 0, i32 0
  %139 = getelementptr inbounds %"class.std::__1::vector.205", %"class.std::__1::vector.205"* %13, i64 0, i32 0, i32 1
  %140 = getelementptr inbounds %"class.std::__1::vector.205", %"class.std::__1::vector.205"* %13, i64 0, i32 0, i32 2, i32 0, i32 0
  %141 = icmp sgt i32 %63, 0
  %142 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 0
  %143 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 3
  %144 = bitcast %"class.gemmlowp::MatrixMap.195"* %4 to i64*
  %145 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %4, i64 0, i32 3
  %146 = bitcast %"struct.gemmlowp::Task"*** %139 to i64*
  %147 = bitcast %"class.std::__1::vector.205"* %13 to i64*
  %148 = bitcast %"struct.gemmlowp::Task"*** %140 to i64*
  %149 = load i32, i32* %69, align 4
  br label %155

150:                                              ; preds = %173, %61
  %151 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 0
  store i8 0, i8* %151, align 8
  %152 = load i64, i64* %99, align 8
  %153 = add i64 %152, 1
  store i64 %153, i64* %99, align 8
  %154 = bitcast i64* %95 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %154, i8 0, i64 16, i1 false) #19
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %78) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %66) #19
  br label %303

155:                                              ; preds = %126, %173
  %156 = phi i32 [ %149, %126 ], [ %174, %173 ]
  %157 = phi i32 [ 0, %126 ], [ %175, %173 ]
  %158 = sub nsw i32 %17, %157
  %159 = icmp slt i32 %158, %156
  %160 = select i1 %159, i32 %158, i32 %156
  %161 = load i8*, i8** %127, align 8, !noalias !533
  %162 = load i32, i32* %128, align 8, !noalias !533
  %163 = mul nsw i32 %162, %157
  %164 = sext i32 %163 to i64
  %165 = getelementptr inbounds i8, i8* %161, i64 %164
  %166 = ptrtoint i8* %165 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %129) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %129, i8 -86, i64 24, i1 false) #19
  store i64 %166, i64* %133, align 8
  store i32 %160, i32* %130, align 8
  store i32 %19, i32* %131, align 4
  store i32 %162, i32* %132, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %134) #19
  store %"class.gemmlowp::PackedSideBlock"* %12, %"class.gemmlowp::PackedSideBlock"** %135, align 8
  store %"class.gemmlowp::SideMap"* %9, %"class.gemmlowp::SideMap"** %136, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %10) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %134) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %129) #19
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %137) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %137, i8 0, i64 24, i1 false) #19
  br i1 %141, label %177, label %167

167:                                              ; preds = %297, %155
  call void @_ZN8gemmlowp11WorkersPool28LegacyExecuteAndDestroyTasksERKNSt3__16vectorIPNS_4TaskENS1_9allocatorIS4_EEEE(%"class.gemmlowp::WorkersPool"* %65, %"class.std::__1::vector.205"* nonnull dereferenceable(24) %13) #19
  %168 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %138, align 8
  %169 = icmp eq %"struct.gemmlowp::Task"** %168, null
  br i1 %169, label %173, label %170

170:                                              ; preds = %167
  %171 = ptrtoint %"struct.gemmlowp::Task"** %168 to i64
  store i64 %171, i64* %146, align 8
  %172 = bitcast %"struct.gemmlowp::Task"** %168 to i8*
  call void @_ZdlPv(i8* %172) #18
  br label %173

173:                                              ; preds = %167, %170
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %137) #19
  %174 = load i32, i32* %69, align 4
  %175 = add nsw i32 %174, %157
  %176 = icmp sgt i32 %17, %175
  br i1 %176, label %155, label %150

177:                                              ; preds = %155, %299
  %178 = phi i64 [ %302, %299 ], [ 0, %155 ]
  %179 = phi %"struct.gemmlowp::Task"** [ %301, %299 ], [ null, %155 ]
  %180 = phi %"struct.gemmlowp::Task"** [ %300, %299 ], [ null, %155 ]
  %181 = phi i32 [ %183, %299 ], [ 0, %155 ]
  %182 = phi i32 [ %189, %299 ], [ 0, %155 ]
  %183 = add nuw nsw i32 %181, 1
  %184 = mul nsw i32 %183, %15
  %185 = sdiv i32 %184, %63
  %186 = add i32 %185, 3
  %187 = and i32 %186, -4
  %188 = icmp slt i32 %187, %15
  %189 = select i1 %188, i32 %187, i32 %15
  %190 = sub nsw i32 %189, %182
  %191 = load i8*, i8** %142, align 8, !noalias !536
  %192 = load i32, i32* %143, align 8, !noalias !536
  %193 = mul nsw i32 %192, %182
  %194 = sext i32 %193 to i64
  %195 = getelementptr inbounds i8, i8* %191, i64 %194
  %196 = ptrtoint i8* %195 to i64
  %197 = call i8* @_Znwm(i64 208) #18
  %198 = bitcast i8* %197 to i32 (...)***
  %199 = getelementptr inbounds i8, i8* %197, i64 8
  %200 = bitcast i8* %199 to %"class.gemmlowp::Allocator"**
  store %"class.gemmlowp::Allocator"* null, %"class.gemmlowp::Allocator"** %200, align 8
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %198, align 8
  %201 = getelementptr inbounds i8, i8* %197, i64 16
  %202 = bitcast i8* %201 to %"class.gemmlowp::GemmContext"**
  store %"class.gemmlowp::GemmContext"* %0, %"class.gemmlowp::GemmContext"** %202, align 8
  %203 = getelementptr inbounds i8, i8* %197, i64 24
  %204 = bitcast i8* %203 to %"struct.gemmlowp::KernelBase"**
  store %"struct.gemmlowp::KernelBase"* %1, %"struct.gemmlowp::KernelBase"** %204, align 8
  %205 = getelementptr inbounds i8, i8* %197, i64 32
  %206 = bitcast i8* %205 to i64*
  store i64 %196, i64* %206, align 8
  %207 = getelementptr inbounds i8, i8* %197, i64 40
  %208 = bitcast i8* %207 to i32*
  store i32 %190, i32* %208, align 8
  %209 = getelementptr inbounds i8, i8* %197, i64 44
  %210 = bitcast i8* %209 to i32*
  store i32 %19, i32* %210, align 4
  %211 = getelementptr inbounds i8, i8* %197, i64 48
  %212 = bitcast i8* %211 to i32*
  store i32 %192, i32* %212, align 8
  %213 = getelementptr inbounds i8, i8* %197, i64 56
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %213, i8* nonnull align 8 %78, i64 80, i1 false) #19
  %214 = getelementptr inbounds i8, i8* %197, i64 136
  %215 = load i64, i64* %144, align 8
  %216 = bitcast i8* %214 to i64*
  store i64 %215, i64* %216, align 8
  %217 = getelementptr inbounds i8, i8* %197, i64 144
  %218 = bitcast i8* %217 to i32*
  %219 = load i32, i32* %14, align 8
  store i32 %219, i32* %218, align 8
  %220 = getelementptr inbounds i8, i8* %197, i64 148
  %221 = bitcast i8* %220 to i32*
  %222 = load i32, i32* %16, align 4
  store i32 %222, i32* %221, align 4
  %223 = getelementptr inbounds i8, i8* %197, i64 152
  %224 = bitcast i8* %223 to i32*
  %225 = load i32, i32* %145, align 8
  store i32 %225, i32* %224, align 8
  %226 = getelementptr inbounds i8, i8* %197, i64 160
  %227 = bitcast i8* %226 to i32*
  store i32 %182, i32* %227, align 8
  %228 = getelementptr inbounds i8, i8* %197, i64 164
  %229 = bitcast i8* %228 to i32*
  store i32 %157, i32* %229, align 4
  %230 = getelementptr inbounds i8, i8* %197, i64 168
  %231 = bitcast i8* %230 to i32*
  store i32 %190, i32* %231, align 8
  %232 = getelementptr inbounds i8, i8* %197, i64 172
  %233 = bitcast i8* %232 to i32*
  store i32 %160, i32* %233, align 4
  %234 = getelementptr inbounds i8, i8* %197, i64 176
  %235 = bitcast i8* %234 to %"class.gemmlowp::VectorDup.194"**
  store %"class.gemmlowp::VectorDup.194"* %5, %"class.gemmlowp::VectorDup.194"** %235, align 8
  %236 = getelementptr inbounds i8, i8* %197, i64 184
  %237 = bitcast i8* %236 to %"class.gemmlowp::VectorDup"**
  store %"class.gemmlowp::VectorDup"* %6, %"class.gemmlowp::VectorDup"** %237, align 8
  %238 = getelementptr inbounds i8, i8* %197, i64 192
  %239 = bitcast i8* %238 to %"struct.gemmlowp::BlockParams"**
  store %"struct.gemmlowp::BlockParams"* %11, %"struct.gemmlowp::BlockParams"** %239, align 8
  %240 = getelementptr inbounds i8, i8* %197, i64 200
  %241 = bitcast i8* %240 to %"class.std::__1::tuple.197"**
  store %"class.std::__1::tuple.197"* %7, %"class.std::__1::tuple.197"** %241, align 8
  %242 = ptrtoint i8* %197 to i64
  %243 = icmp ult %"struct.gemmlowp::Task"** %180, %179
  %244 = ptrtoint %"struct.gemmlowp::Task"** %179 to i64
  br i1 %243, label %245, label %249

245:                                              ; preds = %177
  %246 = bitcast %"struct.gemmlowp::Task"** %180 to i64*
  store i64 %242, i64* %246, align 8
  %247 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %180, i64 1
  %248 = ptrtoint %"struct.gemmlowp::Task"** %247 to i64
  store i64 %248, i64* %146, align 8
  br label %297

249:                                              ; preds = %177
  %250 = ptrtoint %"struct.gemmlowp::Task"** %180 to i64
  %251 = load i64, i64* %147, align 8
  %252 = sub i64 %250, %251
  %253 = ashr exact i64 %252, 3
  %254 = add nsw i64 %253, 1
  %255 = icmp ugt i64 %254, 2305843009213693951
  br i1 %255, label %256, label %258

256:                                              ; preds = %249
  %257 = bitcast %"class.std::__1::vector.205"* %13 to %"class.std::__1::__vector_base_common"*
  call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* nonnull %257) #20
  unreachable

258:                                              ; preds = %249
  %259 = sub i64 %244, %251
  %260 = ashr exact i64 %259, 3
  %261 = icmp ult i64 %260, 1152921504606846975
  br i1 %261, label %262, label %270

262:                                              ; preds = %258
  %263 = ashr exact i64 %259, 2
  %264 = icmp ult i64 %263, %254
  %265 = select i1 %264, i64 %254, i64 %263
  %266 = icmp eq i64 %265, 0
  br i1 %266, label %275, label %267

267:                                              ; preds = %262
  %268 = icmp ugt i64 %265, 2305843009213693951
  br i1 %268, label %269, label %270

269:                                              ; preds = %267
  call void @abort() #20
  unreachable

270:                                              ; preds = %267, %258
  %271 = phi i64 [ %265, %267 ], [ 2305843009213693951, %258 ]
  %272 = shl i64 %271, 3
  %273 = call i8* @_Znwm(i64 %272) #18
  %274 = bitcast i8* %273 to %"struct.gemmlowp::Task"**
  br label %275

275:                                              ; preds = %270, %262
  %276 = phi i64 [ %271, %270 ], [ 0, %262 ]
  %277 = phi %"struct.gemmlowp::Task"** [ %274, %270 ], [ null, %262 ]
  %278 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %277, i64 %253
  %279 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %277, i64 %276
  %280 = ptrtoint %"struct.gemmlowp::Task"** %279 to i64
  %281 = bitcast %"struct.gemmlowp::Task"** %278 to i64*
  store i64 %242, i64* %281, align 8
  %282 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %278, i64 1
  %283 = ptrtoint %"struct.gemmlowp::Task"** %282 to i64
  %284 = sub i64 %178, %251
  %285 = ashr exact i64 %284, 3
  %286 = sub nsw i64 0, %285
  %287 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %278, i64 %286
  %288 = ptrtoint %"struct.gemmlowp::Task"** %287 to i64
  %289 = icmp sgt i64 %284, 0
  br i1 %289, label %290, label %293

290:                                              ; preds = %275
  %291 = bitcast %"struct.gemmlowp::Task"** %287 to i8*
  %292 = inttoptr i64 %251 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %291, i8* align 8 %292, i64 %284, i1 false) #19
  br label %293

293:                                              ; preds = %290, %275
  store i64 %288, i64* %147, align 8
  store i64 %283, i64* %146, align 8
  store i64 %280, i64* %148, align 8
  %294 = icmp eq i64 %251, 0
  br i1 %294, label %297, label %295

295:                                              ; preds = %293
  %296 = inttoptr i64 %251 to i8*
  call void @_ZdlPv(i8* %296) #18
  br label %297

297:                                              ; preds = %245, %293, %295
  %298 = icmp eq i32 %183, %63
  br i1 %298, label %167, label %299

299:                                              ; preds = %297
  %300 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %139, align 8
  %301 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %140, align 8
  %302 = ptrtoint %"struct.gemmlowp::Task"** %300 to i64
  br label %177

303:                                              ; preds = %150, %59
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSY_IS10_XT4_EEEPNSY_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::SingleThreadGemmContext"*, %"struct.gemmlowp::KernelBase"* dereferenceable(8), %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.180"* dereferenceable(24), %"class.gemmlowp::MatrixMap.195"*, %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.std::__1::tuple.197"* dereferenceable(40)) local_unnamed_addr #1 comdat {
  %9 = alloca %"class.gemmlowp::SideMap", align 8
  %10 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %11 = alloca %"class.gemmlowp::SideMap", align 8
  %12 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %13 = alloca %"class.gemmlowp::SideMap", align 8
  %14 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %15 = alloca %"class.gemmlowp::ComputeImpl", align 8
  %16 = alloca %"struct.gemmlowp::BlockParams", align 4
  %17 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %18 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %19 = alloca %"class.gemmlowp::PackedResult", align 8
  %20 = alloca %"struct.gemmlowp::MatrixBlockBounds", align 4
  %21 = alloca %"class.gemmlowp::VectorDup.194", align 4
  %22 = alloca %"class.gemmlowp::VectorDup", align 4
  %23 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %4, i64 0, i32 1
  %24 = load i32, i32* %23, align 8
  %25 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %4, i64 0, i32 2
  %26 = load i32, i32* %25, align 4
  %27 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 2
  %28 = load i32, i32* %27, align 4
  %29 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0
  %30 = bitcast %"struct.gemmlowp::BlockParams"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %30) #19
  %31 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 0
  %32 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 1
  %33 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 2
  %34 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 3
  %35 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 4
  %36 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 5
  %37 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 1
  %38 = bitcast %"struct.gemmlowp::BlockParams"* %16 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %38, i8 -86, i64 24, i1 false)
  %39 = load i32, i32* %37, align 8
  %40 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 2
  %41 = load i32, i32* %40, align 4
  %42 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 3
  %43 = load float, float* %42, align 8
  call void @_ZN8gemmlowp11BlockParams4InitINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES7_EEEEviiiiiif(%"struct.gemmlowp::BlockParams"* nonnull %16, i32 %24, i32 %26, i32 %28, i32 1, i32 %39, i32 %41, float %43)
  %44 = bitcast %"class.gemmlowp::PackedSideBlock"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %44) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %44, i8 -86, i64 80, i1 false)
  %45 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %45, align 8
  %46 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 4
  store i32 0, i32* %46, align 8
  %47 = load i32, i32* %31, align 4
  %48 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 0
  store i32 %47, i32* %48, align 8
  %49 = load i32, i32* %34, align 4
  %50 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 2
  store i32 %49, i32* %50, align 8
  %51 = load i32, i32* %33, align 4
  %52 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 1
  store i32 %51, i32* %52, align 4
  %53 = load i32, i32* %36, align 4
  %54 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 3
  store i32 %53, i32* %54, align 4
  %55 = mul nsw i32 %53, %49
  %56 = sext i32 %55 to i64
  %57 = add nsw i64 %56, 63
  %58 = and i64 %57, -64
  %59 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 4
  %60 = load i64, i64* %59, align 8, !noalias !539
  %61 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 3
  %62 = load i64, i64* %61, align 8, !noalias !539
  %63 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %62
  store i64 %60, i64* %63, align 8, !noalias !539
  %64 = trunc i64 %62 to i8
  %65 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 6
  %66 = load i64, i64* %65, align 8, !noalias !539
  %67 = load i64, i64* %61, align 8, !noalias !539
  %68 = add i64 %67, 1
  store i64 %68, i64* %61, align 8, !noalias !539
  %69 = load i64, i64* %59, align 8, !noalias !539
  %70 = add i64 %69, %58
  store i64 %70, i64* %59, align 8, !noalias !539
  %71 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 0
  store i8 %64, i8* %71, align 8
  %72 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %72, i8 -86, i64 7, i1 false) #19
  %73 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 2
  store i64 %66, i64* %73, align 8
  %74 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 3
  store i8 0, i8* %74, align 8
  %75 = sext i32 %49 to i64
  %76 = shl nsw i64 %75, 2
  %77 = add nsw i64 %76, 63
  %78 = and i64 %77, -64
  %79 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %68
  store i64 %70, i64* %79, align 8, !noalias !542
  %80 = trunc i64 %68 to i8
  %81 = load i64, i64* %65, align 8, !noalias !542
  %82 = load i64, i64* %61, align 8, !noalias !542
  %83 = add i64 %82, 1
  store i64 %83, i64* %61, align 8, !noalias !542
  %84 = load i64, i64* %59, align 8, !noalias !542
  %85 = add i64 %84, %78
  store i64 %85, i64* %59, align 8, !noalias !542
  %86 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 0
  store i8 %80, i8* %86, align 8
  %87 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %87, i8 -86, i64 7, i1 false) #19
  %88 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 2
  store i64 %81, i64* %88, align 8
  %89 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 3
  store i8 5, i8* %89, align 8
  %90 = bitcast %"class.gemmlowp::PackedSideBlock"* %18 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %90) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %90, i8 -86, i64 80, i1 false)
  %91 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %91, align 8
  %92 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 4
  store i32 0, i32* %92, align 8
  %93 = load i32, i32* %32, align 4
  %94 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 0
  store i32 %93, i32* %94, align 8
  %95 = load i32, i32* %35, align 4
  %96 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 2
  store i32 %95, i32* %96, align 8
  %97 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 1
  store i32 %51, i32* %97, align 4
  %98 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 3
  store i32 %53, i32* %98, align 4
  %99 = mul nsw i32 %53, %95
  %100 = sext i32 %99 to i64
  %101 = add nsw i64 %100, 63
  %102 = and i64 %101, -64
  %103 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %83
  store i64 %85, i64* %103, align 8, !noalias !545
  %104 = trunc i64 %83 to i8
  %105 = load i64, i64* %65, align 8, !noalias !545
  %106 = load i64, i64* %61, align 8, !noalias !545
  %107 = add i64 %106, 1
  store i64 %107, i64* %61, align 8, !noalias !545
  %108 = load i64, i64* %59, align 8, !noalias !545
  %109 = add i64 %108, %102
  store i64 %109, i64* %59, align 8, !noalias !545
  %110 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 0
  store i8 %104, i8* %110, align 8
  %111 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %111, i8 -86, i64 7, i1 false) #19
  %112 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 2
  store i64 %105, i64* %112, align 8
  %113 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 3
  store i8 0, i8* %113, align 8
  %114 = sext i32 %95 to i64
  %115 = shl nsw i64 %114, 2
  %116 = add nsw i64 %115, 63
  %117 = and i64 %116, -64
  %118 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %107
  store i64 %109, i64* %118, align 8, !noalias !548
  %119 = trunc i64 %107 to i8
  %120 = load i64, i64* %65, align 8, !noalias !548
  %121 = load i64, i64* %61, align 8, !noalias !548
  %122 = add i64 %121, 1
  store i64 %122, i64* %61, align 8, !noalias !548
  %123 = load i64, i64* %59, align 8, !noalias !548
  %124 = add i64 %123, %117
  store i64 %124, i64* %59, align 8, !noalias !548
  %125 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 0
  store i8 %119, i8* %125, align 8
  %126 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %126, i8 -86, i64 7, i1 false) #19
  %127 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 2
  store i64 %120, i64* %127, align 8
  %128 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 3
  store i8 5, i8* %128, align 8
  %129 = bitcast %"class.gemmlowp::PackedResult"* %19 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %129) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %129, i8 -86, i64 32, i1 false)
  %130 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 0
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %130, align 8
  %131 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 2
  store %"struct.gemmlowp::BlockParams"* %16, %"struct.gemmlowp::BlockParams"** %131, align 8
  %132 = load i32, i32* %34, align 4
  %133 = mul nsw i32 %95, %132
  %134 = sext i32 %133 to i64
  %135 = shl nsw i64 %134, 2
  %136 = add nsw i64 %135, 63
  %137 = and i64 %136, -64
  %138 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %122
  store i64 %124, i64* %138, align 8, !noalias !551
  %139 = trunc i64 %122 to i8
  %140 = load i64, i64* %65, align 8, !noalias !551
  %141 = bitcast i64* %61 to <2 x i64>*
  %142 = load <2 x i64>, <2 x i64>* %141, align 8, !noalias !551
  %143 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %137, i32 1
  %144 = add <2 x i64> %142, %143
  %145 = bitcast i64* %61 to <2 x i64>*
  store <2 x i64> %144, <2 x i64>* %145, align 8, !noalias !551
  %146 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 0
  store i8 %139, i8* %146, align 8
  %147 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %147, i8 -86, i64 7, i1 false) #19
  %148 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 2
  store i64 %140, i64* %148, align 8
  %149 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 3
  store i8 5, i8* %149, align 8
  call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %29)
  %150 = load i32, i32* %35, align 4
  %151 = icmp sge i32 %150, %26
  br i1 %151, label %152, label %169

152:                                              ; preds = %8
  %153 = bitcast %"class.gemmlowp::SideMap"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %153) #19
  %154 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 1
  %155 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 2
  %156 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 3
  %157 = bitcast %"class.gemmlowp::MatrixMap.180"* %3 to i64*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %153, i8 -86, i64 24, i1 false) #19
  %158 = load i64, i64* %157, align 8
  %159 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 2
  %160 = load i32, i32* %159, align 4
  %161 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 1
  %162 = load i32, i32* %161, align 8
  %163 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 3
  %164 = load i32, i32* %163, align 8
  %165 = bitcast %"class.gemmlowp::SideMap"* %9 to i64*
  store i64 %158, i64* %165, align 8
  store i32 %160, i32* %154, align 8
  store i32 %162, i32* %155, align 4
  store i32 %164, i32* %156, align 8
  %166 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %166) #19
  %167 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 0
  %168 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 1
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %167, align 8
  store %"class.gemmlowp::SideMap"* %9, %"class.gemmlowp::SideMap"** %168, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %10) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %166) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %153) #19
  br label %169

169:                                              ; preds = %152, %8
  %170 = icmp sgt i32 %24, 0
  br i1 %170, label %171, label %216

171:                                              ; preds = %169
  %172 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 0
  %173 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 3
  %174 = bitcast %"class.gemmlowp::SideMap"* %11 to i8*
  %175 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 1
  %176 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 2
  %177 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 3
  %178 = bitcast %"class.gemmlowp::SideMap"* %11 to i64*
  %179 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %12 to i8*
  %180 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %12, i64 0, i32 0
  %181 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %12, i64 0, i32 1
  %182 = icmp sgt i32 %26, 0
  %183 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 0
  %184 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 3
  %185 = bitcast %"class.gemmlowp::SideMap"* %13 to i8*
  %186 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 1
  %187 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 2
  %188 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 3
  %189 = bitcast %"class.gemmlowp::SideMap"* %13 to i64*
  %190 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %14 to i8*
  %191 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %14, i64 0, i32 0
  %192 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %14, i64 0, i32 1
  %193 = bitcast %"class.gemmlowp::ComputeImpl"* %15 to i8*
  %194 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 0
  %195 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 1
  %196 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 2
  %197 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 3
  %198 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 4
  %199 = add i32 %28, 15
  %200 = and i32 %199, -16
  %201 = icmp sgt i32 %200, 0
  %202 = bitcast %"struct.gemmlowp::MatrixBlockBounds"* %20 to i8*
  %203 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 0
  %204 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 1
  %205 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 2
  %206 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 3
  %207 = bitcast %"class.gemmlowp::VectorDup.194"* %21 to i8*
  %208 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 0
  %209 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %21, i64 0, i32 0
  %210 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %21, i64 0, i32 1
  %211 = bitcast %"class.gemmlowp::VectorDup"* %22 to i8*
  %212 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %213 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %22, i64 0, i32 0
  %214 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %22, i64 0, i32 1
  %215 = load i32, i32* %34, align 4
  br label %221

216:                                              ; preds = %235, %169
  %217 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 0
  store i8 0, i8* %217, align 8
  %218 = load i64, i64* %65, align 8
  %219 = add i64 %218, 1
  store i64 %219, i64* %65, align 8
  %220 = bitcast i64* %61 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %220, i8 0, i64 16, i1 false) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %129) #19
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %90) #19
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %44) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %30) #19
  ret void

221:                                              ; preds = %171, %235
  %222 = phi i32 [ %215, %171 ], [ %236, %235 ]
  %223 = phi i32 [ 0, %171 ], [ %237, %235 ]
  %224 = sub nsw i32 %24, %223
  %225 = icmp slt i32 %224, %222
  %226 = select i1 %225, i32 %224, i32 %222
  %227 = load i8*, i8** %172, align 8, !noalias !554
  %228 = load i32, i32* %173, align 8, !noalias !554
  %229 = mul nsw i32 %228, %223
  %230 = sext i32 %229 to i64
  %231 = getelementptr inbounds i8, i8* %227, i64 %230
  %232 = ptrtoint i8* %231 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %174) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %174, i8 -86, i64 24, i1 false) #19
  store i64 %232, i64* %178, align 8
  store i32 %226, i32* %175, align 8
  store i32 %28, i32* %176, align 4
  store i32 %228, i32* %177, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %179) #19
  store %"class.gemmlowp::PackedSideBlock"* %17, %"class.gemmlowp::PackedSideBlock"** %180, align 8
  store %"class.gemmlowp::SideMap"* %11, %"class.gemmlowp::SideMap"** %181, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %12) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %179) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %174) #19
  br i1 %182, label %233, label %235

233:                                              ; preds = %221
  %234 = load i32, i32* %35, align 4
  br label %239

235:                                              ; preds = %311, %221
  %236 = load i32, i32* %34, align 4
  %237 = add nsw i32 %236, %223
  %238 = icmp sgt i32 %24, %237
  br i1 %238, label %221, label %216

239:                                              ; preds = %233, %311
  %240 = phi i32 [ %334, %311 ], [ %234, %233 ]
  %241 = phi i32 [ %335, %311 ], [ 0, %233 ]
  %242 = sub nsw i32 %26, %241
  %243 = icmp slt i32 %242, %240
  %244 = select i1 %243, i32 %242, i32 %240
  br i1 %151, label %252, label %245

245:                                              ; preds = %239
  %246 = load i8*, i8** %183, align 8, !noalias !557
  %247 = load i32, i32* %184, align 8, !noalias !557
  %248 = mul nsw i32 %247, %241
  %249 = sext i32 %248 to i64
  %250 = getelementptr inbounds i8, i8* %246, i64 %249
  %251 = ptrtoint i8* %250 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %185) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %185, i8 -86, i64 24, i1 false) #19
  store i64 %251, i64* %189, align 8
  store i32 %244, i32* %186, align 8
  store i32 %28, i32* %187, align 4
  store i32 %247, i32* %188, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %190) #19
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %191, align 8
  store %"class.gemmlowp::SideMap"* %13, %"class.gemmlowp::SideMap"** %192, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %14) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %190) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %185) #19
  br label %252

252:                                              ; preds = %245, %239
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %193) #19
  store %"struct.gemmlowp::KernelBase"* %1, %"struct.gemmlowp::KernelBase"** %194, align 8
  store %"struct.gemmlowp::BlockParams"* %16, %"struct.gemmlowp::BlockParams"** %195, align 8
  store %"class.gemmlowp::PackedResult"* %19, %"class.gemmlowp::PackedResult"** %196, align 8
  store %"class.gemmlowp::PackedSideBlock"* %17, %"class.gemmlowp::PackedSideBlock"** %197, align 8
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %198, align 8
  br i1 %201, label %253, label %311

253:                                              ; preds = %252, %271
  %254 = phi %"struct.gemmlowp::BlockParams"* [ %273, %271 ], [ %16, %252 ]
  %255 = phi %"struct.gemmlowp::BlockParams"* [ %274, %271 ], [ %16, %252 ]
  %256 = phi i32 [ %275, %271 ], [ 0, %252 ]
  %257 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 2
  %258 = sub nsw i32 %200, %256
  %259 = load i32, i32* %257, align 4
  %260 = icmp slt i32 %258, %259
  %261 = select i1 %260, i32 %258, i32 %259
  %262 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 3
  %263 = load i32, i32* %262, align 4
  %264 = icmp sgt i32 %263, 0
  br i1 %264, label %265, label %271

265:                                              ; preds = %253
  %266 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 0
  %267 = load i32, i32* %266, align 4
  br label %277

268:                                              ; preds = %303
  %269 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 2
  %270 = load i32, i32* %269, align 4
  br label %271

271:                                              ; preds = %268, %253
  %272 = phi i32 [ %259, %253 ], [ %270, %268 ]
  %273 = phi %"struct.gemmlowp::BlockParams"* [ %254, %253 ], [ %304, %268 ]
  %274 = phi %"struct.gemmlowp::BlockParams"* [ %255, %253 ], [ %304, %268 ]
  %275 = add nsw i32 %272, %256
  %276 = icmp sgt i32 %200, %275
  br i1 %276, label %253, label %311

277:                                              ; preds = %303, %265
  %278 = phi %"struct.gemmlowp::BlockParams"* [ %304, %303 ], [ %254, %265 ]
  %279 = phi i32 [ %306, %303 ], [ %267, %265 ]
  %280 = phi i32 [ %309, %303 ], [ %263, %265 ]
  %281 = phi %"struct.gemmlowp::BlockParams"* [ %304, %303 ], [ %255, %265 ]
  %282 = phi i32 [ %307, %303 ], [ 0, %265 ]
  %283 = sub nsw i32 %280, %282
  %284 = icmp slt i32 %283, %279
  %285 = select i1 %284, i32 %283, i32 %279
  %286 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %281, i64 0, i32 4
  %287 = load i32, i32* %286, align 4
  %288 = icmp sgt i32 %287, 0
  br i1 %288, label %289, label %303

289:                                              ; preds = %277
  %290 = icmp sgt i32 %285, 0
  br label %291

291:                                              ; preds = %293, %289
  %292 = phi i32 [ 0, %289 ], [ %294, %293 ]
  br i1 %290, label %296, label %293

293:                                              ; preds = %296, %291
  %294 = add nuw nsw i32 %292, 4
  %295 = icmp slt i32 %294, %287
  br i1 %295, label %291, label %301

296:                                              ; preds = %291, %296
  %297 = phi i32 [ %299, %296 ], [ 0, %291 ]
  %298 = add nsw i32 %297, %282
  call void @_ZN8gemmlowp11ComputeImplINS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEES7_NS_12PackedResultEE10ComputeRunEiiii(%"class.gemmlowp::ComputeImpl"* nonnull %15, i32 %298, i32 %292, i32 %256, i32 %261) #19
  %299 = add nuw nsw i32 %297, 4
  %300 = icmp slt i32 %299, %285
  br i1 %300, label %296, label %293

301:                                              ; preds = %293
  %302 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %195, align 8
  br label %303

303:                                              ; preds = %301, %277
  %304 = phi %"struct.gemmlowp::BlockParams"* [ %302, %301 ], [ %278, %277 ]
  %305 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 0
  %306 = load i32, i32* %305, align 4
  %307 = add nsw i32 %306, %282
  %308 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 3
  %309 = load i32, i32* %308, align 4
  %310 = icmp sgt i32 %309, %307
  br i1 %310, label %277, label %268

311:                                              ; preds = %271, %252
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %193) #19
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %202) #19
  store i32 %223, i32* %203, align 4
  store i32 %241, i32* %204, align 4
  store i32 %226, i32* %205, align 4
  store i32 %244, i32* %206, align 4
  %312 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %45, align 8
  %313 = load i8, i8* %86, align 8
  %314 = zext i8 %313 to i64
  %315 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %312, i64 0, i32 5, i64 %314
  %316 = load i64, i64* %315, align 8
  %317 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %312, i64 0, i32 2
  %318 = bitcast i8** %317 to i64*
  %319 = load i64, i64* %318, align 8
  %320 = add i64 %319, %316
  %321 = inttoptr i64 %320 to i32*
  %322 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %91, align 8
  %323 = load i8, i8* %125, align 8
  %324 = zext i8 %323 to i64
  %325 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %322, i64 0, i32 5, i64 %324
  %326 = load i64, i64* %325, align 8
  %327 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %322, i64 0, i32 2
  %328 = bitcast i8** %327 to i64*
  %329 = load i64, i64* %328, align 8
  %330 = add i64 %329, %326
  %331 = inttoptr i64 %330 to i32*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %207) #19
  %332 = load i32, i32* %208, align 4, !noalias !560
  store i32 %332, i32* %209, align 4, !alias.scope !560
  store i32 %226, i32* %210, align 4, !alias.scope !560
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %211) #19
  %333 = load i32, i32* %212, align 4, !noalias !563
  store i32 %333, i32* %213, align 4, !alias.scope !563
  store i32 %244, i32* %214, align 4, !alias.scope !563
  call void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIhLNS_8MapOrderE1EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE1EEENSC_ISD_LSE_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISD_LSE_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SZ_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.195"* %4, %"struct.gemmlowp::MatrixBlockBounds"* nonnull dereferenceable(16) %20, %"class.gemmlowp::PackedResult"* nonnull dereferenceable(40) %19, i32 %28, i32* %321, i32* %331, %"class.gemmlowp::VectorDup.194"* nonnull dereferenceable(8) %21, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %22, %"class.std::__1::tuple.197"* dereferenceable(40) %7)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %211) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %207) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %202) #19
  %334 = load i32, i32* %35, align 4
  %335 = add nsw i32 %334, %241
  %336 = icmp sgt i32 %26, %335
  br i1 %336, label %239, label %235
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp11BlockParams4InitINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES7_EEEEviiiiiif(%"struct.gemmlowp::BlockParams"*, i32, i32, i32, i32, i32, i32, float) local_unnamed_addr #1 comdat align 2 {
  %9 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %0, i64 0, i32 3
  %10 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %0, i64 0, i32 4
  %11 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %0, i64 0, i32 5
  %12 = add i32 %1, 3
  %13 = and i32 %12, -4
  %14 = sdiv i32 %13, %4
  %15 = icmp sgt i32 %14, 1
  %16 = select i1 %15, i32 %14, i32 1
  %17 = add i32 %3, 15
  %18 = and i32 %17, -16
  %19 = sdiv i32 %6, %18
  %20 = sitofp i32 %19 to float
  %21 = fmul float %20, %7
  %22 = fptosi float %21 to i32
  %23 = icmp sgt i32 %22, 1
  %24 = select i1 %23, i32 %22, i32 1
  %25 = add i32 %2, -1
  %26 = add i32 %24, %25
  %27 = sdiv i32 %26, %24
  %28 = icmp sgt i32 %27, 1
  %29 = select i1 %28, i32 %27, i32 1
  %30 = add i32 %29, %25
  %31 = sdiv i32 %30, %29
  %32 = add i32 %31, 3
  %33 = and i32 %32, -4
  %34 = fcmp oeq float %7, 1.000000e+00
  br i1 %34, label %35, label %37

35:                                               ; preds = %8
  %36 = shl i32 %33, 2
  br label %53

37:                                               ; preds = %8
  %38 = mul nsw i32 %33, %18
  %39 = sub nsw i32 %6, %38
  %40 = shl i32 %33, 2
  %41 = add nsw i32 %40, %18
  %42 = mul nsw i32 %41, %4
  %43 = sdiv i32 %39, %42
  %44 = icmp sgt i32 %43, 1
  %45 = select i1 %44, i32 %43, i32 1
  %46 = add nsw i32 %16, -1
  %47 = add nuw i32 %45, %46
  %48 = sdiv i32 %47, %45
  %49 = icmp sgt i32 %48, 1
  %50 = select i1 %49, i32 %48, i32 1
  %51 = add nuw i32 %50, %46
  %52 = sdiv i32 %51, %50
  br label %53

53:                                               ; preds = %35, %37
  %54 = phi i32 [ %36, %35 ], [ %40, %37 ]
  %55 = phi i32 [ %16, %35 ], [ %52, %37 ]
  %56 = add i32 %55, 3
  %57 = and i32 %56, -4
  store i32 %57, i32* %9, align 4
  store i32 %33, i32* %10, align 4
  store i32 %18, i32* %11, align 4
  %58 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %0, i64 0, i32 0
  %59 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %0, i64 0, i32 1
  %60 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %0, i64 0, i32 2
  %61 = add nsw i32 %5, -64
  %62 = sdiv i32 %61, 8
  %63 = icmp sgt i32 %62, 1
  %64 = select i1 %63, i32 %62, i32 1
  %65 = add i32 %18, -1
  %66 = add i32 %64, %65
  %67 = sdiv i32 %66, %64
  %68 = icmp sgt i32 %67, 1
  %69 = select i1 %68, i32 %67, i32 1
  %70 = add i32 %69, %65
  %71 = sdiv i32 %70, %69
  %72 = add i32 %71, 15
  %73 = and i32 %72, -16
  %74 = add nsw i32 %73, %54
  %75 = sdiv i32 %5, %74
  %76 = icmp sgt i32 %75, 1
  %77 = select i1 %76, i32 %75, i32 1
  %78 = add i32 %57, -1
  %79 = add i32 %77, %78
  %80 = sdiv i32 %79, %77
  %81 = icmp sgt i32 %80, 1
  %82 = select i1 %81, i32 %80, i32 1
  %83 = add i32 %82, %78
  %84 = sdiv i32 %83, %82
  %85 = add i32 %84, 3
  %86 = and i32 %85, -4
  store i32 %86, i32* %58, align 4
  store i32 %33, i32* %59, align 4
  store i32 %73, i32* %60, align 4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"*) local_unnamed_addr #1 comdat align 2 {
  %2 = alloca i8*, align 8
  %3 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %0, i64 0, i32 4
  %4 = load i64, i64* %3, align 8
  %5 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %0, i64 0, i32 1
  %6 = load i64, i64* %5, align 8
  %7 = icmp ugt i64 %4, %6
  br i1 %7, label %8, label %33

8:                                                ; preds = %1
  %9 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %0, i64 0, i32 2
  %10 = load i8*, i8** %9, align 8
  tail call void @free(i8* %10) #19
  %11 = load i64, i64* %3, align 8
  %12 = add i64 %11, -1
  %13 = lshr i64 %12, 1
  %14 = or i64 %13, %12
  %15 = lshr i64 %14, 2
  %16 = or i64 %15, %14
  %17 = lshr i64 %16, 4
  %18 = or i64 %17, %16
  %19 = lshr i64 %18, 8
  %20 = or i64 %19, %18
  %21 = lshr i64 %20, 16
  %22 = or i64 %21, %20
  %23 = add i64 %22, 1
  store i64 %23, i64* %5, align 8
  %24 = bitcast i8** %2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %24) #19
  store i8* inttoptr (i64 -6148914691236517206 to i8*), i8** %2, align 8
  %25 = call i32 @posix_memalign(i8** nonnull %2, i64 64, i64 %23) #19
  %26 = icmp eq i32 %25, 0
  br i1 %26, label %27, label %29

27:                                               ; preds = %8
  %28 = load i8*, i8** %2, align 8
  br label %30

29:                                               ; preds = %8
  store i8* null, i8** %2, align 8
  br label %30

30:                                               ; preds = %27, %29
  %31 = phi i8* [ %28, %27 ], [ null, %29 ]
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %24) #19
  store i8* %31, i8** %9, align 8
  %32 = load i64, i64* %5, align 8
  br label %33

33:                                               ; preds = %30, %1
  %34 = phi i64 [ %32, %30 ], [ %6, %1 ]
  %35 = icmp eq i64 %34, 0
  br i1 %35, label %43, label %36

36:                                               ; preds = %33
  %37 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %0, i64 0, i32 2
  %38 = load i8*, i8** %37, align 8
  %39 = icmp eq i8* %38, null
  br i1 %39, label %40, label %43

40:                                               ; preds = %36
  %41 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
  %42 = call i32 (%struct._IO_FILE*, i8*, ...) @fprintf(%struct._IO_FILE* %41, i8* getelementptr inbounds ([20 x i8], [20 x i8]* @.str.63, i64 0, i64 0), i8* getelementptr inbounds ([19 x i8], [19 x i8]* @.str.62, i64 0, i64 0)) #21
  call void @abort() #20
  unreachable

43:                                               ; preds = %36, %33
  %44 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %0, i64 0, i32 0
  store i8 1, i8* %44, align 8
  ret void
}

; Function Attrs: nofree nounwind
declare i32 @__cxa_guard_acquire(i64*) local_unnamed_addr #15

; Function Attrs: nounwind
declare i64 @sysconf(i32) local_unnamed_addr #14

; Function Attrs: nofree nounwind
declare void @__cxa_guard_release(i64*) local_unnamed_addr #15

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIhLNS_8MapOrderE1EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE1EEENSC_ISD_LSE_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISD_LSE_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SZ_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.195"*, %"struct.gemmlowp::MatrixBlockBounds"* dereferenceable(16), %"class.gemmlowp::PackedResult"* dereferenceable(40), i32, i32*, i32*, %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.std::__1::tuple.197"* dereferenceable(40)) local_unnamed_addr #1 comdat {
  %10 = alloca %"struct.gemmlowp::RegisterBlock", align 8
  %11 = alloca %"class.gemmlowp::MatrixMap.214", align 8
  %12 = alloca %"class.gemmlowp::VectorMap", align 8
  %13 = alloca %"class.gemmlowp::VectorMap.201", align 8
  %14 = alloca %"struct.gemmlowp::OutputPipelineExecutor", align 8
  %15 = alloca %"struct.gemmlowp::OutputPipelineExecutor.226", align 8
  %16 = alloca %"struct.gemmlowp::OutputPipelineExecutor.242", align 8
  %17 = alloca %"struct.gemmlowp::OutputPipelineExecutor.258", align 8
  %18 = alloca %"struct.gemmlowp::OutputPipelineExecutor.270", align 8
  %19 = alloca %"struct.gemmlowp::OutputPipelineExecutor.286", align 8
  %20 = alloca [64 x i8], align 16
  %21 = alloca %"class.gemmlowp::MatrixMap.182", align 8
  %22 = bitcast %"class.gemmlowp::MatrixMap.214"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %22) #19
  %23 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %11, i64 0, i32 0
  %24 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %11, i64 0, i32 1
  %25 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %11, i64 0, i32 2
  %26 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %11, i64 0, i32 3
  %27 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 0
  %28 = bitcast %"class.gemmlowp::MatrixMap.214"* %11 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %28, i8 -86, i64 24, i1 false)
  %29 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %27, align 8, !noalias !566
  %30 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 1, i32 0
  %31 = load i8, i8* %30, align 8, !noalias !566
  %32 = zext i8 %31 to i64
  %33 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %29, i64 0, i32 5, i64 %32
  %34 = load i64, i64* %33, align 8, !noalias !566
  %35 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %29, i64 0, i32 2
  %36 = bitcast i8** %35 to i64*
  %37 = load i64, i64* %36, align 8, !noalias !566
  %38 = add i64 %37, %34
  %39 = inttoptr i64 %38 to i32*
  %40 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 2
  %41 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %40, align 8, !noalias !566
  %42 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %41, i64 0, i32 3
  %43 = load i32, i32* %42, align 4, !noalias !566
  %44 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %41, i64 0, i32 4
  %45 = load i32, i32* %44, align 4, !noalias !566
  store i32* %39, i32** %23, align 8, !alias.scope !566
  store i32 %43, i32* %24, align 8, !alias.scope !566
  store i32 %45, i32* %25, align 4, !alias.scope !566
  store i32 %43, i32* %26, align 8, !alias.scope !566
  %46 = bitcast %"class.gemmlowp::VectorMap"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %46) #19
  %47 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %12, i64 0, i32 0
  %48 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %12, i64 0, i32 1
  %49 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 2
  %50 = bitcast %"class.gemmlowp::VectorMap"* %12 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %50, i8 -86, i64 16, i1 false)
  %51 = load i32, i32* %49, align 4
  store i32* %4, i32** %47, align 8
  store i32 %51, i32* %48, align 8
  %52 = bitcast %"class.gemmlowp::VectorMap.201"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %52) #19
  %53 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %13, i64 0, i32 0
  %54 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %13, i64 0, i32 1
  %55 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 3
  %56 = bitcast %"class.gemmlowp::VectorMap.201"* %13 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %56, i8 -86, i64 16, i1 false)
  %57 = load i32, i32* %55, align 4
  store i32* %5, i32** %53, align 8
  store i32 %57, i32* %54, align 8
  %58 = bitcast %"struct.gemmlowp::OutputPipelineExecutor"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %58) #19
  %59 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor", %"struct.gemmlowp::OutputPipelineExecutor"* %14, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %60 = bitcast i8* %59 to i64*
  store i64 -6148914691236517206, i64* %60, align 8
  %61 = getelementptr inbounds %"class.std::__1::tuple.197", %"class.std::__1::tuple.197"* %8, i64 0, i32 0, i32 0, i32 0
  %62 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor", %"struct.gemmlowp::OutputPipelineExecutor"* %14, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition.200"* %61, %"struct.gemmlowp::OutputStageBiasAddition.200"** %62, align 8
  %63 = getelementptr inbounds %"class.std::__1::tuple.197", %"class.std::__1::tuple.197"* %8, i64 0, i32 0, i32 1, i32 0
  %64 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor", %"struct.gemmlowp::OutputPipelineExecutor"* %14, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %63, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %64, align 8
  %65 = getelementptr inbounds %"class.std::__1::tuple.197", %"class.std::__1::tuple.197"* %8, i64 0, i32 0, i32 1, i32 0, i32 1
  %66 = load i32, i32* %65, align 4
  %67 = icmp sgt i32 %66, 0
  %68 = select i1 %67, i32 %66, i32 0
  %69 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor", %"struct.gemmlowp::OutputPipelineExecutor"* %14, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %68, i32* %69, align 8
  %70 = sub nsw i32 0, %66
  %71 = icmp sgt i32 %70, 0
  %72 = select i1 %71, i32 %70, i32 0
  %73 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor", %"struct.gemmlowp::OutputPipelineExecutor"* %14, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %72, i32* %73, align 4
  %74 = getelementptr inbounds %"class.std::__1::tuple.197", %"class.std::__1::tuple.197"* %8, i64 0, i32 0, i32 2, i32 0
  %75 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor", %"struct.gemmlowp::OutputPipelineExecutor"* %14, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %74, %"struct.gemmlowp::OutputStageClamp"** %75, align 8
  %76 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.226"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %76) #19
  %77 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.226", %"struct.gemmlowp::OutputPipelineExecutor.226"* %15, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %78 = bitcast i8* %77 to i64*
  store i64 -6148914691236517206, i64* %78, align 8
  %79 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.226", %"struct.gemmlowp::OutputPipelineExecutor.226"* %15, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition.200"* %61, %"struct.gemmlowp::OutputStageBiasAddition.200"** %79, align 8
  %80 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.226", %"struct.gemmlowp::OutputPipelineExecutor.226"* %15, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %63, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %80, align 8
  %81 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.226", %"struct.gemmlowp::OutputPipelineExecutor.226"* %15, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %68, i32* %81, align 8
  %82 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.226", %"struct.gemmlowp::OutputPipelineExecutor.226"* %15, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %72, i32* %82, align 4
  %83 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.226", %"struct.gemmlowp::OutputPipelineExecutor.226"* %15, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %74, %"struct.gemmlowp::OutputStageClamp"** %83, align 8
  %84 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.242"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %84) #19
  %85 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.242", %"struct.gemmlowp::OutputPipelineExecutor.242"* %16, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %86 = bitcast i8* %85 to i64*
  store i64 -6148914691236517206, i64* %86, align 8
  %87 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.242", %"struct.gemmlowp::OutputPipelineExecutor.242"* %16, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition.200"* %61, %"struct.gemmlowp::OutputStageBiasAddition.200"** %87, align 8
  %88 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.242", %"struct.gemmlowp::OutputPipelineExecutor.242"* %16, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %63, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %88, align 8
  %89 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.242", %"struct.gemmlowp::OutputPipelineExecutor.242"* %16, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %68, i32* %89, align 8
  %90 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.242", %"struct.gemmlowp::OutputPipelineExecutor.242"* %16, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %72, i32* %90, align 4
  %91 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.242", %"struct.gemmlowp::OutputPipelineExecutor.242"* %16, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %74, %"struct.gemmlowp::OutputStageClamp"** %91, align 8
  %92 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.258"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %92) #19
  %93 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.258", %"struct.gemmlowp::OutputPipelineExecutor.258"* %17, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %94 = bitcast i8* %93 to i64*
  store i64 -6148914691236517206, i64* %94, align 8
  %95 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.258", %"struct.gemmlowp::OutputPipelineExecutor.258"* %17, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition.200"* %61, %"struct.gemmlowp::OutputStageBiasAddition.200"** %95, align 8
  %96 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.258", %"struct.gemmlowp::OutputPipelineExecutor.258"* %17, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %63, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %96, align 8
  %97 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.258", %"struct.gemmlowp::OutputPipelineExecutor.258"* %17, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %68, i32* %97, align 8
  %98 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.258", %"struct.gemmlowp::OutputPipelineExecutor.258"* %17, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %72, i32* %98, align 4
  %99 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.258", %"struct.gemmlowp::OutputPipelineExecutor.258"* %17, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %74, %"struct.gemmlowp::OutputStageClamp"** %99, align 8
  %100 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.270"* %18 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %100) #19
  %101 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.270", %"struct.gemmlowp::OutputPipelineExecutor.270"* %18, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %102 = bitcast i8* %101 to i64*
  store i64 -6148914691236517206, i64* %102, align 8
  %103 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.270", %"struct.gemmlowp::OutputPipelineExecutor.270"* %18, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition.200"* %61, %"struct.gemmlowp::OutputStageBiasAddition.200"** %103, align 8
  %104 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.270", %"struct.gemmlowp::OutputPipelineExecutor.270"* %18, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %63, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %104, align 8
  %105 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.270", %"struct.gemmlowp::OutputPipelineExecutor.270"* %18, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %68, i32* %105, align 8
  %106 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.270", %"struct.gemmlowp::OutputPipelineExecutor.270"* %18, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %72, i32* %106, align 4
  %107 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.270", %"struct.gemmlowp::OutputPipelineExecutor.270"* %18, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %74, %"struct.gemmlowp::OutputStageClamp"** %107, align 8
  %108 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.286"* %19 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %108) #19
  %109 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.286", %"struct.gemmlowp::OutputPipelineExecutor.286"* %19, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %110 = bitcast i8* %109 to i64*
  store i64 -6148914691236517206, i64* %110, align 8
  %111 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.286", %"struct.gemmlowp::OutputPipelineExecutor.286"* %19, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition.200"* %61, %"struct.gemmlowp::OutputStageBiasAddition.200"** %111, align 8
  %112 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.286", %"struct.gemmlowp::OutputPipelineExecutor.286"* %19, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %63, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %112, align 8
  %113 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.286", %"struct.gemmlowp::OutputPipelineExecutor.286"* %19, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %68, i32* %113, align 8
  %114 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.286", %"struct.gemmlowp::OutputPipelineExecutor.286"* %19, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %72, i32* %114, align 4
  %115 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.286", %"struct.gemmlowp::OutputPipelineExecutor.286"* %19, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %74, %"struct.gemmlowp::OutputStageClamp"** %115, align 8
  %116 = icmp slt i32 %57, 8
  br i1 %116, label %133, label %117

117:                                              ; preds = %9
  %118 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 0
  %119 = getelementptr inbounds [64 x i8], [64 x i8]* %20, i64 0, i64 0
  %120 = bitcast %"class.gemmlowp::MatrixMap.182"* %21 to i8*
  %121 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %21, i64 0, i32 0
  %122 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %21, i64 0, i32 1
  %123 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %21, i64 0, i32 2
  %124 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %21, i64 0, i32 3
  %125 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 1
  %126 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock", %"struct.gemmlowp::RegisterBlock"* %10, i64 0, i32 0, i32 0, i64 0
  %127 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %6, i64 0, i32 0
  %128 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %7, i64 0, i32 0
  %129 = load i32, i32* %49, align 4
  %130 = bitcast %"class.gemmlowp::MatrixMap.182"* %21 to i8*
  br label %145

131:                                              ; preds = %442
  %132 = trunc i64 %444 to i32
  br label %133

133:                                              ; preds = %131, %9
  %134 = phi i32 [ %57, %9 ], [ %445, %131 ]
  %135 = phi i32 [ 0, %9 ], [ %132, %131 ]
  %136 = add nsw i32 %134, -4
  %137 = icmp sgt i32 %135, %136
  br i1 %137, label %451, label %138

138:                                              ; preds = %133
  %139 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 1
  %140 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 0
  %141 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %6, i64 0, i32 0
  %142 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %7, i64 0, i32 0
  %143 = zext i32 %135 to i64
  %144 = load i32, i32* %49, align 4
  br label %462

145:                                              ; preds = %117, %442
  %146 = phi i32 [ %129, %117 ], [ %443, %442 ]
  %147 = phi i64 [ 0, %117 ], [ %444, %442 ]
  %148 = load i32*, i32** %23, align 8
  %149 = load i32, i32* %26, align 8
  %150 = trunc i64 %147 to i32
  %151 = mul nsw i32 %149, %150
  %152 = sext i32 %151 to i64
  %153 = load i32*, i32** %47, align 8
  %154 = bitcast i32* %153 to i8*
  call void @llvm.prefetch(i8* %154, i32 0, i32 3, i32 1) #19
  %155 = getelementptr inbounds i32, i32* %153, i64 4
  %156 = bitcast i32* %155 to i8*
  call void @llvm.prefetch(i8* %156, i32 0, i32 3, i32 1) #19
  %157 = getelementptr inbounds i32, i32* %148, i64 %152
  %158 = sext i32 %149 to i64
  %159 = bitcast i32* %157 to i8*
  call void @llvm.prefetch(i8* %159, i32 0, i32 3, i32 1) #19
  %160 = getelementptr inbounds i32, i32* %157, i64 4
  %161 = bitcast i32* %160 to i8*
  call void @llvm.prefetch(i8* %161, i32 0, i32 3, i32 1) #19
  %162 = getelementptr inbounds i32, i32* %157, i64 %158
  %163 = bitcast i32* %162 to i8*
  call void @llvm.prefetch(i8* %163, i32 0, i32 3, i32 1) #19
  %164 = getelementptr inbounds i32, i32* %162, i64 4
  %165 = bitcast i32* %164 to i8*
  call void @llvm.prefetch(i8* %165, i32 0, i32 3, i32 1) #19
  %166 = shl nsw i64 %158, 1
  %167 = getelementptr inbounds i32, i32* %157, i64 %166
  %168 = bitcast i32* %167 to i8*
  call void @llvm.prefetch(i8* %168, i32 0, i32 3, i32 1) #19
  %169 = getelementptr inbounds i32, i32* %167, i64 4
  %170 = bitcast i32* %169 to i8*
  call void @llvm.prefetch(i8* %170, i32 0, i32 3, i32 1) #19
  %171 = mul nsw i64 %158, 3
  %172 = getelementptr inbounds i32, i32* %157, i64 %171
  %173 = bitcast i32* %172 to i8*
  call void @llvm.prefetch(i8* %173, i32 0, i32 3, i32 1) #19
  %174 = getelementptr inbounds i32, i32* %172, i64 4
  %175 = bitcast i32* %174 to i8*
  call void @llvm.prefetch(i8* %175, i32 0, i32 3, i32 1) #19
  %176 = shl nsw i64 %158, 2
  %177 = getelementptr inbounds i32, i32* %157, i64 %176
  %178 = bitcast i32* %177 to i8*
  call void @llvm.prefetch(i8* %178, i32 0, i32 3, i32 1) #19
  %179 = getelementptr inbounds i32, i32* %177, i64 4
  %180 = bitcast i32* %179 to i8*
  call void @llvm.prefetch(i8* %180, i32 0, i32 3, i32 1) #19
  %181 = mul nsw i64 %158, 5
  %182 = getelementptr inbounds i32, i32* %157, i64 %181
  %183 = bitcast i32* %182 to i8*
  call void @llvm.prefetch(i8* %183, i32 0, i32 3, i32 1) #19
  %184 = getelementptr inbounds i32, i32* %182, i64 4
  %185 = bitcast i32* %184 to i8*
  call void @llvm.prefetch(i8* %185, i32 0, i32 3, i32 1) #19
  %186 = mul nsw i64 %158, 6
  %187 = getelementptr inbounds i32, i32* %157, i64 %186
  %188 = bitcast i32* %187 to i8*
  call void @llvm.prefetch(i8* %188, i32 0, i32 3, i32 1) #19
  %189 = getelementptr inbounds i32, i32* %187, i64 4
  %190 = bitcast i32* %189 to i8*
  call void @llvm.prefetch(i8* %190, i32 0, i32 3, i32 1) #19
  %191 = mul nsw i64 %158, 7
  %192 = getelementptr inbounds i32, i32* %157, i64 %191
  %193 = bitcast i32* %192 to i8*
  call void @llvm.prefetch(i8* %193, i32 0, i32 3, i32 1) #19
  %194 = getelementptr inbounds i32, i32* %192, i64 4
  %195 = bitcast i32* %194 to i8*
  call void @llvm.prefetch(i8* %195, i32 0, i32 3, i32 1) #19
  %196 = icmp slt i32 %146, 8
  br i1 %196, label %202, label %197

197:                                              ; preds = %145
  %198 = trunc i64 %147 to i32
  %199 = or i32 %198, 4
  br label %210

200:                                              ; preds = %210
  %201 = trunc i64 %218 to i32
  br label %202

202:                                              ; preds = %200, %145
  %203 = phi i32 [ %146, %145 ], [ %273, %200 ]
  %204 = phi i32 [ 0, %145 ], [ %201, %200 ]
  %205 = add nsw i32 %203, -4
  %206 = icmp sgt i32 %204, %205
  br i1 %206, label %281, label %207

207:                                              ; preds = %202
  %208 = trunc i64 %147 to i32
  %209 = or i32 %208, 4
  br label %295

210:                                              ; preds = %277, %197
  %211 = phi i32* [ %153, %197 ], [ %280, %277 ]
  %212 = phi i32 [ %149, %197 ], [ %279, %277 ]
  %213 = phi i32* [ %148, %197 ], [ %278, %277 ]
  %214 = phi i64 [ 0, %197 ], [ %218, %277 ]
  %215 = load i32, i32* %118, align 4
  %216 = trunc i64 %214 to i32
  %217 = add nsw i32 %215, %216
  %218 = add nuw i64 %214, 8
  %219 = mul nsw i32 %212, %150
  %220 = sext i32 %219 to i64
  %221 = getelementptr inbounds i32, i32* %211, i64 %218
  %222 = bitcast i32* %221 to i8*
  call void @llvm.prefetch(i8* %222, i32 0, i32 3, i32 1) #19
  %223 = getelementptr inbounds i32, i32* %221, i64 4
  %224 = bitcast i32* %223 to i8*
  call void @llvm.prefetch(i8* %224, i32 0, i32 3, i32 1) #19
  %225 = getelementptr inbounds i32, i32* %213, i64 %218
  %226 = getelementptr inbounds i32, i32* %225, i64 %220
  %227 = sext i32 %212 to i64
  %228 = bitcast i32* %226 to i8*
  call void @llvm.prefetch(i8* %228, i32 0, i32 3, i32 1) #19
  %229 = getelementptr inbounds i32, i32* %226, i64 4
  %230 = bitcast i32* %229 to i8*
  call void @llvm.prefetch(i8* %230, i32 0, i32 3, i32 1) #19
  %231 = getelementptr inbounds i32, i32* %226, i64 %227
  %232 = bitcast i32* %231 to i8*
  call void @llvm.prefetch(i8* %232, i32 0, i32 3, i32 1) #19
  %233 = getelementptr inbounds i32, i32* %231, i64 4
  %234 = bitcast i32* %233 to i8*
  call void @llvm.prefetch(i8* %234, i32 0, i32 3, i32 1) #19
  %235 = shl nsw i64 %227, 1
  %236 = getelementptr inbounds i32, i32* %226, i64 %235
  %237 = bitcast i32* %236 to i8*
  call void @llvm.prefetch(i8* %237, i32 0, i32 3, i32 1) #19
  %238 = getelementptr inbounds i32, i32* %236, i64 4
  %239 = bitcast i32* %238 to i8*
  call void @llvm.prefetch(i8* %239, i32 0, i32 3, i32 1) #19
  %240 = mul nsw i64 %227, 3
  %241 = getelementptr inbounds i32, i32* %226, i64 %240
  %242 = bitcast i32* %241 to i8*
  call void @llvm.prefetch(i8* %242, i32 0, i32 3, i32 1) #19
  %243 = getelementptr inbounds i32, i32* %241, i64 4
  %244 = bitcast i32* %243 to i8*
  call void @llvm.prefetch(i8* %244, i32 0, i32 3, i32 1) #19
  %245 = shl nsw i64 %227, 2
  %246 = getelementptr inbounds i32, i32* %226, i64 %245
  %247 = bitcast i32* %246 to i8*
  call void @llvm.prefetch(i8* %247, i32 0, i32 3, i32 1) #19
  %248 = getelementptr inbounds i32, i32* %246, i64 4
  %249 = bitcast i32* %248 to i8*
  call void @llvm.prefetch(i8* %249, i32 0, i32 3, i32 1) #19
  %250 = mul nsw i64 %227, 5
  %251 = getelementptr inbounds i32, i32* %226, i64 %250
  %252 = bitcast i32* %251 to i8*
  call void @llvm.prefetch(i8* %252, i32 0, i32 3, i32 1) #19
  %253 = getelementptr inbounds i32, i32* %251, i64 4
  %254 = bitcast i32* %253 to i8*
  call void @llvm.prefetch(i8* %254, i32 0, i32 3, i32 1) #19
  %255 = mul nsw i64 %227, 6
  %256 = getelementptr inbounds i32, i32* %226, i64 %255
  %257 = bitcast i32* %256 to i8*
  call void @llvm.prefetch(i8* %257, i32 0, i32 3, i32 1) #19
  %258 = getelementptr inbounds i32, i32* %256, i64 4
  %259 = bitcast i32* %258 to i8*
  call void @llvm.prefetch(i8* %259, i32 0, i32 3, i32 1) #19
  %260 = mul nsw i64 %227, 7
  %261 = getelementptr inbounds i32, i32* %226, i64 %260
  %262 = bitcast i32* %261 to i8*
  call void @llvm.prefetch(i8* %262, i32 0, i32 3, i32 1) #19
  %263 = getelementptr inbounds i32, i32* %261, i64 4
  %264 = bitcast i32* %263 to i8*
  call void @llvm.prefetch(i8* %264, i32 0, i32 3, i32 1) #19
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %119) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %119, i8 -86, i64 64, i1 false)
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %120) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %130, i8 -86, i64 24, i1 false)
  store i8* %119, i8** %121, align 8
  store i32 8, i32* %122, align 8
  store i32 8, i32* %123, align 4
  store i32 8, i32* %124, align 8
  %265 = load i32, i32* %125, align 4
  %266 = add nsw i32 %265, %150
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.286"* nonnull dereferenceable(40) %19, %"class.gemmlowp::MatrixMap.182"* nonnull %21, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %216, i32 %150, i32 %217, i32 %266, i32 0, i32 0)
  %267 = load i32, i32* %125, align 4
  %268 = add nsw i32 %267, %199
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.286"* nonnull dereferenceable(40) %19, %"class.gemmlowp::MatrixMap.182"* nonnull %21, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %216, i32 %199, i32 %217, i32 %268, i32 0, i32 4)
  %269 = load i32, i32* %118, align 4
  %270 = add nsw i32 %269, %216
  %271 = load i32, i32* %125, align 4
  %272 = add nsw i32 %271, %150
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %126)
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %126, i8* nonnull align 16 %119, i64 64, i1 false)
  call void @_ZN8gemmlowp20StoreFinalOutputImplINS_13RegisterBlockIhLi8ELi8EEENS_9MatrixMapIhLNS_8MapOrderE1EEEE3RunERKS2_PS5_ii(%"struct.gemmlowp::RegisterBlock"* nonnull dereferenceable(64) %10, %"class.gemmlowp::MatrixMap.195"* %0, i32 %270, i32 %272) #19
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %126)
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %120) #19
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %119) #19
  %273 = load i32, i32* %49, align 4
  %274 = add nsw i32 %273, -8
  %275 = trunc i64 %218 to i32
  %276 = icmp slt i32 %274, %275
  br i1 %276, label %200, label %277

277:                                              ; preds = %210
  %278 = load i32*, i32** %23, align 8
  %279 = load i32, i32* %26, align 8
  %280 = load i32*, i32** %47, align 8
  br label %210

281:                                              ; preds = %295, %202
  %282 = phi i32 [ %203, %202 ], [ %304, %295 ]
  %283 = phi i32 [ %204, %202 ], [ %303, %295 ]
  %284 = icmp slt i32 %283, %282
  br i1 %284, label %285, label %442

285:                                              ; preds = %281
  %286 = zext i32 %283 to i64
  %287 = or i64 %147, 1
  %288 = or i64 %147, 2
  %289 = or i64 %147, 3
  %290 = or i64 %147, 4
  %291 = trunc i64 %290 to i32
  %292 = or i64 %147, 5
  %293 = or i64 %147, 6
  %294 = or i64 %147, 7
  br label %307

295:                                              ; preds = %207, %295
  %296 = phi i32 [ %303, %295 ], [ %204, %207 ]
  %297 = load i32, i32* %118, align 4
  %298 = add nsw i32 %297, %296
  %299 = load i32, i32* %125, align 4
  %300 = add nsw i32 %299, %150
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.270"* nonnull dereferenceable(40) %18, %"class.gemmlowp::MatrixMap.195"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %296, i32 %150, i32 %298, i32 %300, i32 %298, i32 %300)
  %301 = load i32, i32* %125, align 4
  %302 = add nsw i32 %301, %209
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.270"* nonnull dereferenceable(40) %18, %"class.gemmlowp::MatrixMap.195"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %296, i32 %209, i32 %298, i32 %302, i32 %298, i32 %302)
  %303 = add nuw nsw i32 %296, 4
  %304 = load i32, i32* %49, align 4
  %305 = add nsw i32 %304, -4
  %306 = icmp sgt i32 %303, %305
  br i1 %306, label %281, label %295

307:                                              ; preds = %285, %307
  %308 = phi i64 [ %286, %285 ], [ %438, %307 ]
  %309 = load i32, i32* %118, align 4
  %310 = trunc i64 %308 to i32
  %311 = add nsw i32 %309, %310
  %312 = load i32, i32* %125, align 4
  %313 = add nsw i32 %312, %150
  %314 = load i32*, i32** %23, align 8
  %315 = getelementptr inbounds i32, i32* %314, i64 %308
  %316 = load i32, i32* %26, align 8
  %317 = mul nsw i32 %316, %150
  %318 = sext i32 %317 to i64
  %319 = getelementptr inbounds i32, i32* %315, i64 %318
  %320 = load i32, i32* %319, align 4
  %321 = sext i32 %316 to i64
  %322 = mul nsw i64 %287, %321
  %323 = getelementptr inbounds i32, i32* %315, i64 %322
  %324 = load i32, i32* %323, align 4
  %325 = mul nsw i64 %288, %321
  %326 = getelementptr inbounds i32, i32* %315, i64 %325
  %327 = load i32, i32* %326, align 4
  %328 = mul nsw i64 %289, %321
  %329 = getelementptr inbounds i32, i32* %315, i64 %328
  %330 = load i32, i32* %329, align 4
  %331 = load i32*, i32** %47, align 8
  %332 = getelementptr inbounds i32, i32* %331, i64 %308
  %333 = load i32, i32* %332, align 4
  %334 = load i32*, i32** %53, align 8
  %335 = getelementptr i32, i32* %334, i64 %147
  %336 = bitcast i32* %335 to i64*
  %337 = load i64, i64* %336, align 4
  %338 = getelementptr inbounds i32, i32* %335, i64 2
  %339 = bitcast i32* %338 to i64*
  %340 = load i64, i64* %339, align 4
  %341 = trunc i64 %337 to i32
  %342 = lshr i64 %337, 32
  %343 = trunc i64 %342 to i32
  %344 = load i32, i32* %127, align 4
  %345 = load i32, i32* %128, align 4
  %346 = mul nsw i32 %345, %333
  %347 = add nsw i32 %346, %320
  %348 = add nsw i32 %346, %324
  %349 = add nsw i32 %346, %327
  %350 = add nsw i32 %346, %330
  %351 = mul nsw i32 %345, %3
  %352 = add nsw i32 %351, %341
  %353 = add nsw i32 %351, %343
  %354 = trunc i64 %340 to i32
  %355 = add nsw i32 %351, %354
  %356 = lshr i64 %340, 32
  %357 = trunc i64 %356 to i32
  %358 = add nsw i32 %351, %357
  %359 = mul nsw i32 %352, %344
  %360 = add nsw i32 %347, %359
  %361 = mul nsw i32 %353, %344
  %362 = add nsw i32 %348, %361
  %363 = mul nsw i32 %355, %344
  %364 = add nsw i32 %349, %363
  %365 = zext i32 %364 to i64
  %366 = mul nsw i32 %358, %344
  %367 = add nsw i32 %350, %366
  %368 = zext i32 %367 to i64
  %369 = shl nuw i64 %368, 32
  %370 = or i64 %369, %365
  %371 = zext i32 %362 to i64
  %372 = shl nuw i64 %371, 32
  %373 = zext i32 %360 to i64
  %374 = or i64 %372, %373
  call void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_13RegisterBlockIiLi1ELi4EEEE7ExecuteINS_9MatrixMapIhLNS_8MapOrderE1EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.258"* nonnull %17, i64 %374, i64 %370, %"class.gemmlowp::MatrixMap.195"* %0, i32 %311, i32 %313, i32 %311, i32 %313) #19
  %375 = load i32, i32* %125, align 4
  %376 = add nsw i32 %375, %291
  %377 = load i32*, i32** %23, align 8
  %378 = getelementptr inbounds i32, i32* %377, i64 %308
  %379 = load i32, i32* %26, align 8
  %380 = mul nsw i32 %379, %291
  %381 = sext i32 %380 to i64
  %382 = getelementptr inbounds i32, i32* %378, i64 %381
  %383 = load i32, i32* %382, align 4
  %384 = sext i32 %379 to i64
  %385 = mul nsw i64 %292, %384
  %386 = getelementptr inbounds i32, i32* %378, i64 %385
  %387 = load i32, i32* %386, align 4
  %388 = mul nsw i64 %293, %384
  %389 = getelementptr inbounds i32, i32* %378, i64 %388
  %390 = load i32, i32* %389, align 4
  %391 = mul nsw i64 %294, %384
  %392 = getelementptr inbounds i32, i32* %378, i64 %391
  %393 = load i32, i32* %392, align 4
  %394 = load i32*, i32** %47, align 8
  %395 = getelementptr inbounds i32, i32* %394, i64 %308
  %396 = load i32, i32* %395, align 4
  %397 = load i32*, i32** %53, align 8
  %398 = getelementptr i32, i32* %397, i64 %290
  %399 = bitcast i32* %398 to i64*
  %400 = load i64, i64* %399, align 4
  %401 = getelementptr inbounds i32, i32* %398, i64 2
  %402 = bitcast i32* %401 to i64*
  %403 = load i64, i64* %402, align 4
  %404 = trunc i64 %400 to i32
  %405 = lshr i64 %400, 32
  %406 = trunc i64 %405 to i32
  %407 = load i32, i32* %127, align 4
  %408 = load i32, i32* %128, align 4
  %409 = mul nsw i32 %408, %396
  %410 = add nsw i32 %409, %383
  %411 = add nsw i32 %409, %387
  %412 = add nsw i32 %409, %390
  %413 = add nsw i32 %409, %393
  %414 = mul nsw i32 %408, %3
  %415 = add nsw i32 %414, %404
  %416 = add nsw i32 %414, %406
  %417 = trunc i64 %403 to i32
  %418 = add nsw i32 %414, %417
  %419 = lshr i64 %403, 32
  %420 = trunc i64 %419 to i32
  %421 = add nsw i32 %414, %420
  %422 = mul nsw i32 %415, %407
  %423 = add nsw i32 %410, %422
  %424 = mul nsw i32 %416, %407
  %425 = add nsw i32 %411, %424
  %426 = mul nsw i32 %418, %407
  %427 = add nsw i32 %412, %426
  %428 = zext i32 %427 to i64
  %429 = mul nsw i32 %421, %407
  %430 = add nsw i32 %413, %429
  %431 = zext i32 %430 to i64
  %432 = shl nuw i64 %431, 32
  %433 = or i64 %432, %428
  %434 = zext i32 %425 to i64
  %435 = shl nuw i64 %434, 32
  %436 = zext i32 %423 to i64
  %437 = or i64 %435, %436
  call void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_13RegisterBlockIiLi1ELi4EEEE7ExecuteINS_9MatrixMapIhLNS_8MapOrderE1EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.258"* nonnull %17, i64 %437, i64 %433, %"class.gemmlowp::MatrixMap.195"* %0, i32 %311, i32 %376, i32 %311, i32 %376) #19
  %438 = add nuw nsw i64 %308, 1
  %439 = load i32, i32* %49, align 4
  %440 = trunc i64 %438 to i32
  %441 = icmp sgt i32 %439, %440
  br i1 %441, label %307, label %442

442:                                              ; preds = %307, %281
  %443 = phi i32 [ %282, %281 ], [ %439, %307 ]
  %444 = add nuw i64 %147, 8
  %445 = load i32, i32* %55, align 4
  %446 = add nsw i32 %445, -8
  %447 = trunc i64 %444 to i32
  %448 = icmp slt i32 %446, %447
  br i1 %448, label %131, label %145

449:                                              ; preds = %635
  %450 = trunc i64 %637 to i32
  br label %451

451:                                              ; preds = %449, %133
  %452 = phi i32 [ %134, %133 ], [ %638, %449 ]
  %453 = phi i32 [ %135, %133 ], [ %450, %449 ]
  %454 = icmp slt i32 %453, %452
  br i1 %454, label %455, label %781

455:                                              ; preds = %451
  %456 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 1
  %457 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 0
  %458 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %6, i64 0, i32 0
  %459 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %7, i64 0, i32 0
  %460 = zext i32 %453 to i64
  %461 = load i32, i32* %49, align 4
  br label %642

462:                                              ; preds = %138, %635
  %463 = phi i32 [ %144, %138 ], [ %636, %635 ]
  %464 = phi i64 [ %143, %138 ], [ %637, %635 ]
  %465 = load i32, i32* %139, align 4
  %466 = trunc i64 %464 to i32
  %467 = add nsw i32 %465, %466
  %468 = load i32*, i32** %23, align 8
  %469 = load i32, i32* %26, align 8
  %470 = mul nsw i32 %469, %466
  %471 = sext i32 %470 to i64
  %472 = load i32*, i32** %47, align 8
  %473 = bitcast i32* %472 to i8*
  call void @llvm.prefetch(i8* %473, i32 0, i32 3, i32 1) #19
  %474 = getelementptr inbounds i32, i32* %472, i64 4
  %475 = bitcast i32* %474 to i8*
  call void @llvm.prefetch(i8* %475, i32 0, i32 3, i32 1) #19
  %476 = getelementptr inbounds i32, i32* %468, i64 %471
  %477 = sext i32 %469 to i64
  %478 = bitcast i32* %476 to i8*
  call void @llvm.prefetch(i8* %478, i32 0, i32 3, i32 1) #19
  %479 = getelementptr inbounds i32, i32* %476, i64 4
  %480 = bitcast i32* %479 to i8*
  call void @llvm.prefetch(i8* %480, i32 0, i32 3, i32 1) #19
  %481 = getelementptr inbounds i32, i32* %476, i64 %477
  %482 = bitcast i32* %481 to i8*
  call void @llvm.prefetch(i8* %482, i32 0, i32 3, i32 1) #19
  %483 = getelementptr inbounds i32, i32* %481, i64 4
  %484 = bitcast i32* %483 to i8*
  call void @llvm.prefetch(i8* %484, i32 0, i32 3, i32 1) #19
  %485 = shl nsw i64 %477, 1
  %486 = getelementptr inbounds i32, i32* %476, i64 %485
  %487 = bitcast i32* %486 to i8*
  call void @llvm.prefetch(i8* %487, i32 0, i32 3, i32 1) #19
  %488 = getelementptr inbounds i32, i32* %486, i64 4
  %489 = bitcast i32* %488 to i8*
  call void @llvm.prefetch(i8* %489, i32 0, i32 3, i32 1) #19
  %490 = mul nsw i64 %477, 3
  %491 = getelementptr inbounds i32, i32* %476, i64 %490
  %492 = bitcast i32* %491 to i8*
  call void @llvm.prefetch(i8* %492, i32 0, i32 3, i32 1) #19
  %493 = getelementptr inbounds i32, i32* %491, i64 4
  %494 = bitcast i32* %493 to i8*
  call void @llvm.prefetch(i8* %494, i32 0, i32 3, i32 1) #19
  %495 = icmp slt i32 %463, 8
  br i1 %495, label %498, label %503

496:                                              ; preds = %503
  %497 = trunc i64 %511 to i32
  br label %498

498:                                              ; preds = %496, %462
  %499 = phi i32 [ %463, %462 ], [ %538, %496 ]
  %500 = phi i32 [ 0, %462 ], [ %497, %496 ]
  %501 = add nsw i32 %499, -4
  %502 = icmp sgt i32 %500, %501
  br i1 %502, label %546, label %555

503:                                              ; preds = %462, %542
  %504 = phi i32* [ %545, %542 ], [ %472, %462 ]
  %505 = phi i32 [ %544, %542 ], [ %469, %462 ]
  %506 = phi i32* [ %543, %542 ], [ %468, %462 ]
  %507 = phi i64 [ %511, %542 ], [ 0, %462 ]
  %508 = load i32, i32* %140, align 4
  %509 = trunc i64 %507 to i32
  %510 = add nsw i32 %508, %509
  %511 = add nuw i64 %507, 8
  %512 = mul nsw i32 %505, %466
  %513 = sext i32 %512 to i64
  %514 = getelementptr inbounds i32, i32* %504, i64 %511
  %515 = bitcast i32* %514 to i8*
  call void @llvm.prefetch(i8* %515, i32 0, i32 3, i32 1) #19
  %516 = getelementptr inbounds i32, i32* %514, i64 4
  %517 = bitcast i32* %516 to i8*
  call void @llvm.prefetch(i8* %517, i32 0, i32 3, i32 1) #19
  %518 = getelementptr inbounds i32, i32* %506, i64 %511
  %519 = getelementptr inbounds i32, i32* %518, i64 %513
  %520 = sext i32 %505 to i64
  %521 = bitcast i32* %519 to i8*
  call void @llvm.prefetch(i8* %521, i32 0, i32 3, i32 1) #19
  %522 = getelementptr inbounds i32, i32* %519, i64 4
  %523 = bitcast i32* %522 to i8*
  call void @llvm.prefetch(i8* %523, i32 0, i32 3, i32 1) #19
  %524 = getelementptr inbounds i32, i32* %519, i64 %520
  %525 = bitcast i32* %524 to i8*
  call void @llvm.prefetch(i8* %525, i32 0, i32 3, i32 1) #19
  %526 = getelementptr inbounds i32, i32* %524, i64 4
  %527 = bitcast i32* %526 to i8*
  call void @llvm.prefetch(i8* %527, i32 0, i32 3, i32 1) #19
  %528 = shl nsw i64 %520, 1
  %529 = getelementptr inbounds i32, i32* %519, i64 %528
  %530 = bitcast i32* %529 to i8*
  call void @llvm.prefetch(i8* %530, i32 0, i32 3, i32 1) #19
  %531 = getelementptr inbounds i32, i32* %529, i64 4
  %532 = bitcast i32* %531 to i8*
  call void @llvm.prefetch(i8* %532, i32 0, i32 3, i32 1) #19
  %533 = mul nsw i64 %520, 3
  %534 = getelementptr inbounds i32, i32* %519, i64 %533
  %535 = bitcast i32* %534 to i8*
  call void @llvm.prefetch(i8* %535, i32 0, i32 3, i32 1) #19
  %536 = getelementptr inbounds i32, i32* %534, i64 4
  %537 = bitcast i32* %536 to i8*
  call void @llvm.prefetch(i8* %537, i32 0, i32 3, i32 1) #19
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.286"* nonnull dereferenceable(40) %19, %"class.gemmlowp::MatrixMap.195"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %509, i32 %466, i32 %510, i32 %467, i32 %510, i32 %467)
  %538 = load i32, i32* %49, align 4
  %539 = add nsw i32 %538, -8
  %540 = trunc i64 %511 to i32
  %541 = icmp slt i32 %539, %540
  br i1 %541, label %496, label %542

542:                                              ; preds = %503
  %543 = load i32*, i32** %23, align 8
  %544 = load i32, i32* %26, align 8
  %545 = load i32*, i32** %47, align 8
  br label %503

546:                                              ; preds = %555, %498
  %547 = phi i32 [ %499, %498 ], [ %560, %555 ]
  %548 = phi i32 [ %500, %498 ], [ %559, %555 ]
  %549 = icmp slt i32 %548, %547
  br i1 %549, label %550, label %635

550:                                              ; preds = %546
  %551 = or i32 %466, 1
  %552 = or i32 %466, 2
  %553 = or i32 %466, 3
  %554 = zext i32 %548 to i64
  br label %563

555:                                              ; preds = %498, %555
  %556 = phi i32 [ %559, %555 ], [ %500, %498 ]
  %557 = load i32, i32* %140, align 4
  %558 = add nsw i32 %557, %556
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.270"* nonnull dereferenceable(40) %18, %"class.gemmlowp::MatrixMap.195"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %556, i32 %466, i32 %558, i32 %467, i32 %558, i32 %467)
  %559 = add nuw nsw i32 %556, 4
  %560 = load i32, i32* %49, align 4
  %561 = add nsw i32 %560, -4
  %562 = icmp sgt i32 %559, %561
  br i1 %562, label %546, label %555

563:                                              ; preds = %550, %563
  %564 = phi i64 [ %554, %550 ], [ %631, %563 ]
  %565 = load i32, i32* %140, align 4
  %566 = trunc i64 %564 to i32
  %567 = add nsw i32 %565, %566
  %568 = load i32*, i32** %23, align 8
  %569 = getelementptr inbounds i32, i32* %568, i64 %564
  %570 = load i32, i32* %26, align 8
  %571 = mul nsw i32 %570, %466
  %572 = sext i32 %571 to i64
  %573 = getelementptr inbounds i32, i32* %569, i64 %572
  %574 = load i32, i32* %573, align 4
  %575 = mul nsw i32 %570, %551
  %576 = sext i32 %575 to i64
  %577 = getelementptr inbounds i32, i32* %569, i64 %576
  %578 = load i32, i32* %577, align 4
  %579 = mul nsw i32 %570, %552
  %580 = sext i32 %579 to i64
  %581 = getelementptr inbounds i32, i32* %569, i64 %580
  %582 = load i32, i32* %581, align 4
  %583 = mul nsw i32 %570, %553
  %584 = sext i32 %583 to i64
  %585 = getelementptr inbounds i32, i32* %569, i64 %584
  %586 = load i32, i32* %585, align 4
  %587 = load i32*, i32** %47, align 8
  %588 = getelementptr inbounds i32, i32* %587, i64 %564
  %589 = load i32, i32* %588, align 4
  %590 = load i32*, i32** %53, align 8
  %591 = getelementptr i32, i32* %590, i64 %464
  %592 = bitcast i32* %591 to i64*
  %593 = load i64, i64* %592, align 4
  %594 = getelementptr inbounds i32, i32* %591, i64 2
  %595 = bitcast i32* %594 to i64*
  %596 = load i64, i64* %595, align 4
  %597 = trunc i64 %593 to i32
  %598 = lshr i64 %593, 32
  %599 = trunc i64 %598 to i32
  %600 = load i32, i32* %141, align 4
  %601 = load i32, i32* %142, align 4
  %602 = mul nsw i32 %601, %589
  %603 = add nsw i32 %602, %574
  %604 = add nsw i32 %602, %578
  %605 = add nsw i32 %602, %582
  %606 = add nsw i32 %602, %586
  %607 = mul nsw i32 %601, %3
  %608 = add nsw i32 %607, %597
  %609 = add nsw i32 %607, %599
  %610 = trunc i64 %596 to i32
  %611 = add nsw i32 %607, %610
  %612 = lshr i64 %596, 32
  %613 = trunc i64 %612 to i32
  %614 = add nsw i32 %607, %613
  %615 = mul nsw i32 %608, %600
  %616 = add nsw i32 %603, %615
  %617 = mul nsw i32 %609, %600
  %618 = add nsw i32 %604, %617
  %619 = mul nsw i32 %611, %600
  %620 = add nsw i32 %605, %619
  %621 = zext i32 %620 to i64
  %622 = mul nsw i32 %614, %600
  %623 = add nsw i32 %606, %622
  %624 = zext i32 %623 to i64
  %625 = shl nuw i64 %624, 32
  %626 = or i64 %625, %621
  %627 = zext i32 %618 to i64
  %628 = shl nuw i64 %627, 32
  %629 = zext i32 %616 to i64
  %630 = or i64 %628, %629
  call void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_13RegisterBlockIiLi1ELi4EEEE7ExecuteINS_9MatrixMapIhLNS_8MapOrderE1EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.258"* nonnull %17, i64 %630, i64 %626, %"class.gemmlowp::MatrixMap.195"* %0, i32 %567, i32 %467, i32 %567, i32 %467) #19
  %631 = add nuw nsw i64 %564, 1
  %632 = load i32, i32* %49, align 4
  %633 = trunc i64 %631 to i32
  %634 = icmp sgt i32 %632, %633
  br i1 %634, label %563, label %635

635:                                              ; preds = %563, %546
  %636 = phi i32 [ %547, %546 ], [ %632, %563 ]
  %637 = add nuw i64 %464, 4
  %638 = load i32, i32* %55, align 4
  %639 = add nsw i32 %638, -4
  %640 = trunc i64 %637 to i32
  %641 = icmp slt i32 %639, %640
  br i1 %641, label %449, label %462

642:                                              ; preds = %455, %775
  %643 = phi i32 [ %461, %455 ], [ %776, %775 ]
  %644 = phi i64 [ %460, %455 ], [ %777, %775 ]
  %645 = load i32, i32* %456, align 4
  %646 = trunc i64 %644 to i32
  %647 = add nsw i32 %645, %646
  %648 = load i32*, i32** %23, align 8
  %649 = load i32, i32* %26, align 8
  %650 = mul nsw i32 %649, %646
  %651 = sext i32 %650 to i64
  %652 = load i32*, i32** %47, align 8
  %653 = bitcast i32* %652 to i8*
  call void @llvm.prefetch(i8* %653, i32 0, i32 3, i32 1) #19
  %654 = getelementptr inbounds i32, i32* %652, i64 4
  %655 = bitcast i32* %654 to i8*
  call void @llvm.prefetch(i8* %655, i32 0, i32 3, i32 1) #19
  %656 = getelementptr inbounds i32, i32* %648, i64 %651
  %657 = bitcast i32* %656 to i8*
  call void @llvm.prefetch(i8* %657, i32 0, i32 3, i32 1) #19
  %658 = getelementptr inbounds i32, i32* %656, i64 4
  %659 = bitcast i32* %658 to i8*
  call void @llvm.prefetch(i8* %659, i32 0, i32 3, i32 1) #19
  %660 = icmp slt i32 %643, 8
  br i1 %660, label %663, label %670

661:                                              ; preds = %670
  %662 = trunc i64 %678 to i32
  br label %663

663:                                              ; preds = %661, %642
  %664 = phi i32 [ %643, %642 ], [ %690, %661 ]
  %665 = phi i32 [ 0, %642 ], [ %662, %661 ]
  %666 = add nsw i32 %664, -4
  %667 = icmp sgt i32 %665, %666
  br i1 %667, label %700, label %668

668:                                              ; preds = %663
  %669 = zext i32 %665 to i64
  br label %704

670:                                              ; preds = %642, %694
  %671 = phi i32* [ %697, %694 ], [ %652, %642 ]
  %672 = phi i32 [ %696, %694 ], [ %649, %642 ]
  %673 = phi i32* [ %695, %694 ], [ %648, %642 ]
  %674 = phi i64 [ %678, %694 ], [ 0, %642 ]
  %675 = load i32, i32* %457, align 4
  %676 = trunc i64 %674 to i32
  %677 = add nsw i32 %675, %676
  %678 = add nuw i64 %674, 8
  %679 = mul nsw i32 %672, %646
  %680 = sext i32 %679 to i64
  %681 = getelementptr inbounds i32, i32* %671, i64 %678
  %682 = bitcast i32* %681 to i8*
  call void @llvm.prefetch(i8* %682, i32 0, i32 3, i32 1) #19
  %683 = getelementptr inbounds i32, i32* %681, i64 4
  %684 = bitcast i32* %683 to i8*
  call void @llvm.prefetch(i8* %684, i32 0, i32 3, i32 1) #19
  %685 = getelementptr inbounds i32, i32* %673, i64 %678
  %686 = getelementptr inbounds i32, i32* %685, i64 %680
  %687 = bitcast i32* %686 to i8*
  call void @llvm.prefetch(i8* %687, i32 0, i32 3, i32 1) #19
  %688 = getelementptr inbounds i32, i32* %686, i64 4
  %689 = bitcast i32* %688 to i8*
  call void @llvm.prefetch(i8* %689, i32 0, i32 3, i32 1) #19
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.242"* nonnull dereferenceable(40) %16, %"class.gemmlowp::MatrixMap.195"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %676, i32 %646, i32 %677, i32 %647, i32 %677, i32 %647)
  %690 = load i32, i32* %49, align 4
  %691 = add nsw i32 %690, -8
  %692 = trunc i64 %678 to i32
  %693 = icmp slt i32 %691, %692
  br i1 %693, label %661, label %694

694:                                              ; preds = %670
  %695 = load i32*, i32** %23, align 8
  %696 = load i32, i32* %26, align 8
  %697 = load i32*, i32** %47, align 8
  br label %670

698:                                              ; preds = %704
  %699 = trunc i64 %763 to i32
  br label %700

700:                                              ; preds = %698, %663
  %701 = phi i32 [ %664, %663 ], [ %764, %698 ]
  %702 = phi i32 [ %665, %663 ], [ %699, %698 ]
  %703 = icmp slt i32 %702, %701
  br i1 %703, label %768, label %775

704:                                              ; preds = %668, %704
  %705 = phi i64 [ %669, %668 ], [ %763, %704 ]
  %706 = load i32, i32* %457, align 4
  %707 = trunc i64 %705 to i32
  %708 = add nsw i32 %706, %707
  %709 = load i32*, i32** %23, align 8
  %710 = getelementptr inbounds i32, i32* %709, i64 %705
  %711 = load i32, i32* %26, align 8
  %712 = mul nsw i32 %711, %646
  %713 = sext i32 %712 to i64
  %714 = getelementptr inbounds i32, i32* %710, i64 %713
  %715 = getelementptr inbounds i32, i32* %714, i64 1
  %716 = load i32, i32* %714, align 4
  %717 = getelementptr inbounds i32, i32* %715, i64 1
  %718 = load i32, i32* %715, align 4
  %719 = getelementptr inbounds i32, i32* %717, i64 1
  %720 = load i32, i32* %717, align 4
  %721 = load i32, i32* %719, align 4
  %722 = load i32*, i32** %47, align 8
  %723 = getelementptr i32, i32* %722, i64 %705
  %724 = bitcast i32* %723 to i64*
  %725 = load i64, i64* %724, align 4
  %726 = getelementptr inbounds i32, i32* %723, i64 2
  %727 = bitcast i32* %726 to i64*
  %728 = load i64, i64* %727, align 4
  %729 = trunc i64 %725 to i32
  %730 = lshr i64 %725, 32
  %731 = trunc i64 %730 to i32
  %732 = load i32*, i32** %53, align 8
  %733 = getelementptr inbounds i32, i32* %732, i64 %644
  %734 = load i32, i32* %733, align 4
  %735 = load i32, i32* %458, align 4
  %736 = load i32, i32* %459, align 4
  %737 = mul nsw i32 %736, %729
  %738 = add nsw i32 %737, %716
  %739 = mul nsw i32 %736, %731
  %740 = add nsw i32 %739, %718
  %741 = trunc i64 %728 to i32
  %742 = mul nsw i32 %736, %741
  %743 = add nsw i32 %742, %720
  %744 = lshr i64 %728, 32
  %745 = trunc i64 %744 to i32
  %746 = mul nsw i32 %736, %745
  %747 = add nsw i32 %746, %721
  %748 = mul nsw i32 %736, %3
  %749 = add nsw i32 %748, %734
  %750 = mul nsw i32 %749, %735
  %751 = add nsw i32 %738, %750
  %752 = add nsw i32 %740, %750
  %753 = add nsw i32 %743, %750
  %754 = zext i32 %753 to i64
  %755 = add nsw i32 %747, %750
  %756 = zext i32 %755 to i64
  %757 = shl nuw i64 %756, 32
  %758 = or i64 %757, %754
  %759 = zext i32 %752 to i64
  %760 = shl nuw i64 %759, 32
  %761 = zext i32 %751 to i64
  %762 = or i64 %760, %761
  call void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_13RegisterBlockIiLi4ELi1EEEE7ExecuteINS_9MatrixMapIhLNS_8MapOrderE1EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.226"* nonnull %15, i64 %762, i64 %758, %"class.gemmlowp::MatrixMap.195"* %0, i32 %708, i32 %647, i32 %708, i32 %647) #19
  %763 = add nuw i64 %705, 4
  %764 = load i32, i32* %49, align 4
  %765 = add nsw i32 %764, -4
  %766 = trunc i64 %763 to i32
  %767 = icmp slt i32 %765, %766
  br i1 %767, label %698, label %704

768:                                              ; preds = %700, %768
  %769 = phi i32 [ %772, %768 ], [ %702, %700 ]
  %770 = load i32, i32* %457, align 4
  %771 = add nsw i32 %770, %769
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor"* nonnull dereferenceable(40) %14, %"class.gemmlowp::MatrixMap.195"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %769, i32 %646, i32 %771, i32 %647, i32 %771, i32 %647)
  %772 = add nuw nsw i32 %769, 1
  %773 = load i32, i32* %49, align 4
  %774 = icmp slt i32 %772, %773
  br i1 %774, label %768, label %775

775:                                              ; preds = %768, %700
  %776 = phi i32 [ %701, %700 ], [ %773, %768 ]
  %777 = add nuw nsw i64 %644, 1
  %778 = load i32, i32* %55, align 4
  %779 = trunc i64 %777 to i32
  %780 = icmp sgt i32 %778, %779
  br i1 %780, label %642, label %781

781:                                              ; preds = %775, %451
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %108) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %100) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %92) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %84) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %76) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %58) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %52) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %46) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %22) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"*) local_unnamed_addr #1 comdat align 2 {
  %2 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %0, i64 0, i32 0
  %3 = load %"class.gemmlowp::PackedSideBlock"*, %"class.gemmlowp::PackedSideBlock"** %2, align 8
  %4 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %3, i64 0, i32 1
  %5 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %4, align 8
  %6 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %3, i64 0, i32 3, i32 0
  %7 = load i8, i8* %6, align 8
  %8 = zext i8 %7 to i64
  %9 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %5, i64 0, i32 5, i64 %8
  %10 = load i64, i64* %9, align 8
  %11 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %5, i64 0, i32 2
  %12 = bitcast i8** %11 to i64*
  %13 = load i64, i64* %12, align 8
  %14 = add i64 %13, %10
  %15 = inttoptr i64 %14 to i8*
  %16 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %3, i64 0, i32 0, i32 2
  %17 = load i32, i32* %16, align 4
  %18 = sext i32 %17 to i64
  %19 = shl nsw i64 %18, 2
  tail call void @llvm.memset.p0i8.i64(i8* align 4 %15, i8 0, i64 %19, i1 false)
  %20 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %0, i64 0, i32 1
  %21 = load %"class.gemmlowp::SideMap"*, %"class.gemmlowp::SideMap"** %20, align 8
  %22 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %21, i64 0, i32 2
  %23 = load i32, i32* %22, align 4
  %24 = icmp sgt i32 %23, 0
  br i1 %24, label %25, label %27

25:                                               ; preds = %1
  %26 = load %"class.gemmlowp::PackedSideBlock"*, %"class.gemmlowp::PackedSideBlock"** %2, align 8
  br label %28

27:                                               ; preds = %46, %1
  ret void

28:                                               ; preds = %25, %46
  %29 = phi %"class.gemmlowp::SideMap"* [ %47, %46 ], [ %21, %25 ]
  %30 = phi %"class.gemmlowp::PackedSideBlock"* [ %48, %46 ], [ %26, %25 ]
  %31 = phi %"class.gemmlowp::PackedSideBlock"* [ %49, %46 ], [ %26, %25 ]
  %32 = phi i32 [ %54, %46 ], [ %23, %25 ]
  %33 = phi i32 [ %52, %46 ], [ 0, %25 ]
  %34 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %31, i64 0, i32 0, i32 1
  %35 = sub nsw i32 %32, %33
  %36 = load i32, i32* %34, align 4
  %37 = icmp slt i32 %35, %36
  %38 = select i1 %37, i32 %35, i32 %36
  %39 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %29, i64 0, i32 1
  %40 = load i32, i32* %39, align 8
  %41 = icmp sgt i32 %40, 0
  br i1 %41, label %42, label %46

42:                                               ; preds = %28
  %43 = icmp sgt i32 %38, 0
  %44 = sext i32 %33 to i64
  %45 = sext i32 %38 to i64
  br label %56

46:                                               ; preds = %151, %28
  %47 = phi %"class.gemmlowp::SideMap"* [ %29, %28 ], [ %152, %151 ]
  %48 = phi %"class.gemmlowp::PackedSideBlock"* [ %30, %28 ], [ %153, %151 ]
  %49 = phi %"class.gemmlowp::PackedSideBlock"* [ %31, %28 ], [ %153, %151 ]
  %50 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %49, i64 0, i32 0, i32 1
  %51 = load i32, i32* %50, align 4
  %52 = add nsw i32 %51, %33
  %53 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %47, i64 0, i32 2
  %54 = load i32, i32* %53, align 4
  %55 = icmp sgt i32 %54, %52
  br i1 %55, label %28, label %27

56:                                               ; preds = %42, %151
  %57 = phi %"class.gemmlowp::SideMap"* [ %29, %42 ], [ %152, %151 ]
  %58 = phi %"class.gemmlowp::PackedSideBlock"* [ %30, %42 ], [ %153, %151 ]
  %59 = phi %"class.gemmlowp::SideMap"* [ %29, %42 ], [ %154, %151 ]
  %60 = phi %"class.gemmlowp::PackedSideBlock"* [ %31, %42 ], [ %153, %151 ]
  %61 = phi i32 [ %40, %42 ], [ %158, %151 ]
  %62 = phi i32 [ 0, %42 ], [ %156, %151 ]
  %63 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %60, i64 0, i32 0, i32 0
  %64 = sub nsw i32 %61, %62
  %65 = load i32, i32* %63, align 4
  %66 = icmp slt i32 %64, %65
  %67 = select i1 %66, i32 %64, i32 %65
  br i1 %43, label %68, label %122

68:                                               ; preds = %56
  %69 = icmp sgt i32 %67, 0
  %70 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %59, i64 0, i32 0
  %71 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %59, i64 0, i32 3
  %72 = sext i32 %62 to i64
  %73 = zext i32 %67 to i64
  %74 = add nsw i64 %73, -1
  %75 = and i64 %73, 3
  %76 = icmp ult i64 %74, 3
  %77 = sub nsw i64 %73, %75
  %78 = icmp eq i64 %75, 0
  br label %79

79:                                               ; preds = %98, %68
  %80 = phi i64 [ 0, %68 ], [ %99, %98 ]
  br i1 %69, label %81, label %98

81:                                               ; preds = %79
  %82 = add nsw i64 %80, %44
  %83 = load i8*, i8** %70, align 8
  %84 = load i32, i32* %71, align 8
  %85 = getelementptr inbounds i8, i8* %83, i64 %82
  %86 = sext i32 %84 to i64
  br i1 %76, label %87, label %101

87:                                               ; preds = %101, %81
  %88 = phi i64 [ 0, %81 ], [ %119, %101 ]
  br i1 %78, label %98, label %89

89:                                               ; preds = %87, %89
  %90 = phi i64 [ %95, %89 ], [ %88, %87 ]
  %91 = phi i64 [ %96, %89 ], [ %75, %87 ]
  %92 = add nsw i64 %90, %72
  %93 = mul nsw i64 %92, %86
  %94 = getelementptr inbounds i8, i8* %85, i64 %93
  tail call void @llvm.prefetch(i8* %94, i32 0, i32 3, i32 1) #19
  %95 = add nuw nsw i64 %90, 1
  %96 = add i64 %91, -1
  %97 = icmp eq i64 %96, 0
  br i1 %97, label %98, label %89, !llvm.loop !569

98:                                               ; preds = %87, %89, %79
  %99 = add nuw nsw i64 %80, 64
  %100 = icmp slt i64 %99, %45
  br i1 %100, label %79, label %122

101:                                              ; preds = %81, %101
  %102 = phi i64 [ %119, %101 ], [ 0, %81 ]
  %103 = phi i64 [ %120, %101 ], [ %77, %81 ]
  %104 = add nsw i64 %102, %72
  %105 = mul nsw i64 %104, %86
  %106 = getelementptr inbounds i8, i8* %85, i64 %105
  tail call void @llvm.prefetch(i8* %106, i32 0, i32 3, i32 1) #19
  %107 = or i64 %102, 1
  %108 = add nsw i64 %107, %72
  %109 = mul nsw i64 %108, %86
  %110 = getelementptr inbounds i8, i8* %85, i64 %109
  tail call void @llvm.prefetch(i8* %110, i32 0, i32 3, i32 1) #19
  %111 = or i64 %102, 2
  %112 = add nsw i64 %111, %72
  %113 = mul nsw i64 %112, %86
  %114 = getelementptr inbounds i8, i8* %85, i64 %113
  tail call void @llvm.prefetch(i8* %114, i32 0, i32 3, i32 1) #19
  %115 = or i64 %102, 3
  %116 = add nsw i64 %115, %72
  %117 = mul nsw i64 %116, %86
  %118 = getelementptr inbounds i8, i8* %85, i64 %117
  tail call void @llvm.prefetch(i8* %118, i32 0, i32 3, i32 1) #19
  %119 = add nuw nsw i64 %102, 4
  %120 = add i64 %103, -4
  %121 = icmp eq i64 %120, 0
  br i1 %121, label %87, label %101

122:                                              ; preds = %98, %56
  %123 = icmp sgt i32 %67, 0
  br i1 %123, label %124, label %151

124:                                              ; preds = %122, %124
  %125 = phi %"class.gemmlowp::PackedSideBlock"* [ %146, %124 ], [ %60, %122 ]
  %126 = phi i32 [ %144, %124 ], [ 0, %122 ]
  %127 = sub nsw i32 %67, %126
  %128 = icmp slt i32 %127, 4
  %129 = select i1 %128, i32 %127, i32 4
  %130 = add nsw i32 %126, %62
  %131 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %125, i64 0, i32 0, i32 1
  %132 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %125, i64 0, i32 0, i32 3
  %133 = load i32, i32* %132, align 4
  %134 = sub nsw i32 %133, %33
  %135 = load i32, i32* %131, align 4
  %136 = icmp slt i32 %134, %135
  %137 = select i1 %136, i32 %134, i32 %135
  %138 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %125, i64 0, i32 0, i32 2
  %139 = load i32, i32* %138, align 8
  %140 = mul nsw i32 %139, %33
  %141 = mul nsw i32 %137, %130
  %142 = add nsw i32 %141, %140
  %143 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %125, i64 0, i32 4
  store i32 %142, i32* %143, align 8
  tail call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE7PackRunEiiii(%"class.gemmlowp::PackSideBlockImpl"* %0, i32 %130, i32 %129, i32 %33, i32 %38) #19
  %144 = add nuw nsw i32 %126, 4
  %145 = icmp slt i32 %144, %67
  %146 = load %"class.gemmlowp::PackedSideBlock"*, %"class.gemmlowp::PackedSideBlock"** %2, align 8
  br i1 %145, label %124, label %147

147:                                              ; preds = %124
  %148 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %146, i64 0, i32 0, i32 0
  %149 = load i32, i32* %148, align 4
  %150 = load %"class.gemmlowp::SideMap"*, %"class.gemmlowp::SideMap"** %20, align 8
  br label %151

151:                                              ; preds = %147, %122
  %152 = phi %"class.gemmlowp::SideMap"* [ %150, %147 ], [ %57, %122 ]
  %153 = phi %"class.gemmlowp::PackedSideBlock"* [ %146, %147 ], [ %58, %122 ]
  %154 = phi %"class.gemmlowp::SideMap"* [ %150, %147 ], [ %59, %122 ]
  %155 = phi i32 [ %149, %147 ], [ %65, %122 ]
  %156 = add nsw i32 %155, %62
  %157 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %154, i64 0, i32 1
  %158 = load i32, i32* %157, align 8
  %159 = icmp sgt i32 %158, %156
  br i1 %159, label %56, label %46
}

; Function Attrs: inaccessiblemem_or_argmemonly nounwind
declare void @llvm.prefetch(i8* nocapture readonly, i32 immarg, i32 immarg, i32) #16

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE7PackRunEiiii(%"class.gemmlowp::PackSideBlockImpl"*, i32, i32, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %6 = alloca %"class.gemmlowp::PackingRegisterBlock", align 8
  %7 = bitcast %"class.gemmlowp::PackingRegisterBlock"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 88, i8* nonnull %7) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %7, i8 -86, i64 88, i1 false)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %7, i8 0, i64 20, i1 false) #19
  %8 = icmp eq i32 %2, 4
  br i1 %8, label %28, label %9

9:                                                ; preds = %5
  %10 = icmp sgt i32 %4, 0
  br i1 %10, label %11, label %149

11:                                               ; preds = %9
  %12 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0
  %13 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %0, i64 0, i32 1
  %14 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 1, i64 0
  %15 = icmp sgt i32 %2, 0
  %16 = sext i32 %2 to i64
  %17 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 0, i32 0
  %18 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 0, i32 1
  %19 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 0, i32 2
  %20 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 0, i32 3
  %21 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %0, i64 0, i32 0
  %22 = sext i32 %3 to i64
  %23 = sext i32 %4 to i64
  %24 = and i64 %16, 1
  %25 = icmp eq i32 %2, 1
  %26 = sub nsw i64 %16, %24
  %27 = icmp eq i64 %24, 0
  br label %96

28:                                               ; preds = %5
  %29 = and i32 %4, -16
  %30 = icmp sgt i32 %29, 0
  br i1 %30, label %31, label %56

31:                                               ; preds = %28
  %32 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0
  %33 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %0, i64 0, i32 1
  %34 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 0, i32 0
  %35 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 0, i32 1
  %36 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 0, i32 2
  %37 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 0, i32 3
  %38 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %0, i64 0, i32 0
  %39 = sext i32 %3 to i64
  %40 = sext i32 %29 to i64
  br label %41

41:                                               ; preds = %31, %41
  %42 = phi i64 [ 0, %31 ], [ %54, %41 ]
  %43 = load %"class.gemmlowp::SideMap"*, %"class.gemmlowp::SideMap"** %33, align 8
  %44 = add nsw i64 %42, %39
  %45 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %43, i64 0, i32 0
  %46 = load i8*, i8** %45, align 8, !noalias !570
  %47 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %43, i64 0, i32 3
  %48 = load i32, i32* %47, align 8, !noalias !570
  %49 = mul nsw i32 %48, %1
  %50 = sext i32 %49 to i64
  %51 = getelementptr inbounds i8, i8* %46, i64 %50
  %52 = getelementptr inbounds i8, i8* %51, i64 %44
  store i8* %52, i8** %34, align 8
  store i32 4, i32* %35, align 8
  store i32 16, i32* %36, align 4
  store i32 %48, i32* %37, align 8
  %53 = load %"class.gemmlowp::PackedSideBlock"*, %"class.gemmlowp::PackedSideBlock"** %38, align 8
  call void @_ZN8gemmlowp24PackingRegisterBlockBaseINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE4PackEPSB_i(%"class.gemmlowp::PackingRegisterBlockBase"* nonnull %32, %"class.gemmlowp::PackedSideBlock"* %53, i32 %1)
  %54 = add nuw nsw i64 %42, 16
  %55 = icmp slt i64 %54, %40
  br i1 %55, label %41, label %56

56:                                               ; preds = %41, %28
  %57 = icmp slt i32 %29, %4
  br i1 %57, label %58, label %149

58:                                               ; preds = %56
  %59 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %0, i64 0, i32 1
  %60 = load %"class.gemmlowp::SideMap"*, %"class.gemmlowp::SideMap"** %59, align 8
  %61 = add nsw i32 %29, %3
  %62 = sub nsw i32 %4, %29
  %63 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %60, i64 0, i32 0
  %64 = load i8*, i8** %63, align 8, !noalias !573
  %65 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %60, i64 0, i32 3
  %66 = load i32, i32* %65, align 8, !noalias !573
  %67 = mul nsw i32 %66, %1
  %68 = sext i32 %67 to i64
  %69 = getelementptr inbounds i8, i8* %64, i64 %68
  %70 = sext i32 %61 to i64
  %71 = getelementptr inbounds i8, i8* %69, i64 %70
  %72 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 1, i64 0
  %73 = sext i32 %62 to i64
  %74 = icmp ugt i32 %62, 63
  %75 = sub nsw i64 64, %73
  %76 = select i1 %74, i64 0, i64 %75
  %77 = getelementptr %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 1, i64 %73
  call void @llvm.memset.p0i8.i64(i8* align 1 %77, i8 0, i64 %76, i1 false)
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %72, i8* align 1 %71, i64 %73, i1 false) #19
  %78 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 1, i64 16
  %79 = sext i32 %66 to i64
  %80 = getelementptr inbounds i8, i8* %71, i64 %79
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %78, i8* align 1 %80, i64 %73, i1 false) #19
  %81 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 1, i64 32
  %82 = shl nsw i32 %66, 1
  %83 = sext i32 %82 to i64
  %84 = getelementptr inbounds i8, i8* %71, i64 %83
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %81, i8* align 1 %84, i64 %73, i1 false) #19
  %85 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 1, i64 48
  %86 = mul nsw i32 %66, 3
  %87 = sext i32 %86 to i64
  %88 = getelementptr inbounds i8, i8* %71, i64 %87
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %85, i8* align 1 %88, i64 %73, i1 false) #19
  %89 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0
  %90 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 0, i32 0
  store i8* %72, i8** %90, align 8
  %91 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 0, i32 1
  store i32 4, i32* %91, align 8
  %92 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 0, i32 2
  store i32 16, i32* %92, align 4
  %93 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 0, i32 3
  store i32 16, i32* %93, align 8
  %94 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %0, i64 0, i32 0
  %95 = load %"class.gemmlowp::PackedSideBlock"*, %"class.gemmlowp::PackedSideBlock"** %94, align 8
  call void @_ZN8gemmlowp24PackingRegisterBlockBaseINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE4PackEPSB_i(%"class.gemmlowp::PackingRegisterBlockBase"* nonnull %89, %"class.gemmlowp::PackedSideBlock"* %95, i32 %1)
  br label %149

96:                                               ; preds = %11, %145
  %97 = phi i64 [ 0, %11 ], [ %147, %145 ]
  %98 = sub nsw i64 %23, %97
  %99 = load %"class.gemmlowp::SideMap"*, %"class.gemmlowp::SideMap"** %13, align 8
  %100 = add nsw i64 %97, %22
  %101 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %99, i64 0, i32 0
  %102 = load i8*, i8** %101, align 8, !noalias !576
  %103 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %99, i64 0, i32 3
  %104 = load i32, i32* %103, align 8, !noalias !576
  %105 = mul nsw i32 %104, %1
  %106 = sext i32 %105 to i64
  %107 = getelementptr inbounds i8, i8* %102, i64 %106
  %108 = getelementptr inbounds i8, i8* %107, i64 %100
  call void @llvm.memset.p0i8.i64(i8* align 8 %14, i8 0, i64 64, i1 false) #19
  br i1 %15, label %109, label %145

109:                                              ; preds = %96
  %110 = icmp slt i64 %98, 16
  %111 = select i1 %110, i64 %98, i64 16
  %112 = shl i64 %111, 32
  %113 = ashr exact i64 %112, 32
  br i1 %25, label %135, label %114

114:                                              ; preds = %109, %114
  %115 = phi i64 [ %132, %114 ], [ 0, %109 ]
  %116 = phi i64 [ %133, %114 ], [ %26, %109 ]
  %117 = trunc i64 %115 to i32
  %118 = shl i64 %115, 4
  %119 = and i64 %118, 4294967264
  %120 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 1, i64 %119
  %121 = mul nsw i32 %104, %117
  %122 = sext i32 %121 to i64
  %123 = getelementptr inbounds i8, i8* %108, i64 %122
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %120, i8* align 1 %123, i64 %113, i1 false) #19
  %124 = or i64 %115, 1
  %125 = trunc i64 %124 to i32
  %126 = shl i64 %124, 4
  %127 = and i64 %126, 4294967280
  %128 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 1, i64 %127
  %129 = mul nsw i32 %104, %125
  %130 = sext i32 %129 to i64
  %131 = getelementptr inbounds i8, i8* %108, i64 %130
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %128, i8* align 1 %131, i64 %113, i1 false) #19
  %132 = add nuw nsw i64 %115, 2
  %133 = add i64 %116, -2
  %134 = icmp eq i64 %133, 0
  br i1 %134, label %135, label %114

135:                                              ; preds = %114, %109
  %136 = phi i64 [ 0, %109 ], [ %132, %114 ]
  br i1 %27, label %145, label %137

137:                                              ; preds = %135
  %138 = trunc i64 %136 to i32
  %139 = shl i64 %136, 4
  %140 = and i64 %139, 4294967280
  %141 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlock", %"class.gemmlowp::PackingRegisterBlock"* %6, i64 0, i32 0, i32 1, i64 %140
  %142 = mul nsw i32 %104, %138
  %143 = sext i32 %142 to i64
  %144 = getelementptr inbounds i8, i8* %108, i64 %143
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %141, i8* align 1 %144, i64 %113, i1 false) #19
  br label %145

145:                                              ; preds = %137, %135, %96
  store i8* %14, i8** %17, align 8
  store i32 4, i32* %18, align 8
  store i32 16, i32* %19, align 4
  store i32 16, i32* %20, align 8
  %146 = load %"class.gemmlowp::PackedSideBlock"*, %"class.gemmlowp::PackedSideBlock"** %21, align 8
  call void @_ZN8gemmlowp24PackingRegisterBlockBaseINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE4PackEPSB_i(%"class.gemmlowp::PackingRegisterBlockBase"* nonnull %12, %"class.gemmlowp::PackedSideBlock"* %146, i32 %1)
  %147 = add nuw i64 %97, 16
  %148 = icmp slt i64 %147, %23
  br i1 %148, label %96, label %149

149:                                              ; preds = %145, %9, %56, %58
  call void @llvm.lifetime.end.p0i8(i64 88, i8* nonnull %7) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp24PackingRegisterBlockBaseINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE4PackEPSB_i(%"class.gemmlowp::PackingRegisterBlockBase"*, %"class.gemmlowp::PackedSideBlock"*, i32) local_unnamed_addr #1 comdat align 2 {
  %4 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %1, i64 0, i32 1
  %5 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %4, align 8
  %6 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %1, i64 0, i32 2, i32 0
  %7 = load i8, i8* %6, align 8
  %8 = zext i8 %7 to i64
  %9 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %5, i64 0, i32 5, i64 %8
  %10 = load i64, i64* %9, align 8
  %11 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %5, i64 0, i32 2
  %12 = bitcast i8** %11 to i64*
  %13 = load i64, i64* %12, align 8
  %14 = add i64 %13, %10
  %15 = inttoptr i64 %14 to i8*
  %16 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %1, i64 0, i32 4
  %17 = load i32, i32* %16, align 8
  %18 = sext i32 %17 to i64
  %19 = getelementptr inbounds i8, i8* %15, i64 %18
  %20 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %1, i64 0, i32 3, i32 0
  %21 = sext i32 %2 to i64
  %22 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlockBase", %"class.gemmlowp::PackingRegisterBlockBase"* %0, i64 0, i32 0, i32 0
  %23 = getelementptr inbounds %"class.gemmlowp::PackingRegisterBlockBase", %"class.gemmlowp::PackingRegisterBlockBase"* %0, i64 0, i32 0, i32 3
  %24 = load i8, i8* %20, align 8
  %25 = zext i8 %24 to i64
  %26 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %5, i64 0, i32 5, i64 %25
  %27 = load i64, i64* %26, align 8
  %28 = add i64 %13, %27
  %29 = inttoptr i64 %28 to i32*
  %30 = getelementptr inbounds i32, i32* %29, i64 %21
  %31 = load i8*, i8** %22, align 8, !noalias !579
  %32 = load i32, i32* %23, align 8, !noalias !579
  %33 = sext i32 %32 to i64
  br label %34

34:                                               ; preds = %34, %3
  %35 = phi i64 [ 0, %3 ], [ %135, %34 ]
  %36 = mul nsw i64 %35, %33
  %37 = getelementptr inbounds i8, i8* %31, i64 %36
  %38 = shl i64 %35, 4
  %39 = load i8, i8* %37, align 1
  %40 = getelementptr inbounds i8, i8* %19, i64 %38
  store i8 %39, i8* %40, align 1
  %41 = zext i8 %39 to i32
  %42 = getelementptr inbounds i8, i8* %37, i64 1
  %43 = load i8, i8* %42, align 1
  %44 = or i64 %38, 1
  %45 = getelementptr inbounds i8, i8* %19, i64 %44
  store i8 %43, i8* %45, align 1
  %46 = zext i8 %43 to i32
  %47 = add nuw nsw i32 %41, %46
  %48 = getelementptr inbounds i8, i8* %37, i64 2
  %49 = load i8, i8* %48, align 1
  %50 = or i64 %38, 2
  %51 = getelementptr inbounds i8, i8* %19, i64 %50
  store i8 %49, i8* %51, align 1
  %52 = zext i8 %49 to i32
  %53 = add nuw nsw i32 %47, %52
  %54 = getelementptr inbounds i8, i8* %37, i64 3
  %55 = load i8, i8* %54, align 1
  %56 = or i64 %38, 3
  %57 = getelementptr inbounds i8, i8* %19, i64 %56
  store i8 %55, i8* %57, align 1
  %58 = zext i8 %55 to i32
  %59 = add nuw nsw i32 %53, %58
  %60 = getelementptr inbounds i8, i8* %37, i64 4
  %61 = load i8, i8* %60, align 1
  %62 = or i64 %38, 4
  %63 = getelementptr inbounds i8, i8* %19, i64 %62
  store i8 %61, i8* %63, align 1
  %64 = zext i8 %61 to i32
  %65 = add nuw nsw i32 %59, %64
  %66 = getelementptr inbounds i8, i8* %37, i64 5
  %67 = load i8, i8* %66, align 1
  %68 = or i64 %38, 5
  %69 = getelementptr inbounds i8, i8* %19, i64 %68
  store i8 %67, i8* %69, align 1
  %70 = zext i8 %67 to i32
  %71 = add nuw nsw i32 %65, %70
  %72 = getelementptr inbounds i8, i8* %37, i64 6
  %73 = load i8, i8* %72, align 1
  %74 = or i64 %38, 6
  %75 = getelementptr inbounds i8, i8* %19, i64 %74
  store i8 %73, i8* %75, align 1
  %76 = zext i8 %73 to i32
  %77 = add nuw nsw i32 %71, %76
  %78 = getelementptr inbounds i8, i8* %37, i64 7
  %79 = load i8, i8* %78, align 1
  %80 = or i64 %38, 7
  %81 = getelementptr inbounds i8, i8* %19, i64 %80
  store i8 %79, i8* %81, align 1
  %82 = zext i8 %79 to i32
  %83 = add nuw nsw i32 %77, %82
  %84 = getelementptr inbounds i8, i8* %37, i64 8
  %85 = load i8, i8* %84, align 1
  %86 = or i64 %38, 8
  %87 = getelementptr inbounds i8, i8* %19, i64 %86
  store i8 %85, i8* %87, align 1
  %88 = zext i8 %85 to i32
  %89 = add nuw nsw i32 %83, %88
  %90 = getelementptr inbounds i8, i8* %37, i64 9
  %91 = load i8, i8* %90, align 1
  %92 = or i64 %38, 9
  %93 = getelementptr inbounds i8, i8* %19, i64 %92
  store i8 %91, i8* %93, align 1
  %94 = zext i8 %91 to i32
  %95 = add nuw nsw i32 %89, %94
  %96 = getelementptr inbounds i8, i8* %37, i64 10
  %97 = load i8, i8* %96, align 1
  %98 = or i64 %38, 10
  %99 = getelementptr inbounds i8, i8* %19, i64 %98
  store i8 %97, i8* %99, align 1
  %100 = zext i8 %97 to i32
  %101 = add nuw nsw i32 %95, %100
  %102 = getelementptr inbounds i8, i8* %37, i64 11
  %103 = load i8, i8* %102, align 1
  %104 = or i64 %38, 11
  %105 = getelementptr inbounds i8, i8* %19, i64 %104
  store i8 %103, i8* %105, align 1
  %106 = zext i8 %103 to i32
  %107 = add nuw nsw i32 %101, %106
  %108 = getelementptr inbounds i8, i8* %37, i64 12
  %109 = load i8, i8* %108, align 1
  %110 = or i64 %38, 12
  %111 = getelementptr inbounds i8, i8* %19, i64 %110
  store i8 %109, i8* %111, align 1
  %112 = zext i8 %109 to i32
  %113 = add nuw nsw i32 %107, %112
  %114 = getelementptr inbounds i8, i8* %37, i64 13
  %115 = load i8, i8* %114, align 1
  %116 = or i64 %38, 13
  %117 = getelementptr inbounds i8, i8* %19, i64 %116
  store i8 %115, i8* %117, align 1
  %118 = zext i8 %115 to i32
  %119 = add nuw nsw i32 %113, %118
  %120 = getelementptr inbounds i8, i8* %37, i64 14
  %121 = load i8, i8* %120, align 1
  %122 = or i64 %38, 14
  %123 = getelementptr inbounds i8, i8* %19, i64 %122
  store i8 %121, i8* %123, align 1
  %124 = zext i8 %121 to i32
  %125 = add nuw nsw i32 %119, %124
  %126 = getelementptr inbounds i8, i8* %37, i64 15
  %127 = load i8, i8* %126, align 1
  %128 = or i64 %38, 15
  %129 = getelementptr inbounds i8, i8* %19, i64 %128
  store i8 %127, i8* %129, align 1
  %130 = zext i8 %127 to i32
  %131 = add nuw nsw i32 %125, %130
  %132 = getelementptr inbounds i32, i32* %30, i64 %35
  %133 = load i32, i32* %132, align 4
  %134 = add nsw i32 %133, %131
  store i32 %134, i32* %132, align 4
  %135 = add nuw nsw i64 %35, 1
  %136 = icmp eq i64 %135, 4
  br i1 %136, label %137, label %34

137:                                              ; preds = %34
  %138 = load i32, i32* %16, align 8
  %139 = add nsw i32 %138, 64
  store i32 %139, i32* %16, align 8
  ret void
}

; Function Attrs: noinline nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp11ComputeImplINS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEES7_NS_12PackedResultEE10ComputeRunEiiii(%"class.gemmlowp::ComputeImpl"*, i32, i32, i32, i32) local_unnamed_addr #17 comdat align 2 {
  %6 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %0, i64 0, i32 3
  %7 = load %"class.gemmlowp::PackedSideBlock"*, %"class.gemmlowp::PackedSideBlock"** %6, align 8
  %8 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %7, i64 0, i32 0, i32 1
  %9 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %7, i64 0, i32 0, i32 3
  %10 = load i32, i32* %9, align 4
  %11 = sub nsw i32 %10, %3
  %12 = load i32, i32* %8, align 4
  %13 = icmp slt i32 %11, %12
  %14 = select i1 %13, i32 %11, i32 %12
  %15 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %7, i64 0, i32 0, i32 2
  %16 = load i32, i32* %15, align 8
  %17 = mul nsw i32 %16, %3
  %18 = mul nsw i32 %14, %1
  %19 = add nsw i32 %18, %17
  %20 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %7, i64 0, i32 4
  store i32 %19, i32* %20, align 8
  %21 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %0, i64 0, i32 4
  %22 = load %"class.gemmlowp::PackedSideBlock"*, %"class.gemmlowp::PackedSideBlock"** %21, align 8
  %23 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %22, i64 0, i32 0, i32 1
  %24 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %22, i64 0, i32 0, i32 3
  %25 = load i32, i32* %24, align 4
  %26 = sub nsw i32 %25, %3
  %27 = load i32, i32* %23, align 4
  %28 = icmp slt i32 %26, %27
  %29 = select i1 %28, i32 %26, i32 %27
  %30 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %22, i64 0, i32 0, i32 2
  %31 = load i32, i32* %30, align 8
  %32 = mul nsw i32 %31, %3
  %33 = mul nsw i32 %29, %2
  %34 = add nsw i32 %33, %32
  %35 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %22, i64 0, i32 4
  store i32 %34, i32* %35, align 8
  %36 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %0, i64 0, i32 2
  %37 = load %"class.gemmlowp::PackedResult"*, %"class.gemmlowp::PackedResult"** %36, align 8
  %38 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %37, i64 0, i32 0
  %39 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %38, align 8, !noalias !582
  %40 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %37, i64 0, i32 1, i32 0
  %41 = load i8, i8* %40, align 8, !noalias !582
  %42 = zext i8 %41 to i64
  %43 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %39, i64 0, i32 5, i64 %42
  %44 = load i64, i64* %43, align 8, !noalias !582
  %45 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %39, i64 0, i32 2
  %46 = bitcast i8** %45 to i64*
  %47 = load i64, i64* %46, align 8, !noalias !582
  %48 = add i64 %47, %44
  %49 = inttoptr i64 %48 to i32*
  %50 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %37, i64 0, i32 2
  %51 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %50, align 8, !noalias !582
  %52 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %51, i64 0, i32 3
  %53 = load i32, i32* %52, align 4, !noalias !582
  %54 = sext i32 %1 to i64
  %55 = getelementptr inbounds i32, i32* %49, i64 %54
  %56 = mul nsw i32 %53, %2
  %57 = sext i32 %56 to i64
  %58 = getelementptr inbounds i32, i32* %55, i64 %57
  %59 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %0, i64 0, i32 0
  %60 = load %"struct.gemmlowp::KernelBase"*, %"struct.gemmlowp::KernelBase"** %59, align 8
  %61 = sext i32 %53 to i64
  %62 = load %"class.gemmlowp::PackedSideBlock"*, %"class.gemmlowp::PackedSideBlock"** %6, align 8
  %63 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %62, i64 0, i32 1
  %64 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %63, align 8
  %65 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %62, i64 0, i32 2, i32 0
  %66 = load i8, i8* %65, align 8
  %67 = zext i8 %66 to i64
  %68 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %64, i64 0, i32 5, i64 %67
  %69 = load i64, i64* %68, align 8
  %70 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %64, i64 0, i32 2
  %71 = bitcast i8** %70 to i64*
  %72 = load i64, i64* %71, align 8
  %73 = add i64 %72, %69
  %74 = inttoptr i64 %73 to i8*
  %75 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %62, i64 0, i32 4
  %76 = load i32, i32* %75, align 8
  %77 = sext i32 %76 to i64
  %78 = getelementptr inbounds i8, i8* %74, i64 %77
  %79 = load %"class.gemmlowp::PackedSideBlock"*, %"class.gemmlowp::PackedSideBlock"** %21, align 8
  %80 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %79, i64 0, i32 1
  %81 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %80, align 8
  %82 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %79, i64 0, i32 2, i32 0
  %83 = load i8, i8* %82, align 8
  %84 = zext i8 %83 to i64
  %85 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %81, i64 0, i32 5, i64 %84
  %86 = load i64, i64* %85, align 8
  %87 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %81, i64 0, i32 2
  %88 = bitcast i8** %87 to i64*
  %89 = load i64, i64* %88, align 8
  %90 = add i64 %89, %86
  %91 = inttoptr i64 %90 to i8*
  %92 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %79, i64 0, i32 4
  %93 = load i32, i32* %92, align 8
  %94 = sext i32 %93 to i64
  %95 = getelementptr inbounds i8, i8* %91, i64 %94
  %96 = sext i32 %3 to i64
  %97 = sext i32 %4 to i64
  %98 = bitcast %"struct.gemmlowp::KernelBase"* %60 to void (%"struct.gemmlowp::KernelBase"*, i32*, i64, i64, i8*, i8*, i64, i64)***
  %99 = load void (%"struct.gemmlowp::KernelBase"*, i32*, i64, i64, i8*, i8*, i64, i64)**, void (%"struct.gemmlowp::KernelBase"*, i32*, i64, i64, i8*, i8*, i64, i64)*** %98, align 8
  %100 = getelementptr inbounds void (%"struct.gemmlowp::KernelBase"*, i32*, i64, i64, i8*, i8*, i64, i64)*, void (%"struct.gemmlowp::KernelBase"*, i32*, i64, i64, i8*, i8*, i64, i64)** %99, i64 1
  %101 = load void (%"struct.gemmlowp::KernelBase"*, i32*, i64, i64, i8*, i8*, i64, i64)*, void (%"struct.gemmlowp::KernelBase"*, i32*, i64, i64, i8*, i8*, i64, i64)** %100, align 8
  tail call void %101(%"struct.gemmlowp::KernelBase"* %60, i32* %58, i64 1, i64 %61, i8* %78, i8* %95, i64 %96, i64 %97) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.286"* dereferenceable(40), %"class.gemmlowp::MatrixMap.182"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.302", align 16
  %16 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %16) #19
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %18 = sext i32 %8 to i64
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %20 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %20, i8 -86, i64 128, i1 false)
  %21 = load i32*, i32** %17, align 8, !noalias !585
  %22 = getelementptr inbounds i32, i32* %21, i64 %18
  %23 = load i32, i32* %19, align 8, !noalias !585
  %24 = mul nsw i32 %23, %9
  %25 = sext i32 %24 to i64
  %26 = getelementptr inbounds i32, i32* %22, i64 %25
  %27 = getelementptr inbounds i32, i32* %26, i64 1
  %28 = load i32, i32* %26, align 4
  %29 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 0
  store i32 %28, i32* %29, align 16, !alias.scope !585
  %30 = getelementptr inbounds i32, i32* %27, i64 1
  %31 = load i32, i32* %27, align 4
  %32 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 1
  store i32 %31, i32* %32, align 4, !alias.scope !585
  %33 = getelementptr inbounds i32, i32* %30, i64 1
  %34 = load i32, i32* %30, align 4
  %35 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 2
  store i32 %34, i32* %35, align 8, !alias.scope !585
  %36 = getelementptr inbounds i32, i32* %33, i64 1
  %37 = load i32, i32* %33, align 4
  %38 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 3
  store i32 %37, i32* %38, align 4, !alias.scope !585
  %39 = getelementptr inbounds i32, i32* %36, i64 1
  %40 = load i32, i32* %36, align 4
  %41 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 4
  store i32 %40, i32* %41, align 16, !alias.scope !585
  %42 = getelementptr inbounds i32, i32* %39, i64 1
  %43 = load i32, i32* %39, align 4
  %44 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 5
  store i32 %43, i32* %44, align 4, !alias.scope !585
  %45 = getelementptr inbounds i32, i32* %42, i64 1
  %46 = load i32, i32* %42, align 4
  %47 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 6
  store i32 %46, i32* %47, align 8, !alias.scope !585
  %48 = load i32, i32* %45, align 4
  %49 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 7
  store i32 %48, i32* %49, align 4, !alias.scope !585
  %50 = add nsw i32 %9, 1
  %51 = mul nsw i32 %23, %50
  %52 = sext i32 %51 to i64
  %53 = getelementptr inbounds i32, i32* %22, i64 %52
  %54 = getelementptr inbounds i32, i32* %53, i64 1
  %55 = load i32, i32* %53, align 4
  %56 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 8
  store i32 %55, i32* %56, align 16, !alias.scope !585
  %57 = getelementptr inbounds i32, i32* %54, i64 1
  %58 = load i32, i32* %54, align 4
  %59 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 9
  store i32 %58, i32* %59, align 4, !alias.scope !585
  %60 = getelementptr inbounds i32, i32* %57, i64 1
  %61 = load i32, i32* %57, align 4
  %62 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 10
  store i32 %61, i32* %62, align 8, !alias.scope !585
  %63 = getelementptr inbounds i32, i32* %60, i64 1
  %64 = load i32, i32* %60, align 4
  %65 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 11
  store i32 %64, i32* %65, align 4, !alias.scope !585
  %66 = getelementptr inbounds i32, i32* %63, i64 1
  %67 = load i32, i32* %63, align 4
  %68 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 12
  store i32 %67, i32* %68, align 16, !alias.scope !585
  %69 = getelementptr inbounds i32, i32* %66, i64 1
  %70 = load i32, i32* %66, align 4
  %71 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 13
  store i32 %70, i32* %71, align 4, !alias.scope !585
  %72 = getelementptr inbounds i32, i32* %69, i64 1
  %73 = load i32, i32* %69, align 4
  %74 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 14
  store i32 %73, i32* %74, align 8, !alias.scope !585
  %75 = load i32, i32* %72, align 4
  %76 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 15
  store i32 %75, i32* %76, align 4, !alias.scope !585
  %77 = add nsw i32 %9, 2
  %78 = mul nsw i32 %23, %77
  %79 = sext i32 %78 to i64
  %80 = getelementptr inbounds i32, i32* %22, i64 %79
  %81 = getelementptr inbounds i32, i32* %80, i64 1
  %82 = load i32, i32* %80, align 4
  %83 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 16
  store i32 %82, i32* %83, align 16, !alias.scope !585
  %84 = getelementptr inbounds i32, i32* %81, i64 1
  %85 = load i32, i32* %81, align 4
  %86 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 17
  store i32 %85, i32* %86, align 4, !alias.scope !585
  %87 = getelementptr inbounds i32, i32* %84, i64 1
  %88 = load i32, i32* %84, align 4
  %89 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 18
  store i32 %88, i32* %89, align 8, !alias.scope !585
  %90 = getelementptr inbounds i32, i32* %87, i64 1
  %91 = load i32, i32* %87, align 4
  %92 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 19
  store i32 %91, i32* %92, align 4, !alias.scope !585
  %93 = getelementptr inbounds i32, i32* %90, i64 1
  %94 = load i32, i32* %90, align 4
  %95 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 20
  store i32 %94, i32* %95, align 16, !alias.scope !585
  %96 = getelementptr inbounds i32, i32* %93, i64 1
  %97 = load i32, i32* %93, align 4
  %98 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 21
  store i32 %97, i32* %98, align 4, !alias.scope !585
  %99 = getelementptr inbounds i32, i32* %96, i64 1
  %100 = load i32, i32* %96, align 4
  %101 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 22
  store i32 %100, i32* %101, align 8, !alias.scope !585
  %102 = load i32, i32* %99, align 4
  %103 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 23
  store i32 %102, i32* %103, align 4, !alias.scope !585
  %104 = add nsw i32 %9, 3
  %105 = mul nsw i32 %23, %104
  %106 = sext i32 %105 to i64
  %107 = getelementptr inbounds i32, i32* %22, i64 %106
  %108 = getelementptr inbounds i32, i32* %107, i64 1
  %109 = load i32, i32* %107, align 4
  %110 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 24
  store i32 %109, i32* %110, align 16, !alias.scope !585
  %111 = getelementptr inbounds i32, i32* %108, i64 1
  %112 = load i32, i32* %108, align 4
  %113 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 25
  store i32 %112, i32* %113, align 4, !alias.scope !585
  %114 = getelementptr inbounds i32, i32* %111, i64 1
  %115 = load i32, i32* %111, align 4
  %116 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 26
  store i32 %115, i32* %116, align 8, !alias.scope !585
  %117 = getelementptr inbounds i32, i32* %114, i64 1
  %118 = load i32, i32* %114, align 4
  %119 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 27
  store i32 %118, i32* %119, align 4, !alias.scope !585
  %120 = getelementptr inbounds i32, i32* %117, i64 1
  %121 = load i32, i32* %117, align 4
  %122 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 28
  store i32 %121, i32* %122, align 16, !alias.scope !585
  %123 = getelementptr inbounds i32, i32* %120, i64 1
  %124 = load i32, i32* %120, align 4
  %125 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 29
  store i32 %124, i32* %125, align 4, !alias.scope !585
  %126 = getelementptr inbounds i32, i32* %123, i64 1
  %127 = load i32, i32* %123, align 4
  %128 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 30
  store i32 %127, i32* %128, align 8, !alias.scope !585
  %129 = load i32, i32* %126, align 4
  %130 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 31
  store i32 %129, i32* %130, align 4, !alias.scope !585
  %131 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %132 = load i32*, i32** %131, align 8, !noalias !588
  %133 = getelementptr i32, i32* %132, i64 %18
  %134 = bitcast i32* %133 to <4 x i32>*
  %135 = load <4 x i32>, <4 x i32>* %134, align 4
  %136 = getelementptr inbounds i32, i32* %133, i64 4
  %137 = bitcast i32* %136 to <4 x i32>*
  %138 = load <4 x i32>, <4 x i32>* %137, align 4
  %139 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %140 = load i32*, i32** %139, align 8
  %141 = sext i32 %9 to i64
  %142 = getelementptr i32, i32* %140, i64 %141
  %143 = bitcast i32* %142 to i64*
  %144 = load i64, i64* %143, align 4
  %145 = getelementptr inbounds i32, i32* %142, i64 2
  %146 = bitcast i32* %145 to i64*
  %147 = load i64, i64* %146, align 4
  %148 = lshr i64 %144, 32
  %149 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 0
  %150 = load i32, i32* %149, align 4
  %151 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %152 = load i32, i32* %151, align 4
  %153 = insertelement <4 x i32> undef, i32 %152, i32 0
  %154 = shufflevector <4 x i32> %153, <4 x i32> undef, <4 x i32> zeroinitializer
  %155 = mul nsw <4 x i32> %154, %135
  %156 = mul nsw <4 x i32> %154, %138
  %157 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to <4 x i32>*
  %158 = load <4 x i32>, <4 x i32>* %157, align 16
  %159 = add nsw <4 x i32> %158, %155
  %160 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to <4 x i32>*
  store <4 x i32> %159, <4 x i32>* %160, align 16
  %161 = bitcast i32* %41 to <4 x i32>*
  %162 = load <4 x i32>, <4 x i32>* %161, align 16
  %163 = add nsw <4 x i32> %162, %156
  %164 = bitcast i32* %41 to <4 x i32>*
  store <4 x i32> %163, <4 x i32>* %164, align 16
  %165 = bitcast i32* %56 to <4 x i32>*
  %166 = load <4 x i32>, <4 x i32>* %165, align 16
  %167 = add nsw <4 x i32> %166, %155
  %168 = bitcast i32* %56 to <4 x i32>*
  store <4 x i32> %167, <4 x i32>* %168, align 16
  %169 = bitcast i32* %68 to <4 x i32>*
  %170 = load <4 x i32>, <4 x i32>* %169, align 16
  %171 = add nsw <4 x i32> %170, %156
  %172 = bitcast i32* %68 to <4 x i32>*
  store <4 x i32> %171, <4 x i32>* %172, align 16
  %173 = bitcast i32* %83 to <4 x i32>*
  %174 = load <4 x i32>, <4 x i32>* %173, align 16
  %175 = add nsw <4 x i32> %174, %155
  %176 = bitcast i32* %83 to <4 x i32>*
  store <4 x i32> %175, <4 x i32>* %176, align 16
  %177 = bitcast i32* %95 to <4 x i32>*
  %178 = load <4 x i32>, <4 x i32>* %177, align 16
  %179 = add nsw <4 x i32> %178, %156
  %180 = bitcast i32* %95 to <4 x i32>*
  store <4 x i32> %179, <4 x i32>* %180, align 16
  %181 = bitcast i32* %110 to <4 x i32>*
  %182 = load <4 x i32>, <4 x i32>* %181, align 16
  %183 = add nsw <4 x i32> %182, %155
  %184 = bitcast i32* %110 to <4 x i32>*
  store <4 x i32> %183, <4 x i32>* %184, align 16
  %185 = bitcast i32* %122 to <4 x i32>*
  %186 = load <4 x i32>, <4 x i32>* %185, align 16
  %187 = add nsw <4 x i32> %186, %156
  %188 = bitcast i32* %122 to <4 x i32>*
  store <4 x i32> %187, <4 x i32>* %188, align 16
  %189 = trunc i64 %144 to i32
  %190 = trunc i64 %148 to i32
  %191 = mul nsw i32 %152, %7
  %192 = add nsw i32 %191, %189
  %193 = add nsw i32 %191, %190
  %194 = trunc i64 %147 to i32
  %195 = add nsw i32 %191, %194
  %196 = lshr i64 %147, 32
  %197 = trunc i64 %196 to i32
  %198 = add nsw i32 %191, %197
  %199 = mul nsw i32 %192, %150
  %200 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to <4 x i32>*
  %201 = load <4 x i32>, <4 x i32>* %200, align 16
  %202 = insertelement <4 x i32> undef, i32 %199, i32 0
  %203 = shufflevector <4 x i32> %202, <4 x i32> undef, <4 x i32> zeroinitializer
  %204 = add nsw <4 x i32> %201, %203
  %205 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to <4 x i32>*
  store <4 x i32> %204, <4 x i32>* %205, align 16
  %206 = bitcast i32* %41 to <4 x i32>*
  %207 = load <4 x i32>, <4 x i32>* %206, align 16
  %208 = add nsw <4 x i32> %207, %203
  %209 = bitcast i32* %41 to <4 x i32>*
  store <4 x i32> %208, <4 x i32>* %209, align 16
  %210 = mul nsw i32 %193, %150
  %211 = bitcast i32* %56 to <4 x i32>*
  %212 = load <4 x i32>, <4 x i32>* %211, align 16
  %213 = insertelement <4 x i32> undef, i32 %210, i32 0
  %214 = shufflevector <4 x i32> %213, <4 x i32> undef, <4 x i32> zeroinitializer
  %215 = add nsw <4 x i32> %212, %214
  %216 = bitcast i32* %56 to <4 x i32>*
  store <4 x i32> %215, <4 x i32>* %216, align 16
  %217 = bitcast i32* %68 to <4 x i32>*
  %218 = load <4 x i32>, <4 x i32>* %217, align 16
  %219 = add nsw <4 x i32> %218, %214
  %220 = bitcast i32* %68 to <4 x i32>*
  store <4 x i32> %219, <4 x i32>* %220, align 16
  %221 = mul nsw i32 %195, %150
  %222 = bitcast i32* %83 to <4 x i32>*
  %223 = load <4 x i32>, <4 x i32>* %222, align 16
  %224 = insertelement <4 x i32> undef, i32 %221, i32 0
  %225 = shufflevector <4 x i32> %224, <4 x i32> undef, <4 x i32> zeroinitializer
  %226 = add nsw <4 x i32> %223, %225
  %227 = bitcast i32* %83 to <4 x i32>*
  store <4 x i32> %226, <4 x i32>* %227, align 16
  %228 = bitcast i32* %95 to <4 x i32>*
  %229 = load <4 x i32>, <4 x i32>* %228, align 16
  %230 = add nsw <4 x i32> %229, %225
  %231 = bitcast i32* %95 to <4 x i32>*
  store <4 x i32> %230, <4 x i32>* %231, align 16
  %232 = mul nsw i32 %198, %150
  %233 = bitcast i32* %110 to <4 x i32>*
  %234 = load <4 x i32>, <4 x i32>* %233, align 16
  %235 = insertelement <4 x i32> undef, i32 %232, i32 0
  %236 = shufflevector <4 x i32> %235, <4 x i32> undef, <4 x i32> zeroinitializer
  %237 = add nsw <4 x i32> %234, %236
  %238 = bitcast i32* %110 to <4 x i32>*
  store <4 x i32> %237, <4 x i32>* %238, align 16
  %239 = bitcast i32* %122 to <4 x i32>*
  %240 = load <4 x i32>, <4 x i32>* %239, align 16
  %241 = add nsw <4 x i32> %240, %236
  %242 = bitcast i32* %122 to <4 x i32>*
  store <4 x i32> %241, <4 x i32>* %242, align 16
  tail call void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_13RegisterBlockIiLi8ELi4EEEE7ExecuteINS_9MatrixMapIhLNS_8MapOrderE0EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.286"* %1, %"struct.gemmlowp::RegisterBlock.302"* nonnull byval(%"struct.gemmlowp::RegisterBlock.302") align 8 %15, %"class.gemmlowp::MatrixMap.182"* %2, i32 %10, i32 %11, i32 %12, i32 %13)
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %16) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.270"* dereferenceable(40), %"class.gemmlowp::MatrixMap.195"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.312", align 8
  %16 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %17 = sext i32 %8 to i64
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %19 = load i32*, i32** %16, align 8, !noalias !593
  %20 = getelementptr inbounds i32, i32* %19, i64 %17
  %21 = load i32, i32* %18, align 8, !noalias !593
  %22 = mul nsw i32 %21, %9
  %23 = sext i32 %22 to i64
  %24 = getelementptr inbounds i32, i32* %20, i64 %23
  %25 = getelementptr inbounds i32, i32* %24, i64 1
  %26 = load i32, i32* %24, align 4, !noalias !593
  %27 = getelementptr inbounds i32, i32* %25, i64 1
  %28 = load i32, i32* %25, align 4, !noalias !593
  %29 = getelementptr inbounds i32, i32* %27, i64 1
  %30 = load i32, i32* %27, align 4, !noalias !593
  %31 = load i32, i32* %29, align 4, !noalias !593
  %32 = add nsw i32 %9, 1
  %33 = mul nsw i32 %21, %32
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds i32, i32* %20, i64 %34
  %36 = getelementptr inbounds i32, i32* %35, i64 1
  %37 = load i32, i32* %35, align 4, !noalias !593
  %38 = getelementptr inbounds i32, i32* %36, i64 1
  %39 = load i32, i32* %36, align 4, !noalias !593
  %40 = getelementptr inbounds i32, i32* %38, i64 1
  %41 = load i32, i32* %38, align 4, !noalias !593
  %42 = load i32, i32* %40, align 4, !noalias !593
  %43 = add nsw i32 %9, 2
  %44 = mul nsw i32 %21, %43
  %45 = sext i32 %44 to i64
  %46 = getelementptr inbounds i32, i32* %20, i64 %45
  %47 = getelementptr inbounds i32, i32* %46, i64 1
  %48 = load i32, i32* %46, align 4, !noalias !593
  %49 = getelementptr inbounds i32, i32* %47, i64 1
  %50 = load i32, i32* %47, align 4, !noalias !593
  %51 = getelementptr inbounds i32, i32* %49, i64 1
  %52 = load i32, i32* %49, align 4, !noalias !593
  %53 = load i32, i32* %51, align 4, !noalias !593
  %54 = add nsw i32 %9, 3
  %55 = mul nsw i32 %21, %54
  %56 = sext i32 %55 to i64
  %57 = getelementptr inbounds i32, i32* %20, i64 %56
  %58 = getelementptr inbounds i32, i32* %57, i64 1
  %59 = load i32, i32* %57, align 4, !noalias !593
  %60 = getelementptr inbounds i32, i32* %58, i64 1
  %61 = load i32, i32* %58, align 4, !noalias !593
  %62 = getelementptr inbounds i32, i32* %60, i64 1
  %63 = load i32, i32* %60, align 4, !noalias !593
  %64 = load i32, i32* %62, align 4, !noalias !593
  %65 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %66 = load i32*, i32** %65, align 8
  %67 = getelementptr i32, i32* %66, i64 %17
  %68 = bitcast i32* %67 to i64*
  %69 = load i64, i64* %68, align 4
  %70 = getelementptr inbounds i32, i32* %67, i64 2
  %71 = bitcast i32* %70 to i64*
  %72 = load i64, i64* %71, align 4
  %73 = trunc i64 %69 to i32
  %74 = lshr i64 %69, 32
  %75 = trunc i64 %74 to i32
  %76 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %77 = load i32*, i32** %76, align 8
  %78 = sext i32 %9 to i64
  %79 = getelementptr i32, i32* %77, i64 %78
  %80 = bitcast i32* %79 to i64*
  %81 = load i64, i64* %80, align 4
  %82 = getelementptr inbounds i32, i32* %79, i64 2
  %83 = bitcast i32* %82 to i64*
  %84 = load i64, i64* %83, align 4
  %85 = trunc i64 %81 to i32
  %86 = lshr i64 %81, 32
  %87 = trunc i64 %86 to i32
  %88 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 0
  %89 = load i32, i32* %88, align 4
  %90 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %91 = load i32, i32* %90, align 4
  %92 = mul nsw i32 %91, %73
  %93 = add nsw i32 %92, %26
  %94 = mul nsw i32 %91, %75
  %95 = add nsw i32 %94, %28
  %96 = trunc i64 %72 to i32
  %97 = mul nsw i32 %91, %96
  %98 = add nsw i32 %97, %30
  %99 = lshr i64 %72, 32
  %100 = trunc i64 %99 to i32
  %101 = mul nsw i32 %91, %100
  %102 = add nsw i32 %101, %31
  %103 = add nsw i32 %92, %37
  %104 = add nsw i32 %94, %39
  %105 = add nsw i32 %97, %41
  %106 = add nsw i32 %101, %42
  %107 = add nsw i32 %92, %48
  %108 = add nsw i32 %94, %50
  %109 = add nsw i32 %97, %52
  %110 = add nsw i32 %101, %53
  %111 = add nsw i32 %92, %59
  %112 = add nsw i32 %94, %61
  %113 = add nsw i32 %97, %63
  %114 = add nsw i32 %101, %64
  %115 = mul nsw i32 %91, %7
  %116 = add nsw i32 %115, %85
  %117 = add nsw i32 %115, %87
  %118 = trunc i64 %84 to i32
  %119 = add nsw i32 %115, %118
  %120 = lshr i64 %84, 32
  %121 = trunc i64 %120 to i32
  %122 = add nsw i32 %115, %121
  %123 = mul nsw i32 %116, %89
  %124 = add nsw i32 %93, %123
  %125 = add nsw i32 %95, %123
  %126 = add nsw i32 %98, %123
  %127 = add nsw i32 %102, %123
  %128 = mul nsw i32 %117, %89
  %129 = add nsw i32 %103, %128
  %130 = add nsw i32 %104, %128
  %131 = add nsw i32 %105, %128
  %132 = add nsw i32 %106, %128
  %133 = mul nsw i32 %119, %89
  %134 = add nsw i32 %107, %133
  %135 = add nsw i32 %108, %133
  %136 = add nsw i32 %109, %133
  %137 = add nsw i32 %110, %133
  %138 = mul nsw i32 %122, %89
  %139 = add nsw i32 %111, %138
  %140 = add nsw i32 %112, %138
  %141 = add nsw i32 %113, %138
  %142 = add nsw i32 %114, %138
  %143 = bitcast %"struct.gemmlowp::RegisterBlock.312"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %143)
  %144 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 0
  store i32 %124, i32* %144, align 8
  %145 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 1
  store i32 %125, i32* %145, align 4
  %146 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 2
  store i32 %126, i32* %146, align 8
  %147 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 3
  store i32 %127, i32* %147, align 4
  %148 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 4
  store i32 %129, i32* %148, align 8
  %149 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 5
  store i32 %130, i32* %149, align 4
  %150 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 6
  store i32 %131, i32* %150, align 8
  %151 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 7
  store i32 %132, i32* %151, align 4
  %152 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 8
  store i32 %134, i32* %152, align 8
  %153 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 9
  store i32 %135, i32* %153, align 4
  %154 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 10
  store i32 %136, i32* %154, align 8
  %155 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 11
  store i32 %137, i32* %155, align 4
  %156 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 12
  store i32 %139, i32* %156, align 8
  %157 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 13
  store i32 %140, i32* %157, align 4
  %158 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 14
  store i32 %141, i32* %158, align 8
  %159 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 15
  store i32 %142, i32* %159, align 4
  %160 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.270", %"struct.gemmlowp::OutputPipelineExecutor.270"* %1, i64 0, i32 0
  %161 = tail call { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi0ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.271"* %160, %"struct.gemmlowp::RegisterBlock.312"* nonnull byval(%"struct.gemmlowp::RegisterBlock.312") align 8 %15, i32 %10, i32 %11) #19
  %162 = extractvalue { i64, i64 } %161, 0
  %163 = extractvalue { i64, i64 } %161, 1
  tail call void @_ZN8gemmlowp16StoreFinalOutputINS_13RegisterBlockIhLi4ELi4EEENS_9MatrixMapIhLNS_8MapOrderE1EEEEEvT_PT0_ii(i64 %162, i64 %163, %"class.gemmlowp::MatrixMap.195"* %2, i32 %12, i32 %13) #19
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %143)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.286"* dereferenceable(40), %"class.gemmlowp::MatrixMap.195"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.302", align 16
  %16 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %16) #19
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %18 = sext i32 %8 to i64
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %20 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %20, i8 -86, i64 128, i1 false)
  %21 = load i32*, i32** %17, align 8, !noalias !598
  %22 = getelementptr inbounds i32, i32* %21, i64 %18
  %23 = load i32, i32* %19, align 8, !noalias !598
  %24 = mul nsw i32 %23, %9
  %25 = sext i32 %24 to i64
  %26 = getelementptr inbounds i32, i32* %22, i64 %25
  %27 = getelementptr inbounds i32, i32* %26, i64 1
  %28 = load i32, i32* %26, align 4
  %29 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 0
  store i32 %28, i32* %29, align 16, !alias.scope !598
  %30 = getelementptr inbounds i32, i32* %27, i64 1
  %31 = load i32, i32* %27, align 4
  %32 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 1
  store i32 %31, i32* %32, align 4, !alias.scope !598
  %33 = getelementptr inbounds i32, i32* %30, i64 1
  %34 = load i32, i32* %30, align 4
  %35 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 2
  store i32 %34, i32* %35, align 8, !alias.scope !598
  %36 = getelementptr inbounds i32, i32* %33, i64 1
  %37 = load i32, i32* %33, align 4
  %38 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 3
  store i32 %37, i32* %38, align 4, !alias.scope !598
  %39 = getelementptr inbounds i32, i32* %36, i64 1
  %40 = load i32, i32* %36, align 4
  %41 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 4
  store i32 %40, i32* %41, align 16, !alias.scope !598
  %42 = getelementptr inbounds i32, i32* %39, i64 1
  %43 = load i32, i32* %39, align 4
  %44 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 5
  store i32 %43, i32* %44, align 4, !alias.scope !598
  %45 = getelementptr inbounds i32, i32* %42, i64 1
  %46 = load i32, i32* %42, align 4
  %47 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 6
  store i32 %46, i32* %47, align 8, !alias.scope !598
  %48 = load i32, i32* %45, align 4
  %49 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 7
  store i32 %48, i32* %49, align 4, !alias.scope !598
  %50 = add nsw i32 %9, 1
  %51 = mul nsw i32 %23, %50
  %52 = sext i32 %51 to i64
  %53 = getelementptr inbounds i32, i32* %22, i64 %52
  %54 = getelementptr inbounds i32, i32* %53, i64 1
  %55 = load i32, i32* %53, align 4
  %56 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 8
  store i32 %55, i32* %56, align 16, !alias.scope !598
  %57 = getelementptr inbounds i32, i32* %54, i64 1
  %58 = load i32, i32* %54, align 4
  %59 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 9
  store i32 %58, i32* %59, align 4, !alias.scope !598
  %60 = getelementptr inbounds i32, i32* %57, i64 1
  %61 = load i32, i32* %57, align 4
  %62 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 10
  store i32 %61, i32* %62, align 8, !alias.scope !598
  %63 = getelementptr inbounds i32, i32* %60, i64 1
  %64 = load i32, i32* %60, align 4
  %65 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 11
  store i32 %64, i32* %65, align 4, !alias.scope !598
  %66 = getelementptr inbounds i32, i32* %63, i64 1
  %67 = load i32, i32* %63, align 4
  %68 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 12
  store i32 %67, i32* %68, align 16, !alias.scope !598
  %69 = getelementptr inbounds i32, i32* %66, i64 1
  %70 = load i32, i32* %66, align 4
  %71 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 13
  store i32 %70, i32* %71, align 4, !alias.scope !598
  %72 = getelementptr inbounds i32, i32* %69, i64 1
  %73 = load i32, i32* %69, align 4
  %74 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 14
  store i32 %73, i32* %74, align 8, !alias.scope !598
  %75 = load i32, i32* %72, align 4
  %76 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 15
  store i32 %75, i32* %76, align 4, !alias.scope !598
  %77 = add nsw i32 %9, 2
  %78 = mul nsw i32 %23, %77
  %79 = sext i32 %78 to i64
  %80 = getelementptr inbounds i32, i32* %22, i64 %79
  %81 = getelementptr inbounds i32, i32* %80, i64 1
  %82 = load i32, i32* %80, align 4
  %83 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 16
  store i32 %82, i32* %83, align 16, !alias.scope !598
  %84 = getelementptr inbounds i32, i32* %81, i64 1
  %85 = load i32, i32* %81, align 4
  %86 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 17
  store i32 %85, i32* %86, align 4, !alias.scope !598
  %87 = getelementptr inbounds i32, i32* %84, i64 1
  %88 = load i32, i32* %84, align 4
  %89 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 18
  store i32 %88, i32* %89, align 8, !alias.scope !598
  %90 = getelementptr inbounds i32, i32* %87, i64 1
  %91 = load i32, i32* %87, align 4
  %92 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 19
  store i32 %91, i32* %92, align 4, !alias.scope !598
  %93 = getelementptr inbounds i32, i32* %90, i64 1
  %94 = load i32, i32* %90, align 4
  %95 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 20
  store i32 %94, i32* %95, align 16, !alias.scope !598
  %96 = getelementptr inbounds i32, i32* %93, i64 1
  %97 = load i32, i32* %93, align 4
  %98 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 21
  store i32 %97, i32* %98, align 4, !alias.scope !598
  %99 = getelementptr inbounds i32, i32* %96, i64 1
  %100 = load i32, i32* %96, align 4
  %101 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 22
  store i32 %100, i32* %101, align 8, !alias.scope !598
  %102 = load i32, i32* %99, align 4
  %103 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 23
  store i32 %102, i32* %103, align 4, !alias.scope !598
  %104 = add nsw i32 %9, 3
  %105 = mul nsw i32 %23, %104
  %106 = sext i32 %105 to i64
  %107 = getelementptr inbounds i32, i32* %22, i64 %106
  %108 = getelementptr inbounds i32, i32* %107, i64 1
  %109 = load i32, i32* %107, align 4
  %110 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 24
  store i32 %109, i32* %110, align 16, !alias.scope !598
  %111 = getelementptr inbounds i32, i32* %108, i64 1
  %112 = load i32, i32* %108, align 4
  %113 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 25
  store i32 %112, i32* %113, align 4, !alias.scope !598
  %114 = getelementptr inbounds i32, i32* %111, i64 1
  %115 = load i32, i32* %111, align 4
  %116 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 26
  store i32 %115, i32* %116, align 8, !alias.scope !598
  %117 = getelementptr inbounds i32, i32* %114, i64 1
  %118 = load i32, i32* %114, align 4
  %119 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 27
  store i32 %118, i32* %119, align 4, !alias.scope !598
  %120 = getelementptr inbounds i32, i32* %117, i64 1
  %121 = load i32, i32* %117, align 4
  %122 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 28
  store i32 %121, i32* %122, align 16, !alias.scope !598
  %123 = getelementptr inbounds i32, i32* %120, i64 1
  %124 = load i32, i32* %120, align 4
  %125 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 29
  store i32 %124, i32* %125, align 4, !alias.scope !598
  %126 = getelementptr inbounds i32, i32* %123, i64 1
  %127 = load i32, i32* %123, align 4
  %128 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 30
  store i32 %127, i32* %128, align 8, !alias.scope !598
  %129 = load i32, i32* %126, align 4
  %130 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 31
  store i32 %129, i32* %130, align 4, !alias.scope !598
  %131 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %132 = load i32*, i32** %131, align 8, !noalias !601
  %133 = getelementptr i32, i32* %132, i64 %18
  %134 = bitcast i32* %133 to <4 x i32>*
  %135 = load <4 x i32>, <4 x i32>* %134, align 4
  %136 = getelementptr inbounds i32, i32* %133, i64 4
  %137 = bitcast i32* %136 to <4 x i32>*
  %138 = load <4 x i32>, <4 x i32>* %137, align 4
  %139 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %140 = load i32*, i32** %139, align 8
  %141 = sext i32 %9 to i64
  %142 = getelementptr i32, i32* %140, i64 %141
  %143 = bitcast i32* %142 to i64*
  %144 = load i64, i64* %143, align 4
  %145 = getelementptr inbounds i32, i32* %142, i64 2
  %146 = bitcast i32* %145 to i64*
  %147 = load i64, i64* %146, align 4
  %148 = lshr i64 %144, 32
  %149 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 0
  %150 = load i32, i32* %149, align 4
  %151 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %152 = load i32, i32* %151, align 4
  %153 = insertelement <4 x i32> undef, i32 %152, i32 0
  %154 = shufflevector <4 x i32> %153, <4 x i32> undef, <4 x i32> zeroinitializer
  %155 = mul nsw <4 x i32> %154, %135
  %156 = mul nsw <4 x i32> %154, %138
  %157 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to <4 x i32>*
  %158 = load <4 x i32>, <4 x i32>* %157, align 16
  %159 = add nsw <4 x i32> %158, %155
  %160 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to <4 x i32>*
  store <4 x i32> %159, <4 x i32>* %160, align 16
  %161 = bitcast i32* %41 to <4 x i32>*
  %162 = load <4 x i32>, <4 x i32>* %161, align 16
  %163 = add nsw <4 x i32> %162, %156
  %164 = bitcast i32* %41 to <4 x i32>*
  store <4 x i32> %163, <4 x i32>* %164, align 16
  %165 = bitcast i32* %56 to <4 x i32>*
  %166 = load <4 x i32>, <4 x i32>* %165, align 16
  %167 = add nsw <4 x i32> %166, %155
  %168 = bitcast i32* %56 to <4 x i32>*
  store <4 x i32> %167, <4 x i32>* %168, align 16
  %169 = bitcast i32* %68 to <4 x i32>*
  %170 = load <4 x i32>, <4 x i32>* %169, align 16
  %171 = add nsw <4 x i32> %170, %156
  %172 = bitcast i32* %68 to <4 x i32>*
  store <4 x i32> %171, <4 x i32>* %172, align 16
  %173 = bitcast i32* %83 to <4 x i32>*
  %174 = load <4 x i32>, <4 x i32>* %173, align 16
  %175 = add nsw <4 x i32> %174, %155
  %176 = bitcast i32* %83 to <4 x i32>*
  store <4 x i32> %175, <4 x i32>* %176, align 16
  %177 = bitcast i32* %95 to <4 x i32>*
  %178 = load <4 x i32>, <4 x i32>* %177, align 16
  %179 = add nsw <4 x i32> %178, %156
  %180 = bitcast i32* %95 to <4 x i32>*
  store <4 x i32> %179, <4 x i32>* %180, align 16
  %181 = bitcast i32* %110 to <4 x i32>*
  %182 = load <4 x i32>, <4 x i32>* %181, align 16
  %183 = add nsw <4 x i32> %182, %155
  %184 = bitcast i32* %110 to <4 x i32>*
  store <4 x i32> %183, <4 x i32>* %184, align 16
  %185 = bitcast i32* %122 to <4 x i32>*
  %186 = load <4 x i32>, <4 x i32>* %185, align 16
  %187 = add nsw <4 x i32> %186, %156
  %188 = bitcast i32* %122 to <4 x i32>*
  store <4 x i32> %187, <4 x i32>* %188, align 16
  %189 = trunc i64 %144 to i32
  %190 = trunc i64 %148 to i32
  %191 = mul nsw i32 %152, %7
  %192 = add nsw i32 %191, %189
  %193 = add nsw i32 %191, %190
  %194 = trunc i64 %147 to i32
  %195 = add nsw i32 %191, %194
  %196 = lshr i64 %147, 32
  %197 = trunc i64 %196 to i32
  %198 = add nsw i32 %191, %197
  %199 = mul nsw i32 %192, %150
  %200 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to <4 x i32>*
  %201 = load <4 x i32>, <4 x i32>* %200, align 16
  %202 = insertelement <4 x i32> undef, i32 %199, i32 0
  %203 = shufflevector <4 x i32> %202, <4 x i32> undef, <4 x i32> zeroinitializer
  %204 = add nsw <4 x i32> %201, %203
  %205 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to <4 x i32>*
  store <4 x i32> %204, <4 x i32>* %205, align 16
  %206 = bitcast i32* %41 to <4 x i32>*
  %207 = load <4 x i32>, <4 x i32>* %206, align 16
  %208 = add nsw <4 x i32> %207, %203
  %209 = bitcast i32* %41 to <4 x i32>*
  store <4 x i32> %208, <4 x i32>* %209, align 16
  %210 = mul nsw i32 %193, %150
  %211 = bitcast i32* %56 to <4 x i32>*
  %212 = load <4 x i32>, <4 x i32>* %211, align 16
  %213 = insertelement <4 x i32> undef, i32 %210, i32 0
  %214 = shufflevector <4 x i32> %213, <4 x i32> undef, <4 x i32> zeroinitializer
  %215 = add nsw <4 x i32> %212, %214
  %216 = bitcast i32* %56 to <4 x i32>*
  store <4 x i32> %215, <4 x i32>* %216, align 16
  %217 = bitcast i32* %68 to <4 x i32>*
  %218 = load <4 x i32>, <4 x i32>* %217, align 16
  %219 = add nsw <4 x i32> %218, %214
  %220 = bitcast i32* %68 to <4 x i32>*
  store <4 x i32> %219, <4 x i32>* %220, align 16
  %221 = mul nsw i32 %195, %150
  %222 = bitcast i32* %83 to <4 x i32>*
  %223 = load <4 x i32>, <4 x i32>* %222, align 16
  %224 = insertelement <4 x i32> undef, i32 %221, i32 0
  %225 = shufflevector <4 x i32> %224, <4 x i32> undef, <4 x i32> zeroinitializer
  %226 = add nsw <4 x i32> %223, %225
  %227 = bitcast i32* %83 to <4 x i32>*
  store <4 x i32> %226, <4 x i32>* %227, align 16
  %228 = bitcast i32* %95 to <4 x i32>*
  %229 = load <4 x i32>, <4 x i32>* %228, align 16
  %230 = add nsw <4 x i32> %229, %225
  %231 = bitcast i32* %95 to <4 x i32>*
  store <4 x i32> %230, <4 x i32>* %231, align 16
  %232 = mul nsw i32 %198, %150
  %233 = bitcast i32* %110 to <4 x i32>*
  %234 = load <4 x i32>, <4 x i32>* %233, align 16
  %235 = insertelement <4 x i32> undef, i32 %232, i32 0
  %236 = shufflevector <4 x i32> %235, <4 x i32> undef, <4 x i32> zeroinitializer
  %237 = add nsw <4 x i32> %234, %236
  %238 = bitcast i32* %110 to <4 x i32>*
  store <4 x i32> %237, <4 x i32>* %238, align 16
  %239 = bitcast i32* %122 to <4 x i32>*
  %240 = load <4 x i32>, <4 x i32>* %239, align 16
  %241 = add nsw <4 x i32> %240, %236
  %242 = bitcast i32* %122 to <4 x i32>*
  store <4 x i32> %241, <4 x i32>* %242, align 16
  tail call void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_13RegisterBlockIiLi8ELi4EEEE7ExecuteINS_9MatrixMapIhLNS_8MapOrderE1EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.286"* %1, %"struct.gemmlowp::RegisterBlock.302"* nonnull byval(%"struct.gemmlowp::RegisterBlock.302") align 8 %15, %"class.gemmlowp::MatrixMap.195"* %2, i32 %10, i32 %11, i32 %12, i32 %13)
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %16) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.242"* dereferenceable(40), %"class.gemmlowp::MatrixMap.195"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.304", align 16
  %16 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %17 = sext i32 %8 to i64
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %19 = load i32*, i32** %16, align 8, !noalias !606
  %20 = getelementptr inbounds i32, i32* %19, i64 %17
  %21 = load i32, i32* %18, align 8, !noalias !606
  %22 = mul nsw i32 %21, %9
  %23 = sext i32 %22 to i64
  %24 = getelementptr inbounds i32, i32* %20, i64 %23
  %25 = getelementptr inbounds i32, i32* %24, i64 1
  %26 = getelementptr inbounds i32, i32* %25, i64 1
  %27 = getelementptr inbounds i32, i32* %26, i64 1
  %28 = getelementptr inbounds i32, i32* %27, i64 1
  %29 = bitcast i32* %24 to <4 x i32>*
  %30 = load <4 x i32>, <4 x i32>* %29, align 4, !noalias !606
  %31 = getelementptr inbounds i32, i32* %28, i64 1
  %32 = load i32, i32* %28, align 4, !noalias !606
  %33 = getelementptr inbounds i32, i32* %31, i64 1
  %34 = load i32, i32* %31, align 4, !noalias !606
  %35 = getelementptr inbounds i32, i32* %33, i64 1
  %36 = load i32, i32* %33, align 4, !noalias !606
  %37 = load i32, i32* %35, align 4, !noalias !606
  %38 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %39 = load i32*, i32** %38, align 8, !noalias !611
  %40 = getelementptr i32, i32* %39, i64 %17
  %41 = bitcast i32* %40 to <4 x i32>*
  %42 = load <4 x i32>, <4 x i32>* %41, align 4
  %43 = getelementptr inbounds i32, i32* %40, i64 4
  %44 = bitcast i32* %43 to <4 x i32>*
  %45 = load <4 x i32>, <4 x i32>* %44, align 4
  %46 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %47 = load i32*, i32** %46, align 8
  %48 = sext i32 %9 to i64
  %49 = getelementptr inbounds i32, i32* %47, i64 %48
  %50 = load i32, i32* %49, align 4
  %51 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 0
  %52 = load i32, i32* %51, align 4
  %53 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %54 = load i32, i32* %53, align 4
  %55 = insertelement <4 x i32> undef, i32 %54, i32 0
  %56 = shufflevector <4 x i32> %55, <4 x i32> undef, <4 x i32> zeroinitializer
  %57 = mul nsw <4 x i32> %56, %42
  %58 = mul nsw <4 x i32> %56, %45
  %59 = mul nsw i32 %54, %7
  %60 = add nsw i32 %59, %50
  %61 = mul nsw i32 %60, %52
  %62 = bitcast %"struct.gemmlowp::RegisterBlock.304"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %62) #19
  %63 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.242", %"struct.gemmlowp::OutputPipelineExecutor.242"* %1, i64 0, i32 0, i32 0, i32 0
  %64 = load %"struct.gemmlowp::OutputStageBiasAddition.200"*, %"struct.gemmlowp::OutputStageBiasAddition.200"** %63, align 8, !noalias !616
  %65 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition.200", %"struct.gemmlowp::OutputStageBiasAddition.200"* %64, i64 0, i32 0, i32 0
  %66 = load i32*, i32** %65, align 8, !noalias !616
  %67 = sext i32 %11 to i64
  %68 = getelementptr inbounds i32, i32* %66, i64 %67
  %69 = load i32, i32* %68, align 4, !noalias !616
  %70 = add i32 %69, %61
  %71 = insertelement <4 x i32> undef, i32 %70, i32 0
  %72 = shufflevector <4 x i32> %71, <4 x i32> undef, <4 x i32> zeroinitializer
  %73 = add <4 x i32> %72, %30
  %74 = add <4 x i32> %73, %57
  %75 = insertelement <4 x i32> undef, i32 %32, i32 0
  %76 = insertelement <4 x i32> %75, i32 %34, i32 1
  %77 = insertelement <4 x i32> %76, i32 %36, i32 2
  %78 = insertelement <4 x i32> %77, i32 %37, i32 3
  %79 = add <4 x i32> %72, %78
  %80 = add <4 x i32> %79, %58
  %81 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.242", %"struct.gemmlowp::OutputPipelineExecutor.242"* %1, i64 0, i32 0, i32 1
  %82 = bitcast %"struct.gemmlowp::RegisterBlock.304"* %15 to <4 x i32>*
  store <4 x i32> %74, <4 x i32>* %82, align 16
  %83 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %15, i64 0, i32 0, i32 0, i64 4
  %84 = bitcast i32* %83 to <4 x i32>*
  store <4 x i32> %80, <4 x i32>* %84, align 16
  %85 = tail call i64 @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi1ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalESE_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.245"* %81, %"struct.gemmlowp::RegisterBlock.304"* nonnull byval(%"struct.gemmlowp::RegisterBlock.304") align 8 %15, i32 %10, i32 %11) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %62) #19
  %86 = trunc i64 %85 to i8
  %87 = lshr i64 %85, 8
  %88 = trunc i64 %87 to i8
  %89 = lshr i64 %85, 16
  %90 = trunc i64 %89 to i8
  %91 = lshr i64 %85, 24
  %92 = trunc i64 %91 to i8
  %93 = lshr i64 %85, 32
  %94 = trunc i64 %93 to i8
  %95 = lshr i64 %85, 40
  %96 = trunc i64 %95 to i8
  %97 = lshr i64 %85, 48
  %98 = trunc i64 %97 to i8
  %99 = lshr i64 %85, 56
  %100 = trunc i64 %99 to i8
  %101 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %2, i64 0, i32 0
  %102 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %2, i64 0, i32 3
  %103 = sext i32 %12 to i64
  %104 = load i8*, i8** %101, align 8
  %105 = load i32, i32* %102, align 8
  %106 = sext i32 %105 to i64
  %107 = mul nsw i64 %106, %103
  %108 = getelementptr inbounds i8, i8* %104, i64 %107
  %109 = sext i32 %13 to i64
  %110 = getelementptr inbounds i8, i8* %108, i64 %109
  store i8 %86, i8* %110, align 1
  %111 = add nsw i64 %103, 1
  %112 = load i8*, i8** %101, align 8
  %113 = load i32, i32* %102, align 8
  %114 = sext i32 %113 to i64
  %115 = mul nsw i64 %111, %114
  %116 = getelementptr inbounds i8, i8* %112, i64 %115
  %117 = getelementptr inbounds i8, i8* %116, i64 %109
  store i8 %88, i8* %117, align 1
  %118 = add nsw i64 %103, 2
  %119 = load i8*, i8** %101, align 8
  %120 = load i32, i32* %102, align 8
  %121 = sext i32 %120 to i64
  %122 = mul nsw i64 %118, %121
  %123 = getelementptr inbounds i8, i8* %119, i64 %122
  %124 = getelementptr inbounds i8, i8* %123, i64 %109
  store i8 %90, i8* %124, align 1
  %125 = add nsw i64 %103, 3
  %126 = load i8*, i8** %101, align 8
  %127 = load i32, i32* %102, align 8
  %128 = sext i32 %127 to i64
  %129 = mul nsw i64 %125, %128
  %130 = getelementptr inbounds i8, i8* %126, i64 %129
  %131 = getelementptr inbounds i8, i8* %130, i64 %109
  store i8 %92, i8* %131, align 1
  %132 = add nsw i64 %103, 4
  %133 = load i8*, i8** %101, align 8
  %134 = load i32, i32* %102, align 8
  %135 = sext i32 %134 to i64
  %136 = mul nsw i64 %132, %135
  %137 = getelementptr inbounds i8, i8* %133, i64 %136
  %138 = getelementptr inbounds i8, i8* %137, i64 %109
  store i8 %94, i8* %138, align 1
  %139 = add nsw i64 %103, 5
  %140 = load i8*, i8** %101, align 8
  %141 = load i32, i32* %102, align 8
  %142 = sext i32 %141 to i64
  %143 = mul nsw i64 %139, %142
  %144 = getelementptr inbounds i8, i8* %140, i64 %143
  %145 = getelementptr inbounds i8, i8* %144, i64 %109
  store i8 %96, i8* %145, align 1
  %146 = add nsw i64 %103, 6
  %147 = load i8*, i8** %101, align 8
  %148 = load i32, i32* %102, align 8
  %149 = sext i32 %148 to i64
  %150 = mul nsw i64 %146, %149
  %151 = getelementptr inbounds i8, i8* %147, i64 %150
  %152 = getelementptr inbounds i8, i8* %151, i64 %109
  store i8 %98, i8* %152, align 1
  %153 = add nsw i64 %103, 7
  %154 = load i8*, i8** %101, align 8
  %155 = load i32, i32* %102, align 8
  %156 = sext i32 %155 to i64
  %157 = mul nsw i64 %153, %156
  %158 = getelementptr inbounds i8, i8* %154, i64 %157
  %159 = getelementptr inbounds i8, i8* %158, i64 %109
  store i8 %100, i8* %159, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor"* dereferenceable(40), %"class.gemmlowp::MatrixMap.195"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %16 = load i32*, i32** %15, align 8
  %17 = sext i32 %8 to i64
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %19 = load i32, i32* %18, align 8
  %20 = getelementptr inbounds i32, i32* %16, i64 %17
  %21 = mul nsw i32 %19, %9
  %22 = sext i32 %21 to i64
  %23 = getelementptr inbounds i32, i32* %20, i64 %22
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %26 = load i32*, i32** %25, align 8
  %27 = getelementptr inbounds i32, i32* %26, i64 %17
  %28 = load i32, i32* %27, align 4
  %29 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %30 = load i32*, i32** %29, align 8
  %31 = sext i32 %9 to i64
  %32 = getelementptr inbounds i32, i32* %30, i64 %31
  %33 = load i32, i32* %32, align 4
  %34 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 0
  %35 = load i32, i32* %34, align 4
  %36 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %37 = load i32, i32* %36, align 4
  %38 = mul nsw i32 %37, %28
  %39 = add nsw i32 %38, %24
  %40 = mul nsw i32 %37, %7
  %41 = add nsw i32 %40, %33
  %42 = mul nsw i32 %41, %35
  %43 = add nsw i32 %39, %42
  %44 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor", %"struct.gemmlowp::OutputPipelineExecutor"* %1, i64 0, i32 0, i32 0, i32 0
  %45 = load %"struct.gemmlowp::OutputStageBiasAddition.200"*, %"struct.gemmlowp::OutputStageBiasAddition.200"** %44, align 8
  %46 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition.200", %"struct.gemmlowp::OutputStageBiasAddition.200"* %45, i64 0, i32 0, i32 0
  %47 = load i32*, i32** %46, align 8
  %48 = sext i32 %11 to i64
  %49 = getelementptr inbounds i32, i32* %47, i64 %48
  %50 = load i32, i32* %49, align 4
  %51 = add nsw i32 %43, %50
  %52 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor", %"struct.gemmlowp::OutputPipelineExecutor"* %1, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %53 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %52, align 8
  %54 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %53, i64 0, i32 2
  %55 = load i32, i32* %54, align 4
  %56 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor", %"struct.gemmlowp::OutputPipelineExecutor"* %1, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  %57 = load i32, i32* %56, align 8
  %58 = sext i32 %51 to i64
  %59 = shl i32 1, %57
  %60 = sext i32 %59 to i64
  %61 = mul nsw i64 %60, %58
  %62 = icmp slt i64 %61, 2147483647
  %63 = select i1 %62, i64 %61, i64 2147483647
  %64 = icmp sgt i64 %63, -2147483648
  %65 = select i1 %64, i64 %63, i64 -2147483648
  %66 = trunc i64 %65 to i32
  %67 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %53, i64 0, i32 0
  %68 = load i32, i32* %67, align 4
  %69 = icmp ne i32 %68, %66
  %70 = icmp ne i32 %66, -2147483648
  %71 = or i1 %69, %70
  br i1 %71, label %72, label %81

72:                                               ; preds = %14
  %73 = sext i32 %68 to i64
  %74 = select i1 %69, i64 %73, i64 %65
  %75 = mul nsw i64 %74, %65
  %76 = icmp sgt i64 %75, -1
  %77 = select i1 %76, i64 1073741824, i64 -1073741823
  %78 = add nsw i64 %77, %75
  %79 = sdiv i64 %78, 2147483648
  %80 = trunc i64 %79 to i32
  br label %81

81:                                               ; preds = %14, %72
  %82 = phi i32 [ %80, %72 ], [ 2147483647, %14 ]
  %83 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor", %"struct.gemmlowp::OutputPipelineExecutor"* %1, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  %84 = load i32, i32* %83, align 4
  %85 = zext i32 %84 to i64
  %86 = shl nsw i64 -1, %85
  %87 = trunc i64 %86 to i32
  %88 = xor i32 %87, -1
  %89 = and i32 %82, %88
  %90 = ashr i32 %88, 1
  %91 = lshr i32 %82, 31
  %92 = add nsw i32 %90, %91
  %93 = ashr i32 %82, %84
  %94 = icmp sgt i32 %89, %92
  %95 = zext i1 %94 to i32
  %96 = add i32 %93, %55
  %97 = add i32 %96, %95
  %98 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor", %"struct.gemmlowp::OutputPipelineExecutor"* %1, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %99 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %98, align 8
  %100 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %99, i64 0, i32 0
  %101 = load i32, i32* %100, align 4
  %102 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %99, i64 0, i32 1
  %103 = load i32, i32* %102, align 4
  %104 = icmp sgt i32 %101, %97
  %105 = select i1 %104, i32 %101, i32 %97
  %106 = icmp slt i32 %103, %105
  %107 = select i1 %106, i32 %103, i32 %105
  %108 = icmp sgt i32 %107, 0
  %109 = select i1 %108, i32 %107, i32 0
  %110 = icmp slt i32 %109, 255
  %111 = select i1 %110, i32 %109, i32 255
  %112 = trunc i32 %111 to i8
  %113 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %2, i64 0, i32 0
  %114 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %2, i64 0, i32 3
  %115 = load i8*, i8** %113, align 8
  %116 = load i32, i32* %114, align 8
  %117 = mul nsw i32 %116, %12
  %118 = sext i32 %117 to i64
  %119 = getelementptr inbounds i8, i8* %115, i64 %118
  %120 = sext i32 %13 to i64
  %121 = getelementptr inbounds i8, i8* %119, i64 %120
  store i8 %112, i8* %121, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_13RegisterBlockIiLi8ELi4EEEE7ExecuteINS_9MatrixMapIhLNS_8MapOrderE0EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.286"*, %"struct.gemmlowp::RegisterBlock.302"* byval(%"struct.gemmlowp::RegisterBlock.302") align 8, %"class.gemmlowp::MatrixMap.182"*, i32, i32, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %8 = alloca %"struct.gemmlowp::RegisterBlock.302", align 16
  %9 = alloca %"struct.gemmlowp::RegisterBlock.310", align 8
  %10 = alloca %"struct.gemmlowp::RegisterBlock.310", align 1
  %11 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %10, i64 0, i32 0, i32 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %11) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 1 %11, i8 -86, i64 32, i1 false)
  %12 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %1 to <4 x i32>*
  %13 = load <4 x i32>, <4 x i32>* %12, align 8
  %14 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 4
  %15 = bitcast i32* %14 to <4 x i32>*
  %16 = load <4 x i32>, <4 x i32>* %15, align 8
  %17 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 8
  %18 = bitcast i32* %17 to <4 x i32>*
  %19 = load <4 x i32>, <4 x i32>* %18, align 8
  %20 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 12
  %21 = bitcast i32* %20 to <4 x i32>*
  %22 = load <4 x i32>, <4 x i32>* %21, align 8
  %23 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 16
  %24 = bitcast i32* %23 to <4 x i32>*
  %25 = load <4 x i32>, <4 x i32>* %24, align 8
  %26 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 20
  %27 = bitcast i32* %26 to <4 x i32>*
  %28 = load <4 x i32>, <4 x i32>* %27, align 8
  %29 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 24
  %30 = bitcast i32* %29 to <4 x i32>*
  %31 = load <4 x i32>, <4 x i32>* %30, align 8
  %32 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 28
  %33 = bitcast i32* %32 to <4 x i32>*
  %34 = load <4 x i32>, <4 x i32>* %33, align 8
  %35 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %35)
  %36 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.286", %"struct.gemmlowp::OutputPipelineExecutor.286"* %0, i64 0, i32 0, i32 0, i32 0
  %37 = load %"struct.gemmlowp::OutputStageBiasAddition.200"*, %"struct.gemmlowp::OutputStageBiasAddition.200"** %36, align 8, !noalias !619
  %38 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition.200", %"struct.gemmlowp::OutputStageBiasAddition.200"* %37, i64 0, i32 0, i32 0
  %39 = load i32*, i32** %38, align 8, !noalias !619
  %40 = sext i32 %4 to i64
  %41 = getelementptr i32, i32* %39, i64 %40
  %42 = bitcast i32* %41 to i64*
  %43 = load i64, i64* %42, align 4, !noalias !619
  %44 = getelementptr inbounds i32, i32* %41, i64 2
  %45 = bitcast i32* %44 to i64*
  %46 = load i64, i64* %45, align 4, !noalias !619
  %47 = trunc i64 %43 to i32
  %48 = lshr i64 %43, 32
  %49 = trunc i64 %48 to i32
  %50 = insertelement <4 x i32> undef, i32 %47, i32 0
  %51 = shufflevector <4 x i32> %50, <4 x i32> undef, <4 x i32> zeroinitializer
  %52 = add nsw <4 x i32> %13, %51
  %53 = add nsw <4 x i32> %16, %51
  %54 = insertelement <4 x i32> undef, i32 %49, i32 0
  %55 = shufflevector <4 x i32> %54, <4 x i32> undef, <4 x i32> zeroinitializer
  %56 = add nsw <4 x i32> %19, %55
  %57 = add nsw <4 x i32> %22, %55
  %58 = trunc i64 %46 to i32
  %59 = insertelement <4 x i32> undef, i32 %58, i32 0
  %60 = shufflevector <4 x i32> %59, <4 x i32> undef, <4 x i32> zeroinitializer
  %61 = add nsw <4 x i32> %25, %60
  %62 = add nsw <4 x i32> %28, %60
  %63 = lshr i64 %46, 32
  %64 = trunc i64 %63 to i32
  %65 = insertelement <4 x i32> undef, i32 %64, i32 0
  %66 = shufflevector <4 x i32> %65, <4 x i32> undef, <4 x i32> zeroinitializer
  %67 = add nsw <4 x i32> %31, %66
  %68 = add nsw <4 x i32> %34, %66
  %69 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.286", %"struct.gemmlowp::OutputPipelineExecutor.286"* %0, i64 0, i32 0, i32 1
  %70 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %8 to <4 x i32>*
  store <4 x i32> %52, <4 x i32>* %70, align 16, !noalias !624
  %71 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %8, i64 0, i32 0, i32 0, i64 4
  %72 = bitcast i32* %71 to <4 x i32>*
  store <4 x i32> %53, <4 x i32>* %72, align 16, !noalias !624
  %73 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %8, i64 0, i32 0, i32 0, i64 8
  %74 = bitcast i32* %73 to <4 x i32>*
  store <4 x i32> %56, <4 x i32>* %74, align 16, !noalias !624
  %75 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %8, i64 0, i32 0, i32 0, i64 12
  %76 = bitcast i32* %75 to <4 x i32>*
  store <4 x i32> %57, <4 x i32>* %76, align 16, !noalias !624
  %77 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %8, i64 0, i32 0, i32 0, i64 16
  %78 = bitcast i32* %77 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %78, align 16, !noalias !624
  %79 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %8, i64 0, i32 0, i32 0, i64 20
  %80 = bitcast i32* %79 to <4 x i32>*
  store <4 x i32> %62, <4 x i32>* %80, align 16, !noalias !624
  %81 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %8, i64 0, i32 0, i32 0, i64 24
  %82 = bitcast i32* %81 to <4 x i32>*
  store <4 x i32> %67, <4 x i32>* %82, align 16, !noalias !624
  %83 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %8, i64 0, i32 0, i32 0, i64 28
  %84 = bitcast i32* %83 to <4 x i32>*
  store <4 x i32> %68, <4 x i32>* %84, align 16, !noalias !624
  call void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi1ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.310"* nonnull sret %10, %"struct.gemmlowp::OutputPipelineEvalImpl.289"* %69, %"struct.gemmlowp::RegisterBlock.302"* nonnull byval(%"struct.gemmlowp::RegisterBlock.302") align 8 %8, i32 %3, i32 %4) #19
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %35)
  %85 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %9, i64 0, i32 0, i32 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %85)
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %85, i8* nonnull align 1 %11, i64 32, i1 false)
  %86 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %2, i64 0, i32 0
  %87 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %2, i64 0, i32 3
  %88 = sext i32 %6 to i64
  %89 = sext i32 %5 to i64
  %90 = add nsw i64 %88, 1
  %91 = add nsw i64 %88, 2
  %92 = add nsw i64 %88, 3
  br label %93

93:                                               ; preds = %93, %7
  %94 = phi i64 [ 0, %7 ], [ %131, %93 ]
  %95 = add nsw i64 %94, %89
  %96 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %9, i64 0, i32 0, i32 0, i64 %94
  %97 = load i8, i8* %96, align 1
  %98 = load i8*, i8** %86, align 8
  %99 = getelementptr inbounds i8, i8* %98, i64 %95
  %100 = load i32, i32* %87, align 8
  %101 = sext i32 %100 to i64
  %102 = mul nsw i64 %101, %88
  %103 = getelementptr inbounds i8, i8* %99, i64 %102
  store i8 %97, i8* %103, align 1
  %104 = add nuw nsw i64 %94, 8
  %105 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %9, i64 0, i32 0, i32 0, i64 %104
  %106 = load i8, i8* %105, align 1
  %107 = load i8*, i8** %86, align 8
  %108 = getelementptr inbounds i8, i8* %107, i64 %95
  %109 = load i32, i32* %87, align 8
  %110 = sext i32 %109 to i64
  %111 = mul nsw i64 %90, %110
  %112 = getelementptr inbounds i8, i8* %108, i64 %111
  store i8 %106, i8* %112, align 1
  %113 = add nuw nsw i64 %94, 16
  %114 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %9, i64 0, i32 0, i32 0, i64 %113
  %115 = load i8, i8* %114, align 1
  %116 = load i8*, i8** %86, align 8
  %117 = getelementptr inbounds i8, i8* %116, i64 %95
  %118 = load i32, i32* %87, align 8
  %119 = sext i32 %118 to i64
  %120 = mul nsw i64 %91, %119
  %121 = getelementptr inbounds i8, i8* %117, i64 %120
  store i8 %115, i8* %121, align 1
  %122 = add nuw nsw i64 %94, 24
  %123 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %9, i64 0, i32 0, i32 0, i64 %122
  %124 = load i8, i8* %123, align 1
  %125 = load i8*, i8** %86, align 8
  %126 = getelementptr inbounds i8, i8* %125, i64 %95
  %127 = load i32, i32* %87, align 8
  %128 = sext i32 %127 to i64
  %129 = mul nsw i64 %92, %128
  %130 = getelementptr inbounds i8, i8* %126, i64 %129
  store i8 %124, i8* %130, align 1
  %131 = add nuw nsw i64 %94, 1
  %132 = icmp eq i64 %131, 8
  br i1 %132, label %133, label %93

133:                                              ; preds = %93
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %85)
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %11) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi1ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.310"* noalias sret, %"struct.gemmlowp::OutputPipelineEvalImpl.289"*, %"struct.gemmlowp::RegisterBlock.302"* byval(%"struct.gemmlowp::RegisterBlock.302") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %6 = alloca %"struct.gemmlowp::RegisterBuffer.303", align 16
  %7 = alloca %"struct.gemmlowp::RegisterBuffer.303", align 16
  %8 = alloca [32 x i32], align 8
  %9 = alloca %"struct.gemmlowp::RegisterBuffer.303", align 8
  %10 = alloca %"struct.gemmlowp::RegisterBuffer.303", align 4
  %11 = alloca [32 x i32], align 4
  %12 = bitcast [32 x i32]* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %12)
  %13 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %2 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %12, i8 -86, i64 128, i1 false), !alias.scope !625
  %14 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %14) #19, !noalias !625
  %15 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %15) #19, !noalias !625
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %15, i8* nonnull align 8 %13, i64 128, i1 false)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %14, i8 -86, i64 128, i1 false) #19, !alias.scope !628, !noalias !625
  %16 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.289", %"struct.gemmlowp::OutputPipelineEvalImpl.289"* %1, i64 0, i32 0, i32 0, i32 0
  %17 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %16, align 8, !noalias !631
  %18 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %17, i64 0, i32 2
  %19 = load i32, i32* %18, align 4, !noalias !631
  %20 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.289", %"struct.gemmlowp::OutputPipelineEvalImpl.289"* %1, i64 0, i32 0, i32 0, i32 1
  %21 = load i32, i32* %20, align 8, !noalias !631
  %22 = shl i32 1, %21
  %23 = sext i32 %22 to i64
  %24 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %17, i64 0, i32 0
  %25 = load i32, i32* %24, align 4, !noalias !631
  %26 = sext i32 %25 to i64
  %27 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.289", %"struct.gemmlowp::OutputPipelineEvalImpl.289"* %1, i64 0, i32 0, i32 0, i32 2
  %28 = load i32, i32* %27, align 4, !noalias !631
  %29 = zext i32 %28 to i64
  %30 = shl nsw i64 -1, %29
  %31 = trunc i64 %30 to i32
  %32 = xor i32 %31, -1
  %33 = ashr i32 %32, 1
  %34 = icmp ne i32 %25, -2147483648
  br label %35

35:                                               ; preds = %56, %5
  %36 = phi i64 [ 0, %5 ], [ %67, %56 ]
  %37 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %9, i64 0, i32 0, i64 %36
  %38 = load i32, i32* %37, align 4, !noalias !631
  %39 = sext i32 %38 to i64
  %40 = mul nsw i64 %39, %23
  %41 = icmp slt i64 %40, 2147483647
  %42 = select i1 %41, i64 %40, i64 2147483647
  %43 = icmp sgt i64 %42, -2147483648
  %44 = select i1 %43, i64 %42, i64 -2147483648
  %45 = trunc i64 %44 to i32
  %46 = icmp ne i32 %25, %45
  %47 = or i1 %34, %46
  br i1 %47, label %48, label %56

48:                                               ; preds = %35
  %49 = select i1 %46, i64 %26, i64 %44
  %50 = mul nsw i64 %49, %44
  %51 = icmp sgt i64 %50, -1
  %52 = select i1 %51, i64 1073741824, i64 -1073741823
  %53 = add nsw i64 %52, %50
  %54 = sdiv i64 %53, 2147483648
  %55 = trunc i64 %54 to i32
  br label %56

56:                                               ; preds = %48, %35
  %57 = phi i32 [ %55, %48 ], [ 2147483647, %35 ]
  %58 = and i32 %57, %32
  %59 = lshr i32 %57, 31
  %60 = add nsw i32 %59, %33
  %61 = ashr i32 %57, %28
  %62 = icmp sgt i32 %58, %60
  %63 = zext i1 %62 to i32
  %64 = add i32 %61, %19
  %65 = add i32 %64, %63
  %66 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %10, i64 0, i32 0, i64 %36
  store i32 %65, i32* %66, align 4, !alias.scope !628, !noalias !625
  %67 = add nuw nsw i64 %36, 1
  %68 = icmp eq i64 %67, 32
  br i1 %68, label %69, label %35

69:                                               ; preds = %56
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %15) #19, !noalias !625
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 4 %12, i8* nonnull align 4 %14, i64 128, i1 false)
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %14) #19, !noalias !625
  %70 = bitcast [32 x i32]* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %70) #19, !noalias !632
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %70, i8 -86, i64 128, i1 false) #19, !alias.scope !635, !noalias !632
  %71 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %71) #19, !noalias !638
  %72 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %72) #19, !noalias !638
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %72, i8* nonnull align 4 %12, i64 128, i1 false)
  %73 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.289", %"struct.gemmlowp::OutputPipelineEvalImpl.289"* %1, i64 0, i32 1, i32 0, i32 0, i32 0
  %74 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %73, align 8, !noalias !639
  %75 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %74, i64 0, i32 0
  %76 = load i32, i32* %75, align 4, !noalias !639
  %77 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %74, i64 0, i32 1
  %78 = load i32, i32* %77, align 4, !noalias !639
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %71, i8 -86, i64 128, i1 false) #19, !alias.scope !642, !noalias !638
  %79 = insertelement <4 x i32> undef, i32 %76, i32 0
  %80 = shufflevector <4 x i32> %79, <4 x i32> undef, <4 x i32> zeroinitializer
  %81 = insertelement <4 x i32> undef, i32 %78, i32 0
  %82 = shufflevector <4 x i32> %81, <4 x i32> undef, <4 x i32> zeroinitializer
  %83 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %6 to <4 x i32>*
  %84 = load <4 x i32>, <4 x i32>* %83, align 16, !noalias !639
  %85 = icmp slt <4 x i32> %84, %80
  %86 = select <4 x i1> %85, <4 x i32> %80, <4 x i32> %84
  %87 = icmp slt <4 x i32> %82, %86
  %88 = select <4 x i1> %87, <4 x i32> %82, <4 x i32> %86
  %89 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %7 to <4 x i32>*
  store <4 x i32> %88, <4 x i32>* %89, align 16, !alias.scope !642, !noalias !638
  %90 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 4
  %91 = bitcast i32* %90 to <4 x i32>*
  %92 = load <4 x i32>, <4 x i32>* %91, align 16, !noalias !639
  %93 = icmp slt <4 x i32> %92, %80
  %94 = select <4 x i1> %93, <4 x i32> %80, <4 x i32> %92
  %95 = icmp slt <4 x i32> %82, %94
  %96 = select <4 x i1> %95, <4 x i32> %82, <4 x i32> %94
  %97 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %7, i64 0, i32 0, i64 4
  %98 = bitcast i32* %97 to <4 x i32>*
  store <4 x i32> %96, <4 x i32>* %98, align 16, !alias.scope !642, !noalias !638
  %99 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 8
  %100 = bitcast i32* %99 to <4 x i32>*
  %101 = load <4 x i32>, <4 x i32>* %100, align 16, !noalias !639
  %102 = icmp slt <4 x i32> %101, %80
  %103 = select <4 x i1> %102, <4 x i32> %80, <4 x i32> %101
  %104 = icmp slt <4 x i32> %82, %103
  %105 = select <4 x i1> %104, <4 x i32> %82, <4 x i32> %103
  %106 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %7, i64 0, i32 0, i64 8
  %107 = bitcast i32* %106 to <4 x i32>*
  store <4 x i32> %105, <4 x i32>* %107, align 16, !alias.scope !642, !noalias !638
  %108 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 12
  %109 = bitcast i32* %108 to <4 x i32>*
  %110 = load <4 x i32>, <4 x i32>* %109, align 16, !noalias !639
  %111 = icmp slt <4 x i32> %110, %80
  %112 = select <4 x i1> %111, <4 x i32> %80, <4 x i32> %110
  %113 = icmp slt <4 x i32> %82, %112
  %114 = select <4 x i1> %113, <4 x i32> %82, <4 x i32> %112
  %115 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %7, i64 0, i32 0, i64 12
  %116 = bitcast i32* %115 to <4 x i32>*
  store <4 x i32> %114, <4 x i32>* %116, align 16, !alias.scope !642, !noalias !638
  %117 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 16
  %118 = bitcast i32* %117 to <4 x i32>*
  %119 = load <4 x i32>, <4 x i32>* %118, align 16, !noalias !639
  %120 = icmp slt <4 x i32> %119, %80
  %121 = select <4 x i1> %120, <4 x i32> %80, <4 x i32> %119
  %122 = icmp slt <4 x i32> %82, %121
  %123 = select <4 x i1> %122, <4 x i32> %82, <4 x i32> %121
  %124 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %7, i64 0, i32 0, i64 16
  %125 = bitcast i32* %124 to <4 x i32>*
  store <4 x i32> %123, <4 x i32>* %125, align 16, !alias.scope !642, !noalias !638
  %126 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 20
  %127 = bitcast i32* %126 to <4 x i32>*
  %128 = load <4 x i32>, <4 x i32>* %127, align 16, !noalias !639
  %129 = icmp slt <4 x i32> %128, %80
  %130 = select <4 x i1> %129, <4 x i32> %80, <4 x i32> %128
  %131 = icmp slt <4 x i32> %82, %130
  %132 = select <4 x i1> %131, <4 x i32> %82, <4 x i32> %130
  %133 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %7, i64 0, i32 0, i64 20
  %134 = bitcast i32* %133 to <4 x i32>*
  store <4 x i32> %132, <4 x i32>* %134, align 16, !alias.scope !642, !noalias !638
  %135 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 24
  %136 = bitcast i32* %135 to <4 x i32>*
  %137 = load <4 x i32>, <4 x i32>* %136, align 16, !noalias !639
  %138 = icmp slt <4 x i32> %137, %80
  %139 = select <4 x i1> %138, <4 x i32> %80, <4 x i32> %137
  %140 = icmp slt <4 x i32> %82, %139
  %141 = select <4 x i1> %140, <4 x i32> %82, <4 x i32> %139
  %142 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %7, i64 0, i32 0, i64 24
  %143 = bitcast i32* %142 to <4 x i32>*
  store <4 x i32> %141, <4 x i32>* %143, align 16, !alias.scope !642, !noalias !638
  %144 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 28
  %145 = bitcast i32* %144 to <4 x i32>*
  %146 = load <4 x i32>, <4 x i32>* %145, align 16, !noalias !639
  %147 = icmp slt <4 x i32> %146, %80
  %148 = select <4 x i1> %147, <4 x i32> %80, <4 x i32> %146
  %149 = icmp slt <4 x i32> %82, %148
  %150 = select <4 x i1> %149, <4 x i32> %82, <4 x i32> %148
  %151 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %7, i64 0, i32 0, i64 28
  %152 = bitcast i32* %151 to <4 x i32>*
  store <4 x i32> %150, <4 x i32>* %152, align 16, !alias.scope !642, !noalias !638
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %72) #19, !noalias !638
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %70, i8* nonnull align 16 %71, i64 128, i1 false) #19, !noalias !632
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %71) #19, !noalias !638
  %153 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.289", %"struct.gemmlowp::OutputPipelineEvalImpl.289"* %1, i64 0, i32 1, i32 1
  %154 = bitcast [32 x i32]* %8 to %"struct.gemmlowp::RegisterBlock.302"*
  tail call void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi3ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.310"* sret %0, %"struct.gemmlowp::OutputPipelineEvalImpl.295"* %153, %"struct.gemmlowp::RegisterBlock.302"* nonnull byval(%"struct.gemmlowp::RegisterBlock.302") align 8 %154, i32 %3, i32 %4) #19
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %70) #19, !noalias !632
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %12)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi3ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.310"* noalias sret, %"struct.gemmlowp::OutputPipelineEvalImpl.295"*, %"struct.gemmlowp::RegisterBlock.302"* byval(%"struct.gemmlowp::RegisterBlock.302") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %6 = alloca %"struct.gemmlowp::RegisterBuffer.303", align 16
  %7 = alloca %"struct.gemmlowp::RegisterBuffer.311", align 16
  %8 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %2 to i8*
  %9 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.311", %"struct.gemmlowp::RegisterBuffer.311"* %7, i64 0, i32 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %9) #19, !noalias !643
  %10 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %10) #19, !noalias !643
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %10, i8* nonnull align 8 %8, i64 128, i1 false)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 32, i1 false) #19, !alias.scope !646, !noalias !643
  %11 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %6 to <4 x i32>*
  %12 = load <4 x i32>, <4 x i32>* %11, align 16, !noalias !649
  %13 = icmp sgt <4 x i32> %12, zeroinitializer
  %14 = select <4 x i1> %13, <4 x i32> %12, <4 x i32> zeroinitializer
  %15 = icmp slt <4 x i32> %14, <i32 255, i32 255, i32 255, i32 255>
  %16 = select <4 x i1> %15, <4 x i32> %14, <4 x i32> <i32 255, i32 255, i32 255, i32 255>
  %17 = trunc <4 x i32> %16 to <4 x i8>
  %18 = bitcast %"struct.gemmlowp::RegisterBuffer.311"* %7 to <4 x i8>*
  store <4 x i8> %17, <4 x i8>* %18, align 16, !alias.scope !646, !noalias !643
  %19 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 4
  %20 = bitcast i32* %19 to <4 x i32>*
  %21 = load <4 x i32>, <4 x i32>* %20, align 16, !noalias !649
  %22 = icmp sgt <4 x i32> %21, zeroinitializer
  %23 = select <4 x i1> %22, <4 x i32> %21, <4 x i32> zeroinitializer
  %24 = icmp slt <4 x i32> %23, <i32 255, i32 255, i32 255, i32 255>
  %25 = select <4 x i1> %24, <4 x i32> %23, <4 x i32> <i32 255, i32 255, i32 255, i32 255>
  %26 = trunc <4 x i32> %25 to <4 x i8>
  %27 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.311", %"struct.gemmlowp::RegisterBuffer.311"* %7, i64 0, i32 0, i64 4
  %28 = bitcast i8* %27 to <4 x i8>*
  store <4 x i8> %26, <4 x i8>* %28, align 4, !alias.scope !646, !noalias !643
  %29 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 8
  %30 = bitcast i32* %29 to <4 x i32>*
  %31 = load <4 x i32>, <4 x i32>* %30, align 16, !noalias !649
  %32 = icmp sgt <4 x i32> %31, zeroinitializer
  %33 = select <4 x i1> %32, <4 x i32> %31, <4 x i32> zeroinitializer
  %34 = icmp slt <4 x i32> %33, <i32 255, i32 255, i32 255, i32 255>
  %35 = select <4 x i1> %34, <4 x i32> %33, <4 x i32> <i32 255, i32 255, i32 255, i32 255>
  %36 = trunc <4 x i32> %35 to <4 x i8>
  %37 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.311", %"struct.gemmlowp::RegisterBuffer.311"* %7, i64 0, i32 0, i64 8
  %38 = bitcast i8* %37 to <4 x i8>*
  store <4 x i8> %36, <4 x i8>* %38, align 8, !alias.scope !646, !noalias !643
  %39 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 12
  %40 = bitcast i32* %39 to <4 x i32>*
  %41 = load <4 x i32>, <4 x i32>* %40, align 16, !noalias !649
  %42 = icmp sgt <4 x i32> %41, zeroinitializer
  %43 = select <4 x i1> %42, <4 x i32> %41, <4 x i32> zeroinitializer
  %44 = icmp slt <4 x i32> %43, <i32 255, i32 255, i32 255, i32 255>
  %45 = select <4 x i1> %44, <4 x i32> %43, <4 x i32> <i32 255, i32 255, i32 255, i32 255>
  %46 = trunc <4 x i32> %45 to <4 x i8>
  %47 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.311", %"struct.gemmlowp::RegisterBuffer.311"* %7, i64 0, i32 0, i64 12
  %48 = bitcast i8* %47 to <4 x i8>*
  store <4 x i8> %46, <4 x i8>* %48, align 4, !alias.scope !646, !noalias !643
  %49 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 16
  %50 = bitcast i32* %49 to <4 x i32>*
  %51 = load <4 x i32>, <4 x i32>* %50, align 16, !noalias !649
  %52 = icmp sgt <4 x i32> %51, zeroinitializer
  %53 = select <4 x i1> %52, <4 x i32> %51, <4 x i32> zeroinitializer
  %54 = icmp slt <4 x i32> %53, <i32 255, i32 255, i32 255, i32 255>
  %55 = select <4 x i1> %54, <4 x i32> %53, <4 x i32> <i32 255, i32 255, i32 255, i32 255>
  %56 = trunc <4 x i32> %55 to <4 x i8>
  %57 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.311", %"struct.gemmlowp::RegisterBuffer.311"* %7, i64 0, i32 0, i64 16
  %58 = bitcast i8* %57 to <4 x i8>*
  store <4 x i8> %56, <4 x i8>* %58, align 16, !alias.scope !646, !noalias !643
  %59 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 20
  %60 = bitcast i32* %59 to <4 x i32>*
  %61 = load <4 x i32>, <4 x i32>* %60, align 16, !noalias !649
  %62 = icmp sgt <4 x i32> %61, zeroinitializer
  %63 = select <4 x i1> %62, <4 x i32> %61, <4 x i32> zeroinitializer
  %64 = icmp slt <4 x i32> %63, <i32 255, i32 255, i32 255, i32 255>
  %65 = select <4 x i1> %64, <4 x i32> %63, <4 x i32> <i32 255, i32 255, i32 255, i32 255>
  %66 = trunc <4 x i32> %65 to <4 x i8>
  %67 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.311", %"struct.gemmlowp::RegisterBuffer.311"* %7, i64 0, i32 0, i64 20
  %68 = bitcast i8* %67 to <4 x i8>*
  store <4 x i8> %66, <4 x i8>* %68, align 4, !alias.scope !646, !noalias !643
  %69 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 24
  %70 = bitcast i32* %69 to <4 x i32>*
  %71 = load <4 x i32>, <4 x i32>* %70, align 16, !noalias !649
  %72 = icmp sgt <4 x i32> %71, zeroinitializer
  %73 = select <4 x i1> %72, <4 x i32> %71, <4 x i32> zeroinitializer
  %74 = icmp slt <4 x i32> %73, <i32 255, i32 255, i32 255, i32 255>
  %75 = select <4 x i1> %74, <4 x i32> %73, <4 x i32> <i32 255, i32 255, i32 255, i32 255>
  %76 = trunc <4 x i32> %75 to <4 x i8>
  %77 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.311", %"struct.gemmlowp::RegisterBuffer.311"* %7, i64 0, i32 0, i64 24
  %78 = bitcast i8* %77 to <4 x i8>*
  store <4 x i8> %76, <4 x i8>* %78, align 8, !alias.scope !646, !noalias !643
  %79 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 28
  %80 = bitcast i32* %79 to <4 x i32>*
  %81 = load <4 x i32>, <4 x i32>* %80, align 16, !noalias !649
  %82 = icmp sgt <4 x i32> %81, zeroinitializer
  %83 = select <4 x i1> %82, <4 x i32> %81, <4 x i32> zeroinitializer
  %84 = icmp slt <4 x i32> %83, <i32 255, i32 255, i32 255, i32 255>
  %85 = select <4 x i1> %84, <4 x i32> %83, <4 x i32> <i32 255, i32 255, i32 255, i32 255>
  %86 = trunc <4 x i32> %85 to <4 x i8>
  %87 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.311", %"struct.gemmlowp::RegisterBuffer.311"* %7, i64 0, i32 0, i64 28
  %88 = bitcast i8* %87 to <4 x i8>*
  store <4 x i8> %86, <4 x i8>* %88, align 4, !alias.scope !646, !noalias !643
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %10) #19, !noalias !643
  %89 = bitcast %"struct.gemmlowp::RegisterBuffer.311"* %7 to <16 x i8>*
  %90 = load <16 x i8>, <16 x i8>* %89, align 16
  %91 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.311", %"struct.gemmlowp::RegisterBuffer.311"* %7, i64 0, i32 0, i64 16
  %92 = bitcast i8* %91 to <16 x i8>*
  %93 = load <16 x i8>, <16 x i8>* %92, align 16
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %9) #19, !noalias !643
  %94 = bitcast %"struct.gemmlowp::RegisterBlock.310"* %0 to <16 x i8>*
  store <16 x i8> %90, <16 x i8>* %94, align 1
  %95 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %0, i64 0, i32 0, i32 0, i64 16
  %96 = bitcast i8* %95 to <16 x i8>*
  store <16 x i8> %93, <16 x i8>* %96, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp20StoreFinalOutputImplINS_13RegisterBlockIhLi8ELi8EEENS_9MatrixMapIhLNS_8MapOrderE1EEEE3RunERKS2_PS5_ii(%"struct.gemmlowp::RegisterBlock"* dereferenceable(64), %"class.gemmlowp::MatrixMap.195"*, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %5 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %1, i64 0, i32 0
  %6 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %1, i64 0, i32 3
  %7 = sext i32 %3 to i64
  %8 = sext i32 %2 to i64
  %9 = add nsw i64 %7, 1
  %10 = add nsw i64 %7, 2
  %11 = add nsw i64 %7, 3
  %12 = add nsw i64 %7, 4
  %13 = add nsw i64 %7, 5
  %14 = add nsw i64 %7, 6
  %15 = add nsw i64 %7, 7
  br label %16

16:                                               ; preds = %16, %4
  %17 = phi i64 [ 0, %4 ], [ %90, %16 ]
  %18 = add nsw i64 %17, %8
  %19 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock", %"struct.gemmlowp::RegisterBlock"* %0, i64 0, i32 0, i32 0, i64 %17
  %20 = load i8, i8* %19, align 1
  %21 = load i8*, i8** %5, align 8
  %22 = load i32, i32* %6, align 8
  %23 = sext i32 %22 to i64
  %24 = mul nsw i64 %18, %23
  %25 = getelementptr inbounds i8, i8* %21, i64 %7
  %26 = getelementptr inbounds i8, i8* %25, i64 %24
  store i8 %20, i8* %26, align 1
  %27 = add nuw nsw i64 %17, 8
  %28 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock", %"struct.gemmlowp::RegisterBlock"* %0, i64 0, i32 0, i32 0, i64 %27
  %29 = load i8, i8* %28, align 1
  %30 = load i8*, i8** %5, align 8
  %31 = load i32, i32* %6, align 8
  %32 = sext i32 %31 to i64
  %33 = mul nsw i64 %18, %32
  %34 = getelementptr inbounds i8, i8* %30, i64 %9
  %35 = getelementptr inbounds i8, i8* %34, i64 %33
  store i8 %29, i8* %35, align 1
  %36 = add nuw nsw i64 %17, 16
  %37 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock", %"struct.gemmlowp::RegisterBlock"* %0, i64 0, i32 0, i32 0, i64 %36
  %38 = load i8, i8* %37, align 1
  %39 = load i8*, i8** %5, align 8
  %40 = load i32, i32* %6, align 8
  %41 = sext i32 %40 to i64
  %42 = mul nsw i64 %18, %41
  %43 = getelementptr inbounds i8, i8* %39, i64 %10
  %44 = getelementptr inbounds i8, i8* %43, i64 %42
  store i8 %38, i8* %44, align 1
  %45 = add nuw nsw i64 %17, 24
  %46 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock", %"struct.gemmlowp::RegisterBlock"* %0, i64 0, i32 0, i32 0, i64 %45
  %47 = load i8, i8* %46, align 1
  %48 = load i8*, i8** %5, align 8
  %49 = load i32, i32* %6, align 8
  %50 = sext i32 %49 to i64
  %51 = mul nsw i64 %18, %50
  %52 = getelementptr inbounds i8, i8* %48, i64 %11
  %53 = getelementptr inbounds i8, i8* %52, i64 %51
  store i8 %47, i8* %53, align 1
  %54 = add nuw nsw i64 %17, 32
  %55 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock", %"struct.gemmlowp::RegisterBlock"* %0, i64 0, i32 0, i32 0, i64 %54
  %56 = load i8, i8* %55, align 1
  %57 = load i8*, i8** %5, align 8
  %58 = load i32, i32* %6, align 8
  %59 = sext i32 %58 to i64
  %60 = mul nsw i64 %18, %59
  %61 = getelementptr inbounds i8, i8* %57, i64 %12
  %62 = getelementptr inbounds i8, i8* %61, i64 %60
  store i8 %56, i8* %62, align 1
  %63 = add nuw nsw i64 %17, 40
  %64 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock", %"struct.gemmlowp::RegisterBlock"* %0, i64 0, i32 0, i32 0, i64 %63
  %65 = load i8, i8* %64, align 1
  %66 = load i8*, i8** %5, align 8
  %67 = load i32, i32* %6, align 8
  %68 = sext i32 %67 to i64
  %69 = mul nsw i64 %18, %68
  %70 = getelementptr inbounds i8, i8* %66, i64 %13
  %71 = getelementptr inbounds i8, i8* %70, i64 %69
  store i8 %65, i8* %71, align 1
  %72 = add nuw nsw i64 %17, 48
  %73 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock", %"struct.gemmlowp::RegisterBlock"* %0, i64 0, i32 0, i32 0, i64 %72
  %74 = load i8, i8* %73, align 1
  %75 = load i8*, i8** %5, align 8
  %76 = load i32, i32* %6, align 8
  %77 = sext i32 %76 to i64
  %78 = mul nsw i64 %18, %77
  %79 = getelementptr inbounds i8, i8* %75, i64 %14
  %80 = getelementptr inbounds i8, i8* %79, i64 %78
  store i8 %74, i8* %80, align 1
  %81 = add nuw nsw i64 %17, 56
  %82 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock", %"struct.gemmlowp::RegisterBlock"* %0, i64 0, i32 0, i32 0, i64 %81
  %83 = load i8, i8* %82, align 1
  %84 = load i8*, i8** %5, align 8
  %85 = load i32, i32* %6, align 8
  %86 = sext i32 %85 to i64
  %87 = mul nsw i64 %18, %86
  %88 = getelementptr inbounds i8, i8* %84, i64 %15
  %89 = getelementptr inbounds i8, i8* %88, i64 %87
  store i8 %83, i8* %89, align 1
  %90 = add nuw nsw i64 %17, 1
  %91 = icmp eq i64 %90, 8
  br i1 %91, label %92, label %16

92:                                               ; preds = %16
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi0ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.271"*, %"struct.gemmlowp::RegisterBlock.312"* byval(%"struct.gemmlowp::RegisterBlock.312") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %5 = alloca %"struct.gemmlowp::RegisterBuffer.313", align 16
  %6 = alloca %"struct.gemmlowp::RegisterBuffer.313", align 8
  %7 = alloca [16 x i32], align 8
  %8 = bitcast %"struct.gemmlowp::RegisterBlock.312"* %1 to <4 x i32>*
  %9 = load <4 x i32>, <4 x i32>* %8, align 8
  %10 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 4
  %11 = bitcast i32* %10 to <4 x i32>*
  %12 = load <4 x i32>, <4 x i32>* %11, align 8
  %13 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 8
  %14 = bitcast i32* %13 to <4 x i32>*
  %15 = load <4 x i32>, <4 x i32>* %14, align 8
  %16 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 12
  %17 = bitcast i32* %16 to <4 x i32>*
  %18 = load <4 x i32>, <4 x i32>* %17, align 8
  %19 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.271", %"struct.gemmlowp::OutputPipelineEvalImpl.271"* %0, i64 0, i32 0, i32 0
  %20 = load %"struct.gemmlowp::OutputStageBiasAddition.200"*, %"struct.gemmlowp::OutputStageBiasAddition.200"** %19, align 8, !noalias !650
  %21 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition.200", %"struct.gemmlowp::OutputStageBiasAddition.200"* %20, i64 0, i32 0, i32 0
  %22 = load i32*, i32** %21, align 8, !noalias !650
  %23 = sext i32 %3 to i64
  %24 = getelementptr i32, i32* %22, i64 %23
  %25 = bitcast i32* %24 to i64*
  %26 = load i64, i64* %25, align 4, !noalias !650
  %27 = getelementptr inbounds i32, i32* %24, i64 2
  %28 = bitcast i32* %27 to i64*
  %29 = load i64, i64* %28, align 4, !noalias !650
  %30 = trunc i64 %26 to i32
  %31 = lshr i64 %26, 32
  %32 = trunc i64 %31 to i32
  %33 = insertelement <4 x i32> undef, i32 %30, i32 0
  %34 = shufflevector <4 x i32> %33, <4 x i32> undef, <4 x i32> zeroinitializer
  %35 = add nsw <4 x i32> %9, %34
  %36 = insertelement <4 x i32> undef, i32 %32, i32 0
  %37 = shufflevector <4 x i32> %36, <4 x i32> undef, <4 x i32> zeroinitializer
  %38 = add nsw <4 x i32> %12, %37
  %39 = trunc i64 %29 to i32
  %40 = insertelement <4 x i32> undef, i32 %39, i32 0
  %41 = shufflevector <4 x i32> %40, <4 x i32> undef, <4 x i32> zeroinitializer
  %42 = add nsw <4 x i32> %15, %41
  %43 = lshr i64 %29, 32
  %44 = trunc i64 %43 to i32
  %45 = insertelement <4 x i32> undef, i32 %44, i32 0
  %46 = shufflevector <4 x i32> %45, <4 x i32> undef, <4 x i32> zeroinitializer
  %47 = add nsw <4 x i32> %18, %46
  %48 = bitcast [16 x i32]* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %48) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %48, i8 -86, i64 64, i1 false) #19, !alias.scope !653
  %49 = bitcast %"struct.gemmlowp::RegisterBuffer.313"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %49) #19, !noalias !653
  %50 = bitcast %"struct.gemmlowp::RegisterBuffer.313"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %50) #19, !noalias !653
  %51 = bitcast %"struct.gemmlowp::RegisterBuffer.313"* %5 to <4 x i32>*
  store <4 x i32> %35, <4 x i32>* %51, align 16
  %52 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %5, i64 0, i32 0, i64 4
  %53 = bitcast i32* %52 to <4 x i32>*
  store <4 x i32> %38, <4 x i32>* %53, align 16
  %54 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %5, i64 0, i32 0, i64 8
  %55 = bitcast i32* %54 to <4 x i32>*
  store <4 x i32> %42, <4 x i32>* %55, align 16
  %56 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %5, i64 0, i32 0, i64 12
  %57 = bitcast i32* %56 to <4 x i32>*
  store <4 x i32> %47, <4 x i32>* %57, align 16
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %49, i8 -86, i64 64, i1 false) #19, !alias.scope !656, !noalias !653
  %58 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.271", %"struct.gemmlowp::OutputPipelineEvalImpl.271"* %0, i64 0, i32 1, i32 0, i32 0, i32 0
  %59 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %58, align 8, !noalias !659
  %60 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %59, i64 0, i32 2
  %61 = load i32, i32* %60, align 4, !noalias !659
  %62 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.271", %"struct.gemmlowp::OutputPipelineEvalImpl.271"* %0, i64 0, i32 1, i32 0, i32 0, i32 1
  %63 = load i32, i32* %62, align 8, !noalias !659
  %64 = shl i32 1, %63
  %65 = sext i32 %64 to i64
  %66 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %59, i64 0, i32 0
  %67 = load i32, i32* %66, align 4, !noalias !659
  %68 = sext i32 %67 to i64
  %69 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.271", %"struct.gemmlowp::OutputPipelineEvalImpl.271"* %0, i64 0, i32 1, i32 0, i32 0, i32 2
  %70 = load i32, i32* %69, align 4, !noalias !659
  %71 = zext i32 %70 to i64
  %72 = shl nsw i64 -1, %71
  %73 = trunc i64 %72 to i32
  %74 = xor i32 %73, -1
  %75 = ashr i32 %74, 1
  %76 = icmp ne i32 %67, -2147483648
  %77 = extractelement <4 x i32> %35, i32 0
  br label %78

78:                                               ; preds = %111, %4
  %79 = phi i32 [ %77, %4 ], [ %113, %111 ]
  %80 = phi i64 [ 0, %4 ], [ %109, %111 ]
  %81 = sext i32 %79 to i64
  %82 = mul nsw i64 %81, %65
  %83 = icmp slt i64 %82, 2147483647
  %84 = select i1 %83, i64 %82, i64 2147483647
  %85 = icmp sgt i64 %84, -2147483648
  %86 = select i1 %85, i64 %84, i64 -2147483648
  %87 = trunc i64 %86 to i32
  %88 = icmp ne i32 %67, %87
  %89 = or i1 %76, %88
  br i1 %89, label %90, label %98

90:                                               ; preds = %78
  %91 = select i1 %88, i64 %68, i64 %86
  %92 = mul nsw i64 %91, %86
  %93 = icmp sgt i64 %92, -1
  %94 = select i1 %93, i64 1073741824, i64 -1073741823
  %95 = add nsw i64 %94, %92
  %96 = sdiv i64 %95, 2147483648
  %97 = trunc i64 %96 to i32
  br label %98

98:                                               ; preds = %90, %78
  %99 = phi i32 [ %97, %90 ], [ 2147483647, %78 ]
  %100 = and i32 %99, %74
  %101 = lshr i32 %99, 31
  %102 = add nsw i32 %101, %75
  %103 = ashr i32 %99, %70
  %104 = icmp sgt i32 %100, %102
  %105 = zext i1 %104 to i32
  %106 = add i32 %103, %61
  %107 = add i32 %106, %105
  %108 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %6, i64 0, i32 0, i64 %80
  store i32 %107, i32* %108, align 4, !alias.scope !656, !noalias !653
  %109 = add nuw nsw i64 %80, 1
  %110 = icmp eq i64 %109, 16
  br i1 %110, label %114, label %111

111:                                              ; preds = %98
  %112 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %5, i64 0, i32 0, i64 %109
  %113 = load i32, i32* %112, align 4, !noalias !659
  br label %78

114:                                              ; preds = %98
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %50) #19, !noalias !653
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %48, i8* nonnull align 8 %49, i64 64, i1 false) #19
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %49) #19, !noalias !653
  %115 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.271", %"struct.gemmlowp::OutputPipelineEvalImpl.271"* %0, i64 0, i32 1, i32 1
  %116 = bitcast [16 x i32]* %7 to %"struct.gemmlowp::RegisterBlock.312"*
  %117 = tail call { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi2ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.276"* %115, %"struct.gemmlowp::RegisterBlock.312"* nonnull byval(%"struct.gemmlowp::RegisterBlock.312") align 8 %116, i32 %2, i32 %3) #19
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %48) #19
  ret { i64, i64 } %117
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp16StoreFinalOutputINS_13RegisterBlockIhLi4ELi4EEENS_9MatrixMapIhLNS_8MapOrderE1EEEEEvT_PT0_ii(i64, i64, %"class.gemmlowp::MatrixMap.195"*, i32, i32) local_unnamed_addr #1 comdat {
  %6 = trunc i64 %0 to i8
  %7 = lshr i64 %0, 8
  %8 = trunc i64 %7 to i8
  %9 = lshr i64 %0, 16
  %10 = trunc i64 %9 to i8
  %11 = lshr i64 %0, 24
  %12 = trunc i64 %11 to i8
  %13 = lshr i64 %0, 32
  %14 = trunc i64 %13 to i8
  %15 = lshr i64 %0, 40
  %16 = trunc i64 %15 to i8
  %17 = lshr i64 %0, 48
  %18 = trunc i64 %17 to i8
  %19 = lshr i64 %0, 56
  %20 = trunc i64 %19 to i8
  %21 = trunc i64 %1 to i8
  %22 = lshr i64 %1, 8
  %23 = trunc i64 %22 to i8
  %24 = lshr i64 %1, 16
  %25 = trunc i64 %24 to i8
  %26 = lshr i64 %1, 24
  %27 = trunc i64 %26 to i8
  %28 = lshr i64 %1, 32
  %29 = trunc i64 %28 to i8
  %30 = lshr i64 %1, 40
  %31 = trunc i64 %30 to i8
  %32 = lshr i64 %1, 48
  %33 = trunc i64 %32 to i8
  %34 = lshr i64 %1, 56
  %35 = trunc i64 %34 to i8
  %36 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %2, i64 0, i32 0
  %37 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %2, i64 0, i32 3
  %38 = sext i32 %4 to i64
  %39 = sext i32 %3 to i64
  %40 = load i8*, i8** %36, align 8
  %41 = load i32, i32* %37, align 8
  %42 = sext i32 %41 to i64
  %43 = mul nsw i64 %42, %39
  %44 = getelementptr inbounds i8, i8* %40, i64 %43
  %45 = getelementptr inbounds i8, i8* %44, i64 %38
  store i8 %6, i8* %45, align 1
  %46 = add nsw i64 %38, 1
  %47 = load i8*, i8** %36, align 8
  %48 = load i32, i32* %37, align 8
  %49 = sext i32 %48 to i64
  %50 = mul nsw i64 %49, %39
  %51 = getelementptr inbounds i8, i8* %47, i64 %50
  %52 = getelementptr inbounds i8, i8* %51, i64 %46
  store i8 %14, i8* %52, align 1
  %53 = add nsw i64 %38, 2
  %54 = load i8*, i8** %36, align 8
  %55 = load i32, i32* %37, align 8
  %56 = sext i32 %55 to i64
  %57 = mul nsw i64 %56, %39
  %58 = getelementptr inbounds i8, i8* %54, i64 %57
  %59 = getelementptr inbounds i8, i8* %58, i64 %53
  store i8 %21, i8* %59, align 1
  %60 = add nsw i64 %38, 3
  %61 = load i8*, i8** %36, align 8
  %62 = load i32, i32* %37, align 8
  %63 = sext i32 %62 to i64
  %64 = mul nsw i64 %63, %39
  %65 = getelementptr inbounds i8, i8* %61, i64 %64
  %66 = getelementptr inbounds i8, i8* %65, i64 %60
  store i8 %29, i8* %66, align 1
  %67 = add nsw i64 %39, 1
  %68 = load i8*, i8** %36, align 8
  %69 = load i32, i32* %37, align 8
  %70 = sext i32 %69 to i64
  %71 = mul nsw i64 %67, %70
  %72 = getelementptr inbounds i8, i8* %68, i64 %71
  %73 = getelementptr inbounds i8, i8* %72, i64 %38
  store i8 %8, i8* %73, align 1
  %74 = load i8*, i8** %36, align 8
  %75 = load i32, i32* %37, align 8
  %76 = sext i32 %75 to i64
  %77 = mul nsw i64 %67, %76
  %78 = getelementptr inbounds i8, i8* %74, i64 %77
  %79 = getelementptr inbounds i8, i8* %78, i64 %46
  store i8 %16, i8* %79, align 1
  %80 = load i8*, i8** %36, align 8
  %81 = load i32, i32* %37, align 8
  %82 = sext i32 %81 to i64
  %83 = mul nsw i64 %67, %82
  %84 = getelementptr inbounds i8, i8* %80, i64 %83
  %85 = getelementptr inbounds i8, i8* %84, i64 %53
  store i8 %23, i8* %85, align 1
  %86 = load i8*, i8** %36, align 8
  %87 = load i32, i32* %37, align 8
  %88 = sext i32 %87 to i64
  %89 = mul nsw i64 %67, %88
  %90 = getelementptr inbounds i8, i8* %86, i64 %89
  %91 = getelementptr inbounds i8, i8* %90, i64 %60
  store i8 %31, i8* %91, align 1
  %92 = add nsw i64 %39, 2
  %93 = load i8*, i8** %36, align 8
  %94 = load i32, i32* %37, align 8
  %95 = sext i32 %94 to i64
  %96 = mul nsw i64 %92, %95
  %97 = getelementptr inbounds i8, i8* %93, i64 %96
  %98 = getelementptr inbounds i8, i8* %97, i64 %38
  store i8 %10, i8* %98, align 1
  %99 = load i8*, i8** %36, align 8
  %100 = load i32, i32* %37, align 8
  %101 = sext i32 %100 to i64
  %102 = mul nsw i64 %92, %101
  %103 = getelementptr inbounds i8, i8* %99, i64 %102
  %104 = getelementptr inbounds i8, i8* %103, i64 %46
  store i8 %18, i8* %104, align 1
  %105 = load i8*, i8** %36, align 8
  %106 = load i32, i32* %37, align 8
  %107 = sext i32 %106 to i64
  %108 = mul nsw i64 %92, %107
  %109 = getelementptr inbounds i8, i8* %105, i64 %108
  %110 = getelementptr inbounds i8, i8* %109, i64 %53
  store i8 %25, i8* %110, align 1
  %111 = load i8*, i8** %36, align 8
  %112 = load i32, i32* %37, align 8
  %113 = sext i32 %112 to i64
  %114 = mul nsw i64 %92, %113
  %115 = getelementptr inbounds i8, i8* %111, i64 %114
  %116 = getelementptr inbounds i8, i8* %115, i64 %60
  store i8 %33, i8* %116, align 1
  %117 = add nsw i64 %39, 3
  %118 = load i8*, i8** %36, align 8
  %119 = load i32, i32* %37, align 8
  %120 = sext i32 %119 to i64
  %121 = mul nsw i64 %117, %120
  %122 = getelementptr inbounds i8, i8* %118, i64 %121
  %123 = getelementptr inbounds i8, i8* %122, i64 %38
  store i8 %12, i8* %123, align 1
  %124 = load i8*, i8** %36, align 8
  %125 = load i32, i32* %37, align 8
  %126 = sext i32 %125 to i64
  %127 = mul nsw i64 %117, %126
  %128 = getelementptr inbounds i8, i8* %124, i64 %127
  %129 = getelementptr inbounds i8, i8* %128, i64 %46
  store i8 %20, i8* %129, align 1
  %130 = load i8*, i8** %36, align 8
  %131 = load i32, i32* %37, align 8
  %132 = sext i32 %131 to i64
  %133 = mul nsw i64 %117, %132
  %134 = getelementptr inbounds i8, i8* %130, i64 %133
  %135 = getelementptr inbounds i8, i8* %134, i64 %53
  store i8 %27, i8* %135, align 1
  %136 = load i8*, i8** %36, align 8
  %137 = load i32, i32* %37, align 8
  %138 = sext i32 %137 to i64
  %139 = mul nsw i64 %117, %138
  %140 = getelementptr inbounds i8, i8* %136, i64 %139
  %141 = getelementptr inbounds i8, i8* %140, i64 %60
  store i8 %35, i8* %141, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi2ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.276"*, %"struct.gemmlowp::RegisterBlock.312"* byval(%"struct.gemmlowp::RegisterBlock.312") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %5 = alloca %"struct.gemmlowp::RegisterBlock.312", align 16
  %6 = bitcast %"struct.gemmlowp::RegisterBlock.312"* %1 to <4 x i32>*
  %7 = load <4 x i32>, <4 x i32>* %6, align 8
  %8 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 4
  %9 = bitcast i32* %8 to <4 x i32>*
  %10 = load <4 x i32>, <4 x i32>* %9, align 8
  %11 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 8
  %12 = bitcast i32* %11 to <4 x i32>*
  %13 = load <4 x i32>, <4 x i32>* %12, align 8
  %14 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 12
  %15 = bitcast i32* %14 to <4 x i32>*
  %16 = load <4 x i32>, <4 x i32>* %15, align 8
  %17 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.276", %"struct.gemmlowp::OutputPipelineEvalImpl.276"* %0, i64 0, i32 0, i32 0, i32 0
  %18 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %17, align 8, !noalias !660
  %19 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %18, i64 0, i32 0
  %20 = load i32, i32* %19, align 4, !noalias !660
  %21 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %18, i64 0, i32 1
  %22 = load i32, i32* %21, align 4, !noalias !660
  %23 = insertelement <4 x i32> undef, i32 %20, i32 0
  %24 = shufflevector <4 x i32> %23, <4 x i32> undef, <4 x i32> zeroinitializer
  %25 = icmp slt <4 x i32> %7, %24
  %26 = select <4 x i1> %25, <4 x i32> %24, <4 x i32> %7
  %27 = insertelement <4 x i32> undef, i32 %22, i32 0
  %28 = shufflevector <4 x i32> %27, <4 x i32> undef, <4 x i32> zeroinitializer
  %29 = icmp slt <4 x i32> %28, %26
  %30 = select <4 x i1> %29, <4 x i32> %28, <4 x i32> %26
  %31 = icmp slt <4 x i32> %10, %24
  %32 = select <4 x i1> %31, <4 x i32> %24, <4 x i32> %10
  %33 = icmp slt <4 x i32> %28, %32
  %34 = select <4 x i1> %33, <4 x i32> %28, <4 x i32> %32
  %35 = icmp slt <4 x i32> %13, %24
  %36 = select <4 x i1> %35, <4 x i32> %24, <4 x i32> %13
  %37 = icmp slt <4 x i32> %28, %36
  %38 = select <4 x i1> %37, <4 x i32> %28, <4 x i32> %36
  %39 = icmp slt <4 x i32> %16, %24
  %40 = select <4 x i1> %39, <4 x i32> %24, <4 x i32> %16
  %41 = icmp slt <4 x i32> %28, %40
  %42 = select <4 x i1> %41, <4 x i32> %28, <4 x i32> %40
  %43 = bitcast %"struct.gemmlowp::RegisterBlock.312"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %43)
  %44 = bitcast %"struct.gemmlowp::RegisterBlock.312"* %5 to <4 x i32>*
  store <4 x i32> %30, <4 x i32>* %44, align 16
  %45 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %5, i64 0, i32 0, i32 0, i64 4
  %46 = bitcast i32* %45 to <4 x i32>*
  store <4 x i32> %34, <4 x i32>* %46, align 16
  %47 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %5, i64 0, i32 0, i32 0, i64 8
  %48 = bitcast i32* %47 to <4 x i32>*
  store <4 x i32> %38, <4 x i32>* %48, align 16
  %49 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %5, i64 0, i32 0, i32 0, i64 12
  %50 = bitcast i32* %49 to <4 x i32>*
  store <4 x i32> %42, <4 x i32>* %50, align 16
  %51 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.276", %"struct.gemmlowp::OutputPipelineEvalImpl.276"* %0, i64 0, i32 1, i32 0
  %52 = tail call { i64, i64 } @_ZNK8gemmlowp19OutputStageEvalImplINS_32OutputStageSaturatingCastToUint8ENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii(%"struct.gemmlowp::OutputStageEvalImpl.280"* %51, %"struct.gemmlowp::RegisterBlock.312"* nonnull byval(%"struct.gemmlowp::RegisterBlock.312") align 8 %5, i32 %2, i32 %3) #19
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %43)
  ret { i64, i64 } %52
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden { i64, i64 } @_ZNK8gemmlowp19OutputStageEvalImplINS_32OutputStageSaturatingCastToUint8ENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii(%"struct.gemmlowp::OutputStageEvalImpl.280"*, %"struct.gemmlowp::RegisterBlock.312"* byval(%"struct.gemmlowp::RegisterBlock.312") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %5 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 0
  %6 = load i32, i32* %5, align 8
  %7 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 1
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 2
  %10 = load i32, i32* %9, align 8
  %11 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 3
  %12 = load i32, i32* %11, align 4
  %13 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 4
  %14 = bitcast i32* %13 to <4 x i32>*
  %15 = load <4 x i32>, <4 x i32>* %14, align 8
  %16 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 8
  %17 = load i32, i32* %16, align 8
  %18 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 9
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 10
  %21 = load i32, i32* %20, align 8
  %22 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 11
  %23 = load i32, i32* %22, align 4
  %24 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 12
  %25 = load i32, i32* %24, align 8
  %26 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 13
  %27 = load i32, i32* %26, align 4
  %28 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 14
  %29 = load i32, i32* %28, align 8
  %30 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 15
  %31 = load i32, i32* %30, align 4
  %32 = icmp sgt i32 %6, 0
  %33 = select i1 %32, i32 %6, i32 0
  %34 = icmp slt i32 %33, 255
  %35 = select i1 %34, i32 %33, i32 255
  %36 = icmp sgt i32 %8, 0
  %37 = select i1 %36, i32 %8, i32 0
  %38 = icmp slt i32 %37, 255
  %39 = select i1 %38, i32 %37, i32 255
  %40 = icmp sgt i32 %10, 0
  %41 = select i1 %40, i32 %10, i32 0
  %42 = icmp slt i32 %41, 255
  %43 = select i1 %42, i32 %41, i32 255
  %44 = icmp sgt i32 %12, 0
  %45 = select i1 %44, i32 %12, i32 0
  %46 = icmp slt i32 %45, 255
  %47 = select i1 %46, i32 %45, i32 255
  %48 = icmp sgt <4 x i32> %15, zeroinitializer
  %49 = select <4 x i1> %48, <4 x i32> %15, <4 x i32> zeroinitializer
  %50 = icmp slt <4 x i32> %49, <i32 255, i32 255, i32 255, i32 255>
  %51 = select <4 x i1> %50, <4 x i32> %49, <4 x i32> <i32 255, i32 255, i32 255, i32 255>
  %52 = zext <4 x i32> %51 to <4 x i64>
  %53 = icmp sgt i32 %17, 0
  %54 = select i1 %53, i32 %17, i32 0
  %55 = icmp slt i32 %54, 255
  %56 = select i1 %55, i32 %54, i32 255
  %57 = icmp sgt i32 %19, 0
  %58 = select i1 %57, i32 %19, i32 0
  %59 = icmp slt i32 %58, 255
  %60 = select i1 %59, i32 %58, i32 255
  %61 = shl nuw nsw i32 %60, 8
  %62 = and i32 %56, 255
  %63 = icmp sgt i32 %21, 0
  %64 = select i1 %63, i32 %21, i32 0
  %65 = icmp slt i32 %64, 255
  %66 = select i1 %65, i32 %64, i32 255
  %67 = shl nuw nsw i32 %66, 16
  %68 = and i32 %61, 65280
  %69 = or i32 %68, %62
  %70 = icmp sgt i32 %23, 0
  %71 = select i1 %70, i32 %23, i32 0
  %72 = icmp slt i32 %71, 255
  %73 = select i1 %72, i32 %71, i32 255
  %74 = shl nuw i32 %73, 24
  %75 = and i32 %67, 16711680
  %76 = or i32 %69, %75
  %77 = or i32 %76, %74
  %78 = zext i32 %77 to i64
  %79 = icmp sgt i32 %25, 0
  %80 = select i1 %79, i32 %25, i32 0
  %81 = icmp slt i32 %80, 255
  %82 = select i1 %81, i32 %80, i32 255
  %83 = zext i32 %82 to i64
  %84 = shl nuw nsw i64 %83, 32
  %85 = icmp sgt i32 %27, 0
  %86 = select i1 %85, i32 %27, i32 0
  %87 = icmp slt i32 %86, 255
  %88 = select i1 %87, i32 %86, i32 255
  %89 = zext i32 %88 to i64
  %90 = shl nuw nsw i64 %89, 40
  %91 = or i64 %84, %78
  %92 = icmp sgt i32 %29, 0
  %93 = select i1 %92, i32 %29, i32 0
  %94 = icmp slt i32 %93, 255
  %95 = select i1 %94, i32 %93, i32 255
  %96 = zext i32 %95 to i64
  %97 = shl nuw nsw i64 %96, 48
  %98 = and i64 %90, 280375465082880
  %99 = or i64 %91, %98
  %100 = icmp sgt i32 %31, 0
  %101 = select i1 %100, i32 %31, i32 0
  %102 = icmp slt i32 %101, 255
  %103 = select i1 %102, i32 %101, i32 255
  %104 = zext i32 %103 to i64
  %105 = shl nuw i64 %104, 56
  %106 = and i64 %97, 71776119061217280
  %107 = or i64 %99, %106
  %108 = or i64 %107, %105
  %109 = shl nuw <4 x i64> %52, <i64 32, i64 40, i64 48, i64 56>
  %110 = shl nuw i32 %47, 24
  %111 = shl nuw nsw i32 %43, 16
  %112 = shl nuw nsw i32 %39, 8
  %113 = or i32 %112, %35
  %114 = or i32 %113, %111
  %115 = or i32 %114, %110
  %116 = zext i32 %115 to i64
  %117 = shufflevector <4 x i64> %109, <4 x i64> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %118 = or <4 x i64> %109, %117
  %119 = shufflevector <4 x i64> %118, <4 x i64> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %120 = or <4 x i64> %118, %119
  %121 = extractelement <4 x i64> %120, i32 0
  %122 = or i64 %121, %116
  %123 = insertvalue { i64, i64 } undef, i64 %122, 0
  %124 = insertvalue { i64, i64 } %123, i64 %108, 1
  ret { i64, i64 } %124
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_13RegisterBlockIiLi1ELi4EEEE7ExecuteINS_9MatrixMapIhLNS_8MapOrderE1EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.258"*, i64, i64, %"class.gemmlowp::MatrixMap.195"*, i32, i32, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %9 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.258", %"struct.gemmlowp::OutputPipelineExecutor.258"* %0, i64 0, i32 0, i32 0, i32 0
  %10 = load %"struct.gemmlowp::OutputStageBiasAddition.200"*, %"struct.gemmlowp::OutputStageBiasAddition.200"** %9, align 8
  %11 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition.200", %"struct.gemmlowp::OutputStageBiasAddition.200"* %10, i64 0, i32 0, i32 0
  %12 = load i32*, i32** %11, align 8
  %13 = sext i32 %5 to i64
  %14 = getelementptr i32, i32* %12, i64 %13
  %15 = bitcast i32* %14 to i64*
  %16 = load i64, i64* %15, align 4
  %17 = getelementptr inbounds i32, i32* %14, i64 2
  %18 = bitcast i32* %17 to i64*
  %19 = load i64, i64* %18, align 4
  %20 = and i64 %16, -4294967296
  %21 = add i64 %16, %1
  %22 = add i64 %19, %2
  %23 = and i64 %22, 4294967295
  %24 = and i64 %19, -4294967296
  %25 = add i64 %24, %2
  %26 = and i64 %25, -4294967296
  %27 = or i64 %26, %23
  %28 = add i64 %20, %1
  %29 = and i64 %28, -4294967296
  %30 = and i64 %21, 4294967295
  %31 = or i64 %29, %30
  %32 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.258", %"struct.gemmlowp::OutputPipelineExecutor.258"* %0, i64 0, i32 0, i32 1, i32 0, i32 0
  %33 = tail call { i64, i64 } @_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi4EEEE4EvalES3_(%"struct.gemmlowp::OutputStageEvalBufferImpl.231"* %32, i64 %31, i64 %27) #19
  %34 = extractvalue { i64, i64 } %33, 0
  %35 = extractvalue { i64, i64 } %33, 1
  %36 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.258", %"struct.gemmlowp::OutputPipelineExecutor.258"* %0, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %37 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %36, align 8
  %38 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %37, i64 0, i32 0
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %37, i64 0, i32 1
  %41 = load i32, i32* %40, align 4
  %42 = trunc i64 %34 to i32
  %43 = icmp sgt i32 %39, %42
  %44 = select i1 %43, i32 %39, i32 %42
  %45 = icmp slt i32 %41, %44
  %46 = select i1 %45, i32 %41, i32 %44
  %47 = lshr i64 %34, 32
  %48 = trunc i64 %47 to i32
  %49 = icmp sgt i32 %39, %48
  %50 = select i1 %49, i32 %39, i32 %48
  %51 = icmp slt i32 %41, %50
  %52 = select i1 %51, i32 %41, i32 %50
  %53 = trunc i64 %35 to i32
  %54 = icmp sgt i32 %39, %53
  %55 = select i1 %54, i32 %39, i32 %53
  %56 = icmp slt i32 %41, %55
  %57 = select i1 %56, i32 %41, i32 %55
  %58 = lshr i64 %35, 32
  %59 = trunc i64 %58 to i32
  %60 = icmp sgt i32 %39, %59
  %61 = select i1 %60, i32 %39, i32 %59
  %62 = icmp slt i32 %41, %61
  %63 = select i1 %62, i32 %41, i32 %61
  %64 = icmp sgt i32 %46, 0
  %65 = select i1 %64, i32 %46, i32 0
  %66 = icmp slt i32 %65, 255
  %67 = select i1 %66, i32 %65, i32 255
  %68 = icmp sgt i32 %52, 0
  %69 = select i1 %68, i32 %52, i32 0
  %70 = icmp slt i32 %69, 255
  %71 = select i1 %70, i32 %69, i32 255
  %72 = icmp sgt i32 %57, 0
  %73 = select i1 %72, i32 %57, i32 0
  %74 = icmp slt i32 %73, 255
  %75 = select i1 %74, i32 %73, i32 255
  %76 = icmp sgt i32 %63, 0
  %77 = select i1 %76, i32 %63, i32 0
  %78 = icmp slt i32 %77, 255
  %79 = select i1 %78, i32 %77, i32 255
  %80 = trunc i32 %67 to i8
  %81 = trunc i32 %71 to i8
  %82 = trunc i32 %75 to i8
  %83 = trunc i32 %79 to i8
  %84 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %3, i64 0, i32 0
  %85 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %3, i64 0, i32 3
  %86 = sext i32 %7 to i64
  %87 = sext i32 %6 to i64
  %88 = load i8*, i8** %84, align 8
  %89 = load i32, i32* %85, align 8
  %90 = sext i32 %89 to i64
  %91 = mul nsw i64 %90, %87
  %92 = getelementptr inbounds i8, i8* %88, i64 %91
  %93 = getelementptr inbounds i8, i8* %92, i64 %86
  store i8 %80, i8* %93, align 1
  %94 = add nsw i64 %86, 1
  %95 = load i8*, i8** %84, align 8
  %96 = load i32, i32* %85, align 8
  %97 = sext i32 %96 to i64
  %98 = mul nsw i64 %97, %87
  %99 = getelementptr inbounds i8, i8* %95, i64 %98
  %100 = getelementptr inbounds i8, i8* %99, i64 %94
  store i8 %81, i8* %100, align 1
  %101 = add nsw i64 %86, 2
  %102 = load i8*, i8** %84, align 8
  %103 = load i32, i32* %85, align 8
  %104 = sext i32 %103 to i64
  %105 = mul nsw i64 %104, %87
  %106 = getelementptr inbounds i8, i8* %102, i64 %105
  %107 = getelementptr inbounds i8, i8* %106, i64 %101
  store i8 %82, i8* %107, align 1
  %108 = add nsw i64 %86, 3
  %109 = load i8*, i8** %84, align 8
  %110 = load i32, i32* %85, align 8
  %111 = sext i32 %110 to i64
  %112 = mul nsw i64 %111, %87
  %113 = getelementptr inbounds i8, i8* %109, i64 %112
  %114 = getelementptr inbounds i8, i8* %113, i64 %108
  store i8 %83, i8* %114, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden { i64, i64 } @_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi4EEEE4EvalES3_(%"struct.gemmlowp::OutputStageEvalBufferImpl.231"*, i64, i64) local_unnamed_addr #1 comdat align 2 {
  %4 = alloca { i64, i64 }, align 8
  %5 = bitcast { i64, i64 }* %4 to [4 x i32]*
  %6 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %4, i64 0, i32 1
  %7 = getelementptr inbounds %"struct.gemmlowp::OutputStageEvalBufferImpl.231", %"struct.gemmlowp::OutputStageEvalBufferImpl.231"* %0, i64 0, i32 0
  %8 = bitcast { i64, i64 }* %4 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %8, i8 -86, i64 16, i1 false)
  %9 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %7, align 8
  %10 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %9, i64 0, i32 2
  %11 = load i32, i32* %10, align 4
  %12 = getelementptr inbounds %"struct.gemmlowp::OutputStageEvalBufferImpl.231", %"struct.gemmlowp::OutputStageEvalBufferImpl.231"* %0, i64 0, i32 1
  %13 = load i32, i32* %12, align 8
  %14 = shl i32 1, %13
  %15 = sext i32 %14 to i64
  %16 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %9, i64 0, i32 0
  %17 = load i32, i32* %16, align 4
  %18 = sext i32 %17 to i64
  %19 = getelementptr inbounds %"struct.gemmlowp::OutputStageEvalBufferImpl.231", %"struct.gemmlowp::OutputStageEvalBufferImpl.231"* %0, i64 0, i32 2
  %20 = load i32, i32* %19, align 4
  %21 = zext i32 %20 to i64
  %22 = shl nsw i64 -1, %21
  %23 = trunc i64 %22 to i32
  %24 = xor i32 %23, -1
  %25 = ashr i32 %24, 1
  %26 = shl i64 %1, 32
  %27 = ashr exact i64 %26, 32
  %28 = mul nsw i64 %27, %15
  %29 = icmp slt i64 %28, 2147483647
  %30 = select i1 %29, i64 %28, i64 2147483647
  %31 = icmp sgt i64 %30, -2147483648
  %32 = select i1 %31, i64 %30, i64 -2147483648
  %33 = trunc i64 %32 to i32
  %34 = icmp eq i32 %17, %33
  br i1 %34, label %35, label %37

35:                                               ; preds = %3
  %36 = icmp eq i32 %17, -2147483648
  br i1 %36, label %45, label %37

37:                                               ; preds = %3, %35
  %38 = phi i64 [ %32, %35 ], [ %18, %3 ]
  %39 = mul nsw i64 %38, %32
  %40 = icmp sgt i64 %39, -1
  %41 = select i1 %40, i64 1073741824, i64 -1073741823
  %42 = add nsw i64 %41, %39
  %43 = sdiv i64 %42, 2147483648
  %44 = trunc i64 %43 to i32
  br label %45

45:                                               ; preds = %35, %37
  %46 = phi i32 [ %44, %37 ], [ 2147483647, %35 ]
  %47 = and i32 %46, %24
  %48 = lshr i32 %46, 31
  %49 = add nsw i32 %25, %48
  %50 = ashr i32 %46, %20
  %51 = icmp sgt i32 %47, %49
  %52 = zext i1 %51 to i32
  %53 = add i32 %50, %11
  %54 = add i32 %53, %52
  %55 = bitcast { i64, i64 }* %4 to i32*
  store i32 %54, i32* %55, align 8
  %56 = ashr i64 %1, 32
  %57 = mul nsw i64 %56, %15
  %58 = icmp slt i64 %57, 2147483647
  %59 = select i1 %58, i64 %57, i64 2147483647
  %60 = icmp sgt i64 %59, -2147483648
  %61 = select i1 %60, i64 %59, i64 -2147483648
  %62 = trunc i64 %61 to i32
  %63 = icmp eq i32 %17, %62
  br i1 %63, label %64, label %66

64:                                               ; preds = %45
  %65 = icmp eq i32 %17, -2147483648
  br i1 %65, label %74, label %66

66:                                               ; preds = %64, %45
  %67 = phi i64 [ %61, %64 ], [ %18, %45 ]
  %68 = mul nsw i64 %67, %61
  %69 = icmp sgt i64 %68, -1
  %70 = select i1 %69, i64 1073741824, i64 -1073741823
  %71 = add nsw i64 %70, %68
  %72 = sdiv i64 %71, 2147483648
  %73 = trunc i64 %72 to i32
  br label %74

74:                                               ; preds = %66, %64
  %75 = phi i32 [ %73, %66 ], [ 2147483647, %64 ]
  %76 = and i32 %75, %24
  %77 = lshr i32 %75, 31
  %78 = add nsw i32 %25, %77
  %79 = ashr i32 %75, %20
  %80 = icmp sgt i32 %76, %78
  %81 = zext i1 %80 to i32
  %82 = add i32 %79, %11
  %83 = add i32 %82, %81
  %84 = getelementptr inbounds [4 x i32], [4 x i32]* %5, i64 0, i64 1
  store i32 %83, i32* %84, align 4
  %85 = shl i64 %2, 32
  %86 = ashr exact i64 %85, 32
  %87 = mul nsw i64 %86, %15
  %88 = icmp slt i64 %87, 2147483647
  %89 = select i1 %88, i64 %87, i64 2147483647
  %90 = icmp sgt i64 %89, -2147483648
  %91 = select i1 %90, i64 %89, i64 -2147483648
  %92 = trunc i64 %91 to i32
  %93 = icmp eq i32 %17, %92
  br i1 %93, label %94, label %96

94:                                               ; preds = %74
  %95 = icmp eq i32 %17, -2147483648
  br i1 %95, label %104, label %96

96:                                               ; preds = %94, %74
  %97 = phi i64 [ %91, %94 ], [ %18, %74 ]
  %98 = mul nsw i64 %97, %91
  %99 = icmp sgt i64 %98, -1
  %100 = select i1 %99, i64 1073741824, i64 -1073741823
  %101 = add nsw i64 %100, %98
  %102 = sdiv i64 %101, 2147483648
  %103 = trunc i64 %102 to i32
  br label %104

104:                                              ; preds = %96, %94
  %105 = phi i32 [ %103, %96 ], [ 2147483647, %94 ]
  %106 = and i32 %105, %24
  %107 = lshr i32 %105, 31
  %108 = add nsw i32 %25, %107
  %109 = ashr i32 %105, %20
  %110 = icmp sgt i32 %106, %108
  %111 = zext i1 %110 to i32
  %112 = add i32 %109, %11
  %113 = add i32 %112, %111
  %114 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %4, i64 0, i32 1
  %115 = bitcast i64* %114 to i32*
  store i32 %113, i32* %115, align 8
  %116 = ashr i64 %2, 32
  %117 = mul nsw i64 %116, %15
  %118 = icmp slt i64 %117, 2147483647
  %119 = select i1 %118, i64 %117, i64 2147483647
  %120 = icmp sgt i64 %119, -2147483648
  %121 = select i1 %120, i64 %119, i64 -2147483648
  %122 = trunc i64 %121 to i32
  %123 = icmp eq i32 %17, %122
  br i1 %123, label %124, label %126

124:                                              ; preds = %104
  %125 = icmp eq i32 %17, -2147483648
  br i1 %125, label %134, label %126

126:                                              ; preds = %124, %104
  %127 = phi i64 [ %121, %124 ], [ %18, %104 ]
  %128 = mul nsw i64 %127, %121
  %129 = icmp sgt i64 %128, -1
  %130 = select i1 %129, i64 1073741824, i64 -1073741823
  %131 = add nsw i64 %130, %128
  %132 = sdiv i64 %131, 2147483648
  %133 = trunc i64 %132 to i32
  br label %134

134:                                              ; preds = %126, %124
  %135 = phi i32 [ %133, %126 ], [ 2147483647, %124 ]
  %136 = and i32 %135, %24
  %137 = lshr i32 %135, 31
  %138 = add nsw i32 %25, %137
  %139 = ashr i32 %135, %20
  %140 = icmp sgt i32 %136, %138
  %141 = zext i1 %140 to i32
  %142 = add i32 %139, %11
  %143 = add i32 %142, %141
  %144 = getelementptr inbounds [4 x i32], [4 x i32]* %5, i64 0, i64 3
  store i32 %143, i32* %144, align 4
  %145 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %4, i64 0, i32 0
  %146 = load i64, i64* %145, align 8
  %147 = insertvalue { i64, i64 } undef, i64 %146, 0
  %148 = load i64, i64* %6, align 8
  %149 = insertvalue { i64, i64 } %147, i64 %148, 1
  ret { i64, i64 } %149
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_13RegisterBlockIiLi8ELi4EEEE7ExecuteINS_9MatrixMapIhLNS_8MapOrderE1EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.286"*, %"struct.gemmlowp::RegisterBlock.302"* byval(%"struct.gemmlowp::RegisterBlock.302") align 8, %"class.gemmlowp::MatrixMap.195"*, i32, i32, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %8 = alloca %"struct.gemmlowp::RegisterBlock.302", align 16
  %9 = alloca %"struct.gemmlowp::RegisterBlock.310", align 8
  %10 = alloca %"struct.gemmlowp::RegisterBlock.310", align 1
  %11 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %10, i64 0, i32 0, i32 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %11) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 1 %11, i8 -86, i64 32, i1 false)
  %12 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %1 to <4 x i32>*
  %13 = load <4 x i32>, <4 x i32>* %12, align 8
  %14 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 4
  %15 = bitcast i32* %14 to <4 x i32>*
  %16 = load <4 x i32>, <4 x i32>* %15, align 8
  %17 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 8
  %18 = bitcast i32* %17 to <4 x i32>*
  %19 = load <4 x i32>, <4 x i32>* %18, align 8
  %20 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 12
  %21 = bitcast i32* %20 to <4 x i32>*
  %22 = load <4 x i32>, <4 x i32>* %21, align 8
  %23 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 16
  %24 = bitcast i32* %23 to <4 x i32>*
  %25 = load <4 x i32>, <4 x i32>* %24, align 8
  %26 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 20
  %27 = bitcast i32* %26 to <4 x i32>*
  %28 = load <4 x i32>, <4 x i32>* %27, align 8
  %29 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 24
  %30 = bitcast i32* %29 to <4 x i32>*
  %31 = load <4 x i32>, <4 x i32>* %30, align 8
  %32 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 28
  %33 = bitcast i32* %32 to <4 x i32>*
  %34 = load <4 x i32>, <4 x i32>* %33, align 8
  %35 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %35)
  %36 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.286", %"struct.gemmlowp::OutputPipelineExecutor.286"* %0, i64 0, i32 0, i32 0, i32 0
  %37 = load %"struct.gemmlowp::OutputStageBiasAddition.200"*, %"struct.gemmlowp::OutputStageBiasAddition.200"** %36, align 8, !noalias !665
  %38 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition.200", %"struct.gemmlowp::OutputStageBiasAddition.200"* %37, i64 0, i32 0, i32 0
  %39 = load i32*, i32** %38, align 8, !noalias !665
  %40 = sext i32 %4 to i64
  %41 = getelementptr i32, i32* %39, i64 %40
  %42 = bitcast i32* %41 to i64*
  %43 = load i64, i64* %42, align 4, !noalias !665
  %44 = getelementptr inbounds i32, i32* %41, i64 2
  %45 = bitcast i32* %44 to i64*
  %46 = load i64, i64* %45, align 4, !noalias !665
  %47 = trunc i64 %43 to i32
  %48 = lshr i64 %43, 32
  %49 = trunc i64 %48 to i32
  %50 = insertelement <4 x i32> undef, i32 %47, i32 0
  %51 = shufflevector <4 x i32> %50, <4 x i32> undef, <4 x i32> zeroinitializer
  %52 = add nsw <4 x i32> %13, %51
  %53 = add nsw <4 x i32> %16, %51
  %54 = insertelement <4 x i32> undef, i32 %49, i32 0
  %55 = shufflevector <4 x i32> %54, <4 x i32> undef, <4 x i32> zeroinitializer
  %56 = add nsw <4 x i32> %19, %55
  %57 = add nsw <4 x i32> %22, %55
  %58 = trunc i64 %46 to i32
  %59 = insertelement <4 x i32> undef, i32 %58, i32 0
  %60 = shufflevector <4 x i32> %59, <4 x i32> undef, <4 x i32> zeroinitializer
  %61 = add nsw <4 x i32> %25, %60
  %62 = add nsw <4 x i32> %28, %60
  %63 = lshr i64 %46, 32
  %64 = trunc i64 %63 to i32
  %65 = insertelement <4 x i32> undef, i32 %64, i32 0
  %66 = shufflevector <4 x i32> %65, <4 x i32> undef, <4 x i32> zeroinitializer
  %67 = add nsw <4 x i32> %31, %66
  %68 = add nsw <4 x i32> %34, %66
  %69 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.286", %"struct.gemmlowp::OutputPipelineExecutor.286"* %0, i64 0, i32 0, i32 1
  %70 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %8 to <4 x i32>*
  store <4 x i32> %52, <4 x i32>* %70, align 16, !noalias !670
  %71 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %8, i64 0, i32 0, i32 0, i64 4
  %72 = bitcast i32* %71 to <4 x i32>*
  store <4 x i32> %53, <4 x i32>* %72, align 16, !noalias !670
  %73 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %8, i64 0, i32 0, i32 0, i64 8
  %74 = bitcast i32* %73 to <4 x i32>*
  store <4 x i32> %56, <4 x i32>* %74, align 16, !noalias !670
  %75 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %8, i64 0, i32 0, i32 0, i64 12
  %76 = bitcast i32* %75 to <4 x i32>*
  store <4 x i32> %57, <4 x i32>* %76, align 16, !noalias !670
  %77 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %8, i64 0, i32 0, i32 0, i64 16
  %78 = bitcast i32* %77 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %78, align 16, !noalias !670
  %79 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %8, i64 0, i32 0, i32 0, i64 20
  %80 = bitcast i32* %79 to <4 x i32>*
  store <4 x i32> %62, <4 x i32>* %80, align 16, !noalias !670
  %81 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %8, i64 0, i32 0, i32 0, i64 24
  %82 = bitcast i32* %81 to <4 x i32>*
  store <4 x i32> %67, <4 x i32>* %82, align 16, !noalias !670
  %83 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %8, i64 0, i32 0, i32 0, i64 28
  %84 = bitcast i32* %83 to <4 x i32>*
  store <4 x i32> %68, <4 x i32>* %84, align 16, !noalias !670
  call void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi1ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.310"* nonnull sret %10, %"struct.gemmlowp::OutputPipelineEvalImpl.289"* %69, %"struct.gemmlowp::RegisterBlock.302"* nonnull byval(%"struct.gemmlowp::RegisterBlock.302") align 8 %8, i32 %3, i32 %4) #19
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %35)
  %85 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %9, i64 0, i32 0, i32 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %85)
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %85, i8* nonnull align 1 %11, i64 32, i1 false)
  %86 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %2, i64 0, i32 0
  %87 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %2, i64 0, i32 3
  %88 = sext i32 %6 to i64
  %89 = sext i32 %5 to i64
  %90 = add nsw i64 %88, 1
  %91 = add nsw i64 %88, 2
  %92 = add nsw i64 %88, 3
  br label %93

93:                                               ; preds = %93, %7
  %94 = phi i64 [ 0, %7 ], [ %131, %93 ]
  %95 = add nsw i64 %94, %89
  %96 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %9, i64 0, i32 0, i32 0, i64 %94
  %97 = load i8, i8* %96, align 1
  %98 = load i8*, i8** %86, align 8
  %99 = load i32, i32* %87, align 8
  %100 = sext i32 %99 to i64
  %101 = mul nsw i64 %95, %100
  %102 = getelementptr inbounds i8, i8* %98, i64 %88
  %103 = getelementptr inbounds i8, i8* %102, i64 %101
  store i8 %97, i8* %103, align 1
  %104 = add nuw nsw i64 %94, 8
  %105 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %9, i64 0, i32 0, i32 0, i64 %104
  %106 = load i8, i8* %105, align 1
  %107 = load i8*, i8** %86, align 8
  %108 = load i32, i32* %87, align 8
  %109 = sext i32 %108 to i64
  %110 = mul nsw i64 %95, %109
  %111 = getelementptr inbounds i8, i8* %107, i64 %90
  %112 = getelementptr inbounds i8, i8* %111, i64 %110
  store i8 %106, i8* %112, align 1
  %113 = add nuw nsw i64 %94, 16
  %114 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %9, i64 0, i32 0, i32 0, i64 %113
  %115 = load i8, i8* %114, align 1
  %116 = load i8*, i8** %86, align 8
  %117 = load i32, i32* %87, align 8
  %118 = sext i32 %117 to i64
  %119 = mul nsw i64 %95, %118
  %120 = getelementptr inbounds i8, i8* %116, i64 %91
  %121 = getelementptr inbounds i8, i8* %120, i64 %119
  store i8 %115, i8* %121, align 1
  %122 = add nuw nsw i64 %94, 24
  %123 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %9, i64 0, i32 0, i32 0, i64 %122
  %124 = load i8, i8* %123, align 1
  %125 = load i8*, i8** %86, align 8
  %126 = load i32, i32* %87, align 8
  %127 = sext i32 %126 to i64
  %128 = mul nsw i64 %95, %127
  %129 = getelementptr inbounds i8, i8* %125, i64 %92
  %130 = getelementptr inbounds i8, i8* %129, i64 %128
  store i8 %124, i8* %130, align 1
  %131 = add nuw nsw i64 %94, 1
  %132 = icmp eq i64 %131, 8
  br i1 %132, label %133, label %93

133:                                              ; preds = %93
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %85)
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %11) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi1ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalESE_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.245"*, %"struct.gemmlowp::RegisterBlock.304"* byval(%"struct.gemmlowp::RegisterBlock.304") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %5 = alloca %"struct.gemmlowp::RegisterBuffer.305", align 8
  %6 = alloca %"struct.gemmlowp::RegisterBuffer.305", align 4
  %7 = bitcast %"struct.gemmlowp::RegisterBlock.304"* %1 to i8*
  %8 = bitcast %"struct.gemmlowp::RegisterBuffer.305"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %8) #19, !noalias !671
  %9 = bitcast %"struct.gemmlowp::RegisterBuffer.305"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %9) #19, !noalias !671
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %9, i8* nonnull align 8 %7, i64 32, i1 false)
  %10 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.245", %"struct.gemmlowp::OutputPipelineEvalImpl.245"* %0, i64 0, i32 0, i32 0, i32 0
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %8, i8 -86, i64 32, i1 false) #19, !alias.scope !674, !noalias !671
  %11 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %10, align 8, !noalias !677
  %12 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %11, i64 0, i32 2
  %13 = load i32, i32* %12, align 4, !noalias !677
  %14 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.245", %"struct.gemmlowp::OutputPipelineEvalImpl.245"* %0, i64 0, i32 0, i32 0, i32 1
  %15 = load i32, i32* %14, align 8, !noalias !677
  %16 = shl i32 1, %15
  %17 = sext i32 %16 to i64
  %18 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %11, i64 0, i32 0
  %19 = load i32, i32* %18, align 4, !noalias !677
  %20 = sext i32 %19 to i64
  %21 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.245", %"struct.gemmlowp::OutputPipelineEvalImpl.245"* %0, i64 0, i32 0, i32 0, i32 2
  %22 = load i32, i32* %21, align 4, !noalias !677
  %23 = zext i32 %22 to i64
  %24 = shl nsw i64 -1, %23
  %25 = trunc i64 %24 to i32
  %26 = xor i32 %25, -1
  %27 = ashr i32 %26, 1
  %28 = icmp ne i32 %19, -2147483648
  br label %29

29:                                               ; preds = %50, %4
  %30 = phi i64 [ 0, %4 ], [ %61, %50 ]
  %31 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.305", %"struct.gemmlowp::RegisterBuffer.305"* %5, i64 0, i32 0, i64 %30
  %32 = load i32, i32* %31, align 4, !noalias !677
  %33 = sext i32 %32 to i64
  %34 = mul nsw i64 %33, %17
  %35 = icmp slt i64 %34, 2147483647
  %36 = select i1 %35, i64 %34, i64 2147483647
  %37 = icmp sgt i64 %36, -2147483648
  %38 = select i1 %37, i64 %36, i64 -2147483648
  %39 = trunc i64 %38 to i32
  %40 = icmp ne i32 %19, %39
  %41 = or i1 %28, %40
  br i1 %41, label %42, label %50

42:                                               ; preds = %29
  %43 = select i1 %40, i64 %20, i64 %38
  %44 = mul nsw i64 %43, %38
  %45 = icmp sgt i64 %44, -1
  %46 = select i1 %45, i64 1073741824, i64 -1073741823
  %47 = add nsw i64 %46, %44
  %48 = sdiv i64 %47, 2147483648
  %49 = trunc i64 %48 to i32
  br label %50

50:                                               ; preds = %42, %29
  %51 = phi i32 [ %49, %42 ], [ 2147483647, %29 ]
  %52 = and i32 %51, %26
  %53 = lshr i32 %51, 31
  %54 = add nsw i32 %53, %27
  %55 = ashr i32 %51, %22
  %56 = icmp sgt i32 %52, %54
  %57 = zext i1 %56 to i32
  %58 = add i32 %55, %13
  %59 = add i32 %58, %57
  %60 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.305", %"struct.gemmlowp::RegisterBuffer.305"* %6, i64 0, i32 0, i64 %30
  store i32 %59, i32* %60, align 4, !alias.scope !674, !noalias !671
  %61 = add nuw nsw i64 %30, 1
  %62 = icmp eq i64 %61, 8
  br i1 %62, label %63, label %29

63:                                               ; preds = %50
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %9) #19, !noalias !671
  %64 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.305", %"struct.gemmlowp::RegisterBuffer.305"* %6, i64 0, i32 0, i64 0
  %65 = load i32, i32* %64, align 4
  %66 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.305", %"struct.gemmlowp::RegisterBuffer.305"* %6, i64 0, i32 0, i64 1
  %67 = load i32, i32* %66, align 4
  %68 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.305", %"struct.gemmlowp::RegisterBuffer.305"* %6, i64 0, i32 0, i64 2
  %69 = load i32, i32* %68, align 4
  %70 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.305", %"struct.gemmlowp::RegisterBuffer.305"* %6, i64 0, i32 0, i64 3
  %71 = load i32, i32* %70, align 4
  %72 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.305", %"struct.gemmlowp::RegisterBuffer.305"* %6, i64 0, i32 0, i64 4
  %73 = bitcast i32* %72 to <4 x i32>*
  %74 = load <4 x i32>, <4 x i32>* %73, align 4
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %8) #19, !noalias !671
  %75 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.245", %"struct.gemmlowp::OutputPipelineEvalImpl.245"* %0, i64 0, i32 1, i32 0, i32 0, i32 0
  %76 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %75, align 8, !noalias !678
  %77 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %76, i64 0, i32 0
  %78 = load i32, i32* %77, align 4, !noalias !678
  %79 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %76, i64 0, i32 1
  %80 = load i32, i32* %79, align 4, !noalias !678
  %81 = icmp slt i32 %65, %78
  %82 = select i1 %81, i32 %78, i32 %65
  %83 = icmp slt i32 %80, %82
  %84 = select i1 %83, i32 %80, i32 %82
  %85 = icmp slt i32 %67, %78
  %86 = select i1 %85, i32 %78, i32 %67
  %87 = icmp slt i32 %80, %86
  %88 = select i1 %87, i32 %80, i32 %86
  %89 = icmp slt i32 %69, %78
  %90 = select i1 %89, i32 %78, i32 %69
  %91 = icmp slt i32 %80, %90
  %92 = select i1 %91, i32 %80, i32 %90
  %93 = icmp slt i32 %71, %78
  %94 = select i1 %93, i32 %78, i32 %71
  %95 = icmp slt i32 %80, %94
  %96 = select i1 %95, i32 %80, i32 %94
  %97 = insertelement <4 x i32> undef, i32 %78, i32 0
  %98 = shufflevector <4 x i32> %97, <4 x i32> undef, <4 x i32> zeroinitializer
  %99 = icmp slt <4 x i32> %74, %98
  %100 = select <4 x i1> %99, <4 x i32> %98, <4 x i32> %74
  %101 = insertelement <4 x i32> undef, i32 %80, i32 0
  %102 = shufflevector <4 x i32> %101, <4 x i32> undef, <4 x i32> zeroinitializer
  %103 = icmp slt <4 x i32> %102, %100
  %104 = select <4 x i1> %103, <4 x i32> %102, <4 x i32> %100
  %105 = icmp sgt i32 %84, 0
  %106 = select i1 %105, i32 %84, i32 0
  %107 = icmp slt i32 %106, 255
  %108 = select i1 %107, i32 %106, i32 255
  %109 = icmp sgt i32 %88, 0
  %110 = select i1 %109, i32 %88, i32 0
  %111 = icmp slt i32 %110, 255
  %112 = select i1 %111, i32 %110, i32 255
  %113 = icmp sgt i32 %92, 0
  %114 = select i1 %113, i32 %92, i32 0
  %115 = icmp slt i32 %114, 255
  %116 = select i1 %115, i32 %114, i32 255
  %117 = icmp sgt i32 %96, 0
  %118 = select i1 %117, i32 %96, i32 0
  %119 = icmp slt i32 %118, 255
  %120 = select i1 %119, i32 %118, i32 255
  %121 = icmp sgt <4 x i32> %104, zeroinitializer
  %122 = select <4 x i1> %121, <4 x i32> %104, <4 x i32> zeroinitializer
  %123 = icmp slt <4 x i32> %122, <i32 255, i32 255, i32 255, i32 255>
  %124 = select <4 x i1> %123, <4 x i32> %122, <4 x i32> <i32 255, i32 255, i32 255, i32 255>
  %125 = zext <4 x i32> %124 to <4 x i64>
  %126 = shl nuw <4 x i64> %125, <i64 32, i64 40, i64 48, i64 56>
  %127 = shl nuw i32 %120, 24
  %128 = shl nuw nsw i32 %116, 16
  %129 = shl nuw nsw i32 %112, 8
  %130 = or i32 %129, %108
  %131 = or i32 %130, %128
  %132 = or i32 %131, %127
  %133 = zext i32 %132 to i64
  %134 = shufflevector <4 x i64> %126, <4 x i64> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %135 = or <4 x i64> %126, %134
  %136 = shufflevector <4 x i64> %135, <4 x i64> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %137 = or <4 x i64> %135, %136
  %138 = extractelement <4 x i64> %137, i32 0
  %139 = or i64 %138, %133
  ret i64 %139
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_13RegisterBlockIiLi4ELi1EEEE7ExecuteINS_9MatrixMapIhLNS_8MapOrderE1EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.226"*, i64, i64, %"class.gemmlowp::MatrixMap.195"*, i32, i32, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %9 = trunc i64 %1 to i32
  %10 = lshr i64 %1, 32
  %11 = trunc i64 %10 to i32
  %12 = trunc i64 %2 to i32
  %13 = lshr i64 %2, 32
  %14 = trunc i64 %13 to i32
  %15 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.226", %"struct.gemmlowp::OutputPipelineExecutor.226"* %0, i64 0, i32 0, i32 0, i32 0
  %16 = load %"struct.gemmlowp::OutputStageBiasAddition.200"*, %"struct.gemmlowp::OutputStageBiasAddition.200"** %15, align 8
  %17 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition.200", %"struct.gemmlowp::OutputStageBiasAddition.200"* %16, i64 0, i32 0, i32 0
  %18 = load i32*, i32** %17, align 8
  %19 = sext i32 %5 to i64
  %20 = getelementptr inbounds i32, i32* %18, i64 %19
  %21 = load i32, i32* %20, align 4
  %22 = add nsw i32 %21, %9
  %23 = add nsw i32 %21, %11
  %24 = add nsw i32 %21, %12
  %25 = zext i32 %24 to i64
  %26 = add nsw i32 %21, %14
  %27 = zext i32 %26 to i64
  %28 = shl nuw i64 %27, 32
  %29 = or i64 %28, %25
  %30 = zext i32 %23 to i64
  %31 = shl nuw i64 %30, 32
  %32 = zext i32 %22 to i64
  %33 = or i64 %31, %32
  %34 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.226", %"struct.gemmlowp::OutputPipelineExecutor.226"* %0, i64 0, i32 0, i32 1, i32 0, i32 0
  %35 = tail call { i64, i64 } @_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi4EEEE4EvalES3_(%"struct.gemmlowp::OutputStageEvalBufferImpl.231"* %34, i64 %33, i64 %29) #19
  %36 = extractvalue { i64, i64 } %35, 0
  %37 = extractvalue { i64, i64 } %35, 1
  %38 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.226", %"struct.gemmlowp::OutputPipelineExecutor.226"* %0, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %39 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %38, align 8
  %40 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %39, i64 0, i32 0
  %41 = load i32, i32* %40, align 4
  %42 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %39, i64 0, i32 1
  %43 = load i32, i32* %42, align 4
  %44 = trunc i64 %36 to i32
  %45 = icmp sgt i32 %41, %44
  %46 = select i1 %45, i32 %41, i32 %44
  %47 = icmp slt i32 %43, %46
  %48 = select i1 %47, i32 %43, i32 %46
  %49 = lshr i64 %36, 32
  %50 = trunc i64 %49 to i32
  %51 = icmp sgt i32 %41, %50
  %52 = select i1 %51, i32 %41, i32 %50
  %53 = icmp slt i32 %43, %52
  %54 = select i1 %53, i32 %43, i32 %52
  %55 = trunc i64 %37 to i32
  %56 = icmp sgt i32 %41, %55
  %57 = select i1 %56, i32 %41, i32 %55
  %58 = icmp slt i32 %43, %57
  %59 = select i1 %58, i32 %43, i32 %57
  %60 = lshr i64 %37, 32
  %61 = trunc i64 %60 to i32
  %62 = icmp sgt i32 %41, %61
  %63 = select i1 %62, i32 %41, i32 %61
  %64 = icmp slt i32 %43, %63
  %65 = select i1 %64, i32 %43, i32 %63
  %66 = icmp sgt i32 %48, 0
  %67 = select i1 %66, i32 %48, i32 0
  %68 = icmp slt i32 %67, 255
  %69 = select i1 %68, i32 %67, i32 255
  %70 = icmp sgt i32 %54, 0
  %71 = select i1 %70, i32 %54, i32 0
  %72 = icmp slt i32 %71, 255
  %73 = select i1 %72, i32 %71, i32 255
  %74 = icmp sgt i32 %59, 0
  %75 = select i1 %74, i32 %59, i32 0
  %76 = icmp slt i32 %75, 255
  %77 = select i1 %76, i32 %75, i32 255
  %78 = icmp sgt i32 %65, 0
  %79 = select i1 %78, i32 %65, i32 0
  %80 = icmp slt i32 %79, 255
  %81 = select i1 %80, i32 %79, i32 255
  %82 = trunc i32 %69 to i8
  %83 = trunc i32 %73 to i8
  %84 = trunc i32 %77 to i8
  %85 = trunc i32 %81 to i8
  %86 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %3, i64 0, i32 0
  %87 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %3, i64 0, i32 3
  %88 = sext i32 %6 to i64
  %89 = load i8*, i8** %86, align 8
  %90 = load i32, i32* %87, align 8
  %91 = sext i32 %90 to i64
  %92 = mul nsw i64 %91, %88
  %93 = getelementptr inbounds i8, i8* %89, i64 %92
  %94 = sext i32 %7 to i64
  %95 = getelementptr inbounds i8, i8* %93, i64 %94
  store i8 %82, i8* %95, align 1
  %96 = add nsw i64 %88, 1
  %97 = load i8*, i8** %86, align 8
  %98 = load i32, i32* %87, align 8
  %99 = sext i32 %98 to i64
  %100 = mul nsw i64 %96, %99
  %101 = getelementptr inbounds i8, i8* %97, i64 %100
  %102 = getelementptr inbounds i8, i8* %101, i64 %94
  store i8 %83, i8* %102, align 1
  %103 = add nsw i64 %88, 2
  %104 = load i8*, i8** %86, align 8
  %105 = load i32, i32* %87, align 8
  %106 = sext i32 %105 to i64
  %107 = mul nsw i64 %103, %106
  %108 = getelementptr inbounds i8, i8* %104, i64 %107
  %109 = getelementptr inbounds i8, i8* %108, i64 %94
  store i8 %84, i8* %109, align 1
  %110 = add nsw i64 %88, 3
  %111 = load i8*, i8** %86, align 8
  %112 = load i32, i32* %87, align 8
  %113 = sext i32 %112 to i64
  %114 = mul nsw i64 %110, %113
  %115 = getelementptr inbounds i8, i8* %111, i64 %114
  %116 = getelementptr inbounds i8, i8* %115, i64 %94
  store i8 %85, i8* %116, align 1
  ret void
}

; Function Attrs: nounwind
declare void @free(i8* nocapture) local_unnamed_addr #14

; Function Attrs: nofree nounwind
declare i32 @posix_memalign(i8**, i64, i64) local_unnamed_addr #9

; Function Attrs: nofree nounwind
declare i32 @fprintf(%struct._IO_FILE* nocapture, i8* nocapture readonly, ...) local_unnamed_addr #9

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEED2Ev(%"struct.gemmlowp::GemmWithPackedRhsTask"*) unnamed_addr #4 comdat align 2 {
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEED0Ev(%"struct.gemmlowp::GemmWithPackedRhsTask"*) unnamed_addr #4 comdat align 2 {
  %2 = bitcast %"struct.gemmlowp::GemmWithPackedRhsTask"* %0 to i8*
  tail call void @_ZdlPv(i8* %2) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEE3RunEv(%"struct.gemmlowp::GemmWithPackedRhsTask"*) unnamed_addr #1 comdat align 2 {
  %2 = alloca %"class.gemmlowp::SideMap", align 8
  %3 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %4 = alloca %"class.gemmlowp::ComputeImpl", align 8
  %5 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %6 = alloca %"class.gemmlowp::PackedResult", align 8
  %7 = alloca %"struct.gemmlowp::MatrixBlockBounds", align 4
  %8 = alloca %"class.gemmlowp::VectorDup.194", align 4
  %9 = alloca %"class.gemmlowp::VectorDup", align 4
  %10 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask", %"struct.gemmlowp::GemmWithPackedRhsTask"* %0, i64 0, i32 6, i32 2
  %11 = load i32, i32* %10, align 8
  %12 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask", %"struct.gemmlowp::GemmWithPackedRhsTask"* %0, i64 0, i32 6, i32 3
  %13 = load i32, i32* %12, align 4
  %14 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask", %"struct.gemmlowp::GemmWithPackedRhsTask"* %0, i64 0, i32 3, i32 2
  %15 = load i32, i32* %14, align 4
  %16 = bitcast %"class.gemmlowp::PackedSideBlock"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %16) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %16, i8 -86, i64 80, i1 false)
  %17 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask", %"struct.gemmlowp::GemmWithPackedRhsTask"* %0, i64 0, i32 0, i32 1
  %18 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %19 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask", %"struct.gemmlowp::GemmWithPackedRhsTask"* %0, i64 0, i32 9
  %20 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %21 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %18, %"class.gemmlowp::Allocator"** %21, align 8
  %22 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 4
  store i32 0, i32* %22, align 8
  %23 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 0
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 0
  store i32 %24, i32* %25, align 8
  %26 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 3
  %27 = load i32, i32* %26, align 4
  %28 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 2
  store i32 %27, i32* %28, align 8
  %29 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 2
  %30 = load i32, i32* %29, align 4
  %31 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 1
  store i32 %30, i32* %31, align 4
  %32 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 5
  %33 = load i32, i32* %32, align 4
  %34 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 3
  store i32 %33, i32* %34, align 4
  %35 = mul nsw i32 %33, %27
  %36 = sext i32 %35 to i64
  %37 = add nsw i64 %36, 63
  %38 = and i64 %37, -64
  %39 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 4
  %40 = load i64, i64* %39, align 8, !noalias !683
  %41 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 3
  %42 = load i64, i64* %41, align 8, !noalias !683
  %43 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 5, i64 %42
  store i64 %40, i64* %43, align 8, !noalias !683
  %44 = trunc i64 %42 to i8
  %45 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 6
  %46 = load i64, i64* %45, align 8, !noalias !683
  %47 = bitcast i64* %41 to <2 x i64>*
  %48 = load <2 x i64>, <2 x i64>* %47, align 8, !noalias !683
  %49 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %38, i32 1
  %50 = add <2 x i64> %48, %49
  %51 = bitcast i64* %41 to <2 x i64>*
  store <2 x i64> %50, <2 x i64>* %51, align 8, !noalias !683
  %52 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 0
  store i8 %44, i8* %52, align 8
  %53 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %53, i8 -86, i64 7, i1 false) #19
  %54 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 2
  store i64 %46, i64* %54, align 8
  %55 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 3
  store i8 0, i8* %55, align 8
  %56 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %21, align 8
  %57 = load i32, i32* %28, align 8
  %58 = sext i32 %57 to i64
  %59 = shl nsw i64 %58, 2
  %60 = add nsw i64 %59, 63
  %61 = and i64 %60, -64
  %62 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 4
  %63 = load i64, i64* %62, align 8, !noalias !686
  %64 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 3
  %65 = load i64, i64* %64, align 8, !noalias !686
  %66 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 5, i64 %65
  store i64 %63, i64* %66, align 8, !noalias !686
  %67 = trunc i64 %65 to i8
  %68 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 6
  %69 = load i64, i64* %68, align 8, !noalias !686
  %70 = bitcast i64* %64 to <2 x i64>*
  %71 = load <2 x i64>, <2 x i64>* %70, align 8, !noalias !686
  %72 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %61, i32 1
  %73 = add <2 x i64> %71, %72
  %74 = bitcast i64* %64 to <2 x i64>*
  store <2 x i64> %73, <2 x i64>* %74, align 8, !noalias !686
  %75 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 0
  store i8 %67, i8* %75, align 8
  %76 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %76, i8 -86, i64 7, i1 false) #19
  %77 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 2
  store i64 %69, i64* %77, align 8
  %78 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 3
  store i8 5, i8* %78, align 8
  %79 = bitcast %"class.gemmlowp::PackedResult"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %79) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %79, i8 -86, i64 32, i1 false)
  %80 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %81 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %82 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 0
  store %"class.gemmlowp::Allocator"* %80, %"class.gemmlowp::Allocator"** %82, align 8
  %83 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 2
  store %"struct.gemmlowp::BlockParams"* %81, %"struct.gemmlowp::BlockParams"** %83, align 8
  %84 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %81, i64 0, i32 3
  %85 = load i32, i32* %84, align 4
  %86 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %81, i64 0, i32 4
  %87 = load i32, i32* %86, align 4
  %88 = mul nsw i32 %87, %85
  %89 = sext i32 %88 to i64
  %90 = shl nsw i64 %89, 2
  %91 = add nsw i64 %90, 63
  %92 = and i64 %91, -64
  %93 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 4
  %94 = load i64, i64* %93, align 8, !noalias !689
  %95 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 3
  %96 = load i64, i64* %95, align 8, !noalias !689
  %97 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 5, i64 %96
  store i64 %94, i64* %97, align 8, !noalias !689
  %98 = trunc i64 %96 to i8
  %99 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 6
  %100 = load i64, i64* %99, align 8, !noalias !689
  %101 = bitcast i64* %95 to <2 x i64>*
  %102 = load <2 x i64>, <2 x i64>* %101, align 8, !noalias !689
  %103 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %92, i32 1
  %104 = add <2 x i64> %102, %103
  %105 = bitcast i64* %95 to <2 x i64>*
  store <2 x i64> %104, <2 x i64>* %105, align 8, !noalias !689
  %106 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 0
  store i8 %98, i8* %106, align 8
  %107 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %107, i8 -86, i64 7, i1 false) #19
  %108 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 2
  store i64 %100, i64* %108, align 8
  %109 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 3
  store i8 5, i8* %109, align 8
  %110 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  tail call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %110)
  %111 = icmp sgt i32 %13, 0
  br i1 %111, label %112, label %156

112:                                              ; preds = %1
  %113 = icmp sgt i32 %11, 0
  %114 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask", %"struct.gemmlowp::GemmWithPackedRhsTask"* %0, i64 0, i32 3, i32 0
  %115 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask", %"struct.gemmlowp::GemmWithPackedRhsTask"* %0, i64 0, i32 3, i32 3
  %116 = bitcast %"class.gemmlowp::SideMap"* %2 to i8*
  %117 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 1
  %118 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 2
  %119 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 3
  %120 = bitcast %"class.gemmlowp::SideMap"* %2 to i64*
  %121 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %3 to i8*
  %122 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %3, i64 0, i32 0
  %123 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %3, i64 0, i32 1
  %124 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask", %"struct.gemmlowp::GemmWithPackedRhsTask"* %0, i64 0, i32 2
  %125 = bitcast %"struct.gemmlowp::KernelBase"** %124 to i64*
  %126 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask", %"struct.gemmlowp::GemmWithPackedRhsTask"* %0, i64 0, i32 4
  %127 = bitcast %"class.gemmlowp::ComputeImpl"* %4 to i8*
  %128 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 1
  %129 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 2
  %130 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 3
  %131 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 4
  %132 = bitcast %"class.gemmlowp::ComputeImpl"* %4 to i64*
  %133 = add i32 %15, 15
  %134 = and i32 %133, -16
  %135 = icmp sgt i32 %134, 0
  %136 = bitcast %"struct.gemmlowp::MatrixBlockBounds"* %7 to i8*
  %137 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 0
  %138 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 1
  %139 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 2
  %140 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 3
  %141 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask", %"struct.gemmlowp::GemmWithPackedRhsTask"* %0, i64 0, i32 6, i32 0
  %142 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask", %"struct.gemmlowp::GemmWithPackedRhsTask"* %0, i64 0, i32 6, i32 1
  %143 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask", %"struct.gemmlowp::GemmWithPackedRhsTask"* %0, i64 0, i32 5
  %144 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask", %"struct.gemmlowp::GemmWithPackedRhsTask"* %0, i64 0, i32 4, i32 1
  %145 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask", %"struct.gemmlowp::GemmWithPackedRhsTask"* %0, i64 0, i32 4, i32 3, i32 0
  %146 = bitcast %"class.gemmlowp::VectorDup.194"* %8 to i8*
  %147 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask", %"struct.gemmlowp::GemmWithPackedRhsTask"* %0, i64 0, i32 7
  %148 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %8, i64 0, i32 0
  %149 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %8, i64 0, i32 1
  %150 = bitcast %"class.gemmlowp::VectorDup"* %9 to i8*
  %151 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask", %"struct.gemmlowp::GemmWithPackedRhsTask"* %0, i64 0, i32 8
  %152 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %9, i64 0, i32 0
  %153 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %9, i64 0, i32 1
  %154 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask", %"struct.gemmlowp::GemmWithPackedRhsTask"* %0, i64 0, i32 10
  %155 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  br label %164

156:                                              ; preds = %178, %1
  %157 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %158 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 0
  store i8 0, i8* %158, align 8
  %159 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 6
  %160 = load i64, i64* %159, align 8
  %161 = add i64 %160, 1
  store i64 %161, i64* %159, align 8
  %162 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 3
  %163 = bitcast i64* %162 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %163, i8 0, i64 16, i1 false) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %79) #19
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %16) #19
  ret void

164:                                              ; preds = %112, %178
  %165 = phi %"struct.gemmlowp::BlockParams"* [ %155, %112 ], [ %180, %178 ]
  %166 = phi i32 [ 0, %112 ], [ %181, %178 ]
  %167 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %165, i64 0, i32 4
  %168 = sub nsw i32 %13, %166
  %169 = load i32, i32* %167, align 4
  %170 = icmp slt i32 %168, %169
  %171 = select i1 %170, i32 %168, i32 %169
  br i1 %113, label %172, label %178

172:                                              ; preds = %164
  %173 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %165, i64 0, i32 3
  %174 = load i32, i32* %173, align 4
  br label %183

175:                                              ; preds = %255
  %176 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %287, i64 0, i32 4
  %177 = load i32, i32* %176, align 4
  br label %178

178:                                              ; preds = %175, %164
  %179 = phi i32 [ %169, %164 ], [ %177, %175 ]
  %180 = phi %"struct.gemmlowp::BlockParams"* [ %165, %164 ], [ %287, %175 ]
  %181 = add nsw i32 %179, %166
  %182 = icmp sgt i32 %13, %181
  br i1 %182, label %164, label %156

183:                                              ; preds = %172, %255
  %184 = phi i32 [ %289, %255 ], [ %174, %172 ]
  %185 = phi i32 [ %290, %255 ], [ 0, %172 ]
  %186 = sub nsw i32 %11, %185
  %187 = icmp slt i32 %186, %184
  %188 = select i1 %187, i32 %186, i32 %184
  %189 = load i8*, i8** %114, align 8, !noalias !692
  %190 = load i32, i32* %115, align 8, !noalias !692
  %191 = mul nsw i32 %190, %185
  %192 = sext i32 %191 to i64
  %193 = getelementptr inbounds i8, i8* %189, i64 %192
  %194 = ptrtoint i8* %193 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %116) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %116, i8 -86, i64 24, i1 false) #19
  store i64 %194, i64* %120, align 8
  store i32 %188, i32* %117, align 8
  store i32 %15, i32* %118, align 4
  store i32 %190, i32* %119, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %121) #19
  store %"class.gemmlowp::PackedSideBlock"* %5, %"class.gemmlowp::PackedSideBlock"** %122, align 8
  store %"class.gemmlowp::SideMap"* %2, %"class.gemmlowp::SideMap"** %123, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %3) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %121) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %116) #19
  %195 = load i64, i64* %125, align 8
  %196 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %127) #19
  store i64 %195, i64* %132, align 8
  store %"struct.gemmlowp::BlockParams"* %196, %"struct.gemmlowp::BlockParams"** %128, align 8
  store %"class.gemmlowp::PackedResult"* %6, %"class.gemmlowp::PackedResult"** %129, align 8
  store %"class.gemmlowp::PackedSideBlock"* %5, %"class.gemmlowp::PackedSideBlock"** %130, align 8
  store %"class.gemmlowp::PackedSideBlock"* %126, %"class.gemmlowp::PackedSideBlock"** %131, align 8
  br i1 %135, label %197, label %255

197:                                              ; preds = %183, %215
  %198 = phi %"struct.gemmlowp::BlockParams"* [ %217, %215 ], [ %196, %183 ]
  %199 = phi %"struct.gemmlowp::BlockParams"* [ %218, %215 ], [ %196, %183 ]
  %200 = phi i32 [ %219, %215 ], [ 0, %183 ]
  %201 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 2
  %202 = sub nsw i32 %134, %200
  %203 = load i32, i32* %201, align 4
  %204 = icmp slt i32 %202, %203
  %205 = select i1 %204, i32 %202, i32 %203
  %206 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 3
  %207 = load i32, i32* %206, align 4
  %208 = icmp sgt i32 %207, 0
  br i1 %208, label %209, label %215

209:                                              ; preds = %197
  %210 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 0
  %211 = load i32, i32* %210, align 4
  br label %221

212:                                              ; preds = %247
  %213 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 2
  %214 = load i32, i32* %213, align 4
  br label %215

215:                                              ; preds = %212, %197
  %216 = phi i32 [ %203, %197 ], [ %214, %212 ]
  %217 = phi %"struct.gemmlowp::BlockParams"* [ %198, %197 ], [ %248, %212 ]
  %218 = phi %"struct.gemmlowp::BlockParams"* [ %199, %197 ], [ %248, %212 ]
  %219 = add nsw i32 %216, %200
  %220 = icmp sgt i32 %134, %219
  br i1 %220, label %197, label %255

221:                                              ; preds = %247, %209
  %222 = phi %"struct.gemmlowp::BlockParams"* [ %248, %247 ], [ %198, %209 ]
  %223 = phi i32 [ %250, %247 ], [ %211, %209 ]
  %224 = phi i32 [ %253, %247 ], [ %207, %209 ]
  %225 = phi %"struct.gemmlowp::BlockParams"* [ %248, %247 ], [ %199, %209 ]
  %226 = phi i32 [ %251, %247 ], [ 0, %209 ]
  %227 = sub nsw i32 %224, %226
  %228 = icmp slt i32 %227, %223
  %229 = select i1 %228, i32 %227, i32 %223
  %230 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %225, i64 0, i32 4
  %231 = load i32, i32* %230, align 4
  %232 = icmp sgt i32 %231, 0
  br i1 %232, label %233, label %247

233:                                              ; preds = %221
  %234 = icmp sgt i32 %229, 0
  br label %235

235:                                              ; preds = %237, %233
  %236 = phi i32 [ 0, %233 ], [ %238, %237 ]
  br i1 %234, label %240, label %237

237:                                              ; preds = %240, %235
  %238 = add nuw nsw i32 %236, 4
  %239 = icmp slt i32 %238, %231
  br i1 %239, label %235, label %245

240:                                              ; preds = %235, %240
  %241 = phi i32 [ %243, %240 ], [ 0, %235 ]
  %242 = add nsw i32 %241, %226
  call void @_ZN8gemmlowp11ComputeImplINS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEES7_NS_12PackedResultEE10ComputeRunEiiii(%"class.gemmlowp::ComputeImpl"* nonnull %4, i32 %242, i32 %236, i32 %200, i32 %205) #19
  %243 = add nuw nsw i32 %241, 4
  %244 = icmp slt i32 %243, %229
  br i1 %244, label %240, label %237

245:                                              ; preds = %237
  %246 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %128, align 8
  br label %247

247:                                              ; preds = %245, %221
  %248 = phi %"struct.gemmlowp::BlockParams"* [ %246, %245 ], [ %222, %221 ]
  %249 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 0
  %250 = load i32, i32* %249, align 4
  %251 = add nsw i32 %250, %226
  %252 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 3
  %253 = load i32, i32* %252, align 4
  %254 = icmp sgt i32 %253, %251
  br i1 %254, label %221, label %212

255:                                              ; preds = %215, %183
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %127) #19
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %136) #19
  %256 = load i32, i32* %141, align 8
  %257 = add nsw i32 %256, %185
  %258 = load i32, i32* %142, align 4
  %259 = add nsw i32 %258, %166
  store i32 %257, i32* %137, align 4
  store i32 %259, i32* %138, align 4
  store i32 %188, i32* %139, align 4
  store i32 %171, i32* %140, align 4
  %260 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %21, align 8
  %261 = load i8, i8* %75, align 8
  %262 = zext i8 %261 to i64
  %263 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %260, i64 0, i32 5, i64 %262
  %264 = load i64, i64* %263, align 8
  %265 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %260, i64 0, i32 2
  %266 = bitcast i8** %265 to i64*
  %267 = load i64, i64* %266, align 8
  %268 = add i64 %267, %264
  %269 = inttoptr i64 %268 to i32*
  %270 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %144, align 8
  %271 = load i8, i8* %145, align 8
  %272 = zext i8 %271 to i64
  %273 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %270, i64 0, i32 5, i64 %272
  %274 = load i64, i64* %273, align 8
  %275 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %270, i64 0, i32 2
  %276 = bitcast i8** %275 to i64*
  %277 = load i64, i64* %276, align 8
  %278 = add i64 %277, %274
  %279 = inttoptr i64 %278 to i32*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %146) #19
  %280 = load %"class.gemmlowp::VectorDup.194"*, %"class.gemmlowp::VectorDup.194"** %147, align 8
  %281 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %280, i64 0, i32 0
  %282 = load i32, i32* %281, align 4, !noalias !695
  store i32 %282, i32* %148, align 4, !alias.scope !695
  store i32 %188, i32* %149, align 4, !alias.scope !695
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %150) #19
  %283 = load %"class.gemmlowp::VectorDup"*, %"class.gemmlowp::VectorDup"** %151, align 8
  %284 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %283, i64 0, i32 0
  %285 = load i32, i32* %284, align 4, !noalias !698
  store i32 %285, i32* %152, align 4, !alias.scope !698
  store i32 %171, i32* %153, align 4, !alias.scope !698
  %286 = load %"class.std::__1::tuple.197"*, %"class.std::__1::tuple.197"** %154, align 8
  call void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIhLNS_8MapOrderE1EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE1EEENSC_ISD_LSE_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISD_LSE_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SZ_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.195"* %143, %"struct.gemmlowp::MatrixBlockBounds"* nonnull dereferenceable(16) %7, %"class.gemmlowp::PackedResult"* nonnull dereferenceable(40) %6, i32 %15, i32* %269, i32* %279, %"class.gemmlowp::VectorDup.194"* nonnull dereferenceable(8) %8, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %9, %"class.std::__1::tuple.197"* dereferenceable(40) %286)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %150) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %146) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %136) #19
  %287 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %288 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %287, i64 0, i32 3
  %289 = load i32, i32* %288, align 4
  %290 = add nsw i32 %289, %185
  %291 = icmp sgt i32 %11, %290
  br i1 %291, label %183, label %175
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp11WorkersPool28LegacyExecuteAndDestroyTasksERKNSt3__16vectorIPNS_4TaskENS1_9allocatorIS4_EEEE(%"class.gemmlowp::WorkersPool"*, %"class.std::__1::vector.205"* dereferenceable(24)) local_unnamed_addr #1 comdat align 2 {
  %3 = alloca %"class.std::__1::chrono::duration.98", align 8
  %4 = getelementptr inbounds %"class.std::__1::vector.205", %"class.std::__1::vector.205"* %1, i64 0, i32 0, i32 1
  %5 = bitcast %"struct.gemmlowp::Task"*** %4 to i64*
  %6 = load i64, i64* %5, align 8
  %7 = bitcast %"class.std::__1::vector.205"* %1 to i64*
  %8 = load i64, i64* %7, align 8
  %9 = sub i64 %6, %8
  %10 = ashr exact i64 %9, 3
  %11 = add nsw i64 %10, -1
  tail call void @_ZN8gemmlowp11WorkersPool13CreateWorkersEm(%"class.gemmlowp::WorkersPool"* %0, i64 %11)
  %12 = getelementptr inbounds %"class.gemmlowp::WorkersPool", %"class.gemmlowp::WorkersPool"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %13 = load atomic i64, i64* %12 monotonic, align 8
  store atomic i64 %11, i64* %12 release, align 8
  %14 = icmp eq i64 %11, 0
  br i1 %14, label %18, label %15

15:                                               ; preds = %2
  %16 = getelementptr inbounds %"class.gemmlowp::WorkersPool", %"class.gemmlowp::WorkersPool"* %0, i64 0, i32 0, i32 0, i32 0
  %17 = getelementptr inbounds %"class.std::__1::vector.205", %"class.std::__1::vector.205"* %1, i64 0, i32 0, i32 0
  br label %60

18:                                               ; preds = %74, %2
  %19 = getelementptr inbounds %"class.std::__1::vector.205", %"class.std::__1::vector.205"* %1, i64 0, i32 0, i32 0
  %20 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %19, align 8
  %21 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %20, i64 %11
  %22 = load %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %21, align 8
  %23 = getelementptr inbounds %"class.gemmlowp::WorkersPool", %"class.gemmlowp::WorkersPool"* %0, i64 0, i32 2
  %24 = getelementptr inbounds %"struct.gemmlowp::Task", %"struct.gemmlowp::Task"* %22, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %23, %"class.gemmlowp::Allocator"** %24, align 8
  %25 = bitcast %"struct.gemmlowp::Task"* %22 to void (%"struct.gemmlowp::Task"*)***
  %26 = load void (%"struct.gemmlowp::Task"*)**, void (%"struct.gemmlowp::Task"*)*** %25, align 8
  %27 = getelementptr inbounds void (%"struct.gemmlowp::Task"*)*, void (%"struct.gemmlowp::Task"*)** %26, i64 2
  %28 = load void (%"struct.gemmlowp::Task"*)*, void (%"struct.gemmlowp::Task"*)** %27, align 8
  tail call void %28(%"struct.gemmlowp::Task"* %22) #19
  %29 = load atomic i64, i64* %12 acquire, align 8
  %30 = icmp eq i64 %29, 0
  br i1 %30, label %43, label %31

31:                                               ; preds = %18
  %32 = bitcast %"class.std::__1::chrono::duration.98"* %3 to i8*
  %33 = getelementptr inbounds %"class.std::__1::chrono::duration.98", %"class.std::__1::chrono::duration.98"* %3, i64 0, i32 0
  br label %34

34:                                               ; preds = %39, %31
  %35 = phi i32 [ 0, %31 ], [ %40, %39 ]
  call void asm sideeffect "nop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0Anop\0A", "~{dirflag},~{fpsr},~{flags}"() #19, !srcloc !301
  %36 = add nsw i32 %35, 64
  %37 = icmp sgt i32 %36, 4000000
  br i1 %37, label %38, label %39

38:                                               ; preds = %34
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %32) #19
  store i64 1000000, i64* %33, align 8
  call void @_ZNSt3__111this_thread9sleep_forERKNS_6chrono8durationIxNS_5ratioILl1ELl1000000000EEEEE(%"class.std::__1::chrono::duration.98"* nonnull dereferenceable(8) %3) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %32) #19
  br label %39

39:                                               ; preds = %38, %34
  %40 = phi i32 [ 0, %38 ], [ %36, %34 ]
  %41 = load atomic i64, i64* %12 acquire, align 8
  %42 = icmp eq i64 %41, 0
  br i1 %42, label %43, label %34

43:                                               ; preds = %39, %18
  %44 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %19, align 8
  %45 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %4, align 8
  %46 = icmp eq %"struct.gemmlowp::Task"** %44, %45
  br i1 %46, label %59, label %47

47:                                               ; preds = %43, %56
  %48 = phi %"struct.gemmlowp::Task"** [ %57, %56 ], [ %44, %43 ]
  %49 = load %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %48, align 8
  %50 = icmp eq %"struct.gemmlowp::Task"* %49, null
  br i1 %50, label %56, label %51

51:                                               ; preds = %47
  %52 = bitcast %"struct.gemmlowp::Task"* %49 to void (%"struct.gemmlowp::Task"*)***
  %53 = load void (%"struct.gemmlowp::Task"*)**, void (%"struct.gemmlowp::Task"*)*** %52, align 8
  %54 = getelementptr inbounds void (%"struct.gemmlowp::Task"*)*, void (%"struct.gemmlowp::Task"*)** %53, i64 1
  %55 = load void (%"struct.gemmlowp::Task"*)*, void (%"struct.gemmlowp::Task"*)** %54, align 8
  call void %55(%"struct.gemmlowp::Task"* nonnull %49) #19
  br label %56

56:                                               ; preds = %51, %47
  %57 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %48, i64 1
  %58 = icmp eq %"struct.gemmlowp::Task"** %57, %45
  br i1 %58, label %59, label %47

59:                                               ; preds = %56, %43
  ret void

60:                                               ; preds = %74, %15
  %61 = phi i64 [ 0, %15 ], [ %81, %74 ]
  %62 = load %"class.gemmlowp::Worker"**, %"class.gemmlowp::Worker"*** %16, align 8
  %63 = getelementptr inbounds %"class.gemmlowp::Worker"*, %"class.gemmlowp::Worker"** %62, i64 %61
  %64 = load %"class.gemmlowp::Worker"*, %"class.gemmlowp::Worker"** %63, align 8
  %65 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %17, align 8
  %66 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %65, i64 %61
  %67 = load %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %66, align 8
  %68 = getelementptr inbounds %"class.gemmlowp::Worker", %"class.gemmlowp::Worker"* %64, i64 0, i32 3
  %69 = tail call i32 @pthread_mutex_lock(%union.pthread_mutex_t* %68) #19
  %70 = getelementptr inbounds %"class.gemmlowp::Worker", %"class.gemmlowp::Worker"* %64, i64 0, i32 4, i32 0, i32 0, i32 0, i32 0
  %71 = load atomic i32, i32* %70 monotonic, align 4
  %72 = icmp ult i32 %71, 3
  br i1 %72, label %74, label %73

73:                                               ; preds = %60
  tail call void @abort() #20
  unreachable

74:                                               ; preds = %60
  %75 = getelementptr inbounds %"class.gemmlowp::Worker", %"class.gemmlowp::Worker"* %64, i64 0, i32 5
  %76 = getelementptr inbounds %"struct.gemmlowp::Task", %"struct.gemmlowp::Task"* %67, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %75, %"class.gemmlowp::Allocator"** %76, align 8
  %77 = getelementptr inbounds %"class.gemmlowp::Worker", %"class.gemmlowp::Worker"* %64, i64 0, i32 1
  store %"struct.gemmlowp::Task"* %67, %"struct.gemmlowp::Task"** %77, align 8
  store atomic i32 2, i32* %70 monotonic, align 4
  %78 = getelementptr inbounds %"class.gemmlowp::Worker", %"class.gemmlowp::Worker"* %64, i64 0, i32 2
  %79 = tail call i32 @pthread_cond_broadcast(%union.pthread_cond_t* %78) #19
  %80 = tail call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* %68) #19
  %81 = add nuw i64 %61, 1
  %82 = icmp eq i64 %81, %11
  br i1 %82, label %18, label %60
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSY_IS10_XT4_EEEPNSY_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::SingleThreadGemmContext"*, %"struct.gemmlowp::KernelBase"* dereferenceable(8), %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.180"* dereferenceable(24), %"class.gemmlowp::MatrixMap.182"*, %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.std::__1::tuple"* dereferenceable(40)) local_unnamed_addr #1 comdat {
  %9 = alloca %"class.gemmlowp::SideMap", align 8
  %10 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %11 = alloca %"class.gemmlowp::SideMap", align 8
  %12 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %13 = alloca %"class.gemmlowp::SideMap", align 8
  %14 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %15 = alloca %"class.gemmlowp::ComputeImpl", align 8
  %16 = alloca %"struct.gemmlowp::BlockParams", align 4
  %17 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %18 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %19 = alloca %"class.gemmlowp::PackedResult", align 8
  %20 = alloca %"struct.gemmlowp::MatrixBlockBounds", align 4
  %21 = alloca %"class.gemmlowp::VectorDup", align 4
  %22 = alloca %"class.gemmlowp::VectorDup.194", align 4
  %23 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %4, i64 0, i32 1
  %24 = load i32, i32* %23, align 8
  %25 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %4, i64 0, i32 2
  %26 = load i32, i32* %25, align 4
  %27 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 2
  %28 = load i32, i32* %27, align 4
  %29 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0
  %30 = bitcast %"struct.gemmlowp::BlockParams"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %30) #19
  %31 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 0
  %32 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 1
  %33 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 2
  %34 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 3
  %35 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 4
  %36 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 5
  %37 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 1
  %38 = bitcast %"struct.gemmlowp::BlockParams"* %16 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %38, i8 -86, i64 24, i1 false)
  %39 = load i32, i32* %37, align 8
  %40 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 2
  %41 = load i32, i32* %40, align 4
  %42 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 3
  %43 = load float, float* %42, align 8
  call void @_ZN8gemmlowp11BlockParams4InitINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES7_EEEEviiiiiif(%"struct.gemmlowp::BlockParams"* nonnull %16, i32 %24, i32 %26, i32 %28, i32 1, i32 %39, i32 %41, float %43)
  %44 = bitcast %"class.gemmlowp::PackedSideBlock"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %44) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %44, i8 -86, i64 80, i1 false)
  %45 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %45, align 8
  %46 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 4
  store i32 0, i32* %46, align 8
  %47 = load i32, i32* %31, align 4
  %48 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 0
  store i32 %47, i32* %48, align 8
  %49 = load i32, i32* %34, align 4
  %50 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 2
  store i32 %49, i32* %50, align 8
  %51 = load i32, i32* %33, align 4
  %52 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 1
  store i32 %51, i32* %52, align 4
  %53 = load i32, i32* %36, align 4
  %54 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 3
  store i32 %53, i32* %54, align 4
  %55 = mul nsw i32 %53, %49
  %56 = sext i32 %55 to i64
  %57 = add nsw i64 %56, 63
  %58 = and i64 %57, -64
  %59 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 4
  %60 = load i64, i64* %59, align 8, !noalias !701
  %61 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 3
  %62 = load i64, i64* %61, align 8, !noalias !701
  %63 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %62
  store i64 %60, i64* %63, align 8, !noalias !701
  %64 = trunc i64 %62 to i8
  %65 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 6
  %66 = load i64, i64* %65, align 8, !noalias !701
  %67 = load i64, i64* %61, align 8, !noalias !701
  %68 = add i64 %67, 1
  store i64 %68, i64* %61, align 8, !noalias !701
  %69 = load i64, i64* %59, align 8, !noalias !701
  %70 = add i64 %69, %58
  store i64 %70, i64* %59, align 8, !noalias !701
  %71 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 0
  store i8 %64, i8* %71, align 8
  %72 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %72, i8 -86, i64 7, i1 false) #19
  %73 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 2
  store i64 %66, i64* %73, align 8
  %74 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 3
  store i8 0, i8* %74, align 8
  %75 = sext i32 %49 to i64
  %76 = shl nsw i64 %75, 2
  %77 = add nsw i64 %76, 63
  %78 = and i64 %77, -64
  %79 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %68
  store i64 %70, i64* %79, align 8, !noalias !704
  %80 = trunc i64 %68 to i8
  %81 = load i64, i64* %65, align 8, !noalias !704
  %82 = load i64, i64* %61, align 8, !noalias !704
  %83 = add i64 %82, 1
  store i64 %83, i64* %61, align 8, !noalias !704
  %84 = load i64, i64* %59, align 8, !noalias !704
  %85 = add i64 %84, %78
  store i64 %85, i64* %59, align 8, !noalias !704
  %86 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 0
  store i8 %80, i8* %86, align 8
  %87 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %87, i8 -86, i64 7, i1 false) #19
  %88 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 2
  store i64 %81, i64* %88, align 8
  %89 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 3
  store i8 5, i8* %89, align 8
  %90 = bitcast %"class.gemmlowp::PackedSideBlock"* %18 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %90) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %90, i8 -86, i64 80, i1 false)
  %91 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %91, align 8
  %92 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 4
  store i32 0, i32* %92, align 8
  %93 = load i32, i32* %32, align 4
  %94 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 0
  store i32 %93, i32* %94, align 8
  %95 = load i32, i32* %35, align 4
  %96 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 2
  store i32 %95, i32* %96, align 8
  %97 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 1
  store i32 %51, i32* %97, align 4
  %98 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 3
  store i32 %53, i32* %98, align 4
  %99 = mul nsw i32 %53, %95
  %100 = sext i32 %99 to i64
  %101 = add nsw i64 %100, 63
  %102 = and i64 %101, -64
  %103 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %83
  store i64 %85, i64* %103, align 8, !noalias !707
  %104 = trunc i64 %83 to i8
  %105 = load i64, i64* %65, align 8, !noalias !707
  %106 = load i64, i64* %61, align 8, !noalias !707
  %107 = add i64 %106, 1
  store i64 %107, i64* %61, align 8, !noalias !707
  %108 = load i64, i64* %59, align 8, !noalias !707
  %109 = add i64 %108, %102
  store i64 %109, i64* %59, align 8, !noalias !707
  %110 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 0
  store i8 %104, i8* %110, align 8
  %111 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %111, i8 -86, i64 7, i1 false) #19
  %112 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 2
  store i64 %105, i64* %112, align 8
  %113 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 3
  store i8 0, i8* %113, align 8
  %114 = sext i32 %95 to i64
  %115 = shl nsw i64 %114, 2
  %116 = add nsw i64 %115, 63
  %117 = and i64 %116, -64
  %118 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %107
  store i64 %109, i64* %118, align 8, !noalias !710
  %119 = trunc i64 %107 to i8
  %120 = load i64, i64* %65, align 8, !noalias !710
  %121 = load i64, i64* %61, align 8, !noalias !710
  %122 = add i64 %121, 1
  store i64 %122, i64* %61, align 8, !noalias !710
  %123 = load i64, i64* %59, align 8, !noalias !710
  %124 = add i64 %123, %117
  store i64 %124, i64* %59, align 8, !noalias !710
  %125 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 0
  store i8 %119, i8* %125, align 8
  %126 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %126, i8 -86, i64 7, i1 false) #19
  %127 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 2
  store i64 %120, i64* %127, align 8
  %128 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 3
  store i8 5, i8* %128, align 8
  %129 = bitcast %"class.gemmlowp::PackedResult"* %19 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %129) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %129, i8 -86, i64 32, i1 false)
  %130 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 0
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %130, align 8
  %131 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 2
  store %"struct.gemmlowp::BlockParams"* %16, %"struct.gemmlowp::BlockParams"** %131, align 8
  %132 = load i32, i32* %34, align 4
  %133 = mul nsw i32 %95, %132
  %134 = sext i32 %133 to i64
  %135 = shl nsw i64 %134, 2
  %136 = add nsw i64 %135, 63
  %137 = and i64 %136, -64
  %138 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %122
  store i64 %124, i64* %138, align 8, !noalias !713
  %139 = trunc i64 %122 to i8
  %140 = load i64, i64* %65, align 8, !noalias !713
  %141 = bitcast i64* %61 to <2 x i64>*
  %142 = load <2 x i64>, <2 x i64>* %141, align 8, !noalias !713
  %143 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %137, i32 1
  %144 = add <2 x i64> %142, %143
  %145 = bitcast i64* %61 to <2 x i64>*
  store <2 x i64> %144, <2 x i64>* %145, align 8, !noalias !713
  %146 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 0
  store i8 %139, i8* %146, align 8
  %147 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %147, i8 -86, i64 7, i1 false) #19
  %148 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 2
  store i64 %140, i64* %148, align 8
  %149 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 3
  store i8 5, i8* %149, align 8
  call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %29)
  %150 = load i32, i32* %35, align 4
  %151 = icmp sge i32 %150, %26
  br i1 %151, label %152, label %169

152:                                              ; preds = %8
  %153 = bitcast %"class.gemmlowp::SideMap"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %153) #19
  %154 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 1
  %155 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 2
  %156 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 3
  %157 = bitcast %"class.gemmlowp::MatrixMap.180"* %3 to i64*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %153, i8 -86, i64 24, i1 false) #19
  %158 = load i64, i64* %157, align 8
  %159 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 2
  %160 = load i32, i32* %159, align 4
  %161 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 1
  %162 = load i32, i32* %161, align 8
  %163 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 3
  %164 = load i32, i32* %163, align 8
  %165 = bitcast %"class.gemmlowp::SideMap"* %9 to i64*
  store i64 %158, i64* %165, align 8
  store i32 %160, i32* %154, align 8
  store i32 %162, i32* %155, align 4
  store i32 %164, i32* %156, align 8
  %166 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %166) #19
  %167 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 0
  %168 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 1
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %167, align 8
  store %"class.gemmlowp::SideMap"* %9, %"class.gemmlowp::SideMap"** %168, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %10) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %166) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %153) #19
  br label %169

169:                                              ; preds = %152, %8
  %170 = icmp sgt i32 %24, 0
  br i1 %170, label %171, label %216

171:                                              ; preds = %169
  %172 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 0
  %173 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 3
  %174 = bitcast %"class.gemmlowp::SideMap"* %11 to i8*
  %175 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 1
  %176 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 2
  %177 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 3
  %178 = bitcast %"class.gemmlowp::SideMap"* %11 to i64*
  %179 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %12 to i8*
  %180 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %12, i64 0, i32 0
  %181 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %12, i64 0, i32 1
  %182 = icmp sgt i32 %26, 0
  %183 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 0
  %184 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 3
  %185 = bitcast %"class.gemmlowp::SideMap"* %13 to i8*
  %186 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 1
  %187 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 2
  %188 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 3
  %189 = bitcast %"class.gemmlowp::SideMap"* %13 to i64*
  %190 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %14 to i8*
  %191 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %14, i64 0, i32 0
  %192 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %14, i64 0, i32 1
  %193 = bitcast %"class.gemmlowp::ComputeImpl"* %15 to i8*
  %194 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 0
  %195 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 1
  %196 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 2
  %197 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 3
  %198 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 4
  %199 = add i32 %28, 15
  %200 = and i32 %199, -16
  %201 = icmp sgt i32 %200, 0
  %202 = bitcast %"struct.gemmlowp::MatrixBlockBounds"* %20 to i8*
  %203 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 0
  %204 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 1
  %205 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 2
  %206 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 3
  %207 = bitcast %"class.gemmlowp::VectorDup"* %21 to i8*
  %208 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %209 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %21, i64 0, i32 0
  %210 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %21, i64 0, i32 1
  %211 = bitcast %"class.gemmlowp::VectorDup.194"* %22 to i8*
  %212 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %6, i64 0, i32 0
  %213 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %22, i64 0, i32 0
  %214 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %22, i64 0, i32 1
  %215 = load i32, i32* %34, align 4
  br label %221

216:                                              ; preds = %235, %169
  %217 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 0
  store i8 0, i8* %217, align 8
  %218 = load i64, i64* %65, align 8
  %219 = add i64 %218, 1
  store i64 %219, i64* %65, align 8
  %220 = bitcast i64* %61 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %220, i8 0, i64 16, i1 false) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %129) #19
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %90) #19
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %44) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %30) #19
  ret void

221:                                              ; preds = %171, %235
  %222 = phi i32 [ %215, %171 ], [ %236, %235 ]
  %223 = phi i32 [ 0, %171 ], [ %237, %235 ]
  %224 = sub nsw i32 %24, %223
  %225 = icmp slt i32 %224, %222
  %226 = select i1 %225, i32 %224, i32 %222
  %227 = load i8*, i8** %172, align 8, !noalias !716
  %228 = load i32, i32* %173, align 8, !noalias !716
  %229 = mul nsw i32 %228, %223
  %230 = sext i32 %229 to i64
  %231 = getelementptr inbounds i8, i8* %227, i64 %230
  %232 = ptrtoint i8* %231 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %174) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %174, i8 -86, i64 24, i1 false) #19
  store i64 %232, i64* %178, align 8
  store i32 %226, i32* %175, align 8
  store i32 %28, i32* %176, align 4
  store i32 %228, i32* %177, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %179) #19
  store %"class.gemmlowp::PackedSideBlock"* %17, %"class.gemmlowp::PackedSideBlock"** %180, align 8
  store %"class.gemmlowp::SideMap"* %11, %"class.gemmlowp::SideMap"** %181, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %12) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %179) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %174) #19
  br i1 %182, label %233, label %235

233:                                              ; preds = %221
  %234 = load i32, i32* %35, align 4
  br label %239

235:                                              ; preds = %311, %221
  %236 = load i32, i32* %34, align 4
  %237 = add nsw i32 %236, %223
  %238 = icmp sgt i32 %24, %237
  br i1 %238, label %221, label %216

239:                                              ; preds = %233, %311
  %240 = phi i32 [ %334, %311 ], [ %234, %233 ]
  %241 = phi i32 [ %335, %311 ], [ 0, %233 ]
  %242 = sub nsw i32 %26, %241
  %243 = icmp slt i32 %242, %240
  %244 = select i1 %243, i32 %242, i32 %240
  br i1 %151, label %252, label %245

245:                                              ; preds = %239
  %246 = load i8*, i8** %183, align 8, !noalias !719
  %247 = load i32, i32* %184, align 8, !noalias !719
  %248 = mul nsw i32 %247, %241
  %249 = sext i32 %248 to i64
  %250 = getelementptr inbounds i8, i8* %246, i64 %249
  %251 = ptrtoint i8* %250 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %185) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %185, i8 -86, i64 24, i1 false) #19
  store i64 %251, i64* %189, align 8
  store i32 %244, i32* %186, align 8
  store i32 %28, i32* %187, align 4
  store i32 %247, i32* %188, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %190) #19
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %191, align 8
  store %"class.gemmlowp::SideMap"* %13, %"class.gemmlowp::SideMap"** %192, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %14) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %190) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %185) #19
  br label %252

252:                                              ; preds = %245, %239
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %193) #19
  store %"struct.gemmlowp::KernelBase"* %1, %"struct.gemmlowp::KernelBase"** %194, align 8
  store %"struct.gemmlowp::BlockParams"* %16, %"struct.gemmlowp::BlockParams"** %195, align 8
  store %"class.gemmlowp::PackedResult"* %19, %"class.gemmlowp::PackedResult"** %196, align 8
  store %"class.gemmlowp::PackedSideBlock"* %17, %"class.gemmlowp::PackedSideBlock"** %197, align 8
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %198, align 8
  br i1 %201, label %253, label %311

253:                                              ; preds = %252, %271
  %254 = phi %"struct.gemmlowp::BlockParams"* [ %273, %271 ], [ %16, %252 ]
  %255 = phi %"struct.gemmlowp::BlockParams"* [ %274, %271 ], [ %16, %252 ]
  %256 = phi i32 [ %275, %271 ], [ 0, %252 ]
  %257 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 2
  %258 = sub nsw i32 %200, %256
  %259 = load i32, i32* %257, align 4
  %260 = icmp slt i32 %258, %259
  %261 = select i1 %260, i32 %258, i32 %259
  %262 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 3
  %263 = load i32, i32* %262, align 4
  %264 = icmp sgt i32 %263, 0
  br i1 %264, label %265, label %271

265:                                              ; preds = %253
  %266 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 0
  %267 = load i32, i32* %266, align 4
  br label %277

268:                                              ; preds = %303
  %269 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 2
  %270 = load i32, i32* %269, align 4
  br label %271

271:                                              ; preds = %268, %253
  %272 = phi i32 [ %259, %253 ], [ %270, %268 ]
  %273 = phi %"struct.gemmlowp::BlockParams"* [ %254, %253 ], [ %304, %268 ]
  %274 = phi %"struct.gemmlowp::BlockParams"* [ %255, %253 ], [ %304, %268 ]
  %275 = add nsw i32 %272, %256
  %276 = icmp sgt i32 %200, %275
  br i1 %276, label %253, label %311

277:                                              ; preds = %303, %265
  %278 = phi %"struct.gemmlowp::BlockParams"* [ %304, %303 ], [ %254, %265 ]
  %279 = phi i32 [ %306, %303 ], [ %267, %265 ]
  %280 = phi i32 [ %309, %303 ], [ %263, %265 ]
  %281 = phi %"struct.gemmlowp::BlockParams"* [ %304, %303 ], [ %255, %265 ]
  %282 = phi i32 [ %307, %303 ], [ 0, %265 ]
  %283 = sub nsw i32 %280, %282
  %284 = icmp slt i32 %283, %279
  %285 = select i1 %284, i32 %283, i32 %279
  %286 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %281, i64 0, i32 4
  %287 = load i32, i32* %286, align 4
  %288 = icmp sgt i32 %287, 0
  br i1 %288, label %289, label %303

289:                                              ; preds = %277
  %290 = icmp sgt i32 %285, 0
  br label %291

291:                                              ; preds = %293, %289
  %292 = phi i32 [ 0, %289 ], [ %294, %293 ]
  br i1 %290, label %296, label %293

293:                                              ; preds = %296, %291
  %294 = add nuw nsw i32 %292, 4
  %295 = icmp slt i32 %294, %287
  br i1 %295, label %291, label %301

296:                                              ; preds = %291, %296
  %297 = phi i32 [ %299, %296 ], [ 0, %291 ]
  %298 = add nsw i32 %297, %282
  call void @_ZN8gemmlowp11ComputeImplINS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEES7_NS_12PackedResultEE10ComputeRunEiiii(%"class.gemmlowp::ComputeImpl"* nonnull %15, i32 %298, i32 %292, i32 %256, i32 %261) #19
  %299 = add nuw nsw i32 %297, 4
  %300 = icmp slt i32 %299, %285
  br i1 %300, label %296, label %293

301:                                              ; preds = %293
  %302 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %195, align 8
  br label %303

303:                                              ; preds = %301, %277
  %304 = phi %"struct.gemmlowp::BlockParams"* [ %302, %301 ], [ %278, %277 ]
  %305 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 0
  %306 = load i32, i32* %305, align 4
  %307 = add nsw i32 %306, %282
  %308 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 3
  %309 = load i32, i32* %308, align 4
  %310 = icmp sgt i32 %309, %307
  br i1 %310, label %277, label %268

311:                                              ; preds = %271, %252
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %193) #19
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %202) #19
  store i32 %223, i32* %203, align 4
  store i32 %241, i32* %204, align 4
  store i32 %226, i32* %205, align 4
  store i32 %244, i32* %206, align 4
  %312 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %45, align 8
  %313 = load i8, i8* %86, align 8
  %314 = zext i8 %313 to i64
  %315 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %312, i64 0, i32 5, i64 %314
  %316 = load i64, i64* %315, align 8
  %317 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %312, i64 0, i32 2
  %318 = bitcast i8** %317 to i64*
  %319 = load i64, i64* %318, align 8
  %320 = add i64 %319, %316
  %321 = inttoptr i64 %320 to i32*
  %322 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %91, align 8
  %323 = load i8, i8* %125, align 8
  %324 = zext i8 %323 to i64
  %325 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %322, i64 0, i32 5, i64 %324
  %326 = load i64, i64* %325, align 8
  %327 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %322, i64 0, i32 2
  %328 = bitcast i8** %327 to i64*
  %329 = load i64, i64* %328, align 8
  %330 = add i64 %329, %326
  %331 = inttoptr i64 %330 to i32*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %207) #19
  %332 = load i32, i32* %208, align 4, !noalias !722
  store i32 %332, i32* %209, align 4, !alias.scope !722
  store i32 %226, i32* %210, align 4, !alias.scope !722
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %211) #19
  %333 = load i32, i32* %212, align 4, !noalias !725
  store i32 %333, i32* %213, align 4, !alias.scope !725
  store i32 %244, i32* %214, align 4, !alias.scope !725
  call void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIhLNS_8MapOrderE0EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE0EEENSC_ISD_LSE_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISD_LSE_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SZ_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.182"* %4, %"struct.gemmlowp::MatrixBlockBounds"* nonnull dereferenceable(16) %20, %"class.gemmlowp::PackedResult"* nonnull dereferenceable(40) %19, i32 %28, i32* %321, i32* %331, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %21, %"class.gemmlowp::VectorDup.194"* nonnull dereferenceable(8) %22, %"class.std::__1::tuple"* dereferenceable(40) %7)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %211) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %207) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %202) #19
  %334 = load i32, i32* %35, align 4
  %335 = add nsw i32 %334, %241
  %336 = icmp sgt i32 %26, %335
  br i1 %336, label %239, label %235
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIhLNS_8MapOrderE0EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE0EEENSC_ISD_LSE_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISD_LSE_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SZ_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.182"*, %"struct.gemmlowp::MatrixBlockBounds"* dereferenceable(16), %"class.gemmlowp::PackedResult"* dereferenceable(40), i32, i32*, i32*, %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.std::__1::tuple"* dereferenceable(40)) local_unnamed_addr #1 comdat {
  %10 = alloca %"class.gemmlowp::MatrixMap.214", align 8
  %11 = alloca %"class.gemmlowp::VectorMap", align 8
  %12 = alloca %"class.gemmlowp::VectorMap.201", align 8
  %13 = alloca %"struct.gemmlowp::OutputPipelineExecutor.329", align 8
  %14 = alloca %"struct.gemmlowp::OutputPipelineExecutor.338", align 8
  %15 = alloca %"struct.gemmlowp::OutputPipelineExecutor.347", align 8
  %16 = alloca %"struct.gemmlowp::OutputPipelineExecutor.356", align 8
  %17 = alloca %"struct.gemmlowp::OutputPipelineExecutor.365", align 8
  %18 = alloca %"struct.gemmlowp::OutputPipelineExecutor.374", align 8
  %19 = bitcast %"class.gemmlowp::MatrixMap.214"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %19) #19
  %20 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %10, i64 0, i32 0
  %21 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %10, i64 0, i32 1
  %22 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %10, i64 0, i32 2
  %23 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %10, i64 0, i32 3
  %24 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 0
  %25 = bitcast %"class.gemmlowp::MatrixMap.214"* %10 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %25, i8 -86, i64 24, i1 false)
  %26 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %24, align 8, !noalias !728
  %27 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 1, i32 0
  %28 = load i8, i8* %27, align 8, !noalias !728
  %29 = zext i8 %28 to i64
  %30 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %26, i64 0, i32 5, i64 %29
  %31 = load i64, i64* %30, align 8, !noalias !728
  %32 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %26, i64 0, i32 2
  %33 = bitcast i8** %32 to i64*
  %34 = load i64, i64* %33, align 8, !noalias !728
  %35 = add i64 %34, %31
  %36 = inttoptr i64 %35 to i32*
  %37 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 2
  %38 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %37, align 8, !noalias !728
  %39 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %38, i64 0, i32 3
  %40 = load i32, i32* %39, align 4, !noalias !728
  %41 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %38, i64 0, i32 4
  %42 = load i32, i32* %41, align 4, !noalias !728
  store i32* %36, i32** %20, align 8, !alias.scope !728
  store i32 %40, i32* %21, align 8, !alias.scope !728
  store i32 %42, i32* %22, align 4, !alias.scope !728
  store i32 %40, i32* %23, align 8, !alias.scope !728
  %43 = bitcast %"class.gemmlowp::VectorMap"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %43) #19
  %44 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %11, i64 0, i32 0
  %45 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %11, i64 0, i32 1
  %46 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 2
  %47 = bitcast %"class.gemmlowp::VectorMap"* %11 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %47, i8 -86, i64 16, i1 false)
  %48 = load i32, i32* %46, align 4
  store i32* %4, i32** %44, align 8
  store i32 %48, i32* %45, align 8
  %49 = bitcast %"class.gemmlowp::VectorMap.201"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %49) #19
  %50 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %12, i64 0, i32 0
  %51 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %12, i64 0, i32 1
  %52 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 3
  %53 = bitcast %"class.gemmlowp::VectorMap.201"* %12 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %53, i8 -86, i64 16, i1 false)
  %54 = load i32, i32* %52, align 4
  store i32* %5, i32** %50, align 8
  store i32 %54, i32* %51, align 8
  %55 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.329"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %55) #19
  %56 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.329", %"struct.gemmlowp::OutputPipelineExecutor.329"* %13, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %57 = bitcast i8* %56 to i64*
  store i64 -6148914691236517206, i64* %57, align 8
  %58 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %8, i64 0, i32 0, i32 0, i32 0
  %59 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.329", %"struct.gemmlowp::OutputPipelineExecutor.329"* %13, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition"* %58, %"struct.gemmlowp::OutputStageBiasAddition"** %59, align 8
  %60 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %8, i64 0, i32 0, i32 1, i32 0
  %61 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.329", %"struct.gemmlowp::OutputPipelineExecutor.329"* %13, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %60, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %61, align 8
  %62 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %8, i64 0, i32 0, i32 1, i32 0, i32 1
  %63 = load i32, i32* %62, align 4
  %64 = icmp sgt i32 %63, 0
  %65 = select i1 %64, i32 %63, i32 0
  %66 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.329", %"struct.gemmlowp::OutputPipelineExecutor.329"* %13, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %65, i32* %66, align 8
  %67 = sub nsw i32 0, %63
  %68 = icmp sgt i32 %67, 0
  %69 = select i1 %68, i32 %67, i32 0
  %70 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.329", %"struct.gemmlowp::OutputPipelineExecutor.329"* %13, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %69, i32* %70, align 4
  %71 = getelementptr inbounds %"class.std::__1::tuple", %"class.std::__1::tuple"* %8, i64 0, i32 0, i32 2, i32 0
  %72 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.329", %"struct.gemmlowp::OutputPipelineExecutor.329"* %13, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %71, %"struct.gemmlowp::OutputStageClamp"** %72, align 8
  %73 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.338"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %73) #19
  %74 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.338", %"struct.gemmlowp::OutputPipelineExecutor.338"* %14, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %75 = bitcast i8* %74 to i64*
  store i64 -6148914691236517206, i64* %75, align 8
  %76 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.338", %"struct.gemmlowp::OutputPipelineExecutor.338"* %14, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition"* %58, %"struct.gemmlowp::OutputStageBiasAddition"** %76, align 8
  %77 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.338", %"struct.gemmlowp::OutputPipelineExecutor.338"* %14, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %60, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %77, align 8
  %78 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.338", %"struct.gemmlowp::OutputPipelineExecutor.338"* %14, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %65, i32* %78, align 8
  %79 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.338", %"struct.gemmlowp::OutputPipelineExecutor.338"* %14, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %69, i32* %79, align 4
  %80 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.338", %"struct.gemmlowp::OutputPipelineExecutor.338"* %14, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %71, %"struct.gemmlowp::OutputStageClamp"** %80, align 8
  %81 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.347"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %81) #19
  %82 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.347", %"struct.gemmlowp::OutputPipelineExecutor.347"* %15, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %83 = bitcast i8* %82 to i64*
  store i64 -6148914691236517206, i64* %83, align 8
  %84 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.347", %"struct.gemmlowp::OutputPipelineExecutor.347"* %15, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition"* %58, %"struct.gemmlowp::OutputStageBiasAddition"** %84, align 8
  %85 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.347", %"struct.gemmlowp::OutputPipelineExecutor.347"* %15, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %60, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %85, align 8
  %86 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.347", %"struct.gemmlowp::OutputPipelineExecutor.347"* %15, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %65, i32* %86, align 8
  %87 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.347", %"struct.gemmlowp::OutputPipelineExecutor.347"* %15, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %69, i32* %87, align 4
  %88 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.347", %"struct.gemmlowp::OutputPipelineExecutor.347"* %15, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %71, %"struct.gemmlowp::OutputStageClamp"** %88, align 8
  %89 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.356"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %89) #19
  %90 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.356", %"struct.gemmlowp::OutputPipelineExecutor.356"* %16, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %91 = bitcast i8* %90 to i64*
  store i64 -6148914691236517206, i64* %91, align 8
  %92 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.356", %"struct.gemmlowp::OutputPipelineExecutor.356"* %16, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition"* %58, %"struct.gemmlowp::OutputStageBiasAddition"** %92, align 8
  %93 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.356", %"struct.gemmlowp::OutputPipelineExecutor.356"* %16, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %60, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %93, align 8
  %94 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.356", %"struct.gemmlowp::OutputPipelineExecutor.356"* %16, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %65, i32* %94, align 8
  %95 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.356", %"struct.gemmlowp::OutputPipelineExecutor.356"* %16, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %69, i32* %95, align 4
  %96 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.356", %"struct.gemmlowp::OutputPipelineExecutor.356"* %16, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %71, %"struct.gemmlowp::OutputStageClamp"** %96, align 8
  %97 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.365"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %97) #19
  %98 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.365", %"struct.gemmlowp::OutputPipelineExecutor.365"* %17, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %99 = bitcast i8* %98 to i64*
  store i64 -6148914691236517206, i64* %99, align 8
  %100 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.365", %"struct.gemmlowp::OutputPipelineExecutor.365"* %17, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition"* %58, %"struct.gemmlowp::OutputStageBiasAddition"** %100, align 8
  %101 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.365", %"struct.gemmlowp::OutputPipelineExecutor.365"* %17, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %60, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %101, align 8
  %102 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.365", %"struct.gemmlowp::OutputPipelineExecutor.365"* %17, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %65, i32* %102, align 8
  %103 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.365", %"struct.gemmlowp::OutputPipelineExecutor.365"* %17, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %69, i32* %103, align 4
  %104 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.365", %"struct.gemmlowp::OutputPipelineExecutor.365"* %17, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %71, %"struct.gemmlowp::OutputStageClamp"** %104, align 8
  %105 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.374"* %18 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %105) #19
  %106 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.374", %"struct.gemmlowp::OutputPipelineExecutor.374"* %18, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %107 = bitcast i8* %106 to i64*
  store i64 -6148914691236517206, i64* %107, align 8
  %108 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.374", %"struct.gemmlowp::OutputPipelineExecutor.374"* %18, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition"* %58, %"struct.gemmlowp::OutputStageBiasAddition"** %108, align 8
  %109 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.374", %"struct.gemmlowp::OutputPipelineExecutor.374"* %18, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %60, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %109, align 8
  %110 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.374", %"struct.gemmlowp::OutputPipelineExecutor.374"* %18, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %65, i32* %110, align 8
  %111 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.374", %"struct.gemmlowp::OutputPipelineExecutor.374"* %18, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %69, i32* %111, align 4
  %112 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.374", %"struct.gemmlowp::OutputPipelineExecutor.374"* %18, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %71, %"struct.gemmlowp::OutputStageClamp"** %112, align 8
  %113 = icmp slt i32 %54, 4
  br i1 %113, label %122, label %114

114:                                              ; preds = %9
  %115 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 1
  %116 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 0
  %117 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %118 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %7, i64 0, i32 0
  %119 = load i32, i32* %46, align 4
  br label %133

120:                                              ; preds = %304
  %121 = trunc i64 %306 to i32
  br label %122

122:                                              ; preds = %120, %9
  %123 = phi i32 [ %54, %9 ], [ %307, %120 ]
  %124 = phi i32 [ 0, %9 ], [ %121, %120 ]
  %125 = icmp slt i32 %124, %123
  br i1 %125, label %126, label %450

126:                                              ; preds = %122
  %127 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 1
  %128 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 0
  %129 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %130 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %7, i64 0, i32 0
  %131 = zext i32 %124 to i64
  %132 = load i32, i32* %46, align 4
  br label %311

133:                                              ; preds = %114, %304
  %134 = phi i32 [ %119, %114 ], [ %305, %304 ]
  %135 = phi i64 [ 0, %114 ], [ %306, %304 ]
  %136 = load i32, i32* %115, align 4
  %137 = trunc i64 %135 to i32
  %138 = add nsw i32 %136, %137
  %139 = load i32*, i32** %20, align 8
  %140 = load i32, i32* %23, align 8
  %141 = mul nsw i32 %140, %137
  %142 = sext i32 %141 to i64
  %143 = load i32*, i32** %44, align 8
  %144 = bitcast i32* %143 to i8*
  call void @llvm.prefetch(i8* %144, i32 0, i32 3, i32 1) #19
  %145 = getelementptr inbounds i32, i32* %143, i64 4
  %146 = bitcast i32* %145 to i8*
  call void @llvm.prefetch(i8* %146, i32 0, i32 3, i32 1) #19
  %147 = getelementptr inbounds i32, i32* %139, i64 %142
  %148 = sext i32 %140 to i64
  %149 = bitcast i32* %147 to i8*
  call void @llvm.prefetch(i8* %149, i32 0, i32 3, i32 1) #19
  %150 = getelementptr inbounds i32, i32* %147, i64 4
  %151 = bitcast i32* %150 to i8*
  call void @llvm.prefetch(i8* %151, i32 0, i32 3, i32 1) #19
  %152 = getelementptr inbounds i32, i32* %147, i64 %148
  %153 = bitcast i32* %152 to i8*
  call void @llvm.prefetch(i8* %153, i32 0, i32 3, i32 1) #19
  %154 = getelementptr inbounds i32, i32* %152, i64 4
  %155 = bitcast i32* %154 to i8*
  call void @llvm.prefetch(i8* %155, i32 0, i32 3, i32 1) #19
  %156 = shl nsw i64 %148, 1
  %157 = getelementptr inbounds i32, i32* %147, i64 %156
  %158 = bitcast i32* %157 to i8*
  call void @llvm.prefetch(i8* %158, i32 0, i32 3, i32 1) #19
  %159 = getelementptr inbounds i32, i32* %157, i64 4
  %160 = bitcast i32* %159 to i8*
  call void @llvm.prefetch(i8* %160, i32 0, i32 3, i32 1) #19
  %161 = mul nsw i64 %148, 3
  %162 = getelementptr inbounds i32, i32* %147, i64 %161
  %163 = bitcast i32* %162 to i8*
  call void @llvm.prefetch(i8* %163, i32 0, i32 3, i32 1) #19
  %164 = getelementptr inbounds i32, i32* %162, i64 4
  %165 = bitcast i32* %164 to i8*
  call void @llvm.prefetch(i8* %165, i32 0, i32 3, i32 1) #19
  %166 = icmp slt i32 %134, 8
  br i1 %166, label %169, label %174

167:                                              ; preds = %174
  %168 = trunc i64 %182 to i32
  br label %169

169:                                              ; preds = %167, %133
  %170 = phi i32 [ %134, %133 ], [ %209, %167 ]
  %171 = phi i32 [ 0, %133 ], [ %168, %167 ]
  %172 = add nsw i32 %170, -4
  %173 = icmp sgt i32 %171, %172
  br i1 %173, label %217, label %226

174:                                              ; preds = %133, %213
  %175 = phi i32* [ %216, %213 ], [ %143, %133 ]
  %176 = phi i32 [ %215, %213 ], [ %140, %133 ]
  %177 = phi i32* [ %214, %213 ], [ %139, %133 ]
  %178 = phi i64 [ %182, %213 ], [ 0, %133 ]
  %179 = load i32, i32* %116, align 4
  %180 = trunc i64 %178 to i32
  %181 = add nsw i32 %179, %180
  %182 = add nuw i64 %178, 8
  %183 = mul nsw i32 %176, %137
  %184 = sext i32 %183 to i64
  %185 = getelementptr inbounds i32, i32* %175, i64 %182
  %186 = bitcast i32* %185 to i8*
  call void @llvm.prefetch(i8* %186, i32 0, i32 3, i32 1) #19
  %187 = getelementptr inbounds i32, i32* %185, i64 4
  %188 = bitcast i32* %187 to i8*
  call void @llvm.prefetch(i8* %188, i32 0, i32 3, i32 1) #19
  %189 = getelementptr inbounds i32, i32* %177, i64 %182
  %190 = getelementptr inbounds i32, i32* %189, i64 %184
  %191 = sext i32 %176 to i64
  %192 = bitcast i32* %190 to i8*
  call void @llvm.prefetch(i8* %192, i32 0, i32 3, i32 1) #19
  %193 = getelementptr inbounds i32, i32* %190, i64 4
  %194 = bitcast i32* %193 to i8*
  call void @llvm.prefetch(i8* %194, i32 0, i32 3, i32 1) #19
  %195 = getelementptr inbounds i32, i32* %190, i64 %191
  %196 = bitcast i32* %195 to i8*
  call void @llvm.prefetch(i8* %196, i32 0, i32 3, i32 1) #19
  %197 = getelementptr inbounds i32, i32* %195, i64 4
  %198 = bitcast i32* %197 to i8*
  call void @llvm.prefetch(i8* %198, i32 0, i32 3, i32 1) #19
  %199 = shl nsw i64 %191, 1
  %200 = getelementptr inbounds i32, i32* %190, i64 %199
  %201 = bitcast i32* %200 to i8*
  call void @llvm.prefetch(i8* %201, i32 0, i32 3, i32 1) #19
  %202 = getelementptr inbounds i32, i32* %200, i64 4
  %203 = bitcast i32* %202 to i8*
  call void @llvm.prefetch(i8* %203, i32 0, i32 3, i32 1) #19
  %204 = mul nsw i64 %191, 3
  %205 = getelementptr inbounds i32, i32* %190, i64 %204
  %206 = bitcast i32* %205 to i8*
  call void @llvm.prefetch(i8* %206, i32 0, i32 3, i32 1) #19
  %207 = getelementptr inbounds i32, i32* %205, i64 4
  %208 = bitcast i32* %207 to i8*
  call void @llvm.prefetch(i8* %208, i32 0, i32 3, i32 1) #19
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %10, %"struct.gemmlowp::OutputPipelineExecutor.374"* nonnull dereferenceable(40) %18, %"class.gemmlowp::MatrixMap.182"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %11, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorDup"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %7, i32 %3, i32 %180, i32 %137, i32 %181, i32 %138, i32 %181, i32 %138)
  %209 = load i32, i32* %46, align 4
  %210 = add nsw i32 %209, -8
  %211 = trunc i64 %182 to i32
  %212 = icmp slt i32 %210, %211
  br i1 %212, label %167, label %213

213:                                              ; preds = %174
  %214 = load i32*, i32** %20, align 8
  %215 = load i32, i32* %23, align 8
  %216 = load i32*, i32** %44, align 8
  br label %174

217:                                              ; preds = %226, %169
  %218 = phi i32 [ %170, %169 ], [ %231, %226 ]
  %219 = phi i32 [ %171, %169 ], [ %230, %226 ]
  %220 = icmp slt i32 %219, %218
  br i1 %220, label %221, label %304

221:                                              ; preds = %217
  %222 = or i64 %135, 1
  %223 = or i64 %135, 2
  %224 = or i64 %135, 3
  %225 = zext i32 %219 to i64
  br label %234

226:                                              ; preds = %169, %226
  %227 = phi i32 [ %230, %226 ], [ %171, %169 ]
  %228 = load i32, i32* %116, align 4
  %229 = add nsw i32 %228, %227
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %10, %"struct.gemmlowp::OutputPipelineExecutor.365"* nonnull dereferenceable(40) %17, %"class.gemmlowp::MatrixMap.182"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %11, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorDup"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %7, i32 %3, i32 %227, i32 %137, i32 %229, i32 %138, i32 %229, i32 %138)
  %230 = add nuw nsw i32 %227, 4
  %231 = load i32, i32* %46, align 4
  %232 = add nsw i32 %231, -4
  %233 = icmp sgt i32 %230, %232
  br i1 %233, label %217, label %226

234:                                              ; preds = %221, %234
  %235 = phi i64 [ %225, %221 ], [ %300, %234 ]
  %236 = load i32, i32* %116, align 4
  %237 = trunc i64 %235 to i32
  %238 = add nsw i32 %236, %237
  %239 = load i32*, i32** %20, align 8
  %240 = getelementptr inbounds i32, i32* %239, i64 %235
  %241 = load i32, i32* %23, align 8
  %242 = mul nsw i32 %241, %137
  %243 = sext i32 %242 to i64
  %244 = getelementptr inbounds i32, i32* %240, i64 %243
  %245 = load i32, i32* %244, align 4
  %246 = sext i32 %241 to i64
  %247 = mul nsw i64 %222, %246
  %248 = getelementptr inbounds i32, i32* %240, i64 %247
  %249 = load i32, i32* %248, align 4
  %250 = mul nsw i64 %223, %246
  %251 = getelementptr inbounds i32, i32* %240, i64 %250
  %252 = load i32, i32* %251, align 4
  %253 = mul nsw i64 %224, %246
  %254 = getelementptr inbounds i32, i32* %240, i64 %253
  %255 = load i32, i32* %254, align 4
  %256 = load i32*, i32** %44, align 8
  %257 = getelementptr inbounds i32, i32* %256, i64 %235
  %258 = load i32, i32* %257, align 4
  %259 = load i32*, i32** %50, align 8
  %260 = getelementptr i32, i32* %259, i64 %135
  %261 = bitcast i32* %260 to i64*
  %262 = load i64, i64* %261, align 4
  %263 = getelementptr inbounds i32, i32* %260, i64 2
  %264 = bitcast i32* %263 to i64*
  %265 = load i64, i64* %264, align 4
  %266 = trunc i64 %262 to i32
  %267 = lshr i64 %262, 32
  %268 = trunc i64 %267 to i32
  %269 = load i32, i32* %117, align 4
  %270 = load i32, i32* %118, align 4
  %271 = mul nsw i32 %270, %258
  %272 = add nsw i32 %271, %245
  %273 = add nsw i32 %271, %249
  %274 = add nsw i32 %271, %252
  %275 = add nsw i32 %271, %255
  %276 = mul nsw i32 %270, %3
  %277 = add nsw i32 %276, %266
  %278 = add nsw i32 %276, %268
  %279 = trunc i64 %265 to i32
  %280 = add nsw i32 %276, %279
  %281 = lshr i64 %265, 32
  %282 = trunc i64 %281 to i32
  %283 = add nsw i32 %276, %282
  %284 = mul nsw i32 %277, %269
  %285 = add nsw i32 %272, %284
  %286 = mul nsw i32 %278, %269
  %287 = add nsw i32 %273, %286
  %288 = mul nsw i32 %280, %269
  %289 = add nsw i32 %274, %288
  %290 = zext i32 %289 to i64
  %291 = mul nsw i32 %283, %269
  %292 = add nsw i32 %275, %291
  %293 = zext i32 %292 to i64
  %294 = shl nuw i64 %293, 32
  %295 = or i64 %294, %290
  %296 = zext i32 %287 to i64
  %297 = shl nuw i64 %296, 32
  %298 = zext i32 %285 to i64
  %299 = or i64 %297, %298
  call void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_13RegisterBlockIiLi1ELi4EEEE7ExecuteINS_9MatrixMapIhLNS_8MapOrderE0EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.356"* nonnull %16, i64 %299, i64 %295, %"class.gemmlowp::MatrixMap.182"* %0, i32 %238, i32 %138, i32 %238, i32 %138) #19
  %300 = add nuw nsw i64 %235, 1
  %301 = load i32, i32* %46, align 4
  %302 = trunc i64 %300 to i32
  %303 = icmp sgt i32 %301, %302
  br i1 %303, label %234, label %304

304:                                              ; preds = %234, %217
  %305 = phi i32 [ %218, %217 ], [ %301, %234 ]
  %306 = add nuw i64 %135, 4
  %307 = load i32, i32* %52, align 4
  %308 = add nsw i32 %307, -4
  %309 = trunc i64 %306 to i32
  %310 = icmp slt i32 %308, %309
  br i1 %310, label %120, label %133

311:                                              ; preds = %126, %444
  %312 = phi i32 [ %132, %126 ], [ %445, %444 ]
  %313 = phi i64 [ %131, %126 ], [ %446, %444 ]
  %314 = load i32, i32* %127, align 4
  %315 = trunc i64 %313 to i32
  %316 = add nsw i32 %314, %315
  %317 = load i32*, i32** %20, align 8
  %318 = load i32, i32* %23, align 8
  %319 = mul nsw i32 %318, %315
  %320 = sext i32 %319 to i64
  %321 = load i32*, i32** %44, align 8
  %322 = bitcast i32* %321 to i8*
  call void @llvm.prefetch(i8* %322, i32 0, i32 3, i32 1) #19
  %323 = getelementptr inbounds i32, i32* %321, i64 4
  %324 = bitcast i32* %323 to i8*
  call void @llvm.prefetch(i8* %324, i32 0, i32 3, i32 1) #19
  %325 = getelementptr inbounds i32, i32* %317, i64 %320
  %326 = bitcast i32* %325 to i8*
  call void @llvm.prefetch(i8* %326, i32 0, i32 3, i32 1) #19
  %327 = getelementptr inbounds i32, i32* %325, i64 4
  %328 = bitcast i32* %327 to i8*
  call void @llvm.prefetch(i8* %328, i32 0, i32 3, i32 1) #19
  %329 = icmp slt i32 %312, 8
  br i1 %329, label %332, label %339

330:                                              ; preds = %339
  %331 = trunc i64 %347 to i32
  br label %332

332:                                              ; preds = %330, %311
  %333 = phi i32 [ %312, %311 ], [ %359, %330 ]
  %334 = phi i32 [ 0, %311 ], [ %331, %330 ]
  %335 = add nsw i32 %333, -4
  %336 = icmp sgt i32 %334, %335
  br i1 %336, label %369, label %337

337:                                              ; preds = %332
  %338 = zext i32 %334 to i64
  br label %373

339:                                              ; preds = %311, %363
  %340 = phi i32* [ %366, %363 ], [ %321, %311 ]
  %341 = phi i32 [ %365, %363 ], [ %318, %311 ]
  %342 = phi i32* [ %364, %363 ], [ %317, %311 ]
  %343 = phi i64 [ %347, %363 ], [ 0, %311 ]
  %344 = load i32, i32* %128, align 4
  %345 = trunc i64 %343 to i32
  %346 = add nsw i32 %344, %345
  %347 = add nuw i64 %343, 8
  %348 = mul nsw i32 %341, %315
  %349 = sext i32 %348 to i64
  %350 = getelementptr inbounds i32, i32* %340, i64 %347
  %351 = bitcast i32* %350 to i8*
  call void @llvm.prefetch(i8* %351, i32 0, i32 3, i32 1) #19
  %352 = getelementptr inbounds i32, i32* %350, i64 4
  %353 = bitcast i32* %352 to i8*
  call void @llvm.prefetch(i8* %353, i32 0, i32 3, i32 1) #19
  %354 = getelementptr inbounds i32, i32* %342, i64 %347
  %355 = getelementptr inbounds i32, i32* %354, i64 %349
  %356 = bitcast i32* %355 to i8*
  call void @llvm.prefetch(i8* %356, i32 0, i32 3, i32 1) #19
  %357 = getelementptr inbounds i32, i32* %355, i64 4
  %358 = bitcast i32* %357 to i8*
  call void @llvm.prefetch(i8* %358, i32 0, i32 3, i32 1) #19
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %10, %"struct.gemmlowp::OutputPipelineExecutor.347"* nonnull dereferenceable(40) %15, %"class.gemmlowp::MatrixMap.182"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %11, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorDup"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %7, i32 %3, i32 %345, i32 %315, i32 %346, i32 %316, i32 %346, i32 %316)
  %359 = load i32, i32* %46, align 4
  %360 = add nsw i32 %359, -8
  %361 = trunc i64 %347 to i32
  %362 = icmp slt i32 %360, %361
  br i1 %362, label %330, label %363

363:                                              ; preds = %339
  %364 = load i32*, i32** %20, align 8
  %365 = load i32, i32* %23, align 8
  %366 = load i32*, i32** %44, align 8
  br label %339

367:                                              ; preds = %373
  %368 = trunc i64 %432 to i32
  br label %369

369:                                              ; preds = %367, %332
  %370 = phi i32 [ %333, %332 ], [ %433, %367 ]
  %371 = phi i32 [ %334, %332 ], [ %368, %367 ]
  %372 = icmp slt i32 %371, %370
  br i1 %372, label %437, label %444

373:                                              ; preds = %337, %373
  %374 = phi i64 [ %338, %337 ], [ %432, %373 ]
  %375 = load i32, i32* %128, align 4
  %376 = trunc i64 %374 to i32
  %377 = add nsw i32 %375, %376
  %378 = load i32*, i32** %20, align 8
  %379 = getelementptr inbounds i32, i32* %378, i64 %374
  %380 = load i32, i32* %23, align 8
  %381 = mul nsw i32 %380, %315
  %382 = sext i32 %381 to i64
  %383 = getelementptr inbounds i32, i32* %379, i64 %382
  %384 = getelementptr inbounds i32, i32* %383, i64 1
  %385 = load i32, i32* %383, align 4
  %386 = getelementptr inbounds i32, i32* %384, i64 1
  %387 = load i32, i32* %384, align 4
  %388 = getelementptr inbounds i32, i32* %386, i64 1
  %389 = load i32, i32* %386, align 4
  %390 = load i32, i32* %388, align 4
  %391 = load i32*, i32** %44, align 8
  %392 = getelementptr i32, i32* %391, i64 %374
  %393 = bitcast i32* %392 to i64*
  %394 = load i64, i64* %393, align 4
  %395 = getelementptr inbounds i32, i32* %392, i64 2
  %396 = bitcast i32* %395 to i64*
  %397 = load i64, i64* %396, align 4
  %398 = trunc i64 %394 to i32
  %399 = lshr i64 %394, 32
  %400 = trunc i64 %399 to i32
  %401 = load i32*, i32** %50, align 8
  %402 = getelementptr inbounds i32, i32* %401, i64 %313
  %403 = load i32, i32* %402, align 4
  %404 = load i32, i32* %129, align 4
  %405 = load i32, i32* %130, align 4
  %406 = mul nsw i32 %405, %398
  %407 = add nsw i32 %406, %385
  %408 = mul nsw i32 %405, %400
  %409 = add nsw i32 %408, %387
  %410 = trunc i64 %397 to i32
  %411 = mul nsw i32 %405, %410
  %412 = add nsw i32 %411, %389
  %413 = lshr i64 %397, 32
  %414 = trunc i64 %413 to i32
  %415 = mul nsw i32 %405, %414
  %416 = add nsw i32 %415, %390
  %417 = mul nsw i32 %405, %3
  %418 = add nsw i32 %417, %403
  %419 = mul nsw i32 %418, %404
  %420 = add nsw i32 %407, %419
  %421 = add nsw i32 %409, %419
  %422 = add nsw i32 %412, %419
  %423 = zext i32 %422 to i64
  %424 = add nsw i32 %416, %419
  %425 = zext i32 %424 to i64
  %426 = shl nuw i64 %425, 32
  %427 = or i64 %426, %423
  %428 = zext i32 %421 to i64
  %429 = shl nuw i64 %428, 32
  %430 = zext i32 %420 to i64
  %431 = or i64 %429, %430
  call void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_13RegisterBlockIiLi4ELi1EEEE7ExecuteINS_9MatrixMapIhLNS_8MapOrderE0EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.338"* nonnull %14, i64 %431, i64 %427, %"class.gemmlowp::MatrixMap.182"* %0, i32 %377, i32 %316, i32 %377, i32 %316) #19
  %432 = add nuw i64 %374, 4
  %433 = load i32, i32* %46, align 4
  %434 = add nsw i32 %433, -4
  %435 = trunc i64 %432 to i32
  %436 = icmp slt i32 %434, %435
  br i1 %436, label %367, label %373

437:                                              ; preds = %369, %437
  %438 = phi i32 [ %441, %437 ], [ %371, %369 ]
  %439 = load i32, i32* %128, align 4
  %440 = add nsw i32 %439, %438
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %10, %"struct.gemmlowp::OutputPipelineExecutor.329"* nonnull dereferenceable(40) %13, %"class.gemmlowp::MatrixMap.182"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %11, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorDup"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %7, i32 %3, i32 %438, i32 %315, i32 %440, i32 %316, i32 %440, i32 %316)
  %441 = add nuw nsw i32 %438, 1
  %442 = load i32, i32* %46, align 4
  %443 = icmp slt i32 %441, %442
  br i1 %443, label %437, label %444

444:                                              ; preds = %437, %369
  %445 = phi i32 [ %370, %369 ], [ %442, %437 ]
  %446 = add nuw nsw i64 %313, 1
  %447 = load i32, i32* %52, align 4
  %448 = trunc i64 %446 to i32
  %449 = icmp sgt i32 %447, %448
  br i1 %449, label %311, label %450

450:                                              ; preds = %444, %122
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %105) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %97) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %89) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %81) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %73) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %55) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %49) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %43) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %19) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.374"* dereferenceable(40), %"class.gemmlowp::MatrixMap.182"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.302", align 16
  %16 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %16) #19
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %18 = sext i32 %8 to i64
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %20 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %20, i8 -86, i64 128, i1 false)
  %21 = load i32*, i32** %17, align 8, !noalias !731
  %22 = getelementptr inbounds i32, i32* %21, i64 %18
  %23 = load i32, i32* %19, align 8, !noalias !731
  %24 = mul nsw i32 %23, %9
  %25 = sext i32 %24 to i64
  %26 = getelementptr inbounds i32, i32* %22, i64 %25
  %27 = getelementptr inbounds i32, i32* %26, i64 1
  %28 = load i32, i32* %26, align 4
  %29 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 0
  store i32 %28, i32* %29, align 16, !alias.scope !731
  %30 = getelementptr inbounds i32, i32* %27, i64 1
  %31 = load i32, i32* %27, align 4
  %32 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 1
  store i32 %31, i32* %32, align 4, !alias.scope !731
  %33 = getelementptr inbounds i32, i32* %30, i64 1
  %34 = load i32, i32* %30, align 4
  %35 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 2
  store i32 %34, i32* %35, align 8, !alias.scope !731
  %36 = getelementptr inbounds i32, i32* %33, i64 1
  %37 = load i32, i32* %33, align 4
  %38 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 3
  store i32 %37, i32* %38, align 4, !alias.scope !731
  %39 = getelementptr inbounds i32, i32* %36, i64 1
  %40 = load i32, i32* %36, align 4
  %41 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 4
  store i32 %40, i32* %41, align 16, !alias.scope !731
  %42 = getelementptr inbounds i32, i32* %39, i64 1
  %43 = load i32, i32* %39, align 4
  %44 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 5
  store i32 %43, i32* %44, align 4, !alias.scope !731
  %45 = getelementptr inbounds i32, i32* %42, i64 1
  %46 = load i32, i32* %42, align 4
  %47 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 6
  store i32 %46, i32* %47, align 8, !alias.scope !731
  %48 = load i32, i32* %45, align 4
  %49 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 7
  store i32 %48, i32* %49, align 4, !alias.scope !731
  %50 = add nsw i32 %9, 1
  %51 = mul nsw i32 %23, %50
  %52 = sext i32 %51 to i64
  %53 = getelementptr inbounds i32, i32* %22, i64 %52
  %54 = getelementptr inbounds i32, i32* %53, i64 1
  %55 = load i32, i32* %53, align 4
  %56 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 8
  store i32 %55, i32* %56, align 16, !alias.scope !731
  %57 = getelementptr inbounds i32, i32* %54, i64 1
  %58 = load i32, i32* %54, align 4
  %59 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 9
  store i32 %58, i32* %59, align 4, !alias.scope !731
  %60 = getelementptr inbounds i32, i32* %57, i64 1
  %61 = load i32, i32* %57, align 4
  %62 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 10
  store i32 %61, i32* %62, align 8, !alias.scope !731
  %63 = getelementptr inbounds i32, i32* %60, i64 1
  %64 = load i32, i32* %60, align 4
  %65 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 11
  store i32 %64, i32* %65, align 4, !alias.scope !731
  %66 = getelementptr inbounds i32, i32* %63, i64 1
  %67 = load i32, i32* %63, align 4
  %68 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 12
  store i32 %67, i32* %68, align 16, !alias.scope !731
  %69 = getelementptr inbounds i32, i32* %66, i64 1
  %70 = load i32, i32* %66, align 4
  %71 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 13
  store i32 %70, i32* %71, align 4, !alias.scope !731
  %72 = getelementptr inbounds i32, i32* %69, i64 1
  %73 = load i32, i32* %69, align 4
  %74 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 14
  store i32 %73, i32* %74, align 8, !alias.scope !731
  %75 = load i32, i32* %72, align 4
  %76 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 15
  store i32 %75, i32* %76, align 4, !alias.scope !731
  %77 = add nsw i32 %9, 2
  %78 = mul nsw i32 %23, %77
  %79 = sext i32 %78 to i64
  %80 = getelementptr inbounds i32, i32* %22, i64 %79
  %81 = getelementptr inbounds i32, i32* %80, i64 1
  %82 = load i32, i32* %80, align 4
  %83 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 16
  store i32 %82, i32* %83, align 16, !alias.scope !731
  %84 = getelementptr inbounds i32, i32* %81, i64 1
  %85 = load i32, i32* %81, align 4
  %86 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 17
  store i32 %85, i32* %86, align 4, !alias.scope !731
  %87 = getelementptr inbounds i32, i32* %84, i64 1
  %88 = load i32, i32* %84, align 4
  %89 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 18
  store i32 %88, i32* %89, align 8, !alias.scope !731
  %90 = getelementptr inbounds i32, i32* %87, i64 1
  %91 = load i32, i32* %87, align 4
  %92 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 19
  store i32 %91, i32* %92, align 4, !alias.scope !731
  %93 = getelementptr inbounds i32, i32* %90, i64 1
  %94 = load i32, i32* %90, align 4
  %95 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 20
  store i32 %94, i32* %95, align 16, !alias.scope !731
  %96 = getelementptr inbounds i32, i32* %93, i64 1
  %97 = load i32, i32* %93, align 4
  %98 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 21
  store i32 %97, i32* %98, align 4, !alias.scope !731
  %99 = getelementptr inbounds i32, i32* %96, i64 1
  %100 = load i32, i32* %96, align 4
  %101 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 22
  store i32 %100, i32* %101, align 8, !alias.scope !731
  %102 = load i32, i32* %99, align 4
  %103 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 23
  store i32 %102, i32* %103, align 4, !alias.scope !731
  %104 = add nsw i32 %9, 3
  %105 = mul nsw i32 %23, %104
  %106 = sext i32 %105 to i64
  %107 = getelementptr inbounds i32, i32* %22, i64 %106
  %108 = getelementptr inbounds i32, i32* %107, i64 1
  %109 = load i32, i32* %107, align 4
  %110 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 24
  store i32 %109, i32* %110, align 16, !alias.scope !731
  %111 = getelementptr inbounds i32, i32* %108, i64 1
  %112 = load i32, i32* %108, align 4
  %113 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 25
  store i32 %112, i32* %113, align 4, !alias.scope !731
  %114 = getelementptr inbounds i32, i32* %111, i64 1
  %115 = load i32, i32* %111, align 4
  %116 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 26
  store i32 %115, i32* %116, align 8, !alias.scope !731
  %117 = getelementptr inbounds i32, i32* %114, i64 1
  %118 = load i32, i32* %114, align 4
  %119 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 27
  store i32 %118, i32* %119, align 4, !alias.scope !731
  %120 = getelementptr inbounds i32, i32* %117, i64 1
  %121 = load i32, i32* %117, align 4
  %122 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 28
  store i32 %121, i32* %122, align 16, !alias.scope !731
  %123 = getelementptr inbounds i32, i32* %120, i64 1
  %124 = load i32, i32* %120, align 4
  %125 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 29
  store i32 %124, i32* %125, align 4, !alias.scope !731
  %126 = getelementptr inbounds i32, i32* %123, i64 1
  %127 = load i32, i32* %123, align 4
  %128 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 30
  store i32 %127, i32* %128, align 8, !alias.scope !731
  %129 = load i32, i32* %126, align 4
  %130 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 31
  store i32 %129, i32* %130, align 4, !alias.scope !731
  %131 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %132 = load i32*, i32** %131, align 8, !noalias !734
  %133 = getelementptr i32, i32* %132, i64 %18
  %134 = bitcast i32* %133 to <4 x i32>*
  %135 = load <4 x i32>, <4 x i32>* %134, align 4
  %136 = getelementptr inbounds i32, i32* %133, i64 4
  %137 = bitcast i32* %136 to <4 x i32>*
  %138 = load <4 x i32>, <4 x i32>* %137, align 4
  %139 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %140 = load i32*, i32** %139, align 8
  %141 = sext i32 %9 to i64
  %142 = getelementptr i32, i32* %140, i64 %141
  %143 = bitcast i32* %142 to i64*
  %144 = load i64, i64* %143, align 4
  %145 = getelementptr inbounds i32, i32* %142, i64 2
  %146 = bitcast i32* %145 to i64*
  %147 = load i64, i64* %146, align 4
  %148 = lshr i64 %144, 32
  %149 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %150 = load i32, i32* %149, align 4
  %151 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %6, i64 0, i32 0
  %152 = load i32, i32* %151, align 4
  %153 = insertelement <4 x i32> undef, i32 %152, i32 0
  %154 = shufflevector <4 x i32> %153, <4 x i32> undef, <4 x i32> zeroinitializer
  %155 = mul nsw <4 x i32> %154, %135
  %156 = mul nsw <4 x i32> %154, %138
  %157 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to <4 x i32>*
  %158 = load <4 x i32>, <4 x i32>* %157, align 16
  %159 = add nsw <4 x i32> %158, %155
  %160 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to <4 x i32>*
  store <4 x i32> %159, <4 x i32>* %160, align 16
  %161 = bitcast i32* %41 to <4 x i32>*
  %162 = load <4 x i32>, <4 x i32>* %161, align 16
  %163 = add nsw <4 x i32> %162, %156
  %164 = bitcast i32* %41 to <4 x i32>*
  store <4 x i32> %163, <4 x i32>* %164, align 16
  %165 = bitcast i32* %56 to <4 x i32>*
  %166 = load <4 x i32>, <4 x i32>* %165, align 16
  %167 = add nsw <4 x i32> %166, %155
  %168 = bitcast i32* %56 to <4 x i32>*
  store <4 x i32> %167, <4 x i32>* %168, align 16
  %169 = bitcast i32* %68 to <4 x i32>*
  %170 = load <4 x i32>, <4 x i32>* %169, align 16
  %171 = add nsw <4 x i32> %170, %156
  %172 = bitcast i32* %68 to <4 x i32>*
  store <4 x i32> %171, <4 x i32>* %172, align 16
  %173 = bitcast i32* %83 to <4 x i32>*
  %174 = load <4 x i32>, <4 x i32>* %173, align 16
  %175 = add nsw <4 x i32> %174, %155
  %176 = bitcast i32* %83 to <4 x i32>*
  store <4 x i32> %175, <4 x i32>* %176, align 16
  %177 = bitcast i32* %95 to <4 x i32>*
  %178 = load <4 x i32>, <4 x i32>* %177, align 16
  %179 = add nsw <4 x i32> %178, %156
  %180 = bitcast i32* %95 to <4 x i32>*
  store <4 x i32> %179, <4 x i32>* %180, align 16
  %181 = bitcast i32* %110 to <4 x i32>*
  %182 = load <4 x i32>, <4 x i32>* %181, align 16
  %183 = add nsw <4 x i32> %182, %155
  %184 = bitcast i32* %110 to <4 x i32>*
  store <4 x i32> %183, <4 x i32>* %184, align 16
  %185 = bitcast i32* %122 to <4 x i32>*
  %186 = load <4 x i32>, <4 x i32>* %185, align 16
  %187 = add nsw <4 x i32> %186, %156
  %188 = bitcast i32* %122 to <4 x i32>*
  store <4 x i32> %187, <4 x i32>* %188, align 16
  %189 = trunc i64 %144 to i32
  %190 = trunc i64 %148 to i32
  %191 = mul nsw i32 %152, %7
  %192 = add nsw i32 %191, %189
  %193 = add nsw i32 %191, %190
  %194 = trunc i64 %147 to i32
  %195 = add nsw i32 %191, %194
  %196 = lshr i64 %147, 32
  %197 = trunc i64 %196 to i32
  %198 = add nsw i32 %191, %197
  %199 = mul nsw i32 %192, %150
  %200 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to <4 x i32>*
  %201 = load <4 x i32>, <4 x i32>* %200, align 16
  %202 = insertelement <4 x i32> undef, i32 %199, i32 0
  %203 = shufflevector <4 x i32> %202, <4 x i32> undef, <4 x i32> zeroinitializer
  %204 = add nsw <4 x i32> %201, %203
  %205 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to <4 x i32>*
  store <4 x i32> %204, <4 x i32>* %205, align 16
  %206 = bitcast i32* %41 to <4 x i32>*
  %207 = load <4 x i32>, <4 x i32>* %206, align 16
  %208 = add nsw <4 x i32> %207, %203
  %209 = bitcast i32* %41 to <4 x i32>*
  store <4 x i32> %208, <4 x i32>* %209, align 16
  %210 = mul nsw i32 %193, %150
  %211 = bitcast i32* %56 to <4 x i32>*
  %212 = load <4 x i32>, <4 x i32>* %211, align 16
  %213 = insertelement <4 x i32> undef, i32 %210, i32 0
  %214 = shufflevector <4 x i32> %213, <4 x i32> undef, <4 x i32> zeroinitializer
  %215 = add nsw <4 x i32> %212, %214
  %216 = bitcast i32* %56 to <4 x i32>*
  store <4 x i32> %215, <4 x i32>* %216, align 16
  %217 = bitcast i32* %68 to <4 x i32>*
  %218 = load <4 x i32>, <4 x i32>* %217, align 16
  %219 = add nsw <4 x i32> %218, %214
  %220 = bitcast i32* %68 to <4 x i32>*
  store <4 x i32> %219, <4 x i32>* %220, align 16
  %221 = mul nsw i32 %195, %150
  %222 = bitcast i32* %83 to <4 x i32>*
  %223 = load <4 x i32>, <4 x i32>* %222, align 16
  %224 = insertelement <4 x i32> undef, i32 %221, i32 0
  %225 = shufflevector <4 x i32> %224, <4 x i32> undef, <4 x i32> zeroinitializer
  %226 = add nsw <4 x i32> %223, %225
  %227 = bitcast i32* %83 to <4 x i32>*
  store <4 x i32> %226, <4 x i32>* %227, align 16
  %228 = bitcast i32* %95 to <4 x i32>*
  %229 = load <4 x i32>, <4 x i32>* %228, align 16
  %230 = add nsw <4 x i32> %229, %225
  %231 = bitcast i32* %95 to <4 x i32>*
  store <4 x i32> %230, <4 x i32>* %231, align 16
  %232 = mul nsw i32 %198, %150
  %233 = bitcast i32* %110 to <4 x i32>*
  %234 = load <4 x i32>, <4 x i32>* %233, align 16
  %235 = insertelement <4 x i32> undef, i32 %232, i32 0
  %236 = shufflevector <4 x i32> %235, <4 x i32> undef, <4 x i32> zeroinitializer
  %237 = add nsw <4 x i32> %234, %236
  %238 = bitcast i32* %110 to <4 x i32>*
  store <4 x i32> %237, <4 x i32>* %238, align 16
  %239 = bitcast i32* %122 to <4 x i32>*
  %240 = load <4 x i32>, <4 x i32>* %239, align 16
  %241 = add nsw <4 x i32> %240, %236
  %242 = bitcast i32* %122 to <4 x i32>*
  store <4 x i32> %241, <4 x i32>* %242, align 16
  tail call void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_13RegisterBlockIiLi8ELi4EEEE7ExecuteINS_9MatrixMapIhLNS_8MapOrderE0EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.374"* %1, %"struct.gemmlowp::RegisterBlock.302"* nonnull byval(%"struct.gemmlowp::RegisterBlock.302") align 8 %15, %"class.gemmlowp::MatrixMap.182"* %2, i32 %10, i32 %11, i32 %12, i32 %13)
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %16) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.365"* dereferenceable(40), %"class.gemmlowp::MatrixMap.182"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.312", align 8
  %16 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %17 = sext i32 %8 to i64
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %19 = load i32*, i32** %16, align 8, !noalias !739
  %20 = getelementptr inbounds i32, i32* %19, i64 %17
  %21 = load i32, i32* %18, align 8, !noalias !739
  %22 = mul nsw i32 %21, %9
  %23 = sext i32 %22 to i64
  %24 = getelementptr inbounds i32, i32* %20, i64 %23
  %25 = getelementptr inbounds i32, i32* %24, i64 1
  %26 = load i32, i32* %24, align 4, !noalias !739
  %27 = getelementptr inbounds i32, i32* %25, i64 1
  %28 = load i32, i32* %25, align 4, !noalias !739
  %29 = getelementptr inbounds i32, i32* %27, i64 1
  %30 = load i32, i32* %27, align 4, !noalias !739
  %31 = load i32, i32* %29, align 4, !noalias !739
  %32 = add nsw i32 %9, 1
  %33 = mul nsw i32 %21, %32
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds i32, i32* %20, i64 %34
  %36 = getelementptr inbounds i32, i32* %35, i64 1
  %37 = load i32, i32* %35, align 4, !noalias !739
  %38 = getelementptr inbounds i32, i32* %36, i64 1
  %39 = load i32, i32* %36, align 4, !noalias !739
  %40 = getelementptr inbounds i32, i32* %38, i64 1
  %41 = load i32, i32* %38, align 4, !noalias !739
  %42 = load i32, i32* %40, align 4, !noalias !739
  %43 = add nsw i32 %9, 2
  %44 = mul nsw i32 %21, %43
  %45 = sext i32 %44 to i64
  %46 = getelementptr inbounds i32, i32* %20, i64 %45
  %47 = getelementptr inbounds i32, i32* %46, i64 1
  %48 = load i32, i32* %46, align 4, !noalias !739
  %49 = getelementptr inbounds i32, i32* %47, i64 1
  %50 = load i32, i32* %47, align 4, !noalias !739
  %51 = getelementptr inbounds i32, i32* %49, i64 1
  %52 = load i32, i32* %49, align 4, !noalias !739
  %53 = load i32, i32* %51, align 4, !noalias !739
  %54 = add nsw i32 %9, 3
  %55 = mul nsw i32 %21, %54
  %56 = sext i32 %55 to i64
  %57 = getelementptr inbounds i32, i32* %20, i64 %56
  %58 = getelementptr inbounds i32, i32* %57, i64 1
  %59 = load i32, i32* %57, align 4, !noalias !739
  %60 = getelementptr inbounds i32, i32* %58, i64 1
  %61 = load i32, i32* %58, align 4, !noalias !739
  %62 = getelementptr inbounds i32, i32* %60, i64 1
  %63 = load i32, i32* %60, align 4, !noalias !739
  %64 = load i32, i32* %62, align 4, !noalias !739
  %65 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %66 = load i32*, i32** %65, align 8
  %67 = getelementptr i32, i32* %66, i64 %17
  %68 = bitcast i32* %67 to i64*
  %69 = load i64, i64* %68, align 4
  %70 = getelementptr inbounds i32, i32* %67, i64 2
  %71 = bitcast i32* %70 to i64*
  %72 = load i64, i64* %71, align 4
  %73 = trunc i64 %69 to i32
  %74 = lshr i64 %69, 32
  %75 = trunc i64 %74 to i32
  %76 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %77 = load i32*, i32** %76, align 8
  %78 = sext i32 %9 to i64
  %79 = getelementptr i32, i32* %77, i64 %78
  %80 = bitcast i32* %79 to i64*
  %81 = load i64, i64* %80, align 4
  %82 = getelementptr inbounds i32, i32* %79, i64 2
  %83 = bitcast i32* %82 to i64*
  %84 = load i64, i64* %83, align 4
  %85 = trunc i64 %81 to i32
  %86 = lshr i64 %81, 32
  %87 = trunc i64 %86 to i32
  %88 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %89 = load i32, i32* %88, align 4
  %90 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %6, i64 0, i32 0
  %91 = load i32, i32* %90, align 4
  %92 = mul nsw i32 %91, %73
  %93 = add nsw i32 %92, %26
  %94 = mul nsw i32 %91, %75
  %95 = add nsw i32 %94, %28
  %96 = trunc i64 %72 to i32
  %97 = mul nsw i32 %91, %96
  %98 = add nsw i32 %97, %30
  %99 = lshr i64 %72, 32
  %100 = trunc i64 %99 to i32
  %101 = mul nsw i32 %91, %100
  %102 = add nsw i32 %101, %31
  %103 = add nsw i32 %92, %37
  %104 = add nsw i32 %94, %39
  %105 = add nsw i32 %97, %41
  %106 = add nsw i32 %101, %42
  %107 = add nsw i32 %92, %48
  %108 = add nsw i32 %94, %50
  %109 = add nsw i32 %97, %52
  %110 = add nsw i32 %101, %53
  %111 = add nsw i32 %92, %59
  %112 = add nsw i32 %94, %61
  %113 = add nsw i32 %97, %63
  %114 = add nsw i32 %101, %64
  %115 = mul nsw i32 %91, %7
  %116 = add nsw i32 %115, %85
  %117 = add nsw i32 %115, %87
  %118 = trunc i64 %84 to i32
  %119 = add nsw i32 %115, %118
  %120 = lshr i64 %84, 32
  %121 = trunc i64 %120 to i32
  %122 = add nsw i32 %115, %121
  %123 = mul nsw i32 %116, %89
  %124 = add nsw i32 %93, %123
  %125 = add nsw i32 %95, %123
  %126 = add nsw i32 %98, %123
  %127 = add nsw i32 %102, %123
  %128 = mul nsw i32 %117, %89
  %129 = add nsw i32 %103, %128
  %130 = add nsw i32 %104, %128
  %131 = add nsw i32 %105, %128
  %132 = add nsw i32 %106, %128
  %133 = mul nsw i32 %119, %89
  %134 = add nsw i32 %107, %133
  %135 = add nsw i32 %108, %133
  %136 = add nsw i32 %109, %133
  %137 = add nsw i32 %110, %133
  %138 = mul nsw i32 %122, %89
  %139 = add nsw i32 %111, %138
  %140 = add nsw i32 %112, %138
  %141 = add nsw i32 %113, %138
  %142 = add nsw i32 %114, %138
  %143 = bitcast %"struct.gemmlowp::RegisterBlock.312"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %143)
  %144 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 0
  store i32 %124, i32* %144, align 8
  %145 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 1
  store i32 %125, i32* %145, align 4
  %146 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 2
  store i32 %126, i32* %146, align 8
  %147 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 3
  store i32 %127, i32* %147, align 4
  %148 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 4
  store i32 %129, i32* %148, align 8
  %149 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 5
  store i32 %130, i32* %149, align 4
  %150 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 6
  store i32 %131, i32* %150, align 8
  %151 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 7
  store i32 %132, i32* %151, align 4
  %152 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 8
  store i32 %134, i32* %152, align 8
  %153 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 9
  store i32 %135, i32* %153, align 4
  %154 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 10
  store i32 %136, i32* %154, align 8
  %155 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 11
  store i32 %137, i32* %155, align 4
  %156 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 12
  store i32 %139, i32* %156, align 8
  %157 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 13
  store i32 %140, i32* %157, align 4
  %158 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 14
  store i32 %141, i32* %158, align 8
  %159 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 15
  store i32 %142, i32* %159, align 4
  %160 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.365", %"struct.gemmlowp::OutputPipelineExecutor.365"* %1, i64 0, i32 0
  %161 = tail call { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi0ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.366"* %160, %"struct.gemmlowp::RegisterBlock.312"* nonnull byval(%"struct.gemmlowp::RegisterBlock.312") align 8 %15, i32 %10, i32 %11) #19
  %162 = extractvalue { i64, i64 } %161, 0
  %163 = extractvalue { i64, i64 } %161, 1
  tail call void @_ZN8gemmlowp16StoreFinalOutputINS_13RegisterBlockIhLi4ELi4EEENS_9MatrixMapIhLNS_8MapOrderE0EEEEEvT_PT0_ii(i64 %162, i64 %163, %"class.gemmlowp::MatrixMap.182"* %2, i32 %12, i32 %13) #19
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %143)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.347"* dereferenceable(40), %"class.gemmlowp::MatrixMap.182"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.304", align 16
  %16 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %17 = sext i32 %8 to i64
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %19 = load i32*, i32** %16, align 8, !noalias !744
  %20 = getelementptr inbounds i32, i32* %19, i64 %17
  %21 = load i32, i32* %18, align 8, !noalias !744
  %22 = mul nsw i32 %21, %9
  %23 = sext i32 %22 to i64
  %24 = getelementptr inbounds i32, i32* %20, i64 %23
  %25 = getelementptr inbounds i32, i32* %24, i64 1
  %26 = getelementptr inbounds i32, i32* %25, i64 1
  %27 = getelementptr inbounds i32, i32* %26, i64 1
  %28 = getelementptr inbounds i32, i32* %27, i64 1
  %29 = bitcast i32* %24 to <4 x i32>*
  %30 = load <4 x i32>, <4 x i32>* %29, align 4, !noalias !744
  %31 = getelementptr inbounds i32, i32* %28, i64 1
  %32 = load i32, i32* %28, align 4, !noalias !744
  %33 = getelementptr inbounds i32, i32* %31, i64 1
  %34 = load i32, i32* %31, align 4, !noalias !744
  %35 = getelementptr inbounds i32, i32* %33, i64 1
  %36 = load i32, i32* %33, align 4, !noalias !744
  %37 = load i32, i32* %35, align 4, !noalias !744
  %38 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %39 = load i32*, i32** %38, align 8, !noalias !749
  %40 = getelementptr i32, i32* %39, i64 %17
  %41 = bitcast i32* %40 to <4 x i32>*
  %42 = load <4 x i32>, <4 x i32>* %41, align 4
  %43 = getelementptr inbounds i32, i32* %40, i64 4
  %44 = bitcast i32* %43 to <4 x i32>*
  %45 = load <4 x i32>, <4 x i32>* %44, align 4
  %46 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %47 = load i32*, i32** %46, align 8
  %48 = sext i32 %9 to i64
  %49 = getelementptr inbounds i32, i32* %47, i64 %48
  %50 = load i32, i32* %49, align 4
  %51 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %52 = load i32, i32* %51, align 4
  %53 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %6, i64 0, i32 0
  %54 = load i32, i32* %53, align 4
  %55 = insertelement <4 x i32> undef, i32 %54, i32 0
  %56 = shufflevector <4 x i32> %55, <4 x i32> undef, <4 x i32> zeroinitializer
  %57 = mul nsw <4 x i32> %56, %42
  %58 = add nsw <4 x i32> %57, %30
  %59 = mul nsw <4 x i32> %56, %45
  %60 = insertelement <4 x i32> undef, i32 %32, i32 0
  %61 = insertelement <4 x i32> %60, i32 %34, i32 1
  %62 = insertelement <4 x i32> %61, i32 %36, i32 2
  %63 = insertelement <4 x i32> %62, i32 %37, i32 3
  %64 = add nsw <4 x i32> %59, %63
  %65 = mul nsw i32 %54, %7
  %66 = add nsw i32 %65, %50
  %67 = mul nsw i32 %66, %52
  %68 = insertelement <4 x i32> undef, i32 %67, i32 0
  %69 = shufflevector <4 x i32> %68, <4 x i32> undef, <4 x i32> zeroinitializer
  %70 = add nsw <4 x i32> %58, %69
  %71 = add nsw <4 x i32> %64, %69
  %72 = bitcast %"struct.gemmlowp::RegisterBlock.304"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %72) #19
  %73 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.347", %"struct.gemmlowp::OutputPipelineExecutor.347"* %1, i64 0, i32 0, i32 0, i32 0
  %74 = load %"struct.gemmlowp::OutputStageBiasAddition"*, %"struct.gemmlowp::OutputStageBiasAddition"** %73, align 8, !noalias !754
  %75 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition", %"struct.gemmlowp::OutputStageBiasAddition"* %74, i64 0, i32 0, i32 0
  %76 = load i32*, i32** %75, align 8, !noalias !757
  %77 = sext i32 %10 to i64
  %78 = getelementptr i32, i32* %76, i64 %77
  %79 = bitcast i32* %78 to <4 x i32>*
  %80 = load <4 x i32>, <4 x i32>* %79, align 4, !noalias !754
  %81 = getelementptr inbounds i32, i32* %78, i64 4
  %82 = bitcast i32* %81 to <4 x i32>*
  %83 = load <4 x i32>, <4 x i32>* %82, align 4, !noalias !754
  %84 = add nsw <4 x i32> %70, %80
  %85 = add nsw <4 x i32> %71, %83
  %86 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.347", %"struct.gemmlowp::OutputPipelineExecutor.347"* %1, i64 0, i32 0, i32 1
  %87 = bitcast %"struct.gemmlowp::RegisterBlock.304"* %15 to <4 x i32>*
  store <4 x i32> %84, <4 x i32>* %87, align 16
  %88 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %15, i64 0, i32 0, i32 0, i64 4
  %89 = bitcast i32* %88 to <4 x i32>*
  store <4 x i32> %85, <4 x i32>* %89, align 16
  %90 = tail call i64 @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi1ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalESE_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.350"* %86, %"struct.gemmlowp::RegisterBlock.304"* nonnull byval(%"struct.gemmlowp::RegisterBlock.304") align 8 %15, i32 %10, i32 %11) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %72) #19
  %91 = trunc i64 %90 to i8
  %92 = lshr i64 %90, 8
  %93 = trunc i64 %92 to i8
  %94 = lshr i64 %90, 16
  %95 = trunc i64 %94 to i8
  %96 = lshr i64 %90, 24
  %97 = trunc i64 %96 to i8
  %98 = lshr i64 %90, 32
  %99 = trunc i64 %98 to i8
  %100 = lshr i64 %90, 40
  %101 = trunc i64 %100 to i8
  %102 = lshr i64 %90, 48
  %103 = trunc i64 %102 to i8
  %104 = lshr i64 %90, 56
  %105 = trunc i64 %104 to i8
  %106 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %2, i64 0, i32 0
  %107 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %2, i64 0, i32 3
  %108 = sext i32 %12 to i64
  %109 = load i8*, i8** %106, align 8
  %110 = getelementptr inbounds i8, i8* %109, i64 %108
  %111 = load i32, i32* %107, align 8
  %112 = mul nsw i32 %111, %13
  %113 = sext i32 %112 to i64
  %114 = getelementptr inbounds i8, i8* %110, i64 %113
  store i8 %91, i8* %114, align 1
  %115 = add nsw i64 %108, 1
  %116 = load i8*, i8** %106, align 8
  %117 = getelementptr inbounds i8, i8* %116, i64 %115
  %118 = load i32, i32* %107, align 8
  %119 = mul nsw i32 %118, %13
  %120 = sext i32 %119 to i64
  %121 = getelementptr inbounds i8, i8* %117, i64 %120
  store i8 %93, i8* %121, align 1
  %122 = add nsw i64 %108, 2
  %123 = load i8*, i8** %106, align 8
  %124 = getelementptr inbounds i8, i8* %123, i64 %122
  %125 = load i32, i32* %107, align 8
  %126 = mul nsw i32 %125, %13
  %127 = sext i32 %126 to i64
  %128 = getelementptr inbounds i8, i8* %124, i64 %127
  store i8 %95, i8* %128, align 1
  %129 = add nsw i64 %108, 3
  %130 = load i8*, i8** %106, align 8
  %131 = getelementptr inbounds i8, i8* %130, i64 %129
  %132 = load i32, i32* %107, align 8
  %133 = mul nsw i32 %132, %13
  %134 = sext i32 %133 to i64
  %135 = getelementptr inbounds i8, i8* %131, i64 %134
  store i8 %97, i8* %135, align 1
  %136 = add nsw i64 %108, 4
  %137 = load i8*, i8** %106, align 8
  %138 = getelementptr inbounds i8, i8* %137, i64 %136
  %139 = load i32, i32* %107, align 8
  %140 = mul nsw i32 %139, %13
  %141 = sext i32 %140 to i64
  %142 = getelementptr inbounds i8, i8* %138, i64 %141
  store i8 %99, i8* %142, align 1
  %143 = add nsw i64 %108, 5
  %144 = load i8*, i8** %106, align 8
  %145 = getelementptr inbounds i8, i8* %144, i64 %143
  %146 = load i32, i32* %107, align 8
  %147 = mul nsw i32 %146, %13
  %148 = sext i32 %147 to i64
  %149 = getelementptr inbounds i8, i8* %145, i64 %148
  store i8 %101, i8* %149, align 1
  %150 = add nsw i64 %108, 6
  %151 = load i8*, i8** %106, align 8
  %152 = getelementptr inbounds i8, i8* %151, i64 %150
  %153 = load i32, i32* %107, align 8
  %154 = mul nsw i32 %153, %13
  %155 = sext i32 %154 to i64
  %156 = getelementptr inbounds i8, i8* %152, i64 %155
  store i8 %103, i8* %156, align 1
  %157 = add nsw i64 %108, 7
  %158 = load i8*, i8** %106, align 8
  %159 = getelementptr inbounds i8, i8* %158, i64 %157
  %160 = load i32, i32* %107, align 8
  %161 = mul nsw i32 %160, %13
  %162 = sext i32 %161 to i64
  %163 = getelementptr inbounds i8, i8* %159, i64 %162
  store i8 %105, i8* %163, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.329"* dereferenceable(40), %"class.gemmlowp::MatrixMap.182"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %16 = load i32*, i32** %15, align 8
  %17 = sext i32 %8 to i64
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %19 = load i32, i32* %18, align 8
  %20 = getelementptr inbounds i32, i32* %16, i64 %17
  %21 = mul nsw i32 %19, %9
  %22 = sext i32 %21 to i64
  %23 = getelementptr inbounds i32, i32* %20, i64 %22
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %26 = load i32*, i32** %25, align 8
  %27 = getelementptr inbounds i32, i32* %26, i64 %17
  %28 = load i32, i32* %27, align 4
  %29 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %30 = load i32*, i32** %29, align 8
  %31 = sext i32 %9 to i64
  %32 = getelementptr inbounds i32, i32* %30, i64 %31
  %33 = load i32, i32* %32, align 4
  %34 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %35 = load i32, i32* %34, align 4
  %36 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %6, i64 0, i32 0
  %37 = load i32, i32* %36, align 4
  %38 = mul nsw i32 %37, %28
  %39 = add nsw i32 %38, %24
  %40 = mul nsw i32 %37, %7
  %41 = add nsw i32 %40, %33
  %42 = mul nsw i32 %41, %35
  %43 = add nsw i32 %39, %42
  %44 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.329", %"struct.gemmlowp::OutputPipelineExecutor.329"* %1, i64 0, i32 0, i32 0, i32 0
  %45 = load %"struct.gemmlowp::OutputStageBiasAddition"*, %"struct.gemmlowp::OutputStageBiasAddition"** %44, align 8
  %46 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition", %"struct.gemmlowp::OutputStageBiasAddition"* %45, i64 0, i32 0, i32 0
  %47 = load i32*, i32** %46, align 8
  %48 = sext i32 %10 to i64
  %49 = getelementptr inbounds i32, i32* %47, i64 %48
  %50 = load i32, i32* %49, align 4
  %51 = add nsw i32 %43, %50
  %52 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.329", %"struct.gemmlowp::OutputPipelineExecutor.329"* %1, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %53 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %52, align 8
  %54 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %53, i64 0, i32 2
  %55 = load i32, i32* %54, align 4
  %56 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.329", %"struct.gemmlowp::OutputPipelineExecutor.329"* %1, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  %57 = load i32, i32* %56, align 8
  %58 = sext i32 %51 to i64
  %59 = shl i32 1, %57
  %60 = sext i32 %59 to i64
  %61 = mul nsw i64 %60, %58
  %62 = icmp slt i64 %61, 2147483647
  %63 = select i1 %62, i64 %61, i64 2147483647
  %64 = icmp sgt i64 %63, -2147483648
  %65 = select i1 %64, i64 %63, i64 -2147483648
  %66 = trunc i64 %65 to i32
  %67 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %53, i64 0, i32 0
  %68 = load i32, i32* %67, align 4
  %69 = icmp ne i32 %68, %66
  %70 = icmp ne i32 %66, -2147483648
  %71 = or i1 %69, %70
  br i1 %71, label %72, label %81

72:                                               ; preds = %14
  %73 = sext i32 %68 to i64
  %74 = select i1 %69, i64 %73, i64 %65
  %75 = mul nsw i64 %74, %65
  %76 = icmp sgt i64 %75, -1
  %77 = select i1 %76, i64 1073741824, i64 -1073741823
  %78 = add nsw i64 %77, %75
  %79 = sdiv i64 %78, 2147483648
  %80 = trunc i64 %79 to i32
  br label %81

81:                                               ; preds = %14, %72
  %82 = phi i32 [ %80, %72 ], [ 2147483647, %14 ]
  %83 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.329", %"struct.gemmlowp::OutputPipelineExecutor.329"* %1, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  %84 = load i32, i32* %83, align 4
  %85 = zext i32 %84 to i64
  %86 = shl nsw i64 -1, %85
  %87 = trunc i64 %86 to i32
  %88 = xor i32 %87, -1
  %89 = and i32 %82, %88
  %90 = ashr i32 %88, 1
  %91 = lshr i32 %82, 31
  %92 = add nsw i32 %90, %91
  %93 = ashr i32 %82, %84
  %94 = icmp sgt i32 %89, %92
  %95 = zext i1 %94 to i32
  %96 = add i32 %93, %55
  %97 = add i32 %96, %95
  %98 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.329", %"struct.gemmlowp::OutputPipelineExecutor.329"* %1, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %99 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %98, align 8
  %100 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %99, i64 0, i32 0
  %101 = load i32, i32* %100, align 4
  %102 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %99, i64 0, i32 1
  %103 = load i32, i32* %102, align 4
  %104 = icmp sgt i32 %101, %97
  %105 = select i1 %104, i32 %101, i32 %97
  %106 = icmp slt i32 %103, %105
  %107 = select i1 %106, i32 %103, i32 %105
  %108 = icmp sgt i32 %107, 0
  %109 = select i1 %108, i32 %107, i32 0
  %110 = icmp slt i32 %109, 255
  %111 = select i1 %110, i32 %109, i32 255
  %112 = trunc i32 %111 to i8
  %113 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %2, i64 0, i32 0
  %114 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %2, i64 0, i32 3
  %115 = sext i32 %12 to i64
  %116 = load i8*, i8** %113, align 8
  %117 = getelementptr inbounds i8, i8* %116, i64 %115
  %118 = load i32, i32* %114, align 8
  %119 = mul nsw i32 %118, %13
  %120 = sext i32 %119 to i64
  %121 = getelementptr inbounds i8, i8* %117, i64 %120
  store i8 %112, i8* %121, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_13RegisterBlockIiLi8ELi4EEEE7ExecuteINS_9MatrixMapIhLNS_8MapOrderE0EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.374"*, %"struct.gemmlowp::RegisterBlock.302"* byval(%"struct.gemmlowp::RegisterBlock.302") align 8, %"class.gemmlowp::MatrixMap.182"*, i32, i32, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %8 = alloca %"struct.gemmlowp::RegisterBlock.302", align 16
  %9 = alloca %"struct.gemmlowp::RegisterBlock.310", align 8
  %10 = alloca %"struct.gemmlowp::RegisterBlock.310", align 1
  %11 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %10, i64 0, i32 0, i32 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %11) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 1 %11, i8 -86, i64 32, i1 false)
  %12 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %1 to <4 x i32>*
  %13 = load <4 x i32>, <4 x i32>* %12, align 8
  %14 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 4
  %15 = bitcast i32* %14 to <4 x i32>*
  %16 = load <4 x i32>, <4 x i32>* %15, align 8
  %17 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 8
  %18 = bitcast i32* %17 to <4 x i32>*
  %19 = load <4 x i32>, <4 x i32>* %18, align 8
  %20 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 12
  %21 = bitcast i32* %20 to <4 x i32>*
  %22 = load <4 x i32>, <4 x i32>* %21, align 8
  %23 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 16
  %24 = bitcast i32* %23 to <4 x i32>*
  %25 = load <4 x i32>, <4 x i32>* %24, align 8
  %26 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 20
  %27 = bitcast i32* %26 to <4 x i32>*
  %28 = load <4 x i32>, <4 x i32>* %27, align 8
  %29 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 24
  %30 = bitcast i32* %29 to <4 x i32>*
  %31 = load <4 x i32>, <4 x i32>* %30, align 8
  %32 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 28
  %33 = bitcast i32* %32 to <4 x i32>*
  %34 = load <4 x i32>, <4 x i32>* %33, align 8
  %35 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %35)
  %36 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.374", %"struct.gemmlowp::OutputPipelineExecutor.374"* %0, i64 0, i32 0, i32 0, i32 0
  %37 = load %"struct.gemmlowp::OutputStageBiasAddition"*, %"struct.gemmlowp::OutputStageBiasAddition"** %36, align 8, !noalias !762
  %38 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition", %"struct.gemmlowp::OutputStageBiasAddition"* %37, i64 0, i32 0, i32 0
  %39 = load i32*, i32** %38, align 8, !noalias !767
  %40 = sext i32 %3 to i64
  %41 = getelementptr i32, i32* %39, i64 %40
  %42 = bitcast i32* %41 to <4 x i32>*
  %43 = load <4 x i32>, <4 x i32>* %42, align 4, !noalias !762
  %44 = getelementptr inbounds i32, i32* %41, i64 4
  %45 = bitcast i32* %44 to <4 x i32>*
  %46 = load <4 x i32>, <4 x i32>* %45, align 4, !noalias !762
  %47 = add nsw <4 x i32> %43, %13
  %48 = add nsw <4 x i32> %46, %16
  %49 = add nsw <4 x i32> %43, %19
  %50 = add nsw <4 x i32> %46, %22
  %51 = add nsw <4 x i32> %43, %25
  %52 = add nsw <4 x i32> %46, %28
  %53 = add nsw <4 x i32> %43, %31
  %54 = add nsw <4 x i32> %46, %34
  %55 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.374", %"struct.gemmlowp::OutputPipelineExecutor.374"* %0, i64 0, i32 0, i32 1
  %56 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %8 to <4 x i32>*
  store <4 x i32> %47, <4 x i32>* %56, align 16, !noalias !772
  %57 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %8, i64 0, i32 0, i32 0, i64 4
  %58 = bitcast i32* %57 to <4 x i32>*
  store <4 x i32> %48, <4 x i32>* %58, align 16, !noalias !772
  %59 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %8, i64 0, i32 0, i32 0, i64 8
  %60 = bitcast i32* %59 to <4 x i32>*
  store <4 x i32> %49, <4 x i32>* %60, align 16, !noalias !772
  %61 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %8, i64 0, i32 0, i32 0, i64 12
  %62 = bitcast i32* %61 to <4 x i32>*
  store <4 x i32> %50, <4 x i32>* %62, align 16, !noalias !772
  %63 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %8, i64 0, i32 0, i32 0, i64 16
  %64 = bitcast i32* %63 to <4 x i32>*
  store <4 x i32> %51, <4 x i32>* %64, align 16, !noalias !772
  %65 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %8, i64 0, i32 0, i32 0, i64 20
  %66 = bitcast i32* %65 to <4 x i32>*
  store <4 x i32> %52, <4 x i32>* %66, align 16, !noalias !772
  %67 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %8, i64 0, i32 0, i32 0, i64 24
  %68 = bitcast i32* %67 to <4 x i32>*
  store <4 x i32> %53, <4 x i32>* %68, align 16, !noalias !772
  %69 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %8, i64 0, i32 0, i32 0, i64 28
  %70 = bitcast i32* %69 to <4 x i32>*
  store <4 x i32> %54, <4 x i32>* %70, align 16, !noalias !772
  call void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi1ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.310"* nonnull sret %10, %"struct.gemmlowp::OutputPipelineEvalImpl.377"* %55, %"struct.gemmlowp::RegisterBlock.302"* nonnull byval(%"struct.gemmlowp::RegisterBlock.302") align 8 %8, i32 %3, i32 %4) #19
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %35)
  %71 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %9, i64 0, i32 0, i32 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %71)
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %71, i8* nonnull align 1 %11, i64 32, i1 false)
  %72 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %2, i64 0, i32 0
  %73 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %2, i64 0, i32 3
  %74 = sext i32 %6 to i64
  %75 = sext i32 %5 to i64
  %76 = add nsw i64 %74, 1
  %77 = add nsw i64 %74, 2
  %78 = add nsw i64 %74, 3
  br label %79

79:                                               ; preds = %79, %7
  %80 = phi i64 [ 0, %7 ], [ %117, %79 ]
  %81 = add nsw i64 %80, %75
  %82 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %9, i64 0, i32 0, i32 0, i64 %80
  %83 = load i8, i8* %82, align 1
  %84 = load i8*, i8** %72, align 8
  %85 = getelementptr inbounds i8, i8* %84, i64 %81
  %86 = load i32, i32* %73, align 8
  %87 = sext i32 %86 to i64
  %88 = mul nsw i64 %87, %74
  %89 = getelementptr inbounds i8, i8* %85, i64 %88
  store i8 %83, i8* %89, align 1
  %90 = add nuw nsw i64 %80, 8
  %91 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %9, i64 0, i32 0, i32 0, i64 %90
  %92 = load i8, i8* %91, align 1
  %93 = load i8*, i8** %72, align 8
  %94 = getelementptr inbounds i8, i8* %93, i64 %81
  %95 = load i32, i32* %73, align 8
  %96 = sext i32 %95 to i64
  %97 = mul nsw i64 %76, %96
  %98 = getelementptr inbounds i8, i8* %94, i64 %97
  store i8 %92, i8* %98, align 1
  %99 = add nuw nsw i64 %80, 16
  %100 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %9, i64 0, i32 0, i32 0, i64 %99
  %101 = load i8, i8* %100, align 1
  %102 = load i8*, i8** %72, align 8
  %103 = getelementptr inbounds i8, i8* %102, i64 %81
  %104 = load i32, i32* %73, align 8
  %105 = sext i32 %104 to i64
  %106 = mul nsw i64 %77, %105
  %107 = getelementptr inbounds i8, i8* %103, i64 %106
  store i8 %101, i8* %107, align 1
  %108 = add nuw nsw i64 %80, 24
  %109 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %9, i64 0, i32 0, i32 0, i64 %108
  %110 = load i8, i8* %109, align 1
  %111 = load i8*, i8** %72, align 8
  %112 = getelementptr inbounds i8, i8* %111, i64 %81
  %113 = load i32, i32* %73, align 8
  %114 = sext i32 %113 to i64
  %115 = mul nsw i64 %78, %114
  %116 = getelementptr inbounds i8, i8* %112, i64 %115
  store i8 %110, i8* %116, align 1
  %117 = add nuw nsw i64 %80, 1
  %118 = icmp eq i64 %117, 8
  br i1 %118, label %119, label %79

119:                                              ; preds = %79
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %71)
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %11) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi1ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.310"* noalias sret, %"struct.gemmlowp::OutputPipelineEvalImpl.377"*, %"struct.gemmlowp::RegisterBlock.302"* byval(%"struct.gemmlowp::RegisterBlock.302") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %6 = alloca %"struct.gemmlowp::RegisterBuffer.303", align 16
  %7 = alloca %"struct.gemmlowp::RegisterBuffer.303", align 16
  %8 = alloca [32 x i32], align 8
  %9 = alloca %"struct.gemmlowp::RegisterBuffer.303", align 8
  %10 = alloca %"struct.gemmlowp::RegisterBuffer.303", align 4
  %11 = alloca [32 x i32], align 4
  %12 = bitcast [32 x i32]* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %12)
  %13 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %2 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %12, i8 -86, i64 128, i1 false), !alias.scope !773
  %14 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %14) #19, !noalias !773
  %15 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %15) #19, !noalias !773
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %15, i8* nonnull align 8 %13, i64 128, i1 false)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %14, i8 -86, i64 128, i1 false) #19, !alias.scope !776, !noalias !773
  %16 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.377", %"struct.gemmlowp::OutputPipelineEvalImpl.377"* %1, i64 0, i32 0, i32 0, i32 0
  %17 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %16, align 8, !noalias !779
  %18 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %17, i64 0, i32 2
  %19 = load i32, i32* %18, align 4, !noalias !779
  %20 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.377", %"struct.gemmlowp::OutputPipelineEvalImpl.377"* %1, i64 0, i32 0, i32 0, i32 1
  %21 = load i32, i32* %20, align 8, !noalias !779
  %22 = shl i32 1, %21
  %23 = sext i32 %22 to i64
  %24 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %17, i64 0, i32 0
  %25 = load i32, i32* %24, align 4, !noalias !779
  %26 = sext i32 %25 to i64
  %27 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.377", %"struct.gemmlowp::OutputPipelineEvalImpl.377"* %1, i64 0, i32 0, i32 0, i32 2
  %28 = load i32, i32* %27, align 4, !noalias !779
  %29 = zext i32 %28 to i64
  %30 = shl nsw i64 -1, %29
  %31 = trunc i64 %30 to i32
  %32 = xor i32 %31, -1
  %33 = ashr i32 %32, 1
  %34 = icmp ne i32 %25, -2147483648
  br label %35

35:                                               ; preds = %56, %5
  %36 = phi i64 [ 0, %5 ], [ %67, %56 ]
  %37 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %9, i64 0, i32 0, i64 %36
  %38 = load i32, i32* %37, align 4, !noalias !779
  %39 = sext i32 %38 to i64
  %40 = mul nsw i64 %39, %23
  %41 = icmp slt i64 %40, 2147483647
  %42 = select i1 %41, i64 %40, i64 2147483647
  %43 = icmp sgt i64 %42, -2147483648
  %44 = select i1 %43, i64 %42, i64 -2147483648
  %45 = trunc i64 %44 to i32
  %46 = icmp ne i32 %25, %45
  %47 = or i1 %34, %46
  br i1 %47, label %48, label %56

48:                                               ; preds = %35
  %49 = select i1 %46, i64 %26, i64 %44
  %50 = mul nsw i64 %49, %44
  %51 = icmp sgt i64 %50, -1
  %52 = select i1 %51, i64 1073741824, i64 -1073741823
  %53 = add nsw i64 %52, %50
  %54 = sdiv i64 %53, 2147483648
  %55 = trunc i64 %54 to i32
  br label %56

56:                                               ; preds = %48, %35
  %57 = phi i32 [ %55, %48 ], [ 2147483647, %35 ]
  %58 = and i32 %57, %32
  %59 = lshr i32 %57, 31
  %60 = add nsw i32 %59, %33
  %61 = ashr i32 %57, %28
  %62 = icmp sgt i32 %58, %60
  %63 = zext i1 %62 to i32
  %64 = add i32 %61, %19
  %65 = add i32 %64, %63
  %66 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %10, i64 0, i32 0, i64 %36
  store i32 %65, i32* %66, align 4, !alias.scope !776, !noalias !773
  %67 = add nuw nsw i64 %36, 1
  %68 = icmp eq i64 %67, 32
  br i1 %68, label %69, label %35

69:                                               ; preds = %56
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %15) #19, !noalias !773
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 4 %12, i8* nonnull align 4 %14, i64 128, i1 false)
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %14) #19, !noalias !773
  %70 = bitcast [32 x i32]* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %70) #19, !noalias !780
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %70, i8 -86, i64 128, i1 false) #19, !alias.scope !783, !noalias !780
  %71 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %71) #19, !noalias !786
  %72 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %72) #19, !noalias !786
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %72, i8* nonnull align 4 %12, i64 128, i1 false)
  %73 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.377", %"struct.gemmlowp::OutputPipelineEvalImpl.377"* %1, i64 0, i32 1, i32 0, i32 0, i32 0
  %74 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %73, align 8, !noalias !787
  %75 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %74, i64 0, i32 0
  %76 = load i32, i32* %75, align 4, !noalias !787
  %77 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %74, i64 0, i32 1
  %78 = load i32, i32* %77, align 4, !noalias !787
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %71, i8 -86, i64 128, i1 false) #19, !alias.scope !790, !noalias !786
  %79 = insertelement <4 x i32> undef, i32 %76, i32 0
  %80 = shufflevector <4 x i32> %79, <4 x i32> undef, <4 x i32> zeroinitializer
  %81 = insertelement <4 x i32> undef, i32 %78, i32 0
  %82 = shufflevector <4 x i32> %81, <4 x i32> undef, <4 x i32> zeroinitializer
  %83 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %6 to <4 x i32>*
  %84 = load <4 x i32>, <4 x i32>* %83, align 16, !noalias !787
  %85 = icmp slt <4 x i32> %84, %80
  %86 = select <4 x i1> %85, <4 x i32> %80, <4 x i32> %84
  %87 = icmp slt <4 x i32> %82, %86
  %88 = select <4 x i1> %87, <4 x i32> %82, <4 x i32> %86
  %89 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %7 to <4 x i32>*
  store <4 x i32> %88, <4 x i32>* %89, align 16, !alias.scope !790, !noalias !786
  %90 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 4
  %91 = bitcast i32* %90 to <4 x i32>*
  %92 = load <4 x i32>, <4 x i32>* %91, align 16, !noalias !787
  %93 = icmp slt <4 x i32> %92, %80
  %94 = select <4 x i1> %93, <4 x i32> %80, <4 x i32> %92
  %95 = icmp slt <4 x i32> %82, %94
  %96 = select <4 x i1> %95, <4 x i32> %82, <4 x i32> %94
  %97 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %7, i64 0, i32 0, i64 4
  %98 = bitcast i32* %97 to <4 x i32>*
  store <4 x i32> %96, <4 x i32>* %98, align 16, !alias.scope !790, !noalias !786
  %99 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 8
  %100 = bitcast i32* %99 to <4 x i32>*
  %101 = load <4 x i32>, <4 x i32>* %100, align 16, !noalias !787
  %102 = icmp slt <4 x i32> %101, %80
  %103 = select <4 x i1> %102, <4 x i32> %80, <4 x i32> %101
  %104 = icmp slt <4 x i32> %82, %103
  %105 = select <4 x i1> %104, <4 x i32> %82, <4 x i32> %103
  %106 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %7, i64 0, i32 0, i64 8
  %107 = bitcast i32* %106 to <4 x i32>*
  store <4 x i32> %105, <4 x i32>* %107, align 16, !alias.scope !790, !noalias !786
  %108 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 12
  %109 = bitcast i32* %108 to <4 x i32>*
  %110 = load <4 x i32>, <4 x i32>* %109, align 16, !noalias !787
  %111 = icmp slt <4 x i32> %110, %80
  %112 = select <4 x i1> %111, <4 x i32> %80, <4 x i32> %110
  %113 = icmp slt <4 x i32> %82, %112
  %114 = select <4 x i1> %113, <4 x i32> %82, <4 x i32> %112
  %115 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %7, i64 0, i32 0, i64 12
  %116 = bitcast i32* %115 to <4 x i32>*
  store <4 x i32> %114, <4 x i32>* %116, align 16, !alias.scope !790, !noalias !786
  %117 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 16
  %118 = bitcast i32* %117 to <4 x i32>*
  %119 = load <4 x i32>, <4 x i32>* %118, align 16, !noalias !787
  %120 = icmp slt <4 x i32> %119, %80
  %121 = select <4 x i1> %120, <4 x i32> %80, <4 x i32> %119
  %122 = icmp slt <4 x i32> %82, %121
  %123 = select <4 x i1> %122, <4 x i32> %82, <4 x i32> %121
  %124 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %7, i64 0, i32 0, i64 16
  %125 = bitcast i32* %124 to <4 x i32>*
  store <4 x i32> %123, <4 x i32>* %125, align 16, !alias.scope !790, !noalias !786
  %126 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 20
  %127 = bitcast i32* %126 to <4 x i32>*
  %128 = load <4 x i32>, <4 x i32>* %127, align 16, !noalias !787
  %129 = icmp slt <4 x i32> %128, %80
  %130 = select <4 x i1> %129, <4 x i32> %80, <4 x i32> %128
  %131 = icmp slt <4 x i32> %82, %130
  %132 = select <4 x i1> %131, <4 x i32> %82, <4 x i32> %130
  %133 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %7, i64 0, i32 0, i64 20
  %134 = bitcast i32* %133 to <4 x i32>*
  store <4 x i32> %132, <4 x i32>* %134, align 16, !alias.scope !790, !noalias !786
  %135 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 24
  %136 = bitcast i32* %135 to <4 x i32>*
  %137 = load <4 x i32>, <4 x i32>* %136, align 16, !noalias !787
  %138 = icmp slt <4 x i32> %137, %80
  %139 = select <4 x i1> %138, <4 x i32> %80, <4 x i32> %137
  %140 = icmp slt <4 x i32> %82, %139
  %141 = select <4 x i1> %140, <4 x i32> %82, <4 x i32> %139
  %142 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %7, i64 0, i32 0, i64 24
  %143 = bitcast i32* %142 to <4 x i32>*
  store <4 x i32> %141, <4 x i32>* %143, align 16, !alias.scope !790, !noalias !786
  %144 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 28
  %145 = bitcast i32* %144 to <4 x i32>*
  %146 = load <4 x i32>, <4 x i32>* %145, align 16, !noalias !787
  %147 = icmp slt <4 x i32> %146, %80
  %148 = select <4 x i1> %147, <4 x i32> %80, <4 x i32> %146
  %149 = icmp slt <4 x i32> %82, %148
  %150 = select <4 x i1> %149, <4 x i32> %82, <4 x i32> %148
  %151 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %7, i64 0, i32 0, i64 28
  %152 = bitcast i32* %151 to <4 x i32>*
  store <4 x i32> %150, <4 x i32>* %152, align 16, !alias.scope !790, !noalias !786
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %72) #19, !noalias !786
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %70, i8* nonnull align 16 %71, i64 128, i1 false) #19, !noalias !780
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %71) #19, !noalias !786
  %153 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.377", %"struct.gemmlowp::OutputPipelineEvalImpl.377"* %1, i64 0, i32 1, i32 1
  %154 = bitcast [32 x i32]* %8 to %"struct.gemmlowp::RegisterBlock.302"*
  tail call void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi3ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.310"* sret %0, %"struct.gemmlowp::OutputPipelineEvalImpl.379"* %153, %"struct.gemmlowp::RegisterBlock.302"* nonnull byval(%"struct.gemmlowp::RegisterBlock.302") align 8 %154, i32 %3, i32 %4) #19
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %70) #19, !noalias !780
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %12)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi3ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.310"* noalias sret, %"struct.gemmlowp::OutputPipelineEvalImpl.379"*, %"struct.gemmlowp::RegisterBlock.302"* byval(%"struct.gemmlowp::RegisterBlock.302") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %6 = alloca %"struct.gemmlowp::RegisterBuffer.303", align 16
  %7 = alloca %"struct.gemmlowp::RegisterBuffer.311", align 16
  %8 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %2 to i8*
  %9 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.311", %"struct.gemmlowp::RegisterBuffer.311"* %7, i64 0, i32 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %9) #19, !noalias !791
  %10 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %10) #19, !noalias !791
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %10, i8* nonnull align 8 %8, i64 128, i1 false)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 32, i1 false) #19, !alias.scope !794, !noalias !791
  %11 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %6 to <4 x i32>*
  %12 = load <4 x i32>, <4 x i32>* %11, align 16, !noalias !797
  %13 = icmp sgt <4 x i32> %12, zeroinitializer
  %14 = select <4 x i1> %13, <4 x i32> %12, <4 x i32> zeroinitializer
  %15 = icmp slt <4 x i32> %14, <i32 255, i32 255, i32 255, i32 255>
  %16 = select <4 x i1> %15, <4 x i32> %14, <4 x i32> <i32 255, i32 255, i32 255, i32 255>
  %17 = trunc <4 x i32> %16 to <4 x i8>
  %18 = bitcast %"struct.gemmlowp::RegisterBuffer.311"* %7 to <4 x i8>*
  store <4 x i8> %17, <4 x i8>* %18, align 16, !alias.scope !794, !noalias !791
  %19 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 4
  %20 = bitcast i32* %19 to <4 x i32>*
  %21 = load <4 x i32>, <4 x i32>* %20, align 16, !noalias !797
  %22 = icmp sgt <4 x i32> %21, zeroinitializer
  %23 = select <4 x i1> %22, <4 x i32> %21, <4 x i32> zeroinitializer
  %24 = icmp slt <4 x i32> %23, <i32 255, i32 255, i32 255, i32 255>
  %25 = select <4 x i1> %24, <4 x i32> %23, <4 x i32> <i32 255, i32 255, i32 255, i32 255>
  %26 = trunc <4 x i32> %25 to <4 x i8>
  %27 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.311", %"struct.gemmlowp::RegisterBuffer.311"* %7, i64 0, i32 0, i64 4
  %28 = bitcast i8* %27 to <4 x i8>*
  store <4 x i8> %26, <4 x i8>* %28, align 4, !alias.scope !794, !noalias !791
  %29 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 8
  %30 = bitcast i32* %29 to <4 x i32>*
  %31 = load <4 x i32>, <4 x i32>* %30, align 16, !noalias !797
  %32 = icmp sgt <4 x i32> %31, zeroinitializer
  %33 = select <4 x i1> %32, <4 x i32> %31, <4 x i32> zeroinitializer
  %34 = icmp slt <4 x i32> %33, <i32 255, i32 255, i32 255, i32 255>
  %35 = select <4 x i1> %34, <4 x i32> %33, <4 x i32> <i32 255, i32 255, i32 255, i32 255>
  %36 = trunc <4 x i32> %35 to <4 x i8>
  %37 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.311", %"struct.gemmlowp::RegisterBuffer.311"* %7, i64 0, i32 0, i64 8
  %38 = bitcast i8* %37 to <4 x i8>*
  store <4 x i8> %36, <4 x i8>* %38, align 8, !alias.scope !794, !noalias !791
  %39 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 12
  %40 = bitcast i32* %39 to <4 x i32>*
  %41 = load <4 x i32>, <4 x i32>* %40, align 16, !noalias !797
  %42 = icmp sgt <4 x i32> %41, zeroinitializer
  %43 = select <4 x i1> %42, <4 x i32> %41, <4 x i32> zeroinitializer
  %44 = icmp slt <4 x i32> %43, <i32 255, i32 255, i32 255, i32 255>
  %45 = select <4 x i1> %44, <4 x i32> %43, <4 x i32> <i32 255, i32 255, i32 255, i32 255>
  %46 = trunc <4 x i32> %45 to <4 x i8>
  %47 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.311", %"struct.gemmlowp::RegisterBuffer.311"* %7, i64 0, i32 0, i64 12
  %48 = bitcast i8* %47 to <4 x i8>*
  store <4 x i8> %46, <4 x i8>* %48, align 4, !alias.scope !794, !noalias !791
  %49 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 16
  %50 = bitcast i32* %49 to <4 x i32>*
  %51 = load <4 x i32>, <4 x i32>* %50, align 16, !noalias !797
  %52 = icmp sgt <4 x i32> %51, zeroinitializer
  %53 = select <4 x i1> %52, <4 x i32> %51, <4 x i32> zeroinitializer
  %54 = icmp slt <4 x i32> %53, <i32 255, i32 255, i32 255, i32 255>
  %55 = select <4 x i1> %54, <4 x i32> %53, <4 x i32> <i32 255, i32 255, i32 255, i32 255>
  %56 = trunc <4 x i32> %55 to <4 x i8>
  %57 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.311", %"struct.gemmlowp::RegisterBuffer.311"* %7, i64 0, i32 0, i64 16
  %58 = bitcast i8* %57 to <4 x i8>*
  store <4 x i8> %56, <4 x i8>* %58, align 16, !alias.scope !794, !noalias !791
  %59 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 20
  %60 = bitcast i32* %59 to <4 x i32>*
  %61 = load <4 x i32>, <4 x i32>* %60, align 16, !noalias !797
  %62 = icmp sgt <4 x i32> %61, zeroinitializer
  %63 = select <4 x i1> %62, <4 x i32> %61, <4 x i32> zeroinitializer
  %64 = icmp slt <4 x i32> %63, <i32 255, i32 255, i32 255, i32 255>
  %65 = select <4 x i1> %64, <4 x i32> %63, <4 x i32> <i32 255, i32 255, i32 255, i32 255>
  %66 = trunc <4 x i32> %65 to <4 x i8>
  %67 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.311", %"struct.gemmlowp::RegisterBuffer.311"* %7, i64 0, i32 0, i64 20
  %68 = bitcast i8* %67 to <4 x i8>*
  store <4 x i8> %66, <4 x i8>* %68, align 4, !alias.scope !794, !noalias !791
  %69 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 24
  %70 = bitcast i32* %69 to <4 x i32>*
  %71 = load <4 x i32>, <4 x i32>* %70, align 16, !noalias !797
  %72 = icmp sgt <4 x i32> %71, zeroinitializer
  %73 = select <4 x i1> %72, <4 x i32> %71, <4 x i32> zeroinitializer
  %74 = icmp slt <4 x i32> %73, <i32 255, i32 255, i32 255, i32 255>
  %75 = select <4 x i1> %74, <4 x i32> %73, <4 x i32> <i32 255, i32 255, i32 255, i32 255>
  %76 = trunc <4 x i32> %75 to <4 x i8>
  %77 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.311", %"struct.gemmlowp::RegisterBuffer.311"* %7, i64 0, i32 0, i64 24
  %78 = bitcast i8* %77 to <4 x i8>*
  store <4 x i8> %76, <4 x i8>* %78, align 8, !alias.scope !794, !noalias !791
  %79 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 28
  %80 = bitcast i32* %79 to <4 x i32>*
  %81 = load <4 x i32>, <4 x i32>* %80, align 16, !noalias !797
  %82 = icmp sgt <4 x i32> %81, zeroinitializer
  %83 = select <4 x i1> %82, <4 x i32> %81, <4 x i32> zeroinitializer
  %84 = icmp slt <4 x i32> %83, <i32 255, i32 255, i32 255, i32 255>
  %85 = select <4 x i1> %84, <4 x i32> %83, <4 x i32> <i32 255, i32 255, i32 255, i32 255>
  %86 = trunc <4 x i32> %85 to <4 x i8>
  %87 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.311", %"struct.gemmlowp::RegisterBuffer.311"* %7, i64 0, i32 0, i64 28
  %88 = bitcast i8* %87 to <4 x i8>*
  store <4 x i8> %86, <4 x i8>* %88, align 4, !alias.scope !794, !noalias !791
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %10) #19, !noalias !791
  %89 = bitcast %"struct.gemmlowp::RegisterBuffer.311"* %7 to <16 x i8>*
  %90 = load <16 x i8>, <16 x i8>* %89, align 16
  %91 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.311", %"struct.gemmlowp::RegisterBuffer.311"* %7, i64 0, i32 0, i64 16
  %92 = bitcast i8* %91 to <16 x i8>*
  %93 = load <16 x i8>, <16 x i8>* %92, align 16
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %9) #19, !noalias !791
  %94 = bitcast %"struct.gemmlowp::RegisterBlock.310"* %0 to <16 x i8>*
  store <16 x i8> %90, <16 x i8>* %94, align 1
  %95 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %0, i64 0, i32 0, i32 0, i64 16
  %96 = bitcast i8* %95 to <16 x i8>*
  store <16 x i8> %93, <16 x i8>* %96, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi0ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.366"*, %"struct.gemmlowp::RegisterBlock.312"* byval(%"struct.gemmlowp::RegisterBlock.312") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %5 = alloca %"struct.gemmlowp::RegisterBuffer.313", align 8
  %6 = alloca %"struct.gemmlowp::RegisterBuffer.313", align 8
  %7 = alloca [16 x i32], align 8
  %8 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 0
  %9 = load i32, i32* %8, align 8
  %10 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 1
  %11 = load i32, i32* %10, align 4
  %12 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 2
  %13 = load i32, i32* %12, align 8
  %14 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 3
  %15 = load i32, i32* %14, align 4
  %16 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 4
  %17 = load i32, i32* %16, align 8
  %18 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 5
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 6
  %21 = load i32, i32* %20, align 8
  %22 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 7
  %23 = load i32, i32* %22, align 4
  %24 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 8
  %25 = load i32, i32* %24, align 8
  %26 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 9
  %27 = load i32, i32* %26, align 4
  %28 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 10
  %29 = load i32, i32* %28, align 8
  %30 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 11
  %31 = load i32, i32* %30, align 4
  %32 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 12
  %33 = load i32, i32* %32, align 8
  %34 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 13
  %35 = load i32, i32* %34, align 4
  %36 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 14
  %37 = load i32, i32* %36, align 8
  %38 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 15
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.366", %"struct.gemmlowp::OutputPipelineEvalImpl.366"* %0, i64 0, i32 0, i32 0
  %41 = load %"struct.gemmlowp::OutputStageBiasAddition"*, %"struct.gemmlowp::OutputStageBiasAddition"** %40, align 8, !noalias !798
  %42 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition", %"struct.gemmlowp::OutputStageBiasAddition"* %41, i64 0, i32 0, i32 0
  %43 = load i32*, i32** %42, align 8, !noalias !798
  %44 = sext i32 %2 to i64
  %45 = getelementptr i32, i32* %43, i64 %44
  %46 = bitcast i32* %45 to i64*
  %47 = load i64, i64* %46, align 4, !noalias !798
  %48 = getelementptr inbounds i32, i32* %45, i64 2
  %49 = bitcast i32* %48 to i64*
  %50 = load i64, i64* %49, align 4, !noalias !798
  %51 = trunc i64 %47 to i32
  %52 = lshr i64 %47, 32
  %53 = trunc i64 %52 to i32
  %54 = add nsw i32 %9, %51
  %55 = add nsw i32 %11, %53
  %56 = trunc i64 %50 to i32
  %57 = add nsw i32 %13, %56
  %58 = lshr i64 %50, 32
  %59 = trunc i64 %58 to i32
  %60 = add nsw i32 %15, %59
  %61 = add nsw i32 %17, %51
  %62 = add nsw i32 %19, %53
  %63 = add nsw i32 %21, %56
  %64 = add nsw i32 %23, %59
  %65 = add nsw i32 %25, %51
  %66 = add nsw i32 %27, %53
  %67 = add nsw i32 %29, %56
  %68 = add nsw i32 %31, %59
  %69 = add nsw i32 %33, %51
  %70 = add nsw i32 %35, %53
  %71 = add nsw i32 %37, %56
  %72 = add nsw i32 %39, %59
  %73 = bitcast [16 x i32]* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %73) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %73, i8 -86, i64 64, i1 false) #19, !alias.scope !801
  %74 = bitcast %"struct.gemmlowp::RegisterBuffer.313"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %74) #19, !noalias !801
  %75 = bitcast %"struct.gemmlowp::RegisterBuffer.313"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %75) #19, !noalias !801
  %76 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %5, i64 0, i32 0, i64 0
  store i32 %54, i32* %76, align 8
  %77 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %5, i64 0, i32 0, i64 1
  store i32 %55, i32* %77, align 4
  %78 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %5, i64 0, i32 0, i64 2
  store i32 %57, i32* %78, align 8
  %79 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %5, i64 0, i32 0, i64 3
  store i32 %60, i32* %79, align 4
  %80 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %5, i64 0, i32 0, i64 4
  store i32 %61, i32* %80, align 8
  %81 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %5, i64 0, i32 0, i64 5
  store i32 %62, i32* %81, align 4
  %82 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %5, i64 0, i32 0, i64 6
  store i32 %63, i32* %82, align 8
  %83 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %5, i64 0, i32 0, i64 7
  store i32 %64, i32* %83, align 4
  %84 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %5, i64 0, i32 0, i64 8
  store i32 %65, i32* %84, align 8
  %85 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %5, i64 0, i32 0, i64 9
  store i32 %66, i32* %85, align 4
  %86 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %5, i64 0, i32 0, i64 10
  store i32 %67, i32* %86, align 8
  %87 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %5, i64 0, i32 0, i64 11
  store i32 %68, i32* %87, align 4
  %88 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %5, i64 0, i32 0, i64 12
  store i32 %69, i32* %88, align 8
  %89 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %5, i64 0, i32 0, i64 13
  store i32 %70, i32* %89, align 4
  %90 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %5, i64 0, i32 0, i64 14
  store i32 %71, i32* %90, align 8
  %91 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %5, i64 0, i32 0, i64 15
  store i32 %72, i32* %91, align 4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %74, i8 -86, i64 64, i1 false) #19, !alias.scope !804, !noalias !801
  %92 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.366", %"struct.gemmlowp::OutputPipelineEvalImpl.366"* %0, i64 0, i32 1, i32 0, i32 0, i32 0
  %93 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %92, align 8, !noalias !807
  %94 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %93, i64 0, i32 2
  %95 = load i32, i32* %94, align 4, !noalias !807
  %96 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.366", %"struct.gemmlowp::OutputPipelineEvalImpl.366"* %0, i64 0, i32 1, i32 0, i32 0, i32 1
  %97 = load i32, i32* %96, align 8, !noalias !807
  %98 = shl i32 1, %97
  %99 = sext i32 %98 to i64
  %100 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %93, i64 0, i32 0
  %101 = load i32, i32* %100, align 4, !noalias !807
  %102 = sext i32 %101 to i64
  %103 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.366", %"struct.gemmlowp::OutputPipelineEvalImpl.366"* %0, i64 0, i32 1, i32 0, i32 0, i32 2
  %104 = load i32, i32* %103, align 4, !noalias !807
  %105 = zext i32 %104 to i64
  %106 = shl nsw i64 -1, %105
  %107 = trunc i64 %106 to i32
  %108 = xor i32 %107, -1
  %109 = ashr i32 %108, 1
  %110 = icmp ne i32 %101, -2147483648
  br label %111

111:                                              ; preds = %144, %4
  %112 = phi i32 [ %54, %4 ], [ %146, %144 ]
  %113 = phi i64 [ 0, %4 ], [ %142, %144 ]
  %114 = sext i32 %112 to i64
  %115 = mul nsw i64 %114, %99
  %116 = icmp slt i64 %115, 2147483647
  %117 = select i1 %116, i64 %115, i64 2147483647
  %118 = icmp sgt i64 %117, -2147483648
  %119 = select i1 %118, i64 %117, i64 -2147483648
  %120 = trunc i64 %119 to i32
  %121 = icmp ne i32 %101, %120
  %122 = or i1 %110, %121
  br i1 %122, label %123, label %131

123:                                              ; preds = %111
  %124 = select i1 %121, i64 %102, i64 %119
  %125 = mul nsw i64 %124, %119
  %126 = icmp sgt i64 %125, -1
  %127 = select i1 %126, i64 1073741824, i64 -1073741823
  %128 = add nsw i64 %127, %125
  %129 = sdiv i64 %128, 2147483648
  %130 = trunc i64 %129 to i32
  br label %131

131:                                              ; preds = %123, %111
  %132 = phi i32 [ %130, %123 ], [ 2147483647, %111 ]
  %133 = and i32 %132, %108
  %134 = lshr i32 %132, 31
  %135 = add nsw i32 %134, %109
  %136 = ashr i32 %132, %104
  %137 = icmp sgt i32 %133, %135
  %138 = zext i1 %137 to i32
  %139 = add i32 %136, %95
  %140 = add i32 %139, %138
  %141 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %6, i64 0, i32 0, i64 %113
  store i32 %140, i32* %141, align 4, !alias.scope !804, !noalias !801
  %142 = add nuw nsw i64 %113, 1
  %143 = icmp eq i64 %142, 16
  br i1 %143, label %147, label %144

144:                                              ; preds = %131
  %145 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %5, i64 0, i32 0, i64 %142
  %146 = load i32, i32* %145, align 4, !noalias !807
  br label %111

147:                                              ; preds = %131
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %75) #19, !noalias !801
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %73, i8* nonnull align 8 %74, i64 64, i1 false) #19
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %74) #19, !noalias !801
  %148 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.366", %"struct.gemmlowp::OutputPipelineEvalImpl.366"* %0, i64 0, i32 1, i32 1
  %149 = bitcast [16 x i32]* %7 to %"struct.gemmlowp::RegisterBlock.312"*
  %150 = tail call { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi2ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.369"* %148, %"struct.gemmlowp::RegisterBlock.312"* nonnull byval(%"struct.gemmlowp::RegisterBlock.312") align 8 %149, i32 %2, i32 %3) #19
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %73) #19
  ret { i64, i64 } %150
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp16StoreFinalOutputINS_13RegisterBlockIhLi4ELi4EEENS_9MatrixMapIhLNS_8MapOrderE0EEEEEvT_PT0_ii(i64, i64, %"class.gemmlowp::MatrixMap.182"*, i32, i32) local_unnamed_addr #1 comdat {
  %6 = trunc i64 %0 to i8
  %7 = lshr i64 %0, 8
  %8 = trunc i64 %7 to i8
  %9 = lshr i64 %0, 16
  %10 = trunc i64 %9 to i8
  %11 = lshr i64 %0, 24
  %12 = trunc i64 %11 to i8
  %13 = lshr i64 %0, 32
  %14 = trunc i64 %13 to i8
  %15 = lshr i64 %0, 40
  %16 = trunc i64 %15 to i8
  %17 = lshr i64 %0, 48
  %18 = trunc i64 %17 to i8
  %19 = lshr i64 %0, 56
  %20 = trunc i64 %19 to i8
  %21 = trunc i64 %1 to i8
  %22 = lshr i64 %1, 8
  %23 = trunc i64 %22 to i8
  %24 = lshr i64 %1, 16
  %25 = trunc i64 %24 to i8
  %26 = lshr i64 %1, 24
  %27 = trunc i64 %26 to i8
  %28 = lshr i64 %1, 32
  %29 = trunc i64 %28 to i8
  %30 = lshr i64 %1, 40
  %31 = trunc i64 %30 to i8
  %32 = lshr i64 %1, 48
  %33 = trunc i64 %32 to i8
  %34 = lshr i64 %1, 56
  %35 = trunc i64 %34 to i8
  %36 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %2, i64 0, i32 0
  %37 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %2, i64 0, i32 3
  %38 = sext i32 %4 to i64
  %39 = sext i32 %3 to i64
  %40 = load i8*, i8** %36, align 8
  %41 = getelementptr inbounds i8, i8* %40, i64 %39
  %42 = load i32, i32* %37, align 8
  %43 = sext i32 %42 to i64
  %44 = mul nsw i64 %43, %38
  %45 = getelementptr inbounds i8, i8* %41, i64 %44
  store i8 %6, i8* %45, align 1
  %46 = add nsw i64 %38, 1
  %47 = load i8*, i8** %36, align 8
  %48 = getelementptr inbounds i8, i8* %47, i64 %39
  %49 = load i32, i32* %37, align 8
  %50 = sext i32 %49 to i64
  %51 = mul nsw i64 %46, %50
  %52 = getelementptr inbounds i8, i8* %48, i64 %51
  store i8 %14, i8* %52, align 1
  %53 = add nsw i64 %38, 2
  %54 = load i8*, i8** %36, align 8
  %55 = getelementptr inbounds i8, i8* %54, i64 %39
  %56 = load i32, i32* %37, align 8
  %57 = sext i32 %56 to i64
  %58 = mul nsw i64 %53, %57
  %59 = getelementptr inbounds i8, i8* %55, i64 %58
  store i8 %21, i8* %59, align 1
  %60 = add nsw i64 %38, 3
  %61 = load i8*, i8** %36, align 8
  %62 = getelementptr inbounds i8, i8* %61, i64 %39
  %63 = load i32, i32* %37, align 8
  %64 = sext i32 %63 to i64
  %65 = mul nsw i64 %60, %64
  %66 = getelementptr inbounds i8, i8* %62, i64 %65
  store i8 %29, i8* %66, align 1
  %67 = add nsw i64 %39, 1
  %68 = load i8*, i8** %36, align 8
  %69 = getelementptr inbounds i8, i8* %68, i64 %67
  %70 = load i32, i32* %37, align 8
  %71 = sext i32 %70 to i64
  %72 = mul nsw i64 %71, %38
  %73 = getelementptr inbounds i8, i8* %69, i64 %72
  store i8 %8, i8* %73, align 1
  %74 = load i8*, i8** %36, align 8
  %75 = getelementptr inbounds i8, i8* %74, i64 %67
  %76 = load i32, i32* %37, align 8
  %77 = sext i32 %76 to i64
  %78 = mul nsw i64 %46, %77
  %79 = getelementptr inbounds i8, i8* %75, i64 %78
  store i8 %16, i8* %79, align 1
  %80 = load i8*, i8** %36, align 8
  %81 = getelementptr inbounds i8, i8* %80, i64 %67
  %82 = load i32, i32* %37, align 8
  %83 = sext i32 %82 to i64
  %84 = mul nsw i64 %53, %83
  %85 = getelementptr inbounds i8, i8* %81, i64 %84
  store i8 %23, i8* %85, align 1
  %86 = load i8*, i8** %36, align 8
  %87 = getelementptr inbounds i8, i8* %86, i64 %67
  %88 = load i32, i32* %37, align 8
  %89 = sext i32 %88 to i64
  %90 = mul nsw i64 %60, %89
  %91 = getelementptr inbounds i8, i8* %87, i64 %90
  store i8 %31, i8* %91, align 1
  %92 = add nsw i64 %39, 2
  %93 = load i8*, i8** %36, align 8
  %94 = getelementptr inbounds i8, i8* %93, i64 %92
  %95 = load i32, i32* %37, align 8
  %96 = sext i32 %95 to i64
  %97 = mul nsw i64 %96, %38
  %98 = getelementptr inbounds i8, i8* %94, i64 %97
  store i8 %10, i8* %98, align 1
  %99 = load i8*, i8** %36, align 8
  %100 = getelementptr inbounds i8, i8* %99, i64 %92
  %101 = load i32, i32* %37, align 8
  %102 = sext i32 %101 to i64
  %103 = mul nsw i64 %46, %102
  %104 = getelementptr inbounds i8, i8* %100, i64 %103
  store i8 %18, i8* %104, align 1
  %105 = load i8*, i8** %36, align 8
  %106 = getelementptr inbounds i8, i8* %105, i64 %92
  %107 = load i32, i32* %37, align 8
  %108 = sext i32 %107 to i64
  %109 = mul nsw i64 %53, %108
  %110 = getelementptr inbounds i8, i8* %106, i64 %109
  store i8 %25, i8* %110, align 1
  %111 = load i8*, i8** %36, align 8
  %112 = getelementptr inbounds i8, i8* %111, i64 %92
  %113 = load i32, i32* %37, align 8
  %114 = sext i32 %113 to i64
  %115 = mul nsw i64 %60, %114
  %116 = getelementptr inbounds i8, i8* %112, i64 %115
  store i8 %33, i8* %116, align 1
  %117 = add nsw i64 %39, 3
  %118 = load i8*, i8** %36, align 8
  %119 = getelementptr inbounds i8, i8* %118, i64 %117
  %120 = load i32, i32* %37, align 8
  %121 = sext i32 %120 to i64
  %122 = mul nsw i64 %121, %38
  %123 = getelementptr inbounds i8, i8* %119, i64 %122
  store i8 %12, i8* %123, align 1
  %124 = load i8*, i8** %36, align 8
  %125 = getelementptr inbounds i8, i8* %124, i64 %117
  %126 = load i32, i32* %37, align 8
  %127 = sext i32 %126 to i64
  %128 = mul nsw i64 %46, %127
  %129 = getelementptr inbounds i8, i8* %125, i64 %128
  store i8 %20, i8* %129, align 1
  %130 = load i8*, i8** %36, align 8
  %131 = getelementptr inbounds i8, i8* %130, i64 %117
  %132 = load i32, i32* %37, align 8
  %133 = sext i32 %132 to i64
  %134 = mul nsw i64 %53, %133
  %135 = getelementptr inbounds i8, i8* %131, i64 %134
  store i8 %27, i8* %135, align 1
  %136 = load i8*, i8** %36, align 8
  %137 = getelementptr inbounds i8, i8* %136, i64 %117
  %138 = load i32, i32* %37, align 8
  %139 = sext i32 %138 to i64
  %140 = mul nsw i64 %60, %139
  %141 = getelementptr inbounds i8, i8* %137, i64 %140
  store i8 %35, i8* %141, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi2ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.369"*, %"struct.gemmlowp::RegisterBlock.312"* byval(%"struct.gemmlowp::RegisterBlock.312") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %5 = alloca %"struct.gemmlowp::RegisterBlock.312", align 16
  %6 = bitcast %"struct.gemmlowp::RegisterBlock.312"* %1 to <4 x i32>*
  %7 = load <4 x i32>, <4 x i32>* %6, align 8
  %8 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 4
  %9 = bitcast i32* %8 to <4 x i32>*
  %10 = load <4 x i32>, <4 x i32>* %9, align 8
  %11 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 8
  %12 = bitcast i32* %11 to <4 x i32>*
  %13 = load <4 x i32>, <4 x i32>* %12, align 8
  %14 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 12
  %15 = bitcast i32* %14 to <4 x i32>*
  %16 = load <4 x i32>, <4 x i32>* %15, align 8
  %17 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.369", %"struct.gemmlowp::OutputPipelineEvalImpl.369"* %0, i64 0, i32 0, i32 0, i32 0
  %18 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %17, align 8, !noalias !808
  %19 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %18, i64 0, i32 0
  %20 = load i32, i32* %19, align 4, !noalias !808
  %21 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %18, i64 0, i32 1
  %22 = load i32, i32* %21, align 4, !noalias !808
  %23 = insertelement <4 x i32> undef, i32 %20, i32 0
  %24 = shufflevector <4 x i32> %23, <4 x i32> undef, <4 x i32> zeroinitializer
  %25 = icmp slt <4 x i32> %7, %24
  %26 = select <4 x i1> %25, <4 x i32> %24, <4 x i32> %7
  %27 = insertelement <4 x i32> undef, i32 %22, i32 0
  %28 = shufflevector <4 x i32> %27, <4 x i32> undef, <4 x i32> zeroinitializer
  %29 = icmp slt <4 x i32> %28, %26
  %30 = select <4 x i1> %29, <4 x i32> %28, <4 x i32> %26
  %31 = icmp slt <4 x i32> %10, %24
  %32 = select <4 x i1> %31, <4 x i32> %24, <4 x i32> %10
  %33 = icmp slt <4 x i32> %28, %32
  %34 = select <4 x i1> %33, <4 x i32> %28, <4 x i32> %32
  %35 = icmp slt <4 x i32> %13, %24
  %36 = select <4 x i1> %35, <4 x i32> %24, <4 x i32> %13
  %37 = icmp slt <4 x i32> %28, %36
  %38 = select <4 x i1> %37, <4 x i32> %28, <4 x i32> %36
  %39 = icmp slt <4 x i32> %16, %24
  %40 = select <4 x i1> %39, <4 x i32> %24, <4 x i32> %16
  %41 = icmp slt <4 x i32> %28, %40
  %42 = select <4 x i1> %41, <4 x i32> %28, <4 x i32> %40
  %43 = bitcast %"struct.gemmlowp::RegisterBlock.312"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %43)
  %44 = bitcast %"struct.gemmlowp::RegisterBlock.312"* %5 to <4 x i32>*
  store <4 x i32> %30, <4 x i32>* %44, align 16
  %45 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %5, i64 0, i32 0, i32 0, i64 4
  %46 = bitcast i32* %45 to <4 x i32>*
  store <4 x i32> %34, <4 x i32>* %46, align 16
  %47 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %5, i64 0, i32 0, i32 0, i64 8
  %48 = bitcast i32* %47 to <4 x i32>*
  store <4 x i32> %38, <4 x i32>* %48, align 16
  %49 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %5, i64 0, i32 0, i32 0, i64 12
  %50 = bitcast i32* %49 to <4 x i32>*
  store <4 x i32> %42, <4 x i32>* %50, align 16
  %51 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.369", %"struct.gemmlowp::OutputPipelineEvalImpl.369"* %0, i64 0, i32 1, i32 0
  %52 = tail call { i64, i64 } @_ZNK8gemmlowp19OutputStageEvalImplINS_32OutputStageSaturatingCastToUint8ENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii(%"struct.gemmlowp::OutputStageEvalImpl.280"* %51, %"struct.gemmlowp::RegisterBlock.312"* nonnull byval(%"struct.gemmlowp::RegisterBlock.312") align 8 %5, i32 %2, i32 %3) #19
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %43)
  ret { i64, i64 } %52
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_13RegisterBlockIiLi1ELi4EEEE7ExecuteINS_9MatrixMapIhLNS_8MapOrderE0EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.356"*, i64, i64, %"class.gemmlowp::MatrixMap.182"*, i32, i32, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %9 = trunc i64 %1 to i32
  %10 = lshr i64 %1, 32
  %11 = trunc i64 %10 to i32
  %12 = trunc i64 %2 to i32
  %13 = lshr i64 %2, 32
  %14 = trunc i64 %13 to i32
  %15 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.356", %"struct.gemmlowp::OutputPipelineExecutor.356"* %0, i64 0, i32 0, i32 0, i32 0
  %16 = load %"struct.gemmlowp::OutputStageBiasAddition"*, %"struct.gemmlowp::OutputStageBiasAddition"** %15, align 8
  %17 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition", %"struct.gemmlowp::OutputStageBiasAddition"* %16, i64 0, i32 0, i32 0
  %18 = load i32*, i32** %17, align 8
  %19 = sext i32 %4 to i64
  %20 = getelementptr inbounds i32, i32* %18, i64 %19
  %21 = load i32, i32* %20, align 4
  %22 = add nsw i32 %21, %9
  %23 = add nsw i32 %21, %11
  %24 = add nsw i32 %21, %12
  %25 = zext i32 %24 to i64
  %26 = add nsw i32 %21, %14
  %27 = zext i32 %26 to i64
  %28 = shl nuw i64 %27, 32
  %29 = or i64 %28, %25
  %30 = zext i32 %23 to i64
  %31 = shl nuw i64 %30, 32
  %32 = zext i32 %22 to i64
  %33 = or i64 %31, %32
  %34 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.356", %"struct.gemmlowp::OutputPipelineExecutor.356"* %0, i64 0, i32 0, i32 1, i32 0, i32 0
  %35 = tail call { i64, i64 } @_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi4EEEE4EvalES3_(%"struct.gemmlowp::OutputStageEvalBufferImpl.231"* %34, i64 %33, i64 %29) #19
  %36 = extractvalue { i64, i64 } %35, 0
  %37 = extractvalue { i64, i64 } %35, 1
  %38 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.356", %"struct.gemmlowp::OutputPipelineExecutor.356"* %0, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %39 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %38, align 8
  %40 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %39, i64 0, i32 0
  %41 = load i32, i32* %40, align 4
  %42 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %39, i64 0, i32 1
  %43 = load i32, i32* %42, align 4
  %44 = trunc i64 %36 to i32
  %45 = icmp sgt i32 %41, %44
  %46 = select i1 %45, i32 %41, i32 %44
  %47 = icmp slt i32 %43, %46
  %48 = select i1 %47, i32 %43, i32 %46
  %49 = lshr i64 %36, 32
  %50 = trunc i64 %49 to i32
  %51 = icmp sgt i32 %41, %50
  %52 = select i1 %51, i32 %41, i32 %50
  %53 = icmp slt i32 %43, %52
  %54 = select i1 %53, i32 %43, i32 %52
  %55 = trunc i64 %37 to i32
  %56 = icmp sgt i32 %41, %55
  %57 = select i1 %56, i32 %41, i32 %55
  %58 = icmp slt i32 %43, %57
  %59 = select i1 %58, i32 %43, i32 %57
  %60 = lshr i64 %37, 32
  %61 = trunc i64 %60 to i32
  %62 = icmp sgt i32 %41, %61
  %63 = select i1 %62, i32 %41, i32 %61
  %64 = icmp slt i32 %43, %63
  %65 = select i1 %64, i32 %43, i32 %63
  %66 = icmp sgt i32 %48, 0
  %67 = select i1 %66, i32 %48, i32 0
  %68 = icmp slt i32 %67, 255
  %69 = select i1 %68, i32 %67, i32 255
  %70 = icmp sgt i32 %54, 0
  %71 = select i1 %70, i32 %54, i32 0
  %72 = icmp slt i32 %71, 255
  %73 = select i1 %72, i32 %71, i32 255
  %74 = icmp sgt i32 %59, 0
  %75 = select i1 %74, i32 %59, i32 0
  %76 = icmp slt i32 %75, 255
  %77 = select i1 %76, i32 %75, i32 255
  %78 = icmp sgt i32 %65, 0
  %79 = select i1 %78, i32 %65, i32 0
  %80 = icmp slt i32 %79, 255
  %81 = select i1 %80, i32 %79, i32 255
  %82 = trunc i32 %69 to i8
  %83 = trunc i32 %73 to i8
  %84 = trunc i32 %77 to i8
  %85 = trunc i32 %81 to i8
  %86 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %3, i64 0, i32 0
  %87 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %3, i64 0, i32 3
  %88 = sext i32 %7 to i64
  %89 = sext i32 %6 to i64
  %90 = load i8*, i8** %86, align 8
  %91 = getelementptr inbounds i8, i8* %90, i64 %89
  %92 = load i32, i32* %87, align 8
  %93 = sext i32 %92 to i64
  %94 = mul nsw i64 %93, %88
  %95 = getelementptr inbounds i8, i8* %91, i64 %94
  store i8 %82, i8* %95, align 1
  %96 = add nsw i64 %88, 1
  %97 = load i8*, i8** %86, align 8
  %98 = getelementptr inbounds i8, i8* %97, i64 %89
  %99 = load i32, i32* %87, align 8
  %100 = sext i32 %99 to i64
  %101 = mul nsw i64 %96, %100
  %102 = getelementptr inbounds i8, i8* %98, i64 %101
  store i8 %83, i8* %102, align 1
  %103 = add nsw i64 %88, 2
  %104 = load i8*, i8** %86, align 8
  %105 = getelementptr inbounds i8, i8* %104, i64 %89
  %106 = load i32, i32* %87, align 8
  %107 = sext i32 %106 to i64
  %108 = mul nsw i64 %103, %107
  %109 = getelementptr inbounds i8, i8* %105, i64 %108
  store i8 %84, i8* %109, align 1
  %110 = add nsw i64 %88, 3
  %111 = load i8*, i8** %86, align 8
  %112 = getelementptr inbounds i8, i8* %111, i64 %89
  %113 = load i32, i32* %87, align 8
  %114 = sext i32 %113 to i64
  %115 = mul nsw i64 %110, %114
  %116 = getelementptr inbounds i8, i8* %112, i64 %115
  store i8 %85, i8* %116, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi1ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalESE_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.350"*, %"struct.gemmlowp::RegisterBlock.304"* byval(%"struct.gemmlowp::RegisterBlock.304") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %5 = alloca %"struct.gemmlowp::RegisterBuffer.305", align 8
  %6 = alloca %"struct.gemmlowp::RegisterBuffer.305", align 4
  %7 = bitcast %"struct.gemmlowp::RegisterBlock.304"* %1 to i8*
  %8 = bitcast %"struct.gemmlowp::RegisterBuffer.305"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %8) #19, !noalias !813
  %9 = bitcast %"struct.gemmlowp::RegisterBuffer.305"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %9) #19, !noalias !813
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %9, i8* nonnull align 8 %7, i64 32, i1 false)
  %10 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.350", %"struct.gemmlowp::OutputPipelineEvalImpl.350"* %0, i64 0, i32 0, i32 0, i32 0
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %8, i8 -86, i64 32, i1 false) #19, !alias.scope !816, !noalias !813
  %11 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %10, align 8, !noalias !819
  %12 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %11, i64 0, i32 2
  %13 = load i32, i32* %12, align 4, !noalias !819
  %14 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.350", %"struct.gemmlowp::OutputPipelineEvalImpl.350"* %0, i64 0, i32 0, i32 0, i32 1
  %15 = load i32, i32* %14, align 8, !noalias !819
  %16 = shl i32 1, %15
  %17 = sext i32 %16 to i64
  %18 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %11, i64 0, i32 0
  %19 = load i32, i32* %18, align 4, !noalias !819
  %20 = sext i32 %19 to i64
  %21 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.350", %"struct.gemmlowp::OutputPipelineEvalImpl.350"* %0, i64 0, i32 0, i32 0, i32 2
  %22 = load i32, i32* %21, align 4, !noalias !819
  %23 = zext i32 %22 to i64
  %24 = shl nsw i64 -1, %23
  %25 = trunc i64 %24 to i32
  %26 = xor i32 %25, -1
  %27 = ashr i32 %26, 1
  %28 = icmp ne i32 %19, -2147483648
  br label %29

29:                                               ; preds = %50, %4
  %30 = phi i64 [ 0, %4 ], [ %61, %50 ]
  %31 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.305", %"struct.gemmlowp::RegisterBuffer.305"* %5, i64 0, i32 0, i64 %30
  %32 = load i32, i32* %31, align 4, !noalias !819
  %33 = sext i32 %32 to i64
  %34 = mul nsw i64 %33, %17
  %35 = icmp slt i64 %34, 2147483647
  %36 = select i1 %35, i64 %34, i64 2147483647
  %37 = icmp sgt i64 %36, -2147483648
  %38 = select i1 %37, i64 %36, i64 -2147483648
  %39 = trunc i64 %38 to i32
  %40 = icmp ne i32 %19, %39
  %41 = or i1 %28, %40
  br i1 %41, label %42, label %50

42:                                               ; preds = %29
  %43 = select i1 %40, i64 %20, i64 %38
  %44 = mul nsw i64 %43, %38
  %45 = icmp sgt i64 %44, -1
  %46 = select i1 %45, i64 1073741824, i64 -1073741823
  %47 = add nsw i64 %46, %44
  %48 = sdiv i64 %47, 2147483648
  %49 = trunc i64 %48 to i32
  br label %50

50:                                               ; preds = %42, %29
  %51 = phi i32 [ %49, %42 ], [ 2147483647, %29 ]
  %52 = and i32 %51, %26
  %53 = lshr i32 %51, 31
  %54 = add nsw i32 %53, %27
  %55 = ashr i32 %51, %22
  %56 = icmp sgt i32 %52, %54
  %57 = zext i1 %56 to i32
  %58 = add i32 %55, %13
  %59 = add i32 %58, %57
  %60 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.305", %"struct.gemmlowp::RegisterBuffer.305"* %6, i64 0, i32 0, i64 %30
  store i32 %59, i32* %60, align 4, !alias.scope !816, !noalias !813
  %61 = add nuw nsw i64 %30, 1
  %62 = icmp eq i64 %61, 8
  br i1 %62, label %63, label %29

63:                                               ; preds = %50
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %9) #19, !noalias !813
  %64 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.305", %"struct.gemmlowp::RegisterBuffer.305"* %6, i64 0, i32 0, i64 0
  %65 = load i32, i32* %64, align 4
  %66 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.305", %"struct.gemmlowp::RegisterBuffer.305"* %6, i64 0, i32 0, i64 1
  %67 = load i32, i32* %66, align 4
  %68 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.305", %"struct.gemmlowp::RegisterBuffer.305"* %6, i64 0, i32 0, i64 2
  %69 = load i32, i32* %68, align 4
  %70 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.305", %"struct.gemmlowp::RegisterBuffer.305"* %6, i64 0, i32 0, i64 3
  %71 = load i32, i32* %70, align 4
  %72 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.305", %"struct.gemmlowp::RegisterBuffer.305"* %6, i64 0, i32 0, i64 4
  %73 = bitcast i32* %72 to <4 x i32>*
  %74 = load <4 x i32>, <4 x i32>* %73, align 4
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %8) #19, !noalias !813
  %75 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.350", %"struct.gemmlowp::OutputPipelineEvalImpl.350"* %0, i64 0, i32 1, i32 0, i32 0, i32 0
  %76 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %75, align 8, !noalias !820
  %77 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %76, i64 0, i32 0
  %78 = load i32, i32* %77, align 4, !noalias !820
  %79 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %76, i64 0, i32 1
  %80 = load i32, i32* %79, align 4, !noalias !820
  %81 = icmp slt i32 %65, %78
  %82 = select i1 %81, i32 %78, i32 %65
  %83 = icmp slt i32 %80, %82
  %84 = select i1 %83, i32 %80, i32 %82
  %85 = icmp slt i32 %67, %78
  %86 = select i1 %85, i32 %78, i32 %67
  %87 = icmp slt i32 %80, %86
  %88 = select i1 %87, i32 %80, i32 %86
  %89 = icmp slt i32 %69, %78
  %90 = select i1 %89, i32 %78, i32 %69
  %91 = icmp slt i32 %80, %90
  %92 = select i1 %91, i32 %80, i32 %90
  %93 = icmp slt i32 %71, %78
  %94 = select i1 %93, i32 %78, i32 %71
  %95 = icmp slt i32 %80, %94
  %96 = select i1 %95, i32 %80, i32 %94
  %97 = insertelement <4 x i32> undef, i32 %78, i32 0
  %98 = shufflevector <4 x i32> %97, <4 x i32> undef, <4 x i32> zeroinitializer
  %99 = icmp slt <4 x i32> %74, %98
  %100 = select <4 x i1> %99, <4 x i32> %98, <4 x i32> %74
  %101 = insertelement <4 x i32> undef, i32 %80, i32 0
  %102 = shufflevector <4 x i32> %101, <4 x i32> undef, <4 x i32> zeroinitializer
  %103 = icmp slt <4 x i32> %102, %100
  %104 = select <4 x i1> %103, <4 x i32> %102, <4 x i32> %100
  %105 = icmp sgt i32 %84, 0
  %106 = select i1 %105, i32 %84, i32 0
  %107 = icmp slt i32 %106, 255
  %108 = select i1 %107, i32 %106, i32 255
  %109 = icmp sgt i32 %88, 0
  %110 = select i1 %109, i32 %88, i32 0
  %111 = icmp slt i32 %110, 255
  %112 = select i1 %111, i32 %110, i32 255
  %113 = icmp sgt i32 %92, 0
  %114 = select i1 %113, i32 %92, i32 0
  %115 = icmp slt i32 %114, 255
  %116 = select i1 %115, i32 %114, i32 255
  %117 = icmp sgt i32 %96, 0
  %118 = select i1 %117, i32 %96, i32 0
  %119 = icmp slt i32 %118, 255
  %120 = select i1 %119, i32 %118, i32 255
  %121 = icmp sgt <4 x i32> %104, zeroinitializer
  %122 = select <4 x i1> %121, <4 x i32> %104, <4 x i32> zeroinitializer
  %123 = icmp slt <4 x i32> %122, <i32 255, i32 255, i32 255, i32 255>
  %124 = select <4 x i1> %123, <4 x i32> %122, <4 x i32> <i32 255, i32 255, i32 255, i32 255>
  %125 = zext <4 x i32> %124 to <4 x i64>
  %126 = shl nuw <4 x i64> %125, <i64 32, i64 40, i64 48, i64 56>
  %127 = shl nuw i32 %120, 24
  %128 = shl nuw nsw i32 %116, 16
  %129 = shl nuw nsw i32 %112, 8
  %130 = or i32 %129, %108
  %131 = or i32 %130, %128
  %132 = or i32 %131, %127
  %133 = zext i32 %132 to i64
  %134 = shufflevector <4 x i64> %126, <4 x i64> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %135 = or <4 x i64> %126, %134
  %136 = shufflevector <4 x i64> %135, <4 x i64> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %137 = or <4 x i64> %135, %136
  %138 = extractelement <4 x i64> %137, i32 0
  %139 = or i64 %138, %133
  ret i64 %139
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_13RegisterBlockIiLi4ELi1EEEE7ExecuteINS_9MatrixMapIhLNS_8MapOrderE0EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.338"*, i64, i64, %"class.gemmlowp::MatrixMap.182"*, i32, i32, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %9 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.338", %"struct.gemmlowp::OutputPipelineExecutor.338"* %0, i64 0, i32 0, i32 0, i32 0
  %10 = load %"struct.gemmlowp::OutputStageBiasAddition"*, %"struct.gemmlowp::OutputStageBiasAddition"** %9, align 8
  %11 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition", %"struct.gemmlowp::OutputStageBiasAddition"* %10, i64 0, i32 0, i32 0
  %12 = load i32*, i32** %11, align 8
  %13 = sext i32 %4 to i64
  %14 = getelementptr i32, i32* %12, i64 %13
  %15 = bitcast i32* %14 to i64*
  %16 = load i64, i64* %15, align 4
  %17 = getelementptr inbounds i32, i32* %14, i64 2
  %18 = bitcast i32* %17 to i64*
  %19 = load i64, i64* %18, align 4
  %20 = and i64 %16, -4294967296
  %21 = add i64 %16, %1
  %22 = add i64 %19, %2
  %23 = and i64 %22, 4294967295
  %24 = and i64 %19, -4294967296
  %25 = add i64 %24, %2
  %26 = and i64 %25, -4294967296
  %27 = or i64 %26, %23
  %28 = add i64 %20, %1
  %29 = and i64 %28, -4294967296
  %30 = and i64 %21, 4294967295
  %31 = or i64 %29, %30
  %32 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.338", %"struct.gemmlowp::OutputPipelineExecutor.338"* %0, i64 0, i32 0, i32 1, i32 0, i32 0
  %33 = tail call { i64, i64 } @_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi4EEEE4EvalES3_(%"struct.gemmlowp::OutputStageEvalBufferImpl.231"* %32, i64 %31, i64 %27) #19
  %34 = extractvalue { i64, i64 } %33, 0
  %35 = extractvalue { i64, i64 } %33, 1
  %36 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.338", %"struct.gemmlowp::OutputPipelineExecutor.338"* %0, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %37 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %36, align 8
  %38 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %37, i64 0, i32 0
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %37, i64 0, i32 1
  %41 = load i32, i32* %40, align 4
  %42 = trunc i64 %34 to i32
  %43 = icmp sgt i32 %39, %42
  %44 = select i1 %43, i32 %39, i32 %42
  %45 = icmp slt i32 %41, %44
  %46 = select i1 %45, i32 %41, i32 %44
  %47 = lshr i64 %34, 32
  %48 = trunc i64 %47 to i32
  %49 = icmp sgt i32 %39, %48
  %50 = select i1 %49, i32 %39, i32 %48
  %51 = icmp slt i32 %41, %50
  %52 = select i1 %51, i32 %41, i32 %50
  %53 = trunc i64 %35 to i32
  %54 = icmp sgt i32 %39, %53
  %55 = select i1 %54, i32 %39, i32 %53
  %56 = icmp slt i32 %41, %55
  %57 = select i1 %56, i32 %41, i32 %55
  %58 = lshr i64 %35, 32
  %59 = trunc i64 %58 to i32
  %60 = icmp sgt i32 %39, %59
  %61 = select i1 %60, i32 %39, i32 %59
  %62 = icmp slt i32 %41, %61
  %63 = select i1 %62, i32 %41, i32 %61
  %64 = icmp sgt i32 %46, 0
  %65 = select i1 %64, i32 %46, i32 0
  %66 = icmp slt i32 %65, 255
  %67 = select i1 %66, i32 %65, i32 255
  %68 = icmp sgt i32 %52, 0
  %69 = select i1 %68, i32 %52, i32 0
  %70 = icmp slt i32 %69, 255
  %71 = select i1 %70, i32 %69, i32 255
  %72 = icmp sgt i32 %57, 0
  %73 = select i1 %72, i32 %57, i32 0
  %74 = icmp slt i32 %73, 255
  %75 = select i1 %74, i32 %73, i32 255
  %76 = icmp sgt i32 %63, 0
  %77 = select i1 %76, i32 %63, i32 0
  %78 = icmp slt i32 %77, 255
  %79 = select i1 %78, i32 %77, i32 255
  %80 = trunc i32 %67 to i8
  %81 = trunc i32 %71 to i8
  %82 = trunc i32 %75 to i8
  %83 = trunc i32 %79 to i8
  %84 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %3, i64 0, i32 0
  %85 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %3, i64 0, i32 3
  %86 = sext i32 %6 to i64
  %87 = load i8*, i8** %84, align 8
  %88 = getelementptr inbounds i8, i8* %87, i64 %86
  %89 = load i32, i32* %85, align 8
  %90 = mul nsw i32 %89, %7
  %91 = sext i32 %90 to i64
  %92 = getelementptr inbounds i8, i8* %88, i64 %91
  store i8 %80, i8* %92, align 1
  %93 = add nsw i64 %86, 1
  %94 = load i8*, i8** %84, align 8
  %95 = getelementptr inbounds i8, i8* %94, i64 %93
  %96 = load i32, i32* %85, align 8
  %97 = mul nsw i32 %96, %7
  %98 = sext i32 %97 to i64
  %99 = getelementptr inbounds i8, i8* %95, i64 %98
  store i8 %81, i8* %99, align 1
  %100 = add nsw i64 %86, 2
  %101 = load i8*, i8** %84, align 8
  %102 = getelementptr inbounds i8, i8* %101, i64 %100
  %103 = load i32, i32* %85, align 8
  %104 = mul nsw i32 %103, %7
  %105 = sext i32 %104 to i64
  %106 = getelementptr inbounds i8, i8* %102, i64 %105
  store i8 %82, i8* %106, align 1
  %107 = add nsw i64 %86, 3
  %108 = load i8*, i8** %84, align 8
  %109 = getelementptr inbounds i8, i8* %108, i64 %107
  %110 = load i32, i32* %85, align 8
  %111 = mul nsw i32 %110, %7
  %112 = sext i32 %111 to i64
  %113 = getelementptr inbounds i8, i8* %109, i64 %112
  store i8 %83, i8* %113, align 1
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEED2Ev(%"struct.gemmlowp::GemmWithPackedRhsTask.328"*) unnamed_addr #4 comdat align 2 {
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEED0Ev(%"struct.gemmlowp::GemmWithPackedRhsTask.328"*) unnamed_addr #4 comdat align 2 {
  %2 = bitcast %"struct.gemmlowp::GemmWithPackedRhsTask.328"* %0 to i8*
  tail call void @_ZdlPv(i8* %2) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEE3RunEv(%"struct.gemmlowp::GemmWithPackedRhsTask.328"*) unnamed_addr #1 comdat align 2 {
  %2 = alloca %"class.gemmlowp::SideMap", align 8
  %3 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %4 = alloca %"class.gemmlowp::ComputeImpl", align 8
  %5 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %6 = alloca %"class.gemmlowp::PackedResult", align 8
  %7 = alloca %"struct.gemmlowp::MatrixBlockBounds", align 4
  %8 = alloca %"class.gemmlowp::VectorDup", align 4
  %9 = alloca %"class.gemmlowp::VectorDup.194", align 4
  %10 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.328", %"struct.gemmlowp::GemmWithPackedRhsTask.328"* %0, i64 0, i32 6, i32 2
  %11 = load i32, i32* %10, align 8
  %12 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.328", %"struct.gemmlowp::GemmWithPackedRhsTask.328"* %0, i64 0, i32 6, i32 3
  %13 = load i32, i32* %12, align 4
  %14 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.328", %"struct.gemmlowp::GemmWithPackedRhsTask.328"* %0, i64 0, i32 3, i32 2
  %15 = load i32, i32* %14, align 4
  %16 = bitcast %"class.gemmlowp::PackedSideBlock"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %16) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %16, i8 -86, i64 80, i1 false)
  %17 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.328", %"struct.gemmlowp::GemmWithPackedRhsTask.328"* %0, i64 0, i32 0, i32 1
  %18 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %19 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.328", %"struct.gemmlowp::GemmWithPackedRhsTask.328"* %0, i64 0, i32 9
  %20 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %21 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %18, %"class.gemmlowp::Allocator"** %21, align 8
  %22 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 4
  store i32 0, i32* %22, align 8
  %23 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 0
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 0
  store i32 %24, i32* %25, align 8
  %26 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 3
  %27 = load i32, i32* %26, align 4
  %28 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 2
  store i32 %27, i32* %28, align 8
  %29 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 2
  %30 = load i32, i32* %29, align 4
  %31 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 1
  store i32 %30, i32* %31, align 4
  %32 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 5
  %33 = load i32, i32* %32, align 4
  %34 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 3
  store i32 %33, i32* %34, align 4
  %35 = mul nsw i32 %33, %27
  %36 = sext i32 %35 to i64
  %37 = add nsw i64 %36, 63
  %38 = and i64 %37, -64
  %39 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 4
  %40 = load i64, i64* %39, align 8, !noalias !825
  %41 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 3
  %42 = load i64, i64* %41, align 8, !noalias !825
  %43 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 5, i64 %42
  store i64 %40, i64* %43, align 8, !noalias !825
  %44 = trunc i64 %42 to i8
  %45 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 6
  %46 = load i64, i64* %45, align 8, !noalias !825
  %47 = bitcast i64* %41 to <2 x i64>*
  %48 = load <2 x i64>, <2 x i64>* %47, align 8, !noalias !825
  %49 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %38, i32 1
  %50 = add <2 x i64> %48, %49
  %51 = bitcast i64* %41 to <2 x i64>*
  store <2 x i64> %50, <2 x i64>* %51, align 8, !noalias !825
  %52 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 0
  store i8 %44, i8* %52, align 8
  %53 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %53, i8 -86, i64 7, i1 false) #19
  %54 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 2
  store i64 %46, i64* %54, align 8
  %55 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 3
  store i8 0, i8* %55, align 8
  %56 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %21, align 8
  %57 = load i32, i32* %28, align 8
  %58 = sext i32 %57 to i64
  %59 = shl nsw i64 %58, 2
  %60 = add nsw i64 %59, 63
  %61 = and i64 %60, -64
  %62 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 4
  %63 = load i64, i64* %62, align 8, !noalias !828
  %64 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 3
  %65 = load i64, i64* %64, align 8, !noalias !828
  %66 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 5, i64 %65
  store i64 %63, i64* %66, align 8, !noalias !828
  %67 = trunc i64 %65 to i8
  %68 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 6
  %69 = load i64, i64* %68, align 8, !noalias !828
  %70 = bitcast i64* %64 to <2 x i64>*
  %71 = load <2 x i64>, <2 x i64>* %70, align 8, !noalias !828
  %72 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %61, i32 1
  %73 = add <2 x i64> %71, %72
  %74 = bitcast i64* %64 to <2 x i64>*
  store <2 x i64> %73, <2 x i64>* %74, align 8, !noalias !828
  %75 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 0
  store i8 %67, i8* %75, align 8
  %76 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %76, i8 -86, i64 7, i1 false) #19
  %77 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 2
  store i64 %69, i64* %77, align 8
  %78 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 3
  store i8 5, i8* %78, align 8
  %79 = bitcast %"class.gemmlowp::PackedResult"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %79) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %79, i8 -86, i64 32, i1 false)
  %80 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %81 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %82 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 0
  store %"class.gemmlowp::Allocator"* %80, %"class.gemmlowp::Allocator"** %82, align 8
  %83 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 2
  store %"struct.gemmlowp::BlockParams"* %81, %"struct.gemmlowp::BlockParams"** %83, align 8
  %84 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %81, i64 0, i32 3
  %85 = load i32, i32* %84, align 4
  %86 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %81, i64 0, i32 4
  %87 = load i32, i32* %86, align 4
  %88 = mul nsw i32 %87, %85
  %89 = sext i32 %88 to i64
  %90 = shl nsw i64 %89, 2
  %91 = add nsw i64 %90, 63
  %92 = and i64 %91, -64
  %93 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 4
  %94 = load i64, i64* %93, align 8, !noalias !831
  %95 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 3
  %96 = load i64, i64* %95, align 8, !noalias !831
  %97 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 5, i64 %96
  store i64 %94, i64* %97, align 8, !noalias !831
  %98 = trunc i64 %96 to i8
  %99 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 6
  %100 = load i64, i64* %99, align 8, !noalias !831
  %101 = bitcast i64* %95 to <2 x i64>*
  %102 = load <2 x i64>, <2 x i64>* %101, align 8, !noalias !831
  %103 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %92, i32 1
  %104 = add <2 x i64> %102, %103
  %105 = bitcast i64* %95 to <2 x i64>*
  store <2 x i64> %104, <2 x i64>* %105, align 8, !noalias !831
  %106 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 0
  store i8 %98, i8* %106, align 8
  %107 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %107, i8 -86, i64 7, i1 false) #19
  %108 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 2
  store i64 %100, i64* %108, align 8
  %109 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 3
  store i8 5, i8* %109, align 8
  %110 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  tail call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %110)
  %111 = icmp sgt i32 %13, 0
  br i1 %111, label %112, label %156

112:                                              ; preds = %1
  %113 = icmp sgt i32 %11, 0
  %114 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.328", %"struct.gemmlowp::GemmWithPackedRhsTask.328"* %0, i64 0, i32 3, i32 0
  %115 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.328", %"struct.gemmlowp::GemmWithPackedRhsTask.328"* %0, i64 0, i32 3, i32 3
  %116 = bitcast %"class.gemmlowp::SideMap"* %2 to i8*
  %117 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 1
  %118 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 2
  %119 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 3
  %120 = bitcast %"class.gemmlowp::SideMap"* %2 to i64*
  %121 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %3 to i8*
  %122 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %3, i64 0, i32 0
  %123 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %3, i64 0, i32 1
  %124 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.328", %"struct.gemmlowp::GemmWithPackedRhsTask.328"* %0, i64 0, i32 2
  %125 = bitcast %"struct.gemmlowp::KernelBase"** %124 to i64*
  %126 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.328", %"struct.gemmlowp::GemmWithPackedRhsTask.328"* %0, i64 0, i32 4
  %127 = bitcast %"class.gemmlowp::ComputeImpl"* %4 to i8*
  %128 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 1
  %129 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 2
  %130 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 3
  %131 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 4
  %132 = bitcast %"class.gemmlowp::ComputeImpl"* %4 to i64*
  %133 = add i32 %15, 15
  %134 = and i32 %133, -16
  %135 = icmp sgt i32 %134, 0
  %136 = bitcast %"struct.gemmlowp::MatrixBlockBounds"* %7 to i8*
  %137 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 0
  %138 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 1
  %139 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 2
  %140 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 3
  %141 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.328", %"struct.gemmlowp::GemmWithPackedRhsTask.328"* %0, i64 0, i32 6, i32 0
  %142 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.328", %"struct.gemmlowp::GemmWithPackedRhsTask.328"* %0, i64 0, i32 6, i32 1
  %143 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.328", %"struct.gemmlowp::GemmWithPackedRhsTask.328"* %0, i64 0, i32 5
  %144 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.328", %"struct.gemmlowp::GemmWithPackedRhsTask.328"* %0, i64 0, i32 4, i32 1
  %145 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.328", %"struct.gemmlowp::GemmWithPackedRhsTask.328"* %0, i64 0, i32 4, i32 3, i32 0
  %146 = bitcast %"class.gemmlowp::VectorDup"* %8 to i8*
  %147 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.328", %"struct.gemmlowp::GemmWithPackedRhsTask.328"* %0, i64 0, i32 7
  %148 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %8, i64 0, i32 0
  %149 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %8, i64 0, i32 1
  %150 = bitcast %"class.gemmlowp::VectorDup.194"* %9 to i8*
  %151 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.328", %"struct.gemmlowp::GemmWithPackedRhsTask.328"* %0, i64 0, i32 8
  %152 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %9, i64 0, i32 0
  %153 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %9, i64 0, i32 1
  %154 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.328", %"struct.gemmlowp::GemmWithPackedRhsTask.328"* %0, i64 0, i32 10
  %155 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  br label %164

156:                                              ; preds = %178, %1
  %157 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %158 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 0
  store i8 0, i8* %158, align 8
  %159 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 6
  %160 = load i64, i64* %159, align 8
  %161 = add i64 %160, 1
  store i64 %161, i64* %159, align 8
  %162 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 3
  %163 = bitcast i64* %162 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %163, i8 0, i64 16, i1 false) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %79) #19
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %16) #19
  ret void

164:                                              ; preds = %112, %178
  %165 = phi %"struct.gemmlowp::BlockParams"* [ %155, %112 ], [ %180, %178 ]
  %166 = phi i32 [ 0, %112 ], [ %181, %178 ]
  %167 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %165, i64 0, i32 4
  %168 = sub nsw i32 %13, %166
  %169 = load i32, i32* %167, align 4
  %170 = icmp slt i32 %168, %169
  %171 = select i1 %170, i32 %168, i32 %169
  br i1 %113, label %172, label %178

172:                                              ; preds = %164
  %173 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %165, i64 0, i32 3
  %174 = load i32, i32* %173, align 4
  br label %183

175:                                              ; preds = %255
  %176 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %287, i64 0, i32 4
  %177 = load i32, i32* %176, align 4
  br label %178

178:                                              ; preds = %175, %164
  %179 = phi i32 [ %169, %164 ], [ %177, %175 ]
  %180 = phi %"struct.gemmlowp::BlockParams"* [ %165, %164 ], [ %287, %175 ]
  %181 = add nsw i32 %179, %166
  %182 = icmp sgt i32 %13, %181
  br i1 %182, label %164, label %156

183:                                              ; preds = %172, %255
  %184 = phi i32 [ %289, %255 ], [ %174, %172 ]
  %185 = phi i32 [ %290, %255 ], [ 0, %172 ]
  %186 = sub nsw i32 %11, %185
  %187 = icmp slt i32 %186, %184
  %188 = select i1 %187, i32 %186, i32 %184
  %189 = load i8*, i8** %114, align 8, !noalias !834
  %190 = load i32, i32* %115, align 8, !noalias !834
  %191 = mul nsw i32 %190, %185
  %192 = sext i32 %191 to i64
  %193 = getelementptr inbounds i8, i8* %189, i64 %192
  %194 = ptrtoint i8* %193 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %116) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %116, i8 -86, i64 24, i1 false) #19
  store i64 %194, i64* %120, align 8
  store i32 %188, i32* %117, align 8
  store i32 %15, i32* %118, align 4
  store i32 %190, i32* %119, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %121) #19
  store %"class.gemmlowp::PackedSideBlock"* %5, %"class.gemmlowp::PackedSideBlock"** %122, align 8
  store %"class.gemmlowp::SideMap"* %2, %"class.gemmlowp::SideMap"** %123, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %3) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %121) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %116) #19
  %195 = load i64, i64* %125, align 8
  %196 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %127) #19
  store i64 %195, i64* %132, align 8
  store %"struct.gemmlowp::BlockParams"* %196, %"struct.gemmlowp::BlockParams"** %128, align 8
  store %"class.gemmlowp::PackedResult"* %6, %"class.gemmlowp::PackedResult"** %129, align 8
  store %"class.gemmlowp::PackedSideBlock"* %5, %"class.gemmlowp::PackedSideBlock"** %130, align 8
  store %"class.gemmlowp::PackedSideBlock"* %126, %"class.gemmlowp::PackedSideBlock"** %131, align 8
  br i1 %135, label %197, label %255

197:                                              ; preds = %183, %215
  %198 = phi %"struct.gemmlowp::BlockParams"* [ %217, %215 ], [ %196, %183 ]
  %199 = phi %"struct.gemmlowp::BlockParams"* [ %218, %215 ], [ %196, %183 ]
  %200 = phi i32 [ %219, %215 ], [ 0, %183 ]
  %201 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 2
  %202 = sub nsw i32 %134, %200
  %203 = load i32, i32* %201, align 4
  %204 = icmp slt i32 %202, %203
  %205 = select i1 %204, i32 %202, i32 %203
  %206 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 3
  %207 = load i32, i32* %206, align 4
  %208 = icmp sgt i32 %207, 0
  br i1 %208, label %209, label %215

209:                                              ; preds = %197
  %210 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 0
  %211 = load i32, i32* %210, align 4
  br label %221

212:                                              ; preds = %247
  %213 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 2
  %214 = load i32, i32* %213, align 4
  br label %215

215:                                              ; preds = %212, %197
  %216 = phi i32 [ %203, %197 ], [ %214, %212 ]
  %217 = phi %"struct.gemmlowp::BlockParams"* [ %198, %197 ], [ %248, %212 ]
  %218 = phi %"struct.gemmlowp::BlockParams"* [ %199, %197 ], [ %248, %212 ]
  %219 = add nsw i32 %216, %200
  %220 = icmp sgt i32 %134, %219
  br i1 %220, label %197, label %255

221:                                              ; preds = %247, %209
  %222 = phi %"struct.gemmlowp::BlockParams"* [ %248, %247 ], [ %198, %209 ]
  %223 = phi i32 [ %250, %247 ], [ %211, %209 ]
  %224 = phi i32 [ %253, %247 ], [ %207, %209 ]
  %225 = phi %"struct.gemmlowp::BlockParams"* [ %248, %247 ], [ %199, %209 ]
  %226 = phi i32 [ %251, %247 ], [ 0, %209 ]
  %227 = sub nsw i32 %224, %226
  %228 = icmp slt i32 %227, %223
  %229 = select i1 %228, i32 %227, i32 %223
  %230 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %225, i64 0, i32 4
  %231 = load i32, i32* %230, align 4
  %232 = icmp sgt i32 %231, 0
  br i1 %232, label %233, label %247

233:                                              ; preds = %221
  %234 = icmp sgt i32 %229, 0
  br label %235

235:                                              ; preds = %237, %233
  %236 = phi i32 [ 0, %233 ], [ %238, %237 ]
  br i1 %234, label %240, label %237

237:                                              ; preds = %240, %235
  %238 = add nuw nsw i32 %236, 4
  %239 = icmp slt i32 %238, %231
  br i1 %239, label %235, label %245

240:                                              ; preds = %235, %240
  %241 = phi i32 [ %243, %240 ], [ 0, %235 ]
  %242 = add nsw i32 %241, %226
  call void @_ZN8gemmlowp11ComputeImplINS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEES7_NS_12PackedResultEE10ComputeRunEiiii(%"class.gemmlowp::ComputeImpl"* nonnull %4, i32 %242, i32 %236, i32 %200, i32 %205) #19
  %243 = add nuw nsw i32 %241, 4
  %244 = icmp slt i32 %243, %229
  br i1 %244, label %240, label %237

245:                                              ; preds = %237
  %246 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %128, align 8
  br label %247

247:                                              ; preds = %245, %221
  %248 = phi %"struct.gemmlowp::BlockParams"* [ %246, %245 ], [ %222, %221 ]
  %249 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 0
  %250 = load i32, i32* %249, align 4
  %251 = add nsw i32 %250, %226
  %252 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 3
  %253 = load i32, i32* %252, align 4
  %254 = icmp sgt i32 %253, %251
  br i1 %254, label %221, label %212

255:                                              ; preds = %215, %183
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %127) #19
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %136) #19
  %256 = load i32, i32* %141, align 8
  %257 = add nsw i32 %256, %185
  %258 = load i32, i32* %142, align 4
  %259 = add nsw i32 %258, %166
  store i32 %257, i32* %137, align 4
  store i32 %259, i32* %138, align 4
  store i32 %188, i32* %139, align 4
  store i32 %171, i32* %140, align 4
  %260 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %21, align 8
  %261 = load i8, i8* %75, align 8
  %262 = zext i8 %261 to i64
  %263 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %260, i64 0, i32 5, i64 %262
  %264 = load i64, i64* %263, align 8
  %265 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %260, i64 0, i32 2
  %266 = bitcast i8** %265 to i64*
  %267 = load i64, i64* %266, align 8
  %268 = add i64 %267, %264
  %269 = inttoptr i64 %268 to i32*
  %270 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %144, align 8
  %271 = load i8, i8* %145, align 8
  %272 = zext i8 %271 to i64
  %273 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %270, i64 0, i32 5, i64 %272
  %274 = load i64, i64* %273, align 8
  %275 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %270, i64 0, i32 2
  %276 = bitcast i8** %275 to i64*
  %277 = load i64, i64* %276, align 8
  %278 = add i64 %277, %274
  %279 = inttoptr i64 %278 to i32*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %146) #19
  %280 = load %"class.gemmlowp::VectorDup"*, %"class.gemmlowp::VectorDup"** %147, align 8
  %281 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %280, i64 0, i32 0
  %282 = load i32, i32* %281, align 4, !noalias !837
  store i32 %282, i32* %148, align 4, !alias.scope !837
  store i32 %188, i32* %149, align 4, !alias.scope !837
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %150) #19
  %283 = load %"class.gemmlowp::VectorDup.194"*, %"class.gemmlowp::VectorDup.194"** %151, align 8
  %284 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %283, i64 0, i32 0
  %285 = load i32, i32* %284, align 4, !noalias !840
  store i32 %285, i32* %152, align 4, !alias.scope !840
  store i32 %171, i32* %153, align 4, !alias.scope !840
  %286 = load %"class.std::__1::tuple"*, %"class.std::__1::tuple"** %154, align 8
  call void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIhLNS_8MapOrderE0EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE0EEENSC_ISD_LSE_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISD_LSE_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SZ_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.182"* %143, %"struct.gemmlowp::MatrixBlockBounds"* nonnull dereferenceable(16) %7, %"class.gemmlowp::PackedResult"* nonnull dereferenceable(40) %6, i32 %15, i32* %269, i32* %279, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %8, %"class.gemmlowp::VectorDup.194"* nonnull dereferenceable(8) %9, %"class.std::__1::tuple"* dereferenceable(40) %286)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %150) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %146) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %136) #19
  %287 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %288 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %287, i64 0, i32 3
  %289 = load i32, i32* %288, align 4
  %290 = add nsw i32 %289, %185
  %291 = icmp sgt i32 %11, %290
  br i1 %291, label %183, label %175
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i8* @_ZNK8gemmlowp15ReferenceKernelINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEE4NameEv(%"struct.gemmlowp::ReferenceKernel"*) unnamed_addr #1 comdat align 2 {
  %2 = tail call i32 (i8*, i64, i8*, ...) @snprintf(i8* getelementptr inbounds ([256 x i8], [256 x i8]* @_ZZNK8gemmlowp15ReferenceKernelINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEE4NameEvE3buf, i64 0, i64 0), i64 256, i8* getelementptr inbounds ([58 x i8], [58 x i8]* @.str.67, i64 0, i64 0), i32 1, i32 4, i32 16, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.69, i64 0, i64 0), i32 1, i32 16, i32 4, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.69, i64 0, i64 0)) #19
  ret i8* getelementptr inbounds ([256 x i8], [256 x i8]* @_ZZNK8gemmlowp15ReferenceKernelINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEE4NameEvE3buf, i64 0, i64 0)
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp15ReferenceKernelINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEE3RunEPimmPKhSB_mm(%"struct.gemmlowp::ReferenceKernel"*, i32*, i64, i64, i8*, i8*, i64, i64) unnamed_addr #1 comdat align 2 {
  %9 = alloca [16 x i32], align 16
  %10 = bitcast [16 x i32]* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %10) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %10, i8 0, i64 64, i1 false)
  %11 = lshr i64 %7, 4
  %12 = trunc i64 %11 to i32
  %13 = icmp sgt i32 %12, 0
  br i1 %13, label %14, label %48

14:                                               ; preds = %8
  %15 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 3
  %16 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 0
  %17 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 4
  %18 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 8
  %19 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 12
  %20 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 1
  %21 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 5
  %22 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 9
  %23 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 13
  %24 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 2
  %25 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 6
  %26 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 10
  %27 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 14
  %28 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 7
  %29 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 11
  %30 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 15
  %31 = load i32, i32* %16, align 16
  %32 = load i32, i32* %17, align 16
  %33 = load i32, i32* %18, align 16
  %34 = load i32, i32* %19, align 16
  %35 = load i32, i32* %20, align 4
  %36 = load i32, i32* %21, align 4
  %37 = load i32, i32* %22, align 4
  %38 = load i32, i32* %23, align 4
  %39 = load i32, i32* %24, align 8
  %40 = load i32, i32* %25, align 8
  %41 = load i32, i32* %26, align 8
  %42 = load i32, i32* %27, align 8
  %43 = load i32, i32* %15, align 4
  %44 = load i32, i32* %28, align 4
  %45 = load i32, i32* %29, align 4
  %46 = load i32, i32* %30, align 4
  br label %201

47:                                               ; preds = %326
  store i32 %331, i32* %16, align 16
  store i32 %336, i32* %17, align 16
  store i32 %341, i32* %18, align 16
  store i32 %346, i32* %19, align 16
  store i32 %351, i32* %20, align 4
  store i32 %356, i32* %21, align 4
  store i32 %361, i32* %22, align 4
  store i32 %366, i32* %23, align 4
  store i32 %371, i32* %24, align 8
  store i32 %376, i32* %25, align 8
  store i32 %381, i32* %26, align 8
  store i32 %386, i32* %27, align 8
  store i32 %391, i32* %15, align 4
  store i32 %396, i32* %28, align 4
  store i32 %401, i32* %29, align 4
  store i32 %406, i32* %30, align 4
  br label %48

48:                                               ; preds = %47, %8
  %49 = phi i32 [ 0, %8 ], [ %406, %47 ]
  %50 = icmp eq i64 %6, 0
  %51 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 0
  %52 = load i32, i32* %51, align 16
  br i1 %50, label %144, label %53

53:                                               ; preds = %48
  %54 = load i32, i32* %1, align 4
  %55 = add nsw i32 %54, %52
  store i32 %55, i32* %1, align 4
  %56 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 4
  %57 = load i32, i32* %56, align 16
  %58 = getelementptr inbounds i32, i32* %1, i64 %3
  %59 = load i32, i32* %58, align 4
  %60 = add nsw i32 %59, %57
  store i32 %60, i32* %58, align 4
  %61 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 8
  %62 = load i32, i32* %61, align 16
  %63 = shl i64 %3, 1
  %64 = getelementptr inbounds i32, i32* %1, i64 %63
  %65 = load i32, i32* %64, align 4
  %66 = add nsw i32 %65, %62
  store i32 %66, i32* %64, align 4
  %67 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 12
  %68 = load i32, i32* %67, align 16
  %69 = mul i64 %3, 3
  %70 = getelementptr inbounds i32, i32* %1, i64 %69
  %71 = load i32, i32* %70, align 4
  %72 = add nsw i32 %71, %68
  store i32 %72, i32* %70, align 4
  %73 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 1
  %74 = load i32, i32* %73, align 4
  %75 = getelementptr inbounds i32, i32* %1, i64 %2
  %76 = load i32, i32* %75, align 4
  %77 = add nsw i32 %76, %74
  store i32 %77, i32* %75, align 4
  %78 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 5
  %79 = load i32, i32* %78, align 4
  %80 = add i64 %3, %2
  %81 = getelementptr inbounds i32, i32* %1, i64 %80
  %82 = load i32, i32* %81, align 4
  %83 = add nsw i32 %82, %79
  store i32 %83, i32* %81, align 4
  %84 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 9
  %85 = load i32, i32* %84, align 4
  %86 = add i64 %63, %2
  %87 = getelementptr inbounds i32, i32* %1, i64 %86
  %88 = load i32, i32* %87, align 4
  %89 = add nsw i32 %88, %85
  store i32 %89, i32* %87, align 4
  %90 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 13
  %91 = load i32, i32* %90, align 4
  %92 = add i64 %69, %2
  %93 = getelementptr inbounds i32, i32* %1, i64 %92
  %94 = load i32, i32* %93, align 4
  %95 = add nsw i32 %94, %91
  store i32 %95, i32* %93, align 4
  %96 = shl i64 %2, 1
  %97 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 2
  %98 = load i32, i32* %97, align 8
  %99 = getelementptr inbounds i32, i32* %1, i64 %96
  %100 = load i32, i32* %99, align 4
  %101 = add nsw i32 %100, %98
  store i32 %101, i32* %99, align 4
  %102 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 6
  %103 = load i32, i32* %102, align 8
  %104 = add i64 %96, %3
  %105 = getelementptr inbounds i32, i32* %1, i64 %104
  %106 = load i32, i32* %105, align 4
  %107 = add nsw i32 %106, %103
  store i32 %107, i32* %105, align 4
  %108 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 10
  %109 = load i32, i32* %108, align 8
  %110 = add i64 %63, %96
  %111 = getelementptr inbounds i32, i32* %1, i64 %110
  %112 = load i32, i32* %111, align 4
  %113 = add nsw i32 %112, %109
  store i32 %113, i32* %111, align 4
  %114 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 14
  %115 = load i32, i32* %114, align 8
  %116 = add i64 %69, %96
  %117 = getelementptr inbounds i32, i32* %1, i64 %116
  %118 = load i32, i32* %117, align 4
  %119 = add nsw i32 %118, %115
  store i32 %119, i32* %117, align 4
  %120 = mul i64 %2, 3
  %121 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 3
  %122 = load i32, i32* %121, align 4
  %123 = getelementptr inbounds i32, i32* %1, i64 %120
  %124 = load i32, i32* %123, align 4
  %125 = add nsw i32 %124, %122
  store i32 %125, i32* %123, align 4
  %126 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 7
  %127 = load i32, i32* %126, align 4
  %128 = add i64 %120, %3
  %129 = getelementptr inbounds i32, i32* %1, i64 %128
  %130 = load i32, i32* %129, align 4
  %131 = add nsw i32 %130, %127
  store i32 %131, i32* %129, align 4
  %132 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 11
  %133 = load i32, i32* %132, align 4
  %134 = add i64 %63, %120
  %135 = getelementptr inbounds i32, i32* %1, i64 %134
  %136 = load i32, i32* %135, align 4
  %137 = add nsw i32 %136, %133
  store i32 %137, i32* %135, align 4
  %138 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 15
  %139 = load i32, i32* %138, align 4
  %140 = add i64 %69, %120
  %141 = getelementptr inbounds i32, i32* %1, i64 %140
  %142 = load i32, i32* %141, align 4
  %143 = add nsw i32 %142, %139
  store i32 %143, i32* %141, align 4
  br label %409

144:                                              ; preds = %48
  store i32 %52, i32* %1, align 4
  %145 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 4
  %146 = load i32, i32* %145, align 16
  %147 = getelementptr inbounds i32, i32* %1, i64 %3
  store i32 %146, i32* %147, align 4
  %148 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 8
  %149 = load i32, i32* %148, align 16
  %150 = shl i64 %3, 1
  %151 = getelementptr inbounds i32, i32* %1, i64 %150
  store i32 %149, i32* %151, align 4
  %152 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 12
  %153 = load i32, i32* %152, align 16
  %154 = mul i64 %3, 3
  %155 = getelementptr inbounds i32, i32* %1, i64 %154
  store i32 %153, i32* %155, align 4
  %156 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 1
  %157 = load i32, i32* %156, align 4
  %158 = getelementptr inbounds i32, i32* %1, i64 %2
  store i32 %157, i32* %158, align 4
  %159 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 5
  %160 = load i32, i32* %159, align 4
  %161 = add i64 %3, %2
  %162 = getelementptr inbounds i32, i32* %1, i64 %161
  store i32 %160, i32* %162, align 4
  %163 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 9
  %164 = load i32, i32* %163, align 4
  %165 = add i64 %150, %2
  %166 = getelementptr inbounds i32, i32* %1, i64 %165
  store i32 %164, i32* %166, align 4
  %167 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 13
  %168 = load i32, i32* %167, align 4
  %169 = add i64 %154, %2
  %170 = getelementptr inbounds i32, i32* %1, i64 %169
  store i32 %168, i32* %170, align 4
  %171 = shl i64 %2, 1
  %172 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 2
  %173 = load i32, i32* %172, align 8
  %174 = getelementptr inbounds i32, i32* %1, i64 %171
  store i32 %173, i32* %174, align 4
  %175 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 6
  %176 = load i32, i32* %175, align 8
  %177 = add i64 %171, %3
  %178 = getelementptr inbounds i32, i32* %1, i64 %177
  store i32 %176, i32* %178, align 4
  %179 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 10
  %180 = load i32, i32* %179, align 8
  %181 = add i64 %150, %171
  %182 = getelementptr inbounds i32, i32* %1, i64 %181
  store i32 %180, i32* %182, align 4
  %183 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 14
  %184 = load i32, i32* %183, align 8
  %185 = add i64 %154, %171
  %186 = getelementptr inbounds i32, i32* %1, i64 %185
  store i32 %184, i32* %186, align 4
  %187 = mul i64 %2, 3
  %188 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 3
  %189 = load i32, i32* %188, align 4
  %190 = getelementptr inbounds i32, i32* %1, i64 %187
  store i32 %189, i32* %190, align 4
  %191 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 7
  %192 = load i32, i32* %191, align 4
  %193 = add i64 %187, %3
  %194 = getelementptr inbounds i32, i32* %1, i64 %193
  store i32 %192, i32* %194, align 4
  %195 = getelementptr inbounds [16 x i32], [16 x i32]* %9, i64 0, i64 11
  %196 = load i32, i32* %195, align 4
  %197 = add i64 %150, %187
  %198 = getelementptr inbounds i32, i32* %1, i64 %197
  store i32 %196, i32* %198, align 4
  %199 = add i64 %154, %187
  %200 = getelementptr inbounds i32, i32* %1, i64 %199
  store i32 %49, i32* %200, align 4
  br label %409

201:                                              ; preds = %326, %14
  %202 = phi i32 [ %406, %326 ], [ %46, %14 ]
  %203 = phi i32 [ %401, %326 ], [ %45, %14 ]
  %204 = phi i32 [ %396, %326 ], [ %44, %14 ]
  %205 = phi i32 [ %391, %326 ], [ %43, %14 ]
  %206 = phi i32 [ %386, %326 ], [ %42, %14 ]
  %207 = phi i32 [ %381, %326 ], [ %41, %14 ]
  %208 = phi i32 [ %376, %326 ], [ %40, %14 ]
  %209 = phi i32 [ %371, %326 ], [ %39, %14 ]
  %210 = phi i32 [ %366, %326 ], [ %38, %14 ]
  %211 = phi i32 [ %361, %326 ], [ %37, %14 ]
  %212 = phi i32 [ %356, %326 ], [ %36, %14 ]
  %213 = phi i32 [ %351, %326 ], [ %35, %14 ]
  %214 = phi i32 [ %346, %326 ], [ %34, %14 ]
  %215 = phi i32 [ %341, %326 ], [ %33, %14 ]
  %216 = phi i32 [ %336, %326 ], [ %32, %14 ]
  %217 = phi i32 [ %331, %326 ], [ %31, %14 ]
  %218 = phi i32 [ %407, %326 ], [ 0, %14 ]
  %219 = shl nsw i32 %218, 6
  %220 = zext i32 %219 to i64
  %221 = getelementptr inbounds i8, i8* %4, i64 %220
  %222 = getelementptr inbounds i8, i8* %5, i64 %220
  %223 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %202, i32 0
  %224 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %203, i32 0
  %225 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %204, i32 0
  %226 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %205, i32 0
  %227 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %206, i32 0
  %228 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %207, i32 0
  %229 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %208, i32 0
  %230 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %209, i32 0
  %231 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %210, i32 0
  %232 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %211, i32 0
  %233 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %212, i32 0
  %234 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %213, i32 0
  %235 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %214, i32 0
  %236 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %215, i32 0
  %237 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %216, i32 0
  %238 = insertelement <4 x i32> <i32 undef, i32 0, i32 0, i32 0>, i32 %217, i32 0
  br label %239

239:                                              ; preds = %239, %201
  %240 = phi i64 [ 0, %201 ], [ %324, %239 ]
  %241 = phi <4 x i32> [ %223, %201 ], [ %323, %239 ]
  %242 = phi <4 x i32> [ %224, %201 ], [ %321, %239 ]
  %243 = phi <4 x i32> [ %225, %201 ], [ %319, %239 ]
  %244 = phi <4 x i32> [ %226, %201 ], [ %317, %239 ]
  %245 = phi <4 x i32> [ %227, %201 ], [ %311, %239 ]
  %246 = phi <4 x i32> [ %228, %201 ], [ %309, %239 ]
  %247 = phi <4 x i32> [ %229, %201 ], [ %307, %239 ]
  %248 = phi <4 x i32> [ %230, %201 ], [ %305, %239 ]
  %249 = phi <4 x i32> [ %231, %201 ], [ %299, %239 ]
  %250 = phi <4 x i32> [ %232, %201 ], [ %297, %239 ]
  %251 = phi <4 x i32> [ %233, %201 ], [ %295, %239 ]
  %252 = phi <4 x i32> [ %234, %201 ], [ %293, %239 ]
  %253 = phi <4 x i32> [ %235, %201 ], [ %287, %239 ]
  %254 = phi <4 x i32> [ %236, %201 ], [ %280, %239 ]
  %255 = phi <4 x i32> [ %237, %201 ], [ %273, %239 ]
  %256 = phi <4 x i32> [ %238, %201 ], [ %266, %239 ]
  %257 = getelementptr inbounds i8, i8* %222, i64 %240
  %258 = getelementptr inbounds i8, i8* %221, i64 %240
  %259 = bitcast i8* %258 to <4 x i8>*
  %260 = load <4 x i8>, <4 x i8>* %259, align 1
  %261 = zext <4 x i8> %260 to <4 x i32>
  %262 = bitcast i8* %257 to <4 x i8>*
  %263 = load <4 x i8>, <4 x i8>* %262, align 1
  %264 = zext <4 x i8> %263 to <4 x i32>
  %265 = mul nuw nsw <4 x i32> %264, %261
  %266 = add nsw <4 x i32> %265, %256
  %267 = add nuw nsw i64 %240, 16
  %268 = getelementptr inbounds i8, i8* %222, i64 %267
  %269 = bitcast i8* %268 to <4 x i8>*
  %270 = load <4 x i8>, <4 x i8>* %269, align 1
  %271 = zext <4 x i8> %270 to <4 x i32>
  %272 = mul nuw nsw <4 x i32> %271, %261
  %273 = add nsw <4 x i32> %272, %255
  %274 = add nuw nsw i64 %240, 32
  %275 = getelementptr inbounds i8, i8* %222, i64 %274
  %276 = bitcast i8* %275 to <4 x i8>*
  %277 = load <4 x i8>, <4 x i8>* %276, align 1
  %278 = zext <4 x i8> %277 to <4 x i32>
  %279 = mul nuw nsw <4 x i32> %278, %261
  %280 = add nsw <4 x i32> %279, %254
  %281 = add nuw nsw i64 %240, 48
  %282 = getelementptr inbounds i8, i8* %222, i64 %281
  %283 = bitcast i8* %282 to <4 x i8>*
  %284 = load <4 x i8>, <4 x i8>* %283, align 1
  %285 = zext <4 x i8> %284 to <4 x i32>
  %286 = mul nuw nsw <4 x i32> %285, %261
  %287 = add nsw <4 x i32> %286, %253
  %288 = getelementptr inbounds i8, i8* %221, i64 %267
  %289 = bitcast i8* %288 to <4 x i8>*
  %290 = load <4 x i8>, <4 x i8>* %289, align 1
  %291 = zext <4 x i8> %290 to <4 x i32>
  %292 = mul nuw nsw <4 x i32> %264, %291
  %293 = add nsw <4 x i32> %292, %252
  %294 = mul nuw nsw <4 x i32> %271, %291
  %295 = add nsw <4 x i32> %294, %251
  %296 = mul nuw nsw <4 x i32> %278, %291
  %297 = add nsw <4 x i32> %296, %250
  %298 = mul nuw nsw <4 x i32> %285, %291
  %299 = add nsw <4 x i32> %298, %249
  %300 = getelementptr inbounds i8, i8* %221, i64 %274
  %301 = bitcast i8* %300 to <4 x i8>*
  %302 = load <4 x i8>, <4 x i8>* %301, align 1
  %303 = zext <4 x i8> %302 to <4 x i32>
  %304 = mul nuw nsw <4 x i32> %264, %303
  %305 = add nsw <4 x i32> %304, %248
  %306 = mul nuw nsw <4 x i32> %271, %303
  %307 = add nsw <4 x i32> %306, %247
  %308 = mul nuw nsw <4 x i32> %278, %303
  %309 = add nsw <4 x i32> %308, %246
  %310 = mul nuw nsw <4 x i32> %285, %303
  %311 = add nsw <4 x i32> %310, %245
  %312 = getelementptr inbounds i8, i8* %221, i64 %281
  %313 = bitcast i8* %312 to <4 x i8>*
  %314 = load <4 x i8>, <4 x i8>* %313, align 1
  %315 = zext <4 x i8> %314 to <4 x i32>
  %316 = mul nuw nsw <4 x i32> %264, %315
  %317 = add nsw <4 x i32> %316, %244
  %318 = mul nuw nsw <4 x i32> %271, %315
  %319 = add nsw <4 x i32> %318, %243
  %320 = mul nuw nsw <4 x i32> %278, %315
  %321 = add nsw <4 x i32> %320, %242
  %322 = mul nuw nsw <4 x i32> %285, %315
  %323 = add nsw <4 x i32> %322, %241
  %324 = add i64 %240, 4
  %325 = icmp eq i64 %324, 16
  br i1 %325, label %326, label %239, !llvm.loop !843

326:                                              ; preds = %239
  %327 = shufflevector <4 x i32> %266, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %328 = add <4 x i32> %266, %327
  %329 = shufflevector <4 x i32> %328, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %330 = add <4 x i32> %328, %329
  %331 = extractelement <4 x i32> %330, i32 0
  %332 = shufflevector <4 x i32> %273, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %333 = add <4 x i32> %273, %332
  %334 = shufflevector <4 x i32> %333, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %335 = add <4 x i32> %333, %334
  %336 = extractelement <4 x i32> %335, i32 0
  %337 = shufflevector <4 x i32> %280, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %338 = add <4 x i32> %280, %337
  %339 = shufflevector <4 x i32> %338, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %340 = add <4 x i32> %338, %339
  %341 = extractelement <4 x i32> %340, i32 0
  %342 = shufflevector <4 x i32> %287, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %343 = add <4 x i32> %287, %342
  %344 = shufflevector <4 x i32> %343, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %345 = add <4 x i32> %343, %344
  %346 = extractelement <4 x i32> %345, i32 0
  %347 = shufflevector <4 x i32> %293, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %348 = add <4 x i32> %293, %347
  %349 = shufflevector <4 x i32> %348, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %350 = add <4 x i32> %348, %349
  %351 = extractelement <4 x i32> %350, i32 0
  %352 = shufflevector <4 x i32> %295, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %353 = add <4 x i32> %295, %352
  %354 = shufflevector <4 x i32> %353, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %355 = add <4 x i32> %353, %354
  %356 = extractelement <4 x i32> %355, i32 0
  %357 = shufflevector <4 x i32> %297, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %358 = add <4 x i32> %297, %357
  %359 = shufflevector <4 x i32> %358, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %360 = add <4 x i32> %358, %359
  %361 = extractelement <4 x i32> %360, i32 0
  %362 = shufflevector <4 x i32> %299, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %363 = add <4 x i32> %299, %362
  %364 = shufflevector <4 x i32> %363, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %365 = add <4 x i32> %363, %364
  %366 = extractelement <4 x i32> %365, i32 0
  %367 = shufflevector <4 x i32> %305, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %368 = add <4 x i32> %305, %367
  %369 = shufflevector <4 x i32> %368, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %370 = add <4 x i32> %368, %369
  %371 = extractelement <4 x i32> %370, i32 0
  %372 = shufflevector <4 x i32> %307, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %373 = add <4 x i32> %307, %372
  %374 = shufflevector <4 x i32> %373, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %375 = add <4 x i32> %373, %374
  %376 = extractelement <4 x i32> %375, i32 0
  %377 = shufflevector <4 x i32> %309, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %378 = add <4 x i32> %309, %377
  %379 = shufflevector <4 x i32> %378, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %380 = add <4 x i32> %378, %379
  %381 = extractelement <4 x i32> %380, i32 0
  %382 = shufflevector <4 x i32> %311, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %383 = add <4 x i32> %311, %382
  %384 = shufflevector <4 x i32> %383, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %385 = add <4 x i32> %383, %384
  %386 = extractelement <4 x i32> %385, i32 0
  %387 = shufflevector <4 x i32> %317, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %388 = add <4 x i32> %317, %387
  %389 = shufflevector <4 x i32> %388, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %390 = add <4 x i32> %388, %389
  %391 = extractelement <4 x i32> %390, i32 0
  %392 = shufflevector <4 x i32> %319, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %393 = add <4 x i32> %319, %392
  %394 = shufflevector <4 x i32> %393, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %395 = add <4 x i32> %393, %394
  %396 = extractelement <4 x i32> %395, i32 0
  %397 = shufflevector <4 x i32> %321, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %398 = add <4 x i32> %321, %397
  %399 = shufflevector <4 x i32> %398, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %400 = add <4 x i32> %398, %399
  %401 = extractelement <4 x i32> %400, i32 0
  %402 = shufflevector <4 x i32> %323, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %403 = add <4 x i32> %323, %402
  %404 = shufflevector <4 x i32> %403, <4 x i32> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %405 = add <4 x i32> %403, %404
  %406 = extractelement <4 x i32> %405, i32 0
  %407 = add nuw nsw i32 %218, 1
  %408 = icmp eq i32 %407, %12
  br i1 %408, label %47, label %201

409:                                              ; preds = %53, %144
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %10) #19
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp13DefaultKernelINS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEEED0Ev(%"struct.gemmlowp::DefaultKernel"*) unnamed_addr #4 comdat align 2 {
  %2 = bitcast %"struct.gemmlowp::DefaultKernel"* %0 to i8*
  tail call void @_ZdlPv(i8* %2) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp10KernelBaseD2Ev(%"struct.gemmlowp::KernelBase"*) unnamed_addr #1 comdat align 2 {
  ret void
}

; Function Attrs: nofree nounwind
declare i32 @snprintf(i8* nocapture, i64, i8* nocapture readonly, ...) local_unnamed_addr #9

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17DispatchGemmShapeIhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENS7_IS8_LS9_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSL_ISN_XT3_EEEPNSL_IT0_XT4_EEERKT5_RKT6_RKT7_(%"class.gemmlowp::GemmContext"*, %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.180"* dereferenceable(24), %"class.gemmlowp::MatrixMap.182"*, %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.std::__1::tuple.187"* dereferenceable(20)) local_unnamed_addr #1 comdat {
  %8 = alloca %"class.gemmlowp::MatrixMap.195", align 8
  %9 = alloca %"class.gemmlowp::MatrixMap", align 8
  %10 = alloca %"class.gemmlowp::MatrixMap.180", align 8
  %11 = alloca %"class.gemmlowp::VectorDup.194", align 4
  %12 = alloca %"class.gemmlowp::VectorDup", align 4
  %13 = alloca %"class.std::__1::tuple.187", align 8
  %14 = alloca %"struct.gemmlowp::DefaultKernel", align 8
  %15 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %3, i64 0, i32 1
  %16 = load i32, i32* %15, align 8
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %3, i64 0, i32 2
  %18 = load i32, i32* %17, align 4
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 2
  %20 = load i32, i32* %19, align 4
  %21 = icmp eq i32 %16, 0
  %22 = icmp eq i32 %18, 0
  %23 = or i1 %21, %22
  %24 = icmp eq i32 %20, 0
  %25 = or i1 %23, %24
  br i1 %25, label %93, label %26

26:                                               ; preds = %7
  %27 = icmp slt i32 %16, %18
  br i1 %27, label %28, label %89

28:                                               ; preds = %26
  %29 = bitcast %"class.gemmlowp::MatrixMap.195"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %29) #19
  %30 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %8, i64 0, i32 1
  %31 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %8, i64 0, i32 2
  %32 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %8, i64 0, i32 3
  %33 = bitcast %"class.gemmlowp::MatrixMap.182"* %3 to i64*
  %34 = bitcast %"class.gemmlowp::MatrixMap.195"* %8 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %34, i8 -86, i64 24, i1 false)
  %35 = load i64, i64* %33, align 8, !noalias !844
  %36 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %3, i64 0, i32 3
  %37 = load i32, i32* %36, align 8, !noalias !844
  %38 = bitcast %"class.gemmlowp::MatrixMap.195"* %8 to i64*
  store i64 %35, i64* %38, align 8, !alias.scope !844
  store i32 %18, i32* %30, align 8, !alias.scope !844
  store i32 %16, i32* %31, align 4, !alias.scope !844
  store i32 %37, i32* %32, align 8, !alias.scope !844
  %39 = bitcast %"class.gemmlowp::MatrixMap"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %39) #19
  %40 = bitcast %"class.gemmlowp::MatrixMap.180"* %2 to i64*
  %41 = load i64, i64* %40, align 8, !noalias !849
  %42 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %2, i64 0, i32 2
  %43 = load i32, i32* %42, align 4, !noalias !849
  %44 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %2, i64 0, i32 1
  %45 = load i32, i32* %44, align 8, !noalias !849
  %46 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %2, i64 0, i32 3
  %47 = load i32, i32* %46, align 8, !noalias !849
  %48 = bitcast %"class.gemmlowp::MatrixMap"* %9 to i64*
  store i64 %41, i64* %48, align 8, !alias.scope !849
  %49 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 1
  store i32 %43, i32* %49, align 8, !alias.scope !849
  %50 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 2
  store i32 %45, i32* %50, align 4, !alias.scope !849
  %51 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 3
  store i32 %47, i32* %51, align 8, !alias.scope !849
  %52 = bitcast %"class.gemmlowp::MatrixMap.180"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %52) #19
  %53 = bitcast %"class.gemmlowp::MatrixMap"* %1 to i64*
  %54 = load i64, i64* %53, align 8, !noalias !854
  %55 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 1
  %56 = load i32, i32* %55, align 8, !noalias !854
  %57 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 3
  %58 = load i32, i32* %57, align 8, !noalias !854
  %59 = bitcast %"class.gemmlowp::MatrixMap.180"* %10 to i64*
  store i64 %54, i64* %59, align 8, !alias.scope !854
  %60 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %10, i64 0, i32 1
  store i32 %20, i32* %60, align 8, !alias.scope !854
  %61 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %10, i64 0, i32 2
  store i32 %56, i32* %61, align 4, !alias.scope !854
  %62 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %10, i64 0, i32 3
  store i32 %58, i32* %62, align 8, !alias.scope !854
  %63 = bitcast %"class.gemmlowp::VectorDup.194"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %63) #19
  %64 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %11, i64 0, i32 0
  %65 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 0
  %66 = load i32, i32* %65, align 4, !noalias !859
  store i32 %66, i32* %64, align 4, !alias.scope !859
  %67 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %11, i64 0, i32 1
  %68 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 1
  %69 = load i32, i32* %68, align 4, !noalias !859
  store i32 %69, i32* %67, align 4, !alias.scope !859
  %70 = bitcast %"class.gemmlowp::VectorDup"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %70) #19
  %71 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %12, i64 0, i32 0
  %72 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %4, i64 0, i32 0
  %73 = load i32, i32* %72, align 4, !noalias !864
  store i32 %73, i32* %71, align 4, !alias.scope !864
  %74 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %12, i64 0, i32 1
  %75 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %4, i64 0, i32 1
  %76 = load i32, i32* %75, align 4, !noalias !864
  store i32 %76, i32* %74, align 4, !alias.scope !864
  %77 = bitcast %"class.std::__1::tuple.187"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 20, i8* nonnull %77) #19
  %78 = bitcast %"class.std::__1::tuple.187"* %6 to i64*
  %79 = load i64, i64* %78, align 4, !noalias !869
  %80 = getelementptr inbounds %"class.std::__1::tuple.187", %"class.std::__1::tuple.187"* %6, i64 0, i32 0, i32 0, i32 0, i32 2
  %81 = load i32, i32* %80, align 4, !noalias !869
  %82 = getelementptr inbounds %"class.std::__1::tuple.187", %"class.std::__1::tuple.187"* %6, i64 0, i32 0, i32 1, i32 0
  %83 = bitcast %"struct.gemmlowp::OutputStageClamp"* %82 to i64*
  %84 = load i64, i64* %83, align 4, !noalias !869
  %85 = bitcast %"class.std::__1::tuple.187"* %13 to i64*
  store i64 %79, i64* %85, align 8, !alias.scope !869
  %86 = getelementptr inbounds %"class.std::__1::tuple.187", %"class.std::__1::tuple.187"* %13, i64 0, i32 0, i32 0, i32 0, i32 2
  store i32 %81, i32* %86, align 8, !alias.scope !869
  %87 = getelementptr inbounds %"class.std::__1::tuple.187", %"class.std::__1::tuple.187"* %13, i64 0, i32 0, i32 1
  %88 = bitcast %"class.std::__1::__tuple_leaf.190"* %87 to i64*
  store i64 %84, i64* %88, align 4, !alias.scope !872
  call void @_ZN8gemmlowp17DispatchGemmShapeIhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENS7_IS8_LS9_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSL_ISN_XT3_EEEPNSL_IT0_XT4_EEERKT5_RKT6_RKT7_(%"class.gemmlowp::GemmContext"* %0, %"class.gemmlowp::MatrixMap"* nonnull dereferenceable(24) %9, %"class.gemmlowp::MatrixMap.180"* nonnull dereferenceable(24) %10, %"class.gemmlowp::MatrixMap.195"* nonnull %8, %"class.gemmlowp::VectorDup.194"* nonnull dereferenceable(8) %11, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %12, %"class.std::__1::tuple.187"* nonnull dereferenceable(20) %13)
  call void @llvm.lifetime.end.p0i8(i64 20, i8* nonnull %77) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %70) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %63) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %52) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %39) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %29) #19
  br label %93

89:                                               ; preds = %26
  %90 = bitcast %"struct.gemmlowp::DefaultKernel"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %90) #19
  %91 = getelementptr inbounds %"struct.gemmlowp::DefaultKernel", %"struct.gemmlowp::DefaultKernel"* %14, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [6 x i8*] }, { [6 x i8*] }* @_ZTVN8gemmlowp13DefaultKernelINS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %91, align 8
  %92 = getelementptr inbounds %"struct.gemmlowp::DefaultKernel", %"struct.gemmlowp::DefaultKernel"* %14, i64 0, i32 0, i32 0, i32 0, i32 0
  call void @_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSV_ISX_XT4_EEEPNSV_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::GemmContext"* %0, %"struct.gemmlowp::KernelBase"* nonnull dereferenceable(8) %92, %"class.gemmlowp::MatrixMap"* dereferenceable(24) %1, %"class.gemmlowp::MatrixMap.180"* dereferenceable(24) %2, %"class.gemmlowp::MatrixMap.182"* %3, %"class.gemmlowp::VectorDup"* dereferenceable(8) %4, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %5, %"class.std::__1::tuple.187"* dereferenceable(20) %6)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %90) #19
  br label %93

93:                                               ; preds = %7, %89, %28
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17DispatchGemmShapeIhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENS7_IS8_LS9_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSL_ISN_XT3_EEEPNSL_IT0_XT4_EEERKT5_RKT6_RKT7_(%"class.gemmlowp::GemmContext"*, %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.180"* dereferenceable(24), %"class.gemmlowp::MatrixMap.195"*, %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.std::__1::tuple.187"* dereferenceable(20)) local_unnamed_addr #1 comdat {
  %8 = alloca %"class.gemmlowp::MatrixMap.182", align 8
  %9 = alloca %"class.gemmlowp::MatrixMap", align 8
  %10 = alloca %"class.gemmlowp::MatrixMap.180", align 8
  %11 = alloca %"class.gemmlowp::VectorDup", align 4
  %12 = alloca %"class.gemmlowp::VectorDup.194", align 4
  %13 = alloca %"class.std::__1::tuple.187", align 8
  %14 = alloca %"struct.gemmlowp::DefaultKernel", align 8
  %15 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %3, i64 0, i32 1
  %16 = load i32, i32* %15, align 8
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %3, i64 0, i32 2
  %18 = load i32, i32* %17, align 4
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 2
  %20 = load i32, i32* %19, align 4
  %21 = icmp eq i32 %16, 0
  %22 = icmp eq i32 %18, 0
  %23 = or i1 %21, %22
  %24 = icmp eq i32 %20, 0
  %25 = or i1 %23, %24
  br i1 %25, label %93, label %26

26:                                               ; preds = %7
  %27 = icmp slt i32 %16, %18
  br i1 %27, label %28, label %89

28:                                               ; preds = %26
  %29 = bitcast %"class.gemmlowp::MatrixMap.182"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %29) #19
  %30 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %8, i64 0, i32 1
  %31 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %8, i64 0, i32 2
  %32 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %8, i64 0, i32 3
  %33 = bitcast %"class.gemmlowp::MatrixMap.195"* %3 to i64*
  %34 = bitcast %"class.gemmlowp::MatrixMap.182"* %8 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %34, i8 -86, i64 24, i1 false)
  %35 = load i64, i64* %33, align 8, !noalias !875
  %36 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %3, i64 0, i32 3
  %37 = load i32, i32* %36, align 8, !noalias !875
  %38 = bitcast %"class.gemmlowp::MatrixMap.182"* %8 to i64*
  store i64 %35, i64* %38, align 8, !alias.scope !875
  store i32 %18, i32* %30, align 8, !alias.scope !875
  store i32 %16, i32* %31, align 4, !alias.scope !875
  store i32 %37, i32* %32, align 8, !alias.scope !875
  %39 = bitcast %"class.gemmlowp::MatrixMap"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %39) #19
  %40 = bitcast %"class.gemmlowp::MatrixMap.180"* %2 to i64*
  %41 = load i64, i64* %40, align 8, !noalias !880
  %42 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %2, i64 0, i32 2
  %43 = load i32, i32* %42, align 4, !noalias !880
  %44 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %2, i64 0, i32 1
  %45 = load i32, i32* %44, align 8, !noalias !880
  %46 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %2, i64 0, i32 3
  %47 = load i32, i32* %46, align 8, !noalias !880
  %48 = bitcast %"class.gemmlowp::MatrixMap"* %9 to i64*
  store i64 %41, i64* %48, align 8, !alias.scope !880
  %49 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 1
  store i32 %43, i32* %49, align 8, !alias.scope !880
  %50 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 2
  store i32 %45, i32* %50, align 4, !alias.scope !880
  %51 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 3
  store i32 %47, i32* %51, align 8, !alias.scope !880
  %52 = bitcast %"class.gemmlowp::MatrixMap.180"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %52) #19
  %53 = bitcast %"class.gemmlowp::MatrixMap"* %1 to i64*
  %54 = load i64, i64* %53, align 8, !noalias !885
  %55 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 1
  %56 = load i32, i32* %55, align 8, !noalias !885
  %57 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 3
  %58 = load i32, i32* %57, align 8, !noalias !885
  %59 = bitcast %"class.gemmlowp::MatrixMap.180"* %10 to i64*
  store i64 %54, i64* %59, align 8, !alias.scope !885
  %60 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %10, i64 0, i32 1
  store i32 %20, i32* %60, align 8, !alias.scope !885
  %61 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %10, i64 0, i32 2
  store i32 %56, i32* %61, align 4, !alias.scope !885
  %62 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %10, i64 0, i32 3
  store i32 %58, i32* %62, align 8, !alias.scope !885
  %63 = bitcast %"class.gemmlowp::VectorDup"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %63) #19
  %64 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %11, i64 0, i32 0
  %65 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %66 = load i32, i32* %65, align 4, !noalias !890
  store i32 %66, i32* %64, align 4, !alias.scope !890
  %67 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %11, i64 0, i32 1
  %68 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 1
  %69 = load i32, i32* %68, align 4, !noalias !890
  store i32 %69, i32* %67, align 4, !alias.scope !890
  %70 = bitcast %"class.gemmlowp::VectorDup.194"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %70) #19
  %71 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %12, i64 0, i32 0
  %72 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %4, i64 0, i32 0
  %73 = load i32, i32* %72, align 4, !noalias !895
  store i32 %73, i32* %71, align 4, !alias.scope !895
  %74 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %12, i64 0, i32 1
  %75 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %4, i64 0, i32 1
  %76 = load i32, i32* %75, align 4, !noalias !895
  store i32 %76, i32* %74, align 4, !alias.scope !895
  %77 = bitcast %"class.std::__1::tuple.187"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 20, i8* nonnull %77) #19
  %78 = bitcast %"class.std::__1::tuple.187"* %6 to i64*
  %79 = load i64, i64* %78, align 4, !noalias !900
  %80 = getelementptr inbounds %"class.std::__1::tuple.187", %"class.std::__1::tuple.187"* %6, i64 0, i32 0, i32 0, i32 0, i32 2
  %81 = load i32, i32* %80, align 4, !noalias !900
  %82 = getelementptr inbounds %"class.std::__1::tuple.187", %"class.std::__1::tuple.187"* %6, i64 0, i32 0, i32 1, i32 0
  %83 = bitcast %"struct.gemmlowp::OutputStageClamp"* %82 to i64*
  %84 = load i64, i64* %83, align 4, !noalias !900
  %85 = bitcast %"class.std::__1::tuple.187"* %13 to i64*
  store i64 %79, i64* %85, align 8, !alias.scope !900
  %86 = getelementptr inbounds %"class.std::__1::tuple.187", %"class.std::__1::tuple.187"* %13, i64 0, i32 0, i32 0, i32 0, i32 2
  store i32 %81, i32* %86, align 8, !alias.scope !900
  %87 = getelementptr inbounds %"class.std::__1::tuple.187", %"class.std::__1::tuple.187"* %13, i64 0, i32 0, i32 1
  %88 = bitcast %"class.std::__1::__tuple_leaf.190"* %87 to i64*
  store i64 %84, i64* %88, align 4, !alias.scope !903
  call void @_ZN8gemmlowp17DispatchGemmShapeIhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENS7_IS8_LS9_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSL_ISN_XT3_EEEPNSL_IT0_XT4_EEERKT5_RKT6_RKT7_(%"class.gemmlowp::GemmContext"* %0, %"class.gemmlowp::MatrixMap"* nonnull dereferenceable(24) %9, %"class.gemmlowp::MatrixMap.180"* nonnull dereferenceable(24) %10, %"class.gemmlowp::MatrixMap.182"* nonnull %8, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %11, %"class.gemmlowp::VectorDup.194"* nonnull dereferenceable(8) %12, %"class.std::__1::tuple.187"* nonnull dereferenceable(20) %13)
  call void @llvm.lifetime.end.p0i8(i64 20, i8* nonnull %77) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %70) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %63) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %52) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %39) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %29) #19
  br label %93

89:                                               ; preds = %26
  %90 = bitcast %"struct.gemmlowp::DefaultKernel"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %90) #19
  %91 = getelementptr inbounds %"struct.gemmlowp::DefaultKernel", %"struct.gemmlowp::DefaultKernel"* %14, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [6 x i8*] }, { [6 x i8*] }* @_ZTVN8gemmlowp13DefaultKernelINS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %91, align 8
  %92 = getelementptr inbounds %"struct.gemmlowp::DefaultKernel", %"struct.gemmlowp::DefaultKernel"* %14, i64 0, i32 0, i32 0, i32 0, i32 0
  call void @_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSV_ISX_XT4_EEEPNSV_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::GemmContext"* %0, %"struct.gemmlowp::KernelBase"* nonnull dereferenceable(8) %92, %"class.gemmlowp::MatrixMap"* dereferenceable(24) %1, %"class.gemmlowp::MatrixMap.180"* dereferenceable(24) %2, %"class.gemmlowp::MatrixMap.195"* %3, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %4, %"class.gemmlowp::VectorDup"* dereferenceable(8) %5, %"class.std::__1::tuple.187"* dereferenceable(20) %6)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %90) #19
  br label %93

93:                                               ; preds = %7, %89, %28
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSV_ISX_XT4_EEEPNSV_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::GemmContext"*, %"struct.gemmlowp::KernelBase"* dereferenceable(8), %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.180"* dereferenceable(24), %"class.gemmlowp::MatrixMap.182"*, %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.std::__1::tuple.187"* dereferenceable(20)) local_unnamed_addr #1 comdat {
  %9 = alloca %"class.gemmlowp::SideMap", align 8
  %10 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %11 = alloca %"struct.gemmlowp::BlockParams", align 4
  %12 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %13 = alloca %"class.std::__1::vector.205", align 8
  %14 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %4, i64 0, i32 1
  %15 = load i32, i32* %14, align 8
  %16 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %4, i64 0, i32 2
  %17 = load i32, i32* %16, align 4
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 2
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %"class.gemmlowp::GemmContext", %"class.gemmlowp::GemmContext"* %0, i64 0, i32 0, i32 0, i32 1
  %21 = load i32, i32* %20, align 4
  switch i32 %21, label %34 [
    i32 1, label %54
    i32 0, label %22
  ]

22:                                               ; preds = %8
  %23 = load atomic i8, i8* bitcast (i64* @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count to i8*) acquire, align 8
  %24 = icmp eq i8 %23, 0
  br i1 %24, label %25, label %32, !prof !514

25:                                               ; preds = %22
  %26 = tail call i32 @__cxa_guard_acquire(i64* nonnull @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count) #19
  %27 = icmp eq i32 %26, 0
  br i1 %27, label %32, label %28

28:                                               ; preds = %25
  %29 = tail call i64 @sysconf(i32 83) #19
  %30 = trunc i64 %29 to i32
  store i32 %30, i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count, align 4
  %31 = tail call {}* @llvm.invariant.start.p0i8(i64 4, i8* bitcast (i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count to i8*)) #19
  tail call void @__cxa_guard_release(i64* nonnull @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count) #19
  br label %32

32:                                               ; preds = %28, %25, %22
  %33 = load i32, i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count, align 4
  br label %34

34:                                               ; preds = %32, %8
  %35 = phi i32 [ %33, %32 ], [ %21, %8 ]
  %36 = add i32 %15, 15
  %37 = sdiv i32 %36, 16
  %38 = icmp slt i32 %37, %35
  %39 = select i1 %38, i32 %37, i32 %35
  %40 = icmp sgt i32 %39, 1
  br i1 %40, label %41, label %56

41:                                               ; preds = %34
  %42 = sext i32 %15 to i64
  %43 = sext i32 %17 to i64
  %44 = mul nsw i64 %43, %42
  %45 = sext i32 %19 to i64
  %46 = mul i64 %44, %45
  %47 = lshr i64 %46, 16
  %48 = trunc i64 %47 to i32
  %49 = icmp sgt i32 %39, %48
  %50 = select i1 %49, i32 %48, i32 %39
  %51 = icmp sgt i32 %50, 1
  br i1 %51, label %52, label %54

52:                                               ; preds = %41
  %53 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br label %61

54:                                               ; preds = %41, %8
  %55 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br label %59

56:                                               ; preds = %34
  %57 = icmp eq i32 %39, 1
  %58 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br i1 %57, label %59, label %61

59:                                               ; preds = %54, %56
  %60 = phi %"class.gemmlowp::SingleThreadGemmContext"* [ %55, %54 ], [ %58, %56 ]
  tail call void @_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSU_ISW_XT4_EEEPNSU_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::SingleThreadGemmContext"* %60, %"struct.gemmlowp::KernelBase"* dereferenceable(8) %1, %"class.gemmlowp::MatrixMap"* dereferenceable(24) %2, %"class.gemmlowp::MatrixMap.180"* dereferenceable(24) %3, %"class.gemmlowp::MatrixMap.182"* %4, %"class.gemmlowp::VectorDup"* dereferenceable(8) %5, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.std::__1::tuple.187"* dereferenceable(20) %7)
  br label %303

61:                                               ; preds = %52, %56
  %62 = phi %"class.gemmlowp::SingleThreadGemmContext"* [ %53, %52 ], [ %58, %56 ]
  %63 = phi i32 [ %50, %52 ], [ %39, %56 ]
  %64 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0
  %65 = getelementptr inbounds %"class.gemmlowp::GemmContext", %"class.gemmlowp::GemmContext"* %0, i64 0, i32 0, i32 1
  %66 = bitcast %"struct.gemmlowp::BlockParams"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %66) #19
  %67 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 1
  %68 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 2
  %69 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 4
  %70 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 5
  %71 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 1
  %72 = bitcast %"struct.gemmlowp::BlockParams"* %11 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %72, i8 -86, i64 24, i1 false)
  %73 = load i32, i32* %71, align 8
  %74 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 2
  %75 = load i32, i32* %74, align 4
  %76 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 3
  %77 = load float, float* %76, align 8
  call void @_ZN8gemmlowp11BlockParams4InitINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES7_EEEEviiiiiif(%"struct.gemmlowp::BlockParams"* nonnull %11, i32 %15, i32 %17, i32 %19, i32 %63, i32 %73, i32 %75, float %77)
  %78 = bitcast %"class.gemmlowp::PackedSideBlock"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %78) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %78, i8 -86, i64 80, i1 false)
  %79 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %64, %"class.gemmlowp::Allocator"** %79, align 8
  %80 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 4
  store i32 0, i32* %80, align 8
  %81 = load i32, i32* %67, align 4
  %82 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 0
  store i32 %81, i32* %82, align 8
  %83 = load i32, i32* %69, align 4
  %84 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 2
  store i32 %83, i32* %84, align 8
  %85 = load i32, i32* %68, align 4
  %86 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 1
  store i32 %85, i32* %86, align 4
  %87 = load i32, i32* %70, align 4
  %88 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 3
  store i32 %87, i32* %88, align 4
  %89 = mul nsw i32 %87, %83
  %90 = sext i32 %89 to i64
  %91 = add nsw i64 %90, 63
  %92 = and i64 %91, -64
  %93 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 4
  %94 = load i64, i64* %93, align 8, !noalias !906
  %95 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 3
  %96 = load i64, i64* %95, align 8, !noalias !906
  %97 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 5, i64 %96
  store i64 %94, i64* %97, align 8, !noalias !906
  %98 = trunc i64 %96 to i8
  %99 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 6
  %100 = load i64, i64* %99, align 8, !noalias !906
  %101 = load i64, i64* %95, align 8, !noalias !906
  %102 = add i64 %101, 1
  store i64 %102, i64* %95, align 8, !noalias !906
  %103 = load i64, i64* %93, align 8, !noalias !906
  %104 = add i64 %103, %92
  store i64 %104, i64* %93, align 8, !noalias !906
  %105 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 0
  store i8 %98, i8* %105, align 8
  %106 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %106, i8 -86, i64 7, i1 false) #19
  %107 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 2
  store i64 %100, i64* %107, align 8
  %108 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 3
  store i8 0, i8* %108, align 8
  %109 = sext i32 %83 to i64
  %110 = shl nsw i64 %109, 2
  %111 = add nsw i64 %110, 63
  %112 = and i64 %111, -64
  %113 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 5, i64 %102
  store i64 %104, i64* %113, align 8, !noalias !909
  %114 = trunc i64 %102 to i8
  %115 = load i64, i64* %99, align 8, !noalias !909
  %116 = bitcast i64* %95 to <2 x i64>*
  %117 = load <2 x i64>, <2 x i64>* %116, align 8, !noalias !909
  %118 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %112, i32 1
  %119 = add <2 x i64> %117, %118
  %120 = bitcast i64* %95 to <2 x i64>*
  store <2 x i64> %119, <2 x i64>* %120, align 8, !noalias !909
  %121 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 0
  store i8 %114, i8* %121, align 8
  %122 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %122, i8 -86, i64 7, i1 false) #19
  %123 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 2
  store i64 %115, i64* %123, align 8
  %124 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 3
  store i8 5, i8* %124, align 8
  call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %64)
  %125 = icmp sgt i32 %17, 0
  br i1 %125, label %126, label %150

126:                                              ; preds = %61
  %127 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 0
  %128 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 3
  %129 = bitcast %"class.gemmlowp::SideMap"* %9 to i8*
  %130 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 1
  %131 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 2
  %132 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 3
  %133 = bitcast %"class.gemmlowp::SideMap"* %9 to i64*
  %134 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %10 to i8*
  %135 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 0
  %136 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 1
  %137 = bitcast %"class.std::__1::vector.205"* %13 to i8*
  %138 = getelementptr inbounds %"class.std::__1::vector.205", %"class.std::__1::vector.205"* %13, i64 0, i32 0, i32 0
  %139 = getelementptr inbounds %"class.std::__1::vector.205", %"class.std::__1::vector.205"* %13, i64 0, i32 0, i32 1
  %140 = getelementptr inbounds %"class.std::__1::vector.205", %"class.std::__1::vector.205"* %13, i64 0, i32 0, i32 2, i32 0, i32 0
  %141 = icmp sgt i32 %63, 0
  %142 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 0
  %143 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 3
  %144 = bitcast %"class.gemmlowp::MatrixMap.182"* %4 to i64*
  %145 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %4, i64 0, i32 3
  %146 = bitcast %"struct.gemmlowp::Task"*** %139 to i64*
  %147 = bitcast %"class.std::__1::vector.205"* %13 to i64*
  %148 = bitcast %"struct.gemmlowp::Task"*** %140 to i64*
  %149 = load i32, i32* %69, align 4
  br label %155

150:                                              ; preds = %173, %61
  %151 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 0
  store i8 0, i8* %151, align 8
  %152 = load i64, i64* %99, align 8
  %153 = add i64 %152, 1
  store i64 %153, i64* %99, align 8
  %154 = bitcast i64* %95 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %154, i8 0, i64 16, i1 false) #19
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %78) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %66) #19
  br label %303

155:                                              ; preds = %126, %173
  %156 = phi i32 [ %149, %126 ], [ %174, %173 ]
  %157 = phi i32 [ 0, %126 ], [ %175, %173 ]
  %158 = sub nsw i32 %17, %157
  %159 = icmp slt i32 %158, %156
  %160 = select i1 %159, i32 %158, i32 %156
  %161 = load i8*, i8** %127, align 8, !noalias !912
  %162 = load i32, i32* %128, align 8, !noalias !912
  %163 = mul nsw i32 %162, %157
  %164 = sext i32 %163 to i64
  %165 = getelementptr inbounds i8, i8* %161, i64 %164
  %166 = ptrtoint i8* %165 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %129) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %129, i8 -86, i64 24, i1 false) #19
  store i64 %166, i64* %133, align 8
  store i32 %160, i32* %130, align 8
  store i32 %19, i32* %131, align 4
  store i32 %162, i32* %132, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %134) #19
  store %"class.gemmlowp::PackedSideBlock"* %12, %"class.gemmlowp::PackedSideBlock"** %135, align 8
  store %"class.gemmlowp::SideMap"* %9, %"class.gemmlowp::SideMap"** %136, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %10) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %134) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %129) #19
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %137) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %137, i8 0, i64 24, i1 false) #19
  br i1 %141, label %177, label %167

167:                                              ; preds = %297, %155
  call void @_ZN8gemmlowp11WorkersPool28LegacyExecuteAndDestroyTasksERKNSt3__16vectorIPNS_4TaskENS1_9allocatorIS4_EEEE(%"class.gemmlowp::WorkersPool"* %65, %"class.std::__1::vector.205"* nonnull dereferenceable(24) %13) #19
  %168 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %138, align 8
  %169 = icmp eq %"struct.gemmlowp::Task"** %168, null
  br i1 %169, label %173, label %170

170:                                              ; preds = %167
  %171 = ptrtoint %"struct.gemmlowp::Task"** %168 to i64
  store i64 %171, i64* %146, align 8
  %172 = bitcast %"struct.gemmlowp::Task"** %168 to i8*
  call void @_ZdlPv(i8* %172) #18
  br label %173

173:                                              ; preds = %167, %170
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %137) #19
  %174 = load i32, i32* %69, align 4
  %175 = add nsw i32 %174, %157
  %176 = icmp sgt i32 %17, %175
  br i1 %176, label %155, label %150

177:                                              ; preds = %155, %299
  %178 = phi i64 [ %302, %299 ], [ 0, %155 ]
  %179 = phi %"struct.gemmlowp::Task"** [ %301, %299 ], [ null, %155 ]
  %180 = phi %"struct.gemmlowp::Task"** [ %300, %299 ], [ null, %155 ]
  %181 = phi i32 [ %183, %299 ], [ 0, %155 ]
  %182 = phi i32 [ %189, %299 ], [ 0, %155 ]
  %183 = add nuw nsw i32 %181, 1
  %184 = mul nsw i32 %183, %15
  %185 = sdiv i32 %184, %63
  %186 = add i32 %185, 3
  %187 = and i32 %186, -4
  %188 = icmp slt i32 %187, %15
  %189 = select i1 %188, i32 %187, i32 %15
  %190 = sub nsw i32 %189, %182
  %191 = load i8*, i8** %142, align 8, !noalias !915
  %192 = load i32, i32* %143, align 8, !noalias !915
  %193 = mul nsw i32 %192, %182
  %194 = sext i32 %193 to i64
  %195 = getelementptr inbounds i8, i8* %191, i64 %194
  %196 = ptrtoint i8* %195 to i64
  %197 = call i8* @_Znwm(i64 208) #18
  %198 = bitcast i8* %197 to i32 (...)***
  %199 = getelementptr inbounds i8, i8* %197, i64 8
  %200 = bitcast i8* %199 to %"class.gemmlowp::Allocator"**
  store %"class.gemmlowp::Allocator"* null, %"class.gemmlowp::Allocator"** %200, align 8
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %198, align 8
  %201 = getelementptr inbounds i8, i8* %197, i64 16
  %202 = bitcast i8* %201 to %"class.gemmlowp::GemmContext"**
  store %"class.gemmlowp::GemmContext"* %0, %"class.gemmlowp::GemmContext"** %202, align 8
  %203 = getelementptr inbounds i8, i8* %197, i64 24
  %204 = bitcast i8* %203 to %"struct.gemmlowp::KernelBase"**
  store %"struct.gemmlowp::KernelBase"* %1, %"struct.gemmlowp::KernelBase"** %204, align 8
  %205 = getelementptr inbounds i8, i8* %197, i64 32
  %206 = bitcast i8* %205 to i64*
  store i64 %196, i64* %206, align 8
  %207 = getelementptr inbounds i8, i8* %197, i64 40
  %208 = bitcast i8* %207 to i32*
  store i32 %190, i32* %208, align 8
  %209 = getelementptr inbounds i8, i8* %197, i64 44
  %210 = bitcast i8* %209 to i32*
  store i32 %19, i32* %210, align 4
  %211 = getelementptr inbounds i8, i8* %197, i64 48
  %212 = bitcast i8* %211 to i32*
  store i32 %192, i32* %212, align 8
  %213 = getelementptr inbounds i8, i8* %197, i64 56
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %213, i8* nonnull align 8 %78, i64 80, i1 false) #19
  %214 = getelementptr inbounds i8, i8* %197, i64 136
  %215 = load i64, i64* %144, align 8
  %216 = bitcast i8* %214 to i64*
  store i64 %215, i64* %216, align 8
  %217 = getelementptr inbounds i8, i8* %197, i64 144
  %218 = bitcast i8* %217 to i32*
  %219 = load i32, i32* %14, align 8
  store i32 %219, i32* %218, align 8
  %220 = getelementptr inbounds i8, i8* %197, i64 148
  %221 = bitcast i8* %220 to i32*
  %222 = load i32, i32* %16, align 4
  store i32 %222, i32* %221, align 4
  %223 = getelementptr inbounds i8, i8* %197, i64 152
  %224 = bitcast i8* %223 to i32*
  %225 = load i32, i32* %145, align 8
  store i32 %225, i32* %224, align 8
  %226 = getelementptr inbounds i8, i8* %197, i64 160
  %227 = bitcast i8* %226 to i32*
  store i32 %182, i32* %227, align 8
  %228 = getelementptr inbounds i8, i8* %197, i64 164
  %229 = bitcast i8* %228 to i32*
  store i32 %157, i32* %229, align 4
  %230 = getelementptr inbounds i8, i8* %197, i64 168
  %231 = bitcast i8* %230 to i32*
  store i32 %190, i32* %231, align 8
  %232 = getelementptr inbounds i8, i8* %197, i64 172
  %233 = bitcast i8* %232 to i32*
  store i32 %160, i32* %233, align 4
  %234 = getelementptr inbounds i8, i8* %197, i64 176
  %235 = bitcast i8* %234 to %"class.gemmlowp::VectorDup"**
  store %"class.gemmlowp::VectorDup"* %5, %"class.gemmlowp::VectorDup"** %235, align 8
  %236 = getelementptr inbounds i8, i8* %197, i64 184
  %237 = bitcast i8* %236 to %"class.gemmlowp::VectorDup.194"**
  store %"class.gemmlowp::VectorDup.194"* %6, %"class.gemmlowp::VectorDup.194"** %237, align 8
  %238 = getelementptr inbounds i8, i8* %197, i64 192
  %239 = bitcast i8* %238 to %"struct.gemmlowp::BlockParams"**
  store %"struct.gemmlowp::BlockParams"* %11, %"struct.gemmlowp::BlockParams"** %239, align 8
  %240 = getelementptr inbounds i8, i8* %197, i64 200
  %241 = bitcast i8* %240 to %"class.std::__1::tuple.187"**
  store %"class.std::__1::tuple.187"* %7, %"class.std::__1::tuple.187"** %241, align 8
  %242 = ptrtoint i8* %197 to i64
  %243 = icmp ult %"struct.gemmlowp::Task"** %180, %179
  %244 = ptrtoint %"struct.gemmlowp::Task"** %179 to i64
  br i1 %243, label %245, label %249

245:                                              ; preds = %177
  %246 = bitcast %"struct.gemmlowp::Task"** %180 to i64*
  store i64 %242, i64* %246, align 8
  %247 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %180, i64 1
  %248 = ptrtoint %"struct.gemmlowp::Task"** %247 to i64
  store i64 %248, i64* %146, align 8
  br label %297

249:                                              ; preds = %177
  %250 = ptrtoint %"struct.gemmlowp::Task"** %180 to i64
  %251 = load i64, i64* %147, align 8
  %252 = sub i64 %250, %251
  %253 = ashr exact i64 %252, 3
  %254 = add nsw i64 %253, 1
  %255 = icmp ugt i64 %254, 2305843009213693951
  br i1 %255, label %256, label %258

256:                                              ; preds = %249
  %257 = bitcast %"class.std::__1::vector.205"* %13 to %"class.std::__1::__vector_base_common"*
  call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* nonnull %257) #20
  unreachable

258:                                              ; preds = %249
  %259 = sub i64 %244, %251
  %260 = ashr exact i64 %259, 3
  %261 = icmp ult i64 %260, 1152921504606846975
  br i1 %261, label %262, label %270

262:                                              ; preds = %258
  %263 = ashr exact i64 %259, 2
  %264 = icmp ult i64 %263, %254
  %265 = select i1 %264, i64 %254, i64 %263
  %266 = icmp eq i64 %265, 0
  br i1 %266, label %275, label %267

267:                                              ; preds = %262
  %268 = icmp ugt i64 %265, 2305843009213693951
  br i1 %268, label %269, label %270

269:                                              ; preds = %267
  call void @abort() #20
  unreachable

270:                                              ; preds = %267, %258
  %271 = phi i64 [ %265, %267 ], [ 2305843009213693951, %258 ]
  %272 = shl i64 %271, 3
  %273 = call i8* @_Znwm(i64 %272) #18
  %274 = bitcast i8* %273 to %"struct.gemmlowp::Task"**
  br label %275

275:                                              ; preds = %270, %262
  %276 = phi i64 [ %271, %270 ], [ 0, %262 ]
  %277 = phi %"struct.gemmlowp::Task"** [ %274, %270 ], [ null, %262 ]
  %278 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %277, i64 %253
  %279 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %277, i64 %276
  %280 = ptrtoint %"struct.gemmlowp::Task"** %279 to i64
  %281 = bitcast %"struct.gemmlowp::Task"** %278 to i64*
  store i64 %242, i64* %281, align 8
  %282 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %278, i64 1
  %283 = ptrtoint %"struct.gemmlowp::Task"** %282 to i64
  %284 = sub i64 %178, %251
  %285 = ashr exact i64 %284, 3
  %286 = sub nsw i64 0, %285
  %287 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %278, i64 %286
  %288 = ptrtoint %"struct.gemmlowp::Task"** %287 to i64
  %289 = icmp sgt i64 %284, 0
  br i1 %289, label %290, label %293

290:                                              ; preds = %275
  %291 = bitcast %"struct.gemmlowp::Task"** %287 to i8*
  %292 = inttoptr i64 %251 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %291, i8* align 8 %292, i64 %284, i1 false) #19
  br label %293

293:                                              ; preds = %290, %275
  store i64 %288, i64* %147, align 8
  store i64 %283, i64* %146, align 8
  store i64 %280, i64* %148, align 8
  %294 = icmp eq i64 %251, 0
  br i1 %294, label %297, label %295

295:                                              ; preds = %293
  %296 = inttoptr i64 %251 to i8*
  call void @_ZdlPv(i8* %296) #18
  br label %297

297:                                              ; preds = %245, %293, %295
  %298 = icmp eq i32 %183, %63
  br i1 %298, label %167, label %299

299:                                              ; preds = %297
  %300 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %139, align 8
  %301 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %140, align 8
  %302 = ptrtoint %"struct.gemmlowp::Task"** %300 to i64
  br label %177

303:                                              ; preds = %150, %59
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSV_ISX_XT4_EEEPNSV_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::GemmContext"*, %"struct.gemmlowp::KernelBase"* dereferenceable(8), %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.180"* dereferenceable(24), %"class.gemmlowp::MatrixMap.195"*, %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.std::__1::tuple.187"* dereferenceable(20)) local_unnamed_addr #1 comdat {
  %9 = alloca %"class.gemmlowp::SideMap", align 8
  %10 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %11 = alloca %"struct.gemmlowp::BlockParams", align 4
  %12 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %13 = alloca %"class.std::__1::vector.205", align 8
  %14 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %4, i64 0, i32 1
  %15 = load i32, i32* %14, align 8
  %16 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %4, i64 0, i32 2
  %17 = load i32, i32* %16, align 4
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 2
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %"class.gemmlowp::GemmContext", %"class.gemmlowp::GemmContext"* %0, i64 0, i32 0, i32 0, i32 1
  %21 = load i32, i32* %20, align 4
  switch i32 %21, label %34 [
    i32 1, label %54
    i32 0, label %22
  ]

22:                                               ; preds = %8
  %23 = load atomic i8, i8* bitcast (i64* @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count to i8*) acquire, align 8
  %24 = icmp eq i8 %23, 0
  br i1 %24, label %25, label %32, !prof !514

25:                                               ; preds = %22
  %26 = tail call i32 @__cxa_guard_acquire(i64* nonnull @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count) #19
  %27 = icmp eq i32 %26, 0
  br i1 %27, label %32, label %28

28:                                               ; preds = %25
  %29 = tail call i64 @sysconf(i32 83) #19
  %30 = trunc i64 %29 to i32
  store i32 %30, i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count, align 4
  %31 = tail call {}* @llvm.invariant.start.p0i8(i64 4, i8* bitcast (i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count to i8*)) #19
  tail call void @__cxa_guard_release(i64* nonnull @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count) #19
  br label %32

32:                                               ; preds = %28, %25, %22
  %33 = load i32, i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count, align 4
  br label %34

34:                                               ; preds = %32, %8
  %35 = phi i32 [ %33, %32 ], [ %21, %8 ]
  %36 = add i32 %15, 15
  %37 = sdiv i32 %36, 16
  %38 = icmp slt i32 %37, %35
  %39 = select i1 %38, i32 %37, i32 %35
  %40 = icmp sgt i32 %39, 1
  br i1 %40, label %41, label %56

41:                                               ; preds = %34
  %42 = sext i32 %15 to i64
  %43 = sext i32 %17 to i64
  %44 = mul nsw i64 %43, %42
  %45 = sext i32 %19 to i64
  %46 = mul i64 %44, %45
  %47 = lshr i64 %46, 16
  %48 = trunc i64 %47 to i32
  %49 = icmp sgt i32 %39, %48
  %50 = select i1 %49, i32 %48, i32 %39
  %51 = icmp sgt i32 %50, 1
  br i1 %51, label %52, label %54

52:                                               ; preds = %41
  %53 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br label %61

54:                                               ; preds = %41, %8
  %55 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br label %59

56:                                               ; preds = %34
  %57 = icmp eq i32 %39, 1
  %58 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br i1 %57, label %59, label %61

59:                                               ; preds = %54, %56
  %60 = phi %"class.gemmlowp::SingleThreadGemmContext"* [ %55, %54 ], [ %58, %56 ]
  tail call void @_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSU_ISW_XT4_EEEPNSU_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::SingleThreadGemmContext"* %60, %"struct.gemmlowp::KernelBase"* dereferenceable(8) %1, %"class.gemmlowp::MatrixMap"* dereferenceable(24) %2, %"class.gemmlowp::MatrixMap.180"* dereferenceable(24) %3, %"class.gemmlowp::MatrixMap.195"* %4, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %5, %"class.gemmlowp::VectorDup"* dereferenceable(8) %6, %"class.std::__1::tuple.187"* dereferenceable(20) %7)
  br label %303

61:                                               ; preds = %52, %56
  %62 = phi %"class.gemmlowp::SingleThreadGemmContext"* [ %53, %52 ], [ %58, %56 ]
  %63 = phi i32 [ %50, %52 ], [ %39, %56 ]
  %64 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0
  %65 = getelementptr inbounds %"class.gemmlowp::GemmContext", %"class.gemmlowp::GemmContext"* %0, i64 0, i32 0, i32 1
  %66 = bitcast %"struct.gemmlowp::BlockParams"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %66) #19
  %67 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 1
  %68 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 2
  %69 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 4
  %70 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 5
  %71 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 1
  %72 = bitcast %"struct.gemmlowp::BlockParams"* %11 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %72, i8 -86, i64 24, i1 false)
  %73 = load i32, i32* %71, align 8
  %74 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 2
  %75 = load i32, i32* %74, align 4
  %76 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 3
  %77 = load float, float* %76, align 8
  call void @_ZN8gemmlowp11BlockParams4InitINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES7_EEEEviiiiiif(%"struct.gemmlowp::BlockParams"* nonnull %11, i32 %15, i32 %17, i32 %19, i32 %63, i32 %73, i32 %75, float %77)
  %78 = bitcast %"class.gemmlowp::PackedSideBlock"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %78) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %78, i8 -86, i64 80, i1 false)
  %79 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %64, %"class.gemmlowp::Allocator"** %79, align 8
  %80 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 4
  store i32 0, i32* %80, align 8
  %81 = load i32, i32* %67, align 4
  %82 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 0
  store i32 %81, i32* %82, align 8
  %83 = load i32, i32* %69, align 4
  %84 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 2
  store i32 %83, i32* %84, align 8
  %85 = load i32, i32* %68, align 4
  %86 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 1
  store i32 %85, i32* %86, align 4
  %87 = load i32, i32* %70, align 4
  %88 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 3
  store i32 %87, i32* %88, align 4
  %89 = mul nsw i32 %87, %83
  %90 = sext i32 %89 to i64
  %91 = add nsw i64 %90, 63
  %92 = and i64 %91, -64
  %93 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 4
  %94 = load i64, i64* %93, align 8, !noalias !918
  %95 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 3
  %96 = load i64, i64* %95, align 8, !noalias !918
  %97 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 5, i64 %96
  store i64 %94, i64* %97, align 8, !noalias !918
  %98 = trunc i64 %96 to i8
  %99 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 6
  %100 = load i64, i64* %99, align 8, !noalias !918
  %101 = load i64, i64* %95, align 8, !noalias !918
  %102 = add i64 %101, 1
  store i64 %102, i64* %95, align 8, !noalias !918
  %103 = load i64, i64* %93, align 8, !noalias !918
  %104 = add i64 %103, %92
  store i64 %104, i64* %93, align 8, !noalias !918
  %105 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 0
  store i8 %98, i8* %105, align 8
  %106 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %106, i8 -86, i64 7, i1 false) #19
  %107 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 2
  store i64 %100, i64* %107, align 8
  %108 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 3
  store i8 0, i8* %108, align 8
  %109 = sext i32 %83 to i64
  %110 = shl nsw i64 %109, 2
  %111 = add nsw i64 %110, 63
  %112 = and i64 %111, -64
  %113 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 5, i64 %102
  store i64 %104, i64* %113, align 8, !noalias !921
  %114 = trunc i64 %102 to i8
  %115 = load i64, i64* %99, align 8, !noalias !921
  %116 = bitcast i64* %95 to <2 x i64>*
  %117 = load <2 x i64>, <2 x i64>* %116, align 8, !noalias !921
  %118 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %112, i32 1
  %119 = add <2 x i64> %117, %118
  %120 = bitcast i64* %95 to <2 x i64>*
  store <2 x i64> %119, <2 x i64>* %120, align 8, !noalias !921
  %121 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 0
  store i8 %114, i8* %121, align 8
  %122 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %122, i8 -86, i64 7, i1 false) #19
  %123 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 2
  store i64 %115, i64* %123, align 8
  %124 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 3
  store i8 5, i8* %124, align 8
  call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %64)
  %125 = icmp sgt i32 %17, 0
  br i1 %125, label %126, label %150

126:                                              ; preds = %61
  %127 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 0
  %128 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 3
  %129 = bitcast %"class.gemmlowp::SideMap"* %9 to i8*
  %130 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 1
  %131 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 2
  %132 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 3
  %133 = bitcast %"class.gemmlowp::SideMap"* %9 to i64*
  %134 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %10 to i8*
  %135 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 0
  %136 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 1
  %137 = bitcast %"class.std::__1::vector.205"* %13 to i8*
  %138 = getelementptr inbounds %"class.std::__1::vector.205", %"class.std::__1::vector.205"* %13, i64 0, i32 0, i32 0
  %139 = getelementptr inbounds %"class.std::__1::vector.205", %"class.std::__1::vector.205"* %13, i64 0, i32 0, i32 1
  %140 = getelementptr inbounds %"class.std::__1::vector.205", %"class.std::__1::vector.205"* %13, i64 0, i32 0, i32 2, i32 0, i32 0
  %141 = icmp sgt i32 %63, 0
  %142 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 0
  %143 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 3
  %144 = bitcast %"class.gemmlowp::MatrixMap.195"* %4 to i64*
  %145 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %4, i64 0, i32 3
  %146 = bitcast %"struct.gemmlowp::Task"*** %139 to i64*
  %147 = bitcast %"class.std::__1::vector.205"* %13 to i64*
  %148 = bitcast %"struct.gemmlowp::Task"*** %140 to i64*
  %149 = load i32, i32* %69, align 4
  br label %155

150:                                              ; preds = %173, %61
  %151 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 0
  store i8 0, i8* %151, align 8
  %152 = load i64, i64* %99, align 8
  %153 = add i64 %152, 1
  store i64 %153, i64* %99, align 8
  %154 = bitcast i64* %95 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %154, i8 0, i64 16, i1 false) #19
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %78) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %66) #19
  br label %303

155:                                              ; preds = %126, %173
  %156 = phi i32 [ %149, %126 ], [ %174, %173 ]
  %157 = phi i32 [ 0, %126 ], [ %175, %173 ]
  %158 = sub nsw i32 %17, %157
  %159 = icmp slt i32 %158, %156
  %160 = select i1 %159, i32 %158, i32 %156
  %161 = load i8*, i8** %127, align 8, !noalias !924
  %162 = load i32, i32* %128, align 8, !noalias !924
  %163 = mul nsw i32 %162, %157
  %164 = sext i32 %163 to i64
  %165 = getelementptr inbounds i8, i8* %161, i64 %164
  %166 = ptrtoint i8* %165 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %129) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %129, i8 -86, i64 24, i1 false) #19
  store i64 %166, i64* %133, align 8
  store i32 %160, i32* %130, align 8
  store i32 %19, i32* %131, align 4
  store i32 %162, i32* %132, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %134) #19
  store %"class.gemmlowp::PackedSideBlock"* %12, %"class.gemmlowp::PackedSideBlock"** %135, align 8
  store %"class.gemmlowp::SideMap"* %9, %"class.gemmlowp::SideMap"** %136, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %10) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %134) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %129) #19
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %137) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %137, i8 0, i64 24, i1 false) #19
  br i1 %141, label %177, label %167

167:                                              ; preds = %297, %155
  call void @_ZN8gemmlowp11WorkersPool28LegacyExecuteAndDestroyTasksERKNSt3__16vectorIPNS_4TaskENS1_9allocatorIS4_EEEE(%"class.gemmlowp::WorkersPool"* %65, %"class.std::__1::vector.205"* nonnull dereferenceable(24) %13) #19
  %168 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %138, align 8
  %169 = icmp eq %"struct.gemmlowp::Task"** %168, null
  br i1 %169, label %173, label %170

170:                                              ; preds = %167
  %171 = ptrtoint %"struct.gemmlowp::Task"** %168 to i64
  store i64 %171, i64* %146, align 8
  %172 = bitcast %"struct.gemmlowp::Task"** %168 to i8*
  call void @_ZdlPv(i8* %172) #18
  br label %173

173:                                              ; preds = %167, %170
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %137) #19
  %174 = load i32, i32* %69, align 4
  %175 = add nsw i32 %174, %157
  %176 = icmp sgt i32 %17, %175
  br i1 %176, label %155, label %150

177:                                              ; preds = %155, %299
  %178 = phi i64 [ %302, %299 ], [ 0, %155 ]
  %179 = phi %"struct.gemmlowp::Task"** [ %301, %299 ], [ null, %155 ]
  %180 = phi %"struct.gemmlowp::Task"** [ %300, %299 ], [ null, %155 ]
  %181 = phi i32 [ %183, %299 ], [ 0, %155 ]
  %182 = phi i32 [ %189, %299 ], [ 0, %155 ]
  %183 = add nuw nsw i32 %181, 1
  %184 = mul nsw i32 %183, %15
  %185 = sdiv i32 %184, %63
  %186 = add i32 %185, 3
  %187 = and i32 %186, -4
  %188 = icmp slt i32 %187, %15
  %189 = select i1 %188, i32 %187, i32 %15
  %190 = sub nsw i32 %189, %182
  %191 = load i8*, i8** %142, align 8, !noalias !927
  %192 = load i32, i32* %143, align 8, !noalias !927
  %193 = mul nsw i32 %192, %182
  %194 = sext i32 %193 to i64
  %195 = getelementptr inbounds i8, i8* %191, i64 %194
  %196 = ptrtoint i8* %195 to i64
  %197 = call i8* @_Znwm(i64 208) #18
  %198 = bitcast i8* %197 to i32 (...)***
  %199 = getelementptr inbounds i8, i8* %197, i64 8
  %200 = bitcast i8* %199 to %"class.gemmlowp::Allocator"**
  store %"class.gemmlowp::Allocator"* null, %"class.gemmlowp::Allocator"** %200, align 8
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %198, align 8
  %201 = getelementptr inbounds i8, i8* %197, i64 16
  %202 = bitcast i8* %201 to %"class.gemmlowp::GemmContext"**
  store %"class.gemmlowp::GemmContext"* %0, %"class.gemmlowp::GemmContext"** %202, align 8
  %203 = getelementptr inbounds i8, i8* %197, i64 24
  %204 = bitcast i8* %203 to %"struct.gemmlowp::KernelBase"**
  store %"struct.gemmlowp::KernelBase"* %1, %"struct.gemmlowp::KernelBase"** %204, align 8
  %205 = getelementptr inbounds i8, i8* %197, i64 32
  %206 = bitcast i8* %205 to i64*
  store i64 %196, i64* %206, align 8
  %207 = getelementptr inbounds i8, i8* %197, i64 40
  %208 = bitcast i8* %207 to i32*
  store i32 %190, i32* %208, align 8
  %209 = getelementptr inbounds i8, i8* %197, i64 44
  %210 = bitcast i8* %209 to i32*
  store i32 %19, i32* %210, align 4
  %211 = getelementptr inbounds i8, i8* %197, i64 48
  %212 = bitcast i8* %211 to i32*
  store i32 %192, i32* %212, align 8
  %213 = getelementptr inbounds i8, i8* %197, i64 56
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %213, i8* nonnull align 8 %78, i64 80, i1 false) #19
  %214 = getelementptr inbounds i8, i8* %197, i64 136
  %215 = load i64, i64* %144, align 8
  %216 = bitcast i8* %214 to i64*
  store i64 %215, i64* %216, align 8
  %217 = getelementptr inbounds i8, i8* %197, i64 144
  %218 = bitcast i8* %217 to i32*
  %219 = load i32, i32* %14, align 8
  store i32 %219, i32* %218, align 8
  %220 = getelementptr inbounds i8, i8* %197, i64 148
  %221 = bitcast i8* %220 to i32*
  %222 = load i32, i32* %16, align 4
  store i32 %222, i32* %221, align 4
  %223 = getelementptr inbounds i8, i8* %197, i64 152
  %224 = bitcast i8* %223 to i32*
  %225 = load i32, i32* %145, align 8
  store i32 %225, i32* %224, align 8
  %226 = getelementptr inbounds i8, i8* %197, i64 160
  %227 = bitcast i8* %226 to i32*
  store i32 %182, i32* %227, align 8
  %228 = getelementptr inbounds i8, i8* %197, i64 164
  %229 = bitcast i8* %228 to i32*
  store i32 %157, i32* %229, align 4
  %230 = getelementptr inbounds i8, i8* %197, i64 168
  %231 = bitcast i8* %230 to i32*
  store i32 %190, i32* %231, align 8
  %232 = getelementptr inbounds i8, i8* %197, i64 172
  %233 = bitcast i8* %232 to i32*
  store i32 %160, i32* %233, align 4
  %234 = getelementptr inbounds i8, i8* %197, i64 176
  %235 = bitcast i8* %234 to %"class.gemmlowp::VectorDup.194"**
  store %"class.gemmlowp::VectorDup.194"* %5, %"class.gemmlowp::VectorDup.194"** %235, align 8
  %236 = getelementptr inbounds i8, i8* %197, i64 184
  %237 = bitcast i8* %236 to %"class.gemmlowp::VectorDup"**
  store %"class.gemmlowp::VectorDup"* %6, %"class.gemmlowp::VectorDup"** %237, align 8
  %238 = getelementptr inbounds i8, i8* %197, i64 192
  %239 = bitcast i8* %238 to %"struct.gemmlowp::BlockParams"**
  store %"struct.gemmlowp::BlockParams"* %11, %"struct.gemmlowp::BlockParams"** %239, align 8
  %240 = getelementptr inbounds i8, i8* %197, i64 200
  %241 = bitcast i8* %240 to %"class.std::__1::tuple.187"**
  store %"class.std::__1::tuple.187"* %7, %"class.std::__1::tuple.187"** %241, align 8
  %242 = ptrtoint i8* %197 to i64
  %243 = icmp ult %"struct.gemmlowp::Task"** %180, %179
  %244 = ptrtoint %"struct.gemmlowp::Task"** %179 to i64
  br i1 %243, label %245, label %249

245:                                              ; preds = %177
  %246 = bitcast %"struct.gemmlowp::Task"** %180 to i64*
  store i64 %242, i64* %246, align 8
  %247 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %180, i64 1
  %248 = ptrtoint %"struct.gemmlowp::Task"** %247 to i64
  store i64 %248, i64* %146, align 8
  br label %297

249:                                              ; preds = %177
  %250 = ptrtoint %"struct.gemmlowp::Task"** %180 to i64
  %251 = load i64, i64* %147, align 8
  %252 = sub i64 %250, %251
  %253 = ashr exact i64 %252, 3
  %254 = add nsw i64 %253, 1
  %255 = icmp ugt i64 %254, 2305843009213693951
  br i1 %255, label %256, label %258

256:                                              ; preds = %249
  %257 = bitcast %"class.std::__1::vector.205"* %13 to %"class.std::__1::__vector_base_common"*
  call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* nonnull %257) #20
  unreachable

258:                                              ; preds = %249
  %259 = sub i64 %244, %251
  %260 = ashr exact i64 %259, 3
  %261 = icmp ult i64 %260, 1152921504606846975
  br i1 %261, label %262, label %270

262:                                              ; preds = %258
  %263 = ashr exact i64 %259, 2
  %264 = icmp ult i64 %263, %254
  %265 = select i1 %264, i64 %254, i64 %263
  %266 = icmp eq i64 %265, 0
  br i1 %266, label %275, label %267

267:                                              ; preds = %262
  %268 = icmp ugt i64 %265, 2305843009213693951
  br i1 %268, label %269, label %270

269:                                              ; preds = %267
  call void @abort() #20
  unreachable

270:                                              ; preds = %267, %258
  %271 = phi i64 [ %265, %267 ], [ 2305843009213693951, %258 ]
  %272 = shl i64 %271, 3
  %273 = call i8* @_Znwm(i64 %272) #18
  %274 = bitcast i8* %273 to %"struct.gemmlowp::Task"**
  br label %275

275:                                              ; preds = %270, %262
  %276 = phi i64 [ %271, %270 ], [ 0, %262 ]
  %277 = phi %"struct.gemmlowp::Task"** [ %274, %270 ], [ null, %262 ]
  %278 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %277, i64 %253
  %279 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %277, i64 %276
  %280 = ptrtoint %"struct.gemmlowp::Task"** %279 to i64
  %281 = bitcast %"struct.gemmlowp::Task"** %278 to i64*
  store i64 %242, i64* %281, align 8
  %282 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %278, i64 1
  %283 = ptrtoint %"struct.gemmlowp::Task"** %282 to i64
  %284 = sub i64 %178, %251
  %285 = ashr exact i64 %284, 3
  %286 = sub nsw i64 0, %285
  %287 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %278, i64 %286
  %288 = ptrtoint %"struct.gemmlowp::Task"** %287 to i64
  %289 = icmp sgt i64 %284, 0
  br i1 %289, label %290, label %293

290:                                              ; preds = %275
  %291 = bitcast %"struct.gemmlowp::Task"** %287 to i8*
  %292 = inttoptr i64 %251 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %291, i8* align 8 %292, i64 %284, i1 false) #19
  br label %293

293:                                              ; preds = %290, %275
  store i64 %288, i64* %147, align 8
  store i64 %283, i64* %146, align 8
  store i64 %280, i64* %148, align 8
  %294 = icmp eq i64 %251, 0
  br i1 %294, label %297, label %295

295:                                              ; preds = %293
  %296 = inttoptr i64 %251 to i8*
  call void @_ZdlPv(i8* %296) #18
  br label %297

297:                                              ; preds = %245, %293, %295
  %298 = icmp eq i32 %183, %63
  br i1 %298, label %167, label %299

299:                                              ; preds = %297
  %300 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %139, align 8
  %301 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %140, align 8
  %302 = ptrtoint %"struct.gemmlowp::Task"** %300 to i64
  br label %177

303:                                              ; preds = %150, %59
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSU_ISW_XT4_EEEPNSU_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::SingleThreadGemmContext"*, %"struct.gemmlowp::KernelBase"* dereferenceable(8), %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.180"* dereferenceable(24), %"class.gemmlowp::MatrixMap.195"*, %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.std::__1::tuple.187"* dereferenceable(20)) local_unnamed_addr #1 comdat {
  %9 = alloca %"class.gemmlowp::SideMap", align 8
  %10 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %11 = alloca %"class.gemmlowp::SideMap", align 8
  %12 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %13 = alloca %"class.gemmlowp::SideMap", align 8
  %14 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %15 = alloca %"class.gemmlowp::ComputeImpl", align 8
  %16 = alloca %"struct.gemmlowp::BlockParams", align 4
  %17 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %18 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %19 = alloca %"class.gemmlowp::PackedResult", align 8
  %20 = alloca %"struct.gemmlowp::MatrixBlockBounds", align 4
  %21 = alloca %"class.gemmlowp::VectorDup.194", align 4
  %22 = alloca %"class.gemmlowp::VectorDup", align 4
  %23 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %4, i64 0, i32 1
  %24 = load i32, i32* %23, align 8
  %25 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %4, i64 0, i32 2
  %26 = load i32, i32* %25, align 4
  %27 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 2
  %28 = load i32, i32* %27, align 4
  %29 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0
  %30 = bitcast %"struct.gemmlowp::BlockParams"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %30) #19
  %31 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 0
  %32 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 1
  %33 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 2
  %34 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 3
  %35 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 4
  %36 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 5
  %37 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 1
  %38 = bitcast %"struct.gemmlowp::BlockParams"* %16 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %38, i8 -86, i64 24, i1 false)
  %39 = load i32, i32* %37, align 8
  %40 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 2
  %41 = load i32, i32* %40, align 4
  %42 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 3
  %43 = load float, float* %42, align 8
  call void @_ZN8gemmlowp11BlockParams4InitINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES7_EEEEviiiiiif(%"struct.gemmlowp::BlockParams"* nonnull %16, i32 %24, i32 %26, i32 %28, i32 1, i32 %39, i32 %41, float %43)
  %44 = bitcast %"class.gemmlowp::PackedSideBlock"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %44) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %44, i8 -86, i64 80, i1 false)
  %45 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %45, align 8
  %46 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 4
  store i32 0, i32* %46, align 8
  %47 = load i32, i32* %31, align 4
  %48 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 0
  store i32 %47, i32* %48, align 8
  %49 = load i32, i32* %34, align 4
  %50 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 2
  store i32 %49, i32* %50, align 8
  %51 = load i32, i32* %33, align 4
  %52 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 1
  store i32 %51, i32* %52, align 4
  %53 = load i32, i32* %36, align 4
  %54 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 3
  store i32 %53, i32* %54, align 4
  %55 = mul nsw i32 %53, %49
  %56 = sext i32 %55 to i64
  %57 = add nsw i64 %56, 63
  %58 = and i64 %57, -64
  %59 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 4
  %60 = load i64, i64* %59, align 8, !noalias !930
  %61 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 3
  %62 = load i64, i64* %61, align 8, !noalias !930
  %63 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %62
  store i64 %60, i64* %63, align 8, !noalias !930
  %64 = trunc i64 %62 to i8
  %65 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 6
  %66 = load i64, i64* %65, align 8, !noalias !930
  %67 = load i64, i64* %61, align 8, !noalias !930
  %68 = add i64 %67, 1
  store i64 %68, i64* %61, align 8, !noalias !930
  %69 = load i64, i64* %59, align 8, !noalias !930
  %70 = add i64 %69, %58
  store i64 %70, i64* %59, align 8, !noalias !930
  %71 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 0
  store i8 %64, i8* %71, align 8
  %72 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %72, i8 -86, i64 7, i1 false) #19
  %73 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 2
  store i64 %66, i64* %73, align 8
  %74 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 3
  store i8 0, i8* %74, align 8
  %75 = sext i32 %49 to i64
  %76 = shl nsw i64 %75, 2
  %77 = add nsw i64 %76, 63
  %78 = and i64 %77, -64
  %79 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %68
  store i64 %70, i64* %79, align 8, !noalias !933
  %80 = trunc i64 %68 to i8
  %81 = load i64, i64* %65, align 8, !noalias !933
  %82 = load i64, i64* %61, align 8, !noalias !933
  %83 = add i64 %82, 1
  store i64 %83, i64* %61, align 8, !noalias !933
  %84 = load i64, i64* %59, align 8, !noalias !933
  %85 = add i64 %84, %78
  store i64 %85, i64* %59, align 8, !noalias !933
  %86 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 0
  store i8 %80, i8* %86, align 8
  %87 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %87, i8 -86, i64 7, i1 false) #19
  %88 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 2
  store i64 %81, i64* %88, align 8
  %89 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 3
  store i8 5, i8* %89, align 8
  %90 = bitcast %"class.gemmlowp::PackedSideBlock"* %18 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %90) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %90, i8 -86, i64 80, i1 false)
  %91 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %91, align 8
  %92 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 4
  store i32 0, i32* %92, align 8
  %93 = load i32, i32* %32, align 4
  %94 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 0
  store i32 %93, i32* %94, align 8
  %95 = load i32, i32* %35, align 4
  %96 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 2
  store i32 %95, i32* %96, align 8
  %97 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 1
  store i32 %51, i32* %97, align 4
  %98 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 3
  store i32 %53, i32* %98, align 4
  %99 = mul nsw i32 %53, %95
  %100 = sext i32 %99 to i64
  %101 = add nsw i64 %100, 63
  %102 = and i64 %101, -64
  %103 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %83
  store i64 %85, i64* %103, align 8, !noalias !936
  %104 = trunc i64 %83 to i8
  %105 = load i64, i64* %65, align 8, !noalias !936
  %106 = load i64, i64* %61, align 8, !noalias !936
  %107 = add i64 %106, 1
  store i64 %107, i64* %61, align 8, !noalias !936
  %108 = load i64, i64* %59, align 8, !noalias !936
  %109 = add i64 %108, %102
  store i64 %109, i64* %59, align 8, !noalias !936
  %110 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 0
  store i8 %104, i8* %110, align 8
  %111 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %111, i8 -86, i64 7, i1 false) #19
  %112 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 2
  store i64 %105, i64* %112, align 8
  %113 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 3
  store i8 0, i8* %113, align 8
  %114 = sext i32 %95 to i64
  %115 = shl nsw i64 %114, 2
  %116 = add nsw i64 %115, 63
  %117 = and i64 %116, -64
  %118 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %107
  store i64 %109, i64* %118, align 8, !noalias !939
  %119 = trunc i64 %107 to i8
  %120 = load i64, i64* %65, align 8, !noalias !939
  %121 = load i64, i64* %61, align 8, !noalias !939
  %122 = add i64 %121, 1
  store i64 %122, i64* %61, align 8, !noalias !939
  %123 = load i64, i64* %59, align 8, !noalias !939
  %124 = add i64 %123, %117
  store i64 %124, i64* %59, align 8, !noalias !939
  %125 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 0
  store i8 %119, i8* %125, align 8
  %126 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %126, i8 -86, i64 7, i1 false) #19
  %127 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 2
  store i64 %120, i64* %127, align 8
  %128 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 3
  store i8 5, i8* %128, align 8
  %129 = bitcast %"class.gemmlowp::PackedResult"* %19 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %129) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %129, i8 -86, i64 32, i1 false)
  %130 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 0
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %130, align 8
  %131 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 2
  store %"struct.gemmlowp::BlockParams"* %16, %"struct.gemmlowp::BlockParams"** %131, align 8
  %132 = load i32, i32* %34, align 4
  %133 = mul nsw i32 %95, %132
  %134 = sext i32 %133 to i64
  %135 = shl nsw i64 %134, 2
  %136 = add nsw i64 %135, 63
  %137 = and i64 %136, -64
  %138 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %122
  store i64 %124, i64* %138, align 8, !noalias !942
  %139 = trunc i64 %122 to i8
  %140 = load i64, i64* %65, align 8, !noalias !942
  %141 = bitcast i64* %61 to <2 x i64>*
  %142 = load <2 x i64>, <2 x i64>* %141, align 8, !noalias !942
  %143 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %137, i32 1
  %144 = add <2 x i64> %142, %143
  %145 = bitcast i64* %61 to <2 x i64>*
  store <2 x i64> %144, <2 x i64>* %145, align 8, !noalias !942
  %146 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 0
  store i8 %139, i8* %146, align 8
  %147 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %147, i8 -86, i64 7, i1 false) #19
  %148 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 2
  store i64 %140, i64* %148, align 8
  %149 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 3
  store i8 5, i8* %149, align 8
  call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %29)
  %150 = load i32, i32* %35, align 4
  %151 = icmp sge i32 %150, %26
  br i1 %151, label %152, label %169

152:                                              ; preds = %8
  %153 = bitcast %"class.gemmlowp::SideMap"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %153) #19
  %154 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 1
  %155 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 2
  %156 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 3
  %157 = bitcast %"class.gemmlowp::MatrixMap.180"* %3 to i64*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %153, i8 -86, i64 24, i1 false) #19
  %158 = load i64, i64* %157, align 8
  %159 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 2
  %160 = load i32, i32* %159, align 4
  %161 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 1
  %162 = load i32, i32* %161, align 8
  %163 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 3
  %164 = load i32, i32* %163, align 8
  %165 = bitcast %"class.gemmlowp::SideMap"* %9 to i64*
  store i64 %158, i64* %165, align 8
  store i32 %160, i32* %154, align 8
  store i32 %162, i32* %155, align 4
  store i32 %164, i32* %156, align 8
  %166 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %166) #19
  %167 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 0
  %168 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 1
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %167, align 8
  store %"class.gemmlowp::SideMap"* %9, %"class.gemmlowp::SideMap"** %168, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %10) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %166) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %153) #19
  br label %169

169:                                              ; preds = %152, %8
  %170 = icmp sgt i32 %24, 0
  br i1 %170, label %171, label %216

171:                                              ; preds = %169
  %172 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 0
  %173 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 3
  %174 = bitcast %"class.gemmlowp::SideMap"* %11 to i8*
  %175 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 1
  %176 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 2
  %177 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 3
  %178 = bitcast %"class.gemmlowp::SideMap"* %11 to i64*
  %179 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %12 to i8*
  %180 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %12, i64 0, i32 0
  %181 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %12, i64 0, i32 1
  %182 = icmp sgt i32 %26, 0
  %183 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 0
  %184 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 3
  %185 = bitcast %"class.gemmlowp::SideMap"* %13 to i8*
  %186 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 1
  %187 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 2
  %188 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 3
  %189 = bitcast %"class.gemmlowp::SideMap"* %13 to i64*
  %190 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %14 to i8*
  %191 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %14, i64 0, i32 0
  %192 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %14, i64 0, i32 1
  %193 = bitcast %"class.gemmlowp::ComputeImpl"* %15 to i8*
  %194 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 0
  %195 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 1
  %196 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 2
  %197 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 3
  %198 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 4
  %199 = add i32 %28, 15
  %200 = and i32 %199, -16
  %201 = icmp sgt i32 %200, 0
  %202 = bitcast %"struct.gemmlowp::MatrixBlockBounds"* %20 to i8*
  %203 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 0
  %204 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 1
  %205 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 2
  %206 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 3
  %207 = bitcast %"class.gemmlowp::VectorDup.194"* %21 to i8*
  %208 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 0
  %209 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %21, i64 0, i32 0
  %210 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %21, i64 0, i32 1
  %211 = bitcast %"class.gemmlowp::VectorDup"* %22 to i8*
  %212 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %213 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %22, i64 0, i32 0
  %214 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %22, i64 0, i32 1
  %215 = load i32, i32* %34, align 4
  br label %221

216:                                              ; preds = %235, %169
  %217 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 0
  store i8 0, i8* %217, align 8
  %218 = load i64, i64* %65, align 8
  %219 = add i64 %218, 1
  store i64 %219, i64* %65, align 8
  %220 = bitcast i64* %61 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %220, i8 0, i64 16, i1 false) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %129) #19
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %90) #19
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %44) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %30) #19
  ret void

221:                                              ; preds = %171, %235
  %222 = phi i32 [ %215, %171 ], [ %236, %235 ]
  %223 = phi i32 [ 0, %171 ], [ %237, %235 ]
  %224 = sub nsw i32 %24, %223
  %225 = icmp slt i32 %224, %222
  %226 = select i1 %225, i32 %224, i32 %222
  %227 = load i8*, i8** %172, align 8, !noalias !945
  %228 = load i32, i32* %173, align 8, !noalias !945
  %229 = mul nsw i32 %228, %223
  %230 = sext i32 %229 to i64
  %231 = getelementptr inbounds i8, i8* %227, i64 %230
  %232 = ptrtoint i8* %231 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %174) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %174, i8 -86, i64 24, i1 false) #19
  store i64 %232, i64* %178, align 8
  store i32 %226, i32* %175, align 8
  store i32 %28, i32* %176, align 4
  store i32 %228, i32* %177, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %179) #19
  store %"class.gemmlowp::PackedSideBlock"* %17, %"class.gemmlowp::PackedSideBlock"** %180, align 8
  store %"class.gemmlowp::SideMap"* %11, %"class.gemmlowp::SideMap"** %181, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %12) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %179) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %174) #19
  br i1 %182, label %233, label %235

233:                                              ; preds = %221
  %234 = load i32, i32* %35, align 4
  br label %239

235:                                              ; preds = %311, %221
  %236 = load i32, i32* %34, align 4
  %237 = add nsw i32 %236, %223
  %238 = icmp sgt i32 %24, %237
  br i1 %238, label %221, label %216

239:                                              ; preds = %233, %311
  %240 = phi i32 [ %334, %311 ], [ %234, %233 ]
  %241 = phi i32 [ %335, %311 ], [ 0, %233 ]
  %242 = sub nsw i32 %26, %241
  %243 = icmp slt i32 %242, %240
  %244 = select i1 %243, i32 %242, i32 %240
  br i1 %151, label %252, label %245

245:                                              ; preds = %239
  %246 = load i8*, i8** %183, align 8, !noalias !948
  %247 = load i32, i32* %184, align 8, !noalias !948
  %248 = mul nsw i32 %247, %241
  %249 = sext i32 %248 to i64
  %250 = getelementptr inbounds i8, i8* %246, i64 %249
  %251 = ptrtoint i8* %250 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %185) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %185, i8 -86, i64 24, i1 false) #19
  store i64 %251, i64* %189, align 8
  store i32 %244, i32* %186, align 8
  store i32 %28, i32* %187, align 4
  store i32 %247, i32* %188, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %190) #19
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %191, align 8
  store %"class.gemmlowp::SideMap"* %13, %"class.gemmlowp::SideMap"** %192, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %14) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %190) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %185) #19
  br label %252

252:                                              ; preds = %245, %239
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %193) #19
  store %"struct.gemmlowp::KernelBase"* %1, %"struct.gemmlowp::KernelBase"** %194, align 8
  store %"struct.gemmlowp::BlockParams"* %16, %"struct.gemmlowp::BlockParams"** %195, align 8
  store %"class.gemmlowp::PackedResult"* %19, %"class.gemmlowp::PackedResult"** %196, align 8
  store %"class.gemmlowp::PackedSideBlock"* %17, %"class.gemmlowp::PackedSideBlock"** %197, align 8
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %198, align 8
  br i1 %201, label %253, label %311

253:                                              ; preds = %252, %271
  %254 = phi %"struct.gemmlowp::BlockParams"* [ %273, %271 ], [ %16, %252 ]
  %255 = phi %"struct.gemmlowp::BlockParams"* [ %274, %271 ], [ %16, %252 ]
  %256 = phi i32 [ %275, %271 ], [ 0, %252 ]
  %257 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 2
  %258 = sub nsw i32 %200, %256
  %259 = load i32, i32* %257, align 4
  %260 = icmp slt i32 %258, %259
  %261 = select i1 %260, i32 %258, i32 %259
  %262 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 3
  %263 = load i32, i32* %262, align 4
  %264 = icmp sgt i32 %263, 0
  br i1 %264, label %265, label %271

265:                                              ; preds = %253
  %266 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 0
  %267 = load i32, i32* %266, align 4
  br label %277

268:                                              ; preds = %303
  %269 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 2
  %270 = load i32, i32* %269, align 4
  br label %271

271:                                              ; preds = %268, %253
  %272 = phi i32 [ %259, %253 ], [ %270, %268 ]
  %273 = phi %"struct.gemmlowp::BlockParams"* [ %254, %253 ], [ %304, %268 ]
  %274 = phi %"struct.gemmlowp::BlockParams"* [ %255, %253 ], [ %304, %268 ]
  %275 = add nsw i32 %272, %256
  %276 = icmp sgt i32 %200, %275
  br i1 %276, label %253, label %311

277:                                              ; preds = %303, %265
  %278 = phi %"struct.gemmlowp::BlockParams"* [ %304, %303 ], [ %254, %265 ]
  %279 = phi i32 [ %306, %303 ], [ %267, %265 ]
  %280 = phi i32 [ %309, %303 ], [ %263, %265 ]
  %281 = phi %"struct.gemmlowp::BlockParams"* [ %304, %303 ], [ %255, %265 ]
  %282 = phi i32 [ %307, %303 ], [ 0, %265 ]
  %283 = sub nsw i32 %280, %282
  %284 = icmp slt i32 %283, %279
  %285 = select i1 %284, i32 %283, i32 %279
  %286 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %281, i64 0, i32 4
  %287 = load i32, i32* %286, align 4
  %288 = icmp sgt i32 %287, 0
  br i1 %288, label %289, label %303

289:                                              ; preds = %277
  %290 = icmp sgt i32 %285, 0
  br label %291

291:                                              ; preds = %293, %289
  %292 = phi i32 [ 0, %289 ], [ %294, %293 ]
  br i1 %290, label %296, label %293

293:                                              ; preds = %296, %291
  %294 = add nuw nsw i32 %292, 4
  %295 = icmp slt i32 %294, %287
  br i1 %295, label %291, label %301

296:                                              ; preds = %291, %296
  %297 = phi i32 [ %299, %296 ], [ 0, %291 ]
  %298 = add nsw i32 %297, %282
  call void @_ZN8gemmlowp11ComputeImplINS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEES7_NS_12PackedResultEE10ComputeRunEiiii(%"class.gemmlowp::ComputeImpl"* nonnull %15, i32 %298, i32 %292, i32 %256, i32 %261) #19
  %299 = add nuw nsw i32 %297, 4
  %300 = icmp slt i32 %299, %285
  br i1 %300, label %296, label %293

301:                                              ; preds = %293
  %302 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %195, align 8
  br label %303

303:                                              ; preds = %301, %277
  %304 = phi %"struct.gemmlowp::BlockParams"* [ %302, %301 ], [ %278, %277 ]
  %305 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 0
  %306 = load i32, i32* %305, align 4
  %307 = add nsw i32 %306, %282
  %308 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 3
  %309 = load i32, i32* %308, align 4
  %310 = icmp sgt i32 %309, %307
  br i1 %310, label %277, label %268

311:                                              ; preds = %271, %252
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %193) #19
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %202) #19
  store i32 %223, i32* %203, align 4
  store i32 %241, i32* %204, align 4
  store i32 %226, i32* %205, align 4
  store i32 %244, i32* %206, align 4
  %312 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %45, align 8
  %313 = load i8, i8* %86, align 8
  %314 = zext i8 %313 to i64
  %315 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %312, i64 0, i32 5, i64 %314
  %316 = load i64, i64* %315, align 8
  %317 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %312, i64 0, i32 2
  %318 = bitcast i8** %317 to i64*
  %319 = load i64, i64* %318, align 8
  %320 = add i64 %319, %316
  %321 = inttoptr i64 %320 to i32*
  %322 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %91, align 8
  %323 = load i8, i8* %125, align 8
  %324 = zext i8 %323 to i64
  %325 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %322, i64 0, i32 5, i64 %324
  %326 = load i64, i64* %325, align 8
  %327 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %322, i64 0, i32 2
  %328 = bitcast i8** %327 to i64*
  %329 = load i64, i64* %328, align 8
  %330 = add i64 %329, %326
  %331 = inttoptr i64 %330 to i32*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %207) #19
  %332 = load i32, i32* %208, align 4, !noalias !951
  store i32 %332, i32* %209, align 4, !alias.scope !951
  store i32 %226, i32* %210, align 4, !alias.scope !951
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %211) #19
  %333 = load i32, i32* %212, align 4, !noalias !954
  store i32 %333, i32* %213, align 4, !alias.scope !954
  store i32 %244, i32* %214, align 4, !alias.scope !954
  call void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIhLNS_8MapOrderE1EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE1EEENSC_ISD_LSE_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SV_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.195"* %4, %"struct.gemmlowp::MatrixBlockBounds"* nonnull dereferenceable(16) %20, %"class.gemmlowp::PackedResult"* nonnull dereferenceable(40) %19, i32 %28, i32* %321, i32* %331, %"class.gemmlowp::VectorDup.194"* nonnull dereferenceable(8) %21, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %22, %"class.std::__1::tuple.187"* dereferenceable(20) %7)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %211) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %207) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %202) #19
  %334 = load i32, i32* %35, align 4
  %335 = add nsw i32 %334, %241
  %336 = icmp sgt i32 %26, %335
  br i1 %336, label %239, label %235
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIhLNS_8MapOrderE1EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE1EEENSC_ISD_LSE_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SV_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.195"*, %"struct.gemmlowp::MatrixBlockBounds"* dereferenceable(16), %"class.gemmlowp::PackedResult"* dereferenceable(40), i32, i32*, i32*, %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.std::__1::tuple.187"* dereferenceable(20)) local_unnamed_addr #1 comdat {
  %10 = alloca %"struct.gemmlowp::RegisterBlock", align 8
  %11 = alloca %"class.gemmlowp::MatrixMap.214", align 8
  %12 = alloca %"class.gemmlowp::VectorMap", align 8
  %13 = alloca %"class.gemmlowp::VectorMap.201", align 8
  %14 = alloca %"struct.gemmlowp::OutputPipelineExecutor.393", align 8
  %15 = alloca %"struct.gemmlowp::OutputPipelineExecutor.400", align 8
  %16 = alloca %"struct.gemmlowp::OutputPipelineExecutor.407", align 8
  %17 = alloca %"struct.gemmlowp::OutputPipelineExecutor.414", align 8
  %18 = alloca %"struct.gemmlowp::OutputPipelineExecutor.421", align 8
  %19 = alloca [64 x i8], align 16
  %20 = alloca %"class.gemmlowp::MatrixMap.182", align 8
  %21 = bitcast %"class.gemmlowp::MatrixMap.214"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %21) #19
  %22 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %11, i64 0, i32 0
  %23 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %11, i64 0, i32 1
  %24 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %11, i64 0, i32 2
  %25 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %11, i64 0, i32 3
  %26 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 0
  %27 = bitcast %"class.gemmlowp::MatrixMap.214"* %11 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %27, i8 -86, i64 24, i1 false)
  %28 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %26, align 8, !noalias !957
  %29 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 1, i32 0
  %30 = load i8, i8* %29, align 8, !noalias !957
  %31 = zext i8 %30 to i64
  %32 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %28, i64 0, i32 5, i64 %31
  %33 = load i64, i64* %32, align 8, !noalias !957
  %34 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %28, i64 0, i32 2
  %35 = bitcast i8** %34 to i64*
  %36 = load i64, i64* %35, align 8, !noalias !957
  %37 = add i64 %36, %33
  %38 = inttoptr i64 %37 to i32*
  %39 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 2
  %40 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %39, align 8, !noalias !957
  %41 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %40, i64 0, i32 3
  %42 = load i32, i32* %41, align 4, !noalias !957
  %43 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %40, i64 0, i32 4
  %44 = load i32, i32* %43, align 4, !noalias !957
  store i32* %38, i32** %22, align 8, !alias.scope !957
  store i32 %42, i32* %23, align 8, !alias.scope !957
  store i32 %44, i32* %24, align 4, !alias.scope !957
  store i32 %42, i32* %25, align 8, !alias.scope !957
  %45 = bitcast %"class.gemmlowp::VectorMap"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %45) #19
  %46 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %12, i64 0, i32 0
  %47 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %12, i64 0, i32 1
  %48 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 2
  %49 = bitcast %"class.gemmlowp::VectorMap"* %12 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %49, i8 -86, i64 16, i1 false)
  %50 = load i32, i32* %48, align 4
  store i32* %4, i32** %46, align 8
  store i32 %50, i32* %47, align 8
  %51 = bitcast %"class.gemmlowp::VectorMap.201"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %51) #19
  %52 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %13, i64 0, i32 0
  %53 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %13, i64 0, i32 1
  %54 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 3
  %55 = bitcast %"class.gemmlowp::VectorMap.201"* %13 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %55, i8 -86, i64 16, i1 false)
  %56 = load i32, i32* %54, align 4
  store i32* %5, i32** %52, align 8
  store i32 %56, i32* %53, align 8
  %57 = getelementptr inbounds %"class.std::__1::tuple.187", %"class.std::__1::tuple.187"* %8, i64 0, i32 0, i32 0, i32 0
  %58 = getelementptr inbounds %"class.std::__1::tuple.187", %"class.std::__1::tuple.187"* %8, i64 0, i32 0, i32 0, i32 0, i32 1
  %59 = load i32, i32* %58, align 4
  %60 = icmp sgt i32 %59, 0
  %61 = select i1 %60, i32 %59, i32 0
  %62 = sub nsw i32 0, %59
  %63 = icmp sgt i32 %62, 0
  %64 = select i1 %63, i32 %62, i32 0
  %65 = getelementptr inbounds %"class.std::__1::tuple.187", %"class.std::__1::tuple.187"* %8, i64 0, i32 0, i32 1, i32 0
  %66 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.393"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %66) #19
  %67 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.393", %"struct.gemmlowp::OutputPipelineExecutor.393"* %14, i64 0, i32 0, i32 0, i32 0, i32 0
  %68 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.393", %"struct.gemmlowp::OutputPipelineExecutor.393"* %14, i64 0, i32 0, i32 0, i32 0, i32 1
  %69 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.393", %"struct.gemmlowp::OutputPipelineExecutor.393"* %14, i64 0, i32 0, i32 0, i32 0, i32 2
  %70 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.393", %"struct.gemmlowp::OutputPipelineExecutor.393"* %14, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %71 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.393", %"struct.gemmlowp::OutputPipelineExecutor.393"* %14, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %72 = bitcast i8* %71 to i64*
  store i64 -6148914691236517206, i64* %72, align 8
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %57, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %67, align 8
  store i32 %61, i32* %68, align 8
  store i32 %64, i32* %69, align 4
  store %"struct.gemmlowp::OutputStageClamp"* %65, %"struct.gemmlowp::OutputStageClamp"** %70, align 8
  %73 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.400"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %73) #19
  %74 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.400", %"struct.gemmlowp::OutputPipelineExecutor.400"* %15, i64 0, i32 0, i32 0, i32 0, i32 0
  %75 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.400", %"struct.gemmlowp::OutputPipelineExecutor.400"* %15, i64 0, i32 0, i32 0, i32 0, i32 1
  %76 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.400", %"struct.gemmlowp::OutputPipelineExecutor.400"* %15, i64 0, i32 0, i32 0, i32 0, i32 2
  %77 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.400", %"struct.gemmlowp::OutputPipelineExecutor.400"* %15, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %78 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.400", %"struct.gemmlowp::OutputPipelineExecutor.400"* %15, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %79 = bitcast i8* %78 to i64*
  store i64 -6148914691236517206, i64* %79, align 8
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %57, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %74, align 8
  store i32 %61, i32* %75, align 8
  store i32 %64, i32* %76, align 4
  store %"struct.gemmlowp::OutputStageClamp"* %65, %"struct.gemmlowp::OutputStageClamp"** %77, align 8
  %80 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.407"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %80) #19
  %81 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.407", %"struct.gemmlowp::OutputPipelineExecutor.407"* %16, i64 0, i32 0, i32 0, i32 0, i32 0
  %82 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.407", %"struct.gemmlowp::OutputPipelineExecutor.407"* %16, i64 0, i32 0, i32 0, i32 0, i32 1
  %83 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.407", %"struct.gemmlowp::OutputPipelineExecutor.407"* %16, i64 0, i32 0, i32 0, i32 0, i32 2
  %84 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.407", %"struct.gemmlowp::OutputPipelineExecutor.407"* %16, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %85 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.407", %"struct.gemmlowp::OutputPipelineExecutor.407"* %16, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %86 = bitcast i8* %85 to i64*
  store i64 -6148914691236517206, i64* %86, align 8
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %57, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %81, align 8
  store i32 %61, i32* %82, align 8
  store i32 %64, i32* %83, align 4
  store %"struct.gemmlowp::OutputStageClamp"* %65, %"struct.gemmlowp::OutputStageClamp"** %84, align 8
  %87 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.414"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %87) #19
  %88 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.414", %"struct.gemmlowp::OutputPipelineExecutor.414"* %17, i64 0, i32 0, i32 0, i32 0, i32 0
  %89 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.414", %"struct.gemmlowp::OutputPipelineExecutor.414"* %17, i64 0, i32 0, i32 0, i32 0, i32 1
  %90 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.414", %"struct.gemmlowp::OutputPipelineExecutor.414"* %17, i64 0, i32 0, i32 0, i32 0, i32 2
  %91 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.414", %"struct.gemmlowp::OutputPipelineExecutor.414"* %17, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %92 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.414", %"struct.gemmlowp::OutputPipelineExecutor.414"* %17, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %93 = bitcast i8* %92 to i64*
  store i64 -6148914691236517206, i64* %93, align 8
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %57, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %88, align 8
  store i32 %61, i32* %89, align 8
  store i32 %64, i32* %90, align 4
  store %"struct.gemmlowp::OutputStageClamp"* %65, %"struct.gemmlowp::OutputStageClamp"** %91, align 8
  %94 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.421"* %18 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %94) #19
  %95 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.421", %"struct.gemmlowp::OutputPipelineExecutor.421"* %18, i64 0, i32 0, i32 0, i32 0, i32 0
  %96 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.421", %"struct.gemmlowp::OutputPipelineExecutor.421"* %18, i64 0, i32 0, i32 0, i32 0, i32 1
  %97 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.421", %"struct.gemmlowp::OutputPipelineExecutor.421"* %18, i64 0, i32 0, i32 0, i32 0, i32 2
  %98 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.421", %"struct.gemmlowp::OutputPipelineExecutor.421"* %18, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %99 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.421", %"struct.gemmlowp::OutputPipelineExecutor.421"* %18, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %100 = bitcast i8* %99 to i64*
  store i64 -6148914691236517206, i64* %100, align 8
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %57, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %95, align 8
  store i32 %61, i32* %96, align 8
  store i32 %64, i32* %97, align 4
  store %"struct.gemmlowp::OutputStageClamp"* %65, %"struct.gemmlowp::OutputStageClamp"** %98, align 8
  %101 = load i32, i32* %54, align 4
  %102 = icmp slt i32 %101, 8
  br i1 %102, label %115, label %103

103:                                              ; preds = %9
  %104 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 0
  %105 = getelementptr inbounds [64 x i8], [64 x i8]* %19, i64 0, i64 0
  %106 = bitcast %"class.gemmlowp::MatrixMap.182"* %20 to i8*
  %107 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %20, i64 0, i32 0
  %108 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %20, i64 0, i32 1
  %109 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %20, i64 0, i32 2
  %110 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %20, i64 0, i32 3
  %111 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 1
  %112 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock", %"struct.gemmlowp::RegisterBlock"* %10, i64 0, i32 0, i32 0, i64 0
  %113 = load i32, i32* %48, align 4
  %114 = bitcast %"class.gemmlowp::MatrixMap.182"* %20 to i8*
  br label %124

115:                                              ; preds = %286, %9
  %116 = phi i32 [ %101, %9 ], [ %289, %286 ]
  %117 = phi i32 [ 0, %9 ], [ %288, %286 ]
  %118 = add nsw i32 %116, -4
  %119 = icmp sgt i32 %117, %118
  br i1 %119, label %292, label %120

120:                                              ; preds = %115
  %121 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 1
  %122 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 0
  %123 = load i32, i32* %48, align 4
  br label %316

124:                                              ; preds = %103, %286
  %125 = phi i32 [ %113, %103 ], [ %287, %286 ]
  %126 = phi i32 [ 0, %103 ], [ %288, %286 ]
  %127 = load i32*, i32** %22, align 8
  %128 = load i32, i32* %25, align 8
  %129 = mul nsw i32 %128, %126
  %130 = sext i32 %129 to i64
  %131 = load i32*, i32** %46, align 8
  %132 = bitcast i32* %131 to i8*
  call void @llvm.prefetch(i8* %132, i32 0, i32 3, i32 1) #19
  %133 = getelementptr inbounds i32, i32* %131, i64 4
  %134 = bitcast i32* %133 to i8*
  call void @llvm.prefetch(i8* %134, i32 0, i32 3, i32 1) #19
  %135 = getelementptr inbounds i32, i32* %127, i64 %130
  %136 = sext i32 %128 to i64
  %137 = bitcast i32* %135 to i8*
  call void @llvm.prefetch(i8* %137, i32 0, i32 3, i32 1) #19
  %138 = getelementptr inbounds i32, i32* %135, i64 4
  %139 = bitcast i32* %138 to i8*
  call void @llvm.prefetch(i8* %139, i32 0, i32 3, i32 1) #19
  %140 = getelementptr inbounds i32, i32* %135, i64 %136
  %141 = bitcast i32* %140 to i8*
  call void @llvm.prefetch(i8* %141, i32 0, i32 3, i32 1) #19
  %142 = getelementptr inbounds i32, i32* %140, i64 4
  %143 = bitcast i32* %142 to i8*
  call void @llvm.prefetch(i8* %143, i32 0, i32 3, i32 1) #19
  %144 = shl nsw i64 %136, 1
  %145 = getelementptr inbounds i32, i32* %135, i64 %144
  %146 = bitcast i32* %145 to i8*
  call void @llvm.prefetch(i8* %146, i32 0, i32 3, i32 1) #19
  %147 = getelementptr inbounds i32, i32* %145, i64 4
  %148 = bitcast i32* %147 to i8*
  call void @llvm.prefetch(i8* %148, i32 0, i32 3, i32 1) #19
  %149 = mul nsw i64 %136, 3
  %150 = getelementptr inbounds i32, i32* %135, i64 %149
  %151 = bitcast i32* %150 to i8*
  call void @llvm.prefetch(i8* %151, i32 0, i32 3, i32 1) #19
  %152 = getelementptr inbounds i32, i32* %150, i64 4
  %153 = bitcast i32* %152 to i8*
  call void @llvm.prefetch(i8* %153, i32 0, i32 3, i32 1) #19
  %154 = shl nsw i64 %136, 2
  %155 = getelementptr inbounds i32, i32* %135, i64 %154
  %156 = bitcast i32* %155 to i8*
  call void @llvm.prefetch(i8* %156, i32 0, i32 3, i32 1) #19
  %157 = getelementptr inbounds i32, i32* %155, i64 4
  %158 = bitcast i32* %157 to i8*
  call void @llvm.prefetch(i8* %158, i32 0, i32 3, i32 1) #19
  %159 = mul nsw i64 %136, 5
  %160 = getelementptr inbounds i32, i32* %135, i64 %159
  %161 = bitcast i32* %160 to i8*
  call void @llvm.prefetch(i8* %161, i32 0, i32 3, i32 1) #19
  %162 = getelementptr inbounds i32, i32* %160, i64 4
  %163 = bitcast i32* %162 to i8*
  call void @llvm.prefetch(i8* %163, i32 0, i32 3, i32 1) #19
  %164 = mul nsw i64 %136, 6
  %165 = getelementptr inbounds i32, i32* %135, i64 %164
  %166 = bitcast i32* %165 to i8*
  call void @llvm.prefetch(i8* %166, i32 0, i32 3, i32 1) #19
  %167 = getelementptr inbounds i32, i32* %165, i64 4
  %168 = bitcast i32* %167 to i8*
  call void @llvm.prefetch(i8* %168, i32 0, i32 3, i32 1) #19
  %169 = mul nsw i64 %136, 7
  %170 = getelementptr inbounds i32, i32* %135, i64 %169
  %171 = bitcast i32* %170 to i8*
  call void @llvm.prefetch(i8* %171, i32 0, i32 3, i32 1) #19
  %172 = getelementptr inbounds i32, i32* %170, i64 4
  %173 = bitcast i32* %172 to i8*
  call void @llvm.prefetch(i8* %173, i32 0, i32 3, i32 1) #19
  %174 = icmp slt i32 %125, 8
  br i1 %174, label %179, label %175

175:                                              ; preds = %124
  %176 = or i32 %126, 4
  br label %186

177:                                              ; preds = %186
  %178 = trunc i64 %194 to i32
  br label %179

179:                                              ; preds = %177, %124
  %180 = phi i32 [ %125, %124 ], [ %249, %177 ]
  %181 = phi i32 [ 0, %124 ], [ %178, %177 ]
  %182 = add nsw i32 %180, -4
  %183 = icmp sgt i32 %181, %182
  br i1 %183, label %257, label %184

184:                                              ; preds = %179
  %185 = or i32 %126, 4
  br label %263

186:                                              ; preds = %253, %175
  %187 = phi i32* [ %131, %175 ], [ %256, %253 ]
  %188 = phi i32 [ %128, %175 ], [ %255, %253 ]
  %189 = phi i32* [ %127, %175 ], [ %254, %253 ]
  %190 = phi i64 [ 0, %175 ], [ %194, %253 ]
  %191 = load i32, i32* %104, align 4
  %192 = trunc i64 %190 to i32
  %193 = add nsw i32 %191, %192
  %194 = add nuw i64 %190, 8
  %195 = mul nsw i32 %188, %126
  %196 = sext i32 %195 to i64
  %197 = getelementptr inbounds i32, i32* %187, i64 %194
  %198 = bitcast i32* %197 to i8*
  call void @llvm.prefetch(i8* %198, i32 0, i32 3, i32 1) #19
  %199 = getelementptr inbounds i32, i32* %197, i64 4
  %200 = bitcast i32* %199 to i8*
  call void @llvm.prefetch(i8* %200, i32 0, i32 3, i32 1) #19
  %201 = getelementptr inbounds i32, i32* %189, i64 %194
  %202 = getelementptr inbounds i32, i32* %201, i64 %196
  %203 = sext i32 %188 to i64
  %204 = bitcast i32* %202 to i8*
  call void @llvm.prefetch(i8* %204, i32 0, i32 3, i32 1) #19
  %205 = getelementptr inbounds i32, i32* %202, i64 4
  %206 = bitcast i32* %205 to i8*
  call void @llvm.prefetch(i8* %206, i32 0, i32 3, i32 1) #19
  %207 = getelementptr inbounds i32, i32* %202, i64 %203
  %208 = bitcast i32* %207 to i8*
  call void @llvm.prefetch(i8* %208, i32 0, i32 3, i32 1) #19
  %209 = getelementptr inbounds i32, i32* %207, i64 4
  %210 = bitcast i32* %209 to i8*
  call void @llvm.prefetch(i8* %210, i32 0, i32 3, i32 1) #19
  %211 = shl nsw i64 %203, 1
  %212 = getelementptr inbounds i32, i32* %202, i64 %211
  %213 = bitcast i32* %212 to i8*
  call void @llvm.prefetch(i8* %213, i32 0, i32 3, i32 1) #19
  %214 = getelementptr inbounds i32, i32* %212, i64 4
  %215 = bitcast i32* %214 to i8*
  call void @llvm.prefetch(i8* %215, i32 0, i32 3, i32 1) #19
  %216 = mul nsw i64 %203, 3
  %217 = getelementptr inbounds i32, i32* %202, i64 %216
  %218 = bitcast i32* %217 to i8*
  call void @llvm.prefetch(i8* %218, i32 0, i32 3, i32 1) #19
  %219 = getelementptr inbounds i32, i32* %217, i64 4
  %220 = bitcast i32* %219 to i8*
  call void @llvm.prefetch(i8* %220, i32 0, i32 3, i32 1) #19
  %221 = shl nsw i64 %203, 2
  %222 = getelementptr inbounds i32, i32* %202, i64 %221
  %223 = bitcast i32* %222 to i8*
  call void @llvm.prefetch(i8* %223, i32 0, i32 3, i32 1) #19
  %224 = getelementptr inbounds i32, i32* %222, i64 4
  %225 = bitcast i32* %224 to i8*
  call void @llvm.prefetch(i8* %225, i32 0, i32 3, i32 1) #19
  %226 = mul nsw i64 %203, 5
  %227 = getelementptr inbounds i32, i32* %202, i64 %226
  %228 = bitcast i32* %227 to i8*
  call void @llvm.prefetch(i8* %228, i32 0, i32 3, i32 1) #19
  %229 = getelementptr inbounds i32, i32* %227, i64 4
  %230 = bitcast i32* %229 to i8*
  call void @llvm.prefetch(i8* %230, i32 0, i32 3, i32 1) #19
  %231 = mul nsw i64 %203, 6
  %232 = getelementptr inbounds i32, i32* %202, i64 %231
  %233 = bitcast i32* %232 to i8*
  call void @llvm.prefetch(i8* %233, i32 0, i32 3, i32 1) #19
  %234 = getelementptr inbounds i32, i32* %232, i64 4
  %235 = bitcast i32* %234 to i8*
  call void @llvm.prefetch(i8* %235, i32 0, i32 3, i32 1) #19
  %236 = mul nsw i64 %203, 7
  %237 = getelementptr inbounds i32, i32* %202, i64 %236
  %238 = bitcast i32* %237 to i8*
  call void @llvm.prefetch(i8* %238, i32 0, i32 3, i32 1) #19
  %239 = getelementptr inbounds i32, i32* %237, i64 4
  %240 = bitcast i32* %239 to i8*
  call void @llvm.prefetch(i8* %240, i32 0, i32 3, i32 1) #19
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %105) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %105, i8 -86, i64 64, i1 false)
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %106) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %114, i8 -86, i64 24, i1 false)
  store i8* %105, i8** %107, align 8
  store i32 8, i32* %108, align 8
  store i32 8, i32* %109, align 4
  store i32 8, i32* %110, align 8
  %241 = load i32, i32* %111, align 4
  %242 = add nsw i32 %241, %126
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.421"* nonnull dereferenceable(32) %18, %"class.gemmlowp::MatrixMap.182"* nonnull %20, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %192, i32 %126, i32 %193, i32 %242, i32 0, i32 0)
  %243 = load i32, i32* %111, align 4
  %244 = add nsw i32 %243, %176
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.421"* nonnull dereferenceable(32) %18, %"class.gemmlowp::MatrixMap.182"* nonnull %20, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %192, i32 %176, i32 %193, i32 %244, i32 0, i32 4)
  %245 = load i32, i32* %104, align 4
  %246 = add nsw i32 %245, %192
  %247 = load i32, i32* %111, align 4
  %248 = add nsw i32 %247, %126
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %112)
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %112, i8* nonnull align 16 %105, i64 64, i1 false)
  call void @_ZN8gemmlowp20StoreFinalOutputImplINS_13RegisterBlockIhLi8ELi8EEENS_9MatrixMapIhLNS_8MapOrderE1EEEE3RunERKS2_PS5_ii(%"struct.gemmlowp::RegisterBlock"* nonnull dereferenceable(64) %10, %"class.gemmlowp::MatrixMap.195"* %0, i32 %246, i32 %248) #19
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %112)
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %106) #19
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %105) #19
  %249 = load i32, i32* %48, align 4
  %250 = add nsw i32 %249, -8
  %251 = trunc i64 %194 to i32
  %252 = icmp slt i32 %250, %251
  br i1 %252, label %177, label %253

253:                                              ; preds = %186
  %254 = load i32*, i32** %22, align 8
  %255 = load i32, i32* %25, align 8
  %256 = load i32*, i32** %46, align 8
  br label %186

257:                                              ; preds = %263, %179
  %258 = phi i32 [ %180, %179 ], [ %272, %263 ]
  %259 = phi i32 [ %181, %179 ], [ %271, %263 ]
  %260 = icmp slt i32 %259, %258
  br i1 %260, label %261, label %286

261:                                              ; preds = %257
  %262 = or i32 %126, 4
  br label %275

263:                                              ; preds = %184, %263
  %264 = phi i32 [ %271, %263 ], [ %181, %184 ]
  %265 = load i32, i32* %104, align 4
  %266 = add nsw i32 %265, %264
  %267 = load i32, i32* %111, align 4
  %268 = add nsw i32 %267, %126
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.414"* nonnull dereferenceable(32) %17, %"class.gemmlowp::MatrixMap.195"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %264, i32 %126, i32 %266, i32 %268, i32 %266, i32 %268)
  %269 = load i32, i32* %111, align 4
  %270 = add nsw i32 %269, %185
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.414"* nonnull dereferenceable(32) %17, %"class.gemmlowp::MatrixMap.195"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %264, i32 %185, i32 %266, i32 %270, i32 %266, i32 %270)
  %271 = add nuw nsw i32 %264, 4
  %272 = load i32, i32* %48, align 4
  %273 = add nsw i32 %272, -4
  %274 = icmp sgt i32 %271, %273
  br i1 %274, label %257, label %263

275:                                              ; preds = %261, %275
  %276 = phi i32 [ %283, %275 ], [ %259, %261 ]
  %277 = load i32, i32* %104, align 4
  %278 = add nsw i32 %277, %276
  %279 = load i32, i32* %111, align 4
  %280 = add nsw i32 %279, %126
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.407"* nonnull dereferenceable(32) %16, %"class.gemmlowp::MatrixMap.195"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %276, i32 %126, i32 %278, i32 %280, i32 %278, i32 %280)
  %281 = load i32, i32* %111, align 4
  %282 = add nsw i32 %281, %262
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.407"* nonnull dereferenceable(32) %16, %"class.gemmlowp::MatrixMap.195"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %276, i32 %262, i32 %278, i32 %282, i32 %278, i32 %282)
  %283 = add nuw nsw i32 %276, 1
  %284 = load i32, i32* %48, align 4
  %285 = icmp slt i32 %283, %284
  br i1 %285, label %275, label %286

286:                                              ; preds = %275, %257
  %287 = phi i32 [ %258, %257 ], [ %284, %275 ]
  %288 = add nuw nsw i32 %126, 8
  %289 = load i32, i32* %54, align 4
  %290 = add nsw i32 %289, -8
  %291 = icmp sgt i32 %288, %290
  br i1 %291, label %115, label %124

292:                                              ; preds = %418, %115
  %293 = phi i32 [ %116, %115 ], [ %421, %418 ]
  %294 = phi i32 [ %117, %115 ], [ %420, %418 ]
  %295 = icmp slt i32 %294, %293
  br i1 %295, label %296, label %577

296:                                              ; preds = %292
  %297 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 1
  %298 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 0
  %299 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %6, i64 0, i32 0
  %300 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %7, i64 0, i32 0
  %301 = getelementptr inbounds %"class.std::__1::tuple.187", %"class.std::__1::tuple.187"* %8, i64 0, i32 0, i32 0, i32 0, i32 2
  %302 = shl i32 1, %61
  %303 = sext i32 %302 to i64
  %304 = getelementptr inbounds %"class.std::__1::tuple.187", %"class.std::__1::tuple.187"* %8, i64 0, i32 0, i32 0, i32 0, i32 0
  %305 = zext i32 %64 to i64
  %306 = shl nsw i64 -1, %305
  %307 = trunc i64 %306 to i32
  %308 = xor i32 %307, -1
  %309 = ashr i32 %308, 1
  %310 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %65, i64 0, i32 0
  %311 = getelementptr inbounds %"class.std::__1::tuple.187", %"class.std::__1::tuple.187"* %8, i64 0, i32 0, i32 1, i32 0, i32 1
  %312 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %0, i64 0, i32 0
  %313 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %0, i64 0, i32 3
  %314 = zext i32 %294 to i64
  %315 = load i32, i32* %48, align 4
  br label %424

316:                                              ; preds = %120, %418
  %317 = phi i32 [ %123, %120 ], [ %419, %418 ]
  %318 = phi i32 [ %117, %120 ], [ %420, %418 ]
  %319 = load i32, i32* %121, align 4
  %320 = add nsw i32 %319, %318
  %321 = load i32*, i32** %22, align 8
  %322 = load i32, i32* %25, align 8
  %323 = mul nsw i32 %322, %318
  %324 = sext i32 %323 to i64
  %325 = load i32*, i32** %46, align 8
  %326 = bitcast i32* %325 to i8*
  call void @llvm.prefetch(i8* %326, i32 0, i32 3, i32 1) #19
  %327 = getelementptr inbounds i32, i32* %325, i64 4
  %328 = bitcast i32* %327 to i8*
  call void @llvm.prefetch(i8* %328, i32 0, i32 3, i32 1) #19
  %329 = getelementptr inbounds i32, i32* %321, i64 %324
  %330 = sext i32 %322 to i64
  %331 = bitcast i32* %329 to i8*
  call void @llvm.prefetch(i8* %331, i32 0, i32 3, i32 1) #19
  %332 = getelementptr inbounds i32, i32* %329, i64 4
  %333 = bitcast i32* %332 to i8*
  call void @llvm.prefetch(i8* %333, i32 0, i32 3, i32 1) #19
  %334 = getelementptr inbounds i32, i32* %329, i64 %330
  %335 = bitcast i32* %334 to i8*
  call void @llvm.prefetch(i8* %335, i32 0, i32 3, i32 1) #19
  %336 = getelementptr inbounds i32, i32* %334, i64 4
  %337 = bitcast i32* %336 to i8*
  call void @llvm.prefetch(i8* %337, i32 0, i32 3, i32 1) #19
  %338 = shl nsw i64 %330, 1
  %339 = getelementptr inbounds i32, i32* %329, i64 %338
  %340 = bitcast i32* %339 to i8*
  call void @llvm.prefetch(i8* %340, i32 0, i32 3, i32 1) #19
  %341 = getelementptr inbounds i32, i32* %339, i64 4
  %342 = bitcast i32* %341 to i8*
  call void @llvm.prefetch(i8* %342, i32 0, i32 3, i32 1) #19
  %343 = mul nsw i64 %330, 3
  %344 = getelementptr inbounds i32, i32* %329, i64 %343
  %345 = bitcast i32* %344 to i8*
  call void @llvm.prefetch(i8* %345, i32 0, i32 3, i32 1) #19
  %346 = getelementptr inbounds i32, i32* %344, i64 4
  %347 = bitcast i32* %346 to i8*
  call void @llvm.prefetch(i8* %347, i32 0, i32 3, i32 1) #19
  %348 = icmp slt i32 %317, 8
  br i1 %348, label %351, label %356

349:                                              ; preds = %356
  %350 = trunc i64 %364 to i32
  br label %351

351:                                              ; preds = %349, %316
  %352 = phi i32 [ %317, %316 ], [ %391, %349 ]
  %353 = phi i32 [ 0, %316 ], [ %350, %349 ]
  %354 = add nsw i32 %352, -4
  %355 = icmp sgt i32 %353, %354
  br i1 %355, label %399, label %403

356:                                              ; preds = %316, %395
  %357 = phi i32* [ %398, %395 ], [ %325, %316 ]
  %358 = phi i32 [ %397, %395 ], [ %322, %316 ]
  %359 = phi i32* [ %396, %395 ], [ %321, %316 ]
  %360 = phi i64 [ %364, %395 ], [ 0, %316 ]
  %361 = load i32, i32* %122, align 4
  %362 = trunc i64 %360 to i32
  %363 = add nsw i32 %361, %362
  %364 = add nuw i64 %360, 8
  %365 = mul nsw i32 %358, %318
  %366 = sext i32 %365 to i64
  %367 = getelementptr inbounds i32, i32* %357, i64 %364
  %368 = bitcast i32* %367 to i8*
  call void @llvm.prefetch(i8* %368, i32 0, i32 3, i32 1) #19
  %369 = getelementptr inbounds i32, i32* %367, i64 4
  %370 = bitcast i32* %369 to i8*
  call void @llvm.prefetch(i8* %370, i32 0, i32 3, i32 1) #19
  %371 = getelementptr inbounds i32, i32* %359, i64 %364
  %372 = getelementptr inbounds i32, i32* %371, i64 %366
  %373 = sext i32 %358 to i64
  %374 = bitcast i32* %372 to i8*
  call void @llvm.prefetch(i8* %374, i32 0, i32 3, i32 1) #19
  %375 = getelementptr inbounds i32, i32* %372, i64 4
  %376 = bitcast i32* %375 to i8*
  call void @llvm.prefetch(i8* %376, i32 0, i32 3, i32 1) #19
  %377 = getelementptr inbounds i32, i32* %372, i64 %373
  %378 = bitcast i32* %377 to i8*
  call void @llvm.prefetch(i8* %378, i32 0, i32 3, i32 1) #19
  %379 = getelementptr inbounds i32, i32* %377, i64 4
  %380 = bitcast i32* %379 to i8*
  call void @llvm.prefetch(i8* %380, i32 0, i32 3, i32 1) #19
  %381 = shl nsw i64 %373, 1
  %382 = getelementptr inbounds i32, i32* %372, i64 %381
  %383 = bitcast i32* %382 to i8*
  call void @llvm.prefetch(i8* %383, i32 0, i32 3, i32 1) #19
  %384 = getelementptr inbounds i32, i32* %382, i64 4
  %385 = bitcast i32* %384 to i8*
  call void @llvm.prefetch(i8* %385, i32 0, i32 3, i32 1) #19
  %386 = mul nsw i64 %373, 3
  %387 = getelementptr inbounds i32, i32* %372, i64 %386
  %388 = bitcast i32* %387 to i8*
  call void @llvm.prefetch(i8* %388, i32 0, i32 3, i32 1) #19
  %389 = getelementptr inbounds i32, i32* %387, i64 4
  %390 = bitcast i32* %389 to i8*
  call void @llvm.prefetch(i8* %390, i32 0, i32 3, i32 1) #19
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.421"* nonnull dereferenceable(32) %18, %"class.gemmlowp::MatrixMap.195"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %362, i32 %318, i32 %363, i32 %320, i32 %363, i32 %320)
  %391 = load i32, i32* %48, align 4
  %392 = add nsw i32 %391, -8
  %393 = trunc i64 %364 to i32
  %394 = icmp slt i32 %392, %393
  br i1 %394, label %349, label %395

395:                                              ; preds = %356
  %396 = load i32*, i32** %22, align 8
  %397 = load i32, i32* %25, align 8
  %398 = load i32*, i32** %46, align 8
  br label %356

399:                                              ; preds = %403, %351
  %400 = phi i32 [ %352, %351 ], [ %408, %403 ]
  %401 = phi i32 [ %353, %351 ], [ %407, %403 ]
  %402 = icmp slt i32 %401, %400
  br i1 %402, label %411, label %418

403:                                              ; preds = %351, %403
  %404 = phi i32 [ %407, %403 ], [ %353, %351 ]
  %405 = load i32, i32* %122, align 4
  %406 = add nsw i32 %405, %404
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.414"* nonnull dereferenceable(32) %17, %"class.gemmlowp::MatrixMap.195"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %404, i32 %318, i32 %406, i32 %320, i32 %406, i32 %320)
  %407 = add nuw nsw i32 %404, 4
  %408 = load i32, i32* %48, align 4
  %409 = add nsw i32 %408, -4
  %410 = icmp sgt i32 %407, %409
  br i1 %410, label %399, label %403

411:                                              ; preds = %399, %411
  %412 = phi i32 [ %415, %411 ], [ %401, %399 ]
  %413 = load i32, i32* %122, align 4
  %414 = add nsw i32 %413, %412
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.407"* nonnull dereferenceable(32) %16, %"class.gemmlowp::MatrixMap.195"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %412, i32 %318, i32 %414, i32 %320, i32 %414, i32 %320)
  %415 = add nuw nsw i32 %412, 1
  %416 = load i32, i32* %48, align 4
  %417 = icmp slt i32 %415, %416
  br i1 %417, label %411, label %418

418:                                              ; preds = %411, %399
  %419 = phi i32 [ %400, %399 ], [ %416, %411 ]
  %420 = add nuw nsw i32 %318, 4
  %421 = load i32, i32* %54, align 4
  %422 = add nsw i32 %421, -4
  %423 = icmp sgt i32 %420, %422
  br i1 %423, label %292, label %316

424:                                              ; preds = %296, %571
  %425 = phi i32 [ %315, %296 ], [ %572, %571 ]
  %426 = phi i64 [ %314, %296 ], [ %573, %571 ]
  %427 = load i32, i32* %297, align 4
  %428 = trunc i64 %426 to i32
  %429 = add nsw i32 %427, %428
  %430 = load i32*, i32** %22, align 8
  %431 = load i32, i32* %25, align 8
  %432 = mul nsw i32 %431, %428
  %433 = sext i32 %432 to i64
  %434 = load i32*, i32** %46, align 8
  %435 = bitcast i32* %434 to i8*
  call void @llvm.prefetch(i8* %435, i32 0, i32 3, i32 1) #19
  %436 = getelementptr inbounds i32, i32* %434, i64 4
  %437 = bitcast i32* %436 to i8*
  call void @llvm.prefetch(i8* %437, i32 0, i32 3, i32 1) #19
  %438 = getelementptr inbounds i32, i32* %430, i64 %433
  %439 = bitcast i32* %438 to i8*
  call void @llvm.prefetch(i8* %439, i32 0, i32 3, i32 1) #19
  %440 = getelementptr inbounds i32, i32* %438, i64 4
  %441 = bitcast i32* %440 to i8*
  call void @llvm.prefetch(i8* %441, i32 0, i32 3, i32 1) #19
  %442 = icmp slt i32 %425, 8
  br i1 %442, label %445, label %450

443:                                              ; preds = %450
  %444 = trunc i64 %458 to i32
  br label %445

445:                                              ; preds = %443, %424
  %446 = phi i32 [ %425, %424 ], [ %470, %443 ]
  %447 = phi i32 [ 0, %424 ], [ %444, %443 ]
  %448 = add nsw i32 %446, -4
  %449 = icmp sgt i32 %447, %448
  br i1 %449, label %478, label %485

450:                                              ; preds = %424, %474
  %451 = phi i32* [ %477, %474 ], [ %434, %424 ]
  %452 = phi i32 [ %476, %474 ], [ %431, %424 ]
  %453 = phi i32* [ %475, %474 ], [ %430, %424 ]
  %454 = phi i64 [ %458, %474 ], [ 0, %424 ]
  %455 = load i32, i32* %298, align 4
  %456 = trunc i64 %454 to i32
  %457 = add nsw i32 %455, %456
  %458 = add nuw i64 %454, 8
  %459 = mul nsw i32 %452, %428
  %460 = sext i32 %459 to i64
  %461 = getelementptr inbounds i32, i32* %451, i64 %458
  %462 = bitcast i32* %461 to i8*
  call void @llvm.prefetch(i8* %462, i32 0, i32 3, i32 1) #19
  %463 = getelementptr inbounds i32, i32* %461, i64 4
  %464 = bitcast i32* %463 to i8*
  call void @llvm.prefetch(i8* %464, i32 0, i32 3, i32 1) #19
  %465 = getelementptr inbounds i32, i32* %453, i64 %458
  %466 = getelementptr inbounds i32, i32* %465, i64 %460
  %467 = bitcast i32* %466 to i8*
  call void @llvm.prefetch(i8* %467, i32 0, i32 3, i32 1) #19
  %468 = getelementptr inbounds i32, i32* %466, i64 4
  %469 = bitcast i32* %468 to i8*
  call void @llvm.prefetch(i8* %469, i32 0, i32 3, i32 1) #19
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.400"* nonnull dereferenceable(32) %15, %"class.gemmlowp::MatrixMap.195"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %456, i32 %428, i32 %457, i32 %429, i32 %457, i32 %429)
  %470 = load i32, i32* %48, align 4
  %471 = add nsw i32 %470, -8
  %472 = trunc i64 %458 to i32
  %473 = icmp slt i32 %471, %472
  br i1 %473, label %443, label %474

474:                                              ; preds = %450
  %475 = load i32*, i32** %22, align 8
  %476 = load i32, i32* %25, align 8
  %477 = load i32*, i32** %46, align 8
  br label %450

478:                                              ; preds = %485, %445
  %479 = phi i32 [ %446, %445 ], [ %490, %485 ]
  %480 = phi i32 [ %447, %445 ], [ %489, %485 ]
  %481 = icmp slt i32 %480, %479
  br i1 %481, label %482, label %571

482:                                              ; preds = %478
  %483 = sext i32 %429 to i64
  %484 = zext i32 %480 to i64
  br label %493

485:                                              ; preds = %445, %485
  %486 = phi i32 [ %489, %485 ], [ %447, %445 ]
  %487 = load i32, i32* %298, align 4
  %488 = add nsw i32 %487, %486
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.393"* nonnull dereferenceable(32) %14, %"class.gemmlowp::MatrixMap.195"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %486, i32 %428, i32 %488, i32 %429, i32 %488, i32 %429)
  %489 = add nuw nsw i32 %486, 4
  %490 = load i32, i32* %48, align 4
  %491 = add nsw i32 %490, -4
  %492 = icmp sgt i32 %489, %491
  br i1 %492, label %478, label %485

493:                                              ; preds = %482, %540
  %494 = phi i64 [ %484, %482 ], [ %567, %540 ]
  %495 = load i32, i32* %298, align 4
  %496 = trunc i64 %494 to i32
  %497 = add nsw i32 %495, %496
  %498 = load i32*, i32** %22, align 8
  %499 = load i32, i32* %25, align 8
  %500 = getelementptr inbounds i32, i32* %498, i64 %494
  %501 = mul nsw i32 %499, %428
  %502 = sext i32 %501 to i64
  %503 = getelementptr inbounds i32, i32* %500, i64 %502
  %504 = load i32, i32* %503, align 4
  %505 = load i32*, i32** %46, align 8
  %506 = getelementptr inbounds i32, i32* %505, i64 %494
  %507 = load i32, i32* %506, align 4
  %508 = load i32*, i32** %52, align 8
  %509 = getelementptr inbounds i32, i32* %508, i64 %426
  %510 = load i32, i32* %509, align 4
  %511 = load i32, i32* %299, align 4
  %512 = load i32, i32* %300, align 4
  %513 = mul nsw i32 %512, %507
  %514 = add nsw i32 %513, %504
  %515 = mul nsw i32 %512, %3
  %516 = add nsw i32 %515, %510
  %517 = mul nsw i32 %516, %511
  %518 = add nsw i32 %514, %517
  %519 = load i32, i32* %301, align 4
  %520 = sext i32 %518 to i64
  %521 = mul nsw i64 %520, %303
  %522 = icmp slt i64 %521, 2147483647
  %523 = select i1 %522, i64 %521, i64 2147483647
  %524 = icmp sgt i64 %523, -2147483648
  %525 = select i1 %524, i64 %523, i64 -2147483648
  %526 = trunc i64 %525 to i32
  %527 = load i32, i32* %304, align 4
  %528 = icmp ne i32 %527, %526
  %529 = icmp ne i32 %526, -2147483648
  %530 = or i1 %528, %529
  br i1 %530, label %531, label %540

531:                                              ; preds = %493
  %532 = sext i32 %527 to i64
  %533 = select i1 %528, i64 %532, i64 %525
  %534 = mul nsw i64 %533, %525
  %535 = icmp sgt i64 %534, -1
  %536 = select i1 %535, i64 1073741824, i64 -1073741823
  %537 = add nsw i64 %536, %534
  %538 = sdiv i64 %537, 2147483648
  %539 = trunc i64 %538 to i32
  br label %540

540:                                              ; preds = %493, %531
  %541 = phi i32 [ %539, %531 ], [ 2147483647, %493 ]
  %542 = and i32 %541, %308
  %543 = lshr i32 %541, 31
  %544 = add nsw i32 %543, %309
  %545 = ashr i32 %541, %64
  %546 = icmp sgt i32 %542, %544
  %547 = zext i1 %546 to i32
  %548 = add i32 %545, %519
  %549 = add i32 %548, %547
  %550 = load i32, i32* %310, align 4
  %551 = load i32, i32* %311, align 4
  %552 = icmp sgt i32 %550, %549
  %553 = select i1 %552, i32 %550, i32 %549
  %554 = icmp slt i32 %551, %553
  %555 = select i1 %554, i32 %551, i32 %553
  %556 = icmp sgt i32 %555, 0
  %557 = select i1 %556, i32 %555, i32 0
  %558 = icmp slt i32 %557, 255
  %559 = select i1 %558, i32 %557, i32 255
  %560 = trunc i32 %559 to i8
  %561 = load i8*, i8** %312, align 8
  %562 = load i32, i32* %313, align 8
  %563 = mul nsw i32 %562, %497
  %564 = sext i32 %563 to i64
  %565 = getelementptr inbounds i8, i8* %561, i64 %483
  %566 = getelementptr inbounds i8, i8* %565, i64 %564
  store i8 %560, i8* %566, align 1
  %567 = add nuw nsw i64 %494, 1
  %568 = load i32, i32* %48, align 4
  %569 = trunc i64 %567 to i32
  %570 = icmp sgt i32 %568, %569
  br i1 %570, label %493, label %571

571:                                              ; preds = %540, %478
  %572 = phi i32 [ %479, %478 ], [ %568, %540 ]
  %573 = add nuw nsw i64 %426, 1
  %574 = load i32, i32* %54, align 4
  %575 = trunc i64 %573 to i32
  %576 = icmp sgt i32 %574, %575
  br i1 %576, label %424, label %577

577:                                              ; preds = %571, %292
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %94) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %87) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %80) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %73) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %66) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %51) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %45) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %21) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.421"* dereferenceable(32), %"class.gemmlowp::MatrixMap.182"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.310", align 8
  %16 = alloca %"struct.gemmlowp::RegisterBlock.310", align 1
  %17 = alloca %"struct.gemmlowp::RegisterBlock.302", align 16
  %18 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %18) #19
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %20 = sext i32 %8 to i64
  %21 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %22 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %22, i8 -86, i64 128, i1 false)
  %23 = load i32*, i32** %19, align 8, !noalias !960
  %24 = getelementptr inbounds i32, i32* %23, i64 %20
  %25 = load i32, i32* %21, align 8, !noalias !960
  %26 = mul nsw i32 %25, %9
  %27 = sext i32 %26 to i64
  %28 = getelementptr inbounds i32, i32* %24, i64 %27
  %29 = getelementptr inbounds i32, i32* %28, i64 1
  %30 = load i32, i32* %28, align 4
  %31 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 0
  store i32 %30, i32* %31, align 16, !alias.scope !960
  %32 = getelementptr inbounds i32, i32* %29, i64 1
  %33 = load i32, i32* %29, align 4
  %34 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 1
  store i32 %33, i32* %34, align 4, !alias.scope !960
  %35 = getelementptr inbounds i32, i32* %32, i64 1
  %36 = load i32, i32* %32, align 4
  %37 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 2
  store i32 %36, i32* %37, align 8, !alias.scope !960
  %38 = getelementptr inbounds i32, i32* %35, i64 1
  %39 = load i32, i32* %35, align 4
  %40 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 3
  store i32 %39, i32* %40, align 4, !alias.scope !960
  %41 = getelementptr inbounds i32, i32* %38, i64 1
  %42 = load i32, i32* %38, align 4
  %43 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 4
  store i32 %42, i32* %43, align 16, !alias.scope !960
  %44 = getelementptr inbounds i32, i32* %41, i64 1
  %45 = load i32, i32* %41, align 4
  %46 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 5
  store i32 %45, i32* %46, align 4, !alias.scope !960
  %47 = getelementptr inbounds i32, i32* %44, i64 1
  %48 = load i32, i32* %44, align 4
  %49 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 6
  store i32 %48, i32* %49, align 8, !alias.scope !960
  %50 = load i32, i32* %47, align 4
  %51 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 7
  store i32 %50, i32* %51, align 4, !alias.scope !960
  %52 = add nsw i32 %9, 1
  %53 = mul nsw i32 %25, %52
  %54 = sext i32 %53 to i64
  %55 = getelementptr inbounds i32, i32* %24, i64 %54
  %56 = getelementptr inbounds i32, i32* %55, i64 1
  %57 = load i32, i32* %55, align 4
  %58 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 8
  store i32 %57, i32* %58, align 16, !alias.scope !960
  %59 = getelementptr inbounds i32, i32* %56, i64 1
  %60 = load i32, i32* %56, align 4
  %61 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 9
  store i32 %60, i32* %61, align 4, !alias.scope !960
  %62 = getelementptr inbounds i32, i32* %59, i64 1
  %63 = load i32, i32* %59, align 4
  %64 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 10
  store i32 %63, i32* %64, align 8, !alias.scope !960
  %65 = getelementptr inbounds i32, i32* %62, i64 1
  %66 = load i32, i32* %62, align 4
  %67 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 11
  store i32 %66, i32* %67, align 4, !alias.scope !960
  %68 = getelementptr inbounds i32, i32* %65, i64 1
  %69 = load i32, i32* %65, align 4
  %70 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 12
  store i32 %69, i32* %70, align 16, !alias.scope !960
  %71 = getelementptr inbounds i32, i32* %68, i64 1
  %72 = load i32, i32* %68, align 4
  %73 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 13
  store i32 %72, i32* %73, align 4, !alias.scope !960
  %74 = getelementptr inbounds i32, i32* %71, i64 1
  %75 = load i32, i32* %71, align 4
  %76 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 14
  store i32 %75, i32* %76, align 8, !alias.scope !960
  %77 = load i32, i32* %74, align 4
  %78 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 15
  store i32 %77, i32* %78, align 4, !alias.scope !960
  %79 = add nsw i32 %9, 2
  %80 = mul nsw i32 %25, %79
  %81 = sext i32 %80 to i64
  %82 = getelementptr inbounds i32, i32* %24, i64 %81
  %83 = getelementptr inbounds i32, i32* %82, i64 1
  %84 = load i32, i32* %82, align 4
  %85 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 16
  store i32 %84, i32* %85, align 16, !alias.scope !960
  %86 = getelementptr inbounds i32, i32* %83, i64 1
  %87 = load i32, i32* %83, align 4
  %88 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 17
  store i32 %87, i32* %88, align 4, !alias.scope !960
  %89 = getelementptr inbounds i32, i32* %86, i64 1
  %90 = load i32, i32* %86, align 4
  %91 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 18
  store i32 %90, i32* %91, align 8, !alias.scope !960
  %92 = getelementptr inbounds i32, i32* %89, i64 1
  %93 = load i32, i32* %89, align 4
  %94 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 19
  store i32 %93, i32* %94, align 4, !alias.scope !960
  %95 = getelementptr inbounds i32, i32* %92, i64 1
  %96 = load i32, i32* %92, align 4
  %97 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 20
  store i32 %96, i32* %97, align 16, !alias.scope !960
  %98 = getelementptr inbounds i32, i32* %95, i64 1
  %99 = load i32, i32* %95, align 4
  %100 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 21
  store i32 %99, i32* %100, align 4, !alias.scope !960
  %101 = getelementptr inbounds i32, i32* %98, i64 1
  %102 = load i32, i32* %98, align 4
  %103 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 22
  store i32 %102, i32* %103, align 8, !alias.scope !960
  %104 = load i32, i32* %101, align 4
  %105 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 23
  store i32 %104, i32* %105, align 4, !alias.scope !960
  %106 = add nsw i32 %9, 3
  %107 = mul nsw i32 %25, %106
  %108 = sext i32 %107 to i64
  %109 = getelementptr inbounds i32, i32* %24, i64 %108
  %110 = getelementptr inbounds i32, i32* %109, i64 1
  %111 = load i32, i32* %109, align 4
  %112 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 24
  store i32 %111, i32* %112, align 16, !alias.scope !960
  %113 = getelementptr inbounds i32, i32* %110, i64 1
  %114 = load i32, i32* %110, align 4
  %115 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 25
  store i32 %114, i32* %115, align 4, !alias.scope !960
  %116 = getelementptr inbounds i32, i32* %113, i64 1
  %117 = load i32, i32* %113, align 4
  %118 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 26
  store i32 %117, i32* %118, align 8, !alias.scope !960
  %119 = getelementptr inbounds i32, i32* %116, i64 1
  %120 = load i32, i32* %116, align 4
  %121 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 27
  store i32 %120, i32* %121, align 4, !alias.scope !960
  %122 = getelementptr inbounds i32, i32* %119, i64 1
  %123 = load i32, i32* %119, align 4
  %124 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 28
  store i32 %123, i32* %124, align 16, !alias.scope !960
  %125 = getelementptr inbounds i32, i32* %122, i64 1
  %126 = load i32, i32* %122, align 4
  %127 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 29
  store i32 %126, i32* %127, align 4, !alias.scope !960
  %128 = getelementptr inbounds i32, i32* %125, i64 1
  %129 = load i32, i32* %125, align 4
  %130 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 30
  store i32 %129, i32* %130, align 8, !alias.scope !960
  %131 = load i32, i32* %128, align 4
  %132 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 31
  store i32 %131, i32* %132, align 4, !alias.scope !960
  %133 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %134 = load i32*, i32** %133, align 8, !noalias !963
  %135 = getelementptr i32, i32* %134, i64 %20
  %136 = bitcast i32* %135 to <4 x i32>*
  %137 = load <4 x i32>, <4 x i32>* %136, align 4
  %138 = getelementptr inbounds i32, i32* %135, i64 4
  %139 = bitcast i32* %138 to <4 x i32>*
  %140 = load <4 x i32>, <4 x i32>* %139, align 4
  %141 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %142 = load i32*, i32** %141, align 8
  %143 = sext i32 %9 to i64
  %144 = getelementptr i32, i32* %142, i64 %143
  %145 = bitcast i32* %144 to i64*
  %146 = load i64, i64* %145, align 4
  %147 = getelementptr inbounds i32, i32* %144, i64 2
  %148 = bitcast i32* %147 to i64*
  %149 = load i64, i64* %148, align 4
  %150 = lshr i64 %146, 32
  %151 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 0
  %152 = load i32, i32* %151, align 4
  %153 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %154 = load i32, i32* %153, align 4
  %155 = insertelement <4 x i32> undef, i32 %154, i32 0
  %156 = shufflevector <4 x i32> %155, <4 x i32> undef, <4 x i32> zeroinitializer
  %157 = mul nsw <4 x i32> %156, %137
  %158 = mul nsw <4 x i32> %156, %140
  %159 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to <4 x i32>*
  %160 = load <4 x i32>, <4 x i32>* %159, align 16
  %161 = add nsw <4 x i32> %160, %157
  %162 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to <4 x i32>*
  store <4 x i32> %161, <4 x i32>* %162, align 16
  %163 = bitcast i32* %43 to <4 x i32>*
  %164 = load <4 x i32>, <4 x i32>* %163, align 16
  %165 = add nsw <4 x i32> %164, %158
  %166 = bitcast i32* %43 to <4 x i32>*
  store <4 x i32> %165, <4 x i32>* %166, align 16
  %167 = bitcast i32* %58 to <4 x i32>*
  %168 = load <4 x i32>, <4 x i32>* %167, align 16
  %169 = add nsw <4 x i32> %168, %157
  %170 = bitcast i32* %58 to <4 x i32>*
  store <4 x i32> %169, <4 x i32>* %170, align 16
  %171 = bitcast i32* %70 to <4 x i32>*
  %172 = load <4 x i32>, <4 x i32>* %171, align 16
  %173 = add nsw <4 x i32> %172, %158
  %174 = bitcast i32* %70 to <4 x i32>*
  store <4 x i32> %173, <4 x i32>* %174, align 16
  %175 = bitcast i32* %85 to <4 x i32>*
  %176 = load <4 x i32>, <4 x i32>* %175, align 16
  %177 = add nsw <4 x i32> %176, %157
  %178 = bitcast i32* %85 to <4 x i32>*
  store <4 x i32> %177, <4 x i32>* %178, align 16
  %179 = bitcast i32* %97 to <4 x i32>*
  %180 = load <4 x i32>, <4 x i32>* %179, align 16
  %181 = add nsw <4 x i32> %180, %158
  %182 = bitcast i32* %97 to <4 x i32>*
  store <4 x i32> %181, <4 x i32>* %182, align 16
  %183 = bitcast i32* %112 to <4 x i32>*
  %184 = load <4 x i32>, <4 x i32>* %183, align 16
  %185 = add nsw <4 x i32> %184, %157
  %186 = bitcast i32* %112 to <4 x i32>*
  store <4 x i32> %185, <4 x i32>* %186, align 16
  %187 = bitcast i32* %124 to <4 x i32>*
  %188 = load <4 x i32>, <4 x i32>* %187, align 16
  %189 = add nsw <4 x i32> %188, %158
  %190 = bitcast i32* %124 to <4 x i32>*
  store <4 x i32> %189, <4 x i32>* %190, align 16
  %191 = trunc i64 %146 to i32
  %192 = trunc i64 %150 to i32
  %193 = mul nsw i32 %154, %7
  %194 = add nsw i32 %193, %191
  %195 = add nsw i32 %193, %192
  %196 = trunc i64 %149 to i32
  %197 = add nsw i32 %193, %196
  %198 = lshr i64 %149, 32
  %199 = trunc i64 %198 to i32
  %200 = add nsw i32 %193, %199
  %201 = mul nsw i32 %194, %152
  %202 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to <4 x i32>*
  %203 = load <4 x i32>, <4 x i32>* %202, align 16
  %204 = insertelement <4 x i32> undef, i32 %201, i32 0
  %205 = shufflevector <4 x i32> %204, <4 x i32> undef, <4 x i32> zeroinitializer
  %206 = add nsw <4 x i32> %203, %205
  %207 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to <4 x i32>*
  store <4 x i32> %206, <4 x i32>* %207, align 16
  %208 = bitcast i32* %43 to <4 x i32>*
  %209 = load <4 x i32>, <4 x i32>* %208, align 16
  %210 = add nsw <4 x i32> %209, %205
  %211 = bitcast i32* %43 to <4 x i32>*
  store <4 x i32> %210, <4 x i32>* %211, align 16
  %212 = mul nsw i32 %195, %152
  %213 = bitcast i32* %58 to <4 x i32>*
  %214 = load <4 x i32>, <4 x i32>* %213, align 16
  %215 = insertelement <4 x i32> undef, i32 %212, i32 0
  %216 = shufflevector <4 x i32> %215, <4 x i32> undef, <4 x i32> zeroinitializer
  %217 = add nsw <4 x i32> %214, %216
  %218 = bitcast i32* %58 to <4 x i32>*
  store <4 x i32> %217, <4 x i32>* %218, align 16
  %219 = bitcast i32* %70 to <4 x i32>*
  %220 = load <4 x i32>, <4 x i32>* %219, align 16
  %221 = add nsw <4 x i32> %220, %216
  %222 = bitcast i32* %70 to <4 x i32>*
  store <4 x i32> %221, <4 x i32>* %222, align 16
  %223 = mul nsw i32 %197, %152
  %224 = bitcast i32* %85 to <4 x i32>*
  %225 = load <4 x i32>, <4 x i32>* %224, align 16
  %226 = insertelement <4 x i32> undef, i32 %223, i32 0
  %227 = shufflevector <4 x i32> %226, <4 x i32> undef, <4 x i32> zeroinitializer
  %228 = add nsw <4 x i32> %225, %227
  %229 = bitcast i32* %85 to <4 x i32>*
  store <4 x i32> %228, <4 x i32>* %229, align 16
  %230 = bitcast i32* %97 to <4 x i32>*
  %231 = load <4 x i32>, <4 x i32>* %230, align 16
  %232 = add nsw <4 x i32> %231, %227
  %233 = bitcast i32* %97 to <4 x i32>*
  store <4 x i32> %232, <4 x i32>* %233, align 16
  %234 = mul nsw i32 %200, %152
  %235 = bitcast i32* %112 to <4 x i32>*
  %236 = load <4 x i32>, <4 x i32>* %235, align 16
  %237 = insertelement <4 x i32> undef, i32 %234, i32 0
  %238 = shufflevector <4 x i32> %237, <4 x i32> undef, <4 x i32> zeroinitializer
  %239 = add nsw <4 x i32> %236, %238
  %240 = bitcast i32* %112 to <4 x i32>*
  store <4 x i32> %239, <4 x i32>* %240, align 16
  %241 = bitcast i32* %124 to <4 x i32>*
  %242 = load <4 x i32>, <4 x i32>* %241, align 16
  %243 = add nsw <4 x i32> %242, %238
  %244 = bitcast i32* %124 to <4 x i32>*
  store <4 x i32> %243, <4 x i32>* %244, align 16
  %245 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %16, i64 0, i32 0, i32 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %245) #19
  %246 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.421", %"struct.gemmlowp::OutputPipelineExecutor.421"* %1, i64 0, i32 0
  call void @llvm.memset.p0i8.i64(i8* nonnull align 1 %245, i8 -86, i64 32, i1 false) #19
  call void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi0ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalES8_ii(%"struct.gemmlowp::RegisterBlock.310"* nonnull sret %16, %"struct.gemmlowp::OutputPipelineEvalImpl.422"* %246, %"struct.gemmlowp::RegisterBlock.302"* nonnull byval(%"struct.gemmlowp::RegisterBlock.302") align 8 %17, i32 %10, i32 %11) #19
  %247 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %15, i64 0, i32 0, i32 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %247) #19
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %247, i8* nonnull align 1 %245, i64 32, i1 false) #19
  %248 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %2, i64 0, i32 0
  %249 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %2, i64 0, i32 3
  %250 = sext i32 %13 to i64
  %251 = sext i32 %12 to i64
  %252 = add nsw i64 %250, 1
  %253 = add nsw i64 %250, 2
  %254 = add nsw i64 %250, 3
  br label %255

255:                                              ; preds = %255, %14
  %256 = phi i64 [ 0, %14 ], [ %293, %255 ]
  %257 = add nsw i64 %256, %251
  %258 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %15, i64 0, i32 0, i32 0, i64 %256
  %259 = load i8, i8* %258, align 1
  %260 = load i8*, i8** %248, align 8
  %261 = getelementptr inbounds i8, i8* %260, i64 %257
  %262 = load i32, i32* %249, align 8
  %263 = sext i32 %262 to i64
  %264 = mul nsw i64 %263, %250
  %265 = getelementptr inbounds i8, i8* %261, i64 %264
  store i8 %259, i8* %265, align 1
  %266 = add nuw nsw i64 %256, 8
  %267 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %15, i64 0, i32 0, i32 0, i64 %266
  %268 = load i8, i8* %267, align 1
  %269 = load i8*, i8** %248, align 8
  %270 = getelementptr inbounds i8, i8* %269, i64 %257
  %271 = load i32, i32* %249, align 8
  %272 = sext i32 %271 to i64
  %273 = mul nsw i64 %252, %272
  %274 = getelementptr inbounds i8, i8* %270, i64 %273
  store i8 %268, i8* %274, align 1
  %275 = add nuw nsw i64 %256, 16
  %276 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %15, i64 0, i32 0, i32 0, i64 %275
  %277 = load i8, i8* %276, align 1
  %278 = load i8*, i8** %248, align 8
  %279 = getelementptr inbounds i8, i8* %278, i64 %257
  %280 = load i32, i32* %249, align 8
  %281 = sext i32 %280 to i64
  %282 = mul nsw i64 %253, %281
  %283 = getelementptr inbounds i8, i8* %279, i64 %282
  store i8 %277, i8* %283, align 1
  %284 = add nuw nsw i64 %256, 24
  %285 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %15, i64 0, i32 0, i32 0, i64 %284
  %286 = load i8, i8* %285, align 1
  %287 = load i8*, i8** %248, align 8
  %288 = getelementptr inbounds i8, i8* %287, i64 %257
  %289 = load i32, i32* %249, align 8
  %290 = sext i32 %289 to i64
  %291 = mul nsw i64 %254, %290
  %292 = getelementptr inbounds i8, i8* %288, i64 %291
  store i8 %286, i8* %292, align 1
  %293 = add nuw nsw i64 %256, 1
  %294 = icmp eq i64 %293, 8
  br i1 %294, label %295, label %255

295:                                              ; preds = %255
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %247) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %245) #19
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %18) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.414"* dereferenceable(32), %"class.gemmlowp::MatrixMap.195"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBuffer.313", align 8
  %16 = alloca %"struct.gemmlowp::RegisterBuffer.313", align 8
  %17 = alloca [16 x i32], align 8
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %19 = sext i32 %8 to i64
  %20 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %21 = load i32*, i32** %18, align 8, !noalias !968
  %22 = getelementptr inbounds i32, i32* %21, i64 %19
  %23 = load i32, i32* %20, align 8, !noalias !968
  %24 = mul nsw i32 %23, %9
  %25 = sext i32 %24 to i64
  %26 = getelementptr inbounds i32, i32* %22, i64 %25
  %27 = getelementptr inbounds i32, i32* %26, i64 1
  %28 = load i32, i32* %26, align 4, !noalias !968
  %29 = getelementptr inbounds i32, i32* %27, i64 1
  %30 = load i32, i32* %27, align 4, !noalias !968
  %31 = getelementptr inbounds i32, i32* %29, i64 1
  %32 = load i32, i32* %29, align 4, !noalias !968
  %33 = load i32, i32* %31, align 4, !noalias !968
  %34 = add nsw i32 %9, 1
  %35 = mul nsw i32 %23, %34
  %36 = sext i32 %35 to i64
  %37 = getelementptr inbounds i32, i32* %22, i64 %36
  %38 = getelementptr inbounds i32, i32* %37, i64 1
  %39 = load i32, i32* %37, align 4, !noalias !968
  %40 = getelementptr inbounds i32, i32* %38, i64 1
  %41 = load i32, i32* %38, align 4, !noalias !968
  %42 = getelementptr inbounds i32, i32* %40, i64 1
  %43 = load i32, i32* %40, align 4, !noalias !968
  %44 = load i32, i32* %42, align 4, !noalias !968
  %45 = add nsw i32 %9, 2
  %46 = mul nsw i32 %23, %45
  %47 = sext i32 %46 to i64
  %48 = getelementptr inbounds i32, i32* %22, i64 %47
  %49 = getelementptr inbounds i32, i32* %48, i64 1
  %50 = load i32, i32* %48, align 4, !noalias !968
  %51 = getelementptr inbounds i32, i32* %49, i64 1
  %52 = load i32, i32* %49, align 4, !noalias !968
  %53 = getelementptr inbounds i32, i32* %51, i64 1
  %54 = load i32, i32* %51, align 4, !noalias !968
  %55 = load i32, i32* %53, align 4, !noalias !968
  %56 = add nsw i32 %9, 3
  %57 = mul nsw i32 %23, %56
  %58 = sext i32 %57 to i64
  %59 = getelementptr inbounds i32, i32* %22, i64 %58
  %60 = getelementptr inbounds i32, i32* %59, i64 1
  %61 = load i32, i32* %59, align 4, !noalias !968
  %62 = getelementptr inbounds i32, i32* %60, i64 1
  %63 = load i32, i32* %60, align 4, !noalias !968
  %64 = getelementptr inbounds i32, i32* %62, i64 1
  %65 = load i32, i32* %62, align 4, !noalias !968
  %66 = load i32, i32* %64, align 4, !noalias !968
  %67 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %68 = load i32*, i32** %67, align 8
  %69 = getelementptr i32, i32* %68, i64 %19
  %70 = bitcast i32* %69 to i64*
  %71 = load i64, i64* %70, align 4
  %72 = getelementptr inbounds i32, i32* %69, i64 2
  %73 = bitcast i32* %72 to i64*
  %74 = load i64, i64* %73, align 4
  %75 = trunc i64 %71 to i32
  %76 = lshr i64 %71, 32
  %77 = trunc i64 %76 to i32
  %78 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %79 = load i32*, i32** %78, align 8
  %80 = sext i32 %9 to i64
  %81 = getelementptr i32, i32* %79, i64 %80
  %82 = bitcast i32* %81 to i64*
  %83 = load i64, i64* %82, align 4
  %84 = getelementptr inbounds i32, i32* %81, i64 2
  %85 = bitcast i32* %84 to i64*
  %86 = load i64, i64* %85, align 4
  %87 = trunc i64 %83 to i32
  %88 = lshr i64 %83, 32
  %89 = trunc i64 %88 to i32
  %90 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 0
  %91 = load i32, i32* %90, align 4
  %92 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %93 = load i32, i32* %92, align 4
  %94 = mul nsw i32 %93, %75
  %95 = add nsw i32 %94, %28
  %96 = mul nsw i32 %93, %77
  %97 = add nsw i32 %96, %30
  %98 = trunc i64 %74 to i32
  %99 = mul nsw i32 %93, %98
  %100 = add nsw i32 %99, %32
  %101 = lshr i64 %74, 32
  %102 = trunc i64 %101 to i32
  %103 = mul nsw i32 %93, %102
  %104 = add nsw i32 %103, %33
  %105 = add nsw i32 %94, %39
  %106 = add nsw i32 %96, %41
  %107 = add nsw i32 %99, %43
  %108 = add nsw i32 %103, %44
  %109 = add nsw i32 %94, %50
  %110 = add nsw i32 %96, %52
  %111 = add nsw i32 %99, %54
  %112 = add nsw i32 %103, %55
  %113 = add nsw i32 %94, %61
  %114 = add nsw i32 %96, %63
  %115 = add nsw i32 %99, %65
  %116 = add nsw i32 %103, %66
  %117 = mul nsw i32 %93, %7
  %118 = add nsw i32 %117, %87
  %119 = add nsw i32 %117, %89
  %120 = trunc i64 %86 to i32
  %121 = add nsw i32 %117, %120
  %122 = lshr i64 %86, 32
  %123 = trunc i64 %122 to i32
  %124 = add nsw i32 %117, %123
  %125 = mul nsw i32 %118, %91
  %126 = add nsw i32 %95, %125
  %127 = add nsw i32 %97, %125
  %128 = add nsw i32 %100, %125
  %129 = add nsw i32 %104, %125
  %130 = mul nsw i32 %119, %91
  %131 = add nsw i32 %105, %130
  %132 = add nsw i32 %106, %130
  %133 = add nsw i32 %107, %130
  %134 = add nsw i32 %108, %130
  %135 = mul nsw i32 %121, %91
  %136 = add nsw i32 %109, %135
  %137 = add nsw i32 %110, %135
  %138 = add nsw i32 %111, %135
  %139 = add nsw i32 %112, %135
  %140 = mul nsw i32 %124, %91
  %141 = add nsw i32 %113, %140
  %142 = add nsw i32 %114, %140
  %143 = add nsw i32 %115, %140
  %144 = add nsw i32 %116, %140
  %145 = bitcast [16 x i32]* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %145) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %145, i8 -86, i64 64, i1 false) #19, !alias.scope !973
  %146 = bitcast %"struct.gemmlowp::RegisterBuffer.313"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %146) #19, !noalias !973
  %147 = bitcast %"struct.gemmlowp::RegisterBuffer.313"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %147) #19, !noalias !973
  %148 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %15, i64 0, i32 0, i64 0
  store i32 %126, i32* %148, align 8
  %149 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %15, i64 0, i32 0, i64 1
  store i32 %127, i32* %149, align 4
  %150 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %15, i64 0, i32 0, i64 2
  store i32 %128, i32* %150, align 8
  %151 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %15, i64 0, i32 0, i64 3
  store i32 %129, i32* %151, align 4
  %152 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %15, i64 0, i32 0, i64 4
  store i32 %131, i32* %152, align 8
  %153 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %15, i64 0, i32 0, i64 5
  store i32 %132, i32* %153, align 4
  %154 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %15, i64 0, i32 0, i64 6
  store i32 %133, i32* %154, align 8
  %155 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %15, i64 0, i32 0, i64 7
  store i32 %134, i32* %155, align 4
  %156 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %15, i64 0, i32 0, i64 8
  store i32 %136, i32* %156, align 8
  %157 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %15, i64 0, i32 0, i64 9
  store i32 %137, i32* %157, align 4
  %158 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %15, i64 0, i32 0, i64 10
  store i32 %138, i32* %158, align 8
  %159 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %15, i64 0, i32 0, i64 11
  store i32 %139, i32* %159, align 4
  %160 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %15, i64 0, i32 0, i64 12
  store i32 %141, i32* %160, align 8
  %161 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %15, i64 0, i32 0, i64 13
  store i32 %142, i32* %161, align 4
  %162 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %15, i64 0, i32 0, i64 14
  store i32 %143, i32* %162, align 8
  %163 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %15, i64 0, i32 0, i64 15
  store i32 %144, i32* %163, align 4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %146, i8 -86, i64 64, i1 false) #19, !alias.scope !976, !noalias !973
  %164 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.414", %"struct.gemmlowp::OutputPipelineExecutor.414"* %1, i64 0, i32 0, i32 0, i32 0, i32 0
  %165 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %164, align 8, !noalias !979
  %166 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %165, i64 0, i32 2
  %167 = load i32, i32* %166, align 4, !noalias !979
  %168 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.414", %"struct.gemmlowp::OutputPipelineExecutor.414"* %1, i64 0, i32 0, i32 0, i32 0, i32 1
  %169 = load i32, i32* %168, align 8, !noalias !979
  %170 = shl i32 1, %169
  %171 = sext i32 %170 to i64
  %172 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %165, i64 0, i32 0
  %173 = load i32, i32* %172, align 4, !noalias !979
  %174 = sext i32 %173 to i64
  %175 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.414", %"struct.gemmlowp::OutputPipelineExecutor.414"* %1, i64 0, i32 0, i32 0, i32 0, i32 2
  %176 = load i32, i32* %175, align 4, !noalias !979
  %177 = zext i32 %176 to i64
  %178 = shl nsw i64 -1, %177
  %179 = trunc i64 %178 to i32
  %180 = xor i32 %179, -1
  %181 = ashr i32 %180, 1
  %182 = icmp ne i32 %173, -2147483648
  br label %183

183:                                              ; preds = %216, %14
  %184 = phi i32 [ %126, %14 ], [ %218, %216 ]
  %185 = phi i64 [ 0, %14 ], [ %214, %216 ]
  %186 = sext i32 %184 to i64
  %187 = mul nsw i64 %186, %171
  %188 = icmp slt i64 %187, 2147483647
  %189 = select i1 %188, i64 %187, i64 2147483647
  %190 = icmp sgt i64 %189, -2147483648
  %191 = select i1 %190, i64 %189, i64 -2147483648
  %192 = trunc i64 %191 to i32
  %193 = icmp ne i32 %173, %192
  %194 = or i1 %182, %193
  br i1 %194, label %195, label %203

195:                                              ; preds = %183
  %196 = select i1 %193, i64 %174, i64 %191
  %197 = mul nsw i64 %196, %191
  %198 = icmp sgt i64 %197, -1
  %199 = select i1 %198, i64 1073741824, i64 -1073741823
  %200 = add nsw i64 %199, %197
  %201 = sdiv i64 %200, 2147483648
  %202 = trunc i64 %201 to i32
  br label %203

203:                                              ; preds = %195, %183
  %204 = phi i32 [ %202, %195 ], [ 2147483647, %183 ]
  %205 = and i32 %204, %180
  %206 = lshr i32 %204, 31
  %207 = add nsw i32 %206, %181
  %208 = ashr i32 %204, %176
  %209 = icmp sgt i32 %205, %207
  %210 = zext i1 %209 to i32
  %211 = add i32 %208, %167
  %212 = add i32 %211, %210
  %213 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %16, i64 0, i32 0, i64 %185
  store i32 %212, i32* %213, align 4, !alias.scope !976, !noalias !973
  %214 = add nuw nsw i64 %185, 1
  %215 = icmp eq i64 %214, 16
  br i1 %215, label %219, label %216

216:                                              ; preds = %203
  %217 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %15, i64 0, i32 0, i64 %214
  %218 = load i32, i32* %217, align 4, !noalias !979
  br label %183

219:                                              ; preds = %203
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %147) #19, !noalias !973
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %145, i8* nonnull align 8 %146, i64 64, i1 false) #19
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %146) #19, !noalias !973
  %220 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.414", %"struct.gemmlowp::OutputPipelineExecutor.414"* %1, i64 0, i32 0, i32 1
  %221 = bitcast [16 x i32]* %17 to %"struct.gemmlowp::RegisterBlock.312"*
  %222 = tail call { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi1ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalES8_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.416"* %220, %"struct.gemmlowp::RegisterBlock.312"* nonnull byval(%"struct.gemmlowp::RegisterBlock.312") align 8 %221, i32 %10, i32 %11) #19
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %145) #19
  %223 = extractvalue { i64, i64 } %222, 0
  %224 = extractvalue { i64, i64 } %222, 1
  tail call void @_ZN8gemmlowp16StoreFinalOutputINS_13RegisterBlockIhLi4ELi4EEENS_9MatrixMapIhLNS_8MapOrderE1EEEEEvT_PT0_ii(i64 %223, i64 %224, %"class.gemmlowp::MatrixMap.195"* %2, i32 %12, i32 %13) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.407"* dereferenceable(32), %"class.gemmlowp::MatrixMap.195"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %16 = sext i32 %8 to i64
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %18 = load i32*, i32** %15, align 8
  %19 = getelementptr inbounds i32, i32* %18, i64 %16
  %20 = load i32, i32* %17, align 8
  %21 = mul nsw i32 %20, %9
  %22 = sext i32 %21 to i64
  %23 = getelementptr inbounds i32, i32* %19, i64 %22
  %24 = load i32, i32* %23, align 4
  %25 = add nsw i32 %9, 1
  %26 = mul nsw i32 %20, %25
  %27 = sext i32 %26 to i64
  %28 = getelementptr inbounds i32, i32* %19, i64 %27
  %29 = load i32, i32* %28, align 4
  %30 = add nsw i32 %9, 2
  %31 = mul nsw i32 %20, %30
  %32 = sext i32 %31 to i64
  %33 = getelementptr inbounds i32, i32* %19, i64 %32
  %34 = load i32, i32* %33, align 4
  %35 = add nsw i32 %9, 3
  %36 = mul nsw i32 %20, %35
  %37 = sext i32 %36 to i64
  %38 = getelementptr inbounds i32, i32* %19, i64 %37
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %41 = load i32*, i32** %40, align 8
  %42 = getelementptr inbounds i32, i32* %41, i64 %16
  %43 = load i32, i32* %42, align 4
  %44 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %45 = load i32*, i32** %44, align 8
  %46 = sext i32 %9 to i64
  %47 = getelementptr i32, i32* %45, i64 %46
  %48 = bitcast i32* %47 to i64*
  %49 = load i64, i64* %48, align 4
  %50 = getelementptr inbounds i32, i32* %47, i64 2
  %51 = bitcast i32* %50 to i64*
  %52 = load i64, i64* %51, align 4
  %53 = trunc i64 %49 to i32
  %54 = lshr i64 %49, 32
  %55 = trunc i64 %54 to i32
  %56 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 0
  %57 = load i32, i32* %56, align 4
  %58 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %59 = load i32, i32* %58, align 4
  %60 = mul nsw i32 %59, %43
  %61 = add nsw i32 %60, %24
  %62 = add nsw i32 %60, %29
  %63 = add nsw i32 %60, %34
  %64 = add nsw i32 %60, %39
  %65 = mul nsw i32 %59, %7
  %66 = add nsw i32 %65, %53
  %67 = add nsw i32 %65, %55
  %68 = trunc i64 %52 to i32
  %69 = add nsw i32 %65, %68
  %70 = lshr i64 %52, 32
  %71 = trunc i64 %70 to i32
  %72 = add nsw i32 %65, %71
  %73 = mul nsw i32 %66, %57
  %74 = add nsw i32 %61, %73
  %75 = mul nsw i32 %67, %57
  %76 = add nsw i32 %62, %75
  %77 = mul nsw i32 %69, %57
  %78 = add nsw i32 %63, %77
  %79 = zext i32 %78 to i64
  %80 = mul nsw i32 %72, %57
  %81 = add nsw i32 %64, %80
  %82 = zext i32 %81 to i64
  %83 = shl nuw i64 %82, 32
  %84 = or i64 %83, %79
  %85 = zext i32 %76 to i64
  %86 = shl nuw i64 %85, 32
  %87 = zext i32 %74 to i64
  %88 = or i64 %86, %87
  %89 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.407", %"struct.gemmlowp::OutputPipelineExecutor.407"* %1, i64 0, i32 0, i32 0, i32 0
  %90 = tail call { i64, i64 } @_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi4EEEE4EvalES3_(%"struct.gemmlowp::OutputStageEvalBufferImpl.231"* %89, i64 %88, i64 %84) #19
  %91 = extractvalue { i64, i64 } %90, 0
  %92 = extractvalue { i64, i64 } %90, 1
  %93 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.407", %"struct.gemmlowp::OutputPipelineExecutor.407"* %1, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %94 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %93, align 8
  %95 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %94, i64 0, i32 0
  %96 = load i32, i32* %95, align 4
  %97 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %94, i64 0, i32 1
  %98 = load i32, i32* %97, align 4
  %99 = trunc i64 %91 to i32
  %100 = icmp sgt i32 %96, %99
  %101 = select i1 %100, i32 %96, i32 %99
  %102 = icmp slt i32 %98, %101
  %103 = select i1 %102, i32 %98, i32 %101
  %104 = lshr i64 %91, 32
  %105 = trunc i64 %104 to i32
  %106 = icmp sgt i32 %96, %105
  %107 = select i1 %106, i32 %96, i32 %105
  %108 = icmp slt i32 %98, %107
  %109 = select i1 %108, i32 %98, i32 %107
  %110 = trunc i64 %92 to i32
  %111 = icmp sgt i32 %96, %110
  %112 = select i1 %111, i32 %96, i32 %110
  %113 = icmp slt i32 %98, %112
  %114 = select i1 %113, i32 %98, i32 %112
  %115 = lshr i64 %92, 32
  %116 = trunc i64 %115 to i32
  %117 = icmp sgt i32 %96, %116
  %118 = select i1 %117, i32 %96, i32 %116
  %119 = icmp slt i32 %98, %118
  %120 = select i1 %119, i32 %98, i32 %118
  %121 = icmp sgt i32 %103, 0
  %122 = select i1 %121, i32 %103, i32 0
  %123 = icmp slt i32 %122, 255
  %124 = select i1 %123, i32 %122, i32 255
  %125 = icmp sgt i32 %109, 0
  %126 = select i1 %125, i32 %109, i32 0
  %127 = icmp slt i32 %126, 255
  %128 = select i1 %127, i32 %126, i32 255
  %129 = icmp sgt i32 %114, 0
  %130 = select i1 %129, i32 %114, i32 0
  %131 = icmp slt i32 %130, 255
  %132 = select i1 %131, i32 %130, i32 255
  %133 = icmp sgt i32 %120, 0
  %134 = select i1 %133, i32 %120, i32 0
  %135 = icmp slt i32 %134, 255
  %136 = select i1 %135, i32 %134, i32 255
  %137 = trunc i32 %124 to i8
  %138 = trunc i32 %128 to i8
  %139 = trunc i32 %132 to i8
  %140 = trunc i32 %136 to i8
  %141 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %2, i64 0, i32 0
  %142 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %2, i64 0, i32 3
  %143 = sext i32 %13 to i64
  %144 = sext i32 %12 to i64
  %145 = load i8*, i8** %141, align 8
  %146 = load i32, i32* %142, align 8
  %147 = sext i32 %146 to i64
  %148 = mul nsw i64 %147, %144
  %149 = getelementptr inbounds i8, i8* %145, i64 %148
  %150 = getelementptr inbounds i8, i8* %149, i64 %143
  store i8 %137, i8* %150, align 1
  %151 = add nsw i64 %143, 1
  %152 = load i8*, i8** %141, align 8
  %153 = load i32, i32* %142, align 8
  %154 = sext i32 %153 to i64
  %155 = mul nsw i64 %154, %144
  %156 = getelementptr inbounds i8, i8* %152, i64 %155
  %157 = getelementptr inbounds i8, i8* %156, i64 %151
  store i8 %138, i8* %157, align 1
  %158 = add nsw i64 %143, 2
  %159 = load i8*, i8** %141, align 8
  %160 = load i32, i32* %142, align 8
  %161 = sext i32 %160 to i64
  %162 = mul nsw i64 %161, %144
  %163 = getelementptr inbounds i8, i8* %159, i64 %162
  %164 = getelementptr inbounds i8, i8* %163, i64 %158
  store i8 %139, i8* %164, align 1
  %165 = add nsw i64 %143, 3
  %166 = load i8*, i8** %141, align 8
  %167 = load i32, i32* %142, align 8
  %168 = sext i32 %167 to i64
  %169 = mul nsw i64 %168, %144
  %170 = getelementptr inbounds i8, i8* %166, i64 %169
  %171 = getelementptr inbounds i8, i8* %170, i64 %165
  store i8 %140, i8* %171, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.421"* dereferenceable(32), %"class.gemmlowp::MatrixMap.195"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.310", align 8
  %16 = alloca %"struct.gemmlowp::RegisterBlock.310", align 1
  %17 = alloca %"struct.gemmlowp::RegisterBlock.302", align 16
  %18 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %18) #19
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %20 = sext i32 %8 to i64
  %21 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %22 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %22, i8 -86, i64 128, i1 false)
  %23 = load i32*, i32** %19, align 8, !noalias !980
  %24 = getelementptr inbounds i32, i32* %23, i64 %20
  %25 = load i32, i32* %21, align 8, !noalias !980
  %26 = mul nsw i32 %25, %9
  %27 = sext i32 %26 to i64
  %28 = getelementptr inbounds i32, i32* %24, i64 %27
  %29 = getelementptr inbounds i32, i32* %28, i64 1
  %30 = load i32, i32* %28, align 4
  %31 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 0
  store i32 %30, i32* %31, align 16, !alias.scope !980
  %32 = getelementptr inbounds i32, i32* %29, i64 1
  %33 = load i32, i32* %29, align 4
  %34 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 1
  store i32 %33, i32* %34, align 4, !alias.scope !980
  %35 = getelementptr inbounds i32, i32* %32, i64 1
  %36 = load i32, i32* %32, align 4
  %37 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 2
  store i32 %36, i32* %37, align 8, !alias.scope !980
  %38 = getelementptr inbounds i32, i32* %35, i64 1
  %39 = load i32, i32* %35, align 4
  %40 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 3
  store i32 %39, i32* %40, align 4, !alias.scope !980
  %41 = getelementptr inbounds i32, i32* %38, i64 1
  %42 = load i32, i32* %38, align 4
  %43 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 4
  store i32 %42, i32* %43, align 16, !alias.scope !980
  %44 = getelementptr inbounds i32, i32* %41, i64 1
  %45 = load i32, i32* %41, align 4
  %46 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 5
  store i32 %45, i32* %46, align 4, !alias.scope !980
  %47 = getelementptr inbounds i32, i32* %44, i64 1
  %48 = load i32, i32* %44, align 4
  %49 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 6
  store i32 %48, i32* %49, align 8, !alias.scope !980
  %50 = load i32, i32* %47, align 4
  %51 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 7
  store i32 %50, i32* %51, align 4, !alias.scope !980
  %52 = add nsw i32 %9, 1
  %53 = mul nsw i32 %25, %52
  %54 = sext i32 %53 to i64
  %55 = getelementptr inbounds i32, i32* %24, i64 %54
  %56 = getelementptr inbounds i32, i32* %55, i64 1
  %57 = load i32, i32* %55, align 4
  %58 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 8
  store i32 %57, i32* %58, align 16, !alias.scope !980
  %59 = getelementptr inbounds i32, i32* %56, i64 1
  %60 = load i32, i32* %56, align 4
  %61 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 9
  store i32 %60, i32* %61, align 4, !alias.scope !980
  %62 = getelementptr inbounds i32, i32* %59, i64 1
  %63 = load i32, i32* %59, align 4
  %64 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 10
  store i32 %63, i32* %64, align 8, !alias.scope !980
  %65 = getelementptr inbounds i32, i32* %62, i64 1
  %66 = load i32, i32* %62, align 4
  %67 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 11
  store i32 %66, i32* %67, align 4, !alias.scope !980
  %68 = getelementptr inbounds i32, i32* %65, i64 1
  %69 = load i32, i32* %65, align 4
  %70 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 12
  store i32 %69, i32* %70, align 16, !alias.scope !980
  %71 = getelementptr inbounds i32, i32* %68, i64 1
  %72 = load i32, i32* %68, align 4
  %73 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 13
  store i32 %72, i32* %73, align 4, !alias.scope !980
  %74 = getelementptr inbounds i32, i32* %71, i64 1
  %75 = load i32, i32* %71, align 4
  %76 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 14
  store i32 %75, i32* %76, align 8, !alias.scope !980
  %77 = load i32, i32* %74, align 4
  %78 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 15
  store i32 %77, i32* %78, align 4, !alias.scope !980
  %79 = add nsw i32 %9, 2
  %80 = mul nsw i32 %25, %79
  %81 = sext i32 %80 to i64
  %82 = getelementptr inbounds i32, i32* %24, i64 %81
  %83 = getelementptr inbounds i32, i32* %82, i64 1
  %84 = load i32, i32* %82, align 4
  %85 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 16
  store i32 %84, i32* %85, align 16, !alias.scope !980
  %86 = getelementptr inbounds i32, i32* %83, i64 1
  %87 = load i32, i32* %83, align 4
  %88 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 17
  store i32 %87, i32* %88, align 4, !alias.scope !980
  %89 = getelementptr inbounds i32, i32* %86, i64 1
  %90 = load i32, i32* %86, align 4
  %91 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 18
  store i32 %90, i32* %91, align 8, !alias.scope !980
  %92 = getelementptr inbounds i32, i32* %89, i64 1
  %93 = load i32, i32* %89, align 4
  %94 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 19
  store i32 %93, i32* %94, align 4, !alias.scope !980
  %95 = getelementptr inbounds i32, i32* %92, i64 1
  %96 = load i32, i32* %92, align 4
  %97 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 20
  store i32 %96, i32* %97, align 16, !alias.scope !980
  %98 = getelementptr inbounds i32, i32* %95, i64 1
  %99 = load i32, i32* %95, align 4
  %100 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 21
  store i32 %99, i32* %100, align 4, !alias.scope !980
  %101 = getelementptr inbounds i32, i32* %98, i64 1
  %102 = load i32, i32* %98, align 4
  %103 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 22
  store i32 %102, i32* %103, align 8, !alias.scope !980
  %104 = load i32, i32* %101, align 4
  %105 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 23
  store i32 %104, i32* %105, align 4, !alias.scope !980
  %106 = add nsw i32 %9, 3
  %107 = mul nsw i32 %25, %106
  %108 = sext i32 %107 to i64
  %109 = getelementptr inbounds i32, i32* %24, i64 %108
  %110 = getelementptr inbounds i32, i32* %109, i64 1
  %111 = load i32, i32* %109, align 4
  %112 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 24
  store i32 %111, i32* %112, align 16, !alias.scope !980
  %113 = getelementptr inbounds i32, i32* %110, i64 1
  %114 = load i32, i32* %110, align 4
  %115 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 25
  store i32 %114, i32* %115, align 4, !alias.scope !980
  %116 = getelementptr inbounds i32, i32* %113, i64 1
  %117 = load i32, i32* %113, align 4
  %118 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 26
  store i32 %117, i32* %118, align 8, !alias.scope !980
  %119 = getelementptr inbounds i32, i32* %116, i64 1
  %120 = load i32, i32* %116, align 4
  %121 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 27
  store i32 %120, i32* %121, align 4, !alias.scope !980
  %122 = getelementptr inbounds i32, i32* %119, i64 1
  %123 = load i32, i32* %119, align 4
  %124 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 28
  store i32 %123, i32* %124, align 16, !alias.scope !980
  %125 = getelementptr inbounds i32, i32* %122, i64 1
  %126 = load i32, i32* %122, align 4
  %127 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 29
  store i32 %126, i32* %127, align 4, !alias.scope !980
  %128 = getelementptr inbounds i32, i32* %125, i64 1
  %129 = load i32, i32* %125, align 4
  %130 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 30
  store i32 %129, i32* %130, align 8, !alias.scope !980
  %131 = load i32, i32* %128, align 4
  %132 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 31
  store i32 %131, i32* %132, align 4, !alias.scope !980
  %133 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %134 = load i32*, i32** %133, align 8, !noalias !983
  %135 = getelementptr i32, i32* %134, i64 %20
  %136 = bitcast i32* %135 to <4 x i32>*
  %137 = load <4 x i32>, <4 x i32>* %136, align 4
  %138 = getelementptr inbounds i32, i32* %135, i64 4
  %139 = bitcast i32* %138 to <4 x i32>*
  %140 = load <4 x i32>, <4 x i32>* %139, align 4
  %141 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %142 = load i32*, i32** %141, align 8
  %143 = sext i32 %9 to i64
  %144 = getelementptr i32, i32* %142, i64 %143
  %145 = bitcast i32* %144 to i64*
  %146 = load i64, i64* %145, align 4
  %147 = getelementptr inbounds i32, i32* %144, i64 2
  %148 = bitcast i32* %147 to i64*
  %149 = load i64, i64* %148, align 4
  %150 = lshr i64 %146, 32
  %151 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 0
  %152 = load i32, i32* %151, align 4
  %153 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %154 = load i32, i32* %153, align 4
  %155 = insertelement <4 x i32> undef, i32 %154, i32 0
  %156 = shufflevector <4 x i32> %155, <4 x i32> undef, <4 x i32> zeroinitializer
  %157 = mul nsw <4 x i32> %156, %137
  %158 = mul nsw <4 x i32> %156, %140
  %159 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to <4 x i32>*
  %160 = load <4 x i32>, <4 x i32>* %159, align 16
  %161 = add nsw <4 x i32> %160, %157
  %162 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to <4 x i32>*
  store <4 x i32> %161, <4 x i32>* %162, align 16
  %163 = bitcast i32* %43 to <4 x i32>*
  %164 = load <4 x i32>, <4 x i32>* %163, align 16
  %165 = add nsw <4 x i32> %164, %158
  %166 = bitcast i32* %43 to <4 x i32>*
  store <4 x i32> %165, <4 x i32>* %166, align 16
  %167 = bitcast i32* %58 to <4 x i32>*
  %168 = load <4 x i32>, <4 x i32>* %167, align 16
  %169 = add nsw <4 x i32> %168, %157
  %170 = bitcast i32* %58 to <4 x i32>*
  store <4 x i32> %169, <4 x i32>* %170, align 16
  %171 = bitcast i32* %70 to <4 x i32>*
  %172 = load <4 x i32>, <4 x i32>* %171, align 16
  %173 = add nsw <4 x i32> %172, %158
  %174 = bitcast i32* %70 to <4 x i32>*
  store <4 x i32> %173, <4 x i32>* %174, align 16
  %175 = bitcast i32* %85 to <4 x i32>*
  %176 = load <4 x i32>, <4 x i32>* %175, align 16
  %177 = add nsw <4 x i32> %176, %157
  %178 = bitcast i32* %85 to <4 x i32>*
  store <4 x i32> %177, <4 x i32>* %178, align 16
  %179 = bitcast i32* %97 to <4 x i32>*
  %180 = load <4 x i32>, <4 x i32>* %179, align 16
  %181 = add nsw <4 x i32> %180, %158
  %182 = bitcast i32* %97 to <4 x i32>*
  store <4 x i32> %181, <4 x i32>* %182, align 16
  %183 = bitcast i32* %112 to <4 x i32>*
  %184 = load <4 x i32>, <4 x i32>* %183, align 16
  %185 = add nsw <4 x i32> %184, %157
  %186 = bitcast i32* %112 to <4 x i32>*
  store <4 x i32> %185, <4 x i32>* %186, align 16
  %187 = bitcast i32* %124 to <4 x i32>*
  %188 = load <4 x i32>, <4 x i32>* %187, align 16
  %189 = add nsw <4 x i32> %188, %158
  %190 = bitcast i32* %124 to <4 x i32>*
  store <4 x i32> %189, <4 x i32>* %190, align 16
  %191 = trunc i64 %146 to i32
  %192 = trunc i64 %150 to i32
  %193 = mul nsw i32 %154, %7
  %194 = add nsw i32 %193, %191
  %195 = add nsw i32 %193, %192
  %196 = trunc i64 %149 to i32
  %197 = add nsw i32 %193, %196
  %198 = lshr i64 %149, 32
  %199 = trunc i64 %198 to i32
  %200 = add nsw i32 %193, %199
  %201 = mul nsw i32 %194, %152
  %202 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to <4 x i32>*
  %203 = load <4 x i32>, <4 x i32>* %202, align 16
  %204 = insertelement <4 x i32> undef, i32 %201, i32 0
  %205 = shufflevector <4 x i32> %204, <4 x i32> undef, <4 x i32> zeroinitializer
  %206 = add nsw <4 x i32> %203, %205
  %207 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to <4 x i32>*
  store <4 x i32> %206, <4 x i32>* %207, align 16
  %208 = bitcast i32* %43 to <4 x i32>*
  %209 = load <4 x i32>, <4 x i32>* %208, align 16
  %210 = add nsw <4 x i32> %209, %205
  %211 = bitcast i32* %43 to <4 x i32>*
  store <4 x i32> %210, <4 x i32>* %211, align 16
  %212 = mul nsw i32 %195, %152
  %213 = bitcast i32* %58 to <4 x i32>*
  %214 = load <4 x i32>, <4 x i32>* %213, align 16
  %215 = insertelement <4 x i32> undef, i32 %212, i32 0
  %216 = shufflevector <4 x i32> %215, <4 x i32> undef, <4 x i32> zeroinitializer
  %217 = add nsw <4 x i32> %214, %216
  %218 = bitcast i32* %58 to <4 x i32>*
  store <4 x i32> %217, <4 x i32>* %218, align 16
  %219 = bitcast i32* %70 to <4 x i32>*
  %220 = load <4 x i32>, <4 x i32>* %219, align 16
  %221 = add nsw <4 x i32> %220, %216
  %222 = bitcast i32* %70 to <4 x i32>*
  store <4 x i32> %221, <4 x i32>* %222, align 16
  %223 = mul nsw i32 %197, %152
  %224 = bitcast i32* %85 to <4 x i32>*
  %225 = load <4 x i32>, <4 x i32>* %224, align 16
  %226 = insertelement <4 x i32> undef, i32 %223, i32 0
  %227 = shufflevector <4 x i32> %226, <4 x i32> undef, <4 x i32> zeroinitializer
  %228 = add nsw <4 x i32> %225, %227
  %229 = bitcast i32* %85 to <4 x i32>*
  store <4 x i32> %228, <4 x i32>* %229, align 16
  %230 = bitcast i32* %97 to <4 x i32>*
  %231 = load <4 x i32>, <4 x i32>* %230, align 16
  %232 = add nsw <4 x i32> %231, %227
  %233 = bitcast i32* %97 to <4 x i32>*
  store <4 x i32> %232, <4 x i32>* %233, align 16
  %234 = mul nsw i32 %200, %152
  %235 = bitcast i32* %112 to <4 x i32>*
  %236 = load <4 x i32>, <4 x i32>* %235, align 16
  %237 = insertelement <4 x i32> undef, i32 %234, i32 0
  %238 = shufflevector <4 x i32> %237, <4 x i32> undef, <4 x i32> zeroinitializer
  %239 = add nsw <4 x i32> %236, %238
  %240 = bitcast i32* %112 to <4 x i32>*
  store <4 x i32> %239, <4 x i32>* %240, align 16
  %241 = bitcast i32* %124 to <4 x i32>*
  %242 = load <4 x i32>, <4 x i32>* %241, align 16
  %243 = add nsw <4 x i32> %242, %238
  %244 = bitcast i32* %124 to <4 x i32>*
  store <4 x i32> %243, <4 x i32>* %244, align 16
  %245 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %16, i64 0, i32 0, i32 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %245) #19
  %246 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.421", %"struct.gemmlowp::OutputPipelineExecutor.421"* %1, i64 0, i32 0
  call void @llvm.memset.p0i8.i64(i8* nonnull align 1 %245, i8 -86, i64 32, i1 false) #19
  call void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi0ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalES8_ii(%"struct.gemmlowp::RegisterBlock.310"* nonnull sret %16, %"struct.gemmlowp::OutputPipelineEvalImpl.422"* %246, %"struct.gemmlowp::RegisterBlock.302"* nonnull byval(%"struct.gemmlowp::RegisterBlock.302") align 8 %17, i32 %10, i32 %11) #19
  %247 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %15, i64 0, i32 0, i32 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %247) #19
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %247, i8* nonnull align 1 %245, i64 32, i1 false) #19
  %248 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %2, i64 0, i32 0
  %249 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %2, i64 0, i32 3
  %250 = sext i32 %13 to i64
  %251 = sext i32 %12 to i64
  %252 = add nsw i64 %250, 1
  %253 = add nsw i64 %250, 2
  %254 = add nsw i64 %250, 3
  br label %255

255:                                              ; preds = %255, %14
  %256 = phi i64 [ 0, %14 ], [ %293, %255 ]
  %257 = add nsw i64 %256, %251
  %258 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %15, i64 0, i32 0, i32 0, i64 %256
  %259 = load i8, i8* %258, align 1
  %260 = load i8*, i8** %248, align 8
  %261 = load i32, i32* %249, align 8
  %262 = sext i32 %261 to i64
  %263 = mul nsw i64 %257, %262
  %264 = getelementptr inbounds i8, i8* %260, i64 %250
  %265 = getelementptr inbounds i8, i8* %264, i64 %263
  store i8 %259, i8* %265, align 1
  %266 = add nuw nsw i64 %256, 8
  %267 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %15, i64 0, i32 0, i32 0, i64 %266
  %268 = load i8, i8* %267, align 1
  %269 = load i8*, i8** %248, align 8
  %270 = load i32, i32* %249, align 8
  %271 = sext i32 %270 to i64
  %272 = mul nsw i64 %257, %271
  %273 = getelementptr inbounds i8, i8* %269, i64 %252
  %274 = getelementptr inbounds i8, i8* %273, i64 %272
  store i8 %268, i8* %274, align 1
  %275 = add nuw nsw i64 %256, 16
  %276 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %15, i64 0, i32 0, i32 0, i64 %275
  %277 = load i8, i8* %276, align 1
  %278 = load i8*, i8** %248, align 8
  %279 = load i32, i32* %249, align 8
  %280 = sext i32 %279 to i64
  %281 = mul nsw i64 %257, %280
  %282 = getelementptr inbounds i8, i8* %278, i64 %253
  %283 = getelementptr inbounds i8, i8* %282, i64 %281
  store i8 %277, i8* %283, align 1
  %284 = add nuw nsw i64 %256, 24
  %285 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %15, i64 0, i32 0, i32 0, i64 %284
  %286 = load i8, i8* %285, align 1
  %287 = load i8*, i8** %248, align 8
  %288 = load i32, i32* %249, align 8
  %289 = sext i32 %288 to i64
  %290 = mul nsw i64 %257, %289
  %291 = getelementptr inbounds i8, i8* %287, i64 %254
  %292 = getelementptr inbounds i8, i8* %291, i64 %290
  store i8 %286, i8* %292, align 1
  %293 = add nuw nsw i64 %256, 1
  %294 = icmp eq i64 %293, 8
  br i1 %294, label %295, label %255

295:                                              ; preds = %255
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %247) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %245) #19
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %18) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.400"* dereferenceable(32), %"class.gemmlowp::MatrixMap.195"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.304", align 16
  %16 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %17 = sext i32 %8 to i64
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %19 = load i32*, i32** %16, align 8, !noalias !988
  %20 = getelementptr inbounds i32, i32* %19, i64 %17
  %21 = load i32, i32* %18, align 8, !noalias !988
  %22 = mul nsw i32 %21, %9
  %23 = sext i32 %22 to i64
  %24 = getelementptr inbounds i32, i32* %20, i64 %23
  %25 = getelementptr inbounds i32, i32* %24, i64 1
  %26 = getelementptr inbounds i32, i32* %25, i64 1
  %27 = getelementptr inbounds i32, i32* %26, i64 1
  %28 = getelementptr inbounds i32, i32* %27, i64 1
  %29 = bitcast i32* %24 to <4 x i32>*
  %30 = load <4 x i32>, <4 x i32>* %29, align 4, !noalias !988
  %31 = getelementptr inbounds i32, i32* %28, i64 1
  %32 = load i32, i32* %28, align 4, !noalias !988
  %33 = getelementptr inbounds i32, i32* %31, i64 1
  %34 = load i32, i32* %31, align 4, !noalias !988
  %35 = getelementptr inbounds i32, i32* %33, i64 1
  %36 = load i32, i32* %33, align 4, !noalias !988
  %37 = load i32, i32* %35, align 4, !noalias !988
  %38 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %39 = load i32*, i32** %38, align 8, !noalias !993
  %40 = getelementptr i32, i32* %39, i64 %17
  %41 = bitcast i32* %40 to <4 x i32>*
  %42 = load <4 x i32>, <4 x i32>* %41, align 4
  %43 = getelementptr inbounds i32, i32* %40, i64 4
  %44 = bitcast i32* %43 to <4 x i32>*
  %45 = load <4 x i32>, <4 x i32>* %44, align 4
  %46 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %47 = load i32*, i32** %46, align 8
  %48 = sext i32 %9 to i64
  %49 = getelementptr inbounds i32, i32* %47, i64 %48
  %50 = load i32, i32* %49, align 4
  %51 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 0
  %52 = load i32, i32* %51, align 4
  %53 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %54 = load i32, i32* %53, align 4
  %55 = insertelement <4 x i32> undef, i32 %54, i32 0
  %56 = shufflevector <4 x i32> %55, <4 x i32> undef, <4 x i32> zeroinitializer
  %57 = mul nsw <4 x i32> %56, %42
  %58 = add nsw <4 x i32> %57, %30
  %59 = mul nsw <4 x i32> %56, %45
  %60 = insertelement <4 x i32> undef, i32 %32, i32 0
  %61 = insertelement <4 x i32> %60, i32 %34, i32 1
  %62 = insertelement <4 x i32> %61, i32 %36, i32 2
  %63 = insertelement <4 x i32> %62, i32 %37, i32 3
  %64 = add nsw <4 x i32> %59, %63
  %65 = mul nsw i32 %54, %7
  %66 = add nsw i32 %65, %50
  %67 = mul nsw i32 %66, %52
  %68 = insertelement <4 x i32> undef, i32 %67, i32 0
  %69 = shufflevector <4 x i32> %68, <4 x i32> undef, <4 x i32> zeroinitializer
  %70 = add nsw <4 x i32> %58, %69
  %71 = add nsw <4 x i32> %64, %69
  %72 = bitcast %"struct.gemmlowp::RegisterBlock.304"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %72)
  %73 = bitcast %"struct.gemmlowp::RegisterBlock.304"* %15 to <4 x i32>*
  store <4 x i32> %70, <4 x i32>* %73, align 16
  %74 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %15, i64 0, i32 0, i32 0, i64 4
  %75 = bitcast i32* %74 to <4 x i32>*
  store <4 x i32> %71, <4 x i32>* %75, align 16
  %76 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.400", %"struct.gemmlowp::OutputPipelineExecutor.400"* %1, i64 0, i32 0
  %77 = tail call i64 @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi0ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalES8_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.401"* %76, %"struct.gemmlowp::RegisterBlock.304"* nonnull byval(%"struct.gemmlowp::RegisterBlock.304") align 8 %15, i32 %10, i32 %11) #19
  %78 = trunc i64 %77 to i8
  %79 = lshr i64 %77, 8
  %80 = trunc i64 %79 to i8
  %81 = lshr i64 %77, 16
  %82 = trunc i64 %81 to i8
  %83 = lshr i64 %77, 24
  %84 = trunc i64 %83 to i8
  %85 = lshr i64 %77, 32
  %86 = trunc i64 %85 to i8
  %87 = lshr i64 %77, 40
  %88 = trunc i64 %87 to i8
  %89 = lshr i64 %77, 48
  %90 = trunc i64 %89 to i8
  %91 = lshr i64 %77, 56
  %92 = trunc i64 %91 to i8
  %93 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %2, i64 0, i32 0
  %94 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %2, i64 0, i32 3
  %95 = sext i32 %12 to i64
  %96 = load i8*, i8** %93, align 8
  %97 = load i32, i32* %94, align 8
  %98 = sext i32 %97 to i64
  %99 = mul nsw i64 %98, %95
  %100 = getelementptr inbounds i8, i8* %96, i64 %99
  %101 = sext i32 %13 to i64
  %102 = getelementptr inbounds i8, i8* %100, i64 %101
  store i8 %78, i8* %102, align 1
  %103 = add nsw i64 %95, 1
  %104 = load i8*, i8** %93, align 8
  %105 = load i32, i32* %94, align 8
  %106 = sext i32 %105 to i64
  %107 = mul nsw i64 %103, %106
  %108 = getelementptr inbounds i8, i8* %104, i64 %107
  %109 = getelementptr inbounds i8, i8* %108, i64 %101
  store i8 %80, i8* %109, align 1
  %110 = add nsw i64 %95, 2
  %111 = load i8*, i8** %93, align 8
  %112 = load i32, i32* %94, align 8
  %113 = sext i32 %112 to i64
  %114 = mul nsw i64 %110, %113
  %115 = getelementptr inbounds i8, i8* %111, i64 %114
  %116 = getelementptr inbounds i8, i8* %115, i64 %101
  store i8 %82, i8* %116, align 1
  %117 = add nsw i64 %95, 3
  %118 = load i8*, i8** %93, align 8
  %119 = load i32, i32* %94, align 8
  %120 = sext i32 %119 to i64
  %121 = mul nsw i64 %117, %120
  %122 = getelementptr inbounds i8, i8* %118, i64 %121
  %123 = getelementptr inbounds i8, i8* %122, i64 %101
  store i8 %84, i8* %123, align 1
  %124 = add nsw i64 %95, 4
  %125 = load i8*, i8** %93, align 8
  %126 = load i32, i32* %94, align 8
  %127 = sext i32 %126 to i64
  %128 = mul nsw i64 %124, %127
  %129 = getelementptr inbounds i8, i8* %125, i64 %128
  %130 = getelementptr inbounds i8, i8* %129, i64 %101
  store i8 %86, i8* %130, align 1
  %131 = add nsw i64 %95, 5
  %132 = load i8*, i8** %93, align 8
  %133 = load i32, i32* %94, align 8
  %134 = sext i32 %133 to i64
  %135 = mul nsw i64 %131, %134
  %136 = getelementptr inbounds i8, i8* %132, i64 %135
  %137 = getelementptr inbounds i8, i8* %136, i64 %101
  store i8 %88, i8* %137, align 1
  %138 = add nsw i64 %95, 6
  %139 = load i8*, i8** %93, align 8
  %140 = load i32, i32* %94, align 8
  %141 = sext i32 %140 to i64
  %142 = mul nsw i64 %138, %141
  %143 = getelementptr inbounds i8, i8* %139, i64 %142
  %144 = getelementptr inbounds i8, i8* %143, i64 %101
  store i8 %90, i8* %144, align 1
  %145 = add nsw i64 %95, 7
  %146 = load i8*, i8** %93, align 8
  %147 = load i32, i32* %94, align 8
  %148 = sext i32 %147 to i64
  %149 = mul nsw i64 %145, %148
  %150 = getelementptr inbounds i8, i8* %146, i64 %149
  %151 = getelementptr inbounds i8, i8* %150, i64 %101
  store i8 %92, i8* %151, align 1
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %72)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.393"* dereferenceable(32), %"class.gemmlowp::MatrixMap.195"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %16 = sext i32 %8 to i64
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %18 = load i32*, i32** %15, align 8
  %19 = getelementptr inbounds i32, i32* %18, i64 %16
  %20 = load i32, i32* %17, align 8
  %21 = mul nsw i32 %20, %9
  %22 = sext i32 %21 to i64
  %23 = getelementptr inbounds i32, i32* %19, i64 %22
  %24 = getelementptr inbounds i32, i32* %23, i64 1
  %25 = load i32, i32* %23, align 4
  %26 = getelementptr inbounds i32, i32* %24, i64 1
  %27 = load i32, i32* %24, align 4
  %28 = getelementptr inbounds i32, i32* %26, i64 1
  %29 = load i32, i32* %26, align 4
  %30 = load i32, i32* %28, align 4
  %31 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %32 = load i32*, i32** %31, align 8
  %33 = getelementptr i32, i32* %32, i64 %16
  %34 = bitcast i32* %33 to i64*
  %35 = load i64, i64* %34, align 4
  %36 = getelementptr inbounds i32, i32* %33, i64 2
  %37 = bitcast i32* %36 to i64*
  %38 = load i64, i64* %37, align 4
  %39 = trunc i64 %35 to i32
  %40 = lshr i64 %35, 32
  %41 = trunc i64 %40 to i32
  %42 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %43 = load i32*, i32** %42, align 8
  %44 = sext i32 %9 to i64
  %45 = getelementptr inbounds i32, i32* %43, i64 %44
  %46 = load i32, i32* %45, align 4
  %47 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 0
  %48 = load i32, i32* %47, align 4
  %49 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %50 = load i32, i32* %49, align 4
  %51 = mul nsw i32 %50, %39
  %52 = add nsw i32 %51, %25
  %53 = mul nsw i32 %50, %41
  %54 = add nsw i32 %53, %27
  %55 = trunc i64 %38 to i32
  %56 = mul nsw i32 %50, %55
  %57 = add nsw i32 %56, %29
  %58 = lshr i64 %38, 32
  %59 = trunc i64 %58 to i32
  %60 = mul nsw i32 %50, %59
  %61 = add nsw i32 %60, %30
  %62 = mul nsw i32 %50, %7
  %63 = add nsw i32 %62, %46
  %64 = mul nsw i32 %63, %48
  %65 = add nsw i32 %52, %64
  %66 = add nsw i32 %54, %64
  %67 = add nsw i32 %57, %64
  %68 = zext i32 %67 to i64
  %69 = add nsw i32 %61, %64
  %70 = zext i32 %69 to i64
  %71 = shl nuw i64 %70, 32
  %72 = or i64 %71, %68
  %73 = zext i32 %66 to i64
  %74 = shl nuw i64 %73, 32
  %75 = zext i32 %65 to i64
  %76 = or i64 %74, %75
  %77 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.393", %"struct.gemmlowp::OutputPipelineExecutor.393"* %1, i64 0, i32 0, i32 0, i32 0
  %78 = tail call { i64, i64 } @_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi4EEEE4EvalES3_(%"struct.gemmlowp::OutputStageEvalBufferImpl.231"* %77, i64 %76, i64 %72) #19
  %79 = extractvalue { i64, i64 } %78, 0
  %80 = extractvalue { i64, i64 } %78, 1
  %81 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.393", %"struct.gemmlowp::OutputPipelineExecutor.393"* %1, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %82 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %81, align 8
  %83 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %82, i64 0, i32 0
  %84 = load i32, i32* %83, align 4
  %85 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %82, i64 0, i32 1
  %86 = load i32, i32* %85, align 4
  %87 = trunc i64 %79 to i32
  %88 = icmp sgt i32 %84, %87
  %89 = select i1 %88, i32 %84, i32 %87
  %90 = icmp slt i32 %86, %89
  %91 = select i1 %90, i32 %86, i32 %89
  %92 = lshr i64 %79, 32
  %93 = trunc i64 %92 to i32
  %94 = icmp sgt i32 %84, %93
  %95 = select i1 %94, i32 %84, i32 %93
  %96 = icmp slt i32 %86, %95
  %97 = select i1 %96, i32 %86, i32 %95
  %98 = trunc i64 %80 to i32
  %99 = icmp sgt i32 %84, %98
  %100 = select i1 %99, i32 %84, i32 %98
  %101 = icmp slt i32 %86, %100
  %102 = select i1 %101, i32 %86, i32 %100
  %103 = lshr i64 %80, 32
  %104 = trunc i64 %103 to i32
  %105 = icmp sgt i32 %84, %104
  %106 = select i1 %105, i32 %84, i32 %104
  %107 = icmp slt i32 %86, %106
  %108 = select i1 %107, i32 %86, i32 %106
  %109 = icmp sgt i32 %91, 0
  %110 = select i1 %109, i32 %91, i32 0
  %111 = icmp slt i32 %110, 255
  %112 = select i1 %111, i32 %110, i32 255
  %113 = icmp sgt i32 %97, 0
  %114 = select i1 %113, i32 %97, i32 0
  %115 = icmp slt i32 %114, 255
  %116 = select i1 %115, i32 %114, i32 255
  %117 = icmp sgt i32 %102, 0
  %118 = select i1 %117, i32 %102, i32 0
  %119 = icmp slt i32 %118, 255
  %120 = select i1 %119, i32 %118, i32 255
  %121 = icmp sgt i32 %108, 0
  %122 = select i1 %121, i32 %108, i32 0
  %123 = icmp slt i32 %122, 255
  %124 = select i1 %123, i32 %122, i32 255
  %125 = trunc i32 %112 to i8
  %126 = trunc i32 %116 to i8
  %127 = trunc i32 %120 to i8
  %128 = trunc i32 %124 to i8
  %129 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %2, i64 0, i32 0
  %130 = getelementptr inbounds %"class.gemmlowp::MatrixMap.195", %"class.gemmlowp::MatrixMap.195"* %2, i64 0, i32 3
  %131 = sext i32 %12 to i64
  %132 = load i8*, i8** %129, align 8
  %133 = load i32, i32* %130, align 8
  %134 = sext i32 %133 to i64
  %135 = mul nsw i64 %134, %131
  %136 = getelementptr inbounds i8, i8* %132, i64 %135
  %137 = sext i32 %13 to i64
  %138 = getelementptr inbounds i8, i8* %136, i64 %137
  store i8 %125, i8* %138, align 1
  %139 = add nsw i64 %131, 1
  %140 = load i8*, i8** %129, align 8
  %141 = load i32, i32* %130, align 8
  %142 = sext i32 %141 to i64
  %143 = mul nsw i64 %139, %142
  %144 = getelementptr inbounds i8, i8* %140, i64 %143
  %145 = getelementptr inbounds i8, i8* %144, i64 %137
  store i8 %126, i8* %145, align 1
  %146 = add nsw i64 %131, 2
  %147 = load i8*, i8** %129, align 8
  %148 = load i32, i32* %130, align 8
  %149 = sext i32 %148 to i64
  %150 = mul nsw i64 %146, %149
  %151 = getelementptr inbounds i8, i8* %147, i64 %150
  %152 = getelementptr inbounds i8, i8* %151, i64 %137
  store i8 %127, i8* %152, align 1
  %153 = add nsw i64 %131, 3
  %154 = load i8*, i8** %129, align 8
  %155 = load i32, i32* %130, align 8
  %156 = sext i32 %155 to i64
  %157 = mul nsw i64 %153, %156
  %158 = getelementptr inbounds i8, i8* %154, i64 %157
  %159 = getelementptr inbounds i8, i8* %158, i64 %137
  store i8 %128, i8* %159, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi0ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalES8_ii(%"struct.gemmlowp::RegisterBlock.310"* noalias sret, %"struct.gemmlowp::OutputPipelineEvalImpl.422"*, %"struct.gemmlowp::RegisterBlock.302"* byval(%"struct.gemmlowp::RegisterBlock.302") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %6 = alloca %"struct.gemmlowp::RegisterBuffer.303", align 16
  %7 = alloca %"struct.gemmlowp::RegisterBuffer.303", align 16
  %8 = alloca [32 x i32], align 8
  %9 = alloca %"struct.gemmlowp::RegisterBuffer.303", align 8
  %10 = alloca %"struct.gemmlowp::RegisterBuffer.303", align 4
  %11 = alloca [32 x i32], align 4
  %12 = bitcast [32 x i32]* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %12)
  %13 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %2 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %12, i8 -86, i64 128, i1 false), !alias.scope !998
  %14 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %14) #19, !noalias !998
  %15 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %15) #19, !noalias !998
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %15, i8* nonnull align 8 %13, i64 128, i1 false)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %14, i8 -86, i64 128, i1 false) #19, !alias.scope !1001, !noalias !998
  %16 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.422", %"struct.gemmlowp::OutputPipelineEvalImpl.422"* %1, i64 0, i32 0, i32 0, i32 0
  %17 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %16, align 8, !noalias !1004
  %18 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %17, i64 0, i32 2
  %19 = load i32, i32* %18, align 4, !noalias !1004
  %20 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.422", %"struct.gemmlowp::OutputPipelineEvalImpl.422"* %1, i64 0, i32 0, i32 0, i32 1
  %21 = load i32, i32* %20, align 8, !noalias !1004
  %22 = shl i32 1, %21
  %23 = sext i32 %22 to i64
  %24 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %17, i64 0, i32 0
  %25 = load i32, i32* %24, align 4, !noalias !1004
  %26 = sext i32 %25 to i64
  %27 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.422", %"struct.gemmlowp::OutputPipelineEvalImpl.422"* %1, i64 0, i32 0, i32 0, i32 2
  %28 = load i32, i32* %27, align 4, !noalias !1004
  %29 = zext i32 %28 to i64
  %30 = shl nsw i64 -1, %29
  %31 = trunc i64 %30 to i32
  %32 = xor i32 %31, -1
  %33 = ashr i32 %32, 1
  %34 = icmp ne i32 %25, -2147483648
  br label %35

35:                                               ; preds = %56, %5
  %36 = phi i64 [ 0, %5 ], [ %67, %56 ]
  %37 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %9, i64 0, i32 0, i64 %36
  %38 = load i32, i32* %37, align 4, !noalias !1004
  %39 = sext i32 %38 to i64
  %40 = mul nsw i64 %39, %23
  %41 = icmp slt i64 %40, 2147483647
  %42 = select i1 %41, i64 %40, i64 2147483647
  %43 = icmp sgt i64 %42, -2147483648
  %44 = select i1 %43, i64 %42, i64 -2147483648
  %45 = trunc i64 %44 to i32
  %46 = icmp ne i32 %25, %45
  %47 = or i1 %34, %46
  br i1 %47, label %48, label %56

48:                                               ; preds = %35
  %49 = select i1 %46, i64 %26, i64 %44
  %50 = mul nsw i64 %49, %44
  %51 = icmp sgt i64 %50, -1
  %52 = select i1 %51, i64 1073741824, i64 -1073741823
  %53 = add nsw i64 %52, %50
  %54 = sdiv i64 %53, 2147483648
  %55 = trunc i64 %54 to i32
  br label %56

56:                                               ; preds = %48, %35
  %57 = phi i32 [ %55, %48 ], [ 2147483647, %35 ]
  %58 = and i32 %57, %32
  %59 = lshr i32 %57, 31
  %60 = add nsw i32 %59, %33
  %61 = ashr i32 %57, %28
  %62 = icmp sgt i32 %58, %60
  %63 = zext i1 %62 to i32
  %64 = add i32 %61, %19
  %65 = add i32 %64, %63
  %66 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %10, i64 0, i32 0, i64 %36
  store i32 %65, i32* %66, align 4, !alias.scope !1001, !noalias !998
  %67 = add nuw nsw i64 %36, 1
  %68 = icmp eq i64 %67, 32
  br i1 %68, label %69, label %35

69:                                               ; preds = %56
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %15) #19, !noalias !998
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 4 %12, i8* nonnull align 4 %14, i64 128, i1 false)
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %14) #19, !noalias !998
  %70 = bitcast [32 x i32]* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %70) #19, !noalias !1005
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %70, i8 -86, i64 128, i1 false) #19, !alias.scope !1008, !noalias !1005
  %71 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %71) #19, !noalias !1011
  %72 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %72) #19, !noalias !1011
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %72, i8* nonnull align 4 %12, i64 128, i1 false)
  %73 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.422", %"struct.gemmlowp::OutputPipelineEvalImpl.422"* %1, i64 0, i32 1, i32 0, i32 0, i32 0
  %74 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %73, align 8, !noalias !1012
  %75 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %74, i64 0, i32 0
  %76 = load i32, i32* %75, align 4, !noalias !1012
  %77 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %74, i64 0, i32 1
  %78 = load i32, i32* %77, align 4, !noalias !1012
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %71, i8 -86, i64 128, i1 false) #19, !alias.scope !1015, !noalias !1011
  %79 = insertelement <4 x i32> undef, i32 %76, i32 0
  %80 = shufflevector <4 x i32> %79, <4 x i32> undef, <4 x i32> zeroinitializer
  %81 = insertelement <4 x i32> undef, i32 %78, i32 0
  %82 = shufflevector <4 x i32> %81, <4 x i32> undef, <4 x i32> zeroinitializer
  %83 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %6 to <4 x i32>*
  %84 = load <4 x i32>, <4 x i32>* %83, align 16, !noalias !1012
  %85 = icmp slt <4 x i32> %84, %80
  %86 = select <4 x i1> %85, <4 x i32> %80, <4 x i32> %84
  %87 = icmp slt <4 x i32> %82, %86
  %88 = select <4 x i1> %87, <4 x i32> %82, <4 x i32> %86
  %89 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %7 to <4 x i32>*
  store <4 x i32> %88, <4 x i32>* %89, align 16, !alias.scope !1015, !noalias !1011
  %90 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 4
  %91 = bitcast i32* %90 to <4 x i32>*
  %92 = load <4 x i32>, <4 x i32>* %91, align 16, !noalias !1012
  %93 = icmp slt <4 x i32> %92, %80
  %94 = select <4 x i1> %93, <4 x i32> %80, <4 x i32> %92
  %95 = icmp slt <4 x i32> %82, %94
  %96 = select <4 x i1> %95, <4 x i32> %82, <4 x i32> %94
  %97 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %7, i64 0, i32 0, i64 4
  %98 = bitcast i32* %97 to <4 x i32>*
  store <4 x i32> %96, <4 x i32>* %98, align 16, !alias.scope !1015, !noalias !1011
  %99 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 8
  %100 = bitcast i32* %99 to <4 x i32>*
  %101 = load <4 x i32>, <4 x i32>* %100, align 16, !noalias !1012
  %102 = icmp slt <4 x i32> %101, %80
  %103 = select <4 x i1> %102, <4 x i32> %80, <4 x i32> %101
  %104 = icmp slt <4 x i32> %82, %103
  %105 = select <4 x i1> %104, <4 x i32> %82, <4 x i32> %103
  %106 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %7, i64 0, i32 0, i64 8
  %107 = bitcast i32* %106 to <4 x i32>*
  store <4 x i32> %105, <4 x i32>* %107, align 16, !alias.scope !1015, !noalias !1011
  %108 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 12
  %109 = bitcast i32* %108 to <4 x i32>*
  %110 = load <4 x i32>, <4 x i32>* %109, align 16, !noalias !1012
  %111 = icmp slt <4 x i32> %110, %80
  %112 = select <4 x i1> %111, <4 x i32> %80, <4 x i32> %110
  %113 = icmp slt <4 x i32> %82, %112
  %114 = select <4 x i1> %113, <4 x i32> %82, <4 x i32> %112
  %115 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %7, i64 0, i32 0, i64 12
  %116 = bitcast i32* %115 to <4 x i32>*
  store <4 x i32> %114, <4 x i32>* %116, align 16, !alias.scope !1015, !noalias !1011
  %117 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 16
  %118 = bitcast i32* %117 to <4 x i32>*
  %119 = load <4 x i32>, <4 x i32>* %118, align 16, !noalias !1012
  %120 = icmp slt <4 x i32> %119, %80
  %121 = select <4 x i1> %120, <4 x i32> %80, <4 x i32> %119
  %122 = icmp slt <4 x i32> %82, %121
  %123 = select <4 x i1> %122, <4 x i32> %82, <4 x i32> %121
  %124 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %7, i64 0, i32 0, i64 16
  %125 = bitcast i32* %124 to <4 x i32>*
  store <4 x i32> %123, <4 x i32>* %125, align 16, !alias.scope !1015, !noalias !1011
  %126 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 20
  %127 = bitcast i32* %126 to <4 x i32>*
  %128 = load <4 x i32>, <4 x i32>* %127, align 16, !noalias !1012
  %129 = icmp slt <4 x i32> %128, %80
  %130 = select <4 x i1> %129, <4 x i32> %80, <4 x i32> %128
  %131 = icmp slt <4 x i32> %82, %130
  %132 = select <4 x i1> %131, <4 x i32> %82, <4 x i32> %130
  %133 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %7, i64 0, i32 0, i64 20
  %134 = bitcast i32* %133 to <4 x i32>*
  store <4 x i32> %132, <4 x i32>* %134, align 16, !alias.scope !1015, !noalias !1011
  %135 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 24
  %136 = bitcast i32* %135 to <4 x i32>*
  %137 = load <4 x i32>, <4 x i32>* %136, align 16, !noalias !1012
  %138 = icmp slt <4 x i32> %137, %80
  %139 = select <4 x i1> %138, <4 x i32> %80, <4 x i32> %137
  %140 = icmp slt <4 x i32> %82, %139
  %141 = select <4 x i1> %140, <4 x i32> %82, <4 x i32> %139
  %142 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %7, i64 0, i32 0, i64 24
  %143 = bitcast i32* %142 to <4 x i32>*
  store <4 x i32> %141, <4 x i32>* %143, align 16, !alias.scope !1015, !noalias !1011
  %144 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 28
  %145 = bitcast i32* %144 to <4 x i32>*
  %146 = load <4 x i32>, <4 x i32>* %145, align 16, !noalias !1012
  %147 = icmp slt <4 x i32> %146, %80
  %148 = select <4 x i1> %147, <4 x i32> %80, <4 x i32> %146
  %149 = icmp slt <4 x i32> %82, %148
  %150 = select <4 x i1> %149, <4 x i32> %82, <4 x i32> %148
  %151 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %7, i64 0, i32 0, i64 28
  %152 = bitcast i32* %151 to <4 x i32>*
  store <4 x i32> %150, <4 x i32>* %152, align 16, !alias.scope !1015, !noalias !1011
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %72) #19, !noalias !1011
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %70, i8* nonnull align 16 %71, i64 128, i1 false) #19, !noalias !1005
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %71) #19, !noalias !1011
  %153 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.422", %"struct.gemmlowp::OutputPipelineEvalImpl.422"* %1, i64 0, i32 1, i32 1
  %154 = bitcast [32 x i32]* %8 to %"struct.gemmlowp::RegisterBlock.302"*
  tail call void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi2ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalES8_ii(%"struct.gemmlowp::RegisterBlock.310"* sret %0, %"struct.gemmlowp::OutputPipelineEvalImpl.424"* %153, %"struct.gemmlowp::RegisterBlock.302"* nonnull byval(%"struct.gemmlowp::RegisterBlock.302") align 8 %154, i32 %3, i32 %4) #19
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %70) #19, !noalias !1005
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %12)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi2ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalES8_ii(%"struct.gemmlowp::RegisterBlock.310"* noalias sret, %"struct.gemmlowp::OutputPipelineEvalImpl.424"*, %"struct.gemmlowp::RegisterBlock.302"* byval(%"struct.gemmlowp::RegisterBlock.302") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %6 = alloca %"struct.gemmlowp::RegisterBuffer.303", align 16
  %7 = alloca %"struct.gemmlowp::RegisterBuffer.311", align 16
  %8 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %2 to i8*
  %9 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.311", %"struct.gemmlowp::RegisterBuffer.311"* %7, i64 0, i32 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %9) #19, !noalias !1016
  %10 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %10) #19, !noalias !1016
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %10, i8* nonnull align 8 %8, i64 128, i1 false)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 32, i1 false) #19, !alias.scope !1019, !noalias !1016
  %11 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %6 to <4 x i32>*
  %12 = load <4 x i32>, <4 x i32>* %11, align 16, !noalias !1022
  %13 = icmp sgt <4 x i32> %12, zeroinitializer
  %14 = select <4 x i1> %13, <4 x i32> %12, <4 x i32> zeroinitializer
  %15 = icmp slt <4 x i32> %14, <i32 255, i32 255, i32 255, i32 255>
  %16 = select <4 x i1> %15, <4 x i32> %14, <4 x i32> <i32 255, i32 255, i32 255, i32 255>
  %17 = trunc <4 x i32> %16 to <4 x i8>
  %18 = bitcast %"struct.gemmlowp::RegisterBuffer.311"* %7 to <4 x i8>*
  store <4 x i8> %17, <4 x i8>* %18, align 16, !alias.scope !1019, !noalias !1016
  %19 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 4
  %20 = bitcast i32* %19 to <4 x i32>*
  %21 = load <4 x i32>, <4 x i32>* %20, align 16, !noalias !1022
  %22 = icmp sgt <4 x i32> %21, zeroinitializer
  %23 = select <4 x i1> %22, <4 x i32> %21, <4 x i32> zeroinitializer
  %24 = icmp slt <4 x i32> %23, <i32 255, i32 255, i32 255, i32 255>
  %25 = select <4 x i1> %24, <4 x i32> %23, <4 x i32> <i32 255, i32 255, i32 255, i32 255>
  %26 = trunc <4 x i32> %25 to <4 x i8>
  %27 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.311", %"struct.gemmlowp::RegisterBuffer.311"* %7, i64 0, i32 0, i64 4
  %28 = bitcast i8* %27 to <4 x i8>*
  store <4 x i8> %26, <4 x i8>* %28, align 4, !alias.scope !1019, !noalias !1016
  %29 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 8
  %30 = bitcast i32* %29 to <4 x i32>*
  %31 = load <4 x i32>, <4 x i32>* %30, align 16, !noalias !1022
  %32 = icmp sgt <4 x i32> %31, zeroinitializer
  %33 = select <4 x i1> %32, <4 x i32> %31, <4 x i32> zeroinitializer
  %34 = icmp slt <4 x i32> %33, <i32 255, i32 255, i32 255, i32 255>
  %35 = select <4 x i1> %34, <4 x i32> %33, <4 x i32> <i32 255, i32 255, i32 255, i32 255>
  %36 = trunc <4 x i32> %35 to <4 x i8>
  %37 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.311", %"struct.gemmlowp::RegisterBuffer.311"* %7, i64 0, i32 0, i64 8
  %38 = bitcast i8* %37 to <4 x i8>*
  store <4 x i8> %36, <4 x i8>* %38, align 8, !alias.scope !1019, !noalias !1016
  %39 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 12
  %40 = bitcast i32* %39 to <4 x i32>*
  %41 = load <4 x i32>, <4 x i32>* %40, align 16, !noalias !1022
  %42 = icmp sgt <4 x i32> %41, zeroinitializer
  %43 = select <4 x i1> %42, <4 x i32> %41, <4 x i32> zeroinitializer
  %44 = icmp slt <4 x i32> %43, <i32 255, i32 255, i32 255, i32 255>
  %45 = select <4 x i1> %44, <4 x i32> %43, <4 x i32> <i32 255, i32 255, i32 255, i32 255>
  %46 = trunc <4 x i32> %45 to <4 x i8>
  %47 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.311", %"struct.gemmlowp::RegisterBuffer.311"* %7, i64 0, i32 0, i64 12
  %48 = bitcast i8* %47 to <4 x i8>*
  store <4 x i8> %46, <4 x i8>* %48, align 4, !alias.scope !1019, !noalias !1016
  %49 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 16
  %50 = bitcast i32* %49 to <4 x i32>*
  %51 = load <4 x i32>, <4 x i32>* %50, align 16, !noalias !1022
  %52 = icmp sgt <4 x i32> %51, zeroinitializer
  %53 = select <4 x i1> %52, <4 x i32> %51, <4 x i32> zeroinitializer
  %54 = icmp slt <4 x i32> %53, <i32 255, i32 255, i32 255, i32 255>
  %55 = select <4 x i1> %54, <4 x i32> %53, <4 x i32> <i32 255, i32 255, i32 255, i32 255>
  %56 = trunc <4 x i32> %55 to <4 x i8>
  %57 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.311", %"struct.gemmlowp::RegisterBuffer.311"* %7, i64 0, i32 0, i64 16
  %58 = bitcast i8* %57 to <4 x i8>*
  store <4 x i8> %56, <4 x i8>* %58, align 16, !alias.scope !1019, !noalias !1016
  %59 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 20
  %60 = bitcast i32* %59 to <4 x i32>*
  %61 = load <4 x i32>, <4 x i32>* %60, align 16, !noalias !1022
  %62 = icmp sgt <4 x i32> %61, zeroinitializer
  %63 = select <4 x i1> %62, <4 x i32> %61, <4 x i32> zeroinitializer
  %64 = icmp slt <4 x i32> %63, <i32 255, i32 255, i32 255, i32 255>
  %65 = select <4 x i1> %64, <4 x i32> %63, <4 x i32> <i32 255, i32 255, i32 255, i32 255>
  %66 = trunc <4 x i32> %65 to <4 x i8>
  %67 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.311", %"struct.gemmlowp::RegisterBuffer.311"* %7, i64 0, i32 0, i64 20
  %68 = bitcast i8* %67 to <4 x i8>*
  store <4 x i8> %66, <4 x i8>* %68, align 4, !alias.scope !1019, !noalias !1016
  %69 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 24
  %70 = bitcast i32* %69 to <4 x i32>*
  %71 = load <4 x i32>, <4 x i32>* %70, align 16, !noalias !1022
  %72 = icmp sgt <4 x i32> %71, zeroinitializer
  %73 = select <4 x i1> %72, <4 x i32> %71, <4 x i32> zeroinitializer
  %74 = icmp slt <4 x i32> %73, <i32 255, i32 255, i32 255, i32 255>
  %75 = select <4 x i1> %74, <4 x i32> %73, <4 x i32> <i32 255, i32 255, i32 255, i32 255>
  %76 = trunc <4 x i32> %75 to <4 x i8>
  %77 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.311", %"struct.gemmlowp::RegisterBuffer.311"* %7, i64 0, i32 0, i64 24
  %78 = bitcast i8* %77 to <4 x i8>*
  store <4 x i8> %76, <4 x i8>* %78, align 8, !alias.scope !1019, !noalias !1016
  %79 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 28
  %80 = bitcast i32* %79 to <4 x i32>*
  %81 = load <4 x i32>, <4 x i32>* %80, align 16, !noalias !1022
  %82 = icmp sgt <4 x i32> %81, zeroinitializer
  %83 = select <4 x i1> %82, <4 x i32> %81, <4 x i32> zeroinitializer
  %84 = icmp slt <4 x i32> %83, <i32 255, i32 255, i32 255, i32 255>
  %85 = select <4 x i1> %84, <4 x i32> %83, <4 x i32> <i32 255, i32 255, i32 255, i32 255>
  %86 = trunc <4 x i32> %85 to <4 x i8>
  %87 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.311", %"struct.gemmlowp::RegisterBuffer.311"* %7, i64 0, i32 0, i64 28
  %88 = bitcast i8* %87 to <4 x i8>*
  store <4 x i8> %86, <4 x i8>* %88, align 4, !alias.scope !1019, !noalias !1016
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %10) #19, !noalias !1016
  %89 = bitcast %"struct.gemmlowp::RegisterBuffer.311"* %7 to <16 x i8>*
  %90 = load <16 x i8>, <16 x i8>* %89, align 16
  %91 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.311", %"struct.gemmlowp::RegisterBuffer.311"* %7, i64 0, i32 0, i64 16
  %92 = bitcast i8* %91 to <16 x i8>*
  %93 = load <16 x i8>, <16 x i8>* %92, align 16
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %9) #19, !noalias !1016
  %94 = bitcast %"struct.gemmlowp::RegisterBlock.310"* %0 to <16 x i8>*
  store <16 x i8> %90, <16 x i8>* %94, align 1
  %95 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %0, i64 0, i32 0, i32 0, i64 16
  %96 = bitcast i8* %95 to <16 x i8>*
  store <16 x i8> %93, <16 x i8>* %96, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi1ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalES8_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.416"*, %"struct.gemmlowp::RegisterBlock.312"* byval(%"struct.gemmlowp::RegisterBlock.312") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %5 = alloca %"struct.gemmlowp::RegisterBlock.312", align 16
  %6 = bitcast %"struct.gemmlowp::RegisterBlock.312"* %1 to <4 x i32>*
  %7 = load <4 x i32>, <4 x i32>* %6, align 8
  %8 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 4
  %9 = bitcast i32* %8 to <4 x i32>*
  %10 = load <4 x i32>, <4 x i32>* %9, align 8
  %11 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 8
  %12 = bitcast i32* %11 to <4 x i32>*
  %13 = load <4 x i32>, <4 x i32>* %12, align 8
  %14 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %1, i64 0, i32 0, i32 0, i64 12
  %15 = bitcast i32* %14 to <4 x i32>*
  %16 = load <4 x i32>, <4 x i32>* %15, align 8
  %17 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.416", %"struct.gemmlowp::OutputPipelineEvalImpl.416"* %0, i64 0, i32 0, i32 0, i32 0
  %18 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %17, align 8, !noalias !1023
  %19 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %18, i64 0, i32 0
  %20 = load i32, i32* %19, align 4, !noalias !1023
  %21 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %18, i64 0, i32 1
  %22 = load i32, i32* %21, align 4, !noalias !1023
  %23 = insertelement <4 x i32> undef, i32 %20, i32 0
  %24 = shufflevector <4 x i32> %23, <4 x i32> undef, <4 x i32> zeroinitializer
  %25 = icmp slt <4 x i32> %7, %24
  %26 = select <4 x i1> %25, <4 x i32> %24, <4 x i32> %7
  %27 = insertelement <4 x i32> undef, i32 %22, i32 0
  %28 = shufflevector <4 x i32> %27, <4 x i32> undef, <4 x i32> zeroinitializer
  %29 = icmp slt <4 x i32> %28, %26
  %30 = select <4 x i1> %29, <4 x i32> %28, <4 x i32> %26
  %31 = icmp slt <4 x i32> %10, %24
  %32 = select <4 x i1> %31, <4 x i32> %24, <4 x i32> %10
  %33 = icmp slt <4 x i32> %28, %32
  %34 = select <4 x i1> %33, <4 x i32> %28, <4 x i32> %32
  %35 = icmp slt <4 x i32> %13, %24
  %36 = select <4 x i1> %35, <4 x i32> %24, <4 x i32> %13
  %37 = icmp slt <4 x i32> %28, %36
  %38 = select <4 x i1> %37, <4 x i32> %28, <4 x i32> %36
  %39 = icmp slt <4 x i32> %16, %24
  %40 = select <4 x i1> %39, <4 x i32> %24, <4 x i32> %16
  %41 = icmp slt <4 x i32> %28, %40
  %42 = select <4 x i1> %41, <4 x i32> %28, <4 x i32> %40
  %43 = bitcast %"struct.gemmlowp::RegisterBlock.312"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %43)
  %44 = bitcast %"struct.gemmlowp::RegisterBlock.312"* %5 to <4 x i32>*
  store <4 x i32> %30, <4 x i32>* %44, align 16
  %45 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %5, i64 0, i32 0, i32 0, i64 4
  %46 = bitcast i32* %45 to <4 x i32>*
  store <4 x i32> %34, <4 x i32>* %46, align 16
  %47 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %5, i64 0, i32 0, i32 0, i64 8
  %48 = bitcast i32* %47 to <4 x i32>*
  store <4 x i32> %38, <4 x i32>* %48, align 16
  %49 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %5, i64 0, i32 0, i32 0, i64 12
  %50 = bitcast i32* %49 to <4 x i32>*
  store <4 x i32> %42, <4 x i32>* %50, align 16
  %51 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.416", %"struct.gemmlowp::OutputPipelineEvalImpl.416"* %0, i64 0, i32 1, i32 0
  %52 = tail call { i64, i64 } @_ZNK8gemmlowp19OutputStageEvalImplINS_32OutputStageSaturatingCastToUint8ENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii(%"struct.gemmlowp::OutputStageEvalImpl.280"* %51, %"struct.gemmlowp::RegisterBlock.312"* nonnull byval(%"struct.gemmlowp::RegisterBlock.312") align 8 %5, i32 %2, i32 %3) #19
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %43)
  ret { i64, i64 } %52
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi0ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalES8_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.401"*, %"struct.gemmlowp::RegisterBlock.304"* byval(%"struct.gemmlowp::RegisterBlock.304") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %5 = alloca %"struct.gemmlowp::RegisterBuffer.305", align 8
  %6 = alloca %"struct.gemmlowp::RegisterBuffer.305", align 4
  %7 = bitcast %"struct.gemmlowp::RegisterBlock.304"* %1 to i8*
  %8 = bitcast %"struct.gemmlowp::RegisterBuffer.305"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %8) #19, !noalias !1028
  %9 = bitcast %"struct.gemmlowp::RegisterBuffer.305"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %9) #19, !noalias !1028
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %9, i8* nonnull align 8 %7, i64 32, i1 false)
  %10 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.401", %"struct.gemmlowp::OutputPipelineEvalImpl.401"* %0, i64 0, i32 0, i32 0, i32 0
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %8, i8 -86, i64 32, i1 false) #19, !alias.scope !1031, !noalias !1028
  %11 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %10, align 8, !noalias !1034
  %12 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %11, i64 0, i32 2
  %13 = load i32, i32* %12, align 4, !noalias !1034
  %14 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.401", %"struct.gemmlowp::OutputPipelineEvalImpl.401"* %0, i64 0, i32 0, i32 0, i32 1
  %15 = load i32, i32* %14, align 8, !noalias !1034
  %16 = shl i32 1, %15
  %17 = sext i32 %16 to i64
  %18 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %11, i64 0, i32 0
  %19 = load i32, i32* %18, align 4, !noalias !1034
  %20 = sext i32 %19 to i64
  %21 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.401", %"struct.gemmlowp::OutputPipelineEvalImpl.401"* %0, i64 0, i32 0, i32 0, i32 2
  %22 = load i32, i32* %21, align 4, !noalias !1034
  %23 = zext i32 %22 to i64
  %24 = shl nsw i64 -1, %23
  %25 = trunc i64 %24 to i32
  %26 = xor i32 %25, -1
  %27 = ashr i32 %26, 1
  %28 = icmp ne i32 %19, -2147483648
  br label %29

29:                                               ; preds = %50, %4
  %30 = phi i64 [ 0, %4 ], [ %61, %50 ]
  %31 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.305", %"struct.gemmlowp::RegisterBuffer.305"* %5, i64 0, i32 0, i64 %30
  %32 = load i32, i32* %31, align 4, !noalias !1034
  %33 = sext i32 %32 to i64
  %34 = mul nsw i64 %33, %17
  %35 = icmp slt i64 %34, 2147483647
  %36 = select i1 %35, i64 %34, i64 2147483647
  %37 = icmp sgt i64 %36, -2147483648
  %38 = select i1 %37, i64 %36, i64 -2147483648
  %39 = trunc i64 %38 to i32
  %40 = icmp ne i32 %19, %39
  %41 = or i1 %28, %40
  br i1 %41, label %42, label %50

42:                                               ; preds = %29
  %43 = select i1 %40, i64 %20, i64 %38
  %44 = mul nsw i64 %43, %38
  %45 = icmp sgt i64 %44, -1
  %46 = select i1 %45, i64 1073741824, i64 -1073741823
  %47 = add nsw i64 %46, %44
  %48 = sdiv i64 %47, 2147483648
  %49 = trunc i64 %48 to i32
  br label %50

50:                                               ; preds = %42, %29
  %51 = phi i32 [ %49, %42 ], [ 2147483647, %29 ]
  %52 = and i32 %51, %26
  %53 = lshr i32 %51, 31
  %54 = add nsw i32 %53, %27
  %55 = ashr i32 %51, %22
  %56 = icmp sgt i32 %52, %54
  %57 = zext i1 %56 to i32
  %58 = add i32 %55, %13
  %59 = add i32 %58, %57
  %60 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.305", %"struct.gemmlowp::RegisterBuffer.305"* %6, i64 0, i32 0, i64 %30
  store i32 %59, i32* %60, align 4, !alias.scope !1031, !noalias !1028
  %61 = add nuw nsw i64 %30, 1
  %62 = icmp eq i64 %61, 8
  br i1 %62, label %63, label %29

63:                                               ; preds = %50
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %9) #19, !noalias !1028
  %64 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.305", %"struct.gemmlowp::RegisterBuffer.305"* %6, i64 0, i32 0, i64 0
  %65 = load i32, i32* %64, align 4
  %66 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.305", %"struct.gemmlowp::RegisterBuffer.305"* %6, i64 0, i32 0, i64 1
  %67 = load i32, i32* %66, align 4
  %68 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.305", %"struct.gemmlowp::RegisterBuffer.305"* %6, i64 0, i32 0, i64 2
  %69 = load i32, i32* %68, align 4
  %70 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.305", %"struct.gemmlowp::RegisterBuffer.305"* %6, i64 0, i32 0, i64 3
  %71 = load i32, i32* %70, align 4
  %72 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.305", %"struct.gemmlowp::RegisterBuffer.305"* %6, i64 0, i32 0, i64 4
  %73 = bitcast i32* %72 to <4 x i32>*
  %74 = load <4 x i32>, <4 x i32>* %73, align 4
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %8) #19, !noalias !1028
  %75 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.401", %"struct.gemmlowp::OutputPipelineEvalImpl.401"* %0, i64 0, i32 1, i32 0, i32 0, i32 0
  %76 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %75, align 8, !noalias !1035
  %77 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %76, i64 0, i32 0
  %78 = load i32, i32* %77, align 4, !noalias !1035
  %79 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %76, i64 0, i32 1
  %80 = load i32, i32* %79, align 4, !noalias !1035
  %81 = icmp slt i32 %65, %78
  %82 = select i1 %81, i32 %78, i32 %65
  %83 = icmp slt i32 %80, %82
  %84 = select i1 %83, i32 %80, i32 %82
  %85 = icmp slt i32 %67, %78
  %86 = select i1 %85, i32 %78, i32 %67
  %87 = icmp slt i32 %80, %86
  %88 = select i1 %87, i32 %80, i32 %86
  %89 = icmp slt i32 %69, %78
  %90 = select i1 %89, i32 %78, i32 %69
  %91 = icmp slt i32 %80, %90
  %92 = select i1 %91, i32 %80, i32 %90
  %93 = icmp slt i32 %71, %78
  %94 = select i1 %93, i32 %78, i32 %71
  %95 = icmp slt i32 %80, %94
  %96 = select i1 %95, i32 %80, i32 %94
  %97 = insertelement <4 x i32> undef, i32 %78, i32 0
  %98 = shufflevector <4 x i32> %97, <4 x i32> undef, <4 x i32> zeroinitializer
  %99 = icmp slt <4 x i32> %74, %98
  %100 = select <4 x i1> %99, <4 x i32> %98, <4 x i32> %74
  %101 = insertelement <4 x i32> undef, i32 %80, i32 0
  %102 = shufflevector <4 x i32> %101, <4 x i32> undef, <4 x i32> zeroinitializer
  %103 = icmp slt <4 x i32> %102, %100
  %104 = select <4 x i1> %103, <4 x i32> %102, <4 x i32> %100
  %105 = icmp sgt i32 %84, 0
  %106 = select i1 %105, i32 %84, i32 0
  %107 = icmp slt i32 %106, 255
  %108 = select i1 %107, i32 %106, i32 255
  %109 = icmp sgt i32 %88, 0
  %110 = select i1 %109, i32 %88, i32 0
  %111 = icmp slt i32 %110, 255
  %112 = select i1 %111, i32 %110, i32 255
  %113 = icmp sgt i32 %92, 0
  %114 = select i1 %113, i32 %92, i32 0
  %115 = icmp slt i32 %114, 255
  %116 = select i1 %115, i32 %114, i32 255
  %117 = icmp sgt i32 %96, 0
  %118 = select i1 %117, i32 %96, i32 0
  %119 = icmp slt i32 %118, 255
  %120 = select i1 %119, i32 %118, i32 255
  %121 = icmp sgt <4 x i32> %104, zeroinitializer
  %122 = select <4 x i1> %121, <4 x i32> %104, <4 x i32> zeroinitializer
  %123 = icmp slt <4 x i32> %122, <i32 255, i32 255, i32 255, i32 255>
  %124 = select <4 x i1> %123, <4 x i32> %122, <4 x i32> <i32 255, i32 255, i32 255, i32 255>
  %125 = zext <4 x i32> %124 to <4 x i64>
  %126 = shl nuw <4 x i64> %125, <i64 32, i64 40, i64 48, i64 56>
  %127 = shl nuw i32 %120, 24
  %128 = shl nuw nsw i32 %116, 16
  %129 = shl nuw nsw i32 %112, 8
  %130 = or i32 %129, %108
  %131 = or i32 %130, %128
  %132 = or i32 %131, %127
  %133 = zext i32 %132 to i64
  %134 = shufflevector <4 x i64> %126, <4 x i64> undef, <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
  %135 = or <4 x i64> %126, %134
  %136 = shufflevector <4 x i64> %135, <4 x i64> undef, <4 x i32> <i32 1, i32 undef, i32 undef, i32 undef>
  %137 = or <4 x i64> %135, %136
  %138 = extractelement <4 x i64> %137, i32 0
  %139 = or i64 %138, %133
  ret i64 %139
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEED2Ev(%"struct.gemmlowp::GemmWithPackedRhsTask.385"*) unnamed_addr #4 comdat align 2 {
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEED0Ev(%"struct.gemmlowp::GemmWithPackedRhsTask.385"*) unnamed_addr #4 comdat align 2 {
  %2 = bitcast %"struct.gemmlowp::GemmWithPackedRhsTask.385"* %0 to i8*
  tail call void @_ZdlPv(i8* %2) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEE3RunEv(%"struct.gemmlowp::GemmWithPackedRhsTask.385"*) unnamed_addr #1 comdat align 2 {
  %2 = alloca %"class.gemmlowp::SideMap", align 8
  %3 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %4 = alloca %"class.gemmlowp::ComputeImpl", align 8
  %5 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %6 = alloca %"class.gemmlowp::PackedResult", align 8
  %7 = alloca %"struct.gemmlowp::MatrixBlockBounds", align 4
  %8 = alloca %"class.gemmlowp::VectorDup.194", align 4
  %9 = alloca %"class.gemmlowp::VectorDup", align 4
  %10 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.385", %"struct.gemmlowp::GemmWithPackedRhsTask.385"* %0, i64 0, i32 6, i32 2
  %11 = load i32, i32* %10, align 8
  %12 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.385", %"struct.gemmlowp::GemmWithPackedRhsTask.385"* %0, i64 0, i32 6, i32 3
  %13 = load i32, i32* %12, align 4
  %14 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.385", %"struct.gemmlowp::GemmWithPackedRhsTask.385"* %0, i64 0, i32 3, i32 2
  %15 = load i32, i32* %14, align 4
  %16 = bitcast %"class.gemmlowp::PackedSideBlock"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %16) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %16, i8 -86, i64 80, i1 false)
  %17 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.385", %"struct.gemmlowp::GemmWithPackedRhsTask.385"* %0, i64 0, i32 0, i32 1
  %18 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %19 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.385", %"struct.gemmlowp::GemmWithPackedRhsTask.385"* %0, i64 0, i32 9
  %20 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %21 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %18, %"class.gemmlowp::Allocator"** %21, align 8
  %22 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 4
  store i32 0, i32* %22, align 8
  %23 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 0
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 0
  store i32 %24, i32* %25, align 8
  %26 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 3
  %27 = load i32, i32* %26, align 4
  %28 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 2
  store i32 %27, i32* %28, align 8
  %29 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 2
  %30 = load i32, i32* %29, align 4
  %31 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 1
  store i32 %30, i32* %31, align 4
  %32 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 5
  %33 = load i32, i32* %32, align 4
  %34 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 3
  store i32 %33, i32* %34, align 4
  %35 = mul nsw i32 %33, %27
  %36 = sext i32 %35 to i64
  %37 = add nsw i64 %36, 63
  %38 = and i64 %37, -64
  %39 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 4
  %40 = load i64, i64* %39, align 8, !noalias !1040
  %41 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 3
  %42 = load i64, i64* %41, align 8, !noalias !1040
  %43 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 5, i64 %42
  store i64 %40, i64* %43, align 8, !noalias !1040
  %44 = trunc i64 %42 to i8
  %45 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 6
  %46 = load i64, i64* %45, align 8, !noalias !1040
  %47 = bitcast i64* %41 to <2 x i64>*
  %48 = load <2 x i64>, <2 x i64>* %47, align 8, !noalias !1040
  %49 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %38, i32 1
  %50 = add <2 x i64> %48, %49
  %51 = bitcast i64* %41 to <2 x i64>*
  store <2 x i64> %50, <2 x i64>* %51, align 8, !noalias !1040
  %52 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 0
  store i8 %44, i8* %52, align 8
  %53 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %53, i8 -86, i64 7, i1 false) #19
  %54 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 2
  store i64 %46, i64* %54, align 8
  %55 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 3
  store i8 0, i8* %55, align 8
  %56 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %21, align 8
  %57 = load i32, i32* %28, align 8
  %58 = sext i32 %57 to i64
  %59 = shl nsw i64 %58, 2
  %60 = add nsw i64 %59, 63
  %61 = and i64 %60, -64
  %62 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 4
  %63 = load i64, i64* %62, align 8, !noalias !1043
  %64 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 3
  %65 = load i64, i64* %64, align 8, !noalias !1043
  %66 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 5, i64 %65
  store i64 %63, i64* %66, align 8, !noalias !1043
  %67 = trunc i64 %65 to i8
  %68 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 6
  %69 = load i64, i64* %68, align 8, !noalias !1043
  %70 = bitcast i64* %64 to <2 x i64>*
  %71 = load <2 x i64>, <2 x i64>* %70, align 8, !noalias !1043
  %72 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %61, i32 1
  %73 = add <2 x i64> %71, %72
  %74 = bitcast i64* %64 to <2 x i64>*
  store <2 x i64> %73, <2 x i64>* %74, align 8, !noalias !1043
  %75 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 0
  store i8 %67, i8* %75, align 8
  %76 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %76, i8 -86, i64 7, i1 false) #19
  %77 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 2
  store i64 %69, i64* %77, align 8
  %78 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 3
  store i8 5, i8* %78, align 8
  %79 = bitcast %"class.gemmlowp::PackedResult"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %79) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %79, i8 -86, i64 32, i1 false)
  %80 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %81 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %82 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 0
  store %"class.gemmlowp::Allocator"* %80, %"class.gemmlowp::Allocator"** %82, align 8
  %83 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 2
  store %"struct.gemmlowp::BlockParams"* %81, %"struct.gemmlowp::BlockParams"** %83, align 8
  %84 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %81, i64 0, i32 3
  %85 = load i32, i32* %84, align 4
  %86 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %81, i64 0, i32 4
  %87 = load i32, i32* %86, align 4
  %88 = mul nsw i32 %87, %85
  %89 = sext i32 %88 to i64
  %90 = shl nsw i64 %89, 2
  %91 = add nsw i64 %90, 63
  %92 = and i64 %91, -64
  %93 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 4
  %94 = load i64, i64* %93, align 8, !noalias !1046
  %95 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 3
  %96 = load i64, i64* %95, align 8, !noalias !1046
  %97 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 5, i64 %96
  store i64 %94, i64* %97, align 8, !noalias !1046
  %98 = trunc i64 %96 to i8
  %99 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 6
  %100 = load i64, i64* %99, align 8, !noalias !1046
  %101 = bitcast i64* %95 to <2 x i64>*
  %102 = load <2 x i64>, <2 x i64>* %101, align 8, !noalias !1046
  %103 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %92, i32 1
  %104 = add <2 x i64> %102, %103
  %105 = bitcast i64* %95 to <2 x i64>*
  store <2 x i64> %104, <2 x i64>* %105, align 8, !noalias !1046
  %106 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 0
  store i8 %98, i8* %106, align 8
  %107 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %107, i8 -86, i64 7, i1 false) #19
  %108 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 2
  store i64 %100, i64* %108, align 8
  %109 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 3
  store i8 5, i8* %109, align 8
  %110 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  tail call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %110)
  %111 = icmp sgt i32 %13, 0
  br i1 %111, label %112, label %156

112:                                              ; preds = %1
  %113 = icmp sgt i32 %11, 0
  %114 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.385", %"struct.gemmlowp::GemmWithPackedRhsTask.385"* %0, i64 0, i32 3, i32 0
  %115 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.385", %"struct.gemmlowp::GemmWithPackedRhsTask.385"* %0, i64 0, i32 3, i32 3
  %116 = bitcast %"class.gemmlowp::SideMap"* %2 to i8*
  %117 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 1
  %118 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 2
  %119 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 3
  %120 = bitcast %"class.gemmlowp::SideMap"* %2 to i64*
  %121 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %3 to i8*
  %122 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %3, i64 0, i32 0
  %123 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %3, i64 0, i32 1
  %124 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.385", %"struct.gemmlowp::GemmWithPackedRhsTask.385"* %0, i64 0, i32 2
  %125 = bitcast %"struct.gemmlowp::KernelBase"** %124 to i64*
  %126 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.385", %"struct.gemmlowp::GemmWithPackedRhsTask.385"* %0, i64 0, i32 4
  %127 = bitcast %"class.gemmlowp::ComputeImpl"* %4 to i8*
  %128 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 1
  %129 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 2
  %130 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 3
  %131 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 4
  %132 = bitcast %"class.gemmlowp::ComputeImpl"* %4 to i64*
  %133 = add i32 %15, 15
  %134 = and i32 %133, -16
  %135 = icmp sgt i32 %134, 0
  %136 = bitcast %"struct.gemmlowp::MatrixBlockBounds"* %7 to i8*
  %137 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 0
  %138 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 1
  %139 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 2
  %140 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 3
  %141 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.385", %"struct.gemmlowp::GemmWithPackedRhsTask.385"* %0, i64 0, i32 6, i32 0
  %142 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.385", %"struct.gemmlowp::GemmWithPackedRhsTask.385"* %0, i64 0, i32 6, i32 1
  %143 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.385", %"struct.gemmlowp::GemmWithPackedRhsTask.385"* %0, i64 0, i32 5
  %144 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.385", %"struct.gemmlowp::GemmWithPackedRhsTask.385"* %0, i64 0, i32 4, i32 1
  %145 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.385", %"struct.gemmlowp::GemmWithPackedRhsTask.385"* %0, i64 0, i32 4, i32 3, i32 0
  %146 = bitcast %"class.gemmlowp::VectorDup.194"* %8 to i8*
  %147 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.385", %"struct.gemmlowp::GemmWithPackedRhsTask.385"* %0, i64 0, i32 7
  %148 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %8, i64 0, i32 0
  %149 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %8, i64 0, i32 1
  %150 = bitcast %"class.gemmlowp::VectorDup"* %9 to i8*
  %151 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.385", %"struct.gemmlowp::GemmWithPackedRhsTask.385"* %0, i64 0, i32 8
  %152 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %9, i64 0, i32 0
  %153 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %9, i64 0, i32 1
  %154 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.385", %"struct.gemmlowp::GemmWithPackedRhsTask.385"* %0, i64 0, i32 10
  %155 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  br label %164

156:                                              ; preds = %178, %1
  %157 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %158 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 0
  store i8 0, i8* %158, align 8
  %159 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 6
  %160 = load i64, i64* %159, align 8
  %161 = add i64 %160, 1
  store i64 %161, i64* %159, align 8
  %162 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 3
  %163 = bitcast i64* %162 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %163, i8 0, i64 16, i1 false) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %79) #19
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %16) #19
  ret void

164:                                              ; preds = %112, %178
  %165 = phi %"struct.gemmlowp::BlockParams"* [ %155, %112 ], [ %180, %178 ]
  %166 = phi i32 [ 0, %112 ], [ %181, %178 ]
  %167 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %165, i64 0, i32 4
  %168 = sub nsw i32 %13, %166
  %169 = load i32, i32* %167, align 4
  %170 = icmp slt i32 %168, %169
  %171 = select i1 %170, i32 %168, i32 %169
  br i1 %113, label %172, label %178

172:                                              ; preds = %164
  %173 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %165, i64 0, i32 3
  %174 = load i32, i32* %173, align 4
  br label %183

175:                                              ; preds = %255
  %176 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %287, i64 0, i32 4
  %177 = load i32, i32* %176, align 4
  br label %178

178:                                              ; preds = %175, %164
  %179 = phi i32 [ %169, %164 ], [ %177, %175 ]
  %180 = phi %"struct.gemmlowp::BlockParams"* [ %165, %164 ], [ %287, %175 ]
  %181 = add nsw i32 %179, %166
  %182 = icmp sgt i32 %13, %181
  br i1 %182, label %164, label %156

183:                                              ; preds = %172, %255
  %184 = phi i32 [ %289, %255 ], [ %174, %172 ]
  %185 = phi i32 [ %290, %255 ], [ 0, %172 ]
  %186 = sub nsw i32 %11, %185
  %187 = icmp slt i32 %186, %184
  %188 = select i1 %187, i32 %186, i32 %184
  %189 = load i8*, i8** %114, align 8, !noalias !1049
  %190 = load i32, i32* %115, align 8, !noalias !1049
  %191 = mul nsw i32 %190, %185
  %192 = sext i32 %191 to i64
  %193 = getelementptr inbounds i8, i8* %189, i64 %192
  %194 = ptrtoint i8* %193 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %116) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %116, i8 -86, i64 24, i1 false) #19
  store i64 %194, i64* %120, align 8
  store i32 %188, i32* %117, align 8
  store i32 %15, i32* %118, align 4
  store i32 %190, i32* %119, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %121) #19
  store %"class.gemmlowp::PackedSideBlock"* %5, %"class.gemmlowp::PackedSideBlock"** %122, align 8
  store %"class.gemmlowp::SideMap"* %2, %"class.gemmlowp::SideMap"** %123, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %3) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %121) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %116) #19
  %195 = load i64, i64* %125, align 8
  %196 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %127) #19
  store i64 %195, i64* %132, align 8
  store %"struct.gemmlowp::BlockParams"* %196, %"struct.gemmlowp::BlockParams"** %128, align 8
  store %"class.gemmlowp::PackedResult"* %6, %"class.gemmlowp::PackedResult"** %129, align 8
  store %"class.gemmlowp::PackedSideBlock"* %5, %"class.gemmlowp::PackedSideBlock"** %130, align 8
  store %"class.gemmlowp::PackedSideBlock"* %126, %"class.gemmlowp::PackedSideBlock"** %131, align 8
  br i1 %135, label %197, label %255

197:                                              ; preds = %183, %215
  %198 = phi %"struct.gemmlowp::BlockParams"* [ %217, %215 ], [ %196, %183 ]
  %199 = phi %"struct.gemmlowp::BlockParams"* [ %218, %215 ], [ %196, %183 ]
  %200 = phi i32 [ %219, %215 ], [ 0, %183 ]
  %201 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 2
  %202 = sub nsw i32 %134, %200
  %203 = load i32, i32* %201, align 4
  %204 = icmp slt i32 %202, %203
  %205 = select i1 %204, i32 %202, i32 %203
  %206 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 3
  %207 = load i32, i32* %206, align 4
  %208 = icmp sgt i32 %207, 0
  br i1 %208, label %209, label %215

209:                                              ; preds = %197
  %210 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 0
  %211 = load i32, i32* %210, align 4
  br label %221

212:                                              ; preds = %247
  %213 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 2
  %214 = load i32, i32* %213, align 4
  br label %215

215:                                              ; preds = %212, %197
  %216 = phi i32 [ %203, %197 ], [ %214, %212 ]
  %217 = phi %"struct.gemmlowp::BlockParams"* [ %198, %197 ], [ %248, %212 ]
  %218 = phi %"struct.gemmlowp::BlockParams"* [ %199, %197 ], [ %248, %212 ]
  %219 = add nsw i32 %216, %200
  %220 = icmp sgt i32 %134, %219
  br i1 %220, label %197, label %255

221:                                              ; preds = %247, %209
  %222 = phi %"struct.gemmlowp::BlockParams"* [ %248, %247 ], [ %198, %209 ]
  %223 = phi i32 [ %250, %247 ], [ %211, %209 ]
  %224 = phi i32 [ %253, %247 ], [ %207, %209 ]
  %225 = phi %"struct.gemmlowp::BlockParams"* [ %248, %247 ], [ %199, %209 ]
  %226 = phi i32 [ %251, %247 ], [ 0, %209 ]
  %227 = sub nsw i32 %224, %226
  %228 = icmp slt i32 %227, %223
  %229 = select i1 %228, i32 %227, i32 %223
  %230 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %225, i64 0, i32 4
  %231 = load i32, i32* %230, align 4
  %232 = icmp sgt i32 %231, 0
  br i1 %232, label %233, label %247

233:                                              ; preds = %221
  %234 = icmp sgt i32 %229, 0
  br label %235

235:                                              ; preds = %237, %233
  %236 = phi i32 [ 0, %233 ], [ %238, %237 ]
  br i1 %234, label %240, label %237

237:                                              ; preds = %240, %235
  %238 = add nuw nsw i32 %236, 4
  %239 = icmp slt i32 %238, %231
  br i1 %239, label %235, label %245

240:                                              ; preds = %235, %240
  %241 = phi i32 [ %243, %240 ], [ 0, %235 ]
  %242 = add nsw i32 %241, %226
  call void @_ZN8gemmlowp11ComputeImplINS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEES7_NS_12PackedResultEE10ComputeRunEiiii(%"class.gemmlowp::ComputeImpl"* nonnull %4, i32 %242, i32 %236, i32 %200, i32 %205) #19
  %243 = add nuw nsw i32 %241, 4
  %244 = icmp slt i32 %243, %229
  br i1 %244, label %240, label %237

245:                                              ; preds = %237
  %246 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %128, align 8
  br label %247

247:                                              ; preds = %245, %221
  %248 = phi %"struct.gemmlowp::BlockParams"* [ %246, %245 ], [ %222, %221 ]
  %249 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 0
  %250 = load i32, i32* %249, align 4
  %251 = add nsw i32 %250, %226
  %252 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 3
  %253 = load i32, i32* %252, align 4
  %254 = icmp sgt i32 %253, %251
  br i1 %254, label %221, label %212

255:                                              ; preds = %215, %183
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %127) #19
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %136) #19
  %256 = load i32, i32* %141, align 8
  %257 = add nsw i32 %256, %185
  %258 = load i32, i32* %142, align 4
  %259 = add nsw i32 %258, %166
  store i32 %257, i32* %137, align 4
  store i32 %259, i32* %138, align 4
  store i32 %188, i32* %139, align 4
  store i32 %171, i32* %140, align 4
  %260 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %21, align 8
  %261 = load i8, i8* %75, align 8
  %262 = zext i8 %261 to i64
  %263 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %260, i64 0, i32 5, i64 %262
  %264 = load i64, i64* %263, align 8
  %265 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %260, i64 0, i32 2
  %266 = bitcast i8** %265 to i64*
  %267 = load i64, i64* %266, align 8
  %268 = add i64 %267, %264
  %269 = inttoptr i64 %268 to i32*
  %270 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %144, align 8
  %271 = load i8, i8* %145, align 8
  %272 = zext i8 %271 to i64
  %273 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %270, i64 0, i32 5, i64 %272
  %274 = load i64, i64* %273, align 8
  %275 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %270, i64 0, i32 2
  %276 = bitcast i8** %275 to i64*
  %277 = load i64, i64* %276, align 8
  %278 = add i64 %277, %274
  %279 = inttoptr i64 %278 to i32*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %146) #19
  %280 = load %"class.gemmlowp::VectorDup.194"*, %"class.gemmlowp::VectorDup.194"** %147, align 8
  %281 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %280, i64 0, i32 0
  %282 = load i32, i32* %281, align 4, !noalias !1052
  store i32 %282, i32* %148, align 4, !alias.scope !1052
  store i32 %188, i32* %149, align 4, !alias.scope !1052
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %150) #19
  %283 = load %"class.gemmlowp::VectorDup"*, %"class.gemmlowp::VectorDup"** %151, align 8
  %284 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %283, i64 0, i32 0
  %285 = load i32, i32* %284, align 4, !noalias !1055
  store i32 %285, i32* %152, align 4, !alias.scope !1055
  store i32 %171, i32* %153, align 4, !alias.scope !1055
  %286 = load %"class.std::__1::tuple.187"*, %"class.std::__1::tuple.187"** %154, align 8
  call void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIhLNS_8MapOrderE1EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE1EEENSC_ISD_LSE_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SV_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.195"* %143, %"struct.gemmlowp::MatrixBlockBounds"* nonnull dereferenceable(16) %7, %"class.gemmlowp::PackedResult"* nonnull dereferenceable(40) %6, i32 %15, i32* %269, i32* %279, %"class.gemmlowp::VectorDup.194"* nonnull dereferenceable(8) %8, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %9, %"class.std::__1::tuple.187"* dereferenceable(20) %286)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %150) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %146) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %136) #19
  %287 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %288 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %287, i64 0, i32 3
  %289 = load i32, i32* %288, align 4
  %290 = add nsw i32 %289, %185
  %291 = icmp sgt i32 %11, %290
  br i1 %291, label %183, label %175
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSU_ISW_XT4_EEEPNSU_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::SingleThreadGemmContext"*, %"struct.gemmlowp::KernelBase"* dereferenceable(8), %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.180"* dereferenceable(24), %"class.gemmlowp::MatrixMap.182"*, %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.std::__1::tuple.187"* dereferenceable(20)) local_unnamed_addr #1 comdat {
  %9 = alloca %"class.gemmlowp::SideMap", align 8
  %10 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %11 = alloca %"class.gemmlowp::SideMap", align 8
  %12 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %13 = alloca %"class.gemmlowp::SideMap", align 8
  %14 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %15 = alloca %"class.gemmlowp::ComputeImpl", align 8
  %16 = alloca %"struct.gemmlowp::BlockParams", align 4
  %17 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %18 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %19 = alloca %"class.gemmlowp::PackedResult", align 8
  %20 = alloca %"struct.gemmlowp::MatrixBlockBounds", align 4
  %21 = alloca %"class.gemmlowp::VectorDup", align 4
  %22 = alloca %"class.gemmlowp::VectorDup.194", align 4
  %23 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %4, i64 0, i32 1
  %24 = load i32, i32* %23, align 8
  %25 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %4, i64 0, i32 2
  %26 = load i32, i32* %25, align 4
  %27 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 2
  %28 = load i32, i32* %27, align 4
  %29 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0
  %30 = bitcast %"struct.gemmlowp::BlockParams"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %30) #19
  %31 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 0
  %32 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 1
  %33 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 2
  %34 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 3
  %35 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 4
  %36 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 5
  %37 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 1
  %38 = bitcast %"struct.gemmlowp::BlockParams"* %16 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %38, i8 -86, i64 24, i1 false)
  %39 = load i32, i32* %37, align 8
  %40 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 2
  %41 = load i32, i32* %40, align 4
  %42 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 3
  %43 = load float, float* %42, align 8
  call void @_ZN8gemmlowp11BlockParams4InitINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES7_EEEEviiiiiif(%"struct.gemmlowp::BlockParams"* nonnull %16, i32 %24, i32 %26, i32 %28, i32 1, i32 %39, i32 %41, float %43)
  %44 = bitcast %"class.gemmlowp::PackedSideBlock"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %44) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %44, i8 -86, i64 80, i1 false)
  %45 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %45, align 8
  %46 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 4
  store i32 0, i32* %46, align 8
  %47 = load i32, i32* %31, align 4
  %48 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 0
  store i32 %47, i32* %48, align 8
  %49 = load i32, i32* %34, align 4
  %50 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 2
  store i32 %49, i32* %50, align 8
  %51 = load i32, i32* %33, align 4
  %52 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 1
  store i32 %51, i32* %52, align 4
  %53 = load i32, i32* %36, align 4
  %54 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 3
  store i32 %53, i32* %54, align 4
  %55 = mul nsw i32 %53, %49
  %56 = sext i32 %55 to i64
  %57 = add nsw i64 %56, 63
  %58 = and i64 %57, -64
  %59 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 4
  %60 = load i64, i64* %59, align 8, !noalias !1058
  %61 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 3
  %62 = load i64, i64* %61, align 8, !noalias !1058
  %63 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %62
  store i64 %60, i64* %63, align 8, !noalias !1058
  %64 = trunc i64 %62 to i8
  %65 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 6
  %66 = load i64, i64* %65, align 8, !noalias !1058
  %67 = load i64, i64* %61, align 8, !noalias !1058
  %68 = add i64 %67, 1
  store i64 %68, i64* %61, align 8, !noalias !1058
  %69 = load i64, i64* %59, align 8, !noalias !1058
  %70 = add i64 %69, %58
  store i64 %70, i64* %59, align 8, !noalias !1058
  %71 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 0
  store i8 %64, i8* %71, align 8
  %72 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %72, i8 -86, i64 7, i1 false) #19
  %73 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 2
  store i64 %66, i64* %73, align 8
  %74 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 3
  store i8 0, i8* %74, align 8
  %75 = sext i32 %49 to i64
  %76 = shl nsw i64 %75, 2
  %77 = add nsw i64 %76, 63
  %78 = and i64 %77, -64
  %79 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %68
  store i64 %70, i64* %79, align 8, !noalias !1061
  %80 = trunc i64 %68 to i8
  %81 = load i64, i64* %65, align 8, !noalias !1061
  %82 = load i64, i64* %61, align 8, !noalias !1061
  %83 = add i64 %82, 1
  store i64 %83, i64* %61, align 8, !noalias !1061
  %84 = load i64, i64* %59, align 8, !noalias !1061
  %85 = add i64 %84, %78
  store i64 %85, i64* %59, align 8, !noalias !1061
  %86 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 0
  store i8 %80, i8* %86, align 8
  %87 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %87, i8 -86, i64 7, i1 false) #19
  %88 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 2
  store i64 %81, i64* %88, align 8
  %89 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 3
  store i8 5, i8* %89, align 8
  %90 = bitcast %"class.gemmlowp::PackedSideBlock"* %18 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %90) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %90, i8 -86, i64 80, i1 false)
  %91 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %91, align 8
  %92 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 4
  store i32 0, i32* %92, align 8
  %93 = load i32, i32* %32, align 4
  %94 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 0
  store i32 %93, i32* %94, align 8
  %95 = load i32, i32* %35, align 4
  %96 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 2
  store i32 %95, i32* %96, align 8
  %97 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 1
  store i32 %51, i32* %97, align 4
  %98 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 3
  store i32 %53, i32* %98, align 4
  %99 = mul nsw i32 %53, %95
  %100 = sext i32 %99 to i64
  %101 = add nsw i64 %100, 63
  %102 = and i64 %101, -64
  %103 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %83
  store i64 %85, i64* %103, align 8, !noalias !1064
  %104 = trunc i64 %83 to i8
  %105 = load i64, i64* %65, align 8, !noalias !1064
  %106 = load i64, i64* %61, align 8, !noalias !1064
  %107 = add i64 %106, 1
  store i64 %107, i64* %61, align 8, !noalias !1064
  %108 = load i64, i64* %59, align 8, !noalias !1064
  %109 = add i64 %108, %102
  store i64 %109, i64* %59, align 8, !noalias !1064
  %110 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 0
  store i8 %104, i8* %110, align 8
  %111 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %111, i8 -86, i64 7, i1 false) #19
  %112 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 2
  store i64 %105, i64* %112, align 8
  %113 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 3
  store i8 0, i8* %113, align 8
  %114 = sext i32 %95 to i64
  %115 = shl nsw i64 %114, 2
  %116 = add nsw i64 %115, 63
  %117 = and i64 %116, -64
  %118 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %107
  store i64 %109, i64* %118, align 8, !noalias !1067
  %119 = trunc i64 %107 to i8
  %120 = load i64, i64* %65, align 8, !noalias !1067
  %121 = load i64, i64* %61, align 8, !noalias !1067
  %122 = add i64 %121, 1
  store i64 %122, i64* %61, align 8, !noalias !1067
  %123 = load i64, i64* %59, align 8, !noalias !1067
  %124 = add i64 %123, %117
  store i64 %124, i64* %59, align 8, !noalias !1067
  %125 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 0
  store i8 %119, i8* %125, align 8
  %126 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %126, i8 -86, i64 7, i1 false) #19
  %127 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 2
  store i64 %120, i64* %127, align 8
  %128 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 3
  store i8 5, i8* %128, align 8
  %129 = bitcast %"class.gemmlowp::PackedResult"* %19 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %129) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %129, i8 -86, i64 32, i1 false)
  %130 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 0
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %130, align 8
  %131 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 2
  store %"struct.gemmlowp::BlockParams"* %16, %"struct.gemmlowp::BlockParams"** %131, align 8
  %132 = load i32, i32* %34, align 4
  %133 = mul nsw i32 %95, %132
  %134 = sext i32 %133 to i64
  %135 = shl nsw i64 %134, 2
  %136 = add nsw i64 %135, 63
  %137 = and i64 %136, -64
  %138 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %122
  store i64 %124, i64* %138, align 8, !noalias !1070
  %139 = trunc i64 %122 to i8
  %140 = load i64, i64* %65, align 8, !noalias !1070
  %141 = bitcast i64* %61 to <2 x i64>*
  %142 = load <2 x i64>, <2 x i64>* %141, align 8, !noalias !1070
  %143 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %137, i32 1
  %144 = add <2 x i64> %142, %143
  %145 = bitcast i64* %61 to <2 x i64>*
  store <2 x i64> %144, <2 x i64>* %145, align 8, !noalias !1070
  %146 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 0
  store i8 %139, i8* %146, align 8
  %147 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %147, i8 -86, i64 7, i1 false) #19
  %148 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 2
  store i64 %140, i64* %148, align 8
  %149 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 3
  store i8 5, i8* %149, align 8
  call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %29)
  %150 = load i32, i32* %35, align 4
  %151 = icmp sge i32 %150, %26
  br i1 %151, label %152, label %169

152:                                              ; preds = %8
  %153 = bitcast %"class.gemmlowp::SideMap"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %153) #19
  %154 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 1
  %155 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 2
  %156 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 3
  %157 = bitcast %"class.gemmlowp::MatrixMap.180"* %3 to i64*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %153, i8 -86, i64 24, i1 false) #19
  %158 = load i64, i64* %157, align 8
  %159 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 2
  %160 = load i32, i32* %159, align 4
  %161 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 1
  %162 = load i32, i32* %161, align 8
  %163 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 3
  %164 = load i32, i32* %163, align 8
  %165 = bitcast %"class.gemmlowp::SideMap"* %9 to i64*
  store i64 %158, i64* %165, align 8
  store i32 %160, i32* %154, align 8
  store i32 %162, i32* %155, align 4
  store i32 %164, i32* %156, align 8
  %166 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %166) #19
  %167 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 0
  %168 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 1
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %167, align 8
  store %"class.gemmlowp::SideMap"* %9, %"class.gemmlowp::SideMap"** %168, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %10) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %166) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %153) #19
  br label %169

169:                                              ; preds = %152, %8
  %170 = icmp sgt i32 %24, 0
  br i1 %170, label %171, label %216

171:                                              ; preds = %169
  %172 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 0
  %173 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 3
  %174 = bitcast %"class.gemmlowp::SideMap"* %11 to i8*
  %175 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 1
  %176 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 2
  %177 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 3
  %178 = bitcast %"class.gemmlowp::SideMap"* %11 to i64*
  %179 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %12 to i8*
  %180 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %12, i64 0, i32 0
  %181 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %12, i64 0, i32 1
  %182 = icmp sgt i32 %26, 0
  %183 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 0
  %184 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 3
  %185 = bitcast %"class.gemmlowp::SideMap"* %13 to i8*
  %186 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 1
  %187 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 2
  %188 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 3
  %189 = bitcast %"class.gemmlowp::SideMap"* %13 to i64*
  %190 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %14 to i8*
  %191 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %14, i64 0, i32 0
  %192 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %14, i64 0, i32 1
  %193 = bitcast %"class.gemmlowp::ComputeImpl"* %15 to i8*
  %194 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 0
  %195 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 1
  %196 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 2
  %197 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 3
  %198 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 4
  %199 = add i32 %28, 15
  %200 = and i32 %199, -16
  %201 = icmp sgt i32 %200, 0
  %202 = bitcast %"struct.gemmlowp::MatrixBlockBounds"* %20 to i8*
  %203 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 0
  %204 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 1
  %205 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 2
  %206 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 3
  %207 = bitcast %"class.gemmlowp::VectorDup"* %21 to i8*
  %208 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %209 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %21, i64 0, i32 0
  %210 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %21, i64 0, i32 1
  %211 = bitcast %"class.gemmlowp::VectorDup.194"* %22 to i8*
  %212 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %6, i64 0, i32 0
  %213 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %22, i64 0, i32 0
  %214 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %22, i64 0, i32 1
  %215 = load i32, i32* %34, align 4
  br label %221

216:                                              ; preds = %235, %169
  %217 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 0
  store i8 0, i8* %217, align 8
  %218 = load i64, i64* %65, align 8
  %219 = add i64 %218, 1
  store i64 %219, i64* %65, align 8
  %220 = bitcast i64* %61 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %220, i8 0, i64 16, i1 false) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %129) #19
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %90) #19
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %44) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %30) #19
  ret void

221:                                              ; preds = %171, %235
  %222 = phi i32 [ %215, %171 ], [ %236, %235 ]
  %223 = phi i32 [ 0, %171 ], [ %237, %235 ]
  %224 = sub nsw i32 %24, %223
  %225 = icmp slt i32 %224, %222
  %226 = select i1 %225, i32 %224, i32 %222
  %227 = load i8*, i8** %172, align 8, !noalias !1073
  %228 = load i32, i32* %173, align 8, !noalias !1073
  %229 = mul nsw i32 %228, %223
  %230 = sext i32 %229 to i64
  %231 = getelementptr inbounds i8, i8* %227, i64 %230
  %232 = ptrtoint i8* %231 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %174) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %174, i8 -86, i64 24, i1 false) #19
  store i64 %232, i64* %178, align 8
  store i32 %226, i32* %175, align 8
  store i32 %28, i32* %176, align 4
  store i32 %228, i32* %177, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %179) #19
  store %"class.gemmlowp::PackedSideBlock"* %17, %"class.gemmlowp::PackedSideBlock"** %180, align 8
  store %"class.gemmlowp::SideMap"* %11, %"class.gemmlowp::SideMap"** %181, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %12) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %179) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %174) #19
  br i1 %182, label %233, label %235

233:                                              ; preds = %221
  %234 = load i32, i32* %35, align 4
  br label %239

235:                                              ; preds = %311, %221
  %236 = load i32, i32* %34, align 4
  %237 = add nsw i32 %236, %223
  %238 = icmp sgt i32 %24, %237
  br i1 %238, label %221, label %216

239:                                              ; preds = %233, %311
  %240 = phi i32 [ %334, %311 ], [ %234, %233 ]
  %241 = phi i32 [ %335, %311 ], [ 0, %233 ]
  %242 = sub nsw i32 %26, %241
  %243 = icmp slt i32 %242, %240
  %244 = select i1 %243, i32 %242, i32 %240
  br i1 %151, label %252, label %245

245:                                              ; preds = %239
  %246 = load i8*, i8** %183, align 8, !noalias !1076
  %247 = load i32, i32* %184, align 8, !noalias !1076
  %248 = mul nsw i32 %247, %241
  %249 = sext i32 %248 to i64
  %250 = getelementptr inbounds i8, i8* %246, i64 %249
  %251 = ptrtoint i8* %250 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %185) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %185, i8 -86, i64 24, i1 false) #19
  store i64 %251, i64* %189, align 8
  store i32 %244, i32* %186, align 8
  store i32 %28, i32* %187, align 4
  store i32 %247, i32* %188, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %190) #19
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %191, align 8
  store %"class.gemmlowp::SideMap"* %13, %"class.gemmlowp::SideMap"** %192, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %14) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %190) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %185) #19
  br label %252

252:                                              ; preds = %245, %239
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %193) #19
  store %"struct.gemmlowp::KernelBase"* %1, %"struct.gemmlowp::KernelBase"** %194, align 8
  store %"struct.gemmlowp::BlockParams"* %16, %"struct.gemmlowp::BlockParams"** %195, align 8
  store %"class.gemmlowp::PackedResult"* %19, %"class.gemmlowp::PackedResult"** %196, align 8
  store %"class.gemmlowp::PackedSideBlock"* %17, %"class.gemmlowp::PackedSideBlock"** %197, align 8
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %198, align 8
  br i1 %201, label %253, label %311

253:                                              ; preds = %252, %271
  %254 = phi %"struct.gemmlowp::BlockParams"* [ %273, %271 ], [ %16, %252 ]
  %255 = phi %"struct.gemmlowp::BlockParams"* [ %274, %271 ], [ %16, %252 ]
  %256 = phi i32 [ %275, %271 ], [ 0, %252 ]
  %257 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 2
  %258 = sub nsw i32 %200, %256
  %259 = load i32, i32* %257, align 4
  %260 = icmp slt i32 %258, %259
  %261 = select i1 %260, i32 %258, i32 %259
  %262 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 3
  %263 = load i32, i32* %262, align 4
  %264 = icmp sgt i32 %263, 0
  br i1 %264, label %265, label %271

265:                                              ; preds = %253
  %266 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 0
  %267 = load i32, i32* %266, align 4
  br label %277

268:                                              ; preds = %303
  %269 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 2
  %270 = load i32, i32* %269, align 4
  br label %271

271:                                              ; preds = %268, %253
  %272 = phi i32 [ %259, %253 ], [ %270, %268 ]
  %273 = phi %"struct.gemmlowp::BlockParams"* [ %254, %253 ], [ %304, %268 ]
  %274 = phi %"struct.gemmlowp::BlockParams"* [ %255, %253 ], [ %304, %268 ]
  %275 = add nsw i32 %272, %256
  %276 = icmp sgt i32 %200, %275
  br i1 %276, label %253, label %311

277:                                              ; preds = %303, %265
  %278 = phi %"struct.gemmlowp::BlockParams"* [ %304, %303 ], [ %254, %265 ]
  %279 = phi i32 [ %306, %303 ], [ %267, %265 ]
  %280 = phi i32 [ %309, %303 ], [ %263, %265 ]
  %281 = phi %"struct.gemmlowp::BlockParams"* [ %304, %303 ], [ %255, %265 ]
  %282 = phi i32 [ %307, %303 ], [ 0, %265 ]
  %283 = sub nsw i32 %280, %282
  %284 = icmp slt i32 %283, %279
  %285 = select i1 %284, i32 %283, i32 %279
  %286 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %281, i64 0, i32 4
  %287 = load i32, i32* %286, align 4
  %288 = icmp sgt i32 %287, 0
  br i1 %288, label %289, label %303

289:                                              ; preds = %277
  %290 = icmp sgt i32 %285, 0
  br label %291

291:                                              ; preds = %293, %289
  %292 = phi i32 [ 0, %289 ], [ %294, %293 ]
  br i1 %290, label %296, label %293

293:                                              ; preds = %296, %291
  %294 = add nuw nsw i32 %292, 4
  %295 = icmp slt i32 %294, %287
  br i1 %295, label %291, label %301

296:                                              ; preds = %291, %296
  %297 = phi i32 [ %299, %296 ], [ 0, %291 ]
  %298 = add nsw i32 %297, %282
  call void @_ZN8gemmlowp11ComputeImplINS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEES7_NS_12PackedResultEE10ComputeRunEiiii(%"class.gemmlowp::ComputeImpl"* nonnull %15, i32 %298, i32 %292, i32 %256, i32 %261) #19
  %299 = add nuw nsw i32 %297, 4
  %300 = icmp slt i32 %299, %285
  br i1 %300, label %296, label %293

301:                                              ; preds = %293
  %302 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %195, align 8
  br label %303

303:                                              ; preds = %301, %277
  %304 = phi %"struct.gemmlowp::BlockParams"* [ %302, %301 ], [ %278, %277 ]
  %305 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 0
  %306 = load i32, i32* %305, align 4
  %307 = add nsw i32 %306, %282
  %308 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 3
  %309 = load i32, i32* %308, align 4
  %310 = icmp sgt i32 %309, %307
  br i1 %310, label %277, label %268

311:                                              ; preds = %271, %252
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %193) #19
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %202) #19
  store i32 %223, i32* %203, align 4
  store i32 %241, i32* %204, align 4
  store i32 %226, i32* %205, align 4
  store i32 %244, i32* %206, align 4
  %312 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %45, align 8
  %313 = load i8, i8* %86, align 8
  %314 = zext i8 %313 to i64
  %315 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %312, i64 0, i32 5, i64 %314
  %316 = load i64, i64* %315, align 8
  %317 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %312, i64 0, i32 2
  %318 = bitcast i8** %317 to i64*
  %319 = load i64, i64* %318, align 8
  %320 = add i64 %319, %316
  %321 = inttoptr i64 %320 to i32*
  %322 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %91, align 8
  %323 = load i8, i8* %125, align 8
  %324 = zext i8 %323 to i64
  %325 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %322, i64 0, i32 5, i64 %324
  %326 = load i64, i64* %325, align 8
  %327 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %322, i64 0, i32 2
  %328 = bitcast i8** %327 to i64*
  %329 = load i64, i64* %328, align 8
  %330 = add i64 %329, %326
  %331 = inttoptr i64 %330 to i32*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %207) #19
  %332 = load i32, i32* %208, align 4, !noalias !1079
  store i32 %332, i32* %209, align 4, !alias.scope !1079
  store i32 %226, i32* %210, align 4, !alias.scope !1079
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %211) #19
  %333 = load i32, i32* %212, align 4, !noalias !1082
  store i32 %333, i32* %213, align 4, !alias.scope !1082
  store i32 %244, i32* %214, align 4, !alias.scope !1082
  call void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIhLNS_8MapOrderE0EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE0EEENSC_ISD_LSE_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SV_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.182"* %4, %"struct.gemmlowp::MatrixBlockBounds"* nonnull dereferenceable(16) %20, %"class.gemmlowp::PackedResult"* nonnull dereferenceable(40) %19, i32 %28, i32* %321, i32* %331, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %21, %"class.gemmlowp::VectorDup.194"* nonnull dereferenceable(8) %22, %"class.std::__1::tuple.187"* dereferenceable(20) %7)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %211) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %207) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %202) #19
  %334 = load i32, i32* %35, align 4
  %335 = add nsw i32 %334, %241
  %336 = icmp sgt i32 %26, %335
  br i1 %336, label %239, label %235
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIhLNS_8MapOrderE0EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE0EEENSC_ISD_LSE_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SV_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.182"*, %"struct.gemmlowp::MatrixBlockBounds"* dereferenceable(16), %"class.gemmlowp::PackedResult"* dereferenceable(40), i32, i32*, i32*, %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.std::__1::tuple.187"* dereferenceable(20)) local_unnamed_addr #1 comdat {
  %10 = alloca %"class.gemmlowp::MatrixMap.214", align 8
  %11 = alloca %"class.gemmlowp::VectorMap", align 8
  %12 = alloca %"class.gemmlowp::VectorMap.201", align 8
  %13 = alloca %"struct.gemmlowp::OutputPipelineExecutor.393", align 8
  %14 = alloca %"struct.gemmlowp::OutputPipelineExecutor.400", align 8
  %15 = alloca %"struct.gemmlowp::OutputPipelineExecutor.407", align 8
  %16 = alloca %"struct.gemmlowp::OutputPipelineExecutor.414", align 8
  %17 = alloca %"struct.gemmlowp::OutputPipelineExecutor.421", align 8
  %18 = bitcast %"class.gemmlowp::MatrixMap.214"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %18) #19
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %10, i64 0, i32 0
  %20 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %10, i64 0, i32 1
  %21 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %10, i64 0, i32 2
  %22 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %10, i64 0, i32 3
  %23 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 0
  %24 = bitcast %"class.gemmlowp::MatrixMap.214"* %10 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %24, i8 -86, i64 24, i1 false)
  %25 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %23, align 8, !noalias !1085
  %26 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 1, i32 0
  %27 = load i8, i8* %26, align 8, !noalias !1085
  %28 = zext i8 %27 to i64
  %29 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %25, i64 0, i32 5, i64 %28
  %30 = load i64, i64* %29, align 8, !noalias !1085
  %31 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %25, i64 0, i32 2
  %32 = bitcast i8** %31 to i64*
  %33 = load i64, i64* %32, align 8, !noalias !1085
  %34 = add i64 %33, %30
  %35 = inttoptr i64 %34 to i32*
  %36 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 2
  %37 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %36, align 8, !noalias !1085
  %38 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %37, i64 0, i32 3
  %39 = load i32, i32* %38, align 4, !noalias !1085
  %40 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %37, i64 0, i32 4
  %41 = load i32, i32* %40, align 4, !noalias !1085
  store i32* %35, i32** %19, align 8, !alias.scope !1085
  store i32 %39, i32* %20, align 8, !alias.scope !1085
  store i32 %41, i32* %21, align 4, !alias.scope !1085
  store i32 %39, i32* %22, align 8, !alias.scope !1085
  %42 = bitcast %"class.gemmlowp::VectorMap"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %42) #19
  %43 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %11, i64 0, i32 0
  %44 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %11, i64 0, i32 1
  %45 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 2
  %46 = bitcast %"class.gemmlowp::VectorMap"* %11 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %46, i8 -86, i64 16, i1 false)
  %47 = load i32, i32* %45, align 4
  store i32* %4, i32** %43, align 8
  store i32 %47, i32* %44, align 8
  %48 = bitcast %"class.gemmlowp::VectorMap.201"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %48) #19
  %49 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %12, i64 0, i32 0
  %50 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %12, i64 0, i32 1
  %51 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 3
  %52 = bitcast %"class.gemmlowp::VectorMap.201"* %12 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %52, i8 -86, i64 16, i1 false)
  %53 = load i32, i32* %51, align 4
  store i32* %5, i32** %49, align 8
  store i32 %53, i32* %50, align 8
  %54 = getelementptr inbounds %"class.std::__1::tuple.187", %"class.std::__1::tuple.187"* %8, i64 0, i32 0, i32 0, i32 0
  %55 = getelementptr inbounds %"class.std::__1::tuple.187", %"class.std::__1::tuple.187"* %8, i64 0, i32 0, i32 0, i32 0, i32 1
  %56 = load i32, i32* %55, align 4
  %57 = icmp sgt i32 %56, 0
  %58 = select i1 %57, i32 %56, i32 0
  %59 = sub nsw i32 0, %56
  %60 = icmp sgt i32 %59, 0
  %61 = select i1 %60, i32 %59, i32 0
  %62 = getelementptr inbounds %"class.std::__1::tuple.187", %"class.std::__1::tuple.187"* %8, i64 0, i32 0, i32 1, i32 0
  %63 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.393"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %63) #19
  %64 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.393", %"struct.gemmlowp::OutputPipelineExecutor.393"* %13, i64 0, i32 0, i32 0, i32 0, i32 0
  %65 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.393", %"struct.gemmlowp::OutputPipelineExecutor.393"* %13, i64 0, i32 0, i32 0, i32 0, i32 1
  %66 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.393", %"struct.gemmlowp::OutputPipelineExecutor.393"* %13, i64 0, i32 0, i32 0, i32 0, i32 2
  %67 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.393", %"struct.gemmlowp::OutputPipelineExecutor.393"* %13, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %68 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.393", %"struct.gemmlowp::OutputPipelineExecutor.393"* %13, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %69 = bitcast i8* %68 to i64*
  store i64 -6148914691236517206, i64* %69, align 8
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %54, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %64, align 8
  store i32 %58, i32* %65, align 8
  store i32 %61, i32* %66, align 4
  store %"struct.gemmlowp::OutputStageClamp"* %62, %"struct.gemmlowp::OutputStageClamp"** %67, align 8
  %70 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.400"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %70) #19
  %71 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.400", %"struct.gemmlowp::OutputPipelineExecutor.400"* %14, i64 0, i32 0, i32 0, i32 0, i32 0
  %72 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.400", %"struct.gemmlowp::OutputPipelineExecutor.400"* %14, i64 0, i32 0, i32 0, i32 0, i32 1
  %73 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.400", %"struct.gemmlowp::OutputPipelineExecutor.400"* %14, i64 0, i32 0, i32 0, i32 0, i32 2
  %74 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.400", %"struct.gemmlowp::OutputPipelineExecutor.400"* %14, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %75 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.400", %"struct.gemmlowp::OutputPipelineExecutor.400"* %14, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %76 = bitcast i8* %75 to i64*
  store i64 -6148914691236517206, i64* %76, align 8
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %54, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %71, align 8
  store i32 %58, i32* %72, align 8
  store i32 %61, i32* %73, align 4
  store %"struct.gemmlowp::OutputStageClamp"* %62, %"struct.gemmlowp::OutputStageClamp"** %74, align 8
  %77 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.407"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %77) #19
  %78 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.407", %"struct.gemmlowp::OutputPipelineExecutor.407"* %15, i64 0, i32 0, i32 0, i32 0, i32 0
  %79 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.407", %"struct.gemmlowp::OutputPipelineExecutor.407"* %15, i64 0, i32 0, i32 0, i32 0, i32 1
  %80 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.407", %"struct.gemmlowp::OutputPipelineExecutor.407"* %15, i64 0, i32 0, i32 0, i32 0, i32 2
  %81 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.407", %"struct.gemmlowp::OutputPipelineExecutor.407"* %15, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %82 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.407", %"struct.gemmlowp::OutputPipelineExecutor.407"* %15, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %83 = bitcast i8* %82 to i64*
  store i64 -6148914691236517206, i64* %83, align 8
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %54, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %78, align 8
  store i32 %58, i32* %79, align 8
  store i32 %61, i32* %80, align 4
  store %"struct.gemmlowp::OutputStageClamp"* %62, %"struct.gemmlowp::OutputStageClamp"** %81, align 8
  %84 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.414"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %84) #19
  %85 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.414", %"struct.gemmlowp::OutputPipelineExecutor.414"* %16, i64 0, i32 0, i32 0, i32 0, i32 0
  %86 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.414", %"struct.gemmlowp::OutputPipelineExecutor.414"* %16, i64 0, i32 0, i32 0, i32 0, i32 1
  %87 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.414", %"struct.gemmlowp::OutputPipelineExecutor.414"* %16, i64 0, i32 0, i32 0, i32 0, i32 2
  %88 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.414", %"struct.gemmlowp::OutputPipelineExecutor.414"* %16, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %89 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.414", %"struct.gemmlowp::OutputPipelineExecutor.414"* %16, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %90 = bitcast i8* %89 to i64*
  store i64 -6148914691236517206, i64* %90, align 8
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %54, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %85, align 8
  store i32 %58, i32* %86, align 8
  store i32 %61, i32* %87, align 4
  store %"struct.gemmlowp::OutputStageClamp"* %62, %"struct.gemmlowp::OutputStageClamp"** %88, align 8
  %91 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.421"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %91) #19
  %92 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.421", %"struct.gemmlowp::OutputPipelineExecutor.421"* %17, i64 0, i32 0, i32 0, i32 0, i32 0
  %93 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.421", %"struct.gemmlowp::OutputPipelineExecutor.421"* %17, i64 0, i32 0, i32 0, i32 0, i32 1
  %94 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.421", %"struct.gemmlowp::OutputPipelineExecutor.421"* %17, i64 0, i32 0, i32 0, i32 0, i32 2
  %95 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.421", %"struct.gemmlowp::OutputPipelineExecutor.421"* %17, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %96 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.421", %"struct.gemmlowp::OutputPipelineExecutor.421"* %17, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %97 = bitcast i8* %96 to i64*
  store i64 -6148914691236517206, i64* %97, align 8
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %54, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %92, align 8
  store i32 %58, i32* %93, align 8
  store i32 %61, i32* %94, align 4
  store %"struct.gemmlowp::OutputStageClamp"* %62, %"struct.gemmlowp::OutputStageClamp"** %95, align 8
  %98 = load i32, i32* %51, align 4
  %99 = icmp slt i32 %98, 4
  br i1 %99, label %104, label %100

100:                                              ; preds = %9
  %101 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 1
  %102 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 0
  %103 = load i32, i32* %45, align 4
  br label %128

104:                                              ; preds = %230, %9
  %105 = phi i32 [ %98, %9 ], [ %233, %230 ]
  %106 = phi i32 [ 0, %9 ], [ %232, %230 ]
  %107 = icmp slt i32 %106, %105
  br i1 %107, label %108, label %389

108:                                              ; preds = %104
  %109 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 1
  %110 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 0
  %111 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %112 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %7, i64 0, i32 0
  %113 = getelementptr inbounds %"class.std::__1::tuple.187", %"class.std::__1::tuple.187"* %8, i64 0, i32 0, i32 0, i32 0, i32 2
  %114 = shl i32 1, %58
  %115 = sext i32 %114 to i64
  %116 = getelementptr inbounds %"class.std::__1::tuple.187", %"class.std::__1::tuple.187"* %8, i64 0, i32 0, i32 0, i32 0, i32 0
  %117 = zext i32 %61 to i64
  %118 = shl nsw i64 -1, %117
  %119 = trunc i64 %118 to i32
  %120 = xor i32 %119, -1
  %121 = ashr i32 %120, 1
  %122 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %62, i64 0, i32 0
  %123 = getelementptr inbounds %"class.std::__1::tuple.187", %"class.std::__1::tuple.187"* %8, i64 0, i32 0, i32 1, i32 0, i32 1
  %124 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %0, i64 0, i32 0
  %125 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %0, i64 0, i32 3
  %126 = zext i32 %106 to i64
  %127 = load i32, i32* %45, align 4
  br label %236

128:                                              ; preds = %100, %230
  %129 = phi i32 [ %103, %100 ], [ %231, %230 ]
  %130 = phi i32 [ 0, %100 ], [ %232, %230 ]
  %131 = load i32, i32* %101, align 4
  %132 = add nsw i32 %131, %130
  %133 = load i32*, i32** %19, align 8
  %134 = load i32, i32* %22, align 8
  %135 = mul nsw i32 %134, %130
  %136 = sext i32 %135 to i64
  %137 = load i32*, i32** %43, align 8
  %138 = bitcast i32* %137 to i8*
  call void @llvm.prefetch(i8* %138, i32 0, i32 3, i32 1) #19
  %139 = getelementptr inbounds i32, i32* %137, i64 4
  %140 = bitcast i32* %139 to i8*
  call void @llvm.prefetch(i8* %140, i32 0, i32 3, i32 1) #19
  %141 = getelementptr inbounds i32, i32* %133, i64 %136
  %142 = sext i32 %134 to i64
  %143 = bitcast i32* %141 to i8*
  call void @llvm.prefetch(i8* %143, i32 0, i32 3, i32 1) #19
  %144 = getelementptr inbounds i32, i32* %141, i64 4
  %145 = bitcast i32* %144 to i8*
  call void @llvm.prefetch(i8* %145, i32 0, i32 3, i32 1) #19
  %146 = getelementptr inbounds i32, i32* %141, i64 %142
  %147 = bitcast i32* %146 to i8*
  call void @llvm.prefetch(i8* %147, i32 0, i32 3, i32 1) #19
  %148 = getelementptr inbounds i32, i32* %146, i64 4
  %149 = bitcast i32* %148 to i8*
  call void @llvm.prefetch(i8* %149, i32 0, i32 3, i32 1) #19
  %150 = shl nsw i64 %142, 1
  %151 = getelementptr inbounds i32, i32* %141, i64 %150
  %152 = bitcast i32* %151 to i8*
  call void @llvm.prefetch(i8* %152, i32 0, i32 3, i32 1) #19
  %153 = getelementptr inbounds i32, i32* %151, i64 4
  %154 = bitcast i32* %153 to i8*
  call void @llvm.prefetch(i8* %154, i32 0, i32 3, i32 1) #19
  %155 = mul nsw i64 %142, 3
  %156 = getelementptr inbounds i32, i32* %141, i64 %155
  %157 = bitcast i32* %156 to i8*
  call void @llvm.prefetch(i8* %157, i32 0, i32 3, i32 1) #19
  %158 = getelementptr inbounds i32, i32* %156, i64 4
  %159 = bitcast i32* %158 to i8*
  call void @llvm.prefetch(i8* %159, i32 0, i32 3, i32 1) #19
  %160 = icmp slt i32 %129, 8
  br i1 %160, label %163, label %168

161:                                              ; preds = %168
  %162 = trunc i64 %176 to i32
  br label %163

163:                                              ; preds = %161, %128
  %164 = phi i32 [ %129, %128 ], [ %203, %161 ]
  %165 = phi i32 [ 0, %128 ], [ %162, %161 ]
  %166 = add nsw i32 %164, -4
  %167 = icmp sgt i32 %165, %166
  br i1 %167, label %211, label %215

168:                                              ; preds = %128, %207
  %169 = phi i32* [ %210, %207 ], [ %137, %128 ]
  %170 = phi i32 [ %209, %207 ], [ %134, %128 ]
  %171 = phi i32* [ %208, %207 ], [ %133, %128 ]
  %172 = phi i64 [ %176, %207 ], [ 0, %128 ]
  %173 = load i32, i32* %102, align 4
  %174 = trunc i64 %172 to i32
  %175 = add nsw i32 %173, %174
  %176 = add nuw i64 %172, 8
  %177 = mul nsw i32 %170, %130
  %178 = sext i32 %177 to i64
  %179 = getelementptr inbounds i32, i32* %169, i64 %176
  %180 = bitcast i32* %179 to i8*
  call void @llvm.prefetch(i8* %180, i32 0, i32 3, i32 1) #19
  %181 = getelementptr inbounds i32, i32* %179, i64 4
  %182 = bitcast i32* %181 to i8*
  call void @llvm.prefetch(i8* %182, i32 0, i32 3, i32 1) #19
  %183 = getelementptr inbounds i32, i32* %171, i64 %176
  %184 = getelementptr inbounds i32, i32* %183, i64 %178
  %185 = sext i32 %170 to i64
  %186 = bitcast i32* %184 to i8*
  call void @llvm.prefetch(i8* %186, i32 0, i32 3, i32 1) #19
  %187 = getelementptr inbounds i32, i32* %184, i64 4
  %188 = bitcast i32* %187 to i8*
  call void @llvm.prefetch(i8* %188, i32 0, i32 3, i32 1) #19
  %189 = getelementptr inbounds i32, i32* %184, i64 %185
  %190 = bitcast i32* %189 to i8*
  call void @llvm.prefetch(i8* %190, i32 0, i32 3, i32 1) #19
  %191 = getelementptr inbounds i32, i32* %189, i64 4
  %192 = bitcast i32* %191 to i8*
  call void @llvm.prefetch(i8* %192, i32 0, i32 3, i32 1) #19
  %193 = shl nsw i64 %185, 1
  %194 = getelementptr inbounds i32, i32* %184, i64 %193
  %195 = bitcast i32* %194 to i8*
  call void @llvm.prefetch(i8* %195, i32 0, i32 3, i32 1) #19
  %196 = getelementptr inbounds i32, i32* %194, i64 4
  %197 = bitcast i32* %196 to i8*
  call void @llvm.prefetch(i8* %197, i32 0, i32 3, i32 1) #19
  %198 = mul nsw i64 %185, 3
  %199 = getelementptr inbounds i32, i32* %184, i64 %198
  %200 = bitcast i32* %199 to i8*
  call void @llvm.prefetch(i8* %200, i32 0, i32 3, i32 1) #19
  %201 = getelementptr inbounds i32, i32* %199, i64 4
  %202 = bitcast i32* %201 to i8*
  call void @llvm.prefetch(i8* %202, i32 0, i32 3, i32 1) #19
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %10, %"struct.gemmlowp::OutputPipelineExecutor.421"* nonnull dereferenceable(32) %17, %"class.gemmlowp::MatrixMap.182"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %11, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorDup"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %7, i32 %3, i32 %174, i32 %130, i32 %175, i32 %132, i32 %175, i32 %132)
  %203 = load i32, i32* %45, align 4
  %204 = add nsw i32 %203, -8
  %205 = trunc i64 %176 to i32
  %206 = icmp slt i32 %204, %205
  br i1 %206, label %161, label %207

207:                                              ; preds = %168
  %208 = load i32*, i32** %19, align 8
  %209 = load i32, i32* %22, align 8
  %210 = load i32*, i32** %43, align 8
  br label %168

211:                                              ; preds = %215, %163
  %212 = phi i32 [ %164, %163 ], [ %220, %215 ]
  %213 = phi i32 [ %165, %163 ], [ %219, %215 ]
  %214 = icmp slt i32 %213, %212
  br i1 %214, label %223, label %230

215:                                              ; preds = %163, %215
  %216 = phi i32 [ %219, %215 ], [ %165, %163 ]
  %217 = load i32, i32* %102, align 4
  %218 = add nsw i32 %217, %216
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %10, %"struct.gemmlowp::OutputPipelineExecutor.414"* nonnull dereferenceable(32) %16, %"class.gemmlowp::MatrixMap.182"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %11, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorDup"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %7, i32 %3, i32 %216, i32 %130, i32 %218, i32 %132, i32 %218, i32 %132)
  %219 = add nuw nsw i32 %216, 4
  %220 = load i32, i32* %45, align 4
  %221 = add nsw i32 %220, -4
  %222 = icmp sgt i32 %219, %221
  br i1 %222, label %211, label %215

223:                                              ; preds = %211, %223
  %224 = phi i32 [ %227, %223 ], [ %213, %211 ]
  %225 = load i32, i32* %102, align 4
  %226 = add nsw i32 %225, %224
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %10, %"struct.gemmlowp::OutputPipelineExecutor.407"* nonnull dereferenceable(32) %15, %"class.gemmlowp::MatrixMap.182"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %11, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorDup"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %7, i32 %3, i32 %224, i32 %130, i32 %226, i32 %132, i32 %226, i32 %132)
  %227 = add nuw nsw i32 %224, 1
  %228 = load i32, i32* %45, align 4
  %229 = icmp slt i32 %227, %228
  br i1 %229, label %223, label %230

230:                                              ; preds = %223, %211
  %231 = phi i32 [ %212, %211 ], [ %228, %223 ]
  %232 = add nuw nsw i32 %130, 4
  %233 = load i32, i32* %51, align 4
  %234 = add nsw i32 %233, -4
  %235 = icmp sgt i32 %232, %234
  br i1 %235, label %104, label %128

236:                                              ; preds = %108, %383
  %237 = phi i32 [ %127, %108 ], [ %384, %383 ]
  %238 = phi i64 [ %126, %108 ], [ %385, %383 ]
  %239 = load i32, i32* %109, align 4
  %240 = trunc i64 %238 to i32
  %241 = add nsw i32 %239, %240
  %242 = load i32*, i32** %19, align 8
  %243 = load i32, i32* %22, align 8
  %244 = mul nsw i32 %243, %240
  %245 = sext i32 %244 to i64
  %246 = load i32*, i32** %43, align 8
  %247 = bitcast i32* %246 to i8*
  call void @llvm.prefetch(i8* %247, i32 0, i32 3, i32 1) #19
  %248 = getelementptr inbounds i32, i32* %246, i64 4
  %249 = bitcast i32* %248 to i8*
  call void @llvm.prefetch(i8* %249, i32 0, i32 3, i32 1) #19
  %250 = getelementptr inbounds i32, i32* %242, i64 %245
  %251 = bitcast i32* %250 to i8*
  call void @llvm.prefetch(i8* %251, i32 0, i32 3, i32 1) #19
  %252 = getelementptr inbounds i32, i32* %250, i64 4
  %253 = bitcast i32* %252 to i8*
  call void @llvm.prefetch(i8* %253, i32 0, i32 3, i32 1) #19
  %254 = icmp slt i32 %237, 8
  br i1 %254, label %257, label %262

255:                                              ; preds = %262
  %256 = trunc i64 %270 to i32
  br label %257

257:                                              ; preds = %255, %236
  %258 = phi i32 [ %237, %236 ], [ %282, %255 ]
  %259 = phi i32 [ 0, %236 ], [ %256, %255 ]
  %260 = add nsw i32 %258, -4
  %261 = icmp sgt i32 %259, %260
  br i1 %261, label %290, label %296

262:                                              ; preds = %236, %286
  %263 = phi i32* [ %289, %286 ], [ %246, %236 ]
  %264 = phi i32 [ %288, %286 ], [ %243, %236 ]
  %265 = phi i32* [ %287, %286 ], [ %242, %236 ]
  %266 = phi i64 [ %270, %286 ], [ 0, %236 ]
  %267 = load i32, i32* %110, align 4
  %268 = trunc i64 %266 to i32
  %269 = add nsw i32 %267, %268
  %270 = add nuw i64 %266, 8
  %271 = mul nsw i32 %264, %240
  %272 = sext i32 %271 to i64
  %273 = getelementptr inbounds i32, i32* %263, i64 %270
  %274 = bitcast i32* %273 to i8*
  call void @llvm.prefetch(i8* %274, i32 0, i32 3, i32 1) #19
  %275 = getelementptr inbounds i32, i32* %273, i64 4
  %276 = bitcast i32* %275 to i8*
  call void @llvm.prefetch(i8* %276, i32 0, i32 3, i32 1) #19
  %277 = getelementptr inbounds i32, i32* %265, i64 %270
  %278 = getelementptr inbounds i32, i32* %277, i64 %272
  %279 = bitcast i32* %278 to i8*
  call void @llvm.prefetch(i8* %279, i32 0, i32 3, i32 1) #19
  %280 = getelementptr inbounds i32, i32* %278, i64 4
  %281 = bitcast i32* %280 to i8*
  call void @llvm.prefetch(i8* %281, i32 0, i32 3, i32 1) #19
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %10, %"struct.gemmlowp::OutputPipelineExecutor.400"* nonnull dereferenceable(32) %14, %"class.gemmlowp::MatrixMap.182"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %11, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorDup"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %7, i32 %3, i32 %268, i32 %240, i32 %269, i32 %241, i32 %269, i32 %241)
  %282 = load i32, i32* %45, align 4
  %283 = add nsw i32 %282, -8
  %284 = trunc i64 %270 to i32
  %285 = icmp slt i32 %283, %284
  br i1 %285, label %255, label %286

286:                                              ; preds = %262
  %287 = load i32*, i32** %19, align 8
  %288 = load i32, i32* %22, align 8
  %289 = load i32*, i32** %43, align 8
  br label %262

290:                                              ; preds = %296, %257
  %291 = phi i32 [ %258, %257 ], [ %301, %296 ]
  %292 = phi i32 [ %259, %257 ], [ %300, %296 ]
  %293 = icmp slt i32 %292, %291
  br i1 %293, label %294, label %383

294:                                              ; preds = %290
  %295 = zext i32 %292 to i64
  br label %304

296:                                              ; preds = %257, %296
  %297 = phi i32 [ %300, %296 ], [ %259, %257 ]
  %298 = load i32, i32* %110, align 4
  %299 = add nsw i32 %298, %297
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %10, %"struct.gemmlowp::OutputPipelineExecutor.393"* nonnull dereferenceable(32) %13, %"class.gemmlowp::MatrixMap.182"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %11, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorDup"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %7, i32 %3, i32 %297, i32 %240, i32 %299, i32 %241, i32 %299, i32 %241)
  %300 = add nuw nsw i32 %297, 4
  %301 = load i32, i32* %45, align 4
  %302 = add nsw i32 %301, -4
  %303 = icmp sgt i32 %300, %302
  br i1 %303, label %290, label %296

304:                                              ; preds = %294, %351
  %305 = phi i64 [ %295, %294 ], [ %379, %351 ]
  %306 = load i32, i32* %110, align 4
  %307 = trunc i64 %305 to i32
  %308 = add nsw i32 %306, %307
  %309 = load i32*, i32** %19, align 8
  %310 = load i32, i32* %22, align 8
  %311 = getelementptr inbounds i32, i32* %309, i64 %305
  %312 = mul nsw i32 %310, %240
  %313 = sext i32 %312 to i64
  %314 = getelementptr inbounds i32, i32* %311, i64 %313
  %315 = load i32, i32* %314, align 4
  %316 = load i32*, i32** %43, align 8
  %317 = getelementptr inbounds i32, i32* %316, i64 %305
  %318 = load i32, i32* %317, align 4
  %319 = load i32*, i32** %49, align 8
  %320 = getelementptr inbounds i32, i32* %319, i64 %238
  %321 = load i32, i32* %320, align 4
  %322 = load i32, i32* %111, align 4
  %323 = load i32, i32* %112, align 4
  %324 = mul nsw i32 %323, %318
  %325 = add nsw i32 %324, %315
  %326 = mul nsw i32 %323, %3
  %327 = add nsw i32 %326, %321
  %328 = mul nsw i32 %327, %322
  %329 = add nsw i32 %325, %328
  %330 = load i32, i32* %113, align 4
  %331 = sext i32 %329 to i64
  %332 = mul nsw i64 %331, %115
  %333 = icmp slt i64 %332, 2147483647
  %334 = select i1 %333, i64 %332, i64 2147483647
  %335 = icmp sgt i64 %334, -2147483648
  %336 = select i1 %335, i64 %334, i64 -2147483648
  %337 = trunc i64 %336 to i32
  %338 = load i32, i32* %116, align 4
  %339 = icmp ne i32 %338, %337
  %340 = icmp ne i32 %337, -2147483648
  %341 = or i1 %339, %340
  br i1 %341, label %342, label %351

342:                                              ; preds = %304
  %343 = sext i32 %338 to i64
  %344 = select i1 %339, i64 %343, i64 %336
  %345 = mul nsw i64 %344, %336
  %346 = icmp sgt i64 %345, -1
  %347 = select i1 %346, i64 1073741824, i64 -1073741823
  %348 = add nsw i64 %347, %345
  %349 = sdiv i64 %348, 2147483648
  %350 = trunc i64 %349 to i32
  br label %351

351:                                              ; preds = %304, %342
  %352 = phi i32 [ %350, %342 ], [ 2147483647, %304 ]
  %353 = and i32 %352, %120
  %354 = lshr i32 %352, 31
  %355 = add nsw i32 %354, %121
  %356 = ashr i32 %352, %61
  %357 = icmp sgt i32 %353, %355
  %358 = zext i1 %357 to i32
  %359 = add i32 %356, %330
  %360 = add i32 %359, %358
  %361 = load i32, i32* %122, align 4
  %362 = load i32, i32* %123, align 4
  %363 = icmp sgt i32 %361, %360
  %364 = select i1 %363, i32 %361, i32 %360
  %365 = icmp slt i32 %362, %364
  %366 = select i1 %365, i32 %362, i32 %364
  %367 = icmp sgt i32 %366, 0
  %368 = select i1 %367, i32 %366, i32 0
  %369 = icmp slt i32 %368, 255
  %370 = select i1 %369, i32 %368, i32 255
  %371 = trunc i32 %370 to i8
  %372 = sext i32 %308 to i64
  %373 = load i8*, i8** %124, align 8
  %374 = getelementptr inbounds i8, i8* %373, i64 %372
  %375 = load i32, i32* %125, align 8
  %376 = mul nsw i32 %375, %241
  %377 = sext i32 %376 to i64
  %378 = getelementptr inbounds i8, i8* %374, i64 %377
  store i8 %371, i8* %378, align 1
  %379 = add nuw nsw i64 %305, 1
  %380 = load i32, i32* %45, align 4
  %381 = trunc i64 %379 to i32
  %382 = icmp sgt i32 %380, %381
  br i1 %382, label %304, label %383

383:                                              ; preds = %351, %290
  %384 = phi i32 [ %291, %290 ], [ %380, %351 ]
  %385 = add nuw nsw i64 %238, 1
  %386 = load i32, i32* %51, align 4
  %387 = trunc i64 %385 to i32
  %388 = icmp sgt i32 %386, %387
  br i1 %388, label %236, label %389

389:                                              ; preds = %383, %104
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %91) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %84) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %77) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %70) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %63) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %48) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %42) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %18) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.421"* dereferenceable(32), %"class.gemmlowp::MatrixMap.182"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.310", align 8
  %16 = alloca %"struct.gemmlowp::RegisterBlock.310", align 1
  %17 = alloca %"struct.gemmlowp::RegisterBlock.302", align 16
  %18 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %18) #19
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %20 = sext i32 %8 to i64
  %21 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %22 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %22, i8 -86, i64 128, i1 false)
  %23 = load i32*, i32** %19, align 8, !noalias !1088
  %24 = getelementptr inbounds i32, i32* %23, i64 %20
  %25 = load i32, i32* %21, align 8, !noalias !1088
  %26 = mul nsw i32 %25, %9
  %27 = sext i32 %26 to i64
  %28 = getelementptr inbounds i32, i32* %24, i64 %27
  %29 = getelementptr inbounds i32, i32* %28, i64 1
  %30 = load i32, i32* %28, align 4
  %31 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 0
  store i32 %30, i32* %31, align 16, !alias.scope !1088
  %32 = getelementptr inbounds i32, i32* %29, i64 1
  %33 = load i32, i32* %29, align 4
  %34 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 1
  store i32 %33, i32* %34, align 4, !alias.scope !1088
  %35 = getelementptr inbounds i32, i32* %32, i64 1
  %36 = load i32, i32* %32, align 4
  %37 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 2
  store i32 %36, i32* %37, align 8, !alias.scope !1088
  %38 = getelementptr inbounds i32, i32* %35, i64 1
  %39 = load i32, i32* %35, align 4
  %40 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 3
  store i32 %39, i32* %40, align 4, !alias.scope !1088
  %41 = getelementptr inbounds i32, i32* %38, i64 1
  %42 = load i32, i32* %38, align 4
  %43 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 4
  store i32 %42, i32* %43, align 16, !alias.scope !1088
  %44 = getelementptr inbounds i32, i32* %41, i64 1
  %45 = load i32, i32* %41, align 4
  %46 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 5
  store i32 %45, i32* %46, align 4, !alias.scope !1088
  %47 = getelementptr inbounds i32, i32* %44, i64 1
  %48 = load i32, i32* %44, align 4
  %49 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 6
  store i32 %48, i32* %49, align 8, !alias.scope !1088
  %50 = load i32, i32* %47, align 4
  %51 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 7
  store i32 %50, i32* %51, align 4, !alias.scope !1088
  %52 = add nsw i32 %9, 1
  %53 = mul nsw i32 %25, %52
  %54 = sext i32 %53 to i64
  %55 = getelementptr inbounds i32, i32* %24, i64 %54
  %56 = getelementptr inbounds i32, i32* %55, i64 1
  %57 = load i32, i32* %55, align 4
  %58 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 8
  store i32 %57, i32* %58, align 16, !alias.scope !1088
  %59 = getelementptr inbounds i32, i32* %56, i64 1
  %60 = load i32, i32* %56, align 4
  %61 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 9
  store i32 %60, i32* %61, align 4, !alias.scope !1088
  %62 = getelementptr inbounds i32, i32* %59, i64 1
  %63 = load i32, i32* %59, align 4
  %64 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 10
  store i32 %63, i32* %64, align 8, !alias.scope !1088
  %65 = getelementptr inbounds i32, i32* %62, i64 1
  %66 = load i32, i32* %62, align 4
  %67 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 11
  store i32 %66, i32* %67, align 4, !alias.scope !1088
  %68 = getelementptr inbounds i32, i32* %65, i64 1
  %69 = load i32, i32* %65, align 4
  %70 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 12
  store i32 %69, i32* %70, align 16, !alias.scope !1088
  %71 = getelementptr inbounds i32, i32* %68, i64 1
  %72 = load i32, i32* %68, align 4
  %73 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 13
  store i32 %72, i32* %73, align 4, !alias.scope !1088
  %74 = getelementptr inbounds i32, i32* %71, i64 1
  %75 = load i32, i32* %71, align 4
  %76 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 14
  store i32 %75, i32* %76, align 8, !alias.scope !1088
  %77 = load i32, i32* %74, align 4
  %78 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 15
  store i32 %77, i32* %78, align 4, !alias.scope !1088
  %79 = add nsw i32 %9, 2
  %80 = mul nsw i32 %25, %79
  %81 = sext i32 %80 to i64
  %82 = getelementptr inbounds i32, i32* %24, i64 %81
  %83 = getelementptr inbounds i32, i32* %82, i64 1
  %84 = load i32, i32* %82, align 4
  %85 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 16
  store i32 %84, i32* %85, align 16, !alias.scope !1088
  %86 = getelementptr inbounds i32, i32* %83, i64 1
  %87 = load i32, i32* %83, align 4
  %88 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 17
  store i32 %87, i32* %88, align 4, !alias.scope !1088
  %89 = getelementptr inbounds i32, i32* %86, i64 1
  %90 = load i32, i32* %86, align 4
  %91 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 18
  store i32 %90, i32* %91, align 8, !alias.scope !1088
  %92 = getelementptr inbounds i32, i32* %89, i64 1
  %93 = load i32, i32* %89, align 4
  %94 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 19
  store i32 %93, i32* %94, align 4, !alias.scope !1088
  %95 = getelementptr inbounds i32, i32* %92, i64 1
  %96 = load i32, i32* %92, align 4
  %97 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 20
  store i32 %96, i32* %97, align 16, !alias.scope !1088
  %98 = getelementptr inbounds i32, i32* %95, i64 1
  %99 = load i32, i32* %95, align 4
  %100 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 21
  store i32 %99, i32* %100, align 4, !alias.scope !1088
  %101 = getelementptr inbounds i32, i32* %98, i64 1
  %102 = load i32, i32* %98, align 4
  %103 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 22
  store i32 %102, i32* %103, align 8, !alias.scope !1088
  %104 = load i32, i32* %101, align 4
  %105 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 23
  store i32 %104, i32* %105, align 4, !alias.scope !1088
  %106 = add nsw i32 %9, 3
  %107 = mul nsw i32 %25, %106
  %108 = sext i32 %107 to i64
  %109 = getelementptr inbounds i32, i32* %24, i64 %108
  %110 = getelementptr inbounds i32, i32* %109, i64 1
  %111 = load i32, i32* %109, align 4
  %112 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 24
  store i32 %111, i32* %112, align 16, !alias.scope !1088
  %113 = getelementptr inbounds i32, i32* %110, i64 1
  %114 = load i32, i32* %110, align 4
  %115 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 25
  store i32 %114, i32* %115, align 4, !alias.scope !1088
  %116 = getelementptr inbounds i32, i32* %113, i64 1
  %117 = load i32, i32* %113, align 4
  %118 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 26
  store i32 %117, i32* %118, align 8, !alias.scope !1088
  %119 = getelementptr inbounds i32, i32* %116, i64 1
  %120 = load i32, i32* %116, align 4
  %121 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 27
  store i32 %120, i32* %121, align 4, !alias.scope !1088
  %122 = getelementptr inbounds i32, i32* %119, i64 1
  %123 = load i32, i32* %119, align 4
  %124 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 28
  store i32 %123, i32* %124, align 16, !alias.scope !1088
  %125 = getelementptr inbounds i32, i32* %122, i64 1
  %126 = load i32, i32* %122, align 4
  %127 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 29
  store i32 %126, i32* %127, align 4, !alias.scope !1088
  %128 = getelementptr inbounds i32, i32* %125, i64 1
  %129 = load i32, i32* %125, align 4
  %130 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 30
  store i32 %129, i32* %130, align 8, !alias.scope !1088
  %131 = load i32, i32* %128, align 4
  %132 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 31
  store i32 %131, i32* %132, align 4, !alias.scope !1088
  %133 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %134 = load i32*, i32** %133, align 8, !noalias !1091
  %135 = getelementptr i32, i32* %134, i64 %20
  %136 = bitcast i32* %135 to <4 x i32>*
  %137 = load <4 x i32>, <4 x i32>* %136, align 4
  %138 = getelementptr inbounds i32, i32* %135, i64 4
  %139 = bitcast i32* %138 to <4 x i32>*
  %140 = load <4 x i32>, <4 x i32>* %139, align 4
  %141 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %142 = load i32*, i32** %141, align 8
  %143 = sext i32 %9 to i64
  %144 = getelementptr i32, i32* %142, i64 %143
  %145 = bitcast i32* %144 to i64*
  %146 = load i64, i64* %145, align 4
  %147 = getelementptr inbounds i32, i32* %144, i64 2
  %148 = bitcast i32* %147 to i64*
  %149 = load i64, i64* %148, align 4
  %150 = lshr i64 %146, 32
  %151 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %152 = load i32, i32* %151, align 4
  %153 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %6, i64 0, i32 0
  %154 = load i32, i32* %153, align 4
  %155 = insertelement <4 x i32> undef, i32 %154, i32 0
  %156 = shufflevector <4 x i32> %155, <4 x i32> undef, <4 x i32> zeroinitializer
  %157 = mul nsw <4 x i32> %156, %137
  %158 = mul nsw <4 x i32> %156, %140
  %159 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to <4 x i32>*
  %160 = load <4 x i32>, <4 x i32>* %159, align 16
  %161 = add nsw <4 x i32> %160, %157
  %162 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to <4 x i32>*
  store <4 x i32> %161, <4 x i32>* %162, align 16
  %163 = bitcast i32* %43 to <4 x i32>*
  %164 = load <4 x i32>, <4 x i32>* %163, align 16
  %165 = add nsw <4 x i32> %164, %158
  %166 = bitcast i32* %43 to <4 x i32>*
  store <4 x i32> %165, <4 x i32>* %166, align 16
  %167 = bitcast i32* %58 to <4 x i32>*
  %168 = load <4 x i32>, <4 x i32>* %167, align 16
  %169 = add nsw <4 x i32> %168, %157
  %170 = bitcast i32* %58 to <4 x i32>*
  store <4 x i32> %169, <4 x i32>* %170, align 16
  %171 = bitcast i32* %70 to <4 x i32>*
  %172 = load <4 x i32>, <4 x i32>* %171, align 16
  %173 = add nsw <4 x i32> %172, %158
  %174 = bitcast i32* %70 to <4 x i32>*
  store <4 x i32> %173, <4 x i32>* %174, align 16
  %175 = bitcast i32* %85 to <4 x i32>*
  %176 = load <4 x i32>, <4 x i32>* %175, align 16
  %177 = add nsw <4 x i32> %176, %157
  %178 = bitcast i32* %85 to <4 x i32>*
  store <4 x i32> %177, <4 x i32>* %178, align 16
  %179 = bitcast i32* %97 to <4 x i32>*
  %180 = load <4 x i32>, <4 x i32>* %179, align 16
  %181 = add nsw <4 x i32> %180, %158
  %182 = bitcast i32* %97 to <4 x i32>*
  store <4 x i32> %181, <4 x i32>* %182, align 16
  %183 = bitcast i32* %112 to <4 x i32>*
  %184 = load <4 x i32>, <4 x i32>* %183, align 16
  %185 = add nsw <4 x i32> %184, %157
  %186 = bitcast i32* %112 to <4 x i32>*
  store <4 x i32> %185, <4 x i32>* %186, align 16
  %187 = bitcast i32* %124 to <4 x i32>*
  %188 = load <4 x i32>, <4 x i32>* %187, align 16
  %189 = add nsw <4 x i32> %188, %158
  %190 = bitcast i32* %124 to <4 x i32>*
  store <4 x i32> %189, <4 x i32>* %190, align 16
  %191 = trunc i64 %146 to i32
  %192 = trunc i64 %150 to i32
  %193 = mul nsw i32 %154, %7
  %194 = add nsw i32 %193, %191
  %195 = add nsw i32 %193, %192
  %196 = trunc i64 %149 to i32
  %197 = add nsw i32 %193, %196
  %198 = lshr i64 %149, 32
  %199 = trunc i64 %198 to i32
  %200 = add nsw i32 %193, %199
  %201 = mul nsw i32 %194, %152
  %202 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to <4 x i32>*
  %203 = load <4 x i32>, <4 x i32>* %202, align 16
  %204 = insertelement <4 x i32> undef, i32 %201, i32 0
  %205 = shufflevector <4 x i32> %204, <4 x i32> undef, <4 x i32> zeroinitializer
  %206 = add nsw <4 x i32> %203, %205
  %207 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to <4 x i32>*
  store <4 x i32> %206, <4 x i32>* %207, align 16
  %208 = bitcast i32* %43 to <4 x i32>*
  %209 = load <4 x i32>, <4 x i32>* %208, align 16
  %210 = add nsw <4 x i32> %209, %205
  %211 = bitcast i32* %43 to <4 x i32>*
  store <4 x i32> %210, <4 x i32>* %211, align 16
  %212 = mul nsw i32 %195, %152
  %213 = bitcast i32* %58 to <4 x i32>*
  %214 = load <4 x i32>, <4 x i32>* %213, align 16
  %215 = insertelement <4 x i32> undef, i32 %212, i32 0
  %216 = shufflevector <4 x i32> %215, <4 x i32> undef, <4 x i32> zeroinitializer
  %217 = add nsw <4 x i32> %214, %216
  %218 = bitcast i32* %58 to <4 x i32>*
  store <4 x i32> %217, <4 x i32>* %218, align 16
  %219 = bitcast i32* %70 to <4 x i32>*
  %220 = load <4 x i32>, <4 x i32>* %219, align 16
  %221 = add nsw <4 x i32> %220, %216
  %222 = bitcast i32* %70 to <4 x i32>*
  store <4 x i32> %221, <4 x i32>* %222, align 16
  %223 = mul nsw i32 %197, %152
  %224 = bitcast i32* %85 to <4 x i32>*
  %225 = load <4 x i32>, <4 x i32>* %224, align 16
  %226 = insertelement <4 x i32> undef, i32 %223, i32 0
  %227 = shufflevector <4 x i32> %226, <4 x i32> undef, <4 x i32> zeroinitializer
  %228 = add nsw <4 x i32> %225, %227
  %229 = bitcast i32* %85 to <4 x i32>*
  store <4 x i32> %228, <4 x i32>* %229, align 16
  %230 = bitcast i32* %97 to <4 x i32>*
  %231 = load <4 x i32>, <4 x i32>* %230, align 16
  %232 = add nsw <4 x i32> %231, %227
  %233 = bitcast i32* %97 to <4 x i32>*
  store <4 x i32> %232, <4 x i32>* %233, align 16
  %234 = mul nsw i32 %200, %152
  %235 = bitcast i32* %112 to <4 x i32>*
  %236 = load <4 x i32>, <4 x i32>* %235, align 16
  %237 = insertelement <4 x i32> undef, i32 %234, i32 0
  %238 = shufflevector <4 x i32> %237, <4 x i32> undef, <4 x i32> zeroinitializer
  %239 = add nsw <4 x i32> %236, %238
  %240 = bitcast i32* %112 to <4 x i32>*
  store <4 x i32> %239, <4 x i32>* %240, align 16
  %241 = bitcast i32* %124 to <4 x i32>*
  %242 = load <4 x i32>, <4 x i32>* %241, align 16
  %243 = add nsw <4 x i32> %242, %238
  %244 = bitcast i32* %124 to <4 x i32>*
  store <4 x i32> %243, <4 x i32>* %244, align 16
  %245 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %16, i64 0, i32 0, i32 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %245) #19
  %246 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.421", %"struct.gemmlowp::OutputPipelineExecutor.421"* %1, i64 0, i32 0
  call void @llvm.memset.p0i8.i64(i8* nonnull align 1 %245, i8 -86, i64 32, i1 false) #19
  call void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi0ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalES8_ii(%"struct.gemmlowp::RegisterBlock.310"* nonnull sret %16, %"struct.gemmlowp::OutputPipelineEvalImpl.422"* %246, %"struct.gemmlowp::RegisterBlock.302"* nonnull byval(%"struct.gemmlowp::RegisterBlock.302") align 8 %17, i32 %10, i32 %11) #19
  %247 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %15, i64 0, i32 0, i32 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %247) #19
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %247, i8* nonnull align 1 %245, i64 32, i1 false) #19
  %248 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %2, i64 0, i32 0
  %249 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %2, i64 0, i32 3
  %250 = sext i32 %13 to i64
  %251 = sext i32 %12 to i64
  %252 = add nsw i64 %250, 1
  %253 = add nsw i64 %250, 2
  %254 = add nsw i64 %250, 3
  br label %255

255:                                              ; preds = %255, %14
  %256 = phi i64 [ 0, %14 ], [ %293, %255 ]
  %257 = add nsw i64 %256, %251
  %258 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %15, i64 0, i32 0, i32 0, i64 %256
  %259 = load i8, i8* %258, align 1
  %260 = load i8*, i8** %248, align 8
  %261 = getelementptr inbounds i8, i8* %260, i64 %257
  %262 = load i32, i32* %249, align 8
  %263 = sext i32 %262 to i64
  %264 = mul nsw i64 %263, %250
  %265 = getelementptr inbounds i8, i8* %261, i64 %264
  store i8 %259, i8* %265, align 1
  %266 = add nuw nsw i64 %256, 8
  %267 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %15, i64 0, i32 0, i32 0, i64 %266
  %268 = load i8, i8* %267, align 1
  %269 = load i8*, i8** %248, align 8
  %270 = getelementptr inbounds i8, i8* %269, i64 %257
  %271 = load i32, i32* %249, align 8
  %272 = sext i32 %271 to i64
  %273 = mul nsw i64 %252, %272
  %274 = getelementptr inbounds i8, i8* %270, i64 %273
  store i8 %268, i8* %274, align 1
  %275 = add nuw nsw i64 %256, 16
  %276 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %15, i64 0, i32 0, i32 0, i64 %275
  %277 = load i8, i8* %276, align 1
  %278 = load i8*, i8** %248, align 8
  %279 = getelementptr inbounds i8, i8* %278, i64 %257
  %280 = load i32, i32* %249, align 8
  %281 = sext i32 %280 to i64
  %282 = mul nsw i64 %253, %281
  %283 = getelementptr inbounds i8, i8* %279, i64 %282
  store i8 %277, i8* %283, align 1
  %284 = add nuw nsw i64 %256, 24
  %285 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.310", %"struct.gemmlowp::RegisterBlock.310"* %15, i64 0, i32 0, i32 0, i64 %284
  %286 = load i8, i8* %285, align 1
  %287 = load i8*, i8** %248, align 8
  %288 = getelementptr inbounds i8, i8* %287, i64 %257
  %289 = load i32, i32* %249, align 8
  %290 = sext i32 %289 to i64
  %291 = mul nsw i64 %254, %290
  %292 = getelementptr inbounds i8, i8* %288, i64 %291
  store i8 %286, i8* %292, align 1
  %293 = add nuw nsw i64 %256, 1
  %294 = icmp eq i64 %293, 8
  br i1 %294, label %295, label %255

295:                                              ; preds = %255
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %247) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %245) #19
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %18) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.414"* dereferenceable(32), %"class.gemmlowp::MatrixMap.182"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBuffer.313", align 8
  %16 = alloca %"struct.gemmlowp::RegisterBuffer.313", align 8
  %17 = alloca [16 x i32], align 8
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %19 = sext i32 %8 to i64
  %20 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %21 = load i32*, i32** %18, align 8, !noalias !1096
  %22 = getelementptr inbounds i32, i32* %21, i64 %19
  %23 = load i32, i32* %20, align 8, !noalias !1096
  %24 = mul nsw i32 %23, %9
  %25 = sext i32 %24 to i64
  %26 = getelementptr inbounds i32, i32* %22, i64 %25
  %27 = getelementptr inbounds i32, i32* %26, i64 1
  %28 = load i32, i32* %26, align 4, !noalias !1096
  %29 = getelementptr inbounds i32, i32* %27, i64 1
  %30 = load i32, i32* %27, align 4, !noalias !1096
  %31 = getelementptr inbounds i32, i32* %29, i64 1
  %32 = load i32, i32* %29, align 4, !noalias !1096
  %33 = load i32, i32* %31, align 4, !noalias !1096
  %34 = add nsw i32 %9, 1
  %35 = mul nsw i32 %23, %34
  %36 = sext i32 %35 to i64
  %37 = getelementptr inbounds i32, i32* %22, i64 %36
  %38 = getelementptr inbounds i32, i32* %37, i64 1
  %39 = load i32, i32* %37, align 4, !noalias !1096
  %40 = getelementptr inbounds i32, i32* %38, i64 1
  %41 = load i32, i32* %38, align 4, !noalias !1096
  %42 = getelementptr inbounds i32, i32* %40, i64 1
  %43 = load i32, i32* %40, align 4, !noalias !1096
  %44 = load i32, i32* %42, align 4, !noalias !1096
  %45 = add nsw i32 %9, 2
  %46 = mul nsw i32 %23, %45
  %47 = sext i32 %46 to i64
  %48 = getelementptr inbounds i32, i32* %22, i64 %47
  %49 = getelementptr inbounds i32, i32* %48, i64 1
  %50 = load i32, i32* %48, align 4, !noalias !1096
  %51 = getelementptr inbounds i32, i32* %49, i64 1
  %52 = load i32, i32* %49, align 4, !noalias !1096
  %53 = getelementptr inbounds i32, i32* %51, i64 1
  %54 = load i32, i32* %51, align 4, !noalias !1096
  %55 = load i32, i32* %53, align 4, !noalias !1096
  %56 = add nsw i32 %9, 3
  %57 = mul nsw i32 %23, %56
  %58 = sext i32 %57 to i64
  %59 = getelementptr inbounds i32, i32* %22, i64 %58
  %60 = getelementptr inbounds i32, i32* %59, i64 1
  %61 = load i32, i32* %59, align 4, !noalias !1096
  %62 = getelementptr inbounds i32, i32* %60, i64 1
  %63 = load i32, i32* %60, align 4, !noalias !1096
  %64 = getelementptr inbounds i32, i32* %62, i64 1
  %65 = load i32, i32* %62, align 4, !noalias !1096
  %66 = load i32, i32* %64, align 4, !noalias !1096
  %67 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %68 = load i32*, i32** %67, align 8
  %69 = getelementptr i32, i32* %68, i64 %19
  %70 = bitcast i32* %69 to i64*
  %71 = load i64, i64* %70, align 4
  %72 = getelementptr inbounds i32, i32* %69, i64 2
  %73 = bitcast i32* %72 to i64*
  %74 = load i64, i64* %73, align 4
  %75 = trunc i64 %71 to i32
  %76 = lshr i64 %71, 32
  %77 = trunc i64 %76 to i32
  %78 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %79 = load i32*, i32** %78, align 8
  %80 = sext i32 %9 to i64
  %81 = getelementptr i32, i32* %79, i64 %80
  %82 = bitcast i32* %81 to i64*
  %83 = load i64, i64* %82, align 4
  %84 = getelementptr inbounds i32, i32* %81, i64 2
  %85 = bitcast i32* %84 to i64*
  %86 = load i64, i64* %85, align 4
  %87 = trunc i64 %83 to i32
  %88 = lshr i64 %83, 32
  %89 = trunc i64 %88 to i32
  %90 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %91 = load i32, i32* %90, align 4
  %92 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %6, i64 0, i32 0
  %93 = load i32, i32* %92, align 4
  %94 = mul nsw i32 %93, %75
  %95 = add nsw i32 %94, %28
  %96 = mul nsw i32 %93, %77
  %97 = add nsw i32 %96, %30
  %98 = trunc i64 %74 to i32
  %99 = mul nsw i32 %93, %98
  %100 = add nsw i32 %99, %32
  %101 = lshr i64 %74, 32
  %102 = trunc i64 %101 to i32
  %103 = mul nsw i32 %93, %102
  %104 = add nsw i32 %103, %33
  %105 = add nsw i32 %94, %39
  %106 = add nsw i32 %96, %41
  %107 = add nsw i32 %99, %43
  %108 = add nsw i32 %103, %44
  %109 = add nsw i32 %94, %50
  %110 = add nsw i32 %96, %52
  %111 = add nsw i32 %99, %54
  %112 = add nsw i32 %103, %55
  %113 = add nsw i32 %94, %61
  %114 = add nsw i32 %96, %63
  %115 = add nsw i32 %99, %65
  %116 = add nsw i32 %103, %66
  %117 = mul nsw i32 %93, %7
  %118 = add nsw i32 %117, %87
  %119 = add nsw i32 %117, %89
  %120 = trunc i64 %86 to i32
  %121 = add nsw i32 %117, %120
  %122 = lshr i64 %86, 32
  %123 = trunc i64 %122 to i32
  %124 = add nsw i32 %117, %123
  %125 = mul nsw i32 %118, %91
  %126 = add nsw i32 %95, %125
  %127 = add nsw i32 %97, %125
  %128 = add nsw i32 %100, %125
  %129 = add nsw i32 %104, %125
  %130 = mul nsw i32 %119, %91
  %131 = add nsw i32 %105, %130
  %132 = add nsw i32 %106, %130
  %133 = add nsw i32 %107, %130
  %134 = add nsw i32 %108, %130
  %135 = mul nsw i32 %121, %91
  %136 = add nsw i32 %109, %135
  %137 = add nsw i32 %110, %135
  %138 = add nsw i32 %111, %135
  %139 = add nsw i32 %112, %135
  %140 = mul nsw i32 %124, %91
  %141 = add nsw i32 %113, %140
  %142 = add nsw i32 %114, %140
  %143 = add nsw i32 %115, %140
  %144 = add nsw i32 %116, %140
  %145 = bitcast [16 x i32]* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %145) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %145, i8 -86, i64 64, i1 false) #19, !alias.scope !1101
  %146 = bitcast %"struct.gemmlowp::RegisterBuffer.313"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %146) #19, !noalias !1101
  %147 = bitcast %"struct.gemmlowp::RegisterBuffer.313"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %147) #19, !noalias !1101
  %148 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %15, i64 0, i32 0, i64 0
  store i32 %126, i32* %148, align 8
  %149 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %15, i64 0, i32 0, i64 1
  store i32 %127, i32* %149, align 4
  %150 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %15, i64 0, i32 0, i64 2
  store i32 %128, i32* %150, align 8
  %151 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %15, i64 0, i32 0, i64 3
  store i32 %129, i32* %151, align 4
  %152 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %15, i64 0, i32 0, i64 4
  store i32 %131, i32* %152, align 8
  %153 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %15, i64 0, i32 0, i64 5
  store i32 %132, i32* %153, align 4
  %154 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %15, i64 0, i32 0, i64 6
  store i32 %133, i32* %154, align 8
  %155 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %15, i64 0, i32 0, i64 7
  store i32 %134, i32* %155, align 4
  %156 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %15, i64 0, i32 0, i64 8
  store i32 %136, i32* %156, align 8
  %157 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %15, i64 0, i32 0, i64 9
  store i32 %137, i32* %157, align 4
  %158 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %15, i64 0, i32 0, i64 10
  store i32 %138, i32* %158, align 8
  %159 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %15, i64 0, i32 0, i64 11
  store i32 %139, i32* %159, align 4
  %160 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %15, i64 0, i32 0, i64 12
  store i32 %141, i32* %160, align 8
  %161 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %15, i64 0, i32 0, i64 13
  store i32 %142, i32* %161, align 4
  %162 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %15, i64 0, i32 0, i64 14
  store i32 %143, i32* %162, align 8
  %163 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %15, i64 0, i32 0, i64 15
  store i32 %144, i32* %163, align 4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %146, i8 -86, i64 64, i1 false) #19, !alias.scope !1104, !noalias !1101
  %164 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.414", %"struct.gemmlowp::OutputPipelineExecutor.414"* %1, i64 0, i32 0, i32 0, i32 0, i32 0
  %165 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %164, align 8, !noalias !1107
  %166 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %165, i64 0, i32 2
  %167 = load i32, i32* %166, align 4, !noalias !1107
  %168 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.414", %"struct.gemmlowp::OutputPipelineExecutor.414"* %1, i64 0, i32 0, i32 0, i32 0, i32 1
  %169 = load i32, i32* %168, align 8, !noalias !1107
  %170 = shl i32 1, %169
  %171 = sext i32 %170 to i64
  %172 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %165, i64 0, i32 0
  %173 = load i32, i32* %172, align 4, !noalias !1107
  %174 = sext i32 %173 to i64
  %175 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.414", %"struct.gemmlowp::OutputPipelineExecutor.414"* %1, i64 0, i32 0, i32 0, i32 0, i32 2
  %176 = load i32, i32* %175, align 4, !noalias !1107
  %177 = zext i32 %176 to i64
  %178 = shl nsw i64 -1, %177
  %179 = trunc i64 %178 to i32
  %180 = xor i32 %179, -1
  %181 = ashr i32 %180, 1
  %182 = icmp ne i32 %173, -2147483648
  br label %183

183:                                              ; preds = %216, %14
  %184 = phi i32 [ %126, %14 ], [ %218, %216 ]
  %185 = phi i64 [ 0, %14 ], [ %214, %216 ]
  %186 = sext i32 %184 to i64
  %187 = mul nsw i64 %186, %171
  %188 = icmp slt i64 %187, 2147483647
  %189 = select i1 %188, i64 %187, i64 2147483647
  %190 = icmp sgt i64 %189, -2147483648
  %191 = select i1 %190, i64 %189, i64 -2147483648
  %192 = trunc i64 %191 to i32
  %193 = icmp ne i32 %173, %192
  %194 = or i1 %182, %193
  br i1 %194, label %195, label %203

195:                                              ; preds = %183
  %196 = select i1 %193, i64 %174, i64 %191
  %197 = mul nsw i64 %196, %191
  %198 = icmp sgt i64 %197, -1
  %199 = select i1 %198, i64 1073741824, i64 -1073741823
  %200 = add nsw i64 %199, %197
  %201 = sdiv i64 %200, 2147483648
  %202 = trunc i64 %201 to i32
  br label %203

203:                                              ; preds = %195, %183
  %204 = phi i32 [ %202, %195 ], [ 2147483647, %183 ]
  %205 = and i32 %204, %180
  %206 = lshr i32 %204, 31
  %207 = add nsw i32 %206, %181
  %208 = ashr i32 %204, %176
  %209 = icmp sgt i32 %205, %207
  %210 = zext i1 %209 to i32
  %211 = add i32 %208, %167
  %212 = add i32 %211, %210
  %213 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %16, i64 0, i32 0, i64 %185
  store i32 %212, i32* %213, align 4, !alias.scope !1104, !noalias !1101
  %214 = add nuw nsw i64 %185, 1
  %215 = icmp eq i64 %214, 16
  br i1 %215, label %219, label %216

216:                                              ; preds = %203
  %217 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %15, i64 0, i32 0, i64 %214
  %218 = load i32, i32* %217, align 4, !noalias !1107
  br label %183

219:                                              ; preds = %203
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %147) #19, !noalias !1101
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %145, i8* nonnull align 8 %146, i64 64, i1 false) #19
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %146) #19, !noalias !1101
  %220 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.414", %"struct.gemmlowp::OutputPipelineExecutor.414"* %1, i64 0, i32 0, i32 1
  %221 = bitcast [16 x i32]* %17 to %"struct.gemmlowp::RegisterBlock.312"*
  %222 = tail call { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi1ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalES8_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.416"* %220, %"struct.gemmlowp::RegisterBlock.312"* nonnull byval(%"struct.gemmlowp::RegisterBlock.312") align 8 %221, i32 %10, i32 %11) #19
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %145) #19
  %223 = extractvalue { i64, i64 } %222, 0
  %224 = extractvalue { i64, i64 } %222, 1
  tail call void @_ZN8gemmlowp16StoreFinalOutputINS_13RegisterBlockIhLi4ELi4EEENS_9MatrixMapIhLNS_8MapOrderE0EEEEEvT_PT0_ii(i64 %223, i64 %224, %"class.gemmlowp::MatrixMap.182"* %2, i32 %12, i32 %13) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.407"* dereferenceable(32), %"class.gemmlowp::MatrixMap.182"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %16 = sext i32 %8 to i64
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %18 = load i32*, i32** %15, align 8
  %19 = getelementptr inbounds i32, i32* %18, i64 %16
  %20 = load i32, i32* %17, align 8
  %21 = mul nsw i32 %20, %9
  %22 = sext i32 %21 to i64
  %23 = getelementptr inbounds i32, i32* %19, i64 %22
  %24 = load i32, i32* %23, align 4
  %25 = add nsw i32 %9, 1
  %26 = mul nsw i32 %20, %25
  %27 = sext i32 %26 to i64
  %28 = getelementptr inbounds i32, i32* %19, i64 %27
  %29 = load i32, i32* %28, align 4
  %30 = add nsw i32 %9, 2
  %31 = mul nsw i32 %20, %30
  %32 = sext i32 %31 to i64
  %33 = getelementptr inbounds i32, i32* %19, i64 %32
  %34 = load i32, i32* %33, align 4
  %35 = add nsw i32 %9, 3
  %36 = mul nsw i32 %20, %35
  %37 = sext i32 %36 to i64
  %38 = getelementptr inbounds i32, i32* %19, i64 %37
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %41 = load i32*, i32** %40, align 8
  %42 = getelementptr inbounds i32, i32* %41, i64 %16
  %43 = load i32, i32* %42, align 4
  %44 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %45 = load i32*, i32** %44, align 8
  %46 = sext i32 %9 to i64
  %47 = getelementptr i32, i32* %45, i64 %46
  %48 = bitcast i32* %47 to i64*
  %49 = load i64, i64* %48, align 4
  %50 = getelementptr inbounds i32, i32* %47, i64 2
  %51 = bitcast i32* %50 to i64*
  %52 = load i64, i64* %51, align 4
  %53 = trunc i64 %49 to i32
  %54 = lshr i64 %49, 32
  %55 = trunc i64 %54 to i32
  %56 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %57 = load i32, i32* %56, align 4
  %58 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %6, i64 0, i32 0
  %59 = load i32, i32* %58, align 4
  %60 = mul nsw i32 %59, %43
  %61 = add nsw i32 %60, %24
  %62 = add nsw i32 %60, %29
  %63 = add nsw i32 %60, %34
  %64 = add nsw i32 %60, %39
  %65 = mul nsw i32 %59, %7
  %66 = add nsw i32 %65, %53
  %67 = add nsw i32 %65, %55
  %68 = trunc i64 %52 to i32
  %69 = add nsw i32 %65, %68
  %70 = lshr i64 %52, 32
  %71 = trunc i64 %70 to i32
  %72 = add nsw i32 %65, %71
  %73 = mul nsw i32 %66, %57
  %74 = add nsw i32 %61, %73
  %75 = mul nsw i32 %67, %57
  %76 = add nsw i32 %62, %75
  %77 = mul nsw i32 %69, %57
  %78 = add nsw i32 %63, %77
  %79 = zext i32 %78 to i64
  %80 = mul nsw i32 %72, %57
  %81 = add nsw i32 %64, %80
  %82 = zext i32 %81 to i64
  %83 = shl nuw i64 %82, 32
  %84 = or i64 %83, %79
  %85 = zext i32 %76 to i64
  %86 = shl nuw i64 %85, 32
  %87 = zext i32 %74 to i64
  %88 = or i64 %86, %87
  %89 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.407", %"struct.gemmlowp::OutputPipelineExecutor.407"* %1, i64 0, i32 0, i32 0, i32 0
  %90 = tail call { i64, i64 } @_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi4EEEE4EvalES3_(%"struct.gemmlowp::OutputStageEvalBufferImpl.231"* %89, i64 %88, i64 %84) #19
  %91 = extractvalue { i64, i64 } %90, 0
  %92 = extractvalue { i64, i64 } %90, 1
  %93 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.407", %"struct.gemmlowp::OutputPipelineExecutor.407"* %1, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %94 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %93, align 8
  %95 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %94, i64 0, i32 0
  %96 = load i32, i32* %95, align 4
  %97 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %94, i64 0, i32 1
  %98 = load i32, i32* %97, align 4
  %99 = trunc i64 %91 to i32
  %100 = icmp sgt i32 %96, %99
  %101 = select i1 %100, i32 %96, i32 %99
  %102 = icmp slt i32 %98, %101
  %103 = select i1 %102, i32 %98, i32 %101
  %104 = lshr i64 %91, 32
  %105 = trunc i64 %104 to i32
  %106 = icmp sgt i32 %96, %105
  %107 = select i1 %106, i32 %96, i32 %105
  %108 = icmp slt i32 %98, %107
  %109 = select i1 %108, i32 %98, i32 %107
  %110 = trunc i64 %92 to i32
  %111 = icmp sgt i32 %96, %110
  %112 = select i1 %111, i32 %96, i32 %110
  %113 = icmp slt i32 %98, %112
  %114 = select i1 %113, i32 %98, i32 %112
  %115 = lshr i64 %92, 32
  %116 = trunc i64 %115 to i32
  %117 = icmp sgt i32 %96, %116
  %118 = select i1 %117, i32 %96, i32 %116
  %119 = icmp slt i32 %98, %118
  %120 = select i1 %119, i32 %98, i32 %118
  %121 = icmp sgt i32 %103, 0
  %122 = select i1 %121, i32 %103, i32 0
  %123 = icmp slt i32 %122, 255
  %124 = select i1 %123, i32 %122, i32 255
  %125 = icmp sgt i32 %109, 0
  %126 = select i1 %125, i32 %109, i32 0
  %127 = icmp slt i32 %126, 255
  %128 = select i1 %127, i32 %126, i32 255
  %129 = icmp sgt i32 %114, 0
  %130 = select i1 %129, i32 %114, i32 0
  %131 = icmp slt i32 %130, 255
  %132 = select i1 %131, i32 %130, i32 255
  %133 = icmp sgt i32 %120, 0
  %134 = select i1 %133, i32 %120, i32 0
  %135 = icmp slt i32 %134, 255
  %136 = select i1 %135, i32 %134, i32 255
  %137 = trunc i32 %124 to i8
  %138 = trunc i32 %128 to i8
  %139 = trunc i32 %132 to i8
  %140 = trunc i32 %136 to i8
  %141 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %2, i64 0, i32 0
  %142 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %2, i64 0, i32 3
  %143 = sext i32 %13 to i64
  %144 = sext i32 %12 to i64
  %145 = load i8*, i8** %141, align 8
  %146 = getelementptr inbounds i8, i8* %145, i64 %144
  %147 = load i32, i32* %142, align 8
  %148 = sext i32 %147 to i64
  %149 = mul nsw i64 %148, %143
  %150 = getelementptr inbounds i8, i8* %146, i64 %149
  store i8 %137, i8* %150, align 1
  %151 = add nsw i64 %143, 1
  %152 = load i8*, i8** %141, align 8
  %153 = getelementptr inbounds i8, i8* %152, i64 %144
  %154 = load i32, i32* %142, align 8
  %155 = sext i32 %154 to i64
  %156 = mul nsw i64 %151, %155
  %157 = getelementptr inbounds i8, i8* %153, i64 %156
  store i8 %138, i8* %157, align 1
  %158 = add nsw i64 %143, 2
  %159 = load i8*, i8** %141, align 8
  %160 = getelementptr inbounds i8, i8* %159, i64 %144
  %161 = load i32, i32* %142, align 8
  %162 = sext i32 %161 to i64
  %163 = mul nsw i64 %158, %162
  %164 = getelementptr inbounds i8, i8* %160, i64 %163
  store i8 %139, i8* %164, align 1
  %165 = add nsw i64 %143, 3
  %166 = load i8*, i8** %141, align 8
  %167 = getelementptr inbounds i8, i8* %166, i64 %144
  %168 = load i32, i32* %142, align 8
  %169 = sext i32 %168 to i64
  %170 = mul nsw i64 %165, %169
  %171 = getelementptr inbounds i8, i8* %167, i64 %170
  store i8 %140, i8* %171, align 1
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.400"* dereferenceable(32), %"class.gemmlowp::MatrixMap.182"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.304", align 16
  %16 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %17 = sext i32 %8 to i64
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %19 = load i32*, i32** %16, align 8, !noalias !1108
  %20 = getelementptr inbounds i32, i32* %19, i64 %17
  %21 = load i32, i32* %18, align 8, !noalias !1108
  %22 = mul nsw i32 %21, %9
  %23 = sext i32 %22 to i64
  %24 = getelementptr inbounds i32, i32* %20, i64 %23
  %25 = getelementptr inbounds i32, i32* %24, i64 1
  %26 = getelementptr inbounds i32, i32* %25, i64 1
  %27 = getelementptr inbounds i32, i32* %26, i64 1
  %28 = getelementptr inbounds i32, i32* %27, i64 1
  %29 = bitcast i32* %24 to <4 x i32>*
  %30 = load <4 x i32>, <4 x i32>* %29, align 4, !noalias !1108
  %31 = getelementptr inbounds i32, i32* %28, i64 1
  %32 = load i32, i32* %28, align 4, !noalias !1108
  %33 = getelementptr inbounds i32, i32* %31, i64 1
  %34 = load i32, i32* %31, align 4, !noalias !1108
  %35 = getelementptr inbounds i32, i32* %33, i64 1
  %36 = load i32, i32* %33, align 4, !noalias !1108
  %37 = load i32, i32* %35, align 4, !noalias !1108
  %38 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %39 = load i32*, i32** %38, align 8, !noalias !1113
  %40 = getelementptr i32, i32* %39, i64 %17
  %41 = bitcast i32* %40 to <4 x i32>*
  %42 = load <4 x i32>, <4 x i32>* %41, align 4
  %43 = getelementptr inbounds i32, i32* %40, i64 4
  %44 = bitcast i32* %43 to <4 x i32>*
  %45 = load <4 x i32>, <4 x i32>* %44, align 4
  %46 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %47 = load i32*, i32** %46, align 8
  %48 = sext i32 %9 to i64
  %49 = getelementptr inbounds i32, i32* %47, i64 %48
  %50 = load i32, i32* %49, align 4
  %51 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %52 = load i32, i32* %51, align 4
  %53 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %6, i64 0, i32 0
  %54 = load i32, i32* %53, align 4
  %55 = insertelement <4 x i32> undef, i32 %54, i32 0
  %56 = shufflevector <4 x i32> %55, <4 x i32> undef, <4 x i32> zeroinitializer
  %57 = mul nsw <4 x i32> %56, %42
  %58 = add nsw <4 x i32> %57, %30
  %59 = mul nsw <4 x i32> %56, %45
  %60 = insertelement <4 x i32> undef, i32 %32, i32 0
  %61 = insertelement <4 x i32> %60, i32 %34, i32 1
  %62 = insertelement <4 x i32> %61, i32 %36, i32 2
  %63 = insertelement <4 x i32> %62, i32 %37, i32 3
  %64 = add nsw <4 x i32> %59, %63
  %65 = mul nsw i32 %54, %7
  %66 = add nsw i32 %65, %50
  %67 = mul nsw i32 %66, %52
  %68 = insertelement <4 x i32> undef, i32 %67, i32 0
  %69 = shufflevector <4 x i32> %68, <4 x i32> undef, <4 x i32> zeroinitializer
  %70 = add nsw <4 x i32> %58, %69
  %71 = add nsw <4 x i32> %64, %69
  %72 = bitcast %"struct.gemmlowp::RegisterBlock.304"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %72)
  %73 = bitcast %"struct.gemmlowp::RegisterBlock.304"* %15 to <4 x i32>*
  store <4 x i32> %70, <4 x i32>* %73, align 16
  %74 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %15, i64 0, i32 0, i32 0, i64 4
  %75 = bitcast i32* %74 to <4 x i32>*
  store <4 x i32> %71, <4 x i32>* %75, align 16
  %76 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.400", %"struct.gemmlowp::OutputPipelineExecutor.400"* %1, i64 0, i32 0
  %77 = tail call i64 @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi0ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalES8_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.401"* %76, %"struct.gemmlowp::RegisterBlock.304"* nonnull byval(%"struct.gemmlowp::RegisterBlock.304") align 8 %15, i32 %10, i32 %11) #19
  %78 = trunc i64 %77 to i8
  %79 = lshr i64 %77, 8
  %80 = trunc i64 %79 to i8
  %81 = lshr i64 %77, 16
  %82 = trunc i64 %81 to i8
  %83 = lshr i64 %77, 24
  %84 = trunc i64 %83 to i8
  %85 = lshr i64 %77, 32
  %86 = trunc i64 %85 to i8
  %87 = lshr i64 %77, 40
  %88 = trunc i64 %87 to i8
  %89 = lshr i64 %77, 48
  %90 = trunc i64 %89 to i8
  %91 = lshr i64 %77, 56
  %92 = trunc i64 %91 to i8
  %93 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %2, i64 0, i32 0
  %94 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %2, i64 0, i32 3
  %95 = sext i32 %12 to i64
  %96 = load i8*, i8** %93, align 8
  %97 = getelementptr inbounds i8, i8* %96, i64 %95
  %98 = load i32, i32* %94, align 8
  %99 = mul nsw i32 %98, %13
  %100 = sext i32 %99 to i64
  %101 = getelementptr inbounds i8, i8* %97, i64 %100
  store i8 %78, i8* %101, align 1
  %102 = add nsw i64 %95, 1
  %103 = load i8*, i8** %93, align 8
  %104 = getelementptr inbounds i8, i8* %103, i64 %102
  %105 = load i32, i32* %94, align 8
  %106 = mul nsw i32 %105, %13
  %107 = sext i32 %106 to i64
  %108 = getelementptr inbounds i8, i8* %104, i64 %107
  store i8 %80, i8* %108, align 1
  %109 = add nsw i64 %95, 2
  %110 = load i8*, i8** %93, align 8
  %111 = getelementptr inbounds i8, i8* %110, i64 %109
  %112 = load i32, i32* %94, align 8
  %113 = mul nsw i32 %112, %13
  %114 = sext i32 %113 to i64
  %115 = getelementptr inbounds i8, i8* %111, i64 %114
  store i8 %82, i8* %115, align 1
  %116 = add nsw i64 %95, 3
  %117 = load i8*, i8** %93, align 8
  %118 = getelementptr inbounds i8, i8* %117, i64 %116
  %119 = load i32, i32* %94, align 8
  %120 = mul nsw i32 %119, %13
  %121 = sext i32 %120 to i64
  %122 = getelementptr inbounds i8, i8* %118, i64 %121
  store i8 %84, i8* %122, align 1
  %123 = add nsw i64 %95, 4
  %124 = load i8*, i8** %93, align 8
  %125 = getelementptr inbounds i8, i8* %124, i64 %123
  %126 = load i32, i32* %94, align 8
  %127 = mul nsw i32 %126, %13
  %128 = sext i32 %127 to i64
  %129 = getelementptr inbounds i8, i8* %125, i64 %128
  store i8 %86, i8* %129, align 1
  %130 = add nsw i64 %95, 5
  %131 = load i8*, i8** %93, align 8
  %132 = getelementptr inbounds i8, i8* %131, i64 %130
  %133 = load i32, i32* %94, align 8
  %134 = mul nsw i32 %133, %13
  %135 = sext i32 %134 to i64
  %136 = getelementptr inbounds i8, i8* %132, i64 %135
  store i8 %88, i8* %136, align 1
  %137 = add nsw i64 %95, 6
  %138 = load i8*, i8** %93, align 8
  %139 = getelementptr inbounds i8, i8* %138, i64 %137
  %140 = load i32, i32* %94, align 8
  %141 = mul nsw i32 %140, %13
  %142 = sext i32 %141 to i64
  %143 = getelementptr inbounds i8, i8* %139, i64 %142
  store i8 %90, i8* %143, align 1
  %144 = add nsw i64 %95, 7
  %145 = load i8*, i8** %93, align 8
  %146 = getelementptr inbounds i8, i8* %145, i64 %144
  %147 = load i32, i32* %94, align 8
  %148 = mul nsw i32 %147, %13
  %149 = sext i32 %148 to i64
  %150 = getelementptr inbounds i8, i8* %146, i64 %149
  store i8 %92, i8* %150, align 1
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %72)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEES9_EENSA_IhLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.393"* dereferenceable(32), %"class.gemmlowp::MatrixMap.182"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %16 = sext i32 %8 to i64
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %18 = load i32*, i32** %15, align 8
  %19 = getelementptr inbounds i32, i32* %18, i64 %16
  %20 = load i32, i32* %17, align 8
  %21 = mul nsw i32 %20, %9
  %22 = sext i32 %21 to i64
  %23 = getelementptr inbounds i32, i32* %19, i64 %22
  %24 = getelementptr inbounds i32, i32* %23, i64 1
  %25 = load i32, i32* %23, align 4
  %26 = getelementptr inbounds i32, i32* %24, i64 1
  %27 = load i32, i32* %24, align 4
  %28 = getelementptr inbounds i32, i32* %26, i64 1
  %29 = load i32, i32* %26, align 4
  %30 = load i32, i32* %28, align 4
  %31 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %32 = load i32*, i32** %31, align 8
  %33 = getelementptr i32, i32* %32, i64 %16
  %34 = bitcast i32* %33 to i64*
  %35 = load i64, i64* %34, align 4
  %36 = getelementptr inbounds i32, i32* %33, i64 2
  %37 = bitcast i32* %36 to i64*
  %38 = load i64, i64* %37, align 4
  %39 = trunc i64 %35 to i32
  %40 = lshr i64 %35, 32
  %41 = trunc i64 %40 to i32
  %42 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %43 = load i32*, i32** %42, align 8
  %44 = sext i32 %9 to i64
  %45 = getelementptr inbounds i32, i32* %43, i64 %44
  %46 = load i32, i32* %45, align 4
  %47 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %48 = load i32, i32* %47, align 4
  %49 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %6, i64 0, i32 0
  %50 = load i32, i32* %49, align 4
  %51 = mul nsw i32 %50, %39
  %52 = add nsw i32 %51, %25
  %53 = mul nsw i32 %50, %41
  %54 = add nsw i32 %53, %27
  %55 = trunc i64 %38 to i32
  %56 = mul nsw i32 %50, %55
  %57 = add nsw i32 %56, %29
  %58 = lshr i64 %38, 32
  %59 = trunc i64 %58 to i32
  %60 = mul nsw i32 %50, %59
  %61 = add nsw i32 %60, %30
  %62 = mul nsw i32 %50, %7
  %63 = add nsw i32 %62, %46
  %64 = mul nsw i32 %63, %48
  %65 = add nsw i32 %52, %64
  %66 = add nsw i32 %54, %64
  %67 = add nsw i32 %57, %64
  %68 = zext i32 %67 to i64
  %69 = add nsw i32 %61, %64
  %70 = zext i32 %69 to i64
  %71 = shl nuw i64 %70, 32
  %72 = or i64 %71, %68
  %73 = zext i32 %66 to i64
  %74 = shl nuw i64 %73, 32
  %75 = zext i32 %65 to i64
  %76 = or i64 %74, %75
  %77 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.393", %"struct.gemmlowp::OutputPipelineExecutor.393"* %1, i64 0, i32 0, i32 0, i32 0
  %78 = tail call { i64, i64 } @_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi4EEEE4EvalES3_(%"struct.gemmlowp::OutputStageEvalBufferImpl.231"* %77, i64 %76, i64 %72) #19
  %79 = extractvalue { i64, i64 } %78, 0
  %80 = extractvalue { i64, i64 } %78, 1
  %81 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.393", %"struct.gemmlowp::OutputPipelineExecutor.393"* %1, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %82 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %81, align 8
  %83 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %82, i64 0, i32 0
  %84 = load i32, i32* %83, align 4
  %85 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %82, i64 0, i32 1
  %86 = load i32, i32* %85, align 4
  %87 = trunc i64 %79 to i32
  %88 = icmp sgt i32 %84, %87
  %89 = select i1 %88, i32 %84, i32 %87
  %90 = icmp slt i32 %86, %89
  %91 = select i1 %90, i32 %86, i32 %89
  %92 = lshr i64 %79, 32
  %93 = trunc i64 %92 to i32
  %94 = icmp sgt i32 %84, %93
  %95 = select i1 %94, i32 %84, i32 %93
  %96 = icmp slt i32 %86, %95
  %97 = select i1 %96, i32 %86, i32 %95
  %98 = trunc i64 %80 to i32
  %99 = icmp sgt i32 %84, %98
  %100 = select i1 %99, i32 %84, i32 %98
  %101 = icmp slt i32 %86, %100
  %102 = select i1 %101, i32 %86, i32 %100
  %103 = lshr i64 %80, 32
  %104 = trunc i64 %103 to i32
  %105 = icmp sgt i32 %84, %104
  %106 = select i1 %105, i32 %84, i32 %104
  %107 = icmp slt i32 %86, %106
  %108 = select i1 %107, i32 %86, i32 %106
  %109 = icmp sgt i32 %91, 0
  %110 = select i1 %109, i32 %91, i32 0
  %111 = icmp slt i32 %110, 255
  %112 = select i1 %111, i32 %110, i32 255
  %113 = icmp sgt i32 %97, 0
  %114 = select i1 %113, i32 %97, i32 0
  %115 = icmp slt i32 %114, 255
  %116 = select i1 %115, i32 %114, i32 255
  %117 = icmp sgt i32 %102, 0
  %118 = select i1 %117, i32 %102, i32 0
  %119 = icmp slt i32 %118, 255
  %120 = select i1 %119, i32 %118, i32 255
  %121 = icmp sgt i32 %108, 0
  %122 = select i1 %121, i32 %108, i32 0
  %123 = icmp slt i32 %122, 255
  %124 = select i1 %123, i32 %122, i32 255
  %125 = trunc i32 %112 to i8
  %126 = trunc i32 %116 to i8
  %127 = trunc i32 %120 to i8
  %128 = trunc i32 %124 to i8
  %129 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %2, i64 0, i32 0
  %130 = getelementptr inbounds %"class.gemmlowp::MatrixMap.182", %"class.gemmlowp::MatrixMap.182"* %2, i64 0, i32 3
  %131 = sext i32 %12 to i64
  %132 = load i8*, i8** %129, align 8
  %133 = getelementptr inbounds i8, i8* %132, i64 %131
  %134 = load i32, i32* %130, align 8
  %135 = mul nsw i32 %134, %13
  %136 = sext i32 %135 to i64
  %137 = getelementptr inbounds i8, i8* %133, i64 %136
  store i8 %125, i8* %137, align 1
  %138 = add nsw i64 %131, 1
  %139 = load i8*, i8** %129, align 8
  %140 = getelementptr inbounds i8, i8* %139, i64 %138
  %141 = load i32, i32* %130, align 8
  %142 = mul nsw i32 %141, %13
  %143 = sext i32 %142 to i64
  %144 = getelementptr inbounds i8, i8* %140, i64 %143
  store i8 %126, i8* %144, align 1
  %145 = add nsw i64 %131, 2
  %146 = load i8*, i8** %129, align 8
  %147 = getelementptr inbounds i8, i8* %146, i64 %145
  %148 = load i32, i32* %130, align 8
  %149 = mul nsw i32 %148, %13
  %150 = sext i32 %149 to i64
  %151 = getelementptr inbounds i8, i8* %147, i64 %150
  store i8 %127, i8* %151, align 1
  %152 = add nsw i64 %131, 3
  %153 = load i8*, i8** %129, align 8
  %154 = getelementptr inbounds i8, i8* %153, i64 %152
  %155 = load i32, i32* %130, align 8
  %156 = mul nsw i32 %155, %13
  %157 = sext i32 %156 to i64
  %158 = getelementptr inbounds i8, i8* %154, i64 %157
  store i8 %128, i8* %158, align 1
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEED2Ev(%"struct.gemmlowp::GemmWithPackedRhsTask.428"*) unnamed_addr #4 comdat align 2 {
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEED0Ev(%"struct.gemmlowp::GemmWithPackedRhsTask.428"*) unnamed_addr #4 comdat align 2 {
  %2 = bitcast %"struct.gemmlowp::GemmWithPackedRhsTask.428"* %0 to i8*
  tail call void @_ZdlPv(i8* %2) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhhNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEENS_11GemmContextEE3RunEv(%"struct.gemmlowp::GemmWithPackedRhsTask.428"*) unnamed_addr #1 comdat align 2 {
  %2 = alloca %"class.gemmlowp::SideMap", align 8
  %3 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %4 = alloca %"class.gemmlowp::ComputeImpl", align 8
  %5 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %6 = alloca %"class.gemmlowp::PackedResult", align 8
  %7 = alloca %"struct.gemmlowp::MatrixBlockBounds", align 4
  %8 = alloca %"class.gemmlowp::VectorDup", align 4
  %9 = alloca %"class.gemmlowp::VectorDup.194", align 4
  %10 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.428", %"struct.gemmlowp::GemmWithPackedRhsTask.428"* %0, i64 0, i32 6, i32 2
  %11 = load i32, i32* %10, align 8
  %12 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.428", %"struct.gemmlowp::GemmWithPackedRhsTask.428"* %0, i64 0, i32 6, i32 3
  %13 = load i32, i32* %12, align 4
  %14 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.428", %"struct.gemmlowp::GemmWithPackedRhsTask.428"* %0, i64 0, i32 3, i32 2
  %15 = load i32, i32* %14, align 4
  %16 = bitcast %"class.gemmlowp::PackedSideBlock"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %16) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %16, i8 -86, i64 80, i1 false)
  %17 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.428", %"struct.gemmlowp::GemmWithPackedRhsTask.428"* %0, i64 0, i32 0, i32 1
  %18 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %19 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.428", %"struct.gemmlowp::GemmWithPackedRhsTask.428"* %0, i64 0, i32 9
  %20 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %21 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %18, %"class.gemmlowp::Allocator"** %21, align 8
  %22 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 4
  store i32 0, i32* %22, align 8
  %23 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 0
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 0
  store i32 %24, i32* %25, align 8
  %26 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 3
  %27 = load i32, i32* %26, align 4
  %28 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 2
  store i32 %27, i32* %28, align 8
  %29 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 2
  %30 = load i32, i32* %29, align 4
  %31 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 1
  store i32 %30, i32* %31, align 4
  %32 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 5
  %33 = load i32, i32* %32, align 4
  %34 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 3
  store i32 %33, i32* %34, align 4
  %35 = mul nsw i32 %33, %27
  %36 = sext i32 %35 to i64
  %37 = add nsw i64 %36, 63
  %38 = and i64 %37, -64
  %39 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 4
  %40 = load i64, i64* %39, align 8, !noalias !1118
  %41 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 3
  %42 = load i64, i64* %41, align 8, !noalias !1118
  %43 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 5, i64 %42
  store i64 %40, i64* %43, align 8, !noalias !1118
  %44 = trunc i64 %42 to i8
  %45 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 6
  %46 = load i64, i64* %45, align 8, !noalias !1118
  %47 = bitcast i64* %41 to <2 x i64>*
  %48 = load <2 x i64>, <2 x i64>* %47, align 8, !noalias !1118
  %49 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %38, i32 1
  %50 = add <2 x i64> %48, %49
  %51 = bitcast i64* %41 to <2 x i64>*
  store <2 x i64> %50, <2 x i64>* %51, align 8, !noalias !1118
  %52 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 0
  store i8 %44, i8* %52, align 8
  %53 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %53, i8 -86, i64 7, i1 false) #19
  %54 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 2
  store i64 %46, i64* %54, align 8
  %55 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 3
  store i8 0, i8* %55, align 8
  %56 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %21, align 8
  %57 = load i32, i32* %28, align 8
  %58 = sext i32 %57 to i64
  %59 = shl nsw i64 %58, 2
  %60 = add nsw i64 %59, 63
  %61 = and i64 %60, -64
  %62 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 4
  %63 = load i64, i64* %62, align 8, !noalias !1121
  %64 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 3
  %65 = load i64, i64* %64, align 8, !noalias !1121
  %66 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 5, i64 %65
  store i64 %63, i64* %66, align 8, !noalias !1121
  %67 = trunc i64 %65 to i8
  %68 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 6
  %69 = load i64, i64* %68, align 8, !noalias !1121
  %70 = bitcast i64* %64 to <2 x i64>*
  %71 = load <2 x i64>, <2 x i64>* %70, align 8, !noalias !1121
  %72 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %61, i32 1
  %73 = add <2 x i64> %71, %72
  %74 = bitcast i64* %64 to <2 x i64>*
  store <2 x i64> %73, <2 x i64>* %74, align 8, !noalias !1121
  %75 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 0
  store i8 %67, i8* %75, align 8
  %76 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %76, i8 -86, i64 7, i1 false) #19
  %77 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 2
  store i64 %69, i64* %77, align 8
  %78 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 3
  store i8 5, i8* %78, align 8
  %79 = bitcast %"class.gemmlowp::PackedResult"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %79) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %79, i8 -86, i64 32, i1 false)
  %80 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %81 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %82 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 0
  store %"class.gemmlowp::Allocator"* %80, %"class.gemmlowp::Allocator"** %82, align 8
  %83 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 2
  store %"struct.gemmlowp::BlockParams"* %81, %"struct.gemmlowp::BlockParams"** %83, align 8
  %84 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %81, i64 0, i32 3
  %85 = load i32, i32* %84, align 4
  %86 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %81, i64 0, i32 4
  %87 = load i32, i32* %86, align 4
  %88 = mul nsw i32 %87, %85
  %89 = sext i32 %88 to i64
  %90 = shl nsw i64 %89, 2
  %91 = add nsw i64 %90, 63
  %92 = and i64 %91, -64
  %93 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 4
  %94 = load i64, i64* %93, align 8, !noalias !1124
  %95 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 3
  %96 = load i64, i64* %95, align 8, !noalias !1124
  %97 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 5, i64 %96
  store i64 %94, i64* %97, align 8, !noalias !1124
  %98 = trunc i64 %96 to i8
  %99 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 6
  %100 = load i64, i64* %99, align 8, !noalias !1124
  %101 = bitcast i64* %95 to <2 x i64>*
  %102 = load <2 x i64>, <2 x i64>* %101, align 8, !noalias !1124
  %103 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %92, i32 1
  %104 = add <2 x i64> %102, %103
  %105 = bitcast i64* %95 to <2 x i64>*
  store <2 x i64> %104, <2 x i64>* %105, align 8, !noalias !1124
  %106 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 0
  store i8 %98, i8* %106, align 8
  %107 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %107, i8 -86, i64 7, i1 false) #19
  %108 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 2
  store i64 %100, i64* %108, align 8
  %109 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 3
  store i8 5, i8* %109, align 8
  %110 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  tail call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %110)
  %111 = icmp sgt i32 %13, 0
  br i1 %111, label %112, label %156

112:                                              ; preds = %1
  %113 = icmp sgt i32 %11, 0
  %114 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.428", %"struct.gemmlowp::GemmWithPackedRhsTask.428"* %0, i64 0, i32 3, i32 0
  %115 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.428", %"struct.gemmlowp::GemmWithPackedRhsTask.428"* %0, i64 0, i32 3, i32 3
  %116 = bitcast %"class.gemmlowp::SideMap"* %2 to i8*
  %117 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 1
  %118 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 2
  %119 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 3
  %120 = bitcast %"class.gemmlowp::SideMap"* %2 to i64*
  %121 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %3 to i8*
  %122 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %3, i64 0, i32 0
  %123 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %3, i64 0, i32 1
  %124 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.428", %"struct.gemmlowp::GemmWithPackedRhsTask.428"* %0, i64 0, i32 2
  %125 = bitcast %"struct.gemmlowp::KernelBase"** %124 to i64*
  %126 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.428", %"struct.gemmlowp::GemmWithPackedRhsTask.428"* %0, i64 0, i32 4
  %127 = bitcast %"class.gemmlowp::ComputeImpl"* %4 to i8*
  %128 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 1
  %129 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 2
  %130 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 3
  %131 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 4
  %132 = bitcast %"class.gemmlowp::ComputeImpl"* %4 to i64*
  %133 = add i32 %15, 15
  %134 = and i32 %133, -16
  %135 = icmp sgt i32 %134, 0
  %136 = bitcast %"struct.gemmlowp::MatrixBlockBounds"* %7 to i8*
  %137 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 0
  %138 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 1
  %139 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 2
  %140 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 3
  %141 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.428", %"struct.gemmlowp::GemmWithPackedRhsTask.428"* %0, i64 0, i32 6, i32 0
  %142 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.428", %"struct.gemmlowp::GemmWithPackedRhsTask.428"* %0, i64 0, i32 6, i32 1
  %143 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.428", %"struct.gemmlowp::GemmWithPackedRhsTask.428"* %0, i64 0, i32 5
  %144 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.428", %"struct.gemmlowp::GemmWithPackedRhsTask.428"* %0, i64 0, i32 4, i32 1
  %145 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.428", %"struct.gemmlowp::GemmWithPackedRhsTask.428"* %0, i64 0, i32 4, i32 3, i32 0
  %146 = bitcast %"class.gemmlowp::VectorDup"* %8 to i8*
  %147 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.428", %"struct.gemmlowp::GemmWithPackedRhsTask.428"* %0, i64 0, i32 7
  %148 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %8, i64 0, i32 0
  %149 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %8, i64 0, i32 1
  %150 = bitcast %"class.gemmlowp::VectorDup.194"* %9 to i8*
  %151 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.428", %"struct.gemmlowp::GemmWithPackedRhsTask.428"* %0, i64 0, i32 8
  %152 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %9, i64 0, i32 0
  %153 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %9, i64 0, i32 1
  %154 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.428", %"struct.gemmlowp::GemmWithPackedRhsTask.428"* %0, i64 0, i32 10
  %155 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  br label %164

156:                                              ; preds = %178, %1
  %157 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %158 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 0
  store i8 0, i8* %158, align 8
  %159 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 6
  %160 = load i64, i64* %159, align 8
  %161 = add i64 %160, 1
  store i64 %161, i64* %159, align 8
  %162 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 3
  %163 = bitcast i64* %162 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %163, i8 0, i64 16, i1 false) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %79) #19
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %16) #19
  ret void

164:                                              ; preds = %112, %178
  %165 = phi %"struct.gemmlowp::BlockParams"* [ %155, %112 ], [ %180, %178 ]
  %166 = phi i32 [ 0, %112 ], [ %181, %178 ]
  %167 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %165, i64 0, i32 4
  %168 = sub nsw i32 %13, %166
  %169 = load i32, i32* %167, align 4
  %170 = icmp slt i32 %168, %169
  %171 = select i1 %170, i32 %168, i32 %169
  br i1 %113, label %172, label %178

172:                                              ; preds = %164
  %173 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %165, i64 0, i32 3
  %174 = load i32, i32* %173, align 4
  br label %183

175:                                              ; preds = %255
  %176 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %287, i64 0, i32 4
  %177 = load i32, i32* %176, align 4
  br label %178

178:                                              ; preds = %175, %164
  %179 = phi i32 [ %169, %164 ], [ %177, %175 ]
  %180 = phi %"struct.gemmlowp::BlockParams"* [ %165, %164 ], [ %287, %175 ]
  %181 = add nsw i32 %179, %166
  %182 = icmp sgt i32 %13, %181
  br i1 %182, label %164, label %156

183:                                              ; preds = %172, %255
  %184 = phi i32 [ %289, %255 ], [ %174, %172 ]
  %185 = phi i32 [ %290, %255 ], [ 0, %172 ]
  %186 = sub nsw i32 %11, %185
  %187 = icmp slt i32 %186, %184
  %188 = select i1 %187, i32 %186, i32 %184
  %189 = load i8*, i8** %114, align 8, !noalias !1127
  %190 = load i32, i32* %115, align 8, !noalias !1127
  %191 = mul nsw i32 %190, %185
  %192 = sext i32 %191 to i64
  %193 = getelementptr inbounds i8, i8* %189, i64 %192
  %194 = ptrtoint i8* %193 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %116) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %116, i8 -86, i64 24, i1 false) #19
  store i64 %194, i64* %120, align 8
  store i32 %188, i32* %117, align 8
  store i32 %15, i32* %118, align 4
  store i32 %190, i32* %119, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %121) #19
  store %"class.gemmlowp::PackedSideBlock"* %5, %"class.gemmlowp::PackedSideBlock"** %122, align 8
  store %"class.gemmlowp::SideMap"* %2, %"class.gemmlowp::SideMap"** %123, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %3) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %121) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %116) #19
  %195 = load i64, i64* %125, align 8
  %196 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %127) #19
  store i64 %195, i64* %132, align 8
  store %"struct.gemmlowp::BlockParams"* %196, %"struct.gemmlowp::BlockParams"** %128, align 8
  store %"class.gemmlowp::PackedResult"* %6, %"class.gemmlowp::PackedResult"** %129, align 8
  store %"class.gemmlowp::PackedSideBlock"* %5, %"class.gemmlowp::PackedSideBlock"** %130, align 8
  store %"class.gemmlowp::PackedSideBlock"* %126, %"class.gemmlowp::PackedSideBlock"** %131, align 8
  br i1 %135, label %197, label %255

197:                                              ; preds = %183, %215
  %198 = phi %"struct.gemmlowp::BlockParams"* [ %217, %215 ], [ %196, %183 ]
  %199 = phi %"struct.gemmlowp::BlockParams"* [ %218, %215 ], [ %196, %183 ]
  %200 = phi i32 [ %219, %215 ], [ 0, %183 ]
  %201 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 2
  %202 = sub nsw i32 %134, %200
  %203 = load i32, i32* %201, align 4
  %204 = icmp slt i32 %202, %203
  %205 = select i1 %204, i32 %202, i32 %203
  %206 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 3
  %207 = load i32, i32* %206, align 4
  %208 = icmp sgt i32 %207, 0
  br i1 %208, label %209, label %215

209:                                              ; preds = %197
  %210 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 0
  %211 = load i32, i32* %210, align 4
  br label %221

212:                                              ; preds = %247
  %213 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 2
  %214 = load i32, i32* %213, align 4
  br label %215

215:                                              ; preds = %212, %197
  %216 = phi i32 [ %203, %197 ], [ %214, %212 ]
  %217 = phi %"struct.gemmlowp::BlockParams"* [ %198, %197 ], [ %248, %212 ]
  %218 = phi %"struct.gemmlowp::BlockParams"* [ %199, %197 ], [ %248, %212 ]
  %219 = add nsw i32 %216, %200
  %220 = icmp sgt i32 %134, %219
  br i1 %220, label %197, label %255

221:                                              ; preds = %247, %209
  %222 = phi %"struct.gemmlowp::BlockParams"* [ %248, %247 ], [ %198, %209 ]
  %223 = phi i32 [ %250, %247 ], [ %211, %209 ]
  %224 = phi i32 [ %253, %247 ], [ %207, %209 ]
  %225 = phi %"struct.gemmlowp::BlockParams"* [ %248, %247 ], [ %199, %209 ]
  %226 = phi i32 [ %251, %247 ], [ 0, %209 ]
  %227 = sub nsw i32 %224, %226
  %228 = icmp slt i32 %227, %223
  %229 = select i1 %228, i32 %227, i32 %223
  %230 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %225, i64 0, i32 4
  %231 = load i32, i32* %230, align 4
  %232 = icmp sgt i32 %231, 0
  br i1 %232, label %233, label %247

233:                                              ; preds = %221
  %234 = icmp sgt i32 %229, 0
  br label %235

235:                                              ; preds = %237, %233
  %236 = phi i32 [ 0, %233 ], [ %238, %237 ]
  br i1 %234, label %240, label %237

237:                                              ; preds = %240, %235
  %238 = add nuw nsw i32 %236, 4
  %239 = icmp slt i32 %238, %231
  br i1 %239, label %235, label %245

240:                                              ; preds = %235, %240
  %241 = phi i32 [ %243, %240 ], [ 0, %235 ]
  %242 = add nsw i32 %241, %226
  call void @_ZN8gemmlowp11ComputeImplINS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEES7_NS_12PackedResultEE10ComputeRunEiiii(%"class.gemmlowp::ComputeImpl"* nonnull %4, i32 %242, i32 %236, i32 %200, i32 %205) #19
  %243 = add nuw nsw i32 %241, 4
  %244 = icmp slt i32 %243, %229
  br i1 %244, label %240, label %237

245:                                              ; preds = %237
  %246 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %128, align 8
  br label %247

247:                                              ; preds = %245, %221
  %248 = phi %"struct.gemmlowp::BlockParams"* [ %246, %245 ], [ %222, %221 ]
  %249 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 0
  %250 = load i32, i32* %249, align 4
  %251 = add nsw i32 %250, %226
  %252 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 3
  %253 = load i32, i32* %252, align 4
  %254 = icmp sgt i32 %253, %251
  br i1 %254, label %221, label %212

255:                                              ; preds = %215, %183
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %127) #19
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %136) #19
  %256 = load i32, i32* %141, align 8
  %257 = add nsw i32 %256, %185
  %258 = load i32, i32* %142, align 4
  %259 = add nsw i32 %258, %166
  store i32 %257, i32* %137, align 4
  store i32 %259, i32* %138, align 4
  store i32 %188, i32* %139, align 4
  store i32 %171, i32* %140, align 4
  %260 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %21, align 8
  %261 = load i8, i8* %75, align 8
  %262 = zext i8 %261 to i64
  %263 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %260, i64 0, i32 5, i64 %262
  %264 = load i64, i64* %263, align 8
  %265 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %260, i64 0, i32 2
  %266 = bitcast i8** %265 to i64*
  %267 = load i64, i64* %266, align 8
  %268 = add i64 %267, %264
  %269 = inttoptr i64 %268 to i32*
  %270 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %144, align 8
  %271 = load i8, i8* %145, align 8
  %272 = zext i8 %271 to i64
  %273 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %270, i64 0, i32 5, i64 %272
  %274 = load i64, i64* %273, align 8
  %275 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %270, i64 0, i32 2
  %276 = bitcast i8** %275 to i64*
  %277 = load i64, i64* %276, align 8
  %278 = add i64 %277, %274
  %279 = inttoptr i64 %278 to i32*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %146) #19
  %280 = load %"class.gemmlowp::VectorDup"*, %"class.gemmlowp::VectorDup"** %147, align 8
  %281 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %280, i64 0, i32 0
  %282 = load i32, i32* %281, align 4, !noalias !1130
  store i32 %282, i32* %148, align 4, !alias.scope !1130
  store i32 %188, i32* %149, align 4, !alias.scope !1130
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %150) #19
  %283 = load %"class.gemmlowp::VectorDup.194"*, %"class.gemmlowp::VectorDup.194"** %151, align 8
  %284 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %283, i64 0, i32 0
  %285 = load i32, i32* %284, align 4, !noalias !1133
  store i32 %285, i32* %152, align 4, !alias.scope !1133
  store i32 %171, i32* %153, align 4, !alias.scope !1133
  %286 = load %"class.std::__1::tuple.187"*, %"class.std::__1::tuple.187"** %154, align 8
  call void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIhLNS_8MapOrderE0EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE0EEENSC_ISD_LSE_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SV_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.182"* %143, %"struct.gemmlowp::MatrixBlockBounds"* nonnull dereferenceable(16) %7, %"class.gemmlowp::PackedResult"* nonnull dereferenceable(40) %6, i32 %15, i32* %269, i32* %279, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %8, %"class.gemmlowp::VectorDup.194"* nonnull dereferenceable(8) %9, %"class.std::__1::tuple.187"* dereferenceable(20) %286)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %150) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %146) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %136) #19
  %287 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %288 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %287, i64 0, i32 3
  %289 = load i32, i32* %288, align 4
  %290 = add nsw i32 %289, %185
  %291 = icmp sgt i32 %11, %290
  br i1 %291, label %183, label %175
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN6tflite16cpu_backend_gemm6detail16GemmImplUsingRuyIaaiaLNS0_18QuantizationFlavorE1EE3RunERKNS0_12MatrixParamsIaEEPKaS8_SA_S8_PaRKNS0_10GemmParamsIiaLS3_1EEEPNS_17CpuBackendContextE(%"struct.tflite::cpu_backend_gemm::MatrixParams.429"* dereferenceable(16), i8*, %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* dereferenceable(16), i8*, %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* dereferenceable(16), i8*, %"struct.tflite::cpu_backend_gemm::GemmParams.431"* dereferenceable(40), %"class.tflite::CpuBackendContext"*) local_unnamed_addr #1 comdat align 2 {
  %9 = alloca %"struct.ruy::Mat.438", align 8
  %10 = alloca %"struct.ruy::Mat.438", align 8
  %11 = alloca %"struct.ruy::Mat.438", align 8
  %12 = alloca %"class.ruy::MulParams.436", align 8
  %13 = getelementptr inbounds %"class.tflite::CpuBackendContext", %"class.tflite::CpuBackendContext"* %7, i64 0, i32 4
  %14 = load i8, i8* %13, align 4, !range !10
  %15 = icmp ne i8 %14, 0
  %16 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %0, i64 0, i32 0
  %17 = load i32, i32* %16, align 4
  %18 = icmp ne i32 %17, 0
  %19 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %0, i64 0, i32 1
  %20 = load i32, i32* %19, align 4
  %21 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %0, i64 0, i32 2
  %22 = load i32, i32* %21, align 4
  %23 = select i1 %18, i32 %22, i32 %20
  %24 = ptrtoint i8* %1 to i64
  %25 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %0, i64 0, i32 3
  %26 = load i8, i8* %25, align 4
  br i1 %15, label %27, label %34

27:                                               ; preds = %8
  %28 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %0, i64 0, i32 4
  %29 = load i8, i8* %28, align 1
  %30 = icmp eq i8 %29, 1
  %31 = zext i1 %30 to i8
  %32 = icmp eq i8 %29, 2
  %33 = select i1 %32, i8 3, i8 %31
  br label %34

34:                                               ; preds = %8, %27
  %35 = phi i8 [ %33, %27 ], [ 0, %8 ]
  %36 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %2, i64 0, i32 0
  %37 = load i32, i32* %36, align 4
  %38 = icmp ne i32 %37, 0
  %39 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %2, i64 0, i32 1
  %40 = load i32, i32* %39, align 4
  %41 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %2, i64 0, i32 2
  %42 = load i32, i32* %41, align 4
  %43 = select i1 %38, i32 %42, i32 %40
  %44 = ptrtoint i8* %3 to i64
  %45 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %2, i64 0, i32 3
  %46 = load i8, i8* %45, align 4
  br i1 %15, label %47, label %54

47:                                               ; preds = %34
  %48 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %2, i64 0, i32 4
  %49 = load i8, i8* %48, align 1
  %50 = icmp eq i8 %49, 1
  %51 = zext i1 %50 to i8
  %52 = icmp eq i8 %49, 2
  %53 = select i1 %52, i8 3, i8 %51
  br label %54

54:                                               ; preds = %34, %47
  %55 = phi i8 [ %53, %47 ], [ 0, %34 ]
  %56 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %4, i64 0, i32 0
  %57 = load i32, i32* %56, align 4
  %58 = icmp ne i32 %57, 0
  %59 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %4, i64 0, i32 1
  %60 = load i32, i32* %59, align 4
  %61 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %4, i64 0, i32 2
  %62 = load i32, i32* %61, align 4
  %63 = select i1 %58, i32 %62, i32 %60
  %64 = ptrtoint i8* %5 to i64
  %65 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %4, i64 0, i32 3
  %66 = load i8, i8* %65, align 4
  %67 = bitcast %"class.ruy::MulParams.436"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %67) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %67, i8 -86, i64 40, i1 false)
  %68 = getelementptr inbounds %"class.ruy::MulParams.436", %"class.ruy::MulParams.436"* %12, i64 0, i32 5
  %69 = getelementptr inbounds %"class.ruy::MulParams.436", %"class.ruy::MulParams.436"* %12, i64 0, i32 6
  %70 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.431", %"struct.tflite::cpu_backend_gemm::GemmParams.431"* %6, i64 0, i32 0
  %71 = load i32, i32* %70, align 8
  %72 = getelementptr inbounds %"class.ruy::MulParams.436", %"class.ruy::MulParams.436"* %12, i64 0, i32 1
  store i32 %71, i32* %72, align 8
  %73 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.431", %"struct.tflite::cpu_backend_gemm::GemmParams.431"* %6, i64 0, i32 1
  %74 = load i32, i32* %73, align 4
  %75 = getelementptr inbounds %"class.ruy::MulParams.436", %"class.ruy::MulParams.436"* %12, i64 0, i32 2
  store i32 %74, i32* %75, align 4
  %76 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.431", %"struct.tflite::cpu_backend_gemm::GemmParams.431"* %6, i64 0, i32 2
  %77 = getelementptr inbounds %"class.ruy::MulParams.436", %"class.ruy::MulParams.436"* %12, i64 0, i32 3
  %78 = bitcast i32** %76 to <2 x i64>*
  %79 = load <2 x i64>, <2 x i64>* %78, align 8
  %80 = bitcast i32** %77 to <2 x i64>*
  store <2 x i64> %79, <2 x i64>* %80, align 8
  %81 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.431", %"struct.tflite::cpu_backend_gemm::GemmParams.431"* %6, i64 0, i32 4
  %82 = bitcast i32** %81 to i64*
  %83 = load i64, i64* %82, align 8
  %84 = bitcast %"class.ruy::MulParams.436"* %12 to i64*
  store i64 %83, i64* %84, align 8
  %85 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.431", %"struct.tflite::cpu_backend_gemm::GemmParams.431"* %6, i64 0, i32 5
  %86 = load i8, i8* %85, align 8
  store i8 %86, i8* %68, align 8
  %87 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.431", %"struct.tflite::cpu_backend_gemm::GemmParams.431"* %6, i64 0, i32 6
  %88 = load i8, i8* %87, align 1
  store i8 %88, i8* %69, align 1
  %89 = getelementptr inbounds %"class.tflite::CpuBackendContext", %"class.tflite::CpuBackendContext"* %7, i64 0, i32 1, i32 0, i32 0, i32 0
  %90 = load %"class.ruy::Context"*, %"class.ruy::Context"** %89, align 8
  %91 = bitcast %"struct.ruy::Mat.438"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %91) #19
  %92 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %9, i64 0, i32 1, i32 2
  %93 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %9, i64 0, i32 2
  %94 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %9, i64 0, i32 3
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %91, i8 -86, i64 32, i1 false) #19
  %95 = bitcast %"struct.ruy::Mat.438"* %9 to i64*
  store i64 %24, i64* %95, align 8, !alias.scope !1136
  %96 = zext i32 %23 to i64
  %97 = zext i1 %18 to i64
  %98 = shl nuw nsw i64 %97, 32
  %99 = or i64 %98, %96
  %100 = zext i32 %22 to i64
  %101 = shl nuw i64 %100, 32
  %102 = zext i32 %20 to i64
  %103 = or i64 %101, %102
  %104 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %9, i64 0, i32 1
  %105 = bitcast %"struct.ruy::MatLayout"* %104 to i64*
  store i64 %103, i64* %105, align 8, !alias.scope !1136
  %106 = bitcast i32* %92 to i40*
  %107 = trunc i64 %99 to i40
  store i40 %107, i40* %106, align 8, !alias.scope !1136
  store i8 %26, i8* %93, align 8, !alias.scope !1136
  store i8 %35, i8* %94, align 1, !alias.scope !1136
  %108 = bitcast %"struct.ruy::Mat.438"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %108) #19
  %109 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %10, i64 0, i32 1, i32 2
  %110 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %10, i64 0, i32 2
  %111 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %10, i64 0, i32 3
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %108, i8 -86, i64 32, i1 false) #19
  %112 = bitcast %"struct.ruy::Mat.438"* %10 to i64*
  store i64 %44, i64* %112, align 8, !alias.scope !1139
  %113 = zext i32 %43 to i64
  %114 = zext i1 %38 to i64
  %115 = shl nuw nsw i64 %114, 32
  %116 = or i64 %115, %113
  %117 = zext i32 %42 to i64
  %118 = shl nuw i64 %117, 32
  %119 = zext i32 %40 to i64
  %120 = or i64 %118, %119
  %121 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %10, i64 0, i32 1
  %122 = bitcast %"struct.ruy::MatLayout"* %121 to i64*
  store i64 %120, i64* %122, align 8, !alias.scope !1139
  %123 = bitcast i32* %109 to i40*
  %124 = trunc i64 %116 to i40
  store i40 %124, i40* %123, align 8, !alias.scope !1139
  store i8 %46, i8* %110, align 8, !alias.scope !1139
  store i8 %55, i8* %111, align 1, !alias.scope !1139
  %125 = bitcast %"struct.ruy::Mat.438"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %125) #19
  %126 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %11, i64 0, i32 1, i32 2
  %127 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %11, i64 0, i32 2
  %128 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %11, i64 0, i32 3
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %125, i8 -86, i64 32, i1 false) #19
  %129 = bitcast %"struct.ruy::Mat.438"* %11 to i64*
  store i64 %64, i64* %129, align 8, !alias.scope !1142
  %130 = zext i32 %63 to i64
  %131 = zext i1 %58 to i64
  %132 = shl nuw nsw i64 %131, 32
  %133 = or i64 %132, %130
  %134 = zext i32 %62 to i64
  %135 = shl nuw i64 %134, 32
  %136 = zext i32 %60 to i64
  %137 = or i64 %135, %136
  %138 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %11, i64 0, i32 1
  %139 = bitcast %"struct.ruy::MatLayout"* %138 to i64*
  store i64 %137, i64* %139, align 8, !alias.scope !1142
  %140 = bitcast i32* %126 to i40*
  %141 = trunc i64 %133 to i40
  store i40 %141, i40* %140, align 8, !alias.scope !1142
  store i8 %66, i8* %127, align 8, !alias.scope !1142
  store i8 0, i8* %128, align 1, !alias.scope !1142
  %142 = tail call %"class.ruy::Ctx"* @_ZN3ruy7get_ctxEPNS_7ContextE(%"class.ruy::Context"* %90) #19
  call void @_ZN3ruy11DispatchMulILNS_4PathE26EaaaNS_9MulParamsIiaEEEEvRKNS_3MatIT0_EERKNS4_IT1_EERKT3_PNS_3CtxEPNS4_IT2_EE(%"struct.ruy::Mat.438"* nonnull dereferenceable(32) %9, %"struct.ruy::Mat.438"* nonnull dereferenceable(32) %10, %"class.ruy::MulParams.436"* nonnull dereferenceable(40) %12, %"class.ruy::Ctx"* %142, %"struct.ruy::Mat.438"* nonnull %11) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %125) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %108) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %91) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %67) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy11DispatchMulILNS_4PathE26EaaaNS_9MulParamsIiaEEEEvRKNS_3MatIT0_EERKNS4_IT1_EERKT3_PNS_3CtxEPNS4_IT2_EE(%"struct.ruy::Mat.438"* dereferenceable(32), %"struct.ruy::Mat.438"* dereferenceable(32), %"class.ruy::MulParams.436"* dereferenceable(40), %"class.ruy::Ctx"*, %"struct.ruy::Mat.438"*) local_unnamed_addr #1 comdat {
  %6 = alloca %"struct.ruy::TrMulParams", align 8
  %7 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %0, i64 0, i32 1, i32 1
  %8 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %0, i64 0, i32 2
  %9 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %1, i64 0, i32 2
  %10 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %4, i64 0, i32 2
  %11 = tail call zeroext i8 @_ZN3ruy3Ctx10SelectPathENS_4PathE(%"class.ruy::Ctx"* %3, i8 zeroext 26) #19
  %12 = bitcast %"struct.ruy::Mat.438"* %0 to i64*
  %13 = load i64, i64* %12, align 8
  %14 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %0, i64 0, i32 1, i32 0
  %15 = load i32, i32* %14, align 8
  %16 = load i32, i32* %7, align 4
  %17 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %0, i64 0, i32 1, i32 2
  %18 = load i32, i32* %17, align 8
  %19 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %0, i64 0, i32 1, i32 3
  %20 = load i8, i8* %19, align 4
  %21 = load i8, i8* %8, align 8
  %22 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %0, i64 0, i32 3
  %23 = load i8, i8* %22, align 1
  %24 = icmp eq i8 %20, 0
  %25 = zext i1 %24 to i8
  %26 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 0
  call void @llvm.lifetime.start.p0i8(i64 280, i8* nonnull %26) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %26, i8 -86, i64 272, i1 false)
  %27 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 1
  %28 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 0, i32 2
  %29 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 0, i32 4
  %30 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 0, i32 5
  %31 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1, i32 2
  %32 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1, i32 4
  store i32 0, i32* %32, align 8
  %33 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1, i32 5
  %34 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 4, i32 0, i32 0
  store i8 0, i8* %34, align 8
  %35 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 4, i32 0, i32 1
  store i8 0, i8* %35, align 1
  %36 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 4, i32 0, i32 2
  store i8 0, i8* %36, align 2
  %37 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 4, i32 2
  %38 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 4, i32 4
  store i32 0, i32* %38, align 8
  %39 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 4, i32 5
  store i8 0, i8* %39, align 4
  %40 = bitcast i8** %37 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %40, i8 0, i64 21, i1 false) #19
  %41 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 0, i32 0
  store i8 0, i8* %41, align 8
  %42 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 0, i32 1
  store i8 0, i8* %42, align 1
  %43 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 0, i32 2
  store i8 0, i8* %43, align 2
  %44 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 2
  %45 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 5
  %46 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 1
  %47 = bitcast i8** %44 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %47, i8 0, i64 11, i1 false) #19
  %48 = bitcast i8** %45 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %48, i8 0, i64 22, i1 false) #19
  %49 = bitcast %"class.ruy::SidePair"* %27 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %49, i8 0, i64 24, i1 false) #19
  store i8 1, i8* %46, align 1
  %50 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 2
  store i8 1, i8* %50, align 1
  %51 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 7
  store i32 0, i32* %51, align 8
  %52 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 0, i32 0
  store i8 0, i8* %52, align 8
  %53 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 0, i32 1
  store i8 0, i8* %53, align 1
  %54 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 0, i32 2
  store i8 0, i8* %54, align 2
  %55 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 2
  %56 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 5
  %57 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 1
  %58 = bitcast i8** %55 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %58, i8 0, i64 11, i1 false) #19
  %59 = bitcast i8** %56 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %59, i8 0, i64 22, i1 false) #19
  store i8 1, i8* %57, align 1
  %60 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 2
  store i8 1, i8* %60, align 1
  %61 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 7
  store i32 0, i32* %61, align 8
  %62 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 6, i32 0, i64 0
  store i8 0, i8* %62, align 8
  %63 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 6, i32 0, i64 1
  store i8 0, i8* %63, align 1
  %64 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 7
  %65 = sext i8 %21 to i32
  %66 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3
  %67 = bitcast %"class.ruy::SidePair.106"* %66 to i24*
  store i24 65537, i24* %67, align 8
  %68 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 0, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %68, i8 -86, i64 5, i1 false) #19
  %69 = bitcast i8** %28 to i64*
  store i64 %13, i64* %69, align 8
  %70 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 0, i32 3, i32 0
  store i32 %16, i32* %70, align 8
  %71 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 0, i32 3, i32 1
  store i32 %15, i32* %71, align 4
  %72 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 0, i32 3, i32 2
  store i32 %18, i32* %72, align 8
  %73 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 0, i32 3, i32 3
  store i8 %25, i8* %73, align 4
  %74 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 0, i32 3, i32 4, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %74, i8 -86, i64 3, i1 false) #19
  store i32 %65, i32* %29, align 8
  store i8 %23, i8* %30, align 4
  %75 = bitcast %"struct.ruy::Mat.438"* %1 to i64*
  %76 = load i64, i64* %75, align 8, !noalias !1145
  %77 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %1, i64 0, i32 1
  %78 = bitcast %"struct.ruy::MatLayout"* %77 to i8*
  %79 = load i8, i8* %9, align 8, !noalias !1145
  %80 = sext i8 %79 to i32
  %81 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %1, i64 0, i32 3
  %82 = load i8, i8* %81, align 1, !noalias !1145
  %83 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1
  %84 = bitcast %"struct.ruy::EMat"* %83 to i24*
  store i24 65537, i24* %84, align 8
  %85 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %85, i8 -86, i64 5, i1 false) #19
  %86 = bitcast i8** %31 to i64*
  store i64 %76, i64* %86, align 8
  %87 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1, i32 3
  %88 = bitcast %"struct.ruy::MatLayout"* %87 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %88, i8* align 4 %78, i64 13, i1 false)
  %89 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1, i32 3, i32 4, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %89, i8 -86, i64 3, i1 false) #19
  store i32 %80, i32* %32, align 8
  store i8 %82, i8* %33, align 4
  %90 = bitcast %"struct.ruy::Mat.438"* %4 to i64*
  %91 = load i64, i64* %90, align 8, !noalias !1148
  %92 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %4, i64 0, i32 1
  %93 = bitcast %"struct.ruy::MatLayout"* %92 to i8*
  %94 = load i8, i8* %10, align 8, !noalias !1148
  %95 = sext i8 %94 to i32
  %96 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %4, i64 0, i32 3
  %97 = load i8, i8* %96, align 1, !noalias !1148
  %98 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 4
  %99 = bitcast %"struct.ruy::EMat"* %98 to i24*
  store i24 65537, i24* %99, align 8
  %100 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 4, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %100, i8 -86, i64 5, i1 false) #19
  %101 = bitcast i8** %37 to i64*
  store i64 %91, i64* %101, align 8
  %102 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 4, i32 3
  %103 = bitcast %"struct.ruy::MatLayout"* %102 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %103, i8* align 4 %93, i64 13, i1 false)
  %104 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 4, i32 3, i32 4, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %104, i8 -86, i64 3, i1 false) #19
  store i32 %95, i32* %38, align 8
  store i8 %97, i8* %39, align 4
  %105 = bitcast i8** %64 to %"class.ruy::MulParams.436"**
  store %"class.ruy::MulParams.436"* %2, %"class.ruy::MulParams.436"** %105, align 8
  %106 = icmp eq i8 %11, 16
  br i1 %106, label %107, label %192

107:                                              ; preds = %5
  br i1 %24, label %116, label %108

108:                                              ; preds = %107
  %109 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1, i32 3, i32 3
  %110 = load i8, i8* %109, align 4
  %111 = icmp eq i8 %110, 0
  br i1 %111, label %112, label %116

112:                                              ; preds = %108
  %113 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 4, i32 3, i32 3
  %114 = load i8, i8* %113, align 4
  %115 = icmp eq i8 %114, 0
  br i1 %115, label %150, label %116

116:                                              ; preds = %107, %112, %108
  store i8 2, i8* %26, align 8
  %117 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0
  %118 = bitcast %"struct.ruy::PEMat"* %117 to i24*
  store i24 65537, i24* %118, align 8
  %119 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 3
  %120 = bitcast %"struct.ruy::Type"* %119 to i24*
  store i24 262145, i24* %120, align 8
  %121 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 3
  store i8 0, i8* %121, align 4
  %122 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 0
  store i32 %16, i32* %122, align 8
  %123 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 1
  store i32 %15, i32* %123, align 4
  %124 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 0
  store i8 0, i8* %124, align 1
  store i8 1, i8* %46, align 1
  store i8 1, i8* %50, align 1
  %125 = and i32 %16, 1023
  %126 = icmp eq i32 %125, 0
  %127 = add nsw i32 %16, 64
  %128 = select i1 %126, i32 %127, i32 %16
  %129 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 2
  store i32 %128, i32* %129, align 8
  store i32 %65, i32* %51, align 8
  %130 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1
  %131 = bitcast %"struct.ruy::PEMat"* %130 to i24*
  store i24 65537, i24* %131, align 8
  %132 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 3
  %133 = bitcast %"struct.ruy::Type"* %132 to i24*
  store i24 262145, i24* %133, align 8
  %134 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 3
  store i8 0, i8* %134, align 4
  %135 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1, i32 3, i32 0
  %136 = load i32, i32* %135, align 8
  %137 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 0
  store i32 %136, i32* %137, align 8
  %138 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1, i32 3, i32 1
  %139 = load i32, i32* %138, align 4
  %140 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 1
  store i32 %139, i32* %140, align 4
  %141 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 0
  store i8 0, i8* %141, align 1
  store i8 1, i8* %57, align 1
  store i8 1, i8* %60, align 1
  %142 = and i32 %136, 1023
  %143 = icmp eq i32 %142, 0
  %144 = add nsw i32 %136, 64
  %145 = select i1 %143, i32 %144, i32 %136
  %146 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 2
  store i32 %145, i32* %146, align 8
  store i32 %80, i32* %61, align 8
  %147 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 1, i32 0, i64 0
  %148 = bitcast void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)** %147 to <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*>*
  store <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*> <void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* @_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEaaEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii, void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* @_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEaaEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii>, <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*>* %148, align 8
  %149 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 2
  store void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)* @_ZN3ruy9RunKernelILNS_4PathE2EaaaNS_9MulParamsIiaEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE, void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)** %149, align 8
  br label %193

150:                                              ; preds = %112
  store i8 16, i8* %26, align 8
  %151 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0
  %152 = bitcast %"struct.ruy::PEMat"* %151 to i24*
  store i24 65537, i24* %152, align 8
  %153 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 3
  %154 = bitcast %"struct.ruy::Type"* %153 to i24*
  store i24 262145, i24* %154, align 8
  %155 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 3
  store i8 0, i8* %155, align 4
  %156 = add i32 %16, 3
  %157 = and i32 %156, -4
  %158 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 0
  store i32 %157, i32* %158, align 8
  %159 = add i32 %15, 15
  %160 = and i32 %159, -16
  %161 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 1
  store i32 %160, i32* %161, align 4
  %162 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 0
  store i8 0, i8* %162, align 1
  store i8 4, i8* %46, align 1
  store i8 16, i8* %50, align 1
  %163 = and i32 %156, 1020
  %164 = icmp eq i32 %163, 0
  %165 = add nsw i32 %157, 64
  %166 = select i1 %164, i32 %165, i32 %157
  %167 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 0, i32 6, i32 2
  store i32 %166, i32* %167, align 8
  store i32 %65, i32* %51, align 8
  %168 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1
  %169 = bitcast %"struct.ruy::PEMat"* %168 to i24*
  store i24 65537, i24* %169, align 8
  %170 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 3
  %171 = bitcast %"struct.ruy::Type"* %170 to i24*
  store i24 262145, i24* %171, align 8
  %172 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 3
  store i8 0, i8* %172, align 4
  %173 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1, i32 3, i32 0
  %174 = load i32, i32* %173, align 8
  %175 = add i32 %174, 3
  %176 = and i32 %175, -4
  %177 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 0
  store i32 %176, i32* %177, align 8
  %178 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 3, i32 0, i64 1, i32 3, i32 1
  %179 = load i32, i32* %178, align 4
  %180 = add i32 %179, 15
  %181 = and i32 %180, -16
  %182 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 1
  store i32 %181, i32* %182, align 4
  %183 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 0
  store i8 0, i8* %183, align 1
  store i8 4, i8* %57, align 1
  store i8 16, i8* %60, align 1
  %184 = and i32 %175, 1020
  %185 = icmp eq i32 %184, 0
  %186 = add nsw i32 %176, 64
  %187 = select i1 %185, i32 %186, i32 %176
  %188 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 5, i32 0, i64 1, i32 6, i32 2
  store i32 %187, i32* %188, align 8
  store i32 %80, i32* %61, align 8
  %189 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 1, i32 0, i64 0
  %190 = bitcast void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)** %189 to <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*>*
  store <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*> <void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* @_ZN3ruy7RunPackILNS_4PathE16ENS_17FixedKernelLayoutILNS_5OrderE0ELi4ELi16EEEaaEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii, void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* @_ZN3ruy7RunPackILNS_4PathE16ENS_17FixedKernelLayoutILNS_5OrderE0ELi4ELi16EEEaaEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii>, <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*>* %190, align 8
  %191 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %6, i64 0, i32 2
  store void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)* @_ZN3ruy9RunKernelILNS_4PathE16EaaaNS_9MulParamsIiaEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE, void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)** %191, align 8
  br label %193

192:                                              ; preds = %5
  call void @_ZN3ruy27PathSearchOnlyCompiledPathsILNS_4PathE26ELb1ELi3EaaaNS_9MulParamsIiaEEE6SearchES1_PNS_11TrMulParamsE(i8 zeroext %11, %"struct.ruy::TrMulParams"* nonnull %6) #19
  br label %193

193:                                              ; preds = %150, %116, %192
  call void @_ZN3ruy22HandlePrepackedCachingEPNS_11TrMulParamsEPNS_3CtxE(%"struct.ruy::TrMulParams"* nonnull %6, %"class.ruy::Ctx"* %3)
  call void @_ZN3ruy5TrMulEPNS_11TrMulParamsEPNS_3CtxE(%"struct.ruy::TrMulParams"* nonnull %6, %"class.ruy::Ctx"* %3) #19
  call void @llvm.lifetime.end.p0i8(i64 280, i8* nonnull %26) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy7RunPackILNS_4PathE16ENS_17FixedKernelLayoutILNS_5OrderE0ELi4ELi16EEEaaEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii(i32, %"struct.ruy::EMat"* dereferenceable(40), %"struct.ruy::PEMat"*, i32, i32) #1 comdat {
  %6 = alloca [32 x i8], align 16
  %7 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 2
  %8 = load i8*, i8** %7, align 8, !noalias !1151
  %9 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3, i32 0
  %10 = load i32, i32* %9, align 4
  %11 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3, i32 1
  %12 = load i32, i32* %11, align 4
  %13 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3, i32 2
  %14 = load i32, i32* %13, align 4
  %15 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 2
  %16 = load i8*, i8** %15, align 8, !noalias !1154
  %17 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 5
  %18 = bitcast i8** %17 to i32**
  %19 = load i32*, i32** %18, align 8, !noalias !1154
  %20 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 6, i32 2
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 7
  %23 = load i32, i32* %22, align 8, !noalias !1154
  %24 = getelementptr inbounds [32 x i8], [32 x i8]* %6, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %24) #19
  %25 = trunc i32 %23 to i8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %24, i8 %25, i64 32, i1 false) #19
  %26 = icmp slt i32 %3, %4
  br i1 %26, label %27, label %46

27:                                               ; preds = %5
  %28 = icmp eq i32* %19, null
  %29 = sext i32 %3 to i64
  %30 = sext i32 %4 to i64
  %31 = sext i32 %14 to i64
  br label %32

32:                                               ; preds = %32, %27
  %33 = phi i64 [ %29, %27 ], [ %44, %32 ]
  %34 = getelementptr inbounds i32, i32* %19, i64 %33
  %35 = select i1 %28, i32* null, i32* %34
  %36 = mul nsw i64 %33, %31
  %37 = getelementptr inbounds i8, i8* %8, i64 %36
  %38 = trunc i64 %33 to i32
  %39 = sub nsw i32 %12, %38
  %40 = and i32 %38, -16
  %41 = mul nsw i32 %40, %21
  %42 = sext i32 %41 to i64
  %43 = getelementptr inbounds i8, i8* %16, i64 %42
  call void @_ZN3ruy14Pack8bitAvx512EPKaaS1_iiiPaPi(i8* %37, i8 signext 0, i8* nonnull %24, i32 %14, i32 %39, i32 %10, i8* %43, i32* %35) #19
  %44 = add nsw i64 %33, 16
  %45 = icmp slt i64 %44, %30
  br i1 %45, label %32, label %46

46:                                               ; preds = %32, %5
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %24) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy9RunKernelILNS_4PathE16EaaaNS_9MulParamsIiaEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE(i32, %"class.ruy::SidePair.104"* dereferenceable(112), i8*, %"class.ruy::SidePair.105"* dereferenceable(8), %"class.ruy::SidePair.105"* dereferenceable(8), %"struct.ruy::EMat"*) #1 comdat {
  %7 = alloca %"struct.ruy::KernelParams8bit", align 8
  %8 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 2
  %9 = load i8*, i8** %8, align 8, !noalias !1157
  %10 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 0
  %11 = load i32, i32* %10, align 4
  %12 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 1
  %13 = load i32, i32* %12, align 4
  %14 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 2
  %15 = load i32, i32* %14, align 4
  %16 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 4
  %17 = load i32, i32* %16, align 8, !noalias !1157
  %18 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 2
  %19 = load i8*, i8** %18, align 8, !noalias !1160
  %20 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 5
  %21 = bitcast i8** %20 to i32**
  %22 = load i32*, i32** %21, align 8, !noalias !1160
  %23 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 6, i32 0
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 6, i32 2
  %26 = load i32, i32* %25, align 4
  %27 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 7
  %28 = load i32, i32* %27, align 8, !noalias !1160
  %29 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 2
  %30 = load i8*, i8** %29, align 8, !noalias !1163
  %31 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 5
  %32 = bitcast i8** %31 to i32**
  %33 = load i32*, i32** %32, align 8, !noalias !1163
  %34 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 6, i32 2
  %35 = load i32, i32* %34, align 4
  %36 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 7
  %37 = load i32, i32* %36, align 8, !noalias !1163
  %38 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %3, i64 0, i32 0, i64 0
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %3, i64 0, i32 0, i64 1
  %41 = load i32, i32* %40, align 4
  %42 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %4, i64 0, i32 0, i64 0
  %43 = load i32, i32* %42, align 4
  %44 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %4, i64 0, i32 0, i64 1
  %45 = load i32, i32* %44, align 4
  %46 = bitcast %"struct.ruy::KernelParams8bit"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1352, i8* nonnull %46) #19
  %47 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 1
  %48 = bitcast i32** %47 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %48, i8 -86, i64 1344, i1 false) #19
  %49 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 27, i64 0
  %50 = bitcast i32* %49 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 4 %50, i8 0, i64 64, i1 false) #19
  %51 = mul nsw i32 %39, %26
  %52 = sext i32 %51 to i64
  %53 = getelementptr inbounds i8, i8* %19, i64 %52
  %54 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 3
  store i8* %53, i8** %54, align 8
  %55 = mul nsw i32 %41, %35
  %56 = sext i32 %55 to i64
  %57 = getelementptr inbounds i8, i8* %30, i64 %56
  %58 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 6
  store i8* %57, i8** %58, align 8
  %59 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 24
  store i8 0, i8* %59, align 8
  %60 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 0
  store i32* %49, i32** %60, align 8
  %61 = bitcast i8* %2 to i32**
  %62 = load i32*, i32** %61, align 8
  %63 = icmp eq i32* %62, null
  br i1 %63, label %65, label %64

64:                                               ; preds = %6
  store i32* %62, i32** %60, align 8
  store i8 1, i8* %59, align 8
  br label %65

65:                                               ; preds = %64, %6
  %66 = phi i8 [ 0, %6 ], [ 1, %64 ]
  %67 = icmp eq i32* %22, null
  br i1 %67, label %71, label %68

68:                                               ; preds = %65
  %69 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 1
  store i32* %22, i32** %69, align 8
  %70 = or i8 %66, 2
  store i8 %70, i8* %59, align 8
  br label %71

71:                                               ; preds = %68, %65
  %72 = phi i8 [ %66, %65 ], [ %70, %68 ]
  %73 = icmp eq i32* %33, null
  br i1 %73, label %77, label %74

74:                                               ; preds = %71
  %75 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 2
  store i32* %33, i32** %75, align 8
  %76 = or i8 %72, 4
  store i8 %76, i8* %59, align 8
  br label %77

77:                                               ; preds = %74, %71
  %78 = phi i8 [ %72, %71 ], [ %76, %74 ]
  %79 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 12
  store i32 %39, i32* %79, align 8
  %80 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 13
  store i32 %41, i32* %80, align 4
  %81 = add nsw i32 %43, -16
  %82 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 14
  store i32 %81, i32* %82, align 8
  %83 = add nsw i32 %45, -16
  %84 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 15
  store i32 %83, i32* %84, align 4
  %85 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 18
  store i32 %26, i32* %85, align 8
  %86 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 19
  store i32 %35, i32* %86, align 4
  %87 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 20
  store i32 %15, i32* %87, align 8
  %88 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 8
  store i32 %28, i32* %88, align 8
  %89 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 9
  store i32 %37, i32* %89, align 4
  %90 = shl i32 %17, 24
  %91 = ashr exact i32 %90, 24
  %92 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 10
  store i32 %91, i32* %92, align 8
  %93 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 21
  store i32 %24, i32* %93, align 4
  %94 = mul i32 %28, %24
  %95 = mul i32 %94, %37
  %96 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 11
  store i32 %95, i32* %96, align 4
  %97 = getelementptr inbounds i8, i8* %2, i64 16
  %98 = bitcast i8* %97 to i32**
  %99 = load i32*, i32** %98, align 8
  %100 = icmp eq i32* %99, null
  br i1 %100, label %111, label %101

101:                                              ; preds = %77
  %102 = ptrtoint i32* %99 to i64
  %103 = or i8 %78, 24
  store i8 %103, i8* %59, align 8
  %104 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 4
  %105 = bitcast i32** %104 to i64*
  store i64 %102, i64* %105, align 8
  %106 = getelementptr inbounds i8, i8* %2, i64 24
  %107 = bitcast i8* %106 to i64*
  %108 = load i64, i64* %107, align 8
  %109 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 5
  %110 = bitcast i32** %109 to i64*
  store i64 %108, i64* %110, align 8
  br label %148

111:                                              ; preds = %77
  %112 = getelementptr inbounds i8, i8* %2, i64 12
  %113 = bitcast i8* %112 to i32*
  %114 = load i32, i32* %113, align 4
  %115 = icmp sgt i32 %114, 0
  br i1 %115, label %116, label %118

116:                                              ; preds = %111
  %117 = or i8 %78, 16
  store i8 %117, i8* %59, align 8
  br label %118

118:                                              ; preds = %116, %111
  %119 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 29, i64 0
  %120 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 4
  store i32* %119, i32** %120, align 8
  %121 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 30, i64 0
  %122 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 5
  store i32* %121, i32** %122, align 8
  %123 = getelementptr inbounds i8, i8* %2, i64 8
  %124 = bitcast i8* %123 to i32*
  %125 = load i32, i32* %124, align 8
  %126 = insertelement <4 x i32> undef, i32 %125, i32 0
  %127 = shufflevector <4 x i32> %126, <4 x i32> undef, <4 x i32> zeroinitializer
  %128 = bitcast i32* %119 to <4 x i32>*
  store <4 x i32> %127, <4 x i32>* %128, align 4
  %129 = insertelement <4 x i32> undef, i32 %114, i32 0
  %130 = shufflevector <4 x i32> %129, <4 x i32> undef, <4 x i32> zeroinitializer
  %131 = bitcast i32* %121 to <4 x i32>*
  store <4 x i32> %130, <4 x i32>* %131, align 4
  %132 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 29, i64 4
  store i32 %125, i32* %132, align 4
  %133 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 30, i64 4
  store i32 %114, i32* %133, align 4
  %134 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 29, i64 5
  store i32 %125, i32* %134, align 4
  %135 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 30, i64 5
  store i32 %114, i32* %135, align 4
  %136 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 29, i64 6
  store i32 %125, i32* %136, align 4
  %137 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 30, i64 6
  store i32 %114, i32* %137, align 4
  %138 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 29, i64 7
  %139 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 30, i64 7
  %140 = bitcast i32* %138 to <4 x i32>*
  store <4 x i32> %127, <4 x i32>* %140, align 4
  %141 = bitcast i32* %139 to <4 x i32>*
  store <4 x i32> %130, <4 x i32>* %141, align 4
  %142 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 29, i64 11
  %143 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 30, i64 11
  %144 = bitcast i32* %142 to <4 x i32>*
  store <4 x i32> %127, <4 x i32>* %144, align 4
  %145 = bitcast i32* %143 to <4 x i32>*
  store <4 x i32> %130, <4 x i32>* %145, align 4
  %146 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 29, i64 15
  store i32 %125, i32* %146, align 4
  %147 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 30, i64 15
  store i32 %114, i32* %147, align 4
  br label %148

148:                                              ; preds = %101, %118
  %149 = getelementptr inbounds i8, i8* %2, i64 32
  %150 = load i8, i8* %149, align 8
  %151 = sext i8 %150 to i32
  %152 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 22
  store i32 %151, i32* %152, align 8
  %153 = getelementptr inbounds i8, i8* %2, i64 33
  %154 = load i8, i8* %153, align 1
  %155 = sext i8 %154 to i32
  %156 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 23
  store i32 %155, i32* %156, align 4
  %157 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 16
  store i32 %11, i32* %157, align 8
  %158 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 17
  store i32 %13, i32* %158, align 4
  %159 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 25
  store i8 2, i8* %159, align 1
  %160 = mul nsw i32 %41, %15
  %161 = sext i32 %160 to i64
  %162 = getelementptr inbounds i8, i8* %9, i64 %161
  %163 = sext i32 %39 to i64
  %164 = getelementptr inbounds i8, i8* %162, i64 %163
  %165 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 7
  store i8* %164, i8** %165, align 8
  %166 = icmp eq i32 %13, 1
  br i1 %166, label %167, label %168

167:                                              ; preds = %148
  call void @_ZN3ruy25Kernel8bitAvx512SingleColERKNS_16KernelParams8bitILi16ELi16EEE(%"struct.ruy::KernelParams8bit"* nonnull dereferenceable(1352) %7) #19
  br label %169

168:                                              ; preds = %148
  call void @_ZN3ruy16Kernel8bitAvx512ERKNS_16KernelParams8bitILi16ELi16EEE(%"struct.ruy::KernelParams8bit"* nonnull dereferenceable(1352) %7) #19
  br label %169

169:                                              ; preds = %167, %168
  call void @llvm.lifetime.end.p0i8(i64 1352, i8* nonnull %46) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEaaEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii(i32, %"struct.ruy::EMat"* dereferenceable(40), %"struct.ruy::PEMat"*, i32, i32) #1 comdat {
  %6 = alloca %"struct.ruy::Mat.438", align 8
  %7 = alloca %"struct.ruy::PMat.164", align 8
  %8 = bitcast %"struct.ruy::Mat.438"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %8) #19
  %9 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %6, i64 0, i32 2
  %10 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %6, i64 0, i32 3
  %11 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %6, i64 0, i32 1
  %12 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 2
  %13 = bitcast i8** %12 to i64*
  %14 = bitcast %"struct.ruy::Mat.438"* %6 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %14, i8 -86, i64 32, i1 false)
  %15 = load i64, i64* %13, align 8, !noalias !1166
  %16 = bitcast %"struct.ruy::Mat.438"* %6 to i64*
  store i64 %15, i64* %16, align 8, !alias.scope !1166
  %17 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3
  %18 = bitcast %"struct.ruy::MatLayout"* %11 to i8*
  %19 = bitcast %"struct.ruy::MatLayout"* %17 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %18, i8* align 4 %19, i64 13, i1 false) #19
  %20 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 4
  %21 = load i32, i32* %20, align 8, !noalias !1166
  %22 = trunc i32 %21 to i8
  store i8 %22, i8* %9, align 8, !alias.scope !1166
  %23 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 5
  %24 = load i8, i8* %23, align 4, !noalias !1166
  store i8 %24, i8* %10, align 1, !alias.scope !1166
  %25 = bitcast %"struct.ruy::PMat.164"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %25) #19
  %26 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %7, i64 0, i32 3
  %27 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 2
  %28 = bitcast i8** %27 to i64*
  %29 = bitcast %"struct.ruy::PMat.164"* %7 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %29, i8 -86, i64 40, i1 false)
  %30 = load i64, i64* %28, align 8, !noalias !1169
  %31 = bitcast %"struct.ruy::PMat.164"* %7 to i64*
  store i64 %30, i64* %31, align 8, !alias.scope !1169
  %32 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 5
  %33 = bitcast i8** %32 to i64*
  %34 = load i64, i64* %33, align 8, !noalias !1169
  %35 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %7, i64 0, i32 1
  %36 = bitcast i32** %35 to i64*
  store i64 %34, i64* %36, align 8, !alias.scope !1169
  %37 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 6
  %38 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %7, i64 0, i32 2
  %39 = bitcast %"struct.ruy::PMatLayout"* %38 to i8*
  %40 = bitcast %"struct.ruy::PMatLayout"* %37 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %39, i8* align 4 %40, i64 16, i1 false) #19
  %41 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 7
  %42 = load i32, i32* %41, align 8, !noalias !1169
  store i32 %42, i32* %26, align 8, !alias.scope !1169
  call void @_ZN3ruy8PackImplILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEaaiE3RunENS_6TuningERKNS_3MatIaEEPNS_4PMatIaEEii(i32 %0, %"struct.ruy::Mat.438"* nonnull dereferenceable(32) %6, %"struct.ruy::PMat.164"* nonnull %7, i32 %3, i32 %4)
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %25) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %8) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy9RunKernelILNS_4PathE2EaaaNS_9MulParamsIiaEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE(i32, %"class.ruy::SidePair.104"* dereferenceable(112), i8*, %"class.ruy::SidePair.105"* dereferenceable(8), %"class.ruy::SidePair.105"* dereferenceable(8), %"struct.ruy::EMat"*) #1 comdat {
  %7 = alloca %"struct.ruy::Kernel.439", align 1
  %8 = alloca %"struct.ruy::Mat.438", align 8
  %9 = alloca %"struct.ruy::PMat.164", align 8
  %10 = alloca %"struct.ruy::PMat.164", align 8
  %11 = bitcast %"struct.ruy::Mat.438"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %11) #19
  %12 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %8, i64 0, i32 2
  %13 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %8, i64 0, i32 3
  %14 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %8, i64 0, i32 1
  %15 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 2
  %16 = bitcast i8** %15 to i64*
  %17 = bitcast %"struct.ruy::Mat.438"* %8 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %17, i8 -86, i64 32, i1 false)
  %18 = load i64, i64* %16, align 8, !noalias !1172
  %19 = bitcast %"struct.ruy::Mat.438"* %8 to i64*
  store i64 %18, i64* %19, align 8, !alias.scope !1172
  %20 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3
  %21 = bitcast %"struct.ruy::MatLayout"* %14 to i8*
  %22 = bitcast %"struct.ruy::MatLayout"* %20 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %21, i8* align 4 %22, i64 13, i1 false) #19
  %23 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 4
  %24 = load i32, i32* %23, align 8, !noalias !1172
  %25 = trunc i32 %24 to i8
  store i8 %25, i8* %12, align 8, !alias.scope !1172
  %26 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 5
  %27 = load i8, i8* %26, align 4, !noalias !1172
  store i8 %27, i8* %13, align 1, !alias.scope !1172
  %28 = bitcast %"struct.ruy::PMat.164"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %28) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %28, i8 -86, i64 40, i1 false) #19, !alias.scope !1175
  %29 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %9, i64 0, i32 3
  %30 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 2
  %31 = bitcast i8** %30 to i64*
  %32 = load i64, i64* %31, align 8, !noalias !1175
  %33 = bitcast %"struct.ruy::PMat.164"* %9 to i64*
  store i64 %32, i64* %33, align 8, !alias.scope !1175
  %34 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 5
  %35 = bitcast i8** %34 to i64*
  %36 = load i64, i64* %35, align 8, !noalias !1175
  %37 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %9, i64 0, i32 1
  %38 = bitcast i32** %37 to i64*
  store i64 %36, i64* %38, align 8, !alias.scope !1175
  %39 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 6
  %40 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %9, i64 0, i32 2
  %41 = bitcast %"struct.ruy::PMatLayout"* %40 to i8*
  %42 = bitcast %"struct.ruy::PMatLayout"* %39 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %41, i8* align 4 %42, i64 16, i1 false) #19
  %43 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 7
  %44 = load i32, i32* %43, align 8, !noalias !1175
  store i32 %44, i32* %29, align 8, !alias.scope !1175
  %45 = bitcast %"struct.ruy::PMat.164"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %45) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %45, i8 -86, i64 40, i1 false) #19, !alias.scope !1178
  %46 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %10, i64 0, i32 3
  %47 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 2
  %48 = bitcast i8** %47 to i64*
  %49 = load i64, i64* %48, align 8, !noalias !1178
  %50 = bitcast %"struct.ruy::PMat.164"* %10 to i64*
  store i64 %49, i64* %50, align 8, !alias.scope !1178
  %51 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 5
  %52 = bitcast i8** %51 to i64*
  %53 = load i64, i64* %52, align 8, !noalias !1178
  %54 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %10, i64 0, i32 1
  %55 = bitcast i32** %54 to i64*
  store i64 %53, i64* %55, align 8, !alias.scope !1178
  %56 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 6
  %57 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %10, i64 0, i32 2
  %58 = bitcast %"struct.ruy::PMatLayout"* %57 to i8*
  %59 = bitcast %"struct.ruy::PMatLayout"* %56 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %58, i8* align 4 %59, i64 16, i1 false) #19
  %60 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 7
  %61 = load i32, i32* %60, align 8, !noalias !1178
  store i32 %61, i32* %46, align 8, !alias.scope !1178
  %62 = bitcast i8* %2 to %"class.ruy::MulParams.436"*
  %63 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %3, i64 0, i32 0, i64 0
  %64 = load i32, i32* %63, align 4
  %65 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %3, i64 0, i32 0, i64 1
  %66 = load i32, i32* %65, align 4
  %67 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %4, i64 0, i32 0, i64 0
  %68 = load i32, i32* %67, align 4
  %69 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %4, i64 0, i32 0, i64 1
  %70 = load i32, i32* %69, align 4
  %71 = getelementptr inbounds %"struct.ruy::Kernel.439", %"struct.ruy::Kernel.439"* %7, i64 0, i32 0
  call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %71) #19
  store i8 -86, i8* %71, align 1
  call void @_ZNK3ruy6KernelILNS_4PathE2EaaaNS_9MulParamsIiaEEE3RunERKNS_4PMatIaEES8_RKS3_iiiiPNS_3MatIaEE(%"struct.ruy::Kernel.439"* nonnull %7, %"struct.ruy::PMat.164"* nonnull dereferenceable(40) %9, %"struct.ruy::PMat.164"* nonnull dereferenceable(40) %10, %"class.ruy::MulParams.436"* dereferenceable(40) %62, i32 %64, i32 %66, i32 %68, i32 %70, %"struct.ruy::Mat.438"* nonnull %8) #19
  call void @llvm.lifetime.end.p0i8(i64 1, i8* nonnull %71) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %45) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %28) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %11) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy8PackImplILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEaaiE3RunENS_6TuningERKNS_3MatIaEEPNS_4PMatIaEEii(i32, %"struct.ruy::Mat.438"* dereferenceable(32), %"struct.ruy::PMat.164"*, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %6 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %2, i64 0, i32 1
  %7 = load i32*, i32** %6, align 8
  %8 = icmp slt i32 %3, %4
  br i1 %8, label %9, label %33

9:                                                ; preds = %5
  %10 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %2, i64 0, i32 2, i32 0
  %11 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %1, i64 0, i32 1, i32 1
  %12 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %1, i64 0, i32 1, i32 0
  %13 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %2, i64 0, i32 3
  %14 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %1, i64 0, i32 0, i32 0
  %15 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %1, i64 0, i32 1, i32 3
  %16 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %1, i64 0, i32 1, i32 2
  %17 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %2, i64 0, i32 0
  %18 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %2, i64 0, i32 2, i32 4, i32 1
  %19 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %2, i64 0, i32 2, i32 4, i32 2
  %20 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %2, i64 0, i32 2, i32 3
  %21 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %2, i64 0, i32 2, i32 2
  %22 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %2, i64 0, i32 2, i32 4, i32 0
  %23 = icmp eq i32* %7, null
  %24 = sext i32 %3 to i64
  %25 = sext i32 %4 to i64
  br label %26

26:                                               ; preds = %107, %9
  %27 = phi i64 [ %24, %9 ], [ %108, %107 ]
  %28 = load i32, i32* %10, align 8
  %29 = icmp sgt i32 %28, 0
  br i1 %29, label %30, label %34

30:                                               ; preds = %26
  %31 = trunc i64 %27 to i32
  %32 = trunc i64 %27 to i32
  br label %36

33:                                               ; preds = %107, %5
  ret void

34:                                               ; preds = %64, %26
  %35 = phi i32 [ 0, %26 ], [ %68, %64 ]
  br i1 %23, label %107, label %105

36:                                               ; preds = %30, %64
  %37 = phi i32 [ %102, %64 ], [ 0, %30 ]
  %38 = phi i32 [ %68, %64 ], [ 0, %30 ]
  %39 = load i32, i32* %11, align 4
  %40 = sext i32 %39 to i64
  %41 = icmp slt i64 %27, %40
  br i1 %41, label %42, label %61

42:                                               ; preds = %36
  %43 = load i32, i32* %12, align 8
  %44 = icmp slt i32 %37, %43
  br i1 %44, label %45, label %61

45:                                               ; preds = %42
  %46 = load i8*, i8** %14, align 8
  %47 = load i8, i8* %15, align 4
  %48 = load i32, i32* %16, align 4
  switch i8 %47, label %49 [
    i8 0, label %50
    i8 1, label %52
  ]

49:                                               ; preds = %45
  br label %50

50:                                               ; preds = %49, %45
  %51 = phi i32 [ 1, %45 ], [ %48, %49 ]
  br label %52

52:                                               ; preds = %45, %50
  %53 = phi i32 [ %51, %50 ], [ %48, %45 ]
  %54 = phi i32 [ %48, %50 ], [ 1, %45 ]
  %55 = mul nsw i32 %53, %37
  %56 = mul nsw i32 %54, %32
  %57 = add nsw i32 %56, %55
  %58 = sext i32 %57 to i64
  %59 = getelementptr inbounds i8, i8* %46, i64 %58
  %60 = load i8, i8* %59, align 1
  br label %64

61:                                               ; preds = %42, %36
  %62 = load i32, i32* %13, align 8
  %63 = trunc i32 %62 to i8
  br label %64

64:                                               ; preds = %61, %52
  %65 = phi i32 [ %31, %61 ], [ %32, %52 ]
  %66 = phi i8 [ %63, %61 ], [ %60, %52 ]
  %67 = sext i8 %66 to i32
  %68 = add nsw i32 %38, %67
  %69 = load i8*, i8** %17, align 8
  %70 = load i8, i8* %18, align 1
  %71 = zext i8 %70 to i32
  %72 = sub nsw i32 0, %71
  %73 = and i32 %37, %72
  %74 = load i8, i8* %19, align 1
  %75 = zext i8 %74 to i32
  %76 = sub nsw i32 0, %75
  %77 = and i32 %65, %76
  %78 = load i8, i8* %20, align 4
  %79 = icmp eq i8 %78, 0
  %80 = load i32, i32* %21, align 4
  %81 = select i1 %79, i32 %75, i32 %80
  %82 = icmp eq i8 %78, 1
  %83 = select i1 %82, i32 %71, i32 %80
  %84 = mul nsw i32 %81, %73
  %85 = mul nsw i32 %83, %77
  %86 = sub nsw i32 %37, %73
  %87 = sub nsw i32 %65, %77
  %88 = load i8, i8* %22, align 1
  %89 = icmp eq i8 %88, 0
  %90 = select i1 %89, i8 1, i8 %74
  %91 = zext i8 %90 to i32
  %92 = icmp eq i8 %88, 1
  %93 = select i1 %92, i8 1, i8 %70
  %94 = zext i8 %93 to i32
  %95 = mul nsw i32 %86, %91
  %96 = mul nsw i32 %87, %94
  %97 = add i32 %84, %85
  %98 = add i32 %97, %96
  %99 = add i32 %98, %95
  %100 = sext i32 %99 to i64
  %101 = getelementptr inbounds i8, i8* %69, i64 %100
  store i8 %66, i8* %101, align 1
  %102 = add nuw nsw i32 %37, 1
  %103 = load i32, i32* %10, align 8
  %104 = icmp slt i32 %102, %103
  br i1 %104, label %36, label %34

105:                                              ; preds = %34
  %106 = getelementptr inbounds i32, i32* %7, i64 %27
  store i32 %35, i32* %106, align 4
  br label %107

107:                                              ; preds = %34, %105
  %108 = add nsw i64 %27, 1
  %109 = icmp eq i64 %108, %25
  br i1 %109, label %33, label %26
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK3ruy6KernelILNS_4PathE2EaaaNS_9MulParamsIiaEEE3RunERKNS_4PMatIaEES8_RKS3_iiiiPNS_3MatIaEE(%"struct.ruy::Kernel.439"*, %"struct.ruy::PMat.164"* dereferenceable(40), %"struct.ruy::PMat.164"* dereferenceable(40), %"class.ruy::MulParams.436"* dereferenceable(40), i32, i32, i32, i32, %"struct.ruy::Mat.438"*) local_unnamed_addr #1 comdat align 2 {
  %10 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %8, i64 0, i32 1, i32 0
  %11 = load i32, i32* %10, align 4
  %12 = icmp slt i32 %11, %6
  %13 = select i1 %12, i32 %11, i32 %6
  %14 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %8, i64 0, i32 1, i32 1
  %15 = load i32, i32* %14, align 4
  %16 = icmp slt i32 %15, %7
  %17 = select i1 %16, i32 %15, i32 %7
  %18 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %1, i64 0, i32 2, i32 0
  %19 = load i32, i32* %18, align 8
  %20 = icmp sgt i32 %13, %4
  br i1 %20, label %21, label %60

21:                                               ; preds = %9
  %22 = icmp sgt i32 %17, %5
  %23 = icmp sgt i32 %19, 0
  %24 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %1, i64 0, i32 0
  %25 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %1, i64 0, i32 2, i32 4, i32 1
  %26 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %1, i64 0, i32 2, i32 4, i32 2
  %27 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %1, i64 0, i32 2, i32 3
  %28 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %1, i64 0, i32 2, i32 2
  %29 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %1, i64 0, i32 2, i32 4, i32 0
  %30 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %2, i64 0, i32 0
  %31 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %2, i64 0, i32 2, i32 4, i32 1
  %32 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %2, i64 0, i32 2, i32 4, i32 2
  %33 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %2, i64 0, i32 2, i32 3
  %34 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %2, i64 0, i32 2, i32 2
  %35 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %2, i64 0, i32 2, i32 4, i32 0
  %36 = getelementptr inbounds %"class.ruy::MulParams.436", %"class.ruy::MulParams.436"* %3, i64 0, i32 0
  %37 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %1, i64 0, i32 3
  %38 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %2, i64 0, i32 1
  %39 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %2, i64 0, i32 3
  %40 = getelementptr inbounds %"struct.ruy::PMat.164", %"struct.ruy::PMat.164"* %1, i64 0, i32 1
  %41 = getelementptr inbounds %"class.ruy::MulParams.436", %"class.ruy::MulParams.436"* %3, i64 0, i32 3
  %42 = getelementptr inbounds %"class.ruy::MulParams.436", %"class.ruy::MulParams.436"* %3, i64 0, i32 1
  %43 = getelementptr inbounds %"class.ruy::MulParams.436", %"class.ruy::MulParams.436"* %3, i64 0, i32 4
  %44 = getelementptr inbounds %"class.ruy::MulParams.436", %"class.ruy::MulParams.436"* %3, i64 0, i32 2
  %45 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %8, i64 0, i32 2
  %46 = getelementptr inbounds %"class.ruy::MulParams.436", %"class.ruy::MulParams.436"* %3, i64 0, i32 6
  %47 = getelementptr inbounds %"class.ruy::MulParams.436", %"class.ruy::MulParams.436"* %3, i64 0, i32 5
  %48 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %8, i64 0, i32 0, i32 0
  %49 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %8, i64 0, i32 1, i32 3
  %50 = getelementptr inbounds %"struct.ruy::Mat.438", %"struct.ruy::Mat.438"* %8, i64 0, i32 1, i32 2
  %51 = sext i32 %5 to i64
  %52 = sext i32 %17 to i64
  %53 = sext i32 %4 to i64
  %54 = sext i32 %13 to i64
  br label %55

55:                                               ; preds = %21, %113
  %56 = phi i64 [ %53, %21 ], [ %114, %113 ]
  br i1 %22, label %57, label %113

57:                                               ; preds = %55
  %58 = trunc i64 %56 to i32
  %59 = trunc i64 %56 to i32
  br label %61

60:                                               ; preds = %113, %9
  ret void

61:                                               ; preds = %57, %209
  %62 = phi i64 [ %51, %57 ], [ %218, %209 ]
  br i1 %23, label %63, label %116

63:                                               ; preds = %61
  %64 = load i8*, i8** %24, align 8
  %65 = load i8, i8* %25, align 1
  %66 = zext i8 %65 to i32
  %67 = sub nsw i32 0, %66
  %68 = load i8, i8* %26, align 1
  %69 = zext i8 %68 to i32
  %70 = sub nsw i32 0, %69
  %71 = and i32 %58, %70
  %72 = load i8, i8* %27, align 4
  %73 = icmp eq i8 %72, 0
  %74 = load i32, i32* %28, align 4
  %75 = select i1 %73, i32 %69, i32 %74
  %76 = icmp eq i8 %72, 1
  %77 = select i1 %76, i32 %66, i32 %74
  %78 = mul nsw i32 %77, %71
  %79 = sub nsw i32 %58, %71
  %80 = load i8, i8* %29, align 1
  %81 = icmp eq i8 %80, 0
  %82 = select i1 %81, i8 1, i8 %68
  %83 = zext i8 %82 to i32
  %84 = icmp eq i8 %80, 1
  %85 = select i1 %84, i8 1, i8 %65
  %86 = zext i8 %85 to i32
  %87 = mul nsw i32 %79, %86
  %88 = load i8*, i8** %30, align 8
  %89 = load i8, i8* %31, align 1
  %90 = zext i8 %89 to i32
  %91 = sub nsw i32 0, %90
  %92 = load i8, i8* %32, align 1
  %93 = zext i8 %92 to i32
  %94 = sub nsw i32 0, %93
  %95 = trunc i64 %62 to i32
  %96 = and i32 %95, %94
  %97 = load i8, i8* %33, align 4
  %98 = icmp eq i8 %97, 0
  %99 = load i32, i32* %34, align 4
  %100 = select i1 %98, i32 %93, i32 %99
  %101 = icmp eq i8 %97, 1
  %102 = select i1 %101, i32 %90, i32 %99
  %103 = mul nsw i32 %102, %96
  %104 = sub nsw i32 %95, %96
  %105 = load i8, i8* %35, align 1
  %106 = icmp eq i8 %105, 0
  %107 = select i1 %106, i8 1, i8 %92
  %108 = zext i8 %107 to i32
  %109 = icmp eq i8 %105, 1
  %110 = select i1 %109, i8 1, i8 %89
  %111 = zext i8 %110 to i32
  %112 = mul nsw i32 %104, %111
  br label %120

113:                                              ; preds = %209, %55
  %114 = add nsw i64 %56, 1
  %115 = icmp slt i64 %114, %54
  br i1 %115, label %55, label %60

116:                                              ; preds = %120, %61
  %117 = phi i32 [ 0, %61 ], [ %146, %120 ]
  %118 = load i32*, i32** %36, align 8
  %119 = icmp eq i32* %118, null
  br i1 %119, label %153, label %149

120:                                              ; preds = %120, %63
  %121 = phi i32 [ 0, %63 ], [ %147, %120 ]
  %122 = phi i32 [ 0, %63 ], [ %146, %120 ]
  %123 = and i32 %121, %67
  %124 = mul nsw i32 %75, %123
  %125 = sub nsw i32 %121, %123
  %126 = mul nsw i32 %125, %83
  %127 = add i32 %124, %78
  %128 = add i32 %127, %87
  %129 = add i32 %128, %126
  %130 = sext i32 %129 to i64
  %131 = getelementptr inbounds i8, i8* %64, i64 %130
  %132 = load i8, i8* %131, align 1
  %133 = sext i8 %132 to i32
  %134 = and i32 %121, %91
  %135 = mul nsw i32 %100, %134
  %136 = sub nsw i32 %121, %134
  %137 = mul nsw i32 %136, %108
  %138 = add i32 %135, %103
  %139 = add i32 %138, %112
  %140 = add i32 %139, %137
  %141 = sext i32 %140 to i64
  %142 = getelementptr inbounds i8, i8* %88, i64 %141
  %143 = load i8, i8* %142, align 1
  %144 = sext i8 %143 to i32
  %145 = mul nsw i32 %144, %133
  %146 = add nsw i32 %145, %122
  %147 = add nuw nsw i32 %121, 1
  %148 = icmp eq i32 %147, %19
  br i1 %148, label %116, label %120

149:                                              ; preds = %116
  %150 = getelementptr inbounds i32, i32* %118, i64 %56
  %151 = load i32, i32* %150, align 4
  %152 = add nsw i32 %151, %117
  br label %153

153:                                              ; preds = %116, %149
  %154 = phi i32 [ %117, %116 ], [ %152, %149 ]
  %155 = load i32, i32* %37, align 8
  %156 = icmp eq i32 %155, 0
  br i1 %156, label %163, label %157

157:                                              ; preds = %153
  %158 = load i32*, i32** %38, align 8
  %159 = getelementptr inbounds i32, i32* %158, i64 %62
  %160 = load i32, i32* %159, align 4
  %161 = mul nsw i32 %160, %155
  %162 = sub nsw i32 %154, %161
  br label %163

163:                                              ; preds = %153, %157
  %164 = phi i32 [ %154, %153 ], [ %162, %157 ]
  %165 = load i32, i32* %39, align 8
  %166 = icmp eq i32 %165, 0
  br i1 %166, label %178, label %167

167:                                              ; preds = %163
  %168 = load i32*, i32** %40, align 8
  %169 = getelementptr inbounds i32, i32* %168, i64 %56
  %170 = load i32, i32* %169, align 4
  %171 = mul nsw i32 %170, %165
  %172 = sub nsw i32 %164, %171
  %173 = or i1 %156, %166
  br i1 %173, label %178, label %174

174:                                              ; preds = %167
  %175 = mul i32 %155, %19
  %176 = mul i32 %175, %165
  %177 = add nsw i32 %172, %176
  br label %178

178:                                              ; preds = %163, %167, %174
  %179 = phi i32 [ %172, %167 ], [ %177, %174 ], [ %164, %163 ]
  %180 = load i32*, i32** %41, align 8
  %181 = icmp eq i32* %180, null
  %182 = getelementptr inbounds i32, i32* %180, i64 %56
  %183 = select i1 %181, i32* %42, i32* %182
  %184 = load i32, i32* %183, align 4
  %185 = load i32*, i32** %43, align 8
  %186 = icmp eq i32* %185, null
  %187 = getelementptr inbounds i32, i32* %185, i64 %56
  %188 = select i1 %186, i32* %44, i32* %187
  %189 = load i32, i32* %188, align 4
  %190 = tail call i32 @_ZN3ruy6detail29MultiplyByQuantizedMultiplierEiii(i32 %179, i32 %184, i32 %189) #19
  %191 = load i8, i8* %45, align 8
  %192 = sext i8 %191 to i32
  %193 = add nsw i32 %190, %192
  %194 = load i8, i8* %46, align 1
  %195 = sext i8 %194 to i32
  %196 = icmp sgt i32 %193, %195
  %197 = select i1 %196, i32 %195, i32 %193
  %198 = load i8, i8* %47, align 8
  %199 = sext i8 %198 to i32
  %200 = icmp slt i32 %197, %199
  %201 = select i1 %200, i32 %199, i32 %197
  %202 = trunc i32 %201 to i8
  %203 = load i8*, i8** %48, align 8
  %204 = load i8, i8* %49, align 4
  %205 = load i32, i32* %50, align 4
  switch i8 %204, label %206 [
    i8 0, label %207
    i8 1, label %209
  ]

206:                                              ; preds = %178
  br label %207

207:                                              ; preds = %206, %178
  %208 = phi i32 [ 1, %178 ], [ %205, %206 ]
  br label %209

209:                                              ; preds = %178, %207
  %210 = phi i32 [ %208, %207 ], [ %205, %178 ]
  %211 = phi i32 [ %205, %207 ], [ 1, %178 ]
  %212 = mul nsw i32 %210, %59
  %213 = trunc i64 %62 to i32
  %214 = mul nsw i32 %211, %213
  %215 = add nsw i32 %214, %212
  %216 = sext i32 %215 to i64
  %217 = getelementptr inbounds i8, i8* %203, i64 %216
  store i8 %202, i8* %217, align 1
  %218 = add nsw i64 %62, 1
  %219 = icmp slt i64 %218, %52
  br i1 %219, label %61, label %113
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy27PathSearchOnlyCompiledPathsILNS_4PathE26ELb1ELi3EaaaNS_9MulParamsIiaEEE6SearchES1_PNS_11TrMulParamsE(i8 zeroext, %"struct.ruy::TrMulParams"*) local_unnamed_addr #1 comdat align 2 {
  switch i8 %0, label %57 [
    i8 8, label %3
    i8 2, label %4
  ]

3:                                                ; preds = %2
  tail call void @_ZN3ruy19PopulateTrMulParamsILNS_4PathE8EaaaNS_9MulParamsIiaEEEEvPNS_11TrMulParamsE(%"struct.ruy::TrMulParams"* %1)
  br label %57

4:                                                ; preds = %2
  %5 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 0
  store i8 2, i8* %5, align 8
  %6 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 0
  %7 = bitcast %"struct.ruy::PEMat"* %6 to i24*
  store i24 65537, i24* %7, align 8
  %8 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 0, i32 3
  %9 = bitcast %"struct.ruy::Type"* %8 to i24*
  store i24 262145, i24* %9, align 8
  %10 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 0, i32 6, i32 3
  store i8 0, i8* %10, align 4
  %11 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 3, i32 0, i64 0, i32 3, i32 0
  %12 = load i32, i32* %11, align 4
  %13 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 0, i32 6, i32 0
  store i32 %12, i32* %13, align 4
  %14 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 3, i32 0, i64 0, i32 3, i32 1
  %15 = load i32, i32* %14, align 4
  %16 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 0, i32 6, i32 1
  store i32 %15, i32* %16, align 4
  %17 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 0
  store i8 0, i8* %17, align 1
  %18 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 1
  store i8 1, i8* %18, align 1
  %19 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 2
  store i8 1, i8* %19, align 1
  %20 = and i32 %12, 1023
  %21 = icmp eq i32 %20, 0
  %22 = add nsw i32 %12, 64
  %23 = select i1 %21, i32 %22, i32 %12
  %24 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 0, i32 6, i32 2
  store i32 %23, i32* %24, align 4
  %25 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 3, i32 0, i64 0, i32 4
  %26 = load i32, i32* %25, align 8
  %27 = shl i32 %26, 24
  %28 = ashr exact i32 %27, 24
  %29 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 0, i32 7
  store i32 %28, i32* %29, align 8
  %30 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 1
  %31 = bitcast %"struct.ruy::PEMat"* %30 to i24*
  store i24 65537, i24* %31, align 8
  %32 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 1, i32 3
  %33 = bitcast %"struct.ruy::Type"* %32 to i24*
  store i24 262145, i24* %33, align 8
  %34 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 1, i32 6, i32 3
  store i8 0, i8* %34, align 4
  %35 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 3, i32 0, i64 1, i32 3, i32 0
  %36 = load i32, i32* %35, align 4
  %37 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 1, i32 6, i32 0
  store i32 %36, i32* %37, align 4
  %38 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 3, i32 0, i64 1, i32 3, i32 1
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 1, i32 6, i32 1
  store i32 %39, i32* %40, align 4
  %41 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 0
  store i8 0, i8* %41, align 1
  %42 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 1
  store i8 1, i8* %42, align 1
  %43 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 2
  store i8 1, i8* %43, align 1
  %44 = and i32 %36, 1023
  %45 = icmp eq i32 %44, 0
  %46 = add nsw i32 %36, 64
  %47 = select i1 %45, i32 %46, i32 %36
  %48 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 1, i32 6, i32 2
  store i32 %47, i32* %48, align 4
  %49 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 3, i32 0, i64 1, i32 4
  %50 = load i32, i32* %49, align 8
  %51 = shl i32 %50, 24
  %52 = ashr exact i32 %51, 24
  %53 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 5, i32 0, i64 1, i32 7
  store i32 %52, i32* %53, align 8
  %54 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 1, i32 0, i64 0
  %55 = bitcast void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)** %54 to <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*>*
  store <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*> <void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* @_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEaaEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii, void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* @_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEaaEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii>, <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*>* %55, align 8
  %56 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %1, i64 0, i32 2
  store void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)* @_ZN3ruy9RunKernelILNS_4PathE2EaaaNS_9MulParamsIiaEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE, void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)** %56, align 8
  br label %57

57:                                               ; preds = %2, %4, %3
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy19PopulateTrMulParamsILNS_4PathE8EaaaNS_9MulParamsIiaEEEEvPNS_11TrMulParamsE(%"struct.ruy::TrMulParams"*) local_unnamed_addr #1 comdat {
  %2 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 3
  %3 = load i8, i8* %2, align 4
  %4 = icmp eq i8 %3, 0
  br i1 %4, label %5, label %13

5:                                                ; preds = %1
  %6 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 3
  %7 = load i8, i8* %6, align 4
  %8 = icmp eq i8 %7, 0
  br i1 %8, label %9, label %13

9:                                                ; preds = %5
  %10 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 4, i32 3, i32 3
  %11 = load i8, i8* %10, align 4
  %12 = icmp eq i8 %11, 0
  br i1 %12, label %54, label %13

13:                                               ; preds = %1, %5, %9
  %14 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 0
  store i8 2, i8* %14, align 8
  %15 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0
  %16 = bitcast %"struct.ruy::PEMat"* %15 to i24*
  store i24 65537, i24* %16, align 8
  %17 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 3
  %18 = bitcast %"struct.ruy::Type"* %17 to i24*
  store i24 262145, i24* %18, align 8
  %19 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 3
  store i8 0, i8* %19, align 4
  %20 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 0
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 0
  store i32 %21, i32* %22, align 4
  %23 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 1
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 1
  store i32 %24, i32* %25, align 4
  %26 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 0
  store i8 0, i8* %26, align 1
  %27 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 1
  store i8 1, i8* %27, align 1
  %28 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 2
  store i8 1, i8* %28, align 1
  %29 = and i32 %21, 1023
  %30 = icmp eq i32 %29, 0
  %31 = add nsw i32 %21, 64
  %32 = select i1 %30, i32 %31, i32 %21
  %33 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 2
  store i32 %32, i32* %33, align 4
  %34 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 4
  %35 = load i32, i32* %34, align 8
  %36 = shl i32 %35, 24
  %37 = ashr exact i32 %36, 24
  %38 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 7
  store i32 %37, i32* %38, align 8
  %39 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1
  %40 = bitcast %"struct.ruy::PEMat"* %39 to i24*
  store i24 65537, i24* %40, align 8
  %41 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 3
  %42 = bitcast %"struct.ruy::Type"* %41 to i24*
  store i24 262145, i24* %42, align 8
  %43 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 3
  store i8 0, i8* %43, align 4
  %44 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 0
  %45 = load i32, i32* %44, align 4
  %46 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 0
  store i32 %45, i32* %46, align 4
  %47 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 1
  %48 = load i32, i32* %47, align 4
  %49 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 1
  store i32 %48, i32* %49, align 4
  %50 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 0
  store i8 0, i8* %50, align 1
  %51 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 1
  store i8 1, i8* %51, align 1
  %52 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 2
  store i8 1, i8* %52, align 1
  %53 = and i32 %45, 1023
  br label %103

54:                                               ; preds = %9
  %55 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 0
  store i8 8, i8* %55, align 8
  %56 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0
  %57 = bitcast %"struct.ruy::PEMat"* %56 to i24*
  store i24 65537, i24* %57, align 8
  %58 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 3
  %59 = bitcast %"struct.ruy::Type"* %58 to i24*
  store i24 262145, i24* %59, align 8
  %60 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 3
  store i8 0, i8* %60, align 4
  %61 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 0
  %62 = load i32, i32* %61, align 4
  %63 = add i32 %62, 3
  %64 = and i32 %63, -4
  %65 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 0
  store i32 %64, i32* %65, align 4
  %66 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 1
  %67 = load i32, i32* %66, align 4
  %68 = add i32 %67, 7
  %69 = and i32 %68, -8
  %70 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 1
  store i32 %69, i32* %70, align 4
  %71 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 0
  store i8 0, i8* %71, align 1
  %72 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 1
  store i8 4, i8* %72, align 1
  %73 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 2
  store i8 8, i8* %73, align 1
  %74 = and i32 %63, 1020
  %75 = icmp eq i32 %74, 0
  %76 = add nsw i32 %64, 64
  %77 = select i1 %75, i32 %76, i32 %64
  %78 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 2
  store i32 %77, i32* %78, align 4
  %79 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 4
  %80 = load i32, i32* %79, align 8
  %81 = shl i32 %80, 24
  %82 = ashr exact i32 %81, 24
  %83 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 7
  store i32 %82, i32* %83, align 8
  %84 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1
  %85 = bitcast %"struct.ruy::PEMat"* %84 to i24*
  store i24 65537, i24* %85, align 8
  %86 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 3
  %87 = bitcast %"struct.ruy::Type"* %86 to i24*
  store i24 262145, i24* %87, align 8
  %88 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 3
  store i8 0, i8* %88, align 4
  %89 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 0
  %90 = load i32, i32* %89, align 4
  %91 = add i32 %90, 3
  %92 = and i32 %91, -4
  %93 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 0
  store i32 %92, i32* %93, align 4
  %94 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 1
  %95 = load i32, i32* %94, align 4
  %96 = add i32 %95, 7
  %97 = and i32 %96, -8
  %98 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 1
  store i32 %97, i32* %98, align 4
  %99 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 0
  store i8 0, i8* %99, align 1
  %100 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 1
  store i8 4, i8* %100, align 1
  %101 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 2
  store i8 8, i8* %101, align 1
  %102 = and i32 %91, 1020
  br label %103

103:                                              ; preds = %54, %13
  %104 = phi i32 [ %102, %54 ], [ %53, %13 ]
  %105 = phi i32 [ %92, %54 ], [ %45, %13 ]
  %106 = phi void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* [ @_ZN3ruy7RunPackILNS_4PathE8ENS_17FixedKernelLayoutILNS_5OrderE0ELi4ELi8EEEaaEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii, %54 ], [ @_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEaaEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii, %13 ]
  %107 = phi void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)* [ @_ZN3ruy9RunKernelILNS_4PathE8EaaaNS_9MulParamsIiaEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE, %54 ], [ @_ZN3ruy9RunKernelILNS_4PathE2EaaaNS_9MulParamsIiaEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE, %13 ]
  %108 = icmp eq i32 %104, 0
  %109 = add nsw i32 %105, 64
  %110 = select i1 %108, i32 %109, i32 %105
  %111 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 2
  store i32 %110, i32* %111, align 4
  %112 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 4
  %113 = load i32, i32* %112, align 8
  %114 = shl i32 %113, 24
  %115 = ashr exact i32 %114, 24
  %116 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 7
  store i32 %115, i32* %116, align 8
  %117 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 1, i32 0, i64 0
  store void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* %106, void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)** %117, align 8
  %118 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 1, i32 0, i64 1
  store void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* %106, void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)** %118, align 8
  %119 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 2
  store void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)* %107, void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)** %119, align 8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy7RunPackILNS_4PathE8ENS_17FixedKernelLayoutILNS_5OrderE0ELi4ELi8EEEaaEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii(i32, %"struct.ruy::EMat"* dereferenceable(40), %"struct.ruy::PEMat"*, i32, i32) #1 comdat {
  %6 = alloca [32 x i8], align 16
  %7 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 2
  %8 = load i8*, i8** %7, align 8, !noalias !1181
  %9 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3, i32 0
  %10 = load i32, i32* %9, align 4
  %11 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3, i32 1
  %12 = load i32, i32* %11, align 4
  %13 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %1, i64 0, i32 3, i32 2
  %14 = load i32, i32* %13, align 4
  %15 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 2
  %16 = load i8*, i8** %15, align 8, !noalias !1184
  %17 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 5
  %18 = bitcast i8** %17 to i32**
  %19 = load i32*, i32** %18, align 8, !noalias !1184
  %20 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 6, i32 2
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %"struct.ruy::PEMat", %"struct.ruy::PEMat"* %2, i64 0, i32 7
  %23 = load i32, i32* %22, align 8, !noalias !1184
  %24 = getelementptr inbounds [32 x i8], [32 x i8]* %6, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %24) #19
  %25 = trunc i32 %23 to i8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %24, i8 %25, i64 32, i1 false) #19
  %26 = icmp slt i32 %3, %4
  br i1 %26, label %27, label %46

27:                                               ; preds = %5
  %28 = icmp eq i32* %19, null
  %29 = sext i32 %3 to i64
  %30 = sext i32 %4 to i64
  %31 = sext i32 %14 to i64
  br label %32

32:                                               ; preds = %32, %27
  %33 = phi i64 [ %29, %27 ], [ %44, %32 ]
  %34 = getelementptr inbounds i32, i32* %19, i64 %33
  %35 = select i1 %28, i32* null, i32* %34
  %36 = mul nsw i64 %33, %31
  %37 = getelementptr inbounds i8, i8* %8, i64 %36
  %38 = trunc i64 %33 to i32
  %39 = sub nsw i32 %12, %38
  %40 = and i32 %38, -8
  %41 = mul nsw i32 %40, %21
  %42 = sext i32 %41 to i64
  %43 = getelementptr inbounds i8, i8* %16, i64 %42
  call void @_ZN3ruy12Pack8bitAvx2EPKaaS1_iiiPaPi(i8* %37, i8 signext 0, i8* nonnull %24, i32 %14, i32 %39, i32 %10, i8* %43, i32* %35) #19
  %44 = add nsw i64 %33, 8
  %45 = icmp slt i64 %44, %30
  br i1 %45, label %32, label %46

46:                                               ; preds = %32, %5
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %24) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy9RunKernelILNS_4PathE8EaaaNS_9MulParamsIiaEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE(i32, %"class.ruy::SidePair.104"* dereferenceable(112), i8*, %"class.ruy::SidePair.105"* dereferenceable(8), %"class.ruy::SidePair.105"* dereferenceable(8), %"struct.ruy::EMat"*) #1 comdat {
  %7 = alloca %"struct.ruy::KernelParams8bit.167", align 8
  %8 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 2
  %9 = load i8*, i8** %8, align 8, !noalias !1187
  %10 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 0
  %11 = load i32, i32* %10, align 4
  %12 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 1
  %13 = load i32, i32* %12, align 4
  %14 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 2
  %15 = load i32, i32* %14, align 4
  %16 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 4
  %17 = load i32, i32* %16, align 8, !noalias !1187
  %18 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 2
  %19 = load i8*, i8** %18, align 8, !noalias !1190
  %20 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 5
  %21 = bitcast i8** %20 to i32**
  %22 = load i32*, i32** %21, align 8, !noalias !1190
  %23 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 6, i32 0
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 6, i32 2
  %26 = load i32, i32* %25, align 4
  %27 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 7
  %28 = load i32, i32* %27, align 8, !noalias !1190
  %29 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 2
  %30 = load i8*, i8** %29, align 8, !noalias !1193
  %31 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 5
  %32 = bitcast i8** %31 to i32**
  %33 = load i32*, i32** %32, align 8, !noalias !1193
  %34 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 6, i32 2
  %35 = load i32, i32* %34, align 4
  %36 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 7
  %37 = load i32, i32* %36, align 8, !noalias !1193
  %38 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %3, i64 0, i32 0, i64 0
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %3, i64 0, i32 0, i64 1
  %41 = load i32, i32* %40, align 4
  %42 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %4, i64 0, i32 0, i64 0
  %43 = load i32, i32* %42, align 4
  %44 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %4, i64 0, i32 0, i64 1
  %45 = load i32, i32* %44, align 4
  %46 = bitcast %"struct.ruy::KernelParams8bit.167"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 488, i8* nonnull %46) #19
  %47 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 1
  %48 = bitcast i32** %47 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %48, i8 -86, i64 480, i1 false) #19
  %49 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 27, i64 0
  %50 = bitcast i32* %49 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 4 %50, i8 0, i64 32, i1 false) #19
  %51 = mul nsw i32 %39, %26
  %52 = sext i32 %51 to i64
  %53 = getelementptr inbounds i8, i8* %19, i64 %52
  %54 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 3
  store i8* %53, i8** %54, align 8
  %55 = mul nsw i32 %41, %35
  %56 = sext i32 %55 to i64
  %57 = getelementptr inbounds i8, i8* %30, i64 %56
  %58 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 6
  store i8* %57, i8** %58, align 8
  %59 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 24
  store i8 0, i8* %59, align 8
  %60 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 0
  store i32* %49, i32** %60, align 8
  %61 = bitcast i8* %2 to i32**
  %62 = load i32*, i32** %61, align 8
  %63 = icmp eq i32* %62, null
  br i1 %63, label %65, label %64

64:                                               ; preds = %6
  store i32* %62, i32** %60, align 8
  store i8 1, i8* %59, align 8
  br label %65

65:                                               ; preds = %64, %6
  %66 = phi i8 [ 0, %6 ], [ 1, %64 ]
  %67 = icmp eq i32* %22, null
  br i1 %67, label %71, label %68

68:                                               ; preds = %65
  %69 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 1
  store i32* %22, i32** %69, align 8
  %70 = or i8 %66, 2
  store i8 %70, i8* %59, align 8
  br label %71

71:                                               ; preds = %68, %65
  %72 = phi i8 [ %66, %65 ], [ %70, %68 ]
  %73 = icmp eq i32* %33, null
  br i1 %73, label %77, label %74

74:                                               ; preds = %71
  %75 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 2
  store i32* %33, i32** %75, align 8
  %76 = or i8 %72, 4
  store i8 %76, i8* %59, align 8
  br label %77

77:                                               ; preds = %74, %71
  %78 = phi i8 [ %72, %71 ], [ %76, %74 ]
  %79 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 12
  store i32 %39, i32* %79, align 8
  %80 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 13
  store i32 %41, i32* %80, align 4
  %81 = add nsw i32 %43, -8
  %82 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 14
  store i32 %81, i32* %82, align 8
  %83 = add nsw i32 %45, -8
  %84 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 15
  store i32 %83, i32* %84, align 4
  %85 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 18
  store i32 %26, i32* %85, align 8
  %86 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 19
  store i32 %35, i32* %86, align 4
  %87 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 20
  store i32 %15, i32* %87, align 8
  %88 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 8
  store i32 %28, i32* %88, align 8
  %89 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 9
  store i32 %37, i32* %89, align 4
  %90 = shl i32 %17, 24
  %91 = ashr exact i32 %90, 24
  %92 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 10
  store i32 %91, i32* %92, align 8
  %93 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 21
  store i32 %24, i32* %93, align 4
  %94 = mul i32 %28, %24
  %95 = mul i32 %94, %37
  %96 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 11
  store i32 %95, i32* %96, align 4
  %97 = getelementptr inbounds i8, i8* %2, i64 16
  %98 = bitcast i8* %97 to i32**
  %99 = load i32*, i32** %98, align 8
  %100 = icmp eq i32* %99, null
  br i1 %100, label %111, label %101

101:                                              ; preds = %77
  %102 = ptrtoint i32* %99 to i64
  %103 = or i8 %78, 24
  store i8 %103, i8* %59, align 8
  %104 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 4
  %105 = bitcast i32** %104 to i64*
  store i64 %102, i64* %105, align 8
  %106 = getelementptr inbounds i8, i8* %2, i64 24
  %107 = bitcast i8* %106 to i64*
  %108 = load i64, i64* %107, align 8
  %109 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 5
  %110 = bitcast i32** %109 to i64*
  store i64 %108, i64* %110, align 8
  br label %140

111:                                              ; preds = %77
  %112 = getelementptr inbounds i8, i8* %2, i64 12
  %113 = bitcast i8* %112 to i32*
  %114 = load i32, i32* %113, align 4
  %115 = icmp sgt i32 %114, 0
  br i1 %115, label %116, label %118

116:                                              ; preds = %111
  %117 = or i8 %78, 16
  store i8 %117, i8* %59, align 8
  br label %118

118:                                              ; preds = %116, %111
  %119 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 29, i64 0
  %120 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 4
  store i32* %119, i32** %120, align 8
  %121 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 30, i64 0
  %122 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 5
  store i32* %121, i32** %122, align 8
  %123 = getelementptr inbounds i8, i8* %2, i64 8
  %124 = bitcast i8* %123 to i32*
  %125 = load i32, i32* %124, align 8
  %126 = insertelement <4 x i32> undef, i32 %125, i32 0
  %127 = shufflevector <4 x i32> %126, <4 x i32> undef, <4 x i32> zeroinitializer
  %128 = bitcast i32* %119 to <4 x i32>*
  store <4 x i32> %127, <4 x i32>* %128, align 4
  %129 = insertelement <4 x i32> undef, i32 %114, i32 0
  %130 = shufflevector <4 x i32> %129, <4 x i32> undef, <4 x i32> zeroinitializer
  %131 = bitcast i32* %121 to <4 x i32>*
  store <4 x i32> %130, <4 x i32>* %131, align 4
  %132 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 29, i64 4
  store i32 %125, i32* %132, align 4
  %133 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 30, i64 4
  store i32 %114, i32* %133, align 4
  %134 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 29, i64 5
  store i32 %125, i32* %134, align 4
  %135 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 30, i64 5
  store i32 %114, i32* %135, align 4
  %136 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 29, i64 6
  store i32 %125, i32* %136, align 4
  %137 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 30, i64 6
  store i32 %114, i32* %137, align 4
  %138 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 29, i64 7
  store i32 %125, i32* %138, align 4
  %139 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 30, i64 7
  store i32 %114, i32* %139, align 4
  br label %140

140:                                              ; preds = %101, %118
  %141 = getelementptr inbounds i8, i8* %2, i64 32
  %142 = load i8, i8* %141, align 8
  %143 = sext i8 %142 to i32
  %144 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 22
  store i32 %143, i32* %144, align 8
  %145 = getelementptr inbounds i8, i8* %2, i64 33
  %146 = load i8, i8* %145, align 1
  %147 = sext i8 %146 to i32
  %148 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 23
  store i32 %147, i32* %148, align 4
  %149 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 16
  store i32 %11, i32* %149, align 8
  %150 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 17
  store i32 %13, i32* %150, align 4
  %151 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 25
  store i8 2, i8* %151, align 1
  %152 = mul nsw i32 %41, %15
  %153 = sext i32 %152 to i64
  %154 = getelementptr inbounds i8, i8* %9, i64 %153
  %155 = sext i32 %39 to i64
  %156 = getelementptr inbounds i8, i8* %154, i64 %155
  %157 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 7
  store i8* %156, i8** %157, align 8
  %158 = icmp eq i32 %13, 1
  br i1 %158, label %159, label %160

159:                                              ; preds = %140
  call void @_ZN3ruy23Kernel8bitAvx2SingleColERKNS_16KernelParams8bitILi8ELi8EEE(%"struct.ruy::KernelParams8bit.167"* nonnull dereferenceable(488) %7) #19
  br label %161

160:                                              ; preds = %140
  call void @_ZN3ruy14Kernel8bitAvx2ERKNS_16KernelParams8bitILi8ELi8EEE(%"struct.ruy::KernelParams8bit.167"* nonnull dereferenceable(488) %7) #19
  br label %161

161:                                              ; preds = %159, %160
  call void @llvm.lifetime.end.p0i8(i64 488, i8* nonnull %46) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp4TaskD2Ev(%"struct.gemmlowp::Task"*) unnamed_addr #1 comdat align 2 {
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN6tflite16cpu_backend_gemm6detail16GemmImplUsingRuyIhhisLNS0_18QuantizationFlavorE1EE3RunERKNS0_12MatrixParamsIhEEPKhS8_SA_RKNS5_IsEEPsRKNS0_10GemmParamsIisLS3_1EEEPNS_17CpuBackendContextE(%"struct.tflite::cpu_backend_gemm::MatrixParams.153"* dereferenceable(16), i8*, %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* dereferenceable(16), i8*, %"struct.tflite::cpu_backend_gemm::MatrixParams.454"* dereferenceable(16), i16*, %"struct.tflite::cpu_backend_gemm::GemmParams.456"* dereferenceable(40), %"class.tflite::CpuBackendContext"*) local_unnamed_addr #1 comdat align 2 {
  %9 = alloca %"struct.ruy::Mat.160", align 8
  %10 = alloca %"struct.ruy::Mat.160", align 8
  %11 = alloca %"struct.ruy::Mat.463", align 8
  %12 = alloca %"class.ruy::MulParams.461", align 8
  %13 = getelementptr inbounds %"class.tflite::CpuBackendContext", %"class.tflite::CpuBackendContext"* %7, i64 0, i32 4
  %14 = load i8, i8* %13, align 4, !range !10
  %15 = icmp ne i8 %14, 0
  %16 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %0, i64 0, i32 0
  %17 = load i32, i32* %16, align 4
  %18 = icmp ne i32 %17, 0
  %19 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %0, i64 0, i32 1
  %20 = load i32, i32* %19, align 4
  %21 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %0, i64 0, i32 2
  %22 = load i32, i32* %21, align 4
  %23 = select i1 %18, i32 %22, i32 %20
  %24 = ptrtoint i8* %1 to i64
  %25 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %0, i64 0, i32 3
  %26 = load i8, i8* %25, align 4
  br i1 %15, label %27, label %34

27:                                               ; preds = %8
  %28 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %0, i64 0, i32 4
  %29 = load i8, i8* %28, align 1
  %30 = icmp eq i8 %29, 1
  %31 = zext i1 %30 to i8
  %32 = icmp eq i8 %29, 2
  %33 = select i1 %32, i8 3, i8 %31
  br label %34

34:                                               ; preds = %8, %27
  %35 = phi i8 [ %33, %27 ], [ 0, %8 ]
  %36 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %2, i64 0, i32 0
  %37 = load i32, i32* %36, align 4
  %38 = icmp ne i32 %37, 0
  %39 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %2, i64 0, i32 1
  %40 = load i32, i32* %39, align 4
  %41 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %2, i64 0, i32 2
  %42 = load i32, i32* %41, align 4
  %43 = select i1 %38, i32 %42, i32 %40
  %44 = ptrtoint i8* %3 to i64
  %45 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %2, i64 0, i32 3
  %46 = load i8, i8* %45, align 4
  br i1 %15, label %47, label %54

47:                                               ; preds = %34
  %48 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %2, i64 0, i32 4
  %49 = load i8, i8* %48, align 1
  %50 = icmp eq i8 %49, 1
  %51 = zext i1 %50 to i8
  %52 = icmp eq i8 %49, 2
  %53 = select i1 %52, i8 3, i8 %51
  br label %54

54:                                               ; preds = %34, %47
  %55 = phi i8 [ %53, %47 ], [ 0, %34 ]
  %56 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.454", %"struct.tflite::cpu_backend_gemm::MatrixParams.454"* %4, i64 0, i32 0
  %57 = load i32, i32* %56, align 4
  %58 = icmp ne i32 %57, 0
  %59 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.454", %"struct.tflite::cpu_backend_gemm::MatrixParams.454"* %4, i64 0, i32 1
  %60 = load i32, i32* %59, align 4
  %61 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.454", %"struct.tflite::cpu_backend_gemm::MatrixParams.454"* %4, i64 0, i32 2
  %62 = load i32, i32* %61, align 4
  %63 = select i1 %58, i32 %62, i32 %60
  %64 = ptrtoint i16* %5 to i64
  %65 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.454", %"struct.tflite::cpu_backend_gemm::MatrixParams.454"* %4, i64 0, i32 3
  %66 = load i16, i16* %65, align 4
  %67 = bitcast %"class.ruy::MulParams.461"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %67) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %67, i8 -86, i64 40, i1 false)
  %68 = getelementptr inbounds %"class.ruy::MulParams.461", %"class.ruy::MulParams.461"* %12, i64 0, i32 5
  %69 = getelementptr inbounds %"class.ruy::MulParams.461", %"class.ruy::MulParams.461"* %12, i64 0, i32 6
  %70 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.456", %"struct.tflite::cpu_backend_gemm::GemmParams.456"* %6, i64 0, i32 0
  %71 = load i32, i32* %70, align 8
  %72 = getelementptr inbounds %"class.ruy::MulParams.461", %"class.ruy::MulParams.461"* %12, i64 0, i32 1
  store i32 %71, i32* %72, align 8
  %73 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.456", %"struct.tflite::cpu_backend_gemm::GemmParams.456"* %6, i64 0, i32 1
  %74 = load i32, i32* %73, align 4
  %75 = getelementptr inbounds %"class.ruy::MulParams.461", %"class.ruy::MulParams.461"* %12, i64 0, i32 2
  store i32 %74, i32* %75, align 4
  %76 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.456", %"struct.tflite::cpu_backend_gemm::GemmParams.456"* %6, i64 0, i32 2
  %77 = getelementptr inbounds %"class.ruy::MulParams.461", %"class.ruy::MulParams.461"* %12, i64 0, i32 3
  %78 = bitcast i32** %76 to <2 x i64>*
  %79 = load <2 x i64>, <2 x i64>* %78, align 8
  %80 = bitcast i32** %77 to <2 x i64>*
  store <2 x i64> %79, <2 x i64>* %80, align 8
  %81 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.456", %"struct.tflite::cpu_backend_gemm::GemmParams.456"* %6, i64 0, i32 4
  %82 = bitcast i32** %81 to i64*
  %83 = load i64, i64* %82, align 8
  %84 = bitcast %"class.ruy::MulParams.461"* %12 to i64*
  store i64 %83, i64* %84, align 8
  %85 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.456", %"struct.tflite::cpu_backend_gemm::GemmParams.456"* %6, i64 0, i32 5
  %86 = load i16, i16* %85, align 8
  store i16 %86, i16* %68, align 8
  %87 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.456", %"struct.tflite::cpu_backend_gemm::GemmParams.456"* %6, i64 0, i32 6
  %88 = load i16, i16* %87, align 2
  store i16 %88, i16* %69, align 2
  %89 = getelementptr inbounds %"class.tflite::CpuBackendContext", %"class.tflite::CpuBackendContext"* %7, i64 0, i32 1, i32 0, i32 0, i32 0
  %90 = load %"class.ruy::Context"*, %"class.ruy::Context"** %89, align 8
  %91 = bitcast %"struct.ruy::Mat.160"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %91) #19
  %92 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %9, i64 0, i32 1, i32 2
  %93 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %9, i64 0, i32 2
  %94 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %9, i64 0, i32 3
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %91, i8 -86, i64 32, i1 false) #19
  %95 = bitcast %"struct.ruy::Mat.160"* %9 to i64*
  store i64 %24, i64* %95, align 8, !alias.scope !1196
  %96 = zext i32 %23 to i64
  %97 = zext i1 %18 to i64
  %98 = shl nuw nsw i64 %97, 32
  %99 = or i64 %98, %96
  %100 = zext i32 %22 to i64
  %101 = shl nuw i64 %100, 32
  %102 = zext i32 %20 to i64
  %103 = or i64 %101, %102
  %104 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %9, i64 0, i32 1
  %105 = bitcast %"struct.ruy::MatLayout"* %104 to i64*
  store i64 %103, i64* %105, align 8, !alias.scope !1196
  %106 = bitcast i32* %92 to i40*
  %107 = trunc i64 %99 to i40
  store i40 %107, i40* %106, align 8, !alias.scope !1196
  store i8 %26, i8* %93, align 8, !alias.scope !1196
  store i8 %35, i8* %94, align 1, !alias.scope !1196
  %108 = bitcast %"struct.ruy::Mat.160"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %108) #19
  %109 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %10, i64 0, i32 1, i32 2
  %110 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %10, i64 0, i32 2
  %111 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %10, i64 0, i32 3
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %108, i8 -86, i64 32, i1 false) #19
  %112 = bitcast %"struct.ruy::Mat.160"* %10 to i64*
  store i64 %44, i64* %112, align 8, !alias.scope !1199
  %113 = zext i32 %43 to i64
  %114 = zext i1 %38 to i64
  %115 = shl nuw nsw i64 %114, 32
  %116 = or i64 %115, %113
  %117 = zext i32 %42 to i64
  %118 = shl nuw i64 %117, 32
  %119 = zext i32 %40 to i64
  %120 = or i64 %118, %119
  %121 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %10, i64 0, i32 1
  %122 = bitcast %"struct.ruy::MatLayout"* %121 to i64*
  store i64 %120, i64* %122, align 8, !alias.scope !1199
  %123 = bitcast i32* %109 to i40*
  %124 = trunc i64 %116 to i40
  store i40 %124, i40* %123, align 8, !alias.scope !1199
  store i8 %46, i8* %110, align 8, !alias.scope !1199
  store i8 %55, i8* %111, align 1, !alias.scope !1199
  %125 = bitcast %"struct.ruy::Mat.463"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %125) #19
  %126 = getelementptr inbounds %"struct.ruy::Mat.463", %"struct.ruy::Mat.463"* %11, i64 0, i32 1, i32 2
  %127 = getelementptr inbounds %"struct.ruy::Mat.463", %"struct.ruy::Mat.463"* %11, i64 0, i32 2
  %128 = getelementptr inbounds %"struct.ruy::Mat.463", %"struct.ruy::Mat.463"* %11, i64 0, i32 3
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %125, i8 -86, i64 32, i1 false) #19
  %129 = bitcast %"struct.ruy::Mat.463"* %11 to i64*
  store i64 %64, i64* %129, align 8, !alias.scope !1202
  %130 = zext i32 %63 to i64
  %131 = zext i1 %58 to i64
  %132 = shl nuw nsw i64 %131, 32
  %133 = or i64 %132, %130
  %134 = zext i32 %62 to i64
  %135 = shl nuw i64 %134, 32
  %136 = zext i32 %60 to i64
  %137 = or i64 %135, %136
  %138 = getelementptr inbounds %"struct.ruy::Mat.463", %"struct.ruy::Mat.463"* %11, i64 0, i32 1
  %139 = bitcast %"struct.ruy::MatLayout"* %138 to i64*
  store i64 %137, i64* %139, align 8, !alias.scope !1202
  %140 = bitcast i32* %126 to i40*
  %141 = trunc i64 %133 to i40
  store i40 %141, i40* %140, align 8, !alias.scope !1202
  store i16 %66, i16* %127, align 8, !alias.scope !1202
  store i8 0, i8* %128, align 2, !alias.scope !1202
  %142 = tail call %"class.ruy::Ctx"* @_ZN3ruy7get_ctxEPNS_7ContextE(%"class.ruy::Context"* %90) #19
  call void @_ZN3ruy11DispatchMulILNS_4PathE26EhhsNS_9MulParamsIisEEEEvRKNS_3MatIT0_EERKNS4_IT1_EERKT3_PNS_3CtxEPNS4_IT2_EE(%"struct.ruy::Mat.160"* nonnull dereferenceable(32) %9, %"struct.ruy::Mat.160"* nonnull dereferenceable(32) %10, %"class.ruy::MulParams.461"* nonnull dereferenceable(40) %12, %"class.ruy::Ctx"* %142, %"struct.ruy::Mat.463"* nonnull %11) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %125) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %108) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %91) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %67) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN6tflite16cpu_backend_gemm6detail21GemmImplUsingGemmlowpIhhisLNS0_18QuantizationFlavorE1EE3RunERKNS0_12MatrixParamsIhEEPKhS8_SA_RKNS5_IsEEPsRKNS0_10GemmParamsIisLS3_1EEEPNS_17CpuBackendContextE(%"struct.tflite::cpu_backend_gemm::MatrixParams.153"* dereferenceable(16), i8*, %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* dereferenceable(16), i8*, %"struct.tflite::cpu_backend_gemm::MatrixParams.454"* dereferenceable(16), i16*, %"struct.tflite::cpu_backend_gemm::GemmParams.456"* dereferenceable(40), %"class.tflite::CpuBackendContext"*) local_unnamed_addr #1 comdat align 2 {
  %9 = alloca %"class.gemmlowp::VectorDup", align 4
  %10 = alloca %"class.gemmlowp::VectorDup.194", align 4
  %11 = alloca %"class.gemmlowp::VectorDup", align 4
  %12 = alloca %"class.gemmlowp::VectorDup.194", align 4
  %13 = alloca %"class.gemmlowp::MatrixMap", align 8
  %14 = alloca %"class.gemmlowp::MatrixMap.180", align 8
  %15 = alloca %"class.gemmlowp::MatrixMap.479", align 8
  %16 = alloca %"class.std::__1::tuple.481", align 8
  %17 = alloca %"class.std::__1::tuple.485", align 4
  %18 = bitcast %"class.gemmlowp::MatrixMap"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %18) #19
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %13, i64 0, i32 0
  %20 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %13, i64 0, i32 1
  %21 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %13, i64 0, i32 2
  %22 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %13, i64 0, i32 3
  %23 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %0, i64 0, i32 1
  %24 = bitcast %"class.gemmlowp::MatrixMap"* %13 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %24, i8 -86, i64 24, i1 false)
  %25 = load i32, i32* %23, align 4
  %26 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %0, i64 0, i32 2
  %27 = load i32, i32* %26, align 4
  store i8* %1, i8** %19, align 8
  store i32 %25, i32* %20, align 8
  store i32 %27, i32* %21, align 4
  store i32 %27, i32* %22, align 8
  %28 = bitcast %"class.gemmlowp::MatrixMap.180"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %28) #19
  %29 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %14, i64 0, i32 0
  %30 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %14, i64 0, i32 1
  %31 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %14, i64 0, i32 2
  %32 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %14, i64 0, i32 3
  %33 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %2, i64 0, i32 1
  %34 = bitcast %"class.gemmlowp::MatrixMap.180"* %14 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %34, i8 -86, i64 24, i1 false)
  %35 = load i32, i32* %33, align 4
  %36 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %2, i64 0, i32 2
  %37 = load i32, i32* %36, align 4
  store i8* %3, i8** %29, align 8
  store i32 %35, i32* %30, align 8
  store i32 %37, i32* %31, align 4
  store i32 %35, i32* %32, align 8
  %38 = bitcast %"class.gemmlowp::MatrixMap.479"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %38) #19
  %39 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %15, i64 0, i32 0
  %40 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %15, i64 0, i32 1
  %41 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %15, i64 0, i32 2
  %42 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %15, i64 0, i32 3
  %43 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.454", %"struct.tflite::cpu_backend_gemm::MatrixParams.454"* %4, i64 0, i32 1
  %44 = bitcast %"class.gemmlowp::MatrixMap.479"* %15 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %44, i8 -86, i64 24, i1 false)
  %45 = load i32, i32* %43, align 4
  %46 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.454", %"struct.tflite::cpu_backend_gemm::MatrixParams.454"* %4, i64 0, i32 2
  %47 = load i32, i32* %46, align 4
  store i16* %5, i16** %39, align 8
  store i32 %45, i32* %40, align 8
  store i32 %47, i32* %41, align 4
  store i32 %45, i32* %42, align 8
  %48 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.454", %"struct.tflite::cpu_backend_gemm::MatrixParams.454"* %4, i64 0, i32 3
  %49 = load i16, i16* %48, align 4
  %50 = sext i16 %49 to i32
  %51 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.456", %"struct.tflite::cpu_backend_gemm::GemmParams.456"* %6, i64 0, i32 0
  %52 = load i32, i32* %51, align 8
  %53 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.456", %"struct.tflite::cpu_backend_gemm::GemmParams.456"* %6, i64 0, i32 1
  %54 = load i32, i32* %53, align 4
  %55 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.456", %"struct.tflite::cpu_backend_gemm::GemmParams.456"* %6, i64 0, i32 5
  %56 = load i16, i16* %55, align 8
  %57 = sext i16 %56 to i32
  %58 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.456", %"struct.tflite::cpu_backend_gemm::GemmParams.456"* %6, i64 0, i32 6
  %59 = load i16, i16* %58, align 2
  %60 = sext i16 %59 to i32
  %61 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.456", %"struct.tflite::cpu_backend_gemm::GemmParams.456"* %6, i64 0, i32 4
  %62 = load i32*, i32** %61, align 8
  %63 = icmp eq i32* %62, null
  br i1 %63, label %94, label %64

64:                                               ; preds = %8
  %65 = ptrtoint i32* %62 to i64
  %66 = bitcast %"class.std::__1::tuple.481"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %66) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %66, i8 -86, i64 40, i1 false)
  %67 = bitcast %"class.std::__1::tuple.481"* %16 to i64*
  store i64 %65, i64* %67, align 8, !alias.scope !1205
  %68 = getelementptr inbounds %"class.std::__1::tuple.481", %"class.std::__1::tuple.481"* %16, i64 0, i32 0, i32 0, i32 0, i32 0, i32 1
  store i32 %25, i32* %68, align 8, !alias.scope !1205
  %69 = getelementptr inbounds %"class.std::__1::tuple.481", %"class.std::__1::tuple.481"* %16, i64 0, i32 0, i32 1, i32 0, i32 0
  store i32 %52, i32* %69, align 8
  %70 = getelementptr inbounds %"class.std::__1::tuple.481", %"class.std::__1::tuple.481"* %16, i64 0, i32 0, i32 1, i32 0, i32 1
  store i32 %54, i32* %70, align 4
  %71 = getelementptr inbounds %"class.std::__1::tuple.481", %"class.std::__1::tuple.481"* %16, i64 0, i32 0, i32 1, i32 0, i32 2
  store i32 %50, i32* %71, align 8
  %72 = getelementptr inbounds %"class.std::__1::tuple.481", %"class.std::__1::tuple.481"* %16, i64 0, i32 0, i32 2
  %73 = bitcast %"class.std::__1::__tuple_leaf.185"* %72 to i64*
  %74 = zext i32 %60 to i64
  %75 = shl nuw i64 %74, 32
  %76 = zext i32 %57 to i64
  %77 = or i64 %75, %76
  store i64 %77, i64* %73, align 4, !alias.scope !1205
  %78 = getelementptr inbounds %"class.tflite::CpuBackendContext", %"class.tflite::CpuBackendContext"* %7, i64 0, i32 2, i32 0, i32 0, i32 0
  %79 = load %"class.gemmlowp::GemmContext"*, %"class.gemmlowp::GemmContext"** %78, align 8
  %80 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %0, i64 0, i32 3
  %81 = load i8, i8* %80, align 4
  %82 = zext i8 %81 to i32
  %83 = sub nsw i32 0, %82
  %84 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %2, i64 0, i32 3
  %85 = load i8, i8* %84, align 4
  %86 = zext i8 %85 to i32
  %87 = sub nsw i32 0, %86
  %88 = bitcast %"class.gemmlowp::VectorDup"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %88) #19
  %89 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %9, i64 0, i32 0
  %90 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %9, i64 0, i32 1
  store i32 %83, i32* %89, align 4
  store i32 %25, i32* %90, align 4
  %91 = bitcast %"class.gemmlowp::VectorDup.194"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %91) #19
  %92 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %10, i64 0, i32 0
  %93 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %10, i64 0, i32 1
  store i32 %87, i32* %92, align 4
  store i32 %37, i32* %93, align 4
  call void @_ZN8gemmlowp17DispatchGemmShapeIhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENS7_IS8_LS9_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIS8_LS9_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSP_ISR_XT3_EEEPNSP_IT0_XT4_EEERKT5_RKT6_RKT7_(%"class.gemmlowp::GemmContext"* %79, %"class.gemmlowp::MatrixMap"* nonnull dereferenceable(24) %13, %"class.gemmlowp::MatrixMap.180"* nonnull dereferenceable(24) %14, %"class.gemmlowp::MatrixMap.479"* nonnull %15, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %9, %"class.gemmlowp::VectorDup.194"* nonnull dereferenceable(8) %10, %"class.std::__1::tuple.481"* nonnull dereferenceable(40) %16) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %91) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %88) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %66) #19
  br label %121

94:                                               ; preds = %8
  %95 = bitcast %"class.std::__1::tuple.485"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 20, i8* nonnull %95) #19
  %96 = getelementptr inbounds %"class.std::__1::tuple.485", %"class.std::__1::tuple.485"* %17, i64 0, i32 0, i32 0, i32 0, i32 0
  %97 = getelementptr inbounds %"class.std::__1::tuple.485", %"class.std::__1::tuple.485"* %17, i64 0, i32 0, i32 0, i32 0, i32 1
  %98 = getelementptr inbounds %"class.std::__1::tuple.485", %"class.std::__1::tuple.485"* %17, i64 0, i32 0, i32 0, i32 0, i32 2
  store i32 %52, i32* %96, align 4
  store i32 %54, i32* %97, align 4
  store i32 %50, i32* %98, align 4
  %99 = getelementptr inbounds %"class.std::__1::tuple.485", %"class.std::__1::tuple.485"* %17, i64 0, i32 0, i32 1
  %100 = bitcast %"class.std::__1::__tuple_leaf.190"* %99 to i64*
  %101 = zext i32 %60 to i64
  %102 = shl nuw i64 %101, 32
  %103 = zext i32 %57 to i64
  %104 = or i64 %102, %103
  store i64 %104, i64* %100, align 4, !alias.scope !1208
  %105 = getelementptr inbounds %"class.tflite::CpuBackendContext", %"class.tflite::CpuBackendContext"* %7, i64 0, i32 2, i32 0, i32 0, i32 0
  %106 = load %"class.gemmlowp::GemmContext"*, %"class.gemmlowp::GemmContext"** %105, align 8
  %107 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %0, i64 0, i32 3
  %108 = load i8, i8* %107, align 4
  %109 = zext i8 %108 to i32
  %110 = sub nsw i32 0, %109
  %111 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.153", %"struct.tflite::cpu_backend_gemm::MatrixParams.153"* %2, i64 0, i32 3
  %112 = load i8, i8* %111, align 4
  %113 = zext i8 %112 to i32
  %114 = sub nsw i32 0, %113
  %115 = bitcast %"class.gemmlowp::VectorDup"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %115) #19
  %116 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %11, i64 0, i32 0
  %117 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %11, i64 0, i32 1
  store i32 %110, i32* %116, align 4
  store i32 %25, i32* %117, align 4
  %118 = bitcast %"class.gemmlowp::VectorDup.194"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %118) #19
  %119 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %12, i64 0, i32 0
  %120 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %12, i64 0, i32 1
  store i32 %114, i32* %119, align 4
  store i32 %37, i32* %120, align 4
  call void @_ZN8gemmlowp17DispatchGemmShapeIhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENS7_IS8_LS9_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSL_ISN_XT3_EEEPNSL_IT0_XT4_EEERKT5_RKT6_RKT7_(%"class.gemmlowp::GemmContext"* %106, %"class.gemmlowp::MatrixMap"* nonnull dereferenceable(24) %13, %"class.gemmlowp::MatrixMap.180"* nonnull dereferenceable(24) %14, %"class.gemmlowp::MatrixMap.479"* nonnull %15, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %11, %"class.gemmlowp::VectorDup.194"* nonnull dereferenceable(8) %12, %"class.std::__1::tuple.485"* nonnull dereferenceable(20) %17) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %118) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %115) #19
  call void @llvm.lifetime.end.p0i8(i64 20, i8* nonnull %95) #19
  br label %121

121:                                              ; preds = %94, %64
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %38) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %28) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %18) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy11DispatchMulILNS_4PathE26EhhsNS_9MulParamsIisEEEEvRKNS_3MatIT0_EERKNS4_IT1_EERKT3_PNS_3CtxEPNS4_IT2_EE(%"struct.ruy::Mat.160"* dereferenceable(32), %"struct.ruy::Mat.160"* dereferenceable(32), %"class.ruy::MulParams.461"* dereferenceable(40), %"class.ruy::Ctx"*, %"struct.ruy::Mat.463"*) local_unnamed_addr #1 comdat {
  %6 = alloca %"struct.ruy::Mat.160", align 8
  %7 = alloca %"struct.ruy::TrMulParams", align 8
  %8 = tail call zeroext i8 @_ZN3ruy3Ctx10SelectPathENS_4PathE(%"class.ruy::Ctx"* %3, i8 zeroext 26) #19
  %9 = bitcast %"struct.ruy::Mat.160"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %9) #19
  %10 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %6, i64 0, i32 1, i32 0
  %11 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %6, i64 0, i32 1, i32 1
  %12 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %6, i64 0, i32 1, i32 3
  %13 = bitcast %"struct.ruy::Mat.160"* %0 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %9, i8* align 8 %13, i64 32, i1 false)
  %14 = load i8, i8* %12, align 4
  %15 = icmp eq i8 %14, 0
  %16 = zext i1 %15 to i8
  store i8 %16, i8* %12, align 4
  %17 = load i32, i32* %10, align 8
  %18 = load i32, i32* %11, align 4
  store i32 %18, i32* %10, align 8
  store i32 %17, i32* %11, align 4
  %19 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 0
  call void @llvm.lifetime.start.p0i8(i64 280, i8* nonnull %19) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %19, i8 -86, i64 272, i1 false)
  %20 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 1
  %21 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 3, i32 0, i64 0, i32 2
  %22 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 3, i32 0, i64 0, i32 4
  store i32 0, i32* %22, align 8
  %23 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 3, i32 0, i64 0, i32 5
  store i8 0, i8* %23, align 4
  %24 = bitcast i8** %21 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %24, i8 0, i64 21, i1 false) #19
  %25 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 3, i32 0, i64 1, i32 0, i32 0
  store i8 0, i8* %25, align 8
  %26 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 3, i32 0, i64 1, i32 0, i32 1
  store i8 0, i8* %26, align 1
  %27 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 3, i32 0, i64 1, i32 0, i32 2
  store i8 0, i8* %27, align 2
  %28 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 3, i32 0, i64 1, i32 2
  %29 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 3, i32 0, i64 1, i32 4
  store i32 0, i32* %29, align 8
  %30 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 3, i32 0, i64 1, i32 5
  store i8 0, i8* %30, align 4
  %31 = bitcast i8** %28 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %31, i8 0, i64 21, i1 false) #19
  %32 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 4, i32 0, i32 0
  store i8 0, i8* %32, align 8
  %33 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 4, i32 0, i32 1
  store i8 0, i8* %33, align 1
  %34 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 4, i32 0, i32 2
  store i8 0, i8* %34, align 2
  %35 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 4, i32 2
  %36 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 4, i32 4
  store i32 0, i32* %36, align 8
  %37 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 4, i32 5
  store i8 0, i8* %37, align 4
  %38 = bitcast i8** %35 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %38, i8 0, i64 21, i1 false) #19
  %39 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 0, i32 0, i32 0
  store i8 0, i8* %39, align 8
  %40 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 0, i32 0, i32 1
  store i8 0, i8* %40, align 1
  %41 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 0, i32 0, i32 2
  store i8 0, i8* %41, align 2
  %42 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 0, i32 2
  %43 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 0, i32 5
  %44 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 1
  %45 = bitcast i8** %42 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %45, i8 0, i64 11, i1 false) #19
  %46 = bitcast i8** %43 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %46, i8 0, i64 22, i1 false) #19
  %47 = bitcast %"class.ruy::SidePair"* %20 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %47, i8 0, i64 27, i1 false) #19
  store i8 1, i8* %44, align 1
  %48 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 2
  store i8 1, i8* %48, align 1
  %49 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 0, i32 7
  store i32 0, i32* %49, align 8
  %50 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 1, i32 0, i32 0
  store i8 0, i8* %50, align 8
  %51 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 1, i32 0, i32 1
  store i8 0, i8* %51, align 1
  %52 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 1, i32 0, i32 2
  store i8 0, i8* %52, align 2
  %53 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 1, i32 2
  %54 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 1, i32 5
  %55 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 1
  %56 = bitcast i8** %53 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %56, i8 0, i64 11, i1 false) #19
  %57 = bitcast i8** %54 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %57, i8 0, i64 22, i1 false) #19
  store i8 1, i8* %55, align 1
  %58 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 2
  store i8 1, i8* %58, align 1
  %59 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 5, i32 0, i64 1, i32 7
  store i32 0, i32* %59, align 8
  %60 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 6, i32 0, i64 0
  store i8 0, i8* %60, align 8
  %61 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 6, i32 0, i64 1
  store i8 0, i8* %61, align 1
  %62 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %7, i64 0, i32 7
  store i8* null, i8** %62, align 8
  call void @_ZN3ruy17CreateTrMulParamsILNS_4PathE26EhhsNS_9MulParamsIisEEEEvRKNS_3MatIT0_EERKNS4_IT1_EERKT3_PNS4_IT2_EES1_PNS_11TrMulParamsE(%"struct.ruy::Mat.160"* nonnull dereferenceable(32) %6, %"struct.ruy::Mat.160"* dereferenceable(32) %1, %"class.ruy::MulParams.461"* dereferenceable(40) %2, %"struct.ruy::Mat.463"* %4, i8 zeroext %8, %"struct.ruy::TrMulParams"* nonnull %7)
  call void @_ZN3ruy22HandlePrepackedCachingEPNS_11TrMulParamsEPNS_3CtxE(%"struct.ruy::TrMulParams"* nonnull %7, %"class.ruy::Ctx"* %3)
  call void @_ZN3ruy5TrMulEPNS_11TrMulParamsEPNS_3CtxE(%"struct.ruy::TrMulParams"* nonnull %7, %"class.ruy::Ctx"* %3) #19
  call void @llvm.lifetime.end.p0i8(i64 280, i8* nonnull %19) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %9) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy17CreateTrMulParamsILNS_4PathE26EhhsNS_9MulParamsIisEEEEvRKNS_3MatIT0_EERKNS4_IT1_EERKT3_PNS4_IT2_EES1_PNS_11TrMulParamsE(%"struct.ruy::Mat.160"* dereferenceable(32), %"struct.ruy::Mat.160"* dereferenceable(32), %"class.ruy::MulParams.461"* dereferenceable(40), %"struct.ruy::Mat.463"*, i8 zeroext, %"struct.ruy::TrMulParams"*) local_unnamed_addr #1 comdat {
  %7 = alloca [13 x i8], align 8
  %8 = alloca [13 x i8], align 8
  %9 = alloca [13 x i8], align 8
  %10 = getelementptr inbounds [13 x i8], [13 x i8]* %9, i64 0, i64 0
  %11 = getelementptr inbounds [13 x i8], [13 x i8]* %8, i64 0, i64 0
  %12 = getelementptr inbounds [13 x i8], [13 x i8]* %7, i64 0, i64 0
  call void @llvm.lifetime.start.p0i8(i64 13, i8* nonnull %12)
  %13 = bitcast %"struct.ruy::Mat.160"* %0 to i64*
  %14 = load i64, i64* %13, align 8, !noalias !1211
  %15 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %0, i64 0, i32 1
  %16 = bitcast %"struct.ruy::MatLayout"* %15 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %12, i8* align 4 %16, i64 13, i1 false)
  %17 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %0, i64 0, i32 2
  %18 = load i8, i8* %17, align 8, !noalias !1211
  %19 = zext i8 %18 to i32
  %20 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %0, i64 0, i32 3
  %21 = load i8, i8* %20, align 1, !noalias !1211
  %22 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3
  %23 = bitcast %"class.ruy::SidePair.106"* %22 to i24*
  store i24 65536, i24* %23, align 8
  %24 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 0, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %24, i8 -86, i64 5, i1 false)
  %25 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 0, i32 2
  %26 = bitcast i8** %25 to i64*
  store i64 %14, i64* %26, align 8
  %27 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 0, i32 3
  %28 = bitcast %"struct.ruy::MatLayout"* %27 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %28, i8* nonnull align 8 %12, i64 13, i1 false)
  %29 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 0, i32 3, i32 4, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %29, i8 -86, i64 3, i1 false)
  %30 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 0, i32 4
  store i32 %19, i32* %30, align 8
  %31 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 0, i32 5
  store i8 %21, i8* %31, align 4
  call void @llvm.lifetime.end.p0i8(i64 13, i8* nonnull %12)
  call void @llvm.lifetime.start.p0i8(i64 13, i8* nonnull %11)
  %32 = bitcast %"struct.ruy::Mat.160"* %1 to i64*
  %33 = load i64, i64* %32, align 8, !noalias !1214
  %34 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %1, i64 0, i32 1
  %35 = bitcast %"struct.ruy::MatLayout"* %34 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %11, i8* align 4 %35, i64 13, i1 false)
  %36 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %1, i64 0, i32 2
  %37 = load i8, i8* %36, align 8, !noalias !1214
  %38 = zext i8 %37 to i32
  %39 = getelementptr inbounds %"struct.ruy::Mat.160", %"struct.ruy::Mat.160"* %1, i64 0, i32 3
  %40 = load i8, i8* %39, align 1, !noalias !1214
  %41 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 1
  %42 = bitcast %"struct.ruy::EMat"* %41 to i24*
  store i24 65536, i24* %42, align 8
  %43 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 1, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %43, i8 -86, i64 5, i1 false)
  %44 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 1, i32 2
  %45 = bitcast i8** %44 to i64*
  store i64 %33, i64* %45, align 8
  %46 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 1, i32 3
  %47 = bitcast %"struct.ruy::MatLayout"* %46 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %47, i8* nonnull align 8 %11, i64 13, i1 false)
  %48 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 1, i32 3, i32 4, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %48, i8 -86, i64 3, i1 false)
  %49 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 1, i32 4
  store i32 %38, i32* %49, align 8
  %50 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 1, i32 5
  store i8 %40, i8* %50, align 4
  call void @llvm.lifetime.end.p0i8(i64 13, i8* nonnull %11)
  call void @llvm.lifetime.start.p0i8(i64 13, i8* nonnull %10)
  %51 = bitcast %"struct.ruy::Mat.463"* %3 to i64*
  %52 = load i64, i64* %51, align 8, !noalias !1217
  %53 = getelementptr inbounds %"struct.ruy::Mat.463", %"struct.ruy::Mat.463"* %3, i64 0, i32 1
  %54 = bitcast %"struct.ruy::MatLayout"* %53 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %10, i8* align 4 %54, i64 13, i1 false)
  %55 = getelementptr inbounds %"struct.ruy::Mat.463", %"struct.ruy::Mat.463"* %3, i64 0, i32 2
  %56 = load i16, i16* %55, align 8, !noalias !1217
  %57 = sext i16 %56 to i32
  %58 = getelementptr inbounds %"struct.ruy::Mat.463", %"struct.ruy::Mat.463"* %3, i64 0, i32 3
  %59 = load i8, i8* %58, align 2, !noalias !1217
  %60 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 4
  %61 = bitcast %"struct.ruy::EMat"* %60 to i24*
  store i24 131073, i24* %61, align 8
  %62 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 4, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %62, i8 -86, i64 5, i1 false)
  %63 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 4, i32 2
  %64 = bitcast i8** %63 to i64*
  store i64 %52, i64* %64, align 8
  %65 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 4, i32 3
  %66 = bitcast %"struct.ruy::MatLayout"* %65 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %66, i8* nonnull align 8 %10, i64 13, i1 false)
  %67 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 4, i32 3, i32 4, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %67, i8 -86, i64 3, i1 false)
  %68 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 4, i32 4
  store i32 %57, i32* %68, align 8
  %69 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 4, i32 5
  store i8 %59, i8* %69, align 4
  call void @llvm.lifetime.end.p0i8(i64 13, i8* nonnull %10)
  %70 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 7
  %71 = bitcast i8** %70 to %"class.ruy::MulParams.461"**
  store %"class.ruy::MulParams.461"* %2, %"class.ruy::MulParams.461"** %71, align 8
  switch i8 %4, label %119 [
    i8 16, label %72
    i8 8, label %73
    i8 2, label %74
  ]

72:                                               ; preds = %6
  tail call void @_ZN3ruy19PopulateTrMulParamsILNS_4PathE16EhhsNS_9MulParamsIisEEEEvPNS_11TrMulParamsE(%"struct.ruy::TrMulParams"* %5) #19
  br label %119

73:                                               ; preds = %6
  tail call void @_ZN3ruy19PopulateTrMulParamsILNS_4PathE8EhhsNS_9MulParamsIisEEEEvPNS_11TrMulParamsE(%"struct.ruy::TrMulParams"* %5) #19
  br label %119

74:                                               ; preds = %6
  %75 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 0
  store i8 2, i8* %75, align 8
  %76 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 0
  %77 = bitcast %"struct.ruy::PEMat"* %76 to i24*
  store i24 65536, i24* %77, align 8
  %78 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 0, i32 3
  %79 = bitcast %"struct.ruy::Type"* %78 to i24*
  store i24 262145, i24* %79, align 8
  %80 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 0, i32 6, i32 3
  store i8 0, i8* %80, align 4
  %81 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 0, i32 3, i32 0
  %82 = load i32, i32* %81, align 4
  %83 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 0, i32 6, i32 0
  store i32 %82, i32* %83, align 4
  %84 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 0, i32 3, i32 1
  %85 = load i32, i32* %84, align 4
  %86 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 0, i32 6, i32 1
  store i32 %85, i32* %86, align 4
  %87 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 0
  store i8 0, i8* %87, align 1
  %88 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 1
  store i8 1, i8* %88, align 1
  %89 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 2
  store i8 1, i8* %89, align 1
  %90 = and i32 %82, 1023
  %91 = icmp eq i32 %90, 0
  %92 = add nsw i32 %82, 64
  %93 = select i1 %91, i32 %92, i32 %82
  %94 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 0, i32 6, i32 2
  store i32 %93, i32* %94, align 4
  %95 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 0, i32 7
  store i32 %19, i32* %95, align 8
  %96 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 1
  %97 = bitcast %"struct.ruy::PEMat"* %96 to i24*
  store i24 65536, i24* %97, align 8
  %98 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 1, i32 3
  %99 = bitcast %"struct.ruy::Type"* %98 to i24*
  store i24 262145, i24* %99, align 8
  %100 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 1, i32 6, i32 3
  store i8 0, i8* %100, align 4
  %101 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 1, i32 3, i32 0
  %102 = load i32, i32* %101, align 4
  %103 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 1, i32 6, i32 0
  store i32 %102, i32* %103, align 4
  %104 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 3, i32 0, i64 1, i32 3, i32 1
  %105 = load i32, i32* %104, align 4
  %106 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 1, i32 6, i32 1
  store i32 %105, i32* %106, align 4
  %107 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 0
  store i8 0, i8* %107, align 1
  %108 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 1
  store i8 1, i8* %108, align 1
  %109 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 2
  store i8 1, i8* %109, align 1
  %110 = and i32 %102, 1023
  %111 = icmp eq i32 %110, 0
  %112 = add nsw i32 %102, 64
  %113 = select i1 %111, i32 %112, i32 %102
  %114 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 1, i32 6, i32 2
  store i32 %113, i32* %114, align 4
  %115 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 5, i32 0, i64 1, i32 7
  store i32 %38, i32* %115, align 8
  %116 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 1, i32 0, i64 0
  %117 = bitcast void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)** %116 to <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*>*
  store <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*> <void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* @_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEhhEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii, void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* @_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEhhEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii>, <2 x void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)*>* %117, align 8
  %118 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %5, i64 0, i32 2
  store void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)* @_ZN3ruy9RunKernelILNS_4PathE2EhhsNS_9MulParamsIisEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE, void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)** %118, align 8
  br label %119

119:                                              ; preds = %6, %74, %73, %72
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy19PopulateTrMulParamsILNS_4PathE16EhhsNS_9MulParamsIisEEEEvPNS_11TrMulParamsE(%"struct.ruy::TrMulParams"*) local_unnamed_addr #1 comdat {
  %2 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 3
  %3 = load i8, i8* %2, align 4
  %4 = icmp eq i8 %3, 0
  br i1 %4, label %5, label %13

5:                                                ; preds = %1
  %6 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 3
  %7 = load i8, i8* %6, align 4
  %8 = icmp eq i8 %7, 0
  br i1 %8, label %9, label %13

9:                                                ; preds = %5
  %10 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 4, i32 3, i32 3
  %11 = load i8, i8* %10, align 4
  %12 = icmp eq i8 %11, 0
  br i1 %12, label %60, label %13

13:                                               ; preds = %1, %5, %9
  %14 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 0
  store i8 2, i8* %14, align 8
  %15 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0
  %16 = bitcast %"struct.ruy::PEMat"* %15 to i24*
  store i24 65536, i24* %16, align 8
  %17 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 3
  %18 = bitcast %"struct.ruy::Type"* %17 to i24*
  store i24 262145, i24* %18, align 8
  %19 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 3
  store i8 0, i8* %19, align 4
  %20 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 0
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 0
  store i32 %21, i32* %22, align 4
  %23 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 1
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 1
  store i32 %24, i32* %25, align 4
  %26 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 0
  store i8 0, i8* %26, align 1
  %27 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 1
  store i8 1, i8* %27, align 1
  %28 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 2
  store i8 1, i8* %28, align 1
  %29 = and i32 %21, 1023
  %30 = icmp eq i32 %29, 0
  %31 = add nsw i32 %21, 64
  %32 = select i1 %30, i32 %31, i32 %21
  %33 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 2
  store i32 %32, i32* %33, align 4
  %34 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 4
  %35 = load i32, i32* %34, align 8
  %36 = and i32 %35, 255
  %37 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 7
  store i32 %36, i32* %37, align 8
  %38 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1
  %39 = bitcast %"struct.ruy::PEMat"* %38 to i24*
  store i24 65536, i24* %39, align 8
  %40 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 3
  %41 = bitcast %"struct.ruy::Type"* %40 to i24*
  store i24 262145, i24* %41, align 8
  %42 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 3
  store i8 0, i8* %42, align 4
  %43 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 0
  %44 = load i32, i32* %43, align 4
  %45 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 0
  store i32 %44, i32* %45, align 4
  %46 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 1
  %47 = load i32, i32* %46, align 4
  %48 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 1
  store i32 %47, i32* %48, align 4
  %49 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 0
  store i8 0, i8* %49, align 1
  %50 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 1
  store i8 1, i8* %50, align 1
  %51 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 2
  store i8 1, i8* %51, align 1
  %52 = and i32 %44, 1023
  %53 = icmp eq i32 %52, 0
  %54 = add nsw i32 %44, 64
  %55 = select i1 %53, i32 %54, i32 %44
  %56 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 2
  store i32 %55, i32* %56, align 4
  %57 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 4
  %58 = load i32, i32* %57, align 8
  %59 = and i32 %58, 255
  br label %119

60:                                               ; preds = %9
  %61 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 0
  store i8 16, i8* %61, align 8
  %62 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0
  %63 = bitcast %"struct.ruy::PEMat"* %62 to i24*
  store i24 65537, i24* %63, align 8
  %64 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 3
  %65 = bitcast %"struct.ruy::Type"* %64 to i24*
  store i24 262145, i24* %65, align 8
  %66 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 3
  store i8 0, i8* %66, align 4
  %67 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 0
  %68 = load i32, i32* %67, align 4
  %69 = add i32 %68, 3
  %70 = and i32 %69, -4
  %71 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 0
  store i32 %70, i32* %71, align 4
  %72 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 1
  %73 = load i32, i32* %72, align 4
  %74 = add i32 %73, 15
  %75 = and i32 %74, -16
  %76 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 1
  store i32 %75, i32* %76, align 4
  %77 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 0
  store i8 0, i8* %77, align 1
  %78 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 1
  store i8 4, i8* %78, align 1
  %79 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 2
  store i8 16, i8* %79, align 1
  %80 = and i32 %69, 1020
  %81 = icmp eq i32 %80, 0
  %82 = add nsw i32 %70, 64
  %83 = select i1 %81, i32 %82, i32 %70
  %84 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 2
  store i32 %83, i32* %84, align 4
  %85 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 4
  %86 = load i32, i32* %85, align 8
  %87 = shl i32 %86, 24
  %88 = ashr exact i32 %87, 24
  %89 = xor i32 %88, -128
  %90 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 7
  store i32 %89, i32* %90, align 8
  %91 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1
  %92 = bitcast %"struct.ruy::PEMat"* %91 to i24*
  store i24 65537, i24* %92, align 8
  %93 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 3
  %94 = bitcast %"struct.ruy::Type"* %93 to i24*
  store i24 262145, i24* %94, align 8
  %95 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 3
  store i8 0, i8* %95, align 4
  %96 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 0
  %97 = load i32, i32* %96, align 4
  %98 = add i32 %97, 3
  %99 = and i32 %98, -4
  %100 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 0
  store i32 %99, i32* %100, align 4
  %101 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 1
  %102 = load i32, i32* %101, align 4
  %103 = add i32 %102, 15
  %104 = and i32 %103, -16
  %105 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 1
  store i32 %104, i32* %105, align 4
  %106 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 0
  store i8 0, i8* %106, align 1
  %107 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 1
  store i8 4, i8* %107, align 1
  %108 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 2
  store i8 16, i8* %108, align 1
  %109 = and i32 %98, 1020
  %110 = icmp eq i32 %109, 0
  %111 = add nsw i32 %99, 64
  %112 = select i1 %110, i32 %111, i32 %99
  %113 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 2
  store i32 %112, i32* %113, align 4
  %114 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 4
  %115 = load i32, i32* %114, align 8
  %116 = shl i32 %115, 24
  %117 = ashr exact i32 %116, 24
  %118 = xor i32 %117, -128
  br label %119

119:                                              ; preds = %60, %13
  %120 = phi i32 [ %118, %60 ], [ %59, %13 ]
  %121 = phi void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* [ @_ZN3ruy7RunPackILNS_4PathE16ENS_17FixedKernelLayoutILNS_5OrderE0ELi4ELi16EEEhaEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii, %60 ], [ @_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEhhEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii, %13 ]
  %122 = phi void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)* [ @_ZN3ruy9RunKernelILNS_4PathE16EaasNS_9MulParamsIisEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE, %60 ], [ @_ZN3ruy9RunKernelILNS_4PathE2EhhsNS_9MulParamsIisEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE, %13 ]
  %123 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 7
  store i32 %120, i32* %123, align 8
  %124 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 1, i32 0, i64 0
  store void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* %121, void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)** %124, align 8
  %125 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 1, i32 0, i64 1
  store void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* %121, void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)** %125, align 8
  %126 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 2
  store void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)* %122, void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)** %126, align 8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy9RunKernelILNS_4PathE16EaasNS_9MulParamsIisEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE(i32, %"class.ruy::SidePair.104"* dereferenceable(112), i8*, %"class.ruy::SidePair.105"* dereferenceable(8), %"class.ruy::SidePair.105"* dereferenceable(8), %"struct.ruy::EMat"*) #1 comdat {
  %7 = alloca %"struct.ruy::KernelParams8bit", align 8
  %8 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 2
  %9 = bitcast i8** %8 to i16**
  %10 = load i16*, i16** %9, align 8, !noalias !1220
  %11 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 0
  %12 = load i32, i32* %11, align 4
  %13 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 1
  %14 = load i32, i32* %13, align 4
  %15 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 2
  %16 = load i32, i32* %15, align 4
  %17 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 4
  %18 = load i32, i32* %17, align 8, !noalias !1220
  %19 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 2
  %20 = load i8*, i8** %19, align 8, !noalias !1223
  %21 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 5
  %22 = bitcast i8** %21 to i32**
  %23 = load i32*, i32** %22, align 8, !noalias !1223
  %24 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 6, i32 0
  %25 = load i32, i32* %24, align 4
  %26 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 6, i32 2
  %27 = load i32, i32* %26, align 4
  %28 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 7
  %29 = load i32, i32* %28, align 8, !noalias !1223
  %30 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 2
  %31 = load i8*, i8** %30, align 8, !noalias !1226
  %32 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 5
  %33 = bitcast i8** %32 to i32**
  %34 = load i32*, i32** %33, align 8, !noalias !1226
  %35 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 6, i32 2
  %36 = load i32, i32* %35, align 4
  %37 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 7
  %38 = load i32, i32* %37, align 8, !noalias !1226
  %39 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %3, i64 0, i32 0, i64 0
  %40 = load i32, i32* %39, align 4
  %41 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %3, i64 0, i32 0, i64 1
  %42 = load i32, i32* %41, align 4
  %43 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %4, i64 0, i32 0, i64 0
  %44 = load i32, i32* %43, align 4
  %45 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %4, i64 0, i32 0, i64 1
  %46 = load i32, i32* %45, align 4
  %47 = bitcast %"struct.ruy::KernelParams8bit"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1352, i8* nonnull %47) #19
  %48 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 1
  %49 = bitcast i32** %48 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %49, i8 -86, i64 1344, i1 false) #19
  %50 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 27, i64 0
  %51 = bitcast i32* %50 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 4 %51, i8 0, i64 64, i1 false) #19
  %52 = mul nsw i32 %40, %27
  %53 = sext i32 %52 to i64
  %54 = getelementptr inbounds i8, i8* %20, i64 %53
  %55 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 3
  store i8* %54, i8** %55, align 8
  %56 = mul nsw i32 %42, %36
  %57 = sext i32 %56 to i64
  %58 = getelementptr inbounds i8, i8* %31, i64 %57
  %59 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 6
  store i8* %58, i8** %59, align 8
  %60 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 24
  store i8 0, i8* %60, align 8
  %61 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 0
  store i32* %50, i32** %61, align 8
  %62 = bitcast i8* %2 to i32**
  %63 = load i32*, i32** %62, align 8
  %64 = icmp eq i32* %63, null
  br i1 %64, label %66, label %65

65:                                               ; preds = %6
  store i32* %63, i32** %61, align 8
  store i8 1, i8* %60, align 8
  br label %66

66:                                               ; preds = %65, %6
  %67 = phi i8 [ 0, %6 ], [ 1, %65 ]
  %68 = icmp eq i32* %23, null
  br i1 %68, label %72, label %69

69:                                               ; preds = %66
  %70 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 1
  store i32* %23, i32** %70, align 8
  %71 = or i8 %67, 2
  store i8 %71, i8* %60, align 8
  br label %72

72:                                               ; preds = %69, %66
  %73 = phi i8 [ %67, %66 ], [ %71, %69 ]
  %74 = icmp eq i32* %34, null
  br i1 %74, label %78, label %75

75:                                               ; preds = %72
  %76 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 2
  store i32* %34, i32** %76, align 8
  %77 = or i8 %73, 4
  store i8 %77, i8* %60, align 8
  br label %78

78:                                               ; preds = %75, %72
  %79 = phi i8 [ %73, %72 ], [ %77, %75 ]
  %80 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 12
  store i32 %40, i32* %80, align 8
  %81 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 13
  store i32 %42, i32* %81, align 4
  %82 = add nsw i32 %44, -16
  %83 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 14
  store i32 %82, i32* %83, align 8
  %84 = add nsw i32 %46, -16
  %85 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 15
  store i32 %84, i32* %85, align 4
  %86 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 18
  store i32 %27, i32* %86, align 8
  %87 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 19
  store i32 %36, i32* %87, align 4
  %88 = shl i32 %16, 1
  %89 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 20
  store i32 %88, i32* %89, align 8
  %90 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 8
  store i32 %29, i32* %90, align 8
  %91 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 9
  store i32 %38, i32* %91, align 4
  %92 = shl i32 %18, 16
  %93 = ashr exact i32 %92, 16
  %94 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 10
  store i32 %93, i32* %94, align 8
  %95 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 21
  store i32 %25, i32* %95, align 4
  %96 = mul i32 %29, %25
  %97 = mul i32 %96, %38
  %98 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 11
  store i32 %97, i32* %98, align 4
  %99 = getelementptr inbounds i8, i8* %2, i64 16
  %100 = bitcast i8* %99 to i32**
  %101 = load i32*, i32** %100, align 8
  %102 = icmp eq i32* %101, null
  br i1 %102, label %113, label %103

103:                                              ; preds = %78
  %104 = ptrtoint i32* %101 to i64
  %105 = or i8 %79, 24
  store i8 %105, i8* %60, align 8
  %106 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 4
  %107 = bitcast i32** %106 to i64*
  store i64 %104, i64* %107, align 8
  %108 = getelementptr inbounds i8, i8* %2, i64 24
  %109 = bitcast i8* %108 to i64*
  %110 = load i64, i64* %109, align 8
  %111 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 5
  %112 = bitcast i32** %111 to i64*
  store i64 %110, i64* %112, align 8
  br label %150

113:                                              ; preds = %78
  %114 = getelementptr inbounds i8, i8* %2, i64 12
  %115 = bitcast i8* %114 to i32*
  %116 = load i32, i32* %115, align 4
  %117 = icmp sgt i32 %116, 0
  br i1 %117, label %118, label %120

118:                                              ; preds = %113
  %119 = or i8 %79, 16
  store i8 %119, i8* %60, align 8
  br label %120

120:                                              ; preds = %118, %113
  %121 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 29, i64 0
  %122 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 4
  store i32* %121, i32** %122, align 8
  %123 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 30, i64 0
  %124 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 5
  store i32* %123, i32** %124, align 8
  %125 = getelementptr inbounds i8, i8* %2, i64 8
  %126 = bitcast i8* %125 to i32*
  %127 = load i32, i32* %126, align 8
  %128 = insertelement <4 x i32> undef, i32 %127, i32 0
  %129 = shufflevector <4 x i32> %128, <4 x i32> undef, <4 x i32> zeroinitializer
  %130 = bitcast i32* %121 to <4 x i32>*
  store <4 x i32> %129, <4 x i32>* %130, align 4
  %131 = insertelement <4 x i32> undef, i32 %116, i32 0
  %132 = shufflevector <4 x i32> %131, <4 x i32> undef, <4 x i32> zeroinitializer
  %133 = bitcast i32* %123 to <4 x i32>*
  store <4 x i32> %132, <4 x i32>* %133, align 4
  %134 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 29, i64 4
  store i32 %127, i32* %134, align 4
  %135 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 30, i64 4
  store i32 %116, i32* %135, align 4
  %136 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 29, i64 5
  store i32 %127, i32* %136, align 4
  %137 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 30, i64 5
  store i32 %116, i32* %137, align 4
  %138 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 29, i64 6
  store i32 %127, i32* %138, align 4
  %139 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 30, i64 6
  store i32 %116, i32* %139, align 4
  %140 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 29, i64 7
  %141 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 30, i64 7
  %142 = bitcast i32* %140 to <4 x i32>*
  store <4 x i32> %129, <4 x i32>* %142, align 4
  %143 = bitcast i32* %141 to <4 x i32>*
  store <4 x i32> %132, <4 x i32>* %143, align 4
  %144 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 29, i64 11
  %145 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 30, i64 11
  %146 = bitcast i32* %144 to <4 x i32>*
  store <4 x i32> %129, <4 x i32>* %146, align 4
  %147 = bitcast i32* %145 to <4 x i32>*
  store <4 x i32> %132, <4 x i32>* %147, align 4
  %148 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 29, i64 15
  store i32 %127, i32* %148, align 4
  %149 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 30, i64 15
  store i32 %116, i32* %149, align 4
  br label %150

150:                                              ; preds = %103, %120
  %151 = getelementptr inbounds i8, i8* %2, i64 32
  %152 = bitcast i8* %151 to i16*
  %153 = load i16, i16* %152, align 8
  %154 = sext i16 %153 to i32
  %155 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 22
  store i32 %154, i32* %155, align 8
  %156 = getelementptr inbounds i8, i8* %2, i64 34
  %157 = bitcast i8* %156 to i16*
  %158 = load i16, i16* %157, align 2
  %159 = sext i16 %158 to i32
  %160 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 23
  store i32 %159, i32* %160, align 4
  %161 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 16
  store i32 %12, i32* %161, align 8
  %162 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 17
  store i32 %14, i32* %162, align 4
  %163 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 25
  store i8 3, i8* %163, align 1
  %164 = mul nsw i32 %42, %16
  %165 = sext i32 %164 to i64
  %166 = getelementptr inbounds i16, i16* %10, i64 %165
  %167 = sext i32 %40 to i64
  %168 = getelementptr inbounds i16, i16* %166, i64 %167
  %169 = getelementptr inbounds %"struct.ruy::KernelParams8bit", %"struct.ruy::KernelParams8bit"* %7, i64 0, i32 7
  %170 = bitcast i8** %169 to i16**
  store i16* %168, i16** %170, align 8
  %171 = icmp eq i32 %14, 1
  br i1 %171, label %172, label %173

172:                                              ; preds = %150
  call void @_ZN3ruy25Kernel8bitAvx512SingleColERKNS_16KernelParams8bitILi16ELi16EEE(%"struct.ruy::KernelParams8bit"* nonnull dereferenceable(1352) %7) #19
  br label %174

173:                                              ; preds = %150
  call void @_ZN3ruy16Kernel8bitAvx512ERKNS_16KernelParams8bitILi16ELi16EEE(%"struct.ruy::KernelParams8bit"* nonnull dereferenceable(1352) %7) #19
  br label %174

174:                                              ; preds = %172, %173
  call void @llvm.lifetime.end.p0i8(i64 1352, i8* nonnull %47) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy9RunKernelILNS_4PathE2EhhsNS_9MulParamsIisEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE(i32, %"class.ruy::SidePair.104"* dereferenceable(112), i8*, %"class.ruy::SidePair.105"* dereferenceable(8), %"class.ruy::SidePair.105"* dereferenceable(8), %"struct.ruy::EMat"*) #1 comdat {
  %7 = alloca %"struct.ruy::Kernel.464", align 1
  %8 = alloca %"struct.ruy::Mat.463", align 8
  %9 = alloca %"struct.ruy::PMat.161", align 8
  %10 = alloca %"struct.ruy::PMat.161", align 8
  %11 = bitcast %"struct.ruy::Mat.463"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %11) #19
  %12 = getelementptr inbounds %"struct.ruy::Mat.463", %"struct.ruy::Mat.463"* %8, i64 0, i32 2
  %13 = getelementptr inbounds %"struct.ruy::Mat.463", %"struct.ruy::Mat.463"* %8, i64 0, i32 3
  %14 = getelementptr inbounds %"struct.ruy::Mat.463", %"struct.ruy::Mat.463"* %8, i64 0, i32 1
  %15 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 2
  %16 = bitcast i8** %15 to i64*
  %17 = bitcast %"struct.ruy::Mat.463"* %8 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %17, i8 -86, i64 32, i1 false)
  %18 = load i64, i64* %16, align 8, !noalias !1229
  %19 = bitcast %"struct.ruy::Mat.463"* %8 to i64*
  store i64 %18, i64* %19, align 8, !alias.scope !1229
  %20 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3
  %21 = bitcast %"struct.ruy::MatLayout"* %14 to i8*
  %22 = bitcast %"struct.ruy::MatLayout"* %20 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %21, i8* align 4 %22, i64 13, i1 false) #19
  %23 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 4
  %24 = load i32, i32* %23, align 8, !noalias !1229
  %25 = trunc i32 %24 to i16
  store i16 %25, i16* %12, align 8, !alias.scope !1229
  %26 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 5
  %27 = load i8, i8* %26, align 4, !noalias !1229
  store i8 %27, i8* %13, align 2, !alias.scope !1229
  %28 = bitcast %"struct.ruy::PMat.161"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %28) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %28, i8 -86, i64 40, i1 false) #19, !alias.scope !1232
  %29 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %9, i64 0, i32 3
  %30 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 2
  %31 = bitcast i8** %30 to i64*
  %32 = load i64, i64* %31, align 8, !noalias !1232
  %33 = bitcast %"struct.ruy::PMat.161"* %9 to i64*
  store i64 %32, i64* %33, align 8, !alias.scope !1232
  %34 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 5
  %35 = bitcast i8** %34 to i64*
  %36 = load i64, i64* %35, align 8, !noalias !1232
  %37 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %9, i64 0, i32 1
  %38 = bitcast i32** %37 to i64*
  store i64 %36, i64* %38, align 8, !alias.scope !1232
  %39 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 6
  %40 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %9, i64 0, i32 2
  %41 = bitcast %"struct.ruy::PMatLayout"* %40 to i8*
  %42 = bitcast %"struct.ruy::PMatLayout"* %39 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %41, i8* align 4 %42, i64 16, i1 false) #19
  %43 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 7
  %44 = load i32, i32* %43, align 8, !noalias !1232
  store i32 %44, i32* %29, align 8, !alias.scope !1232
  %45 = bitcast %"struct.ruy::PMat.161"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %45) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %45, i8 -86, i64 40, i1 false) #19, !alias.scope !1235
  %46 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %10, i64 0, i32 3
  %47 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 2
  %48 = bitcast i8** %47 to i64*
  %49 = load i64, i64* %48, align 8, !noalias !1235
  %50 = bitcast %"struct.ruy::PMat.161"* %10 to i64*
  store i64 %49, i64* %50, align 8, !alias.scope !1235
  %51 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 5
  %52 = bitcast i8** %51 to i64*
  %53 = load i64, i64* %52, align 8, !noalias !1235
  %54 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %10, i64 0, i32 1
  %55 = bitcast i32** %54 to i64*
  store i64 %53, i64* %55, align 8, !alias.scope !1235
  %56 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 6
  %57 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %10, i64 0, i32 2
  %58 = bitcast %"struct.ruy::PMatLayout"* %57 to i8*
  %59 = bitcast %"struct.ruy::PMatLayout"* %56 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %58, i8* align 4 %59, i64 16, i1 false) #19
  %60 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 7
  %61 = load i32, i32* %60, align 8, !noalias !1235
  store i32 %61, i32* %46, align 8, !alias.scope !1235
  %62 = bitcast i8* %2 to %"class.ruy::MulParams.461"*
  %63 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %3, i64 0, i32 0, i64 0
  %64 = load i32, i32* %63, align 4
  %65 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %3, i64 0, i32 0, i64 1
  %66 = load i32, i32* %65, align 4
  %67 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %4, i64 0, i32 0, i64 0
  %68 = load i32, i32* %67, align 4
  %69 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %4, i64 0, i32 0, i64 1
  %70 = load i32, i32* %69, align 4
  %71 = getelementptr inbounds %"struct.ruy::Kernel.464", %"struct.ruy::Kernel.464"* %7, i64 0, i32 0
  call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %71) #19
  store i8 -86, i8* %71, align 1
  call void @_ZNK3ruy6KernelILNS_4PathE2EhhsNS_9MulParamsIisEEE3RunERKNS_4PMatIhEES8_RKS3_iiiiPNS_3MatIsEE(%"struct.ruy::Kernel.464"* nonnull %7, %"struct.ruy::PMat.161"* nonnull dereferenceable(40) %9, %"struct.ruy::PMat.161"* nonnull dereferenceable(40) %10, %"class.ruy::MulParams.461"* dereferenceable(40) %62, i32 %64, i32 %66, i32 %68, i32 %70, %"struct.ruy::Mat.463"* nonnull %8) #19
  call void @llvm.lifetime.end.p0i8(i64 1, i8* nonnull %71) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %45) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %28) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %11) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK3ruy6KernelILNS_4PathE2EhhsNS_9MulParamsIisEEE3RunERKNS_4PMatIhEES8_RKS3_iiiiPNS_3MatIsEE(%"struct.ruy::Kernel.464"*, %"struct.ruy::PMat.161"* dereferenceable(40), %"struct.ruy::PMat.161"* dereferenceable(40), %"class.ruy::MulParams.461"* dereferenceable(40), i32, i32, i32, i32, %"struct.ruy::Mat.463"*) local_unnamed_addr #1 comdat align 2 {
  %10 = getelementptr inbounds %"struct.ruy::Mat.463", %"struct.ruy::Mat.463"* %8, i64 0, i32 1, i32 0
  %11 = load i32, i32* %10, align 4
  %12 = icmp slt i32 %11, %6
  %13 = select i1 %12, i32 %11, i32 %6
  %14 = getelementptr inbounds %"struct.ruy::Mat.463", %"struct.ruy::Mat.463"* %8, i64 0, i32 1, i32 1
  %15 = load i32, i32* %14, align 4
  %16 = icmp slt i32 %15, %7
  %17 = select i1 %16, i32 %15, i32 %7
  %18 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %1, i64 0, i32 2, i32 0
  %19 = load i32, i32* %18, align 8
  %20 = icmp sgt i32 %13, %4
  br i1 %20, label %21, label %60

21:                                               ; preds = %9
  %22 = icmp sgt i32 %17, %5
  %23 = icmp sgt i32 %19, 0
  %24 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %1, i64 0, i32 0
  %25 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %1, i64 0, i32 2, i32 4, i32 1
  %26 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %1, i64 0, i32 2, i32 4, i32 2
  %27 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %1, i64 0, i32 2, i32 3
  %28 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %1, i64 0, i32 2, i32 2
  %29 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %1, i64 0, i32 2, i32 4, i32 0
  %30 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %2, i64 0, i32 0
  %31 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %2, i64 0, i32 2, i32 4, i32 1
  %32 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %2, i64 0, i32 2, i32 4, i32 2
  %33 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %2, i64 0, i32 2, i32 3
  %34 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %2, i64 0, i32 2, i32 2
  %35 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %2, i64 0, i32 2, i32 4, i32 0
  %36 = getelementptr inbounds %"class.ruy::MulParams.461", %"class.ruy::MulParams.461"* %3, i64 0, i32 0
  %37 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %1, i64 0, i32 3
  %38 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %2, i64 0, i32 1
  %39 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %2, i64 0, i32 3
  %40 = getelementptr inbounds %"struct.ruy::PMat.161", %"struct.ruy::PMat.161"* %1, i64 0, i32 1
  %41 = getelementptr inbounds %"class.ruy::MulParams.461", %"class.ruy::MulParams.461"* %3, i64 0, i32 3
  %42 = getelementptr inbounds %"class.ruy::MulParams.461", %"class.ruy::MulParams.461"* %3, i64 0, i32 1
  %43 = getelementptr inbounds %"class.ruy::MulParams.461", %"class.ruy::MulParams.461"* %3, i64 0, i32 4
  %44 = getelementptr inbounds %"class.ruy::MulParams.461", %"class.ruy::MulParams.461"* %3, i64 0, i32 2
  %45 = getelementptr inbounds %"struct.ruy::Mat.463", %"struct.ruy::Mat.463"* %8, i64 0, i32 2
  %46 = getelementptr inbounds %"class.ruy::MulParams.461", %"class.ruy::MulParams.461"* %3, i64 0, i32 6
  %47 = getelementptr inbounds %"class.ruy::MulParams.461", %"class.ruy::MulParams.461"* %3, i64 0, i32 5
  %48 = getelementptr inbounds %"struct.ruy::Mat.463", %"struct.ruy::Mat.463"* %8, i64 0, i32 0, i32 0
  %49 = getelementptr inbounds %"struct.ruy::Mat.463", %"struct.ruy::Mat.463"* %8, i64 0, i32 1, i32 3
  %50 = getelementptr inbounds %"struct.ruy::Mat.463", %"struct.ruy::Mat.463"* %8, i64 0, i32 1, i32 2
  %51 = sext i32 %5 to i64
  %52 = sext i32 %17 to i64
  %53 = sext i32 %4 to i64
  %54 = sext i32 %13 to i64
  br label %55

55:                                               ; preds = %21, %113
  %56 = phi i64 [ %53, %21 ], [ %114, %113 ]
  br i1 %22, label %57, label %113

57:                                               ; preds = %55
  %58 = trunc i64 %56 to i32
  %59 = trunc i64 %56 to i32
  br label %61

60:                                               ; preds = %113, %9
  ret void

61:                                               ; preds = %57, %209
  %62 = phi i64 [ %51, %57 ], [ %218, %209 ]
  br i1 %23, label %63, label %116

63:                                               ; preds = %61
  %64 = load i8*, i8** %24, align 8
  %65 = load i8, i8* %25, align 1
  %66 = zext i8 %65 to i32
  %67 = sub nsw i32 0, %66
  %68 = load i8, i8* %26, align 1
  %69 = zext i8 %68 to i32
  %70 = sub nsw i32 0, %69
  %71 = and i32 %58, %70
  %72 = load i8, i8* %27, align 4
  %73 = icmp eq i8 %72, 0
  %74 = load i32, i32* %28, align 4
  %75 = select i1 %73, i32 %69, i32 %74
  %76 = icmp eq i8 %72, 1
  %77 = select i1 %76, i32 %66, i32 %74
  %78 = mul nsw i32 %77, %71
  %79 = sub nsw i32 %58, %71
  %80 = load i8, i8* %29, align 1
  %81 = icmp eq i8 %80, 0
  %82 = select i1 %81, i8 1, i8 %68
  %83 = zext i8 %82 to i32
  %84 = icmp eq i8 %80, 1
  %85 = select i1 %84, i8 1, i8 %65
  %86 = zext i8 %85 to i32
  %87 = mul nsw i32 %79, %86
  %88 = load i8*, i8** %30, align 8
  %89 = load i8, i8* %31, align 1
  %90 = zext i8 %89 to i32
  %91 = sub nsw i32 0, %90
  %92 = load i8, i8* %32, align 1
  %93 = zext i8 %92 to i32
  %94 = sub nsw i32 0, %93
  %95 = trunc i64 %62 to i32
  %96 = and i32 %95, %94
  %97 = load i8, i8* %33, align 4
  %98 = icmp eq i8 %97, 0
  %99 = load i32, i32* %34, align 4
  %100 = select i1 %98, i32 %93, i32 %99
  %101 = icmp eq i8 %97, 1
  %102 = select i1 %101, i32 %90, i32 %99
  %103 = mul nsw i32 %102, %96
  %104 = sub nsw i32 %95, %96
  %105 = load i8, i8* %35, align 1
  %106 = icmp eq i8 %105, 0
  %107 = select i1 %106, i8 1, i8 %92
  %108 = zext i8 %107 to i32
  %109 = icmp eq i8 %105, 1
  %110 = select i1 %109, i8 1, i8 %89
  %111 = zext i8 %110 to i32
  %112 = mul nsw i32 %104, %111
  br label %120

113:                                              ; preds = %209, %55
  %114 = add nsw i64 %56, 1
  %115 = icmp slt i64 %114, %54
  br i1 %115, label %55, label %60

116:                                              ; preds = %120, %61
  %117 = phi i32 [ 0, %61 ], [ %146, %120 ]
  %118 = load i32*, i32** %36, align 8
  %119 = icmp eq i32* %118, null
  br i1 %119, label %153, label %149

120:                                              ; preds = %120, %63
  %121 = phi i32 [ 0, %63 ], [ %147, %120 ]
  %122 = phi i32 [ 0, %63 ], [ %146, %120 ]
  %123 = and i32 %121, %67
  %124 = mul nsw i32 %75, %123
  %125 = sub nsw i32 %121, %123
  %126 = mul nsw i32 %125, %83
  %127 = add i32 %124, %78
  %128 = add i32 %127, %87
  %129 = add i32 %128, %126
  %130 = sext i32 %129 to i64
  %131 = getelementptr inbounds i8, i8* %64, i64 %130
  %132 = load i8, i8* %131, align 1
  %133 = zext i8 %132 to i32
  %134 = and i32 %121, %91
  %135 = mul nsw i32 %100, %134
  %136 = sub nsw i32 %121, %134
  %137 = mul nsw i32 %136, %108
  %138 = add i32 %135, %103
  %139 = add i32 %138, %112
  %140 = add i32 %139, %137
  %141 = sext i32 %140 to i64
  %142 = getelementptr inbounds i8, i8* %88, i64 %141
  %143 = load i8, i8* %142, align 1
  %144 = zext i8 %143 to i32
  %145 = mul nuw nsw i32 %144, %133
  %146 = add nuw nsw i32 %145, %122
  %147 = add nuw nsw i32 %121, 1
  %148 = icmp eq i32 %147, %19
  br i1 %148, label %116, label %120

149:                                              ; preds = %116
  %150 = getelementptr inbounds i32, i32* %118, i64 %56
  %151 = load i32, i32* %150, align 4
  %152 = add nsw i32 %151, %117
  br label %153

153:                                              ; preds = %116, %149
  %154 = phi i32 [ %117, %116 ], [ %152, %149 ]
  %155 = load i32, i32* %37, align 8
  %156 = icmp eq i32 %155, 0
  br i1 %156, label %163, label %157

157:                                              ; preds = %153
  %158 = load i32*, i32** %38, align 8
  %159 = getelementptr inbounds i32, i32* %158, i64 %62
  %160 = load i32, i32* %159, align 4
  %161 = mul nsw i32 %160, %155
  %162 = sub nsw i32 %154, %161
  br label %163

163:                                              ; preds = %153, %157
  %164 = phi i32 [ %154, %153 ], [ %162, %157 ]
  %165 = load i32, i32* %39, align 8
  %166 = icmp eq i32 %165, 0
  br i1 %166, label %178, label %167

167:                                              ; preds = %163
  %168 = load i32*, i32** %40, align 8
  %169 = getelementptr inbounds i32, i32* %168, i64 %56
  %170 = load i32, i32* %169, align 4
  %171 = mul nsw i32 %170, %165
  %172 = sub nsw i32 %164, %171
  %173 = or i1 %156, %166
  br i1 %173, label %178, label %174

174:                                              ; preds = %167
  %175 = mul i32 %155, %19
  %176 = mul i32 %175, %165
  %177 = add nsw i32 %172, %176
  br label %178

178:                                              ; preds = %163, %167, %174
  %179 = phi i32 [ %172, %167 ], [ %177, %174 ], [ %164, %163 ]
  %180 = load i32*, i32** %41, align 8
  %181 = icmp eq i32* %180, null
  %182 = getelementptr inbounds i32, i32* %180, i64 %56
  %183 = select i1 %181, i32* %42, i32* %182
  %184 = load i32, i32* %183, align 4
  %185 = load i32*, i32** %43, align 8
  %186 = icmp eq i32* %185, null
  %187 = getelementptr inbounds i32, i32* %185, i64 %56
  %188 = select i1 %186, i32* %44, i32* %187
  %189 = load i32, i32* %188, align 4
  %190 = tail call i32 @_ZN3ruy6detail29MultiplyByQuantizedMultiplierEiii(i32 %179, i32 %184, i32 %189) #19
  %191 = load i16, i16* %45, align 8
  %192 = sext i16 %191 to i32
  %193 = add nsw i32 %190, %192
  %194 = load i16, i16* %46, align 2
  %195 = sext i16 %194 to i32
  %196 = icmp sgt i32 %193, %195
  %197 = select i1 %196, i32 %195, i32 %193
  %198 = load i16, i16* %47, align 8
  %199 = sext i16 %198 to i32
  %200 = icmp slt i32 %197, %199
  %201 = select i1 %200, i32 %199, i32 %197
  %202 = trunc i32 %201 to i16
  %203 = load i16*, i16** %48, align 8
  %204 = load i8, i8* %49, align 4
  %205 = load i32, i32* %50, align 4
  switch i8 %204, label %206 [
    i8 0, label %207
    i8 1, label %209
  ]

206:                                              ; preds = %178
  br label %207

207:                                              ; preds = %206, %178
  %208 = phi i32 [ 1, %178 ], [ %205, %206 ]
  br label %209

209:                                              ; preds = %178, %207
  %210 = phi i32 [ %208, %207 ], [ %205, %178 ]
  %211 = phi i32 [ %205, %207 ], [ 1, %178 ]
  %212 = mul nsw i32 %210, %59
  %213 = trunc i64 %62 to i32
  %214 = mul nsw i32 %211, %213
  %215 = add nsw i32 %214, %212
  %216 = sext i32 %215 to i64
  %217 = getelementptr inbounds i16, i16* %203, i64 %216
  store i16 %202, i16* %217, align 2
  %218 = add nsw i64 %62, 1
  %219 = icmp slt i64 %218, %52
  br i1 %219, label %61, label %113
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy19PopulateTrMulParamsILNS_4PathE8EhhsNS_9MulParamsIisEEEEvPNS_11TrMulParamsE(%"struct.ruy::TrMulParams"*) local_unnamed_addr #1 comdat {
  %2 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 3
  %3 = load i8, i8* %2, align 4
  %4 = icmp eq i8 %3, 0
  br i1 %4, label %5, label %13

5:                                                ; preds = %1
  %6 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 3
  %7 = load i8, i8* %6, align 4
  %8 = icmp eq i8 %7, 0
  br i1 %8, label %9, label %13

9:                                                ; preds = %5
  %10 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 4, i32 3, i32 3
  %11 = load i8, i8* %10, align 4
  %12 = icmp eq i8 %11, 0
  br i1 %12, label %60, label %13

13:                                               ; preds = %1, %5, %9
  %14 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 0
  store i8 2, i8* %14, align 8
  %15 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0
  %16 = bitcast %"struct.ruy::PEMat"* %15 to i24*
  store i24 65536, i24* %16, align 8
  %17 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 3
  %18 = bitcast %"struct.ruy::Type"* %17 to i24*
  store i24 262145, i24* %18, align 8
  %19 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 3
  store i8 0, i8* %19, align 4
  %20 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 0
  %21 = load i32, i32* %20, align 4
  %22 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 0
  store i32 %21, i32* %22, align 4
  %23 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 1
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 1
  store i32 %24, i32* %25, align 4
  %26 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 0
  store i8 0, i8* %26, align 1
  %27 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 1
  store i8 1, i8* %27, align 1
  %28 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 2
  store i8 1, i8* %28, align 1
  %29 = and i32 %21, 1023
  %30 = icmp eq i32 %29, 0
  %31 = add nsw i32 %21, 64
  %32 = select i1 %30, i32 %31, i32 %21
  %33 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 2
  store i32 %32, i32* %33, align 4
  %34 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 4
  %35 = load i32, i32* %34, align 8
  %36 = and i32 %35, 255
  %37 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 7
  store i32 %36, i32* %37, align 8
  %38 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1
  %39 = bitcast %"struct.ruy::PEMat"* %38 to i24*
  store i24 65536, i24* %39, align 8
  %40 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 3
  %41 = bitcast %"struct.ruy::Type"* %40 to i24*
  store i24 262145, i24* %41, align 8
  %42 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 3
  store i8 0, i8* %42, align 4
  %43 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 0
  %44 = load i32, i32* %43, align 4
  %45 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 0
  store i32 %44, i32* %45, align 4
  %46 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 1
  %47 = load i32, i32* %46, align 4
  %48 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 1
  store i32 %47, i32* %48, align 4
  %49 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 0
  store i8 0, i8* %49, align 1
  %50 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 1
  store i8 1, i8* %50, align 1
  %51 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 2
  store i8 1, i8* %51, align 1
  %52 = and i32 %44, 1023
  %53 = icmp eq i32 %52, 0
  %54 = add nsw i32 %44, 64
  %55 = select i1 %53, i32 %54, i32 %44
  %56 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 2
  store i32 %55, i32* %56, align 4
  %57 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 4
  %58 = load i32, i32* %57, align 8
  %59 = and i32 %58, 255
  br label %119

60:                                               ; preds = %9
  %61 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 0
  store i8 8, i8* %61, align 8
  %62 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0
  %63 = bitcast %"struct.ruy::PEMat"* %62 to i24*
  store i24 65537, i24* %63, align 8
  %64 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 3
  %65 = bitcast %"struct.ruy::Type"* %64 to i24*
  store i24 262145, i24* %65, align 8
  %66 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 3
  store i8 0, i8* %66, align 4
  %67 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 0
  %68 = load i32, i32* %67, align 4
  %69 = add i32 %68, 3
  %70 = and i32 %69, -4
  %71 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 0
  store i32 %70, i32* %71, align 4
  %72 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 3, i32 1
  %73 = load i32, i32* %72, align 4
  %74 = add i32 %73, 7
  %75 = and i32 %74, -8
  %76 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 1
  store i32 %75, i32* %76, align 4
  %77 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 0
  store i8 0, i8* %77, align 1
  %78 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 1
  store i8 4, i8* %78, align 1
  %79 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 4, i32 2
  store i8 8, i8* %79, align 1
  %80 = and i32 %69, 1020
  %81 = icmp eq i32 %80, 0
  %82 = add nsw i32 %70, 64
  %83 = select i1 %81, i32 %82, i32 %70
  %84 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 6, i32 2
  store i32 %83, i32* %84, align 4
  %85 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 0, i32 4
  %86 = load i32, i32* %85, align 8
  %87 = shl i32 %86, 24
  %88 = ashr exact i32 %87, 24
  %89 = xor i32 %88, -128
  %90 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 0, i32 7
  store i32 %89, i32* %90, align 8
  %91 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1
  %92 = bitcast %"struct.ruy::PEMat"* %91 to i24*
  store i24 65537, i24* %92, align 8
  %93 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 3
  %94 = bitcast %"struct.ruy::Type"* %93 to i24*
  store i24 262145, i24* %94, align 8
  %95 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 3
  store i8 0, i8* %95, align 4
  %96 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 0
  %97 = load i32, i32* %96, align 4
  %98 = add i32 %97, 3
  %99 = and i32 %98, -4
  %100 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 0
  store i32 %99, i32* %100, align 4
  %101 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 3, i32 1
  %102 = load i32, i32* %101, align 4
  %103 = add i32 %102, 7
  %104 = and i32 %103, -8
  %105 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 1
  store i32 %104, i32* %105, align 4
  %106 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 0
  store i8 0, i8* %106, align 1
  %107 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 1
  store i8 4, i8* %107, align 1
  %108 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 4, i32 2
  store i8 8, i8* %108, align 1
  %109 = and i32 %98, 1020
  %110 = icmp eq i32 %109, 0
  %111 = add nsw i32 %99, 64
  %112 = select i1 %110, i32 %111, i32 %99
  %113 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 6, i32 2
  store i32 %112, i32* %113, align 4
  %114 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 3, i32 0, i64 1, i32 4
  %115 = load i32, i32* %114, align 8
  %116 = shl i32 %115, 24
  %117 = ashr exact i32 %116, 24
  %118 = xor i32 %117, -128
  br label %119

119:                                              ; preds = %60, %13
  %120 = phi i32 [ %118, %60 ], [ %59, %13 ]
  %121 = phi void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* [ @_ZN3ruy7RunPackILNS_4PathE8ENS_17FixedKernelLayoutILNS_5OrderE0ELi4ELi8EEEhaEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii, %60 ], [ @_ZN3ruy7RunPackILNS_4PathE2ENS_17FixedKernelLayoutILNS_5OrderE0ELi1ELi1EEEhhEEvNS_6TuningERKNS_4EMatEPNS_5PEMatEii, %13 ]
  %122 = phi void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)* [ @_ZN3ruy9RunKernelILNS_4PathE8EaasNS_9MulParamsIisEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE, %60 ], [ @_ZN3ruy9RunKernelILNS_4PathE2EhhsNS_9MulParamsIisEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE, %13 ]
  %123 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 5, i32 0, i64 1, i32 7
  store i32 %120, i32* %123, align 8
  %124 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 1, i32 0, i64 0
  store void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* %121, void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)** %124, align 8
  %125 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 1, i32 0, i64 1
  store void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)* %121, void (i32, %"struct.ruy::EMat"*, %"struct.ruy::PEMat"*, i32, i32)** %125, align 8
  %126 = getelementptr inbounds %"struct.ruy::TrMulParams", %"struct.ruy::TrMulParams"* %0, i64 0, i32 2
  store void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)* %122, void (i32, %"class.ruy::SidePair.104"*, i8*, %"class.ruy::SidePair.105"*, %"class.ruy::SidePair.105"*, %"struct.ruy::EMat"*)** %126, align 8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN3ruy9RunKernelILNS_4PathE8EaasNS_9MulParamsIisEEEEvNS_6TuningERKNS_8SidePairINS_5PEMatEEEPvRKNS5_IiEESD_PNS_4EMatE(i32, %"class.ruy::SidePair.104"* dereferenceable(112), i8*, %"class.ruy::SidePair.105"* dereferenceable(8), %"class.ruy::SidePair.105"* dereferenceable(8), %"struct.ruy::EMat"*) #1 comdat {
  %7 = alloca %"struct.ruy::KernelParams8bit.167", align 8
  %8 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 2
  %9 = bitcast i8** %8 to i16**
  %10 = load i16*, i16** %9, align 8, !noalias !1238
  %11 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 0
  %12 = load i32, i32* %11, align 4
  %13 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 1
  %14 = load i32, i32* %13, align 4
  %15 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 3, i32 2
  %16 = load i32, i32* %15, align 4
  %17 = getelementptr inbounds %"struct.ruy::EMat", %"struct.ruy::EMat"* %5, i64 0, i32 4
  %18 = load i32, i32* %17, align 8, !noalias !1238
  %19 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 2
  %20 = load i8*, i8** %19, align 8, !noalias !1241
  %21 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 5
  %22 = bitcast i8** %21 to i32**
  %23 = load i32*, i32** %22, align 8, !noalias !1241
  %24 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 6, i32 0
  %25 = load i32, i32* %24, align 4
  %26 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 6, i32 2
  %27 = load i32, i32* %26, align 4
  %28 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 0, i32 7
  %29 = load i32, i32* %28, align 8, !noalias !1241
  %30 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 2
  %31 = load i8*, i8** %30, align 8, !noalias !1244
  %32 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 5
  %33 = bitcast i8** %32 to i32**
  %34 = load i32*, i32** %33, align 8, !noalias !1244
  %35 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 6, i32 2
  %36 = load i32, i32* %35, align 4
  %37 = getelementptr inbounds %"class.ruy::SidePair.104", %"class.ruy::SidePair.104"* %1, i64 0, i32 0, i64 1, i32 7
  %38 = load i32, i32* %37, align 8, !noalias !1244
  %39 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %3, i64 0, i32 0, i64 0
  %40 = load i32, i32* %39, align 4
  %41 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %3, i64 0, i32 0, i64 1
  %42 = load i32, i32* %41, align 4
  %43 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %4, i64 0, i32 0, i64 0
  %44 = load i32, i32* %43, align 4
  %45 = getelementptr inbounds %"class.ruy::SidePair.105", %"class.ruy::SidePair.105"* %4, i64 0, i32 0, i64 1
  %46 = load i32, i32* %45, align 4
  %47 = bitcast %"struct.ruy::KernelParams8bit.167"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 488, i8* nonnull %47) #19
  %48 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 1
  %49 = bitcast i32** %48 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %49, i8 -86, i64 480, i1 false) #19
  %50 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 27, i64 0
  %51 = bitcast i32* %50 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 4 %51, i8 0, i64 32, i1 false) #19
  %52 = mul nsw i32 %40, %27
  %53 = sext i32 %52 to i64
  %54 = getelementptr inbounds i8, i8* %20, i64 %53
  %55 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 3
  store i8* %54, i8** %55, align 8
  %56 = mul nsw i32 %42, %36
  %57 = sext i32 %56 to i64
  %58 = getelementptr inbounds i8, i8* %31, i64 %57
  %59 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 6
  store i8* %58, i8** %59, align 8
  %60 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 24
  store i8 0, i8* %60, align 8
  %61 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 0
  store i32* %50, i32** %61, align 8
  %62 = bitcast i8* %2 to i32**
  %63 = load i32*, i32** %62, align 8
  %64 = icmp eq i32* %63, null
  br i1 %64, label %66, label %65

65:                                               ; preds = %6
  store i32* %63, i32** %61, align 8
  store i8 1, i8* %60, align 8
  br label %66

66:                                               ; preds = %65, %6
  %67 = phi i8 [ 0, %6 ], [ 1, %65 ]
  %68 = icmp eq i32* %23, null
  br i1 %68, label %72, label %69

69:                                               ; preds = %66
  %70 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 1
  store i32* %23, i32** %70, align 8
  %71 = or i8 %67, 2
  store i8 %71, i8* %60, align 8
  br label %72

72:                                               ; preds = %69, %66
  %73 = phi i8 [ %67, %66 ], [ %71, %69 ]
  %74 = icmp eq i32* %34, null
  br i1 %74, label %78, label %75

75:                                               ; preds = %72
  %76 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 2
  store i32* %34, i32** %76, align 8
  %77 = or i8 %73, 4
  store i8 %77, i8* %60, align 8
  br label %78

78:                                               ; preds = %75, %72
  %79 = phi i8 [ %73, %72 ], [ %77, %75 ]
  %80 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 12
  store i32 %40, i32* %80, align 8
  %81 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 13
  store i32 %42, i32* %81, align 4
  %82 = add nsw i32 %44, -8
  %83 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 14
  store i32 %82, i32* %83, align 8
  %84 = add nsw i32 %46, -8
  %85 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 15
  store i32 %84, i32* %85, align 4
  %86 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 18
  store i32 %27, i32* %86, align 8
  %87 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 19
  store i32 %36, i32* %87, align 4
  %88 = shl i32 %16, 1
  %89 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 20
  store i32 %88, i32* %89, align 8
  %90 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 8
  store i32 %29, i32* %90, align 8
  %91 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 9
  store i32 %38, i32* %91, align 4
  %92 = shl i32 %18, 16
  %93 = ashr exact i32 %92, 16
  %94 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 10
  store i32 %93, i32* %94, align 8
  %95 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 21
  store i32 %25, i32* %95, align 4
  %96 = mul i32 %29, %25
  %97 = mul i32 %96, %38
  %98 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 11
  store i32 %97, i32* %98, align 4
  %99 = getelementptr inbounds i8, i8* %2, i64 16
  %100 = bitcast i8* %99 to i32**
  %101 = load i32*, i32** %100, align 8
  %102 = icmp eq i32* %101, null
  br i1 %102, label %113, label %103

103:                                              ; preds = %78
  %104 = ptrtoint i32* %101 to i64
  %105 = or i8 %79, 24
  store i8 %105, i8* %60, align 8
  %106 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 4
  %107 = bitcast i32** %106 to i64*
  store i64 %104, i64* %107, align 8
  %108 = getelementptr inbounds i8, i8* %2, i64 24
  %109 = bitcast i8* %108 to i64*
  %110 = load i64, i64* %109, align 8
  %111 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 5
  %112 = bitcast i32** %111 to i64*
  store i64 %110, i64* %112, align 8
  br label %142

113:                                              ; preds = %78
  %114 = getelementptr inbounds i8, i8* %2, i64 12
  %115 = bitcast i8* %114 to i32*
  %116 = load i32, i32* %115, align 4
  %117 = icmp sgt i32 %116, 0
  br i1 %117, label %118, label %120

118:                                              ; preds = %113
  %119 = or i8 %79, 16
  store i8 %119, i8* %60, align 8
  br label %120

120:                                              ; preds = %118, %113
  %121 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 29, i64 0
  %122 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 4
  store i32* %121, i32** %122, align 8
  %123 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 30, i64 0
  %124 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 5
  store i32* %123, i32** %124, align 8
  %125 = getelementptr inbounds i8, i8* %2, i64 8
  %126 = bitcast i8* %125 to i32*
  %127 = load i32, i32* %126, align 8
  %128 = insertelement <4 x i32> undef, i32 %127, i32 0
  %129 = shufflevector <4 x i32> %128, <4 x i32> undef, <4 x i32> zeroinitializer
  %130 = bitcast i32* %121 to <4 x i32>*
  store <4 x i32> %129, <4 x i32>* %130, align 4
  %131 = insertelement <4 x i32> undef, i32 %116, i32 0
  %132 = shufflevector <4 x i32> %131, <4 x i32> undef, <4 x i32> zeroinitializer
  %133 = bitcast i32* %123 to <4 x i32>*
  store <4 x i32> %132, <4 x i32>* %133, align 4
  %134 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 29, i64 4
  store i32 %127, i32* %134, align 4
  %135 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 30, i64 4
  store i32 %116, i32* %135, align 4
  %136 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 29, i64 5
  store i32 %127, i32* %136, align 4
  %137 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 30, i64 5
  store i32 %116, i32* %137, align 4
  %138 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 29, i64 6
  store i32 %127, i32* %138, align 4
  %139 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 30, i64 6
  store i32 %116, i32* %139, align 4
  %140 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 29, i64 7
  store i32 %127, i32* %140, align 4
  %141 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 30, i64 7
  store i32 %116, i32* %141, align 4
  br label %142

142:                                              ; preds = %103, %120
  %143 = getelementptr inbounds i8, i8* %2, i64 32
  %144 = bitcast i8* %143 to i16*
  %145 = load i16, i16* %144, align 8
  %146 = sext i16 %145 to i32
  %147 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 22
  store i32 %146, i32* %147, align 8
  %148 = getelementptr inbounds i8, i8* %2, i64 34
  %149 = bitcast i8* %148 to i16*
  %150 = load i16, i16* %149, align 2
  %151 = sext i16 %150 to i32
  %152 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 23
  store i32 %151, i32* %152, align 4
  %153 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 16
  store i32 %12, i32* %153, align 8
  %154 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 17
  store i32 %14, i32* %154, align 4
  %155 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 25
  store i8 3, i8* %155, align 1
  %156 = mul nsw i32 %42, %16
  %157 = sext i32 %156 to i64
  %158 = getelementptr inbounds i16, i16* %10, i64 %157
  %159 = sext i32 %40 to i64
  %160 = getelementptr inbounds i16, i16* %158, i64 %159
  %161 = getelementptr inbounds %"struct.ruy::KernelParams8bit.167", %"struct.ruy::KernelParams8bit.167"* %7, i64 0, i32 7
  %162 = bitcast i8** %161 to i16**
  store i16* %160, i16** %162, align 8
  %163 = icmp eq i32 %14, 1
  br i1 %163, label %164, label %165

164:                                              ; preds = %142
  call void @_ZN3ruy23Kernel8bitAvx2SingleColERKNS_16KernelParams8bitILi8ELi8EEE(%"struct.ruy::KernelParams8bit.167"* nonnull dereferenceable(488) %7) #19
  br label %166

165:                                              ; preds = %142
  call void @_ZN3ruy14Kernel8bitAvx2ERKNS_16KernelParams8bitILi8ELi8EEE(%"struct.ruy::KernelParams8bit.167"* nonnull dereferenceable(488) %7) #19
  br label %166

166:                                              ; preds = %164, %165
  call void @llvm.lifetime.end.p0i8(i64 488, i8* nonnull %47) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17DispatchGemmShapeIhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENS7_IS8_LS9_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIS8_LS9_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSP_ISR_XT3_EEEPNSP_IT0_XT4_EEERKT5_RKT6_RKT7_(%"class.gemmlowp::GemmContext"*, %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.180"* dereferenceable(24), %"class.gemmlowp::MatrixMap.479"*, %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.std::__1::tuple.481"* dereferenceable(40)) local_unnamed_addr #1 comdat {
  %8 = alloca %"class.gemmlowp::MatrixMap.489", align 8
  %9 = alloca %"class.gemmlowp::MatrixMap", align 8
  %10 = alloca %"class.gemmlowp::MatrixMap.180", align 8
  %11 = alloca %"class.gemmlowp::VectorDup.194", align 4
  %12 = alloca %"class.gemmlowp::VectorDup", align 4
  %13 = alloca %"class.std::__1::tuple.491", align 8
  %14 = alloca %"struct.gemmlowp::DefaultKernel", align 8
  %15 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %3, i64 0, i32 1
  %16 = load i32, i32* %15, align 8
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %3, i64 0, i32 2
  %18 = load i32, i32* %17, align 4
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 2
  %20 = load i32, i32* %19, align 4
  %21 = icmp eq i32 %16, 0
  %22 = icmp eq i32 %18, 0
  %23 = or i1 %21, %22
  %24 = icmp eq i32 %20, 0
  %25 = or i1 %23, %24
  br i1 %25, label %101, label %26

26:                                               ; preds = %7
  %27 = icmp slt i32 %16, %18
  br i1 %27, label %28, label %97

28:                                               ; preds = %26
  %29 = bitcast %"class.gemmlowp::MatrixMap.489"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %29) #19
  %30 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %8, i64 0, i32 1
  %31 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %8, i64 0, i32 2
  %32 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %8, i64 0, i32 3
  %33 = bitcast %"class.gemmlowp::MatrixMap.479"* %3 to i64*
  %34 = bitcast %"class.gemmlowp::MatrixMap.489"* %8 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %34, i8 -86, i64 24, i1 false)
  %35 = load i64, i64* %33, align 8, !noalias !1247
  %36 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %3, i64 0, i32 3
  %37 = load i32, i32* %36, align 8, !noalias !1247
  %38 = bitcast %"class.gemmlowp::MatrixMap.489"* %8 to i64*
  store i64 %35, i64* %38, align 8, !alias.scope !1247
  store i32 %18, i32* %30, align 8, !alias.scope !1247
  store i32 %16, i32* %31, align 4, !alias.scope !1247
  store i32 %37, i32* %32, align 8, !alias.scope !1247
  %39 = bitcast %"class.gemmlowp::MatrixMap"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %39) #19
  %40 = bitcast %"class.gemmlowp::MatrixMap.180"* %2 to i64*
  %41 = load i64, i64* %40, align 8, !noalias !1252
  %42 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %2, i64 0, i32 2
  %43 = load i32, i32* %42, align 4, !noalias !1252
  %44 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %2, i64 0, i32 1
  %45 = load i32, i32* %44, align 8, !noalias !1252
  %46 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %2, i64 0, i32 3
  %47 = load i32, i32* %46, align 8, !noalias !1252
  %48 = bitcast %"class.gemmlowp::MatrixMap"* %9 to i64*
  store i64 %41, i64* %48, align 8, !alias.scope !1252
  %49 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 1
  store i32 %43, i32* %49, align 8, !alias.scope !1252
  %50 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 2
  store i32 %45, i32* %50, align 4, !alias.scope !1252
  %51 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 3
  store i32 %47, i32* %51, align 8, !alias.scope !1252
  %52 = bitcast %"class.gemmlowp::MatrixMap.180"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %52) #19
  %53 = bitcast %"class.gemmlowp::MatrixMap"* %1 to i64*
  %54 = load i64, i64* %53, align 8, !noalias !1257
  %55 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 1
  %56 = load i32, i32* %55, align 8, !noalias !1257
  %57 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 3
  %58 = load i32, i32* %57, align 8, !noalias !1257
  %59 = bitcast %"class.gemmlowp::MatrixMap.180"* %10 to i64*
  store i64 %54, i64* %59, align 8, !alias.scope !1257
  %60 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %10, i64 0, i32 1
  store i32 %20, i32* %60, align 8, !alias.scope !1257
  %61 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %10, i64 0, i32 2
  store i32 %56, i32* %61, align 4, !alias.scope !1257
  %62 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %10, i64 0, i32 3
  store i32 %58, i32* %62, align 8, !alias.scope !1257
  %63 = bitcast %"class.gemmlowp::VectorDup.194"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %63) #19
  %64 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %11, i64 0, i32 0
  %65 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 0
  %66 = load i32, i32* %65, align 4, !noalias !1262
  store i32 %66, i32* %64, align 4, !alias.scope !1262
  %67 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %11, i64 0, i32 1
  %68 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 1
  %69 = load i32, i32* %68, align 4, !noalias !1262
  store i32 %69, i32* %67, align 4, !alias.scope !1262
  %70 = bitcast %"class.gemmlowp::VectorDup"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %70) #19
  %71 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %12, i64 0, i32 0
  %72 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %4, i64 0, i32 0
  %73 = load i32, i32* %72, align 4, !noalias !1267
  store i32 %73, i32* %71, align 4, !alias.scope !1267
  %74 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %12, i64 0, i32 1
  %75 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %4, i64 0, i32 1
  %76 = load i32, i32* %75, align 4, !noalias !1267
  store i32 %76, i32* %74, align 4, !alias.scope !1267
  %77 = bitcast %"class.std::__1::tuple.491"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %77) #19
  %78 = bitcast %"class.std::__1::tuple.481"* %6 to i64*
  %79 = load i64, i64* %78, align 8, !noalias !1272
  %80 = getelementptr inbounds %"class.std::__1::tuple.481", %"class.std::__1::tuple.481"* %6, i64 0, i32 0, i32 0, i32 0, i32 0, i32 1
  %81 = load i32, i32* %80, align 8, !noalias !1272
  %82 = getelementptr inbounds %"class.std::__1::tuple.481", %"class.std::__1::tuple.481"* %6, i64 0, i32 0, i32 1, i32 0
  %83 = bitcast %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %82 to i64*
  %84 = load i64, i64* %83, align 4, !noalias !1283
  %85 = getelementptr inbounds %"class.std::__1::tuple.481", %"class.std::__1::tuple.481"* %6, i64 0, i32 0, i32 1, i32 0, i32 2
  %86 = load i32, i32* %85, align 4, !noalias !1283
  %87 = getelementptr inbounds %"class.std::__1::tuple.481", %"class.std::__1::tuple.481"* %6, i64 0, i32 0, i32 2, i32 0
  %88 = bitcast %"struct.gemmlowp::OutputStageClamp"* %87 to i64*
  %89 = load i64, i64* %88, align 4, !noalias !1283
  %90 = bitcast %"class.std::__1::tuple.491"* %13 to i64*
  store i64 %79, i64* %90, align 8, !alias.scope !1284
  %91 = getelementptr inbounds %"class.std::__1::tuple.491", %"class.std::__1::tuple.491"* %13, i64 0, i32 0, i32 0, i32 0, i32 0, i32 1
  store i32 %81, i32* %91, align 8, !alias.scope !1284
  %92 = getelementptr inbounds %"class.std::__1::tuple.491", %"class.std::__1::tuple.491"* %13, i64 0, i32 0, i32 1
  %93 = bitcast %"class.std::__1::__tuple_leaf.184"* %92 to i64*
  store i64 %84, i64* %93, align 8, !alias.scope !1283
  %94 = getelementptr inbounds %"class.std::__1::tuple.491", %"class.std::__1::tuple.491"* %13, i64 0, i32 0, i32 1, i32 0, i32 2
  store i32 %86, i32* %94, align 8, !alias.scope !1283
  %95 = getelementptr inbounds %"class.std::__1::tuple.491", %"class.std::__1::tuple.491"* %13, i64 0, i32 0, i32 2
  %96 = bitcast %"class.std::__1::__tuple_leaf.185"* %95 to i64*
  store i64 %89, i64* %96, align 4, !alias.scope !1284
  call void @_ZN8gemmlowp17DispatchGemmShapeIhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENS7_IS8_LS9_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIS8_LS9_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSP_ISR_XT3_EEEPNSP_IT0_XT4_EEERKT5_RKT6_RKT7_(%"class.gemmlowp::GemmContext"* %0, %"class.gemmlowp::MatrixMap"* nonnull dereferenceable(24) %9, %"class.gemmlowp::MatrixMap.180"* nonnull dereferenceable(24) %10, %"class.gemmlowp::MatrixMap.489"* nonnull %8, %"class.gemmlowp::VectorDup.194"* nonnull dereferenceable(8) %11, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %12, %"class.std::__1::tuple.491"* nonnull dereferenceable(40) %13)
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %77) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %70) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %63) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %52) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %39) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %29) #19
  br label %101

97:                                               ; preds = %26
  %98 = bitcast %"struct.gemmlowp::DefaultKernel"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %98) #19
  %99 = getelementptr inbounds %"struct.gemmlowp::DefaultKernel", %"struct.gemmlowp::DefaultKernel"* %14, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [6 x i8*] }, { [6 x i8*] }* @_ZTVN8gemmlowp13DefaultKernelINS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %99, align 8
  %100 = getelementptr inbounds %"struct.gemmlowp::DefaultKernel", %"struct.gemmlowp::DefaultKernel"* %14, i64 0, i32 0, i32 0, i32 0, i32 0
  call void @_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSZ_IS11_XT4_EEEPNSZ_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::GemmContext"* %0, %"struct.gemmlowp::KernelBase"* nonnull dereferenceable(8) %100, %"class.gemmlowp::MatrixMap"* dereferenceable(24) %1, %"class.gemmlowp::MatrixMap.180"* dereferenceable(24) %2, %"class.gemmlowp::MatrixMap.479"* %3, %"class.gemmlowp::VectorDup"* dereferenceable(8) %4, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %5, %"class.std::__1::tuple.481"* dereferenceable(40) %6)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %98) #19
  br label %101

101:                                              ; preds = %7, %97, %28
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17DispatchGemmShapeIhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENS7_IS8_LS9_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIS8_LS9_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSP_ISR_XT3_EEEPNSP_IT0_XT4_EEERKT5_RKT6_RKT7_(%"class.gemmlowp::GemmContext"*, %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.180"* dereferenceable(24), %"class.gemmlowp::MatrixMap.489"*, %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.std::__1::tuple.491"* dereferenceable(40)) local_unnamed_addr #1 comdat {
  %8 = alloca %"class.gemmlowp::MatrixMap.479", align 8
  %9 = alloca %"class.gemmlowp::MatrixMap", align 8
  %10 = alloca %"class.gemmlowp::MatrixMap.180", align 8
  %11 = alloca %"class.gemmlowp::VectorDup", align 4
  %12 = alloca %"class.gemmlowp::VectorDup.194", align 4
  %13 = alloca %"class.std::__1::tuple.481", align 8
  %14 = alloca %"struct.gemmlowp::DefaultKernel", align 8
  %15 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %3, i64 0, i32 1
  %16 = load i32, i32* %15, align 8
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %3, i64 0, i32 2
  %18 = load i32, i32* %17, align 4
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 2
  %20 = load i32, i32* %19, align 4
  %21 = icmp eq i32 %16, 0
  %22 = icmp eq i32 %18, 0
  %23 = or i1 %21, %22
  %24 = icmp eq i32 %20, 0
  %25 = or i1 %23, %24
  br i1 %25, label %101, label %26

26:                                               ; preds = %7
  %27 = icmp slt i32 %16, %18
  br i1 %27, label %28, label %97

28:                                               ; preds = %26
  %29 = bitcast %"class.gemmlowp::MatrixMap.479"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %29) #19
  %30 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %8, i64 0, i32 1
  %31 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %8, i64 0, i32 2
  %32 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %8, i64 0, i32 3
  %33 = bitcast %"class.gemmlowp::MatrixMap.489"* %3 to i64*
  %34 = bitcast %"class.gemmlowp::MatrixMap.479"* %8 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %34, i8 -86, i64 24, i1 false)
  %35 = load i64, i64* %33, align 8, !noalias !1287
  %36 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %3, i64 0, i32 3
  %37 = load i32, i32* %36, align 8, !noalias !1287
  %38 = bitcast %"class.gemmlowp::MatrixMap.479"* %8 to i64*
  store i64 %35, i64* %38, align 8, !alias.scope !1287
  store i32 %18, i32* %30, align 8, !alias.scope !1287
  store i32 %16, i32* %31, align 4, !alias.scope !1287
  store i32 %37, i32* %32, align 8, !alias.scope !1287
  %39 = bitcast %"class.gemmlowp::MatrixMap"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %39) #19
  %40 = bitcast %"class.gemmlowp::MatrixMap.180"* %2 to i64*
  %41 = load i64, i64* %40, align 8, !noalias !1292
  %42 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %2, i64 0, i32 2
  %43 = load i32, i32* %42, align 4, !noalias !1292
  %44 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %2, i64 0, i32 1
  %45 = load i32, i32* %44, align 8, !noalias !1292
  %46 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %2, i64 0, i32 3
  %47 = load i32, i32* %46, align 8, !noalias !1292
  %48 = bitcast %"class.gemmlowp::MatrixMap"* %9 to i64*
  store i64 %41, i64* %48, align 8, !alias.scope !1292
  %49 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 1
  store i32 %43, i32* %49, align 8, !alias.scope !1292
  %50 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 2
  store i32 %45, i32* %50, align 4, !alias.scope !1292
  %51 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 3
  store i32 %47, i32* %51, align 8, !alias.scope !1292
  %52 = bitcast %"class.gemmlowp::MatrixMap.180"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %52) #19
  %53 = bitcast %"class.gemmlowp::MatrixMap"* %1 to i64*
  %54 = load i64, i64* %53, align 8, !noalias !1297
  %55 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 1
  %56 = load i32, i32* %55, align 8, !noalias !1297
  %57 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 3
  %58 = load i32, i32* %57, align 8, !noalias !1297
  %59 = bitcast %"class.gemmlowp::MatrixMap.180"* %10 to i64*
  store i64 %54, i64* %59, align 8, !alias.scope !1297
  %60 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %10, i64 0, i32 1
  store i32 %20, i32* %60, align 8, !alias.scope !1297
  %61 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %10, i64 0, i32 2
  store i32 %56, i32* %61, align 4, !alias.scope !1297
  %62 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %10, i64 0, i32 3
  store i32 %58, i32* %62, align 8, !alias.scope !1297
  %63 = bitcast %"class.gemmlowp::VectorDup"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %63) #19
  %64 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %11, i64 0, i32 0
  %65 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %66 = load i32, i32* %65, align 4, !noalias !1302
  store i32 %66, i32* %64, align 4, !alias.scope !1302
  %67 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %11, i64 0, i32 1
  %68 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 1
  %69 = load i32, i32* %68, align 4, !noalias !1302
  store i32 %69, i32* %67, align 4, !alias.scope !1302
  %70 = bitcast %"class.gemmlowp::VectorDup.194"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %70) #19
  %71 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %12, i64 0, i32 0
  %72 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %4, i64 0, i32 0
  %73 = load i32, i32* %72, align 4, !noalias !1307
  store i32 %73, i32* %71, align 4, !alias.scope !1307
  %74 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %12, i64 0, i32 1
  %75 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %4, i64 0, i32 1
  %76 = load i32, i32* %75, align 4, !noalias !1307
  store i32 %76, i32* %74, align 4, !alias.scope !1307
  %77 = bitcast %"class.std::__1::tuple.481"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %77) #19
  %78 = bitcast %"class.std::__1::tuple.491"* %6 to i64*
  %79 = load i64, i64* %78, align 8, !noalias !1312
  %80 = getelementptr inbounds %"class.std::__1::tuple.491", %"class.std::__1::tuple.491"* %6, i64 0, i32 0, i32 0, i32 0, i32 0, i32 1
  %81 = load i32, i32* %80, align 8, !noalias !1312
  %82 = getelementptr inbounds %"class.std::__1::tuple.491", %"class.std::__1::tuple.491"* %6, i64 0, i32 0, i32 1, i32 0
  %83 = bitcast %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %82 to i64*
  %84 = load i64, i64* %83, align 4, !noalias !1323
  %85 = getelementptr inbounds %"class.std::__1::tuple.491", %"class.std::__1::tuple.491"* %6, i64 0, i32 0, i32 1, i32 0, i32 2
  %86 = load i32, i32* %85, align 4, !noalias !1323
  %87 = getelementptr inbounds %"class.std::__1::tuple.491", %"class.std::__1::tuple.491"* %6, i64 0, i32 0, i32 2, i32 0
  %88 = bitcast %"struct.gemmlowp::OutputStageClamp"* %87 to i64*
  %89 = load i64, i64* %88, align 4, !noalias !1323
  %90 = bitcast %"class.std::__1::tuple.481"* %13 to i64*
  store i64 %79, i64* %90, align 8, !alias.scope !1324
  %91 = getelementptr inbounds %"class.std::__1::tuple.481", %"class.std::__1::tuple.481"* %13, i64 0, i32 0, i32 0, i32 0, i32 0, i32 1
  store i32 %81, i32* %91, align 8, !alias.scope !1324
  %92 = getelementptr inbounds %"class.std::__1::tuple.481", %"class.std::__1::tuple.481"* %13, i64 0, i32 0, i32 1
  %93 = bitcast %"class.std::__1::__tuple_leaf.184"* %92 to i64*
  store i64 %84, i64* %93, align 8, !alias.scope !1323
  %94 = getelementptr inbounds %"class.std::__1::tuple.481", %"class.std::__1::tuple.481"* %13, i64 0, i32 0, i32 1, i32 0, i32 2
  store i32 %86, i32* %94, align 8, !alias.scope !1323
  %95 = getelementptr inbounds %"class.std::__1::tuple.481", %"class.std::__1::tuple.481"* %13, i64 0, i32 0, i32 2
  %96 = bitcast %"class.std::__1::__tuple_leaf.185"* %95 to i64*
  store i64 %89, i64* %96, align 4, !alias.scope !1324
  call void @_ZN8gemmlowp17DispatchGemmShapeIhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENS7_IS8_LS9_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIS8_LS9_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSP_ISR_XT3_EEEPNSP_IT0_XT4_EEERKT5_RKT6_RKT7_(%"class.gemmlowp::GemmContext"* %0, %"class.gemmlowp::MatrixMap"* nonnull dereferenceable(24) %9, %"class.gemmlowp::MatrixMap.180"* nonnull dereferenceable(24) %10, %"class.gemmlowp::MatrixMap.479"* nonnull %8, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %11, %"class.gemmlowp::VectorDup.194"* nonnull dereferenceable(8) %12, %"class.std::__1::tuple.481"* nonnull dereferenceable(40) %13)
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %77) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %70) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %63) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %52) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %39) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %29) #19
  br label %101

97:                                               ; preds = %26
  %98 = bitcast %"struct.gemmlowp::DefaultKernel"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %98) #19
  %99 = getelementptr inbounds %"struct.gemmlowp::DefaultKernel", %"struct.gemmlowp::DefaultKernel"* %14, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [6 x i8*] }, { [6 x i8*] }* @_ZTVN8gemmlowp13DefaultKernelINS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %99, align 8
  %100 = getelementptr inbounds %"struct.gemmlowp::DefaultKernel", %"struct.gemmlowp::DefaultKernel"* %14, i64 0, i32 0, i32 0, i32 0, i32 0
  call void @_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSZ_IS11_XT4_EEEPNSZ_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::GemmContext"* %0, %"struct.gemmlowp::KernelBase"* nonnull dereferenceable(8) %100, %"class.gemmlowp::MatrixMap"* dereferenceable(24) %1, %"class.gemmlowp::MatrixMap.180"* dereferenceable(24) %2, %"class.gemmlowp::MatrixMap.489"* %3, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %4, %"class.gemmlowp::VectorDup"* dereferenceable(8) %5, %"class.std::__1::tuple.491"* dereferenceable(40) %6)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %98) #19
  br label %101

101:                                              ; preds = %7, %97, %28
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSZ_IS11_XT4_EEEPNSZ_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::GemmContext"*, %"struct.gemmlowp::KernelBase"* dereferenceable(8), %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.180"* dereferenceable(24), %"class.gemmlowp::MatrixMap.479"*, %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.std::__1::tuple.481"* dereferenceable(40)) local_unnamed_addr #1 comdat {
  %9 = alloca %"class.gemmlowp::SideMap", align 8
  %10 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %11 = alloca %"struct.gemmlowp::BlockParams", align 4
  %12 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %13 = alloca %"class.std::__1::vector.205", align 8
  %14 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %4, i64 0, i32 1
  %15 = load i32, i32* %14, align 8
  %16 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %4, i64 0, i32 2
  %17 = load i32, i32* %16, align 4
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 2
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %"class.gemmlowp::GemmContext", %"class.gemmlowp::GemmContext"* %0, i64 0, i32 0, i32 0, i32 1
  %21 = load i32, i32* %20, align 4
  switch i32 %21, label %34 [
    i32 1, label %54
    i32 0, label %22
  ]

22:                                               ; preds = %8
  %23 = load atomic i8, i8* bitcast (i64* @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count to i8*) acquire, align 8
  %24 = icmp eq i8 %23, 0
  br i1 %24, label %25, label %32, !prof !514

25:                                               ; preds = %22
  %26 = tail call i32 @__cxa_guard_acquire(i64* nonnull @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count) #19
  %27 = icmp eq i32 %26, 0
  br i1 %27, label %32, label %28

28:                                               ; preds = %25
  %29 = tail call i64 @sysconf(i32 83) #19
  %30 = trunc i64 %29 to i32
  store i32 %30, i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count, align 4
  %31 = tail call {}* @llvm.invariant.start.p0i8(i64 4, i8* bitcast (i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count to i8*)) #19
  tail call void @__cxa_guard_release(i64* nonnull @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count) #19
  br label %32

32:                                               ; preds = %28, %25, %22
  %33 = load i32, i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count, align 4
  br label %34

34:                                               ; preds = %32, %8
  %35 = phi i32 [ %33, %32 ], [ %21, %8 ]
  %36 = add i32 %15, 15
  %37 = sdiv i32 %36, 16
  %38 = icmp slt i32 %37, %35
  %39 = select i1 %38, i32 %37, i32 %35
  %40 = icmp sgt i32 %39, 1
  br i1 %40, label %41, label %56

41:                                               ; preds = %34
  %42 = sext i32 %15 to i64
  %43 = sext i32 %17 to i64
  %44 = mul nsw i64 %43, %42
  %45 = sext i32 %19 to i64
  %46 = mul i64 %44, %45
  %47 = lshr i64 %46, 16
  %48 = trunc i64 %47 to i32
  %49 = icmp sgt i32 %39, %48
  %50 = select i1 %49, i32 %48, i32 %39
  %51 = icmp sgt i32 %50, 1
  br i1 %51, label %52, label %54

52:                                               ; preds = %41
  %53 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br label %61

54:                                               ; preds = %41, %8
  %55 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br label %59

56:                                               ; preds = %34
  %57 = icmp eq i32 %39, 1
  %58 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br i1 %57, label %59, label %61

59:                                               ; preds = %54, %56
  %60 = phi %"class.gemmlowp::SingleThreadGemmContext"* [ %55, %54 ], [ %58, %56 ]
  tail call void @_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSY_IS10_XT4_EEEPNSY_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::SingleThreadGemmContext"* %60, %"struct.gemmlowp::KernelBase"* dereferenceable(8) %1, %"class.gemmlowp::MatrixMap"* dereferenceable(24) %2, %"class.gemmlowp::MatrixMap.180"* dereferenceable(24) %3, %"class.gemmlowp::MatrixMap.479"* %4, %"class.gemmlowp::VectorDup"* dereferenceable(8) %5, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.std::__1::tuple.481"* dereferenceable(40) %7)
  br label %303

61:                                               ; preds = %52, %56
  %62 = phi %"class.gemmlowp::SingleThreadGemmContext"* [ %53, %52 ], [ %58, %56 ]
  %63 = phi i32 [ %50, %52 ], [ %39, %56 ]
  %64 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0
  %65 = getelementptr inbounds %"class.gemmlowp::GemmContext", %"class.gemmlowp::GemmContext"* %0, i64 0, i32 0, i32 1
  %66 = bitcast %"struct.gemmlowp::BlockParams"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %66) #19
  %67 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 1
  %68 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 2
  %69 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 4
  %70 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 5
  %71 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 1
  %72 = bitcast %"struct.gemmlowp::BlockParams"* %11 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %72, i8 -86, i64 24, i1 false)
  %73 = load i32, i32* %71, align 8
  %74 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 2
  %75 = load i32, i32* %74, align 4
  %76 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 3
  %77 = load float, float* %76, align 8
  call void @_ZN8gemmlowp11BlockParams4InitINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES7_EEEEviiiiiif(%"struct.gemmlowp::BlockParams"* nonnull %11, i32 %15, i32 %17, i32 %19, i32 %63, i32 %73, i32 %75, float %77)
  %78 = bitcast %"class.gemmlowp::PackedSideBlock"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %78) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %78, i8 -86, i64 80, i1 false)
  %79 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %64, %"class.gemmlowp::Allocator"** %79, align 8
  %80 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 4
  store i32 0, i32* %80, align 8
  %81 = load i32, i32* %67, align 4
  %82 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 0
  store i32 %81, i32* %82, align 8
  %83 = load i32, i32* %69, align 4
  %84 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 2
  store i32 %83, i32* %84, align 8
  %85 = load i32, i32* %68, align 4
  %86 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 1
  store i32 %85, i32* %86, align 4
  %87 = load i32, i32* %70, align 4
  %88 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 3
  store i32 %87, i32* %88, align 4
  %89 = mul nsw i32 %87, %83
  %90 = sext i32 %89 to i64
  %91 = add nsw i64 %90, 63
  %92 = and i64 %91, -64
  %93 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 4
  %94 = load i64, i64* %93, align 8, !noalias !1327
  %95 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 3
  %96 = load i64, i64* %95, align 8, !noalias !1327
  %97 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 5, i64 %96
  store i64 %94, i64* %97, align 8, !noalias !1327
  %98 = trunc i64 %96 to i8
  %99 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 6
  %100 = load i64, i64* %99, align 8, !noalias !1327
  %101 = load i64, i64* %95, align 8, !noalias !1327
  %102 = add i64 %101, 1
  store i64 %102, i64* %95, align 8, !noalias !1327
  %103 = load i64, i64* %93, align 8, !noalias !1327
  %104 = add i64 %103, %92
  store i64 %104, i64* %93, align 8, !noalias !1327
  %105 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 0
  store i8 %98, i8* %105, align 8
  %106 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %106, i8 -86, i64 7, i1 false) #19
  %107 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 2
  store i64 %100, i64* %107, align 8
  %108 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 3
  store i8 0, i8* %108, align 8
  %109 = sext i32 %83 to i64
  %110 = shl nsw i64 %109, 2
  %111 = add nsw i64 %110, 63
  %112 = and i64 %111, -64
  %113 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 5, i64 %102
  store i64 %104, i64* %113, align 8, !noalias !1330
  %114 = trunc i64 %102 to i8
  %115 = load i64, i64* %99, align 8, !noalias !1330
  %116 = bitcast i64* %95 to <2 x i64>*
  %117 = load <2 x i64>, <2 x i64>* %116, align 8, !noalias !1330
  %118 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %112, i32 1
  %119 = add <2 x i64> %117, %118
  %120 = bitcast i64* %95 to <2 x i64>*
  store <2 x i64> %119, <2 x i64>* %120, align 8, !noalias !1330
  %121 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 0
  store i8 %114, i8* %121, align 8
  %122 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %122, i8 -86, i64 7, i1 false) #19
  %123 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 2
  store i64 %115, i64* %123, align 8
  %124 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 3
  store i8 5, i8* %124, align 8
  call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %64)
  %125 = icmp sgt i32 %17, 0
  br i1 %125, label %126, label %150

126:                                              ; preds = %61
  %127 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 0
  %128 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 3
  %129 = bitcast %"class.gemmlowp::SideMap"* %9 to i8*
  %130 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 1
  %131 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 2
  %132 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 3
  %133 = bitcast %"class.gemmlowp::SideMap"* %9 to i64*
  %134 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %10 to i8*
  %135 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 0
  %136 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 1
  %137 = bitcast %"class.std::__1::vector.205"* %13 to i8*
  %138 = getelementptr inbounds %"class.std::__1::vector.205", %"class.std::__1::vector.205"* %13, i64 0, i32 0, i32 0
  %139 = getelementptr inbounds %"class.std::__1::vector.205", %"class.std::__1::vector.205"* %13, i64 0, i32 0, i32 1
  %140 = getelementptr inbounds %"class.std::__1::vector.205", %"class.std::__1::vector.205"* %13, i64 0, i32 0, i32 2, i32 0, i32 0
  %141 = icmp sgt i32 %63, 0
  %142 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 0
  %143 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 3
  %144 = bitcast %"class.gemmlowp::MatrixMap.479"* %4 to i64*
  %145 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %4, i64 0, i32 3
  %146 = bitcast %"struct.gemmlowp::Task"*** %139 to i64*
  %147 = bitcast %"class.std::__1::vector.205"* %13 to i64*
  %148 = bitcast %"struct.gemmlowp::Task"*** %140 to i64*
  %149 = load i32, i32* %69, align 4
  br label %155

150:                                              ; preds = %173, %61
  %151 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 0
  store i8 0, i8* %151, align 8
  %152 = load i64, i64* %99, align 8
  %153 = add i64 %152, 1
  store i64 %153, i64* %99, align 8
  %154 = bitcast i64* %95 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %154, i8 0, i64 16, i1 false) #19
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %78) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %66) #19
  br label %303

155:                                              ; preds = %126, %173
  %156 = phi i32 [ %149, %126 ], [ %174, %173 ]
  %157 = phi i32 [ 0, %126 ], [ %175, %173 ]
  %158 = sub nsw i32 %17, %157
  %159 = icmp slt i32 %158, %156
  %160 = select i1 %159, i32 %158, i32 %156
  %161 = load i8*, i8** %127, align 8, !noalias !1333
  %162 = load i32, i32* %128, align 8, !noalias !1333
  %163 = mul nsw i32 %162, %157
  %164 = sext i32 %163 to i64
  %165 = getelementptr inbounds i8, i8* %161, i64 %164
  %166 = ptrtoint i8* %165 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %129) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %129, i8 -86, i64 24, i1 false) #19
  store i64 %166, i64* %133, align 8
  store i32 %160, i32* %130, align 8
  store i32 %19, i32* %131, align 4
  store i32 %162, i32* %132, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %134) #19
  store %"class.gemmlowp::PackedSideBlock"* %12, %"class.gemmlowp::PackedSideBlock"** %135, align 8
  store %"class.gemmlowp::SideMap"* %9, %"class.gemmlowp::SideMap"** %136, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %10) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %134) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %129) #19
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %137) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %137, i8 0, i64 24, i1 false) #19
  br i1 %141, label %177, label %167

167:                                              ; preds = %297, %155
  call void @_ZN8gemmlowp11WorkersPool28LegacyExecuteAndDestroyTasksERKNSt3__16vectorIPNS_4TaskENS1_9allocatorIS4_EEEE(%"class.gemmlowp::WorkersPool"* %65, %"class.std::__1::vector.205"* nonnull dereferenceable(24) %13) #19
  %168 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %138, align 8
  %169 = icmp eq %"struct.gemmlowp::Task"** %168, null
  br i1 %169, label %173, label %170

170:                                              ; preds = %167
  %171 = ptrtoint %"struct.gemmlowp::Task"** %168 to i64
  store i64 %171, i64* %146, align 8
  %172 = bitcast %"struct.gemmlowp::Task"** %168 to i8*
  call void @_ZdlPv(i8* %172) #18
  br label %173

173:                                              ; preds = %167, %170
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %137) #19
  %174 = load i32, i32* %69, align 4
  %175 = add nsw i32 %174, %157
  %176 = icmp sgt i32 %17, %175
  br i1 %176, label %155, label %150

177:                                              ; preds = %155, %299
  %178 = phi i64 [ %302, %299 ], [ 0, %155 ]
  %179 = phi %"struct.gemmlowp::Task"** [ %301, %299 ], [ null, %155 ]
  %180 = phi %"struct.gemmlowp::Task"** [ %300, %299 ], [ null, %155 ]
  %181 = phi i32 [ %183, %299 ], [ 0, %155 ]
  %182 = phi i32 [ %189, %299 ], [ 0, %155 ]
  %183 = add nuw nsw i32 %181, 1
  %184 = mul nsw i32 %183, %15
  %185 = sdiv i32 %184, %63
  %186 = add i32 %185, 3
  %187 = and i32 %186, -4
  %188 = icmp slt i32 %187, %15
  %189 = select i1 %188, i32 %187, i32 %15
  %190 = sub nsw i32 %189, %182
  %191 = load i8*, i8** %142, align 8, !noalias !1336
  %192 = load i32, i32* %143, align 8, !noalias !1336
  %193 = mul nsw i32 %192, %182
  %194 = sext i32 %193 to i64
  %195 = getelementptr inbounds i8, i8* %191, i64 %194
  %196 = ptrtoint i8* %195 to i64
  %197 = call i8* @_Znwm(i64 208) #18
  %198 = bitcast i8* %197 to i32 (...)***
  %199 = getelementptr inbounds i8, i8* %197, i64 8
  %200 = bitcast i8* %199 to %"class.gemmlowp::Allocator"**
  store %"class.gemmlowp::Allocator"* null, %"class.gemmlowp::Allocator"** %200, align 8
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %198, align 8
  %201 = getelementptr inbounds i8, i8* %197, i64 16
  %202 = bitcast i8* %201 to %"class.gemmlowp::GemmContext"**
  store %"class.gemmlowp::GemmContext"* %0, %"class.gemmlowp::GemmContext"** %202, align 8
  %203 = getelementptr inbounds i8, i8* %197, i64 24
  %204 = bitcast i8* %203 to %"struct.gemmlowp::KernelBase"**
  store %"struct.gemmlowp::KernelBase"* %1, %"struct.gemmlowp::KernelBase"** %204, align 8
  %205 = getelementptr inbounds i8, i8* %197, i64 32
  %206 = bitcast i8* %205 to i64*
  store i64 %196, i64* %206, align 8
  %207 = getelementptr inbounds i8, i8* %197, i64 40
  %208 = bitcast i8* %207 to i32*
  store i32 %190, i32* %208, align 8
  %209 = getelementptr inbounds i8, i8* %197, i64 44
  %210 = bitcast i8* %209 to i32*
  store i32 %19, i32* %210, align 4
  %211 = getelementptr inbounds i8, i8* %197, i64 48
  %212 = bitcast i8* %211 to i32*
  store i32 %192, i32* %212, align 8
  %213 = getelementptr inbounds i8, i8* %197, i64 56
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %213, i8* nonnull align 8 %78, i64 80, i1 false) #19
  %214 = getelementptr inbounds i8, i8* %197, i64 136
  %215 = load i64, i64* %144, align 8
  %216 = bitcast i8* %214 to i64*
  store i64 %215, i64* %216, align 8
  %217 = getelementptr inbounds i8, i8* %197, i64 144
  %218 = bitcast i8* %217 to i32*
  %219 = load i32, i32* %14, align 8
  store i32 %219, i32* %218, align 8
  %220 = getelementptr inbounds i8, i8* %197, i64 148
  %221 = bitcast i8* %220 to i32*
  %222 = load i32, i32* %16, align 4
  store i32 %222, i32* %221, align 4
  %223 = getelementptr inbounds i8, i8* %197, i64 152
  %224 = bitcast i8* %223 to i32*
  %225 = load i32, i32* %145, align 8
  store i32 %225, i32* %224, align 8
  %226 = getelementptr inbounds i8, i8* %197, i64 160
  %227 = bitcast i8* %226 to i32*
  store i32 %182, i32* %227, align 8
  %228 = getelementptr inbounds i8, i8* %197, i64 164
  %229 = bitcast i8* %228 to i32*
  store i32 %157, i32* %229, align 4
  %230 = getelementptr inbounds i8, i8* %197, i64 168
  %231 = bitcast i8* %230 to i32*
  store i32 %190, i32* %231, align 8
  %232 = getelementptr inbounds i8, i8* %197, i64 172
  %233 = bitcast i8* %232 to i32*
  store i32 %160, i32* %233, align 4
  %234 = getelementptr inbounds i8, i8* %197, i64 176
  %235 = bitcast i8* %234 to %"class.gemmlowp::VectorDup"**
  store %"class.gemmlowp::VectorDup"* %5, %"class.gemmlowp::VectorDup"** %235, align 8
  %236 = getelementptr inbounds i8, i8* %197, i64 184
  %237 = bitcast i8* %236 to %"class.gemmlowp::VectorDup.194"**
  store %"class.gemmlowp::VectorDup.194"* %6, %"class.gemmlowp::VectorDup.194"** %237, align 8
  %238 = getelementptr inbounds i8, i8* %197, i64 192
  %239 = bitcast i8* %238 to %"struct.gemmlowp::BlockParams"**
  store %"struct.gemmlowp::BlockParams"* %11, %"struct.gemmlowp::BlockParams"** %239, align 8
  %240 = getelementptr inbounds i8, i8* %197, i64 200
  %241 = bitcast i8* %240 to %"class.std::__1::tuple.481"**
  store %"class.std::__1::tuple.481"* %7, %"class.std::__1::tuple.481"** %241, align 8
  %242 = ptrtoint i8* %197 to i64
  %243 = icmp ult %"struct.gemmlowp::Task"** %180, %179
  %244 = ptrtoint %"struct.gemmlowp::Task"** %179 to i64
  br i1 %243, label %245, label %249

245:                                              ; preds = %177
  %246 = bitcast %"struct.gemmlowp::Task"** %180 to i64*
  store i64 %242, i64* %246, align 8
  %247 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %180, i64 1
  %248 = ptrtoint %"struct.gemmlowp::Task"** %247 to i64
  store i64 %248, i64* %146, align 8
  br label %297

249:                                              ; preds = %177
  %250 = ptrtoint %"struct.gemmlowp::Task"** %180 to i64
  %251 = load i64, i64* %147, align 8
  %252 = sub i64 %250, %251
  %253 = ashr exact i64 %252, 3
  %254 = add nsw i64 %253, 1
  %255 = icmp ugt i64 %254, 2305843009213693951
  br i1 %255, label %256, label %258

256:                                              ; preds = %249
  %257 = bitcast %"class.std::__1::vector.205"* %13 to %"class.std::__1::__vector_base_common"*
  call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* nonnull %257) #20
  unreachable

258:                                              ; preds = %249
  %259 = sub i64 %244, %251
  %260 = ashr exact i64 %259, 3
  %261 = icmp ult i64 %260, 1152921504606846975
  br i1 %261, label %262, label %270

262:                                              ; preds = %258
  %263 = ashr exact i64 %259, 2
  %264 = icmp ult i64 %263, %254
  %265 = select i1 %264, i64 %254, i64 %263
  %266 = icmp eq i64 %265, 0
  br i1 %266, label %275, label %267

267:                                              ; preds = %262
  %268 = icmp ugt i64 %265, 2305843009213693951
  br i1 %268, label %269, label %270

269:                                              ; preds = %267
  call void @abort() #20
  unreachable

270:                                              ; preds = %267, %258
  %271 = phi i64 [ %265, %267 ], [ 2305843009213693951, %258 ]
  %272 = shl i64 %271, 3
  %273 = call i8* @_Znwm(i64 %272) #18
  %274 = bitcast i8* %273 to %"struct.gemmlowp::Task"**
  br label %275

275:                                              ; preds = %270, %262
  %276 = phi i64 [ %271, %270 ], [ 0, %262 ]
  %277 = phi %"struct.gemmlowp::Task"** [ %274, %270 ], [ null, %262 ]
  %278 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %277, i64 %253
  %279 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %277, i64 %276
  %280 = ptrtoint %"struct.gemmlowp::Task"** %279 to i64
  %281 = bitcast %"struct.gemmlowp::Task"** %278 to i64*
  store i64 %242, i64* %281, align 8
  %282 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %278, i64 1
  %283 = ptrtoint %"struct.gemmlowp::Task"** %282 to i64
  %284 = sub i64 %178, %251
  %285 = ashr exact i64 %284, 3
  %286 = sub nsw i64 0, %285
  %287 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %278, i64 %286
  %288 = ptrtoint %"struct.gemmlowp::Task"** %287 to i64
  %289 = icmp sgt i64 %284, 0
  br i1 %289, label %290, label %293

290:                                              ; preds = %275
  %291 = bitcast %"struct.gemmlowp::Task"** %287 to i8*
  %292 = inttoptr i64 %251 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %291, i8* align 8 %292, i64 %284, i1 false) #19
  br label %293

293:                                              ; preds = %290, %275
  store i64 %288, i64* %147, align 8
  store i64 %283, i64* %146, align 8
  store i64 %280, i64* %148, align 8
  %294 = icmp eq i64 %251, 0
  br i1 %294, label %297, label %295

295:                                              ; preds = %293
  %296 = inttoptr i64 %251 to i8*
  call void @_ZdlPv(i8* %296) #18
  br label %297

297:                                              ; preds = %245, %293, %295
  %298 = icmp eq i32 %183, %63
  br i1 %298, label %167, label %299

299:                                              ; preds = %297
  %300 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %139, align 8
  %301 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %140, align 8
  %302 = ptrtoint %"struct.gemmlowp::Task"** %300 to i64
  br label %177

303:                                              ; preds = %150, %59
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSZ_IS11_XT4_EEEPNSZ_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::GemmContext"*, %"struct.gemmlowp::KernelBase"* dereferenceable(8), %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.180"* dereferenceable(24), %"class.gemmlowp::MatrixMap.489"*, %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.std::__1::tuple.491"* dereferenceable(40)) local_unnamed_addr #1 comdat {
  %9 = alloca %"class.gemmlowp::SideMap", align 8
  %10 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %11 = alloca %"struct.gemmlowp::BlockParams", align 4
  %12 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %13 = alloca %"class.std::__1::vector.205", align 8
  %14 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %4, i64 0, i32 1
  %15 = load i32, i32* %14, align 8
  %16 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %4, i64 0, i32 2
  %17 = load i32, i32* %16, align 4
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 2
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %"class.gemmlowp::GemmContext", %"class.gemmlowp::GemmContext"* %0, i64 0, i32 0, i32 0, i32 1
  %21 = load i32, i32* %20, align 4
  switch i32 %21, label %34 [
    i32 1, label %54
    i32 0, label %22
  ]

22:                                               ; preds = %8
  %23 = load atomic i8, i8* bitcast (i64* @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count to i8*) acquire, align 8
  %24 = icmp eq i8 %23, 0
  br i1 %24, label %25, label %32, !prof !514

25:                                               ; preds = %22
  %26 = tail call i32 @__cxa_guard_acquire(i64* nonnull @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count) #19
  %27 = icmp eq i32 %26, 0
  br i1 %27, label %32, label %28

28:                                               ; preds = %25
  %29 = tail call i64 @sysconf(i32 83) #19
  %30 = trunc i64 %29 to i32
  store i32 %30, i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count, align 4
  %31 = tail call {}* @llvm.invariant.start.p0i8(i64 4, i8* bitcast (i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count to i8*)) #19
  tail call void @__cxa_guard_release(i64* nonnull @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count) #19
  br label %32

32:                                               ; preds = %28, %25, %22
  %33 = load i32, i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count, align 4
  br label %34

34:                                               ; preds = %32, %8
  %35 = phi i32 [ %33, %32 ], [ %21, %8 ]
  %36 = add i32 %15, 15
  %37 = sdiv i32 %36, 16
  %38 = icmp slt i32 %37, %35
  %39 = select i1 %38, i32 %37, i32 %35
  %40 = icmp sgt i32 %39, 1
  br i1 %40, label %41, label %56

41:                                               ; preds = %34
  %42 = sext i32 %15 to i64
  %43 = sext i32 %17 to i64
  %44 = mul nsw i64 %43, %42
  %45 = sext i32 %19 to i64
  %46 = mul i64 %44, %45
  %47 = lshr i64 %46, 16
  %48 = trunc i64 %47 to i32
  %49 = icmp sgt i32 %39, %48
  %50 = select i1 %49, i32 %48, i32 %39
  %51 = icmp sgt i32 %50, 1
  br i1 %51, label %52, label %54

52:                                               ; preds = %41
  %53 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br label %61

54:                                               ; preds = %41, %8
  %55 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br label %59

56:                                               ; preds = %34
  %57 = icmp eq i32 %39, 1
  %58 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br i1 %57, label %59, label %61

59:                                               ; preds = %54, %56
  %60 = phi %"class.gemmlowp::SingleThreadGemmContext"* [ %55, %54 ], [ %58, %56 ]
  tail call void @_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSY_IS10_XT4_EEEPNSY_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::SingleThreadGemmContext"* %60, %"struct.gemmlowp::KernelBase"* dereferenceable(8) %1, %"class.gemmlowp::MatrixMap"* dereferenceable(24) %2, %"class.gemmlowp::MatrixMap.180"* dereferenceable(24) %3, %"class.gemmlowp::MatrixMap.489"* %4, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %5, %"class.gemmlowp::VectorDup"* dereferenceable(8) %6, %"class.std::__1::tuple.491"* dereferenceable(40) %7)
  br label %303

61:                                               ; preds = %52, %56
  %62 = phi %"class.gemmlowp::SingleThreadGemmContext"* [ %53, %52 ], [ %58, %56 ]
  %63 = phi i32 [ %50, %52 ], [ %39, %56 ]
  %64 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0
  %65 = getelementptr inbounds %"class.gemmlowp::GemmContext", %"class.gemmlowp::GemmContext"* %0, i64 0, i32 0, i32 1
  %66 = bitcast %"struct.gemmlowp::BlockParams"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %66) #19
  %67 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 1
  %68 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 2
  %69 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 4
  %70 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 5
  %71 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 1
  %72 = bitcast %"struct.gemmlowp::BlockParams"* %11 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %72, i8 -86, i64 24, i1 false)
  %73 = load i32, i32* %71, align 8
  %74 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 2
  %75 = load i32, i32* %74, align 4
  %76 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 3
  %77 = load float, float* %76, align 8
  call void @_ZN8gemmlowp11BlockParams4InitINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES7_EEEEviiiiiif(%"struct.gemmlowp::BlockParams"* nonnull %11, i32 %15, i32 %17, i32 %19, i32 %63, i32 %73, i32 %75, float %77)
  %78 = bitcast %"class.gemmlowp::PackedSideBlock"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %78) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %78, i8 -86, i64 80, i1 false)
  %79 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %64, %"class.gemmlowp::Allocator"** %79, align 8
  %80 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 4
  store i32 0, i32* %80, align 8
  %81 = load i32, i32* %67, align 4
  %82 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 0
  store i32 %81, i32* %82, align 8
  %83 = load i32, i32* %69, align 4
  %84 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 2
  store i32 %83, i32* %84, align 8
  %85 = load i32, i32* %68, align 4
  %86 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 1
  store i32 %85, i32* %86, align 4
  %87 = load i32, i32* %70, align 4
  %88 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 3
  store i32 %87, i32* %88, align 4
  %89 = mul nsw i32 %87, %83
  %90 = sext i32 %89 to i64
  %91 = add nsw i64 %90, 63
  %92 = and i64 %91, -64
  %93 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 4
  %94 = load i64, i64* %93, align 8, !noalias !1339
  %95 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 3
  %96 = load i64, i64* %95, align 8, !noalias !1339
  %97 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 5, i64 %96
  store i64 %94, i64* %97, align 8, !noalias !1339
  %98 = trunc i64 %96 to i8
  %99 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 6
  %100 = load i64, i64* %99, align 8, !noalias !1339
  %101 = load i64, i64* %95, align 8, !noalias !1339
  %102 = add i64 %101, 1
  store i64 %102, i64* %95, align 8, !noalias !1339
  %103 = load i64, i64* %93, align 8, !noalias !1339
  %104 = add i64 %103, %92
  store i64 %104, i64* %93, align 8, !noalias !1339
  %105 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 0
  store i8 %98, i8* %105, align 8
  %106 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %106, i8 -86, i64 7, i1 false) #19
  %107 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 2
  store i64 %100, i64* %107, align 8
  %108 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 3
  store i8 0, i8* %108, align 8
  %109 = sext i32 %83 to i64
  %110 = shl nsw i64 %109, 2
  %111 = add nsw i64 %110, 63
  %112 = and i64 %111, -64
  %113 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 5, i64 %102
  store i64 %104, i64* %113, align 8, !noalias !1342
  %114 = trunc i64 %102 to i8
  %115 = load i64, i64* %99, align 8, !noalias !1342
  %116 = bitcast i64* %95 to <2 x i64>*
  %117 = load <2 x i64>, <2 x i64>* %116, align 8, !noalias !1342
  %118 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %112, i32 1
  %119 = add <2 x i64> %117, %118
  %120 = bitcast i64* %95 to <2 x i64>*
  store <2 x i64> %119, <2 x i64>* %120, align 8, !noalias !1342
  %121 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 0
  store i8 %114, i8* %121, align 8
  %122 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %122, i8 -86, i64 7, i1 false) #19
  %123 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 2
  store i64 %115, i64* %123, align 8
  %124 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 3
  store i8 5, i8* %124, align 8
  call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %64)
  %125 = icmp sgt i32 %17, 0
  br i1 %125, label %126, label %150

126:                                              ; preds = %61
  %127 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 0
  %128 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 3
  %129 = bitcast %"class.gemmlowp::SideMap"* %9 to i8*
  %130 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 1
  %131 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 2
  %132 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 3
  %133 = bitcast %"class.gemmlowp::SideMap"* %9 to i64*
  %134 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %10 to i8*
  %135 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 0
  %136 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 1
  %137 = bitcast %"class.std::__1::vector.205"* %13 to i8*
  %138 = getelementptr inbounds %"class.std::__1::vector.205", %"class.std::__1::vector.205"* %13, i64 0, i32 0, i32 0
  %139 = getelementptr inbounds %"class.std::__1::vector.205", %"class.std::__1::vector.205"* %13, i64 0, i32 0, i32 1
  %140 = getelementptr inbounds %"class.std::__1::vector.205", %"class.std::__1::vector.205"* %13, i64 0, i32 0, i32 2, i32 0, i32 0
  %141 = icmp sgt i32 %63, 0
  %142 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 0
  %143 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 3
  %144 = bitcast %"class.gemmlowp::MatrixMap.489"* %4 to i64*
  %145 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %4, i64 0, i32 3
  %146 = bitcast %"struct.gemmlowp::Task"*** %139 to i64*
  %147 = bitcast %"class.std::__1::vector.205"* %13 to i64*
  %148 = bitcast %"struct.gemmlowp::Task"*** %140 to i64*
  %149 = load i32, i32* %69, align 4
  br label %155

150:                                              ; preds = %173, %61
  %151 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 0
  store i8 0, i8* %151, align 8
  %152 = load i64, i64* %99, align 8
  %153 = add i64 %152, 1
  store i64 %153, i64* %99, align 8
  %154 = bitcast i64* %95 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %154, i8 0, i64 16, i1 false) #19
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %78) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %66) #19
  br label %303

155:                                              ; preds = %126, %173
  %156 = phi i32 [ %149, %126 ], [ %174, %173 ]
  %157 = phi i32 [ 0, %126 ], [ %175, %173 ]
  %158 = sub nsw i32 %17, %157
  %159 = icmp slt i32 %158, %156
  %160 = select i1 %159, i32 %158, i32 %156
  %161 = load i8*, i8** %127, align 8, !noalias !1345
  %162 = load i32, i32* %128, align 8, !noalias !1345
  %163 = mul nsw i32 %162, %157
  %164 = sext i32 %163 to i64
  %165 = getelementptr inbounds i8, i8* %161, i64 %164
  %166 = ptrtoint i8* %165 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %129) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %129, i8 -86, i64 24, i1 false) #19
  store i64 %166, i64* %133, align 8
  store i32 %160, i32* %130, align 8
  store i32 %19, i32* %131, align 4
  store i32 %162, i32* %132, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %134) #19
  store %"class.gemmlowp::PackedSideBlock"* %12, %"class.gemmlowp::PackedSideBlock"** %135, align 8
  store %"class.gemmlowp::SideMap"* %9, %"class.gemmlowp::SideMap"** %136, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %10) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %134) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %129) #19
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %137) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %137, i8 0, i64 24, i1 false) #19
  br i1 %141, label %177, label %167

167:                                              ; preds = %297, %155
  call void @_ZN8gemmlowp11WorkersPool28LegacyExecuteAndDestroyTasksERKNSt3__16vectorIPNS_4TaskENS1_9allocatorIS4_EEEE(%"class.gemmlowp::WorkersPool"* %65, %"class.std::__1::vector.205"* nonnull dereferenceable(24) %13) #19
  %168 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %138, align 8
  %169 = icmp eq %"struct.gemmlowp::Task"** %168, null
  br i1 %169, label %173, label %170

170:                                              ; preds = %167
  %171 = ptrtoint %"struct.gemmlowp::Task"** %168 to i64
  store i64 %171, i64* %146, align 8
  %172 = bitcast %"struct.gemmlowp::Task"** %168 to i8*
  call void @_ZdlPv(i8* %172) #18
  br label %173

173:                                              ; preds = %167, %170
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %137) #19
  %174 = load i32, i32* %69, align 4
  %175 = add nsw i32 %174, %157
  %176 = icmp sgt i32 %17, %175
  br i1 %176, label %155, label %150

177:                                              ; preds = %155, %299
  %178 = phi i64 [ %302, %299 ], [ 0, %155 ]
  %179 = phi %"struct.gemmlowp::Task"** [ %301, %299 ], [ null, %155 ]
  %180 = phi %"struct.gemmlowp::Task"** [ %300, %299 ], [ null, %155 ]
  %181 = phi i32 [ %183, %299 ], [ 0, %155 ]
  %182 = phi i32 [ %189, %299 ], [ 0, %155 ]
  %183 = add nuw nsw i32 %181, 1
  %184 = mul nsw i32 %183, %15
  %185 = sdiv i32 %184, %63
  %186 = add i32 %185, 3
  %187 = and i32 %186, -4
  %188 = icmp slt i32 %187, %15
  %189 = select i1 %188, i32 %187, i32 %15
  %190 = sub nsw i32 %189, %182
  %191 = load i8*, i8** %142, align 8, !noalias !1348
  %192 = load i32, i32* %143, align 8, !noalias !1348
  %193 = mul nsw i32 %192, %182
  %194 = sext i32 %193 to i64
  %195 = getelementptr inbounds i8, i8* %191, i64 %194
  %196 = ptrtoint i8* %195 to i64
  %197 = call i8* @_Znwm(i64 208) #18
  %198 = bitcast i8* %197 to i32 (...)***
  %199 = getelementptr inbounds i8, i8* %197, i64 8
  %200 = bitcast i8* %199 to %"class.gemmlowp::Allocator"**
  store %"class.gemmlowp::Allocator"* null, %"class.gemmlowp::Allocator"** %200, align 8
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %198, align 8
  %201 = getelementptr inbounds i8, i8* %197, i64 16
  %202 = bitcast i8* %201 to %"class.gemmlowp::GemmContext"**
  store %"class.gemmlowp::GemmContext"* %0, %"class.gemmlowp::GemmContext"** %202, align 8
  %203 = getelementptr inbounds i8, i8* %197, i64 24
  %204 = bitcast i8* %203 to %"struct.gemmlowp::KernelBase"**
  store %"struct.gemmlowp::KernelBase"* %1, %"struct.gemmlowp::KernelBase"** %204, align 8
  %205 = getelementptr inbounds i8, i8* %197, i64 32
  %206 = bitcast i8* %205 to i64*
  store i64 %196, i64* %206, align 8
  %207 = getelementptr inbounds i8, i8* %197, i64 40
  %208 = bitcast i8* %207 to i32*
  store i32 %190, i32* %208, align 8
  %209 = getelementptr inbounds i8, i8* %197, i64 44
  %210 = bitcast i8* %209 to i32*
  store i32 %19, i32* %210, align 4
  %211 = getelementptr inbounds i8, i8* %197, i64 48
  %212 = bitcast i8* %211 to i32*
  store i32 %192, i32* %212, align 8
  %213 = getelementptr inbounds i8, i8* %197, i64 56
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %213, i8* nonnull align 8 %78, i64 80, i1 false) #19
  %214 = getelementptr inbounds i8, i8* %197, i64 136
  %215 = load i64, i64* %144, align 8
  %216 = bitcast i8* %214 to i64*
  store i64 %215, i64* %216, align 8
  %217 = getelementptr inbounds i8, i8* %197, i64 144
  %218 = bitcast i8* %217 to i32*
  %219 = load i32, i32* %14, align 8
  store i32 %219, i32* %218, align 8
  %220 = getelementptr inbounds i8, i8* %197, i64 148
  %221 = bitcast i8* %220 to i32*
  %222 = load i32, i32* %16, align 4
  store i32 %222, i32* %221, align 4
  %223 = getelementptr inbounds i8, i8* %197, i64 152
  %224 = bitcast i8* %223 to i32*
  %225 = load i32, i32* %145, align 8
  store i32 %225, i32* %224, align 8
  %226 = getelementptr inbounds i8, i8* %197, i64 160
  %227 = bitcast i8* %226 to i32*
  store i32 %182, i32* %227, align 8
  %228 = getelementptr inbounds i8, i8* %197, i64 164
  %229 = bitcast i8* %228 to i32*
  store i32 %157, i32* %229, align 4
  %230 = getelementptr inbounds i8, i8* %197, i64 168
  %231 = bitcast i8* %230 to i32*
  store i32 %190, i32* %231, align 8
  %232 = getelementptr inbounds i8, i8* %197, i64 172
  %233 = bitcast i8* %232 to i32*
  store i32 %160, i32* %233, align 4
  %234 = getelementptr inbounds i8, i8* %197, i64 176
  %235 = bitcast i8* %234 to %"class.gemmlowp::VectorDup.194"**
  store %"class.gemmlowp::VectorDup.194"* %5, %"class.gemmlowp::VectorDup.194"** %235, align 8
  %236 = getelementptr inbounds i8, i8* %197, i64 184
  %237 = bitcast i8* %236 to %"class.gemmlowp::VectorDup"**
  store %"class.gemmlowp::VectorDup"* %6, %"class.gemmlowp::VectorDup"** %237, align 8
  %238 = getelementptr inbounds i8, i8* %197, i64 192
  %239 = bitcast i8* %238 to %"struct.gemmlowp::BlockParams"**
  store %"struct.gemmlowp::BlockParams"* %11, %"struct.gemmlowp::BlockParams"** %239, align 8
  %240 = getelementptr inbounds i8, i8* %197, i64 200
  %241 = bitcast i8* %240 to %"class.std::__1::tuple.491"**
  store %"class.std::__1::tuple.491"* %7, %"class.std::__1::tuple.491"** %241, align 8
  %242 = ptrtoint i8* %197 to i64
  %243 = icmp ult %"struct.gemmlowp::Task"** %180, %179
  %244 = ptrtoint %"struct.gemmlowp::Task"** %179 to i64
  br i1 %243, label %245, label %249

245:                                              ; preds = %177
  %246 = bitcast %"struct.gemmlowp::Task"** %180 to i64*
  store i64 %242, i64* %246, align 8
  %247 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %180, i64 1
  %248 = ptrtoint %"struct.gemmlowp::Task"** %247 to i64
  store i64 %248, i64* %146, align 8
  br label %297

249:                                              ; preds = %177
  %250 = ptrtoint %"struct.gemmlowp::Task"** %180 to i64
  %251 = load i64, i64* %147, align 8
  %252 = sub i64 %250, %251
  %253 = ashr exact i64 %252, 3
  %254 = add nsw i64 %253, 1
  %255 = icmp ugt i64 %254, 2305843009213693951
  br i1 %255, label %256, label %258

256:                                              ; preds = %249
  %257 = bitcast %"class.std::__1::vector.205"* %13 to %"class.std::__1::__vector_base_common"*
  call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* nonnull %257) #20
  unreachable

258:                                              ; preds = %249
  %259 = sub i64 %244, %251
  %260 = ashr exact i64 %259, 3
  %261 = icmp ult i64 %260, 1152921504606846975
  br i1 %261, label %262, label %270

262:                                              ; preds = %258
  %263 = ashr exact i64 %259, 2
  %264 = icmp ult i64 %263, %254
  %265 = select i1 %264, i64 %254, i64 %263
  %266 = icmp eq i64 %265, 0
  br i1 %266, label %275, label %267

267:                                              ; preds = %262
  %268 = icmp ugt i64 %265, 2305843009213693951
  br i1 %268, label %269, label %270

269:                                              ; preds = %267
  call void @abort() #20
  unreachable

270:                                              ; preds = %267, %258
  %271 = phi i64 [ %265, %267 ], [ 2305843009213693951, %258 ]
  %272 = shl i64 %271, 3
  %273 = call i8* @_Znwm(i64 %272) #18
  %274 = bitcast i8* %273 to %"struct.gemmlowp::Task"**
  br label %275

275:                                              ; preds = %270, %262
  %276 = phi i64 [ %271, %270 ], [ 0, %262 ]
  %277 = phi %"struct.gemmlowp::Task"** [ %274, %270 ], [ null, %262 ]
  %278 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %277, i64 %253
  %279 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %277, i64 %276
  %280 = ptrtoint %"struct.gemmlowp::Task"** %279 to i64
  %281 = bitcast %"struct.gemmlowp::Task"** %278 to i64*
  store i64 %242, i64* %281, align 8
  %282 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %278, i64 1
  %283 = ptrtoint %"struct.gemmlowp::Task"** %282 to i64
  %284 = sub i64 %178, %251
  %285 = ashr exact i64 %284, 3
  %286 = sub nsw i64 0, %285
  %287 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %278, i64 %286
  %288 = ptrtoint %"struct.gemmlowp::Task"** %287 to i64
  %289 = icmp sgt i64 %284, 0
  br i1 %289, label %290, label %293

290:                                              ; preds = %275
  %291 = bitcast %"struct.gemmlowp::Task"** %287 to i8*
  %292 = inttoptr i64 %251 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %291, i8* align 8 %292, i64 %284, i1 false) #19
  br label %293

293:                                              ; preds = %290, %275
  store i64 %288, i64* %147, align 8
  store i64 %283, i64* %146, align 8
  store i64 %280, i64* %148, align 8
  %294 = icmp eq i64 %251, 0
  br i1 %294, label %297, label %295

295:                                              ; preds = %293
  %296 = inttoptr i64 %251 to i8*
  call void @_ZdlPv(i8* %296) #18
  br label %297

297:                                              ; preds = %245, %293, %295
  %298 = icmp eq i32 %183, %63
  br i1 %298, label %167, label %299

299:                                              ; preds = %297
  %300 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %139, align 8
  %301 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %140, align 8
  %302 = ptrtoint %"struct.gemmlowp::Task"** %300 to i64
  br label %177

303:                                              ; preds = %150, %59
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSY_IS10_XT4_EEEPNSY_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::SingleThreadGemmContext"*, %"struct.gemmlowp::KernelBase"* dereferenceable(8), %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.180"* dereferenceable(24), %"class.gemmlowp::MatrixMap.489"*, %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.std::__1::tuple.491"* dereferenceable(40)) local_unnamed_addr #1 comdat {
  %9 = alloca %"class.gemmlowp::SideMap", align 8
  %10 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %11 = alloca %"class.gemmlowp::SideMap", align 8
  %12 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %13 = alloca %"class.gemmlowp::SideMap", align 8
  %14 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %15 = alloca %"class.gemmlowp::ComputeImpl", align 8
  %16 = alloca %"struct.gemmlowp::BlockParams", align 4
  %17 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %18 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %19 = alloca %"class.gemmlowp::PackedResult", align 8
  %20 = alloca %"struct.gemmlowp::MatrixBlockBounds", align 4
  %21 = alloca %"class.gemmlowp::VectorDup.194", align 4
  %22 = alloca %"class.gemmlowp::VectorDup", align 4
  %23 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %4, i64 0, i32 1
  %24 = load i32, i32* %23, align 8
  %25 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %4, i64 0, i32 2
  %26 = load i32, i32* %25, align 4
  %27 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 2
  %28 = load i32, i32* %27, align 4
  %29 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0
  %30 = bitcast %"struct.gemmlowp::BlockParams"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %30) #19
  %31 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 0
  %32 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 1
  %33 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 2
  %34 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 3
  %35 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 4
  %36 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 5
  %37 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 1
  %38 = bitcast %"struct.gemmlowp::BlockParams"* %16 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %38, i8 -86, i64 24, i1 false)
  %39 = load i32, i32* %37, align 8
  %40 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 2
  %41 = load i32, i32* %40, align 4
  %42 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 3
  %43 = load float, float* %42, align 8
  call void @_ZN8gemmlowp11BlockParams4InitINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES7_EEEEviiiiiif(%"struct.gemmlowp::BlockParams"* nonnull %16, i32 %24, i32 %26, i32 %28, i32 1, i32 %39, i32 %41, float %43)
  %44 = bitcast %"class.gemmlowp::PackedSideBlock"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %44) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %44, i8 -86, i64 80, i1 false)
  %45 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %45, align 8
  %46 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 4
  store i32 0, i32* %46, align 8
  %47 = load i32, i32* %31, align 4
  %48 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 0
  store i32 %47, i32* %48, align 8
  %49 = load i32, i32* %34, align 4
  %50 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 2
  store i32 %49, i32* %50, align 8
  %51 = load i32, i32* %33, align 4
  %52 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 1
  store i32 %51, i32* %52, align 4
  %53 = load i32, i32* %36, align 4
  %54 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 3
  store i32 %53, i32* %54, align 4
  %55 = mul nsw i32 %53, %49
  %56 = sext i32 %55 to i64
  %57 = add nsw i64 %56, 63
  %58 = and i64 %57, -64
  %59 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 4
  %60 = load i64, i64* %59, align 8, !noalias !1351
  %61 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 3
  %62 = load i64, i64* %61, align 8, !noalias !1351
  %63 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %62
  store i64 %60, i64* %63, align 8, !noalias !1351
  %64 = trunc i64 %62 to i8
  %65 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 6
  %66 = load i64, i64* %65, align 8, !noalias !1351
  %67 = load i64, i64* %61, align 8, !noalias !1351
  %68 = add i64 %67, 1
  store i64 %68, i64* %61, align 8, !noalias !1351
  %69 = load i64, i64* %59, align 8, !noalias !1351
  %70 = add i64 %69, %58
  store i64 %70, i64* %59, align 8, !noalias !1351
  %71 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 0
  store i8 %64, i8* %71, align 8
  %72 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %72, i8 -86, i64 7, i1 false) #19
  %73 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 2
  store i64 %66, i64* %73, align 8
  %74 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 3
  store i8 0, i8* %74, align 8
  %75 = sext i32 %49 to i64
  %76 = shl nsw i64 %75, 2
  %77 = add nsw i64 %76, 63
  %78 = and i64 %77, -64
  %79 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %68
  store i64 %70, i64* %79, align 8, !noalias !1354
  %80 = trunc i64 %68 to i8
  %81 = load i64, i64* %65, align 8, !noalias !1354
  %82 = load i64, i64* %61, align 8, !noalias !1354
  %83 = add i64 %82, 1
  store i64 %83, i64* %61, align 8, !noalias !1354
  %84 = load i64, i64* %59, align 8, !noalias !1354
  %85 = add i64 %84, %78
  store i64 %85, i64* %59, align 8, !noalias !1354
  %86 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 0
  store i8 %80, i8* %86, align 8
  %87 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %87, i8 -86, i64 7, i1 false) #19
  %88 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 2
  store i64 %81, i64* %88, align 8
  %89 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 3
  store i8 5, i8* %89, align 8
  %90 = bitcast %"class.gemmlowp::PackedSideBlock"* %18 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %90) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %90, i8 -86, i64 80, i1 false)
  %91 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %91, align 8
  %92 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 4
  store i32 0, i32* %92, align 8
  %93 = load i32, i32* %32, align 4
  %94 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 0
  store i32 %93, i32* %94, align 8
  %95 = load i32, i32* %35, align 4
  %96 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 2
  store i32 %95, i32* %96, align 8
  %97 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 1
  store i32 %51, i32* %97, align 4
  %98 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 3
  store i32 %53, i32* %98, align 4
  %99 = mul nsw i32 %53, %95
  %100 = sext i32 %99 to i64
  %101 = add nsw i64 %100, 63
  %102 = and i64 %101, -64
  %103 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %83
  store i64 %85, i64* %103, align 8, !noalias !1357
  %104 = trunc i64 %83 to i8
  %105 = load i64, i64* %65, align 8, !noalias !1357
  %106 = load i64, i64* %61, align 8, !noalias !1357
  %107 = add i64 %106, 1
  store i64 %107, i64* %61, align 8, !noalias !1357
  %108 = load i64, i64* %59, align 8, !noalias !1357
  %109 = add i64 %108, %102
  store i64 %109, i64* %59, align 8, !noalias !1357
  %110 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 0
  store i8 %104, i8* %110, align 8
  %111 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %111, i8 -86, i64 7, i1 false) #19
  %112 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 2
  store i64 %105, i64* %112, align 8
  %113 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 3
  store i8 0, i8* %113, align 8
  %114 = sext i32 %95 to i64
  %115 = shl nsw i64 %114, 2
  %116 = add nsw i64 %115, 63
  %117 = and i64 %116, -64
  %118 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %107
  store i64 %109, i64* %118, align 8, !noalias !1360
  %119 = trunc i64 %107 to i8
  %120 = load i64, i64* %65, align 8, !noalias !1360
  %121 = load i64, i64* %61, align 8, !noalias !1360
  %122 = add i64 %121, 1
  store i64 %122, i64* %61, align 8, !noalias !1360
  %123 = load i64, i64* %59, align 8, !noalias !1360
  %124 = add i64 %123, %117
  store i64 %124, i64* %59, align 8, !noalias !1360
  %125 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 0
  store i8 %119, i8* %125, align 8
  %126 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %126, i8 -86, i64 7, i1 false) #19
  %127 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 2
  store i64 %120, i64* %127, align 8
  %128 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 3
  store i8 5, i8* %128, align 8
  %129 = bitcast %"class.gemmlowp::PackedResult"* %19 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %129) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %129, i8 -86, i64 32, i1 false)
  %130 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 0
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %130, align 8
  %131 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 2
  store %"struct.gemmlowp::BlockParams"* %16, %"struct.gemmlowp::BlockParams"** %131, align 8
  %132 = load i32, i32* %34, align 4
  %133 = mul nsw i32 %95, %132
  %134 = sext i32 %133 to i64
  %135 = shl nsw i64 %134, 2
  %136 = add nsw i64 %135, 63
  %137 = and i64 %136, -64
  %138 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %122
  store i64 %124, i64* %138, align 8, !noalias !1363
  %139 = trunc i64 %122 to i8
  %140 = load i64, i64* %65, align 8, !noalias !1363
  %141 = bitcast i64* %61 to <2 x i64>*
  %142 = load <2 x i64>, <2 x i64>* %141, align 8, !noalias !1363
  %143 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %137, i32 1
  %144 = add <2 x i64> %142, %143
  %145 = bitcast i64* %61 to <2 x i64>*
  store <2 x i64> %144, <2 x i64>* %145, align 8, !noalias !1363
  %146 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 0
  store i8 %139, i8* %146, align 8
  %147 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %147, i8 -86, i64 7, i1 false) #19
  %148 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 2
  store i64 %140, i64* %148, align 8
  %149 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 3
  store i8 5, i8* %149, align 8
  call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %29)
  %150 = load i32, i32* %35, align 4
  %151 = icmp sge i32 %150, %26
  br i1 %151, label %152, label %169

152:                                              ; preds = %8
  %153 = bitcast %"class.gemmlowp::SideMap"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %153) #19
  %154 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 1
  %155 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 2
  %156 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 3
  %157 = bitcast %"class.gemmlowp::MatrixMap.180"* %3 to i64*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %153, i8 -86, i64 24, i1 false) #19
  %158 = load i64, i64* %157, align 8
  %159 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 2
  %160 = load i32, i32* %159, align 4
  %161 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 1
  %162 = load i32, i32* %161, align 8
  %163 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 3
  %164 = load i32, i32* %163, align 8
  %165 = bitcast %"class.gemmlowp::SideMap"* %9 to i64*
  store i64 %158, i64* %165, align 8
  store i32 %160, i32* %154, align 8
  store i32 %162, i32* %155, align 4
  store i32 %164, i32* %156, align 8
  %166 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %166) #19
  %167 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 0
  %168 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 1
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %167, align 8
  store %"class.gemmlowp::SideMap"* %9, %"class.gemmlowp::SideMap"** %168, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %10) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %166) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %153) #19
  br label %169

169:                                              ; preds = %152, %8
  %170 = icmp sgt i32 %24, 0
  br i1 %170, label %171, label %216

171:                                              ; preds = %169
  %172 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 0
  %173 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 3
  %174 = bitcast %"class.gemmlowp::SideMap"* %11 to i8*
  %175 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 1
  %176 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 2
  %177 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 3
  %178 = bitcast %"class.gemmlowp::SideMap"* %11 to i64*
  %179 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %12 to i8*
  %180 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %12, i64 0, i32 0
  %181 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %12, i64 0, i32 1
  %182 = icmp sgt i32 %26, 0
  %183 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 0
  %184 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 3
  %185 = bitcast %"class.gemmlowp::SideMap"* %13 to i8*
  %186 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 1
  %187 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 2
  %188 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 3
  %189 = bitcast %"class.gemmlowp::SideMap"* %13 to i64*
  %190 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %14 to i8*
  %191 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %14, i64 0, i32 0
  %192 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %14, i64 0, i32 1
  %193 = bitcast %"class.gemmlowp::ComputeImpl"* %15 to i8*
  %194 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 0
  %195 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 1
  %196 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 2
  %197 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 3
  %198 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 4
  %199 = add i32 %28, 15
  %200 = and i32 %199, -16
  %201 = icmp sgt i32 %200, 0
  %202 = bitcast %"struct.gemmlowp::MatrixBlockBounds"* %20 to i8*
  %203 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 0
  %204 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 1
  %205 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 2
  %206 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 3
  %207 = bitcast %"class.gemmlowp::VectorDup.194"* %21 to i8*
  %208 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 0
  %209 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %21, i64 0, i32 0
  %210 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %21, i64 0, i32 1
  %211 = bitcast %"class.gemmlowp::VectorDup"* %22 to i8*
  %212 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %213 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %22, i64 0, i32 0
  %214 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %22, i64 0, i32 1
  %215 = load i32, i32* %34, align 4
  br label %221

216:                                              ; preds = %235, %169
  %217 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 0
  store i8 0, i8* %217, align 8
  %218 = load i64, i64* %65, align 8
  %219 = add i64 %218, 1
  store i64 %219, i64* %65, align 8
  %220 = bitcast i64* %61 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %220, i8 0, i64 16, i1 false) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %129) #19
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %90) #19
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %44) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %30) #19
  ret void

221:                                              ; preds = %171, %235
  %222 = phi i32 [ %215, %171 ], [ %236, %235 ]
  %223 = phi i32 [ 0, %171 ], [ %237, %235 ]
  %224 = sub nsw i32 %24, %223
  %225 = icmp slt i32 %224, %222
  %226 = select i1 %225, i32 %224, i32 %222
  %227 = load i8*, i8** %172, align 8, !noalias !1366
  %228 = load i32, i32* %173, align 8, !noalias !1366
  %229 = mul nsw i32 %228, %223
  %230 = sext i32 %229 to i64
  %231 = getelementptr inbounds i8, i8* %227, i64 %230
  %232 = ptrtoint i8* %231 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %174) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %174, i8 -86, i64 24, i1 false) #19
  store i64 %232, i64* %178, align 8
  store i32 %226, i32* %175, align 8
  store i32 %28, i32* %176, align 4
  store i32 %228, i32* %177, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %179) #19
  store %"class.gemmlowp::PackedSideBlock"* %17, %"class.gemmlowp::PackedSideBlock"** %180, align 8
  store %"class.gemmlowp::SideMap"* %11, %"class.gemmlowp::SideMap"** %181, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %12) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %179) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %174) #19
  br i1 %182, label %233, label %235

233:                                              ; preds = %221
  %234 = load i32, i32* %35, align 4
  br label %239

235:                                              ; preds = %311, %221
  %236 = load i32, i32* %34, align 4
  %237 = add nsw i32 %236, %223
  %238 = icmp sgt i32 %24, %237
  br i1 %238, label %221, label %216

239:                                              ; preds = %233, %311
  %240 = phi i32 [ %334, %311 ], [ %234, %233 ]
  %241 = phi i32 [ %335, %311 ], [ 0, %233 ]
  %242 = sub nsw i32 %26, %241
  %243 = icmp slt i32 %242, %240
  %244 = select i1 %243, i32 %242, i32 %240
  br i1 %151, label %252, label %245

245:                                              ; preds = %239
  %246 = load i8*, i8** %183, align 8, !noalias !1369
  %247 = load i32, i32* %184, align 8, !noalias !1369
  %248 = mul nsw i32 %247, %241
  %249 = sext i32 %248 to i64
  %250 = getelementptr inbounds i8, i8* %246, i64 %249
  %251 = ptrtoint i8* %250 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %185) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %185, i8 -86, i64 24, i1 false) #19
  store i64 %251, i64* %189, align 8
  store i32 %244, i32* %186, align 8
  store i32 %28, i32* %187, align 4
  store i32 %247, i32* %188, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %190) #19
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %191, align 8
  store %"class.gemmlowp::SideMap"* %13, %"class.gemmlowp::SideMap"** %192, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %14) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %190) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %185) #19
  br label %252

252:                                              ; preds = %245, %239
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %193) #19
  store %"struct.gemmlowp::KernelBase"* %1, %"struct.gemmlowp::KernelBase"** %194, align 8
  store %"struct.gemmlowp::BlockParams"* %16, %"struct.gemmlowp::BlockParams"** %195, align 8
  store %"class.gemmlowp::PackedResult"* %19, %"class.gemmlowp::PackedResult"** %196, align 8
  store %"class.gemmlowp::PackedSideBlock"* %17, %"class.gemmlowp::PackedSideBlock"** %197, align 8
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %198, align 8
  br i1 %201, label %253, label %311

253:                                              ; preds = %252, %271
  %254 = phi %"struct.gemmlowp::BlockParams"* [ %273, %271 ], [ %16, %252 ]
  %255 = phi %"struct.gemmlowp::BlockParams"* [ %274, %271 ], [ %16, %252 ]
  %256 = phi i32 [ %275, %271 ], [ 0, %252 ]
  %257 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 2
  %258 = sub nsw i32 %200, %256
  %259 = load i32, i32* %257, align 4
  %260 = icmp slt i32 %258, %259
  %261 = select i1 %260, i32 %258, i32 %259
  %262 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 3
  %263 = load i32, i32* %262, align 4
  %264 = icmp sgt i32 %263, 0
  br i1 %264, label %265, label %271

265:                                              ; preds = %253
  %266 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 0
  %267 = load i32, i32* %266, align 4
  br label %277

268:                                              ; preds = %303
  %269 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 2
  %270 = load i32, i32* %269, align 4
  br label %271

271:                                              ; preds = %268, %253
  %272 = phi i32 [ %259, %253 ], [ %270, %268 ]
  %273 = phi %"struct.gemmlowp::BlockParams"* [ %254, %253 ], [ %304, %268 ]
  %274 = phi %"struct.gemmlowp::BlockParams"* [ %255, %253 ], [ %304, %268 ]
  %275 = add nsw i32 %272, %256
  %276 = icmp sgt i32 %200, %275
  br i1 %276, label %253, label %311

277:                                              ; preds = %303, %265
  %278 = phi %"struct.gemmlowp::BlockParams"* [ %304, %303 ], [ %254, %265 ]
  %279 = phi i32 [ %306, %303 ], [ %267, %265 ]
  %280 = phi i32 [ %309, %303 ], [ %263, %265 ]
  %281 = phi %"struct.gemmlowp::BlockParams"* [ %304, %303 ], [ %255, %265 ]
  %282 = phi i32 [ %307, %303 ], [ 0, %265 ]
  %283 = sub nsw i32 %280, %282
  %284 = icmp slt i32 %283, %279
  %285 = select i1 %284, i32 %283, i32 %279
  %286 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %281, i64 0, i32 4
  %287 = load i32, i32* %286, align 4
  %288 = icmp sgt i32 %287, 0
  br i1 %288, label %289, label %303

289:                                              ; preds = %277
  %290 = icmp sgt i32 %285, 0
  br label %291

291:                                              ; preds = %293, %289
  %292 = phi i32 [ 0, %289 ], [ %294, %293 ]
  br i1 %290, label %296, label %293

293:                                              ; preds = %296, %291
  %294 = add nuw nsw i32 %292, 4
  %295 = icmp slt i32 %294, %287
  br i1 %295, label %291, label %301

296:                                              ; preds = %291, %296
  %297 = phi i32 [ %299, %296 ], [ 0, %291 ]
  %298 = add nsw i32 %297, %282
  call void @_ZN8gemmlowp11ComputeImplINS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEES7_NS_12PackedResultEE10ComputeRunEiiii(%"class.gemmlowp::ComputeImpl"* nonnull %15, i32 %298, i32 %292, i32 %256, i32 %261) #19
  %299 = add nuw nsw i32 %297, 4
  %300 = icmp slt i32 %299, %285
  br i1 %300, label %296, label %293

301:                                              ; preds = %293
  %302 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %195, align 8
  br label %303

303:                                              ; preds = %301, %277
  %304 = phi %"struct.gemmlowp::BlockParams"* [ %302, %301 ], [ %278, %277 ]
  %305 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 0
  %306 = load i32, i32* %305, align 4
  %307 = add nsw i32 %306, %282
  %308 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 3
  %309 = load i32, i32* %308, align 4
  %310 = icmp sgt i32 %309, %307
  br i1 %310, label %277, label %268

311:                                              ; preds = %271, %252
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %193) #19
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %202) #19
  store i32 %223, i32* %203, align 4
  store i32 %241, i32* %204, align 4
  store i32 %226, i32* %205, align 4
  store i32 %244, i32* %206, align 4
  %312 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %45, align 8
  %313 = load i8, i8* %86, align 8
  %314 = zext i8 %313 to i64
  %315 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %312, i64 0, i32 5, i64 %314
  %316 = load i64, i64* %315, align 8
  %317 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %312, i64 0, i32 2
  %318 = bitcast i8** %317 to i64*
  %319 = load i64, i64* %318, align 8
  %320 = add i64 %319, %316
  %321 = inttoptr i64 %320 to i32*
  %322 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %91, align 8
  %323 = load i8, i8* %125, align 8
  %324 = zext i8 %323 to i64
  %325 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %322, i64 0, i32 5, i64 %324
  %326 = load i64, i64* %325, align 8
  %327 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %322, i64 0, i32 2
  %328 = bitcast i8** %327 to i64*
  %329 = load i64, i64* %328, align 8
  %330 = add i64 %329, %326
  %331 = inttoptr i64 %330 to i32*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %207) #19
  %332 = load i32, i32* %208, align 4, !noalias !1372
  store i32 %332, i32* %209, align 4, !alias.scope !1372
  store i32 %226, i32* %210, align 4, !alias.scope !1372
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %211) #19
  %333 = load i32, i32* %212, align 4, !noalias !1375
  store i32 %333, i32* %213, align 4, !alias.scope !1375
  store i32 %244, i32* %214, align 4, !alias.scope !1375
  call void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIsLNS_8MapOrderE1EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE1EEENSC_ISD_LSE_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISD_LSE_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SZ_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.489"* %4, %"struct.gemmlowp::MatrixBlockBounds"* nonnull dereferenceable(16) %20, %"class.gemmlowp::PackedResult"* nonnull dereferenceable(40) %19, i32 %28, i32* %321, i32* %331, %"class.gemmlowp::VectorDup.194"* nonnull dereferenceable(8) %21, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %22, %"class.std::__1::tuple.491"* dereferenceable(40) %7)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %211) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %207) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %202) #19
  %334 = load i32, i32* %35, align 4
  %335 = add nsw i32 %334, %241
  %336 = icmp sgt i32 %26, %335
  br i1 %336, label %239, label %235
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIsLNS_8MapOrderE1EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE1EEENSC_ISD_LSE_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISD_LSE_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SZ_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.489"*, %"struct.gemmlowp::MatrixBlockBounds"* dereferenceable(16), %"class.gemmlowp::PackedResult"* dereferenceable(40), i32, i32*, i32*, %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.std::__1::tuple.491"* dereferenceable(40)) local_unnamed_addr #1 comdat {
  %10 = alloca %"struct.gemmlowp::RegisterBlock.559", align 8
  %11 = alloca %"class.gemmlowp::MatrixMap.214", align 8
  %12 = alloca %"class.gemmlowp::VectorMap", align 8
  %13 = alloca %"class.gemmlowp::VectorMap.201", align 8
  %14 = alloca %"struct.gemmlowp::OutputPipelineExecutor.495", align 8
  %15 = alloca %"struct.gemmlowp::OutputPipelineExecutor.506", align 8
  %16 = alloca %"struct.gemmlowp::OutputPipelineExecutor.517", align 8
  %17 = alloca %"struct.gemmlowp::OutputPipelineExecutor.528", align 8
  %18 = alloca %"struct.gemmlowp::OutputPipelineExecutor.537", align 8
  %19 = alloca %"struct.gemmlowp::OutputPipelineExecutor.548", align 8
  %20 = alloca [64 x i16], align 16
  %21 = alloca %"class.gemmlowp::MatrixMap.479", align 8
  %22 = bitcast %"class.gemmlowp::MatrixMap.214"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %22) #19
  %23 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %11, i64 0, i32 0
  %24 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %11, i64 0, i32 1
  %25 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %11, i64 0, i32 2
  %26 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %11, i64 0, i32 3
  %27 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 0
  %28 = bitcast %"class.gemmlowp::MatrixMap.214"* %11 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %28, i8 -86, i64 24, i1 false)
  %29 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %27, align 8, !noalias !1378
  %30 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 1, i32 0
  %31 = load i8, i8* %30, align 8, !noalias !1378
  %32 = zext i8 %31 to i64
  %33 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %29, i64 0, i32 5, i64 %32
  %34 = load i64, i64* %33, align 8, !noalias !1378
  %35 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %29, i64 0, i32 2
  %36 = bitcast i8** %35 to i64*
  %37 = load i64, i64* %36, align 8, !noalias !1378
  %38 = add i64 %37, %34
  %39 = inttoptr i64 %38 to i32*
  %40 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 2
  %41 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %40, align 8, !noalias !1378
  %42 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %41, i64 0, i32 3
  %43 = load i32, i32* %42, align 4, !noalias !1378
  %44 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %41, i64 0, i32 4
  %45 = load i32, i32* %44, align 4, !noalias !1378
  store i32* %39, i32** %23, align 8, !alias.scope !1378
  store i32 %43, i32* %24, align 8, !alias.scope !1378
  store i32 %45, i32* %25, align 4, !alias.scope !1378
  store i32 %43, i32* %26, align 8, !alias.scope !1378
  %46 = bitcast %"class.gemmlowp::VectorMap"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %46) #19
  %47 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %12, i64 0, i32 0
  %48 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %12, i64 0, i32 1
  %49 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 2
  %50 = bitcast %"class.gemmlowp::VectorMap"* %12 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %50, i8 -86, i64 16, i1 false)
  %51 = load i32, i32* %49, align 4
  store i32* %4, i32** %47, align 8
  store i32 %51, i32* %48, align 8
  %52 = bitcast %"class.gemmlowp::VectorMap.201"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %52) #19
  %53 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %13, i64 0, i32 0
  %54 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %13, i64 0, i32 1
  %55 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 3
  %56 = bitcast %"class.gemmlowp::VectorMap.201"* %13 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %56, i8 -86, i64 16, i1 false)
  %57 = load i32, i32* %55, align 4
  store i32* %5, i32** %53, align 8
  store i32 %57, i32* %54, align 8
  %58 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.495"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %58) #19
  %59 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.495", %"struct.gemmlowp::OutputPipelineExecutor.495"* %14, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %60 = bitcast i8* %59 to i64*
  store i64 -6148914691236517206, i64* %60, align 8
  %61 = getelementptr inbounds %"class.std::__1::tuple.491", %"class.std::__1::tuple.491"* %8, i64 0, i32 0, i32 0, i32 0
  %62 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.495", %"struct.gemmlowp::OutputPipelineExecutor.495"* %14, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition.200"* %61, %"struct.gemmlowp::OutputStageBiasAddition.200"** %62, align 8
  %63 = getelementptr inbounds %"class.std::__1::tuple.491", %"class.std::__1::tuple.491"* %8, i64 0, i32 0, i32 1, i32 0
  %64 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.495", %"struct.gemmlowp::OutputPipelineExecutor.495"* %14, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %63, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %64, align 8
  %65 = getelementptr inbounds %"class.std::__1::tuple.491", %"class.std::__1::tuple.491"* %8, i64 0, i32 0, i32 1, i32 0, i32 1
  %66 = load i32, i32* %65, align 4
  %67 = icmp sgt i32 %66, 0
  %68 = select i1 %67, i32 %66, i32 0
  %69 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.495", %"struct.gemmlowp::OutputPipelineExecutor.495"* %14, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %68, i32* %69, align 8
  %70 = sub nsw i32 0, %66
  %71 = icmp sgt i32 %70, 0
  %72 = select i1 %71, i32 %70, i32 0
  %73 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.495", %"struct.gemmlowp::OutputPipelineExecutor.495"* %14, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %72, i32* %73, align 4
  %74 = getelementptr inbounds %"class.std::__1::tuple.491", %"class.std::__1::tuple.491"* %8, i64 0, i32 0, i32 2, i32 0
  %75 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.495", %"struct.gemmlowp::OutputPipelineExecutor.495"* %14, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %74, %"struct.gemmlowp::OutputStageClamp"** %75, align 8
  %76 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.506"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %76) #19
  %77 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.506", %"struct.gemmlowp::OutputPipelineExecutor.506"* %15, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %78 = bitcast i8* %77 to i64*
  store i64 -6148914691236517206, i64* %78, align 8
  %79 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.506", %"struct.gemmlowp::OutputPipelineExecutor.506"* %15, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition.200"* %61, %"struct.gemmlowp::OutputStageBiasAddition.200"** %79, align 8
  %80 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.506", %"struct.gemmlowp::OutputPipelineExecutor.506"* %15, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %63, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %80, align 8
  %81 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.506", %"struct.gemmlowp::OutputPipelineExecutor.506"* %15, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %68, i32* %81, align 8
  %82 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.506", %"struct.gemmlowp::OutputPipelineExecutor.506"* %15, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %72, i32* %82, align 4
  %83 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.506", %"struct.gemmlowp::OutputPipelineExecutor.506"* %15, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %74, %"struct.gemmlowp::OutputStageClamp"** %83, align 8
  %84 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.517"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %84) #19
  %85 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.517", %"struct.gemmlowp::OutputPipelineExecutor.517"* %16, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %86 = bitcast i8* %85 to i64*
  store i64 -6148914691236517206, i64* %86, align 8
  %87 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.517", %"struct.gemmlowp::OutputPipelineExecutor.517"* %16, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition.200"* %61, %"struct.gemmlowp::OutputStageBiasAddition.200"** %87, align 8
  %88 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.517", %"struct.gemmlowp::OutputPipelineExecutor.517"* %16, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %63, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %88, align 8
  %89 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.517", %"struct.gemmlowp::OutputPipelineExecutor.517"* %16, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %68, i32* %89, align 8
  %90 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.517", %"struct.gemmlowp::OutputPipelineExecutor.517"* %16, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %72, i32* %90, align 4
  %91 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.517", %"struct.gemmlowp::OutputPipelineExecutor.517"* %16, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %74, %"struct.gemmlowp::OutputStageClamp"** %91, align 8
  %92 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.528"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %92) #19
  %93 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.528", %"struct.gemmlowp::OutputPipelineExecutor.528"* %17, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %94 = bitcast i8* %93 to i64*
  store i64 -6148914691236517206, i64* %94, align 8
  %95 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.528", %"struct.gemmlowp::OutputPipelineExecutor.528"* %17, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition.200"* %61, %"struct.gemmlowp::OutputStageBiasAddition.200"** %95, align 8
  %96 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.528", %"struct.gemmlowp::OutputPipelineExecutor.528"* %17, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %63, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %96, align 8
  %97 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.528", %"struct.gemmlowp::OutputPipelineExecutor.528"* %17, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %68, i32* %97, align 8
  %98 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.528", %"struct.gemmlowp::OutputPipelineExecutor.528"* %17, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %72, i32* %98, align 4
  %99 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.528", %"struct.gemmlowp::OutputPipelineExecutor.528"* %17, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %74, %"struct.gemmlowp::OutputStageClamp"** %99, align 8
  %100 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.537"* %18 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %100) #19
  %101 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.537", %"struct.gemmlowp::OutputPipelineExecutor.537"* %18, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %102 = bitcast i8* %101 to i64*
  store i64 -6148914691236517206, i64* %102, align 8
  %103 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.537", %"struct.gemmlowp::OutputPipelineExecutor.537"* %18, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition.200"* %61, %"struct.gemmlowp::OutputStageBiasAddition.200"** %103, align 8
  %104 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.537", %"struct.gemmlowp::OutputPipelineExecutor.537"* %18, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %63, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %104, align 8
  %105 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.537", %"struct.gemmlowp::OutputPipelineExecutor.537"* %18, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %68, i32* %105, align 8
  %106 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.537", %"struct.gemmlowp::OutputPipelineExecutor.537"* %18, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %72, i32* %106, align 4
  %107 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.537", %"struct.gemmlowp::OutputPipelineExecutor.537"* %18, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %74, %"struct.gemmlowp::OutputStageClamp"** %107, align 8
  %108 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.548"* %19 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %108) #19
  %109 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.548", %"struct.gemmlowp::OutputPipelineExecutor.548"* %19, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %110 = bitcast i8* %109 to i64*
  store i64 -6148914691236517206, i64* %110, align 8
  %111 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.548", %"struct.gemmlowp::OutputPipelineExecutor.548"* %19, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition.200"* %61, %"struct.gemmlowp::OutputStageBiasAddition.200"** %111, align 8
  %112 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.548", %"struct.gemmlowp::OutputPipelineExecutor.548"* %19, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %63, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %112, align 8
  %113 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.548", %"struct.gemmlowp::OutputPipelineExecutor.548"* %19, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %68, i32* %113, align 8
  %114 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.548", %"struct.gemmlowp::OutputPipelineExecutor.548"* %19, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %72, i32* %114, align 4
  %115 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.548", %"struct.gemmlowp::OutputPipelineExecutor.548"* %19, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %74, %"struct.gemmlowp::OutputStageClamp"** %115, align 8
  %116 = icmp slt i32 %57, 8
  br i1 %116, label %130, label %117

117:                                              ; preds = %9
  %118 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 0
  %119 = bitcast [64 x i16]* %20 to i8*
  %120 = bitcast %"class.gemmlowp::MatrixMap.479"* %21 to i8*
  %121 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %21, i64 0, i32 0
  %122 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %21, i64 0, i32 1
  %123 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %21, i64 0, i32 2
  %124 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %21, i64 0, i32 3
  %125 = getelementptr inbounds [64 x i16], [64 x i16]* %20, i64 0, i64 0
  %126 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 1
  %127 = bitcast %"struct.gemmlowp::RegisterBlock.559"* %10 to i8*
  %128 = load i32, i32* %49, align 4
  %129 = bitcast %"class.gemmlowp::MatrixMap.479"* %21 to i8*
  br label %139

130:                                              ; preds = %301, %9
  %131 = phi i32 [ %57, %9 ], [ %304, %301 ]
  %132 = phi i32 [ 0, %9 ], [ %303, %301 ]
  %133 = add nsw i32 %131, -4
  %134 = icmp sgt i32 %132, %133
  br i1 %134, label %307, label %135

135:                                              ; preds = %130
  %136 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 1
  %137 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 0
  %138 = load i32, i32* %49, align 4
  br label %318

139:                                              ; preds = %117, %301
  %140 = phi i32 [ %128, %117 ], [ %302, %301 ]
  %141 = phi i32 [ 0, %117 ], [ %303, %301 ]
  %142 = load i32*, i32** %23, align 8
  %143 = load i32, i32* %26, align 8
  %144 = mul nsw i32 %143, %141
  %145 = sext i32 %144 to i64
  %146 = load i32*, i32** %47, align 8
  %147 = bitcast i32* %146 to i8*
  call void @llvm.prefetch(i8* %147, i32 0, i32 3, i32 1) #19
  %148 = getelementptr inbounds i32, i32* %146, i64 4
  %149 = bitcast i32* %148 to i8*
  call void @llvm.prefetch(i8* %149, i32 0, i32 3, i32 1) #19
  %150 = getelementptr inbounds i32, i32* %142, i64 %145
  %151 = sext i32 %143 to i64
  %152 = bitcast i32* %150 to i8*
  call void @llvm.prefetch(i8* %152, i32 0, i32 3, i32 1) #19
  %153 = getelementptr inbounds i32, i32* %150, i64 4
  %154 = bitcast i32* %153 to i8*
  call void @llvm.prefetch(i8* %154, i32 0, i32 3, i32 1) #19
  %155 = getelementptr inbounds i32, i32* %150, i64 %151
  %156 = bitcast i32* %155 to i8*
  call void @llvm.prefetch(i8* %156, i32 0, i32 3, i32 1) #19
  %157 = getelementptr inbounds i32, i32* %155, i64 4
  %158 = bitcast i32* %157 to i8*
  call void @llvm.prefetch(i8* %158, i32 0, i32 3, i32 1) #19
  %159 = shl nsw i64 %151, 1
  %160 = getelementptr inbounds i32, i32* %150, i64 %159
  %161 = bitcast i32* %160 to i8*
  call void @llvm.prefetch(i8* %161, i32 0, i32 3, i32 1) #19
  %162 = getelementptr inbounds i32, i32* %160, i64 4
  %163 = bitcast i32* %162 to i8*
  call void @llvm.prefetch(i8* %163, i32 0, i32 3, i32 1) #19
  %164 = mul nsw i64 %151, 3
  %165 = getelementptr inbounds i32, i32* %150, i64 %164
  %166 = bitcast i32* %165 to i8*
  call void @llvm.prefetch(i8* %166, i32 0, i32 3, i32 1) #19
  %167 = getelementptr inbounds i32, i32* %165, i64 4
  %168 = bitcast i32* %167 to i8*
  call void @llvm.prefetch(i8* %168, i32 0, i32 3, i32 1) #19
  %169 = shl nsw i64 %151, 2
  %170 = getelementptr inbounds i32, i32* %150, i64 %169
  %171 = bitcast i32* %170 to i8*
  call void @llvm.prefetch(i8* %171, i32 0, i32 3, i32 1) #19
  %172 = getelementptr inbounds i32, i32* %170, i64 4
  %173 = bitcast i32* %172 to i8*
  call void @llvm.prefetch(i8* %173, i32 0, i32 3, i32 1) #19
  %174 = mul nsw i64 %151, 5
  %175 = getelementptr inbounds i32, i32* %150, i64 %174
  %176 = bitcast i32* %175 to i8*
  call void @llvm.prefetch(i8* %176, i32 0, i32 3, i32 1) #19
  %177 = getelementptr inbounds i32, i32* %175, i64 4
  %178 = bitcast i32* %177 to i8*
  call void @llvm.prefetch(i8* %178, i32 0, i32 3, i32 1) #19
  %179 = mul nsw i64 %151, 6
  %180 = getelementptr inbounds i32, i32* %150, i64 %179
  %181 = bitcast i32* %180 to i8*
  call void @llvm.prefetch(i8* %181, i32 0, i32 3, i32 1) #19
  %182 = getelementptr inbounds i32, i32* %180, i64 4
  %183 = bitcast i32* %182 to i8*
  call void @llvm.prefetch(i8* %183, i32 0, i32 3, i32 1) #19
  %184 = mul nsw i64 %151, 7
  %185 = getelementptr inbounds i32, i32* %150, i64 %184
  %186 = bitcast i32* %185 to i8*
  call void @llvm.prefetch(i8* %186, i32 0, i32 3, i32 1) #19
  %187 = getelementptr inbounds i32, i32* %185, i64 4
  %188 = bitcast i32* %187 to i8*
  call void @llvm.prefetch(i8* %188, i32 0, i32 3, i32 1) #19
  %189 = icmp slt i32 %140, 8
  br i1 %189, label %194, label %190

190:                                              ; preds = %139
  %191 = or i32 %141, 4
  br label %201

192:                                              ; preds = %201
  %193 = trunc i64 %209 to i32
  br label %194

194:                                              ; preds = %192, %139
  %195 = phi i32 [ %140, %139 ], [ %264, %192 ]
  %196 = phi i32 [ 0, %139 ], [ %193, %192 ]
  %197 = add nsw i32 %195, -4
  %198 = icmp sgt i32 %196, %197
  br i1 %198, label %272, label %199

199:                                              ; preds = %194
  %200 = or i32 %141, 4
  br label %278

201:                                              ; preds = %268, %190
  %202 = phi i32* [ %146, %190 ], [ %271, %268 ]
  %203 = phi i32 [ %143, %190 ], [ %270, %268 ]
  %204 = phi i32* [ %142, %190 ], [ %269, %268 ]
  %205 = phi i64 [ 0, %190 ], [ %209, %268 ]
  %206 = load i32, i32* %118, align 4
  %207 = trunc i64 %205 to i32
  %208 = add nsw i32 %206, %207
  %209 = add nuw i64 %205, 8
  %210 = mul nsw i32 %203, %141
  %211 = sext i32 %210 to i64
  %212 = getelementptr inbounds i32, i32* %202, i64 %209
  %213 = bitcast i32* %212 to i8*
  call void @llvm.prefetch(i8* %213, i32 0, i32 3, i32 1) #19
  %214 = getelementptr inbounds i32, i32* %212, i64 4
  %215 = bitcast i32* %214 to i8*
  call void @llvm.prefetch(i8* %215, i32 0, i32 3, i32 1) #19
  %216 = getelementptr inbounds i32, i32* %204, i64 %209
  %217 = getelementptr inbounds i32, i32* %216, i64 %211
  %218 = sext i32 %203 to i64
  %219 = bitcast i32* %217 to i8*
  call void @llvm.prefetch(i8* %219, i32 0, i32 3, i32 1) #19
  %220 = getelementptr inbounds i32, i32* %217, i64 4
  %221 = bitcast i32* %220 to i8*
  call void @llvm.prefetch(i8* %221, i32 0, i32 3, i32 1) #19
  %222 = getelementptr inbounds i32, i32* %217, i64 %218
  %223 = bitcast i32* %222 to i8*
  call void @llvm.prefetch(i8* %223, i32 0, i32 3, i32 1) #19
  %224 = getelementptr inbounds i32, i32* %222, i64 4
  %225 = bitcast i32* %224 to i8*
  call void @llvm.prefetch(i8* %225, i32 0, i32 3, i32 1) #19
  %226 = shl nsw i64 %218, 1
  %227 = getelementptr inbounds i32, i32* %217, i64 %226
  %228 = bitcast i32* %227 to i8*
  call void @llvm.prefetch(i8* %228, i32 0, i32 3, i32 1) #19
  %229 = getelementptr inbounds i32, i32* %227, i64 4
  %230 = bitcast i32* %229 to i8*
  call void @llvm.prefetch(i8* %230, i32 0, i32 3, i32 1) #19
  %231 = mul nsw i64 %218, 3
  %232 = getelementptr inbounds i32, i32* %217, i64 %231
  %233 = bitcast i32* %232 to i8*
  call void @llvm.prefetch(i8* %233, i32 0, i32 3, i32 1) #19
  %234 = getelementptr inbounds i32, i32* %232, i64 4
  %235 = bitcast i32* %234 to i8*
  call void @llvm.prefetch(i8* %235, i32 0, i32 3, i32 1) #19
  %236 = shl nsw i64 %218, 2
  %237 = getelementptr inbounds i32, i32* %217, i64 %236
  %238 = bitcast i32* %237 to i8*
  call void @llvm.prefetch(i8* %238, i32 0, i32 3, i32 1) #19
  %239 = getelementptr inbounds i32, i32* %237, i64 4
  %240 = bitcast i32* %239 to i8*
  call void @llvm.prefetch(i8* %240, i32 0, i32 3, i32 1) #19
  %241 = mul nsw i64 %218, 5
  %242 = getelementptr inbounds i32, i32* %217, i64 %241
  %243 = bitcast i32* %242 to i8*
  call void @llvm.prefetch(i8* %243, i32 0, i32 3, i32 1) #19
  %244 = getelementptr inbounds i32, i32* %242, i64 4
  %245 = bitcast i32* %244 to i8*
  call void @llvm.prefetch(i8* %245, i32 0, i32 3, i32 1) #19
  %246 = mul nsw i64 %218, 6
  %247 = getelementptr inbounds i32, i32* %217, i64 %246
  %248 = bitcast i32* %247 to i8*
  call void @llvm.prefetch(i8* %248, i32 0, i32 3, i32 1) #19
  %249 = getelementptr inbounds i32, i32* %247, i64 4
  %250 = bitcast i32* %249 to i8*
  call void @llvm.prefetch(i8* %250, i32 0, i32 3, i32 1) #19
  %251 = mul nsw i64 %218, 7
  %252 = getelementptr inbounds i32, i32* %217, i64 %251
  %253 = bitcast i32* %252 to i8*
  call void @llvm.prefetch(i8* %253, i32 0, i32 3, i32 1) #19
  %254 = getelementptr inbounds i32, i32* %252, i64 4
  %255 = bitcast i32* %254 to i8*
  call void @llvm.prefetch(i8* %255, i32 0, i32 3, i32 1) #19
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %119) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %119, i8 -86, i64 128, i1 false)
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %120) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %129, i8 -86, i64 24, i1 false)
  store i16* %125, i16** %121, align 8
  store i32 8, i32* %122, align 8
  store i32 8, i32* %123, align 4
  store i32 8, i32* %124, align 8
  %256 = load i32, i32* %126, align 4
  %257 = add nsw i32 %256, %141
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.548"* nonnull dereferenceable(40) %19, %"class.gemmlowp::MatrixMap.479"* nonnull %21, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %207, i32 %141, i32 %208, i32 %257, i32 0, i32 0)
  %258 = load i32, i32* %126, align 4
  %259 = add nsw i32 %258, %191
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.548"* nonnull dereferenceable(40) %19, %"class.gemmlowp::MatrixMap.479"* nonnull %21, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %207, i32 %191, i32 %208, i32 %259, i32 0, i32 4)
  %260 = load i32, i32* %118, align 4
  %261 = add nsw i32 %260, %207
  %262 = load i32, i32* %126, align 4
  %263 = add nsw i32 %262, %141
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %127)
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %127, i8* nonnull align 16 %119, i64 128, i1 false)
  call void @_ZN8gemmlowp20StoreFinalOutputImplINS_13RegisterBlockIsLi8ELi8EEENS_9MatrixMapIsLNS_8MapOrderE1EEEE3RunERKS2_PS5_ii(%"struct.gemmlowp::RegisterBlock.559"* nonnull dereferenceable(128) %10, %"class.gemmlowp::MatrixMap.489"* %0, i32 %261, i32 %263) #19
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %127)
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %120) #19
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %119) #19
  %264 = load i32, i32* %49, align 4
  %265 = add nsw i32 %264, -8
  %266 = trunc i64 %209 to i32
  %267 = icmp slt i32 %265, %266
  br i1 %267, label %192, label %268

268:                                              ; preds = %201
  %269 = load i32*, i32** %23, align 8
  %270 = load i32, i32* %26, align 8
  %271 = load i32*, i32** %47, align 8
  br label %201

272:                                              ; preds = %278, %194
  %273 = phi i32 [ %195, %194 ], [ %287, %278 ]
  %274 = phi i32 [ %196, %194 ], [ %286, %278 ]
  %275 = icmp slt i32 %274, %273
  br i1 %275, label %276, label %301

276:                                              ; preds = %272
  %277 = or i32 %141, 4
  br label %290

278:                                              ; preds = %199, %278
  %279 = phi i32 [ %286, %278 ], [ %196, %199 ]
  %280 = load i32, i32* %118, align 4
  %281 = add nsw i32 %280, %279
  %282 = load i32, i32* %126, align 4
  %283 = add nsw i32 %282, %141
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.537"* nonnull dereferenceable(40) %18, %"class.gemmlowp::MatrixMap.489"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %279, i32 %141, i32 %281, i32 %283, i32 %281, i32 %283)
  %284 = load i32, i32* %126, align 4
  %285 = add nsw i32 %284, %200
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.537"* nonnull dereferenceable(40) %18, %"class.gemmlowp::MatrixMap.489"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %279, i32 %200, i32 %281, i32 %285, i32 %281, i32 %285)
  %286 = add nuw nsw i32 %279, 4
  %287 = load i32, i32* %49, align 4
  %288 = add nsw i32 %287, -4
  %289 = icmp sgt i32 %286, %288
  br i1 %289, label %272, label %278

290:                                              ; preds = %276, %290
  %291 = phi i32 [ %298, %290 ], [ %274, %276 ]
  %292 = load i32, i32* %118, align 4
  %293 = add nsw i32 %292, %291
  %294 = load i32, i32* %126, align 4
  %295 = add nsw i32 %294, %141
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.528"* nonnull dereferenceable(40) %17, %"class.gemmlowp::MatrixMap.489"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %291, i32 %141, i32 %293, i32 %295, i32 %293, i32 %295)
  %296 = load i32, i32* %126, align 4
  %297 = add nsw i32 %296, %277
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.528"* nonnull dereferenceable(40) %17, %"class.gemmlowp::MatrixMap.489"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %291, i32 %277, i32 %293, i32 %297, i32 %293, i32 %297)
  %298 = add nuw nsw i32 %291, 1
  %299 = load i32, i32* %49, align 4
  %300 = icmp slt i32 %298, %299
  br i1 %300, label %290, label %301

301:                                              ; preds = %290, %272
  %302 = phi i32 [ %273, %272 ], [ %299, %290 ]
  %303 = add nuw nsw i32 %141, 8
  %304 = load i32, i32* %55, align 4
  %305 = add nsw i32 %304, -8
  %306 = icmp sgt i32 %303, %305
  br i1 %306, label %130, label %139

307:                                              ; preds = %420, %130
  %308 = phi i32 [ %131, %130 ], [ %423, %420 ]
  %309 = phi i32 [ %132, %130 ], [ %422, %420 ]
  %310 = icmp slt i32 %309, %308
  br i1 %310, label %311, label %565

311:                                              ; preds = %307
  %312 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 1
  %313 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 0
  %314 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %6, i64 0, i32 0
  %315 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %7, i64 0, i32 0
  %316 = zext i32 %309 to i64
  %317 = load i32, i32* %49, align 4
  br label %426

318:                                              ; preds = %135, %420
  %319 = phi i32 [ %138, %135 ], [ %421, %420 ]
  %320 = phi i32 [ %132, %135 ], [ %422, %420 ]
  %321 = load i32, i32* %136, align 4
  %322 = add nsw i32 %321, %320
  %323 = load i32*, i32** %23, align 8
  %324 = load i32, i32* %26, align 8
  %325 = mul nsw i32 %324, %320
  %326 = sext i32 %325 to i64
  %327 = load i32*, i32** %47, align 8
  %328 = bitcast i32* %327 to i8*
  call void @llvm.prefetch(i8* %328, i32 0, i32 3, i32 1) #19
  %329 = getelementptr inbounds i32, i32* %327, i64 4
  %330 = bitcast i32* %329 to i8*
  call void @llvm.prefetch(i8* %330, i32 0, i32 3, i32 1) #19
  %331 = getelementptr inbounds i32, i32* %323, i64 %326
  %332 = sext i32 %324 to i64
  %333 = bitcast i32* %331 to i8*
  call void @llvm.prefetch(i8* %333, i32 0, i32 3, i32 1) #19
  %334 = getelementptr inbounds i32, i32* %331, i64 4
  %335 = bitcast i32* %334 to i8*
  call void @llvm.prefetch(i8* %335, i32 0, i32 3, i32 1) #19
  %336 = getelementptr inbounds i32, i32* %331, i64 %332
  %337 = bitcast i32* %336 to i8*
  call void @llvm.prefetch(i8* %337, i32 0, i32 3, i32 1) #19
  %338 = getelementptr inbounds i32, i32* %336, i64 4
  %339 = bitcast i32* %338 to i8*
  call void @llvm.prefetch(i8* %339, i32 0, i32 3, i32 1) #19
  %340 = shl nsw i64 %332, 1
  %341 = getelementptr inbounds i32, i32* %331, i64 %340
  %342 = bitcast i32* %341 to i8*
  call void @llvm.prefetch(i8* %342, i32 0, i32 3, i32 1) #19
  %343 = getelementptr inbounds i32, i32* %341, i64 4
  %344 = bitcast i32* %343 to i8*
  call void @llvm.prefetch(i8* %344, i32 0, i32 3, i32 1) #19
  %345 = mul nsw i64 %332, 3
  %346 = getelementptr inbounds i32, i32* %331, i64 %345
  %347 = bitcast i32* %346 to i8*
  call void @llvm.prefetch(i8* %347, i32 0, i32 3, i32 1) #19
  %348 = getelementptr inbounds i32, i32* %346, i64 4
  %349 = bitcast i32* %348 to i8*
  call void @llvm.prefetch(i8* %349, i32 0, i32 3, i32 1) #19
  %350 = icmp slt i32 %319, 8
  br i1 %350, label %353, label %358

351:                                              ; preds = %358
  %352 = trunc i64 %366 to i32
  br label %353

353:                                              ; preds = %351, %318
  %354 = phi i32 [ %319, %318 ], [ %393, %351 ]
  %355 = phi i32 [ 0, %318 ], [ %352, %351 ]
  %356 = add nsw i32 %354, -4
  %357 = icmp sgt i32 %355, %356
  br i1 %357, label %401, label %405

358:                                              ; preds = %318, %397
  %359 = phi i32* [ %400, %397 ], [ %327, %318 ]
  %360 = phi i32 [ %399, %397 ], [ %324, %318 ]
  %361 = phi i32* [ %398, %397 ], [ %323, %318 ]
  %362 = phi i64 [ %366, %397 ], [ 0, %318 ]
  %363 = load i32, i32* %137, align 4
  %364 = trunc i64 %362 to i32
  %365 = add nsw i32 %363, %364
  %366 = add nuw i64 %362, 8
  %367 = mul nsw i32 %360, %320
  %368 = sext i32 %367 to i64
  %369 = getelementptr inbounds i32, i32* %359, i64 %366
  %370 = bitcast i32* %369 to i8*
  call void @llvm.prefetch(i8* %370, i32 0, i32 3, i32 1) #19
  %371 = getelementptr inbounds i32, i32* %369, i64 4
  %372 = bitcast i32* %371 to i8*
  call void @llvm.prefetch(i8* %372, i32 0, i32 3, i32 1) #19
  %373 = getelementptr inbounds i32, i32* %361, i64 %366
  %374 = getelementptr inbounds i32, i32* %373, i64 %368
  %375 = sext i32 %360 to i64
  %376 = bitcast i32* %374 to i8*
  call void @llvm.prefetch(i8* %376, i32 0, i32 3, i32 1) #19
  %377 = getelementptr inbounds i32, i32* %374, i64 4
  %378 = bitcast i32* %377 to i8*
  call void @llvm.prefetch(i8* %378, i32 0, i32 3, i32 1) #19
  %379 = getelementptr inbounds i32, i32* %374, i64 %375
  %380 = bitcast i32* %379 to i8*
  call void @llvm.prefetch(i8* %380, i32 0, i32 3, i32 1) #19
  %381 = getelementptr inbounds i32, i32* %379, i64 4
  %382 = bitcast i32* %381 to i8*
  call void @llvm.prefetch(i8* %382, i32 0, i32 3, i32 1) #19
  %383 = shl nsw i64 %375, 1
  %384 = getelementptr inbounds i32, i32* %374, i64 %383
  %385 = bitcast i32* %384 to i8*
  call void @llvm.prefetch(i8* %385, i32 0, i32 3, i32 1) #19
  %386 = getelementptr inbounds i32, i32* %384, i64 4
  %387 = bitcast i32* %386 to i8*
  call void @llvm.prefetch(i8* %387, i32 0, i32 3, i32 1) #19
  %388 = mul nsw i64 %375, 3
  %389 = getelementptr inbounds i32, i32* %374, i64 %388
  %390 = bitcast i32* %389 to i8*
  call void @llvm.prefetch(i8* %390, i32 0, i32 3, i32 1) #19
  %391 = getelementptr inbounds i32, i32* %389, i64 4
  %392 = bitcast i32* %391 to i8*
  call void @llvm.prefetch(i8* %392, i32 0, i32 3, i32 1) #19
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.548"* nonnull dereferenceable(40) %19, %"class.gemmlowp::MatrixMap.489"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %364, i32 %320, i32 %365, i32 %322, i32 %365, i32 %322)
  %393 = load i32, i32* %49, align 4
  %394 = add nsw i32 %393, -8
  %395 = trunc i64 %366 to i32
  %396 = icmp slt i32 %394, %395
  br i1 %396, label %351, label %397

397:                                              ; preds = %358
  %398 = load i32*, i32** %23, align 8
  %399 = load i32, i32* %26, align 8
  %400 = load i32*, i32** %47, align 8
  br label %358

401:                                              ; preds = %405, %353
  %402 = phi i32 [ %354, %353 ], [ %410, %405 ]
  %403 = phi i32 [ %355, %353 ], [ %409, %405 ]
  %404 = icmp slt i32 %403, %402
  br i1 %404, label %413, label %420

405:                                              ; preds = %353, %405
  %406 = phi i32 [ %409, %405 ], [ %355, %353 ]
  %407 = load i32, i32* %137, align 4
  %408 = add nsw i32 %407, %406
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.537"* nonnull dereferenceable(40) %18, %"class.gemmlowp::MatrixMap.489"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %406, i32 %320, i32 %408, i32 %322, i32 %408, i32 %322)
  %409 = add nuw nsw i32 %406, 4
  %410 = load i32, i32* %49, align 4
  %411 = add nsw i32 %410, -4
  %412 = icmp sgt i32 %409, %411
  br i1 %412, label %401, label %405

413:                                              ; preds = %401, %413
  %414 = phi i32 [ %417, %413 ], [ %403, %401 ]
  %415 = load i32, i32* %137, align 4
  %416 = add nsw i32 %415, %414
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.528"* nonnull dereferenceable(40) %17, %"class.gemmlowp::MatrixMap.489"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %414, i32 %320, i32 %416, i32 %322, i32 %416, i32 %322)
  %417 = add nuw nsw i32 %414, 1
  %418 = load i32, i32* %49, align 4
  %419 = icmp slt i32 %417, %418
  br i1 %419, label %413, label %420

420:                                              ; preds = %413, %401
  %421 = phi i32 [ %402, %401 ], [ %418, %413 ]
  %422 = add nuw nsw i32 %320, 4
  %423 = load i32, i32* %55, align 4
  %424 = add nsw i32 %423, -4
  %425 = icmp sgt i32 %422, %424
  br i1 %425, label %307, label %318

426:                                              ; preds = %311, %559
  %427 = phi i32 [ %317, %311 ], [ %560, %559 ]
  %428 = phi i64 [ %316, %311 ], [ %561, %559 ]
  %429 = load i32, i32* %312, align 4
  %430 = trunc i64 %428 to i32
  %431 = add nsw i32 %429, %430
  %432 = load i32*, i32** %23, align 8
  %433 = load i32, i32* %26, align 8
  %434 = mul nsw i32 %433, %430
  %435 = sext i32 %434 to i64
  %436 = load i32*, i32** %47, align 8
  %437 = bitcast i32* %436 to i8*
  call void @llvm.prefetch(i8* %437, i32 0, i32 3, i32 1) #19
  %438 = getelementptr inbounds i32, i32* %436, i64 4
  %439 = bitcast i32* %438 to i8*
  call void @llvm.prefetch(i8* %439, i32 0, i32 3, i32 1) #19
  %440 = getelementptr inbounds i32, i32* %432, i64 %435
  %441 = bitcast i32* %440 to i8*
  call void @llvm.prefetch(i8* %441, i32 0, i32 3, i32 1) #19
  %442 = getelementptr inbounds i32, i32* %440, i64 4
  %443 = bitcast i32* %442 to i8*
  call void @llvm.prefetch(i8* %443, i32 0, i32 3, i32 1) #19
  %444 = icmp slt i32 %427, 8
  br i1 %444, label %447, label %454

445:                                              ; preds = %454
  %446 = trunc i64 %462 to i32
  br label %447

447:                                              ; preds = %445, %426
  %448 = phi i32 [ %427, %426 ], [ %474, %445 ]
  %449 = phi i32 [ 0, %426 ], [ %446, %445 ]
  %450 = add nsw i32 %448, -4
  %451 = icmp sgt i32 %449, %450
  br i1 %451, label %484, label %452

452:                                              ; preds = %447
  %453 = zext i32 %449 to i64
  br label %488

454:                                              ; preds = %426, %478
  %455 = phi i32* [ %481, %478 ], [ %436, %426 ]
  %456 = phi i32 [ %480, %478 ], [ %433, %426 ]
  %457 = phi i32* [ %479, %478 ], [ %432, %426 ]
  %458 = phi i64 [ %462, %478 ], [ 0, %426 ]
  %459 = load i32, i32* %313, align 4
  %460 = trunc i64 %458 to i32
  %461 = add nsw i32 %459, %460
  %462 = add nuw i64 %458, 8
  %463 = mul nsw i32 %456, %430
  %464 = sext i32 %463 to i64
  %465 = getelementptr inbounds i32, i32* %455, i64 %462
  %466 = bitcast i32* %465 to i8*
  call void @llvm.prefetch(i8* %466, i32 0, i32 3, i32 1) #19
  %467 = getelementptr inbounds i32, i32* %465, i64 4
  %468 = bitcast i32* %467 to i8*
  call void @llvm.prefetch(i8* %468, i32 0, i32 3, i32 1) #19
  %469 = getelementptr inbounds i32, i32* %457, i64 %462
  %470 = getelementptr inbounds i32, i32* %469, i64 %464
  %471 = bitcast i32* %470 to i8*
  call void @llvm.prefetch(i8* %471, i32 0, i32 3, i32 1) #19
  %472 = getelementptr inbounds i32, i32* %470, i64 4
  %473 = bitcast i32* %472 to i8*
  call void @llvm.prefetch(i8* %473, i32 0, i32 3, i32 1) #19
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.517"* nonnull dereferenceable(40) %16, %"class.gemmlowp::MatrixMap.489"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %460, i32 %430, i32 %461, i32 %431, i32 %461, i32 %431)
  %474 = load i32, i32* %49, align 4
  %475 = add nsw i32 %474, -8
  %476 = trunc i64 %462 to i32
  %477 = icmp slt i32 %475, %476
  br i1 %477, label %445, label %478

478:                                              ; preds = %454
  %479 = load i32*, i32** %23, align 8
  %480 = load i32, i32* %26, align 8
  %481 = load i32*, i32** %47, align 8
  br label %454

482:                                              ; preds = %488
  %483 = trunc i64 %547 to i32
  br label %484

484:                                              ; preds = %482, %447
  %485 = phi i32 [ %448, %447 ], [ %548, %482 ]
  %486 = phi i32 [ %449, %447 ], [ %483, %482 ]
  %487 = icmp slt i32 %486, %485
  br i1 %487, label %552, label %559

488:                                              ; preds = %452, %488
  %489 = phi i64 [ %453, %452 ], [ %547, %488 ]
  %490 = load i32, i32* %313, align 4
  %491 = trunc i64 %489 to i32
  %492 = add nsw i32 %490, %491
  %493 = load i32*, i32** %23, align 8
  %494 = getelementptr inbounds i32, i32* %493, i64 %489
  %495 = load i32, i32* %26, align 8
  %496 = mul nsw i32 %495, %430
  %497 = sext i32 %496 to i64
  %498 = getelementptr inbounds i32, i32* %494, i64 %497
  %499 = getelementptr inbounds i32, i32* %498, i64 1
  %500 = load i32, i32* %498, align 4
  %501 = getelementptr inbounds i32, i32* %499, i64 1
  %502 = load i32, i32* %499, align 4
  %503 = getelementptr inbounds i32, i32* %501, i64 1
  %504 = load i32, i32* %501, align 4
  %505 = load i32, i32* %503, align 4
  %506 = load i32*, i32** %47, align 8
  %507 = getelementptr i32, i32* %506, i64 %489
  %508 = bitcast i32* %507 to i64*
  %509 = load i64, i64* %508, align 4
  %510 = getelementptr inbounds i32, i32* %507, i64 2
  %511 = bitcast i32* %510 to i64*
  %512 = load i64, i64* %511, align 4
  %513 = trunc i64 %509 to i32
  %514 = lshr i64 %509, 32
  %515 = trunc i64 %514 to i32
  %516 = load i32*, i32** %53, align 8
  %517 = getelementptr inbounds i32, i32* %516, i64 %428
  %518 = load i32, i32* %517, align 4
  %519 = load i32, i32* %314, align 4
  %520 = load i32, i32* %315, align 4
  %521 = mul nsw i32 %520, %513
  %522 = add nsw i32 %521, %500
  %523 = mul nsw i32 %520, %515
  %524 = add nsw i32 %523, %502
  %525 = trunc i64 %512 to i32
  %526 = mul nsw i32 %520, %525
  %527 = add nsw i32 %526, %504
  %528 = lshr i64 %512, 32
  %529 = trunc i64 %528 to i32
  %530 = mul nsw i32 %520, %529
  %531 = add nsw i32 %530, %505
  %532 = mul nsw i32 %520, %3
  %533 = add nsw i32 %532, %518
  %534 = mul nsw i32 %533, %519
  %535 = add nsw i32 %522, %534
  %536 = add nsw i32 %524, %534
  %537 = add nsw i32 %527, %534
  %538 = zext i32 %537 to i64
  %539 = add nsw i32 %531, %534
  %540 = zext i32 %539 to i64
  %541 = shl nuw i64 %540, 32
  %542 = or i64 %541, %538
  %543 = zext i32 %536 to i64
  %544 = shl nuw i64 %543, 32
  %545 = zext i32 %535 to i64
  %546 = or i64 %544, %545
  call void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi4ELi1EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE1EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.506"* nonnull %15, i64 %546, i64 %542, %"class.gemmlowp::MatrixMap.489"* %0, i32 %492, i32 %431, i32 %492, i32 %431) #19
  %547 = add nuw i64 %489, 4
  %548 = load i32, i32* %49, align 4
  %549 = add nsw i32 %548, -4
  %550 = trunc i64 %547 to i32
  %551 = icmp slt i32 %549, %550
  br i1 %551, label %482, label %488

552:                                              ; preds = %484, %552
  %553 = phi i32 [ %556, %552 ], [ %486, %484 ]
  %554 = load i32, i32* %313, align 4
  %555 = add nsw i32 %554, %553
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.495"* nonnull dereferenceable(40) %14, %"class.gemmlowp::MatrixMap.489"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %553, i32 %430, i32 %555, i32 %431, i32 %555, i32 %431)
  %556 = add nuw nsw i32 %553, 1
  %557 = load i32, i32* %49, align 4
  %558 = icmp slt i32 %556, %557
  br i1 %558, label %552, label %559

559:                                              ; preds = %552, %484
  %560 = phi i32 [ %485, %484 ], [ %557, %552 ]
  %561 = add nuw nsw i64 %428, 1
  %562 = load i32, i32* %55, align 4
  %563 = trunc i64 %561 to i32
  %564 = icmp sgt i32 %562, %563
  br i1 %564, label %426, label %565

565:                                              ; preds = %559, %307
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %108) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %100) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %92) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %84) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %76) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %58) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %52) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %46) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %22) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.548"* dereferenceable(40), %"class.gemmlowp::MatrixMap.479"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.302", align 16
  %16 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %16) #19
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %18 = sext i32 %8 to i64
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %20 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %20, i8 -86, i64 128, i1 false)
  %21 = load i32*, i32** %17, align 8, !noalias !1381
  %22 = getelementptr inbounds i32, i32* %21, i64 %18
  %23 = load i32, i32* %19, align 8, !noalias !1381
  %24 = mul nsw i32 %23, %9
  %25 = sext i32 %24 to i64
  %26 = getelementptr inbounds i32, i32* %22, i64 %25
  %27 = getelementptr inbounds i32, i32* %26, i64 1
  %28 = load i32, i32* %26, align 4
  %29 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 0
  store i32 %28, i32* %29, align 16, !alias.scope !1381
  %30 = getelementptr inbounds i32, i32* %27, i64 1
  %31 = load i32, i32* %27, align 4
  %32 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 1
  store i32 %31, i32* %32, align 4, !alias.scope !1381
  %33 = getelementptr inbounds i32, i32* %30, i64 1
  %34 = load i32, i32* %30, align 4
  %35 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 2
  store i32 %34, i32* %35, align 8, !alias.scope !1381
  %36 = getelementptr inbounds i32, i32* %33, i64 1
  %37 = load i32, i32* %33, align 4
  %38 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 3
  store i32 %37, i32* %38, align 4, !alias.scope !1381
  %39 = getelementptr inbounds i32, i32* %36, i64 1
  %40 = load i32, i32* %36, align 4
  %41 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 4
  store i32 %40, i32* %41, align 16, !alias.scope !1381
  %42 = getelementptr inbounds i32, i32* %39, i64 1
  %43 = load i32, i32* %39, align 4
  %44 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 5
  store i32 %43, i32* %44, align 4, !alias.scope !1381
  %45 = getelementptr inbounds i32, i32* %42, i64 1
  %46 = load i32, i32* %42, align 4
  %47 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 6
  store i32 %46, i32* %47, align 8, !alias.scope !1381
  %48 = load i32, i32* %45, align 4
  %49 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 7
  store i32 %48, i32* %49, align 4, !alias.scope !1381
  %50 = add nsw i32 %9, 1
  %51 = mul nsw i32 %23, %50
  %52 = sext i32 %51 to i64
  %53 = getelementptr inbounds i32, i32* %22, i64 %52
  %54 = getelementptr inbounds i32, i32* %53, i64 1
  %55 = load i32, i32* %53, align 4
  %56 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 8
  store i32 %55, i32* %56, align 16, !alias.scope !1381
  %57 = getelementptr inbounds i32, i32* %54, i64 1
  %58 = load i32, i32* %54, align 4
  %59 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 9
  store i32 %58, i32* %59, align 4, !alias.scope !1381
  %60 = getelementptr inbounds i32, i32* %57, i64 1
  %61 = load i32, i32* %57, align 4
  %62 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 10
  store i32 %61, i32* %62, align 8, !alias.scope !1381
  %63 = getelementptr inbounds i32, i32* %60, i64 1
  %64 = load i32, i32* %60, align 4
  %65 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 11
  store i32 %64, i32* %65, align 4, !alias.scope !1381
  %66 = getelementptr inbounds i32, i32* %63, i64 1
  %67 = load i32, i32* %63, align 4
  %68 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 12
  store i32 %67, i32* %68, align 16, !alias.scope !1381
  %69 = getelementptr inbounds i32, i32* %66, i64 1
  %70 = load i32, i32* %66, align 4
  %71 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 13
  store i32 %70, i32* %71, align 4, !alias.scope !1381
  %72 = getelementptr inbounds i32, i32* %69, i64 1
  %73 = load i32, i32* %69, align 4
  %74 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 14
  store i32 %73, i32* %74, align 8, !alias.scope !1381
  %75 = load i32, i32* %72, align 4
  %76 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 15
  store i32 %75, i32* %76, align 4, !alias.scope !1381
  %77 = add nsw i32 %9, 2
  %78 = mul nsw i32 %23, %77
  %79 = sext i32 %78 to i64
  %80 = getelementptr inbounds i32, i32* %22, i64 %79
  %81 = getelementptr inbounds i32, i32* %80, i64 1
  %82 = load i32, i32* %80, align 4
  %83 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 16
  store i32 %82, i32* %83, align 16, !alias.scope !1381
  %84 = getelementptr inbounds i32, i32* %81, i64 1
  %85 = load i32, i32* %81, align 4
  %86 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 17
  store i32 %85, i32* %86, align 4, !alias.scope !1381
  %87 = getelementptr inbounds i32, i32* %84, i64 1
  %88 = load i32, i32* %84, align 4
  %89 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 18
  store i32 %88, i32* %89, align 8, !alias.scope !1381
  %90 = getelementptr inbounds i32, i32* %87, i64 1
  %91 = load i32, i32* %87, align 4
  %92 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 19
  store i32 %91, i32* %92, align 4, !alias.scope !1381
  %93 = getelementptr inbounds i32, i32* %90, i64 1
  %94 = load i32, i32* %90, align 4
  %95 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 20
  store i32 %94, i32* %95, align 16, !alias.scope !1381
  %96 = getelementptr inbounds i32, i32* %93, i64 1
  %97 = load i32, i32* %93, align 4
  %98 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 21
  store i32 %97, i32* %98, align 4, !alias.scope !1381
  %99 = getelementptr inbounds i32, i32* %96, i64 1
  %100 = load i32, i32* %96, align 4
  %101 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 22
  store i32 %100, i32* %101, align 8, !alias.scope !1381
  %102 = load i32, i32* %99, align 4
  %103 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 23
  store i32 %102, i32* %103, align 4, !alias.scope !1381
  %104 = add nsw i32 %9, 3
  %105 = mul nsw i32 %23, %104
  %106 = sext i32 %105 to i64
  %107 = getelementptr inbounds i32, i32* %22, i64 %106
  %108 = getelementptr inbounds i32, i32* %107, i64 1
  %109 = load i32, i32* %107, align 4
  %110 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 24
  store i32 %109, i32* %110, align 16, !alias.scope !1381
  %111 = getelementptr inbounds i32, i32* %108, i64 1
  %112 = load i32, i32* %108, align 4
  %113 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 25
  store i32 %112, i32* %113, align 4, !alias.scope !1381
  %114 = getelementptr inbounds i32, i32* %111, i64 1
  %115 = load i32, i32* %111, align 4
  %116 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 26
  store i32 %115, i32* %116, align 8, !alias.scope !1381
  %117 = getelementptr inbounds i32, i32* %114, i64 1
  %118 = load i32, i32* %114, align 4
  %119 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 27
  store i32 %118, i32* %119, align 4, !alias.scope !1381
  %120 = getelementptr inbounds i32, i32* %117, i64 1
  %121 = load i32, i32* %117, align 4
  %122 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 28
  store i32 %121, i32* %122, align 16, !alias.scope !1381
  %123 = getelementptr inbounds i32, i32* %120, i64 1
  %124 = load i32, i32* %120, align 4
  %125 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 29
  store i32 %124, i32* %125, align 4, !alias.scope !1381
  %126 = getelementptr inbounds i32, i32* %123, i64 1
  %127 = load i32, i32* %123, align 4
  %128 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 30
  store i32 %127, i32* %128, align 8, !alias.scope !1381
  %129 = load i32, i32* %126, align 4
  %130 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 31
  store i32 %129, i32* %130, align 4, !alias.scope !1381
  %131 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %132 = load i32*, i32** %131, align 8, !noalias !1384
  %133 = getelementptr i32, i32* %132, i64 %18
  %134 = bitcast i32* %133 to <4 x i32>*
  %135 = load <4 x i32>, <4 x i32>* %134, align 4
  %136 = getelementptr inbounds i32, i32* %133, i64 4
  %137 = bitcast i32* %136 to <4 x i32>*
  %138 = load <4 x i32>, <4 x i32>* %137, align 4
  %139 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %140 = load i32*, i32** %139, align 8
  %141 = sext i32 %9 to i64
  %142 = getelementptr i32, i32* %140, i64 %141
  %143 = bitcast i32* %142 to i64*
  %144 = load i64, i64* %143, align 4
  %145 = getelementptr inbounds i32, i32* %142, i64 2
  %146 = bitcast i32* %145 to i64*
  %147 = load i64, i64* %146, align 4
  %148 = lshr i64 %144, 32
  %149 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 0
  %150 = load i32, i32* %149, align 4
  %151 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %152 = load i32, i32* %151, align 4
  %153 = insertelement <4 x i32> undef, i32 %152, i32 0
  %154 = shufflevector <4 x i32> %153, <4 x i32> undef, <4 x i32> zeroinitializer
  %155 = mul nsw <4 x i32> %154, %135
  %156 = mul nsw <4 x i32> %154, %138
  %157 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to <4 x i32>*
  %158 = load <4 x i32>, <4 x i32>* %157, align 16
  %159 = add nsw <4 x i32> %158, %155
  %160 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to <4 x i32>*
  store <4 x i32> %159, <4 x i32>* %160, align 16
  %161 = bitcast i32* %41 to <4 x i32>*
  %162 = load <4 x i32>, <4 x i32>* %161, align 16
  %163 = add nsw <4 x i32> %162, %156
  %164 = bitcast i32* %41 to <4 x i32>*
  store <4 x i32> %163, <4 x i32>* %164, align 16
  %165 = bitcast i32* %56 to <4 x i32>*
  %166 = load <4 x i32>, <4 x i32>* %165, align 16
  %167 = add nsw <4 x i32> %166, %155
  %168 = bitcast i32* %56 to <4 x i32>*
  store <4 x i32> %167, <4 x i32>* %168, align 16
  %169 = bitcast i32* %68 to <4 x i32>*
  %170 = load <4 x i32>, <4 x i32>* %169, align 16
  %171 = add nsw <4 x i32> %170, %156
  %172 = bitcast i32* %68 to <4 x i32>*
  store <4 x i32> %171, <4 x i32>* %172, align 16
  %173 = bitcast i32* %83 to <4 x i32>*
  %174 = load <4 x i32>, <4 x i32>* %173, align 16
  %175 = add nsw <4 x i32> %174, %155
  %176 = bitcast i32* %83 to <4 x i32>*
  store <4 x i32> %175, <4 x i32>* %176, align 16
  %177 = bitcast i32* %95 to <4 x i32>*
  %178 = load <4 x i32>, <4 x i32>* %177, align 16
  %179 = add nsw <4 x i32> %178, %156
  %180 = bitcast i32* %95 to <4 x i32>*
  store <4 x i32> %179, <4 x i32>* %180, align 16
  %181 = bitcast i32* %110 to <4 x i32>*
  %182 = load <4 x i32>, <4 x i32>* %181, align 16
  %183 = add nsw <4 x i32> %182, %155
  %184 = bitcast i32* %110 to <4 x i32>*
  store <4 x i32> %183, <4 x i32>* %184, align 16
  %185 = bitcast i32* %122 to <4 x i32>*
  %186 = load <4 x i32>, <4 x i32>* %185, align 16
  %187 = add nsw <4 x i32> %186, %156
  %188 = bitcast i32* %122 to <4 x i32>*
  store <4 x i32> %187, <4 x i32>* %188, align 16
  %189 = trunc i64 %144 to i32
  %190 = trunc i64 %148 to i32
  %191 = mul nsw i32 %152, %7
  %192 = add nsw i32 %191, %189
  %193 = add nsw i32 %191, %190
  %194 = trunc i64 %147 to i32
  %195 = add nsw i32 %191, %194
  %196 = lshr i64 %147, 32
  %197 = trunc i64 %196 to i32
  %198 = add nsw i32 %191, %197
  %199 = mul nsw i32 %192, %150
  %200 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to <4 x i32>*
  %201 = load <4 x i32>, <4 x i32>* %200, align 16
  %202 = insertelement <4 x i32> undef, i32 %199, i32 0
  %203 = shufflevector <4 x i32> %202, <4 x i32> undef, <4 x i32> zeroinitializer
  %204 = add nsw <4 x i32> %201, %203
  %205 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to <4 x i32>*
  store <4 x i32> %204, <4 x i32>* %205, align 16
  %206 = bitcast i32* %41 to <4 x i32>*
  %207 = load <4 x i32>, <4 x i32>* %206, align 16
  %208 = add nsw <4 x i32> %207, %203
  %209 = bitcast i32* %41 to <4 x i32>*
  store <4 x i32> %208, <4 x i32>* %209, align 16
  %210 = mul nsw i32 %193, %150
  %211 = bitcast i32* %56 to <4 x i32>*
  %212 = load <4 x i32>, <4 x i32>* %211, align 16
  %213 = insertelement <4 x i32> undef, i32 %210, i32 0
  %214 = shufflevector <4 x i32> %213, <4 x i32> undef, <4 x i32> zeroinitializer
  %215 = add nsw <4 x i32> %212, %214
  %216 = bitcast i32* %56 to <4 x i32>*
  store <4 x i32> %215, <4 x i32>* %216, align 16
  %217 = bitcast i32* %68 to <4 x i32>*
  %218 = load <4 x i32>, <4 x i32>* %217, align 16
  %219 = add nsw <4 x i32> %218, %214
  %220 = bitcast i32* %68 to <4 x i32>*
  store <4 x i32> %219, <4 x i32>* %220, align 16
  %221 = mul nsw i32 %195, %150
  %222 = bitcast i32* %83 to <4 x i32>*
  %223 = load <4 x i32>, <4 x i32>* %222, align 16
  %224 = insertelement <4 x i32> undef, i32 %221, i32 0
  %225 = shufflevector <4 x i32> %224, <4 x i32> undef, <4 x i32> zeroinitializer
  %226 = add nsw <4 x i32> %223, %225
  %227 = bitcast i32* %83 to <4 x i32>*
  store <4 x i32> %226, <4 x i32>* %227, align 16
  %228 = bitcast i32* %95 to <4 x i32>*
  %229 = load <4 x i32>, <4 x i32>* %228, align 16
  %230 = add nsw <4 x i32> %229, %225
  %231 = bitcast i32* %95 to <4 x i32>*
  store <4 x i32> %230, <4 x i32>* %231, align 16
  %232 = mul nsw i32 %198, %150
  %233 = bitcast i32* %110 to <4 x i32>*
  %234 = load <4 x i32>, <4 x i32>* %233, align 16
  %235 = insertelement <4 x i32> undef, i32 %232, i32 0
  %236 = shufflevector <4 x i32> %235, <4 x i32> undef, <4 x i32> zeroinitializer
  %237 = add nsw <4 x i32> %234, %236
  %238 = bitcast i32* %110 to <4 x i32>*
  store <4 x i32> %237, <4 x i32>* %238, align 16
  %239 = bitcast i32* %122 to <4 x i32>*
  %240 = load <4 x i32>, <4 x i32>* %239, align 16
  %241 = add nsw <4 x i32> %240, %236
  %242 = bitcast i32* %122 to <4 x i32>*
  store <4 x i32> %241, <4 x i32>* %242, align 16
  tail call void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi8ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE0EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.548"* %1, %"struct.gemmlowp::RegisterBlock.302"* nonnull byval(%"struct.gemmlowp::RegisterBlock.302") align 8 %15, %"class.gemmlowp::MatrixMap.479"* %2, i32 %10, i32 %11, i32 %12, i32 %13)
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %16) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.537"* dereferenceable(40), %"class.gemmlowp::MatrixMap.489"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.563", align 2
  %16 = alloca %"struct.gemmlowp::RegisterBlock.312", align 8
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %18 = sext i32 %8 to i64
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %20 = load i32*, i32** %17, align 8, !noalias !1389
  %21 = getelementptr inbounds i32, i32* %20, i64 %18
  %22 = load i32, i32* %19, align 8, !noalias !1389
  %23 = mul nsw i32 %22, %9
  %24 = sext i32 %23 to i64
  %25 = getelementptr inbounds i32, i32* %21, i64 %24
  %26 = getelementptr inbounds i32, i32* %25, i64 1
  %27 = load i32, i32* %25, align 4, !noalias !1389
  %28 = getelementptr inbounds i32, i32* %26, i64 1
  %29 = load i32, i32* %26, align 4, !noalias !1389
  %30 = getelementptr inbounds i32, i32* %28, i64 1
  %31 = load i32, i32* %28, align 4, !noalias !1389
  %32 = load i32, i32* %30, align 4, !noalias !1389
  %33 = add nsw i32 %9, 1
  %34 = mul nsw i32 %22, %33
  %35 = sext i32 %34 to i64
  %36 = getelementptr inbounds i32, i32* %21, i64 %35
  %37 = getelementptr inbounds i32, i32* %36, i64 1
  %38 = load i32, i32* %36, align 4, !noalias !1389
  %39 = getelementptr inbounds i32, i32* %37, i64 1
  %40 = load i32, i32* %37, align 4, !noalias !1389
  %41 = getelementptr inbounds i32, i32* %39, i64 1
  %42 = load i32, i32* %39, align 4, !noalias !1389
  %43 = load i32, i32* %41, align 4, !noalias !1389
  %44 = add nsw i32 %9, 2
  %45 = mul nsw i32 %22, %44
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds i32, i32* %21, i64 %46
  %48 = getelementptr inbounds i32, i32* %47, i64 1
  %49 = load i32, i32* %47, align 4, !noalias !1389
  %50 = getelementptr inbounds i32, i32* %48, i64 1
  %51 = load i32, i32* %48, align 4, !noalias !1389
  %52 = getelementptr inbounds i32, i32* %50, i64 1
  %53 = load i32, i32* %50, align 4, !noalias !1389
  %54 = load i32, i32* %52, align 4, !noalias !1389
  %55 = add nsw i32 %9, 3
  %56 = mul nsw i32 %22, %55
  %57 = sext i32 %56 to i64
  %58 = getelementptr inbounds i32, i32* %21, i64 %57
  %59 = getelementptr inbounds i32, i32* %58, i64 1
  %60 = load i32, i32* %58, align 4, !noalias !1389
  %61 = getelementptr inbounds i32, i32* %59, i64 1
  %62 = load i32, i32* %59, align 4, !noalias !1389
  %63 = getelementptr inbounds i32, i32* %61, i64 1
  %64 = load i32, i32* %61, align 4, !noalias !1389
  %65 = load i32, i32* %63, align 4, !noalias !1389
  %66 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %67 = load i32*, i32** %66, align 8
  %68 = getelementptr i32, i32* %67, i64 %18
  %69 = bitcast i32* %68 to i64*
  %70 = load i64, i64* %69, align 4
  %71 = getelementptr inbounds i32, i32* %68, i64 2
  %72 = bitcast i32* %71 to i64*
  %73 = load i64, i64* %72, align 4
  %74 = trunc i64 %70 to i32
  %75 = lshr i64 %70, 32
  %76 = trunc i64 %75 to i32
  %77 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %78 = load i32*, i32** %77, align 8
  %79 = sext i32 %9 to i64
  %80 = getelementptr i32, i32* %78, i64 %79
  %81 = bitcast i32* %80 to i64*
  %82 = load i64, i64* %81, align 4
  %83 = getelementptr inbounds i32, i32* %80, i64 2
  %84 = bitcast i32* %83 to i64*
  %85 = load i64, i64* %84, align 4
  %86 = trunc i64 %82 to i32
  %87 = lshr i64 %82, 32
  %88 = trunc i64 %87 to i32
  %89 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 0
  %90 = load i32, i32* %89, align 4
  %91 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %92 = load i32, i32* %91, align 4
  %93 = mul nsw i32 %92, %74
  %94 = add nsw i32 %93, %27
  %95 = mul nsw i32 %92, %76
  %96 = add nsw i32 %95, %29
  %97 = trunc i64 %73 to i32
  %98 = mul nsw i32 %92, %97
  %99 = add nsw i32 %98, %31
  %100 = lshr i64 %73, 32
  %101 = trunc i64 %100 to i32
  %102 = mul nsw i32 %92, %101
  %103 = add nsw i32 %102, %32
  %104 = add nsw i32 %93, %38
  %105 = add nsw i32 %95, %40
  %106 = add nsw i32 %98, %42
  %107 = add nsw i32 %102, %43
  %108 = add nsw i32 %93, %49
  %109 = add nsw i32 %95, %51
  %110 = add nsw i32 %98, %53
  %111 = add nsw i32 %102, %54
  %112 = add nsw i32 %93, %60
  %113 = add nsw i32 %95, %62
  %114 = add nsw i32 %98, %64
  %115 = add nsw i32 %102, %65
  %116 = mul nsw i32 %92, %7
  %117 = add nsw i32 %116, %86
  %118 = add nsw i32 %116, %88
  %119 = trunc i64 %85 to i32
  %120 = add nsw i32 %116, %119
  %121 = lshr i64 %85, 32
  %122 = trunc i64 %121 to i32
  %123 = add nsw i32 %116, %122
  %124 = mul nsw i32 %117, %90
  %125 = add nsw i32 %94, %124
  %126 = add nsw i32 %96, %124
  %127 = add nsw i32 %99, %124
  %128 = add nsw i32 %103, %124
  %129 = mul nsw i32 %118, %90
  %130 = add nsw i32 %104, %129
  %131 = add nsw i32 %105, %129
  %132 = add nsw i32 %106, %129
  %133 = add nsw i32 %107, %129
  %134 = mul nsw i32 %120, %90
  %135 = add nsw i32 %108, %134
  %136 = add nsw i32 %109, %134
  %137 = add nsw i32 %110, %134
  %138 = add nsw i32 %111, %134
  %139 = mul nsw i32 %123, %90
  %140 = add nsw i32 %112, %139
  %141 = add nsw i32 %113, %139
  %142 = add nsw i32 %114, %139
  %143 = add nsw i32 %115, %139
  %144 = bitcast %"struct.gemmlowp::RegisterBlock.312"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %144)
  %145 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %16, i64 0, i32 0, i32 0, i64 0
  store i32 %125, i32* %145, align 8
  %146 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %16, i64 0, i32 0, i32 0, i64 1
  store i32 %126, i32* %146, align 4
  %147 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %16, i64 0, i32 0, i32 0, i64 2
  store i32 %127, i32* %147, align 8
  %148 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %16, i64 0, i32 0, i32 0, i64 3
  store i32 %128, i32* %148, align 4
  %149 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %16, i64 0, i32 0, i32 0, i64 4
  store i32 %130, i32* %149, align 8
  %150 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %16, i64 0, i32 0, i32 0, i64 5
  store i32 %131, i32* %150, align 4
  %151 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %16, i64 0, i32 0, i32 0, i64 6
  store i32 %132, i32* %151, align 8
  %152 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %16, i64 0, i32 0, i32 0, i64 7
  store i32 %133, i32* %152, align 4
  %153 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %16, i64 0, i32 0, i32 0, i64 8
  store i32 %135, i32* %153, align 8
  %154 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %16, i64 0, i32 0, i32 0, i64 9
  store i32 %136, i32* %154, align 4
  %155 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %16, i64 0, i32 0, i32 0, i64 10
  store i32 %137, i32* %155, align 8
  %156 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %16, i64 0, i32 0, i32 0, i64 11
  store i32 %138, i32* %156, align 4
  %157 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %16, i64 0, i32 0, i32 0, i64 12
  store i32 %140, i32* %157, align 8
  %158 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %16, i64 0, i32 0, i32 0, i64 13
  store i32 %141, i32* %158, align 4
  %159 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %16, i64 0, i32 0, i32 0, i64 14
  store i32 %142, i32* %159, align 8
  %160 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %16, i64 0, i32 0, i32 0, i64 15
  store i32 %143, i32* %160, align 4
  %161 = bitcast %"struct.gemmlowp::RegisterBlock.563"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %161) #19
  %162 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.537", %"struct.gemmlowp::OutputPipelineExecutor.537"* %1, i64 0, i32 0
  call void @llvm.memset.p0i8.i64(i8* nonnull align 2 %161, i8 -86, i64 32, i1 false) #19
  call void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.563"* nonnull sret %15, %"struct.gemmlowp::OutputPipelineEvalImpl.538"* %162, %"struct.gemmlowp::RegisterBlock.312"* nonnull byval(%"struct.gemmlowp::RegisterBlock.312") align 8 %16, i32 %10, i32 %11) #19
  %163 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %15, i64 0, i32 0, i32 0, i64 0
  %164 = load i16, i16* %163, align 2
  %165 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %15, i64 0, i32 0, i32 0, i64 1
  %166 = load i16, i16* %165, align 2
  %167 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %15, i64 0, i32 0, i32 0, i64 2
  %168 = load i16, i16* %167, align 2
  %169 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %15, i64 0, i32 0, i32 0, i64 3
  %170 = load i16, i16* %169, align 2
  %171 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %15, i64 0, i32 0, i32 0, i64 4
  %172 = load i16, i16* %171, align 2
  %173 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %15, i64 0, i32 0, i32 0, i64 5
  %174 = load i16, i16* %173, align 2
  %175 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %15, i64 0, i32 0, i32 0, i64 6
  %176 = load i16, i16* %175, align 2
  %177 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %15, i64 0, i32 0, i32 0, i64 7
  %178 = load i16, i16* %177, align 2
  %179 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %15, i64 0, i32 0, i32 0, i64 8
  %180 = load i16, i16* %179, align 2
  %181 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %15, i64 0, i32 0, i32 0, i64 9
  %182 = load i16, i16* %181, align 2
  %183 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %15, i64 0, i32 0, i32 0, i64 10
  %184 = load i16, i16* %183, align 2
  %185 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %15, i64 0, i32 0, i32 0, i64 11
  %186 = load i16, i16* %185, align 2
  %187 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %15, i64 0, i32 0, i32 0, i64 12
  %188 = load i16, i16* %187, align 2
  %189 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %15, i64 0, i32 0, i32 0, i64 13
  %190 = load i16, i16* %189, align 2
  %191 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %15, i64 0, i32 0, i32 0, i64 14
  %192 = load i16, i16* %191, align 2
  %193 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %15, i64 0, i32 0, i32 0, i64 15
  %194 = load i16, i16* %193, align 2
  %195 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %2, i64 0, i32 0
  %196 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %2, i64 0, i32 3
  %197 = sext i32 %13 to i64
  %198 = sext i32 %12 to i64
  %199 = load i16*, i16** %195, align 8
  %200 = load i32, i32* %196, align 8
  %201 = sext i32 %200 to i64
  %202 = mul nsw i64 %201, %198
  %203 = getelementptr inbounds i16, i16* %199, i64 %202
  %204 = getelementptr inbounds i16, i16* %203, i64 %197
  store i16 %164, i16* %204, align 2
  %205 = add nsw i64 %197, 1
  %206 = load i16*, i16** %195, align 8
  %207 = load i32, i32* %196, align 8
  %208 = sext i32 %207 to i64
  %209 = mul nsw i64 %208, %198
  %210 = getelementptr inbounds i16, i16* %206, i64 %209
  %211 = getelementptr inbounds i16, i16* %210, i64 %205
  store i16 %172, i16* %211, align 2
  %212 = add nsw i64 %197, 2
  %213 = load i16*, i16** %195, align 8
  %214 = load i32, i32* %196, align 8
  %215 = sext i32 %214 to i64
  %216 = mul nsw i64 %215, %198
  %217 = getelementptr inbounds i16, i16* %213, i64 %216
  %218 = getelementptr inbounds i16, i16* %217, i64 %212
  store i16 %180, i16* %218, align 2
  %219 = add nsw i64 %197, 3
  %220 = load i16*, i16** %195, align 8
  %221 = load i32, i32* %196, align 8
  %222 = sext i32 %221 to i64
  %223 = mul nsw i64 %222, %198
  %224 = getelementptr inbounds i16, i16* %220, i64 %223
  %225 = getelementptr inbounds i16, i16* %224, i64 %219
  store i16 %188, i16* %225, align 2
  %226 = add nsw i64 %198, 1
  %227 = load i16*, i16** %195, align 8
  %228 = load i32, i32* %196, align 8
  %229 = sext i32 %228 to i64
  %230 = mul nsw i64 %226, %229
  %231 = getelementptr inbounds i16, i16* %227, i64 %230
  %232 = getelementptr inbounds i16, i16* %231, i64 %197
  store i16 %166, i16* %232, align 2
  %233 = load i16*, i16** %195, align 8
  %234 = load i32, i32* %196, align 8
  %235 = sext i32 %234 to i64
  %236 = mul nsw i64 %226, %235
  %237 = getelementptr inbounds i16, i16* %233, i64 %236
  %238 = getelementptr inbounds i16, i16* %237, i64 %205
  store i16 %174, i16* %238, align 2
  %239 = load i16*, i16** %195, align 8
  %240 = load i32, i32* %196, align 8
  %241 = sext i32 %240 to i64
  %242 = mul nsw i64 %226, %241
  %243 = getelementptr inbounds i16, i16* %239, i64 %242
  %244 = getelementptr inbounds i16, i16* %243, i64 %212
  store i16 %182, i16* %244, align 2
  %245 = load i16*, i16** %195, align 8
  %246 = load i32, i32* %196, align 8
  %247 = sext i32 %246 to i64
  %248 = mul nsw i64 %226, %247
  %249 = getelementptr inbounds i16, i16* %245, i64 %248
  %250 = getelementptr inbounds i16, i16* %249, i64 %219
  store i16 %190, i16* %250, align 2
  %251 = add nsw i64 %198, 2
  %252 = load i16*, i16** %195, align 8
  %253 = load i32, i32* %196, align 8
  %254 = sext i32 %253 to i64
  %255 = mul nsw i64 %251, %254
  %256 = getelementptr inbounds i16, i16* %252, i64 %255
  %257 = getelementptr inbounds i16, i16* %256, i64 %197
  store i16 %168, i16* %257, align 2
  %258 = load i16*, i16** %195, align 8
  %259 = load i32, i32* %196, align 8
  %260 = sext i32 %259 to i64
  %261 = mul nsw i64 %251, %260
  %262 = getelementptr inbounds i16, i16* %258, i64 %261
  %263 = getelementptr inbounds i16, i16* %262, i64 %205
  store i16 %176, i16* %263, align 2
  %264 = load i16*, i16** %195, align 8
  %265 = load i32, i32* %196, align 8
  %266 = sext i32 %265 to i64
  %267 = mul nsw i64 %251, %266
  %268 = getelementptr inbounds i16, i16* %264, i64 %267
  %269 = getelementptr inbounds i16, i16* %268, i64 %212
  store i16 %184, i16* %269, align 2
  %270 = load i16*, i16** %195, align 8
  %271 = load i32, i32* %196, align 8
  %272 = sext i32 %271 to i64
  %273 = mul nsw i64 %251, %272
  %274 = getelementptr inbounds i16, i16* %270, i64 %273
  %275 = getelementptr inbounds i16, i16* %274, i64 %219
  store i16 %192, i16* %275, align 2
  %276 = add nsw i64 %198, 3
  %277 = load i16*, i16** %195, align 8
  %278 = load i32, i32* %196, align 8
  %279 = sext i32 %278 to i64
  %280 = mul nsw i64 %276, %279
  %281 = getelementptr inbounds i16, i16* %277, i64 %280
  %282 = getelementptr inbounds i16, i16* %281, i64 %197
  store i16 %170, i16* %282, align 2
  %283 = load i16*, i16** %195, align 8
  %284 = load i32, i32* %196, align 8
  %285 = sext i32 %284 to i64
  %286 = mul nsw i64 %276, %285
  %287 = getelementptr inbounds i16, i16* %283, i64 %286
  %288 = getelementptr inbounds i16, i16* %287, i64 %205
  store i16 %178, i16* %288, align 2
  %289 = load i16*, i16** %195, align 8
  %290 = load i32, i32* %196, align 8
  %291 = sext i32 %290 to i64
  %292 = mul nsw i64 %276, %291
  %293 = getelementptr inbounds i16, i16* %289, i64 %292
  %294 = getelementptr inbounds i16, i16* %293, i64 %212
  store i16 %186, i16* %294, align 2
  %295 = load i16*, i16** %195, align 8
  %296 = load i32, i32* %196, align 8
  %297 = sext i32 %296 to i64
  %298 = mul nsw i64 %276, %297
  %299 = getelementptr inbounds i16, i16* %295, i64 %298
  %300 = getelementptr inbounds i16, i16* %299, i64 %219
  store i16 %194, i16* %300, align 2
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %161) #19
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %144)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.528"* dereferenceable(40), %"class.gemmlowp::MatrixMap.489"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %16 = sext i32 %8 to i64
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %18 = load i32*, i32** %15, align 8
  %19 = getelementptr inbounds i32, i32* %18, i64 %16
  %20 = load i32, i32* %17, align 8
  %21 = mul nsw i32 %20, %9
  %22 = sext i32 %21 to i64
  %23 = getelementptr inbounds i32, i32* %19, i64 %22
  %24 = load i32, i32* %23, align 4
  %25 = add nsw i32 %9, 1
  %26 = mul nsw i32 %20, %25
  %27 = sext i32 %26 to i64
  %28 = getelementptr inbounds i32, i32* %19, i64 %27
  %29 = load i32, i32* %28, align 4
  %30 = add nsw i32 %9, 2
  %31 = mul nsw i32 %20, %30
  %32 = sext i32 %31 to i64
  %33 = getelementptr inbounds i32, i32* %19, i64 %32
  %34 = load i32, i32* %33, align 4
  %35 = add nsw i32 %9, 3
  %36 = mul nsw i32 %20, %35
  %37 = sext i32 %36 to i64
  %38 = getelementptr inbounds i32, i32* %19, i64 %37
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %41 = load i32*, i32** %40, align 8
  %42 = getelementptr inbounds i32, i32* %41, i64 %16
  %43 = load i32, i32* %42, align 4
  %44 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %45 = load i32*, i32** %44, align 8
  %46 = sext i32 %9 to i64
  %47 = getelementptr i32, i32* %45, i64 %46
  %48 = bitcast i32* %47 to i64*
  %49 = load i64, i64* %48, align 4
  %50 = getelementptr inbounds i32, i32* %47, i64 2
  %51 = bitcast i32* %50 to i64*
  %52 = load i64, i64* %51, align 4
  %53 = trunc i64 %49 to i32
  %54 = lshr i64 %49, 32
  %55 = trunc i64 %54 to i32
  %56 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 0
  %57 = load i32, i32* %56, align 4
  %58 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %59 = load i32, i32* %58, align 4
  %60 = mul nsw i32 %59, %43
  %61 = add nsw i32 %60, %24
  %62 = add nsw i32 %60, %29
  %63 = add nsw i32 %60, %34
  %64 = add nsw i32 %60, %39
  %65 = mul nsw i32 %59, %7
  %66 = add nsw i32 %65, %53
  %67 = add nsw i32 %65, %55
  %68 = trunc i64 %52 to i32
  %69 = add nsw i32 %65, %68
  %70 = lshr i64 %52, 32
  %71 = trunc i64 %70 to i32
  %72 = add nsw i32 %65, %71
  %73 = mul nsw i32 %66, %57
  %74 = add nsw i32 %61, %73
  %75 = mul nsw i32 %67, %57
  %76 = add nsw i32 %62, %75
  %77 = mul nsw i32 %69, %57
  %78 = add nsw i32 %63, %77
  %79 = zext i32 %78 to i64
  %80 = mul nsw i32 %72, %57
  %81 = add nsw i32 %64, %80
  %82 = zext i32 %81 to i64
  %83 = shl nuw i64 %82, 32
  %84 = or i64 %83, %79
  %85 = zext i32 %76 to i64
  %86 = shl nuw i64 %85, 32
  %87 = zext i32 %74 to i64
  %88 = or i64 %86, %87
  %89 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.528", %"struct.gemmlowp::OutputPipelineExecutor.528"* %1, i64 0, i32 0, i32 0, i32 0
  %90 = load %"struct.gemmlowp::OutputStageBiasAddition.200"*, %"struct.gemmlowp::OutputStageBiasAddition.200"** %89, align 8
  %91 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition.200", %"struct.gemmlowp::OutputStageBiasAddition.200"* %90, i64 0, i32 0, i32 0
  %92 = load i32*, i32** %91, align 8
  %93 = sext i32 %11 to i64
  %94 = getelementptr i32, i32* %92, i64 %93
  %95 = bitcast i32* %94 to i64*
  %96 = load i64, i64* %95, align 4
  %97 = getelementptr inbounds i32, i32* %94, i64 2
  %98 = bitcast i32* %97 to i64*
  %99 = load i64, i64* %98, align 4
  %100 = and i64 %96, -4294967296
  %101 = add i64 %96, %87
  %102 = add i64 %99, %79
  %103 = and i64 %102, 4294967295
  %104 = and i64 %99, -4294967296
  %105 = add i64 %104, %84
  %106 = and i64 %105, -4294967296
  %107 = or i64 %106, %103
  %108 = add i64 %100, %88
  %109 = and i64 %108, -4294967296
  %110 = and i64 %101, 4294967295
  %111 = or i64 %109, %110
  %112 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.528", %"struct.gemmlowp::OutputPipelineExecutor.528"* %1, i64 0, i32 0, i32 1, i32 0, i32 0
  %113 = tail call { i64, i64 } @_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi4EEEE4EvalES3_(%"struct.gemmlowp::OutputStageEvalBufferImpl.231"* %112, i64 %111, i64 %107) #19
  %114 = extractvalue { i64, i64 } %113, 0
  %115 = extractvalue { i64, i64 } %113, 1
  %116 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.528", %"struct.gemmlowp::OutputPipelineExecutor.528"* %1, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %117 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %116, align 8
  %118 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %117, i64 0, i32 0
  %119 = load i32, i32* %118, align 4
  %120 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %117, i64 0, i32 1
  %121 = load i32, i32* %120, align 4
  %122 = trunc i64 %114 to i32
  %123 = icmp sgt i32 %119, %122
  %124 = select i1 %123, i32 %119, i32 %122
  %125 = icmp slt i32 %121, %124
  %126 = select i1 %125, i32 %121, i32 %124
  %127 = lshr i64 %114, 32
  %128 = trunc i64 %127 to i32
  %129 = icmp sgt i32 %119, %128
  %130 = select i1 %129, i32 %119, i32 %128
  %131 = icmp slt i32 %121, %130
  %132 = select i1 %131, i32 %121, i32 %130
  %133 = trunc i64 %115 to i32
  %134 = icmp sgt i32 %119, %133
  %135 = select i1 %134, i32 %119, i32 %133
  %136 = icmp slt i32 %121, %135
  %137 = select i1 %136, i32 %121, i32 %135
  %138 = lshr i64 %115, 32
  %139 = trunc i64 %138 to i32
  %140 = icmp sgt i32 %119, %139
  %141 = select i1 %140, i32 %119, i32 %139
  %142 = icmp slt i32 %121, %141
  %143 = select i1 %142, i32 %121, i32 %141
  %144 = icmp sgt i32 %126, -32768
  %145 = select i1 %144, i32 %126, i32 -32768
  %146 = icmp slt i32 %145, 32767
  %147 = select i1 %146, i32 %145, i32 32767
  %148 = icmp sgt i32 %132, -32768
  %149 = select i1 %148, i32 %132, i32 -32768
  %150 = icmp slt i32 %149, 32767
  %151 = select i1 %150, i32 %149, i32 32767
  %152 = icmp sgt i32 %137, -32768
  %153 = select i1 %152, i32 %137, i32 -32768
  %154 = icmp slt i32 %153, 32767
  %155 = select i1 %154, i32 %153, i32 32767
  %156 = icmp sgt i32 %143, -32768
  %157 = select i1 %156, i32 %143, i32 -32768
  %158 = icmp slt i32 %157, 32767
  %159 = select i1 %158, i32 %157, i32 32767
  %160 = trunc i32 %147 to i16
  %161 = trunc i32 %151 to i16
  %162 = trunc i32 %155 to i16
  %163 = trunc i32 %159 to i16
  %164 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %2, i64 0, i32 0
  %165 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %2, i64 0, i32 3
  %166 = sext i32 %13 to i64
  %167 = sext i32 %12 to i64
  %168 = load i16*, i16** %164, align 8
  %169 = load i32, i32* %165, align 8
  %170 = sext i32 %169 to i64
  %171 = mul nsw i64 %170, %167
  %172 = getelementptr inbounds i16, i16* %168, i64 %171
  %173 = getelementptr inbounds i16, i16* %172, i64 %166
  store i16 %160, i16* %173, align 2
  %174 = add nsw i64 %166, 1
  %175 = load i16*, i16** %164, align 8
  %176 = load i32, i32* %165, align 8
  %177 = sext i32 %176 to i64
  %178 = mul nsw i64 %177, %167
  %179 = getelementptr inbounds i16, i16* %175, i64 %178
  %180 = getelementptr inbounds i16, i16* %179, i64 %174
  store i16 %161, i16* %180, align 2
  %181 = add nsw i64 %166, 2
  %182 = load i16*, i16** %164, align 8
  %183 = load i32, i32* %165, align 8
  %184 = sext i32 %183 to i64
  %185 = mul nsw i64 %184, %167
  %186 = getelementptr inbounds i16, i16* %182, i64 %185
  %187 = getelementptr inbounds i16, i16* %186, i64 %181
  store i16 %162, i16* %187, align 2
  %188 = add nsw i64 %166, 3
  %189 = load i16*, i16** %164, align 8
  %190 = load i32, i32* %165, align 8
  %191 = sext i32 %190 to i64
  %192 = mul nsw i64 %191, %167
  %193 = getelementptr inbounds i16, i16* %189, i64 %192
  %194 = getelementptr inbounds i16, i16* %193, i64 %188
  store i16 %163, i16* %194, align 2
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.548"* dereferenceable(40), %"class.gemmlowp::MatrixMap.489"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.302", align 16
  %16 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %16) #19
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %18 = sext i32 %8 to i64
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %20 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %20, i8 -86, i64 128, i1 false)
  %21 = load i32*, i32** %17, align 8, !noalias !1394
  %22 = getelementptr inbounds i32, i32* %21, i64 %18
  %23 = load i32, i32* %19, align 8, !noalias !1394
  %24 = mul nsw i32 %23, %9
  %25 = sext i32 %24 to i64
  %26 = getelementptr inbounds i32, i32* %22, i64 %25
  %27 = getelementptr inbounds i32, i32* %26, i64 1
  %28 = load i32, i32* %26, align 4
  %29 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 0
  store i32 %28, i32* %29, align 16, !alias.scope !1394
  %30 = getelementptr inbounds i32, i32* %27, i64 1
  %31 = load i32, i32* %27, align 4
  %32 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 1
  store i32 %31, i32* %32, align 4, !alias.scope !1394
  %33 = getelementptr inbounds i32, i32* %30, i64 1
  %34 = load i32, i32* %30, align 4
  %35 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 2
  store i32 %34, i32* %35, align 8, !alias.scope !1394
  %36 = getelementptr inbounds i32, i32* %33, i64 1
  %37 = load i32, i32* %33, align 4
  %38 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 3
  store i32 %37, i32* %38, align 4, !alias.scope !1394
  %39 = getelementptr inbounds i32, i32* %36, i64 1
  %40 = load i32, i32* %36, align 4
  %41 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 4
  store i32 %40, i32* %41, align 16, !alias.scope !1394
  %42 = getelementptr inbounds i32, i32* %39, i64 1
  %43 = load i32, i32* %39, align 4
  %44 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 5
  store i32 %43, i32* %44, align 4, !alias.scope !1394
  %45 = getelementptr inbounds i32, i32* %42, i64 1
  %46 = load i32, i32* %42, align 4
  %47 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 6
  store i32 %46, i32* %47, align 8, !alias.scope !1394
  %48 = load i32, i32* %45, align 4
  %49 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 7
  store i32 %48, i32* %49, align 4, !alias.scope !1394
  %50 = add nsw i32 %9, 1
  %51 = mul nsw i32 %23, %50
  %52 = sext i32 %51 to i64
  %53 = getelementptr inbounds i32, i32* %22, i64 %52
  %54 = getelementptr inbounds i32, i32* %53, i64 1
  %55 = load i32, i32* %53, align 4
  %56 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 8
  store i32 %55, i32* %56, align 16, !alias.scope !1394
  %57 = getelementptr inbounds i32, i32* %54, i64 1
  %58 = load i32, i32* %54, align 4
  %59 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 9
  store i32 %58, i32* %59, align 4, !alias.scope !1394
  %60 = getelementptr inbounds i32, i32* %57, i64 1
  %61 = load i32, i32* %57, align 4
  %62 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 10
  store i32 %61, i32* %62, align 8, !alias.scope !1394
  %63 = getelementptr inbounds i32, i32* %60, i64 1
  %64 = load i32, i32* %60, align 4
  %65 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 11
  store i32 %64, i32* %65, align 4, !alias.scope !1394
  %66 = getelementptr inbounds i32, i32* %63, i64 1
  %67 = load i32, i32* %63, align 4
  %68 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 12
  store i32 %67, i32* %68, align 16, !alias.scope !1394
  %69 = getelementptr inbounds i32, i32* %66, i64 1
  %70 = load i32, i32* %66, align 4
  %71 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 13
  store i32 %70, i32* %71, align 4, !alias.scope !1394
  %72 = getelementptr inbounds i32, i32* %69, i64 1
  %73 = load i32, i32* %69, align 4
  %74 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 14
  store i32 %73, i32* %74, align 8, !alias.scope !1394
  %75 = load i32, i32* %72, align 4
  %76 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 15
  store i32 %75, i32* %76, align 4, !alias.scope !1394
  %77 = add nsw i32 %9, 2
  %78 = mul nsw i32 %23, %77
  %79 = sext i32 %78 to i64
  %80 = getelementptr inbounds i32, i32* %22, i64 %79
  %81 = getelementptr inbounds i32, i32* %80, i64 1
  %82 = load i32, i32* %80, align 4
  %83 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 16
  store i32 %82, i32* %83, align 16, !alias.scope !1394
  %84 = getelementptr inbounds i32, i32* %81, i64 1
  %85 = load i32, i32* %81, align 4
  %86 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 17
  store i32 %85, i32* %86, align 4, !alias.scope !1394
  %87 = getelementptr inbounds i32, i32* %84, i64 1
  %88 = load i32, i32* %84, align 4
  %89 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 18
  store i32 %88, i32* %89, align 8, !alias.scope !1394
  %90 = getelementptr inbounds i32, i32* %87, i64 1
  %91 = load i32, i32* %87, align 4
  %92 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 19
  store i32 %91, i32* %92, align 4, !alias.scope !1394
  %93 = getelementptr inbounds i32, i32* %90, i64 1
  %94 = load i32, i32* %90, align 4
  %95 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 20
  store i32 %94, i32* %95, align 16, !alias.scope !1394
  %96 = getelementptr inbounds i32, i32* %93, i64 1
  %97 = load i32, i32* %93, align 4
  %98 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 21
  store i32 %97, i32* %98, align 4, !alias.scope !1394
  %99 = getelementptr inbounds i32, i32* %96, i64 1
  %100 = load i32, i32* %96, align 4
  %101 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 22
  store i32 %100, i32* %101, align 8, !alias.scope !1394
  %102 = load i32, i32* %99, align 4
  %103 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 23
  store i32 %102, i32* %103, align 4, !alias.scope !1394
  %104 = add nsw i32 %9, 3
  %105 = mul nsw i32 %23, %104
  %106 = sext i32 %105 to i64
  %107 = getelementptr inbounds i32, i32* %22, i64 %106
  %108 = getelementptr inbounds i32, i32* %107, i64 1
  %109 = load i32, i32* %107, align 4
  %110 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 24
  store i32 %109, i32* %110, align 16, !alias.scope !1394
  %111 = getelementptr inbounds i32, i32* %108, i64 1
  %112 = load i32, i32* %108, align 4
  %113 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 25
  store i32 %112, i32* %113, align 4, !alias.scope !1394
  %114 = getelementptr inbounds i32, i32* %111, i64 1
  %115 = load i32, i32* %111, align 4
  %116 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 26
  store i32 %115, i32* %116, align 8, !alias.scope !1394
  %117 = getelementptr inbounds i32, i32* %114, i64 1
  %118 = load i32, i32* %114, align 4
  %119 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 27
  store i32 %118, i32* %119, align 4, !alias.scope !1394
  %120 = getelementptr inbounds i32, i32* %117, i64 1
  %121 = load i32, i32* %117, align 4
  %122 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 28
  store i32 %121, i32* %122, align 16, !alias.scope !1394
  %123 = getelementptr inbounds i32, i32* %120, i64 1
  %124 = load i32, i32* %120, align 4
  %125 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 29
  store i32 %124, i32* %125, align 4, !alias.scope !1394
  %126 = getelementptr inbounds i32, i32* %123, i64 1
  %127 = load i32, i32* %123, align 4
  %128 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 30
  store i32 %127, i32* %128, align 8, !alias.scope !1394
  %129 = load i32, i32* %126, align 4
  %130 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 31
  store i32 %129, i32* %130, align 4, !alias.scope !1394
  %131 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %132 = load i32*, i32** %131, align 8, !noalias !1397
  %133 = getelementptr i32, i32* %132, i64 %18
  %134 = bitcast i32* %133 to <4 x i32>*
  %135 = load <4 x i32>, <4 x i32>* %134, align 4
  %136 = getelementptr inbounds i32, i32* %133, i64 4
  %137 = bitcast i32* %136 to <4 x i32>*
  %138 = load <4 x i32>, <4 x i32>* %137, align 4
  %139 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %140 = load i32*, i32** %139, align 8
  %141 = sext i32 %9 to i64
  %142 = getelementptr i32, i32* %140, i64 %141
  %143 = bitcast i32* %142 to i64*
  %144 = load i64, i64* %143, align 4
  %145 = getelementptr inbounds i32, i32* %142, i64 2
  %146 = bitcast i32* %145 to i64*
  %147 = load i64, i64* %146, align 4
  %148 = lshr i64 %144, 32
  %149 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 0
  %150 = load i32, i32* %149, align 4
  %151 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %152 = load i32, i32* %151, align 4
  %153 = insertelement <4 x i32> undef, i32 %152, i32 0
  %154 = shufflevector <4 x i32> %153, <4 x i32> undef, <4 x i32> zeroinitializer
  %155 = mul nsw <4 x i32> %154, %135
  %156 = mul nsw <4 x i32> %154, %138
  %157 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to <4 x i32>*
  %158 = load <4 x i32>, <4 x i32>* %157, align 16
  %159 = add nsw <4 x i32> %158, %155
  %160 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to <4 x i32>*
  store <4 x i32> %159, <4 x i32>* %160, align 16
  %161 = bitcast i32* %41 to <4 x i32>*
  %162 = load <4 x i32>, <4 x i32>* %161, align 16
  %163 = add nsw <4 x i32> %162, %156
  %164 = bitcast i32* %41 to <4 x i32>*
  store <4 x i32> %163, <4 x i32>* %164, align 16
  %165 = bitcast i32* %56 to <4 x i32>*
  %166 = load <4 x i32>, <4 x i32>* %165, align 16
  %167 = add nsw <4 x i32> %166, %155
  %168 = bitcast i32* %56 to <4 x i32>*
  store <4 x i32> %167, <4 x i32>* %168, align 16
  %169 = bitcast i32* %68 to <4 x i32>*
  %170 = load <4 x i32>, <4 x i32>* %169, align 16
  %171 = add nsw <4 x i32> %170, %156
  %172 = bitcast i32* %68 to <4 x i32>*
  store <4 x i32> %171, <4 x i32>* %172, align 16
  %173 = bitcast i32* %83 to <4 x i32>*
  %174 = load <4 x i32>, <4 x i32>* %173, align 16
  %175 = add nsw <4 x i32> %174, %155
  %176 = bitcast i32* %83 to <4 x i32>*
  store <4 x i32> %175, <4 x i32>* %176, align 16
  %177 = bitcast i32* %95 to <4 x i32>*
  %178 = load <4 x i32>, <4 x i32>* %177, align 16
  %179 = add nsw <4 x i32> %178, %156
  %180 = bitcast i32* %95 to <4 x i32>*
  store <4 x i32> %179, <4 x i32>* %180, align 16
  %181 = bitcast i32* %110 to <4 x i32>*
  %182 = load <4 x i32>, <4 x i32>* %181, align 16
  %183 = add nsw <4 x i32> %182, %155
  %184 = bitcast i32* %110 to <4 x i32>*
  store <4 x i32> %183, <4 x i32>* %184, align 16
  %185 = bitcast i32* %122 to <4 x i32>*
  %186 = load <4 x i32>, <4 x i32>* %185, align 16
  %187 = add nsw <4 x i32> %186, %156
  %188 = bitcast i32* %122 to <4 x i32>*
  store <4 x i32> %187, <4 x i32>* %188, align 16
  %189 = trunc i64 %144 to i32
  %190 = trunc i64 %148 to i32
  %191 = mul nsw i32 %152, %7
  %192 = add nsw i32 %191, %189
  %193 = add nsw i32 %191, %190
  %194 = trunc i64 %147 to i32
  %195 = add nsw i32 %191, %194
  %196 = lshr i64 %147, 32
  %197 = trunc i64 %196 to i32
  %198 = add nsw i32 %191, %197
  %199 = mul nsw i32 %192, %150
  %200 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to <4 x i32>*
  %201 = load <4 x i32>, <4 x i32>* %200, align 16
  %202 = insertelement <4 x i32> undef, i32 %199, i32 0
  %203 = shufflevector <4 x i32> %202, <4 x i32> undef, <4 x i32> zeroinitializer
  %204 = add nsw <4 x i32> %201, %203
  %205 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to <4 x i32>*
  store <4 x i32> %204, <4 x i32>* %205, align 16
  %206 = bitcast i32* %41 to <4 x i32>*
  %207 = load <4 x i32>, <4 x i32>* %206, align 16
  %208 = add nsw <4 x i32> %207, %203
  %209 = bitcast i32* %41 to <4 x i32>*
  store <4 x i32> %208, <4 x i32>* %209, align 16
  %210 = mul nsw i32 %193, %150
  %211 = bitcast i32* %56 to <4 x i32>*
  %212 = load <4 x i32>, <4 x i32>* %211, align 16
  %213 = insertelement <4 x i32> undef, i32 %210, i32 0
  %214 = shufflevector <4 x i32> %213, <4 x i32> undef, <4 x i32> zeroinitializer
  %215 = add nsw <4 x i32> %212, %214
  %216 = bitcast i32* %56 to <4 x i32>*
  store <4 x i32> %215, <4 x i32>* %216, align 16
  %217 = bitcast i32* %68 to <4 x i32>*
  %218 = load <4 x i32>, <4 x i32>* %217, align 16
  %219 = add nsw <4 x i32> %218, %214
  %220 = bitcast i32* %68 to <4 x i32>*
  store <4 x i32> %219, <4 x i32>* %220, align 16
  %221 = mul nsw i32 %195, %150
  %222 = bitcast i32* %83 to <4 x i32>*
  %223 = load <4 x i32>, <4 x i32>* %222, align 16
  %224 = insertelement <4 x i32> undef, i32 %221, i32 0
  %225 = shufflevector <4 x i32> %224, <4 x i32> undef, <4 x i32> zeroinitializer
  %226 = add nsw <4 x i32> %223, %225
  %227 = bitcast i32* %83 to <4 x i32>*
  store <4 x i32> %226, <4 x i32>* %227, align 16
  %228 = bitcast i32* %95 to <4 x i32>*
  %229 = load <4 x i32>, <4 x i32>* %228, align 16
  %230 = add nsw <4 x i32> %229, %225
  %231 = bitcast i32* %95 to <4 x i32>*
  store <4 x i32> %230, <4 x i32>* %231, align 16
  %232 = mul nsw i32 %198, %150
  %233 = bitcast i32* %110 to <4 x i32>*
  %234 = load <4 x i32>, <4 x i32>* %233, align 16
  %235 = insertelement <4 x i32> undef, i32 %232, i32 0
  %236 = shufflevector <4 x i32> %235, <4 x i32> undef, <4 x i32> zeroinitializer
  %237 = add nsw <4 x i32> %234, %236
  %238 = bitcast i32* %110 to <4 x i32>*
  store <4 x i32> %237, <4 x i32>* %238, align 16
  %239 = bitcast i32* %122 to <4 x i32>*
  %240 = load <4 x i32>, <4 x i32>* %239, align 16
  %241 = add nsw <4 x i32> %240, %236
  %242 = bitcast i32* %122 to <4 x i32>*
  store <4 x i32> %241, <4 x i32>* %242, align 16
  tail call void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi8ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE1EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.548"* %1, %"struct.gemmlowp::RegisterBlock.302"* nonnull byval(%"struct.gemmlowp::RegisterBlock.302") align 8 %15, %"class.gemmlowp::MatrixMap.489"* %2, i32 %10, i32 %11, i32 %12, i32 %13)
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %16) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.517"* dereferenceable(40), %"class.gemmlowp::MatrixMap.489"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.304", align 16
  %16 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %17 = sext i32 %8 to i64
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %19 = load i32*, i32** %16, align 8, !noalias !1402
  %20 = getelementptr inbounds i32, i32* %19, i64 %17
  %21 = load i32, i32* %18, align 8, !noalias !1402
  %22 = mul nsw i32 %21, %9
  %23 = sext i32 %22 to i64
  %24 = getelementptr inbounds i32, i32* %20, i64 %23
  %25 = getelementptr inbounds i32, i32* %24, i64 1
  %26 = getelementptr inbounds i32, i32* %25, i64 1
  %27 = getelementptr inbounds i32, i32* %26, i64 1
  %28 = getelementptr inbounds i32, i32* %27, i64 1
  %29 = bitcast i32* %24 to <4 x i32>*
  %30 = load <4 x i32>, <4 x i32>* %29, align 4, !noalias !1402
  %31 = getelementptr inbounds i32, i32* %28, i64 1
  %32 = load i32, i32* %28, align 4, !noalias !1402
  %33 = getelementptr inbounds i32, i32* %31, i64 1
  %34 = load i32, i32* %31, align 4, !noalias !1402
  %35 = getelementptr inbounds i32, i32* %33, i64 1
  %36 = load i32, i32* %33, align 4, !noalias !1402
  %37 = load i32, i32* %35, align 4, !noalias !1402
  %38 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %39 = load i32*, i32** %38, align 8, !noalias !1407
  %40 = getelementptr i32, i32* %39, i64 %17
  %41 = bitcast i32* %40 to <4 x i32>*
  %42 = load <4 x i32>, <4 x i32>* %41, align 4
  %43 = getelementptr inbounds i32, i32* %40, i64 4
  %44 = bitcast i32* %43 to <4 x i32>*
  %45 = load <4 x i32>, <4 x i32>* %44, align 4
  %46 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %47 = load i32*, i32** %46, align 8
  %48 = sext i32 %9 to i64
  %49 = getelementptr inbounds i32, i32* %47, i64 %48
  %50 = load i32, i32* %49, align 4
  %51 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 0
  %52 = load i32, i32* %51, align 4
  %53 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %54 = load i32, i32* %53, align 4
  %55 = insertelement <4 x i32> undef, i32 %54, i32 0
  %56 = shufflevector <4 x i32> %55, <4 x i32> undef, <4 x i32> zeroinitializer
  %57 = mul nsw <4 x i32> %56, %42
  %58 = mul nsw <4 x i32> %56, %45
  %59 = mul nsw i32 %54, %7
  %60 = add nsw i32 %59, %50
  %61 = mul nsw i32 %60, %52
  %62 = bitcast %"struct.gemmlowp::RegisterBlock.304"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %62) #19
  %63 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.517", %"struct.gemmlowp::OutputPipelineExecutor.517"* %1, i64 0, i32 0, i32 0, i32 0
  %64 = load %"struct.gemmlowp::OutputStageBiasAddition.200"*, %"struct.gemmlowp::OutputStageBiasAddition.200"** %63, align 8, !noalias !1412
  %65 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition.200", %"struct.gemmlowp::OutputStageBiasAddition.200"* %64, i64 0, i32 0, i32 0
  %66 = load i32*, i32** %65, align 8, !noalias !1412
  %67 = sext i32 %11 to i64
  %68 = getelementptr inbounds i32, i32* %66, i64 %67
  %69 = load i32, i32* %68, align 4, !noalias !1412
  %70 = add i32 %69, %61
  %71 = insertelement <4 x i32> undef, i32 %70, i32 0
  %72 = shufflevector <4 x i32> %71, <4 x i32> undef, <4 x i32> zeroinitializer
  %73 = add <4 x i32> %72, %30
  %74 = add <4 x i32> %73, %57
  %75 = insertelement <4 x i32> undef, i32 %32, i32 0
  %76 = insertelement <4 x i32> %75, i32 %34, i32 1
  %77 = insertelement <4 x i32> %76, i32 %36, i32 2
  %78 = insertelement <4 x i32> %77, i32 %37, i32 3
  %79 = add <4 x i32> %72, %78
  %80 = add <4 x i32> %79, %58
  %81 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.517", %"struct.gemmlowp::OutputPipelineExecutor.517"* %1, i64 0, i32 0, i32 1
  %82 = bitcast %"struct.gemmlowp::RegisterBlock.304"* %15 to <4 x i32>*
  store <4 x i32> %74, <4 x i32>* %82, align 16
  %83 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %15, i64 0, i32 0, i32 0, i64 4
  %84 = bitcast i32* %83 to <4 x i32>*
  store <4 x i32> %80, <4 x i32>* %84, align 16
  %85 = tail call { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalESE_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.519"* %81, %"struct.gemmlowp::RegisterBlock.304"* nonnull byval(%"struct.gemmlowp::RegisterBlock.304") align 8 %15, i32 %10, i32 %11) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %62) #19
  %86 = extractvalue { i64, i64 } %85, 0
  %87 = extractvalue { i64, i64 } %85, 1
  %88 = trunc i64 %86 to i16
  %89 = lshr i64 %86, 16
  %90 = trunc i64 %89 to i16
  %91 = lshr i64 %86, 32
  %92 = trunc i64 %91 to i16
  %93 = lshr i64 %86, 48
  %94 = trunc i64 %93 to i16
  %95 = trunc i64 %87 to i16
  %96 = lshr i64 %87, 16
  %97 = trunc i64 %96 to i16
  %98 = lshr i64 %87, 32
  %99 = trunc i64 %98 to i16
  %100 = lshr i64 %87, 48
  %101 = trunc i64 %100 to i16
  %102 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %2, i64 0, i32 0
  %103 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %2, i64 0, i32 3
  %104 = sext i32 %12 to i64
  %105 = load i16*, i16** %102, align 8
  %106 = load i32, i32* %103, align 8
  %107 = sext i32 %106 to i64
  %108 = mul nsw i64 %107, %104
  %109 = getelementptr inbounds i16, i16* %105, i64 %108
  %110 = sext i32 %13 to i64
  %111 = getelementptr inbounds i16, i16* %109, i64 %110
  store i16 %88, i16* %111, align 2
  %112 = add nsw i64 %104, 1
  %113 = load i16*, i16** %102, align 8
  %114 = load i32, i32* %103, align 8
  %115 = sext i32 %114 to i64
  %116 = mul nsw i64 %112, %115
  %117 = getelementptr inbounds i16, i16* %113, i64 %116
  %118 = getelementptr inbounds i16, i16* %117, i64 %110
  store i16 %90, i16* %118, align 2
  %119 = add nsw i64 %104, 2
  %120 = load i16*, i16** %102, align 8
  %121 = load i32, i32* %103, align 8
  %122 = sext i32 %121 to i64
  %123 = mul nsw i64 %119, %122
  %124 = getelementptr inbounds i16, i16* %120, i64 %123
  %125 = getelementptr inbounds i16, i16* %124, i64 %110
  store i16 %92, i16* %125, align 2
  %126 = add nsw i64 %104, 3
  %127 = load i16*, i16** %102, align 8
  %128 = load i32, i32* %103, align 8
  %129 = sext i32 %128 to i64
  %130 = mul nsw i64 %126, %129
  %131 = getelementptr inbounds i16, i16* %127, i64 %130
  %132 = getelementptr inbounds i16, i16* %131, i64 %110
  store i16 %94, i16* %132, align 2
  %133 = add nsw i64 %104, 4
  %134 = load i16*, i16** %102, align 8
  %135 = load i32, i32* %103, align 8
  %136 = sext i32 %135 to i64
  %137 = mul nsw i64 %133, %136
  %138 = getelementptr inbounds i16, i16* %134, i64 %137
  %139 = getelementptr inbounds i16, i16* %138, i64 %110
  store i16 %95, i16* %139, align 2
  %140 = add nsw i64 %104, 5
  %141 = load i16*, i16** %102, align 8
  %142 = load i32, i32* %103, align 8
  %143 = sext i32 %142 to i64
  %144 = mul nsw i64 %140, %143
  %145 = getelementptr inbounds i16, i16* %141, i64 %144
  %146 = getelementptr inbounds i16, i16* %145, i64 %110
  store i16 %97, i16* %146, align 2
  %147 = add nsw i64 %104, 6
  %148 = load i16*, i16** %102, align 8
  %149 = load i32, i32* %103, align 8
  %150 = sext i32 %149 to i64
  %151 = mul nsw i64 %147, %150
  %152 = getelementptr inbounds i16, i16* %148, i64 %151
  %153 = getelementptr inbounds i16, i16* %152, i64 %110
  store i16 %99, i16* %153, align 2
  %154 = add nsw i64 %104, 7
  %155 = load i16*, i16** %102, align 8
  %156 = load i32, i32* %103, align 8
  %157 = sext i32 %156 to i64
  %158 = mul nsw i64 %154, %157
  %159 = getelementptr inbounds i16, i16* %155, i64 %158
  %160 = getelementptr inbounds i16, i16* %159, i64 %110
  store i16 %101, i16* %160, align 2
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNSM_ISB_LSF_0EEERKSN_RKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.495"* dereferenceable(40), %"class.gemmlowp::MatrixMap.489"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %16 = load i32*, i32** %15, align 8
  %17 = sext i32 %8 to i64
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %19 = load i32, i32* %18, align 8
  %20 = getelementptr inbounds i32, i32* %16, i64 %17
  %21 = mul nsw i32 %19, %9
  %22 = sext i32 %21 to i64
  %23 = getelementptr inbounds i32, i32* %20, i64 %22
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %26 = load i32*, i32** %25, align 8
  %27 = getelementptr inbounds i32, i32* %26, i64 %17
  %28 = load i32, i32* %27, align 4
  %29 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %30 = load i32*, i32** %29, align 8
  %31 = sext i32 %9 to i64
  %32 = getelementptr inbounds i32, i32* %30, i64 %31
  %33 = load i32, i32* %32, align 4
  %34 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 0
  %35 = load i32, i32* %34, align 4
  %36 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %37 = load i32, i32* %36, align 4
  %38 = mul nsw i32 %37, %28
  %39 = add nsw i32 %38, %24
  %40 = mul nsw i32 %37, %7
  %41 = add nsw i32 %40, %33
  %42 = mul nsw i32 %41, %35
  %43 = add nsw i32 %39, %42
  %44 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.495", %"struct.gemmlowp::OutputPipelineExecutor.495"* %1, i64 0, i32 0, i32 0, i32 0
  %45 = load %"struct.gemmlowp::OutputStageBiasAddition.200"*, %"struct.gemmlowp::OutputStageBiasAddition.200"** %44, align 8
  %46 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition.200", %"struct.gemmlowp::OutputStageBiasAddition.200"* %45, i64 0, i32 0, i32 0
  %47 = load i32*, i32** %46, align 8
  %48 = sext i32 %11 to i64
  %49 = getelementptr inbounds i32, i32* %47, i64 %48
  %50 = load i32, i32* %49, align 4
  %51 = add nsw i32 %43, %50
  %52 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.495", %"struct.gemmlowp::OutputPipelineExecutor.495"* %1, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %53 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %52, align 8
  %54 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %53, i64 0, i32 2
  %55 = load i32, i32* %54, align 4
  %56 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.495", %"struct.gemmlowp::OutputPipelineExecutor.495"* %1, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  %57 = load i32, i32* %56, align 8
  %58 = sext i32 %51 to i64
  %59 = shl i32 1, %57
  %60 = sext i32 %59 to i64
  %61 = mul nsw i64 %60, %58
  %62 = icmp slt i64 %61, 2147483647
  %63 = select i1 %62, i64 %61, i64 2147483647
  %64 = icmp sgt i64 %63, -2147483648
  %65 = select i1 %64, i64 %63, i64 -2147483648
  %66 = trunc i64 %65 to i32
  %67 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %53, i64 0, i32 0
  %68 = load i32, i32* %67, align 4
  %69 = icmp ne i32 %68, %66
  %70 = icmp ne i32 %66, -2147483648
  %71 = or i1 %69, %70
  br i1 %71, label %72, label %81

72:                                               ; preds = %14
  %73 = sext i32 %68 to i64
  %74 = select i1 %69, i64 %73, i64 %65
  %75 = mul nsw i64 %74, %65
  %76 = icmp sgt i64 %75, -1
  %77 = select i1 %76, i64 1073741824, i64 -1073741823
  %78 = add nsw i64 %77, %75
  %79 = sdiv i64 %78, 2147483648
  %80 = trunc i64 %79 to i32
  br label %81

81:                                               ; preds = %14, %72
  %82 = phi i32 [ %80, %72 ], [ 2147483647, %14 ]
  %83 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.495", %"struct.gemmlowp::OutputPipelineExecutor.495"* %1, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  %84 = load i32, i32* %83, align 4
  %85 = zext i32 %84 to i64
  %86 = shl nsw i64 -1, %85
  %87 = trunc i64 %86 to i32
  %88 = xor i32 %87, -1
  %89 = and i32 %82, %88
  %90 = ashr i32 %88, 1
  %91 = lshr i32 %82, 31
  %92 = add nsw i32 %90, %91
  %93 = ashr i32 %82, %84
  %94 = icmp sgt i32 %89, %92
  %95 = zext i1 %94 to i32
  %96 = add i32 %93, %55
  %97 = add i32 %96, %95
  %98 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.495", %"struct.gemmlowp::OutputPipelineExecutor.495"* %1, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %99 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %98, align 8
  %100 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %99, i64 0, i32 0
  %101 = load i32, i32* %100, align 4
  %102 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %99, i64 0, i32 1
  %103 = load i32, i32* %102, align 4
  %104 = icmp sgt i32 %101, %97
  %105 = select i1 %104, i32 %101, i32 %97
  %106 = icmp slt i32 %103, %105
  %107 = select i1 %106, i32 %103, i32 %105
  %108 = icmp sgt i32 %107, -32768
  %109 = select i1 %108, i32 %107, i32 -32768
  %110 = icmp slt i32 %109, 32767
  %111 = select i1 %110, i32 %109, i32 32767
  %112 = trunc i32 %111 to i16
  %113 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %2, i64 0, i32 0
  %114 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %2, i64 0, i32 3
  %115 = load i16*, i16** %113, align 8
  %116 = load i32, i32* %114, align 8
  %117 = mul nsw i32 %116, %12
  %118 = sext i32 %117 to i64
  %119 = getelementptr inbounds i16, i16* %115, i64 %118
  %120 = sext i32 %13 to i64
  %121 = getelementptr inbounds i16, i16* %119, i64 %120
  store i16 %112, i16* %121, align 2
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi8ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE0EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.548"*, %"struct.gemmlowp::RegisterBlock.302"* byval(%"struct.gemmlowp::RegisterBlock.302") align 8, %"class.gemmlowp::MatrixMap.479"*, i32, i32, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %8 = alloca %"struct.gemmlowp::RegisterBlock.561", align 8
  %9 = alloca %"struct.gemmlowp::RegisterBlock.302", align 16
  %10 = alloca %"struct.gemmlowp::RegisterBlock.561", align 2
  %11 = bitcast %"struct.gemmlowp::RegisterBlock.561"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %11) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 2 %11, i8 -86, i64 64, i1 false)
  %12 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %1 to <4 x i32>*
  %13 = load <4 x i32>, <4 x i32>* %12, align 8
  %14 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 4
  %15 = bitcast i32* %14 to <4 x i32>*
  %16 = load <4 x i32>, <4 x i32>* %15, align 8
  %17 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 8
  %18 = bitcast i32* %17 to <4 x i32>*
  %19 = load <4 x i32>, <4 x i32>* %18, align 8
  %20 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 12
  %21 = bitcast i32* %20 to <4 x i32>*
  %22 = load <4 x i32>, <4 x i32>* %21, align 8
  %23 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 16
  %24 = bitcast i32* %23 to <4 x i32>*
  %25 = load <4 x i32>, <4 x i32>* %24, align 8
  %26 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 20
  %27 = bitcast i32* %26 to <4 x i32>*
  %28 = load <4 x i32>, <4 x i32>* %27, align 8
  %29 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 24
  %30 = bitcast i32* %29 to <4 x i32>*
  %31 = load <4 x i32>, <4 x i32>* %30, align 8
  %32 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 28
  %33 = bitcast i32* %32 to <4 x i32>*
  %34 = load <4 x i32>, <4 x i32>* %33, align 8
  %35 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %35)
  %36 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.548", %"struct.gemmlowp::OutputPipelineExecutor.548"* %0, i64 0, i32 0, i32 0, i32 0
  %37 = load %"struct.gemmlowp::OutputStageBiasAddition.200"*, %"struct.gemmlowp::OutputStageBiasAddition.200"** %36, align 8, !noalias !1415
  %38 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition.200", %"struct.gemmlowp::OutputStageBiasAddition.200"* %37, i64 0, i32 0, i32 0
  %39 = load i32*, i32** %38, align 8, !noalias !1415
  %40 = sext i32 %4 to i64
  %41 = getelementptr i32, i32* %39, i64 %40
  %42 = bitcast i32* %41 to i64*
  %43 = load i64, i64* %42, align 4, !noalias !1415
  %44 = getelementptr inbounds i32, i32* %41, i64 2
  %45 = bitcast i32* %44 to i64*
  %46 = load i64, i64* %45, align 4, !noalias !1415
  %47 = trunc i64 %43 to i32
  %48 = lshr i64 %43, 32
  %49 = trunc i64 %48 to i32
  %50 = insertelement <4 x i32> undef, i32 %47, i32 0
  %51 = shufflevector <4 x i32> %50, <4 x i32> undef, <4 x i32> zeroinitializer
  %52 = add nsw <4 x i32> %13, %51
  %53 = add nsw <4 x i32> %16, %51
  %54 = insertelement <4 x i32> undef, i32 %49, i32 0
  %55 = shufflevector <4 x i32> %54, <4 x i32> undef, <4 x i32> zeroinitializer
  %56 = add nsw <4 x i32> %19, %55
  %57 = add nsw <4 x i32> %22, %55
  %58 = trunc i64 %46 to i32
  %59 = insertelement <4 x i32> undef, i32 %58, i32 0
  %60 = shufflevector <4 x i32> %59, <4 x i32> undef, <4 x i32> zeroinitializer
  %61 = add nsw <4 x i32> %25, %60
  %62 = add nsw <4 x i32> %28, %60
  %63 = lshr i64 %46, 32
  %64 = trunc i64 %63 to i32
  %65 = insertelement <4 x i32> undef, i32 %64, i32 0
  %66 = shufflevector <4 x i32> %65, <4 x i32> undef, <4 x i32> zeroinitializer
  %67 = add nsw <4 x i32> %31, %66
  %68 = add nsw <4 x i32> %34, %66
  %69 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.548", %"struct.gemmlowp::OutputPipelineExecutor.548"* %0, i64 0, i32 0, i32 1
  %70 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %9 to <4 x i32>*
  store <4 x i32> %52, <4 x i32>* %70, align 16, !noalias !1420
  %71 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %9, i64 0, i32 0, i32 0, i64 4
  %72 = bitcast i32* %71 to <4 x i32>*
  store <4 x i32> %53, <4 x i32>* %72, align 16, !noalias !1420
  %73 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %9, i64 0, i32 0, i32 0, i64 8
  %74 = bitcast i32* %73 to <4 x i32>*
  store <4 x i32> %56, <4 x i32>* %74, align 16, !noalias !1420
  %75 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %9, i64 0, i32 0, i32 0, i64 12
  %76 = bitcast i32* %75 to <4 x i32>*
  store <4 x i32> %57, <4 x i32>* %76, align 16, !noalias !1420
  %77 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %9, i64 0, i32 0, i32 0, i64 16
  %78 = bitcast i32* %77 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %78, align 16, !noalias !1420
  %79 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %9, i64 0, i32 0, i32 0, i64 20
  %80 = bitcast i32* %79 to <4 x i32>*
  store <4 x i32> %62, <4 x i32>* %80, align 16, !noalias !1420
  %81 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %9, i64 0, i32 0, i32 0, i64 24
  %82 = bitcast i32* %81 to <4 x i32>*
  store <4 x i32> %67, <4 x i32>* %82, align 16, !noalias !1420
  %83 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %9, i64 0, i32 0, i32 0, i64 28
  %84 = bitcast i32* %83 to <4 x i32>*
  store <4 x i32> %68, <4 x i32>* %84, align 16, !noalias !1420
  call void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.561"* nonnull sret %10, %"struct.gemmlowp::OutputPipelineEvalImpl.550"* %69, %"struct.gemmlowp::RegisterBlock.302"* nonnull byval(%"struct.gemmlowp::RegisterBlock.302") align 8 %9, i32 %3, i32 %4) #19
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %35)
  %85 = bitcast %"struct.gemmlowp::RegisterBlock.561"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %85)
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %85, i8* nonnull align 2 %11, i64 64, i1 false)
  %86 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %2, i64 0, i32 0
  %87 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %2, i64 0, i32 3
  %88 = sext i32 %6 to i64
  %89 = sext i32 %5 to i64
  %90 = add nsw i64 %88, 1
  %91 = add nsw i64 %88, 2
  %92 = add nsw i64 %88, 3
  br label %93

93:                                               ; preds = %93, %7
  %94 = phi i64 [ 0, %7 ], [ %131, %93 ]
  %95 = add nsw i64 %94, %89
  %96 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.561", %"struct.gemmlowp::RegisterBlock.561"* %8, i64 0, i32 0, i32 0, i64 %94
  %97 = load i16, i16* %96, align 2
  %98 = load i16*, i16** %86, align 8
  %99 = getelementptr inbounds i16, i16* %98, i64 %95
  %100 = load i32, i32* %87, align 8
  %101 = sext i32 %100 to i64
  %102 = mul nsw i64 %101, %88
  %103 = getelementptr inbounds i16, i16* %99, i64 %102
  store i16 %97, i16* %103, align 2
  %104 = add nuw nsw i64 %94, 8
  %105 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.561", %"struct.gemmlowp::RegisterBlock.561"* %8, i64 0, i32 0, i32 0, i64 %104
  %106 = load i16, i16* %105, align 2
  %107 = load i16*, i16** %86, align 8
  %108 = getelementptr inbounds i16, i16* %107, i64 %95
  %109 = load i32, i32* %87, align 8
  %110 = sext i32 %109 to i64
  %111 = mul nsw i64 %90, %110
  %112 = getelementptr inbounds i16, i16* %108, i64 %111
  store i16 %106, i16* %112, align 2
  %113 = add nuw nsw i64 %94, 16
  %114 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.561", %"struct.gemmlowp::RegisterBlock.561"* %8, i64 0, i32 0, i32 0, i64 %113
  %115 = load i16, i16* %114, align 2
  %116 = load i16*, i16** %86, align 8
  %117 = getelementptr inbounds i16, i16* %116, i64 %95
  %118 = load i32, i32* %87, align 8
  %119 = sext i32 %118 to i64
  %120 = mul nsw i64 %91, %119
  %121 = getelementptr inbounds i16, i16* %117, i64 %120
  store i16 %115, i16* %121, align 2
  %122 = add nuw nsw i64 %94, 24
  %123 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.561", %"struct.gemmlowp::RegisterBlock.561"* %8, i64 0, i32 0, i32 0, i64 %122
  %124 = load i16, i16* %123, align 2
  %125 = load i16*, i16** %86, align 8
  %126 = getelementptr inbounds i16, i16* %125, i64 %95
  %127 = load i32, i32* %87, align 8
  %128 = sext i32 %127 to i64
  %129 = mul nsw i64 %92, %128
  %130 = getelementptr inbounds i16, i16* %126, i64 %129
  store i16 %124, i16* %130, align 2
  %131 = add nuw nsw i64 %94, 1
  %132 = icmp eq i64 %131, 8
  br i1 %132, label %133, label %93

133:                                              ; preds = %93
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %85)
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %11) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.561"* noalias sret, %"struct.gemmlowp::OutputPipelineEvalImpl.550"*, %"struct.gemmlowp::RegisterBlock.302"* byval(%"struct.gemmlowp::RegisterBlock.302") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %6 = alloca %"struct.gemmlowp::RegisterBuffer.303", align 16
  %7 = alloca %"struct.gemmlowp::RegisterBuffer.562", align 8
  %8 = alloca [32 x i16], align 2
  %9 = alloca %"struct.gemmlowp::RegisterBuffer.303", align 16
  %10 = alloca %"struct.gemmlowp::RegisterBuffer.303", align 16
  %11 = alloca [32 x i32], align 4
  %12 = alloca %"struct.gemmlowp::RegisterBuffer.303", align 8
  %13 = alloca %"struct.gemmlowp::RegisterBuffer.303", align 4
  %14 = alloca [32 x i32], align 4
  %15 = bitcast [32 x i32]* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %15)
  %16 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %2 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %15, i8 -86, i64 128, i1 false), !alias.scope !1421
  %17 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %17) #19, !noalias !1421
  %18 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %18) #19, !noalias !1421
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %18, i8* nonnull align 8 %16, i64 128, i1 false)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %17, i8 -86, i64 128, i1 false) #19, !alias.scope !1424, !noalias !1421
  %19 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.550", %"struct.gemmlowp::OutputPipelineEvalImpl.550"* %1, i64 0, i32 0, i32 0, i32 0
  %20 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %19, align 8, !noalias !1427
  %21 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %20, i64 0, i32 2
  %22 = load i32, i32* %21, align 4, !noalias !1427
  %23 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.550", %"struct.gemmlowp::OutputPipelineEvalImpl.550"* %1, i64 0, i32 0, i32 0, i32 1
  %24 = load i32, i32* %23, align 8, !noalias !1427
  %25 = shl i32 1, %24
  %26 = sext i32 %25 to i64
  %27 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %20, i64 0, i32 0
  %28 = load i32, i32* %27, align 4, !noalias !1427
  %29 = sext i32 %28 to i64
  %30 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.550", %"struct.gemmlowp::OutputPipelineEvalImpl.550"* %1, i64 0, i32 0, i32 0, i32 2
  %31 = load i32, i32* %30, align 4, !noalias !1427
  %32 = zext i32 %31 to i64
  %33 = shl nsw i64 -1, %32
  %34 = trunc i64 %33 to i32
  %35 = xor i32 %34, -1
  %36 = ashr i32 %35, 1
  %37 = icmp ne i32 %28, -2147483648
  br label %38

38:                                               ; preds = %59, %5
  %39 = phi i64 [ 0, %5 ], [ %70, %59 ]
  %40 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %12, i64 0, i32 0, i64 %39
  %41 = load i32, i32* %40, align 4, !noalias !1427
  %42 = sext i32 %41 to i64
  %43 = mul nsw i64 %42, %26
  %44 = icmp slt i64 %43, 2147483647
  %45 = select i1 %44, i64 %43, i64 2147483647
  %46 = icmp sgt i64 %45, -2147483648
  %47 = select i1 %46, i64 %45, i64 -2147483648
  %48 = trunc i64 %47 to i32
  %49 = icmp ne i32 %28, %48
  %50 = or i1 %37, %49
  br i1 %50, label %51, label %59

51:                                               ; preds = %38
  %52 = select i1 %49, i64 %29, i64 %47
  %53 = mul nsw i64 %52, %47
  %54 = icmp sgt i64 %53, -1
  %55 = select i1 %54, i64 1073741824, i64 -1073741823
  %56 = add nsw i64 %55, %53
  %57 = sdiv i64 %56, 2147483648
  %58 = trunc i64 %57 to i32
  br label %59

59:                                               ; preds = %51, %38
  %60 = phi i32 [ %58, %51 ], [ 2147483647, %38 ]
  %61 = and i32 %60, %35
  %62 = lshr i32 %60, 31
  %63 = add nsw i32 %62, %36
  %64 = ashr i32 %60, %31
  %65 = icmp sgt i32 %61, %63
  %66 = zext i1 %65 to i32
  %67 = add i32 %64, %22
  %68 = add i32 %67, %66
  %69 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %13, i64 0, i32 0, i64 %39
  store i32 %68, i32* %69, align 4, !alias.scope !1424, !noalias !1421
  %70 = add nuw nsw i64 %39, 1
  %71 = icmp eq i64 %70, 32
  br i1 %71, label %72, label %38

72:                                               ; preds = %59
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %18) #19, !noalias !1421
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 4 %15, i8* nonnull align 4 %17, i64 128, i1 false)
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %17) #19, !noalias !1421
  %73 = bitcast [32 x i32]* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %73)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %73, i8 -86, i64 128, i1 false), !alias.scope !1428, !noalias !1431
  %74 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %74) #19, !noalias !1434
  %75 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %75) #19, !noalias !1434
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %75, i8* nonnull align 4 %15, i64 128, i1 false)
  %76 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.550", %"struct.gemmlowp::OutputPipelineEvalImpl.550"* %1, i64 0, i32 1, i32 0, i32 0, i32 0
  %77 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %76, align 8, !noalias !1435
  %78 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %77, i64 0, i32 0
  %79 = load i32, i32* %78, align 4, !noalias !1435
  %80 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %77, i64 0, i32 1
  %81 = load i32, i32* %80, align 4, !noalias !1435
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %74, i8 -86, i64 128, i1 false) #19, !alias.scope !1438, !noalias !1434
  %82 = insertelement <4 x i32> undef, i32 %79, i32 0
  %83 = shufflevector <4 x i32> %82, <4 x i32> undef, <4 x i32> zeroinitializer
  %84 = insertelement <4 x i32> undef, i32 %81, i32 0
  %85 = shufflevector <4 x i32> %84, <4 x i32> undef, <4 x i32> zeroinitializer
  %86 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %9 to <4 x i32>*
  %87 = load <4 x i32>, <4 x i32>* %86, align 16, !noalias !1435
  %88 = icmp slt <4 x i32> %87, %83
  %89 = select <4 x i1> %88, <4 x i32> %83, <4 x i32> %87
  %90 = icmp slt <4 x i32> %85, %89
  %91 = select <4 x i1> %90, <4 x i32> %85, <4 x i32> %89
  %92 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %10 to <4 x i32>*
  store <4 x i32> %91, <4 x i32>* %92, align 16, !alias.scope !1438, !noalias !1434
  %93 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %9, i64 0, i32 0, i64 4
  %94 = bitcast i32* %93 to <4 x i32>*
  %95 = load <4 x i32>, <4 x i32>* %94, align 16, !noalias !1435
  %96 = icmp slt <4 x i32> %95, %83
  %97 = select <4 x i1> %96, <4 x i32> %83, <4 x i32> %95
  %98 = icmp slt <4 x i32> %85, %97
  %99 = select <4 x i1> %98, <4 x i32> %85, <4 x i32> %97
  %100 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %10, i64 0, i32 0, i64 4
  %101 = bitcast i32* %100 to <4 x i32>*
  store <4 x i32> %99, <4 x i32>* %101, align 16, !alias.scope !1438, !noalias !1434
  %102 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %9, i64 0, i32 0, i64 8
  %103 = bitcast i32* %102 to <4 x i32>*
  %104 = load <4 x i32>, <4 x i32>* %103, align 16, !noalias !1435
  %105 = icmp slt <4 x i32> %104, %83
  %106 = select <4 x i1> %105, <4 x i32> %83, <4 x i32> %104
  %107 = icmp slt <4 x i32> %85, %106
  %108 = select <4 x i1> %107, <4 x i32> %85, <4 x i32> %106
  %109 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %10, i64 0, i32 0, i64 8
  %110 = bitcast i32* %109 to <4 x i32>*
  store <4 x i32> %108, <4 x i32>* %110, align 16, !alias.scope !1438, !noalias !1434
  %111 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %9, i64 0, i32 0, i64 12
  %112 = bitcast i32* %111 to <4 x i32>*
  %113 = load <4 x i32>, <4 x i32>* %112, align 16, !noalias !1435
  %114 = icmp slt <4 x i32> %113, %83
  %115 = select <4 x i1> %114, <4 x i32> %83, <4 x i32> %113
  %116 = icmp slt <4 x i32> %85, %115
  %117 = select <4 x i1> %116, <4 x i32> %85, <4 x i32> %115
  %118 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %10, i64 0, i32 0, i64 12
  %119 = bitcast i32* %118 to <4 x i32>*
  store <4 x i32> %117, <4 x i32>* %119, align 16, !alias.scope !1438, !noalias !1434
  %120 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %9, i64 0, i32 0, i64 16
  %121 = bitcast i32* %120 to <4 x i32>*
  %122 = load <4 x i32>, <4 x i32>* %121, align 16, !noalias !1435
  %123 = icmp slt <4 x i32> %122, %83
  %124 = select <4 x i1> %123, <4 x i32> %83, <4 x i32> %122
  %125 = icmp slt <4 x i32> %85, %124
  %126 = select <4 x i1> %125, <4 x i32> %85, <4 x i32> %124
  %127 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %10, i64 0, i32 0, i64 16
  %128 = bitcast i32* %127 to <4 x i32>*
  store <4 x i32> %126, <4 x i32>* %128, align 16, !alias.scope !1438, !noalias !1434
  %129 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %9, i64 0, i32 0, i64 20
  %130 = bitcast i32* %129 to <4 x i32>*
  %131 = load <4 x i32>, <4 x i32>* %130, align 16, !noalias !1435
  %132 = icmp slt <4 x i32> %131, %83
  %133 = select <4 x i1> %132, <4 x i32> %83, <4 x i32> %131
  %134 = icmp slt <4 x i32> %85, %133
  %135 = select <4 x i1> %134, <4 x i32> %85, <4 x i32> %133
  %136 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %10, i64 0, i32 0, i64 20
  %137 = bitcast i32* %136 to <4 x i32>*
  store <4 x i32> %135, <4 x i32>* %137, align 16, !alias.scope !1438, !noalias !1434
  %138 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %9, i64 0, i32 0, i64 24
  %139 = bitcast i32* %138 to <4 x i32>*
  %140 = load <4 x i32>, <4 x i32>* %139, align 16, !noalias !1435
  %141 = icmp slt <4 x i32> %140, %83
  %142 = select <4 x i1> %141, <4 x i32> %83, <4 x i32> %140
  %143 = icmp slt <4 x i32> %85, %142
  %144 = select <4 x i1> %143, <4 x i32> %85, <4 x i32> %142
  %145 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %10, i64 0, i32 0, i64 24
  %146 = bitcast i32* %145 to <4 x i32>*
  store <4 x i32> %144, <4 x i32>* %146, align 16, !alias.scope !1438, !noalias !1434
  %147 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %9, i64 0, i32 0, i64 28
  %148 = bitcast i32* %147 to <4 x i32>*
  %149 = load <4 x i32>, <4 x i32>* %148, align 16, !noalias !1435
  %150 = icmp slt <4 x i32> %149, %83
  %151 = select <4 x i1> %150, <4 x i32> %83, <4 x i32> %149
  %152 = icmp slt <4 x i32> %85, %151
  %153 = select <4 x i1> %152, <4 x i32> %85, <4 x i32> %151
  %154 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %10, i64 0, i32 0, i64 28
  %155 = bitcast i32* %154 to <4 x i32>*
  store <4 x i32> %153, <4 x i32>* %155, align 16, !alias.scope !1438, !noalias !1434
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %75) #19, !noalias !1434
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 4 %73, i8* nonnull align 16 %74, i64 128, i1 false) #19, !noalias !1431
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %74) #19, !noalias !1434
  %156 = bitcast [32 x i16]* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %156)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 2 %156, i8 -86, i64 64, i1 false), !alias.scope !1439, !noalias !1442
  %157 = bitcast %"struct.gemmlowp::RegisterBuffer.562"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %157) #19, !noalias !1445
  %158 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %158) #19, !noalias !1445
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %158, i8* nonnull align 4 %73, i64 128, i1 false) #19, !noalias !1431
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %157, i8 -86, i64 64, i1 false) #19, !alias.scope !1446, !noalias !1445
  %159 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %6 to <4 x i32>*
  %160 = load <4 x i32>, <4 x i32>* %159, align 16, !noalias !1449
  %161 = icmp sgt <4 x i32> %160, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %162 = select <4 x i1> %161, <4 x i32> %160, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %163 = icmp slt <4 x i32> %162, <i32 32767, i32 32767, i32 32767, i32 32767>
  %164 = select <4 x i1> %163, <4 x i32> %162, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %165 = trunc <4 x i32> %164 to <4 x i16>
  %166 = bitcast %"struct.gemmlowp::RegisterBuffer.562"* %7 to <4 x i16>*
  store <4 x i16> %165, <4 x i16>* %166, align 8, !alias.scope !1446, !noalias !1445
  %167 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 4
  %168 = bitcast i32* %167 to <4 x i32>*
  %169 = load <4 x i32>, <4 x i32>* %168, align 16, !noalias !1449
  %170 = icmp sgt <4 x i32> %169, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %171 = select <4 x i1> %170, <4 x i32> %169, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %172 = icmp slt <4 x i32> %171, <i32 32767, i32 32767, i32 32767, i32 32767>
  %173 = select <4 x i1> %172, <4 x i32> %171, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %174 = trunc <4 x i32> %173 to <4 x i16>
  %175 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.562", %"struct.gemmlowp::RegisterBuffer.562"* %7, i64 0, i32 0, i64 4
  %176 = bitcast i16* %175 to <4 x i16>*
  store <4 x i16> %174, <4 x i16>* %176, align 8, !alias.scope !1446, !noalias !1445
  %177 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 8
  %178 = bitcast i32* %177 to <4 x i32>*
  %179 = load <4 x i32>, <4 x i32>* %178, align 16, !noalias !1449
  %180 = icmp sgt <4 x i32> %179, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %181 = select <4 x i1> %180, <4 x i32> %179, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %182 = icmp slt <4 x i32> %181, <i32 32767, i32 32767, i32 32767, i32 32767>
  %183 = select <4 x i1> %182, <4 x i32> %181, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %184 = trunc <4 x i32> %183 to <4 x i16>
  %185 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.562", %"struct.gemmlowp::RegisterBuffer.562"* %7, i64 0, i32 0, i64 8
  %186 = bitcast i16* %185 to <4 x i16>*
  store <4 x i16> %184, <4 x i16>* %186, align 8, !alias.scope !1446, !noalias !1445
  %187 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 12
  %188 = bitcast i32* %187 to <4 x i32>*
  %189 = load <4 x i32>, <4 x i32>* %188, align 16, !noalias !1449
  %190 = icmp sgt <4 x i32> %189, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %191 = select <4 x i1> %190, <4 x i32> %189, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %192 = icmp slt <4 x i32> %191, <i32 32767, i32 32767, i32 32767, i32 32767>
  %193 = select <4 x i1> %192, <4 x i32> %191, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %194 = trunc <4 x i32> %193 to <4 x i16>
  %195 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.562", %"struct.gemmlowp::RegisterBuffer.562"* %7, i64 0, i32 0, i64 12
  %196 = bitcast i16* %195 to <4 x i16>*
  store <4 x i16> %194, <4 x i16>* %196, align 8, !alias.scope !1446, !noalias !1445
  %197 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 16
  %198 = bitcast i32* %197 to <4 x i32>*
  %199 = load <4 x i32>, <4 x i32>* %198, align 16, !noalias !1449
  %200 = icmp sgt <4 x i32> %199, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %201 = select <4 x i1> %200, <4 x i32> %199, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %202 = icmp slt <4 x i32> %201, <i32 32767, i32 32767, i32 32767, i32 32767>
  %203 = select <4 x i1> %202, <4 x i32> %201, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %204 = trunc <4 x i32> %203 to <4 x i16>
  %205 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.562", %"struct.gemmlowp::RegisterBuffer.562"* %7, i64 0, i32 0, i64 16
  %206 = bitcast i16* %205 to <4 x i16>*
  store <4 x i16> %204, <4 x i16>* %206, align 8, !alias.scope !1446, !noalias !1445
  %207 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 20
  %208 = bitcast i32* %207 to <4 x i32>*
  %209 = load <4 x i32>, <4 x i32>* %208, align 16, !noalias !1449
  %210 = icmp sgt <4 x i32> %209, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %211 = select <4 x i1> %210, <4 x i32> %209, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %212 = icmp slt <4 x i32> %211, <i32 32767, i32 32767, i32 32767, i32 32767>
  %213 = select <4 x i1> %212, <4 x i32> %211, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %214 = trunc <4 x i32> %213 to <4 x i16>
  %215 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.562", %"struct.gemmlowp::RegisterBuffer.562"* %7, i64 0, i32 0, i64 20
  %216 = bitcast i16* %215 to <4 x i16>*
  store <4 x i16> %214, <4 x i16>* %216, align 8, !alias.scope !1446, !noalias !1445
  %217 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 24
  %218 = bitcast i32* %217 to <4 x i32>*
  %219 = load <4 x i32>, <4 x i32>* %218, align 16, !noalias !1449
  %220 = icmp sgt <4 x i32> %219, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %221 = select <4 x i1> %220, <4 x i32> %219, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %222 = icmp slt <4 x i32> %221, <i32 32767, i32 32767, i32 32767, i32 32767>
  %223 = select <4 x i1> %222, <4 x i32> %221, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %224 = trunc <4 x i32> %223 to <4 x i16>
  %225 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.562", %"struct.gemmlowp::RegisterBuffer.562"* %7, i64 0, i32 0, i64 24
  %226 = bitcast i16* %225 to <4 x i16>*
  store <4 x i16> %224, <4 x i16>* %226, align 8, !alias.scope !1446, !noalias !1445
  %227 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 28
  %228 = bitcast i32* %227 to <4 x i32>*
  %229 = load <4 x i32>, <4 x i32>* %228, align 16, !noalias !1449
  %230 = icmp sgt <4 x i32> %229, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %231 = select <4 x i1> %230, <4 x i32> %229, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %232 = icmp slt <4 x i32> %231, <i32 32767, i32 32767, i32 32767, i32 32767>
  %233 = select <4 x i1> %232, <4 x i32> %231, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %234 = trunc <4 x i32> %233 to <4 x i16>
  %235 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.562", %"struct.gemmlowp::RegisterBuffer.562"* %7, i64 0, i32 0, i64 28
  %236 = bitcast i16* %235 to <4 x i16>*
  store <4 x i16> %234, <4 x i16>* %236, align 8, !alias.scope !1446, !noalias !1445
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %158) #19, !noalias !1445
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 2 %156, i8* nonnull align 8 %157, i64 64, i1 false) #19, !noalias !1442
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %157) #19, !noalias !1445
  %237 = bitcast %"struct.gemmlowp::RegisterBlock.561"* %0 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 2 %237, i8* nonnull align 2 %156, i64 64, i1 false) #19
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %156)
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %73)
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %15)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp20StoreFinalOutputImplINS_13RegisterBlockIsLi8ELi8EEENS_9MatrixMapIsLNS_8MapOrderE1EEEE3RunERKS2_PS5_ii(%"struct.gemmlowp::RegisterBlock.559"* dereferenceable(128), %"class.gemmlowp::MatrixMap.489"*, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %5 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %1, i64 0, i32 0
  %6 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %1, i64 0, i32 3
  %7 = sext i32 %3 to i64
  %8 = sext i32 %2 to i64
  %9 = add nsw i64 %7, 1
  %10 = add nsw i64 %7, 2
  %11 = add nsw i64 %7, 3
  %12 = add nsw i64 %7, 4
  %13 = add nsw i64 %7, 5
  %14 = add nsw i64 %7, 6
  %15 = add nsw i64 %7, 7
  br label %16

16:                                               ; preds = %16, %4
  %17 = phi i64 [ 0, %4 ], [ %90, %16 ]
  %18 = add nsw i64 %17, %8
  %19 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.559", %"struct.gemmlowp::RegisterBlock.559"* %0, i64 0, i32 0, i32 0, i64 %17
  %20 = load i16, i16* %19, align 2
  %21 = load i16*, i16** %5, align 8
  %22 = load i32, i32* %6, align 8
  %23 = sext i32 %22 to i64
  %24 = mul nsw i64 %18, %23
  %25 = getelementptr inbounds i16, i16* %21, i64 %7
  %26 = getelementptr inbounds i16, i16* %25, i64 %24
  store i16 %20, i16* %26, align 2
  %27 = add nuw nsw i64 %17, 8
  %28 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.559", %"struct.gemmlowp::RegisterBlock.559"* %0, i64 0, i32 0, i32 0, i64 %27
  %29 = load i16, i16* %28, align 2
  %30 = load i16*, i16** %5, align 8
  %31 = load i32, i32* %6, align 8
  %32 = sext i32 %31 to i64
  %33 = mul nsw i64 %18, %32
  %34 = getelementptr inbounds i16, i16* %30, i64 %9
  %35 = getelementptr inbounds i16, i16* %34, i64 %33
  store i16 %29, i16* %35, align 2
  %36 = add nuw nsw i64 %17, 16
  %37 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.559", %"struct.gemmlowp::RegisterBlock.559"* %0, i64 0, i32 0, i32 0, i64 %36
  %38 = load i16, i16* %37, align 2
  %39 = load i16*, i16** %5, align 8
  %40 = load i32, i32* %6, align 8
  %41 = sext i32 %40 to i64
  %42 = mul nsw i64 %18, %41
  %43 = getelementptr inbounds i16, i16* %39, i64 %10
  %44 = getelementptr inbounds i16, i16* %43, i64 %42
  store i16 %38, i16* %44, align 2
  %45 = add nuw nsw i64 %17, 24
  %46 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.559", %"struct.gemmlowp::RegisterBlock.559"* %0, i64 0, i32 0, i32 0, i64 %45
  %47 = load i16, i16* %46, align 2
  %48 = load i16*, i16** %5, align 8
  %49 = load i32, i32* %6, align 8
  %50 = sext i32 %49 to i64
  %51 = mul nsw i64 %18, %50
  %52 = getelementptr inbounds i16, i16* %48, i64 %11
  %53 = getelementptr inbounds i16, i16* %52, i64 %51
  store i16 %47, i16* %53, align 2
  %54 = add nuw nsw i64 %17, 32
  %55 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.559", %"struct.gemmlowp::RegisterBlock.559"* %0, i64 0, i32 0, i32 0, i64 %54
  %56 = load i16, i16* %55, align 2
  %57 = load i16*, i16** %5, align 8
  %58 = load i32, i32* %6, align 8
  %59 = sext i32 %58 to i64
  %60 = mul nsw i64 %18, %59
  %61 = getelementptr inbounds i16, i16* %57, i64 %12
  %62 = getelementptr inbounds i16, i16* %61, i64 %60
  store i16 %56, i16* %62, align 2
  %63 = add nuw nsw i64 %17, 40
  %64 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.559", %"struct.gemmlowp::RegisterBlock.559"* %0, i64 0, i32 0, i32 0, i64 %63
  %65 = load i16, i16* %64, align 2
  %66 = load i16*, i16** %5, align 8
  %67 = load i32, i32* %6, align 8
  %68 = sext i32 %67 to i64
  %69 = mul nsw i64 %18, %68
  %70 = getelementptr inbounds i16, i16* %66, i64 %13
  %71 = getelementptr inbounds i16, i16* %70, i64 %69
  store i16 %65, i16* %71, align 2
  %72 = add nuw nsw i64 %17, 48
  %73 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.559", %"struct.gemmlowp::RegisterBlock.559"* %0, i64 0, i32 0, i32 0, i64 %72
  %74 = load i16, i16* %73, align 2
  %75 = load i16*, i16** %5, align 8
  %76 = load i32, i32* %6, align 8
  %77 = sext i32 %76 to i64
  %78 = mul nsw i64 %18, %77
  %79 = getelementptr inbounds i16, i16* %75, i64 %14
  %80 = getelementptr inbounds i16, i16* %79, i64 %78
  store i16 %74, i16* %80, align 2
  %81 = add nuw nsw i64 %17, 56
  %82 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.559", %"struct.gemmlowp::RegisterBlock.559"* %0, i64 0, i32 0, i32 0, i64 %81
  %83 = load i16, i16* %82, align 2
  %84 = load i16*, i16** %5, align 8
  %85 = load i32, i32* %6, align 8
  %86 = sext i32 %85 to i64
  %87 = mul nsw i64 %18, %86
  %88 = getelementptr inbounds i16, i16* %84, i64 %15
  %89 = getelementptr inbounds i16, i16* %88, i64 %87
  store i16 %83, i16* %89, align 2
  %90 = add nuw nsw i64 %17, 1
  %91 = icmp eq i64 %90, 8
  br i1 %91, label %92, label %16

92:                                               ; preds = %16
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.563"* noalias sret, %"struct.gemmlowp::OutputPipelineEvalImpl.538"*, %"struct.gemmlowp::RegisterBlock.312"* byval(%"struct.gemmlowp::RegisterBlock.312") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %6 = alloca %"struct.gemmlowp::RegisterBuffer.313", align 16
  %7 = alloca %"struct.gemmlowp::RegisterBuffer.313", align 8
  %8 = alloca [16 x i32], align 8
  %9 = bitcast %"struct.gemmlowp::RegisterBlock.312"* %2 to <4 x i32>*
  %10 = load <4 x i32>, <4 x i32>* %9, align 8
  %11 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 4
  %12 = bitcast i32* %11 to <4 x i32>*
  %13 = load <4 x i32>, <4 x i32>* %12, align 8
  %14 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 8
  %15 = bitcast i32* %14 to <4 x i32>*
  %16 = load <4 x i32>, <4 x i32>* %15, align 8
  %17 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 12
  %18 = bitcast i32* %17 to <4 x i32>*
  %19 = load <4 x i32>, <4 x i32>* %18, align 8
  %20 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.538", %"struct.gemmlowp::OutputPipelineEvalImpl.538"* %1, i64 0, i32 0, i32 0
  %21 = load %"struct.gemmlowp::OutputStageBiasAddition.200"*, %"struct.gemmlowp::OutputStageBiasAddition.200"** %20, align 8, !noalias !1450
  %22 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition.200", %"struct.gemmlowp::OutputStageBiasAddition.200"* %21, i64 0, i32 0, i32 0
  %23 = load i32*, i32** %22, align 8, !noalias !1450
  %24 = sext i32 %4 to i64
  %25 = getelementptr i32, i32* %23, i64 %24
  %26 = bitcast i32* %25 to i64*
  %27 = load i64, i64* %26, align 4, !noalias !1450
  %28 = getelementptr inbounds i32, i32* %25, i64 2
  %29 = bitcast i32* %28 to i64*
  %30 = load i64, i64* %29, align 4, !noalias !1450
  %31 = trunc i64 %27 to i32
  %32 = lshr i64 %27, 32
  %33 = trunc i64 %32 to i32
  %34 = insertelement <4 x i32> undef, i32 %31, i32 0
  %35 = shufflevector <4 x i32> %34, <4 x i32> undef, <4 x i32> zeroinitializer
  %36 = add nsw <4 x i32> %10, %35
  %37 = insertelement <4 x i32> undef, i32 %33, i32 0
  %38 = shufflevector <4 x i32> %37, <4 x i32> undef, <4 x i32> zeroinitializer
  %39 = add nsw <4 x i32> %13, %38
  %40 = trunc i64 %30 to i32
  %41 = insertelement <4 x i32> undef, i32 %40, i32 0
  %42 = shufflevector <4 x i32> %41, <4 x i32> undef, <4 x i32> zeroinitializer
  %43 = add nsw <4 x i32> %16, %42
  %44 = lshr i64 %30, 32
  %45 = trunc i64 %44 to i32
  %46 = insertelement <4 x i32> undef, i32 %45, i32 0
  %47 = shufflevector <4 x i32> %46, <4 x i32> undef, <4 x i32> zeroinitializer
  %48 = add nsw <4 x i32> %19, %47
  %49 = bitcast [16 x i32]* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %49) #19, !noalias !1453
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %49, i8 -86, i64 64, i1 false) #19, !alias.scope !1456, !noalias !1453
  %50 = bitcast %"struct.gemmlowp::RegisterBuffer.313"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %50) #19, !noalias !1459
  %51 = bitcast %"struct.gemmlowp::RegisterBuffer.313"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %51) #19, !noalias !1459
  %52 = bitcast %"struct.gemmlowp::RegisterBuffer.313"* %6 to <4 x i32>*
  store <4 x i32> %36, <4 x i32>* %52, align 16, !noalias !1453
  %53 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %6, i64 0, i32 0, i64 4
  %54 = bitcast i32* %53 to <4 x i32>*
  store <4 x i32> %39, <4 x i32>* %54, align 16, !noalias !1453
  %55 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %6, i64 0, i32 0, i64 8
  %56 = bitcast i32* %55 to <4 x i32>*
  store <4 x i32> %43, <4 x i32>* %56, align 16, !noalias !1453
  %57 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %6, i64 0, i32 0, i64 12
  %58 = bitcast i32* %57 to <4 x i32>*
  store <4 x i32> %48, <4 x i32>* %58, align 16, !noalias !1453
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %50, i8 -86, i64 64, i1 false) #19, !alias.scope !1460, !noalias !1459
  %59 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.538", %"struct.gemmlowp::OutputPipelineEvalImpl.538"* %1, i64 0, i32 1, i32 0, i32 0, i32 0
  %60 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %59, align 8, !noalias !1463
  %61 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %60, i64 0, i32 2
  %62 = load i32, i32* %61, align 4, !noalias !1463
  %63 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.538", %"struct.gemmlowp::OutputPipelineEvalImpl.538"* %1, i64 0, i32 1, i32 0, i32 0, i32 1
  %64 = load i32, i32* %63, align 8, !noalias !1463
  %65 = shl i32 1, %64
  %66 = sext i32 %65 to i64
  %67 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %60, i64 0, i32 0
  %68 = load i32, i32* %67, align 4, !noalias !1463
  %69 = sext i32 %68 to i64
  %70 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.538", %"struct.gemmlowp::OutputPipelineEvalImpl.538"* %1, i64 0, i32 1, i32 0, i32 0, i32 2
  %71 = load i32, i32* %70, align 4, !noalias !1463
  %72 = zext i32 %71 to i64
  %73 = shl nsw i64 -1, %72
  %74 = trunc i64 %73 to i32
  %75 = xor i32 %74, -1
  %76 = ashr i32 %75, 1
  %77 = icmp ne i32 %68, -2147483648
  %78 = extractelement <4 x i32> %36, i32 0
  br label %79

79:                                               ; preds = %112, %5
  %80 = phi i32 [ %78, %5 ], [ %114, %112 ]
  %81 = phi i64 [ 0, %5 ], [ %110, %112 ]
  %82 = sext i32 %80 to i64
  %83 = mul nsw i64 %82, %66
  %84 = icmp slt i64 %83, 2147483647
  %85 = select i1 %84, i64 %83, i64 2147483647
  %86 = icmp sgt i64 %85, -2147483648
  %87 = select i1 %86, i64 %85, i64 -2147483648
  %88 = trunc i64 %87 to i32
  %89 = icmp ne i32 %68, %88
  %90 = or i1 %77, %89
  br i1 %90, label %91, label %99

91:                                               ; preds = %79
  %92 = select i1 %89, i64 %69, i64 %87
  %93 = mul nsw i64 %92, %87
  %94 = icmp sgt i64 %93, -1
  %95 = select i1 %94, i64 1073741824, i64 -1073741823
  %96 = add nsw i64 %95, %93
  %97 = sdiv i64 %96, 2147483648
  %98 = trunc i64 %97 to i32
  br label %99

99:                                               ; preds = %91, %79
  %100 = phi i32 [ %98, %91 ], [ 2147483647, %79 ]
  %101 = and i32 %100, %75
  %102 = lshr i32 %100, 31
  %103 = add nsw i32 %102, %76
  %104 = ashr i32 %100, %71
  %105 = icmp sgt i32 %101, %103
  %106 = zext i1 %105 to i32
  %107 = add i32 %104, %62
  %108 = add i32 %107, %106
  %109 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %7, i64 0, i32 0, i64 %81
  store i32 %108, i32* %109, align 4, !alias.scope !1460, !noalias !1459
  %110 = add nuw nsw i64 %81, 1
  %111 = icmp eq i64 %110, 16
  br i1 %111, label %115, label %112

112:                                              ; preds = %99
  %113 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %6, i64 0, i32 0, i64 %110
  %114 = load i32, i32* %113, align 4, !noalias !1463
  br label %79

115:                                              ; preds = %99
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %51) #19, !noalias !1459
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %49, i8* nonnull align 8 %50, i64 64, i1 false) #19, !noalias !1453
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %50) #19, !noalias !1459
  %116 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.538", %"struct.gemmlowp::OutputPipelineEvalImpl.538"* %1, i64 0, i32 1, i32 1
  %117 = bitcast [16 x i32]* %8 to %"struct.gemmlowp::RegisterBlock.312"*
  tail call void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.563"* sret %0, %"struct.gemmlowp::OutputPipelineEvalImpl.540"* %116, %"struct.gemmlowp::RegisterBlock.312"* nonnull byval(%"struct.gemmlowp::RegisterBlock.312") align 8 %117, i32 %3, i32 %4) #19
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %49) #19, !noalias !1453
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.563"* noalias sret, %"struct.gemmlowp::OutputPipelineEvalImpl.540"*, %"struct.gemmlowp::RegisterBlock.312"* byval(%"struct.gemmlowp::RegisterBlock.312") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %6 = bitcast %"struct.gemmlowp::RegisterBlock.312"* %2 to <8 x i32>*
  %7 = load <8 x i32>, <8 x i32>* %6, align 8
  %8 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 8
  %9 = load i32, i32* %8, align 8
  %10 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 9
  %11 = load i32, i32* %10, align 4
  %12 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 10
  %13 = load i32, i32* %12, align 8
  %14 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 11
  %15 = load i32, i32* %14, align 4
  %16 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 12
  %17 = load i32, i32* %16, align 8
  %18 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 13
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 14
  %21 = load i32, i32* %20, align 8
  %22 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 15
  %23 = load i32, i32* %22, align 4
  %24 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.540", %"struct.gemmlowp::OutputPipelineEvalImpl.540"* %1, i64 0, i32 0, i32 0, i32 0
  %25 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %24, align 8, !noalias !1464
  %26 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %25, i64 0, i32 0
  %27 = load i32, i32* %26, align 4, !noalias !1464
  %28 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %25, i64 0, i32 1
  %29 = load i32, i32* %28, align 4, !noalias !1464
  %30 = insertelement <8 x i32> undef, i32 %27, i32 0
  %31 = shufflevector <8 x i32> %30, <8 x i32> undef, <8 x i32> zeroinitializer
  %32 = icmp slt <8 x i32> %7, %31
  %33 = select <8 x i1> %32, <8 x i32> %31, <8 x i32> %7
  %34 = insertelement <8 x i32> undef, i32 %29, i32 0
  %35 = shufflevector <8 x i32> %34, <8 x i32> undef, <8 x i32> zeroinitializer
  %36 = icmp slt <8 x i32> %35, %33
  %37 = select <8 x i1> %36, <8 x i32> %35, <8 x i32> %33
  %38 = icmp slt i32 %9, %27
  %39 = select i1 %38, i32 %27, i32 %9
  %40 = icmp slt i32 %29, %39
  %41 = select i1 %40, i32 %29, i32 %39
  %42 = icmp slt i32 %11, %27
  %43 = select i1 %42, i32 %27, i32 %11
  %44 = icmp slt i32 %29, %43
  %45 = select i1 %44, i32 %29, i32 %43
  %46 = icmp slt i32 %13, %27
  %47 = select i1 %46, i32 %27, i32 %13
  %48 = icmp slt i32 %29, %47
  %49 = select i1 %48, i32 %29, i32 %47
  %50 = icmp slt i32 %15, %27
  %51 = select i1 %50, i32 %27, i32 %15
  %52 = icmp slt i32 %29, %51
  %53 = select i1 %52, i32 %29, i32 %51
  %54 = icmp slt i32 %17, %27
  %55 = select i1 %54, i32 %27, i32 %17
  %56 = icmp slt i32 %29, %55
  %57 = select i1 %56, i32 %29, i32 %55
  %58 = icmp slt i32 %19, %27
  %59 = select i1 %58, i32 %27, i32 %19
  %60 = icmp slt i32 %29, %59
  %61 = select i1 %60, i32 %29, i32 %59
  %62 = icmp slt i32 %21, %27
  %63 = select i1 %62, i32 %27, i32 %21
  %64 = icmp slt i32 %29, %63
  %65 = select i1 %64, i32 %29, i32 %63
  %66 = icmp slt i32 %23, %27
  %67 = select i1 %66, i32 %27, i32 %23
  %68 = icmp slt i32 %29, %67
  %69 = select i1 %68, i32 %29, i32 %67
  %70 = icmp sgt <8 x i32> %37, <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %71 = select <8 x i1> %70, <8 x i32> %37, <8 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %72 = icmp slt <8 x i32> %71, <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>
  %73 = select <8 x i1> %72, <8 x i32> %71, <8 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>
  %74 = trunc <8 x i32> %73 to <8 x i16>
  %75 = icmp sgt i32 %41, -32768
  %76 = select i1 %75, i32 %41, i32 -32768
  %77 = icmp slt i32 %76, 32767
  %78 = select i1 %77, i32 %76, i32 32767
  %79 = trunc i32 %78 to i16
  %80 = icmp sgt i32 %45, -32768
  %81 = select i1 %80, i32 %45, i32 -32768
  %82 = icmp slt i32 %81, 32767
  %83 = select i1 %82, i32 %81, i32 32767
  %84 = trunc i32 %83 to i16
  %85 = icmp sgt i32 %49, -32768
  %86 = select i1 %85, i32 %49, i32 -32768
  %87 = icmp slt i32 %86, 32767
  %88 = select i1 %87, i32 %86, i32 32767
  %89 = trunc i32 %88 to i16
  %90 = icmp sgt i32 %53, -32768
  %91 = select i1 %90, i32 %53, i32 -32768
  %92 = icmp slt i32 %91, 32767
  %93 = select i1 %92, i32 %91, i32 32767
  %94 = trunc i32 %93 to i16
  %95 = icmp sgt i32 %57, -32768
  %96 = select i1 %95, i32 %57, i32 -32768
  %97 = icmp slt i32 %96, 32767
  %98 = select i1 %97, i32 %96, i32 32767
  %99 = icmp sgt i32 %61, -32768
  %100 = select i1 %99, i32 %61, i32 -32768
  %101 = icmp slt i32 %100, 32767
  %102 = select i1 %101, i32 %100, i32 32767
  %103 = shl nsw i32 %102, 16
  %104 = and i32 %98, 65535
  %105 = or i32 %103, %104
  %106 = zext i32 %105 to i64
  %107 = icmp sgt i32 %65, -32768
  %108 = select i1 %107, i32 %65, i32 -32768
  %109 = icmp slt i32 %108, 32767
  %110 = select i1 %109, i32 %108, i32 32767
  %111 = and i32 %110, 65535
  %112 = zext i32 %111 to i64
  %113 = shl nuw nsw i64 %112, 32
  %114 = icmp sgt i32 %69, -32768
  %115 = select i1 %114, i32 %69, i32 -32768
  %116 = icmp slt i32 %115, 32767
  %117 = select i1 %116, i32 %115, i32 32767
  %118 = zext i32 %117 to i64
  %119 = shl i64 %118, 48
  %120 = or i64 %119, %106
  %121 = or i64 %120, %113
  %122 = bitcast %"struct.gemmlowp::RegisterBlock.563"* %0 to <8 x i16>*
  store <8 x i16> %74, <8 x i16>* %122, align 2, !alias.scope !1469
  %123 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %0, i64 0, i32 0, i32 0, i64 8
  store i16 %79, i16* %123, align 2, !alias.scope !1469
  %124 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %0, i64 0, i32 0, i32 0, i64 9
  store i16 %84, i16* %124, align 2, !alias.scope !1469
  %125 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %0, i64 0, i32 0, i32 0, i64 10
  store i16 %89, i16* %125, align 2, !alias.scope !1469
  %126 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %0, i64 0, i32 0, i32 0, i64 11
  store i16 %94, i16* %126, align 2, !alias.scope !1469
  %127 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %0, i64 0, i32 0, i32 0, i64 12
  %128 = bitcast i16* %127 to i64*
  store i64 %121, i64* %128, align 2, !alias.scope !1469
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi8ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE1EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.548"*, %"struct.gemmlowp::RegisterBlock.302"* byval(%"struct.gemmlowp::RegisterBlock.302") align 8, %"class.gemmlowp::MatrixMap.489"*, i32, i32, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %8 = alloca %"struct.gemmlowp::RegisterBlock.561", align 8
  %9 = alloca %"struct.gemmlowp::RegisterBlock.302", align 16
  %10 = alloca %"struct.gemmlowp::RegisterBlock.561", align 2
  %11 = bitcast %"struct.gemmlowp::RegisterBlock.561"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %11) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 2 %11, i8 -86, i64 64, i1 false)
  %12 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %1 to <4 x i32>*
  %13 = load <4 x i32>, <4 x i32>* %12, align 8
  %14 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 4
  %15 = bitcast i32* %14 to <4 x i32>*
  %16 = load <4 x i32>, <4 x i32>* %15, align 8
  %17 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 8
  %18 = bitcast i32* %17 to <4 x i32>*
  %19 = load <4 x i32>, <4 x i32>* %18, align 8
  %20 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 12
  %21 = bitcast i32* %20 to <4 x i32>*
  %22 = load <4 x i32>, <4 x i32>* %21, align 8
  %23 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 16
  %24 = bitcast i32* %23 to <4 x i32>*
  %25 = load <4 x i32>, <4 x i32>* %24, align 8
  %26 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 20
  %27 = bitcast i32* %26 to <4 x i32>*
  %28 = load <4 x i32>, <4 x i32>* %27, align 8
  %29 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 24
  %30 = bitcast i32* %29 to <4 x i32>*
  %31 = load <4 x i32>, <4 x i32>* %30, align 8
  %32 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 28
  %33 = bitcast i32* %32 to <4 x i32>*
  %34 = load <4 x i32>, <4 x i32>* %33, align 8
  %35 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %35)
  %36 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.548", %"struct.gemmlowp::OutputPipelineExecutor.548"* %0, i64 0, i32 0, i32 0, i32 0
  %37 = load %"struct.gemmlowp::OutputStageBiasAddition.200"*, %"struct.gemmlowp::OutputStageBiasAddition.200"** %36, align 8, !noalias !1472
  %38 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition.200", %"struct.gemmlowp::OutputStageBiasAddition.200"* %37, i64 0, i32 0, i32 0
  %39 = load i32*, i32** %38, align 8, !noalias !1472
  %40 = sext i32 %4 to i64
  %41 = getelementptr i32, i32* %39, i64 %40
  %42 = bitcast i32* %41 to i64*
  %43 = load i64, i64* %42, align 4, !noalias !1472
  %44 = getelementptr inbounds i32, i32* %41, i64 2
  %45 = bitcast i32* %44 to i64*
  %46 = load i64, i64* %45, align 4, !noalias !1472
  %47 = trunc i64 %43 to i32
  %48 = lshr i64 %43, 32
  %49 = trunc i64 %48 to i32
  %50 = insertelement <4 x i32> undef, i32 %47, i32 0
  %51 = shufflevector <4 x i32> %50, <4 x i32> undef, <4 x i32> zeroinitializer
  %52 = add nsw <4 x i32> %13, %51
  %53 = add nsw <4 x i32> %16, %51
  %54 = insertelement <4 x i32> undef, i32 %49, i32 0
  %55 = shufflevector <4 x i32> %54, <4 x i32> undef, <4 x i32> zeroinitializer
  %56 = add nsw <4 x i32> %19, %55
  %57 = add nsw <4 x i32> %22, %55
  %58 = trunc i64 %46 to i32
  %59 = insertelement <4 x i32> undef, i32 %58, i32 0
  %60 = shufflevector <4 x i32> %59, <4 x i32> undef, <4 x i32> zeroinitializer
  %61 = add nsw <4 x i32> %25, %60
  %62 = add nsw <4 x i32> %28, %60
  %63 = lshr i64 %46, 32
  %64 = trunc i64 %63 to i32
  %65 = insertelement <4 x i32> undef, i32 %64, i32 0
  %66 = shufflevector <4 x i32> %65, <4 x i32> undef, <4 x i32> zeroinitializer
  %67 = add nsw <4 x i32> %31, %66
  %68 = add nsw <4 x i32> %34, %66
  %69 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.548", %"struct.gemmlowp::OutputPipelineExecutor.548"* %0, i64 0, i32 0, i32 1
  %70 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %9 to <4 x i32>*
  store <4 x i32> %52, <4 x i32>* %70, align 16, !noalias !1477
  %71 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %9, i64 0, i32 0, i32 0, i64 4
  %72 = bitcast i32* %71 to <4 x i32>*
  store <4 x i32> %53, <4 x i32>* %72, align 16, !noalias !1477
  %73 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %9, i64 0, i32 0, i32 0, i64 8
  %74 = bitcast i32* %73 to <4 x i32>*
  store <4 x i32> %56, <4 x i32>* %74, align 16, !noalias !1477
  %75 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %9, i64 0, i32 0, i32 0, i64 12
  %76 = bitcast i32* %75 to <4 x i32>*
  store <4 x i32> %57, <4 x i32>* %76, align 16, !noalias !1477
  %77 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %9, i64 0, i32 0, i32 0, i64 16
  %78 = bitcast i32* %77 to <4 x i32>*
  store <4 x i32> %61, <4 x i32>* %78, align 16, !noalias !1477
  %79 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %9, i64 0, i32 0, i32 0, i64 20
  %80 = bitcast i32* %79 to <4 x i32>*
  store <4 x i32> %62, <4 x i32>* %80, align 16, !noalias !1477
  %81 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %9, i64 0, i32 0, i32 0, i64 24
  %82 = bitcast i32* %81 to <4 x i32>*
  store <4 x i32> %67, <4 x i32>* %82, align 16, !noalias !1477
  %83 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %9, i64 0, i32 0, i32 0, i64 28
  %84 = bitcast i32* %83 to <4 x i32>*
  store <4 x i32> %68, <4 x i32>* %84, align 16, !noalias !1477
  call void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.561"* nonnull sret %10, %"struct.gemmlowp::OutputPipelineEvalImpl.550"* %69, %"struct.gemmlowp::RegisterBlock.302"* nonnull byval(%"struct.gemmlowp::RegisterBlock.302") align 8 %9, i32 %3, i32 %4) #19
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %35)
  %85 = bitcast %"struct.gemmlowp::RegisterBlock.561"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %85)
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %85, i8* nonnull align 2 %11, i64 64, i1 false)
  %86 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %2, i64 0, i32 0
  %87 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %2, i64 0, i32 3
  %88 = sext i32 %6 to i64
  %89 = sext i32 %5 to i64
  %90 = add nsw i64 %88, 1
  %91 = add nsw i64 %88, 2
  %92 = add nsw i64 %88, 3
  br label %93

93:                                               ; preds = %93, %7
  %94 = phi i64 [ 0, %7 ], [ %131, %93 ]
  %95 = add nsw i64 %94, %89
  %96 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.561", %"struct.gemmlowp::RegisterBlock.561"* %8, i64 0, i32 0, i32 0, i64 %94
  %97 = load i16, i16* %96, align 2
  %98 = load i16*, i16** %86, align 8
  %99 = load i32, i32* %87, align 8
  %100 = sext i32 %99 to i64
  %101 = mul nsw i64 %95, %100
  %102 = getelementptr inbounds i16, i16* %98, i64 %88
  %103 = getelementptr inbounds i16, i16* %102, i64 %101
  store i16 %97, i16* %103, align 2
  %104 = add nuw nsw i64 %94, 8
  %105 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.561", %"struct.gemmlowp::RegisterBlock.561"* %8, i64 0, i32 0, i32 0, i64 %104
  %106 = load i16, i16* %105, align 2
  %107 = load i16*, i16** %86, align 8
  %108 = load i32, i32* %87, align 8
  %109 = sext i32 %108 to i64
  %110 = mul nsw i64 %95, %109
  %111 = getelementptr inbounds i16, i16* %107, i64 %90
  %112 = getelementptr inbounds i16, i16* %111, i64 %110
  store i16 %106, i16* %112, align 2
  %113 = add nuw nsw i64 %94, 16
  %114 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.561", %"struct.gemmlowp::RegisterBlock.561"* %8, i64 0, i32 0, i32 0, i64 %113
  %115 = load i16, i16* %114, align 2
  %116 = load i16*, i16** %86, align 8
  %117 = load i32, i32* %87, align 8
  %118 = sext i32 %117 to i64
  %119 = mul nsw i64 %95, %118
  %120 = getelementptr inbounds i16, i16* %116, i64 %91
  %121 = getelementptr inbounds i16, i16* %120, i64 %119
  store i16 %115, i16* %121, align 2
  %122 = add nuw nsw i64 %94, 24
  %123 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.561", %"struct.gemmlowp::RegisterBlock.561"* %8, i64 0, i32 0, i32 0, i64 %122
  %124 = load i16, i16* %123, align 2
  %125 = load i16*, i16** %86, align 8
  %126 = load i32, i32* %87, align 8
  %127 = sext i32 %126 to i64
  %128 = mul nsw i64 %95, %127
  %129 = getelementptr inbounds i16, i16* %125, i64 %92
  %130 = getelementptr inbounds i16, i16* %129, i64 %128
  store i16 %124, i16* %130, align 2
  %131 = add nuw nsw i64 %94, 1
  %132 = icmp eq i64 %131, 8
  br i1 %132, label %133, label %93

133:                                              ; preds = %93
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %85)
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %11) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalESE_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.519"*, %"struct.gemmlowp::RegisterBlock.304"* byval(%"struct.gemmlowp::RegisterBlock.304") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %5 = alloca %"struct.gemmlowp::RegisterBuffer.305", align 8
  %6 = alloca %"struct.gemmlowp::RegisterBuffer.305", align 16
  %7 = alloca %"struct.gemmlowp::RegisterBlock.304", align 16
  %8 = bitcast %"struct.gemmlowp::RegisterBlock.304"* %1 to i8*
  %9 = bitcast %"struct.gemmlowp::RegisterBuffer.305"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %9) #19, !noalias !1478
  %10 = bitcast %"struct.gemmlowp::RegisterBuffer.305"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %10) #19, !noalias !1478
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %10, i8* nonnull align 8 %8, i64 32, i1 false)
  %11 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.519", %"struct.gemmlowp::OutputPipelineEvalImpl.519"* %0, i64 0, i32 0, i32 0, i32 0
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 32, i1 false) #19, !alias.scope !1481, !noalias !1478
  %12 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %11, align 8, !noalias !1484
  %13 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %12, i64 0, i32 2
  %14 = load i32, i32* %13, align 4, !noalias !1484
  %15 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.519", %"struct.gemmlowp::OutputPipelineEvalImpl.519"* %0, i64 0, i32 0, i32 0, i32 1
  %16 = load i32, i32* %15, align 8, !noalias !1484
  %17 = shl i32 1, %16
  %18 = sext i32 %17 to i64
  %19 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %12, i64 0, i32 0
  %20 = load i32, i32* %19, align 4, !noalias !1484
  %21 = sext i32 %20 to i64
  %22 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.519", %"struct.gemmlowp::OutputPipelineEvalImpl.519"* %0, i64 0, i32 0, i32 0, i32 2
  %23 = load i32, i32* %22, align 4, !noalias !1484
  %24 = zext i32 %23 to i64
  %25 = shl nsw i64 -1, %24
  %26 = trunc i64 %25 to i32
  %27 = xor i32 %26, -1
  %28 = ashr i32 %27, 1
  %29 = icmp ne i32 %20, -2147483648
  br label %30

30:                                               ; preds = %51, %4
  %31 = phi i64 [ 0, %4 ], [ %62, %51 ]
  %32 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.305", %"struct.gemmlowp::RegisterBuffer.305"* %5, i64 0, i32 0, i64 %31
  %33 = load i32, i32* %32, align 4, !noalias !1484
  %34 = sext i32 %33 to i64
  %35 = mul nsw i64 %34, %18
  %36 = icmp slt i64 %35, 2147483647
  %37 = select i1 %36, i64 %35, i64 2147483647
  %38 = icmp sgt i64 %37, -2147483648
  %39 = select i1 %38, i64 %37, i64 -2147483648
  %40 = trunc i64 %39 to i32
  %41 = icmp ne i32 %20, %40
  %42 = or i1 %29, %41
  br i1 %42, label %43, label %51

43:                                               ; preds = %30
  %44 = select i1 %41, i64 %21, i64 %39
  %45 = mul nsw i64 %44, %39
  %46 = icmp sgt i64 %45, -1
  %47 = select i1 %46, i64 1073741824, i64 -1073741823
  %48 = add nsw i64 %47, %45
  %49 = sdiv i64 %48, 2147483648
  %50 = trunc i64 %49 to i32
  br label %51

51:                                               ; preds = %43, %30
  %52 = phi i32 [ %50, %43 ], [ 2147483647, %30 ]
  %53 = and i32 %52, %27
  %54 = lshr i32 %52, 31
  %55 = add nsw i32 %54, %28
  %56 = ashr i32 %52, %23
  %57 = icmp sgt i32 %53, %55
  %58 = zext i1 %57 to i32
  %59 = add i32 %56, %14
  %60 = add i32 %59, %58
  %61 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.305", %"struct.gemmlowp::RegisterBuffer.305"* %6, i64 0, i32 0, i64 %31
  store i32 %60, i32* %61, align 4, !alias.scope !1481, !noalias !1478
  %62 = add nuw nsw i64 %31, 1
  %63 = icmp eq i64 %62, 8
  br i1 %63, label %64, label %30

64:                                               ; preds = %51
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %10) #19, !noalias !1478
  %65 = bitcast %"struct.gemmlowp::RegisterBuffer.305"* %6 to <4 x i32>*
  %66 = load <4 x i32>, <4 x i32>* %65, align 16
  %67 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.305", %"struct.gemmlowp::RegisterBuffer.305"* %6, i64 0, i32 0, i64 4
  %68 = bitcast i32* %67 to <4 x i32>*
  %69 = load <4 x i32>, <4 x i32>* %68, align 16
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %9) #19, !noalias !1478
  %70 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.519", %"struct.gemmlowp::OutputPipelineEvalImpl.519"* %0, i64 0, i32 1
  %71 = bitcast %"struct.gemmlowp::RegisterBlock.304"* %7 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %71, align 16
  %72 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %7, i64 0, i32 0, i32 0, i64 4
  %73 = bitcast i32* %72 to <4 x i32>*
  store <4 x i32> %69, <4 x i32>* %73, align 16
  %74 = tail call { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalESE_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.520"* %70, %"struct.gemmlowp::RegisterBlock.304"* nonnull byval(%"struct.gemmlowp::RegisterBlock.304") align 8 %7, i32 %2, i32 %3)
  ret { i64, i64 } %74
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalESE_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.520"*, %"struct.gemmlowp::RegisterBlock.304"* byval(%"struct.gemmlowp::RegisterBlock.304") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %5 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %1, i64 0, i32 0, i32 0, i64 0
  %6 = load i32, i32* %5, align 8
  %7 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %1, i64 0, i32 0, i32 0, i64 1
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %1, i64 0, i32 0, i32 0, i64 2
  %10 = load i32, i32* %9, align 8
  %11 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %1, i64 0, i32 0, i32 0, i64 3
  %12 = load i32, i32* %11, align 4
  %13 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %1, i64 0, i32 0, i32 0, i64 4
  %14 = load i32, i32* %13, align 8
  %15 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %1, i64 0, i32 0, i32 0, i64 5
  %16 = load i32, i32* %15, align 4
  %17 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %1, i64 0, i32 0, i32 0, i64 6
  %18 = load i32, i32* %17, align 8
  %19 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %1, i64 0, i32 0, i32 0, i64 7
  %20 = load i32, i32* %19, align 4
  %21 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.520", %"struct.gemmlowp::OutputPipelineEvalImpl.520"* %0, i64 0, i32 0, i32 0, i32 0
  %22 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %21, align 8, !noalias !1485
  %23 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %22, i64 0, i32 0
  %24 = load i32, i32* %23, align 4, !noalias !1485
  %25 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %22, i64 0, i32 1
  %26 = load i32, i32* %25, align 4, !noalias !1485
  %27 = icmp slt i32 %6, %24
  %28 = select i1 %27, i32 %24, i32 %6
  %29 = icmp slt i32 %26, %28
  %30 = select i1 %29, i32 %26, i32 %28
  %31 = icmp slt i32 %8, %24
  %32 = select i1 %31, i32 %24, i32 %8
  %33 = icmp slt i32 %26, %32
  %34 = select i1 %33, i32 %26, i32 %32
  %35 = icmp slt i32 %10, %24
  %36 = select i1 %35, i32 %24, i32 %10
  %37 = icmp slt i32 %26, %36
  %38 = select i1 %37, i32 %26, i32 %36
  %39 = icmp slt i32 %12, %24
  %40 = select i1 %39, i32 %24, i32 %12
  %41 = icmp slt i32 %26, %40
  %42 = select i1 %41, i32 %26, i32 %40
  %43 = icmp slt i32 %14, %24
  %44 = select i1 %43, i32 %24, i32 %14
  %45 = icmp slt i32 %26, %44
  %46 = select i1 %45, i32 %26, i32 %44
  %47 = icmp slt i32 %16, %24
  %48 = select i1 %47, i32 %24, i32 %16
  %49 = icmp slt i32 %26, %48
  %50 = select i1 %49, i32 %26, i32 %48
  %51 = icmp slt i32 %18, %24
  %52 = select i1 %51, i32 %24, i32 %18
  %53 = icmp slt i32 %26, %52
  %54 = select i1 %53, i32 %26, i32 %52
  %55 = icmp slt i32 %20, %24
  %56 = select i1 %55, i32 %24, i32 %20
  %57 = icmp slt i32 %26, %56
  %58 = select i1 %57, i32 %26, i32 %56
  %59 = icmp sgt i32 %30, -32768
  %60 = select i1 %59, i32 %30, i32 -32768
  %61 = icmp slt i32 %60, 32767
  %62 = select i1 %61, i32 %60, i32 32767
  %63 = icmp sgt i32 %34, -32768
  %64 = select i1 %63, i32 %34, i32 -32768
  %65 = icmp slt i32 %64, 32767
  %66 = select i1 %65, i32 %64, i32 32767
  %67 = icmp sgt i32 %38, -32768
  %68 = select i1 %67, i32 %38, i32 -32768
  %69 = icmp slt i32 %68, 32767
  %70 = select i1 %69, i32 %68, i32 32767
  %71 = icmp sgt i32 %42, -32768
  %72 = select i1 %71, i32 %42, i32 -32768
  %73 = icmp slt i32 %72, 32767
  %74 = select i1 %73, i32 %72, i32 32767
  %75 = icmp sgt i32 %46, -32768
  %76 = select i1 %75, i32 %46, i32 -32768
  %77 = icmp slt i32 %76, 32767
  %78 = select i1 %77, i32 %76, i32 32767
  %79 = icmp sgt i32 %50, -32768
  %80 = select i1 %79, i32 %50, i32 -32768
  %81 = icmp slt i32 %80, 32767
  %82 = select i1 %81, i32 %80, i32 32767
  %83 = shl nsw i32 %82, 16
  %84 = and i32 %78, 65535
  %85 = or i32 %83, %84
  %86 = zext i32 %85 to i64
  %87 = icmp sgt i32 %54, -32768
  %88 = select i1 %87, i32 %54, i32 -32768
  %89 = icmp slt i32 %88, 32767
  %90 = select i1 %89, i32 %88, i32 32767
  %91 = and i32 %90, 65535
  %92 = zext i32 %91 to i64
  %93 = shl nuw nsw i64 %92, 32
  %94 = icmp sgt i32 %58, -32768
  %95 = select i1 %94, i32 %58, i32 -32768
  %96 = icmp slt i32 %95, 32767
  %97 = select i1 %96, i32 %95, i32 32767
  %98 = zext i32 %97 to i64
  %99 = shl i64 %98, 48
  %100 = or i64 %99, %86
  %101 = or i64 %100, %93
  %102 = zext i32 %74 to i64
  %103 = shl i64 %102, 48
  %104 = and i32 %70, 65535
  %105 = zext i32 %104 to i64
  %106 = shl nuw nsw i64 %105, 32
  %107 = shl nsw i32 %66, 16
  %108 = and i32 %62, 65535
  %109 = or i32 %107, %108
  %110 = zext i32 %109 to i64
  %111 = or i64 %103, %110
  %112 = or i64 %111, %106
  %113 = insertvalue { i64, i64 } undef, i64 %112, 0
  %114 = insertvalue { i64, i64 } %113, i64 %101, 1
  ret { i64, i64 } %114
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi4ELi1EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE1EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.506"*, i64, i64, %"class.gemmlowp::MatrixMap.489"*, i32, i32, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %9 = trunc i64 %1 to i32
  %10 = lshr i64 %1, 32
  %11 = trunc i64 %10 to i32
  %12 = trunc i64 %2 to i32
  %13 = lshr i64 %2, 32
  %14 = trunc i64 %13 to i32
  %15 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.506", %"struct.gemmlowp::OutputPipelineExecutor.506"* %0, i64 0, i32 0, i32 0, i32 0
  %16 = load %"struct.gemmlowp::OutputStageBiasAddition.200"*, %"struct.gemmlowp::OutputStageBiasAddition.200"** %15, align 8
  %17 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition.200", %"struct.gemmlowp::OutputStageBiasAddition.200"* %16, i64 0, i32 0, i32 0
  %18 = load i32*, i32** %17, align 8
  %19 = sext i32 %5 to i64
  %20 = getelementptr inbounds i32, i32* %18, i64 %19
  %21 = load i32, i32* %20, align 4
  %22 = add nsw i32 %21, %9
  %23 = add nsw i32 %21, %11
  %24 = add nsw i32 %21, %12
  %25 = zext i32 %24 to i64
  %26 = add nsw i32 %21, %14
  %27 = zext i32 %26 to i64
  %28 = shl nuw i64 %27, 32
  %29 = or i64 %28, %25
  %30 = zext i32 %23 to i64
  %31 = shl nuw i64 %30, 32
  %32 = zext i32 %22 to i64
  %33 = or i64 %31, %32
  %34 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.506", %"struct.gemmlowp::OutputPipelineExecutor.506"* %0, i64 0, i32 0, i32 1, i32 0, i32 0
  %35 = tail call { i64, i64 } @_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi4EEEE4EvalES3_(%"struct.gemmlowp::OutputStageEvalBufferImpl.231"* %34, i64 %33, i64 %29) #19
  %36 = extractvalue { i64, i64 } %35, 0
  %37 = extractvalue { i64, i64 } %35, 1
  %38 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.506", %"struct.gemmlowp::OutputPipelineExecutor.506"* %0, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %39 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %38, align 8
  %40 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %39, i64 0, i32 0
  %41 = load i32, i32* %40, align 4
  %42 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %39, i64 0, i32 1
  %43 = load i32, i32* %42, align 4
  %44 = trunc i64 %36 to i32
  %45 = icmp sgt i32 %41, %44
  %46 = select i1 %45, i32 %41, i32 %44
  %47 = icmp slt i32 %43, %46
  %48 = select i1 %47, i32 %43, i32 %46
  %49 = lshr i64 %36, 32
  %50 = trunc i64 %49 to i32
  %51 = icmp sgt i32 %41, %50
  %52 = select i1 %51, i32 %41, i32 %50
  %53 = icmp slt i32 %43, %52
  %54 = select i1 %53, i32 %43, i32 %52
  %55 = trunc i64 %37 to i32
  %56 = icmp sgt i32 %41, %55
  %57 = select i1 %56, i32 %41, i32 %55
  %58 = icmp slt i32 %43, %57
  %59 = select i1 %58, i32 %43, i32 %57
  %60 = lshr i64 %37, 32
  %61 = trunc i64 %60 to i32
  %62 = icmp sgt i32 %41, %61
  %63 = select i1 %62, i32 %41, i32 %61
  %64 = icmp slt i32 %43, %63
  %65 = select i1 %64, i32 %43, i32 %63
  %66 = icmp sgt i32 %48, -32768
  %67 = select i1 %66, i32 %48, i32 -32768
  %68 = icmp slt i32 %67, 32767
  %69 = select i1 %68, i32 %67, i32 32767
  %70 = icmp sgt i32 %54, -32768
  %71 = select i1 %70, i32 %54, i32 -32768
  %72 = icmp slt i32 %71, 32767
  %73 = select i1 %72, i32 %71, i32 32767
  %74 = icmp sgt i32 %59, -32768
  %75 = select i1 %74, i32 %59, i32 -32768
  %76 = icmp slt i32 %75, 32767
  %77 = select i1 %76, i32 %75, i32 32767
  %78 = icmp sgt i32 %65, -32768
  %79 = select i1 %78, i32 %65, i32 -32768
  %80 = icmp slt i32 %79, 32767
  %81 = select i1 %80, i32 %79, i32 32767
  %82 = trunc i32 %69 to i16
  %83 = trunc i32 %73 to i16
  %84 = trunc i32 %77 to i16
  %85 = trunc i32 %81 to i16
  %86 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %3, i64 0, i32 0
  %87 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %3, i64 0, i32 3
  %88 = sext i32 %6 to i64
  %89 = load i16*, i16** %86, align 8
  %90 = load i32, i32* %87, align 8
  %91 = sext i32 %90 to i64
  %92 = mul nsw i64 %91, %88
  %93 = getelementptr inbounds i16, i16* %89, i64 %92
  %94 = sext i32 %7 to i64
  %95 = getelementptr inbounds i16, i16* %93, i64 %94
  store i16 %82, i16* %95, align 2
  %96 = add nsw i64 %88, 1
  %97 = load i16*, i16** %86, align 8
  %98 = load i32, i32* %87, align 8
  %99 = sext i32 %98 to i64
  %100 = mul nsw i64 %96, %99
  %101 = getelementptr inbounds i16, i16* %97, i64 %100
  %102 = getelementptr inbounds i16, i16* %101, i64 %94
  store i16 %83, i16* %102, align 2
  %103 = add nsw i64 %88, 2
  %104 = load i16*, i16** %86, align 8
  %105 = load i32, i32* %87, align 8
  %106 = sext i32 %105 to i64
  %107 = mul nsw i64 %103, %106
  %108 = getelementptr inbounds i16, i16* %104, i64 %107
  %109 = getelementptr inbounds i16, i16* %108, i64 %94
  store i16 %84, i16* %109, align 2
  %110 = add nsw i64 %88, 3
  %111 = load i16*, i16** %86, align 8
  %112 = load i32, i32* %87, align 8
  %113 = sext i32 %112 to i64
  %114 = mul nsw i64 %110, %113
  %115 = getelementptr inbounds i16, i16* %111, i64 %114
  %116 = getelementptr inbounds i16, i16* %115, i64 %94
  store i16 %85, i16* %116, align 2
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED2Ev(%"struct.gemmlowp::GemmWithPackedRhsTask.494"*) unnamed_addr #4 comdat align 2 {
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED0Ev(%"struct.gemmlowp::GemmWithPackedRhsTask.494"*) unnamed_addr #4 comdat align 2 {
  %2 = bitcast %"struct.gemmlowp::GemmWithPackedRhsTask.494"* %0 to i8*
  tail call void @_ZdlPv(i8* %2) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEE3RunEv(%"struct.gemmlowp::GemmWithPackedRhsTask.494"*) unnamed_addr #1 comdat align 2 {
  %2 = alloca %"class.gemmlowp::SideMap", align 8
  %3 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %4 = alloca %"class.gemmlowp::ComputeImpl", align 8
  %5 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %6 = alloca %"class.gemmlowp::PackedResult", align 8
  %7 = alloca %"struct.gemmlowp::MatrixBlockBounds", align 4
  %8 = alloca %"class.gemmlowp::VectorDup.194", align 4
  %9 = alloca %"class.gemmlowp::VectorDup", align 4
  %10 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.494", %"struct.gemmlowp::GemmWithPackedRhsTask.494"* %0, i64 0, i32 6, i32 2
  %11 = load i32, i32* %10, align 8
  %12 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.494", %"struct.gemmlowp::GemmWithPackedRhsTask.494"* %0, i64 0, i32 6, i32 3
  %13 = load i32, i32* %12, align 4
  %14 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.494", %"struct.gemmlowp::GemmWithPackedRhsTask.494"* %0, i64 0, i32 3, i32 2
  %15 = load i32, i32* %14, align 4
  %16 = bitcast %"class.gemmlowp::PackedSideBlock"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %16) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %16, i8 -86, i64 80, i1 false)
  %17 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.494", %"struct.gemmlowp::GemmWithPackedRhsTask.494"* %0, i64 0, i32 0, i32 1
  %18 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %19 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.494", %"struct.gemmlowp::GemmWithPackedRhsTask.494"* %0, i64 0, i32 9
  %20 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %21 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %18, %"class.gemmlowp::Allocator"** %21, align 8
  %22 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 4
  store i32 0, i32* %22, align 8
  %23 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 0
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 0
  store i32 %24, i32* %25, align 8
  %26 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 3
  %27 = load i32, i32* %26, align 4
  %28 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 2
  store i32 %27, i32* %28, align 8
  %29 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 2
  %30 = load i32, i32* %29, align 4
  %31 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 1
  store i32 %30, i32* %31, align 4
  %32 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 5
  %33 = load i32, i32* %32, align 4
  %34 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 3
  store i32 %33, i32* %34, align 4
  %35 = mul nsw i32 %33, %27
  %36 = sext i32 %35 to i64
  %37 = add nsw i64 %36, 63
  %38 = and i64 %37, -64
  %39 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 4
  %40 = load i64, i64* %39, align 8, !noalias !1490
  %41 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 3
  %42 = load i64, i64* %41, align 8, !noalias !1490
  %43 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 5, i64 %42
  store i64 %40, i64* %43, align 8, !noalias !1490
  %44 = trunc i64 %42 to i8
  %45 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 6
  %46 = load i64, i64* %45, align 8, !noalias !1490
  %47 = bitcast i64* %41 to <2 x i64>*
  %48 = load <2 x i64>, <2 x i64>* %47, align 8, !noalias !1490
  %49 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %38, i32 1
  %50 = add <2 x i64> %48, %49
  %51 = bitcast i64* %41 to <2 x i64>*
  store <2 x i64> %50, <2 x i64>* %51, align 8, !noalias !1490
  %52 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 0
  store i8 %44, i8* %52, align 8
  %53 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %53, i8 -86, i64 7, i1 false) #19
  %54 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 2
  store i64 %46, i64* %54, align 8
  %55 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 3
  store i8 0, i8* %55, align 8
  %56 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %21, align 8
  %57 = load i32, i32* %28, align 8
  %58 = sext i32 %57 to i64
  %59 = shl nsw i64 %58, 2
  %60 = add nsw i64 %59, 63
  %61 = and i64 %60, -64
  %62 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 4
  %63 = load i64, i64* %62, align 8, !noalias !1493
  %64 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 3
  %65 = load i64, i64* %64, align 8, !noalias !1493
  %66 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 5, i64 %65
  store i64 %63, i64* %66, align 8, !noalias !1493
  %67 = trunc i64 %65 to i8
  %68 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 6
  %69 = load i64, i64* %68, align 8, !noalias !1493
  %70 = bitcast i64* %64 to <2 x i64>*
  %71 = load <2 x i64>, <2 x i64>* %70, align 8, !noalias !1493
  %72 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %61, i32 1
  %73 = add <2 x i64> %71, %72
  %74 = bitcast i64* %64 to <2 x i64>*
  store <2 x i64> %73, <2 x i64>* %74, align 8, !noalias !1493
  %75 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 0
  store i8 %67, i8* %75, align 8
  %76 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %76, i8 -86, i64 7, i1 false) #19
  %77 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 2
  store i64 %69, i64* %77, align 8
  %78 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 3
  store i8 5, i8* %78, align 8
  %79 = bitcast %"class.gemmlowp::PackedResult"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %79) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %79, i8 -86, i64 32, i1 false)
  %80 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %81 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %82 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 0
  store %"class.gemmlowp::Allocator"* %80, %"class.gemmlowp::Allocator"** %82, align 8
  %83 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 2
  store %"struct.gemmlowp::BlockParams"* %81, %"struct.gemmlowp::BlockParams"** %83, align 8
  %84 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %81, i64 0, i32 3
  %85 = load i32, i32* %84, align 4
  %86 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %81, i64 0, i32 4
  %87 = load i32, i32* %86, align 4
  %88 = mul nsw i32 %87, %85
  %89 = sext i32 %88 to i64
  %90 = shl nsw i64 %89, 2
  %91 = add nsw i64 %90, 63
  %92 = and i64 %91, -64
  %93 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 4
  %94 = load i64, i64* %93, align 8, !noalias !1496
  %95 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 3
  %96 = load i64, i64* %95, align 8, !noalias !1496
  %97 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 5, i64 %96
  store i64 %94, i64* %97, align 8, !noalias !1496
  %98 = trunc i64 %96 to i8
  %99 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 6
  %100 = load i64, i64* %99, align 8, !noalias !1496
  %101 = bitcast i64* %95 to <2 x i64>*
  %102 = load <2 x i64>, <2 x i64>* %101, align 8, !noalias !1496
  %103 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %92, i32 1
  %104 = add <2 x i64> %102, %103
  %105 = bitcast i64* %95 to <2 x i64>*
  store <2 x i64> %104, <2 x i64>* %105, align 8, !noalias !1496
  %106 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 0
  store i8 %98, i8* %106, align 8
  %107 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %107, i8 -86, i64 7, i1 false) #19
  %108 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 2
  store i64 %100, i64* %108, align 8
  %109 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 3
  store i8 5, i8* %109, align 8
  %110 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  tail call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %110)
  %111 = icmp sgt i32 %13, 0
  br i1 %111, label %112, label %156

112:                                              ; preds = %1
  %113 = icmp sgt i32 %11, 0
  %114 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.494", %"struct.gemmlowp::GemmWithPackedRhsTask.494"* %0, i64 0, i32 3, i32 0
  %115 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.494", %"struct.gemmlowp::GemmWithPackedRhsTask.494"* %0, i64 0, i32 3, i32 3
  %116 = bitcast %"class.gemmlowp::SideMap"* %2 to i8*
  %117 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 1
  %118 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 2
  %119 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 3
  %120 = bitcast %"class.gemmlowp::SideMap"* %2 to i64*
  %121 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %3 to i8*
  %122 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %3, i64 0, i32 0
  %123 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %3, i64 0, i32 1
  %124 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.494", %"struct.gemmlowp::GemmWithPackedRhsTask.494"* %0, i64 0, i32 2
  %125 = bitcast %"struct.gemmlowp::KernelBase"** %124 to i64*
  %126 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.494", %"struct.gemmlowp::GemmWithPackedRhsTask.494"* %0, i64 0, i32 4
  %127 = bitcast %"class.gemmlowp::ComputeImpl"* %4 to i8*
  %128 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 1
  %129 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 2
  %130 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 3
  %131 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 4
  %132 = bitcast %"class.gemmlowp::ComputeImpl"* %4 to i64*
  %133 = add i32 %15, 15
  %134 = and i32 %133, -16
  %135 = icmp sgt i32 %134, 0
  %136 = bitcast %"struct.gemmlowp::MatrixBlockBounds"* %7 to i8*
  %137 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 0
  %138 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 1
  %139 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 2
  %140 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 3
  %141 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.494", %"struct.gemmlowp::GemmWithPackedRhsTask.494"* %0, i64 0, i32 6, i32 0
  %142 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.494", %"struct.gemmlowp::GemmWithPackedRhsTask.494"* %0, i64 0, i32 6, i32 1
  %143 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.494", %"struct.gemmlowp::GemmWithPackedRhsTask.494"* %0, i64 0, i32 5
  %144 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.494", %"struct.gemmlowp::GemmWithPackedRhsTask.494"* %0, i64 0, i32 4, i32 1
  %145 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.494", %"struct.gemmlowp::GemmWithPackedRhsTask.494"* %0, i64 0, i32 4, i32 3, i32 0
  %146 = bitcast %"class.gemmlowp::VectorDup.194"* %8 to i8*
  %147 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.494", %"struct.gemmlowp::GemmWithPackedRhsTask.494"* %0, i64 0, i32 7
  %148 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %8, i64 0, i32 0
  %149 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %8, i64 0, i32 1
  %150 = bitcast %"class.gemmlowp::VectorDup"* %9 to i8*
  %151 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.494", %"struct.gemmlowp::GemmWithPackedRhsTask.494"* %0, i64 0, i32 8
  %152 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %9, i64 0, i32 0
  %153 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %9, i64 0, i32 1
  %154 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.494", %"struct.gemmlowp::GemmWithPackedRhsTask.494"* %0, i64 0, i32 10
  %155 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  br label %164

156:                                              ; preds = %178, %1
  %157 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %158 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 0
  store i8 0, i8* %158, align 8
  %159 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 6
  %160 = load i64, i64* %159, align 8
  %161 = add i64 %160, 1
  store i64 %161, i64* %159, align 8
  %162 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 3
  %163 = bitcast i64* %162 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %163, i8 0, i64 16, i1 false) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %79) #19
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %16) #19
  ret void

164:                                              ; preds = %112, %178
  %165 = phi %"struct.gemmlowp::BlockParams"* [ %155, %112 ], [ %180, %178 ]
  %166 = phi i32 [ 0, %112 ], [ %181, %178 ]
  %167 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %165, i64 0, i32 4
  %168 = sub nsw i32 %13, %166
  %169 = load i32, i32* %167, align 4
  %170 = icmp slt i32 %168, %169
  %171 = select i1 %170, i32 %168, i32 %169
  br i1 %113, label %172, label %178

172:                                              ; preds = %164
  %173 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %165, i64 0, i32 3
  %174 = load i32, i32* %173, align 4
  br label %183

175:                                              ; preds = %255
  %176 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %287, i64 0, i32 4
  %177 = load i32, i32* %176, align 4
  br label %178

178:                                              ; preds = %175, %164
  %179 = phi i32 [ %169, %164 ], [ %177, %175 ]
  %180 = phi %"struct.gemmlowp::BlockParams"* [ %165, %164 ], [ %287, %175 ]
  %181 = add nsw i32 %179, %166
  %182 = icmp sgt i32 %13, %181
  br i1 %182, label %164, label %156

183:                                              ; preds = %172, %255
  %184 = phi i32 [ %289, %255 ], [ %174, %172 ]
  %185 = phi i32 [ %290, %255 ], [ 0, %172 ]
  %186 = sub nsw i32 %11, %185
  %187 = icmp slt i32 %186, %184
  %188 = select i1 %187, i32 %186, i32 %184
  %189 = load i8*, i8** %114, align 8, !noalias !1499
  %190 = load i32, i32* %115, align 8, !noalias !1499
  %191 = mul nsw i32 %190, %185
  %192 = sext i32 %191 to i64
  %193 = getelementptr inbounds i8, i8* %189, i64 %192
  %194 = ptrtoint i8* %193 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %116) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %116, i8 -86, i64 24, i1 false) #19
  store i64 %194, i64* %120, align 8
  store i32 %188, i32* %117, align 8
  store i32 %15, i32* %118, align 4
  store i32 %190, i32* %119, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %121) #19
  store %"class.gemmlowp::PackedSideBlock"* %5, %"class.gemmlowp::PackedSideBlock"** %122, align 8
  store %"class.gemmlowp::SideMap"* %2, %"class.gemmlowp::SideMap"** %123, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %3) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %121) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %116) #19
  %195 = load i64, i64* %125, align 8
  %196 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %127) #19
  store i64 %195, i64* %132, align 8
  store %"struct.gemmlowp::BlockParams"* %196, %"struct.gemmlowp::BlockParams"** %128, align 8
  store %"class.gemmlowp::PackedResult"* %6, %"class.gemmlowp::PackedResult"** %129, align 8
  store %"class.gemmlowp::PackedSideBlock"* %5, %"class.gemmlowp::PackedSideBlock"** %130, align 8
  store %"class.gemmlowp::PackedSideBlock"* %126, %"class.gemmlowp::PackedSideBlock"** %131, align 8
  br i1 %135, label %197, label %255

197:                                              ; preds = %183, %215
  %198 = phi %"struct.gemmlowp::BlockParams"* [ %217, %215 ], [ %196, %183 ]
  %199 = phi %"struct.gemmlowp::BlockParams"* [ %218, %215 ], [ %196, %183 ]
  %200 = phi i32 [ %219, %215 ], [ 0, %183 ]
  %201 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 2
  %202 = sub nsw i32 %134, %200
  %203 = load i32, i32* %201, align 4
  %204 = icmp slt i32 %202, %203
  %205 = select i1 %204, i32 %202, i32 %203
  %206 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 3
  %207 = load i32, i32* %206, align 4
  %208 = icmp sgt i32 %207, 0
  br i1 %208, label %209, label %215

209:                                              ; preds = %197
  %210 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 0
  %211 = load i32, i32* %210, align 4
  br label %221

212:                                              ; preds = %247
  %213 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 2
  %214 = load i32, i32* %213, align 4
  br label %215

215:                                              ; preds = %212, %197
  %216 = phi i32 [ %203, %197 ], [ %214, %212 ]
  %217 = phi %"struct.gemmlowp::BlockParams"* [ %198, %197 ], [ %248, %212 ]
  %218 = phi %"struct.gemmlowp::BlockParams"* [ %199, %197 ], [ %248, %212 ]
  %219 = add nsw i32 %216, %200
  %220 = icmp sgt i32 %134, %219
  br i1 %220, label %197, label %255

221:                                              ; preds = %247, %209
  %222 = phi %"struct.gemmlowp::BlockParams"* [ %248, %247 ], [ %198, %209 ]
  %223 = phi i32 [ %250, %247 ], [ %211, %209 ]
  %224 = phi i32 [ %253, %247 ], [ %207, %209 ]
  %225 = phi %"struct.gemmlowp::BlockParams"* [ %248, %247 ], [ %199, %209 ]
  %226 = phi i32 [ %251, %247 ], [ 0, %209 ]
  %227 = sub nsw i32 %224, %226
  %228 = icmp slt i32 %227, %223
  %229 = select i1 %228, i32 %227, i32 %223
  %230 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %225, i64 0, i32 4
  %231 = load i32, i32* %230, align 4
  %232 = icmp sgt i32 %231, 0
  br i1 %232, label %233, label %247

233:                                              ; preds = %221
  %234 = icmp sgt i32 %229, 0
  br label %235

235:                                              ; preds = %237, %233
  %236 = phi i32 [ 0, %233 ], [ %238, %237 ]
  br i1 %234, label %240, label %237

237:                                              ; preds = %240, %235
  %238 = add nuw nsw i32 %236, 4
  %239 = icmp slt i32 %238, %231
  br i1 %239, label %235, label %245

240:                                              ; preds = %235, %240
  %241 = phi i32 [ %243, %240 ], [ 0, %235 ]
  %242 = add nsw i32 %241, %226
  call void @_ZN8gemmlowp11ComputeImplINS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEES7_NS_12PackedResultEE10ComputeRunEiiii(%"class.gemmlowp::ComputeImpl"* nonnull %4, i32 %242, i32 %236, i32 %200, i32 %205) #19
  %243 = add nuw nsw i32 %241, 4
  %244 = icmp slt i32 %243, %229
  br i1 %244, label %240, label %237

245:                                              ; preds = %237
  %246 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %128, align 8
  br label %247

247:                                              ; preds = %245, %221
  %248 = phi %"struct.gemmlowp::BlockParams"* [ %246, %245 ], [ %222, %221 ]
  %249 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 0
  %250 = load i32, i32* %249, align 4
  %251 = add nsw i32 %250, %226
  %252 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 3
  %253 = load i32, i32* %252, align 4
  %254 = icmp sgt i32 %253, %251
  br i1 %254, label %221, label %212

255:                                              ; preds = %215, %183
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %127) #19
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %136) #19
  %256 = load i32, i32* %141, align 8
  %257 = add nsw i32 %256, %185
  %258 = load i32, i32* %142, align 4
  %259 = add nsw i32 %258, %166
  store i32 %257, i32* %137, align 4
  store i32 %259, i32* %138, align 4
  store i32 %188, i32* %139, align 4
  store i32 %171, i32* %140, align 4
  %260 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %21, align 8
  %261 = load i8, i8* %75, align 8
  %262 = zext i8 %261 to i64
  %263 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %260, i64 0, i32 5, i64 %262
  %264 = load i64, i64* %263, align 8
  %265 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %260, i64 0, i32 2
  %266 = bitcast i8** %265 to i64*
  %267 = load i64, i64* %266, align 8
  %268 = add i64 %267, %264
  %269 = inttoptr i64 %268 to i32*
  %270 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %144, align 8
  %271 = load i8, i8* %145, align 8
  %272 = zext i8 %271 to i64
  %273 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %270, i64 0, i32 5, i64 %272
  %274 = load i64, i64* %273, align 8
  %275 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %270, i64 0, i32 2
  %276 = bitcast i8** %275 to i64*
  %277 = load i64, i64* %276, align 8
  %278 = add i64 %277, %274
  %279 = inttoptr i64 %278 to i32*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %146) #19
  %280 = load %"class.gemmlowp::VectorDup.194"*, %"class.gemmlowp::VectorDup.194"** %147, align 8
  %281 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %280, i64 0, i32 0
  %282 = load i32, i32* %281, align 4, !noalias !1502
  store i32 %282, i32* %148, align 4, !alias.scope !1502
  store i32 %188, i32* %149, align 4, !alias.scope !1502
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %150) #19
  %283 = load %"class.gemmlowp::VectorDup"*, %"class.gemmlowp::VectorDup"** %151, align 8
  %284 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %283, i64 0, i32 0
  %285 = load i32, i32* %284, align 4, !noalias !1505
  store i32 %285, i32* %152, align 4, !alias.scope !1505
  store i32 %171, i32* %153, align 4, !alias.scope !1505
  %286 = load %"class.std::__1::tuple.491"*, %"class.std::__1::tuple.491"** %154, align 8
  call void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIsLNS_8MapOrderE1EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE1EEENSC_ISD_LSE_0EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISD_LSE_1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SZ_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.489"* %143, %"struct.gemmlowp::MatrixBlockBounds"* nonnull dereferenceable(16) %7, %"class.gemmlowp::PackedResult"* nonnull dereferenceable(40) %6, i32 %15, i32* %269, i32* %279, %"class.gemmlowp::VectorDup.194"* nonnull dereferenceable(8) %8, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %9, %"class.std::__1::tuple.491"* dereferenceable(40) %286)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %150) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %146) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %136) #19
  %287 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %288 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %287, i64 0, i32 3
  %289 = load i32, i32* %288, align 4
  %290 = add nsw i32 %289, %185
  %291 = icmp sgt i32 %11, %290
  br i1 %291, label %183, label %175
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSY_IS10_XT4_EEEPNSY_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::SingleThreadGemmContext"*, %"struct.gemmlowp::KernelBase"* dereferenceable(8), %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.180"* dereferenceable(24), %"class.gemmlowp::MatrixMap.479"*, %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.std::__1::tuple.481"* dereferenceable(40)) local_unnamed_addr #1 comdat {
  %9 = alloca %"class.gemmlowp::SideMap", align 8
  %10 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %11 = alloca %"class.gemmlowp::SideMap", align 8
  %12 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %13 = alloca %"class.gemmlowp::SideMap", align 8
  %14 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %15 = alloca %"class.gemmlowp::ComputeImpl", align 8
  %16 = alloca %"struct.gemmlowp::BlockParams", align 4
  %17 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %18 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %19 = alloca %"class.gemmlowp::PackedResult", align 8
  %20 = alloca %"struct.gemmlowp::MatrixBlockBounds", align 4
  %21 = alloca %"class.gemmlowp::VectorDup", align 4
  %22 = alloca %"class.gemmlowp::VectorDup.194", align 4
  %23 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %4, i64 0, i32 1
  %24 = load i32, i32* %23, align 8
  %25 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %4, i64 0, i32 2
  %26 = load i32, i32* %25, align 4
  %27 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 2
  %28 = load i32, i32* %27, align 4
  %29 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0
  %30 = bitcast %"struct.gemmlowp::BlockParams"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %30) #19
  %31 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 0
  %32 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 1
  %33 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 2
  %34 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 3
  %35 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 4
  %36 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 5
  %37 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 1
  %38 = bitcast %"struct.gemmlowp::BlockParams"* %16 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %38, i8 -86, i64 24, i1 false)
  %39 = load i32, i32* %37, align 8
  %40 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 2
  %41 = load i32, i32* %40, align 4
  %42 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 3
  %43 = load float, float* %42, align 8
  call void @_ZN8gemmlowp11BlockParams4InitINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES7_EEEEviiiiiif(%"struct.gemmlowp::BlockParams"* nonnull %16, i32 %24, i32 %26, i32 %28, i32 1, i32 %39, i32 %41, float %43)
  %44 = bitcast %"class.gemmlowp::PackedSideBlock"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %44) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %44, i8 -86, i64 80, i1 false)
  %45 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %45, align 8
  %46 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 4
  store i32 0, i32* %46, align 8
  %47 = load i32, i32* %31, align 4
  %48 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 0
  store i32 %47, i32* %48, align 8
  %49 = load i32, i32* %34, align 4
  %50 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 2
  store i32 %49, i32* %50, align 8
  %51 = load i32, i32* %33, align 4
  %52 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 1
  store i32 %51, i32* %52, align 4
  %53 = load i32, i32* %36, align 4
  %54 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 3
  store i32 %53, i32* %54, align 4
  %55 = mul nsw i32 %53, %49
  %56 = sext i32 %55 to i64
  %57 = add nsw i64 %56, 63
  %58 = and i64 %57, -64
  %59 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 4
  %60 = load i64, i64* %59, align 8, !noalias !1508
  %61 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 3
  %62 = load i64, i64* %61, align 8, !noalias !1508
  %63 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %62
  store i64 %60, i64* %63, align 8, !noalias !1508
  %64 = trunc i64 %62 to i8
  %65 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 6
  %66 = load i64, i64* %65, align 8, !noalias !1508
  %67 = load i64, i64* %61, align 8, !noalias !1508
  %68 = add i64 %67, 1
  store i64 %68, i64* %61, align 8, !noalias !1508
  %69 = load i64, i64* %59, align 8, !noalias !1508
  %70 = add i64 %69, %58
  store i64 %70, i64* %59, align 8, !noalias !1508
  %71 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 0
  store i8 %64, i8* %71, align 8
  %72 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %72, i8 -86, i64 7, i1 false) #19
  %73 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 2
  store i64 %66, i64* %73, align 8
  %74 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 3
  store i8 0, i8* %74, align 8
  %75 = sext i32 %49 to i64
  %76 = shl nsw i64 %75, 2
  %77 = add nsw i64 %76, 63
  %78 = and i64 %77, -64
  %79 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %68
  store i64 %70, i64* %79, align 8, !noalias !1511
  %80 = trunc i64 %68 to i8
  %81 = load i64, i64* %65, align 8, !noalias !1511
  %82 = load i64, i64* %61, align 8, !noalias !1511
  %83 = add i64 %82, 1
  store i64 %83, i64* %61, align 8, !noalias !1511
  %84 = load i64, i64* %59, align 8, !noalias !1511
  %85 = add i64 %84, %78
  store i64 %85, i64* %59, align 8, !noalias !1511
  %86 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 0
  store i8 %80, i8* %86, align 8
  %87 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %87, i8 -86, i64 7, i1 false) #19
  %88 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 2
  store i64 %81, i64* %88, align 8
  %89 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 3
  store i8 5, i8* %89, align 8
  %90 = bitcast %"class.gemmlowp::PackedSideBlock"* %18 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %90) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %90, i8 -86, i64 80, i1 false)
  %91 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %91, align 8
  %92 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 4
  store i32 0, i32* %92, align 8
  %93 = load i32, i32* %32, align 4
  %94 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 0
  store i32 %93, i32* %94, align 8
  %95 = load i32, i32* %35, align 4
  %96 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 2
  store i32 %95, i32* %96, align 8
  %97 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 1
  store i32 %51, i32* %97, align 4
  %98 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 3
  store i32 %53, i32* %98, align 4
  %99 = mul nsw i32 %53, %95
  %100 = sext i32 %99 to i64
  %101 = add nsw i64 %100, 63
  %102 = and i64 %101, -64
  %103 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %83
  store i64 %85, i64* %103, align 8, !noalias !1514
  %104 = trunc i64 %83 to i8
  %105 = load i64, i64* %65, align 8, !noalias !1514
  %106 = load i64, i64* %61, align 8, !noalias !1514
  %107 = add i64 %106, 1
  store i64 %107, i64* %61, align 8, !noalias !1514
  %108 = load i64, i64* %59, align 8, !noalias !1514
  %109 = add i64 %108, %102
  store i64 %109, i64* %59, align 8, !noalias !1514
  %110 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 0
  store i8 %104, i8* %110, align 8
  %111 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %111, i8 -86, i64 7, i1 false) #19
  %112 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 2
  store i64 %105, i64* %112, align 8
  %113 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 3
  store i8 0, i8* %113, align 8
  %114 = sext i32 %95 to i64
  %115 = shl nsw i64 %114, 2
  %116 = add nsw i64 %115, 63
  %117 = and i64 %116, -64
  %118 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %107
  store i64 %109, i64* %118, align 8, !noalias !1517
  %119 = trunc i64 %107 to i8
  %120 = load i64, i64* %65, align 8, !noalias !1517
  %121 = load i64, i64* %61, align 8, !noalias !1517
  %122 = add i64 %121, 1
  store i64 %122, i64* %61, align 8, !noalias !1517
  %123 = load i64, i64* %59, align 8, !noalias !1517
  %124 = add i64 %123, %117
  store i64 %124, i64* %59, align 8, !noalias !1517
  %125 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 0
  store i8 %119, i8* %125, align 8
  %126 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %126, i8 -86, i64 7, i1 false) #19
  %127 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 2
  store i64 %120, i64* %127, align 8
  %128 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 3
  store i8 5, i8* %128, align 8
  %129 = bitcast %"class.gemmlowp::PackedResult"* %19 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %129) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %129, i8 -86, i64 32, i1 false)
  %130 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 0
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %130, align 8
  %131 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 2
  store %"struct.gemmlowp::BlockParams"* %16, %"struct.gemmlowp::BlockParams"** %131, align 8
  %132 = load i32, i32* %34, align 4
  %133 = mul nsw i32 %95, %132
  %134 = sext i32 %133 to i64
  %135 = shl nsw i64 %134, 2
  %136 = add nsw i64 %135, 63
  %137 = and i64 %136, -64
  %138 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %122
  store i64 %124, i64* %138, align 8, !noalias !1520
  %139 = trunc i64 %122 to i8
  %140 = load i64, i64* %65, align 8, !noalias !1520
  %141 = bitcast i64* %61 to <2 x i64>*
  %142 = load <2 x i64>, <2 x i64>* %141, align 8, !noalias !1520
  %143 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %137, i32 1
  %144 = add <2 x i64> %142, %143
  %145 = bitcast i64* %61 to <2 x i64>*
  store <2 x i64> %144, <2 x i64>* %145, align 8, !noalias !1520
  %146 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 0
  store i8 %139, i8* %146, align 8
  %147 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %147, i8 -86, i64 7, i1 false) #19
  %148 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 2
  store i64 %140, i64* %148, align 8
  %149 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 3
  store i8 5, i8* %149, align 8
  call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %29)
  %150 = load i32, i32* %35, align 4
  %151 = icmp sge i32 %150, %26
  br i1 %151, label %152, label %169

152:                                              ; preds = %8
  %153 = bitcast %"class.gemmlowp::SideMap"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %153) #19
  %154 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 1
  %155 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 2
  %156 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 3
  %157 = bitcast %"class.gemmlowp::MatrixMap.180"* %3 to i64*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %153, i8 -86, i64 24, i1 false) #19
  %158 = load i64, i64* %157, align 8
  %159 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 2
  %160 = load i32, i32* %159, align 4
  %161 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 1
  %162 = load i32, i32* %161, align 8
  %163 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 3
  %164 = load i32, i32* %163, align 8
  %165 = bitcast %"class.gemmlowp::SideMap"* %9 to i64*
  store i64 %158, i64* %165, align 8
  store i32 %160, i32* %154, align 8
  store i32 %162, i32* %155, align 4
  store i32 %164, i32* %156, align 8
  %166 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %166) #19
  %167 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 0
  %168 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 1
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %167, align 8
  store %"class.gemmlowp::SideMap"* %9, %"class.gemmlowp::SideMap"** %168, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %10) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %166) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %153) #19
  br label %169

169:                                              ; preds = %152, %8
  %170 = icmp sgt i32 %24, 0
  br i1 %170, label %171, label %216

171:                                              ; preds = %169
  %172 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 0
  %173 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 3
  %174 = bitcast %"class.gemmlowp::SideMap"* %11 to i8*
  %175 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 1
  %176 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 2
  %177 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 3
  %178 = bitcast %"class.gemmlowp::SideMap"* %11 to i64*
  %179 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %12 to i8*
  %180 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %12, i64 0, i32 0
  %181 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %12, i64 0, i32 1
  %182 = icmp sgt i32 %26, 0
  %183 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 0
  %184 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 3
  %185 = bitcast %"class.gemmlowp::SideMap"* %13 to i8*
  %186 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 1
  %187 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 2
  %188 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 3
  %189 = bitcast %"class.gemmlowp::SideMap"* %13 to i64*
  %190 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %14 to i8*
  %191 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %14, i64 0, i32 0
  %192 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %14, i64 0, i32 1
  %193 = bitcast %"class.gemmlowp::ComputeImpl"* %15 to i8*
  %194 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 0
  %195 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 1
  %196 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 2
  %197 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 3
  %198 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 4
  %199 = add i32 %28, 15
  %200 = and i32 %199, -16
  %201 = icmp sgt i32 %200, 0
  %202 = bitcast %"struct.gemmlowp::MatrixBlockBounds"* %20 to i8*
  %203 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 0
  %204 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 1
  %205 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 2
  %206 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 3
  %207 = bitcast %"class.gemmlowp::VectorDup"* %21 to i8*
  %208 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %209 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %21, i64 0, i32 0
  %210 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %21, i64 0, i32 1
  %211 = bitcast %"class.gemmlowp::VectorDup.194"* %22 to i8*
  %212 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %6, i64 0, i32 0
  %213 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %22, i64 0, i32 0
  %214 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %22, i64 0, i32 1
  %215 = load i32, i32* %34, align 4
  br label %221

216:                                              ; preds = %235, %169
  %217 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 0
  store i8 0, i8* %217, align 8
  %218 = load i64, i64* %65, align 8
  %219 = add i64 %218, 1
  store i64 %219, i64* %65, align 8
  %220 = bitcast i64* %61 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %220, i8 0, i64 16, i1 false) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %129) #19
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %90) #19
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %44) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %30) #19
  ret void

221:                                              ; preds = %171, %235
  %222 = phi i32 [ %215, %171 ], [ %236, %235 ]
  %223 = phi i32 [ 0, %171 ], [ %237, %235 ]
  %224 = sub nsw i32 %24, %223
  %225 = icmp slt i32 %224, %222
  %226 = select i1 %225, i32 %224, i32 %222
  %227 = load i8*, i8** %172, align 8, !noalias !1523
  %228 = load i32, i32* %173, align 8, !noalias !1523
  %229 = mul nsw i32 %228, %223
  %230 = sext i32 %229 to i64
  %231 = getelementptr inbounds i8, i8* %227, i64 %230
  %232 = ptrtoint i8* %231 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %174) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %174, i8 -86, i64 24, i1 false) #19
  store i64 %232, i64* %178, align 8
  store i32 %226, i32* %175, align 8
  store i32 %28, i32* %176, align 4
  store i32 %228, i32* %177, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %179) #19
  store %"class.gemmlowp::PackedSideBlock"* %17, %"class.gemmlowp::PackedSideBlock"** %180, align 8
  store %"class.gemmlowp::SideMap"* %11, %"class.gemmlowp::SideMap"** %181, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %12) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %179) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %174) #19
  br i1 %182, label %233, label %235

233:                                              ; preds = %221
  %234 = load i32, i32* %35, align 4
  br label %239

235:                                              ; preds = %311, %221
  %236 = load i32, i32* %34, align 4
  %237 = add nsw i32 %236, %223
  %238 = icmp sgt i32 %24, %237
  br i1 %238, label %221, label %216

239:                                              ; preds = %233, %311
  %240 = phi i32 [ %334, %311 ], [ %234, %233 ]
  %241 = phi i32 [ %335, %311 ], [ 0, %233 ]
  %242 = sub nsw i32 %26, %241
  %243 = icmp slt i32 %242, %240
  %244 = select i1 %243, i32 %242, i32 %240
  br i1 %151, label %252, label %245

245:                                              ; preds = %239
  %246 = load i8*, i8** %183, align 8, !noalias !1526
  %247 = load i32, i32* %184, align 8, !noalias !1526
  %248 = mul nsw i32 %247, %241
  %249 = sext i32 %248 to i64
  %250 = getelementptr inbounds i8, i8* %246, i64 %249
  %251 = ptrtoint i8* %250 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %185) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %185, i8 -86, i64 24, i1 false) #19
  store i64 %251, i64* %189, align 8
  store i32 %244, i32* %186, align 8
  store i32 %28, i32* %187, align 4
  store i32 %247, i32* %188, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %190) #19
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %191, align 8
  store %"class.gemmlowp::SideMap"* %13, %"class.gemmlowp::SideMap"** %192, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %14) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %190) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %185) #19
  br label %252

252:                                              ; preds = %245, %239
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %193) #19
  store %"struct.gemmlowp::KernelBase"* %1, %"struct.gemmlowp::KernelBase"** %194, align 8
  store %"struct.gemmlowp::BlockParams"* %16, %"struct.gemmlowp::BlockParams"** %195, align 8
  store %"class.gemmlowp::PackedResult"* %19, %"class.gemmlowp::PackedResult"** %196, align 8
  store %"class.gemmlowp::PackedSideBlock"* %17, %"class.gemmlowp::PackedSideBlock"** %197, align 8
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %198, align 8
  br i1 %201, label %253, label %311

253:                                              ; preds = %252, %271
  %254 = phi %"struct.gemmlowp::BlockParams"* [ %273, %271 ], [ %16, %252 ]
  %255 = phi %"struct.gemmlowp::BlockParams"* [ %274, %271 ], [ %16, %252 ]
  %256 = phi i32 [ %275, %271 ], [ 0, %252 ]
  %257 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 2
  %258 = sub nsw i32 %200, %256
  %259 = load i32, i32* %257, align 4
  %260 = icmp slt i32 %258, %259
  %261 = select i1 %260, i32 %258, i32 %259
  %262 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 3
  %263 = load i32, i32* %262, align 4
  %264 = icmp sgt i32 %263, 0
  br i1 %264, label %265, label %271

265:                                              ; preds = %253
  %266 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 0
  %267 = load i32, i32* %266, align 4
  br label %277

268:                                              ; preds = %303
  %269 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 2
  %270 = load i32, i32* %269, align 4
  br label %271

271:                                              ; preds = %268, %253
  %272 = phi i32 [ %259, %253 ], [ %270, %268 ]
  %273 = phi %"struct.gemmlowp::BlockParams"* [ %254, %253 ], [ %304, %268 ]
  %274 = phi %"struct.gemmlowp::BlockParams"* [ %255, %253 ], [ %304, %268 ]
  %275 = add nsw i32 %272, %256
  %276 = icmp sgt i32 %200, %275
  br i1 %276, label %253, label %311

277:                                              ; preds = %303, %265
  %278 = phi %"struct.gemmlowp::BlockParams"* [ %304, %303 ], [ %254, %265 ]
  %279 = phi i32 [ %306, %303 ], [ %267, %265 ]
  %280 = phi i32 [ %309, %303 ], [ %263, %265 ]
  %281 = phi %"struct.gemmlowp::BlockParams"* [ %304, %303 ], [ %255, %265 ]
  %282 = phi i32 [ %307, %303 ], [ 0, %265 ]
  %283 = sub nsw i32 %280, %282
  %284 = icmp slt i32 %283, %279
  %285 = select i1 %284, i32 %283, i32 %279
  %286 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %281, i64 0, i32 4
  %287 = load i32, i32* %286, align 4
  %288 = icmp sgt i32 %287, 0
  br i1 %288, label %289, label %303

289:                                              ; preds = %277
  %290 = icmp sgt i32 %285, 0
  br label %291

291:                                              ; preds = %293, %289
  %292 = phi i32 [ 0, %289 ], [ %294, %293 ]
  br i1 %290, label %296, label %293

293:                                              ; preds = %296, %291
  %294 = add nuw nsw i32 %292, 4
  %295 = icmp slt i32 %294, %287
  br i1 %295, label %291, label %301

296:                                              ; preds = %291, %296
  %297 = phi i32 [ %299, %296 ], [ 0, %291 ]
  %298 = add nsw i32 %297, %282
  call void @_ZN8gemmlowp11ComputeImplINS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEES7_NS_12PackedResultEE10ComputeRunEiiii(%"class.gemmlowp::ComputeImpl"* nonnull %15, i32 %298, i32 %292, i32 %256, i32 %261) #19
  %299 = add nuw nsw i32 %297, 4
  %300 = icmp slt i32 %299, %285
  br i1 %300, label %296, label %293

301:                                              ; preds = %293
  %302 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %195, align 8
  br label %303

303:                                              ; preds = %301, %277
  %304 = phi %"struct.gemmlowp::BlockParams"* [ %302, %301 ], [ %278, %277 ]
  %305 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 0
  %306 = load i32, i32* %305, align 4
  %307 = add nsw i32 %306, %282
  %308 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 3
  %309 = load i32, i32* %308, align 4
  %310 = icmp sgt i32 %309, %307
  br i1 %310, label %277, label %268

311:                                              ; preds = %271, %252
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %193) #19
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %202) #19
  store i32 %223, i32* %203, align 4
  store i32 %241, i32* %204, align 4
  store i32 %226, i32* %205, align 4
  store i32 %244, i32* %206, align 4
  %312 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %45, align 8
  %313 = load i8, i8* %86, align 8
  %314 = zext i8 %313 to i64
  %315 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %312, i64 0, i32 5, i64 %314
  %316 = load i64, i64* %315, align 8
  %317 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %312, i64 0, i32 2
  %318 = bitcast i8** %317 to i64*
  %319 = load i64, i64* %318, align 8
  %320 = add i64 %319, %316
  %321 = inttoptr i64 %320 to i32*
  %322 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %91, align 8
  %323 = load i8, i8* %125, align 8
  %324 = zext i8 %323 to i64
  %325 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %322, i64 0, i32 5, i64 %324
  %326 = load i64, i64* %325, align 8
  %327 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %322, i64 0, i32 2
  %328 = bitcast i8** %327 to i64*
  %329 = load i64, i64* %328, align 8
  %330 = add i64 %329, %326
  %331 = inttoptr i64 %330 to i32*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %207) #19
  %332 = load i32, i32* %208, align 4, !noalias !1529
  store i32 %332, i32* %209, align 4, !alias.scope !1529
  store i32 %226, i32* %210, align 4, !alias.scope !1529
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %211) #19
  %333 = load i32, i32* %212, align 4, !noalias !1532
  store i32 %333, i32* %213, align 4, !alias.scope !1532
  store i32 %244, i32* %214, align 4, !alias.scope !1532
  call void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIsLNS_8MapOrderE0EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE0EEENSC_ISD_LSE_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISD_LSE_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SZ_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.479"* %4, %"struct.gemmlowp::MatrixBlockBounds"* nonnull dereferenceable(16) %20, %"class.gemmlowp::PackedResult"* nonnull dereferenceable(40) %19, i32 %28, i32* %321, i32* %331, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %21, %"class.gemmlowp::VectorDup.194"* nonnull dereferenceable(8) %22, %"class.std::__1::tuple.481"* dereferenceable(40) %7)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %211) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %207) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %202) #19
  %334 = load i32, i32* %35, align 4
  %335 = add nsw i32 %334, %241
  %336 = icmp sgt i32 %26, %335
  br i1 %336, label %239, label %235
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIsLNS_8MapOrderE0EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE0EEENSC_ISD_LSE_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISD_LSE_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SZ_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.479"*, %"struct.gemmlowp::MatrixBlockBounds"* dereferenceable(16), %"class.gemmlowp::PackedResult"* dereferenceable(40), i32, i32*, i32*, %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.std::__1::tuple.481"* dereferenceable(40)) local_unnamed_addr #1 comdat {
  %10 = alloca %"struct.gemmlowp::RegisterBlock.304", align 16
  %11 = alloca %"class.gemmlowp::MatrixMap.214", align 8
  %12 = alloca %"class.gemmlowp::VectorMap", align 8
  %13 = alloca %"class.gemmlowp::VectorMap.201", align 8
  %14 = alloca %"struct.gemmlowp::OutputPipelineExecutor.574", align 8
  %15 = alloca %"struct.gemmlowp::OutputPipelineExecutor.582", align 8
  %16 = alloca %"struct.gemmlowp::OutputPipelineExecutor.590", align 8
  %17 = alloca %"struct.gemmlowp::OutputPipelineExecutor.598", align 8
  %18 = alloca %"struct.gemmlowp::OutputPipelineExecutor.606", align 8
  %19 = alloca %"struct.gemmlowp::OutputPipelineExecutor.614", align 8
  %20 = bitcast %"class.gemmlowp::MatrixMap.214"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %20) #19
  %21 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %11, i64 0, i32 0
  %22 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %11, i64 0, i32 1
  %23 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %11, i64 0, i32 2
  %24 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %11, i64 0, i32 3
  %25 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 0
  %26 = bitcast %"class.gemmlowp::MatrixMap.214"* %11 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %26, i8 -86, i64 24, i1 false)
  %27 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %25, align 8, !noalias !1535
  %28 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 1, i32 0
  %29 = load i8, i8* %28, align 8, !noalias !1535
  %30 = zext i8 %29 to i64
  %31 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %27, i64 0, i32 5, i64 %30
  %32 = load i64, i64* %31, align 8, !noalias !1535
  %33 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %27, i64 0, i32 2
  %34 = bitcast i8** %33 to i64*
  %35 = load i64, i64* %34, align 8, !noalias !1535
  %36 = add i64 %35, %32
  %37 = inttoptr i64 %36 to i32*
  %38 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 2
  %39 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %38, align 8, !noalias !1535
  %40 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %39, i64 0, i32 3
  %41 = load i32, i32* %40, align 4, !noalias !1535
  %42 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %39, i64 0, i32 4
  %43 = load i32, i32* %42, align 4, !noalias !1535
  store i32* %37, i32** %21, align 8, !alias.scope !1535
  store i32 %41, i32* %22, align 8, !alias.scope !1535
  store i32 %43, i32* %23, align 4, !alias.scope !1535
  store i32 %41, i32* %24, align 8, !alias.scope !1535
  %44 = bitcast %"class.gemmlowp::VectorMap"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %44) #19
  %45 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %12, i64 0, i32 0
  %46 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %12, i64 0, i32 1
  %47 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 2
  %48 = bitcast %"class.gemmlowp::VectorMap"* %12 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %48, i8 -86, i64 16, i1 false)
  %49 = load i32, i32* %47, align 4
  store i32* %4, i32** %45, align 8
  store i32 %49, i32* %46, align 8
  %50 = bitcast %"class.gemmlowp::VectorMap.201"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %50) #19
  %51 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %13, i64 0, i32 0
  %52 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %13, i64 0, i32 1
  %53 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 3
  %54 = bitcast %"class.gemmlowp::VectorMap.201"* %13 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %54, i8 -86, i64 16, i1 false)
  %55 = load i32, i32* %53, align 4
  store i32* %5, i32** %51, align 8
  store i32 %55, i32* %52, align 8
  %56 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.574"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %56) #19
  %57 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.574", %"struct.gemmlowp::OutputPipelineExecutor.574"* %14, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %58 = bitcast i8* %57 to i64*
  store i64 -6148914691236517206, i64* %58, align 8
  %59 = getelementptr inbounds %"class.std::__1::tuple.481", %"class.std::__1::tuple.481"* %8, i64 0, i32 0, i32 0, i32 0
  %60 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.574", %"struct.gemmlowp::OutputPipelineExecutor.574"* %14, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition"* %59, %"struct.gemmlowp::OutputStageBiasAddition"** %60, align 8
  %61 = getelementptr inbounds %"class.std::__1::tuple.481", %"class.std::__1::tuple.481"* %8, i64 0, i32 0, i32 1, i32 0
  %62 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.574", %"struct.gemmlowp::OutputPipelineExecutor.574"* %14, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %61, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %62, align 8
  %63 = getelementptr inbounds %"class.std::__1::tuple.481", %"class.std::__1::tuple.481"* %8, i64 0, i32 0, i32 1, i32 0, i32 1
  %64 = load i32, i32* %63, align 4
  %65 = icmp sgt i32 %64, 0
  %66 = select i1 %65, i32 %64, i32 0
  %67 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.574", %"struct.gemmlowp::OutputPipelineExecutor.574"* %14, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %66, i32* %67, align 8
  %68 = sub nsw i32 0, %64
  %69 = icmp sgt i32 %68, 0
  %70 = select i1 %69, i32 %68, i32 0
  %71 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.574", %"struct.gemmlowp::OutputPipelineExecutor.574"* %14, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %70, i32* %71, align 4
  %72 = getelementptr inbounds %"class.std::__1::tuple.481", %"class.std::__1::tuple.481"* %8, i64 0, i32 0, i32 2, i32 0
  %73 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.574", %"struct.gemmlowp::OutputPipelineExecutor.574"* %14, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %72, %"struct.gemmlowp::OutputStageClamp"** %73, align 8
  %74 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.582"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %74) #19
  %75 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.582", %"struct.gemmlowp::OutputPipelineExecutor.582"* %15, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %76 = bitcast i8* %75 to i64*
  store i64 -6148914691236517206, i64* %76, align 8
  %77 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.582", %"struct.gemmlowp::OutputPipelineExecutor.582"* %15, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition"* %59, %"struct.gemmlowp::OutputStageBiasAddition"** %77, align 8
  %78 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.582", %"struct.gemmlowp::OutputPipelineExecutor.582"* %15, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %61, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %78, align 8
  %79 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.582", %"struct.gemmlowp::OutputPipelineExecutor.582"* %15, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %66, i32* %79, align 8
  %80 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.582", %"struct.gemmlowp::OutputPipelineExecutor.582"* %15, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %70, i32* %80, align 4
  %81 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.582", %"struct.gemmlowp::OutputPipelineExecutor.582"* %15, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %72, %"struct.gemmlowp::OutputStageClamp"** %81, align 8
  %82 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.590"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %82) #19
  %83 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.590", %"struct.gemmlowp::OutputPipelineExecutor.590"* %16, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %84 = bitcast i8* %83 to i64*
  store i64 -6148914691236517206, i64* %84, align 8
  %85 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.590", %"struct.gemmlowp::OutputPipelineExecutor.590"* %16, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition"* %59, %"struct.gemmlowp::OutputStageBiasAddition"** %85, align 8
  %86 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.590", %"struct.gemmlowp::OutputPipelineExecutor.590"* %16, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %61, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %86, align 8
  %87 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.590", %"struct.gemmlowp::OutputPipelineExecutor.590"* %16, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %66, i32* %87, align 8
  %88 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.590", %"struct.gemmlowp::OutputPipelineExecutor.590"* %16, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %70, i32* %88, align 4
  %89 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.590", %"struct.gemmlowp::OutputPipelineExecutor.590"* %16, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %72, %"struct.gemmlowp::OutputStageClamp"** %89, align 8
  %90 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.598"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %90) #19
  %91 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.598", %"struct.gemmlowp::OutputPipelineExecutor.598"* %17, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %92 = bitcast i8* %91 to i64*
  store i64 -6148914691236517206, i64* %92, align 8
  %93 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.598", %"struct.gemmlowp::OutputPipelineExecutor.598"* %17, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition"* %59, %"struct.gemmlowp::OutputStageBiasAddition"** %93, align 8
  %94 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.598", %"struct.gemmlowp::OutputPipelineExecutor.598"* %17, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %61, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %94, align 8
  %95 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.598", %"struct.gemmlowp::OutputPipelineExecutor.598"* %17, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %66, i32* %95, align 8
  %96 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.598", %"struct.gemmlowp::OutputPipelineExecutor.598"* %17, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %70, i32* %96, align 4
  %97 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.598", %"struct.gemmlowp::OutputPipelineExecutor.598"* %17, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %72, %"struct.gemmlowp::OutputStageClamp"** %97, align 8
  %98 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.606"* %18 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %98) #19
  %99 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.606", %"struct.gemmlowp::OutputPipelineExecutor.606"* %18, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %100 = bitcast i8* %99 to i64*
  store i64 -6148914691236517206, i64* %100, align 8
  %101 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.606", %"struct.gemmlowp::OutputPipelineExecutor.606"* %18, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition"* %59, %"struct.gemmlowp::OutputStageBiasAddition"** %101, align 8
  %102 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.606", %"struct.gemmlowp::OutputPipelineExecutor.606"* %18, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %61, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %102, align 8
  %103 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.606", %"struct.gemmlowp::OutputPipelineExecutor.606"* %18, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %66, i32* %103, align 8
  %104 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.606", %"struct.gemmlowp::OutputPipelineExecutor.606"* %18, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %70, i32* %104, align 4
  %105 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.606", %"struct.gemmlowp::OutputPipelineExecutor.606"* %18, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %72, %"struct.gemmlowp::OutputStageClamp"** %105, align 8
  %106 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.614"* %19 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %106) #19
  %107 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.614", %"struct.gemmlowp::OutputPipelineExecutor.614"* %19, i64 0, i32 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0
  %108 = bitcast i8* %107 to i64*
  store i64 -6148914691236517206, i64* %108, align 8
  %109 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.614", %"struct.gemmlowp::OutputPipelineExecutor.614"* %19, i64 0, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageBiasAddition"* %59, %"struct.gemmlowp::OutputStageBiasAddition"** %109, align 8
  %110 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.614", %"struct.gemmlowp::OutputPipelineExecutor.614"* %19, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %61, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %110, align 8
  %111 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.614", %"struct.gemmlowp::OutputPipelineExecutor.614"* %19, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  store i32 %66, i32* %111, align 8
  %112 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.614", %"struct.gemmlowp::OutputPipelineExecutor.614"* %19, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  store i32 %70, i32* %112, align 4
  %113 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.614", %"struct.gemmlowp::OutputPipelineExecutor.614"* %19, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  store %"struct.gemmlowp::OutputStageClamp"* %72, %"struct.gemmlowp::OutputStageClamp"** %113, align 8
  %114 = icmp slt i32 %55, 4
  br i1 %114, label %123, label %115

115:                                              ; preds = %9
  %116 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 1
  %117 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 0
  %118 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %119 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %7, i64 0, i32 0
  %120 = load i32, i32* %47, align 4
  br label %138

121:                                              ; preds = %309
  %122 = trunc i64 %311 to i32
  br label %123

123:                                              ; preds = %121, %9
  %124 = phi i32 [ %55, %9 ], [ %312, %121 ]
  %125 = phi i32 [ 0, %9 ], [ %122, %121 ]
  %126 = icmp slt i32 %125, %124
  br i1 %126, label %127, label %438

127:                                              ; preds = %123
  %128 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 1
  %129 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 0
  %130 = bitcast %"struct.gemmlowp::RegisterBlock.304"* %10 to i8*
  %131 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %132 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %7, i64 0, i32 0
  %133 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %10, i64 0, i32 0, i32 0, i64 4
  %134 = zext i32 %125 to i64
  %135 = load i32, i32* %47, align 4
  %136 = bitcast %"struct.gemmlowp::RegisterBlock.304"* %10 to <4 x i32>*
  %137 = bitcast i32* %133 to <4 x i32>*
  br label %316

138:                                              ; preds = %115, %309
  %139 = phi i32 [ %120, %115 ], [ %310, %309 ]
  %140 = phi i64 [ 0, %115 ], [ %311, %309 ]
  %141 = load i32, i32* %116, align 4
  %142 = trunc i64 %140 to i32
  %143 = add nsw i32 %141, %142
  %144 = load i32*, i32** %21, align 8
  %145 = load i32, i32* %24, align 8
  %146 = mul nsw i32 %145, %142
  %147 = sext i32 %146 to i64
  %148 = load i32*, i32** %45, align 8
  %149 = bitcast i32* %148 to i8*
  call void @llvm.prefetch(i8* %149, i32 0, i32 3, i32 1) #19
  %150 = getelementptr inbounds i32, i32* %148, i64 4
  %151 = bitcast i32* %150 to i8*
  call void @llvm.prefetch(i8* %151, i32 0, i32 3, i32 1) #19
  %152 = getelementptr inbounds i32, i32* %144, i64 %147
  %153 = sext i32 %145 to i64
  %154 = bitcast i32* %152 to i8*
  call void @llvm.prefetch(i8* %154, i32 0, i32 3, i32 1) #19
  %155 = getelementptr inbounds i32, i32* %152, i64 4
  %156 = bitcast i32* %155 to i8*
  call void @llvm.prefetch(i8* %156, i32 0, i32 3, i32 1) #19
  %157 = getelementptr inbounds i32, i32* %152, i64 %153
  %158 = bitcast i32* %157 to i8*
  call void @llvm.prefetch(i8* %158, i32 0, i32 3, i32 1) #19
  %159 = getelementptr inbounds i32, i32* %157, i64 4
  %160 = bitcast i32* %159 to i8*
  call void @llvm.prefetch(i8* %160, i32 0, i32 3, i32 1) #19
  %161 = shl nsw i64 %153, 1
  %162 = getelementptr inbounds i32, i32* %152, i64 %161
  %163 = bitcast i32* %162 to i8*
  call void @llvm.prefetch(i8* %163, i32 0, i32 3, i32 1) #19
  %164 = getelementptr inbounds i32, i32* %162, i64 4
  %165 = bitcast i32* %164 to i8*
  call void @llvm.prefetch(i8* %165, i32 0, i32 3, i32 1) #19
  %166 = mul nsw i64 %153, 3
  %167 = getelementptr inbounds i32, i32* %152, i64 %166
  %168 = bitcast i32* %167 to i8*
  call void @llvm.prefetch(i8* %168, i32 0, i32 3, i32 1) #19
  %169 = getelementptr inbounds i32, i32* %167, i64 4
  %170 = bitcast i32* %169 to i8*
  call void @llvm.prefetch(i8* %170, i32 0, i32 3, i32 1) #19
  %171 = icmp slt i32 %139, 8
  br i1 %171, label %174, label %179

172:                                              ; preds = %179
  %173 = trunc i64 %187 to i32
  br label %174

174:                                              ; preds = %172, %138
  %175 = phi i32 [ %139, %138 ], [ %214, %172 ]
  %176 = phi i32 [ 0, %138 ], [ %173, %172 ]
  %177 = add nsw i32 %175, -4
  %178 = icmp sgt i32 %176, %177
  br i1 %178, label %222, label %231

179:                                              ; preds = %138, %218
  %180 = phi i32* [ %221, %218 ], [ %148, %138 ]
  %181 = phi i32 [ %220, %218 ], [ %145, %138 ]
  %182 = phi i32* [ %219, %218 ], [ %144, %138 ]
  %183 = phi i64 [ %187, %218 ], [ 0, %138 ]
  %184 = load i32, i32* %117, align 4
  %185 = trunc i64 %183 to i32
  %186 = add nsw i32 %184, %185
  %187 = add nuw i64 %183, 8
  %188 = mul nsw i32 %181, %142
  %189 = sext i32 %188 to i64
  %190 = getelementptr inbounds i32, i32* %180, i64 %187
  %191 = bitcast i32* %190 to i8*
  call void @llvm.prefetch(i8* %191, i32 0, i32 3, i32 1) #19
  %192 = getelementptr inbounds i32, i32* %190, i64 4
  %193 = bitcast i32* %192 to i8*
  call void @llvm.prefetch(i8* %193, i32 0, i32 3, i32 1) #19
  %194 = getelementptr inbounds i32, i32* %182, i64 %187
  %195 = getelementptr inbounds i32, i32* %194, i64 %189
  %196 = sext i32 %181 to i64
  %197 = bitcast i32* %195 to i8*
  call void @llvm.prefetch(i8* %197, i32 0, i32 3, i32 1) #19
  %198 = getelementptr inbounds i32, i32* %195, i64 4
  %199 = bitcast i32* %198 to i8*
  call void @llvm.prefetch(i8* %199, i32 0, i32 3, i32 1) #19
  %200 = getelementptr inbounds i32, i32* %195, i64 %196
  %201 = bitcast i32* %200 to i8*
  call void @llvm.prefetch(i8* %201, i32 0, i32 3, i32 1) #19
  %202 = getelementptr inbounds i32, i32* %200, i64 4
  %203 = bitcast i32* %202 to i8*
  call void @llvm.prefetch(i8* %203, i32 0, i32 3, i32 1) #19
  %204 = shl nsw i64 %196, 1
  %205 = getelementptr inbounds i32, i32* %195, i64 %204
  %206 = bitcast i32* %205 to i8*
  call void @llvm.prefetch(i8* %206, i32 0, i32 3, i32 1) #19
  %207 = getelementptr inbounds i32, i32* %205, i64 4
  %208 = bitcast i32* %207 to i8*
  call void @llvm.prefetch(i8* %208, i32 0, i32 3, i32 1) #19
  %209 = mul nsw i64 %196, 3
  %210 = getelementptr inbounds i32, i32* %195, i64 %209
  %211 = bitcast i32* %210 to i8*
  call void @llvm.prefetch(i8* %211, i32 0, i32 3, i32 1) #19
  %212 = getelementptr inbounds i32, i32* %210, i64 4
  %213 = bitcast i32* %212 to i8*
  call void @llvm.prefetch(i8* %213, i32 0, i32 3, i32 1) #19
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.614"* nonnull dereferenceable(40) %19, %"class.gemmlowp::MatrixMap.479"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %7, i32 %3, i32 %185, i32 %142, i32 %186, i32 %143, i32 %186, i32 %143)
  %214 = load i32, i32* %47, align 4
  %215 = add nsw i32 %214, -8
  %216 = trunc i64 %187 to i32
  %217 = icmp slt i32 %215, %216
  br i1 %217, label %172, label %218

218:                                              ; preds = %179
  %219 = load i32*, i32** %21, align 8
  %220 = load i32, i32* %24, align 8
  %221 = load i32*, i32** %45, align 8
  br label %179

222:                                              ; preds = %231, %174
  %223 = phi i32 [ %175, %174 ], [ %236, %231 ]
  %224 = phi i32 [ %176, %174 ], [ %235, %231 ]
  %225 = icmp slt i32 %224, %223
  br i1 %225, label %226, label %309

226:                                              ; preds = %222
  %227 = or i64 %140, 1
  %228 = or i64 %140, 2
  %229 = or i64 %140, 3
  %230 = zext i32 %224 to i64
  br label %239

231:                                              ; preds = %174, %231
  %232 = phi i32 [ %235, %231 ], [ %176, %174 ]
  %233 = load i32, i32* %117, align 4
  %234 = add nsw i32 %233, %232
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.606"* nonnull dereferenceable(40) %18, %"class.gemmlowp::MatrixMap.479"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %7, i32 %3, i32 %232, i32 %142, i32 %234, i32 %143, i32 %234, i32 %143)
  %235 = add nuw nsw i32 %232, 4
  %236 = load i32, i32* %47, align 4
  %237 = add nsw i32 %236, -4
  %238 = icmp sgt i32 %235, %237
  br i1 %238, label %222, label %231

239:                                              ; preds = %226, %239
  %240 = phi i64 [ %230, %226 ], [ %305, %239 ]
  %241 = load i32, i32* %117, align 4
  %242 = trunc i64 %240 to i32
  %243 = add nsw i32 %241, %242
  %244 = load i32*, i32** %21, align 8
  %245 = getelementptr inbounds i32, i32* %244, i64 %240
  %246 = load i32, i32* %24, align 8
  %247 = mul nsw i32 %246, %142
  %248 = sext i32 %247 to i64
  %249 = getelementptr inbounds i32, i32* %245, i64 %248
  %250 = load i32, i32* %249, align 4
  %251 = sext i32 %246 to i64
  %252 = mul nsw i64 %227, %251
  %253 = getelementptr inbounds i32, i32* %245, i64 %252
  %254 = load i32, i32* %253, align 4
  %255 = mul nsw i64 %228, %251
  %256 = getelementptr inbounds i32, i32* %245, i64 %255
  %257 = load i32, i32* %256, align 4
  %258 = mul nsw i64 %229, %251
  %259 = getelementptr inbounds i32, i32* %245, i64 %258
  %260 = load i32, i32* %259, align 4
  %261 = load i32*, i32** %45, align 8
  %262 = getelementptr inbounds i32, i32* %261, i64 %240
  %263 = load i32, i32* %262, align 4
  %264 = load i32*, i32** %51, align 8
  %265 = getelementptr i32, i32* %264, i64 %140
  %266 = bitcast i32* %265 to i64*
  %267 = load i64, i64* %266, align 4
  %268 = getelementptr inbounds i32, i32* %265, i64 2
  %269 = bitcast i32* %268 to i64*
  %270 = load i64, i64* %269, align 4
  %271 = trunc i64 %267 to i32
  %272 = lshr i64 %267, 32
  %273 = trunc i64 %272 to i32
  %274 = load i32, i32* %118, align 4
  %275 = load i32, i32* %119, align 4
  %276 = mul nsw i32 %275, %263
  %277 = add nsw i32 %276, %250
  %278 = add nsw i32 %276, %254
  %279 = add nsw i32 %276, %257
  %280 = add nsw i32 %276, %260
  %281 = mul nsw i32 %275, %3
  %282 = add nsw i32 %281, %271
  %283 = add nsw i32 %281, %273
  %284 = trunc i64 %270 to i32
  %285 = add nsw i32 %281, %284
  %286 = lshr i64 %270, 32
  %287 = trunc i64 %286 to i32
  %288 = add nsw i32 %281, %287
  %289 = mul nsw i32 %282, %274
  %290 = add nsw i32 %277, %289
  %291 = mul nsw i32 %283, %274
  %292 = add nsw i32 %278, %291
  %293 = mul nsw i32 %285, %274
  %294 = add nsw i32 %279, %293
  %295 = zext i32 %294 to i64
  %296 = mul nsw i32 %288, %274
  %297 = add nsw i32 %280, %296
  %298 = zext i32 %297 to i64
  %299 = shl nuw i64 %298, 32
  %300 = or i64 %299, %295
  %301 = zext i32 %292 to i64
  %302 = shl nuw i64 %301, 32
  %303 = zext i32 %290 to i64
  %304 = or i64 %302, %303
  call void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi1ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE0EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.598"* nonnull %17, i64 %304, i64 %300, %"class.gemmlowp::MatrixMap.479"* %0, i32 %243, i32 %143, i32 %243, i32 %143) #19
  %305 = add nuw nsw i64 %240, 1
  %306 = load i32, i32* %47, align 4
  %307 = trunc i64 %305 to i32
  %308 = icmp sgt i32 %306, %307
  br i1 %308, label %239, label %309

309:                                              ; preds = %239, %222
  %310 = phi i32 [ %223, %222 ], [ %306, %239 ]
  %311 = add nuw i64 %140, 4
  %312 = load i32, i32* %53, align 4
  %313 = add nsw i32 %312, -4
  %314 = trunc i64 %311 to i32
  %315 = icmp slt i32 %313, %314
  br i1 %315, label %121, label %138

316:                                              ; preds = %127, %432
  %317 = phi i32 [ %135, %127 ], [ %433, %432 ]
  %318 = phi i64 [ %134, %127 ], [ %434, %432 ]
  %319 = load i32, i32* %128, align 4
  %320 = trunc i64 %318 to i32
  %321 = add nsw i32 %319, %320
  %322 = load i32*, i32** %21, align 8
  %323 = load i32, i32* %24, align 8
  %324 = mul nsw i32 %323, %320
  %325 = sext i32 %324 to i64
  %326 = load i32*, i32** %45, align 8
  %327 = bitcast i32* %326 to i8*
  call void @llvm.prefetch(i8* %327, i32 0, i32 3, i32 1) #19
  %328 = getelementptr inbounds i32, i32* %326, i64 4
  %329 = bitcast i32* %328 to i8*
  call void @llvm.prefetch(i8* %329, i32 0, i32 3, i32 1) #19
  %330 = getelementptr inbounds i32, i32* %322, i64 %325
  %331 = bitcast i32* %330 to i8*
  call void @llvm.prefetch(i8* %331, i32 0, i32 3, i32 1) #19
  %332 = getelementptr inbounds i32, i32* %330, i64 4
  %333 = bitcast i32* %332 to i8*
  call void @llvm.prefetch(i8* %333, i32 0, i32 3, i32 1) #19
  %334 = icmp slt i32 %317, 8
  br i1 %334, label %337, label %342

335:                                              ; preds = %342
  %336 = trunc i64 %350 to i32
  br label %337

337:                                              ; preds = %335, %316
  %338 = phi i32 [ %317, %316 ], [ %405, %335 ]
  %339 = phi i32 [ 0, %316 ], [ %336, %335 ]
  %340 = add nsw i32 %338, -4
  %341 = icmp sgt i32 %339, %340
  br i1 %341, label %413, label %417

342:                                              ; preds = %316, %409
  %343 = phi i32* [ %412, %409 ], [ %326, %316 ]
  %344 = phi i32 [ %411, %409 ], [ %323, %316 ]
  %345 = phi i32* [ %410, %409 ], [ %322, %316 ]
  %346 = phi i64 [ %350, %409 ], [ 0, %316 ]
  %347 = load i32, i32* %129, align 4
  %348 = trunc i64 %346 to i32
  %349 = add nsw i32 %347, %348
  %350 = add nuw i64 %346, 8
  %351 = mul nsw i32 %344, %320
  %352 = sext i32 %351 to i64
  %353 = getelementptr inbounds i32, i32* %343, i64 %350
  %354 = bitcast i32* %353 to i8*
  call void @llvm.prefetch(i8* %354, i32 0, i32 3, i32 1) #19
  %355 = getelementptr inbounds i32, i32* %353, i64 4
  %356 = bitcast i32* %355 to i8*
  call void @llvm.prefetch(i8* %356, i32 0, i32 3, i32 1) #19
  %357 = getelementptr inbounds i32, i32* %345, i64 %350
  %358 = getelementptr inbounds i32, i32* %357, i64 %352
  %359 = bitcast i32* %358 to i8*
  call void @llvm.prefetch(i8* %359, i32 0, i32 3, i32 1) #19
  %360 = getelementptr inbounds i32, i32* %358, i64 4
  %361 = bitcast i32* %360 to i8*
  call void @llvm.prefetch(i8* %361, i32 0, i32 3, i32 1) #19
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %130)
  %362 = getelementptr inbounds i32, i32* %345, i64 %346
  %363 = getelementptr inbounds i32, i32* %362, i64 %352
  %364 = getelementptr inbounds i32, i32* %363, i64 1
  %365 = getelementptr inbounds i32, i32* %364, i64 1
  %366 = getelementptr inbounds i32, i32* %365, i64 1
  %367 = getelementptr inbounds i32, i32* %366, i64 1
  %368 = bitcast i32* %363 to <4 x i32>*
  %369 = load <4 x i32>, <4 x i32>* %368, align 4, !noalias !1538
  %370 = getelementptr inbounds i32, i32* %367, i64 1
  %371 = load i32, i32* %367, align 4, !noalias !1538
  %372 = getelementptr inbounds i32, i32* %370, i64 1
  %373 = load i32, i32* %370, align 4, !noalias !1538
  %374 = getelementptr inbounds i32, i32* %372, i64 1
  %375 = load i32, i32* %372, align 4, !noalias !1538
  %376 = load i32, i32* %374, align 4, !noalias !1538
  %377 = getelementptr i32, i32* %343, i64 %346
  %378 = bitcast i32* %377 to <4 x i32>*
  %379 = load <4 x i32>, <4 x i32>* %378, align 4
  %380 = getelementptr inbounds i32, i32* %377, i64 4
  %381 = bitcast i32* %380 to <4 x i32>*
  %382 = load <4 x i32>, <4 x i32>* %381, align 4
  %383 = load i32*, i32** %51, align 8
  %384 = getelementptr inbounds i32, i32* %383, i64 %318
  %385 = load i32, i32* %384, align 4
  %386 = load i32, i32* %131, align 4
  %387 = load i32, i32* %132, align 4
  %388 = insertelement <4 x i32> undef, i32 %387, i32 0
  %389 = shufflevector <4 x i32> %388, <4 x i32> undef, <4 x i32> zeroinitializer
  %390 = mul nsw <4 x i32> %389, %379
  %391 = add nsw <4 x i32> %390, %369
  %392 = mul nsw <4 x i32> %389, %382
  %393 = insertelement <4 x i32> undef, i32 %371, i32 0
  %394 = insertelement <4 x i32> %393, i32 %373, i32 1
  %395 = insertelement <4 x i32> %394, i32 %375, i32 2
  %396 = insertelement <4 x i32> %395, i32 %376, i32 3
  %397 = add nsw <4 x i32> %392, %396
  %398 = mul nsw i32 %387, %3
  %399 = add nsw i32 %398, %385
  %400 = mul nsw i32 %399, %386
  %401 = insertelement <4 x i32> undef, i32 %400, i32 0
  %402 = shufflevector <4 x i32> %401, <4 x i32> undef, <4 x i32> zeroinitializer
  %403 = add nsw <4 x i32> %391, %402
  %404 = add nsw <4 x i32> %397, %402
  store <4 x i32> %403, <4 x i32>* %136, align 16
  store <4 x i32> %404, <4 x i32>* %137, align 16
  call void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi8ELi1EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE0EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.590"* nonnull %16, %"struct.gemmlowp::RegisterBlock.304"* nonnull byval(%"struct.gemmlowp::RegisterBlock.304") align 8 %10, %"class.gemmlowp::MatrixMap.479"* %0, i32 %349, i32 %321, i32 %349, i32 %321) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %130)
  %405 = load i32, i32* %47, align 4
  %406 = add nsw i32 %405, -8
  %407 = trunc i64 %350 to i32
  %408 = icmp slt i32 %406, %407
  br i1 %408, label %335, label %409

409:                                              ; preds = %342
  %410 = load i32*, i32** %21, align 8
  %411 = load i32, i32* %24, align 8
  %412 = load i32*, i32** %45, align 8
  br label %342

413:                                              ; preds = %417, %337
  %414 = phi i32 [ %338, %337 ], [ %422, %417 ]
  %415 = phi i32 [ %339, %337 ], [ %421, %417 ]
  %416 = icmp slt i32 %415, %414
  br i1 %416, label %425, label %432

417:                                              ; preds = %337, %417
  %418 = phi i32 [ %421, %417 ], [ %339, %337 ]
  %419 = load i32, i32* %129, align 4
  %420 = add nsw i32 %419, %418
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.582"* nonnull dereferenceable(40) %15, %"class.gemmlowp::MatrixMap.479"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %7, i32 %3, i32 %418, i32 %320, i32 %420, i32 %321, i32 %420, i32 %321)
  %421 = add nuw nsw i32 %418, 4
  %422 = load i32, i32* %47, align 4
  %423 = add nsw i32 %422, -4
  %424 = icmp sgt i32 %421, %423
  br i1 %424, label %413, label %417

425:                                              ; preds = %413, %425
  %426 = phi i32 [ %429, %425 ], [ %415, %413 ]
  %427 = load i32, i32* %129, align 4
  %428 = add nsw i32 %427, %426
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.574"* nonnull dereferenceable(40) %14, %"class.gemmlowp::MatrixMap.479"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %7, i32 %3, i32 %426, i32 %320, i32 %428, i32 %321, i32 %428, i32 %321)
  %429 = add nuw nsw i32 %426, 1
  %430 = load i32, i32* %47, align 4
  %431 = icmp slt i32 %429, %430
  br i1 %431, label %425, label %432

432:                                              ; preds = %425, %413
  %433 = phi i32 [ %414, %413 ], [ %430, %425 ]
  %434 = add nuw nsw i64 %318, 1
  %435 = load i32, i32* %53, align 4
  %436 = trunc i64 %434 to i32
  %437 = icmp sgt i32 %435, %436
  br i1 %437, label %316, label %438

438:                                              ; preds = %432, %123
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %106) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %98) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %90) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %82) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %74) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %56) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %50) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %44) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %20) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.614"* dereferenceable(40), %"class.gemmlowp::MatrixMap.479"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.302", align 16
  %16 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %16) #19
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %18 = sext i32 %8 to i64
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %20 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %20, i8 -86, i64 128, i1 false)
  %21 = load i32*, i32** %17, align 8, !noalias !1543
  %22 = getelementptr inbounds i32, i32* %21, i64 %18
  %23 = load i32, i32* %19, align 8, !noalias !1543
  %24 = mul nsw i32 %23, %9
  %25 = sext i32 %24 to i64
  %26 = getelementptr inbounds i32, i32* %22, i64 %25
  %27 = getelementptr inbounds i32, i32* %26, i64 1
  %28 = load i32, i32* %26, align 4
  %29 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 0
  store i32 %28, i32* %29, align 16, !alias.scope !1543
  %30 = getelementptr inbounds i32, i32* %27, i64 1
  %31 = load i32, i32* %27, align 4
  %32 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 1
  store i32 %31, i32* %32, align 4, !alias.scope !1543
  %33 = getelementptr inbounds i32, i32* %30, i64 1
  %34 = load i32, i32* %30, align 4
  %35 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 2
  store i32 %34, i32* %35, align 8, !alias.scope !1543
  %36 = getelementptr inbounds i32, i32* %33, i64 1
  %37 = load i32, i32* %33, align 4
  %38 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 3
  store i32 %37, i32* %38, align 4, !alias.scope !1543
  %39 = getelementptr inbounds i32, i32* %36, i64 1
  %40 = load i32, i32* %36, align 4
  %41 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 4
  store i32 %40, i32* %41, align 16, !alias.scope !1543
  %42 = getelementptr inbounds i32, i32* %39, i64 1
  %43 = load i32, i32* %39, align 4
  %44 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 5
  store i32 %43, i32* %44, align 4, !alias.scope !1543
  %45 = getelementptr inbounds i32, i32* %42, i64 1
  %46 = load i32, i32* %42, align 4
  %47 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 6
  store i32 %46, i32* %47, align 8, !alias.scope !1543
  %48 = load i32, i32* %45, align 4
  %49 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 7
  store i32 %48, i32* %49, align 4, !alias.scope !1543
  %50 = add nsw i32 %9, 1
  %51 = mul nsw i32 %23, %50
  %52 = sext i32 %51 to i64
  %53 = getelementptr inbounds i32, i32* %22, i64 %52
  %54 = getelementptr inbounds i32, i32* %53, i64 1
  %55 = load i32, i32* %53, align 4
  %56 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 8
  store i32 %55, i32* %56, align 16, !alias.scope !1543
  %57 = getelementptr inbounds i32, i32* %54, i64 1
  %58 = load i32, i32* %54, align 4
  %59 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 9
  store i32 %58, i32* %59, align 4, !alias.scope !1543
  %60 = getelementptr inbounds i32, i32* %57, i64 1
  %61 = load i32, i32* %57, align 4
  %62 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 10
  store i32 %61, i32* %62, align 8, !alias.scope !1543
  %63 = getelementptr inbounds i32, i32* %60, i64 1
  %64 = load i32, i32* %60, align 4
  %65 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 11
  store i32 %64, i32* %65, align 4, !alias.scope !1543
  %66 = getelementptr inbounds i32, i32* %63, i64 1
  %67 = load i32, i32* %63, align 4
  %68 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 12
  store i32 %67, i32* %68, align 16, !alias.scope !1543
  %69 = getelementptr inbounds i32, i32* %66, i64 1
  %70 = load i32, i32* %66, align 4
  %71 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 13
  store i32 %70, i32* %71, align 4, !alias.scope !1543
  %72 = getelementptr inbounds i32, i32* %69, i64 1
  %73 = load i32, i32* %69, align 4
  %74 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 14
  store i32 %73, i32* %74, align 8, !alias.scope !1543
  %75 = load i32, i32* %72, align 4
  %76 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 15
  store i32 %75, i32* %76, align 4, !alias.scope !1543
  %77 = add nsw i32 %9, 2
  %78 = mul nsw i32 %23, %77
  %79 = sext i32 %78 to i64
  %80 = getelementptr inbounds i32, i32* %22, i64 %79
  %81 = getelementptr inbounds i32, i32* %80, i64 1
  %82 = load i32, i32* %80, align 4
  %83 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 16
  store i32 %82, i32* %83, align 16, !alias.scope !1543
  %84 = getelementptr inbounds i32, i32* %81, i64 1
  %85 = load i32, i32* %81, align 4
  %86 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 17
  store i32 %85, i32* %86, align 4, !alias.scope !1543
  %87 = getelementptr inbounds i32, i32* %84, i64 1
  %88 = load i32, i32* %84, align 4
  %89 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 18
  store i32 %88, i32* %89, align 8, !alias.scope !1543
  %90 = getelementptr inbounds i32, i32* %87, i64 1
  %91 = load i32, i32* %87, align 4
  %92 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 19
  store i32 %91, i32* %92, align 4, !alias.scope !1543
  %93 = getelementptr inbounds i32, i32* %90, i64 1
  %94 = load i32, i32* %90, align 4
  %95 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 20
  store i32 %94, i32* %95, align 16, !alias.scope !1543
  %96 = getelementptr inbounds i32, i32* %93, i64 1
  %97 = load i32, i32* %93, align 4
  %98 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 21
  store i32 %97, i32* %98, align 4, !alias.scope !1543
  %99 = getelementptr inbounds i32, i32* %96, i64 1
  %100 = load i32, i32* %96, align 4
  %101 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 22
  store i32 %100, i32* %101, align 8, !alias.scope !1543
  %102 = load i32, i32* %99, align 4
  %103 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 23
  store i32 %102, i32* %103, align 4, !alias.scope !1543
  %104 = add nsw i32 %9, 3
  %105 = mul nsw i32 %23, %104
  %106 = sext i32 %105 to i64
  %107 = getelementptr inbounds i32, i32* %22, i64 %106
  %108 = getelementptr inbounds i32, i32* %107, i64 1
  %109 = load i32, i32* %107, align 4
  %110 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 24
  store i32 %109, i32* %110, align 16, !alias.scope !1543
  %111 = getelementptr inbounds i32, i32* %108, i64 1
  %112 = load i32, i32* %108, align 4
  %113 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 25
  store i32 %112, i32* %113, align 4, !alias.scope !1543
  %114 = getelementptr inbounds i32, i32* %111, i64 1
  %115 = load i32, i32* %111, align 4
  %116 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 26
  store i32 %115, i32* %116, align 8, !alias.scope !1543
  %117 = getelementptr inbounds i32, i32* %114, i64 1
  %118 = load i32, i32* %114, align 4
  %119 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 27
  store i32 %118, i32* %119, align 4, !alias.scope !1543
  %120 = getelementptr inbounds i32, i32* %117, i64 1
  %121 = load i32, i32* %117, align 4
  %122 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 28
  store i32 %121, i32* %122, align 16, !alias.scope !1543
  %123 = getelementptr inbounds i32, i32* %120, i64 1
  %124 = load i32, i32* %120, align 4
  %125 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 29
  store i32 %124, i32* %125, align 4, !alias.scope !1543
  %126 = getelementptr inbounds i32, i32* %123, i64 1
  %127 = load i32, i32* %123, align 4
  %128 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 30
  store i32 %127, i32* %128, align 8, !alias.scope !1543
  %129 = load i32, i32* %126, align 4
  %130 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %15, i64 0, i32 0, i32 0, i64 31
  store i32 %129, i32* %130, align 4, !alias.scope !1543
  %131 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %132 = load i32*, i32** %131, align 8, !noalias !1546
  %133 = getelementptr i32, i32* %132, i64 %18
  %134 = bitcast i32* %133 to <4 x i32>*
  %135 = load <4 x i32>, <4 x i32>* %134, align 4
  %136 = getelementptr inbounds i32, i32* %133, i64 4
  %137 = bitcast i32* %136 to <4 x i32>*
  %138 = load <4 x i32>, <4 x i32>* %137, align 4
  %139 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %140 = load i32*, i32** %139, align 8
  %141 = sext i32 %9 to i64
  %142 = getelementptr i32, i32* %140, i64 %141
  %143 = bitcast i32* %142 to i64*
  %144 = load i64, i64* %143, align 4
  %145 = getelementptr inbounds i32, i32* %142, i64 2
  %146 = bitcast i32* %145 to i64*
  %147 = load i64, i64* %146, align 4
  %148 = lshr i64 %144, 32
  %149 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %150 = load i32, i32* %149, align 4
  %151 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %6, i64 0, i32 0
  %152 = load i32, i32* %151, align 4
  %153 = insertelement <4 x i32> undef, i32 %152, i32 0
  %154 = shufflevector <4 x i32> %153, <4 x i32> undef, <4 x i32> zeroinitializer
  %155 = mul nsw <4 x i32> %154, %135
  %156 = mul nsw <4 x i32> %154, %138
  %157 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to <4 x i32>*
  %158 = load <4 x i32>, <4 x i32>* %157, align 16
  %159 = add nsw <4 x i32> %158, %155
  %160 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to <4 x i32>*
  store <4 x i32> %159, <4 x i32>* %160, align 16
  %161 = bitcast i32* %41 to <4 x i32>*
  %162 = load <4 x i32>, <4 x i32>* %161, align 16
  %163 = add nsw <4 x i32> %162, %156
  %164 = bitcast i32* %41 to <4 x i32>*
  store <4 x i32> %163, <4 x i32>* %164, align 16
  %165 = bitcast i32* %56 to <4 x i32>*
  %166 = load <4 x i32>, <4 x i32>* %165, align 16
  %167 = add nsw <4 x i32> %166, %155
  %168 = bitcast i32* %56 to <4 x i32>*
  store <4 x i32> %167, <4 x i32>* %168, align 16
  %169 = bitcast i32* %68 to <4 x i32>*
  %170 = load <4 x i32>, <4 x i32>* %169, align 16
  %171 = add nsw <4 x i32> %170, %156
  %172 = bitcast i32* %68 to <4 x i32>*
  store <4 x i32> %171, <4 x i32>* %172, align 16
  %173 = bitcast i32* %83 to <4 x i32>*
  %174 = load <4 x i32>, <4 x i32>* %173, align 16
  %175 = add nsw <4 x i32> %174, %155
  %176 = bitcast i32* %83 to <4 x i32>*
  store <4 x i32> %175, <4 x i32>* %176, align 16
  %177 = bitcast i32* %95 to <4 x i32>*
  %178 = load <4 x i32>, <4 x i32>* %177, align 16
  %179 = add nsw <4 x i32> %178, %156
  %180 = bitcast i32* %95 to <4 x i32>*
  store <4 x i32> %179, <4 x i32>* %180, align 16
  %181 = bitcast i32* %110 to <4 x i32>*
  %182 = load <4 x i32>, <4 x i32>* %181, align 16
  %183 = add nsw <4 x i32> %182, %155
  %184 = bitcast i32* %110 to <4 x i32>*
  store <4 x i32> %183, <4 x i32>* %184, align 16
  %185 = bitcast i32* %122 to <4 x i32>*
  %186 = load <4 x i32>, <4 x i32>* %185, align 16
  %187 = add nsw <4 x i32> %186, %156
  %188 = bitcast i32* %122 to <4 x i32>*
  store <4 x i32> %187, <4 x i32>* %188, align 16
  %189 = trunc i64 %144 to i32
  %190 = trunc i64 %148 to i32
  %191 = mul nsw i32 %152, %7
  %192 = add nsw i32 %191, %189
  %193 = add nsw i32 %191, %190
  %194 = trunc i64 %147 to i32
  %195 = add nsw i32 %191, %194
  %196 = lshr i64 %147, 32
  %197 = trunc i64 %196 to i32
  %198 = add nsw i32 %191, %197
  %199 = mul nsw i32 %192, %150
  %200 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to <4 x i32>*
  %201 = load <4 x i32>, <4 x i32>* %200, align 16
  %202 = insertelement <4 x i32> undef, i32 %199, i32 0
  %203 = shufflevector <4 x i32> %202, <4 x i32> undef, <4 x i32> zeroinitializer
  %204 = add nsw <4 x i32> %201, %203
  %205 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %15 to <4 x i32>*
  store <4 x i32> %204, <4 x i32>* %205, align 16
  %206 = bitcast i32* %41 to <4 x i32>*
  %207 = load <4 x i32>, <4 x i32>* %206, align 16
  %208 = add nsw <4 x i32> %207, %203
  %209 = bitcast i32* %41 to <4 x i32>*
  store <4 x i32> %208, <4 x i32>* %209, align 16
  %210 = mul nsw i32 %193, %150
  %211 = bitcast i32* %56 to <4 x i32>*
  %212 = load <4 x i32>, <4 x i32>* %211, align 16
  %213 = insertelement <4 x i32> undef, i32 %210, i32 0
  %214 = shufflevector <4 x i32> %213, <4 x i32> undef, <4 x i32> zeroinitializer
  %215 = add nsw <4 x i32> %212, %214
  %216 = bitcast i32* %56 to <4 x i32>*
  store <4 x i32> %215, <4 x i32>* %216, align 16
  %217 = bitcast i32* %68 to <4 x i32>*
  %218 = load <4 x i32>, <4 x i32>* %217, align 16
  %219 = add nsw <4 x i32> %218, %214
  %220 = bitcast i32* %68 to <4 x i32>*
  store <4 x i32> %219, <4 x i32>* %220, align 16
  %221 = mul nsw i32 %195, %150
  %222 = bitcast i32* %83 to <4 x i32>*
  %223 = load <4 x i32>, <4 x i32>* %222, align 16
  %224 = insertelement <4 x i32> undef, i32 %221, i32 0
  %225 = shufflevector <4 x i32> %224, <4 x i32> undef, <4 x i32> zeroinitializer
  %226 = add nsw <4 x i32> %223, %225
  %227 = bitcast i32* %83 to <4 x i32>*
  store <4 x i32> %226, <4 x i32>* %227, align 16
  %228 = bitcast i32* %95 to <4 x i32>*
  %229 = load <4 x i32>, <4 x i32>* %228, align 16
  %230 = add nsw <4 x i32> %229, %225
  %231 = bitcast i32* %95 to <4 x i32>*
  store <4 x i32> %230, <4 x i32>* %231, align 16
  %232 = mul nsw i32 %198, %150
  %233 = bitcast i32* %110 to <4 x i32>*
  %234 = load <4 x i32>, <4 x i32>* %233, align 16
  %235 = insertelement <4 x i32> undef, i32 %232, i32 0
  %236 = shufflevector <4 x i32> %235, <4 x i32> undef, <4 x i32> zeroinitializer
  %237 = add nsw <4 x i32> %234, %236
  %238 = bitcast i32* %110 to <4 x i32>*
  store <4 x i32> %237, <4 x i32>* %238, align 16
  %239 = bitcast i32* %122 to <4 x i32>*
  %240 = load <4 x i32>, <4 x i32>* %239, align 16
  %241 = add nsw <4 x i32> %240, %236
  %242 = bitcast i32* %122 to <4 x i32>*
  store <4 x i32> %241, <4 x i32>* %242, align 16
  tail call void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi8ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE0EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.614"* %1, %"struct.gemmlowp::RegisterBlock.302"* nonnull byval(%"struct.gemmlowp::RegisterBlock.302") align 8 %15, %"class.gemmlowp::MatrixMap.479"* %2, i32 %10, i32 %11, i32 %12, i32 %13)
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %16) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.606"* dereferenceable(40), %"class.gemmlowp::MatrixMap.479"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.563", align 2
  %16 = alloca %"struct.gemmlowp::RegisterBlock.312", align 8
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %18 = sext i32 %8 to i64
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %20 = load i32*, i32** %17, align 8, !noalias !1551
  %21 = getelementptr inbounds i32, i32* %20, i64 %18
  %22 = load i32, i32* %19, align 8, !noalias !1551
  %23 = mul nsw i32 %22, %9
  %24 = sext i32 %23 to i64
  %25 = getelementptr inbounds i32, i32* %21, i64 %24
  %26 = getelementptr inbounds i32, i32* %25, i64 1
  %27 = load i32, i32* %25, align 4, !noalias !1551
  %28 = getelementptr inbounds i32, i32* %26, i64 1
  %29 = load i32, i32* %26, align 4, !noalias !1551
  %30 = getelementptr inbounds i32, i32* %28, i64 1
  %31 = load i32, i32* %28, align 4, !noalias !1551
  %32 = load i32, i32* %30, align 4, !noalias !1551
  %33 = add nsw i32 %9, 1
  %34 = mul nsw i32 %22, %33
  %35 = sext i32 %34 to i64
  %36 = getelementptr inbounds i32, i32* %21, i64 %35
  %37 = getelementptr inbounds i32, i32* %36, i64 1
  %38 = load i32, i32* %36, align 4, !noalias !1551
  %39 = getelementptr inbounds i32, i32* %37, i64 1
  %40 = load i32, i32* %37, align 4, !noalias !1551
  %41 = getelementptr inbounds i32, i32* %39, i64 1
  %42 = load i32, i32* %39, align 4, !noalias !1551
  %43 = load i32, i32* %41, align 4, !noalias !1551
  %44 = add nsw i32 %9, 2
  %45 = mul nsw i32 %22, %44
  %46 = sext i32 %45 to i64
  %47 = getelementptr inbounds i32, i32* %21, i64 %46
  %48 = getelementptr inbounds i32, i32* %47, i64 1
  %49 = load i32, i32* %47, align 4, !noalias !1551
  %50 = getelementptr inbounds i32, i32* %48, i64 1
  %51 = load i32, i32* %48, align 4, !noalias !1551
  %52 = getelementptr inbounds i32, i32* %50, i64 1
  %53 = load i32, i32* %50, align 4, !noalias !1551
  %54 = load i32, i32* %52, align 4, !noalias !1551
  %55 = add nsw i32 %9, 3
  %56 = mul nsw i32 %22, %55
  %57 = sext i32 %56 to i64
  %58 = getelementptr inbounds i32, i32* %21, i64 %57
  %59 = getelementptr inbounds i32, i32* %58, i64 1
  %60 = load i32, i32* %58, align 4, !noalias !1551
  %61 = getelementptr inbounds i32, i32* %59, i64 1
  %62 = load i32, i32* %59, align 4, !noalias !1551
  %63 = getelementptr inbounds i32, i32* %61, i64 1
  %64 = load i32, i32* %61, align 4, !noalias !1551
  %65 = load i32, i32* %63, align 4, !noalias !1551
  %66 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %67 = load i32*, i32** %66, align 8
  %68 = getelementptr i32, i32* %67, i64 %18
  %69 = bitcast i32* %68 to i64*
  %70 = load i64, i64* %69, align 4
  %71 = getelementptr inbounds i32, i32* %68, i64 2
  %72 = bitcast i32* %71 to i64*
  %73 = load i64, i64* %72, align 4
  %74 = trunc i64 %70 to i32
  %75 = lshr i64 %70, 32
  %76 = trunc i64 %75 to i32
  %77 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %78 = load i32*, i32** %77, align 8
  %79 = sext i32 %9 to i64
  %80 = getelementptr i32, i32* %78, i64 %79
  %81 = bitcast i32* %80 to i64*
  %82 = load i64, i64* %81, align 4
  %83 = getelementptr inbounds i32, i32* %80, i64 2
  %84 = bitcast i32* %83 to i64*
  %85 = load i64, i64* %84, align 4
  %86 = trunc i64 %82 to i32
  %87 = lshr i64 %82, 32
  %88 = trunc i64 %87 to i32
  %89 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %90 = load i32, i32* %89, align 4
  %91 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %6, i64 0, i32 0
  %92 = load i32, i32* %91, align 4
  %93 = mul nsw i32 %92, %74
  %94 = add nsw i32 %93, %27
  %95 = mul nsw i32 %92, %76
  %96 = add nsw i32 %95, %29
  %97 = trunc i64 %73 to i32
  %98 = mul nsw i32 %92, %97
  %99 = add nsw i32 %98, %31
  %100 = lshr i64 %73, 32
  %101 = trunc i64 %100 to i32
  %102 = mul nsw i32 %92, %101
  %103 = add nsw i32 %102, %32
  %104 = add nsw i32 %93, %38
  %105 = add nsw i32 %95, %40
  %106 = add nsw i32 %98, %42
  %107 = add nsw i32 %102, %43
  %108 = add nsw i32 %93, %49
  %109 = add nsw i32 %95, %51
  %110 = add nsw i32 %98, %53
  %111 = add nsw i32 %102, %54
  %112 = add nsw i32 %93, %60
  %113 = add nsw i32 %95, %62
  %114 = add nsw i32 %98, %64
  %115 = add nsw i32 %102, %65
  %116 = mul nsw i32 %92, %7
  %117 = add nsw i32 %116, %86
  %118 = add nsw i32 %116, %88
  %119 = trunc i64 %85 to i32
  %120 = add nsw i32 %116, %119
  %121 = lshr i64 %85, 32
  %122 = trunc i64 %121 to i32
  %123 = add nsw i32 %116, %122
  %124 = mul nsw i32 %117, %90
  %125 = add nsw i32 %94, %124
  %126 = add nsw i32 %96, %124
  %127 = add nsw i32 %99, %124
  %128 = add nsw i32 %103, %124
  %129 = mul nsw i32 %118, %90
  %130 = add nsw i32 %104, %129
  %131 = add nsw i32 %105, %129
  %132 = add nsw i32 %106, %129
  %133 = add nsw i32 %107, %129
  %134 = mul nsw i32 %120, %90
  %135 = add nsw i32 %108, %134
  %136 = add nsw i32 %109, %134
  %137 = add nsw i32 %110, %134
  %138 = add nsw i32 %111, %134
  %139 = mul nsw i32 %123, %90
  %140 = add nsw i32 %112, %139
  %141 = add nsw i32 %113, %139
  %142 = add nsw i32 %114, %139
  %143 = add nsw i32 %115, %139
  %144 = bitcast %"struct.gemmlowp::RegisterBlock.312"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %144)
  %145 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %16, i64 0, i32 0, i32 0, i64 0
  store i32 %125, i32* %145, align 8
  %146 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %16, i64 0, i32 0, i32 0, i64 1
  store i32 %126, i32* %146, align 4
  %147 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %16, i64 0, i32 0, i32 0, i64 2
  store i32 %127, i32* %147, align 8
  %148 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %16, i64 0, i32 0, i32 0, i64 3
  store i32 %128, i32* %148, align 4
  %149 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %16, i64 0, i32 0, i32 0, i64 4
  store i32 %130, i32* %149, align 8
  %150 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %16, i64 0, i32 0, i32 0, i64 5
  store i32 %131, i32* %150, align 4
  %151 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %16, i64 0, i32 0, i32 0, i64 6
  store i32 %132, i32* %151, align 8
  %152 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %16, i64 0, i32 0, i32 0, i64 7
  store i32 %133, i32* %152, align 4
  %153 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %16, i64 0, i32 0, i32 0, i64 8
  store i32 %135, i32* %153, align 8
  %154 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %16, i64 0, i32 0, i32 0, i64 9
  store i32 %136, i32* %154, align 4
  %155 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %16, i64 0, i32 0, i32 0, i64 10
  store i32 %137, i32* %155, align 8
  %156 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %16, i64 0, i32 0, i32 0, i64 11
  store i32 %138, i32* %156, align 4
  %157 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %16, i64 0, i32 0, i32 0, i64 12
  store i32 %140, i32* %157, align 8
  %158 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %16, i64 0, i32 0, i32 0, i64 13
  store i32 %141, i32* %158, align 4
  %159 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %16, i64 0, i32 0, i32 0, i64 14
  store i32 %142, i32* %159, align 8
  %160 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %16, i64 0, i32 0, i32 0, i64 15
  store i32 %143, i32* %160, align 4
  %161 = bitcast %"struct.gemmlowp::RegisterBlock.563"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %161) #19
  %162 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.606", %"struct.gemmlowp::OutputPipelineExecutor.606"* %1, i64 0, i32 0
  call void @llvm.memset.p0i8.i64(i8* nonnull align 2 %161, i8 -86, i64 32, i1 false) #19
  call void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.563"* nonnull sret %15, %"struct.gemmlowp::OutputPipelineEvalImpl.607"* %162, %"struct.gemmlowp::RegisterBlock.312"* nonnull byval(%"struct.gemmlowp::RegisterBlock.312") align 8 %16, i32 %10, i32 %11) #19
  %163 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %15, i64 0, i32 0, i32 0, i64 0
  %164 = load i16, i16* %163, align 2
  %165 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %15, i64 0, i32 0, i32 0, i64 1
  %166 = load i16, i16* %165, align 2
  %167 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %15, i64 0, i32 0, i32 0, i64 2
  %168 = load i16, i16* %167, align 2
  %169 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %15, i64 0, i32 0, i32 0, i64 3
  %170 = load i16, i16* %169, align 2
  %171 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %15, i64 0, i32 0, i32 0, i64 4
  %172 = load i16, i16* %171, align 2
  %173 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %15, i64 0, i32 0, i32 0, i64 5
  %174 = load i16, i16* %173, align 2
  %175 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %15, i64 0, i32 0, i32 0, i64 6
  %176 = load i16, i16* %175, align 2
  %177 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %15, i64 0, i32 0, i32 0, i64 7
  %178 = load i16, i16* %177, align 2
  %179 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %15, i64 0, i32 0, i32 0, i64 8
  %180 = load i16, i16* %179, align 2
  %181 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %15, i64 0, i32 0, i32 0, i64 9
  %182 = load i16, i16* %181, align 2
  %183 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %15, i64 0, i32 0, i32 0, i64 10
  %184 = load i16, i16* %183, align 2
  %185 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %15, i64 0, i32 0, i32 0, i64 11
  %186 = load i16, i16* %185, align 2
  %187 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %15, i64 0, i32 0, i32 0, i64 12
  %188 = load i16, i16* %187, align 2
  %189 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %15, i64 0, i32 0, i32 0, i64 13
  %190 = load i16, i16* %189, align 2
  %191 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %15, i64 0, i32 0, i32 0, i64 14
  %192 = load i16, i16* %191, align 2
  %193 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %15, i64 0, i32 0, i32 0, i64 15
  %194 = load i16, i16* %193, align 2
  %195 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %2, i64 0, i32 0
  %196 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %2, i64 0, i32 3
  %197 = sext i32 %13 to i64
  %198 = sext i32 %12 to i64
  %199 = load i16*, i16** %195, align 8
  %200 = getelementptr inbounds i16, i16* %199, i64 %198
  %201 = load i32, i32* %196, align 8
  %202 = sext i32 %201 to i64
  %203 = mul nsw i64 %202, %197
  %204 = getelementptr inbounds i16, i16* %200, i64 %203
  store i16 %164, i16* %204, align 2
  %205 = add nsw i64 %197, 1
  %206 = load i16*, i16** %195, align 8
  %207 = getelementptr inbounds i16, i16* %206, i64 %198
  %208 = load i32, i32* %196, align 8
  %209 = sext i32 %208 to i64
  %210 = mul nsw i64 %205, %209
  %211 = getelementptr inbounds i16, i16* %207, i64 %210
  store i16 %172, i16* %211, align 2
  %212 = add nsw i64 %197, 2
  %213 = load i16*, i16** %195, align 8
  %214 = getelementptr inbounds i16, i16* %213, i64 %198
  %215 = load i32, i32* %196, align 8
  %216 = sext i32 %215 to i64
  %217 = mul nsw i64 %212, %216
  %218 = getelementptr inbounds i16, i16* %214, i64 %217
  store i16 %180, i16* %218, align 2
  %219 = add nsw i64 %197, 3
  %220 = load i16*, i16** %195, align 8
  %221 = getelementptr inbounds i16, i16* %220, i64 %198
  %222 = load i32, i32* %196, align 8
  %223 = sext i32 %222 to i64
  %224 = mul nsw i64 %219, %223
  %225 = getelementptr inbounds i16, i16* %221, i64 %224
  store i16 %188, i16* %225, align 2
  %226 = add nsw i64 %198, 1
  %227 = load i16*, i16** %195, align 8
  %228 = getelementptr inbounds i16, i16* %227, i64 %226
  %229 = load i32, i32* %196, align 8
  %230 = sext i32 %229 to i64
  %231 = mul nsw i64 %230, %197
  %232 = getelementptr inbounds i16, i16* %228, i64 %231
  store i16 %166, i16* %232, align 2
  %233 = load i16*, i16** %195, align 8
  %234 = getelementptr inbounds i16, i16* %233, i64 %226
  %235 = load i32, i32* %196, align 8
  %236 = sext i32 %235 to i64
  %237 = mul nsw i64 %205, %236
  %238 = getelementptr inbounds i16, i16* %234, i64 %237
  store i16 %174, i16* %238, align 2
  %239 = load i16*, i16** %195, align 8
  %240 = getelementptr inbounds i16, i16* %239, i64 %226
  %241 = load i32, i32* %196, align 8
  %242 = sext i32 %241 to i64
  %243 = mul nsw i64 %212, %242
  %244 = getelementptr inbounds i16, i16* %240, i64 %243
  store i16 %182, i16* %244, align 2
  %245 = load i16*, i16** %195, align 8
  %246 = getelementptr inbounds i16, i16* %245, i64 %226
  %247 = load i32, i32* %196, align 8
  %248 = sext i32 %247 to i64
  %249 = mul nsw i64 %219, %248
  %250 = getelementptr inbounds i16, i16* %246, i64 %249
  store i16 %190, i16* %250, align 2
  %251 = add nsw i64 %198, 2
  %252 = load i16*, i16** %195, align 8
  %253 = getelementptr inbounds i16, i16* %252, i64 %251
  %254 = load i32, i32* %196, align 8
  %255 = sext i32 %254 to i64
  %256 = mul nsw i64 %255, %197
  %257 = getelementptr inbounds i16, i16* %253, i64 %256
  store i16 %168, i16* %257, align 2
  %258 = load i16*, i16** %195, align 8
  %259 = getelementptr inbounds i16, i16* %258, i64 %251
  %260 = load i32, i32* %196, align 8
  %261 = sext i32 %260 to i64
  %262 = mul nsw i64 %205, %261
  %263 = getelementptr inbounds i16, i16* %259, i64 %262
  store i16 %176, i16* %263, align 2
  %264 = load i16*, i16** %195, align 8
  %265 = getelementptr inbounds i16, i16* %264, i64 %251
  %266 = load i32, i32* %196, align 8
  %267 = sext i32 %266 to i64
  %268 = mul nsw i64 %212, %267
  %269 = getelementptr inbounds i16, i16* %265, i64 %268
  store i16 %184, i16* %269, align 2
  %270 = load i16*, i16** %195, align 8
  %271 = getelementptr inbounds i16, i16* %270, i64 %251
  %272 = load i32, i32* %196, align 8
  %273 = sext i32 %272 to i64
  %274 = mul nsw i64 %219, %273
  %275 = getelementptr inbounds i16, i16* %271, i64 %274
  store i16 %192, i16* %275, align 2
  %276 = add nsw i64 %198, 3
  %277 = load i16*, i16** %195, align 8
  %278 = getelementptr inbounds i16, i16* %277, i64 %276
  %279 = load i32, i32* %196, align 8
  %280 = sext i32 %279 to i64
  %281 = mul nsw i64 %280, %197
  %282 = getelementptr inbounds i16, i16* %278, i64 %281
  store i16 %170, i16* %282, align 2
  %283 = load i16*, i16** %195, align 8
  %284 = getelementptr inbounds i16, i16* %283, i64 %276
  %285 = load i32, i32* %196, align 8
  %286 = sext i32 %285 to i64
  %287 = mul nsw i64 %205, %286
  %288 = getelementptr inbounds i16, i16* %284, i64 %287
  store i16 %178, i16* %288, align 2
  %289 = load i16*, i16** %195, align 8
  %290 = getelementptr inbounds i16, i16* %289, i64 %276
  %291 = load i32, i32* %196, align 8
  %292 = sext i32 %291 to i64
  %293 = mul nsw i64 %212, %292
  %294 = getelementptr inbounds i16, i16* %290, i64 %293
  store i16 %186, i16* %294, align 2
  %295 = load i16*, i16** %195, align 8
  %296 = getelementptr inbounds i16, i16* %295, i64 %276
  %297 = load i32, i32* %196, align 8
  %298 = sext i32 %297 to i64
  %299 = mul nsw i64 %219, %298
  %300 = getelementptr inbounds i16, i16* %296, i64 %299
  store i16 %194, i16* %300, align 2
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %161) #19
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %144)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.582"* dereferenceable(40), %"class.gemmlowp::MatrixMap.479"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %16 = sext i32 %8 to i64
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %18 = load i32*, i32** %15, align 8
  %19 = getelementptr inbounds i32, i32* %18, i64 %16
  %20 = load i32, i32* %17, align 8
  %21 = mul nsw i32 %20, %9
  %22 = sext i32 %21 to i64
  %23 = getelementptr inbounds i32, i32* %19, i64 %22
  %24 = getelementptr inbounds i32, i32* %23, i64 1
  %25 = load i32, i32* %23, align 4
  %26 = getelementptr inbounds i32, i32* %24, i64 1
  %27 = load i32, i32* %24, align 4
  %28 = getelementptr inbounds i32, i32* %26, i64 1
  %29 = load i32, i32* %26, align 4
  %30 = load i32, i32* %28, align 4
  %31 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %32 = load i32*, i32** %31, align 8
  %33 = getelementptr i32, i32* %32, i64 %16
  %34 = bitcast i32* %33 to i64*
  %35 = load i64, i64* %34, align 4
  %36 = getelementptr inbounds i32, i32* %33, i64 2
  %37 = bitcast i32* %36 to i64*
  %38 = load i64, i64* %37, align 4
  %39 = trunc i64 %35 to i32
  %40 = lshr i64 %35, 32
  %41 = trunc i64 %40 to i32
  %42 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %43 = load i32*, i32** %42, align 8
  %44 = sext i32 %9 to i64
  %45 = getelementptr inbounds i32, i32* %43, i64 %44
  %46 = load i32, i32* %45, align 4
  %47 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %48 = load i32, i32* %47, align 4
  %49 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %6, i64 0, i32 0
  %50 = load i32, i32* %49, align 4
  %51 = mul nsw i32 %50, %39
  %52 = add nsw i32 %51, %25
  %53 = mul nsw i32 %50, %41
  %54 = add nsw i32 %53, %27
  %55 = trunc i64 %38 to i32
  %56 = mul nsw i32 %50, %55
  %57 = add nsw i32 %56, %29
  %58 = lshr i64 %38, 32
  %59 = trunc i64 %58 to i32
  %60 = mul nsw i32 %50, %59
  %61 = add nsw i32 %60, %30
  %62 = mul nsw i32 %50, %7
  %63 = add nsw i32 %62, %46
  %64 = mul nsw i32 %63, %48
  %65 = add nsw i32 %52, %64
  %66 = add nsw i32 %54, %64
  %67 = add nsw i32 %57, %64
  %68 = zext i32 %67 to i64
  %69 = add nsw i32 %61, %64
  %70 = zext i32 %69 to i64
  %71 = shl nuw i64 %70, 32
  %72 = or i64 %71, %68
  %73 = zext i32 %66 to i64
  %74 = shl nuw i64 %73, 32
  %75 = zext i32 %65 to i64
  %76 = or i64 %74, %75
  %77 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.582", %"struct.gemmlowp::OutputPipelineExecutor.582"* %1, i64 0, i32 0, i32 0, i32 0
  %78 = load %"struct.gemmlowp::OutputStageBiasAddition"*, %"struct.gemmlowp::OutputStageBiasAddition"** %77, align 8
  %79 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition", %"struct.gemmlowp::OutputStageBiasAddition"* %78, i64 0, i32 0, i32 0
  %80 = load i32*, i32** %79, align 8
  %81 = sext i32 %10 to i64
  %82 = getelementptr i32, i32* %80, i64 %81
  %83 = bitcast i32* %82 to i64*
  %84 = load i64, i64* %83, align 4
  %85 = getelementptr inbounds i32, i32* %82, i64 2
  %86 = bitcast i32* %85 to i64*
  %87 = load i64, i64* %86, align 4
  %88 = and i64 %84, -4294967296
  %89 = add i64 %84, %75
  %90 = add i64 %87, %68
  %91 = and i64 %90, 4294967295
  %92 = and i64 %87, -4294967296
  %93 = add i64 %92, %72
  %94 = and i64 %93, -4294967296
  %95 = or i64 %94, %91
  %96 = add i64 %88, %76
  %97 = and i64 %96, -4294967296
  %98 = and i64 %89, 4294967295
  %99 = or i64 %97, %98
  %100 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.582", %"struct.gemmlowp::OutputPipelineExecutor.582"* %1, i64 0, i32 0, i32 1, i32 0, i32 0
  %101 = tail call { i64, i64 } @_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi4EEEE4EvalES3_(%"struct.gemmlowp::OutputStageEvalBufferImpl.231"* %100, i64 %99, i64 %95) #19
  %102 = extractvalue { i64, i64 } %101, 0
  %103 = extractvalue { i64, i64 } %101, 1
  %104 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.582", %"struct.gemmlowp::OutputPipelineExecutor.582"* %1, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %105 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %104, align 8
  %106 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %105, i64 0, i32 0
  %107 = load i32, i32* %106, align 4
  %108 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %105, i64 0, i32 1
  %109 = load i32, i32* %108, align 4
  %110 = trunc i64 %102 to i32
  %111 = icmp sgt i32 %107, %110
  %112 = select i1 %111, i32 %107, i32 %110
  %113 = icmp slt i32 %109, %112
  %114 = select i1 %113, i32 %109, i32 %112
  %115 = lshr i64 %102, 32
  %116 = trunc i64 %115 to i32
  %117 = icmp sgt i32 %107, %116
  %118 = select i1 %117, i32 %107, i32 %116
  %119 = icmp slt i32 %109, %118
  %120 = select i1 %119, i32 %109, i32 %118
  %121 = trunc i64 %103 to i32
  %122 = icmp sgt i32 %107, %121
  %123 = select i1 %122, i32 %107, i32 %121
  %124 = icmp slt i32 %109, %123
  %125 = select i1 %124, i32 %109, i32 %123
  %126 = lshr i64 %103, 32
  %127 = trunc i64 %126 to i32
  %128 = icmp sgt i32 %107, %127
  %129 = select i1 %128, i32 %107, i32 %127
  %130 = icmp slt i32 %109, %129
  %131 = select i1 %130, i32 %109, i32 %129
  %132 = icmp sgt i32 %114, -32768
  %133 = select i1 %132, i32 %114, i32 -32768
  %134 = icmp slt i32 %133, 32767
  %135 = select i1 %134, i32 %133, i32 32767
  %136 = icmp sgt i32 %120, -32768
  %137 = select i1 %136, i32 %120, i32 -32768
  %138 = icmp slt i32 %137, 32767
  %139 = select i1 %138, i32 %137, i32 32767
  %140 = icmp sgt i32 %125, -32768
  %141 = select i1 %140, i32 %125, i32 -32768
  %142 = icmp slt i32 %141, 32767
  %143 = select i1 %142, i32 %141, i32 32767
  %144 = icmp sgt i32 %131, -32768
  %145 = select i1 %144, i32 %131, i32 -32768
  %146 = icmp slt i32 %145, 32767
  %147 = select i1 %146, i32 %145, i32 32767
  %148 = trunc i32 %135 to i16
  %149 = trunc i32 %139 to i16
  %150 = trunc i32 %143 to i16
  %151 = trunc i32 %147 to i16
  %152 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %2, i64 0, i32 0
  %153 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %2, i64 0, i32 3
  %154 = sext i32 %12 to i64
  %155 = load i16*, i16** %152, align 8
  %156 = getelementptr inbounds i16, i16* %155, i64 %154
  %157 = load i32, i32* %153, align 8
  %158 = mul nsw i32 %157, %13
  %159 = sext i32 %158 to i64
  %160 = getelementptr inbounds i16, i16* %156, i64 %159
  store i16 %148, i16* %160, align 2
  %161 = add nsw i64 %154, 1
  %162 = load i16*, i16** %152, align 8
  %163 = getelementptr inbounds i16, i16* %162, i64 %161
  %164 = load i32, i32* %153, align 8
  %165 = mul nsw i32 %164, %13
  %166 = sext i32 %165 to i64
  %167 = getelementptr inbounds i16, i16* %163, i64 %166
  store i16 %149, i16* %167, align 2
  %168 = add nsw i64 %154, 2
  %169 = load i16*, i16** %152, align 8
  %170 = getelementptr inbounds i16, i16* %169, i64 %168
  %171 = load i32, i32* %153, align 8
  %172 = mul nsw i32 %171, %13
  %173 = sext i32 %172 to i64
  %174 = getelementptr inbounds i16, i16* %170, i64 %173
  store i16 %150, i16* %174, align 2
  %175 = add nsw i64 %154, 3
  %176 = load i16*, i16** %152, align 8
  %177 = getelementptr inbounds i16, i16* %176, i64 %175
  %178 = load i32, i32* %153, align 8
  %179 = mul nsw i32 %178, %13
  %180 = sext i32 %179 to i64
  %181 = getelementptr inbounds i16, i16* %177, i64 %180
  store i16 %151, i16* %181, align 2
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISB_LSF_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKSN_RKNSM_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.574"* dereferenceable(40), %"class.gemmlowp::MatrixMap.479"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %16 = load i32*, i32** %15, align 8
  %17 = sext i32 %8 to i64
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %19 = load i32, i32* %18, align 8
  %20 = getelementptr inbounds i32, i32* %16, i64 %17
  %21 = mul nsw i32 %19, %9
  %22 = sext i32 %21 to i64
  %23 = getelementptr inbounds i32, i32* %20, i64 %22
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %26 = load i32*, i32** %25, align 8
  %27 = getelementptr inbounds i32, i32* %26, i64 %17
  %28 = load i32, i32* %27, align 4
  %29 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %30 = load i32*, i32** %29, align 8
  %31 = sext i32 %9 to i64
  %32 = getelementptr inbounds i32, i32* %30, i64 %31
  %33 = load i32, i32* %32, align 4
  %34 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %35 = load i32, i32* %34, align 4
  %36 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %6, i64 0, i32 0
  %37 = load i32, i32* %36, align 4
  %38 = mul nsw i32 %37, %28
  %39 = add nsw i32 %38, %24
  %40 = mul nsw i32 %37, %7
  %41 = add nsw i32 %40, %33
  %42 = mul nsw i32 %41, %35
  %43 = add nsw i32 %39, %42
  %44 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.574", %"struct.gemmlowp::OutputPipelineExecutor.574"* %1, i64 0, i32 0, i32 0, i32 0
  %45 = load %"struct.gemmlowp::OutputStageBiasAddition"*, %"struct.gemmlowp::OutputStageBiasAddition"** %44, align 8
  %46 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition", %"struct.gemmlowp::OutputStageBiasAddition"* %45, i64 0, i32 0, i32 0
  %47 = load i32*, i32** %46, align 8
  %48 = sext i32 %10 to i64
  %49 = getelementptr inbounds i32, i32* %47, i64 %48
  %50 = load i32, i32* %49, align 4
  %51 = add nsw i32 %43, %50
  %52 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.574", %"struct.gemmlowp::OutputPipelineExecutor.574"* %1, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %53 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %52, align 8
  %54 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %53, i64 0, i32 2
  %55 = load i32, i32* %54, align 4
  %56 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.574", %"struct.gemmlowp::OutputPipelineExecutor.574"* %1, i64 0, i32 0, i32 1, i32 0, i32 0, i32 1
  %57 = load i32, i32* %56, align 8
  %58 = sext i32 %51 to i64
  %59 = shl i32 1, %57
  %60 = sext i32 %59 to i64
  %61 = mul nsw i64 %60, %58
  %62 = icmp slt i64 %61, 2147483647
  %63 = select i1 %62, i64 %61, i64 2147483647
  %64 = icmp sgt i64 %63, -2147483648
  %65 = select i1 %64, i64 %63, i64 -2147483648
  %66 = trunc i64 %65 to i32
  %67 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %53, i64 0, i32 0
  %68 = load i32, i32* %67, align 4
  %69 = icmp ne i32 %68, %66
  %70 = icmp ne i32 %66, -2147483648
  %71 = or i1 %69, %70
  br i1 %71, label %72, label %81

72:                                               ; preds = %14
  %73 = sext i32 %68 to i64
  %74 = select i1 %69, i64 %73, i64 %65
  %75 = mul nsw i64 %74, %65
  %76 = icmp sgt i64 %75, -1
  %77 = select i1 %76, i64 1073741824, i64 -1073741823
  %78 = add nsw i64 %77, %75
  %79 = sdiv i64 %78, 2147483648
  %80 = trunc i64 %79 to i32
  br label %81

81:                                               ; preds = %14, %72
  %82 = phi i32 [ %80, %72 ], [ 2147483647, %14 ]
  %83 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.574", %"struct.gemmlowp::OutputPipelineExecutor.574"* %1, i64 0, i32 0, i32 1, i32 0, i32 0, i32 2
  %84 = load i32, i32* %83, align 4
  %85 = zext i32 %84 to i64
  %86 = shl nsw i64 -1, %85
  %87 = trunc i64 %86 to i32
  %88 = xor i32 %87, -1
  %89 = and i32 %82, %88
  %90 = ashr i32 %88, 1
  %91 = lshr i32 %82, 31
  %92 = add nsw i32 %90, %91
  %93 = ashr i32 %82, %84
  %94 = icmp sgt i32 %89, %92
  %95 = zext i1 %94 to i32
  %96 = add i32 %93, %55
  %97 = add i32 %96, %95
  %98 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.574", %"struct.gemmlowp::OutputPipelineExecutor.574"* %1, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %99 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %98, align 8
  %100 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %99, i64 0, i32 0
  %101 = load i32, i32* %100, align 4
  %102 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %99, i64 0, i32 1
  %103 = load i32, i32* %102, align 4
  %104 = icmp sgt i32 %101, %97
  %105 = select i1 %104, i32 %101, i32 %97
  %106 = icmp slt i32 %103, %105
  %107 = select i1 %106, i32 %103, i32 %105
  %108 = icmp sgt i32 %107, -32768
  %109 = select i1 %108, i32 %107, i32 -32768
  %110 = icmp slt i32 %109, 32767
  %111 = select i1 %110, i32 %109, i32 32767
  %112 = trunc i32 %111 to i16
  %113 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %2, i64 0, i32 0
  %114 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %2, i64 0, i32 3
  %115 = sext i32 %12 to i64
  %116 = load i16*, i16** %113, align 8
  %117 = getelementptr inbounds i16, i16* %116, i64 %115
  %118 = load i32, i32* %114, align 8
  %119 = mul nsw i32 %118, %13
  %120 = sext i32 %119 to i64
  %121 = getelementptr inbounds i16, i16* %117, i64 %120
  store i16 %112, i16* %121, align 2
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi8ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE0EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.614"*, %"struct.gemmlowp::RegisterBlock.302"* byval(%"struct.gemmlowp::RegisterBlock.302") align 8, %"class.gemmlowp::MatrixMap.479"*, i32, i32, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %8 = alloca %"struct.gemmlowp::RegisterBlock.561", align 8
  %9 = alloca %"struct.gemmlowp::RegisterBlock.302", align 16
  %10 = alloca %"struct.gemmlowp::RegisterBlock.561", align 2
  %11 = bitcast %"struct.gemmlowp::RegisterBlock.561"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %11) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 2 %11, i8 -86, i64 64, i1 false)
  %12 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %1 to <4 x i32>*
  %13 = load <4 x i32>, <4 x i32>* %12, align 8
  %14 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 4
  %15 = bitcast i32* %14 to <4 x i32>*
  %16 = load <4 x i32>, <4 x i32>* %15, align 8
  %17 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 8
  %18 = bitcast i32* %17 to <4 x i32>*
  %19 = load <4 x i32>, <4 x i32>* %18, align 8
  %20 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 12
  %21 = bitcast i32* %20 to <4 x i32>*
  %22 = load <4 x i32>, <4 x i32>* %21, align 8
  %23 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 16
  %24 = bitcast i32* %23 to <4 x i32>*
  %25 = load <4 x i32>, <4 x i32>* %24, align 8
  %26 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 20
  %27 = bitcast i32* %26 to <4 x i32>*
  %28 = load <4 x i32>, <4 x i32>* %27, align 8
  %29 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 24
  %30 = bitcast i32* %29 to <4 x i32>*
  %31 = load <4 x i32>, <4 x i32>* %30, align 8
  %32 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %1, i64 0, i32 0, i32 0, i64 28
  %33 = bitcast i32* %32 to <4 x i32>*
  %34 = load <4 x i32>, <4 x i32>* %33, align 8
  %35 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %35)
  %36 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.614", %"struct.gemmlowp::OutputPipelineExecutor.614"* %0, i64 0, i32 0, i32 0, i32 0
  %37 = load %"struct.gemmlowp::OutputStageBiasAddition"*, %"struct.gemmlowp::OutputStageBiasAddition"** %36, align 8, !noalias !1556
  %38 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition", %"struct.gemmlowp::OutputStageBiasAddition"* %37, i64 0, i32 0, i32 0
  %39 = load i32*, i32** %38, align 8, !noalias !1561
  %40 = sext i32 %3 to i64
  %41 = getelementptr i32, i32* %39, i64 %40
  %42 = bitcast i32* %41 to <4 x i32>*
  %43 = load <4 x i32>, <4 x i32>* %42, align 4, !noalias !1556
  %44 = getelementptr inbounds i32, i32* %41, i64 4
  %45 = bitcast i32* %44 to <4 x i32>*
  %46 = load <4 x i32>, <4 x i32>* %45, align 4, !noalias !1556
  %47 = add nsw <4 x i32> %43, %13
  %48 = add nsw <4 x i32> %46, %16
  %49 = add nsw <4 x i32> %43, %19
  %50 = add nsw <4 x i32> %46, %22
  %51 = add nsw <4 x i32> %43, %25
  %52 = add nsw <4 x i32> %46, %28
  %53 = add nsw <4 x i32> %43, %31
  %54 = add nsw <4 x i32> %46, %34
  %55 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.614", %"struct.gemmlowp::OutputPipelineExecutor.614"* %0, i64 0, i32 0, i32 1
  %56 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %9 to <4 x i32>*
  store <4 x i32> %47, <4 x i32>* %56, align 16, !noalias !1566
  %57 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %9, i64 0, i32 0, i32 0, i64 4
  %58 = bitcast i32* %57 to <4 x i32>*
  store <4 x i32> %48, <4 x i32>* %58, align 16, !noalias !1566
  %59 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %9, i64 0, i32 0, i32 0, i64 8
  %60 = bitcast i32* %59 to <4 x i32>*
  store <4 x i32> %49, <4 x i32>* %60, align 16, !noalias !1566
  %61 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %9, i64 0, i32 0, i32 0, i64 12
  %62 = bitcast i32* %61 to <4 x i32>*
  store <4 x i32> %50, <4 x i32>* %62, align 16, !noalias !1566
  %63 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %9, i64 0, i32 0, i32 0, i64 16
  %64 = bitcast i32* %63 to <4 x i32>*
  store <4 x i32> %51, <4 x i32>* %64, align 16, !noalias !1566
  %65 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %9, i64 0, i32 0, i32 0, i64 20
  %66 = bitcast i32* %65 to <4 x i32>*
  store <4 x i32> %52, <4 x i32>* %66, align 16, !noalias !1566
  %67 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %9, i64 0, i32 0, i32 0, i64 24
  %68 = bitcast i32* %67 to <4 x i32>*
  store <4 x i32> %53, <4 x i32>* %68, align 16, !noalias !1566
  %69 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %9, i64 0, i32 0, i32 0, i64 28
  %70 = bitcast i32* %69 to <4 x i32>*
  store <4 x i32> %54, <4 x i32>* %70, align 16, !noalias !1566
  call void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.561"* nonnull sret %10, %"struct.gemmlowp::OutputPipelineEvalImpl.616"* %55, %"struct.gemmlowp::RegisterBlock.302"* nonnull byval(%"struct.gemmlowp::RegisterBlock.302") align 8 %9, i32 %3, i32 %4) #19
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %35)
  %71 = bitcast %"struct.gemmlowp::RegisterBlock.561"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %71)
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %71, i8* nonnull align 2 %11, i64 64, i1 false)
  %72 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %2, i64 0, i32 0
  %73 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %2, i64 0, i32 3
  %74 = sext i32 %6 to i64
  %75 = sext i32 %5 to i64
  %76 = add nsw i64 %74, 1
  %77 = add nsw i64 %74, 2
  %78 = add nsw i64 %74, 3
  br label %79

79:                                               ; preds = %79, %7
  %80 = phi i64 [ 0, %7 ], [ %117, %79 ]
  %81 = add nsw i64 %80, %75
  %82 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.561", %"struct.gemmlowp::RegisterBlock.561"* %8, i64 0, i32 0, i32 0, i64 %80
  %83 = load i16, i16* %82, align 2
  %84 = load i16*, i16** %72, align 8
  %85 = getelementptr inbounds i16, i16* %84, i64 %81
  %86 = load i32, i32* %73, align 8
  %87 = sext i32 %86 to i64
  %88 = mul nsw i64 %87, %74
  %89 = getelementptr inbounds i16, i16* %85, i64 %88
  store i16 %83, i16* %89, align 2
  %90 = add nuw nsw i64 %80, 8
  %91 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.561", %"struct.gemmlowp::RegisterBlock.561"* %8, i64 0, i32 0, i32 0, i64 %90
  %92 = load i16, i16* %91, align 2
  %93 = load i16*, i16** %72, align 8
  %94 = getelementptr inbounds i16, i16* %93, i64 %81
  %95 = load i32, i32* %73, align 8
  %96 = sext i32 %95 to i64
  %97 = mul nsw i64 %76, %96
  %98 = getelementptr inbounds i16, i16* %94, i64 %97
  store i16 %92, i16* %98, align 2
  %99 = add nuw nsw i64 %80, 16
  %100 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.561", %"struct.gemmlowp::RegisterBlock.561"* %8, i64 0, i32 0, i32 0, i64 %99
  %101 = load i16, i16* %100, align 2
  %102 = load i16*, i16** %72, align 8
  %103 = getelementptr inbounds i16, i16* %102, i64 %81
  %104 = load i32, i32* %73, align 8
  %105 = sext i32 %104 to i64
  %106 = mul nsw i64 %77, %105
  %107 = getelementptr inbounds i16, i16* %103, i64 %106
  store i16 %101, i16* %107, align 2
  %108 = add nuw nsw i64 %80, 24
  %109 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.561", %"struct.gemmlowp::RegisterBlock.561"* %8, i64 0, i32 0, i32 0, i64 %108
  %110 = load i16, i16* %109, align 2
  %111 = load i16*, i16** %72, align 8
  %112 = getelementptr inbounds i16, i16* %111, i64 %81
  %113 = load i32, i32* %73, align 8
  %114 = sext i32 %113 to i64
  %115 = mul nsw i64 %78, %114
  %116 = getelementptr inbounds i16, i16* %112, i64 %115
  store i16 %110, i16* %116, align 2
  %117 = add nuw nsw i64 %80, 1
  %118 = icmp eq i64 %117, 8
  br i1 %118, label %119, label %79

119:                                              ; preds = %79
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %71)
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %11) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.561"* noalias sret, %"struct.gemmlowp::OutputPipelineEvalImpl.616"*, %"struct.gemmlowp::RegisterBlock.302"* byval(%"struct.gemmlowp::RegisterBlock.302") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %6 = alloca %"struct.gemmlowp::RegisterBuffer.303", align 16
  %7 = alloca %"struct.gemmlowp::RegisterBuffer.562", align 8
  %8 = alloca [32 x i16], align 2
  %9 = alloca %"struct.gemmlowp::RegisterBuffer.303", align 16
  %10 = alloca %"struct.gemmlowp::RegisterBuffer.303", align 16
  %11 = alloca [32 x i32], align 4
  %12 = alloca %"struct.gemmlowp::RegisterBuffer.303", align 8
  %13 = alloca %"struct.gemmlowp::RegisterBuffer.303", align 4
  %14 = alloca [32 x i32], align 4
  %15 = bitcast [32 x i32]* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %15)
  %16 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %2 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %15, i8 -86, i64 128, i1 false), !alias.scope !1567
  %17 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %17) #19, !noalias !1567
  %18 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %18) #19, !noalias !1567
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %18, i8* nonnull align 8 %16, i64 128, i1 false)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %17, i8 -86, i64 128, i1 false) #19, !alias.scope !1570, !noalias !1567
  %19 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.616", %"struct.gemmlowp::OutputPipelineEvalImpl.616"* %1, i64 0, i32 0, i32 0, i32 0
  %20 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %19, align 8, !noalias !1573
  %21 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %20, i64 0, i32 2
  %22 = load i32, i32* %21, align 4, !noalias !1573
  %23 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.616", %"struct.gemmlowp::OutputPipelineEvalImpl.616"* %1, i64 0, i32 0, i32 0, i32 1
  %24 = load i32, i32* %23, align 8, !noalias !1573
  %25 = shl i32 1, %24
  %26 = sext i32 %25 to i64
  %27 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %20, i64 0, i32 0
  %28 = load i32, i32* %27, align 4, !noalias !1573
  %29 = sext i32 %28 to i64
  %30 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.616", %"struct.gemmlowp::OutputPipelineEvalImpl.616"* %1, i64 0, i32 0, i32 0, i32 2
  %31 = load i32, i32* %30, align 4, !noalias !1573
  %32 = zext i32 %31 to i64
  %33 = shl nsw i64 -1, %32
  %34 = trunc i64 %33 to i32
  %35 = xor i32 %34, -1
  %36 = ashr i32 %35, 1
  %37 = icmp ne i32 %28, -2147483648
  br label %38

38:                                               ; preds = %59, %5
  %39 = phi i64 [ 0, %5 ], [ %70, %59 ]
  %40 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %12, i64 0, i32 0, i64 %39
  %41 = load i32, i32* %40, align 4, !noalias !1573
  %42 = sext i32 %41 to i64
  %43 = mul nsw i64 %42, %26
  %44 = icmp slt i64 %43, 2147483647
  %45 = select i1 %44, i64 %43, i64 2147483647
  %46 = icmp sgt i64 %45, -2147483648
  %47 = select i1 %46, i64 %45, i64 -2147483648
  %48 = trunc i64 %47 to i32
  %49 = icmp ne i32 %28, %48
  %50 = or i1 %37, %49
  br i1 %50, label %51, label %59

51:                                               ; preds = %38
  %52 = select i1 %49, i64 %29, i64 %47
  %53 = mul nsw i64 %52, %47
  %54 = icmp sgt i64 %53, -1
  %55 = select i1 %54, i64 1073741824, i64 -1073741823
  %56 = add nsw i64 %55, %53
  %57 = sdiv i64 %56, 2147483648
  %58 = trunc i64 %57 to i32
  br label %59

59:                                               ; preds = %51, %38
  %60 = phi i32 [ %58, %51 ], [ 2147483647, %38 ]
  %61 = and i32 %60, %35
  %62 = lshr i32 %60, 31
  %63 = add nsw i32 %62, %36
  %64 = ashr i32 %60, %31
  %65 = icmp sgt i32 %61, %63
  %66 = zext i1 %65 to i32
  %67 = add i32 %64, %22
  %68 = add i32 %67, %66
  %69 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %13, i64 0, i32 0, i64 %39
  store i32 %68, i32* %69, align 4, !alias.scope !1570, !noalias !1567
  %70 = add nuw nsw i64 %39, 1
  %71 = icmp eq i64 %70, 32
  br i1 %71, label %72, label %38

72:                                               ; preds = %59
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %18) #19, !noalias !1567
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 4 %15, i8* nonnull align 4 %17, i64 128, i1 false)
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %17) #19, !noalias !1567
  %73 = bitcast [32 x i32]* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %73)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %73, i8 -86, i64 128, i1 false), !alias.scope !1574, !noalias !1577
  %74 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %74) #19, !noalias !1580
  %75 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %75) #19, !noalias !1580
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %75, i8* nonnull align 4 %15, i64 128, i1 false)
  %76 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.616", %"struct.gemmlowp::OutputPipelineEvalImpl.616"* %1, i64 0, i32 1, i32 0, i32 0, i32 0
  %77 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %76, align 8, !noalias !1581
  %78 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %77, i64 0, i32 0
  %79 = load i32, i32* %78, align 4, !noalias !1581
  %80 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %77, i64 0, i32 1
  %81 = load i32, i32* %80, align 4, !noalias !1581
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %74, i8 -86, i64 128, i1 false) #19, !alias.scope !1584, !noalias !1580
  %82 = insertelement <4 x i32> undef, i32 %79, i32 0
  %83 = shufflevector <4 x i32> %82, <4 x i32> undef, <4 x i32> zeroinitializer
  %84 = insertelement <4 x i32> undef, i32 %81, i32 0
  %85 = shufflevector <4 x i32> %84, <4 x i32> undef, <4 x i32> zeroinitializer
  %86 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %9 to <4 x i32>*
  %87 = load <4 x i32>, <4 x i32>* %86, align 16, !noalias !1581
  %88 = icmp slt <4 x i32> %87, %83
  %89 = select <4 x i1> %88, <4 x i32> %83, <4 x i32> %87
  %90 = icmp slt <4 x i32> %85, %89
  %91 = select <4 x i1> %90, <4 x i32> %85, <4 x i32> %89
  %92 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %10 to <4 x i32>*
  store <4 x i32> %91, <4 x i32>* %92, align 16, !alias.scope !1584, !noalias !1580
  %93 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %9, i64 0, i32 0, i64 4
  %94 = bitcast i32* %93 to <4 x i32>*
  %95 = load <4 x i32>, <4 x i32>* %94, align 16, !noalias !1581
  %96 = icmp slt <4 x i32> %95, %83
  %97 = select <4 x i1> %96, <4 x i32> %83, <4 x i32> %95
  %98 = icmp slt <4 x i32> %85, %97
  %99 = select <4 x i1> %98, <4 x i32> %85, <4 x i32> %97
  %100 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %10, i64 0, i32 0, i64 4
  %101 = bitcast i32* %100 to <4 x i32>*
  store <4 x i32> %99, <4 x i32>* %101, align 16, !alias.scope !1584, !noalias !1580
  %102 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %9, i64 0, i32 0, i64 8
  %103 = bitcast i32* %102 to <4 x i32>*
  %104 = load <4 x i32>, <4 x i32>* %103, align 16, !noalias !1581
  %105 = icmp slt <4 x i32> %104, %83
  %106 = select <4 x i1> %105, <4 x i32> %83, <4 x i32> %104
  %107 = icmp slt <4 x i32> %85, %106
  %108 = select <4 x i1> %107, <4 x i32> %85, <4 x i32> %106
  %109 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %10, i64 0, i32 0, i64 8
  %110 = bitcast i32* %109 to <4 x i32>*
  store <4 x i32> %108, <4 x i32>* %110, align 16, !alias.scope !1584, !noalias !1580
  %111 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %9, i64 0, i32 0, i64 12
  %112 = bitcast i32* %111 to <4 x i32>*
  %113 = load <4 x i32>, <4 x i32>* %112, align 16, !noalias !1581
  %114 = icmp slt <4 x i32> %113, %83
  %115 = select <4 x i1> %114, <4 x i32> %83, <4 x i32> %113
  %116 = icmp slt <4 x i32> %85, %115
  %117 = select <4 x i1> %116, <4 x i32> %85, <4 x i32> %115
  %118 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %10, i64 0, i32 0, i64 12
  %119 = bitcast i32* %118 to <4 x i32>*
  store <4 x i32> %117, <4 x i32>* %119, align 16, !alias.scope !1584, !noalias !1580
  %120 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %9, i64 0, i32 0, i64 16
  %121 = bitcast i32* %120 to <4 x i32>*
  %122 = load <4 x i32>, <4 x i32>* %121, align 16, !noalias !1581
  %123 = icmp slt <4 x i32> %122, %83
  %124 = select <4 x i1> %123, <4 x i32> %83, <4 x i32> %122
  %125 = icmp slt <4 x i32> %85, %124
  %126 = select <4 x i1> %125, <4 x i32> %85, <4 x i32> %124
  %127 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %10, i64 0, i32 0, i64 16
  %128 = bitcast i32* %127 to <4 x i32>*
  store <4 x i32> %126, <4 x i32>* %128, align 16, !alias.scope !1584, !noalias !1580
  %129 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %9, i64 0, i32 0, i64 20
  %130 = bitcast i32* %129 to <4 x i32>*
  %131 = load <4 x i32>, <4 x i32>* %130, align 16, !noalias !1581
  %132 = icmp slt <4 x i32> %131, %83
  %133 = select <4 x i1> %132, <4 x i32> %83, <4 x i32> %131
  %134 = icmp slt <4 x i32> %85, %133
  %135 = select <4 x i1> %134, <4 x i32> %85, <4 x i32> %133
  %136 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %10, i64 0, i32 0, i64 20
  %137 = bitcast i32* %136 to <4 x i32>*
  store <4 x i32> %135, <4 x i32>* %137, align 16, !alias.scope !1584, !noalias !1580
  %138 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %9, i64 0, i32 0, i64 24
  %139 = bitcast i32* %138 to <4 x i32>*
  %140 = load <4 x i32>, <4 x i32>* %139, align 16, !noalias !1581
  %141 = icmp slt <4 x i32> %140, %83
  %142 = select <4 x i1> %141, <4 x i32> %83, <4 x i32> %140
  %143 = icmp slt <4 x i32> %85, %142
  %144 = select <4 x i1> %143, <4 x i32> %85, <4 x i32> %142
  %145 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %10, i64 0, i32 0, i64 24
  %146 = bitcast i32* %145 to <4 x i32>*
  store <4 x i32> %144, <4 x i32>* %146, align 16, !alias.scope !1584, !noalias !1580
  %147 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %9, i64 0, i32 0, i64 28
  %148 = bitcast i32* %147 to <4 x i32>*
  %149 = load <4 x i32>, <4 x i32>* %148, align 16, !noalias !1581
  %150 = icmp slt <4 x i32> %149, %83
  %151 = select <4 x i1> %150, <4 x i32> %83, <4 x i32> %149
  %152 = icmp slt <4 x i32> %85, %151
  %153 = select <4 x i1> %152, <4 x i32> %85, <4 x i32> %151
  %154 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %10, i64 0, i32 0, i64 28
  %155 = bitcast i32* %154 to <4 x i32>*
  store <4 x i32> %153, <4 x i32>* %155, align 16, !alias.scope !1584, !noalias !1580
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %75) #19, !noalias !1580
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 4 %73, i8* nonnull align 16 %74, i64 128, i1 false) #19, !noalias !1577
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %74) #19, !noalias !1580
  %156 = bitcast [32 x i16]* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %156)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 2 %156, i8 -86, i64 64, i1 false), !alias.scope !1585, !noalias !1588
  %157 = bitcast %"struct.gemmlowp::RegisterBuffer.562"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %157) #19, !noalias !1591
  %158 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %158) #19, !noalias !1591
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %158, i8* nonnull align 4 %73, i64 128, i1 false) #19, !noalias !1577
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %157, i8 -86, i64 64, i1 false) #19, !alias.scope !1592, !noalias !1591
  %159 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %6 to <4 x i32>*
  %160 = load <4 x i32>, <4 x i32>* %159, align 16, !noalias !1595
  %161 = icmp sgt <4 x i32> %160, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %162 = select <4 x i1> %161, <4 x i32> %160, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %163 = icmp slt <4 x i32> %162, <i32 32767, i32 32767, i32 32767, i32 32767>
  %164 = select <4 x i1> %163, <4 x i32> %162, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %165 = trunc <4 x i32> %164 to <4 x i16>
  %166 = bitcast %"struct.gemmlowp::RegisterBuffer.562"* %7 to <4 x i16>*
  store <4 x i16> %165, <4 x i16>* %166, align 8, !alias.scope !1592, !noalias !1591
  %167 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 4
  %168 = bitcast i32* %167 to <4 x i32>*
  %169 = load <4 x i32>, <4 x i32>* %168, align 16, !noalias !1595
  %170 = icmp sgt <4 x i32> %169, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %171 = select <4 x i1> %170, <4 x i32> %169, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %172 = icmp slt <4 x i32> %171, <i32 32767, i32 32767, i32 32767, i32 32767>
  %173 = select <4 x i1> %172, <4 x i32> %171, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %174 = trunc <4 x i32> %173 to <4 x i16>
  %175 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.562", %"struct.gemmlowp::RegisterBuffer.562"* %7, i64 0, i32 0, i64 4
  %176 = bitcast i16* %175 to <4 x i16>*
  store <4 x i16> %174, <4 x i16>* %176, align 8, !alias.scope !1592, !noalias !1591
  %177 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 8
  %178 = bitcast i32* %177 to <4 x i32>*
  %179 = load <4 x i32>, <4 x i32>* %178, align 16, !noalias !1595
  %180 = icmp sgt <4 x i32> %179, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %181 = select <4 x i1> %180, <4 x i32> %179, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %182 = icmp slt <4 x i32> %181, <i32 32767, i32 32767, i32 32767, i32 32767>
  %183 = select <4 x i1> %182, <4 x i32> %181, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %184 = trunc <4 x i32> %183 to <4 x i16>
  %185 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.562", %"struct.gemmlowp::RegisterBuffer.562"* %7, i64 0, i32 0, i64 8
  %186 = bitcast i16* %185 to <4 x i16>*
  store <4 x i16> %184, <4 x i16>* %186, align 8, !alias.scope !1592, !noalias !1591
  %187 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 12
  %188 = bitcast i32* %187 to <4 x i32>*
  %189 = load <4 x i32>, <4 x i32>* %188, align 16, !noalias !1595
  %190 = icmp sgt <4 x i32> %189, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %191 = select <4 x i1> %190, <4 x i32> %189, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %192 = icmp slt <4 x i32> %191, <i32 32767, i32 32767, i32 32767, i32 32767>
  %193 = select <4 x i1> %192, <4 x i32> %191, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %194 = trunc <4 x i32> %193 to <4 x i16>
  %195 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.562", %"struct.gemmlowp::RegisterBuffer.562"* %7, i64 0, i32 0, i64 12
  %196 = bitcast i16* %195 to <4 x i16>*
  store <4 x i16> %194, <4 x i16>* %196, align 8, !alias.scope !1592, !noalias !1591
  %197 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 16
  %198 = bitcast i32* %197 to <4 x i32>*
  %199 = load <4 x i32>, <4 x i32>* %198, align 16, !noalias !1595
  %200 = icmp sgt <4 x i32> %199, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %201 = select <4 x i1> %200, <4 x i32> %199, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %202 = icmp slt <4 x i32> %201, <i32 32767, i32 32767, i32 32767, i32 32767>
  %203 = select <4 x i1> %202, <4 x i32> %201, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %204 = trunc <4 x i32> %203 to <4 x i16>
  %205 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.562", %"struct.gemmlowp::RegisterBuffer.562"* %7, i64 0, i32 0, i64 16
  %206 = bitcast i16* %205 to <4 x i16>*
  store <4 x i16> %204, <4 x i16>* %206, align 8, !alias.scope !1592, !noalias !1591
  %207 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 20
  %208 = bitcast i32* %207 to <4 x i32>*
  %209 = load <4 x i32>, <4 x i32>* %208, align 16, !noalias !1595
  %210 = icmp sgt <4 x i32> %209, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %211 = select <4 x i1> %210, <4 x i32> %209, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %212 = icmp slt <4 x i32> %211, <i32 32767, i32 32767, i32 32767, i32 32767>
  %213 = select <4 x i1> %212, <4 x i32> %211, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %214 = trunc <4 x i32> %213 to <4 x i16>
  %215 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.562", %"struct.gemmlowp::RegisterBuffer.562"* %7, i64 0, i32 0, i64 20
  %216 = bitcast i16* %215 to <4 x i16>*
  store <4 x i16> %214, <4 x i16>* %216, align 8, !alias.scope !1592, !noalias !1591
  %217 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 24
  %218 = bitcast i32* %217 to <4 x i32>*
  %219 = load <4 x i32>, <4 x i32>* %218, align 16, !noalias !1595
  %220 = icmp sgt <4 x i32> %219, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %221 = select <4 x i1> %220, <4 x i32> %219, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %222 = icmp slt <4 x i32> %221, <i32 32767, i32 32767, i32 32767, i32 32767>
  %223 = select <4 x i1> %222, <4 x i32> %221, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %224 = trunc <4 x i32> %223 to <4 x i16>
  %225 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.562", %"struct.gemmlowp::RegisterBuffer.562"* %7, i64 0, i32 0, i64 24
  %226 = bitcast i16* %225 to <4 x i16>*
  store <4 x i16> %224, <4 x i16>* %226, align 8, !alias.scope !1592, !noalias !1591
  %227 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 28
  %228 = bitcast i32* %227 to <4 x i32>*
  %229 = load <4 x i32>, <4 x i32>* %228, align 16, !noalias !1595
  %230 = icmp sgt <4 x i32> %229, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %231 = select <4 x i1> %230, <4 x i32> %229, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %232 = icmp slt <4 x i32> %231, <i32 32767, i32 32767, i32 32767, i32 32767>
  %233 = select <4 x i1> %232, <4 x i32> %231, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %234 = trunc <4 x i32> %233 to <4 x i16>
  %235 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.562", %"struct.gemmlowp::RegisterBuffer.562"* %7, i64 0, i32 0, i64 28
  %236 = bitcast i16* %235 to <4 x i16>*
  store <4 x i16> %234, <4 x i16>* %236, align 8, !alias.scope !1592, !noalias !1591
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %158) #19, !noalias !1591
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 2 %156, i8* nonnull align 8 %157, i64 64, i1 false) #19, !noalias !1588
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %157) #19, !noalias !1591
  %237 = bitcast %"struct.gemmlowp::RegisterBlock.561"* %0 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 2 %237, i8* nonnull align 2 %156, i64 64, i1 false) #19
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %156)
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %73)
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %15)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.563"* noalias sret, %"struct.gemmlowp::OutputPipelineEvalImpl.607"*, %"struct.gemmlowp::RegisterBlock.312"* byval(%"struct.gemmlowp::RegisterBlock.312") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %6 = alloca %"struct.gemmlowp::RegisterBuffer.313", align 8
  %7 = alloca %"struct.gemmlowp::RegisterBuffer.313", align 8
  %8 = alloca [16 x i32], align 8
  %9 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 0
  %10 = load i32, i32* %9, align 8
  %11 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 1
  %12 = load i32, i32* %11, align 4
  %13 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 2
  %14 = load i32, i32* %13, align 8
  %15 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 3
  %16 = load i32, i32* %15, align 4
  %17 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 4
  %18 = load i32, i32* %17, align 8
  %19 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 5
  %20 = load i32, i32* %19, align 4
  %21 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 6
  %22 = load i32, i32* %21, align 8
  %23 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 7
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 8
  %26 = load i32, i32* %25, align 8
  %27 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 9
  %28 = load i32, i32* %27, align 4
  %29 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 10
  %30 = load i32, i32* %29, align 8
  %31 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 11
  %32 = load i32, i32* %31, align 4
  %33 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 12
  %34 = load i32, i32* %33, align 8
  %35 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 13
  %36 = load i32, i32* %35, align 4
  %37 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 14
  %38 = load i32, i32* %37, align 8
  %39 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 15
  %40 = load i32, i32* %39, align 4
  %41 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.607", %"struct.gemmlowp::OutputPipelineEvalImpl.607"* %1, i64 0, i32 0, i32 0
  %42 = load %"struct.gemmlowp::OutputStageBiasAddition"*, %"struct.gemmlowp::OutputStageBiasAddition"** %41, align 8, !noalias !1596
  %43 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition", %"struct.gemmlowp::OutputStageBiasAddition"* %42, i64 0, i32 0, i32 0
  %44 = load i32*, i32** %43, align 8, !noalias !1596
  %45 = sext i32 %3 to i64
  %46 = getelementptr i32, i32* %44, i64 %45
  %47 = bitcast i32* %46 to i64*
  %48 = load i64, i64* %47, align 4, !noalias !1596
  %49 = getelementptr inbounds i32, i32* %46, i64 2
  %50 = bitcast i32* %49 to i64*
  %51 = load i64, i64* %50, align 4, !noalias !1596
  %52 = trunc i64 %48 to i32
  %53 = lshr i64 %48, 32
  %54 = trunc i64 %53 to i32
  %55 = add nsw i32 %10, %52
  %56 = add nsw i32 %12, %54
  %57 = trunc i64 %51 to i32
  %58 = add nsw i32 %14, %57
  %59 = lshr i64 %51, 32
  %60 = trunc i64 %59 to i32
  %61 = add nsw i32 %16, %60
  %62 = add nsw i32 %18, %52
  %63 = add nsw i32 %20, %54
  %64 = add nsw i32 %22, %57
  %65 = add nsw i32 %24, %60
  %66 = add nsw i32 %26, %52
  %67 = add nsw i32 %28, %54
  %68 = add nsw i32 %30, %57
  %69 = add nsw i32 %32, %60
  %70 = add nsw i32 %34, %52
  %71 = add nsw i32 %36, %54
  %72 = add nsw i32 %38, %57
  %73 = add nsw i32 %40, %60
  %74 = bitcast [16 x i32]* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %74) #19, !noalias !1599
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %74, i8 -86, i64 64, i1 false) #19, !alias.scope !1602, !noalias !1599
  %75 = bitcast %"struct.gemmlowp::RegisterBuffer.313"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %75) #19, !noalias !1605
  %76 = bitcast %"struct.gemmlowp::RegisterBuffer.313"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %76) #19, !noalias !1605
  %77 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %6, i64 0, i32 0, i64 0
  store i32 %55, i32* %77, align 8, !noalias !1599
  %78 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %6, i64 0, i32 0, i64 1
  store i32 %56, i32* %78, align 4, !noalias !1599
  %79 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %6, i64 0, i32 0, i64 2
  store i32 %58, i32* %79, align 8, !noalias !1599
  %80 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %6, i64 0, i32 0, i64 3
  store i32 %61, i32* %80, align 4, !noalias !1599
  %81 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %6, i64 0, i32 0, i64 4
  store i32 %62, i32* %81, align 8, !noalias !1599
  %82 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %6, i64 0, i32 0, i64 5
  store i32 %63, i32* %82, align 4, !noalias !1599
  %83 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %6, i64 0, i32 0, i64 6
  store i32 %64, i32* %83, align 8, !noalias !1599
  %84 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %6, i64 0, i32 0, i64 7
  store i32 %65, i32* %84, align 4, !noalias !1599
  %85 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %6, i64 0, i32 0, i64 8
  store i32 %66, i32* %85, align 8, !noalias !1599
  %86 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %6, i64 0, i32 0, i64 9
  store i32 %67, i32* %86, align 4, !noalias !1599
  %87 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %6, i64 0, i32 0, i64 10
  store i32 %68, i32* %87, align 8, !noalias !1599
  %88 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %6, i64 0, i32 0, i64 11
  store i32 %69, i32* %88, align 4, !noalias !1599
  %89 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %6, i64 0, i32 0, i64 12
  store i32 %70, i32* %89, align 8, !noalias !1599
  %90 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %6, i64 0, i32 0, i64 13
  store i32 %71, i32* %90, align 4, !noalias !1599
  %91 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %6, i64 0, i32 0, i64 14
  store i32 %72, i32* %91, align 8, !noalias !1599
  %92 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %6, i64 0, i32 0, i64 15
  store i32 %73, i32* %92, align 4, !noalias !1599
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %75, i8 -86, i64 64, i1 false) #19, !alias.scope !1606, !noalias !1605
  %93 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.607", %"struct.gemmlowp::OutputPipelineEvalImpl.607"* %1, i64 0, i32 1, i32 0, i32 0, i32 0
  %94 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %93, align 8, !noalias !1609
  %95 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %94, i64 0, i32 2
  %96 = load i32, i32* %95, align 4, !noalias !1609
  %97 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.607", %"struct.gemmlowp::OutputPipelineEvalImpl.607"* %1, i64 0, i32 1, i32 0, i32 0, i32 1
  %98 = load i32, i32* %97, align 8, !noalias !1609
  %99 = shl i32 1, %98
  %100 = sext i32 %99 to i64
  %101 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %94, i64 0, i32 0
  %102 = load i32, i32* %101, align 4, !noalias !1609
  %103 = sext i32 %102 to i64
  %104 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.607", %"struct.gemmlowp::OutputPipelineEvalImpl.607"* %1, i64 0, i32 1, i32 0, i32 0, i32 2
  %105 = load i32, i32* %104, align 4, !noalias !1609
  %106 = zext i32 %105 to i64
  %107 = shl nsw i64 -1, %106
  %108 = trunc i64 %107 to i32
  %109 = xor i32 %108, -1
  %110 = ashr i32 %109, 1
  %111 = icmp ne i32 %102, -2147483648
  br label %112

112:                                              ; preds = %145, %5
  %113 = phi i32 [ %55, %5 ], [ %147, %145 ]
  %114 = phi i64 [ 0, %5 ], [ %143, %145 ]
  %115 = sext i32 %113 to i64
  %116 = mul nsw i64 %115, %100
  %117 = icmp slt i64 %116, 2147483647
  %118 = select i1 %117, i64 %116, i64 2147483647
  %119 = icmp sgt i64 %118, -2147483648
  %120 = select i1 %119, i64 %118, i64 -2147483648
  %121 = trunc i64 %120 to i32
  %122 = icmp ne i32 %102, %121
  %123 = or i1 %111, %122
  br i1 %123, label %124, label %132

124:                                              ; preds = %112
  %125 = select i1 %122, i64 %103, i64 %120
  %126 = mul nsw i64 %125, %120
  %127 = icmp sgt i64 %126, -1
  %128 = select i1 %127, i64 1073741824, i64 -1073741823
  %129 = add nsw i64 %128, %126
  %130 = sdiv i64 %129, 2147483648
  %131 = trunc i64 %130 to i32
  br label %132

132:                                              ; preds = %124, %112
  %133 = phi i32 [ %131, %124 ], [ 2147483647, %112 ]
  %134 = and i32 %133, %109
  %135 = lshr i32 %133, 31
  %136 = add nsw i32 %135, %110
  %137 = ashr i32 %133, %105
  %138 = icmp sgt i32 %134, %136
  %139 = zext i1 %138 to i32
  %140 = add i32 %137, %96
  %141 = add i32 %140, %139
  %142 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %7, i64 0, i32 0, i64 %114
  store i32 %141, i32* %142, align 4, !alias.scope !1606, !noalias !1605
  %143 = add nuw nsw i64 %114, 1
  %144 = icmp eq i64 %143, 16
  br i1 %144, label %148, label %145

145:                                              ; preds = %132
  %146 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %6, i64 0, i32 0, i64 %143
  %147 = load i32, i32* %146, align 4, !noalias !1609
  br label %112

148:                                              ; preds = %132
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %76) #19, !noalias !1605
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %74, i8* nonnull align 8 %75, i64 64, i1 false) #19, !noalias !1599
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %75) #19, !noalias !1605
  %149 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.607", %"struct.gemmlowp::OutputPipelineEvalImpl.607"* %1, i64 0, i32 1, i32 1
  %150 = bitcast [16 x i32]* %8 to %"struct.gemmlowp::RegisterBlock.312"*
  tail call void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.563"* sret %0, %"struct.gemmlowp::OutputPipelineEvalImpl.609"* %149, %"struct.gemmlowp::RegisterBlock.312"* nonnull byval(%"struct.gemmlowp::RegisterBlock.312") align 8 %150, i32 %3, i32 %4) #19
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %74) #19, !noalias !1599
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii(%"struct.gemmlowp::RegisterBlock.563"* noalias sret, %"struct.gemmlowp::OutputPipelineEvalImpl.609"*, %"struct.gemmlowp::RegisterBlock.312"* byval(%"struct.gemmlowp::RegisterBlock.312") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %6 = bitcast %"struct.gemmlowp::RegisterBlock.312"* %2 to <8 x i32>*
  %7 = load <8 x i32>, <8 x i32>* %6, align 8
  %8 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 8
  %9 = load i32, i32* %8, align 8
  %10 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 9
  %11 = load i32, i32* %10, align 4
  %12 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 10
  %13 = load i32, i32* %12, align 8
  %14 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 11
  %15 = load i32, i32* %14, align 4
  %16 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 12
  %17 = load i32, i32* %16, align 8
  %18 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 13
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 14
  %21 = load i32, i32* %20, align 8
  %22 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 15
  %23 = load i32, i32* %22, align 4
  %24 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.609", %"struct.gemmlowp::OutputPipelineEvalImpl.609"* %1, i64 0, i32 0, i32 0, i32 0
  %25 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %24, align 8, !noalias !1610
  %26 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %25, i64 0, i32 0
  %27 = load i32, i32* %26, align 4, !noalias !1610
  %28 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %25, i64 0, i32 1
  %29 = load i32, i32* %28, align 4, !noalias !1610
  %30 = insertelement <8 x i32> undef, i32 %27, i32 0
  %31 = shufflevector <8 x i32> %30, <8 x i32> undef, <8 x i32> zeroinitializer
  %32 = icmp slt <8 x i32> %7, %31
  %33 = select <8 x i1> %32, <8 x i32> %31, <8 x i32> %7
  %34 = insertelement <8 x i32> undef, i32 %29, i32 0
  %35 = shufflevector <8 x i32> %34, <8 x i32> undef, <8 x i32> zeroinitializer
  %36 = icmp slt <8 x i32> %35, %33
  %37 = select <8 x i1> %36, <8 x i32> %35, <8 x i32> %33
  %38 = icmp slt i32 %9, %27
  %39 = select i1 %38, i32 %27, i32 %9
  %40 = icmp slt i32 %29, %39
  %41 = select i1 %40, i32 %29, i32 %39
  %42 = icmp slt i32 %11, %27
  %43 = select i1 %42, i32 %27, i32 %11
  %44 = icmp slt i32 %29, %43
  %45 = select i1 %44, i32 %29, i32 %43
  %46 = icmp slt i32 %13, %27
  %47 = select i1 %46, i32 %27, i32 %13
  %48 = icmp slt i32 %29, %47
  %49 = select i1 %48, i32 %29, i32 %47
  %50 = icmp slt i32 %15, %27
  %51 = select i1 %50, i32 %27, i32 %15
  %52 = icmp slt i32 %29, %51
  %53 = select i1 %52, i32 %29, i32 %51
  %54 = icmp slt i32 %17, %27
  %55 = select i1 %54, i32 %27, i32 %17
  %56 = icmp slt i32 %29, %55
  %57 = select i1 %56, i32 %29, i32 %55
  %58 = icmp slt i32 %19, %27
  %59 = select i1 %58, i32 %27, i32 %19
  %60 = icmp slt i32 %29, %59
  %61 = select i1 %60, i32 %29, i32 %59
  %62 = icmp slt i32 %21, %27
  %63 = select i1 %62, i32 %27, i32 %21
  %64 = icmp slt i32 %29, %63
  %65 = select i1 %64, i32 %29, i32 %63
  %66 = icmp slt i32 %23, %27
  %67 = select i1 %66, i32 %27, i32 %23
  %68 = icmp slt i32 %29, %67
  %69 = select i1 %68, i32 %29, i32 %67
  %70 = icmp sgt <8 x i32> %37, <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %71 = select <8 x i1> %70, <8 x i32> %37, <8 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %72 = icmp slt <8 x i32> %71, <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>
  %73 = select <8 x i1> %72, <8 x i32> %71, <8 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>
  %74 = trunc <8 x i32> %73 to <8 x i16>
  %75 = icmp sgt i32 %41, -32768
  %76 = select i1 %75, i32 %41, i32 -32768
  %77 = icmp slt i32 %76, 32767
  %78 = select i1 %77, i32 %76, i32 32767
  %79 = trunc i32 %78 to i16
  %80 = icmp sgt i32 %45, -32768
  %81 = select i1 %80, i32 %45, i32 -32768
  %82 = icmp slt i32 %81, 32767
  %83 = select i1 %82, i32 %81, i32 32767
  %84 = trunc i32 %83 to i16
  %85 = icmp sgt i32 %49, -32768
  %86 = select i1 %85, i32 %49, i32 -32768
  %87 = icmp slt i32 %86, 32767
  %88 = select i1 %87, i32 %86, i32 32767
  %89 = trunc i32 %88 to i16
  %90 = icmp sgt i32 %53, -32768
  %91 = select i1 %90, i32 %53, i32 -32768
  %92 = icmp slt i32 %91, 32767
  %93 = select i1 %92, i32 %91, i32 32767
  %94 = trunc i32 %93 to i16
  %95 = icmp sgt i32 %57, -32768
  %96 = select i1 %95, i32 %57, i32 -32768
  %97 = icmp slt i32 %96, 32767
  %98 = select i1 %97, i32 %96, i32 32767
  %99 = icmp sgt i32 %61, -32768
  %100 = select i1 %99, i32 %61, i32 -32768
  %101 = icmp slt i32 %100, 32767
  %102 = select i1 %101, i32 %100, i32 32767
  %103 = shl nsw i32 %102, 16
  %104 = and i32 %98, 65535
  %105 = or i32 %103, %104
  %106 = zext i32 %105 to i64
  %107 = icmp sgt i32 %65, -32768
  %108 = select i1 %107, i32 %65, i32 -32768
  %109 = icmp slt i32 %108, 32767
  %110 = select i1 %109, i32 %108, i32 32767
  %111 = and i32 %110, 65535
  %112 = zext i32 %111 to i64
  %113 = shl nuw nsw i64 %112, 32
  %114 = icmp sgt i32 %69, -32768
  %115 = select i1 %114, i32 %69, i32 -32768
  %116 = icmp slt i32 %115, 32767
  %117 = select i1 %116, i32 %115, i32 32767
  %118 = zext i32 %117 to i64
  %119 = shl i64 %118, 48
  %120 = or i64 %119, %106
  %121 = or i64 %120, %113
  %122 = bitcast %"struct.gemmlowp::RegisterBlock.563"* %0 to <8 x i16>*
  store <8 x i16> %74, <8 x i16>* %122, align 2, !alias.scope !1615
  %123 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %0, i64 0, i32 0, i32 0, i64 8
  store i16 %79, i16* %123, align 2, !alias.scope !1615
  %124 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %0, i64 0, i32 0, i32 0, i64 9
  store i16 %84, i16* %124, align 2, !alias.scope !1615
  %125 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %0, i64 0, i32 0, i32 0, i64 10
  store i16 %89, i16* %125, align 2, !alias.scope !1615
  %126 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %0, i64 0, i32 0, i32 0, i64 11
  store i16 %94, i16* %126, align 2, !alias.scope !1615
  %127 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %0, i64 0, i32 0, i32 0, i64 12
  %128 = bitcast i16* %127 to i64*
  store i64 %121, i64* %128, align 2, !alias.scope !1615
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi1ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE0EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.598"*, i64, i64, %"class.gemmlowp::MatrixMap.479"*, i32, i32, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %9 = trunc i64 %1 to i32
  %10 = lshr i64 %1, 32
  %11 = trunc i64 %10 to i32
  %12 = trunc i64 %2 to i32
  %13 = lshr i64 %2, 32
  %14 = trunc i64 %13 to i32
  %15 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.598", %"struct.gemmlowp::OutputPipelineExecutor.598"* %0, i64 0, i32 0, i32 0, i32 0
  %16 = load %"struct.gemmlowp::OutputStageBiasAddition"*, %"struct.gemmlowp::OutputStageBiasAddition"** %15, align 8
  %17 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition", %"struct.gemmlowp::OutputStageBiasAddition"* %16, i64 0, i32 0, i32 0
  %18 = load i32*, i32** %17, align 8
  %19 = sext i32 %4 to i64
  %20 = getelementptr inbounds i32, i32* %18, i64 %19
  %21 = load i32, i32* %20, align 4
  %22 = add nsw i32 %21, %9
  %23 = add nsw i32 %21, %11
  %24 = add nsw i32 %21, %12
  %25 = zext i32 %24 to i64
  %26 = add nsw i32 %21, %14
  %27 = zext i32 %26 to i64
  %28 = shl nuw i64 %27, 32
  %29 = or i64 %28, %25
  %30 = zext i32 %23 to i64
  %31 = shl nuw i64 %30, 32
  %32 = zext i32 %22 to i64
  %33 = or i64 %31, %32
  %34 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.598", %"struct.gemmlowp::OutputPipelineExecutor.598"* %0, i64 0, i32 0, i32 1, i32 0, i32 0
  %35 = tail call { i64, i64 } @_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi4EEEE4EvalES3_(%"struct.gemmlowp::OutputStageEvalBufferImpl.231"* %34, i64 %33, i64 %29) #19
  %36 = extractvalue { i64, i64 } %35, 0
  %37 = extractvalue { i64, i64 } %35, 1
  %38 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.598", %"struct.gemmlowp::OutputPipelineExecutor.598"* %0, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %39 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %38, align 8
  %40 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %39, i64 0, i32 0
  %41 = load i32, i32* %40, align 4
  %42 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %39, i64 0, i32 1
  %43 = load i32, i32* %42, align 4
  %44 = trunc i64 %36 to i32
  %45 = icmp sgt i32 %41, %44
  %46 = select i1 %45, i32 %41, i32 %44
  %47 = icmp slt i32 %43, %46
  %48 = select i1 %47, i32 %43, i32 %46
  %49 = lshr i64 %36, 32
  %50 = trunc i64 %49 to i32
  %51 = icmp sgt i32 %41, %50
  %52 = select i1 %51, i32 %41, i32 %50
  %53 = icmp slt i32 %43, %52
  %54 = select i1 %53, i32 %43, i32 %52
  %55 = trunc i64 %37 to i32
  %56 = icmp sgt i32 %41, %55
  %57 = select i1 %56, i32 %41, i32 %55
  %58 = icmp slt i32 %43, %57
  %59 = select i1 %58, i32 %43, i32 %57
  %60 = lshr i64 %37, 32
  %61 = trunc i64 %60 to i32
  %62 = icmp sgt i32 %41, %61
  %63 = select i1 %62, i32 %41, i32 %61
  %64 = icmp slt i32 %43, %63
  %65 = select i1 %64, i32 %43, i32 %63
  %66 = icmp sgt i32 %48, -32768
  %67 = select i1 %66, i32 %48, i32 -32768
  %68 = icmp slt i32 %67, 32767
  %69 = select i1 %68, i32 %67, i32 32767
  %70 = icmp sgt i32 %54, -32768
  %71 = select i1 %70, i32 %54, i32 -32768
  %72 = icmp slt i32 %71, 32767
  %73 = select i1 %72, i32 %71, i32 32767
  %74 = icmp sgt i32 %59, -32768
  %75 = select i1 %74, i32 %59, i32 -32768
  %76 = icmp slt i32 %75, 32767
  %77 = select i1 %76, i32 %75, i32 32767
  %78 = icmp sgt i32 %65, -32768
  %79 = select i1 %78, i32 %65, i32 -32768
  %80 = icmp slt i32 %79, 32767
  %81 = select i1 %80, i32 %79, i32 32767
  %82 = trunc i32 %69 to i16
  %83 = trunc i32 %73 to i16
  %84 = trunc i32 %77 to i16
  %85 = trunc i32 %81 to i16
  %86 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %3, i64 0, i32 0
  %87 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %3, i64 0, i32 3
  %88 = sext i32 %7 to i64
  %89 = sext i32 %6 to i64
  %90 = load i16*, i16** %86, align 8
  %91 = getelementptr inbounds i16, i16* %90, i64 %89
  %92 = load i32, i32* %87, align 8
  %93 = sext i32 %92 to i64
  %94 = mul nsw i64 %93, %88
  %95 = getelementptr inbounds i16, i16* %91, i64 %94
  store i16 %82, i16* %95, align 2
  %96 = add nsw i64 %88, 1
  %97 = load i16*, i16** %86, align 8
  %98 = getelementptr inbounds i16, i16* %97, i64 %89
  %99 = load i32, i32* %87, align 8
  %100 = sext i32 %99 to i64
  %101 = mul nsw i64 %96, %100
  %102 = getelementptr inbounds i16, i16* %98, i64 %101
  store i16 %83, i16* %102, align 2
  %103 = add nsw i64 %88, 2
  %104 = load i16*, i16** %86, align 8
  %105 = getelementptr inbounds i16, i16* %104, i64 %89
  %106 = load i32, i32* %87, align 8
  %107 = sext i32 %106 to i64
  %108 = mul nsw i64 %103, %107
  %109 = getelementptr inbounds i16, i16* %105, i64 %108
  store i16 %84, i16* %109, align 2
  %110 = add nsw i64 %88, 3
  %111 = load i16*, i16** %86, align 8
  %112 = getelementptr inbounds i16, i16* %111, i64 %89
  %113 = load i32, i32* %87, align 8
  %114 = sext i32 %113 to i64
  %115 = mul nsw i64 %110, %114
  %116 = getelementptr inbounds i16, i16* %112, i64 %115
  store i16 %85, i16* %116, align 2
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi8ELi1EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE0EEEEEvSE_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.590"*, %"struct.gemmlowp::RegisterBlock.304"* byval(%"struct.gemmlowp::RegisterBlock.304") align 8, %"class.gemmlowp::MatrixMap.479"*, i32, i32, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %8 = alloca %"struct.gemmlowp::RegisterBlock.304", align 16
  %9 = bitcast %"struct.gemmlowp::RegisterBlock.304"* %1 to <4 x i32>*
  %10 = load <4 x i32>, <4 x i32>* %9, align 8
  %11 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %1, i64 0, i32 0, i32 0, i64 4
  %12 = bitcast i32* %11 to <4 x i32>*
  %13 = load <4 x i32>, <4 x i32>* %12, align 8
  %14 = bitcast %"struct.gemmlowp::RegisterBlock.304"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %14)
  %15 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.590", %"struct.gemmlowp::OutputPipelineExecutor.590"* %0, i64 0, i32 0, i32 0, i32 0
  %16 = load %"struct.gemmlowp::OutputStageBiasAddition"*, %"struct.gemmlowp::OutputStageBiasAddition"** %15, align 8, !noalias !1618
  %17 = getelementptr inbounds %"struct.gemmlowp::OutputStageBiasAddition", %"struct.gemmlowp::OutputStageBiasAddition"* %16, i64 0, i32 0, i32 0
  %18 = load i32*, i32** %17, align 8, !noalias !1621
  %19 = sext i32 %3 to i64
  %20 = getelementptr i32, i32* %18, i64 %19
  %21 = bitcast i32* %20 to <4 x i32>*
  %22 = load <4 x i32>, <4 x i32>* %21, align 4, !noalias !1618
  %23 = getelementptr inbounds i32, i32* %20, i64 4
  %24 = bitcast i32* %23 to <4 x i32>*
  %25 = load <4 x i32>, <4 x i32>* %24, align 4, !noalias !1618
  %26 = add nsw <4 x i32> %22, %10
  %27 = add nsw <4 x i32> %25, %13
  %28 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.590", %"struct.gemmlowp::OutputPipelineExecutor.590"* %0, i64 0, i32 0, i32 1
  %29 = bitcast %"struct.gemmlowp::RegisterBlock.304"* %8 to <4 x i32>*
  store <4 x i32> %26, <4 x i32>* %29, align 16
  %30 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %8, i64 0, i32 0, i32 0, i64 4
  %31 = bitcast i32* %30 to <4 x i32>*
  store <4 x i32> %27, <4 x i32>* %31, align 16
  %32 = tail call { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalESE_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.592"* %28, %"struct.gemmlowp::RegisterBlock.304"* nonnull byval(%"struct.gemmlowp::RegisterBlock.304") align 8 %8, i32 %3, i32 %4) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %14)
  %33 = extractvalue { i64, i64 } %32, 0
  %34 = extractvalue { i64, i64 } %32, 1
  %35 = trunc i64 %33 to i16
  %36 = lshr i64 %33, 16
  %37 = trunc i64 %36 to i16
  %38 = lshr i64 %33, 32
  %39 = trunc i64 %38 to i16
  %40 = lshr i64 %33, 48
  %41 = trunc i64 %40 to i16
  %42 = trunc i64 %34 to i16
  %43 = lshr i64 %34, 16
  %44 = trunc i64 %43 to i16
  %45 = lshr i64 %34, 32
  %46 = trunc i64 %45 to i16
  %47 = lshr i64 %34, 48
  %48 = trunc i64 %47 to i16
  %49 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %2, i64 0, i32 0
  %50 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %2, i64 0, i32 3
  %51 = sext i32 %5 to i64
  %52 = load i16*, i16** %49, align 8
  %53 = getelementptr inbounds i16, i16* %52, i64 %51
  %54 = load i32, i32* %50, align 8
  %55 = mul nsw i32 %54, %6
  %56 = sext i32 %55 to i64
  %57 = getelementptr inbounds i16, i16* %53, i64 %56
  store i16 %35, i16* %57, align 2
  %58 = add nsw i64 %51, 1
  %59 = load i16*, i16** %49, align 8
  %60 = getelementptr inbounds i16, i16* %59, i64 %58
  %61 = load i32, i32* %50, align 8
  %62 = mul nsw i32 %61, %6
  %63 = sext i32 %62 to i64
  %64 = getelementptr inbounds i16, i16* %60, i64 %63
  store i16 %37, i16* %64, align 2
  %65 = add nsw i64 %51, 2
  %66 = load i16*, i16** %49, align 8
  %67 = getelementptr inbounds i16, i16* %66, i64 %65
  %68 = load i32, i32* %50, align 8
  %69 = mul nsw i32 %68, %6
  %70 = sext i32 %69 to i64
  %71 = getelementptr inbounds i16, i16* %67, i64 %70
  store i16 %39, i16* %71, align 2
  %72 = add nsw i64 %51, 3
  %73 = load i16*, i16** %49, align 8
  %74 = getelementptr inbounds i16, i16* %73, i64 %72
  %75 = load i32, i32* %50, align 8
  %76 = mul nsw i32 %75, %6
  %77 = sext i32 %76 to i64
  %78 = getelementptr inbounds i16, i16* %74, i64 %77
  store i16 %41, i16* %78, align 2
  %79 = add nsw i64 %51, 4
  %80 = load i16*, i16** %49, align 8
  %81 = getelementptr inbounds i16, i16* %80, i64 %79
  %82 = load i32, i32* %50, align 8
  %83 = mul nsw i32 %82, %6
  %84 = sext i32 %83 to i64
  %85 = getelementptr inbounds i16, i16* %81, i64 %84
  store i16 %42, i16* %85, align 2
  %86 = add nsw i64 %51, 5
  %87 = load i16*, i16** %49, align 8
  %88 = getelementptr inbounds i16, i16* %87, i64 %86
  %89 = load i32, i32* %50, align 8
  %90 = mul nsw i32 %89, %6
  %91 = sext i32 %90 to i64
  %92 = getelementptr inbounds i16, i16* %88, i64 %91
  store i16 %44, i16* %92, align 2
  %93 = add nsw i64 %51, 6
  %94 = load i16*, i16** %49, align 8
  %95 = getelementptr inbounds i16, i16* %94, i64 %93
  %96 = load i32, i32* %50, align 8
  %97 = mul nsw i32 %96, %6
  %98 = sext i32 %97 to i64
  %99 = getelementptr inbounds i16, i16* %95, i64 %98
  store i16 %46, i16* %99, align 2
  %100 = add nsw i64 %51, 7
  %101 = load i16*, i16** %49, align 8
  %102 = getelementptr inbounds i16, i16* %101, i64 %100
  %103 = load i32, i32* %50, align 8
  %104 = mul nsw i32 %103, %6
  %105 = sext i32 %104 to i64
  %106 = getelementptr inbounds i16, i16* %102, i64 %105
  store i16 %48, i16* %106, align 2
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalESE_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.592"*, %"struct.gemmlowp::RegisterBlock.304"* byval(%"struct.gemmlowp::RegisterBlock.304") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %5 = alloca %"struct.gemmlowp::RegisterBuffer.305", align 8
  %6 = alloca %"struct.gemmlowp::RegisterBuffer.305", align 16
  %7 = alloca %"struct.gemmlowp::RegisterBlock.304", align 16
  %8 = bitcast %"struct.gemmlowp::RegisterBlock.304"* %1 to i8*
  %9 = bitcast %"struct.gemmlowp::RegisterBuffer.305"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %9) #19, !noalias !1626
  %10 = bitcast %"struct.gemmlowp::RegisterBuffer.305"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %10) #19, !noalias !1626
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %10, i8* nonnull align 8 %8, i64 32, i1 false)
  %11 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.592", %"struct.gemmlowp::OutputPipelineEvalImpl.592"* %0, i64 0, i32 0, i32 0, i32 0
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 32, i1 false) #19, !alias.scope !1629, !noalias !1626
  %12 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %11, align 8, !noalias !1632
  %13 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %12, i64 0, i32 2
  %14 = load i32, i32* %13, align 4, !noalias !1632
  %15 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.592", %"struct.gemmlowp::OutputPipelineEvalImpl.592"* %0, i64 0, i32 0, i32 0, i32 1
  %16 = load i32, i32* %15, align 8, !noalias !1632
  %17 = shl i32 1, %16
  %18 = sext i32 %17 to i64
  %19 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %12, i64 0, i32 0
  %20 = load i32, i32* %19, align 4, !noalias !1632
  %21 = sext i32 %20 to i64
  %22 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.592", %"struct.gemmlowp::OutputPipelineEvalImpl.592"* %0, i64 0, i32 0, i32 0, i32 2
  %23 = load i32, i32* %22, align 4, !noalias !1632
  %24 = zext i32 %23 to i64
  %25 = shl nsw i64 -1, %24
  %26 = trunc i64 %25 to i32
  %27 = xor i32 %26, -1
  %28 = ashr i32 %27, 1
  %29 = icmp ne i32 %20, -2147483648
  br label %30

30:                                               ; preds = %51, %4
  %31 = phi i64 [ 0, %4 ], [ %62, %51 ]
  %32 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.305", %"struct.gemmlowp::RegisterBuffer.305"* %5, i64 0, i32 0, i64 %31
  %33 = load i32, i32* %32, align 4, !noalias !1632
  %34 = sext i32 %33 to i64
  %35 = mul nsw i64 %34, %18
  %36 = icmp slt i64 %35, 2147483647
  %37 = select i1 %36, i64 %35, i64 2147483647
  %38 = icmp sgt i64 %37, -2147483648
  %39 = select i1 %38, i64 %37, i64 -2147483648
  %40 = trunc i64 %39 to i32
  %41 = icmp ne i32 %20, %40
  %42 = or i1 %29, %41
  br i1 %42, label %43, label %51

43:                                               ; preds = %30
  %44 = select i1 %41, i64 %21, i64 %39
  %45 = mul nsw i64 %44, %39
  %46 = icmp sgt i64 %45, -1
  %47 = select i1 %46, i64 1073741824, i64 -1073741823
  %48 = add nsw i64 %47, %45
  %49 = sdiv i64 %48, 2147483648
  %50 = trunc i64 %49 to i32
  br label %51

51:                                               ; preds = %43, %30
  %52 = phi i32 [ %50, %43 ], [ 2147483647, %30 ]
  %53 = and i32 %52, %27
  %54 = lshr i32 %52, 31
  %55 = add nsw i32 %54, %28
  %56 = ashr i32 %52, %23
  %57 = icmp sgt i32 %53, %55
  %58 = zext i1 %57 to i32
  %59 = add i32 %56, %14
  %60 = add i32 %59, %58
  %61 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.305", %"struct.gemmlowp::RegisterBuffer.305"* %6, i64 0, i32 0, i64 %31
  store i32 %60, i32* %61, align 4, !alias.scope !1629, !noalias !1626
  %62 = add nuw nsw i64 %31, 1
  %63 = icmp eq i64 %62, 8
  br i1 %63, label %64, label %30

64:                                               ; preds = %51
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %10) #19, !noalias !1626
  %65 = bitcast %"struct.gemmlowp::RegisterBuffer.305"* %6 to <4 x i32>*
  %66 = load <4 x i32>, <4 x i32>* %65, align 16
  %67 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.305", %"struct.gemmlowp::RegisterBuffer.305"* %6, i64 0, i32 0, i64 4
  %68 = bitcast i32* %67 to <4 x i32>*
  %69 = load <4 x i32>, <4 x i32>* %68, align 16
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %9) #19, !noalias !1626
  %70 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.592", %"struct.gemmlowp::OutputPipelineEvalImpl.592"* %0, i64 0, i32 1
  %71 = bitcast %"struct.gemmlowp::RegisterBlock.304"* %7 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %71, align 16
  %72 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %7, i64 0, i32 0, i32 0, i64 4
  %73 = bitcast i32* %72 to <4 x i32>*
  store <4 x i32> %69, <4 x i32>* %73, align 16
  %74 = tail call { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalESE_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.593"* %70, %"struct.gemmlowp::RegisterBlock.304"* nonnull byval(%"struct.gemmlowp::RegisterBlock.304") align 8 %7, i32 %2, i32 %3)
  ret { i64, i64 } %74
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalESE_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.593"*, %"struct.gemmlowp::RegisterBlock.304"* byval(%"struct.gemmlowp::RegisterBlock.304") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %5 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %1, i64 0, i32 0, i32 0, i64 0
  %6 = load i32, i32* %5, align 8
  %7 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %1, i64 0, i32 0, i32 0, i64 1
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %1, i64 0, i32 0, i32 0, i64 2
  %10 = load i32, i32* %9, align 8
  %11 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %1, i64 0, i32 0, i32 0, i64 3
  %12 = load i32, i32* %11, align 4
  %13 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %1, i64 0, i32 0, i32 0, i64 4
  %14 = load i32, i32* %13, align 8
  %15 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %1, i64 0, i32 0, i32 0, i64 5
  %16 = load i32, i32* %15, align 4
  %17 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %1, i64 0, i32 0, i32 0, i64 6
  %18 = load i32, i32* %17, align 8
  %19 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %1, i64 0, i32 0, i32 0, i64 7
  %20 = load i32, i32* %19, align 4
  %21 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.593", %"struct.gemmlowp::OutputPipelineEvalImpl.593"* %0, i64 0, i32 0, i32 0, i32 0
  %22 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %21, align 8, !noalias !1633
  %23 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %22, i64 0, i32 0
  %24 = load i32, i32* %23, align 4, !noalias !1633
  %25 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %22, i64 0, i32 1
  %26 = load i32, i32* %25, align 4, !noalias !1633
  %27 = icmp slt i32 %6, %24
  %28 = select i1 %27, i32 %24, i32 %6
  %29 = icmp slt i32 %26, %28
  %30 = select i1 %29, i32 %26, i32 %28
  %31 = icmp slt i32 %8, %24
  %32 = select i1 %31, i32 %24, i32 %8
  %33 = icmp slt i32 %26, %32
  %34 = select i1 %33, i32 %26, i32 %32
  %35 = icmp slt i32 %10, %24
  %36 = select i1 %35, i32 %24, i32 %10
  %37 = icmp slt i32 %26, %36
  %38 = select i1 %37, i32 %26, i32 %36
  %39 = icmp slt i32 %12, %24
  %40 = select i1 %39, i32 %24, i32 %12
  %41 = icmp slt i32 %26, %40
  %42 = select i1 %41, i32 %26, i32 %40
  %43 = icmp slt i32 %14, %24
  %44 = select i1 %43, i32 %24, i32 %14
  %45 = icmp slt i32 %26, %44
  %46 = select i1 %45, i32 %26, i32 %44
  %47 = icmp slt i32 %16, %24
  %48 = select i1 %47, i32 %24, i32 %16
  %49 = icmp slt i32 %26, %48
  %50 = select i1 %49, i32 %26, i32 %48
  %51 = icmp slt i32 %18, %24
  %52 = select i1 %51, i32 %24, i32 %18
  %53 = icmp slt i32 %26, %52
  %54 = select i1 %53, i32 %26, i32 %52
  %55 = icmp slt i32 %20, %24
  %56 = select i1 %55, i32 %24, i32 %20
  %57 = icmp slt i32 %26, %56
  %58 = select i1 %57, i32 %26, i32 %56
  %59 = icmp sgt i32 %30, -32768
  %60 = select i1 %59, i32 %30, i32 -32768
  %61 = icmp slt i32 %60, 32767
  %62 = select i1 %61, i32 %60, i32 32767
  %63 = icmp sgt i32 %34, -32768
  %64 = select i1 %63, i32 %34, i32 -32768
  %65 = icmp slt i32 %64, 32767
  %66 = select i1 %65, i32 %64, i32 32767
  %67 = icmp sgt i32 %38, -32768
  %68 = select i1 %67, i32 %38, i32 -32768
  %69 = icmp slt i32 %68, 32767
  %70 = select i1 %69, i32 %68, i32 32767
  %71 = icmp sgt i32 %42, -32768
  %72 = select i1 %71, i32 %42, i32 -32768
  %73 = icmp slt i32 %72, 32767
  %74 = select i1 %73, i32 %72, i32 32767
  %75 = icmp sgt i32 %46, -32768
  %76 = select i1 %75, i32 %46, i32 -32768
  %77 = icmp slt i32 %76, 32767
  %78 = select i1 %77, i32 %76, i32 32767
  %79 = icmp sgt i32 %50, -32768
  %80 = select i1 %79, i32 %50, i32 -32768
  %81 = icmp slt i32 %80, 32767
  %82 = select i1 %81, i32 %80, i32 32767
  %83 = shl nsw i32 %82, 16
  %84 = and i32 %78, 65535
  %85 = or i32 %83, %84
  %86 = zext i32 %85 to i64
  %87 = icmp sgt i32 %54, -32768
  %88 = select i1 %87, i32 %54, i32 -32768
  %89 = icmp slt i32 %88, 32767
  %90 = select i1 %89, i32 %88, i32 32767
  %91 = and i32 %90, 65535
  %92 = zext i32 %91 to i64
  %93 = shl nuw nsw i64 %92, 32
  %94 = icmp sgt i32 %58, -32768
  %95 = select i1 %94, i32 %58, i32 -32768
  %96 = icmp slt i32 %95, 32767
  %97 = select i1 %96, i32 %95, i32 32767
  %98 = zext i32 %97 to i64
  %99 = shl i64 %98, 48
  %100 = or i64 %99, %86
  %101 = or i64 %100, %93
  %102 = zext i32 %74 to i64
  %103 = shl i64 %102, 48
  %104 = and i32 %70, 65535
  %105 = zext i32 %104 to i64
  %106 = shl nuw nsw i64 %105, 32
  %107 = shl nsw i32 %66, 16
  %108 = and i32 %62, 65535
  %109 = or i32 %107, %108
  %110 = zext i32 %109 to i64
  %111 = or i64 %103, %110
  %112 = or i64 %111, %106
  %113 = insertvalue { i64, i64 } undef, i64 %112, 0
  %114 = insertvalue { i64, i64 } %113, i64 %101, 1
  ret { i64, i64 } %114
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED2Ev(%"struct.gemmlowp::GemmWithPackedRhsTask.573"*) unnamed_addr #4 comdat align 2 {
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED0Ev(%"struct.gemmlowp::GemmWithPackedRhsTask.573"*) unnamed_addr #4 comdat align 2 {
  %2 = bitcast %"struct.gemmlowp::GemmWithPackedRhsTask.573"* %0 to i8*
  tail call void @_ZdlPv(i8* %2) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISF_LSG_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEE3RunEv(%"struct.gemmlowp::GemmWithPackedRhsTask.573"*) unnamed_addr #1 comdat align 2 {
  %2 = alloca %"class.gemmlowp::SideMap", align 8
  %3 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %4 = alloca %"class.gemmlowp::ComputeImpl", align 8
  %5 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %6 = alloca %"class.gemmlowp::PackedResult", align 8
  %7 = alloca %"struct.gemmlowp::MatrixBlockBounds", align 4
  %8 = alloca %"class.gemmlowp::VectorDup", align 4
  %9 = alloca %"class.gemmlowp::VectorDup.194", align 4
  %10 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.573", %"struct.gemmlowp::GemmWithPackedRhsTask.573"* %0, i64 0, i32 6, i32 2
  %11 = load i32, i32* %10, align 8
  %12 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.573", %"struct.gemmlowp::GemmWithPackedRhsTask.573"* %0, i64 0, i32 6, i32 3
  %13 = load i32, i32* %12, align 4
  %14 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.573", %"struct.gemmlowp::GemmWithPackedRhsTask.573"* %0, i64 0, i32 3, i32 2
  %15 = load i32, i32* %14, align 4
  %16 = bitcast %"class.gemmlowp::PackedSideBlock"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %16) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %16, i8 -86, i64 80, i1 false)
  %17 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.573", %"struct.gemmlowp::GemmWithPackedRhsTask.573"* %0, i64 0, i32 0, i32 1
  %18 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %19 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.573", %"struct.gemmlowp::GemmWithPackedRhsTask.573"* %0, i64 0, i32 9
  %20 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %21 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %18, %"class.gemmlowp::Allocator"** %21, align 8
  %22 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 4
  store i32 0, i32* %22, align 8
  %23 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 0
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 0
  store i32 %24, i32* %25, align 8
  %26 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 3
  %27 = load i32, i32* %26, align 4
  %28 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 2
  store i32 %27, i32* %28, align 8
  %29 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 2
  %30 = load i32, i32* %29, align 4
  %31 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 1
  store i32 %30, i32* %31, align 4
  %32 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 5
  %33 = load i32, i32* %32, align 4
  %34 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 3
  store i32 %33, i32* %34, align 4
  %35 = mul nsw i32 %33, %27
  %36 = sext i32 %35 to i64
  %37 = add nsw i64 %36, 63
  %38 = and i64 %37, -64
  %39 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 4
  %40 = load i64, i64* %39, align 8, !noalias !1638
  %41 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 3
  %42 = load i64, i64* %41, align 8, !noalias !1638
  %43 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 5, i64 %42
  store i64 %40, i64* %43, align 8, !noalias !1638
  %44 = trunc i64 %42 to i8
  %45 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 6
  %46 = load i64, i64* %45, align 8, !noalias !1638
  %47 = bitcast i64* %41 to <2 x i64>*
  %48 = load <2 x i64>, <2 x i64>* %47, align 8, !noalias !1638
  %49 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %38, i32 1
  %50 = add <2 x i64> %48, %49
  %51 = bitcast i64* %41 to <2 x i64>*
  store <2 x i64> %50, <2 x i64>* %51, align 8, !noalias !1638
  %52 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 0
  store i8 %44, i8* %52, align 8
  %53 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %53, i8 -86, i64 7, i1 false) #19
  %54 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 2
  store i64 %46, i64* %54, align 8
  %55 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 3
  store i8 0, i8* %55, align 8
  %56 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %21, align 8
  %57 = load i32, i32* %28, align 8
  %58 = sext i32 %57 to i64
  %59 = shl nsw i64 %58, 2
  %60 = add nsw i64 %59, 63
  %61 = and i64 %60, -64
  %62 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 4
  %63 = load i64, i64* %62, align 8, !noalias !1641
  %64 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 3
  %65 = load i64, i64* %64, align 8, !noalias !1641
  %66 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 5, i64 %65
  store i64 %63, i64* %66, align 8, !noalias !1641
  %67 = trunc i64 %65 to i8
  %68 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 6
  %69 = load i64, i64* %68, align 8, !noalias !1641
  %70 = bitcast i64* %64 to <2 x i64>*
  %71 = load <2 x i64>, <2 x i64>* %70, align 8, !noalias !1641
  %72 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %61, i32 1
  %73 = add <2 x i64> %71, %72
  %74 = bitcast i64* %64 to <2 x i64>*
  store <2 x i64> %73, <2 x i64>* %74, align 8, !noalias !1641
  %75 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 0
  store i8 %67, i8* %75, align 8
  %76 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %76, i8 -86, i64 7, i1 false) #19
  %77 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 2
  store i64 %69, i64* %77, align 8
  %78 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 3
  store i8 5, i8* %78, align 8
  %79 = bitcast %"class.gemmlowp::PackedResult"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %79) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %79, i8 -86, i64 32, i1 false)
  %80 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %81 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %82 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 0
  store %"class.gemmlowp::Allocator"* %80, %"class.gemmlowp::Allocator"** %82, align 8
  %83 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 2
  store %"struct.gemmlowp::BlockParams"* %81, %"struct.gemmlowp::BlockParams"** %83, align 8
  %84 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %81, i64 0, i32 3
  %85 = load i32, i32* %84, align 4
  %86 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %81, i64 0, i32 4
  %87 = load i32, i32* %86, align 4
  %88 = mul nsw i32 %87, %85
  %89 = sext i32 %88 to i64
  %90 = shl nsw i64 %89, 2
  %91 = add nsw i64 %90, 63
  %92 = and i64 %91, -64
  %93 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 4
  %94 = load i64, i64* %93, align 8, !noalias !1644
  %95 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 3
  %96 = load i64, i64* %95, align 8, !noalias !1644
  %97 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 5, i64 %96
  store i64 %94, i64* %97, align 8, !noalias !1644
  %98 = trunc i64 %96 to i8
  %99 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 6
  %100 = load i64, i64* %99, align 8, !noalias !1644
  %101 = bitcast i64* %95 to <2 x i64>*
  %102 = load <2 x i64>, <2 x i64>* %101, align 8, !noalias !1644
  %103 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %92, i32 1
  %104 = add <2 x i64> %102, %103
  %105 = bitcast i64* %95 to <2 x i64>*
  store <2 x i64> %104, <2 x i64>* %105, align 8, !noalias !1644
  %106 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 0
  store i8 %98, i8* %106, align 8
  %107 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %107, i8 -86, i64 7, i1 false) #19
  %108 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 2
  store i64 %100, i64* %108, align 8
  %109 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 3
  store i8 5, i8* %109, align 8
  %110 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  tail call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %110)
  %111 = icmp sgt i32 %13, 0
  br i1 %111, label %112, label %156

112:                                              ; preds = %1
  %113 = icmp sgt i32 %11, 0
  %114 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.573", %"struct.gemmlowp::GemmWithPackedRhsTask.573"* %0, i64 0, i32 3, i32 0
  %115 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.573", %"struct.gemmlowp::GemmWithPackedRhsTask.573"* %0, i64 0, i32 3, i32 3
  %116 = bitcast %"class.gemmlowp::SideMap"* %2 to i8*
  %117 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 1
  %118 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 2
  %119 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 3
  %120 = bitcast %"class.gemmlowp::SideMap"* %2 to i64*
  %121 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %3 to i8*
  %122 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %3, i64 0, i32 0
  %123 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %3, i64 0, i32 1
  %124 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.573", %"struct.gemmlowp::GemmWithPackedRhsTask.573"* %0, i64 0, i32 2
  %125 = bitcast %"struct.gemmlowp::KernelBase"** %124 to i64*
  %126 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.573", %"struct.gemmlowp::GemmWithPackedRhsTask.573"* %0, i64 0, i32 4
  %127 = bitcast %"class.gemmlowp::ComputeImpl"* %4 to i8*
  %128 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 1
  %129 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 2
  %130 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 3
  %131 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 4
  %132 = bitcast %"class.gemmlowp::ComputeImpl"* %4 to i64*
  %133 = add i32 %15, 15
  %134 = and i32 %133, -16
  %135 = icmp sgt i32 %134, 0
  %136 = bitcast %"struct.gemmlowp::MatrixBlockBounds"* %7 to i8*
  %137 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 0
  %138 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 1
  %139 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 2
  %140 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 3
  %141 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.573", %"struct.gemmlowp::GemmWithPackedRhsTask.573"* %0, i64 0, i32 6, i32 0
  %142 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.573", %"struct.gemmlowp::GemmWithPackedRhsTask.573"* %0, i64 0, i32 6, i32 1
  %143 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.573", %"struct.gemmlowp::GemmWithPackedRhsTask.573"* %0, i64 0, i32 5
  %144 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.573", %"struct.gemmlowp::GemmWithPackedRhsTask.573"* %0, i64 0, i32 4, i32 1
  %145 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.573", %"struct.gemmlowp::GemmWithPackedRhsTask.573"* %0, i64 0, i32 4, i32 3, i32 0
  %146 = bitcast %"class.gemmlowp::VectorDup"* %8 to i8*
  %147 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.573", %"struct.gemmlowp::GemmWithPackedRhsTask.573"* %0, i64 0, i32 7
  %148 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %8, i64 0, i32 0
  %149 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %8, i64 0, i32 1
  %150 = bitcast %"class.gemmlowp::VectorDup.194"* %9 to i8*
  %151 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.573", %"struct.gemmlowp::GemmWithPackedRhsTask.573"* %0, i64 0, i32 8
  %152 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %9, i64 0, i32 0
  %153 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %9, i64 0, i32 1
  %154 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.573", %"struct.gemmlowp::GemmWithPackedRhsTask.573"* %0, i64 0, i32 10
  %155 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  br label %164

156:                                              ; preds = %178, %1
  %157 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %158 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 0
  store i8 0, i8* %158, align 8
  %159 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 6
  %160 = load i64, i64* %159, align 8
  %161 = add i64 %160, 1
  store i64 %161, i64* %159, align 8
  %162 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 3
  %163 = bitcast i64* %162 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %163, i8 0, i64 16, i1 false) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %79) #19
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %16) #19
  ret void

164:                                              ; preds = %112, %178
  %165 = phi %"struct.gemmlowp::BlockParams"* [ %155, %112 ], [ %180, %178 ]
  %166 = phi i32 [ 0, %112 ], [ %181, %178 ]
  %167 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %165, i64 0, i32 4
  %168 = sub nsw i32 %13, %166
  %169 = load i32, i32* %167, align 4
  %170 = icmp slt i32 %168, %169
  %171 = select i1 %170, i32 %168, i32 %169
  br i1 %113, label %172, label %178

172:                                              ; preds = %164
  %173 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %165, i64 0, i32 3
  %174 = load i32, i32* %173, align 4
  br label %183

175:                                              ; preds = %255
  %176 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %287, i64 0, i32 4
  %177 = load i32, i32* %176, align 4
  br label %178

178:                                              ; preds = %175, %164
  %179 = phi i32 [ %169, %164 ], [ %177, %175 ]
  %180 = phi %"struct.gemmlowp::BlockParams"* [ %165, %164 ], [ %287, %175 ]
  %181 = add nsw i32 %179, %166
  %182 = icmp sgt i32 %13, %181
  br i1 %182, label %164, label %156

183:                                              ; preds = %172, %255
  %184 = phi i32 [ %289, %255 ], [ %174, %172 ]
  %185 = phi i32 [ %290, %255 ], [ 0, %172 ]
  %186 = sub nsw i32 %11, %185
  %187 = icmp slt i32 %186, %184
  %188 = select i1 %187, i32 %186, i32 %184
  %189 = load i8*, i8** %114, align 8, !noalias !1647
  %190 = load i32, i32* %115, align 8, !noalias !1647
  %191 = mul nsw i32 %190, %185
  %192 = sext i32 %191 to i64
  %193 = getelementptr inbounds i8, i8* %189, i64 %192
  %194 = ptrtoint i8* %193 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %116) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %116, i8 -86, i64 24, i1 false) #19
  store i64 %194, i64* %120, align 8
  store i32 %188, i32* %117, align 8
  store i32 %15, i32* %118, align 4
  store i32 %190, i32* %119, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %121) #19
  store %"class.gemmlowp::PackedSideBlock"* %5, %"class.gemmlowp::PackedSideBlock"** %122, align 8
  store %"class.gemmlowp::SideMap"* %2, %"class.gemmlowp::SideMap"** %123, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %3) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %121) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %116) #19
  %195 = load i64, i64* %125, align 8
  %196 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %127) #19
  store i64 %195, i64* %132, align 8
  store %"struct.gemmlowp::BlockParams"* %196, %"struct.gemmlowp::BlockParams"** %128, align 8
  store %"class.gemmlowp::PackedResult"* %6, %"class.gemmlowp::PackedResult"** %129, align 8
  store %"class.gemmlowp::PackedSideBlock"* %5, %"class.gemmlowp::PackedSideBlock"** %130, align 8
  store %"class.gemmlowp::PackedSideBlock"* %126, %"class.gemmlowp::PackedSideBlock"** %131, align 8
  br i1 %135, label %197, label %255

197:                                              ; preds = %183, %215
  %198 = phi %"struct.gemmlowp::BlockParams"* [ %217, %215 ], [ %196, %183 ]
  %199 = phi %"struct.gemmlowp::BlockParams"* [ %218, %215 ], [ %196, %183 ]
  %200 = phi i32 [ %219, %215 ], [ 0, %183 ]
  %201 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 2
  %202 = sub nsw i32 %134, %200
  %203 = load i32, i32* %201, align 4
  %204 = icmp slt i32 %202, %203
  %205 = select i1 %204, i32 %202, i32 %203
  %206 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 3
  %207 = load i32, i32* %206, align 4
  %208 = icmp sgt i32 %207, 0
  br i1 %208, label %209, label %215

209:                                              ; preds = %197
  %210 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 0
  %211 = load i32, i32* %210, align 4
  br label %221

212:                                              ; preds = %247
  %213 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 2
  %214 = load i32, i32* %213, align 4
  br label %215

215:                                              ; preds = %212, %197
  %216 = phi i32 [ %203, %197 ], [ %214, %212 ]
  %217 = phi %"struct.gemmlowp::BlockParams"* [ %198, %197 ], [ %248, %212 ]
  %218 = phi %"struct.gemmlowp::BlockParams"* [ %199, %197 ], [ %248, %212 ]
  %219 = add nsw i32 %216, %200
  %220 = icmp sgt i32 %134, %219
  br i1 %220, label %197, label %255

221:                                              ; preds = %247, %209
  %222 = phi %"struct.gemmlowp::BlockParams"* [ %248, %247 ], [ %198, %209 ]
  %223 = phi i32 [ %250, %247 ], [ %211, %209 ]
  %224 = phi i32 [ %253, %247 ], [ %207, %209 ]
  %225 = phi %"struct.gemmlowp::BlockParams"* [ %248, %247 ], [ %199, %209 ]
  %226 = phi i32 [ %251, %247 ], [ 0, %209 ]
  %227 = sub nsw i32 %224, %226
  %228 = icmp slt i32 %227, %223
  %229 = select i1 %228, i32 %227, i32 %223
  %230 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %225, i64 0, i32 4
  %231 = load i32, i32* %230, align 4
  %232 = icmp sgt i32 %231, 0
  br i1 %232, label %233, label %247

233:                                              ; preds = %221
  %234 = icmp sgt i32 %229, 0
  br label %235

235:                                              ; preds = %237, %233
  %236 = phi i32 [ 0, %233 ], [ %238, %237 ]
  br i1 %234, label %240, label %237

237:                                              ; preds = %240, %235
  %238 = add nuw nsw i32 %236, 4
  %239 = icmp slt i32 %238, %231
  br i1 %239, label %235, label %245

240:                                              ; preds = %235, %240
  %241 = phi i32 [ %243, %240 ], [ 0, %235 ]
  %242 = add nsw i32 %241, %226
  call void @_ZN8gemmlowp11ComputeImplINS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEES7_NS_12PackedResultEE10ComputeRunEiiii(%"class.gemmlowp::ComputeImpl"* nonnull %4, i32 %242, i32 %236, i32 %200, i32 %205) #19
  %243 = add nuw nsw i32 %241, 4
  %244 = icmp slt i32 %243, %229
  br i1 %244, label %240, label %237

245:                                              ; preds = %237
  %246 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %128, align 8
  br label %247

247:                                              ; preds = %245, %221
  %248 = phi %"struct.gemmlowp::BlockParams"* [ %246, %245 ], [ %222, %221 ]
  %249 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 0
  %250 = load i32, i32* %249, align 4
  %251 = add nsw i32 %250, %226
  %252 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 3
  %253 = load i32, i32* %252, align 4
  %254 = icmp sgt i32 %253, %251
  br i1 %254, label %221, label %212

255:                                              ; preds = %215, %183
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %127) #19
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %136) #19
  %256 = load i32, i32* %141, align 8
  %257 = add nsw i32 %256, %185
  %258 = load i32, i32* %142, align 4
  %259 = add nsw i32 %258, %166
  store i32 %257, i32* %137, align 4
  store i32 %259, i32* %138, align 4
  store i32 %188, i32* %139, align 4
  store i32 %171, i32* %140, align 4
  %260 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %21, align 8
  %261 = load i8, i8* %75, align 8
  %262 = zext i8 %261 to i64
  %263 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %260, i64 0, i32 5, i64 %262
  %264 = load i64, i64* %263, align 8
  %265 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %260, i64 0, i32 2
  %266 = bitcast i8** %265 to i64*
  %267 = load i64, i64* %266, align 8
  %268 = add i64 %267, %264
  %269 = inttoptr i64 %268 to i32*
  %270 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %144, align 8
  %271 = load i8, i8* %145, align 8
  %272 = zext i8 %271 to i64
  %273 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %270, i64 0, i32 5, i64 %272
  %274 = load i64, i64* %273, align 8
  %275 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %270, i64 0, i32 2
  %276 = bitcast i8** %275 to i64*
  %277 = load i64, i64* %276, align 8
  %278 = add i64 %277, %274
  %279 = inttoptr i64 %278 to i32*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %146) #19
  %280 = load %"class.gemmlowp::VectorDup"*, %"class.gemmlowp::VectorDup"** %147, align 8
  %281 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %280, i64 0, i32 0
  %282 = load i32, i32* %281, align 4, !noalias !1650
  store i32 %282, i32* %148, align 4, !alias.scope !1650
  store i32 %188, i32* %149, align 4, !alias.scope !1650
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %150) #19
  %283 = load %"class.gemmlowp::VectorDup.194"*, %"class.gemmlowp::VectorDup.194"** %151, align 8
  %284 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %283, i64 0, i32 0
  %285 = load i32, i32* %284, align 4, !noalias !1653
  store i32 %285, i32* %152, align 4, !alias.scope !1653
  store i32 %171, i32* %153, align 4, !alias.scope !1653
  %286 = load %"class.std::__1::tuple.481"*, %"class.std::__1::tuple.481"** %154, align 8
  call void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIsLNS_8MapOrderE0EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE0EEENSC_ISD_LSE_1EEENSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapISD_LSE_0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SZ_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.479"* %143, %"struct.gemmlowp::MatrixBlockBounds"* nonnull dereferenceable(16) %7, %"class.gemmlowp::PackedResult"* nonnull dereferenceable(40) %6, i32 %15, i32* %269, i32* %279, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %8, %"class.gemmlowp::VectorDup.194"* nonnull dereferenceable(8) %9, %"class.std::__1::tuple.481"* dereferenceable(40) %286)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %150) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %146) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %136) #19
  %287 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %288 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %287, i64 0, i32 3
  %289 = load i32, i32* %288, align 4
  %290 = add nsw i32 %289, %185
  %291 = icmp sgt i32 %11, %290
  br i1 %291, label %183, label %175
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17DispatchGemmShapeIhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENS7_IS8_LS9_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSL_ISN_XT3_EEEPNSL_IT0_XT4_EEERKT5_RKT6_RKT7_(%"class.gemmlowp::GemmContext"*, %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.180"* dereferenceable(24), %"class.gemmlowp::MatrixMap.479"*, %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.std::__1::tuple.485"* dereferenceable(20)) local_unnamed_addr #1 comdat {
  %8 = alloca %"class.gemmlowp::MatrixMap.489", align 8
  %9 = alloca %"class.gemmlowp::MatrixMap", align 8
  %10 = alloca %"class.gemmlowp::MatrixMap.180", align 8
  %11 = alloca %"class.gemmlowp::VectorDup.194", align 4
  %12 = alloca %"class.gemmlowp::VectorDup", align 4
  %13 = alloca %"class.std::__1::tuple.485", align 8
  %14 = alloca %"struct.gemmlowp::DefaultKernel", align 8
  %15 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %3, i64 0, i32 1
  %16 = load i32, i32* %15, align 8
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %3, i64 0, i32 2
  %18 = load i32, i32* %17, align 4
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 2
  %20 = load i32, i32* %19, align 4
  %21 = icmp eq i32 %16, 0
  %22 = icmp eq i32 %18, 0
  %23 = or i1 %21, %22
  %24 = icmp eq i32 %20, 0
  %25 = or i1 %23, %24
  br i1 %25, label %93, label %26

26:                                               ; preds = %7
  %27 = icmp slt i32 %16, %18
  br i1 %27, label %28, label %89

28:                                               ; preds = %26
  %29 = bitcast %"class.gemmlowp::MatrixMap.489"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %29) #19
  %30 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %8, i64 0, i32 1
  %31 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %8, i64 0, i32 2
  %32 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %8, i64 0, i32 3
  %33 = bitcast %"class.gemmlowp::MatrixMap.479"* %3 to i64*
  %34 = bitcast %"class.gemmlowp::MatrixMap.489"* %8 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %34, i8 -86, i64 24, i1 false)
  %35 = load i64, i64* %33, align 8, !noalias !1656
  %36 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %3, i64 0, i32 3
  %37 = load i32, i32* %36, align 8, !noalias !1656
  %38 = bitcast %"class.gemmlowp::MatrixMap.489"* %8 to i64*
  store i64 %35, i64* %38, align 8, !alias.scope !1656
  store i32 %18, i32* %30, align 8, !alias.scope !1656
  store i32 %16, i32* %31, align 4, !alias.scope !1656
  store i32 %37, i32* %32, align 8, !alias.scope !1656
  %39 = bitcast %"class.gemmlowp::MatrixMap"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %39) #19
  %40 = bitcast %"class.gemmlowp::MatrixMap.180"* %2 to i64*
  %41 = load i64, i64* %40, align 8, !noalias !1661
  %42 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %2, i64 0, i32 2
  %43 = load i32, i32* %42, align 4, !noalias !1661
  %44 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %2, i64 0, i32 1
  %45 = load i32, i32* %44, align 8, !noalias !1661
  %46 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %2, i64 0, i32 3
  %47 = load i32, i32* %46, align 8, !noalias !1661
  %48 = bitcast %"class.gemmlowp::MatrixMap"* %9 to i64*
  store i64 %41, i64* %48, align 8, !alias.scope !1661
  %49 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 1
  store i32 %43, i32* %49, align 8, !alias.scope !1661
  %50 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 2
  store i32 %45, i32* %50, align 4, !alias.scope !1661
  %51 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 3
  store i32 %47, i32* %51, align 8, !alias.scope !1661
  %52 = bitcast %"class.gemmlowp::MatrixMap.180"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %52) #19
  %53 = bitcast %"class.gemmlowp::MatrixMap"* %1 to i64*
  %54 = load i64, i64* %53, align 8, !noalias !1666
  %55 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 1
  %56 = load i32, i32* %55, align 8, !noalias !1666
  %57 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 3
  %58 = load i32, i32* %57, align 8, !noalias !1666
  %59 = bitcast %"class.gemmlowp::MatrixMap.180"* %10 to i64*
  store i64 %54, i64* %59, align 8, !alias.scope !1666
  %60 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %10, i64 0, i32 1
  store i32 %20, i32* %60, align 8, !alias.scope !1666
  %61 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %10, i64 0, i32 2
  store i32 %56, i32* %61, align 4, !alias.scope !1666
  %62 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %10, i64 0, i32 3
  store i32 %58, i32* %62, align 8, !alias.scope !1666
  %63 = bitcast %"class.gemmlowp::VectorDup.194"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %63) #19
  %64 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %11, i64 0, i32 0
  %65 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 0
  %66 = load i32, i32* %65, align 4, !noalias !1671
  store i32 %66, i32* %64, align 4, !alias.scope !1671
  %67 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %11, i64 0, i32 1
  %68 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 1
  %69 = load i32, i32* %68, align 4, !noalias !1671
  store i32 %69, i32* %67, align 4, !alias.scope !1671
  %70 = bitcast %"class.gemmlowp::VectorDup"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %70) #19
  %71 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %12, i64 0, i32 0
  %72 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %4, i64 0, i32 0
  %73 = load i32, i32* %72, align 4, !noalias !1676
  store i32 %73, i32* %71, align 4, !alias.scope !1676
  %74 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %12, i64 0, i32 1
  %75 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %4, i64 0, i32 1
  %76 = load i32, i32* %75, align 4, !noalias !1676
  store i32 %76, i32* %74, align 4, !alias.scope !1676
  %77 = bitcast %"class.std::__1::tuple.485"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 20, i8* nonnull %77) #19
  %78 = bitcast %"class.std::__1::tuple.485"* %6 to i64*
  %79 = load i64, i64* %78, align 4, !noalias !1681
  %80 = getelementptr inbounds %"class.std::__1::tuple.485", %"class.std::__1::tuple.485"* %6, i64 0, i32 0, i32 0, i32 0, i32 2
  %81 = load i32, i32* %80, align 4, !noalias !1681
  %82 = getelementptr inbounds %"class.std::__1::tuple.485", %"class.std::__1::tuple.485"* %6, i64 0, i32 0, i32 1, i32 0
  %83 = bitcast %"struct.gemmlowp::OutputStageClamp"* %82 to i64*
  %84 = load i64, i64* %83, align 4, !noalias !1681
  %85 = bitcast %"class.std::__1::tuple.485"* %13 to i64*
  store i64 %79, i64* %85, align 8, !alias.scope !1681
  %86 = getelementptr inbounds %"class.std::__1::tuple.485", %"class.std::__1::tuple.485"* %13, i64 0, i32 0, i32 0, i32 0, i32 2
  store i32 %81, i32* %86, align 8, !alias.scope !1681
  %87 = getelementptr inbounds %"class.std::__1::tuple.485", %"class.std::__1::tuple.485"* %13, i64 0, i32 0, i32 1
  %88 = bitcast %"class.std::__1::__tuple_leaf.190"* %87 to i64*
  store i64 %84, i64* %88, align 4, !alias.scope !1684
  call void @_ZN8gemmlowp17DispatchGemmShapeIhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENS7_IS8_LS9_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSL_ISN_XT3_EEEPNSL_IT0_XT4_EEERKT5_RKT6_RKT7_(%"class.gemmlowp::GemmContext"* %0, %"class.gemmlowp::MatrixMap"* nonnull dereferenceable(24) %9, %"class.gemmlowp::MatrixMap.180"* nonnull dereferenceable(24) %10, %"class.gemmlowp::MatrixMap.489"* nonnull %8, %"class.gemmlowp::VectorDup.194"* nonnull dereferenceable(8) %11, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %12, %"class.std::__1::tuple.485"* nonnull dereferenceable(20) %13)
  call void @llvm.lifetime.end.p0i8(i64 20, i8* nonnull %77) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %70) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %63) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %52) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %39) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %29) #19
  br label %93

89:                                               ; preds = %26
  %90 = bitcast %"struct.gemmlowp::DefaultKernel"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %90) #19
  %91 = getelementptr inbounds %"struct.gemmlowp::DefaultKernel", %"struct.gemmlowp::DefaultKernel"* %14, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [6 x i8*] }, { [6 x i8*] }* @_ZTVN8gemmlowp13DefaultKernelINS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %91, align 8
  %92 = getelementptr inbounds %"struct.gemmlowp::DefaultKernel", %"struct.gemmlowp::DefaultKernel"* %14, i64 0, i32 0, i32 0, i32 0, i32 0
  call void @_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSV_ISX_XT4_EEEPNSV_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::GemmContext"* %0, %"struct.gemmlowp::KernelBase"* nonnull dereferenceable(8) %92, %"class.gemmlowp::MatrixMap"* dereferenceable(24) %1, %"class.gemmlowp::MatrixMap.180"* dereferenceable(24) %2, %"class.gemmlowp::MatrixMap.479"* %3, %"class.gemmlowp::VectorDup"* dereferenceable(8) %4, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %5, %"class.std::__1::tuple.485"* dereferenceable(20) %6)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %90) #19
  br label %93

93:                                               ; preds = %7, %89, %28
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17DispatchGemmShapeIhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENS7_IS8_LS9_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSL_ISN_XT3_EEEPNSL_IT0_XT4_EEERKT5_RKT6_RKT7_(%"class.gemmlowp::GemmContext"*, %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.180"* dereferenceable(24), %"class.gemmlowp::MatrixMap.489"*, %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.std::__1::tuple.485"* dereferenceable(20)) local_unnamed_addr #1 comdat {
  %8 = alloca %"class.gemmlowp::MatrixMap.479", align 8
  %9 = alloca %"class.gemmlowp::MatrixMap", align 8
  %10 = alloca %"class.gemmlowp::MatrixMap.180", align 8
  %11 = alloca %"class.gemmlowp::VectorDup", align 4
  %12 = alloca %"class.gemmlowp::VectorDup.194", align 4
  %13 = alloca %"class.std::__1::tuple.485", align 8
  %14 = alloca %"struct.gemmlowp::DefaultKernel", align 8
  %15 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %3, i64 0, i32 1
  %16 = load i32, i32* %15, align 8
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %3, i64 0, i32 2
  %18 = load i32, i32* %17, align 4
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 2
  %20 = load i32, i32* %19, align 4
  %21 = icmp eq i32 %16, 0
  %22 = icmp eq i32 %18, 0
  %23 = or i1 %21, %22
  %24 = icmp eq i32 %20, 0
  %25 = or i1 %23, %24
  br i1 %25, label %93, label %26

26:                                               ; preds = %7
  %27 = icmp slt i32 %16, %18
  br i1 %27, label %28, label %89

28:                                               ; preds = %26
  %29 = bitcast %"class.gemmlowp::MatrixMap.479"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %29) #19
  %30 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %8, i64 0, i32 1
  %31 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %8, i64 0, i32 2
  %32 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %8, i64 0, i32 3
  %33 = bitcast %"class.gemmlowp::MatrixMap.489"* %3 to i64*
  %34 = bitcast %"class.gemmlowp::MatrixMap.479"* %8 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %34, i8 -86, i64 24, i1 false)
  %35 = load i64, i64* %33, align 8, !noalias !1687
  %36 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %3, i64 0, i32 3
  %37 = load i32, i32* %36, align 8, !noalias !1687
  %38 = bitcast %"class.gemmlowp::MatrixMap.479"* %8 to i64*
  store i64 %35, i64* %38, align 8, !alias.scope !1687
  store i32 %18, i32* %30, align 8, !alias.scope !1687
  store i32 %16, i32* %31, align 4, !alias.scope !1687
  store i32 %37, i32* %32, align 8, !alias.scope !1687
  %39 = bitcast %"class.gemmlowp::MatrixMap"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %39) #19
  %40 = bitcast %"class.gemmlowp::MatrixMap.180"* %2 to i64*
  %41 = load i64, i64* %40, align 8, !noalias !1692
  %42 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %2, i64 0, i32 2
  %43 = load i32, i32* %42, align 4, !noalias !1692
  %44 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %2, i64 0, i32 1
  %45 = load i32, i32* %44, align 8, !noalias !1692
  %46 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %2, i64 0, i32 3
  %47 = load i32, i32* %46, align 8, !noalias !1692
  %48 = bitcast %"class.gemmlowp::MatrixMap"* %9 to i64*
  store i64 %41, i64* %48, align 8, !alias.scope !1692
  %49 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 1
  store i32 %43, i32* %49, align 8, !alias.scope !1692
  %50 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 2
  store i32 %45, i32* %50, align 4, !alias.scope !1692
  %51 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %9, i64 0, i32 3
  store i32 %47, i32* %51, align 8, !alias.scope !1692
  %52 = bitcast %"class.gemmlowp::MatrixMap.180"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %52) #19
  %53 = bitcast %"class.gemmlowp::MatrixMap"* %1 to i64*
  %54 = load i64, i64* %53, align 8, !noalias !1697
  %55 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 1
  %56 = load i32, i32* %55, align 8, !noalias !1697
  %57 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %1, i64 0, i32 3
  %58 = load i32, i32* %57, align 8, !noalias !1697
  %59 = bitcast %"class.gemmlowp::MatrixMap.180"* %10 to i64*
  store i64 %54, i64* %59, align 8, !alias.scope !1697
  %60 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %10, i64 0, i32 1
  store i32 %20, i32* %60, align 8, !alias.scope !1697
  %61 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %10, i64 0, i32 2
  store i32 %56, i32* %61, align 4, !alias.scope !1697
  %62 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %10, i64 0, i32 3
  store i32 %58, i32* %62, align 8, !alias.scope !1697
  %63 = bitcast %"class.gemmlowp::VectorDup"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %63) #19
  %64 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %11, i64 0, i32 0
  %65 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %66 = load i32, i32* %65, align 4, !noalias !1702
  store i32 %66, i32* %64, align 4, !alias.scope !1702
  %67 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %11, i64 0, i32 1
  %68 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 1
  %69 = load i32, i32* %68, align 4, !noalias !1702
  store i32 %69, i32* %67, align 4, !alias.scope !1702
  %70 = bitcast %"class.gemmlowp::VectorDup.194"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %70) #19
  %71 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %12, i64 0, i32 0
  %72 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %4, i64 0, i32 0
  %73 = load i32, i32* %72, align 4, !noalias !1707
  store i32 %73, i32* %71, align 4, !alias.scope !1707
  %74 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %12, i64 0, i32 1
  %75 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %4, i64 0, i32 1
  %76 = load i32, i32* %75, align 4, !noalias !1707
  store i32 %76, i32* %74, align 4, !alias.scope !1707
  %77 = bitcast %"class.std::__1::tuple.485"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 20, i8* nonnull %77) #19
  %78 = bitcast %"class.std::__1::tuple.485"* %6 to i64*
  %79 = load i64, i64* %78, align 4, !noalias !1712
  %80 = getelementptr inbounds %"class.std::__1::tuple.485", %"class.std::__1::tuple.485"* %6, i64 0, i32 0, i32 0, i32 0, i32 2
  %81 = load i32, i32* %80, align 4, !noalias !1712
  %82 = getelementptr inbounds %"class.std::__1::tuple.485", %"class.std::__1::tuple.485"* %6, i64 0, i32 0, i32 1, i32 0
  %83 = bitcast %"struct.gemmlowp::OutputStageClamp"* %82 to i64*
  %84 = load i64, i64* %83, align 4, !noalias !1712
  %85 = bitcast %"class.std::__1::tuple.485"* %13 to i64*
  store i64 %79, i64* %85, align 8, !alias.scope !1712
  %86 = getelementptr inbounds %"class.std::__1::tuple.485", %"class.std::__1::tuple.485"* %13, i64 0, i32 0, i32 0, i32 0, i32 2
  store i32 %81, i32* %86, align 8, !alias.scope !1712
  %87 = getelementptr inbounds %"class.std::__1::tuple.485", %"class.std::__1::tuple.485"* %13, i64 0, i32 0, i32 1
  %88 = bitcast %"class.std::__1::__tuple_leaf.190"* %87 to i64*
  store i64 %84, i64* %88, align 4, !alias.scope !1715
  call void @_ZN8gemmlowp17DispatchGemmShapeIhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEELNS_8MapOrderE1ELS6_0ELS6_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENS7_IS8_LS9_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT8_RKNS_9MatrixMapIKT_XT2_EEERKNSL_ISN_XT3_EEEPNSL_IT0_XT4_EEERKT5_RKT6_RKT7_(%"class.gemmlowp::GemmContext"* %0, %"class.gemmlowp::MatrixMap"* nonnull dereferenceable(24) %9, %"class.gemmlowp::MatrixMap.180"* nonnull dereferenceable(24) %10, %"class.gemmlowp::MatrixMap.479"* nonnull %8, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %11, %"class.gemmlowp::VectorDup.194"* nonnull dereferenceable(8) %12, %"class.std::__1::tuple.485"* nonnull dereferenceable(20) %13)
  call void @llvm.lifetime.end.p0i8(i64 20, i8* nonnull %77) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %70) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %63) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %52) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %39) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %29) #19
  br label %93

89:                                               ; preds = %26
  %90 = bitcast %"struct.gemmlowp::DefaultKernel"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %90) #19
  %91 = getelementptr inbounds %"struct.gemmlowp::DefaultKernel", %"struct.gemmlowp::DefaultKernel"* %14, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [6 x i8*] }, { [6 x i8*] }* @_ZTVN8gemmlowp13DefaultKernelINS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS2_ILi0ELi255EEEEEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %91, align 8
  %92 = getelementptr inbounds %"struct.gemmlowp::DefaultKernel", %"struct.gemmlowp::DefaultKernel"* %14, i64 0, i32 0, i32 0, i32 0, i32 0
  call void @_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSV_ISX_XT4_EEEPNSV_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::GemmContext"* %0, %"struct.gemmlowp::KernelBase"* nonnull dereferenceable(8) %92, %"class.gemmlowp::MatrixMap"* dereferenceable(24) %1, %"class.gemmlowp::MatrixMap.180"* dereferenceable(24) %2, %"class.gemmlowp::MatrixMap.489"* %3, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %4, %"class.gemmlowp::VectorDup"* dereferenceable(8) %5, %"class.std::__1::tuple.485"* dereferenceable(20) %6)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %90) #19
  br label %93

93:                                               ; preds = %7, %89, %28
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSV_ISX_XT4_EEEPNSV_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::GemmContext"*, %"struct.gemmlowp::KernelBase"* dereferenceable(8), %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.180"* dereferenceable(24), %"class.gemmlowp::MatrixMap.479"*, %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.std::__1::tuple.485"* dereferenceable(20)) local_unnamed_addr #1 comdat {
  %9 = alloca %"class.gemmlowp::SideMap", align 8
  %10 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %11 = alloca %"struct.gemmlowp::BlockParams", align 4
  %12 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %13 = alloca %"class.std::__1::vector.205", align 8
  %14 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %4, i64 0, i32 1
  %15 = load i32, i32* %14, align 8
  %16 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %4, i64 0, i32 2
  %17 = load i32, i32* %16, align 4
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 2
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %"class.gemmlowp::GemmContext", %"class.gemmlowp::GemmContext"* %0, i64 0, i32 0, i32 0, i32 1
  %21 = load i32, i32* %20, align 4
  switch i32 %21, label %34 [
    i32 1, label %54
    i32 0, label %22
  ]

22:                                               ; preds = %8
  %23 = load atomic i8, i8* bitcast (i64* @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count to i8*) acquire, align 8
  %24 = icmp eq i8 %23, 0
  br i1 %24, label %25, label %32, !prof !514

25:                                               ; preds = %22
  %26 = tail call i32 @__cxa_guard_acquire(i64* nonnull @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count) #19
  %27 = icmp eq i32 %26, 0
  br i1 %27, label %32, label %28

28:                                               ; preds = %25
  %29 = tail call i64 @sysconf(i32 83) #19
  %30 = trunc i64 %29 to i32
  store i32 %30, i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count, align 4
  %31 = tail call {}* @llvm.invariant.start.p0i8(i64 4, i8* bitcast (i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count to i8*)) #19
  tail call void @__cxa_guard_release(i64* nonnull @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count) #19
  br label %32

32:                                               ; preds = %28, %25, %22
  %33 = load i32, i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count, align 4
  br label %34

34:                                               ; preds = %32, %8
  %35 = phi i32 [ %33, %32 ], [ %21, %8 ]
  %36 = add i32 %15, 15
  %37 = sdiv i32 %36, 16
  %38 = icmp slt i32 %37, %35
  %39 = select i1 %38, i32 %37, i32 %35
  %40 = icmp sgt i32 %39, 1
  br i1 %40, label %41, label %56

41:                                               ; preds = %34
  %42 = sext i32 %15 to i64
  %43 = sext i32 %17 to i64
  %44 = mul nsw i64 %43, %42
  %45 = sext i32 %19 to i64
  %46 = mul i64 %44, %45
  %47 = lshr i64 %46, 16
  %48 = trunc i64 %47 to i32
  %49 = icmp sgt i32 %39, %48
  %50 = select i1 %49, i32 %48, i32 %39
  %51 = icmp sgt i32 %50, 1
  br i1 %51, label %52, label %54

52:                                               ; preds = %41
  %53 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br label %61

54:                                               ; preds = %41, %8
  %55 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br label %59

56:                                               ; preds = %34
  %57 = icmp eq i32 %39, 1
  %58 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br i1 %57, label %59, label %61

59:                                               ; preds = %54, %56
  %60 = phi %"class.gemmlowp::SingleThreadGemmContext"* [ %55, %54 ], [ %58, %56 ]
  tail call void @_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSU_ISW_XT4_EEEPNSU_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::SingleThreadGemmContext"* %60, %"struct.gemmlowp::KernelBase"* dereferenceable(8) %1, %"class.gemmlowp::MatrixMap"* dereferenceable(24) %2, %"class.gemmlowp::MatrixMap.180"* dereferenceable(24) %3, %"class.gemmlowp::MatrixMap.479"* %4, %"class.gemmlowp::VectorDup"* dereferenceable(8) %5, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.std::__1::tuple.485"* dereferenceable(20) %7)
  br label %303

61:                                               ; preds = %52, %56
  %62 = phi %"class.gemmlowp::SingleThreadGemmContext"* [ %53, %52 ], [ %58, %56 ]
  %63 = phi i32 [ %50, %52 ], [ %39, %56 ]
  %64 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0
  %65 = getelementptr inbounds %"class.gemmlowp::GemmContext", %"class.gemmlowp::GemmContext"* %0, i64 0, i32 0, i32 1
  %66 = bitcast %"struct.gemmlowp::BlockParams"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %66) #19
  %67 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 1
  %68 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 2
  %69 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 4
  %70 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 5
  %71 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 1
  %72 = bitcast %"struct.gemmlowp::BlockParams"* %11 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %72, i8 -86, i64 24, i1 false)
  %73 = load i32, i32* %71, align 8
  %74 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 2
  %75 = load i32, i32* %74, align 4
  %76 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 3
  %77 = load float, float* %76, align 8
  call void @_ZN8gemmlowp11BlockParams4InitINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES7_EEEEviiiiiif(%"struct.gemmlowp::BlockParams"* nonnull %11, i32 %15, i32 %17, i32 %19, i32 %63, i32 %73, i32 %75, float %77)
  %78 = bitcast %"class.gemmlowp::PackedSideBlock"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %78) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %78, i8 -86, i64 80, i1 false)
  %79 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %64, %"class.gemmlowp::Allocator"** %79, align 8
  %80 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 4
  store i32 0, i32* %80, align 8
  %81 = load i32, i32* %67, align 4
  %82 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 0
  store i32 %81, i32* %82, align 8
  %83 = load i32, i32* %69, align 4
  %84 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 2
  store i32 %83, i32* %84, align 8
  %85 = load i32, i32* %68, align 4
  %86 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 1
  store i32 %85, i32* %86, align 4
  %87 = load i32, i32* %70, align 4
  %88 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 3
  store i32 %87, i32* %88, align 4
  %89 = mul nsw i32 %87, %83
  %90 = sext i32 %89 to i64
  %91 = add nsw i64 %90, 63
  %92 = and i64 %91, -64
  %93 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 4
  %94 = load i64, i64* %93, align 8, !noalias !1718
  %95 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 3
  %96 = load i64, i64* %95, align 8, !noalias !1718
  %97 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 5, i64 %96
  store i64 %94, i64* %97, align 8, !noalias !1718
  %98 = trunc i64 %96 to i8
  %99 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 6
  %100 = load i64, i64* %99, align 8, !noalias !1718
  %101 = load i64, i64* %95, align 8, !noalias !1718
  %102 = add i64 %101, 1
  store i64 %102, i64* %95, align 8, !noalias !1718
  %103 = load i64, i64* %93, align 8, !noalias !1718
  %104 = add i64 %103, %92
  store i64 %104, i64* %93, align 8, !noalias !1718
  %105 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 0
  store i8 %98, i8* %105, align 8
  %106 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %106, i8 -86, i64 7, i1 false) #19
  %107 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 2
  store i64 %100, i64* %107, align 8
  %108 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 3
  store i8 0, i8* %108, align 8
  %109 = sext i32 %83 to i64
  %110 = shl nsw i64 %109, 2
  %111 = add nsw i64 %110, 63
  %112 = and i64 %111, -64
  %113 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 5, i64 %102
  store i64 %104, i64* %113, align 8, !noalias !1721
  %114 = trunc i64 %102 to i8
  %115 = load i64, i64* %99, align 8, !noalias !1721
  %116 = bitcast i64* %95 to <2 x i64>*
  %117 = load <2 x i64>, <2 x i64>* %116, align 8, !noalias !1721
  %118 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %112, i32 1
  %119 = add <2 x i64> %117, %118
  %120 = bitcast i64* %95 to <2 x i64>*
  store <2 x i64> %119, <2 x i64>* %120, align 8, !noalias !1721
  %121 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 0
  store i8 %114, i8* %121, align 8
  %122 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %122, i8 -86, i64 7, i1 false) #19
  %123 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 2
  store i64 %115, i64* %123, align 8
  %124 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 3
  store i8 5, i8* %124, align 8
  call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %64)
  %125 = icmp sgt i32 %17, 0
  br i1 %125, label %126, label %150

126:                                              ; preds = %61
  %127 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 0
  %128 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 3
  %129 = bitcast %"class.gemmlowp::SideMap"* %9 to i8*
  %130 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 1
  %131 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 2
  %132 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 3
  %133 = bitcast %"class.gemmlowp::SideMap"* %9 to i64*
  %134 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %10 to i8*
  %135 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 0
  %136 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 1
  %137 = bitcast %"class.std::__1::vector.205"* %13 to i8*
  %138 = getelementptr inbounds %"class.std::__1::vector.205", %"class.std::__1::vector.205"* %13, i64 0, i32 0, i32 0
  %139 = getelementptr inbounds %"class.std::__1::vector.205", %"class.std::__1::vector.205"* %13, i64 0, i32 0, i32 1
  %140 = getelementptr inbounds %"class.std::__1::vector.205", %"class.std::__1::vector.205"* %13, i64 0, i32 0, i32 2, i32 0, i32 0
  %141 = icmp sgt i32 %63, 0
  %142 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 0
  %143 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 3
  %144 = bitcast %"class.gemmlowp::MatrixMap.479"* %4 to i64*
  %145 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %4, i64 0, i32 3
  %146 = bitcast %"struct.gemmlowp::Task"*** %139 to i64*
  %147 = bitcast %"class.std::__1::vector.205"* %13 to i64*
  %148 = bitcast %"struct.gemmlowp::Task"*** %140 to i64*
  %149 = load i32, i32* %69, align 4
  br label %155

150:                                              ; preds = %173, %61
  %151 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 0
  store i8 0, i8* %151, align 8
  %152 = load i64, i64* %99, align 8
  %153 = add i64 %152, 1
  store i64 %153, i64* %99, align 8
  %154 = bitcast i64* %95 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %154, i8 0, i64 16, i1 false) #19
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %78) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %66) #19
  br label %303

155:                                              ; preds = %126, %173
  %156 = phi i32 [ %149, %126 ], [ %174, %173 ]
  %157 = phi i32 [ 0, %126 ], [ %175, %173 ]
  %158 = sub nsw i32 %17, %157
  %159 = icmp slt i32 %158, %156
  %160 = select i1 %159, i32 %158, i32 %156
  %161 = load i8*, i8** %127, align 8, !noalias !1724
  %162 = load i32, i32* %128, align 8, !noalias !1724
  %163 = mul nsw i32 %162, %157
  %164 = sext i32 %163 to i64
  %165 = getelementptr inbounds i8, i8* %161, i64 %164
  %166 = ptrtoint i8* %165 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %129) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %129, i8 -86, i64 24, i1 false) #19
  store i64 %166, i64* %133, align 8
  store i32 %160, i32* %130, align 8
  store i32 %19, i32* %131, align 4
  store i32 %162, i32* %132, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %134) #19
  store %"class.gemmlowp::PackedSideBlock"* %12, %"class.gemmlowp::PackedSideBlock"** %135, align 8
  store %"class.gemmlowp::SideMap"* %9, %"class.gemmlowp::SideMap"** %136, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %10) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %134) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %129) #19
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %137) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %137, i8 0, i64 24, i1 false) #19
  br i1 %141, label %177, label %167

167:                                              ; preds = %297, %155
  call void @_ZN8gemmlowp11WorkersPool28LegacyExecuteAndDestroyTasksERKNSt3__16vectorIPNS_4TaskENS1_9allocatorIS4_EEEE(%"class.gemmlowp::WorkersPool"* %65, %"class.std::__1::vector.205"* nonnull dereferenceable(24) %13) #19
  %168 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %138, align 8
  %169 = icmp eq %"struct.gemmlowp::Task"** %168, null
  br i1 %169, label %173, label %170

170:                                              ; preds = %167
  %171 = ptrtoint %"struct.gemmlowp::Task"** %168 to i64
  store i64 %171, i64* %146, align 8
  %172 = bitcast %"struct.gemmlowp::Task"** %168 to i8*
  call void @_ZdlPv(i8* %172) #18
  br label %173

173:                                              ; preds = %167, %170
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %137) #19
  %174 = load i32, i32* %69, align 4
  %175 = add nsw i32 %174, %157
  %176 = icmp sgt i32 %17, %175
  br i1 %176, label %155, label %150

177:                                              ; preds = %155, %299
  %178 = phi i64 [ %302, %299 ], [ 0, %155 ]
  %179 = phi %"struct.gemmlowp::Task"** [ %301, %299 ], [ null, %155 ]
  %180 = phi %"struct.gemmlowp::Task"** [ %300, %299 ], [ null, %155 ]
  %181 = phi i32 [ %183, %299 ], [ 0, %155 ]
  %182 = phi i32 [ %189, %299 ], [ 0, %155 ]
  %183 = add nuw nsw i32 %181, 1
  %184 = mul nsw i32 %183, %15
  %185 = sdiv i32 %184, %63
  %186 = add i32 %185, 3
  %187 = and i32 %186, -4
  %188 = icmp slt i32 %187, %15
  %189 = select i1 %188, i32 %187, i32 %15
  %190 = sub nsw i32 %189, %182
  %191 = load i8*, i8** %142, align 8, !noalias !1727
  %192 = load i32, i32* %143, align 8, !noalias !1727
  %193 = mul nsw i32 %192, %182
  %194 = sext i32 %193 to i64
  %195 = getelementptr inbounds i8, i8* %191, i64 %194
  %196 = ptrtoint i8* %195 to i64
  %197 = call i8* @_Znwm(i64 208) #18
  %198 = bitcast i8* %197 to i32 (...)***
  %199 = getelementptr inbounds i8, i8* %197, i64 8
  %200 = bitcast i8* %199 to %"class.gemmlowp::Allocator"**
  store %"class.gemmlowp::Allocator"* null, %"class.gemmlowp::Allocator"** %200, align 8
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %198, align 8
  %201 = getelementptr inbounds i8, i8* %197, i64 16
  %202 = bitcast i8* %201 to %"class.gemmlowp::GemmContext"**
  store %"class.gemmlowp::GemmContext"* %0, %"class.gemmlowp::GemmContext"** %202, align 8
  %203 = getelementptr inbounds i8, i8* %197, i64 24
  %204 = bitcast i8* %203 to %"struct.gemmlowp::KernelBase"**
  store %"struct.gemmlowp::KernelBase"* %1, %"struct.gemmlowp::KernelBase"** %204, align 8
  %205 = getelementptr inbounds i8, i8* %197, i64 32
  %206 = bitcast i8* %205 to i64*
  store i64 %196, i64* %206, align 8
  %207 = getelementptr inbounds i8, i8* %197, i64 40
  %208 = bitcast i8* %207 to i32*
  store i32 %190, i32* %208, align 8
  %209 = getelementptr inbounds i8, i8* %197, i64 44
  %210 = bitcast i8* %209 to i32*
  store i32 %19, i32* %210, align 4
  %211 = getelementptr inbounds i8, i8* %197, i64 48
  %212 = bitcast i8* %211 to i32*
  store i32 %192, i32* %212, align 8
  %213 = getelementptr inbounds i8, i8* %197, i64 56
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %213, i8* nonnull align 8 %78, i64 80, i1 false) #19
  %214 = getelementptr inbounds i8, i8* %197, i64 136
  %215 = load i64, i64* %144, align 8
  %216 = bitcast i8* %214 to i64*
  store i64 %215, i64* %216, align 8
  %217 = getelementptr inbounds i8, i8* %197, i64 144
  %218 = bitcast i8* %217 to i32*
  %219 = load i32, i32* %14, align 8
  store i32 %219, i32* %218, align 8
  %220 = getelementptr inbounds i8, i8* %197, i64 148
  %221 = bitcast i8* %220 to i32*
  %222 = load i32, i32* %16, align 4
  store i32 %222, i32* %221, align 4
  %223 = getelementptr inbounds i8, i8* %197, i64 152
  %224 = bitcast i8* %223 to i32*
  %225 = load i32, i32* %145, align 8
  store i32 %225, i32* %224, align 8
  %226 = getelementptr inbounds i8, i8* %197, i64 160
  %227 = bitcast i8* %226 to i32*
  store i32 %182, i32* %227, align 8
  %228 = getelementptr inbounds i8, i8* %197, i64 164
  %229 = bitcast i8* %228 to i32*
  store i32 %157, i32* %229, align 4
  %230 = getelementptr inbounds i8, i8* %197, i64 168
  %231 = bitcast i8* %230 to i32*
  store i32 %190, i32* %231, align 8
  %232 = getelementptr inbounds i8, i8* %197, i64 172
  %233 = bitcast i8* %232 to i32*
  store i32 %160, i32* %233, align 4
  %234 = getelementptr inbounds i8, i8* %197, i64 176
  %235 = bitcast i8* %234 to %"class.gemmlowp::VectorDup"**
  store %"class.gemmlowp::VectorDup"* %5, %"class.gemmlowp::VectorDup"** %235, align 8
  %236 = getelementptr inbounds i8, i8* %197, i64 184
  %237 = bitcast i8* %236 to %"class.gemmlowp::VectorDup.194"**
  store %"class.gemmlowp::VectorDup.194"* %6, %"class.gemmlowp::VectorDup.194"** %237, align 8
  %238 = getelementptr inbounds i8, i8* %197, i64 192
  %239 = bitcast i8* %238 to %"struct.gemmlowp::BlockParams"**
  store %"struct.gemmlowp::BlockParams"* %11, %"struct.gemmlowp::BlockParams"** %239, align 8
  %240 = getelementptr inbounds i8, i8* %197, i64 200
  %241 = bitcast i8* %240 to %"class.std::__1::tuple.485"**
  store %"class.std::__1::tuple.485"* %7, %"class.std::__1::tuple.485"** %241, align 8
  %242 = ptrtoint i8* %197 to i64
  %243 = icmp ult %"struct.gemmlowp::Task"** %180, %179
  %244 = ptrtoint %"struct.gemmlowp::Task"** %179 to i64
  br i1 %243, label %245, label %249

245:                                              ; preds = %177
  %246 = bitcast %"struct.gemmlowp::Task"** %180 to i64*
  store i64 %242, i64* %246, align 8
  %247 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %180, i64 1
  %248 = ptrtoint %"struct.gemmlowp::Task"** %247 to i64
  store i64 %248, i64* %146, align 8
  br label %297

249:                                              ; preds = %177
  %250 = ptrtoint %"struct.gemmlowp::Task"** %180 to i64
  %251 = load i64, i64* %147, align 8
  %252 = sub i64 %250, %251
  %253 = ashr exact i64 %252, 3
  %254 = add nsw i64 %253, 1
  %255 = icmp ugt i64 %254, 2305843009213693951
  br i1 %255, label %256, label %258

256:                                              ; preds = %249
  %257 = bitcast %"class.std::__1::vector.205"* %13 to %"class.std::__1::__vector_base_common"*
  call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* nonnull %257) #20
  unreachable

258:                                              ; preds = %249
  %259 = sub i64 %244, %251
  %260 = ashr exact i64 %259, 3
  %261 = icmp ult i64 %260, 1152921504606846975
  br i1 %261, label %262, label %270

262:                                              ; preds = %258
  %263 = ashr exact i64 %259, 2
  %264 = icmp ult i64 %263, %254
  %265 = select i1 %264, i64 %254, i64 %263
  %266 = icmp eq i64 %265, 0
  br i1 %266, label %275, label %267

267:                                              ; preds = %262
  %268 = icmp ugt i64 %265, 2305843009213693951
  br i1 %268, label %269, label %270

269:                                              ; preds = %267
  call void @abort() #20
  unreachable

270:                                              ; preds = %267, %258
  %271 = phi i64 [ %265, %267 ], [ 2305843009213693951, %258 ]
  %272 = shl i64 %271, 3
  %273 = call i8* @_Znwm(i64 %272) #18
  %274 = bitcast i8* %273 to %"struct.gemmlowp::Task"**
  br label %275

275:                                              ; preds = %270, %262
  %276 = phi i64 [ %271, %270 ], [ 0, %262 ]
  %277 = phi %"struct.gemmlowp::Task"** [ %274, %270 ], [ null, %262 ]
  %278 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %277, i64 %253
  %279 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %277, i64 %276
  %280 = ptrtoint %"struct.gemmlowp::Task"** %279 to i64
  %281 = bitcast %"struct.gemmlowp::Task"** %278 to i64*
  store i64 %242, i64* %281, align 8
  %282 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %278, i64 1
  %283 = ptrtoint %"struct.gemmlowp::Task"** %282 to i64
  %284 = sub i64 %178, %251
  %285 = ashr exact i64 %284, 3
  %286 = sub nsw i64 0, %285
  %287 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %278, i64 %286
  %288 = ptrtoint %"struct.gemmlowp::Task"** %287 to i64
  %289 = icmp sgt i64 %284, 0
  br i1 %289, label %290, label %293

290:                                              ; preds = %275
  %291 = bitcast %"struct.gemmlowp::Task"** %287 to i8*
  %292 = inttoptr i64 %251 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %291, i8* align 8 %292, i64 %284, i1 false) #19
  br label %293

293:                                              ; preds = %290, %275
  store i64 %288, i64* %147, align 8
  store i64 %283, i64* %146, align 8
  store i64 %280, i64* %148, align 8
  %294 = icmp eq i64 %251, 0
  br i1 %294, label %297, label %295

295:                                              ; preds = %293
  %296 = inttoptr i64 %251 to i8*
  call void @_ZdlPv(i8* %296) #18
  br label %297

297:                                              ; preds = %245, %293, %295
  %298 = icmp eq i32 %183, %63
  br i1 %298, label %167, label %299

299:                                              ; preds = %297
  %300 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %139, align 8
  %301 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %140, align 8
  %302 = ptrtoint %"struct.gemmlowp::Task"** %300 to i64
  br label %177

303:                                              ; preds = %150, %59
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp15MultiThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEEvPT9_RKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSV_ISX_XT4_EEEPNSV_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::GemmContext"*, %"struct.gemmlowp::KernelBase"* dereferenceable(8), %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.180"* dereferenceable(24), %"class.gemmlowp::MatrixMap.489"*, %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.std::__1::tuple.485"* dereferenceable(20)) local_unnamed_addr #1 comdat {
  %9 = alloca %"class.gemmlowp::SideMap", align 8
  %10 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %11 = alloca %"struct.gemmlowp::BlockParams", align 4
  %12 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %13 = alloca %"class.std::__1::vector.205", align 8
  %14 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %4, i64 0, i32 1
  %15 = load i32, i32* %14, align 8
  %16 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %4, i64 0, i32 2
  %17 = load i32, i32* %16, align 4
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 2
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %"class.gemmlowp::GemmContext", %"class.gemmlowp::GemmContext"* %0, i64 0, i32 0, i32 0, i32 1
  %21 = load i32, i32* %20, align 4
  switch i32 %21, label %34 [
    i32 1, label %54
    i32 0, label %22
  ]

22:                                               ; preds = %8
  %23 = load atomic i8, i8* bitcast (i64* @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count to i8*) acquire, align 8
  %24 = icmp eq i8 %23, 0
  br i1 %24, label %25, label %32, !prof !514

25:                                               ; preds = %22
  %26 = tail call i32 @__cxa_guard_acquire(i64* nonnull @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count) #19
  %27 = icmp eq i32 %26, 0
  br i1 %27, label %32, label %28

28:                                               ; preds = %25
  %29 = tail call i64 @sysconf(i32 83) #19
  %30 = trunc i64 %29 to i32
  store i32 %30, i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count, align 4
  %31 = tail call {}* @llvm.invariant.start.p0i8(i64 4, i8* bitcast (i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count to i8*)) #19
  tail call void @__cxa_guard_release(i64* nonnull @_ZGVZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count) #19
  br label %32

32:                                               ; preds = %28, %25, %22
  %33 = load i32, i32* @_ZZN8gemmlowp22GetHardwareConcurrencyEiE22hardware_threads_count, align 4
  br label %34

34:                                               ; preds = %32, %8
  %35 = phi i32 [ %33, %32 ], [ %21, %8 ]
  %36 = add i32 %15, 15
  %37 = sdiv i32 %36, 16
  %38 = icmp slt i32 %37, %35
  %39 = select i1 %38, i32 %37, i32 %35
  %40 = icmp sgt i32 %39, 1
  br i1 %40, label %41, label %56

41:                                               ; preds = %34
  %42 = sext i32 %15 to i64
  %43 = sext i32 %17 to i64
  %44 = mul nsw i64 %43, %42
  %45 = sext i32 %19 to i64
  %46 = mul i64 %44, %45
  %47 = lshr i64 %46, 16
  %48 = trunc i64 %47 to i32
  %49 = icmp sgt i32 %39, %48
  %50 = select i1 %49, i32 %48, i32 %39
  %51 = icmp sgt i32 %50, 1
  br i1 %51, label %52, label %54

52:                                               ; preds = %41
  %53 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br label %61

54:                                               ; preds = %41, %8
  %55 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br label %59

56:                                               ; preds = %34
  %57 = icmp eq i32 %39, 1
  %58 = bitcast %"class.gemmlowp::GemmContext"* %0 to %"class.gemmlowp::SingleThreadGemmContext"*
  br i1 %57, label %59, label %61

59:                                               ; preds = %54, %56
  %60 = phi %"class.gemmlowp::SingleThreadGemmContext"* [ %55, %54 ], [ %58, %56 ]
  tail call void @_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSU_ISW_XT4_EEEPNSU_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::SingleThreadGemmContext"* %60, %"struct.gemmlowp::KernelBase"* dereferenceable(8) %1, %"class.gemmlowp::MatrixMap"* dereferenceable(24) %2, %"class.gemmlowp::MatrixMap.180"* dereferenceable(24) %3, %"class.gemmlowp::MatrixMap.489"* %4, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %5, %"class.gemmlowp::VectorDup"* dereferenceable(8) %6, %"class.std::__1::tuple.485"* dereferenceable(20) %7)
  br label %303

61:                                               ; preds = %52, %56
  %62 = phi %"class.gemmlowp::SingleThreadGemmContext"* [ %53, %52 ], [ %58, %56 ]
  %63 = phi i32 [ %50, %52 ], [ %39, %56 ]
  %64 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0
  %65 = getelementptr inbounds %"class.gemmlowp::GemmContext", %"class.gemmlowp::GemmContext"* %0, i64 0, i32 0, i32 1
  %66 = bitcast %"struct.gemmlowp::BlockParams"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %66) #19
  %67 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 1
  %68 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 2
  %69 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 4
  %70 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %11, i64 0, i32 5
  %71 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 1
  %72 = bitcast %"struct.gemmlowp::BlockParams"* %11 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %72, i8 -86, i64 24, i1 false)
  %73 = load i32, i32* %71, align 8
  %74 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 2
  %75 = load i32, i32* %74, align 4
  %76 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 3
  %77 = load float, float* %76, align 8
  call void @_ZN8gemmlowp11BlockParams4InitINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES7_EEEEviiiiiif(%"struct.gemmlowp::BlockParams"* nonnull %11, i32 %15, i32 %17, i32 %19, i32 %63, i32 %73, i32 %75, float %77)
  %78 = bitcast %"class.gemmlowp::PackedSideBlock"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %78) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %78, i8 -86, i64 80, i1 false)
  %79 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %64, %"class.gemmlowp::Allocator"** %79, align 8
  %80 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 4
  store i32 0, i32* %80, align 8
  %81 = load i32, i32* %67, align 4
  %82 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 0
  store i32 %81, i32* %82, align 8
  %83 = load i32, i32* %69, align 4
  %84 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 2
  store i32 %83, i32* %84, align 8
  %85 = load i32, i32* %68, align 4
  %86 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 1
  store i32 %85, i32* %86, align 4
  %87 = load i32, i32* %70, align 4
  %88 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 0, i32 3
  store i32 %87, i32* %88, align 4
  %89 = mul nsw i32 %87, %83
  %90 = sext i32 %89 to i64
  %91 = add nsw i64 %90, 63
  %92 = and i64 %91, -64
  %93 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 4
  %94 = load i64, i64* %93, align 8, !noalias !1730
  %95 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 3
  %96 = load i64, i64* %95, align 8, !noalias !1730
  %97 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 5, i64 %96
  store i64 %94, i64* %97, align 8, !noalias !1730
  %98 = trunc i64 %96 to i8
  %99 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 6
  %100 = load i64, i64* %99, align 8, !noalias !1730
  %101 = load i64, i64* %95, align 8, !noalias !1730
  %102 = add i64 %101, 1
  store i64 %102, i64* %95, align 8, !noalias !1730
  %103 = load i64, i64* %93, align 8, !noalias !1730
  %104 = add i64 %103, %92
  store i64 %104, i64* %93, align 8, !noalias !1730
  %105 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 0
  store i8 %98, i8* %105, align 8
  %106 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %106, i8 -86, i64 7, i1 false) #19
  %107 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 2
  store i64 %100, i64* %107, align 8
  %108 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 2, i32 3
  store i8 0, i8* %108, align 8
  %109 = sext i32 %83 to i64
  %110 = shl nsw i64 %109, 2
  %111 = add nsw i64 %110, 63
  %112 = and i64 %111, -64
  %113 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 5, i64 %102
  store i64 %104, i64* %113, align 8, !noalias !1733
  %114 = trunc i64 %102 to i8
  %115 = load i64, i64* %99, align 8, !noalias !1733
  %116 = bitcast i64* %95 to <2 x i64>*
  %117 = load <2 x i64>, <2 x i64>* %116, align 8, !noalias !1733
  %118 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %112, i32 1
  %119 = add <2 x i64> %117, %118
  %120 = bitcast i64* %95 to <2 x i64>*
  store <2 x i64> %119, <2 x i64>* %120, align 8, !noalias !1733
  %121 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 0
  store i8 %114, i8* %121, align 8
  %122 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %122, i8 -86, i64 7, i1 false) #19
  %123 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 2
  store i64 %115, i64* %123, align 8
  %124 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %12, i64 0, i32 3, i32 3
  store i8 5, i8* %124, align 8
  call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %64)
  %125 = icmp sgt i32 %17, 0
  br i1 %125, label %126, label %150

126:                                              ; preds = %61
  %127 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 0
  %128 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 3
  %129 = bitcast %"class.gemmlowp::SideMap"* %9 to i8*
  %130 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 1
  %131 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 2
  %132 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 3
  %133 = bitcast %"class.gemmlowp::SideMap"* %9 to i64*
  %134 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %10 to i8*
  %135 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 0
  %136 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 1
  %137 = bitcast %"class.std::__1::vector.205"* %13 to i8*
  %138 = getelementptr inbounds %"class.std::__1::vector.205", %"class.std::__1::vector.205"* %13, i64 0, i32 0, i32 0
  %139 = getelementptr inbounds %"class.std::__1::vector.205", %"class.std::__1::vector.205"* %13, i64 0, i32 0, i32 1
  %140 = getelementptr inbounds %"class.std::__1::vector.205", %"class.std::__1::vector.205"* %13, i64 0, i32 0, i32 2, i32 0, i32 0
  %141 = icmp sgt i32 %63, 0
  %142 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 0
  %143 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 3
  %144 = bitcast %"class.gemmlowp::MatrixMap.489"* %4 to i64*
  %145 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %4, i64 0, i32 3
  %146 = bitcast %"struct.gemmlowp::Task"*** %139 to i64*
  %147 = bitcast %"class.std::__1::vector.205"* %13 to i64*
  %148 = bitcast %"struct.gemmlowp::Task"*** %140 to i64*
  %149 = load i32, i32* %69, align 4
  br label %155

150:                                              ; preds = %173, %61
  %151 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %62, i64 0, i32 0, i32 0
  store i8 0, i8* %151, align 8
  %152 = load i64, i64* %99, align 8
  %153 = add i64 %152, 1
  store i64 %153, i64* %99, align 8
  %154 = bitcast i64* %95 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %154, i8 0, i64 16, i1 false) #19
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %78) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %66) #19
  br label %303

155:                                              ; preds = %126, %173
  %156 = phi i32 [ %149, %126 ], [ %174, %173 ]
  %157 = phi i32 [ 0, %126 ], [ %175, %173 ]
  %158 = sub nsw i32 %17, %157
  %159 = icmp slt i32 %158, %156
  %160 = select i1 %159, i32 %158, i32 %156
  %161 = load i8*, i8** %127, align 8, !noalias !1736
  %162 = load i32, i32* %128, align 8, !noalias !1736
  %163 = mul nsw i32 %162, %157
  %164 = sext i32 %163 to i64
  %165 = getelementptr inbounds i8, i8* %161, i64 %164
  %166 = ptrtoint i8* %165 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %129) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %129, i8 -86, i64 24, i1 false) #19
  store i64 %166, i64* %133, align 8
  store i32 %160, i32* %130, align 8
  store i32 %19, i32* %131, align 4
  store i32 %162, i32* %132, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %134) #19
  store %"class.gemmlowp::PackedSideBlock"* %12, %"class.gemmlowp::PackedSideBlock"** %135, align 8
  store %"class.gemmlowp::SideMap"* %9, %"class.gemmlowp::SideMap"** %136, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %10) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %134) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %129) #19
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %137) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %137, i8 0, i64 24, i1 false) #19
  br i1 %141, label %177, label %167

167:                                              ; preds = %297, %155
  call void @_ZN8gemmlowp11WorkersPool28LegacyExecuteAndDestroyTasksERKNSt3__16vectorIPNS_4TaskENS1_9allocatorIS4_EEEE(%"class.gemmlowp::WorkersPool"* %65, %"class.std::__1::vector.205"* nonnull dereferenceable(24) %13) #19
  %168 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %138, align 8
  %169 = icmp eq %"struct.gemmlowp::Task"** %168, null
  br i1 %169, label %173, label %170

170:                                              ; preds = %167
  %171 = ptrtoint %"struct.gemmlowp::Task"** %168 to i64
  store i64 %171, i64* %146, align 8
  %172 = bitcast %"struct.gemmlowp::Task"** %168 to i8*
  call void @_ZdlPv(i8* %172) #18
  br label %173

173:                                              ; preds = %167, %170
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %137) #19
  %174 = load i32, i32* %69, align 4
  %175 = add nsw i32 %174, %157
  %176 = icmp sgt i32 %17, %175
  br i1 %176, label %155, label %150

177:                                              ; preds = %155, %299
  %178 = phi i64 [ %302, %299 ], [ 0, %155 ]
  %179 = phi %"struct.gemmlowp::Task"** [ %301, %299 ], [ null, %155 ]
  %180 = phi %"struct.gemmlowp::Task"** [ %300, %299 ], [ null, %155 ]
  %181 = phi i32 [ %183, %299 ], [ 0, %155 ]
  %182 = phi i32 [ %189, %299 ], [ 0, %155 ]
  %183 = add nuw nsw i32 %181, 1
  %184 = mul nsw i32 %183, %15
  %185 = sdiv i32 %184, %63
  %186 = add i32 %185, 3
  %187 = and i32 %186, -4
  %188 = icmp slt i32 %187, %15
  %189 = select i1 %188, i32 %187, i32 %15
  %190 = sub nsw i32 %189, %182
  %191 = load i8*, i8** %142, align 8, !noalias !1739
  %192 = load i32, i32* %143, align 8, !noalias !1739
  %193 = mul nsw i32 %192, %182
  %194 = sext i32 %193 to i64
  %195 = getelementptr inbounds i8, i8* %191, i64 %194
  %196 = ptrtoint i8* %195 to i64
  %197 = call i8* @_Znwm(i64 208) #18
  %198 = bitcast i8* %197 to i32 (...)***
  %199 = getelementptr inbounds i8, i8* %197, i64 8
  %200 = bitcast i8* %199 to %"class.gemmlowp::Allocator"**
  store %"class.gemmlowp::Allocator"* null, %"class.gemmlowp::Allocator"** %200, align 8
  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %198, align 8
  %201 = getelementptr inbounds i8, i8* %197, i64 16
  %202 = bitcast i8* %201 to %"class.gemmlowp::GemmContext"**
  store %"class.gemmlowp::GemmContext"* %0, %"class.gemmlowp::GemmContext"** %202, align 8
  %203 = getelementptr inbounds i8, i8* %197, i64 24
  %204 = bitcast i8* %203 to %"struct.gemmlowp::KernelBase"**
  store %"struct.gemmlowp::KernelBase"* %1, %"struct.gemmlowp::KernelBase"** %204, align 8
  %205 = getelementptr inbounds i8, i8* %197, i64 32
  %206 = bitcast i8* %205 to i64*
  store i64 %196, i64* %206, align 8
  %207 = getelementptr inbounds i8, i8* %197, i64 40
  %208 = bitcast i8* %207 to i32*
  store i32 %190, i32* %208, align 8
  %209 = getelementptr inbounds i8, i8* %197, i64 44
  %210 = bitcast i8* %209 to i32*
  store i32 %19, i32* %210, align 4
  %211 = getelementptr inbounds i8, i8* %197, i64 48
  %212 = bitcast i8* %211 to i32*
  store i32 %192, i32* %212, align 8
  %213 = getelementptr inbounds i8, i8* %197, i64 56
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %213, i8* nonnull align 8 %78, i64 80, i1 false) #19
  %214 = getelementptr inbounds i8, i8* %197, i64 136
  %215 = load i64, i64* %144, align 8
  %216 = bitcast i8* %214 to i64*
  store i64 %215, i64* %216, align 8
  %217 = getelementptr inbounds i8, i8* %197, i64 144
  %218 = bitcast i8* %217 to i32*
  %219 = load i32, i32* %14, align 8
  store i32 %219, i32* %218, align 8
  %220 = getelementptr inbounds i8, i8* %197, i64 148
  %221 = bitcast i8* %220 to i32*
  %222 = load i32, i32* %16, align 4
  store i32 %222, i32* %221, align 4
  %223 = getelementptr inbounds i8, i8* %197, i64 152
  %224 = bitcast i8* %223 to i32*
  %225 = load i32, i32* %145, align 8
  store i32 %225, i32* %224, align 8
  %226 = getelementptr inbounds i8, i8* %197, i64 160
  %227 = bitcast i8* %226 to i32*
  store i32 %182, i32* %227, align 8
  %228 = getelementptr inbounds i8, i8* %197, i64 164
  %229 = bitcast i8* %228 to i32*
  store i32 %157, i32* %229, align 4
  %230 = getelementptr inbounds i8, i8* %197, i64 168
  %231 = bitcast i8* %230 to i32*
  store i32 %190, i32* %231, align 8
  %232 = getelementptr inbounds i8, i8* %197, i64 172
  %233 = bitcast i8* %232 to i32*
  store i32 %160, i32* %233, align 4
  %234 = getelementptr inbounds i8, i8* %197, i64 176
  %235 = bitcast i8* %234 to %"class.gemmlowp::VectorDup.194"**
  store %"class.gemmlowp::VectorDup.194"* %5, %"class.gemmlowp::VectorDup.194"** %235, align 8
  %236 = getelementptr inbounds i8, i8* %197, i64 184
  %237 = bitcast i8* %236 to %"class.gemmlowp::VectorDup"**
  store %"class.gemmlowp::VectorDup"* %6, %"class.gemmlowp::VectorDup"** %237, align 8
  %238 = getelementptr inbounds i8, i8* %197, i64 192
  %239 = bitcast i8* %238 to %"struct.gemmlowp::BlockParams"**
  store %"struct.gemmlowp::BlockParams"* %11, %"struct.gemmlowp::BlockParams"** %239, align 8
  %240 = getelementptr inbounds i8, i8* %197, i64 200
  %241 = bitcast i8* %240 to %"class.std::__1::tuple.485"**
  store %"class.std::__1::tuple.485"* %7, %"class.std::__1::tuple.485"** %241, align 8
  %242 = ptrtoint i8* %197 to i64
  %243 = icmp ult %"struct.gemmlowp::Task"** %180, %179
  %244 = ptrtoint %"struct.gemmlowp::Task"** %179 to i64
  br i1 %243, label %245, label %249

245:                                              ; preds = %177
  %246 = bitcast %"struct.gemmlowp::Task"** %180 to i64*
  store i64 %242, i64* %246, align 8
  %247 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %180, i64 1
  %248 = ptrtoint %"struct.gemmlowp::Task"** %247 to i64
  store i64 %248, i64* %146, align 8
  br label %297

249:                                              ; preds = %177
  %250 = ptrtoint %"struct.gemmlowp::Task"** %180 to i64
  %251 = load i64, i64* %147, align 8
  %252 = sub i64 %250, %251
  %253 = ashr exact i64 %252, 3
  %254 = add nsw i64 %253, 1
  %255 = icmp ugt i64 %254, 2305843009213693951
  br i1 %255, label %256, label %258

256:                                              ; preds = %249
  %257 = bitcast %"class.std::__1::vector.205"* %13 to %"class.std::__1::__vector_base_common"*
  call void @_ZNKSt3__120__vector_base_commonILb1EE20__throw_length_errorEv(%"class.std::__1::__vector_base_common"* nonnull %257) #20
  unreachable

258:                                              ; preds = %249
  %259 = sub i64 %244, %251
  %260 = ashr exact i64 %259, 3
  %261 = icmp ult i64 %260, 1152921504606846975
  br i1 %261, label %262, label %270

262:                                              ; preds = %258
  %263 = ashr exact i64 %259, 2
  %264 = icmp ult i64 %263, %254
  %265 = select i1 %264, i64 %254, i64 %263
  %266 = icmp eq i64 %265, 0
  br i1 %266, label %275, label %267

267:                                              ; preds = %262
  %268 = icmp ugt i64 %265, 2305843009213693951
  br i1 %268, label %269, label %270

269:                                              ; preds = %267
  call void @abort() #20
  unreachable

270:                                              ; preds = %267, %258
  %271 = phi i64 [ %265, %267 ], [ 2305843009213693951, %258 ]
  %272 = shl i64 %271, 3
  %273 = call i8* @_Znwm(i64 %272) #18
  %274 = bitcast i8* %273 to %"struct.gemmlowp::Task"**
  br label %275

275:                                              ; preds = %270, %262
  %276 = phi i64 [ %271, %270 ], [ 0, %262 ]
  %277 = phi %"struct.gemmlowp::Task"** [ %274, %270 ], [ null, %262 ]
  %278 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %277, i64 %253
  %279 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %277, i64 %276
  %280 = ptrtoint %"struct.gemmlowp::Task"** %279 to i64
  %281 = bitcast %"struct.gemmlowp::Task"** %278 to i64*
  store i64 %242, i64* %281, align 8
  %282 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %278, i64 1
  %283 = ptrtoint %"struct.gemmlowp::Task"** %282 to i64
  %284 = sub i64 %178, %251
  %285 = ashr exact i64 %284, 3
  %286 = sub nsw i64 0, %285
  %287 = getelementptr inbounds %"struct.gemmlowp::Task"*, %"struct.gemmlowp::Task"** %278, i64 %286
  %288 = ptrtoint %"struct.gemmlowp::Task"** %287 to i64
  %289 = icmp sgt i64 %284, 0
  br i1 %289, label %290, label %293

290:                                              ; preds = %275
  %291 = bitcast %"struct.gemmlowp::Task"** %287 to i8*
  %292 = inttoptr i64 %251 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 8 %291, i8* align 8 %292, i64 %284, i1 false) #19
  br label %293

293:                                              ; preds = %290, %275
  store i64 %288, i64* %147, align 8
  store i64 %283, i64* %146, align 8
  store i64 %280, i64* %148, align 8
  %294 = icmp eq i64 %251, 0
  br i1 %294, label %297, label %295

295:                                              ; preds = %293
  %296 = inttoptr i64 %251 to i8*
  call void @_ZdlPv(i8* %296) #18
  br label %297

297:                                              ; preds = %245, %293, %295
  %298 = icmp eq i32 %183, %63
  br i1 %298, label %167, label %299

299:                                              ; preds = %297
  %300 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %139, align 8
  %301 = load %"struct.gemmlowp::Task"**, %"struct.gemmlowp::Task"*** %140, align 8
  %302 = ptrtoint %"struct.gemmlowp::Task"** %300 to i64
  br label %177

303:                                              ; preds = %150, %59
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSU_ISW_XT4_EEEPNSU_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::SingleThreadGemmContext"*, %"struct.gemmlowp::KernelBase"* dereferenceable(8), %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.180"* dereferenceable(24), %"class.gemmlowp::MatrixMap.489"*, %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.std::__1::tuple.485"* dereferenceable(20)) local_unnamed_addr #1 comdat {
  %9 = alloca %"class.gemmlowp::SideMap", align 8
  %10 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %11 = alloca %"class.gemmlowp::SideMap", align 8
  %12 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %13 = alloca %"class.gemmlowp::SideMap", align 8
  %14 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %15 = alloca %"class.gemmlowp::ComputeImpl", align 8
  %16 = alloca %"struct.gemmlowp::BlockParams", align 4
  %17 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %18 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %19 = alloca %"class.gemmlowp::PackedResult", align 8
  %20 = alloca %"struct.gemmlowp::MatrixBlockBounds", align 4
  %21 = alloca %"class.gemmlowp::VectorDup.194", align 4
  %22 = alloca %"class.gemmlowp::VectorDup", align 4
  %23 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %4, i64 0, i32 1
  %24 = load i32, i32* %23, align 8
  %25 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %4, i64 0, i32 2
  %26 = load i32, i32* %25, align 4
  %27 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 2
  %28 = load i32, i32* %27, align 4
  %29 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0
  %30 = bitcast %"struct.gemmlowp::BlockParams"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %30) #19
  %31 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 0
  %32 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 1
  %33 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 2
  %34 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 3
  %35 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 4
  %36 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 5
  %37 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 1
  %38 = bitcast %"struct.gemmlowp::BlockParams"* %16 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %38, i8 -86, i64 24, i1 false)
  %39 = load i32, i32* %37, align 8
  %40 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 2
  %41 = load i32, i32* %40, align 4
  %42 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 3
  %43 = load float, float* %42, align 8
  call void @_ZN8gemmlowp11BlockParams4InitINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES7_EEEEviiiiiif(%"struct.gemmlowp::BlockParams"* nonnull %16, i32 %24, i32 %26, i32 %28, i32 1, i32 %39, i32 %41, float %43)
  %44 = bitcast %"class.gemmlowp::PackedSideBlock"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %44) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %44, i8 -86, i64 80, i1 false)
  %45 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %45, align 8
  %46 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 4
  store i32 0, i32* %46, align 8
  %47 = load i32, i32* %31, align 4
  %48 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 0
  store i32 %47, i32* %48, align 8
  %49 = load i32, i32* %34, align 4
  %50 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 2
  store i32 %49, i32* %50, align 8
  %51 = load i32, i32* %33, align 4
  %52 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 1
  store i32 %51, i32* %52, align 4
  %53 = load i32, i32* %36, align 4
  %54 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 3
  store i32 %53, i32* %54, align 4
  %55 = mul nsw i32 %53, %49
  %56 = sext i32 %55 to i64
  %57 = add nsw i64 %56, 63
  %58 = and i64 %57, -64
  %59 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 4
  %60 = load i64, i64* %59, align 8, !noalias !1742
  %61 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 3
  %62 = load i64, i64* %61, align 8, !noalias !1742
  %63 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %62
  store i64 %60, i64* %63, align 8, !noalias !1742
  %64 = trunc i64 %62 to i8
  %65 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 6
  %66 = load i64, i64* %65, align 8, !noalias !1742
  %67 = load i64, i64* %61, align 8, !noalias !1742
  %68 = add i64 %67, 1
  store i64 %68, i64* %61, align 8, !noalias !1742
  %69 = load i64, i64* %59, align 8, !noalias !1742
  %70 = add i64 %69, %58
  store i64 %70, i64* %59, align 8, !noalias !1742
  %71 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 0
  store i8 %64, i8* %71, align 8
  %72 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %72, i8 -86, i64 7, i1 false) #19
  %73 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 2
  store i64 %66, i64* %73, align 8
  %74 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 3
  store i8 0, i8* %74, align 8
  %75 = sext i32 %49 to i64
  %76 = shl nsw i64 %75, 2
  %77 = add nsw i64 %76, 63
  %78 = and i64 %77, -64
  %79 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %68
  store i64 %70, i64* %79, align 8, !noalias !1745
  %80 = trunc i64 %68 to i8
  %81 = load i64, i64* %65, align 8, !noalias !1745
  %82 = load i64, i64* %61, align 8, !noalias !1745
  %83 = add i64 %82, 1
  store i64 %83, i64* %61, align 8, !noalias !1745
  %84 = load i64, i64* %59, align 8, !noalias !1745
  %85 = add i64 %84, %78
  store i64 %85, i64* %59, align 8, !noalias !1745
  %86 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 0
  store i8 %80, i8* %86, align 8
  %87 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %87, i8 -86, i64 7, i1 false) #19
  %88 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 2
  store i64 %81, i64* %88, align 8
  %89 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 3
  store i8 5, i8* %89, align 8
  %90 = bitcast %"class.gemmlowp::PackedSideBlock"* %18 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %90) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %90, i8 -86, i64 80, i1 false)
  %91 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %91, align 8
  %92 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 4
  store i32 0, i32* %92, align 8
  %93 = load i32, i32* %32, align 4
  %94 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 0
  store i32 %93, i32* %94, align 8
  %95 = load i32, i32* %35, align 4
  %96 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 2
  store i32 %95, i32* %96, align 8
  %97 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 1
  store i32 %51, i32* %97, align 4
  %98 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 3
  store i32 %53, i32* %98, align 4
  %99 = mul nsw i32 %53, %95
  %100 = sext i32 %99 to i64
  %101 = add nsw i64 %100, 63
  %102 = and i64 %101, -64
  %103 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %83
  store i64 %85, i64* %103, align 8, !noalias !1748
  %104 = trunc i64 %83 to i8
  %105 = load i64, i64* %65, align 8, !noalias !1748
  %106 = load i64, i64* %61, align 8, !noalias !1748
  %107 = add i64 %106, 1
  store i64 %107, i64* %61, align 8, !noalias !1748
  %108 = load i64, i64* %59, align 8, !noalias !1748
  %109 = add i64 %108, %102
  store i64 %109, i64* %59, align 8, !noalias !1748
  %110 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 0
  store i8 %104, i8* %110, align 8
  %111 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %111, i8 -86, i64 7, i1 false) #19
  %112 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 2
  store i64 %105, i64* %112, align 8
  %113 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 3
  store i8 0, i8* %113, align 8
  %114 = sext i32 %95 to i64
  %115 = shl nsw i64 %114, 2
  %116 = add nsw i64 %115, 63
  %117 = and i64 %116, -64
  %118 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %107
  store i64 %109, i64* %118, align 8, !noalias !1751
  %119 = trunc i64 %107 to i8
  %120 = load i64, i64* %65, align 8, !noalias !1751
  %121 = load i64, i64* %61, align 8, !noalias !1751
  %122 = add i64 %121, 1
  store i64 %122, i64* %61, align 8, !noalias !1751
  %123 = load i64, i64* %59, align 8, !noalias !1751
  %124 = add i64 %123, %117
  store i64 %124, i64* %59, align 8, !noalias !1751
  %125 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 0
  store i8 %119, i8* %125, align 8
  %126 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %126, i8 -86, i64 7, i1 false) #19
  %127 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 2
  store i64 %120, i64* %127, align 8
  %128 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 3
  store i8 5, i8* %128, align 8
  %129 = bitcast %"class.gemmlowp::PackedResult"* %19 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %129) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %129, i8 -86, i64 32, i1 false)
  %130 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 0
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %130, align 8
  %131 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 2
  store %"struct.gemmlowp::BlockParams"* %16, %"struct.gemmlowp::BlockParams"** %131, align 8
  %132 = load i32, i32* %34, align 4
  %133 = mul nsw i32 %95, %132
  %134 = sext i32 %133 to i64
  %135 = shl nsw i64 %134, 2
  %136 = add nsw i64 %135, 63
  %137 = and i64 %136, -64
  %138 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %122
  store i64 %124, i64* %138, align 8, !noalias !1754
  %139 = trunc i64 %122 to i8
  %140 = load i64, i64* %65, align 8, !noalias !1754
  %141 = bitcast i64* %61 to <2 x i64>*
  %142 = load <2 x i64>, <2 x i64>* %141, align 8, !noalias !1754
  %143 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %137, i32 1
  %144 = add <2 x i64> %142, %143
  %145 = bitcast i64* %61 to <2 x i64>*
  store <2 x i64> %144, <2 x i64>* %145, align 8, !noalias !1754
  %146 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 0
  store i8 %139, i8* %146, align 8
  %147 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %147, i8 -86, i64 7, i1 false) #19
  %148 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 2
  store i64 %140, i64* %148, align 8
  %149 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 3
  store i8 5, i8* %149, align 8
  call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %29)
  %150 = load i32, i32* %35, align 4
  %151 = icmp sge i32 %150, %26
  br i1 %151, label %152, label %169

152:                                              ; preds = %8
  %153 = bitcast %"class.gemmlowp::SideMap"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %153) #19
  %154 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 1
  %155 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 2
  %156 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 3
  %157 = bitcast %"class.gemmlowp::MatrixMap.180"* %3 to i64*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %153, i8 -86, i64 24, i1 false) #19
  %158 = load i64, i64* %157, align 8
  %159 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 2
  %160 = load i32, i32* %159, align 4
  %161 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 1
  %162 = load i32, i32* %161, align 8
  %163 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 3
  %164 = load i32, i32* %163, align 8
  %165 = bitcast %"class.gemmlowp::SideMap"* %9 to i64*
  store i64 %158, i64* %165, align 8
  store i32 %160, i32* %154, align 8
  store i32 %162, i32* %155, align 4
  store i32 %164, i32* %156, align 8
  %166 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %166) #19
  %167 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 0
  %168 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 1
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %167, align 8
  store %"class.gemmlowp::SideMap"* %9, %"class.gemmlowp::SideMap"** %168, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %10) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %166) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %153) #19
  br label %169

169:                                              ; preds = %152, %8
  %170 = icmp sgt i32 %24, 0
  br i1 %170, label %171, label %216

171:                                              ; preds = %169
  %172 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 0
  %173 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 3
  %174 = bitcast %"class.gemmlowp::SideMap"* %11 to i8*
  %175 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 1
  %176 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 2
  %177 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 3
  %178 = bitcast %"class.gemmlowp::SideMap"* %11 to i64*
  %179 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %12 to i8*
  %180 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %12, i64 0, i32 0
  %181 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %12, i64 0, i32 1
  %182 = icmp sgt i32 %26, 0
  %183 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 0
  %184 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 3
  %185 = bitcast %"class.gemmlowp::SideMap"* %13 to i8*
  %186 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 1
  %187 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 2
  %188 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 3
  %189 = bitcast %"class.gemmlowp::SideMap"* %13 to i64*
  %190 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %14 to i8*
  %191 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %14, i64 0, i32 0
  %192 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %14, i64 0, i32 1
  %193 = bitcast %"class.gemmlowp::ComputeImpl"* %15 to i8*
  %194 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 0
  %195 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 1
  %196 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 2
  %197 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 3
  %198 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 4
  %199 = add i32 %28, 15
  %200 = and i32 %199, -16
  %201 = icmp sgt i32 %200, 0
  %202 = bitcast %"struct.gemmlowp::MatrixBlockBounds"* %20 to i8*
  %203 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 0
  %204 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 1
  %205 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 2
  %206 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 3
  %207 = bitcast %"class.gemmlowp::VectorDup.194"* %21 to i8*
  %208 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 0
  %209 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %21, i64 0, i32 0
  %210 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %21, i64 0, i32 1
  %211 = bitcast %"class.gemmlowp::VectorDup"* %22 to i8*
  %212 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %213 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %22, i64 0, i32 0
  %214 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %22, i64 0, i32 1
  %215 = load i32, i32* %34, align 4
  br label %221

216:                                              ; preds = %235, %169
  %217 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 0
  store i8 0, i8* %217, align 8
  %218 = load i64, i64* %65, align 8
  %219 = add i64 %218, 1
  store i64 %219, i64* %65, align 8
  %220 = bitcast i64* %61 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %220, i8 0, i64 16, i1 false) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %129) #19
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %90) #19
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %44) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %30) #19
  ret void

221:                                              ; preds = %171, %235
  %222 = phi i32 [ %215, %171 ], [ %236, %235 ]
  %223 = phi i32 [ 0, %171 ], [ %237, %235 ]
  %224 = sub nsw i32 %24, %223
  %225 = icmp slt i32 %224, %222
  %226 = select i1 %225, i32 %224, i32 %222
  %227 = load i8*, i8** %172, align 8, !noalias !1757
  %228 = load i32, i32* %173, align 8, !noalias !1757
  %229 = mul nsw i32 %228, %223
  %230 = sext i32 %229 to i64
  %231 = getelementptr inbounds i8, i8* %227, i64 %230
  %232 = ptrtoint i8* %231 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %174) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %174, i8 -86, i64 24, i1 false) #19
  store i64 %232, i64* %178, align 8
  store i32 %226, i32* %175, align 8
  store i32 %28, i32* %176, align 4
  store i32 %228, i32* %177, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %179) #19
  store %"class.gemmlowp::PackedSideBlock"* %17, %"class.gemmlowp::PackedSideBlock"** %180, align 8
  store %"class.gemmlowp::SideMap"* %11, %"class.gemmlowp::SideMap"** %181, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %12) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %179) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %174) #19
  br i1 %182, label %233, label %235

233:                                              ; preds = %221
  %234 = load i32, i32* %35, align 4
  br label %239

235:                                              ; preds = %311, %221
  %236 = load i32, i32* %34, align 4
  %237 = add nsw i32 %236, %223
  %238 = icmp sgt i32 %24, %237
  br i1 %238, label %221, label %216

239:                                              ; preds = %233, %311
  %240 = phi i32 [ %334, %311 ], [ %234, %233 ]
  %241 = phi i32 [ %335, %311 ], [ 0, %233 ]
  %242 = sub nsw i32 %26, %241
  %243 = icmp slt i32 %242, %240
  %244 = select i1 %243, i32 %242, i32 %240
  br i1 %151, label %252, label %245

245:                                              ; preds = %239
  %246 = load i8*, i8** %183, align 8, !noalias !1760
  %247 = load i32, i32* %184, align 8, !noalias !1760
  %248 = mul nsw i32 %247, %241
  %249 = sext i32 %248 to i64
  %250 = getelementptr inbounds i8, i8* %246, i64 %249
  %251 = ptrtoint i8* %250 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %185) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %185, i8 -86, i64 24, i1 false) #19
  store i64 %251, i64* %189, align 8
  store i32 %244, i32* %186, align 8
  store i32 %28, i32* %187, align 4
  store i32 %247, i32* %188, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %190) #19
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %191, align 8
  store %"class.gemmlowp::SideMap"* %13, %"class.gemmlowp::SideMap"** %192, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %14) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %190) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %185) #19
  br label %252

252:                                              ; preds = %245, %239
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %193) #19
  store %"struct.gemmlowp::KernelBase"* %1, %"struct.gemmlowp::KernelBase"** %194, align 8
  store %"struct.gemmlowp::BlockParams"* %16, %"struct.gemmlowp::BlockParams"** %195, align 8
  store %"class.gemmlowp::PackedResult"* %19, %"class.gemmlowp::PackedResult"** %196, align 8
  store %"class.gemmlowp::PackedSideBlock"* %17, %"class.gemmlowp::PackedSideBlock"** %197, align 8
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %198, align 8
  br i1 %201, label %253, label %311

253:                                              ; preds = %252, %271
  %254 = phi %"struct.gemmlowp::BlockParams"* [ %273, %271 ], [ %16, %252 ]
  %255 = phi %"struct.gemmlowp::BlockParams"* [ %274, %271 ], [ %16, %252 ]
  %256 = phi i32 [ %275, %271 ], [ 0, %252 ]
  %257 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 2
  %258 = sub nsw i32 %200, %256
  %259 = load i32, i32* %257, align 4
  %260 = icmp slt i32 %258, %259
  %261 = select i1 %260, i32 %258, i32 %259
  %262 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 3
  %263 = load i32, i32* %262, align 4
  %264 = icmp sgt i32 %263, 0
  br i1 %264, label %265, label %271

265:                                              ; preds = %253
  %266 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 0
  %267 = load i32, i32* %266, align 4
  br label %277

268:                                              ; preds = %303
  %269 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 2
  %270 = load i32, i32* %269, align 4
  br label %271

271:                                              ; preds = %268, %253
  %272 = phi i32 [ %259, %253 ], [ %270, %268 ]
  %273 = phi %"struct.gemmlowp::BlockParams"* [ %254, %253 ], [ %304, %268 ]
  %274 = phi %"struct.gemmlowp::BlockParams"* [ %255, %253 ], [ %304, %268 ]
  %275 = add nsw i32 %272, %256
  %276 = icmp sgt i32 %200, %275
  br i1 %276, label %253, label %311

277:                                              ; preds = %303, %265
  %278 = phi %"struct.gemmlowp::BlockParams"* [ %304, %303 ], [ %254, %265 ]
  %279 = phi i32 [ %306, %303 ], [ %267, %265 ]
  %280 = phi i32 [ %309, %303 ], [ %263, %265 ]
  %281 = phi %"struct.gemmlowp::BlockParams"* [ %304, %303 ], [ %255, %265 ]
  %282 = phi i32 [ %307, %303 ], [ 0, %265 ]
  %283 = sub nsw i32 %280, %282
  %284 = icmp slt i32 %283, %279
  %285 = select i1 %284, i32 %283, i32 %279
  %286 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %281, i64 0, i32 4
  %287 = load i32, i32* %286, align 4
  %288 = icmp sgt i32 %287, 0
  br i1 %288, label %289, label %303

289:                                              ; preds = %277
  %290 = icmp sgt i32 %285, 0
  br label %291

291:                                              ; preds = %293, %289
  %292 = phi i32 [ 0, %289 ], [ %294, %293 ]
  br i1 %290, label %296, label %293

293:                                              ; preds = %296, %291
  %294 = add nuw nsw i32 %292, 4
  %295 = icmp slt i32 %294, %287
  br i1 %295, label %291, label %301

296:                                              ; preds = %291, %296
  %297 = phi i32 [ %299, %296 ], [ 0, %291 ]
  %298 = add nsw i32 %297, %282
  call void @_ZN8gemmlowp11ComputeImplINS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEES7_NS_12PackedResultEE10ComputeRunEiiii(%"class.gemmlowp::ComputeImpl"* nonnull %15, i32 %298, i32 %292, i32 %256, i32 %261) #19
  %299 = add nuw nsw i32 %297, 4
  %300 = icmp slt i32 %299, %285
  br i1 %300, label %296, label %293

301:                                              ; preds = %293
  %302 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %195, align 8
  br label %303

303:                                              ; preds = %301, %277
  %304 = phi %"struct.gemmlowp::BlockParams"* [ %302, %301 ], [ %278, %277 ]
  %305 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 0
  %306 = load i32, i32* %305, align 4
  %307 = add nsw i32 %306, %282
  %308 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 3
  %309 = load i32, i32* %308, align 4
  %310 = icmp sgt i32 %309, %307
  br i1 %310, label %277, label %268

311:                                              ; preds = %271, %252
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %193) #19
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %202) #19
  store i32 %223, i32* %203, align 4
  store i32 %241, i32* %204, align 4
  store i32 %226, i32* %205, align 4
  store i32 %244, i32* %206, align 4
  %312 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %45, align 8
  %313 = load i8, i8* %86, align 8
  %314 = zext i8 %313 to i64
  %315 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %312, i64 0, i32 5, i64 %314
  %316 = load i64, i64* %315, align 8
  %317 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %312, i64 0, i32 2
  %318 = bitcast i8** %317 to i64*
  %319 = load i64, i64* %318, align 8
  %320 = add i64 %319, %316
  %321 = inttoptr i64 %320 to i32*
  %322 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %91, align 8
  %323 = load i8, i8* %125, align 8
  %324 = zext i8 %323 to i64
  %325 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %322, i64 0, i32 5, i64 %324
  %326 = load i64, i64* %325, align 8
  %327 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %322, i64 0, i32 2
  %328 = bitcast i8** %327 to i64*
  %329 = load i64, i64* %328, align 8
  %330 = add i64 %329, %326
  %331 = inttoptr i64 %330 to i32*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %207) #19
  %332 = load i32, i32* %208, align 4, !noalias !1763
  store i32 %332, i32* %209, align 4, !alias.scope !1763
  store i32 %226, i32* %210, align 4, !alias.scope !1763
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %211) #19
  %333 = load i32, i32* %212, align 4, !noalias !1766
  store i32 %333, i32* %213, align 4, !alias.scope !1766
  store i32 %244, i32* %214, align 4, !alias.scope !1766
  call void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIsLNS_8MapOrderE1EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE1EEENSC_ISD_LSE_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SV_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.489"* %4, %"struct.gemmlowp::MatrixBlockBounds"* nonnull dereferenceable(16) %20, %"class.gemmlowp::PackedResult"* nonnull dereferenceable(40) %19, i32 %28, i32* %321, i32* %331, %"class.gemmlowp::VectorDup.194"* nonnull dereferenceable(8) %21, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %22, %"class.std::__1::tuple.485"* dereferenceable(20) %7)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %211) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %207) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %202) #19
  %334 = load i32, i32* %35, align 4
  %335 = add nsw i32 %334, %241
  %336 = icmp sgt i32 %26, %335
  br i1 %336, label %239, label %235
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIsLNS_8MapOrderE1EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE1EEENSC_ISD_LSE_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SV_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.489"*, %"struct.gemmlowp::MatrixBlockBounds"* dereferenceable(16), %"class.gemmlowp::PackedResult"* dereferenceable(40), i32, i32*, i32*, %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.std::__1::tuple.485"* dereferenceable(20)) local_unnamed_addr #1 comdat {
  %10 = alloca %"struct.gemmlowp::RegisterBlock.559", align 8
  %11 = alloca %"class.gemmlowp::MatrixMap.214", align 8
  %12 = alloca %"class.gemmlowp::VectorMap", align 8
  %13 = alloca %"class.gemmlowp::VectorMap.201", align 8
  %14 = alloca %"struct.gemmlowp::OutputPipelineExecutor.631", align 8
  %15 = alloca %"struct.gemmlowp::OutputPipelineExecutor.638", align 8
  %16 = alloca %"struct.gemmlowp::OutputPipelineExecutor.645", align 8
  %17 = alloca %"struct.gemmlowp::OutputPipelineExecutor.652", align 8
  %18 = alloca %"struct.gemmlowp::OutputPipelineExecutor.659", align 8
  %19 = alloca [64 x i16], align 16
  %20 = alloca %"class.gemmlowp::MatrixMap.479", align 8
  %21 = bitcast %"class.gemmlowp::MatrixMap.214"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %21) #19
  %22 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %11, i64 0, i32 0
  %23 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %11, i64 0, i32 1
  %24 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %11, i64 0, i32 2
  %25 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %11, i64 0, i32 3
  %26 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 0
  %27 = bitcast %"class.gemmlowp::MatrixMap.214"* %11 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %27, i8 -86, i64 24, i1 false)
  %28 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %26, align 8, !noalias !1769
  %29 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 1, i32 0
  %30 = load i8, i8* %29, align 8, !noalias !1769
  %31 = zext i8 %30 to i64
  %32 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %28, i64 0, i32 5, i64 %31
  %33 = load i64, i64* %32, align 8, !noalias !1769
  %34 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %28, i64 0, i32 2
  %35 = bitcast i8** %34 to i64*
  %36 = load i64, i64* %35, align 8, !noalias !1769
  %37 = add i64 %36, %33
  %38 = inttoptr i64 %37 to i32*
  %39 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 2
  %40 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %39, align 8, !noalias !1769
  %41 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %40, i64 0, i32 3
  %42 = load i32, i32* %41, align 4, !noalias !1769
  %43 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %40, i64 0, i32 4
  %44 = load i32, i32* %43, align 4, !noalias !1769
  store i32* %38, i32** %22, align 8, !alias.scope !1769
  store i32 %42, i32* %23, align 8, !alias.scope !1769
  store i32 %44, i32* %24, align 4, !alias.scope !1769
  store i32 %42, i32* %25, align 8, !alias.scope !1769
  %45 = bitcast %"class.gemmlowp::VectorMap"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %45) #19
  %46 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %12, i64 0, i32 0
  %47 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %12, i64 0, i32 1
  %48 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 2
  %49 = bitcast %"class.gemmlowp::VectorMap"* %12 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %49, i8 -86, i64 16, i1 false)
  %50 = load i32, i32* %48, align 4
  store i32* %4, i32** %46, align 8
  store i32 %50, i32* %47, align 8
  %51 = bitcast %"class.gemmlowp::VectorMap.201"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %51) #19
  %52 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %13, i64 0, i32 0
  %53 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %13, i64 0, i32 1
  %54 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 3
  %55 = bitcast %"class.gemmlowp::VectorMap.201"* %13 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %55, i8 -86, i64 16, i1 false)
  %56 = load i32, i32* %54, align 4
  store i32* %5, i32** %52, align 8
  store i32 %56, i32* %53, align 8
  %57 = getelementptr inbounds %"class.std::__1::tuple.485", %"class.std::__1::tuple.485"* %8, i64 0, i32 0, i32 0, i32 0
  %58 = getelementptr inbounds %"class.std::__1::tuple.485", %"class.std::__1::tuple.485"* %8, i64 0, i32 0, i32 0, i32 0, i32 1
  %59 = load i32, i32* %58, align 4
  %60 = icmp sgt i32 %59, 0
  %61 = select i1 %60, i32 %59, i32 0
  %62 = sub nsw i32 0, %59
  %63 = icmp sgt i32 %62, 0
  %64 = select i1 %63, i32 %62, i32 0
  %65 = getelementptr inbounds %"class.std::__1::tuple.485", %"class.std::__1::tuple.485"* %8, i64 0, i32 0, i32 1, i32 0
  %66 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.631"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %66) #19
  %67 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.631", %"struct.gemmlowp::OutputPipelineExecutor.631"* %14, i64 0, i32 0, i32 0, i32 0, i32 0
  %68 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.631", %"struct.gemmlowp::OutputPipelineExecutor.631"* %14, i64 0, i32 0, i32 0, i32 0, i32 1
  %69 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.631", %"struct.gemmlowp::OutputPipelineExecutor.631"* %14, i64 0, i32 0, i32 0, i32 0, i32 2
  %70 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.631", %"struct.gemmlowp::OutputPipelineExecutor.631"* %14, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %71 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.631", %"struct.gemmlowp::OutputPipelineExecutor.631"* %14, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %72 = bitcast i8* %71 to i64*
  store i64 -6148914691236517206, i64* %72, align 8
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %57, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %67, align 8
  store i32 %61, i32* %68, align 8
  store i32 %64, i32* %69, align 4
  store %"struct.gemmlowp::OutputStageClamp"* %65, %"struct.gemmlowp::OutputStageClamp"** %70, align 8
  %73 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.638"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %73) #19
  %74 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.638", %"struct.gemmlowp::OutputPipelineExecutor.638"* %15, i64 0, i32 0, i32 0, i32 0, i32 0
  %75 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.638", %"struct.gemmlowp::OutputPipelineExecutor.638"* %15, i64 0, i32 0, i32 0, i32 0, i32 1
  %76 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.638", %"struct.gemmlowp::OutputPipelineExecutor.638"* %15, i64 0, i32 0, i32 0, i32 0, i32 2
  %77 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.638", %"struct.gemmlowp::OutputPipelineExecutor.638"* %15, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %78 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.638", %"struct.gemmlowp::OutputPipelineExecutor.638"* %15, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %79 = bitcast i8* %78 to i64*
  store i64 -6148914691236517206, i64* %79, align 8
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %57, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %74, align 8
  store i32 %61, i32* %75, align 8
  store i32 %64, i32* %76, align 4
  store %"struct.gemmlowp::OutputStageClamp"* %65, %"struct.gemmlowp::OutputStageClamp"** %77, align 8
  %80 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.645"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %80) #19
  %81 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.645", %"struct.gemmlowp::OutputPipelineExecutor.645"* %16, i64 0, i32 0, i32 0, i32 0, i32 0
  %82 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.645", %"struct.gemmlowp::OutputPipelineExecutor.645"* %16, i64 0, i32 0, i32 0, i32 0, i32 1
  %83 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.645", %"struct.gemmlowp::OutputPipelineExecutor.645"* %16, i64 0, i32 0, i32 0, i32 0, i32 2
  %84 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.645", %"struct.gemmlowp::OutputPipelineExecutor.645"* %16, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %85 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.645", %"struct.gemmlowp::OutputPipelineExecutor.645"* %16, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %86 = bitcast i8* %85 to i64*
  store i64 -6148914691236517206, i64* %86, align 8
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %57, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %81, align 8
  store i32 %61, i32* %82, align 8
  store i32 %64, i32* %83, align 4
  store %"struct.gemmlowp::OutputStageClamp"* %65, %"struct.gemmlowp::OutputStageClamp"** %84, align 8
  %87 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.652"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %87) #19
  %88 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.652", %"struct.gemmlowp::OutputPipelineExecutor.652"* %17, i64 0, i32 0, i32 0, i32 0, i32 0
  %89 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.652", %"struct.gemmlowp::OutputPipelineExecutor.652"* %17, i64 0, i32 0, i32 0, i32 0, i32 1
  %90 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.652", %"struct.gemmlowp::OutputPipelineExecutor.652"* %17, i64 0, i32 0, i32 0, i32 0, i32 2
  %91 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.652", %"struct.gemmlowp::OutputPipelineExecutor.652"* %17, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %92 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.652", %"struct.gemmlowp::OutputPipelineExecutor.652"* %17, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %93 = bitcast i8* %92 to i64*
  store i64 -6148914691236517206, i64* %93, align 8
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %57, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %88, align 8
  store i32 %61, i32* %89, align 8
  store i32 %64, i32* %90, align 4
  store %"struct.gemmlowp::OutputStageClamp"* %65, %"struct.gemmlowp::OutputStageClamp"** %91, align 8
  %94 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.659"* %18 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %94) #19
  %95 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.659", %"struct.gemmlowp::OutputPipelineExecutor.659"* %18, i64 0, i32 0, i32 0, i32 0, i32 0
  %96 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.659", %"struct.gemmlowp::OutputPipelineExecutor.659"* %18, i64 0, i32 0, i32 0, i32 0, i32 1
  %97 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.659", %"struct.gemmlowp::OutputPipelineExecutor.659"* %18, i64 0, i32 0, i32 0, i32 0, i32 2
  %98 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.659", %"struct.gemmlowp::OutputPipelineExecutor.659"* %18, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %99 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.659", %"struct.gemmlowp::OutputPipelineExecutor.659"* %18, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %100 = bitcast i8* %99 to i64*
  store i64 -6148914691236517206, i64* %100, align 8
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %57, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %95, align 8
  store i32 %61, i32* %96, align 8
  store i32 %64, i32* %97, align 4
  store %"struct.gemmlowp::OutputStageClamp"* %65, %"struct.gemmlowp::OutputStageClamp"** %98, align 8
  %101 = load i32, i32* %54, align 4
  %102 = icmp slt i32 %101, 8
  br i1 %102, label %116, label %103

103:                                              ; preds = %9
  %104 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 0
  %105 = bitcast [64 x i16]* %19 to i8*
  %106 = bitcast %"class.gemmlowp::MatrixMap.479"* %20 to i8*
  %107 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %20, i64 0, i32 0
  %108 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %20, i64 0, i32 1
  %109 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %20, i64 0, i32 2
  %110 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %20, i64 0, i32 3
  %111 = getelementptr inbounds [64 x i16], [64 x i16]* %19, i64 0, i64 0
  %112 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 1
  %113 = bitcast %"struct.gemmlowp::RegisterBlock.559"* %10 to i8*
  %114 = load i32, i32* %48, align 4
  %115 = bitcast %"class.gemmlowp::MatrixMap.479"* %20 to i8*
  br label %125

116:                                              ; preds = %287, %9
  %117 = phi i32 [ %101, %9 ], [ %290, %287 ]
  %118 = phi i32 [ 0, %9 ], [ %289, %287 ]
  %119 = add nsw i32 %117, -4
  %120 = icmp sgt i32 %118, %119
  br i1 %120, label %293, label %121

121:                                              ; preds = %116
  %122 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 1
  %123 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 0
  %124 = load i32, i32* %48, align 4
  br label %317

125:                                              ; preds = %103, %287
  %126 = phi i32 [ %114, %103 ], [ %288, %287 ]
  %127 = phi i32 [ 0, %103 ], [ %289, %287 ]
  %128 = load i32*, i32** %22, align 8
  %129 = load i32, i32* %25, align 8
  %130 = mul nsw i32 %129, %127
  %131 = sext i32 %130 to i64
  %132 = load i32*, i32** %46, align 8
  %133 = bitcast i32* %132 to i8*
  call void @llvm.prefetch(i8* %133, i32 0, i32 3, i32 1) #19
  %134 = getelementptr inbounds i32, i32* %132, i64 4
  %135 = bitcast i32* %134 to i8*
  call void @llvm.prefetch(i8* %135, i32 0, i32 3, i32 1) #19
  %136 = getelementptr inbounds i32, i32* %128, i64 %131
  %137 = sext i32 %129 to i64
  %138 = bitcast i32* %136 to i8*
  call void @llvm.prefetch(i8* %138, i32 0, i32 3, i32 1) #19
  %139 = getelementptr inbounds i32, i32* %136, i64 4
  %140 = bitcast i32* %139 to i8*
  call void @llvm.prefetch(i8* %140, i32 0, i32 3, i32 1) #19
  %141 = getelementptr inbounds i32, i32* %136, i64 %137
  %142 = bitcast i32* %141 to i8*
  call void @llvm.prefetch(i8* %142, i32 0, i32 3, i32 1) #19
  %143 = getelementptr inbounds i32, i32* %141, i64 4
  %144 = bitcast i32* %143 to i8*
  call void @llvm.prefetch(i8* %144, i32 0, i32 3, i32 1) #19
  %145 = shl nsw i64 %137, 1
  %146 = getelementptr inbounds i32, i32* %136, i64 %145
  %147 = bitcast i32* %146 to i8*
  call void @llvm.prefetch(i8* %147, i32 0, i32 3, i32 1) #19
  %148 = getelementptr inbounds i32, i32* %146, i64 4
  %149 = bitcast i32* %148 to i8*
  call void @llvm.prefetch(i8* %149, i32 0, i32 3, i32 1) #19
  %150 = mul nsw i64 %137, 3
  %151 = getelementptr inbounds i32, i32* %136, i64 %150
  %152 = bitcast i32* %151 to i8*
  call void @llvm.prefetch(i8* %152, i32 0, i32 3, i32 1) #19
  %153 = getelementptr inbounds i32, i32* %151, i64 4
  %154 = bitcast i32* %153 to i8*
  call void @llvm.prefetch(i8* %154, i32 0, i32 3, i32 1) #19
  %155 = shl nsw i64 %137, 2
  %156 = getelementptr inbounds i32, i32* %136, i64 %155
  %157 = bitcast i32* %156 to i8*
  call void @llvm.prefetch(i8* %157, i32 0, i32 3, i32 1) #19
  %158 = getelementptr inbounds i32, i32* %156, i64 4
  %159 = bitcast i32* %158 to i8*
  call void @llvm.prefetch(i8* %159, i32 0, i32 3, i32 1) #19
  %160 = mul nsw i64 %137, 5
  %161 = getelementptr inbounds i32, i32* %136, i64 %160
  %162 = bitcast i32* %161 to i8*
  call void @llvm.prefetch(i8* %162, i32 0, i32 3, i32 1) #19
  %163 = getelementptr inbounds i32, i32* %161, i64 4
  %164 = bitcast i32* %163 to i8*
  call void @llvm.prefetch(i8* %164, i32 0, i32 3, i32 1) #19
  %165 = mul nsw i64 %137, 6
  %166 = getelementptr inbounds i32, i32* %136, i64 %165
  %167 = bitcast i32* %166 to i8*
  call void @llvm.prefetch(i8* %167, i32 0, i32 3, i32 1) #19
  %168 = getelementptr inbounds i32, i32* %166, i64 4
  %169 = bitcast i32* %168 to i8*
  call void @llvm.prefetch(i8* %169, i32 0, i32 3, i32 1) #19
  %170 = mul nsw i64 %137, 7
  %171 = getelementptr inbounds i32, i32* %136, i64 %170
  %172 = bitcast i32* %171 to i8*
  call void @llvm.prefetch(i8* %172, i32 0, i32 3, i32 1) #19
  %173 = getelementptr inbounds i32, i32* %171, i64 4
  %174 = bitcast i32* %173 to i8*
  call void @llvm.prefetch(i8* %174, i32 0, i32 3, i32 1) #19
  %175 = icmp slt i32 %126, 8
  br i1 %175, label %180, label %176

176:                                              ; preds = %125
  %177 = or i32 %127, 4
  br label %187

178:                                              ; preds = %187
  %179 = trunc i64 %195 to i32
  br label %180

180:                                              ; preds = %178, %125
  %181 = phi i32 [ %126, %125 ], [ %250, %178 ]
  %182 = phi i32 [ 0, %125 ], [ %179, %178 ]
  %183 = add nsw i32 %181, -4
  %184 = icmp sgt i32 %182, %183
  br i1 %184, label %258, label %185

185:                                              ; preds = %180
  %186 = or i32 %127, 4
  br label %264

187:                                              ; preds = %254, %176
  %188 = phi i32* [ %132, %176 ], [ %257, %254 ]
  %189 = phi i32 [ %129, %176 ], [ %256, %254 ]
  %190 = phi i32* [ %128, %176 ], [ %255, %254 ]
  %191 = phi i64 [ 0, %176 ], [ %195, %254 ]
  %192 = load i32, i32* %104, align 4
  %193 = trunc i64 %191 to i32
  %194 = add nsw i32 %192, %193
  %195 = add nuw i64 %191, 8
  %196 = mul nsw i32 %189, %127
  %197 = sext i32 %196 to i64
  %198 = getelementptr inbounds i32, i32* %188, i64 %195
  %199 = bitcast i32* %198 to i8*
  call void @llvm.prefetch(i8* %199, i32 0, i32 3, i32 1) #19
  %200 = getelementptr inbounds i32, i32* %198, i64 4
  %201 = bitcast i32* %200 to i8*
  call void @llvm.prefetch(i8* %201, i32 0, i32 3, i32 1) #19
  %202 = getelementptr inbounds i32, i32* %190, i64 %195
  %203 = getelementptr inbounds i32, i32* %202, i64 %197
  %204 = sext i32 %189 to i64
  %205 = bitcast i32* %203 to i8*
  call void @llvm.prefetch(i8* %205, i32 0, i32 3, i32 1) #19
  %206 = getelementptr inbounds i32, i32* %203, i64 4
  %207 = bitcast i32* %206 to i8*
  call void @llvm.prefetch(i8* %207, i32 0, i32 3, i32 1) #19
  %208 = getelementptr inbounds i32, i32* %203, i64 %204
  %209 = bitcast i32* %208 to i8*
  call void @llvm.prefetch(i8* %209, i32 0, i32 3, i32 1) #19
  %210 = getelementptr inbounds i32, i32* %208, i64 4
  %211 = bitcast i32* %210 to i8*
  call void @llvm.prefetch(i8* %211, i32 0, i32 3, i32 1) #19
  %212 = shl nsw i64 %204, 1
  %213 = getelementptr inbounds i32, i32* %203, i64 %212
  %214 = bitcast i32* %213 to i8*
  call void @llvm.prefetch(i8* %214, i32 0, i32 3, i32 1) #19
  %215 = getelementptr inbounds i32, i32* %213, i64 4
  %216 = bitcast i32* %215 to i8*
  call void @llvm.prefetch(i8* %216, i32 0, i32 3, i32 1) #19
  %217 = mul nsw i64 %204, 3
  %218 = getelementptr inbounds i32, i32* %203, i64 %217
  %219 = bitcast i32* %218 to i8*
  call void @llvm.prefetch(i8* %219, i32 0, i32 3, i32 1) #19
  %220 = getelementptr inbounds i32, i32* %218, i64 4
  %221 = bitcast i32* %220 to i8*
  call void @llvm.prefetch(i8* %221, i32 0, i32 3, i32 1) #19
  %222 = shl nsw i64 %204, 2
  %223 = getelementptr inbounds i32, i32* %203, i64 %222
  %224 = bitcast i32* %223 to i8*
  call void @llvm.prefetch(i8* %224, i32 0, i32 3, i32 1) #19
  %225 = getelementptr inbounds i32, i32* %223, i64 4
  %226 = bitcast i32* %225 to i8*
  call void @llvm.prefetch(i8* %226, i32 0, i32 3, i32 1) #19
  %227 = mul nsw i64 %204, 5
  %228 = getelementptr inbounds i32, i32* %203, i64 %227
  %229 = bitcast i32* %228 to i8*
  call void @llvm.prefetch(i8* %229, i32 0, i32 3, i32 1) #19
  %230 = getelementptr inbounds i32, i32* %228, i64 4
  %231 = bitcast i32* %230 to i8*
  call void @llvm.prefetch(i8* %231, i32 0, i32 3, i32 1) #19
  %232 = mul nsw i64 %204, 6
  %233 = getelementptr inbounds i32, i32* %203, i64 %232
  %234 = bitcast i32* %233 to i8*
  call void @llvm.prefetch(i8* %234, i32 0, i32 3, i32 1) #19
  %235 = getelementptr inbounds i32, i32* %233, i64 4
  %236 = bitcast i32* %235 to i8*
  call void @llvm.prefetch(i8* %236, i32 0, i32 3, i32 1) #19
  %237 = mul nsw i64 %204, 7
  %238 = getelementptr inbounds i32, i32* %203, i64 %237
  %239 = bitcast i32* %238 to i8*
  call void @llvm.prefetch(i8* %239, i32 0, i32 3, i32 1) #19
  %240 = getelementptr inbounds i32, i32* %238, i64 4
  %241 = bitcast i32* %240 to i8*
  call void @llvm.prefetch(i8* %241, i32 0, i32 3, i32 1) #19
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %105) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %105, i8 -86, i64 128, i1 false)
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %106) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %115, i8 -86, i64 24, i1 false)
  store i16* %111, i16** %107, align 8
  store i32 8, i32* %108, align 8
  store i32 8, i32* %109, align 4
  store i32 8, i32* %110, align 8
  %242 = load i32, i32* %112, align 4
  %243 = add nsw i32 %242, %127
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.659"* nonnull dereferenceable(32) %18, %"class.gemmlowp::MatrixMap.479"* nonnull %20, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %193, i32 %127, i32 %194, i32 %243, i32 0, i32 0)
  %244 = load i32, i32* %112, align 4
  %245 = add nsw i32 %244, %177
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.659"* nonnull dereferenceable(32) %18, %"class.gemmlowp::MatrixMap.479"* nonnull %20, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %193, i32 %177, i32 %194, i32 %245, i32 0, i32 4)
  %246 = load i32, i32* %104, align 4
  %247 = add nsw i32 %246, %193
  %248 = load i32, i32* %112, align 4
  %249 = add nsw i32 %248, %127
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %113)
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %113, i8* nonnull align 16 %105, i64 128, i1 false)
  call void @_ZN8gemmlowp20StoreFinalOutputImplINS_13RegisterBlockIsLi8ELi8EEENS_9MatrixMapIsLNS_8MapOrderE1EEEE3RunERKS2_PS5_ii(%"struct.gemmlowp::RegisterBlock.559"* nonnull dereferenceable(128) %10, %"class.gemmlowp::MatrixMap.489"* %0, i32 %247, i32 %249) #19
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %113)
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %106) #19
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %105) #19
  %250 = load i32, i32* %48, align 4
  %251 = add nsw i32 %250, -8
  %252 = trunc i64 %195 to i32
  %253 = icmp slt i32 %251, %252
  br i1 %253, label %178, label %254

254:                                              ; preds = %187
  %255 = load i32*, i32** %22, align 8
  %256 = load i32, i32* %25, align 8
  %257 = load i32*, i32** %46, align 8
  br label %187

258:                                              ; preds = %264, %180
  %259 = phi i32 [ %181, %180 ], [ %273, %264 ]
  %260 = phi i32 [ %182, %180 ], [ %272, %264 ]
  %261 = icmp slt i32 %260, %259
  br i1 %261, label %262, label %287

262:                                              ; preds = %258
  %263 = or i32 %127, 4
  br label %276

264:                                              ; preds = %185, %264
  %265 = phi i32 [ %272, %264 ], [ %182, %185 ]
  %266 = load i32, i32* %104, align 4
  %267 = add nsw i32 %266, %265
  %268 = load i32, i32* %112, align 4
  %269 = add nsw i32 %268, %127
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.652"* nonnull dereferenceable(32) %17, %"class.gemmlowp::MatrixMap.489"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %265, i32 %127, i32 %267, i32 %269, i32 %267, i32 %269)
  %270 = load i32, i32* %112, align 4
  %271 = add nsw i32 %270, %186
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.652"* nonnull dereferenceable(32) %17, %"class.gemmlowp::MatrixMap.489"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %265, i32 %186, i32 %267, i32 %271, i32 %267, i32 %271)
  %272 = add nuw nsw i32 %265, 4
  %273 = load i32, i32* %48, align 4
  %274 = add nsw i32 %273, -4
  %275 = icmp sgt i32 %272, %274
  br i1 %275, label %258, label %264

276:                                              ; preds = %262, %276
  %277 = phi i32 [ %284, %276 ], [ %260, %262 ]
  %278 = load i32, i32* %104, align 4
  %279 = add nsw i32 %278, %277
  %280 = load i32, i32* %112, align 4
  %281 = add nsw i32 %280, %127
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.645"* nonnull dereferenceable(32) %16, %"class.gemmlowp::MatrixMap.489"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %277, i32 %127, i32 %279, i32 %281, i32 %279, i32 %281)
  %282 = load i32, i32* %112, align 4
  %283 = add nsw i32 %282, %263
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.645"* nonnull dereferenceable(32) %16, %"class.gemmlowp::MatrixMap.489"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %277, i32 %263, i32 %279, i32 %283, i32 %279, i32 %283)
  %284 = add nuw nsw i32 %277, 1
  %285 = load i32, i32* %48, align 4
  %286 = icmp slt i32 %284, %285
  br i1 %286, label %276, label %287

287:                                              ; preds = %276, %258
  %288 = phi i32 [ %259, %258 ], [ %285, %276 ]
  %289 = add nuw nsw i32 %127, 8
  %290 = load i32, i32* %54, align 4
  %291 = add nsw i32 %290, -8
  %292 = icmp sgt i32 %289, %291
  br i1 %292, label %116, label %125

293:                                              ; preds = %419, %116
  %294 = phi i32 [ %117, %116 ], [ %422, %419 ]
  %295 = phi i32 [ %118, %116 ], [ %421, %419 ]
  %296 = icmp slt i32 %295, %294
  br i1 %296, label %297, label %578

297:                                              ; preds = %293
  %298 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 1
  %299 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 0
  %300 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %6, i64 0, i32 0
  %301 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %7, i64 0, i32 0
  %302 = getelementptr inbounds %"class.std::__1::tuple.485", %"class.std::__1::tuple.485"* %8, i64 0, i32 0, i32 0, i32 0, i32 2
  %303 = shl i32 1, %61
  %304 = sext i32 %303 to i64
  %305 = getelementptr inbounds %"class.std::__1::tuple.485", %"class.std::__1::tuple.485"* %8, i64 0, i32 0, i32 0, i32 0, i32 0
  %306 = zext i32 %64 to i64
  %307 = shl nsw i64 -1, %306
  %308 = trunc i64 %307 to i32
  %309 = xor i32 %308, -1
  %310 = ashr i32 %309, 1
  %311 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %65, i64 0, i32 0
  %312 = getelementptr inbounds %"class.std::__1::tuple.485", %"class.std::__1::tuple.485"* %8, i64 0, i32 0, i32 1, i32 0, i32 1
  %313 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %0, i64 0, i32 0
  %314 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %0, i64 0, i32 3
  %315 = zext i32 %295 to i64
  %316 = load i32, i32* %48, align 4
  br label %425

317:                                              ; preds = %121, %419
  %318 = phi i32 [ %124, %121 ], [ %420, %419 ]
  %319 = phi i32 [ %118, %121 ], [ %421, %419 ]
  %320 = load i32, i32* %122, align 4
  %321 = add nsw i32 %320, %319
  %322 = load i32*, i32** %22, align 8
  %323 = load i32, i32* %25, align 8
  %324 = mul nsw i32 %323, %319
  %325 = sext i32 %324 to i64
  %326 = load i32*, i32** %46, align 8
  %327 = bitcast i32* %326 to i8*
  call void @llvm.prefetch(i8* %327, i32 0, i32 3, i32 1) #19
  %328 = getelementptr inbounds i32, i32* %326, i64 4
  %329 = bitcast i32* %328 to i8*
  call void @llvm.prefetch(i8* %329, i32 0, i32 3, i32 1) #19
  %330 = getelementptr inbounds i32, i32* %322, i64 %325
  %331 = sext i32 %323 to i64
  %332 = bitcast i32* %330 to i8*
  call void @llvm.prefetch(i8* %332, i32 0, i32 3, i32 1) #19
  %333 = getelementptr inbounds i32, i32* %330, i64 4
  %334 = bitcast i32* %333 to i8*
  call void @llvm.prefetch(i8* %334, i32 0, i32 3, i32 1) #19
  %335 = getelementptr inbounds i32, i32* %330, i64 %331
  %336 = bitcast i32* %335 to i8*
  call void @llvm.prefetch(i8* %336, i32 0, i32 3, i32 1) #19
  %337 = getelementptr inbounds i32, i32* %335, i64 4
  %338 = bitcast i32* %337 to i8*
  call void @llvm.prefetch(i8* %338, i32 0, i32 3, i32 1) #19
  %339 = shl nsw i64 %331, 1
  %340 = getelementptr inbounds i32, i32* %330, i64 %339
  %341 = bitcast i32* %340 to i8*
  call void @llvm.prefetch(i8* %341, i32 0, i32 3, i32 1) #19
  %342 = getelementptr inbounds i32, i32* %340, i64 4
  %343 = bitcast i32* %342 to i8*
  call void @llvm.prefetch(i8* %343, i32 0, i32 3, i32 1) #19
  %344 = mul nsw i64 %331, 3
  %345 = getelementptr inbounds i32, i32* %330, i64 %344
  %346 = bitcast i32* %345 to i8*
  call void @llvm.prefetch(i8* %346, i32 0, i32 3, i32 1) #19
  %347 = getelementptr inbounds i32, i32* %345, i64 4
  %348 = bitcast i32* %347 to i8*
  call void @llvm.prefetch(i8* %348, i32 0, i32 3, i32 1) #19
  %349 = icmp slt i32 %318, 8
  br i1 %349, label %352, label %357

350:                                              ; preds = %357
  %351 = trunc i64 %365 to i32
  br label %352

352:                                              ; preds = %350, %317
  %353 = phi i32 [ %318, %317 ], [ %392, %350 ]
  %354 = phi i32 [ 0, %317 ], [ %351, %350 ]
  %355 = add nsw i32 %353, -4
  %356 = icmp sgt i32 %354, %355
  br i1 %356, label %400, label %404

357:                                              ; preds = %317, %396
  %358 = phi i32* [ %399, %396 ], [ %326, %317 ]
  %359 = phi i32 [ %398, %396 ], [ %323, %317 ]
  %360 = phi i32* [ %397, %396 ], [ %322, %317 ]
  %361 = phi i64 [ %365, %396 ], [ 0, %317 ]
  %362 = load i32, i32* %123, align 4
  %363 = trunc i64 %361 to i32
  %364 = add nsw i32 %362, %363
  %365 = add nuw i64 %361, 8
  %366 = mul nsw i32 %359, %319
  %367 = sext i32 %366 to i64
  %368 = getelementptr inbounds i32, i32* %358, i64 %365
  %369 = bitcast i32* %368 to i8*
  call void @llvm.prefetch(i8* %369, i32 0, i32 3, i32 1) #19
  %370 = getelementptr inbounds i32, i32* %368, i64 4
  %371 = bitcast i32* %370 to i8*
  call void @llvm.prefetch(i8* %371, i32 0, i32 3, i32 1) #19
  %372 = getelementptr inbounds i32, i32* %360, i64 %365
  %373 = getelementptr inbounds i32, i32* %372, i64 %367
  %374 = sext i32 %359 to i64
  %375 = bitcast i32* %373 to i8*
  call void @llvm.prefetch(i8* %375, i32 0, i32 3, i32 1) #19
  %376 = getelementptr inbounds i32, i32* %373, i64 4
  %377 = bitcast i32* %376 to i8*
  call void @llvm.prefetch(i8* %377, i32 0, i32 3, i32 1) #19
  %378 = getelementptr inbounds i32, i32* %373, i64 %374
  %379 = bitcast i32* %378 to i8*
  call void @llvm.prefetch(i8* %379, i32 0, i32 3, i32 1) #19
  %380 = getelementptr inbounds i32, i32* %378, i64 4
  %381 = bitcast i32* %380 to i8*
  call void @llvm.prefetch(i8* %381, i32 0, i32 3, i32 1) #19
  %382 = shl nsw i64 %374, 1
  %383 = getelementptr inbounds i32, i32* %373, i64 %382
  %384 = bitcast i32* %383 to i8*
  call void @llvm.prefetch(i8* %384, i32 0, i32 3, i32 1) #19
  %385 = getelementptr inbounds i32, i32* %383, i64 4
  %386 = bitcast i32* %385 to i8*
  call void @llvm.prefetch(i8* %386, i32 0, i32 3, i32 1) #19
  %387 = mul nsw i64 %374, 3
  %388 = getelementptr inbounds i32, i32* %373, i64 %387
  %389 = bitcast i32* %388 to i8*
  call void @llvm.prefetch(i8* %389, i32 0, i32 3, i32 1) #19
  %390 = getelementptr inbounds i32, i32* %388, i64 4
  %391 = bitcast i32* %390 to i8*
  call void @llvm.prefetch(i8* %391, i32 0, i32 3, i32 1) #19
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.659"* nonnull dereferenceable(32) %18, %"class.gemmlowp::MatrixMap.489"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %363, i32 %319, i32 %364, i32 %321, i32 %364, i32 %321)
  %392 = load i32, i32* %48, align 4
  %393 = add nsw i32 %392, -8
  %394 = trunc i64 %365 to i32
  %395 = icmp slt i32 %393, %394
  br i1 %395, label %350, label %396

396:                                              ; preds = %357
  %397 = load i32*, i32** %22, align 8
  %398 = load i32, i32* %25, align 8
  %399 = load i32*, i32** %46, align 8
  br label %357

400:                                              ; preds = %404, %352
  %401 = phi i32 [ %353, %352 ], [ %409, %404 ]
  %402 = phi i32 [ %354, %352 ], [ %408, %404 ]
  %403 = icmp slt i32 %402, %401
  br i1 %403, label %412, label %419

404:                                              ; preds = %352, %404
  %405 = phi i32 [ %408, %404 ], [ %354, %352 ]
  %406 = load i32, i32* %123, align 4
  %407 = add nsw i32 %406, %405
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.652"* nonnull dereferenceable(32) %17, %"class.gemmlowp::MatrixMap.489"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %405, i32 %319, i32 %407, i32 %321, i32 %407, i32 %321)
  %408 = add nuw nsw i32 %405, 4
  %409 = load i32, i32* %48, align 4
  %410 = add nsw i32 %409, -4
  %411 = icmp sgt i32 %408, %410
  br i1 %411, label %400, label %404

412:                                              ; preds = %400, %412
  %413 = phi i32 [ %416, %412 ], [ %402, %400 ]
  %414 = load i32, i32* %123, align 4
  %415 = add nsw i32 %414, %413
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.645"* nonnull dereferenceable(32) %16, %"class.gemmlowp::MatrixMap.489"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %413, i32 %319, i32 %415, i32 %321, i32 %415, i32 %321)
  %416 = add nuw nsw i32 %413, 1
  %417 = load i32, i32* %48, align 4
  %418 = icmp slt i32 %416, %417
  br i1 %418, label %412, label %419

419:                                              ; preds = %412, %400
  %420 = phi i32 [ %401, %400 ], [ %417, %412 ]
  %421 = add nuw nsw i32 %319, 4
  %422 = load i32, i32* %54, align 4
  %423 = add nsw i32 %422, -4
  %424 = icmp sgt i32 %421, %423
  br i1 %424, label %293, label %317

425:                                              ; preds = %297, %572
  %426 = phi i32 [ %316, %297 ], [ %573, %572 ]
  %427 = phi i64 [ %315, %297 ], [ %574, %572 ]
  %428 = load i32, i32* %298, align 4
  %429 = trunc i64 %427 to i32
  %430 = add nsw i32 %428, %429
  %431 = load i32*, i32** %22, align 8
  %432 = load i32, i32* %25, align 8
  %433 = mul nsw i32 %432, %429
  %434 = sext i32 %433 to i64
  %435 = load i32*, i32** %46, align 8
  %436 = bitcast i32* %435 to i8*
  call void @llvm.prefetch(i8* %436, i32 0, i32 3, i32 1) #19
  %437 = getelementptr inbounds i32, i32* %435, i64 4
  %438 = bitcast i32* %437 to i8*
  call void @llvm.prefetch(i8* %438, i32 0, i32 3, i32 1) #19
  %439 = getelementptr inbounds i32, i32* %431, i64 %434
  %440 = bitcast i32* %439 to i8*
  call void @llvm.prefetch(i8* %440, i32 0, i32 3, i32 1) #19
  %441 = getelementptr inbounds i32, i32* %439, i64 4
  %442 = bitcast i32* %441 to i8*
  call void @llvm.prefetch(i8* %442, i32 0, i32 3, i32 1) #19
  %443 = icmp slt i32 %426, 8
  br i1 %443, label %446, label %451

444:                                              ; preds = %451
  %445 = trunc i64 %459 to i32
  br label %446

446:                                              ; preds = %444, %425
  %447 = phi i32 [ %426, %425 ], [ %471, %444 ]
  %448 = phi i32 [ 0, %425 ], [ %445, %444 ]
  %449 = add nsw i32 %447, -4
  %450 = icmp sgt i32 %448, %449
  br i1 %450, label %479, label %486

451:                                              ; preds = %425, %475
  %452 = phi i32* [ %478, %475 ], [ %435, %425 ]
  %453 = phi i32 [ %477, %475 ], [ %432, %425 ]
  %454 = phi i32* [ %476, %475 ], [ %431, %425 ]
  %455 = phi i64 [ %459, %475 ], [ 0, %425 ]
  %456 = load i32, i32* %299, align 4
  %457 = trunc i64 %455 to i32
  %458 = add nsw i32 %456, %457
  %459 = add nuw i64 %455, 8
  %460 = mul nsw i32 %453, %429
  %461 = sext i32 %460 to i64
  %462 = getelementptr inbounds i32, i32* %452, i64 %459
  %463 = bitcast i32* %462 to i8*
  call void @llvm.prefetch(i8* %463, i32 0, i32 3, i32 1) #19
  %464 = getelementptr inbounds i32, i32* %462, i64 4
  %465 = bitcast i32* %464 to i8*
  call void @llvm.prefetch(i8* %465, i32 0, i32 3, i32 1) #19
  %466 = getelementptr inbounds i32, i32* %454, i64 %459
  %467 = getelementptr inbounds i32, i32* %466, i64 %461
  %468 = bitcast i32* %467 to i8*
  call void @llvm.prefetch(i8* %468, i32 0, i32 3, i32 1) #19
  %469 = getelementptr inbounds i32, i32* %467, i64 4
  %470 = bitcast i32* %469 to i8*
  call void @llvm.prefetch(i8* %470, i32 0, i32 3, i32 1) #19
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.638"* nonnull dereferenceable(32) %15, %"class.gemmlowp::MatrixMap.489"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %457, i32 %429, i32 %458, i32 %430, i32 %458, i32 %430)
  %471 = load i32, i32* %48, align 4
  %472 = add nsw i32 %471, -8
  %473 = trunc i64 %459 to i32
  %474 = icmp slt i32 %472, %473
  br i1 %474, label %444, label %475

475:                                              ; preds = %451
  %476 = load i32*, i32** %22, align 8
  %477 = load i32, i32* %25, align 8
  %478 = load i32*, i32** %46, align 8
  br label %451

479:                                              ; preds = %486, %446
  %480 = phi i32 [ %447, %446 ], [ %491, %486 ]
  %481 = phi i32 [ %448, %446 ], [ %490, %486 ]
  %482 = icmp slt i32 %481, %480
  br i1 %482, label %483, label %572

483:                                              ; preds = %479
  %484 = sext i32 %430 to i64
  %485 = zext i32 %481 to i64
  br label %494

486:                                              ; preds = %446, %486
  %487 = phi i32 [ %490, %486 ], [ %448, %446 ]
  %488 = load i32, i32* %299, align 4
  %489 = add nsw i32 %488, %487
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %11, %"struct.gemmlowp::OutputPipelineExecutor.631"* nonnull dereferenceable(32) %14, %"class.gemmlowp::MatrixMap.489"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %13, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup"* dereferenceable(8) %7, i32 %3, i32 %487, i32 %429, i32 %489, i32 %430, i32 %489, i32 %430)
  %490 = add nuw nsw i32 %487, 4
  %491 = load i32, i32* %48, align 4
  %492 = add nsw i32 %491, -4
  %493 = icmp sgt i32 %490, %492
  br i1 %493, label %479, label %486

494:                                              ; preds = %483, %541
  %495 = phi i64 [ %485, %483 ], [ %568, %541 ]
  %496 = load i32, i32* %299, align 4
  %497 = trunc i64 %495 to i32
  %498 = add nsw i32 %496, %497
  %499 = load i32*, i32** %22, align 8
  %500 = load i32, i32* %25, align 8
  %501 = getelementptr inbounds i32, i32* %499, i64 %495
  %502 = mul nsw i32 %500, %429
  %503 = sext i32 %502 to i64
  %504 = getelementptr inbounds i32, i32* %501, i64 %503
  %505 = load i32, i32* %504, align 4
  %506 = load i32*, i32** %46, align 8
  %507 = getelementptr inbounds i32, i32* %506, i64 %495
  %508 = load i32, i32* %507, align 4
  %509 = load i32*, i32** %52, align 8
  %510 = getelementptr inbounds i32, i32* %509, i64 %427
  %511 = load i32, i32* %510, align 4
  %512 = load i32, i32* %300, align 4
  %513 = load i32, i32* %301, align 4
  %514 = mul nsw i32 %513, %508
  %515 = add nsw i32 %514, %505
  %516 = mul nsw i32 %513, %3
  %517 = add nsw i32 %516, %511
  %518 = mul nsw i32 %517, %512
  %519 = add nsw i32 %515, %518
  %520 = load i32, i32* %302, align 4
  %521 = sext i32 %519 to i64
  %522 = mul nsw i64 %521, %304
  %523 = icmp slt i64 %522, 2147483647
  %524 = select i1 %523, i64 %522, i64 2147483647
  %525 = icmp sgt i64 %524, -2147483648
  %526 = select i1 %525, i64 %524, i64 -2147483648
  %527 = trunc i64 %526 to i32
  %528 = load i32, i32* %305, align 4
  %529 = icmp ne i32 %528, %527
  %530 = icmp ne i32 %527, -2147483648
  %531 = or i1 %529, %530
  br i1 %531, label %532, label %541

532:                                              ; preds = %494
  %533 = sext i32 %528 to i64
  %534 = select i1 %529, i64 %533, i64 %526
  %535 = mul nsw i64 %534, %526
  %536 = icmp sgt i64 %535, -1
  %537 = select i1 %536, i64 1073741824, i64 -1073741823
  %538 = add nsw i64 %537, %535
  %539 = sdiv i64 %538, 2147483648
  %540 = trunc i64 %539 to i32
  br label %541

541:                                              ; preds = %494, %532
  %542 = phi i32 [ %540, %532 ], [ 2147483647, %494 ]
  %543 = and i32 %542, %309
  %544 = lshr i32 %542, 31
  %545 = add nsw i32 %544, %310
  %546 = ashr i32 %542, %64
  %547 = icmp sgt i32 %543, %545
  %548 = zext i1 %547 to i32
  %549 = add i32 %546, %520
  %550 = add i32 %549, %548
  %551 = load i32, i32* %311, align 4
  %552 = load i32, i32* %312, align 4
  %553 = icmp sgt i32 %551, %550
  %554 = select i1 %553, i32 %551, i32 %550
  %555 = icmp slt i32 %552, %554
  %556 = select i1 %555, i32 %552, i32 %554
  %557 = icmp sgt i32 %556, -32768
  %558 = select i1 %557, i32 %556, i32 -32768
  %559 = icmp slt i32 %558, 32767
  %560 = select i1 %559, i32 %558, i32 32767
  %561 = trunc i32 %560 to i16
  %562 = load i16*, i16** %313, align 8
  %563 = load i32, i32* %314, align 8
  %564 = mul nsw i32 %563, %498
  %565 = sext i32 %564 to i64
  %566 = getelementptr inbounds i16, i16* %562, i64 %484
  %567 = getelementptr inbounds i16, i16* %566, i64 %565
  store i16 %561, i16* %567, align 2
  %568 = add nuw nsw i64 %495, 1
  %569 = load i32, i32* %48, align 4
  %570 = trunc i64 %568 to i32
  %571 = icmp sgt i32 %569, %570
  br i1 %571, label %494, label %572

572:                                              ; preds = %541, %479
  %573 = phi i32 [ %480, %479 ], [ %569, %541 ]
  %574 = add nuw nsw i64 %427, 1
  %575 = load i32, i32* %54, align 4
  %576 = trunc i64 %574 to i32
  %577 = icmp sgt i32 %575, %576
  br i1 %577, label %425, label %578

578:                                              ; preds = %572, %293
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %94) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %87) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %80) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %73) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %66) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %51) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %45) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %21) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.659"* dereferenceable(32), %"class.gemmlowp::MatrixMap.479"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.561", align 8
  %16 = alloca %"struct.gemmlowp::RegisterBlock.561", align 2
  %17 = alloca %"struct.gemmlowp::RegisterBlock.302", align 16
  %18 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %18) #19
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %20 = sext i32 %8 to i64
  %21 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %22 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %22, i8 -86, i64 128, i1 false)
  %23 = load i32*, i32** %19, align 8, !noalias !1772
  %24 = getelementptr inbounds i32, i32* %23, i64 %20
  %25 = load i32, i32* %21, align 8, !noalias !1772
  %26 = mul nsw i32 %25, %9
  %27 = sext i32 %26 to i64
  %28 = getelementptr inbounds i32, i32* %24, i64 %27
  %29 = getelementptr inbounds i32, i32* %28, i64 1
  %30 = load i32, i32* %28, align 4
  %31 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 0
  store i32 %30, i32* %31, align 16, !alias.scope !1772
  %32 = getelementptr inbounds i32, i32* %29, i64 1
  %33 = load i32, i32* %29, align 4
  %34 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 1
  store i32 %33, i32* %34, align 4, !alias.scope !1772
  %35 = getelementptr inbounds i32, i32* %32, i64 1
  %36 = load i32, i32* %32, align 4
  %37 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 2
  store i32 %36, i32* %37, align 8, !alias.scope !1772
  %38 = getelementptr inbounds i32, i32* %35, i64 1
  %39 = load i32, i32* %35, align 4
  %40 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 3
  store i32 %39, i32* %40, align 4, !alias.scope !1772
  %41 = getelementptr inbounds i32, i32* %38, i64 1
  %42 = load i32, i32* %38, align 4
  %43 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 4
  store i32 %42, i32* %43, align 16, !alias.scope !1772
  %44 = getelementptr inbounds i32, i32* %41, i64 1
  %45 = load i32, i32* %41, align 4
  %46 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 5
  store i32 %45, i32* %46, align 4, !alias.scope !1772
  %47 = getelementptr inbounds i32, i32* %44, i64 1
  %48 = load i32, i32* %44, align 4
  %49 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 6
  store i32 %48, i32* %49, align 8, !alias.scope !1772
  %50 = load i32, i32* %47, align 4
  %51 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 7
  store i32 %50, i32* %51, align 4, !alias.scope !1772
  %52 = add nsw i32 %9, 1
  %53 = mul nsw i32 %25, %52
  %54 = sext i32 %53 to i64
  %55 = getelementptr inbounds i32, i32* %24, i64 %54
  %56 = getelementptr inbounds i32, i32* %55, i64 1
  %57 = load i32, i32* %55, align 4
  %58 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 8
  store i32 %57, i32* %58, align 16, !alias.scope !1772
  %59 = getelementptr inbounds i32, i32* %56, i64 1
  %60 = load i32, i32* %56, align 4
  %61 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 9
  store i32 %60, i32* %61, align 4, !alias.scope !1772
  %62 = getelementptr inbounds i32, i32* %59, i64 1
  %63 = load i32, i32* %59, align 4
  %64 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 10
  store i32 %63, i32* %64, align 8, !alias.scope !1772
  %65 = getelementptr inbounds i32, i32* %62, i64 1
  %66 = load i32, i32* %62, align 4
  %67 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 11
  store i32 %66, i32* %67, align 4, !alias.scope !1772
  %68 = getelementptr inbounds i32, i32* %65, i64 1
  %69 = load i32, i32* %65, align 4
  %70 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 12
  store i32 %69, i32* %70, align 16, !alias.scope !1772
  %71 = getelementptr inbounds i32, i32* %68, i64 1
  %72 = load i32, i32* %68, align 4
  %73 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 13
  store i32 %72, i32* %73, align 4, !alias.scope !1772
  %74 = getelementptr inbounds i32, i32* %71, i64 1
  %75 = load i32, i32* %71, align 4
  %76 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 14
  store i32 %75, i32* %76, align 8, !alias.scope !1772
  %77 = load i32, i32* %74, align 4
  %78 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 15
  store i32 %77, i32* %78, align 4, !alias.scope !1772
  %79 = add nsw i32 %9, 2
  %80 = mul nsw i32 %25, %79
  %81 = sext i32 %80 to i64
  %82 = getelementptr inbounds i32, i32* %24, i64 %81
  %83 = getelementptr inbounds i32, i32* %82, i64 1
  %84 = load i32, i32* %82, align 4
  %85 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 16
  store i32 %84, i32* %85, align 16, !alias.scope !1772
  %86 = getelementptr inbounds i32, i32* %83, i64 1
  %87 = load i32, i32* %83, align 4
  %88 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 17
  store i32 %87, i32* %88, align 4, !alias.scope !1772
  %89 = getelementptr inbounds i32, i32* %86, i64 1
  %90 = load i32, i32* %86, align 4
  %91 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 18
  store i32 %90, i32* %91, align 8, !alias.scope !1772
  %92 = getelementptr inbounds i32, i32* %89, i64 1
  %93 = load i32, i32* %89, align 4
  %94 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 19
  store i32 %93, i32* %94, align 4, !alias.scope !1772
  %95 = getelementptr inbounds i32, i32* %92, i64 1
  %96 = load i32, i32* %92, align 4
  %97 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 20
  store i32 %96, i32* %97, align 16, !alias.scope !1772
  %98 = getelementptr inbounds i32, i32* %95, i64 1
  %99 = load i32, i32* %95, align 4
  %100 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 21
  store i32 %99, i32* %100, align 4, !alias.scope !1772
  %101 = getelementptr inbounds i32, i32* %98, i64 1
  %102 = load i32, i32* %98, align 4
  %103 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 22
  store i32 %102, i32* %103, align 8, !alias.scope !1772
  %104 = load i32, i32* %101, align 4
  %105 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 23
  store i32 %104, i32* %105, align 4, !alias.scope !1772
  %106 = add nsw i32 %9, 3
  %107 = mul nsw i32 %25, %106
  %108 = sext i32 %107 to i64
  %109 = getelementptr inbounds i32, i32* %24, i64 %108
  %110 = getelementptr inbounds i32, i32* %109, i64 1
  %111 = load i32, i32* %109, align 4
  %112 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 24
  store i32 %111, i32* %112, align 16, !alias.scope !1772
  %113 = getelementptr inbounds i32, i32* %110, i64 1
  %114 = load i32, i32* %110, align 4
  %115 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 25
  store i32 %114, i32* %115, align 4, !alias.scope !1772
  %116 = getelementptr inbounds i32, i32* %113, i64 1
  %117 = load i32, i32* %113, align 4
  %118 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 26
  store i32 %117, i32* %118, align 8, !alias.scope !1772
  %119 = getelementptr inbounds i32, i32* %116, i64 1
  %120 = load i32, i32* %116, align 4
  %121 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 27
  store i32 %120, i32* %121, align 4, !alias.scope !1772
  %122 = getelementptr inbounds i32, i32* %119, i64 1
  %123 = load i32, i32* %119, align 4
  %124 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 28
  store i32 %123, i32* %124, align 16, !alias.scope !1772
  %125 = getelementptr inbounds i32, i32* %122, i64 1
  %126 = load i32, i32* %122, align 4
  %127 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 29
  store i32 %126, i32* %127, align 4, !alias.scope !1772
  %128 = getelementptr inbounds i32, i32* %125, i64 1
  %129 = load i32, i32* %125, align 4
  %130 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 30
  store i32 %129, i32* %130, align 8, !alias.scope !1772
  %131 = load i32, i32* %128, align 4
  %132 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 31
  store i32 %131, i32* %132, align 4, !alias.scope !1772
  %133 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %134 = load i32*, i32** %133, align 8, !noalias !1775
  %135 = getelementptr i32, i32* %134, i64 %20
  %136 = bitcast i32* %135 to <4 x i32>*
  %137 = load <4 x i32>, <4 x i32>* %136, align 4
  %138 = getelementptr inbounds i32, i32* %135, i64 4
  %139 = bitcast i32* %138 to <4 x i32>*
  %140 = load <4 x i32>, <4 x i32>* %139, align 4
  %141 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %142 = load i32*, i32** %141, align 8
  %143 = sext i32 %9 to i64
  %144 = getelementptr i32, i32* %142, i64 %143
  %145 = bitcast i32* %144 to i64*
  %146 = load i64, i64* %145, align 4
  %147 = getelementptr inbounds i32, i32* %144, i64 2
  %148 = bitcast i32* %147 to i64*
  %149 = load i64, i64* %148, align 4
  %150 = lshr i64 %146, 32
  %151 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 0
  %152 = load i32, i32* %151, align 4
  %153 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %154 = load i32, i32* %153, align 4
  %155 = insertelement <4 x i32> undef, i32 %154, i32 0
  %156 = shufflevector <4 x i32> %155, <4 x i32> undef, <4 x i32> zeroinitializer
  %157 = mul nsw <4 x i32> %156, %137
  %158 = mul nsw <4 x i32> %156, %140
  %159 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to <4 x i32>*
  %160 = load <4 x i32>, <4 x i32>* %159, align 16
  %161 = add nsw <4 x i32> %160, %157
  %162 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to <4 x i32>*
  store <4 x i32> %161, <4 x i32>* %162, align 16
  %163 = bitcast i32* %43 to <4 x i32>*
  %164 = load <4 x i32>, <4 x i32>* %163, align 16
  %165 = add nsw <4 x i32> %164, %158
  %166 = bitcast i32* %43 to <4 x i32>*
  store <4 x i32> %165, <4 x i32>* %166, align 16
  %167 = bitcast i32* %58 to <4 x i32>*
  %168 = load <4 x i32>, <4 x i32>* %167, align 16
  %169 = add nsw <4 x i32> %168, %157
  %170 = bitcast i32* %58 to <4 x i32>*
  store <4 x i32> %169, <4 x i32>* %170, align 16
  %171 = bitcast i32* %70 to <4 x i32>*
  %172 = load <4 x i32>, <4 x i32>* %171, align 16
  %173 = add nsw <4 x i32> %172, %158
  %174 = bitcast i32* %70 to <4 x i32>*
  store <4 x i32> %173, <4 x i32>* %174, align 16
  %175 = bitcast i32* %85 to <4 x i32>*
  %176 = load <4 x i32>, <4 x i32>* %175, align 16
  %177 = add nsw <4 x i32> %176, %157
  %178 = bitcast i32* %85 to <4 x i32>*
  store <4 x i32> %177, <4 x i32>* %178, align 16
  %179 = bitcast i32* %97 to <4 x i32>*
  %180 = load <4 x i32>, <4 x i32>* %179, align 16
  %181 = add nsw <4 x i32> %180, %158
  %182 = bitcast i32* %97 to <4 x i32>*
  store <4 x i32> %181, <4 x i32>* %182, align 16
  %183 = bitcast i32* %112 to <4 x i32>*
  %184 = load <4 x i32>, <4 x i32>* %183, align 16
  %185 = add nsw <4 x i32> %184, %157
  %186 = bitcast i32* %112 to <4 x i32>*
  store <4 x i32> %185, <4 x i32>* %186, align 16
  %187 = bitcast i32* %124 to <4 x i32>*
  %188 = load <4 x i32>, <4 x i32>* %187, align 16
  %189 = add nsw <4 x i32> %188, %158
  %190 = bitcast i32* %124 to <4 x i32>*
  store <4 x i32> %189, <4 x i32>* %190, align 16
  %191 = trunc i64 %146 to i32
  %192 = trunc i64 %150 to i32
  %193 = mul nsw i32 %154, %7
  %194 = add nsw i32 %193, %191
  %195 = add nsw i32 %193, %192
  %196 = trunc i64 %149 to i32
  %197 = add nsw i32 %193, %196
  %198 = lshr i64 %149, 32
  %199 = trunc i64 %198 to i32
  %200 = add nsw i32 %193, %199
  %201 = mul nsw i32 %194, %152
  %202 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to <4 x i32>*
  %203 = load <4 x i32>, <4 x i32>* %202, align 16
  %204 = insertelement <4 x i32> undef, i32 %201, i32 0
  %205 = shufflevector <4 x i32> %204, <4 x i32> undef, <4 x i32> zeroinitializer
  %206 = add nsw <4 x i32> %203, %205
  %207 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to <4 x i32>*
  store <4 x i32> %206, <4 x i32>* %207, align 16
  %208 = bitcast i32* %43 to <4 x i32>*
  %209 = load <4 x i32>, <4 x i32>* %208, align 16
  %210 = add nsw <4 x i32> %209, %205
  %211 = bitcast i32* %43 to <4 x i32>*
  store <4 x i32> %210, <4 x i32>* %211, align 16
  %212 = mul nsw i32 %195, %152
  %213 = bitcast i32* %58 to <4 x i32>*
  %214 = load <4 x i32>, <4 x i32>* %213, align 16
  %215 = insertelement <4 x i32> undef, i32 %212, i32 0
  %216 = shufflevector <4 x i32> %215, <4 x i32> undef, <4 x i32> zeroinitializer
  %217 = add nsw <4 x i32> %214, %216
  %218 = bitcast i32* %58 to <4 x i32>*
  store <4 x i32> %217, <4 x i32>* %218, align 16
  %219 = bitcast i32* %70 to <4 x i32>*
  %220 = load <4 x i32>, <4 x i32>* %219, align 16
  %221 = add nsw <4 x i32> %220, %216
  %222 = bitcast i32* %70 to <4 x i32>*
  store <4 x i32> %221, <4 x i32>* %222, align 16
  %223 = mul nsw i32 %197, %152
  %224 = bitcast i32* %85 to <4 x i32>*
  %225 = load <4 x i32>, <4 x i32>* %224, align 16
  %226 = insertelement <4 x i32> undef, i32 %223, i32 0
  %227 = shufflevector <4 x i32> %226, <4 x i32> undef, <4 x i32> zeroinitializer
  %228 = add nsw <4 x i32> %225, %227
  %229 = bitcast i32* %85 to <4 x i32>*
  store <4 x i32> %228, <4 x i32>* %229, align 16
  %230 = bitcast i32* %97 to <4 x i32>*
  %231 = load <4 x i32>, <4 x i32>* %230, align 16
  %232 = add nsw <4 x i32> %231, %227
  %233 = bitcast i32* %97 to <4 x i32>*
  store <4 x i32> %232, <4 x i32>* %233, align 16
  %234 = mul nsw i32 %200, %152
  %235 = bitcast i32* %112 to <4 x i32>*
  %236 = load <4 x i32>, <4 x i32>* %235, align 16
  %237 = insertelement <4 x i32> undef, i32 %234, i32 0
  %238 = shufflevector <4 x i32> %237, <4 x i32> undef, <4 x i32> zeroinitializer
  %239 = add nsw <4 x i32> %236, %238
  %240 = bitcast i32* %112 to <4 x i32>*
  store <4 x i32> %239, <4 x i32>* %240, align 16
  %241 = bitcast i32* %124 to <4 x i32>*
  %242 = load <4 x i32>, <4 x i32>* %241, align 16
  %243 = add nsw <4 x i32> %242, %238
  %244 = bitcast i32* %124 to <4 x i32>*
  store <4 x i32> %243, <4 x i32>* %244, align 16
  %245 = bitcast %"struct.gemmlowp::RegisterBlock.561"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %245) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 2 %245, i8 -86, i64 64, i1 false) #19
  %246 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.659", %"struct.gemmlowp::OutputPipelineExecutor.659"* %1, i64 0, i32 0
  call void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalES8_ii(%"struct.gemmlowp::RegisterBlock.561"* nonnull sret %16, %"struct.gemmlowp::OutputPipelineEvalImpl.660"* %246, %"struct.gemmlowp::RegisterBlock.302"* nonnull byval(%"struct.gemmlowp::RegisterBlock.302") align 8 %17, i32 %10, i32 %11) #19
  %247 = bitcast %"struct.gemmlowp::RegisterBlock.561"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %247) #19
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %247, i8* nonnull align 2 %245, i64 64, i1 false) #19
  %248 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %2, i64 0, i32 0
  %249 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %2, i64 0, i32 3
  %250 = sext i32 %13 to i64
  %251 = sext i32 %12 to i64
  %252 = add nsw i64 %250, 1
  %253 = add nsw i64 %250, 2
  %254 = add nsw i64 %250, 3
  br label %255

255:                                              ; preds = %255, %14
  %256 = phi i64 [ 0, %14 ], [ %293, %255 ]
  %257 = add nsw i64 %256, %251
  %258 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.561", %"struct.gemmlowp::RegisterBlock.561"* %15, i64 0, i32 0, i32 0, i64 %256
  %259 = load i16, i16* %258, align 2
  %260 = load i16*, i16** %248, align 8
  %261 = getelementptr inbounds i16, i16* %260, i64 %257
  %262 = load i32, i32* %249, align 8
  %263 = sext i32 %262 to i64
  %264 = mul nsw i64 %263, %250
  %265 = getelementptr inbounds i16, i16* %261, i64 %264
  store i16 %259, i16* %265, align 2
  %266 = add nuw nsw i64 %256, 8
  %267 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.561", %"struct.gemmlowp::RegisterBlock.561"* %15, i64 0, i32 0, i32 0, i64 %266
  %268 = load i16, i16* %267, align 2
  %269 = load i16*, i16** %248, align 8
  %270 = getelementptr inbounds i16, i16* %269, i64 %257
  %271 = load i32, i32* %249, align 8
  %272 = sext i32 %271 to i64
  %273 = mul nsw i64 %252, %272
  %274 = getelementptr inbounds i16, i16* %270, i64 %273
  store i16 %268, i16* %274, align 2
  %275 = add nuw nsw i64 %256, 16
  %276 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.561", %"struct.gemmlowp::RegisterBlock.561"* %15, i64 0, i32 0, i32 0, i64 %275
  %277 = load i16, i16* %276, align 2
  %278 = load i16*, i16** %248, align 8
  %279 = getelementptr inbounds i16, i16* %278, i64 %257
  %280 = load i32, i32* %249, align 8
  %281 = sext i32 %280 to i64
  %282 = mul nsw i64 %253, %281
  %283 = getelementptr inbounds i16, i16* %279, i64 %282
  store i16 %277, i16* %283, align 2
  %284 = add nuw nsw i64 %256, 24
  %285 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.561", %"struct.gemmlowp::RegisterBlock.561"* %15, i64 0, i32 0, i32 0, i64 %284
  %286 = load i16, i16* %285, align 2
  %287 = load i16*, i16** %248, align 8
  %288 = getelementptr inbounds i16, i16* %287, i64 %257
  %289 = load i32, i32* %249, align 8
  %290 = sext i32 %289 to i64
  %291 = mul nsw i64 %254, %290
  %292 = getelementptr inbounds i16, i16* %288, i64 %291
  store i16 %286, i16* %292, align 2
  %293 = add nuw nsw i64 %256, 1
  %294 = icmp eq i64 %293, 8
  br i1 %294, label %295, label %255

295:                                              ; preds = %255
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %247) #19
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %245) #19
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %18) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.652"* dereferenceable(32), %"class.gemmlowp::MatrixMap.489"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.312", align 8
  %16 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %17 = sext i32 %8 to i64
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %19 = load i32*, i32** %16, align 8, !noalias !1780
  %20 = getelementptr inbounds i32, i32* %19, i64 %17
  %21 = load i32, i32* %18, align 8, !noalias !1780
  %22 = mul nsw i32 %21, %9
  %23 = sext i32 %22 to i64
  %24 = getelementptr inbounds i32, i32* %20, i64 %23
  %25 = getelementptr inbounds i32, i32* %24, i64 1
  %26 = load i32, i32* %24, align 4, !noalias !1780
  %27 = getelementptr inbounds i32, i32* %25, i64 1
  %28 = load i32, i32* %25, align 4, !noalias !1780
  %29 = getelementptr inbounds i32, i32* %27, i64 1
  %30 = load i32, i32* %27, align 4, !noalias !1780
  %31 = load i32, i32* %29, align 4, !noalias !1780
  %32 = add nsw i32 %9, 1
  %33 = mul nsw i32 %21, %32
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds i32, i32* %20, i64 %34
  %36 = getelementptr inbounds i32, i32* %35, i64 1
  %37 = load i32, i32* %35, align 4, !noalias !1780
  %38 = getelementptr inbounds i32, i32* %36, i64 1
  %39 = load i32, i32* %36, align 4, !noalias !1780
  %40 = getelementptr inbounds i32, i32* %38, i64 1
  %41 = load i32, i32* %38, align 4, !noalias !1780
  %42 = load i32, i32* %40, align 4, !noalias !1780
  %43 = add nsw i32 %9, 2
  %44 = mul nsw i32 %21, %43
  %45 = sext i32 %44 to i64
  %46 = getelementptr inbounds i32, i32* %20, i64 %45
  %47 = getelementptr inbounds i32, i32* %46, i64 1
  %48 = load i32, i32* %46, align 4, !noalias !1780
  %49 = getelementptr inbounds i32, i32* %47, i64 1
  %50 = load i32, i32* %47, align 4, !noalias !1780
  %51 = getelementptr inbounds i32, i32* %49, i64 1
  %52 = load i32, i32* %49, align 4, !noalias !1780
  %53 = load i32, i32* %51, align 4, !noalias !1780
  %54 = add nsw i32 %9, 3
  %55 = mul nsw i32 %21, %54
  %56 = sext i32 %55 to i64
  %57 = getelementptr inbounds i32, i32* %20, i64 %56
  %58 = getelementptr inbounds i32, i32* %57, i64 1
  %59 = load i32, i32* %57, align 4, !noalias !1780
  %60 = getelementptr inbounds i32, i32* %58, i64 1
  %61 = load i32, i32* %58, align 4, !noalias !1780
  %62 = getelementptr inbounds i32, i32* %60, i64 1
  %63 = load i32, i32* %60, align 4, !noalias !1780
  %64 = load i32, i32* %62, align 4, !noalias !1780
  %65 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %66 = load i32*, i32** %65, align 8
  %67 = getelementptr i32, i32* %66, i64 %17
  %68 = bitcast i32* %67 to i64*
  %69 = load i64, i64* %68, align 4
  %70 = getelementptr inbounds i32, i32* %67, i64 2
  %71 = bitcast i32* %70 to i64*
  %72 = load i64, i64* %71, align 4
  %73 = trunc i64 %69 to i32
  %74 = lshr i64 %69, 32
  %75 = trunc i64 %74 to i32
  %76 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %77 = load i32*, i32** %76, align 8
  %78 = sext i32 %9 to i64
  %79 = getelementptr i32, i32* %77, i64 %78
  %80 = bitcast i32* %79 to i64*
  %81 = load i64, i64* %80, align 4
  %82 = getelementptr inbounds i32, i32* %79, i64 2
  %83 = bitcast i32* %82 to i64*
  %84 = load i64, i64* %83, align 4
  %85 = trunc i64 %81 to i32
  %86 = lshr i64 %81, 32
  %87 = trunc i64 %86 to i32
  %88 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 0
  %89 = load i32, i32* %88, align 4
  %90 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %91 = load i32, i32* %90, align 4
  %92 = mul nsw i32 %91, %73
  %93 = add nsw i32 %92, %26
  %94 = mul nsw i32 %91, %75
  %95 = add nsw i32 %94, %28
  %96 = trunc i64 %72 to i32
  %97 = mul nsw i32 %91, %96
  %98 = add nsw i32 %97, %30
  %99 = lshr i64 %72, 32
  %100 = trunc i64 %99 to i32
  %101 = mul nsw i32 %91, %100
  %102 = add nsw i32 %101, %31
  %103 = add nsw i32 %92, %37
  %104 = add nsw i32 %94, %39
  %105 = add nsw i32 %97, %41
  %106 = add nsw i32 %101, %42
  %107 = add nsw i32 %92, %48
  %108 = add nsw i32 %94, %50
  %109 = add nsw i32 %97, %52
  %110 = add nsw i32 %101, %53
  %111 = add nsw i32 %92, %59
  %112 = add nsw i32 %94, %61
  %113 = add nsw i32 %97, %63
  %114 = add nsw i32 %101, %64
  %115 = mul nsw i32 %91, %7
  %116 = add nsw i32 %115, %85
  %117 = add nsw i32 %115, %87
  %118 = trunc i64 %84 to i32
  %119 = add nsw i32 %115, %118
  %120 = lshr i64 %84, 32
  %121 = trunc i64 %120 to i32
  %122 = add nsw i32 %115, %121
  %123 = mul nsw i32 %116, %89
  %124 = add nsw i32 %93, %123
  %125 = add nsw i32 %95, %123
  %126 = add nsw i32 %98, %123
  %127 = add nsw i32 %102, %123
  %128 = mul nsw i32 %117, %89
  %129 = add nsw i32 %103, %128
  %130 = add nsw i32 %104, %128
  %131 = add nsw i32 %105, %128
  %132 = add nsw i32 %106, %128
  %133 = mul nsw i32 %119, %89
  %134 = add nsw i32 %107, %133
  %135 = add nsw i32 %108, %133
  %136 = add nsw i32 %109, %133
  %137 = add nsw i32 %110, %133
  %138 = mul nsw i32 %122, %89
  %139 = add nsw i32 %111, %138
  %140 = add nsw i32 %112, %138
  %141 = add nsw i32 %113, %138
  %142 = add nsw i32 %114, %138
  %143 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 0
  store i32 %124, i32* %143, align 8
  %144 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 1
  store i32 %125, i32* %144, align 4
  %145 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 2
  store i32 %126, i32* %145, align 8
  %146 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 3
  store i32 %127, i32* %146, align 4
  %147 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 4
  store i32 %129, i32* %147, align 8
  %148 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 5
  store i32 %130, i32* %148, align 4
  %149 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 6
  store i32 %131, i32* %149, align 8
  %150 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 7
  store i32 %132, i32* %150, align 4
  %151 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 8
  store i32 %134, i32* %151, align 8
  %152 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 9
  store i32 %135, i32* %152, align 4
  %153 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 10
  store i32 %136, i32* %153, align 8
  %154 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 11
  store i32 %137, i32* %154, align 4
  %155 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 12
  store i32 %139, i32* %155, align 8
  %156 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 13
  store i32 %140, i32* %156, align 4
  %157 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 14
  store i32 %141, i32* %157, align 8
  %158 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 15
  store i32 %142, i32* %158, align 4
  tail call void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi4ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE1EEEEEvS8_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.652"* %1, %"struct.gemmlowp::RegisterBlock.312"* nonnull byval(%"struct.gemmlowp::RegisterBlock.312") align 8 %15, %"class.gemmlowp::MatrixMap.489"* %2, i32 %10, i32 %11, i32 %12, i32 %13)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.645"* dereferenceable(32), %"class.gemmlowp::MatrixMap.489"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %16 = sext i32 %8 to i64
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %18 = load i32*, i32** %15, align 8
  %19 = getelementptr inbounds i32, i32* %18, i64 %16
  %20 = load i32, i32* %17, align 8
  %21 = mul nsw i32 %20, %9
  %22 = sext i32 %21 to i64
  %23 = getelementptr inbounds i32, i32* %19, i64 %22
  %24 = load i32, i32* %23, align 4
  %25 = add nsw i32 %9, 1
  %26 = mul nsw i32 %20, %25
  %27 = sext i32 %26 to i64
  %28 = getelementptr inbounds i32, i32* %19, i64 %27
  %29 = load i32, i32* %28, align 4
  %30 = add nsw i32 %9, 2
  %31 = mul nsw i32 %20, %30
  %32 = sext i32 %31 to i64
  %33 = getelementptr inbounds i32, i32* %19, i64 %32
  %34 = load i32, i32* %33, align 4
  %35 = add nsw i32 %9, 3
  %36 = mul nsw i32 %20, %35
  %37 = sext i32 %36 to i64
  %38 = getelementptr inbounds i32, i32* %19, i64 %37
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %41 = load i32*, i32** %40, align 8
  %42 = getelementptr inbounds i32, i32* %41, i64 %16
  %43 = load i32, i32* %42, align 4
  %44 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %45 = load i32*, i32** %44, align 8
  %46 = sext i32 %9 to i64
  %47 = getelementptr i32, i32* %45, i64 %46
  %48 = bitcast i32* %47 to i64*
  %49 = load i64, i64* %48, align 4
  %50 = getelementptr inbounds i32, i32* %47, i64 2
  %51 = bitcast i32* %50 to i64*
  %52 = load i64, i64* %51, align 4
  %53 = trunc i64 %49 to i32
  %54 = lshr i64 %49, 32
  %55 = trunc i64 %54 to i32
  %56 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 0
  %57 = load i32, i32* %56, align 4
  %58 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %59 = load i32, i32* %58, align 4
  %60 = mul nsw i32 %59, %43
  %61 = add nsw i32 %60, %24
  %62 = add nsw i32 %60, %29
  %63 = add nsw i32 %60, %34
  %64 = add nsw i32 %60, %39
  %65 = mul nsw i32 %59, %7
  %66 = add nsw i32 %65, %53
  %67 = add nsw i32 %65, %55
  %68 = trunc i64 %52 to i32
  %69 = add nsw i32 %65, %68
  %70 = lshr i64 %52, 32
  %71 = trunc i64 %70 to i32
  %72 = add nsw i32 %65, %71
  %73 = mul nsw i32 %66, %57
  %74 = add nsw i32 %61, %73
  %75 = mul nsw i32 %67, %57
  %76 = add nsw i32 %62, %75
  %77 = mul nsw i32 %69, %57
  %78 = add nsw i32 %63, %77
  %79 = zext i32 %78 to i64
  %80 = mul nsw i32 %72, %57
  %81 = add nsw i32 %64, %80
  %82 = zext i32 %81 to i64
  %83 = shl nuw i64 %82, 32
  %84 = or i64 %83, %79
  %85 = zext i32 %76 to i64
  %86 = shl nuw i64 %85, 32
  %87 = zext i32 %74 to i64
  %88 = or i64 %86, %87
  %89 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.645", %"struct.gemmlowp::OutputPipelineExecutor.645"* %1, i64 0, i32 0, i32 0, i32 0
  %90 = tail call { i64, i64 } @_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi4EEEE4EvalES3_(%"struct.gemmlowp::OutputStageEvalBufferImpl.231"* %89, i64 %88, i64 %84) #19
  %91 = extractvalue { i64, i64 } %90, 0
  %92 = extractvalue { i64, i64 } %90, 1
  %93 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.645", %"struct.gemmlowp::OutputPipelineExecutor.645"* %1, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %94 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %93, align 8
  %95 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %94, i64 0, i32 0
  %96 = load i32, i32* %95, align 4
  %97 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %94, i64 0, i32 1
  %98 = load i32, i32* %97, align 4
  %99 = trunc i64 %91 to i32
  %100 = icmp sgt i32 %96, %99
  %101 = select i1 %100, i32 %96, i32 %99
  %102 = icmp slt i32 %98, %101
  %103 = select i1 %102, i32 %98, i32 %101
  %104 = lshr i64 %91, 32
  %105 = trunc i64 %104 to i32
  %106 = icmp sgt i32 %96, %105
  %107 = select i1 %106, i32 %96, i32 %105
  %108 = icmp slt i32 %98, %107
  %109 = select i1 %108, i32 %98, i32 %107
  %110 = trunc i64 %92 to i32
  %111 = icmp sgt i32 %96, %110
  %112 = select i1 %111, i32 %96, i32 %110
  %113 = icmp slt i32 %98, %112
  %114 = select i1 %113, i32 %98, i32 %112
  %115 = lshr i64 %92, 32
  %116 = trunc i64 %115 to i32
  %117 = icmp sgt i32 %96, %116
  %118 = select i1 %117, i32 %96, i32 %116
  %119 = icmp slt i32 %98, %118
  %120 = select i1 %119, i32 %98, i32 %118
  %121 = icmp sgt i32 %103, -32768
  %122 = select i1 %121, i32 %103, i32 -32768
  %123 = icmp slt i32 %122, 32767
  %124 = select i1 %123, i32 %122, i32 32767
  %125 = icmp sgt i32 %109, -32768
  %126 = select i1 %125, i32 %109, i32 -32768
  %127 = icmp slt i32 %126, 32767
  %128 = select i1 %127, i32 %126, i32 32767
  %129 = icmp sgt i32 %114, -32768
  %130 = select i1 %129, i32 %114, i32 -32768
  %131 = icmp slt i32 %130, 32767
  %132 = select i1 %131, i32 %130, i32 32767
  %133 = icmp sgt i32 %120, -32768
  %134 = select i1 %133, i32 %120, i32 -32768
  %135 = icmp slt i32 %134, 32767
  %136 = select i1 %135, i32 %134, i32 32767
  %137 = trunc i32 %124 to i16
  %138 = trunc i32 %128 to i16
  %139 = trunc i32 %132 to i16
  %140 = trunc i32 %136 to i16
  %141 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %2, i64 0, i32 0
  %142 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %2, i64 0, i32 3
  %143 = sext i32 %13 to i64
  %144 = sext i32 %12 to i64
  %145 = load i16*, i16** %141, align 8
  %146 = load i32, i32* %142, align 8
  %147 = sext i32 %146 to i64
  %148 = mul nsw i64 %147, %144
  %149 = getelementptr inbounds i16, i16* %145, i64 %148
  %150 = getelementptr inbounds i16, i16* %149, i64 %143
  store i16 %137, i16* %150, align 2
  %151 = add nsw i64 %143, 1
  %152 = load i16*, i16** %141, align 8
  %153 = load i32, i32* %142, align 8
  %154 = sext i32 %153 to i64
  %155 = mul nsw i64 %154, %144
  %156 = getelementptr inbounds i16, i16* %152, i64 %155
  %157 = getelementptr inbounds i16, i16* %156, i64 %151
  store i16 %138, i16* %157, align 2
  %158 = add nsw i64 %143, 2
  %159 = load i16*, i16** %141, align 8
  %160 = load i32, i32* %142, align 8
  %161 = sext i32 %160 to i64
  %162 = mul nsw i64 %161, %144
  %163 = getelementptr inbounds i16, i16* %159, i64 %162
  %164 = getelementptr inbounds i16, i16* %163, i64 %158
  store i16 %139, i16* %164, align 2
  %165 = add nsw i64 %143, 3
  %166 = load i16*, i16** %141, align 8
  %167 = load i32, i32* %142, align 8
  %168 = sext i32 %167 to i64
  %169 = mul nsw i64 %168, %144
  %170 = getelementptr inbounds i16, i16* %166, i64 %169
  %171 = getelementptr inbounds i16, i16* %170, i64 %165
  store i16 %140, i16* %171, align 2
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.659"* dereferenceable(32), %"class.gemmlowp::MatrixMap.489"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.561", align 8
  %16 = alloca %"struct.gemmlowp::RegisterBlock.561", align 2
  %17 = alloca %"struct.gemmlowp::RegisterBlock.302", align 16
  %18 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %18) #19
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %20 = sext i32 %8 to i64
  %21 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %22 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %22, i8 -86, i64 128, i1 false)
  %23 = load i32*, i32** %19, align 8, !noalias !1785
  %24 = getelementptr inbounds i32, i32* %23, i64 %20
  %25 = load i32, i32* %21, align 8, !noalias !1785
  %26 = mul nsw i32 %25, %9
  %27 = sext i32 %26 to i64
  %28 = getelementptr inbounds i32, i32* %24, i64 %27
  %29 = getelementptr inbounds i32, i32* %28, i64 1
  %30 = load i32, i32* %28, align 4
  %31 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 0
  store i32 %30, i32* %31, align 16, !alias.scope !1785
  %32 = getelementptr inbounds i32, i32* %29, i64 1
  %33 = load i32, i32* %29, align 4
  %34 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 1
  store i32 %33, i32* %34, align 4, !alias.scope !1785
  %35 = getelementptr inbounds i32, i32* %32, i64 1
  %36 = load i32, i32* %32, align 4
  %37 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 2
  store i32 %36, i32* %37, align 8, !alias.scope !1785
  %38 = getelementptr inbounds i32, i32* %35, i64 1
  %39 = load i32, i32* %35, align 4
  %40 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 3
  store i32 %39, i32* %40, align 4, !alias.scope !1785
  %41 = getelementptr inbounds i32, i32* %38, i64 1
  %42 = load i32, i32* %38, align 4
  %43 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 4
  store i32 %42, i32* %43, align 16, !alias.scope !1785
  %44 = getelementptr inbounds i32, i32* %41, i64 1
  %45 = load i32, i32* %41, align 4
  %46 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 5
  store i32 %45, i32* %46, align 4, !alias.scope !1785
  %47 = getelementptr inbounds i32, i32* %44, i64 1
  %48 = load i32, i32* %44, align 4
  %49 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 6
  store i32 %48, i32* %49, align 8, !alias.scope !1785
  %50 = load i32, i32* %47, align 4
  %51 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 7
  store i32 %50, i32* %51, align 4, !alias.scope !1785
  %52 = add nsw i32 %9, 1
  %53 = mul nsw i32 %25, %52
  %54 = sext i32 %53 to i64
  %55 = getelementptr inbounds i32, i32* %24, i64 %54
  %56 = getelementptr inbounds i32, i32* %55, i64 1
  %57 = load i32, i32* %55, align 4
  %58 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 8
  store i32 %57, i32* %58, align 16, !alias.scope !1785
  %59 = getelementptr inbounds i32, i32* %56, i64 1
  %60 = load i32, i32* %56, align 4
  %61 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 9
  store i32 %60, i32* %61, align 4, !alias.scope !1785
  %62 = getelementptr inbounds i32, i32* %59, i64 1
  %63 = load i32, i32* %59, align 4
  %64 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 10
  store i32 %63, i32* %64, align 8, !alias.scope !1785
  %65 = getelementptr inbounds i32, i32* %62, i64 1
  %66 = load i32, i32* %62, align 4
  %67 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 11
  store i32 %66, i32* %67, align 4, !alias.scope !1785
  %68 = getelementptr inbounds i32, i32* %65, i64 1
  %69 = load i32, i32* %65, align 4
  %70 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 12
  store i32 %69, i32* %70, align 16, !alias.scope !1785
  %71 = getelementptr inbounds i32, i32* %68, i64 1
  %72 = load i32, i32* %68, align 4
  %73 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 13
  store i32 %72, i32* %73, align 4, !alias.scope !1785
  %74 = getelementptr inbounds i32, i32* %71, i64 1
  %75 = load i32, i32* %71, align 4
  %76 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 14
  store i32 %75, i32* %76, align 8, !alias.scope !1785
  %77 = load i32, i32* %74, align 4
  %78 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 15
  store i32 %77, i32* %78, align 4, !alias.scope !1785
  %79 = add nsw i32 %9, 2
  %80 = mul nsw i32 %25, %79
  %81 = sext i32 %80 to i64
  %82 = getelementptr inbounds i32, i32* %24, i64 %81
  %83 = getelementptr inbounds i32, i32* %82, i64 1
  %84 = load i32, i32* %82, align 4
  %85 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 16
  store i32 %84, i32* %85, align 16, !alias.scope !1785
  %86 = getelementptr inbounds i32, i32* %83, i64 1
  %87 = load i32, i32* %83, align 4
  %88 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 17
  store i32 %87, i32* %88, align 4, !alias.scope !1785
  %89 = getelementptr inbounds i32, i32* %86, i64 1
  %90 = load i32, i32* %86, align 4
  %91 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 18
  store i32 %90, i32* %91, align 8, !alias.scope !1785
  %92 = getelementptr inbounds i32, i32* %89, i64 1
  %93 = load i32, i32* %89, align 4
  %94 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 19
  store i32 %93, i32* %94, align 4, !alias.scope !1785
  %95 = getelementptr inbounds i32, i32* %92, i64 1
  %96 = load i32, i32* %92, align 4
  %97 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 20
  store i32 %96, i32* %97, align 16, !alias.scope !1785
  %98 = getelementptr inbounds i32, i32* %95, i64 1
  %99 = load i32, i32* %95, align 4
  %100 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 21
  store i32 %99, i32* %100, align 4, !alias.scope !1785
  %101 = getelementptr inbounds i32, i32* %98, i64 1
  %102 = load i32, i32* %98, align 4
  %103 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 22
  store i32 %102, i32* %103, align 8, !alias.scope !1785
  %104 = load i32, i32* %101, align 4
  %105 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 23
  store i32 %104, i32* %105, align 4, !alias.scope !1785
  %106 = add nsw i32 %9, 3
  %107 = mul nsw i32 %25, %106
  %108 = sext i32 %107 to i64
  %109 = getelementptr inbounds i32, i32* %24, i64 %108
  %110 = getelementptr inbounds i32, i32* %109, i64 1
  %111 = load i32, i32* %109, align 4
  %112 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 24
  store i32 %111, i32* %112, align 16, !alias.scope !1785
  %113 = getelementptr inbounds i32, i32* %110, i64 1
  %114 = load i32, i32* %110, align 4
  %115 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 25
  store i32 %114, i32* %115, align 4, !alias.scope !1785
  %116 = getelementptr inbounds i32, i32* %113, i64 1
  %117 = load i32, i32* %113, align 4
  %118 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 26
  store i32 %117, i32* %118, align 8, !alias.scope !1785
  %119 = getelementptr inbounds i32, i32* %116, i64 1
  %120 = load i32, i32* %116, align 4
  %121 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 27
  store i32 %120, i32* %121, align 4, !alias.scope !1785
  %122 = getelementptr inbounds i32, i32* %119, i64 1
  %123 = load i32, i32* %119, align 4
  %124 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 28
  store i32 %123, i32* %124, align 16, !alias.scope !1785
  %125 = getelementptr inbounds i32, i32* %122, i64 1
  %126 = load i32, i32* %122, align 4
  %127 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 29
  store i32 %126, i32* %127, align 4, !alias.scope !1785
  %128 = getelementptr inbounds i32, i32* %125, i64 1
  %129 = load i32, i32* %125, align 4
  %130 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 30
  store i32 %129, i32* %130, align 8, !alias.scope !1785
  %131 = load i32, i32* %128, align 4
  %132 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 31
  store i32 %131, i32* %132, align 4, !alias.scope !1785
  %133 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %134 = load i32*, i32** %133, align 8, !noalias !1788
  %135 = getelementptr i32, i32* %134, i64 %20
  %136 = bitcast i32* %135 to <4 x i32>*
  %137 = load <4 x i32>, <4 x i32>* %136, align 4
  %138 = getelementptr inbounds i32, i32* %135, i64 4
  %139 = bitcast i32* %138 to <4 x i32>*
  %140 = load <4 x i32>, <4 x i32>* %139, align 4
  %141 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %142 = load i32*, i32** %141, align 8
  %143 = sext i32 %9 to i64
  %144 = getelementptr i32, i32* %142, i64 %143
  %145 = bitcast i32* %144 to i64*
  %146 = load i64, i64* %145, align 4
  %147 = getelementptr inbounds i32, i32* %144, i64 2
  %148 = bitcast i32* %147 to i64*
  %149 = load i64, i64* %148, align 4
  %150 = lshr i64 %146, 32
  %151 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 0
  %152 = load i32, i32* %151, align 4
  %153 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %154 = load i32, i32* %153, align 4
  %155 = insertelement <4 x i32> undef, i32 %154, i32 0
  %156 = shufflevector <4 x i32> %155, <4 x i32> undef, <4 x i32> zeroinitializer
  %157 = mul nsw <4 x i32> %156, %137
  %158 = mul nsw <4 x i32> %156, %140
  %159 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to <4 x i32>*
  %160 = load <4 x i32>, <4 x i32>* %159, align 16
  %161 = add nsw <4 x i32> %160, %157
  %162 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to <4 x i32>*
  store <4 x i32> %161, <4 x i32>* %162, align 16
  %163 = bitcast i32* %43 to <4 x i32>*
  %164 = load <4 x i32>, <4 x i32>* %163, align 16
  %165 = add nsw <4 x i32> %164, %158
  %166 = bitcast i32* %43 to <4 x i32>*
  store <4 x i32> %165, <4 x i32>* %166, align 16
  %167 = bitcast i32* %58 to <4 x i32>*
  %168 = load <4 x i32>, <4 x i32>* %167, align 16
  %169 = add nsw <4 x i32> %168, %157
  %170 = bitcast i32* %58 to <4 x i32>*
  store <4 x i32> %169, <4 x i32>* %170, align 16
  %171 = bitcast i32* %70 to <4 x i32>*
  %172 = load <4 x i32>, <4 x i32>* %171, align 16
  %173 = add nsw <4 x i32> %172, %158
  %174 = bitcast i32* %70 to <4 x i32>*
  store <4 x i32> %173, <4 x i32>* %174, align 16
  %175 = bitcast i32* %85 to <4 x i32>*
  %176 = load <4 x i32>, <4 x i32>* %175, align 16
  %177 = add nsw <4 x i32> %176, %157
  %178 = bitcast i32* %85 to <4 x i32>*
  store <4 x i32> %177, <4 x i32>* %178, align 16
  %179 = bitcast i32* %97 to <4 x i32>*
  %180 = load <4 x i32>, <4 x i32>* %179, align 16
  %181 = add nsw <4 x i32> %180, %158
  %182 = bitcast i32* %97 to <4 x i32>*
  store <4 x i32> %181, <4 x i32>* %182, align 16
  %183 = bitcast i32* %112 to <4 x i32>*
  %184 = load <4 x i32>, <4 x i32>* %183, align 16
  %185 = add nsw <4 x i32> %184, %157
  %186 = bitcast i32* %112 to <4 x i32>*
  store <4 x i32> %185, <4 x i32>* %186, align 16
  %187 = bitcast i32* %124 to <4 x i32>*
  %188 = load <4 x i32>, <4 x i32>* %187, align 16
  %189 = add nsw <4 x i32> %188, %158
  %190 = bitcast i32* %124 to <4 x i32>*
  store <4 x i32> %189, <4 x i32>* %190, align 16
  %191 = trunc i64 %146 to i32
  %192 = trunc i64 %150 to i32
  %193 = mul nsw i32 %154, %7
  %194 = add nsw i32 %193, %191
  %195 = add nsw i32 %193, %192
  %196 = trunc i64 %149 to i32
  %197 = add nsw i32 %193, %196
  %198 = lshr i64 %149, 32
  %199 = trunc i64 %198 to i32
  %200 = add nsw i32 %193, %199
  %201 = mul nsw i32 %194, %152
  %202 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to <4 x i32>*
  %203 = load <4 x i32>, <4 x i32>* %202, align 16
  %204 = insertelement <4 x i32> undef, i32 %201, i32 0
  %205 = shufflevector <4 x i32> %204, <4 x i32> undef, <4 x i32> zeroinitializer
  %206 = add nsw <4 x i32> %203, %205
  %207 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to <4 x i32>*
  store <4 x i32> %206, <4 x i32>* %207, align 16
  %208 = bitcast i32* %43 to <4 x i32>*
  %209 = load <4 x i32>, <4 x i32>* %208, align 16
  %210 = add nsw <4 x i32> %209, %205
  %211 = bitcast i32* %43 to <4 x i32>*
  store <4 x i32> %210, <4 x i32>* %211, align 16
  %212 = mul nsw i32 %195, %152
  %213 = bitcast i32* %58 to <4 x i32>*
  %214 = load <4 x i32>, <4 x i32>* %213, align 16
  %215 = insertelement <4 x i32> undef, i32 %212, i32 0
  %216 = shufflevector <4 x i32> %215, <4 x i32> undef, <4 x i32> zeroinitializer
  %217 = add nsw <4 x i32> %214, %216
  %218 = bitcast i32* %58 to <4 x i32>*
  store <4 x i32> %217, <4 x i32>* %218, align 16
  %219 = bitcast i32* %70 to <4 x i32>*
  %220 = load <4 x i32>, <4 x i32>* %219, align 16
  %221 = add nsw <4 x i32> %220, %216
  %222 = bitcast i32* %70 to <4 x i32>*
  store <4 x i32> %221, <4 x i32>* %222, align 16
  %223 = mul nsw i32 %197, %152
  %224 = bitcast i32* %85 to <4 x i32>*
  %225 = load <4 x i32>, <4 x i32>* %224, align 16
  %226 = insertelement <4 x i32> undef, i32 %223, i32 0
  %227 = shufflevector <4 x i32> %226, <4 x i32> undef, <4 x i32> zeroinitializer
  %228 = add nsw <4 x i32> %225, %227
  %229 = bitcast i32* %85 to <4 x i32>*
  store <4 x i32> %228, <4 x i32>* %229, align 16
  %230 = bitcast i32* %97 to <4 x i32>*
  %231 = load <4 x i32>, <4 x i32>* %230, align 16
  %232 = add nsw <4 x i32> %231, %227
  %233 = bitcast i32* %97 to <4 x i32>*
  store <4 x i32> %232, <4 x i32>* %233, align 16
  %234 = mul nsw i32 %200, %152
  %235 = bitcast i32* %112 to <4 x i32>*
  %236 = load <4 x i32>, <4 x i32>* %235, align 16
  %237 = insertelement <4 x i32> undef, i32 %234, i32 0
  %238 = shufflevector <4 x i32> %237, <4 x i32> undef, <4 x i32> zeroinitializer
  %239 = add nsw <4 x i32> %236, %238
  %240 = bitcast i32* %112 to <4 x i32>*
  store <4 x i32> %239, <4 x i32>* %240, align 16
  %241 = bitcast i32* %124 to <4 x i32>*
  %242 = load <4 x i32>, <4 x i32>* %241, align 16
  %243 = add nsw <4 x i32> %242, %238
  %244 = bitcast i32* %124 to <4 x i32>*
  store <4 x i32> %243, <4 x i32>* %244, align 16
  %245 = bitcast %"struct.gemmlowp::RegisterBlock.561"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %245) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 2 %245, i8 -86, i64 64, i1 false) #19
  %246 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.659", %"struct.gemmlowp::OutputPipelineExecutor.659"* %1, i64 0, i32 0
  call void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalES8_ii(%"struct.gemmlowp::RegisterBlock.561"* nonnull sret %16, %"struct.gemmlowp::OutputPipelineEvalImpl.660"* %246, %"struct.gemmlowp::RegisterBlock.302"* nonnull byval(%"struct.gemmlowp::RegisterBlock.302") align 8 %17, i32 %10, i32 %11) #19
  %247 = bitcast %"struct.gemmlowp::RegisterBlock.561"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %247) #19
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %247, i8* nonnull align 2 %245, i64 64, i1 false) #19
  %248 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %2, i64 0, i32 0
  %249 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %2, i64 0, i32 3
  %250 = sext i32 %13 to i64
  %251 = sext i32 %12 to i64
  %252 = add nsw i64 %250, 1
  %253 = add nsw i64 %250, 2
  %254 = add nsw i64 %250, 3
  br label %255

255:                                              ; preds = %255, %14
  %256 = phi i64 [ 0, %14 ], [ %293, %255 ]
  %257 = add nsw i64 %256, %251
  %258 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.561", %"struct.gemmlowp::RegisterBlock.561"* %15, i64 0, i32 0, i32 0, i64 %256
  %259 = load i16, i16* %258, align 2
  %260 = load i16*, i16** %248, align 8
  %261 = load i32, i32* %249, align 8
  %262 = sext i32 %261 to i64
  %263 = mul nsw i64 %257, %262
  %264 = getelementptr inbounds i16, i16* %260, i64 %250
  %265 = getelementptr inbounds i16, i16* %264, i64 %263
  store i16 %259, i16* %265, align 2
  %266 = add nuw nsw i64 %256, 8
  %267 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.561", %"struct.gemmlowp::RegisterBlock.561"* %15, i64 0, i32 0, i32 0, i64 %266
  %268 = load i16, i16* %267, align 2
  %269 = load i16*, i16** %248, align 8
  %270 = load i32, i32* %249, align 8
  %271 = sext i32 %270 to i64
  %272 = mul nsw i64 %257, %271
  %273 = getelementptr inbounds i16, i16* %269, i64 %252
  %274 = getelementptr inbounds i16, i16* %273, i64 %272
  store i16 %268, i16* %274, align 2
  %275 = add nuw nsw i64 %256, 16
  %276 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.561", %"struct.gemmlowp::RegisterBlock.561"* %15, i64 0, i32 0, i32 0, i64 %275
  %277 = load i16, i16* %276, align 2
  %278 = load i16*, i16** %248, align 8
  %279 = load i32, i32* %249, align 8
  %280 = sext i32 %279 to i64
  %281 = mul nsw i64 %257, %280
  %282 = getelementptr inbounds i16, i16* %278, i64 %253
  %283 = getelementptr inbounds i16, i16* %282, i64 %281
  store i16 %277, i16* %283, align 2
  %284 = add nuw nsw i64 %256, 24
  %285 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.561", %"struct.gemmlowp::RegisterBlock.561"* %15, i64 0, i32 0, i32 0, i64 %284
  %286 = load i16, i16* %285, align 2
  %287 = load i16*, i16** %248, align 8
  %288 = load i32, i32* %249, align 8
  %289 = sext i32 %288 to i64
  %290 = mul nsw i64 %257, %289
  %291 = getelementptr inbounds i16, i16* %287, i64 %254
  %292 = getelementptr inbounds i16, i16* %291, i64 %290
  store i16 %286, i16* %292, align 2
  %293 = add nuw nsw i64 %256, 1
  %294 = icmp eq i64 %293, 8
  br i1 %294, label %295, label %255

295:                                              ; preds = %255
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %247) #19
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %245) #19
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %18) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.638"* dereferenceable(32), %"class.gemmlowp::MatrixMap.489"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.304", align 16
  %16 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %17 = sext i32 %8 to i64
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %19 = load i32*, i32** %16, align 8, !noalias !1793
  %20 = getelementptr inbounds i32, i32* %19, i64 %17
  %21 = load i32, i32* %18, align 8, !noalias !1793
  %22 = mul nsw i32 %21, %9
  %23 = sext i32 %22 to i64
  %24 = getelementptr inbounds i32, i32* %20, i64 %23
  %25 = getelementptr inbounds i32, i32* %24, i64 1
  %26 = getelementptr inbounds i32, i32* %25, i64 1
  %27 = getelementptr inbounds i32, i32* %26, i64 1
  %28 = getelementptr inbounds i32, i32* %27, i64 1
  %29 = bitcast i32* %24 to <4 x i32>*
  %30 = load <4 x i32>, <4 x i32>* %29, align 4, !noalias !1793
  %31 = getelementptr inbounds i32, i32* %28, i64 1
  %32 = load i32, i32* %28, align 4, !noalias !1793
  %33 = getelementptr inbounds i32, i32* %31, i64 1
  %34 = load i32, i32* %31, align 4, !noalias !1793
  %35 = getelementptr inbounds i32, i32* %33, i64 1
  %36 = load i32, i32* %33, align 4, !noalias !1793
  %37 = load i32, i32* %35, align 4, !noalias !1793
  %38 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %39 = load i32*, i32** %38, align 8, !noalias !1798
  %40 = getelementptr i32, i32* %39, i64 %17
  %41 = bitcast i32* %40 to <4 x i32>*
  %42 = load <4 x i32>, <4 x i32>* %41, align 4
  %43 = getelementptr inbounds i32, i32* %40, i64 4
  %44 = bitcast i32* %43 to <4 x i32>*
  %45 = load <4 x i32>, <4 x i32>* %44, align 4
  %46 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %47 = load i32*, i32** %46, align 8
  %48 = sext i32 %9 to i64
  %49 = getelementptr inbounds i32, i32* %47, i64 %48
  %50 = load i32, i32* %49, align 4
  %51 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 0
  %52 = load i32, i32* %51, align 4
  %53 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %54 = load i32, i32* %53, align 4
  %55 = insertelement <4 x i32> undef, i32 %54, i32 0
  %56 = shufflevector <4 x i32> %55, <4 x i32> undef, <4 x i32> zeroinitializer
  %57 = mul nsw <4 x i32> %56, %42
  %58 = add nsw <4 x i32> %57, %30
  %59 = mul nsw <4 x i32> %56, %45
  %60 = insertelement <4 x i32> undef, i32 %32, i32 0
  %61 = insertelement <4 x i32> %60, i32 %34, i32 1
  %62 = insertelement <4 x i32> %61, i32 %36, i32 2
  %63 = insertelement <4 x i32> %62, i32 %37, i32 3
  %64 = add nsw <4 x i32> %59, %63
  %65 = mul nsw i32 %54, %7
  %66 = add nsw i32 %65, %50
  %67 = mul nsw i32 %66, %52
  %68 = insertelement <4 x i32> undef, i32 %67, i32 0
  %69 = shufflevector <4 x i32> %68, <4 x i32> undef, <4 x i32> zeroinitializer
  %70 = add nsw <4 x i32> %58, %69
  %71 = add nsw <4 x i32> %64, %69
  %72 = bitcast %"struct.gemmlowp::RegisterBlock.304"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %72)
  %73 = bitcast %"struct.gemmlowp::RegisterBlock.304"* %15 to <4 x i32>*
  store <4 x i32> %70, <4 x i32>* %73, align 16
  %74 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %15, i64 0, i32 0, i32 0, i64 4
  %75 = bitcast i32* %74 to <4 x i32>*
  store <4 x i32> %71, <4 x i32>* %75, align 16
  %76 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.638", %"struct.gemmlowp::OutputPipelineExecutor.638"* %1, i64 0, i32 0
  %77 = tail call { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalES8_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.639"* %76, %"struct.gemmlowp::RegisterBlock.304"* nonnull byval(%"struct.gemmlowp::RegisterBlock.304") align 8 %15, i32 %10, i32 %11) #19
  %78 = extractvalue { i64, i64 } %77, 0
  %79 = extractvalue { i64, i64 } %77, 1
  %80 = trunc i64 %78 to i16
  %81 = lshr i64 %78, 16
  %82 = trunc i64 %81 to i16
  %83 = lshr i64 %78, 32
  %84 = trunc i64 %83 to i16
  %85 = lshr i64 %78, 48
  %86 = trunc i64 %85 to i16
  %87 = trunc i64 %79 to i16
  %88 = lshr i64 %79, 16
  %89 = trunc i64 %88 to i16
  %90 = lshr i64 %79, 32
  %91 = trunc i64 %90 to i16
  %92 = lshr i64 %79, 48
  %93 = trunc i64 %92 to i16
  %94 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %2, i64 0, i32 0
  %95 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %2, i64 0, i32 3
  %96 = sext i32 %12 to i64
  %97 = load i16*, i16** %94, align 8
  %98 = load i32, i32* %95, align 8
  %99 = sext i32 %98 to i64
  %100 = mul nsw i64 %99, %96
  %101 = getelementptr inbounds i16, i16* %97, i64 %100
  %102 = sext i32 %13 to i64
  %103 = getelementptr inbounds i16, i16* %101, i64 %102
  store i16 %80, i16* %103, align 2
  %104 = add nsw i64 %96, 1
  %105 = load i16*, i16** %94, align 8
  %106 = load i32, i32* %95, align 8
  %107 = sext i32 %106 to i64
  %108 = mul nsw i64 %104, %107
  %109 = getelementptr inbounds i16, i16* %105, i64 %108
  %110 = getelementptr inbounds i16, i16* %109, i64 %102
  store i16 %82, i16* %110, align 2
  %111 = add nsw i64 %96, 2
  %112 = load i16*, i16** %94, align 8
  %113 = load i32, i32* %95, align 8
  %114 = sext i32 %113 to i64
  %115 = mul nsw i64 %111, %114
  %116 = getelementptr inbounds i16, i16* %112, i64 %115
  %117 = getelementptr inbounds i16, i16* %116, i64 %102
  store i16 %84, i16* %117, align 2
  %118 = add nsw i64 %96, 3
  %119 = load i16*, i16** %94, align 8
  %120 = load i32, i32* %95, align 8
  %121 = sext i32 %120 to i64
  %122 = mul nsw i64 %118, %121
  %123 = getelementptr inbounds i16, i16* %119, i64 %122
  %124 = getelementptr inbounds i16, i16* %123, i64 %102
  store i16 %86, i16* %124, align 2
  %125 = add nsw i64 %96, 4
  %126 = load i16*, i16** %94, align 8
  %127 = load i32, i32* %95, align 8
  %128 = sext i32 %127 to i64
  %129 = mul nsw i64 %125, %128
  %130 = getelementptr inbounds i16, i16* %126, i64 %129
  %131 = getelementptr inbounds i16, i16* %130, i64 %102
  store i16 %87, i16* %131, align 2
  %132 = add nsw i64 %96, 5
  %133 = load i16*, i16** %94, align 8
  %134 = load i32, i32* %95, align 8
  %135 = sext i32 %134 to i64
  %136 = mul nsw i64 %132, %135
  %137 = getelementptr inbounds i16, i16* %133, i64 %136
  %138 = getelementptr inbounds i16, i16* %137, i64 %102
  store i16 %89, i16* %138, align 2
  %139 = add nsw i64 %96, 6
  %140 = load i16*, i16** %94, align 8
  %141 = load i32, i32* %95, align 8
  %142 = sext i32 %141 to i64
  %143 = mul nsw i64 %139, %142
  %144 = getelementptr inbounds i16, i16* %140, i64 %143
  %145 = getelementptr inbounds i16, i16* %144, i64 %102
  store i16 %91, i16* %145, align 2
  %146 = add nsw i64 %96, 7
  %147 = load i16*, i16** %94, align 8
  %148 = load i32, i32* %95, align 8
  %149 = sext i32 %148 to i64
  %150 = mul nsw i64 %146, %149
  %151 = getelementptr inbounds i16, i16* %147, i64 %150
  %152 = getelementptr inbounds i16, i16* %151, i64 %102
  store i16 %93, i16* %152, align 2
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %72)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE1EEENSE_ISB_LSF_0EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_1EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.631"* dereferenceable(32), %"class.gemmlowp::MatrixMap.489"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.gemmlowp::VectorDup"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %16 = sext i32 %8 to i64
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %18 = load i32*, i32** %15, align 8
  %19 = getelementptr inbounds i32, i32* %18, i64 %16
  %20 = load i32, i32* %17, align 8
  %21 = mul nsw i32 %20, %9
  %22 = sext i32 %21 to i64
  %23 = getelementptr inbounds i32, i32* %19, i64 %22
  %24 = getelementptr inbounds i32, i32* %23, i64 1
  %25 = load i32, i32* %23, align 4
  %26 = getelementptr inbounds i32, i32* %24, i64 1
  %27 = load i32, i32* %24, align 4
  %28 = getelementptr inbounds i32, i32* %26, i64 1
  %29 = load i32, i32* %26, align 4
  %30 = load i32, i32* %28, align 4
  %31 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %32 = load i32*, i32** %31, align 8
  %33 = getelementptr i32, i32* %32, i64 %16
  %34 = bitcast i32* %33 to i64*
  %35 = load i64, i64* %34, align 4
  %36 = getelementptr inbounds i32, i32* %33, i64 2
  %37 = bitcast i32* %36 to i64*
  %38 = load i64, i64* %37, align 4
  %39 = trunc i64 %35 to i32
  %40 = lshr i64 %35, 32
  %41 = trunc i64 %40 to i32
  %42 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %43 = load i32*, i32** %42, align 8
  %44 = sext i32 %9 to i64
  %45 = getelementptr inbounds i32, i32* %43, i64 %44
  %46 = load i32, i32* %45, align 4
  %47 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %5, i64 0, i32 0
  %48 = load i32, i32* %47, align 4
  %49 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %50 = load i32, i32* %49, align 4
  %51 = mul nsw i32 %50, %39
  %52 = add nsw i32 %51, %25
  %53 = mul nsw i32 %50, %41
  %54 = add nsw i32 %53, %27
  %55 = trunc i64 %38 to i32
  %56 = mul nsw i32 %50, %55
  %57 = add nsw i32 %56, %29
  %58 = lshr i64 %38, 32
  %59 = trunc i64 %58 to i32
  %60 = mul nsw i32 %50, %59
  %61 = add nsw i32 %60, %30
  %62 = mul nsw i32 %50, %7
  %63 = add nsw i32 %62, %46
  %64 = mul nsw i32 %63, %48
  %65 = add nsw i32 %52, %64
  %66 = add nsw i32 %54, %64
  %67 = add nsw i32 %57, %64
  %68 = zext i32 %67 to i64
  %69 = add nsw i32 %61, %64
  %70 = zext i32 %69 to i64
  %71 = shl nuw i64 %70, 32
  %72 = or i64 %71, %68
  %73 = zext i32 %66 to i64
  %74 = shl nuw i64 %73, 32
  %75 = zext i32 %65 to i64
  %76 = or i64 %74, %75
  %77 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.631", %"struct.gemmlowp::OutputPipelineExecutor.631"* %1, i64 0, i32 0, i32 0, i32 0
  %78 = tail call { i64, i64 } @_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi4EEEE4EvalES3_(%"struct.gemmlowp::OutputStageEvalBufferImpl.231"* %77, i64 %76, i64 %72) #19
  %79 = extractvalue { i64, i64 } %78, 0
  %80 = extractvalue { i64, i64 } %78, 1
  %81 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.631", %"struct.gemmlowp::OutputPipelineExecutor.631"* %1, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %82 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %81, align 8
  %83 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %82, i64 0, i32 0
  %84 = load i32, i32* %83, align 4
  %85 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %82, i64 0, i32 1
  %86 = load i32, i32* %85, align 4
  %87 = trunc i64 %79 to i32
  %88 = icmp sgt i32 %84, %87
  %89 = select i1 %88, i32 %84, i32 %87
  %90 = icmp slt i32 %86, %89
  %91 = select i1 %90, i32 %86, i32 %89
  %92 = lshr i64 %79, 32
  %93 = trunc i64 %92 to i32
  %94 = icmp sgt i32 %84, %93
  %95 = select i1 %94, i32 %84, i32 %93
  %96 = icmp slt i32 %86, %95
  %97 = select i1 %96, i32 %86, i32 %95
  %98 = trunc i64 %80 to i32
  %99 = icmp sgt i32 %84, %98
  %100 = select i1 %99, i32 %84, i32 %98
  %101 = icmp slt i32 %86, %100
  %102 = select i1 %101, i32 %86, i32 %100
  %103 = lshr i64 %80, 32
  %104 = trunc i64 %103 to i32
  %105 = icmp sgt i32 %84, %104
  %106 = select i1 %105, i32 %84, i32 %104
  %107 = icmp slt i32 %86, %106
  %108 = select i1 %107, i32 %86, i32 %106
  %109 = icmp sgt i32 %91, -32768
  %110 = select i1 %109, i32 %91, i32 -32768
  %111 = icmp slt i32 %110, 32767
  %112 = select i1 %111, i32 %110, i32 32767
  %113 = icmp sgt i32 %97, -32768
  %114 = select i1 %113, i32 %97, i32 -32768
  %115 = icmp slt i32 %114, 32767
  %116 = select i1 %115, i32 %114, i32 32767
  %117 = icmp sgt i32 %102, -32768
  %118 = select i1 %117, i32 %102, i32 -32768
  %119 = icmp slt i32 %118, 32767
  %120 = select i1 %119, i32 %118, i32 32767
  %121 = icmp sgt i32 %108, -32768
  %122 = select i1 %121, i32 %108, i32 -32768
  %123 = icmp slt i32 %122, 32767
  %124 = select i1 %123, i32 %122, i32 32767
  %125 = trunc i32 %112 to i16
  %126 = trunc i32 %116 to i16
  %127 = trunc i32 %120 to i16
  %128 = trunc i32 %124 to i16
  %129 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %2, i64 0, i32 0
  %130 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %2, i64 0, i32 3
  %131 = sext i32 %12 to i64
  %132 = load i16*, i16** %129, align 8
  %133 = load i32, i32* %130, align 8
  %134 = sext i32 %133 to i64
  %135 = mul nsw i64 %134, %131
  %136 = getelementptr inbounds i16, i16* %132, i64 %135
  %137 = sext i32 %13 to i64
  %138 = getelementptr inbounds i16, i16* %136, i64 %137
  store i16 %125, i16* %138, align 2
  %139 = add nsw i64 %131, 1
  %140 = load i16*, i16** %129, align 8
  %141 = load i32, i32* %130, align 8
  %142 = sext i32 %141 to i64
  %143 = mul nsw i64 %139, %142
  %144 = getelementptr inbounds i16, i16* %140, i64 %143
  %145 = getelementptr inbounds i16, i16* %144, i64 %137
  store i16 %126, i16* %145, align 2
  %146 = add nsw i64 %131, 2
  %147 = load i16*, i16** %129, align 8
  %148 = load i32, i32* %130, align 8
  %149 = sext i32 %148 to i64
  %150 = mul nsw i64 %146, %149
  %151 = getelementptr inbounds i16, i16* %147, i64 %150
  %152 = getelementptr inbounds i16, i16* %151, i64 %137
  store i16 %127, i16* %152, align 2
  %153 = add nsw i64 %131, 3
  %154 = load i16*, i16** %129, align 8
  %155 = load i32, i32* %130, align 8
  %156 = sext i32 %155 to i64
  %157 = mul nsw i64 %153, %156
  %158 = getelementptr inbounds i16, i16* %154, i64 %157
  %159 = getelementptr inbounds i16, i16* %158, i64 %137
  store i16 %128, i16* %159, align 2
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalES8_ii(%"struct.gemmlowp::RegisterBlock.561"* noalias sret, %"struct.gemmlowp::OutputPipelineEvalImpl.660"*, %"struct.gemmlowp::RegisterBlock.302"* byval(%"struct.gemmlowp::RegisterBlock.302") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %6 = alloca %"struct.gemmlowp::RegisterBuffer.303", align 16
  %7 = alloca %"struct.gemmlowp::RegisterBuffer.562", align 8
  %8 = alloca [32 x i16], align 2
  %9 = alloca %"struct.gemmlowp::RegisterBuffer.303", align 16
  %10 = alloca %"struct.gemmlowp::RegisterBuffer.303", align 16
  %11 = alloca [32 x i32], align 4
  %12 = alloca %"struct.gemmlowp::RegisterBuffer.303", align 8
  %13 = alloca %"struct.gemmlowp::RegisterBuffer.303", align 4
  %14 = alloca [32 x i32], align 4
  %15 = bitcast [32 x i32]* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %15)
  %16 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %2 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %15, i8 -86, i64 128, i1 false), !alias.scope !1803
  %17 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %17) #19, !noalias !1803
  %18 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %18) #19, !noalias !1803
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %18, i8* nonnull align 8 %16, i64 128, i1 false)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %17, i8 -86, i64 128, i1 false) #19, !alias.scope !1806, !noalias !1803
  %19 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.660", %"struct.gemmlowp::OutputPipelineEvalImpl.660"* %1, i64 0, i32 0, i32 0, i32 0
  %20 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %19, align 8, !noalias !1809
  %21 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %20, i64 0, i32 2
  %22 = load i32, i32* %21, align 4, !noalias !1809
  %23 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.660", %"struct.gemmlowp::OutputPipelineEvalImpl.660"* %1, i64 0, i32 0, i32 0, i32 1
  %24 = load i32, i32* %23, align 8, !noalias !1809
  %25 = shl i32 1, %24
  %26 = sext i32 %25 to i64
  %27 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %20, i64 0, i32 0
  %28 = load i32, i32* %27, align 4, !noalias !1809
  %29 = sext i32 %28 to i64
  %30 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.660", %"struct.gemmlowp::OutputPipelineEvalImpl.660"* %1, i64 0, i32 0, i32 0, i32 2
  %31 = load i32, i32* %30, align 4, !noalias !1809
  %32 = zext i32 %31 to i64
  %33 = shl nsw i64 -1, %32
  %34 = trunc i64 %33 to i32
  %35 = xor i32 %34, -1
  %36 = ashr i32 %35, 1
  %37 = icmp ne i32 %28, -2147483648
  br label %38

38:                                               ; preds = %59, %5
  %39 = phi i64 [ 0, %5 ], [ %70, %59 ]
  %40 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %12, i64 0, i32 0, i64 %39
  %41 = load i32, i32* %40, align 4, !noalias !1809
  %42 = sext i32 %41 to i64
  %43 = mul nsw i64 %42, %26
  %44 = icmp slt i64 %43, 2147483647
  %45 = select i1 %44, i64 %43, i64 2147483647
  %46 = icmp sgt i64 %45, -2147483648
  %47 = select i1 %46, i64 %45, i64 -2147483648
  %48 = trunc i64 %47 to i32
  %49 = icmp ne i32 %28, %48
  %50 = or i1 %37, %49
  br i1 %50, label %51, label %59

51:                                               ; preds = %38
  %52 = select i1 %49, i64 %29, i64 %47
  %53 = mul nsw i64 %52, %47
  %54 = icmp sgt i64 %53, -1
  %55 = select i1 %54, i64 1073741824, i64 -1073741823
  %56 = add nsw i64 %55, %53
  %57 = sdiv i64 %56, 2147483648
  %58 = trunc i64 %57 to i32
  br label %59

59:                                               ; preds = %51, %38
  %60 = phi i32 [ %58, %51 ], [ 2147483647, %38 ]
  %61 = and i32 %60, %35
  %62 = lshr i32 %60, 31
  %63 = add nsw i32 %62, %36
  %64 = ashr i32 %60, %31
  %65 = icmp sgt i32 %61, %63
  %66 = zext i1 %65 to i32
  %67 = add i32 %64, %22
  %68 = add i32 %67, %66
  %69 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %13, i64 0, i32 0, i64 %39
  store i32 %68, i32* %69, align 4, !alias.scope !1806, !noalias !1803
  %70 = add nuw nsw i64 %39, 1
  %71 = icmp eq i64 %70, 32
  br i1 %71, label %72, label %38

72:                                               ; preds = %59
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %18) #19, !noalias !1803
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 4 %15, i8* nonnull align 4 %17, i64 128, i1 false)
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %17) #19, !noalias !1803
  %73 = bitcast [32 x i32]* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %73)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %73, i8 -86, i64 128, i1 false), !alias.scope !1810, !noalias !1813
  %74 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %74) #19, !noalias !1816
  %75 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %75) #19, !noalias !1816
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %75, i8* nonnull align 4 %15, i64 128, i1 false)
  %76 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.660", %"struct.gemmlowp::OutputPipelineEvalImpl.660"* %1, i64 0, i32 1, i32 0, i32 0, i32 0
  %77 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %76, align 8, !noalias !1817
  %78 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %77, i64 0, i32 0
  %79 = load i32, i32* %78, align 4, !noalias !1817
  %80 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %77, i64 0, i32 1
  %81 = load i32, i32* %80, align 4, !noalias !1817
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %74, i8 -86, i64 128, i1 false) #19, !alias.scope !1820, !noalias !1816
  %82 = insertelement <4 x i32> undef, i32 %79, i32 0
  %83 = shufflevector <4 x i32> %82, <4 x i32> undef, <4 x i32> zeroinitializer
  %84 = insertelement <4 x i32> undef, i32 %81, i32 0
  %85 = shufflevector <4 x i32> %84, <4 x i32> undef, <4 x i32> zeroinitializer
  %86 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %9 to <4 x i32>*
  %87 = load <4 x i32>, <4 x i32>* %86, align 16, !noalias !1817
  %88 = icmp slt <4 x i32> %87, %83
  %89 = select <4 x i1> %88, <4 x i32> %83, <4 x i32> %87
  %90 = icmp slt <4 x i32> %85, %89
  %91 = select <4 x i1> %90, <4 x i32> %85, <4 x i32> %89
  %92 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %10 to <4 x i32>*
  store <4 x i32> %91, <4 x i32>* %92, align 16, !alias.scope !1820, !noalias !1816
  %93 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %9, i64 0, i32 0, i64 4
  %94 = bitcast i32* %93 to <4 x i32>*
  %95 = load <4 x i32>, <4 x i32>* %94, align 16, !noalias !1817
  %96 = icmp slt <4 x i32> %95, %83
  %97 = select <4 x i1> %96, <4 x i32> %83, <4 x i32> %95
  %98 = icmp slt <4 x i32> %85, %97
  %99 = select <4 x i1> %98, <4 x i32> %85, <4 x i32> %97
  %100 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %10, i64 0, i32 0, i64 4
  %101 = bitcast i32* %100 to <4 x i32>*
  store <4 x i32> %99, <4 x i32>* %101, align 16, !alias.scope !1820, !noalias !1816
  %102 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %9, i64 0, i32 0, i64 8
  %103 = bitcast i32* %102 to <4 x i32>*
  %104 = load <4 x i32>, <4 x i32>* %103, align 16, !noalias !1817
  %105 = icmp slt <4 x i32> %104, %83
  %106 = select <4 x i1> %105, <4 x i32> %83, <4 x i32> %104
  %107 = icmp slt <4 x i32> %85, %106
  %108 = select <4 x i1> %107, <4 x i32> %85, <4 x i32> %106
  %109 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %10, i64 0, i32 0, i64 8
  %110 = bitcast i32* %109 to <4 x i32>*
  store <4 x i32> %108, <4 x i32>* %110, align 16, !alias.scope !1820, !noalias !1816
  %111 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %9, i64 0, i32 0, i64 12
  %112 = bitcast i32* %111 to <4 x i32>*
  %113 = load <4 x i32>, <4 x i32>* %112, align 16, !noalias !1817
  %114 = icmp slt <4 x i32> %113, %83
  %115 = select <4 x i1> %114, <4 x i32> %83, <4 x i32> %113
  %116 = icmp slt <4 x i32> %85, %115
  %117 = select <4 x i1> %116, <4 x i32> %85, <4 x i32> %115
  %118 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %10, i64 0, i32 0, i64 12
  %119 = bitcast i32* %118 to <4 x i32>*
  store <4 x i32> %117, <4 x i32>* %119, align 16, !alias.scope !1820, !noalias !1816
  %120 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %9, i64 0, i32 0, i64 16
  %121 = bitcast i32* %120 to <4 x i32>*
  %122 = load <4 x i32>, <4 x i32>* %121, align 16, !noalias !1817
  %123 = icmp slt <4 x i32> %122, %83
  %124 = select <4 x i1> %123, <4 x i32> %83, <4 x i32> %122
  %125 = icmp slt <4 x i32> %85, %124
  %126 = select <4 x i1> %125, <4 x i32> %85, <4 x i32> %124
  %127 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %10, i64 0, i32 0, i64 16
  %128 = bitcast i32* %127 to <4 x i32>*
  store <4 x i32> %126, <4 x i32>* %128, align 16, !alias.scope !1820, !noalias !1816
  %129 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %9, i64 0, i32 0, i64 20
  %130 = bitcast i32* %129 to <4 x i32>*
  %131 = load <4 x i32>, <4 x i32>* %130, align 16, !noalias !1817
  %132 = icmp slt <4 x i32> %131, %83
  %133 = select <4 x i1> %132, <4 x i32> %83, <4 x i32> %131
  %134 = icmp slt <4 x i32> %85, %133
  %135 = select <4 x i1> %134, <4 x i32> %85, <4 x i32> %133
  %136 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %10, i64 0, i32 0, i64 20
  %137 = bitcast i32* %136 to <4 x i32>*
  store <4 x i32> %135, <4 x i32>* %137, align 16, !alias.scope !1820, !noalias !1816
  %138 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %9, i64 0, i32 0, i64 24
  %139 = bitcast i32* %138 to <4 x i32>*
  %140 = load <4 x i32>, <4 x i32>* %139, align 16, !noalias !1817
  %141 = icmp slt <4 x i32> %140, %83
  %142 = select <4 x i1> %141, <4 x i32> %83, <4 x i32> %140
  %143 = icmp slt <4 x i32> %85, %142
  %144 = select <4 x i1> %143, <4 x i32> %85, <4 x i32> %142
  %145 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %10, i64 0, i32 0, i64 24
  %146 = bitcast i32* %145 to <4 x i32>*
  store <4 x i32> %144, <4 x i32>* %146, align 16, !alias.scope !1820, !noalias !1816
  %147 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %9, i64 0, i32 0, i64 28
  %148 = bitcast i32* %147 to <4 x i32>*
  %149 = load <4 x i32>, <4 x i32>* %148, align 16, !noalias !1817
  %150 = icmp slt <4 x i32> %149, %83
  %151 = select <4 x i1> %150, <4 x i32> %83, <4 x i32> %149
  %152 = icmp slt <4 x i32> %85, %151
  %153 = select <4 x i1> %152, <4 x i32> %85, <4 x i32> %151
  %154 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %10, i64 0, i32 0, i64 28
  %155 = bitcast i32* %154 to <4 x i32>*
  store <4 x i32> %153, <4 x i32>* %155, align 16, !alias.scope !1820, !noalias !1816
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %75) #19, !noalias !1816
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 4 %73, i8* nonnull align 16 %74, i64 128, i1 false) #19, !noalias !1813
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %74) #19, !noalias !1816
  %156 = bitcast [32 x i16]* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %156)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 2 %156, i8 -86, i64 64, i1 false), !alias.scope !1821, !noalias !1824
  %157 = bitcast %"struct.gemmlowp::RegisterBuffer.562"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %157) #19, !noalias !1827
  %158 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %158) #19, !noalias !1827
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 %158, i8* nonnull align 4 %73, i64 128, i1 false) #19, !noalias !1813
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %157, i8 -86, i64 64, i1 false) #19, !alias.scope !1828, !noalias !1827
  %159 = bitcast %"struct.gemmlowp::RegisterBuffer.303"* %6 to <4 x i32>*
  %160 = load <4 x i32>, <4 x i32>* %159, align 16, !noalias !1831
  %161 = icmp sgt <4 x i32> %160, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %162 = select <4 x i1> %161, <4 x i32> %160, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %163 = icmp slt <4 x i32> %162, <i32 32767, i32 32767, i32 32767, i32 32767>
  %164 = select <4 x i1> %163, <4 x i32> %162, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %165 = trunc <4 x i32> %164 to <4 x i16>
  %166 = bitcast %"struct.gemmlowp::RegisterBuffer.562"* %7 to <4 x i16>*
  store <4 x i16> %165, <4 x i16>* %166, align 8, !alias.scope !1828, !noalias !1827
  %167 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 4
  %168 = bitcast i32* %167 to <4 x i32>*
  %169 = load <4 x i32>, <4 x i32>* %168, align 16, !noalias !1831
  %170 = icmp sgt <4 x i32> %169, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %171 = select <4 x i1> %170, <4 x i32> %169, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %172 = icmp slt <4 x i32> %171, <i32 32767, i32 32767, i32 32767, i32 32767>
  %173 = select <4 x i1> %172, <4 x i32> %171, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %174 = trunc <4 x i32> %173 to <4 x i16>
  %175 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.562", %"struct.gemmlowp::RegisterBuffer.562"* %7, i64 0, i32 0, i64 4
  %176 = bitcast i16* %175 to <4 x i16>*
  store <4 x i16> %174, <4 x i16>* %176, align 8, !alias.scope !1828, !noalias !1827
  %177 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 8
  %178 = bitcast i32* %177 to <4 x i32>*
  %179 = load <4 x i32>, <4 x i32>* %178, align 16, !noalias !1831
  %180 = icmp sgt <4 x i32> %179, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %181 = select <4 x i1> %180, <4 x i32> %179, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %182 = icmp slt <4 x i32> %181, <i32 32767, i32 32767, i32 32767, i32 32767>
  %183 = select <4 x i1> %182, <4 x i32> %181, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %184 = trunc <4 x i32> %183 to <4 x i16>
  %185 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.562", %"struct.gemmlowp::RegisterBuffer.562"* %7, i64 0, i32 0, i64 8
  %186 = bitcast i16* %185 to <4 x i16>*
  store <4 x i16> %184, <4 x i16>* %186, align 8, !alias.scope !1828, !noalias !1827
  %187 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 12
  %188 = bitcast i32* %187 to <4 x i32>*
  %189 = load <4 x i32>, <4 x i32>* %188, align 16, !noalias !1831
  %190 = icmp sgt <4 x i32> %189, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %191 = select <4 x i1> %190, <4 x i32> %189, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %192 = icmp slt <4 x i32> %191, <i32 32767, i32 32767, i32 32767, i32 32767>
  %193 = select <4 x i1> %192, <4 x i32> %191, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %194 = trunc <4 x i32> %193 to <4 x i16>
  %195 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.562", %"struct.gemmlowp::RegisterBuffer.562"* %7, i64 0, i32 0, i64 12
  %196 = bitcast i16* %195 to <4 x i16>*
  store <4 x i16> %194, <4 x i16>* %196, align 8, !alias.scope !1828, !noalias !1827
  %197 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 16
  %198 = bitcast i32* %197 to <4 x i32>*
  %199 = load <4 x i32>, <4 x i32>* %198, align 16, !noalias !1831
  %200 = icmp sgt <4 x i32> %199, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %201 = select <4 x i1> %200, <4 x i32> %199, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %202 = icmp slt <4 x i32> %201, <i32 32767, i32 32767, i32 32767, i32 32767>
  %203 = select <4 x i1> %202, <4 x i32> %201, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %204 = trunc <4 x i32> %203 to <4 x i16>
  %205 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.562", %"struct.gemmlowp::RegisterBuffer.562"* %7, i64 0, i32 0, i64 16
  %206 = bitcast i16* %205 to <4 x i16>*
  store <4 x i16> %204, <4 x i16>* %206, align 8, !alias.scope !1828, !noalias !1827
  %207 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 20
  %208 = bitcast i32* %207 to <4 x i32>*
  %209 = load <4 x i32>, <4 x i32>* %208, align 16, !noalias !1831
  %210 = icmp sgt <4 x i32> %209, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %211 = select <4 x i1> %210, <4 x i32> %209, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %212 = icmp slt <4 x i32> %211, <i32 32767, i32 32767, i32 32767, i32 32767>
  %213 = select <4 x i1> %212, <4 x i32> %211, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %214 = trunc <4 x i32> %213 to <4 x i16>
  %215 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.562", %"struct.gemmlowp::RegisterBuffer.562"* %7, i64 0, i32 0, i64 20
  %216 = bitcast i16* %215 to <4 x i16>*
  store <4 x i16> %214, <4 x i16>* %216, align 8, !alias.scope !1828, !noalias !1827
  %217 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 24
  %218 = bitcast i32* %217 to <4 x i32>*
  %219 = load <4 x i32>, <4 x i32>* %218, align 16, !noalias !1831
  %220 = icmp sgt <4 x i32> %219, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %221 = select <4 x i1> %220, <4 x i32> %219, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %222 = icmp slt <4 x i32> %221, <i32 32767, i32 32767, i32 32767, i32 32767>
  %223 = select <4 x i1> %222, <4 x i32> %221, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %224 = trunc <4 x i32> %223 to <4 x i16>
  %225 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.562", %"struct.gemmlowp::RegisterBuffer.562"* %7, i64 0, i32 0, i64 24
  %226 = bitcast i16* %225 to <4 x i16>*
  store <4 x i16> %224, <4 x i16>* %226, align 8, !alias.scope !1828, !noalias !1827
  %227 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.303", %"struct.gemmlowp::RegisterBuffer.303"* %6, i64 0, i32 0, i64 28
  %228 = bitcast i32* %227 to <4 x i32>*
  %229 = load <4 x i32>, <4 x i32>* %228, align 16, !noalias !1831
  %230 = icmp sgt <4 x i32> %229, <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %231 = select <4 x i1> %230, <4 x i32> %229, <4 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %232 = icmp slt <4 x i32> %231, <i32 32767, i32 32767, i32 32767, i32 32767>
  %233 = select <4 x i1> %232, <4 x i32> %231, <4 x i32> <i32 32767, i32 32767, i32 32767, i32 32767>
  %234 = trunc <4 x i32> %233 to <4 x i16>
  %235 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.562", %"struct.gemmlowp::RegisterBuffer.562"* %7, i64 0, i32 0, i64 28
  %236 = bitcast i16* %235 to <4 x i16>*
  store <4 x i16> %234, <4 x i16>* %236, align 8, !alias.scope !1828, !noalias !1827
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %158) #19, !noalias !1827
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 2 %156, i8* nonnull align 8 %157, i64 64, i1 false) #19, !noalias !1824
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %157) #19, !noalias !1827
  %237 = bitcast %"struct.gemmlowp::RegisterBlock.561"* %0 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 2 %237, i8* nonnull align 2 %156, i64 64, i1 false) #19
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %156)
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %73)
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %15)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi4ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE1EEEEEvS8_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.652"*, %"struct.gemmlowp::RegisterBlock.312"* byval(%"struct.gemmlowp::RegisterBlock.312") align 8, %"class.gemmlowp::MatrixMap.489"*, i32, i32, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %8 = alloca %"struct.gemmlowp::RegisterBuffer.313", align 8
  %9 = alloca %"struct.gemmlowp::RegisterBuffer.313", align 8
  %10 = alloca [16 x i32], align 8
  %11 = alloca %"struct.gemmlowp::RegisterBlock.563", align 2
  %12 = bitcast %"struct.gemmlowp::RegisterBlock.563"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %12) #19
  %13 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %11, i64 0, i32 0, i32 0, i64 0
  %14 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %11, i64 0, i32 0, i32 0, i64 1
  %15 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %11, i64 0, i32 0, i32 0, i64 2
  %16 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %11, i64 0, i32 0, i32 0, i64 3
  %17 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %11, i64 0, i32 0, i32 0, i64 4
  %18 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %11, i64 0, i32 0, i32 0, i64 5
  %19 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %11, i64 0, i32 0, i32 0, i64 6
  %20 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %11, i64 0, i32 0, i32 0, i64 7
  %21 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %11, i64 0, i32 0, i32 0, i64 8
  %22 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %11, i64 0, i32 0, i32 0, i64 9
  %23 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %11, i64 0, i32 0, i32 0, i64 10
  %24 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %11, i64 0, i32 0, i32 0, i64 11
  %25 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %11, i64 0, i32 0, i32 0, i64 12
  %26 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %11, i64 0, i32 0, i32 0, i64 13
  %27 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %11, i64 0, i32 0, i32 0, i64 14
  %28 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %11, i64 0, i32 0, i32 0, i64 15
  %29 = bitcast %"struct.gemmlowp::RegisterBlock.312"* %1 to i8*
  %30 = bitcast %"struct.gemmlowp::RegisterBlock.563"* %11 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 2 %30, i8 -86, i64 32, i1 false)
  %31 = bitcast [16 x i32]* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %31) #19, !noalias !1832
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %31, i8 -86, i64 64, i1 false) #19, !alias.scope !1835, !noalias !1832
  %32 = bitcast %"struct.gemmlowp::RegisterBuffer.313"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %32) #19, !noalias !1838
  %33 = bitcast %"struct.gemmlowp::RegisterBuffer.313"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %33) #19, !noalias !1838
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %33, i8* nonnull align 8 %29, i64 64, i1 false)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %32, i8 -86, i64 64, i1 false) #19, !alias.scope !1839, !noalias !1838
  %34 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.652", %"struct.gemmlowp::OutputPipelineExecutor.652"* %0, i64 0, i32 0, i32 0, i32 0, i32 0
  %35 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %34, align 8, !noalias !1842
  %36 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %35, i64 0, i32 2
  %37 = load i32, i32* %36, align 4, !noalias !1842
  %38 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.652", %"struct.gemmlowp::OutputPipelineExecutor.652"* %0, i64 0, i32 0, i32 0, i32 0, i32 1
  %39 = load i32, i32* %38, align 8, !noalias !1842
  %40 = shl i32 1, %39
  %41 = sext i32 %40 to i64
  %42 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %35, i64 0, i32 0
  %43 = load i32, i32* %42, align 4, !noalias !1842
  %44 = sext i32 %43 to i64
  %45 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.652", %"struct.gemmlowp::OutputPipelineExecutor.652"* %0, i64 0, i32 0, i32 0, i32 0, i32 2
  %46 = load i32, i32* %45, align 4, !noalias !1842
  %47 = zext i32 %46 to i64
  %48 = shl nsw i64 -1, %47
  %49 = trunc i64 %48 to i32
  %50 = xor i32 %49, -1
  %51 = ashr i32 %50, 1
  %52 = icmp ne i32 %43, -2147483648
  br label %53

53:                                               ; preds = %74, %7
  %54 = phi i64 [ 0, %7 ], [ %85, %74 ]
  %55 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %8, i64 0, i32 0, i64 %54
  %56 = load i32, i32* %55, align 4, !noalias !1842
  %57 = sext i32 %56 to i64
  %58 = mul nsw i64 %57, %41
  %59 = icmp slt i64 %58, 2147483647
  %60 = select i1 %59, i64 %58, i64 2147483647
  %61 = icmp sgt i64 %60, -2147483648
  %62 = select i1 %61, i64 %60, i64 -2147483648
  %63 = trunc i64 %62 to i32
  %64 = icmp ne i32 %43, %63
  %65 = or i1 %52, %64
  br i1 %65, label %66, label %74

66:                                               ; preds = %53
  %67 = select i1 %64, i64 %44, i64 %62
  %68 = mul nsw i64 %67, %62
  %69 = icmp sgt i64 %68, -1
  %70 = select i1 %69, i64 1073741824, i64 -1073741823
  %71 = add nsw i64 %70, %68
  %72 = sdiv i64 %71, 2147483648
  %73 = trunc i64 %72 to i32
  br label %74

74:                                               ; preds = %66, %53
  %75 = phi i32 [ %73, %66 ], [ 2147483647, %53 ]
  %76 = and i32 %75, %50
  %77 = lshr i32 %75, 31
  %78 = add nsw i32 %77, %51
  %79 = ashr i32 %75, %46
  %80 = icmp sgt i32 %76, %78
  %81 = zext i1 %80 to i32
  %82 = add i32 %79, %37
  %83 = add i32 %82, %81
  %84 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %9, i64 0, i32 0, i64 %54
  store i32 %83, i32* %84, align 4, !alias.scope !1839, !noalias !1838
  %85 = add nuw nsw i64 %54, 1
  %86 = icmp eq i64 %85, 16
  br i1 %86, label %87, label %53

87:                                               ; preds = %74
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %33) #19, !noalias !1838
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %31, i8* nonnull align 8 %32, i64 64, i1 false) #19, !noalias !1832
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %32) #19, !noalias !1838
  %88 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.652", %"struct.gemmlowp::OutputPipelineExecutor.652"* %0, i64 0, i32 0, i32 1
  %89 = bitcast [16 x i32]* %10 to %"struct.gemmlowp::RegisterBlock.312"*
  call void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalES8_ii(%"struct.gemmlowp::RegisterBlock.563"* nonnull sret %11, %"struct.gemmlowp::OutputPipelineEvalImpl.654"* %88, %"struct.gemmlowp::RegisterBlock.312"* nonnull byval(%"struct.gemmlowp::RegisterBlock.312") align 8 %89, i32 %3, i32 %4) #19
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %31) #19, !noalias !1832
  %90 = load i16, i16* %13, align 2
  %91 = load i16, i16* %14, align 2
  %92 = load i16, i16* %15, align 2
  %93 = load i16, i16* %16, align 2
  %94 = load i16, i16* %17, align 2
  %95 = load i16, i16* %18, align 2
  %96 = load i16, i16* %19, align 2
  %97 = load i16, i16* %20, align 2
  %98 = load i16, i16* %21, align 2
  %99 = load i16, i16* %22, align 2
  %100 = load i16, i16* %23, align 2
  %101 = load i16, i16* %24, align 2
  %102 = load i16, i16* %25, align 2
  %103 = load i16, i16* %26, align 2
  %104 = load i16, i16* %27, align 2
  %105 = load i16, i16* %28, align 2
  %106 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %2, i64 0, i32 0
  %107 = getelementptr inbounds %"class.gemmlowp::MatrixMap.489", %"class.gemmlowp::MatrixMap.489"* %2, i64 0, i32 3
  %108 = sext i32 %6 to i64
  %109 = sext i32 %5 to i64
  %110 = load i16*, i16** %106, align 8
  %111 = load i32, i32* %107, align 8
  %112 = sext i32 %111 to i64
  %113 = mul nsw i64 %112, %109
  %114 = getelementptr inbounds i16, i16* %110, i64 %113
  %115 = getelementptr inbounds i16, i16* %114, i64 %108
  store i16 %90, i16* %115, align 2
  %116 = add nsw i64 %108, 1
  %117 = load i16*, i16** %106, align 8
  %118 = load i32, i32* %107, align 8
  %119 = sext i32 %118 to i64
  %120 = mul nsw i64 %119, %109
  %121 = getelementptr inbounds i16, i16* %117, i64 %120
  %122 = getelementptr inbounds i16, i16* %121, i64 %116
  store i16 %94, i16* %122, align 2
  %123 = add nsw i64 %108, 2
  %124 = load i16*, i16** %106, align 8
  %125 = load i32, i32* %107, align 8
  %126 = sext i32 %125 to i64
  %127 = mul nsw i64 %126, %109
  %128 = getelementptr inbounds i16, i16* %124, i64 %127
  %129 = getelementptr inbounds i16, i16* %128, i64 %123
  store i16 %98, i16* %129, align 2
  %130 = add nsw i64 %108, 3
  %131 = load i16*, i16** %106, align 8
  %132 = load i32, i32* %107, align 8
  %133 = sext i32 %132 to i64
  %134 = mul nsw i64 %133, %109
  %135 = getelementptr inbounds i16, i16* %131, i64 %134
  %136 = getelementptr inbounds i16, i16* %135, i64 %130
  store i16 %102, i16* %136, align 2
  %137 = add nsw i64 %109, 1
  %138 = load i16*, i16** %106, align 8
  %139 = load i32, i32* %107, align 8
  %140 = sext i32 %139 to i64
  %141 = mul nsw i64 %137, %140
  %142 = getelementptr inbounds i16, i16* %138, i64 %141
  %143 = getelementptr inbounds i16, i16* %142, i64 %108
  store i16 %91, i16* %143, align 2
  %144 = load i16*, i16** %106, align 8
  %145 = load i32, i32* %107, align 8
  %146 = sext i32 %145 to i64
  %147 = mul nsw i64 %137, %146
  %148 = getelementptr inbounds i16, i16* %144, i64 %147
  %149 = getelementptr inbounds i16, i16* %148, i64 %116
  store i16 %95, i16* %149, align 2
  %150 = load i16*, i16** %106, align 8
  %151 = load i32, i32* %107, align 8
  %152 = sext i32 %151 to i64
  %153 = mul nsw i64 %137, %152
  %154 = getelementptr inbounds i16, i16* %150, i64 %153
  %155 = getelementptr inbounds i16, i16* %154, i64 %123
  store i16 %99, i16* %155, align 2
  %156 = load i16*, i16** %106, align 8
  %157 = load i32, i32* %107, align 8
  %158 = sext i32 %157 to i64
  %159 = mul nsw i64 %137, %158
  %160 = getelementptr inbounds i16, i16* %156, i64 %159
  %161 = getelementptr inbounds i16, i16* %160, i64 %130
  store i16 %103, i16* %161, align 2
  %162 = add nsw i64 %109, 2
  %163 = load i16*, i16** %106, align 8
  %164 = load i32, i32* %107, align 8
  %165 = sext i32 %164 to i64
  %166 = mul nsw i64 %162, %165
  %167 = getelementptr inbounds i16, i16* %163, i64 %166
  %168 = getelementptr inbounds i16, i16* %167, i64 %108
  store i16 %92, i16* %168, align 2
  %169 = load i16*, i16** %106, align 8
  %170 = load i32, i32* %107, align 8
  %171 = sext i32 %170 to i64
  %172 = mul nsw i64 %162, %171
  %173 = getelementptr inbounds i16, i16* %169, i64 %172
  %174 = getelementptr inbounds i16, i16* %173, i64 %116
  store i16 %96, i16* %174, align 2
  %175 = load i16*, i16** %106, align 8
  %176 = load i32, i32* %107, align 8
  %177 = sext i32 %176 to i64
  %178 = mul nsw i64 %162, %177
  %179 = getelementptr inbounds i16, i16* %175, i64 %178
  %180 = getelementptr inbounds i16, i16* %179, i64 %123
  store i16 %100, i16* %180, align 2
  %181 = load i16*, i16** %106, align 8
  %182 = load i32, i32* %107, align 8
  %183 = sext i32 %182 to i64
  %184 = mul nsw i64 %162, %183
  %185 = getelementptr inbounds i16, i16* %181, i64 %184
  %186 = getelementptr inbounds i16, i16* %185, i64 %130
  store i16 %104, i16* %186, align 2
  %187 = add nsw i64 %109, 3
  %188 = load i16*, i16** %106, align 8
  %189 = load i32, i32* %107, align 8
  %190 = sext i32 %189 to i64
  %191 = mul nsw i64 %187, %190
  %192 = getelementptr inbounds i16, i16* %188, i64 %191
  %193 = getelementptr inbounds i16, i16* %192, i64 %108
  store i16 %93, i16* %193, align 2
  %194 = load i16*, i16** %106, align 8
  %195 = load i32, i32* %107, align 8
  %196 = sext i32 %195 to i64
  %197 = mul nsw i64 %187, %196
  %198 = getelementptr inbounds i16, i16* %194, i64 %197
  %199 = getelementptr inbounds i16, i16* %198, i64 %116
  store i16 %97, i16* %199, align 2
  %200 = load i16*, i16** %106, align 8
  %201 = load i32, i32* %107, align 8
  %202 = sext i32 %201 to i64
  %203 = mul nsw i64 %187, %202
  %204 = getelementptr inbounds i16, i16* %200, i64 %203
  %205 = getelementptr inbounds i16, i16* %204, i64 %123
  store i16 %101, i16* %205, align 2
  %206 = load i16*, i16** %106, align 8
  %207 = load i32, i32* %107, align 8
  %208 = sext i32 %207 to i64
  %209 = mul nsw i64 %187, %208
  %210 = getelementptr inbounds i16, i16* %206, i64 %209
  %211 = getelementptr inbounds i16, i16* %210, i64 %130
  store i16 %105, i16* %211, align 2
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %12) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalES8_ii(%"struct.gemmlowp::RegisterBlock.563"* noalias sret, %"struct.gemmlowp::OutputPipelineEvalImpl.654"*, %"struct.gemmlowp::RegisterBlock.312"* byval(%"struct.gemmlowp::RegisterBlock.312") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %6 = bitcast %"struct.gemmlowp::RegisterBlock.312"* %2 to <8 x i32>*
  %7 = load <8 x i32>, <8 x i32>* %6, align 8
  %8 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 8
  %9 = load i32, i32* %8, align 8
  %10 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 9
  %11 = load i32, i32* %10, align 4
  %12 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 10
  %13 = load i32, i32* %12, align 8
  %14 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 11
  %15 = load i32, i32* %14, align 4
  %16 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 12
  %17 = load i32, i32* %16, align 8
  %18 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 13
  %19 = load i32, i32* %18, align 4
  %20 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 14
  %21 = load i32, i32* %20, align 8
  %22 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %2, i64 0, i32 0, i32 0, i64 15
  %23 = load i32, i32* %22, align 4
  %24 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.654", %"struct.gemmlowp::OutputPipelineEvalImpl.654"* %1, i64 0, i32 0, i32 0, i32 0
  %25 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %24, align 8, !noalias !1843
  %26 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %25, i64 0, i32 0
  %27 = load i32, i32* %26, align 4, !noalias !1843
  %28 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %25, i64 0, i32 1
  %29 = load i32, i32* %28, align 4, !noalias !1843
  %30 = insertelement <8 x i32> undef, i32 %27, i32 0
  %31 = shufflevector <8 x i32> %30, <8 x i32> undef, <8 x i32> zeroinitializer
  %32 = icmp slt <8 x i32> %7, %31
  %33 = select <8 x i1> %32, <8 x i32> %31, <8 x i32> %7
  %34 = insertelement <8 x i32> undef, i32 %29, i32 0
  %35 = shufflevector <8 x i32> %34, <8 x i32> undef, <8 x i32> zeroinitializer
  %36 = icmp slt <8 x i32> %35, %33
  %37 = select <8 x i1> %36, <8 x i32> %35, <8 x i32> %33
  %38 = icmp slt i32 %9, %27
  %39 = select i1 %38, i32 %27, i32 %9
  %40 = icmp slt i32 %29, %39
  %41 = select i1 %40, i32 %29, i32 %39
  %42 = icmp slt i32 %11, %27
  %43 = select i1 %42, i32 %27, i32 %11
  %44 = icmp slt i32 %29, %43
  %45 = select i1 %44, i32 %29, i32 %43
  %46 = icmp slt i32 %13, %27
  %47 = select i1 %46, i32 %27, i32 %13
  %48 = icmp slt i32 %29, %47
  %49 = select i1 %48, i32 %29, i32 %47
  %50 = icmp slt i32 %15, %27
  %51 = select i1 %50, i32 %27, i32 %15
  %52 = icmp slt i32 %29, %51
  %53 = select i1 %52, i32 %29, i32 %51
  %54 = icmp slt i32 %17, %27
  %55 = select i1 %54, i32 %27, i32 %17
  %56 = icmp slt i32 %29, %55
  %57 = select i1 %56, i32 %29, i32 %55
  %58 = icmp slt i32 %19, %27
  %59 = select i1 %58, i32 %27, i32 %19
  %60 = icmp slt i32 %29, %59
  %61 = select i1 %60, i32 %29, i32 %59
  %62 = icmp slt i32 %21, %27
  %63 = select i1 %62, i32 %27, i32 %21
  %64 = icmp slt i32 %29, %63
  %65 = select i1 %64, i32 %29, i32 %63
  %66 = icmp slt i32 %23, %27
  %67 = select i1 %66, i32 %27, i32 %23
  %68 = icmp slt i32 %29, %67
  %69 = select i1 %68, i32 %29, i32 %67
  %70 = icmp sgt <8 x i32> %37, <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %71 = select <8 x i1> %70, <8 x i32> %37, <8 x i32> <i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768, i32 -32768>
  %72 = icmp slt <8 x i32> %71, <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>
  %73 = select <8 x i1> %72, <8 x i32> %71, <8 x i32> <i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767, i32 32767>
  %74 = trunc <8 x i32> %73 to <8 x i16>
  %75 = icmp sgt i32 %41, -32768
  %76 = select i1 %75, i32 %41, i32 -32768
  %77 = icmp slt i32 %76, 32767
  %78 = select i1 %77, i32 %76, i32 32767
  %79 = trunc i32 %78 to i16
  %80 = icmp sgt i32 %45, -32768
  %81 = select i1 %80, i32 %45, i32 -32768
  %82 = icmp slt i32 %81, 32767
  %83 = select i1 %82, i32 %81, i32 32767
  %84 = trunc i32 %83 to i16
  %85 = icmp sgt i32 %49, -32768
  %86 = select i1 %85, i32 %49, i32 -32768
  %87 = icmp slt i32 %86, 32767
  %88 = select i1 %87, i32 %86, i32 32767
  %89 = trunc i32 %88 to i16
  %90 = icmp sgt i32 %53, -32768
  %91 = select i1 %90, i32 %53, i32 -32768
  %92 = icmp slt i32 %91, 32767
  %93 = select i1 %92, i32 %91, i32 32767
  %94 = trunc i32 %93 to i16
  %95 = icmp sgt i32 %57, -32768
  %96 = select i1 %95, i32 %57, i32 -32768
  %97 = icmp slt i32 %96, 32767
  %98 = select i1 %97, i32 %96, i32 32767
  %99 = icmp sgt i32 %61, -32768
  %100 = select i1 %99, i32 %61, i32 -32768
  %101 = icmp slt i32 %100, 32767
  %102 = select i1 %101, i32 %100, i32 32767
  %103 = shl nsw i32 %102, 16
  %104 = and i32 %98, 65535
  %105 = or i32 %103, %104
  %106 = zext i32 %105 to i64
  %107 = icmp sgt i32 %65, -32768
  %108 = select i1 %107, i32 %65, i32 -32768
  %109 = icmp slt i32 %108, 32767
  %110 = select i1 %109, i32 %108, i32 32767
  %111 = and i32 %110, 65535
  %112 = zext i32 %111 to i64
  %113 = shl nuw nsw i64 %112, 32
  %114 = icmp sgt i32 %69, -32768
  %115 = select i1 %114, i32 %69, i32 -32768
  %116 = icmp slt i32 %115, 32767
  %117 = select i1 %116, i32 %115, i32 32767
  %118 = zext i32 %117 to i64
  %119 = shl i64 %118, 48
  %120 = or i64 %119, %106
  %121 = or i64 %120, %113
  %122 = bitcast %"struct.gemmlowp::RegisterBlock.563"* %0 to <8 x i16>*
  store <8 x i16> %74, <8 x i16>* %122, align 2, !alias.scope !1848
  %123 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %0, i64 0, i32 0, i32 0, i64 8
  store i16 %79, i16* %123, align 2, !alias.scope !1848
  %124 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %0, i64 0, i32 0, i32 0, i64 9
  store i16 %84, i16* %124, align 2, !alias.scope !1848
  %125 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %0, i64 0, i32 0, i32 0, i64 10
  store i16 %89, i16* %125, align 2, !alias.scope !1848
  %126 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %0, i64 0, i32 0, i32 0, i64 11
  store i16 %94, i16* %126, align 2, !alias.scope !1848
  %127 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %0, i64 0, i32 0, i32 0, i64 12
  %128 = bitcast i16* %127 to i64*
  store i64 %121, i64* %128, align 2, !alias.scope !1848
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalES8_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.639"*, %"struct.gemmlowp::RegisterBlock.304"* byval(%"struct.gemmlowp::RegisterBlock.304") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %5 = alloca %"struct.gemmlowp::RegisterBuffer.305", align 8
  %6 = alloca %"struct.gemmlowp::RegisterBuffer.305", align 16
  %7 = alloca %"struct.gemmlowp::RegisterBlock.304", align 16
  %8 = bitcast %"struct.gemmlowp::RegisterBlock.304"* %1 to i8*
  %9 = bitcast %"struct.gemmlowp::RegisterBuffer.305"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %9) #19, !noalias !1851
  %10 = bitcast %"struct.gemmlowp::RegisterBuffer.305"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %10) #19, !noalias !1851
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %10, i8* nonnull align 8 %8, i64 32, i1 false)
  %11 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.639", %"struct.gemmlowp::OutputPipelineEvalImpl.639"* %0, i64 0, i32 0, i32 0, i32 0
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 32, i1 false) #19, !alias.scope !1854, !noalias !1851
  %12 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %11, align 8, !noalias !1857
  %13 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %12, i64 0, i32 2
  %14 = load i32, i32* %13, align 4, !noalias !1857
  %15 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.639", %"struct.gemmlowp::OutputPipelineEvalImpl.639"* %0, i64 0, i32 0, i32 0, i32 1
  %16 = load i32, i32* %15, align 8, !noalias !1857
  %17 = shl i32 1, %16
  %18 = sext i32 %17 to i64
  %19 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %12, i64 0, i32 0
  %20 = load i32, i32* %19, align 4, !noalias !1857
  %21 = sext i32 %20 to i64
  %22 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.639", %"struct.gemmlowp::OutputPipelineEvalImpl.639"* %0, i64 0, i32 0, i32 0, i32 2
  %23 = load i32, i32* %22, align 4, !noalias !1857
  %24 = zext i32 %23 to i64
  %25 = shl nsw i64 -1, %24
  %26 = trunc i64 %25 to i32
  %27 = xor i32 %26, -1
  %28 = ashr i32 %27, 1
  %29 = icmp ne i32 %20, -2147483648
  br label %30

30:                                               ; preds = %51, %4
  %31 = phi i64 [ 0, %4 ], [ %62, %51 ]
  %32 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.305", %"struct.gemmlowp::RegisterBuffer.305"* %5, i64 0, i32 0, i64 %31
  %33 = load i32, i32* %32, align 4, !noalias !1857
  %34 = sext i32 %33 to i64
  %35 = mul nsw i64 %34, %18
  %36 = icmp slt i64 %35, 2147483647
  %37 = select i1 %36, i64 %35, i64 2147483647
  %38 = icmp sgt i64 %37, -2147483648
  %39 = select i1 %38, i64 %37, i64 -2147483648
  %40 = trunc i64 %39 to i32
  %41 = icmp ne i32 %20, %40
  %42 = or i1 %29, %41
  br i1 %42, label %43, label %51

43:                                               ; preds = %30
  %44 = select i1 %41, i64 %21, i64 %39
  %45 = mul nsw i64 %44, %39
  %46 = icmp sgt i64 %45, -1
  %47 = select i1 %46, i64 1073741824, i64 -1073741823
  %48 = add nsw i64 %47, %45
  %49 = sdiv i64 %48, 2147483648
  %50 = trunc i64 %49 to i32
  br label %51

51:                                               ; preds = %43, %30
  %52 = phi i32 [ %50, %43 ], [ 2147483647, %30 ]
  %53 = and i32 %52, %27
  %54 = lshr i32 %52, 31
  %55 = add nsw i32 %54, %28
  %56 = ashr i32 %52, %23
  %57 = icmp sgt i32 %53, %55
  %58 = zext i1 %57 to i32
  %59 = add i32 %56, %14
  %60 = add i32 %59, %58
  %61 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.305", %"struct.gemmlowp::RegisterBuffer.305"* %6, i64 0, i32 0, i64 %31
  store i32 %60, i32* %61, align 4, !alias.scope !1854, !noalias !1851
  %62 = add nuw nsw i64 %31, 1
  %63 = icmp eq i64 %62, 8
  br i1 %63, label %64, label %30

64:                                               ; preds = %51
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %10) #19, !noalias !1851
  %65 = bitcast %"struct.gemmlowp::RegisterBuffer.305"* %6 to <4 x i32>*
  %66 = load <4 x i32>, <4 x i32>* %65, align 16
  %67 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.305", %"struct.gemmlowp::RegisterBuffer.305"* %6, i64 0, i32 0, i64 4
  %68 = bitcast i32* %67 to <4 x i32>*
  %69 = load <4 x i32>, <4 x i32>* %68, align 16
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %9) #19, !noalias !1851
  %70 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.639", %"struct.gemmlowp::OutputPipelineEvalImpl.639"* %0, i64 0, i32 1
  %71 = bitcast %"struct.gemmlowp::RegisterBlock.304"* %7 to <4 x i32>*
  store <4 x i32> %66, <4 x i32>* %71, align 16
  %72 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %7, i64 0, i32 0, i32 0, i64 4
  %73 = bitcast i32* %72 to <4 x i32>*
  store <4 x i32> %69, <4 x i32>* %73, align 16
  %74 = tail call { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalES8_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.640"* %70, %"struct.gemmlowp::RegisterBlock.304"* nonnull byval(%"struct.gemmlowp::RegisterBlock.304") align 8 %7, i32 %2, i32 %3)
  ret { i64, i64 } %74
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalES8_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.640"*, %"struct.gemmlowp::RegisterBlock.304"* byval(%"struct.gemmlowp::RegisterBlock.304") align 8, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %5 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %1, i64 0, i32 0, i32 0, i64 0
  %6 = load i32, i32* %5, align 8
  %7 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %1, i64 0, i32 0, i32 0, i64 1
  %8 = load i32, i32* %7, align 4
  %9 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %1, i64 0, i32 0, i32 0, i64 2
  %10 = load i32, i32* %9, align 8
  %11 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %1, i64 0, i32 0, i32 0, i64 3
  %12 = load i32, i32* %11, align 4
  %13 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %1, i64 0, i32 0, i32 0, i64 4
  %14 = load i32, i32* %13, align 8
  %15 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %1, i64 0, i32 0, i32 0, i64 5
  %16 = load i32, i32* %15, align 4
  %17 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %1, i64 0, i32 0, i32 0, i64 6
  %18 = load i32, i32* %17, align 8
  %19 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %1, i64 0, i32 0, i32 0, i64 7
  %20 = load i32, i32* %19, align 4
  %21 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineEvalImpl.640", %"struct.gemmlowp::OutputPipelineEvalImpl.640"* %0, i64 0, i32 0, i32 0, i32 0
  %22 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %21, align 8, !noalias !1858
  %23 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %22, i64 0, i32 0
  %24 = load i32, i32* %23, align 4, !noalias !1858
  %25 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %22, i64 0, i32 1
  %26 = load i32, i32* %25, align 4, !noalias !1858
  %27 = icmp slt i32 %6, %24
  %28 = select i1 %27, i32 %24, i32 %6
  %29 = icmp slt i32 %26, %28
  %30 = select i1 %29, i32 %26, i32 %28
  %31 = icmp slt i32 %8, %24
  %32 = select i1 %31, i32 %24, i32 %8
  %33 = icmp slt i32 %26, %32
  %34 = select i1 %33, i32 %26, i32 %32
  %35 = icmp slt i32 %10, %24
  %36 = select i1 %35, i32 %24, i32 %10
  %37 = icmp slt i32 %26, %36
  %38 = select i1 %37, i32 %26, i32 %36
  %39 = icmp slt i32 %12, %24
  %40 = select i1 %39, i32 %24, i32 %12
  %41 = icmp slt i32 %26, %40
  %42 = select i1 %41, i32 %26, i32 %40
  %43 = icmp slt i32 %14, %24
  %44 = select i1 %43, i32 %24, i32 %14
  %45 = icmp slt i32 %26, %44
  %46 = select i1 %45, i32 %26, i32 %44
  %47 = icmp slt i32 %16, %24
  %48 = select i1 %47, i32 %24, i32 %16
  %49 = icmp slt i32 %26, %48
  %50 = select i1 %49, i32 %26, i32 %48
  %51 = icmp slt i32 %18, %24
  %52 = select i1 %51, i32 %24, i32 %18
  %53 = icmp slt i32 %26, %52
  %54 = select i1 %53, i32 %26, i32 %52
  %55 = icmp slt i32 %20, %24
  %56 = select i1 %55, i32 %24, i32 %20
  %57 = icmp slt i32 %26, %56
  %58 = select i1 %57, i32 %26, i32 %56
  %59 = icmp sgt i32 %30, -32768
  %60 = select i1 %59, i32 %30, i32 -32768
  %61 = icmp slt i32 %60, 32767
  %62 = select i1 %61, i32 %60, i32 32767
  %63 = icmp sgt i32 %34, -32768
  %64 = select i1 %63, i32 %34, i32 -32768
  %65 = icmp slt i32 %64, 32767
  %66 = select i1 %65, i32 %64, i32 32767
  %67 = icmp sgt i32 %38, -32768
  %68 = select i1 %67, i32 %38, i32 -32768
  %69 = icmp slt i32 %68, 32767
  %70 = select i1 %69, i32 %68, i32 32767
  %71 = icmp sgt i32 %42, -32768
  %72 = select i1 %71, i32 %42, i32 -32768
  %73 = icmp slt i32 %72, 32767
  %74 = select i1 %73, i32 %72, i32 32767
  %75 = icmp sgt i32 %46, -32768
  %76 = select i1 %75, i32 %46, i32 -32768
  %77 = icmp slt i32 %76, 32767
  %78 = select i1 %77, i32 %76, i32 32767
  %79 = icmp sgt i32 %50, -32768
  %80 = select i1 %79, i32 %50, i32 -32768
  %81 = icmp slt i32 %80, 32767
  %82 = select i1 %81, i32 %80, i32 32767
  %83 = shl nsw i32 %82, 16
  %84 = and i32 %78, 65535
  %85 = or i32 %83, %84
  %86 = zext i32 %85 to i64
  %87 = icmp sgt i32 %54, -32768
  %88 = select i1 %87, i32 %54, i32 -32768
  %89 = icmp slt i32 %88, 32767
  %90 = select i1 %89, i32 %88, i32 32767
  %91 = and i32 %90, 65535
  %92 = zext i32 %91 to i64
  %93 = shl nuw nsw i64 %92, 32
  %94 = icmp sgt i32 %58, -32768
  %95 = select i1 %94, i32 %58, i32 -32768
  %96 = icmp slt i32 %95, 32767
  %97 = select i1 %96, i32 %95, i32 32767
  %98 = zext i32 %97 to i64
  %99 = shl i64 %98, 48
  %100 = or i64 %99, %86
  %101 = or i64 %100, %93
  %102 = zext i32 %74 to i64
  %103 = shl i64 %102, 48
  %104 = and i32 %70, 65535
  %105 = zext i32 %104 to i64
  %106 = shl nuw nsw i64 %105, 32
  %107 = shl nsw i32 %66, 16
  %108 = and i32 %62, 65535
  %109 = or i32 %107, %108
  %110 = zext i32 %109 to i64
  %111 = or i64 %103, %110
  %112 = or i64 %111, %106
  %113 = insertvalue { i64, i64 } undef, i64 %112, 0
  %114 = insertvalue { i64, i64 } %113, i64 %101, 1
  ret { i64, i64 } %114
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED2Ev(%"struct.gemmlowp::GemmWithPackedRhsTask.623"*) unnamed_addr #4 comdat align 2 {
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED0Ev(%"struct.gemmlowp::GemmWithPackedRhsTask.623"*) unnamed_addr #4 comdat align 2 {
  %2 = bitcast %"struct.gemmlowp::GemmWithPackedRhsTask.623"* %0 to i8*
  tail call void @_ZdlPv(i8* %2) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_1ENS_9VectorDupIKiLNS_11VectorShapeE1EEENSE_ISF_LSG_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEE3RunEv(%"struct.gemmlowp::GemmWithPackedRhsTask.623"*) unnamed_addr #1 comdat align 2 {
  %2 = alloca %"class.gemmlowp::SideMap", align 8
  %3 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %4 = alloca %"class.gemmlowp::ComputeImpl", align 8
  %5 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %6 = alloca %"class.gemmlowp::PackedResult", align 8
  %7 = alloca %"struct.gemmlowp::MatrixBlockBounds", align 4
  %8 = alloca %"class.gemmlowp::VectorDup.194", align 4
  %9 = alloca %"class.gemmlowp::VectorDup", align 4
  %10 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.623", %"struct.gemmlowp::GemmWithPackedRhsTask.623"* %0, i64 0, i32 6, i32 2
  %11 = load i32, i32* %10, align 8
  %12 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.623", %"struct.gemmlowp::GemmWithPackedRhsTask.623"* %0, i64 0, i32 6, i32 3
  %13 = load i32, i32* %12, align 4
  %14 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.623", %"struct.gemmlowp::GemmWithPackedRhsTask.623"* %0, i64 0, i32 3, i32 2
  %15 = load i32, i32* %14, align 4
  %16 = bitcast %"class.gemmlowp::PackedSideBlock"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %16) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %16, i8 -86, i64 80, i1 false)
  %17 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.623", %"struct.gemmlowp::GemmWithPackedRhsTask.623"* %0, i64 0, i32 0, i32 1
  %18 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %19 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.623", %"struct.gemmlowp::GemmWithPackedRhsTask.623"* %0, i64 0, i32 9
  %20 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %21 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %18, %"class.gemmlowp::Allocator"** %21, align 8
  %22 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 4
  store i32 0, i32* %22, align 8
  %23 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 0
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 0
  store i32 %24, i32* %25, align 8
  %26 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 3
  %27 = load i32, i32* %26, align 4
  %28 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 2
  store i32 %27, i32* %28, align 8
  %29 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 2
  %30 = load i32, i32* %29, align 4
  %31 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 1
  store i32 %30, i32* %31, align 4
  %32 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 5
  %33 = load i32, i32* %32, align 4
  %34 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 3
  store i32 %33, i32* %34, align 4
  %35 = mul nsw i32 %33, %27
  %36 = sext i32 %35 to i64
  %37 = add nsw i64 %36, 63
  %38 = and i64 %37, -64
  %39 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 4
  %40 = load i64, i64* %39, align 8, !noalias !1863
  %41 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 3
  %42 = load i64, i64* %41, align 8, !noalias !1863
  %43 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 5, i64 %42
  store i64 %40, i64* %43, align 8, !noalias !1863
  %44 = trunc i64 %42 to i8
  %45 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 6
  %46 = load i64, i64* %45, align 8, !noalias !1863
  %47 = bitcast i64* %41 to <2 x i64>*
  %48 = load <2 x i64>, <2 x i64>* %47, align 8, !noalias !1863
  %49 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %38, i32 1
  %50 = add <2 x i64> %48, %49
  %51 = bitcast i64* %41 to <2 x i64>*
  store <2 x i64> %50, <2 x i64>* %51, align 8, !noalias !1863
  %52 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 0
  store i8 %44, i8* %52, align 8
  %53 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %53, i8 -86, i64 7, i1 false) #19
  %54 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 2
  store i64 %46, i64* %54, align 8
  %55 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 3
  store i8 0, i8* %55, align 8
  %56 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %21, align 8
  %57 = load i32, i32* %28, align 8
  %58 = sext i32 %57 to i64
  %59 = shl nsw i64 %58, 2
  %60 = add nsw i64 %59, 63
  %61 = and i64 %60, -64
  %62 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 4
  %63 = load i64, i64* %62, align 8, !noalias !1866
  %64 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 3
  %65 = load i64, i64* %64, align 8, !noalias !1866
  %66 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 5, i64 %65
  store i64 %63, i64* %66, align 8, !noalias !1866
  %67 = trunc i64 %65 to i8
  %68 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 6
  %69 = load i64, i64* %68, align 8, !noalias !1866
  %70 = bitcast i64* %64 to <2 x i64>*
  %71 = load <2 x i64>, <2 x i64>* %70, align 8, !noalias !1866
  %72 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %61, i32 1
  %73 = add <2 x i64> %71, %72
  %74 = bitcast i64* %64 to <2 x i64>*
  store <2 x i64> %73, <2 x i64>* %74, align 8, !noalias !1866
  %75 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 0
  store i8 %67, i8* %75, align 8
  %76 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %76, i8 -86, i64 7, i1 false) #19
  %77 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 2
  store i64 %69, i64* %77, align 8
  %78 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 3
  store i8 5, i8* %78, align 8
  %79 = bitcast %"class.gemmlowp::PackedResult"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %79) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %79, i8 -86, i64 32, i1 false)
  %80 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %81 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %82 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 0
  store %"class.gemmlowp::Allocator"* %80, %"class.gemmlowp::Allocator"** %82, align 8
  %83 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 2
  store %"struct.gemmlowp::BlockParams"* %81, %"struct.gemmlowp::BlockParams"** %83, align 8
  %84 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %81, i64 0, i32 3
  %85 = load i32, i32* %84, align 4
  %86 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %81, i64 0, i32 4
  %87 = load i32, i32* %86, align 4
  %88 = mul nsw i32 %87, %85
  %89 = sext i32 %88 to i64
  %90 = shl nsw i64 %89, 2
  %91 = add nsw i64 %90, 63
  %92 = and i64 %91, -64
  %93 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 4
  %94 = load i64, i64* %93, align 8, !noalias !1869
  %95 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 3
  %96 = load i64, i64* %95, align 8, !noalias !1869
  %97 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 5, i64 %96
  store i64 %94, i64* %97, align 8, !noalias !1869
  %98 = trunc i64 %96 to i8
  %99 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 6
  %100 = load i64, i64* %99, align 8, !noalias !1869
  %101 = bitcast i64* %95 to <2 x i64>*
  %102 = load <2 x i64>, <2 x i64>* %101, align 8, !noalias !1869
  %103 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %92, i32 1
  %104 = add <2 x i64> %102, %103
  %105 = bitcast i64* %95 to <2 x i64>*
  store <2 x i64> %104, <2 x i64>* %105, align 8, !noalias !1869
  %106 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 0
  store i8 %98, i8* %106, align 8
  %107 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %107, i8 -86, i64 7, i1 false) #19
  %108 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 2
  store i64 %100, i64* %108, align 8
  %109 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 3
  store i8 5, i8* %109, align 8
  %110 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  tail call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %110)
  %111 = icmp sgt i32 %13, 0
  br i1 %111, label %112, label %156

112:                                              ; preds = %1
  %113 = icmp sgt i32 %11, 0
  %114 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.623", %"struct.gemmlowp::GemmWithPackedRhsTask.623"* %0, i64 0, i32 3, i32 0
  %115 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.623", %"struct.gemmlowp::GemmWithPackedRhsTask.623"* %0, i64 0, i32 3, i32 3
  %116 = bitcast %"class.gemmlowp::SideMap"* %2 to i8*
  %117 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 1
  %118 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 2
  %119 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 3
  %120 = bitcast %"class.gemmlowp::SideMap"* %2 to i64*
  %121 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %3 to i8*
  %122 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %3, i64 0, i32 0
  %123 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %3, i64 0, i32 1
  %124 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.623", %"struct.gemmlowp::GemmWithPackedRhsTask.623"* %0, i64 0, i32 2
  %125 = bitcast %"struct.gemmlowp::KernelBase"** %124 to i64*
  %126 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.623", %"struct.gemmlowp::GemmWithPackedRhsTask.623"* %0, i64 0, i32 4
  %127 = bitcast %"class.gemmlowp::ComputeImpl"* %4 to i8*
  %128 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 1
  %129 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 2
  %130 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 3
  %131 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 4
  %132 = bitcast %"class.gemmlowp::ComputeImpl"* %4 to i64*
  %133 = add i32 %15, 15
  %134 = and i32 %133, -16
  %135 = icmp sgt i32 %134, 0
  %136 = bitcast %"struct.gemmlowp::MatrixBlockBounds"* %7 to i8*
  %137 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 0
  %138 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 1
  %139 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 2
  %140 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 3
  %141 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.623", %"struct.gemmlowp::GemmWithPackedRhsTask.623"* %0, i64 0, i32 6, i32 0
  %142 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.623", %"struct.gemmlowp::GemmWithPackedRhsTask.623"* %0, i64 0, i32 6, i32 1
  %143 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.623", %"struct.gemmlowp::GemmWithPackedRhsTask.623"* %0, i64 0, i32 5
  %144 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.623", %"struct.gemmlowp::GemmWithPackedRhsTask.623"* %0, i64 0, i32 4, i32 1
  %145 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.623", %"struct.gemmlowp::GemmWithPackedRhsTask.623"* %0, i64 0, i32 4, i32 3, i32 0
  %146 = bitcast %"class.gemmlowp::VectorDup.194"* %8 to i8*
  %147 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.623", %"struct.gemmlowp::GemmWithPackedRhsTask.623"* %0, i64 0, i32 7
  %148 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %8, i64 0, i32 0
  %149 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %8, i64 0, i32 1
  %150 = bitcast %"class.gemmlowp::VectorDup"* %9 to i8*
  %151 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.623", %"struct.gemmlowp::GemmWithPackedRhsTask.623"* %0, i64 0, i32 8
  %152 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %9, i64 0, i32 0
  %153 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %9, i64 0, i32 1
  %154 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.623", %"struct.gemmlowp::GemmWithPackedRhsTask.623"* %0, i64 0, i32 10
  %155 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  br label %164

156:                                              ; preds = %178, %1
  %157 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %158 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 0
  store i8 0, i8* %158, align 8
  %159 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 6
  %160 = load i64, i64* %159, align 8
  %161 = add i64 %160, 1
  store i64 %161, i64* %159, align 8
  %162 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 3
  %163 = bitcast i64* %162 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %163, i8 0, i64 16, i1 false) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %79) #19
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %16) #19
  ret void

164:                                              ; preds = %112, %178
  %165 = phi %"struct.gemmlowp::BlockParams"* [ %155, %112 ], [ %180, %178 ]
  %166 = phi i32 [ 0, %112 ], [ %181, %178 ]
  %167 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %165, i64 0, i32 4
  %168 = sub nsw i32 %13, %166
  %169 = load i32, i32* %167, align 4
  %170 = icmp slt i32 %168, %169
  %171 = select i1 %170, i32 %168, i32 %169
  br i1 %113, label %172, label %178

172:                                              ; preds = %164
  %173 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %165, i64 0, i32 3
  %174 = load i32, i32* %173, align 4
  br label %183

175:                                              ; preds = %255
  %176 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %287, i64 0, i32 4
  %177 = load i32, i32* %176, align 4
  br label %178

178:                                              ; preds = %175, %164
  %179 = phi i32 [ %169, %164 ], [ %177, %175 ]
  %180 = phi %"struct.gemmlowp::BlockParams"* [ %165, %164 ], [ %287, %175 ]
  %181 = add nsw i32 %179, %166
  %182 = icmp sgt i32 %13, %181
  br i1 %182, label %164, label %156

183:                                              ; preds = %172, %255
  %184 = phi i32 [ %289, %255 ], [ %174, %172 ]
  %185 = phi i32 [ %290, %255 ], [ 0, %172 ]
  %186 = sub nsw i32 %11, %185
  %187 = icmp slt i32 %186, %184
  %188 = select i1 %187, i32 %186, i32 %184
  %189 = load i8*, i8** %114, align 8, !noalias !1872
  %190 = load i32, i32* %115, align 8, !noalias !1872
  %191 = mul nsw i32 %190, %185
  %192 = sext i32 %191 to i64
  %193 = getelementptr inbounds i8, i8* %189, i64 %192
  %194 = ptrtoint i8* %193 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %116) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %116, i8 -86, i64 24, i1 false) #19
  store i64 %194, i64* %120, align 8
  store i32 %188, i32* %117, align 8
  store i32 %15, i32* %118, align 4
  store i32 %190, i32* %119, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %121) #19
  store %"class.gemmlowp::PackedSideBlock"* %5, %"class.gemmlowp::PackedSideBlock"** %122, align 8
  store %"class.gemmlowp::SideMap"* %2, %"class.gemmlowp::SideMap"** %123, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %3) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %121) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %116) #19
  %195 = load i64, i64* %125, align 8
  %196 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %127) #19
  store i64 %195, i64* %132, align 8
  store %"struct.gemmlowp::BlockParams"* %196, %"struct.gemmlowp::BlockParams"** %128, align 8
  store %"class.gemmlowp::PackedResult"* %6, %"class.gemmlowp::PackedResult"** %129, align 8
  store %"class.gemmlowp::PackedSideBlock"* %5, %"class.gemmlowp::PackedSideBlock"** %130, align 8
  store %"class.gemmlowp::PackedSideBlock"* %126, %"class.gemmlowp::PackedSideBlock"** %131, align 8
  br i1 %135, label %197, label %255

197:                                              ; preds = %183, %215
  %198 = phi %"struct.gemmlowp::BlockParams"* [ %217, %215 ], [ %196, %183 ]
  %199 = phi %"struct.gemmlowp::BlockParams"* [ %218, %215 ], [ %196, %183 ]
  %200 = phi i32 [ %219, %215 ], [ 0, %183 ]
  %201 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 2
  %202 = sub nsw i32 %134, %200
  %203 = load i32, i32* %201, align 4
  %204 = icmp slt i32 %202, %203
  %205 = select i1 %204, i32 %202, i32 %203
  %206 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 3
  %207 = load i32, i32* %206, align 4
  %208 = icmp sgt i32 %207, 0
  br i1 %208, label %209, label %215

209:                                              ; preds = %197
  %210 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 0
  %211 = load i32, i32* %210, align 4
  br label %221

212:                                              ; preds = %247
  %213 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 2
  %214 = load i32, i32* %213, align 4
  br label %215

215:                                              ; preds = %212, %197
  %216 = phi i32 [ %203, %197 ], [ %214, %212 ]
  %217 = phi %"struct.gemmlowp::BlockParams"* [ %198, %197 ], [ %248, %212 ]
  %218 = phi %"struct.gemmlowp::BlockParams"* [ %199, %197 ], [ %248, %212 ]
  %219 = add nsw i32 %216, %200
  %220 = icmp sgt i32 %134, %219
  br i1 %220, label %197, label %255

221:                                              ; preds = %247, %209
  %222 = phi %"struct.gemmlowp::BlockParams"* [ %248, %247 ], [ %198, %209 ]
  %223 = phi i32 [ %250, %247 ], [ %211, %209 ]
  %224 = phi i32 [ %253, %247 ], [ %207, %209 ]
  %225 = phi %"struct.gemmlowp::BlockParams"* [ %248, %247 ], [ %199, %209 ]
  %226 = phi i32 [ %251, %247 ], [ 0, %209 ]
  %227 = sub nsw i32 %224, %226
  %228 = icmp slt i32 %227, %223
  %229 = select i1 %228, i32 %227, i32 %223
  %230 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %225, i64 0, i32 4
  %231 = load i32, i32* %230, align 4
  %232 = icmp sgt i32 %231, 0
  br i1 %232, label %233, label %247

233:                                              ; preds = %221
  %234 = icmp sgt i32 %229, 0
  br label %235

235:                                              ; preds = %237, %233
  %236 = phi i32 [ 0, %233 ], [ %238, %237 ]
  br i1 %234, label %240, label %237

237:                                              ; preds = %240, %235
  %238 = add nuw nsw i32 %236, 4
  %239 = icmp slt i32 %238, %231
  br i1 %239, label %235, label %245

240:                                              ; preds = %235, %240
  %241 = phi i32 [ %243, %240 ], [ 0, %235 ]
  %242 = add nsw i32 %241, %226
  call void @_ZN8gemmlowp11ComputeImplINS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEES7_NS_12PackedResultEE10ComputeRunEiiii(%"class.gemmlowp::ComputeImpl"* nonnull %4, i32 %242, i32 %236, i32 %200, i32 %205) #19
  %243 = add nuw nsw i32 %241, 4
  %244 = icmp slt i32 %243, %229
  br i1 %244, label %240, label %237

245:                                              ; preds = %237
  %246 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %128, align 8
  br label %247

247:                                              ; preds = %245, %221
  %248 = phi %"struct.gemmlowp::BlockParams"* [ %246, %245 ], [ %222, %221 ]
  %249 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 0
  %250 = load i32, i32* %249, align 4
  %251 = add nsw i32 %250, %226
  %252 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 3
  %253 = load i32, i32* %252, align 4
  %254 = icmp sgt i32 %253, %251
  br i1 %254, label %221, label %212

255:                                              ; preds = %215, %183
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %127) #19
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %136) #19
  %256 = load i32, i32* %141, align 8
  %257 = add nsw i32 %256, %185
  %258 = load i32, i32* %142, align 4
  %259 = add nsw i32 %258, %166
  store i32 %257, i32* %137, align 4
  store i32 %259, i32* %138, align 4
  store i32 %188, i32* %139, align 4
  store i32 %171, i32* %140, align 4
  %260 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %21, align 8
  %261 = load i8, i8* %75, align 8
  %262 = zext i8 %261 to i64
  %263 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %260, i64 0, i32 5, i64 %262
  %264 = load i64, i64* %263, align 8
  %265 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %260, i64 0, i32 2
  %266 = bitcast i8** %265 to i64*
  %267 = load i64, i64* %266, align 8
  %268 = add i64 %267, %264
  %269 = inttoptr i64 %268 to i32*
  %270 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %144, align 8
  %271 = load i8, i8* %145, align 8
  %272 = zext i8 %271 to i64
  %273 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %270, i64 0, i32 5, i64 %272
  %274 = load i64, i64* %273, align 8
  %275 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %270, i64 0, i32 2
  %276 = bitcast i8** %275 to i64*
  %277 = load i64, i64* %276, align 8
  %278 = add i64 %277, %274
  %279 = inttoptr i64 %278 to i32*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %146) #19
  %280 = load %"class.gemmlowp::VectorDup.194"*, %"class.gemmlowp::VectorDup.194"** %147, align 8
  %281 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %280, i64 0, i32 0
  %282 = load i32, i32* %281, align 4, !noalias !1875
  store i32 %282, i32* %148, align 4, !alias.scope !1875
  store i32 %188, i32* %149, align 4, !alias.scope !1875
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %150) #19
  %283 = load %"class.gemmlowp::VectorDup"*, %"class.gemmlowp::VectorDup"** %151, align 8
  %284 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %283, i64 0, i32 0
  %285 = load i32, i32* %284, align 4, !noalias !1878
  store i32 %285, i32* %152, align 4, !alias.scope !1878
  store i32 %171, i32* %153, align 4, !alias.scope !1878
  %286 = load %"class.std::__1::tuple.485"*, %"class.std::__1::tuple.485"** %154, align 8
  call void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIsLNS_8MapOrderE1EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE1EEENSC_ISD_LSE_0EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SV_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.489"* %143, %"struct.gemmlowp::MatrixBlockBounds"* nonnull dereferenceable(16) %7, %"class.gemmlowp::PackedResult"* nonnull dereferenceable(40) %6, i32 %15, i32* %269, i32* %279, %"class.gemmlowp::VectorDup.194"* nonnull dereferenceable(8) %8, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %9, %"class.std::__1::tuple.485"* dereferenceable(20) %286)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %150) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %146) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %136) #19
  %287 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %288 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %287, i64 0, i32 3
  %289 = load i32, i32* %288, align 4
  %290 = add nsw i32 %289, %185
  %291 = icmp sgt i32 %11, %290
  br i1 %291, label %183, label %175
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp16SingleThreadGemmINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPNS_23SingleThreadGemmContextERKNS_10KernelBaseERKNS_9MatrixMapIKT0_XT3_EEERKNSU_ISW_XT4_EEEPNSU_IT1_XT5_EEERKT6_RKT7_RKT8_(%"class.gemmlowp::SingleThreadGemmContext"*, %"struct.gemmlowp::KernelBase"* dereferenceable(8), %"class.gemmlowp::MatrixMap"* dereferenceable(24), %"class.gemmlowp::MatrixMap.180"* dereferenceable(24), %"class.gemmlowp::MatrixMap.479"*, %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.std::__1::tuple.485"* dereferenceable(20)) local_unnamed_addr #1 comdat {
  %9 = alloca %"class.gemmlowp::SideMap", align 8
  %10 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %11 = alloca %"class.gemmlowp::SideMap", align 8
  %12 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %13 = alloca %"class.gemmlowp::SideMap", align 8
  %14 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %15 = alloca %"class.gemmlowp::ComputeImpl", align 8
  %16 = alloca %"struct.gemmlowp::BlockParams", align 4
  %17 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %18 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %19 = alloca %"class.gemmlowp::PackedResult", align 8
  %20 = alloca %"struct.gemmlowp::MatrixBlockBounds", align 4
  %21 = alloca %"class.gemmlowp::VectorDup", align 4
  %22 = alloca %"class.gemmlowp::VectorDup.194", align 4
  %23 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %4, i64 0, i32 1
  %24 = load i32, i32* %23, align 8
  %25 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %4, i64 0, i32 2
  %26 = load i32, i32* %25, align 4
  %27 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 2
  %28 = load i32, i32* %27, align 4
  %29 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0
  %30 = bitcast %"struct.gemmlowp::BlockParams"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %30) #19
  %31 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 0
  %32 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 1
  %33 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 2
  %34 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 3
  %35 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 4
  %36 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %16, i64 0, i32 5
  %37 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 1
  %38 = bitcast %"struct.gemmlowp::BlockParams"* %16 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %38, i8 -86, i64 24, i1 false)
  %39 = load i32, i32* %37, align 8
  %40 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 2
  %41 = load i32, i32* %40, align 4
  %42 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 3
  %43 = load float, float* %42, align 8
  call void @_ZN8gemmlowp11BlockParams4InitINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES7_EEEEviiiiiif(%"struct.gemmlowp::BlockParams"* nonnull %16, i32 %24, i32 %26, i32 %28, i32 1, i32 %39, i32 %41, float %43)
  %44 = bitcast %"class.gemmlowp::PackedSideBlock"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %44) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %44, i8 -86, i64 80, i1 false)
  %45 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %45, align 8
  %46 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 4
  store i32 0, i32* %46, align 8
  %47 = load i32, i32* %31, align 4
  %48 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 0
  store i32 %47, i32* %48, align 8
  %49 = load i32, i32* %34, align 4
  %50 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 2
  store i32 %49, i32* %50, align 8
  %51 = load i32, i32* %33, align 4
  %52 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 1
  store i32 %51, i32* %52, align 4
  %53 = load i32, i32* %36, align 4
  %54 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 0, i32 3
  store i32 %53, i32* %54, align 4
  %55 = mul nsw i32 %53, %49
  %56 = sext i32 %55 to i64
  %57 = add nsw i64 %56, 63
  %58 = and i64 %57, -64
  %59 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 4
  %60 = load i64, i64* %59, align 8, !noalias !1881
  %61 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 3
  %62 = load i64, i64* %61, align 8, !noalias !1881
  %63 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %62
  store i64 %60, i64* %63, align 8, !noalias !1881
  %64 = trunc i64 %62 to i8
  %65 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 6
  %66 = load i64, i64* %65, align 8, !noalias !1881
  %67 = load i64, i64* %61, align 8, !noalias !1881
  %68 = add i64 %67, 1
  store i64 %68, i64* %61, align 8, !noalias !1881
  %69 = load i64, i64* %59, align 8, !noalias !1881
  %70 = add i64 %69, %58
  store i64 %70, i64* %59, align 8, !noalias !1881
  %71 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 0
  store i8 %64, i8* %71, align 8
  %72 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %72, i8 -86, i64 7, i1 false) #19
  %73 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 2
  store i64 %66, i64* %73, align 8
  %74 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 2, i32 3
  store i8 0, i8* %74, align 8
  %75 = sext i32 %49 to i64
  %76 = shl nsw i64 %75, 2
  %77 = add nsw i64 %76, 63
  %78 = and i64 %77, -64
  %79 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %68
  store i64 %70, i64* %79, align 8, !noalias !1884
  %80 = trunc i64 %68 to i8
  %81 = load i64, i64* %65, align 8, !noalias !1884
  %82 = load i64, i64* %61, align 8, !noalias !1884
  %83 = add i64 %82, 1
  store i64 %83, i64* %61, align 8, !noalias !1884
  %84 = load i64, i64* %59, align 8, !noalias !1884
  %85 = add i64 %84, %78
  store i64 %85, i64* %59, align 8, !noalias !1884
  %86 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 0
  store i8 %80, i8* %86, align 8
  %87 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %87, i8 -86, i64 7, i1 false) #19
  %88 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 2
  store i64 %81, i64* %88, align 8
  %89 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %17, i64 0, i32 3, i32 3
  store i8 5, i8* %89, align 8
  %90 = bitcast %"class.gemmlowp::PackedSideBlock"* %18 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %90) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %90, i8 -86, i64 80, i1 false)
  %91 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %91, align 8
  %92 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 4
  store i32 0, i32* %92, align 8
  %93 = load i32, i32* %32, align 4
  %94 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 0
  store i32 %93, i32* %94, align 8
  %95 = load i32, i32* %35, align 4
  %96 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 2
  store i32 %95, i32* %96, align 8
  %97 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 1
  store i32 %51, i32* %97, align 4
  %98 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 0, i32 3
  store i32 %53, i32* %98, align 4
  %99 = mul nsw i32 %53, %95
  %100 = sext i32 %99 to i64
  %101 = add nsw i64 %100, 63
  %102 = and i64 %101, -64
  %103 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %83
  store i64 %85, i64* %103, align 8, !noalias !1887
  %104 = trunc i64 %83 to i8
  %105 = load i64, i64* %65, align 8, !noalias !1887
  %106 = load i64, i64* %61, align 8, !noalias !1887
  %107 = add i64 %106, 1
  store i64 %107, i64* %61, align 8, !noalias !1887
  %108 = load i64, i64* %59, align 8, !noalias !1887
  %109 = add i64 %108, %102
  store i64 %109, i64* %59, align 8, !noalias !1887
  %110 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 0
  store i8 %104, i8* %110, align 8
  %111 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %111, i8 -86, i64 7, i1 false) #19
  %112 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 2
  store i64 %105, i64* %112, align 8
  %113 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 2, i32 3
  store i8 0, i8* %113, align 8
  %114 = sext i32 %95 to i64
  %115 = shl nsw i64 %114, 2
  %116 = add nsw i64 %115, 63
  %117 = and i64 %116, -64
  %118 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %107
  store i64 %109, i64* %118, align 8, !noalias !1890
  %119 = trunc i64 %107 to i8
  %120 = load i64, i64* %65, align 8, !noalias !1890
  %121 = load i64, i64* %61, align 8, !noalias !1890
  %122 = add i64 %121, 1
  store i64 %122, i64* %61, align 8, !noalias !1890
  %123 = load i64, i64* %59, align 8, !noalias !1890
  %124 = add i64 %123, %117
  store i64 %124, i64* %59, align 8, !noalias !1890
  %125 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 0
  store i8 %119, i8* %125, align 8
  %126 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %126, i8 -86, i64 7, i1 false) #19
  %127 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 2
  store i64 %120, i64* %127, align 8
  %128 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %18, i64 0, i32 3, i32 3
  store i8 5, i8* %128, align 8
  %129 = bitcast %"class.gemmlowp::PackedResult"* %19 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %129) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %129, i8 -86, i64 32, i1 false)
  %130 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 0
  store %"class.gemmlowp::Allocator"* %29, %"class.gemmlowp::Allocator"** %130, align 8
  %131 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 2
  store %"struct.gemmlowp::BlockParams"* %16, %"struct.gemmlowp::BlockParams"** %131, align 8
  %132 = load i32, i32* %34, align 4
  %133 = mul nsw i32 %95, %132
  %134 = sext i32 %133 to i64
  %135 = shl nsw i64 %134, 2
  %136 = add nsw i64 %135, 63
  %137 = and i64 %136, -64
  %138 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 5, i64 %122
  store i64 %124, i64* %138, align 8, !noalias !1893
  %139 = trunc i64 %122 to i8
  %140 = load i64, i64* %65, align 8, !noalias !1893
  %141 = bitcast i64* %61 to <2 x i64>*
  %142 = load <2 x i64>, <2 x i64>* %141, align 8, !noalias !1893
  %143 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %137, i32 1
  %144 = add <2 x i64> %142, %143
  %145 = bitcast i64* %61 to <2 x i64>*
  store <2 x i64> %144, <2 x i64>* %145, align 8, !noalias !1893
  %146 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 0
  store i8 %139, i8* %146, align 8
  %147 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %147, i8 -86, i64 7, i1 false) #19
  %148 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 2
  store i64 %140, i64* %148, align 8
  %149 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %19, i64 0, i32 1, i32 3
  store i8 5, i8* %149, align 8
  call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %29)
  %150 = load i32, i32* %35, align 4
  %151 = icmp sge i32 %150, %26
  br i1 %151, label %152, label %169

152:                                              ; preds = %8
  %153 = bitcast %"class.gemmlowp::SideMap"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %153) #19
  %154 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 1
  %155 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 2
  %156 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %9, i64 0, i32 3
  %157 = bitcast %"class.gemmlowp::MatrixMap.180"* %3 to i64*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %153, i8 -86, i64 24, i1 false) #19
  %158 = load i64, i64* %157, align 8
  %159 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 2
  %160 = load i32, i32* %159, align 4
  %161 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 1
  %162 = load i32, i32* %161, align 8
  %163 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 3
  %164 = load i32, i32* %163, align 8
  %165 = bitcast %"class.gemmlowp::SideMap"* %9 to i64*
  store i64 %158, i64* %165, align 8
  store i32 %160, i32* %154, align 8
  store i32 %162, i32* %155, align 4
  store i32 %164, i32* %156, align 8
  %166 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %166) #19
  %167 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 0
  %168 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %10, i64 0, i32 1
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %167, align 8
  store %"class.gemmlowp::SideMap"* %9, %"class.gemmlowp::SideMap"** %168, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %10) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %166) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %153) #19
  br label %169

169:                                              ; preds = %152, %8
  %170 = icmp sgt i32 %24, 0
  br i1 %170, label %171, label %216

171:                                              ; preds = %169
  %172 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 0
  %173 = getelementptr inbounds %"class.gemmlowp::MatrixMap", %"class.gemmlowp::MatrixMap"* %2, i64 0, i32 3
  %174 = bitcast %"class.gemmlowp::SideMap"* %11 to i8*
  %175 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 1
  %176 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 2
  %177 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %11, i64 0, i32 3
  %178 = bitcast %"class.gemmlowp::SideMap"* %11 to i64*
  %179 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %12 to i8*
  %180 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %12, i64 0, i32 0
  %181 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %12, i64 0, i32 1
  %182 = icmp sgt i32 %26, 0
  %183 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 0
  %184 = getelementptr inbounds %"class.gemmlowp::MatrixMap.180", %"class.gemmlowp::MatrixMap.180"* %3, i64 0, i32 3
  %185 = bitcast %"class.gemmlowp::SideMap"* %13 to i8*
  %186 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 1
  %187 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 2
  %188 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %13, i64 0, i32 3
  %189 = bitcast %"class.gemmlowp::SideMap"* %13 to i64*
  %190 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %14 to i8*
  %191 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %14, i64 0, i32 0
  %192 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %14, i64 0, i32 1
  %193 = bitcast %"class.gemmlowp::ComputeImpl"* %15 to i8*
  %194 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 0
  %195 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 1
  %196 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 2
  %197 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 3
  %198 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %15, i64 0, i32 4
  %199 = add i32 %28, 15
  %200 = and i32 %199, -16
  %201 = icmp sgt i32 %200, 0
  %202 = bitcast %"struct.gemmlowp::MatrixBlockBounds"* %20 to i8*
  %203 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 0
  %204 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 1
  %205 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 2
  %206 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %20, i64 0, i32 3
  %207 = bitcast %"class.gemmlowp::VectorDup"* %21 to i8*
  %208 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %209 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %21, i64 0, i32 0
  %210 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %21, i64 0, i32 1
  %211 = bitcast %"class.gemmlowp::VectorDup.194"* %22 to i8*
  %212 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %6, i64 0, i32 0
  %213 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %22, i64 0, i32 0
  %214 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %22, i64 0, i32 1
  %215 = load i32, i32* %34, align 4
  br label %221

216:                                              ; preds = %235, %169
  %217 = getelementptr inbounds %"class.gemmlowp::SingleThreadGemmContext", %"class.gemmlowp::SingleThreadGemmContext"* %0, i64 0, i32 0, i32 0
  store i8 0, i8* %217, align 8
  %218 = load i64, i64* %65, align 8
  %219 = add i64 %218, 1
  store i64 %219, i64* %65, align 8
  %220 = bitcast i64* %61 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %220, i8 0, i64 16, i1 false) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %129) #19
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %90) #19
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %44) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %30) #19
  ret void

221:                                              ; preds = %171, %235
  %222 = phi i32 [ %215, %171 ], [ %236, %235 ]
  %223 = phi i32 [ 0, %171 ], [ %237, %235 ]
  %224 = sub nsw i32 %24, %223
  %225 = icmp slt i32 %224, %222
  %226 = select i1 %225, i32 %224, i32 %222
  %227 = load i8*, i8** %172, align 8, !noalias !1896
  %228 = load i32, i32* %173, align 8, !noalias !1896
  %229 = mul nsw i32 %228, %223
  %230 = sext i32 %229 to i64
  %231 = getelementptr inbounds i8, i8* %227, i64 %230
  %232 = ptrtoint i8* %231 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %174) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %174, i8 -86, i64 24, i1 false) #19
  store i64 %232, i64* %178, align 8
  store i32 %226, i32* %175, align 8
  store i32 %28, i32* %176, align 4
  store i32 %228, i32* %177, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %179) #19
  store %"class.gemmlowp::PackedSideBlock"* %17, %"class.gemmlowp::PackedSideBlock"** %180, align 8
  store %"class.gemmlowp::SideMap"* %11, %"class.gemmlowp::SideMap"** %181, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %12) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %179) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %174) #19
  br i1 %182, label %233, label %235

233:                                              ; preds = %221
  %234 = load i32, i32* %35, align 4
  br label %239

235:                                              ; preds = %311, %221
  %236 = load i32, i32* %34, align 4
  %237 = add nsw i32 %236, %223
  %238 = icmp sgt i32 %24, %237
  br i1 %238, label %221, label %216

239:                                              ; preds = %233, %311
  %240 = phi i32 [ %334, %311 ], [ %234, %233 ]
  %241 = phi i32 [ %335, %311 ], [ 0, %233 ]
  %242 = sub nsw i32 %26, %241
  %243 = icmp slt i32 %242, %240
  %244 = select i1 %243, i32 %242, i32 %240
  br i1 %151, label %252, label %245

245:                                              ; preds = %239
  %246 = load i8*, i8** %183, align 8, !noalias !1899
  %247 = load i32, i32* %184, align 8, !noalias !1899
  %248 = mul nsw i32 %247, %241
  %249 = sext i32 %248 to i64
  %250 = getelementptr inbounds i8, i8* %246, i64 %249
  %251 = ptrtoint i8* %250 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %185) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %185, i8 -86, i64 24, i1 false) #19
  store i64 %251, i64* %189, align 8
  store i32 %244, i32* %186, align 8
  store i32 %28, i32* %187, align 4
  store i32 %247, i32* %188, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %190) #19
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %191, align 8
  store %"class.gemmlowp::SideMap"* %13, %"class.gemmlowp::SideMap"** %192, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %14) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %190) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %185) #19
  br label %252

252:                                              ; preds = %245, %239
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %193) #19
  store %"struct.gemmlowp::KernelBase"* %1, %"struct.gemmlowp::KernelBase"** %194, align 8
  store %"struct.gemmlowp::BlockParams"* %16, %"struct.gemmlowp::BlockParams"** %195, align 8
  store %"class.gemmlowp::PackedResult"* %19, %"class.gemmlowp::PackedResult"** %196, align 8
  store %"class.gemmlowp::PackedSideBlock"* %17, %"class.gemmlowp::PackedSideBlock"** %197, align 8
  store %"class.gemmlowp::PackedSideBlock"* %18, %"class.gemmlowp::PackedSideBlock"** %198, align 8
  br i1 %201, label %253, label %311

253:                                              ; preds = %252, %271
  %254 = phi %"struct.gemmlowp::BlockParams"* [ %273, %271 ], [ %16, %252 ]
  %255 = phi %"struct.gemmlowp::BlockParams"* [ %274, %271 ], [ %16, %252 ]
  %256 = phi i32 [ %275, %271 ], [ 0, %252 ]
  %257 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 2
  %258 = sub nsw i32 %200, %256
  %259 = load i32, i32* %257, align 4
  %260 = icmp slt i32 %258, %259
  %261 = select i1 %260, i32 %258, i32 %259
  %262 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 3
  %263 = load i32, i32* %262, align 4
  %264 = icmp sgt i32 %263, 0
  br i1 %264, label %265, label %271

265:                                              ; preds = %253
  %266 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %255, i64 0, i32 0
  %267 = load i32, i32* %266, align 4
  br label %277

268:                                              ; preds = %303
  %269 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 2
  %270 = load i32, i32* %269, align 4
  br label %271

271:                                              ; preds = %268, %253
  %272 = phi i32 [ %259, %253 ], [ %270, %268 ]
  %273 = phi %"struct.gemmlowp::BlockParams"* [ %254, %253 ], [ %304, %268 ]
  %274 = phi %"struct.gemmlowp::BlockParams"* [ %255, %253 ], [ %304, %268 ]
  %275 = add nsw i32 %272, %256
  %276 = icmp sgt i32 %200, %275
  br i1 %276, label %253, label %311

277:                                              ; preds = %303, %265
  %278 = phi %"struct.gemmlowp::BlockParams"* [ %304, %303 ], [ %254, %265 ]
  %279 = phi i32 [ %306, %303 ], [ %267, %265 ]
  %280 = phi i32 [ %309, %303 ], [ %263, %265 ]
  %281 = phi %"struct.gemmlowp::BlockParams"* [ %304, %303 ], [ %255, %265 ]
  %282 = phi i32 [ %307, %303 ], [ 0, %265 ]
  %283 = sub nsw i32 %280, %282
  %284 = icmp slt i32 %283, %279
  %285 = select i1 %284, i32 %283, i32 %279
  %286 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %281, i64 0, i32 4
  %287 = load i32, i32* %286, align 4
  %288 = icmp sgt i32 %287, 0
  br i1 %288, label %289, label %303

289:                                              ; preds = %277
  %290 = icmp sgt i32 %285, 0
  br label %291

291:                                              ; preds = %293, %289
  %292 = phi i32 [ 0, %289 ], [ %294, %293 ]
  br i1 %290, label %296, label %293

293:                                              ; preds = %296, %291
  %294 = add nuw nsw i32 %292, 4
  %295 = icmp slt i32 %294, %287
  br i1 %295, label %291, label %301

296:                                              ; preds = %291, %296
  %297 = phi i32 [ %299, %296 ], [ 0, %291 ]
  %298 = add nsw i32 %297, %282
  call void @_ZN8gemmlowp11ComputeImplINS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEES7_NS_12PackedResultEE10ComputeRunEiiii(%"class.gemmlowp::ComputeImpl"* nonnull %15, i32 %298, i32 %292, i32 %256, i32 %261) #19
  %299 = add nuw nsw i32 %297, 4
  %300 = icmp slt i32 %299, %285
  br i1 %300, label %296, label %293

301:                                              ; preds = %293
  %302 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %195, align 8
  br label %303

303:                                              ; preds = %301, %277
  %304 = phi %"struct.gemmlowp::BlockParams"* [ %302, %301 ], [ %278, %277 ]
  %305 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 0
  %306 = load i32, i32* %305, align 4
  %307 = add nsw i32 %306, %282
  %308 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %304, i64 0, i32 3
  %309 = load i32, i32* %308, align 4
  %310 = icmp sgt i32 %309, %307
  br i1 %310, label %277, label %268

311:                                              ; preds = %271, %252
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %193) #19
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %202) #19
  store i32 %223, i32* %203, align 4
  store i32 %241, i32* %204, align 4
  store i32 %226, i32* %205, align 4
  store i32 %244, i32* %206, align 4
  %312 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %45, align 8
  %313 = load i8, i8* %86, align 8
  %314 = zext i8 %313 to i64
  %315 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %312, i64 0, i32 5, i64 %314
  %316 = load i64, i64* %315, align 8
  %317 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %312, i64 0, i32 2
  %318 = bitcast i8** %317 to i64*
  %319 = load i64, i64* %318, align 8
  %320 = add i64 %319, %316
  %321 = inttoptr i64 %320 to i32*
  %322 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %91, align 8
  %323 = load i8, i8* %125, align 8
  %324 = zext i8 %323 to i64
  %325 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %322, i64 0, i32 5, i64 %324
  %326 = load i64, i64* %325, align 8
  %327 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %322, i64 0, i32 2
  %328 = bitcast i8** %327 to i64*
  %329 = load i64, i64* %328, align 8
  %330 = add i64 %329, %326
  %331 = inttoptr i64 %330 to i32*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %207) #19
  %332 = load i32, i32* %208, align 4, !noalias !1902
  store i32 %332, i32* %209, align 4, !alias.scope !1902
  store i32 %226, i32* %210, align 4, !alias.scope !1902
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %211) #19
  %333 = load i32, i32* %212, align 4, !noalias !1905
  store i32 %333, i32* %213, align 4, !alias.scope !1905
  store i32 %244, i32* %214, align 4, !alias.scope !1905
  call void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIsLNS_8MapOrderE0EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE0EEENSC_ISD_LSE_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SV_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.479"* %4, %"struct.gemmlowp::MatrixBlockBounds"* nonnull dereferenceable(16) %20, %"class.gemmlowp::PackedResult"* nonnull dereferenceable(40) %19, i32 %28, i32* %321, i32* %331, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %21, %"class.gemmlowp::VectorDup.194"* nonnull dereferenceable(8) %22, %"class.std::__1::tuple.485"* dereferenceable(20) %7)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %211) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %207) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %202) #19
  %334 = load i32, i32* %35, align 4
  %335 = add nsw i32 %334, %241
  %336 = icmp sgt i32 %26, %335
  br i1 %336, label %239, label %235
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIsLNS_8MapOrderE0EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE0EEENSC_ISD_LSE_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SV_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.479"*, %"struct.gemmlowp::MatrixBlockBounds"* dereferenceable(16), %"class.gemmlowp::PackedResult"* dereferenceable(40), i32, i32*, i32*, %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), %"class.std::__1::tuple.485"* dereferenceable(20)) local_unnamed_addr #1 comdat {
  %10 = alloca %"class.gemmlowp::MatrixMap.214", align 8
  %11 = alloca %"class.gemmlowp::VectorMap", align 8
  %12 = alloca %"class.gemmlowp::VectorMap.201", align 8
  %13 = alloca %"struct.gemmlowp::OutputPipelineExecutor.631", align 8
  %14 = alloca %"struct.gemmlowp::OutputPipelineExecutor.638", align 8
  %15 = alloca %"struct.gemmlowp::OutputPipelineExecutor.645", align 8
  %16 = alloca %"struct.gemmlowp::OutputPipelineExecutor.652", align 8
  %17 = alloca %"struct.gemmlowp::OutputPipelineExecutor.659", align 8
  %18 = bitcast %"class.gemmlowp::MatrixMap.214"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %18) #19
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %10, i64 0, i32 0
  %20 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %10, i64 0, i32 1
  %21 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %10, i64 0, i32 2
  %22 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %10, i64 0, i32 3
  %23 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 0
  %24 = bitcast %"class.gemmlowp::MatrixMap.214"* %10 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %24, i8 -86, i64 24, i1 false)
  %25 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %23, align 8, !noalias !1908
  %26 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 1, i32 0
  %27 = load i8, i8* %26, align 8, !noalias !1908
  %28 = zext i8 %27 to i64
  %29 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %25, i64 0, i32 5, i64 %28
  %30 = load i64, i64* %29, align 8, !noalias !1908
  %31 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %25, i64 0, i32 2
  %32 = bitcast i8** %31 to i64*
  %33 = load i64, i64* %32, align 8, !noalias !1908
  %34 = add i64 %33, %30
  %35 = inttoptr i64 %34 to i32*
  %36 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %2, i64 0, i32 2
  %37 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %36, align 8, !noalias !1908
  %38 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %37, i64 0, i32 3
  %39 = load i32, i32* %38, align 4, !noalias !1908
  %40 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %37, i64 0, i32 4
  %41 = load i32, i32* %40, align 4, !noalias !1908
  store i32* %35, i32** %19, align 8, !alias.scope !1908
  store i32 %39, i32* %20, align 8, !alias.scope !1908
  store i32 %41, i32* %21, align 4, !alias.scope !1908
  store i32 %39, i32* %22, align 8, !alias.scope !1908
  %42 = bitcast %"class.gemmlowp::VectorMap"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %42) #19
  %43 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %11, i64 0, i32 0
  %44 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %11, i64 0, i32 1
  %45 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 2
  %46 = bitcast %"class.gemmlowp::VectorMap"* %11 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %46, i8 -86, i64 16, i1 false)
  %47 = load i32, i32* %45, align 4
  store i32* %4, i32** %43, align 8
  store i32 %47, i32* %44, align 8
  %48 = bitcast %"class.gemmlowp::VectorMap.201"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %48) #19
  %49 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %12, i64 0, i32 0
  %50 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %12, i64 0, i32 1
  %51 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 3
  %52 = bitcast %"class.gemmlowp::VectorMap.201"* %12 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %52, i8 -86, i64 16, i1 false)
  %53 = load i32, i32* %51, align 4
  store i32* %5, i32** %49, align 8
  store i32 %53, i32* %50, align 8
  %54 = getelementptr inbounds %"class.std::__1::tuple.485", %"class.std::__1::tuple.485"* %8, i64 0, i32 0, i32 0, i32 0
  %55 = getelementptr inbounds %"class.std::__1::tuple.485", %"class.std::__1::tuple.485"* %8, i64 0, i32 0, i32 0, i32 0, i32 1
  %56 = load i32, i32* %55, align 4
  %57 = icmp sgt i32 %56, 0
  %58 = select i1 %57, i32 %56, i32 0
  %59 = sub nsw i32 0, %56
  %60 = icmp sgt i32 %59, 0
  %61 = select i1 %60, i32 %59, i32 0
  %62 = getelementptr inbounds %"class.std::__1::tuple.485", %"class.std::__1::tuple.485"* %8, i64 0, i32 0, i32 1, i32 0
  %63 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.631"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %63) #19
  %64 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.631", %"struct.gemmlowp::OutputPipelineExecutor.631"* %13, i64 0, i32 0, i32 0, i32 0, i32 0
  %65 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.631", %"struct.gemmlowp::OutputPipelineExecutor.631"* %13, i64 0, i32 0, i32 0, i32 0, i32 1
  %66 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.631", %"struct.gemmlowp::OutputPipelineExecutor.631"* %13, i64 0, i32 0, i32 0, i32 0, i32 2
  %67 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.631", %"struct.gemmlowp::OutputPipelineExecutor.631"* %13, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %68 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.631", %"struct.gemmlowp::OutputPipelineExecutor.631"* %13, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %69 = bitcast i8* %68 to i64*
  store i64 -6148914691236517206, i64* %69, align 8
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %54, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %64, align 8
  store i32 %58, i32* %65, align 8
  store i32 %61, i32* %66, align 4
  store %"struct.gemmlowp::OutputStageClamp"* %62, %"struct.gemmlowp::OutputStageClamp"** %67, align 8
  %70 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.638"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %70) #19
  %71 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.638", %"struct.gemmlowp::OutputPipelineExecutor.638"* %14, i64 0, i32 0, i32 0, i32 0, i32 0
  %72 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.638", %"struct.gemmlowp::OutputPipelineExecutor.638"* %14, i64 0, i32 0, i32 0, i32 0, i32 1
  %73 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.638", %"struct.gemmlowp::OutputPipelineExecutor.638"* %14, i64 0, i32 0, i32 0, i32 0, i32 2
  %74 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.638", %"struct.gemmlowp::OutputPipelineExecutor.638"* %14, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %75 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.638", %"struct.gemmlowp::OutputPipelineExecutor.638"* %14, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %76 = bitcast i8* %75 to i64*
  store i64 -6148914691236517206, i64* %76, align 8
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %54, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %71, align 8
  store i32 %58, i32* %72, align 8
  store i32 %61, i32* %73, align 4
  store %"struct.gemmlowp::OutputStageClamp"* %62, %"struct.gemmlowp::OutputStageClamp"** %74, align 8
  %77 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.645"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %77) #19
  %78 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.645", %"struct.gemmlowp::OutputPipelineExecutor.645"* %15, i64 0, i32 0, i32 0, i32 0, i32 0
  %79 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.645", %"struct.gemmlowp::OutputPipelineExecutor.645"* %15, i64 0, i32 0, i32 0, i32 0, i32 1
  %80 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.645", %"struct.gemmlowp::OutputPipelineExecutor.645"* %15, i64 0, i32 0, i32 0, i32 0, i32 2
  %81 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.645", %"struct.gemmlowp::OutputPipelineExecutor.645"* %15, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %82 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.645", %"struct.gemmlowp::OutputPipelineExecutor.645"* %15, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %83 = bitcast i8* %82 to i64*
  store i64 -6148914691236517206, i64* %83, align 8
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %54, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %78, align 8
  store i32 %58, i32* %79, align 8
  store i32 %61, i32* %80, align 4
  store %"struct.gemmlowp::OutputStageClamp"* %62, %"struct.gemmlowp::OutputStageClamp"** %81, align 8
  %84 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.652"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %84) #19
  %85 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.652", %"struct.gemmlowp::OutputPipelineExecutor.652"* %16, i64 0, i32 0, i32 0, i32 0, i32 0
  %86 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.652", %"struct.gemmlowp::OutputPipelineExecutor.652"* %16, i64 0, i32 0, i32 0, i32 0, i32 1
  %87 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.652", %"struct.gemmlowp::OutputPipelineExecutor.652"* %16, i64 0, i32 0, i32 0, i32 0, i32 2
  %88 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.652", %"struct.gemmlowp::OutputPipelineExecutor.652"* %16, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %89 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.652", %"struct.gemmlowp::OutputPipelineExecutor.652"* %16, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %90 = bitcast i8* %89 to i64*
  store i64 -6148914691236517206, i64* %90, align 8
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %54, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %85, align 8
  store i32 %58, i32* %86, align 8
  store i32 %61, i32* %87, align 4
  store %"struct.gemmlowp::OutputStageClamp"* %62, %"struct.gemmlowp::OutputStageClamp"** %88, align 8
  %91 = bitcast %"struct.gemmlowp::OutputPipelineExecutor.659"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %91) #19
  %92 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.659", %"struct.gemmlowp::OutputPipelineExecutor.659"* %17, i64 0, i32 0, i32 0, i32 0, i32 0
  %93 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.659", %"struct.gemmlowp::OutputPipelineExecutor.659"* %17, i64 0, i32 0, i32 0, i32 0, i32 1
  %94 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.659", %"struct.gemmlowp::OutputPipelineExecutor.659"* %17, i64 0, i32 0, i32 0, i32 0, i32 2
  %95 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.659", %"struct.gemmlowp::OutputPipelineExecutor.659"* %17, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %96 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.659", %"struct.gemmlowp::OutputPipelineExecutor.659"* %17, i64 0, i32 0, i32 1, i32 1, i32 0, i32 0, i32 0
  %97 = bitcast i8* %96 to i64*
  store i64 -6148914691236517206, i64* %97, align 8
  store %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %54, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %92, align 8
  store i32 %58, i32* %93, align 8
  store i32 %61, i32* %94, align 4
  store %"struct.gemmlowp::OutputStageClamp"* %62, %"struct.gemmlowp::OutputStageClamp"** %95, align 8
  %98 = load i32, i32* %51, align 4
  %99 = icmp slt i32 %98, 4
  br i1 %99, label %104, label %100

100:                                              ; preds = %9
  %101 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 1
  %102 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 0
  %103 = load i32, i32* %45, align 4
  br label %128

104:                                              ; preds = %230, %9
  %105 = phi i32 [ %98, %9 ], [ %233, %230 ]
  %106 = phi i32 [ 0, %9 ], [ %232, %230 ]
  %107 = icmp slt i32 %106, %105
  br i1 %107, label %108, label %389

108:                                              ; preds = %104
  %109 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 1
  %110 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %1, i64 0, i32 0
  %111 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %6, i64 0, i32 0
  %112 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %7, i64 0, i32 0
  %113 = getelementptr inbounds %"class.std::__1::tuple.485", %"class.std::__1::tuple.485"* %8, i64 0, i32 0, i32 0, i32 0, i32 2
  %114 = shl i32 1, %58
  %115 = sext i32 %114 to i64
  %116 = getelementptr inbounds %"class.std::__1::tuple.485", %"class.std::__1::tuple.485"* %8, i64 0, i32 0, i32 0, i32 0, i32 0
  %117 = zext i32 %61 to i64
  %118 = shl nsw i64 -1, %117
  %119 = trunc i64 %118 to i32
  %120 = xor i32 %119, -1
  %121 = ashr i32 %120, 1
  %122 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %62, i64 0, i32 0
  %123 = getelementptr inbounds %"class.std::__1::tuple.485", %"class.std::__1::tuple.485"* %8, i64 0, i32 0, i32 1, i32 0, i32 1
  %124 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %0, i64 0, i32 0
  %125 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %0, i64 0, i32 3
  %126 = zext i32 %106 to i64
  %127 = load i32, i32* %45, align 4
  br label %236

128:                                              ; preds = %100, %230
  %129 = phi i32 [ %103, %100 ], [ %231, %230 ]
  %130 = phi i32 [ 0, %100 ], [ %232, %230 ]
  %131 = load i32, i32* %101, align 4
  %132 = add nsw i32 %131, %130
  %133 = load i32*, i32** %19, align 8
  %134 = load i32, i32* %22, align 8
  %135 = mul nsw i32 %134, %130
  %136 = sext i32 %135 to i64
  %137 = load i32*, i32** %43, align 8
  %138 = bitcast i32* %137 to i8*
  call void @llvm.prefetch(i8* %138, i32 0, i32 3, i32 1) #19
  %139 = getelementptr inbounds i32, i32* %137, i64 4
  %140 = bitcast i32* %139 to i8*
  call void @llvm.prefetch(i8* %140, i32 0, i32 3, i32 1) #19
  %141 = getelementptr inbounds i32, i32* %133, i64 %136
  %142 = sext i32 %134 to i64
  %143 = bitcast i32* %141 to i8*
  call void @llvm.prefetch(i8* %143, i32 0, i32 3, i32 1) #19
  %144 = getelementptr inbounds i32, i32* %141, i64 4
  %145 = bitcast i32* %144 to i8*
  call void @llvm.prefetch(i8* %145, i32 0, i32 3, i32 1) #19
  %146 = getelementptr inbounds i32, i32* %141, i64 %142
  %147 = bitcast i32* %146 to i8*
  call void @llvm.prefetch(i8* %147, i32 0, i32 3, i32 1) #19
  %148 = getelementptr inbounds i32, i32* %146, i64 4
  %149 = bitcast i32* %148 to i8*
  call void @llvm.prefetch(i8* %149, i32 0, i32 3, i32 1) #19
  %150 = shl nsw i64 %142, 1
  %151 = getelementptr inbounds i32, i32* %141, i64 %150
  %152 = bitcast i32* %151 to i8*
  call void @llvm.prefetch(i8* %152, i32 0, i32 3, i32 1) #19
  %153 = getelementptr inbounds i32, i32* %151, i64 4
  %154 = bitcast i32* %153 to i8*
  call void @llvm.prefetch(i8* %154, i32 0, i32 3, i32 1) #19
  %155 = mul nsw i64 %142, 3
  %156 = getelementptr inbounds i32, i32* %141, i64 %155
  %157 = bitcast i32* %156 to i8*
  call void @llvm.prefetch(i8* %157, i32 0, i32 3, i32 1) #19
  %158 = getelementptr inbounds i32, i32* %156, i64 4
  %159 = bitcast i32* %158 to i8*
  call void @llvm.prefetch(i8* %159, i32 0, i32 3, i32 1) #19
  %160 = icmp slt i32 %129, 8
  br i1 %160, label %163, label %168

161:                                              ; preds = %168
  %162 = trunc i64 %176 to i32
  br label %163

163:                                              ; preds = %161, %128
  %164 = phi i32 [ %129, %128 ], [ %203, %161 ]
  %165 = phi i32 [ 0, %128 ], [ %162, %161 ]
  %166 = add nsw i32 %164, -4
  %167 = icmp sgt i32 %165, %166
  br i1 %167, label %211, label %215

168:                                              ; preds = %128, %207
  %169 = phi i32* [ %210, %207 ], [ %137, %128 ]
  %170 = phi i32 [ %209, %207 ], [ %134, %128 ]
  %171 = phi i32* [ %208, %207 ], [ %133, %128 ]
  %172 = phi i64 [ %176, %207 ], [ 0, %128 ]
  %173 = load i32, i32* %102, align 4
  %174 = trunc i64 %172 to i32
  %175 = add nsw i32 %173, %174
  %176 = add nuw i64 %172, 8
  %177 = mul nsw i32 %170, %130
  %178 = sext i32 %177 to i64
  %179 = getelementptr inbounds i32, i32* %169, i64 %176
  %180 = bitcast i32* %179 to i8*
  call void @llvm.prefetch(i8* %180, i32 0, i32 3, i32 1) #19
  %181 = getelementptr inbounds i32, i32* %179, i64 4
  %182 = bitcast i32* %181 to i8*
  call void @llvm.prefetch(i8* %182, i32 0, i32 3, i32 1) #19
  %183 = getelementptr inbounds i32, i32* %171, i64 %176
  %184 = getelementptr inbounds i32, i32* %183, i64 %178
  %185 = sext i32 %170 to i64
  %186 = bitcast i32* %184 to i8*
  call void @llvm.prefetch(i8* %186, i32 0, i32 3, i32 1) #19
  %187 = getelementptr inbounds i32, i32* %184, i64 4
  %188 = bitcast i32* %187 to i8*
  call void @llvm.prefetch(i8* %188, i32 0, i32 3, i32 1) #19
  %189 = getelementptr inbounds i32, i32* %184, i64 %185
  %190 = bitcast i32* %189 to i8*
  call void @llvm.prefetch(i8* %190, i32 0, i32 3, i32 1) #19
  %191 = getelementptr inbounds i32, i32* %189, i64 4
  %192 = bitcast i32* %191 to i8*
  call void @llvm.prefetch(i8* %192, i32 0, i32 3, i32 1) #19
  %193 = shl nsw i64 %185, 1
  %194 = getelementptr inbounds i32, i32* %184, i64 %193
  %195 = bitcast i32* %194 to i8*
  call void @llvm.prefetch(i8* %195, i32 0, i32 3, i32 1) #19
  %196 = getelementptr inbounds i32, i32* %194, i64 4
  %197 = bitcast i32* %196 to i8*
  call void @llvm.prefetch(i8* %197, i32 0, i32 3, i32 1) #19
  %198 = mul nsw i64 %185, 3
  %199 = getelementptr inbounds i32, i32* %184, i64 %198
  %200 = bitcast i32* %199 to i8*
  call void @llvm.prefetch(i8* %200, i32 0, i32 3, i32 1) #19
  %201 = getelementptr inbounds i32, i32* %199, i64 4
  %202 = bitcast i32* %201 to i8*
  call void @llvm.prefetch(i8* %202, i32 0, i32 3, i32 1) #19
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %10, %"struct.gemmlowp::OutputPipelineExecutor.659"* nonnull dereferenceable(32) %17, %"class.gemmlowp::MatrixMap.479"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %11, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorDup"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %7, i32 %3, i32 %174, i32 %130, i32 %175, i32 %132, i32 %175, i32 %132)
  %203 = load i32, i32* %45, align 4
  %204 = add nsw i32 %203, -8
  %205 = trunc i64 %176 to i32
  %206 = icmp slt i32 %204, %205
  br i1 %206, label %161, label %207

207:                                              ; preds = %168
  %208 = load i32*, i32** %19, align 8
  %209 = load i32, i32* %22, align 8
  %210 = load i32*, i32** %43, align 8
  br label %168

211:                                              ; preds = %215, %163
  %212 = phi i32 [ %164, %163 ], [ %220, %215 ]
  %213 = phi i32 [ %165, %163 ], [ %219, %215 ]
  %214 = icmp slt i32 %213, %212
  br i1 %214, label %223, label %230

215:                                              ; preds = %163, %215
  %216 = phi i32 [ %219, %215 ], [ %165, %163 ]
  %217 = load i32, i32* %102, align 4
  %218 = add nsw i32 %217, %216
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %10, %"struct.gemmlowp::OutputPipelineExecutor.652"* nonnull dereferenceable(32) %16, %"class.gemmlowp::MatrixMap.479"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %11, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorDup"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %7, i32 %3, i32 %216, i32 %130, i32 %218, i32 %132, i32 %218, i32 %132)
  %219 = add nuw nsw i32 %216, 4
  %220 = load i32, i32* %45, align 4
  %221 = add nsw i32 %220, -4
  %222 = icmp sgt i32 %219, %221
  br i1 %222, label %211, label %215

223:                                              ; preds = %211, %223
  %224 = phi i32 [ %227, %223 ], [ %213, %211 ]
  %225 = load i32, i32* %102, align 4
  %226 = add nsw i32 %225, %224
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %10, %"struct.gemmlowp::OutputPipelineExecutor.645"* nonnull dereferenceable(32) %15, %"class.gemmlowp::MatrixMap.479"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %11, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorDup"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %7, i32 %3, i32 %224, i32 %130, i32 %226, i32 %132, i32 %226, i32 %132)
  %227 = add nuw nsw i32 %224, 1
  %228 = load i32, i32* %45, align 4
  %229 = icmp slt i32 %227, %228
  br i1 %229, label %223, label %230

230:                                              ; preds = %223, %211
  %231 = phi i32 [ %212, %211 ], [ %228, %223 ]
  %232 = add nuw nsw i32 %130, 4
  %233 = load i32, i32* %51, align 4
  %234 = add nsw i32 %233, -4
  %235 = icmp sgt i32 %232, %234
  br i1 %235, label %104, label %128

236:                                              ; preds = %108, %383
  %237 = phi i32 [ %127, %108 ], [ %384, %383 ]
  %238 = phi i64 [ %126, %108 ], [ %385, %383 ]
  %239 = load i32, i32* %109, align 4
  %240 = trunc i64 %238 to i32
  %241 = add nsw i32 %239, %240
  %242 = load i32*, i32** %19, align 8
  %243 = load i32, i32* %22, align 8
  %244 = mul nsw i32 %243, %240
  %245 = sext i32 %244 to i64
  %246 = load i32*, i32** %43, align 8
  %247 = bitcast i32* %246 to i8*
  call void @llvm.prefetch(i8* %247, i32 0, i32 3, i32 1) #19
  %248 = getelementptr inbounds i32, i32* %246, i64 4
  %249 = bitcast i32* %248 to i8*
  call void @llvm.prefetch(i8* %249, i32 0, i32 3, i32 1) #19
  %250 = getelementptr inbounds i32, i32* %242, i64 %245
  %251 = bitcast i32* %250 to i8*
  call void @llvm.prefetch(i8* %251, i32 0, i32 3, i32 1) #19
  %252 = getelementptr inbounds i32, i32* %250, i64 4
  %253 = bitcast i32* %252 to i8*
  call void @llvm.prefetch(i8* %253, i32 0, i32 3, i32 1) #19
  %254 = icmp slt i32 %237, 8
  br i1 %254, label %257, label %262

255:                                              ; preds = %262
  %256 = trunc i64 %270 to i32
  br label %257

257:                                              ; preds = %255, %236
  %258 = phi i32 [ %237, %236 ], [ %282, %255 ]
  %259 = phi i32 [ 0, %236 ], [ %256, %255 ]
  %260 = add nsw i32 %258, -4
  %261 = icmp sgt i32 %259, %260
  br i1 %261, label %290, label %296

262:                                              ; preds = %236, %286
  %263 = phi i32* [ %289, %286 ], [ %246, %236 ]
  %264 = phi i32 [ %288, %286 ], [ %243, %236 ]
  %265 = phi i32* [ %287, %286 ], [ %242, %236 ]
  %266 = phi i64 [ %270, %286 ], [ 0, %236 ]
  %267 = load i32, i32* %110, align 4
  %268 = trunc i64 %266 to i32
  %269 = add nsw i32 %267, %268
  %270 = add nuw i64 %266, 8
  %271 = mul nsw i32 %264, %240
  %272 = sext i32 %271 to i64
  %273 = getelementptr inbounds i32, i32* %263, i64 %270
  %274 = bitcast i32* %273 to i8*
  call void @llvm.prefetch(i8* %274, i32 0, i32 3, i32 1) #19
  %275 = getelementptr inbounds i32, i32* %273, i64 4
  %276 = bitcast i32* %275 to i8*
  call void @llvm.prefetch(i8* %276, i32 0, i32 3, i32 1) #19
  %277 = getelementptr inbounds i32, i32* %265, i64 %270
  %278 = getelementptr inbounds i32, i32* %277, i64 %272
  %279 = bitcast i32* %278 to i8*
  call void @llvm.prefetch(i8* %279, i32 0, i32 3, i32 1) #19
  %280 = getelementptr inbounds i32, i32* %278, i64 4
  %281 = bitcast i32* %280 to i8*
  call void @llvm.prefetch(i8* %281, i32 0, i32 3, i32 1) #19
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %10, %"struct.gemmlowp::OutputPipelineExecutor.638"* nonnull dereferenceable(32) %14, %"class.gemmlowp::MatrixMap.479"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %11, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorDup"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %7, i32 %3, i32 %268, i32 %240, i32 %269, i32 %241, i32 %269, i32 %241)
  %282 = load i32, i32* %45, align 4
  %283 = add nsw i32 %282, -8
  %284 = trunc i64 %270 to i32
  %285 = icmp slt i32 %283, %284
  br i1 %285, label %255, label %286

286:                                              ; preds = %262
  %287 = load i32*, i32** %19, align 8
  %288 = load i32, i32* %22, align 8
  %289 = load i32*, i32** %43, align 8
  br label %262

290:                                              ; preds = %296, %257
  %291 = phi i32 [ %258, %257 ], [ %301, %296 ]
  %292 = phi i32 [ %259, %257 ], [ %300, %296 ]
  %293 = icmp slt i32 %292, %291
  br i1 %293, label %294, label %383

294:                                              ; preds = %290
  %295 = zext i32 %292 to i64
  br label %304

296:                                              ; preds = %257, %296
  %297 = phi i32 [ %300, %296 ], [ %259, %257 ]
  %298 = load i32, i32* %110, align 4
  %299 = add nsw i32 %298, %297
  call void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* nonnull dereferenceable(24) %10, %"struct.gemmlowp::OutputPipelineExecutor.631"* nonnull dereferenceable(32) %13, %"class.gemmlowp::MatrixMap.479"* %0, %"class.gemmlowp::VectorMap"* nonnull dereferenceable(16) %11, %"class.gemmlowp::VectorMap.201"* nonnull dereferenceable(16) %12, %"class.gemmlowp::VectorDup"* dereferenceable(8) %6, %"class.gemmlowp::VectorDup.194"* dereferenceable(8) %7, i32 %3, i32 %297, i32 %240, i32 %299, i32 %241, i32 %299, i32 %241)
  %300 = add nuw nsw i32 %297, 4
  %301 = load i32, i32* %45, align 4
  %302 = add nsw i32 %301, -4
  %303 = icmp sgt i32 %300, %302
  br i1 %303, label %290, label %296

304:                                              ; preds = %294, %351
  %305 = phi i64 [ %295, %294 ], [ %379, %351 ]
  %306 = load i32, i32* %110, align 4
  %307 = trunc i64 %305 to i32
  %308 = add nsw i32 %306, %307
  %309 = load i32*, i32** %19, align 8
  %310 = load i32, i32* %22, align 8
  %311 = getelementptr inbounds i32, i32* %309, i64 %305
  %312 = mul nsw i32 %310, %240
  %313 = sext i32 %312 to i64
  %314 = getelementptr inbounds i32, i32* %311, i64 %313
  %315 = load i32, i32* %314, align 4
  %316 = load i32*, i32** %43, align 8
  %317 = getelementptr inbounds i32, i32* %316, i64 %305
  %318 = load i32, i32* %317, align 4
  %319 = load i32*, i32** %49, align 8
  %320 = getelementptr inbounds i32, i32* %319, i64 %238
  %321 = load i32, i32* %320, align 4
  %322 = load i32, i32* %111, align 4
  %323 = load i32, i32* %112, align 4
  %324 = mul nsw i32 %323, %318
  %325 = add nsw i32 %324, %315
  %326 = mul nsw i32 %323, %3
  %327 = add nsw i32 %326, %321
  %328 = mul nsw i32 %327, %322
  %329 = add nsw i32 %325, %328
  %330 = load i32, i32* %113, align 4
  %331 = sext i32 %329 to i64
  %332 = mul nsw i64 %331, %115
  %333 = icmp slt i64 %332, 2147483647
  %334 = select i1 %333, i64 %332, i64 2147483647
  %335 = icmp sgt i64 %334, -2147483648
  %336 = select i1 %335, i64 %334, i64 -2147483648
  %337 = trunc i64 %336 to i32
  %338 = load i32, i32* %116, align 4
  %339 = icmp ne i32 %338, %337
  %340 = icmp ne i32 %337, -2147483648
  %341 = or i1 %339, %340
  br i1 %341, label %342, label %351

342:                                              ; preds = %304
  %343 = sext i32 %338 to i64
  %344 = select i1 %339, i64 %343, i64 %336
  %345 = mul nsw i64 %344, %336
  %346 = icmp sgt i64 %345, -1
  %347 = select i1 %346, i64 1073741824, i64 -1073741823
  %348 = add nsw i64 %347, %345
  %349 = sdiv i64 %348, 2147483648
  %350 = trunc i64 %349 to i32
  br label %351

351:                                              ; preds = %304, %342
  %352 = phi i32 [ %350, %342 ], [ 2147483647, %304 ]
  %353 = and i32 %352, %120
  %354 = lshr i32 %352, 31
  %355 = add nsw i32 %354, %121
  %356 = ashr i32 %352, %61
  %357 = icmp sgt i32 %353, %355
  %358 = zext i1 %357 to i32
  %359 = add i32 %356, %330
  %360 = add i32 %359, %358
  %361 = load i32, i32* %122, align 4
  %362 = load i32, i32* %123, align 4
  %363 = icmp sgt i32 %361, %360
  %364 = select i1 %363, i32 %361, i32 %360
  %365 = icmp slt i32 %362, %364
  %366 = select i1 %365, i32 %362, i32 %364
  %367 = icmp sgt i32 %366, -32768
  %368 = select i1 %367, i32 %366, i32 -32768
  %369 = icmp slt i32 %368, 32767
  %370 = select i1 %369, i32 %368, i32 32767
  %371 = trunc i32 %370 to i16
  %372 = sext i32 %308 to i64
  %373 = load i16*, i16** %124, align 8
  %374 = getelementptr inbounds i16, i16* %373, i64 %372
  %375 = load i32, i32* %125, align 8
  %376 = mul nsw i32 %375, %241
  %377 = sext i32 %376 to i64
  %378 = getelementptr inbounds i16, i16* %374, i64 %377
  store i16 %371, i16* %378, align 2
  %379 = add nuw nsw i64 %305, 1
  %380 = load i32, i32* %45, align 4
  %381 = trunc i64 %379 to i32
  %382 = icmp sgt i32 %380, %381
  br i1 %382, label %304, label %383

383:                                              ; preds = %351, %290
  %384 = phi i32 [ %291, %290 ], [ %380, %351 ]
  %385 = add nuw nsw i64 %238, 1
  %386 = load i32, i32* %51, align 4
  %387 = trunc i64 %385 to i32
  %388 = icmp sgt i32 %386, %387
  br i1 %388, label %236, label %389

389:                                              ; preds = %383, %104
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %91) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %84) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %77) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %70) #19
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %63) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %48) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %42) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %18) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.659"* dereferenceable(32), %"class.gemmlowp::MatrixMap.479"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.561", align 8
  %16 = alloca %"struct.gemmlowp::RegisterBlock.561", align 2
  %17 = alloca %"struct.gemmlowp::RegisterBlock.302", align 16
  %18 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %18) #19
  %19 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %20 = sext i32 %8 to i64
  %21 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %22 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %22, i8 -86, i64 128, i1 false)
  %23 = load i32*, i32** %19, align 8, !noalias !1911
  %24 = getelementptr inbounds i32, i32* %23, i64 %20
  %25 = load i32, i32* %21, align 8, !noalias !1911
  %26 = mul nsw i32 %25, %9
  %27 = sext i32 %26 to i64
  %28 = getelementptr inbounds i32, i32* %24, i64 %27
  %29 = getelementptr inbounds i32, i32* %28, i64 1
  %30 = load i32, i32* %28, align 4
  %31 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 0
  store i32 %30, i32* %31, align 16, !alias.scope !1911
  %32 = getelementptr inbounds i32, i32* %29, i64 1
  %33 = load i32, i32* %29, align 4
  %34 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 1
  store i32 %33, i32* %34, align 4, !alias.scope !1911
  %35 = getelementptr inbounds i32, i32* %32, i64 1
  %36 = load i32, i32* %32, align 4
  %37 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 2
  store i32 %36, i32* %37, align 8, !alias.scope !1911
  %38 = getelementptr inbounds i32, i32* %35, i64 1
  %39 = load i32, i32* %35, align 4
  %40 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 3
  store i32 %39, i32* %40, align 4, !alias.scope !1911
  %41 = getelementptr inbounds i32, i32* %38, i64 1
  %42 = load i32, i32* %38, align 4
  %43 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 4
  store i32 %42, i32* %43, align 16, !alias.scope !1911
  %44 = getelementptr inbounds i32, i32* %41, i64 1
  %45 = load i32, i32* %41, align 4
  %46 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 5
  store i32 %45, i32* %46, align 4, !alias.scope !1911
  %47 = getelementptr inbounds i32, i32* %44, i64 1
  %48 = load i32, i32* %44, align 4
  %49 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 6
  store i32 %48, i32* %49, align 8, !alias.scope !1911
  %50 = load i32, i32* %47, align 4
  %51 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 7
  store i32 %50, i32* %51, align 4, !alias.scope !1911
  %52 = add nsw i32 %9, 1
  %53 = mul nsw i32 %25, %52
  %54 = sext i32 %53 to i64
  %55 = getelementptr inbounds i32, i32* %24, i64 %54
  %56 = getelementptr inbounds i32, i32* %55, i64 1
  %57 = load i32, i32* %55, align 4
  %58 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 8
  store i32 %57, i32* %58, align 16, !alias.scope !1911
  %59 = getelementptr inbounds i32, i32* %56, i64 1
  %60 = load i32, i32* %56, align 4
  %61 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 9
  store i32 %60, i32* %61, align 4, !alias.scope !1911
  %62 = getelementptr inbounds i32, i32* %59, i64 1
  %63 = load i32, i32* %59, align 4
  %64 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 10
  store i32 %63, i32* %64, align 8, !alias.scope !1911
  %65 = getelementptr inbounds i32, i32* %62, i64 1
  %66 = load i32, i32* %62, align 4
  %67 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 11
  store i32 %66, i32* %67, align 4, !alias.scope !1911
  %68 = getelementptr inbounds i32, i32* %65, i64 1
  %69 = load i32, i32* %65, align 4
  %70 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 12
  store i32 %69, i32* %70, align 16, !alias.scope !1911
  %71 = getelementptr inbounds i32, i32* %68, i64 1
  %72 = load i32, i32* %68, align 4
  %73 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 13
  store i32 %72, i32* %73, align 4, !alias.scope !1911
  %74 = getelementptr inbounds i32, i32* %71, i64 1
  %75 = load i32, i32* %71, align 4
  %76 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 14
  store i32 %75, i32* %76, align 8, !alias.scope !1911
  %77 = load i32, i32* %74, align 4
  %78 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 15
  store i32 %77, i32* %78, align 4, !alias.scope !1911
  %79 = add nsw i32 %9, 2
  %80 = mul nsw i32 %25, %79
  %81 = sext i32 %80 to i64
  %82 = getelementptr inbounds i32, i32* %24, i64 %81
  %83 = getelementptr inbounds i32, i32* %82, i64 1
  %84 = load i32, i32* %82, align 4
  %85 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 16
  store i32 %84, i32* %85, align 16, !alias.scope !1911
  %86 = getelementptr inbounds i32, i32* %83, i64 1
  %87 = load i32, i32* %83, align 4
  %88 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 17
  store i32 %87, i32* %88, align 4, !alias.scope !1911
  %89 = getelementptr inbounds i32, i32* %86, i64 1
  %90 = load i32, i32* %86, align 4
  %91 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 18
  store i32 %90, i32* %91, align 8, !alias.scope !1911
  %92 = getelementptr inbounds i32, i32* %89, i64 1
  %93 = load i32, i32* %89, align 4
  %94 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 19
  store i32 %93, i32* %94, align 4, !alias.scope !1911
  %95 = getelementptr inbounds i32, i32* %92, i64 1
  %96 = load i32, i32* %92, align 4
  %97 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 20
  store i32 %96, i32* %97, align 16, !alias.scope !1911
  %98 = getelementptr inbounds i32, i32* %95, i64 1
  %99 = load i32, i32* %95, align 4
  %100 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 21
  store i32 %99, i32* %100, align 4, !alias.scope !1911
  %101 = getelementptr inbounds i32, i32* %98, i64 1
  %102 = load i32, i32* %98, align 4
  %103 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 22
  store i32 %102, i32* %103, align 8, !alias.scope !1911
  %104 = load i32, i32* %101, align 4
  %105 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 23
  store i32 %104, i32* %105, align 4, !alias.scope !1911
  %106 = add nsw i32 %9, 3
  %107 = mul nsw i32 %25, %106
  %108 = sext i32 %107 to i64
  %109 = getelementptr inbounds i32, i32* %24, i64 %108
  %110 = getelementptr inbounds i32, i32* %109, i64 1
  %111 = load i32, i32* %109, align 4
  %112 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 24
  store i32 %111, i32* %112, align 16, !alias.scope !1911
  %113 = getelementptr inbounds i32, i32* %110, i64 1
  %114 = load i32, i32* %110, align 4
  %115 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 25
  store i32 %114, i32* %115, align 4, !alias.scope !1911
  %116 = getelementptr inbounds i32, i32* %113, i64 1
  %117 = load i32, i32* %113, align 4
  %118 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 26
  store i32 %117, i32* %118, align 8, !alias.scope !1911
  %119 = getelementptr inbounds i32, i32* %116, i64 1
  %120 = load i32, i32* %116, align 4
  %121 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 27
  store i32 %120, i32* %121, align 4, !alias.scope !1911
  %122 = getelementptr inbounds i32, i32* %119, i64 1
  %123 = load i32, i32* %119, align 4
  %124 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 28
  store i32 %123, i32* %124, align 16, !alias.scope !1911
  %125 = getelementptr inbounds i32, i32* %122, i64 1
  %126 = load i32, i32* %122, align 4
  %127 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 29
  store i32 %126, i32* %127, align 4, !alias.scope !1911
  %128 = getelementptr inbounds i32, i32* %125, i64 1
  %129 = load i32, i32* %125, align 4
  %130 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 30
  store i32 %129, i32* %130, align 8, !alias.scope !1911
  %131 = load i32, i32* %128, align 4
  %132 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.302", %"struct.gemmlowp::RegisterBlock.302"* %17, i64 0, i32 0, i32 0, i64 31
  store i32 %131, i32* %132, align 4, !alias.scope !1911
  %133 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %134 = load i32*, i32** %133, align 8, !noalias !1914
  %135 = getelementptr i32, i32* %134, i64 %20
  %136 = bitcast i32* %135 to <4 x i32>*
  %137 = load <4 x i32>, <4 x i32>* %136, align 4
  %138 = getelementptr inbounds i32, i32* %135, i64 4
  %139 = bitcast i32* %138 to <4 x i32>*
  %140 = load <4 x i32>, <4 x i32>* %139, align 4
  %141 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %142 = load i32*, i32** %141, align 8
  %143 = sext i32 %9 to i64
  %144 = getelementptr i32, i32* %142, i64 %143
  %145 = bitcast i32* %144 to i64*
  %146 = load i64, i64* %145, align 4
  %147 = getelementptr inbounds i32, i32* %144, i64 2
  %148 = bitcast i32* %147 to i64*
  %149 = load i64, i64* %148, align 4
  %150 = lshr i64 %146, 32
  %151 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %152 = load i32, i32* %151, align 4
  %153 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %6, i64 0, i32 0
  %154 = load i32, i32* %153, align 4
  %155 = insertelement <4 x i32> undef, i32 %154, i32 0
  %156 = shufflevector <4 x i32> %155, <4 x i32> undef, <4 x i32> zeroinitializer
  %157 = mul nsw <4 x i32> %156, %137
  %158 = mul nsw <4 x i32> %156, %140
  %159 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to <4 x i32>*
  %160 = load <4 x i32>, <4 x i32>* %159, align 16
  %161 = add nsw <4 x i32> %160, %157
  %162 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to <4 x i32>*
  store <4 x i32> %161, <4 x i32>* %162, align 16
  %163 = bitcast i32* %43 to <4 x i32>*
  %164 = load <4 x i32>, <4 x i32>* %163, align 16
  %165 = add nsw <4 x i32> %164, %158
  %166 = bitcast i32* %43 to <4 x i32>*
  store <4 x i32> %165, <4 x i32>* %166, align 16
  %167 = bitcast i32* %58 to <4 x i32>*
  %168 = load <4 x i32>, <4 x i32>* %167, align 16
  %169 = add nsw <4 x i32> %168, %157
  %170 = bitcast i32* %58 to <4 x i32>*
  store <4 x i32> %169, <4 x i32>* %170, align 16
  %171 = bitcast i32* %70 to <4 x i32>*
  %172 = load <4 x i32>, <4 x i32>* %171, align 16
  %173 = add nsw <4 x i32> %172, %158
  %174 = bitcast i32* %70 to <4 x i32>*
  store <4 x i32> %173, <4 x i32>* %174, align 16
  %175 = bitcast i32* %85 to <4 x i32>*
  %176 = load <4 x i32>, <4 x i32>* %175, align 16
  %177 = add nsw <4 x i32> %176, %157
  %178 = bitcast i32* %85 to <4 x i32>*
  store <4 x i32> %177, <4 x i32>* %178, align 16
  %179 = bitcast i32* %97 to <4 x i32>*
  %180 = load <4 x i32>, <4 x i32>* %179, align 16
  %181 = add nsw <4 x i32> %180, %158
  %182 = bitcast i32* %97 to <4 x i32>*
  store <4 x i32> %181, <4 x i32>* %182, align 16
  %183 = bitcast i32* %112 to <4 x i32>*
  %184 = load <4 x i32>, <4 x i32>* %183, align 16
  %185 = add nsw <4 x i32> %184, %157
  %186 = bitcast i32* %112 to <4 x i32>*
  store <4 x i32> %185, <4 x i32>* %186, align 16
  %187 = bitcast i32* %124 to <4 x i32>*
  %188 = load <4 x i32>, <4 x i32>* %187, align 16
  %189 = add nsw <4 x i32> %188, %158
  %190 = bitcast i32* %124 to <4 x i32>*
  store <4 x i32> %189, <4 x i32>* %190, align 16
  %191 = trunc i64 %146 to i32
  %192 = trunc i64 %150 to i32
  %193 = mul nsw i32 %154, %7
  %194 = add nsw i32 %193, %191
  %195 = add nsw i32 %193, %192
  %196 = trunc i64 %149 to i32
  %197 = add nsw i32 %193, %196
  %198 = lshr i64 %149, 32
  %199 = trunc i64 %198 to i32
  %200 = add nsw i32 %193, %199
  %201 = mul nsw i32 %194, %152
  %202 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to <4 x i32>*
  %203 = load <4 x i32>, <4 x i32>* %202, align 16
  %204 = insertelement <4 x i32> undef, i32 %201, i32 0
  %205 = shufflevector <4 x i32> %204, <4 x i32> undef, <4 x i32> zeroinitializer
  %206 = add nsw <4 x i32> %203, %205
  %207 = bitcast %"struct.gemmlowp::RegisterBlock.302"* %17 to <4 x i32>*
  store <4 x i32> %206, <4 x i32>* %207, align 16
  %208 = bitcast i32* %43 to <4 x i32>*
  %209 = load <4 x i32>, <4 x i32>* %208, align 16
  %210 = add nsw <4 x i32> %209, %205
  %211 = bitcast i32* %43 to <4 x i32>*
  store <4 x i32> %210, <4 x i32>* %211, align 16
  %212 = mul nsw i32 %195, %152
  %213 = bitcast i32* %58 to <4 x i32>*
  %214 = load <4 x i32>, <4 x i32>* %213, align 16
  %215 = insertelement <4 x i32> undef, i32 %212, i32 0
  %216 = shufflevector <4 x i32> %215, <4 x i32> undef, <4 x i32> zeroinitializer
  %217 = add nsw <4 x i32> %214, %216
  %218 = bitcast i32* %58 to <4 x i32>*
  store <4 x i32> %217, <4 x i32>* %218, align 16
  %219 = bitcast i32* %70 to <4 x i32>*
  %220 = load <4 x i32>, <4 x i32>* %219, align 16
  %221 = add nsw <4 x i32> %220, %216
  %222 = bitcast i32* %70 to <4 x i32>*
  store <4 x i32> %221, <4 x i32>* %222, align 16
  %223 = mul nsw i32 %197, %152
  %224 = bitcast i32* %85 to <4 x i32>*
  %225 = load <4 x i32>, <4 x i32>* %224, align 16
  %226 = insertelement <4 x i32> undef, i32 %223, i32 0
  %227 = shufflevector <4 x i32> %226, <4 x i32> undef, <4 x i32> zeroinitializer
  %228 = add nsw <4 x i32> %225, %227
  %229 = bitcast i32* %85 to <4 x i32>*
  store <4 x i32> %228, <4 x i32>* %229, align 16
  %230 = bitcast i32* %97 to <4 x i32>*
  %231 = load <4 x i32>, <4 x i32>* %230, align 16
  %232 = add nsw <4 x i32> %231, %227
  %233 = bitcast i32* %97 to <4 x i32>*
  store <4 x i32> %232, <4 x i32>* %233, align 16
  %234 = mul nsw i32 %200, %152
  %235 = bitcast i32* %112 to <4 x i32>*
  %236 = load <4 x i32>, <4 x i32>* %235, align 16
  %237 = insertelement <4 x i32> undef, i32 %234, i32 0
  %238 = shufflevector <4 x i32> %237, <4 x i32> undef, <4 x i32> zeroinitializer
  %239 = add nsw <4 x i32> %236, %238
  %240 = bitcast i32* %112 to <4 x i32>*
  store <4 x i32> %239, <4 x i32>* %240, align 16
  %241 = bitcast i32* %124 to <4 x i32>*
  %242 = load <4 x i32>, <4 x i32>* %241, align 16
  %243 = add nsw <4 x i32> %242, %238
  %244 = bitcast i32* %124 to <4 x i32>*
  store <4 x i32> %243, <4 x i32>* %244, align 16
  %245 = bitcast %"struct.gemmlowp::RegisterBlock.561"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %245) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 2 %245, i8 -86, i64 64, i1 false) #19
  %246 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.659", %"struct.gemmlowp::OutputPipelineExecutor.659"* %1, i64 0, i32 0
  call void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalES8_ii(%"struct.gemmlowp::RegisterBlock.561"* nonnull sret %16, %"struct.gemmlowp::OutputPipelineEvalImpl.660"* %246, %"struct.gemmlowp::RegisterBlock.302"* nonnull byval(%"struct.gemmlowp::RegisterBlock.302") align 8 %17, i32 %10, i32 %11) #19
  %247 = bitcast %"struct.gemmlowp::RegisterBlock.561"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %247) #19
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %247, i8* nonnull align 2 %245, i64 64, i1 false) #19
  %248 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %2, i64 0, i32 0
  %249 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %2, i64 0, i32 3
  %250 = sext i32 %13 to i64
  %251 = sext i32 %12 to i64
  %252 = add nsw i64 %250, 1
  %253 = add nsw i64 %250, 2
  %254 = add nsw i64 %250, 3
  br label %255

255:                                              ; preds = %255, %14
  %256 = phi i64 [ 0, %14 ], [ %293, %255 ]
  %257 = add nsw i64 %256, %251
  %258 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.561", %"struct.gemmlowp::RegisterBlock.561"* %15, i64 0, i32 0, i32 0, i64 %256
  %259 = load i16, i16* %258, align 2
  %260 = load i16*, i16** %248, align 8
  %261 = getelementptr inbounds i16, i16* %260, i64 %257
  %262 = load i32, i32* %249, align 8
  %263 = sext i32 %262 to i64
  %264 = mul nsw i64 %263, %250
  %265 = getelementptr inbounds i16, i16* %261, i64 %264
  store i16 %259, i16* %265, align 2
  %266 = add nuw nsw i64 %256, 8
  %267 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.561", %"struct.gemmlowp::RegisterBlock.561"* %15, i64 0, i32 0, i32 0, i64 %266
  %268 = load i16, i16* %267, align 2
  %269 = load i16*, i16** %248, align 8
  %270 = getelementptr inbounds i16, i16* %269, i64 %257
  %271 = load i32, i32* %249, align 8
  %272 = sext i32 %271 to i64
  %273 = mul nsw i64 %252, %272
  %274 = getelementptr inbounds i16, i16* %270, i64 %273
  store i16 %268, i16* %274, align 2
  %275 = add nuw nsw i64 %256, 16
  %276 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.561", %"struct.gemmlowp::RegisterBlock.561"* %15, i64 0, i32 0, i32 0, i64 %275
  %277 = load i16, i16* %276, align 2
  %278 = load i16*, i16** %248, align 8
  %279 = getelementptr inbounds i16, i16* %278, i64 %257
  %280 = load i32, i32* %249, align 8
  %281 = sext i32 %280 to i64
  %282 = mul nsw i64 %253, %281
  %283 = getelementptr inbounds i16, i16* %279, i64 %282
  store i16 %277, i16* %283, align 2
  %284 = add nuw nsw i64 %256, 24
  %285 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.561", %"struct.gemmlowp::RegisterBlock.561"* %15, i64 0, i32 0, i32 0, i64 %284
  %286 = load i16, i16* %285, align 2
  %287 = load i16*, i16** %248, align 8
  %288 = getelementptr inbounds i16, i16* %287, i64 %257
  %289 = load i32, i32* %249, align 8
  %290 = sext i32 %289 to i64
  %291 = mul nsw i64 %254, %290
  %292 = getelementptr inbounds i16, i16* %288, i64 %291
  store i16 %286, i16* %292, align 2
  %293 = add nuw nsw i64 %256, 1
  %294 = icmp eq i64 %293, 8
  br i1 %294, label %295, label %255

295:                                              ; preds = %255
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %247) #19
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %245) #19
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %18) #19
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.652"* dereferenceable(32), %"class.gemmlowp::MatrixMap.479"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.312", align 8
  %16 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %17 = sext i32 %8 to i64
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %19 = load i32*, i32** %16, align 8, !noalias !1919
  %20 = getelementptr inbounds i32, i32* %19, i64 %17
  %21 = load i32, i32* %18, align 8, !noalias !1919
  %22 = mul nsw i32 %21, %9
  %23 = sext i32 %22 to i64
  %24 = getelementptr inbounds i32, i32* %20, i64 %23
  %25 = getelementptr inbounds i32, i32* %24, i64 1
  %26 = load i32, i32* %24, align 4, !noalias !1919
  %27 = getelementptr inbounds i32, i32* %25, i64 1
  %28 = load i32, i32* %25, align 4, !noalias !1919
  %29 = getelementptr inbounds i32, i32* %27, i64 1
  %30 = load i32, i32* %27, align 4, !noalias !1919
  %31 = load i32, i32* %29, align 4, !noalias !1919
  %32 = add nsw i32 %9, 1
  %33 = mul nsw i32 %21, %32
  %34 = sext i32 %33 to i64
  %35 = getelementptr inbounds i32, i32* %20, i64 %34
  %36 = getelementptr inbounds i32, i32* %35, i64 1
  %37 = load i32, i32* %35, align 4, !noalias !1919
  %38 = getelementptr inbounds i32, i32* %36, i64 1
  %39 = load i32, i32* %36, align 4, !noalias !1919
  %40 = getelementptr inbounds i32, i32* %38, i64 1
  %41 = load i32, i32* %38, align 4, !noalias !1919
  %42 = load i32, i32* %40, align 4, !noalias !1919
  %43 = add nsw i32 %9, 2
  %44 = mul nsw i32 %21, %43
  %45 = sext i32 %44 to i64
  %46 = getelementptr inbounds i32, i32* %20, i64 %45
  %47 = getelementptr inbounds i32, i32* %46, i64 1
  %48 = load i32, i32* %46, align 4, !noalias !1919
  %49 = getelementptr inbounds i32, i32* %47, i64 1
  %50 = load i32, i32* %47, align 4, !noalias !1919
  %51 = getelementptr inbounds i32, i32* %49, i64 1
  %52 = load i32, i32* %49, align 4, !noalias !1919
  %53 = load i32, i32* %51, align 4, !noalias !1919
  %54 = add nsw i32 %9, 3
  %55 = mul nsw i32 %21, %54
  %56 = sext i32 %55 to i64
  %57 = getelementptr inbounds i32, i32* %20, i64 %56
  %58 = getelementptr inbounds i32, i32* %57, i64 1
  %59 = load i32, i32* %57, align 4, !noalias !1919
  %60 = getelementptr inbounds i32, i32* %58, i64 1
  %61 = load i32, i32* %58, align 4, !noalias !1919
  %62 = getelementptr inbounds i32, i32* %60, i64 1
  %63 = load i32, i32* %60, align 4, !noalias !1919
  %64 = load i32, i32* %62, align 4, !noalias !1919
  %65 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %66 = load i32*, i32** %65, align 8
  %67 = getelementptr i32, i32* %66, i64 %17
  %68 = bitcast i32* %67 to i64*
  %69 = load i64, i64* %68, align 4
  %70 = getelementptr inbounds i32, i32* %67, i64 2
  %71 = bitcast i32* %70 to i64*
  %72 = load i64, i64* %71, align 4
  %73 = trunc i64 %69 to i32
  %74 = lshr i64 %69, 32
  %75 = trunc i64 %74 to i32
  %76 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %77 = load i32*, i32** %76, align 8
  %78 = sext i32 %9 to i64
  %79 = getelementptr i32, i32* %77, i64 %78
  %80 = bitcast i32* %79 to i64*
  %81 = load i64, i64* %80, align 4
  %82 = getelementptr inbounds i32, i32* %79, i64 2
  %83 = bitcast i32* %82 to i64*
  %84 = load i64, i64* %83, align 4
  %85 = trunc i64 %81 to i32
  %86 = lshr i64 %81, 32
  %87 = trunc i64 %86 to i32
  %88 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %89 = load i32, i32* %88, align 4
  %90 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %6, i64 0, i32 0
  %91 = load i32, i32* %90, align 4
  %92 = mul nsw i32 %91, %73
  %93 = add nsw i32 %92, %26
  %94 = mul nsw i32 %91, %75
  %95 = add nsw i32 %94, %28
  %96 = trunc i64 %72 to i32
  %97 = mul nsw i32 %91, %96
  %98 = add nsw i32 %97, %30
  %99 = lshr i64 %72, 32
  %100 = trunc i64 %99 to i32
  %101 = mul nsw i32 %91, %100
  %102 = add nsw i32 %101, %31
  %103 = add nsw i32 %92, %37
  %104 = add nsw i32 %94, %39
  %105 = add nsw i32 %97, %41
  %106 = add nsw i32 %101, %42
  %107 = add nsw i32 %92, %48
  %108 = add nsw i32 %94, %50
  %109 = add nsw i32 %97, %52
  %110 = add nsw i32 %101, %53
  %111 = add nsw i32 %92, %59
  %112 = add nsw i32 %94, %61
  %113 = add nsw i32 %97, %63
  %114 = add nsw i32 %101, %64
  %115 = mul nsw i32 %91, %7
  %116 = add nsw i32 %115, %85
  %117 = add nsw i32 %115, %87
  %118 = trunc i64 %84 to i32
  %119 = add nsw i32 %115, %118
  %120 = lshr i64 %84, 32
  %121 = trunc i64 %120 to i32
  %122 = add nsw i32 %115, %121
  %123 = mul nsw i32 %116, %89
  %124 = add nsw i32 %93, %123
  %125 = add nsw i32 %95, %123
  %126 = add nsw i32 %98, %123
  %127 = add nsw i32 %102, %123
  %128 = mul nsw i32 %117, %89
  %129 = add nsw i32 %103, %128
  %130 = add nsw i32 %104, %128
  %131 = add nsw i32 %105, %128
  %132 = add nsw i32 %106, %128
  %133 = mul nsw i32 %119, %89
  %134 = add nsw i32 %107, %133
  %135 = add nsw i32 %108, %133
  %136 = add nsw i32 %109, %133
  %137 = add nsw i32 %110, %133
  %138 = mul nsw i32 %122, %89
  %139 = add nsw i32 %111, %138
  %140 = add nsw i32 %112, %138
  %141 = add nsw i32 %113, %138
  %142 = add nsw i32 %114, %138
  %143 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 0
  store i32 %124, i32* %143, align 8
  %144 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 1
  store i32 %125, i32* %144, align 4
  %145 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 2
  store i32 %126, i32* %145, align 8
  %146 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 3
  store i32 %127, i32* %146, align 4
  %147 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 4
  store i32 %129, i32* %147, align 8
  %148 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 5
  store i32 %130, i32* %148, align 4
  %149 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 6
  store i32 %131, i32* %149, align 8
  %150 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 7
  store i32 %132, i32* %150, align 4
  %151 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 8
  store i32 %134, i32* %151, align 8
  %152 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 9
  store i32 %135, i32* %152, align 4
  %153 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 10
  store i32 %136, i32* %153, align 8
  %154 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 11
  store i32 %137, i32* %154, align 4
  %155 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 12
  store i32 %139, i32* %155, align 8
  %156 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 13
  store i32 %140, i32* %156, align 4
  %157 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 14
  store i32 %141, i32* %157, align 8
  %158 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.312", %"struct.gemmlowp::RegisterBlock.312"* %15, i64 0, i32 0, i32 0, i64 15
  store i32 %142, i32* %158, align 4
  tail call void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi4ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE0EEEEEvS8_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.652"* %1, %"struct.gemmlowp::RegisterBlock.312"* nonnull byval(%"struct.gemmlowp::RegisterBlock.312") align 8 %15, %"class.gemmlowp::MatrixMap.479"* %2, i32 %10, i32 %11, i32 %12, i32 %13)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi1ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.645"* dereferenceable(32), %"class.gemmlowp::MatrixMap.479"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %16 = sext i32 %8 to i64
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %18 = load i32*, i32** %15, align 8
  %19 = getelementptr inbounds i32, i32* %18, i64 %16
  %20 = load i32, i32* %17, align 8
  %21 = mul nsw i32 %20, %9
  %22 = sext i32 %21 to i64
  %23 = getelementptr inbounds i32, i32* %19, i64 %22
  %24 = load i32, i32* %23, align 4
  %25 = add nsw i32 %9, 1
  %26 = mul nsw i32 %20, %25
  %27 = sext i32 %26 to i64
  %28 = getelementptr inbounds i32, i32* %19, i64 %27
  %29 = load i32, i32* %28, align 4
  %30 = add nsw i32 %9, 2
  %31 = mul nsw i32 %20, %30
  %32 = sext i32 %31 to i64
  %33 = getelementptr inbounds i32, i32* %19, i64 %32
  %34 = load i32, i32* %33, align 4
  %35 = add nsw i32 %9, 3
  %36 = mul nsw i32 %20, %35
  %37 = sext i32 %36 to i64
  %38 = getelementptr inbounds i32, i32* %19, i64 %37
  %39 = load i32, i32* %38, align 4
  %40 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %41 = load i32*, i32** %40, align 8
  %42 = getelementptr inbounds i32, i32* %41, i64 %16
  %43 = load i32, i32* %42, align 4
  %44 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %45 = load i32*, i32** %44, align 8
  %46 = sext i32 %9 to i64
  %47 = getelementptr i32, i32* %45, i64 %46
  %48 = bitcast i32* %47 to i64*
  %49 = load i64, i64* %48, align 4
  %50 = getelementptr inbounds i32, i32* %47, i64 2
  %51 = bitcast i32* %50 to i64*
  %52 = load i64, i64* %51, align 4
  %53 = trunc i64 %49 to i32
  %54 = lshr i64 %49, 32
  %55 = trunc i64 %54 to i32
  %56 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %57 = load i32, i32* %56, align 4
  %58 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %6, i64 0, i32 0
  %59 = load i32, i32* %58, align 4
  %60 = mul nsw i32 %59, %43
  %61 = add nsw i32 %60, %24
  %62 = add nsw i32 %60, %29
  %63 = add nsw i32 %60, %34
  %64 = add nsw i32 %60, %39
  %65 = mul nsw i32 %59, %7
  %66 = add nsw i32 %65, %53
  %67 = add nsw i32 %65, %55
  %68 = trunc i64 %52 to i32
  %69 = add nsw i32 %65, %68
  %70 = lshr i64 %52, 32
  %71 = trunc i64 %70 to i32
  %72 = add nsw i32 %65, %71
  %73 = mul nsw i32 %66, %57
  %74 = add nsw i32 %61, %73
  %75 = mul nsw i32 %67, %57
  %76 = add nsw i32 %62, %75
  %77 = mul nsw i32 %69, %57
  %78 = add nsw i32 %63, %77
  %79 = zext i32 %78 to i64
  %80 = mul nsw i32 %72, %57
  %81 = add nsw i32 %64, %80
  %82 = zext i32 %81 to i64
  %83 = shl nuw i64 %82, 32
  %84 = or i64 %83, %79
  %85 = zext i32 %76 to i64
  %86 = shl nuw i64 %85, 32
  %87 = zext i32 %74 to i64
  %88 = or i64 %86, %87
  %89 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.645", %"struct.gemmlowp::OutputPipelineExecutor.645"* %1, i64 0, i32 0, i32 0, i32 0
  %90 = tail call { i64, i64 } @_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi4EEEE4EvalES3_(%"struct.gemmlowp::OutputStageEvalBufferImpl.231"* %89, i64 %88, i64 %84) #19
  %91 = extractvalue { i64, i64 } %90, 0
  %92 = extractvalue { i64, i64 } %90, 1
  %93 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.645", %"struct.gemmlowp::OutputPipelineExecutor.645"* %1, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %94 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %93, align 8
  %95 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %94, i64 0, i32 0
  %96 = load i32, i32* %95, align 4
  %97 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %94, i64 0, i32 1
  %98 = load i32, i32* %97, align 4
  %99 = trunc i64 %91 to i32
  %100 = icmp sgt i32 %96, %99
  %101 = select i1 %100, i32 %96, i32 %99
  %102 = icmp slt i32 %98, %101
  %103 = select i1 %102, i32 %98, i32 %101
  %104 = lshr i64 %91, 32
  %105 = trunc i64 %104 to i32
  %106 = icmp sgt i32 %96, %105
  %107 = select i1 %106, i32 %96, i32 %105
  %108 = icmp slt i32 %98, %107
  %109 = select i1 %108, i32 %98, i32 %107
  %110 = trunc i64 %92 to i32
  %111 = icmp sgt i32 %96, %110
  %112 = select i1 %111, i32 %96, i32 %110
  %113 = icmp slt i32 %98, %112
  %114 = select i1 %113, i32 %98, i32 %112
  %115 = lshr i64 %92, 32
  %116 = trunc i64 %115 to i32
  %117 = icmp sgt i32 %96, %116
  %118 = select i1 %117, i32 %96, i32 %116
  %119 = icmp slt i32 %98, %118
  %120 = select i1 %119, i32 %98, i32 %118
  %121 = icmp sgt i32 %103, -32768
  %122 = select i1 %121, i32 %103, i32 -32768
  %123 = icmp slt i32 %122, 32767
  %124 = select i1 %123, i32 %122, i32 32767
  %125 = icmp sgt i32 %109, -32768
  %126 = select i1 %125, i32 %109, i32 -32768
  %127 = icmp slt i32 %126, 32767
  %128 = select i1 %127, i32 %126, i32 32767
  %129 = icmp sgt i32 %114, -32768
  %130 = select i1 %129, i32 %114, i32 -32768
  %131 = icmp slt i32 %130, 32767
  %132 = select i1 %131, i32 %130, i32 32767
  %133 = icmp sgt i32 %120, -32768
  %134 = select i1 %133, i32 %120, i32 -32768
  %135 = icmp slt i32 %134, 32767
  %136 = select i1 %135, i32 %134, i32 32767
  %137 = trunc i32 %124 to i16
  %138 = trunc i32 %128 to i16
  %139 = trunc i32 %132 to i16
  %140 = trunc i32 %136 to i16
  %141 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %2, i64 0, i32 0
  %142 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %2, i64 0, i32 3
  %143 = sext i32 %13 to i64
  %144 = sext i32 %12 to i64
  %145 = load i16*, i16** %141, align 8
  %146 = getelementptr inbounds i16, i16* %145, i64 %144
  %147 = load i32, i32* %142, align 8
  %148 = sext i32 %147 to i64
  %149 = mul nsw i64 %148, %143
  %150 = getelementptr inbounds i16, i16* %146, i64 %149
  store i16 %137, i16* %150, align 2
  %151 = add nsw i64 %143, 1
  %152 = load i16*, i16** %141, align 8
  %153 = getelementptr inbounds i16, i16* %152, i64 %144
  %154 = load i32, i32* %142, align 8
  %155 = sext i32 %154 to i64
  %156 = mul nsw i64 %151, %155
  %157 = getelementptr inbounds i16, i16* %153, i64 %156
  store i16 %138, i16* %157, align 2
  %158 = add nsw i64 %143, 2
  %159 = load i16*, i16** %141, align 8
  %160 = getelementptr inbounds i16, i16* %159, i64 %144
  %161 = load i32, i32* %142, align 8
  %162 = sext i32 %161 to i64
  %163 = mul nsw i64 %158, %162
  %164 = getelementptr inbounds i16, i16* %160, i64 %163
  store i16 %139, i16* %164, align 2
  %165 = add nsw i64 %143, 3
  %166 = load i16*, i16** %141, align 8
  %167 = getelementptr inbounds i16, i16* %166, i64 %144
  %168 = load i32, i32* %142, align 8
  %169 = sext i32 %168 to i64
  %170 = mul nsw i64 %165, %169
  %171 = getelementptr inbounds i16, i16* %167, i64 %170
  store i16 %140, i16* %171, align 2
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.638"* dereferenceable(32), %"class.gemmlowp::MatrixMap.479"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = alloca %"struct.gemmlowp::RegisterBlock.304", align 16
  %16 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %17 = sext i32 %8 to i64
  %18 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %19 = load i32*, i32** %16, align 8, !noalias !1924
  %20 = getelementptr inbounds i32, i32* %19, i64 %17
  %21 = load i32, i32* %18, align 8, !noalias !1924
  %22 = mul nsw i32 %21, %9
  %23 = sext i32 %22 to i64
  %24 = getelementptr inbounds i32, i32* %20, i64 %23
  %25 = getelementptr inbounds i32, i32* %24, i64 1
  %26 = getelementptr inbounds i32, i32* %25, i64 1
  %27 = getelementptr inbounds i32, i32* %26, i64 1
  %28 = getelementptr inbounds i32, i32* %27, i64 1
  %29 = bitcast i32* %24 to <4 x i32>*
  %30 = load <4 x i32>, <4 x i32>* %29, align 4, !noalias !1924
  %31 = getelementptr inbounds i32, i32* %28, i64 1
  %32 = load i32, i32* %28, align 4, !noalias !1924
  %33 = getelementptr inbounds i32, i32* %31, i64 1
  %34 = load i32, i32* %31, align 4, !noalias !1924
  %35 = getelementptr inbounds i32, i32* %33, i64 1
  %36 = load i32, i32* %33, align 4, !noalias !1924
  %37 = load i32, i32* %35, align 4, !noalias !1924
  %38 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %39 = load i32*, i32** %38, align 8, !noalias !1929
  %40 = getelementptr i32, i32* %39, i64 %17
  %41 = bitcast i32* %40 to <4 x i32>*
  %42 = load <4 x i32>, <4 x i32>* %41, align 4
  %43 = getelementptr inbounds i32, i32* %40, i64 4
  %44 = bitcast i32* %43 to <4 x i32>*
  %45 = load <4 x i32>, <4 x i32>* %44, align 4
  %46 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %47 = load i32*, i32** %46, align 8
  %48 = sext i32 %9 to i64
  %49 = getelementptr inbounds i32, i32* %47, i64 %48
  %50 = load i32, i32* %49, align 4
  %51 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %52 = load i32, i32* %51, align 4
  %53 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %6, i64 0, i32 0
  %54 = load i32, i32* %53, align 4
  %55 = insertelement <4 x i32> undef, i32 %54, i32 0
  %56 = shufflevector <4 x i32> %55, <4 x i32> undef, <4 x i32> zeroinitializer
  %57 = mul nsw <4 x i32> %56, %42
  %58 = add nsw <4 x i32> %57, %30
  %59 = mul nsw <4 x i32> %56, %45
  %60 = insertelement <4 x i32> undef, i32 %32, i32 0
  %61 = insertelement <4 x i32> %60, i32 %34, i32 1
  %62 = insertelement <4 x i32> %61, i32 %36, i32 2
  %63 = insertelement <4 x i32> %62, i32 %37, i32 3
  %64 = add nsw <4 x i32> %59, %63
  %65 = mul nsw i32 %54, %7
  %66 = add nsw i32 %65, %50
  %67 = mul nsw i32 %66, %52
  %68 = insertelement <4 x i32> undef, i32 %67, i32 0
  %69 = shufflevector <4 x i32> %68, <4 x i32> undef, <4 x i32> zeroinitializer
  %70 = add nsw <4 x i32> %58, %69
  %71 = add nsw <4 x i32> %64, %69
  %72 = bitcast %"struct.gemmlowp::RegisterBlock.304"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %72)
  %73 = bitcast %"struct.gemmlowp::RegisterBlock.304"* %15 to <4 x i32>*
  store <4 x i32> %70, <4 x i32>* %73, align 16
  %74 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.304", %"struct.gemmlowp::RegisterBlock.304"* %15, i64 0, i32 0, i32 0, i64 4
  %75 = bitcast i32* %74 to <4 x i32>*
  store <4 x i32> %71, <4 x i32>* %75, align 16
  %76 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.638", %"struct.gemmlowp::OutputPipelineExecutor.638"* %1, i64 0, i32 0
  %77 = tail call { i64, i64 } @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi8ELi1EEELb0EE4EvalES8_ii(%"struct.gemmlowp::OutputPipelineEvalImpl.639"* %76, %"struct.gemmlowp::RegisterBlock.304"* nonnull byval(%"struct.gemmlowp::RegisterBlock.304") align 8 %15, i32 %10, i32 %11) #19
  %78 = extractvalue { i64, i64 } %77, 0
  %79 = extractvalue { i64, i64 } %77, 1
  %80 = trunc i64 %78 to i16
  %81 = lshr i64 %78, 16
  %82 = trunc i64 %81 to i16
  %83 = lshr i64 %78, 32
  %84 = trunc i64 %83 to i16
  %85 = lshr i64 %78, 48
  %86 = trunc i64 %85 to i16
  %87 = trunc i64 %79 to i16
  %88 = lshr i64 %79, 16
  %89 = trunc i64 %88 to i16
  %90 = lshr i64 %79, 32
  %91 = trunc i64 %90 to i16
  %92 = lshr i64 %79, 48
  %93 = trunc i64 %92 to i16
  %94 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %2, i64 0, i32 0
  %95 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %2, i64 0, i32 3
  %96 = sext i32 %12 to i64
  %97 = load i16*, i16** %94, align 8
  %98 = getelementptr inbounds i16, i16* %97, i64 %96
  %99 = load i32, i32* %95, align 8
  %100 = mul nsw i32 %99, %13
  %101 = sext i32 %100 to i64
  %102 = getelementptr inbounds i16, i16* %98, i64 %101
  store i16 %80, i16* %102, align 2
  %103 = add nsw i64 %96, 1
  %104 = load i16*, i16** %94, align 8
  %105 = getelementptr inbounds i16, i16* %104, i64 %103
  %106 = load i32, i32* %95, align 8
  %107 = mul nsw i32 %106, %13
  %108 = sext i32 %107 to i64
  %109 = getelementptr inbounds i16, i16* %105, i64 %108
  store i16 %82, i16* %109, align 2
  %110 = add nsw i64 %96, 2
  %111 = load i16*, i16** %94, align 8
  %112 = getelementptr inbounds i16, i16* %111, i64 %110
  %113 = load i32, i32* %95, align 8
  %114 = mul nsw i32 %113, %13
  %115 = sext i32 %114 to i64
  %116 = getelementptr inbounds i16, i16* %112, i64 %115
  store i16 %84, i16* %116, align 2
  %117 = add nsw i64 %96, 3
  %118 = load i16*, i16** %94, align 8
  %119 = getelementptr inbounds i16, i16* %118, i64 %117
  %120 = load i32, i32* %95, align 8
  %121 = mul nsw i32 %120, %13
  %122 = sext i32 %121 to i64
  %123 = getelementptr inbounds i16, i16* %119, i64 %122
  store i16 %86, i16* %123, align 2
  %124 = add nsw i64 %96, 4
  %125 = load i16*, i16** %94, align 8
  %126 = getelementptr inbounds i16, i16* %125, i64 %124
  %127 = load i32, i32* %95, align 8
  %128 = mul nsw i32 %127, %13
  %129 = sext i32 %128 to i64
  %130 = getelementptr inbounds i16, i16* %126, i64 %129
  store i16 %87, i16* %130, align 2
  %131 = add nsw i64 %96, 5
  %132 = load i16*, i16** %94, align 8
  %133 = getelementptr inbounds i16, i16* %132, i64 %131
  %134 = load i32, i32* %95, align 8
  %135 = mul nsw i32 %134, %13
  %136 = sext i32 %135 to i64
  %137 = getelementptr inbounds i16, i16* %133, i64 %136
  store i16 %89, i16* %137, align 2
  %138 = add nsw i64 %96, 6
  %139 = load i16*, i16** %94, align 8
  %140 = getelementptr inbounds i16, i16* %139, i64 %138
  %141 = load i32, i32* %95, align 8
  %142 = mul nsw i32 %141, %13
  %143 = sext i32 %142 to i64
  %144 = getelementptr inbounds i16, i16* %140, i64 %143
  store i16 %91, i16* %144, align 2
  %145 = add nsw i64 %96, 7
  %146 = load i16*, i16** %94, align 8
  %147 = getelementptr inbounds i16, i16* %146, i64 %145
  %148 = load i32, i32* %95, align 8
  %149 = mul nsw i32 %148, %13
  %150 = sext i32 %149 to i64
  %151 = getelementptr inbounds i16, i16* %147, i64 %150
  store i16 %93, i16* %151, align 2
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %72)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp17UnpackResultBlockINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_13RegisterBlockIiLi4ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEENS_9VectorDupISB_LNS_11VectorShapeE0EEENSE_ISB_LSF_1EEENS_22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEES9_EENSA_IsLSC_0EEEEEvRKT1_RKT4_PT5_RKNS_9VectorMapISB_LSF_0EEERKNSZ_ISB_LSF_1EEERKT2_RKT3_iiiiiii(%"class.gemmlowp::MatrixMap.214"* dereferenceable(24), %"struct.gemmlowp::OutputPipelineExecutor.631"* dereferenceable(32), %"class.gemmlowp::MatrixMap.479"*, %"class.gemmlowp::VectorMap"* dereferenceable(16), %"class.gemmlowp::VectorMap.201"* dereferenceable(16), %"class.gemmlowp::VectorDup"* dereferenceable(8), %"class.gemmlowp::VectorDup.194"* dereferenceable(8), i32, i32, i32, i32, i32, i32, i32) local_unnamed_addr #1 comdat {
  %15 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 0
  %16 = sext i32 %8 to i64
  %17 = getelementptr inbounds %"class.gemmlowp::MatrixMap.214", %"class.gemmlowp::MatrixMap.214"* %0, i64 0, i32 3
  %18 = load i32*, i32** %15, align 8
  %19 = getelementptr inbounds i32, i32* %18, i64 %16
  %20 = load i32, i32* %17, align 8
  %21 = mul nsw i32 %20, %9
  %22 = sext i32 %21 to i64
  %23 = getelementptr inbounds i32, i32* %19, i64 %22
  %24 = getelementptr inbounds i32, i32* %23, i64 1
  %25 = load i32, i32* %23, align 4
  %26 = getelementptr inbounds i32, i32* %24, i64 1
  %27 = load i32, i32* %24, align 4
  %28 = getelementptr inbounds i32, i32* %26, i64 1
  %29 = load i32, i32* %26, align 4
  %30 = load i32, i32* %28, align 4
  %31 = getelementptr inbounds %"class.gemmlowp::VectorMap", %"class.gemmlowp::VectorMap"* %3, i64 0, i32 0
  %32 = load i32*, i32** %31, align 8
  %33 = getelementptr i32, i32* %32, i64 %16
  %34 = bitcast i32* %33 to i64*
  %35 = load i64, i64* %34, align 4
  %36 = getelementptr inbounds i32, i32* %33, i64 2
  %37 = bitcast i32* %36 to i64*
  %38 = load i64, i64* %37, align 4
  %39 = trunc i64 %35 to i32
  %40 = lshr i64 %35, 32
  %41 = trunc i64 %40 to i32
  %42 = getelementptr inbounds %"class.gemmlowp::VectorMap.201", %"class.gemmlowp::VectorMap.201"* %4, i64 0, i32 0
  %43 = load i32*, i32** %42, align 8
  %44 = sext i32 %9 to i64
  %45 = getelementptr inbounds i32, i32* %43, i64 %44
  %46 = load i32, i32* %45, align 4
  %47 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %5, i64 0, i32 0
  %48 = load i32, i32* %47, align 4
  %49 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %6, i64 0, i32 0
  %50 = load i32, i32* %49, align 4
  %51 = mul nsw i32 %50, %39
  %52 = add nsw i32 %51, %25
  %53 = mul nsw i32 %50, %41
  %54 = add nsw i32 %53, %27
  %55 = trunc i64 %38 to i32
  %56 = mul nsw i32 %50, %55
  %57 = add nsw i32 %56, %29
  %58 = lshr i64 %38, 32
  %59 = trunc i64 %58 to i32
  %60 = mul nsw i32 %50, %59
  %61 = add nsw i32 %60, %30
  %62 = mul nsw i32 %50, %7
  %63 = add nsw i32 %62, %46
  %64 = mul nsw i32 %63, %48
  %65 = add nsw i32 %52, %64
  %66 = add nsw i32 %54, %64
  %67 = add nsw i32 %57, %64
  %68 = zext i32 %67 to i64
  %69 = add nsw i32 %61, %64
  %70 = zext i32 %69 to i64
  %71 = shl nuw i64 %70, 32
  %72 = or i64 %71, %68
  %73 = zext i32 %66 to i64
  %74 = shl nuw i64 %73, 32
  %75 = zext i32 %65 to i64
  %76 = or i64 %74, %75
  %77 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.631", %"struct.gemmlowp::OutputPipelineExecutor.631"* %1, i64 0, i32 0, i32 0, i32 0
  %78 = tail call { i64, i64 } @_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi4EEEE4EvalES3_(%"struct.gemmlowp::OutputStageEvalBufferImpl.231"* %77, i64 %76, i64 %72) #19
  %79 = extractvalue { i64, i64 } %78, 0
  %80 = extractvalue { i64, i64 } %78, 1
  %81 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.631", %"struct.gemmlowp::OutputPipelineExecutor.631"* %1, i64 0, i32 0, i32 1, i32 0, i32 0, i32 0
  %82 = load %"struct.gemmlowp::OutputStageClamp"*, %"struct.gemmlowp::OutputStageClamp"** %81, align 8
  %83 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %82, i64 0, i32 0
  %84 = load i32, i32* %83, align 4
  %85 = getelementptr inbounds %"struct.gemmlowp::OutputStageClamp", %"struct.gemmlowp::OutputStageClamp"* %82, i64 0, i32 1
  %86 = load i32, i32* %85, align 4
  %87 = trunc i64 %79 to i32
  %88 = icmp sgt i32 %84, %87
  %89 = select i1 %88, i32 %84, i32 %87
  %90 = icmp slt i32 %86, %89
  %91 = select i1 %90, i32 %86, i32 %89
  %92 = lshr i64 %79, 32
  %93 = trunc i64 %92 to i32
  %94 = icmp sgt i32 %84, %93
  %95 = select i1 %94, i32 %84, i32 %93
  %96 = icmp slt i32 %86, %95
  %97 = select i1 %96, i32 %86, i32 %95
  %98 = trunc i64 %80 to i32
  %99 = icmp sgt i32 %84, %98
  %100 = select i1 %99, i32 %84, i32 %98
  %101 = icmp slt i32 %86, %100
  %102 = select i1 %101, i32 %86, i32 %100
  %103 = lshr i64 %80, 32
  %104 = trunc i64 %103 to i32
  %105 = icmp sgt i32 %84, %104
  %106 = select i1 %105, i32 %84, i32 %104
  %107 = icmp slt i32 %86, %106
  %108 = select i1 %107, i32 %86, i32 %106
  %109 = icmp sgt i32 %91, -32768
  %110 = select i1 %109, i32 %91, i32 -32768
  %111 = icmp slt i32 %110, 32767
  %112 = select i1 %111, i32 %110, i32 32767
  %113 = icmp sgt i32 %97, -32768
  %114 = select i1 %113, i32 %97, i32 -32768
  %115 = icmp slt i32 %114, 32767
  %116 = select i1 %115, i32 %114, i32 32767
  %117 = icmp sgt i32 %102, -32768
  %118 = select i1 %117, i32 %102, i32 -32768
  %119 = icmp slt i32 %118, 32767
  %120 = select i1 %119, i32 %118, i32 32767
  %121 = icmp sgt i32 %108, -32768
  %122 = select i1 %121, i32 %108, i32 -32768
  %123 = icmp slt i32 %122, 32767
  %124 = select i1 %123, i32 %122, i32 32767
  %125 = trunc i32 %112 to i16
  %126 = trunc i32 %116 to i16
  %127 = trunc i32 %120 to i16
  %128 = trunc i32 %124 to i16
  %129 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %2, i64 0, i32 0
  %130 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %2, i64 0, i32 3
  %131 = sext i32 %12 to i64
  %132 = load i16*, i16** %129, align 8
  %133 = getelementptr inbounds i16, i16* %132, i64 %131
  %134 = load i32, i32* %130, align 8
  %135 = mul nsw i32 %134, %13
  %136 = sext i32 %135 to i64
  %137 = getelementptr inbounds i16, i16* %133, i64 %136
  store i16 %125, i16* %137, align 2
  %138 = add nsw i64 %131, 1
  %139 = load i16*, i16** %129, align 8
  %140 = getelementptr inbounds i16, i16* %139, i64 %138
  %141 = load i32, i32* %130, align 8
  %142 = mul nsw i32 %141, %13
  %143 = sext i32 %142 to i64
  %144 = getelementptr inbounds i16, i16* %140, i64 %143
  store i16 %126, i16* %144, align 2
  %145 = add nsw i64 %131, 2
  %146 = load i16*, i16** %129, align 8
  %147 = getelementptr inbounds i16, i16* %146, i64 %145
  %148 = load i32, i32* %130, align 8
  %149 = mul nsw i32 %148, %13
  %150 = sext i32 %149 to i64
  %151 = getelementptr inbounds i16, i16* %147, i64 %150
  store i16 %127, i16* %151, align 2
  %152 = add nsw i64 %131, 3
  %153 = load i16*, i16** %129, align 8
  %154 = getelementptr inbounds i16, i16* %153, i64 %152
  %155 = load i32, i32* %130, align 8
  %156 = mul nsw i32 %155, %13
  %157 = sext i32 %156 to i64
  %158 = getelementptr inbounds i16, i16* %154, i64 %157
  store i16 %128, i16* %158, align 2
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZNK8gemmlowp22OutputPipelineExecutorINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_13RegisterBlockIiLi4ELi4EEEE7ExecuteINS_9MatrixMapIsLNS_8MapOrderE0EEEEEvS8_PT_iiii(%"struct.gemmlowp::OutputPipelineExecutor.652"*, %"struct.gemmlowp::RegisterBlock.312"* byval(%"struct.gemmlowp::RegisterBlock.312") align 8, %"class.gemmlowp::MatrixMap.479"*, i32, i32, i32, i32) local_unnamed_addr #1 comdat align 2 {
  %8 = alloca %"struct.gemmlowp::RegisterBuffer.313", align 8
  %9 = alloca %"struct.gemmlowp::RegisterBuffer.313", align 8
  %10 = alloca [16 x i32], align 8
  %11 = alloca %"struct.gemmlowp::RegisterBlock.563", align 2
  %12 = bitcast %"struct.gemmlowp::RegisterBlock.563"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %12) #19
  %13 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %11, i64 0, i32 0, i32 0, i64 0
  %14 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %11, i64 0, i32 0, i32 0, i64 1
  %15 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %11, i64 0, i32 0, i32 0, i64 2
  %16 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %11, i64 0, i32 0, i32 0, i64 3
  %17 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %11, i64 0, i32 0, i32 0, i64 4
  %18 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %11, i64 0, i32 0, i32 0, i64 5
  %19 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %11, i64 0, i32 0, i32 0, i64 6
  %20 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %11, i64 0, i32 0, i32 0, i64 7
  %21 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %11, i64 0, i32 0, i32 0, i64 8
  %22 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %11, i64 0, i32 0, i32 0, i64 9
  %23 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %11, i64 0, i32 0, i32 0, i64 10
  %24 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %11, i64 0, i32 0, i32 0, i64 11
  %25 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %11, i64 0, i32 0, i32 0, i64 12
  %26 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %11, i64 0, i32 0, i32 0, i64 13
  %27 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %11, i64 0, i32 0, i32 0, i64 14
  %28 = getelementptr inbounds %"struct.gemmlowp::RegisterBlock.563", %"struct.gemmlowp::RegisterBlock.563"* %11, i64 0, i32 0, i32 0, i64 15
  %29 = bitcast %"struct.gemmlowp::RegisterBlock.312"* %1 to i8*
  %30 = bitcast %"struct.gemmlowp::RegisterBlock.563"* %11 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 2 %30, i8 -86, i64 32, i1 false)
  %31 = bitcast [16 x i32]* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %31) #19, !noalias !1934
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %31, i8 -86, i64 64, i1 false) #19, !alias.scope !1937, !noalias !1934
  %32 = bitcast %"struct.gemmlowp::RegisterBuffer.313"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %32) #19, !noalias !1940
  %33 = bitcast %"struct.gemmlowp::RegisterBuffer.313"* %8 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %33) #19, !noalias !1940
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %33, i8* nonnull align 8 %29, i64 64, i1 false)
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %32, i8 -86, i64 64, i1 false) #19, !alias.scope !1941, !noalias !1940
  %34 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.652", %"struct.gemmlowp::OutputPipelineExecutor.652"* %0, i64 0, i32 0, i32 0, i32 0, i32 0
  %35 = load %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"*, %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"** %34, align 8, !noalias !1944
  %36 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %35, i64 0, i32 2
  %37 = load i32, i32* %36, align 4, !noalias !1944
  %38 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.652", %"struct.gemmlowp::OutputPipelineExecutor.652"* %0, i64 0, i32 0, i32 0, i32 0, i32 1
  %39 = load i32, i32* %38, align 8, !noalias !1944
  %40 = shl i32 1, %39
  %41 = sext i32 %40 to i64
  %42 = getelementptr inbounds %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent", %"struct.gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent"* %35, i64 0, i32 0
  %43 = load i32, i32* %42, align 4, !noalias !1944
  %44 = sext i32 %43 to i64
  %45 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.652", %"struct.gemmlowp::OutputPipelineExecutor.652"* %0, i64 0, i32 0, i32 0, i32 0, i32 2
  %46 = load i32, i32* %45, align 4, !noalias !1944
  %47 = zext i32 %46 to i64
  %48 = shl nsw i64 -1, %47
  %49 = trunc i64 %48 to i32
  %50 = xor i32 %49, -1
  %51 = ashr i32 %50, 1
  %52 = icmp ne i32 %43, -2147483648
  br label %53

53:                                               ; preds = %74, %7
  %54 = phi i64 [ 0, %7 ], [ %85, %74 ]
  %55 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %8, i64 0, i32 0, i64 %54
  %56 = load i32, i32* %55, align 4, !noalias !1944
  %57 = sext i32 %56 to i64
  %58 = mul nsw i64 %57, %41
  %59 = icmp slt i64 %58, 2147483647
  %60 = select i1 %59, i64 %58, i64 2147483647
  %61 = icmp sgt i64 %60, -2147483648
  %62 = select i1 %61, i64 %60, i64 -2147483648
  %63 = trunc i64 %62 to i32
  %64 = icmp ne i32 %43, %63
  %65 = or i1 %52, %64
  br i1 %65, label %66, label %74

66:                                               ; preds = %53
  %67 = select i1 %64, i64 %44, i64 %62
  %68 = mul nsw i64 %67, %62
  %69 = icmp sgt i64 %68, -1
  %70 = select i1 %69, i64 1073741824, i64 -1073741823
  %71 = add nsw i64 %70, %68
  %72 = sdiv i64 %71, 2147483648
  %73 = trunc i64 %72 to i32
  br label %74

74:                                               ; preds = %66, %53
  %75 = phi i32 [ %73, %66 ], [ 2147483647, %53 ]
  %76 = and i32 %75, %50
  %77 = lshr i32 %75, 31
  %78 = add nsw i32 %77, %51
  %79 = ashr i32 %75, %46
  %80 = icmp sgt i32 %76, %78
  %81 = zext i1 %80 to i32
  %82 = add i32 %79, %37
  %83 = add i32 %82, %81
  %84 = getelementptr inbounds %"struct.gemmlowp::RegisterBuffer.313", %"struct.gemmlowp::RegisterBuffer.313"* %9, i64 0, i32 0, i64 %54
  store i32 %83, i32* %84, align 4, !alias.scope !1941, !noalias !1940
  %85 = add nuw nsw i64 %54, 1
  %86 = icmp eq i64 %85, 16
  br i1 %86, label %87, label %53

87:                                               ; preds = %74
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %33) #19, !noalias !1940
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %31, i8* nonnull align 8 %32, i64 64, i1 false) #19, !noalias !1934
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %32) #19, !noalias !1940
  %88 = getelementptr inbounds %"struct.gemmlowp::OutputPipelineExecutor.652", %"struct.gemmlowp::OutputPipelineExecutor.652"* %0, i64 0, i32 0, i32 1
  %89 = bitcast [16 x i32]* %10 to %"struct.gemmlowp::RegisterBlock.312"*
  call void @_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalES8_ii(%"struct.gemmlowp::RegisterBlock.563"* nonnull sret %11, %"struct.gemmlowp::OutputPipelineEvalImpl.654"* %88, %"struct.gemmlowp::RegisterBlock.312"* nonnull byval(%"struct.gemmlowp::RegisterBlock.312") align 8 %89, i32 %3, i32 %4) #19
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %31) #19, !noalias !1934
  %90 = load i16, i16* %13, align 2
  %91 = load i16, i16* %14, align 2
  %92 = load i16, i16* %15, align 2
  %93 = load i16, i16* %16, align 2
  %94 = load i16, i16* %17, align 2
  %95 = load i16, i16* %18, align 2
  %96 = load i16, i16* %19, align 2
  %97 = load i16, i16* %20, align 2
  %98 = load i16, i16* %21, align 2
  %99 = load i16, i16* %22, align 2
  %100 = load i16, i16* %23, align 2
  %101 = load i16, i16* %24, align 2
  %102 = load i16, i16* %25, align 2
  %103 = load i16, i16* %26, align 2
  %104 = load i16, i16* %27, align 2
  %105 = load i16, i16* %28, align 2
  %106 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %2, i64 0, i32 0
  %107 = getelementptr inbounds %"class.gemmlowp::MatrixMap.479", %"class.gemmlowp::MatrixMap.479"* %2, i64 0, i32 3
  %108 = sext i32 %6 to i64
  %109 = sext i32 %5 to i64
  %110 = load i16*, i16** %106, align 8
  %111 = getelementptr inbounds i16, i16* %110, i64 %109
  %112 = load i32, i32* %107, align 8
  %113 = sext i32 %112 to i64
  %114 = mul nsw i64 %113, %108
  %115 = getelementptr inbounds i16, i16* %111, i64 %114
  store i16 %90, i16* %115, align 2
  %116 = add nsw i64 %108, 1
  %117 = load i16*, i16** %106, align 8
  %118 = getelementptr inbounds i16, i16* %117, i64 %109
  %119 = load i32, i32* %107, align 8
  %120 = sext i32 %119 to i64
  %121 = mul nsw i64 %116, %120
  %122 = getelementptr inbounds i16, i16* %118, i64 %121
  store i16 %94, i16* %122, align 2
  %123 = add nsw i64 %108, 2
  %124 = load i16*, i16** %106, align 8
  %125 = getelementptr inbounds i16, i16* %124, i64 %109
  %126 = load i32, i32* %107, align 8
  %127 = sext i32 %126 to i64
  %128 = mul nsw i64 %123, %127
  %129 = getelementptr inbounds i16, i16* %125, i64 %128
  store i16 %98, i16* %129, align 2
  %130 = add nsw i64 %108, 3
  %131 = load i16*, i16** %106, align 8
  %132 = getelementptr inbounds i16, i16* %131, i64 %109
  %133 = load i32, i32* %107, align 8
  %134 = sext i32 %133 to i64
  %135 = mul nsw i64 %130, %134
  %136 = getelementptr inbounds i16, i16* %132, i64 %135
  store i16 %102, i16* %136, align 2
  %137 = add nsw i64 %109, 1
  %138 = load i16*, i16** %106, align 8
  %139 = getelementptr inbounds i16, i16* %138, i64 %137
  %140 = load i32, i32* %107, align 8
  %141 = sext i32 %140 to i64
  %142 = mul nsw i64 %141, %108
  %143 = getelementptr inbounds i16, i16* %139, i64 %142
  store i16 %91, i16* %143, align 2
  %144 = load i16*, i16** %106, align 8
  %145 = getelementptr inbounds i16, i16* %144, i64 %137
  %146 = load i32, i32* %107, align 8
  %147 = sext i32 %146 to i64
  %148 = mul nsw i64 %116, %147
  %149 = getelementptr inbounds i16, i16* %145, i64 %148
  store i16 %95, i16* %149, align 2
  %150 = load i16*, i16** %106, align 8
  %151 = getelementptr inbounds i16, i16* %150, i64 %137
  %152 = load i32, i32* %107, align 8
  %153 = sext i32 %152 to i64
  %154 = mul nsw i64 %123, %153
  %155 = getelementptr inbounds i16, i16* %151, i64 %154
  store i16 %99, i16* %155, align 2
  %156 = load i16*, i16** %106, align 8
  %157 = getelementptr inbounds i16, i16* %156, i64 %137
  %158 = load i32, i32* %107, align 8
  %159 = sext i32 %158 to i64
  %160 = mul nsw i64 %130, %159
  %161 = getelementptr inbounds i16, i16* %157, i64 %160
  store i16 %103, i16* %161, align 2
  %162 = add nsw i64 %109, 2
  %163 = load i16*, i16** %106, align 8
  %164 = getelementptr inbounds i16, i16* %163, i64 %162
  %165 = load i32, i32* %107, align 8
  %166 = sext i32 %165 to i64
  %167 = mul nsw i64 %166, %108
  %168 = getelementptr inbounds i16, i16* %164, i64 %167
  store i16 %92, i16* %168, align 2
  %169 = load i16*, i16** %106, align 8
  %170 = getelementptr inbounds i16, i16* %169, i64 %162
  %171 = load i32, i32* %107, align 8
  %172 = sext i32 %171 to i64
  %173 = mul nsw i64 %116, %172
  %174 = getelementptr inbounds i16, i16* %170, i64 %173
  store i16 %96, i16* %174, align 2
  %175 = load i16*, i16** %106, align 8
  %176 = getelementptr inbounds i16, i16* %175, i64 %162
  %177 = load i32, i32* %107, align 8
  %178 = sext i32 %177 to i64
  %179 = mul nsw i64 %123, %178
  %180 = getelementptr inbounds i16, i16* %176, i64 %179
  store i16 %100, i16* %180, align 2
  %181 = load i16*, i16** %106, align 8
  %182 = getelementptr inbounds i16, i16* %181, i64 %162
  %183 = load i32, i32* %107, align 8
  %184 = sext i32 %183 to i64
  %185 = mul nsw i64 %130, %184
  %186 = getelementptr inbounds i16, i16* %182, i64 %185
  store i16 %104, i16* %186, align 2
  %187 = add nsw i64 %109, 3
  %188 = load i16*, i16** %106, align 8
  %189 = getelementptr inbounds i16, i16* %188, i64 %187
  %190 = load i32, i32* %107, align 8
  %191 = sext i32 %190 to i64
  %192 = mul nsw i64 %191, %108
  %193 = getelementptr inbounds i16, i16* %189, i64 %192
  store i16 %93, i16* %193, align 2
  %194 = load i16*, i16** %106, align 8
  %195 = getelementptr inbounds i16, i16* %194, i64 %187
  %196 = load i32, i32* %107, align 8
  %197 = sext i32 %196 to i64
  %198 = mul nsw i64 %116, %197
  %199 = getelementptr inbounds i16, i16* %195, i64 %198
  store i16 %97, i16* %199, align 2
  %200 = load i16*, i16** %106, align 8
  %201 = getelementptr inbounds i16, i16* %200, i64 %187
  %202 = load i32, i32* %107, align 8
  %203 = sext i32 %202 to i64
  %204 = mul nsw i64 %123, %203
  %205 = getelementptr inbounds i16, i16* %201, i64 %204
  store i16 %101, i16* %205, align 2
  %206 = load i16*, i16** %106, align 8
  %207 = getelementptr inbounds i16, i16* %206, i64 %187
  %208 = load i32, i32* %107, align 8
  %209 = sext i32 %208 to i64
  %210 = mul nsw i64 %130, %209
  %211 = getelementptr inbounds i16, i16* %207, i64 %210
  store i16 %105, i16* %211, align 2
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %12) #19
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED2Ev(%"struct.gemmlowp::GemmWithPackedRhsTask.666"*) unnamed_addr #4 comdat align 2 {
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEED0Ev(%"struct.gemmlowp::GemmWithPackedRhsTask.666"*) unnamed_addr #4 comdat align 2 {
  %2 = bitcast %"struct.gemmlowp::GemmWithPackedRhsTask.666"* %0 to i8*
  tail call void @_ZdlPv(i8* %2) #18
  ret void
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden void @_ZN8gemmlowp21GemmWithPackedRhsTaskINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EEhsNS_14BitDepthParamsINS_12OperandRangeILi1ELi255EEENS9_ILi0ELi255EEEEELNS_8MapOrderE1ELSD_0ELSD_0ENS_9VectorDupIKiLNS_11VectorShapeE0EEENSE_ISF_LSG_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEENS_11GemmContextEE3RunEv(%"struct.gemmlowp::GemmWithPackedRhsTask.666"*) unnamed_addr #1 comdat align 2 {
  %2 = alloca %"class.gemmlowp::SideMap", align 8
  %3 = alloca %"class.gemmlowp::PackSideBlockImpl", align 8
  %4 = alloca %"class.gemmlowp::ComputeImpl", align 8
  %5 = alloca %"class.gemmlowp::PackedSideBlock", align 8
  %6 = alloca %"class.gemmlowp::PackedResult", align 8
  %7 = alloca %"struct.gemmlowp::MatrixBlockBounds", align 4
  %8 = alloca %"class.gemmlowp::VectorDup", align 4
  %9 = alloca %"class.gemmlowp::VectorDup.194", align 4
  %10 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.666", %"struct.gemmlowp::GemmWithPackedRhsTask.666"* %0, i64 0, i32 6, i32 2
  %11 = load i32, i32* %10, align 8
  %12 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.666", %"struct.gemmlowp::GemmWithPackedRhsTask.666"* %0, i64 0, i32 6, i32 3
  %13 = load i32, i32* %12, align 4
  %14 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.666", %"struct.gemmlowp::GemmWithPackedRhsTask.666"* %0, i64 0, i32 3, i32 2
  %15 = load i32, i32* %14, align 4
  %16 = bitcast %"class.gemmlowp::PackedSideBlock"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %16) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %16, i8 -86, i64 80, i1 false)
  %17 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.666", %"struct.gemmlowp::GemmWithPackedRhsTask.666"* %0, i64 0, i32 0, i32 1
  %18 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %19 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.666", %"struct.gemmlowp::GemmWithPackedRhsTask.666"* %0, i64 0, i32 9
  %20 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %21 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 1
  store %"class.gemmlowp::Allocator"* %18, %"class.gemmlowp::Allocator"** %21, align 8
  %22 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 4
  store i32 0, i32* %22, align 8
  %23 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 0
  %24 = load i32, i32* %23, align 4
  %25 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 0
  store i32 %24, i32* %25, align 8
  %26 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 3
  %27 = load i32, i32* %26, align 4
  %28 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 2
  store i32 %27, i32* %28, align 8
  %29 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 2
  %30 = load i32, i32* %29, align 4
  %31 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 1
  store i32 %30, i32* %31, align 4
  %32 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %20, i64 0, i32 5
  %33 = load i32, i32* %32, align 4
  %34 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 0, i32 3
  store i32 %33, i32* %34, align 4
  %35 = mul nsw i32 %33, %27
  %36 = sext i32 %35 to i64
  %37 = add nsw i64 %36, 63
  %38 = and i64 %37, -64
  %39 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 4
  %40 = load i64, i64* %39, align 8, !noalias !1945
  %41 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 3
  %42 = load i64, i64* %41, align 8, !noalias !1945
  %43 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 5, i64 %42
  store i64 %40, i64* %43, align 8, !noalias !1945
  %44 = trunc i64 %42 to i8
  %45 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %18, i64 0, i32 6
  %46 = load i64, i64* %45, align 8, !noalias !1945
  %47 = bitcast i64* %41 to <2 x i64>*
  %48 = load <2 x i64>, <2 x i64>* %47, align 8, !noalias !1945
  %49 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %38, i32 1
  %50 = add <2 x i64> %48, %49
  %51 = bitcast i64* %41 to <2 x i64>*
  store <2 x i64> %50, <2 x i64>* %51, align 8, !noalias !1945
  %52 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 0
  store i8 %44, i8* %52, align 8
  %53 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %53, i8 -86, i64 7, i1 false) #19
  %54 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 2
  store i64 %46, i64* %54, align 8
  %55 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 2, i32 3
  store i8 0, i8* %55, align 8
  %56 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %21, align 8
  %57 = load i32, i32* %28, align 8
  %58 = sext i32 %57 to i64
  %59 = shl nsw i64 %58, 2
  %60 = add nsw i64 %59, 63
  %61 = and i64 %60, -64
  %62 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 4
  %63 = load i64, i64* %62, align 8, !noalias !1948
  %64 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 3
  %65 = load i64, i64* %64, align 8, !noalias !1948
  %66 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 5, i64 %65
  store i64 %63, i64* %66, align 8, !noalias !1948
  %67 = trunc i64 %65 to i8
  %68 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %56, i64 0, i32 6
  %69 = load i64, i64* %68, align 8, !noalias !1948
  %70 = bitcast i64* %64 to <2 x i64>*
  %71 = load <2 x i64>, <2 x i64>* %70, align 8, !noalias !1948
  %72 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %61, i32 1
  %73 = add <2 x i64> %71, %72
  %74 = bitcast i64* %64 to <2 x i64>*
  store <2 x i64> %73, <2 x i64>* %74, align 8, !noalias !1948
  %75 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 0
  store i8 %67, i8* %75, align 8
  %76 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %76, i8 -86, i64 7, i1 false) #19
  %77 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 2
  store i64 %69, i64* %77, align 8
  %78 = getelementptr inbounds %"class.gemmlowp::PackedSideBlock", %"class.gemmlowp::PackedSideBlock"* %5, i64 0, i32 3, i32 3
  store i8 5, i8* %78, align 8
  %79 = bitcast %"class.gemmlowp::PackedResult"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %79) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %79, i8 -86, i64 32, i1 false)
  %80 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %81 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %82 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 0
  store %"class.gemmlowp::Allocator"* %80, %"class.gemmlowp::Allocator"** %82, align 8
  %83 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 2
  store %"struct.gemmlowp::BlockParams"* %81, %"struct.gemmlowp::BlockParams"** %83, align 8
  %84 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %81, i64 0, i32 3
  %85 = load i32, i32* %84, align 4
  %86 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %81, i64 0, i32 4
  %87 = load i32, i32* %86, align 4
  %88 = mul nsw i32 %87, %85
  %89 = sext i32 %88 to i64
  %90 = shl nsw i64 %89, 2
  %91 = add nsw i64 %90, 63
  %92 = and i64 %91, -64
  %93 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 4
  %94 = load i64, i64* %93, align 8, !noalias !1951
  %95 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 3
  %96 = load i64, i64* %95, align 8, !noalias !1951
  %97 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 5, i64 %96
  store i64 %94, i64* %97, align 8, !noalias !1951
  %98 = trunc i64 %96 to i8
  %99 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %80, i64 0, i32 6
  %100 = load i64, i64* %99, align 8, !noalias !1951
  %101 = bitcast i64* %95 to <2 x i64>*
  %102 = load <2 x i64>, <2 x i64>* %101, align 8, !noalias !1951
  %103 = insertelement <2 x i64> <i64 1, i64 undef>, i64 %92, i32 1
  %104 = add <2 x i64> %102, %103
  %105 = bitcast i64* %95 to <2 x i64>*
  store <2 x i64> %104, <2 x i64>* %105, align 8, !noalias !1951
  %106 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 0
  store i8 %98, i8* %106, align 8
  %107 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 1, i64 0
  call void @llvm.memset.p0i8.i64(i8* align 1 %107, i8 -86, i64 7, i1 false) #19
  %108 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 2
  store i64 %100, i64* %108, align 8
  %109 = getelementptr inbounds %"class.gemmlowp::PackedResult", %"class.gemmlowp::PackedResult"* %6, i64 0, i32 1, i32 3
  store i8 5, i8* %109, align 8
  %110 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  tail call void @_ZN8gemmlowp9Allocator6CommitEv(%"class.gemmlowp::Allocator"* %110)
  %111 = icmp sgt i32 %13, 0
  br i1 %111, label %112, label %156

112:                                              ; preds = %1
  %113 = icmp sgt i32 %11, 0
  %114 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.666", %"struct.gemmlowp::GemmWithPackedRhsTask.666"* %0, i64 0, i32 3, i32 0
  %115 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.666", %"struct.gemmlowp::GemmWithPackedRhsTask.666"* %0, i64 0, i32 3, i32 3
  %116 = bitcast %"class.gemmlowp::SideMap"* %2 to i8*
  %117 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 1
  %118 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 2
  %119 = getelementptr inbounds %"class.gemmlowp::SideMap", %"class.gemmlowp::SideMap"* %2, i64 0, i32 3
  %120 = bitcast %"class.gemmlowp::SideMap"* %2 to i64*
  %121 = bitcast %"class.gemmlowp::PackSideBlockImpl"* %3 to i8*
  %122 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %3, i64 0, i32 0
  %123 = getelementptr inbounds %"class.gemmlowp::PackSideBlockImpl", %"class.gemmlowp::PackSideBlockImpl"* %3, i64 0, i32 1
  %124 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.666", %"struct.gemmlowp::GemmWithPackedRhsTask.666"* %0, i64 0, i32 2
  %125 = bitcast %"struct.gemmlowp::KernelBase"** %124 to i64*
  %126 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.666", %"struct.gemmlowp::GemmWithPackedRhsTask.666"* %0, i64 0, i32 4
  %127 = bitcast %"class.gemmlowp::ComputeImpl"* %4 to i8*
  %128 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 1
  %129 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 2
  %130 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 3
  %131 = getelementptr inbounds %"class.gemmlowp::ComputeImpl", %"class.gemmlowp::ComputeImpl"* %4, i64 0, i32 4
  %132 = bitcast %"class.gemmlowp::ComputeImpl"* %4 to i64*
  %133 = add i32 %15, 15
  %134 = and i32 %133, -16
  %135 = icmp sgt i32 %134, 0
  %136 = bitcast %"struct.gemmlowp::MatrixBlockBounds"* %7 to i8*
  %137 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 0
  %138 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 1
  %139 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 2
  %140 = getelementptr inbounds %"struct.gemmlowp::MatrixBlockBounds", %"struct.gemmlowp::MatrixBlockBounds"* %7, i64 0, i32 3
  %141 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.666", %"struct.gemmlowp::GemmWithPackedRhsTask.666"* %0, i64 0, i32 6, i32 0
  %142 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.666", %"struct.gemmlowp::GemmWithPackedRhsTask.666"* %0, i64 0, i32 6, i32 1
  %143 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.666", %"struct.gemmlowp::GemmWithPackedRhsTask.666"* %0, i64 0, i32 5
  %144 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.666", %"struct.gemmlowp::GemmWithPackedRhsTask.666"* %0, i64 0, i32 4, i32 1
  %145 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.666", %"struct.gemmlowp::GemmWithPackedRhsTask.666"* %0, i64 0, i32 4, i32 3, i32 0
  %146 = bitcast %"class.gemmlowp::VectorDup"* %8 to i8*
  %147 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.666", %"struct.gemmlowp::GemmWithPackedRhsTask.666"* %0, i64 0, i32 7
  %148 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %8, i64 0, i32 0
  %149 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %8, i64 0, i32 1
  %150 = bitcast %"class.gemmlowp::VectorDup.194"* %9 to i8*
  %151 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.666", %"struct.gemmlowp::GemmWithPackedRhsTask.666"* %0, i64 0, i32 8
  %152 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %9, i64 0, i32 0
  %153 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %9, i64 0, i32 1
  %154 = getelementptr inbounds %"struct.gemmlowp::GemmWithPackedRhsTask.666", %"struct.gemmlowp::GemmWithPackedRhsTask.666"* %0, i64 0, i32 10
  %155 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  br label %164

156:                                              ; preds = %178, %1
  %157 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %17, align 8
  %158 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 0
  store i8 0, i8* %158, align 8
  %159 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 6
  %160 = load i64, i64* %159, align 8
  %161 = add i64 %160, 1
  store i64 %161, i64* %159, align 8
  %162 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %157, i64 0, i32 3
  %163 = bitcast i64* %162 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 8 %163, i8 0, i64 16, i1 false) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %79) #19
  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %16) #19
  ret void

164:                                              ; preds = %112, %178
  %165 = phi %"struct.gemmlowp::BlockParams"* [ %155, %112 ], [ %180, %178 ]
  %166 = phi i32 [ 0, %112 ], [ %181, %178 ]
  %167 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %165, i64 0, i32 4
  %168 = sub nsw i32 %13, %166
  %169 = load i32, i32* %167, align 4
  %170 = icmp slt i32 %168, %169
  %171 = select i1 %170, i32 %168, i32 %169
  br i1 %113, label %172, label %178

172:                                              ; preds = %164
  %173 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %165, i64 0, i32 3
  %174 = load i32, i32* %173, align 4
  br label %183

175:                                              ; preds = %255
  %176 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %287, i64 0, i32 4
  %177 = load i32, i32* %176, align 4
  br label %178

178:                                              ; preds = %175, %164
  %179 = phi i32 [ %169, %164 ], [ %177, %175 ]
  %180 = phi %"struct.gemmlowp::BlockParams"* [ %165, %164 ], [ %287, %175 ]
  %181 = add nsw i32 %179, %166
  %182 = icmp sgt i32 %13, %181
  br i1 %182, label %164, label %156

183:                                              ; preds = %172, %255
  %184 = phi i32 [ %289, %255 ], [ %174, %172 ]
  %185 = phi i32 [ %290, %255 ], [ 0, %172 ]
  %186 = sub nsw i32 %11, %185
  %187 = icmp slt i32 %186, %184
  %188 = select i1 %187, i32 %186, i32 %184
  %189 = load i8*, i8** %114, align 8, !noalias !1954
  %190 = load i32, i32* %115, align 8, !noalias !1954
  %191 = mul nsw i32 %190, %185
  %192 = sext i32 %191 to i64
  %193 = getelementptr inbounds i8, i8* %189, i64 %192
  %194 = ptrtoint i8* %193 to i64
  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %116) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %116, i8 -86, i64 24, i1 false) #19
  store i64 %194, i64* %120, align 8
  store i32 %188, i32* %117, align 8
  store i32 %15, i32* %118, align 4
  store i32 %190, i32* %119, align 8
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %121) #19
  store %"class.gemmlowp::PackedSideBlock"* %5, %"class.gemmlowp::PackedSideBlock"** %122, align 8
  store %"class.gemmlowp::SideMap"* %2, %"class.gemmlowp::SideMap"** %123, align 8
  call void @_ZN8gemmlowp17PackSideBlockImplINS_7SideMapIKhLNS_12SideMapOrderE0EEENS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEEE6PackL2Ev(%"class.gemmlowp::PackSideBlockImpl"* nonnull %3) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %121) #19
  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %116) #19
  %195 = load i64, i64* %125, align 8
  %196 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %127) #19
  store i64 %195, i64* %132, align 8
  store %"struct.gemmlowp::BlockParams"* %196, %"struct.gemmlowp::BlockParams"** %128, align 8
  store %"class.gemmlowp::PackedResult"* %6, %"class.gemmlowp::PackedResult"** %129, align 8
  store %"class.gemmlowp::PackedSideBlock"* %5, %"class.gemmlowp::PackedSideBlock"** %130, align 8
  store %"class.gemmlowp::PackedSideBlock"* %126, %"class.gemmlowp::PackedSideBlock"** %131, align 8
  br i1 %135, label %197, label %255

197:                                              ; preds = %183, %215
  %198 = phi %"struct.gemmlowp::BlockParams"* [ %217, %215 ], [ %196, %183 ]
  %199 = phi %"struct.gemmlowp::BlockParams"* [ %218, %215 ], [ %196, %183 ]
  %200 = phi i32 [ %219, %215 ], [ 0, %183 ]
  %201 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 2
  %202 = sub nsw i32 %134, %200
  %203 = load i32, i32* %201, align 4
  %204 = icmp slt i32 %202, %203
  %205 = select i1 %204, i32 %202, i32 %203
  %206 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 3
  %207 = load i32, i32* %206, align 4
  %208 = icmp sgt i32 %207, 0
  br i1 %208, label %209, label %215

209:                                              ; preds = %197
  %210 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %199, i64 0, i32 0
  %211 = load i32, i32* %210, align 4
  br label %221

212:                                              ; preds = %247
  %213 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 2
  %214 = load i32, i32* %213, align 4
  br label %215

215:                                              ; preds = %212, %197
  %216 = phi i32 [ %203, %197 ], [ %214, %212 ]
  %217 = phi %"struct.gemmlowp::BlockParams"* [ %198, %197 ], [ %248, %212 ]
  %218 = phi %"struct.gemmlowp::BlockParams"* [ %199, %197 ], [ %248, %212 ]
  %219 = add nsw i32 %216, %200
  %220 = icmp sgt i32 %134, %219
  br i1 %220, label %197, label %255

221:                                              ; preds = %247, %209
  %222 = phi %"struct.gemmlowp::BlockParams"* [ %248, %247 ], [ %198, %209 ]
  %223 = phi i32 [ %250, %247 ], [ %211, %209 ]
  %224 = phi i32 [ %253, %247 ], [ %207, %209 ]
  %225 = phi %"struct.gemmlowp::BlockParams"* [ %248, %247 ], [ %199, %209 ]
  %226 = phi i32 [ %251, %247 ], [ 0, %209 ]
  %227 = sub nsw i32 %224, %226
  %228 = icmp slt i32 %227, %223
  %229 = select i1 %228, i32 %227, i32 %223
  %230 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %225, i64 0, i32 4
  %231 = load i32, i32* %230, align 4
  %232 = icmp sgt i32 %231, 0
  br i1 %232, label %233, label %247

233:                                              ; preds = %221
  %234 = icmp sgt i32 %229, 0
  br label %235

235:                                              ; preds = %237, %233
  %236 = phi i32 [ 0, %233 ], [ %238, %237 ]
  br i1 %234, label %240, label %237

237:                                              ; preds = %240, %235
  %238 = add nuw nsw i32 %236, 4
  %239 = icmp slt i32 %238, %231
  br i1 %239, label %235, label %245

240:                                              ; preds = %235, %240
  %241 = phi i32 [ %243, %240 ], [ 0, %235 ]
  %242 = add nsw i32 %241, %226
  call void @_ZN8gemmlowp11ComputeImplINS_15PackedSideBlockINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEEEES7_NS_12PackedResultEE10ComputeRunEiiii(%"class.gemmlowp::ComputeImpl"* nonnull %4, i32 %242, i32 %236, i32 %200, i32 %205) #19
  %243 = add nuw nsw i32 %241, 4
  %244 = icmp slt i32 %243, %229
  br i1 %244, label %240, label %237

245:                                              ; preds = %237
  %246 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %128, align 8
  br label %247

247:                                              ; preds = %245, %221
  %248 = phi %"struct.gemmlowp::BlockParams"* [ %246, %245 ], [ %222, %221 ]
  %249 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 0
  %250 = load i32, i32* %249, align 4
  %251 = add nsw i32 %250, %226
  %252 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %248, i64 0, i32 3
  %253 = load i32, i32* %252, align 4
  %254 = icmp sgt i32 %253, %251
  br i1 %254, label %221, label %212

255:                                              ; preds = %215, %183
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %127) #19
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %136) #19
  %256 = load i32, i32* %141, align 8
  %257 = add nsw i32 %256, %185
  %258 = load i32, i32* %142, align 4
  %259 = add nsw i32 %258, %166
  store i32 %257, i32* %137, align 4
  store i32 %259, i32* %138, align 4
  store i32 %188, i32* %139, align 4
  store i32 %171, i32* %140, align 4
  %260 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %21, align 8
  %261 = load i8, i8* %75, align 8
  %262 = zext i8 %261 to i64
  %263 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %260, i64 0, i32 5, i64 %262
  %264 = load i64, i64* %263, align 8
  %265 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %260, i64 0, i32 2
  %266 = bitcast i8** %265 to i64*
  %267 = load i64, i64* %266, align 8
  %268 = add i64 %267, %264
  %269 = inttoptr i64 %268 to i32*
  %270 = load %"class.gemmlowp::Allocator"*, %"class.gemmlowp::Allocator"** %144, align 8
  %271 = load i8, i8* %145, align 8
  %272 = zext i8 %271 to i64
  %273 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %270, i64 0, i32 5, i64 %272
  %274 = load i64, i64* %273, align 8
  %275 = getelementptr inbounds %"class.gemmlowp::Allocator", %"class.gemmlowp::Allocator"* %270, i64 0, i32 2
  %276 = bitcast i8** %275 to i64*
  %277 = load i64, i64* %276, align 8
  %278 = add i64 %277, %274
  %279 = inttoptr i64 %278 to i32*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %146) #19
  %280 = load %"class.gemmlowp::VectorDup"*, %"class.gemmlowp::VectorDup"** %147, align 8
  %281 = getelementptr inbounds %"class.gemmlowp::VectorDup", %"class.gemmlowp::VectorDup"* %280, i64 0, i32 0
  %282 = load i32, i32* %281, align 4, !noalias !1957
  store i32 %282, i32* %148, align 4, !alias.scope !1957
  store i32 %188, i32* %149, align 4, !alias.scope !1957
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %150) #19
  %283 = load %"class.gemmlowp::VectorDup.194"*, %"class.gemmlowp::VectorDup.194"** %151, align 8
  %284 = getelementptr inbounds %"class.gemmlowp::VectorDup.194", %"class.gemmlowp::VectorDup.194"* %283, i64 0, i32 0
  %285 = load i32, i32* %284, align 4, !noalias !1960
  store i32 %285, i32* %152, align 4, !alias.scope !1960
  store i32 %171, i32* %153, align 4, !alias.scope !1960
  %286 = load %"class.std::__1::tuple.485"*, %"class.std::__1::tuple.485"** %154, align 8
  call void @_ZN8gemmlowp12UnpackResultINS_12KernelFormatINS_16KernelSideFormatINS_10CellFormatILi4ELi16ELNS_9CellOrderE1EEELi1EEES6_EENS_9MatrixMapIsLNS_8MapOrderE0EEENS_12PackedResultENS_9VectorDupIKiLNS_11VectorShapeE0EEENSC_ISD_LSE_1EEENSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEEEEvPT0_RKNS_17MatrixBlockBoundsERKT1_iPSD_SV_RKT2_RKT3_RKT4_(%"class.gemmlowp::MatrixMap.479"* %143, %"struct.gemmlowp::MatrixBlockBounds"* nonnull dereferenceable(16) %7, %"class.gemmlowp::PackedResult"* nonnull dereferenceable(40) %6, i32 %15, i32* %269, i32* %279, %"class.gemmlowp::VectorDup"* nonnull dereferenceable(8) %8, %"class.gemmlowp::VectorDup.194"* nonnull dereferenceable(8) %9, %"class.std::__1::tuple.485"* dereferenceable(20) %286)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %150) #19
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %146) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %136) #19
  %287 = load %"struct.gemmlowp::BlockParams"*, %"struct.gemmlowp::BlockParams"** %19, align 8
  %288 = getelementptr inbounds %"struct.gemmlowp::BlockParams", %"struct.gemmlowp::BlockParams"* %287, i64 0, i32 3
  %289 = load i32, i32* %288, align 4
  %290 = add nsw i32 %289, %185
  %291 = icmp sgt i32 %11, %290
  br i1 %291, label %183, label %175
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i32 @_ZN6tflite3ops7builtin15fully_connected21EvalShuffledQuantizedILNS2_10KernelTypeE2EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_SH_(%struct.TfLiteContext*, %struct.TfLiteNode*, %struct.TfLiteFullyConnectedParams*, %"struct.tflite::ops::builtin::fully_connected::OpData"*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*) local_unnamed_addr #1 comdat {
  %10 = alloca %"struct.tflite::FullyConnectedParams", align 4
  %11 = alloca %"class.tflite::RuntimeShape", align 8
  %12 = alloca %"class.tflite::RuntimeShape", align 8
  %13 = alloca %"class.tflite::RuntimeShape", align 8
  %14 = alloca %"class.tflite::RuntimeShape", align 8
  %15 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %8, i64 0, i32 0
  %16 = load i32, i32* %15, align 8
  %17 = icmp eq i32 %16, 3
  br i1 %17, label %21, label %18

18:                                               ; preds = %9
  %19 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %20 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %19, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %20(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.34, i64 0, i64 0)) #19
  br label %220

21:                                               ; preds = %9
  %22 = bitcast %"struct.tflite::FullyConnectedParams"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %22) #19
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 4 %22, i8* align 4 bitcast ({ i32, i32, i32, i32, i32, i32, i32, float, float, i8, i8, i8, [1 x i8] }* @__const._ZN6tflite3ops7builtin15fully_connected13EvalQuantizedILNS2_10KernelTypeE2EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_.op_params to i8*), i64 40, i1 false)
  %23 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %10, i64 0, i32 3
  %24 = bitcast %"struct.tflite::ops::builtin::fully_connected::OpData"* %3 to <4 x i32>*
  %25 = load <4 x i32>, <4 x i32>* %24, align 4
  %26 = bitcast i32* %23 to <4 x i32>*
  store <4 x i32> %25, <4 x i32>* %26, align 4
  %27 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 4
  %28 = load i32, i32* %27, align 8
  %29 = icmp eq i32 %28, 1
  %30 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %10, i64 0, i32 9
  %31 = zext i1 %29 to i8
  store i8 %31, i8* %30, align 4
  %32 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 4
  %33 = load i32, i32* %32, align 8
  %34 = icmp eq i32 %33, 1
  %35 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %10, i64 0, i32 10
  %36 = zext i1 %34 to i8
  store i8 %36, i8* %35, align 1
  %37 = bitcast %"class.tflite::RuntimeShape"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %37) #19
  %38 = icmp eq %struct.TfLiteTensor* %4, null
  br i1 %38, label %39, label %41

39:                                               ; preds = %21
  %40 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 0
  store i32 0, i32* %40, align 8, !alias.scope !1963
  br label %69

41:                                               ; preds = %21
  %42 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 2
  %43 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %42, align 8, !noalias !1963
  %44 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %43, i64 0, i32 0
  %45 = load i32, i32* %44, align 4, !noalias !1963
  %46 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %43, i64 0, i32 1, i64 0
  %47 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 0
  store i32 %45, i32* %47, align 8, !alias.scope !1963
  %48 = icmp sgt i32 %45, 5
  br i1 %48, label %49, label %56

49:                                               ; preds = %41
  %50 = sext i32 %45 to i64
  %51 = shl nsw i64 %50, 2
  %52 = tail call i8* @_Znam(i64 %51) #18, !noalias !1963
  %53 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 1, i32 0
  %54 = bitcast i32** %53 to i8**
  store i8* %52, i8** %54, align 8, !alias.scope !1963
  %55 = bitcast i8* %52 to i32*
  br label %61

56:                                               ; preds = %41
  %57 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 1
  %58 = bitcast %union.anon.54* %57 to i32*
  %59 = sext i32 %45 to i64
  %60 = shl nsw i64 %59, 2
  br label %61

61:                                               ; preds = %56, %49
  %62 = phi i64 [ %51, %49 ], [ %60, %56 ]
  %63 = phi i32* [ %55, %49 ], [ %58, %56 ]
  %64 = bitcast i32* %63 to i8*
  %65 = bitcast i32* %46 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %64, i8* align 4 %65, i64 %62, i1 false) #19
  %66 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 1
  %67 = bitcast %union.TfLitePtrUnion* %66 to i8**
  %68 = load i8*, i8** %67, align 8
  br label %69

69:                                               ; preds = %39, %61
  %70 = phi i8* [ %68, %61 ], [ null, %39 ]
  %71 = bitcast %"class.tflite::RuntimeShape"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %71) #19
  %72 = icmp eq %struct.TfLiteTensor* %5, null
  br i1 %72, label %73, label %75

73:                                               ; preds = %69
  %74 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 0
  store i32 0, i32* %74, align 8, !alias.scope !1966
  br label %103

75:                                               ; preds = %69
  %76 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 2
  %77 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %76, align 8, !noalias !1966
  %78 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %77, i64 0, i32 0
  %79 = load i32, i32* %78, align 4, !noalias !1966
  %80 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %77, i64 0, i32 1, i64 0
  %81 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 0
  store i32 %79, i32* %81, align 8, !alias.scope !1966
  %82 = icmp sgt i32 %79, 5
  br i1 %82, label %83, label %90

83:                                               ; preds = %75
  %84 = sext i32 %79 to i64
  %85 = shl nsw i64 %84, 2
  %86 = tail call i8* @_Znam(i64 %85) #18, !noalias !1966
  %87 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 1, i32 0
  %88 = bitcast i32** %87 to i8**
  store i8* %86, i8** %88, align 8, !alias.scope !1966
  %89 = bitcast i8* %86 to i32*
  br label %95

90:                                               ; preds = %75
  %91 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 1
  %92 = bitcast %union.anon.54* %91 to i32*
  %93 = sext i32 %79 to i64
  %94 = shl nsw i64 %93, 2
  br label %95

95:                                               ; preds = %90, %83
  %96 = phi i64 [ %85, %83 ], [ %94, %90 ]
  %97 = phi i32* [ %89, %83 ], [ %92, %90 ]
  %98 = bitcast i32* %97 to i8*
  %99 = bitcast i32* %80 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %98, i8* align 4 %99, i64 %96, i1 false) #19
  %100 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 1
  %101 = bitcast %union.TfLitePtrUnion* %100 to i8**
  %102 = load i8*, i8** %101, align 8
  br label %103

103:                                              ; preds = %73, %95
  %104 = phi i8* [ %102, %95 ], [ null, %73 ]
  %105 = bitcast %"class.tflite::RuntimeShape"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %105) #19
  %106 = icmp eq %struct.TfLiteTensor* %6, null
  br i1 %106, label %107, label %109

107:                                              ; preds = %103
  %108 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 0
  store i32 0, i32* %108, align 8, !alias.scope !1969
  br label %136

109:                                              ; preds = %103
  %110 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 2
  %111 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %110, align 8, !noalias !1969
  %112 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %111, i64 0, i32 0
  %113 = load i32, i32* %112, align 4, !noalias !1969
  %114 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %111, i64 0, i32 1, i64 0
  %115 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 0
  store i32 %113, i32* %115, align 8, !alias.scope !1969
  %116 = icmp sgt i32 %113, 5
  br i1 %116, label %117, label %124

117:                                              ; preds = %109
  %118 = sext i32 %113 to i64
  %119 = shl nsw i64 %118, 2
  %120 = tail call i8* @_Znam(i64 %119) #18, !noalias !1969
  %121 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 1, i32 0
  %122 = bitcast i32** %121 to i8**
  store i8* %120, i8** %122, align 8, !alias.scope !1969
  %123 = bitcast i8* %120 to i32*
  br label %129

124:                                              ; preds = %109
  %125 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 1
  %126 = bitcast %union.anon.54* %125 to i32*
  %127 = sext i32 %113 to i64
  %128 = shl nsw i64 %127, 2
  br label %129

129:                                              ; preds = %124, %117
  %130 = phi i64 [ %119, %117 ], [ %128, %124 ]
  %131 = phi i32* [ %123, %117 ], [ %126, %124 ]
  %132 = bitcast i32* %131 to i8*
  %133 = bitcast i32* %114 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %132, i8* align 4 %133, i64 %130, i1 false) #19
  %134 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 1, i32 0
  %135 = load i32*, i32** %134, align 8
  br label %136

136:                                              ; preds = %107, %129
  %137 = phi i32* [ %135, %129 ], [ null, %107 ]
  %138 = bitcast %"class.tflite::RuntimeShape"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %138) #19
  %139 = icmp eq %struct.TfLiteTensor* %7, null
  br i1 %139, label %140, label %142

140:                                              ; preds = %136
  %141 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 0
  store i32 0, i32* %141, align 8, !alias.scope !1972
  br label %170

142:                                              ; preds = %136
  %143 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 2
  %144 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %143, align 8, !noalias !1972
  %145 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %144, i64 0, i32 0
  %146 = load i32, i32* %145, align 4, !noalias !1972
  %147 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %144, i64 0, i32 1, i64 0
  %148 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 0
  store i32 %146, i32* %148, align 8, !alias.scope !1972
  %149 = icmp sgt i32 %146, 5
  br i1 %149, label %150, label %157

150:                                              ; preds = %142
  %151 = sext i32 %146 to i64
  %152 = shl nsw i64 %151, 2
  %153 = tail call i8* @_Znam(i64 %152) #18, !noalias !1972
  %154 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 1, i32 0
  %155 = bitcast i32** %154 to i8**
  store i8* %153, i8** %155, align 8, !alias.scope !1972
  %156 = bitcast i8* %153 to i32*
  br label %162

157:                                              ; preds = %142
  %158 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 1
  %159 = bitcast %union.anon.54* %158 to i32*
  %160 = sext i32 %146 to i64
  %161 = shl nsw i64 %160, 2
  br label %162

162:                                              ; preds = %157, %150
  %163 = phi i64 [ %152, %150 ], [ %161, %157 ]
  %164 = phi i32* [ %156, %150 ], [ %159, %157 ]
  %165 = bitcast i32* %164 to i8*
  %166 = bitcast i32* %147 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %165, i8* align 4 %166, i64 %163, i1 false) #19
  %167 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 1
  %168 = bitcast %union.TfLitePtrUnion* %167 to i16**
  %169 = load i16*, i16** %168, align 8
  br label %170

170:                                              ; preds = %140, %162
  %171 = phi i16* [ %169, %162 ], [ null, %140 ]
  %172 = icmp eq %struct.TfLiteTensor* %8, null
  br i1 %172, label %177, label %173

173:                                              ; preds = %170
  %174 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %8, i64 0, i32 1
  %175 = bitcast %union.TfLitePtrUnion* %174 to i8**
  %176 = load i8*, i8** %175, align 8
  br label %177

177:                                              ; preds = %170, %173
  %178 = phi i8* [ %176, %173 ], [ null, %170 ]
  %179 = tail call %"class.tflite::CpuBackendContext"* @_ZN6tflite17CpuBackendContext14GetFromContextEP13TfLiteContext(%struct.TfLiteContext* %0) #19
  call void @_ZN6tflite13optimized_ops22ShuffledFullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKiS6_PsPhPNS_17CpuBackendContextE(%"struct.tflite::FullyConnectedParams"* nonnull dereferenceable(40) %10, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %11, i8* %70, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %12, i8* %104, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %13, i32* %137, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %14, i16* %171, i8* %178, %"class.tflite::CpuBackendContext"* %179)
  %180 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 0
  %181 = load i32, i32* %180, align 8
  %182 = icmp sgt i32 %181, 5
  br i1 %182, label %183, label %189

183:                                              ; preds = %177
  %184 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 1, i32 0
  %185 = load i32*, i32** %184, align 8
  %186 = icmp eq i32* %185, null
  br i1 %186, label %189, label %187

187:                                              ; preds = %183
  %188 = bitcast i32* %185 to i8*
  call void @_ZdaPv(i8* %188) #18
  br label %189

189:                                              ; preds = %177, %183, %187
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %138) #19
  %190 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 0
  %191 = load i32, i32* %190, align 8
  %192 = icmp sgt i32 %191, 5
  br i1 %192, label %193, label %199

193:                                              ; preds = %189
  %194 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 1, i32 0
  %195 = load i32*, i32** %194, align 8
  %196 = icmp eq i32* %195, null
  br i1 %196, label %199, label %197

197:                                              ; preds = %193
  %198 = bitcast i32* %195 to i8*
  call void @_ZdaPv(i8* %198) #18
  br label %199

199:                                              ; preds = %189, %193, %197
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %105) #19
  %200 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 0
  %201 = load i32, i32* %200, align 8
  %202 = icmp sgt i32 %201, 5
  br i1 %202, label %203, label %209

203:                                              ; preds = %199
  %204 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %12, i64 0, i32 1, i32 0
  %205 = load i32*, i32** %204, align 8
  %206 = icmp eq i32* %205, null
  br i1 %206, label %209, label %207

207:                                              ; preds = %203
  %208 = bitcast i32* %205 to i8*
  call void @_ZdaPv(i8* %208) #18
  br label %209

209:                                              ; preds = %199, %203, %207
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %71) #19
  %210 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 0
  %211 = load i32, i32* %210, align 8
  %212 = icmp sgt i32 %211, 5
  br i1 %212, label %213, label %219

213:                                              ; preds = %209
  %214 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %11, i64 0, i32 1, i32 0
  %215 = load i32*, i32** %214, align 8
  %216 = icmp eq i32* %215, null
  br i1 %216, label %219, label %217

217:                                              ; preds = %213
  %218 = bitcast i32* %215 to i8*
  call void @_ZdaPv(i8* %218) #18
  br label %219

219:                                              ; preds = %209, %213, %217
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %37) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %22) #19
  br label %220

220:                                              ; preds = %219, %18
  %221 = phi i32 [ 1, %18 ], [ 0, %219 ]
  ret i32 %221
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i32 @_ZN6tflite3ops7builtin15fully_connected13EvalQuantizedILNS2_10KernelTypeE2EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_(%struct.TfLiteContext*, %struct.TfLiteNode*, %struct.TfLiteFullyConnectedParams*, %"struct.tflite::ops::builtin::fully_connected::OpData"*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*, %struct.TfLiteTensor*) local_unnamed_addr #1 comdat {
  %9 = alloca %"struct.tflite::cpu_backend_gemm::MatrixParams.429", align 4
  %10 = alloca %"struct.tflite::cpu_backend_gemm::MatrixParams.429", align 4
  %11 = alloca %"struct.tflite::cpu_backend_gemm::MatrixParams.429", align 4
  %12 = alloca %"struct.tflite::cpu_backend_gemm::GemmParams.431", align 8
  %13 = alloca %"class.tflite::RuntimeShape", align 8
  %14 = alloca %"class.tflite::RuntimeShape", align 8
  %15 = alloca %"class.tflite::RuntimeShape", align 8
  %16 = alloca %"class.tflite::RuntimeShape", align 8
  %17 = alloca %"class.tflite::RuntimeShape", align 8
  %18 = alloca %"class.tflite::RuntimeShape", align 8
  %19 = alloca %"class.tflite::RuntimeShape", align 8
  %20 = alloca %"class.tflite::RuntimeShape", align 8
  %21 = alloca %"struct.tflite::FullyConnectedParams", align 4
  %22 = alloca %"class.tflite::RuntimeShape", align 8
  %23 = alloca %"class.tflite::RuntimeShape", align 8
  %24 = alloca %"class.tflite::RuntimeShape", align 8
  %25 = alloca %"class.tflite::RuntimeShape", align 8
  %26 = alloca %"class.tflite::RuntimeShape", align 8
  %27 = alloca %"class.tflite::RuntimeShape", align 8
  %28 = alloca %"class.tflite::RuntimeShape", align 8
  %29 = alloca %"class.tflite::RuntimeShape", align 8
  %30 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 0
  %31 = load i32, i32* %30, align 8
  %32 = icmp eq i32 %31, 1
  br i1 %32, label %33, label %87

33:                                               ; preds = %8
  %34 = getelementptr inbounds %struct.TfLiteNode, %struct.TfLiteNode* %1, i64 0, i32 3
  %35 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %34, align 8
  %36 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %35, i64 0, i32 1, i64 0
  %37 = load i32, i32* %36, align 4
  %38 = icmp slt i32 %37, 0
  br i1 %38, label %44, label %39

39:                                               ; preds = %33
  %40 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %41 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %40, align 8
  %42 = sext i32 %37 to i64
  %43 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %41, i64 %42
  br label %44

44:                                               ; preds = %33, %39
  %45 = phi %struct.TfLiteTensor* [ %43, %39 ], [ null, %33 ]
  %46 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %35, i64 0, i32 1, i64 1
  %47 = load i32, i32* %46, align 4
  %48 = icmp slt i32 %47, 0
  br i1 %48, label %54, label %49

49:                                               ; preds = %44
  %50 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %51 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %50, align 8
  %52 = sext i32 %47 to i64
  %53 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %51, i64 %52
  br label %54

54:                                               ; preds = %44, %49
  %55 = phi %struct.TfLiteTensor* [ %53, %49 ], [ null, %44 ]
  %56 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %35, i64 0, i32 1, i64 2
  %57 = load i32, i32* %56, align 4
  %58 = icmp slt i32 %57, 0
  br i1 %58, label %64, label %59

59:                                               ; preds = %54
  %60 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %61 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %60, align 8
  %62 = sext i32 %57 to i64
  %63 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %61, i64 %62
  br label %64

64:                                               ; preds = %54, %59
  %65 = phi %struct.TfLiteTensor* [ %63, %59 ], [ null, %54 ]
  %66 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %35, i64 0, i32 1, i64 3
  %67 = load i32, i32* %66, align 4
  %68 = icmp slt i32 %67, 0
  br i1 %68, label %74, label %69

69:                                               ; preds = %64
  %70 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %71 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %70, align 8
  %72 = sext i32 %67 to i64
  %73 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %71, i64 %72
  br label %74

74:                                               ; preds = %64, %69
  %75 = phi %struct.TfLiteTensor* [ %73, %69 ], [ null, %64 ]
  %76 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %35, i64 0, i32 1, i64 4
  %77 = load i32, i32* %76, align 4
  %78 = icmp slt i32 %77, 0
  br i1 %78, label %84, label %79

79:                                               ; preds = %74
  %80 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 2
  %81 = load %struct.TfLiteTensor*, %struct.TfLiteTensor** %80, align 8
  %82 = sext i32 %77 to i64
  %83 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %81, i64 %82
  br label %84

84:                                               ; preds = %74, %79
  %85 = phi %struct.TfLiteTensor* [ %83, %79 ], [ null, %74 ]
  %86 = tail call i32 @_ZN6tflite3ops7builtin15fully_connected10EvalHybridEP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSD_SD_PSB_SE_SE_SE_SE_SE_(%struct.TfLiteContext* %0, %struct.TfLiteNode* undef, %struct.TfLiteFullyConnectedParams* %2, %"struct.tflite::ops::builtin::fully_connected::OpData"* %3, %struct.TfLiteTensor* %4, %struct.TfLiteTensor* %5, %struct.TfLiteTensor* %6, %struct.TfLiteTensor* %45, %struct.TfLiteTensor* %55, %struct.TfLiteTensor* %65, %struct.TfLiteTensor* %85, %struct.TfLiteTensor* %75, %struct.TfLiteTensor* %7)
  ret i32 0

87:                                               ; preds = %8
  %88 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 3, i32 1
  %89 = load i32, i32* %88, align 4
  %90 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 3, i32 1
  %91 = load i32, i32* %90, align 4
  %92 = sub nsw i32 0, %91
  %93 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 3, i32 1
  %94 = load i32, i32* %93, align 4
  %95 = sub nsw i32 0, %94
  %96 = bitcast %"struct.tflite::FullyConnectedParams"* %21 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %96) #19
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 4 %96, i8* align 4 bitcast ({ i32, i32, i32, i32, i32, i32, i32, float, float, i8, i8, i8, [1 x i8] }* @__const._ZN6tflite3ops7builtin15fully_connected13EvalQuantizedILNS2_10KernelTypeE2EEE12TfLiteStatusP13TfLiteContextP10TfLiteNodeP26TfLiteFullyConnectedParamsPNS2_6OpDataEPK12TfLiteTensorSG_SG_PSE_.op_params to i8*), i64 40, i1 false)
  %97 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %21, i64 0, i32 0
  store i32 %95, i32* %97, align 4
  %98 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %21, i64 0, i32 1
  store i32 %92, i32* %98, align 4
  %99 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %21, i64 0, i32 2
  store i32 %89, i32* %99, align 4
  %100 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %21, i64 0, i32 3
  %101 = bitcast %"struct.tflite::ops::builtin::fully_connected::OpData"* %3 to <4 x i32>*
  %102 = load <4 x i32>, <4 x i32>* %101, align 4
  %103 = bitcast i32* %100 to <4 x i32>*
  store <4 x i32> %102, <4 x i32>* %103, align 4
  %104 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 4
  %105 = load i32, i32* %104, align 8
  %106 = icmp eq i32 %105, 1
  %107 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %21, i64 0, i32 9
  %108 = zext i1 %106 to i8
  store i8 %108, i8* %107, align 4
  %109 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 4
  %110 = load i32, i32* %109, align 8
  %111 = icmp eq i32 %110, 1
  %112 = getelementptr inbounds %"struct.tflite::FullyConnectedParams", %"struct.tflite::FullyConnectedParams"* %21, i64 0, i32 10
  %113 = zext i1 %111 to i8
  store i8 %113, i8* %112, align 1
  %114 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 0
  %115 = load i32, i32* %114, align 8
  switch i32 %115, label %1057 [
    i32 3, label %116
    i32 9, label %292
    i32 7, label %573
  ]

116:                                              ; preds = %87
  %117 = bitcast %"class.tflite::RuntimeShape"* %22 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %117) #19
  %118 = icmp eq %struct.TfLiteTensor* %4, null
  br i1 %118, label %119, label %121

119:                                              ; preds = %116
  %120 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %22, i64 0, i32 0
  store i32 0, i32* %120, align 8, !alias.scope !1975
  br label %149

121:                                              ; preds = %116
  %122 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 2
  %123 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %122, align 8, !noalias !1975
  %124 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %123, i64 0, i32 0
  %125 = load i32, i32* %124, align 4, !noalias !1975
  %126 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %123, i64 0, i32 1, i64 0
  %127 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %22, i64 0, i32 0
  store i32 %125, i32* %127, align 8, !alias.scope !1975
  %128 = icmp sgt i32 %125, 5
  br i1 %128, label %129, label %136

129:                                              ; preds = %121
  %130 = sext i32 %125 to i64
  %131 = shl nsw i64 %130, 2
  %132 = tail call i8* @_Znam(i64 %131) #18, !noalias !1975
  %133 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %22, i64 0, i32 1, i32 0
  %134 = bitcast i32** %133 to i8**
  store i8* %132, i8** %134, align 8, !alias.scope !1975
  %135 = bitcast i8* %132 to i32*
  br label %141

136:                                              ; preds = %121
  %137 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %22, i64 0, i32 1
  %138 = bitcast %union.anon.54* %137 to i32*
  %139 = sext i32 %125 to i64
  %140 = shl nsw i64 %139, 2
  br label %141

141:                                              ; preds = %136, %129
  %142 = phi i64 [ %131, %129 ], [ %140, %136 ]
  %143 = phi i32* [ %135, %129 ], [ %138, %136 ]
  %144 = bitcast i32* %143 to i8*
  %145 = bitcast i32* %126 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %144, i8* align 4 %145, i64 %142, i1 false) #19
  %146 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 1
  %147 = bitcast %union.TfLitePtrUnion* %146 to i8**
  %148 = load i8*, i8** %147, align 8
  br label %149

149:                                              ; preds = %119, %141
  %150 = phi i8* [ %148, %141 ], [ null, %119 ]
  %151 = bitcast %"class.tflite::RuntimeShape"* %23 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %151) #19
  %152 = icmp eq %struct.TfLiteTensor* %5, null
  br i1 %152, label %153, label %155

153:                                              ; preds = %149
  %154 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %23, i64 0, i32 0
  store i32 0, i32* %154, align 8, !alias.scope !1978
  br label %183

155:                                              ; preds = %149
  %156 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 2
  %157 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %156, align 8, !noalias !1978
  %158 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %157, i64 0, i32 0
  %159 = load i32, i32* %158, align 4, !noalias !1978
  %160 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %157, i64 0, i32 1, i64 0
  %161 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %23, i64 0, i32 0
  store i32 %159, i32* %161, align 8, !alias.scope !1978
  %162 = icmp sgt i32 %159, 5
  br i1 %162, label %163, label %170

163:                                              ; preds = %155
  %164 = sext i32 %159 to i64
  %165 = shl nsw i64 %164, 2
  %166 = tail call i8* @_Znam(i64 %165) #18, !noalias !1978
  %167 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %23, i64 0, i32 1, i32 0
  %168 = bitcast i32** %167 to i8**
  store i8* %166, i8** %168, align 8, !alias.scope !1978
  %169 = bitcast i8* %166 to i32*
  br label %175

170:                                              ; preds = %155
  %171 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %23, i64 0, i32 1
  %172 = bitcast %union.anon.54* %171 to i32*
  %173 = sext i32 %159 to i64
  %174 = shl nsw i64 %173, 2
  br label %175

175:                                              ; preds = %170, %163
  %176 = phi i64 [ %165, %163 ], [ %174, %170 ]
  %177 = phi i32* [ %169, %163 ], [ %172, %170 ]
  %178 = bitcast i32* %177 to i8*
  %179 = bitcast i32* %160 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %178, i8* align 4 %179, i64 %176, i1 false) #19
  %180 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 1
  %181 = bitcast %union.TfLitePtrUnion* %180 to i8**
  %182 = load i8*, i8** %181, align 8
  br label %183

183:                                              ; preds = %153, %175
  %184 = phi i8* [ %182, %175 ], [ null, %153 ]
  %185 = bitcast %"class.tflite::RuntimeShape"* %24 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %185) #19
  %186 = icmp eq %struct.TfLiteTensor* %6, null
  br i1 %186, label %187, label %189

187:                                              ; preds = %183
  %188 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %24, i64 0, i32 0
  store i32 0, i32* %188, align 8, !alias.scope !1981
  br label %216

189:                                              ; preds = %183
  %190 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 2
  %191 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %190, align 8, !noalias !1981
  %192 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %191, i64 0, i32 0
  %193 = load i32, i32* %192, align 4, !noalias !1981
  %194 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %191, i64 0, i32 1, i64 0
  %195 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %24, i64 0, i32 0
  store i32 %193, i32* %195, align 8, !alias.scope !1981
  %196 = icmp sgt i32 %193, 5
  br i1 %196, label %197, label %204

197:                                              ; preds = %189
  %198 = sext i32 %193 to i64
  %199 = shl nsw i64 %198, 2
  %200 = tail call i8* @_Znam(i64 %199) #18, !noalias !1981
  %201 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %24, i64 0, i32 1, i32 0
  %202 = bitcast i32** %201 to i8**
  store i8* %200, i8** %202, align 8, !alias.scope !1981
  %203 = bitcast i8* %200 to i32*
  br label %209

204:                                              ; preds = %189
  %205 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %24, i64 0, i32 1
  %206 = bitcast %union.anon.54* %205 to i32*
  %207 = sext i32 %193 to i64
  %208 = shl nsw i64 %207, 2
  br label %209

209:                                              ; preds = %204, %197
  %210 = phi i64 [ %199, %197 ], [ %208, %204 ]
  %211 = phi i32* [ %203, %197 ], [ %206, %204 ]
  %212 = bitcast i32* %211 to i8*
  %213 = bitcast i32* %194 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %212, i8* align 4 %213, i64 %210, i1 false) #19
  %214 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 1, i32 0
  %215 = load i32*, i32** %214, align 8
  br label %216

216:                                              ; preds = %187, %209
  %217 = phi i32* [ %215, %209 ], [ null, %187 ]
  %218 = bitcast %"class.tflite::RuntimeShape"* %25 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %218) #19
  %219 = icmp eq %struct.TfLiteTensor* %7, null
  br i1 %219, label %220, label %222

220:                                              ; preds = %216
  %221 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %25, i64 0, i32 0
  store i32 0, i32* %221, align 8, !alias.scope !1984
  br label %250

222:                                              ; preds = %216
  %223 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 2
  %224 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %223, align 8, !noalias !1984
  %225 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %224, i64 0, i32 0
  %226 = load i32, i32* %225, align 4, !noalias !1984
  %227 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %224, i64 0, i32 1, i64 0
  %228 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %25, i64 0, i32 0
  store i32 %226, i32* %228, align 8, !alias.scope !1984
  %229 = icmp sgt i32 %226, 5
  br i1 %229, label %230, label %237

230:                                              ; preds = %222
  %231 = sext i32 %226 to i64
  %232 = shl nsw i64 %231, 2
  %233 = tail call i8* @_Znam(i64 %232) #18, !noalias !1984
  %234 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %25, i64 0, i32 1, i32 0
  %235 = bitcast i32** %234 to i8**
  store i8* %233, i8** %235, align 8, !alias.scope !1984
  %236 = bitcast i8* %233 to i32*
  br label %242

237:                                              ; preds = %222
  %238 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %25, i64 0, i32 1
  %239 = bitcast %union.anon.54* %238 to i32*
  %240 = sext i32 %226 to i64
  %241 = shl nsw i64 %240, 2
  br label %242

242:                                              ; preds = %237, %230
  %243 = phi i64 [ %232, %230 ], [ %241, %237 ]
  %244 = phi i32* [ %236, %230 ], [ %239, %237 ]
  %245 = bitcast i32* %244 to i8*
  %246 = bitcast i32* %227 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %245, i8* align 4 %246, i64 %243, i1 false) #19
  %247 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 1
  %248 = bitcast %union.TfLitePtrUnion* %247 to i8**
  %249 = load i8*, i8** %248, align 8
  br label %250

250:                                              ; preds = %220, %242
  %251 = phi i8* [ %249, %242 ], [ null, %220 ]
  %252 = tail call %"class.tflite::CpuBackendContext"* @_ZN6tflite17CpuBackendContext14GetFromContextEP13TfLiteContext(%struct.TfLiteContext* %0) #19
  call void @_ZN6tflite13optimized_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKiS6_PhPNS_17CpuBackendContextE(%"struct.tflite::FullyConnectedParams"* nonnull dereferenceable(40) %21, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %22, i8* %150, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %23, i8* %184, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %24, i32* %217, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %25, i8* %251, %"class.tflite::CpuBackendContext"* %252)
  %253 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %25, i64 0, i32 0
  %254 = load i32, i32* %253, align 8
  %255 = icmp sgt i32 %254, 5
  br i1 %255, label %256, label %262

256:                                              ; preds = %250
  %257 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %25, i64 0, i32 1, i32 0
  %258 = load i32*, i32** %257, align 8
  %259 = icmp eq i32* %258, null
  br i1 %259, label %262, label %260

260:                                              ; preds = %256
  %261 = bitcast i32* %258 to i8*
  call void @_ZdaPv(i8* %261) #18
  br label %262

262:                                              ; preds = %250, %256, %260
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %218) #19
  %263 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %24, i64 0, i32 0
  %264 = load i32, i32* %263, align 8
  %265 = icmp sgt i32 %264, 5
  br i1 %265, label %266, label %272

266:                                              ; preds = %262
  %267 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %24, i64 0, i32 1, i32 0
  %268 = load i32*, i32** %267, align 8
  %269 = icmp eq i32* %268, null
  br i1 %269, label %272, label %270

270:                                              ; preds = %266
  %271 = bitcast i32* %268 to i8*
  call void @_ZdaPv(i8* %271) #18
  br label %272

272:                                              ; preds = %262, %266, %270
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %185) #19
  %273 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %23, i64 0, i32 0
  %274 = load i32, i32* %273, align 8
  %275 = icmp sgt i32 %274, 5
  br i1 %275, label %276, label %282

276:                                              ; preds = %272
  %277 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %23, i64 0, i32 1, i32 0
  %278 = load i32*, i32** %277, align 8
  %279 = icmp eq i32* %278, null
  br i1 %279, label %282, label %280

280:                                              ; preds = %276
  %281 = bitcast i32* %278 to i8*
  call void @_ZdaPv(i8* %281) #18
  br label %282

282:                                              ; preds = %272, %276, %280
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %151) #19
  %283 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %22, i64 0, i32 0
  %284 = load i32, i32* %283, align 8
  %285 = icmp sgt i32 %284, 5
  br i1 %285, label %286, label %1060

286:                                              ; preds = %282
  %287 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %22, i64 0, i32 1, i32 0
  %288 = load i32*, i32** %287, align 8
  %289 = icmp eq i32* %288, null
  br i1 %289, label %1060, label %290

290:                                              ; preds = %286
  %291 = bitcast i32* %288 to i8*
  call void @_ZdaPv(i8* %291) #18
  br label %1060

292:                                              ; preds = %87
  %293 = getelementptr inbounds %"struct.tflite::ops::builtin::fully_connected::OpData", %"struct.tflite::ops::builtin::fully_connected::OpData"* %3, i64 0, i32 0
  %294 = getelementptr inbounds %"struct.tflite::ops::builtin::fully_connected::OpData", %"struct.tflite::ops::builtin::fully_connected::OpData"* %3, i64 0, i32 3
  %295 = getelementptr inbounds %"struct.tflite::ops::builtin::fully_connected::OpData", %"struct.tflite::ops::builtin::fully_connected::OpData"* %3, i64 0, i32 2
  %296 = getelementptr inbounds %"struct.tflite::ops::builtin::fully_connected::OpData", %"struct.tflite::ops::builtin::fully_connected::OpData"* %3, i64 0, i32 1
  %297 = tail call %"class.tflite::CpuBackendContext"* @_ZN6tflite17CpuBackendContext14GetFromContextEP13TfLiteContext(%struct.TfLiteContext* %0) #19
  %298 = load i32, i32* %93, align 4
  %299 = load i32, i32* %90, align 4
  %300 = load i32, i32* %88, align 4
  %301 = load i32, i32* %293, align 4
  %302 = load i32, i32* %296, align 4
  %303 = load i32, i32* %295, align 4
  %304 = load i32, i32* %294, align 4
  %305 = bitcast %"class.tflite::RuntimeShape"* %13 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %305) #19
  %306 = icmp eq %struct.TfLiteTensor* %4, null
  br i1 %306, label %307, label %309

307:                                              ; preds = %292
  %308 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 0
  store i32 0, i32* %308, align 8, !alias.scope !1987
  br label %337

309:                                              ; preds = %292
  %310 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 2
  %311 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %310, align 8, !noalias !1987
  %312 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %311, i64 0, i32 0
  %313 = load i32, i32* %312, align 4, !noalias !1987
  %314 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %311, i64 0, i32 1, i64 0
  %315 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 0
  store i32 %313, i32* %315, align 8, !alias.scope !1987
  %316 = icmp sgt i32 %313, 5
  br i1 %316, label %317, label %324

317:                                              ; preds = %309
  %318 = sext i32 %313 to i64
  %319 = shl nsw i64 %318, 2
  %320 = tail call i8* @_Znam(i64 %319) #18, !noalias !1987
  %321 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 1, i32 0
  %322 = bitcast i32** %321 to i8**
  store i8* %320, i8** %322, align 8, !alias.scope !1987
  %323 = bitcast i8* %320 to i32*
  br label %329

324:                                              ; preds = %309
  %325 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 1
  %326 = bitcast %union.anon.54* %325 to i32*
  %327 = sext i32 %313 to i64
  %328 = shl nsw i64 %327, 2
  br label %329

329:                                              ; preds = %324, %317
  %330 = phi i64 [ %319, %317 ], [ %328, %324 ]
  %331 = phi i32* [ %323, %317 ], [ %326, %324 ]
  %332 = bitcast i32* %331 to i8*
  %333 = bitcast i32* %314 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %332, i8* align 4 %333, i64 %330, i1 false) #19
  %334 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 1
  %335 = bitcast %union.TfLitePtrUnion* %334 to i8**
  %336 = load i8*, i8** %335, align 8
  br label %337

337:                                              ; preds = %329, %307
  %338 = phi i32 [ %313, %329 ], [ 0, %307 ]
  %339 = phi i8* [ %336, %329 ], [ null, %307 ]
  %340 = bitcast %"class.tflite::RuntimeShape"* %14 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %340) #19
  %341 = icmp eq %struct.TfLiteTensor* %5, null
  br i1 %341, label %342, label %344

342:                                              ; preds = %337
  %343 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 0
  store i32 0, i32* %343, align 8, !alias.scope !1990
  br label %372

344:                                              ; preds = %337
  %345 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 2
  %346 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %345, align 8, !noalias !1990
  %347 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %346, i64 0, i32 0
  %348 = load i32, i32* %347, align 4, !noalias !1990
  %349 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %346, i64 0, i32 1, i64 0
  %350 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 0
  store i32 %348, i32* %350, align 8, !alias.scope !1990
  %351 = icmp sgt i32 %348, 5
  br i1 %351, label %352, label %359

352:                                              ; preds = %344
  %353 = sext i32 %348 to i64
  %354 = shl nsw i64 %353, 2
  %355 = tail call i8* @_Znam(i64 %354) #18, !noalias !1990
  %356 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 1, i32 0
  %357 = bitcast i32** %356 to i8**
  store i8* %355, i8** %357, align 8, !alias.scope !1990
  %358 = bitcast i8* %355 to i32*
  br label %364

359:                                              ; preds = %344
  %360 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 1
  %361 = bitcast %union.anon.54* %360 to i32*
  %362 = sext i32 %348 to i64
  %363 = shl nsw i64 %362, 2
  br label %364

364:                                              ; preds = %359, %352
  %365 = phi i64 [ %354, %352 ], [ %363, %359 ]
  %366 = phi i32* [ %358, %352 ], [ %361, %359 ]
  %367 = bitcast i32* %366 to i8*
  %368 = bitcast i32* %349 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %367, i8* align 4 %368, i64 %365, i1 false) #19
  %369 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 1
  %370 = bitcast %union.TfLitePtrUnion* %369 to i8**
  %371 = load i8*, i8** %370, align 8
  br label %372

372:                                              ; preds = %364, %342
  %373 = phi i32 [ %348, %364 ], [ 0, %342 ]
  %374 = phi i8* [ %371, %364 ], [ null, %342 ]
  %375 = bitcast %"class.tflite::RuntimeShape"* %15 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %375) #19
  %376 = icmp eq %struct.TfLiteTensor* %6, null
  br i1 %376, label %377, label %379

377:                                              ; preds = %372
  %378 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %15, i64 0, i32 0
  store i32 0, i32* %378, align 8, !alias.scope !1993
  br label %406

379:                                              ; preds = %372
  %380 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 2
  %381 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %380, align 8, !noalias !1993
  %382 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %381, i64 0, i32 0
  %383 = load i32, i32* %382, align 4, !noalias !1993
  %384 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %381, i64 0, i32 1, i64 0
  %385 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %15, i64 0, i32 0
  store i32 %383, i32* %385, align 8, !alias.scope !1993
  %386 = icmp sgt i32 %383, 5
  br i1 %386, label %387, label %394

387:                                              ; preds = %379
  %388 = sext i32 %383 to i64
  %389 = shl nsw i64 %388, 2
  %390 = tail call i8* @_Znam(i64 %389) #18, !noalias !1993
  %391 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %15, i64 0, i32 1, i32 0
  %392 = bitcast i32** %391 to i8**
  store i8* %390, i8** %392, align 8, !alias.scope !1993
  %393 = bitcast i8* %390 to i32*
  br label %399

394:                                              ; preds = %379
  %395 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %15, i64 0, i32 1
  %396 = bitcast %union.anon.54* %395 to i32*
  %397 = sext i32 %383 to i64
  %398 = shl nsw i64 %397, 2
  br label %399

399:                                              ; preds = %394, %387
  %400 = phi i64 [ %389, %387 ], [ %398, %394 ]
  %401 = phi i32* [ %393, %387 ], [ %396, %394 ]
  %402 = bitcast i32* %401 to i8*
  %403 = bitcast i32* %384 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %402, i8* align 4 %403, i64 %400, i1 false) #19
  %404 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 1, i32 0
  %405 = load i32*, i32** %404, align 8
  br label %406

406:                                              ; preds = %399, %377
  %407 = phi i32 [ %383, %399 ], [ 0, %377 ]
  %408 = phi i32* [ %405, %399 ], [ null, %377 ]
  %409 = bitcast %"class.tflite::RuntimeShape"* %16 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %409) #19
  %410 = icmp eq %struct.TfLiteTensor* %7, null
  br i1 %410, label %411, label %413

411:                                              ; preds = %406
  %412 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %16, i64 0, i32 0
  store i32 0, i32* %412, align 8, !alias.scope !1996
  br label %489

413:                                              ; preds = %406
  %414 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 2
  %415 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %414, align 8, !noalias !1996
  %416 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %415, i64 0, i32 0
  %417 = load i32, i32* %416, align 4, !noalias !1996
  %418 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %415, i64 0, i32 1, i64 0
  %419 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %16, i64 0, i32 0
  store i32 %417, i32* %419, align 8, !alias.scope !1996
  %420 = icmp sgt i32 %417, 5
  br i1 %420, label %421, label %428

421:                                              ; preds = %413
  %422 = sext i32 %417 to i64
  %423 = shl nsw i64 %422, 2
  %424 = tail call i8* @_Znam(i64 %423) #18, !noalias !1996
  %425 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %16, i64 0, i32 1, i32 0
  %426 = bitcast i32** %425 to i8**
  store i8* %424, i8** %426, align 8, !alias.scope !1996
  %427 = bitcast i8* %424 to i32*
  br label %433

428:                                              ; preds = %413
  %429 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %16, i64 0, i32 1
  %430 = bitcast %union.anon.54* %429 to i32*
  %431 = sext i32 %417 to i64
  %432 = shl nsw i64 %431, 2
  br label %433

433:                                              ; preds = %428, %421
  %434 = phi i64 [ %423, %421 ], [ %432, %428 ]
  %435 = phi i32* [ %427, %421 ], [ %430, %428 ]
  %436 = bitcast i32* %435 to i8*
  %437 = bitcast i32* %418 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %436, i8* align 4 %437, i64 %434, i1 false) #19
  %438 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 1
  %439 = bitcast %union.TfLitePtrUnion* %438 to i8**
  %440 = load i8*, i8** %439, align 8
  %441 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %16, i64 0, i32 1, i32 0
  %442 = load i32*, i32** %441, align 8
  %443 = bitcast i32* %442 to i8*
  %444 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %16, i64 0, i32 1
  %445 = bitcast %union.anon.54* %444 to i32*
  %446 = select i1 %420, i32* %442, i32* %445
  %447 = icmp sgt i32 %417, 0
  br i1 %447, label %448, label %489

448:                                              ; preds = %433
  %449 = add nsw i32 %417, -1
  %450 = zext i32 %449 to i64
  %451 = zext i32 %417 to i64
  %452 = add nsw i64 %451, -1
  %453 = and i64 %451, 3
  %454 = icmp ult i64 %452, 3
  br i1 %454, label %470, label %455

455:                                              ; preds = %448
  %456 = sub nsw i64 %451, %453
  br label %457

457:                                              ; preds = %1083, %455
  %458 = phi i64 [ 0, %455 ], [ %1086, %1083 ]
  %459 = phi i32 [ 1, %455 ], [ %1085, %1083 ]
  %460 = phi i64 [ %456, %455 ], [ %1087, %1083 ]
  %461 = icmp eq i64 %458, %450
  br i1 %461, label %465, label %462

462:                                              ; preds = %457
  %463 = getelementptr inbounds i32, i32* %446, i64 %458
  %464 = load i32, i32* %463, align 4
  br label %465

465:                                              ; preds = %462, %457
  %466 = phi i32 [ %464, %462 ], [ 1, %457 ]
  %467 = mul nsw i32 %466, %459
  %468 = or i64 %458, 1
  %469 = icmp eq i64 %468, %450
  br i1 %469, label %1067, label %1064

470:                                              ; preds = %1083, %448
  %471 = phi i32 [ undef, %448 ], [ %1085, %1083 ]
  %472 = phi i64 [ 0, %448 ], [ %1086, %1083 ]
  %473 = phi i32 [ 1, %448 ], [ %1085, %1083 ]
  %474 = icmp eq i64 %453, 0
  br i1 %474, label %489, label %475

475:                                              ; preds = %470, %483
  %476 = phi i64 [ %486, %483 ], [ %472, %470 ]
  %477 = phi i32 [ %485, %483 ], [ %473, %470 ]
  %478 = phi i64 [ %487, %483 ], [ %453, %470 ]
  %479 = icmp eq i64 %476, %450
  br i1 %479, label %483, label %480

480:                                              ; preds = %475
  %481 = getelementptr inbounds i32, i32* %446, i64 %476
  %482 = load i32, i32* %481, align 4
  br label %483

483:                                              ; preds = %480, %475
  %484 = phi i32 [ %482, %480 ], [ 1, %475 ]
  %485 = mul nsw i32 %484, %477
  %486 = add nuw nsw i64 %476, 1
  %487 = add i64 %478, -1
  %488 = icmp eq i64 %487, 0
  br i1 %488, label %489, label %475, !llvm.loop !1999

489:                                              ; preds = %470, %483, %433, %411
  %490 = phi i1 [ %420, %433 ], [ false, %411 ], [ %420, %483 ], [ %420, %470 ]
  %491 = phi i8* [ %440, %433 ], [ null, %411 ], [ %440, %483 ], [ %440, %470 ]
  %492 = phi i32* [ %442, %433 ], [ undef, %411 ], [ %442, %483 ], [ %442, %470 ]
  %493 = phi i8* [ %443, %433 ], [ undef, %411 ], [ %443, %483 ], [ %443, %470 ]
  %494 = phi i32 [ 1, %433 ], [ 1, %411 ], [ %471, %470 ], [ %485, %483 ]
  %495 = add nsw i32 %373, -2
  %496 = icmp sgt i32 %373, 5
  %497 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 1
  br i1 %496, label %498, label %506

498:                                              ; preds = %489
  %499 = getelementptr inbounds %union.anon.54, %union.anon.54* %497, i64 0, i32 0
  %500 = load i32*, i32** %499, align 8
  %501 = sext i32 %495 to i64
  %502 = getelementptr inbounds i32, i32* %500, i64 %501
  %503 = add nsw i32 %373, -1
  %504 = sext i32 %503 to i64
  %505 = getelementptr inbounds i32, i32* %500, i64 %504
  br label %513

506:                                              ; preds = %489
  %507 = bitcast %union.anon.54* %497 to [5 x i32]*
  %508 = sext i32 %495 to i64
  %509 = getelementptr inbounds [5 x i32], [5 x i32]* %507, i64 0, i64 %508
  %510 = add nsw i32 %373, -1
  %511 = sext i32 %510 to i64
  %512 = getelementptr inbounds [5 x i32], [5 x i32]* %507, i64 0, i64 %511
  br label %513

513:                                              ; preds = %506, %498
  %514 = phi i32* [ %505, %498 ], [ %512, %506 ]
  %515 = phi i32* [ %502, %498 ], [ %509, %506 ]
  %516 = load i32, i32* %515, align 4
  %517 = load i32, i32* %514, align 4
  %518 = bitcast %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %9 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %518) #19
  %519 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %9, i64 0, i32 0
  %520 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %9, i64 0, i32 1
  %521 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %9, i64 0, i32 2
  %522 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %9, i64 0, i32 3
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %518, i8 -86, i64 16, i1 false) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %518, i8 0, i64 14, i1 false) #19
  store i32 %516, i32* %520, align 4
  store i32 %517, i32* %521, align 4
  store i32 1, i32* %519, align 4
  %523 = trunc i32 %299 to i8
  store i8 %523, i8* %522, align 4
  %524 = bitcast %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %10 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %524) #19
  %525 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %10, i64 0, i32 0
  %526 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %10, i64 0, i32 1
  %527 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %10, i64 0, i32 2
  %528 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %10, i64 0, i32 3
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %524, i8 -86, i64 16, i1 false) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %524, i8 0, i64 14, i1 false) #19
  store i32 %517, i32* %526, align 4
  store i32 %494, i32* %527, align 4
  store i32 0, i32* %525, align 4
  %529 = trunc i32 %298 to i8
  store i8 %529, i8* %528, align 4
  %530 = bitcast %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %11 to i8*
  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %530) #19
  %531 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %11, i64 0, i32 0
  %532 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %11, i64 0, i32 1
  %533 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %11, i64 0, i32 2
  %534 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::MatrixParams.429", %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* %11, i64 0, i32 3
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %530, i8 -86, i64 16, i1 false) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 %530, i8 0, i64 14, i1 false) #19
  store i32 %516, i32* %532, align 4
  store i32 %494, i32* %533, align 4
  store i32 0, i32* %531, align 4
  %535 = trunc i32 %300 to i8
  store i8 %535, i8* %534, align 4
  %536 = bitcast %"struct.tflite::cpu_backend_gemm::GemmParams.431"* %12 to i8*
  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %536) #19
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %536, i8 -86, i64 40, i1 false) #19
  %537 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.431", %"struct.tflite::cpu_backend_gemm::GemmParams.431"* %12, i64 0, i32 5
  %538 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.431", %"struct.tflite::cpu_backend_gemm::GemmParams.431"* %12, i64 0, i32 2
  %539 = bitcast i32** %538 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 %539, i8 0, i64 16, i1 false) #19
  %540 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.431", %"struct.tflite::cpu_backend_gemm::GemmParams.431"* %12, i64 0, i32 6
  %541 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.431", %"struct.tflite::cpu_backend_gemm::GemmParams.431"* %12, i64 0, i32 4
  store i32* %408, i32** %541, align 8
  %542 = trunc i32 %303 to i8
  store i8 %542, i8* %537, align 8
  %543 = trunc i32 %304 to i8
  store i8 %543, i8* %540, align 1
  %544 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.431", %"struct.tflite::cpu_backend_gemm::GemmParams.431"* %12, i64 0, i32 0
  store i32 %301, i32* %544, align 8
  %545 = getelementptr inbounds %"struct.tflite::cpu_backend_gemm::GemmParams.431", %"struct.tflite::cpu_backend_gemm::GemmParams.431"* %12, i64 0, i32 1
  store i32 %302, i32* %545, align 4
  call void @_ZN6tflite16cpu_backend_gemm6detail16GemmImplUsingRuyIaaiaLNS0_18QuantizationFlavorE1EE3RunERKNS0_12MatrixParamsIaEEPKaS8_SA_S8_PaRKNS0_10GemmParamsIiaLS3_1EEEPNS_17CpuBackendContextE(%"struct.tflite::cpu_backend_gemm::MatrixParams.429"* nonnull dereferenceable(16) %9, i8* %374, %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* nonnull dereferenceable(16) %10, i8* %339, %"struct.tflite::cpu_backend_gemm::MatrixParams.429"* nonnull dereferenceable(16) %11, i8* %491, %"struct.tflite::cpu_backend_gemm::GemmParams.431"* nonnull dereferenceable(40) %12, %"class.tflite::CpuBackendContext"* %297) #19
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %536) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %530) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %524) #19
  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %518) #19
  %546 = xor i1 %490, true
  %547 = icmp eq i32* %492, null
  %548 = or i1 %547, %546
  br i1 %548, label %550, label %549

549:                                              ; preds = %513
  call void @_ZdaPv(i8* %493) #18
  br label %550

550:                                              ; preds = %549, %513
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %409) #19
  %551 = icmp sgt i32 %407, 5
  br i1 %551, label %552, label %558

552:                                              ; preds = %550
  %553 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %15, i64 0, i32 1, i32 0
  %554 = load i32*, i32** %553, align 8
  %555 = icmp eq i32* %554, null
  br i1 %555, label %558, label %556

556:                                              ; preds = %552
  %557 = bitcast i32* %554 to i8*
  call void @_ZdaPv(i8* %557) #18
  br label %558

558:                                              ; preds = %556, %552, %550
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %375) #19
  br i1 %496, label %559, label %565

559:                                              ; preds = %558
  %560 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %14, i64 0, i32 1, i32 0
  %561 = load i32*, i32** %560, align 8
  %562 = icmp eq i32* %561, null
  br i1 %562, label %565, label %563

563:                                              ; preds = %559
  %564 = bitcast i32* %561 to i8*
  call void @_ZdaPv(i8* %564) #18
  br label %565

565:                                              ; preds = %563, %559, %558
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %340) #19
  %566 = icmp sgt i32 %338, 5
  br i1 %566, label %567, label %1060

567:                                              ; preds = %565
  %568 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %13, i64 0, i32 1, i32 0
  %569 = load i32*, i32** %568, align 8
  %570 = icmp eq i32* %569, null
  br i1 %570, label %1060, label %571

571:                                              ; preds = %567
  %572 = bitcast i32* %569 to i8*
  call void @_ZdaPv(i8* %572) #18
  br label %1060

573:                                              ; preds = %87
  %574 = icmp eq i32 %31, 7
  br i1 %574, label %575, label %881

575:                                              ; preds = %573
  %576 = bitcast %"class.tflite::RuntimeShape"* %17 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %576) #19
  %577 = icmp eq %struct.TfLiteTensor* %4, null
  br i1 %577, label %578, label %580

578:                                              ; preds = %575
  %579 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %17, i64 0, i32 0
  store i32 0, i32* %579, align 8, !alias.scope !2000
  br label %608

580:                                              ; preds = %575
  %581 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 2
  %582 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %581, align 8, !noalias !2000
  %583 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %582, i64 0, i32 0
  %584 = load i32, i32* %583, align 4, !noalias !2000
  %585 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %582, i64 0, i32 1, i64 0
  %586 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %17, i64 0, i32 0
  store i32 %584, i32* %586, align 8, !alias.scope !2000
  %587 = icmp sgt i32 %584, 5
  br i1 %587, label %588, label %595

588:                                              ; preds = %580
  %589 = sext i32 %584 to i64
  %590 = shl nsw i64 %589, 2
  %591 = tail call i8* @_Znam(i64 %590) #18, !noalias !2000
  %592 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %17, i64 0, i32 1, i32 0
  %593 = bitcast i32** %592 to i8**
  store i8* %591, i8** %593, align 8, !alias.scope !2000
  %594 = bitcast i8* %591 to i32*
  br label %600

595:                                              ; preds = %580
  %596 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %17, i64 0, i32 1
  %597 = bitcast %union.anon.54* %596 to i32*
  %598 = sext i32 %584 to i64
  %599 = shl nsw i64 %598, 2
  br label %600

600:                                              ; preds = %595, %588
  %601 = phi i64 [ %590, %588 ], [ %599, %595 ]
  %602 = phi i32* [ %594, %588 ], [ %597, %595 ]
  %603 = bitcast i32* %602 to i8*
  %604 = bitcast i32* %585 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %603, i8* align 4 %604, i64 %601, i1 false) #19
  %605 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 1
  %606 = bitcast %union.TfLitePtrUnion* %605 to i16**
  %607 = load i16*, i16** %606, align 8
  br label %608

608:                                              ; preds = %600, %578
  %609 = phi i32 [ %584, %600 ], [ 0, %578 ]
  %610 = phi i16* [ %607, %600 ], [ null, %578 ]
  %611 = bitcast %"class.tflite::RuntimeShape"* %18 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %611) #19
  %612 = icmp eq %struct.TfLiteTensor* %5, null
  br i1 %612, label %613, label %615

613:                                              ; preds = %608
  %614 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %18, i64 0, i32 0
  store i32 0, i32* %614, align 8, !alias.scope !2003
  br label %643

615:                                              ; preds = %608
  %616 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 2
  %617 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %616, align 8, !noalias !2003
  %618 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %617, i64 0, i32 0
  %619 = load i32, i32* %618, align 4, !noalias !2003
  %620 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %617, i64 0, i32 1, i64 0
  %621 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %18, i64 0, i32 0
  store i32 %619, i32* %621, align 8, !alias.scope !2003
  %622 = icmp sgt i32 %619, 5
  br i1 %622, label %623, label %630

623:                                              ; preds = %615
  %624 = sext i32 %619 to i64
  %625 = shl nsw i64 %624, 2
  %626 = tail call i8* @_Znam(i64 %625) #18, !noalias !2003
  %627 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %18, i64 0, i32 1, i32 0
  %628 = bitcast i32** %627 to i8**
  store i8* %626, i8** %628, align 8, !alias.scope !2003
  %629 = bitcast i8* %626 to i32*
  br label %635

630:                                              ; preds = %615
  %631 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %18, i64 0, i32 1
  %632 = bitcast %union.anon.54* %631 to i32*
  %633 = sext i32 %619 to i64
  %634 = shl nsw i64 %633, 2
  br label %635

635:                                              ; preds = %630, %623
  %636 = phi i64 [ %625, %623 ], [ %634, %630 ]
  %637 = phi i32* [ %629, %623 ], [ %632, %630 ]
  %638 = bitcast i32* %637 to i8*
  %639 = bitcast i32* %620 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %638, i8* align 4 %639, i64 %636, i1 false) #19
  %640 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 1
  %641 = bitcast %union.TfLitePtrUnion* %640 to i8**
  %642 = load i8*, i8** %641, align 8
  br label %643

643:                                              ; preds = %635, %613
  %644 = phi i32 [ %619, %635 ], [ 0, %613 ]
  %645 = phi i8* [ %642, %635 ], [ null, %613 ]
  %646 = bitcast %"class.tflite::RuntimeShape"* %19 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %646) #19
  %647 = icmp eq %struct.TfLiteTensor* %6, null
  br i1 %647, label %648, label %650

648:                                              ; preds = %643
  %649 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %19, i64 0, i32 0
  store i32 0, i32* %649, align 8, !alias.scope !2006
  br label %678

650:                                              ; preds = %643
  %651 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 2
  %652 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %651, align 8, !noalias !2006
  %653 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %652, i64 0, i32 0
  %654 = load i32, i32* %653, align 4, !noalias !2006
  %655 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %652, i64 0, i32 1, i64 0
  %656 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %19, i64 0, i32 0
  store i32 %654, i32* %656, align 8, !alias.scope !2006
  %657 = icmp sgt i32 %654, 5
  br i1 %657, label %658, label %665

658:                                              ; preds = %650
  %659 = sext i32 %654 to i64
  %660 = shl nsw i64 %659, 2
  %661 = tail call i8* @_Znam(i64 %660) #18, !noalias !2006
  %662 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %19, i64 0, i32 1, i32 0
  %663 = bitcast i32** %662 to i8**
  store i8* %661, i8** %663, align 8, !alias.scope !2006
  %664 = bitcast i8* %661 to i32*
  br label %670

665:                                              ; preds = %650
  %666 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %19, i64 0, i32 1
  %667 = bitcast %union.anon.54* %666 to i32*
  %668 = sext i32 %654 to i64
  %669 = shl nsw i64 %668, 2
  br label %670

670:                                              ; preds = %665, %658
  %671 = phi i64 [ %660, %658 ], [ %669, %665 ]
  %672 = phi i32* [ %664, %658 ], [ %667, %665 ]
  %673 = bitcast i32* %672 to i8*
  %674 = bitcast i32* %655 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %673, i8* align 4 %674, i64 %671, i1 false) #19
  %675 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 1
  %676 = bitcast %union.TfLitePtrUnion* %675 to i64**
  %677 = load i64*, i64** %676, align 8
  br label %678

678:                                              ; preds = %670, %648
  %679 = phi i32 [ %654, %670 ], [ 0, %648 ]
  %680 = phi i64* [ %677, %670 ], [ null, %648 ]
  %681 = bitcast %"class.tflite::RuntimeShape"* %20 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %681) #19
  %682 = icmp eq %struct.TfLiteTensor* %7, null
  br i1 %682, label %683, label %686

683:                                              ; preds = %678
  %684 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %20, i64 0, i32 0
  store i32 0, i32* %684, align 8, !alias.scope !2009
  %685 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %20, i64 0, i32 1
  br label %719

686:                                              ; preds = %678
  %687 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 2
  %688 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %687, align 8, !noalias !2009
  %689 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %688, i64 0, i32 0
  %690 = load i32, i32* %689, align 4, !noalias !2009
  %691 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %688, i64 0, i32 1, i64 0
  %692 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %20, i64 0, i32 0
  store i32 %690, i32* %692, align 8, !alias.scope !2009
  %693 = icmp sgt i32 %690, 5
  br i1 %693, label %694, label %701

694:                                              ; preds = %686
  %695 = sext i32 %690 to i64
  %696 = shl nsw i64 %695, 2
  %697 = tail call i8* @_Znam(i64 %696) #18, !noalias !2009
  %698 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %20, i64 0, i32 1, i32 0
  %699 = bitcast i32** %698 to i8**
  store i8* %697, i8** %699, align 8, !alias.scope !2009
  %700 = bitcast i8* %697 to i32*
  br label %706

701:                                              ; preds = %686
  %702 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %20, i64 0, i32 1
  %703 = bitcast %union.anon.54* %702 to i32*
  %704 = sext i32 %690 to i64
  %705 = shl nsw i64 %704, 2
  br label %706

706:                                              ; preds = %701, %694
  %707 = phi i64 [ %696, %694 ], [ %705, %701 ]
  %708 = phi i32* [ %700, %694 ], [ %703, %701 ]
  %709 = bitcast i32* %708 to i8*
  %710 = bitcast i32* %691 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %709, i8* align 4 %710, i64 %707, i1 false) #19
  %711 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 1
  %712 = bitcast %union.TfLitePtrUnion* %711 to i16**
  %713 = load i16*, i16** %712, align 8
  %714 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %20, i64 0, i32 1, i32 0
  %715 = load i32*, i32** %714, align 8
  %716 = bitcast i32* %715 to i8*
  %717 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %20, i64 0, i32 1
  %718 = getelementptr inbounds i32, i32* %715, i64 1
  br i1 %693, label %727, label %719

719:                                              ; preds = %706, %683
  %720 = phi %union.anon.54* [ %685, %683 ], [ %717, %706 ]
  %721 = phi i16* [ null, %683 ], [ %713, %706 ]
  %722 = phi i32* [ undef, %683 ], [ %715, %706 ]
  %723 = phi i8* [ undef, %683 ], [ %716, %706 ]
  %724 = bitcast %union.anon.54* %720 to [5 x i32]*
  %725 = bitcast %union.anon.54* %720 to i32*
  %726 = getelementptr inbounds [5 x i32], [5 x i32]* %724, i64 0, i64 1
  br label %727

727:                                              ; preds = %719, %706
  %728 = phi i32* [ %725, %719 ], [ %715, %706 ]
  %729 = phi i8* [ %723, %719 ], [ %716, %706 ]
  %730 = phi i32* [ %722, %719 ], [ %715, %706 ]
  %731 = phi i1 [ true, %719 ], [ false, %706 ]
  %732 = phi i16* [ %721, %719 ], [ %713, %706 ]
  %733 = phi i32* [ %726, %719 ], [ %718, %706 ]
  %734 = load i32, i32* %728, align 4
  %735 = load i32, i32* %733, align 4
  %736 = icmp sgt i32 %644, 5
  %737 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %18, i64 0, i32 1
  %738 = add nsw i32 %644, -1
  %739 = getelementptr inbounds %union.anon.54, %union.anon.54* %737, i64 0, i32 0
  %740 = load i32*, i32** %739, align 8
  %741 = sext i32 %738 to i64
  %742 = getelementptr inbounds i32, i32* %740, i64 %741
  %743 = bitcast %union.anon.54* %737 to [5 x i32]*
  %744 = getelementptr inbounds [5 x i32], [5 x i32]* %743, i64 0, i64 %741
  %745 = select i1 %736, i32* %742, i32* %744
  %746 = load i32, i32* %745, align 4
  %747 = icmp sgt i32 %734, 0
  br i1 %747, label %748, label %855

748:                                              ; preds = %727
  %749 = icmp sgt i32 %735, 0
  %750 = icmp sgt i32 %746, 0
  %751 = icmp eq i64* %680, null
  %752 = extractelement <4 x i32> %102, i32 0
  %753 = add nsw i32 %752, 32768
  %754 = ashr i32 %753, 16
  %755 = extractelement <4 x i32> %102, i32 1
  %756 = sub nsw i32 15, %755
  %757 = sext i32 %754 to i64
  %758 = sub i32 14, %755
  %759 = zext i32 %758 to i64
  %760 = shl i64 1, %759
  %761 = zext i32 %756 to i64
  %762 = sext i32 %746 to i64
  %763 = sext i32 %735 to i64
  %764 = zext i32 %734 to i64
  %765 = zext i32 %735 to i64
  %766 = zext i32 %746 to i64
  %767 = and i64 %766, 1
  %768 = icmp eq i32 %746, 1
  %769 = sub nsw i64 %766, %767
  %770 = icmp eq i64 %767, 0
  %771 = extractelement <4 x i32> %102, i32 2
  %772 = extractelement <4 x i32> %102, i32 3
  br label %773

773:                                              ; preds = %782, %748
  %774 = phi i64 [ 0, %748 ], [ %783, %782 ]
  br i1 %749, label %775, label %782

775:                                              ; preds = %773
  %776 = mul nsw i64 %774, %762
  %777 = mul nsw i64 %774, %763
  br label %778

778:                                              ; preds = %840, %775
  %779 = phi i64 [ 0, %775 ], [ %853, %840 ]
  br i1 %750, label %780, label %802

780:                                              ; preds = %778
  %781 = mul nsw i64 %779, %762
  br i1 %768, label %785, label %804

782:                                              ; preds = %840, %773
  %783 = add nuw nsw i64 %774, 1
  %784 = icmp eq i64 %783, %764
  br i1 %784, label %855, label %773

785:                                              ; preds = %804, %780
  %786 = phi i64 [ undef, %780 ], [ %832, %804 ]
  %787 = phi i64 [ 0, %780 ], [ %833, %804 ]
  %788 = phi i64 [ 0, %780 ], [ %832, %804 ]
  br i1 %770, label %802, label %789

789:                                              ; preds = %785
  %790 = add nsw i64 %787, %781
  %791 = getelementptr inbounds i8, i8* %645, i64 %790
  %792 = load i8, i8* %791, align 1
  %793 = sext i8 %792 to i32
  %794 = sub i32 %793, %91
  %795 = add nsw i64 %787, %776
  %796 = getelementptr inbounds i16, i16* %610, i64 %795
  %797 = load i16, i16* %796, align 2
  %798 = sext i16 %797 to i32
  %799 = mul nsw i32 %794, %798
  %800 = sext i32 %799 to i64
  %801 = add nsw i64 %788, %800
  br label %802

802:                                              ; preds = %789, %785, %778
  %803 = phi i64 [ 0, %778 ], [ %786, %785 ], [ %801, %789 ]
  br i1 %751, label %840, label %836

804:                                              ; preds = %780, %804
  %805 = phi i64 [ %833, %804 ], [ 0, %780 ]
  %806 = phi i64 [ %832, %804 ], [ 0, %780 ]
  %807 = phi i64 [ %834, %804 ], [ %769, %780 ]
  %808 = add nsw i64 %805, %776
  %809 = getelementptr inbounds i16, i16* %610, i64 %808
  %810 = load i16, i16* %809, align 2
  %811 = sext i16 %810 to i32
  %812 = add nsw i64 %805, %781
  %813 = getelementptr inbounds i8, i8* %645, i64 %812
  %814 = load i8, i8* %813, align 1
  %815 = sext i8 %814 to i32
  %816 = sub i32 %815, %91
  %817 = mul nsw i32 %816, %811
  %818 = sext i32 %817 to i64
  %819 = add nsw i64 %806, %818
  %820 = or i64 %805, 1
  %821 = add nsw i64 %820, %776
  %822 = getelementptr inbounds i16, i16* %610, i64 %821
  %823 = load i16, i16* %822, align 2
  %824 = sext i16 %823 to i32
  %825 = add nsw i64 %820, %781
  %826 = getelementptr inbounds i8, i8* %645, i64 %825
  %827 = load i8, i8* %826, align 1
  %828 = sext i8 %827 to i32
  %829 = sub i32 %828, %91
  %830 = mul nsw i32 %829, %824
  %831 = sext i32 %830 to i64
  %832 = add nsw i64 %819, %831
  %833 = add nuw nsw i64 %805, 2
  %834 = add i64 %807, -2
  %835 = icmp eq i64 %834, 0
  br i1 %835, label %785, label %804

836:                                              ; preds = %802
  %837 = getelementptr inbounds i64, i64* %680, i64 %779
  %838 = load i64, i64* %837, align 8
  %839 = add nsw i64 %838, %803
  br label %840

840:                                              ; preds = %836, %802
  %841 = phi i64 [ %839, %836 ], [ %803, %802 ]
  %842 = mul nsw i64 %841, %757
  %843 = add nsw i64 %842, %760
  %844 = ashr i64 %843, %761
  %845 = trunc i64 %844 to i32
  %846 = icmp sgt i32 %771, %845
  %847 = select i1 %846, i32 %771, i32 %845
  %848 = icmp slt i32 %772, %847
  %849 = select i1 %848, i32 %772, i32 %847
  %850 = trunc i32 %849 to i16
  %851 = add nsw i64 %779, %777
  %852 = getelementptr inbounds i16, i16* %732, i64 %851
  store i16 %850, i16* %852, align 2
  %853 = add nuw nsw i64 %779, 1
  %854 = icmp eq i64 %853, %765
  br i1 %854, label %782, label %778

855:                                              ; preds = %782, %727
  %856 = icmp eq i32* %730, null
  %857 = or i1 %731, %856
  br i1 %857, label %859, label %858

858:                                              ; preds = %855
  tail call void @_ZdaPv(i8* %729) #18
  br label %859

859:                                              ; preds = %858, %855
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %681) #19
  %860 = icmp sgt i32 %679, 5
  br i1 %860, label %861, label %867

861:                                              ; preds = %859
  %862 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %19, i64 0, i32 1, i32 0
  %863 = load i32*, i32** %862, align 8
  %864 = icmp eq i32* %863, null
  br i1 %864, label %867, label %865

865:                                              ; preds = %861
  %866 = bitcast i32* %863 to i8*
  tail call void @_ZdaPv(i8* %866) #18
  br label %867

867:                                              ; preds = %865, %861, %859
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %646) #19
  %868 = xor i1 %736, true
  %869 = icmp eq i32* %740, null
  %870 = or i1 %869, %868
  br i1 %870, label %873, label %871

871:                                              ; preds = %867
  %872 = bitcast i32* %740 to i8*
  tail call void @_ZdaPv(i8* %872) #18
  br label %873

873:                                              ; preds = %871, %867
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %611) #19
  %874 = icmp sgt i32 %609, 5
  br i1 %874, label %875, label %1060

875:                                              ; preds = %873
  %876 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %17, i64 0, i32 1, i32 0
  %877 = load i32*, i32** %876, align 8
  %878 = icmp eq i32* %877, null
  br i1 %878, label %1060, label %879

879:                                              ; preds = %875
  %880 = bitcast i32* %877 to i8*
  tail call void @_ZdaPv(i8* %880) #18
  br label %1060

881:                                              ; preds = %573
  %882 = bitcast %"class.tflite::RuntimeShape"* %26 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %882) #19
  %883 = icmp eq %struct.TfLiteTensor* %4, null
  br i1 %883, label %884, label %886

884:                                              ; preds = %881
  %885 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %26, i64 0, i32 0
  store i32 0, i32* %885, align 8, !alias.scope !2012
  br label %914

886:                                              ; preds = %881
  %887 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 2
  %888 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %887, align 8, !noalias !2012
  %889 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %888, i64 0, i32 0
  %890 = load i32, i32* %889, align 4, !noalias !2012
  %891 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %888, i64 0, i32 1, i64 0
  %892 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %26, i64 0, i32 0
  store i32 %890, i32* %892, align 8, !alias.scope !2012
  %893 = icmp sgt i32 %890, 5
  br i1 %893, label %894, label %901

894:                                              ; preds = %886
  %895 = sext i32 %890 to i64
  %896 = shl nsw i64 %895, 2
  %897 = tail call i8* @_Znam(i64 %896) #18, !noalias !2012
  %898 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %26, i64 0, i32 1, i32 0
  %899 = bitcast i32** %898 to i8**
  store i8* %897, i8** %899, align 8, !alias.scope !2012
  %900 = bitcast i8* %897 to i32*
  br label %906

901:                                              ; preds = %886
  %902 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %26, i64 0, i32 1
  %903 = bitcast %union.anon.54* %902 to i32*
  %904 = sext i32 %890 to i64
  %905 = shl nsw i64 %904, 2
  br label %906

906:                                              ; preds = %901, %894
  %907 = phi i64 [ %896, %894 ], [ %905, %901 ]
  %908 = phi i32* [ %900, %894 ], [ %903, %901 ]
  %909 = bitcast i32* %908 to i8*
  %910 = bitcast i32* %891 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %909, i8* align 4 %910, i64 %907, i1 false) #19
  %911 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %4, i64 0, i32 1
  %912 = bitcast %union.TfLitePtrUnion* %911 to i8**
  %913 = load i8*, i8** %912, align 8
  br label %914

914:                                              ; preds = %884, %906
  %915 = phi i8* [ %913, %906 ], [ null, %884 ]
  %916 = bitcast %"class.tflite::RuntimeShape"* %27 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %916) #19
  %917 = icmp eq %struct.TfLiteTensor* %5, null
  br i1 %917, label %918, label %920

918:                                              ; preds = %914
  %919 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %27, i64 0, i32 0
  store i32 0, i32* %919, align 8, !alias.scope !2015
  br label %948

920:                                              ; preds = %914
  %921 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 2
  %922 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %921, align 8, !noalias !2015
  %923 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %922, i64 0, i32 0
  %924 = load i32, i32* %923, align 4, !noalias !2015
  %925 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %922, i64 0, i32 1, i64 0
  %926 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %27, i64 0, i32 0
  store i32 %924, i32* %926, align 8, !alias.scope !2015
  %927 = icmp sgt i32 %924, 5
  br i1 %927, label %928, label %935

928:                                              ; preds = %920
  %929 = sext i32 %924 to i64
  %930 = shl nsw i64 %929, 2
  %931 = tail call i8* @_Znam(i64 %930) #18, !noalias !2015
  %932 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %27, i64 0, i32 1, i32 0
  %933 = bitcast i32** %932 to i8**
  store i8* %931, i8** %933, align 8, !alias.scope !2015
  %934 = bitcast i8* %931 to i32*
  br label %940

935:                                              ; preds = %920
  %936 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %27, i64 0, i32 1
  %937 = bitcast %union.anon.54* %936 to i32*
  %938 = sext i32 %924 to i64
  %939 = shl nsw i64 %938, 2
  br label %940

940:                                              ; preds = %935, %928
  %941 = phi i64 [ %930, %928 ], [ %939, %935 ]
  %942 = phi i32* [ %934, %928 ], [ %937, %935 ]
  %943 = bitcast i32* %942 to i8*
  %944 = bitcast i32* %925 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %943, i8* align 4 %944, i64 %941, i1 false) #19
  %945 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %5, i64 0, i32 1
  %946 = bitcast %union.TfLitePtrUnion* %945 to i8**
  %947 = load i8*, i8** %946, align 8
  br label %948

948:                                              ; preds = %918, %940
  %949 = phi i8* [ %947, %940 ], [ null, %918 ]
  %950 = bitcast %"class.tflite::RuntimeShape"* %28 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %950) #19
  %951 = icmp eq %struct.TfLiteTensor* %6, null
  br i1 %951, label %952, label %954

952:                                              ; preds = %948
  %953 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %28, i64 0, i32 0
  store i32 0, i32* %953, align 8, !alias.scope !2018
  br label %981

954:                                              ; preds = %948
  %955 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 2
  %956 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %955, align 8, !noalias !2018
  %957 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %956, i64 0, i32 0
  %958 = load i32, i32* %957, align 4, !noalias !2018
  %959 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %956, i64 0, i32 1, i64 0
  %960 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %28, i64 0, i32 0
  store i32 %958, i32* %960, align 8, !alias.scope !2018
  %961 = icmp sgt i32 %958, 5
  br i1 %961, label %962, label %969

962:                                              ; preds = %954
  %963 = sext i32 %958 to i64
  %964 = shl nsw i64 %963, 2
  %965 = tail call i8* @_Znam(i64 %964) #18, !noalias !2018
  %966 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %28, i64 0, i32 1, i32 0
  %967 = bitcast i32** %966 to i8**
  store i8* %965, i8** %967, align 8, !alias.scope !2018
  %968 = bitcast i8* %965 to i32*
  br label %974

969:                                              ; preds = %954
  %970 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %28, i64 0, i32 1
  %971 = bitcast %union.anon.54* %970 to i32*
  %972 = sext i32 %958 to i64
  %973 = shl nsw i64 %972, 2
  br label %974

974:                                              ; preds = %969, %962
  %975 = phi i64 [ %964, %962 ], [ %973, %969 ]
  %976 = phi i32* [ %968, %962 ], [ %971, %969 ]
  %977 = bitcast i32* %976 to i8*
  %978 = bitcast i32* %959 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %977, i8* align 4 %978, i64 %975, i1 false) #19
  %979 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %6, i64 0, i32 1, i32 0
  %980 = load i32*, i32** %979, align 8
  br label %981

981:                                              ; preds = %952, %974
  %982 = phi i32* [ %980, %974 ], [ null, %952 ]
  %983 = bitcast %"class.tflite::RuntimeShape"* %29 to i8*
  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %983) #19
  %984 = icmp eq %struct.TfLiteTensor* %7, null
  br i1 %984, label %985, label %987

985:                                              ; preds = %981
  %986 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %29, i64 0, i32 0
  store i32 0, i32* %986, align 8, !alias.scope !2021
  br label %1015

987:                                              ; preds = %981
  %988 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 2
  %989 = load %struct.TfLiteIntArray*, %struct.TfLiteIntArray** %988, align 8, !noalias !2021
  %990 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %989, i64 0, i32 0
  %991 = load i32, i32* %990, align 4, !noalias !2021
  %992 = getelementptr inbounds %struct.TfLiteIntArray, %struct.TfLiteIntArray* %989, i64 0, i32 1, i64 0
  %993 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %29, i64 0, i32 0
  store i32 %991, i32* %993, align 8, !alias.scope !2021
  %994 = icmp sgt i32 %991, 5
  br i1 %994, label %995, label %1002

995:                                              ; preds = %987
  %996 = sext i32 %991 to i64
  %997 = shl nsw i64 %996, 2
  %998 = tail call i8* @_Znam(i64 %997) #18, !noalias !2021
  %999 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %29, i64 0, i32 1, i32 0
  %1000 = bitcast i32** %999 to i8**
  store i8* %998, i8** %1000, align 8, !alias.scope !2021
  %1001 = bitcast i8* %998 to i32*
  br label %1007

1002:                                             ; preds = %987
  %1003 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %29, i64 0, i32 1
  %1004 = bitcast %union.anon.54* %1003 to i32*
  %1005 = sext i32 %991 to i64
  %1006 = shl nsw i64 %1005, 2
  br label %1007

1007:                                             ; preds = %1002, %995
  %1008 = phi i64 [ %997, %995 ], [ %1006, %1002 ]
  %1009 = phi i32* [ %1001, %995 ], [ %1004, %1002 ]
  %1010 = bitcast i32* %1009 to i8*
  %1011 = bitcast i32* %992 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 4 %1010, i8* align 4 %1011, i64 %1008, i1 false) #19
  %1012 = getelementptr inbounds %struct.TfLiteTensor, %struct.TfLiteTensor* %7, i64 0, i32 1
  %1013 = bitcast %union.TfLitePtrUnion* %1012 to i16**
  %1014 = load i16*, i16** %1013, align 8
  br label %1015

1015:                                             ; preds = %985, %1007
  %1016 = phi i16* [ %1014, %1007 ], [ null, %985 ]
  %1017 = tail call %"class.tflite::CpuBackendContext"* @_ZN6tflite17CpuBackendContext14GetFromContextEP13TfLiteContext(%struct.TfLiteContext* %0) #19
  call void @_ZN6tflite13optimized_ops14FullyConnectedERKNS_20FullyConnectedParamsERKNS_12RuntimeShapeEPKhS6_S8_S6_PKiS6_PsPNS_17CpuBackendContextE(%"struct.tflite::FullyConnectedParams"* nonnull dereferenceable(40) %21, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %26, i8* %915, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %27, i8* %949, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %28, i32* %982, %"class.tflite::RuntimeShape"* nonnull dereferenceable(32) %29, i16* %1016, %"class.tflite::CpuBackendContext"* %1017)
  %1018 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %29, i64 0, i32 0
  %1019 = load i32, i32* %1018, align 8
  %1020 = icmp sgt i32 %1019, 5
  br i1 %1020, label %1021, label %1027

1021:                                             ; preds = %1015
  %1022 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %29, i64 0, i32 1, i32 0
  %1023 = load i32*, i32** %1022, align 8
  %1024 = icmp eq i32* %1023, null
  br i1 %1024, label %1027, label %1025

1025:                                             ; preds = %1021
  %1026 = bitcast i32* %1023 to i8*
  call void @_ZdaPv(i8* %1026) #18
  br label %1027

1027:                                             ; preds = %1015, %1021, %1025
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %983) #19
  %1028 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %28, i64 0, i32 0
  %1029 = load i32, i32* %1028, align 8
  %1030 = icmp sgt i32 %1029, 5
  br i1 %1030, label %1031, label %1037

1031:                                             ; preds = %1027
  %1032 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %28, i64 0, i32 1, i32 0
  %1033 = load i32*, i32** %1032, align 8
  %1034 = icmp eq i32* %1033, null
  br i1 %1034, label %1037, label %1035

1035:                                             ; preds = %1031
  %1036 = bitcast i32* %1033 to i8*
  call void @_ZdaPv(i8* %1036) #18
  br label %1037

1037:                                             ; preds = %1027, %1031, %1035
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %950) #19
  %1038 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %27, i64 0, i32 0
  %1039 = load i32, i32* %1038, align 8
  %1040 = icmp sgt i32 %1039, 5
  br i1 %1040, label %1041, label %1047

1041:                                             ; preds = %1037
  %1042 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %27, i64 0, i32 1, i32 0
  %1043 = load i32*, i32** %1042, align 8
  %1044 = icmp eq i32* %1043, null
  br i1 %1044, label %1047, label %1045

1045:                                             ; preds = %1041
  %1046 = bitcast i32* %1043 to i8*
  call void @_ZdaPv(i8* %1046) #18
  br label %1047

1047:                                             ; preds = %1037, %1041, %1045
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %916) #19
  %1048 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %26, i64 0, i32 0
  %1049 = load i32, i32* %1048, align 8
  %1050 = icmp sgt i32 %1049, 5
  br i1 %1050, label %1051, label %1060

1051:                                             ; preds = %1047
  %1052 = getelementptr inbounds %"class.tflite::RuntimeShape", %"class.tflite::RuntimeShape"* %26, i64 0, i32 1, i32 0
  %1053 = load i32*, i32** %1052, align 8
  %1054 = icmp eq i32* %1053, null
  br i1 %1054, label %1060, label %1055

1055:                                             ; preds = %1051
  %1056 = bitcast i32* %1053 to i8*
  call void @_ZdaPv(i8* %1056) #18
  br label %1060

1057:                                             ; preds = %87
  %1058 = getelementptr inbounds %struct.TfLiteContext, %struct.TfLiteContext* %0, i64 0, i32 5
  %1059 = load void (%struct.TfLiteContext*, i8*, ...)*, void (%struct.TfLiteContext*, i8*, ...)** %1058, align 8
  tail call void (%struct.TfLiteContext*, i8*, ...) %1059(%struct.TfLiteContext* %0, i8* getelementptr inbounds ([71 x i8], [71 x i8]* @.str.35, i64 0, i64 0)) #19
  br label %1062

1060:                                             ; preds = %1055, %1051, %1047, %879, %875, %873, %571, %567, %565, %290, %286, %282
  %1061 = phi i8* [ %117, %282 ], [ %117, %286 ], [ %117, %290 ], [ %305, %565 ], [ %305, %567 ], [ %305, %571 ], [ %576, %873 ], [ %576, %875 ], [ %576, %879 ], [ %882, %1047 ], [ %882, %1051 ], [ %882, %1055 ]
  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %1061) #19
  br label %1062

1062:                                             ; preds = %1057, %1060
  %1063 = phi i32 [ 0, %1060 ], [ 1, %1057 ]
  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %96) #19
  ret i32 %1063

1064:                                             ; preds = %465
  %1065 = getelementptr inbounds i32, i32* %446, i64 %468
  %1066 = load i32, i32* %1065, align 4
  br label %1067

1067:                                             ; preds = %1064, %465
  %1068 = phi i32 [ %1066, %1064 ], [ 1, %465 ]
  %1069 = mul nsw i32 %1068, %467
  %1070 = or i64 %458, 2
  %1071 = icmp eq i64 %1070, %450
  br i1 %1071, label %1075, label %1072

1072:                                             ; preds = %1067
  %1073 = getelementptr inbounds i32, i32* %446, i64 %1070
  %1074 = load i32, i32* %1073, align 4
  br label %1075

1075:                                             ; preds = %1072, %1067
  %1076 = phi i32 [ %1074, %1072 ], [ 1, %1067 ]
  %1077 = mul nsw i32 %1076, %1069
  %1078 = or i64 %458, 3
  %1079 = icmp eq i64 %1078, %450
  br i1 %1079, label %1083, label %1080

1080:                                             ; preds = %1075
  %1081 = getelementptr inbounds i32, i32* %446, i64 %1078
  %1082 = load i32, i32* %1081, align 4
  br label %1083

1083:                                             ; preds = %1080, %1075
  %1084 = phi i32 [ %1082, %1080 ], [ 1, %1075 ]
  %1085 = mul nsw i32 %1084, %1077
  %1086 = add nuw nsw i64 %458, 4
  %1087 = add i64 %460, -4
  %1088 = icmp eq i64 %1087, 0
  br i1 %1088, label %470, label %457
}

attributes #0 = { argmemonly nounwind }
attributes #1 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { nobuiltin nofree "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { nobuiltin nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { inlinehint nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #6 = { norecurse nounwind readnone ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #7 = { inlinehint nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #8 = { nounwind readnone speculatable }
attributes #9 = { nofree nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #10 = { nounwind readnone }
attributes #11 = { noreturn "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #12 = { noreturn nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #13 = { cold noreturn nounwind }
attributes #14 = { nounwind "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #15 = { nofree nounwind }
attributes #16 = { inaccessiblemem_or_argmemonly nounwind }
attributes #17 = { noinline nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #18 = { builtin nounwind }
attributes #19 = { nounwind }
attributes #20 = { noreturn nounwind }
attributes #21 = { cold nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = distinct !{!2, !3}
!3 = !{!"llvm.loop.isvectorized", i32 1}
!4 = distinct !{!4, !5}
!5 = !{!"llvm.loop.unroll.disable"}
!6 = distinct !{!6, !7, !3}
!7 = !{!"llvm.loop.unroll.runtime.disable"}
!8 = distinct !{!8, !5}
!9 = distinct !{!9, !5}
!10 = !{i8 0, i8 2}
!11 = distinct !{!11, !3}
!12 = distinct !{!12, !5}
!13 = distinct !{!13, !7, !3}
!14 = distinct !{!14, !5}
!15 = !{!16, !18}
!16 = distinct !{!16, !17, !"_ZN6tflite12tensor_utils17ApplyReluToVectorEPKfiPf: argument 0"}
!17 = distinct !{!17, !"_ZN6tflite12tensor_utils17ApplyReluToVectorEPKfiPf"}
!18 = distinct !{!18, !17, !"_ZN6tflite12tensor_utils17ApplyReluToVectorEPKfiPf: argument 1"}
!19 = !{!16}
!20 = !{!18}
!21 = !{!22, !24}
!22 = distinct !{!22, !23, !"_ZN6tflite12tensor_utils18ApplyRelu1ToVectorEPKfiPf: argument 0"}
!23 = distinct !{!23, !"_ZN6tflite12tensor_utils18ApplyRelu1ToVectorEPKfiPf"}
!24 = distinct !{!24, !23, !"_ZN6tflite12tensor_utils18ApplyRelu1ToVectorEPKfiPf: argument 1"}
!25 = !{!22}
!26 = !{!24}
!27 = !{!28, !30}
!28 = distinct !{!28, !29, !"_ZN6tflite12tensor_utils18ApplyRelu6ToVectorEPKfiPf: argument 0"}
!29 = distinct !{!29, !"_ZN6tflite12tensor_utils18ApplyRelu6ToVectorEPKfiPf"}
!30 = distinct !{!30, !29, !"_ZN6tflite12tensor_utils18ApplyRelu6ToVectorEPKfiPf: argument 1"}
!31 = !{!28}
!32 = !{!30}
!33 = !{!34, !36}
!34 = distinct !{!34, !35, !"_ZN6tflite12tensor_utils17ApplyTanhToVectorEPKfiPf: argument 0"}
!35 = distinct !{!35, !"_ZN6tflite12tensor_utils17ApplyTanhToVectorEPKfiPf"}
!36 = distinct !{!36, !35, !"_ZN6tflite12tensor_utils17ApplyTanhToVectorEPKfiPf: argument 1"}
!37 = !{!38}
!38 = distinct !{!38, !39, !"_ZN6tflite12tensor_utils20ApplySignbitToVectorEPKfiPf: argument 0"}
!39 = distinct !{!39, !"_ZN6tflite12tensor_utils20ApplySignbitToVectorEPKfiPf"}
!40 = !{!41}
!41 = distinct !{!41, !39, !"_ZN6tflite12tensor_utils20ApplySignbitToVectorEPKfiPf: argument 1"}
!42 = distinct !{!42, !3}
!43 = distinct !{!43, !7, !3}
!44 = !{!45, !47}
!45 = distinct !{!45, !46, !"_ZN6tflite12tensor_utils20ApplySigmoidToVectorEPKfiPf: argument 0"}
!46 = distinct !{!46, !"_ZN6tflite12tensor_utils20ApplySigmoidToVectorEPKfiPf"}
!47 = distinct !{!47, !46, !"_ZN6tflite12tensor_utils20ApplySigmoidToVectorEPKfiPf: argument 1"}
!48 = distinct !{!48, !3}
!49 = distinct !{!49, !5}
!50 = distinct !{!50, !7, !3}
!51 = distinct !{!51, !5}
!52 = distinct !{!52, !5}
!53 = !{!54}
!54 = distinct !{!54, !55}
!55 = distinct !{!55, !"LVerDomain"}
!56 = !{!57}
!57 = distinct !{!57, !55}
!58 = distinct !{!58, !3}
!59 = distinct !{!59, !3}
!60 = !{i32 7186468}
!61 = !{i32 7188361}
!62 = !{!"branch_weights", i32 1, i32 2000}
!63 = !{!"branch_weights", i32 2000, i32 1}
!64 = !{!65}
!65 = distinct !{!65, !66, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!66 = distinct !{!66, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!67 = !{!68}
!68 = distinct !{!68, !69, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!69 = distinct !{!69, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!70 = !{!71}
!71 = distinct !{!71, !72, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!72 = distinct !{!72, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!73 = !{!74}
!74 = distinct !{!74, !75, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!75 = distinct !{!75, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!76 = !{!77}
!77 = distinct !{!77, !78, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!78 = distinct !{!78, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!79 = !{!80}
!80 = distinct !{!80, !81, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!81 = distinct !{!81, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!82 = !{!83}
!83 = distinct !{!83, !84, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!84 = distinct !{!84, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!85 = !{!86}
!86 = distinct !{!86, !87, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!87 = distinct !{!87, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!88 = distinct !{!88, !5}
!89 = !{!90}
!90 = distinct !{!90, !91, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!91 = distinct !{!91, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!92 = !{!93}
!93 = distinct !{!93, !94, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!94 = distinct !{!94, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!95 = !{!96}
!96 = distinct !{!96, !97, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!97 = distinct !{!97, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!98 = !{!99}
!99 = distinct !{!99, !100, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!100 = distinct !{!100, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!101 = !{!102}
!102 = distinct !{!102, !103, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!103 = distinct !{!103, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!104 = !{!105}
!105 = distinct !{!105, !106, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!106 = distinct !{!106, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!107 = !{!108}
!108 = distinct !{!108, !109, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!109 = distinct !{!109, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!110 = !{!111}
!111 = distinct !{!111, !112, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!112 = distinct !{!112, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!113 = !{!114}
!114 = distinct !{!114, !115, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!115 = distinct !{!115, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!116 = !{!117}
!117 = distinct !{!117, !118, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!118 = distinct !{!118, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!119 = !{!120}
!120 = distinct !{!120, !121, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!121 = distinct !{!121, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!122 = !{!123}
!123 = distinct !{!123, !124, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!124 = distinct !{!124, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!125 = distinct !{!125, !3}
!126 = distinct !{!126, !7, !3}
!127 = !{!128}
!128 = distinct !{!128, !129, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!129 = distinct !{!129, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!130 = !{!131}
!131 = distinct !{!131, !132, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!132 = distinct !{!132, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!133 = !{!134}
!134 = distinct !{!134, !135, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!135 = distinct !{!135, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!136 = !{!137}
!137 = distinct !{!137, !138, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!138 = distinct !{!138, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!139 = !{!140}
!140 = distinct !{!140, !141, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!141 = distinct !{!141, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!142 = !{!143}
!143 = distinct !{!143, !144, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!144 = distinct !{!144, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!145 = !{!146}
!146 = distinct !{!146, !147, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!147 = distinct !{!147, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!148 = !{!149}
!149 = distinct !{!149, !150, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!150 = distinct !{!150, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!151 = !{!152}
!152 = distinct !{!152, !153, !"_ZN6tflite8optimize8sparsity15FormatConverterIfE7GetDataEv: argument 0"}
!153 = distinct !{!153, !"_ZN6tflite8optimize8sparsity15FormatConverterIfE7GetDataEv"}
!154 = distinct !{!154, !5}
!155 = distinct !{!155, !5}
!156 = !{!157}
!157 = distinct !{!157, !158}
!158 = distinct !{!158, !"LVerDomain"}
!159 = !{!160}
!160 = distinct !{!160, !158}
!161 = distinct !{!161, !3}
!162 = distinct !{!162, !5}
!163 = distinct !{!163, !3}
!164 = distinct !{!164, !5}
!165 = distinct !{!165, !3}
!166 = distinct !{!166, !7, !3}
!167 = distinct !{!167, !5}
!168 = distinct !{!168, !3}
!169 = distinct !{!169, !7, !3}
!170 = !{!171}
!171 = distinct !{!171, !172, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!172 = distinct !{!172, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!173 = !{!174}
!174 = distinct !{!174, !175, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!175 = distinct !{!175, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!176 = !{!177}
!177 = distinct !{!177, !178, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!178 = distinct !{!178, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!179 = !{!180}
!180 = distinct !{!180, !181, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!181 = distinct !{!181, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!182 = !{!183}
!183 = distinct !{!183, !184, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!184 = distinct !{!184, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!185 = !{!186}
!186 = distinct !{!186, !187, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!187 = distinct !{!187, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!188 = !{!189}
!189 = distinct !{!189, !190, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!190 = distinct !{!190, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!191 = !{!192}
!192 = distinct !{!192, !193, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!193 = distinct !{!193, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!194 = !{!195}
!195 = distinct !{!195, !196, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!196 = distinct !{!196, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!197 = !{!198}
!198 = distinct !{!198, !199, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!199 = distinct !{!199, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!200 = !{!201}
!201 = distinct !{!201, !202, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!202 = distinct !{!202, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!203 = !{!204}
!204 = distinct !{!204, !205, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!205 = distinct !{!205, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!206 = !{!207}
!207 = distinct !{!207, !208, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!208 = distinct !{!208, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!209 = !{!210}
!210 = distinct !{!210, !211, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!211 = distinct !{!211, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!212 = !{!213}
!213 = distinct !{!213, !214, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!214 = distinct !{!214, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!215 = !{!216}
!216 = distinct !{!216, !217, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!217 = distinct !{!217, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!218 = !{!219}
!219 = distinct !{!219, !220, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!220 = distinct !{!220, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!221 = !{!222}
!222 = distinct !{!222, !223, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!223 = distinct !{!223, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!224 = !{!225}
!225 = distinct !{!225, !226, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!226 = distinct !{!226, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!227 = !{!228}
!228 = distinct !{!228, !229, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!229 = distinct !{!229, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!230 = !{!231}
!231 = distinct !{!231, !232, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!232 = distinct !{!232, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!233 = !{!234}
!234 = distinct !{!234, !235, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!235 = distinct !{!235, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!236 = !{!237}
!237 = distinct !{!237, !238, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!238 = distinct !{!238, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!239 = !{!240}
!240 = distinct !{!240, !241, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!241 = distinct !{!241, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!242 = distinct !{!242, !5}
!243 = !{!244}
!244 = distinct !{!244, !245, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!245 = distinct !{!245, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!246 = !{!247}
!247 = distinct !{!247, !248, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!248 = distinct !{!248, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!249 = !{!250}
!250 = distinct !{!250, !251, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!251 = distinct !{!251, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!252 = !{!253}
!253 = distinct !{!253, !254, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!254 = distinct !{!254, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!255 = !{!256}
!256 = distinct !{!256, !257, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!257 = distinct !{!257, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!258 = !{!259}
!259 = distinct !{!259, !260, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!260 = distinct !{!260, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!261 = !{!262}
!262 = distinct !{!262, !263, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!263 = distinct !{!263, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!264 = !{!265}
!265 = distinct !{!265, !266, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!266 = distinct !{!266, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!267 = distinct !{!267, !3}
!268 = distinct !{!268, !5}
!269 = distinct !{!269, !7, !3}
!270 = distinct !{!270, !5}
!271 = !{!272}
!272 = distinct !{!272, !273}
!273 = distinct !{!273, !"LVerDomain"}
!274 = !{!275}
!275 = distinct !{!275, !273}
!276 = distinct !{!276, !3}
!277 = distinct !{!277, !3}
!278 = distinct !{!278, !3}
!279 = distinct !{!279, !5}
!280 = distinct !{!280, !7, !3}
!281 = distinct !{!281, !5}
!282 = !{!283}
!283 = distinct !{!283, !284}
!284 = distinct !{!284, !"LVerDomain"}
!285 = !{!286}
!286 = distinct !{!286, !284}
!287 = distinct !{!287, !3}
!288 = distinct !{!288, !3}
!289 = distinct !{!289, !3}
!290 = distinct !{!290, !5}
!291 = distinct !{!291, !7, !3}
!292 = distinct !{!292, !5}
!293 = distinct !{!293, !5}
!294 = !{!295}
!295 = distinct !{!295, !296}
!296 = distinct !{!296, !"LVerDomain"}
!297 = !{!298}
!298 = distinct !{!298, !296}
!299 = distinct !{!299, !3}
!300 = distinct !{!300, !3}
!301 = !{i32 -2143214324, i32 -2143214315, i32 -2143214307, i32 -2143214299, i32 -2143214291, i32 -2143214283, i32 -2143214275, i32 -2143214267, i32 -2143214259, i32 -2143214251, i32 -2143214243, i32 -2143214235, i32 -2143214227, i32 -2143214219, i32 -2143214211, i32 -2143214203, i32 -2143214195, i32 -2143214187, i32 -2143214179, i32 -2143214171, i32 -2143214163, i32 -2143214155, i32 -2143214147, i32 -2143214139, i32 -2143214131, i32 -2143214123, i32 -2143214115, i32 -2143214107, i32 -2143214099, i32 -2143214091, i32 -2143214083, i32 -2143214075, i32 -2143214067, i32 -2143214059, i32 -2143214051, i32 -2143214043, i32 -2143214035, i32 -2143214027, i32 -2143214019, i32 -2143214011, i32 -2143214003, i32 -2143213995, i32 -2143213987, i32 -2143213979, i32 -2143213971, i32 -2143213963, i32 -2143213955, i32 -2143213947, i32 -2143213939, i32 -2143213931, i32 -2143213923, i32 -2143213915, i32 -2143213907, i32 -2143213899, i32 -2143213891, i32 -2143213883, i32 -2143213875, i32 -2143213867, i32 -2143213859, i32 -2143213851, i32 -2143213843, i32 -2143213835, i32 -2143213827, i32 -2143213819}
!302 = !{!303}
!303 = distinct !{!303, !304, !"_ZN3ruy10ToInternalIfEENS_3MatIT_EERKNS_6MatrixIS2_EE: argument 0"}
!304 = distinct !{!304, !"_ZN3ruy10ToInternalIfEENS_3MatIT_EERKNS_6MatrixIS2_EE"}
!305 = !{!306}
!306 = distinct !{!306, !307, !"_ZN3ruy10ToInternalIfEENS_3MatIT_EERKNS_6MatrixIS2_EE: argument 0"}
!307 = distinct !{!307, !"_ZN3ruy10ToInternalIfEENS_3MatIT_EERKNS_6MatrixIS2_EE"}
!308 = !{!309}
!309 = distinct !{!309, !310, !"_ZN3ruy10ToInternalIfEENS_3MatIT_EERNS_6MatrixIS2_EE: argument 0"}
!310 = distinct !{!310, !"_ZN3ruy10ToInternalIfEENS_3MatIT_EERNS_6MatrixIS2_EE"}
!311 = !{!312}
!312 = distinct !{!312, !313, !"_ZN3ruy9EraseTypeIfEENS_4EMatERKNS_3MatIT_EE: argument 0"}
!313 = distinct !{!313, !"_ZN3ruy9EraseTypeIfEENS_4EMatERKNS_3MatIT_EE"}
!314 = !{!315}
!315 = distinct !{!315, !316, !"_ZN3ruy9EraseTypeIfEENS_4EMatERKNS_3MatIT_EE: argument 0"}
!316 = distinct !{!316, !"_ZN3ruy9EraseTypeIfEENS_4EMatERKNS_3MatIT_EE"}
!317 = !{!318}
!318 = distinct !{!318, !319, !"_ZN3ruy11UneraseTypeIfEENS_3MatIT_EERKNS_4EMatE: argument 0"}
!319 = distinct !{!319, !"_ZN3ruy11UneraseTypeIfEENS_3MatIT_EERKNS_4EMatE"}
!320 = !{!321}
!321 = distinct !{!321, !322, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!322 = distinct !{!322, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE"}
!323 = !{!324}
!324 = distinct !{!324, !325, !"_ZN3ruy11UneraseTypeIfEENS_3MatIT_EERKNS_4EMatE: argument 0"}
!325 = distinct !{!325, !"_ZN3ruy11UneraseTypeIfEENS_3MatIT_EERKNS_4EMatE"}
!326 = !{!327}
!327 = distinct !{!327, !328, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!328 = distinct !{!328, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE"}
!329 = !{!330}
!330 = distinct !{!330, !331, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!331 = distinct !{!331, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE"}
!332 = !{!333}
!333 = distinct !{!333, !334, !"_ZN3ruy11UneraseTypeIfEENS_3MatIT_EERKNS_4EMatE: argument 0"}
!334 = distinct !{!334, !"_ZN3ruy11UneraseTypeIfEENS_3MatIT_EERKNS_4EMatE"}
!335 = !{!336}
!336 = distinct !{!336, !337, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!337 = distinct !{!337, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE"}
!338 = !{!339}
!339 = distinct !{!339, !340, !"_ZN3ruy11UneraseTypeIfEENS_3MatIT_EERKNS_4EMatE: argument 0"}
!340 = distinct !{!340, !"_ZN3ruy11UneraseTypeIfEENS_3MatIT_EERKNS_4EMatE"}
!341 = !{!342}
!342 = distinct !{!342, !343, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!343 = distinct !{!343, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE"}
!344 = !{!345}
!345 = distinct !{!345, !346, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!346 = distinct !{!346, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE"}
!347 = !{!348}
!348 = distinct !{!348, !349, !"_ZN3ruy11UneraseTypeIfEENS_3MatIT_EERKNS_4EMatE: argument 0"}
!349 = distinct !{!349, !"_ZN3ruy11UneraseTypeIfEENS_3MatIT_EERKNS_4EMatE"}
!350 = !{!351}
!351 = distinct !{!351, !352, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!352 = distinct !{!352, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE"}
!353 = !{!354}
!354 = distinct !{!354, !355, !"_ZN3ruy11UneraseTypeIfEENS_3MatIT_EERKNS_4EMatE: argument 0"}
!355 = distinct !{!355, !"_ZN3ruy11UneraseTypeIfEENS_3MatIT_EERKNS_4EMatE"}
!356 = !{!357}
!357 = distinct !{!357, !358, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!358 = distinct !{!358, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE"}
!359 = !{!360}
!360 = distinct !{!360, !361, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!361 = distinct !{!361, !"_ZN3ruy11UneraseTypeIfEENS_4PMatIT_EERKNS_5PEMatE"}
!362 = distinct !{!362, !5}
!363 = distinct !{!363, !5}
!364 = distinct !{!364, !5}
!365 = !{!366}
!366 = distinct !{!366, !367, !"_ZN3ruy10ToInternalIhEENS_3MatIT_EERKNS_6MatrixIS2_EE: argument 0"}
!367 = distinct !{!367, !"_ZN3ruy10ToInternalIhEENS_3MatIT_EERKNS_6MatrixIS2_EE"}
!368 = !{!369}
!369 = distinct !{!369, !370, !"_ZN3ruy10ToInternalIhEENS_3MatIT_EERKNS_6MatrixIS2_EE: argument 0"}
!370 = distinct !{!370, !"_ZN3ruy10ToInternalIhEENS_3MatIT_EERKNS_6MatrixIS2_EE"}
!371 = !{!372}
!372 = distinct !{!372, !373, !"_ZN3ruy10ToInternalIhEENS_3MatIT_EERNS_6MatrixIS2_EE: argument 0"}
!373 = distinct !{!373, !"_ZN3ruy10ToInternalIhEENS_3MatIT_EERNS_6MatrixIS2_EE"}
!374 = !{!375}
!375 = distinct !{!375, !376, !"_ZNSt3__110make_tupleIJRN8gemmlowp23OutputStageBiasAdditionINS1_9VectorMapIKiLNS1_11VectorShapeE0EEEEERNS1_44OutputStageScaleInt32ByFixedPointAndExponentERNS1_16OutputStageClampERNS1_32OutputStageSaturatingCastToUint8EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOSH_: argument 0"}
!376 = distinct !{!376, !"_ZNSt3__110make_tupleIJRN8gemmlowp23OutputStageBiasAdditionINS1_9VectorMapIKiLNS1_11VectorShapeE0EEEEERNS1_44OutputStageScaleInt32ByFixedPointAndExponentERNS1_16OutputStageClampERNS1_32OutputStageSaturatingCastToUint8EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOSH_"}
!377 = !{!378}
!378 = distinct !{!378, !379, !"_ZNSt3__110make_tupleIJRN8gemmlowp44OutputStageScaleInt32ByFixedPointAndExponentERNS1_16OutputStageClampERNS1_32OutputStageSaturatingCastToUint8EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOSA_: argument 0"}
!379 = distinct !{!379, !"_ZNSt3__110make_tupleIJRN8gemmlowp44OutputStageScaleInt32ByFixedPointAndExponentERNS1_16OutputStageClampERNS1_32OutputStageSaturatingCastToUint8EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOSA_"}
!380 = !{!381}
!381 = distinct !{!381, !382, !"_ZN3ruy9EraseTypeIhEENS_4EMatERKNS_3MatIT_EE: argument 0"}
!382 = distinct !{!382, !"_ZN3ruy9EraseTypeIhEENS_4EMatERKNS_3MatIT_EE"}
!383 = !{!384}
!384 = distinct !{!384, !385, !"_ZN3ruy9EraseTypeIhEENS_4EMatERKNS_3MatIT_EE: argument 0"}
!385 = distinct !{!385, !"_ZN3ruy9EraseTypeIhEENS_4EMatERKNS_3MatIT_EE"}
!386 = !{!387}
!387 = distinct !{!387, !388, !"_ZN3ruy9EraseTypeIhEENS_4EMatERKNS_3MatIT_EE: argument 0"}
!388 = distinct !{!388, !"_ZN3ruy9EraseTypeIhEENS_4EMatERKNS_3MatIT_EE"}
!389 = !{!390}
!390 = distinct !{!390, !391, !"_ZN3ruy11UneraseTypeIhEENS_3MatIT_EERKNS_4EMatE: argument 0"}
!391 = distinct !{!391, !"_ZN3ruy11UneraseTypeIhEENS_3MatIT_EERKNS_4EMatE"}
!392 = !{!393}
!393 = distinct !{!393, !394, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!394 = distinct !{!394, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE"}
!395 = !{!396}
!396 = distinct !{!396, !397, !"_ZN3ruy11UneraseTypeIhEENS_3MatIT_EERKNS_4EMatE: argument 0"}
!397 = distinct !{!397, !"_ZN3ruy11UneraseTypeIhEENS_3MatIT_EERKNS_4EMatE"}
!398 = !{!399}
!399 = distinct !{!399, !400, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!400 = distinct !{!400, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE"}
!401 = !{!402}
!402 = distinct !{!402, !403, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!403 = distinct !{!403, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE"}
!404 = !{!405}
!405 = distinct !{!405, !406, !"_ZN3ruy11UneraseTypeIhEENS_3MatIT_EERKNS_4EMatE: argument 0"}
!406 = distinct !{!406, !"_ZN3ruy11UneraseTypeIhEENS_3MatIT_EERKNS_4EMatE"}
!407 = !{!408}
!408 = distinct !{!408, !409, !"_ZN3ruy11UneraseTypeIhEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!409 = distinct !{!409, !"_ZN3ruy11UneraseTypeIhEENS_4PMatIT_EERKNS_5PEMatE"}
!410 = !{!411}
!411 = distinct !{!411, !412, !"_ZN3ruy11UneraseTypeIhEENS_3MatIT_EERKNS_4EMatE: argument 0"}
!412 = distinct !{!412, !"_ZN3ruy11UneraseTypeIhEENS_3MatIT_EERKNS_4EMatE"}
!413 = !{!414}
!414 = distinct !{!414, !415, !"_ZN3ruy11UneraseTypeIhEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!415 = distinct !{!415, !"_ZN3ruy11UneraseTypeIhEENS_4PMatIT_EERKNS_5PEMatE"}
!416 = !{!417}
!417 = distinct !{!417, !418, !"_ZN3ruy11UneraseTypeIhEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!418 = distinct !{!418, !"_ZN3ruy11UneraseTypeIhEENS_4PMatIT_EERKNS_5PEMatE"}
!419 = !{!420}
!420 = distinct !{!420, !421, !"_ZN3ruy11UneraseTypeIhEENS_3MatIT_EERKNS_4EMatE: argument 0"}
!421 = distinct !{!421, !"_ZN3ruy11UneraseTypeIhEENS_3MatIT_EERKNS_4EMatE"}
!422 = !{!423}
!423 = distinct !{!423, !424, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!424 = distinct !{!424, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE"}
!425 = !{!426}
!426 = distinct !{!426, !427, !"_ZN3ruy11UneraseTypeIhEENS_3MatIT_EERKNS_4EMatE: argument 0"}
!427 = distinct !{!427, !"_ZN3ruy11UneraseTypeIhEENS_3MatIT_EERKNS_4EMatE"}
!428 = !{!429}
!429 = distinct !{!429, !430, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!430 = distinct !{!430, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE"}
!431 = !{!432}
!432 = distinct !{!432, !433, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!433 = distinct !{!433, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE"}
!434 = !{!435, !437}
!435 = distinct !{!435, !436, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIhLNS_8MapOrderE0EEEE3RunERKS3_: argument 0"}
!436 = distinct !{!436, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIhLNS_8MapOrderE0EEEE3RunERKS3_"}
!437 = distinct !{!437, !438, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIhLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS5_: argument 0"}
!438 = distinct !{!438, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIhLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS5_"}
!439 = !{!440, !442}
!440 = distinct !{!440, !441, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE0EEEE3RunERKS4_: argument 0"}
!441 = distinct !{!441, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE0EEEE3RunERKS4_"}
!442 = distinct !{!442, !443, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!443 = distinct !{!443, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!444 = !{!445, !447}
!445 = distinct !{!445, !446, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE1EEEE3RunERKS4_: argument 0"}
!446 = distinct !{!446, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE1EEEE3RunERKS4_"}
!447 = distinct !{!447, !448, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!448 = distinct !{!448, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!449 = !{!450, !452}
!450 = distinct !{!450, !451, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE1EEEE3RunERKS4_: argument 0"}
!451 = distinct !{!451, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE1EEEE3RunERKS4_"}
!452 = distinct !{!452, !453, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!453 = distinct !{!453, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!454 = !{!455, !457}
!455 = distinct !{!455, !456, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE0EEEE3RunERKS4_: argument 0"}
!456 = distinct !{!456, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE0EEEE3RunERKS4_"}
!457 = distinct !{!457, !458, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!458 = distinct !{!458, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!459 = !{!460, !462, !464, !466, !468}
!460 = distinct !{!460, !461, !"_ZN8gemmlowp13TransposeImplINS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS4_: argument 0"}
!461 = distinct !{!461, !"_ZN8gemmlowp13TransposeImplINS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS4_"}
!462 = distinct !{!462, !463, !"_ZN8gemmlowp9TransposeINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!463 = distinct !{!463, !"_ZN8gemmlowp9TransposeINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!464 = distinct !{!464, !465, !"_ZN8gemmlowp13TransposeImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEEE3RunERKS6_: argument 0"}
!465 = distinct !{!465, !"_ZN8gemmlowp13TransposeImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEEE3RunERKS6_"}
!466 = distinct !{!466, !467, !"_ZN8gemmlowp9TransposeINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEEEENS_13TransposeImplIT_E7DstTypeERKS8_: argument 0"}
!467 = distinct !{!467, !"_ZN8gemmlowp9TransposeINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEEEENS_13TransposeImplIT_E7DstTypeERKS8_"}
!468 = distinct !{!468, !469, !"_ZN8gemmlowp14TransposeTupleINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEENSt3__15tupleIJNS_13TransposeImplIT_E7DstTypeENSC_IT0_E7DstTypeENSC_IT1_E7DstTypeENSC_IT2_E7DstTypeEEEERKNSB_IJSD_SG_SJ_SM_EEE: argument 0"}
!469 = distinct !{!469, !"_ZN8gemmlowp14TransposeTupleINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEENSt3__15tupleIJNS_13TransposeImplIT_E7DstTypeENSC_IT0_E7DstTypeENSC_IT1_E7DstTypeENSC_IT2_E7DstTypeEEEERKNSB_IJSD_SG_SJ_SM_EEE"}
!470 = !{!468}
!471 = !{!472, !468}
!472 = distinct !{!472, !473, !"_ZNSt3__110make_tupleIJN8gemmlowp23OutputStageBiasAdditionINS1_9VectorMapIKiLNS1_11VectorShapeE1EEEEENS1_44OutputStageScaleInt32ByFixedPointAndExponentENS1_16OutputStageClampENS1_32OutputStageSaturatingCastToUint8EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOSD_: argument 0"}
!473 = distinct !{!473, !"_ZNSt3__110make_tupleIJN8gemmlowp23OutputStageBiasAdditionINS1_9VectorMapIKiLNS1_11VectorShapeE1EEEEENS1_44OutputStageScaleInt32ByFixedPointAndExponentENS1_16OutputStageClampENS1_32OutputStageSaturatingCastToUint8EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOSD_"}
!474 = !{!475, !477}
!475 = distinct !{!475, !476, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIhLNS_8MapOrderE1EEEE3RunERKS3_: argument 0"}
!476 = distinct !{!476, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIhLNS_8MapOrderE1EEEE3RunERKS3_"}
!477 = distinct !{!477, !478, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIhLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS5_: argument 0"}
!478 = distinct !{!478, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIhLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS5_"}
!479 = !{!480, !482}
!480 = distinct !{!480, !481, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE0EEEE3RunERKS4_: argument 0"}
!481 = distinct !{!481, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE0EEEE3RunERKS4_"}
!482 = distinct !{!482, !483, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!483 = distinct !{!483, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!484 = !{!485, !487}
!485 = distinct !{!485, !486, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE1EEEE3RunERKS4_: argument 0"}
!486 = distinct !{!486, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE1EEEE3RunERKS4_"}
!487 = distinct !{!487, !488, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!488 = distinct !{!488, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!489 = !{!490, !492}
!490 = distinct !{!490, !491, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE0EEEE3RunERKS4_: argument 0"}
!491 = distinct !{!491, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE0EEEE3RunERKS4_"}
!492 = distinct !{!492, !493, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!493 = distinct !{!493, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!494 = !{!495, !497}
!495 = distinct !{!495, !496, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE1EEEE3RunERKS4_: argument 0"}
!496 = distinct !{!496, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE1EEEE3RunERKS4_"}
!497 = distinct !{!497, !498, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!498 = distinct !{!498, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!499 = !{!500, !502, !504, !506, !508}
!500 = distinct !{!500, !501, !"_ZN8gemmlowp13TransposeImplINS_9VectorMapIKiLNS_11VectorShapeE1EEEE3RunERKS4_: argument 0"}
!501 = distinct !{!501, !"_ZN8gemmlowp13TransposeImplINS_9VectorMapIKiLNS_11VectorShapeE1EEEE3RunERKS4_"}
!502 = distinct !{!502, !503, !"_ZN8gemmlowp9TransposeINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!503 = distinct !{!503, !"_ZN8gemmlowp9TransposeINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!504 = distinct !{!504, !505, !"_ZN8gemmlowp13TransposeImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEEE3RunERKS6_: argument 0"}
!505 = distinct !{!505, !"_ZN8gemmlowp13TransposeImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEEE3RunERKS6_"}
!506 = distinct !{!506, !507, !"_ZN8gemmlowp9TransposeINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEEEENS_13TransposeImplIT_E7DstTypeERKS8_: argument 0"}
!507 = distinct !{!507, !"_ZN8gemmlowp9TransposeINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEEEENS_13TransposeImplIT_E7DstTypeERKS8_"}
!508 = distinct !{!508, !509, !"_ZN8gemmlowp14TransposeTupleINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEENSt3__15tupleIJNS_13TransposeImplIT_E7DstTypeENSC_IT0_E7DstTypeENSC_IT1_E7DstTypeENSC_IT2_E7DstTypeEEEERKNSB_IJSD_SG_SJ_SM_EEE: argument 0"}
!509 = distinct !{!509, !"_ZN8gemmlowp14TransposeTupleINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEENSt3__15tupleIJNS_13TransposeImplIT_E7DstTypeENSC_IT0_E7DstTypeENSC_IT1_E7DstTypeENSC_IT2_E7DstTypeEEEERKNSB_IJSD_SG_SJ_SM_EEE"}
!510 = !{!508}
!511 = !{!512, !508}
!512 = distinct !{!512, !513, !"_ZNSt3__110make_tupleIJN8gemmlowp23OutputStageBiasAdditionINS1_9VectorMapIKiLNS1_11VectorShapeE0EEEEENS1_44OutputStageScaleInt32ByFixedPointAndExponentENS1_16OutputStageClampENS1_32OutputStageSaturatingCastToUint8EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOSD_: argument 0"}
!513 = distinct !{!513, !"_ZNSt3__110make_tupleIJN8gemmlowp23OutputStageBiasAdditionINS1_9VectorMapIKiLNS1_11VectorShapeE0EEEEENS1_44OutputStageScaleInt32ByFixedPointAndExponentENS1_16OutputStageClampENS1_32OutputStageSaturatingCastToUint8EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOSD_"}
!514 = !{!"branch_weights", i32 1, i32 1048575}
!515 = !{!516}
!516 = distinct !{!516, !517, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!517 = distinct !{!517, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!518 = !{!519}
!519 = distinct !{!519, !520, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!520 = distinct !{!520, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!521 = !{!522}
!522 = distinct !{!522, !523, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii: argument 0"}
!523 = distinct !{!523, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii"}
!524 = !{!525}
!525 = distinct !{!525, !526, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!526 = distinct !{!526, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!527 = !{!528}
!528 = distinct !{!528, !529, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!529 = distinct !{!529, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!530 = !{!531}
!531 = distinct !{!531, !532, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!532 = distinct !{!532, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!533 = !{!534}
!534 = distinct !{!534, !535, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii: argument 0"}
!535 = distinct !{!535, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii"}
!536 = !{!537}
!537 = distinct !{!537, !538, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!538 = distinct !{!538, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!539 = !{!540}
!540 = distinct !{!540, !541, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!541 = distinct !{!541, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!542 = !{!543}
!543 = distinct !{!543, !544, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!544 = distinct !{!544, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!545 = !{!546}
!546 = distinct !{!546, !547, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!547 = distinct !{!547, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!548 = !{!549}
!549 = distinct !{!549, !550, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!550 = distinct !{!550, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!551 = !{!552}
!552 = distinct !{!552, !553, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!553 = distinct !{!553, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!554 = !{!555}
!555 = distinct !{!555, !556, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!556 = distinct !{!556, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!557 = !{!558}
!558 = distinct !{!558, !559, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii: argument 0"}
!559 = distinct !{!559, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii"}
!560 = !{!561}
!561 = distinct !{!561, !562, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii: argument 0"}
!562 = distinct !{!562, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii"}
!563 = !{!564}
!564 = distinct !{!564, !565, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii: argument 0"}
!565 = distinct !{!565, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii"}
!566 = !{!567}
!567 = distinct !{!567, !568, !"_ZNK8gemmlowp12PackedResult3MapEv: argument 0"}
!568 = distinct !{!568, !"_ZNK8gemmlowp12PackedResult3MapEv"}
!569 = distinct !{!569, !5}
!570 = !{!571}
!571 = distinct !{!571, !572, !"_ZNK8gemmlowp7SideMapIKhLNS_12SideMapOrderE0EE5blockEiiii: argument 0"}
!572 = distinct !{!572, !"_ZNK8gemmlowp7SideMapIKhLNS_12SideMapOrderE0EE5blockEiiii"}
!573 = !{!574}
!574 = distinct !{!574, !575, !"_ZNK8gemmlowp7SideMapIKhLNS_12SideMapOrderE0EE5blockEiiii: argument 0"}
!575 = distinct !{!575, !"_ZNK8gemmlowp7SideMapIKhLNS_12SideMapOrderE0EE5blockEiiii"}
!576 = !{!577}
!577 = distinct !{!577, !578, !"_ZNK8gemmlowp7SideMapIKhLNS_12SideMapOrderE0EE5blockEiiii: argument 0"}
!578 = distinct !{!578, !"_ZNK8gemmlowp7SideMapIKhLNS_12SideMapOrderE0EE5blockEiiii"}
!579 = !{!580}
!580 = distinct !{!580, !581, !"_ZNK8gemmlowp7SideMapIKhLNS_12SideMapOrderE0EE5blockEiiii: argument 0"}
!581 = distinct !{!581, !"_ZNK8gemmlowp7SideMapIKhLNS_12SideMapOrderE0EE5blockEiiii"}
!582 = !{!583}
!583 = distinct !{!583, !584, !"_ZN8gemmlowp12PackedResult3MapEv: argument 0"}
!584 = distinct !{!584, !"_ZN8gemmlowp12PackedResult3MapEv"}
!585 = !{!586}
!586 = distinct !{!586, !587, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!587 = distinct !{!587, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!588 = !{!589, !591}
!589 = distinct !{!589, !590, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i: argument 0"}
!590 = distinct !{!590, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i"}
!591 = distinct !{!591, !592, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i: argument 0"}
!592 = distinct !{!592, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i"}
!593 = !{!594, !596}
!594 = distinct !{!594, !595, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!595 = distinct !{!595, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!596 = distinct !{!596, !597, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii: argument 0"}
!597 = distinct !{!597, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii"}
!598 = !{!599}
!599 = distinct !{!599, !600, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!600 = distinct !{!600, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!601 = !{!602, !604}
!602 = distinct !{!602, !603, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i: argument 0"}
!603 = distinct !{!603, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i"}
!604 = distinct !{!604, !605, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i: argument 0"}
!605 = distinct !{!605, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i"}
!606 = !{!607, !609}
!607 = distinct !{!607, !608, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!608 = distinct !{!608, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!609 = distinct !{!609, !610, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii: argument 0"}
!610 = distinct !{!610, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii"}
!611 = !{!612, !614}
!612 = distinct !{!612, !613, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i: argument 0"}
!613 = distinct !{!613, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i"}
!614 = distinct !{!614, !615, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i: argument 0"}
!615 = distinct !{!615, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i"}
!616 = !{!617}
!617 = distinct !{!617, !618, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_13RegisterBlockIiLi8ELi1EEEE4EvalES8_ii: argument 0"}
!618 = distinct !{!618, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_13RegisterBlockIiLi8ELi1EEEE4EvalES8_ii"}
!619 = !{!620, !622}
!620 = distinct !{!620, !621, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_13RegisterBlockIiLi8ELi4EEEE4EvalES8_ii: argument 0"}
!621 = distinct !{!621, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_13RegisterBlockIiLi8ELi4EEEE4EvalES8_ii"}
!622 = distinct !{!622, !623, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi0ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii: argument 0"}
!623 = distinct !{!623, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi0ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii"}
!624 = !{!622}
!625 = !{!626}
!626 = distinct !{!626, !627, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii: argument 0"}
!627 = distinct !{!627, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii"}
!628 = !{!629}
!629 = distinct !{!629, !630, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi32EEEE4EvalES3_: argument 0"}
!630 = distinct !{!630, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi32EEEE4EvalES3_"}
!631 = !{!629, !626}
!632 = !{!633}
!633 = distinct !{!633, !634, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi2ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii: argument 0"}
!634 = distinct !{!634, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi2ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii"}
!635 = !{!636}
!636 = distinct !{!636, !637, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii: argument 0"}
!637 = distinct !{!637, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii"}
!638 = !{!636, !633}
!639 = !{!640, !636, !633}
!640 = distinct !{!640, !641, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi32EEEE4EvalES3_: argument 0"}
!641 = distinct !{!641, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi32EEEE4EvalES3_"}
!642 = !{!640}
!643 = !{!644}
!644 = distinct !{!644, !645, !"_ZNK8gemmlowp19OutputStageEvalImplINS_32OutputStageSaturatingCastToUint8ENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii: argument 0"}
!645 = distinct !{!645, !"_ZNK8gemmlowp19OutputStageEvalImplINS_32OutputStageSaturatingCastToUint8ENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii"}
!646 = !{!647}
!647 = distinct !{!647, !648, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_32OutputStageSaturatingCastToUint8ENS_14RegisterBufferIiLi32EEEE4EvalES3_: argument 0"}
!648 = distinct !{!648, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_32OutputStageSaturatingCastToUint8ENS_14RegisterBufferIiLi32EEEE4EvalES3_"}
!649 = !{!647, !644}
!650 = !{!651}
!651 = distinct !{!651, !652, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_13RegisterBlockIiLi4ELi4EEEE4EvalES8_ii: argument 0"}
!652 = distinct !{!652, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_13RegisterBlockIiLi4ELi4EEEE4EvalES8_ii"}
!653 = !{!654}
!654 = distinct !{!654, !655, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii: argument 0"}
!655 = distinct !{!655, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii"}
!656 = !{!657}
!657 = distinct !{!657, !658, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi16EEEE4EvalES3_: argument 0"}
!658 = distinct !{!658, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi16EEEE4EvalES3_"}
!659 = !{!657, !654}
!660 = !{!661, !663}
!661 = distinct !{!661, !662, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi16EEEE4EvalES3_: argument 0"}
!662 = distinct !{!662, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi16EEEE4EvalES3_"}
!663 = distinct !{!663, !664, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii: argument 0"}
!664 = distinct !{!664, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii"}
!665 = !{!666, !668}
!666 = distinct !{!666, !667, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_13RegisterBlockIiLi8ELi4EEEE4EvalES8_ii: argument 0"}
!667 = distinct !{!667, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_13RegisterBlockIiLi8ELi4EEEE4EvalES8_ii"}
!668 = distinct !{!668, !669, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi0ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii: argument 0"}
!669 = distinct !{!669, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi0ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii"}
!670 = !{!668}
!671 = !{!672}
!672 = distinct !{!672, !673, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii: argument 0"}
!673 = distinct !{!673, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii"}
!674 = !{!675}
!675 = distinct !{!675, !676, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi8EEEE4EvalES3_: argument 0"}
!676 = distinct !{!676, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi8EEEE4EvalES3_"}
!677 = !{!675, !672}
!678 = !{!679, !681}
!679 = distinct !{!679, !680, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi8EEEE4EvalES3_: argument 0"}
!680 = distinct !{!680, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi8EEEE4EvalES3_"}
!681 = distinct !{!681, !682, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii: argument 0"}
!682 = distinct !{!682, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii"}
!683 = !{!684}
!684 = distinct !{!684, !685, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!685 = distinct !{!685, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!686 = !{!687}
!687 = distinct !{!687, !688, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!688 = distinct !{!688, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!689 = !{!690}
!690 = distinct !{!690, !691, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!691 = distinct !{!691, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!692 = !{!693}
!693 = distinct !{!693, !694, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!694 = distinct !{!694, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!695 = !{!696}
!696 = distinct !{!696, !697, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii: argument 0"}
!697 = distinct !{!697, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii"}
!698 = !{!699}
!699 = distinct !{!699, !700, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii: argument 0"}
!700 = distinct !{!700, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii"}
!701 = !{!702}
!702 = distinct !{!702, !703, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!703 = distinct !{!703, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!704 = !{!705}
!705 = distinct !{!705, !706, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!706 = distinct !{!706, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!707 = !{!708}
!708 = distinct !{!708, !709, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!709 = distinct !{!709, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!710 = !{!711}
!711 = distinct !{!711, !712, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!712 = distinct !{!712, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!713 = !{!714}
!714 = distinct !{!714, !715, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!715 = distinct !{!715, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!716 = !{!717}
!717 = distinct !{!717, !718, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!718 = distinct !{!718, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!719 = !{!720}
!720 = distinct !{!720, !721, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii: argument 0"}
!721 = distinct !{!721, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii"}
!722 = !{!723}
!723 = distinct !{!723, !724, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii: argument 0"}
!724 = distinct !{!724, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii"}
!725 = !{!726}
!726 = distinct !{!726, !727, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii: argument 0"}
!727 = distinct !{!727, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii"}
!728 = !{!729}
!729 = distinct !{!729, !730, !"_ZNK8gemmlowp12PackedResult3MapEv: argument 0"}
!730 = distinct !{!730, !"_ZNK8gemmlowp12PackedResult3MapEv"}
!731 = !{!732}
!732 = distinct !{!732, !733, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!733 = distinct !{!733, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!734 = !{!735, !737}
!735 = distinct !{!735, !736, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i: argument 0"}
!736 = distinct !{!736, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i"}
!737 = distinct !{!737, !738, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i: argument 0"}
!738 = distinct !{!738, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i"}
!739 = !{!740, !742}
!740 = distinct !{!740, !741, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!741 = distinct !{!741, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!742 = distinct !{!742, !743, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii: argument 0"}
!743 = distinct !{!743, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii"}
!744 = !{!745, !747}
!745 = distinct !{!745, !746, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!746 = distinct !{!746, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!747 = distinct !{!747, !748, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii: argument 0"}
!748 = distinct !{!748, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii"}
!749 = !{!750, !752}
!750 = distinct !{!750, !751, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i: argument 0"}
!751 = distinct !{!751, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i"}
!752 = distinct !{!752, !753, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i: argument 0"}
!753 = distinct !{!753, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i"}
!754 = !{!755}
!755 = distinct !{!755, !756, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_13RegisterBlockIiLi8ELi1EEEE4EvalES8_ii: argument 0"}
!756 = distinct !{!756, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_13RegisterBlockIiLi8ELi1EEEE4EvalES8_ii"}
!757 = !{!758, !760, !755}
!758 = distinct !{!758, !759, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i: argument 0"}
!759 = distinct !{!759, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i"}
!760 = distinct !{!760, !761, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i: argument 0"}
!761 = distinct !{!761, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i"}
!762 = !{!763, !765}
!763 = distinct !{!763, !764, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_13RegisterBlockIiLi8ELi4EEEE4EvalES8_ii: argument 0"}
!764 = distinct !{!764, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_13RegisterBlockIiLi8ELi4EEEE4EvalES8_ii"}
!765 = distinct !{!765, !766, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi0ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii: argument 0"}
!766 = distinct !{!766, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi0ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii"}
!767 = !{!768, !770, !763, !765}
!768 = distinct !{!768, !769, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i: argument 0"}
!769 = distinct !{!769, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i"}
!770 = distinct !{!770, !771, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i: argument 0"}
!771 = distinct !{!771, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i"}
!772 = !{!765}
!773 = !{!774}
!774 = distinct !{!774, !775, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii: argument 0"}
!775 = distinct !{!775, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii"}
!776 = !{!777}
!777 = distinct !{!777, !778, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi32EEEE4EvalES3_: argument 0"}
!778 = distinct !{!778, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi32EEEE4EvalES3_"}
!779 = !{!777, !774}
!780 = !{!781}
!781 = distinct !{!781, !782, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi2ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii: argument 0"}
!782 = distinct !{!782, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi2ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii"}
!783 = !{!784}
!784 = distinct !{!784, !785, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii: argument 0"}
!785 = distinct !{!785, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii"}
!786 = !{!784, !781}
!787 = !{!788, !784, !781}
!788 = distinct !{!788, !789, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi32EEEE4EvalES3_: argument 0"}
!789 = distinct !{!789, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi32EEEE4EvalES3_"}
!790 = !{!788}
!791 = !{!792}
!792 = distinct !{!792, !793, !"_ZNK8gemmlowp19OutputStageEvalImplINS_32OutputStageSaturatingCastToUint8ENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii: argument 0"}
!793 = distinct !{!793, !"_ZNK8gemmlowp19OutputStageEvalImplINS_32OutputStageSaturatingCastToUint8ENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii"}
!794 = !{!795}
!795 = distinct !{!795, !796, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_32OutputStageSaturatingCastToUint8ENS_14RegisterBufferIiLi32EEEE4EvalES3_: argument 0"}
!796 = distinct !{!796, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_32OutputStageSaturatingCastToUint8ENS_14RegisterBufferIiLi32EEEE4EvalES3_"}
!797 = !{!795, !792}
!798 = !{!799}
!799 = distinct !{!799, !800, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_13RegisterBlockIiLi4ELi4EEEE4EvalES8_ii: argument 0"}
!800 = distinct !{!800, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_13RegisterBlockIiLi4ELi4EEEE4EvalES8_ii"}
!801 = !{!802}
!802 = distinct !{!802, !803, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii: argument 0"}
!803 = distinct !{!803, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii"}
!804 = !{!805}
!805 = distinct !{!805, !806, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi16EEEE4EvalES3_: argument 0"}
!806 = distinct !{!806, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi16EEEE4EvalES3_"}
!807 = !{!805, !802}
!808 = !{!809, !811}
!809 = distinct !{!809, !810, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi16EEEE4EvalES3_: argument 0"}
!810 = distinct !{!810, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi16EEEE4EvalES3_"}
!811 = distinct !{!811, !812, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii: argument 0"}
!812 = distinct !{!812, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii"}
!813 = !{!814}
!814 = distinct !{!814, !815, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii: argument 0"}
!815 = distinct !{!815, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii"}
!816 = !{!817}
!817 = distinct !{!817, !818, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi8EEEE4EvalES3_: argument 0"}
!818 = distinct !{!818, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi8EEEE4EvalES3_"}
!819 = !{!817, !814}
!820 = !{!821, !823}
!821 = distinct !{!821, !822, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi8EEEE4EvalES3_: argument 0"}
!822 = distinct !{!822, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi8EEEE4EvalES3_"}
!823 = distinct !{!823, !824, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii: argument 0"}
!824 = distinct !{!824, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii"}
!825 = !{!826}
!826 = distinct !{!826, !827, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!827 = distinct !{!827, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!828 = !{!829}
!829 = distinct !{!829, !830, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!830 = distinct !{!830, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!831 = !{!832}
!832 = distinct !{!832, !833, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!833 = distinct !{!833, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!834 = !{!835}
!835 = distinct !{!835, !836, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!836 = distinct !{!836, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!837 = !{!838}
!838 = distinct !{!838, !839, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii: argument 0"}
!839 = distinct !{!839, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii"}
!840 = !{!841}
!841 = distinct !{!841, !842, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii: argument 0"}
!842 = distinct !{!842, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii"}
!843 = distinct !{!843, !3}
!844 = !{!845, !847}
!845 = distinct !{!845, !846, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIhLNS_8MapOrderE0EEEE3RunERKS3_: argument 0"}
!846 = distinct !{!846, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIhLNS_8MapOrderE0EEEE3RunERKS3_"}
!847 = distinct !{!847, !848, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIhLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS5_: argument 0"}
!848 = distinct !{!848, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIhLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS5_"}
!849 = !{!850, !852}
!850 = distinct !{!850, !851, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE0EEEE3RunERKS4_: argument 0"}
!851 = distinct !{!851, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE0EEEE3RunERKS4_"}
!852 = distinct !{!852, !853, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!853 = distinct !{!853, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!854 = !{!855, !857}
!855 = distinct !{!855, !856, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE1EEEE3RunERKS4_: argument 0"}
!856 = distinct !{!856, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE1EEEE3RunERKS4_"}
!857 = distinct !{!857, !858, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!858 = distinct !{!858, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!859 = !{!860, !862}
!860 = distinct !{!860, !861, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE1EEEE3RunERKS4_: argument 0"}
!861 = distinct !{!861, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE1EEEE3RunERKS4_"}
!862 = distinct !{!862, !863, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!863 = distinct !{!863, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!864 = !{!865, !867}
!865 = distinct !{!865, !866, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE0EEEE3RunERKS4_: argument 0"}
!866 = distinct !{!866, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE0EEEE3RunERKS4_"}
!867 = distinct !{!867, !868, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!868 = distinct !{!868, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!869 = !{!870}
!870 = distinct !{!870, !871, !"_ZN8gemmlowp14TransposeTupleINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEENSt3__15tupleIJNS_13TransposeImplIT_E7DstTypeENS6_IT0_E7DstTypeENS6_IT1_E7DstTypeEEEERKNS5_IJS7_SA_SD_EEE: argument 0"}
!871 = distinct !{!871, !"_ZN8gemmlowp14TransposeTupleINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEENSt3__15tupleIJNS_13TransposeImplIT_E7DstTypeENS6_IT0_E7DstTypeENS6_IT1_E7DstTypeEEEERKNS5_IJS7_SA_SD_EEE"}
!872 = !{!873, !870}
!873 = distinct !{!873, !874, !"_ZNSt3__110make_tupleIJN8gemmlowp44OutputStageScaleInt32ByFixedPointAndExponentENS1_16OutputStageClampENS1_32OutputStageSaturatingCastToUint8EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOS7_: argument 0"}
!874 = distinct !{!874, !"_ZNSt3__110make_tupleIJN8gemmlowp44OutputStageScaleInt32ByFixedPointAndExponentENS1_16OutputStageClampENS1_32OutputStageSaturatingCastToUint8EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOS7_"}
!875 = !{!876, !878}
!876 = distinct !{!876, !877, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIhLNS_8MapOrderE1EEEE3RunERKS3_: argument 0"}
!877 = distinct !{!877, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIhLNS_8MapOrderE1EEEE3RunERKS3_"}
!878 = distinct !{!878, !879, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIhLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS5_: argument 0"}
!879 = distinct !{!879, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIhLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS5_"}
!880 = !{!881, !883}
!881 = distinct !{!881, !882, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE0EEEE3RunERKS4_: argument 0"}
!882 = distinct !{!882, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE0EEEE3RunERKS4_"}
!883 = distinct !{!883, !884, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!884 = distinct !{!884, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!885 = !{!886, !888}
!886 = distinct !{!886, !887, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE1EEEE3RunERKS4_: argument 0"}
!887 = distinct !{!887, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE1EEEE3RunERKS4_"}
!888 = distinct !{!888, !889, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!889 = distinct !{!889, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!890 = !{!891, !893}
!891 = distinct !{!891, !892, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE0EEEE3RunERKS4_: argument 0"}
!892 = distinct !{!892, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE0EEEE3RunERKS4_"}
!893 = distinct !{!893, !894, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!894 = distinct !{!894, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!895 = !{!896, !898}
!896 = distinct !{!896, !897, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE1EEEE3RunERKS4_: argument 0"}
!897 = distinct !{!897, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE1EEEE3RunERKS4_"}
!898 = distinct !{!898, !899, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!899 = distinct !{!899, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!900 = !{!901}
!901 = distinct !{!901, !902, !"_ZN8gemmlowp14TransposeTupleINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEENSt3__15tupleIJNS_13TransposeImplIT_E7DstTypeENS6_IT0_E7DstTypeENS6_IT1_E7DstTypeEEEERKNS5_IJS7_SA_SD_EEE: argument 0"}
!902 = distinct !{!902, !"_ZN8gemmlowp14TransposeTupleINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEENSt3__15tupleIJNS_13TransposeImplIT_E7DstTypeENS6_IT0_E7DstTypeENS6_IT1_E7DstTypeEEEERKNS5_IJS7_SA_SD_EEE"}
!903 = !{!904, !901}
!904 = distinct !{!904, !905, !"_ZNSt3__110make_tupleIJN8gemmlowp44OutputStageScaleInt32ByFixedPointAndExponentENS1_16OutputStageClampENS1_32OutputStageSaturatingCastToUint8EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOS7_: argument 0"}
!905 = distinct !{!905, !"_ZNSt3__110make_tupleIJN8gemmlowp44OutputStageScaleInt32ByFixedPointAndExponentENS1_16OutputStageClampENS1_32OutputStageSaturatingCastToUint8EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOS7_"}
!906 = !{!907}
!907 = distinct !{!907, !908, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!908 = distinct !{!908, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!909 = !{!910}
!910 = distinct !{!910, !911, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!911 = distinct !{!911, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!912 = !{!913}
!913 = distinct !{!913, !914, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii: argument 0"}
!914 = distinct !{!914, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii"}
!915 = !{!916}
!916 = distinct !{!916, !917, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!917 = distinct !{!917, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!918 = !{!919}
!919 = distinct !{!919, !920, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!920 = distinct !{!920, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!921 = !{!922}
!922 = distinct !{!922, !923, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!923 = distinct !{!923, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!924 = !{!925}
!925 = distinct !{!925, !926, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii: argument 0"}
!926 = distinct !{!926, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii"}
!927 = !{!928}
!928 = distinct !{!928, !929, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!929 = distinct !{!929, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!930 = !{!931}
!931 = distinct !{!931, !932, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!932 = distinct !{!932, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!933 = !{!934}
!934 = distinct !{!934, !935, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!935 = distinct !{!935, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!936 = !{!937}
!937 = distinct !{!937, !938, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!938 = distinct !{!938, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!939 = !{!940}
!940 = distinct !{!940, !941, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!941 = distinct !{!941, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!942 = !{!943}
!943 = distinct !{!943, !944, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!944 = distinct !{!944, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!945 = !{!946}
!946 = distinct !{!946, !947, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!947 = distinct !{!947, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!948 = !{!949}
!949 = distinct !{!949, !950, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii: argument 0"}
!950 = distinct !{!950, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii"}
!951 = !{!952}
!952 = distinct !{!952, !953, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii: argument 0"}
!953 = distinct !{!953, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii"}
!954 = !{!955}
!955 = distinct !{!955, !956, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii: argument 0"}
!956 = distinct !{!956, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii"}
!957 = !{!958}
!958 = distinct !{!958, !959, !"_ZNK8gemmlowp12PackedResult3MapEv: argument 0"}
!959 = distinct !{!959, !"_ZNK8gemmlowp12PackedResult3MapEv"}
!960 = !{!961}
!961 = distinct !{!961, !962, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!962 = distinct !{!962, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!963 = !{!964, !966}
!964 = distinct !{!964, !965, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i: argument 0"}
!965 = distinct !{!965, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i"}
!966 = distinct !{!966, !967, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i: argument 0"}
!967 = distinct !{!967, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i"}
!968 = !{!969, !971}
!969 = distinct !{!969, !970, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!970 = distinct !{!970, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!971 = distinct !{!971, !972, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii: argument 0"}
!972 = distinct !{!972, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii"}
!973 = !{!974}
!974 = distinct !{!974, !975, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii: argument 0"}
!975 = distinct !{!975, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii"}
!976 = !{!977}
!977 = distinct !{!977, !978, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi16EEEE4EvalES3_: argument 0"}
!978 = distinct !{!978, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi16EEEE4EvalES3_"}
!979 = !{!977, !974}
!980 = !{!981}
!981 = distinct !{!981, !982, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!982 = distinct !{!982, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!983 = !{!984, !986}
!984 = distinct !{!984, !985, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i: argument 0"}
!985 = distinct !{!985, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i"}
!986 = distinct !{!986, !987, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i: argument 0"}
!987 = distinct !{!987, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i"}
!988 = !{!989, !991}
!989 = distinct !{!989, !990, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!990 = distinct !{!990, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!991 = distinct !{!991, !992, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii: argument 0"}
!992 = distinct !{!992, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii"}
!993 = !{!994, !996}
!994 = distinct !{!994, !995, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i: argument 0"}
!995 = distinct !{!995, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i"}
!996 = distinct !{!996, !997, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i: argument 0"}
!997 = distinct !{!997, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i"}
!998 = !{!999}
!999 = distinct !{!999, !1000, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii: argument 0"}
!1000 = distinct !{!1000, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii"}
!1001 = !{!1002}
!1002 = distinct !{!1002, !1003, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi32EEEE4EvalES3_: argument 0"}
!1003 = distinct !{!1003, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi32EEEE4EvalES3_"}
!1004 = !{!1002, !999}
!1005 = !{!1006}
!1006 = distinct !{!1006, !1007, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi1ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalES8_ii: argument 0"}
!1007 = distinct !{!1007, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToUint8EEEELi1ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalES8_ii"}
!1008 = !{!1009}
!1009 = distinct !{!1009, !1010, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii: argument 0"}
!1010 = distinct !{!1010, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii"}
!1011 = !{!1009, !1006}
!1012 = !{!1013, !1009, !1006}
!1013 = distinct !{!1013, !1014, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi32EEEE4EvalES3_: argument 0"}
!1014 = distinct !{!1014, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi32EEEE4EvalES3_"}
!1015 = !{!1013}
!1016 = !{!1017}
!1017 = distinct !{!1017, !1018, !"_ZNK8gemmlowp19OutputStageEvalImplINS_32OutputStageSaturatingCastToUint8ENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii: argument 0"}
!1018 = distinct !{!1018, !"_ZNK8gemmlowp19OutputStageEvalImplINS_32OutputStageSaturatingCastToUint8ENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii"}
!1019 = !{!1020}
!1020 = distinct !{!1020, !1021, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_32OutputStageSaturatingCastToUint8ENS_14RegisterBufferIiLi32EEEE4EvalES3_: argument 0"}
!1021 = distinct !{!1021, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_32OutputStageSaturatingCastToUint8ENS_14RegisterBufferIiLi32EEEE4EvalES3_"}
!1022 = !{!1020, !1017}
!1023 = !{!1024, !1026}
!1024 = distinct !{!1024, !1025, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi16EEEE4EvalES3_: argument 0"}
!1025 = distinct !{!1025, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi16EEEE4EvalES3_"}
!1026 = distinct !{!1026, !1027, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii: argument 0"}
!1027 = distinct !{!1027, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii"}
!1028 = !{!1029}
!1029 = distinct !{!1029, !1030, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii: argument 0"}
!1030 = distinct !{!1030, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii"}
!1031 = !{!1032}
!1032 = distinct !{!1032, !1033, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi8EEEE4EvalES3_: argument 0"}
!1033 = distinct !{!1033, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi8EEEE4EvalES3_"}
!1034 = !{!1032, !1029}
!1035 = !{!1036, !1038}
!1036 = distinct !{!1036, !1037, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi8EEEE4EvalES3_: argument 0"}
!1037 = distinct !{!1037, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi8EEEE4EvalES3_"}
!1038 = distinct !{!1038, !1039, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii: argument 0"}
!1039 = distinct !{!1039, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii"}
!1040 = !{!1041}
!1041 = distinct !{!1041, !1042, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!1042 = distinct !{!1042, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!1043 = !{!1044}
!1044 = distinct !{!1044, !1045, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!1045 = distinct !{!1045, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!1046 = !{!1047}
!1047 = distinct !{!1047, !1048, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!1048 = distinct !{!1048, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!1049 = !{!1050}
!1050 = distinct !{!1050, !1051, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!1051 = distinct !{!1051, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!1052 = !{!1053}
!1053 = distinct !{!1053, !1054, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii: argument 0"}
!1054 = distinct !{!1054, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii"}
!1055 = !{!1056}
!1056 = distinct !{!1056, !1057, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii: argument 0"}
!1057 = distinct !{!1057, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii"}
!1058 = !{!1059}
!1059 = distinct !{!1059, !1060, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!1060 = distinct !{!1060, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!1061 = !{!1062}
!1062 = distinct !{!1062, !1063, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!1063 = distinct !{!1063, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!1064 = !{!1065}
!1065 = distinct !{!1065, !1066, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!1066 = distinct !{!1066, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!1067 = !{!1068}
!1068 = distinct !{!1068, !1069, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!1069 = distinct !{!1069, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!1070 = !{!1071}
!1071 = distinct !{!1071, !1072, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!1072 = distinct !{!1072, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!1073 = !{!1074}
!1074 = distinct !{!1074, !1075, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!1075 = distinct !{!1075, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!1076 = !{!1077}
!1077 = distinct !{!1077, !1078, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii: argument 0"}
!1078 = distinct !{!1078, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii"}
!1079 = !{!1080}
!1080 = distinct !{!1080, !1081, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii: argument 0"}
!1081 = distinct !{!1081, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii"}
!1082 = !{!1083}
!1083 = distinct !{!1083, !1084, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii: argument 0"}
!1084 = distinct !{!1084, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii"}
!1085 = !{!1086}
!1086 = distinct !{!1086, !1087, !"_ZNK8gemmlowp12PackedResult3MapEv: argument 0"}
!1087 = distinct !{!1087, !"_ZNK8gemmlowp12PackedResult3MapEv"}
!1088 = !{!1089}
!1089 = distinct !{!1089, !1090, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!1090 = distinct !{!1090, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!1091 = !{!1092, !1094}
!1092 = distinct !{!1092, !1093, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i: argument 0"}
!1093 = distinct !{!1093, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i"}
!1094 = distinct !{!1094, !1095, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i: argument 0"}
!1095 = distinct !{!1095, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i"}
!1096 = !{!1097, !1099}
!1097 = distinct !{!1097, !1098, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!1098 = distinct !{!1098, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!1099 = distinct !{!1099, !1100, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii: argument 0"}
!1100 = distinct !{!1100, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii"}
!1101 = !{!1102}
!1102 = distinct !{!1102, !1103, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii: argument 0"}
!1103 = distinct !{!1103, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii"}
!1104 = !{!1105}
!1105 = distinct !{!1105, !1106, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi16EEEE4EvalES3_: argument 0"}
!1106 = distinct !{!1106, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi16EEEE4EvalES3_"}
!1107 = !{!1105, !1102}
!1108 = !{!1109, !1111}
!1109 = distinct !{!1109, !1110, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!1110 = distinct !{!1110, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!1111 = distinct !{!1111, !1112, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii: argument 0"}
!1112 = distinct !{!1112, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii"}
!1113 = !{!1114, !1116}
!1114 = distinct !{!1114, !1115, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i: argument 0"}
!1115 = distinct !{!1115, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i"}
!1116 = distinct !{!1116, !1117, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i: argument 0"}
!1117 = distinct !{!1117, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i"}
!1118 = !{!1119}
!1119 = distinct !{!1119, !1120, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!1120 = distinct !{!1120, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!1121 = !{!1122}
!1122 = distinct !{!1122, !1123, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!1123 = distinct !{!1123, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!1124 = !{!1125}
!1125 = distinct !{!1125, !1126, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!1126 = distinct !{!1126, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!1127 = !{!1128}
!1128 = distinct !{!1128, !1129, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!1129 = distinct !{!1129, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!1130 = !{!1131}
!1131 = distinct !{!1131, !1132, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii: argument 0"}
!1132 = distinct !{!1132, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii"}
!1133 = !{!1134}
!1134 = distinct !{!1134, !1135, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii: argument 0"}
!1135 = distinct !{!1135, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii"}
!1136 = !{!1137}
!1137 = distinct !{!1137, !1138, !"_ZN3ruy10ToInternalIaEENS_3MatIT_EERKNS_6MatrixIS2_EE: argument 0"}
!1138 = distinct !{!1138, !"_ZN3ruy10ToInternalIaEENS_3MatIT_EERKNS_6MatrixIS2_EE"}
!1139 = !{!1140}
!1140 = distinct !{!1140, !1141, !"_ZN3ruy10ToInternalIaEENS_3MatIT_EERKNS_6MatrixIS2_EE: argument 0"}
!1141 = distinct !{!1141, !"_ZN3ruy10ToInternalIaEENS_3MatIT_EERKNS_6MatrixIS2_EE"}
!1142 = !{!1143}
!1143 = distinct !{!1143, !1144, !"_ZN3ruy10ToInternalIaEENS_3MatIT_EERNS_6MatrixIS2_EE: argument 0"}
!1144 = distinct !{!1144, !"_ZN3ruy10ToInternalIaEENS_3MatIT_EERNS_6MatrixIS2_EE"}
!1145 = !{!1146}
!1146 = distinct !{!1146, !1147, !"_ZN3ruy9EraseTypeIaEENS_4EMatERKNS_3MatIT_EE: argument 0"}
!1147 = distinct !{!1147, !"_ZN3ruy9EraseTypeIaEENS_4EMatERKNS_3MatIT_EE"}
!1148 = !{!1149}
!1149 = distinct !{!1149, !1150, !"_ZN3ruy9EraseTypeIaEENS_4EMatERKNS_3MatIT_EE: argument 0"}
!1150 = distinct !{!1150, !"_ZN3ruy9EraseTypeIaEENS_4EMatERKNS_3MatIT_EE"}
!1151 = !{!1152}
!1152 = distinct !{!1152, !1153, !"_ZN3ruy11UneraseTypeIaEENS_3MatIT_EERKNS_4EMatE: argument 0"}
!1153 = distinct !{!1153, !"_ZN3ruy11UneraseTypeIaEENS_3MatIT_EERKNS_4EMatE"}
!1154 = !{!1155}
!1155 = distinct !{!1155, !1156, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!1156 = distinct !{!1156, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE"}
!1157 = !{!1158}
!1158 = distinct !{!1158, !1159, !"_ZN3ruy11UneraseTypeIaEENS_3MatIT_EERKNS_4EMatE: argument 0"}
!1159 = distinct !{!1159, !"_ZN3ruy11UneraseTypeIaEENS_3MatIT_EERKNS_4EMatE"}
!1160 = !{!1161}
!1161 = distinct !{!1161, !1162, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!1162 = distinct !{!1162, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE"}
!1163 = !{!1164}
!1164 = distinct !{!1164, !1165, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!1165 = distinct !{!1165, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE"}
!1166 = !{!1167}
!1167 = distinct !{!1167, !1168, !"_ZN3ruy11UneraseTypeIaEENS_3MatIT_EERKNS_4EMatE: argument 0"}
!1168 = distinct !{!1168, !"_ZN3ruy11UneraseTypeIaEENS_3MatIT_EERKNS_4EMatE"}
!1169 = !{!1170}
!1170 = distinct !{!1170, !1171, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!1171 = distinct !{!1171, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE"}
!1172 = !{!1173}
!1173 = distinct !{!1173, !1174, !"_ZN3ruy11UneraseTypeIaEENS_3MatIT_EERKNS_4EMatE: argument 0"}
!1174 = distinct !{!1174, !"_ZN3ruy11UneraseTypeIaEENS_3MatIT_EERKNS_4EMatE"}
!1175 = !{!1176}
!1176 = distinct !{!1176, !1177, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!1177 = distinct !{!1177, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE"}
!1178 = !{!1179}
!1179 = distinct !{!1179, !1180, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!1180 = distinct !{!1180, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE"}
!1181 = !{!1182}
!1182 = distinct !{!1182, !1183, !"_ZN3ruy11UneraseTypeIaEENS_3MatIT_EERKNS_4EMatE: argument 0"}
!1183 = distinct !{!1183, !"_ZN3ruy11UneraseTypeIaEENS_3MatIT_EERKNS_4EMatE"}
!1184 = !{!1185}
!1185 = distinct !{!1185, !1186, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!1186 = distinct !{!1186, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE"}
!1187 = !{!1188}
!1188 = distinct !{!1188, !1189, !"_ZN3ruy11UneraseTypeIaEENS_3MatIT_EERKNS_4EMatE: argument 0"}
!1189 = distinct !{!1189, !"_ZN3ruy11UneraseTypeIaEENS_3MatIT_EERKNS_4EMatE"}
!1190 = !{!1191}
!1191 = distinct !{!1191, !1192, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!1192 = distinct !{!1192, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE"}
!1193 = !{!1194}
!1194 = distinct !{!1194, !1195, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!1195 = distinct !{!1195, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE"}
!1196 = !{!1197}
!1197 = distinct !{!1197, !1198, !"_ZN3ruy10ToInternalIhEENS_3MatIT_EERKNS_6MatrixIS2_EE: argument 0"}
!1198 = distinct !{!1198, !"_ZN3ruy10ToInternalIhEENS_3MatIT_EERKNS_6MatrixIS2_EE"}
!1199 = !{!1200}
!1200 = distinct !{!1200, !1201, !"_ZN3ruy10ToInternalIhEENS_3MatIT_EERKNS_6MatrixIS2_EE: argument 0"}
!1201 = distinct !{!1201, !"_ZN3ruy10ToInternalIhEENS_3MatIT_EERKNS_6MatrixIS2_EE"}
!1202 = !{!1203}
!1203 = distinct !{!1203, !1204, !"_ZN3ruy10ToInternalIsEENS_3MatIT_EERNS_6MatrixIS2_EE: argument 0"}
!1204 = distinct !{!1204, !"_ZN3ruy10ToInternalIsEENS_3MatIT_EERNS_6MatrixIS2_EE"}
!1205 = !{!1206}
!1206 = distinct !{!1206, !1207, !"_ZNSt3__110make_tupleIJRN8gemmlowp23OutputStageBiasAdditionINS1_9VectorMapIKiLNS1_11VectorShapeE0EEEEERNS1_44OutputStageScaleInt32ByFixedPointAndExponentERNS1_16OutputStageClampERNS1_32OutputStageSaturatingCastToInt16EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOSH_: argument 0"}
!1207 = distinct !{!1207, !"_ZNSt3__110make_tupleIJRN8gemmlowp23OutputStageBiasAdditionINS1_9VectorMapIKiLNS1_11VectorShapeE0EEEEERNS1_44OutputStageScaleInt32ByFixedPointAndExponentERNS1_16OutputStageClampERNS1_32OutputStageSaturatingCastToInt16EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOSH_"}
!1208 = !{!1209}
!1209 = distinct !{!1209, !1210, !"_ZNSt3__110make_tupleIJRN8gemmlowp44OutputStageScaleInt32ByFixedPointAndExponentERNS1_16OutputStageClampERNS1_32OutputStageSaturatingCastToInt16EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOSA_: argument 0"}
!1210 = distinct !{!1210, !"_ZNSt3__110make_tupleIJRN8gemmlowp44OutputStageScaleInt32ByFixedPointAndExponentERNS1_16OutputStageClampERNS1_32OutputStageSaturatingCastToInt16EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOSA_"}
!1211 = !{!1212}
!1212 = distinct !{!1212, !1213, !"_ZN3ruy9EraseTypeIhEENS_4EMatERKNS_3MatIT_EE: argument 0"}
!1213 = distinct !{!1213, !"_ZN3ruy9EraseTypeIhEENS_4EMatERKNS_3MatIT_EE"}
!1214 = !{!1215}
!1215 = distinct !{!1215, !1216, !"_ZN3ruy9EraseTypeIhEENS_4EMatERKNS_3MatIT_EE: argument 0"}
!1216 = distinct !{!1216, !"_ZN3ruy9EraseTypeIhEENS_4EMatERKNS_3MatIT_EE"}
!1217 = !{!1218}
!1218 = distinct !{!1218, !1219, !"_ZN3ruy9EraseTypeIsEENS_4EMatERKNS_3MatIT_EE: argument 0"}
!1219 = distinct !{!1219, !"_ZN3ruy9EraseTypeIsEENS_4EMatERKNS_3MatIT_EE"}
!1220 = !{!1221}
!1221 = distinct !{!1221, !1222, !"_ZN3ruy11UneraseTypeIsEENS_3MatIT_EERKNS_4EMatE: argument 0"}
!1222 = distinct !{!1222, !"_ZN3ruy11UneraseTypeIsEENS_3MatIT_EERKNS_4EMatE"}
!1223 = !{!1224}
!1224 = distinct !{!1224, !1225, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!1225 = distinct !{!1225, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE"}
!1226 = !{!1227}
!1227 = distinct !{!1227, !1228, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!1228 = distinct !{!1228, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE"}
!1229 = !{!1230}
!1230 = distinct !{!1230, !1231, !"_ZN3ruy11UneraseTypeIsEENS_3MatIT_EERKNS_4EMatE: argument 0"}
!1231 = distinct !{!1231, !"_ZN3ruy11UneraseTypeIsEENS_3MatIT_EERKNS_4EMatE"}
!1232 = !{!1233}
!1233 = distinct !{!1233, !1234, !"_ZN3ruy11UneraseTypeIhEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!1234 = distinct !{!1234, !"_ZN3ruy11UneraseTypeIhEENS_4PMatIT_EERKNS_5PEMatE"}
!1235 = !{!1236}
!1236 = distinct !{!1236, !1237, !"_ZN3ruy11UneraseTypeIhEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!1237 = distinct !{!1237, !"_ZN3ruy11UneraseTypeIhEENS_4PMatIT_EERKNS_5PEMatE"}
!1238 = !{!1239}
!1239 = distinct !{!1239, !1240, !"_ZN3ruy11UneraseTypeIsEENS_3MatIT_EERKNS_4EMatE: argument 0"}
!1240 = distinct !{!1240, !"_ZN3ruy11UneraseTypeIsEENS_3MatIT_EERKNS_4EMatE"}
!1241 = !{!1242}
!1242 = distinct !{!1242, !1243, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!1243 = distinct !{!1243, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE"}
!1244 = !{!1245}
!1245 = distinct !{!1245, !1246, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE: argument 0"}
!1246 = distinct !{!1246, !"_ZN3ruy11UneraseTypeIaEENS_4PMatIT_EERKNS_5PEMatE"}
!1247 = !{!1248, !1250}
!1248 = distinct !{!1248, !1249, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIsLNS_8MapOrderE0EEEE3RunERKS3_: argument 0"}
!1249 = distinct !{!1249, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIsLNS_8MapOrderE0EEEE3RunERKS3_"}
!1250 = distinct !{!1250, !1251, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIsLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS5_: argument 0"}
!1251 = distinct !{!1251, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIsLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS5_"}
!1252 = !{!1253, !1255}
!1253 = distinct !{!1253, !1254, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE0EEEE3RunERKS4_: argument 0"}
!1254 = distinct !{!1254, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE0EEEE3RunERKS4_"}
!1255 = distinct !{!1255, !1256, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!1256 = distinct !{!1256, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!1257 = !{!1258, !1260}
!1258 = distinct !{!1258, !1259, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE1EEEE3RunERKS4_: argument 0"}
!1259 = distinct !{!1259, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE1EEEE3RunERKS4_"}
!1260 = distinct !{!1260, !1261, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!1261 = distinct !{!1261, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!1262 = !{!1263, !1265}
!1263 = distinct !{!1263, !1264, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE1EEEE3RunERKS4_: argument 0"}
!1264 = distinct !{!1264, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE1EEEE3RunERKS4_"}
!1265 = distinct !{!1265, !1266, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!1266 = distinct !{!1266, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!1267 = !{!1268, !1270}
!1268 = distinct !{!1268, !1269, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE0EEEE3RunERKS4_: argument 0"}
!1269 = distinct !{!1269, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE0EEEE3RunERKS4_"}
!1270 = distinct !{!1270, !1271, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!1271 = distinct !{!1271, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!1272 = !{!1273, !1275, !1277, !1279, !1281}
!1273 = distinct !{!1273, !1274, !"_ZN8gemmlowp13TransposeImplINS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS4_: argument 0"}
!1274 = distinct !{!1274, !"_ZN8gemmlowp13TransposeImplINS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS4_"}
!1275 = distinct !{!1275, !1276, !"_ZN8gemmlowp9TransposeINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!1276 = distinct !{!1276, !"_ZN8gemmlowp9TransposeINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!1277 = distinct !{!1277, !1278, !"_ZN8gemmlowp13TransposeImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEEE3RunERKS6_: argument 0"}
!1278 = distinct !{!1278, !"_ZN8gemmlowp13TransposeImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEEE3RunERKS6_"}
!1279 = distinct !{!1279, !1280, !"_ZN8gemmlowp9TransposeINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEEEENS_13TransposeImplIT_E7DstTypeERKS8_: argument 0"}
!1280 = distinct !{!1280, !"_ZN8gemmlowp9TransposeINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEEEENS_13TransposeImplIT_E7DstTypeERKS8_"}
!1281 = distinct !{!1281, !1282, !"_ZN8gemmlowp14TransposeTupleINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEENSt3__15tupleIJNS_13TransposeImplIT_E7DstTypeENSC_IT0_E7DstTypeENSC_IT1_E7DstTypeENSC_IT2_E7DstTypeEEEERKNSB_IJSD_SG_SJ_SM_EEE: argument 0"}
!1282 = distinct !{!1282, !"_ZN8gemmlowp14TransposeTupleINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEENSt3__15tupleIJNS_13TransposeImplIT_E7DstTypeENSC_IT0_E7DstTypeENSC_IT1_E7DstTypeENSC_IT2_E7DstTypeEEEERKNSB_IJSD_SG_SJ_SM_EEE"}
!1283 = !{!1281}
!1284 = !{!1285, !1281}
!1285 = distinct !{!1285, !1286, !"_ZNSt3__110make_tupleIJN8gemmlowp23OutputStageBiasAdditionINS1_9VectorMapIKiLNS1_11VectorShapeE1EEEEENS1_44OutputStageScaleInt32ByFixedPointAndExponentENS1_16OutputStageClampENS1_32OutputStageSaturatingCastToInt16EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOSD_: argument 0"}
!1286 = distinct !{!1286, !"_ZNSt3__110make_tupleIJN8gemmlowp23OutputStageBiasAdditionINS1_9VectorMapIKiLNS1_11VectorShapeE1EEEEENS1_44OutputStageScaleInt32ByFixedPointAndExponentENS1_16OutputStageClampENS1_32OutputStageSaturatingCastToInt16EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOSD_"}
!1287 = !{!1288, !1290}
!1288 = distinct !{!1288, !1289, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIsLNS_8MapOrderE1EEEE3RunERKS3_: argument 0"}
!1289 = distinct !{!1289, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIsLNS_8MapOrderE1EEEE3RunERKS3_"}
!1290 = distinct !{!1290, !1291, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIsLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS5_: argument 0"}
!1291 = distinct !{!1291, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIsLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS5_"}
!1292 = !{!1293, !1295}
!1293 = distinct !{!1293, !1294, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE0EEEE3RunERKS4_: argument 0"}
!1294 = distinct !{!1294, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE0EEEE3RunERKS4_"}
!1295 = distinct !{!1295, !1296, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!1296 = distinct !{!1296, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!1297 = !{!1298, !1300}
!1298 = distinct !{!1298, !1299, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE1EEEE3RunERKS4_: argument 0"}
!1299 = distinct !{!1299, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE1EEEE3RunERKS4_"}
!1300 = distinct !{!1300, !1301, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!1301 = distinct !{!1301, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!1302 = !{!1303, !1305}
!1303 = distinct !{!1303, !1304, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE0EEEE3RunERKS4_: argument 0"}
!1304 = distinct !{!1304, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE0EEEE3RunERKS4_"}
!1305 = distinct !{!1305, !1306, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!1306 = distinct !{!1306, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!1307 = !{!1308, !1310}
!1308 = distinct !{!1308, !1309, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE1EEEE3RunERKS4_: argument 0"}
!1309 = distinct !{!1309, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE1EEEE3RunERKS4_"}
!1310 = distinct !{!1310, !1311, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!1311 = distinct !{!1311, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!1312 = !{!1313, !1315, !1317, !1319, !1321}
!1313 = distinct !{!1313, !1314, !"_ZN8gemmlowp13TransposeImplINS_9VectorMapIKiLNS_11VectorShapeE1EEEE3RunERKS4_: argument 0"}
!1314 = distinct !{!1314, !"_ZN8gemmlowp13TransposeImplINS_9VectorMapIKiLNS_11VectorShapeE1EEEE3RunERKS4_"}
!1315 = distinct !{!1315, !1316, !"_ZN8gemmlowp9TransposeINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!1316 = distinct !{!1316, !"_ZN8gemmlowp9TransposeINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!1317 = distinct !{!1317, !1318, !"_ZN8gemmlowp13TransposeImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEEE3RunERKS6_: argument 0"}
!1318 = distinct !{!1318, !"_ZN8gemmlowp13TransposeImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEEE3RunERKS6_"}
!1319 = distinct !{!1319, !1320, !"_ZN8gemmlowp9TransposeINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEEEENS_13TransposeImplIT_E7DstTypeERKS8_: argument 0"}
!1320 = distinct !{!1320, !"_ZN8gemmlowp9TransposeINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEEEENS_13TransposeImplIT_E7DstTypeERKS8_"}
!1321 = distinct !{!1321, !1322, !"_ZN8gemmlowp14TransposeTupleINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEENSt3__15tupleIJNS_13TransposeImplIT_E7DstTypeENSC_IT0_E7DstTypeENSC_IT1_E7DstTypeENSC_IT2_E7DstTypeEEEERKNSB_IJSD_SG_SJ_SM_EEE: argument 0"}
!1322 = distinct !{!1322, !"_ZN8gemmlowp14TransposeTupleINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEENSt3__15tupleIJNS_13TransposeImplIT_E7DstTypeENSC_IT0_E7DstTypeENSC_IT1_E7DstTypeENSC_IT2_E7DstTypeEEEERKNSB_IJSD_SG_SJ_SM_EEE"}
!1323 = !{!1321}
!1324 = !{!1325, !1321}
!1325 = distinct !{!1325, !1326, !"_ZNSt3__110make_tupleIJN8gemmlowp23OutputStageBiasAdditionINS1_9VectorMapIKiLNS1_11VectorShapeE0EEEEENS1_44OutputStageScaleInt32ByFixedPointAndExponentENS1_16OutputStageClampENS1_32OutputStageSaturatingCastToInt16EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOSD_: argument 0"}
!1326 = distinct !{!1326, !"_ZNSt3__110make_tupleIJN8gemmlowp23OutputStageBiasAdditionINS1_9VectorMapIKiLNS1_11VectorShapeE0EEEEENS1_44OutputStageScaleInt32ByFixedPointAndExponentENS1_16OutputStageClampENS1_32OutputStageSaturatingCastToInt16EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOSD_"}
!1327 = !{!1328}
!1328 = distinct !{!1328, !1329, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!1329 = distinct !{!1329, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!1330 = !{!1331}
!1331 = distinct !{!1331, !1332, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!1332 = distinct !{!1332, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!1333 = !{!1334}
!1334 = distinct !{!1334, !1335, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii: argument 0"}
!1335 = distinct !{!1335, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii"}
!1336 = !{!1337}
!1337 = distinct !{!1337, !1338, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!1338 = distinct !{!1338, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!1339 = !{!1340}
!1340 = distinct !{!1340, !1341, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!1341 = distinct !{!1341, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!1342 = !{!1343}
!1343 = distinct !{!1343, !1344, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!1344 = distinct !{!1344, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!1345 = !{!1346}
!1346 = distinct !{!1346, !1347, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii: argument 0"}
!1347 = distinct !{!1347, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii"}
!1348 = !{!1349}
!1349 = distinct !{!1349, !1350, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!1350 = distinct !{!1350, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!1351 = !{!1352}
!1352 = distinct !{!1352, !1353, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!1353 = distinct !{!1353, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!1354 = !{!1355}
!1355 = distinct !{!1355, !1356, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!1356 = distinct !{!1356, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!1357 = !{!1358}
!1358 = distinct !{!1358, !1359, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!1359 = distinct !{!1359, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!1360 = !{!1361}
!1361 = distinct !{!1361, !1362, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!1362 = distinct !{!1362, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!1363 = !{!1364}
!1364 = distinct !{!1364, !1365, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!1365 = distinct !{!1365, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!1366 = !{!1367}
!1367 = distinct !{!1367, !1368, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!1368 = distinct !{!1368, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!1369 = !{!1370}
!1370 = distinct !{!1370, !1371, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii: argument 0"}
!1371 = distinct !{!1371, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii"}
!1372 = !{!1373}
!1373 = distinct !{!1373, !1374, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii: argument 0"}
!1374 = distinct !{!1374, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii"}
!1375 = !{!1376}
!1376 = distinct !{!1376, !1377, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii: argument 0"}
!1377 = distinct !{!1377, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii"}
!1378 = !{!1379}
!1379 = distinct !{!1379, !1380, !"_ZNK8gemmlowp12PackedResult3MapEv: argument 0"}
!1380 = distinct !{!1380, !"_ZNK8gemmlowp12PackedResult3MapEv"}
!1381 = !{!1382}
!1382 = distinct !{!1382, !1383, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!1383 = distinct !{!1383, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!1384 = !{!1385, !1387}
!1385 = distinct !{!1385, !1386, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i: argument 0"}
!1386 = distinct !{!1386, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i"}
!1387 = distinct !{!1387, !1388, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i: argument 0"}
!1388 = distinct !{!1388, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i"}
!1389 = !{!1390, !1392}
!1390 = distinct !{!1390, !1391, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!1391 = distinct !{!1391, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!1392 = distinct !{!1392, !1393, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii: argument 0"}
!1393 = distinct !{!1393, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii"}
!1394 = !{!1395}
!1395 = distinct !{!1395, !1396, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!1396 = distinct !{!1396, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!1397 = !{!1398, !1400}
!1398 = distinct !{!1398, !1399, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i: argument 0"}
!1399 = distinct !{!1399, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i"}
!1400 = distinct !{!1400, !1401, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i: argument 0"}
!1401 = distinct !{!1401, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i"}
!1402 = !{!1403, !1405}
!1403 = distinct !{!1403, !1404, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!1404 = distinct !{!1404, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!1405 = distinct !{!1405, !1406, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii: argument 0"}
!1406 = distinct !{!1406, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii"}
!1407 = !{!1408, !1410}
!1408 = distinct !{!1408, !1409, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i: argument 0"}
!1409 = distinct !{!1409, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i"}
!1410 = distinct !{!1410, !1411, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i: argument 0"}
!1411 = distinct !{!1411, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i"}
!1412 = !{!1413}
!1413 = distinct !{!1413, !1414, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_13RegisterBlockIiLi8ELi1EEEE4EvalES8_ii: argument 0"}
!1414 = distinct !{!1414, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_13RegisterBlockIiLi8ELi1EEEE4EvalES8_ii"}
!1415 = !{!1416, !1418}
!1416 = distinct !{!1416, !1417, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_13RegisterBlockIiLi8ELi4EEEE4EvalES8_ii: argument 0"}
!1417 = distinct !{!1417, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_13RegisterBlockIiLi8ELi4EEEE4EvalES8_ii"}
!1418 = distinct !{!1418, !1419, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii: argument 0"}
!1419 = distinct !{!1419, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii"}
!1420 = !{!1418}
!1421 = !{!1422}
!1422 = distinct !{!1422, !1423, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii: argument 0"}
!1423 = distinct !{!1423, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii"}
!1424 = !{!1425}
!1425 = distinct !{!1425, !1426, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi32EEEE4EvalES3_: argument 0"}
!1426 = distinct !{!1426, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi32EEEE4EvalES3_"}
!1427 = !{!1425, !1422}
!1428 = !{!1429}
!1429 = distinct !{!1429, !1430, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii: argument 0"}
!1430 = distinct !{!1430, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii"}
!1431 = !{!1432}
!1432 = distinct !{!1432, !1433, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii: argument 0"}
!1433 = distinct !{!1433, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii"}
!1434 = !{!1429, !1432}
!1435 = !{!1436, !1429, !1432}
!1436 = distinct !{!1436, !1437, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi32EEEE4EvalES3_: argument 0"}
!1437 = distinct !{!1437, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi32EEEE4EvalES3_"}
!1438 = !{!1436}
!1439 = !{!1440}
!1440 = distinct !{!1440, !1441, !"_ZNK8gemmlowp19OutputStageEvalImplINS_32OutputStageSaturatingCastToInt16ENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii: argument 0"}
!1441 = distinct !{!1441, !"_ZNK8gemmlowp19OutputStageEvalImplINS_32OutputStageSaturatingCastToInt16ENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii"}
!1442 = !{!1443, !1432}
!1443 = distinct !{!1443, !1444, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi3ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii: argument 0"}
!1444 = distinct !{!1444, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi3ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii"}
!1445 = !{!1440, !1443, !1432}
!1446 = !{!1447}
!1447 = distinct !{!1447, !1448, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_32OutputStageSaturatingCastToInt16ENS_14RegisterBufferIiLi32EEEE4EvalES3_: argument 0"}
!1448 = distinct !{!1448, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_32OutputStageSaturatingCastToInt16ENS_14RegisterBufferIiLi32EEEE4EvalES3_"}
!1449 = !{!1447, !1440, !1443, !1432}
!1450 = !{!1451}
!1451 = distinct !{!1451, !1452, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_13RegisterBlockIiLi4ELi4EEEE4EvalES8_ii: argument 0"}
!1452 = distinct !{!1452, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_13RegisterBlockIiLi4ELi4EEEE4EvalES8_ii"}
!1453 = !{!1454}
!1454 = distinct !{!1454, !1455, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii: argument 0"}
!1455 = distinct !{!1455, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii"}
!1456 = !{!1457}
!1457 = distinct !{!1457, !1458, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii: argument 0"}
!1458 = distinct !{!1458, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii"}
!1459 = !{!1457, !1454}
!1460 = !{!1461}
!1461 = distinct !{!1461, !1462, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi16EEEE4EvalES3_: argument 0"}
!1462 = distinct !{!1462, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi16EEEE4EvalES3_"}
!1463 = !{!1461, !1457, !1454}
!1464 = !{!1465, !1467}
!1465 = distinct !{!1465, !1466, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi16EEEE4EvalES3_: argument 0"}
!1466 = distinct !{!1466, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi16EEEE4EvalES3_"}
!1467 = distinct !{!1467, !1468, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii: argument 0"}
!1468 = distinct !{!1468, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii"}
!1469 = !{!1470}
!1470 = distinct !{!1470, !1471, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi3ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii: argument 0"}
!1471 = distinct !{!1471, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi3ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii"}
!1472 = !{!1473, !1475}
!1473 = distinct !{!1473, !1474, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_13RegisterBlockIiLi8ELi4EEEE4EvalES8_ii: argument 0"}
!1474 = distinct !{!1474, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_13RegisterBlockIiLi8ELi4EEEE4EvalES8_ii"}
!1475 = distinct !{!1475, !1476, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii: argument 0"}
!1476 = distinct !{!1476, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE1EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii"}
!1477 = !{!1475}
!1478 = !{!1479}
!1479 = distinct !{!1479, !1480, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii: argument 0"}
!1480 = distinct !{!1480, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii"}
!1481 = !{!1482}
!1482 = distinct !{!1482, !1483, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi8EEEE4EvalES3_: argument 0"}
!1483 = distinct !{!1483, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi8EEEE4EvalES3_"}
!1484 = !{!1482, !1479}
!1485 = !{!1486, !1488}
!1486 = distinct !{!1486, !1487, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi8EEEE4EvalES3_: argument 0"}
!1487 = distinct !{!1487, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi8EEEE4EvalES3_"}
!1488 = distinct !{!1488, !1489, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii: argument 0"}
!1489 = distinct !{!1489, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii"}
!1490 = !{!1491}
!1491 = distinct !{!1491, !1492, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!1492 = distinct !{!1492, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!1493 = !{!1494}
!1494 = distinct !{!1494, !1495, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!1495 = distinct !{!1495, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!1496 = !{!1497}
!1497 = distinct !{!1497, !1498, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!1498 = distinct !{!1498, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!1499 = !{!1500}
!1500 = distinct !{!1500, !1501, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!1501 = distinct !{!1501, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!1502 = !{!1503}
!1503 = distinct !{!1503, !1504, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii: argument 0"}
!1504 = distinct !{!1504, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii"}
!1505 = !{!1506}
!1506 = distinct !{!1506, !1507, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii: argument 0"}
!1507 = distinct !{!1507, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii"}
!1508 = !{!1509}
!1509 = distinct !{!1509, !1510, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!1510 = distinct !{!1510, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!1511 = !{!1512}
!1512 = distinct !{!1512, !1513, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!1513 = distinct !{!1513, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!1514 = !{!1515}
!1515 = distinct !{!1515, !1516, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!1516 = distinct !{!1516, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!1517 = !{!1518}
!1518 = distinct !{!1518, !1519, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!1519 = distinct !{!1519, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!1520 = !{!1521}
!1521 = distinct !{!1521, !1522, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!1522 = distinct !{!1522, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!1523 = !{!1524}
!1524 = distinct !{!1524, !1525, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!1525 = distinct !{!1525, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!1526 = !{!1527}
!1527 = distinct !{!1527, !1528, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii: argument 0"}
!1528 = distinct !{!1528, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii"}
!1529 = !{!1530}
!1530 = distinct !{!1530, !1531, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii: argument 0"}
!1531 = distinct !{!1531, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii"}
!1532 = !{!1533}
!1533 = distinct !{!1533, !1534, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii: argument 0"}
!1534 = distinct !{!1534, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii"}
!1535 = !{!1536}
!1536 = distinct !{!1536, !1537, !"_ZNK8gemmlowp12PackedResult3MapEv: argument 0"}
!1537 = distinct !{!1537, !"_ZNK8gemmlowp12PackedResult3MapEv"}
!1538 = !{!1539, !1541}
!1539 = distinct !{!1539, !1540, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!1540 = distinct !{!1540, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!1541 = distinct !{!1541, !1542, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii: argument 0"}
!1542 = distinct !{!1542, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii"}
!1543 = !{!1544}
!1544 = distinct !{!1544, !1545, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!1545 = distinct !{!1545, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!1546 = !{!1547, !1549}
!1547 = distinct !{!1547, !1548, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i: argument 0"}
!1548 = distinct !{!1548, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i"}
!1549 = distinct !{!1549, !1550, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i: argument 0"}
!1550 = distinct !{!1550, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i"}
!1551 = !{!1552, !1554}
!1552 = distinct !{!1552, !1553, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!1553 = distinct !{!1553, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!1554 = distinct !{!1554, !1555, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii: argument 0"}
!1555 = distinct !{!1555, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii"}
!1556 = !{!1557, !1559}
!1557 = distinct !{!1557, !1558, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_13RegisterBlockIiLi8ELi4EEEE4EvalES8_ii: argument 0"}
!1558 = distinct !{!1558, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_13RegisterBlockIiLi8ELi4EEEE4EvalES8_ii"}
!1559 = distinct !{!1559, !1560, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii: argument 0"}
!1560 = distinct !{!1560, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii"}
!1561 = !{!1562, !1564, !1557, !1559}
!1562 = distinct !{!1562, !1563, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i: argument 0"}
!1563 = distinct !{!1563, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i"}
!1564 = distinct !{!1564, !1565, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i: argument 0"}
!1565 = distinct !{!1565, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i"}
!1566 = !{!1559}
!1567 = !{!1568}
!1568 = distinct !{!1568, !1569, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii: argument 0"}
!1569 = distinct !{!1569, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii"}
!1570 = !{!1571}
!1571 = distinct !{!1571, !1572, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi32EEEE4EvalES3_: argument 0"}
!1572 = distinct !{!1572, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi32EEEE4EvalES3_"}
!1573 = !{!1571, !1568}
!1574 = !{!1575}
!1575 = distinct !{!1575, !1576, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii: argument 0"}
!1576 = distinct !{!1576, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii"}
!1577 = !{!1578}
!1578 = distinct !{!1578, !1579, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii: argument 0"}
!1579 = distinct !{!1579, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii"}
!1580 = !{!1575, !1578}
!1581 = !{!1582, !1575, !1578}
!1582 = distinct !{!1582, !1583, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi32EEEE4EvalES3_: argument 0"}
!1583 = distinct !{!1583, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi32EEEE4EvalES3_"}
!1584 = !{!1582}
!1585 = !{!1586}
!1586 = distinct !{!1586, !1587, !"_ZNK8gemmlowp19OutputStageEvalImplINS_32OutputStageSaturatingCastToInt16ENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii: argument 0"}
!1587 = distinct !{!1587, !"_ZNK8gemmlowp19OutputStageEvalImplINS_32OutputStageSaturatingCastToInt16ENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii"}
!1588 = !{!1589, !1578}
!1589 = distinct !{!1589, !1590, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi3ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii: argument 0"}
!1590 = distinct !{!1590, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi3ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalESE_ii"}
!1591 = !{!1586, !1589, !1578}
!1592 = !{!1593}
!1593 = distinct !{!1593, !1594, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_32OutputStageSaturatingCastToInt16ENS_14RegisterBufferIiLi32EEEE4EvalES3_: argument 0"}
!1594 = distinct !{!1594, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_32OutputStageSaturatingCastToInt16ENS_14RegisterBufferIiLi32EEEE4EvalES3_"}
!1595 = !{!1593, !1586, !1589, !1578}
!1596 = !{!1597}
!1597 = distinct !{!1597, !1598, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_13RegisterBlockIiLi4ELi4EEEE4EvalES8_ii: argument 0"}
!1598 = distinct !{!1598, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_13RegisterBlockIiLi4ELi4EEEE4EvalES8_ii"}
!1599 = !{!1600}
!1600 = distinct !{!1600, !1601, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii: argument 0"}
!1601 = distinct !{!1601, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii"}
!1602 = !{!1603}
!1603 = distinct !{!1603, !1604, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii: argument 0"}
!1604 = distinct !{!1604, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii"}
!1605 = !{!1603, !1600}
!1606 = !{!1607}
!1607 = distinct !{!1607, !1608, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi16EEEE4EvalES3_: argument 0"}
!1608 = distinct !{!1608, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi16EEEE4EvalES3_"}
!1609 = !{!1607, !1603, !1600}
!1610 = !{!1611, !1613}
!1611 = distinct !{!1611, !1612, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi16EEEE4EvalES3_: argument 0"}
!1612 = distinct !{!1612, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi16EEEE4EvalES3_"}
!1613 = distinct !{!1613, !1614, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii: argument 0"}
!1614 = distinct !{!1614, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii"}
!1615 = !{!1616}
!1616 = distinct !{!1616, !1617, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi3ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii: argument 0"}
!1617 = distinct !{!1617, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi3ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalESE_ii"}
!1618 = !{!1619}
!1619 = distinct !{!1619, !1620, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_13RegisterBlockIiLi8ELi1EEEE4EvalES8_ii: argument 0"}
!1620 = distinct !{!1620, !"_ZNK8gemmlowp19OutputStageEvalImplINS_23OutputStageBiasAdditionINS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_13RegisterBlockIiLi8ELi1EEEE4EvalES8_ii"}
!1621 = !{!1622, !1624, !1619}
!1622 = distinct !{!1622, !1623, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i: argument 0"}
!1623 = distinct !{!1623, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i"}
!1624 = distinct !{!1624, !1625, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i: argument 0"}
!1625 = distinct !{!1625, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i"}
!1626 = !{!1627}
!1627 = distinct !{!1627, !1628, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii: argument 0"}
!1628 = distinct !{!1628, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii"}
!1629 = !{!1630}
!1630 = distinct !{!1630, !1631, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi8EEEE4EvalES3_: argument 0"}
!1631 = distinct !{!1631, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi8EEEE4EvalES3_"}
!1632 = !{!1630, !1627}
!1633 = !{!1634, !1636}
!1634 = distinct !{!1634, !1635, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi8EEEE4EvalES3_: argument 0"}
!1635 = distinct !{!1635, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi8EEEE4EvalES3_"}
!1636 = distinct !{!1636, !1637, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii: argument 0"}
!1637 = distinct !{!1637, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii"}
!1638 = !{!1639}
!1639 = distinct !{!1639, !1640, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!1640 = distinct !{!1640, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!1641 = !{!1642}
!1642 = distinct !{!1642, !1643, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!1643 = distinct !{!1643, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!1644 = !{!1645}
!1645 = distinct !{!1645, !1646, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!1646 = distinct !{!1646, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!1647 = !{!1648}
!1648 = distinct !{!1648, !1649, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!1649 = distinct !{!1649, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!1650 = !{!1651}
!1651 = distinct !{!1651, !1652, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii: argument 0"}
!1652 = distinct !{!1652, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii"}
!1653 = !{!1654}
!1654 = distinct !{!1654, !1655, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii: argument 0"}
!1655 = distinct !{!1655, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii"}
!1656 = !{!1657, !1659}
!1657 = distinct !{!1657, !1658, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIsLNS_8MapOrderE0EEEE3RunERKS3_: argument 0"}
!1658 = distinct !{!1658, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIsLNS_8MapOrderE0EEEE3RunERKS3_"}
!1659 = distinct !{!1659, !1660, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIsLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS5_: argument 0"}
!1660 = distinct !{!1660, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIsLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS5_"}
!1661 = !{!1662, !1664}
!1662 = distinct !{!1662, !1663, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE0EEEE3RunERKS4_: argument 0"}
!1663 = distinct !{!1663, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE0EEEE3RunERKS4_"}
!1664 = distinct !{!1664, !1665, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!1665 = distinct !{!1665, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!1666 = !{!1667, !1669}
!1667 = distinct !{!1667, !1668, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE1EEEE3RunERKS4_: argument 0"}
!1668 = distinct !{!1668, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE1EEEE3RunERKS4_"}
!1669 = distinct !{!1669, !1670, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!1670 = distinct !{!1670, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!1671 = !{!1672, !1674}
!1672 = distinct !{!1672, !1673, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE1EEEE3RunERKS4_: argument 0"}
!1673 = distinct !{!1673, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE1EEEE3RunERKS4_"}
!1674 = distinct !{!1674, !1675, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!1675 = distinct !{!1675, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!1676 = !{!1677, !1679}
!1677 = distinct !{!1677, !1678, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE0EEEE3RunERKS4_: argument 0"}
!1678 = distinct !{!1678, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE0EEEE3RunERKS4_"}
!1679 = distinct !{!1679, !1680, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!1680 = distinct !{!1680, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!1681 = !{!1682}
!1682 = distinct !{!1682, !1683, !"_ZN8gemmlowp14TransposeTupleINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEENSt3__15tupleIJNS_13TransposeImplIT_E7DstTypeENS6_IT0_E7DstTypeENS6_IT1_E7DstTypeEEEERKNS5_IJS7_SA_SD_EEE: argument 0"}
!1683 = distinct !{!1683, !"_ZN8gemmlowp14TransposeTupleINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEENSt3__15tupleIJNS_13TransposeImplIT_E7DstTypeENS6_IT0_E7DstTypeENS6_IT1_E7DstTypeEEEERKNS5_IJS7_SA_SD_EEE"}
!1684 = !{!1685, !1682}
!1685 = distinct !{!1685, !1686, !"_ZNSt3__110make_tupleIJN8gemmlowp44OutputStageScaleInt32ByFixedPointAndExponentENS1_16OutputStageClampENS1_32OutputStageSaturatingCastToInt16EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOS7_: argument 0"}
!1686 = distinct !{!1686, !"_ZNSt3__110make_tupleIJN8gemmlowp44OutputStageScaleInt32ByFixedPointAndExponentENS1_16OutputStageClampENS1_32OutputStageSaturatingCastToInt16EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOS7_"}
!1687 = !{!1688, !1690}
!1688 = distinct !{!1688, !1689, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIsLNS_8MapOrderE1EEEE3RunERKS3_: argument 0"}
!1689 = distinct !{!1689, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIsLNS_8MapOrderE1EEEE3RunERKS3_"}
!1690 = distinct !{!1690, !1691, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIsLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS5_: argument 0"}
!1691 = distinct !{!1691, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIsLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS5_"}
!1692 = !{!1693, !1695}
!1693 = distinct !{!1693, !1694, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE0EEEE3RunERKS4_: argument 0"}
!1694 = distinct !{!1694, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE0EEEE3RunERKS4_"}
!1695 = distinct !{!1695, !1696, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!1696 = distinct !{!1696, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!1697 = !{!1698, !1700}
!1698 = distinct !{!1698, !1699, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE1EEEE3RunERKS4_: argument 0"}
!1699 = distinct !{!1699, !"_ZN8gemmlowp13TransposeImplINS_9MatrixMapIKhLNS_8MapOrderE1EEEE3RunERKS4_"}
!1700 = distinct !{!1700, !1701, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!1701 = distinct !{!1701, !"_ZN8gemmlowp9TransposeINS_9MatrixMapIKhLNS_8MapOrderE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!1702 = !{!1703, !1705}
!1703 = distinct !{!1703, !1704, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE0EEEE3RunERKS4_: argument 0"}
!1704 = distinct !{!1704, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE0EEEE3RunERKS4_"}
!1705 = distinct !{!1705, !1706, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!1706 = distinct !{!1706, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE0EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!1707 = !{!1708, !1710}
!1708 = distinct !{!1708, !1709, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE1EEEE3RunERKS4_: argument 0"}
!1709 = distinct !{!1709, !"_ZN8gemmlowp13TransposeImplINS_9VectorDupIKiLNS_11VectorShapeE1EEEE3RunERKS4_"}
!1710 = distinct !{!1710, !1711, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_: argument 0"}
!1711 = distinct !{!1711, !"_ZN8gemmlowp9TransposeINS_9VectorDupIKiLNS_11VectorShapeE1EEEEENS_13TransposeImplIT_E7DstTypeERKS6_"}
!1712 = !{!1713}
!1713 = distinct !{!1713, !1714, !"_ZN8gemmlowp14TransposeTupleINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEENSt3__15tupleIJNS_13TransposeImplIT_E7DstTypeENS6_IT0_E7DstTypeENS6_IT1_E7DstTypeEEEERKNS5_IJS7_SA_SD_EEE: argument 0"}
!1714 = distinct !{!1714, !"_ZN8gemmlowp14TransposeTupleINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEENSt3__15tupleIJNS_13TransposeImplIT_E7DstTypeENS6_IT0_E7DstTypeENS6_IT1_E7DstTypeEEEERKNS5_IJS7_SA_SD_EEE"}
!1715 = !{!1716, !1713}
!1716 = distinct !{!1716, !1717, !"_ZNSt3__110make_tupleIJN8gemmlowp44OutputStageScaleInt32ByFixedPointAndExponentENS1_16OutputStageClampENS1_32OutputStageSaturatingCastToInt16EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOS7_: argument 0"}
!1717 = distinct !{!1717, !"_ZNSt3__110make_tupleIJN8gemmlowp44OutputStageScaleInt32ByFixedPointAndExponentENS1_16OutputStageClampENS1_32OutputStageSaturatingCastToInt16EEEENS_5tupleIJDpNS_18__unwrap_ref_decayIT_E4typeEEEEDpOS7_"}
!1718 = !{!1719}
!1719 = distinct !{!1719, !1720, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!1720 = distinct !{!1720, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!1721 = !{!1722}
!1722 = distinct !{!1722, !1723, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!1723 = distinct !{!1723, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!1724 = !{!1725}
!1725 = distinct !{!1725, !1726, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii: argument 0"}
!1726 = distinct !{!1726, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii"}
!1727 = !{!1728}
!1728 = distinct !{!1728, !1729, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!1729 = distinct !{!1729, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!1730 = !{!1731}
!1731 = distinct !{!1731, !1732, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!1732 = distinct !{!1732, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!1733 = !{!1734}
!1734 = distinct !{!1734, !1735, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!1735 = distinct !{!1735, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!1736 = !{!1737}
!1737 = distinct !{!1737, !1738, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii: argument 0"}
!1738 = distinct !{!1738, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii"}
!1739 = !{!1740}
!1740 = distinct !{!1740, !1741, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!1741 = distinct !{!1741, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!1742 = !{!1743}
!1743 = distinct !{!1743, !1744, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!1744 = distinct !{!1744, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!1745 = !{!1746}
!1746 = distinct !{!1746, !1747, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!1747 = distinct !{!1747, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!1748 = !{!1749}
!1749 = distinct !{!1749, !1750, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!1750 = distinct !{!1750, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!1751 = !{!1752}
!1752 = distinct !{!1752, !1753, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!1753 = distinct !{!1753, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!1754 = !{!1755}
!1755 = distinct !{!1755, !1756, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!1756 = distinct !{!1756, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!1757 = !{!1758}
!1758 = distinct !{!1758, !1759, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!1759 = distinct !{!1759, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!1760 = !{!1761}
!1761 = distinct !{!1761, !1762, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii: argument 0"}
!1762 = distinct !{!1762, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii"}
!1763 = !{!1764}
!1764 = distinct !{!1764, !1765, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii: argument 0"}
!1765 = distinct !{!1765, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii"}
!1766 = !{!1767}
!1767 = distinct !{!1767, !1768, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii: argument 0"}
!1768 = distinct !{!1768, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii"}
!1769 = !{!1770}
!1770 = distinct !{!1770, !1771, !"_ZNK8gemmlowp12PackedResult3MapEv: argument 0"}
!1771 = distinct !{!1771, !"_ZNK8gemmlowp12PackedResult3MapEv"}
!1772 = !{!1773}
!1773 = distinct !{!1773, !1774, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!1774 = distinct !{!1774, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!1775 = !{!1776, !1778}
!1776 = distinct !{!1776, !1777, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i: argument 0"}
!1777 = distinct !{!1777, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i"}
!1778 = distinct !{!1778, !1779, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i: argument 0"}
!1779 = distinct !{!1779, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i"}
!1780 = !{!1781, !1783}
!1781 = distinct !{!1781, !1782, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!1782 = distinct !{!1782, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!1783 = distinct !{!1783, !1784, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii: argument 0"}
!1784 = distinct !{!1784, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii"}
!1785 = !{!1786}
!1786 = distinct !{!1786, !1787, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!1787 = distinct !{!1787, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!1788 = !{!1789, !1791}
!1789 = distinct !{!1789, !1790, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i: argument 0"}
!1790 = distinct !{!1790, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i"}
!1791 = distinct !{!1791, !1792, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i: argument 0"}
!1792 = distinct !{!1792, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i"}
!1793 = !{!1794, !1796}
!1794 = distinct !{!1794, !1795, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!1795 = distinct !{!1795, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!1796 = distinct !{!1796, !1797, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii: argument 0"}
!1797 = distinct !{!1797, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii"}
!1798 = !{!1799, !1801}
!1799 = distinct !{!1799, !1800, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i: argument 0"}
!1800 = distinct !{!1800, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i"}
!1801 = distinct !{!1801, !1802, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i: argument 0"}
!1802 = distinct !{!1802, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i"}
!1803 = !{!1804}
!1804 = distinct !{!1804, !1805, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii: argument 0"}
!1805 = distinct !{!1805, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii"}
!1806 = !{!1807}
!1807 = distinct !{!1807, !1808, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi32EEEE4EvalES3_: argument 0"}
!1808 = distinct !{!1808, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi32EEEE4EvalES3_"}
!1809 = !{!1807, !1804}
!1810 = !{!1811}
!1811 = distinct !{!1811, !1812, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii: argument 0"}
!1812 = distinct !{!1812, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii"}
!1813 = !{!1814}
!1814 = distinct !{!1814, !1815, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalES8_ii: argument 0"}
!1815 = distinct !{!1815, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi1ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalES8_ii"}
!1816 = !{!1811, !1814}
!1817 = !{!1818, !1811, !1814}
!1818 = distinct !{!1818, !1819, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi32EEEE4EvalES3_: argument 0"}
!1819 = distinct !{!1819, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi32EEEE4EvalES3_"}
!1820 = !{!1818}
!1821 = !{!1822}
!1822 = distinct !{!1822, !1823, !"_ZNK8gemmlowp19OutputStageEvalImplINS_32OutputStageSaturatingCastToInt16ENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii: argument 0"}
!1823 = distinct !{!1823, !"_ZNK8gemmlowp19OutputStageEvalImplINS_32OutputStageSaturatingCastToInt16ENS_13RegisterBlockIiLi8ELi4EEEE4EvalES3_ii"}
!1824 = !{!1825, !1814}
!1825 = distinct !{!1825, !1826, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalES8_ii: argument 0"}
!1826 = distinct !{!1826, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi8ELi4EEELb0EE4EvalES8_ii"}
!1827 = !{!1822, !1825, !1814}
!1828 = !{!1829}
!1829 = distinct !{!1829, !1830, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_32OutputStageSaturatingCastToInt16ENS_14RegisterBufferIiLi32EEEE4EvalES3_: argument 0"}
!1830 = distinct !{!1830, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_32OutputStageSaturatingCastToInt16ENS_14RegisterBufferIiLi32EEEE4EvalES3_"}
!1831 = !{!1829, !1822, !1825, !1814}
!1832 = !{!1833}
!1833 = distinct !{!1833, !1834, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalES8_ii: argument 0"}
!1834 = distinct !{!1834, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalES8_ii"}
!1835 = !{!1836}
!1836 = distinct !{!1836, !1837, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii: argument 0"}
!1837 = distinct !{!1837, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii"}
!1838 = !{!1836, !1833}
!1839 = !{!1840}
!1840 = distinct !{!1840, !1841, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi16EEEE4EvalES3_: argument 0"}
!1841 = distinct !{!1841, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi16EEEE4EvalES3_"}
!1842 = !{!1840, !1836, !1833}
!1843 = !{!1844, !1846}
!1844 = distinct !{!1844, !1845, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi16EEEE4EvalES3_: argument 0"}
!1845 = distinct !{!1845, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi16EEEE4EvalES3_"}
!1846 = distinct !{!1846, !1847, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii: argument 0"}
!1847 = distinct !{!1847, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii"}
!1848 = !{!1849}
!1849 = distinct !{!1849, !1850, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalES8_ii: argument 0"}
!1850 = distinct !{!1850, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi2ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalES8_ii"}
!1851 = !{!1852}
!1852 = distinct !{!1852, !1853, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii: argument 0"}
!1853 = distinct !{!1853, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii"}
!1854 = !{!1855}
!1855 = distinct !{!1855, !1856, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi8EEEE4EvalES3_: argument 0"}
!1856 = distinct !{!1856, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi8EEEE4EvalES3_"}
!1857 = !{!1855, !1852}
!1858 = !{!1859, !1861}
!1859 = distinct !{!1859, !1860, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi8EEEE4EvalES3_: argument 0"}
!1860 = distinct !{!1860, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_16OutputStageClampENS_14RegisterBufferIiLi8EEEE4EvalES3_"}
!1861 = distinct !{!1861, !1862, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii: argument 0"}
!1862 = distinct !{!1862, !"_ZNK8gemmlowp19OutputStageEvalImplINS_16OutputStageClampENS_13RegisterBlockIiLi8ELi1EEEE4EvalES3_ii"}
!1863 = !{!1864}
!1864 = distinct !{!1864, !1865, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!1865 = distinct !{!1865, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!1866 = !{!1867}
!1867 = distinct !{!1867, !1868, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!1868 = distinct !{!1868, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!1869 = !{!1870}
!1870 = distinct !{!1870, !1871, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!1871 = distinct !{!1871, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!1872 = !{!1873}
!1873 = distinct !{!1873, !1874, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!1874 = distinct !{!1874, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!1875 = !{!1876}
!1876 = distinct !{!1876, !1877, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii: argument 0"}
!1877 = distinct !{!1877, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii"}
!1878 = !{!1879}
!1879 = distinct !{!1879, !1880, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii: argument 0"}
!1880 = distinct !{!1880, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii"}
!1881 = !{!1882}
!1882 = distinct !{!1882, !1883, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!1883 = distinct !{!1883, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!1884 = !{!1885}
!1885 = distinct !{!1885, !1886, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!1886 = distinct !{!1886, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!1887 = !{!1888}
!1888 = distinct !{!1888, !1889, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!1889 = distinct !{!1889, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!1890 = !{!1891}
!1891 = distinct !{!1891, !1892, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!1892 = distinct !{!1892, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!1893 = !{!1894}
!1894 = distinct !{!1894, !1895, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!1895 = distinct !{!1895, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!1896 = !{!1897}
!1897 = distinct !{!1897, !1898, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!1898 = distinct !{!1898, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!1899 = !{!1900}
!1900 = distinct !{!1900, !1901, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii: argument 0"}
!1901 = distinct !{!1901, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE0EE5blockEiiii"}
!1902 = !{!1903}
!1903 = distinct !{!1903, !1904, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii: argument 0"}
!1904 = distinct !{!1904, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii"}
!1905 = !{!1906}
!1906 = distinct !{!1906, !1907, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii: argument 0"}
!1907 = distinct !{!1907, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii"}
!1908 = !{!1909}
!1909 = distinct !{!1909, !1910, !"_ZNK8gemmlowp12PackedResult3MapEv: argument 0"}
!1910 = distinct !{!1910, !"_ZNK8gemmlowp12PackedResult3MapEv"}
!1911 = !{!1912}
!1912 = distinct !{!1912, !1913, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!1913 = distinct !{!1913, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!1914 = !{!1915, !1917}
!1915 = distinct !{!1915, !1916, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i: argument 0"}
!1916 = distinct !{!1916, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i"}
!1917 = distinct !{!1917, !1918, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i: argument 0"}
!1918 = distinct !{!1918, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi4EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i"}
!1919 = !{!1920, !1922}
!1920 = distinct !{!1920, !1921, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!1921 = distinct !{!1921, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!1922 = distinct !{!1922, !1923, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii: argument 0"}
!1923 = distinct !{!1923, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi4ELi4EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii"}
!1924 = !{!1925, !1927}
!1925 = distinct !{!1925, !1926, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii: argument 0"}
!1926 = distinct !{!1926, !"_ZN8gemmlowp8LoadImplINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEE3RunERKS6_ii"}
!1927 = distinct !{!1927, !1928, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii: argument 0"}
!1928 = distinct !{!1928, !"_ZN8gemmlowp4LoadINS_13RegisterBlockIiLi8ELi1EEENS_9MatrixMapIKiLNS_8MapOrderE0EEEEET_RKT0_ii"}
!1929 = !{!1930, !1932}
!1930 = distinct !{!1930, !1931, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i: argument 0"}
!1931 = distinct !{!1931, !"_ZN8gemmlowp23LoadForBroadcastingImplINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEE3RunERKS6_i"}
!1932 = distinct !{!1932, !1933, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i: argument 0"}
!1933 = distinct !{!1933, !"_ZN8gemmlowp19LoadForBroadcastingINS_13RegisterBlockIiLi8ELi1EEENS_9VectorMapIKiLNS_11VectorShapeE0EEEEENS_32LoadForBroadcastingRegisterBlockIT_T0_E4TypeERKS9_i"}
!1934 = !{!1935}
!1935 = distinct !{!1935, !1936, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalES8_ii: argument 0"}
!1936 = distinct !{!1936, !"_ZNK8gemmlowp22OutputPipelineEvalImplINSt3__15tupleIJNS_44OutputStageScaleInt32ByFixedPointAndExponentENS_16OutputStageClampENS_32OutputStageSaturatingCastToInt16EEEELi0ENS_13RegisterBlockIiLi4ELi4EEELb0EE4EvalES8_ii"}
!1937 = !{!1938}
!1938 = distinct !{!1938, !1939, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii: argument 0"}
!1939 = distinct !{!1939, !"_ZNK8gemmlowp19OutputStageEvalImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_13RegisterBlockIiLi4ELi4EEEE4EvalES3_ii"}
!1940 = !{!1938, !1935}
!1941 = !{!1942}
!1942 = distinct !{!1942, !1943, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi16EEEE4EvalES3_: argument 0"}
!1943 = distinct !{!1943, !"_ZNK8gemmlowp25OutputStageEvalBufferImplINS_44OutputStageScaleInt32ByFixedPointAndExponentENS_14RegisterBufferIiLi16EEEE4EvalES3_"}
!1944 = !{!1942, !1938, !1935}
!1945 = !{!1946}
!1946 = distinct !{!1946, !1947, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm: argument 0"}
!1947 = distinct !{!1947, !"_ZN8gemmlowp9Allocator7ReserveIhEENS0_6HandleEm"}
!1948 = !{!1949}
!1949 = distinct !{!1949, !1950, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!1950 = distinct !{!1950, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!1951 = !{!1952}
!1952 = distinct !{!1952, !1953, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm: argument 0"}
!1953 = distinct !{!1953, !"_ZN8gemmlowp9Allocator7ReserveIiEENS0_6HandleEm"}
!1954 = !{!1955}
!1955 = distinct !{!1955, !1956, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii: argument 0"}
!1956 = distinct !{!1956, !"_ZNK8gemmlowp9MatrixMapIKhLNS_8MapOrderE1EE5blockEiiii"}
!1957 = !{!1958}
!1958 = distinct !{!1958, !1959, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii: argument 0"}
!1959 = distinct !{!1959, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE0EE5blockEii"}
!1960 = !{!1961}
!1961 = distinct !{!1961, !1962, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii: argument 0"}
!1962 = distinct !{!1962, !"_ZNK8gemmlowp9VectorDupIKiLNS_11VectorShapeE1EE5blockEii"}
!1963 = !{!1964}
!1964 = distinct !{!1964, !1965, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!1965 = distinct !{!1965, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!1966 = !{!1967}
!1967 = distinct !{!1967, !1968, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!1968 = distinct !{!1968, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!1969 = !{!1970}
!1970 = distinct !{!1970, !1971, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!1971 = distinct !{!1971, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!1972 = !{!1973}
!1973 = distinct !{!1973, !1974, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!1974 = distinct !{!1974, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!1975 = !{!1976}
!1976 = distinct !{!1976, !1977, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!1977 = distinct !{!1977, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!1978 = !{!1979}
!1979 = distinct !{!1979, !1980, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!1980 = distinct !{!1980, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!1981 = !{!1982}
!1982 = distinct !{!1982, !1983, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!1983 = distinct !{!1983, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!1984 = !{!1985}
!1985 = distinct !{!1985, !1986, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!1986 = distinct !{!1986, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!1987 = !{!1988}
!1988 = distinct !{!1988, !1989, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!1989 = distinct !{!1989, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!1990 = !{!1991}
!1991 = distinct !{!1991, !1992, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!1992 = distinct !{!1992, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!1993 = !{!1994}
!1994 = distinct !{!1994, !1995, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!1995 = distinct !{!1995, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!1996 = !{!1997}
!1997 = distinct !{!1997, !1998, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!1998 = distinct !{!1998, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!1999 = distinct !{!1999, !5}
!2000 = !{!2001}
!2001 = distinct !{!2001, !2002, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!2002 = distinct !{!2002, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!2003 = !{!2004}
!2004 = distinct !{!2004, !2005, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!2005 = distinct !{!2005, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!2006 = !{!2007}
!2007 = distinct !{!2007, !2008, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!2008 = distinct !{!2008, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!2009 = !{!2010}
!2010 = distinct !{!2010, !2011, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!2011 = distinct !{!2011, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!2012 = !{!2013}
!2013 = distinct !{!2013, !2014, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!2014 = distinct !{!2014, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!2015 = !{!2016}
!2016 = distinct !{!2016, !2017, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!2017 = distinct !{!2017, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!2018 = !{!2019}
!2019 = distinct !{!2019, !2020, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!2020 = distinct !{!2020, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
!2021 = !{!2022}
!2022 = distinct !{!2022, !2023, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor: argument 0"}
!2023 = distinct !{!2023, !"_ZN6tflite14GetTensorShapeEPK12TfLiteTensor"}
