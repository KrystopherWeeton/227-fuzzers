; ModuleID = '../../third_party/libgav1/src/src/dsp/x86/weight_mask_sse4.cc'
source_filename = "../../third_party/libgav1/src/src/dsp/x86/weight_mask_sse4.cc"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%"struct.libgav1::dsp::Dsp" = type { void (i8*, i8*, i32, i32, i8*, i64)*, void (i8*, i64, i8*, i32*)*, [2 x [3 x void (i16*, i64, i32, i32, i32, i32, i32, i8*, i64)*]], [19 x void (i8*, i64, [32 x i16]*, i32)*], [19 x [3 x void ([32 x i16]*, i32, i32, i8*, i64)*]], [2 x [2 x [2 x [2 x void (i8*, i64, i32, i32, i32, i32, i32, i32, i8*, i64)*]]]], [2 x void (i8*, i64, i32, i32, i32, i32, i32, i32, i32, i32, i8*, i64)*], void (i8*, i64, i8*, i32, i32, i32, i1)*, void (i8*, i64, i8*, i8*, i32, i32, i32, i32, i1, i1)*, void (i8*, i64, i8*, i32, i32, i32, i1)*, void (i8*, i8*, i8, i8, i32, i32, i8*, i64)*, %"struct.libgav1::dsp::FilmGrainFuncs", void (i8*, i64, i8*, i8*, i8, i32, i32)*, [3 x void (i8*, i8*, i64, i8*, i64, i32, i32)*], void (i8*, i32, i32)*, void (i8*, i32)*, [19 x [10 x void (i8*, i64, i8*, i8*)*]], [4 x [5 x [2 x void (i8, i8, i32, i8*, i32, i32, i8*)*]]], [4 x [2 x void (i8*, i64, i32, i32, i32)*]], [2 x void (%"struct.libgav1::RestorationUnitInfo"*, i8*, i64, i8*, i64, i8*, i64, i32, i32, %"union.libgav1::RestorationBuffer"*, i8*)*], [3 x [2 x void (i8*, i8*, i64, i8*, i64, i32, i32, i8*, i64)*]], void (%"struct.libgav1::ReferenceInfo"*, i32, i32, i32, i32, i32, i32, %"struct.libgav1::TemporalMotionField"*)*, [3 x void (%"struct.libgav1::MotionVector"*, i8*, i32*, i32, %"union.libgav1::CompoundMotionVector"*)*], [3 x void (%"struct.libgav1::MotionVector"*, i8*, i32, i32, %"struct.libgav1::MotionVector"*)*], [2 x void (i8*, i64, i32, i32, i8*, i64)*], void (i32, i32, i32, i8*)*, void (i8*, i8*, i64, i32, i32, i32, i32, i32, i8*, i64)*, void (i8*, i64, i32, i32, i32*, i32, i32, i32, i32, i32, i32, i16, i16, i16, i16, i8*, i64)*, void (i8*, i64, i32, i32, i32*, i32, i32, i32, i32, i32, i32, i16, i16, i16, i16, i8*, i64)*, [6 x [6 x [2 x void (i8*, i8*, i8*, i64)*]]] }
%"struct.libgav1::dsp::FilmGrainFuncs" = type { [3 x void (%"struct.libgav1::FilmGrainParams"*, i8*)*], [2 x [4 x void (%"struct.libgav1::FilmGrainParams"*, i8*, i32, i32, i8*, i8*)*]], [2 x void (i8*, i32, i32, i32, i32, i32, i8*)*], void (i8*, i32, i32, i32, i32, i8*)*, void (i32, i8*, i8*, i8*)*, void (i8*, i32, i32, i32, i32, i32, i32, i8*, i8*, i64, i8*, i64)*, [2 x void (i8, %"struct.libgav1::FilmGrainParams"*, i8*, i32, i32, i32, i32, i32, i32, i32, i8*, i8*, i64, i8*, i64, i8*, i64)*] }
%"struct.libgav1::FilmGrainParams" = type { i8, i8, i8, i8, i8, i8, i8, i8, [14 x i8], [14 x i8], [10 x i8], [10 x i8], [10 x i8], [10 x i8], i8, i8, [24 x i8], [25 x i8], [25 x i8], i8, i16, i32, i32, i8, i8, i16, i8, i8, i16 }
%"struct.libgav1::RestorationUnitInfo" = type { i8, %"struct.libgav1::SgrProjInfo", [16 x i8], %"struct.libgav1::WienerInfo" }
%"struct.libgav1::SgrProjInfo" = type { i32, [2 x i32] }
%"struct.libgav1::WienerInfo" = type { [2 x i16], [28 x i8], [2 x [4 x i16]], [16 x i8] }
%"union.libgav1::RestorationBuffer" = type { %"struct.libgav1::SgrBuffer", [5024 x i8] }
%"struct.libgav1::SgrBuffer" = type { [1152 x i16], [1440 x i16], [1152 x i32], [1440 x i32], [1024 x i16], [768 x i16], [512 x i16], [1024 x i32], [768 x i32], [512 x i32], [288 x i8], [288 x i32] }
%"struct.libgav1::ReferenceInfo" = type { %"struct.std::__1::array", %"struct.std::__1::array.0", %"struct.std::__1::array.0", %"struct.std::__1::array.1", %"struct.std::__1::array.2", %"class.libgav1::Array2D", %"class.libgav1::Array2D.4" }
%"struct.std::__1::array" = type { [8 x i8] }
%"struct.std::__1::array.0" = type { [8 x i8] }
%"struct.std::__1::array.1" = type { [8 x i8] }
%"struct.std::__1::array.2" = type { [8 x i16] }
%"class.libgav1::Array2D" = type { %"class.std::__1::unique_ptr", i64, i64, %"class.libgav1::Array2DView" }
%"class.std::__1::unique_ptr" = type { %"class.std::__1::__compressed_pair" }
%"class.std::__1::__compressed_pair" = type { %"struct.std::__1::__compressed_pair_elem" }
%"struct.std::__1::__compressed_pair_elem" = type { i8* }
%"class.libgav1::Array2DView" = type { i32, i32, i8* }
%"class.libgav1::Array2D.4" = type { %"class.std::__1::unique_ptr.5", i64, i64, %"class.libgav1::Array2DView.11" }
%"class.std::__1::unique_ptr.5" = type { %"class.std::__1::__compressed_pair.6" }
%"class.std::__1::__compressed_pair.6" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"struct.std::__1::__compressed_pair_elem.7" = type { %"struct.libgav1::MotionVector"* }
%"struct.libgav1::MotionVector" = type { %union.anon }
%union.anon = type { i32 }
%"class.libgav1::Array2DView.11" = type { i32, i32, %"struct.libgav1::MotionVector"* }
%"struct.libgav1::TemporalMotionField" = type { %"class.libgav1::Array2D.4", %"class.libgav1::Array2D.12" }
%"class.libgav1::Array2D.12" = type { %"class.std::__1::unique_ptr.13", i64, i64, %"class.libgav1::Array2DView.19" }
%"class.std::__1::unique_ptr.13" = type { %"class.std::__1::__compressed_pair.14" }
%"class.std::__1::__compressed_pair.14" = type { %"struct.std::__1::__compressed_pair_elem.15" }
%"struct.std::__1::__compressed_pair_elem.15" = type { i8* }
%"class.libgav1::Array2DView.19" = type { i32, i32, i8* }
%"union.libgav1::CompoundMotionVector" = type { i64 }

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN7libgav13dsp21WeightMaskInit_SSE4_1Ev() local_unnamed_addr #0 {
  %1 = tail call %"struct.libgav1::dsp::Dsp"* @_ZN7libgav112dsp_internal19GetWritableDspTableEi(i32 8) #5
  %2 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 29, i64 0, i64 0, i64 0
  %3 = bitcast void (i8*, i8*, i8*, i64)** %2 to <2 x void (i8*, i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i8*, i64)*> <void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_118WeightMask8x8_SSE4ILb0EEEvPKvS5_Phl, void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_118WeightMask8x8_SSE4ILb1EEEvPKvS5_Phl>, <2 x void (i8*, i8*, i8*, i64)*>* %3, align 8
  %4 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 29, i64 0, i64 1, i64 0
  %5 = bitcast void (i8*, i8*, i8*, i64)** %4 to <2 x void (i8*, i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i8*, i64)*> <void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_119WeightMask8x16_SSE4ILb0EEEvPKvS5_Phl, void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_119WeightMask8x16_SSE4ILb1EEEvPKvS5_Phl>, <2 x void (i8*, i8*, i8*, i64)*>* %5, align 8
  %6 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 29, i64 0, i64 2, i64 0
  %7 = bitcast void (i8*, i8*, i8*, i64)** %6 to <2 x void (i8*, i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i8*, i64)*> <void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_119WeightMask8x32_SSE4ILb0EEEvPKvS5_Phl, void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_119WeightMask8x32_SSE4ILb1EEEvPKvS5_Phl>, <2 x void (i8*, i8*, i8*, i64)*>* %7, align 8
  %8 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 29, i64 1, i64 0, i64 0
  %9 = bitcast void (i8*, i8*, i8*, i64)** %8 to <2 x void (i8*, i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i8*, i64)*> <void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_119WeightMask16x8_SSE4ILb0EEEvPKvS5_Phl, void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_119WeightMask16x8_SSE4ILb1EEEvPKvS5_Phl>, <2 x void (i8*, i8*, i8*, i64)*>* %9, align 8
  %10 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 29, i64 1, i64 1, i64 0
  %11 = bitcast void (i8*, i8*, i8*, i64)** %10 to <2 x void (i8*, i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i8*, i64)*> <void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask16x16_SSE4ILb0EEEvPKvS5_Phl, void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask16x16_SSE4ILb1EEEvPKvS5_Phl>, <2 x void (i8*, i8*, i8*, i64)*>* %11, align 8
  %12 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 29, i64 1, i64 2, i64 0
  %13 = bitcast void (i8*, i8*, i8*, i64)** %12 to <2 x void (i8*, i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i8*, i64)*> <void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask16x32_SSE4ILb0EEEvPKvS5_Phl, void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask16x32_SSE4ILb1EEEvPKvS5_Phl>, <2 x void (i8*, i8*, i8*, i64)*>* %13, align 8
  %14 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 29, i64 1, i64 3, i64 0
  %15 = bitcast void (i8*, i8*, i8*, i64)** %14 to <2 x void (i8*, i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i8*, i64)*> <void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask16x64_SSE4ILb0EEEvPKvS5_Phl, void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask16x64_SSE4ILb1EEEvPKvS5_Phl>, <2 x void (i8*, i8*, i8*, i64)*>* %15, align 8
  %16 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 29, i64 2, i64 0, i64 0
  %17 = bitcast void (i8*, i8*, i8*, i64)** %16 to <2 x void (i8*, i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i8*, i64)*> <void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_119WeightMask32x8_SSE4ILb0EEEvPKvS5_Phl, void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_119WeightMask32x8_SSE4ILb1EEEvPKvS5_Phl>, <2 x void (i8*, i8*, i8*, i64)*>* %17, align 8
  %18 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 29, i64 2, i64 1, i64 0
  %19 = bitcast void (i8*, i8*, i8*, i64)** %18 to <2 x void (i8*, i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i8*, i64)*> <void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask32x16_SSE4ILb0EEEvPKvS5_Phl, void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask32x16_SSE4ILb1EEEvPKvS5_Phl>, <2 x void (i8*, i8*, i8*, i64)*>* %19, align 8
  %20 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 29, i64 2, i64 2, i64 0
  %21 = bitcast void (i8*, i8*, i8*, i64)** %20 to <2 x void (i8*, i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i8*, i64)*> <void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask32x32_SSE4ILb0EEEvPKvS5_Phl, void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask32x32_SSE4ILb1EEEvPKvS5_Phl>, <2 x void (i8*, i8*, i8*, i64)*>* %21, align 8
  %22 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 29, i64 2, i64 3, i64 0
  %23 = bitcast void (i8*, i8*, i8*, i64)** %22 to <2 x void (i8*, i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i8*, i64)*> <void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask32x64_SSE4ILb0EEEvPKvS5_Phl, void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask32x64_SSE4ILb1EEEvPKvS5_Phl>, <2 x void (i8*, i8*, i8*, i64)*>* %23, align 8
  %24 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 29, i64 3, i64 1, i64 0
  %25 = bitcast void (i8*, i8*, i8*, i64)** %24 to <2 x void (i8*, i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i8*, i64)*> <void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask64x16_SSE4ILb0EEEvPKvS5_Phl, void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask64x16_SSE4ILb1EEEvPKvS5_Phl>, <2 x void (i8*, i8*, i8*, i64)*>* %25, align 8
  %26 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 29, i64 3, i64 2, i64 0
  %27 = bitcast void (i8*, i8*, i8*, i64)** %26 to <2 x void (i8*, i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i8*, i64)*> <void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask64x32_SSE4ILb0EEEvPKvS5_Phl, void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask64x32_SSE4ILb1EEEvPKvS5_Phl>, <2 x void (i8*, i8*, i8*, i64)*>* %27, align 8
  %28 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 29, i64 3, i64 3, i64 0
  %29 = bitcast void (i8*, i8*, i8*, i64)** %28 to <2 x void (i8*, i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i8*, i64)*> <void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask64x64_SSE4ILb0EEEvPKvS5_Phl, void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask64x64_SSE4ILb1EEEvPKvS5_Phl>, <2 x void (i8*, i8*, i8*, i64)*>* %29, align 8
  %30 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 29, i64 3, i64 4, i64 0
  %31 = bitcast void (i8*, i8*, i8*, i64)** %30 to <2 x void (i8*, i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i8*, i64)*> <void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_121WeightMask64x128_SSE4ILb0EEEvPKvS5_Phl, void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_121WeightMask64x128_SSE4ILb1EEEvPKvS5_Phl>, <2 x void (i8*, i8*, i8*, i64)*>* %31, align 8
  %32 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 29, i64 4, i64 3, i64 0
  %33 = bitcast void (i8*, i8*, i8*, i64)** %32 to <2 x void (i8*, i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i8*, i64)*> <void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_121WeightMask128x64_SSE4ILb0EEEvPKvS5_Phl, void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_121WeightMask128x64_SSE4ILb1EEEvPKvS5_Phl>, <2 x void (i8*, i8*, i8*, i64)*>* %33, align 8
  %34 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %1, i64 0, i32 29, i64 4, i64 4, i64 0
  %35 = bitcast void (i8*, i8*, i8*, i64)** %34 to <2 x void (i8*, i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i8*, i64)*> <void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_122WeightMask128x128_SSE4ILb0EEEvPKvS5_Phl, void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_122WeightMask128x128_SSE4ILb1EEEvPKvS5_Phl>, <2 x void (i8*, i8*, i8*, i64)*>* %35, align 8
  %36 = tail call %"struct.libgav1::dsp::Dsp"* @_ZN7libgav112dsp_internal19GetWritableDspTableEi(i32 10) #5
  %37 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %36, i64 0, i32 29, i64 0, i64 0, i64 0
  %38 = bitcast void (i8*, i8*, i8*, i64)** %37 to <2 x void (i8*, i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i8*, i64)*> <void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_124WeightMask8x8_10bpp_SSE4ILb0EEEvPKvS5_Phl, void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_124WeightMask8x8_10bpp_SSE4ILb1EEEvPKvS5_Phl>, <2 x void (i8*, i8*, i8*, i64)*>* %38, align 8
  %39 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %36, i64 0, i32 29, i64 0, i64 1, i64 0
  %40 = bitcast void (i8*, i8*, i8*, i64)** %39 to <2 x void (i8*, i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i8*, i64)*> <void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_125WeightMask8x16_10bpp_SSE4ILb0EEEvPKvS5_Phl, void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_125WeightMask8x16_10bpp_SSE4ILb1EEEvPKvS5_Phl>, <2 x void (i8*, i8*, i8*, i64)*>* %40, align 8
  %41 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %36, i64 0, i32 29, i64 0, i64 2, i64 0
  %42 = bitcast void (i8*, i8*, i8*, i64)** %41 to <2 x void (i8*, i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i8*, i64)*> <void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_125WeightMask8x32_10bpp_SSE4ILb0EEEvPKvS5_Phl, void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_125WeightMask8x32_10bpp_SSE4ILb1EEEvPKvS5_Phl>, <2 x void (i8*, i8*, i8*, i64)*>* %42, align 8
  %43 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %36, i64 0, i32 29, i64 1, i64 0, i64 0
  %44 = bitcast void (i8*, i8*, i8*, i64)** %43 to <2 x void (i8*, i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i8*, i64)*> <void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_125WeightMask16x8_10bpp_SSE4ILb0EEEvPKvS5_Phl, void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_125WeightMask16x8_10bpp_SSE4ILb1EEEvPKvS5_Phl>, <2 x void (i8*, i8*, i8*, i64)*>* %44, align 8
  %45 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %36, i64 0, i32 29, i64 1, i64 1, i64 0
  %46 = bitcast void (i8*, i8*, i8*, i64)** %45 to <2 x void (i8*, i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i8*, i64)*> <void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask16x16_10bpp_SSE4ILb0EEEvPKvS5_Phl, void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask16x16_10bpp_SSE4ILb1EEEvPKvS5_Phl>, <2 x void (i8*, i8*, i8*, i64)*>* %46, align 8
  %47 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %36, i64 0, i32 29, i64 1, i64 2, i64 0
  %48 = bitcast void (i8*, i8*, i8*, i64)** %47 to <2 x void (i8*, i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i8*, i64)*> <void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask16x32_10bpp_SSE4ILb0EEEvPKvS5_Phl, void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask16x32_10bpp_SSE4ILb1EEEvPKvS5_Phl>, <2 x void (i8*, i8*, i8*, i64)*>* %48, align 8
  %49 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %36, i64 0, i32 29, i64 1, i64 3, i64 0
  %50 = bitcast void (i8*, i8*, i8*, i64)** %49 to <2 x void (i8*, i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i8*, i64)*> <void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask16x64_10bpp_SSE4ILb0EEEvPKvS5_Phl, void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask16x64_10bpp_SSE4ILb1EEEvPKvS5_Phl>, <2 x void (i8*, i8*, i8*, i64)*>* %50, align 8
  %51 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %36, i64 0, i32 29, i64 2, i64 0, i64 0
  %52 = bitcast void (i8*, i8*, i8*, i64)** %51 to <2 x void (i8*, i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i8*, i64)*> <void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_125WeightMask32x8_10bpp_SSE4ILb0EEEvPKvS5_Phl, void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_125WeightMask32x8_10bpp_SSE4ILb1EEEvPKvS5_Phl>, <2 x void (i8*, i8*, i8*, i64)*>* %52, align 8
  %53 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %36, i64 0, i32 29, i64 2, i64 1, i64 0
  %54 = bitcast void (i8*, i8*, i8*, i64)** %53 to <2 x void (i8*, i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i8*, i64)*> <void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask32x16_10bpp_SSE4ILb0EEEvPKvS5_Phl, void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask32x16_10bpp_SSE4ILb1EEEvPKvS5_Phl>, <2 x void (i8*, i8*, i8*, i64)*>* %54, align 8
  %55 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %36, i64 0, i32 29, i64 2, i64 2, i64 0
  %56 = bitcast void (i8*, i8*, i8*, i64)** %55 to <2 x void (i8*, i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i8*, i64)*> <void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask32x32_10bpp_SSE4ILb0EEEvPKvS5_Phl, void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask32x32_10bpp_SSE4ILb1EEEvPKvS5_Phl>, <2 x void (i8*, i8*, i8*, i64)*>* %56, align 8
  %57 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %36, i64 0, i32 29, i64 2, i64 3, i64 0
  %58 = bitcast void (i8*, i8*, i8*, i64)** %57 to <2 x void (i8*, i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i8*, i64)*> <void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask32x64_10bpp_SSE4ILb0EEEvPKvS5_Phl, void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask32x64_10bpp_SSE4ILb1EEEvPKvS5_Phl>, <2 x void (i8*, i8*, i8*, i64)*>* %58, align 8
  %59 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %36, i64 0, i32 29, i64 3, i64 1, i64 0
  %60 = bitcast void (i8*, i8*, i8*, i64)** %59 to <2 x void (i8*, i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i8*, i64)*> <void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask64x16_10bpp_SSE4ILb0EEEvPKvS5_Phl, void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask64x16_10bpp_SSE4ILb1EEEvPKvS5_Phl>, <2 x void (i8*, i8*, i8*, i64)*>* %60, align 8
  %61 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %36, i64 0, i32 29, i64 3, i64 2, i64 0
  %62 = bitcast void (i8*, i8*, i8*, i64)** %61 to <2 x void (i8*, i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i8*, i64)*> <void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask64x32_10bpp_SSE4ILb0EEEvPKvS5_Phl, void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask64x32_10bpp_SSE4ILb1EEEvPKvS5_Phl>, <2 x void (i8*, i8*, i8*, i64)*>* %62, align 8
  %63 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %36, i64 0, i32 29, i64 3, i64 3, i64 0
  %64 = bitcast void (i8*, i8*, i8*, i64)** %63 to <2 x void (i8*, i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i8*, i64)*> <void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask64x64_10bpp_SSE4ILb0EEEvPKvS5_Phl, void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask64x64_10bpp_SSE4ILb1EEEvPKvS5_Phl>, <2 x void (i8*, i8*, i8*, i64)*>* %64, align 8
  %65 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %36, i64 0, i32 29, i64 3, i64 4, i64 0
  %66 = bitcast void (i8*, i8*, i8*, i64)** %65 to <2 x void (i8*, i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i8*, i64)*> <void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_127WeightMask64x128_10bpp_SSE4ILb0EEEvPKvS5_Phl, void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_127WeightMask64x128_10bpp_SSE4ILb1EEEvPKvS5_Phl>, <2 x void (i8*, i8*, i8*, i64)*>* %66, align 8
  %67 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %36, i64 0, i32 29, i64 4, i64 3, i64 0
  %68 = bitcast void (i8*, i8*, i8*, i64)** %67 to <2 x void (i8*, i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i8*, i64)*> <void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_127WeightMask128x64_10bpp_SSE4ILb0EEEvPKvS5_Phl, void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_127WeightMask128x64_10bpp_SSE4ILb1EEEvPKvS5_Phl>, <2 x void (i8*, i8*, i8*, i64)*>* %68, align 8
  %69 = getelementptr inbounds %"struct.libgav1::dsp::Dsp", %"struct.libgav1::dsp::Dsp"* %36, i64 0, i32 29, i64 4, i64 4, i64 0
  %70 = bitcast void (i8*, i8*, i8*, i64)** %69 to <2 x void (i8*, i8*, i8*, i64)*>*
  store <2 x void (i8*, i8*, i8*, i64)*> <void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_128WeightMask128x128_10bpp_SSE4ILb0EEEvPKvS5_Phl, void (i8*, i8*, i8*, i64)* @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_128WeightMask128x128_10bpp_SSE4ILb1EEEvPKvS5_Phl>, <2 x void (i8*, i8*, i8*, i64)*>* %70, align 8
  ret void
}

declare %"struct.libgav1::dsp::Dsp"* @_ZN7libgav112dsp_internal19GetWritableDspTableEi(i32) local_unnamed_addr #1

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_118WeightMask8x8_SSE4ILb0EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to <8 x i16>*
  %6 = load <8 x i16>, <8 x i16>* %5, align 16
  %7 = bitcast i8* %1 to <8 x i16>*
  %8 = load <8 x i16>, <8 x i16>* %7, align 16
  %9 = sub <8 x i16> %6, %8
  %10 = sub <8 x i16> zeroinitializer, %9
  %11 = icmp slt <8 x i16> %9, zeroinitializer
  %12 = select <8 x i1> %11, <8 x i16> %10, <8 x i16> %9
  %13 = lshr <8 x i16> %12, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %14 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %13, <8 x i16> zeroinitializer) #5
  %15 = lshr <8 x i16> %14, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %16 = getelementptr inbounds i8, i8* %0, i64 16
  %17 = bitcast i8* %16 to <8 x i16>*
  %18 = load <8 x i16>, <8 x i16>* %17, align 16
  %19 = getelementptr inbounds i8, i8* %1, i64 16
  %20 = bitcast i8* %19 to <8 x i16>*
  %21 = load <8 x i16>, <8 x i16>* %20, align 16
  %22 = sub <8 x i16> %18, %21
  %23 = sub <8 x i16> zeroinitializer, %22
  %24 = icmp slt <8 x i16> %22, zeroinitializer
  %25 = select <8 x i1> %24, <8 x i16> %23, <8 x i16> %22
  %26 = lshr <8 x i16> %25, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %27 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %26, <8 x i16> zeroinitializer) #5
  %28 = lshr <8 x i16> %27, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %29 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %15, <8 x i16> %28) #5
  %30 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %29, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %31 = icmp slt <16 x i8> %30, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %32 = select <16 x i1> %31, <16 x i8> %30, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %33 = bitcast <16 x i8> %32 to <2 x i64>
  %34 = extractelement <2 x i64> %33, i32 0
  %35 = bitcast i8* %2 to i64*
  store i64 %34, i64* %35, align 1
  %36 = getelementptr inbounds i8, i8* %2, i64 %3
  %37 = bitcast <16 x i8> %32 to <4 x float>
  %38 = shufflevector <4 x float> %37, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %39 = bitcast i8* %36 to <2 x float>*
  store <2 x float> %38, <2 x float>* %39, align 1
  %40 = getelementptr inbounds i8, i8* %0, i64 32
  %41 = getelementptr inbounds i8, i8* %1, i64 32
  %42 = shl i64 %3, 1
  %43 = getelementptr inbounds i8, i8* %2, i64 %42
  %44 = bitcast i8* %40 to <8 x i16>*
  %45 = load <8 x i16>, <8 x i16>* %44, align 16
  %46 = bitcast i8* %41 to <8 x i16>*
  %47 = load <8 x i16>, <8 x i16>* %46, align 16
  %48 = sub <8 x i16> %45, %47
  %49 = sub <8 x i16> zeroinitializer, %48
  %50 = icmp slt <8 x i16> %48, zeroinitializer
  %51 = select <8 x i1> %50, <8 x i16> %49, <8 x i16> %48
  %52 = lshr <8 x i16> %51, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %53 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %52, <8 x i16> zeroinitializer) #5
  %54 = lshr <8 x i16> %53, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %55 = getelementptr inbounds i8, i8* %0, i64 48
  %56 = bitcast i8* %55 to <8 x i16>*
  %57 = load <8 x i16>, <8 x i16>* %56, align 16
  %58 = getelementptr inbounds i8, i8* %1, i64 48
  %59 = bitcast i8* %58 to <8 x i16>*
  %60 = load <8 x i16>, <8 x i16>* %59, align 16
  %61 = sub <8 x i16> %57, %60
  %62 = sub <8 x i16> zeroinitializer, %61
  %63 = icmp slt <8 x i16> %61, zeroinitializer
  %64 = select <8 x i1> %63, <8 x i16> %62, <8 x i16> %61
  %65 = lshr <8 x i16> %64, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %66 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %65, <8 x i16> zeroinitializer) #5
  %67 = lshr <8 x i16> %66, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %68 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %54, <8 x i16> %67) #5
  %69 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %68, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %70 = icmp slt <16 x i8> %69, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %71 = select <16 x i1> %70, <16 x i8> %69, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %72 = bitcast <16 x i8> %71 to <2 x i64>
  %73 = extractelement <2 x i64> %72, i32 0
  %74 = bitcast i8* %43 to i64*
  store i64 %73, i64* %74, align 1
  %75 = getelementptr inbounds i8, i8* %43, i64 %3
  %76 = bitcast <16 x i8> %71 to <4 x float>
  %77 = shufflevector <4 x float> %76, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %78 = bitcast i8* %75 to <2 x float>*
  store <2 x float> %77, <2 x float>* %78, align 1
  %79 = getelementptr inbounds i8, i8* %0, i64 64
  %80 = getelementptr inbounds i8, i8* %1, i64 64
  %81 = getelementptr inbounds i8, i8* %43, i64 %42
  %82 = bitcast i8* %79 to <8 x i16>*
  %83 = load <8 x i16>, <8 x i16>* %82, align 16
  %84 = bitcast i8* %80 to <8 x i16>*
  %85 = load <8 x i16>, <8 x i16>* %84, align 16
  %86 = sub <8 x i16> %83, %85
  %87 = sub <8 x i16> zeroinitializer, %86
  %88 = icmp slt <8 x i16> %86, zeroinitializer
  %89 = select <8 x i1> %88, <8 x i16> %87, <8 x i16> %86
  %90 = lshr <8 x i16> %89, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %91 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %90, <8 x i16> zeroinitializer) #5
  %92 = lshr <8 x i16> %91, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %93 = getelementptr inbounds i8, i8* %0, i64 80
  %94 = bitcast i8* %93 to <8 x i16>*
  %95 = load <8 x i16>, <8 x i16>* %94, align 16
  %96 = getelementptr inbounds i8, i8* %1, i64 80
  %97 = bitcast i8* %96 to <8 x i16>*
  %98 = load <8 x i16>, <8 x i16>* %97, align 16
  %99 = sub <8 x i16> %95, %98
  %100 = sub <8 x i16> zeroinitializer, %99
  %101 = icmp slt <8 x i16> %99, zeroinitializer
  %102 = select <8 x i1> %101, <8 x i16> %100, <8 x i16> %99
  %103 = lshr <8 x i16> %102, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %104 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %103, <8 x i16> zeroinitializer) #5
  %105 = lshr <8 x i16> %104, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %106 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %92, <8 x i16> %105) #5
  %107 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %106, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %108 = icmp slt <16 x i8> %107, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %109 = select <16 x i1> %108, <16 x i8> %107, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %110 = bitcast <16 x i8> %109 to <2 x i64>
  %111 = extractelement <2 x i64> %110, i32 0
  %112 = bitcast i8* %81 to i64*
  store i64 %111, i64* %112, align 1
  %113 = getelementptr inbounds i8, i8* %81, i64 %3
  %114 = bitcast <16 x i8> %109 to <4 x float>
  %115 = shufflevector <4 x float> %114, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %116 = bitcast i8* %113 to <2 x float>*
  store <2 x float> %115, <2 x float>* %116, align 1
  %117 = getelementptr inbounds i8, i8* %0, i64 96
  %118 = getelementptr inbounds i8, i8* %1, i64 96
  %119 = getelementptr inbounds i8, i8* %81, i64 %42
  %120 = bitcast i8* %117 to <8 x i16>*
  %121 = load <8 x i16>, <8 x i16>* %120, align 16
  %122 = bitcast i8* %118 to <8 x i16>*
  %123 = load <8 x i16>, <8 x i16>* %122, align 16
  %124 = sub <8 x i16> %121, %123
  %125 = sub <8 x i16> zeroinitializer, %124
  %126 = icmp slt <8 x i16> %124, zeroinitializer
  %127 = select <8 x i1> %126, <8 x i16> %125, <8 x i16> %124
  %128 = lshr <8 x i16> %127, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %129 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %128, <8 x i16> zeroinitializer) #5
  %130 = lshr <8 x i16> %129, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %131 = getelementptr inbounds i8, i8* %0, i64 112
  %132 = bitcast i8* %131 to <8 x i16>*
  %133 = load <8 x i16>, <8 x i16>* %132, align 16
  %134 = getelementptr inbounds i8, i8* %1, i64 112
  %135 = bitcast i8* %134 to <8 x i16>*
  %136 = load <8 x i16>, <8 x i16>* %135, align 16
  %137 = sub <8 x i16> %133, %136
  %138 = sub <8 x i16> zeroinitializer, %137
  %139 = icmp slt <8 x i16> %137, zeroinitializer
  %140 = select <8 x i1> %139, <8 x i16> %138, <8 x i16> %137
  %141 = lshr <8 x i16> %140, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %142 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %141, <8 x i16> zeroinitializer) #5
  %143 = lshr <8 x i16> %142, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %144 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %130, <8 x i16> %143) #5
  %145 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %144, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %146 = icmp slt <16 x i8> %145, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %147 = select <16 x i1> %146, <16 x i8> %145, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %148 = bitcast <16 x i8> %147 to <2 x i64>
  %149 = extractelement <2 x i64> %148, i32 0
  %150 = bitcast i8* %119 to i64*
  store i64 %149, i64* %150, align 1
  %151 = getelementptr inbounds i8, i8* %119, i64 %3
  %152 = bitcast <16 x i8> %147 to <4 x float>
  %153 = shufflevector <4 x float> %152, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %154 = bitcast i8* %151 to <2 x float>*
  store <2 x float> %153, <2 x float>* %154, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_118WeightMask8x8_SSE4ILb1EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to <8 x i16>*
  %6 = load <8 x i16>, <8 x i16>* %5, align 16
  %7 = bitcast i8* %1 to <8 x i16>*
  %8 = load <8 x i16>, <8 x i16>* %7, align 16
  %9 = sub <8 x i16> %6, %8
  %10 = sub <8 x i16> zeroinitializer, %9
  %11 = icmp slt <8 x i16> %9, zeroinitializer
  %12 = select <8 x i1> %11, <8 x i16> %10, <8 x i16> %9
  %13 = lshr <8 x i16> %12, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %14 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %13, <8 x i16> zeroinitializer) #5
  %15 = lshr <8 x i16> %14, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %16 = getelementptr inbounds i8, i8* %0, i64 16
  %17 = bitcast i8* %16 to <8 x i16>*
  %18 = load <8 x i16>, <8 x i16>* %17, align 16
  %19 = getelementptr inbounds i8, i8* %1, i64 16
  %20 = bitcast i8* %19 to <8 x i16>*
  %21 = load <8 x i16>, <8 x i16>* %20, align 16
  %22 = sub <8 x i16> %18, %21
  %23 = sub <8 x i16> zeroinitializer, %22
  %24 = icmp slt <8 x i16> %22, zeroinitializer
  %25 = select <8 x i1> %24, <8 x i16> %23, <8 x i16> %22
  %26 = lshr <8 x i16> %25, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %27 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %26, <8 x i16> zeroinitializer) #5
  %28 = lshr <8 x i16> %27, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %29 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %15, <8 x i16> %28) #5
  %30 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %29, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %31 = icmp slt <16 x i8> %30, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %32 = select <16 x i1> %31, <16 x i8> %30, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %33 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %32
  %34 = bitcast <16 x i8> %33 to <2 x i64>
  %35 = extractelement <2 x i64> %34, i32 0
  %36 = bitcast i8* %2 to i64*
  store i64 %35, i64* %36, align 1
  %37 = getelementptr inbounds i8, i8* %2, i64 %3
  %38 = bitcast <16 x i8> %33 to <4 x float>
  %39 = shufflevector <4 x float> %38, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %40 = bitcast i8* %37 to <2 x float>*
  store <2 x float> %39, <2 x float>* %40, align 1
  %41 = getelementptr inbounds i8, i8* %0, i64 32
  %42 = getelementptr inbounds i8, i8* %1, i64 32
  %43 = shl i64 %3, 1
  %44 = getelementptr inbounds i8, i8* %2, i64 %43
  %45 = bitcast i8* %41 to <8 x i16>*
  %46 = load <8 x i16>, <8 x i16>* %45, align 16
  %47 = bitcast i8* %42 to <8 x i16>*
  %48 = load <8 x i16>, <8 x i16>* %47, align 16
  %49 = sub <8 x i16> %46, %48
  %50 = sub <8 x i16> zeroinitializer, %49
  %51 = icmp slt <8 x i16> %49, zeroinitializer
  %52 = select <8 x i1> %51, <8 x i16> %50, <8 x i16> %49
  %53 = lshr <8 x i16> %52, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %54 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %53, <8 x i16> zeroinitializer) #5
  %55 = lshr <8 x i16> %54, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %56 = getelementptr inbounds i8, i8* %0, i64 48
  %57 = bitcast i8* %56 to <8 x i16>*
  %58 = load <8 x i16>, <8 x i16>* %57, align 16
  %59 = getelementptr inbounds i8, i8* %1, i64 48
  %60 = bitcast i8* %59 to <8 x i16>*
  %61 = load <8 x i16>, <8 x i16>* %60, align 16
  %62 = sub <8 x i16> %58, %61
  %63 = sub <8 x i16> zeroinitializer, %62
  %64 = icmp slt <8 x i16> %62, zeroinitializer
  %65 = select <8 x i1> %64, <8 x i16> %63, <8 x i16> %62
  %66 = lshr <8 x i16> %65, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %67 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %66, <8 x i16> zeroinitializer) #5
  %68 = lshr <8 x i16> %67, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %69 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %55, <8 x i16> %68) #5
  %70 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %69, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %71 = icmp slt <16 x i8> %70, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %72 = select <16 x i1> %71, <16 x i8> %70, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %73 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %72
  %74 = bitcast <16 x i8> %73 to <2 x i64>
  %75 = extractelement <2 x i64> %74, i32 0
  %76 = bitcast i8* %44 to i64*
  store i64 %75, i64* %76, align 1
  %77 = getelementptr inbounds i8, i8* %44, i64 %3
  %78 = bitcast <16 x i8> %73 to <4 x float>
  %79 = shufflevector <4 x float> %78, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %80 = bitcast i8* %77 to <2 x float>*
  store <2 x float> %79, <2 x float>* %80, align 1
  %81 = getelementptr inbounds i8, i8* %0, i64 64
  %82 = getelementptr inbounds i8, i8* %1, i64 64
  %83 = getelementptr inbounds i8, i8* %44, i64 %43
  %84 = bitcast i8* %81 to <8 x i16>*
  %85 = load <8 x i16>, <8 x i16>* %84, align 16
  %86 = bitcast i8* %82 to <8 x i16>*
  %87 = load <8 x i16>, <8 x i16>* %86, align 16
  %88 = sub <8 x i16> %85, %87
  %89 = sub <8 x i16> zeroinitializer, %88
  %90 = icmp slt <8 x i16> %88, zeroinitializer
  %91 = select <8 x i1> %90, <8 x i16> %89, <8 x i16> %88
  %92 = lshr <8 x i16> %91, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %93 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %92, <8 x i16> zeroinitializer) #5
  %94 = lshr <8 x i16> %93, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %95 = getelementptr inbounds i8, i8* %0, i64 80
  %96 = bitcast i8* %95 to <8 x i16>*
  %97 = load <8 x i16>, <8 x i16>* %96, align 16
  %98 = getelementptr inbounds i8, i8* %1, i64 80
  %99 = bitcast i8* %98 to <8 x i16>*
  %100 = load <8 x i16>, <8 x i16>* %99, align 16
  %101 = sub <8 x i16> %97, %100
  %102 = sub <8 x i16> zeroinitializer, %101
  %103 = icmp slt <8 x i16> %101, zeroinitializer
  %104 = select <8 x i1> %103, <8 x i16> %102, <8 x i16> %101
  %105 = lshr <8 x i16> %104, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %106 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %105, <8 x i16> zeroinitializer) #5
  %107 = lshr <8 x i16> %106, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %108 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %94, <8 x i16> %107) #5
  %109 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %108, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %110 = icmp slt <16 x i8> %109, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %111 = select <16 x i1> %110, <16 x i8> %109, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %112 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %111
  %113 = bitcast <16 x i8> %112 to <2 x i64>
  %114 = extractelement <2 x i64> %113, i32 0
  %115 = bitcast i8* %83 to i64*
  store i64 %114, i64* %115, align 1
  %116 = getelementptr inbounds i8, i8* %83, i64 %3
  %117 = bitcast <16 x i8> %112 to <4 x float>
  %118 = shufflevector <4 x float> %117, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %119 = bitcast i8* %116 to <2 x float>*
  store <2 x float> %118, <2 x float>* %119, align 1
  %120 = getelementptr inbounds i8, i8* %0, i64 96
  %121 = getelementptr inbounds i8, i8* %1, i64 96
  %122 = getelementptr inbounds i8, i8* %83, i64 %43
  %123 = bitcast i8* %120 to <8 x i16>*
  %124 = load <8 x i16>, <8 x i16>* %123, align 16
  %125 = bitcast i8* %121 to <8 x i16>*
  %126 = load <8 x i16>, <8 x i16>* %125, align 16
  %127 = sub <8 x i16> %124, %126
  %128 = sub <8 x i16> zeroinitializer, %127
  %129 = icmp slt <8 x i16> %127, zeroinitializer
  %130 = select <8 x i1> %129, <8 x i16> %128, <8 x i16> %127
  %131 = lshr <8 x i16> %130, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %132 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %131, <8 x i16> zeroinitializer) #5
  %133 = lshr <8 x i16> %132, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %134 = getelementptr inbounds i8, i8* %0, i64 112
  %135 = bitcast i8* %134 to <8 x i16>*
  %136 = load <8 x i16>, <8 x i16>* %135, align 16
  %137 = getelementptr inbounds i8, i8* %1, i64 112
  %138 = bitcast i8* %137 to <8 x i16>*
  %139 = load <8 x i16>, <8 x i16>* %138, align 16
  %140 = sub <8 x i16> %136, %139
  %141 = sub <8 x i16> zeroinitializer, %140
  %142 = icmp slt <8 x i16> %140, zeroinitializer
  %143 = select <8 x i1> %142, <8 x i16> %141, <8 x i16> %140
  %144 = lshr <8 x i16> %143, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %145 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %144, <8 x i16> zeroinitializer) #5
  %146 = lshr <8 x i16> %145, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %147 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %133, <8 x i16> %146) #5
  %148 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %147, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %149 = icmp slt <16 x i8> %148, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %150 = select <16 x i1> %149, <16 x i8> %148, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %151 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %150
  %152 = bitcast <16 x i8> %151 to <2 x i64>
  %153 = extractelement <2 x i64> %152, i32 0
  %154 = bitcast i8* %122 to i64*
  store i64 %153, i64* %154, align 1
  %155 = getelementptr inbounds i8, i8* %122, i64 %3
  %156 = bitcast <16 x i8> %151 to <4 x float>
  %157 = shufflevector <4 x float> %156, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %158 = bitcast i8* %155 to <2 x float>*
  store <2 x float> %157, <2 x float>* %158, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_119WeightMask8x16_SSE4ILb0EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  %7 = shl i64 %3, 1
  br label %8

8:                                                ; preds = %8, %4
  %9 = phi i8* [ %2, %4 ], [ %88, %8 ]
  %10 = phi i16* [ %5, %4 ], [ %86, %8 ]
  %11 = phi i16* [ %6, %4 ], [ %87, %8 ]
  %12 = phi i32 [ 3, %4 ], [ %89, %8 ]
  %13 = bitcast i16* %10 to <8 x i16>*
  %14 = load <8 x i16>, <8 x i16>* %13, align 16
  %15 = bitcast i16* %11 to <8 x i16>*
  %16 = load <8 x i16>, <8 x i16>* %15, align 16
  %17 = sub <8 x i16> %14, %16
  %18 = sub <8 x i16> zeroinitializer, %17
  %19 = icmp slt <8 x i16> %17, zeroinitializer
  %20 = select <8 x i1> %19, <8 x i16> %18, <8 x i16> %17
  %21 = lshr <8 x i16> %20, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %22 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %21, <8 x i16> zeroinitializer) #5
  %23 = lshr <8 x i16> %22, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %24 = getelementptr inbounds i16, i16* %10, i64 8
  %25 = bitcast i16* %24 to <8 x i16>*
  %26 = load <8 x i16>, <8 x i16>* %25, align 16
  %27 = getelementptr inbounds i16, i16* %11, i64 8
  %28 = bitcast i16* %27 to <8 x i16>*
  %29 = load <8 x i16>, <8 x i16>* %28, align 16
  %30 = sub <8 x i16> %26, %29
  %31 = sub <8 x i16> zeroinitializer, %30
  %32 = icmp slt <8 x i16> %30, zeroinitializer
  %33 = select <8 x i1> %32, <8 x i16> %31, <8 x i16> %30
  %34 = lshr <8 x i16> %33, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %35 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %34, <8 x i16> zeroinitializer) #5
  %36 = lshr <8 x i16> %35, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %37 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %23, <8 x i16> %36) #5
  %38 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %37, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %39 = icmp slt <16 x i8> %38, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %40 = select <16 x i1> %39, <16 x i8> %38, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %41 = bitcast <16 x i8> %40 to <2 x i64>
  %42 = extractelement <2 x i64> %41, i32 0
  %43 = bitcast i8* %9 to i64*
  store i64 %42, i64* %43, align 1
  %44 = getelementptr inbounds i8, i8* %9, i64 %3
  %45 = bitcast <16 x i8> %40 to <4 x float>
  %46 = shufflevector <4 x float> %45, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %47 = bitcast i8* %44 to <2 x float>*
  store <2 x float> %46, <2 x float>* %47, align 1
  %48 = getelementptr inbounds i16, i16* %10, i64 16
  %49 = getelementptr inbounds i16, i16* %11, i64 16
  %50 = getelementptr inbounds i8, i8* %9, i64 %7
  %51 = bitcast i16* %48 to <8 x i16>*
  %52 = load <8 x i16>, <8 x i16>* %51, align 16
  %53 = bitcast i16* %49 to <8 x i16>*
  %54 = load <8 x i16>, <8 x i16>* %53, align 16
  %55 = sub <8 x i16> %52, %54
  %56 = sub <8 x i16> zeroinitializer, %55
  %57 = icmp slt <8 x i16> %55, zeroinitializer
  %58 = select <8 x i1> %57, <8 x i16> %56, <8 x i16> %55
  %59 = lshr <8 x i16> %58, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %60 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %59, <8 x i16> zeroinitializer) #5
  %61 = lshr <8 x i16> %60, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %62 = getelementptr inbounds i16, i16* %10, i64 24
  %63 = bitcast i16* %62 to <8 x i16>*
  %64 = load <8 x i16>, <8 x i16>* %63, align 16
  %65 = getelementptr inbounds i16, i16* %11, i64 24
  %66 = bitcast i16* %65 to <8 x i16>*
  %67 = load <8 x i16>, <8 x i16>* %66, align 16
  %68 = sub <8 x i16> %64, %67
  %69 = sub <8 x i16> zeroinitializer, %68
  %70 = icmp slt <8 x i16> %68, zeroinitializer
  %71 = select <8 x i1> %70, <8 x i16> %69, <8 x i16> %68
  %72 = lshr <8 x i16> %71, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %73 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %72, <8 x i16> zeroinitializer) #5
  %74 = lshr <8 x i16> %73, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %75 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %61, <8 x i16> %74) #5
  %76 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %75, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %77 = icmp slt <16 x i8> %76, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %78 = select <16 x i1> %77, <16 x i8> %76, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %79 = bitcast <16 x i8> %78 to <2 x i64>
  %80 = extractelement <2 x i64> %79, i32 0
  %81 = bitcast i8* %50 to i64*
  store i64 %80, i64* %81, align 1
  %82 = getelementptr inbounds i8, i8* %50, i64 %3
  %83 = bitcast <16 x i8> %78 to <4 x float>
  %84 = shufflevector <4 x float> %83, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %85 = bitcast i8* %82 to <2 x float>*
  store <2 x float> %84, <2 x float>* %85, align 1
  %86 = getelementptr inbounds i16, i16* %10, i64 32
  %87 = getelementptr inbounds i16, i16* %11, i64 32
  %88 = getelementptr inbounds i8, i8* %50, i64 %7
  %89 = add nsw i32 %12, -1
  %90 = icmp eq i32 %89, 0
  br i1 %90, label %91, label %8

91:                                               ; preds = %8
  %92 = bitcast i16* %86 to <8 x i16>*
  %93 = load <8 x i16>, <8 x i16>* %92, align 16
  %94 = bitcast i16* %87 to <8 x i16>*
  %95 = load <8 x i16>, <8 x i16>* %94, align 16
  %96 = sub <8 x i16> %93, %95
  %97 = sub <8 x i16> zeroinitializer, %96
  %98 = icmp slt <8 x i16> %96, zeroinitializer
  %99 = select <8 x i1> %98, <8 x i16> %97, <8 x i16> %96
  %100 = lshr <8 x i16> %99, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %101 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %100, <8 x i16> zeroinitializer) #5
  %102 = lshr <8 x i16> %101, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %103 = getelementptr inbounds i16, i16* %10, i64 40
  %104 = bitcast i16* %103 to <8 x i16>*
  %105 = load <8 x i16>, <8 x i16>* %104, align 16
  %106 = getelementptr inbounds i16, i16* %11, i64 40
  %107 = bitcast i16* %106 to <8 x i16>*
  %108 = load <8 x i16>, <8 x i16>* %107, align 16
  %109 = sub <8 x i16> %105, %108
  %110 = sub <8 x i16> zeroinitializer, %109
  %111 = icmp slt <8 x i16> %109, zeroinitializer
  %112 = select <8 x i1> %111, <8 x i16> %110, <8 x i16> %109
  %113 = lshr <8 x i16> %112, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %114 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %113, <8 x i16> zeroinitializer) #5
  %115 = lshr <8 x i16> %114, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %116 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %102, <8 x i16> %115) #5
  %117 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %116, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %118 = icmp slt <16 x i8> %117, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %119 = select <16 x i1> %118, <16 x i8> %117, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %120 = bitcast <16 x i8> %119 to <2 x i64>
  %121 = extractelement <2 x i64> %120, i32 0
  %122 = bitcast i8* %88 to i64*
  store i64 %121, i64* %122, align 1
  %123 = getelementptr inbounds i8, i8* %88, i64 %3
  %124 = bitcast <16 x i8> %119 to <4 x float>
  %125 = shufflevector <4 x float> %124, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %126 = bitcast i8* %123 to <2 x float>*
  store <2 x float> %125, <2 x float>* %126, align 1
  %127 = getelementptr inbounds i16, i16* %10, i64 48
  %128 = getelementptr inbounds i16, i16* %11, i64 48
  %129 = getelementptr inbounds i8, i8* %88, i64 %7
  %130 = bitcast i16* %127 to <8 x i16>*
  %131 = load <8 x i16>, <8 x i16>* %130, align 16
  %132 = bitcast i16* %128 to <8 x i16>*
  %133 = load <8 x i16>, <8 x i16>* %132, align 16
  %134 = sub <8 x i16> %131, %133
  %135 = sub <8 x i16> zeroinitializer, %134
  %136 = icmp slt <8 x i16> %134, zeroinitializer
  %137 = select <8 x i1> %136, <8 x i16> %135, <8 x i16> %134
  %138 = lshr <8 x i16> %137, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %139 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %138, <8 x i16> zeroinitializer) #5
  %140 = lshr <8 x i16> %139, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %141 = getelementptr inbounds i16, i16* %10, i64 56
  %142 = bitcast i16* %141 to <8 x i16>*
  %143 = load <8 x i16>, <8 x i16>* %142, align 16
  %144 = getelementptr inbounds i16, i16* %11, i64 56
  %145 = bitcast i16* %144 to <8 x i16>*
  %146 = load <8 x i16>, <8 x i16>* %145, align 16
  %147 = sub <8 x i16> %143, %146
  %148 = sub <8 x i16> zeroinitializer, %147
  %149 = icmp slt <8 x i16> %147, zeroinitializer
  %150 = select <8 x i1> %149, <8 x i16> %148, <8 x i16> %147
  %151 = lshr <8 x i16> %150, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %152 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %151, <8 x i16> zeroinitializer) #5
  %153 = lshr <8 x i16> %152, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %154 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %140, <8 x i16> %153) #5
  %155 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %154, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %156 = icmp slt <16 x i8> %155, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %157 = select <16 x i1> %156, <16 x i8> %155, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %158 = bitcast <16 x i8> %157 to <2 x i64>
  %159 = extractelement <2 x i64> %158, i32 0
  %160 = bitcast i8* %129 to i64*
  store i64 %159, i64* %160, align 1
  %161 = getelementptr inbounds i8, i8* %129, i64 %3
  %162 = bitcast <16 x i8> %157 to <4 x float>
  %163 = shufflevector <4 x float> %162, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %164 = bitcast i8* %161 to <2 x float>*
  store <2 x float> %163, <2 x float>* %164, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_119WeightMask8x16_SSE4ILb1EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  %7 = shl i64 %3, 1
  br label %8

8:                                                ; preds = %8, %4
  %9 = phi i8* [ %2, %4 ], [ %90, %8 ]
  %10 = phi i16* [ %5, %4 ], [ %88, %8 ]
  %11 = phi i16* [ %6, %4 ], [ %89, %8 ]
  %12 = phi i32 [ 3, %4 ], [ %91, %8 ]
  %13 = bitcast i16* %10 to <8 x i16>*
  %14 = load <8 x i16>, <8 x i16>* %13, align 16
  %15 = bitcast i16* %11 to <8 x i16>*
  %16 = load <8 x i16>, <8 x i16>* %15, align 16
  %17 = sub <8 x i16> %14, %16
  %18 = sub <8 x i16> zeroinitializer, %17
  %19 = icmp slt <8 x i16> %17, zeroinitializer
  %20 = select <8 x i1> %19, <8 x i16> %18, <8 x i16> %17
  %21 = lshr <8 x i16> %20, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %22 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %21, <8 x i16> zeroinitializer) #5
  %23 = lshr <8 x i16> %22, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %24 = getelementptr inbounds i16, i16* %10, i64 8
  %25 = bitcast i16* %24 to <8 x i16>*
  %26 = load <8 x i16>, <8 x i16>* %25, align 16
  %27 = getelementptr inbounds i16, i16* %11, i64 8
  %28 = bitcast i16* %27 to <8 x i16>*
  %29 = load <8 x i16>, <8 x i16>* %28, align 16
  %30 = sub <8 x i16> %26, %29
  %31 = sub <8 x i16> zeroinitializer, %30
  %32 = icmp slt <8 x i16> %30, zeroinitializer
  %33 = select <8 x i1> %32, <8 x i16> %31, <8 x i16> %30
  %34 = lshr <8 x i16> %33, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %35 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %34, <8 x i16> zeroinitializer) #5
  %36 = lshr <8 x i16> %35, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %37 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %23, <8 x i16> %36) #5
  %38 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %37, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %39 = icmp slt <16 x i8> %38, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %40 = select <16 x i1> %39, <16 x i8> %38, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %41 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %40
  %42 = bitcast <16 x i8> %41 to <2 x i64>
  %43 = extractelement <2 x i64> %42, i32 0
  %44 = bitcast i8* %9 to i64*
  store i64 %43, i64* %44, align 1
  %45 = getelementptr inbounds i8, i8* %9, i64 %3
  %46 = bitcast <16 x i8> %41 to <4 x float>
  %47 = shufflevector <4 x float> %46, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %48 = bitcast i8* %45 to <2 x float>*
  store <2 x float> %47, <2 x float>* %48, align 1
  %49 = getelementptr inbounds i16, i16* %10, i64 16
  %50 = getelementptr inbounds i16, i16* %11, i64 16
  %51 = getelementptr inbounds i8, i8* %9, i64 %7
  %52 = bitcast i16* %49 to <8 x i16>*
  %53 = load <8 x i16>, <8 x i16>* %52, align 16
  %54 = bitcast i16* %50 to <8 x i16>*
  %55 = load <8 x i16>, <8 x i16>* %54, align 16
  %56 = sub <8 x i16> %53, %55
  %57 = sub <8 x i16> zeroinitializer, %56
  %58 = icmp slt <8 x i16> %56, zeroinitializer
  %59 = select <8 x i1> %58, <8 x i16> %57, <8 x i16> %56
  %60 = lshr <8 x i16> %59, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %61 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %60, <8 x i16> zeroinitializer) #5
  %62 = lshr <8 x i16> %61, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %63 = getelementptr inbounds i16, i16* %10, i64 24
  %64 = bitcast i16* %63 to <8 x i16>*
  %65 = load <8 x i16>, <8 x i16>* %64, align 16
  %66 = getelementptr inbounds i16, i16* %11, i64 24
  %67 = bitcast i16* %66 to <8 x i16>*
  %68 = load <8 x i16>, <8 x i16>* %67, align 16
  %69 = sub <8 x i16> %65, %68
  %70 = sub <8 x i16> zeroinitializer, %69
  %71 = icmp slt <8 x i16> %69, zeroinitializer
  %72 = select <8 x i1> %71, <8 x i16> %70, <8 x i16> %69
  %73 = lshr <8 x i16> %72, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %74 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %73, <8 x i16> zeroinitializer) #5
  %75 = lshr <8 x i16> %74, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %76 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %62, <8 x i16> %75) #5
  %77 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %76, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %78 = icmp slt <16 x i8> %77, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %79 = select <16 x i1> %78, <16 x i8> %77, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %80 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %79
  %81 = bitcast <16 x i8> %80 to <2 x i64>
  %82 = extractelement <2 x i64> %81, i32 0
  %83 = bitcast i8* %51 to i64*
  store i64 %82, i64* %83, align 1
  %84 = getelementptr inbounds i8, i8* %51, i64 %3
  %85 = bitcast <16 x i8> %80 to <4 x float>
  %86 = shufflevector <4 x float> %85, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %87 = bitcast i8* %84 to <2 x float>*
  store <2 x float> %86, <2 x float>* %87, align 1
  %88 = getelementptr inbounds i16, i16* %10, i64 32
  %89 = getelementptr inbounds i16, i16* %11, i64 32
  %90 = getelementptr inbounds i8, i8* %51, i64 %7
  %91 = add nsw i32 %12, -1
  %92 = icmp eq i32 %91, 0
  br i1 %92, label %93, label %8

93:                                               ; preds = %8
  %94 = bitcast i16* %88 to <8 x i16>*
  %95 = load <8 x i16>, <8 x i16>* %94, align 16
  %96 = bitcast i16* %89 to <8 x i16>*
  %97 = load <8 x i16>, <8 x i16>* %96, align 16
  %98 = sub <8 x i16> %95, %97
  %99 = sub <8 x i16> zeroinitializer, %98
  %100 = icmp slt <8 x i16> %98, zeroinitializer
  %101 = select <8 x i1> %100, <8 x i16> %99, <8 x i16> %98
  %102 = lshr <8 x i16> %101, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %103 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %102, <8 x i16> zeroinitializer) #5
  %104 = lshr <8 x i16> %103, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %105 = getelementptr inbounds i16, i16* %10, i64 40
  %106 = bitcast i16* %105 to <8 x i16>*
  %107 = load <8 x i16>, <8 x i16>* %106, align 16
  %108 = getelementptr inbounds i16, i16* %11, i64 40
  %109 = bitcast i16* %108 to <8 x i16>*
  %110 = load <8 x i16>, <8 x i16>* %109, align 16
  %111 = sub <8 x i16> %107, %110
  %112 = sub <8 x i16> zeroinitializer, %111
  %113 = icmp slt <8 x i16> %111, zeroinitializer
  %114 = select <8 x i1> %113, <8 x i16> %112, <8 x i16> %111
  %115 = lshr <8 x i16> %114, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %116 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %115, <8 x i16> zeroinitializer) #5
  %117 = lshr <8 x i16> %116, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %118 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %104, <8 x i16> %117) #5
  %119 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %118, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %120 = icmp slt <16 x i8> %119, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %121 = select <16 x i1> %120, <16 x i8> %119, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %122 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %121
  %123 = bitcast <16 x i8> %122 to <2 x i64>
  %124 = extractelement <2 x i64> %123, i32 0
  %125 = bitcast i8* %90 to i64*
  store i64 %124, i64* %125, align 1
  %126 = getelementptr inbounds i8, i8* %90, i64 %3
  %127 = bitcast <16 x i8> %122 to <4 x float>
  %128 = shufflevector <4 x float> %127, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %129 = bitcast i8* %126 to <2 x float>*
  store <2 x float> %128, <2 x float>* %129, align 1
  %130 = getelementptr inbounds i16, i16* %10, i64 48
  %131 = getelementptr inbounds i16, i16* %11, i64 48
  %132 = getelementptr inbounds i8, i8* %90, i64 %7
  %133 = bitcast i16* %130 to <8 x i16>*
  %134 = load <8 x i16>, <8 x i16>* %133, align 16
  %135 = bitcast i16* %131 to <8 x i16>*
  %136 = load <8 x i16>, <8 x i16>* %135, align 16
  %137 = sub <8 x i16> %134, %136
  %138 = sub <8 x i16> zeroinitializer, %137
  %139 = icmp slt <8 x i16> %137, zeroinitializer
  %140 = select <8 x i1> %139, <8 x i16> %138, <8 x i16> %137
  %141 = lshr <8 x i16> %140, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %142 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %141, <8 x i16> zeroinitializer) #5
  %143 = lshr <8 x i16> %142, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %144 = getelementptr inbounds i16, i16* %10, i64 56
  %145 = bitcast i16* %144 to <8 x i16>*
  %146 = load <8 x i16>, <8 x i16>* %145, align 16
  %147 = getelementptr inbounds i16, i16* %11, i64 56
  %148 = bitcast i16* %147 to <8 x i16>*
  %149 = load <8 x i16>, <8 x i16>* %148, align 16
  %150 = sub <8 x i16> %146, %149
  %151 = sub <8 x i16> zeroinitializer, %150
  %152 = icmp slt <8 x i16> %150, zeroinitializer
  %153 = select <8 x i1> %152, <8 x i16> %151, <8 x i16> %150
  %154 = lshr <8 x i16> %153, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %155 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %154, <8 x i16> zeroinitializer) #5
  %156 = lshr <8 x i16> %155, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %157 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %143, <8 x i16> %156) #5
  %158 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %157, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %159 = icmp slt <16 x i8> %158, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %160 = select <16 x i1> %159, <16 x i8> %158, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %161 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %160
  %162 = bitcast <16 x i8> %161 to <2 x i64>
  %163 = extractelement <2 x i64> %162, i32 0
  %164 = bitcast i8* %132 to i64*
  store i64 %163, i64* %164, align 1
  %165 = getelementptr inbounds i8, i8* %132, i64 %3
  %166 = bitcast <16 x i8> %161 to <4 x float>
  %167 = shufflevector <4 x float> %166, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %168 = bitcast i8* %165 to <2 x float>*
  store <2 x float> %167, <2 x float>* %168, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_119WeightMask8x32_SSE4ILb0EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  %7 = shl i64 %3, 1
  br label %8

8:                                                ; preds = %8, %4
  %9 = phi i8* [ %2, %4 ], [ %126, %8 ]
  %10 = phi i16* [ %5, %4 ], [ %124, %8 ]
  %11 = phi i16* [ %6, %4 ], [ %125, %8 ]
  %12 = phi i32 [ 5, %4 ], [ %127, %8 ]
  %13 = bitcast i16* %10 to <8 x i16>*
  %14 = load <8 x i16>, <8 x i16>* %13, align 16
  %15 = bitcast i16* %11 to <8 x i16>*
  %16 = load <8 x i16>, <8 x i16>* %15, align 16
  %17 = sub <8 x i16> %14, %16
  %18 = sub <8 x i16> zeroinitializer, %17
  %19 = icmp slt <8 x i16> %17, zeroinitializer
  %20 = select <8 x i1> %19, <8 x i16> %18, <8 x i16> %17
  %21 = lshr <8 x i16> %20, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %22 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %21, <8 x i16> zeroinitializer) #5
  %23 = lshr <8 x i16> %22, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %24 = getelementptr inbounds i16, i16* %10, i64 8
  %25 = bitcast i16* %24 to <8 x i16>*
  %26 = load <8 x i16>, <8 x i16>* %25, align 16
  %27 = getelementptr inbounds i16, i16* %11, i64 8
  %28 = bitcast i16* %27 to <8 x i16>*
  %29 = load <8 x i16>, <8 x i16>* %28, align 16
  %30 = sub <8 x i16> %26, %29
  %31 = sub <8 x i16> zeroinitializer, %30
  %32 = icmp slt <8 x i16> %30, zeroinitializer
  %33 = select <8 x i1> %32, <8 x i16> %31, <8 x i16> %30
  %34 = lshr <8 x i16> %33, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %35 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %34, <8 x i16> zeroinitializer) #5
  %36 = lshr <8 x i16> %35, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %37 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %23, <8 x i16> %36) #5
  %38 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %37, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %39 = icmp slt <16 x i8> %38, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %40 = select <16 x i1> %39, <16 x i8> %38, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %41 = bitcast <16 x i8> %40 to <2 x i64>
  %42 = extractelement <2 x i64> %41, i32 0
  %43 = bitcast i8* %9 to i64*
  store i64 %42, i64* %43, align 1
  %44 = getelementptr inbounds i8, i8* %9, i64 %3
  %45 = bitcast <16 x i8> %40 to <4 x float>
  %46 = shufflevector <4 x float> %45, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %47 = bitcast i8* %44 to <2 x float>*
  store <2 x float> %46, <2 x float>* %47, align 1
  %48 = getelementptr inbounds i16, i16* %10, i64 16
  %49 = getelementptr inbounds i16, i16* %11, i64 16
  %50 = getelementptr inbounds i8, i8* %9, i64 %7
  %51 = bitcast i16* %48 to <8 x i16>*
  %52 = load <8 x i16>, <8 x i16>* %51, align 16
  %53 = bitcast i16* %49 to <8 x i16>*
  %54 = load <8 x i16>, <8 x i16>* %53, align 16
  %55 = sub <8 x i16> %52, %54
  %56 = sub <8 x i16> zeroinitializer, %55
  %57 = icmp slt <8 x i16> %55, zeroinitializer
  %58 = select <8 x i1> %57, <8 x i16> %56, <8 x i16> %55
  %59 = lshr <8 x i16> %58, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %60 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %59, <8 x i16> zeroinitializer) #5
  %61 = lshr <8 x i16> %60, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %62 = getelementptr inbounds i16, i16* %10, i64 24
  %63 = bitcast i16* %62 to <8 x i16>*
  %64 = load <8 x i16>, <8 x i16>* %63, align 16
  %65 = getelementptr inbounds i16, i16* %11, i64 24
  %66 = bitcast i16* %65 to <8 x i16>*
  %67 = load <8 x i16>, <8 x i16>* %66, align 16
  %68 = sub <8 x i16> %64, %67
  %69 = sub <8 x i16> zeroinitializer, %68
  %70 = icmp slt <8 x i16> %68, zeroinitializer
  %71 = select <8 x i1> %70, <8 x i16> %69, <8 x i16> %68
  %72 = lshr <8 x i16> %71, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %73 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %72, <8 x i16> zeroinitializer) #5
  %74 = lshr <8 x i16> %73, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %75 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %61, <8 x i16> %74) #5
  %76 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %75, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %77 = icmp slt <16 x i8> %76, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %78 = select <16 x i1> %77, <16 x i8> %76, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %79 = bitcast <16 x i8> %78 to <2 x i64>
  %80 = extractelement <2 x i64> %79, i32 0
  %81 = bitcast i8* %50 to i64*
  store i64 %80, i64* %81, align 1
  %82 = getelementptr inbounds i8, i8* %50, i64 %3
  %83 = bitcast <16 x i8> %78 to <4 x float>
  %84 = shufflevector <4 x float> %83, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %85 = bitcast i8* %82 to <2 x float>*
  store <2 x float> %84, <2 x float>* %85, align 1
  %86 = getelementptr inbounds i16, i16* %10, i64 32
  %87 = getelementptr inbounds i16, i16* %11, i64 32
  %88 = getelementptr inbounds i8, i8* %50, i64 %7
  %89 = bitcast i16* %86 to <8 x i16>*
  %90 = load <8 x i16>, <8 x i16>* %89, align 16
  %91 = bitcast i16* %87 to <8 x i16>*
  %92 = load <8 x i16>, <8 x i16>* %91, align 16
  %93 = sub <8 x i16> %90, %92
  %94 = sub <8 x i16> zeroinitializer, %93
  %95 = icmp slt <8 x i16> %93, zeroinitializer
  %96 = select <8 x i1> %95, <8 x i16> %94, <8 x i16> %93
  %97 = lshr <8 x i16> %96, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %98 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %97, <8 x i16> zeroinitializer) #5
  %99 = lshr <8 x i16> %98, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %100 = getelementptr inbounds i16, i16* %10, i64 40
  %101 = bitcast i16* %100 to <8 x i16>*
  %102 = load <8 x i16>, <8 x i16>* %101, align 16
  %103 = getelementptr inbounds i16, i16* %11, i64 40
  %104 = bitcast i16* %103 to <8 x i16>*
  %105 = load <8 x i16>, <8 x i16>* %104, align 16
  %106 = sub <8 x i16> %102, %105
  %107 = sub <8 x i16> zeroinitializer, %106
  %108 = icmp slt <8 x i16> %106, zeroinitializer
  %109 = select <8 x i1> %108, <8 x i16> %107, <8 x i16> %106
  %110 = lshr <8 x i16> %109, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %111 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %110, <8 x i16> zeroinitializer) #5
  %112 = lshr <8 x i16> %111, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %113 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %99, <8 x i16> %112) #5
  %114 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %113, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %115 = icmp slt <16 x i8> %114, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %116 = select <16 x i1> %115, <16 x i8> %114, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %117 = bitcast <16 x i8> %116 to <2 x i64>
  %118 = extractelement <2 x i64> %117, i32 0
  %119 = bitcast i8* %88 to i64*
  store i64 %118, i64* %119, align 1
  %120 = getelementptr inbounds i8, i8* %88, i64 %3
  %121 = bitcast <16 x i8> %116 to <4 x float>
  %122 = shufflevector <4 x float> %121, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %123 = bitcast i8* %120 to <2 x float>*
  store <2 x float> %122, <2 x float>* %123, align 1
  %124 = getelementptr inbounds i16, i16* %10, i64 48
  %125 = getelementptr inbounds i16, i16* %11, i64 48
  %126 = getelementptr inbounds i8, i8* %88, i64 %7
  %127 = add nsw i32 %12, -1
  %128 = icmp eq i32 %127, 0
  br i1 %128, label %129, label %8

129:                                              ; preds = %8
  %130 = bitcast i16* %124 to <8 x i16>*
  %131 = load <8 x i16>, <8 x i16>* %130, align 16
  %132 = bitcast i16* %125 to <8 x i16>*
  %133 = load <8 x i16>, <8 x i16>* %132, align 16
  %134 = sub <8 x i16> %131, %133
  %135 = sub <8 x i16> zeroinitializer, %134
  %136 = icmp slt <8 x i16> %134, zeroinitializer
  %137 = select <8 x i1> %136, <8 x i16> %135, <8 x i16> %134
  %138 = lshr <8 x i16> %137, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %139 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %138, <8 x i16> zeroinitializer) #5
  %140 = lshr <8 x i16> %139, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %141 = getelementptr inbounds i16, i16* %10, i64 56
  %142 = bitcast i16* %141 to <8 x i16>*
  %143 = load <8 x i16>, <8 x i16>* %142, align 16
  %144 = getelementptr inbounds i16, i16* %11, i64 56
  %145 = bitcast i16* %144 to <8 x i16>*
  %146 = load <8 x i16>, <8 x i16>* %145, align 16
  %147 = sub <8 x i16> %143, %146
  %148 = sub <8 x i16> zeroinitializer, %147
  %149 = icmp slt <8 x i16> %147, zeroinitializer
  %150 = select <8 x i1> %149, <8 x i16> %148, <8 x i16> %147
  %151 = lshr <8 x i16> %150, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %152 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %151, <8 x i16> zeroinitializer) #5
  %153 = lshr <8 x i16> %152, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %154 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %140, <8 x i16> %153) #5
  %155 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %154, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %156 = icmp slt <16 x i8> %155, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %157 = select <16 x i1> %156, <16 x i8> %155, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %158 = bitcast <16 x i8> %157 to <2 x i64>
  %159 = extractelement <2 x i64> %158, i32 0
  %160 = bitcast i8* %126 to i64*
  store i64 %159, i64* %160, align 1
  %161 = getelementptr inbounds i8, i8* %126, i64 %3
  %162 = bitcast <16 x i8> %157 to <4 x float>
  %163 = shufflevector <4 x float> %162, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %164 = bitcast i8* %161 to <2 x float>*
  store <2 x float> %163, <2 x float>* %164, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_119WeightMask8x32_SSE4ILb1EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  %7 = shl i64 %3, 1
  br label %8

8:                                                ; preds = %8, %4
  %9 = phi i8* [ %2, %4 ], [ %129, %8 ]
  %10 = phi i16* [ %5, %4 ], [ %127, %8 ]
  %11 = phi i16* [ %6, %4 ], [ %128, %8 ]
  %12 = phi i32 [ 5, %4 ], [ %130, %8 ]
  %13 = bitcast i16* %10 to <8 x i16>*
  %14 = load <8 x i16>, <8 x i16>* %13, align 16
  %15 = bitcast i16* %11 to <8 x i16>*
  %16 = load <8 x i16>, <8 x i16>* %15, align 16
  %17 = sub <8 x i16> %14, %16
  %18 = sub <8 x i16> zeroinitializer, %17
  %19 = icmp slt <8 x i16> %17, zeroinitializer
  %20 = select <8 x i1> %19, <8 x i16> %18, <8 x i16> %17
  %21 = lshr <8 x i16> %20, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %22 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %21, <8 x i16> zeroinitializer) #5
  %23 = lshr <8 x i16> %22, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %24 = getelementptr inbounds i16, i16* %10, i64 8
  %25 = bitcast i16* %24 to <8 x i16>*
  %26 = load <8 x i16>, <8 x i16>* %25, align 16
  %27 = getelementptr inbounds i16, i16* %11, i64 8
  %28 = bitcast i16* %27 to <8 x i16>*
  %29 = load <8 x i16>, <8 x i16>* %28, align 16
  %30 = sub <8 x i16> %26, %29
  %31 = sub <8 x i16> zeroinitializer, %30
  %32 = icmp slt <8 x i16> %30, zeroinitializer
  %33 = select <8 x i1> %32, <8 x i16> %31, <8 x i16> %30
  %34 = lshr <8 x i16> %33, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %35 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %34, <8 x i16> zeroinitializer) #5
  %36 = lshr <8 x i16> %35, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %37 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %23, <8 x i16> %36) #5
  %38 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %37, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %39 = icmp slt <16 x i8> %38, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %40 = select <16 x i1> %39, <16 x i8> %38, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %41 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %40
  %42 = bitcast <16 x i8> %41 to <2 x i64>
  %43 = extractelement <2 x i64> %42, i32 0
  %44 = bitcast i8* %9 to i64*
  store i64 %43, i64* %44, align 1
  %45 = getelementptr inbounds i8, i8* %9, i64 %3
  %46 = bitcast <16 x i8> %41 to <4 x float>
  %47 = shufflevector <4 x float> %46, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %48 = bitcast i8* %45 to <2 x float>*
  store <2 x float> %47, <2 x float>* %48, align 1
  %49 = getelementptr inbounds i16, i16* %10, i64 16
  %50 = getelementptr inbounds i16, i16* %11, i64 16
  %51 = getelementptr inbounds i8, i8* %9, i64 %7
  %52 = bitcast i16* %49 to <8 x i16>*
  %53 = load <8 x i16>, <8 x i16>* %52, align 16
  %54 = bitcast i16* %50 to <8 x i16>*
  %55 = load <8 x i16>, <8 x i16>* %54, align 16
  %56 = sub <8 x i16> %53, %55
  %57 = sub <8 x i16> zeroinitializer, %56
  %58 = icmp slt <8 x i16> %56, zeroinitializer
  %59 = select <8 x i1> %58, <8 x i16> %57, <8 x i16> %56
  %60 = lshr <8 x i16> %59, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %61 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %60, <8 x i16> zeroinitializer) #5
  %62 = lshr <8 x i16> %61, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %63 = getelementptr inbounds i16, i16* %10, i64 24
  %64 = bitcast i16* %63 to <8 x i16>*
  %65 = load <8 x i16>, <8 x i16>* %64, align 16
  %66 = getelementptr inbounds i16, i16* %11, i64 24
  %67 = bitcast i16* %66 to <8 x i16>*
  %68 = load <8 x i16>, <8 x i16>* %67, align 16
  %69 = sub <8 x i16> %65, %68
  %70 = sub <8 x i16> zeroinitializer, %69
  %71 = icmp slt <8 x i16> %69, zeroinitializer
  %72 = select <8 x i1> %71, <8 x i16> %70, <8 x i16> %69
  %73 = lshr <8 x i16> %72, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %74 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %73, <8 x i16> zeroinitializer) #5
  %75 = lshr <8 x i16> %74, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %76 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %62, <8 x i16> %75) #5
  %77 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %76, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %78 = icmp slt <16 x i8> %77, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %79 = select <16 x i1> %78, <16 x i8> %77, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %80 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %79
  %81 = bitcast <16 x i8> %80 to <2 x i64>
  %82 = extractelement <2 x i64> %81, i32 0
  %83 = bitcast i8* %51 to i64*
  store i64 %82, i64* %83, align 1
  %84 = getelementptr inbounds i8, i8* %51, i64 %3
  %85 = bitcast <16 x i8> %80 to <4 x float>
  %86 = shufflevector <4 x float> %85, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %87 = bitcast i8* %84 to <2 x float>*
  store <2 x float> %86, <2 x float>* %87, align 1
  %88 = getelementptr inbounds i16, i16* %10, i64 32
  %89 = getelementptr inbounds i16, i16* %11, i64 32
  %90 = getelementptr inbounds i8, i8* %51, i64 %7
  %91 = bitcast i16* %88 to <8 x i16>*
  %92 = load <8 x i16>, <8 x i16>* %91, align 16
  %93 = bitcast i16* %89 to <8 x i16>*
  %94 = load <8 x i16>, <8 x i16>* %93, align 16
  %95 = sub <8 x i16> %92, %94
  %96 = sub <8 x i16> zeroinitializer, %95
  %97 = icmp slt <8 x i16> %95, zeroinitializer
  %98 = select <8 x i1> %97, <8 x i16> %96, <8 x i16> %95
  %99 = lshr <8 x i16> %98, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %100 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %99, <8 x i16> zeroinitializer) #5
  %101 = lshr <8 x i16> %100, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %102 = getelementptr inbounds i16, i16* %10, i64 40
  %103 = bitcast i16* %102 to <8 x i16>*
  %104 = load <8 x i16>, <8 x i16>* %103, align 16
  %105 = getelementptr inbounds i16, i16* %11, i64 40
  %106 = bitcast i16* %105 to <8 x i16>*
  %107 = load <8 x i16>, <8 x i16>* %106, align 16
  %108 = sub <8 x i16> %104, %107
  %109 = sub <8 x i16> zeroinitializer, %108
  %110 = icmp slt <8 x i16> %108, zeroinitializer
  %111 = select <8 x i1> %110, <8 x i16> %109, <8 x i16> %108
  %112 = lshr <8 x i16> %111, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %113 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %112, <8 x i16> zeroinitializer) #5
  %114 = lshr <8 x i16> %113, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %115 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %101, <8 x i16> %114) #5
  %116 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %115, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %117 = icmp slt <16 x i8> %116, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %118 = select <16 x i1> %117, <16 x i8> %116, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %119 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %118
  %120 = bitcast <16 x i8> %119 to <2 x i64>
  %121 = extractelement <2 x i64> %120, i32 0
  %122 = bitcast i8* %90 to i64*
  store i64 %121, i64* %122, align 1
  %123 = getelementptr inbounds i8, i8* %90, i64 %3
  %124 = bitcast <16 x i8> %119 to <4 x float>
  %125 = shufflevector <4 x float> %124, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %126 = bitcast i8* %123 to <2 x float>*
  store <2 x float> %125, <2 x float>* %126, align 1
  %127 = getelementptr inbounds i16, i16* %10, i64 48
  %128 = getelementptr inbounds i16, i16* %11, i64 48
  %129 = getelementptr inbounds i8, i8* %90, i64 %7
  %130 = add nsw i32 %12, -1
  %131 = icmp eq i32 %130, 0
  br i1 %131, label %132, label %8

132:                                              ; preds = %8
  %133 = bitcast i16* %127 to <8 x i16>*
  %134 = load <8 x i16>, <8 x i16>* %133, align 16
  %135 = bitcast i16* %128 to <8 x i16>*
  %136 = load <8 x i16>, <8 x i16>* %135, align 16
  %137 = sub <8 x i16> %134, %136
  %138 = sub <8 x i16> zeroinitializer, %137
  %139 = icmp slt <8 x i16> %137, zeroinitializer
  %140 = select <8 x i1> %139, <8 x i16> %138, <8 x i16> %137
  %141 = lshr <8 x i16> %140, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %142 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %141, <8 x i16> zeroinitializer) #5
  %143 = lshr <8 x i16> %142, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %144 = getelementptr inbounds i16, i16* %10, i64 56
  %145 = bitcast i16* %144 to <8 x i16>*
  %146 = load <8 x i16>, <8 x i16>* %145, align 16
  %147 = getelementptr inbounds i16, i16* %11, i64 56
  %148 = bitcast i16* %147 to <8 x i16>*
  %149 = load <8 x i16>, <8 x i16>* %148, align 16
  %150 = sub <8 x i16> %146, %149
  %151 = sub <8 x i16> zeroinitializer, %150
  %152 = icmp slt <8 x i16> %150, zeroinitializer
  %153 = select <8 x i1> %152, <8 x i16> %151, <8 x i16> %150
  %154 = lshr <8 x i16> %153, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %155 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %154, <8 x i16> zeroinitializer) #5
  %156 = lshr <8 x i16> %155, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %157 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %143, <8 x i16> %156) #5
  %158 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %157, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %159 = icmp slt <16 x i8> %158, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %160 = select <16 x i1> %159, <16 x i8> %158, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %161 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %160
  %162 = bitcast <16 x i8> %161 to <2 x i64>
  %163 = extractelement <2 x i64> %162, i32 0
  %164 = bitcast i8* %129 to i64*
  store i64 %163, i64* %164, align 1
  %165 = getelementptr inbounds i8, i8* %129, i64 %3
  %166 = bitcast <16 x i8> %161 to <4 x float>
  %167 = shufflevector <4 x float> %166, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %168 = bitcast i8* %165 to <2 x float>*
  store <2 x float> %167, <2 x float>* %168, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_119WeightMask16x8_SSE4ILb0EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to <8 x i16>*
  %6 = load <8 x i16>, <8 x i16>* %5, align 16
  %7 = bitcast i8* %1 to <8 x i16>*
  %8 = load <8 x i16>, <8 x i16>* %7, align 16
  %9 = sub <8 x i16> %6, %8
  %10 = sub <8 x i16> zeroinitializer, %9
  %11 = icmp slt <8 x i16> %9, zeroinitializer
  %12 = select <8 x i1> %11, <8 x i16> %10, <8 x i16> %9
  %13 = lshr <8 x i16> %12, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %14 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %13, <8 x i16> zeroinitializer) #5
  %15 = lshr <8 x i16> %14, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %16 = getelementptr inbounds i8, i8* %0, i64 16
  %17 = bitcast i8* %16 to <8 x i16>*
  %18 = load <8 x i16>, <8 x i16>* %17, align 16
  %19 = getelementptr inbounds i8, i8* %1, i64 16
  %20 = bitcast i8* %19 to <8 x i16>*
  %21 = load <8 x i16>, <8 x i16>* %20, align 16
  %22 = sub <8 x i16> %18, %21
  %23 = sub <8 x i16> zeroinitializer, %22
  %24 = icmp slt <8 x i16> %22, zeroinitializer
  %25 = select <8 x i1> %24, <8 x i16> %23, <8 x i16> %22
  %26 = lshr <8 x i16> %25, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %27 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %26, <8 x i16> zeroinitializer) #5
  %28 = lshr <8 x i16> %27, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %29 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %15, <8 x i16> %28) #5
  %30 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %29, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %31 = icmp slt <16 x i8> %30, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %32 = select <16 x i1> %31, <16 x i8> %30, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %33 = bitcast i8* %2 to <16 x i8>*
  store <16 x i8> %32, <16 x i8>* %33, align 16
  %34 = getelementptr inbounds i8, i8* %0, i64 32
  %35 = getelementptr inbounds i8, i8* %1, i64 32
  %36 = getelementptr inbounds i8, i8* %2, i64 %3
  %37 = bitcast i8* %34 to <8 x i16>*
  %38 = load <8 x i16>, <8 x i16>* %37, align 16
  %39 = bitcast i8* %35 to <8 x i16>*
  %40 = load <8 x i16>, <8 x i16>* %39, align 16
  %41 = sub <8 x i16> %38, %40
  %42 = sub <8 x i16> zeroinitializer, %41
  %43 = icmp slt <8 x i16> %41, zeroinitializer
  %44 = select <8 x i1> %43, <8 x i16> %42, <8 x i16> %41
  %45 = lshr <8 x i16> %44, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %46 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %45, <8 x i16> zeroinitializer) #5
  %47 = lshr <8 x i16> %46, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %48 = getelementptr inbounds i8, i8* %0, i64 48
  %49 = bitcast i8* %48 to <8 x i16>*
  %50 = load <8 x i16>, <8 x i16>* %49, align 16
  %51 = getelementptr inbounds i8, i8* %1, i64 48
  %52 = bitcast i8* %51 to <8 x i16>*
  %53 = load <8 x i16>, <8 x i16>* %52, align 16
  %54 = sub <8 x i16> %50, %53
  %55 = sub <8 x i16> zeroinitializer, %54
  %56 = icmp slt <8 x i16> %54, zeroinitializer
  %57 = select <8 x i1> %56, <8 x i16> %55, <8 x i16> %54
  %58 = lshr <8 x i16> %57, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %59 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %58, <8 x i16> zeroinitializer) #5
  %60 = lshr <8 x i16> %59, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %61 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %47, <8 x i16> %60) #5
  %62 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %61, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %63 = icmp slt <16 x i8> %62, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %64 = select <16 x i1> %63, <16 x i8> %62, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %65 = bitcast i8* %36 to <16 x i8>*
  store <16 x i8> %64, <16 x i8>* %65, align 16
  %66 = getelementptr inbounds i8, i8* %0, i64 64
  %67 = getelementptr inbounds i8, i8* %1, i64 64
  %68 = getelementptr inbounds i8, i8* %36, i64 %3
  %69 = bitcast i8* %66 to <8 x i16>*
  %70 = load <8 x i16>, <8 x i16>* %69, align 16
  %71 = bitcast i8* %67 to <8 x i16>*
  %72 = load <8 x i16>, <8 x i16>* %71, align 16
  %73 = sub <8 x i16> %70, %72
  %74 = sub <8 x i16> zeroinitializer, %73
  %75 = icmp slt <8 x i16> %73, zeroinitializer
  %76 = select <8 x i1> %75, <8 x i16> %74, <8 x i16> %73
  %77 = lshr <8 x i16> %76, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %78 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %77, <8 x i16> zeroinitializer) #5
  %79 = lshr <8 x i16> %78, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %80 = getelementptr inbounds i8, i8* %0, i64 80
  %81 = bitcast i8* %80 to <8 x i16>*
  %82 = load <8 x i16>, <8 x i16>* %81, align 16
  %83 = getelementptr inbounds i8, i8* %1, i64 80
  %84 = bitcast i8* %83 to <8 x i16>*
  %85 = load <8 x i16>, <8 x i16>* %84, align 16
  %86 = sub <8 x i16> %82, %85
  %87 = sub <8 x i16> zeroinitializer, %86
  %88 = icmp slt <8 x i16> %86, zeroinitializer
  %89 = select <8 x i1> %88, <8 x i16> %87, <8 x i16> %86
  %90 = lshr <8 x i16> %89, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %91 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %90, <8 x i16> zeroinitializer) #5
  %92 = lshr <8 x i16> %91, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %93 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %79, <8 x i16> %92) #5
  %94 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %93, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %95 = icmp slt <16 x i8> %94, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %96 = select <16 x i1> %95, <16 x i8> %94, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %97 = bitcast i8* %68 to <16 x i8>*
  store <16 x i8> %96, <16 x i8>* %97, align 16
  %98 = getelementptr inbounds i8, i8* %0, i64 96
  %99 = getelementptr inbounds i8, i8* %1, i64 96
  %100 = getelementptr inbounds i8, i8* %68, i64 %3
  %101 = bitcast i8* %98 to <8 x i16>*
  %102 = load <8 x i16>, <8 x i16>* %101, align 16
  %103 = bitcast i8* %99 to <8 x i16>*
  %104 = load <8 x i16>, <8 x i16>* %103, align 16
  %105 = sub <8 x i16> %102, %104
  %106 = sub <8 x i16> zeroinitializer, %105
  %107 = icmp slt <8 x i16> %105, zeroinitializer
  %108 = select <8 x i1> %107, <8 x i16> %106, <8 x i16> %105
  %109 = lshr <8 x i16> %108, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %110 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %109, <8 x i16> zeroinitializer) #5
  %111 = lshr <8 x i16> %110, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %112 = getelementptr inbounds i8, i8* %0, i64 112
  %113 = bitcast i8* %112 to <8 x i16>*
  %114 = load <8 x i16>, <8 x i16>* %113, align 16
  %115 = getelementptr inbounds i8, i8* %1, i64 112
  %116 = bitcast i8* %115 to <8 x i16>*
  %117 = load <8 x i16>, <8 x i16>* %116, align 16
  %118 = sub <8 x i16> %114, %117
  %119 = sub <8 x i16> zeroinitializer, %118
  %120 = icmp slt <8 x i16> %118, zeroinitializer
  %121 = select <8 x i1> %120, <8 x i16> %119, <8 x i16> %118
  %122 = lshr <8 x i16> %121, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %123 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %122, <8 x i16> zeroinitializer) #5
  %124 = lshr <8 x i16> %123, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %125 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %111, <8 x i16> %124) #5
  %126 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %125, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %127 = icmp slt <16 x i8> %126, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %128 = select <16 x i1> %127, <16 x i8> %126, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %129 = bitcast i8* %100 to <16 x i8>*
  store <16 x i8> %128, <16 x i8>* %129, align 16
  %130 = getelementptr inbounds i8, i8* %0, i64 128
  %131 = getelementptr inbounds i8, i8* %1, i64 128
  %132 = getelementptr inbounds i8, i8* %100, i64 %3
  %133 = bitcast i8* %130 to <8 x i16>*
  %134 = load <8 x i16>, <8 x i16>* %133, align 16
  %135 = bitcast i8* %131 to <8 x i16>*
  %136 = load <8 x i16>, <8 x i16>* %135, align 16
  %137 = sub <8 x i16> %134, %136
  %138 = sub <8 x i16> zeroinitializer, %137
  %139 = icmp slt <8 x i16> %137, zeroinitializer
  %140 = select <8 x i1> %139, <8 x i16> %138, <8 x i16> %137
  %141 = lshr <8 x i16> %140, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %142 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %141, <8 x i16> zeroinitializer) #5
  %143 = lshr <8 x i16> %142, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %144 = getelementptr inbounds i8, i8* %0, i64 144
  %145 = bitcast i8* %144 to <8 x i16>*
  %146 = load <8 x i16>, <8 x i16>* %145, align 16
  %147 = getelementptr inbounds i8, i8* %1, i64 144
  %148 = bitcast i8* %147 to <8 x i16>*
  %149 = load <8 x i16>, <8 x i16>* %148, align 16
  %150 = sub <8 x i16> %146, %149
  %151 = sub <8 x i16> zeroinitializer, %150
  %152 = icmp slt <8 x i16> %150, zeroinitializer
  %153 = select <8 x i1> %152, <8 x i16> %151, <8 x i16> %150
  %154 = lshr <8 x i16> %153, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %155 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %154, <8 x i16> zeroinitializer) #5
  %156 = lshr <8 x i16> %155, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %157 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %143, <8 x i16> %156) #5
  %158 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %157, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %159 = icmp slt <16 x i8> %158, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %160 = select <16 x i1> %159, <16 x i8> %158, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %161 = bitcast i8* %132 to <16 x i8>*
  store <16 x i8> %160, <16 x i8>* %161, align 16
  %162 = getelementptr inbounds i8, i8* %0, i64 160
  %163 = getelementptr inbounds i8, i8* %1, i64 160
  %164 = getelementptr inbounds i8, i8* %132, i64 %3
  %165 = bitcast i8* %162 to <8 x i16>*
  %166 = load <8 x i16>, <8 x i16>* %165, align 16
  %167 = bitcast i8* %163 to <8 x i16>*
  %168 = load <8 x i16>, <8 x i16>* %167, align 16
  %169 = sub <8 x i16> %166, %168
  %170 = sub <8 x i16> zeroinitializer, %169
  %171 = icmp slt <8 x i16> %169, zeroinitializer
  %172 = select <8 x i1> %171, <8 x i16> %170, <8 x i16> %169
  %173 = lshr <8 x i16> %172, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %174 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %173, <8 x i16> zeroinitializer) #5
  %175 = lshr <8 x i16> %174, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %176 = getelementptr inbounds i8, i8* %0, i64 176
  %177 = bitcast i8* %176 to <8 x i16>*
  %178 = load <8 x i16>, <8 x i16>* %177, align 16
  %179 = getelementptr inbounds i8, i8* %1, i64 176
  %180 = bitcast i8* %179 to <8 x i16>*
  %181 = load <8 x i16>, <8 x i16>* %180, align 16
  %182 = sub <8 x i16> %178, %181
  %183 = sub <8 x i16> zeroinitializer, %182
  %184 = icmp slt <8 x i16> %182, zeroinitializer
  %185 = select <8 x i1> %184, <8 x i16> %183, <8 x i16> %182
  %186 = lshr <8 x i16> %185, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %187 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %186, <8 x i16> zeroinitializer) #5
  %188 = lshr <8 x i16> %187, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %189 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %175, <8 x i16> %188) #5
  %190 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %189, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %191 = icmp slt <16 x i8> %190, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %192 = select <16 x i1> %191, <16 x i8> %190, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %193 = bitcast i8* %164 to <16 x i8>*
  store <16 x i8> %192, <16 x i8>* %193, align 16
  %194 = getelementptr inbounds i8, i8* %0, i64 192
  %195 = getelementptr inbounds i8, i8* %1, i64 192
  %196 = getelementptr inbounds i8, i8* %164, i64 %3
  %197 = bitcast i8* %194 to <8 x i16>*
  %198 = load <8 x i16>, <8 x i16>* %197, align 16
  %199 = bitcast i8* %195 to <8 x i16>*
  %200 = load <8 x i16>, <8 x i16>* %199, align 16
  %201 = sub <8 x i16> %198, %200
  %202 = sub <8 x i16> zeroinitializer, %201
  %203 = icmp slt <8 x i16> %201, zeroinitializer
  %204 = select <8 x i1> %203, <8 x i16> %202, <8 x i16> %201
  %205 = lshr <8 x i16> %204, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %206 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %205, <8 x i16> zeroinitializer) #5
  %207 = lshr <8 x i16> %206, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %208 = getelementptr inbounds i8, i8* %0, i64 208
  %209 = bitcast i8* %208 to <8 x i16>*
  %210 = load <8 x i16>, <8 x i16>* %209, align 16
  %211 = getelementptr inbounds i8, i8* %1, i64 208
  %212 = bitcast i8* %211 to <8 x i16>*
  %213 = load <8 x i16>, <8 x i16>* %212, align 16
  %214 = sub <8 x i16> %210, %213
  %215 = sub <8 x i16> zeroinitializer, %214
  %216 = icmp slt <8 x i16> %214, zeroinitializer
  %217 = select <8 x i1> %216, <8 x i16> %215, <8 x i16> %214
  %218 = lshr <8 x i16> %217, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %219 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %218, <8 x i16> zeroinitializer) #5
  %220 = lshr <8 x i16> %219, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %221 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %207, <8 x i16> %220) #5
  %222 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %221, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %223 = icmp slt <16 x i8> %222, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %224 = select <16 x i1> %223, <16 x i8> %222, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %225 = bitcast i8* %196 to <16 x i8>*
  store <16 x i8> %224, <16 x i8>* %225, align 16
  %226 = getelementptr inbounds i8, i8* %0, i64 224
  %227 = getelementptr inbounds i8, i8* %1, i64 224
  %228 = getelementptr inbounds i8, i8* %196, i64 %3
  %229 = bitcast i8* %226 to <8 x i16>*
  %230 = load <8 x i16>, <8 x i16>* %229, align 16
  %231 = bitcast i8* %227 to <8 x i16>*
  %232 = load <8 x i16>, <8 x i16>* %231, align 16
  %233 = sub <8 x i16> %230, %232
  %234 = sub <8 x i16> zeroinitializer, %233
  %235 = icmp slt <8 x i16> %233, zeroinitializer
  %236 = select <8 x i1> %235, <8 x i16> %234, <8 x i16> %233
  %237 = lshr <8 x i16> %236, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %238 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %237, <8 x i16> zeroinitializer) #5
  %239 = lshr <8 x i16> %238, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %240 = getelementptr inbounds i8, i8* %0, i64 240
  %241 = bitcast i8* %240 to <8 x i16>*
  %242 = load <8 x i16>, <8 x i16>* %241, align 16
  %243 = getelementptr inbounds i8, i8* %1, i64 240
  %244 = bitcast i8* %243 to <8 x i16>*
  %245 = load <8 x i16>, <8 x i16>* %244, align 16
  %246 = sub <8 x i16> %242, %245
  %247 = sub <8 x i16> zeroinitializer, %246
  %248 = icmp slt <8 x i16> %246, zeroinitializer
  %249 = select <8 x i1> %248, <8 x i16> %247, <8 x i16> %246
  %250 = lshr <8 x i16> %249, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %251 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %250, <8 x i16> zeroinitializer) #5
  %252 = lshr <8 x i16> %251, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %253 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %239, <8 x i16> %252) #5
  %254 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %253, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %255 = icmp slt <16 x i8> %254, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %256 = select <16 x i1> %255, <16 x i8> %254, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %257 = bitcast i8* %228 to <16 x i8>*
  store <16 x i8> %256, <16 x i8>* %257, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_119WeightMask16x8_SSE4ILb1EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %44, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %42, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %43, %7 ]
  %11 = phi i32 [ 7, %4 ], [ %45, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = sub <8 x i16> %13, %15
  %17 = sub <8 x i16> zeroinitializer, %16
  %18 = icmp slt <8 x i16> %16, zeroinitializer
  %19 = select <8 x i1> %18, <8 x i16> %17, <8 x i16> %16
  %20 = lshr <8 x i16> %19, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %21 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %20, <8 x i16> zeroinitializer) #5
  %22 = lshr <8 x i16> %21, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %23 = getelementptr inbounds i16, i16* %9, i64 8
  %24 = bitcast i16* %23 to <8 x i16>*
  %25 = load <8 x i16>, <8 x i16>* %24, align 16
  %26 = getelementptr inbounds i16, i16* %10, i64 8
  %27 = bitcast i16* %26 to <8 x i16>*
  %28 = load <8 x i16>, <8 x i16>* %27, align 16
  %29 = sub <8 x i16> %25, %28
  %30 = sub <8 x i16> zeroinitializer, %29
  %31 = icmp slt <8 x i16> %29, zeroinitializer
  %32 = select <8 x i1> %31, <8 x i16> %30, <8 x i16> %29
  %33 = lshr <8 x i16> %32, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %34 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %33, <8 x i16> zeroinitializer) #5
  %35 = lshr <8 x i16> %34, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %36 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %22, <8 x i16> %35) #5
  %37 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %36, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %38 = icmp slt <16 x i8> %37, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %39 = select <16 x i1> %38, <16 x i8> %37, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %40 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %39
  %41 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %40, <16 x i8>* %41, align 16
  %42 = getelementptr inbounds i16, i16* %9, i64 16
  %43 = getelementptr inbounds i16, i16* %10, i64 16
  %44 = getelementptr inbounds i8, i8* %8, i64 %3
  %45 = add nsw i32 %11, -1
  %46 = icmp eq i32 %45, 0
  br i1 %46, label %47, label %7

47:                                               ; preds = %7
  %48 = bitcast i16* %42 to <8 x i16>*
  %49 = load <8 x i16>, <8 x i16>* %48, align 16
  %50 = bitcast i16* %43 to <8 x i16>*
  %51 = load <8 x i16>, <8 x i16>* %50, align 16
  %52 = sub <8 x i16> %49, %51
  %53 = sub <8 x i16> zeroinitializer, %52
  %54 = icmp slt <8 x i16> %52, zeroinitializer
  %55 = select <8 x i1> %54, <8 x i16> %53, <8 x i16> %52
  %56 = lshr <8 x i16> %55, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %57 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %56, <8 x i16> zeroinitializer) #5
  %58 = lshr <8 x i16> %57, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %59 = getelementptr inbounds i16, i16* %9, i64 24
  %60 = bitcast i16* %59 to <8 x i16>*
  %61 = load <8 x i16>, <8 x i16>* %60, align 16
  %62 = getelementptr inbounds i16, i16* %10, i64 24
  %63 = bitcast i16* %62 to <8 x i16>*
  %64 = load <8 x i16>, <8 x i16>* %63, align 16
  %65 = sub <8 x i16> %61, %64
  %66 = sub <8 x i16> zeroinitializer, %65
  %67 = icmp slt <8 x i16> %65, zeroinitializer
  %68 = select <8 x i1> %67, <8 x i16> %66, <8 x i16> %65
  %69 = lshr <8 x i16> %68, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %70 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %69, <8 x i16> zeroinitializer) #5
  %71 = lshr <8 x i16> %70, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %72 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %58, <8 x i16> %71) #5
  %73 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %72, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %74 = icmp slt <16 x i8> %73, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %75 = select <16 x i1> %74, <16 x i8> %73, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %76 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %75
  %77 = bitcast i8* %44 to <16 x i8>*
  store <16 x i8> %76, <16 x i8>* %77, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask16x16_SSE4ILb0EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %107, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %105, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %106, %7 ]
  %11 = phi i32 [ 5, %4 ], [ %108, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = sub <8 x i16> %13, %15
  %17 = sub <8 x i16> zeroinitializer, %16
  %18 = icmp slt <8 x i16> %16, zeroinitializer
  %19 = select <8 x i1> %18, <8 x i16> %17, <8 x i16> %16
  %20 = lshr <8 x i16> %19, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %21 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %20, <8 x i16> zeroinitializer) #5
  %22 = lshr <8 x i16> %21, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %23 = getelementptr inbounds i16, i16* %9, i64 8
  %24 = bitcast i16* %23 to <8 x i16>*
  %25 = load <8 x i16>, <8 x i16>* %24, align 16
  %26 = getelementptr inbounds i16, i16* %10, i64 8
  %27 = bitcast i16* %26 to <8 x i16>*
  %28 = load <8 x i16>, <8 x i16>* %27, align 16
  %29 = sub <8 x i16> %25, %28
  %30 = sub <8 x i16> zeroinitializer, %29
  %31 = icmp slt <8 x i16> %29, zeroinitializer
  %32 = select <8 x i1> %31, <8 x i16> %30, <8 x i16> %29
  %33 = lshr <8 x i16> %32, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %34 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %33, <8 x i16> zeroinitializer) #5
  %35 = lshr <8 x i16> %34, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %36 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %22, <8 x i16> %35) #5
  %37 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %36, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %38 = icmp slt <16 x i8> %37, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %39 = select <16 x i1> %38, <16 x i8> %37, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %40 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %40, align 16
  %41 = getelementptr inbounds i16, i16* %9, i64 16
  %42 = getelementptr inbounds i16, i16* %10, i64 16
  %43 = getelementptr inbounds i8, i8* %8, i64 %3
  %44 = bitcast i16* %41 to <8 x i16>*
  %45 = load <8 x i16>, <8 x i16>* %44, align 16
  %46 = bitcast i16* %42 to <8 x i16>*
  %47 = load <8 x i16>, <8 x i16>* %46, align 16
  %48 = sub <8 x i16> %45, %47
  %49 = sub <8 x i16> zeroinitializer, %48
  %50 = icmp slt <8 x i16> %48, zeroinitializer
  %51 = select <8 x i1> %50, <8 x i16> %49, <8 x i16> %48
  %52 = lshr <8 x i16> %51, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %53 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %52, <8 x i16> zeroinitializer) #5
  %54 = lshr <8 x i16> %53, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %55 = getelementptr inbounds i16, i16* %9, i64 24
  %56 = bitcast i16* %55 to <8 x i16>*
  %57 = load <8 x i16>, <8 x i16>* %56, align 16
  %58 = getelementptr inbounds i16, i16* %10, i64 24
  %59 = bitcast i16* %58 to <8 x i16>*
  %60 = load <8 x i16>, <8 x i16>* %59, align 16
  %61 = sub <8 x i16> %57, %60
  %62 = sub <8 x i16> zeroinitializer, %61
  %63 = icmp slt <8 x i16> %61, zeroinitializer
  %64 = select <8 x i1> %63, <8 x i16> %62, <8 x i16> %61
  %65 = lshr <8 x i16> %64, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %66 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %65, <8 x i16> zeroinitializer) #5
  %67 = lshr <8 x i16> %66, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %68 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %54, <8 x i16> %67) #5
  %69 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %68, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %70 = icmp slt <16 x i8> %69, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %71 = select <16 x i1> %70, <16 x i8> %69, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %72 = bitcast i8* %43 to <16 x i8>*
  store <16 x i8> %71, <16 x i8>* %72, align 16
  %73 = getelementptr inbounds i16, i16* %9, i64 32
  %74 = getelementptr inbounds i16, i16* %10, i64 32
  %75 = getelementptr inbounds i8, i8* %43, i64 %3
  %76 = bitcast i16* %73 to <8 x i16>*
  %77 = load <8 x i16>, <8 x i16>* %76, align 16
  %78 = bitcast i16* %74 to <8 x i16>*
  %79 = load <8 x i16>, <8 x i16>* %78, align 16
  %80 = sub <8 x i16> %77, %79
  %81 = sub <8 x i16> zeroinitializer, %80
  %82 = icmp slt <8 x i16> %80, zeroinitializer
  %83 = select <8 x i1> %82, <8 x i16> %81, <8 x i16> %80
  %84 = lshr <8 x i16> %83, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %85 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %84, <8 x i16> zeroinitializer) #5
  %86 = lshr <8 x i16> %85, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %87 = getelementptr inbounds i16, i16* %9, i64 40
  %88 = bitcast i16* %87 to <8 x i16>*
  %89 = load <8 x i16>, <8 x i16>* %88, align 16
  %90 = getelementptr inbounds i16, i16* %10, i64 40
  %91 = bitcast i16* %90 to <8 x i16>*
  %92 = load <8 x i16>, <8 x i16>* %91, align 16
  %93 = sub <8 x i16> %89, %92
  %94 = sub <8 x i16> zeroinitializer, %93
  %95 = icmp slt <8 x i16> %93, zeroinitializer
  %96 = select <8 x i1> %95, <8 x i16> %94, <8 x i16> %93
  %97 = lshr <8 x i16> %96, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %98 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %97, <8 x i16> zeroinitializer) #5
  %99 = lshr <8 x i16> %98, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %100 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %86, <8 x i16> %99) #5
  %101 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %100, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %102 = icmp slt <16 x i8> %101, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %103 = select <16 x i1> %102, <16 x i8> %101, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %104 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %103, <16 x i8>* %104, align 16
  %105 = getelementptr inbounds i16, i16* %9, i64 48
  %106 = getelementptr inbounds i16, i16* %10, i64 48
  %107 = getelementptr inbounds i8, i8* %75, i64 %3
  %108 = add nsw i32 %11, -1
  %109 = icmp eq i32 %108, 0
  br i1 %109, label %110, label %7

110:                                              ; preds = %7
  %111 = bitcast i16* %105 to <8 x i16>*
  %112 = load <8 x i16>, <8 x i16>* %111, align 16
  %113 = bitcast i16* %106 to <8 x i16>*
  %114 = load <8 x i16>, <8 x i16>* %113, align 16
  %115 = sub <8 x i16> %112, %114
  %116 = sub <8 x i16> zeroinitializer, %115
  %117 = icmp slt <8 x i16> %115, zeroinitializer
  %118 = select <8 x i1> %117, <8 x i16> %116, <8 x i16> %115
  %119 = lshr <8 x i16> %118, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %120 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %119, <8 x i16> zeroinitializer) #5
  %121 = lshr <8 x i16> %120, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %122 = getelementptr inbounds i16, i16* %9, i64 56
  %123 = bitcast i16* %122 to <8 x i16>*
  %124 = load <8 x i16>, <8 x i16>* %123, align 16
  %125 = getelementptr inbounds i16, i16* %10, i64 56
  %126 = bitcast i16* %125 to <8 x i16>*
  %127 = load <8 x i16>, <8 x i16>* %126, align 16
  %128 = sub <8 x i16> %124, %127
  %129 = sub <8 x i16> zeroinitializer, %128
  %130 = icmp slt <8 x i16> %128, zeroinitializer
  %131 = select <8 x i1> %130, <8 x i16> %129, <8 x i16> %128
  %132 = lshr <8 x i16> %131, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %133 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %132, <8 x i16> zeroinitializer) #5
  %134 = lshr <8 x i16> %133, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %135 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %121, <8 x i16> %134) #5
  %136 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %135, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %137 = icmp slt <16 x i8> %136, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %138 = select <16 x i1> %137, <16 x i8> %136, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %139 = bitcast i8* %107 to <16 x i8>*
  store <16 x i8> %138, <16 x i8>* %139, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask16x16_SSE4ILb1EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %110, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %108, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %109, %7 ]
  %11 = phi i32 [ 5, %4 ], [ %111, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = sub <8 x i16> %13, %15
  %17 = sub <8 x i16> zeroinitializer, %16
  %18 = icmp slt <8 x i16> %16, zeroinitializer
  %19 = select <8 x i1> %18, <8 x i16> %17, <8 x i16> %16
  %20 = lshr <8 x i16> %19, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %21 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %20, <8 x i16> zeroinitializer) #5
  %22 = lshr <8 x i16> %21, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %23 = getelementptr inbounds i16, i16* %9, i64 8
  %24 = bitcast i16* %23 to <8 x i16>*
  %25 = load <8 x i16>, <8 x i16>* %24, align 16
  %26 = getelementptr inbounds i16, i16* %10, i64 8
  %27 = bitcast i16* %26 to <8 x i16>*
  %28 = load <8 x i16>, <8 x i16>* %27, align 16
  %29 = sub <8 x i16> %25, %28
  %30 = sub <8 x i16> zeroinitializer, %29
  %31 = icmp slt <8 x i16> %29, zeroinitializer
  %32 = select <8 x i1> %31, <8 x i16> %30, <8 x i16> %29
  %33 = lshr <8 x i16> %32, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %34 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %33, <8 x i16> zeroinitializer) #5
  %35 = lshr <8 x i16> %34, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %36 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %22, <8 x i16> %35) #5
  %37 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %36, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %38 = icmp slt <16 x i8> %37, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %39 = select <16 x i1> %38, <16 x i8> %37, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %40 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %39
  %41 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %40, <16 x i8>* %41, align 16
  %42 = getelementptr inbounds i16, i16* %9, i64 16
  %43 = getelementptr inbounds i16, i16* %10, i64 16
  %44 = getelementptr inbounds i8, i8* %8, i64 %3
  %45 = bitcast i16* %42 to <8 x i16>*
  %46 = load <8 x i16>, <8 x i16>* %45, align 16
  %47 = bitcast i16* %43 to <8 x i16>*
  %48 = load <8 x i16>, <8 x i16>* %47, align 16
  %49 = sub <8 x i16> %46, %48
  %50 = sub <8 x i16> zeroinitializer, %49
  %51 = icmp slt <8 x i16> %49, zeroinitializer
  %52 = select <8 x i1> %51, <8 x i16> %50, <8 x i16> %49
  %53 = lshr <8 x i16> %52, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %54 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %53, <8 x i16> zeroinitializer) #5
  %55 = lshr <8 x i16> %54, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %56 = getelementptr inbounds i16, i16* %9, i64 24
  %57 = bitcast i16* %56 to <8 x i16>*
  %58 = load <8 x i16>, <8 x i16>* %57, align 16
  %59 = getelementptr inbounds i16, i16* %10, i64 24
  %60 = bitcast i16* %59 to <8 x i16>*
  %61 = load <8 x i16>, <8 x i16>* %60, align 16
  %62 = sub <8 x i16> %58, %61
  %63 = sub <8 x i16> zeroinitializer, %62
  %64 = icmp slt <8 x i16> %62, zeroinitializer
  %65 = select <8 x i1> %64, <8 x i16> %63, <8 x i16> %62
  %66 = lshr <8 x i16> %65, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %67 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %66, <8 x i16> zeroinitializer) #5
  %68 = lshr <8 x i16> %67, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %69 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %55, <8 x i16> %68) #5
  %70 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %69, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %71 = icmp slt <16 x i8> %70, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %72 = select <16 x i1> %71, <16 x i8> %70, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %73 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %72
  %74 = bitcast i8* %44 to <16 x i8>*
  store <16 x i8> %73, <16 x i8>* %74, align 16
  %75 = getelementptr inbounds i16, i16* %9, i64 32
  %76 = getelementptr inbounds i16, i16* %10, i64 32
  %77 = getelementptr inbounds i8, i8* %44, i64 %3
  %78 = bitcast i16* %75 to <8 x i16>*
  %79 = load <8 x i16>, <8 x i16>* %78, align 16
  %80 = bitcast i16* %76 to <8 x i16>*
  %81 = load <8 x i16>, <8 x i16>* %80, align 16
  %82 = sub <8 x i16> %79, %81
  %83 = sub <8 x i16> zeroinitializer, %82
  %84 = icmp slt <8 x i16> %82, zeroinitializer
  %85 = select <8 x i1> %84, <8 x i16> %83, <8 x i16> %82
  %86 = lshr <8 x i16> %85, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %87 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %86, <8 x i16> zeroinitializer) #5
  %88 = lshr <8 x i16> %87, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %89 = getelementptr inbounds i16, i16* %9, i64 40
  %90 = bitcast i16* %89 to <8 x i16>*
  %91 = load <8 x i16>, <8 x i16>* %90, align 16
  %92 = getelementptr inbounds i16, i16* %10, i64 40
  %93 = bitcast i16* %92 to <8 x i16>*
  %94 = load <8 x i16>, <8 x i16>* %93, align 16
  %95 = sub <8 x i16> %91, %94
  %96 = sub <8 x i16> zeroinitializer, %95
  %97 = icmp slt <8 x i16> %95, zeroinitializer
  %98 = select <8 x i1> %97, <8 x i16> %96, <8 x i16> %95
  %99 = lshr <8 x i16> %98, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %100 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %99, <8 x i16> zeroinitializer) #5
  %101 = lshr <8 x i16> %100, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %102 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %88, <8 x i16> %101) #5
  %103 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %102, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %104 = icmp slt <16 x i8> %103, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %105 = select <16 x i1> %104, <16 x i8> %103, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %106 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %105
  %107 = bitcast i8* %77 to <16 x i8>*
  store <16 x i8> %106, <16 x i8>* %107, align 16
  %108 = getelementptr inbounds i16, i16* %9, i64 48
  %109 = getelementptr inbounds i16, i16* %10, i64 48
  %110 = getelementptr inbounds i8, i8* %77, i64 %3
  %111 = add nsw i32 %11, -1
  %112 = icmp eq i32 %111, 0
  br i1 %112, label %113, label %7

113:                                              ; preds = %7
  %114 = bitcast i16* %108 to <8 x i16>*
  %115 = load <8 x i16>, <8 x i16>* %114, align 16
  %116 = bitcast i16* %109 to <8 x i16>*
  %117 = load <8 x i16>, <8 x i16>* %116, align 16
  %118 = sub <8 x i16> %115, %117
  %119 = sub <8 x i16> zeroinitializer, %118
  %120 = icmp slt <8 x i16> %118, zeroinitializer
  %121 = select <8 x i1> %120, <8 x i16> %119, <8 x i16> %118
  %122 = lshr <8 x i16> %121, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %123 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %122, <8 x i16> zeroinitializer) #5
  %124 = lshr <8 x i16> %123, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %125 = getelementptr inbounds i16, i16* %9, i64 56
  %126 = bitcast i16* %125 to <8 x i16>*
  %127 = load <8 x i16>, <8 x i16>* %126, align 16
  %128 = getelementptr inbounds i16, i16* %10, i64 56
  %129 = bitcast i16* %128 to <8 x i16>*
  %130 = load <8 x i16>, <8 x i16>* %129, align 16
  %131 = sub <8 x i16> %127, %130
  %132 = sub <8 x i16> zeroinitializer, %131
  %133 = icmp slt <8 x i16> %131, zeroinitializer
  %134 = select <8 x i1> %133, <8 x i16> %132, <8 x i16> %131
  %135 = lshr <8 x i16> %134, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %136 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %135, <8 x i16> zeroinitializer) #5
  %137 = lshr <8 x i16> %136, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %138 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %124, <8 x i16> %137) #5
  %139 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %138, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %140 = icmp slt <16 x i8> %139, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %141 = select <16 x i1> %140, <16 x i8> %139, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %142 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %141
  %143 = bitcast i8* %110 to <16 x i8>*
  store <16 x i8> %142, <16 x i8>* %143, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask16x32_SSE4ILb0EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %171, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %169, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %170, %7 ]
  %11 = phi i32 [ 6, %4 ], [ %172, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = sub <8 x i16> %13, %15
  %17 = sub <8 x i16> zeroinitializer, %16
  %18 = icmp slt <8 x i16> %16, zeroinitializer
  %19 = select <8 x i1> %18, <8 x i16> %17, <8 x i16> %16
  %20 = lshr <8 x i16> %19, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %21 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %20, <8 x i16> zeroinitializer) #5
  %22 = lshr <8 x i16> %21, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %23 = getelementptr inbounds i16, i16* %9, i64 8
  %24 = bitcast i16* %23 to <8 x i16>*
  %25 = load <8 x i16>, <8 x i16>* %24, align 16
  %26 = getelementptr inbounds i16, i16* %10, i64 8
  %27 = bitcast i16* %26 to <8 x i16>*
  %28 = load <8 x i16>, <8 x i16>* %27, align 16
  %29 = sub <8 x i16> %25, %28
  %30 = sub <8 x i16> zeroinitializer, %29
  %31 = icmp slt <8 x i16> %29, zeroinitializer
  %32 = select <8 x i1> %31, <8 x i16> %30, <8 x i16> %29
  %33 = lshr <8 x i16> %32, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %34 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %33, <8 x i16> zeroinitializer) #5
  %35 = lshr <8 x i16> %34, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %36 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %22, <8 x i16> %35) #5
  %37 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %36, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %38 = icmp slt <16 x i8> %37, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %39 = select <16 x i1> %38, <16 x i8> %37, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %40 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %40, align 16
  %41 = getelementptr inbounds i16, i16* %9, i64 16
  %42 = getelementptr inbounds i16, i16* %10, i64 16
  %43 = getelementptr inbounds i8, i8* %8, i64 %3
  %44 = bitcast i16* %41 to <8 x i16>*
  %45 = load <8 x i16>, <8 x i16>* %44, align 16
  %46 = bitcast i16* %42 to <8 x i16>*
  %47 = load <8 x i16>, <8 x i16>* %46, align 16
  %48 = sub <8 x i16> %45, %47
  %49 = sub <8 x i16> zeroinitializer, %48
  %50 = icmp slt <8 x i16> %48, zeroinitializer
  %51 = select <8 x i1> %50, <8 x i16> %49, <8 x i16> %48
  %52 = lshr <8 x i16> %51, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %53 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %52, <8 x i16> zeroinitializer) #5
  %54 = lshr <8 x i16> %53, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %55 = getelementptr inbounds i16, i16* %9, i64 24
  %56 = bitcast i16* %55 to <8 x i16>*
  %57 = load <8 x i16>, <8 x i16>* %56, align 16
  %58 = getelementptr inbounds i16, i16* %10, i64 24
  %59 = bitcast i16* %58 to <8 x i16>*
  %60 = load <8 x i16>, <8 x i16>* %59, align 16
  %61 = sub <8 x i16> %57, %60
  %62 = sub <8 x i16> zeroinitializer, %61
  %63 = icmp slt <8 x i16> %61, zeroinitializer
  %64 = select <8 x i1> %63, <8 x i16> %62, <8 x i16> %61
  %65 = lshr <8 x i16> %64, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %66 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %65, <8 x i16> zeroinitializer) #5
  %67 = lshr <8 x i16> %66, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %68 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %54, <8 x i16> %67) #5
  %69 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %68, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %70 = icmp slt <16 x i8> %69, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %71 = select <16 x i1> %70, <16 x i8> %69, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %72 = bitcast i8* %43 to <16 x i8>*
  store <16 x i8> %71, <16 x i8>* %72, align 16
  %73 = getelementptr inbounds i16, i16* %9, i64 32
  %74 = getelementptr inbounds i16, i16* %10, i64 32
  %75 = getelementptr inbounds i8, i8* %43, i64 %3
  %76 = bitcast i16* %73 to <8 x i16>*
  %77 = load <8 x i16>, <8 x i16>* %76, align 16
  %78 = bitcast i16* %74 to <8 x i16>*
  %79 = load <8 x i16>, <8 x i16>* %78, align 16
  %80 = sub <8 x i16> %77, %79
  %81 = sub <8 x i16> zeroinitializer, %80
  %82 = icmp slt <8 x i16> %80, zeroinitializer
  %83 = select <8 x i1> %82, <8 x i16> %81, <8 x i16> %80
  %84 = lshr <8 x i16> %83, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %85 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %84, <8 x i16> zeroinitializer) #5
  %86 = lshr <8 x i16> %85, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %87 = getelementptr inbounds i16, i16* %9, i64 40
  %88 = bitcast i16* %87 to <8 x i16>*
  %89 = load <8 x i16>, <8 x i16>* %88, align 16
  %90 = getelementptr inbounds i16, i16* %10, i64 40
  %91 = bitcast i16* %90 to <8 x i16>*
  %92 = load <8 x i16>, <8 x i16>* %91, align 16
  %93 = sub <8 x i16> %89, %92
  %94 = sub <8 x i16> zeroinitializer, %93
  %95 = icmp slt <8 x i16> %93, zeroinitializer
  %96 = select <8 x i1> %95, <8 x i16> %94, <8 x i16> %93
  %97 = lshr <8 x i16> %96, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %98 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %97, <8 x i16> zeroinitializer) #5
  %99 = lshr <8 x i16> %98, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %100 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %86, <8 x i16> %99) #5
  %101 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %100, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %102 = icmp slt <16 x i8> %101, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %103 = select <16 x i1> %102, <16 x i8> %101, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %104 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %103, <16 x i8>* %104, align 16
  %105 = getelementptr inbounds i16, i16* %9, i64 48
  %106 = getelementptr inbounds i16, i16* %10, i64 48
  %107 = getelementptr inbounds i8, i8* %75, i64 %3
  %108 = bitcast i16* %105 to <8 x i16>*
  %109 = load <8 x i16>, <8 x i16>* %108, align 16
  %110 = bitcast i16* %106 to <8 x i16>*
  %111 = load <8 x i16>, <8 x i16>* %110, align 16
  %112 = sub <8 x i16> %109, %111
  %113 = sub <8 x i16> zeroinitializer, %112
  %114 = icmp slt <8 x i16> %112, zeroinitializer
  %115 = select <8 x i1> %114, <8 x i16> %113, <8 x i16> %112
  %116 = lshr <8 x i16> %115, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %117 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %116, <8 x i16> zeroinitializer) #5
  %118 = lshr <8 x i16> %117, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %119 = getelementptr inbounds i16, i16* %9, i64 56
  %120 = bitcast i16* %119 to <8 x i16>*
  %121 = load <8 x i16>, <8 x i16>* %120, align 16
  %122 = getelementptr inbounds i16, i16* %10, i64 56
  %123 = bitcast i16* %122 to <8 x i16>*
  %124 = load <8 x i16>, <8 x i16>* %123, align 16
  %125 = sub <8 x i16> %121, %124
  %126 = sub <8 x i16> zeroinitializer, %125
  %127 = icmp slt <8 x i16> %125, zeroinitializer
  %128 = select <8 x i1> %127, <8 x i16> %126, <8 x i16> %125
  %129 = lshr <8 x i16> %128, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %130 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %129, <8 x i16> zeroinitializer) #5
  %131 = lshr <8 x i16> %130, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %132 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %118, <8 x i16> %131) #5
  %133 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %132, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %134 = icmp slt <16 x i8> %133, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %135 = select <16 x i1> %134, <16 x i8> %133, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %136 = bitcast i8* %107 to <16 x i8>*
  store <16 x i8> %135, <16 x i8>* %136, align 16
  %137 = getelementptr inbounds i16, i16* %9, i64 64
  %138 = getelementptr inbounds i16, i16* %10, i64 64
  %139 = getelementptr inbounds i8, i8* %107, i64 %3
  %140 = bitcast i16* %137 to <8 x i16>*
  %141 = load <8 x i16>, <8 x i16>* %140, align 16
  %142 = bitcast i16* %138 to <8 x i16>*
  %143 = load <8 x i16>, <8 x i16>* %142, align 16
  %144 = sub <8 x i16> %141, %143
  %145 = sub <8 x i16> zeroinitializer, %144
  %146 = icmp slt <8 x i16> %144, zeroinitializer
  %147 = select <8 x i1> %146, <8 x i16> %145, <8 x i16> %144
  %148 = lshr <8 x i16> %147, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %149 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %148, <8 x i16> zeroinitializer) #5
  %150 = lshr <8 x i16> %149, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %151 = getelementptr inbounds i16, i16* %9, i64 72
  %152 = bitcast i16* %151 to <8 x i16>*
  %153 = load <8 x i16>, <8 x i16>* %152, align 16
  %154 = getelementptr inbounds i16, i16* %10, i64 72
  %155 = bitcast i16* %154 to <8 x i16>*
  %156 = load <8 x i16>, <8 x i16>* %155, align 16
  %157 = sub <8 x i16> %153, %156
  %158 = sub <8 x i16> zeroinitializer, %157
  %159 = icmp slt <8 x i16> %157, zeroinitializer
  %160 = select <8 x i1> %159, <8 x i16> %158, <8 x i16> %157
  %161 = lshr <8 x i16> %160, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %162 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %161, <8 x i16> zeroinitializer) #5
  %163 = lshr <8 x i16> %162, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %164 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %150, <8 x i16> %163) #5
  %165 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %164, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %166 = icmp slt <16 x i8> %165, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %167 = select <16 x i1> %166, <16 x i8> %165, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %168 = bitcast i8* %139 to <16 x i8>*
  store <16 x i8> %167, <16 x i8>* %168, align 16
  %169 = getelementptr inbounds i16, i16* %9, i64 80
  %170 = getelementptr inbounds i16, i16* %10, i64 80
  %171 = getelementptr inbounds i8, i8* %139, i64 %3
  %172 = add nsw i32 %11, -1
  %173 = icmp eq i32 %172, 0
  br i1 %173, label %174, label %7

174:                                              ; preds = %7
  %175 = bitcast i16* %169 to <8 x i16>*
  %176 = load <8 x i16>, <8 x i16>* %175, align 16
  %177 = bitcast i16* %170 to <8 x i16>*
  %178 = load <8 x i16>, <8 x i16>* %177, align 16
  %179 = sub <8 x i16> %176, %178
  %180 = sub <8 x i16> zeroinitializer, %179
  %181 = icmp slt <8 x i16> %179, zeroinitializer
  %182 = select <8 x i1> %181, <8 x i16> %180, <8 x i16> %179
  %183 = lshr <8 x i16> %182, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %184 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %183, <8 x i16> zeroinitializer) #5
  %185 = lshr <8 x i16> %184, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %186 = getelementptr inbounds i16, i16* %9, i64 88
  %187 = bitcast i16* %186 to <8 x i16>*
  %188 = load <8 x i16>, <8 x i16>* %187, align 16
  %189 = getelementptr inbounds i16, i16* %10, i64 88
  %190 = bitcast i16* %189 to <8 x i16>*
  %191 = load <8 x i16>, <8 x i16>* %190, align 16
  %192 = sub <8 x i16> %188, %191
  %193 = sub <8 x i16> zeroinitializer, %192
  %194 = icmp slt <8 x i16> %192, zeroinitializer
  %195 = select <8 x i1> %194, <8 x i16> %193, <8 x i16> %192
  %196 = lshr <8 x i16> %195, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %197 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %196, <8 x i16> zeroinitializer) #5
  %198 = lshr <8 x i16> %197, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %199 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %185, <8 x i16> %198) #5
  %200 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %199, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %201 = icmp slt <16 x i8> %200, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %202 = select <16 x i1> %201, <16 x i8> %200, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %203 = bitcast i8* %171 to <16 x i8>*
  store <16 x i8> %202, <16 x i8>* %203, align 16
  %204 = getelementptr inbounds i16, i16* %9, i64 96
  %205 = getelementptr inbounds i16, i16* %10, i64 96
  %206 = getelementptr inbounds i8, i8* %171, i64 %3
  %207 = bitcast i16* %204 to <8 x i16>*
  %208 = load <8 x i16>, <8 x i16>* %207, align 16
  %209 = bitcast i16* %205 to <8 x i16>*
  %210 = load <8 x i16>, <8 x i16>* %209, align 16
  %211 = sub <8 x i16> %208, %210
  %212 = sub <8 x i16> zeroinitializer, %211
  %213 = icmp slt <8 x i16> %211, zeroinitializer
  %214 = select <8 x i1> %213, <8 x i16> %212, <8 x i16> %211
  %215 = lshr <8 x i16> %214, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %216 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %215, <8 x i16> zeroinitializer) #5
  %217 = lshr <8 x i16> %216, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %218 = getelementptr inbounds i16, i16* %9, i64 104
  %219 = bitcast i16* %218 to <8 x i16>*
  %220 = load <8 x i16>, <8 x i16>* %219, align 16
  %221 = getelementptr inbounds i16, i16* %10, i64 104
  %222 = bitcast i16* %221 to <8 x i16>*
  %223 = load <8 x i16>, <8 x i16>* %222, align 16
  %224 = sub <8 x i16> %220, %223
  %225 = sub <8 x i16> zeroinitializer, %224
  %226 = icmp slt <8 x i16> %224, zeroinitializer
  %227 = select <8 x i1> %226, <8 x i16> %225, <8 x i16> %224
  %228 = lshr <8 x i16> %227, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %229 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %228, <8 x i16> zeroinitializer) #5
  %230 = lshr <8 x i16> %229, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %231 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %217, <8 x i16> %230) #5
  %232 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %231, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %233 = icmp slt <16 x i8> %232, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %234 = select <16 x i1> %233, <16 x i8> %232, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %235 = bitcast i8* %206 to <16 x i8>*
  store <16 x i8> %234, <16 x i8>* %235, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask16x32_SSE4ILb1EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %176, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %174, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %175, %7 ]
  %11 = phi i32 [ 6, %4 ], [ %177, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = sub <8 x i16> %13, %15
  %17 = sub <8 x i16> zeroinitializer, %16
  %18 = icmp slt <8 x i16> %16, zeroinitializer
  %19 = select <8 x i1> %18, <8 x i16> %17, <8 x i16> %16
  %20 = lshr <8 x i16> %19, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %21 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %20, <8 x i16> zeroinitializer) #5
  %22 = lshr <8 x i16> %21, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %23 = getelementptr inbounds i16, i16* %9, i64 8
  %24 = bitcast i16* %23 to <8 x i16>*
  %25 = load <8 x i16>, <8 x i16>* %24, align 16
  %26 = getelementptr inbounds i16, i16* %10, i64 8
  %27 = bitcast i16* %26 to <8 x i16>*
  %28 = load <8 x i16>, <8 x i16>* %27, align 16
  %29 = sub <8 x i16> %25, %28
  %30 = sub <8 x i16> zeroinitializer, %29
  %31 = icmp slt <8 x i16> %29, zeroinitializer
  %32 = select <8 x i1> %31, <8 x i16> %30, <8 x i16> %29
  %33 = lshr <8 x i16> %32, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %34 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %33, <8 x i16> zeroinitializer) #5
  %35 = lshr <8 x i16> %34, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %36 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %22, <8 x i16> %35) #5
  %37 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %36, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %38 = icmp slt <16 x i8> %37, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %39 = select <16 x i1> %38, <16 x i8> %37, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %40 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %39
  %41 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %40, <16 x i8>* %41, align 16
  %42 = getelementptr inbounds i16, i16* %9, i64 16
  %43 = getelementptr inbounds i16, i16* %10, i64 16
  %44 = getelementptr inbounds i8, i8* %8, i64 %3
  %45 = bitcast i16* %42 to <8 x i16>*
  %46 = load <8 x i16>, <8 x i16>* %45, align 16
  %47 = bitcast i16* %43 to <8 x i16>*
  %48 = load <8 x i16>, <8 x i16>* %47, align 16
  %49 = sub <8 x i16> %46, %48
  %50 = sub <8 x i16> zeroinitializer, %49
  %51 = icmp slt <8 x i16> %49, zeroinitializer
  %52 = select <8 x i1> %51, <8 x i16> %50, <8 x i16> %49
  %53 = lshr <8 x i16> %52, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %54 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %53, <8 x i16> zeroinitializer) #5
  %55 = lshr <8 x i16> %54, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %56 = getelementptr inbounds i16, i16* %9, i64 24
  %57 = bitcast i16* %56 to <8 x i16>*
  %58 = load <8 x i16>, <8 x i16>* %57, align 16
  %59 = getelementptr inbounds i16, i16* %10, i64 24
  %60 = bitcast i16* %59 to <8 x i16>*
  %61 = load <8 x i16>, <8 x i16>* %60, align 16
  %62 = sub <8 x i16> %58, %61
  %63 = sub <8 x i16> zeroinitializer, %62
  %64 = icmp slt <8 x i16> %62, zeroinitializer
  %65 = select <8 x i1> %64, <8 x i16> %63, <8 x i16> %62
  %66 = lshr <8 x i16> %65, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %67 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %66, <8 x i16> zeroinitializer) #5
  %68 = lshr <8 x i16> %67, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %69 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %55, <8 x i16> %68) #5
  %70 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %69, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %71 = icmp slt <16 x i8> %70, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %72 = select <16 x i1> %71, <16 x i8> %70, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %73 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %72
  %74 = bitcast i8* %44 to <16 x i8>*
  store <16 x i8> %73, <16 x i8>* %74, align 16
  %75 = getelementptr inbounds i16, i16* %9, i64 32
  %76 = getelementptr inbounds i16, i16* %10, i64 32
  %77 = getelementptr inbounds i8, i8* %44, i64 %3
  %78 = bitcast i16* %75 to <8 x i16>*
  %79 = load <8 x i16>, <8 x i16>* %78, align 16
  %80 = bitcast i16* %76 to <8 x i16>*
  %81 = load <8 x i16>, <8 x i16>* %80, align 16
  %82 = sub <8 x i16> %79, %81
  %83 = sub <8 x i16> zeroinitializer, %82
  %84 = icmp slt <8 x i16> %82, zeroinitializer
  %85 = select <8 x i1> %84, <8 x i16> %83, <8 x i16> %82
  %86 = lshr <8 x i16> %85, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %87 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %86, <8 x i16> zeroinitializer) #5
  %88 = lshr <8 x i16> %87, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %89 = getelementptr inbounds i16, i16* %9, i64 40
  %90 = bitcast i16* %89 to <8 x i16>*
  %91 = load <8 x i16>, <8 x i16>* %90, align 16
  %92 = getelementptr inbounds i16, i16* %10, i64 40
  %93 = bitcast i16* %92 to <8 x i16>*
  %94 = load <8 x i16>, <8 x i16>* %93, align 16
  %95 = sub <8 x i16> %91, %94
  %96 = sub <8 x i16> zeroinitializer, %95
  %97 = icmp slt <8 x i16> %95, zeroinitializer
  %98 = select <8 x i1> %97, <8 x i16> %96, <8 x i16> %95
  %99 = lshr <8 x i16> %98, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %100 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %99, <8 x i16> zeroinitializer) #5
  %101 = lshr <8 x i16> %100, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %102 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %88, <8 x i16> %101) #5
  %103 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %102, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %104 = icmp slt <16 x i8> %103, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %105 = select <16 x i1> %104, <16 x i8> %103, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %106 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %105
  %107 = bitcast i8* %77 to <16 x i8>*
  store <16 x i8> %106, <16 x i8>* %107, align 16
  %108 = getelementptr inbounds i16, i16* %9, i64 48
  %109 = getelementptr inbounds i16, i16* %10, i64 48
  %110 = getelementptr inbounds i8, i8* %77, i64 %3
  %111 = bitcast i16* %108 to <8 x i16>*
  %112 = load <8 x i16>, <8 x i16>* %111, align 16
  %113 = bitcast i16* %109 to <8 x i16>*
  %114 = load <8 x i16>, <8 x i16>* %113, align 16
  %115 = sub <8 x i16> %112, %114
  %116 = sub <8 x i16> zeroinitializer, %115
  %117 = icmp slt <8 x i16> %115, zeroinitializer
  %118 = select <8 x i1> %117, <8 x i16> %116, <8 x i16> %115
  %119 = lshr <8 x i16> %118, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %120 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %119, <8 x i16> zeroinitializer) #5
  %121 = lshr <8 x i16> %120, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %122 = getelementptr inbounds i16, i16* %9, i64 56
  %123 = bitcast i16* %122 to <8 x i16>*
  %124 = load <8 x i16>, <8 x i16>* %123, align 16
  %125 = getelementptr inbounds i16, i16* %10, i64 56
  %126 = bitcast i16* %125 to <8 x i16>*
  %127 = load <8 x i16>, <8 x i16>* %126, align 16
  %128 = sub <8 x i16> %124, %127
  %129 = sub <8 x i16> zeroinitializer, %128
  %130 = icmp slt <8 x i16> %128, zeroinitializer
  %131 = select <8 x i1> %130, <8 x i16> %129, <8 x i16> %128
  %132 = lshr <8 x i16> %131, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %133 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %132, <8 x i16> zeroinitializer) #5
  %134 = lshr <8 x i16> %133, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %135 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %121, <8 x i16> %134) #5
  %136 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %135, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %137 = icmp slt <16 x i8> %136, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %138 = select <16 x i1> %137, <16 x i8> %136, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %139 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %138
  %140 = bitcast i8* %110 to <16 x i8>*
  store <16 x i8> %139, <16 x i8>* %140, align 16
  %141 = getelementptr inbounds i16, i16* %9, i64 64
  %142 = getelementptr inbounds i16, i16* %10, i64 64
  %143 = getelementptr inbounds i8, i8* %110, i64 %3
  %144 = bitcast i16* %141 to <8 x i16>*
  %145 = load <8 x i16>, <8 x i16>* %144, align 16
  %146 = bitcast i16* %142 to <8 x i16>*
  %147 = load <8 x i16>, <8 x i16>* %146, align 16
  %148 = sub <8 x i16> %145, %147
  %149 = sub <8 x i16> zeroinitializer, %148
  %150 = icmp slt <8 x i16> %148, zeroinitializer
  %151 = select <8 x i1> %150, <8 x i16> %149, <8 x i16> %148
  %152 = lshr <8 x i16> %151, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %153 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %152, <8 x i16> zeroinitializer) #5
  %154 = lshr <8 x i16> %153, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %155 = getelementptr inbounds i16, i16* %9, i64 72
  %156 = bitcast i16* %155 to <8 x i16>*
  %157 = load <8 x i16>, <8 x i16>* %156, align 16
  %158 = getelementptr inbounds i16, i16* %10, i64 72
  %159 = bitcast i16* %158 to <8 x i16>*
  %160 = load <8 x i16>, <8 x i16>* %159, align 16
  %161 = sub <8 x i16> %157, %160
  %162 = sub <8 x i16> zeroinitializer, %161
  %163 = icmp slt <8 x i16> %161, zeroinitializer
  %164 = select <8 x i1> %163, <8 x i16> %162, <8 x i16> %161
  %165 = lshr <8 x i16> %164, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %166 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %165, <8 x i16> zeroinitializer) #5
  %167 = lshr <8 x i16> %166, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %168 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %154, <8 x i16> %167) #5
  %169 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %168, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %170 = icmp slt <16 x i8> %169, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %171 = select <16 x i1> %170, <16 x i8> %169, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %172 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %171
  %173 = bitcast i8* %143 to <16 x i8>*
  store <16 x i8> %172, <16 x i8>* %173, align 16
  %174 = getelementptr inbounds i16, i16* %9, i64 80
  %175 = getelementptr inbounds i16, i16* %10, i64 80
  %176 = getelementptr inbounds i8, i8* %143, i64 %3
  %177 = add nsw i32 %11, -1
  %178 = icmp eq i32 %177, 0
  br i1 %178, label %179, label %7

179:                                              ; preds = %7
  %180 = bitcast i16* %174 to <8 x i16>*
  %181 = load <8 x i16>, <8 x i16>* %180, align 16
  %182 = bitcast i16* %175 to <8 x i16>*
  %183 = load <8 x i16>, <8 x i16>* %182, align 16
  %184 = sub <8 x i16> %181, %183
  %185 = sub <8 x i16> zeroinitializer, %184
  %186 = icmp slt <8 x i16> %184, zeroinitializer
  %187 = select <8 x i1> %186, <8 x i16> %185, <8 x i16> %184
  %188 = lshr <8 x i16> %187, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %189 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %188, <8 x i16> zeroinitializer) #5
  %190 = lshr <8 x i16> %189, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %191 = getelementptr inbounds i16, i16* %9, i64 88
  %192 = bitcast i16* %191 to <8 x i16>*
  %193 = load <8 x i16>, <8 x i16>* %192, align 16
  %194 = getelementptr inbounds i16, i16* %10, i64 88
  %195 = bitcast i16* %194 to <8 x i16>*
  %196 = load <8 x i16>, <8 x i16>* %195, align 16
  %197 = sub <8 x i16> %193, %196
  %198 = sub <8 x i16> zeroinitializer, %197
  %199 = icmp slt <8 x i16> %197, zeroinitializer
  %200 = select <8 x i1> %199, <8 x i16> %198, <8 x i16> %197
  %201 = lshr <8 x i16> %200, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %202 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %201, <8 x i16> zeroinitializer) #5
  %203 = lshr <8 x i16> %202, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %204 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %190, <8 x i16> %203) #5
  %205 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %204, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %206 = icmp slt <16 x i8> %205, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %207 = select <16 x i1> %206, <16 x i8> %205, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %208 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %207
  %209 = bitcast i8* %176 to <16 x i8>*
  store <16 x i8> %208, <16 x i8>* %209, align 16
  %210 = getelementptr inbounds i16, i16* %9, i64 96
  %211 = getelementptr inbounds i16, i16* %10, i64 96
  %212 = getelementptr inbounds i8, i8* %176, i64 %3
  %213 = bitcast i16* %210 to <8 x i16>*
  %214 = load <8 x i16>, <8 x i16>* %213, align 16
  %215 = bitcast i16* %211 to <8 x i16>*
  %216 = load <8 x i16>, <8 x i16>* %215, align 16
  %217 = sub <8 x i16> %214, %216
  %218 = sub <8 x i16> zeroinitializer, %217
  %219 = icmp slt <8 x i16> %217, zeroinitializer
  %220 = select <8 x i1> %219, <8 x i16> %218, <8 x i16> %217
  %221 = lshr <8 x i16> %220, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %222 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %221, <8 x i16> zeroinitializer) #5
  %223 = lshr <8 x i16> %222, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %224 = getelementptr inbounds i16, i16* %9, i64 104
  %225 = bitcast i16* %224 to <8 x i16>*
  %226 = load <8 x i16>, <8 x i16>* %225, align 16
  %227 = getelementptr inbounds i16, i16* %10, i64 104
  %228 = bitcast i16* %227 to <8 x i16>*
  %229 = load <8 x i16>, <8 x i16>* %228, align 16
  %230 = sub <8 x i16> %226, %229
  %231 = sub <8 x i16> zeroinitializer, %230
  %232 = icmp slt <8 x i16> %230, zeroinitializer
  %233 = select <8 x i1> %232, <8 x i16> %231, <8 x i16> %230
  %234 = lshr <8 x i16> %233, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %235 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %234, <8 x i16> zeroinitializer) #5
  %236 = lshr <8 x i16> %235, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %237 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %223, <8 x i16> %236) #5
  %238 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %237, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %239 = icmp slt <16 x i8> %238, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %240 = select <16 x i1> %239, <16 x i8> %238, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %241 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %240
  %242 = bitcast i8* %212 to <16 x i8>*
  store <16 x i8> %241, <16 x i8>* %242, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask16x64_SSE4ILb0EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %107, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %105, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %106, %7 ]
  %11 = phi i32 [ 21, %4 ], [ %108, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = sub <8 x i16> %13, %15
  %17 = sub <8 x i16> zeroinitializer, %16
  %18 = icmp slt <8 x i16> %16, zeroinitializer
  %19 = select <8 x i1> %18, <8 x i16> %17, <8 x i16> %16
  %20 = lshr <8 x i16> %19, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %21 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %20, <8 x i16> zeroinitializer) #5
  %22 = lshr <8 x i16> %21, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %23 = getelementptr inbounds i16, i16* %9, i64 8
  %24 = bitcast i16* %23 to <8 x i16>*
  %25 = load <8 x i16>, <8 x i16>* %24, align 16
  %26 = getelementptr inbounds i16, i16* %10, i64 8
  %27 = bitcast i16* %26 to <8 x i16>*
  %28 = load <8 x i16>, <8 x i16>* %27, align 16
  %29 = sub <8 x i16> %25, %28
  %30 = sub <8 x i16> zeroinitializer, %29
  %31 = icmp slt <8 x i16> %29, zeroinitializer
  %32 = select <8 x i1> %31, <8 x i16> %30, <8 x i16> %29
  %33 = lshr <8 x i16> %32, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %34 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %33, <8 x i16> zeroinitializer) #5
  %35 = lshr <8 x i16> %34, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %36 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %22, <8 x i16> %35) #5
  %37 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %36, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %38 = icmp slt <16 x i8> %37, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %39 = select <16 x i1> %38, <16 x i8> %37, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %40 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %40, align 16
  %41 = getelementptr inbounds i16, i16* %9, i64 16
  %42 = getelementptr inbounds i16, i16* %10, i64 16
  %43 = getelementptr inbounds i8, i8* %8, i64 %3
  %44 = bitcast i16* %41 to <8 x i16>*
  %45 = load <8 x i16>, <8 x i16>* %44, align 16
  %46 = bitcast i16* %42 to <8 x i16>*
  %47 = load <8 x i16>, <8 x i16>* %46, align 16
  %48 = sub <8 x i16> %45, %47
  %49 = sub <8 x i16> zeroinitializer, %48
  %50 = icmp slt <8 x i16> %48, zeroinitializer
  %51 = select <8 x i1> %50, <8 x i16> %49, <8 x i16> %48
  %52 = lshr <8 x i16> %51, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %53 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %52, <8 x i16> zeroinitializer) #5
  %54 = lshr <8 x i16> %53, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %55 = getelementptr inbounds i16, i16* %9, i64 24
  %56 = bitcast i16* %55 to <8 x i16>*
  %57 = load <8 x i16>, <8 x i16>* %56, align 16
  %58 = getelementptr inbounds i16, i16* %10, i64 24
  %59 = bitcast i16* %58 to <8 x i16>*
  %60 = load <8 x i16>, <8 x i16>* %59, align 16
  %61 = sub <8 x i16> %57, %60
  %62 = sub <8 x i16> zeroinitializer, %61
  %63 = icmp slt <8 x i16> %61, zeroinitializer
  %64 = select <8 x i1> %63, <8 x i16> %62, <8 x i16> %61
  %65 = lshr <8 x i16> %64, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %66 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %65, <8 x i16> zeroinitializer) #5
  %67 = lshr <8 x i16> %66, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %68 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %54, <8 x i16> %67) #5
  %69 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %68, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %70 = icmp slt <16 x i8> %69, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %71 = select <16 x i1> %70, <16 x i8> %69, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %72 = bitcast i8* %43 to <16 x i8>*
  store <16 x i8> %71, <16 x i8>* %72, align 16
  %73 = getelementptr inbounds i16, i16* %9, i64 32
  %74 = getelementptr inbounds i16, i16* %10, i64 32
  %75 = getelementptr inbounds i8, i8* %43, i64 %3
  %76 = bitcast i16* %73 to <8 x i16>*
  %77 = load <8 x i16>, <8 x i16>* %76, align 16
  %78 = bitcast i16* %74 to <8 x i16>*
  %79 = load <8 x i16>, <8 x i16>* %78, align 16
  %80 = sub <8 x i16> %77, %79
  %81 = sub <8 x i16> zeroinitializer, %80
  %82 = icmp slt <8 x i16> %80, zeroinitializer
  %83 = select <8 x i1> %82, <8 x i16> %81, <8 x i16> %80
  %84 = lshr <8 x i16> %83, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %85 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %84, <8 x i16> zeroinitializer) #5
  %86 = lshr <8 x i16> %85, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %87 = getelementptr inbounds i16, i16* %9, i64 40
  %88 = bitcast i16* %87 to <8 x i16>*
  %89 = load <8 x i16>, <8 x i16>* %88, align 16
  %90 = getelementptr inbounds i16, i16* %10, i64 40
  %91 = bitcast i16* %90 to <8 x i16>*
  %92 = load <8 x i16>, <8 x i16>* %91, align 16
  %93 = sub <8 x i16> %89, %92
  %94 = sub <8 x i16> zeroinitializer, %93
  %95 = icmp slt <8 x i16> %93, zeroinitializer
  %96 = select <8 x i1> %95, <8 x i16> %94, <8 x i16> %93
  %97 = lshr <8 x i16> %96, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %98 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %97, <8 x i16> zeroinitializer) #5
  %99 = lshr <8 x i16> %98, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %100 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %86, <8 x i16> %99) #5
  %101 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %100, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %102 = icmp slt <16 x i8> %101, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %103 = select <16 x i1> %102, <16 x i8> %101, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %104 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %103, <16 x i8>* %104, align 16
  %105 = getelementptr inbounds i16, i16* %9, i64 48
  %106 = getelementptr inbounds i16, i16* %10, i64 48
  %107 = getelementptr inbounds i8, i8* %75, i64 %3
  %108 = add nsw i32 %11, -1
  %109 = icmp eq i32 %108, 0
  br i1 %109, label %110, label %7

110:                                              ; preds = %7
  %111 = bitcast i16* %105 to <8 x i16>*
  %112 = load <8 x i16>, <8 x i16>* %111, align 16
  %113 = bitcast i16* %106 to <8 x i16>*
  %114 = load <8 x i16>, <8 x i16>* %113, align 16
  %115 = sub <8 x i16> %112, %114
  %116 = sub <8 x i16> zeroinitializer, %115
  %117 = icmp slt <8 x i16> %115, zeroinitializer
  %118 = select <8 x i1> %117, <8 x i16> %116, <8 x i16> %115
  %119 = lshr <8 x i16> %118, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %120 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %119, <8 x i16> zeroinitializer) #5
  %121 = lshr <8 x i16> %120, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %122 = getelementptr inbounds i16, i16* %9, i64 56
  %123 = bitcast i16* %122 to <8 x i16>*
  %124 = load <8 x i16>, <8 x i16>* %123, align 16
  %125 = getelementptr inbounds i16, i16* %10, i64 56
  %126 = bitcast i16* %125 to <8 x i16>*
  %127 = load <8 x i16>, <8 x i16>* %126, align 16
  %128 = sub <8 x i16> %124, %127
  %129 = sub <8 x i16> zeroinitializer, %128
  %130 = icmp slt <8 x i16> %128, zeroinitializer
  %131 = select <8 x i1> %130, <8 x i16> %129, <8 x i16> %128
  %132 = lshr <8 x i16> %131, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %133 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %132, <8 x i16> zeroinitializer) #5
  %134 = lshr <8 x i16> %133, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %135 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %121, <8 x i16> %134) #5
  %136 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %135, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %137 = icmp slt <16 x i8> %136, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %138 = select <16 x i1> %137, <16 x i8> %136, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %139 = bitcast i8* %107 to <16 x i8>*
  store <16 x i8> %138, <16 x i8>* %139, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask16x64_SSE4ILb1EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %110, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %108, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %109, %7 ]
  %11 = phi i32 [ 21, %4 ], [ %111, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = sub <8 x i16> %13, %15
  %17 = sub <8 x i16> zeroinitializer, %16
  %18 = icmp slt <8 x i16> %16, zeroinitializer
  %19 = select <8 x i1> %18, <8 x i16> %17, <8 x i16> %16
  %20 = lshr <8 x i16> %19, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %21 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %20, <8 x i16> zeroinitializer) #5
  %22 = lshr <8 x i16> %21, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %23 = getelementptr inbounds i16, i16* %9, i64 8
  %24 = bitcast i16* %23 to <8 x i16>*
  %25 = load <8 x i16>, <8 x i16>* %24, align 16
  %26 = getelementptr inbounds i16, i16* %10, i64 8
  %27 = bitcast i16* %26 to <8 x i16>*
  %28 = load <8 x i16>, <8 x i16>* %27, align 16
  %29 = sub <8 x i16> %25, %28
  %30 = sub <8 x i16> zeroinitializer, %29
  %31 = icmp slt <8 x i16> %29, zeroinitializer
  %32 = select <8 x i1> %31, <8 x i16> %30, <8 x i16> %29
  %33 = lshr <8 x i16> %32, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %34 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %33, <8 x i16> zeroinitializer) #5
  %35 = lshr <8 x i16> %34, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %36 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %22, <8 x i16> %35) #5
  %37 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %36, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %38 = icmp slt <16 x i8> %37, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %39 = select <16 x i1> %38, <16 x i8> %37, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %40 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %39
  %41 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %40, <16 x i8>* %41, align 16
  %42 = getelementptr inbounds i16, i16* %9, i64 16
  %43 = getelementptr inbounds i16, i16* %10, i64 16
  %44 = getelementptr inbounds i8, i8* %8, i64 %3
  %45 = bitcast i16* %42 to <8 x i16>*
  %46 = load <8 x i16>, <8 x i16>* %45, align 16
  %47 = bitcast i16* %43 to <8 x i16>*
  %48 = load <8 x i16>, <8 x i16>* %47, align 16
  %49 = sub <8 x i16> %46, %48
  %50 = sub <8 x i16> zeroinitializer, %49
  %51 = icmp slt <8 x i16> %49, zeroinitializer
  %52 = select <8 x i1> %51, <8 x i16> %50, <8 x i16> %49
  %53 = lshr <8 x i16> %52, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %54 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %53, <8 x i16> zeroinitializer) #5
  %55 = lshr <8 x i16> %54, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %56 = getelementptr inbounds i16, i16* %9, i64 24
  %57 = bitcast i16* %56 to <8 x i16>*
  %58 = load <8 x i16>, <8 x i16>* %57, align 16
  %59 = getelementptr inbounds i16, i16* %10, i64 24
  %60 = bitcast i16* %59 to <8 x i16>*
  %61 = load <8 x i16>, <8 x i16>* %60, align 16
  %62 = sub <8 x i16> %58, %61
  %63 = sub <8 x i16> zeroinitializer, %62
  %64 = icmp slt <8 x i16> %62, zeroinitializer
  %65 = select <8 x i1> %64, <8 x i16> %63, <8 x i16> %62
  %66 = lshr <8 x i16> %65, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %67 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %66, <8 x i16> zeroinitializer) #5
  %68 = lshr <8 x i16> %67, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %69 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %55, <8 x i16> %68) #5
  %70 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %69, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %71 = icmp slt <16 x i8> %70, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %72 = select <16 x i1> %71, <16 x i8> %70, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %73 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %72
  %74 = bitcast i8* %44 to <16 x i8>*
  store <16 x i8> %73, <16 x i8>* %74, align 16
  %75 = getelementptr inbounds i16, i16* %9, i64 32
  %76 = getelementptr inbounds i16, i16* %10, i64 32
  %77 = getelementptr inbounds i8, i8* %44, i64 %3
  %78 = bitcast i16* %75 to <8 x i16>*
  %79 = load <8 x i16>, <8 x i16>* %78, align 16
  %80 = bitcast i16* %76 to <8 x i16>*
  %81 = load <8 x i16>, <8 x i16>* %80, align 16
  %82 = sub <8 x i16> %79, %81
  %83 = sub <8 x i16> zeroinitializer, %82
  %84 = icmp slt <8 x i16> %82, zeroinitializer
  %85 = select <8 x i1> %84, <8 x i16> %83, <8 x i16> %82
  %86 = lshr <8 x i16> %85, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %87 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %86, <8 x i16> zeroinitializer) #5
  %88 = lshr <8 x i16> %87, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %89 = getelementptr inbounds i16, i16* %9, i64 40
  %90 = bitcast i16* %89 to <8 x i16>*
  %91 = load <8 x i16>, <8 x i16>* %90, align 16
  %92 = getelementptr inbounds i16, i16* %10, i64 40
  %93 = bitcast i16* %92 to <8 x i16>*
  %94 = load <8 x i16>, <8 x i16>* %93, align 16
  %95 = sub <8 x i16> %91, %94
  %96 = sub <8 x i16> zeroinitializer, %95
  %97 = icmp slt <8 x i16> %95, zeroinitializer
  %98 = select <8 x i1> %97, <8 x i16> %96, <8 x i16> %95
  %99 = lshr <8 x i16> %98, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %100 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %99, <8 x i16> zeroinitializer) #5
  %101 = lshr <8 x i16> %100, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %102 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %88, <8 x i16> %101) #5
  %103 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %102, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %104 = icmp slt <16 x i8> %103, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %105 = select <16 x i1> %104, <16 x i8> %103, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %106 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %105
  %107 = bitcast i8* %77 to <16 x i8>*
  store <16 x i8> %106, <16 x i8>* %107, align 16
  %108 = getelementptr inbounds i16, i16* %9, i64 48
  %109 = getelementptr inbounds i16, i16* %10, i64 48
  %110 = getelementptr inbounds i8, i8* %77, i64 %3
  %111 = add nsw i32 %11, -1
  %112 = icmp eq i32 %111, 0
  br i1 %112, label %113, label %7

113:                                              ; preds = %7
  %114 = bitcast i16* %108 to <8 x i16>*
  %115 = load <8 x i16>, <8 x i16>* %114, align 16
  %116 = bitcast i16* %109 to <8 x i16>*
  %117 = load <8 x i16>, <8 x i16>* %116, align 16
  %118 = sub <8 x i16> %115, %117
  %119 = sub <8 x i16> zeroinitializer, %118
  %120 = icmp slt <8 x i16> %118, zeroinitializer
  %121 = select <8 x i1> %120, <8 x i16> %119, <8 x i16> %118
  %122 = lshr <8 x i16> %121, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %123 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %122, <8 x i16> zeroinitializer) #5
  %124 = lshr <8 x i16> %123, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %125 = getelementptr inbounds i16, i16* %9, i64 56
  %126 = bitcast i16* %125 to <8 x i16>*
  %127 = load <8 x i16>, <8 x i16>* %126, align 16
  %128 = getelementptr inbounds i16, i16* %10, i64 56
  %129 = bitcast i16* %128 to <8 x i16>*
  %130 = load <8 x i16>, <8 x i16>* %129, align 16
  %131 = sub <8 x i16> %127, %130
  %132 = sub <8 x i16> zeroinitializer, %131
  %133 = icmp slt <8 x i16> %131, zeroinitializer
  %134 = select <8 x i1> %133, <8 x i16> %132, <8 x i16> %131
  %135 = lshr <8 x i16> %134, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %136 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %135, <8 x i16> zeroinitializer) #5
  %137 = lshr <8 x i16> %136, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %138 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %124, <8 x i16> %137) #5
  %139 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %138, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %140 = icmp slt <16 x i8> %139, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %141 = select <16 x i1> %140, <16 x i8> %139, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %142 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %141
  %143 = bitcast i8* %110 to <16 x i8>*
  store <16 x i8> %142, <16 x i8>* %143, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_119WeightMask32x8_SSE4ILb0EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to <8 x i16>*
  %6 = load <8 x i16>, <8 x i16>* %5, align 16
  %7 = bitcast i8* %1 to <8 x i16>*
  %8 = load <8 x i16>, <8 x i16>* %7, align 16
  %9 = sub <8 x i16> %6, %8
  %10 = sub <8 x i16> zeroinitializer, %9
  %11 = icmp slt <8 x i16> %9, zeroinitializer
  %12 = select <8 x i1> %11, <8 x i16> %10, <8 x i16> %9
  %13 = lshr <8 x i16> %12, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %14 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %13, <8 x i16> zeroinitializer) #5
  %15 = lshr <8 x i16> %14, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %16 = getelementptr inbounds i8, i8* %0, i64 16
  %17 = bitcast i8* %16 to <8 x i16>*
  %18 = load <8 x i16>, <8 x i16>* %17, align 16
  %19 = getelementptr inbounds i8, i8* %1, i64 16
  %20 = bitcast i8* %19 to <8 x i16>*
  %21 = load <8 x i16>, <8 x i16>* %20, align 16
  %22 = sub <8 x i16> %18, %21
  %23 = sub <8 x i16> zeroinitializer, %22
  %24 = icmp slt <8 x i16> %22, zeroinitializer
  %25 = select <8 x i1> %24, <8 x i16> %23, <8 x i16> %22
  %26 = lshr <8 x i16> %25, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %27 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %26, <8 x i16> zeroinitializer) #5
  %28 = lshr <8 x i16> %27, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %29 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %15, <8 x i16> %28) #5
  %30 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %29, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %31 = icmp slt <16 x i8> %30, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %32 = select <16 x i1> %31, <16 x i8> %30, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %33 = bitcast i8* %2 to <16 x i8>*
  store <16 x i8> %32, <16 x i8>* %33, align 16
  %34 = getelementptr inbounds i8, i8* %0, i64 32
  %35 = getelementptr inbounds i8, i8* %1, i64 32
  %36 = getelementptr inbounds i8, i8* %2, i64 16
  %37 = bitcast i8* %34 to <8 x i16>*
  %38 = load <8 x i16>, <8 x i16>* %37, align 16
  %39 = bitcast i8* %35 to <8 x i16>*
  %40 = load <8 x i16>, <8 x i16>* %39, align 16
  %41 = sub <8 x i16> %38, %40
  %42 = sub <8 x i16> zeroinitializer, %41
  %43 = icmp slt <8 x i16> %41, zeroinitializer
  %44 = select <8 x i1> %43, <8 x i16> %42, <8 x i16> %41
  %45 = lshr <8 x i16> %44, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %46 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %45, <8 x i16> zeroinitializer) #5
  %47 = lshr <8 x i16> %46, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %48 = getelementptr inbounds i8, i8* %0, i64 48
  %49 = bitcast i8* %48 to <8 x i16>*
  %50 = load <8 x i16>, <8 x i16>* %49, align 16
  %51 = getelementptr inbounds i8, i8* %1, i64 48
  %52 = bitcast i8* %51 to <8 x i16>*
  %53 = load <8 x i16>, <8 x i16>* %52, align 16
  %54 = sub <8 x i16> %50, %53
  %55 = sub <8 x i16> zeroinitializer, %54
  %56 = icmp slt <8 x i16> %54, zeroinitializer
  %57 = select <8 x i1> %56, <8 x i16> %55, <8 x i16> %54
  %58 = lshr <8 x i16> %57, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %59 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %58, <8 x i16> zeroinitializer) #5
  %60 = lshr <8 x i16> %59, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %61 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %47, <8 x i16> %60) #5
  %62 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %61, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %63 = icmp slt <16 x i8> %62, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %64 = select <16 x i1> %63, <16 x i8> %62, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %65 = bitcast i8* %36 to <16 x i8>*
  store <16 x i8> %64, <16 x i8>* %65, align 16
  %66 = getelementptr inbounds i8, i8* %0, i64 64
  %67 = getelementptr inbounds i8, i8* %1, i64 64
  %68 = getelementptr inbounds i8, i8* %2, i64 %3
  %69 = bitcast i8* %66 to <8 x i16>*
  %70 = load <8 x i16>, <8 x i16>* %69, align 16
  %71 = bitcast i8* %67 to <8 x i16>*
  %72 = load <8 x i16>, <8 x i16>* %71, align 16
  %73 = sub <8 x i16> %70, %72
  %74 = sub <8 x i16> zeroinitializer, %73
  %75 = icmp slt <8 x i16> %73, zeroinitializer
  %76 = select <8 x i1> %75, <8 x i16> %74, <8 x i16> %73
  %77 = lshr <8 x i16> %76, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %78 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %77, <8 x i16> zeroinitializer) #5
  %79 = lshr <8 x i16> %78, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %80 = getelementptr inbounds i8, i8* %0, i64 80
  %81 = bitcast i8* %80 to <8 x i16>*
  %82 = load <8 x i16>, <8 x i16>* %81, align 16
  %83 = getelementptr inbounds i8, i8* %1, i64 80
  %84 = bitcast i8* %83 to <8 x i16>*
  %85 = load <8 x i16>, <8 x i16>* %84, align 16
  %86 = sub <8 x i16> %82, %85
  %87 = sub <8 x i16> zeroinitializer, %86
  %88 = icmp slt <8 x i16> %86, zeroinitializer
  %89 = select <8 x i1> %88, <8 x i16> %87, <8 x i16> %86
  %90 = lshr <8 x i16> %89, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %91 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %90, <8 x i16> zeroinitializer) #5
  %92 = lshr <8 x i16> %91, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %93 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %79, <8 x i16> %92) #5
  %94 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %93, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %95 = icmp slt <16 x i8> %94, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %96 = select <16 x i1> %95, <16 x i8> %94, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %97 = bitcast i8* %68 to <16 x i8>*
  store <16 x i8> %96, <16 x i8>* %97, align 16
  %98 = getelementptr inbounds i8, i8* %0, i64 96
  %99 = getelementptr inbounds i8, i8* %1, i64 96
  %100 = getelementptr inbounds i8, i8* %68, i64 16
  %101 = bitcast i8* %98 to <8 x i16>*
  %102 = load <8 x i16>, <8 x i16>* %101, align 16
  %103 = bitcast i8* %99 to <8 x i16>*
  %104 = load <8 x i16>, <8 x i16>* %103, align 16
  %105 = sub <8 x i16> %102, %104
  %106 = sub <8 x i16> zeroinitializer, %105
  %107 = icmp slt <8 x i16> %105, zeroinitializer
  %108 = select <8 x i1> %107, <8 x i16> %106, <8 x i16> %105
  %109 = lshr <8 x i16> %108, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %110 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %109, <8 x i16> zeroinitializer) #5
  %111 = lshr <8 x i16> %110, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %112 = getelementptr inbounds i8, i8* %0, i64 112
  %113 = bitcast i8* %112 to <8 x i16>*
  %114 = load <8 x i16>, <8 x i16>* %113, align 16
  %115 = getelementptr inbounds i8, i8* %1, i64 112
  %116 = bitcast i8* %115 to <8 x i16>*
  %117 = load <8 x i16>, <8 x i16>* %116, align 16
  %118 = sub <8 x i16> %114, %117
  %119 = sub <8 x i16> zeroinitializer, %118
  %120 = icmp slt <8 x i16> %118, zeroinitializer
  %121 = select <8 x i1> %120, <8 x i16> %119, <8 x i16> %118
  %122 = lshr <8 x i16> %121, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %123 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %122, <8 x i16> zeroinitializer) #5
  %124 = lshr <8 x i16> %123, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %125 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %111, <8 x i16> %124) #5
  %126 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %125, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %127 = icmp slt <16 x i8> %126, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %128 = select <16 x i1> %127, <16 x i8> %126, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %129 = bitcast i8* %100 to <16 x i8>*
  store <16 x i8> %128, <16 x i8>* %129, align 16
  %130 = getelementptr inbounds i8, i8* %0, i64 128
  %131 = getelementptr inbounds i8, i8* %1, i64 128
  %132 = getelementptr inbounds i8, i8* %68, i64 %3
  %133 = bitcast i8* %130 to <8 x i16>*
  %134 = load <8 x i16>, <8 x i16>* %133, align 16
  %135 = bitcast i8* %131 to <8 x i16>*
  %136 = load <8 x i16>, <8 x i16>* %135, align 16
  %137 = sub <8 x i16> %134, %136
  %138 = sub <8 x i16> zeroinitializer, %137
  %139 = icmp slt <8 x i16> %137, zeroinitializer
  %140 = select <8 x i1> %139, <8 x i16> %138, <8 x i16> %137
  %141 = lshr <8 x i16> %140, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %142 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %141, <8 x i16> zeroinitializer) #5
  %143 = lshr <8 x i16> %142, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %144 = getelementptr inbounds i8, i8* %0, i64 144
  %145 = bitcast i8* %144 to <8 x i16>*
  %146 = load <8 x i16>, <8 x i16>* %145, align 16
  %147 = getelementptr inbounds i8, i8* %1, i64 144
  %148 = bitcast i8* %147 to <8 x i16>*
  %149 = load <8 x i16>, <8 x i16>* %148, align 16
  %150 = sub <8 x i16> %146, %149
  %151 = sub <8 x i16> zeroinitializer, %150
  %152 = icmp slt <8 x i16> %150, zeroinitializer
  %153 = select <8 x i1> %152, <8 x i16> %151, <8 x i16> %150
  %154 = lshr <8 x i16> %153, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %155 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %154, <8 x i16> zeroinitializer) #5
  %156 = lshr <8 x i16> %155, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %157 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %143, <8 x i16> %156) #5
  %158 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %157, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %159 = icmp slt <16 x i8> %158, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %160 = select <16 x i1> %159, <16 x i8> %158, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %161 = bitcast i8* %132 to <16 x i8>*
  store <16 x i8> %160, <16 x i8>* %161, align 16
  %162 = getelementptr inbounds i8, i8* %0, i64 160
  %163 = getelementptr inbounds i8, i8* %1, i64 160
  %164 = getelementptr inbounds i8, i8* %132, i64 16
  %165 = bitcast i8* %162 to <8 x i16>*
  %166 = load <8 x i16>, <8 x i16>* %165, align 16
  %167 = bitcast i8* %163 to <8 x i16>*
  %168 = load <8 x i16>, <8 x i16>* %167, align 16
  %169 = sub <8 x i16> %166, %168
  %170 = sub <8 x i16> zeroinitializer, %169
  %171 = icmp slt <8 x i16> %169, zeroinitializer
  %172 = select <8 x i1> %171, <8 x i16> %170, <8 x i16> %169
  %173 = lshr <8 x i16> %172, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %174 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %173, <8 x i16> zeroinitializer) #5
  %175 = lshr <8 x i16> %174, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %176 = getelementptr inbounds i8, i8* %0, i64 176
  %177 = bitcast i8* %176 to <8 x i16>*
  %178 = load <8 x i16>, <8 x i16>* %177, align 16
  %179 = getelementptr inbounds i8, i8* %1, i64 176
  %180 = bitcast i8* %179 to <8 x i16>*
  %181 = load <8 x i16>, <8 x i16>* %180, align 16
  %182 = sub <8 x i16> %178, %181
  %183 = sub <8 x i16> zeroinitializer, %182
  %184 = icmp slt <8 x i16> %182, zeroinitializer
  %185 = select <8 x i1> %184, <8 x i16> %183, <8 x i16> %182
  %186 = lshr <8 x i16> %185, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %187 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %186, <8 x i16> zeroinitializer) #5
  %188 = lshr <8 x i16> %187, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %189 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %175, <8 x i16> %188) #5
  %190 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %189, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %191 = icmp slt <16 x i8> %190, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %192 = select <16 x i1> %191, <16 x i8> %190, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %193 = bitcast i8* %164 to <16 x i8>*
  store <16 x i8> %192, <16 x i8>* %193, align 16
  %194 = getelementptr inbounds i8, i8* %0, i64 192
  %195 = getelementptr inbounds i8, i8* %1, i64 192
  %196 = getelementptr inbounds i8, i8* %132, i64 %3
  %197 = bitcast i8* %194 to <8 x i16>*
  %198 = load <8 x i16>, <8 x i16>* %197, align 16
  %199 = bitcast i8* %195 to <8 x i16>*
  %200 = load <8 x i16>, <8 x i16>* %199, align 16
  %201 = sub <8 x i16> %198, %200
  %202 = sub <8 x i16> zeroinitializer, %201
  %203 = icmp slt <8 x i16> %201, zeroinitializer
  %204 = select <8 x i1> %203, <8 x i16> %202, <8 x i16> %201
  %205 = lshr <8 x i16> %204, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %206 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %205, <8 x i16> zeroinitializer) #5
  %207 = lshr <8 x i16> %206, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %208 = getelementptr inbounds i8, i8* %0, i64 208
  %209 = bitcast i8* %208 to <8 x i16>*
  %210 = load <8 x i16>, <8 x i16>* %209, align 16
  %211 = getelementptr inbounds i8, i8* %1, i64 208
  %212 = bitcast i8* %211 to <8 x i16>*
  %213 = load <8 x i16>, <8 x i16>* %212, align 16
  %214 = sub <8 x i16> %210, %213
  %215 = sub <8 x i16> zeroinitializer, %214
  %216 = icmp slt <8 x i16> %214, zeroinitializer
  %217 = select <8 x i1> %216, <8 x i16> %215, <8 x i16> %214
  %218 = lshr <8 x i16> %217, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %219 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %218, <8 x i16> zeroinitializer) #5
  %220 = lshr <8 x i16> %219, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %221 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %207, <8 x i16> %220) #5
  %222 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %221, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %223 = icmp slt <16 x i8> %222, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %224 = select <16 x i1> %223, <16 x i8> %222, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %225 = bitcast i8* %196 to <16 x i8>*
  store <16 x i8> %224, <16 x i8>* %225, align 16
  %226 = getelementptr inbounds i8, i8* %0, i64 224
  %227 = getelementptr inbounds i8, i8* %1, i64 224
  %228 = getelementptr inbounds i8, i8* %196, i64 16
  %229 = bitcast i8* %226 to <8 x i16>*
  %230 = load <8 x i16>, <8 x i16>* %229, align 16
  %231 = bitcast i8* %227 to <8 x i16>*
  %232 = load <8 x i16>, <8 x i16>* %231, align 16
  %233 = sub <8 x i16> %230, %232
  %234 = sub <8 x i16> zeroinitializer, %233
  %235 = icmp slt <8 x i16> %233, zeroinitializer
  %236 = select <8 x i1> %235, <8 x i16> %234, <8 x i16> %233
  %237 = lshr <8 x i16> %236, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %238 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %237, <8 x i16> zeroinitializer) #5
  %239 = lshr <8 x i16> %238, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %240 = getelementptr inbounds i8, i8* %0, i64 240
  %241 = bitcast i8* %240 to <8 x i16>*
  %242 = load <8 x i16>, <8 x i16>* %241, align 16
  %243 = getelementptr inbounds i8, i8* %1, i64 240
  %244 = bitcast i8* %243 to <8 x i16>*
  %245 = load <8 x i16>, <8 x i16>* %244, align 16
  %246 = sub <8 x i16> %242, %245
  %247 = sub <8 x i16> zeroinitializer, %246
  %248 = icmp slt <8 x i16> %246, zeroinitializer
  %249 = select <8 x i1> %248, <8 x i16> %247, <8 x i16> %246
  %250 = lshr <8 x i16> %249, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %251 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %250, <8 x i16> zeroinitializer) #5
  %252 = lshr <8 x i16> %251, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %253 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %239, <8 x i16> %252) #5
  %254 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %253, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %255 = icmp slt <16 x i8> %254, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %256 = select <16 x i1> %255, <16 x i8> %254, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %257 = bitcast i8* %228 to <16 x i8>*
  store <16 x i8> %256, <16 x i8>* %257, align 16
  %258 = getelementptr inbounds i8, i8* %0, i64 256
  %259 = getelementptr inbounds i8, i8* %1, i64 256
  %260 = getelementptr inbounds i8, i8* %196, i64 %3
  %261 = bitcast i8* %258 to <8 x i16>*
  %262 = load <8 x i16>, <8 x i16>* %261, align 16
  %263 = bitcast i8* %259 to <8 x i16>*
  %264 = load <8 x i16>, <8 x i16>* %263, align 16
  %265 = sub <8 x i16> %262, %264
  %266 = sub <8 x i16> zeroinitializer, %265
  %267 = icmp slt <8 x i16> %265, zeroinitializer
  %268 = select <8 x i1> %267, <8 x i16> %266, <8 x i16> %265
  %269 = lshr <8 x i16> %268, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %270 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %269, <8 x i16> zeroinitializer) #5
  %271 = lshr <8 x i16> %270, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %272 = getelementptr inbounds i8, i8* %0, i64 272
  %273 = bitcast i8* %272 to <8 x i16>*
  %274 = load <8 x i16>, <8 x i16>* %273, align 16
  %275 = getelementptr inbounds i8, i8* %1, i64 272
  %276 = bitcast i8* %275 to <8 x i16>*
  %277 = load <8 x i16>, <8 x i16>* %276, align 16
  %278 = sub <8 x i16> %274, %277
  %279 = sub <8 x i16> zeroinitializer, %278
  %280 = icmp slt <8 x i16> %278, zeroinitializer
  %281 = select <8 x i1> %280, <8 x i16> %279, <8 x i16> %278
  %282 = lshr <8 x i16> %281, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %283 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %282, <8 x i16> zeroinitializer) #5
  %284 = lshr <8 x i16> %283, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %285 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %271, <8 x i16> %284) #5
  %286 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %285, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %287 = icmp slt <16 x i8> %286, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %288 = select <16 x i1> %287, <16 x i8> %286, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %289 = bitcast i8* %260 to <16 x i8>*
  store <16 x i8> %288, <16 x i8>* %289, align 16
  %290 = getelementptr inbounds i8, i8* %0, i64 288
  %291 = getelementptr inbounds i8, i8* %1, i64 288
  %292 = getelementptr inbounds i8, i8* %260, i64 16
  %293 = bitcast i8* %290 to <8 x i16>*
  %294 = load <8 x i16>, <8 x i16>* %293, align 16
  %295 = bitcast i8* %291 to <8 x i16>*
  %296 = load <8 x i16>, <8 x i16>* %295, align 16
  %297 = sub <8 x i16> %294, %296
  %298 = sub <8 x i16> zeroinitializer, %297
  %299 = icmp slt <8 x i16> %297, zeroinitializer
  %300 = select <8 x i1> %299, <8 x i16> %298, <8 x i16> %297
  %301 = lshr <8 x i16> %300, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %302 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %301, <8 x i16> zeroinitializer) #5
  %303 = lshr <8 x i16> %302, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %304 = getelementptr inbounds i8, i8* %0, i64 304
  %305 = bitcast i8* %304 to <8 x i16>*
  %306 = load <8 x i16>, <8 x i16>* %305, align 16
  %307 = getelementptr inbounds i8, i8* %1, i64 304
  %308 = bitcast i8* %307 to <8 x i16>*
  %309 = load <8 x i16>, <8 x i16>* %308, align 16
  %310 = sub <8 x i16> %306, %309
  %311 = sub <8 x i16> zeroinitializer, %310
  %312 = icmp slt <8 x i16> %310, zeroinitializer
  %313 = select <8 x i1> %312, <8 x i16> %311, <8 x i16> %310
  %314 = lshr <8 x i16> %313, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %315 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %314, <8 x i16> zeroinitializer) #5
  %316 = lshr <8 x i16> %315, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %317 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %303, <8 x i16> %316) #5
  %318 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %317, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %319 = icmp slt <16 x i8> %318, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %320 = select <16 x i1> %319, <16 x i8> %318, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %321 = bitcast i8* %292 to <16 x i8>*
  store <16 x i8> %320, <16 x i8>* %321, align 16
  %322 = getelementptr inbounds i8, i8* %0, i64 320
  %323 = getelementptr inbounds i8, i8* %1, i64 320
  %324 = getelementptr inbounds i8, i8* %260, i64 %3
  %325 = bitcast i8* %322 to <8 x i16>*
  %326 = load <8 x i16>, <8 x i16>* %325, align 16
  %327 = bitcast i8* %323 to <8 x i16>*
  %328 = load <8 x i16>, <8 x i16>* %327, align 16
  %329 = sub <8 x i16> %326, %328
  %330 = sub <8 x i16> zeroinitializer, %329
  %331 = icmp slt <8 x i16> %329, zeroinitializer
  %332 = select <8 x i1> %331, <8 x i16> %330, <8 x i16> %329
  %333 = lshr <8 x i16> %332, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %334 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %333, <8 x i16> zeroinitializer) #5
  %335 = lshr <8 x i16> %334, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %336 = getelementptr inbounds i8, i8* %0, i64 336
  %337 = bitcast i8* %336 to <8 x i16>*
  %338 = load <8 x i16>, <8 x i16>* %337, align 16
  %339 = getelementptr inbounds i8, i8* %1, i64 336
  %340 = bitcast i8* %339 to <8 x i16>*
  %341 = load <8 x i16>, <8 x i16>* %340, align 16
  %342 = sub <8 x i16> %338, %341
  %343 = sub <8 x i16> zeroinitializer, %342
  %344 = icmp slt <8 x i16> %342, zeroinitializer
  %345 = select <8 x i1> %344, <8 x i16> %343, <8 x i16> %342
  %346 = lshr <8 x i16> %345, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %347 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %346, <8 x i16> zeroinitializer) #5
  %348 = lshr <8 x i16> %347, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %349 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %335, <8 x i16> %348) #5
  %350 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %349, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %351 = icmp slt <16 x i8> %350, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %352 = select <16 x i1> %351, <16 x i8> %350, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %353 = bitcast i8* %324 to <16 x i8>*
  store <16 x i8> %352, <16 x i8>* %353, align 16
  %354 = getelementptr inbounds i8, i8* %0, i64 352
  %355 = getelementptr inbounds i8, i8* %1, i64 352
  %356 = getelementptr inbounds i8, i8* %324, i64 16
  %357 = bitcast i8* %354 to <8 x i16>*
  %358 = load <8 x i16>, <8 x i16>* %357, align 16
  %359 = bitcast i8* %355 to <8 x i16>*
  %360 = load <8 x i16>, <8 x i16>* %359, align 16
  %361 = sub <8 x i16> %358, %360
  %362 = sub <8 x i16> zeroinitializer, %361
  %363 = icmp slt <8 x i16> %361, zeroinitializer
  %364 = select <8 x i1> %363, <8 x i16> %362, <8 x i16> %361
  %365 = lshr <8 x i16> %364, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %366 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %365, <8 x i16> zeroinitializer) #5
  %367 = lshr <8 x i16> %366, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %368 = getelementptr inbounds i8, i8* %0, i64 368
  %369 = bitcast i8* %368 to <8 x i16>*
  %370 = load <8 x i16>, <8 x i16>* %369, align 16
  %371 = getelementptr inbounds i8, i8* %1, i64 368
  %372 = bitcast i8* %371 to <8 x i16>*
  %373 = load <8 x i16>, <8 x i16>* %372, align 16
  %374 = sub <8 x i16> %370, %373
  %375 = sub <8 x i16> zeroinitializer, %374
  %376 = icmp slt <8 x i16> %374, zeroinitializer
  %377 = select <8 x i1> %376, <8 x i16> %375, <8 x i16> %374
  %378 = lshr <8 x i16> %377, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %379 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %378, <8 x i16> zeroinitializer) #5
  %380 = lshr <8 x i16> %379, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %381 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %367, <8 x i16> %380) #5
  %382 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %381, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %383 = icmp slt <16 x i8> %382, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %384 = select <16 x i1> %383, <16 x i8> %382, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %385 = bitcast i8* %356 to <16 x i8>*
  store <16 x i8> %384, <16 x i8>* %385, align 16
  %386 = getelementptr inbounds i8, i8* %0, i64 384
  %387 = getelementptr inbounds i8, i8* %1, i64 384
  %388 = getelementptr inbounds i8, i8* %324, i64 %3
  %389 = bitcast i8* %386 to <8 x i16>*
  %390 = load <8 x i16>, <8 x i16>* %389, align 16
  %391 = bitcast i8* %387 to <8 x i16>*
  %392 = load <8 x i16>, <8 x i16>* %391, align 16
  %393 = sub <8 x i16> %390, %392
  %394 = sub <8 x i16> zeroinitializer, %393
  %395 = icmp slt <8 x i16> %393, zeroinitializer
  %396 = select <8 x i1> %395, <8 x i16> %394, <8 x i16> %393
  %397 = lshr <8 x i16> %396, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %398 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %397, <8 x i16> zeroinitializer) #5
  %399 = lshr <8 x i16> %398, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %400 = getelementptr inbounds i8, i8* %0, i64 400
  %401 = bitcast i8* %400 to <8 x i16>*
  %402 = load <8 x i16>, <8 x i16>* %401, align 16
  %403 = getelementptr inbounds i8, i8* %1, i64 400
  %404 = bitcast i8* %403 to <8 x i16>*
  %405 = load <8 x i16>, <8 x i16>* %404, align 16
  %406 = sub <8 x i16> %402, %405
  %407 = sub <8 x i16> zeroinitializer, %406
  %408 = icmp slt <8 x i16> %406, zeroinitializer
  %409 = select <8 x i1> %408, <8 x i16> %407, <8 x i16> %406
  %410 = lshr <8 x i16> %409, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %411 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %410, <8 x i16> zeroinitializer) #5
  %412 = lshr <8 x i16> %411, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %413 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %399, <8 x i16> %412) #5
  %414 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %413, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %415 = icmp slt <16 x i8> %414, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %416 = select <16 x i1> %415, <16 x i8> %414, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %417 = bitcast i8* %388 to <16 x i8>*
  store <16 x i8> %416, <16 x i8>* %417, align 16
  %418 = getelementptr inbounds i8, i8* %0, i64 416
  %419 = getelementptr inbounds i8, i8* %1, i64 416
  %420 = getelementptr inbounds i8, i8* %388, i64 16
  %421 = bitcast i8* %418 to <8 x i16>*
  %422 = load <8 x i16>, <8 x i16>* %421, align 16
  %423 = bitcast i8* %419 to <8 x i16>*
  %424 = load <8 x i16>, <8 x i16>* %423, align 16
  %425 = sub <8 x i16> %422, %424
  %426 = sub <8 x i16> zeroinitializer, %425
  %427 = icmp slt <8 x i16> %425, zeroinitializer
  %428 = select <8 x i1> %427, <8 x i16> %426, <8 x i16> %425
  %429 = lshr <8 x i16> %428, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %430 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %429, <8 x i16> zeroinitializer) #5
  %431 = lshr <8 x i16> %430, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %432 = getelementptr inbounds i8, i8* %0, i64 432
  %433 = bitcast i8* %432 to <8 x i16>*
  %434 = load <8 x i16>, <8 x i16>* %433, align 16
  %435 = getelementptr inbounds i8, i8* %1, i64 432
  %436 = bitcast i8* %435 to <8 x i16>*
  %437 = load <8 x i16>, <8 x i16>* %436, align 16
  %438 = sub <8 x i16> %434, %437
  %439 = sub <8 x i16> zeroinitializer, %438
  %440 = icmp slt <8 x i16> %438, zeroinitializer
  %441 = select <8 x i1> %440, <8 x i16> %439, <8 x i16> %438
  %442 = lshr <8 x i16> %441, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %443 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %442, <8 x i16> zeroinitializer) #5
  %444 = lshr <8 x i16> %443, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %445 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %431, <8 x i16> %444) #5
  %446 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %445, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %447 = icmp slt <16 x i8> %446, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %448 = select <16 x i1> %447, <16 x i8> %446, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %449 = bitcast i8* %420 to <16 x i8>*
  store <16 x i8> %448, <16 x i8>* %449, align 16
  %450 = getelementptr inbounds i8, i8* %0, i64 448
  %451 = getelementptr inbounds i8, i8* %1, i64 448
  %452 = getelementptr inbounds i8, i8* %388, i64 %3
  %453 = bitcast i8* %450 to <8 x i16>*
  %454 = load <8 x i16>, <8 x i16>* %453, align 16
  %455 = bitcast i8* %451 to <8 x i16>*
  %456 = load <8 x i16>, <8 x i16>* %455, align 16
  %457 = sub <8 x i16> %454, %456
  %458 = sub <8 x i16> zeroinitializer, %457
  %459 = icmp slt <8 x i16> %457, zeroinitializer
  %460 = select <8 x i1> %459, <8 x i16> %458, <8 x i16> %457
  %461 = lshr <8 x i16> %460, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %462 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %461, <8 x i16> zeroinitializer) #5
  %463 = lshr <8 x i16> %462, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %464 = getelementptr inbounds i8, i8* %0, i64 464
  %465 = bitcast i8* %464 to <8 x i16>*
  %466 = load <8 x i16>, <8 x i16>* %465, align 16
  %467 = getelementptr inbounds i8, i8* %1, i64 464
  %468 = bitcast i8* %467 to <8 x i16>*
  %469 = load <8 x i16>, <8 x i16>* %468, align 16
  %470 = sub <8 x i16> %466, %469
  %471 = sub <8 x i16> zeroinitializer, %470
  %472 = icmp slt <8 x i16> %470, zeroinitializer
  %473 = select <8 x i1> %472, <8 x i16> %471, <8 x i16> %470
  %474 = lshr <8 x i16> %473, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %475 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %474, <8 x i16> zeroinitializer) #5
  %476 = lshr <8 x i16> %475, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %477 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %463, <8 x i16> %476) #5
  %478 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %477, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %479 = icmp slt <16 x i8> %478, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %480 = select <16 x i1> %479, <16 x i8> %478, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %481 = bitcast i8* %452 to <16 x i8>*
  store <16 x i8> %480, <16 x i8>* %481, align 16
  %482 = getelementptr inbounds i8, i8* %0, i64 480
  %483 = getelementptr inbounds i8, i8* %1, i64 480
  %484 = getelementptr inbounds i8, i8* %452, i64 16
  %485 = bitcast i8* %482 to <8 x i16>*
  %486 = load <8 x i16>, <8 x i16>* %485, align 16
  %487 = bitcast i8* %483 to <8 x i16>*
  %488 = load <8 x i16>, <8 x i16>* %487, align 16
  %489 = sub <8 x i16> %486, %488
  %490 = sub <8 x i16> zeroinitializer, %489
  %491 = icmp slt <8 x i16> %489, zeroinitializer
  %492 = select <8 x i1> %491, <8 x i16> %490, <8 x i16> %489
  %493 = lshr <8 x i16> %492, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %494 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %493, <8 x i16> zeroinitializer) #5
  %495 = lshr <8 x i16> %494, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %496 = getelementptr inbounds i8, i8* %0, i64 496
  %497 = bitcast i8* %496 to <8 x i16>*
  %498 = load <8 x i16>, <8 x i16>* %497, align 16
  %499 = getelementptr inbounds i8, i8* %1, i64 496
  %500 = bitcast i8* %499 to <8 x i16>*
  %501 = load <8 x i16>, <8 x i16>* %500, align 16
  %502 = sub <8 x i16> %498, %501
  %503 = sub <8 x i16> zeroinitializer, %502
  %504 = icmp slt <8 x i16> %502, zeroinitializer
  %505 = select <8 x i1> %504, <8 x i16> %503, <8 x i16> %502
  %506 = lshr <8 x i16> %505, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %507 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %506, <8 x i16> zeroinitializer) #5
  %508 = lshr <8 x i16> %507, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %509 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %495, <8 x i16> %508) #5
  %510 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %509, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %511 = icmp slt <16 x i8> %510, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %512 = select <16 x i1> %511, <16 x i8> %510, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %513 = bitcast i8* %484 to <16 x i8>*
  store <16 x i8> %512, <16 x i8>* %513, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_119WeightMask32x8_SSE4ILb1EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to <8 x i16>*
  %6 = load <8 x i16>, <8 x i16>* %5, align 16
  %7 = bitcast i8* %1 to <8 x i16>*
  %8 = load <8 x i16>, <8 x i16>* %7, align 16
  %9 = sub <8 x i16> %6, %8
  %10 = sub <8 x i16> zeroinitializer, %9
  %11 = icmp slt <8 x i16> %9, zeroinitializer
  %12 = select <8 x i1> %11, <8 x i16> %10, <8 x i16> %9
  %13 = lshr <8 x i16> %12, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %14 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %13, <8 x i16> zeroinitializer) #5
  %15 = lshr <8 x i16> %14, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %16 = getelementptr inbounds i8, i8* %0, i64 16
  %17 = bitcast i8* %16 to <8 x i16>*
  %18 = load <8 x i16>, <8 x i16>* %17, align 16
  %19 = getelementptr inbounds i8, i8* %1, i64 16
  %20 = bitcast i8* %19 to <8 x i16>*
  %21 = load <8 x i16>, <8 x i16>* %20, align 16
  %22 = sub <8 x i16> %18, %21
  %23 = sub <8 x i16> zeroinitializer, %22
  %24 = icmp slt <8 x i16> %22, zeroinitializer
  %25 = select <8 x i1> %24, <8 x i16> %23, <8 x i16> %22
  %26 = lshr <8 x i16> %25, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %27 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %26, <8 x i16> zeroinitializer) #5
  %28 = lshr <8 x i16> %27, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %29 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %15, <8 x i16> %28) #5
  %30 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %29, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %31 = icmp slt <16 x i8> %30, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %32 = select <16 x i1> %31, <16 x i8> %30, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %33 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %32
  %34 = bitcast i8* %2 to <16 x i8>*
  store <16 x i8> %33, <16 x i8>* %34, align 16
  %35 = getelementptr inbounds i8, i8* %0, i64 32
  %36 = getelementptr inbounds i8, i8* %1, i64 32
  %37 = getelementptr inbounds i8, i8* %2, i64 16
  %38 = bitcast i8* %35 to <8 x i16>*
  %39 = load <8 x i16>, <8 x i16>* %38, align 16
  %40 = bitcast i8* %36 to <8 x i16>*
  %41 = load <8 x i16>, <8 x i16>* %40, align 16
  %42 = sub <8 x i16> %39, %41
  %43 = sub <8 x i16> zeroinitializer, %42
  %44 = icmp slt <8 x i16> %42, zeroinitializer
  %45 = select <8 x i1> %44, <8 x i16> %43, <8 x i16> %42
  %46 = lshr <8 x i16> %45, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %47 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %46, <8 x i16> zeroinitializer) #5
  %48 = lshr <8 x i16> %47, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %49 = getelementptr inbounds i8, i8* %0, i64 48
  %50 = bitcast i8* %49 to <8 x i16>*
  %51 = load <8 x i16>, <8 x i16>* %50, align 16
  %52 = getelementptr inbounds i8, i8* %1, i64 48
  %53 = bitcast i8* %52 to <8 x i16>*
  %54 = load <8 x i16>, <8 x i16>* %53, align 16
  %55 = sub <8 x i16> %51, %54
  %56 = sub <8 x i16> zeroinitializer, %55
  %57 = icmp slt <8 x i16> %55, zeroinitializer
  %58 = select <8 x i1> %57, <8 x i16> %56, <8 x i16> %55
  %59 = lshr <8 x i16> %58, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %60 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %59, <8 x i16> zeroinitializer) #5
  %61 = lshr <8 x i16> %60, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %62 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %48, <8 x i16> %61) #5
  %63 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %62, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %64 = icmp slt <16 x i8> %63, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %65 = select <16 x i1> %64, <16 x i8> %63, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %66 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %65
  %67 = bitcast i8* %37 to <16 x i8>*
  store <16 x i8> %66, <16 x i8>* %67, align 16
  %68 = getelementptr inbounds i8, i8* %0, i64 64
  %69 = getelementptr inbounds i8, i8* %1, i64 64
  %70 = getelementptr inbounds i8, i8* %2, i64 %3
  %71 = bitcast i8* %68 to <8 x i16>*
  %72 = load <8 x i16>, <8 x i16>* %71, align 16
  %73 = bitcast i8* %69 to <8 x i16>*
  %74 = load <8 x i16>, <8 x i16>* %73, align 16
  %75 = sub <8 x i16> %72, %74
  %76 = sub <8 x i16> zeroinitializer, %75
  %77 = icmp slt <8 x i16> %75, zeroinitializer
  %78 = select <8 x i1> %77, <8 x i16> %76, <8 x i16> %75
  %79 = lshr <8 x i16> %78, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %80 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %79, <8 x i16> zeroinitializer) #5
  %81 = lshr <8 x i16> %80, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %82 = getelementptr inbounds i8, i8* %0, i64 80
  %83 = bitcast i8* %82 to <8 x i16>*
  %84 = load <8 x i16>, <8 x i16>* %83, align 16
  %85 = getelementptr inbounds i8, i8* %1, i64 80
  %86 = bitcast i8* %85 to <8 x i16>*
  %87 = load <8 x i16>, <8 x i16>* %86, align 16
  %88 = sub <8 x i16> %84, %87
  %89 = sub <8 x i16> zeroinitializer, %88
  %90 = icmp slt <8 x i16> %88, zeroinitializer
  %91 = select <8 x i1> %90, <8 x i16> %89, <8 x i16> %88
  %92 = lshr <8 x i16> %91, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %93 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %92, <8 x i16> zeroinitializer) #5
  %94 = lshr <8 x i16> %93, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %95 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %81, <8 x i16> %94) #5
  %96 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %95, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %97 = icmp slt <16 x i8> %96, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %98 = select <16 x i1> %97, <16 x i8> %96, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %99 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %98
  %100 = bitcast i8* %70 to <16 x i8>*
  store <16 x i8> %99, <16 x i8>* %100, align 16
  %101 = getelementptr inbounds i8, i8* %0, i64 96
  %102 = getelementptr inbounds i8, i8* %1, i64 96
  %103 = getelementptr inbounds i8, i8* %70, i64 16
  %104 = bitcast i8* %101 to <8 x i16>*
  %105 = load <8 x i16>, <8 x i16>* %104, align 16
  %106 = bitcast i8* %102 to <8 x i16>*
  %107 = load <8 x i16>, <8 x i16>* %106, align 16
  %108 = sub <8 x i16> %105, %107
  %109 = sub <8 x i16> zeroinitializer, %108
  %110 = icmp slt <8 x i16> %108, zeroinitializer
  %111 = select <8 x i1> %110, <8 x i16> %109, <8 x i16> %108
  %112 = lshr <8 x i16> %111, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %113 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %112, <8 x i16> zeroinitializer) #5
  %114 = lshr <8 x i16> %113, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %115 = getelementptr inbounds i8, i8* %0, i64 112
  %116 = bitcast i8* %115 to <8 x i16>*
  %117 = load <8 x i16>, <8 x i16>* %116, align 16
  %118 = getelementptr inbounds i8, i8* %1, i64 112
  %119 = bitcast i8* %118 to <8 x i16>*
  %120 = load <8 x i16>, <8 x i16>* %119, align 16
  %121 = sub <8 x i16> %117, %120
  %122 = sub <8 x i16> zeroinitializer, %121
  %123 = icmp slt <8 x i16> %121, zeroinitializer
  %124 = select <8 x i1> %123, <8 x i16> %122, <8 x i16> %121
  %125 = lshr <8 x i16> %124, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %126 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %125, <8 x i16> zeroinitializer) #5
  %127 = lshr <8 x i16> %126, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %128 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %114, <8 x i16> %127) #5
  %129 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %128, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %130 = icmp slt <16 x i8> %129, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %131 = select <16 x i1> %130, <16 x i8> %129, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %132 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %131
  %133 = bitcast i8* %103 to <16 x i8>*
  store <16 x i8> %132, <16 x i8>* %133, align 16
  %134 = getelementptr inbounds i8, i8* %0, i64 128
  %135 = getelementptr inbounds i8, i8* %1, i64 128
  %136 = getelementptr inbounds i8, i8* %70, i64 %3
  %137 = bitcast i8* %134 to <8 x i16>*
  %138 = load <8 x i16>, <8 x i16>* %137, align 16
  %139 = bitcast i8* %135 to <8 x i16>*
  %140 = load <8 x i16>, <8 x i16>* %139, align 16
  %141 = sub <8 x i16> %138, %140
  %142 = sub <8 x i16> zeroinitializer, %141
  %143 = icmp slt <8 x i16> %141, zeroinitializer
  %144 = select <8 x i1> %143, <8 x i16> %142, <8 x i16> %141
  %145 = lshr <8 x i16> %144, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %146 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %145, <8 x i16> zeroinitializer) #5
  %147 = lshr <8 x i16> %146, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %148 = getelementptr inbounds i8, i8* %0, i64 144
  %149 = bitcast i8* %148 to <8 x i16>*
  %150 = load <8 x i16>, <8 x i16>* %149, align 16
  %151 = getelementptr inbounds i8, i8* %1, i64 144
  %152 = bitcast i8* %151 to <8 x i16>*
  %153 = load <8 x i16>, <8 x i16>* %152, align 16
  %154 = sub <8 x i16> %150, %153
  %155 = sub <8 x i16> zeroinitializer, %154
  %156 = icmp slt <8 x i16> %154, zeroinitializer
  %157 = select <8 x i1> %156, <8 x i16> %155, <8 x i16> %154
  %158 = lshr <8 x i16> %157, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %159 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %158, <8 x i16> zeroinitializer) #5
  %160 = lshr <8 x i16> %159, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %161 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %147, <8 x i16> %160) #5
  %162 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %161, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %163 = icmp slt <16 x i8> %162, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %164 = select <16 x i1> %163, <16 x i8> %162, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %165 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %164
  %166 = bitcast i8* %136 to <16 x i8>*
  store <16 x i8> %165, <16 x i8>* %166, align 16
  %167 = getelementptr inbounds i8, i8* %0, i64 160
  %168 = getelementptr inbounds i8, i8* %1, i64 160
  %169 = getelementptr inbounds i8, i8* %136, i64 16
  %170 = bitcast i8* %167 to <8 x i16>*
  %171 = load <8 x i16>, <8 x i16>* %170, align 16
  %172 = bitcast i8* %168 to <8 x i16>*
  %173 = load <8 x i16>, <8 x i16>* %172, align 16
  %174 = sub <8 x i16> %171, %173
  %175 = sub <8 x i16> zeroinitializer, %174
  %176 = icmp slt <8 x i16> %174, zeroinitializer
  %177 = select <8 x i1> %176, <8 x i16> %175, <8 x i16> %174
  %178 = lshr <8 x i16> %177, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %179 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %178, <8 x i16> zeroinitializer) #5
  %180 = lshr <8 x i16> %179, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %181 = getelementptr inbounds i8, i8* %0, i64 176
  %182 = bitcast i8* %181 to <8 x i16>*
  %183 = load <8 x i16>, <8 x i16>* %182, align 16
  %184 = getelementptr inbounds i8, i8* %1, i64 176
  %185 = bitcast i8* %184 to <8 x i16>*
  %186 = load <8 x i16>, <8 x i16>* %185, align 16
  %187 = sub <8 x i16> %183, %186
  %188 = sub <8 x i16> zeroinitializer, %187
  %189 = icmp slt <8 x i16> %187, zeroinitializer
  %190 = select <8 x i1> %189, <8 x i16> %188, <8 x i16> %187
  %191 = lshr <8 x i16> %190, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %192 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %191, <8 x i16> zeroinitializer) #5
  %193 = lshr <8 x i16> %192, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %194 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %180, <8 x i16> %193) #5
  %195 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %194, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %196 = icmp slt <16 x i8> %195, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %197 = select <16 x i1> %196, <16 x i8> %195, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %198 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %197
  %199 = bitcast i8* %169 to <16 x i8>*
  store <16 x i8> %198, <16 x i8>* %199, align 16
  %200 = getelementptr inbounds i8, i8* %0, i64 192
  %201 = getelementptr inbounds i8, i8* %1, i64 192
  %202 = getelementptr inbounds i8, i8* %136, i64 %3
  %203 = bitcast i8* %200 to <8 x i16>*
  %204 = load <8 x i16>, <8 x i16>* %203, align 16
  %205 = bitcast i8* %201 to <8 x i16>*
  %206 = load <8 x i16>, <8 x i16>* %205, align 16
  %207 = sub <8 x i16> %204, %206
  %208 = sub <8 x i16> zeroinitializer, %207
  %209 = icmp slt <8 x i16> %207, zeroinitializer
  %210 = select <8 x i1> %209, <8 x i16> %208, <8 x i16> %207
  %211 = lshr <8 x i16> %210, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %212 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %211, <8 x i16> zeroinitializer) #5
  %213 = lshr <8 x i16> %212, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %214 = getelementptr inbounds i8, i8* %0, i64 208
  %215 = bitcast i8* %214 to <8 x i16>*
  %216 = load <8 x i16>, <8 x i16>* %215, align 16
  %217 = getelementptr inbounds i8, i8* %1, i64 208
  %218 = bitcast i8* %217 to <8 x i16>*
  %219 = load <8 x i16>, <8 x i16>* %218, align 16
  %220 = sub <8 x i16> %216, %219
  %221 = sub <8 x i16> zeroinitializer, %220
  %222 = icmp slt <8 x i16> %220, zeroinitializer
  %223 = select <8 x i1> %222, <8 x i16> %221, <8 x i16> %220
  %224 = lshr <8 x i16> %223, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %225 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %224, <8 x i16> zeroinitializer) #5
  %226 = lshr <8 x i16> %225, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %227 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %213, <8 x i16> %226) #5
  %228 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %227, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %229 = icmp slt <16 x i8> %228, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %230 = select <16 x i1> %229, <16 x i8> %228, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %231 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %230
  %232 = bitcast i8* %202 to <16 x i8>*
  store <16 x i8> %231, <16 x i8>* %232, align 16
  %233 = getelementptr inbounds i8, i8* %0, i64 224
  %234 = getelementptr inbounds i8, i8* %1, i64 224
  %235 = getelementptr inbounds i8, i8* %202, i64 16
  %236 = bitcast i8* %233 to <8 x i16>*
  %237 = load <8 x i16>, <8 x i16>* %236, align 16
  %238 = bitcast i8* %234 to <8 x i16>*
  %239 = load <8 x i16>, <8 x i16>* %238, align 16
  %240 = sub <8 x i16> %237, %239
  %241 = sub <8 x i16> zeroinitializer, %240
  %242 = icmp slt <8 x i16> %240, zeroinitializer
  %243 = select <8 x i1> %242, <8 x i16> %241, <8 x i16> %240
  %244 = lshr <8 x i16> %243, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %245 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %244, <8 x i16> zeroinitializer) #5
  %246 = lshr <8 x i16> %245, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %247 = getelementptr inbounds i8, i8* %0, i64 240
  %248 = bitcast i8* %247 to <8 x i16>*
  %249 = load <8 x i16>, <8 x i16>* %248, align 16
  %250 = getelementptr inbounds i8, i8* %1, i64 240
  %251 = bitcast i8* %250 to <8 x i16>*
  %252 = load <8 x i16>, <8 x i16>* %251, align 16
  %253 = sub <8 x i16> %249, %252
  %254 = sub <8 x i16> zeroinitializer, %253
  %255 = icmp slt <8 x i16> %253, zeroinitializer
  %256 = select <8 x i1> %255, <8 x i16> %254, <8 x i16> %253
  %257 = lshr <8 x i16> %256, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %258 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %257, <8 x i16> zeroinitializer) #5
  %259 = lshr <8 x i16> %258, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %260 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %246, <8 x i16> %259) #5
  %261 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %260, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %262 = icmp slt <16 x i8> %261, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %263 = select <16 x i1> %262, <16 x i8> %261, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %264 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %263
  %265 = bitcast i8* %235 to <16 x i8>*
  store <16 x i8> %264, <16 x i8>* %265, align 16
  %266 = getelementptr inbounds i8, i8* %0, i64 256
  %267 = getelementptr inbounds i8, i8* %1, i64 256
  %268 = getelementptr inbounds i8, i8* %202, i64 %3
  %269 = bitcast i8* %266 to <8 x i16>*
  %270 = load <8 x i16>, <8 x i16>* %269, align 16
  %271 = bitcast i8* %267 to <8 x i16>*
  %272 = load <8 x i16>, <8 x i16>* %271, align 16
  %273 = sub <8 x i16> %270, %272
  %274 = sub <8 x i16> zeroinitializer, %273
  %275 = icmp slt <8 x i16> %273, zeroinitializer
  %276 = select <8 x i1> %275, <8 x i16> %274, <8 x i16> %273
  %277 = lshr <8 x i16> %276, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %278 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %277, <8 x i16> zeroinitializer) #5
  %279 = lshr <8 x i16> %278, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %280 = getelementptr inbounds i8, i8* %0, i64 272
  %281 = bitcast i8* %280 to <8 x i16>*
  %282 = load <8 x i16>, <8 x i16>* %281, align 16
  %283 = getelementptr inbounds i8, i8* %1, i64 272
  %284 = bitcast i8* %283 to <8 x i16>*
  %285 = load <8 x i16>, <8 x i16>* %284, align 16
  %286 = sub <8 x i16> %282, %285
  %287 = sub <8 x i16> zeroinitializer, %286
  %288 = icmp slt <8 x i16> %286, zeroinitializer
  %289 = select <8 x i1> %288, <8 x i16> %287, <8 x i16> %286
  %290 = lshr <8 x i16> %289, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %291 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %290, <8 x i16> zeroinitializer) #5
  %292 = lshr <8 x i16> %291, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %293 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %279, <8 x i16> %292) #5
  %294 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %293, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %295 = icmp slt <16 x i8> %294, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %296 = select <16 x i1> %295, <16 x i8> %294, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %297 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %296
  %298 = bitcast i8* %268 to <16 x i8>*
  store <16 x i8> %297, <16 x i8>* %298, align 16
  %299 = getelementptr inbounds i8, i8* %0, i64 288
  %300 = getelementptr inbounds i8, i8* %1, i64 288
  %301 = getelementptr inbounds i8, i8* %268, i64 16
  %302 = bitcast i8* %299 to <8 x i16>*
  %303 = load <8 x i16>, <8 x i16>* %302, align 16
  %304 = bitcast i8* %300 to <8 x i16>*
  %305 = load <8 x i16>, <8 x i16>* %304, align 16
  %306 = sub <8 x i16> %303, %305
  %307 = sub <8 x i16> zeroinitializer, %306
  %308 = icmp slt <8 x i16> %306, zeroinitializer
  %309 = select <8 x i1> %308, <8 x i16> %307, <8 x i16> %306
  %310 = lshr <8 x i16> %309, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %311 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %310, <8 x i16> zeroinitializer) #5
  %312 = lshr <8 x i16> %311, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %313 = getelementptr inbounds i8, i8* %0, i64 304
  %314 = bitcast i8* %313 to <8 x i16>*
  %315 = load <8 x i16>, <8 x i16>* %314, align 16
  %316 = getelementptr inbounds i8, i8* %1, i64 304
  %317 = bitcast i8* %316 to <8 x i16>*
  %318 = load <8 x i16>, <8 x i16>* %317, align 16
  %319 = sub <8 x i16> %315, %318
  %320 = sub <8 x i16> zeroinitializer, %319
  %321 = icmp slt <8 x i16> %319, zeroinitializer
  %322 = select <8 x i1> %321, <8 x i16> %320, <8 x i16> %319
  %323 = lshr <8 x i16> %322, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %324 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %323, <8 x i16> zeroinitializer) #5
  %325 = lshr <8 x i16> %324, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %326 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %312, <8 x i16> %325) #5
  %327 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %326, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %328 = icmp slt <16 x i8> %327, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %329 = select <16 x i1> %328, <16 x i8> %327, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %330 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %329
  %331 = bitcast i8* %301 to <16 x i8>*
  store <16 x i8> %330, <16 x i8>* %331, align 16
  %332 = getelementptr inbounds i8, i8* %0, i64 320
  %333 = getelementptr inbounds i8, i8* %1, i64 320
  %334 = getelementptr inbounds i8, i8* %268, i64 %3
  %335 = bitcast i8* %332 to <8 x i16>*
  %336 = load <8 x i16>, <8 x i16>* %335, align 16
  %337 = bitcast i8* %333 to <8 x i16>*
  %338 = load <8 x i16>, <8 x i16>* %337, align 16
  %339 = sub <8 x i16> %336, %338
  %340 = sub <8 x i16> zeroinitializer, %339
  %341 = icmp slt <8 x i16> %339, zeroinitializer
  %342 = select <8 x i1> %341, <8 x i16> %340, <8 x i16> %339
  %343 = lshr <8 x i16> %342, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %344 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %343, <8 x i16> zeroinitializer) #5
  %345 = lshr <8 x i16> %344, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %346 = getelementptr inbounds i8, i8* %0, i64 336
  %347 = bitcast i8* %346 to <8 x i16>*
  %348 = load <8 x i16>, <8 x i16>* %347, align 16
  %349 = getelementptr inbounds i8, i8* %1, i64 336
  %350 = bitcast i8* %349 to <8 x i16>*
  %351 = load <8 x i16>, <8 x i16>* %350, align 16
  %352 = sub <8 x i16> %348, %351
  %353 = sub <8 x i16> zeroinitializer, %352
  %354 = icmp slt <8 x i16> %352, zeroinitializer
  %355 = select <8 x i1> %354, <8 x i16> %353, <8 x i16> %352
  %356 = lshr <8 x i16> %355, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %357 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %356, <8 x i16> zeroinitializer) #5
  %358 = lshr <8 x i16> %357, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %359 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %345, <8 x i16> %358) #5
  %360 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %359, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %361 = icmp slt <16 x i8> %360, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %362 = select <16 x i1> %361, <16 x i8> %360, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %363 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %362
  %364 = bitcast i8* %334 to <16 x i8>*
  store <16 x i8> %363, <16 x i8>* %364, align 16
  %365 = getelementptr inbounds i8, i8* %0, i64 352
  %366 = getelementptr inbounds i8, i8* %1, i64 352
  %367 = getelementptr inbounds i8, i8* %334, i64 16
  %368 = bitcast i8* %365 to <8 x i16>*
  %369 = load <8 x i16>, <8 x i16>* %368, align 16
  %370 = bitcast i8* %366 to <8 x i16>*
  %371 = load <8 x i16>, <8 x i16>* %370, align 16
  %372 = sub <8 x i16> %369, %371
  %373 = sub <8 x i16> zeroinitializer, %372
  %374 = icmp slt <8 x i16> %372, zeroinitializer
  %375 = select <8 x i1> %374, <8 x i16> %373, <8 x i16> %372
  %376 = lshr <8 x i16> %375, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %377 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %376, <8 x i16> zeroinitializer) #5
  %378 = lshr <8 x i16> %377, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %379 = getelementptr inbounds i8, i8* %0, i64 368
  %380 = bitcast i8* %379 to <8 x i16>*
  %381 = load <8 x i16>, <8 x i16>* %380, align 16
  %382 = getelementptr inbounds i8, i8* %1, i64 368
  %383 = bitcast i8* %382 to <8 x i16>*
  %384 = load <8 x i16>, <8 x i16>* %383, align 16
  %385 = sub <8 x i16> %381, %384
  %386 = sub <8 x i16> zeroinitializer, %385
  %387 = icmp slt <8 x i16> %385, zeroinitializer
  %388 = select <8 x i1> %387, <8 x i16> %386, <8 x i16> %385
  %389 = lshr <8 x i16> %388, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %390 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %389, <8 x i16> zeroinitializer) #5
  %391 = lshr <8 x i16> %390, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %392 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %378, <8 x i16> %391) #5
  %393 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %392, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %394 = icmp slt <16 x i8> %393, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %395 = select <16 x i1> %394, <16 x i8> %393, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %396 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %395
  %397 = bitcast i8* %367 to <16 x i8>*
  store <16 x i8> %396, <16 x i8>* %397, align 16
  %398 = getelementptr inbounds i8, i8* %0, i64 384
  %399 = getelementptr inbounds i8, i8* %1, i64 384
  %400 = getelementptr inbounds i8, i8* %334, i64 %3
  %401 = bitcast i8* %398 to <8 x i16>*
  %402 = load <8 x i16>, <8 x i16>* %401, align 16
  %403 = bitcast i8* %399 to <8 x i16>*
  %404 = load <8 x i16>, <8 x i16>* %403, align 16
  %405 = sub <8 x i16> %402, %404
  %406 = sub <8 x i16> zeroinitializer, %405
  %407 = icmp slt <8 x i16> %405, zeroinitializer
  %408 = select <8 x i1> %407, <8 x i16> %406, <8 x i16> %405
  %409 = lshr <8 x i16> %408, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %410 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %409, <8 x i16> zeroinitializer) #5
  %411 = lshr <8 x i16> %410, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %412 = getelementptr inbounds i8, i8* %0, i64 400
  %413 = bitcast i8* %412 to <8 x i16>*
  %414 = load <8 x i16>, <8 x i16>* %413, align 16
  %415 = getelementptr inbounds i8, i8* %1, i64 400
  %416 = bitcast i8* %415 to <8 x i16>*
  %417 = load <8 x i16>, <8 x i16>* %416, align 16
  %418 = sub <8 x i16> %414, %417
  %419 = sub <8 x i16> zeroinitializer, %418
  %420 = icmp slt <8 x i16> %418, zeroinitializer
  %421 = select <8 x i1> %420, <8 x i16> %419, <8 x i16> %418
  %422 = lshr <8 x i16> %421, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %423 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %422, <8 x i16> zeroinitializer) #5
  %424 = lshr <8 x i16> %423, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %425 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %411, <8 x i16> %424) #5
  %426 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %425, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %427 = icmp slt <16 x i8> %426, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %428 = select <16 x i1> %427, <16 x i8> %426, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %429 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %428
  %430 = bitcast i8* %400 to <16 x i8>*
  store <16 x i8> %429, <16 x i8>* %430, align 16
  %431 = getelementptr inbounds i8, i8* %0, i64 416
  %432 = getelementptr inbounds i8, i8* %1, i64 416
  %433 = getelementptr inbounds i8, i8* %400, i64 16
  %434 = bitcast i8* %431 to <8 x i16>*
  %435 = load <8 x i16>, <8 x i16>* %434, align 16
  %436 = bitcast i8* %432 to <8 x i16>*
  %437 = load <8 x i16>, <8 x i16>* %436, align 16
  %438 = sub <8 x i16> %435, %437
  %439 = sub <8 x i16> zeroinitializer, %438
  %440 = icmp slt <8 x i16> %438, zeroinitializer
  %441 = select <8 x i1> %440, <8 x i16> %439, <8 x i16> %438
  %442 = lshr <8 x i16> %441, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %443 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %442, <8 x i16> zeroinitializer) #5
  %444 = lshr <8 x i16> %443, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %445 = getelementptr inbounds i8, i8* %0, i64 432
  %446 = bitcast i8* %445 to <8 x i16>*
  %447 = load <8 x i16>, <8 x i16>* %446, align 16
  %448 = getelementptr inbounds i8, i8* %1, i64 432
  %449 = bitcast i8* %448 to <8 x i16>*
  %450 = load <8 x i16>, <8 x i16>* %449, align 16
  %451 = sub <8 x i16> %447, %450
  %452 = sub <8 x i16> zeroinitializer, %451
  %453 = icmp slt <8 x i16> %451, zeroinitializer
  %454 = select <8 x i1> %453, <8 x i16> %452, <8 x i16> %451
  %455 = lshr <8 x i16> %454, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %456 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %455, <8 x i16> zeroinitializer) #5
  %457 = lshr <8 x i16> %456, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %458 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %444, <8 x i16> %457) #5
  %459 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %458, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %460 = icmp slt <16 x i8> %459, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %461 = select <16 x i1> %460, <16 x i8> %459, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %462 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %461
  %463 = bitcast i8* %433 to <16 x i8>*
  store <16 x i8> %462, <16 x i8>* %463, align 16
  %464 = getelementptr inbounds i8, i8* %0, i64 448
  %465 = getelementptr inbounds i8, i8* %1, i64 448
  %466 = getelementptr inbounds i8, i8* %400, i64 %3
  %467 = bitcast i8* %464 to <8 x i16>*
  %468 = load <8 x i16>, <8 x i16>* %467, align 16
  %469 = bitcast i8* %465 to <8 x i16>*
  %470 = load <8 x i16>, <8 x i16>* %469, align 16
  %471 = sub <8 x i16> %468, %470
  %472 = sub <8 x i16> zeroinitializer, %471
  %473 = icmp slt <8 x i16> %471, zeroinitializer
  %474 = select <8 x i1> %473, <8 x i16> %472, <8 x i16> %471
  %475 = lshr <8 x i16> %474, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %476 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %475, <8 x i16> zeroinitializer) #5
  %477 = lshr <8 x i16> %476, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %478 = getelementptr inbounds i8, i8* %0, i64 464
  %479 = bitcast i8* %478 to <8 x i16>*
  %480 = load <8 x i16>, <8 x i16>* %479, align 16
  %481 = getelementptr inbounds i8, i8* %1, i64 464
  %482 = bitcast i8* %481 to <8 x i16>*
  %483 = load <8 x i16>, <8 x i16>* %482, align 16
  %484 = sub <8 x i16> %480, %483
  %485 = sub <8 x i16> zeroinitializer, %484
  %486 = icmp slt <8 x i16> %484, zeroinitializer
  %487 = select <8 x i1> %486, <8 x i16> %485, <8 x i16> %484
  %488 = lshr <8 x i16> %487, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %489 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %488, <8 x i16> zeroinitializer) #5
  %490 = lshr <8 x i16> %489, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %491 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %477, <8 x i16> %490) #5
  %492 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %491, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %493 = icmp slt <16 x i8> %492, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %494 = select <16 x i1> %493, <16 x i8> %492, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %495 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %494
  %496 = bitcast i8* %466 to <16 x i8>*
  store <16 x i8> %495, <16 x i8>* %496, align 16
  %497 = getelementptr inbounds i8, i8* %0, i64 480
  %498 = getelementptr inbounds i8, i8* %1, i64 480
  %499 = getelementptr inbounds i8, i8* %466, i64 16
  %500 = bitcast i8* %497 to <8 x i16>*
  %501 = load <8 x i16>, <8 x i16>* %500, align 16
  %502 = bitcast i8* %498 to <8 x i16>*
  %503 = load <8 x i16>, <8 x i16>* %502, align 16
  %504 = sub <8 x i16> %501, %503
  %505 = sub <8 x i16> zeroinitializer, %504
  %506 = icmp slt <8 x i16> %504, zeroinitializer
  %507 = select <8 x i1> %506, <8 x i16> %505, <8 x i16> %504
  %508 = lshr <8 x i16> %507, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %509 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %508, <8 x i16> zeroinitializer) #5
  %510 = lshr <8 x i16> %509, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %511 = getelementptr inbounds i8, i8* %0, i64 496
  %512 = bitcast i8* %511 to <8 x i16>*
  %513 = load <8 x i16>, <8 x i16>* %512, align 16
  %514 = getelementptr inbounds i8, i8* %1, i64 496
  %515 = bitcast i8* %514 to <8 x i16>*
  %516 = load <8 x i16>, <8 x i16>* %515, align 16
  %517 = sub <8 x i16> %513, %516
  %518 = sub <8 x i16> zeroinitializer, %517
  %519 = icmp slt <8 x i16> %517, zeroinitializer
  %520 = select <8 x i1> %519, <8 x i16> %518, <8 x i16> %517
  %521 = lshr <8 x i16> %520, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %522 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %521, <8 x i16> zeroinitializer) #5
  %523 = lshr <8 x i16> %522, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %524 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %510, <8 x i16> %523) #5
  %525 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %524, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %526 = icmp slt <16 x i8> %525, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %527 = select <16 x i1> %526, <16 x i8> %525, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %528 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %527
  %529 = bitcast i8* %499 to <16 x i8>*
  store <16 x i8> %528, <16 x i8>* %529, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask32x16_SSE4ILb0EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %203, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %201, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %202, %7 ]
  %11 = phi i32 [ 5, %4 ], [ %204, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = sub <8 x i16> %13, %15
  %17 = sub <8 x i16> zeroinitializer, %16
  %18 = icmp slt <8 x i16> %16, zeroinitializer
  %19 = select <8 x i1> %18, <8 x i16> %17, <8 x i16> %16
  %20 = lshr <8 x i16> %19, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %21 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %20, <8 x i16> zeroinitializer) #5
  %22 = lshr <8 x i16> %21, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %23 = getelementptr inbounds i16, i16* %9, i64 8
  %24 = bitcast i16* %23 to <8 x i16>*
  %25 = load <8 x i16>, <8 x i16>* %24, align 16
  %26 = getelementptr inbounds i16, i16* %10, i64 8
  %27 = bitcast i16* %26 to <8 x i16>*
  %28 = load <8 x i16>, <8 x i16>* %27, align 16
  %29 = sub <8 x i16> %25, %28
  %30 = sub <8 x i16> zeroinitializer, %29
  %31 = icmp slt <8 x i16> %29, zeroinitializer
  %32 = select <8 x i1> %31, <8 x i16> %30, <8 x i16> %29
  %33 = lshr <8 x i16> %32, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %34 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %33, <8 x i16> zeroinitializer) #5
  %35 = lshr <8 x i16> %34, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %36 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %22, <8 x i16> %35) #5
  %37 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %36, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %38 = icmp slt <16 x i8> %37, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %39 = select <16 x i1> %38, <16 x i8> %37, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %40 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %40, align 16
  %41 = getelementptr inbounds i16, i16* %9, i64 16
  %42 = getelementptr inbounds i16, i16* %10, i64 16
  %43 = getelementptr inbounds i8, i8* %8, i64 16
  %44 = bitcast i16* %41 to <8 x i16>*
  %45 = load <8 x i16>, <8 x i16>* %44, align 16
  %46 = bitcast i16* %42 to <8 x i16>*
  %47 = load <8 x i16>, <8 x i16>* %46, align 16
  %48 = sub <8 x i16> %45, %47
  %49 = sub <8 x i16> zeroinitializer, %48
  %50 = icmp slt <8 x i16> %48, zeroinitializer
  %51 = select <8 x i1> %50, <8 x i16> %49, <8 x i16> %48
  %52 = lshr <8 x i16> %51, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %53 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %52, <8 x i16> zeroinitializer) #5
  %54 = lshr <8 x i16> %53, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %55 = getelementptr inbounds i16, i16* %9, i64 24
  %56 = bitcast i16* %55 to <8 x i16>*
  %57 = load <8 x i16>, <8 x i16>* %56, align 16
  %58 = getelementptr inbounds i16, i16* %10, i64 24
  %59 = bitcast i16* %58 to <8 x i16>*
  %60 = load <8 x i16>, <8 x i16>* %59, align 16
  %61 = sub <8 x i16> %57, %60
  %62 = sub <8 x i16> zeroinitializer, %61
  %63 = icmp slt <8 x i16> %61, zeroinitializer
  %64 = select <8 x i1> %63, <8 x i16> %62, <8 x i16> %61
  %65 = lshr <8 x i16> %64, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %66 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %65, <8 x i16> zeroinitializer) #5
  %67 = lshr <8 x i16> %66, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %68 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %54, <8 x i16> %67) #5
  %69 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %68, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %70 = icmp slt <16 x i8> %69, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %71 = select <16 x i1> %70, <16 x i8> %69, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %72 = bitcast i8* %43 to <16 x i8>*
  store <16 x i8> %71, <16 x i8>* %72, align 16
  %73 = getelementptr inbounds i16, i16* %9, i64 32
  %74 = getelementptr inbounds i16, i16* %10, i64 32
  %75 = getelementptr inbounds i8, i8* %8, i64 %3
  %76 = bitcast i16* %73 to <8 x i16>*
  %77 = load <8 x i16>, <8 x i16>* %76, align 16
  %78 = bitcast i16* %74 to <8 x i16>*
  %79 = load <8 x i16>, <8 x i16>* %78, align 16
  %80 = sub <8 x i16> %77, %79
  %81 = sub <8 x i16> zeroinitializer, %80
  %82 = icmp slt <8 x i16> %80, zeroinitializer
  %83 = select <8 x i1> %82, <8 x i16> %81, <8 x i16> %80
  %84 = lshr <8 x i16> %83, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %85 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %84, <8 x i16> zeroinitializer) #5
  %86 = lshr <8 x i16> %85, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %87 = getelementptr inbounds i16, i16* %9, i64 40
  %88 = bitcast i16* %87 to <8 x i16>*
  %89 = load <8 x i16>, <8 x i16>* %88, align 16
  %90 = getelementptr inbounds i16, i16* %10, i64 40
  %91 = bitcast i16* %90 to <8 x i16>*
  %92 = load <8 x i16>, <8 x i16>* %91, align 16
  %93 = sub <8 x i16> %89, %92
  %94 = sub <8 x i16> zeroinitializer, %93
  %95 = icmp slt <8 x i16> %93, zeroinitializer
  %96 = select <8 x i1> %95, <8 x i16> %94, <8 x i16> %93
  %97 = lshr <8 x i16> %96, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %98 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %97, <8 x i16> zeroinitializer) #5
  %99 = lshr <8 x i16> %98, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %100 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %86, <8 x i16> %99) #5
  %101 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %100, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %102 = icmp slt <16 x i8> %101, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %103 = select <16 x i1> %102, <16 x i8> %101, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %104 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %103, <16 x i8>* %104, align 16
  %105 = getelementptr inbounds i16, i16* %9, i64 48
  %106 = getelementptr inbounds i16, i16* %10, i64 48
  %107 = getelementptr inbounds i8, i8* %75, i64 16
  %108 = bitcast i16* %105 to <8 x i16>*
  %109 = load <8 x i16>, <8 x i16>* %108, align 16
  %110 = bitcast i16* %106 to <8 x i16>*
  %111 = load <8 x i16>, <8 x i16>* %110, align 16
  %112 = sub <8 x i16> %109, %111
  %113 = sub <8 x i16> zeroinitializer, %112
  %114 = icmp slt <8 x i16> %112, zeroinitializer
  %115 = select <8 x i1> %114, <8 x i16> %113, <8 x i16> %112
  %116 = lshr <8 x i16> %115, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %117 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %116, <8 x i16> zeroinitializer) #5
  %118 = lshr <8 x i16> %117, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %119 = getelementptr inbounds i16, i16* %9, i64 56
  %120 = bitcast i16* %119 to <8 x i16>*
  %121 = load <8 x i16>, <8 x i16>* %120, align 16
  %122 = getelementptr inbounds i16, i16* %10, i64 56
  %123 = bitcast i16* %122 to <8 x i16>*
  %124 = load <8 x i16>, <8 x i16>* %123, align 16
  %125 = sub <8 x i16> %121, %124
  %126 = sub <8 x i16> zeroinitializer, %125
  %127 = icmp slt <8 x i16> %125, zeroinitializer
  %128 = select <8 x i1> %127, <8 x i16> %126, <8 x i16> %125
  %129 = lshr <8 x i16> %128, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %130 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %129, <8 x i16> zeroinitializer) #5
  %131 = lshr <8 x i16> %130, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %132 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %118, <8 x i16> %131) #5
  %133 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %132, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %134 = icmp slt <16 x i8> %133, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %135 = select <16 x i1> %134, <16 x i8> %133, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %136 = bitcast i8* %107 to <16 x i8>*
  store <16 x i8> %135, <16 x i8>* %136, align 16
  %137 = getelementptr inbounds i16, i16* %9, i64 64
  %138 = getelementptr inbounds i16, i16* %10, i64 64
  %139 = getelementptr inbounds i8, i8* %75, i64 %3
  %140 = bitcast i16* %137 to <8 x i16>*
  %141 = load <8 x i16>, <8 x i16>* %140, align 16
  %142 = bitcast i16* %138 to <8 x i16>*
  %143 = load <8 x i16>, <8 x i16>* %142, align 16
  %144 = sub <8 x i16> %141, %143
  %145 = sub <8 x i16> zeroinitializer, %144
  %146 = icmp slt <8 x i16> %144, zeroinitializer
  %147 = select <8 x i1> %146, <8 x i16> %145, <8 x i16> %144
  %148 = lshr <8 x i16> %147, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %149 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %148, <8 x i16> zeroinitializer) #5
  %150 = lshr <8 x i16> %149, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %151 = getelementptr inbounds i16, i16* %9, i64 72
  %152 = bitcast i16* %151 to <8 x i16>*
  %153 = load <8 x i16>, <8 x i16>* %152, align 16
  %154 = getelementptr inbounds i16, i16* %10, i64 72
  %155 = bitcast i16* %154 to <8 x i16>*
  %156 = load <8 x i16>, <8 x i16>* %155, align 16
  %157 = sub <8 x i16> %153, %156
  %158 = sub <8 x i16> zeroinitializer, %157
  %159 = icmp slt <8 x i16> %157, zeroinitializer
  %160 = select <8 x i1> %159, <8 x i16> %158, <8 x i16> %157
  %161 = lshr <8 x i16> %160, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %162 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %161, <8 x i16> zeroinitializer) #5
  %163 = lshr <8 x i16> %162, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %164 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %150, <8 x i16> %163) #5
  %165 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %164, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %166 = icmp slt <16 x i8> %165, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %167 = select <16 x i1> %166, <16 x i8> %165, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %168 = bitcast i8* %139 to <16 x i8>*
  store <16 x i8> %167, <16 x i8>* %168, align 16
  %169 = getelementptr inbounds i16, i16* %9, i64 80
  %170 = getelementptr inbounds i16, i16* %10, i64 80
  %171 = getelementptr inbounds i8, i8* %139, i64 16
  %172 = bitcast i16* %169 to <8 x i16>*
  %173 = load <8 x i16>, <8 x i16>* %172, align 16
  %174 = bitcast i16* %170 to <8 x i16>*
  %175 = load <8 x i16>, <8 x i16>* %174, align 16
  %176 = sub <8 x i16> %173, %175
  %177 = sub <8 x i16> zeroinitializer, %176
  %178 = icmp slt <8 x i16> %176, zeroinitializer
  %179 = select <8 x i1> %178, <8 x i16> %177, <8 x i16> %176
  %180 = lshr <8 x i16> %179, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %181 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %180, <8 x i16> zeroinitializer) #5
  %182 = lshr <8 x i16> %181, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %183 = getelementptr inbounds i16, i16* %9, i64 88
  %184 = bitcast i16* %183 to <8 x i16>*
  %185 = load <8 x i16>, <8 x i16>* %184, align 16
  %186 = getelementptr inbounds i16, i16* %10, i64 88
  %187 = bitcast i16* %186 to <8 x i16>*
  %188 = load <8 x i16>, <8 x i16>* %187, align 16
  %189 = sub <8 x i16> %185, %188
  %190 = sub <8 x i16> zeroinitializer, %189
  %191 = icmp slt <8 x i16> %189, zeroinitializer
  %192 = select <8 x i1> %191, <8 x i16> %190, <8 x i16> %189
  %193 = lshr <8 x i16> %192, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %194 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %193, <8 x i16> zeroinitializer) #5
  %195 = lshr <8 x i16> %194, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %196 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %182, <8 x i16> %195) #5
  %197 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %196, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %198 = icmp slt <16 x i8> %197, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %199 = select <16 x i1> %198, <16 x i8> %197, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %200 = bitcast i8* %171 to <16 x i8>*
  store <16 x i8> %199, <16 x i8>* %200, align 16
  %201 = getelementptr inbounds i16, i16* %9, i64 96
  %202 = getelementptr inbounds i16, i16* %10, i64 96
  %203 = getelementptr inbounds i8, i8* %139, i64 %3
  %204 = add nsw i32 %11, -1
  %205 = icmp eq i32 %204, 0
  br i1 %205, label %206, label %7

206:                                              ; preds = %7
  %207 = bitcast i16* %201 to <8 x i16>*
  %208 = load <8 x i16>, <8 x i16>* %207, align 16
  %209 = bitcast i16* %202 to <8 x i16>*
  %210 = load <8 x i16>, <8 x i16>* %209, align 16
  %211 = sub <8 x i16> %208, %210
  %212 = sub <8 x i16> zeroinitializer, %211
  %213 = icmp slt <8 x i16> %211, zeroinitializer
  %214 = select <8 x i1> %213, <8 x i16> %212, <8 x i16> %211
  %215 = lshr <8 x i16> %214, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %216 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %215, <8 x i16> zeroinitializer) #5
  %217 = lshr <8 x i16> %216, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %218 = getelementptr inbounds i16, i16* %9, i64 104
  %219 = bitcast i16* %218 to <8 x i16>*
  %220 = load <8 x i16>, <8 x i16>* %219, align 16
  %221 = getelementptr inbounds i16, i16* %10, i64 104
  %222 = bitcast i16* %221 to <8 x i16>*
  %223 = load <8 x i16>, <8 x i16>* %222, align 16
  %224 = sub <8 x i16> %220, %223
  %225 = sub <8 x i16> zeroinitializer, %224
  %226 = icmp slt <8 x i16> %224, zeroinitializer
  %227 = select <8 x i1> %226, <8 x i16> %225, <8 x i16> %224
  %228 = lshr <8 x i16> %227, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %229 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %228, <8 x i16> zeroinitializer) #5
  %230 = lshr <8 x i16> %229, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %231 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %217, <8 x i16> %230) #5
  %232 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %231, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %233 = icmp slt <16 x i8> %232, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %234 = select <16 x i1> %233, <16 x i8> %232, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %235 = bitcast i8* %203 to <16 x i8>*
  store <16 x i8> %234, <16 x i8>* %235, align 16
  %236 = getelementptr inbounds i16, i16* %9, i64 112
  %237 = getelementptr inbounds i16, i16* %10, i64 112
  %238 = getelementptr inbounds i8, i8* %203, i64 16
  %239 = bitcast i16* %236 to <8 x i16>*
  %240 = load <8 x i16>, <8 x i16>* %239, align 16
  %241 = bitcast i16* %237 to <8 x i16>*
  %242 = load <8 x i16>, <8 x i16>* %241, align 16
  %243 = sub <8 x i16> %240, %242
  %244 = sub <8 x i16> zeroinitializer, %243
  %245 = icmp slt <8 x i16> %243, zeroinitializer
  %246 = select <8 x i1> %245, <8 x i16> %244, <8 x i16> %243
  %247 = lshr <8 x i16> %246, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %248 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %247, <8 x i16> zeroinitializer) #5
  %249 = lshr <8 x i16> %248, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %250 = getelementptr inbounds i16, i16* %9, i64 120
  %251 = bitcast i16* %250 to <8 x i16>*
  %252 = load <8 x i16>, <8 x i16>* %251, align 16
  %253 = getelementptr inbounds i16, i16* %10, i64 120
  %254 = bitcast i16* %253 to <8 x i16>*
  %255 = load <8 x i16>, <8 x i16>* %254, align 16
  %256 = sub <8 x i16> %252, %255
  %257 = sub <8 x i16> zeroinitializer, %256
  %258 = icmp slt <8 x i16> %256, zeroinitializer
  %259 = select <8 x i1> %258, <8 x i16> %257, <8 x i16> %256
  %260 = lshr <8 x i16> %259, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %261 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %260, <8 x i16> zeroinitializer) #5
  %262 = lshr <8 x i16> %261, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %263 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %249, <8 x i16> %262) #5
  %264 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %263, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %265 = icmp slt <16 x i8> %264, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %266 = select <16 x i1> %265, <16 x i8> %264, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %267 = bitcast i8* %238 to <16 x i8>*
  store <16 x i8> %266, <16 x i8>* %267, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask32x16_SSE4ILb1EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %209, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %207, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %208, %7 ]
  %11 = phi i32 [ 5, %4 ], [ %210, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = sub <8 x i16> %13, %15
  %17 = sub <8 x i16> zeroinitializer, %16
  %18 = icmp slt <8 x i16> %16, zeroinitializer
  %19 = select <8 x i1> %18, <8 x i16> %17, <8 x i16> %16
  %20 = lshr <8 x i16> %19, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %21 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %20, <8 x i16> zeroinitializer) #5
  %22 = lshr <8 x i16> %21, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %23 = getelementptr inbounds i16, i16* %9, i64 8
  %24 = bitcast i16* %23 to <8 x i16>*
  %25 = load <8 x i16>, <8 x i16>* %24, align 16
  %26 = getelementptr inbounds i16, i16* %10, i64 8
  %27 = bitcast i16* %26 to <8 x i16>*
  %28 = load <8 x i16>, <8 x i16>* %27, align 16
  %29 = sub <8 x i16> %25, %28
  %30 = sub <8 x i16> zeroinitializer, %29
  %31 = icmp slt <8 x i16> %29, zeroinitializer
  %32 = select <8 x i1> %31, <8 x i16> %30, <8 x i16> %29
  %33 = lshr <8 x i16> %32, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %34 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %33, <8 x i16> zeroinitializer) #5
  %35 = lshr <8 x i16> %34, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %36 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %22, <8 x i16> %35) #5
  %37 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %36, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %38 = icmp slt <16 x i8> %37, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %39 = select <16 x i1> %38, <16 x i8> %37, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %40 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %39
  %41 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %40, <16 x i8>* %41, align 16
  %42 = getelementptr inbounds i16, i16* %9, i64 16
  %43 = getelementptr inbounds i16, i16* %10, i64 16
  %44 = getelementptr inbounds i8, i8* %8, i64 16
  %45 = bitcast i16* %42 to <8 x i16>*
  %46 = load <8 x i16>, <8 x i16>* %45, align 16
  %47 = bitcast i16* %43 to <8 x i16>*
  %48 = load <8 x i16>, <8 x i16>* %47, align 16
  %49 = sub <8 x i16> %46, %48
  %50 = sub <8 x i16> zeroinitializer, %49
  %51 = icmp slt <8 x i16> %49, zeroinitializer
  %52 = select <8 x i1> %51, <8 x i16> %50, <8 x i16> %49
  %53 = lshr <8 x i16> %52, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %54 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %53, <8 x i16> zeroinitializer) #5
  %55 = lshr <8 x i16> %54, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %56 = getelementptr inbounds i16, i16* %9, i64 24
  %57 = bitcast i16* %56 to <8 x i16>*
  %58 = load <8 x i16>, <8 x i16>* %57, align 16
  %59 = getelementptr inbounds i16, i16* %10, i64 24
  %60 = bitcast i16* %59 to <8 x i16>*
  %61 = load <8 x i16>, <8 x i16>* %60, align 16
  %62 = sub <8 x i16> %58, %61
  %63 = sub <8 x i16> zeroinitializer, %62
  %64 = icmp slt <8 x i16> %62, zeroinitializer
  %65 = select <8 x i1> %64, <8 x i16> %63, <8 x i16> %62
  %66 = lshr <8 x i16> %65, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %67 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %66, <8 x i16> zeroinitializer) #5
  %68 = lshr <8 x i16> %67, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %69 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %55, <8 x i16> %68) #5
  %70 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %69, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %71 = icmp slt <16 x i8> %70, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %72 = select <16 x i1> %71, <16 x i8> %70, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %73 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %72
  %74 = bitcast i8* %44 to <16 x i8>*
  store <16 x i8> %73, <16 x i8>* %74, align 16
  %75 = getelementptr inbounds i16, i16* %9, i64 32
  %76 = getelementptr inbounds i16, i16* %10, i64 32
  %77 = getelementptr inbounds i8, i8* %8, i64 %3
  %78 = bitcast i16* %75 to <8 x i16>*
  %79 = load <8 x i16>, <8 x i16>* %78, align 16
  %80 = bitcast i16* %76 to <8 x i16>*
  %81 = load <8 x i16>, <8 x i16>* %80, align 16
  %82 = sub <8 x i16> %79, %81
  %83 = sub <8 x i16> zeroinitializer, %82
  %84 = icmp slt <8 x i16> %82, zeroinitializer
  %85 = select <8 x i1> %84, <8 x i16> %83, <8 x i16> %82
  %86 = lshr <8 x i16> %85, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %87 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %86, <8 x i16> zeroinitializer) #5
  %88 = lshr <8 x i16> %87, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %89 = getelementptr inbounds i16, i16* %9, i64 40
  %90 = bitcast i16* %89 to <8 x i16>*
  %91 = load <8 x i16>, <8 x i16>* %90, align 16
  %92 = getelementptr inbounds i16, i16* %10, i64 40
  %93 = bitcast i16* %92 to <8 x i16>*
  %94 = load <8 x i16>, <8 x i16>* %93, align 16
  %95 = sub <8 x i16> %91, %94
  %96 = sub <8 x i16> zeroinitializer, %95
  %97 = icmp slt <8 x i16> %95, zeroinitializer
  %98 = select <8 x i1> %97, <8 x i16> %96, <8 x i16> %95
  %99 = lshr <8 x i16> %98, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %100 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %99, <8 x i16> zeroinitializer) #5
  %101 = lshr <8 x i16> %100, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %102 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %88, <8 x i16> %101) #5
  %103 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %102, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %104 = icmp slt <16 x i8> %103, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %105 = select <16 x i1> %104, <16 x i8> %103, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %106 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %105
  %107 = bitcast i8* %77 to <16 x i8>*
  store <16 x i8> %106, <16 x i8>* %107, align 16
  %108 = getelementptr inbounds i16, i16* %9, i64 48
  %109 = getelementptr inbounds i16, i16* %10, i64 48
  %110 = getelementptr inbounds i8, i8* %77, i64 16
  %111 = bitcast i16* %108 to <8 x i16>*
  %112 = load <8 x i16>, <8 x i16>* %111, align 16
  %113 = bitcast i16* %109 to <8 x i16>*
  %114 = load <8 x i16>, <8 x i16>* %113, align 16
  %115 = sub <8 x i16> %112, %114
  %116 = sub <8 x i16> zeroinitializer, %115
  %117 = icmp slt <8 x i16> %115, zeroinitializer
  %118 = select <8 x i1> %117, <8 x i16> %116, <8 x i16> %115
  %119 = lshr <8 x i16> %118, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %120 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %119, <8 x i16> zeroinitializer) #5
  %121 = lshr <8 x i16> %120, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %122 = getelementptr inbounds i16, i16* %9, i64 56
  %123 = bitcast i16* %122 to <8 x i16>*
  %124 = load <8 x i16>, <8 x i16>* %123, align 16
  %125 = getelementptr inbounds i16, i16* %10, i64 56
  %126 = bitcast i16* %125 to <8 x i16>*
  %127 = load <8 x i16>, <8 x i16>* %126, align 16
  %128 = sub <8 x i16> %124, %127
  %129 = sub <8 x i16> zeroinitializer, %128
  %130 = icmp slt <8 x i16> %128, zeroinitializer
  %131 = select <8 x i1> %130, <8 x i16> %129, <8 x i16> %128
  %132 = lshr <8 x i16> %131, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %133 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %132, <8 x i16> zeroinitializer) #5
  %134 = lshr <8 x i16> %133, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %135 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %121, <8 x i16> %134) #5
  %136 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %135, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %137 = icmp slt <16 x i8> %136, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %138 = select <16 x i1> %137, <16 x i8> %136, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %139 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %138
  %140 = bitcast i8* %110 to <16 x i8>*
  store <16 x i8> %139, <16 x i8>* %140, align 16
  %141 = getelementptr inbounds i16, i16* %9, i64 64
  %142 = getelementptr inbounds i16, i16* %10, i64 64
  %143 = getelementptr inbounds i8, i8* %77, i64 %3
  %144 = bitcast i16* %141 to <8 x i16>*
  %145 = load <8 x i16>, <8 x i16>* %144, align 16
  %146 = bitcast i16* %142 to <8 x i16>*
  %147 = load <8 x i16>, <8 x i16>* %146, align 16
  %148 = sub <8 x i16> %145, %147
  %149 = sub <8 x i16> zeroinitializer, %148
  %150 = icmp slt <8 x i16> %148, zeroinitializer
  %151 = select <8 x i1> %150, <8 x i16> %149, <8 x i16> %148
  %152 = lshr <8 x i16> %151, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %153 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %152, <8 x i16> zeroinitializer) #5
  %154 = lshr <8 x i16> %153, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %155 = getelementptr inbounds i16, i16* %9, i64 72
  %156 = bitcast i16* %155 to <8 x i16>*
  %157 = load <8 x i16>, <8 x i16>* %156, align 16
  %158 = getelementptr inbounds i16, i16* %10, i64 72
  %159 = bitcast i16* %158 to <8 x i16>*
  %160 = load <8 x i16>, <8 x i16>* %159, align 16
  %161 = sub <8 x i16> %157, %160
  %162 = sub <8 x i16> zeroinitializer, %161
  %163 = icmp slt <8 x i16> %161, zeroinitializer
  %164 = select <8 x i1> %163, <8 x i16> %162, <8 x i16> %161
  %165 = lshr <8 x i16> %164, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %166 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %165, <8 x i16> zeroinitializer) #5
  %167 = lshr <8 x i16> %166, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %168 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %154, <8 x i16> %167) #5
  %169 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %168, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %170 = icmp slt <16 x i8> %169, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %171 = select <16 x i1> %170, <16 x i8> %169, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %172 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %171
  %173 = bitcast i8* %143 to <16 x i8>*
  store <16 x i8> %172, <16 x i8>* %173, align 16
  %174 = getelementptr inbounds i16, i16* %9, i64 80
  %175 = getelementptr inbounds i16, i16* %10, i64 80
  %176 = getelementptr inbounds i8, i8* %143, i64 16
  %177 = bitcast i16* %174 to <8 x i16>*
  %178 = load <8 x i16>, <8 x i16>* %177, align 16
  %179 = bitcast i16* %175 to <8 x i16>*
  %180 = load <8 x i16>, <8 x i16>* %179, align 16
  %181 = sub <8 x i16> %178, %180
  %182 = sub <8 x i16> zeroinitializer, %181
  %183 = icmp slt <8 x i16> %181, zeroinitializer
  %184 = select <8 x i1> %183, <8 x i16> %182, <8 x i16> %181
  %185 = lshr <8 x i16> %184, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %186 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %185, <8 x i16> zeroinitializer) #5
  %187 = lshr <8 x i16> %186, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %188 = getelementptr inbounds i16, i16* %9, i64 88
  %189 = bitcast i16* %188 to <8 x i16>*
  %190 = load <8 x i16>, <8 x i16>* %189, align 16
  %191 = getelementptr inbounds i16, i16* %10, i64 88
  %192 = bitcast i16* %191 to <8 x i16>*
  %193 = load <8 x i16>, <8 x i16>* %192, align 16
  %194 = sub <8 x i16> %190, %193
  %195 = sub <8 x i16> zeroinitializer, %194
  %196 = icmp slt <8 x i16> %194, zeroinitializer
  %197 = select <8 x i1> %196, <8 x i16> %195, <8 x i16> %194
  %198 = lshr <8 x i16> %197, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %199 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %198, <8 x i16> zeroinitializer) #5
  %200 = lshr <8 x i16> %199, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %201 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %187, <8 x i16> %200) #5
  %202 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %201, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %203 = icmp slt <16 x i8> %202, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %204 = select <16 x i1> %203, <16 x i8> %202, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %205 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %204
  %206 = bitcast i8* %176 to <16 x i8>*
  store <16 x i8> %205, <16 x i8>* %206, align 16
  %207 = getelementptr inbounds i16, i16* %9, i64 96
  %208 = getelementptr inbounds i16, i16* %10, i64 96
  %209 = getelementptr inbounds i8, i8* %143, i64 %3
  %210 = add nsw i32 %11, -1
  %211 = icmp eq i32 %210, 0
  br i1 %211, label %212, label %7

212:                                              ; preds = %7
  %213 = bitcast i16* %207 to <8 x i16>*
  %214 = load <8 x i16>, <8 x i16>* %213, align 16
  %215 = bitcast i16* %208 to <8 x i16>*
  %216 = load <8 x i16>, <8 x i16>* %215, align 16
  %217 = sub <8 x i16> %214, %216
  %218 = sub <8 x i16> zeroinitializer, %217
  %219 = icmp slt <8 x i16> %217, zeroinitializer
  %220 = select <8 x i1> %219, <8 x i16> %218, <8 x i16> %217
  %221 = lshr <8 x i16> %220, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %222 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %221, <8 x i16> zeroinitializer) #5
  %223 = lshr <8 x i16> %222, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %224 = getelementptr inbounds i16, i16* %9, i64 104
  %225 = bitcast i16* %224 to <8 x i16>*
  %226 = load <8 x i16>, <8 x i16>* %225, align 16
  %227 = getelementptr inbounds i16, i16* %10, i64 104
  %228 = bitcast i16* %227 to <8 x i16>*
  %229 = load <8 x i16>, <8 x i16>* %228, align 16
  %230 = sub <8 x i16> %226, %229
  %231 = sub <8 x i16> zeroinitializer, %230
  %232 = icmp slt <8 x i16> %230, zeroinitializer
  %233 = select <8 x i1> %232, <8 x i16> %231, <8 x i16> %230
  %234 = lshr <8 x i16> %233, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %235 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %234, <8 x i16> zeroinitializer) #5
  %236 = lshr <8 x i16> %235, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %237 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %223, <8 x i16> %236) #5
  %238 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %237, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %239 = icmp slt <16 x i8> %238, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %240 = select <16 x i1> %239, <16 x i8> %238, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %241 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %240
  %242 = bitcast i8* %209 to <16 x i8>*
  store <16 x i8> %241, <16 x i8>* %242, align 16
  %243 = getelementptr inbounds i16, i16* %9, i64 112
  %244 = getelementptr inbounds i16, i16* %10, i64 112
  %245 = getelementptr inbounds i8, i8* %209, i64 16
  %246 = bitcast i16* %243 to <8 x i16>*
  %247 = load <8 x i16>, <8 x i16>* %246, align 16
  %248 = bitcast i16* %244 to <8 x i16>*
  %249 = load <8 x i16>, <8 x i16>* %248, align 16
  %250 = sub <8 x i16> %247, %249
  %251 = sub <8 x i16> zeroinitializer, %250
  %252 = icmp slt <8 x i16> %250, zeroinitializer
  %253 = select <8 x i1> %252, <8 x i16> %251, <8 x i16> %250
  %254 = lshr <8 x i16> %253, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %255 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %254, <8 x i16> zeroinitializer) #5
  %256 = lshr <8 x i16> %255, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %257 = getelementptr inbounds i16, i16* %9, i64 120
  %258 = bitcast i16* %257 to <8 x i16>*
  %259 = load <8 x i16>, <8 x i16>* %258, align 16
  %260 = getelementptr inbounds i16, i16* %10, i64 120
  %261 = bitcast i16* %260 to <8 x i16>*
  %262 = load <8 x i16>, <8 x i16>* %261, align 16
  %263 = sub <8 x i16> %259, %262
  %264 = sub <8 x i16> zeroinitializer, %263
  %265 = icmp slt <8 x i16> %263, zeroinitializer
  %266 = select <8 x i1> %265, <8 x i16> %264, <8 x i16> %263
  %267 = lshr <8 x i16> %266, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %268 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %267, <8 x i16> zeroinitializer) #5
  %269 = lshr <8 x i16> %268, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %270 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %256, <8 x i16> %269) #5
  %271 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %270, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %272 = icmp slt <16 x i8> %271, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %273 = select <16 x i1> %272, <16 x i8> %271, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %274 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %273
  %275 = bitcast i8* %245 to <16 x i8>*
  store <16 x i8> %274, <16 x i8>* %275, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask32x32_SSE4ILb0EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %331, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %329, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %330, %7 ]
  %11 = phi i32 [ 6, %4 ], [ %332, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = sub <8 x i16> %13, %15
  %17 = sub <8 x i16> zeroinitializer, %16
  %18 = icmp slt <8 x i16> %16, zeroinitializer
  %19 = select <8 x i1> %18, <8 x i16> %17, <8 x i16> %16
  %20 = lshr <8 x i16> %19, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %21 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %20, <8 x i16> zeroinitializer) #5
  %22 = lshr <8 x i16> %21, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %23 = getelementptr inbounds i16, i16* %9, i64 8
  %24 = bitcast i16* %23 to <8 x i16>*
  %25 = load <8 x i16>, <8 x i16>* %24, align 16
  %26 = getelementptr inbounds i16, i16* %10, i64 8
  %27 = bitcast i16* %26 to <8 x i16>*
  %28 = load <8 x i16>, <8 x i16>* %27, align 16
  %29 = sub <8 x i16> %25, %28
  %30 = sub <8 x i16> zeroinitializer, %29
  %31 = icmp slt <8 x i16> %29, zeroinitializer
  %32 = select <8 x i1> %31, <8 x i16> %30, <8 x i16> %29
  %33 = lshr <8 x i16> %32, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %34 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %33, <8 x i16> zeroinitializer) #5
  %35 = lshr <8 x i16> %34, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %36 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %22, <8 x i16> %35) #5
  %37 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %36, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %38 = icmp slt <16 x i8> %37, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %39 = select <16 x i1> %38, <16 x i8> %37, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %40 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %40, align 16
  %41 = getelementptr inbounds i16, i16* %9, i64 16
  %42 = getelementptr inbounds i16, i16* %10, i64 16
  %43 = getelementptr inbounds i8, i8* %8, i64 16
  %44 = bitcast i16* %41 to <8 x i16>*
  %45 = load <8 x i16>, <8 x i16>* %44, align 16
  %46 = bitcast i16* %42 to <8 x i16>*
  %47 = load <8 x i16>, <8 x i16>* %46, align 16
  %48 = sub <8 x i16> %45, %47
  %49 = sub <8 x i16> zeroinitializer, %48
  %50 = icmp slt <8 x i16> %48, zeroinitializer
  %51 = select <8 x i1> %50, <8 x i16> %49, <8 x i16> %48
  %52 = lshr <8 x i16> %51, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %53 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %52, <8 x i16> zeroinitializer) #5
  %54 = lshr <8 x i16> %53, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %55 = getelementptr inbounds i16, i16* %9, i64 24
  %56 = bitcast i16* %55 to <8 x i16>*
  %57 = load <8 x i16>, <8 x i16>* %56, align 16
  %58 = getelementptr inbounds i16, i16* %10, i64 24
  %59 = bitcast i16* %58 to <8 x i16>*
  %60 = load <8 x i16>, <8 x i16>* %59, align 16
  %61 = sub <8 x i16> %57, %60
  %62 = sub <8 x i16> zeroinitializer, %61
  %63 = icmp slt <8 x i16> %61, zeroinitializer
  %64 = select <8 x i1> %63, <8 x i16> %62, <8 x i16> %61
  %65 = lshr <8 x i16> %64, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %66 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %65, <8 x i16> zeroinitializer) #5
  %67 = lshr <8 x i16> %66, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %68 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %54, <8 x i16> %67) #5
  %69 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %68, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %70 = icmp slt <16 x i8> %69, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %71 = select <16 x i1> %70, <16 x i8> %69, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %72 = bitcast i8* %43 to <16 x i8>*
  store <16 x i8> %71, <16 x i8>* %72, align 16
  %73 = getelementptr inbounds i16, i16* %9, i64 32
  %74 = getelementptr inbounds i16, i16* %10, i64 32
  %75 = getelementptr inbounds i8, i8* %8, i64 %3
  %76 = bitcast i16* %73 to <8 x i16>*
  %77 = load <8 x i16>, <8 x i16>* %76, align 16
  %78 = bitcast i16* %74 to <8 x i16>*
  %79 = load <8 x i16>, <8 x i16>* %78, align 16
  %80 = sub <8 x i16> %77, %79
  %81 = sub <8 x i16> zeroinitializer, %80
  %82 = icmp slt <8 x i16> %80, zeroinitializer
  %83 = select <8 x i1> %82, <8 x i16> %81, <8 x i16> %80
  %84 = lshr <8 x i16> %83, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %85 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %84, <8 x i16> zeroinitializer) #5
  %86 = lshr <8 x i16> %85, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %87 = getelementptr inbounds i16, i16* %9, i64 40
  %88 = bitcast i16* %87 to <8 x i16>*
  %89 = load <8 x i16>, <8 x i16>* %88, align 16
  %90 = getelementptr inbounds i16, i16* %10, i64 40
  %91 = bitcast i16* %90 to <8 x i16>*
  %92 = load <8 x i16>, <8 x i16>* %91, align 16
  %93 = sub <8 x i16> %89, %92
  %94 = sub <8 x i16> zeroinitializer, %93
  %95 = icmp slt <8 x i16> %93, zeroinitializer
  %96 = select <8 x i1> %95, <8 x i16> %94, <8 x i16> %93
  %97 = lshr <8 x i16> %96, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %98 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %97, <8 x i16> zeroinitializer) #5
  %99 = lshr <8 x i16> %98, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %100 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %86, <8 x i16> %99) #5
  %101 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %100, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %102 = icmp slt <16 x i8> %101, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %103 = select <16 x i1> %102, <16 x i8> %101, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %104 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %103, <16 x i8>* %104, align 16
  %105 = getelementptr inbounds i16, i16* %9, i64 48
  %106 = getelementptr inbounds i16, i16* %10, i64 48
  %107 = getelementptr inbounds i8, i8* %75, i64 16
  %108 = bitcast i16* %105 to <8 x i16>*
  %109 = load <8 x i16>, <8 x i16>* %108, align 16
  %110 = bitcast i16* %106 to <8 x i16>*
  %111 = load <8 x i16>, <8 x i16>* %110, align 16
  %112 = sub <8 x i16> %109, %111
  %113 = sub <8 x i16> zeroinitializer, %112
  %114 = icmp slt <8 x i16> %112, zeroinitializer
  %115 = select <8 x i1> %114, <8 x i16> %113, <8 x i16> %112
  %116 = lshr <8 x i16> %115, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %117 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %116, <8 x i16> zeroinitializer) #5
  %118 = lshr <8 x i16> %117, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %119 = getelementptr inbounds i16, i16* %9, i64 56
  %120 = bitcast i16* %119 to <8 x i16>*
  %121 = load <8 x i16>, <8 x i16>* %120, align 16
  %122 = getelementptr inbounds i16, i16* %10, i64 56
  %123 = bitcast i16* %122 to <8 x i16>*
  %124 = load <8 x i16>, <8 x i16>* %123, align 16
  %125 = sub <8 x i16> %121, %124
  %126 = sub <8 x i16> zeroinitializer, %125
  %127 = icmp slt <8 x i16> %125, zeroinitializer
  %128 = select <8 x i1> %127, <8 x i16> %126, <8 x i16> %125
  %129 = lshr <8 x i16> %128, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %130 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %129, <8 x i16> zeroinitializer) #5
  %131 = lshr <8 x i16> %130, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %132 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %118, <8 x i16> %131) #5
  %133 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %132, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %134 = icmp slt <16 x i8> %133, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %135 = select <16 x i1> %134, <16 x i8> %133, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %136 = bitcast i8* %107 to <16 x i8>*
  store <16 x i8> %135, <16 x i8>* %136, align 16
  %137 = getelementptr inbounds i16, i16* %9, i64 64
  %138 = getelementptr inbounds i16, i16* %10, i64 64
  %139 = getelementptr inbounds i8, i8* %75, i64 %3
  %140 = bitcast i16* %137 to <8 x i16>*
  %141 = load <8 x i16>, <8 x i16>* %140, align 16
  %142 = bitcast i16* %138 to <8 x i16>*
  %143 = load <8 x i16>, <8 x i16>* %142, align 16
  %144 = sub <8 x i16> %141, %143
  %145 = sub <8 x i16> zeroinitializer, %144
  %146 = icmp slt <8 x i16> %144, zeroinitializer
  %147 = select <8 x i1> %146, <8 x i16> %145, <8 x i16> %144
  %148 = lshr <8 x i16> %147, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %149 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %148, <8 x i16> zeroinitializer) #5
  %150 = lshr <8 x i16> %149, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %151 = getelementptr inbounds i16, i16* %9, i64 72
  %152 = bitcast i16* %151 to <8 x i16>*
  %153 = load <8 x i16>, <8 x i16>* %152, align 16
  %154 = getelementptr inbounds i16, i16* %10, i64 72
  %155 = bitcast i16* %154 to <8 x i16>*
  %156 = load <8 x i16>, <8 x i16>* %155, align 16
  %157 = sub <8 x i16> %153, %156
  %158 = sub <8 x i16> zeroinitializer, %157
  %159 = icmp slt <8 x i16> %157, zeroinitializer
  %160 = select <8 x i1> %159, <8 x i16> %158, <8 x i16> %157
  %161 = lshr <8 x i16> %160, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %162 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %161, <8 x i16> zeroinitializer) #5
  %163 = lshr <8 x i16> %162, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %164 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %150, <8 x i16> %163) #5
  %165 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %164, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %166 = icmp slt <16 x i8> %165, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %167 = select <16 x i1> %166, <16 x i8> %165, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %168 = bitcast i8* %139 to <16 x i8>*
  store <16 x i8> %167, <16 x i8>* %168, align 16
  %169 = getelementptr inbounds i16, i16* %9, i64 80
  %170 = getelementptr inbounds i16, i16* %10, i64 80
  %171 = getelementptr inbounds i8, i8* %139, i64 16
  %172 = bitcast i16* %169 to <8 x i16>*
  %173 = load <8 x i16>, <8 x i16>* %172, align 16
  %174 = bitcast i16* %170 to <8 x i16>*
  %175 = load <8 x i16>, <8 x i16>* %174, align 16
  %176 = sub <8 x i16> %173, %175
  %177 = sub <8 x i16> zeroinitializer, %176
  %178 = icmp slt <8 x i16> %176, zeroinitializer
  %179 = select <8 x i1> %178, <8 x i16> %177, <8 x i16> %176
  %180 = lshr <8 x i16> %179, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %181 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %180, <8 x i16> zeroinitializer) #5
  %182 = lshr <8 x i16> %181, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %183 = getelementptr inbounds i16, i16* %9, i64 88
  %184 = bitcast i16* %183 to <8 x i16>*
  %185 = load <8 x i16>, <8 x i16>* %184, align 16
  %186 = getelementptr inbounds i16, i16* %10, i64 88
  %187 = bitcast i16* %186 to <8 x i16>*
  %188 = load <8 x i16>, <8 x i16>* %187, align 16
  %189 = sub <8 x i16> %185, %188
  %190 = sub <8 x i16> zeroinitializer, %189
  %191 = icmp slt <8 x i16> %189, zeroinitializer
  %192 = select <8 x i1> %191, <8 x i16> %190, <8 x i16> %189
  %193 = lshr <8 x i16> %192, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %194 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %193, <8 x i16> zeroinitializer) #5
  %195 = lshr <8 x i16> %194, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %196 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %182, <8 x i16> %195) #5
  %197 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %196, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %198 = icmp slt <16 x i8> %197, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %199 = select <16 x i1> %198, <16 x i8> %197, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %200 = bitcast i8* %171 to <16 x i8>*
  store <16 x i8> %199, <16 x i8>* %200, align 16
  %201 = getelementptr inbounds i16, i16* %9, i64 96
  %202 = getelementptr inbounds i16, i16* %10, i64 96
  %203 = getelementptr inbounds i8, i8* %139, i64 %3
  %204 = bitcast i16* %201 to <8 x i16>*
  %205 = load <8 x i16>, <8 x i16>* %204, align 16
  %206 = bitcast i16* %202 to <8 x i16>*
  %207 = load <8 x i16>, <8 x i16>* %206, align 16
  %208 = sub <8 x i16> %205, %207
  %209 = sub <8 x i16> zeroinitializer, %208
  %210 = icmp slt <8 x i16> %208, zeroinitializer
  %211 = select <8 x i1> %210, <8 x i16> %209, <8 x i16> %208
  %212 = lshr <8 x i16> %211, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %213 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %212, <8 x i16> zeroinitializer) #5
  %214 = lshr <8 x i16> %213, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %215 = getelementptr inbounds i16, i16* %9, i64 104
  %216 = bitcast i16* %215 to <8 x i16>*
  %217 = load <8 x i16>, <8 x i16>* %216, align 16
  %218 = getelementptr inbounds i16, i16* %10, i64 104
  %219 = bitcast i16* %218 to <8 x i16>*
  %220 = load <8 x i16>, <8 x i16>* %219, align 16
  %221 = sub <8 x i16> %217, %220
  %222 = sub <8 x i16> zeroinitializer, %221
  %223 = icmp slt <8 x i16> %221, zeroinitializer
  %224 = select <8 x i1> %223, <8 x i16> %222, <8 x i16> %221
  %225 = lshr <8 x i16> %224, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %226 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %225, <8 x i16> zeroinitializer) #5
  %227 = lshr <8 x i16> %226, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %228 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %214, <8 x i16> %227) #5
  %229 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %228, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %230 = icmp slt <16 x i8> %229, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %231 = select <16 x i1> %230, <16 x i8> %229, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %232 = bitcast i8* %203 to <16 x i8>*
  store <16 x i8> %231, <16 x i8>* %232, align 16
  %233 = getelementptr inbounds i16, i16* %9, i64 112
  %234 = getelementptr inbounds i16, i16* %10, i64 112
  %235 = getelementptr inbounds i8, i8* %203, i64 16
  %236 = bitcast i16* %233 to <8 x i16>*
  %237 = load <8 x i16>, <8 x i16>* %236, align 16
  %238 = bitcast i16* %234 to <8 x i16>*
  %239 = load <8 x i16>, <8 x i16>* %238, align 16
  %240 = sub <8 x i16> %237, %239
  %241 = sub <8 x i16> zeroinitializer, %240
  %242 = icmp slt <8 x i16> %240, zeroinitializer
  %243 = select <8 x i1> %242, <8 x i16> %241, <8 x i16> %240
  %244 = lshr <8 x i16> %243, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %245 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %244, <8 x i16> zeroinitializer) #5
  %246 = lshr <8 x i16> %245, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %247 = getelementptr inbounds i16, i16* %9, i64 120
  %248 = bitcast i16* %247 to <8 x i16>*
  %249 = load <8 x i16>, <8 x i16>* %248, align 16
  %250 = getelementptr inbounds i16, i16* %10, i64 120
  %251 = bitcast i16* %250 to <8 x i16>*
  %252 = load <8 x i16>, <8 x i16>* %251, align 16
  %253 = sub <8 x i16> %249, %252
  %254 = sub <8 x i16> zeroinitializer, %253
  %255 = icmp slt <8 x i16> %253, zeroinitializer
  %256 = select <8 x i1> %255, <8 x i16> %254, <8 x i16> %253
  %257 = lshr <8 x i16> %256, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %258 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %257, <8 x i16> zeroinitializer) #5
  %259 = lshr <8 x i16> %258, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %260 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %246, <8 x i16> %259) #5
  %261 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %260, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %262 = icmp slt <16 x i8> %261, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %263 = select <16 x i1> %262, <16 x i8> %261, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %264 = bitcast i8* %235 to <16 x i8>*
  store <16 x i8> %263, <16 x i8>* %264, align 16
  %265 = getelementptr inbounds i16, i16* %9, i64 128
  %266 = getelementptr inbounds i16, i16* %10, i64 128
  %267 = getelementptr inbounds i8, i8* %203, i64 %3
  %268 = bitcast i16* %265 to <8 x i16>*
  %269 = load <8 x i16>, <8 x i16>* %268, align 16
  %270 = bitcast i16* %266 to <8 x i16>*
  %271 = load <8 x i16>, <8 x i16>* %270, align 16
  %272 = sub <8 x i16> %269, %271
  %273 = sub <8 x i16> zeroinitializer, %272
  %274 = icmp slt <8 x i16> %272, zeroinitializer
  %275 = select <8 x i1> %274, <8 x i16> %273, <8 x i16> %272
  %276 = lshr <8 x i16> %275, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %277 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %276, <8 x i16> zeroinitializer) #5
  %278 = lshr <8 x i16> %277, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %279 = getelementptr inbounds i16, i16* %9, i64 136
  %280 = bitcast i16* %279 to <8 x i16>*
  %281 = load <8 x i16>, <8 x i16>* %280, align 16
  %282 = getelementptr inbounds i16, i16* %10, i64 136
  %283 = bitcast i16* %282 to <8 x i16>*
  %284 = load <8 x i16>, <8 x i16>* %283, align 16
  %285 = sub <8 x i16> %281, %284
  %286 = sub <8 x i16> zeroinitializer, %285
  %287 = icmp slt <8 x i16> %285, zeroinitializer
  %288 = select <8 x i1> %287, <8 x i16> %286, <8 x i16> %285
  %289 = lshr <8 x i16> %288, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %290 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %289, <8 x i16> zeroinitializer) #5
  %291 = lshr <8 x i16> %290, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %292 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %278, <8 x i16> %291) #5
  %293 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %292, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %294 = icmp slt <16 x i8> %293, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %295 = select <16 x i1> %294, <16 x i8> %293, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %296 = bitcast i8* %267 to <16 x i8>*
  store <16 x i8> %295, <16 x i8>* %296, align 16
  %297 = getelementptr inbounds i16, i16* %9, i64 144
  %298 = getelementptr inbounds i16, i16* %10, i64 144
  %299 = getelementptr inbounds i8, i8* %267, i64 16
  %300 = bitcast i16* %297 to <8 x i16>*
  %301 = load <8 x i16>, <8 x i16>* %300, align 16
  %302 = bitcast i16* %298 to <8 x i16>*
  %303 = load <8 x i16>, <8 x i16>* %302, align 16
  %304 = sub <8 x i16> %301, %303
  %305 = sub <8 x i16> zeroinitializer, %304
  %306 = icmp slt <8 x i16> %304, zeroinitializer
  %307 = select <8 x i1> %306, <8 x i16> %305, <8 x i16> %304
  %308 = lshr <8 x i16> %307, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %309 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %308, <8 x i16> zeroinitializer) #5
  %310 = lshr <8 x i16> %309, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %311 = getelementptr inbounds i16, i16* %9, i64 152
  %312 = bitcast i16* %311 to <8 x i16>*
  %313 = load <8 x i16>, <8 x i16>* %312, align 16
  %314 = getelementptr inbounds i16, i16* %10, i64 152
  %315 = bitcast i16* %314 to <8 x i16>*
  %316 = load <8 x i16>, <8 x i16>* %315, align 16
  %317 = sub <8 x i16> %313, %316
  %318 = sub <8 x i16> zeroinitializer, %317
  %319 = icmp slt <8 x i16> %317, zeroinitializer
  %320 = select <8 x i1> %319, <8 x i16> %318, <8 x i16> %317
  %321 = lshr <8 x i16> %320, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %322 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %321, <8 x i16> zeroinitializer) #5
  %323 = lshr <8 x i16> %322, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %324 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %310, <8 x i16> %323) #5
  %325 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %324, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %326 = icmp slt <16 x i8> %325, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %327 = select <16 x i1> %326, <16 x i8> %325, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %328 = bitcast i8* %299 to <16 x i8>*
  store <16 x i8> %327, <16 x i8>* %328, align 16
  %329 = getelementptr inbounds i16, i16* %9, i64 160
  %330 = getelementptr inbounds i16, i16* %10, i64 160
  %331 = getelementptr inbounds i8, i8* %267, i64 %3
  %332 = add nsw i32 %11, -1
  %333 = icmp eq i32 %332, 0
  br i1 %333, label %334, label %7

334:                                              ; preds = %7
  %335 = bitcast i16* %329 to <8 x i16>*
  %336 = load <8 x i16>, <8 x i16>* %335, align 16
  %337 = bitcast i16* %330 to <8 x i16>*
  %338 = load <8 x i16>, <8 x i16>* %337, align 16
  %339 = sub <8 x i16> %336, %338
  %340 = sub <8 x i16> zeroinitializer, %339
  %341 = icmp slt <8 x i16> %339, zeroinitializer
  %342 = select <8 x i1> %341, <8 x i16> %340, <8 x i16> %339
  %343 = lshr <8 x i16> %342, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %344 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %343, <8 x i16> zeroinitializer) #5
  %345 = lshr <8 x i16> %344, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %346 = getelementptr inbounds i16, i16* %9, i64 168
  %347 = bitcast i16* %346 to <8 x i16>*
  %348 = load <8 x i16>, <8 x i16>* %347, align 16
  %349 = getelementptr inbounds i16, i16* %10, i64 168
  %350 = bitcast i16* %349 to <8 x i16>*
  %351 = load <8 x i16>, <8 x i16>* %350, align 16
  %352 = sub <8 x i16> %348, %351
  %353 = sub <8 x i16> zeroinitializer, %352
  %354 = icmp slt <8 x i16> %352, zeroinitializer
  %355 = select <8 x i1> %354, <8 x i16> %353, <8 x i16> %352
  %356 = lshr <8 x i16> %355, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %357 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %356, <8 x i16> zeroinitializer) #5
  %358 = lshr <8 x i16> %357, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %359 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %345, <8 x i16> %358) #5
  %360 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %359, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %361 = icmp slt <16 x i8> %360, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %362 = select <16 x i1> %361, <16 x i8> %360, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %363 = bitcast i8* %331 to <16 x i8>*
  store <16 x i8> %362, <16 x i8>* %363, align 16
  %364 = getelementptr inbounds i16, i16* %9, i64 176
  %365 = getelementptr inbounds i16, i16* %10, i64 176
  %366 = getelementptr inbounds i8, i8* %331, i64 16
  %367 = bitcast i16* %364 to <8 x i16>*
  %368 = load <8 x i16>, <8 x i16>* %367, align 16
  %369 = bitcast i16* %365 to <8 x i16>*
  %370 = load <8 x i16>, <8 x i16>* %369, align 16
  %371 = sub <8 x i16> %368, %370
  %372 = sub <8 x i16> zeroinitializer, %371
  %373 = icmp slt <8 x i16> %371, zeroinitializer
  %374 = select <8 x i1> %373, <8 x i16> %372, <8 x i16> %371
  %375 = lshr <8 x i16> %374, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %376 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %375, <8 x i16> zeroinitializer) #5
  %377 = lshr <8 x i16> %376, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %378 = getelementptr inbounds i16, i16* %9, i64 184
  %379 = bitcast i16* %378 to <8 x i16>*
  %380 = load <8 x i16>, <8 x i16>* %379, align 16
  %381 = getelementptr inbounds i16, i16* %10, i64 184
  %382 = bitcast i16* %381 to <8 x i16>*
  %383 = load <8 x i16>, <8 x i16>* %382, align 16
  %384 = sub <8 x i16> %380, %383
  %385 = sub <8 x i16> zeroinitializer, %384
  %386 = icmp slt <8 x i16> %384, zeroinitializer
  %387 = select <8 x i1> %386, <8 x i16> %385, <8 x i16> %384
  %388 = lshr <8 x i16> %387, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %389 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %388, <8 x i16> zeroinitializer) #5
  %390 = lshr <8 x i16> %389, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %391 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %377, <8 x i16> %390) #5
  %392 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %391, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %393 = icmp slt <16 x i8> %392, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %394 = select <16 x i1> %393, <16 x i8> %392, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %395 = bitcast i8* %366 to <16 x i8>*
  store <16 x i8> %394, <16 x i8>* %395, align 16
  %396 = getelementptr inbounds i16, i16* %9, i64 192
  %397 = getelementptr inbounds i16, i16* %10, i64 192
  %398 = getelementptr inbounds i8, i8* %331, i64 %3
  %399 = bitcast i16* %396 to <8 x i16>*
  %400 = load <8 x i16>, <8 x i16>* %399, align 16
  %401 = bitcast i16* %397 to <8 x i16>*
  %402 = load <8 x i16>, <8 x i16>* %401, align 16
  %403 = sub <8 x i16> %400, %402
  %404 = sub <8 x i16> zeroinitializer, %403
  %405 = icmp slt <8 x i16> %403, zeroinitializer
  %406 = select <8 x i1> %405, <8 x i16> %404, <8 x i16> %403
  %407 = lshr <8 x i16> %406, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %408 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %407, <8 x i16> zeroinitializer) #5
  %409 = lshr <8 x i16> %408, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %410 = getelementptr inbounds i16, i16* %9, i64 200
  %411 = bitcast i16* %410 to <8 x i16>*
  %412 = load <8 x i16>, <8 x i16>* %411, align 16
  %413 = getelementptr inbounds i16, i16* %10, i64 200
  %414 = bitcast i16* %413 to <8 x i16>*
  %415 = load <8 x i16>, <8 x i16>* %414, align 16
  %416 = sub <8 x i16> %412, %415
  %417 = sub <8 x i16> zeroinitializer, %416
  %418 = icmp slt <8 x i16> %416, zeroinitializer
  %419 = select <8 x i1> %418, <8 x i16> %417, <8 x i16> %416
  %420 = lshr <8 x i16> %419, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %421 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %420, <8 x i16> zeroinitializer) #5
  %422 = lshr <8 x i16> %421, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %423 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %409, <8 x i16> %422) #5
  %424 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %423, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %425 = icmp slt <16 x i8> %424, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %426 = select <16 x i1> %425, <16 x i8> %424, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %427 = bitcast i8* %398 to <16 x i8>*
  store <16 x i8> %426, <16 x i8>* %427, align 16
  %428 = getelementptr inbounds i16, i16* %9, i64 208
  %429 = getelementptr inbounds i16, i16* %10, i64 208
  %430 = getelementptr inbounds i8, i8* %398, i64 16
  %431 = bitcast i16* %428 to <8 x i16>*
  %432 = load <8 x i16>, <8 x i16>* %431, align 16
  %433 = bitcast i16* %429 to <8 x i16>*
  %434 = load <8 x i16>, <8 x i16>* %433, align 16
  %435 = sub <8 x i16> %432, %434
  %436 = sub <8 x i16> zeroinitializer, %435
  %437 = icmp slt <8 x i16> %435, zeroinitializer
  %438 = select <8 x i1> %437, <8 x i16> %436, <8 x i16> %435
  %439 = lshr <8 x i16> %438, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %440 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %439, <8 x i16> zeroinitializer) #5
  %441 = lshr <8 x i16> %440, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %442 = getelementptr inbounds i16, i16* %9, i64 216
  %443 = bitcast i16* %442 to <8 x i16>*
  %444 = load <8 x i16>, <8 x i16>* %443, align 16
  %445 = getelementptr inbounds i16, i16* %10, i64 216
  %446 = bitcast i16* %445 to <8 x i16>*
  %447 = load <8 x i16>, <8 x i16>* %446, align 16
  %448 = sub <8 x i16> %444, %447
  %449 = sub <8 x i16> zeroinitializer, %448
  %450 = icmp slt <8 x i16> %448, zeroinitializer
  %451 = select <8 x i1> %450, <8 x i16> %449, <8 x i16> %448
  %452 = lshr <8 x i16> %451, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %453 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %452, <8 x i16> zeroinitializer) #5
  %454 = lshr <8 x i16> %453, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %455 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %441, <8 x i16> %454) #5
  %456 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %455, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %457 = icmp slt <16 x i8> %456, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %458 = select <16 x i1> %457, <16 x i8> %456, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %459 = bitcast i8* %430 to <16 x i8>*
  store <16 x i8> %458, <16 x i8>* %459, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask32x32_SSE4ILb1EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %341, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %339, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %340, %7 ]
  %11 = phi i32 [ 6, %4 ], [ %342, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = sub <8 x i16> %13, %15
  %17 = sub <8 x i16> zeroinitializer, %16
  %18 = icmp slt <8 x i16> %16, zeroinitializer
  %19 = select <8 x i1> %18, <8 x i16> %17, <8 x i16> %16
  %20 = lshr <8 x i16> %19, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %21 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %20, <8 x i16> zeroinitializer) #5
  %22 = lshr <8 x i16> %21, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %23 = getelementptr inbounds i16, i16* %9, i64 8
  %24 = bitcast i16* %23 to <8 x i16>*
  %25 = load <8 x i16>, <8 x i16>* %24, align 16
  %26 = getelementptr inbounds i16, i16* %10, i64 8
  %27 = bitcast i16* %26 to <8 x i16>*
  %28 = load <8 x i16>, <8 x i16>* %27, align 16
  %29 = sub <8 x i16> %25, %28
  %30 = sub <8 x i16> zeroinitializer, %29
  %31 = icmp slt <8 x i16> %29, zeroinitializer
  %32 = select <8 x i1> %31, <8 x i16> %30, <8 x i16> %29
  %33 = lshr <8 x i16> %32, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %34 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %33, <8 x i16> zeroinitializer) #5
  %35 = lshr <8 x i16> %34, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %36 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %22, <8 x i16> %35) #5
  %37 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %36, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %38 = icmp slt <16 x i8> %37, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %39 = select <16 x i1> %38, <16 x i8> %37, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %40 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %39
  %41 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %40, <16 x i8>* %41, align 16
  %42 = getelementptr inbounds i16, i16* %9, i64 16
  %43 = getelementptr inbounds i16, i16* %10, i64 16
  %44 = getelementptr inbounds i8, i8* %8, i64 16
  %45 = bitcast i16* %42 to <8 x i16>*
  %46 = load <8 x i16>, <8 x i16>* %45, align 16
  %47 = bitcast i16* %43 to <8 x i16>*
  %48 = load <8 x i16>, <8 x i16>* %47, align 16
  %49 = sub <8 x i16> %46, %48
  %50 = sub <8 x i16> zeroinitializer, %49
  %51 = icmp slt <8 x i16> %49, zeroinitializer
  %52 = select <8 x i1> %51, <8 x i16> %50, <8 x i16> %49
  %53 = lshr <8 x i16> %52, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %54 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %53, <8 x i16> zeroinitializer) #5
  %55 = lshr <8 x i16> %54, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %56 = getelementptr inbounds i16, i16* %9, i64 24
  %57 = bitcast i16* %56 to <8 x i16>*
  %58 = load <8 x i16>, <8 x i16>* %57, align 16
  %59 = getelementptr inbounds i16, i16* %10, i64 24
  %60 = bitcast i16* %59 to <8 x i16>*
  %61 = load <8 x i16>, <8 x i16>* %60, align 16
  %62 = sub <8 x i16> %58, %61
  %63 = sub <8 x i16> zeroinitializer, %62
  %64 = icmp slt <8 x i16> %62, zeroinitializer
  %65 = select <8 x i1> %64, <8 x i16> %63, <8 x i16> %62
  %66 = lshr <8 x i16> %65, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %67 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %66, <8 x i16> zeroinitializer) #5
  %68 = lshr <8 x i16> %67, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %69 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %55, <8 x i16> %68) #5
  %70 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %69, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %71 = icmp slt <16 x i8> %70, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %72 = select <16 x i1> %71, <16 x i8> %70, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %73 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %72
  %74 = bitcast i8* %44 to <16 x i8>*
  store <16 x i8> %73, <16 x i8>* %74, align 16
  %75 = getelementptr inbounds i16, i16* %9, i64 32
  %76 = getelementptr inbounds i16, i16* %10, i64 32
  %77 = getelementptr inbounds i8, i8* %8, i64 %3
  %78 = bitcast i16* %75 to <8 x i16>*
  %79 = load <8 x i16>, <8 x i16>* %78, align 16
  %80 = bitcast i16* %76 to <8 x i16>*
  %81 = load <8 x i16>, <8 x i16>* %80, align 16
  %82 = sub <8 x i16> %79, %81
  %83 = sub <8 x i16> zeroinitializer, %82
  %84 = icmp slt <8 x i16> %82, zeroinitializer
  %85 = select <8 x i1> %84, <8 x i16> %83, <8 x i16> %82
  %86 = lshr <8 x i16> %85, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %87 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %86, <8 x i16> zeroinitializer) #5
  %88 = lshr <8 x i16> %87, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %89 = getelementptr inbounds i16, i16* %9, i64 40
  %90 = bitcast i16* %89 to <8 x i16>*
  %91 = load <8 x i16>, <8 x i16>* %90, align 16
  %92 = getelementptr inbounds i16, i16* %10, i64 40
  %93 = bitcast i16* %92 to <8 x i16>*
  %94 = load <8 x i16>, <8 x i16>* %93, align 16
  %95 = sub <8 x i16> %91, %94
  %96 = sub <8 x i16> zeroinitializer, %95
  %97 = icmp slt <8 x i16> %95, zeroinitializer
  %98 = select <8 x i1> %97, <8 x i16> %96, <8 x i16> %95
  %99 = lshr <8 x i16> %98, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %100 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %99, <8 x i16> zeroinitializer) #5
  %101 = lshr <8 x i16> %100, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %102 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %88, <8 x i16> %101) #5
  %103 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %102, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %104 = icmp slt <16 x i8> %103, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %105 = select <16 x i1> %104, <16 x i8> %103, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %106 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %105
  %107 = bitcast i8* %77 to <16 x i8>*
  store <16 x i8> %106, <16 x i8>* %107, align 16
  %108 = getelementptr inbounds i16, i16* %9, i64 48
  %109 = getelementptr inbounds i16, i16* %10, i64 48
  %110 = getelementptr inbounds i8, i8* %77, i64 16
  %111 = bitcast i16* %108 to <8 x i16>*
  %112 = load <8 x i16>, <8 x i16>* %111, align 16
  %113 = bitcast i16* %109 to <8 x i16>*
  %114 = load <8 x i16>, <8 x i16>* %113, align 16
  %115 = sub <8 x i16> %112, %114
  %116 = sub <8 x i16> zeroinitializer, %115
  %117 = icmp slt <8 x i16> %115, zeroinitializer
  %118 = select <8 x i1> %117, <8 x i16> %116, <8 x i16> %115
  %119 = lshr <8 x i16> %118, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %120 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %119, <8 x i16> zeroinitializer) #5
  %121 = lshr <8 x i16> %120, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %122 = getelementptr inbounds i16, i16* %9, i64 56
  %123 = bitcast i16* %122 to <8 x i16>*
  %124 = load <8 x i16>, <8 x i16>* %123, align 16
  %125 = getelementptr inbounds i16, i16* %10, i64 56
  %126 = bitcast i16* %125 to <8 x i16>*
  %127 = load <8 x i16>, <8 x i16>* %126, align 16
  %128 = sub <8 x i16> %124, %127
  %129 = sub <8 x i16> zeroinitializer, %128
  %130 = icmp slt <8 x i16> %128, zeroinitializer
  %131 = select <8 x i1> %130, <8 x i16> %129, <8 x i16> %128
  %132 = lshr <8 x i16> %131, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %133 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %132, <8 x i16> zeroinitializer) #5
  %134 = lshr <8 x i16> %133, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %135 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %121, <8 x i16> %134) #5
  %136 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %135, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %137 = icmp slt <16 x i8> %136, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %138 = select <16 x i1> %137, <16 x i8> %136, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %139 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %138
  %140 = bitcast i8* %110 to <16 x i8>*
  store <16 x i8> %139, <16 x i8>* %140, align 16
  %141 = getelementptr inbounds i16, i16* %9, i64 64
  %142 = getelementptr inbounds i16, i16* %10, i64 64
  %143 = getelementptr inbounds i8, i8* %77, i64 %3
  %144 = bitcast i16* %141 to <8 x i16>*
  %145 = load <8 x i16>, <8 x i16>* %144, align 16
  %146 = bitcast i16* %142 to <8 x i16>*
  %147 = load <8 x i16>, <8 x i16>* %146, align 16
  %148 = sub <8 x i16> %145, %147
  %149 = sub <8 x i16> zeroinitializer, %148
  %150 = icmp slt <8 x i16> %148, zeroinitializer
  %151 = select <8 x i1> %150, <8 x i16> %149, <8 x i16> %148
  %152 = lshr <8 x i16> %151, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %153 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %152, <8 x i16> zeroinitializer) #5
  %154 = lshr <8 x i16> %153, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %155 = getelementptr inbounds i16, i16* %9, i64 72
  %156 = bitcast i16* %155 to <8 x i16>*
  %157 = load <8 x i16>, <8 x i16>* %156, align 16
  %158 = getelementptr inbounds i16, i16* %10, i64 72
  %159 = bitcast i16* %158 to <8 x i16>*
  %160 = load <8 x i16>, <8 x i16>* %159, align 16
  %161 = sub <8 x i16> %157, %160
  %162 = sub <8 x i16> zeroinitializer, %161
  %163 = icmp slt <8 x i16> %161, zeroinitializer
  %164 = select <8 x i1> %163, <8 x i16> %162, <8 x i16> %161
  %165 = lshr <8 x i16> %164, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %166 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %165, <8 x i16> zeroinitializer) #5
  %167 = lshr <8 x i16> %166, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %168 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %154, <8 x i16> %167) #5
  %169 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %168, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %170 = icmp slt <16 x i8> %169, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %171 = select <16 x i1> %170, <16 x i8> %169, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %172 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %171
  %173 = bitcast i8* %143 to <16 x i8>*
  store <16 x i8> %172, <16 x i8>* %173, align 16
  %174 = getelementptr inbounds i16, i16* %9, i64 80
  %175 = getelementptr inbounds i16, i16* %10, i64 80
  %176 = getelementptr inbounds i8, i8* %143, i64 16
  %177 = bitcast i16* %174 to <8 x i16>*
  %178 = load <8 x i16>, <8 x i16>* %177, align 16
  %179 = bitcast i16* %175 to <8 x i16>*
  %180 = load <8 x i16>, <8 x i16>* %179, align 16
  %181 = sub <8 x i16> %178, %180
  %182 = sub <8 x i16> zeroinitializer, %181
  %183 = icmp slt <8 x i16> %181, zeroinitializer
  %184 = select <8 x i1> %183, <8 x i16> %182, <8 x i16> %181
  %185 = lshr <8 x i16> %184, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %186 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %185, <8 x i16> zeroinitializer) #5
  %187 = lshr <8 x i16> %186, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %188 = getelementptr inbounds i16, i16* %9, i64 88
  %189 = bitcast i16* %188 to <8 x i16>*
  %190 = load <8 x i16>, <8 x i16>* %189, align 16
  %191 = getelementptr inbounds i16, i16* %10, i64 88
  %192 = bitcast i16* %191 to <8 x i16>*
  %193 = load <8 x i16>, <8 x i16>* %192, align 16
  %194 = sub <8 x i16> %190, %193
  %195 = sub <8 x i16> zeroinitializer, %194
  %196 = icmp slt <8 x i16> %194, zeroinitializer
  %197 = select <8 x i1> %196, <8 x i16> %195, <8 x i16> %194
  %198 = lshr <8 x i16> %197, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %199 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %198, <8 x i16> zeroinitializer) #5
  %200 = lshr <8 x i16> %199, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %201 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %187, <8 x i16> %200) #5
  %202 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %201, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %203 = icmp slt <16 x i8> %202, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %204 = select <16 x i1> %203, <16 x i8> %202, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %205 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %204
  %206 = bitcast i8* %176 to <16 x i8>*
  store <16 x i8> %205, <16 x i8>* %206, align 16
  %207 = getelementptr inbounds i16, i16* %9, i64 96
  %208 = getelementptr inbounds i16, i16* %10, i64 96
  %209 = getelementptr inbounds i8, i8* %143, i64 %3
  %210 = bitcast i16* %207 to <8 x i16>*
  %211 = load <8 x i16>, <8 x i16>* %210, align 16
  %212 = bitcast i16* %208 to <8 x i16>*
  %213 = load <8 x i16>, <8 x i16>* %212, align 16
  %214 = sub <8 x i16> %211, %213
  %215 = sub <8 x i16> zeroinitializer, %214
  %216 = icmp slt <8 x i16> %214, zeroinitializer
  %217 = select <8 x i1> %216, <8 x i16> %215, <8 x i16> %214
  %218 = lshr <8 x i16> %217, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %219 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %218, <8 x i16> zeroinitializer) #5
  %220 = lshr <8 x i16> %219, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %221 = getelementptr inbounds i16, i16* %9, i64 104
  %222 = bitcast i16* %221 to <8 x i16>*
  %223 = load <8 x i16>, <8 x i16>* %222, align 16
  %224 = getelementptr inbounds i16, i16* %10, i64 104
  %225 = bitcast i16* %224 to <8 x i16>*
  %226 = load <8 x i16>, <8 x i16>* %225, align 16
  %227 = sub <8 x i16> %223, %226
  %228 = sub <8 x i16> zeroinitializer, %227
  %229 = icmp slt <8 x i16> %227, zeroinitializer
  %230 = select <8 x i1> %229, <8 x i16> %228, <8 x i16> %227
  %231 = lshr <8 x i16> %230, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %232 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %231, <8 x i16> zeroinitializer) #5
  %233 = lshr <8 x i16> %232, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %234 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %220, <8 x i16> %233) #5
  %235 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %234, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %236 = icmp slt <16 x i8> %235, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %237 = select <16 x i1> %236, <16 x i8> %235, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %238 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %237
  %239 = bitcast i8* %209 to <16 x i8>*
  store <16 x i8> %238, <16 x i8>* %239, align 16
  %240 = getelementptr inbounds i16, i16* %9, i64 112
  %241 = getelementptr inbounds i16, i16* %10, i64 112
  %242 = getelementptr inbounds i8, i8* %209, i64 16
  %243 = bitcast i16* %240 to <8 x i16>*
  %244 = load <8 x i16>, <8 x i16>* %243, align 16
  %245 = bitcast i16* %241 to <8 x i16>*
  %246 = load <8 x i16>, <8 x i16>* %245, align 16
  %247 = sub <8 x i16> %244, %246
  %248 = sub <8 x i16> zeroinitializer, %247
  %249 = icmp slt <8 x i16> %247, zeroinitializer
  %250 = select <8 x i1> %249, <8 x i16> %248, <8 x i16> %247
  %251 = lshr <8 x i16> %250, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %252 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %251, <8 x i16> zeroinitializer) #5
  %253 = lshr <8 x i16> %252, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %254 = getelementptr inbounds i16, i16* %9, i64 120
  %255 = bitcast i16* %254 to <8 x i16>*
  %256 = load <8 x i16>, <8 x i16>* %255, align 16
  %257 = getelementptr inbounds i16, i16* %10, i64 120
  %258 = bitcast i16* %257 to <8 x i16>*
  %259 = load <8 x i16>, <8 x i16>* %258, align 16
  %260 = sub <8 x i16> %256, %259
  %261 = sub <8 x i16> zeroinitializer, %260
  %262 = icmp slt <8 x i16> %260, zeroinitializer
  %263 = select <8 x i1> %262, <8 x i16> %261, <8 x i16> %260
  %264 = lshr <8 x i16> %263, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %265 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %264, <8 x i16> zeroinitializer) #5
  %266 = lshr <8 x i16> %265, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %267 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %253, <8 x i16> %266) #5
  %268 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %267, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %269 = icmp slt <16 x i8> %268, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %270 = select <16 x i1> %269, <16 x i8> %268, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %271 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %270
  %272 = bitcast i8* %242 to <16 x i8>*
  store <16 x i8> %271, <16 x i8>* %272, align 16
  %273 = getelementptr inbounds i16, i16* %9, i64 128
  %274 = getelementptr inbounds i16, i16* %10, i64 128
  %275 = getelementptr inbounds i8, i8* %209, i64 %3
  %276 = bitcast i16* %273 to <8 x i16>*
  %277 = load <8 x i16>, <8 x i16>* %276, align 16
  %278 = bitcast i16* %274 to <8 x i16>*
  %279 = load <8 x i16>, <8 x i16>* %278, align 16
  %280 = sub <8 x i16> %277, %279
  %281 = sub <8 x i16> zeroinitializer, %280
  %282 = icmp slt <8 x i16> %280, zeroinitializer
  %283 = select <8 x i1> %282, <8 x i16> %281, <8 x i16> %280
  %284 = lshr <8 x i16> %283, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %285 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %284, <8 x i16> zeroinitializer) #5
  %286 = lshr <8 x i16> %285, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %287 = getelementptr inbounds i16, i16* %9, i64 136
  %288 = bitcast i16* %287 to <8 x i16>*
  %289 = load <8 x i16>, <8 x i16>* %288, align 16
  %290 = getelementptr inbounds i16, i16* %10, i64 136
  %291 = bitcast i16* %290 to <8 x i16>*
  %292 = load <8 x i16>, <8 x i16>* %291, align 16
  %293 = sub <8 x i16> %289, %292
  %294 = sub <8 x i16> zeroinitializer, %293
  %295 = icmp slt <8 x i16> %293, zeroinitializer
  %296 = select <8 x i1> %295, <8 x i16> %294, <8 x i16> %293
  %297 = lshr <8 x i16> %296, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %298 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %297, <8 x i16> zeroinitializer) #5
  %299 = lshr <8 x i16> %298, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %300 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %286, <8 x i16> %299) #5
  %301 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %300, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %302 = icmp slt <16 x i8> %301, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %303 = select <16 x i1> %302, <16 x i8> %301, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %304 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %303
  %305 = bitcast i8* %275 to <16 x i8>*
  store <16 x i8> %304, <16 x i8>* %305, align 16
  %306 = getelementptr inbounds i16, i16* %9, i64 144
  %307 = getelementptr inbounds i16, i16* %10, i64 144
  %308 = getelementptr inbounds i8, i8* %275, i64 16
  %309 = bitcast i16* %306 to <8 x i16>*
  %310 = load <8 x i16>, <8 x i16>* %309, align 16
  %311 = bitcast i16* %307 to <8 x i16>*
  %312 = load <8 x i16>, <8 x i16>* %311, align 16
  %313 = sub <8 x i16> %310, %312
  %314 = sub <8 x i16> zeroinitializer, %313
  %315 = icmp slt <8 x i16> %313, zeroinitializer
  %316 = select <8 x i1> %315, <8 x i16> %314, <8 x i16> %313
  %317 = lshr <8 x i16> %316, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %318 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %317, <8 x i16> zeroinitializer) #5
  %319 = lshr <8 x i16> %318, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %320 = getelementptr inbounds i16, i16* %9, i64 152
  %321 = bitcast i16* %320 to <8 x i16>*
  %322 = load <8 x i16>, <8 x i16>* %321, align 16
  %323 = getelementptr inbounds i16, i16* %10, i64 152
  %324 = bitcast i16* %323 to <8 x i16>*
  %325 = load <8 x i16>, <8 x i16>* %324, align 16
  %326 = sub <8 x i16> %322, %325
  %327 = sub <8 x i16> zeroinitializer, %326
  %328 = icmp slt <8 x i16> %326, zeroinitializer
  %329 = select <8 x i1> %328, <8 x i16> %327, <8 x i16> %326
  %330 = lshr <8 x i16> %329, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %331 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %330, <8 x i16> zeroinitializer) #5
  %332 = lshr <8 x i16> %331, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %333 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %319, <8 x i16> %332) #5
  %334 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %333, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %335 = icmp slt <16 x i8> %334, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %336 = select <16 x i1> %335, <16 x i8> %334, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %337 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %336
  %338 = bitcast i8* %308 to <16 x i8>*
  store <16 x i8> %337, <16 x i8>* %338, align 16
  %339 = getelementptr inbounds i16, i16* %9, i64 160
  %340 = getelementptr inbounds i16, i16* %10, i64 160
  %341 = getelementptr inbounds i8, i8* %275, i64 %3
  %342 = add nsw i32 %11, -1
  %343 = icmp eq i32 %342, 0
  br i1 %343, label %344, label %7

344:                                              ; preds = %7
  %345 = bitcast i16* %339 to <8 x i16>*
  %346 = load <8 x i16>, <8 x i16>* %345, align 16
  %347 = bitcast i16* %340 to <8 x i16>*
  %348 = load <8 x i16>, <8 x i16>* %347, align 16
  %349 = sub <8 x i16> %346, %348
  %350 = sub <8 x i16> zeroinitializer, %349
  %351 = icmp slt <8 x i16> %349, zeroinitializer
  %352 = select <8 x i1> %351, <8 x i16> %350, <8 x i16> %349
  %353 = lshr <8 x i16> %352, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %354 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %353, <8 x i16> zeroinitializer) #5
  %355 = lshr <8 x i16> %354, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %356 = getelementptr inbounds i16, i16* %9, i64 168
  %357 = bitcast i16* %356 to <8 x i16>*
  %358 = load <8 x i16>, <8 x i16>* %357, align 16
  %359 = getelementptr inbounds i16, i16* %10, i64 168
  %360 = bitcast i16* %359 to <8 x i16>*
  %361 = load <8 x i16>, <8 x i16>* %360, align 16
  %362 = sub <8 x i16> %358, %361
  %363 = sub <8 x i16> zeroinitializer, %362
  %364 = icmp slt <8 x i16> %362, zeroinitializer
  %365 = select <8 x i1> %364, <8 x i16> %363, <8 x i16> %362
  %366 = lshr <8 x i16> %365, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %367 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %366, <8 x i16> zeroinitializer) #5
  %368 = lshr <8 x i16> %367, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %369 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %355, <8 x i16> %368) #5
  %370 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %369, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %371 = icmp slt <16 x i8> %370, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %372 = select <16 x i1> %371, <16 x i8> %370, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %373 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %372
  %374 = bitcast i8* %341 to <16 x i8>*
  store <16 x i8> %373, <16 x i8>* %374, align 16
  %375 = getelementptr inbounds i16, i16* %9, i64 176
  %376 = getelementptr inbounds i16, i16* %10, i64 176
  %377 = getelementptr inbounds i8, i8* %341, i64 16
  %378 = bitcast i16* %375 to <8 x i16>*
  %379 = load <8 x i16>, <8 x i16>* %378, align 16
  %380 = bitcast i16* %376 to <8 x i16>*
  %381 = load <8 x i16>, <8 x i16>* %380, align 16
  %382 = sub <8 x i16> %379, %381
  %383 = sub <8 x i16> zeroinitializer, %382
  %384 = icmp slt <8 x i16> %382, zeroinitializer
  %385 = select <8 x i1> %384, <8 x i16> %383, <8 x i16> %382
  %386 = lshr <8 x i16> %385, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %387 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %386, <8 x i16> zeroinitializer) #5
  %388 = lshr <8 x i16> %387, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %389 = getelementptr inbounds i16, i16* %9, i64 184
  %390 = bitcast i16* %389 to <8 x i16>*
  %391 = load <8 x i16>, <8 x i16>* %390, align 16
  %392 = getelementptr inbounds i16, i16* %10, i64 184
  %393 = bitcast i16* %392 to <8 x i16>*
  %394 = load <8 x i16>, <8 x i16>* %393, align 16
  %395 = sub <8 x i16> %391, %394
  %396 = sub <8 x i16> zeroinitializer, %395
  %397 = icmp slt <8 x i16> %395, zeroinitializer
  %398 = select <8 x i1> %397, <8 x i16> %396, <8 x i16> %395
  %399 = lshr <8 x i16> %398, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %400 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %399, <8 x i16> zeroinitializer) #5
  %401 = lshr <8 x i16> %400, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %402 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %388, <8 x i16> %401) #5
  %403 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %402, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %404 = icmp slt <16 x i8> %403, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %405 = select <16 x i1> %404, <16 x i8> %403, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %406 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %405
  %407 = bitcast i8* %377 to <16 x i8>*
  store <16 x i8> %406, <16 x i8>* %407, align 16
  %408 = getelementptr inbounds i16, i16* %9, i64 192
  %409 = getelementptr inbounds i16, i16* %10, i64 192
  %410 = getelementptr inbounds i8, i8* %341, i64 %3
  %411 = bitcast i16* %408 to <8 x i16>*
  %412 = load <8 x i16>, <8 x i16>* %411, align 16
  %413 = bitcast i16* %409 to <8 x i16>*
  %414 = load <8 x i16>, <8 x i16>* %413, align 16
  %415 = sub <8 x i16> %412, %414
  %416 = sub <8 x i16> zeroinitializer, %415
  %417 = icmp slt <8 x i16> %415, zeroinitializer
  %418 = select <8 x i1> %417, <8 x i16> %416, <8 x i16> %415
  %419 = lshr <8 x i16> %418, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %420 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %419, <8 x i16> zeroinitializer) #5
  %421 = lshr <8 x i16> %420, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %422 = getelementptr inbounds i16, i16* %9, i64 200
  %423 = bitcast i16* %422 to <8 x i16>*
  %424 = load <8 x i16>, <8 x i16>* %423, align 16
  %425 = getelementptr inbounds i16, i16* %10, i64 200
  %426 = bitcast i16* %425 to <8 x i16>*
  %427 = load <8 x i16>, <8 x i16>* %426, align 16
  %428 = sub <8 x i16> %424, %427
  %429 = sub <8 x i16> zeroinitializer, %428
  %430 = icmp slt <8 x i16> %428, zeroinitializer
  %431 = select <8 x i1> %430, <8 x i16> %429, <8 x i16> %428
  %432 = lshr <8 x i16> %431, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %433 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %432, <8 x i16> zeroinitializer) #5
  %434 = lshr <8 x i16> %433, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %435 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %421, <8 x i16> %434) #5
  %436 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %435, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %437 = icmp slt <16 x i8> %436, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %438 = select <16 x i1> %437, <16 x i8> %436, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %439 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %438
  %440 = bitcast i8* %410 to <16 x i8>*
  store <16 x i8> %439, <16 x i8>* %440, align 16
  %441 = getelementptr inbounds i16, i16* %9, i64 208
  %442 = getelementptr inbounds i16, i16* %10, i64 208
  %443 = getelementptr inbounds i8, i8* %410, i64 16
  %444 = bitcast i16* %441 to <8 x i16>*
  %445 = load <8 x i16>, <8 x i16>* %444, align 16
  %446 = bitcast i16* %442 to <8 x i16>*
  %447 = load <8 x i16>, <8 x i16>* %446, align 16
  %448 = sub <8 x i16> %445, %447
  %449 = sub <8 x i16> zeroinitializer, %448
  %450 = icmp slt <8 x i16> %448, zeroinitializer
  %451 = select <8 x i1> %450, <8 x i16> %449, <8 x i16> %448
  %452 = lshr <8 x i16> %451, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %453 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %452, <8 x i16> zeroinitializer) #5
  %454 = lshr <8 x i16> %453, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %455 = getelementptr inbounds i16, i16* %9, i64 216
  %456 = bitcast i16* %455 to <8 x i16>*
  %457 = load <8 x i16>, <8 x i16>* %456, align 16
  %458 = getelementptr inbounds i16, i16* %10, i64 216
  %459 = bitcast i16* %458 to <8 x i16>*
  %460 = load <8 x i16>, <8 x i16>* %459, align 16
  %461 = sub <8 x i16> %457, %460
  %462 = sub <8 x i16> zeroinitializer, %461
  %463 = icmp slt <8 x i16> %461, zeroinitializer
  %464 = select <8 x i1> %463, <8 x i16> %462, <8 x i16> %461
  %465 = lshr <8 x i16> %464, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %466 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %465, <8 x i16> zeroinitializer) #5
  %467 = lshr <8 x i16> %466, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %468 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %454, <8 x i16> %467) #5
  %469 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %468, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %470 = icmp slt <16 x i8> %469, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %471 = select <16 x i1> %470, <16 x i8> %469, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %472 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %471
  %473 = bitcast i8* %443 to <16 x i8>*
  store <16 x i8> %472, <16 x i8>* %473, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask32x64_SSE4ILb0EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %203, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %201, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %202, %7 ]
  %11 = phi i32 [ 21, %4 ], [ %204, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = sub <8 x i16> %13, %15
  %17 = sub <8 x i16> zeroinitializer, %16
  %18 = icmp slt <8 x i16> %16, zeroinitializer
  %19 = select <8 x i1> %18, <8 x i16> %17, <8 x i16> %16
  %20 = lshr <8 x i16> %19, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %21 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %20, <8 x i16> zeroinitializer) #5
  %22 = lshr <8 x i16> %21, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %23 = getelementptr inbounds i16, i16* %9, i64 8
  %24 = bitcast i16* %23 to <8 x i16>*
  %25 = load <8 x i16>, <8 x i16>* %24, align 16
  %26 = getelementptr inbounds i16, i16* %10, i64 8
  %27 = bitcast i16* %26 to <8 x i16>*
  %28 = load <8 x i16>, <8 x i16>* %27, align 16
  %29 = sub <8 x i16> %25, %28
  %30 = sub <8 x i16> zeroinitializer, %29
  %31 = icmp slt <8 x i16> %29, zeroinitializer
  %32 = select <8 x i1> %31, <8 x i16> %30, <8 x i16> %29
  %33 = lshr <8 x i16> %32, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %34 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %33, <8 x i16> zeroinitializer) #5
  %35 = lshr <8 x i16> %34, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %36 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %22, <8 x i16> %35) #5
  %37 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %36, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %38 = icmp slt <16 x i8> %37, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %39 = select <16 x i1> %38, <16 x i8> %37, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %40 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %40, align 16
  %41 = getelementptr inbounds i16, i16* %9, i64 16
  %42 = getelementptr inbounds i16, i16* %10, i64 16
  %43 = getelementptr inbounds i8, i8* %8, i64 16
  %44 = bitcast i16* %41 to <8 x i16>*
  %45 = load <8 x i16>, <8 x i16>* %44, align 16
  %46 = bitcast i16* %42 to <8 x i16>*
  %47 = load <8 x i16>, <8 x i16>* %46, align 16
  %48 = sub <8 x i16> %45, %47
  %49 = sub <8 x i16> zeroinitializer, %48
  %50 = icmp slt <8 x i16> %48, zeroinitializer
  %51 = select <8 x i1> %50, <8 x i16> %49, <8 x i16> %48
  %52 = lshr <8 x i16> %51, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %53 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %52, <8 x i16> zeroinitializer) #5
  %54 = lshr <8 x i16> %53, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %55 = getelementptr inbounds i16, i16* %9, i64 24
  %56 = bitcast i16* %55 to <8 x i16>*
  %57 = load <8 x i16>, <8 x i16>* %56, align 16
  %58 = getelementptr inbounds i16, i16* %10, i64 24
  %59 = bitcast i16* %58 to <8 x i16>*
  %60 = load <8 x i16>, <8 x i16>* %59, align 16
  %61 = sub <8 x i16> %57, %60
  %62 = sub <8 x i16> zeroinitializer, %61
  %63 = icmp slt <8 x i16> %61, zeroinitializer
  %64 = select <8 x i1> %63, <8 x i16> %62, <8 x i16> %61
  %65 = lshr <8 x i16> %64, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %66 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %65, <8 x i16> zeroinitializer) #5
  %67 = lshr <8 x i16> %66, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %68 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %54, <8 x i16> %67) #5
  %69 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %68, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %70 = icmp slt <16 x i8> %69, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %71 = select <16 x i1> %70, <16 x i8> %69, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %72 = bitcast i8* %43 to <16 x i8>*
  store <16 x i8> %71, <16 x i8>* %72, align 16
  %73 = getelementptr inbounds i16, i16* %9, i64 32
  %74 = getelementptr inbounds i16, i16* %10, i64 32
  %75 = getelementptr inbounds i8, i8* %8, i64 %3
  %76 = bitcast i16* %73 to <8 x i16>*
  %77 = load <8 x i16>, <8 x i16>* %76, align 16
  %78 = bitcast i16* %74 to <8 x i16>*
  %79 = load <8 x i16>, <8 x i16>* %78, align 16
  %80 = sub <8 x i16> %77, %79
  %81 = sub <8 x i16> zeroinitializer, %80
  %82 = icmp slt <8 x i16> %80, zeroinitializer
  %83 = select <8 x i1> %82, <8 x i16> %81, <8 x i16> %80
  %84 = lshr <8 x i16> %83, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %85 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %84, <8 x i16> zeroinitializer) #5
  %86 = lshr <8 x i16> %85, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %87 = getelementptr inbounds i16, i16* %9, i64 40
  %88 = bitcast i16* %87 to <8 x i16>*
  %89 = load <8 x i16>, <8 x i16>* %88, align 16
  %90 = getelementptr inbounds i16, i16* %10, i64 40
  %91 = bitcast i16* %90 to <8 x i16>*
  %92 = load <8 x i16>, <8 x i16>* %91, align 16
  %93 = sub <8 x i16> %89, %92
  %94 = sub <8 x i16> zeroinitializer, %93
  %95 = icmp slt <8 x i16> %93, zeroinitializer
  %96 = select <8 x i1> %95, <8 x i16> %94, <8 x i16> %93
  %97 = lshr <8 x i16> %96, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %98 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %97, <8 x i16> zeroinitializer) #5
  %99 = lshr <8 x i16> %98, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %100 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %86, <8 x i16> %99) #5
  %101 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %100, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %102 = icmp slt <16 x i8> %101, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %103 = select <16 x i1> %102, <16 x i8> %101, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %104 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %103, <16 x i8>* %104, align 16
  %105 = getelementptr inbounds i16, i16* %9, i64 48
  %106 = getelementptr inbounds i16, i16* %10, i64 48
  %107 = getelementptr inbounds i8, i8* %75, i64 16
  %108 = bitcast i16* %105 to <8 x i16>*
  %109 = load <8 x i16>, <8 x i16>* %108, align 16
  %110 = bitcast i16* %106 to <8 x i16>*
  %111 = load <8 x i16>, <8 x i16>* %110, align 16
  %112 = sub <8 x i16> %109, %111
  %113 = sub <8 x i16> zeroinitializer, %112
  %114 = icmp slt <8 x i16> %112, zeroinitializer
  %115 = select <8 x i1> %114, <8 x i16> %113, <8 x i16> %112
  %116 = lshr <8 x i16> %115, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %117 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %116, <8 x i16> zeroinitializer) #5
  %118 = lshr <8 x i16> %117, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %119 = getelementptr inbounds i16, i16* %9, i64 56
  %120 = bitcast i16* %119 to <8 x i16>*
  %121 = load <8 x i16>, <8 x i16>* %120, align 16
  %122 = getelementptr inbounds i16, i16* %10, i64 56
  %123 = bitcast i16* %122 to <8 x i16>*
  %124 = load <8 x i16>, <8 x i16>* %123, align 16
  %125 = sub <8 x i16> %121, %124
  %126 = sub <8 x i16> zeroinitializer, %125
  %127 = icmp slt <8 x i16> %125, zeroinitializer
  %128 = select <8 x i1> %127, <8 x i16> %126, <8 x i16> %125
  %129 = lshr <8 x i16> %128, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %130 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %129, <8 x i16> zeroinitializer) #5
  %131 = lshr <8 x i16> %130, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %132 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %118, <8 x i16> %131) #5
  %133 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %132, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %134 = icmp slt <16 x i8> %133, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %135 = select <16 x i1> %134, <16 x i8> %133, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %136 = bitcast i8* %107 to <16 x i8>*
  store <16 x i8> %135, <16 x i8>* %136, align 16
  %137 = getelementptr inbounds i16, i16* %9, i64 64
  %138 = getelementptr inbounds i16, i16* %10, i64 64
  %139 = getelementptr inbounds i8, i8* %75, i64 %3
  %140 = bitcast i16* %137 to <8 x i16>*
  %141 = load <8 x i16>, <8 x i16>* %140, align 16
  %142 = bitcast i16* %138 to <8 x i16>*
  %143 = load <8 x i16>, <8 x i16>* %142, align 16
  %144 = sub <8 x i16> %141, %143
  %145 = sub <8 x i16> zeroinitializer, %144
  %146 = icmp slt <8 x i16> %144, zeroinitializer
  %147 = select <8 x i1> %146, <8 x i16> %145, <8 x i16> %144
  %148 = lshr <8 x i16> %147, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %149 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %148, <8 x i16> zeroinitializer) #5
  %150 = lshr <8 x i16> %149, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %151 = getelementptr inbounds i16, i16* %9, i64 72
  %152 = bitcast i16* %151 to <8 x i16>*
  %153 = load <8 x i16>, <8 x i16>* %152, align 16
  %154 = getelementptr inbounds i16, i16* %10, i64 72
  %155 = bitcast i16* %154 to <8 x i16>*
  %156 = load <8 x i16>, <8 x i16>* %155, align 16
  %157 = sub <8 x i16> %153, %156
  %158 = sub <8 x i16> zeroinitializer, %157
  %159 = icmp slt <8 x i16> %157, zeroinitializer
  %160 = select <8 x i1> %159, <8 x i16> %158, <8 x i16> %157
  %161 = lshr <8 x i16> %160, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %162 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %161, <8 x i16> zeroinitializer) #5
  %163 = lshr <8 x i16> %162, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %164 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %150, <8 x i16> %163) #5
  %165 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %164, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %166 = icmp slt <16 x i8> %165, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %167 = select <16 x i1> %166, <16 x i8> %165, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %168 = bitcast i8* %139 to <16 x i8>*
  store <16 x i8> %167, <16 x i8>* %168, align 16
  %169 = getelementptr inbounds i16, i16* %9, i64 80
  %170 = getelementptr inbounds i16, i16* %10, i64 80
  %171 = getelementptr inbounds i8, i8* %139, i64 16
  %172 = bitcast i16* %169 to <8 x i16>*
  %173 = load <8 x i16>, <8 x i16>* %172, align 16
  %174 = bitcast i16* %170 to <8 x i16>*
  %175 = load <8 x i16>, <8 x i16>* %174, align 16
  %176 = sub <8 x i16> %173, %175
  %177 = sub <8 x i16> zeroinitializer, %176
  %178 = icmp slt <8 x i16> %176, zeroinitializer
  %179 = select <8 x i1> %178, <8 x i16> %177, <8 x i16> %176
  %180 = lshr <8 x i16> %179, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %181 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %180, <8 x i16> zeroinitializer) #5
  %182 = lshr <8 x i16> %181, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %183 = getelementptr inbounds i16, i16* %9, i64 88
  %184 = bitcast i16* %183 to <8 x i16>*
  %185 = load <8 x i16>, <8 x i16>* %184, align 16
  %186 = getelementptr inbounds i16, i16* %10, i64 88
  %187 = bitcast i16* %186 to <8 x i16>*
  %188 = load <8 x i16>, <8 x i16>* %187, align 16
  %189 = sub <8 x i16> %185, %188
  %190 = sub <8 x i16> zeroinitializer, %189
  %191 = icmp slt <8 x i16> %189, zeroinitializer
  %192 = select <8 x i1> %191, <8 x i16> %190, <8 x i16> %189
  %193 = lshr <8 x i16> %192, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %194 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %193, <8 x i16> zeroinitializer) #5
  %195 = lshr <8 x i16> %194, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %196 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %182, <8 x i16> %195) #5
  %197 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %196, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %198 = icmp slt <16 x i8> %197, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %199 = select <16 x i1> %198, <16 x i8> %197, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %200 = bitcast i8* %171 to <16 x i8>*
  store <16 x i8> %199, <16 x i8>* %200, align 16
  %201 = getelementptr inbounds i16, i16* %9, i64 96
  %202 = getelementptr inbounds i16, i16* %10, i64 96
  %203 = getelementptr inbounds i8, i8* %139, i64 %3
  %204 = add nsw i32 %11, -1
  %205 = icmp eq i32 %204, 0
  br i1 %205, label %206, label %7

206:                                              ; preds = %7
  %207 = bitcast i16* %201 to <8 x i16>*
  %208 = load <8 x i16>, <8 x i16>* %207, align 16
  %209 = bitcast i16* %202 to <8 x i16>*
  %210 = load <8 x i16>, <8 x i16>* %209, align 16
  %211 = sub <8 x i16> %208, %210
  %212 = sub <8 x i16> zeroinitializer, %211
  %213 = icmp slt <8 x i16> %211, zeroinitializer
  %214 = select <8 x i1> %213, <8 x i16> %212, <8 x i16> %211
  %215 = lshr <8 x i16> %214, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %216 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %215, <8 x i16> zeroinitializer) #5
  %217 = lshr <8 x i16> %216, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %218 = getelementptr inbounds i16, i16* %9, i64 104
  %219 = bitcast i16* %218 to <8 x i16>*
  %220 = load <8 x i16>, <8 x i16>* %219, align 16
  %221 = getelementptr inbounds i16, i16* %10, i64 104
  %222 = bitcast i16* %221 to <8 x i16>*
  %223 = load <8 x i16>, <8 x i16>* %222, align 16
  %224 = sub <8 x i16> %220, %223
  %225 = sub <8 x i16> zeroinitializer, %224
  %226 = icmp slt <8 x i16> %224, zeroinitializer
  %227 = select <8 x i1> %226, <8 x i16> %225, <8 x i16> %224
  %228 = lshr <8 x i16> %227, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %229 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %228, <8 x i16> zeroinitializer) #5
  %230 = lshr <8 x i16> %229, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %231 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %217, <8 x i16> %230) #5
  %232 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %231, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %233 = icmp slt <16 x i8> %232, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %234 = select <16 x i1> %233, <16 x i8> %232, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %235 = bitcast i8* %203 to <16 x i8>*
  store <16 x i8> %234, <16 x i8>* %235, align 16
  %236 = getelementptr inbounds i16, i16* %9, i64 112
  %237 = getelementptr inbounds i16, i16* %10, i64 112
  %238 = getelementptr inbounds i8, i8* %203, i64 16
  %239 = bitcast i16* %236 to <8 x i16>*
  %240 = load <8 x i16>, <8 x i16>* %239, align 16
  %241 = bitcast i16* %237 to <8 x i16>*
  %242 = load <8 x i16>, <8 x i16>* %241, align 16
  %243 = sub <8 x i16> %240, %242
  %244 = sub <8 x i16> zeroinitializer, %243
  %245 = icmp slt <8 x i16> %243, zeroinitializer
  %246 = select <8 x i1> %245, <8 x i16> %244, <8 x i16> %243
  %247 = lshr <8 x i16> %246, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %248 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %247, <8 x i16> zeroinitializer) #5
  %249 = lshr <8 x i16> %248, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %250 = getelementptr inbounds i16, i16* %9, i64 120
  %251 = bitcast i16* %250 to <8 x i16>*
  %252 = load <8 x i16>, <8 x i16>* %251, align 16
  %253 = getelementptr inbounds i16, i16* %10, i64 120
  %254 = bitcast i16* %253 to <8 x i16>*
  %255 = load <8 x i16>, <8 x i16>* %254, align 16
  %256 = sub <8 x i16> %252, %255
  %257 = sub <8 x i16> zeroinitializer, %256
  %258 = icmp slt <8 x i16> %256, zeroinitializer
  %259 = select <8 x i1> %258, <8 x i16> %257, <8 x i16> %256
  %260 = lshr <8 x i16> %259, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %261 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %260, <8 x i16> zeroinitializer) #5
  %262 = lshr <8 x i16> %261, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %263 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %249, <8 x i16> %262) #5
  %264 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %263, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %265 = icmp slt <16 x i8> %264, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %266 = select <16 x i1> %265, <16 x i8> %264, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %267 = bitcast i8* %238 to <16 x i8>*
  store <16 x i8> %266, <16 x i8>* %267, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask32x64_SSE4ILb1EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %209, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %207, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %208, %7 ]
  %11 = phi i32 [ 21, %4 ], [ %210, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = sub <8 x i16> %13, %15
  %17 = sub <8 x i16> zeroinitializer, %16
  %18 = icmp slt <8 x i16> %16, zeroinitializer
  %19 = select <8 x i1> %18, <8 x i16> %17, <8 x i16> %16
  %20 = lshr <8 x i16> %19, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %21 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %20, <8 x i16> zeroinitializer) #5
  %22 = lshr <8 x i16> %21, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %23 = getelementptr inbounds i16, i16* %9, i64 8
  %24 = bitcast i16* %23 to <8 x i16>*
  %25 = load <8 x i16>, <8 x i16>* %24, align 16
  %26 = getelementptr inbounds i16, i16* %10, i64 8
  %27 = bitcast i16* %26 to <8 x i16>*
  %28 = load <8 x i16>, <8 x i16>* %27, align 16
  %29 = sub <8 x i16> %25, %28
  %30 = sub <8 x i16> zeroinitializer, %29
  %31 = icmp slt <8 x i16> %29, zeroinitializer
  %32 = select <8 x i1> %31, <8 x i16> %30, <8 x i16> %29
  %33 = lshr <8 x i16> %32, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %34 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %33, <8 x i16> zeroinitializer) #5
  %35 = lshr <8 x i16> %34, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %36 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %22, <8 x i16> %35) #5
  %37 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %36, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %38 = icmp slt <16 x i8> %37, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %39 = select <16 x i1> %38, <16 x i8> %37, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %40 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %39
  %41 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %40, <16 x i8>* %41, align 16
  %42 = getelementptr inbounds i16, i16* %9, i64 16
  %43 = getelementptr inbounds i16, i16* %10, i64 16
  %44 = getelementptr inbounds i8, i8* %8, i64 16
  %45 = bitcast i16* %42 to <8 x i16>*
  %46 = load <8 x i16>, <8 x i16>* %45, align 16
  %47 = bitcast i16* %43 to <8 x i16>*
  %48 = load <8 x i16>, <8 x i16>* %47, align 16
  %49 = sub <8 x i16> %46, %48
  %50 = sub <8 x i16> zeroinitializer, %49
  %51 = icmp slt <8 x i16> %49, zeroinitializer
  %52 = select <8 x i1> %51, <8 x i16> %50, <8 x i16> %49
  %53 = lshr <8 x i16> %52, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %54 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %53, <8 x i16> zeroinitializer) #5
  %55 = lshr <8 x i16> %54, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %56 = getelementptr inbounds i16, i16* %9, i64 24
  %57 = bitcast i16* %56 to <8 x i16>*
  %58 = load <8 x i16>, <8 x i16>* %57, align 16
  %59 = getelementptr inbounds i16, i16* %10, i64 24
  %60 = bitcast i16* %59 to <8 x i16>*
  %61 = load <8 x i16>, <8 x i16>* %60, align 16
  %62 = sub <8 x i16> %58, %61
  %63 = sub <8 x i16> zeroinitializer, %62
  %64 = icmp slt <8 x i16> %62, zeroinitializer
  %65 = select <8 x i1> %64, <8 x i16> %63, <8 x i16> %62
  %66 = lshr <8 x i16> %65, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %67 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %66, <8 x i16> zeroinitializer) #5
  %68 = lshr <8 x i16> %67, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %69 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %55, <8 x i16> %68) #5
  %70 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %69, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %71 = icmp slt <16 x i8> %70, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %72 = select <16 x i1> %71, <16 x i8> %70, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %73 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %72
  %74 = bitcast i8* %44 to <16 x i8>*
  store <16 x i8> %73, <16 x i8>* %74, align 16
  %75 = getelementptr inbounds i16, i16* %9, i64 32
  %76 = getelementptr inbounds i16, i16* %10, i64 32
  %77 = getelementptr inbounds i8, i8* %8, i64 %3
  %78 = bitcast i16* %75 to <8 x i16>*
  %79 = load <8 x i16>, <8 x i16>* %78, align 16
  %80 = bitcast i16* %76 to <8 x i16>*
  %81 = load <8 x i16>, <8 x i16>* %80, align 16
  %82 = sub <8 x i16> %79, %81
  %83 = sub <8 x i16> zeroinitializer, %82
  %84 = icmp slt <8 x i16> %82, zeroinitializer
  %85 = select <8 x i1> %84, <8 x i16> %83, <8 x i16> %82
  %86 = lshr <8 x i16> %85, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %87 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %86, <8 x i16> zeroinitializer) #5
  %88 = lshr <8 x i16> %87, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %89 = getelementptr inbounds i16, i16* %9, i64 40
  %90 = bitcast i16* %89 to <8 x i16>*
  %91 = load <8 x i16>, <8 x i16>* %90, align 16
  %92 = getelementptr inbounds i16, i16* %10, i64 40
  %93 = bitcast i16* %92 to <8 x i16>*
  %94 = load <8 x i16>, <8 x i16>* %93, align 16
  %95 = sub <8 x i16> %91, %94
  %96 = sub <8 x i16> zeroinitializer, %95
  %97 = icmp slt <8 x i16> %95, zeroinitializer
  %98 = select <8 x i1> %97, <8 x i16> %96, <8 x i16> %95
  %99 = lshr <8 x i16> %98, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %100 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %99, <8 x i16> zeroinitializer) #5
  %101 = lshr <8 x i16> %100, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %102 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %88, <8 x i16> %101) #5
  %103 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %102, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %104 = icmp slt <16 x i8> %103, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %105 = select <16 x i1> %104, <16 x i8> %103, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %106 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %105
  %107 = bitcast i8* %77 to <16 x i8>*
  store <16 x i8> %106, <16 x i8>* %107, align 16
  %108 = getelementptr inbounds i16, i16* %9, i64 48
  %109 = getelementptr inbounds i16, i16* %10, i64 48
  %110 = getelementptr inbounds i8, i8* %77, i64 16
  %111 = bitcast i16* %108 to <8 x i16>*
  %112 = load <8 x i16>, <8 x i16>* %111, align 16
  %113 = bitcast i16* %109 to <8 x i16>*
  %114 = load <8 x i16>, <8 x i16>* %113, align 16
  %115 = sub <8 x i16> %112, %114
  %116 = sub <8 x i16> zeroinitializer, %115
  %117 = icmp slt <8 x i16> %115, zeroinitializer
  %118 = select <8 x i1> %117, <8 x i16> %116, <8 x i16> %115
  %119 = lshr <8 x i16> %118, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %120 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %119, <8 x i16> zeroinitializer) #5
  %121 = lshr <8 x i16> %120, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %122 = getelementptr inbounds i16, i16* %9, i64 56
  %123 = bitcast i16* %122 to <8 x i16>*
  %124 = load <8 x i16>, <8 x i16>* %123, align 16
  %125 = getelementptr inbounds i16, i16* %10, i64 56
  %126 = bitcast i16* %125 to <8 x i16>*
  %127 = load <8 x i16>, <8 x i16>* %126, align 16
  %128 = sub <8 x i16> %124, %127
  %129 = sub <8 x i16> zeroinitializer, %128
  %130 = icmp slt <8 x i16> %128, zeroinitializer
  %131 = select <8 x i1> %130, <8 x i16> %129, <8 x i16> %128
  %132 = lshr <8 x i16> %131, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %133 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %132, <8 x i16> zeroinitializer) #5
  %134 = lshr <8 x i16> %133, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %135 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %121, <8 x i16> %134) #5
  %136 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %135, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %137 = icmp slt <16 x i8> %136, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %138 = select <16 x i1> %137, <16 x i8> %136, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %139 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %138
  %140 = bitcast i8* %110 to <16 x i8>*
  store <16 x i8> %139, <16 x i8>* %140, align 16
  %141 = getelementptr inbounds i16, i16* %9, i64 64
  %142 = getelementptr inbounds i16, i16* %10, i64 64
  %143 = getelementptr inbounds i8, i8* %77, i64 %3
  %144 = bitcast i16* %141 to <8 x i16>*
  %145 = load <8 x i16>, <8 x i16>* %144, align 16
  %146 = bitcast i16* %142 to <8 x i16>*
  %147 = load <8 x i16>, <8 x i16>* %146, align 16
  %148 = sub <8 x i16> %145, %147
  %149 = sub <8 x i16> zeroinitializer, %148
  %150 = icmp slt <8 x i16> %148, zeroinitializer
  %151 = select <8 x i1> %150, <8 x i16> %149, <8 x i16> %148
  %152 = lshr <8 x i16> %151, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %153 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %152, <8 x i16> zeroinitializer) #5
  %154 = lshr <8 x i16> %153, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %155 = getelementptr inbounds i16, i16* %9, i64 72
  %156 = bitcast i16* %155 to <8 x i16>*
  %157 = load <8 x i16>, <8 x i16>* %156, align 16
  %158 = getelementptr inbounds i16, i16* %10, i64 72
  %159 = bitcast i16* %158 to <8 x i16>*
  %160 = load <8 x i16>, <8 x i16>* %159, align 16
  %161 = sub <8 x i16> %157, %160
  %162 = sub <8 x i16> zeroinitializer, %161
  %163 = icmp slt <8 x i16> %161, zeroinitializer
  %164 = select <8 x i1> %163, <8 x i16> %162, <8 x i16> %161
  %165 = lshr <8 x i16> %164, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %166 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %165, <8 x i16> zeroinitializer) #5
  %167 = lshr <8 x i16> %166, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %168 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %154, <8 x i16> %167) #5
  %169 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %168, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %170 = icmp slt <16 x i8> %169, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %171 = select <16 x i1> %170, <16 x i8> %169, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %172 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %171
  %173 = bitcast i8* %143 to <16 x i8>*
  store <16 x i8> %172, <16 x i8>* %173, align 16
  %174 = getelementptr inbounds i16, i16* %9, i64 80
  %175 = getelementptr inbounds i16, i16* %10, i64 80
  %176 = getelementptr inbounds i8, i8* %143, i64 16
  %177 = bitcast i16* %174 to <8 x i16>*
  %178 = load <8 x i16>, <8 x i16>* %177, align 16
  %179 = bitcast i16* %175 to <8 x i16>*
  %180 = load <8 x i16>, <8 x i16>* %179, align 16
  %181 = sub <8 x i16> %178, %180
  %182 = sub <8 x i16> zeroinitializer, %181
  %183 = icmp slt <8 x i16> %181, zeroinitializer
  %184 = select <8 x i1> %183, <8 x i16> %182, <8 x i16> %181
  %185 = lshr <8 x i16> %184, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %186 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %185, <8 x i16> zeroinitializer) #5
  %187 = lshr <8 x i16> %186, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %188 = getelementptr inbounds i16, i16* %9, i64 88
  %189 = bitcast i16* %188 to <8 x i16>*
  %190 = load <8 x i16>, <8 x i16>* %189, align 16
  %191 = getelementptr inbounds i16, i16* %10, i64 88
  %192 = bitcast i16* %191 to <8 x i16>*
  %193 = load <8 x i16>, <8 x i16>* %192, align 16
  %194 = sub <8 x i16> %190, %193
  %195 = sub <8 x i16> zeroinitializer, %194
  %196 = icmp slt <8 x i16> %194, zeroinitializer
  %197 = select <8 x i1> %196, <8 x i16> %195, <8 x i16> %194
  %198 = lshr <8 x i16> %197, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %199 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %198, <8 x i16> zeroinitializer) #5
  %200 = lshr <8 x i16> %199, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %201 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %187, <8 x i16> %200) #5
  %202 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %201, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %203 = icmp slt <16 x i8> %202, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %204 = select <16 x i1> %203, <16 x i8> %202, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %205 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %204
  %206 = bitcast i8* %176 to <16 x i8>*
  store <16 x i8> %205, <16 x i8>* %206, align 16
  %207 = getelementptr inbounds i16, i16* %9, i64 96
  %208 = getelementptr inbounds i16, i16* %10, i64 96
  %209 = getelementptr inbounds i8, i8* %143, i64 %3
  %210 = add nsw i32 %11, -1
  %211 = icmp eq i32 %210, 0
  br i1 %211, label %212, label %7

212:                                              ; preds = %7
  %213 = bitcast i16* %207 to <8 x i16>*
  %214 = load <8 x i16>, <8 x i16>* %213, align 16
  %215 = bitcast i16* %208 to <8 x i16>*
  %216 = load <8 x i16>, <8 x i16>* %215, align 16
  %217 = sub <8 x i16> %214, %216
  %218 = sub <8 x i16> zeroinitializer, %217
  %219 = icmp slt <8 x i16> %217, zeroinitializer
  %220 = select <8 x i1> %219, <8 x i16> %218, <8 x i16> %217
  %221 = lshr <8 x i16> %220, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %222 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %221, <8 x i16> zeroinitializer) #5
  %223 = lshr <8 x i16> %222, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %224 = getelementptr inbounds i16, i16* %9, i64 104
  %225 = bitcast i16* %224 to <8 x i16>*
  %226 = load <8 x i16>, <8 x i16>* %225, align 16
  %227 = getelementptr inbounds i16, i16* %10, i64 104
  %228 = bitcast i16* %227 to <8 x i16>*
  %229 = load <8 x i16>, <8 x i16>* %228, align 16
  %230 = sub <8 x i16> %226, %229
  %231 = sub <8 x i16> zeroinitializer, %230
  %232 = icmp slt <8 x i16> %230, zeroinitializer
  %233 = select <8 x i1> %232, <8 x i16> %231, <8 x i16> %230
  %234 = lshr <8 x i16> %233, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %235 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %234, <8 x i16> zeroinitializer) #5
  %236 = lshr <8 x i16> %235, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %237 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %223, <8 x i16> %236) #5
  %238 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %237, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %239 = icmp slt <16 x i8> %238, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %240 = select <16 x i1> %239, <16 x i8> %238, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %241 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %240
  %242 = bitcast i8* %209 to <16 x i8>*
  store <16 x i8> %241, <16 x i8>* %242, align 16
  %243 = getelementptr inbounds i16, i16* %9, i64 112
  %244 = getelementptr inbounds i16, i16* %10, i64 112
  %245 = getelementptr inbounds i8, i8* %209, i64 16
  %246 = bitcast i16* %243 to <8 x i16>*
  %247 = load <8 x i16>, <8 x i16>* %246, align 16
  %248 = bitcast i16* %244 to <8 x i16>*
  %249 = load <8 x i16>, <8 x i16>* %248, align 16
  %250 = sub <8 x i16> %247, %249
  %251 = sub <8 x i16> zeroinitializer, %250
  %252 = icmp slt <8 x i16> %250, zeroinitializer
  %253 = select <8 x i1> %252, <8 x i16> %251, <8 x i16> %250
  %254 = lshr <8 x i16> %253, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %255 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %254, <8 x i16> zeroinitializer) #5
  %256 = lshr <8 x i16> %255, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %257 = getelementptr inbounds i16, i16* %9, i64 120
  %258 = bitcast i16* %257 to <8 x i16>*
  %259 = load <8 x i16>, <8 x i16>* %258, align 16
  %260 = getelementptr inbounds i16, i16* %10, i64 120
  %261 = bitcast i16* %260 to <8 x i16>*
  %262 = load <8 x i16>, <8 x i16>* %261, align 16
  %263 = sub <8 x i16> %259, %262
  %264 = sub <8 x i16> zeroinitializer, %263
  %265 = icmp slt <8 x i16> %263, zeroinitializer
  %266 = select <8 x i1> %265, <8 x i16> %264, <8 x i16> %263
  %267 = lshr <8 x i16> %266, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %268 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %267, <8 x i16> zeroinitializer) #5
  %269 = lshr <8 x i16> %268, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %270 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %256, <8 x i16> %269) #5
  %271 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %270, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %272 = icmp slt <16 x i8> %271, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %273 = select <16 x i1> %272, <16 x i8> %271, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %274 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %273
  %275 = bitcast i8* %245 to <16 x i8>*
  store <16 x i8> %274, <16 x i8>* %275, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask64x16_SSE4ILb0EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %395, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %393, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %394, %7 ]
  %11 = phi i32 [ 0, %4 ], [ %396, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = sub <8 x i16> %13, %15
  %17 = sub <8 x i16> zeroinitializer, %16
  %18 = icmp slt <8 x i16> %16, zeroinitializer
  %19 = select <8 x i1> %18, <8 x i16> %17, <8 x i16> %16
  %20 = lshr <8 x i16> %19, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %21 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %20, <8 x i16> zeroinitializer) #5
  %22 = lshr <8 x i16> %21, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %23 = getelementptr inbounds i16, i16* %9, i64 8
  %24 = bitcast i16* %23 to <8 x i16>*
  %25 = load <8 x i16>, <8 x i16>* %24, align 16
  %26 = getelementptr inbounds i16, i16* %10, i64 8
  %27 = bitcast i16* %26 to <8 x i16>*
  %28 = load <8 x i16>, <8 x i16>* %27, align 16
  %29 = sub <8 x i16> %25, %28
  %30 = sub <8 x i16> zeroinitializer, %29
  %31 = icmp slt <8 x i16> %29, zeroinitializer
  %32 = select <8 x i1> %31, <8 x i16> %30, <8 x i16> %29
  %33 = lshr <8 x i16> %32, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %34 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %33, <8 x i16> zeroinitializer) #5
  %35 = lshr <8 x i16> %34, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %36 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %22, <8 x i16> %35) #5
  %37 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %36, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %38 = icmp slt <16 x i8> %37, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %39 = select <16 x i1> %38, <16 x i8> %37, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %40 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %40, align 16
  %41 = getelementptr inbounds i16, i16* %9, i64 16
  %42 = getelementptr inbounds i16, i16* %10, i64 16
  %43 = getelementptr inbounds i8, i8* %8, i64 16
  %44 = bitcast i16* %41 to <8 x i16>*
  %45 = load <8 x i16>, <8 x i16>* %44, align 16
  %46 = bitcast i16* %42 to <8 x i16>*
  %47 = load <8 x i16>, <8 x i16>* %46, align 16
  %48 = sub <8 x i16> %45, %47
  %49 = sub <8 x i16> zeroinitializer, %48
  %50 = icmp slt <8 x i16> %48, zeroinitializer
  %51 = select <8 x i1> %50, <8 x i16> %49, <8 x i16> %48
  %52 = lshr <8 x i16> %51, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %53 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %52, <8 x i16> zeroinitializer) #5
  %54 = lshr <8 x i16> %53, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %55 = getelementptr inbounds i16, i16* %9, i64 24
  %56 = bitcast i16* %55 to <8 x i16>*
  %57 = load <8 x i16>, <8 x i16>* %56, align 16
  %58 = getelementptr inbounds i16, i16* %10, i64 24
  %59 = bitcast i16* %58 to <8 x i16>*
  %60 = load <8 x i16>, <8 x i16>* %59, align 16
  %61 = sub <8 x i16> %57, %60
  %62 = sub <8 x i16> zeroinitializer, %61
  %63 = icmp slt <8 x i16> %61, zeroinitializer
  %64 = select <8 x i1> %63, <8 x i16> %62, <8 x i16> %61
  %65 = lshr <8 x i16> %64, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %66 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %65, <8 x i16> zeroinitializer) #5
  %67 = lshr <8 x i16> %66, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %68 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %54, <8 x i16> %67) #5
  %69 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %68, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %70 = icmp slt <16 x i8> %69, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %71 = select <16 x i1> %70, <16 x i8> %69, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %72 = bitcast i8* %43 to <16 x i8>*
  store <16 x i8> %71, <16 x i8>* %72, align 16
  %73 = getelementptr inbounds i16, i16* %9, i64 32
  %74 = getelementptr inbounds i16, i16* %10, i64 32
  %75 = getelementptr inbounds i8, i8* %8, i64 32
  %76 = bitcast i16* %73 to <8 x i16>*
  %77 = load <8 x i16>, <8 x i16>* %76, align 16
  %78 = bitcast i16* %74 to <8 x i16>*
  %79 = load <8 x i16>, <8 x i16>* %78, align 16
  %80 = sub <8 x i16> %77, %79
  %81 = sub <8 x i16> zeroinitializer, %80
  %82 = icmp slt <8 x i16> %80, zeroinitializer
  %83 = select <8 x i1> %82, <8 x i16> %81, <8 x i16> %80
  %84 = lshr <8 x i16> %83, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %85 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %84, <8 x i16> zeroinitializer) #5
  %86 = lshr <8 x i16> %85, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %87 = getelementptr inbounds i16, i16* %9, i64 40
  %88 = bitcast i16* %87 to <8 x i16>*
  %89 = load <8 x i16>, <8 x i16>* %88, align 16
  %90 = getelementptr inbounds i16, i16* %10, i64 40
  %91 = bitcast i16* %90 to <8 x i16>*
  %92 = load <8 x i16>, <8 x i16>* %91, align 16
  %93 = sub <8 x i16> %89, %92
  %94 = sub <8 x i16> zeroinitializer, %93
  %95 = icmp slt <8 x i16> %93, zeroinitializer
  %96 = select <8 x i1> %95, <8 x i16> %94, <8 x i16> %93
  %97 = lshr <8 x i16> %96, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %98 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %97, <8 x i16> zeroinitializer) #5
  %99 = lshr <8 x i16> %98, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %100 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %86, <8 x i16> %99) #5
  %101 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %100, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %102 = icmp slt <16 x i8> %101, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %103 = select <16 x i1> %102, <16 x i8> %101, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %104 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %103, <16 x i8>* %104, align 16
  %105 = getelementptr inbounds i16, i16* %9, i64 48
  %106 = getelementptr inbounds i16, i16* %10, i64 48
  %107 = getelementptr inbounds i8, i8* %8, i64 48
  %108 = bitcast i16* %105 to <8 x i16>*
  %109 = load <8 x i16>, <8 x i16>* %108, align 16
  %110 = bitcast i16* %106 to <8 x i16>*
  %111 = load <8 x i16>, <8 x i16>* %110, align 16
  %112 = sub <8 x i16> %109, %111
  %113 = sub <8 x i16> zeroinitializer, %112
  %114 = icmp slt <8 x i16> %112, zeroinitializer
  %115 = select <8 x i1> %114, <8 x i16> %113, <8 x i16> %112
  %116 = lshr <8 x i16> %115, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %117 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %116, <8 x i16> zeroinitializer) #5
  %118 = lshr <8 x i16> %117, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %119 = getelementptr inbounds i16, i16* %9, i64 56
  %120 = bitcast i16* %119 to <8 x i16>*
  %121 = load <8 x i16>, <8 x i16>* %120, align 16
  %122 = getelementptr inbounds i16, i16* %10, i64 56
  %123 = bitcast i16* %122 to <8 x i16>*
  %124 = load <8 x i16>, <8 x i16>* %123, align 16
  %125 = sub <8 x i16> %121, %124
  %126 = sub <8 x i16> zeroinitializer, %125
  %127 = icmp slt <8 x i16> %125, zeroinitializer
  %128 = select <8 x i1> %127, <8 x i16> %126, <8 x i16> %125
  %129 = lshr <8 x i16> %128, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %130 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %129, <8 x i16> zeroinitializer) #5
  %131 = lshr <8 x i16> %130, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %132 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %118, <8 x i16> %131) #5
  %133 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %132, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %134 = icmp slt <16 x i8> %133, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %135 = select <16 x i1> %134, <16 x i8> %133, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %136 = bitcast i8* %107 to <16 x i8>*
  store <16 x i8> %135, <16 x i8>* %136, align 16
  %137 = getelementptr inbounds i16, i16* %9, i64 64
  %138 = getelementptr inbounds i16, i16* %10, i64 64
  %139 = getelementptr inbounds i8, i8* %8, i64 %3
  %140 = bitcast i16* %137 to <8 x i16>*
  %141 = load <8 x i16>, <8 x i16>* %140, align 16
  %142 = bitcast i16* %138 to <8 x i16>*
  %143 = load <8 x i16>, <8 x i16>* %142, align 16
  %144 = sub <8 x i16> %141, %143
  %145 = sub <8 x i16> zeroinitializer, %144
  %146 = icmp slt <8 x i16> %144, zeroinitializer
  %147 = select <8 x i1> %146, <8 x i16> %145, <8 x i16> %144
  %148 = lshr <8 x i16> %147, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %149 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %148, <8 x i16> zeroinitializer) #5
  %150 = lshr <8 x i16> %149, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %151 = getelementptr inbounds i16, i16* %9, i64 72
  %152 = bitcast i16* %151 to <8 x i16>*
  %153 = load <8 x i16>, <8 x i16>* %152, align 16
  %154 = getelementptr inbounds i16, i16* %10, i64 72
  %155 = bitcast i16* %154 to <8 x i16>*
  %156 = load <8 x i16>, <8 x i16>* %155, align 16
  %157 = sub <8 x i16> %153, %156
  %158 = sub <8 x i16> zeroinitializer, %157
  %159 = icmp slt <8 x i16> %157, zeroinitializer
  %160 = select <8 x i1> %159, <8 x i16> %158, <8 x i16> %157
  %161 = lshr <8 x i16> %160, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %162 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %161, <8 x i16> zeroinitializer) #5
  %163 = lshr <8 x i16> %162, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %164 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %150, <8 x i16> %163) #5
  %165 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %164, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %166 = icmp slt <16 x i8> %165, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %167 = select <16 x i1> %166, <16 x i8> %165, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %168 = bitcast i8* %139 to <16 x i8>*
  store <16 x i8> %167, <16 x i8>* %168, align 16
  %169 = getelementptr inbounds i16, i16* %9, i64 80
  %170 = getelementptr inbounds i16, i16* %10, i64 80
  %171 = getelementptr inbounds i8, i8* %139, i64 16
  %172 = bitcast i16* %169 to <8 x i16>*
  %173 = load <8 x i16>, <8 x i16>* %172, align 16
  %174 = bitcast i16* %170 to <8 x i16>*
  %175 = load <8 x i16>, <8 x i16>* %174, align 16
  %176 = sub <8 x i16> %173, %175
  %177 = sub <8 x i16> zeroinitializer, %176
  %178 = icmp slt <8 x i16> %176, zeroinitializer
  %179 = select <8 x i1> %178, <8 x i16> %177, <8 x i16> %176
  %180 = lshr <8 x i16> %179, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %181 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %180, <8 x i16> zeroinitializer) #5
  %182 = lshr <8 x i16> %181, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %183 = getelementptr inbounds i16, i16* %9, i64 88
  %184 = bitcast i16* %183 to <8 x i16>*
  %185 = load <8 x i16>, <8 x i16>* %184, align 16
  %186 = getelementptr inbounds i16, i16* %10, i64 88
  %187 = bitcast i16* %186 to <8 x i16>*
  %188 = load <8 x i16>, <8 x i16>* %187, align 16
  %189 = sub <8 x i16> %185, %188
  %190 = sub <8 x i16> zeroinitializer, %189
  %191 = icmp slt <8 x i16> %189, zeroinitializer
  %192 = select <8 x i1> %191, <8 x i16> %190, <8 x i16> %189
  %193 = lshr <8 x i16> %192, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %194 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %193, <8 x i16> zeroinitializer) #5
  %195 = lshr <8 x i16> %194, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %196 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %182, <8 x i16> %195) #5
  %197 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %196, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %198 = icmp slt <16 x i8> %197, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %199 = select <16 x i1> %198, <16 x i8> %197, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %200 = bitcast i8* %171 to <16 x i8>*
  store <16 x i8> %199, <16 x i8>* %200, align 16
  %201 = getelementptr inbounds i16, i16* %9, i64 96
  %202 = getelementptr inbounds i16, i16* %10, i64 96
  %203 = getelementptr inbounds i8, i8* %139, i64 32
  %204 = bitcast i16* %201 to <8 x i16>*
  %205 = load <8 x i16>, <8 x i16>* %204, align 16
  %206 = bitcast i16* %202 to <8 x i16>*
  %207 = load <8 x i16>, <8 x i16>* %206, align 16
  %208 = sub <8 x i16> %205, %207
  %209 = sub <8 x i16> zeroinitializer, %208
  %210 = icmp slt <8 x i16> %208, zeroinitializer
  %211 = select <8 x i1> %210, <8 x i16> %209, <8 x i16> %208
  %212 = lshr <8 x i16> %211, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %213 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %212, <8 x i16> zeroinitializer) #5
  %214 = lshr <8 x i16> %213, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %215 = getelementptr inbounds i16, i16* %9, i64 104
  %216 = bitcast i16* %215 to <8 x i16>*
  %217 = load <8 x i16>, <8 x i16>* %216, align 16
  %218 = getelementptr inbounds i16, i16* %10, i64 104
  %219 = bitcast i16* %218 to <8 x i16>*
  %220 = load <8 x i16>, <8 x i16>* %219, align 16
  %221 = sub <8 x i16> %217, %220
  %222 = sub <8 x i16> zeroinitializer, %221
  %223 = icmp slt <8 x i16> %221, zeroinitializer
  %224 = select <8 x i1> %223, <8 x i16> %222, <8 x i16> %221
  %225 = lshr <8 x i16> %224, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %226 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %225, <8 x i16> zeroinitializer) #5
  %227 = lshr <8 x i16> %226, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %228 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %214, <8 x i16> %227) #5
  %229 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %228, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %230 = icmp slt <16 x i8> %229, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %231 = select <16 x i1> %230, <16 x i8> %229, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %232 = bitcast i8* %203 to <16 x i8>*
  store <16 x i8> %231, <16 x i8>* %232, align 16
  %233 = getelementptr inbounds i16, i16* %9, i64 112
  %234 = getelementptr inbounds i16, i16* %10, i64 112
  %235 = getelementptr inbounds i8, i8* %139, i64 48
  %236 = bitcast i16* %233 to <8 x i16>*
  %237 = load <8 x i16>, <8 x i16>* %236, align 16
  %238 = bitcast i16* %234 to <8 x i16>*
  %239 = load <8 x i16>, <8 x i16>* %238, align 16
  %240 = sub <8 x i16> %237, %239
  %241 = sub <8 x i16> zeroinitializer, %240
  %242 = icmp slt <8 x i16> %240, zeroinitializer
  %243 = select <8 x i1> %242, <8 x i16> %241, <8 x i16> %240
  %244 = lshr <8 x i16> %243, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %245 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %244, <8 x i16> zeroinitializer) #5
  %246 = lshr <8 x i16> %245, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %247 = getelementptr inbounds i16, i16* %9, i64 120
  %248 = bitcast i16* %247 to <8 x i16>*
  %249 = load <8 x i16>, <8 x i16>* %248, align 16
  %250 = getelementptr inbounds i16, i16* %10, i64 120
  %251 = bitcast i16* %250 to <8 x i16>*
  %252 = load <8 x i16>, <8 x i16>* %251, align 16
  %253 = sub <8 x i16> %249, %252
  %254 = sub <8 x i16> zeroinitializer, %253
  %255 = icmp slt <8 x i16> %253, zeroinitializer
  %256 = select <8 x i1> %255, <8 x i16> %254, <8 x i16> %253
  %257 = lshr <8 x i16> %256, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %258 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %257, <8 x i16> zeroinitializer) #5
  %259 = lshr <8 x i16> %258, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %260 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %246, <8 x i16> %259) #5
  %261 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %260, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %262 = icmp slt <16 x i8> %261, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %263 = select <16 x i1> %262, <16 x i8> %261, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %264 = bitcast i8* %235 to <16 x i8>*
  store <16 x i8> %263, <16 x i8>* %264, align 16
  %265 = getelementptr inbounds i16, i16* %9, i64 128
  %266 = getelementptr inbounds i16, i16* %10, i64 128
  %267 = getelementptr inbounds i8, i8* %139, i64 %3
  %268 = bitcast i16* %265 to <8 x i16>*
  %269 = load <8 x i16>, <8 x i16>* %268, align 16
  %270 = bitcast i16* %266 to <8 x i16>*
  %271 = load <8 x i16>, <8 x i16>* %270, align 16
  %272 = sub <8 x i16> %269, %271
  %273 = sub <8 x i16> zeroinitializer, %272
  %274 = icmp slt <8 x i16> %272, zeroinitializer
  %275 = select <8 x i1> %274, <8 x i16> %273, <8 x i16> %272
  %276 = lshr <8 x i16> %275, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %277 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %276, <8 x i16> zeroinitializer) #5
  %278 = lshr <8 x i16> %277, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %279 = getelementptr inbounds i16, i16* %9, i64 136
  %280 = bitcast i16* %279 to <8 x i16>*
  %281 = load <8 x i16>, <8 x i16>* %280, align 16
  %282 = getelementptr inbounds i16, i16* %10, i64 136
  %283 = bitcast i16* %282 to <8 x i16>*
  %284 = load <8 x i16>, <8 x i16>* %283, align 16
  %285 = sub <8 x i16> %281, %284
  %286 = sub <8 x i16> zeroinitializer, %285
  %287 = icmp slt <8 x i16> %285, zeroinitializer
  %288 = select <8 x i1> %287, <8 x i16> %286, <8 x i16> %285
  %289 = lshr <8 x i16> %288, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %290 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %289, <8 x i16> zeroinitializer) #5
  %291 = lshr <8 x i16> %290, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %292 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %278, <8 x i16> %291) #5
  %293 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %292, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %294 = icmp slt <16 x i8> %293, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %295 = select <16 x i1> %294, <16 x i8> %293, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %296 = bitcast i8* %267 to <16 x i8>*
  store <16 x i8> %295, <16 x i8>* %296, align 16
  %297 = getelementptr inbounds i16, i16* %9, i64 144
  %298 = getelementptr inbounds i16, i16* %10, i64 144
  %299 = getelementptr inbounds i8, i8* %267, i64 16
  %300 = bitcast i16* %297 to <8 x i16>*
  %301 = load <8 x i16>, <8 x i16>* %300, align 16
  %302 = bitcast i16* %298 to <8 x i16>*
  %303 = load <8 x i16>, <8 x i16>* %302, align 16
  %304 = sub <8 x i16> %301, %303
  %305 = sub <8 x i16> zeroinitializer, %304
  %306 = icmp slt <8 x i16> %304, zeroinitializer
  %307 = select <8 x i1> %306, <8 x i16> %305, <8 x i16> %304
  %308 = lshr <8 x i16> %307, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %309 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %308, <8 x i16> zeroinitializer) #5
  %310 = lshr <8 x i16> %309, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %311 = getelementptr inbounds i16, i16* %9, i64 152
  %312 = bitcast i16* %311 to <8 x i16>*
  %313 = load <8 x i16>, <8 x i16>* %312, align 16
  %314 = getelementptr inbounds i16, i16* %10, i64 152
  %315 = bitcast i16* %314 to <8 x i16>*
  %316 = load <8 x i16>, <8 x i16>* %315, align 16
  %317 = sub <8 x i16> %313, %316
  %318 = sub <8 x i16> zeroinitializer, %317
  %319 = icmp slt <8 x i16> %317, zeroinitializer
  %320 = select <8 x i1> %319, <8 x i16> %318, <8 x i16> %317
  %321 = lshr <8 x i16> %320, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %322 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %321, <8 x i16> zeroinitializer) #5
  %323 = lshr <8 x i16> %322, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %324 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %310, <8 x i16> %323) #5
  %325 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %324, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %326 = icmp slt <16 x i8> %325, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %327 = select <16 x i1> %326, <16 x i8> %325, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %328 = bitcast i8* %299 to <16 x i8>*
  store <16 x i8> %327, <16 x i8>* %328, align 16
  %329 = getelementptr inbounds i16, i16* %9, i64 160
  %330 = getelementptr inbounds i16, i16* %10, i64 160
  %331 = getelementptr inbounds i8, i8* %267, i64 32
  %332 = bitcast i16* %329 to <8 x i16>*
  %333 = load <8 x i16>, <8 x i16>* %332, align 16
  %334 = bitcast i16* %330 to <8 x i16>*
  %335 = load <8 x i16>, <8 x i16>* %334, align 16
  %336 = sub <8 x i16> %333, %335
  %337 = sub <8 x i16> zeroinitializer, %336
  %338 = icmp slt <8 x i16> %336, zeroinitializer
  %339 = select <8 x i1> %338, <8 x i16> %337, <8 x i16> %336
  %340 = lshr <8 x i16> %339, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %341 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %340, <8 x i16> zeroinitializer) #5
  %342 = lshr <8 x i16> %341, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %343 = getelementptr inbounds i16, i16* %9, i64 168
  %344 = bitcast i16* %343 to <8 x i16>*
  %345 = load <8 x i16>, <8 x i16>* %344, align 16
  %346 = getelementptr inbounds i16, i16* %10, i64 168
  %347 = bitcast i16* %346 to <8 x i16>*
  %348 = load <8 x i16>, <8 x i16>* %347, align 16
  %349 = sub <8 x i16> %345, %348
  %350 = sub <8 x i16> zeroinitializer, %349
  %351 = icmp slt <8 x i16> %349, zeroinitializer
  %352 = select <8 x i1> %351, <8 x i16> %350, <8 x i16> %349
  %353 = lshr <8 x i16> %352, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %354 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %353, <8 x i16> zeroinitializer) #5
  %355 = lshr <8 x i16> %354, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %356 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %342, <8 x i16> %355) #5
  %357 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %356, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %358 = icmp slt <16 x i8> %357, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %359 = select <16 x i1> %358, <16 x i8> %357, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %360 = bitcast i8* %331 to <16 x i8>*
  store <16 x i8> %359, <16 x i8>* %360, align 16
  %361 = getelementptr inbounds i16, i16* %9, i64 176
  %362 = getelementptr inbounds i16, i16* %10, i64 176
  %363 = getelementptr inbounds i8, i8* %267, i64 48
  %364 = bitcast i16* %361 to <8 x i16>*
  %365 = load <8 x i16>, <8 x i16>* %364, align 16
  %366 = bitcast i16* %362 to <8 x i16>*
  %367 = load <8 x i16>, <8 x i16>* %366, align 16
  %368 = sub <8 x i16> %365, %367
  %369 = sub <8 x i16> zeroinitializer, %368
  %370 = icmp slt <8 x i16> %368, zeroinitializer
  %371 = select <8 x i1> %370, <8 x i16> %369, <8 x i16> %368
  %372 = lshr <8 x i16> %371, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %373 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %372, <8 x i16> zeroinitializer) #5
  %374 = lshr <8 x i16> %373, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %375 = getelementptr inbounds i16, i16* %9, i64 184
  %376 = bitcast i16* %375 to <8 x i16>*
  %377 = load <8 x i16>, <8 x i16>* %376, align 16
  %378 = getelementptr inbounds i16, i16* %10, i64 184
  %379 = bitcast i16* %378 to <8 x i16>*
  %380 = load <8 x i16>, <8 x i16>* %379, align 16
  %381 = sub <8 x i16> %377, %380
  %382 = sub <8 x i16> zeroinitializer, %381
  %383 = icmp slt <8 x i16> %381, zeroinitializer
  %384 = select <8 x i1> %383, <8 x i16> %382, <8 x i16> %381
  %385 = lshr <8 x i16> %384, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %386 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %385, <8 x i16> zeroinitializer) #5
  %387 = lshr <8 x i16> %386, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %388 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %374, <8 x i16> %387) #5
  %389 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %388, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %390 = icmp slt <16 x i8> %389, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %391 = select <16 x i1> %390, <16 x i8> %389, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %392 = bitcast i8* %363 to <16 x i8>*
  store <16 x i8> %391, <16 x i8>* %392, align 16
  %393 = getelementptr inbounds i16, i16* %9, i64 192
  %394 = getelementptr inbounds i16, i16* %10, i64 192
  %395 = getelementptr inbounds i8, i8* %267, i64 %3
  %396 = add nuw nsw i32 %11, 1
  %397 = icmp eq i32 %396, 5
  br i1 %397, label %398, label %7

398:                                              ; preds = %7
  %399 = bitcast i16* %393 to <8 x i16>*
  %400 = load <8 x i16>, <8 x i16>* %399, align 16
  %401 = bitcast i16* %394 to <8 x i16>*
  %402 = load <8 x i16>, <8 x i16>* %401, align 16
  %403 = sub <8 x i16> %400, %402
  %404 = sub <8 x i16> zeroinitializer, %403
  %405 = icmp slt <8 x i16> %403, zeroinitializer
  %406 = select <8 x i1> %405, <8 x i16> %404, <8 x i16> %403
  %407 = lshr <8 x i16> %406, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %408 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %407, <8 x i16> zeroinitializer) #5
  %409 = lshr <8 x i16> %408, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %410 = getelementptr inbounds i16, i16* %9, i64 200
  %411 = bitcast i16* %410 to <8 x i16>*
  %412 = load <8 x i16>, <8 x i16>* %411, align 16
  %413 = getelementptr inbounds i16, i16* %10, i64 200
  %414 = bitcast i16* %413 to <8 x i16>*
  %415 = load <8 x i16>, <8 x i16>* %414, align 16
  %416 = sub <8 x i16> %412, %415
  %417 = sub <8 x i16> zeroinitializer, %416
  %418 = icmp slt <8 x i16> %416, zeroinitializer
  %419 = select <8 x i1> %418, <8 x i16> %417, <8 x i16> %416
  %420 = lshr <8 x i16> %419, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %421 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %420, <8 x i16> zeroinitializer) #5
  %422 = lshr <8 x i16> %421, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %423 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %409, <8 x i16> %422) #5
  %424 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %423, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %425 = icmp slt <16 x i8> %424, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %426 = select <16 x i1> %425, <16 x i8> %424, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %427 = bitcast i8* %395 to <16 x i8>*
  store <16 x i8> %426, <16 x i8>* %427, align 16
  %428 = getelementptr inbounds i16, i16* %9, i64 208
  %429 = getelementptr inbounds i16, i16* %10, i64 208
  %430 = getelementptr inbounds i8, i8* %395, i64 16
  %431 = bitcast i16* %428 to <8 x i16>*
  %432 = load <8 x i16>, <8 x i16>* %431, align 16
  %433 = bitcast i16* %429 to <8 x i16>*
  %434 = load <8 x i16>, <8 x i16>* %433, align 16
  %435 = sub <8 x i16> %432, %434
  %436 = sub <8 x i16> zeroinitializer, %435
  %437 = icmp slt <8 x i16> %435, zeroinitializer
  %438 = select <8 x i1> %437, <8 x i16> %436, <8 x i16> %435
  %439 = lshr <8 x i16> %438, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %440 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %439, <8 x i16> zeroinitializer) #5
  %441 = lshr <8 x i16> %440, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %442 = getelementptr inbounds i16, i16* %9, i64 216
  %443 = bitcast i16* %442 to <8 x i16>*
  %444 = load <8 x i16>, <8 x i16>* %443, align 16
  %445 = getelementptr inbounds i16, i16* %10, i64 216
  %446 = bitcast i16* %445 to <8 x i16>*
  %447 = load <8 x i16>, <8 x i16>* %446, align 16
  %448 = sub <8 x i16> %444, %447
  %449 = sub <8 x i16> zeroinitializer, %448
  %450 = icmp slt <8 x i16> %448, zeroinitializer
  %451 = select <8 x i1> %450, <8 x i16> %449, <8 x i16> %448
  %452 = lshr <8 x i16> %451, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %453 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %452, <8 x i16> zeroinitializer) #5
  %454 = lshr <8 x i16> %453, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %455 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %441, <8 x i16> %454) #5
  %456 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %455, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %457 = icmp slt <16 x i8> %456, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %458 = select <16 x i1> %457, <16 x i8> %456, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %459 = bitcast i8* %430 to <16 x i8>*
  store <16 x i8> %458, <16 x i8>* %459, align 16
  %460 = getelementptr inbounds i16, i16* %9, i64 224
  %461 = getelementptr inbounds i16, i16* %10, i64 224
  %462 = getelementptr inbounds i8, i8* %395, i64 32
  %463 = bitcast i16* %460 to <8 x i16>*
  %464 = load <8 x i16>, <8 x i16>* %463, align 16
  %465 = bitcast i16* %461 to <8 x i16>*
  %466 = load <8 x i16>, <8 x i16>* %465, align 16
  %467 = sub <8 x i16> %464, %466
  %468 = sub <8 x i16> zeroinitializer, %467
  %469 = icmp slt <8 x i16> %467, zeroinitializer
  %470 = select <8 x i1> %469, <8 x i16> %468, <8 x i16> %467
  %471 = lshr <8 x i16> %470, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %472 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %471, <8 x i16> zeroinitializer) #5
  %473 = lshr <8 x i16> %472, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %474 = getelementptr inbounds i16, i16* %9, i64 232
  %475 = bitcast i16* %474 to <8 x i16>*
  %476 = load <8 x i16>, <8 x i16>* %475, align 16
  %477 = getelementptr inbounds i16, i16* %10, i64 232
  %478 = bitcast i16* %477 to <8 x i16>*
  %479 = load <8 x i16>, <8 x i16>* %478, align 16
  %480 = sub <8 x i16> %476, %479
  %481 = sub <8 x i16> zeroinitializer, %480
  %482 = icmp slt <8 x i16> %480, zeroinitializer
  %483 = select <8 x i1> %482, <8 x i16> %481, <8 x i16> %480
  %484 = lshr <8 x i16> %483, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %485 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %484, <8 x i16> zeroinitializer) #5
  %486 = lshr <8 x i16> %485, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %487 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %473, <8 x i16> %486) #5
  %488 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %487, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %489 = icmp slt <16 x i8> %488, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %490 = select <16 x i1> %489, <16 x i8> %488, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %491 = bitcast i8* %462 to <16 x i8>*
  store <16 x i8> %490, <16 x i8>* %491, align 16
  %492 = getelementptr inbounds i16, i16* %9, i64 240
  %493 = getelementptr inbounds i16, i16* %10, i64 240
  %494 = getelementptr inbounds i8, i8* %395, i64 48
  %495 = bitcast i16* %492 to <8 x i16>*
  %496 = load <8 x i16>, <8 x i16>* %495, align 16
  %497 = bitcast i16* %493 to <8 x i16>*
  %498 = load <8 x i16>, <8 x i16>* %497, align 16
  %499 = sub <8 x i16> %496, %498
  %500 = sub <8 x i16> zeroinitializer, %499
  %501 = icmp slt <8 x i16> %499, zeroinitializer
  %502 = select <8 x i1> %501, <8 x i16> %500, <8 x i16> %499
  %503 = lshr <8 x i16> %502, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %504 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %503, <8 x i16> zeroinitializer) #5
  %505 = lshr <8 x i16> %504, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %506 = getelementptr inbounds i16, i16* %9, i64 248
  %507 = bitcast i16* %506 to <8 x i16>*
  %508 = load <8 x i16>, <8 x i16>* %507, align 16
  %509 = getelementptr inbounds i16, i16* %10, i64 248
  %510 = bitcast i16* %509 to <8 x i16>*
  %511 = load <8 x i16>, <8 x i16>* %510, align 16
  %512 = sub <8 x i16> %508, %511
  %513 = sub <8 x i16> zeroinitializer, %512
  %514 = icmp slt <8 x i16> %512, zeroinitializer
  %515 = select <8 x i1> %514, <8 x i16> %513, <8 x i16> %512
  %516 = lshr <8 x i16> %515, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %517 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %516, <8 x i16> zeroinitializer) #5
  %518 = lshr <8 x i16> %517, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %519 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %505, <8 x i16> %518) #5
  %520 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %519, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %521 = icmp slt <16 x i8> %520, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %522 = select <16 x i1> %521, <16 x i8> %520, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %523 = bitcast i8* %494 to <16 x i8>*
  store <16 x i8> %522, <16 x i8>* %523, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask64x16_SSE4ILb1EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %407, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %405, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %406, %7 ]
  %11 = phi i32 [ 0, %4 ], [ %408, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = sub <8 x i16> %13, %15
  %17 = sub <8 x i16> zeroinitializer, %16
  %18 = icmp slt <8 x i16> %16, zeroinitializer
  %19 = select <8 x i1> %18, <8 x i16> %17, <8 x i16> %16
  %20 = lshr <8 x i16> %19, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %21 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %20, <8 x i16> zeroinitializer) #5
  %22 = lshr <8 x i16> %21, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %23 = getelementptr inbounds i16, i16* %9, i64 8
  %24 = bitcast i16* %23 to <8 x i16>*
  %25 = load <8 x i16>, <8 x i16>* %24, align 16
  %26 = getelementptr inbounds i16, i16* %10, i64 8
  %27 = bitcast i16* %26 to <8 x i16>*
  %28 = load <8 x i16>, <8 x i16>* %27, align 16
  %29 = sub <8 x i16> %25, %28
  %30 = sub <8 x i16> zeroinitializer, %29
  %31 = icmp slt <8 x i16> %29, zeroinitializer
  %32 = select <8 x i1> %31, <8 x i16> %30, <8 x i16> %29
  %33 = lshr <8 x i16> %32, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %34 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %33, <8 x i16> zeroinitializer) #5
  %35 = lshr <8 x i16> %34, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %36 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %22, <8 x i16> %35) #5
  %37 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %36, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %38 = icmp slt <16 x i8> %37, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %39 = select <16 x i1> %38, <16 x i8> %37, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %40 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %39
  %41 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %40, <16 x i8>* %41, align 16
  %42 = getelementptr inbounds i16, i16* %9, i64 16
  %43 = getelementptr inbounds i16, i16* %10, i64 16
  %44 = getelementptr inbounds i8, i8* %8, i64 16
  %45 = bitcast i16* %42 to <8 x i16>*
  %46 = load <8 x i16>, <8 x i16>* %45, align 16
  %47 = bitcast i16* %43 to <8 x i16>*
  %48 = load <8 x i16>, <8 x i16>* %47, align 16
  %49 = sub <8 x i16> %46, %48
  %50 = sub <8 x i16> zeroinitializer, %49
  %51 = icmp slt <8 x i16> %49, zeroinitializer
  %52 = select <8 x i1> %51, <8 x i16> %50, <8 x i16> %49
  %53 = lshr <8 x i16> %52, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %54 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %53, <8 x i16> zeroinitializer) #5
  %55 = lshr <8 x i16> %54, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %56 = getelementptr inbounds i16, i16* %9, i64 24
  %57 = bitcast i16* %56 to <8 x i16>*
  %58 = load <8 x i16>, <8 x i16>* %57, align 16
  %59 = getelementptr inbounds i16, i16* %10, i64 24
  %60 = bitcast i16* %59 to <8 x i16>*
  %61 = load <8 x i16>, <8 x i16>* %60, align 16
  %62 = sub <8 x i16> %58, %61
  %63 = sub <8 x i16> zeroinitializer, %62
  %64 = icmp slt <8 x i16> %62, zeroinitializer
  %65 = select <8 x i1> %64, <8 x i16> %63, <8 x i16> %62
  %66 = lshr <8 x i16> %65, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %67 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %66, <8 x i16> zeroinitializer) #5
  %68 = lshr <8 x i16> %67, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %69 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %55, <8 x i16> %68) #5
  %70 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %69, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %71 = icmp slt <16 x i8> %70, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %72 = select <16 x i1> %71, <16 x i8> %70, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %73 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %72
  %74 = bitcast i8* %44 to <16 x i8>*
  store <16 x i8> %73, <16 x i8>* %74, align 16
  %75 = getelementptr inbounds i16, i16* %9, i64 32
  %76 = getelementptr inbounds i16, i16* %10, i64 32
  %77 = getelementptr inbounds i8, i8* %8, i64 32
  %78 = bitcast i16* %75 to <8 x i16>*
  %79 = load <8 x i16>, <8 x i16>* %78, align 16
  %80 = bitcast i16* %76 to <8 x i16>*
  %81 = load <8 x i16>, <8 x i16>* %80, align 16
  %82 = sub <8 x i16> %79, %81
  %83 = sub <8 x i16> zeroinitializer, %82
  %84 = icmp slt <8 x i16> %82, zeroinitializer
  %85 = select <8 x i1> %84, <8 x i16> %83, <8 x i16> %82
  %86 = lshr <8 x i16> %85, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %87 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %86, <8 x i16> zeroinitializer) #5
  %88 = lshr <8 x i16> %87, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %89 = getelementptr inbounds i16, i16* %9, i64 40
  %90 = bitcast i16* %89 to <8 x i16>*
  %91 = load <8 x i16>, <8 x i16>* %90, align 16
  %92 = getelementptr inbounds i16, i16* %10, i64 40
  %93 = bitcast i16* %92 to <8 x i16>*
  %94 = load <8 x i16>, <8 x i16>* %93, align 16
  %95 = sub <8 x i16> %91, %94
  %96 = sub <8 x i16> zeroinitializer, %95
  %97 = icmp slt <8 x i16> %95, zeroinitializer
  %98 = select <8 x i1> %97, <8 x i16> %96, <8 x i16> %95
  %99 = lshr <8 x i16> %98, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %100 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %99, <8 x i16> zeroinitializer) #5
  %101 = lshr <8 x i16> %100, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %102 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %88, <8 x i16> %101) #5
  %103 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %102, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %104 = icmp slt <16 x i8> %103, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %105 = select <16 x i1> %104, <16 x i8> %103, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %106 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %105
  %107 = bitcast i8* %77 to <16 x i8>*
  store <16 x i8> %106, <16 x i8>* %107, align 16
  %108 = getelementptr inbounds i16, i16* %9, i64 48
  %109 = getelementptr inbounds i16, i16* %10, i64 48
  %110 = getelementptr inbounds i8, i8* %8, i64 48
  %111 = bitcast i16* %108 to <8 x i16>*
  %112 = load <8 x i16>, <8 x i16>* %111, align 16
  %113 = bitcast i16* %109 to <8 x i16>*
  %114 = load <8 x i16>, <8 x i16>* %113, align 16
  %115 = sub <8 x i16> %112, %114
  %116 = sub <8 x i16> zeroinitializer, %115
  %117 = icmp slt <8 x i16> %115, zeroinitializer
  %118 = select <8 x i1> %117, <8 x i16> %116, <8 x i16> %115
  %119 = lshr <8 x i16> %118, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %120 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %119, <8 x i16> zeroinitializer) #5
  %121 = lshr <8 x i16> %120, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %122 = getelementptr inbounds i16, i16* %9, i64 56
  %123 = bitcast i16* %122 to <8 x i16>*
  %124 = load <8 x i16>, <8 x i16>* %123, align 16
  %125 = getelementptr inbounds i16, i16* %10, i64 56
  %126 = bitcast i16* %125 to <8 x i16>*
  %127 = load <8 x i16>, <8 x i16>* %126, align 16
  %128 = sub <8 x i16> %124, %127
  %129 = sub <8 x i16> zeroinitializer, %128
  %130 = icmp slt <8 x i16> %128, zeroinitializer
  %131 = select <8 x i1> %130, <8 x i16> %129, <8 x i16> %128
  %132 = lshr <8 x i16> %131, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %133 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %132, <8 x i16> zeroinitializer) #5
  %134 = lshr <8 x i16> %133, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %135 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %121, <8 x i16> %134) #5
  %136 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %135, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %137 = icmp slt <16 x i8> %136, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %138 = select <16 x i1> %137, <16 x i8> %136, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %139 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %138
  %140 = bitcast i8* %110 to <16 x i8>*
  store <16 x i8> %139, <16 x i8>* %140, align 16
  %141 = getelementptr inbounds i16, i16* %9, i64 64
  %142 = getelementptr inbounds i16, i16* %10, i64 64
  %143 = getelementptr inbounds i8, i8* %8, i64 %3
  %144 = bitcast i16* %141 to <8 x i16>*
  %145 = load <8 x i16>, <8 x i16>* %144, align 16
  %146 = bitcast i16* %142 to <8 x i16>*
  %147 = load <8 x i16>, <8 x i16>* %146, align 16
  %148 = sub <8 x i16> %145, %147
  %149 = sub <8 x i16> zeroinitializer, %148
  %150 = icmp slt <8 x i16> %148, zeroinitializer
  %151 = select <8 x i1> %150, <8 x i16> %149, <8 x i16> %148
  %152 = lshr <8 x i16> %151, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %153 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %152, <8 x i16> zeroinitializer) #5
  %154 = lshr <8 x i16> %153, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %155 = getelementptr inbounds i16, i16* %9, i64 72
  %156 = bitcast i16* %155 to <8 x i16>*
  %157 = load <8 x i16>, <8 x i16>* %156, align 16
  %158 = getelementptr inbounds i16, i16* %10, i64 72
  %159 = bitcast i16* %158 to <8 x i16>*
  %160 = load <8 x i16>, <8 x i16>* %159, align 16
  %161 = sub <8 x i16> %157, %160
  %162 = sub <8 x i16> zeroinitializer, %161
  %163 = icmp slt <8 x i16> %161, zeroinitializer
  %164 = select <8 x i1> %163, <8 x i16> %162, <8 x i16> %161
  %165 = lshr <8 x i16> %164, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %166 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %165, <8 x i16> zeroinitializer) #5
  %167 = lshr <8 x i16> %166, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %168 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %154, <8 x i16> %167) #5
  %169 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %168, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %170 = icmp slt <16 x i8> %169, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %171 = select <16 x i1> %170, <16 x i8> %169, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %172 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %171
  %173 = bitcast i8* %143 to <16 x i8>*
  store <16 x i8> %172, <16 x i8>* %173, align 16
  %174 = getelementptr inbounds i16, i16* %9, i64 80
  %175 = getelementptr inbounds i16, i16* %10, i64 80
  %176 = getelementptr inbounds i8, i8* %143, i64 16
  %177 = bitcast i16* %174 to <8 x i16>*
  %178 = load <8 x i16>, <8 x i16>* %177, align 16
  %179 = bitcast i16* %175 to <8 x i16>*
  %180 = load <8 x i16>, <8 x i16>* %179, align 16
  %181 = sub <8 x i16> %178, %180
  %182 = sub <8 x i16> zeroinitializer, %181
  %183 = icmp slt <8 x i16> %181, zeroinitializer
  %184 = select <8 x i1> %183, <8 x i16> %182, <8 x i16> %181
  %185 = lshr <8 x i16> %184, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %186 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %185, <8 x i16> zeroinitializer) #5
  %187 = lshr <8 x i16> %186, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %188 = getelementptr inbounds i16, i16* %9, i64 88
  %189 = bitcast i16* %188 to <8 x i16>*
  %190 = load <8 x i16>, <8 x i16>* %189, align 16
  %191 = getelementptr inbounds i16, i16* %10, i64 88
  %192 = bitcast i16* %191 to <8 x i16>*
  %193 = load <8 x i16>, <8 x i16>* %192, align 16
  %194 = sub <8 x i16> %190, %193
  %195 = sub <8 x i16> zeroinitializer, %194
  %196 = icmp slt <8 x i16> %194, zeroinitializer
  %197 = select <8 x i1> %196, <8 x i16> %195, <8 x i16> %194
  %198 = lshr <8 x i16> %197, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %199 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %198, <8 x i16> zeroinitializer) #5
  %200 = lshr <8 x i16> %199, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %201 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %187, <8 x i16> %200) #5
  %202 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %201, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %203 = icmp slt <16 x i8> %202, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %204 = select <16 x i1> %203, <16 x i8> %202, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %205 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %204
  %206 = bitcast i8* %176 to <16 x i8>*
  store <16 x i8> %205, <16 x i8>* %206, align 16
  %207 = getelementptr inbounds i16, i16* %9, i64 96
  %208 = getelementptr inbounds i16, i16* %10, i64 96
  %209 = getelementptr inbounds i8, i8* %143, i64 32
  %210 = bitcast i16* %207 to <8 x i16>*
  %211 = load <8 x i16>, <8 x i16>* %210, align 16
  %212 = bitcast i16* %208 to <8 x i16>*
  %213 = load <8 x i16>, <8 x i16>* %212, align 16
  %214 = sub <8 x i16> %211, %213
  %215 = sub <8 x i16> zeroinitializer, %214
  %216 = icmp slt <8 x i16> %214, zeroinitializer
  %217 = select <8 x i1> %216, <8 x i16> %215, <8 x i16> %214
  %218 = lshr <8 x i16> %217, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %219 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %218, <8 x i16> zeroinitializer) #5
  %220 = lshr <8 x i16> %219, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %221 = getelementptr inbounds i16, i16* %9, i64 104
  %222 = bitcast i16* %221 to <8 x i16>*
  %223 = load <8 x i16>, <8 x i16>* %222, align 16
  %224 = getelementptr inbounds i16, i16* %10, i64 104
  %225 = bitcast i16* %224 to <8 x i16>*
  %226 = load <8 x i16>, <8 x i16>* %225, align 16
  %227 = sub <8 x i16> %223, %226
  %228 = sub <8 x i16> zeroinitializer, %227
  %229 = icmp slt <8 x i16> %227, zeroinitializer
  %230 = select <8 x i1> %229, <8 x i16> %228, <8 x i16> %227
  %231 = lshr <8 x i16> %230, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %232 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %231, <8 x i16> zeroinitializer) #5
  %233 = lshr <8 x i16> %232, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %234 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %220, <8 x i16> %233) #5
  %235 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %234, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %236 = icmp slt <16 x i8> %235, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %237 = select <16 x i1> %236, <16 x i8> %235, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %238 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %237
  %239 = bitcast i8* %209 to <16 x i8>*
  store <16 x i8> %238, <16 x i8>* %239, align 16
  %240 = getelementptr inbounds i16, i16* %9, i64 112
  %241 = getelementptr inbounds i16, i16* %10, i64 112
  %242 = getelementptr inbounds i8, i8* %143, i64 48
  %243 = bitcast i16* %240 to <8 x i16>*
  %244 = load <8 x i16>, <8 x i16>* %243, align 16
  %245 = bitcast i16* %241 to <8 x i16>*
  %246 = load <8 x i16>, <8 x i16>* %245, align 16
  %247 = sub <8 x i16> %244, %246
  %248 = sub <8 x i16> zeroinitializer, %247
  %249 = icmp slt <8 x i16> %247, zeroinitializer
  %250 = select <8 x i1> %249, <8 x i16> %248, <8 x i16> %247
  %251 = lshr <8 x i16> %250, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %252 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %251, <8 x i16> zeroinitializer) #5
  %253 = lshr <8 x i16> %252, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %254 = getelementptr inbounds i16, i16* %9, i64 120
  %255 = bitcast i16* %254 to <8 x i16>*
  %256 = load <8 x i16>, <8 x i16>* %255, align 16
  %257 = getelementptr inbounds i16, i16* %10, i64 120
  %258 = bitcast i16* %257 to <8 x i16>*
  %259 = load <8 x i16>, <8 x i16>* %258, align 16
  %260 = sub <8 x i16> %256, %259
  %261 = sub <8 x i16> zeroinitializer, %260
  %262 = icmp slt <8 x i16> %260, zeroinitializer
  %263 = select <8 x i1> %262, <8 x i16> %261, <8 x i16> %260
  %264 = lshr <8 x i16> %263, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %265 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %264, <8 x i16> zeroinitializer) #5
  %266 = lshr <8 x i16> %265, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %267 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %253, <8 x i16> %266) #5
  %268 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %267, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %269 = icmp slt <16 x i8> %268, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %270 = select <16 x i1> %269, <16 x i8> %268, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %271 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %270
  %272 = bitcast i8* %242 to <16 x i8>*
  store <16 x i8> %271, <16 x i8>* %272, align 16
  %273 = getelementptr inbounds i16, i16* %9, i64 128
  %274 = getelementptr inbounds i16, i16* %10, i64 128
  %275 = getelementptr inbounds i8, i8* %143, i64 %3
  %276 = bitcast i16* %273 to <8 x i16>*
  %277 = load <8 x i16>, <8 x i16>* %276, align 16
  %278 = bitcast i16* %274 to <8 x i16>*
  %279 = load <8 x i16>, <8 x i16>* %278, align 16
  %280 = sub <8 x i16> %277, %279
  %281 = sub <8 x i16> zeroinitializer, %280
  %282 = icmp slt <8 x i16> %280, zeroinitializer
  %283 = select <8 x i1> %282, <8 x i16> %281, <8 x i16> %280
  %284 = lshr <8 x i16> %283, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %285 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %284, <8 x i16> zeroinitializer) #5
  %286 = lshr <8 x i16> %285, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %287 = getelementptr inbounds i16, i16* %9, i64 136
  %288 = bitcast i16* %287 to <8 x i16>*
  %289 = load <8 x i16>, <8 x i16>* %288, align 16
  %290 = getelementptr inbounds i16, i16* %10, i64 136
  %291 = bitcast i16* %290 to <8 x i16>*
  %292 = load <8 x i16>, <8 x i16>* %291, align 16
  %293 = sub <8 x i16> %289, %292
  %294 = sub <8 x i16> zeroinitializer, %293
  %295 = icmp slt <8 x i16> %293, zeroinitializer
  %296 = select <8 x i1> %295, <8 x i16> %294, <8 x i16> %293
  %297 = lshr <8 x i16> %296, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %298 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %297, <8 x i16> zeroinitializer) #5
  %299 = lshr <8 x i16> %298, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %300 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %286, <8 x i16> %299) #5
  %301 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %300, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %302 = icmp slt <16 x i8> %301, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %303 = select <16 x i1> %302, <16 x i8> %301, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %304 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %303
  %305 = bitcast i8* %275 to <16 x i8>*
  store <16 x i8> %304, <16 x i8>* %305, align 16
  %306 = getelementptr inbounds i16, i16* %9, i64 144
  %307 = getelementptr inbounds i16, i16* %10, i64 144
  %308 = getelementptr inbounds i8, i8* %275, i64 16
  %309 = bitcast i16* %306 to <8 x i16>*
  %310 = load <8 x i16>, <8 x i16>* %309, align 16
  %311 = bitcast i16* %307 to <8 x i16>*
  %312 = load <8 x i16>, <8 x i16>* %311, align 16
  %313 = sub <8 x i16> %310, %312
  %314 = sub <8 x i16> zeroinitializer, %313
  %315 = icmp slt <8 x i16> %313, zeroinitializer
  %316 = select <8 x i1> %315, <8 x i16> %314, <8 x i16> %313
  %317 = lshr <8 x i16> %316, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %318 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %317, <8 x i16> zeroinitializer) #5
  %319 = lshr <8 x i16> %318, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %320 = getelementptr inbounds i16, i16* %9, i64 152
  %321 = bitcast i16* %320 to <8 x i16>*
  %322 = load <8 x i16>, <8 x i16>* %321, align 16
  %323 = getelementptr inbounds i16, i16* %10, i64 152
  %324 = bitcast i16* %323 to <8 x i16>*
  %325 = load <8 x i16>, <8 x i16>* %324, align 16
  %326 = sub <8 x i16> %322, %325
  %327 = sub <8 x i16> zeroinitializer, %326
  %328 = icmp slt <8 x i16> %326, zeroinitializer
  %329 = select <8 x i1> %328, <8 x i16> %327, <8 x i16> %326
  %330 = lshr <8 x i16> %329, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %331 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %330, <8 x i16> zeroinitializer) #5
  %332 = lshr <8 x i16> %331, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %333 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %319, <8 x i16> %332) #5
  %334 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %333, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %335 = icmp slt <16 x i8> %334, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %336 = select <16 x i1> %335, <16 x i8> %334, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %337 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %336
  %338 = bitcast i8* %308 to <16 x i8>*
  store <16 x i8> %337, <16 x i8>* %338, align 16
  %339 = getelementptr inbounds i16, i16* %9, i64 160
  %340 = getelementptr inbounds i16, i16* %10, i64 160
  %341 = getelementptr inbounds i8, i8* %275, i64 32
  %342 = bitcast i16* %339 to <8 x i16>*
  %343 = load <8 x i16>, <8 x i16>* %342, align 16
  %344 = bitcast i16* %340 to <8 x i16>*
  %345 = load <8 x i16>, <8 x i16>* %344, align 16
  %346 = sub <8 x i16> %343, %345
  %347 = sub <8 x i16> zeroinitializer, %346
  %348 = icmp slt <8 x i16> %346, zeroinitializer
  %349 = select <8 x i1> %348, <8 x i16> %347, <8 x i16> %346
  %350 = lshr <8 x i16> %349, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %351 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %350, <8 x i16> zeroinitializer) #5
  %352 = lshr <8 x i16> %351, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %353 = getelementptr inbounds i16, i16* %9, i64 168
  %354 = bitcast i16* %353 to <8 x i16>*
  %355 = load <8 x i16>, <8 x i16>* %354, align 16
  %356 = getelementptr inbounds i16, i16* %10, i64 168
  %357 = bitcast i16* %356 to <8 x i16>*
  %358 = load <8 x i16>, <8 x i16>* %357, align 16
  %359 = sub <8 x i16> %355, %358
  %360 = sub <8 x i16> zeroinitializer, %359
  %361 = icmp slt <8 x i16> %359, zeroinitializer
  %362 = select <8 x i1> %361, <8 x i16> %360, <8 x i16> %359
  %363 = lshr <8 x i16> %362, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %364 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %363, <8 x i16> zeroinitializer) #5
  %365 = lshr <8 x i16> %364, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %366 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %352, <8 x i16> %365) #5
  %367 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %366, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %368 = icmp slt <16 x i8> %367, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %369 = select <16 x i1> %368, <16 x i8> %367, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %370 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %369
  %371 = bitcast i8* %341 to <16 x i8>*
  store <16 x i8> %370, <16 x i8>* %371, align 16
  %372 = getelementptr inbounds i16, i16* %9, i64 176
  %373 = getelementptr inbounds i16, i16* %10, i64 176
  %374 = getelementptr inbounds i8, i8* %275, i64 48
  %375 = bitcast i16* %372 to <8 x i16>*
  %376 = load <8 x i16>, <8 x i16>* %375, align 16
  %377 = bitcast i16* %373 to <8 x i16>*
  %378 = load <8 x i16>, <8 x i16>* %377, align 16
  %379 = sub <8 x i16> %376, %378
  %380 = sub <8 x i16> zeroinitializer, %379
  %381 = icmp slt <8 x i16> %379, zeroinitializer
  %382 = select <8 x i1> %381, <8 x i16> %380, <8 x i16> %379
  %383 = lshr <8 x i16> %382, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %384 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %383, <8 x i16> zeroinitializer) #5
  %385 = lshr <8 x i16> %384, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %386 = getelementptr inbounds i16, i16* %9, i64 184
  %387 = bitcast i16* %386 to <8 x i16>*
  %388 = load <8 x i16>, <8 x i16>* %387, align 16
  %389 = getelementptr inbounds i16, i16* %10, i64 184
  %390 = bitcast i16* %389 to <8 x i16>*
  %391 = load <8 x i16>, <8 x i16>* %390, align 16
  %392 = sub <8 x i16> %388, %391
  %393 = sub <8 x i16> zeroinitializer, %392
  %394 = icmp slt <8 x i16> %392, zeroinitializer
  %395 = select <8 x i1> %394, <8 x i16> %393, <8 x i16> %392
  %396 = lshr <8 x i16> %395, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %397 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %396, <8 x i16> zeroinitializer) #5
  %398 = lshr <8 x i16> %397, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %399 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %385, <8 x i16> %398) #5
  %400 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %399, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %401 = icmp slt <16 x i8> %400, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %402 = select <16 x i1> %401, <16 x i8> %400, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %403 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %402
  %404 = bitcast i8* %374 to <16 x i8>*
  store <16 x i8> %403, <16 x i8>* %404, align 16
  %405 = getelementptr inbounds i16, i16* %9, i64 192
  %406 = getelementptr inbounds i16, i16* %10, i64 192
  %407 = getelementptr inbounds i8, i8* %275, i64 %3
  %408 = add nuw nsw i32 %11, 1
  %409 = icmp eq i32 %408, 5
  br i1 %409, label %410, label %7

410:                                              ; preds = %7
  %411 = bitcast i16* %405 to <8 x i16>*
  %412 = load <8 x i16>, <8 x i16>* %411, align 16
  %413 = bitcast i16* %406 to <8 x i16>*
  %414 = load <8 x i16>, <8 x i16>* %413, align 16
  %415 = sub <8 x i16> %412, %414
  %416 = sub <8 x i16> zeroinitializer, %415
  %417 = icmp slt <8 x i16> %415, zeroinitializer
  %418 = select <8 x i1> %417, <8 x i16> %416, <8 x i16> %415
  %419 = lshr <8 x i16> %418, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %420 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %419, <8 x i16> zeroinitializer) #5
  %421 = lshr <8 x i16> %420, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %422 = getelementptr inbounds i16, i16* %9, i64 200
  %423 = bitcast i16* %422 to <8 x i16>*
  %424 = load <8 x i16>, <8 x i16>* %423, align 16
  %425 = getelementptr inbounds i16, i16* %10, i64 200
  %426 = bitcast i16* %425 to <8 x i16>*
  %427 = load <8 x i16>, <8 x i16>* %426, align 16
  %428 = sub <8 x i16> %424, %427
  %429 = sub <8 x i16> zeroinitializer, %428
  %430 = icmp slt <8 x i16> %428, zeroinitializer
  %431 = select <8 x i1> %430, <8 x i16> %429, <8 x i16> %428
  %432 = lshr <8 x i16> %431, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %433 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %432, <8 x i16> zeroinitializer) #5
  %434 = lshr <8 x i16> %433, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %435 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %421, <8 x i16> %434) #5
  %436 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %435, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %437 = icmp slt <16 x i8> %436, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %438 = select <16 x i1> %437, <16 x i8> %436, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %439 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %438
  %440 = bitcast i8* %407 to <16 x i8>*
  store <16 x i8> %439, <16 x i8>* %440, align 16
  %441 = getelementptr inbounds i16, i16* %9, i64 208
  %442 = getelementptr inbounds i16, i16* %10, i64 208
  %443 = getelementptr inbounds i8, i8* %407, i64 16
  %444 = bitcast i16* %441 to <8 x i16>*
  %445 = load <8 x i16>, <8 x i16>* %444, align 16
  %446 = bitcast i16* %442 to <8 x i16>*
  %447 = load <8 x i16>, <8 x i16>* %446, align 16
  %448 = sub <8 x i16> %445, %447
  %449 = sub <8 x i16> zeroinitializer, %448
  %450 = icmp slt <8 x i16> %448, zeroinitializer
  %451 = select <8 x i1> %450, <8 x i16> %449, <8 x i16> %448
  %452 = lshr <8 x i16> %451, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %453 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %452, <8 x i16> zeroinitializer) #5
  %454 = lshr <8 x i16> %453, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %455 = getelementptr inbounds i16, i16* %9, i64 216
  %456 = bitcast i16* %455 to <8 x i16>*
  %457 = load <8 x i16>, <8 x i16>* %456, align 16
  %458 = getelementptr inbounds i16, i16* %10, i64 216
  %459 = bitcast i16* %458 to <8 x i16>*
  %460 = load <8 x i16>, <8 x i16>* %459, align 16
  %461 = sub <8 x i16> %457, %460
  %462 = sub <8 x i16> zeroinitializer, %461
  %463 = icmp slt <8 x i16> %461, zeroinitializer
  %464 = select <8 x i1> %463, <8 x i16> %462, <8 x i16> %461
  %465 = lshr <8 x i16> %464, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %466 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %465, <8 x i16> zeroinitializer) #5
  %467 = lshr <8 x i16> %466, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %468 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %454, <8 x i16> %467) #5
  %469 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %468, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %470 = icmp slt <16 x i8> %469, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %471 = select <16 x i1> %470, <16 x i8> %469, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %472 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %471
  %473 = bitcast i8* %443 to <16 x i8>*
  store <16 x i8> %472, <16 x i8>* %473, align 16
  %474 = getelementptr inbounds i16, i16* %9, i64 224
  %475 = getelementptr inbounds i16, i16* %10, i64 224
  %476 = getelementptr inbounds i8, i8* %407, i64 32
  %477 = bitcast i16* %474 to <8 x i16>*
  %478 = load <8 x i16>, <8 x i16>* %477, align 16
  %479 = bitcast i16* %475 to <8 x i16>*
  %480 = load <8 x i16>, <8 x i16>* %479, align 16
  %481 = sub <8 x i16> %478, %480
  %482 = sub <8 x i16> zeroinitializer, %481
  %483 = icmp slt <8 x i16> %481, zeroinitializer
  %484 = select <8 x i1> %483, <8 x i16> %482, <8 x i16> %481
  %485 = lshr <8 x i16> %484, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %486 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %485, <8 x i16> zeroinitializer) #5
  %487 = lshr <8 x i16> %486, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %488 = getelementptr inbounds i16, i16* %9, i64 232
  %489 = bitcast i16* %488 to <8 x i16>*
  %490 = load <8 x i16>, <8 x i16>* %489, align 16
  %491 = getelementptr inbounds i16, i16* %10, i64 232
  %492 = bitcast i16* %491 to <8 x i16>*
  %493 = load <8 x i16>, <8 x i16>* %492, align 16
  %494 = sub <8 x i16> %490, %493
  %495 = sub <8 x i16> zeroinitializer, %494
  %496 = icmp slt <8 x i16> %494, zeroinitializer
  %497 = select <8 x i1> %496, <8 x i16> %495, <8 x i16> %494
  %498 = lshr <8 x i16> %497, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %499 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %498, <8 x i16> zeroinitializer) #5
  %500 = lshr <8 x i16> %499, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %501 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %487, <8 x i16> %500) #5
  %502 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %501, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %503 = icmp slt <16 x i8> %502, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %504 = select <16 x i1> %503, <16 x i8> %502, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %505 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %504
  %506 = bitcast i8* %476 to <16 x i8>*
  store <16 x i8> %505, <16 x i8>* %506, align 16
  %507 = getelementptr inbounds i16, i16* %9, i64 240
  %508 = getelementptr inbounds i16, i16* %10, i64 240
  %509 = getelementptr inbounds i8, i8* %407, i64 48
  %510 = bitcast i16* %507 to <8 x i16>*
  %511 = load <8 x i16>, <8 x i16>* %510, align 16
  %512 = bitcast i16* %508 to <8 x i16>*
  %513 = load <8 x i16>, <8 x i16>* %512, align 16
  %514 = sub <8 x i16> %511, %513
  %515 = sub <8 x i16> zeroinitializer, %514
  %516 = icmp slt <8 x i16> %514, zeroinitializer
  %517 = select <8 x i1> %516, <8 x i16> %515, <8 x i16> %514
  %518 = lshr <8 x i16> %517, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %519 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %518, <8 x i16> zeroinitializer) #5
  %520 = lshr <8 x i16> %519, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %521 = getelementptr inbounds i16, i16* %9, i64 248
  %522 = bitcast i16* %521 to <8 x i16>*
  %523 = load <8 x i16>, <8 x i16>* %522, align 16
  %524 = getelementptr inbounds i16, i16* %10, i64 248
  %525 = bitcast i16* %524 to <8 x i16>*
  %526 = load <8 x i16>, <8 x i16>* %525, align 16
  %527 = sub <8 x i16> %523, %526
  %528 = sub <8 x i16> zeroinitializer, %527
  %529 = icmp slt <8 x i16> %527, zeroinitializer
  %530 = select <8 x i1> %529, <8 x i16> %528, <8 x i16> %527
  %531 = lshr <8 x i16> %530, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %532 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %531, <8 x i16> zeroinitializer) #5
  %533 = lshr <8 x i16> %532, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %534 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %520, <8 x i16> %533) #5
  %535 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %534, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %536 = icmp slt <16 x i8> %535, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %537 = select <16 x i1> %536, <16 x i8> %535, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %538 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %537
  %539 = bitcast i8* %509 to <16 x i8>*
  store <16 x i8> %538, <16 x i8>* %539, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask64x32_SSE4ILb0EEEvPKvS5_Phl(i8* readonly, i8* readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %651, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %649, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %650, %7 ]
  %11 = phi i32 [ 0, %4 ], [ %652, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = sub <8 x i16> %13, %15
  %17 = sub <8 x i16> zeroinitializer, %16
  %18 = icmp slt <8 x i16> %16, zeroinitializer
  %19 = select <8 x i1> %18, <8 x i16> %17, <8 x i16> %16
  %20 = lshr <8 x i16> %19, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %21 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %20, <8 x i16> zeroinitializer) #5
  %22 = lshr <8 x i16> %21, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %23 = getelementptr inbounds i16, i16* %9, i64 8
  %24 = bitcast i16* %23 to <8 x i16>*
  %25 = load <8 x i16>, <8 x i16>* %24, align 16
  %26 = getelementptr inbounds i16, i16* %10, i64 8
  %27 = bitcast i16* %26 to <8 x i16>*
  %28 = load <8 x i16>, <8 x i16>* %27, align 16
  %29 = sub <8 x i16> %25, %28
  %30 = sub <8 x i16> zeroinitializer, %29
  %31 = icmp slt <8 x i16> %29, zeroinitializer
  %32 = select <8 x i1> %31, <8 x i16> %30, <8 x i16> %29
  %33 = lshr <8 x i16> %32, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %34 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %33, <8 x i16> zeroinitializer) #5
  %35 = lshr <8 x i16> %34, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %36 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %22, <8 x i16> %35) #5
  %37 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %36, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %38 = icmp slt <16 x i8> %37, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %39 = select <16 x i1> %38, <16 x i8> %37, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %40 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %40, align 16
  %41 = getelementptr inbounds i16, i16* %9, i64 16
  %42 = getelementptr inbounds i16, i16* %10, i64 16
  %43 = getelementptr inbounds i8, i8* %8, i64 16
  %44 = bitcast i16* %41 to <8 x i16>*
  %45 = load <8 x i16>, <8 x i16>* %44, align 16
  %46 = bitcast i16* %42 to <8 x i16>*
  %47 = load <8 x i16>, <8 x i16>* %46, align 16
  %48 = sub <8 x i16> %45, %47
  %49 = sub <8 x i16> zeroinitializer, %48
  %50 = icmp slt <8 x i16> %48, zeroinitializer
  %51 = select <8 x i1> %50, <8 x i16> %49, <8 x i16> %48
  %52 = lshr <8 x i16> %51, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %53 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %52, <8 x i16> zeroinitializer) #5
  %54 = lshr <8 x i16> %53, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %55 = getelementptr inbounds i16, i16* %9, i64 24
  %56 = bitcast i16* %55 to <8 x i16>*
  %57 = load <8 x i16>, <8 x i16>* %56, align 16
  %58 = getelementptr inbounds i16, i16* %10, i64 24
  %59 = bitcast i16* %58 to <8 x i16>*
  %60 = load <8 x i16>, <8 x i16>* %59, align 16
  %61 = sub <8 x i16> %57, %60
  %62 = sub <8 x i16> zeroinitializer, %61
  %63 = icmp slt <8 x i16> %61, zeroinitializer
  %64 = select <8 x i1> %63, <8 x i16> %62, <8 x i16> %61
  %65 = lshr <8 x i16> %64, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %66 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %65, <8 x i16> zeroinitializer) #5
  %67 = lshr <8 x i16> %66, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %68 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %54, <8 x i16> %67) #5
  %69 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %68, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %70 = icmp slt <16 x i8> %69, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %71 = select <16 x i1> %70, <16 x i8> %69, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %72 = bitcast i8* %43 to <16 x i8>*
  store <16 x i8> %71, <16 x i8>* %72, align 16
  %73 = getelementptr inbounds i16, i16* %9, i64 32
  %74 = getelementptr inbounds i16, i16* %10, i64 32
  %75 = getelementptr inbounds i8, i8* %8, i64 32
  %76 = bitcast i16* %73 to <8 x i16>*
  %77 = load <8 x i16>, <8 x i16>* %76, align 16
  %78 = bitcast i16* %74 to <8 x i16>*
  %79 = load <8 x i16>, <8 x i16>* %78, align 16
  %80 = sub <8 x i16> %77, %79
  %81 = sub <8 x i16> zeroinitializer, %80
  %82 = icmp slt <8 x i16> %80, zeroinitializer
  %83 = select <8 x i1> %82, <8 x i16> %81, <8 x i16> %80
  %84 = lshr <8 x i16> %83, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %85 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %84, <8 x i16> zeroinitializer) #5
  %86 = lshr <8 x i16> %85, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %87 = getelementptr inbounds i16, i16* %9, i64 40
  %88 = bitcast i16* %87 to <8 x i16>*
  %89 = load <8 x i16>, <8 x i16>* %88, align 16
  %90 = getelementptr inbounds i16, i16* %10, i64 40
  %91 = bitcast i16* %90 to <8 x i16>*
  %92 = load <8 x i16>, <8 x i16>* %91, align 16
  %93 = sub <8 x i16> %89, %92
  %94 = sub <8 x i16> zeroinitializer, %93
  %95 = icmp slt <8 x i16> %93, zeroinitializer
  %96 = select <8 x i1> %95, <8 x i16> %94, <8 x i16> %93
  %97 = lshr <8 x i16> %96, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %98 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %97, <8 x i16> zeroinitializer) #5
  %99 = lshr <8 x i16> %98, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %100 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %86, <8 x i16> %99) #5
  %101 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %100, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %102 = icmp slt <16 x i8> %101, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %103 = select <16 x i1> %102, <16 x i8> %101, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %104 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %103, <16 x i8>* %104, align 16
  %105 = getelementptr inbounds i16, i16* %9, i64 48
  %106 = getelementptr inbounds i16, i16* %10, i64 48
  %107 = getelementptr inbounds i8, i8* %8, i64 48
  %108 = bitcast i16* %105 to <8 x i16>*
  %109 = load <8 x i16>, <8 x i16>* %108, align 16
  %110 = bitcast i16* %106 to <8 x i16>*
  %111 = load <8 x i16>, <8 x i16>* %110, align 16
  %112 = sub <8 x i16> %109, %111
  %113 = sub <8 x i16> zeroinitializer, %112
  %114 = icmp slt <8 x i16> %112, zeroinitializer
  %115 = select <8 x i1> %114, <8 x i16> %113, <8 x i16> %112
  %116 = lshr <8 x i16> %115, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %117 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %116, <8 x i16> zeroinitializer) #5
  %118 = lshr <8 x i16> %117, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %119 = getelementptr inbounds i16, i16* %9, i64 56
  %120 = bitcast i16* %119 to <8 x i16>*
  %121 = load <8 x i16>, <8 x i16>* %120, align 16
  %122 = getelementptr inbounds i16, i16* %10, i64 56
  %123 = bitcast i16* %122 to <8 x i16>*
  %124 = load <8 x i16>, <8 x i16>* %123, align 16
  %125 = sub <8 x i16> %121, %124
  %126 = sub <8 x i16> zeroinitializer, %125
  %127 = icmp slt <8 x i16> %125, zeroinitializer
  %128 = select <8 x i1> %127, <8 x i16> %126, <8 x i16> %125
  %129 = lshr <8 x i16> %128, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %130 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %129, <8 x i16> zeroinitializer) #5
  %131 = lshr <8 x i16> %130, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %132 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %118, <8 x i16> %131) #5
  %133 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %132, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %134 = icmp slt <16 x i8> %133, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %135 = select <16 x i1> %134, <16 x i8> %133, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %136 = bitcast i8* %107 to <16 x i8>*
  store <16 x i8> %135, <16 x i8>* %136, align 16
  %137 = getelementptr inbounds i16, i16* %9, i64 64
  %138 = getelementptr inbounds i16, i16* %10, i64 64
  %139 = getelementptr inbounds i8, i8* %8, i64 %3
  %140 = bitcast i16* %137 to <8 x i16>*
  %141 = load <8 x i16>, <8 x i16>* %140, align 16
  %142 = bitcast i16* %138 to <8 x i16>*
  %143 = load <8 x i16>, <8 x i16>* %142, align 16
  %144 = sub <8 x i16> %141, %143
  %145 = sub <8 x i16> zeroinitializer, %144
  %146 = icmp slt <8 x i16> %144, zeroinitializer
  %147 = select <8 x i1> %146, <8 x i16> %145, <8 x i16> %144
  %148 = lshr <8 x i16> %147, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %149 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %148, <8 x i16> zeroinitializer) #5
  %150 = lshr <8 x i16> %149, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %151 = getelementptr inbounds i16, i16* %9, i64 72
  %152 = bitcast i16* %151 to <8 x i16>*
  %153 = load <8 x i16>, <8 x i16>* %152, align 16
  %154 = getelementptr inbounds i16, i16* %10, i64 72
  %155 = bitcast i16* %154 to <8 x i16>*
  %156 = load <8 x i16>, <8 x i16>* %155, align 16
  %157 = sub <8 x i16> %153, %156
  %158 = sub <8 x i16> zeroinitializer, %157
  %159 = icmp slt <8 x i16> %157, zeroinitializer
  %160 = select <8 x i1> %159, <8 x i16> %158, <8 x i16> %157
  %161 = lshr <8 x i16> %160, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %162 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %161, <8 x i16> zeroinitializer) #5
  %163 = lshr <8 x i16> %162, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %164 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %150, <8 x i16> %163) #5
  %165 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %164, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %166 = icmp slt <16 x i8> %165, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %167 = select <16 x i1> %166, <16 x i8> %165, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %168 = bitcast i8* %139 to <16 x i8>*
  store <16 x i8> %167, <16 x i8>* %168, align 16
  %169 = getelementptr inbounds i16, i16* %9, i64 80
  %170 = getelementptr inbounds i16, i16* %10, i64 80
  %171 = getelementptr inbounds i8, i8* %139, i64 16
  %172 = bitcast i16* %169 to <8 x i16>*
  %173 = load <8 x i16>, <8 x i16>* %172, align 16
  %174 = bitcast i16* %170 to <8 x i16>*
  %175 = load <8 x i16>, <8 x i16>* %174, align 16
  %176 = sub <8 x i16> %173, %175
  %177 = sub <8 x i16> zeroinitializer, %176
  %178 = icmp slt <8 x i16> %176, zeroinitializer
  %179 = select <8 x i1> %178, <8 x i16> %177, <8 x i16> %176
  %180 = lshr <8 x i16> %179, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %181 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %180, <8 x i16> zeroinitializer) #5
  %182 = lshr <8 x i16> %181, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %183 = getelementptr inbounds i16, i16* %9, i64 88
  %184 = bitcast i16* %183 to <8 x i16>*
  %185 = load <8 x i16>, <8 x i16>* %184, align 16
  %186 = getelementptr inbounds i16, i16* %10, i64 88
  %187 = bitcast i16* %186 to <8 x i16>*
  %188 = load <8 x i16>, <8 x i16>* %187, align 16
  %189 = sub <8 x i16> %185, %188
  %190 = sub <8 x i16> zeroinitializer, %189
  %191 = icmp slt <8 x i16> %189, zeroinitializer
  %192 = select <8 x i1> %191, <8 x i16> %190, <8 x i16> %189
  %193 = lshr <8 x i16> %192, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %194 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %193, <8 x i16> zeroinitializer) #5
  %195 = lshr <8 x i16> %194, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %196 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %182, <8 x i16> %195) #5
  %197 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %196, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %198 = icmp slt <16 x i8> %197, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %199 = select <16 x i1> %198, <16 x i8> %197, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %200 = bitcast i8* %171 to <16 x i8>*
  store <16 x i8> %199, <16 x i8>* %200, align 16
  %201 = getelementptr inbounds i16, i16* %9, i64 96
  %202 = getelementptr inbounds i16, i16* %10, i64 96
  %203 = getelementptr inbounds i8, i8* %139, i64 32
  %204 = bitcast i16* %201 to <8 x i16>*
  %205 = load <8 x i16>, <8 x i16>* %204, align 16
  %206 = bitcast i16* %202 to <8 x i16>*
  %207 = load <8 x i16>, <8 x i16>* %206, align 16
  %208 = sub <8 x i16> %205, %207
  %209 = sub <8 x i16> zeroinitializer, %208
  %210 = icmp slt <8 x i16> %208, zeroinitializer
  %211 = select <8 x i1> %210, <8 x i16> %209, <8 x i16> %208
  %212 = lshr <8 x i16> %211, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %213 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %212, <8 x i16> zeroinitializer) #5
  %214 = lshr <8 x i16> %213, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %215 = getelementptr inbounds i16, i16* %9, i64 104
  %216 = bitcast i16* %215 to <8 x i16>*
  %217 = load <8 x i16>, <8 x i16>* %216, align 16
  %218 = getelementptr inbounds i16, i16* %10, i64 104
  %219 = bitcast i16* %218 to <8 x i16>*
  %220 = load <8 x i16>, <8 x i16>* %219, align 16
  %221 = sub <8 x i16> %217, %220
  %222 = sub <8 x i16> zeroinitializer, %221
  %223 = icmp slt <8 x i16> %221, zeroinitializer
  %224 = select <8 x i1> %223, <8 x i16> %222, <8 x i16> %221
  %225 = lshr <8 x i16> %224, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %226 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %225, <8 x i16> zeroinitializer) #5
  %227 = lshr <8 x i16> %226, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %228 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %214, <8 x i16> %227) #5
  %229 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %228, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %230 = icmp slt <16 x i8> %229, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %231 = select <16 x i1> %230, <16 x i8> %229, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %232 = bitcast i8* %203 to <16 x i8>*
  store <16 x i8> %231, <16 x i8>* %232, align 16
  %233 = getelementptr inbounds i16, i16* %9, i64 112
  %234 = getelementptr inbounds i16, i16* %10, i64 112
  %235 = getelementptr inbounds i8, i8* %139, i64 48
  %236 = bitcast i16* %233 to <8 x i16>*
  %237 = load <8 x i16>, <8 x i16>* %236, align 16
  %238 = bitcast i16* %234 to <8 x i16>*
  %239 = load <8 x i16>, <8 x i16>* %238, align 16
  %240 = sub <8 x i16> %237, %239
  %241 = sub <8 x i16> zeroinitializer, %240
  %242 = icmp slt <8 x i16> %240, zeroinitializer
  %243 = select <8 x i1> %242, <8 x i16> %241, <8 x i16> %240
  %244 = lshr <8 x i16> %243, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %245 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %244, <8 x i16> zeroinitializer) #5
  %246 = lshr <8 x i16> %245, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %247 = getelementptr inbounds i16, i16* %9, i64 120
  %248 = bitcast i16* %247 to <8 x i16>*
  %249 = load <8 x i16>, <8 x i16>* %248, align 16
  %250 = getelementptr inbounds i16, i16* %10, i64 120
  %251 = bitcast i16* %250 to <8 x i16>*
  %252 = load <8 x i16>, <8 x i16>* %251, align 16
  %253 = sub <8 x i16> %249, %252
  %254 = sub <8 x i16> zeroinitializer, %253
  %255 = icmp slt <8 x i16> %253, zeroinitializer
  %256 = select <8 x i1> %255, <8 x i16> %254, <8 x i16> %253
  %257 = lshr <8 x i16> %256, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %258 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %257, <8 x i16> zeroinitializer) #5
  %259 = lshr <8 x i16> %258, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %260 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %246, <8 x i16> %259) #5
  %261 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %260, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %262 = icmp slt <16 x i8> %261, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %263 = select <16 x i1> %262, <16 x i8> %261, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %264 = bitcast i8* %235 to <16 x i8>*
  store <16 x i8> %263, <16 x i8>* %264, align 16
  %265 = getelementptr inbounds i16, i16* %9, i64 128
  %266 = getelementptr inbounds i16, i16* %10, i64 128
  %267 = getelementptr inbounds i8, i8* %139, i64 %3
  %268 = bitcast i16* %265 to <8 x i16>*
  %269 = load <8 x i16>, <8 x i16>* %268, align 16
  %270 = bitcast i16* %266 to <8 x i16>*
  %271 = load <8 x i16>, <8 x i16>* %270, align 16
  %272 = sub <8 x i16> %269, %271
  %273 = sub <8 x i16> zeroinitializer, %272
  %274 = icmp slt <8 x i16> %272, zeroinitializer
  %275 = select <8 x i1> %274, <8 x i16> %273, <8 x i16> %272
  %276 = lshr <8 x i16> %275, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %277 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %276, <8 x i16> zeroinitializer) #5
  %278 = lshr <8 x i16> %277, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %279 = getelementptr inbounds i16, i16* %9, i64 136
  %280 = bitcast i16* %279 to <8 x i16>*
  %281 = load <8 x i16>, <8 x i16>* %280, align 16
  %282 = getelementptr inbounds i16, i16* %10, i64 136
  %283 = bitcast i16* %282 to <8 x i16>*
  %284 = load <8 x i16>, <8 x i16>* %283, align 16
  %285 = sub <8 x i16> %281, %284
  %286 = sub <8 x i16> zeroinitializer, %285
  %287 = icmp slt <8 x i16> %285, zeroinitializer
  %288 = select <8 x i1> %287, <8 x i16> %286, <8 x i16> %285
  %289 = lshr <8 x i16> %288, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %290 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %289, <8 x i16> zeroinitializer) #5
  %291 = lshr <8 x i16> %290, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %292 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %278, <8 x i16> %291) #5
  %293 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %292, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %294 = icmp slt <16 x i8> %293, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %295 = select <16 x i1> %294, <16 x i8> %293, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %296 = bitcast i8* %267 to <16 x i8>*
  store <16 x i8> %295, <16 x i8>* %296, align 16
  %297 = getelementptr inbounds i16, i16* %9, i64 144
  %298 = getelementptr inbounds i16, i16* %10, i64 144
  %299 = getelementptr inbounds i8, i8* %267, i64 16
  %300 = bitcast i16* %297 to <8 x i16>*
  %301 = load <8 x i16>, <8 x i16>* %300, align 16
  %302 = bitcast i16* %298 to <8 x i16>*
  %303 = load <8 x i16>, <8 x i16>* %302, align 16
  %304 = sub <8 x i16> %301, %303
  %305 = sub <8 x i16> zeroinitializer, %304
  %306 = icmp slt <8 x i16> %304, zeroinitializer
  %307 = select <8 x i1> %306, <8 x i16> %305, <8 x i16> %304
  %308 = lshr <8 x i16> %307, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %309 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %308, <8 x i16> zeroinitializer) #5
  %310 = lshr <8 x i16> %309, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %311 = getelementptr inbounds i16, i16* %9, i64 152
  %312 = bitcast i16* %311 to <8 x i16>*
  %313 = load <8 x i16>, <8 x i16>* %312, align 16
  %314 = getelementptr inbounds i16, i16* %10, i64 152
  %315 = bitcast i16* %314 to <8 x i16>*
  %316 = load <8 x i16>, <8 x i16>* %315, align 16
  %317 = sub <8 x i16> %313, %316
  %318 = sub <8 x i16> zeroinitializer, %317
  %319 = icmp slt <8 x i16> %317, zeroinitializer
  %320 = select <8 x i1> %319, <8 x i16> %318, <8 x i16> %317
  %321 = lshr <8 x i16> %320, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %322 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %321, <8 x i16> zeroinitializer) #5
  %323 = lshr <8 x i16> %322, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %324 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %310, <8 x i16> %323) #5
  %325 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %324, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %326 = icmp slt <16 x i8> %325, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %327 = select <16 x i1> %326, <16 x i8> %325, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %328 = bitcast i8* %299 to <16 x i8>*
  store <16 x i8> %327, <16 x i8>* %328, align 16
  %329 = getelementptr inbounds i16, i16* %9, i64 160
  %330 = getelementptr inbounds i16, i16* %10, i64 160
  %331 = getelementptr inbounds i8, i8* %267, i64 32
  %332 = bitcast i16* %329 to <8 x i16>*
  %333 = load <8 x i16>, <8 x i16>* %332, align 16
  %334 = bitcast i16* %330 to <8 x i16>*
  %335 = load <8 x i16>, <8 x i16>* %334, align 16
  %336 = sub <8 x i16> %333, %335
  %337 = sub <8 x i16> zeroinitializer, %336
  %338 = icmp slt <8 x i16> %336, zeroinitializer
  %339 = select <8 x i1> %338, <8 x i16> %337, <8 x i16> %336
  %340 = lshr <8 x i16> %339, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %341 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %340, <8 x i16> zeroinitializer) #5
  %342 = lshr <8 x i16> %341, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %343 = getelementptr inbounds i16, i16* %9, i64 168
  %344 = bitcast i16* %343 to <8 x i16>*
  %345 = load <8 x i16>, <8 x i16>* %344, align 16
  %346 = getelementptr inbounds i16, i16* %10, i64 168
  %347 = bitcast i16* %346 to <8 x i16>*
  %348 = load <8 x i16>, <8 x i16>* %347, align 16
  %349 = sub <8 x i16> %345, %348
  %350 = sub <8 x i16> zeroinitializer, %349
  %351 = icmp slt <8 x i16> %349, zeroinitializer
  %352 = select <8 x i1> %351, <8 x i16> %350, <8 x i16> %349
  %353 = lshr <8 x i16> %352, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %354 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %353, <8 x i16> zeroinitializer) #5
  %355 = lshr <8 x i16> %354, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %356 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %342, <8 x i16> %355) #5
  %357 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %356, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %358 = icmp slt <16 x i8> %357, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %359 = select <16 x i1> %358, <16 x i8> %357, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %360 = bitcast i8* %331 to <16 x i8>*
  store <16 x i8> %359, <16 x i8>* %360, align 16
  %361 = getelementptr inbounds i16, i16* %9, i64 176
  %362 = getelementptr inbounds i16, i16* %10, i64 176
  %363 = getelementptr inbounds i8, i8* %267, i64 48
  %364 = bitcast i16* %361 to <8 x i16>*
  %365 = load <8 x i16>, <8 x i16>* %364, align 16
  %366 = bitcast i16* %362 to <8 x i16>*
  %367 = load <8 x i16>, <8 x i16>* %366, align 16
  %368 = sub <8 x i16> %365, %367
  %369 = sub <8 x i16> zeroinitializer, %368
  %370 = icmp slt <8 x i16> %368, zeroinitializer
  %371 = select <8 x i1> %370, <8 x i16> %369, <8 x i16> %368
  %372 = lshr <8 x i16> %371, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %373 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %372, <8 x i16> zeroinitializer) #5
  %374 = lshr <8 x i16> %373, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %375 = getelementptr inbounds i16, i16* %9, i64 184
  %376 = bitcast i16* %375 to <8 x i16>*
  %377 = load <8 x i16>, <8 x i16>* %376, align 16
  %378 = getelementptr inbounds i16, i16* %10, i64 184
  %379 = bitcast i16* %378 to <8 x i16>*
  %380 = load <8 x i16>, <8 x i16>* %379, align 16
  %381 = sub <8 x i16> %377, %380
  %382 = sub <8 x i16> zeroinitializer, %381
  %383 = icmp slt <8 x i16> %381, zeroinitializer
  %384 = select <8 x i1> %383, <8 x i16> %382, <8 x i16> %381
  %385 = lshr <8 x i16> %384, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %386 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %385, <8 x i16> zeroinitializer) #5
  %387 = lshr <8 x i16> %386, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %388 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %374, <8 x i16> %387) #5
  %389 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %388, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %390 = icmp slt <16 x i8> %389, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %391 = select <16 x i1> %390, <16 x i8> %389, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %392 = bitcast i8* %363 to <16 x i8>*
  store <16 x i8> %391, <16 x i8>* %392, align 16
  %393 = getelementptr inbounds i16, i16* %9, i64 192
  %394 = getelementptr inbounds i16, i16* %10, i64 192
  %395 = getelementptr inbounds i8, i8* %267, i64 %3
  %396 = bitcast i16* %393 to <8 x i16>*
  %397 = load <8 x i16>, <8 x i16>* %396, align 16
  %398 = bitcast i16* %394 to <8 x i16>*
  %399 = load <8 x i16>, <8 x i16>* %398, align 16
  %400 = sub <8 x i16> %397, %399
  %401 = sub <8 x i16> zeroinitializer, %400
  %402 = icmp slt <8 x i16> %400, zeroinitializer
  %403 = select <8 x i1> %402, <8 x i16> %401, <8 x i16> %400
  %404 = lshr <8 x i16> %403, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %405 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %404, <8 x i16> zeroinitializer) #5
  %406 = lshr <8 x i16> %405, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %407 = getelementptr inbounds i16, i16* %9, i64 200
  %408 = bitcast i16* %407 to <8 x i16>*
  %409 = load <8 x i16>, <8 x i16>* %408, align 16
  %410 = getelementptr inbounds i16, i16* %10, i64 200
  %411 = bitcast i16* %410 to <8 x i16>*
  %412 = load <8 x i16>, <8 x i16>* %411, align 16
  %413 = sub <8 x i16> %409, %412
  %414 = sub <8 x i16> zeroinitializer, %413
  %415 = icmp slt <8 x i16> %413, zeroinitializer
  %416 = select <8 x i1> %415, <8 x i16> %414, <8 x i16> %413
  %417 = lshr <8 x i16> %416, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %418 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %417, <8 x i16> zeroinitializer) #5
  %419 = lshr <8 x i16> %418, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %420 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %406, <8 x i16> %419) #5
  %421 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %420, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %422 = icmp slt <16 x i8> %421, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %423 = select <16 x i1> %422, <16 x i8> %421, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %424 = bitcast i8* %395 to <16 x i8>*
  store <16 x i8> %423, <16 x i8>* %424, align 16
  %425 = getelementptr inbounds i16, i16* %9, i64 208
  %426 = getelementptr inbounds i16, i16* %10, i64 208
  %427 = getelementptr inbounds i8, i8* %395, i64 16
  %428 = bitcast i16* %425 to <8 x i16>*
  %429 = load <8 x i16>, <8 x i16>* %428, align 16
  %430 = bitcast i16* %426 to <8 x i16>*
  %431 = load <8 x i16>, <8 x i16>* %430, align 16
  %432 = sub <8 x i16> %429, %431
  %433 = sub <8 x i16> zeroinitializer, %432
  %434 = icmp slt <8 x i16> %432, zeroinitializer
  %435 = select <8 x i1> %434, <8 x i16> %433, <8 x i16> %432
  %436 = lshr <8 x i16> %435, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %437 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %436, <8 x i16> zeroinitializer) #5
  %438 = lshr <8 x i16> %437, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %439 = getelementptr inbounds i16, i16* %9, i64 216
  %440 = bitcast i16* %439 to <8 x i16>*
  %441 = load <8 x i16>, <8 x i16>* %440, align 16
  %442 = getelementptr inbounds i16, i16* %10, i64 216
  %443 = bitcast i16* %442 to <8 x i16>*
  %444 = load <8 x i16>, <8 x i16>* %443, align 16
  %445 = sub <8 x i16> %441, %444
  %446 = sub <8 x i16> zeroinitializer, %445
  %447 = icmp slt <8 x i16> %445, zeroinitializer
  %448 = select <8 x i1> %447, <8 x i16> %446, <8 x i16> %445
  %449 = lshr <8 x i16> %448, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %450 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %449, <8 x i16> zeroinitializer) #5
  %451 = lshr <8 x i16> %450, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %452 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %438, <8 x i16> %451) #5
  %453 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %452, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %454 = icmp slt <16 x i8> %453, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %455 = select <16 x i1> %454, <16 x i8> %453, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %456 = bitcast i8* %427 to <16 x i8>*
  store <16 x i8> %455, <16 x i8>* %456, align 16
  %457 = getelementptr inbounds i16, i16* %9, i64 224
  %458 = getelementptr inbounds i16, i16* %10, i64 224
  %459 = getelementptr inbounds i8, i8* %395, i64 32
  %460 = bitcast i16* %457 to <8 x i16>*
  %461 = load <8 x i16>, <8 x i16>* %460, align 16
  %462 = bitcast i16* %458 to <8 x i16>*
  %463 = load <8 x i16>, <8 x i16>* %462, align 16
  %464 = sub <8 x i16> %461, %463
  %465 = sub <8 x i16> zeroinitializer, %464
  %466 = icmp slt <8 x i16> %464, zeroinitializer
  %467 = select <8 x i1> %466, <8 x i16> %465, <8 x i16> %464
  %468 = lshr <8 x i16> %467, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %469 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %468, <8 x i16> zeroinitializer) #5
  %470 = lshr <8 x i16> %469, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %471 = getelementptr inbounds i16, i16* %9, i64 232
  %472 = bitcast i16* %471 to <8 x i16>*
  %473 = load <8 x i16>, <8 x i16>* %472, align 16
  %474 = getelementptr inbounds i16, i16* %10, i64 232
  %475 = bitcast i16* %474 to <8 x i16>*
  %476 = load <8 x i16>, <8 x i16>* %475, align 16
  %477 = sub <8 x i16> %473, %476
  %478 = sub <8 x i16> zeroinitializer, %477
  %479 = icmp slt <8 x i16> %477, zeroinitializer
  %480 = select <8 x i1> %479, <8 x i16> %478, <8 x i16> %477
  %481 = lshr <8 x i16> %480, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %482 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %481, <8 x i16> zeroinitializer) #5
  %483 = lshr <8 x i16> %482, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %484 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %470, <8 x i16> %483) #5
  %485 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %484, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %486 = icmp slt <16 x i8> %485, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %487 = select <16 x i1> %486, <16 x i8> %485, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %488 = bitcast i8* %459 to <16 x i8>*
  store <16 x i8> %487, <16 x i8>* %488, align 16
  %489 = getelementptr inbounds i16, i16* %9, i64 240
  %490 = getelementptr inbounds i16, i16* %10, i64 240
  %491 = getelementptr inbounds i8, i8* %395, i64 48
  %492 = bitcast i16* %489 to <8 x i16>*
  %493 = load <8 x i16>, <8 x i16>* %492, align 16
  %494 = bitcast i16* %490 to <8 x i16>*
  %495 = load <8 x i16>, <8 x i16>* %494, align 16
  %496 = sub <8 x i16> %493, %495
  %497 = sub <8 x i16> zeroinitializer, %496
  %498 = icmp slt <8 x i16> %496, zeroinitializer
  %499 = select <8 x i1> %498, <8 x i16> %497, <8 x i16> %496
  %500 = lshr <8 x i16> %499, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %501 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %500, <8 x i16> zeroinitializer) #5
  %502 = lshr <8 x i16> %501, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %503 = getelementptr inbounds i16, i16* %9, i64 248
  %504 = bitcast i16* %503 to <8 x i16>*
  %505 = load <8 x i16>, <8 x i16>* %504, align 16
  %506 = getelementptr inbounds i16, i16* %10, i64 248
  %507 = bitcast i16* %506 to <8 x i16>*
  %508 = load <8 x i16>, <8 x i16>* %507, align 16
  %509 = sub <8 x i16> %505, %508
  %510 = sub <8 x i16> zeroinitializer, %509
  %511 = icmp slt <8 x i16> %509, zeroinitializer
  %512 = select <8 x i1> %511, <8 x i16> %510, <8 x i16> %509
  %513 = lshr <8 x i16> %512, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %514 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %513, <8 x i16> zeroinitializer) #5
  %515 = lshr <8 x i16> %514, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %516 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %502, <8 x i16> %515) #5
  %517 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %516, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %518 = icmp slt <16 x i8> %517, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %519 = select <16 x i1> %518, <16 x i8> %517, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %520 = bitcast i8* %491 to <16 x i8>*
  store <16 x i8> %519, <16 x i8>* %520, align 16
  %521 = getelementptr inbounds i16, i16* %9, i64 256
  %522 = getelementptr inbounds i16, i16* %10, i64 256
  %523 = getelementptr inbounds i8, i8* %395, i64 %3
  %524 = bitcast i16* %521 to <8 x i16>*
  %525 = load <8 x i16>, <8 x i16>* %524, align 16
  %526 = bitcast i16* %522 to <8 x i16>*
  %527 = load <8 x i16>, <8 x i16>* %526, align 16
  %528 = sub <8 x i16> %525, %527
  %529 = sub <8 x i16> zeroinitializer, %528
  %530 = icmp slt <8 x i16> %528, zeroinitializer
  %531 = select <8 x i1> %530, <8 x i16> %529, <8 x i16> %528
  %532 = lshr <8 x i16> %531, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %533 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %532, <8 x i16> zeroinitializer) #5
  %534 = lshr <8 x i16> %533, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %535 = getelementptr inbounds i16, i16* %9, i64 264
  %536 = bitcast i16* %535 to <8 x i16>*
  %537 = load <8 x i16>, <8 x i16>* %536, align 16
  %538 = getelementptr inbounds i16, i16* %10, i64 264
  %539 = bitcast i16* %538 to <8 x i16>*
  %540 = load <8 x i16>, <8 x i16>* %539, align 16
  %541 = sub <8 x i16> %537, %540
  %542 = sub <8 x i16> zeroinitializer, %541
  %543 = icmp slt <8 x i16> %541, zeroinitializer
  %544 = select <8 x i1> %543, <8 x i16> %542, <8 x i16> %541
  %545 = lshr <8 x i16> %544, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %546 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %545, <8 x i16> zeroinitializer) #5
  %547 = lshr <8 x i16> %546, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %548 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %534, <8 x i16> %547) #5
  %549 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %548, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %550 = icmp slt <16 x i8> %549, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %551 = select <16 x i1> %550, <16 x i8> %549, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %552 = bitcast i8* %523 to <16 x i8>*
  store <16 x i8> %551, <16 x i8>* %552, align 16
  %553 = getelementptr inbounds i16, i16* %9, i64 272
  %554 = getelementptr inbounds i16, i16* %10, i64 272
  %555 = getelementptr inbounds i8, i8* %523, i64 16
  %556 = bitcast i16* %553 to <8 x i16>*
  %557 = load <8 x i16>, <8 x i16>* %556, align 16
  %558 = bitcast i16* %554 to <8 x i16>*
  %559 = load <8 x i16>, <8 x i16>* %558, align 16
  %560 = sub <8 x i16> %557, %559
  %561 = sub <8 x i16> zeroinitializer, %560
  %562 = icmp slt <8 x i16> %560, zeroinitializer
  %563 = select <8 x i1> %562, <8 x i16> %561, <8 x i16> %560
  %564 = lshr <8 x i16> %563, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %565 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %564, <8 x i16> zeroinitializer) #5
  %566 = lshr <8 x i16> %565, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %567 = getelementptr inbounds i16, i16* %9, i64 280
  %568 = bitcast i16* %567 to <8 x i16>*
  %569 = load <8 x i16>, <8 x i16>* %568, align 16
  %570 = getelementptr inbounds i16, i16* %10, i64 280
  %571 = bitcast i16* %570 to <8 x i16>*
  %572 = load <8 x i16>, <8 x i16>* %571, align 16
  %573 = sub <8 x i16> %569, %572
  %574 = sub <8 x i16> zeroinitializer, %573
  %575 = icmp slt <8 x i16> %573, zeroinitializer
  %576 = select <8 x i1> %575, <8 x i16> %574, <8 x i16> %573
  %577 = lshr <8 x i16> %576, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %578 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %577, <8 x i16> zeroinitializer) #5
  %579 = lshr <8 x i16> %578, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %580 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %566, <8 x i16> %579) #5
  %581 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %580, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %582 = icmp slt <16 x i8> %581, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %583 = select <16 x i1> %582, <16 x i8> %581, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %584 = bitcast i8* %555 to <16 x i8>*
  store <16 x i8> %583, <16 x i8>* %584, align 16
  %585 = getelementptr inbounds i16, i16* %9, i64 288
  %586 = getelementptr inbounds i16, i16* %10, i64 288
  %587 = getelementptr inbounds i8, i8* %523, i64 32
  %588 = bitcast i16* %585 to <8 x i16>*
  %589 = load <8 x i16>, <8 x i16>* %588, align 16
  %590 = bitcast i16* %586 to <8 x i16>*
  %591 = load <8 x i16>, <8 x i16>* %590, align 16
  %592 = sub <8 x i16> %589, %591
  %593 = sub <8 x i16> zeroinitializer, %592
  %594 = icmp slt <8 x i16> %592, zeroinitializer
  %595 = select <8 x i1> %594, <8 x i16> %593, <8 x i16> %592
  %596 = lshr <8 x i16> %595, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %597 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %596, <8 x i16> zeroinitializer) #5
  %598 = lshr <8 x i16> %597, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %599 = getelementptr inbounds i16, i16* %9, i64 296
  %600 = bitcast i16* %599 to <8 x i16>*
  %601 = load <8 x i16>, <8 x i16>* %600, align 16
  %602 = getelementptr inbounds i16, i16* %10, i64 296
  %603 = bitcast i16* %602 to <8 x i16>*
  %604 = load <8 x i16>, <8 x i16>* %603, align 16
  %605 = sub <8 x i16> %601, %604
  %606 = sub <8 x i16> zeroinitializer, %605
  %607 = icmp slt <8 x i16> %605, zeroinitializer
  %608 = select <8 x i1> %607, <8 x i16> %606, <8 x i16> %605
  %609 = lshr <8 x i16> %608, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %610 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %609, <8 x i16> zeroinitializer) #5
  %611 = lshr <8 x i16> %610, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %612 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %598, <8 x i16> %611) #5
  %613 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %612, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %614 = icmp slt <16 x i8> %613, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %615 = select <16 x i1> %614, <16 x i8> %613, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %616 = bitcast i8* %587 to <16 x i8>*
  store <16 x i8> %615, <16 x i8>* %616, align 16
  %617 = getelementptr inbounds i16, i16* %9, i64 304
  %618 = getelementptr inbounds i16, i16* %10, i64 304
  %619 = getelementptr inbounds i8, i8* %523, i64 48
  %620 = bitcast i16* %617 to <8 x i16>*
  %621 = load <8 x i16>, <8 x i16>* %620, align 16
  %622 = bitcast i16* %618 to <8 x i16>*
  %623 = load <8 x i16>, <8 x i16>* %622, align 16
  %624 = sub <8 x i16> %621, %623
  %625 = sub <8 x i16> zeroinitializer, %624
  %626 = icmp slt <8 x i16> %624, zeroinitializer
  %627 = select <8 x i1> %626, <8 x i16> %625, <8 x i16> %624
  %628 = lshr <8 x i16> %627, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %629 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %628, <8 x i16> zeroinitializer) #5
  %630 = lshr <8 x i16> %629, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %631 = getelementptr inbounds i16, i16* %9, i64 312
  %632 = bitcast i16* %631 to <8 x i16>*
  %633 = load <8 x i16>, <8 x i16>* %632, align 16
  %634 = getelementptr inbounds i16, i16* %10, i64 312
  %635 = bitcast i16* %634 to <8 x i16>*
  %636 = load <8 x i16>, <8 x i16>* %635, align 16
  %637 = sub <8 x i16> %633, %636
  %638 = sub <8 x i16> zeroinitializer, %637
  %639 = icmp slt <8 x i16> %637, zeroinitializer
  %640 = select <8 x i1> %639, <8 x i16> %638, <8 x i16> %637
  %641 = lshr <8 x i16> %640, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %642 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %641, <8 x i16> zeroinitializer) #5
  %643 = lshr <8 x i16> %642, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %644 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %630, <8 x i16> %643) #5
  %645 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %644, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %646 = icmp slt <16 x i8> %645, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %647 = select <16 x i1> %646, <16 x i8> %645, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %648 = bitcast i8* %619 to <16 x i8>*
  store <16 x i8> %647, <16 x i8>* %648, align 16
  %649 = getelementptr inbounds i16, i16* %9, i64 320
  %650 = getelementptr inbounds i16, i16* %10, i64 320
  %651 = getelementptr inbounds i8, i8* %523, i64 %3
  %652 = add nuw nsw i32 %11, 1
  %653 = icmp eq i32 %652, 6
  br i1 %653, label %654, label %7

654:                                              ; preds = %7
  %655 = bitcast i16* %649 to <8 x i16>*
  %656 = load <8 x i16>, <8 x i16>* %655, align 16
  %657 = bitcast i16* %650 to <8 x i16>*
  %658 = load <8 x i16>, <8 x i16>* %657, align 16
  %659 = sub <8 x i16> %656, %658
  %660 = sub <8 x i16> zeroinitializer, %659
  %661 = icmp slt <8 x i16> %659, zeroinitializer
  %662 = select <8 x i1> %661, <8 x i16> %660, <8 x i16> %659
  %663 = lshr <8 x i16> %662, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %664 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %663, <8 x i16> zeroinitializer) #5
  %665 = lshr <8 x i16> %664, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %666 = getelementptr inbounds i16, i16* %9, i64 328
  %667 = bitcast i16* %666 to <8 x i16>*
  %668 = load <8 x i16>, <8 x i16>* %667, align 16
  %669 = getelementptr inbounds i16, i16* %10, i64 328
  %670 = bitcast i16* %669 to <8 x i16>*
  %671 = load <8 x i16>, <8 x i16>* %670, align 16
  %672 = sub <8 x i16> %668, %671
  %673 = sub <8 x i16> zeroinitializer, %672
  %674 = icmp slt <8 x i16> %672, zeroinitializer
  %675 = select <8 x i1> %674, <8 x i16> %673, <8 x i16> %672
  %676 = lshr <8 x i16> %675, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %677 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %676, <8 x i16> zeroinitializer) #5
  %678 = lshr <8 x i16> %677, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %679 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %665, <8 x i16> %678) #5
  %680 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %679, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %681 = icmp slt <16 x i8> %680, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %682 = select <16 x i1> %681, <16 x i8> %680, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %683 = bitcast i8* %651 to <16 x i8>*
  store <16 x i8> %682, <16 x i8>* %683, align 16
  %684 = getelementptr inbounds i16, i16* %9, i64 336
  %685 = getelementptr inbounds i16, i16* %10, i64 336
  %686 = getelementptr inbounds i8, i8* %651, i64 16
  %687 = bitcast i16* %684 to <8 x i16>*
  %688 = load <8 x i16>, <8 x i16>* %687, align 16
  %689 = bitcast i16* %685 to <8 x i16>*
  %690 = load <8 x i16>, <8 x i16>* %689, align 16
  %691 = sub <8 x i16> %688, %690
  %692 = sub <8 x i16> zeroinitializer, %691
  %693 = icmp slt <8 x i16> %691, zeroinitializer
  %694 = select <8 x i1> %693, <8 x i16> %692, <8 x i16> %691
  %695 = lshr <8 x i16> %694, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %696 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %695, <8 x i16> zeroinitializer) #5
  %697 = lshr <8 x i16> %696, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %698 = getelementptr inbounds i16, i16* %9, i64 344
  %699 = bitcast i16* %698 to <8 x i16>*
  %700 = load <8 x i16>, <8 x i16>* %699, align 16
  %701 = getelementptr inbounds i16, i16* %10, i64 344
  %702 = bitcast i16* %701 to <8 x i16>*
  %703 = load <8 x i16>, <8 x i16>* %702, align 16
  %704 = sub <8 x i16> %700, %703
  %705 = sub <8 x i16> zeroinitializer, %704
  %706 = icmp slt <8 x i16> %704, zeroinitializer
  %707 = select <8 x i1> %706, <8 x i16> %705, <8 x i16> %704
  %708 = lshr <8 x i16> %707, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %709 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %708, <8 x i16> zeroinitializer) #5
  %710 = lshr <8 x i16> %709, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %711 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %697, <8 x i16> %710) #5
  %712 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %711, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %713 = icmp slt <16 x i8> %712, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %714 = select <16 x i1> %713, <16 x i8> %712, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %715 = bitcast i8* %686 to <16 x i8>*
  store <16 x i8> %714, <16 x i8>* %715, align 16
  %716 = getelementptr inbounds i16, i16* %9, i64 352
  %717 = getelementptr inbounds i16, i16* %10, i64 352
  %718 = getelementptr inbounds i8, i8* %651, i64 32
  %719 = bitcast i16* %716 to <8 x i16>*
  %720 = load <8 x i16>, <8 x i16>* %719, align 16
  %721 = bitcast i16* %717 to <8 x i16>*
  %722 = load <8 x i16>, <8 x i16>* %721, align 16
  %723 = sub <8 x i16> %720, %722
  %724 = sub <8 x i16> zeroinitializer, %723
  %725 = icmp slt <8 x i16> %723, zeroinitializer
  %726 = select <8 x i1> %725, <8 x i16> %724, <8 x i16> %723
  %727 = lshr <8 x i16> %726, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %728 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %727, <8 x i16> zeroinitializer) #5
  %729 = lshr <8 x i16> %728, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %730 = getelementptr inbounds i16, i16* %9, i64 360
  %731 = bitcast i16* %730 to <8 x i16>*
  %732 = load <8 x i16>, <8 x i16>* %731, align 16
  %733 = getelementptr inbounds i16, i16* %10, i64 360
  %734 = bitcast i16* %733 to <8 x i16>*
  %735 = load <8 x i16>, <8 x i16>* %734, align 16
  %736 = sub <8 x i16> %732, %735
  %737 = sub <8 x i16> zeroinitializer, %736
  %738 = icmp slt <8 x i16> %736, zeroinitializer
  %739 = select <8 x i1> %738, <8 x i16> %737, <8 x i16> %736
  %740 = lshr <8 x i16> %739, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %741 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %740, <8 x i16> zeroinitializer) #5
  %742 = lshr <8 x i16> %741, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %743 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %729, <8 x i16> %742) #5
  %744 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %743, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %745 = icmp slt <16 x i8> %744, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %746 = select <16 x i1> %745, <16 x i8> %744, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %747 = bitcast i8* %718 to <16 x i8>*
  store <16 x i8> %746, <16 x i8>* %747, align 16
  %748 = getelementptr inbounds i16, i16* %9, i64 368
  %749 = getelementptr inbounds i16, i16* %10, i64 368
  %750 = getelementptr inbounds i8, i8* %651, i64 48
  %751 = bitcast i16* %748 to <8 x i16>*
  %752 = load <8 x i16>, <8 x i16>* %751, align 16
  %753 = bitcast i16* %749 to <8 x i16>*
  %754 = load <8 x i16>, <8 x i16>* %753, align 16
  %755 = sub <8 x i16> %752, %754
  %756 = sub <8 x i16> zeroinitializer, %755
  %757 = icmp slt <8 x i16> %755, zeroinitializer
  %758 = select <8 x i1> %757, <8 x i16> %756, <8 x i16> %755
  %759 = lshr <8 x i16> %758, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %760 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %759, <8 x i16> zeroinitializer) #5
  %761 = lshr <8 x i16> %760, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %762 = getelementptr inbounds i16, i16* %9, i64 376
  %763 = bitcast i16* %762 to <8 x i16>*
  %764 = load <8 x i16>, <8 x i16>* %763, align 16
  %765 = getelementptr inbounds i16, i16* %10, i64 376
  %766 = bitcast i16* %765 to <8 x i16>*
  %767 = load <8 x i16>, <8 x i16>* %766, align 16
  %768 = sub <8 x i16> %764, %767
  %769 = sub <8 x i16> zeroinitializer, %768
  %770 = icmp slt <8 x i16> %768, zeroinitializer
  %771 = select <8 x i1> %770, <8 x i16> %769, <8 x i16> %768
  %772 = lshr <8 x i16> %771, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %773 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %772, <8 x i16> zeroinitializer) #5
  %774 = lshr <8 x i16> %773, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %775 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %761, <8 x i16> %774) #5
  %776 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %775, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %777 = icmp slt <16 x i8> %776, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %778 = select <16 x i1> %777, <16 x i8> %776, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %779 = bitcast i8* %750 to <16 x i8>*
  store <16 x i8> %778, <16 x i8>* %779, align 16
  %780 = getelementptr inbounds i16, i16* %9, i64 384
  %781 = getelementptr inbounds i16, i16* %10, i64 384
  %782 = getelementptr inbounds i8, i8* %651, i64 %3
  %783 = bitcast i16* %780 to <8 x i16>*
  %784 = load <8 x i16>, <8 x i16>* %783, align 16
  %785 = bitcast i16* %781 to <8 x i16>*
  %786 = load <8 x i16>, <8 x i16>* %785, align 16
  %787 = sub <8 x i16> %784, %786
  %788 = sub <8 x i16> zeroinitializer, %787
  %789 = icmp slt <8 x i16> %787, zeroinitializer
  %790 = select <8 x i1> %789, <8 x i16> %788, <8 x i16> %787
  %791 = lshr <8 x i16> %790, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %792 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %791, <8 x i16> zeroinitializer) #5
  %793 = lshr <8 x i16> %792, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %794 = getelementptr inbounds i16, i16* %9, i64 392
  %795 = bitcast i16* %794 to <8 x i16>*
  %796 = load <8 x i16>, <8 x i16>* %795, align 16
  %797 = getelementptr inbounds i16, i16* %10, i64 392
  %798 = bitcast i16* %797 to <8 x i16>*
  %799 = load <8 x i16>, <8 x i16>* %798, align 16
  %800 = sub <8 x i16> %796, %799
  %801 = sub <8 x i16> zeroinitializer, %800
  %802 = icmp slt <8 x i16> %800, zeroinitializer
  %803 = select <8 x i1> %802, <8 x i16> %801, <8 x i16> %800
  %804 = lshr <8 x i16> %803, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %805 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %804, <8 x i16> zeroinitializer) #5
  %806 = lshr <8 x i16> %805, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %807 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %793, <8 x i16> %806) #5
  %808 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %807, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %809 = icmp slt <16 x i8> %808, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %810 = select <16 x i1> %809, <16 x i8> %808, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %811 = bitcast i8* %782 to <16 x i8>*
  store <16 x i8> %810, <16 x i8>* %811, align 16
  %812 = getelementptr inbounds i16, i16* %9, i64 400
  %813 = getelementptr inbounds i16, i16* %10, i64 400
  %814 = getelementptr inbounds i8, i8* %782, i64 16
  %815 = bitcast i16* %812 to <8 x i16>*
  %816 = load <8 x i16>, <8 x i16>* %815, align 16
  %817 = bitcast i16* %813 to <8 x i16>*
  %818 = load <8 x i16>, <8 x i16>* %817, align 16
  %819 = sub <8 x i16> %816, %818
  %820 = sub <8 x i16> zeroinitializer, %819
  %821 = icmp slt <8 x i16> %819, zeroinitializer
  %822 = select <8 x i1> %821, <8 x i16> %820, <8 x i16> %819
  %823 = lshr <8 x i16> %822, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %824 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %823, <8 x i16> zeroinitializer) #5
  %825 = lshr <8 x i16> %824, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %826 = getelementptr inbounds i16, i16* %9, i64 408
  %827 = bitcast i16* %826 to <8 x i16>*
  %828 = load <8 x i16>, <8 x i16>* %827, align 16
  %829 = getelementptr inbounds i16, i16* %10, i64 408
  %830 = bitcast i16* %829 to <8 x i16>*
  %831 = load <8 x i16>, <8 x i16>* %830, align 16
  %832 = sub <8 x i16> %828, %831
  %833 = sub <8 x i16> zeroinitializer, %832
  %834 = icmp slt <8 x i16> %832, zeroinitializer
  %835 = select <8 x i1> %834, <8 x i16> %833, <8 x i16> %832
  %836 = lshr <8 x i16> %835, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %837 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %836, <8 x i16> zeroinitializer) #5
  %838 = lshr <8 x i16> %837, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %839 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %825, <8 x i16> %838) #5
  %840 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %839, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %841 = icmp slt <16 x i8> %840, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %842 = select <16 x i1> %841, <16 x i8> %840, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %843 = bitcast i8* %814 to <16 x i8>*
  store <16 x i8> %842, <16 x i8>* %843, align 16
  %844 = getelementptr inbounds i16, i16* %9, i64 416
  %845 = getelementptr inbounds i16, i16* %10, i64 416
  %846 = getelementptr inbounds i8, i8* %782, i64 32
  %847 = bitcast i16* %844 to <8 x i16>*
  %848 = load <8 x i16>, <8 x i16>* %847, align 16
  %849 = bitcast i16* %845 to <8 x i16>*
  %850 = load <8 x i16>, <8 x i16>* %849, align 16
  %851 = sub <8 x i16> %848, %850
  %852 = sub <8 x i16> zeroinitializer, %851
  %853 = icmp slt <8 x i16> %851, zeroinitializer
  %854 = select <8 x i1> %853, <8 x i16> %852, <8 x i16> %851
  %855 = lshr <8 x i16> %854, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %856 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %855, <8 x i16> zeroinitializer) #5
  %857 = lshr <8 x i16> %856, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %858 = getelementptr inbounds i16, i16* %9, i64 424
  %859 = bitcast i16* %858 to <8 x i16>*
  %860 = load <8 x i16>, <8 x i16>* %859, align 16
  %861 = getelementptr inbounds i16, i16* %10, i64 424
  %862 = bitcast i16* %861 to <8 x i16>*
  %863 = load <8 x i16>, <8 x i16>* %862, align 16
  %864 = sub <8 x i16> %860, %863
  %865 = sub <8 x i16> zeroinitializer, %864
  %866 = icmp slt <8 x i16> %864, zeroinitializer
  %867 = select <8 x i1> %866, <8 x i16> %865, <8 x i16> %864
  %868 = lshr <8 x i16> %867, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %869 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %868, <8 x i16> zeroinitializer) #5
  %870 = lshr <8 x i16> %869, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %871 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %857, <8 x i16> %870) #5
  %872 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %871, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %873 = icmp slt <16 x i8> %872, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %874 = select <16 x i1> %873, <16 x i8> %872, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %875 = bitcast i8* %846 to <16 x i8>*
  store <16 x i8> %874, <16 x i8>* %875, align 16
  %876 = getelementptr inbounds i16, i16* %9, i64 432
  %877 = getelementptr inbounds i16, i16* %10, i64 432
  %878 = getelementptr inbounds i8, i8* %782, i64 48
  %879 = bitcast i16* %876 to <8 x i16>*
  %880 = load <8 x i16>, <8 x i16>* %879, align 16
  %881 = bitcast i16* %877 to <8 x i16>*
  %882 = load <8 x i16>, <8 x i16>* %881, align 16
  %883 = sub <8 x i16> %880, %882
  %884 = sub <8 x i16> zeroinitializer, %883
  %885 = icmp slt <8 x i16> %883, zeroinitializer
  %886 = select <8 x i1> %885, <8 x i16> %884, <8 x i16> %883
  %887 = lshr <8 x i16> %886, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %888 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %887, <8 x i16> zeroinitializer) #5
  %889 = lshr <8 x i16> %888, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %890 = getelementptr inbounds i16, i16* %9, i64 440
  %891 = bitcast i16* %890 to <8 x i16>*
  %892 = load <8 x i16>, <8 x i16>* %891, align 16
  %893 = getelementptr inbounds i16, i16* %10, i64 440
  %894 = bitcast i16* %893 to <8 x i16>*
  %895 = load <8 x i16>, <8 x i16>* %894, align 16
  %896 = sub <8 x i16> %892, %895
  %897 = sub <8 x i16> zeroinitializer, %896
  %898 = icmp slt <8 x i16> %896, zeroinitializer
  %899 = select <8 x i1> %898, <8 x i16> %897, <8 x i16> %896
  %900 = lshr <8 x i16> %899, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %901 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %900, <8 x i16> zeroinitializer) #5
  %902 = lshr <8 x i16> %901, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %903 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %889, <8 x i16> %902) #5
  %904 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %903, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %905 = icmp slt <16 x i8> %904, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %906 = select <16 x i1> %905, <16 x i8> %904, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %907 = bitcast i8* %878 to <16 x i8>*
  store <16 x i8> %906, <16 x i8>* %907, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask64x32_SSE4ILb1EEEvPKvS5_Phl(i8* readonly, i8* readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %671, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %669, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %670, %7 ]
  %11 = phi i32 [ 0, %4 ], [ %672, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = sub <8 x i16> %13, %15
  %17 = sub <8 x i16> zeroinitializer, %16
  %18 = icmp slt <8 x i16> %16, zeroinitializer
  %19 = select <8 x i1> %18, <8 x i16> %17, <8 x i16> %16
  %20 = lshr <8 x i16> %19, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %21 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %20, <8 x i16> zeroinitializer) #5
  %22 = lshr <8 x i16> %21, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %23 = getelementptr inbounds i16, i16* %9, i64 8
  %24 = bitcast i16* %23 to <8 x i16>*
  %25 = load <8 x i16>, <8 x i16>* %24, align 16
  %26 = getelementptr inbounds i16, i16* %10, i64 8
  %27 = bitcast i16* %26 to <8 x i16>*
  %28 = load <8 x i16>, <8 x i16>* %27, align 16
  %29 = sub <8 x i16> %25, %28
  %30 = sub <8 x i16> zeroinitializer, %29
  %31 = icmp slt <8 x i16> %29, zeroinitializer
  %32 = select <8 x i1> %31, <8 x i16> %30, <8 x i16> %29
  %33 = lshr <8 x i16> %32, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %34 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %33, <8 x i16> zeroinitializer) #5
  %35 = lshr <8 x i16> %34, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %36 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %22, <8 x i16> %35) #5
  %37 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %36, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %38 = icmp slt <16 x i8> %37, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %39 = select <16 x i1> %38, <16 x i8> %37, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %40 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %39
  %41 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %40, <16 x i8>* %41, align 16
  %42 = getelementptr inbounds i16, i16* %9, i64 16
  %43 = getelementptr inbounds i16, i16* %10, i64 16
  %44 = getelementptr inbounds i8, i8* %8, i64 16
  %45 = bitcast i16* %42 to <8 x i16>*
  %46 = load <8 x i16>, <8 x i16>* %45, align 16
  %47 = bitcast i16* %43 to <8 x i16>*
  %48 = load <8 x i16>, <8 x i16>* %47, align 16
  %49 = sub <8 x i16> %46, %48
  %50 = sub <8 x i16> zeroinitializer, %49
  %51 = icmp slt <8 x i16> %49, zeroinitializer
  %52 = select <8 x i1> %51, <8 x i16> %50, <8 x i16> %49
  %53 = lshr <8 x i16> %52, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %54 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %53, <8 x i16> zeroinitializer) #5
  %55 = lshr <8 x i16> %54, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %56 = getelementptr inbounds i16, i16* %9, i64 24
  %57 = bitcast i16* %56 to <8 x i16>*
  %58 = load <8 x i16>, <8 x i16>* %57, align 16
  %59 = getelementptr inbounds i16, i16* %10, i64 24
  %60 = bitcast i16* %59 to <8 x i16>*
  %61 = load <8 x i16>, <8 x i16>* %60, align 16
  %62 = sub <8 x i16> %58, %61
  %63 = sub <8 x i16> zeroinitializer, %62
  %64 = icmp slt <8 x i16> %62, zeroinitializer
  %65 = select <8 x i1> %64, <8 x i16> %63, <8 x i16> %62
  %66 = lshr <8 x i16> %65, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %67 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %66, <8 x i16> zeroinitializer) #5
  %68 = lshr <8 x i16> %67, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %69 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %55, <8 x i16> %68) #5
  %70 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %69, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %71 = icmp slt <16 x i8> %70, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %72 = select <16 x i1> %71, <16 x i8> %70, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %73 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %72
  %74 = bitcast i8* %44 to <16 x i8>*
  store <16 x i8> %73, <16 x i8>* %74, align 16
  %75 = getelementptr inbounds i16, i16* %9, i64 32
  %76 = getelementptr inbounds i16, i16* %10, i64 32
  %77 = getelementptr inbounds i8, i8* %8, i64 32
  %78 = bitcast i16* %75 to <8 x i16>*
  %79 = load <8 x i16>, <8 x i16>* %78, align 16
  %80 = bitcast i16* %76 to <8 x i16>*
  %81 = load <8 x i16>, <8 x i16>* %80, align 16
  %82 = sub <8 x i16> %79, %81
  %83 = sub <8 x i16> zeroinitializer, %82
  %84 = icmp slt <8 x i16> %82, zeroinitializer
  %85 = select <8 x i1> %84, <8 x i16> %83, <8 x i16> %82
  %86 = lshr <8 x i16> %85, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %87 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %86, <8 x i16> zeroinitializer) #5
  %88 = lshr <8 x i16> %87, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %89 = getelementptr inbounds i16, i16* %9, i64 40
  %90 = bitcast i16* %89 to <8 x i16>*
  %91 = load <8 x i16>, <8 x i16>* %90, align 16
  %92 = getelementptr inbounds i16, i16* %10, i64 40
  %93 = bitcast i16* %92 to <8 x i16>*
  %94 = load <8 x i16>, <8 x i16>* %93, align 16
  %95 = sub <8 x i16> %91, %94
  %96 = sub <8 x i16> zeroinitializer, %95
  %97 = icmp slt <8 x i16> %95, zeroinitializer
  %98 = select <8 x i1> %97, <8 x i16> %96, <8 x i16> %95
  %99 = lshr <8 x i16> %98, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %100 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %99, <8 x i16> zeroinitializer) #5
  %101 = lshr <8 x i16> %100, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %102 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %88, <8 x i16> %101) #5
  %103 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %102, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %104 = icmp slt <16 x i8> %103, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %105 = select <16 x i1> %104, <16 x i8> %103, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %106 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %105
  %107 = bitcast i8* %77 to <16 x i8>*
  store <16 x i8> %106, <16 x i8>* %107, align 16
  %108 = getelementptr inbounds i16, i16* %9, i64 48
  %109 = getelementptr inbounds i16, i16* %10, i64 48
  %110 = getelementptr inbounds i8, i8* %8, i64 48
  %111 = bitcast i16* %108 to <8 x i16>*
  %112 = load <8 x i16>, <8 x i16>* %111, align 16
  %113 = bitcast i16* %109 to <8 x i16>*
  %114 = load <8 x i16>, <8 x i16>* %113, align 16
  %115 = sub <8 x i16> %112, %114
  %116 = sub <8 x i16> zeroinitializer, %115
  %117 = icmp slt <8 x i16> %115, zeroinitializer
  %118 = select <8 x i1> %117, <8 x i16> %116, <8 x i16> %115
  %119 = lshr <8 x i16> %118, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %120 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %119, <8 x i16> zeroinitializer) #5
  %121 = lshr <8 x i16> %120, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %122 = getelementptr inbounds i16, i16* %9, i64 56
  %123 = bitcast i16* %122 to <8 x i16>*
  %124 = load <8 x i16>, <8 x i16>* %123, align 16
  %125 = getelementptr inbounds i16, i16* %10, i64 56
  %126 = bitcast i16* %125 to <8 x i16>*
  %127 = load <8 x i16>, <8 x i16>* %126, align 16
  %128 = sub <8 x i16> %124, %127
  %129 = sub <8 x i16> zeroinitializer, %128
  %130 = icmp slt <8 x i16> %128, zeroinitializer
  %131 = select <8 x i1> %130, <8 x i16> %129, <8 x i16> %128
  %132 = lshr <8 x i16> %131, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %133 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %132, <8 x i16> zeroinitializer) #5
  %134 = lshr <8 x i16> %133, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %135 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %121, <8 x i16> %134) #5
  %136 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %135, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %137 = icmp slt <16 x i8> %136, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %138 = select <16 x i1> %137, <16 x i8> %136, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %139 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %138
  %140 = bitcast i8* %110 to <16 x i8>*
  store <16 x i8> %139, <16 x i8>* %140, align 16
  %141 = getelementptr inbounds i16, i16* %9, i64 64
  %142 = getelementptr inbounds i16, i16* %10, i64 64
  %143 = getelementptr inbounds i8, i8* %8, i64 %3
  %144 = bitcast i16* %141 to <8 x i16>*
  %145 = load <8 x i16>, <8 x i16>* %144, align 16
  %146 = bitcast i16* %142 to <8 x i16>*
  %147 = load <8 x i16>, <8 x i16>* %146, align 16
  %148 = sub <8 x i16> %145, %147
  %149 = sub <8 x i16> zeroinitializer, %148
  %150 = icmp slt <8 x i16> %148, zeroinitializer
  %151 = select <8 x i1> %150, <8 x i16> %149, <8 x i16> %148
  %152 = lshr <8 x i16> %151, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %153 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %152, <8 x i16> zeroinitializer) #5
  %154 = lshr <8 x i16> %153, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %155 = getelementptr inbounds i16, i16* %9, i64 72
  %156 = bitcast i16* %155 to <8 x i16>*
  %157 = load <8 x i16>, <8 x i16>* %156, align 16
  %158 = getelementptr inbounds i16, i16* %10, i64 72
  %159 = bitcast i16* %158 to <8 x i16>*
  %160 = load <8 x i16>, <8 x i16>* %159, align 16
  %161 = sub <8 x i16> %157, %160
  %162 = sub <8 x i16> zeroinitializer, %161
  %163 = icmp slt <8 x i16> %161, zeroinitializer
  %164 = select <8 x i1> %163, <8 x i16> %162, <8 x i16> %161
  %165 = lshr <8 x i16> %164, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %166 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %165, <8 x i16> zeroinitializer) #5
  %167 = lshr <8 x i16> %166, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %168 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %154, <8 x i16> %167) #5
  %169 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %168, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %170 = icmp slt <16 x i8> %169, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %171 = select <16 x i1> %170, <16 x i8> %169, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %172 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %171
  %173 = bitcast i8* %143 to <16 x i8>*
  store <16 x i8> %172, <16 x i8>* %173, align 16
  %174 = getelementptr inbounds i16, i16* %9, i64 80
  %175 = getelementptr inbounds i16, i16* %10, i64 80
  %176 = getelementptr inbounds i8, i8* %143, i64 16
  %177 = bitcast i16* %174 to <8 x i16>*
  %178 = load <8 x i16>, <8 x i16>* %177, align 16
  %179 = bitcast i16* %175 to <8 x i16>*
  %180 = load <8 x i16>, <8 x i16>* %179, align 16
  %181 = sub <8 x i16> %178, %180
  %182 = sub <8 x i16> zeroinitializer, %181
  %183 = icmp slt <8 x i16> %181, zeroinitializer
  %184 = select <8 x i1> %183, <8 x i16> %182, <8 x i16> %181
  %185 = lshr <8 x i16> %184, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %186 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %185, <8 x i16> zeroinitializer) #5
  %187 = lshr <8 x i16> %186, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %188 = getelementptr inbounds i16, i16* %9, i64 88
  %189 = bitcast i16* %188 to <8 x i16>*
  %190 = load <8 x i16>, <8 x i16>* %189, align 16
  %191 = getelementptr inbounds i16, i16* %10, i64 88
  %192 = bitcast i16* %191 to <8 x i16>*
  %193 = load <8 x i16>, <8 x i16>* %192, align 16
  %194 = sub <8 x i16> %190, %193
  %195 = sub <8 x i16> zeroinitializer, %194
  %196 = icmp slt <8 x i16> %194, zeroinitializer
  %197 = select <8 x i1> %196, <8 x i16> %195, <8 x i16> %194
  %198 = lshr <8 x i16> %197, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %199 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %198, <8 x i16> zeroinitializer) #5
  %200 = lshr <8 x i16> %199, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %201 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %187, <8 x i16> %200) #5
  %202 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %201, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %203 = icmp slt <16 x i8> %202, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %204 = select <16 x i1> %203, <16 x i8> %202, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %205 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %204
  %206 = bitcast i8* %176 to <16 x i8>*
  store <16 x i8> %205, <16 x i8>* %206, align 16
  %207 = getelementptr inbounds i16, i16* %9, i64 96
  %208 = getelementptr inbounds i16, i16* %10, i64 96
  %209 = getelementptr inbounds i8, i8* %143, i64 32
  %210 = bitcast i16* %207 to <8 x i16>*
  %211 = load <8 x i16>, <8 x i16>* %210, align 16
  %212 = bitcast i16* %208 to <8 x i16>*
  %213 = load <8 x i16>, <8 x i16>* %212, align 16
  %214 = sub <8 x i16> %211, %213
  %215 = sub <8 x i16> zeroinitializer, %214
  %216 = icmp slt <8 x i16> %214, zeroinitializer
  %217 = select <8 x i1> %216, <8 x i16> %215, <8 x i16> %214
  %218 = lshr <8 x i16> %217, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %219 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %218, <8 x i16> zeroinitializer) #5
  %220 = lshr <8 x i16> %219, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %221 = getelementptr inbounds i16, i16* %9, i64 104
  %222 = bitcast i16* %221 to <8 x i16>*
  %223 = load <8 x i16>, <8 x i16>* %222, align 16
  %224 = getelementptr inbounds i16, i16* %10, i64 104
  %225 = bitcast i16* %224 to <8 x i16>*
  %226 = load <8 x i16>, <8 x i16>* %225, align 16
  %227 = sub <8 x i16> %223, %226
  %228 = sub <8 x i16> zeroinitializer, %227
  %229 = icmp slt <8 x i16> %227, zeroinitializer
  %230 = select <8 x i1> %229, <8 x i16> %228, <8 x i16> %227
  %231 = lshr <8 x i16> %230, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %232 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %231, <8 x i16> zeroinitializer) #5
  %233 = lshr <8 x i16> %232, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %234 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %220, <8 x i16> %233) #5
  %235 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %234, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %236 = icmp slt <16 x i8> %235, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %237 = select <16 x i1> %236, <16 x i8> %235, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %238 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %237
  %239 = bitcast i8* %209 to <16 x i8>*
  store <16 x i8> %238, <16 x i8>* %239, align 16
  %240 = getelementptr inbounds i16, i16* %9, i64 112
  %241 = getelementptr inbounds i16, i16* %10, i64 112
  %242 = getelementptr inbounds i8, i8* %143, i64 48
  %243 = bitcast i16* %240 to <8 x i16>*
  %244 = load <8 x i16>, <8 x i16>* %243, align 16
  %245 = bitcast i16* %241 to <8 x i16>*
  %246 = load <8 x i16>, <8 x i16>* %245, align 16
  %247 = sub <8 x i16> %244, %246
  %248 = sub <8 x i16> zeroinitializer, %247
  %249 = icmp slt <8 x i16> %247, zeroinitializer
  %250 = select <8 x i1> %249, <8 x i16> %248, <8 x i16> %247
  %251 = lshr <8 x i16> %250, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %252 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %251, <8 x i16> zeroinitializer) #5
  %253 = lshr <8 x i16> %252, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %254 = getelementptr inbounds i16, i16* %9, i64 120
  %255 = bitcast i16* %254 to <8 x i16>*
  %256 = load <8 x i16>, <8 x i16>* %255, align 16
  %257 = getelementptr inbounds i16, i16* %10, i64 120
  %258 = bitcast i16* %257 to <8 x i16>*
  %259 = load <8 x i16>, <8 x i16>* %258, align 16
  %260 = sub <8 x i16> %256, %259
  %261 = sub <8 x i16> zeroinitializer, %260
  %262 = icmp slt <8 x i16> %260, zeroinitializer
  %263 = select <8 x i1> %262, <8 x i16> %261, <8 x i16> %260
  %264 = lshr <8 x i16> %263, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %265 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %264, <8 x i16> zeroinitializer) #5
  %266 = lshr <8 x i16> %265, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %267 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %253, <8 x i16> %266) #5
  %268 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %267, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %269 = icmp slt <16 x i8> %268, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %270 = select <16 x i1> %269, <16 x i8> %268, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %271 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %270
  %272 = bitcast i8* %242 to <16 x i8>*
  store <16 x i8> %271, <16 x i8>* %272, align 16
  %273 = getelementptr inbounds i16, i16* %9, i64 128
  %274 = getelementptr inbounds i16, i16* %10, i64 128
  %275 = getelementptr inbounds i8, i8* %143, i64 %3
  %276 = bitcast i16* %273 to <8 x i16>*
  %277 = load <8 x i16>, <8 x i16>* %276, align 16
  %278 = bitcast i16* %274 to <8 x i16>*
  %279 = load <8 x i16>, <8 x i16>* %278, align 16
  %280 = sub <8 x i16> %277, %279
  %281 = sub <8 x i16> zeroinitializer, %280
  %282 = icmp slt <8 x i16> %280, zeroinitializer
  %283 = select <8 x i1> %282, <8 x i16> %281, <8 x i16> %280
  %284 = lshr <8 x i16> %283, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %285 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %284, <8 x i16> zeroinitializer) #5
  %286 = lshr <8 x i16> %285, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %287 = getelementptr inbounds i16, i16* %9, i64 136
  %288 = bitcast i16* %287 to <8 x i16>*
  %289 = load <8 x i16>, <8 x i16>* %288, align 16
  %290 = getelementptr inbounds i16, i16* %10, i64 136
  %291 = bitcast i16* %290 to <8 x i16>*
  %292 = load <8 x i16>, <8 x i16>* %291, align 16
  %293 = sub <8 x i16> %289, %292
  %294 = sub <8 x i16> zeroinitializer, %293
  %295 = icmp slt <8 x i16> %293, zeroinitializer
  %296 = select <8 x i1> %295, <8 x i16> %294, <8 x i16> %293
  %297 = lshr <8 x i16> %296, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %298 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %297, <8 x i16> zeroinitializer) #5
  %299 = lshr <8 x i16> %298, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %300 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %286, <8 x i16> %299) #5
  %301 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %300, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %302 = icmp slt <16 x i8> %301, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %303 = select <16 x i1> %302, <16 x i8> %301, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %304 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %303
  %305 = bitcast i8* %275 to <16 x i8>*
  store <16 x i8> %304, <16 x i8>* %305, align 16
  %306 = getelementptr inbounds i16, i16* %9, i64 144
  %307 = getelementptr inbounds i16, i16* %10, i64 144
  %308 = getelementptr inbounds i8, i8* %275, i64 16
  %309 = bitcast i16* %306 to <8 x i16>*
  %310 = load <8 x i16>, <8 x i16>* %309, align 16
  %311 = bitcast i16* %307 to <8 x i16>*
  %312 = load <8 x i16>, <8 x i16>* %311, align 16
  %313 = sub <8 x i16> %310, %312
  %314 = sub <8 x i16> zeroinitializer, %313
  %315 = icmp slt <8 x i16> %313, zeroinitializer
  %316 = select <8 x i1> %315, <8 x i16> %314, <8 x i16> %313
  %317 = lshr <8 x i16> %316, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %318 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %317, <8 x i16> zeroinitializer) #5
  %319 = lshr <8 x i16> %318, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %320 = getelementptr inbounds i16, i16* %9, i64 152
  %321 = bitcast i16* %320 to <8 x i16>*
  %322 = load <8 x i16>, <8 x i16>* %321, align 16
  %323 = getelementptr inbounds i16, i16* %10, i64 152
  %324 = bitcast i16* %323 to <8 x i16>*
  %325 = load <8 x i16>, <8 x i16>* %324, align 16
  %326 = sub <8 x i16> %322, %325
  %327 = sub <8 x i16> zeroinitializer, %326
  %328 = icmp slt <8 x i16> %326, zeroinitializer
  %329 = select <8 x i1> %328, <8 x i16> %327, <8 x i16> %326
  %330 = lshr <8 x i16> %329, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %331 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %330, <8 x i16> zeroinitializer) #5
  %332 = lshr <8 x i16> %331, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %333 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %319, <8 x i16> %332) #5
  %334 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %333, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %335 = icmp slt <16 x i8> %334, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %336 = select <16 x i1> %335, <16 x i8> %334, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %337 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %336
  %338 = bitcast i8* %308 to <16 x i8>*
  store <16 x i8> %337, <16 x i8>* %338, align 16
  %339 = getelementptr inbounds i16, i16* %9, i64 160
  %340 = getelementptr inbounds i16, i16* %10, i64 160
  %341 = getelementptr inbounds i8, i8* %275, i64 32
  %342 = bitcast i16* %339 to <8 x i16>*
  %343 = load <8 x i16>, <8 x i16>* %342, align 16
  %344 = bitcast i16* %340 to <8 x i16>*
  %345 = load <8 x i16>, <8 x i16>* %344, align 16
  %346 = sub <8 x i16> %343, %345
  %347 = sub <8 x i16> zeroinitializer, %346
  %348 = icmp slt <8 x i16> %346, zeroinitializer
  %349 = select <8 x i1> %348, <8 x i16> %347, <8 x i16> %346
  %350 = lshr <8 x i16> %349, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %351 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %350, <8 x i16> zeroinitializer) #5
  %352 = lshr <8 x i16> %351, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %353 = getelementptr inbounds i16, i16* %9, i64 168
  %354 = bitcast i16* %353 to <8 x i16>*
  %355 = load <8 x i16>, <8 x i16>* %354, align 16
  %356 = getelementptr inbounds i16, i16* %10, i64 168
  %357 = bitcast i16* %356 to <8 x i16>*
  %358 = load <8 x i16>, <8 x i16>* %357, align 16
  %359 = sub <8 x i16> %355, %358
  %360 = sub <8 x i16> zeroinitializer, %359
  %361 = icmp slt <8 x i16> %359, zeroinitializer
  %362 = select <8 x i1> %361, <8 x i16> %360, <8 x i16> %359
  %363 = lshr <8 x i16> %362, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %364 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %363, <8 x i16> zeroinitializer) #5
  %365 = lshr <8 x i16> %364, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %366 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %352, <8 x i16> %365) #5
  %367 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %366, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %368 = icmp slt <16 x i8> %367, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %369 = select <16 x i1> %368, <16 x i8> %367, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %370 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %369
  %371 = bitcast i8* %341 to <16 x i8>*
  store <16 x i8> %370, <16 x i8>* %371, align 16
  %372 = getelementptr inbounds i16, i16* %9, i64 176
  %373 = getelementptr inbounds i16, i16* %10, i64 176
  %374 = getelementptr inbounds i8, i8* %275, i64 48
  %375 = bitcast i16* %372 to <8 x i16>*
  %376 = load <8 x i16>, <8 x i16>* %375, align 16
  %377 = bitcast i16* %373 to <8 x i16>*
  %378 = load <8 x i16>, <8 x i16>* %377, align 16
  %379 = sub <8 x i16> %376, %378
  %380 = sub <8 x i16> zeroinitializer, %379
  %381 = icmp slt <8 x i16> %379, zeroinitializer
  %382 = select <8 x i1> %381, <8 x i16> %380, <8 x i16> %379
  %383 = lshr <8 x i16> %382, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %384 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %383, <8 x i16> zeroinitializer) #5
  %385 = lshr <8 x i16> %384, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %386 = getelementptr inbounds i16, i16* %9, i64 184
  %387 = bitcast i16* %386 to <8 x i16>*
  %388 = load <8 x i16>, <8 x i16>* %387, align 16
  %389 = getelementptr inbounds i16, i16* %10, i64 184
  %390 = bitcast i16* %389 to <8 x i16>*
  %391 = load <8 x i16>, <8 x i16>* %390, align 16
  %392 = sub <8 x i16> %388, %391
  %393 = sub <8 x i16> zeroinitializer, %392
  %394 = icmp slt <8 x i16> %392, zeroinitializer
  %395 = select <8 x i1> %394, <8 x i16> %393, <8 x i16> %392
  %396 = lshr <8 x i16> %395, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %397 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %396, <8 x i16> zeroinitializer) #5
  %398 = lshr <8 x i16> %397, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %399 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %385, <8 x i16> %398) #5
  %400 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %399, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %401 = icmp slt <16 x i8> %400, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %402 = select <16 x i1> %401, <16 x i8> %400, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %403 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %402
  %404 = bitcast i8* %374 to <16 x i8>*
  store <16 x i8> %403, <16 x i8>* %404, align 16
  %405 = getelementptr inbounds i16, i16* %9, i64 192
  %406 = getelementptr inbounds i16, i16* %10, i64 192
  %407 = getelementptr inbounds i8, i8* %275, i64 %3
  %408 = bitcast i16* %405 to <8 x i16>*
  %409 = load <8 x i16>, <8 x i16>* %408, align 16
  %410 = bitcast i16* %406 to <8 x i16>*
  %411 = load <8 x i16>, <8 x i16>* %410, align 16
  %412 = sub <8 x i16> %409, %411
  %413 = sub <8 x i16> zeroinitializer, %412
  %414 = icmp slt <8 x i16> %412, zeroinitializer
  %415 = select <8 x i1> %414, <8 x i16> %413, <8 x i16> %412
  %416 = lshr <8 x i16> %415, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %417 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %416, <8 x i16> zeroinitializer) #5
  %418 = lshr <8 x i16> %417, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %419 = getelementptr inbounds i16, i16* %9, i64 200
  %420 = bitcast i16* %419 to <8 x i16>*
  %421 = load <8 x i16>, <8 x i16>* %420, align 16
  %422 = getelementptr inbounds i16, i16* %10, i64 200
  %423 = bitcast i16* %422 to <8 x i16>*
  %424 = load <8 x i16>, <8 x i16>* %423, align 16
  %425 = sub <8 x i16> %421, %424
  %426 = sub <8 x i16> zeroinitializer, %425
  %427 = icmp slt <8 x i16> %425, zeroinitializer
  %428 = select <8 x i1> %427, <8 x i16> %426, <8 x i16> %425
  %429 = lshr <8 x i16> %428, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %430 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %429, <8 x i16> zeroinitializer) #5
  %431 = lshr <8 x i16> %430, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %432 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %418, <8 x i16> %431) #5
  %433 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %432, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %434 = icmp slt <16 x i8> %433, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %435 = select <16 x i1> %434, <16 x i8> %433, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %436 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %435
  %437 = bitcast i8* %407 to <16 x i8>*
  store <16 x i8> %436, <16 x i8>* %437, align 16
  %438 = getelementptr inbounds i16, i16* %9, i64 208
  %439 = getelementptr inbounds i16, i16* %10, i64 208
  %440 = getelementptr inbounds i8, i8* %407, i64 16
  %441 = bitcast i16* %438 to <8 x i16>*
  %442 = load <8 x i16>, <8 x i16>* %441, align 16
  %443 = bitcast i16* %439 to <8 x i16>*
  %444 = load <8 x i16>, <8 x i16>* %443, align 16
  %445 = sub <8 x i16> %442, %444
  %446 = sub <8 x i16> zeroinitializer, %445
  %447 = icmp slt <8 x i16> %445, zeroinitializer
  %448 = select <8 x i1> %447, <8 x i16> %446, <8 x i16> %445
  %449 = lshr <8 x i16> %448, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %450 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %449, <8 x i16> zeroinitializer) #5
  %451 = lshr <8 x i16> %450, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %452 = getelementptr inbounds i16, i16* %9, i64 216
  %453 = bitcast i16* %452 to <8 x i16>*
  %454 = load <8 x i16>, <8 x i16>* %453, align 16
  %455 = getelementptr inbounds i16, i16* %10, i64 216
  %456 = bitcast i16* %455 to <8 x i16>*
  %457 = load <8 x i16>, <8 x i16>* %456, align 16
  %458 = sub <8 x i16> %454, %457
  %459 = sub <8 x i16> zeroinitializer, %458
  %460 = icmp slt <8 x i16> %458, zeroinitializer
  %461 = select <8 x i1> %460, <8 x i16> %459, <8 x i16> %458
  %462 = lshr <8 x i16> %461, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %463 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %462, <8 x i16> zeroinitializer) #5
  %464 = lshr <8 x i16> %463, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %465 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %451, <8 x i16> %464) #5
  %466 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %465, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %467 = icmp slt <16 x i8> %466, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %468 = select <16 x i1> %467, <16 x i8> %466, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %469 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %468
  %470 = bitcast i8* %440 to <16 x i8>*
  store <16 x i8> %469, <16 x i8>* %470, align 16
  %471 = getelementptr inbounds i16, i16* %9, i64 224
  %472 = getelementptr inbounds i16, i16* %10, i64 224
  %473 = getelementptr inbounds i8, i8* %407, i64 32
  %474 = bitcast i16* %471 to <8 x i16>*
  %475 = load <8 x i16>, <8 x i16>* %474, align 16
  %476 = bitcast i16* %472 to <8 x i16>*
  %477 = load <8 x i16>, <8 x i16>* %476, align 16
  %478 = sub <8 x i16> %475, %477
  %479 = sub <8 x i16> zeroinitializer, %478
  %480 = icmp slt <8 x i16> %478, zeroinitializer
  %481 = select <8 x i1> %480, <8 x i16> %479, <8 x i16> %478
  %482 = lshr <8 x i16> %481, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %483 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %482, <8 x i16> zeroinitializer) #5
  %484 = lshr <8 x i16> %483, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %485 = getelementptr inbounds i16, i16* %9, i64 232
  %486 = bitcast i16* %485 to <8 x i16>*
  %487 = load <8 x i16>, <8 x i16>* %486, align 16
  %488 = getelementptr inbounds i16, i16* %10, i64 232
  %489 = bitcast i16* %488 to <8 x i16>*
  %490 = load <8 x i16>, <8 x i16>* %489, align 16
  %491 = sub <8 x i16> %487, %490
  %492 = sub <8 x i16> zeroinitializer, %491
  %493 = icmp slt <8 x i16> %491, zeroinitializer
  %494 = select <8 x i1> %493, <8 x i16> %492, <8 x i16> %491
  %495 = lshr <8 x i16> %494, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %496 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %495, <8 x i16> zeroinitializer) #5
  %497 = lshr <8 x i16> %496, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %498 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %484, <8 x i16> %497) #5
  %499 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %498, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %500 = icmp slt <16 x i8> %499, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %501 = select <16 x i1> %500, <16 x i8> %499, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %502 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %501
  %503 = bitcast i8* %473 to <16 x i8>*
  store <16 x i8> %502, <16 x i8>* %503, align 16
  %504 = getelementptr inbounds i16, i16* %9, i64 240
  %505 = getelementptr inbounds i16, i16* %10, i64 240
  %506 = getelementptr inbounds i8, i8* %407, i64 48
  %507 = bitcast i16* %504 to <8 x i16>*
  %508 = load <8 x i16>, <8 x i16>* %507, align 16
  %509 = bitcast i16* %505 to <8 x i16>*
  %510 = load <8 x i16>, <8 x i16>* %509, align 16
  %511 = sub <8 x i16> %508, %510
  %512 = sub <8 x i16> zeroinitializer, %511
  %513 = icmp slt <8 x i16> %511, zeroinitializer
  %514 = select <8 x i1> %513, <8 x i16> %512, <8 x i16> %511
  %515 = lshr <8 x i16> %514, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %516 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %515, <8 x i16> zeroinitializer) #5
  %517 = lshr <8 x i16> %516, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %518 = getelementptr inbounds i16, i16* %9, i64 248
  %519 = bitcast i16* %518 to <8 x i16>*
  %520 = load <8 x i16>, <8 x i16>* %519, align 16
  %521 = getelementptr inbounds i16, i16* %10, i64 248
  %522 = bitcast i16* %521 to <8 x i16>*
  %523 = load <8 x i16>, <8 x i16>* %522, align 16
  %524 = sub <8 x i16> %520, %523
  %525 = sub <8 x i16> zeroinitializer, %524
  %526 = icmp slt <8 x i16> %524, zeroinitializer
  %527 = select <8 x i1> %526, <8 x i16> %525, <8 x i16> %524
  %528 = lshr <8 x i16> %527, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %529 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %528, <8 x i16> zeroinitializer) #5
  %530 = lshr <8 x i16> %529, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %531 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %517, <8 x i16> %530) #5
  %532 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %531, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %533 = icmp slt <16 x i8> %532, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %534 = select <16 x i1> %533, <16 x i8> %532, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %535 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %534
  %536 = bitcast i8* %506 to <16 x i8>*
  store <16 x i8> %535, <16 x i8>* %536, align 16
  %537 = getelementptr inbounds i16, i16* %9, i64 256
  %538 = getelementptr inbounds i16, i16* %10, i64 256
  %539 = getelementptr inbounds i8, i8* %407, i64 %3
  %540 = bitcast i16* %537 to <8 x i16>*
  %541 = load <8 x i16>, <8 x i16>* %540, align 16
  %542 = bitcast i16* %538 to <8 x i16>*
  %543 = load <8 x i16>, <8 x i16>* %542, align 16
  %544 = sub <8 x i16> %541, %543
  %545 = sub <8 x i16> zeroinitializer, %544
  %546 = icmp slt <8 x i16> %544, zeroinitializer
  %547 = select <8 x i1> %546, <8 x i16> %545, <8 x i16> %544
  %548 = lshr <8 x i16> %547, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %549 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %548, <8 x i16> zeroinitializer) #5
  %550 = lshr <8 x i16> %549, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %551 = getelementptr inbounds i16, i16* %9, i64 264
  %552 = bitcast i16* %551 to <8 x i16>*
  %553 = load <8 x i16>, <8 x i16>* %552, align 16
  %554 = getelementptr inbounds i16, i16* %10, i64 264
  %555 = bitcast i16* %554 to <8 x i16>*
  %556 = load <8 x i16>, <8 x i16>* %555, align 16
  %557 = sub <8 x i16> %553, %556
  %558 = sub <8 x i16> zeroinitializer, %557
  %559 = icmp slt <8 x i16> %557, zeroinitializer
  %560 = select <8 x i1> %559, <8 x i16> %558, <8 x i16> %557
  %561 = lshr <8 x i16> %560, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %562 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %561, <8 x i16> zeroinitializer) #5
  %563 = lshr <8 x i16> %562, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %564 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %550, <8 x i16> %563) #5
  %565 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %564, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %566 = icmp slt <16 x i8> %565, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %567 = select <16 x i1> %566, <16 x i8> %565, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %568 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %567
  %569 = bitcast i8* %539 to <16 x i8>*
  store <16 x i8> %568, <16 x i8>* %569, align 16
  %570 = getelementptr inbounds i16, i16* %9, i64 272
  %571 = getelementptr inbounds i16, i16* %10, i64 272
  %572 = getelementptr inbounds i8, i8* %539, i64 16
  %573 = bitcast i16* %570 to <8 x i16>*
  %574 = load <8 x i16>, <8 x i16>* %573, align 16
  %575 = bitcast i16* %571 to <8 x i16>*
  %576 = load <8 x i16>, <8 x i16>* %575, align 16
  %577 = sub <8 x i16> %574, %576
  %578 = sub <8 x i16> zeroinitializer, %577
  %579 = icmp slt <8 x i16> %577, zeroinitializer
  %580 = select <8 x i1> %579, <8 x i16> %578, <8 x i16> %577
  %581 = lshr <8 x i16> %580, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %582 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %581, <8 x i16> zeroinitializer) #5
  %583 = lshr <8 x i16> %582, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %584 = getelementptr inbounds i16, i16* %9, i64 280
  %585 = bitcast i16* %584 to <8 x i16>*
  %586 = load <8 x i16>, <8 x i16>* %585, align 16
  %587 = getelementptr inbounds i16, i16* %10, i64 280
  %588 = bitcast i16* %587 to <8 x i16>*
  %589 = load <8 x i16>, <8 x i16>* %588, align 16
  %590 = sub <8 x i16> %586, %589
  %591 = sub <8 x i16> zeroinitializer, %590
  %592 = icmp slt <8 x i16> %590, zeroinitializer
  %593 = select <8 x i1> %592, <8 x i16> %591, <8 x i16> %590
  %594 = lshr <8 x i16> %593, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %595 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %594, <8 x i16> zeroinitializer) #5
  %596 = lshr <8 x i16> %595, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %597 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %583, <8 x i16> %596) #5
  %598 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %597, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %599 = icmp slt <16 x i8> %598, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %600 = select <16 x i1> %599, <16 x i8> %598, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %601 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %600
  %602 = bitcast i8* %572 to <16 x i8>*
  store <16 x i8> %601, <16 x i8>* %602, align 16
  %603 = getelementptr inbounds i16, i16* %9, i64 288
  %604 = getelementptr inbounds i16, i16* %10, i64 288
  %605 = getelementptr inbounds i8, i8* %539, i64 32
  %606 = bitcast i16* %603 to <8 x i16>*
  %607 = load <8 x i16>, <8 x i16>* %606, align 16
  %608 = bitcast i16* %604 to <8 x i16>*
  %609 = load <8 x i16>, <8 x i16>* %608, align 16
  %610 = sub <8 x i16> %607, %609
  %611 = sub <8 x i16> zeroinitializer, %610
  %612 = icmp slt <8 x i16> %610, zeroinitializer
  %613 = select <8 x i1> %612, <8 x i16> %611, <8 x i16> %610
  %614 = lshr <8 x i16> %613, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %615 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %614, <8 x i16> zeroinitializer) #5
  %616 = lshr <8 x i16> %615, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %617 = getelementptr inbounds i16, i16* %9, i64 296
  %618 = bitcast i16* %617 to <8 x i16>*
  %619 = load <8 x i16>, <8 x i16>* %618, align 16
  %620 = getelementptr inbounds i16, i16* %10, i64 296
  %621 = bitcast i16* %620 to <8 x i16>*
  %622 = load <8 x i16>, <8 x i16>* %621, align 16
  %623 = sub <8 x i16> %619, %622
  %624 = sub <8 x i16> zeroinitializer, %623
  %625 = icmp slt <8 x i16> %623, zeroinitializer
  %626 = select <8 x i1> %625, <8 x i16> %624, <8 x i16> %623
  %627 = lshr <8 x i16> %626, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %628 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %627, <8 x i16> zeroinitializer) #5
  %629 = lshr <8 x i16> %628, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %630 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %616, <8 x i16> %629) #5
  %631 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %630, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %632 = icmp slt <16 x i8> %631, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %633 = select <16 x i1> %632, <16 x i8> %631, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %634 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %633
  %635 = bitcast i8* %605 to <16 x i8>*
  store <16 x i8> %634, <16 x i8>* %635, align 16
  %636 = getelementptr inbounds i16, i16* %9, i64 304
  %637 = getelementptr inbounds i16, i16* %10, i64 304
  %638 = getelementptr inbounds i8, i8* %539, i64 48
  %639 = bitcast i16* %636 to <8 x i16>*
  %640 = load <8 x i16>, <8 x i16>* %639, align 16
  %641 = bitcast i16* %637 to <8 x i16>*
  %642 = load <8 x i16>, <8 x i16>* %641, align 16
  %643 = sub <8 x i16> %640, %642
  %644 = sub <8 x i16> zeroinitializer, %643
  %645 = icmp slt <8 x i16> %643, zeroinitializer
  %646 = select <8 x i1> %645, <8 x i16> %644, <8 x i16> %643
  %647 = lshr <8 x i16> %646, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %648 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %647, <8 x i16> zeroinitializer) #5
  %649 = lshr <8 x i16> %648, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %650 = getelementptr inbounds i16, i16* %9, i64 312
  %651 = bitcast i16* %650 to <8 x i16>*
  %652 = load <8 x i16>, <8 x i16>* %651, align 16
  %653 = getelementptr inbounds i16, i16* %10, i64 312
  %654 = bitcast i16* %653 to <8 x i16>*
  %655 = load <8 x i16>, <8 x i16>* %654, align 16
  %656 = sub <8 x i16> %652, %655
  %657 = sub <8 x i16> zeroinitializer, %656
  %658 = icmp slt <8 x i16> %656, zeroinitializer
  %659 = select <8 x i1> %658, <8 x i16> %657, <8 x i16> %656
  %660 = lshr <8 x i16> %659, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %661 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %660, <8 x i16> zeroinitializer) #5
  %662 = lshr <8 x i16> %661, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %663 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %649, <8 x i16> %662) #5
  %664 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %663, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %665 = icmp slt <16 x i8> %664, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %666 = select <16 x i1> %665, <16 x i8> %664, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %667 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %666
  %668 = bitcast i8* %638 to <16 x i8>*
  store <16 x i8> %667, <16 x i8>* %668, align 16
  %669 = getelementptr inbounds i16, i16* %9, i64 320
  %670 = getelementptr inbounds i16, i16* %10, i64 320
  %671 = getelementptr inbounds i8, i8* %539, i64 %3
  %672 = add nuw nsw i32 %11, 1
  %673 = icmp eq i32 %672, 6
  br i1 %673, label %674, label %7

674:                                              ; preds = %7
  %675 = bitcast i16* %669 to <8 x i16>*
  %676 = load <8 x i16>, <8 x i16>* %675, align 16
  %677 = bitcast i16* %670 to <8 x i16>*
  %678 = load <8 x i16>, <8 x i16>* %677, align 16
  %679 = sub <8 x i16> %676, %678
  %680 = sub <8 x i16> zeroinitializer, %679
  %681 = icmp slt <8 x i16> %679, zeroinitializer
  %682 = select <8 x i1> %681, <8 x i16> %680, <8 x i16> %679
  %683 = lshr <8 x i16> %682, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %684 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %683, <8 x i16> zeroinitializer) #5
  %685 = lshr <8 x i16> %684, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %686 = getelementptr inbounds i16, i16* %9, i64 328
  %687 = bitcast i16* %686 to <8 x i16>*
  %688 = load <8 x i16>, <8 x i16>* %687, align 16
  %689 = getelementptr inbounds i16, i16* %10, i64 328
  %690 = bitcast i16* %689 to <8 x i16>*
  %691 = load <8 x i16>, <8 x i16>* %690, align 16
  %692 = sub <8 x i16> %688, %691
  %693 = sub <8 x i16> zeroinitializer, %692
  %694 = icmp slt <8 x i16> %692, zeroinitializer
  %695 = select <8 x i1> %694, <8 x i16> %693, <8 x i16> %692
  %696 = lshr <8 x i16> %695, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %697 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %696, <8 x i16> zeroinitializer) #5
  %698 = lshr <8 x i16> %697, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %699 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %685, <8 x i16> %698) #5
  %700 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %699, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %701 = icmp slt <16 x i8> %700, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %702 = select <16 x i1> %701, <16 x i8> %700, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %703 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %702
  %704 = bitcast i8* %671 to <16 x i8>*
  store <16 x i8> %703, <16 x i8>* %704, align 16
  %705 = getelementptr inbounds i16, i16* %9, i64 336
  %706 = getelementptr inbounds i16, i16* %10, i64 336
  %707 = getelementptr inbounds i8, i8* %671, i64 16
  %708 = bitcast i16* %705 to <8 x i16>*
  %709 = load <8 x i16>, <8 x i16>* %708, align 16
  %710 = bitcast i16* %706 to <8 x i16>*
  %711 = load <8 x i16>, <8 x i16>* %710, align 16
  %712 = sub <8 x i16> %709, %711
  %713 = sub <8 x i16> zeroinitializer, %712
  %714 = icmp slt <8 x i16> %712, zeroinitializer
  %715 = select <8 x i1> %714, <8 x i16> %713, <8 x i16> %712
  %716 = lshr <8 x i16> %715, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %717 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %716, <8 x i16> zeroinitializer) #5
  %718 = lshr <8 x i16> %717, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %719 = getelementptr inbounds i16, i16* %9, i64 344
  %720 = bitcast i16* %719 to <8 x i16>*
  %721 = load <8 x i16>, <8 x i16>* %720, align 16
  %722 = getelementptr inbounds i16, i16* %10, i64 344
  %723 = bitcast i16* %722 to <8 x i16>*
  %724 = load <8 x i16>, <8 x i16>* %723, align 16
  %725 = sub <8 x i16> %721, %724
  %726 = sub <8 x i16> zeroinitializer, %725
  %727 = icmp slt <8 x i16> %725, zeroinitializer
  %728 = select <8 x i1> %727, <8 x i16> %726, <8 x i16> %725
  %729 = lshr <8 x i16> %728, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %730 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %729, <8 x i16> zeroinitializer) #5
  %731 = lshr <8 x i16> %730, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %732 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %718, <8 x i16> %731) #5
  %733 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %732, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %734 = icmp slt <16 x i8> %733, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %735 = select <16 x i1> %734, <16 x i8> %733, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %736 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %735
  %737 = bitcast i8* %707 to <16 x i8>*
  store <16 x i8> %736, <16 x i8>* %737, align 16
  %738 = getelementptr inbounds i16, i16* %9, i64 352
  %739 = getelementptr inbounds i16, i16* %10, i64 352
  %740 = getelementptr inbounds i8, i8* %671, i64 32
  %741 = bitcast i16* %738 to <8 x i16>*
  %742 = load <8 x i16>, <8 x i16>* %741, align 16
  %743 = bitcast i16* %739 to <8 x i16>*
  %744 = load <8 x i16>, <8 x i16>* %743, align 16
  %745 = sub <8 x i16> %742, %744
  %746 = sub <8 x i16> zeroinitializer, %745
  %747 = icmp slt <8 x i16> %745, zeroinitializer
  %748 = select <8 x i1> %747, <8 x i16> %746, <8 x i16> %745
  %749 = lshr <8 x i16> %748, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %750 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %749, <8 x i16> zeroinitializer) #5
  %751 = lshr <8 x i16> %750, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %752 = getelementptr inbounds i16, i16* %9, i64 360
  %753 = bitcast i16* %752 to <8 x i16>*
  %754 = load <8 x i16>, <8 x i16>* %753, align 16
  %755 = getelementptr inbounds i16, i16* %10, i64 360
  %756 = bitcast i16* %755 to <8 x i16>*
  %757 = load <8 x i16>, <8 x i16>* %756, align 16
  %758 = sub <8 x i16> %754, %757
  %759 = sub <8 x i16> zeroinitializer, %758
  %760 = icmp slt <8 x i16> %758, zeroinitializer
  %761 = select <8 x i1> %760, <8 x i16> %759, <8 x i16> %758
  %762 = lshr <8 x i16> %761, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %763 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %762, <8 x i16> zeroinitializer) #5
  %764 = lshr <8 x i16> %763, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %765 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %751, <8 x i16> %764) #5
  %766 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %765, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %767 = icmp slt <16 x i8> %766, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %768 = select <16 x i1> %767, <16 x i8> %766, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %769 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %768
  %770 = bitcast i8* %740 to <16 x i8>*
  store <16 x i8> %769, <16 x i8>* %770, align 16
  %771 = getelementptr inbounds i16, i16* %9, i64 368
  %772 = getelementptr inbounds i16, i16* %10, i64 368
  %773 = getelementptr inbounds i8, i8* %671, i64 48
  %774 = bitcast i16* %771 to <8 x i16>*
  %775 = load <8 x i16>, <8 x i16>* %774, align 16
  %776 = bitcast i16* %772 to <8 x i16>*
  %777 = load <8 x i16>, <8 x i16>* %776, align 16
  %778 = sub <8 x i16> %775, %777
  %779 = sub <8 x i16> zeroinitializer, %778
  %780 = icmp slt <8 x i16> %778, zeroinitializer
  %781 = select <8 x i1> %780, <8 x i16> %779, <8 x i16> %778
  %782 = lshr <8 x i16> %781, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %783 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %782, <8 x i16> zeroinitializer) #5
  %784 = lshr <8 x i16> %783, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %785 = getelementptr inbounds i16, i16* %9, i64 376
  %786 = bitcast i16* %785 to <8 x i16>*
  %787 = load <8 x i16>, <8 x i16>* %786, align 16
  %788 = getelementptr inbounds i16, i16* %10, i64 376
  %789 = bitcast i16* %788 to <8 x i16>*
  %790 = load <8 x i16>, <8 x i16>* %789, align 16
  %791 = sub <8 x i16> %787, %790
  %792 = sub <8 x i16> zeroinitializer, %791
  %793 = icmp slt <8 x i16> %791, zeroinitializer
  %794 = select <8 x i1> %793, <8 x i16> %792, <8 x i16> %791
  %795 = lshr <8 x i16> %794, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %796 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %795, <8 x i16> zeroinitializer) #5
  %797 = lshr <8 x i16> %796, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %798 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %784, <8 x i16> %797) #5
  %799 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %798, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %800 = icmp slt <16 x i8> %799, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %801 = select <16 x i1> %800, <16 x i8> %799, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %802 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %801
  %803 = bitcast i8* %773 to <16 x i8>*
  store <16 x i8> %802, <16 x i8>* %803, align 16
  %804 = getelementptr inbounds i16, i16* %9, i64 384
  %805 = getelementptr inbounds i16, i16* %10, i64 384
  %806 = getelementptr inbounds i8, i8* %671, i64 %3
  %807 = bitcast i16* %804 to <8 x i16>*
  %808 = load <8 x i16>, <8 x i16>* %807, align 16
  %809 = bitcast i16* %805 to <8 x i16>*
  %810 = load <8 x i16>, <8 x i16>* %809, align 16
  %811 = sub <8 x i16> %808, %810
  %812 = sub <8 x i16> zeroinitializer, %811
  %813 = icmp slt <8 x i16> %811, zeroinitializer
  %814 = select <8 x i1> %813, <8 x i16> %812, <8 x i16> %811
  %815 = lshr <8 x i16> %814, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %816 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %815, <8 x i16> zeroinitializer) #5
  %817 = lshr <8 x i16> %816, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %818 = getelementptr inbounds i16, i16* %9, i64 392
  %819 = bitcast i16* %818 to <8 x i16>*
  %820 = load <8 x i16>, <8 x i16>* %819, align 16
  %821 = getelementptr inbounds i16, i16* %10, i64 392
  %822 = bitcast i16* %821 to <8 x i16>*
  %823 = load <8 x i16>, <8 x i16>* %822, align 16
  %824 = sub <8 x i16> %820, %823
  %825 = sub <8 x i16> zeroinitializer, %824
  %826 = icmp slt <8 x i16> %824, zeroinitializer
  %827 = select <8 x i1> %826, <8 x i16> %825, <8 x i16> %824
  %828 = lshr <8 x i16> %827, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %829 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %828, <8 x i16> zeroinitializer) #5
  %830 = lshr <8 x i16> %829, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %831 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %817, <8 x i16> %830) #5
  %832 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %831, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %833 = icmp slt <16 x i8> %832, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %834 = select <16 x i1> %833, <16 x i8> %832, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %835 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %834
  %836 = bitcast i8* %806 to <16 x i8>*
  store <16 x i8> %835, <16 x i8>* %836, align 16
  %837 = getelementptr inbounds i16, i16* %9, i64 400
  %838 = getelementptr inbounds i16, i16* %10, i64 400
  %839 = getelementptr inbounds i8, i8* %806, i64 16
  %840 = bitcast i16* %837 to <8 x i16>*
  %841 = load <8 x i16>, <8 x i16>* %840, align 16
  %842 = bitcast i16* %838 to <8 x i16>*
  %843 = load <8 x i16>, <8 x i16>* %842, align 16
  %844 = sub <8 x i16> %841, %843
  %845 = sub <8 x i16> zeroinitializer, %844
  %846 = icmp slt <8 x i16> %844, zeroinitializer
  %847 = select <8 x i1> %846, <8 x i16> %845, <8 x i16> %844
  %848 = lshr <8 x i16> %847, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %849 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %848, <8 x i16> zeroinitializer) #5
  %850 = lshr <8 x i16> %849, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %851 = getelementptr inbounds i16, i16* %9, i64 408
  %852 = bitcast i16* %851 to <8 x i16>*
  %853 = load <8 x i16>, <8 x i16>* %852, align 16
  %854 = getelementptr inbounds i16, i16* %10, i64 408
  %855 = bitcast i16* %854 to <8 x i16>*
  %856 = load <8 x i16>, <8 x i16>* %855, align 16
  %857 = sub <8 x i16> %853, %856
  %858 = sub <8 x i16> zeroinitializer, %857
  %859 = icmp slt <8 x i16> %857, zeroinitializer
  %860 = select <8 x i1> %859, <8 x i16> %858, <8 x i16> %857
  %861 = lshr <8 x i16> %860, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %862 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %861, <8 x i16> zeroinitializer) #5
  %863 = lshr <8 x i16> %862, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %864 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %850, <8 x i16> %863) #5
  %865 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %864, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %866 = icmp slt <16 x i8> %865, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %867 = select <16 x i1> %866, <16 x i8> %865, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %868 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %867
  %869 = bitcast i8* %839 to <16 x i8>*
  store <16 x i8> %868, <16 x i8>* %869, align 16
  %870 = getelementptr inbounds i16, i16* %9, i64 416
  %871 = getelementptr inbounds i16, i16* %10, i64 416
  %872 = getelementptr inbounds i8, i8* %806, i64 32
  %873 = bitcast i16* %870 to <8 x i16>*
  %874 = load <8 x i16>, <8 x i16>* %873, align 16
  %875 = bitcast i16* %871 to <8 x i16>*
  %876 = load <8 x i16>, <8 x i16>* %875, align 16
  %877 = sub <8 x i16> %874, %876
  %878 = sub <8 x i16> zeroinitializer, %877
  %879 = icmp slt <8 x i16> %877, zeroinitializer
  %880 = select <8 x i1> %879, <8 x i16> %878, <8 x i16> %877
  %881 = lshr <8 x i16> %880, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %882 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %881, <8 x i16> zeroinitializer) #5
  %883 = lshr <8 x i16> %882, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %884 = getelementptr inbounds i16, i16* %9, i64 424
  %885 = bitcast i16* %884 to <8 x i16>*
  %886 = load <8 x i16>, <8 x i16>* %885, align 16
  %887 = getelementptr inbounds i16, i16* %10, i64 424
  %888 = bitcast i16* %887 to <8 x i16>*
  %889 = load <8 x i16>, <8 x i16>* %888, align 16
  %890 = sub <8 x i16> %886, %889
  %891 = sub <8 x i16> zeroinitializer, %890
  %892 = icmp slt <8 x i16> %890, zeroinitializer
  %893 = select <8 x i1> %892, <8 x i16> %891, <8 x i16> %890
  %894 = lshr <8 x i16> %893, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %895 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %894, <8 x i16> zeroinitializer) #5
  %896 = lshr <8 x i16> %895, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %897 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %883, <8 x i16> %896) #5
  %898 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %897, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %899 = icmp slt <16 x i8> %898, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %900 = select <16 x i1> %899, <16 x i8> %898, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %901 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %900
  %902 = bitcast i8* %872 to <16 x i8>*
  store <16 x i8> %901, <16 x i8>* %902, align 16
  %903 = getelementptr inbounds i16, i16* %9, i64 432
  %904 = getelementptr inbounds i16, i16* %10, i64 432
  %905 = getelementptr inbounds i8, i8* %806, i64 48
  %906 = bitcast i16* %903 to <8 x i16>*
  %907 = load <8 x i16>, <8 x i16>* %906, align 16
  %908 = bitcast i16* %904 to <8 x i16>*
  %909 = load <8 x i16>, <8 x i16>* %908, align 16
  %910 = sub <8 x i16> %907, %909
  %911 = sub <8 x i16> zeroinitializer, %910
  %912 = icmp slt <8 x i16> %910, zeroinitializer
  %913 = select <8 x i1> %912, <8 x i16> %911, <8 x i16> %910
  %914 = lshr <8 x i16> %913, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %915 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %914, <8 x i16> zeroinitializer) #5
  %916 = lshr <8 x i16> %915, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %917 = getelementptr inbounds i16, i16* %9, i64 440
  %918 = bitcast i16* %917 to <8 x i16>*
  %919 = load <8 x i16>, <8 x i16>* %918, align 16
  %920 = getelementptr inbounds i16, i16* %10, i64 440
  %921 = bitcast i16* %920 to <8 x i16>*
  %922 = load <8 x i16>, <8 x i16>* %921, align 16
  %923 = sub <8 x i16> %919, %922
  %924 = sub <8 x i16> zeroinitializer, %923
  %925 = icmp slt <8 x i16> %923, zeroinitializer
  %926 = select <8 x i1> %925, <8 x i16> %924, <8 x i16> %923
  %927 = lshr <8 x i16> %926, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %928 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %927, <8 x i16> zeroinitializer) #5
  %929 = lshr <8 x i16> %928, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %930 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %916, <8 x i16> %929) #5
  %931 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %930, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %932 = icmp slt <16 x i8> %931, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %933 = select <16 x i1> %932, <16 x i8> %931, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %934 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %933
  %935 = bitcast i8* %905 to <16 x i8>*
  store <16 x i8> %934, <16 x i8>* %935, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask64x64_SSE4ILb0EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %395, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %393, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %394, %7 ]
  %11 = phi i32 [ 0, %4 ], [ %396, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = sub <8 x i16> %13, %15
  %17 = sub <8 x i16> zeroinitializer, %16
  %18 = icmp slt <8 x i16> %16, zeroinitializer
  %19 = select <8 x i1> %18, <8 x i16> %17, <8 x i16> %16
  %20 = lshr <8 x i16> %19, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %21 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %20, <8 x i16> zeroinitializer) #5
  %22 = lshr <8 x i16> %21, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %23 = getelementptr inbounds i16, i16* %9, i64 8
  %24 = bitcast i16* %23 to <8 x i16>*
  %25 = load <8 x i16>, <8 x i16>* %24, align 16
  %26 = getelementptr inbounds i16, i16* %10, i64 8
  %27 = bitcast i16* %26 to <8 x i16>*
  %28 = load <8 x i16>, <8 x i16>* %27, align 16
  %29 = sub <8 x i16> %25, %28
  %30 = sub <8 x i16> zeroinitializer, %29
  %31 = icmp slt <8 x i16> %29, zeroinitializer
  %32 = select <8 x i1> %31, <8 x i16> %30, <8 x i16> %29
  %33 = lshr <8 x i16> %32, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %34 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %33, <8 x i16> zeroinitializer) #5
  %35 = lshr <8 x i16> %34, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %36 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %22, <8 x i16> %35) #5
  %37 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %36, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %38 = icmp slt <16 x i8> %37, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %39 = select <16 x i1> %38, <16 x i8> %37, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %40 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %40, align 16
  %41 = getelementptr inbounds i16, i16* %9, i64 16
  %42 = getelementptr inbounds i16, i16* %10, i64 16
  %43 = getelementptr inbounds i8, i8* %8, i64 16
  %44 = bitcast i16* %41 to <8 x i16>*
  %45 = load <8 x i16>, <8 x i16>* %44, align 16
  %46 = bitcast i16* %42 to <8 x i16>*
  %47 = load <8 x i16>, <8 x i16>* %46, align 16
  %48 = sub <8 x i16> %45, %47
  %49 = sub <8 x i16> zeroinitializer, %48
  %50 = icmp slt <8 x i16> %48, zeroinitializer
  %51 = select <8 x i1> %50, <8 x i16> %49, <8 x i16> %48
  %52 = lshr <8 x i16> %51, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %53 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %52, <8 x i16> zeroinitializer) #5
  %54 = lshr <8 x i16> %53, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %55 = getelementptr inbounds i16, i16* %9, i64 24
  %56 = bitcast i16* %55 to <8 x i16>*
  %57 = load <8 x i16>, <8 x i16>* %56, align 16
  %58 = getelementptr inbounds i16, i16* %10, i64 24
  %59 = bitcast i16* %58 to <8 x i16>*
  %60 = load <8 x i16>, <8 x i16>* %59, align 16
  %61 = sub <8 x i16> %57, %60
  %62 = sub <8 x i16> zeroinitializer, %61
  %63 = icmp slt <8 x i16> %61, zeroinitializer
  %64 = select <8 x i1> %63, <8 x i16> %62, <8 x i16> %61
  %65 = lshr <8 x i16> %64, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %66 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %65, <8 x i16> zeroinitializer) #5
  %67 = lshr <8 x i16> %66, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %68 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %54, <8 x i16> %67) #5
  %69 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %68, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %70 = icmp slt <16 x i8> %69, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %71 = select <16 x i1> %70, <16 x i8> %69, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %72 = bitcast i8* %43 to <16 x i8>*
  store <16 x i8> %71, <16 x i8>* %72, align 16
  %73 = getelementptr inbounds i16, i16* %9, i64 32
  %74 = getelementptr inbounds i16, i16* %10, i64 32
  %75 = getelementptr inbounds i8, i8* %8, i64 32
  %76 = bitcast i16* %73 to <8 x i16>*
  %77 = load <8 x i16>, <8 x i16>* %76, align 16
  %78 = bitcast i16* %74 to <8 x i16>*
  %79 = load <8 x i16>, <8 x i16>* %78, align 16
  %80 = sub <8 x i16> %77, %79
  %81 = sub <8 x i16> zeroinitializer, %80
  %82 = icmp slt <8 x i16> %80, zeroinitializer
  %83 = select <8 x i1> %82, <8 x i16> %81, <8 x i16> %80
  %84 = lshr <8 x i16> %83, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %85 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %84, <8 x i16> zeroinitializer) #5
  %86 = lshr <8 x i16> %85, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %87 = getelementptr inbounds i16, i16* %9, i64 40
  %88 = bitcast i16* %87 to <8 x i16>*
  %89 = load <8 x i16>, <8 x i16>* %88, align 16
  %90 = getelementptr inbounds i16, i16* %10, i64 40
  %91 = bitcast i16* %90 to <8 x i16>*
  %92 = load <8 x i16>, <8 x i16>* %91, align 16
  %93 = sub <8 x i16> %89, %92
  %94 = sub <8 x i16> zeroinitializer, %93
  %95 = icmp slt <8 x i16> %93, zeroinitializer
  %96 = select <8 x i1> %95, <8 x i16> %94, <8 x i16> %93
  %97 = lshr <8 x i16> %96, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %98 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %97, <8 x i16> zeroinitializer) #5
  %99 = lshr <8 x i16> %98, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %100 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %86, <8 x i16> %99) #5
  %101 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %100, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %102 = icmp slt <16 x i8> %101, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %103 = select <16 x i1> %102, <16 x i8> %101, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %104 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %103, <16 x i8>* %104, align 16
  %105 = getelementptr inbounds i16, i16* %9, i64 48
  %106 = getelementptr inbounds i16, i16* %10, i64 48
  %107 = getelementptr inbounds i8, i8* %8, i64 48
  %108 = bitcast i16* %105 to <8 x i16>*
  %109 = load <8 x i16>, <8 x i16>* %108, align 16
  %110 = bitcast i16* %106 to <8 x i16>*
  %111 = load <8 x i16>, <8 x i16>* %110, align 16
  %112 = sub <8 x i16> %109, %111
  %113 = sub <8 x i16> zeroinitializer, %112
  %114 = icmp slt <8 x i16> %112, zeroinitializer
  %115 = select <8 x i1> %114, <8 x i16> %113, <8 x i16> %112
  %116 = lshr <8 x i16> %115, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %117 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %116, <8 x i16> zeroinitializer) #5
  %118 = lshr <8 x i16> %117, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %119 = getelementptr inbounds i16, i16* %9, i64 56
  %120 = bitcast i16* %119 to <8 x i16>*
  %121 = load <8 x i16>, <8 x i16>* %120, align 16
  %122 = getelementptr inbounds i16, i16* %10, i64 56
  %123 = bitcast i16* %122 to <8 x i16>*
  %124 = load <8 x i16>, <8 x i16>* %123, align 16
  %125 = sub <8 x i16> %121, %124
  %126 = sub <8 x i16> zeroinitializer, %125
  %127 = icmp slt <8 x i16> %125, zeroinitializer
  %128 = select <8 x i1> %127, <8 x i16> %126, <8 x i16> %125
  %129 = lshr <8 x i16> %128, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %130 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %129, <8 x i16> zeroinitializer) #5
  %131 = lshr <8 x i16> %130, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %132 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %118, <8 x i16> %131) #5
  %133 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %132, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %134 = icmp slt <16 x i8> %133, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %135 = select <16 x i1> %134, <16 x i8> %133, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %136 = bitcast i8* %107 to <16 x i8>*
  store <16 x i8> %135, <16 x i8>* %136, align 16
  %137 = getelementptr inbounds i16, i16* %9, i64 64
  %138 = getelementptr inbounds i16, i16* %10, i64 64
  %139 = getelementptr inbounds i8, i8* %8, i64 %3
  %140 = bitcast i16* %137 to <8 x i16>*
  %141 = load <8 x i16>, <8 x i16>* %140, align 16
  %142 = bitcast i16* %138 to <8 x i16>*
  %143 = load <8 x i16>, <8 x i16>* %142, align 16
  %144 = sub <8 x i16> %141, %143
  %145 = sub <8 x i16> zeroinitializer, %144
  %146 = icmp slt <8 x i16> %144, zeroinitializer
  %147 = select <8 x i1> %146, <8 x i16> %145, <8 x i16> %144
  %148 = lshr <8 x i16> %147, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %149 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %148, <8 x i16> zeroinitializer) #5
  %150 = lshr <8 x i16> %149, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %151 = getelementptr inbounds i16, i16* %9, i64 72
  %152 = bitcast i16* %151 to <8 x i16>*
  %153 = load <8 x i16>, <8 x i16>* %152, align 16
  %154 = getelementptr inbounds i16, i16* %10, i64 72
  %155 = bitcast i16* %154 to <8 x i16>*
  %156 = load <8 x i16>, <8 x i16>* %155, align 16
  %157 = sub <8 x i16> %153, %156
  %158 = sub <8 x i16> zeroinitializer, %157
  %159 = icmp slt <8 x i16> %157, zeroinitializer
  %160 = select <8 x i1> %159, <8 x i16> %158, <8 x i16> %157
  %161 = lshr <8 x i16> %160, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %162 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %161, <8 x i16> zeroinitializer) #5
  %163 = lshr <8 x i16> %162, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %164 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %150, <8 x i16> %163) #5
  %165 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %164, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %166 = icmp slt <16 x i8> %165, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %167 = select <16 x i1> %166, <16 x i8> %165, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %168 = bitcast i8* %139 to <16 x i8>*
  store <16 x i8> %167, <16 x i8>* %168, align 16
  %169 = getelementptr inbounds i16, i16* %9, i64 80
  %170 = getelementptr inbounds i16, i16* %10, i64 80
  %171 = getelementptr inbounds i8, i8* %139, i64 16
  %172 = bitcast i16* %169 to <8 x i16>*
  %173 = load <8 x i16>, <8 x i16>* %172, align 16
  %174 = bitcast i16* %170 to <8 x i16>*
  %175 = load <8 x i16>, <8 x i16>* %174, align 16
  %176 = sub <8 x i16> %173, %175
  %177 = sub <8 x i16> zeroinitializer, %176
  %178 = icmp slt <8 x i16> %176, zeroinitializer
  %179 = select <8 x i1> %178, <8 x i16> %177, <8 x i16> %176
  %180 = lshr <8 x i16> %179, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %181 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %180, <8 x i16> zeroinitializer) #5
  %182 = lshr <8 x i16> %181, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %183 = getelementptr inbounds i16, i16* %9, i64 88
  %184 = bitcast i16* %183 to <8 x i16>*
  %185 = load <8 x i16>, <8 x i16>* %184, align 16
  %186 = getelementptr inbounds i16, i16* %10, i64 88
  %187 = bitcast i16* %186 to <8 x i16>*
  %188 = load <8 x i16>, <8 x i16>* %187, align 16
  %189 = sub <8 x i16> %185, %188
  %190 = sub <8 x i16> zeroinitializer, %189
  %191 = icmp slt <8 x i16> %189, zeroinitializer
  %192 = select <8 x i1> %191, <8 x i16> %190, <8 x i16> %189
  %193 = lshr <8 x i16> %192, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %194 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %193, <8 x i16> zeroinitializer) #5
  %195 = lshr <8 x i16> %194, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %196 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %182, <8 x i16> %195) #5
  %197 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %196, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %198 = icmp slt <16 x i8> %197, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %199 = select <16 x i1> %198, <16 x i8> %197, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %200 = bitcast i8* %171 to <16 x i8>*
  store <16 x i8> %199, <16 x i8>* %200, align 16
  %201 = getelementptr inbounds i16, i16* %9, i64 96
  %202 = getelementptr inbounds i16, i16* %10, i64 96
  %203 = getelementptr inbounds i8, i8* %139, i64 32
  %204 = bitcast i16* %201 to <8 x i16>*
  %205 = load <8 x i16>, <8 x i16>* %204, align 16
  %206 = bitcast i16* %202 to <8 x i16>*
  %207 = load <8 x i16>, <8 x i16>* %206, align 16
  %208 = sub <8 x i16> %205, %207
  %209 = sub <8 x i16> zeroinitializer, %208
  %210 = icmp slt <8 x i16> %208, zeroinitializer
  %211 = select <8 x i1> %210, <8 x i16> %209, <8 x i16> %208
  %212 = lshr <8 x i16> %211, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %213 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %212, <8 x i16> zeroinitializer) #5
  %214 = lshr <8 x i16> %213, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %215 = getelementptr inbounds i16, i16* %9, i64 104
  %216 = bitcast i16* %215 to <8 x i16>*
  %217 = load <8 x i16>, <8 x i16>* %216, align 16
  %218 = getelementptr inbounds i16, i16* %10, i64 104
  %219 = bitcast i16* %218 to <8 x i16>*
  %220 = load <8 x i16>, <8 x i16>* %219, align 16
  %221 = sub <8 x i16> %217, %220
  %222 = sub <8 x i16> zeroinitializer, %221
  %223 = icmp slt <8 x i16> %221, zeroinitializer
  %224 = select <8 x i1> %223, <8 x i16> %222, <8 x i16> %221
  %225 = lshr <8 x i16> %224, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %226 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %225, <8 x i16> zeroinitializer) #5
  %227 = lshr <8 x i16> %226, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %228 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %214, <8 x i16> %227) #5
  %229 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %228, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %230 = icmp slt <16 x i8> %229, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %231 = select <16 x i1> %230, <16 x i8> %229, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %232 = bitcast i8* %203 to <16 x i8>*
  store <16 x i8> %231, <16 x i8>* %232, align 16
  %233 = getelementptr inbounds i16, i16* %9, i64 112
  %234 = getelementptr inbounds i16, i16* %10, i64 112
  %235 = getelementptr inbounds i8, i8* %139, i64 48
  %236 = bitcast i16* %233 to <8 x i16>*
  %237 = load <8 x i16>, <8 x i16>* %236, align 16
  %238 = bitcast i16* %234 to <8 x i16>*
  %239 = load <8 x i16>, <8 x i16>* %238, align 16
  %240 = sub <8 x i16> %237, %239
  %241 = sub <8 x i16> zeroinitializer, %240
  %242 = icmp slt <8 x i16> %240, zeroinitializer
  %243 = select <8 x i1> %242, <8 x i16> %241, <8 x i16> %240
  %244 = lshr <8 x i16> %243, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %245 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %244, <8 x i16> zeroinitializer) #5
  %246 = lshr <8 x i16> %245, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %247 = getelementptr inbounds i16, i16* %9, i64 120
  %248 = bitcast i16* %247 to <8 x i16>*
  %249 = load <8 x i16>, <8 x i16>* %248, align 16
  %250 = getelementptr inbounds i16, i16* %10, i64 120
  %251 = bitcast i16* %250 to <8 x i16>*
  %252 = load <8 x i16>, <8 x i16>* %251, align 16
  %253 = sub <8 x i16> %249, %252
  %254 = sub <8 x i16> zeroinitializer, %253
  %255 = icmp slt <8 x i16> %253, zeroinitializer
  %256 = select <8 x i1> %255, <8 x i16> %254, <8 x i16> %253
  %257 = lshr <8 x i16> %256, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %258 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %257, <8 x i16> zeroinitializer) #5
  %259 = lshr <8 x i16> %258, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %260 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %246, <8 x i16> %259) #5
  %261 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %260, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %262 = icmp slt <16 x i8> %261, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %263 = select <16 x i1> %262, <16 x i8> %261, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %264 = bitcast i8* %235 to <16 x i8>*
  store <16 x i8> %263, <16 x i8>* %264, align 16
  %265 = getelementptr inbounds i16, i16* %9, i64 128
  %266 = getelementptr inbounds i16, i16* %10, i64 128
  %267 = getelementptr inbounds i8, i8* %139, i64 %3
  %268 = bitcast i16* %265 to <8 x i16>*
  %269 = load <8 x i16>, <8 x i16>* %268, align 16
  %270 = bitcast i16* %266 to <8 x i16>*
  %271 = load <8 x i16>, <8 x i16>* %270, align 16
  %272 = sub <8 x i16> %269, %271
  %273 = sub <8 x i16> zeroinitializer, %272
  %274 = icmp slt <8 x i16> %272, zeroinitializer
  %275 = select <8 x i1> %274, <8 x i16> %273, <8 x i16> %272
  %276 = lshr <8 x i16> %275, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %277 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %276, <8 x i16> zeroinitializer) #5
  %278 = lshr <8 x i16> %277, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %279 = getelementptr inbounds i16, i16* %9, i64 136
  %280 = bitcast i16* %279 to <8 x i16>*
  %281 = load <8 x i16>, <8 x i16>* %280, align 16
  %282 = getelementptr inbounds i16, i16* %10, i64 136
  %283 = bitcast i16* %282 to <8 x i16>*
  %284 = load <8 x i16>, <8 x i16>* %283, align 16
  %285 = sub <8 x i16> %281, %284
  %286 = sub <8 x i16> zeroinitializer, %285
  %287 = icmp slt <8 x i16> %285, zeroinitializer
  %288 = select <8 x i1> %287, <8 x i16> %286, <8 x i16> %285
  %289 = lshr <8 x i16> %288, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %290 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %289, <8 x i16> zeroinitializer) #5
  %291 = lshr <8 x i16> %290, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %292 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %278, <8 x i16> %291) #5
  %293 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %292, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %294 = icmp slt <16 x i8> %293, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %295 = select <16 x i1> %294, <16 x i8> %293, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %296 = bitcast i8* %267 to <16 x i8>*
  store <16 x i8> %295, <16 x i8>* %296, align 16
  %297 = getelementptr inbounds i16, i16* %9, i64 144
  %298 = getelementptr inbounds i16, i16* %10, i64 144
  %299 = getelementptr inbounds i8, i8* %267, i64 16
  %300 = bitcast i16* %297 to <8 x i16>*
  %301 = load <8 x i16>, <8 x i16>* %300, align 16
  %302 = bitcast i16* %298 to <8 x i16>*
  %303 = load <8 x i16>, <8 x i16>* %302, align 16
  %304 = sub <8 x i16> %301, %303
  %305 = sub <8 x i16> zeroinitializer, %304
  %306 = icmp slt <8 x i16> %304, zeroinitializer
  %307 = select <8 x i1> %306, <8 x i16> %305, <8 x i16> %304
  %308 = lshr <8 x i16> %307, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %309 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %308, <8 x i16> zeroinitializer) #5
  %310 = lshr <8 x i16> %309, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %311 = getelementptr inbounds i16, i16* %9, i64 152
  %312 = bitcast i16* %311 to <8 x i16>*
  %313 = load <8 x i16>, <8 x i16>* %312, align 16
  %314 = getelementptr inbounds i16, i16* %10, i64 152
  %315 = bitcast i16* %314 to <8 x i16>*
  %316 = load <8 x i16>, <8 x i16>* %315, align 16
  %317 = sub <8 x i16> %313, %316
  %318 = sub <8 x i16> zeroinitializer, %317
  %319 = icmp slt <8 x i16> %317, zeroinitializer
  %320 = select <8 x i1> %319, <8 x i16> %318, <8 x i16> %317
  %321 = lshr <8 x i16> %320, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %322 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %321, <8 x i16> zeroinitializer) #5
  %323 = lshr <8 x i16> %322, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %324 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %310, <8 x i16> %323) #5
  %325 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %324, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %326 = icmp slt <16 x i8> %325, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %327 = select <16 x i1> %326, <16 x i8> %325, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %328 = bitcast i8* %299 to <16 x i8>*
  store <16 x i8> %327, <16 x i8>* %328, align 16
  %329 = getelementptr inbounds i16, i16* %9, i64 160
  %330 = getelementptr inbounds i16, i16* %10, i64 160
  %331 = getelementptr inbounds i8, i8* %267, i64 32
  %332 = bitcast i16* %329 to <8 x i16>*
  %333 = load <8 x i16>, <8 x i16>* %332, align 16
  %334 = bitcast i16* %330 to <8 x i16>*
  %335 = load <8 x i16>, <8 x i16>* %334, align 16
  %336 = sub <8 x i16> %333, %335
  %337 = sub <8 x i16> zeroinitializer, %336
  %338 = icmp slt <8 x i16> %336, zeroinitializer
  %339 = select <8 x i1> %338, <8 x i16> %337, <8 x i16> %336
  %340 = lshr <8 x i16> %339, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %341 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %340, <8 x i16> zeroinitializer) #5
  %342 = lshr <8 x i16> %341, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %343 = getelementptr inbounds i16, i16* %9, i64 168
  %344 = bitcast i16* %343 to <8 x i16>*
  %345 = load <8 x i16>, <8 x i16>* %344, align 16
  %346 = getelementptr inbounds i16, i16* %10, i64 168
  %347 = bitcast i16* %346 to <8 x i16>*
  %348 = load <8 x i16>, <8 x i16>* %347, align 16
  %349 = sub <8 x i16> %345, %348
  %350 = sub <8 x i16> zeroinitializer, %349
  %351 = icmp slt <8 x i16> %349, zeroinitializer
  %352 = select <8 x i1> %351, <8 x i16> %350, <8 x i16> %349
  %353 = lshr <8 x i16> %352, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %354 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %353, <8 x i16> zeroinitializer) #5
  %355 = lshr <8 x i16> %354, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %356 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %342, <8 x i16> %355) #5
  %357 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %356, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %358 = icmp slt <16 x i8> %357, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %359 = select <16 x i1> %358, <16 x i8> %357, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %360 = bitcast i8* %331 to <16 x i8>*
  store <16 x i8> %359, <16 x i8>* %360, align 16
  %361 = getelementptr inbounds i16, i16* %9, i64 176
  %362 = getelementptr inbounds i16, i16* %10, i64 176
  %363 = getelementptr inbounds i8, i8* %267, i64 48
  %364 = bitcast i16* %361 to <8 x i16>*
  %365 = load <8 x i16>, <8 x i16>* %364, align 16
  %366 = bitcast i16* %362 to <8 x i16>*
  %367 = load <8 x i16>, <8 x i16>* %366, align 16
  %368 = sub <8 x i16> %365, %367
  %369 = sub <8 x i16> zeroinitializer, %368
  %370 = icmp slt <8 x i16> %368, zeroinitializer
  %371 = select <8 x i1> %370, <8 x i16> %369, <8 x i16> %368
  %372 = lshr <8 x i16> %371, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %373 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %372, <8 x i16> zeroinitializer) #5
  %374 = lshr <8 x i16> %373, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %375 = getelementptr inbounds i16, i16* %9, i64 184
  %376 = bitcast i16* %375 to <8 x i16>*
  %377 = load <8 x i16>, <8 x i16>* %376, align 16
  %378 = getelementptr inbounds i16, i16* %10, i64 184
  %379 = bitcast i16* %378 to <8 x i16>*
  %380 = load <8 x i16>, <8 x i16>* %379, align 16
  %381 = sub <8 x i16> %377, %380
  %382 = sub <8 x i16> zeroinitializer, %381
  %383 = icmp slt <8 x i16> %381, zeroinitializer
  %384 = select <8 x i1> %383, <8 x i16> %382, <8 x i16> %381
  %385 = lshr <8 x i16> %384, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %386 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %385, <8 x i16> zeroinitializer) #5
  %387 = lshr <8 x i16> %386, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %388 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %374, <8 x i16> %387) #5
  %389 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %388, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %390 = icmp slt <16 x i8> %389, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %391 = select <16 x i1> %390, <16 x i8> %389, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %392 = bitcast i8* %363 to <16 x i8>*
  store <16 x i8> %391, <16 x i8>* %392, align 16
  %393 = getelementptr inbounds i16, i16* %9, i64 192
  %394 = getelementptr inbounds i16, i16* %10, i64 192
  %395 = getelementptr inbounds i8, i8* %267, i64 %3
  %396 = add nuw nsw i32 %11, 1
  %397 = icmp eq i32 %396, 21
  br i1 %397, label %398, label %7

398:                                              ; preds = %7
  %399 = bitcast i16* %393 to <8 x i16>*
  %400 = load <8 x i16>, <8 x i16>* %399, align 16
  %401 = bitcast i16* %394 to <8 x i16>*
  %402 = load <8 x i16>, <8 x i16>* %401, align 16
  %403 = sub <8 x i16> %400, %402
  %404 = sub <8 x i16> zeroinitializer, %403
  %405 = icmp slt <8 x i16> %403, zeroinitializer
  %406 = select <8 x i1> %405, <8 x i16> %404, <8 x i16> %403
  %407 = lshr <8 x i16> %406, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %408 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %407, <8 x i16> zeroinitializer) #5
  %409 = lshr <8 x i16> %408, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %410 = getelementptr inbounds i16, i16* %9, i64 200
  %411 = bitcast i16* %410 to <8 x i16>*
  %412 = load <8 x i16>, <8 x i16>* %411, align 16
  %413 = getelementptr inbounds i16, i16* %10, i64 200
  %414 = bitcast i16* %413 to <8 x i16>*
  %415 = load <8 x i16>, <8 x i16>* %414, align 16
  %416 = sub <8 x i16> %412, %415
  %417 = sub <8 x i16> zeroinitializer, %416
  %418 = icmp slt <8 x i16> %416, zeroinitializer
  %419 = select <8 x i1> %418, <8 x i16> %417, <8 x i16> %416
  %420 = lshr <8 x i16> %419, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %421 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %420, <8 x i16> zeroinitializer) #5
  %422 = lshr <8 x i16> %421, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %423 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %409, <8 x i16> %422) #5
  %424 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %423, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %425 = icmp slt <16 x i8> %424, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %426 = select <16 x i1> %425, <16 x i8> %424, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %427 = bitcast i8* %395 to <16 x i8>*
  store <16 x i8> %426, <16 x i8>* %427, align 16
  %428 = getelementptr inbounds i16, i16* %9, i64 208
  %429 = getelementptr inbounds i16, i16* %10, i64 208
  %430 = getelementptr inbounds i8, i8* %395, i64 16
  %431 = bitcast i16* %428 to <8 x i16>*
  %432 = load <8 x i16>, <8 x i16>* %431, align 16
  %433 = bitcast i16* %429 to <8 x i16>*
  %434 = load <8 x i16>, <8 x i16>* %433, align 16
  %435 = sub <8 x i16> %432, %434
  %436 = sub <8 x i16> zeroinitializer, %435
  %437 = icmp slt <8 x i16> %435, zeroinitializer
  %438 = select <8 x i1> %437, <8 x i16> %436, <8 x i16> %435
  %439 = lshr <8 x i16> %438, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %440 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %439, <8 x i16> zeroinitializer) #5
  %441 = lshr <8 x i16> %440, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %442 = getelementptr inbounds i16, i16* %9, i64 216
  %443 = bitcast i16* %442 to <8 x i16>*
  %444 = load <8 x i16>, <8 x i16>* %443, align 16
  %445 = getelementptr inbounds i16, i16* %10, i64 216
  %446 = bitcast i16* %445 to <8 x i16>*
  %447 = load <8 x i16>, <8 x i16>* %446, align 16
  %448 = sub <8 x i16> %444, %447
  %449 = sub <8 x i16> zeroinitializer, %448
  %450 = icmp slt <8 x i16> %448, zeroinitializer
  %451 = select <8 x i1> %450, <8 x i16> %449, <8 x i16> %448
  %452 = lshr <8 x i16> %451, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %453 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %452, <8 x i16> zeroinitializer) #5
  %454 = lshr <8 x i16> %453, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %455 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %441, <8 x i16> %454) #5
  %456 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %455, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %457 = icmp slt <16 x i8> %456, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %458 = select <16 x i1> %457, <16 x i8> %456, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %459 = bitcast i8* %430 to <16 x i8>*
  store <16 x i8> %458, <16 x i8>* %459, align 16
  %460 = getelementptr inbounds i16, i16* %9, i64 224
  %461 = getelementptr inbounds i16, i16* %10, i64 224
  %462 = getelementptr inbounds i8, i8* %395, i64 32
  %463 = bitcast i16* %460 to <8 x i16>*
  %464 = load <8 x i16>, <8 x i16>* %463, align 16
  %465 = bitcast i16* %461 to <8 x i16>*
  %466 = load <8 x i16>, <8 x i16>* %465, align 16
  %467 = sub <8 x i16> %464, %466
  %468 = sub <8 x i16> zeroinitializer, %467
  %469 = icmp slt <8 x i16> %467, zeroinitializer
  %470 = select <8 x i1> %469, <8 x i16> %468, <8 x i16> %467
  %471 = lshr <8 x i16> %470, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %472 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %471, <8 x i16> zeroinitializer) #5
  %473 = lshr <8 x i16> %472, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %474 = getelementptr inbounds i16, i16* %9, i64 232
  %475 = bitcast i16* %474 to <8 x i16>*
  %476 = load <8 x i16>, <8 x i16>* %475, align 16
  %477 = getelementptr inbounds i16, i16* %10, i64 232
  %478 = bitcast i16* %477 to <8 x i16>*
  %479 = load <8 x i16>, <8 x i16>* %478, align 16
  %480 = sub <8 x i16> %476, %479
  %481 = sub <8 x i16> zeroinitializer, %480
  %482 = icmp slt <8 x i16> %480, zeroinitializer
  %483 = select <8 x i1> %482, <8 x i16> %481, <8 x i16> %480
  %484 = lshr <8 x i16> %483, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %485 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %484, <8 x i16> zeroinitializer) #5
  %486 = lshr <8 x i16> %485, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %487 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %473, <8 x i16> %486) #5
  %488 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %487, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %489 = icmp slt <16 x i8> %488, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %490 = select <16 x i1> %489, <16 x i8> %488, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %491 = bitcast i8* %462 to <16 x i8>*
  store <16 x i8> %490, <16 x i8>* %491, align 16
  %492 = getelementptr inbounds i16, i16* %9, i64 240
  %493 = getelementptr inbounds i16, i16* %10, i64 240
  %494 = getelementptr inbounds i8, i8* %395, i64 48
  %495 = bitcast i16* %492 to <8 x i16>*
  %496 = load <8 x i16>, <8 x i16>* %495, align 16
  %497 = bitcast i16* %493 to <8 x i16>*
  %498 = load <8 x i16>, <8 x i16>* %497, align 16
  %499 = sub <8 x i16> %496, %498
  %500 = sub <8 x i16> zeroinitializer, %499
  %501 = icmp slt <8 x i16> %499, zeroinitializer
  %502 = select <8 x i1> %501, <8 x i16> %500, <8 x i16> %499
  %503 = lshr <8 x i16> %502, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %504 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %503, <8 x i16> zeroinitializer) #5
  %505 = lshr <8 x i16> %504, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %506 = getelementptr inbounds i16, i16* %9, i64 248
  %507 = bitcast i16* %506 to <8 x i16>*
  %508 = load <8 x i16>, <8 x i16>* %507, align 16
  %509 = getelementptr inbounds i16, i16* %10, i64 248
  %510 = bitcast i16* %509 to <8 x i16>*
  %511 = load <8 x i16>, <8 x i16>* %510, align 16
  %512 = sub <8 x i16> %508, %511
  %513 = sub <8 x i16> zeroinitializer, %512
  %514 = icmp slt <8 x i16> %512, zeroinitializer
  %515 = select <8 x i1> %514, <8 x i16> %513, <8 x i16> %512
  %516 = lshr <8 x i16> %515, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %517 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %516, <8 x i16> zeroinitializer) #5
  %518 = lshr <8 x i16> %517, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %519 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %505, <8 x i16> %518) #5
  %520 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %519, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %521 = icmp slt <16 x i8> %520, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %522 = select <16 x i1> %521, <16 x i8> %520, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %523 = bitcast i8* %494 to <16 x i8>*
  store <16 x i8> %522, <16 x i8>* %523, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_120WeightMask64x64_SSE4ILb1EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %407, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %405, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %406, %7 ]
  %11 = phi i32 [ 0, %4 ], [ %408, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = sub <8 x i16> %13, %15
  %17 = sub <8 x i16> zeroinitializer, %16
  %18 = icmp slt <8 x i16> %16, zeroinitializer
  %19 = select <8 x i1> %18, <8 x i16> %17, <8 x i16> %16
  %20 = lshr <8 x i16> %19, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %21 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %20, <8 x i16> zeroinitializer) #5
  %22 = lshr <8 x i16> %21, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %23 = getelementptr inbounds i16, i16* %9, i64 8
  %24 = bitcast i16* %23 to <8 x i16>*
  %25 = load <8 x i16>, <8 x i16>* %24, align 16
  %26 = getelementptr inbounds i16, i16* %10, i64 8
  %27 = bitcast i16* %26 to <8 x i16>*
  %28 = load <8 x i16>, <8 x i16>* %27, align 16
  %29 = sub <8 x i16> %25, %28
  %30 = sub <8 x i16> zeroinitializer, %29
  %31 = icmp slt <8 x i16> %29, zeroinitializer
  %32 = select <8 x i1> %31, <8 x i16> %30, <8 x i16> %29
  %33 = lshr <8 x i16> %32, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %34 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %33, <8 x i16> zeroinitializer) #5
  %35 = lshr <8 x i16> %34, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %36 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %22, <8 x i16> %35) #5
  %37 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %36, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %38 = icmp slt <16 x i8> %37, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %39 = select <16 x i1> %38, <16 x i8> %37, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %40 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %39
  %41 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %40, <16 x i8>* %41, align 16
  %42 = getelementptr inbounds i16, i16* %9, i64 16
  %43 = getelementptr inbounds i16, i16* %10, i64 16
  %44 = getelementptr inbounds i8, i8* %8, i64 16
  %45 = bitcast i16* %42 to <8 x i16>*
  %46 = load <8 x i16>, <8 x i16>* %45, align 16
  %47 = bitcast i16* %43 to <8 x i16>*
  %48 = load <8 x i16>, <8 x i16>* %47, align 16
  %49 = sub <8 x i16> %46, %48
  %50 = sub <8 x i16> zeroinitializer, %49
  %51 = icmp slt <8 x i16> %49, zeroinitializer
  %52 = select <8 x i1> %51, <8 x i16> %50, <8 x i16> %49
  %53 = lshr <8 x i16> %52, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %54 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %53, <8 x i16> zeroinitializer) #5
  %55 = lshr <8 x i16> %54, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %56 = getelementptr inbounds i16, i16* %9, i64 24
  %57 = bitcast i16* %56 to <8 x i16>*
  %58 = load <8 x i16>, <8 x i16>* %57, align 16
  %59 = getelementptr inbounds i16, i16* %10, i64 24
  %60 = bitcast i16* %59 to <8 x i16>*
  %61 = load <8 x i16>, <8 x i16>* %60, align 16
  %62 = sub <8 x i16> %58, %61
  %63 = sub <8 x i16> zeroinitializer, %62
  %64 = icmp slt <8 x i16> %62, zeroinitializer
  %65 = select <8 x i1> %64, <8 x i16> %63, <8 x i16> %62
  %66 = lshr <8 x i16> %65, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %67 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %66, <8 x i16> zeroinitializer) #5
  %68 = lshr <8 x i16> %67, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %69 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %55, <8 x i16> %68) #5
  %70 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %69, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %71 = icmp slt <16 x i8> %70, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %72 = select <16 x i1> %71, <16 x i8> %70, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %73 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %72
  %74 = bitcast i8* %44 to <16 x i8>*
  store <16 x i8> %73, <16 x i8>* %74, align 16
  %75 = getelementptr inbounds i16, i16* %9, i64 32
  %76 = getelementptr inbounds i16, i16* %10, i64 32
  %77 = getelementptr inbounds i8, i8* %8, i64 32
  %78 = bitcast i16* %75 to <8 x i16>*
  %79 = load <8 x i16>, <8 x i16>* %78, align 16
  %80 = bitcast i16* %76 to <8 x i16>*
  %81 = load <8 x i16>, <8 x i16>* %80, align 16
  %82 = sub <8 x i16> %79, %81
  %83 = sub <8 x i16> zeroinitializer, %82
  %84 = icmp slt <8 x i16> %82, zeroinitializer
  %85 = select <8 x i1> %84, <8 x i16> %83, <8 x i16> %82
  %86 = lshr <8 x i16> %85, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %87 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %86, <8 x i16> zeroinitializer) #5
  %88 = lshr <8 x i16> %87, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %89 = getelementptr inbounds i16, i16* %9, i64 40
  %90 = bitcast i16* %89 to <8 x i16>*
  %91 = load <8 x i16>, <8 x i16>* %90, align 16
  %92 = getelementptr inbounds i16, i16* %10, i64 40
  %93 = bitcast i16* %92 to <8 x i16>*
  %94 = load <8 x i16>, <8 x i16>* %93, align 16
  %95 = sub <8 x i16> %91, %94
  %96 = sub <8 x i16> zeroinitializer, %95
  %97 = icmp slt <8 x i16> %95, zeroinitializer
  %98 = select <8 x i1> %97, <8 x i16> %96, <8 x i16> %95
  %99 = lshr <8 x i16> %98, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %100 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %99, <8 x i16> zeroinitializer) #5
  %101 = lshr <8 x i16> %100, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %102 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %88, <8 x i16> %101) #5
  %103 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %102, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %104 = icmp slt <16 x i8> %103, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %105 = select <16 x i1> %104, <16 x i8> %103, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %106 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %105
  %107 = bitcast i8* %77 to <16 x i8>*
  store <16 x i8> %106, <16 x i8>* %107, align 16
  %108 = getelementptr inbounds i16, i16* %9, i64 48
  %109 = getelementptr inbounds i16, i16* %10, i64 48
  %110 = getelementptr inbounds i8, i8* %8, i64 48
  %111 = bitcast i16* %108 to <8 x i16>*
  %112 = load <8 x i16>, <8 x i16>* %111, align 16
  %113 = bitcast i16* %109 to <8 x i16>*
  %114 = load <8 x i16>, <8 x i16>* %113, align 16
  %115 = sub <8 x i16> %112, %114
  %116 = sub <8 x i16> zeroinitializer, %115
  %117 = icmp slt <8 x i16> %115, zeroinitializer
  %118 = select <8 x i1> %117, <8 x i16> %116, <8 x i16> %115
  %119 = lshr <8 x i16> %118, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %120 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %119, <8 x i16> zeroinitializer) #5
  %121 = lshr <8 x i16> %120, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %122 = getelementptr inbounds i16, i16* %9, i64 56
  %123 = bitcast i16* %122 to <8 x i16>*
  %124 = load <8 x i16>, <8 x i16>* %123, align 16
  %125 = getelementptr inbounds i16, i16* %10, i64 56
  %126 = bitcast i16* %125 to <8 x i16>*
  %127 = load <8 x i16>, <8 x i16>* %126, align 16
  %128 = sub <8 x i16> %124, %127
  %129 = sub <8 x i16> zeroinitializer, %128
  %130 = icmp slt <8 x i16> %128, zeroinitializer
  %131 = select <8 x i1> %130, <8 x i16> %129, <8 x i16> %128
  %132 = lshr <8 x i16> %131, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %133 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %132, <8 x i16> zeroinitializer) #5
  %134 = lshr <8 x i16> %133, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %135 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %121, <8 x i16> %134) #5
  %136 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %135, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %137 = icmp slt <16 x i8> %136, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %138 = select <16 x i1> %137, <16 x i8> %136, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %139 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %138
  %140 = bitcast i8* %110 to <16 x i8>*
  store <16 x i8> %139, <16 x i8>* %140, align 16
  %141 = getelementptr inbounds i16, i16* %9, i64 64
  %142 = getelementptr inbounds i16, i16* %10, i64 64
  %143 = getelementptr inbounds i8, i8* %8, i64 %3
  %144 = bitcast i16* %141 to <8 x i16>*
  %145 = load <8 x i16>, <8 x i16>* %144, align 16
  %146 = bitcast i16* %142 to <8 x i16>*
  %147 = load <8 x i16>, <8 x i16>* %146, align 16
  %148 = sub <8 x i16> %145, %147
  %149 = sub <8 x i16> zeroinitializer, %148
  %150 = icmp slt <8 x i16> %148, zeroinitializer
  %151 = select <8 x i1> %150, <8 x i16> %149, <8 x i16> %148
  %152 = lshr <8 x i16> %151, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %153 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %152, <8 x i16> zeroinitializer) #5
  %154 = lshr <8 x i16> %153, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %155 = getelementptr inbounds i16, i16* %9, i64 72
  %156 = bitcast i16* %155 to <8 x i16>*
  %157 = load <8 x i16>, <8 x i16>* %156, align 16
  %158 = getelementptr inbounds i16, i16* %10, i64 72
  %159 = bitcast i16* %158 to <8 x i16>*
  %160 = load <8 x i16>, <8 x i16>* %159, align 16
  %161 = sub <8 x i16> %157, %160
  %162 = sub <8 x i16> zeroinitializer, %161
  %163 = icmp slt <8 x i16> %161, zeroinitializer
  %164 = select <8 x i1> %163, <8 x i16> %162, <8 x i16> %161
  %165 = lshr <8 x i16> %164, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %166 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %165, <8 x i16> zeroinitializer) #5
  %167 = lshr <8 x i16> %166, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %168 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %154, <8 x i16> %167) #5
  %169 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %168, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %170 = icmp slt <16 x i8> %169, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %171 = select <16 x i1> %170, <16 x i8> %169, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %172 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %171
  %173 = bitcast i8* %143 to <16 x i8>*
  store <16 x i8> %172, <16 x i8>* %173, align 16
  %174 = getelementptr inbounds i16, i16* %9, i64 80
  %175 = getelementptr inbounds i16, i16* %10, i64 80
  %176 = getelementptr inbounds i8, i8* %143, i64 16
  %177 = bitcast i16* %174 to <8 x i16>*
  %178 = load <8 x i16>, <8 x i16>* %177, align 16
  %179 = bitcast i16* %175 to <8 x i16>*
  %180 = load <8 x i16>, <8 x i16>* %179, align 16
  %181 = sub <8 x i16> %178, %180
  %182 = sub <8 x i16> zeroinitializer, %181
  %183 = icmp slt <8 x i16> %181, zeroinitializer
  %184 = select <8 x i1> %183, <8 x i16> %182, <8 x i16> %181
  %185 = lshr <8 x i16> %184, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %186 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %185, <8 x i16> zeroinitializer) #5
  %187 = lshr <8 x i16> %186, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %188 = getelementptr inbounds i16, i16* %9, i64 88
  %189 = bitcast i16* %188 to <8 x i16>*
  %190 = load <8 x i16>, <8 x i16>* %189, align 16
  %191 = getelementptr inbounds i16, i16* %10, i64 88
  %192 = bitcast i16* %191 to <8 x i16>*
  %193 = load <8 x i16>, <8 x i16>* %192, align 16
  %194 = sub <8 x i16> %190, %193
  %195 = sub <8 x i16> zeroinitializer, %194
  %196 = icmp slt <8 x i16> %194, zeroinitializer
  %197 = select <8 x i1> %196, <8 x i16> %195, <8 x i16> %194
  %198 = lshr <8 x i16> %197, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %199 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %198, <8 x i16> zeroinitializer) #5
  %200 = lshr <8 x i16> %199, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %201 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %187, <8 x i16> %200) #5
  %202 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %201, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %203 = icmp slt <16 x i8> %202, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %204 = select <16 x i1> %203, <16 x i8> %202, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %205 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %204
  %206 = bitcast i8* %176 to <16 x i8>*
  store <16 x i8> %205, <16 x i8>* %206, align 16
  %207 = getelementptr inbounds i16, i16* %9, i64 96
  %208 = getelementptr inbounds i16, i16* %10, i64 96
  %209 = getelementptr inbounds i8, i8* %143, i64 32
  %210 = bitcast i16* %207 to <8 x i16>*
  %211 = load <8 x i16>, <8 x i16>* %210, align 16
  %212 = bitcast i16* %208 to <8 x i16>*
  %213 = load <8 x i16>, <8 x i16>* %212, align 16
  %214 = sub <8 x i16> %211, %213
  %215 = sub <8 x i16> zeroinitializer, %214
  %216 = icmp slt <8 x i16> %214, zeroinitializer
  %217 = select <8 x i1> %216, <8 x i16> %215, <8 x i16> %214
  %218 = lshr <8 x i16> %217, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %219 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %218, <8 x i16> zeroinitializer) #5
  %220 = lshr <8 x i16> %219, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %221 = getelementptr inbounds i16, i16* %9, i64 104
  %222 = bitcast i16* %221 to <8 x i16>*
  %223 = load <8 x i16>, <8 x i16>* %222, align 16
  %224 = getelementptr inbounds i16, i16* %10, i64 104
  %225 = bitcast i16* %224 to <8 x i16>*
  %226 = load <8 x i16>, <8 x i16>* %225, align 16
  %227 = sub <8 x i16> %223, %226
  %228 = sub <8 x i16> zeroinitializer, %227
  %229 = icmp slt <8 x i16> %227, zeroinitializer
  %230 = select <8 x i1> %229, <8 x i16> %228, <8 x i16> %227
  %231 = lshr <8 x i16> %230, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %232 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %231, <8 x i16> zeroinitializer) #5
  %233 = lshr <8 x i16> %232, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %234 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %220, <8 x i16> %233) #5
  %235 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %234, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %236 = icmp slt <16 x i8> %235, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %237 = select <16 x i1> %236, <16 x i8> %235, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %238 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %237
  %239 = bitcast i8* %209 to <16 x i8>*
  store <16 x i8> %238, <16 x i8>* %239, align 16
  %240 = getelementptr inbounds i16, i16* %9, i64 112
  %241 = getelementptr inbounds i16, i16* %10, i64 112
  %242 = getelementptr inbounds i8, i8* %143, i64 48
  %243 = bitcast i16* %240 to <8 x i16>*
  %244 = load <8 x i16>, <8 x i16>* %243, align 16
  %245 = bitcast i16* %241 to <8 x i16>*
  %246 = load <8 x i16>, <8 x i16>* %245, align 16
  %247 = sub <8 x i16> %244, %246
  %248 = sub <8 x i16> zeroinitializer, %247
  %249 = icmp slt <8 x i16> %247, zeroinitializer
  %250 = select <8 x i1> %249, <8 x i16> %248, <8 x i16> %247
  %251 = lshr <8 x i16> %250, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %252 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %251, <8 x i16> zeroinitializer) #5
  %253 = lshr <8 x i16> %252, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %254 = getelementptr inbounds i16, i16* %9, i64 120
  %255 = bitcast i16* %254 to <8 x i16>*
  %256 = load <8 x i16>, <8 x i16>* %255, align 16
  %257 = getelementptr inbounds i16, i16* %10, i64 120
  %258 = bitcast i16* %257 to <8 x i16>*
  %259 = load <8 x i16>, <8 x i16>* %258, align 16
  %260 = sub <8 x i16> %256, %259
  %261 = sub <8 x i16> zeroinitializer, %260
  %262 = icmp slt <8 x i16> %260, zeroinitializer
  %263 = select <8 x i1> %262, <8 x i16> %261, <8 x i16> %260
  %264 = lshr <8 x i16> %263, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %265 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %264, <8 x i16> zeroinitializer) #5
  %266 = lshr <8 x i16> %265, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %267 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %253, <8 x i16> %266) #5
  %268 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %267, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %269 = icmp slt <16 x i8> %268, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %270 = select <16 x i1> %269, <16 x i8> %268, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %271 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %270
  %272 = bitcast i8* %242 to <16 x i8>*
  store <16 x i8> %271, <16 x i8>* %272, align 16
  %273 = getelementptr inbounds i16, i16* %9, i64 128
  %274 = getelementptr inbounds i16, i16* %10, i64 128
  %275 = getelementptr inbounds i8, i8* %143, i64 %3
  %276 = bitcast i16* %273 to <8 x i16>*
  %277 = load <8 x i16>, <8 x i16>* %276, align 16
  %278 = bitcast i16* %274 to <8 x i16>*
  %279 = load <8 x i16>, <8 x i16>* %278, align 16
  %280 = sub <8 x i16> %277, %279
  %281 = sub <8 x i16> zeroinitializer, %280
  %282 = icmp slt <8 x i16> %280, zeroinitializer
  %283 = select <8 x i1> %282, <8 x i16> %281, <8 x i16> %280
  %284 = lshr <8 x i16> %283, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %285 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %284, <8 x i16> zeroinitializer) #5
  %286 = lshr <8 x i16> %285, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %287 = getelementptr inbounds i16, i16* %9, i64 136
  %288 = bitcast i16* %287 to <8 x i16>*
  %289 = load <8 x i16>, <8 x i16>* %288, align 16
  %290 = getelementptr inbounds i16, i16* %10, i64 136
  %291 = bitcast i16* %290 to <8 x i16>*
  %292 = load <8 x i16>, <8 x i16>* %291, align 16
  %293 = sub <8 x i16> %289, %292
  %294 = sub <8 x i16> zeroinitializer, %293
  %295 = icmp slt <8 x i16> %293, zeroinitializer
  %296 = select <8 x i1> %295, <8 x i16> %294, <8 x i16> %293
  %297 = lshr <8 x i16> %296, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %298 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %297, <8 x i16> zeroinitializer) #5
  %299 = lshr <8 x i16> %298, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %300 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %286, <8 x i16> %299) #5
  %301 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %300, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %302 = icmp slt <16 x i8> %301, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %303 = select <16 x i1> %302, <16 x i8> %301, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %304 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %303
  %305 = bitcast i8* %275 to <16 x i8>*
  store <16 x i8> %304, <16 x i8>* %305, align 16
  %306 = getelementptr inbounds i16, i16* %9, i64 144
  %307 = getelementptr inbounds i16, i16* %10, i64 144
  %308 = getelementptr inbounds i8, i8* %275, i64 16
  %309 = bitcast i16* %306 to <8 x i16>*
  %310 = load <8 x i16>, <8 x i16>* %309, align 16
  %311 = bitcast i16* %307 to <8 x i16>*
  %312 = load <8 x i16>, <8 x i16>* %311, align 16
  %313 = sub <8 x i16> %310, %312
  %314 = sub <8 x i16> zeroinitializer, %313
  %315 = icmp slt <8 x i16> %313, zeroinitializer
  %316 = select <8 x i1> %315, <8 x i16> %314, <8 x i16> %313
  %317 = lshr <8 x i16> %316, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %318 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %317, <8 x i16> zeroinitializer) #5
  %319 = lshr <8 x i16> %318, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %320 = getelementptr inbounds i16, i16* %9, i64 152
  %321 = bitcast i16* %320 to <8 x i16>*
  %322 = load <8 x i16>, <8 x i16>* %321, align 16
  %323 = getelementptr inbounds i16, i16* %10, i64 152
  %324 = bitcast i16* %323 to <8 x i16>*
  %325 = load <8 x i16>, <8 x i16>* %324, align 16
  %326 = sub <8 x i16> %322, %325
  %327 = sub <8 x i16> zeroinitializer, %326
  %328 = icmp slt <8 x i16> %326, zeroinitializer
  %329 = select <8 x i1> %328, <8 x i16> %327, <8 x i16> %326
  %330 = lshr <8 x i16> %329, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %331 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %330, <8 x i16> zeroinitializer) #5
  %332 = lshr <8 x i16> %331, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %333 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %319, <8 x i16> %332) #5
  %334 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %333, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %335 = icmp slt <16 x i8> %334, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %336 = select <16 x i1> %335, <16 x i8> %334, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %337 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %336
  %338 = bitcast i8* %308 to <16 x i8>*
  store <16 x i8> %337, <16 x i8>* %338, align 16
  %339 = getelementptr inbounds i16, i16* %9, i64 160
  %340 = getelementptr inbounds i16, i16* %10, i64 160
  %341 = getelementptr inbounds i8, i8* %275, i64 32
  %342 = bitcast i16* %339 to <8 x i16>*
  %343 = load <8 x i16>, <8 x i16>* %342, align 16
  %344 = bitcast i16* %340 to <8 x i16>*
  %345 = load <8 x i16>, <8 x i16>* %344, align 16
  %346 = sub <8 x i16> %343, %345
  %347 = sub <8 x i16> zeroinitializer, %346
  %348 = icmp slt <8 x i16> %346, zeroinitializer
  %349 = select <8 x i1> %348, <8 x i16> %347, <8 x i16> %346
  %350 = lshr <8 x i16> %349, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %351 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %350, <8 x i16> zeroinitializer) #5
  %352 = lshr <8 x i16> %351, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %353 = getelementptr inbounds i16, i16* %9, i64 168
  %354 = bitcast i16* %353 to <8 x i16>*
  %355 = load <8 x i16>, <8 x i16>* %354, align 16
  %356 = getelementptr inbounds i16, i16* %10, i64 168
  %357 = bitcast i16* %356 to <8 x i16>*
  %358 = load <8 x i16>, <8 x i16>* %357, align 16
  %359 = sub <8 x i16> %355, %358
  %360 = sub <8 x i16> zeroinitializer, %359
  %361 = icmp slt <8 x i16> %359, zeroinitializer
  %362 = select <8 x i1> %361, <8 x i16> %360, <8 x i16> %359
  %363 = lshr <8 x i16> %362, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %364 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %363, <8 x i16> zeroinitializer) #5
  %365 = lshr <8 x i16> %364, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %366 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %352, <8 x i16> %365) #5
  %367 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %366, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %368 = icmp slt <16 x i8> %367, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %369 = select <16 x i1> %368, <16 x i8> %367, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %370 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %369
  %371 = bitcast i8* %341 to <16 x i8>*
  store <16 x i8> %370, <16 x i8>* %371, align 16
  %372 = getelementptr inbounds i16, i16* %9, i64 176
  %373 = getelementptr inbounds i16, i16* %10, i64 176
  %374 = getelementptr inbounds i8, i8* %275, i64 48
  %375 = bitcast i16* %372 to <8 x i16>*
  %376 = load <8 x i16>, <8 x i16>* %375, align 16
  %377 = bitcast i16* %373 to <8 x i16>*
  %378 = load <8 x i16>, <8 x i16>* %377, align 16
  %379 = sub <8 x i16> %376, %378
  %380 = sub <8 x i16> zeroinitializer, %379
  %381 = icmp slt <8 x i16> %379, zeroinitializer
  %382 = select <8 x i1> %381, <8 x i16> %380, <8 x i16> %379
  %383 = lshr <8 x i16> %382, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %384 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %383, <8 x i16> zeroinitializer) #5
  %385 = lshr <8 x i16> %384, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %386 = getelementptr inbounds i16, i16* %9, i64 184
  %387 = bitcast i16* %386 to <8 x i16>*
  %388 = load <8 x i16>, <8 x i16>* %387, align 16
  %389 = getelementptr inbounds i16, i16* %10, i64 184
  %390 = bitcast i16* %389 to <8 x i16>*
  %391 = load <8 x i16>, <8 x i16>* %390, align 16
  %392 = sub <8 x i16> %388, %391
  %393 = sub <8 x i16> zeroinitializer, %392
  %394 = icmp slt <8 x i16> %392, zeroinitializer
  %395 = select <8 x i1> %394, <8 x i16> %393, <8 x i16> %392
  %396 = lshr <8 x i16> %395, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %397 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %396, <8 x i16> zeroinitializer) #5
  %398 = lshr <8 x i16> %397, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %399 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %385, <8 x i16> %398) #5
  %400 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %399, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %401 = icmp slt <16 x i8> %400, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %402 = select <16 x i1> %401, <16 x i8> %400, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %403 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %402
  %404 = bitcast i8* %374 to <16 x i8>*
  store <16 x i8> %403, <16 x i8>* %404, align 16
  %405 = getelementptr inbounds i16, i16* %9, i64 192
  %406 = getelementptr inbounds i16, i16* %10, i64 192
  %407 = getelementptr inbounds i8, i8* %275, i64 %3
  %408 = add nuw nsw i32 %11, 1
  %409 = icmp eq i32 %408, 21
  br i1 %409, label %410, label %7

410:                                              ; preds = %7
  %411 = bitcast i16* %405 to <8 x i16>*
  %412 = load <8 x i16>, <8 x i16>* %411, align 16
  %413 = bitcast i16* %406 to <8 x i16>*
  %414 = load <8 x i16>, <8 x i16>* %413, align 16
  %415 = sub <8 x i16> %412, %414
  %416 = sub <8 x i16> zeroinitializer, %415
  %417 = icmp slt <8 x i16> %415, zeroinitializer
  %418 = select <8 x i1> %417, <8 x i16> %416, <8 x i16> %415
  %419 = lshr <8 x i16> %418, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %420 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %419, <8 x i16> zeroinitializer) #5
  %421 = lshr <8 x i16> %420, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %422 = getelementptr inbounds i16, i16* %9, i64 200
  %423 = bitcast i16* %422 to <8 x i16>*
  %424 = load <8 x i16>, <8 x i16>* %423, align 16
  %425 = getelementptr inbounds i16, i16* %10, i64 200
  %426 = bitcast i16* %425 to <8 x i16>*
  %427 = load <8 x i16>, <8 x i16>* %426, align 16
  %428 = sub <8 x i16> %424, %427
  %429 = sub <8 x i16> zeroinitializer, %428
  %430 = icmp slt <8 x i16> %428, zeroinitializer
  %431 = select <8 x i1> %430, <8 x i16> %429, <8 x i16> %428
  %432 = lshr <8 x i16> %431, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %433 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %432, <8 x i16> zeroinitializer) #5
  %434 = lshr <8 x i16> %433, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %435 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %421, <8 x i16> %434) #5
  %436 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %435, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %437 = icmp slt <16 x i8> %436, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %438 = select <16 x i1> %437, <16 x i8> %436, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %439 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %438
  %440 = bitcast i8* %407 to <16 x i8>*
  store <16 x i8> %439, <16 x i8>* %440, align 16
  %441 = getelementptr inbounds i16, i16* %9, i64 208
  %442 = getelementptr inbounds i16, i16* %10, i64 208
  %443 = getelementptr inbounds i8, i8* %407, i64 16
  %444 = bitcast i16* %441 to <8 x i16>*
  %445 = load <8 x i16>, <8 x i16>* %444, align 16
  %446 = bitcast i16* %442 to <8 x i16>*
  %447 = load <8 x i16>, <8 x i16>* %446, align 16
  %448 = sub <8 x i16> %445, %447
  %449 = sub <8 x i16> zeroinitializer, %448
  %450 = icmp slt <8 x i16> %448, zeroinitializer
  %451 = select <8 x i1> %450, <8 x i16> %449, <8 x i16> %448
  %452 = lshr <8 x i16> %451, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %453 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %452, <8 x i16> zeroinitializer) #5
  %454 = lshr <8 x i16> %453, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %455 = getelementptr inbounds i16, i16* %9, i64 216
  %456 = bitcast i16* %455 to <8 x i16>*
  %457 = load <8 x i16>, <8 x i16>* %456, align 16
  %458 = getelementptr inbounds i16, i16* %10, i64 216
  %459 = bitcast i16* %458 to <8 x i16>*
  %460 = load <8 x i16>, <8 x i16>* %459, align 16
  %461 = sub <8 x i16> %457, %460
  %462 = sub <8 x i16> zeroinitializer, %461
  %463 = icmp slt <8 x i16> %461, zeroinitializer
  %464 = select <8 x i1> %463, <8 x i16> %462, <8 x i16> %461
  %465 = lshr <8 x i16> %464, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %466 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %465, <8 x i16> zeroinitializer) #5
  %467 = lshr <8 x i16> %466, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %468 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %454, <8 x i16> %467) #5
  %469 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %468, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %470 = icmp slt <16 x i8> %469, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %471 = select <16 x i1> %470, <16 x i8> %469, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %472 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %471
  %473 = bitcast i8* %443 to <16 x i8>*
  store <16 x i8> %472, <16 x i8>* %473, align 16
  %474 = getelementptr inbounds i16, i16* %9, i64 224
  %475 = getelementptr inbounds i16, i16* %10, i64 224
  %476 = getelementptr inbounds i8, i8* %407, i64 32
  %477 = bitcast i16* %474 to <8 x i16>*
  %478 = load <8 x i16>, <8 x i16>* %477, align 16
  %479 = bitcast i16* %475 to <8 x i16>*
  %480 = load <8 x i16>, <8 x i16>* %479, align 16
  %481 = sub <8 x i16> %478, %480
  %482 = sub <8 x i16> zeroinitializer, %481
  %483 = icmp slt <8 x i16> %481, zeroinitializer
  %484 = select <8 x i1> %483, <8 x i16> %482, <8 x i16> %481
  %485 = lshr <8 x i16> %484, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %486 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %485, <8 x i16> zeroinitializer) #5
  %487 = lshr <8 x i16> %486, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %488 = getelementptr inbounds i16, i16* %9, i64 232
  %489 = bitcast i16* %488 to <8 x i16>*
  %490 = load <8 x i16>, <8 x i16>* %489, align 16
  %491 = getelementptr inbounds i16, i16* %10, i64 232
  %492 = bitcast i16* %491 to <8 x i16>*
  %493 = load <8 x i16>, <8 x i16>* %492, align 16
  %494 = sub <8 x i16> %490, %493
  %495 = sub <8 x i16> zeroinitializer, %494
  %496 = icmp slt <8 x i16> %494, zeroinitializer
  %497 = select <8 x i1> %496, <8 x i16> %495, <8 x i16> %494
  %498 = lshr <8 x i16> %497, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %499 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %498, <8 x i16> zeroinitializer) #5
  %500 = lshr <8 x i16> %499, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %501 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %487, <8 x i16> %500) #5
  %502 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %501, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %503 = icmp slt <16 x i8> %502, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %504 = select <16 x i1> %503, <16 x i8> %502, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %505 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %504
  %506 = bitcast i8* %476 to <16 x i8>*
  store <16 x i8> %505, <16 x i8>* %506, align 16
  %507 = getelementptr inbounds i16, i16* %9, i64 240
  %508 = getelementptr inbounds i16, i16* %10, i64 240
  %509 = getelementptr inbounds i8, i8* %407, i64 48
  %510 = bitcast i16* %507 to <8 x i16>*
  %511 = load <8 x i16>, <8 x i16>* %510, align 16
  %512 = bitcast i16* %508 to <8 x i16>*
  %513 = load <8 x i16>, <8 x i16>* %512, align 16
  %514 = sub <8 x i16> %511, %513
  %515 = sub <8 x i16> zeroinitializer, %514
  %516 = icmp slt <8 x i16> %514, zeroinitializer
  %517 = select <8 x i1> %516, <8 x i16> %515, <8 x i16> %514
  %518 = lshr <8 x i16> %517, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %519 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %518, <8 x i16> zeroinitializer) #5
  %520 = lshr <8 x i16> %519, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %521 = getelementptr inbounds i16, i16* %9, i64 248
  %522 = bitcast i16* %521 to <8 x i16>*
  %523 = load <8 x i16>, <8 x i16>* %522, align 16
  %524 = getelementptr inbounds i16, i16* %10, i64 248
  %525 = bitcast i16* %524 to <8 x i16>*
  %526 = load <8 x i16>, <8 x i16>* %525, align 16
  %527 = sub <8 x i16> %523, %526
  %528 = sub <8 x i16> zeroinitializer, %527
  %529 = icmp slt <8 x i16> %527, zeroinitializer
  %530 = select <8 x i1> %529, <8 x i16> %528, <8 x i16> %527
  %531 = lshr <8 x i16> %530, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %532 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %531, <8 x i16> zeroinitializer) #5
  %533 = lshr <8 x i16> %532, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %534 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %520, <8 x i16> %533) #5
  %535 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %534, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %536 = icmp slt <16 x i8> %535, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %537 = select <16 x i1> %536, <16 x i8> %535, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %538 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %537
  %539 = bitcast i8* %509 to <16 x i8>*
  store <16 x i8> %538, <16 x i8>* %539, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_121WeightMask64x128_SSE4ILb0EEEvPKvS5_Phl(i8* readonly, i8* readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %395, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %393, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %394, %7 ]
  %11 = phi i32 [ 0, %4 ], [ %396, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = sub <8 x i16> %13, %15
  %17 = sub <8 x i16> zeroinitializer, %16
  %18 = icmp slt <8 x i16> %16, zeroinitializer
  %19 = select <8 x i1> %18, <8 x i16> %17, <8 x i16> %16
  %20 = lshr <8 x i16> %19, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %21 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %20, <8 x i16> zeroinitializer) #5
  %22 = lshr <8 x i16> %21, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %23 = getelementptr inbounds i16, i16* %9, i64 8
  %24 = bitcast i16* %23 to <8 x i16>*
  %25 = load <8 x i16>, <8 x i16>* %24, align 16
  %26 = getelementptr inbounds i16, i16* %10, i64 8
  %27 = bitcast i16* %26 to <8 x i16>*
  %28 = load <8 x i16>, <8 x i16>* %27, align 16
  %29 = sub <8 x i16> %25, %28
  %30 = sub <8 x i16> zeroinitializer, %29
  %31 = icmp slt <8 x i16> %29, zeroinitializer
  %32 = select <8 x i1> %31, <8 x i16> %30, <8 x i16> %29
  %33 = lshr <8 x i16> %32, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %34 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %33, <8 x i16> zeroinitializer) #5
  %35 = lshr <8 x i16> %34, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %36 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %22, <8 x i16> %35) #5
  %37 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %36, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %38 = icmp slt <16 x i8> %37, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %39 = select <16 x i1> %38, <16 x i8> %37, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %40 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %39, <16 x i8>* %40, align 16
  %41 = getelementptr inbounds i16, i16* %9, i64 16
  %42 = getelementptr inbounds i16, i16* %10, i64 16
  %43 = getelementptr inbounds i8, i8* %8, i64 16
  %44 = bitcast i16* %41 to <8 x i16>*
  %45 = load <8 x i16>, <8 x i16>* %44, align 16
  %46 = bitcast i16* %42 to <8 x i16>*
  %47 = load <8 x i16>, <8 x i16>* %46, align 16
  %48 = sub <8 x i16> %45, %47
  %49 = sub <8 x i16> zeroinitializer, %48
  %50 = icmp slt <8 x i16> %48, zeroinitializer
  %51 = select <8 x i1> %50, <8 x i16> %49, <8 x i16> %48
  %52 = lshr <8 x i16> %51, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %53 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %52, <8 x i16> zeroinitializer) #5
  %54 = lshr <8 x i16> %53, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %55 = getelementptr inbounds i16, i16* %9, i64 24
  %56 = bitcast i16* %55 to <8 x i16>*
  %57 = load <8 x i16>, <8 x i16>* %56, align 16
  %58 = getelementptr inbounds i16, i16* %10, i64 24
  %59 = bitcast i16* %58 to <8 x i16>*
  %60 = load <8 x i16>, <8 x i16>* %59, align 16
  %61 = sub <8 x i16> %57, %60
  %62 = sub <8 x i16> zeroinitializer, %61
  %63 = icmp slt <8 x i16> %61, zeroinitializer
  %64 = select <8 x i1> %63, <8 x i16> %62, <8 x i16> %61
  %65 = lshr <8 x i16> %64, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %66 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %65, <8 x i16> zeroinitializer) #5
  %67 = lshr <8 x i16> %66, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %68 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %54, <8 x i16> %67) #5
  %69 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %68, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %70 = icmp slt <16 x i8> %69, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %71 = select <16 x i1> %70, <16 x i8> %69, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %72 = bitcast i8* %43 to <16 x i8>*
  store <16 x i8> %71, <16 x i8>* %72, align 16
  %73 = getelementptr inbounds i16, i16* %9, i64 32
  %74 = getelementptr inbounds i16, i16* %10, i64 32
  %75 = getelementptr inbounds i8, i8* %8, i64 32
  %76 = bitcast i16* %73 to <8 x i16>*
  %77 = load <8 x i16>, <8 x i16>* %76, align 16
  %78 = bitcast i16* %74 to <8 x i16>*
  %79 = load <8 x i16>, <8 x i16>* %78, align 16
  %80 = sub <8 x i16> %77, %79
  %81 = sub <8 x i16> zeroinitializer, %80
  %82 = icmp slt <8 x i16> %80, zeroinitializer
  %83 = select <8 x i1> %82, <8 x i16> %81, <8 x i16> %80
  %84 = lshr <8 x i16> %83, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %85 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %84, <8 x i16> zeroinitializer) #5
  %86 = lshr <8 x i16> %85, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %87 = getelementptr inbounds i16, i16* %9, i64 40
  %88 = bitcast i16* %87 to <8 x i16>*
  %89 = load <8 x i16>, <8 x i16>* %88, align 16
  %90 = getelementptr inbounds i16, i16* %10, i64 40
  %91 = bitcast i16* %90 to <8 x i16>*
  %92 = load <8 x i16>, <8 x i16>* %91, align 16
  %93 = sub <8 x i16> %89, %92
  %94 = sub <8 x i16> zeroinitializer, %93
  %95 = icmp slt <8 x i16> %93, zeroinitializer
  %96 = select <8 x i1> %95, <8 x i16> %94, <8 x i16> %93
  %97 = lshr <8 x i16> %96, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %98 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %97, <8 x i16> zeroinitializer) #5
  %99 = lshr <8 x i16> %98, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %100 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %86, <8 x i16> %99) #5
  %101 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %100, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %102 = icmp slt <16 x i8> %101, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %103 = select <16 x i1> %102, <16 x i8> %101, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %104 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %103, <16 x i8>* %104, align 16
  %105 = getelementptr inbounds i16, i16* %9, i64 48
  %106 = getelementptr inbounds i16, i16* %10, i64 48
  %107 = getelementptr inbounds i8, i8* %8, i64 48
  %108 = bitcast i16* %105 to <8 x i16>*
  %109 = load <8 x i16>, <8 x i16>* %108, align 16
  %110 = bitcast i16* %106 to <8 x i16>*
  %111 = load <8 x i16>, <8 x i16>* %110, align 16
  %112 = sub <8 x i16> %109, %111
  %113 = sub <8 x i16> zeroinitializer, %112
  %114 = icmp slt <8 x i16> %112, zeroinitializer
  %115 = select <8 x i1> %114, <8 x i16> %113, <8 x i16> %112
  %116 = lshr <8 x i16> %115, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %117 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %116, <8 x i16> zeroinitializer) #5
  %118 = lshr <8 x i16> %117, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %119 = getelementptr inbounds i16, i16* %9, i64 56
  %120 = bitcast i16* %119 to <8 x i16>*
  %121 = load <8 x i16>, <8 x i16>* %120, align 16
  %122 = getelementptr inbounds i16, i16* %10, i64 56
  %123 = bitcast i16* %122 to <8 x i16>*
  %124 = load <8 x i16>, <8 x i16>* %123, align 16
  %125 = sub <8 x i16> %121, %124
  %126 = sub <8 x i16> zeroinitializer, %125
  %127 = icmp slt <8 x i16> %125, zeroinitializer
  %128 = select <8 x i1> %127, <8 x i16> %126, <8 x i16> %125
  %129 = lshr <8 x i16> %128, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %130 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %129, <8 x i16> zeroinitializer) #5
  %131 = lshr <8 x i16> %130, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %132 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %118, <8 x i16> %131) #5
  %133 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %132, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %134 = icmp slt <16 x i8> %133, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %135 = select <16 x i1> %134, <16 x i8> %133, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %136 = bitcast i8* %107 to <16 x i8>*
  store <16 x i8> %135, <16 x i8>* %136, align 16
  %137 = getelementptr inbounds i16, i16* %9, i64 64
  %138 = getelementptr inbounds i16, i16* %10, i64 64
  %139 = getelementptr inbounds i8, i8* %8, i64 %3
  %140 = bitcast i16* %137 to <8 x i16>*
  %141 = load <8 x i16>, <8 x i16>* %140, align 16
  %142 = bitcast i16* %138 to <8 x i16>*
  %143 = load <8 x i16>, <8 x i16>* %142, align 16
  %144 = sub <8 x i16> %141, %143
  %145 = sub <8 x i16> zeroinitializer, %144
  %146 = icmp slt <8 x i16> %144, zeroinitializer
  %147 = select <8 x i1> %146, <8 x i16> %145, <8 x i16> %144
  %148 = lshr <8 x i16> %147, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %149 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %148, <8 x i16> zeroinitializer) #5
  %150 = lshr <8 x i16> %149, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %151 = getelementptr inbounds i16, i16* %9, i64 72
  %152 = bitcast i16* %151 to <8 x i16>*
  %153 = load <8 x i16>, <8 x i16>* %152, align 16
  %154 = getelementptr inbounds i16, i16* %10, i64 72
  %155 = bitcast i16* %154 to <8 x i16>*
  %156 = load <8 x i16>, <8 x i16>* %155, align 16
  %157 = sub <8 x i16> %153, %156
  %158 = sub <8 x i16> zeroinitializer, %157
  %159 = icmp slt <8 x i16> %157, zeroinitializer
  %160 = select <8 x i1> %159, <8 x i16> %158, <8 x i16> %157
  %161 = lshr <8 x i16> %160, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %162 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %161, <8 x i16> zeroinitializer) #5
  %163 = lshr <8 x i16> %162, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %164 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %150, <8 x i16> %163) #5
  %165 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %164, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %166 = icmp slt <16 x i8> %165, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %167 = select <16 x i1> %166, <16 x i8> %165, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %168 = bitcast i8* %139 to <16 x i8>*
  store <16 x i8> %167, <16 x i8>* %168, align 16
  %169 = getelementptr inbounds i16, i16* %9, i64 80
  %170 = getelementptr inbounds i16, i16* %10, i64 80
  %171 = getelementptr inbounds i8, i8* %139, i64 16
  %172 = bitcast i16* %169 to <8 x i16>*
  %173 = load <8 x i16>, <8 x i16>* %172, align 16
  %174 = bitcast i16* %170 to <8 x i16>*
  %175 = load <8 x i16>, <8 x i16>* %174, align 16
  %176 = sub <8 x i16> %173, %175
  %177 = sub <8 x i16> zeroinitializer, %176
  %178 = icmp slt <8 x i16> %176, zeroinitializer
  %179 = select <8 x i1> %178, <8 x i16> %177, <8 x i16> %176
  %180 = lshr <8 x i16> %179, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %181 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %180, <8 x i16> zeroinitializer) #5
  %182 = lshr <8 x i16> %181, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %183 = getelementptr inbounds i16, i16* %9, i64 88
  %184 = bitcast i16* %183 to <8 x i16>*
  %185 = load <8 x i16>, <8 x i16>* %184, align 16
  %186 = getelementptr inbounds i16, i16* %10, i64 88
  %187 = bitcast i16* %186 to <8 x i16>*
  %188 = load <8 x i16>, <8 x i16>* %187, align 16
  %189 = sub <8 x i16> %185, %188
  %190 = sub <8 x i16> zeroinitializer, %189
  %191 = icmp slt <8 x i16> %189, zeroinitializer
  %192 = select <8 x i1> %191, <8 x i16> %190, <8 x i16> %189
  %193 = lshr <8 x i16> %192, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %194 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %193, <8 x i16> zeroinitializer) #5
  %195 = lshr <8 x i16> %194, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %196 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %182, <8 x i16> %195) #5
  %197 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %196, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %198 = icmp slt <16 x i8> %197, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %199 = select <16 x i1> %198, <16 x i8> %197, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %200 = bitcast i8* %171 to <16 x i8>*
  store <16 x i8> %199, <16 x i8>* %200, align 16
  %201 = getelementptr inbounds i16, i16* %9, i64 96
  %202 = getelementptr inbounds i16, i16* %10, i64 96
  %203 = getelementptr inbounds i8, i8* %139, i64 32
  %204 = bitcast i16* %201 to <8 x i16>*
  %205 = load <8 x i16>, <8 x i16>* %204, align 16
  %206 = bitcast i16* %202 to <8 x i16>*
  %207 = load <8 x i16>, <8 x i16>* %206, align 16
  %208 = sub <8 x i16> %205, %207
  %209 = sub <8 x i16> zeroinitializer, %208
  %210 = icmp slt <8 x i16> %208, zeroinitializer
  %211 = select <8 x i1> %210, <8 x i16> %209, <8 x i16> %208
  %212 = lshr <8 x i16> %211, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %213 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %212, <8 x i16> zeroinitializer) #5
  %214 = lshr <8 x i16> %213, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %215 = getelementptr inbounds i16, i16* %9, i64 104
  %216 = bitcast i16* %215 to <8 x i16>*
  %217 = load <8 x i16>, <8 x i16>* %216, align 16
  %218 = getelementptr inbounds i16, i16* %10, i64 104
  %219 = bitcast i16* %218 to <8 x i16>*
  %220 = load <8 x i16>, <8 x i16>* %219, align 16
  %221 = sub <8 x i16> %217, %220
  %222 = sub <8 x i16> zeroinitializer, %221
  %223 = icmp slt <8 x i16> %221, zeroinitializer
  %224 = select <8 x i1> %223, <8 x i16> %222, <8 x i16> %221
  %225 = lshr <8 x i16> %224, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %226 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %225, <8 x i16> zeroinitializer) #5
  %227 = lshr <8 x i16> %226, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %228 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %214, <8 x i16> %227) #5
  %229 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %228, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %230 = icmp slt <16 x i8> %229, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %231 = select <16 x i1> %230, <16 x i8> %229, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %232 = bitcast i8* %203 to <16 x i8>*
  store <16 x i8> %231, <16 x i8>* %232, align 16
  %233 = getelementptr inbounds i16, i16* %9, i64 112
  %234 = getelementptr inbounds i16, i16* %10, i64 112
  %235 = getelementptr inbounds i8, i8* %139, i64 48
  %236 = bitcast i16* %233 to <8 x i16>*
  %237 = load <8 x i16>, <8 x i16>* %236, align 16
  %238 = bitcast i16* %234 to <8 x i16>*
  %239 = load <8 x i16>, <8 x i16>* %238, align 16
  %240 = sub <8 x i16> %237, %239
  %241 = sub <8 x i16> zeroinitializer, %240
  %242 = icmp slt <8 x i16> %240, zeroinitializer
  %243 = select <8 x i1> %242, <8 x i16> %241, <8 x i16> %240
  %244 = lshr <8 x i16> %243, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %245 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %244, <8 x i16> zeroinitializer) #5
  %246 = lshr <8 x i16> %245, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %247 = getelementptr inbounds i16, i16* %9, i64 120
  %248 = bitcast i16* %247 to <8 x i16>*
  %249 = load <8 x i16>, <8 x i16>* %248, align 16
  %250 = getelementptr inbounds i16, i16* %10, i64 120
  %251 = bitcast i16* %250 to <8 x i16>*
  %252 = load <8 x i16>, <8 x i16>* %251, align 16
  %253 = sub <8 x i16> %249, %252
  %254 = sub <8 x i16> zeroinitializer, %253
  %255 = icmp slt <8 x i16> %253, zeroinitializer
  %256 = select <8 x i1> %255, <8 x i16> %254, <8 x i16> %253
  %257 = lshr <8 x i16> %256, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %258 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %257, <8 x i16> zeroinitializer) #5
  %259 = lshr <8 x i16> %258, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %260 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %246, <8 x i16> %259) #5
  %261 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %260, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %262 = icmp slt <16 x i8> %261, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %263 = select <16 x i1> %262, <16 x i8> %261, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %264 = bitcast i8* %235 to <16 x i8>*
  store <16 x i8> %263, <16 x i8>* %264, align 16
  %265 = getelementptr inbounds i16, i16* %9, i64 128
  %266 = getelementptr inbounds i16, i16* %10, i64 128
  %267 = getelementptr inbounds i8, i8* %139, i64 %3
  %268 = bitcast i16* %265 to <8 x i16>*
  %269 = load <8 x i16>, <8 x i16>* %268, align 16
  %270 = bitcast i16* %266 to <8 x i16>*
  %271 = load <8 x i16>, <8 x i16>* %270, align 16
  %272 = sub <8 x i16> %269, %271
  %273 = sub <8 x i16> zeroinitializer, %272
  %274 = icmp slt <8 x i16> %272, zeroinitializer
  %275 = select <8 x i1> %274, <8 x i16> %273, <8 x i16> %272
  %276 = lshr <8 x i16> %275, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %277 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %276, <8 x i16> zeroinitializer) #5
  %278 = lshr <8 x i16> %277, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %279 = getelementptr inbounds i16, i16* %9, i64 136
  %280 = bitcast i16* %279 to <8 x i16>*
  %281 = load <8 x i16>, <8 x i16>* %280, align 16
  %282 = getelementptr inbounds i16, i16* %10, i64 136
  %283 = bitcast i16* %282 to <8 x i16>*
  %284 = load <8 x i16>, <8 x i16>* %283, align 16
  %285 = sub <8 x i16> %281, %284
  %286 = sub <8 x i16> zeroinitializer, %285
  %287 = icmp slt <8 x i16> %285, zeroinitializer
  %288 = select <8 x i1> %287, <8 x i16> %286, <8 x i16> %285
  %289 = lshr <8 x i16> %288, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %290 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %289, <8 x i16> zeroinitializer) #5
  %291 = lshr <8 x i16> %290, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %292 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %278, <8 x i16> %291) #5
  %293 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %292, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %294 = icmp slt <16 x i8> %293, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %295 = select <16 x i1> %294, <16 x i8> %293, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %296 = bitcast i8* %267 to <16 x i8>*
  store <16 x i8> %295, <16 x i8>* %296, align 16
  %297 = getelementptr inbounds i16, i16* %9, i64 144
  %298 = getelementptr inbounds i16, i16* %10, i64 144
  %299 = getelementptr inbounds i8, i8* %267, i64 16
  %300 = bitcast i16* %297 to <8 x i16>*
  %301 = load <8 x i16>, <8 x i16>* %300, align 16
  %302 = bitcast i16* %298 to <8 x i16>*
  %303 = load <8 x i16>, <8 x i16>* %302, align 16
  %304 = sub <8 x i16> %301, %303
  %305 = sub <8 x i16> zeroinitializer, %304
  %306 = icmp slt <8 x i16> %304, zeroinitializer
  %307 = select <8 x i1> %306, <8 x i16> %305, <8 x i16> %304
  %308 = lshr <8 x i16> %307, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %309 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %308, <8 x i16> zeroinitializer) #5
  %310 = lshr <8 x i16> %309, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %311 = getelementptr inbounds i16, i16* %9, i64 152
  %312 = bitcast i16* %311 to <8 x i16>*
  %313 = load <8 x i16>, <8 x i16>* %312, align 16
  %314 = getelementptr inbounds i16, i16* %10, i64 152
  %315 = bitcast i16* %314 to <8 x i16>*
  %316 = load <8 x i16>, <8 x i16>* %315, align 16
  %317 = sub <8 x i16> %313, %316
  %318 = sub <8 x i16> zeroinitializer, %317
  %319 = icmp slt <8 x i16> %317, zeroinitializer
  %320 = select <8 x i1> %319, <8 x i16> %318, <8 x i16> %317
  %321 = lshr <8 x i16> %320, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %322 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %321, <8 x i16> zeroinitializer) #5
  %323 = lshr <8 x i16> %322, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %324 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %310, <8 x i16> %323) #5
  %325 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %324, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %326 = icmp slt <16 x i8> %325, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %327 = select <16 x i1> %326, <16 x i8> %325, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %328 = bitcast i8* %299 to <16 x i8>*
  store <16 x i8> %327, <16 x i8>* %328, align 16
  %329 = getelementptr inbounds i16, i16* %9, i64 160
  %330 = getelementptr inbounds i16, i16* %10, i64 160
  %331 = getelementptr inbounds i8, i8* %267, i64 32
  %332 = bitcast i16* %329 to <8 x i16>*
  %333 = load <8 x i16>, <8 x i16>* %332, align 16
  %334 = bitcast i16* %330 to <8 x i16>*
  %335 = load <8 x i16>, <8 x i16>* %334, align 16
  %336 = sub <8 x i16> %333, %335
  %337 = sub <8 x i16> zeroinitializer, %336
  %338 = icmp slt <8 x i16> %336, zeroinitializer
  %339 = select <8 x i1> %338, <8 x i16> %337, <8 x i16> %336
  %340 = lshr <8 x i16> %339, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %341 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %340, <8 x i16> zeroinitializer) #5
  %342 = lshr <8 x i16> %341, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %343 = getelementptr inbounds i16, i16* %9, i64 168
  %344 = bitcast i16* %343 to <8 x i16>*
  %345 = load <8 x i16>, <8 x i16>* %344, align 16
  %346 = getelementptr inbounds i16, i16* %10, i64 168
  %347 = bitcast i16* %346 to <8 x i16>*
  %348 = load <8 x i16>, <8 x i16>* %347, align 16
  %349 = sub <8 x i16> %345, %348
  %350 = sub <8 x i16> zeroinitializer, %349
  %351 = icmp slt <8 x i16> %349, zeroinitializer
  %352 = select <8 x i1> %351, <8 x i16> %350, <8 x i16> %349
  %353 = lshr <8 x i16> %352, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %354 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %353, <8 x i16> zeroinitializer) #5
  %355 = lshr <8 x i16> %354, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %356 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %342, <8 x i16> %355) #5
  %357 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %356, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %358 = icmp slt <16 x i8> %357, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %359 = select <16 x i1> %358, <16 x i8> %357, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %360 = bitcast i8* %331 to <16 x i8>*
  store <16 x i8> %359, <16 x i8>* %360, align 16
  %361 = getelementptr inbounds i16, i16* %9, i64 176
  %362 = getelementptr inbounds i16, i16* %10, i64 176
  %363 = getelementptr inbounds i8, i8* %267, i64 48
  %364 = bitcast i16* %361 to <8 x i16>*
  %365 = load <8 x i16>, <8 x i16>* %364, align 16
  %366 = bitcast i16* %362 to <8 x i16>*
  %367 = load <8 x i16>, <8 x i16>* %366, align 16
  %368 = sub <8 x i16> %365, %367
  %369 = sub <8 x i16> zeroinitializer, %368
  %370 = icmp slt <8 x i16> %368, zeroinitializer
  %371 = select <8 x i1> %370, <8 x i16> %369, <8 x i16> %368
  %372 = lshr <8 x i16> %371, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %373 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %372, <8 x i16> zeroinitializer) #5
  %374 = lshr <8 x i16> %373, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %375 = getelementptr inbounds i16, i16* %9, i64 184
  %376 = bitcast i16* %375 to <8 x i16>*
  %377 = load <8 x i16>, <8 x i16>* %376, align 16
  %378 = getelementptr inbounds i16, i16* %10, i64 184
  %379 = bitcast i16* %378 to <8 x i16>*
  %380 = load <8 x i16>, <8 x i16>* %379, align 16
  %381 = sub <8 x i16> %377, %380
  %382 = sub <8 x i16> zeroinitializer, %381
  %383 = icmp slt <8 x i16> %381, zeroinitializer
  %384 = select <8 x i1> %383, <8 x i16> %382, <8 x i16> %381
  %385 = lshr <8 x i16> %384, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %386 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %385, <8 x i16> zeroinitializer) #5
  %387 = lshr <8 x i16> %386, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %388 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %374, <8 x i16> %387) #5
  %389 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %388, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %390 = icmp slt <16 x i8> %389, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %391 = select <16 x i1> %390, <16 x i8> %389, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %392 = bitcast i8* %363 to <16 x i8>*
  store <16 x i8> %391, <16 x i8>* %392, align 16
  %393 = getelementptr inbounds i16, i16* %9, i64 192
  %394 = getelementptr inbounds i16, i16* %10, i64 192
  %395 = getelementptr inbounds i8, i8* %267, i64 %3
  %396 = add nuw nsw i32 %11, 1
  %397 = icmp eq i32 %396, 42
  br i1 %397, label %398, label %7

398:                                              ; preds = %7
  %399 = bitcast i16* %393 to <8 x i16>*
  %400 = load <8 x i16>, <8 x i16>* %399, align 16
  %401 = bitcast i16* %394 to <8 x i16>*
  %402 = load <8 x i16>, <8 x i16>* %401, align 16
  %403 = sub <8 x i16> %400, %402
  %404 = sub <8 x i16> zeroinitializer, %403
  %405 = icmp slt <8 x i16> %403, zeroinitializer
  %406 = select <8 x i1> %405, <8 x i16> %404, <8 x i16> %403
  %407 = lshr <8 x i16> %406, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %408 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %407, <8 x i16> zeroinitializer) #5
  %409 = lshr <8 x i16> %408, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %410 = getelementptr inbounds i16, i16* %9, i64 200
  %411 = bitcast i16* %410 to <8 x i16>*
  %412 = load <8 x i16>, <8 x i16>* %411, align 16
  %413 = getelementptr inbounds i16, i16* %10, i64 200
  %414 = bitcast i16* %413 to <8 x i16>*
  %415 = load <8 x i16>, <8 x i16>* %414, align 16
  %416 = sub <8 x i16> %412, %415
  %417 = sub <8 x i16> zeroinitializer, %416
  %418 = icmp slt <8 x i16> %416, zeroinitializer
  %419 = select <8 x i1> %418, <8 x i16> %417, <8 x i16> %416
  %420 = lshr <8 x i16> %419, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %421 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %420, <8 x i16> zeroinitializer) #5
  %422 = lshr <8 x i16> %421, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %423 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %409, <8 x i16> %422) #5
  %424 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %423, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %425 = icmp slt <16 x i8> %424, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %426 = select <16 x i1> %425, <16 x i8> %424, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %427 = bitcast i8* %395 to <16 x i8>*
  store <16 x i8> %426, <16 x i8>* %427, align 16
  %428 = getelementptr inbounds i16, i16* %9, i64 208
  %429 = getelementptr inbounds i16, i16* %10, i64 208
  %430 = getelementptr inbounds i8, i8* %395, i64 16
  %431 = bitcast i16* %428 to <8 x i16>*
  %432 = load <8 x i16>, <8 x i16>* %431, align 16
  %433 = bitcast i16* %429 to <8 x i16>*
  %434 = load <8 x i16>, <8 x i16>* %433, align 16
  %435 = sub <8 x i16> %432, %434
  %436 = sub <8 x i16> zeroinitializer, %435
  %437 = icmp slt <8 x i16> %435, zeroinitializer
  %438 = select <8 x i1> %437, <8 x i16> %436, <8 x i16> %435
  %439 = lshr <8 x i16> %438, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %440 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %439, <8 x i16> zeroinitializer) #5
  %441 = lshr <8 x i16> %440, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %442 = getelementptr inbounds i16, i16* %9, i64 216
  %443 = bitcast i16* %442 to <8 x i16>*
  %444 = load <8 x i16>, <8 x i16>* %443, align 16
  %445 = getelementptr inbounds i16, i16* %10, i64 216
  %446 = bitcast i16* %445 to <8 x i16>*
  %447 = load <8 x i16>, <8 x i16>* %446, align 16
  %448 = sub <8 x i16> %444, %447
  %449 = sub <8 x i16> zeroinitializer, %448
  %450 = icmp slt <8 x i16> %448, zeroinitializer
  %451 = select <8 x i1> %450, <8 x i16> %449, <8 x i16> %448
  %452 = lshr <8 x i16> %451, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %453 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %452, <8 x i16> zeroinitializer) #5
  %454 = lshr <8 x i16> %453, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %455 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %441, <8 x i16> %454) #5
  %456 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %455, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %457 = icmp slt <16 x i8> %456, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %458 = select <16 x i1> %457, <16 x i8> %456, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %459 = bitcast i8* %430 to <16 x i8>*
  store <16 x i8> %458, <16 x i8>* %459, align 16
  %460 = getelementptr inbounds i16, i16* %9, i64 224
  %461 = getelementptr inbounds i16, i16* %10, i64 224
  %462 = getelementptr inbounds i8, i8* %395, i64 32
  %463 = bitcast i16* %460 to <8 x i16>*
  %464 = load <8 x i16>, <8 x i16>* %463, align 16
  %465 = bitcast i16* %461 to <8 x i16>*
  %466 = load <8 x i16>, <8 x i16>* %465, align 16
  %467 = sub <8 x i16> %464, %466
  %468 = sub <8 x i16> zeroinitializer, %467
  %469 = icmp slt <8 x i16> %467, zeroinitializer
  %470 = select <8 x i1> %469, <8 x i16> %468, <8 x i16> %467
  %471 = lshr <8 x i16> %470, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %472 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %471, <8 x i16> zeroinitializer) #5
  %473 = lshr <8 x i16> %472, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %474 = getelementptr inbounds i16, i16* %9, i64 232
  %475 = bitcast i16* %474 to <8 x i16>*
  %476 = load <8 x i16>, <8 x i16>* %475, align 16
  %477 = getelementptr inbounds i16, i16* %10, i64 232
  %478 = bitcast i16* %477 to <8 x i16>*
  %479 = load <8 x i16>, <8 x i16>* %478, align 16
  %480 = sub <8 x i16> %476, %479
  %481 = sub <8 x i16> zeroinitializer, %480
  %482 = icmp slt <8 x i16> %480, zeroinitializer
  %483 = select <8 x i1> %482, <8 x i16> %481, <8 x i16> %480
  %484 = lshr <8 x i16> %483, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %485 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %484, <8 x i16> zeroinitializer) #5
  %486 = lshr <8 x i16> %485, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %487 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %473, <8 x i16> %486) #5
  %488 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %487, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %489 = icmp slt <16 x i8> %488, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %490 = select <16 x i1> %489, <16 x i8> %488, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %491 = bitcast i8* %462 to <16 x i8>*
  store <16 x i8> %490, <16 x i8>* %491, align 16
  %492 = getelementptr inbounds i16, i16* %9, i64 240
  %493 = getelementptr inbounds i16, i16* %10, i64 240
  %494 = getelementptr inbounds i8, i8* %395, i64 48
  %495 = bitcast i16* %492 to <8 x i16>*
  %496 = load <8 x i16>, <8 x i16>* %495, align 16
  %497 = bitcast i16* %493 to <8 x i16>*
  %498 = load <8 x i16>, <8 x i16>* %497, align 16
  %499 = sub <8 x i16> %496, %498
  %500 = sub <8 x i16> zeroinitializer, %499
  %501 = icmp slt <8 x i16> %499, zeroinitializer
  %502 = select <8 x i1> %501, <8 x i16> %500, <8 x i16> %499
  %503 = lshr <8 x i16> %502, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %504 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %503, <8 x i16> zeroinitializer) #5
  %505 = lshr <8 x i16> %504, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %506 = getelementptr inbounds i16, i16* %9, i64 248
  %507 = bitcast i16* %506 to <8 x i16>*
  %508 = load <8 x i16>, <8 x i16>* %507, align 16
  %509 = getelementptr inbounds i16, i16* %10, i64 248
  %510 = bitcast i16* %509 to <8 x i16>*
  %511 = load <8 x i16>, <8 x i16>* %510, align 16
  %512 = sub <8 x i16> %508, %511
  %513 = sub <8 x i16> zeroinitializer, %512
  %514 = icmp slt <8 x i16> %512, zeroinitializer
  %515 = select <8 x i1> %514, <8 x i16> %513, <8 x i16> %512
  %516 = lshr <8 x i16> %515, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %517 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %516, <8 x i16> zeroinitializer) #5
  %518 = lshr <8 x i16> %517, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %519 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %505, <8 x i16> %518) #5
  %520 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %519, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %521 = icmp slt <16 x i8> %520, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %522 = select <16 x i1> %521, <16 x i8> %520, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %523 = bitcast i8* %494 to <16 x i8>*
  store <16 x i8> %522, <16 x i8>* %523, align 16
  %524 = getelementptr inbounds i16, i16* %9, i64 256
  %525 = getelementptr inbounds i16, i16* %10, i64 256
  %526 = getelementptr inbounds i8, i8* %395, i64 %3
  %527 = bitcast i16* %524 to <8 x i16>*
  %528 = load <8 x i16>, <8 x i16>* %527, align 16
  %529 = bitcast i16* %525 to <8 x i16>*
  %530 = load <8 x i16>, <8 x i16>* %529, align 16
  %531 = sub <8 x i16> %528, %530
  %532 = sub <8 x i16> zeroinitializer, %531
  %533 = icmp slt <8 x i16> %531, zeroinitializer
  %534 = select <8 x i1> %533, <8 x i16> %532, <8 x i16> %531
  %535 = lshr <8 x i16> %534, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %536 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %535, <8 x i16> zeroinitializer) #5
  %537 = lshr <8 x i16> %536, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %538 = getelementptr inbounds i16, i16* %9, i64 264
  %539 = bitcast i16* %538 to <8 x i16>*
  %540 = load <8 x i16>, <8 x i16>* %539, align 16
  %541 = getelementptr inbounds i16, i16* %10, i64 264
  %542 = bitcast i16* %541 to <8 x i16>*
  %543 = load <8 x i16>, <8 x i16>* %542, align 16
  %544 = sub <8 x i16> %540, %543
  %545 = sub <8 x i16> zeroinitializer, %544
  %546 = icmp slt <8 x i16> %544, zeroinitializer
  %547 = select <8 x i1> %546, <8 x i16> %545, <8 x i16> %544
  %548 = lshr <8 x i16> %547, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %549 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %548, <8 x i16> zeroinitializer) #5
  %550 = lshr <8 x i16> %549, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %551 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %537, <8 x i16> %550) #5
  %552 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %551, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %553 = icmp slt <16 x i8> %552, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %554 = select <16 x i1> %553, <16 x i8> %552, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %555 = bitcast i8* %526 to <16 x i8>*
  store <16 x i8> %554, <16 x i8>* %555, align 16
  %556 = getelementptr inbounds i16, i16* %9, i64 272
  %557 = getelementptr inbounds i16, i16* %10, i64 272
  %558 = getelementptr inbounds i8, i8* %526, i64 16
  %559 = bitcast i16* %556 to <8 x i16>*
  %560 = load <8 x i16>, <8 x i16>* %559, align 16
  %561 = bitcast i16* %557 to <8 x i16>*
  %562 = load <8 x i16>, <8 x i16>* %561, align 16
  %563 = sub <8 x i16> %560, %562
  %564 = sub <8 x i16> zeroinitializer, %563
  %565 = icmp slt <8 x i16> %563, zeroinitializer
  %566 = select <8 x i1> %565, <8 x i16> %564, <8 x i16> %563
  %567 = lshr <8 x i16> %566, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %568 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %567, <8 x i16> zeroinitializer) #5
  %569 = lshr <8 x i16> %568, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %570 = getelementptr inbounds i16, i16* %9, i64 280
  %571 = bitcast i16* %570 to <8 x i16>*
  %572 = load <8 x i16>, <8 x i16>* %571, align 16
  %573 = getelementptr inbounds i16, i16* %10, i64 280
  %574 = bitcast i16* %573 to <8 x i16>*
  %575 = load <8 x i16>, <8 x i16>* %574, align 16
  %576 = sub <8 x i16> %572, %575
  %577 = sub <8 x i16> zeroinitializer, %576
  %578 = icmp slt <8 x i16> %576, zeroinitializer
  %579 = select <8 x i1> %578, <8 x i16> %577, <8 x i16> %576
  %580 = lshr <8 x i16> %579, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %581 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %580, <8 x i16> zeroinitializer) #5
  %582 = lshr <8 x i16> %581, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %583 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %569, <8 x i16> %582) #5
  %584 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %583, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %585 = icmp slt <16 x i8> %584, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %586 = select <16 x i1> %585, <16 x i8> %584, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %587 = bitcast i8* %558 to <16 x i8>*
  store <16 x i8> %586, <16 x i8>* %587, align 16
  %588 = getelementptr inbounds i16, i16* %9, i64 288
  %589 = getelementptr inbounds i16, i16* %10, i64 288
  %590 = getelementptr inbounds i8, i8* %526, i64 32
  %591 = bitcast i16* %588 to <8 x i16>*
  %592 = load <8 x i16>, <8 x i16>* %591, align 16
  %593 = bitcast i16* %589 to <8 x i16>*
  %594 = load <8 x i16>, <8 x i16>* %593, align 16
  %595 = sub <8 x i16> %592, %594
  %596 = sub <8 x i16> zeroinitializer, %595
  %597 = icmp slt <8 x i16> %595, zeroinitializer
  %598 = select <8 x i1> %597, <8 x i16> %596, <8 x i16> %595
  %599 = lshr <8 x i16> %598, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %600 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %599, <8 x i16> zeroinitializer) #5
  %601 = lshr <8 x i16> %600, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %602 = getelementptr inbounds i16, i16* %9, i64 296
  %603 = bitcast i16* %602 to <8 x i16>*
  %604 = load <8 x i16>, <8 x i16>* %603, align 16
  %605 = getelementptr inbounds i16, i16* %10, i64 296
  %606 = bitcast i16* %605 to <8 x i16>*
  %607 = load <8 x i16>, <8 x i16>* %606, align 16
  %608 = sub <8 x i16> %604, %607
  %609 = sub <8 x i16> zeroinitializer, %608
  %610 = icmp slt <8 x i16> %608, zeroinitializer
  %611 = select <8 x i1> %610, <8 x i16> %609, <8 x i16> %608
  %612 = lshr <8 x i16> %611, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %613 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %612, <8 x i16> zeroinitializer) #5
  %614 = lshr <8 x i16> %613, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %615 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %601, <8 x i16> %614) #5
  %616 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %615, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %617 = icmp slt <16 x i8> %616, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %618 = select <16 x i1> %617, <16 x i8> %616, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %619 = bitcast i8* %590 to <16 x i8>*
  store <16 x i8> %618, <16 x i8>* %619, align 16
  %620 = getelementptr inbounds i16, i16* %9, i64 304
  %621 = getelementptr inbounds i16, i16* %10, i64 304
  %622 = getelementptr inbounds i8, i8* %526, i64 48
  %623 = bitcast i16* %620 to <8 x i16>*
  %624 = load <8 x i16>, <8 x i16>* %623, align 16
  %625 = bitcast i16* %621 to <8 x i16>*
  %626 = load <8 x i16>, <8 x i16>* %625, align 16
  %627 = sub <8 x i16> %624, %626
  %628 = sub <8 x i16> zeroinitializer, %627
  %629 = icmp slt <8 x i16> %627, zeroinitializer
  %630 = select <8 x i1> %629, <8 x i16> %628, <8 x i16> %627
  %631 = lshr <8 x i16> %630, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %632 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %631, <8 x i16> zeroinitializer) #5
  %633 = lshr <8 x i16> %632, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %634 = getelementptr inbounds i16, i16* %9, i64 312
  %635 = bitcast i16* %634 to <8 x i16>*
  %636 = load <8 x i16>, <8 x i16>* %635, align 16
  %637 = getelementptr inbounds i16, i16* %10, i64 312
  %638 = bitcast i16* %637 to <8 x i16>*
  %639 = load <8 x i16>, <8 x i16>* %638, align 16
  %640 = sub <8 x i16> %636, %639
  %641 = sub <8 x i16> zeroinitializer, %640
  %642 = icmp slt <8 x i16> %640, zeroinitializer
  %643 = select <8 x i1> %642, <8 x i16> %641, <8 x i16> %640
  %644 = lshr <8 x i16> %643, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %645 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %644, <8 x i16> zeroinitializer) #5
  %646 = lshr <8 x i16> %645, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %647 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %633, <8 x i16> %646) #5
  %648 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %647, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %649 = icmp slt <16 x i8> %648, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %650 = select <16 x i1> %649, <16 x i8> %648, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %651 = bitcast i8* %622 to <16 x i8>*
  store <16 x i8> %650, <16 x i8>* %651, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_121WeightMask64x128_SSE4ILb1EEEvPKvS5_Phl(i8* readonly, i8* readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %407, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %405, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %406, %7 ]
  %11 = phi i32 [ 0, %4 ], [ %408, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = sub <8 x i16> %13, %15
  %17 = sub <8 x i16> zeroinitializer, %16
  %18 = icmp slt <8 x i16> %16, zeroinitializer
  %19 = select <8 x i1> %18, <8 x i16> %17, <8 x i16> %16
  %20 = lshr <8 x i16> %19, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %21 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %20, <8 x i16> zeroinitializer) #5
  %22 = lshr <8 x i16> %21, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %23 = getelementptr inbounds i16, i16* %9, i64 8
  %24 = bitcast i16* %23 to <8 x i16>*
  %25 = load <8 x i16>, <8 x i16>* %24, align 16
  %26 = getelementptr inbounds i16, i16* %10, i64 8
  %27 = bitcast i16* %26 to <8 x i16>*
  %28 = load <8 x i16>, <8 x i16>* %27, align 16
  %29 = sub <8 x i16> %25, %28
  %30 = sub <8 x i16> zeroinitializer, %29
  %31 = icmp slt <8 x i16> %29, zeroinitializer
  %32 = select <8 x i1> %31, <8 x i16> %30, <8 x i16> %29
  %33 = lshr <8 x i16> %32, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %34 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %33, <8 x i16> zeroinitializer) #5
  %35 = lshr <8 x i16> %34, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %36 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %22, <8 x i16> %35) #5
  %37 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %36, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %38 = icmp slt <16 x i8> %37, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %39 = select <16 x i1> %38, <16 x i8> %37, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %40 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %39
  %41 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %40, <16 x i8>* %41, align 16
  %42 = getelementptr inbounds i16, i16* %9, i64 16
  %43 = getelementptr inbounds i16, i16* %10, i64 16
  %44 = getelementptr inbounds i8, i8* %8, i64 16
  %45 = bitcast i16* %42 to <8 x i16>*
  %46 = load <8 x i16>, <8 x i16>* %45, align 16
  %47 = bitcast i16* %43 to <8 x i16>*
  %48 = load <8 x i16>, <8 x i16>* %47, align 16
  %49 = sub <8 x i16> %46, %48
  %50 = sub <8 x i16> zeroinitializer, %49
  %51 = icmp slt <8 x i16> %49, zeroinitializer
  %52 = select <8 x i1> %51, <8 x i16> %50, <8 x i16> %49
  %53 = lshr <8 x i16> %52, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %54 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %53, <8 x i16> zeroinitializer) #5
  %55 = lshr <8 x i16> %54, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %56 = getelementptr inbounds i16, i16* %9, i64 24
  %57 = bitcast i16* %56 to <8 x i16>*
  %58 = load <8 x i16>, <8 x i16>* %57, align 16
  %59 = getelementptr inbounds i16, i16* %10, i64 24
  %60 = bitcast i16* %59 to <8 x i16>*
  %61 = load <8 x i16>, <8 x i16>* %60, align 16
  %62 = sub <8 x i16> %58, %61
  %63 = sub <8 x i16> zeroinitializer, %62
  %64 = icmp slt <8 x i16> %62, zeroinitializer
  %65 = select <8 x i1> %64, <8 x i16> %63, <8 x i16> %62
  %66 = lshr <8 x i16> %65, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %67 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %66, <8 x i16> zeroinitializer) #5
  %68 = lshr <8 x i16> %67, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %69 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %55, <8 x i16> %68) #5
  %70 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %69, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %71 = icmp slt <16 x i8> %70, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %72 = select <16 x i1> %71, <16 x i8> %70, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %73 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %72
  %74 = bitcast i8* %44 to <16 x i8>*
  store <16 x i8> %73, <16 x i8>* %74, align 16
  %75 = getelementptr inbounds i16, i16* %9, i64 32
  %76 = getelementptr inbounds i16, i16* %10, i64 32
  %77 = getelementptr inbounds i8, i8* %8, i64 32
  %78 = bitcast i16* %75 to <8 x i16>*
  %79 = load <8 x i16>, <8 x i16>* %78, align 16
  %80 = bitcast i16* %76 to <8 x i16>*
  %81 = load <8 x i16>, <8 x i16>* %80, align 16
  %82 = sub <8 x i16> %79, %81
  %83 = sub <8 x i16> zeroinitializer, %82
  %84 = icmp slt <8 x i16> %82, zeroinitializer
  %85 = select <8 x i1> %84, <8 x i16> %83, <8 x i16> %82
  %86 = lshr <8 x i16> %85, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %87 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %86, <8 x i16> zeroinitializer) #5
  %88 = lshr <8 x i16> %87, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %89 = getelementptr inbounds i16, i16* %9, i64 40
  %90 = bitcast i16* %89 to <8 x i16>*
  %91 = load <8 x i16>, <8 x i16>* %90, align 16
  %92 = getelementptr inbounds i16, i16* %10, i64 40
  %93 = bitcast i16* %92 to <8 x i16>*
  %94 = load <8 x i16>, <8 x i16>* %93, align 16
  %95 = sub <8 x i16> %91, %94
  %96 = sub <8 x i16> zeroinitializer, %95
  %97 = icmp slt <8 x i16> %95, zeroinitializer
  %98 = select <8 x i1> %97, <8 x i16> %96, <8 x i16> %95
  %99 = lshr <8 x i16> %98, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %100 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %99, <8 x i16> zeroinitializer) #5
  %101 = lshr <8 x i16> %100, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %102 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %88, <8 x i16> %101) #5
  %103 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %102, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %104 = icmp slt <16 x i8> %103, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %105 = select <16 x i1> %104, <16 x i8> %103, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %106 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %105
  %107 = bitcast i8* %77 to <16 x i8>*
  store <16 x i8> %106, <16 x i8>* %107, align 16
  %108 = getelementptr inbounds i16, i16* %9, i64 48
  %109 = getelementptr inbounds i16, i16* %10, i64 48
  %110 = getelementptr inbounds i8, i8* %8, i64 48
  %111 = bitcast i16* %108 to <8 x i16>*
  %112 = load <8 x i16>, <8 x i16>* %111, align 16
  %113 = bitcast i16* %109 to <8 x i16>*
  %114 = load <8 x i16>, <8 x i16>* %113, align 16
  %115 = sub <8 x i16> %112, %114
  %116 = sub <8 x i16> zeroinitializer, %115
  %117 = icmp slt <8 x i16> %115, zeroinitializer
  %118 = select <8 x i1> %117, <8 x i16> %116, <8 x i16> %115
  %119 = lshr <8 x i16> %118, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %120 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %119, <8 x i16> zeroinitializer) #5
  %121 = lshr <8 x i16> %120, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %122 = getelementptr inbounds i16, i16* %9, i64 56
  %123 = bitcast i16* %122 to <8 x i16>*
  %124 = load <8 x i16>, <8 x i16>* %123, align 16
  %125 = getelementptr inbounds i16, i16* %10, i64 56
  %126 = bitcast i16* %125 to <8 x i16>*
  %127 = load <8 x i16>, <8 x i16>* %126, align 16
  %128 = sub <8 x i16> %124, %127
  %129 = sub <8 x i16> zeroinitializer, %128
  %130 = icmp slt <8 x i16> %128, zeroinitializer
  %131 = select <8 x i1> %130, <8 x i16> %129, <8 x i16> %128
  %132 = lshr <8 x i16> %131, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %133 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %132, <8 x i16> zeroinitializer) #5
  %134 = lshr <8 x i16> %133, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %135 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %121, <8 x i16> %134) #5
  %136 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %135, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %137 = icmp slt <16 x i8> %136, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %138 = select <16 x i1> %137, <16 x i8> %136, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %139 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %138
  %140 = bitcast i8* %110 to <16 x i8>*
  store <16 x i8> %139, <16 x i8>* %140, align 16
  %141 = getelementptr inbounds i16, i16* %9, i64 64
  %142 = getelementptr inbounds i16, i16* %10, i64 64
  %143 = getelementptr inbounds i8, i8* %8, i64 %3
  %144 = bitcast i16* %141 to <8 x i16>*
  %145 = load <8 x i16>, <8 x i16>* %144, align 16
  %146 = bitcast i16* %142 to <8 x i16>*
  %147 = load <8 x i16>, <8 x i16>* %146, align 16
  %148 = sub <8 x i16> %145, %147
  %149 = sub <8 x i16> zeroinitializer, %148
  %150 = icmp slt <8 x i16> %148, zeroinitializer
  %151 = select <8 x i1> %150, <8 x i16> %149, <8 x i16> %148
  %152 = lshr <8 x i16> %151, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %153 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %152, <8 x i16> zeroinitializer) #5
  %154 = lshr <8 x i16> %153, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %155 = getelementptr inbounds i16, i16* %9, i64 72
  %156 = bitcast i16* %155 to <8 x i16>*
  %157 = load <8 x i16>, <8 x i16>* %156, align 16
  %158 = getelementptr inbounds i16, i16* %10, i64 72
  %159 = bitcast i16* %158 to <8 x i16>*
  %160 = load <8 x i16>, <8 x i16>* %159, align 16
  %161 = sub <8 x i16> %157, %160
  %162 = sub <8 x i16> zeroinitializer, %161
  %163 = icmp slt <8 x i16> %161, zeroinitializer
  %164 = select <8 x i1> %163, <8 x i16> %162, <8 x i16> %161
  %165 = lshr <8 x i16> %164, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %166 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %165, <8 x i16> zeroinitializer) #5
  %167 = lshr <8 x i16> %166, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %168 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %154, <8 x i16> %167) #5
  %169 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %168, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %170 = icmp slt <16 x i8> %169, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %171 = select <16 x i1> %170, <16 x i8> %169, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %172 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %171
  %173 = bitcast i8* %143 to <16 x i8>*
  store <16 x i8> %172, <16 x i8>* %173, align 16
  %174 = getelementptr inbounds i16, i16* %9, i64 80
  %175 = getelementptr inbounds i16, i16* %10, i64 80
  %176 = getelementptr inbounds i8, i8* %143, i64 16
  %177 = bitcast i16* %174 to <8 x i16>*
  %178 = load <8 x i16>, <8 x i16>* %177, align 16
  %179 = bitcast i16* %175 to <8 x i16>*
  %180 = load <8 x i16>, <8 x i16>* %179, align 16
  %181 = sub <8 x i16> %178, %180
  %182 = sub <8 x i16> zeroinitializer, %181
  %183 = icmp slt <8 x i16> %181, zeroinitializer
  %184 = select <8 x i1> %183, <8 x i16> %182, <8 x i16> %181
  %185 = lshr <8 x i16> %184, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %186 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %185, <8 x i16> zeroinitializer) #5
  %187 = lshr <8 x i16> %186, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %188 = getelementptr inbounds i16, i16* %9, i64 88
  %189 = bitcast i16* %188 to <8 x i16>*
  %190 = load <8 x i16>, <8 x i16>* %189, align 16
  %191 = getelementptr inbounds i16, i16* %10, i64 88
  %192 = bitcast i16* %191 to <8 x i16>*
  %193 = load <8 x i16>, <8 x i16>* %192, align 16
  %194 = sub <8 x i16> %190, %193
  %195 = sub <8 x i16> zeroinitializer, %194
  %196 = icmp slt <8 x i16> %194, zeroinitializer
  %197 = select <8 x i1> %196, <8 x i16> %195, <8 x i16> %194
  %198 = lshr <8 x i16> %197, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %199 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %198, <8 x i16> zeroinitializer) #5
  %200 = lshr <8 x i16> %199, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %201 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %187, <8 x i16> %200) #5
  %202 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %201, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %203 = icmp slt <16 x i8> %202, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %204 = select <16 x i1> %203, <16 x i8> %202, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %205 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %204
  %206 = bitcast i8* %176 to <16 x i8>*
  store <16 x i8> %205, <16 x i8>* %206, align 16
  %207 = getelementptr inbounds i16, i16* %9, i64 96
  %208 = getelementptr inbounds i16, i16* %10, i64 96
  %209 = getelementptr inbounds i8, i8* %143, i64 32
  %210 = bitcast i16* %207 to <8 x i16>*
  %211 = load <8 x i16>, <8 x i16>* %210, align 16
  %212 = bitcast i16* %208 to <8 x i16>*
  %213 = load <8 x i16>, <8 x i16>* %212, align 16
  %214 = sub <8 x i16> %211, %213
  %215 = sub <8 x i16> zeroinitializer, %214
  %216 = icmp slt <8 x i16> %214, zeroinitializer
  %217 = select <8 x i1> %216, <8 x i16> %215, <8 x i16> %214
  %218 = lshr <8 x i16> %217, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %219 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %218, <8 x i16> zeroinitializer) #5
  %220 = lshr <8 x i16> %219, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %221 = getelementptr inbounds i16, i16* %9, i64 104
  %222 = bitcast i16* %221 to <8 x i16>*
  %223 = load <8 x i16>, <8 x i16>* %222, align 16
  %224 = getelementptr inbounds i16, i16* %10, i64 104
  %225 = bitcast i16* %224 to <8 x i16>*
  %226 = load <8 x i16>, <8 x i16>* %225, align 16
  %227 = sub <8 x i16> %223, %226
  %228 = sub <8 x i16> zeroinitializer, %227
  %229 = icmp slt <8 x i16> %227, zeroinitializer
  %230 = select <8 x i1> %229, <8 x i16> %228, <8 x i16> %227
  %231 = lshr <8 x i16> %230, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %232 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %231, <8 x i16> zeroinitializer) #5
  %233 = lshr <8 x i16> %232, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %234 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %220, <8 x i16> %233) #5
  %235 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %234, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %236 = icmp slt <16 x i8> %235, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %237 = select <16 x i1> %236, <16 x i8> %235, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %238 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %237
  %239 = bitcast i8* %209 to <16 x i8>*
  store <16 x i8> %238, <16 x i8>* %239, align 16
  %240 = getelementptr inbounds i16, i16* %9, i64 112
  %241 = getelementptr inbounds i16, i16* %10, i64 112
  %242 = getelementptr inbounds i8, i8* %143, i64 48
  %243 = bitcast i16* %240 to <8 x i16>*
  %244 = load <8 x i16>, <8 x i16>* %243, align 16
  %245 = bitcast i16* %241 to <8 x i16>*
  %246 = load <8 x i16>, <8 x i16>* %245, align 16
  %247 = sub <8 x i16> %244, %246
  %248 = sub <8 x i16> zeroinitializer, %247
  %249 = icmp slt <8 x i16> %247, zeroinitializer
  %250 = select <8 x i1> %249, <8 x i16> %248, <8 x i16> %247
  %251 = lshr <8 x i16> %250, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %252 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %251, <8 x i16> zeroinitializer) #5
  %253 = lshr <8 x i16> %252, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %254 = getelementptr inbounds i16, i16* %9, i64 120
  %255 = bitcast i16* %254 to <8 x i16>*
  %256 = load <8 x i16>, <8 x i16>* %255, align 16
  %257 = getelementptr inbounds i16, i16* %10, i64 120
  %258 = bitcast i16* %257 to <8 x i16>*
  %259 = load <8 x i16>, <8 x i16>* %258, align 16
  %260 = sub <8 x i16> %256, %259
  %261 = sub <8 x i16> zeroinitializer, %260
  %262 = icmp slt <8 x i16> %260, zeroinitializer
  %263 = select <8 x i1> %262, <8 x i16> %261, <8 x i16> %260
  %264 = lshr <8 x i16> %263, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %265 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %264, <8 x i16> zeroinitializer) #5
  %266 = lshr <8 x i16> %265, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %267 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %253, <8 x i16> %266) #5
  %268 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %267, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %269 = icmp slt <16 x i8> %268, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %270 = select <16 x i1> %269, <16 x i8> %268, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %271 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %270
  %272 = bitcast i8* %242 to <16 x i8>*
  store <16 x i8> %271, <16 x i8>* %272, align 16
  %273 = getelementptr inbounds i16, i16* %9, i64 128
  %274 = getelementptr inbounds i16, i16* %10, i64 128
  %275 = getelementptr inbounds i8, i8* %143, i64 %3
  %276 = bitcast i16* %273 to <8 x i16>*
  %277 = load <8 x i16>, <8 x i16>* %276, align 16
  %278 = bitcast i16* %274 to <8 x i16>*
  %279 = load <8 x i16>, <8 x i16>* %278, align 16
  %280 = sub <8 x i16> %277, %279
  %281 = sub <8 x i16> zeroinitializer, %280
  %282 = icmp slt <8 x i16> %280, zeroinitializer
  %283 = select <8 x i1> %282, <8 x i16> %281, <8 x i16> %280
  %284 = lshr <8 x i16> %283, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %285 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %284, <8 x i16> zeroinitializer) #5
  %286 = lshr <8 x i16> %285, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %287 = getelementptr inbounds i16, i16* %9, i64 136
  %288 = bitcast i16* %287 to <8 x i16>*
  %289 = load <8 x i16>, <8 x i16>* %288, align 16
  %290 = getelementptr inbounds i16, i16* %10, i64 136
  %291 = bitcast i16* %290 to <8 x i16>*
  %292 = load <8 x i16>, <8 x i16>* %291, align 16
  %293 = sub <8 x i16> %289, %292
  %294 = sub <8 x i16> zeroinitializer, %293
  %295 = icmp slt <8 x i16> %293, zeroinitializer
  %296 = select <8 x i1> %295, <8 x i16> %294, <8 x i16> %293
  %297 = lshr <8 x i16> %296, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %298 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %297, <8 x i16> zeroinitializer) #5
  %299 = lshr <8 x i16> %298, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %300 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %286, <8 x i16> %299) #5
  %301 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %300, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %302 = icmp slt <16 x i8> %301, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %303 = select <16 x i1> %302, <16 x i8> %301, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %304 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %303
  %305 = bitcast i8* %275 to <16 x i8>*
  store <16 x i8> %304, <16 x i8>* %305, align 16
  %306 = getelementptr inbounds i16, i16* %9, i64 144
  %307 = getelementptr inbounds i16, i16* %10, i64 144
  %308 = getelementptr inbounds i8, i8* %275, i64 16
  %309 = bitcast i16* %306 to <8 x i16>*
  %310 = load <8 x i16>, <8 x i16>* %309, align 16
  %311 = bitcast i16* %307 to <8 x i16>*
  %312 = load <8 x i16>, <8 x i16>* %311, align 16
  %313 = sub <8 x i16> %310, %312
  %314 = sub <8 x i16> zeroinitializer, %313
  %315 = icmp slt <8 x i16> %313, zeroinitializer
  %316 = select <8 x i1> %315, <8 x i16> %314, <8 x i16> %313
  %317 = lshr <8 x i16> %316, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %318 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %317, <8 x i16> zeroinitializer) #5
  %319 = lshr <8 x i16> %318, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %320 = getelementptr inbounds i16, i16* %9, i64 152
  %321 = bitcast i16* %320 to <8 x i16>*
  %322 = load <8 x i16>, <8 x i16>* %321, align 16
  %323 = getelementptr inbounds i16, i16* %10, i64 152
  %324 = bitcast i16* %323 to <8 x i16>*
  %325 = load <8 x i16>, <8 x i16>* %324, align 16
  %326 = sub <8 x i16> %322, %325
  %327 = sub <8 x i16> zeroinitializer, %326
  %328 = icmp slt <8 x i16> %326, zeroinitializer
  %329 = select <8 x i1> %328, <8 x i16> %327, <8 x i16> %326
  %330 = lshr <8 x i16> %329, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %331 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %330, <8 x i16> zeroinitializer) #5
  %332 = lshr <8 x i16> %331, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %333 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %319, <8 x i16> %332) #5
  %334 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %333, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %335 = icmp slt <16 x i8> %334, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %336 = select <16 x i1> %335, <16 x i8> %334, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %337 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %336
  %338 = bitcast i8* %308 to <16 x i8>*
  store <16 x i8> %337, <16 x i8>* %338, align 16
  %339 = getelementptr inbounds i16, i16* %9, i64 160
  %340 = getelementptr inbounds i16, i16* %10, i64 160
  %341 = getelementptr inbounds i8, i8* %275, i64 32
  %342 = bitcast i16* %339 to <8 x i16>*
  %343 = load <8 x i16>, <8 x i16>* %342, align 16
  %344 = bitcast i16* %340 to <8 x i16>*
  %345 = load <8 x i16>, <8 x i16>* %344, align 16
  %346 = sub <8 x i16> %343, %345
  %347 = sub <8 x i16> zeroinitializer, %346
  %348 = icmp slt <8 x i16> %346, zeroinitializer
  %349 = select <8 x i1> %348, <8 x i16> %347, <8 x i16> %346
  %350 = lshr <8 x i16> %349, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %351 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %350, <8 x i16> zeroinitializer) #5
  %352 = lshr <8 x i16> %351, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %353 = getelementptr inbounds i16, i16* %9, i64 168
  %354 = bitcast i16* %353 to <8 x i16>*
  %355 = load <8 x i16>, <8 x i16>* %354, align 16
  %356 = getelementptr inbounds i16, i16* %10, i64 168
  %357 = bitcast i16* %356 to <8 x i16>*
  %358 = load <8 x i16>, <8 x i16>* %357, align 16
  %359 = sub <8 x i16> %355, %358
  %360 = sub <8 x i16> zeroinitializer, %359
  %361 = icmp slt <8 x i16> %359, zeroinitializer
  %362 = select <8 x i1> %361, <8 x i16> %360, <8 x i16> %359
  %363 = lshr <8 x i16> %362, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %364 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %363, <8 x i16> zeroinitializer) #5
  %365 = lshr <8 x i16> %364, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %366 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %352, <8 x i16> %365) #5
  %367 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %366, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %368 = icmp slt <16 x i8> %367, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %369 = select <16 x i1> %368, <16 x i8> %367, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %370 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %369
  %371 = bitcast i8* %341 to <16 x i8>*
  store <16 x i8> %370, <16 x i8>* %371, align 16
  %372 = getelementptr inbounds i16, i16* %9, i64 176
  %373 = getelementptr inbounds i16, i16* %10, i64 176
  %374 = getelementptr inbounds i8, i8* %275, i64 48
  %375 = bitcast i16* %372 to <8 x i16>*
  %376 = load <8 x i16>, <8 x i16>* %375, align 16
  %377 = bitcast i16* %373 to <8 x i16>*
  %378 = load <8 x i16>, <8 x i16>* %377, align 16
  %379 = sub <8 x i16> %376, %378
  %380 = sub <8 x i16> zeroinitializer, %379
  %381 = icmp slt <8 x i16> %379, zeroinitializer
  %382 = select <8 x i1> %381, <8 x i16> %380, <8 x i16> %379
  %383 = lshr <8 x i16> %382, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %384 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %383, <8 x i16> zeroinitializer) #5
  %385 = lshr <8 x i16> %384, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %386 = getelementptr inbounds i16, i16* %9, i64 184
  %387 = bitcast i16* %386 to <8 x i16>*
  %388 = load <8 x i16>, <8 x i16>* %387, align 16
  %389 = getelementptr inbounds i16, i16* %10, i64 184
  %390 = bitcast i16* %389 to <8 x i16>*
  %391 = load <8 x i16>, <8 x i16>* %390, align 16
  %392 = sub <8 x i16> %388, %391
  %393 = sub <8 x i16> zeroinitializer, %392
  %394 = icmp slt <8 x i16> %392, zeroinitializer
  %395 = select <8 x i1> %394, <8 x i16> %393, <8 x i16> %392
  %396 = lshr <8 x i16> %395, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %397 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %396, <8 x i16> zeroinitializer) #5
  %398 = lshr <8 x i16> %397, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %399 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %385, <8 x i16> %398) #5
  %400 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %399, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %401 = icmp slt <16 x i8> %400, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %402 = select <16 x i1> %401, <16 x i8> %400, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %403 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %402
  %404 = bitcast i8* %374 to <16 x i8>*
  store <16 x i8> %403, <16 x i8>* %404, align 16
  %405 = getelementptr inbounds i16, i16* %9, i64 192
  %406 = getelementptr inbounds i16, i16* %10, i64 192
  %407 = getelementptr inbounds i8, i8* %275, i64 %3
  %408 = add nuw nsw i32 %11, 1
  %409 = icmp eq i32 %408, 42
  br i1 %409, label %410, label %7

410:                                              ; preds = %7
  %411 = bitcast i16* %405 to <8 x i16>*
  %412 = load <8 x i16>, <8 x i16>* %411, align 16
  %413 = bitcast i16* %406 to <8 x i16>*
  %414 = load <8 x i16>, <8 x i16>* %413, align 16
  %415 = sub <8 x i16> %412, %414
  %416 = sub <8 x i16> zeroinitializer, %415
  %417 = icmp slt <8 x i16> %415, zeroinitializer
  %418 = select <8 x i1> %417, <8 x i16> %416, <8 x i16> %415
  %419 = lshr <8 x i16> %418, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %420 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %419, <8 x i16> zeroinitializer) #5
  %421 = lshr <8 x i16> %420, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %422 = getelementptr inbounds i16, i16* %9, i64 200
  %423 = bitcast i16* %422 to <8 x i16>*
  %424 = load <8 x i16>, <8 x i16>* %423, align 16
  %425 = getelementptr inbounds i16, i16* %10, i64 200
  %426 = bitcast i16* %425 to <8 x i16>*
  %427 = load <8 x i16>, <8 x i16>* %426, align 16
  %428 = sub <8 x i16> %424, %427
  %429 = sub <8 x i16> zeroinitializer, %428
  %430 = icmp slt <8 x i16> %428, zeroinitializer
  %431 = select <8 x i1> %430, <8 x i16> %429, <8 x i16> %428
  %432 = lshr <8 x i16> %431, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %433 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %432, <8 x i16> zeroinitializer) #5
  %434 = lshr <8 x i16> %433, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %435 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %421, <8 x i16> %434) #5
  %436 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %435, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %437 = icmp slt <16 x i8> %436, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %438 = select <16 x i1> %437, <16 x i8> %436, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %439 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %438
  %440 = bitcast i8* %407 to <16 x i8>*
  store <16 x i8> %439, <16 x i8>* %440, align 16
  %441 = getelementptr inbounds i16, i16* %9, i64 208
  %442 = getelementptr inbounds i16, i16* %10, i64 208
  %443 = getelementptr inbounds i8, i8* %407, i64 16
  %444 = bitcast i16* %441 to <8 x i16>*
  %445 = load <8 x i16>, <8 x i16>* %444, align 16
  %446 = bitcast i16* %442 to <8 x i16>*
  %447 = load <8 x i16>, <8 x i16>* %446, align 16
  %448 = sub <8 x i16> %445, %447
  %449 = sub <8 x i16> zeroinitializer, %448
  %450 = icmp slt <8 x i16> %448, zeroinitializer
  %451 = select <8 x i1> %450, <8 x i16> %449, <8 x i16> %448
  %452 = lshr <8 x i16> %451, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %453 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %452, <8 x i16> zeroinitializer) #5
  %454 = lshr <8 x i16> %453, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %455 = getelementptr inbounds i16, i16* %9, i64 216
  %456 = bitcast i16* %455 to <8 x i16>*
  %457 = load <8 x i16>, <8 x i16>* %456, align 16
  %458 = getelementptr inbounds i16, i16* %10, i64 216
  %459 = bitcast i16* %458 to <8 x i16>*
  %460 = load <8 x i16>, <8 x i16>* %459, align 16
  %461 = sub <8 x i16> %457, %460
  %462 = sub <8 x i16> zeroinitializer, %461
  %463 = icmp slt <8 x i16> %461, zeroinitializer
  %464 = select <8 x i1> %463, <8 x i16> %462, <8 x i16> %461
  %465 = lshr <8 x i16> %464, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %466 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %465, <8 x i16> zeroinitializer) #5
  %467 = lshr <8 x i16> %466, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %468 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %454, <8 x i16> %467) #5
  %469 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %468, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %470 = icmp slt <16 x i8> %469, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %471 = select <16 x i1> %470, <16 x i8> %469, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %472 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %471
  %473 = bitcast i8* %443 to <16 x i8>*
  store <16 x i8> %472, <16 x i8>* %473, align 16
  %474 = getelementptr inbounds i16, i16* %9, i64 224
  %475 = getelementptr inbounds i16, i16* %10, i64 224
  %476 = getelementptr inbounds i8, i8* %407, i64 32
  %477 = bitcast i16* %474 to <8 x i16>*
  %478 = load <8 x i16>, <8 x i16>* %477, align 16
  %479 = bitcast i16* %475 to <8 x i16>*
  %480 = load <8 x i16>, <8 x i16>* %479, align 16
  %481 = sub <8 x i16> %478, %480
  %482 = sub <8 x i16> zeroinitializer, %481
  %483 = icmp slt <8 x i16> %481, zeroinitializer
  %484 = select <8 x i1> %483, <8 x i16> %482, <8 x i16> %481
  %485 = lshr <8 x i16> %484, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %486 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %485, <8 x i16> zeroinitializer) #5
  %487 = lshr <8 x i16> %486, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %488 = getelementptr inbounds i16, i16* %9, i64 232
  %489 = bitcast i16* %488 to <8 x i16>*
  %490 = load <8 x i16>, <8 x i16>* %489, align 16
  %491 = getelementptr inbounds i16, i16* %10, i64 232
  %492 = bitcast i16* %491 to <8 x i16>*
  %493 = load <8 x i16>, <8 x i16>* %492, align 16
  %494 = sub <8 x i16> %490, %493
  %495 = sub <8 x i16> zeroinitializer, %494
  %496 = icmp slt <8 x i16> %494, zeroinitializer
  %497 = select <8 x i1> %496, <8 x i16> %495, <8 x i16> %494
  %498 = lshr <8 x i16> %497, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %499 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %498, <8 x i16> zeroinitializer) #5
  %500 = lshr <8 x i16> %499, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %501 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %487, <8 x i16> %500) #5
  %502 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %501, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %503 = icmp slt <16 x i8> %502, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %504 = select <16 x i1> %503, <16 x i8> %502, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %505 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %504
  %506 = bitcast i8* %476 to <16 x i8>*
  store <16 x i8> %505, <16 x i8>* %506, align 16
  %507 = getelementptr inbounds i16, i16* %9, i64 240
  %508 = getelementptr inbounds i16, i16* %10, i64 240
  %509 = getelementptr inbounds i8, i8* %407, i64 48
  %510 = bitcast i16* %507 to <8 x i16>*
  %511 = load <8 x i16>, <8 x i16>* %510, align 16
  %512 = bitcast i16* %508 to <8 x i16>*
  %513 = load <8 x i16>, <8 x i16>* %512, align 16
  %514 = sub <8 x i16> %511, %513
  %515 = sub <8 x i16> zeroinitializer, %514
  %516 = icmp slt <8 x i16> %514, zeroinitializer
  %517 = select <8 x i1> %516, <8 x i16> %515, <8 x i16> %514
  %518 = lshr <8 x i16> %517, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %519 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %518, <8 x i16> zeroinitializer) #5
  %520 = lshr <8 x i16> %519, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %521 = getelementptr inbounds i16, i16* %9, i64 248
  %522 = bitcast i16* %521 to <8 x i16>*
  %523 = load <8 x i16>, <8 x i16>* %522, align 16
  %524 = getelementptr inbounds i16, i16* %10, i64 248
  %525 = bitcast i16* %524 to <8 x i16>*
  %526 = load <8 x i16>, <8 x i16>* %525, align 16
  %527 = sub <8 x i16> %523, %526
  %528 = sub <8 x i16> zeroinitializer, %527
  %529 = icmp slt <8 x i16> %527, zeroinitializer
  %530 = select <8 x i1> %529, <8 x i16> %528, <8 x i16> %527
  %531 = lshr <8 x i16> %530, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %532 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %531, <8 x i16> zeroinitializer) #5
  %533 = lshr <8 x i16> %532, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %534 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %520, <8 x i16> %533) #5
  %535 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %534, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %536 = icmp slt <16 x i8> %535, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %537 = select <16 x i1> %536, <16 x i8> %535, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %538 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %537
  %539 = bitcast i8* %509 to <16 x i8>*
  store <16 x i8> %538, <16 x i8>* %539, align 16
  %540 = getelementptr inbounds i16, i16* %9, i64 256
  %541 = getelementptr inbounds i16, i16* %10, i64 256
  %542 = getelementptr inbounds i8, i8* %407, i64 %3
  %543 = bitcast i16* %540 to <8 x i16>*
  %544 = load <8 x i16>, <8 x i16>* %543, align 16
  %545 = bitcast i16* %541 to <8 x i16>*
  %546 = load <8 x i16>, <8 x i16>* %545, align 16
  %547 = sub <8 x i16> %544, %546
  %548 = sub <8 x i16> zeroinitializer, %547
  %549 = icmp slt <8 x i16> %547, zeroinitializer
  %550 = select <8 x i1> %549, <8 x i16> %548, <8 x i16> %547
  %551 = lshr <8 x i16> %550, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %552 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %551, <8 x i16> zeroinitializer) #5
  %553 = lshr <8 x i16> %552, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %554 = getelementptr inbounds i16, i16* %9, i64 264
  %555 = bitcast i16* %554 to <8 x i16>*
  %556 = load <8 x i16>, <8 x i16>* %555, align 16
  %557 = getelementptr inbounds i16, i16* %10, i64 264
  %558 = bitcast i16* %557 to <8 x i16>*
  %559 = load <8 x i16>, <8 x i16>* %558, align 16
  %560 = sub <8 x i16> %556, %559
  %561 = sub <8 x i16> zeroinitializer, %560
  %562 = icmp slt <8 x i16> %560, zeroinitializer
  %563 = select <8 x i1> %562, <8 x i16> %561, <8 x i16> %560
  %564 = lshr <8 x i16> %563, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %565 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %564, <8 x i16> zeroinitializer) #5
  %566 = lshr <8 x i16> %565, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %567 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %553, <8 x i16> %566) #5
  %568 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %567, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %569 = icmp slt <16 x i8> %568, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %570 = select <16 x i1> %569, <16 x i8> %568, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %571 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %570
  %572 = bitcast i8* %542 to <16 x i8>*
  store <16 x i8> %571, <16 x i8>* %572, align 16
  %573 = getelementptr inbounds i16, i16* %9, i64 272
  %574 = getelementptr inbounds i16, i16* %10, i64 272
  %575 = getelementptr inbounds i8, i8* %542, i64 16
  %576 = bitcast i16* %573 to <8 x i16>*
  %577 = load <8 x i16>, <8 x i16>* %576, align 16
  %578 = bitcast i16* %574 to <8 x i16>*
  %579 = load <8 x i16>, <8 x i16>* %578, align 16
  %580 = sub <8 x i16> %577, %579
  %581 = sub <8 x i16> zeroinitializer, %580
  %582 = icmp slt <8 x i16> %580, zeroinitializer
  %583 = select <8 x i1> %582, <8 x i16> %581, <8 x i16> %580
  %584 = lshr <8 x i16> %583, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %585 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %584, <8 x i16> zeroinitializer) #5
  %586 = lshr <8 x i16> %585, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %587 = getelementptr inbounds i16, i16* %9, i64 280
  %588 = bitcast i16* %587 to <8 x i16>*
  %589 = load <8 x i16>, <8 x i16>* %588, align 16
  %590 = getelementptr inbounds i16, i16* %10, i64 280
  %591 = bitcast i16* %590 to <8 x i16>*
  %592 = load <8 x i16>, <8 x i16>* %591, align 16
  %593 = sub <8 x i16> %589, %592
  %594 = sub <8 x i16> zeroinitializer, %593
  %595 = icmp slt <8 x i16> %593, zeroinitializer
  %596 = select <8 x i1> %595, <8 x i16> %594, <8 x i16> %593
  %597 = lshr <8 x i16> %596, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %598 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %597, <8 x i16> zeroinitializer) #5
  %599 = lshr <8 x i16> %598, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %600 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %586, <8 x i16> %599) #5
  %601 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %600, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %602 = icmp slt <16 x i8> %601, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %603 = select <16 x i1> %602, <16 x i8> %601, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %604 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %603
  %605 = bitcast i8* %575 to <16 x i8>*
  store <16 x i8> %604, <16 x i8>* %605, align 16
  %606 = getelementptr inbounds i16, i16* %9, i64 288
  %607 = getelementptr inbounds i16, i16* %10, i64 288
  %608 = getelementptr inbounds i8, i8* %542, i64 32
  %609 = bitcast i16* %606 to <8 x i16>*
  %610 = load <8 x i16>, <8 x i16>* %609, align 16
  %611 = bitcast i16* %607 to <8 x i16>*
  %612 = load <8 x i16>, <8 x i16>* %611, align 16
  %613 = sub <8 x i16> %610, %612
  %614 = sub <8 x i16> zeroinitializer, %613
  %615 = icmp slt <8 x i16> %613, zeroinitializer
  %616 = select <8 x i1> %615, <8 x i16> %614, <8 x i16> %613
  %617 = lshr <8 x i16> %616, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %618 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %617, <8 x i16> zeroinitializer) #5
  %619 = lshr <8 x i16> %618, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %620 = getelementptr inbounds i16, i16* %9, i64 296
  %621 = bitcast i16* %620 to <8 x i16>*
  %622 = load <8 x i16>, <8 x i16>* %621, align 16
  %623 = getelementptr inbounds i16, i16* %10, i64 296
  %624 = bitcast i16* %623 to <8 x i16>*
  %625 = load <8 x i16>, <8 x i16>* %624, align 16
  %626 = sub <8 x i16> %622, %625
  %627 = sub <8 x i16> zeroinitializer, %626
  %628 = icmp slt <8 x i16> %626, zeroinitializer
  %629 = select <8 x i1> %628, <8 x i16> %627, <8 x i16> %626
  %630 = lshr <8 x i16> %629, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %631 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %630, <8 x i16> zeroinitializer) #5
  %632 = lshr <8 x i16> %631, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %633 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %619, <8 x i16> %632) #5
  %634 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %633, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %635 = icmp slt <16 x i8> %634, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %636 = select <16 x i1> %635, <16 x i8> %634, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %637 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %636
  %638 = bitcast i8* %608 to <16 x i8>*
  store <16 x i8> %637, <16 x i8>* %638, align 16
  %639 = getelementptr inbounds i16, i16* %9, i64 304
  %640 = getelementptr inbounds i16, i16* %10, i64 304
  %641 = getelementptr inbounds i8, i8* %542, i64 48
  %642 = bitcast i16* %639 to <8 x i16>*
  %643 = load <8 x i16>, <8 x i16>* %642, align 16
  %644 = bitcast i16* %640 to <8 x i16>*
  %645 = load <8 x i16>, <8 x i16>* %644, align 16
  %646 = sub <8 x i16> %643, %645
  %647 = sub <8 x i16> zeroinitializer, %646
  %648 = icmp slt <8 x i16> %646, zeroinitializer
  %649 = select <8 x i1> %648, <8 x i16> %647, <8 x i16> %646
  %650 = lshr <8 x i16> %649, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %651 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %650, <8 x i16> zeroinitializer) #5
  %652 = lshr <8 x i16> %651, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %653 = getelementptr inbounds i16, i16* %9, i64 312
  %654 = bitcast i16* %653 to <8 x i16>*
  %655 = load <8 x i16>, <8 x i16>* %654, align 16
  %656 = getelementptr inbounds i16, i16* %10, i64 312
  %657 = bitcast i16* %656 to <8 x i16>*
  %658 = load <8 x i16>, <8 x i16>* %657, align 16
  %659 = sub <8 x i16> %655, %658
  %660 = sub <8 x i16> zeroinitializer, %659
  %661 = icmp slt <8 x i16> %659, zeroinitializer
  %662 = select <8 x i1> %661, <8 x i16> %660, <8 x i16> %659
  %663 = lshr <8 x i16> %662, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %664 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %663, <8 x i16> zeroinitializer) #5
  %665 = lshr <8 x i16> %664, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %666 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %652, <8 x i16> %665) #5
  %667 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %666, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %668 = icmp slt <16 x i8> %667, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %669 = select <16 x i1> %668, <16 x i8> %667, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %670 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %669
  %671 = bitcast i8* %641 to <16 x i8>*
  store <16 x i8> %670, <16 x i8>* %671, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_121WeightMask128x64_SSE4ILb0EEEvPKvS5_Phl(i8* readonly, i8* readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  %7 = add nsw i64 %3, -64
  br label %8

8:                                                ; preds = %8, %4
  %9 = phi i8* [ %2, %4 ], [ %780, %8 ]
  %10 = phi i16* [ %5, %4 ], [ %778, %8 ]
  %11 = phi i16* [ %6, %4 ], [ %779, %8 ]
  %12 = phi i32 [ 0, %4 ], [ %781, %8 ]
  %13 = bitcast i16* %10 to <8 x i16>*
  %14 = load <8 x i16>, <8 x i16>* %13, align 16
  %15 = bitcast i16* %11 to <8 x i16>*
  %16 = load <8 x i16>, <8 x i16>* %15, align 16
  %17 = sub <8 x i16> %14, %16
  %18 = sub <8 x i16> zeroinitializer, %17
  %19 = icmp slt <8 x i16> %17, zeroinitializer
  %20 = select <8 x i1> %19, <8 x i16> %18, <8 x i16> %17
  %21 = lshr <8 x i16> %20, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %22 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %21, <8 x i16> zeroinitializer) #5
  %23 = lshr <8 x i16> %22, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %24 = getelementptr inbounds i16, i16* %10, i64 8
  %25 = bitcast i16* %24 to <8 x i16>*
  %26 = load <8 x i16>, <8 x i16>* %25, align 16
  %27 = getelementptr inbounds i16, i16* %11, i64 8
  %28 = bitcast i16* %27 to <8 x i16>*
  %29 = load <8 x i16>, <8 x i16>* %28, align 16
  %30 = sub <8 x i16> %26, %29
  %31 = sub <8 x i16> zeroinitializer, %30
  %32 = icmp slt <8 x i16> %30, zeroinitializer
  %33 = select <8 x i1> %32, <8 x i16> %31, <8 x i16> %30
  %34 = lshr <8 x i16> %33, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %35 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %34, <8 x i16> zeroinitializer) #5
  %36 = lshr <8 x i16> %35, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %37 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %23, <8 x i16> %36) #5
  %38 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %37, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %39 = icmp slt <16 x i8> %38, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %40 = select <16 x i1> %39, <16 x i8> %38, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %41 = bitcast i8* %9 to <16 x i8>*
  store <16 x i8> %40, <16 x i8>* %41, align 16
  %42 = getelementptr inbounds i16, i16* %10, i64 16
  %43 = getelementptr inbounds i16, i16* %11, i64 16
  %44 = getelementptr inbounds i8, i8* %9, i64 16
  %45 = bitcast i16* %42 to <8 x i16>*
  %46 = load <8 x i16>, <8 x i16>* %45, align 16
  %47 = bitcast i16* %43 to <8 x i16>*
  %48 = load <8 x i16>, <8 x i16>* %47, align 16
  %49 = sub <8 x i16> %46, %48
  %50 = sub <8 x i16> zeroinitializer, %49
  %51 = icmp slt <8 x i16> %49, zeroinitializer
  %52 = select <8 x i1> %51, <8 x i16> %50, <8 x i16> %49
  %53 = lshr <8 x i16> %52, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %54 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %53, <8 x i16> zeroinitializer) #5
  %55 = lshr <8 x i16> %54, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %56 = getelementptr inbounds i16, i16* %10, i64 24
  %57 = bitcast i16* %56 to <8 x i16>*
  %58 = load <8 x i16>, <8 x i16>* %57, align 16
  %59 = getelementptr inbounds i16, i16* %11, i64 24
  %60 = bitcast i16* %59 to <8 x i16>*
  %61 = load <8 x i16>, <8 x i16>* %60, align 16
  %62 = sub <8 x i16> %58, %61
  %63 = sub <8 x i16> zeroinitializer, %62
  %64 = icmp slt <8 x i16> %62, zeroinitializer
  %65 = select <8 x i1> %64, <8 x i16> %63, <8 x i16> %62
  %66 = lshr <8 x i16> %65, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %67 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %66, <8 x i16> zeroinitializer) #5
  %68 = lshr <8 x i16> %67, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %69 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %55, <8 x i16> %68) #5
  %70 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %69, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %71 = icmp slt <16 x i8> %70, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %72 = select <16 x i1> %71, <16 x i8> %70, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %73 = bitcast i8* %44 to <16 x i8>*
  store <16 x i8> %72, <16 x i8>* %73, align 16
  %74 = getelementptr inbounds i16, i16* %10, i64 32
  %75 = getelementptr inbounds i16, i16* %11, i64 32
  %76 = getelementptr inbounds i8, i8* %9, i64 32
  %77 = bitcast i16* %74 to <8 x i16>*
  %78 = load <8 x i16>, <8 x i16>* %77, align 16
  %79 = bitcast i16* %75 to <8 x i16>*
  %80 = load <8 x i16>, <8 x i16>* %79, align 16
  %81 = sub <8 x i16> %78, %80
  %82 = sub <8 x i16> zeroinitializer, %81
  %83 = icmp slt <8 x i16> %81, zeroinitializer
  %84 = select <8 x i1> %83, <8 x i16> %82, <8 x i16> %81
  %85 = lshr <8 x i16> %84, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %86 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %85, <8 x i16> zeroinitializer) #5
  %87 = lshr <8 x i16> %86, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %88 = getelementptr inbounds i16, i16* %10, i64 40
  %89 = bitcast i16* %88 to <8 x i16>*
  %90 = load <8 x i16>, <8 x i16>* %89, align 16
  %91 = getelementptr inbounds i16, i16* %11, i64 40
  %92 = bitcast i16* %91 to <8 x i16>*
  %93 = load <8 x i16>, <8 x i16>* %92, align 16
  %94 = sub <8 x i16> %90, %93
  %95 = sub <8 x i16> zeroinitializer, %94
  %96 = icmp slt <8 x i16> %94, zeroinitializer
  %97 = select <8 x i1> %96, <8 x i16> %95, <8 x i16> %94
  %98 = lshr <8 x i16> %97, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %99 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %98, <8 x i16> zeroinitializer) #5
  %100 = lshr <8 x i16> %99, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %101 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %87, <8 x i16> %100) #5
  %102 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %101, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %103 = icmp slt <16 x i8> %102, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %104 = select <16 x i1> %103, <16 x i8> %102, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %105 = bitcast i8* %76 to <16 x i8>*
  store <16 x i8> %104, <16 x i8>* %105, align 16
  %106 = getelementptr inbounds i16, i16* %10, i64 48
  %107 = getelementptr inbounds i16, i16* %11, i64 48
  %108 = getelementptr inbounds i8, i8* %9, i64 48
  %109 = bitcast i16* %106 to <8 x i16>*
  %110 = load <8 x i16>, <8 x i16>* %109, align 16
  %111 = bitcast i16* %107 to <8 x i16>*
  %112 = load <8 x i16>, <8 x i16>* %111, align 16
  %113 = sub <8 x i16> %110, %112
  %114 = sub <8 x i16> zeroinitializer, %113
  %115 = icmp slt <8 x i16> %113, zeroinitializer
  %116 = select <8 x i1> %115, <8 x i16> %114, <8 x i16> %113
  %117 = lshr <8 x i16> %116, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %118 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %117, <8 x i16> zeroinitializer) #5
  %119 = lshr <8 x i16> %118, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %120 = getelementptr inbounds i16, i16* %10, i64 56
  %121 = bitcast i16* %120 to <8 x i16>*
  %122 = load <8 x i16>, <8 x i16>* %121, align 16
  %123 = getelementptr inbounds i16, i16* %11, i64 56
  %124 = bitcast i16* %123 to <8 x i16>*
  %125 = load <8 x i16>, <8 x i16>* %124, align 16
  %126 = sub <8 x i16> %122, %125
  %127 = sub <8 x i16> zeroinitializer, %126
  %128 = icmp slt <8 x i16> %126, zeroinitializer
  %129 = select <8 x i1> %128, <8 x i16> %127, <8 x i16> %126
  %130 = lshr <8 x i16> %129, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %131 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %130, <8 x i16> zeroinitializer) #5
  %132 = lshr <8 x i16> %131, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %133 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %119, <8 x i16> %132) #5
  %134 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %133, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %135 = icmp slt <16 x i8> %134, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %136 = select <16 x i1> %135, <16 x i8> %134, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %137 = bitcast i8* %108 to <16 x i8>*
  store <16 x i8> %136, <16 x i8>* %137, align 16
  %138 = getelementptr inbounds i16, i16* %10, i64 64
  %139 = getelementptr inbounds i16, i16* %11, i64 64
  %140 = getelementptr inbounds i8, i8* %9, i64 64
  %141 = bitcast i16* %138 to <8 x i16>*
  %142 = load <8 x i16>, <8 x i16>* %141, align 16
  %143 = bitcast i16* %139 to <8 x i16>*
  %144 = load <8 x i16>, <8 x i16>* %143, align 16
  %145 = sub <8 x i16> %142, %144
  %146 = sub <8 x i16> zeroinitializer, %145
  %147 = icmp slt <8 x i16> %145, zeroinitializer
  %148 = select <8 x i1> %147, <8 x i16> %146, <8 x i16> %145
  %149 = lshr <8 x i16> %148, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %150 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %149, <8 x i16> zeroinitializer) #5
  %151 = lshr <8 x i16> %150, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %152 = getelementptr inbounds i16, i16* %10, i64 72
  %153 = bitcast i16* %152 to <8 x i16>*
  %154 = load <8 x i16>, <8 x i16>* %153, align 16
  %155 = getelementptr inbounds i16, i16* %11, i64 72
  %156 = bitcast i16* %155 to <8 x i16>*
  %157 = load <8 x i16>, <8 x i16>* %156, align 16
  %158 = sub <8 x i16> %154, %157
  %159 = sub <8 x i16> zeroinitializer, %158
  %160 = icmp slt <8 x i16> %158, zeroinitializer
  %161 = select <8 x i1> %160, <8 x i16> %159, <8 x i16> %158
  %162 = lshr <8 x i16> %161, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %163 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %162, <8 x i16> zeroinitializer) #5
  %164 = lshr <8 x i16> %163, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %165 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %151, <8 x i16> %164) #5
  %166 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %165, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %167 = icmp slt <16 x i8> %166, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %168 = select <16 x i1> %167, <16 x i8> %166, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %169 = bitcast i8* %140 to <16 x i8>*
  store <16 x i8> %168, <16 x i8>* %169, align 16
  %170 = getelementptr inbounds i16, i16* %10, i64 80
  %171 = getelementptr inbounds i16, i16* %11, i64 80
  %172 = getelementptr inbounds i8, i8* %9, i64 80
  %173 = bitcast i16* %170 to <8 x i16>*
  %174 = load <8 x i16>, <8 x i16>* %173, align 16
  %175 = bitcast i16* %171 to <8 x i16>*
  %176 = load <8 x i16>, <8 x i16>* %175, align 16
  %177 = sub <8 x i16> %174, %176
  %178 = sub <8 x i16> zeroinitializer, %177
  %179 = icmp slt <8 x i16> %177, zeroinitializer
  %180 = select <8 x i1> %179, <8 x i16> %178, <8 x i16> %177
  %181 = lshr <8 x i16> %180, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %182 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %181, <8 x i16> zeroinitializer) #5
  %183 = lshr <8 x i16> %182, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %184 = getelementptr inbounds i16, i16* %10, i64 88
  %185 = bitcast i16* %184 to <8 x i16>*
  %186 = load <8 x i16>, <8 x i16>* %185, align 16
  %187 = getelementptr inbounds i16, i16* %11, i64 88
  %188 = bitcast i16* %187 to <8 x i16>*
  %189 = load <8 x i16>, <8 x i16>* %188, align 16
  %190 = sub <8 x i16> %186, %189
  %191 = sub <8 x i16> zeroinitializer, %190
  %192 = icmp slt <8 x i16> %190, zeroinitializer
  %193 = select <8 x i1> %192, <8 x i16> %191, <8 x i16> %190
  %194 = lshr <8 x i16> %193, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %195 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %194, <8 x i16> zeroinitializer) #5
  %196 = lshr <8 x i16> %195, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %197 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %183, <8 x i16> %196) #5
  %198 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %197, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %199 = icmp slt <16 x i8> %198, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %200 = select <16 x i1> %199, <16 x i8> %198, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %201 = bitcast i8* %172 to <16 x i8>*
  store <16 x i8> %200, <16 x i8>* %201, align 16
  %202 = getelementptr inbounds i16, i16* %10, i64 96
  %203 = getelementptr inbounds i16, i16* %11, i64 96
  %204 = getelementptr inbounds i8, i8* %9, i64 96
  %205 = bitcast i16* %202 to <8 x i16>*
  %206 = load <8 x i16>, <8 x i16>* %205, align 16
  %207 = bitcast i16* %203 to <8 x i16>*
  %208 = load <8 x i16>, <8 x i16>* %207, align 16
  %209 = sub <8 x i16> %206, %208
  %210 = sub <8 x i16> zeroinitializer, %209
  %211 = icmp slt <8 x i16> %209, zeroinitializer
  %212 = select <8 x i1> %211, <8 x i16> %210, <8 x i16> %209
  %213 = lshr <8 x i16> %212, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %214 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %213, <8 x i16> zeroinitializer) #5
  %215 = lshr <8 x i16> %214, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %216 = getelementptr inbounds i16, i16* %10, i64 104
  %217 = bitcast i16* %216 to <8 x i16>*
  %218 = load <8 x i16>, <8 x i16>* %217, align 16
  %219 = getelementptr inbounds i16, i16* %11, i64 104
  %220 = bitcast i16* %219 to <8 x i16>*
  %221 = load <8 x i16>, <8 x i16>* %220, align 16
  %222 = sub <8 x i16> %218, %221
  %223 = sub <8 x i16> zeroinitializer, %222
  %224 = icmp slt <8 x i16> %222, zeroinitializer
  %225 = select <8 x i1> %224, <8 x i16> %223, <8 x i16> %222
  %226 = lshr <8 x i16> %225, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %227 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %226, <8 x i16> zeroinitializer) #5
  %228 = lshr <8 x i16> %227, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %229 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %215, <8 x i16> %228) #5
  %230 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %229, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %231 = icmp slt <16 x i8> %230, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %232 = select <16 x i1> %231, <16 x i8> %230, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %233 = bitcast i8* %204 to <16 x i8>*
  store <16 x i8> %232, <16 x i8>* %233, align 16
  %234 = getelementptr inbounds i16, i16* %10, i64 112
  %235 = getelementptr inbounds i16, i16* %11, i64 112
  %236 = getelementptr inbounds i8, i8* %9, i64 112
  %237 = bitcast i16* %234 to <8 x i16>*
  %238 = load <8 x i16>, <8 x i16>* %237, align 16
  %239 = bitcast i16* %235 to <8 x i16>*
  %240 = load <8 x i16>, <8 x i16>* %239, align 16
  %241 = sub <8 x i16> %238, %240
  %242 = sub <8 x i16> zeroinitializer, %241
  %243 = icmp slt <8 x i16> %241, zeroinitializer
  %244 = select <8 x i1> %243, <8 x i16> %242, <8 x i16> %241
  %245 = lshr <8 x i16> %244, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %246 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %245, <8 x i16> zeroinitializer) #5
  %247 = lshr <8 x i16> %246, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %248 = getelementptr inbounds i16, i16* %10, i64 120
  %249 = bitcast i16* %248 to <8 x i16>*
  %250 = load <8 x i16>, <8 x i16>* %249, align 16
  %251 = getelementptr inbounds i16, i16* %11, i64 120
  %252 = bitcast i16* %251 to <8 x i16>*
  %253 = load <8 x i16>, <8 x i16>* %252, align 16
  %254 = sub <8 x i16> %250, %253
  %255 = sub <8 x i16> zeroinitializer, %254
  %256 = icmp slt <8 x i16> %254, zeroinitializer
  %257 = select <8 x i1> %256, <8 x i16> %255, <8 x i16> %254
  %258 = lshr <8 x i16> %257, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %259 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %258, <8 x i16> zeroinitializer) #5
  %260 = lshr <8 x i16> %259, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %261 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %247, <8 x i16> %260) #5
  %262 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %261, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %263 = icmp slt <16 x i8> %262, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %264 = select <16 x i1> %263, <16 x i8> %262, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %265 = bitcast i8* %236 to <16 x i8>*
  store <16 x i8> %264, <16 x i8>* %265, align 16
  %266 = getelementptr inbounds i16, i16* %10, i64 128
  %267 = getelementptr inbounds i16, i16* %11, i64 128
  %268 = getelementptr inbounds i8, i8* %9, i64 %3
  %269 = bitcast i16* %266 to <8 x i16>*
  %270 = load <8 x i16>, <8 x i16>* %269, align 16
  %271 = bitcast i16* %267 to <8 x i16>*
  %272 = load <8 x i16>, <8 x i16>* %271, align 16
  %273 = sub <8 x i16> %270, %272
  %274 = sub <8 x i16> zeroinitializer, %273
  %275 = icmp slt <8 x i16> %273, zeroinitializer
  %276 = select <8 x i1> %275, <8 x i16> %274, <8 x i16> %273
  %277 = lshr <8 x i16> %276, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %278 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %277, <8 x i16> zeroinitializer) #5
  %279 = lshr <8 x i16> %278, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %280 = getelementptr inbounds i16, i16* %10, i64 136
  %281 = bitcast i16* %280 to <8 x i16>*
  %282 = load <8 x i16>, <8 x i16>* %281, align 16
  %283 = getelementptr inbounds i16, i16* %11, i64 136
  %284 = bitcast i16* %283 to <8 x i16>*
  %285 = load <8 x i16>, <8 x i16>* %284, align 16
  %286 = sub <8 x i16> %282, %285
  %287 = sub <8 x i16> zeroinitializer, %286
  %288 = icmp slt <8 x i16> %286, zeroinitializer
  %289 = select <8 x i1> %288, <8 x i16> %287, <8 x i16> %286
  %290 = lshr <8 x i16> %289, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %291 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %290, <8 x i16> zeroinitializer) #5
  %292 = lshr <8 x i16> %291, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %293 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %279, <8 x i16> %292) #5
  %294 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %293, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %295 = icmp slt <16 x i8> %294, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %296 = select <16 x i1> %295, <16 x i8> %294, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %297 = bitcast i8* %268 to <16 x i8>*
  store <16 x i8> %296, <16 x i8>* %297, align 16
  %298 = getelementptr inbounds i16, i16* %10, i64 144
  %299 = getelementptr inbounds i16, i16* %11, i64 144
  %300 = getelementptr inbounds i8, i8* %268, i64 16
  %301 = bitcast i16* %298 to <8 x i16>*
  %302 = load <8 x i16>, <8 x i16>* %301, align 16
  %303 = bitcast i16* %299 to <8 x i16>*
  %304 = load <8 x i16>, <8 x i16>* %303, align 16
  %305 = sub <8 x i16> %302, %304
  %306 = sub <8 x i16> zeroinitializer, %305
  %307 = icmp slt <8 x i16> %305, zeroinitializer
  %308 = select <8 x i1> %307, <8 x i16> %306, <8 x i16> %305
  %309 = lshr <8 x i16> %308, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %310 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %309, <8 x i16> zeroinitializer) #5
  %311 = lshr <8 x i16> %310, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %312 = getelementptr inbounds i16, i16* %10, i64 152
  %313 = bitcast i16* %312 to <8 x i16>*
  %314 = load <8 x i16>, <8 x i16>* %313, align 16
  %315 = getelementptr inbounds i16, i16* %11, i64 152
  %316 = bitcast i16* %315 to <8 x i16>*
  %317 = load <8 x i16>, <8 x i16>* %316, align 16
  %318 = sub <8 x i16> %314, %317
  %319 = sub <8 x i16> zeroinitializer, %318
  %320 = icmp slt <8 x i16> %318, zeroinitializer
  %321 = select <8 x i1> %320, <8 x i16> %319, <8 x i16> %318
  %322 = lshr <8 x i16> %321, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %323 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %322, <8 x i16> zeroinitializer) #5
  %324 = lshr <8 x i16> %323, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %325 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %311, <8 x i16> %324) #5
  %326 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %325, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %327 = icmp slt <16 x i8> %326, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %328 = select <16 x i1> %327, <16 x i8> %326, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %329 = bitcast i8* %300 to <16 x i8>*
  store <16 x i8> %328, <16 x i8>* %329, align 16
  %330 = getelementptr inbounds i16, i16* %10, i64 160
  %331 = getelementptr inbounds i16, i16* %11, i64 160
  %332 = getelementptr inbounds i8, i8* %268, i64 32
  %333 = bitcast i16* %330 to <8 x i16>*
  %334 = load <8 x i16>, <8 x i16>* %333, align 16
  %335 = bitcast i16* %331 to <8 x i16>*
  %336 = load <8 x i16>, <8 x i16>* %335, align 16
  %337 = sub <8 x i16> %334, %336
  %338 = sub <8 x i16> zeroinitializer, %337
  %339 = icmp slt <8 x i16> %337, zeroinitializer
  %340 = select <8 x i1> %339, <8 x i16> %338, <8 x i16> %337
  %341 = lshr <8 x i16> %340, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %342 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %341, <8 x i16> zeroinitializer) #5
  %343 = lshr <8 x i16> %342, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %344 = getelementptr inbounds i16, i16* %10, i64 168
  %345 = bitcast i16* %344 to <8 x i16>*
  %346 = load <8 x i16>, <8 x i16>* %345, align 16
  %347 = getelementptr inbounds i16, i16* %11, i64 168
  %348 = bitcast i16* %347 to <8 x i16>*
  %349 = load <8 x i16>, <8 x i16>* %348, align 16
  %350 = sub <8 x i16> %346, %349
  %351 = sub <8 x i16> zeroinitializer, %350
  %352 = icmp slt <8 x i16> %350, zeroinitializer
  %353 = select <8 x i1> %352, <8 x i16> %351, <8 x i16> %350
  %354 = lshr <8 x i16> %353, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %355 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %354, <8 x i16> zeroinitializer) #5
  %356 = lshr <8 x i16> %355, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %357 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %343, <8 x i16> %356) #5
  %358 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %357, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %359 = icmp slt <16 x i8> %358, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %360 = select <16 x i1> %359, <16 x i8> %358, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %361 = bitcast i8* %332 to <16 x i8>*
  store <16 x i8> %360, <16 x i8>* %361, align 16
  %362 = getelementptr inbounds i16, i16* %10, i64 176
  %363 = getelementptr inbounds i16, i16* %11, i64 176
  %364 = getelementptr inbounds i8, i8* %268, i64 48
  %365 = bitcast i16* %362 to <8 x i16>*
  %366 = load <8 x i16>, <8 x i16>* %365, align 16
  %367 = bitcast i16* %363 to <8 x i16>*
  %368 = load <8 x i16>, <8 x i16>* %367, align 16
  %369 = sub <8 x i16> %366, %368
  %370 = sub <8 x i16> zeroinitializer, %369
  %371 = icmp slt <8 x i16> %369, zeroinitializer
  %372 = select <8 x i1> %371, <8 x i16> %370, <8 x i16> %369
  %373 = lshr <8 x i16> %372, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %374 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %373, <8 x i16> zeroinitializer) #5
  %375 = lshr <8 x i16> %374, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %376 = getelementptr inbounds i16, i16* %10, i64 184
  %377 = bitcast i16* %376 to <8 x i16>*
  %378 = load <8 x i16>, <8 x i16>* %377, align 16
  %379 = getelementptr inbounds i16, i16* %11, i64 184
  %380 = bitcast i16* %379 to <8 x i16>*
  %381 = load <8 x i16>, <8 x i16>* %380, align 16
  %382 = sub <8 x i16> %378, %381
  %383 = sub <8 x i16> zeroinitializer, %382
  %384 = icmp slt <8 x i16> %382, zeroinitializer
  %385 = select <8 x i1> %384, <8 x i16> %383, <8 x i16> %382
  %386 = lshr <8 x i16> %385, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %387 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %386, <8 x i16> zeroinitializer) #5
  %388 = lshr <8 x i16> %387, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %389 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %375, <8 x i16> %388) #5
  %390 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %389, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %391 = icmp slt <16 x i8> %390, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %392 = select <16 x i1> %391, <16 x i8> %390, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %393 = bitcast i8* %364 to <16 x i8>*
  store <16 x i8> %392, <16 x i8>* %393, align 16
  %394 = getelementptr inbounds i16, i16* %10, i64 192
  %395 = getelementptr inbounds i16, i16* %11, i64 192
  %396 = getelementptr inbounds i8, i8* %268, i64 64
  %397 = bitcast i16* %394 to <8 x i16>*
  %398 = load <8 x i16>, <8 x i16>* %397, align 16
  %399 = bitcast i16* %395 to <8 x i16>*
  %400 = load <8 x i16>, <8 x i16>* %399, align 16
  %401 = sub <8 x i16> %398, %400
  %402 = sub <8 x i16> zeroinitializer, %401
  %403 = icmp slt <8 x i16> %401, zeroinitializer
  %404 = select <8 x i1> %403, <8 x i16> %402, <8 x i16> %401
  %405 = lshr <8 x i16> %404, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %406 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %405, <8 x i16> zeroinitializer) #5
  %407 = lshr <8 x i16> %406, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %408 = getelementptr inbounds i16, i16* %10, i64 200
  %409 = bitcast i16* %408 to <8 x i16>*
  %410 = load <8 x i16>, <8 x i16>* %409, align 16
  %411 = getelementptr inbounds i16, i16* %11, i64 200
  %412 = bitcast i16* %411 to <8 x i16>*
  %413 = load <8 x i16>, <8 x i16>* %412, align 16
  %414 = sub <8 x i16> %410, %413
  %415 = sub <8 x i16> zeroinitializer, %414
  %416 = icmp slt <8 x i16> %414, zeroinitializer
  %417 = select <8 x i1> %416, <8 x i16> %415, <8 x i16> %414
  %418 = lshr <8 x i16> %417, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %419 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %418, <8 x i16> zeroinitializer) #5
  %420 = lshr <8 x i16> %419, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %421 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %407, <8 x i16> %420) #5
  %422 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %421, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %423 = icmp slt <16 x i8> %422, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %424 = select <16 x i1> %423, <16 x i8> %422, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %425 = bitcast i8* %396 to <16 x i8>*
  store <16 x i8> %424, <16 x i8>* %425, align 16
  %426 = getelementptr inbounds i16, i16* %10, i64 208
  %427 = getelementptr inbounds i16, i16* %11, i64 208
  %428 = getelementptr inbounds i8, i8* %396, i64 16
  %429 = bitcast i16* %426 to <8 x i16>*
  %430 = load <8 x i16>, <8 x i16>* %429, align 16
  %431 = bitcast i16* %427 to <8 x i16>*
  %432 = load <8 x i16>, <8 x i16>* %431, align 16
  %433 = sub <8 x i16> %430, %432
  %434 = sub <8 x i16> zeroinitializer, %433
  %435 = icmp slt <8 x i16> %433, zeroinitializer
  %436 = select <8 x i1> %435, <8 x i16> %434, <8 x i16> %433
  %437 = lshr <8 x i16> %436, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %438 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %437, <8 x i16> zeroinitializer) #5
  %439 = lshr <8 x i16> %438, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %440 = getelementptr inbounds i16, i16* %10, i64 216
  %441 = bitcast i16* %440 to <8 x i16>*
  %442 = load <8 x i16>, <8 x i16>* %441, align 16
  %443 = getelementptr inbounds i16, i16* %11, i64 216
  %444 = bitcast i16* %443 to <8 x i16>*
  %445 = load <8 x i16>, <8 x i16>* %444, align 16
  %446 = sub <8 x i16> %442, %445
  %447 = sub <8 x i16> zeroinitializer, %446
  %448 = icmp slt <8 x i16> %446, zeroinitializer
  %449 = select <8 x i1> %448, <8 x i16> %447, <8 x i16> %446
  %450 = lshr <8 x i16> %449, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %451 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %450, <8 x i16> zeroinitializer) #5
  %452 = lshr <8 x i16> %451, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %453 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %439, <8 x i16> %452) #5
  %454 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %453, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %455 = icmp slt <16 x i8> %454, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %456 = select <16 x i1> %455, <16 x i8> %454, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %457 = bitcast i8* %428 to <16 x i8>*
  store <16 x i8> %456, <16 x i8>* %457, align 16
  %458 = getelementptr inbounds i16, i16* %10, i64 224
  %459 = getelementptr inbounds i16, i16* %11, i64 224
  %460 = getelementptr inbounds i8, i8* %396, i64 32
  %461 = bitcast i16* %458 to <8 x i16>*
  %462 = load <8 x i16>, <8 x i16>* %461, align 16
  %463 = bitcast i16* %459 to <8 x i16>*
  %464 = load <8 x i16>, <8 x i16>* %463, align 16
  %465 = sub <8 x i16> %462, %464
  %466 = sub <8 x i16> zeroinitializer, %465
  %467 = icmp slt <8 x i16> %465, zeroinitializer
  %468 = select <8 x i1> %467, <8 x i16> %466, <8 x i16> %465
  %469 = lshr <8 x i16> %468, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %470 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %469, <8 x i16> zeroinitializer) #5
  %471 = lshr <8 x i16> %470, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %472 = getelementptr inbounds i16, i16* %10, i64 232
  %473 = bitcast i16* %472 to <8 x i16>*
  %474 = load <8 x i16>, <8 x i16>* %473, align 16
  %475 = getelementptr inbounds i16, i16* %11, i64 232
  %476 = bitcast i16* %475 to <8 x i16>*
  %477 = load <8 x i16>, <8 x i16>* %476, align 16
  %478 = sub <8 x i16> %474, %477
  %479 = sub <8 x i16> zeroinitializer, %478
  %480 = icmp slt <8 x i16> %478, zeroinitializer
  %481 = select <8 x i1> %480, <8 x i16> %479, <8 x i16> %478
  %482 = lshr <8 x i16> %481, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %483 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %482, <8 x i16> zeroinitializer) #5
  %484 = lshr <8 x i16> %483, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %485 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %471, <8 x i16> %484) #5
  %486 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %485, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %487 = icmp slt <16 x i8> %486, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %488 = select <16 x i1> %487, <16 x i8> %486, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %489 = bitcast i8* %460 to <16 x i8>*
  store <16 x i8> %488, <16 x i8>* %489, align 16
  %490 = getelementptr inbounds i16, i16* %10, i64 240
  %491 = getelementptr inbounds i16, i16* %11, i64 240
  %492 = getelementptr inbounds i8, i8* %396, i64 48
  %493 = bitcast i16* %490 to <8 x i16>*
  %494 = load <8 x i16>, <8 x i16>* %493, align 16
  %495 = bitcast i16* %491 to <8 x i16>*
  %496 = load <8 x i16>, <8 x i16>* %495, align 16
  %497 = sub <8 x i16> %494, %496
  %498 = sub <8 x i16> zeroinitializer, %497
  %499 = icmp slt <8 x i16> %497, zeroinitializer
  %500 = select <8 x i1> %499, <8 x i16> %498, <8 x i16> %497
  %501 = lshr <8 x i16> %500, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %502 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %501, <8 x i16> zeroinitializer) #5
  %503 = lshr <8 x i16> %502, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %504 = getelementptr inbounds i16, i16* %10, i64 248
  %505 = bitcast i16* %504 to <8 x i16>*
  %506 = load <8 x i16>, <8 x i16>* %505, align 16
  %507 = getelementptr inbounds i16, i16* %11, i64 248
  %508 = bitcast i16* %507 to <8 x i16>*
  %509 = load <8 x i16>, <8 x i16>* %508, align 16
  %510 = sub <8 x i16> %506, %509
  %511 = sub <8 x i16> zeroinitializer, %510
  %512 = icmp slt <8 x i16> %510, zeroinitializer
  %513 = select <8 x i1> %512, <8 x i16> %511, <8 x i16> %510
  %514 = lshr <8 x i16> %513, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %515 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %514, <8 x i16> zeroinitializer) #5
  %516 = lshr <8 x i16> %515, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %517 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %503, <8 x i16> %516) #5
  %518 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %517, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %519 = icmp slt <16 x i8> %518, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %520 = select <16 x i1> %519, <16 x i8> %518, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %521 = bitcast i8* %492 to <16 x i8>*
  store <16 x i8> %520, <16 x i8>* %521, align 16
  %522 = getelementptr inbounds i16, i16* %10, i64 256
  %523 = getelementptr inbounds i16, i16* %11, i64 256
  %524 = getelementptr inbounds i8, i8* %396, i64 %7
  %525 = bitcast i16* %522 to <8 x i16>*
  %526 = load <8 x i16>, <8 x i16>* %525, align 16
  %527 = bitcast i16* %523 to <8 x i16>*
  %528 = load <8 x i16>, <8 x i16>* %527, align 16
  %529 = sub <8 x i16> %526, %528
  %530 = sub <8 x i16> zeroinitializer, %529
  %531 = icmp slt <8 x i16> %529, zeroinitializer
  %532 = select <8 x i1> %531, <8 x i16> %530, <8 x i16> %529
  %533 = lshr <8 x i16> %532, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %534 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %533, <8 x i16> zeroinitializer) #5
  %535 = lshr <8 x i16> %534, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %536 = getelementptr inbounds i16, i16* %10, i64 264
  %537 = bitcast i16* %536 to <8 x i16>*
  %538 = load <8 x i16>, <8 x i16>* %537, align 16
  %539 = getelementptr inbounds i16, i16* %11, i64 264
  %540 = bitcast i16* %539 to <8 x i16>*
  %541 = load <8 x i16>, <8 x i16>* %540, align 16
  %542 = sub <8 x i16> %538, %541
  %543 = sub <8 x i16> zeroinitializer, %542
  %544 = icmp slt <8 x i16> %542, zeroinitializer
  %545 = select <8 x i1> %544, <8 x i16> %543, <8 x i16> %542
  %546 = lshr <8 x i16> %545, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %547 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %546, <8 x i16> zeroinitializer) #5
  %548 = lshr <8 x i16> %547, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %549 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %535, <8 x i16> %548) #5
  %550 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %549, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %551 = icmp slt <16 x i8> %550, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %552 = select <16 x i1> %551, <16 x i8> %550, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %553 = bitcast i8* %524 to <16 x i8>*
  store <16 x i8> %552, <16 x i8>* %553, align 16
  %554 = getelementptr inbounds i16, i16* %10, i64 272
  %555 = getelementptr inbounds i16, i16* %11, i64 272
  %556 = getelementptr inbounds i8, i8* %524, i64 16
  %557 = bitcast i16* %554 to <8 x i16>*
  %558 = load <8 x i16>, <8 x i16>* %557, align 16
  %559 = bitcast i16* %555 to <8 x i16>*
  %560 = load <8 x i16>, <8 x i16>* %559, align 16
  %561 = sub <8 x i16> %558, %560
  %562 = sub <8 x i16> zeroinitializer, %561
  %563 = icmp slt <8 x i16> %561, zeroinitializer
  %564 = select <8 x i1> %563, <8 x i16> %562, <8 x i16> %561
  %565 = lshr <8 x i16> %564, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %566 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %565, <8 x i16> zeroinitializer) #5
  %567 = lshr <8 x i16> %566, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %568 = getelementptr inbounds i16, i16* %10, i64 280
  %569 = bitcast i16* %568 to <8 x i16>*
  %570 = load <8 x i16>, <8 x i16>* %569, align 16
  %571 = getelementptr inbounds i16, i16* %11, i64 280
  %572 = bitcast i16* %571 to <8 x i16>*
  %573 = load <8 x i16>, <8 x i16>* %572, align 16
  %574 = sub <8 x i16> %570, %573
  %575 = sub <8 x i16> zeroinitializer, %574
  %576 = icmp slt <8 x i16> %574, zeroinitializer
  %577 = select <8 x i1> %576, <8 x i16> %575, <8 x i16> %574
  %578 = lshr <8 x i16> %577, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %579 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %578, <8 x i16> zeroinitializer) #5
  %580 = lshr <8 x i16> %579, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %581 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %567, <8 x i16> %580) #5
  %582 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %581, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %583 = icmp slt <16 x i8> %582, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %584 = select <16 x i1> %583, <16 x i8> %582, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %585 = bitcast i8* %556 to <16 x i8>*
  store <16 x i8> %584, <16 x i8>* %585, align 16
  %586 = getelementptr inbounds i16, i16* %10, i64 288
  %587 = getelementptr inbounds i16, i16* %11, i64 288
  %588 = getelementptr inbounds i8, i8* %524, i64 32
  %589 = bitcast i16* %586 to <8 x i16>*
  %590 = load <8 x i16>, <8 x i16>* %589, align 16
  %591 = bitcast i16* %587 to <8 x i16>*
  %592 = load <8 x i16>, <8 x i16>* %591, align 16
  %593 = sub <8 x i16> %590, %592
  %594 = sub <8 x i16> zeroinitializer, %593
  %595 = icmp slt <8 x i16> %593, zeroinitializer
  %596 = select <8 x i1> %595, <8 x i16> %594, <8 x i16> %593
  %597 = lshr <8 x i16> %596, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %598 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %597, <8 x i16> zeroinitializer) #5
  %599 = lshr <8 x i16> %598, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %600 = getelementptr inbounds i16, i16* %10, i64 296
  %601 = bitcast i16* %600 to <8 x i16>*
  %602 = load <8 x i16>, <8 x i16>* %601, align 16
  %603 = getelementptr inbounds i16, i16* %11, i64 296
  %604 = bitcast i16* %603 to <8 x i16>*
  %605 = load <8 x i16>, <8 x i16>* %604, align 16
  %606 = sub <8 x i16> %602, %605
  %607 = sub <8 x i16> zeroinitializer, %606
  %608 = icmp slt <8 x i16> %606, zeroinitializer
  %609 = select <8 x i1> %608, <8 x i16> %607, <8 x i16> %606
  %610 = lshr <8 x i16> %609, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %611 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %610, <8 x i16> zeroinitializer) #5
  %612 = lshr <8 x i16> %611, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %613 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %599, <8 x i16> %612) #5
  %614 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %613, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %615 = icmp slt <16 x i8> %614, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %616 = select <16 x i1> %615, <16 x i8> %614, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %617 = bitcast i8* %588 to <16 x i8>*
  store <16 x i8> %616, <16 x i8>* %617, align 16
  %618 = getelementptr inbounds i16, i16* %10, i64 304
  %619 = getelementptr inbounds i16, i16* %11, i64 304
  %620 = getelementptr inbounds i8, i8* %524, i64 48
  %621 = bitcast i16* %618 to <8 x i16>*
  %622 = load <8 x i16>, <8 x i16>* %621, align 16
  %623 = bitcast i16* %619 to <8 x i16>*
  %624 = load <8 x i16>, <8 x i16>* %623, align 16
  %625 = sub <8 x i16> %622, %624
  %626 = sub <8 x i16> zeroinitializer, %625
  %627 = icmp slt <8 x i16> %625, zeroinitializer
  %628 = select <8 x i1> %627, <8 x i16> %626, <8 x i16> %625
  %629 = lshr <8 x i16> %628, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %630 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %629, <8 x i16> zeroinitializer) #5
  %631 = lshr <8 x i16> %630, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %632 = getelementptr inbounds i16, i16* %10, i64 312
  %633 = bitcast i16* %632 to <8 x i16>*
  %634 = load <8 x i16>, <8 x i16>* %633, align 16
  %635 = getelementptr inbounds i16, i16* %11, i64 312
  %636 = bitcast i16* %635 to <8 x i16>*
  %637 = load <8 x i16>, <8 x i16>* %636, align 16
  %638 = sub <8 x i16> %634, %637
  %639 = sub <8 x i16> zeroinitializer, %638
  %640 = icmp slt <8 x i16> %638, zeroinitializer
  %641 = select <8 x i1> %640, <8 x i16> %639, <8 x i16> %638
  %642 = lshr <8 x i16> %641, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %643 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %642, <8 x i16> zeroinitializer) #5
  %644 = lshr <8 x i16> %643, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %645 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %631, <8 x i16> %644) #5
  %646 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %645, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %647 = icmp slt <16 x i8> %646, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %648 = select <16 x i1> %647, <16 x i8> %646, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %649 = bitcast i8* %620 to <16 x i8>*
  store <16 x i8> %648, <16 x i8>* %649, align 16
  %650 = getelementptr inbounds i16, i16* %10, i64 320
  %651 = getelementptr inbounds i16, i16* %11, i64 320
  %652 = getelementptr inbounds i8, i8* %524, i64 64
  %653 = bitcast i16* %650 to <8 x i16>*
  %654 = load <8 x i16>, <8 x i16>* %653, align 16
  %655 = bitcast i16* %651 to <8 x i16>*
  %656 = load <8 x i16>, <8 x i16>* %655, align 16
  %657 = sub <8 x i16> %654, %656
  %658 = sub <8 x i16> zeroinitializer, %657
  %659 = icmp slt <8 x i16> %657, zeroinitializer
  %660 = select <8 x i1> %659, <8 x i16> %658, <8 x i16> %657
  %661 = lshr <8 x i16> %660, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %662 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %661, <8 x i16> zeroinitializer) #5
  %663 = lshr <8 x i16> %662, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %664 = getelementptr inbounds i16, i16* %10, i64 328
  %665 = bitcast i16* %664 to <8 x i16>*
  %666 = load <8 x i16>, <8 x i16>* %665, align 16
  %667 = getelementptr inbounds i16, i16* %11, i64 328
  %668 = bitcast i16* %667 to <8 x i16>*
  %669 = load <8 x i16>, <8 x i16>* %668, align 16
  %670 = sub <8 x i16> %666, %669
  %671 = sub <8 x i16> zeroinitializer, %670
  %672 = icmp slt <8 x i16> %670, zeroinitializer
  %673 = select <8 x i1> %672, <8 x i16> %671, <8 x i16> %670
  %674 = lshr <8 x i16> %673, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %675 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %674, <8 x i16> zeroinitializer) #5
  %676 = lshr <8 x i16> %675, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %677 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %663, <8 x i16> %676) #5
  %678 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %677, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %679 = icmp slt <16 x i8> %678, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %680 = select <16 x i1> %679, <16 x i8> %678, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %681 = bitcast i8* %652 to <16 x i8>*
  store <16 x i8> %680, <16 x i8>* %681, align 16
  %682 = getelementptr inbounds i16, i16* %10, i64 336
  %683 = getelementptr inbounds i16, i16* %11, i64 336
  %684 = getelementptr inbounds i8, i8* %652, i64 16
  %685 = bitcast i16* %682 to <8 x i16>*
  %686 = load <8 x i16>, <8 x i16>* %685, align 16
  %687 = bitcast i16* %683 to <8 x i16>*
  %688 = load <8 x i16>, <8 x i16>* %687, align 16
  %689 = sub <8 x i16> %686, %688
  %690 = sub <8 x i16> zeroinitializer, %689
  %691 = icmp slt <8 x i16> %689, zeroinitializer
  %692 = select <8 x i1> %691, <8 x i16> %690, <8 x i16> %689
  %693 = lshr <8 x i16> %692, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %694 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %693, <8 x i16> zeroinitializer) #5
  %695 = lshr <8 x i16> %694, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %696 = getelementptr inbounds i16, i16* %10, i64 344
  %697 = bitcast i16* %696 to <8 x i16>*
  %698 = load <8 x i16>, <8 x i16>* %697, align 16
  %699 = getelementptr inbounds i16, i16* %11, i64 344
  %700 = bitcast i16* %699 to <8 x i16>*
  %701 = load <8 x i16>, <8 x i16>* %700, align 16
  %702 = sub <8 x i16> %698, %701
  %703 = sub <8 x i16> zeroinitializer, %702
  %704 = icmp slt <8 x i16> %702, zeroinitializer
  %705 = select <8 x i1> %704, <8 x i16> %703, <8 x i16> %702
  %706 = lshr <8 x i16> %705, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %707 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %706, <8 x i16> zeroinitializer) #5
  %708 = lshr <8 x i16> %707, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %709 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %695, <8 x i16> %708) #5
  %710 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %709, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %711 = icmp slt <16 x i8> %710, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %712 = select <16 x i1> %711, <16 x i8> %710, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %713 = bitcast i8* %684 to <16 x i8>*
  store <16 x i8> %712, <16 x i8>* %713, align 16
  %714 = getelementptr inbounds i16, i16* %10, i64 352
  %715 = getelementptr inbounds i16, i16* %11, i64 352
  %716 = getelementptr inbounds i8, i8* %652, i64 32
  %717 = bitcast i16* %714 to <8 x i16>*
  %718 = load <8 x i16>, <8 x i16>* %717, align 16
  %719 = bitcast i16* %715 to <8 x i16>*
  %720 = load <8 x i16>, <8 x i16>* %719, align 16
  %721 = sub <8 x i16> %718, %720
  %722 = sub <8 x i16> zeroinitializer, %721
  %723 = icmp slt <8 x i16> %721, zeroinitializer
  %724 = select <8 x i1> %723, <8 x i16> %722, <8 x i16> %721
  %725 = lshr <8 x i16> %724, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %726 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %725, <8 x i16> zeroinitializer) #5
  %727 = lshr <8 x i16> %726, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %728 = getelementptr inbounds i16, i16* %10, i64 360
  %729 = bitcast i16* %728 to <8 x i16>*
  %730 = load <8 x i16>, <8 x i16>* %729, align 16
  %731 = getelementptr inbounds i16, i16* %11, i64 360
  %732 = bitcast i16* %731 to <8 x i16>*
  %733 = load <8 x i16>, <8 x i16>* %732, align 16
  %734 = sub <8 x i16> %730, %733
  %735 = sub <8 x i16> zeroinitializer, %734
  %736 = icmp slt <8 x i16> %734, zeroinitializer
  %737 = select <8 x i1> %736, <8 x i16> %735, <8 x i16> %734
  %738 = lshr <8 x i16> %737, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %739 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %738, <8 x i16> zeroinitializer) #5
  %740 = lshr <8 x i16> %739, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %741 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %727, <8 x i16> %740) #5
  %742 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %741, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %743 = icmp slt <16 x i8> %742, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %744 = select <16 x i1> %743, <16 x i8> %742, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %745 = bitcast i8* %716 to <16 x i8>*
  store <16 x i8> %744, <16 x i8>* %745, align 16
  %746 = getelementptr inbounds i16, i16* %10, i64 368
  %747 = getelementptr inbounds i16, i16* %11, i64 368
  %748 = getelementptr inbounds i8, i8* %652, i64 48
  %749 = bitcast i16* %746 to <8 x i16>*
  %750 = load <8 x i16>, <8 x i16>* %749, align 16
  %751 = bitcast i16* %747 to <8 x i16>*
  %752 = load <8 x i16>, <8 x i16>* %751, align 16
  %753 = sub <8 x i16> %750, %752
  %754 = sub <8 x i16> zeroinitializer, %753
  %755 = icmp slt <8 x i16> %753, zeroinitializer
  %756 = select <8 x i1> %755, <8 x i16> %754, <8 x i16> %753
  %757 = lshr <8 x i16> %756, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %758 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %757, <8 x i16> zeroinitializer) #5
  %759 = lshr <8 x i16> %758, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %760 = getelementptr inbounds i16, i16* %10, i64 376
  %761 = bitcast i16* %760 to <8 x i16>*
  %762 = load <8 x i16>, <8 x i16>* %761, align 16
  %763 = getelementptr inbounds i16, i16* %11, i64 376
  %764 = bitcast i16* %763 to <8 x i16>*
  %765 = load <8 x i16>, <8 x i16>* %764, align 16
  %766 = sub <8 x i16> %762, %765
  %767 = sub <8 x i16> zeroinitializer, %766
  %768 = icmp slt <8 x i16> %766, zeroinitializer
  %769 = select <8 x i1> %768, <8 x i16> %767, <8 x i16> %766
  %770 = lshr <8 x i16> %769, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %771 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %770, <8 x i16> zeroinitializer) #5
  %772 = lshr <8 x i16> %771, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %773 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %759, <8 x i16> %772) #5
  %774 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %773, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %775 = icmp slt <16 x i8> %774, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %776 = select <16 x i1> %775, <16 x i8> %774, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %777 = bitcast i8* %748 to <16 x i8>*
  store <16 x i8> %776, <16 x i8>* %777, align 16
  %778 = getelementptr inbounds i16, i16* %10, i64 384
  %779 = getelementptr inbounds i16, i16* %11, i64 384
  %780 = getelementptr inbounds i8, i8* %652, i64 %7
  %781 = add nuw nsw i32 %12, 1
  %782 = icmp eq i32 %781, 21
  br i1 %782, label %783, label %8

783:                                              ; preds = %8
  %784 = bitcast i16* %778 to <8 x i16>*
  %785 = load <8 x i16>, <8 x i16>* %784, align 16
  %786 = bitcast i16* %779 to <8 x i16>*
  %787 = load <8 x i16>, <8 x i16>* %786, align 16
  %788 = sub <8 x i16> %785, %787
  %789 = sub <8 x i16> zeroinitializer, %788
  %790 = icmp slt <8 x i16> %788, zeroinitializer
  %791 = select <8 x i1> %790, <8 x i16> %789, <8 x i16> %788
  %792 = lshr <8 x i16> %791, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %793 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %792, <8 x i16> zeroinitializer) #5
  %794 = lshr <8 x i16> %793, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %795 = getelementptr inbounds i16, i16* %10, i64 392
  %796 = bitcast i16* %795 to <8 x i16>*
  %797 = load <8 x i16>, <8 x i16>* %796, align 16
  %798 = getelementptr inbounds i16, i16* %11, i64 392
  %799 = bitcast i16* %798 to <8 x i16>*
  %800 = load <8 x i16>, <8 x i16>* %799, align 16
  %801 = sub <8 x i16> %797, %800
  %802 = sub <8 x i16> zeroinitializer, %801
  %803 = icmp slt <8 x i16> %801, zeroinitializer
  %804 = select <8 x i1> %803, <8 x i16> %802, <8 x i16> %801
  %805 = lshr <8 x i16> %804, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %806 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %805, <8 x i16> zeroinitializer) #5
  %807 = lshr <8 x i16> %806, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %808 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %794, <8 x i16> %807) #5
  %809 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %808, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %810 = icmp slt <16 x i8> %809, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %811 = select <16 x i1> %810, <16 x i8> %809, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %812 = bitcast i8* %780 to <16 x i8>*
  store <16 x i8> %811, <16 x i8>* %812, align 16
  %813 = getelementptr inbounds i16, i16* %10, i64 400
  %814 = getelementptr inbounds i16, i16* %11, i64 400
  %815 = getelementptr inbounds i8, i8* %780, i64 16
  %816 = bitcast i16* %813 to <8 x i16>*
  %817 = load <8 x i16>, <8 x i16>* %816, align 16
  %818 = bitcast i16* %814 to <8 x i16>*
  %819 = load <8 x i16>, <8 x i16>* %818, align 16
  %820 = sub <8 x i16> %817, %819
  %821 = sub <8 x i16> zeroinitializer, %820
  %822 = icmp slt <8 x i16> %820, zeroinitializer
  %823 = select <8 x i1> %822, <8 x i16> %821, <8 x i16> %820
  %824 = lshr <8 x i16> %823, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %825 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %824, <8 x i16> zeroinitializer) #5
  %826 = lshr <8 x i16> %825, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %827 = getelementptr inbounds i16, i16* %10, i64 408
  %828 = bitcast i16* %827 to <8 x i16>*
  %829 = load <8 x i16>, <8 x i16>* %828, align 16
  %830 = getelementptr inbounds i16, i16* %11, i64 408
  %831 = bitcast i16* %830 to <8 x i16>*
  %832 = load <8 x i16>, <8 x i16>* %831, align 16
  %833 = sub <8 x i16> %829, %832
  %834 = sub <8 x i16> zeroinitializer, %833
  %835 = icmp slt <8 x i16> %833, zeroinitializer
  %836 = select <8 x i1> %835, <8 x i16> %834, <8 x i16> %833
  %837 = lshr <8 x i16> %836, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %838 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %837, <8 x i16> zeroinitializer) #5
  %839 = lshr <8 x i16> %838, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %840 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %826, <8 x i16> %839) #5
  %841 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %840, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %842 = icmp slt <16 x i8> %841, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %843 = select <16 x i1> %842, <16 x i8> %841, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %844 = bitcast i8* %815 to <16 x i8>*
  store <16 x i8> %843, <16 x i8>* %844, align 16
  %845 = getelementptr inbounds i16, i16* %10, i64 416
  %846 = getelementptr inbounds i16, i16* %11, i64 416
  %847 = getelementptr inbounds i8, i8* %780, i64 32
  %848 = bitcast i16* %845 to <8 x i16>*
  %849 = load <8 x i16>, <8 x i16>* %848, align 16
  %850 = bitcast i16* %846 to <8 x i16>*
  %851 = load <8 x i16>, <8 x i16>* %850, align 16
  %852 = sub <8 x i16> %849, %851
  %853 = sub <8 x i16> zeroinitializer, %852
  %854 = icmp slt <8 x i16> %852, zeroinitializer
  %855 = select <8 x i1> %854, <8 x i16> %853, <8 x i16> %852
  %856 = lshr <8 x i16> %855, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %857 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %856, <8 x i16> zeroinitializer) #5
  %858 = lshr <8 x i16> %857, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %859 = getelementptr inbounds i16, i16* %10, i64 424
  %860 = bitcast i16* %859 to <8 x i16>*
  %861 = load <8 x i16>, <8 x i16>* %860, align 16
  %862 = getelementptr inbounds i16, i16* %11, i64 424
  %863 = bitcast i16* %862 to <8 x i16>*
  %864 = load <8 x i16>, <8 x i16>* %863, align 16
  %865 = sub <8 x i16> %861, %864
  %866 = sub <8 x i16> zeroinitializer, %865
  %867 = icmp slt <8 x i16> %865, zeroinitializer
  %868 = select <8 x i1> %867, <8 x i16> %866, <8 x i16> %865
  %869 = lshr <8 x i16> %868, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %870 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %869, <8 x i16> zeroinitializer) #5
  %871 = lshr <8 x i16> %870, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %872 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %858, <8 x i16> %871) #5
  %873 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %872, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %874 = icmp slt <16 x i8> %873, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %875 = select <16 x i1> %874, <16 x i8> %873, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %876 = bitcast i8* %847 to <16 x i8>*
  store <16 x i8> %875, <16 x i8>* %876, align 16
  %877 = getelementptr inbounds i16, i16* %10, i64 432
  %878 = getelementptr inbounds i16, i16* %11, i64 432
  %879 = getelementptr inbounds i8, i8* %780, i64 48
  %880 = bitcast i16* %877 to <8 x i16>*
  %881 = load <8 x i16>, <8 x i16>* %880, align 16
  %882 = bitcast i16* %878 to <8 x i16>*
  %883 = load <8 x i16>, <8 x i16>* %882, align 16
  %884 = sub <8 x i16> %881, %883
  %885 = sub <8 x i16> zeroinitializer, %884
  %886 = icmp slt <8 x i16> %884, zeroinitializer
  %887 = select <8 x i1> %886, <8 x i16> %885, <8 x i16> %884
  %888 = lshr <8 x i16> %887, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %889 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %888, <8 x i16> zeroinitializer) #5
  %890 = lshr <8 x i16> %889, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %891 = getelementptr inbounds i16, i16* %10, i64 440
  %892 = bitcast i16* %891 to <8 x i16>*
  %893 = load <8 x i16>, <8 x i16>* %892, align 16
  %894 = getelementptr inbounds i16, i16* %11, i64 440
  %895 = bitcast i16* %894 to <8 x i16>*
  %896 = load <8 x i16>, <8 x i16>* %895, align 16
  %897 = sub <8 x i16> %893, %896
  %898 = sub <8 x i16> zeroinitializer, %897
  %899 = icmp slt <8 x i16> %897, zeroinitializer
  %900 = select <8 x i1> %899, <8 x i16> %898, <8 x i16> %897
  %901 = lshr <8 x i16> %900, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %902 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %901, <8 x i16> zeroinitializer) #5
  %903 = lshr <8 x i16> %902, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %904 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %890, <8 x i16> %903) #5
  %905 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %904, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %906 = icmp slt <16 x i8> %905, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %907 = select <16 x i1> %906, <16 x i8> %905, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %908 = bitcast i8* %879 to <16 x i8>*
  store <16 x i8> %907, <16 x i8>* %908, align 16
  %909 = getelementptr inbounds i16, i16* %10, i64 448
  %910 = getelementptr inbounds i16, i16* %11, i64 448
  %911 = getelementptr inbounds i8, i8* %780, i64 64
  %912 = bitcast i16* %909 to <8 x i16>*
  %913 = load <8 x i16>, <8 x i16>* %912, align 16
  %914 = bitcast i16* %910 to <8 x i16>*
  %915 = load <8 x i16>, <8 x i16>* %914, align 16
  %916 = sub <8 x i16> %913, %915
  %917 = sub <8 x i16> zeroinitializer, %916
  %918 = icmp slt <8 x i16> %916, zeroinitializer
  %919 = select <8 x i1> %918, <8 x i16> %917, <8 x i16> %916
  %920 = lshr <8 x i16> %919, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %921 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %920, <8 x i16> zeroinitializer) #5
  %922 = lshr <8 x i16> %921, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %923 = getelementptr inbounds i16, i16* %10, i64 456
  %924 = bitcast i16* %923 to <8 x i16>*
  %925 = load <8 x i16>, <8 x i16>* %924, align 16
  %926 = getelementptr inbounds i16, i16* %11, i64 456
  %927 = bitcast i16* %926 to <8 x i16>*
  %928 = load <8 x i16>, <8 x i16>* %927, align 16
  %929 = sub <8 x i16> %925, %928
  %930 = sub <8 x i16> zeroinitializer, %929
  %931 = icmp slt <8 x i16> %929, zeroinitializer
  %932 = select <8 x i1> %931, <8 x i16> %930, <8 x i16> %929
  %933 = lshr <8 x i16> %932, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %934 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %933, <8 x i16> zeroinitializer) #5
  %935 = lshr <8 x i16> %934, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %936 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %922, <8 x i16> %935) #5
  %937 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %936, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %938 = icmp slt <16 x i8> %937, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %939 = select <16 x i1> %938, <16 x i8> %937, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %940 = bitcast i8* %911 to <16 x i8>*
  store <16 x i8> %939, <16 x i8>* %940, align 16
  %941 = getelementptr inbounds i16, i16* %10, i64 464
  %942 = getelementptr inbounds i16, i16* %11, i64 464
  %943 = getelementptr inbounds i8, i8* %911, i64 16
  %944 = bitcast i16* %941 to <8 x i16>*
  %945 = load <8 x i16>, <8 x i16>* %944, align 16
  %946 = bitcast i16* %942 to <8 x i16>*
  %947 = load <8 x i16>, <8 x i16>* %946, align 16
  %948 = sub <8 x i16> %945, %947
  %949 = sub <8 x i16> zeroinitializer, %948
  %950 = icmp slt <8 x i16> %948, zeroinitializer
  %951 = select <8 x i1> %950, <8 x i16> %949, <8 x i16> %948
  %952 = lshr <8 x i16> %951, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %953 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %952, <8 x i16> zeroinitializer) #5
  %954 = lshr <8 x i16> %953, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %955 = getelementptr inbounds i16, i16* %10, i64 472
  %956 = bitcast i16* %955 to <8 x i16>*
  %957 = load <8 x i16>, <8 x i16>* %956, align 16
  %958 = getelementptr inbounds i16, i16* %11, i64 472
  %959 = bitcast i16* %958 to <8 x i16>*
  %960 = load <8 x i16>, <8 x i16>* %959, align 16
  %961 = sub <8 x i16> %957, %960
  %962 = sub <8 x i16> zeroinitializer, %961
  %963 = icmp slt <8 x i16> %961, zeroinitializer
  %964 = select <8 x i1> %963, <8 x i16> %962, <8 x i16> %961
  %965 = lshr <8 x i16> %964, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %966 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %965, <8 x i16> zeroinitializer) #5
  %967 = lshr <8 x i16> %966, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %968 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %954, <8 x i16> %967) #5
  %969 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %968, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %970 = icmp slt <16 x i8> %969, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %971 = select <16 x i1> %970, <16 x i8> %969, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %972 = bitcast i8* %943 to <16 x i8>*
  store <16 x i8> %971, <16 x i8>* %972, align 16
  %973 = getelementptr inbounds i16, i16* %10, i64 480
  %974 = getelementptr inbounds i16, i16* %11, i64 480
  %975 = getelementptr inbounds i8, i8* %911, i64 32
  %976 = bitcast i16* %973 to <8 x i16>*
  %977 = load <8 x i16>, <8 x i16>* %976, align 16
  %978 = bitcast i16* %974 to <8 x i16>*
  %979 = load <8 x i16>, <8 x i16>* %978, align 16
  %980 = sub <8 x i16> %977, %979
  %981 = sub <8 x i16> zeroinitializer, %980
  %982 = icmp slt <8 x i16> %980, zeroinitializer
  %983 = select <8 x i1> %982, <8 x i16> %981, <8 x i16> %980
  %984 = lshr <8 x i16> %983, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %985 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %984, <8 x i16> zeroinitializer) #5
  %986 = lshr <8 x i16> %985, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %987 = getelementptr inbounds i16, i16* %10, i64 488
  %988 = bitcast i16* %987 to <8 x i16>*
  %989 = load <8 x i16>, <8 x i16>* %988, align 16
  %990 = getelementptr inbounds i16, i16* %11, i64 488
  %991 = bitcast i16* %990 to <8 x i16>*
  %992 = load <8 x i16>, <8 x i16>* %991, align 16
  %993 = sub <8 x i16> %989, %992
  %994 = sub <8 x i16> zeroinitializer, %993
  %995 = icmp slt <8 x i16> %993, zeroinitializer
  %996 = select <8 x i1> %995, <8 x i16> %994, <8 x i16> %993
  %997 = lshr <8 x i16> %996, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %998 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %997, <8 x i16> zeroinitializer) #5
  %999 = lshr <8 x i16> %998, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1000 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %986, <8 x i16> %999) #5
  %1001 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1000, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1002 = icmp slt <16 x i8> %1001, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1003 = select <16 x i1> %1002, <16 x i8> %1001, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1004 = bitcast i8* %975 to <16 x i8>*
  store <16 x i8> %1003, <16 x i8>* %1004, align 16
  %1005 = getelementptr inbounds i16, i16* %10, i64 496
  %1006 = getelementptr inbounds i16, i16* %11, i64 496
  %1007 = getelementptr inbounds i8, i8* %911, i64 48
  %1008 = bitcast i16* %1005 to <8 x i16>*
  %1009 = load <8 x i16>, <8 x i16>* %1008, align 16
  %1010 = bitcast i16* %1006 to <8 x i16>*
  %1011 = load <8 x i16>, <8 x i16>* %1010, align 16
  %1012 = sub <8 x i16> %1009, %1011
  %1013 = sub <8 x i16> zeroinitializer, %1012
  %1014 = icmp slt <8 x i16> %1012, zeroinitializer
  %1015 = select <8 x i1> %1014, <8 x i16> %1013, <8 x i16> %1012
  %1016 = lshr <8 x i16> %1015, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1017 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1016, <8 x i16> zeroinitializer) #5
  %1018 = lshr <8 x i16> %1017, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1019 = getelementptr inbounds i16, i16* %10, i64 504
  %1020 = bitcast i16* %1019 to <8 x i16>*
  %1021 = load <8 x i16>, <8 x i16>* %1020, align 16
  %1022 = getelementptr inbounds i16, i16* %11, i64 504
  %1023 = bitcast i16* %1022 to <8 x i16>*
  %1024 = load <8 x i16>, <8 x i16>* %1023, align 16
  %1025 = sub <8 x i16> %1021, %1024
  %1026 = sub <8 x i16> zeroinitializer, %1025
  %1027 = icmp slt <8 x i16> %1025, zeroinitializer
  %1028 = select <8 x i1> %1027, <8 x i16> %1026, <8 x i16> %1025
  %1029 = lshr <8 x i16> %1028, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1030 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1029, <8 x i16> zeroinitializer) #5
  %1031 = lshr <8 x i16> %1030, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1032 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1018, <8 x i16> %1031) #5
  %1033 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1032, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1034 = icmp slt <16 x i8> %1033, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1035 = select <16 x i1> %1034, <16 x i8> %1033, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1036 = bitcast i8* %1007 to <16 x i8>*
  store <16 x i8> %1035, <16 x i8>* %1036, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_121WeightMask128x64_SSE4ILb1EEEvPKvS5_Phl(i8* readonly, i8* readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  %7 = add nsw i64 %3, -64
  br label %8

8:                                                ; preds = %8, %4
  %9 = phi i8* [ %2, %4 ], [ %804, %8 ]
  %10 = phi i16* [ %5, %4 ], [ %802, %8 ]
  %11 = phi i16* [ %6, %4 ], [ %803, %8 ]
  %12 = phi i32 [ 0, %4 ], [ %805, %8 ]
  %13 = bitcast i16* %10 to <8 x i16>*
  %14 = load <8 x i16>, <8 x i16>* %13, align 16
  %15 = bitcast i16* %11 to <8 x i16>*
  %16 = load <8 x i16>, <8 x i16>* %15, align 16
  %17 = sub <8 x i16> %14, %16
  %18 = sub <8 x i16> zeroinitializer, %17
  %19 = icmp slt <8 x i16> %17, zeroinitializer
  %20 = select <8 x i1> %19, <8 x i16> %18, <8 x i16> %17
  %21 = lshr <8 x i16> %20, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %22 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %21, <8 x i16> zeroinitializer) #5
  %23 = lshr <8 x i16> %22, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %24 = getelementptr inbounds i16, i16* %10, i64 8
  %25 = bitcast i16* %24 to <8 x i16>*
  %26 = load <8 x i16>, <8 x i16>* %25, align 16
  %27 = getelementptr inbounds i16, i16* %11, i64 8
  %28 = bitcast i16* %27 to <8 x i16>*
  %29 = load <8 x i16>, <8 x i16>* %28, align 16
  %30 = sub <8 x i16> %26, %29
  %31 = sub <8 x i16> zeroinitializer, %30
  %32 = icmp slt <8 x i16> %30, zeroinitializer
  %33 = select <8 x i1> %32, <8 x i16> %31, <8 x i16> %30
  %34 = lshr <8 x i16> %33, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %35 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %34, <8 x i16> zeroinitializer) #5
  %36 = lshr <8 x i16> %35, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %37 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %23, <8 x i16> %36) #5
  %38 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %37, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %39 = icmp slt <16 x i8> %38, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %40 = select <16 x i1> %39, <16 x i8> %38, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %41 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %40
  %42 = bitcast i8* %9 to <16 x i8>*
  store <16 x i8> %41, <16 x i8>* %42, align 16
  %43 = getelementptr inbounds i16, i16* %10, i64 16
  %44 = getelementptr inbounds i16, i16* %11, i64 16
  %45 = getelementptr inbounds i8, i8* %9, i64 16
  %46 = bitcast i16* %43 to <8 x i16>*
  %47 = load <8 x i16>, <8 x i16>* %46, align 16
  %48 = bitcast i16* %44 to <8 x i16>*
  %49 = load <8 x i16>, <8 x i16>* %48, align 16
  %50 = sub <8 x i16> %47, %49
  %51 = sub <8 x i16> zeroinitializer, %50
  %52 = icmp slt <8 x i16> %50, zeroinitializer
  %53 = select <8 x i1> %52, <8 x i16> %51, <8 x i16> %50
  %54 = lshr <8 x i16> %53, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %55 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %54, <8 x i16> zeroinitializer) #5
  %56 = lshr <8 x i16> %55, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %57 = getelementptr inbounds i16, i16* %10, i64 24
  %58 = bitcast i16* %57 to <8 x i16>*
  %59 = load <8 x i16>, <8 x i16>* %58, align 16
  %60 = getelementptr inbounds i16, i16* %11, i64 24
  %61 = bitcast i16* %60 to <8 x i16>*
  %62 = load <8 x i16>, <8 x i16>* %61, align 16
  %63 = sub <8 x i16> %59, %62
  %64 = sub <8 x i16> zeroinitializer, %63
  %65 = icmp slt <8 x i16> %63, zeroinitializer
  %66 = select <8 x i1> %65, <8 x i16> %64, <8 x i16> %63
  %67 = lshr <8 x i16> %66, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %68 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %67, <8 x i16> zeroinitializer) #5
  %69 = lshr <8 x i16> %68, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %70 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %56, <8 x i16> %69) #5
  %71 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %70, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %72 = icmp slt <16 x i8> %71, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %73 = select <16 x i1> %72, <16 x i8> %71, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %74 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %73
  %75 = bitcast i8* %45 to <16 x i8>*
  store <16 x i8> %74, <16 x i8>* %75, align 16
  %76 = getelementptr inbounds i16, i16* %10, i64 32
  %77 = getelementptr inbounds i16, i16* %11, i64 32
  %78 = getelementptr inbounds i8, i8* %9, i64 32
  %79 = bitcast i16* %76 to <8 x i16>*
  %80 = load <8 x i16>, <8 x i16>* %79, align 16
  %81 = bitcast i16* %77 to <8 x i16>*
  %82 = load <8 x i16>, <8 x i16>* %81, align 16
  %83 = sub <8 x i16> %80, %82
  %84 = sub <8 x i16> zeroinitializer, %83
  %85 = icmp slt <8 x i16> %83, zeroinitializer
  %86 = select <8 x i1> %85, <8 x i16> %84, <8 x i16> %83
  %87 = lshr <8 x i16> %86, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %88 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %87, <8 x i16> zeroinitializer) #5
  %89 = lshr <8 x i16> %88, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %90 = getelementptr inbounds i16, i16* %10, i64 40
  %91 = bitcast i16* %90 to <8 x i16>*
  %92 = load <8 x i16>, <8 x i16>* %91, align 16
  %93 = getelementptr inbounds i16, i16* %11, i64 40
  %94 = bitcast i16* %93 to <8 x i16>*
  %95 = load <8 x i16>, <8 x i16>* %94, align 16
  %96 = sub <8 x i16> %92, %95
  %97 = sub <8 x i16> zeroinitializer, %96
  %98 = icmp slt <8 x i16> %96, zeroinitializer
  %99 = select <8 x i1> %98, <8 x i16> %97, <8 x i16> %96
  %100 = lshr <8 x i16> %99, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %101 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %100, <8 x i16> zeroinitializer) #5
  %102 = lshr <8 x i16> %101, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %103 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %89, <8 x i16> %102) #5
  %104 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %103, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %105 = icmp slt <16 x i8> %104, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %106 = select <16 x i1> %105, <16 x i8> %104, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %107 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %106
  %108 = bitcast i8* %78 to <16 x i8>*
  store <16 x i8> %107, <16 x i8>* %108, align 16
  %109 = getelementptr inbounds i16, i16* %10, i64 48
  %110 = getelementptr inbounds i16, i16* %11, i64 48
  %111 = getelementptr inbounds i8, i8* %9, i64 48
  %112 = bitcast i16* %109 to <8 x i16>*
  %113 = load <8 x i16>, <8 x i16>* %112, align 16
  %114 = bitcast i16* %110 to <8 x i16>*
  %115 = load <8 x i16>, <8 x i16>* %114, align 16
  %116 = sub <8 x i16> %113, %115
  %117 = sub <8 x i16> zeroinitializer, %116
  %118 = icmp slt <8 x i16> %116, zeroinitializer
  %119 = select <8 x i1> %118, <8 x i16> %117, <8 x i16> %116
  %120 = lshr <8 x i16> %119, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %121 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %120, <8 x i16> zeroinitializer) #5
  %122 = lshr <8 x i16> %121, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %123 = getelementptr inbounds i16, i16* %10, i64 56
  %124 = bitcast i16* %123 to <8 x i16>*
  %125 = load <8 x i16>, <8 x i16>* %124, align 16
  %126 = getelementptr inbounds i16, i16* %11, i64 56
  %127 = bitcast i16* %126 to <8 x i16>*
  %128 = load <8 x i16>, <8 x i16>* %127, align 16
  %129 = sub <8 x i16> %125, %128
  %130 = sub <8 x i16> zeroinitializer, %129
  %131 = icmp slt <8 x i16> %129, zeroinitializer
  %132 = select <8 x i1> %131, <8 x i16> %130, <8 x i16> %129
  %133 = lshr <8 x i16> %132, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %134 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %133, <8 x i16> zeroinitializer) #5
  %135 = lshr <8 x i16> %134, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %136 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %122, <8 x i16> %135) #5
  %137 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %136, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %138 = icmp slt <16 x i8> %137, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %139 = select <16 x i1> %138, <16 x i8> %137, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %140 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %139
  %141 = bitcast i8* %111 to <16 x i8>*
  store <16 x i8> %140, <16 x i8>* %141, align 16
  %142 = getelementptr inbounds i16, i16* %10, i64 64
  %143 = getelementptr inbounds i16, i16* %11, i64 64
  %144 = getelementptr inbounds i8, i8* %9, i64 64
  %145 = bitcast i16* %142 to <8 x i16>*
  %146 = load <8 x i16>, <8 x i16>* %145, align 16
  %147 = bitcast i16* %143 to <8 x i16>*
  %148 = load <8 x i16>, <8 x i16>* %147, align 16
  %149 = sub <8 x i16> %146, %148
  %150 = sub <8 x i16> zeroinitializer, %149
  %151 = icmp slt <8 x i16> %149, zeroinitializer
  %152 = select <8 x i1> %151, <8 x i16> %150, <8 x i16> %149
  %153 = lshr <8 x i16> %152, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %154 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %153, <8 x i16> zeroinitializer) #5
  %155 = lshr <8 x i16> %154, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %156 = getelementptr inbounds i16, i16* %10, i64 72
  %157 = bitcast i16* %156 to <8 x i16>*
  %158 = load <8 x i16>, <8 x i16>* %157, align 16
  %159 = getelementptr inbounds i16, i16* %11, i64 72
  %160 = bitcast i16* %159 to <8 x i16>*
  %161 = load <8 x i16>, <8 x i16>* %160, align 16
  %162 = sub <8 x i16> %158, %161
  %163 = sub <8 x i16> zeroinitializer, %162
  %164 = icmp slt <8 x i16> %162, zeroinitializer
  %165 = select <8 x i1> %164, <8 x i16> %163, <8 x i16> %162
  %166 = lshr <8 x i16> %165, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %167 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %166, <8 x i16> zeroinitializer) #5
  %168 = lshr <8 x i16> %167, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %169 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %155, <8 x i16> %168) #5
  %170 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %169, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %171 = icmp slt <16 x i8> %170, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %172 = select <16 x i1> %171, <16 x i8> %170, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %173 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %172
  %174 = bitcast i8* %144 to <16 x i8>*
  store <16 x i8> %173, <16 x i8>* %174, align 16
  %175 = getelementptr inbounds i16, i16* %10, i64 80
  %176 = getelementptr inbounds i16, i16* %11, i64 80
  %177 = getelementptr inbounds i8, i8* %9, i64 80
  %178 = bitcast i16* %175 to <8 x i16>*
  %179 = load <8 x i16>, <8 x i16>* %178, align 16
  %180 = bitcast i16* %176 to <8 x i16>*
  %181 = load <8 x i16>, <8 x i16>* %180, align 16
  %182 = sub <8 x i16> %179, %181
  %183 = sub <8 x i16> zeroinitializer, %182
  %184 = icmp slt <8 x i16> %182, zeroinitializer
  %185 = select <8 x i1> %184, <8 x i16> %183, <8 x i16> %182
  %186 = lshr <8 x i16> %185, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %187 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %186, <8 x i16> zeroinitializer) #5
  %188 = lshr <8 x i16> %187, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %189 = getelementptr inbounds i16, i16* %10, i64 88
  %190 = bitcast i16* %189 to <8 x i16>*
  %191 = load <8 x i16>, <8 x i16>* %190, align 16
  %192 = getelementptr inbounds i16, i16* %11, i64 88
  %193 = bitcast i16* %192 to <8 x i16>*
  %194 = load <8 x i16>, <8 x i16>* %193, align 16
  %195 = sub <8 x i16> %191, %194
  %196 = sub <8 x i16> zeroinitializer, %195
  %197 = icmp slt <8 x i16> %195, zeroinitializer
  %198 = select <8 x i1> %197, <8 x i16> %196, <8 x i16> %195
  %199 = lshr <8 x i16> %198, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %200 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %199, <8 x i16> zeroinitializer) #5
  %201 = lshr <8 x i16> %200, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %202 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %188, <8 x i16> %201) #5
  %203 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %202, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %204 = icmp slt <16 x i8> %203, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %205 = select <16 x i1> %204, <16 x i8> %203, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %206 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %205
  %207 = bitcast i8* %177 to <16 x i8>*
  store <16 x i8> %206, <16 x i8>* %207, align 16
  %208 = getelementptr inbounds i16, i16* %10, i64 96
  %209 = getelementptr inbounds i16, i16* %11, i64 96
  %210 = getelementptr inbounds i8, i8* %9, i64 96
  %211 = bitcast i16* %208 to <8 x i16>*
  %212 = load <8 x i16>, <8 x i16>* %211, align 16
  %213 = bitcast i16* %209 to <8 x i16>*
  %214 = load <8 x i16>, <8 x i16>* %213, align 16
  %215 = sub <8 x i16> %212, %214
  %216 = sub <8 x i16> zeroinitializer, %215
  %217 = icmp slt <8 x i16> %215, zeroinitializer
  %218 = select <8 x i1> %217, <8 x i16> %216, <8 x i16> %215
  %219 = lshr <8 x i16> %218, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %220 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %219, <8 x i16> zeroinitializer) #5
  %221 = lshr <8 x i16> %220, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %222 = getelementptr inbounds i16, i16* %10, i64 104
  %223 = bitcast i16* %222 to <8 x i16>*
  %224 = load <8 x i16>, <8 x i16>* %223, align 16
  %225 = getelementptr inbounds i16, i16* %11, i64 104
  %226 = bitcast i16* %225 to <8 x i16>*
  %227 = load <8 x i16>, <8 x i16>* %226, align 16
  %228 = sub <8 x i16> %224, %227
  %229 = sub <8 x i16> zeroinitializer, %228
  %230 = icmp slt <8 x i16> %228, zeroinitializer
  %231 = select <8 x i1> %230, <8 x i16> %229, <8 x i16> %228
  %232 = lshr <8 x i16> %231, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %233 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %232, <8 x i16> zeroinitializer) #5
  %234 = lshr <8 x i16> %233, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %235 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %221, <8 x i16> %234) #5
  %236 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %235, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %237 = icmp slt <16 x i8> %236, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %238 = select <16 x i1> %237, <16 x i8> %236, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %239 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %238
  %240 = bitcast i8* %210 to <16 x i8>*
  store <16 x i8> %239, <16 x i8>* %240, align 16
  %241 = getelementptr inbounds i16, i16* %10, i64 112
  %242 = getelementptr inbounds i16, i16* %11, i64 112
  %243 = getelementptr inbounds i8, i8* %9, i64 112
  %244 = bitcast i16* %241 to <8 x i16>*
  %245 = load <8 x i16>, <8 x i16>* %244, align 16
  %246 = bitcast i16* %242 to <8 x i16>*
  %247 = load <8 x i16>, <8 x i16>* %246, align 16
  %248 = sub <8 x i16> %245, %247
  %249 = sub <8 x i16> zeroinitializer, %248
  %250 = icmp slt <8 x i16> %248, zeroinitializer
  %251 = select <8 x i1> %250, <8 x i16> %249, <8 x i16> %248
  %252 = lshr <8 x i16> %251, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %253 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %252, <8 x i16> zeroinitializer) #5
  %254 = lshr <8 x i16> %253, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %255 = getelementptr inbounds i16, i16* %10, i64 120
  %256 = bitcast i16* %255 to <8 x i16>*
  %257 = load <8 x i16>, <8 x i16>* %256, align 16
  %258 = getelementptr inbounds i16, i16* %11, i64 120
  %259 = bitcast i16* %258 to <8 x i16>*
  %260 = load <8 x i16>, <8 x i16>* %259, align 16
  %261 = sub <8 x i16> %257, %260
  %262 = sub <8 x i16> zeroinitializer, %261
  %263 = icmp slt <8 x i16> %261, zeroinitializer
  %264 = select <8 x i1> %263, <8 x i16> %262, <8 x i16> %261
  %265 = lshr <8 x i16> %264, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %266 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %265, <8 x i16> zeroinitializer) #5
  %267 = lshr <8 x i16> %266, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %268 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %254, <8 x i16> %267) #5
  %269 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %268, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %270 = icmp slt <16 x i8> %269, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %271 = select <16 x i1> %270, <16 x i8> %269, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %272 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %271
  %273 = bitcast i8* %243 to <16 x i8>*
  store <16 x i8> %272, <16 x i8>* %273, align 16
  %274 = getelementptr inbounds i16, i16* %10, i64 128
  %275 = getelementptr inbounds i16, i16* %11, i64 128
  %276 = getelementptr inbounds i8, i8* %9, i64 %3
  %277 = bitcast i16* %274 to <8 x i16>*
  %278 = load <8 x i16>, <8 x i16>* %277, align 16
  %279 = bitcast i16* %275 to <8 x i16>*
  %280 = load <8 x i16>, <8 x i16>* %279, align 16
  %281 = sub <8 x i16> %278, %280
  %282 = sub <8 x i16> zeroinitializer, %281
  %283 = icmp slt <8 x i16> %281, zeroinitializer
  %284 = select <8 x i1> %283, <8 x i16> %282, <8 x i16> %281
  %285 = lshr <8 x i16> %284, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %286 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %285, <8 x i16> zeroinitializer) #5
  %287 = lshr <8 x i16> %286, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %288 = getelementptr inbounds i16, i16* %10, i64 136
  %289 = bitcast i16* %288 to <8 x i16>*
  %290 = load <8 x i16>, <8 x i16>* %289, align 16
  %291 = getelementptr inbounds i16, i16* %11, i64 136
  %292 = bitcast i16* %291 to <8 x i16>*
  %293 = load <8 x i16>, <8 x i16>* %292, align 16
  %294 = sub <8 x i16> %290, %293
  %295 = sub <8 x i16> zeroinitializer, %294
  %296 = icmp slt <8 x i16> %294, zeroinitializer
  %297 = select <8 x i1> %296, <8 x i16> %295, <8 x i16> %294
  %298 = lshr <8 x i16> %297, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %299 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %298, <8 x i16> zeroinitializer) #5
  %300 = lshr <8 x i16> %299, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %301 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %287, <8 x i16> %300) #5
  %302 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %301, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %303 = icmp slt <16 x i8> %302, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %304 = select <16 x i1> %303, <16 x i8> %302, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %305 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %304
  %306 = bitcast i8* %276 to <16 x i8>*
  store <16 x i8> %305, <16 x i8>* %306, align 16
  %307 = getelementptr inbounds i16, i16* %10, i64 144
  %308 = getelementptr inbounds i16, i16* %11, i64 144
  %309 = getelementptr inbounds i8, i8* %276, i64 16
  %310 = bitcast i16* %307 to <8 x i16>*
  %311 = load <8 x i16>, <8 x i16>* %310, align 16
  %312 = bitcast i16* %308 to <8 x i16>*
  %313 = load <8 x i16>, <8 x i16>* %312, align 16
  %314 = sub <8 x i16> %311, %313
  %315 = sub <8 x i16> zeroinitializer, %314
  %316 = icmp slt <8 x i16> %314, zeroinitializer
  %317 = select <8 x i1> %316, <8 x i16> %315, <8 x i16> %314
  %318 = lshr <8 x i16> %317, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %319 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %318, <8 x i16> zeroinitializer) #5
  %320 = lshr <8 x i16> %319, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %321 = getelementptr inbounds i16, i16* %10, i64 152
  %322 = bitcast i16* %321 to <8 x i16>*
  %323 = load <8 x i16>, <8 x i16>* %322, align 16
  %324 = getelementptr inbounds i16, i16* %11, i64 152
  %325 = bitcast i16* %324 to <8 x i16>*
  %326 = load <8 x i16>, <8 x i16>* %325, align 16
  %327 = sub <8 x i16> %323, %326
  %328 = sub <8 x i16> zeroinitializer, %327
  %329 = icmp slt <8 x i16> %327, zeroinitializer
  %330 = select <8 x i1> %329, <8 x i16> %328, <8 x i16> %327
  %331 = lshr <8 x i16> %330, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %332 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %331, <8 x i16> zeroinitializer) #5
  %333 = lshr <8 x i16> %332, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %334 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %320, <8 x i16> %333) #5
  %335 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %334, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %336 = icmp slt <16 x i8> %335, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %337 = select <16 x i1> %336, <16 x i8> %335, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %338 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %337
  %339 = bitcast i8* %309 to <16 x i8>*
  store <16 x i8> %338, <16 x i8>* %339, align 16
  %340 = getelementptr inbounds i16, i16* %10, i64 160
  %341 = getelementptr inbounds i16, i16* %11, i64 160
  %342 = getelementptr inbounds i8, i8* %276, i64 32
  %343 = bitcast i16* %340 to <8 x i16>*
  %344 = load <8 x i16>, <8 x i16>* %343, align 16
  %345 = bitcast i16* %341 to <8 x i16>*
  %346 = load <8 x i16>, <8 x i16>* %345, align 16
  %347 = sub <8 x i16> %344, %346
  %348 = sub <8 x i16> zeroinitializer, %347
  %349 = icmp slt <8 x i16> %347, zeroinitializer
  %350 = select <8 x i1> %349, <8 x i16> %348, <8 x i16> %347
  %351 = lshr <8 x i16> %350, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %352 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %351, <8 x i16> zeroinitializer) #5
  %353 = lshr <8 x i16> %352, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %354 = getelementptr inbounds i16, i16* %10, i64 168
  %355 = bitcast i16* %354 to <8 x i16>*
  %356 = load <8 x i16>, <8 x i16>* %355, align 16
  %357 = getelementptr inbounds i16, i16* %11, i64 168
  %358 = bitcast i16* %357 to <8 x i16>*
  %359 = load <8 x i16>, <8 x i16>* %358, align 16
  %360 = sub <8 x i16> %356, %359
  %361 = sub <8 x i16> zeroinitializer, %360
  %362 = icmp slt <8 x i16> %360, zeroinitializer
  %363 = select <8 x i1> %362, <8 x i16> %361, <8 x i16> %360
  %364 = lshr <8 x i16> %363, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %365 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %364, <8 x i16> zeroinitializer) #5
  %366 = lshr <8 x i16> %365, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %367 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %353, <8 x i16> %366) #5
  %368 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %367, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %369 = icmp slt <16 x i8> %368, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %370 = select <16 x i1> %369, <16 x i8> %368, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %371 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %370
  %372 = bitcast i8* %342 to <16 x i8>*
  store <16 x i8> %371, <16 x i8>* %372, align 16
  %373 = getelementptr inbounds i16, i16* %10, i64 176
  %374 = getelementptr inbounds i16, i16* %11, i64 176
  %375 = getelementptr inbounds i8, i8* %276, i64 48
  %376 = bitcast i16* %373 to <8 x i16>*
  %377 = load <8 x i16>, <8 x i16>* %376, align 16
  %378 = bitcast i16* %374 to <8 x i16>*
  %379 = load <8 x i16>, <8 x i16>* %378, align 16
  %380 = sub <8 x i16> %377, %379
  %381 = sub <8 x i16> zeroinitializer, %380
  %382 = icmp slt <8 x i16> %380, zeroinitializer
  %383 = select <8 x i1> %382, <8 x i16> %381, <8 x i16> %380
  %384 = lshr <8 x i16> %383, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %385 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %384, <8 x i16> zeroinitializer) #5
  %386 = lshr <8 x i16> %385, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %387 = getelementptr inbounds i16, i16* %10, i64 184
  %388 = bitcast i16* %387 to <8 x i16>*
  %389 = load <8 x i16>, <8 x i16>* %388, align 16
  %390 = getelementptr inbounds i16, i16* %11, i64 184
  %391 = bitcast i16* %390 to <8 x i16>*
  %392 = load <8 x i16>, <8 x i16>* %391, align 16
  %393 = sub <8 x i16> %389, %392
  %394 = sub <8 x i16> zeroinitializer, %393
  %395 = icmp slt <8 x i16> %393, zeroinitializer
  %396 = select <8 x i1> %395, <8 x i16> %394, <8 x i16> %393
  %397 = lshr <8 x i16> %396, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %398 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %397, <8 x i16> zeroinitializer) #5
  %399 = lshr <8 x i16> %398, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %400 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %386, <8 x i16> %399) #5
  %401 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %400, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %402 = icmp slt <16 x i8> %401, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %403 = select <16 x i1> %402, <16 x i8> %401, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %404 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %403
  %405 = bitcast i8* %375 to <16 x i8>*
  store <16 x i8> %404, <16 x i8>* %405, align 16
  %406 = getelementptr inbounds i16, i16* %10, i64 192
  %407 = getelementptr inbounds i16, i16* %11, i64 192
  %408 = getelementptr inbounds i8, i8* %276, i64 64
  %409 = bitcast i16* %406 to <8 x i16>*
  %410 = load <8 x i16>, <8 x i16>* %409, align 16
  %411 = bitcast i16* %407 to <8 x i16>*
  %412 = load <8 x i16>, <8 x i16>* %411, align 16
  %413 = sub <8 x i16> %410, %412
  %414 = sub <8 x i16> zeroinitializer, %413
  %415 = icmp slt <8 x i16> %413, zeroinitializer
  %416 = select <8 x i1> %415, <8 x i16> %414, <8 x i16> %413
  %417 = lshr <8 x i16> %416, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %418 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %417, <8 x i16> zeroinitializer) #5
  %419 = lshr <8 x i16> %418, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %420 = getelementptr inbounds i16, i16* %10, i64 200
  %421 = bitcast i16* %420 to <8 x i16>*
  %422 = load <8 x i16>, <8 x i16>* %421, align 16
  %423 = getelementptr inbounds i16, i16* %11, i64 200
  %424 = bitcast i16* %423 to <8 x i16>*
  %425 = load <8 x i16>, <8 x i16>* %424, align 16
  %426 = sub <8 x i16> %422, %425
  %427 = sub <8 x i16> zeroinitializer, %426
  %428 = icmp slt <8 x i16> %426, zeroinitializer
  %429 = select <8 x i1> %428, <8 x i16> %427, <8 x i16> %426
  %430 = lshr <8 x i16> %429, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %431 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %430, <8 x i16> zeroinitializer) #5
  %432 = lshr <8 x i16> %431, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %433 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %419, <8 x i16> %432) #5
  %434 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %433, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %435 = icmp slt <16 x i8> %434, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %436 = select <16 x i1> %435, <16 x i8> %434, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %437 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %436
  %438 = bitcast i8* %408 to <16 x i8>*
  store <16 x i8> %437, <16 x i8>* %438, align 16
  %439 = getelementptr inbounds i16, i16* %10, i64 208
  %440 = getelementptr inbounds i16, i16* %11, i64 208
  %441 = getelementptr inbounds i8, i8* %408, i64 16
  %442 = bitcast i16* %439 to <8 x i16>*
  %443 = load <8 x i16>, <8 x i16>* %442, align 16
  %444 = bitcast i16* %440 to <8 x i16>*
  %445 = load <8 x i16>, <8 x i16>* %444, align 16
  %446 = sub <8 x i16> %443, %445
  %447 = sub <8 x i16> zeroinitializer, %446
  %448 = icmp slt <8 x i16> %446, zeroinitializer
  %449 = select <8 x i1> %448, <8 x i16> %447, <8 x i16> %446
  %450 = lshr <8 x i16> %449, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %451 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %450, <8 x i16> zeroinitializer) #5
  %452 = lshr <8 x i16> %451, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %453 = getelementptr inbounds i16, i16* %10, i64 216
  %454 = bitcast i16* %453 to <8 x i16>*
  %455 = load <8 x i16>, <8 x i16>* %454, align 16
  %456 = getelementptr inbounds i16, i16* %11, i64 216
  %457 = bitcast i16* %456 to <8 x i16>*
  %458 = load <8 x i16>, <8 x i16>* %457, align 16
  %459 = sub <8 x i16> %455, %458
  %460 = sub <8 x i16> zeroinitializer, %459
  %461 = icmp slt <8 x i16> %459, zeroinitializer
  %462 = select <8 x i1> %461, <8 x i16> %460, <8 x i16> %459
  %463 = lshr <8 x i16> %462, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %464 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %463, <8 x i16> zeroinitializer) #5
  %465 = lshr <8 x i16> %464, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %466 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %452, <8 x i16> %465) #5
  %467 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %466, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %468 = icmp slt <16 x i8> %467, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %469 = select <16 x i1> %468, <16 x i8> %467, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %470 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %469
  %471 = bitcast i8* %441 to <16 x i8>*
  store <16 x i8> %470, <16 x i8>* %471, align 16
  %472 = getelementptr inbounds i16, i16* %10, i64 224
  %473 = getelementptr inbounds i16, i16* %11, i64 224
  %474 = getelementptr inbounds i8, i8* %408, i64 32
  %475 = bitcast i16* %472 to <8 x i16>*
  %476 = load <8 x i16>, <8 x i16>* %475, align 16
  %477 = bitcast i16* %473 to <8 x i16>*
  %478 = load <8 x i16>, <8 x i16>* %477, align 16
  %479 = sub <8 x i16> %476, %478
  %480 = sub <8 x i16> zeroinitializer, %479
  %481 = icmp slt <8 x i16> %479, zeroinitializer
  %482 = select <8 x i1> %481, <8 x i16> %480, <8 x i16> %479
  %483 = lshr <8 x i16> %482, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %484 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %483, <8 x i16> zeroinitializer) #5
  %485 = lshr <8 x i16> %484, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %486 = getelementptr inbounds i16, i16* %10, i64 232
  %487 = bitcast i16* %486 to <8 x i16>*
  %488 = load <8 x i16>, <8 x i16>* %487, align 16
  %489 = getelementptr inbounds i16, i16* %11, i64 232
  %490 = bitcast i16* %489 to <8 x i16>*
  %491 = load <8 x i16>, <8 x i16>* %490, align 16
  %492 = sub <8 x i16> %488, %491
  %493 = sub <8 x i16> zeroinitializer, %492
  %494 = icmp slt <8 x i16> %492, zeroinitializer
  %495 = select <8 x i1> %494, <8 x i16> %493, <8 x i16> %492
  %496 = lshr <8 x i16> %495, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %497 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %496, <8 x i16> zeroinitializer) #5
  %498 = lshr <8 x i16> %497, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %499 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %485, <8 x i16> %498) #5
  %500 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %499, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %501 = icmp slt <16 x i8> %500, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %502 = select <16 x i1> %501, <16 x i8> %500, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %503 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %502
  %504 = bitcast i8* %474 to <16 x i8>*
  store <16 x i8> %503, <16 x i8>* %504, align 16
  %505 = getelementptr inbounds i16, i16* %10, i64 240
  %506 = getelementptr inbounds i16, i16* %11, i64 240
  %507 = getelementptr inbounds i8, i8* %408, i64 48
  %508 = bitcast i16* %505 to <8 x i16>*
  %509 = load <8 x i16>, <8 x i16>* %508, align 16
  %510 = bitcast i16* %506 to <8 x i16>*
  %511 = load <8 x i16>, <8 x i16>* %510, align 16
  %512 = sub <8 x i16> %509, %511
  %513 = sub <8 x i16> zeroinitializer, %512
  %514 = icmp slt <8 x i16> %512, zeroinitializer
  %515 = select <8 x i1> %514, <8 x i16> %513, <8 x i16> %512
  %516 = lshr <8 x i16> %515, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %517 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %516, <8 x i16> zeroinitializer) #5
  %518 = lshr <8 x i16> %517, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %519 = getelementptr inbounds i16, i16* %10, i64 248
  %520 = bitcast i16* %519 to <8 x i16>*
  %521 = load <8 x i16>, <8 x i16>* %520, align 16
  %522 = getelementptr inbounds i16, i16* %11, i64 248
  %523 = bitcast i16* %522 to <8 x i16>*
  %524 = load <8 x i16>, <8 x i16>* %523, align 16
  %525 = sub <8 x i16> %521, %524
  %526 = sub <8 x i16> zeroinitializer, %525
  %527 = icmp slt <8 x i16> %525, zeroinitializer
  %528 = select <8 x i1> %527, <8 x i16> %526, <8 x i16> %525
  %529 = lshr <8 x i16> %528, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %530 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %529, <8 x i16> zeroinitializer) #5
  %531 = lshr <8 x i16> %530, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %532 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %518, <8 x i16> %531) #5
  %533 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %532, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %534 = icmp slt <16 x i8> %533, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %535 = select <16 x i1> %534, <16 x i8> %533, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %536 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %535
  %537 = bitcast i8* %507 to <16 x i8>*
  store <16 x i8> %536, <16 x i8>* %537, align 16
  %538 = getelementptr inbounds i16, i16* %10, i64 256
  %539 = getelementptr inbounds i16, i16* %11, i64 256
  %540 = getelementptr inbounds i8, i8* %408, i64 %7
  %541 = bitcast i16* %538 to <8 x i16>*
  %542 = load <8 x i16>, <8 x i16>* %541, align 16
  %543 = bitcast i16* %539 to <8 x i16>*
  %544 = load <8 x i16>, <8 x i16>* %543, align 16
  %545 = sub <8 x i16> %542, %544
  %546 = sub <8 x i16> zeroinitializer, %545
  %547 = icmp slt <8 x i16> %545, zeroinitializer
  %548 = select <8 x i1> %547, <8 x i16> %546, <8 x i16> %545
  %549 = lshr <8 x i16> %548, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %550 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %549, <8 x i16> zeroinitializer) #5
  %551 = lshr <8 x i16> %550, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %552 = getelementptr inbounds i16, i16* %10, i64 264
  %553 = bitcast i16* %552 to <8 x i16>*
  %554 = load <8 x i16>, <8 x i16>* %553, align 16
  %555 = getelementptr inbounds i16, i16* %11, i64 264
  %556 = bitcast i16* %555 to <8 x i16>*
  %557 = load <8 x i16>, <8 x i16>* %556, align 16
  %558 = sub <8 x i16> %554, %557
  %559 = sub <8 x i16> zeroinitializer, %558
  %560 = icmp slt <8 x i16> %558, zeroinitializer
  %561 = select <8 x i1> %560, <8 x i16> %559, <8 x i16> %558
  %562 = lshr <8 x i16> %561, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %563 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %562, <8 x i16> zeroinitializer) #5
  %564 = lshr <8 x i16> %563, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %565 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %551, <8 x i16> %564) #5
  %566 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %565, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %567 = icmp slt <16 x i8> %566, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %568 = select <16 x i1> %567, <16 x i8> %566, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %569 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %568
  %570 = bitcast i8* %540 to <16 x i8>*
  store <16 x i8> %569, <16 x i8>* %570, align 16
  %571 = getelementptr inbounds i16, i16* %10, i64 272
  %572 = getelementptr inbounds i16, i16* %11, i64 272
  %573 = getelementptr inbounds i8, i8* %540, i64 16
  %574 = bitcast i16* %571 to <8 x i16>*
  %575 = load <8 x i16>, <8 x i16>* %574, align 16
  %576 = bitcast i16* %572 to <8 x i16>*
  %577 = load <8 x i16>, <8 x i16>* %576, align 16
  %578 = sub <8 x i16> %575, %577
  %579 = sub <8 x i16> zeroinitializer, %578
  %580 = icmp slt <8 x i16> %578, zeroinitializer
  %581 = select <8 x i1> %580, <8 x i16> %579, <8 x i16> %578
  %582 = lshr <8 x i16> %581, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %583 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %582, <8 x i16> zeroinitializer) #5
  %584 = lshr <8 x i16> %583, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %585 = getelementptr inbounds i16, i16* %10, i64 280
  %586 = bitcast i16* %585 to <8 x i16>*
  %587 = load <8 x i16>, <8 x i16>* %586, align 16
  %588 = getelementptr inbounds i16, i16* %11, i64 280
  %589 = bitcast i16* %588 to <8 x i16>*
  %590 = load <8 x i16>, <8 x i16>* %589, align 16
  %591 = sub <8 x i16> %587, %590
  %592 = sub <8 x i16> zeroinitializer, %591
  %593 = icmp slt <8 x i16> %591, zeroinitializer
  %594 = select <8 x i1> %593, <8 x i16> %592, <8 x i16> %591
  %595 = lshr <8 x i16> %594, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %596 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %595, <8 x i16> zeroinitializer) #5
  %597 = lshr <8 x i16> %596, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %598 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %584, <8 x i16> %597) #5
  %599 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %598, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %600 = icmp slt <16 x i8> %599, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %601 = select <16 x i1> %600, <16 x i8> %599, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %602 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %601
  %603 = bitcast i8* %573 to <16 x i8>*
  store <16 x i8> %602, <16 x i8>* %603, align 16
  %604 = getelementptr inbounds i16, i16* %10, i64 288
  %605 = getelementptr inbounds i16, i16* %11, i64 288
  %606 = getelementptr inbounds i8, i8* %540, i64 32
  %607 = bitcast i16* %604 to <8 x i16>*
  %608 = load <8 x i16>, <8 x i16>* %607, align 16
  %609 = bitcast i16* %605 to <8 x i16>*
  %610 = load <8 x i16>, <8 x i16>* %609, align 16
  %611 = sub <8 x i16> %608, %610
  %612 = sub <8 x i16> zeroinitializer, %611
  %613 = icmp slt <8 x i16> %611, zeroinitializer
  %614 = select <8 x i1> %613, <8 x i16> %612, <8 x i16> %611
  %615 = lshr <8 x i16> %614, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %616 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %615, <8 x i16> zeroinitializer) #5
  %617 = lshr <8 x i16> %616, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %618 = getelementptr inbounds i16, i16* %10, i64 296
  %619 = bitcast i16* %618 to <8 x i16>*
  %620 = load <8 x i16>, <8 x i16>* %619, align 16
  %621 = getelementptr inbounds i16, i16* %11, i64 296
  %622 = bitcast i16* %621 to <8 x i16>*
  %623 = load <8 x i16>, <8 x i16>* %622, align 16
  %624 = sub <8 x i16> %620, %623
  %625 = sub <8 x i16> zeroinitializer, %624
  %626 = icmp slt <8 x i16> %624, zeroinitializer
  %627 = select <8 x i1> %626, <8 x i16> %625, <8 x i16> %624
  %628 = lshr <8 x i16> %627, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %629 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %628, <8 x i16> zeroinitializer) #5
  %630 = lshr <8 x i16> %629, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %631 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %617, <8 x i16> %630) #5
  %632 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %631, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %633 = icmp slt <16 x i8> %632, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %634 = select <16 x i1> %633, <16 x i8> %632, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %635 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %634
  %636 = bitcast i8* %606 to <16 x i8>*
  store <16 x i8> %635, <16 x i8>* %636, align 16
  %637 = getelementptr inbounds i16, i16* %10, i64 304
  %638 = getelementptr inbounds i16, i16* %11, i64 304
  %639 = getelementptr inbounds i8, i8* %540, i64 48
  %640 = bitcast i16* %637 to <8 x i16>*
  %641 = load <8 x i16>, <8 x i16>* %640, align 16
  %642 = bitcast i16* %638 to <8 x i16>*
  %643 = load <8 x i16>, <8 x i16>* %642, align 16
  %644 = sub <8 x i16> %641, %643
  %645 = sub <8 x i16> zeroinitializer, %644
  %646 = icmp slt <8 x i16> %644, zeroinitializer
  %647 = select <8 x i1> %646, <8 x i16> %645, <8 x i16> %644
  %648 = lshr <8 x i16> %647, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %649 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %648, <8 x i16> zeroinitializer) #5
  %650 = lshr <8 x i16> %649, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %651 = getelementptr inbounds i16, i16* %10, i64 312
  %652 = bitcast i16* %651 to <8 x i16>*
  %653 = load <8 x i16>, <8 x i16>* %652, align 16
  %654 = getelementptr inbounds i16, i16* %11, i64 312
  %655 = bitcast i16* %654 to <8 x i16>*
  %656 = load <8 x i16>, <8 x i16>* %655, align 16
  %657 = sub <8 x i16> %653, %656
  %658 = sub <8 x i16> zeroinitializer, %657
  %659 = icmp slt <8 x i16> %657, zeroinitializer
  %660 = select <8 x i1> %659, <8 x i16> %658, <8 x i16> %657
  %661 = lshr <8 x i16> %660, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %662 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %661, <8 x i16> zeroinitializer) #5
  %663 = lshr <8 x i16> %662, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %664 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %650, <8 x i16> %663) #5
  %665 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %664, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %666 = icmp slt <16 x i8> %665, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %667 = select <16 x i1> %666, <16 x i8> %665, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %668 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %667
  %669 = bitcast i8* %639 to <16 x i8>*
  store <16 x i8> %668, <16 x i8>* %669, align 16
  %670 = getelementptr inbounds i16, i16* %10, i64 320
  %671 = getelementptr inbounds i16, i16* %11, i64 320
  %672 = getelementptr inbounds i8, i8* %540, i64 64
  %673 = bitcast i16* %670 to <8 x i16>*
  %674 = load <8 x i16>, <8 x i16>* %673, align 16
  %675 = bitcast i16* %671 to <8 x i16>*
  %676 = load <8 x i16>, <8 x i16>* %675, align 16
  %677 = sub <8 x i16> %674, %676
  %678 = sub <8 x i16> zeroinitializer, %677
  %679 = icmp slt <8 x i16> %677, zeroinitializer
  %680 = select <8 x i1> %679, <8 x i16> %678, <8 x i16> %677
  %681 = lshr <8 x i16> %680, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %682 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %681, <8 x i16> zeroinitializer) #5
  %683 = lshr <8 x i16> %682, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %684 = getelementptr inbounds i16, i16* %10, i64 328
  %685 = bitcast i16* %684 to <8 x i16>*
  %686 = load <8 x i16>, <8 x i16>* %685, align 16
  %687 = getelementptr inbounds i16, i16* %11, i64 328
  %688 = bitcast i16* %687 to <8 x i16>*
  %689 = load <8 x i16>, <8 x i16>* %688, align 16
  %690 = sub <8 x i16> %686, %689
  %691 = sub <8 x i16> zeroinitializer, %690
  %692 = icmp slt <8 x i16> %690, zeroinitializer
  %693 = select <8 x i1> %692, <8 x i16> %691, <8 x i16> %690
  %694 = lshr <8 x i16> %693, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %695 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %694, <8 x i16> zeroinitializer) #5
  %696 = lshr <8 x i16> %695, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %697 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %683, <8 x i16> %696) #5
  %698 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %697, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %699 = icmp slt <16 x i8> %698, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %700 = select <16 x i1> %699, <16 x i8> %698, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %701 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %700
  %702 = bitcast i8* %672 to <16 x i8>*
  store <16 x i8> %701, <16 x i8>* %702, align 16
  %703 = getelementptr inbounds i16, i16* %10, i64 336
  %704 = getelementptr inbounds i16, i16* %11, i64 336
  %705 = getelementptr inbounds i8, i8* %672, i64 16
  %706 = bitcast i16* %703 to <8 x i16>*
  %707 = load <8 x i16>, <8 x i16>* %706, align 16
  %708 = bitcast i16* %704 to <8 x i16>*
  %709 = load <8 x i16>, <8 x i16>* %708, align 16
  %710 = sub <8 x i16> %707, %709
  %711 = sub <8 x i16> zeroinitializer, %710
  %712 = icmp slt <8 x i16> %710, zeroinitializer
  %713 = select <8 x i1> %712, <8 x i16> %711, <8 x i16> %710
  %714 = lshr <8 x i16> %713, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %715 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %714, <8 x i16> zeroinitializer) #5
  %716 = lshr <8 x i16> %715, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %717 = getelementptr inbounds i16, i16* %10, i64 344
  %718 = bitcast i16* %717 to <8 x i16>*
  %719 = load <8 x i16>, <8 x i16>* %718, align 16
  %720 = getelementptr inbounds i16, i16* %11, i64 344
  %721 = bitcast i16* %720 to <8 x i16>*
  %722 = load <8 x i16>, <8 x i16>* %721, align 16
  %723 = sub <8 x i16> %719, %722
  %724 = sub <8 x i16> zeroinitializer, %723
  %725 = icmp slt <8 x i16> %723, zeroinitializer
  %726 = select <8 x i1> %725, <8 x i16> %724, <8 x i16> %723
  %727 = lshr <8 x i16> %726, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %728 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %727, <8 x i16> zeroinitializer) #5
  %729 = lshr <8 x i16> %728, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %730 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %716, <8 x i16> %729) #5
  %731 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %730, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %732 = icmp slt <16 x i8> %731, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %733 = select <16 x i1> %732, <16 x i8> %731, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %734 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %733
  %735 = bitcast i8* %705 to <16 x i8>*
  store <16 x i8> %734, <16 x i8>* %735, align 16
  %736 = getelementptr inbounds i16, i16* %10, i64 352
  %737 = getelementptr inbounds i16, i16* %11, i64 352
  %738 = getelementptr inbounds i8, i8* %672, i64 32
  %739 = bitcast i16* %736 to <8 x i16>*
  %740 = load <8 x i16>, <8 x i16>* %739, align 16
  %741 = bitcast i16* %737 to <8 x i16>*
  %742 = load <8 x i16>, <8 x i16>* %741, align 16
  %743 = sub <8 x i16> %740, %742
  %744 = sub <8 x i16> zeroinitializer, %743
  %745 = icmp slt <8 x i16> %743, zeroinitializer
  %746 = select <8 x i1> %745, <8 x i16> %744, <8 x i16> %743
  %747 = lshr <8 x i16> %746, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %748 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %747, <8 x i16> zeroinitializer) #5
  %749 = lshr <8 x i16> %748, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %750 = getelementptr inbounds i16, i16* %10, i64 360
  %751 = bitcast i16* %750 to <8 x i16>*
  %752 = load <8 x i16>, <8 x i16>* %751, align 16
  %753 = getelementptr inbounds i16, i16* %11, i64 360
  %754 = bitcast i16* %753 to <8 x i16>*
  %755 = load <8 x i16>, <8 x i16>* %754, align 16
  %756 = sub <8 x i16> %752, %755
  %757 = sub <8 x i16> zeroinitializer, %756
  %758 = icmp slt <8 x i16> %756, zeroinitializer
  %759 = select <8 x i1> %758, <8 x i16> %757, <8 x i16> %756
  %760 = lshr <8 x i16> %759, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %761 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %760, <8 x i16> zeroinitializer) #5
  %762 = lshr <8 x i16> %761, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %763 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %749, <8 x i16> %762) #5
  %764 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %763, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %765 = icmp slt <16 x i8> %764, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %766 = select <16 x i1> %765, <16 x i8> %764, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %767 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %766
  %768 = bitcast i8* %738 to <16 x i8>*
  store <16 x i8> %767, <16 x i8>* %768, align 16
  %769 = getelementptr inbounds i16, i16* %10, i64 368
  %770 = getelementptr inbounds i16, i16* %11, i64 368
  %771 = getelementptr inbounds i8, i8* %672, i64 48
  %772 = bitcast i16* %769 to <8 x i16>*
  %773 = load <8 x i16>, <8 x i16>* %772, align 16
  %774 = bitcast i16* %770 to <8 x i16>*
  %775 = load <8 x i16>, <8 x i16>* %774, align 16
  %776 = sub <8 x i16> %773, %775
  %777 = sub <8 x i16> zeroinitializer, %776
  %778 = icmp slt <8 x i16> %776, zeroinitializer
  %779 = select <8 x i1> %778, <8 x i16> %777, <8 x i16> %776
  %780 = lshr <8 x i16> %779, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %781 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %780, <8 x i16> zeroinitializer) #5
  %782 = lshr <8 x i16> %781, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %783 = getelementptr inbounds i16, i16* %10, i64 376
  %784 = bitcast i16* %783 to <8 x i16>*
  %785 = load <8 x i16>, <8 x i16>* %784, align 16
  %786 = getelementptr inbounds i16, i16* %11, i64 376
  %787 = bitcast i16* %786 to <8 x i16>*
  %788 = load <8 x i16>, <8 x i16>* %787, align 16
  %789 = sub <8 x i16> %785, %788
  %790 = sub <8 x i16> zeroinitializer, %789
  %791 = icmp slt <8 x i16> %789, zeroinitializer
  %792 = select <8 x i1> %791, <8 x i16> %790, <8 x i16> %789
  %793 = lshr <8 x i16> %792, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %794 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %793, <8 x i16> zeroinitializer) #5
  %795 = lshr <8 x i16> %794, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %796 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %782, <8 x i16> %795) #5
  %797 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %796, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %798 = icmp slt <16 x i8> %797, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %799 = select <16 x i1> %798, <16 x i8> %797, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %800 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %799
  %801 = bitcast i8* %771 to <16 x i8>*
  store <16 x i8> %800, <16 x i8>* %801, align 16
  %802 = getelementptr inbounds i16, i16* %10, i64 384
  %803 = getelementptr inbounds i16, i16* %11, i64 384
  %804 = getelementptr inbounds i8, i8* %672, i64 %7
  %805 = add nuw nsw i32 %12, 1
  %806 = icmp eq i32 %805, 21
  br i1 %806, label %807, label %8

807:                                              ; preds = %8
  %808 = bitcast i16* %802 to <8 x i16>*
  %809 = load <8 x i16>, <8 x i16>* %808, align 16
  %810 = bitcast i16* %803 to <8 x i16>*
  %811 = load <8 x i16>, <8 x i16>* %810, align 16
  %812 = sub <8 x i16> %809, %811
  %813 = sub <8 x i16> zeroinitializer, %812
  %814 = icmp slt <8 x i16> %812, zeroinitializer
  %815 = select <8 x i1> %814, <8 x i16> %813, <8 x i16> %812
  %816 = lshr <8 x i16> %815, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %817 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %816, <8 x i16> zeroinitializer) #5
  %818 = lshr <8 x i16> %817, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %819 = getelementptr inbounds i16, i16* %10, i64 392
  %820 = bitcast i16* %819 to <8 x i16>*
  %821 = load <8 x i16>, <8 x i16>* %820, align 16
  %822 = getelementptr inbounds i16, i16* %11, i64 392
  %823 = bitcast i16* %822 to <8 x i16>*
  %824 = load <8 x i16>, <8 x i16>* %823, align 16
  %825 = sub <8 x i16> %821, %824
  %826 = sub <8 x i16> zeroinitializer, %825
  %827 = icmp slt <8 x i16> %825, zeroinitializer
  %828 = select <8 x i1> %827, <8 x i16> %826, <8 x i16> %825
  %829 = lshr <8 x i16> %828, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %830 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %829, <8 x i16> zeroinitializer) #5
  %831 = lshr <8 x i16> %830, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %832 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %818, <8 x i16> %831) #5
  %833 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %832, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %834 = icmp slt <16 x i8> %833, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %835 = select <16 x i1> %834, <16 x i8> %833, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %836 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %835
  %837 = bitcast i8* %804 to <16 x i8>*
  store <16 x i8> %836, <16 x i8>* %837, align 16
  %838 = getelementptr inbounds i16, i16* %10, i64 400
  %839 = getelementptr inbounds i16, i16* %11, i64 400
  %840 = getelementptr inbounds i8, i8* %804, i64 16
  %841 = bitcast i16* %838 to <8 x i16>*
  %842 = load <8 x i16>, <8 x i16>* %841, align 16
  %843 = bitcast i16* %839 to <8 x i16>*
  %844 = load <8 x i16>, <8 x i16>* %843, align 16
  %845 = sub <8 x i16> %842, %844
  %846 = sub <8 x i16> zeroinitializer, %845
  %847 = icmp slt <8 x i16> %845, zeroinitializer
  %848 = select <8 x i1> %847, <8 x i16> %846, <8 x i16> %845
  %849 = lshr <8 x i16> %848, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %850 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %849, <8 x i16> zeroinitializer) #5
  %851 = lshr <8 x i16> %850, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %852 = getelementptr inbounds i16, i16* %10, i64 408
  %853 = bitcast i16* %852 to <8 x i16>*
  %854 = load <8 x i16>, <8 x i16>* %853, align 16
  %855 = getelementptr inbounds i16, i16* %11, i64 408
  %856 = bitcast i16* %855 to <8 x i16>*
  %857 = load <8 x i16>, <8 x i16>* %856, align 16
  %858 = sub <8 x i16> %854, %857
  %859 = sub <8 x i16> zeroinitializer, %858
  %860 = icmp slt <8 x i16> %858, zeroinitializer
  %861 = select <8 x i1> %860, <8 x i16> %859, <8 x i16> %858
  %862 = lshr <8 x i16> %861, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %863 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %862, <8 x i16> zeroinitializer) #5
  %864 = lshr <8 x i16> %863, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %865 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %851, <8 x i16> %864) #5
  %866 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %865, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %867 = icmp slt <16 x i8> %866, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %868 = select <16 x i1> %867, <16 x i8> %866, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %869 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %868
  %870 = bitcast i8* %840 to <16 x i8>*
  store <16 x i8> %869, <16 x i8>* %870, align 16
  %871 = getelementptr inbounds i16, i16* %10, i64 416
  %872 = getelementptr inbounds i16, i16* %11, i64 416
  %873 = getelementptr inbounds i8, i8* %804, i64 32
  %874 = bitcast i16* %871 to <8 x i16>*
  %875 = load <8 x i16>, <8 x i16>* %874, align 16
  %876 = bitcast i16* %872 to <8 x i16>*
  %877 = load <8 x i16>, <8 x i16>* %876, align 16
  %878 = sub <8 x i16> %875, %877
  %879 = sub <8 x i16> zeroinitializer, %878
  %880 = icmp slt <8 x i16> %878, zeroinitializer
  %881 = select <8 x i1> %880, <8 x i16> %879, <8 x i16> %878
  %882 = lshr <8 x i16> %881, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %883 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %882, <8 x i16> zeroinitializer) #5
  %884 = lshr <8 x i16> %883, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %885 = getelementptr inbounds i16, i16* %10, i64 424
  %886 = bitcast i16* %885 to <8 x i16>*
  %887 = load <8 x i16>, <8 x i16>* %886, align 16
  %888 = getelementptr inbounds i16, i16* %11, i64 424
  %889 = bitcast i16* %888 to <8 x i16>*
  %890 = load <8 x i16>, <8 x i16>* %889, align 16
  %891 = sub <8 x i16> %887, %890
  %892 = sub <8 x i16> zeroinitializer, %891
  %893 = icmp slt <8 x i16> %891, zeroinitializer
  %894 = select <8 x i1> %893, <8 x i16> %892, <8 x i16> %891
  %895 = lshr <8 x i16> %894, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %896 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %895, <8 x i16> zeroinitializer) #5
  %897 = lshr <8 x i16> %896, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %898 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %884, <8 x i16> %897) #5
  %899 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %898, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %900 = icmp slt <16 x i8> %899, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %901 = select <16 x i1> %900, <16 x i8> %899, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %902 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %901
  %903 = bitcast i8* %873 to <16 x i8>*
  store <16 x i8> %902, <16 x i8>* %903, align 16
  %904 = getelementptr inbounds i16, i16* %10, i64 432
  %905 = getelementptr inbounds i16, i16* %11, i64 432
  %906 = getelementptr inbounds i8, i8* %804, i64 48
  %907 = bitcast i16* %904 to <8 x i16>*
  %908 = load <8 x i16>, <8 x i16>* %907, align 16
  %909 = bitcast i16* %905 to <8 x i16>*
  %910 = load <8 x i16>, <8 x i16>* %909, align 16
  %911 = sub <8 x i16> %908, %910
  %912 = sub <8 x i16> zeroinitializer, %911
  %913 = icmp slt <8 x i16> %911, zeroinitializer
  %914 = select <8 x i1> %913, <8 x i16> %912, <8 x i16> %911
  %915 = lshr <8 x i16> %914, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %916 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %915, <8 x i16> zeroinitializer) #5
  %917 = lshr <8 x i16> %916, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %918 = getelementptr inbounds i16, i16* %10, i64 440
  %919 = bitcast i16* %918 to <8 x i16>*
  %920 = load <8 x i16>, <8 x i16>* %919, align 16
  %921 = getelementptr inbounds i16, i16* %11, i64 440
  %922 = bitcast i16* %921 to <8 x i16>*
  %923 = load <8 x i16>, <8 x i16>* %922, align 16
  %924 = sub <8 x i16> %920, %923
  %925 = sub <8 x i16> zeroinitializer, %924
  %926 = icmp slt <8 x i16> %924, zeroinitializer
  %927 = select <8 x i1> %926, <8 x i16> %925, <8 x i16> %924
  %928 = lshr <8 x i16> %927, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %929 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %928, <8 x i16> zeroinitializer) #5
  %930 = lshr <8 x i16> %929, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %931 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %917, <8 x i16> %930) #5
  %932 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %931, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %933 = icmp slt <16 x i8> %932, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %934 = select <16 x i1> %933, <16 x i8> %932, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %935 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %934
  %936 = bitcast i8* %906 to <16 x i8>*
  store <16 x i8> %935, <16 x i8>* %936, align 16
  %937 = getelementptr inbounds i16, i16* %10, i64 448
  %938 = getelementptr inbounds i16, i16* %11, i64 448
  %939 = getelementptr inbounds i8, i8* %804, i64 64
  %940 = bitcast i16* %937 to <8 x i16>*
  %941 = load <8 x i16>, <8 x i16>* %940, align 16
  %942 = bitcast i16* %938 to <8 x i16>*
  %943 = load <8 x i16>, <8 x i16>* %942, align 16
  %944 = sub <8 x i16> %941, %943
  %945 = sub <8 x i16> zeroinitializer, %944
  %946 = icmp slt <8 x i16> %944, zeroinitializer
  %947 = select <8 x i1> %946, <8 x i16> %945, <8 x i16> %944
  %948 = lshr <8 x i16> %947, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %949 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %948, <8 x i16> zeroinitializer) #5
  %950 = lshr <8 x i16> %949, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %951 = getelementptr inbounds i16, i16* %10, i64 456
  %952 = bitcast i16* %951 to <8 x i16>*
  %953 = load <8 x i16>, <8 x i16>* %952, align 16
  %954 = getelementptr inbounds i16, i16* %11, i64 456
  %955 = bitcast i16* %954 to <8 x i16>*
  %956 = load <8 x i16>, <8 x i16>* %955, align 16
  %957 = sub <8 x i16> %953, %956
  %958 = sub <8 x i16> zeroinitializer, %957
  %959 = icmp slt <8 x i16> %957, zeroinitializer
  %960 = select <8 x i1> %959, <8 x i16> %958, <8 x i16> %957
  %961 = lshr <8 x i16> %960, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %962 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %961, <8 x i16> zeroinitializer) #5
  %963 = lshr <8 x i16> %962, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %964 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %950, <8 x i16> %963) #5
  %965 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %964, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %966 = icmp slt <16 x i8> %965, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %967 = select <16 x i1> %966, <16 x i8> %965, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %968 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %967
  %969 = bitcast i8* %939 to <16 x i8>*
  store <16 x i8> %968, <16 x i8>* %969, align 16
  %970 = getelementptr inbounds i16, i16* %10, i64 464
  %971 = getelementptr inbounds i16, i16* %11, i64 464
  %972 = getelementptr inbounds i8, i8* %939, i64 16
  %973 = bitcast i16* %970 to <8 x i16>*
  %974 = load <8 x i16>, <8 x i16>* %973, align 16
  %975 = bitcast i16* %971 to <8 x i16>*
  %976 = load <8 x i16>, <8 x i16>* %975, align 16
  %977 = sub <8 x i16> %974, %976
  %978 = sub <8 x i16> zeroinitializer, %977
  %979 = icmp slt <8 x i16> %977, zeroinitializer
  %980 = select <8 x i1> %979, <8 x i16> %978, <8 x i16> %977
  %981 = lshr <8 x i16> %980, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %982 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %981, <8 x i16> zeroinitializer) #5
  %983 = lshr <8 x i16> %982, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %984 = getelementptr inbounds i16, i16* %10, i64 472
  %985 = bitcast i16* %984 to <8 x i16>*
  %986 = load <8 x i16>, <8 x i16>* %985, align 16
  %987 = getelementptr inbounds i16, i16* %11, i64 472
  %988 = bitcast i16* %987 to <8 x i16>*
  %989 = load <8 x i16>, <8 x i16>* %988, align 16
  %990 = sub <8 x i16> %986, %989
  %991 = sub <8 x i16> zeroinitializer, %990
  %992 = icmp slt <8 x i16> %990, zeroinitializer
  %993 = select <8 x i1> %992, <8 x i16> %991, <8 x i16> %990
  %994 = lshr <8 x i16> %993, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %995 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %994, <8 x i16> zeroinitializer) #5
  %996 = lshr <8 x i16> %995, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %997 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %983, <8 x i16> %996) #5
  %998 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %997, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %999 = icmp slt <16 x i8> %998, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1000 = select <16 x i1> %999, <16 x i8> %998, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1001 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1000
  %1002 = bitcast i8* %972 to <16 x i8>*
  store <16 x i8> %1001, <16 x i8>* %1002, align 16
  %1003 = getelementptr inbounds i16, i16* %10, i64 480
  %1004 = getelementptr inbounds i16, i16* %11, i64 480
  %1005 = getelementptr inbounds i8, i8* %939, i64 32
  %1006 = bitcast i16* %1003 to <8 x i16>*
  %1007 = load <8 x i16>, <8 x i16>* %1006, align 16
  %1008 = bitcast i16* %1004 to <8 x i16>*
  %1009 = load <8 x i16>, <8 x i16>* %1008, align 16
  %1010 = sub <8 x i16> %1007, %1009
  %1011 = sub <8 x i16> zeroinitializer, %1010
  %1012 = icmp slt <8 x i16> %1010, zeroinitializer
  %1013 = select <8 x i1> %1012, <8 x i16> %1011, <8 x i16> %1010
  %1014 = lshr <8 x i16> %1013, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1015 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1014, <8 x i16> zeroinitializer) #5
  %1016 = lshr <8 x i16> %1015, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1017 = getelementptr inbounds i16, i16* %10, i64 488
  %1018 = bitcast i16* %1017 to <8 x i16>*
  %1019 = load <8 x i16>, <8 x i16>* %1018, align 16
  %1020 = getelementptr inbounds i16, i16* %11, i64 488
  %1021 = bitcast i16* %1020 to <8 x i16>*
  %1022 = load <8 x i16>, <8 x i16>* %1021, align 16
  %1023 = sub <8 x i16> %1019, %1022
  %1024 = sub <8 x i16> zeroinitializer, %1023
  %1025 = icmp slt <8 x i16> %1023, zeroinitializer
  %1026 = select <8 x i1> %1025, <8 x i16> %1024, <8 x i16> %1023
  %1027 = lshr <8 x i16> %1026, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1028 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1027, <8 x i16> zeroinitializer) #5
  %1029 = lshr <8 x i16> %1028, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1030 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1016, <8 x i16> %1029) #5
  %1031 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1030, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1032 = icmp slt <16 x i8> %1031, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1033 = select <16 x i1> %1032, <16 x i8> %1031, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1034 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1033
  %1035 = bitcast i8* %1005 to <16 x i8>*
  store <16 x i8> %1034, <16 x i8>* %1035, align 16
  %1036 = getelementptr inbounds i16, i16* %10, i64 496
  %1037 = getelementptr inbounds i16, i16* %11, i64 496
  %1038 = getelementptr inbounds i8, i8* %939, i64 48
  %1039 = bitcast i16* %1036 to <8 x i16>*
  %1040 = load <8 x i16>, <8 x i16>* %1039, align 16
  %1041 = bitcast i16* %1037 to <8 x i16>*
  %1042 = load <8 x i16>, <8 x i16>* %1041, align 16
  %1043 = sub <8 x i16> %1040, %1042
  %1044 = sub <8 x i16> zeroinitializer, %1043
  %1045 = icmp slt <8 x i16> %1043, zeroinitializer
  %1046 = select <8 x i1> %1045, <8 x i16> %1044, <8 x i16> %1043
  %1047 = lshr <8 x i16> %1046, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1048 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1047, <8 x i16> zeroinitializer) #5
  %1049 = lshr <8 x i16> %1048, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1050 = getelementptr inbounds i16, i16* %10, i64 504
  %1051 = bitcast i16* %1050 to <8 x i16>*
  %1052 = load <8 x i16>, <8 x i16>* %1051, align 16
  %1053 = getelementptr inbounds i16, i16* %11, i64 504
  %1054 = bitcast i16* %1053 to <8 x i16>*
  %1055 = load <8 x i16>, <8 x i16>* %1054, align 16
  %1056 = sub <8 x i16> %1052, %1055
  %1057 = sub <8 x i16> zeroinitializer, %1056
  %1058 = icmp slt <8 x i16> %1056, zeroinitializer
  %1059 = select <8 x i1> %1058, <8 x i16> %1057, <8 x i16> %1056
  %1060 = lshr <8 x i16> %1059, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1061 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1060, <8 x i16> zeroinitializer) #5
  %1062 = lshr <8 x i16> %1061, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1063 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1049, <8 x i16> %1062) #5
  %1064 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1063, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1065 = icmp slt <16 x i8> %1064, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1066 = select <16 x i1> %1065, <16 x i8> %1064, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1067 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1066
  %1068 = bitcast i8* %1038 to <16 x i8>*
  store <16 x i8> %1067, <16 x i8>* %1068, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_122WeightMask128x128_SSE4ILb0EEEvPKvS5_Phl(i8* readonly, i8* readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  %7 = add nsw i64 %3, -64
  br label %8

8:                                                ; preds = %8, %4
  %9 = phi i8* [ %2, %4 ], [ %780, %8 ]
  %10 = phi i16* [ %5, %4 ], [ %778, %8 ]
  %11 = phi i16* [ %6, %4 ], [ %779, %8 ]
  %12 = phi i32 [ 0, %4 ], [ %781, %8 ]
  %13 = bitcast i16* %10 to <8 x i16>*
  %14 = load <8 x i16>, <8 x i16>* %13, align 16
  %15 = bitcast i16* %11 to <8 x i16>*
  %16 = load <8 x i16>, <8 x i16>* %15, align 16
  %17 = sub <8 x i16> %14, %16
  %18 = sub <8 x i16> zeroinitializer, %17
  %19 = icmp slt <8 x i16> %17, zeroinitializer
  %20 = select <8 x i1> %19, <8 x i16> %18, <8 x i16> %17
  %21 = lshr <8 x i16> %20, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %22 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %21, <8 x i16> zeroinitializer) #5
  %23 = lshr <8 x i16> %22, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %24 = getelementptr inbounds i16, i16* %10, i64 8
  %25 = bitcast i16* %24 to <8 x i16>*
  %26 = load <8 x i16>, <8 x i16>* %25, align 16
  %27 = getelementptr inbounds i16, i16* %11, i64 8
  %28 = bitcast i16* %27 to <8 x i16>*
  %29 = load <8 x i16>, <8 x i16>* %28, align 16
  %30 = sub <8 x i16> %26, %29
  %31 = sub <8 x i16> zeroinitializer, %30
  %32 = icmp slt <8 x i16> %30, zeroinitializer
  %33 = select <8 x i1> %32, <8 x i16> %31, <8 x i16> %30
  %34 = lshr <8 x i16> %33, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %35 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %34, <8 x i16> zeroinitializer) #5
  %36 = lshr <8 x i16> %35, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %37 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %23, <8 x i16> %36) #5
  %38 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %37, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %39 = icmp slt <16 x i8> %38, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %40 = select <16 x i1> %39, <16 x i8> %38, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %41 = bitcast i8* %9 to <16 x i8>*
  store <16 x i8> %40, <16 x i8>* %41, align 16
  %42 = getelementptr inbounds i16, i16* %10, i64 16
  %43 = getelementptr inbounds i16, i16* %11, i64 16
  %44 = getelementptr inbounds i8, i8* %9, i64 16
  %45 = bitcast i16* %42 to <8 x i16>*
  %46 = load <8 x i16>, <8 x i16>* %45, align 16
  %47 = bitcast i16* %43 to <8 x i16>*
  %48 = load <8 x i16>, <8 x i16>* %47, align 16
  %49 = sub <8 x i16> %46, %48
  %50 = sub <8 x i16> zeroinitializer, %49
  %51 = icmp slt <8 x i16> %49, zeroinitializer
  %52 = select <8 x i1> %51, <8 x i16> %50, <8 x i16> %49
  %53 = lshr <8 x i16> %52, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %54 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %53, <8 x i16> zeroinitializer) #5
  %55 = lshr <8 x i16> %54, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %56 = getelementptr inbounds i16, i16* %10, i64 24
  %57 = bitcast i16* %56 to <8 x i16>*
  %58 = load <8 x i16>, <8 x i16>* %57, align 16
  %59 = getelementptr inbounds i16, i16* %11, i64 24
  %60 = bitcast i16* %59 to <8 x i16>*
  %61 = load <8 x i16>, <8 x i16>* %60, align 16
  %62 = sub <8 x i16> %58, %61
  %63 = sub <8 x i16> zeroinitializer, %62
  %64 = icmp slt <8 x i16> %62, zeroinitializer
  %65 = select <8 x i1> %64, <8 x i16> %63, <8 x i16> %62
  %66 = lshr <8 x i16> %65, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %67 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %66, <8 x i16> zeroinitializer) #5
  %68 = lshr <8 x i16> %67, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %69 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %55, <8 x i16> %68) #5
  %70 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %69, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %71 = icmp slt <16 x i8> %70, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %72 = select <16 x i1> %71, <16 x i8> %70, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %73 = bitcast i8* %44 to <16 x i8>*
  store <16 x i8> %72, <16 x i8>* %73, align 16
  %74 = getelementptr inbounds i16, i16* %10, i64 32
  %75 = getelementptr inbounds i16, i16* %11, i64 32
  %76 = getelementptr inbounds i8, i8* %9, i64 32
  %77 = bitcast i16* %74 to <8 x i16>*
  %78 = load <8 x i16>, <8 x i16>* %77, align 16
  %79 = bitcast i16* %75 to <8 x i16>*
  %80 = load <8 x i16>, <8 x i16>* %79, align 16
  %81 = sub <8 x i16> %78, %80
  %82 = sub <8 x i16> zeroinitializer, %81
  %83 = icmp slt <8 x i16> %81, zeroinitializer
  %84 = select <8 x i1> %83, <8 x i16> %82, <8 x i16> %81
  %85 = lshr <8 x i16> %84, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %86 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %85, <8 x i16> zeroinitializer) #5
  %87 = lshr <8 x i16> %86, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %88 = getelementptr inbounds i16, i16* %10, i64 40
  %89 = bitcast i16* %88 to <8 x i16>*
  %90 = load <8 x i16>, <8 x i16>* %89, align 16
  %91 = getelementptr inbounds i16, i16* %11, i64 40
  %92 = bitcast i16* %91 to <8 x i16>*
  %93 = load <8 x i16>, <8 x i16>* %92, align 16
  %94 = sub <8 x i16> %90, %93
  %95 = sub <8 x i16> zeroinitializer, %94
  %96 = icmp slt <8 x i16> %94, zeroinitializer
  %97 = select <8 x i1> %96, <8 x i16> %95, <8 x i16> %94
  %98 = lshr <8 x i16> %97, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %99 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %98, <8 x i16> zeroinitializer) #5
  %100 = lshr <8 x i16> %99, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %101 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %87, <8 x i16> %100) #5
  %102 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %101, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %103 = icmp slt <16 x i8> %102, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %104 = select <16 x i1> %103, <16 x i8> %102, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %105 = bitcast i8* %76 to <16 x i8>*
  store <16 x i8> %104, <16 x i8>* %105, align 16
  %106 = getelementptr inbounds i16, i16* %10, i64 48
  %107 = getelementptr inbounds i16, i16* %11, i64 48
  %108 = getelementptr inbounds i8, i8* %9, i64 48
  %109 = bitcast i16* %106 to <8 x i16>*
  %110 = load <8 x i16>, <8 x i16>* %109, align 16
  %111 = bitcast i16* %107 to <8 x i16>*
  %112 = load <8 x i16>, <8 x i16>* %111, align 16
  %113 = sub <8 x i16> %110, %112
  %114 = sub <8 x i16> zeroinitializer, %113
  %115 = icmp slt <8 x i16> %113, zeroinitializer
  %116 = select <8 x i1> %115, <8 x i16> %114, <8 x i16> %113
  %117 = lshr <8 x i16> %116, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %118 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %117, <8 x i16> zeroinitializer) #5
  %119 = lshr <8 x i16> %118, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %120 = getelementptr inbounds i16, i16* %10, i64 56
  %121 = bitcast i16* %120 to <8 x i16>*
  %122 = load <8 x i16>, <8 x i16>* %121, align 16
  %123 = getelementptr inbounds i16, i16* %11, i64 56
  %124 = bitcast i16* %123 to <8 x i16>*
  %125 = load <8 x i16>, <8 x i16>* %124, align 16
  %126 = sub <8 x i16> %122, %125
  %127 = sub <8 x i16> zeroinitializer, %126
  %128 = icmp slt <8 x i16> %126, zeroinitializer
  %129 = select <8 x i1> %128, <8 x i16> %127, <8 x i16> %126
  %130 = lshr <8 x i16> %129, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %131 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %130, <8 x i16> zeroinitializer) #5
  %132 = lshr <8 x i16> %131, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %133 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %119, <8 x i16> %132) #5
  %134 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %133, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %135 = icmp slt <16 x i8> %134, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %136 = select <16 x i1> %135, <16 x i8> %134, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %137 = bitcast i8* %108 to <16 x i8>*
  store <16 x i8> %136, <16 x i8>* %137, align 16
  %138 = getelementptr inbounds i16, i16* %10, i64 64
  %139 = getelementptr inbounds i16, i16* %11, i64 64
  %140 = getelementptr inbounds i8, i8* %9, i64 64
  %141 = bitcast i16* %138 to <8 x i16>*
  %142 = load <8 x i16>, <8 x i16>* %141, align 16
  %143 = bitcast i16* %139 to <8 x i16>*
  %144 = load <8 x i16>, <8 x i16>* %143, align 16
  %145 = sub <8 x i16> %142, %144
  %146 = sub <8 x i16> zeroinitializer, %145
  %147 = icmp slt <8 x i16> %145, zeroinitializer
  %148 = select <8 x i1> %147, <8 x i16> %146, <8 x i16> %145
  %149 = lshr <8 x i16> %148, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %150 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %149, <8 x i16> zeroinitializer) #5
  %151 = lshr <8 x i16> %150, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %152 = getelementptr inbounds i16, i16* %10, i64 72
  %153 = bitcast i16* %152 to <8 x i16>*
  %154 = load <8 x i16>, <8 x i16>* %153, align 16
  %155 = getelementptr inbounds i16, i16* %11, i64 72
  %156 = bitcast i16* %155 to <8 x i16>*
  %157 = load <8 x i16>, <8 x i16>* %156, align 16
  %158 = sub <8 x i16> %154, %157
  %159 = sub <8 x i16> zeroinitializer, %158
  %160 = icmp slt <8 x i16> %158, zeroinitializer
  %161 = select <8 x i1> %160, <8 x i16> %159, <8 x i16> %158
  %162 = lshr <8 x i16> %161, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %163 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %162, <8 x i16> zeroinitializer) #5
  %164 = lshr <8 x i16> %163, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %165 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %151, <8 x i16> %164) #5
  %166 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %165, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %167 = icmp slt <16 x i8> %166, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %168 = select <16 x i1> %167, <16 x i8> %166, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %169 = bitcast i8* %140 to <16 x i8>*
  store <16 x i8> %168, <16 x i8>* %169, align 16
  %170 = getelementptr inbounds i16, i16* %10, i64 80
  %171 = getelementptr inbounds i16, i16* %11, i64 80
  %172 = getelementptr inbounds i8, i8* %9, i64 80
  %173 = bitcast i16* %170 to <8 x i16>*
  %174 = load <8 x i16>, <8 x i16>* %173, align 16
  %175 = bitcast i16* %171 to <8 x i16>*
  %176 = load <8 x i16>, <8 x i16>* %175, align 16
  %177 = sub <8 x i16> %174, %176
  %178 = sub <8 x i16> zeroinitializer, %177
  %179 = icmp slt <8 x i16> %177, zeroinitializer
  %180 = select <8 x i1> %179, <8 x i16> %178, <8 x i16> %177
  %181 = lshr <8 x i16> %180, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %182 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %181, <8 x i16> zeroinitializer) #5
  %183 = lshr <8 x i16> %182, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %184 = getelementptr inbounds i16, i16* %10, i64 88
  %185 = bitcast i16* %184 to <8 x i16>*
  %186 = load <8 x i16>, <8 x i16>* %185, align 16
  %187 = getelementptr inbounds i16, i16* %11, i64 88
  %188 = bitcast i16* %187 to <8 x i16>*
  %189 = load <8 x i16>, <8 x i16>* %188, align 16
  %190 = sub <8 x i16> %186, %189
  %191 = sub <8 x i16> zeroinitializer, %190
  %192 = icmp slt <8 x i16> %190, zeroinitializer
  %193 = select <8 x i1> %192, <8 x i16> %191, <8 x i16> %190
  %194 = lshr <8 x i16> %193, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %195 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %194, <8 x i16> zeroinitializer) #5
  %196 = lshr <8 x i16> %195, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %197 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %183, <8 x i16> %196) #5
  %198 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %197, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %199 = icmp slt <16 x i8> %198, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %200 = select <16 x i1> %199, <16 x i8> %198, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %201 = bitcast i8* %172 to <16 x i8>*
  store <16 x i8> %200, <16 x i8>* %201, align 16
  %202 = getelementptr inbounds i16, i16* %10, i64 96
  %203 = getelementptr inbounds i16, i16* %11, i64 96
  %204 = getelementptr inbounds i8, i8* %9, i64 96
  %205 = bitcast i16* %202 to <8 x i16>*
  %206 = load <8 x i16>, <8 x i16>* %205, align 16
  %207 = bitcast i16* %203 to <8 x i16>*
  %208 = load <8 x i16>, <8 x i16>* %207, align 16
  %209 = sub <8 x i16> %206, %208
  %210 = sub <8 x i16> zeroinitializer, %209
  %211 = icmp slt <8 x i16> %209, zeroinitializer
  %212 = select <8 x i1> %211, <8 x i16> %210, <8 x i16> %209
  %213 = lshr <8 x i16> %212, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %214 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %213, <8 x i16> zeroinitializer) #5
  %215 = lshr <8 x i16> %214, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %216 = getelementptr inbounds i16, i16* %10, i64 104
  %217 = bitcast i16* %216 to <8 x i16>*
  %218 = load <8 x i16>, <8 x i16>* %217, align 16
  %219 = getelementptr inbounds i16, i16* %11, i64 104
  %220 = bitcast i16* %219 to <8 x i16>*
  %221 = load <8 x i16>, <8 x i16>* %220, align 16
  %222 = sub <8 x i16> %218, %221
  %223 = sub <8 x i16> zeroinitializer, %222
  %224 = icmp slt <8 x i16> %222, zeroinitializer
  %225 = select <8 x i1> %224, <8 x i16> %223, <8 x i16> %222
  %226 = lshr <8 x i16> %225, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %227 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %226, <8 x i16> zeroinitializer) #5
  %228 = lshr <8 x i16> %227, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %229 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %215, <8 x i16> %228) #5
  %230 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %229, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %231 = icmp slt <16 x i8> %230, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %232 = select <16 x i1> %231, <16 x i8> %230, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %233 = bitcast i8* %204 to <16 x i8>*
  store <16 x i8> %232, <16 x i8>* %233, align 16
  %234 = getelementptr inbounds i16, i16* %10, i64 112
  %235 = getelementptr inbounds i16, i16* %11, i64 112
  %236 = getelementptr inbounds i8, i8* %9, i64 112
  %237 = bitcast i16* %234 to <8 x i16>*
  %238 = load <8 x i16>, <8 x i16>* %237, align 16
  %239 = bitcast i16* %235 to <8 x i16>*
  %240 = load <8 x i16>, <8 x i16>* %239, align 16
  %241 = sub <8 x i16> %238, %240
  %242 = sub <8 x i16> zeroinitializer, %241
  %243 = icmp slt <8 x i16> %241, zeroinitializer
  %244 = select <8 x i1> %243, <8 x i16> %242, <8 x i16> %241
  %245 = lshr <8 x i16> %244, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %246 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %245, <8 x i16> zeroinitializer) #5
  %247 = lshr <8 x i16> %246, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %248 = getelementptr inbounds i16, i16* %10, i64 120
  %249 = bitcast i16* %248 to <8 x i16>*
  %250 = load <8 x i16>, <8 x i16>* %249, align 16
  %251 = getelementptr inbounds i16, i16* %11, i64 120
  %252 = bitcast i16* %251 to <8 x i16>*
  %253 = load <8 x i16>, <8 x i16>* %252, align 16
  %254 = sub <8 x i16> %250, %253
  %255 = sub <8 x i16> zeroinitializer, %254
  %256 = icmp slt <8 x i16> %254, zeroinitializer
  %257 = select <8 x i1> %256, <8 x i16> %255, <8 x i16> %254
  %258 = lshr <8 x i16> %257, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %259 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %258, <8 x i16> zeroinitializer) #5
  %260 = lshr <8 x i16> %259, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %261 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %247, <8 x i16> %260) #5
  %262 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %261, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %263 = icmp slt <16 x i8> %262, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %264 = select <16 x i1> %263, <16 x i8> %262, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %265 = bitcast i8* %236 to <16 x i8>*
  store <16 x i8> %264, <16 x i8>* %265, align 16
  %266 = getelementptr inbounds i16, i16* %10, i64 128
  %267 = getelementptr inbounds i16, i16* %11, i64 128
  %268 = getelementptr inbounds i8, i8* %9, i64 %3
  %269 = bitcast i16* %266 to <8 x i16>*
  %270 = load <8 x i16>, <8 x i16>* %269, align 16
  %271 = bitcast i16* %267 to <8 x i16>*
  %272 = load <8 x i16>, <8 x i16>* %271, align 16
  %273 = sub <8 x i16> %270, %272
  %274 = sub <8 x i16> zeroinitializer, %273
  %275 = icmp slt <8 x i16> %273, zeroinitializer
  %276 = select <8 x i1> %275, <8 x i16> %274, <8 x i16> %273
  %277 = lshr <8 x i16> %276, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %278 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %277, <8 x i16> zeroinitializer) #5
  %279 = lshr <8 x i16> %278, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %280 = getelementptr inbounds i16, i16* %10, i64 136
  %281 = bitcast i16* %280 to <8 x i16>*
  %282 = load <8 x i16>, <8 x i16>* %281, align 16
  %283 = getelementptr inbounds i16, i16* %11, i64 136
  %284 = bitcast i16* %283 to <8 x i16>*
  %285 = load <8 x i16>, <8 x i16>* %284, align 16
  %286 = sub <8 x i16> %282, %285
  %287 = sub <8 x i16> zeroinitializer, %286
  %288 = icmp slt <8 x i16> %286, zeroinitializer
  %289 = select <8 x i1> %288, <8 x i16> %287, <8 x i16> %286
  %290 = lshr <8 x i16> %289, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %291 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %290, <8 x i16> zeroinitializer) #5
  %292 = lshr <8 x i16> %291, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %293 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %279, <8 x i16> %292) #5
  %294 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %293, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %295 = icmp slt <16 x i8> %294, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %296 = select <16 x i1> %295, <16 x i8> %294, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %297 = bitcast i8* %268 to <16 x i8>*
  store <16 x i8> %296, <16 x i8>* %297, align 16
  %298 = getelementptr inbounds i16, i16* %10, i64 144
  %299 = getelementptr inbounds i16, i16* %11, i64 144
  %300 = getelementptr inbounds i8, i8* %268, i64 16
  %301 = bitcast i16* %298 to <8 x i16>*
  %302 = load <8 x i16>, <8 x i16>* %301, align 16
  %303 = bitcast i16* %299 to <8 x i16>*
  %304 = load <8 x i16>, <8 x i16>* %303, align 16
  %305 = sub <8 x i16> %302, %304
  %306 = sub <8 x i16> zeroinitializer, %305
  %307 = icmp slt <8 x i16> %305, zeroinitializer
  %308 = select <8 x i1> %307, <8 x i16> %306, <8 x i16> %305
  %309 = lshr <8 x i16> %308, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %310 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %309, <8 x i16> zeroinitializer) #5
  %311 = lshr <8 x i16> %310, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %312 = getelementptr inbounds i16, i16* %10, i64 152
  %313 = bitcast i16* %312 to <8 x i16>*
  %314 = load <8 x i16>, <8 x i16>* %313, align 16
  %315 = getelementptr inbounds i16, i16* %11, i64 152
  %316 = bitcast i16* %315 to <8 x i16>*
  %317 = load <8 x i16>, <8 x i16>* %316, align 16
  %318 = sub <8 x i16> %314, %317
  %319 = sub <8 x i16> zeroinitializer, %318
  %320 = icmp slt <8 x i16> %318, zeroinitializer
  %321 = select <8 x i1> %320, <8 x i16> %319, <8 x i16> %318
  %322 = lshr <8 x i16> %321, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %323 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %322, <8 x i16> zeroinitializer) #5
  %324 = lshr <8 x i16> %323, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %325 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %311, <8 x i16> %324) #5
  %326 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %325, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %327 = icmp slt <16 x i8> %326, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %328 = select <16 x i1> %327, <16 x i8> %326, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %329 = bitcast i8* %300 to <16 x i8>*
  store <16 x i8> %328, <16 x i8>* %329, align 16
  %330 = getelementptr inbounds i16, i16* %10, i64 160
  %331 = getelementptr inbounds i16, i16* %11, i64 160
  %332 = getelementptr inbounds i8, i8* %268, i64 32
  %333 = bitcast i16* %330 to <8 x i16>*
  %334 = load <8 x i16>, <8 x i16>* %333, align 16
  %335 = bitcast i16* %331 to <8 x i16>*
  %336 = load <8 x i16>, <8 x i16>* %335, align 16
  %337 = sub <8 x i16> %334, %336
  %338 = sub <8 x i16> zeroinitializer, %337
  %339 = icmp slt <8 x i16> %337, zeroinitializer
  %340 = select <8 x i1> %339, <8 x i16> %338, <8 x i16> %337
  %341 = lshr <8 x i16> %340, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %342 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %341, <8 x i16> zeroinitializer) #5
  %343 = lshr <8 x i16> %342, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %344 = getelementptr inbounds i16, i16* %10, i64 168
  %345 = bitcast i16* %344 to <8 x i16>*
  %346 = load <8 x i16>, <8 x i16>* %345, align 16
  %347 = getelementptr inbounds i16, i16* %11, i64 168
  %348 = bitcast i16* %347 to <8 x i16>*
  %349 = load <8 x i16>, <8 x i16>* %348, align 16
  %350 = sub <8 x i16> %346, %349
  %351 = sub <8 x i16> zeroinitializer, %350
  %352 = icmp slt <8 x i16> %350, zeroinitializer
  %353 = select <8 x i1> %352, <8 x i16> %351, <8 x i16> %350
  %354 = lshr <8 x i16> %353, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %355 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %354, <8 x i16> zeroinitializer) #5
  %356 = lshr <8 x i16> %355, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %357 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %343, <8 x i16> %356) #5
  %358 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %357, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %359 = icmp slt <16 x i8> %358, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %360 = select <16 x i1> %359, <16 x i8> %358, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %361 = bitcast i8* %332 to <16 x i8>*
  store <16 x i8> %360, <16 x i8>* %361, align 16
  %362 = getelementptr inbounds i16, i16* %10, i64 176
  %363 = getelementptr inbounds i16, i16* %11, i64 176
  %364 = getelementptr inbounds i8, i8* %268, i64 48
  %365 = bitcast i16* %362 to <8 x i16>*
  %366 = load <8 x i16>, <8 x i16>* %365, align 16
  %367 = bitcast i16* %363 to <8 x i16>*
  %368 = load <8 x i16>, <8 x i16>* %367, align 16
  %369 = sub <8 x i16> %366, %368
  %370 = sub <8 x i16> zeroinitializer, %369
  %371 = icmp slt <8 x i16> %369, zeroinitializer
  %372 = select <8 x i1> %371, <8 x i16> %370, <8 x i16> %369
  %373 = lshr <8 x i16> %372, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %374 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %373, <8 x i16> zeroinitializer) #5
  %375 = lshr <8 x i16> %374, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %376 = getelementptr inbounds i16, i16* %10, i64 184
  %377 = bitcast i16* %376 to <8 x i16>*
  %378 = load <8 x i16>, <8 x i16>* %377, align 16
  %379 = getelementptr inbounds i16, i16* %11, i64 184
  %380 = bitcast i16* %379 to <8 x i16>*
  %381 = load <8 x i16>, <8 x i16>* %380, align 16
  %382 = sub <8 x i16> %378, %381
  %383 = sub <8 x i16> zeroinitializer, %382
  %384 = icmp slt <8 x i16> %382, zeroinitializer
  %385 = select <8 x i1> %384, <8 x i16> %383, <8 x i16> %382
  %386 = lshr <8 x i16> %385, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %387 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %386, <8 x i16> zeroinitializer) #5
  %388 = lshr <8 x i16> %387, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %389 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %375, <8 x i16> %388) #5
  %390 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %389, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %391 = icmp slt <16 x i8> %390, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %392 = select <16 x i1> %391, <16 x i8> %390, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %393 = bitcast i8* %364 to <16 x i8>*
  store <16 x i8> %392, <16 x i8>* %393, align 16
  %394 = getelementptr inbounds i16, i16* %10, i64 192
  %395 = getelementptr inbounds i16, i16* %11, i64 192
  %396 = getelementptr inbounds i8, i8* %268, i64 64
  %397 = bitcast i16* %394 to <8 x i16>*
  %398 = load <8 x i16>, <8 x i16>* %397, align 16
  %399 = bitcast i16* %395 to <8 x i16>*
  %400 = load <8 x i16>, <8 x i16>* %399, align 16
  %401 = sub <8 x i16> %398, %400
  %402 = sub <8 x i16> zeroinitializer, %401
  %403 = icmp slt <8 x i16> %401, zeroinitializer
  %404 = select <8 x i1> %403, <8 x i16> %402, <8 x i16> %401
  %405 = lshr <8 x i16> %404, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %406 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %405, <8 x i16> zeroinitializer) #5
  %407 = lshr <8 x i16> %406, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %408 = getelementptr inbounds i16, i16* %10, i64 200
  %409 = bitcast i16* %408 to <8 x i16>*
  %410 = load <8 x i16>, <8 x i16>* %409, align 16
  %411 = getelementptr inbounds i16, i16* %11, i64 200
  %412 = bitcast i16* %411 to <8 x i16>*
  %413 = load <8 x i16>, <8 x i16>* %412, align 16
  %414 = sub <8 x i16> %410, %413
  %415 = sub <8 x i16> zeroinitializer, %414
  %416 = icmp slt <8 x i16> %414, zeroinitializer
  %417 = select <8 x i1> %416, <8 x i16> %415, <8 x i16> %414
  %418 = lshr <8 x i16> %417, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %419 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %418, <8 x i16> zeroinitializer) #5
  %420 = lshr <8 x i16> %419, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %421 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %407, <8 x i16> %420) #5
  %422 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %421, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %423 = icmp slt <16 x i8> %422, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %424 = select <16 x i1> %423, <16 x i8> %422, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %425 = bitcast i8* %396 to <16 x i8>*
  store <16 x i8> %424, <16 x i8>* %425, align 16
  %426 = getelementptr inbounds i16, i16* %10, i64 208
  %427 = getelementptr inbounds i16, i16* %11, i64 208
  %428 = getelementptr inbounds i8, i8* %396, i64 16
  %429 = bitcast i16* %426 to <8 x i16>*
  %430 = load <8 x i16>, <8 x i16>* %429, align 16
  %431 = bitcast i16* %427 to <8 x i16>*
  %432 = load <8 x i16>, <8 x i16>* %431, align 16
  %433 = sub <8 x i16> %430, %432
  %434 = sub <8 x i16> zeroinitializer, %433
  %435 = icmp slt <8 x i16> %433, zeroinitializer
  %436 = select <8 x i1> %435, <8 x i16> %434, <8 x i16> %433
  %437 = lshr <8 x i16> %436, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %438 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %437, <8 x i16> zeroinitializer) #5
  %439 = lshr <8 x i16> %438, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %440 = getelementptr inbounds i16, i16* %10, i64 216
  %441 = bitcast i16* %440 to <8 x i16>*
  %442 = load <8 x i16>, <8 x i16>* %441, align 16
  %443 = getelementptr inbounds i16, i16* %11, i64 216
  %444 = bitcast i16* %443 to <8 x i16>*
  %445 = load <8 x i16>, <8 x i16>* %444, align 16
  %446 = sub <8 x i16> %442, %445
  %447 = sub <8 x i16> zeroinitializer, %446
  %448 = icmp slt <8 x i16> %446, zeroinitializer
  %449 = select <8 x i1> %448, <8 x i16> %447, <8 x i16> %446
  %450 = lshr <8 x i16> %449, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %451 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %450, <8 x i16> zeroinitializer) #5
  %452 = lshr <8 x i16> %451, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %453 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %439, <8 x i16> %452) #5
  %454 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %453, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %455 = icmp slt <16 x i8> %454, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %456 = select <16 x i1> %455, <16 x i8> %454, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %457 = bitcast i8* %428 to <16 x i8>*
  store <16 x i8> %456, <16 x i8>* %457, align 16
  %458 = getelementptr inbounds i16, i16* %10, i64 224
  %459 = getelementptr inbounds i16, i16* %11, i64 224
  %460 = getelementptr inbounds i8, i8* %396, i64 32
  %461 = bitcast i16* %458 to <8 x i16>*
  %462 = load <8 x i16>, <8 x i16>* %461, align 16
  %463 = bitcast i16* %459 to <8 x i16>*
  %464 = load <8 x i16>, <8 x i16>* %463, align 16
  %465 = sub <8 x i16> %462, %464
  %466 = sub <8 x i16> zeroinitializer, %465
  %467 = icmp slt <8 x i16> %465, zeroinitializer
  %468 = select <8 x i1> %467, <8 x i16> %466, <8 x i16> %465
  %469 = lshr <8 x i16> %468, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %470 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %469, <8 x i16> zeroinitializer) #5
  %471 = lshr <8 x i16> %470, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %472 = getelementptr inbounds i16, i16* %10, i64 232
  %473 = bitcast i16* %472 to <8 x i16>*
  %474 = load <8 x i16>, <8 x i16>* %473, align 16
  %475 = getelementptr inbounds i16, i16* %11, i64 232
  %476 = bitcast i16* %475 to <8 x i16>*
  %477 = load <8 x i16>, <8 x i16>* %476, align 16
  %478 = sub <8 x i16> %474, %477
  %479 = sub <8 x i16> zeroinitializer, %478
  %480 = icmp slt <8 x i16> %478, zeroinitializer
  %481 = select <8 x i1> %480, <8 x i16> %479, <8 x i16> %478
  %482 = lshr <8 x i16> %481, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %483 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %482, <8 x i16> zeroinitializer) #5
  %484 = lshr <8 x i16> %483, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %485 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %471, <8 x i16> %484) #5
  %486 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %485, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %487 = icmp slt <16 x i8> %486, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %488 = select <16 x i1> %487, <16 x i8> %486, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %489 = bitcast i8* %460 to <16 x i8>*
  store <16 x i8> %488, <16 x i8>* %489, align 16
  %490 = getelementptr inbounds i16, i16* %10, i64 240
  %491 = getelementptr inbounds i16, i16* %11, i64 240
  %492 = getelementptr inbounds i8, i8* %396, i64 48
  %493 = bitcast i16* %490 to <8 x i16>*
  %494 = load <8 x i16>, <8 x i16>* %493, align 16
  %495 = bitcast i16* %491 to <8 x i16>*
  %496 = load <8 x i16>, <8 x i16>* %495, align 16
  %497 = sub <8 x i16> %494, %496
  %498 = sub <8 x i16> zeroinitializer, %497
  %499 = icmp slt <8 x i16> %497, zeroinitializer
  %500 = select <8 x i1> %499, <8 x i16> %498, <8 x i16> %497
  %501 = lshr <8 x i16> %500, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %502 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %501, <8 x i16> zeroinitializer) #5
  %503 = lshr <8 x i16> %502, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %504 = getelementptr inbounds i16, i16* %10, i64 248
  %505 = bitcast i16* %504 to <8 x i16>*
  %506 = load <8 x i16>, <8 x i16>* %505, align 16
  %507 = getelementptr inbounds i16, i16* %11, i64 248
  %508 = bitcast i16* %507 to <8 x i16>*
  %509 = load <8 x i16>, <8 x i16>* %508, align 16
  %510 = sub <8 x i16> %506, %509
  %511 = sub <8 x i16> zeroinitializer, %510
  %512 = icmp slt <8 x i16> %510, zeroinitializer
  %513 = select <8 x i1> %512, <8 x i16> %511, <8 x i16> %510
  %514 = lshr <8 x i16> %513, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %515 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %514, <8 x i16> zeroinitializer) #5
  %516 = lshr <8 x i16> %515, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %517 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %503, <8 x i16> %516) #5
  %518 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %517, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %519 = icmp slt <16 x i8> %518, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %520 = select <16 x i1> %519, <16 x i8> %518, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %521 = bitcast i8* %492 to <16 x i8>*
  store <16 x i8> %520, <16 x i8>* %521, align 16
  %522 = getelementptr inbounds i16, i16* %10, i64 256
  %523 = getelementptr inbounds i16, i16* %11, i64 256
  %524 = getelementptr inbounds i8, i8* %396, i64 %7
  %525 = bitcast i16* %522 to <8 x i16>*
  %526 = load <8 x i16>, <8 x i16>* %525, align 16
  %527 = bitcast i16* %523 to <8 x i16>*
  %528 = load <8 x i16>, <8 x i16>* %527, align 16
  %529 = sub <8 x i16> %526, %528
  %530 = sub <8 x i16> zeroinitializer, %529
  %531 = icmp slt <8 x i16> %529, zeroinitializer
  %532 = select <8 x i1> %531, <8 x i16> %530, <8 x i16> %529
  %533 = lshr <8 x i16> %532, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %534 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %533, <8 x i16> zeroinitializer) #5
  %535 = lshr <8 x i16> %534, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %536 = getelementptr inbounds i16, i16* %10, i64 264
  %537 = bitcast i16* %536 to <8 x i16>*
  %538 = load <8 x i16>, <8 x i16>* %537, align 16
  %539 = getelementptr inbounds i16, i16* %11, i64 264
  %540 = bitcast i16* %539 to <8 x i16>*
  %541 = load <8 x i16>, <8 x i16>* %540, align 16
  %542 = sub <8 x i16> %538, %541
  %543 = sub <8 x i16> zeroinitializer, %542
  %544 = icmp slt <8 x i16> %542, zeroinitializer
  %545 = select <8 x i1> %544, <8 x i16> %543, <8 x i16> %542
  %546 = lshr <8 x i16> %545, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %547 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %546, <8 x i16> zeroinitializer) #5
  %548 = lshr <8 x i16> %547, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %549 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %535, <8 x i16> %548) #5
  %550 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %549, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %551 = icmp slt <16 x i8> %550, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %552 = select <16 x i1> %551, <16 x i8> %550, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %553 = bitcast i8* %524 to <16 x i8>*
  store <16 x i8> %552, <16 x i8>* %553, align 16
  %554 = getelementptr inbounds i16, i16* %10, i64 272
  %555 = getelementptr inbounds i16, i16* %11, i64 272
  %556 = getelementptr inbounds i8, i8* %524, i64 16
  %557 = bitcast i16* %554 to <8 x i16>*
  %558 = load <8 x i16>, <8 x i16>* %557, align 16
  %559 = bitcast i16* %555 to <8 x i16>*
  %560 = load <8 x i16>, <8 x i16>* %559, align 16
  %561 = sub <8 x i16> %558, %560
  %562 = sub <8 x i16> zeroinitializer, %561
  %563 = icmp slt <8 x i16> %561, zeroinitializer
  %564 = select <8 x i1> %563, <8 x i16> %562, <8 x i16> %561
  %565 = lshr <8 x i16> %564, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %566 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %565, <8 x i16> zeroinitializer) #5
  %567 = lshr <8 x i16> %566, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %568 = getelementptr inbounds i16, i16* %10, i64 280
  %569 = bitcast i16* %568 to <8 x i16>*
  %570 = load <8 x i16>, <8 x i16>* %569, align 16
  %571 = getelementptr inbounds i16, i16* %11, i64 280
  %572 = bitcast i16* %571 to <8 x i16>*
  %573 = load <8 x i16>, <8 x i16>* %572, align 16
  %574 = sub <8 x i16> %570, %573
  %575 = sub <8 x i16> zeroinitializer, %574
  %576 = icmp slt <8 x i16> %574, zeroinitializer
  %577 = select <8 x i1> %576, <8 x i16> %575, <8 x i16> %574
  %578 = lshr <8 x i16> %577, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %579 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %578, <8 x i16> zeroinitializer) #5
  %580 = lshr <8 x i16> %579, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %581 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %567, <8 x i16> %580) #5
  %582 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %581, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %583 = icmp slt <16 x i8> %582, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %584 = select <16 x i1> %583, <16 x i8> %582, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %585 = bitcast i8* %556 to <16 x i8>*
  store <16 x i8> %584, <16 x i8>* %585, align 16
  %586 = getelementptr inbounds i16, i16* %10, i64 288
  %587 = getelementptr inbounds i16, i16* %11, i64 288
  %588 = getelementptr inbounds i8, i8* %524, i64 32
  %589 = bitcast i16* %586 to <8 x i16>*
  %590 = load <8 x i16>, <8 x i16>* %589, align 16
  %591 = bitcast i16* %587 to <8 x i16>*
  %592 = load <8 x i16>, <8 x i16>* %591, align 16
  %593 = sub <8 x i16> %590, %592
  %594 = sub <8 x i16> zeroinitializer, %593
  %595 = icmp slt <8 x i16> %593, zeroinitializer
  %596 = select <8 x i1> %595, <8 x i16> %594, <8 x i16> %593
  %597 = lshr <8 x i16> %596, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %598 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %597, <8 x i16> zeroinitializer) #5
  %599 = lshr <8 x i16> %598, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %600 = getelementptr inbounds i16, i16* %10, i64 296
  %601 = bitcast i16* %600 to <8 x i16>*
  %602 = load <8 x i16>, <8 x i16>* %601, align 16
  %603 = getelementptr inbounds i16, i16* %11, i64 296
  %604 = bitcast i16* %603 to <8 x i16>*
  %605 = load <8 x i16>, <8 x i16>* %604, align 16
  %606 = sub <8 x i16> %602, %605
  %607 = sub <8 x i16> zeroinitializer, %606
  %608 = icmp slt <8 x i16> %606, zeroinitializer
  %609 = select <8 x i1> %608, <8 x i16> %607, <8 x i16> %606
  %610 = lshr <8 x i16> %609, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %611 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %610, <8 x i16> zeroinitializer) #5
  %612 = lshr <8 x i16> %611, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %613 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %599, <8 x i16> %612) #5
  %614 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %613, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %615 = icmp slt <16 x i8> %614, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %616 = select <16 x i1> %615, <16 x i8> %614, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %617 = bitcast i8* %588 to <16 x i8>*
  store <16 x i8> %616, <16 x i8>* %617, align 16
  %618 = getelementptr inbounds i16, i16* %10, i64 304
  %619 = getelementptr inbounds i16, i16* %11, i64 304
  %620 = getelementptr inbounds i8, i8* %524, i64 48
  %621 = bitcast i16* %618 to <8 x i16>*
  %622 = load <8 x i16>, <8 x i16>* %621, align 16
  %623 = bitcast i16* %619 to <8 x i16>*
  %624 = load <8 x i16>, <8 x i16>* %623, align 16
  %625 = sub <8 x i16> %622, %624
  %626 = sub <8 x i16> zeroinitializer, %625
  %627 = icmp slt <8 x i16> %625, zeroinitializer
  %628 = select <8 x i1> %627, <8 x i16> %626, <8 x i16> %625
  %629 = lshr <8 x i16> %628, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %630 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %629, <8 x i16> zeroinitializer) #5
  %631 = lshr <8 x i16> %630, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %632 = getelementptr inbounds i16, i16* %10, i64 312
  %633 = bitcast i16* %632 to <8 x i16>*
  %634 = load <8 x i16>, <8 x i16>* %633, align 16
  %635 = getelementptr inbounds i16, i16* %11, i64 312
  %636 = bitcast i16* %635 to <8 x i16>*
  %637 = load <8 x i16>, <8 x i16>* %636, align 16
  %638 = sub <8 x i16> %634, %637
  %639 = sub <8 x i16> zeroinitializer, %638
  %640 = icmp slt <8 x i16> %638, zeroinitializer
  %641 = select <8 x i1> %640, <8 x i16> %639, <8 x i16> %638
  %642 = lshr <8 x i16> %641, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %643 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %642, <8 x i16> zeroinitializer) #5
  %644 = lshr <8 x i16> %643, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %645 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %631, <8 x i16> %644) #5
  %646 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %645, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %647 = icmp slt <16 x i8> %646, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %648 = select <16 x i1> %647, <16 x i8> %646, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %649 = bitcast i8* %620 to <16 x i8>*
  store <16 x i8> %648, <16 x i8>* %649, align 16
  %650 = getelementptr inbounds i16, i16* %10, i64 320
  %651 = getelementptr inbounds i16, i16* %11, i64 320
  %652 = getelementptr inbounds i8, i8* %524, i64 64
  %653 = bitcast i16* %650 to <8 x i16>*
  %654 = load <8 x i16>, <8 x i16>* %653, align 16
  %655 = bitcast i16* %651 to <8 x i16>*
  %656 = load <8 x i16>, <8 x i16>* %655, align 16
  %657 = sub <8 x i16> %654, %656
  %658 = sub <8 x i16> zeroinitializer, %657
  %659 = icmp slt <8 x i16> %657, zeroinitializer
  %660 = select <8 x i1> %659, <8 x i16> %658, <8 x i16> %657
  %661 = lshr <8 x i16> %660, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %662 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %661, <8 x i16> zeroinitializer) #5
  %663 = lshr <8 x i16> %662, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %664 = getelementptr inbounds i16, i16* %10, i64 328
  %665 = bitcast i16* %664 to <8 x i16>*
  %666 = load <8 x i16>, <8 x i16>* %665, align 16
  %667 = getelementptr inbounds i16, i16* %11, i64 328
  %668 = bitcast i16* %667 to <8 x i16>*
  %669 = load <8 x i16>, <8 x i16>* %668, align 16
  %670 = sub <8 x i16> %666, %669
  %671 = sub <8 x i16> zeroinitializer, %670
  %672 = icmp slt <8 x i16> %670, zeroinitializer
  %673 = select <8 x i1> %672, <8 x i16> %671, <8 x i16> %670
  %674 = lshr <8 x i16> %673, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %675 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %674, <8 x i16> zeroinitializer) #5
  %676 = lshr <8 x i16> %675, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %677 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %663, <8 x i16> %676) #5
  %678 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %677, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %679 = icmp slt <16 x i8> %678, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %680 = select <16 x i1> %679, <16 x i8> %678, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %681 = bitcast i8* %652 to <16 x i8>*
  store <16 x i8> %680, <16 x i8>* %681, align 16
  %682 = getelementptr inbounds i16, i16* %10, i64 336
  %683 = getelementptr inbounds i16, i16* %11, i64 336
  %684 = getelementptr inbounds i8, i8* %652, i64 16
  %685 = bitcast i16* %682 to <8 x i16>*
  %686 = load <8 x i16>, <8 x i16>* %685, align 16
  %687 = bitcast i16* %683 to <8 x i16>*
  %688 = load <8 x i16>, <8 x i16>* %687, align 16
  %689 = sub <8 x i16> %686, %688
  %690 = sub <8 x i16> zeroinitializer, %689
  %691 = icmp slt <8 x i16> %689, zeroinitializer
  %692 = select <8 x i1> %691, <8 x i16> %690, <8 x i16> %689
  %693 = lshr <8 x i16> %692, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %694 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %693, <8 x i16> zeroinitializer) #5
  %695 = lshr <8 x i16> %694, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %696 = getelementptr inbounds i16, i16* %10, i64 344
  %697 = bitcast i16* %696 to <8 x i16>*
  %698 = load <8 x i16>, <8 x i16>* %697, align 16
  %699 = getelementptr inbounds i16, i16* %11, i64 344
  %700 = bitcast i16* %699 to <8 x i16>*
  %701 = load <8 x i16>, <8 x i16>* %700, align 16
  %702 = sub <8 x i16> %698, %701
  %703 = sub <8 x i16> zeroinitializer, %702
  %704 = icmp slt <8 x i16> %702, zeroinitializer
  %705 = select <8 x i1> %704, <8 x i16> %703, <8 x i16> %702
  %706 = lshr <8 x i16> %705, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %707 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %706, <8 x i16> zeroinitializer) #5
  %708 = lshr <8 x i16> %707, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %709 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %695, <8 x i16> %708) #5
  %710 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %709, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %711 = icmp slt <16 x i8> %710, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %712 = select <16 x i1> %711, <16 x i8> %710, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %713 = bitcast i8* %684 to <16 x i8>*
  store <16 x i8> %712, <16 x i8>* %713, align 16
  %714 = getelementptr inbounds i16, i16* %10, i64 352
  %715 = getelementptr inbounds i16, i16* %11, i64 352
  %716 = getelementptr inbounds i8, i8* %652, i64 32
  %717 = bitcast i16* %714 to <8 x i16>*
  %718 = load <8 x i16>, <8 x i16>* %717, align 16
  %719 = bitcast i16* %715 to <8 x i16>*
  %720 = load <8 x i16>, <8 x i16>* %719, align 16
  %721 = sub <8 x i16> %718, %720
  %722 = sub <8 x i16> zeroinitializer, %721
  %723 = icmp slt <8 x i16> %721, zeroinitializer
  %724 = select <8 x i1> %723, <8 x i16> %722, <8 x i16> %721
  %725 = lshr <8 x i16> %724, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %726 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %725, <8 x i16> zeroinitializer) #5
  %727 = lshr <8 x i16> %726, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %728 = getelementptr inbounds i16, i16* %10, i64 360
  %729 = bitcast i16* %728 to <8 x i16>*
  %730 = load <8 x i16>, <8 x i16>* %729, align 16
  %731 = getelementptr inbounds i16, i16* %11, i64 360
  %732 = bitcast i16* %731 to <8 x i16>*
  %733 = load <8 x i16>, <8 x i16>* %732, align 16
  %734 = sub <8 x i16> %730, %733
  %735 = sub <8 x i16> zeroinitializer, %734
  %736 = icmp slt <8 x i16> %734, zeroinitializer
  %737 = select <8 x i1> %736, <8 x i16> %735, <8 x i16> %734
  %738 = lshr <8 x i16> %737, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %739 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %738, <8 x i16> zeroinitializer) #5
  %740 = lshr <8 x i16> %739, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %741 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %727, <8 x i16> %740) #5
  %742 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %741, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %743 = icmp slt <16 x i8> %742, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %744 = select <16 x i1> %743, <16 x i8> %742, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %745 = bitcast i8* %716 to <16 x i8>*
  store <16 x i8> %744, <16 x i8>* %745, align 16
  %746 = getelementptr inbounds i16, i16* %10, i64 368
  %747 = getelementptr inbounds i16, i16* %11, i64 368
  %748 = getelementptr inbounds i8, i8* %652, i64 48
  %749 = bitcast i16* %746 to <8 x i16>*
  %750 = load <8 x i16>, <8 x i16>* %749, align 16
  %751 = bitcast i16* %747 to <8 x i16>*
  %752 = load <8 x i16>, <8 x i16>* %751, align 16
  %753 = sub <8 x i16> %750, %752
  %754 = sub <8 x i16> zeroinitializer, %753
  %755 = icmp slt <8 x i16> %753, zeroinitializer
  %756 = select <8 x i1> %755, <8 x i16> %754, <8 x i16> %753
  %757 = lshr <8 x i16> %756, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %758 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %757, <8 x i16> zeroinitializer) #5
  %759 = lshr <8 x i16> %758, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %760 = getelementptr inbounds i16, i16* %10, i64 376
  %761 = bitcast i16* %760 to <8 x i16>*
  %762 = load <8 x i16>, <8 x i16>* %761, align 16
  %763 = getelementptr inbounds i16, i16* %11, i64 376
  %764 = bitcast i16* %763 to <8 x i16>*
  %765 = load <8 x i16>, <8 x i16>* %764, align 16
  %766 = sub <8 x i16> %762, %765
  %767 = sub <8 x i16> zeroinitializer, %766
  %768 = icmp slt <8 x i16> %766, zeroinitializer
  %769 = select <8 x i1> %768, <8 x i16> %767, <8 x i16> %766
  %770 = lshr <8 x i16> %769, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %771 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %770, <8 x i16> zeroinitializer) #5
  %772 = lshr <8 x i16> %771, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %773 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %759, <8 x i16> %772) #5
  %774 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %773, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %775 = icmp slt <16 x i8> %774, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %776 = select <16 x i1> %775, <16 x i8> %774, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %777 = bitcast i8* %748 to <16 x i8>*
  store <16 x i8> %776, <16 x i8>* %777, align 16
  %778 = getelementptr inbounds i16, i16* %10, i64 384
  %779 = getelementptr inbounds i16, i16* %11, i64 384
  %780 = getelementptr inbounds i8, i8* %652, i64 %7
  %781 = add nuw nsw i32 %12, 1
  %782 = icmp eq i32 %781, 42
  br i1 %782, label %783, label %8

783:                                              ; preds = %8
  %784 = bitcast i16* %778 to <8 x i16>*
  %785 = load <8 x i16>, <8 x i16>* %784, align 16
  %786 = bitcast i16* %779 to <8 x i16>*
  %787 = load <8 x i16>, <8 x i16>* %786, align 16
  %788 = sub <8 x i16> %785, %787
  %789 = sub <8 x i16> zeroinitializer, %788
  %790 = icmp slt <8 x i16> %788, zeroinitializer
  %791 = select <8 x i1> %790, <8 x i16> %789, <8 x i16> %788
  %792 = lshr <8 x i16> %791, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %793 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %792, <8 x i16> zeroinitializer) #5
  %794 = lshr <8 x i16> %793, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %795 = getelementptr inbounds i16, i16* %10, i64 392
  %796 = bitcast i16* %795 to <8 x i16>*
  %797 = load <8 x i16>, <8 x i16>* %796, align 16
  %798 = getelementptr inbounds i16, i16* %11, i64 392
  %799 = bitcast i16* %798 to <8 x i16>*
  %800 = load <8 x i16>, <8 x i16>* %799, align 16
  %801 = sub <8 x i16> %797, %800
  %802 = sub <8 x i16> zeroinitializer, %801
  %803 = icmp slt <8 x i16> %801, zeroinitializer
  %804 = select <8 x i1> %803, <8 x i16> %802, <8 x i16> %801
  %805 = lshr <8 x i16> %804, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %806 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %805, <8 x i16> zeroinitializer) #5
  %807 = lshr <8 x i16> %806, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %808 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %794, <8 x i16> %807) #5
  %809 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %808, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %810 = icmp slt <16 x i8> %809, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %811 = select <16 x i1> %810, <16 x i8> %809, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %812 = bitcast i8* %780 to <16 x i8>*
  store <16 x i8> %811, <16 x i8>* %812, align 16
  %813 = getelementptr inbounds i16, i16* %10, i64 400
  %814 = getelementptr inbounds i16, i16* %11, i64 400
  %815 = getelementptr inbounds i8, i8* %780, i64 16
  %816 = bitcast i16* %813 to <8 x i16>*
  %817 = load <8 x i16>, <8 x i16>* %816, align 16
  %818 = bitcast i16* %814 to <8 x i16>*
  %819 = load <8 x i16>, <8 x i16>* %818, align 16
  %820 = sub <8 x i16> %817, %819
  %821 = sub <8 x i16> zeroinitializer, %820
  %822 = icmp slt <8 x i16> %820, zeroinitializer
  %823 = select <8 x i1> %822, <8 x i16> %821, <8 x i16> %820
  %824 = lshr <8 x i16> %823, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %825 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %824, <8 x i16> zeroinitializer) #5
  %826 = lshr <8 x i16> %825, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %827 = getelementptr inbounds i16, i16* %10, i64 408
  %828 = bitcast i16* %827 to <8 x i16>*
  %829 = load <8 x i16>, <8 x i16>* %828, align 16
  %830 = getelementptr inbounds i16, i16* %11, i64 408
  %831 = bitcast i16* %830 to <8 x i16>*
  %832 = load <8 x i16>, <8 x i16>* %831, align 16
  %833 = sub <8 x i16> %829, %832
  %834 = sub <8 x i16> zeroinitializer, %833
  %835 = icmp slt <8 x i16> %833, zeroinitializer
  %836 = select <8 x i1> %835, <8 x i16> %834, <8 x i16> %833
  %837 = lshr <8 x i16> %836, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %838 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %837, <8 x i16> zeroinitializer) #5
  %839 = lshr <8 x i16> %838, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %840 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %826, <8 x i16> %839) #5
  %841 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %840, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %842 = icmp slt <16 x i8> %841, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %843 = select <16 x i1> %842, <16 x i8> %841, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %844 = bitcast i8* %815 to <16 x i8>*
  store <16 x i8> %843, <16 x i8>* %844, align 16
  %845 = getelementptr inbounds i16, i16* %10, i64 416
  %846 = getelementptr inbounds i16, i16* %11, i64 416
  %847 = getelementptr inbounds i8, i8* %780, i64 32
  %848 = bitcast i16* %845 to <8 x i16>*
  %849 = load <8 x i16>, <8 x i16>* %848, align 16
  %850 = bitcast i16* %846 to <8 x i16>*
  %851 = load <8 x i16>, <8 x i16>* %850, align 16
  %852 = sub <8 x i16> %849, %851
  %853 = sub <8 x i16> zeroinitializer, %852
  %854 = icmp slt <8 x i16> %852, zeroinitializer
  %855 = select <8 x i1> %854, <8 x i16> %853, <8 x i16> %852
  %856 = lshr <8 x i16> %855, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %857 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %856, <8 x i16> zeroinitializer) #5
  %858 = lshr <8 x i16> %857, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %859 = getelementptr inbounds i16, i16* %10, i64 424
  %860 = bitcast i16* %859 to <8 x i16>*
  %861 = load <8 x i16>, <8 x i16>* %860, align 16
  %862 = getelementptr inbounds i16, i16* %11, i64 424
  %863 = bitcast i16* %862 to <8 x i16>*
  %864 = load <8 x i16>, <8 x i16>* %863, align 16
  %865 = sub <8 x i16> %861, %864
  %866 = sub <8 x i16> zeroinitializer, %865
  %867 = icmp slt <8 x i16> %865, zeroinitializer
  %868 = select <8 x i1> %867, <8 x i16> %866, <8 x i16> %865
  %869 = lshr <8 x i16> %868, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %870 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %869, <8 x i16> zeroinitializer) #5
  %871 = lshr <8 x i16> %870, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %872 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %858, <8 x i16> %871) #5
  %873 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %872, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %874 = icmp slt <16 x i8> %873, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %875 = select <16 x i1> %874, <16 x i8> %873, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %876 = bitcast i8* %847 to <16 x i8>*
  store <16 x i8> %875, <16 x i8>* %876, align 16
  %877 = getelementptr inbounds i16, i16* %10, i64 432
  %878 = getelementptr inbounds i16, i16* %11, i64 432
  %879 = getelementptr inbounds i8, i8* %780, i64 48
  %880 = bitcast i16* %877 to <8 x i16>*
  %881 = load <8 x i16>, <8 x i16>* %880, align 16
  %882 = bitcast i16* %878 to <8 x i16>*
  %883 = load <8 x i16>, <8 x i16>* %882, align 16
  %884 = sub <8 x i16> %881, %883
  %885 = sub <8 x i16> zeroinitializer, %884
  %886 = icmp slt <8 x i16> %884, zeroinitializer
  %887 = select <8 x i1> %886, <8 x i16> %885, <8 x i16> %884
  %888 = lshr <8 x i16> %887, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %889 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %888, <8 x i16> zeroinitializer) #5
  %890 = lshr <8 x i16> %889, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %891 = getelementptr inbounds i16, i16* %10, i64 440
  %892 = bitcast i16* %891 to <8 x i16>*
  %893 = load <8 x i16>, <8 x i16>* %892, align 16
  %894 = getelementptr inbounds i16, i16* %11, i64 440
  %895 = bitcast i16* %894 to <8 x i16>*
  %896 = load <8 x i16>, <8 x i16>* %895, align 16
  %897 = sub <8 x i16> %893, %896
  %898 = sub <8 x i16> zeroinitializer, %897
  %899 = icmp slt <8 x i16> %897, zeroinitializer
  %900 = select <8 x i1> %899, <8 x i16> %898, <8 x i16> %897
  %901 = lshr <8 x i16> %900, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %902 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %901, <8 x i16> zeroinitializer) #5
  %903 = lshr <8 x i16> %902, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %904 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %890, <8 x i16> %903) #5
  %905 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %904, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %906 = icmp slt <16 x i8> %905, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %907 = select <16 x i1> %906, <16 x i8> %905, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %908 = bitcast i8* %879 to <16 x i8>*
  store <16 x i8> %907, <16 x i8>* %908, align 16
  %909 = getelementptr inbounds i16, i16* %10, i64 448
  %910 = getelementptr inbounds i16, i16* %11, i64 448
  %911 = getelementptr inbounds i8, i8* %780, i64 64
  %912 = bitcast i16* %909 to <8 x i16>*
  %913 = load <8 x i16>, <8 x i16>* %912, align 16
  %914 = bitcast i16* %910 to <8 x i16>*
  %915 = load <8 x i16>, <8 x i16>* %914, align 16
  %916 = sub <8 x i16> %913, %915
  %917 = sub <8 x i16> zeroinitializer, %916
  %918 = icmp slt <8 x i16> %916, zeroinitializer
  %919 = select <8 x i1> %918, <8 x i16> %917, <8 x i16> %916
  %920 = lshr <8 x i16> %919, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %921 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %920, <8 x i16> zeroinitializer) #5
  %922 = lshr <8 x i16> %921, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %923 = getelementptr inbounds i16, i16* %10, i64 456
  %924 = bitcast i16* %923 to <8 x i16>*
  %925 = load <8 x i16>, <8 x i16>* %924, align 16
  %926 = getelementptr inbounds i16, i16* %11, i64 456
  %927 = bitcast i16* %926 to <8 x i16>*
  %928 = load <8 x i16>, <8 x i16>* %927, align 16
  %929 = sub <8 x i16> %925, %928
  %930 = sub <8 x i16> zeroinitializer, %929
  %931 = icmp slt <8 x i16> %929, zeroinitializer
  %932 = select <8 x i1> %931, <8 x i16> %930, <8 x i16> %929
  %933 = lshr <8 x i16> %932, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %934 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %933, <8 x i16> zeroinitializer) #5
  %935 = lshr <8 x i16> %934, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %936 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %922, <8 x i16> %935) #5
  %937 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %936, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %938 = icmp slt <16 x i8> %937, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %939 = select <16 x i1> %938, <16 x i8> %937, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %940 = bitcast i8* %911 to <16 x i8>*
  store <16 x i8> %939, <16 x i8>* %940, align 16
  %941 = getelementptr inbounds i16, i16* %10, i64 464
  %942 = getelementptr inbounds i16, i16* %11, i64 464
  %943 = getelementptr inbounds i8, i8* %911, i64 16
  %944 = bitcast i16* %941 to <8 x i16>*
  %945 = load <8 x i16>, <8 x i16>* %944, align 16
  %946 = bitcast i16* %942 to <8 x i16>*
  %947 = load <8 x i16>, <8 x i16>* %946, align 16
  %948 = sub <8 x i16> %945, %947
  %949 = sub <8 x i16> zeroinitializer, %948
  %950 = icmp slt <8 x i16> %948, zeroinitializer
  %951 = select <8 x i1> %950, <8 x i16> %949, <8 x i16> %948
  %952 = lshr <8 x i16> %951, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %953 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %952, <8 x i16> zeroinitializer) #5
  %954 = lshr <8 x i16> %953, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %955 = getelementptr inbounds i16, i16* %10, i64 472
  %956 = bitcast i16* %955 to <8 x i16>*
  %957 = load <8 x i16>, <8 x i16>* %956, align 16
  %958 = getelementptr inbounds i16, i16* %11, i64 472
  %959 = bitcast i16* %958 to <8 x i16>*
  %960 = load <8 x i16>, <8 x i16>* %959, align 16
  %961 = sub <8 x i16> %957, %960
  %962 = sub <8 x i16> zeroinitializer, %961
  %963 = icmp slt <8 x i16> %961, zeroinitializer
  %964 = select <8 x i1> %963, <8 x i16> %962, <8 x i16> %961
  %965 = lshr <8 x i16> %964, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %966 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %965, <8 x i16> zeroinitializer) #5
  %967 = lshr <8 x i16> %966, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %968 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %954, <8 x i16> %967) #5
  %969 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %968, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %970 = icmp slt <16 x i8> %969, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %971 = select <16 x i1> %970, <16 x i8> %969, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %972 = bitcast i8* %943 to <16 x i8>*
  store <16 x i8> %971, <16 x i8>* %972, align 16
  %973 = getelementptr inbounds i16, i16* %10, i64 480
  %974 = getelementptr inbounds i16, i16* %11, i64 480
  %975 = getelementptr inbounds i8, i8* %911, i64 32
  %976 = bitcast i16* %973 to <8 x i16>*
  %977 = load <8 x i16>, <8 x i16>* %976, align 16
  %978 = bitcast i16* %974 to <8 x i16>*
  %979 = load <8 x i16>, <8 x i16>* %978, align 16
  %980 = sub <8 x i16> %977, %979
  %981 = sub <8 x i16> zeroinitializer, %980
  %982 = icmp slt <8 x i16> %980, zeroinitializer
  %983 = select <8 x i1> %982, <8 x i16> %981, <8 x i16> %980
  %984 = lshr <8 x i16> %983, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %985 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %984, <8 x i16> zeroinitializer) #5
  %986 = lshr <8 x i16> %985, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %987 = getelementptr inbounds i16, i16* %10, i64 488
  %988 = bitcast i16* %987 to <8 x i16>*
  %989 = load <8 x i16>, <8 x i16>* %988, align 16
  %990 = getelementptr inbounds i16, i16* %11, i64 488
  %991 = bitcast i16* %990 to <8 x i16>*
  %992 = load <8 x i16>, <8 x i16>* %991, align 16
  %993 = sub <8 x i16> %989, %992
  %994 = sub <8 x i16> zeroinitializer, %993
  %995 = icmp slt <8 x i16> %993, zeroinitializer
  %996 = select <8 x i1> %995, <8 x i16> %994, <8 x i16> %993
  %997 = lshr <8 x i16> %996, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %998 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %997, <8 x i16> zeroinitializer) #5
  %999 = lshr <8 x i16> %998, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1000 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %986, <8 x i16> %999) #5
  %1001 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1000, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1002 = icmp slt <16 x i8> %1001, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1003 = select <16 x i1> %1002, <16 x i8> %1001, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1004 = bitcast i8* %975 to <16 x i8>*
  store <16 x i8> %1003, <16 x i8>* %1004, align 16
  %1005 = getelementptr inbounds i16, i16* %10, i64 496
  %1006 = getelementptr inbounds i16, i16* %11, i64 496
  %1007 = getelementptr inbounds i8, i8* %911, i64 48
  %1008 = bitcast i16* %1005 to <8 x i16>*
  %1009 = load <8 x i16>, <8 x i16>* %1008, align 16
  %1010 = bitcast i16* %1006 to <8 x i16>*
  %1011 = load <8 x i16>, <8 x i16>* %1010, align 16
  %1012 = sub <8 x i16> %1009, %1011
  %1013 = sub <8 x i16> zeroinitializer, %1012
  %1014 = icmp slt <8 x i16> %1012, zeroinitializer
  %1015 = select <8 x i1> %1014, <8 x i16> %1013, <8 x i16> %1012
  %1016 = lshr <8 x i16> %1015, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1017 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1016, <8 x i16> zeroinitializer) #5
  %1018 = lshr <8 x i16> %1017, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1019 = getelementptr inbounds i16, i16* %10, i64 504
  %1020 = bitcast i16* %1019 to <8 x i16>*
  %1021 = load <8 x i16>, <8 x i16>* %1020, align 16
  %1022 = getelementptr inbounds i16, i16* %11, i64 504
  %1023 = bitcast i16* %1022 to <8 x i16>*
  %1024 = load <8 x i16>, <8 x i16>* %1023, align 16
  %1025 = sub <8 x i16> %1021, %1024
  %1026 = sub <8 x i16> zeroinitializer, %1025
  %1027 = icmp slt <8 x i16> %1025, zeroinitializer
  %1028 = select <8 x i1> %1027, <8 x i16> %1026, <8 x i16> %1025
  %1029 = lshr <8 x i16> %1028, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1030 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1029, <8 x i16> zeroinitializer) #5
  %1031 = lshr <8 x i16> %1030, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1032 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1018, <8 x i16> %1031) #5
  %1033 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1032, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1034 = icmp slt <16 x i8> %1033, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1035 = select <16 x i1> %1034, <16 x i8> %1033, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1036 = bitcast i8* %1007 to <16 x i8>*
  store <16 x i8> %1035, <16 x i8>* %1036, align 16
  %1037 = getelementptr inbounds i16, i16* %10, i64 512
  %1038 = getelementptr inbounds i16, i16* %11, i64 512
  %1039 = getelementptr inbounds i8, i8* %911, i64 %7
  %1040 = bitcast i16* %1037 to <8 x i16>*
  %1041 = load <8 x i16>, <8 x i16>* %1040, align 16
  %1042 = bitcast i16* %1038 to <8 x i16>*
  %1043 = load <8 x i16>, <8 x i16>* %1042, align 16
  %1044 = sub <8 x i16> %1041, %1043
  %1045 = sub <8 x i16> zeroinitializer, %1044
  %1046 = icmp slt <8 x i16> %1044, zeroinitializer
  %1047 = select <8 x i1> %1046, <8 x i16> %1045, <8 x i16> %1044
  %1048 = lshr <8 x i16> %1047, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1049 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1048, <8 x i16> zeroinitializer) #5
  %1050 = lshr <8 x i16> %1049, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1051 = getelementptr inbounds i16, i16* %10, i64 520
  %1052 = bitcast i16* %1051 to <8 x i16>*
  %1053 = load <8 x i16>, <8 x i16>* %1052, align 16
  %1054 = getelementptr inbounds i16, i16* %11, i64 520
  %1055 = bitcast i16* %1054 to <8 x i16>*
  %1056 = load <8 x i16>, <8 x i16>* %1055, align 16
  %1057 = sub <8 x i16> %1053, %1056
  %1058 = sub <8 x i16> zeroinitializer, %1057
  %1059 = icmp slt <8 x i16> %1057, zeroinitializer
  %1060 = select <8 x i1> %1059, <8 x i16> %1058, <8 x i16> %1057
  %1061 = lshr <8 x i16> %1060, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1062 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1061, <8 x i16> zeroinitializer) #5
  %1063 = lshr <8 x i16> %1062, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1064 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1050, <8 x i16> %1063) #5
  %1065 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1064, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1066 = icmp slt <16 x i8> %1065, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1067 = select <16 x i1> %1066, <16 x i8> %1065, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1068 = bitcast i8* %1039 to <16 x i8>*
  store <16 x i8> %1067, <16 x i8>* %1068, align 16
  %1069 = getelementptr inbounds i16, i16* %10, i64 528
  %1070 = getelementptr inbounds i16, i16* %11, i64 528
  %1071 = getelementptr inbounds i8, i8* %1039, i64 16
  %1072 = bitcast i16* %1069 to <8 x i16>*
  %1073 = load <8 x i16>, <8 x i16>* %1072, align 16
  %1074 = bitcast i16* %1070 to <8 x i16>*
  %1075 = load <8 x i16>, <8 x i16>* %1074, align 16
  %1076 = sub <8 x i16> %1073, %1075
  %1077 = sub <8 x i16> zeroinitializer, %1076
  %1078 = icmp slt <8 x i16> %1076, zeroinitializer
  %1079 = select <8 x i1> %1078, <8 x i16> %1077, <8 x i16> %1076
  %1080 = lshr <8 x i16> %1079, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1081 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1080, <8 x i16> zeroinitializer) #5
  %1082 = lshr <8 x i16> %1081, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1083 = getelementptr inbounds i16, i16* %10, i64 536
  %1084 = bitcast i16* %1083 to <8 x i16>*
  %1085 = load <8 x i16>, <8 x i16>* %1084, align 16
  %1086 = getelementptr inbounds i16, i16* %11, i64 536
  %1087 = bitcast i16* %1086 to <8 x i16>*
  %1088 = load <8 x i16>, <8 x i16>* %1087, align 16
  %1089 = sub <8 x i16> %1085, %1088
  %1090 = sub <8 x i16> zeroinitializer, %1089
  %1091 = icmp slt <8 x i16> %1089, zeroinitializer
  %1092 = select <8 x i1> %1091, <8 x i16> %1090, <8 x i16> %1089
  %1093 = lshr <8 x i16> %1092, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1094 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1093, <8 x i16> zeroinitializer) #5
  %1095 = lshr <8 x i16> %1094, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1096 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1082, <8 x i16> %1095) #5
  %1097 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1096, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1098 = icmp slt <16 x i8> %1097, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1099 = select <16 x i1> %1098, <16 x i8> %1097, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1100 = bitcast i8* %1071 to <16 x i8>*
  store <16 x i8> %1099, <16 x i8>* %1100, align 16
  %1101 = getelementptr inbounds i16, i16* %10, i64 544
  %1102 = getelementptr inbounds i16, i16* %11, i64 544
  %1103 = getelementptr inbounds i8, i8* %1039, i64 32
  %1104 = bitcast i16* %1101 to <8 x i16>*
  %1105 = load <8 x i16>, <8 x i16>* %1104, align 16
  %1106 = bitcast i16* %1102 to <8 x i16>*
  %1107 = load <8 x i16>, <8 x i16>* %1106, align 16
  %1108 = sub <8 x i16> %1105, %1107
  %1109 = sub <8 x i16> zeroinitializer, %1108
  %1110 = icmp slt <8 x i16> %1108, zeroinitializer
  %1111 = select <8 x i1> %1110, <8 x i16> %1109, <8 x i16> %1108
  %1112 = lshr <8 x i16> %1111, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1113 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1112, <8 x i16> zeroinitializer) #5
  %1114 = lshr <8 x i16> %1113, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1115 = getelementptr inbounds i16, i16* %10, i64 552
  %1116 = bitcast i16* %1115 to <8 x i16>*
  %1117 = load <8 x i16>, <8 x i16>* %1116, align 16
  %1118 = getelementptr inbounds i16, i16* %11, i64 552
  %1119 = bitcast i16* %1118 to <8 x i16>*
  %1120 = load <8 x i16>, <8 x i16>* %1119, align 16
  %1121 = sub <8 x i16> %1117, %1120
  %1122 = sub <8 x i16> zeroinitializer, %1121
  %1123 = icmp slt <8 x i16> %1121, zeroinitializer
  %1124 = select <8 x i1> %1123, <8 x i16> %1122, <8 x i16> %1121
  %1125 = lshr <8 x i16> %1124, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1126 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1125, <8 x i16> zeroinitializer) #5
  %1127 = lshr <8 x i16> %1126, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1128 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1114, <8 x i16> %1127) #5
  %1129 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1128, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1130 = icmp slt <16 x i8> %1129, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1131 = select <16 x i1> %1130, <16 x i8> %1129, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1132 = bitcast i8* %1103 to <16 x i8>*
  store <16 x i8> %1131, <16 x i8>* %1132, align 16
  %1133 = getelementptr inbounds i16, i16* %10, i64 560
  %1134 = getelementptr inbounds i16, i16* %11, i64 560
  %1135 = getelementptr inbounds i8, i8* %1039, i64 48
  %1136 = bitcast i16* %1133 to <8 x i16>*
  %1137 = load <8 x i16>, <8 x i16>* %1136, align 16
  %1138 = bitcast i16* %1134 to <8 x i16>*
  %1139 = load <8 x i16>, <8 x i16>* %1138, align 16
  %1140 = sub <8 x i16> %1137, %1139
  %1141 = sub <8 x i16> zeroinitializer, %1140
  %1142 = icmp slt <8 x i16> %1140, zeroinitializer
  %1143 = select <8 x i1> %1142, <8 x i16> %1141, <8 x i16> %1140
  %1144 = lshr <8 x i16> %1143, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1145 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1144, <8 x i16> zeroinitializer) #5
  %1146 = lshr <8 x i16> %1145, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1147 = getelementptr inbounds i16, i16* %10, i64 568
  %1148 = bitcast i16* %1147 to <8 x i16>*
  %1149 = load <8 x i16>, <8 x i16>* %1148, align 16
  %1150 = getelementptr inbounds i16, i16* %11, i64 568
  %1151 = bitcast i16* %1150 to <8 x i16>*
  %1152 = load <8 x i16>, <8 x i16>* %1151, align 16
  %1153 = sub <8 x i16> %1149, %1152
  %1154 = sub <8 x i16> zeroinitializer, %1153
  %1155 = icmp slt <8 x i16> %1153, zeroinitializer
  %1156 = select <8 x i1> %1155, <8 x i16> %1154, <8 x i16> %1153
  %1157 = lshr <8 x i16> %1156, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1158 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1157, <8 x i16> zeroinitializer) #5
  %1159 = lshr <8 x i16> %1158, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1160 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1146, <8 x i16> %1159) #5
  %1161 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1160, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1162 = icmp slt <16 x i8> %1161, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1163 = select <16 x i1> %1162, <16 x i8> %1161, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1164 = bitcast i8* %1135 to <16 x i8>*
  store <16 x i8> %1163, <16 x i8>* %1164, align 16
  %1165 = getelementptr inbounds i16, i16* %10, i64 576
  %1166 = getelementptr inbounds i16, i16* %11, i64 576
  %1167 = getelementptr inbounds i8, i8* %1039, i64 64
  %1168 = bitcast i16* %1165 to <8 x i16>*
  %1169 = load <8 x i16>, <8 x i16>* %1168, align 16
  %1170 = bitcast i16* %1166 to <8 x i16>*
  %1171 = load <8 x i16>, <8 x i16>* %1170, align 16
  %1172 = sub <8 x i16> %1169, %1171
  %1173 = sub <8 x i16> zeroinitializer, %1172
  %1174 = icmp slt <8 x i16> %1172, zeroinitializer
  %1175 = select <8 x i1> %1174, <8 x i16> %1173, <8 x i16> %1172
  %1176 = lshr <8 x i16> %1175, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1177 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1176, <8 x i16> zeroinitializer) #5
  %1178 = lshr <8 x i16> %1177, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1179 = getelementptr inbounds i16, i16* %10, i64 584
  %1180 = bitcast i16* %1179 to <8 x i16>*
  %1181 = load <8 x i16>, <8 x i16>* %1180, align 16
  %1182 = getelementptr inbounds i16, i16* %11, i64 584
  %1183 = bitcast i16* %1182 to <8 x i16>*
  %1184 = load <8 x i16>, <8 x i16>* %1183, align 16
  %1185 = sub <8 x i16> %1181, %1184
  %1186 = sub <8 x i16> zeroinitializer, %1185
  %1187 = icmp slt <8 x i16> %1185, zeroinitializer
  %1188 = select <8 x i1> %1187, <8 x i16> %1186, <8 x i16> %1185
  %1189 = lshr <8 x i16> %1188, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1190 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1189, <8 x i16> zeroinitializer) #5
  %1191 = lshr <8 x i16> %1190, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1192 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1178, <8 x i16> %1191) #5
  %1193 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1192, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1194 = icmp slt <16 x i8> %1193, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1195 = select <16 x i1> %1194, <16 x i8> %1193, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1196 = bitcast i8* %1167 to <16 x i8>*
  store <16 x i8> %1195, <16 x i8>* %1196, align 16
  %1197 = getelementptr inbounds i16, i16* %10, i64 592
  %1198 = getelementptr inbounds i16, i16* %11, i64 592
  %1199 = getelementptr inbounds i8, i8* %1167, i64 16
  %1200 = bitcast i16* %1197 to <8 x i16>*
  %1201 = load <8 x i16>, <8 x i16>* %1200, align 16
  %1202 = bitcast i16* %1198 to <8 x i16>*
  %1203 = load <8 x i16>, <8 x i16>* %1202, align 16
  %1204 = sub <8 x i16> %1201, %1203
  %1205 = sub <8 x i16> zeroinitializer, %1204
  %1206 = icmp slt <8 x i16> %1204, zeroinitializer
  %1207 = select <8 x i1> %1206, <8 x i16> %1205, <8 x i16> %1204
  %1208 = lshr <8 x i16> %1207, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1209 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1208, <8 x i16> zeroinitializer) #5
  %1210 = lshr <8 x i16> %1209, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1211 = getelementptr inbounds i16, i16* %10, i64 600
  %1212 = bitcast i16* %1211 to <8 x i16>*
  %1213 = load <8 x i16>, <8 x i16>* %1212, align 16
  %1214 = getelementptr inbounds i16, i16* %11, i64 600
  %1215 = bitcast i16* %1214 to <8 x i16>*
  %1216 = load <8 x i16>, <8 x i16>* %1215, align 16
  %1217 = sub <8 x i16> %1213, %1216
  %1218 = sub <8 x i16> zeroinitializer, %1217
  %1219 = icmp slt <8 x i16> %1217, zeroinitializer
  %1220 = select <8 x i1> %1219, <8 x i16> %1218, <8 x i16> %1217
  %1221 = lshr <8 x i16> %1220, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1222 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1221, <8 x i16> zeroinitializer) #5
  %1223 = lshr <8 x i16> %1222, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1224 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1210, <8 x i16> %1223) #5
  %1225 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1224, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1226 = icmp slt <16 x i8> %1225, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1227 = select <16 x i1> %1226, <16 x i8> %1225, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1228 = bitcast i8* %1199 to <16 x i8>*
  store <16 x i8> %1227, <16 x i8>* %1228, align 16
  %1229 = getelementptr inbounds i16, i16* %10, i64 608
  %1230 = getelementptr inbounds i16, i16* %11, i64 608
  %1231 = getelementptr inbounds i8, i8* %1167, i64 32
  %1232 = bitcast i16* %1229 to <8 x i16>*
  %1233 = load <8 x i16>, <8 x i16>* %1232, align 16
  %1234 = bitcast i16* %1230 to <8 x i16>*
  %1235 = load <8 x i16>, <8 x i16>* %1234, align 16
  %1236 = sub <8 x i16> %1233, %1235
  %1237 = sub <8 x i16> zeroinitializer, %1236
  %1238 = icmp slt <8 x i16> %1236, zeroinitializer
  %1239 = select <8 x i1> %1238, <8 x i16> %1237, <8 x i16> %1236
  %1240 = lshr <8 x i16> %1239, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1241 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1240, <8 x i16> zeroinitializer) #5
  %1242 = lshr <8 x i16> %1241, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1243 = getelementptr inbounds i16, i16* %10, i64 616
  %1244 = bitcast i16* %1243 to <8 x i16>*
  %1245 = load <8 x i16>, <8 x i16>* %1244, align 16
  %1246 = getelementptr inbounds i16, i16* %11, i64 616
  %1247 = bitcast i16* %1246 to <8 x i16>*
  %1248 = load <8 x i16>, <8 x i16>* %1247, align 16
  %1249 = sub <8 x i16> %1245, %1248
  %1250 = sub <8 x i16> zeroinitializer, %1249
  %1251 = icmp slt <8 x i16> %1249, zeroinitializer
  %1252 = select <8 x i1> %1251, <8 x i16> %1250, <8 x i16> %1249
  %1253 = lshr <8 x i16> %1252, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1254 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1253, <8 x i16> zeroinitializer) #5
  %1255 = lshr <8 x i16> %1254, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1256 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1242, <8 x i16> %1255) #5
  %1257 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1256, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1258 = icmp slt <16 x i8> %1257, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1259 = select <16 x i1> %1258, <16 x i8> %1257, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1260 = bitcast i8* %1231 to <16 x i8>*
  store <16 x i8> %1259, <16 x i8>* %1260, align 16
  %1261 = getelementptr inbounds i16, i16* %10, i64 624
  %1262 = getelementptr inbounds i16, i16* %11, i64 624
  %1263 = getelementptr inbounds i8, i8* %1167, i64 48
  %1264 = bitcast i16* %1261 to <8 x i16>*
  %1265 = load <8 x i16>, <8 x i16>* %1264, align 16
  %1266 = bitcast i16* %1262 to <8 x i16>*
  %1267 = load <8 x i16>, <8 x i16>* %1266, align 16
  %1268 = sub <8 x i16> %1265, %1267
  %1269 = sub <8 x i16> zeroinitializer, %1268
  %1270 = icmp slt <8 x i16> %1268, zeroinitializer
  %1271 = select <8 x i1> %1270, <8 x i16> %1269, <8 x i16> %1268
  %1272 = lshr <8 x i16> %1271, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1273 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1272, <8 x i16> zeroinitializer) #5
  %1274 = lshr <8 x i16> %1273, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1275 = getelementptr inbounds i16, i16* %10, i64 632
  %1276 = bitcast i16* %1275 to <8 x i16>*
  %1277 = load <8 x i16>, <8 x i16>* %1276, align 16
  %1278 = getelementptr inbounds i16, i16* %11, i64 632
  %1279 = bitcast i16* %1278 to <8 x i16>*
  %1280 = load <8 x i16>, <8 x i16>* %1279, align 16
  %1281 = sub <8 x i16> %1277, %1280
  %1282 = sub <8 x i16> zeroinitializer, %1281
  %1283 = icmp slt <8 x i16> %1281, zeroinitializer
  %1284 = select <8 x i1> %1283, <8 x i16> %1282, <8 x i16> %1281
  %1285 = lshr <8 x i16> %1284, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1286 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1285, <8 x i16> zeroinitializer) #5
  %1287 = lshr <8 x i16> %1286, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1288 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1274, <8 x i16> %1287) #5
  %1289 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1288, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1290 = icmp slt <16 x i8> %1289, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1291 = select <16 x i1> %1290, <16 x i8> %1289, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1292 = bitcast i8* %1263 to <16 x i8>*
  store <16 x i8> %1291, <16 x i8>* %1292, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp12low_bitdepth12_GLOBAL__N_122WeightMask128x128_SSE4ILb1EEEvPKvS5_Phl(i8* readonly, i8* readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  %7 = add nsw i64 %3, -64
  br label %8

8:                                                ; preds = %8, %4
  %9 = phi i8* [ %2, %4 ], [ %804, %8 ]
  %10 = phi i16* [ %5, %4 ], [ %802, %8 ]
  %11 = phi i16* [ %6, %4 ], [ %803, %8 ]
  %12 = phi i32 [ 0, %4 ], [ %805, %8 ]
  %13 = bitcast i16* %10 to <8 x i16>*
  %14 = load <8 x i16>, <8 x i16>* %13, align 16
  %15 = bitcast i16* %11 to <8 x i16>*
  %16 = load <8 x i16>, <8 x i16>* %15, align 16
  %17 = sub <8 x i16> %14, %16
  %18 = sub <8 x i16> zeroinitializer, %17
  %19 = icmp slt <8 x i16> %17, zeroinitializer
  %20 = select <8 x i1> %19, <8 x i16> %18, <8 x i16> %17
  %21 = lshr <8 x i16> %20, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %22 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %21, <8 x i16> zeroinitializer) #5
  %23 = lshr <8 x i16> %22, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %24 = getelementptr inbounds i16, i16* %10, i64 8
  %25 = bitcast i16* %24 to <8 x i16>*
  %26 = load <8 x i16>, <8 x i16>* %25, align 16
  %27 = getelementptr inbounds i16, i16* %11, i64 8
  %28 = bitcast i16* %27 to <8 x i16>*
  %29 = load <8 x i16>, <8 x i16>* %28, align 16
  %30 = sub <8 x i16> %26, %29
  %31 = sub <8 x i16> zeroinitializer, %30
  %32 = icmp slt <8 x i16> %30, zeroinitializer
  %33 = select <8 x i1> %32, <8 x i16> %31, <8 x i16> %30
  %34 = lshr <8 x i16> %33, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %35 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %34, <8 x i16> zeroinitializer) #5
  %36 = lshr <8 x i16> %35, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %37 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %23, <8 x i16> %36) #5
  %38 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %37, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %39 = icmp slt <16 x i8> %38, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %40 = select <16 x i1> %39, <16 x i8> %38, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %41 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %40
  %42 = bitcast i8* %9 to <16 x i8>*
  store <16 x i8> %41, <16 x i8>* %42, align 16
  %43 = getelementptr inbounds i16, i16* %10, i64 16
  %44 = getelementptr inbounds i16, i16* %11, i64 16
  %45 = getelementptr inbounds i8, i8* %9, i64 16
  %46 = bitcast i16* %43 to <8 x i16>*
  %47 = load <8 x i16>, <8 x i16>* %46, align 16
  %48 = bitcast i16* %44 to <8 x i16>*
  %49 = load <8 x i16>, <8 x i16>* %48, align 16
  %50 = sub <8 x i16> %47, %49
  %51 = sub <8 x i16> zeroinitializer, %50
  %52 = icmp slt <8 x i16> %50, zeroinitializer
  %53 = select <8 x i1> %52, <8 x i16> %51, <8 x i16> %50
  %54 = lshr <8 x i16> %53, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %55 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %54, <8 x i16> zeroinitializer) #5
  %56 = lshr <8 x i16> %55, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %57 = getelementptr inbounds i16, i16* %10, i64 24
  %58 = bitcast i16* %57 to <8 x i16>*
  %59 = load <8 x i16>, <8 x i16>* %58, align 16
  %60 = getelementptr inbounds i16, i16* %11, i64 24
  %61 = bitcast i16* %60 to <8 x i16>*
  %62 = load <8 x i16>, <8 x i16>* %61, align 16
  %63 = sub <8 x i16> %59, %62
  %64 = sub <8 x i16> zeroinitializer, %63
  %65 = icmp slt <8 x i16> %63, zeroinitializer
  %66 = select <8 x i1> %65, <8 x i16> %64, <8 x i16> %63
  %67 = lshr <8 x i16> %66, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %68 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %67, <8 x i16> zeroinitializer) #5
  %69 = lshr <8 x i16> %68, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %70 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %56, <8 x i16> %69) #5
  %71 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %70, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %72 = icmp slt <16 x i8> %71, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %73 = select <16 x i1> %72, <16 x i8> %71, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %74 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %73
  %75 = bitcast i8* %45 to <16 x i8>*
  store <16 x i8> %74, <16 x i8>* %75, align 16
  %76 = getelementptr inbounds i16, i16* %10, i64 32
  %77 = getelementptr inbounds i16, i16* %11, i64 32
  %78 = getelementptr inbounds i8, i8* %9, i64 32
  %79 = bitcast i16* %76 to <8 x i16>*
  %80 = load <8 x i16>, <8 x i16>* %79, align 16
  %81 = bitcast i16* %77 to <8 x i16>*
  %82 = load <8 x i16>, <8 x i16>* %81, align 16
  %83 = sub <8 x i16> %80, %82
  %84 = sub <8 x i16> zeroinitializer, %83
  %85 = icmp slt <8 x i16> %83, zeroinitializer
  %86 = select <8 x i1> %85, <8 x i16> %84, <8 x i16> %83
  %87 = lshr <8 x i16> %86, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %88 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %87, <8 x i16> zeroinitializer) #5
  %89 = lshr <8 x i16> %88, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %90 = getelementptr inbounds i16, i16* %10, i64 40
  %91 = bitcast i16* %90 to <8 x i16>*
  %92 = load <8 x i16>, <8 x i16>* %91, align 16
  %93 = getelementptr inbounds i16, i16* %11, i64 40
  %94 = bitcast i16* %93 to <8 x i16>*
  %95 = load <8 x i16>, <8 x i16>* %94, align 16
  %96 = sub <8 x i16> %92, %95
  %97 = sub <8 x i16> zeroinitializer, %96
  %98 = icmp slt <8 x i16> %96, zeroinitializer
  %99 = select <8 x i1> %98, <8 x i16> %97, <8 x i16> %96
  %100 = lshr <8 x i16> %99, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %101 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %100, <8 x i16> zeroinitializer) #5
  %102 = lshr <8 x i16> %101, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %103 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %89, <8 x i16> %102) #5
  %104 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %103, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %105 = icmp slt <16 x i8> %104, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %106 = select <16 x i1> %105, <16 x i8> %104, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %107 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %106
  %108 = bitcast i8* %78 to <16 x i8>*
  store <16 x i8> %107, <16 x i8>* %108, align 16
  %109 = getelementptr inbounds i16, i16* %10, i64 48
  %110 = getelementptr inbounds i16, i16* %11, i64 48
  %111 = getelementptr inbounds i8, i8* %9, i64 48
  %112 = bitcast i16* %109 to <8 x i16>*
  %113 = load <8 x i16>, <8 x i16>* %112, align 16
  %114 = bitcast i16* %110 to <8 x i16>*
  %115 = load <8 x i16>, <8 x i16>* %114, align 16
  %116 = sub <8 x i16> %113, %115
  %117 = sub <8 x i16> zeroinitializer, %116
  %118 = icmp slt <8 x i16> %116, zeroinitializer
  %119 = select <8 x i1> %118, <8 x i16> %117, <8 x i16> %116
  %120 = lshr <8 x i16> %119, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %121 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %120, <8 x i16> zeroinitializer) #5
  %122 = lshr <8 x i16> %121, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %123 = getelementptr inbounds i16, i16* %10, i64 56
  %124 = bitcast i16* %123 to <8 x i16>*
  %125 = load <8 x i16>, <8 x i16>* %124, align 16
  %126 = getelementptr inbounds i16, i16* %11, i64 56
  %127 = bitcast i16* %126 to <8 x i16>*
  %128 = load <8 x i16>, <8 x i16>* %127, align 16
  %129 = sub <8 x i16> %125, %128
  %130 = sub <8 x i16> zeroinitializer, %129
  %131 = icmp slt <8 x i16> %129, zeroinitializer
  %132 = select <8 x i1> %131, <8 x i16> %130, <8 x i16> %129
  %133 = lshr <8 x i16> %132, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %134 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %133, <8 x i16> zeroinitializer) #5
  %135 = lshr <8 x i16> %134, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %136 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %122, <8 x i16> %135) #5
  %137 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %136, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %138 = icmp slt <16 x i8> %137, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %139 = select <16 x i1> %138, <16 x i8> %137, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %140 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %139
  %141 = bitcast i8* %111 to <16 x i8>*
  store <16 x i8> %140, <16 x i8>* %141, align 16
  %142 = getelementptr inbounds i16, i16* %10, i64 64
  %143 = getelementptr inbounds i16, i16* %11, i64 64
  %144 = getelementptr inbounds i8, i8* %9, i64 64
  %145 = bitcast i16* %142 to <8 x i16>*
  %146 = load <8 x i16>, <8 x i16>* %145, align 16
  %147 = bitcast i16* %143 to <8 x i16>*
  %148 = load <8 x i16>, <8 x i16>* %147, align 16
  %149 = sub <8 x i16> %146, %148
  %150 = sub <8 x i16> zeroinitializer, %149
  %151 = icmp slt <8 x i16> %149, zeroinitializer
  %152 = select <8 x i1> %151, <8 x i16> %150, <8 x i16> %149
  %153 = lshr <8 x i16> %152, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %154 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %153, <8 x i16> zeroinitializer) #5
  %155 = lshr <8 x i16> %154, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %156 = getelementptr inbounds i16, i16* %10, i64 72
  %157 = bitcast i16* %156 to <8 x i16>*
  %158 = load <8 x i16>, <8 x i16>* %157, align 16
  %159 = getelementptr inbounds i16, i16* %11, i64 72
  %160 = bitcast i16* %159 to <8 x i16>*
  %161 = load <8 x i16>, <8 x i16>* %160, align 16
  %162 = sub <8 x i16> %158, %161
  %163 = sub <8 x i16> zeroinitializer, %162
  %164 = icmp slt <8 x i16> %162, zeroinitializer
  %165 = select <8 x i1> %164, <8 x i16> %163, <8 x i16> %162
  %166 = lshr <8 x i16> %165, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %167 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %166, <8 x i16> zeroinitializer) #5
  %168 = lshr <8 x i16> %167, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %169 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %155, <8 x i16> %168) #5
  %170 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %169, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %171 = icmp slt <16 x i8> %170, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %172 = select <16 x i1> %171, <16 x i8> %170, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %173 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %172
  %174 = bitcast i8* %144 to <16 x i8>*
  store <16 x i8> %173, <16 x i8>* %174, align 16
  %175 = getelementptr inbounds i16, i16* %10, i64 80
  %176 = getelementptr inbounds i16, i16* %11, i64 80
  %177 = getelementptr inbounds i8, i8* %9, i64 80
  %178 = bitcast i16* %175 to <8 x i16>*
  %179 = load <8 x i16>, <8 x i16>* %178, align 16
  %180 = bitcast i16* %176 to <8 x i16>*
  %181 = load <8 x i16>, <8 x i16>* %180, align 16
  %182 = sub <8 x i16> %179, %181
  %183 = sub <8 x i16> zeroinitializer, %182
  %184 = icmp slt <8 x i16> %182, zeroinitializer
  %185 = select <8 x i1> %184, <8 x i16> %183, <8 x i16> %182
  %186 = lshr <8 x i16> %185, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %187 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %186, <8 x i16> zeroinitializer) #5
  %188 = lshr <8 x i16> %187, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %189 = getelementptr inbounds i16, i16* %10, i64 88
  %190 = bitcast i16* %189 to <8 x i16>*
  %191 = load <8 x i16>, <8 x i16>* %190, align 16
  %192 = getelementptr inbounds i16, i16* %11, i64 88
  %193 = bitcast i16* %192 to <8 x i16>*
  %194 = load <8 x i16>, <8 x i16>* %193, align 16
  %195 = sub <8 x i16> %191, %194
  %196 = sub <8 x i16> zeroinitializer, %195
  %197 = icmp slt <8 x i16> %195, zeroinitializer
  %198 = select <8 x i1> %197, <8 x i16> %196, <8 x i16> %195
  %199 = lshr <8 x i16> %198, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %200 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %199, <8 x i16> zeroinitializer) #5
  %201 = lshr <8 x i16> %200, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %202 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %188, <8 x i16> %201) #5
  %203 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %202, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %204 = icmp slt <16 x i8> %203, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %205 = select <16 x i1> %204, <16 x i8> %203, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %206 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %205
  %207 = bitcast i8* %177 to <16 x i8>*
  store <16 x i8> %206, <16 x i8>* %207, align 16
  %208 = getelementptr inbounds i16, i16* %10, i64 96
  %209 = getelementptr inbounds i16, i16* %11, i64 96
  %210 = getelementptr inbounds i8, i8* %9, i64 96
  %211 = bitcast i16* %208 to <8 x i16>*
  %212 = load <8 x i16>, <8 x i16>* %211, align 16
  %213 = bitcast i16* %209 to <8 x i16>*
  %214 = load <8 x i16>, <8 x i16>* %213, align 16
  %215 = sub <8 x i16> %212, %214
  %216 = sub <8 x i16> zeroinitializer, %215
  %217 = icmp slt <8 x i16> %215, zeroinitializer
  %218 = select <8 x i1> %217, <8 x i16> %216, <8 x i16> %215
  %219 = lshr <8 x i16> %218, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %220 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %219, <8 x i16> zeroinitializer) #5
  %221 = lshr <8 x i16> %220, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %222 = getelementptr inbounds i16, i16* %10, i64 104
  %223 = bitcast i16* %222 to <8 x i16>*
  %224 = load <8 x i16>, <8 x i16>* %223, align 16
  %225 = getelementptr inbounds i16, i16* %11, i64 104
  %226 = bitcast i16* %225 to <8 x i16>*
  %227 = load <8 x i16>, <8 x i16>* %226, align 16
  %228 = sub <8 x i16> %224, %227
  %229 = sub <8 x i16> zeroinitializer, %228
  %230 = icmp slt <8 x i16> %228, zeroinitializer
  %231 = select <8 x i1> %230, <8 x i16> %229, <8 x i16> %228
  %232 = lshr <8 x i16> %231, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %233 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %232, <8 x i16> zeroinitializer) #5
  %234 = lshr <8 x i16> %233, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %235 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %221, <8 x i16> %234) #5
  %236 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %235, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %237 = icmp slt <16 x i8> %236, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %238 = select <16 x i1> %237, <16 x i8> %236, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %239 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %238
  %240 = bitcast i8* %210 to <16 x i8>*
  store <16 x i8> %239, <16 x i8>* %240, align 16
  %241 = getelementptr inbounds i16, i16* %10, i64 112
  %242 = getelementptr inbounds i16, i16* %11, i64 112
  %243 = getelementptr inbounds i8, i8* %9, i64 112
  %244 = bitcast i16* %241 to <8 x i16>*
  %245 = load <8 x i16>, <8 x i16>* %244, align 16
  %246 = bitcast i16* %242 to <8 x i16>*
  %247 = load <8 x i16>, <8 x i16>* %246, align 16
  %248 = sub <8 x i16> %245, %247
  %249 = sub <8 x i16> zeroinitializer, %248
  %250 = icmp slt <8 x i16> %248, zeroinitializer
  %251 = select <8 x i1> %250, <8 x i16> %249, <8 x i16> %248
  %252 = lshr <8 x i16> %251, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %253 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %252, <8 x i16> zeroinitializer) #5
  %254 = lshr <8 x i16> %253, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %255 = getelementptr inbounds i16, i16* %10, i64 120
  %256 = bitcast i16* %255 to <8 x i16>*
  %257 = load <8 x i16>, <8 x i16>* %256, align 16
  %258 = getelementptr inbounds i16, i16* %11, i64 120
  %259 = bitcast i16* %258 to <8 x i16>*
  %260 = load <8 x i16>, <8 x i16>* %259, align 16
  %261 = sub <8 x i16> %257, %260
  %262 = sub <8 x i16> zeroinitializer, %261
  %263 = icmp slt <8 x i16> %261, zeroinitializer
  %264 = select <8 x i1> %263, <8 x i16> %262, <8 x i16> %261
  %265 = lshr <8 x i16> %264, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %266 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %265, <8 x i16> zeroinitializer) #5
  %267 = lshr <8 x i16> %266, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %268 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %254, <8 x i16> %267) #5
  %269 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %268, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %270 = icmp slt <16 x i8> %269, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %271 = select <16 x i1> %270, <16 x i8> %269, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %272 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %271
  %273 = bitcast i8* %243 to <16 x i8>*
  store <16 x i8> %272, <16 x i8>* %273, align 16
  %274 = getelementptr inbounds i16, i16* %10, i64 128
  %275 = getelementptr inbounds i16, i16* %11, i64 128
  %276 = getelementptr inbounds i8, i8* %9, i64 %3
  %277 = bitcast i16* %274 to <8 x i16>*
  %278 = load <8 x i16>, <8 x i16>* %277, align 16
  %279 = bitcast i16* %275 to <8 x i16>*
  %280 = load <8 x i16>, <8 x i16>* %279, align 16
  %281 = sub <8 x i16> %278, %280
  %282 = sub <8 x i16> zeroinitializer, %281
  %283 = icmp slt <8 x i16> %281, zeroinitializer
  %284 = select <8 x i1> %283, <8 x i16> %282, <8 x i16> %281
  %285 = lshr <8 x i16> %284, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %286 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %285, <8 x i16> zeroinitializer) #5
  %287 = lshr <8 x i16> %286, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %288 = getelementptr inbounds i16, i16* %10, i64 136
  %289 = bitcast i16* %288 to <8 x i16>*
  %290 = load <8 x i16>, <8 x i16>* %289, align 16
  %291 = getelementptr inbounds i16, i16* %11, i64 136
  %292 = bitcast i16* %291 to <8 x i16>*
  %293 = load <8 x i16>, <8 x i16>* %292, align 16
  %294 = sub <8 x i16> %290, %293
  %295 = sub <8 x i16> zeroinitializer, %294
  %296 = icmp slt <8 x i16> %294, zeroinitializer
  %297 = select <8 x i1> %296, <8 x i16> %295, <8 x i16> %294
  %298 = lshr <8 x i16> %297, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %299 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %298, <8 x i16> zeroinitializer) #5
  %300 = lshr <8 x i16> %299, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %301 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %287, <8 x i16> %300) #5
  %302 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %301, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %303 = icmp slt <16 x i8> %302, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %304 = select <16 x i1> %303, <16 x i8> %302, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %305 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %304
  %306 = bitcast i8* %276 to <16 x i8>*
  store <16 x i8> %305, <16 x i8>* %306, align 16
  %307 = getelementptr inbounds i16, i16* %10, i64 144
  %308 = getelementptr inbounds i16, i16* %11, i64 144
  %309 = getelementptr inbounds i8, i8* %276, i64 16
  %310 = bitcast i16* %307 to <8 x i16>*
  %311 = load <8 x i16>, <8 x i16>* %310, align 16
  %312 = bitcast i16* %308 to <8 x i16>*
  %313 = load <8 x i16>, <8 x i16>* %312, align 16
  %314 = sub <8 x i16> %311, %313
  %315 = sub <8 x i16> zeroinitializer, %314
  %316 = icmp slt <8 x i16> %314, zeroinitializer
  %317 = select <8 x i1> %316, <8 x i16> %315, <8 x i16> %314
  %318 = lshr <8 x i16> %317, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %319 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %318, <8 x i16> zeroinitializer) #5
  %320 = lshr <8 x i16> %319, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %321 = getelementptr inbounds i16, i16* %10, i64 152
  %322 = bitcast i16* %321 to <8 x i16>*
  %323 = load <8 x i16>, <8 x i16>* %322, align 16
  %324 = getelementptr inbounds i16, i16* %11, i64 152
  %325 = bitcast i16* %324 to <8 x i16>*
  %326 = load <8 x i16>, <8 x i16>* %325, align 16
  %327 = sub <8 x i16> %323, %326
  %328 = sub <8 x i16> zeroinitializer, %327
  %329 = icmp slt <8 x i16> %327, zeroinitializer
  %330 = select <8 x i1> %329, <8 x i16> %328, <8 x i16> %327
  %331 = lshr <8 x i16> %330, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %332 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %331, <8 x i16> zeroinitializer) #5
  %333 = lshr <8 x i16> %332, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %334 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %320, <8 x i16> %333) #5
  %335 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %334, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %336 = icmp slt <16 x i8> %335, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %337 = select <16 x i1> %336, <16 x i8> %335, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %338 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %337
  %339 = bitcast i8* %309 to <16 x i8>*
  store <16 x i8> %338, <16 x i8>* %339, align 16
  %340 = getelementptr inbounds i16, i16* %10, i64 160
  %341 = getelementptr inbounds i16, i16* %11, i64 160
  %342 = getelementptr inbounds i8, i8* %276, i64 32
  %343 = bitcast i16* %340 to <8 x i16>*
  %344 = load <8 x i16>, <8 x i16>* %343, align 16
  %345 = bitcast i16* %341 to <8 x i16>*
  %346 = load <8 x i16>, <8 x i16>* %345, align 16
  %347 = sub <8 x i16> %344, %346
  %348 = sub <8 x i16> zeroinitializer, %347
  %349 = icmp slt <8 x i16> %347, zeroinitializer
  %350 = select <8 x i1> %349, <8 x i16> %348, <8 x i16> %347
  %351 = lshr <8 x i16> %350, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %352 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %351, <8 x i16> zeroinitializer) #5
  %353 = lshr <8 x i16> %352, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %354 = getelementptr inbounds i16, i16* %10, i64 168
  %355 = bitcast i16* %354 to <8 x i16>*
  %356 = load <8 x i16>, <8 x i16>* %355, align 16
  %357 = getelementptr inbounds i16, i16* %11, i64 168
  %358 = bitcast i16* %357 to <8 x i16>*
  %359 = load <8 x i16>, <8 x i16>* %358, align 16
  %360 = sub <8 x i16> %356, %359
  %361 = sub <8 x i16> zeroinitializer, %360
  %362 = icmp slt <8 x i16> %360, zeroinitializer
  %363 = select <8 x i1> %362, <8 x i16> %361, <8 x i16> %360
  %364 = lshr <8 x i16> %363, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %365 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %364, <8 x i16> zeroinitializer) #5
  %366 = lshr <8 x i16> %365, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %367 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %353, <8 x i16> %366) #5
  %368 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %367, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %369 = icmp slt <16 x i8> %368, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %370 = select <16 x i1> %369, <16 x i8> %368, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %371 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %370
  %372 = bitcast i8* %342 to <16 x i8>*
  store <16 x i8> %371, <16 x i8>* %372, align 16
  %373 = getelementptr inbounds i16, i16* %10, i64 176
  %374 = getelementptr inbounds i16, i16* %11, i64 176
  %375 = getelementptr inbounds i8, i8* %276, i64 48
  %376 = bitcast i16* %373 to <8 x i16>*
  %377 = load <8 x i16>, <8 x i16>* %376, align 16
  %378 = bitcast i16* %374 to <8 x i16>*
  %379 = load <8 x i16>, <8 x i16>* %378, align 16
  %380 = sub <8 x i16> %377, %379
  %381 = sub <8 x i16> zeroinitializer, %380
  %382 = icmp slt <8 x i16> %380, zeroinitializer
  %383 = select <8 x i1> %382, <8 x i16> %381, <8 x i16> %380
  %384 = lshr <8 x i16> %383, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %385 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %384, <8 x i16> zeroinitializer) #5
  %386 = lshr <8 x i16> %385, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %387 = getelementptr inbounds i16, i16* %10, i64 184
  %388 = bitcast i16* %387 to <8 x i16>*
  %389 = load <8 x i16>, <8 x i16>* %388, align 16
  %390 = getelementptr inbounds i16, i16* %11, i64 184
  %391 = bitcast i16* %390 to <8 x i16>*
  %392 = load <8 x i16>, <8 x i16>* %391, align 16
  %393 = sub <8 x i16> %389, %392
  %394 = sub <8 x i16> zeroinitializer, %393
  %395 = icmp slt <8 x i16> %393, zeroinitializer
  %396 = select <8 x i1> %395, <8 x i16> %394, <8 x i16> %393
  %397 = lshr <8 x i16> %396, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %398 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %397, <8 x i16> zeroinitializer) #5
  %399 = lshr <8 x i16> %398, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %400 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %386, <8 x i16> %399) #5
  %401 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %400, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %402 = icmp slt <16 x i8> %401, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %403 = select <16 x i1> %402, <16 x i8> %401, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %404 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %403
  %405 = bitcast i8* %375 to <16 x i8>*
  store <16 x i8> %404, <16 x i8>* %405, align 16
  %406 = getelementptr inbounds i16, i16* %10, i64 192
  %407 = getelementptr inbounds i16, i16* %11, i64 192
  %408 = getelementptr inbounds i8, i8* %276, i64 64
  %409 = bitcast i16* %406 to <8 x i16>*
  %410 = load <8 x i16>, <8 x i16>* %409, align 16
  %411 = bitcast i16* %407 to <8 x i16>*
  %412 = load <8 x i16>, <8 x i16>* %411, align 16
  %413 = sub <8 x i16> %410, %412
  %414 = sub <8 x i16> zeroinitializer, %413
  %415 = icmp slt <8 x i16> %413, zeroinitializer
  %416 = select <8 x i1> %415, <8 x i16> %414, <8 x i16> %413
  %417 = lshr <8 x i16> %416, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %418 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %417, <8 x i16> zeroinitializer) #5
  %419 = lshr <8 x i16> %418, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %420 = getelementptr inbounds i16, i16* %10, i64 200
  %421 = bitcast i16* %420 to <8 x i16>*
  %422 = load <8 x i16>, <8 x i16>* %421, align 16
  %423 = getelementptr inbounds i16, i16* %11, i64 200
  %424 = bitcast i16* %423 to <8 x i16>*
  %425 = load <8 x i16>, <8 x i16>* %424, align 16
  %426 = sub <8 x i16> %422, %425
  %427 = sub <8 x i16> zeroinitializer, %426
  %428 = icmp slt <8 x i16> %426, zeroinitializer
  %429 = select <8 x i1> %428, <8 x i16> %427, <8 x i16> %426
  %430 = lshr <8 x i16> %429, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %431 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %430, <8 x i16> zeroinitializer) #5
  %432 = lshr <8 x i16> %431, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %433 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %419, <8 x i16> %432) #5
  %434 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %433, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %435 = icmp slt <16 x i8> %434, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %436 = select <16 x i1> %435, <16 x i8> %434, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %437 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %436
  %438 = bitcast i8* %408 to <16 x i8>*
  store <16 x i8> %437, <16 x i8>* %438, align 16
  %439 = getelementptr inbounds i16, i16* %10, i64 208
  %440 = getelementptr inbounds i16, i16* %11, i64 208
  %441 = getelementptr inbounds i8, i8* %408, i64 16
  %442 = bitcast i16* %439 to <8 x i16>*
  %443 = load <8 x i16>, <8 x i16>* %442, align 16
  %444 = bitcast i16* %440 to <8 x i16>*
  %445 = load <8 x i16>, <8 x i16>* %444, align 16
  %446 = sub <8 x i16> %443, %445
  %447 = sub <8 x i16> zeroinitializer, %446
  %448 = icmp slt <8 x i16> %446, zeroinitializer
  %449 = select <8 x i1> %448, <8 x i16> %447, <8 x i16> %446
  %450 = lshr <8 x i16> %449, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %451 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %450, <8 x i16> zeroinitializer) #5
  %452 = lshr <8 x i16> %451, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %453 = getelementptr inbounds i16, i16* %10, i64 216
  %454 = bitcast i16* %453 to <8 x i16>*
  %455 = load <8 x i16>, <8 x i16>* %454, align 16
  %456 = getelementptr inbounds i16, i16* %11, i64 216
  %457 = bitcast i16* %456 to <8 x i16>*
  %458 = load <8 x i16>, <8 x i16>* %457, align 16
  %459 = sub <8 x i16> %455, %458
  %460 = sub <8 x i16> zeroinitializer, %459
  %461 = icmp slt <8 x i16> %459, zeroinitializer
  %462 = select <8 x i1> %461, <8 x i16> %460, <8 x i16> %459
  %463 = lshr <8 x i16> %462, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %464 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %463, <8 x i16> zeroinitializer) #5
  %465 = lshr <8 x i16> %464, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %466 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %452, <8 x i16> %465) #5
  %467 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %466, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %468 = icmp slt <16 x i8> %467, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %469 = select <16 x i1> %468, <16 x i8> %467, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %470 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %469
  %471 = bitcast i8* %441 to <16 x i8>*
  store <16 x i8> %470, <16 x i8>* %471, align 16
  %472 = getelementptr inbounds i16, i16* %10, i64 224
  %473 = getelementptr inbounds i16, i16* %11, i64 224
  %474 = getelementptr inbounds i8, i8* %408, i64 32
  %475 = bitcast i16* %472 to <8 x i16>*
  %476 = load <8 x i16>, <8 x i16>* %475, align 16
  %477 = bitcast i16* %473 to <8 x i16>*
  %478 = load <8 x i16>, <8 x i16>* %477, align 16
  %479 = sub <8 x i16> %476, %478
  %480 = sub <8 x i16> zeroinitializer, %479
  %481 = icmp slt <8 x i16> %479, zeroinitializer
  %482 = select <8 x i1> %481, <8 x i16> %480, <8 x i16> %479
  %483 = lshr <8 x i16> %482, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %484 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %483, <8 x i16> zeroinitializer) #5
  %485 = lshr <8 x i16> %484, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %486 = getelementptr inbounds i16, i16* %10, i64 232
  %487 = bitcast i16* %486 to <8 x i16>*
  %488 = load <8 x i16>, <8 x i16>* %487, align 16
  %489 = getelementptr inbounds i16, i16* %11, i64 232
  %490 = bitcast i16* %489 to <8 x i16>*
  %491 = load <8 x i16>, <8 x i16>* %490, align 16
  %492 = sub <8 x i16> %488, %491
  %493 = sub <8 x i16> zeroinitializer, %492
  %494 = icmp slt <8 x i16> %492, zeroinitializer
  %495 = select <8 x i1> %494, <8 x i16> %493, <8 x i16> %492
  %496 = lshr <8 x i16> %495, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %497 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %496, <8 x i16> zeroinitializer) #5
  %498 = lshr <8 x i16> %497, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %499 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %485, <8 x i16> %498) #5
  %500 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %499, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %501 = icmp slt <16 x i8> %500, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %502 = select <16 x i1> %501, <16 x i8> %500, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %503 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %502
  %504 = bitcast i8* %474 to <16 x i8>*
  store <16 x i8> %503, <16 x i8>* %504, align 16
  %505 = getelementptr inbounds i16, i16* %10, i64 240
  %506 = getelementptr inbounds i16, i16* %11, i64 240
  %507 = getelementptr inbounds i8, i8* %408, i64 48
  %508 = bitcast i16* %505 to <8 x i16>*
  %509 = load <8 x i16>, <8 x i16>* %508, align 16
  %510 = bitcast i16* %506 to <8 x i16>*
  %511 = load <8 x i16>, <8 x i16>* %510, align 16
  %512 = sub <8 x i16> %509, %511
  %513 = sub <8 x i16> zeroinitializer, %512
  %514 = icmp slt <8 x i16> %512, zeroinitializer
  %515 = select <8 x i1> %514, <8 x i16> %513, <8 x i16> %512
  %516 = lshr <8 x i16> %515, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %517 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %516, <8 x i16> zeroinitializer) #5
  %518 = lshr <8 x i16> %517, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %519 = getelementptr inbounds i16, i16* %10, i64 248
  %520 = bitcast i16* %519 to <8 x i16>*
  %521 = load <8 x i16>, <8 x i16>* %520, align 16
  %522 = getelementptr inbounds i16, i16* %11, i64 248
  %523 = bitcast i16* %522 to <8 x i16>*
  %524 = load <8 x i16>, <8 x i16>* %523, align 16
  %525 = sub <8 x i16> %521, %524
  %526 = sub <8 x i16> zeroinitializer, %525
  %527 = icmp slt <8 x i16> %525, zeroinitializer
  %528 = select <8 x i1> %527, <8 x i16> %526, <8 x i16> %525
  %529 = lshr <8 x i16> %528, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %530 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %529, <8 x i16> zeroinitializer) #5
  %531 = lshr <8 x i16> %530, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %532 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %518, <8 x i16> %531) #5
  %533 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %532, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %534 = icmp slt <16 x i8> %533, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %535 = select <16 x i1> %534, <16 x i8> %533, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %536 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %535
  %537 = bitcast i8* %507 to <16 x i8>*
  store <16 x i8> %536, <16 x i8>* %537, align 16
  %538 = getelementptr inbounds i16, i16* %10, i64 256
  %539 = getelementptr inbounds i16, i16* %11, i64 256
  %540 = getelementptr inbounds i8, i8* %408, i64 %7
  %541 = bitcast i16* %538 to <8 x i16>*
  %542 = load <8 x i16>, <8 x i16>* %541, align 16
  %543 = bitcast i16* %539 to <8 x i16>*
  %544 = load <8 x i16>, <8 x i16>* %543, align 16
  %545 = sub <8 x i16> %542, %544
  %546 = sub <8 x i16> zeroinitializer, %545
  %547 = icmp slt <8 x i16> %545, zeroinitializer
  %548 = select <8 x i1> %547, <8 x i16> %546, <8 x i16> %545
  %549 = lshr <8 x i16> %548, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %550 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %549, <8 x i16> zeroinitializer) #5
  %551 = lshr <8 x i16> %550, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %552 = getelementptr inbounds i16, i16* %10, i64 264
  %553 = bitcast i16* %552 to <8 x i16>*
  %554 = load <8 x i16>, <8 x i16>* %553, align 16
  %555 = getelementptr inbounds i16, i16* %11, i64 264
  %556 = bitcast i16* %555 to <8 x i16>*
  %557 = load <8 x i16>, <8 x i16>* %556, align 16
  %558 = sub <8 x i16> %554, %557
  %559 = sub <8 x i16> zeroinitializer, %558
  %560 = icmp slt <8 x i16> %558, zeroinitializer
  %561 = select <8 x i1> %560, <8 x i16> %559, <8 x i16> %558
  %562 = lshr <8 x i16> %561, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %563 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %562, <8 x i16> zeroinitializer) #5
  %564 = lshr <8 x i16> %563, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %565 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %551, <8 x i16> %564) #5
  %566 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %565, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %567 = icmp slt <16 x i8> %566, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %568 = select <16 x i1> %567, <16 x i8> %566, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %569 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %568
  %570 = bitcast i8* %540 to <16 x i8>*
  store <16 x i8> %569, <16 x i8>* %570, align 16
  %571 = getelementptr inbounds i16, i16* %10, i64 272
  %572 = getelementptr inbounds i16, i16* %11, i64 272
  %573 = getelementptr inbounds i8, i8* %540, i64 16
  %574 = bitcast i16* %571 to <8 x i16>*
  %575 = load <8 x i16>, <8 x i16>* %574, align 16
  %576 = bitcast i16* %572 to <8 x i16>*
  %577 = load <8 x i16>, <8 x i16>* %576, align 16
  %578 = sub <8 x i16> %575, %577
  %579 = sub <8 x i16> zeroinitializer, %578
  %580 = icmp slt <8 x i16> %578, zeroinitializer
  %581 = select <8 x i1> %580, <8 x i16> %579, <8 x i16> %578
  %582 = lshr <8 x i16> %581, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %583 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %582, <8 x i16> zeroinitializer) #5
  %584 = lshr <8 x i16> %583, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %585 = getelementptr inbounds i16, i16* %10, i64 280
  %586 = bitcast i16* %585 to <8 x i16>*
  %587 = load <8 x i16>, <8 x i16>* %586, align 16
  %588 = getelementptr inbounds i16, i16* %11, i64 280
  %589 = bitcast i16* %588 to <8 x i16>*
  %590 = load <8 x i16>, <8 x i16>* %589, align 16
  %591 = sub <8 x i16> %587, %590
  %592 = sub <8 x i16> zeroinitializer, %591
  %593 = icmp slt <8 x i16> %591, zeroinitializer
  %594 = select <8 x i1> %593, <8 x i16> %592, <8 x i16> %591
  %595 = lshr <8 x i16> %594, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %596 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %595, <8 x i16> zeroinitializer) #5
  %597 = lshr <8 x i16> %596, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %598 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %584, <8 x i16> %597) #5
  %599 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %598, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %600 = icmp slt <16 x i8> %599, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %601 = select <16 x i1> %600, <16 x i8> %599, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %602 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %601
  %603 = bitcast i8* %573 to <16 x i8>*
  store <16 x i8> %602, <16 x i8>* %603, align 16
  %604 = getelementptr inbounds i16, i16* %10, i64 288
  %605 = getelementptr inbounds i16, i16* %11, i64 288
  %606 = getelementptr inbounds i8, i8* %540, i64 32
  %607 = bitcast i16* %604 to <8 x i16>*
  %608 = load <8 x i16>, <8 x i16>* %607, align 16
  %609 = bitcast i16* %605 to <8 x i16>*
  %610 = load <8 x i16>, <8 x i16>* %609, align 16
  %611 = sub <8 x i16> %608, %610
  %612 = sub <8 x i16> zeroinitializer, %611
  %613 = icmp slt <8 x i16> %611, zeroinitializer
  %614 = select <8 x i1> %613, <8 x i16> %612, <8 x i16> %611
  %615 = lshr <8 x i16> %614, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %616 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %615, <8 x i16> zeroinitializer) #5
  %617 = lshr <8 x i16> %616, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %618 = getelementptr inbounds i16, i16* %10, i64 296
  %619 = bitcast i16* %618 to <8 x i16>*
  %620 = load <8 x i16>, <8 x i16>* %619, align 16
  %621 = getelementptr inbounds i16, i16* %11, i64 296
  %622 = bitcast i16* %621 to <8 x i16>*
  %623 = load <8 x i16>, <8 x i16>* %622, align 16
  %624 = sub <8 x i16> %620, %623
  %625 = sub <8 x i16> zeroinitializer, %624
  %626 = icmp slt <8 x i16> %624, zeroinitializer
  %627 = select <8 x i1> %626, <8 x i16> %625, <8 x i16> %624
  %628 = lshr <8 x i16> %627, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %629 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %628, <8 x i16> zeroinitializer) #5
  %630 = lshr <8 x i16> %629, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %631 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %617, <8 x i16> %630) #5
  %632 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %631, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %633 = icmp slt <16 x i8> %632, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %634 = select <16 x i1> %633, <16 x i8> %632, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %635 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %634
  %636 = bitcast i8* %606 to <16 x i8>*
  store <16 x i8> %635, <16 x i8>* %636, align 16
  %637 = getelementptr inbounds i16, i16* %10, i64 304
  %638 = getelementptr inbounds i16, i16* %11, i64 304
  %639 = getelementptr inbounds i8, i8* %540, i64 48
  %640 = bitcast i16* %637 to <8 x i16>*
  %641 = load <8 x i16>, <8 x i16>* %640, align 16
  %642 = bitcast i16* %638 to <8 x i16>*
  %643 = load <8 x i16>, <8 x i16>* %642, align 16
  %644 = sub <8 x i16> %641, %643
  %645 = sub <8 x i16> zeroinitializer, %644
  %646 = icmp slt <8 x i16> %644, zeroinitializer
  %647 = select <8 x i1> %646, <8 x i16> %645, <8 x i16> %644
  %648 = lshr <8 x i16> %647, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %649 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %648, <8 x i16> zeroinitializer) #5
  %650 = lshr <8 x i16> %649, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %651 = getelementptr inbounds i16, i16* %10, i64 312
  %652 = bitcast i16* %651 to <8 x i16>*
  %653 = load <8 x i16>, <8 x i16>* %652, align 16
  %654 = getelementptr inbounds i16, i16* %11, i64 312
  %655 = bitcast i16* %654 to <8 x i16>*
  %656 = load <8 x i16>, <8 x i16>* %655, align 16
  %657 = sub <8 x i16> %653, %656
  %658 = sub <8 x i16> zeroinitializer, %657
  %659 = icmp slt <8 x i16> %657, zeroinitializer
  %660 = select <8 x i1> %659, <8 x i16> %658, <8 x i16> %657
  %661 = lshr <8 x i16> %660, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %662 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %661, <8 x i16> zeroinitializer) #5
  %663 = lshr <8 x i16> %662, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %664 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %650, <8 x i16> %663) #5
  %665 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %664, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %666 = icmp slt <16 x i8> %665, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %667 = select <16 x i1> %666, <16 x i8> %665, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %668 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %667
  %669 = bitcast i8* %639 to <16 x i8>*
  store <16 x i8> %668, <16 x i8>* %669, align 16
  %670 = getelementptr inbounds i16, i16* %10, i64 320
  %671 = getelementptr inbounds i16, i16* %11, i64 320
  %672 = getelementptr inbounds i8, i8* %540, i64 64
  %673 = bitcast i16* %670 to <8 x i16>*
  %674 = load <8 x i16>, <8 x i16>* %673, align 16
  %675 = bitcast i16* %671 to <8 x i16>*
  %676 = load <8 x i16>, <8 x i16>* %675, align 16
  %677 = sub <8 x i16> %674, %676
  %678 = sub <8 x i16> zeroinitializer, %677
  %679 = icmp slt <8 x i16> %677, zeroinitializer
  %680 = select <8 x i1> %679, <8 x i16> %678, <8 x i16> %677
  %681 = lshr <8 x i16> %680, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %682 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %681, <8 x i16> zeroinitializer) #5
  %683 = lshr <8 x i16> %682, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %684 = getelementptr inbounds i16, i16* %10, i64 328
  %685 = bitcast i16* %684 to <8 x i16>*
  %686 = load <8 x i16>, <8 x i16>* %685, align 16
  %687 = getelementptr inbounds i16, i16* %11, i64 328
  %688 = bitcast i16* %687 to <8 x i16>*
  %689 = load <8 x i16>, <8 x i16>* %688, align 16
  %690 = sub <8 x i16> %686, %689
  %691 = sub <8 x i16> zeroinitializer, %690
  %692 = icmp slt <8 x i16> %690, zeroinitializer
  %693 = select <8 x i1> %692, <8 x i16> %691, <8 x i16> %690
  %694 = lshr <8 x i16> %693, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %695 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %694, <8 x i16> zeroinitializer) #5
  %696 = lshr <8 x i16> %695, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %697 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %683, <8 x i16> %696) #5
  %698 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %697, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %699 = icmp slt <16 x i8> %698, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %700 = select <16 x i1> %699, <16 x i8> %698, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %701 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %700
  %702 = bitcast i8* %672 to <16 x i8>*
  store <16 x i8> %701, <16 x i8>* %702, align 16
  %703 = getelementptr inbounds i16, i16* %10, i64 336
  %704 = getelementptr inbounds i16, i16* %11, i64 336
  %705 = getelementptr inbounds i8, i8* %672, i64 16
  %706 = bitcast i16* %703 to <8 x i16>*
  %707 = load <8 x i16>, <8 x i16>* %706, align 16
  %708 = bitcast i16* %704 to <8 x i16>*
  %709 = load <8 x i16>, <8 x i16>* %708, align 16
  %710 = sub <8 x i16> %707, %709
  %711 = sub <8 x i16> zeroinitializer, %710
  %712 = icmp slt <8 x i16> %710, zeroinitializer
  %713 = select <8 x i1> %712, <8 x i16> %711, <8 x i16> %710
  %714 = lshr <8 x i16> %713, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %715 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %714, <8 x i16> zeroinitializer) #5
  %716 = lshr <8 x i16> %715, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %717 = getelementptr inbounds i16, i16* %10, i64 344
  %718 = bitcast i16* %717 to <8 x i16>*
  %719 = load <8 x i16>, <8 x i16>* %718, align 16
  %720 = getelementptr inbounds i16, i16* %11, i64 344
  %721 = bitcast i16* %720 to <8 x i16>*
  %722 = load <8 x i16>, <8 x i16>* %721, align 16
  %723 = sub <8 x i16> %719, %722
  %724 = sub <8 x i16> zeroinitializer, %723
  %725 = icmp slt <8 x i16> %723, zeroinitializer
  %726 = select <8 x i1> %725, <8 x i16> %724, <8 x i16> %723
  %727 = lshr <8 x i16> %726, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %728 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %727, <8 x i16> zeroinitializer) #5
  %729 = lshr <8 x i16> %728, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %730 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %716, <8 x i16> %729) #5
  %731 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %730, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %732 = icmp slt <16 x i8> %731, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %733 = select <16 x i1> %732, <16 x i8> %731, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %734 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %733
  %735 = bitcast i8* %705 to <16 x i8>*
  store <16 x i8> %734, <16 x i8>* %735, align 16
  %736 = getelementptr inbounds i16, i16* %10, i64 352
  %737 = getelementptr inbounds i16, i16* %11, i64 352
  %738 = getelementptr inbounds i8, i8* %672, i64 32
  %739 = bitcast i16* %736 to <8 x i16>*
  %740 = load <8 x i16>, <8 x i16>* %739, align 16
  %741 = bitcast i16* %737 to <8 x i16>*
  %742 = load <8 x i16>, <8 x i16>* %741, align 16
  %743 = sub <8 x i16> %740, %742
  %744 = sub <8 x i16> zeroinitializer, %743
  %745 = icmp slt <8 x i16> %743, zeroinitializer
  %746 = select <8 x i1> %745, <8 x i16> %744, <8 x i16> %743
  %747 = lshr <8 x i16> %746, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %748 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %747, <8 x i16> zeroinitializer) #5
  %749 = lshr <8 x i16> %748, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %750 = getelementptr inbounds i16, i16* %10, i64 360
  %751 = bitcast i16* %750 to <8 x i16>*
  %752 = load <8 x i16>, <8 x i16>* %751, align 16
  %753 = getelementptr inbounds i16, i16* %11, i64 360
  %754 = bitcast i16* %753 to <8 x i16>*
  %755 = load <8 x i16>, <8 x i16>* %754, align 16
  %756 = sub <8 x i16> %752, %755
  %757 = sub <8 x i16> zeroinitializer, %756
  %758 = icmp slt <8 x i16> %756, zeroinitializer
  %759 = select <8 x i1> %758, <8 x i16> %757, <8 x i16> %756
  %760 = lshr <8 x i16> %759, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %761 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %760, <8 x i16> zeroinitializer) #5
  %762 = lshr <8 x i16> %761, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %763 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %749, <8 x i16> %762) #5
  %764 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %763, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %765 = icmp slt <16 x i8> %764, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %766 = select <16 x i1> %765, <16 x i8> %764, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %767 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %766
  %768 = bitcast i8* %738 to <16 x i8>*
  store <16 x i8> %767, <16 x i8>* %768, align 16
  %769 = getelementptr inbounds i16, i16* %10, i64 368
  %770 = getelementptr inbounds i16, i16* %11, i64 368
  %771 = getelementptr inbounds i8, i8* %672, i64 48
  %772 = bitcast i16* %769 to <8 x i16>*
  %773 = load <8 x i16>, <8 x i16>* %772, align 16
  %774 = bitcast i16* %770 to <8 x i16>*
  %775 = load <8 x i16>, <8 x i16>* %774, align 16
  %776 = sub <8 x i16> %773, %775
  %777 = sub <8 x i16> zeroinitializer, %776
  %778 = icmp slt <8 x i16> %776, zeroinitializer
  %779 = select <8 x i1> %778, <8 x i16> %777, <8 x i16> %776
  %780 = lshr <8 x i16> %779, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %781 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %780, <8 x i16> zeroinitializer) #5
  %782 = lshr <8 x i16> %781, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %783 = getelementptr inbounds i16, i16* %10, i64 376
  %784 = bitcast i16* %783 to <8 x i16>*
  %785 = load <8 x i16>, <8 x i16>* %784, align 16
  %786 = getelementptr inbounds i16, i16* %11, i64 376
  %787 = bitcast i16* %786 to <8 x i16>*
  %788 = load <8 x i16>, <8 x i16>* %787, align 16
  %789 = sub <8 x i16> %785, %788
  %790 = sub <8 x i16> zeroinitializer, %789
  %791 = icmp slt <8 x i16> %789, zeroinitializer
  %792 = select <8 x i1> %791, <8 x i16> %790, <8 x i16> %789
  %793 = lshr <8 x i16> %792, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %794 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %793, <8 x i16> zeroinitializer) #5
  %795 = lshr <8 x i16> %794, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %796 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %782, <8 x i16> %795) #5
  %797 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %796, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %798 = icmp slt <16 x i8> %797, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %799 = select <16 x i1> %798, <16 x i8> %797, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %800 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %799
  %801 = bitcast i8* %771 to <16 x i8>*
  store <16 x i8> %800, <16 x i8>* %801, align 16
  %802 = getelementptr inbounds i16, i16* %10, i64 384
  %803 = getelementptr inbounds i16, i16* %11, i64 384
  %804 = getelementptr inbounds i8, i8* %672, i64 %7
  %805 = add nuw nsw i32 %12, 1
  %806 = icmp eq i32 %805, 42
  br i1 %806, label %807, label %8

807:                                              ; preds = %8
  %808 = bitcast i16* %802 to <8 x i16>*
  %809 = load <8 x i16>, <8 x i16>* %808, align 16
  %810 = bitcast i16* %803 to <8 x i16>*
  %811 = load <8 x i16>, <8 x i16>* %810, align 16
  %812 = sub <8 x i16> %809, %811
  %813 = sub <8 x i16> zeroinitializer, %812
  %814 = icmp slt <8 x i16> %812, zeroinitializer
  %815 = select <8 x i1> %814, <8 x i16> %813, <8 x i16> %812
  %816 = lshr <8 x i16> %815, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %817 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %816, <8 x i16> zeroinitializer) #5
  %818 = lshr <8 x i16> %817, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %819 = getelementptr inbounds i16, i16* %10, i64 392
  %820 = bitcast i16* %819 to <8 x i16>*
  %821 = load <8 x i16>, <8 x i16>* %820, align 16
  %822 = getelementptr inbounds i16, i16* %11, i64 392
  %823 = bitcast i16* %822 to <8 x i16>*
  %824 = load <8 x i16>, <8 x i16>* %823, align 16
  %825 = sub <8 x i16> %821, %824
  %826 = sub <8 x i16> zeroinitializer, %825
  %827 = icmp slt <8 x i16> %825, zeroinitializer
  %828 = select <8 x i1> %827, <8 x i16> %826, <8 x i16> %825
  %829 = lshr <8 x i16> %828, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %830 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %829, <8 x i16> zeroinitializer) #5
  %831 = lshr <8 x i16> %830, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %832 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %818, <8 x i16> %831) #5
  %833 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %832, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %834 = icmp slt <16 x i8> %833, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %835 = select <16 x i1> %834, <16 x i8> %833, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %836 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %835
  %837 = bitcast i8* %804 to <16 x i8>*
  store <16 x i8> %836, <16 x i8>* %837, align 16
  %838 = getelementptr inbounds i16, i16* %10, i64 400
  %839 = getelementptr inbounds i16, i16* %11, i64 400
  %840 = getelementptr inbounds i8, i8* %804, i64 16
  %841 = bitcast i16* %838 to <8 x i16>*
  %842 = load <8 x i16>, <8 x i16>* %841, align 16
  %843 = bitcast i16* %839 to <8 x i16>*
  %844 = load <8 x i16>, <8 x i16>* %843, align 16
  %845 = sub <8 x i16> %842, %844
  %846 = sub <8 x i16> zeroinitializer, %845
  %847 = icmp slt <8 x i16> %845, zeroinitializer
  %848 = select <8 x i1> %847, <8 x i16> %846, <8 x i16> %845
  %849 = lshr <8 x i16> %848, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %850 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %849, <8 x i16> zeroinitializer) #5
  %851 = lshr <8 x i16> %850, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %852 = getelementptr inbounds i16, i16* %10, i64 408
  %853 = bitcast i16* %852 to <8 x i16>*
  %854 = load <8 x i16>, <8 x i16>* %853, align 16
  %855 = getelementptr inbounds i16, i16* %11, i64 408
  %856 = bitcast i16* %855 to <8 x i16>*
  %857 = load <8 x i16>, <8 x i16>* %856, align 16
  %858 = sub <8 x i16> %854, %857
  %859 = sub <8 x i16> zeroinitializer, %858
  %860 = icmp slt <8 x i16> %858, zeroinitializer
  %861 = select <8 x i1> %860, <8 x i16> %859, <8 x i16> %858
  %862 = lshr <8 x i16> %861, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %863 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %862, <8 x i16> zeroinitializer) #5
  %864 = lshr <8 x i16> %863, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %865 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %851, <8 x i16> %864) #5
  %866 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %865, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %867 = icmp slt <16 x i8> %866, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %868 = select <16 x i1> %867, <16 x i8> %866, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %869 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %868
  %870 = bitcast i8* %840 to <16 x i8>*
  store <16 x i8> %869, <16 x i8>* %870, align 16
  %871 = getelementptr inbounds i16, i16* %10, i64 416
  %872 = getelementptr inbounds i16, i16* %11, i64 416
  %873 = getelementptr inbounds i8, i8* %804, i64 32
  %874 = bitcast i16* %871 to <8 x i16>*
  %875 = load <8 x i16>, <8 x i16>* %874, align 16
  %876 = bitcast i16* %872 to <8 x i16>*
  %877 = load <8 x i16>, <8 x i16>* %876, align 16
  %878 = sub <8 x i16> %875, %877
  %879 = sub <8 x i16> zeroinitializer, %878
  %880 = icmp slt <8 x i16> %878, zeroinitializer
  %881 = select <8 x i1> %880, <8 x i16> %879, <8 x i16> %878
  %882 = lshr <8 x i16> %881, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %883 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %882, <8 x i16> zeroinitializer) #5
  %884 = lshr <8 x i16> %883, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %885 = getelementptr inbounds i16, i16* %10, i64 424
  %886 = bitcast i16* %885 to <8 x i16>*
  %887 = load <8 x i16>, <8 x i16>* %886, align 16
  %888 = getelementptr inbounds i16, i16* %11, i64 424
  %889 = bitcast i16* %888 to <8 x i16>*
  %890 = load <8 x i16>, <8 x i16>* %889, align 16
  %891 = sub <8 x i16> %887, %890
  %892 = sub <8 x i16> zeroinitializer, %891
  %893 = icmp slt <8 x i16> %891, zeroinitializer
  %894 = select <8 x i1> %893, <8 x i16> %892, <8 x i16> %891
  %895 = lshr <8 x i16> %894, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %896 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %895, <8 x i16> zeroinitializer) #5
  %897 = lshr <8 x i16> %896, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %898 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %884, <8 x i16> %897) #5
  %899 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %898, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %900 = icmp slt <16 x i8> %899, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %901 = select <16 x i1> %900, <16 x i8> %899, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %902 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %901
  %903 = bitcast i8* %873 to <16 x i8>*
  store <16 x i8> %902, <16 x i8>* %903, align 16
  %904 = getelementptr inbounds i16, i16* %10, i64 432
  %905 = getelementptr inbounds i16, i16* %11, i64 432
  %906 = getelementptr inbounds i8, i8* %804, i64 48
  %907 = bitcast i16* %904 to <8 x i16>*
  %908 = load <8 x i16>, <8 x i16>* %907, align 16
  %909 = bitcast i16* %905 to <8 x i16>*
  %910 = load <8 x i16>, <8 x i16>* %909, align 16
  %911 = sub <8 x i16> %908, %910
  %912 = sub <8 x i16> zeroinitializer, %911
  %913 = icmp slt <8 x i16> %911, zeroinitializer
  %914 = select <8 x i1> %913, <8 x i16> %912, <8 x i16> %911
  %915 = lshr <8 x i16> %914, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %916 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %915, <8 x i16> zeroinitializer) #5
  %917 = lshr <8 x i16> %916, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %918 = getelementptr inbounds i16, i16* %10, i64 440
  %919 = bitcast i16* %918 to <8 x i16>*
  %920 = load <8 x i16>, <8 x i16>* %919, align 16
  %921 = getelementptr inbounds i16, i16* %11, i64 440
  %922 = bitcast i16* %921 to <8 x i16>*
  %923 = load <8 x i16>, <8 x i16>* %922, align 16
  %924 = sub <8 x i16> %920, %923
  %925 = sub <8 x i16> zeroinitializer, %924
  %926 = icmp slt <8 x i16> %924, zeroinitializer
  %927 = select <8 x i1> %926, <8 x i16> %925, <8 x i16> %924
  %928 = lshr <8 x i16> %927, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %929 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %928, <8 x i16> zeroinitializer) #5
  %930 = lshr <8 x i16> %929, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %931 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %917, <8 x i16> %930) #5
  %932 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %931, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %933 = icmp slt <16 x i8> %932, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %934 = select <16 x i1> %933, <16 x i8> %932, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %935 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %934
  %936 = bitcast i8* %906 to <16 x i8>*
  store <16 x i8> %935, <16 x i8>* %936, align 16
  %937 = getelementptr inbounds i16, i16* %10, i64 448
  %938 = getelementptr inbounds i16, i16* %11, i64 448
  %939 = getelementptr inbounds i8, i8* %804, i64 64
  %940 = bitcast i16* %937 to <8 x i16>*
  %941 = load <8 x i16>, <8 x i16>* %940, align 16
  %942 = bitcast i16* %938 to <8 x i16>*
  %943 = load <8 x i16>, <8 x i16>* %942, align 16
  %944 = sub <8 x i16> %941, %943
  %945 = sub <8 x i16> zeroinitializer, %944
  %946 = icmp slt <8 x i16> %944, zeroinitializer
  %947 = select <8 x i1> %946, <8 x i16> %945, <8 x i16> %944
  %948 = lshr <8 x i16> %947, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %949 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %948, <8 x i16> zeroinitializer) #5
  %950 = lshr <8 x i16> %949, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %951 = getelementptr inbounds i16, i16* %10, i64 456
  %952 = bitcast i16* %951 to <8 x i16>*
  %953 = load <8 x i16>, <8 x i16>* %952, align 16
  %954 = getelementptr inbounds i16, i16* %11, i64 456
  %955 = bitcast i16* %954 to <8 x i16>*
  %956 = load <8 x i16>, <8 x i16>* %955, align 16
  %957 = sub <8 x i16> %953, %956
  %958 = sub <8 x i16> zeroinitializer, %957
  %959 = icmp slt <8 x i16> %957, zeroinitializer
  %960 = select <8 x i1> %959, <8 x i16> %958, <8 x i16> %957
  %961 = lshr <8 x i16> %960, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %962 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %961, <8 x i16> zeroinitializer) #5
  %963 = lshr <8 x i16> %962, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %964 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %950, <8 x i16> %963) #5
  %965 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %964, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %966 = icmp slt <16 x i8> %965, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %967 = select <16 x i1> %966, <16 x i8> %965, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %968 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %967
  %969 = bitcast i8* %939 to <16 x i8>*
  store <16 x i8> %968, <16 x i8>* %969, align 16
  %970 = getelementptr inbounds i16, i16* %10, i64 464
  %971 = getelementptr inbounds i16, i16* %11, i64 464
  %972 = getelementptr inbounds i8, i8* %939, i64 16
  %973 = bitcast i16* %970 to <8 x i16>*
  %974 = load <8 x i16>, <8 x i16>* %973, align 16
  %975 = bitcast i16* %971 to <8 x i16>*
  %976 = load <8 x i16>, <8 x i16>* %975, align 16
  %977 = sub <8 x i16> %974, %976
  %978 = sub <8 x i16> zeroinitializer, %977
  %979 = icmp slt <8 x i16> %977, zeroinitializer
  %980 = select <8 x i1> %979, <8 x i16> %978, <8 x i16> %977
  %981 = lshr <8 x i16> %980, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %982 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %981, <8 x i16> zeroinitializer) #5
  %983 = lshr <8 x i16> %982, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %984 = getelementptr inbounds i16, i16* %10, i64 472
  %985 = bitcast i16* %984 to <8 x i16>*
  %986 = load <8 x i16>, <8 x i16>* %985, align 16
  %987 = getelementptr inbounds i16, i16* %11, i64 472
  %988 = bitcast i16* %987 to <8 x i16>*
  %989 = load <8 x i16>, <8 x i16>* %988, align 16
  %990 = sub <8 x i16> %986, %989
  %991 = sub <8 x i16> zeroinitializer, %990
  %992 = icmp slt <8 x i16> %990, zeroinitializer
  %993 = select <8 x i1> %992, <8 x i16> %991, <8 x i16> %990
  %994 = lshr <8 x i16> %993, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %995 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %994, <8 x i16> zeroinitializer) #5
  %996 = lshr <8 x i16> %995, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %997 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %983, <8 x i16> %996) #5
  %998 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %997, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %999 = icmp slt <16 x i8> %998, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1000 = select <16 x i1> %999, <16 x i8> %998, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1001 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1000
  %1002 = bitcast i8* %972 to <16 x i8>*
  store <16 x i8> %1001, <16 x i8>* %1002, align 16
  %1003 = getelementptr inbounds i16, i16* %10, i64 480
  %1004 = getelementptr inbounds i16, i16* %11, i64 480
  %1005 = getelementptr inbounds i8, i8* %939, i64 32
  %1006 = bitcast i16* %1003 to <8 x i16>*
  %1007 = load <8 x i16>, <8 x i16>* %1006, align 16
  %1008 = bitcast i16* %1004 to <8 x i16>*
  %1009 = load <8 x i16>, <8 x i16>* %1008, align 16
  %1010 = sub <8 x i16> %1007, %1009
  %1011 = sub <8 x i16> zeroinitializer, %1010
  %1012 = icmp slt <8 x i16> %1010, zeroinitializer
  %1013 = select <8 x i1> %1012, <8 x i16> %1011, <8 x i16> %1010
  %1014 = lshr <8 x i16> %1013, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1015 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1014, <8 x i16> zeroinitializer) #5
  %1016 = lshr <8 x i16> %1015, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1017 = getelementptr inbounds i16, i16* %10, i64 488
  %1018 = bitcast i16* %1017 to <8 x i16>*
  %1019 = load <8 x i16>, <8 x i16>* %1018, align 16
  %1020 = getelementptr inbounds i16, i16* %11, i64 488
  %1021 = bitcast i16* %1020 to <8 x i16>*
  %1022 = load <8 x i16>, <8 x i16>* %1021, align 16
  %1023 = sub <8 x i16> %1019, %1022
  %1024 = sub <8 x i16> zeroinitializer, %1023
  %1025 = icmp slt <8 x i16> %1023, zeroinitializer
  %1026 = select <8 x i1> %1025, <8 x i16> %1024, <8 x i16> %1023
  %1027 = lshr <8 x i16> %1026, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1028 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1027, <8 x i16> zeroinitializer) #5
  %1029 = lshr <8 x i16> %1028, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1030 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1016, <8 x i16> %1029) #5
  %1031 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1030, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1032 = icmp slt <16 x i8> %1031, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1033 = select <16 x i1> %1032, <16 x i8> %1031, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1034 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1033
  %1035 = bitcast i8* %1005 to <16 x i8>*
  store <16 x i8> %1034, <16 x i8>* %1035, align 16
  %1036 = getelementptr inbounds i16, i16* %10, i64 496
  %1037 = getelementptr inbounds i16, i16* %11, i64 496
  %1038 = getelementptr inbounds i8, i8* %939, i64 48
  %1039 = bitcast i16* %1036 to <8 x i16>*
  %1040 = load <8 x i16>, <8 x i16>* %1039, align 16
  %1041 = bitcast i16* %1037 to <8 x i16>*
  %1042 = load <8 x i16>, <8 x i16>* %1041, align 16
  %1043 = sub <8 x i16> %1040, %1042
  %1044 = sub <8 x i16> zeroinitializer, %1043
  %1045 = icmp slt <8 x i16> %1043, zeroinitializer
  %1046 = select <8 x i1> %1045, <8 x i16> %1044, <8 x i16> %1043
  %1047 = lshr <8 x i16> %1046, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1048 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1047, <8 x i16> zeroinitializer) #5
  %1049 = lshr <8 x i16> %1048, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1050 = getelementptr inbounds i16, i16* %10, i64 504
  %1051 = bitcast i16* %1050 to <8 x i16>*
  %1052 = load <8 x i16>, <8 x i16>* %1051, align 16
  %1053 = getelementptr inbounds i16, i16* %11, i64 504
  %1054 = bitcast i16* %1053 to <8 x i16>*
  %1055 = load <8 x i16>, <8 x i16>* %1054, align 16
  %1056 = sub <8 x i16> %1052, %1055
  %1057 = sub <8 x i16> zeroinitializer, %1056
  %1058 = icmp slt <8 x i16> %1056, zeroinitializer
  %1059 = select <8 x i1> %1058, <8 x i16> %1057, <8 x i16> %1056
  %1060 = lshr <8 x i16> %1059, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1061 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1060, <8 x i16> zeroinitializer) #5
  %1062 = lshr <8 x i16> %1061, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1063 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1049, <8 x i16> %1062) #5
  %1064 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1063, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1065 = icmp slt <16 x i8> %1064, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1066 = select <16 x i1> %1065, <16 x i8> %1064, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1067 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1066
  %1068 = bitcast i8* %1038 to <16 x i8>*
  store <16 x i8> %1067, <16 x i8>* %1068, align 16
  %1069 = getelementptr inbounds i16, i16* %10, i64 512
  %1070 = getelementptr inbounds i16, i16* %11, i64 512
  %1071 = getelementptr inbounds i8, i8* %939, i64 %7
  %1072 = bitcast i16* %1069 to <8 x i16>*
  %1073 = load <8 x i16>, <8 x i16>* %1072, align 16
  %1074 = bitcast i16* %1070 to <8 x i16>*
  %1075 = load <8 x i16>, <8 x i16>* %1074, align 16
  %1076 = sub <8 x i16> %1073, %1075
  %1077 = sub <8 x i16> zeroinitializer, %1076
  %1078 = icmp slt <8 x i16> %1076, zeroinitializer
  %1079 = select <8 x i1> %1078, <8 x i16> %1077, <8 x i16> %1076
  %1080 = lshr <8 x i16> %1079, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1081 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1080, <8 x i16> zeroinitializer) #5
  %1082 = lshr <8 x i16> %1081, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1083 = getelementptr inbounds i16, i16* %10, i64 520
  %1084 = bitcast i16* %1083 to <8 x i16>*
  %1085 = load <8 x i16>, <8 x i16>* %1084, align 16
  %1086 = getelementptr inbounds i16, i16* %11, i64 520
  %1087 = bitcast i16* %1086 to <8 x i16>*
  %1088 = load <8 x i16>, <8 x i16>* %1087, align 16
  %1089 = sub <8 x i16> %1085, %1088
  %1090 = sub <8 x i16> zeroinitializer, %1089
  %1091 = icmp slt <8 x i16> %1089, zeroinitializer
  %1092 = select <8 x i1> %1091, <8 x i16> %1090, <8 x i16> %1089
  %1093 = lshr <8 x i16> %1092, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1094 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1093, <8 x i16> zeroinitializer) #5
  %1095 = lshr <8 x i16> %1094, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1096 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1082, <8 x i16> %1095) #5
  %1097 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1096, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1098 = icmp slt <16 x i8> %1097, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1099 = select <16 x i1> %1098, <16 x i8> %1097, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1100 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1099
  %1101 = bitcast i8* %1071 to <16 x i8>*
  store <16 x i8> %1100, <16 x i8>* %1101, align 16
  %1102 = getelementptr inbounds i16, i16* %10, i64 528
  %1103 = getelementptr inbounds i16, i16* %11, i64 528
  %1104 = getelementptr inbounds i8, i8* %1071, i64 16
  %1105 = bitcast i16* %1102 to <8 x i16>*
  %1106 = load <8 x i16>, <8 x i16>* %1105, align 16
  %1107 = bitcast i16* %1103 to <8 x i16>*
  %1108 = load <8 x i16>, <8 x i16>* %1107, align 16
  %1109 = sub <8 x i16> %1106, %1108
  %1110 = sub <8 x i16> zeroinitializer, %1109
  %1111 = icmp slt <8 x i16> %1109, zeroinitializer
  %1112 = select <8 x i1> %1111, <8 x i16> %1110, <8 x i16> %1109
  %1113 = lshr <8 x i16> %1112, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1114 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1113, <8 x i16> zeroinitializer) #5
  %1115 = lshr <8 x i16> %1114, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1116 = getelementptr inbounds i16, i16* %10, i64 536
  %1117 = bitcast i16* %1116 to <8 x i16>*
  %1118 = load <8 x i16>, <8 x i16>* %1117, align 16
  %1119 = getelementptr inbounds i16, i16* %11, i64 536
  %1120 = bitcast i16* %1119 to <8 x i16>*
  %1121 = load <8 x i16>, <8 x i16>* %1120, align 16
  %1122 = sub <8 x i16> %1118, %1121
  %1123 = sub <8 x i16> zeroinitializer, %1122
  %1124 = icmp slt <8 x i16> %1122, zeroinitializer
  %1125 = select <8 x i1> %1124, <8 x i16> %1123, <8 x i16> %1122
  %1126 = lshr <8 x i16> %1125, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1127 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1126, <8 x i16> zeroinitializer) #5
  %1128 = lshr <8 x i16> %1127, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1129 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1115, <8 x i16> %1128) #5
  %1130 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1129, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1131 = icmp slt <16 x i8> %1130, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1132 = select <16 x i1> %1131, <16 x i8> %1130, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1133 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1132
  %1134 = bitcast i8* %1104 to <16 x i8>*
  store <16 x i8> %1133, <16 x i8>* %1134, align 16
  %1135 = getelementptr inbounds i16, i16* %10, i64 544
  %1136 = getelementptr inbounds i16, i16* %11, i64 544
  %1137 = getelementptr inbounds i8, i8* %1071, i64 32
  %1138 = bitcast i16* %1135 to <8 x i16>*
  %1139 = load <8 x i16>, <8 x i16>* %1138, align 16
  %1140 = bitcast i16* %1136 to <8 x i16>*
  %1141 = load <8 x i16>, <8 x i16>* %1140, align 16
  %1142 = sub <8 x i16> %1139, %1141
  %1143 = sub <8 x i16> zeroinitializer, %1142
  %1144 = icmp slt <8 x i16> %1142, zeroinitializer
  %1145 = select <8 x i1> %1144, <8 x i16> %1143, <8 x i16> %1142
  %1146 = lshr <8 x i16> %1145, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1147 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1146, <8 x i16> zeroinitializer) #5
  %1148 = lshr <8 x i16> %1147, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1149 = getelementptr inbounds i16, i16* %10, i64 552
  %1150 = bitcast i16* %1149 to <8 x i16>*
  %1151 = load <8 x i16>, <8 x i16>* %1150, align 16
  %1152 = getelementptr inbounds i16, i16* %11, i64 552
  %1153 = bitcast i16* %1152 to <8 x i16>*
  %1154 = load <8 x i16>, <8 x i16>* %1153, align 16
  %1155 = sub <8 x i16> %1151, %1154
  %1156 = sub <8 x i16> zeroinitializer, %1155
  %1157 = icmp slt <8 x i16> %1155, zeroinitializer
  %1158 = select <8 x i1> %1157, <8 x i16> %1156, <8 x i16> %1155
  %1159 = lshr <8 x i16> %1158, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1160 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1159, <8 x i16> zeroinitializer) #5
  %1161 = lshr <8 x i16> %1160, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1162 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1148, <8 x i16> %1161) #5
  %1163 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1162, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1164 = icmp slt <16 x i8> %1163, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1165 = select <16 x i1> %1164, <16 x i8> %1163, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1166 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1165
  %1167 = bitcast i8* %1137 to <16 x i8>*
  store <16 x i8> %1166, <16 x i8>* %1167, align 16
  %1168 = getelementptr inbounds i16, i16* %10, i64 560
  %1169 = getelementptr inbounds i16, i16* %11, i64 560
  %1170 = getelementptr inbounds i8, i8* %1071, i64 48
  %1171 = bitcast i16* %1168 to <8 x i16>*
  %1172 = load <8 x i16>, <8 x i16>* %1171, align 16
  %1173 = bitcast i16* %1169 to <8 x i16>*
  %1174 = load <8 x i16>, <8 x i16>* %1173, align 16
  %1175 = sub <8 x i16> %1172, %1174
  %1176 = sub <8 x i16> zeroinitializer, %1175
  %1177 = icmp slt <8 x i16> %1175, zeroinitializer
  %1178 = select <8 x i1> %1177, <8 x i16> %1176, <8 x i16> %1175
  %1179 = lshr <8 x i16> %1178, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1180 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1179, <8 x i16> zeroinitializer) #5
  %1181 = lshr <8 x i16> %1180, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1182 = getelementptr inbounds i16, i16* %10, i64 568
  %1183 = bitcast i16* %1182 to <8 x i16>*
  %1184 = load <8 x i16>, <8 x i16>* %1183, align 16
  %1185 = getelementptr inbounds i16, i16* %11, i64 568
  %1186 = bitcast i16* %1185 to <8 x i16>*
  %1187 = load <8 x i16>, <8 x i16>* %1186, align 16
  %1188 = sub <8 x i16> %1184, %1187
  %1189 = sub <8 x i16> zeroinitializer, %1188
  %1190 = icmp slt <8 x i16> %1188, zeroinitializer
  %1191 = select <8 x i1> %1190, <8 x i16> %1189, <8 x i16> %1188
  %1192 = lshr <8 x i16> %1191, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1193 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1192, <8 x i16> zeroinitializer) #5
  %1194 = lshr <8 x i16> %1193, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1195 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1181, <8 x i16> %1194) #5
  %1196 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1195, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1197 = icmp slt <16 x i8> %1196, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1198 = select <16 x i1> %1197, <16 x i8> %1196, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1199 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1198
  %1200 = bitcast i8* %1170 to <16 x i8>*
  store <16 x i8> %1199, <16 x i8>* %1200, align 16
  %1201 = getelementptr inbounds i16, i16* %10, i64 576
  %1202 = getelementptr inbounds i16, i16* %11, i64 576
  %1203 = getelementptr inbounds i8, i8* %1071, i64 64
  %1204 = bitcast i16* %1201 to <8 x i16>*
  %1205 = load <8 x i16>, <8 x i16>* %1204, align 16
  %1206 = bitcast i16* %1202 to <8 x i16>*
  %1207 = load <8 x i16>, <8 x i16>* %1206, align 16
  %1208 = sub <8 x i16> %1205, %1207
  %1209 = sub <8 x i16> zeroinitializer, %1208
  %1210 = icmp slt <8 x i16> %1208, zeroinitializer
  %1211 = select <8 x i1> %1210, <8 x i16> %1209, <8 x i16> %1208
  %1212 = lshr <8 x i16> %1211, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1213 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1212, <8 x i16> zeroinitializer) #5
  %1214 = lshr <8 x i16> %1213, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1215 = getelementptr inbounds i16, i16* %10, i64 584
  %1216 = bitcast i16* %1215 to <8 x i16>*
  %1217 = load <8 x i16>, <8 x i16>* %1216, align 16
  %1218 = getelementptr inbounds i16, i16* %11, i64 584
  %1219 = bitcast i16* %1218 to <8 x i16>*
  %1220 = load <8 x i16>, <8 x i16>* %1219, align 16
  %1221 = sub <8 x i16> %1217, %1220
  %1222 = sub <8 x i16> zeroinitializer, %1221
  %1223 = icmp slt <8 x i16> %1221, zeroinitializer
  %1224 = select <8 x i1> %1223, <8 x i16> %1222, <8 x i16> %1221
  %1225 = lshr <8 x i16> %1224, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1226 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1225, <8 x i16> zeroinitializer) #5
  %1227 = lshr <8 x i16> %1226, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1228 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1214, <8 x i16> %1227) #5
  %1229 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1228, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1230 = icmp slt <16 x i8> %1229, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1231 = select <16 x i1> %1230, <16 x i8> %1229, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1232 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1231
  %1233 = bitcast i8* %1203 to <16 x i8>*
  store <16 x i8> %1232, <16 x i8>* %1233, align 16
  %1234 = getelementptr inbounds i16, i16* %10, i64 592
  %1235 = getelementptr inbounds i16, i16* %11, i64 592
  %1236 = getelementptr inbounds i8, i8* %1203, i64 16
  %1237 = bitcast i16* %1234 to <8 x i16>*
  %1238 = load <8 x i16>, <8 x i16>* %1237, align 16
  %1239 = bitcast i16* %1235 to <8 x i16>*
  %1240 = load <8 x i16>, <8 x i16>* %1239, align 16
  %1241 = sub <8 x i16> %1238, %1240
  %1242 = sub <8 x i16> zeroinitializer, %1241
  %1243 = icmp slt <8 x i16> %1241, zeroinitializer
  %1244 = select <8 x i1> %1243, <8 x i16> %1242, <8 x i16> %1241
  %1245 = lshr <8 x i16> %1244, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1246 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1245, <8 x i16> zeroinitializer) #5
  %1247 = lshr <8 x i16> %1246, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1248 = getelementptr inbounds i16, i16* %10, i64 600
  %1249 = bitcast i16* %1248 to <8 x i16>*
  %1250 = load <8 x i16>, <8 x i16>* %1249, align 16
  %1251 = getelementptr inbounds i16, i16* %11, i64 600
  %1252 = bitcast i16* %1251 to <8 x i16>*
  %1253 = load <8 x i16>, <8 x i16>* %1252, align 16
  %1254 = sub <8 x i16> %1250, %1253
  %1255 = sub <8 x i16> zeroinitializer, %1254
  %1256 = icmp slt <8 x i16> %1254, zeroinitializer
  %1257 = select <8 x i1> %1256, <8 x i16> %1255, <8 x i16> %1254
  %1258 = lshr <8 x i16> %1257, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1259 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1258, <8 x i16> zeroinitializer) #5
  %1260 = lshr <8 x i16> %1259, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1261 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1247, <8 x i16> %1260) #5
  %1262 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1261, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1263 = icmp slt <16 x i8> %1262, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1264 = select <16 x i1> %1263, <16 x i8> %1262, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1265 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1264
  %1266 = bitcast i8* %1236 to <16 x i8>*
  store <16 x i8> %1265, <16 x i8>* %1266, align 16
  %1267 = getelementptr inbounds i16, i16* %10, i64 608
  %1268 = getelementptr inbounds i16, i16* %11, i64 608
  %1269 = getelementptr inbounds i8, i8* %1203, i64 32
  %1270 = bitcast i16* %1267 to <8 x i16>*
  %1271 = load <8 x i16>, <8 x i16>* %1270, align 16
  %1272 = bitcast i16* %1268 to <8 x i16>*
  %1273 = load <8 x i16>, <8 x i16>* %1272, align 16
  %1274 = sub <8 x i16> %1271, %1273
  %1275 = sub <8 x i16> zeroinitializer, %1274
  %1276 = icmp slt <8 x i16> %1274, zeroinitializer
  %1277 = select <8 x i1> %1276, <8 x i16> %1275, <8 x i16> %1274
  %1278 = lshr <8 x i16> %1277, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1279 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1278, <8 x i16> zeroinitializer) #5
  %1280 = lshr <8 x i16> %1279, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1281 = getelementptr inbounds i16, i16* %10, i64 616
  %1282 = bitcast i16* %1281 to <8 x i16>*
  %1283 = load <8 x i16>, <8 x i16>* %1282, align 16
  %1284 = getelementptr inbounds i16, i16* %11, i64 616
  %1285 = bitcast i16* %1284 to <8 x i16>*
  %1286 = load <8 x i16>, <8 x i16>* %1285, align 16
  %1287 = sub <8 x i16> %1283, %1286
  %1288 = sub <8 x i16> zeroinitializer, %1287
  %1289 = icmp slt <8 x i16> %1287, zeroinitializer
  %1290 = select <8 x i1> %1289, <8 x i16> %1288, <8 x i16> %1287
  %1291 = lshr <8 x i16> %1290, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1292 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1291, <8 x i16> zeroinitializer) #5
  %1293 = lshr <8 x i16> %1292, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1294 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1280, <8 x i16> %1293) #5
  %1295 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1294, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1296 = icmp slt <16 x i8> %1295, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1297 = select <16 x i1> %1296, <16 x i8> %1295, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1298 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1297
  %1299 = bitcast i8* %1269 to <16 x i8>*
  store <16 x i8> %1298, <16 x i8>* %1299, align 16
  %1300 = getelementptr inbounds i16, i16* %10, i64 624
  %1301 = getelementptr inbounds i16, i16* %11, i64 624
  %1302 = getelementptr inbounds i8, i8* %1203, i64 48
  %1303 = bitcast i16* %1300 to <8 x i16>*
  %1304 = load <8 x i16>, <8 x i16>* %1303, align 16
  %1305 = bitcast i16* %1301 to <8 x i16>*
  %1306 = load <8 x i16>, <8 x i16>* %1305, align 16
  %1307 = sub <8 x i16> %1304, %1306
  %1308 = sub <8 x i16> zeroinitializer, %1307
  %1309 = icmp slt <8 x i16> %1307, zeroinitializer
  %1310 = select <8 x i1> %1309, <8 x i16> %1308, <8 x i16> %1307
  %1311 = lshr <8 x i16> %1310, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1312 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1311, <8 x i16> zeroinitializer) #5
  %1313 = lshr <8 x i16> %1312, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1314 = getelementptr inbounds i16, i16* %10, i64 632
  %1315 = bitcast i16* %1314 to <8 x i16>*
  %1316 = load <8 x i16>, <8 x i16>* %1315, align 16
  %1317 = getelementptr inbounds i16, i16* %11, i64 632
  %1318 = bitcast i16* %1317 to <8 x i16>*
  %1319 = load <8 x i16>, <8 x i16>* %1318, align 16
  %1320 = sub <8 x i16> %1316, %1319
  %1321 = sub <8 x i16> zeroinitializer, %1320
  %1322 = icmp slt <8 x i16> %1320, zeroinitializer
  %1323 = select <8 x i1> %1322, <8 x i16> %1321, <8 x i16> %1320
  %1324 = lshr <8 x i16> %1323, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  %1325 = tail call <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16> %1324, <8 x i16> zeroinitializer) #5
  %1326 = lshr <8 x i16> %1325, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1327 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1313, <8 x i16> %1326) #5
  %1328 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1327, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1329 = icmp slt <16 x i8> %1328, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1330 = select <16 x i1> %1329, <16 x i8> %1328, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1331 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1330
  %1332 = bitcast i8* %1302 to <16 x i8>*
  store <16 x i8> %1331, <16 x i8>* %1332, align 16
  ret void
}

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.sse2.pavg.w(<8 x i16>, <8 x i16>) #3

; Function Attrs: nounwind readnone speculatable
declare <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8>, <16 x i8>) #4

; Function Attrs: nounwind readnone
declare <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16>, <8 x i16>) #3

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_124WeightMask8x8_10bpp_SSE4ILb0EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to <8 x i16>*
  %6 = load <8 x i16>, <8 x i16>* %5, align 16
  %7 = bitcast i8* %1 to <8 x i16>*
  %8 = load <8 x i16>, <8 x i16>* %7, align 16
  %9 = shufflevector <8 x i16> %6, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %10 = zext <4 x i16> %9 to <4 x i32>
  %11 = shufflevector <8 x i16> %8, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %12 = zext <4 x i16> %11 to <4 x i32>
  %13 = sub nsw <4 x i32> %10, %12
  %14 = sub nsw <4 x i32> zeroinitializer, %13
  %15 = icmp slt <4 x i32> %13, zeroinitializer
  %16 = select <4 x i1> %15, <4 x i32> %14, <4 x i32> %13
  %17 = add nuw nsw <4 x i32> %16, <i32 32, i32 32, i32 32, i32 32>
  %18 = lshr <4 x i32> %17, <i32 6, i32 6, i32 6, i32 6>
  %19 = shufflevector <8 x i16> %6, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %20 = shufflevector <8 x i16> %8, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %21 = bitcast <8 x i16> %19 to <4 x i32>
  %22 = bitcast <8 x i16> %20 to <4 x i32>
  %23 = sub <4 x i32> %21, %22
  %24 = sub <4 x i32> zeroinitializer, %23
  %25 = icmp slt <4 x i32> %23, zeroinitializer
  %26 = select <4 x i1> %25, <4 x i32> %24, <4 x i32> %23
  %27 = add nuw <4 x i32> %26, <i32 32, i32 32, i32 32, i32 32>
  %28 = lshr <4 x i32> %27, <i32 6, i32 6, i32 6, i32 6>
  %29 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %18, <4 x i32> %28) #5
  %30 = lshr <8 x i16> %29, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %31 = getelementptr inbounds i8, i8* %0, i64 16
  %32 = bitcast i8* %31 to <8 x i16>*
  %33 = load <8 x i16>, <8 x i16>* %32, align 16
  %34 = getelementptr inbounds i8, i8* %1, i64 16
  %35 = bitcast i8* %34 to <8 x i16>*
  %36 = load <8 x i16>, <8 x i16>* %35, align 16
  %37 = shufflevector <8 x i16> %33, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %38 = zext <4 x i16> %37 to <4 x i32>
  %39 = shufflevector <8 x i16> %36, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %40 = zext <4 x i16> %39 to <4 x i32>
  %41 = sub nsw <4 x i32> %38, %40
  %42 = sub nsw <4 x i32> zeroinitializer, %41
  %43 = icmp slt <4 x i32> %41, zeroinitializer
  %44 = select <4 x i1> %43, <4 x i32> %42, <4 x i32> %41
  %45 = add nuw nsw <4 x i32> %44, <i32 32, i32 32, i32 32, i32 32>
  %46 = lshr <4 x i32> %45, <i32 6, i32 6, i32 6, i32 6>
  %47 = shufflevector <8 x i16> %33, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %48 = shufflevector <8 x i16> %36, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %49 = bitcast <8 x i16> %47 to <4 x i32>
  %50 = bitcast <8 x i16> %48 to <4 x i32>
  %51 = sub <4 x i32> %49, %50
  %52 = sub <4 x i32> zeroinitializer, %51
  %53 = icmp slt <4 x i32> %51, zeroinitializer
  %54 = select <4 x i1> %53, <4 x i32> %52, <4 x i32> %51
  %55 = add nuw <4 x i32> %54, <i32 32, i32 32, i32 32, i32 32>
  %56 = lshr <4 x i32> %55, <i32 6, i32 6, i32 6, i32 6>
  %57 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %46, <4 x i32> %56) #5
  %58 = lshr <8 x i16> %57, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %59 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %30, <8 x i16> %58) #5
  %60 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %59, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %61 = icmp slt <16 x i8> %60, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %62 = select <16 x i1> %61, <16 x i8> %60, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %63 = bitcast <16 x i8> %62 to <2 x i64>
  %64 = extractelement <2 x i64> %63, i32 0
  %65 = bitcast i8* %2 to i64*
  store i64 %64, i64* %65, align 1
  %66 = getelementptr inbounds i8, i8* %2, i64 %3
  %67 = bitcast <16 x i8> %62 to <4 x float>
  %68 = shufflevector <4 x float> %67, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %69 = bitcast i8* %66 to <2 x float>*
  store <2 x float> %68, <2 x float>* %69, align 1
  %70 = getelementptr inbounds i8, i8* %0, i64 32
  %71 = getelementptr inbounds i8, i8* %1, i64 32
  %72 = shl i64 %3, 1
  %73 = getelementptr inbounds i8, i8* %2, i64 %72
  %74 = bitcast i8* %70 to <8 x i16>*
  %75 = load <8 x i16>, <8 x i16>* %74, align 16
  %76 = bitcast i8* %71 to <8 x i16>*
  %77 = load <8 x i16>, <8 x i16>* %76, align 16
  %78 = shufflevector <8 x i16> %75, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %79 = zext <4 x i16> %78 to <4 x i32>
  %80 = shufflevector <8 x i16> %77, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %81 = zext <4 x i16> %80 to <4 x i32>
  %82 = sub nsw <4 x i32> %79, %81
  %83 = sub nsw <4 x i32> zeroinitializer, %82
  %84 = icmp slt <4 x i32> %82, zeroinitializer
  %85 = select <4 x i1> %84, <4 x i32> %83, <4 x i32> %82
  %86 = add nuw nsw <4 x i32> %85, <i32 32, i32 32, i32 32, i32 32>
  %87 = lshr <4 x i32> %86, <i32 6, i32 6, i32 6, i32 6>
  %88 = shufflevector <8 x i16> %75, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %89 = shufflevector <8 x i16> %77, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %90 = bitcast <8 x i16> %88 to <4 x i32>
  %91 = bitcast <8 x i16> %89 to <4 x i32>
  %92 = sub <4 x i32> %90, %91
  %93 = sub <4 x i32> zeroinitializer, %92
  %94 = icmp slt <4 x i32> %92, zeroinitializer
  %95 = select <4 x i1> %94, <4 x i32> %93, <4 x i32> %92
  %96 = add nuw <4 x i32> %95, <i32 32, i32 32, i32 32, i32 32>
  %97 = lshr <4 x i32> %96, <i32 6, i32 6, i32 6, i32 6>
  %98 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %87, <4 x i32> %97) #5
  %99 = lshr <8 x i16> %98, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %100 = getelementptr inbounds i8, i8* %0, i64 48
  %101 = bitcast i8* %100 to <8 x i16>*
  %102 = load <8 x i16>, <8 x i16>* %101, align 16
  %103 = getelementptr inbounds i8, i8* %1, i64 48
  %104 = bitcast i8* %103 to <8 x i16>*
  %105 = load <8 x i16>, <8 x i16>* %104, align 16
  %106 = shufflevector <8 x i16> %102, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %107 = zext <4 x i16> %106 to <4 x i32>
  %108 = shufflevector <8 x i16> %105, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %109 = zext <4 x i16> %108 to <4 x i32>
  %110 = sub nsw <4 x i32> %107, %109
  %111 = sub nsw <4 x i32> zeroinitializer, %110
  %112 = icmp slt <4 x i32> %110, zeroinitializer
  %113 = select <4 x i1> %112, <4 x i32> %111, <4 x i32> %110
  %114 = add nuw nsw <4 x i32> %113, <i32 32, i32 32, i32 32, i32 32>
  %115 = lshr <4 x i32> %114, <i32 6, i32 6, i32 6, i32 6>
  %116 = shufflevector <8 x i16> %102, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %117 = shufflevector <8 x i16> %105, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %118 = bitcast <8 x i16> %116 to <4 x i32>
  %119 = bitcast <8 x i16> %117 to <4 x i32>
  %120 = sub <4 x i32> %118, %119
  %121 = sub <4 x i32> zeroinitializer, %120
  %122 = icmp slt <4 x i32> %120, zeroinitializer
  %123 = select <4 x i1> %122, <4 x i32> %121, <4 x i32> %120
  %124 = add nuw <4 x i32> %123, <i32 32, i32 32, i32 32, i32 32>
  %125 = lshr <4 x i32> %124, <i32 6, i32 6, i32 6, i32 6>
  %126 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %115, <4 x i32> %125) #5
  %127 = lshr <8 x i16> %126, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %128 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %99, <8 x i16> %127) #5
  %129 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %128, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %130 = icmp slt <16 x i8> %129, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %131 = select <16 x i1> %130, <16 x i8> %129, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %132 = bitcast <16 x i8> %131 to <2 x i64>
  %133 = extractelement <2 x i64> %132, i32 0
  %134 = bitcast i8* %73 to i64*
  store i64 %133, i64* %134, align 1
  %135 = getelementptr inbounds i8, i8* %73, i64 %3
  %136 = bitcast <16 x i8> %131 to <4 x float>
  %137 = shufflevector <4 x float> %136, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %138 = bitcast i8* %135 to <2 x float>*
  store <2 x float> %137, <2 x float>* %138, align 1
  %139 = getelementptr inbounds i8, i8* %0, i64 64
  %140 = getelementptr inbounds i8, i8* %1, i64 64
  %141 = getelementptr inbounds i8, i8* %73, i64 %72
  %142 = bitcast i8* %139 to <8 x i16>*
  %143 = load <8 x i16>, <8 x i16>* %142, align 16
  %144 = bitcast i8* %140 to <8 x i16>*
  %145 = load <8 x i16>, <8 x i16>* %144, align 16
  %146 = shufflevector <8 x i16> %143, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %147 = zext <4 x i16> %146 to <4 x i32>
  %148 = shufflevector <8 x i16> %145, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %149 = zext <4 x i16> %148 to <4 x i32>
  %150 = sub nsw <4 x i32> %147, %149
  %151 = sub nsw <4 x i32> zeroinitializer, %150
  %152 = icmp slt <4 x i32> %150, zeroinitializer
  %153 = select <4 x i1> %152, <4 x i32> %151, <4 x i32> %150
  %154 = add nuw nsw <4 x i32> %153, <i32 32, i32 32, i32 32, i32 32>
  %155 = lshr <4 x i32> %154, <i32 6, i32 6, i32 6, i32 6>
  %156 = shufflevector <8 x i16> %143, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %157 = shufflevector <8 x i16> %145, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %158 = bitcast <8 x i16> %156 to <4 x i32>
  %159 = bitcast <8 x i16> %157 to <4 x i32>
  %160 = sub <4 x i32> %158, %159
  %161 = sub <4 x i32> zeroinitializer, %160
  %162 = icmp slt <4 x i32> %160, zeroinitializer
  %163 = select <4 x i1> %162, <4 x i32> %161, <4 x i32> %160
  %164 = add nuw <4 x i32> %163, <i32 32, i32 32, i32 32, i32 32>
  %165 = lshr <4 x i32> %164, <i32 6, i32 6, i32 6, i32 6>
  %166 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %155, <4 x i32> %165) #5
  %167 = lshr <8 x i16> %166, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %168 = getelementptr inbounds i8, i8* %0, i64 80
  %169 = bitcast i8* %168 to <8 x i16>*
  %170 = load <8 x i16>, <8 x i16>* %169, align 16
  %171 = getelementptr inbounds i8, i8* %1, i64 80
  %172 = bitcast i8* %171 to <8 x i16>*
  %173 = load <8 x i16>, <8 x i16>* %172, align 16
  %174 = shufflevector <8 x i16> %170, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %175 = zext <4 x i16> %174 to <4 x i32>
  %176 = shufflevector <8 x i16> %173, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %177 = zext <4 x i16> %176 to <4 x i32>
  %178 = sub nsw <4 x i32> %175, %177
  %179 = sub nsw <4 x i32> zeroinitializer, %178
  %180 = icmp slt <4 x i32> %178, zeroinitializer
  %181 = select <4 x i1> %180, <4 x i32> %179, <4 x i32> %178
  %182 = add nuw nsw <4 x i32> %181, <i32 32, i32 32, i32 32, i32 32>
  %183 = lshr <4 x i32> %182, <i32 6, i32 6, i32 6, i32 6>
  %184 = shufflevector <8 x i16> %170, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %185 = shufflevector <8 x i16> %173, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %186 = bitcast <8 x i16> %184 to <4 x i32>
  %187 = bitcast <8 x i16> %185 to <4 x i32>
  %188 = sub <4 x i32> %186, %187
  %189 = sub <4 x i32> zeroinitializer, %188
  %190 = icmp slt <4 x i32> %188, zeroinitializer
  %191 = select <4 x i1> %190, <4 x i32> %189, <4 x i32> %188
  %192 = add nuw <4 x i32> %191, <i32 32, i32 32, i32 32, i32 32>
  %193 = lshr <4 x i32> %192, <i32 6, i32 6, i32 6, i32 6>
  %194 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %183, <4 x i32> %193) #5
  %195 = lshr <8 x i16> %194, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %196 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %167, <8 x i16> %195) #5
  %197 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %196, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %198 = icmp slt <16 x i8> %197, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %199 = select <16 x i1> %198, <16 x i8> %197, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %200 = bitcast <16 x i8> %199 to <2 x i64>
  %201 = extractelement <2 x i64> %200, i32 0
  %202 = bitcast i8* %141 to i64*
  store i64 %201, i64* %202, align 1
  %203 = getelementptr inbounds i8, i8* %141, i64 %3
  %204 = bitcast <16 x i8> %199 to <4 x float>
  %205 = shufflevector <4 x float> %204, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %206 = bitcast i8* %203 to <2 x float>*
  store <2 x float> %205, <2 x float>* %206, align 1
  %207 = getelementptr inbounds i8, i8* %0, i64 96
  %208 = getelementptr inbounds i8, i8* %1, i64 96
  %209 = getelementptr inbounds i8, i8* %141, i64 %72
  %210 = bitcast i8* %207 to <8 x i16>*
  %211 = load <8 x i16>, <8 x i16>* %210, align 16
  %212 = bitcast i8* %208 to <8 x i16>*
  %213 = load <8 x i16>, <8 x i16>* %212, align 16
  %214 = shufflevector <8 x i16> %211, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %215 = zext <4 x i16> %214 to <4 x i32>
  %216 = shufflevector <8 x i16> %213, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %217 = zext <4 x i16> %216 to <4 x i32>
  %218 = sub nsw <4 x i32> %215, %217
  %219 = sub nsw <4 x i32> zeroinitializer, %218
  %220 = icmp slt <4 x i32> %218, zeroinitializer
  %221 = select <4 x i1> %220, <4 x i32> %219, <4 x i32> %218
  %222 = add nuw nsw <4 x i32> %221, <i32 32, i32 32, i32 32, i32 32>
  %223 = lshr <4 x i32> %222, <i32 6, i32 6, i32 6, i32 6>
  %224 = shufflevector <8 x i16> %211, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %225 = shufflevector <8 x i16> %213, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %226 = bitcast <8 x i16> %224 to <4 x i32>
  %227 = bitcast <8 x i16> %225 to <4 x i32>
  %228 = sub <4 x i32> %226, %227
  %229 = sub <4 x i32> zeroinitializer, %228
  %230 = icmp slt <4 x i32> %228, zeroinitializer
  %231 = select <4 x i1> %230, <4 x i32> %229, <4 x i32> %228
  %232 = add nuw <4 x i32> %231, <i32 32, i32 32, i32 32, i32 32>
  %233 = lshr <4 x i32> %232, <i32 6, i32 6, i32 6, i32 6>
  %234 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %223, <4 x i32> %233) #5
  %235 = lshr <8 x i16> %234, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %236 = getelementptr inbounds i8, i8* %0, i64 112
  %237 = bitcast i8* %236 to <8 x i16>*
  %238 = load <8 x i16>, <8 x i16>* %237, align 16
  %239 = getelementptr inbounds i8, i8* %1, i64 112
  %240 = bitcast i8* %239 to <8 x i16>*
  %241 = load <8 x i16>, <8 x i16>* %240, align 16
  %242 = shufflevector <8 x i16> %238, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %243 = zext <4 x i16> %242 to <4 x i32>
  %244 = shufflevector <8 x i16> %241, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %245 = zext <4 x i16> %244 to <4 x i32>
  %246 = sub nsw <4 x i32> %243, %245
  %247 = sub nsw <4 x i32> zeroinitializer, %246
  %248 = icmp slt <4 x i32> %246, zeroinitializer
  %249 = select <4 x i1> %248, <4 x i32> %247, <4 x i32> %246
  %250 = add nuw nsw <4 x i32> %249, <i32 32, i32 32, i32 32, i32 32>
  %251 = lshr <4 x i32> %250, <i32 6, i32 6, i32 6, i32 6>
  %252 = shufflevector <8 x i16> %238, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %253 = shufflevector <8 x i16> %241, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %254 = bitcast <8 x i16> %252 to <4 x i32>
  %255 = bitcast <8 x i16> %253 to <4 x i32>
  %256 = sub <4 x i32> %254, %255
  %257 = sub <4 x i32> zeroinitializer, %256
  %258 = icmp slt <4 x i32> %256, zeroinitializer
  %259 = select <4 x i1> %258, <4 x i32> %257, <4 x i32> %256
  %260 = add nuw <4 x i32> %259, <i32 32, i32 32, i32 32, i32 32>
  %261 = lshr <4 x i32> %260, <i32 6, i32 6, i32 6, i32 6>
  %262 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %251, <4 x i32> %261) #5
  %263 = lshr <8 x i16> %262, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %264 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %235, <8 x i16> %263) #5
  %265 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %264, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %266 = icmp slt <16 x i8> %265, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %267 = select <16 x i1> %266, <16 x i8> %265, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %268 = bitcast <16 x i8> %267 to <2 x i64>
  %269 = extractelement <2 x i64> %268, i32 0
  %270 = bitcast i8* %209 to i64*
  store i64 %269, i64* %270, align 1
  %271 = getelementptr inbounds i8, i8* %209, i64 %3
  %272 = bitcast <16 x i8> %267 to <4 x float>
  %273 = shufflevector <4 x float> %272, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %274 = bitcast i8* %271 to <2 x float>*
  store <2 x float> %273, <2 x float>* %274, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_124WeightMask8x8_10bpp_SSE4ILb1EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to <8 x i16>*
  %6 = load <8 x i16>, <8 x i16>* %5, align 16
  %7 = bitcast i8* %1 to <8 x i16>*
  %8 = load <8 x i16>, <8 x i16>* %7, align 16
  %9 = shufflevector <8 x i16> %6, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %10 = zext <4 x i16> %9 to <4 x i32>
  %11 = shufflevector <8 x i16> %8, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %12 = zext <4 x i16> %11 to <4 x i32>
  %13 = sub nsw <4 x i32> %10, %12
  %14 = sub nsw <4 x i32> zeroinitializer, %13
  %15 = icmp slt <4 x i32> %13, zeroinitializer
  %16 = select <4 x i1> %15, <4 x i32> %14, <4 x i32> %13
  %17 = add nuw nsw <4 x i32> %16, <i32 32, i32 32, i32 32, i32 32>
  %18 = lshr <4 x i32> %17, <i32 6, i32 6, i32 6, i32 6>
  %19 = shufflevector <8 x i16> %6, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %20 = shufflevector <8 x i16> %8, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %21 = bitcast <8 x i16> %19 to <4 x i32>
  %22 = bitcast <8 x i16> %20 to <4 x i32>
  %23 = sub <4 x i32> %21, %22
  %24 = sub <4 x i32> zeroinitializer, %23
  %25 = icmp slt <4 x i32> %23, zeroinitializer
  %26 = select <4 x i1> %25, <4 x i32> %24, <4 x i32> %23
  %27 = add nuw <4 x i32> %26, <i32 32, i32 32, i32 32, i32 32>
  %28 = lshr <4 x i32> %27, <i32 6, i32 6, i32 6, i32 6>
  %29 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %18, <4 x i32> %28) #5
  %30 = lshr <8 x i16> %29, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %31 = getelementptr inbounds i8, i8* %0, i64 16
  %32 = bitcast i8* %31 to <8 x i16>*
  %33 = load <8 x i16>, <8 x i16>* %32, align 16
  %34 = getelementptr inbounds i8, i8* %1, i64 16
  %35 = bitcast i8* %34 to <8 x i16>*
  %36 = load <8 x i16>, <8 x i16>* %35, align 16
  %37 = shufflevector <8 x i16> %33, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %38 = zext <4 x i16> %37 to <4 x i32>
  %39 = shufflevector <8 x i16> %36, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %40 = zext <4 x i16> %39 to <4 x i32>
  %41 = sub nsw <4 x i32> %38, %40
  %42 = sub nsw <4 x i32> zeroinitializer, %41
  %43 = icmp slt <4 x i32> %41, zeroinitializer
  %44 = select <4 x i1> %43, <4 x i32> %42, <4 x i32> %41
  %45 = add nuw nsw <4 x i32> %44, <i32 32, i32 32, i32 32, i32 32>
  %46 = lshr <4 x i32> %45, <i32 6, i32 6, i32 6, i32 6>
  %47 = shufflevector <8 x i16> %33, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %48 = shufflevector <8 x i16> %36, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %49 = bitcast <8 x i16> %47 to <4 x i32>
  %50 = bitcast <8 x i16> %48 to <4 x i32>
  %51 = sub <4 x i32> %49, %50
  %52 = sub <4 x i32> zeroinitializer, %51
  %53 = icmp slt <4 x i32> %51, zeroinitializer
  %54 = select <4 x i1> %53, <4 x i32> %52, <4 x i32> %51
  %55 = add nuw <4 x i32> %54, <i32 32, i32 32, i32 32, i32 32>
  %56 = lshr <4 x i32> %55, <i32 6, i32 6, i32 6, i32 6>
  %57 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %46, <4 x i32> %56) #5
  %58 = lshr <8 x i16> %57, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %59 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %30, <8 x i16> %58) #5
  %60 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %59, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %61 = icmp slt <16 x i8> %60, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %62 = select <16 x i1> %61, <16 x i8> %60, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %63 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %62
  %64 = bitcast <16 x i8> %63 to <2 x i64>
  %65 = extractelement <2 x i64> %64, i32 0
  %66 = bitcast i8* %2 to i64*
  store i64 %65, i64* %66, align 1
  %67 = getelementptr inbounds i8, i8* %2, i64 %3
  %68 = bitcast <16 x i8> %63 to <4 x float>
  %69 = shufflevector <4 x float> %68, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %70 = bitcast i8* %67 to <2 x float>*
  store <2 x float> %69, <2 x float>* %70, align 1
  %71 = getelementptr inbounds i8, i8* %0, i64 32
  %72 = getelementptr inbounds i8, i8* %1, i64 32
  %73 = shl i64 %3, 1
  %74 = getelementptr inbounds i8, i8* %2, i64 %73
  %75 = bitcast i8* %71 to <8 x i16>*
  %76 = load <8 x i16>, <8 x i16>* %75, align 16
  %77 = bitcast i8* %72 to <8 x i16>*
  %78 = load <8 x i16>, <8 x i16>* %77, align 16
  %79 = shufflevector <8 x i16> %76, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %80 = zext <4 x i16> %79 to <4 x i32>
  %81 = shufflevector <8 x i16> %78, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %82 = zext <4 x i16> %81 to <4 x i32>
  %83 = sub nsw <4 x i32> %80, %82
  %84 = sub nsw <4 x i32> zeroinitializer, %83
  %85 = icmp slt <4 x i32> %83, zeroinitializer
  %86 = select <4 x i1> %85, <4 x i32> %84, <4 x i32> %83
  %87 = add nuw nsw <4 x i32> %86, <i32 32, i32 32, i32 32, i32 32>
  %88 = lshr <4 x i32> %87, <i32 6, i32 6, i32 6, i32 6>
  %89 = shufflevector <8 x i16> %76, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %90 = shufflevector <8 x i16> %78, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %91 = bitcast <8 x i16> %89 to <4 x i32>
  %92 = bitcast <8 x i16> %90 to <4 x i32>
  %93 = sub <4 x i32> %91, %92
  %94 = sub <4 x i32> zeroinitializer, %93
  %95 = icmp slt <4 x i32> %93, zeroinitializer
  %96 = select <4 x i1> %95, <4 x i32> %94, <4 x i32> %93
  %97 = add nuw <4 x i32> %96, <i32 32, i32 32, i32 32, i32 32>
  %98 = lshr <4 x i32> %97, <i32 6, i32 6, i32 6, i32 6>
  %99 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %88, <4 x i32> %98) #5
  %100 = lshr <8 x i16> %99, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %101 = getelementptr inbounds i8, i8* %0, i64 48
  %102 = bitcast i8* %101 to <8 x i16>*
  %103 = load <8 x i16>, <8 x i16>* %102, align 16
  %104 = getelementptr inbounds i8, i8* %1, i64 48
  %105 = bitcast i8* %104 to <8 x i16>*
  %106 = load <8 x i16>, <8 x i16>* %105, align 16
  %107 = shufflevector <8 x i16> %103, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %108 = zext <4 x i16> %107 to <4 x i32>
  %109 = shufflevector <8 x i16> %106, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %110 = zext <4 x i16> %109 to <4 x i32>
  %111 = sub nsw <4 x i32> %108, %110
  %112 = sub nsw <4 x i32> zeroinitializer, %111
  %113 = icmp slt <4 x i32> %111, zeroinitializer
  %114 = select <4 x i1> %113, <4 x i32> %112, <4 x i32> %111
  %115 = add nuw nsw <4 x i32> %114, <i32 32, i32 32, i32 32, i32 32>
  %116 = lshr <4 x i32> %115, <i32 6, i32 6, i32 6, i32 6>
  %117 = shufflevector <8 x i16> %103, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %118 = shufflevector <8 x i16> %106, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %119 = bitcast <8 x i16> %117 to <4 x i32>
  %120 = bitcast <8 x i16> %118 to <4 x i32>
  %121 = sub <4 x i32> %119, %120
  %122 = sub <4 x i32> zeroinitializer, %121
  %123 = icmp slt <4 x i32> %121, zeroinitializer
  %124 = select <4 x i1> %123, <4 x i32> %122, <4 x i32> %121
  %125 = add nuw <4 x i32> %124, <i32 32, i32 32, i32 32, i32 32>
  %126 = lshr <4 x i32> %125, <i32 6, i32 6, i32 6, i32 6>
  %127 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %116, <4 x i32> %126) #5
  %128 = lshr <8 x i16> %127, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %129 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %100, <8 x i16> %128) #5
  %130 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %129, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %131 = icmp slt <16 x i8> %130, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %132 = select <16 x i1> %131, <16 x i8> %130, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %133 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %132
  %134 = bitcast <16 x i8> %133 to <2 x i64>
  %135 = extractelement <2 x i64> %134, i32 0
  %136 = bitcast i8* %74 to i64*
  store i64 %135, i64* %136, align 1
  %137 = getelementptr inbounds i8, i8* %74, i64 %3
  %138 = bitcast <16 x i8> %133 to <4 x float>
  %139 = shufflevector <4 x float> %138, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %140 = bitcast i8* %137 to <2 x float>*
  store <2 x float> %139, <2 x float>* %140, align 1
  %141 = getelementptr inbounds i8, i8* %0, i64 64
  %142 = getelementptr inbounds i8, i8* %1, i64 64
  %143 = getelementptr inbounds i8, i8* %74, i64 %73
  %144 = bitcast i8* %141 to <8 x i16>*
  %145 = load <8 x i16>, <8 x i16>* %144, align 16
  %146 = bitcast i8* %142 to <8 x i16>*
  %147 = load <8 x i16>, <8 x i16>* %146, align 16
  %148 = shufflevector <8 x i16> %145, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %149 = zext <4 x i16> %148 to <4 x i32>
  %150 = shufflevector <8 x i16> %147, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %151 = zext <4 x i16> %150 to <4 x i32>
  %152 = sub nsw <4 x i32> %149, %151
  %153 = sub nsw <4 x i32> zeroinitializer, %152
  %154 = icmp slt <4 x i32> %152, zeroinitializer
  %155 = select <4 x i1> %154, <4 x i32> %153, <4 x i32> %152
  %156 = add nuw nsw <4 x i32> %155, <i32 32, i32 32, i32 32, i32 32>
  %157 = lshr <4 x i32> %156, <i32 6, i32 6, i32 6, i32 6>
  %158 = shufflevector <8 x i16> %145, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %159 = shufflevector <8 x i16> %147, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %160 = bitcast <8 x i16> %158 to <4 x i32>
  %161 = bitcast <8 x i16> %159 to <4 x i32>
  %162 = sub <4 x i32> %160, %161
  %163 = sub <4 x i32> zeroinitializer, %162
  %164 = icmp slt <4 x i32> %162, zeroinitializer
  %165 = select <4 x i1> %164, <4 x i32> %163, <4 x i32> %162
  %166 = add nuw <4 x i32> %165, <i32 32, i32 32, i32 32, i32 32>
  %167 = lshr <4 x i32> %166, <i32 6, i32 6, i32 6, i32 6>
  %168 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %157, <4 x i32> %167) #5
  %169 = lshr <8 x i16> %168, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %170 = getelementptr inbounds i8, i8* %0, i64 80
  %171 = bitcast i8* %170 to <8 x i16>*
  %172 = load <8 x i16>, <8 x i16>* %171, align 16
  %173 = getelementptr inbounds i8, i8* %1, i64 80
  %174 = bitcast i8* %173 to <8 x i16>*
  %175 = load <8 x i16>, <8 x i16>* %174, align 16
  %176 = shufflevector <8 x i16> %172, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %177 = zext <4 x i16> %176 to <4 x i32>
  %178 = shufflevector <8 x i16> %175, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %179 = zext <4 x i16> %178 to <4 x i32>
  %180 = sub nsw <4 x i32> %177, %179
  %181 = sub nsw <4 x i32> zeroinitializer, %180
  %182 = icmp slt <4 x i32> %180, zeroinitializer
  %183 = select <4 x i1> %182, <4 x i32> %181, <4 x i32> %180
  %184 = add nuw nsw <4 x i32> %183, <i32 32, i32 32, i32 32, i32 32>
  %185 = lshr <4 x i32> %184, <i32 6, i32 6, i32 6, i32 6>
  %186 = shufflevector <8 x i16> %172, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %187 = shufflevector <8 x i16> %175, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %188 = bitcast <8 x i16> %186 to <4 x i32>
  %189 = bitcast <8 x i16> %187 to <4 x i32>
  %190 = sub <4 x i32> %188, %189
  %191 = sub <4 x i32> zeroinitializer, %190
  %192 = icmp slt <4 x i32> %190, zeroinitializer
  %193 = select <4 x i1> %192, <4 x i32> %191, <4 x i32> %190
  %194 = add nuw <4 x i32> %193, <i32 32, i32 32, i32 32, i32 32>
  %195 = lshr <4 x i32> %194, <i32 6, i32 6, i32 6, i32 6>
  %196 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %185, <4 x i32> %195) #5
  %197 = lshr <8 x i16> %196, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %198 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %169, <8 x i16> %197) #5
  %199 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %198, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %200 = icmp slt <16 x i8> %199, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %201 = select <16 x i1> %200, <16 x i8> %199, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %202 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %201
  %203 = bitcast <16 x i8> %202 to <2 x i64>
  %204 = extractelement <2 x i64> %203, i32 0
  %205 = bitcast i8* %143 to i64*
  store i64 %204, i64* %205, align 1
  %206 = getelementptr inbounds i8, i8* %143, i64 %3
  %207 = bitcast <16 x i8> %202 to <4 x float>
  %208 = shufflevector <4 x float> %207, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %209 = bitcast i8* %206 to <2 x float>*
  store <2 x float> %208, <2 x float>* %209, align 1
  %210 = getelementptr inbounds i8, i8* %0, i64 96
  %211 = getelementptr inbounds i8, i8* %1, i64 96
  %212 = getelementptr inbounds i8, i8* %143, i64 %73
  %213 = bitcast i8* %210 to <8 x i16>*
  %214 = load <8 x i16>, <8 x i16>* %213, align 16
  %215 = bitcast i8* %211 to <8 x i16>*
  %216 = load <8 x i16>, <8 x i16>* %215, align 16
  %217 = shufflevector <8 x i16> %214, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %218 = zext <4 x i16> %217 to <4 x i32>
  %219 = shufflevector <8 x i16> %216, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %220 = zext <4 x i16> %219 to <4 x i32>
  %221 = sub nsw <4 x i32> %218, %220
  %222 = sub nsw <4 x i32> zeroinitializer, %221
  %223 = icmp slt <4 x i32> %221, zeroinitializer
  %224 = select <4 x i1> %223, <4 x i32> %222, <4 x i32> %221
  %225 = add nuw nsw <4 x i32> %224, <i32 32, i32 32, i32 32, i32 32>
  %226 = lshr <4 x i32> %225, <i32 6, i32 6, i32 6, i32 6>
  %227 = shufflevector <8 x i16> %214, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %228 = shufflevector <8 x i16> %216, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %229 = bitcast <8 x i16> %227 to <4 x i32>
  %230 = bitcast <8 x i16> %228 to <4 x i32>
  %231 = sub <4 x i32> %229, %230
  %232 = sub <4 x i32> zeroinitializer, %231
  %233 = icmp slt <4 x i32> %231, zeroinitializer
  %234 = select <4 x i1> %233, <4 x i32> %232, <4 x i32> %231
  %235 = add nuw <4 x i32> %234, <i32 32, i32 32, i32 32, i32 32>
  %236 = lshr <4 x i32> %235, <i32 6, i32 6, i32 6, i32 6>
  %237 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %226, <4 x i32> %236) #5
  %238 = lshr <8 x i16> %237, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %239 = getelementptr inbounds i8, i8* %0, i64 112
  %240 = bitcast i8* %239 to <8 x i16>*
  %241 = load <8 x i16>, <8 x i16>* %240, align 16
  %242 = getelementptr inbounds i8, i8* %1, i64 112
  %243 = bitcast i8* %242 to <8 x i16>*
  %244 = load <8 x i16>, <8 x i16>* %243, align 16
  %245 = shufflevector <8 x i16> %241, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %246 = zext <4 x i16> %245 to <4 x i32>
  %247 = shufflevector <8 x i16> %244, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %248 = zext <4 x i16> %247 to <4 x i32>
  %249 = sub nsw <4 x i32> %246, %248
  %250 = sub nsw <4 x i32> zeroinitializer, %249
  %251 = icmp slt <4 x i32> %249, zeroinitializer
  %252 = select <4 x i1> %251, <4 x i32> %250, <4 x i32> %249
  %253 = add nuw nsw <4 x i32> %252, <i32 32, i32 32, i32 32, i32 32>
  %254 = lshr <4 x i32> %253, <i32 6, i32 6, i32 6, i32 6>
  %255 = shufflevector <8 x i16> %241, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %256 = shufflevector <8 x i16> %244, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %257 = bitcast <8 x i16> %255 to <4 x i32>
  %258 = bitcast <8 x i16> %256 to <4 x i32>
  %259 = sub <4 x i32> %257, %258
  %260 = sub <4 x i32> zeroinitializer, %259
  %261 = icmp slt <4 x i32> %259, zeroinitializer
  %262 = select <4 x i1> %261, <4 x i32> %260, <4 x i32> %259
  %263 = add nuw <4 x i32> %262, <i32 32, i32 32, i32 32, i32 32>
  %264 = lshr <4 x i32> %263, <i32 6, i32 6, i32 6, i32 6>
  %265 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %254, <4 x i32> %264) #5
  %266 = lshr <8 x i16> %265, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %267 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %238, <8 x i16> %266) #5
  %268 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %267, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %269 = icmp slt <16 x i8> %268, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %270 = select <16 x i1> %269, <16 x i8> %268, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %271 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %270
  %272 = bitcast <16 x i8> %271 to <2 x i64>
  %273 = extractelement <2 x i64> %272, i32 0
  %274 = bitcast i8* %212 to i64*
  store i64 %273, i64* %274, align 1
  %275 = getelementptr inbounds i8, i8* %212, i64 %3
  %276 = bitcast <16 x i8> %271 to <4 x float>
  %277 = shufflevector <4 x float> %276, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %278 = bitcast i8* %275 to <2 x float>*
  store <2 x float> %277, <2 x float>* %278, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_125WeightMask8x16_10bpp_SSE4ILb0EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  %7 = shl i64 %3, 1
  br label %8

8:                                                ; preds = %8, %4
  %9 = phi i8* [ %2, %4 ], [ %148, %8 ]
  %10 = phi i16* [ %5, %4 ], [ %146, %8 ]
  %11 = phi i16* [ %6, %4 ], [ %147, %8 ]
  %12 = phi i32 [ 3, %4 ], [ %149, %8 ]
  %13 = bitcast i16* %10 to <8 x i16>*
  %14 = load <8 x i16>, <8 x i16>* %13, align 16
  %15 = bitcast i16* %11 to <8 x i16>*
  %16 = load <8 x i16>, <8 x i16>* %15, align 16
  %17 = shufflevector <8 x i16> %14, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %18 = zext <4 x i16> %17 to <4 x i32>
  %19 = shufflevector <8 x i16> %16, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %20 = zext <4 x i16> %19 to <4 x i32>
  %21 = sub nsw <4 x i32> %18, %20
  %22 = sub nsw <4 x i32> zeroinitializer, %21
  %23 = icmp slt <4 x i32> %21, zeroinitializer
  %24 = select <4 x i1> %23, <4 x i32> %22, <4 x i32> %21
  %25 = add nuw nsw <4 x i32> %24, <i32 32, i32 32, i32 32, i32 32>
  %26 = lshr <4 x i32> %25, <i32 6, i32 6, i32 6, i32 6>
  %27 = shufflevector <8 x i16> %14, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %28 = shufflevector <8 x i16> %16, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %29 = bitcast <8 x i16> %27 to <4 x i32>
  %30 = bitcast <8 x i16> %28 to <4 x i32>
  %31 = sub <4 x i32> %29, %30
  %32 = sub <4 x i32> zeroinitializer, %31
  %33 = icmp slt <4 x i32> %31, zeroinitializer
  %34 = select <4 x i1> %33, <4 x i32> %32, <4 x i32> %31
  %35 = add nuw <4 x i32> %34, <i32 32, i32 32, i32 32, i32 32>
  %36 = lshr <4 x i32> %35, <i32 6, i32 6, i32 6, i32 6>
  %37 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %26, <4 x i32> %36) #5
  %38 = lshr <8 x i16> %37, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %39 = getelementptr inbounds i16, i16* %10, i64 8
  %40 = bitcast i16* %39 to <8 x i16>*
  %41 = load <8 x i16>, <8 x i16>* %40, align 16
  %42 = getelementptr inbounds i16, i16* %11, i64 8
  %43 = bitcast i16* %42 to <8 x i16>*
  %44 = load <8 x i16>, <8 x i16>* %43, align 16
  %45 = shufflevector <8 x i16> %41, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %46 = zext <4 x i16> %45 to <4 x i32>
  %47 = shufflevector <8 x i16> %44, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %48 = zext <4 x i16> %47 to <4 x i32>
  %49 = sub nsw <4 x i32> %46, %48
  %50 = sub nsw <4 x i32> zeroinitializer, %49
  %51 = icmp slt <4 x i32> %49, zeroinitializer
  %52 = select <4 x i1> %51, <4 x i32> %50, <4 x i32> %49
  %53 = add nuw nsw <4 x i32> %52, <i32 32, i32 32, i32 32, i32 32>
  %54 = lshr <4 x i32> %53, <i32 6, i32 6, i32 6, i32 6>
  %55 = shufflevector <8 x i16> %41, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %56 = shufflevector <8 x i16> %44, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %57 = bitcast <8 x i16> %55 to <4 x i32>
  %58 = bitcast <8 x i16> %56 to <4 x i32>
  %59 = sub <4 x i32> %57, %58
  %60 = sub <4 x i32> zeroinitializer, %59
  %61 = icmp slt <4 x i32> %59, zeroinitializer
  %62 = select <4 x i1> %61, <4 x i32> %60, <4 x i32> %59
  %63 = add nuw <4 x i32> %62, <i32 32, i32 32, i32 32, i32 32>
  %64 = lshr <4 x i32> %63, <i32 6, i32 6, i32 6, i32 6>
  %65 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %54, <4 x i32> %64) #5
  %66 = lshr <8 x i16> %65, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %67 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %38, <8 x i16> %66) #5
  %68 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %67, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %69 = icmp slt <16 x i8> %68, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %70 = select <16 x i1> %69, <16 x i8> %68, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %71 = bitcast <16 x i8> %70 to <2 x i64>
  %72 = extractelement <2 x i64> %71, i32 0
  %73 = bitcast i8* %9 to i64*
  store i64 %72, i64* %73, align 1
  %74 = getelementptr inbounds i8, i8* %9, i64 %3
  %75 = bitcast <16 x i8> %70 to <4 x float>
  %76 = shufflevector <4 x float> %75, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %77 = bitcast i8* %74 to <2 x float>*
  store <2 x float> %76, <2 x float>* %77, align 1
  %78 = getelementptr inbounds i16, i16* %10, i64 16
  %79 = getelementptr inbounds i16, i16* %11, i64 16
  %80 = getelementptr inbounds i8, i8* %9, i64 %7
  %81 = bitcast i16* %78 to <8 x i16>*
  %82 = load <8 x i16>, <8 x i16>* %81, align 16
  %83 = bitcast i16* %79 to <8 x i16>*
  %84 = load <8 x i16>, <8 x i16>* %83, align 16
  %85 = shufflevector <8 x i16> %82, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %86 = zext <4 x i16> %85 to <4 x i32>
  %87 = shufflevector <8 x i16> %84, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %88 = zext <4 x i16> %87 to <4 x i32>
  %89 = sub nsw <4 x i32> %86, %88
  %90 = sub nsw <4 x i32> zeroinitializer, %89
  %91 = icmp slt <4 x i32> %89, zeroinitializer
  %92 = select <4 x i1> %91, <4 x i32> %90, <4 x i32> %89
  %93 = add nuw nsw <4 x i32> %92, <i32 32, i32 32, i32 32, i32 32>
  %94 = lshr <4 x i32> %93, <i32 6, i32 6, i32 6, i32 6>
  %95 = shufflevector <8 x i16> %82, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %96 = shufflevector <8 x i16> %84, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %97 = bitcast <8 x i16> %95 to <4 x i32>
  %98 = bitcast <8 x i16> %96 to <4 x i32>
  %99 = sub <4 x i32> %97, %98
  %100 = sub <4 x i32> zeroinitializer, %99
  %101 = icmp slt <4 x i32> %99, zeroinitializer
  %102 = select <4 x i1> %101, <4 x i32> %100, <4 x i32> %99
  %103 = add nuw <4 x i32> %102, <i32 32, i32 32, i32 32, i32 32>
  %104 = lshr <4 x i32> %103, <i32 6, i32 6, i32 6, i32 6>
  %105 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %94, <4 x i32> %104) #5
  %106 = lshr <8 x i16> %105, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %107 = getelementptr inbounds i16, i16* %10, i64 24
  %108 = bitcast i16* %107 to <8 x i16>*
  %109 = load <8 x i16>, <8 x i16>* %108, align 16
  %110 = getelementptr inbounds i16, i16* %11, i64 24
  %111 = bitcast i16* %110 to <8 x i16>*
  %112 = load <8 x i16>, <8 x i16>* %111, align 16
  %113 = shufflevector <8 x i16> %109, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %114 = zext <4 x i16> %113 to <4 x i32>
  %115 = shufflevector <8 x i16> %112, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %116 = zext <4 x i16> %115 to <4 x i32>
  %117 = sub nsw <4 x i32> %114, %116
  %118 = sub nsw <4 x i32> zeroinitializer, %117
  %119 = icmp slt <4 x i32> %117, zeroinitializer
  %120 = select <4 x i1> %119, <4 x i32> %118, <4 x i32> %117
  %121 = add nuw nsw <4 x i32> %120, <i32 32, i32 32, i32 32, i32 32>
  %122 = lshr <4 x i32> %121, <i32 6, i32 6, i32 6, i32 6>
  %123 = shufflevector <8 x i16> %109, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %124 = shufflevector <8 x i16> %112, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %125 = bitcast <8 x i16> %123 to <4 x i32>
  %126 = bitcast <8 x i16> %124 to <4 x i32>
  %127 = sub <4 x i32> %125, %126
  %128 = sub <4 x i32> zeroinitializer, %127
  %129 = icmp slt <4 x i32> %127, zeroinitializer
  %130 = select <4 x i1> %129, <4 x i32> %128, <4 x i32> %127
  %131 = add nuw <4 x i32> %130, <i32 32, i32 32, i32 32, i32 32>
  %132 = lshr <4 x i32> %131, <i32 6, i32 6, i32 6, i32 6>
  %133 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %122, <4 x i32> %132) #5
  %134 = lshr <8 x i16> %133, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %135 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %106, <8 x i16> %134) #5
  %136 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %135, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %137 = icmp slt <16 x i8> %136, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %138 = select <16 x i1> %137, <16 x i8> %136, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %139 = bitcast <16 x i8> %138 to <2 x i64>
  %140 = extractelement <2 x i64> %139, i32 0
  %141 = bitcast i8* %80 to i64*
  store i64 %140, i64* %141, align 1
  %142 = getelementptr inbounds i8, i8* %80, i64 %3
  %143 = bitcast <16 x i8> %138 to <4 x float>
  %144 = shufflevector <4 x float> %143, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %145 = bitcast i8* %142 to <2 x float>*
  store <2 x float> %144, <2 x float>* %145, align 1
  %146 = getelementptr inbounds i16, i16* %10, i64 32
  %147 = getelementptr inbounds i16, i16* %11, i64 32
  %148 = getelementptr inbounds i8, i8* %80, i64 %7
  %149 = add nsw i32 %12, -1
  %150 = icmp eq i32 %149, 0
  br i1 %150, label %151, label %8

151:                                              ; preds = %8
  %152 = bitcast i16* %146 to <8 x i16>*
  %153 = load <8 x i16>, <8 x i16>* %152, align 16
  %154 = bitcast i16* %147 to <8 x i16>*
  %155 = load <8 x i16>, <8 x i16>* %154, align 16
  %156 = shufflevector <8 x i16> %153, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %157 = zext <4 x i16> %156 to <4 x i32>
  %158 = shufflevector <8 x i16> %155, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %159 = zext <4 x i16> %158 to <4 x i32>
  %160 = sub nsw <4 x i32> %157, %159
  %161 = sub nsw <4 x i32> zeroinitializer, %160
  %162 = icmp slt <4 x i32> %160, zeroinitializer
  %163 = select <4 x i1> %162, <4 x i32> %161, <4 x i32> %160
  %164 = add nuw nsw <4 x i32> %163, <i32 32, i32 32, i32 32, i32 32>
  %165 = lshr <4 x i32> %164, <i32 6, i32 6, i32 6, i32 6>
  %166 = shufflevector <8 x i16> %153, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %167 = shufflevector <8 x i16> %155, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %168 = bitcast <8 x i16> %166 to <4 x i32>
  %169 = bitcast <8 x i16> %167 to <4 x i32>
  %170 = sub <4 x i32> %168, %169
  %171 = sub <4 x i32> zeroinitializer, %170
  %172 = icmp slt <4 x i32> %170, zeroinitializer
  %173 = select <4 x i1> %172, <4 x i32> %171, <4 x i32> %170
  %174 = add nuw <4 x i32> %173, <i32 32, i32 32, i32 32, i32 32>
  %175 = lshr <4 x i32> %174, <i32 6, i32 6, i32 6, i32 6>
  %176 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %165, <4 x i32> %175) #5
  %177 = lshr <8 x i16> %176, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %178 = getelementptr inbounds i16, i16* %10, i64 40
  %179 = bitcast i16* %178 to <8 x i16>*
  %180 = load <8 x i16>, <8 x i16>* %179, align 16
  %181 = getelementptr inbounds i16, i16* %11, i64 40
  %182 = bitcast i16* %181 to <8 x i16>*
  %183 = load <8 x i16>, <8 x i16>* %182, align 16
  %184 = shufflevector <8 x i16> %180, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %185 = zext <4 x i16> %184 to <4 x i32>
  %186 = shufflevector <8 x i16> %183, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %187 = zext <4 x i16> %186 to <4 x i32>
  %188 = sub nsw <4 x i32> %185, %187
  %189 = sub nsw <4 x i32> zeroinitializer, %188
  %190 = icmp slt <4 x i32> %188, zeroinitializer
  %191 = select <4 x i1> %190, <4 x i32> %189, <4 x i32> %188
  %192 = add nuw nsw <4 x i32> %191, <i32 32, i32 32, i32 32, i32 32>
  %193 = lshr <4 x i32> %192, <i32 6, i32 6, i32 6, i32 6>
  %194 = shufflevector <8 x i16> %180, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %195 = shufflevector <8 x i16> %183, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %196 = bitcast <8 x i16> %194 to <4 x i32>
  %197 = bitcast <8 x i16> %195 to <4 x i32>
  %198 = sub <4 x i32> %196, %197
  %199 = sub <4 x i32> zeroinitializer, %198
  %200 = icmp slt <4 x i32> %198, zeroinitializer
  %201 = select <4 x i1> %200, <4 x i32> %199, <4 x i32> %198
  %202 = add nuw <4 x i32> %201, <i32 32, i32 32, i32 32, i32 32>
  %203 = lshr <4 x i32> %202, <i32 6, i32 6, i32 6, i32 6>
  %204 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %193, <4 x i32> %203) #5
  %205 = lshr <8 x i16> %204, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %206 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %177, <8 x i16> %205) #5
  %207 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %206, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %208 = icmp slt <16 x i8> %207, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %209 = select <16 x i1> %208, <16 x i8> %207, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %210 = bitcast <16 x i8> %209 to <2 x i64>
  %211 = extractelement <2 x i64> %210, i32 0
  %212 = bitcast i8* %148 to i64*
  store i64 %211, i64* %212, align 1
  %213 = getelementptr inbounds i8, i8* %148, i64 %3
  %214 = bitcast <16 x i8> %209 to <4 x float>
  %215 = shufflevector <4 x float> %214, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %216 = bitcast i8* %213 to <2 x float>*
  store <2 x float> %215, <2 x float>* %216, align 1
  %217 = getelementptr inbounds i16, i16* %10, i64 48
  %218 = getelementptr inbounds i16, i16* %11, i64 48
  %219 = getelementptr inbounds i8, i8* %148, i64 %7
  %220 = bitcast i16* %217 to <8 x i16>*
  %221 = load <8 x i16>, <8 x i16>* %220, align 16
  %222 = bitcast i16* %218 to <8 x i16>*
  %223 = load <8 x i16>, <8 x i16>* %222, align 16
  %224 = shufflevector <8 x i16> %221, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %225 = zext <4 x i16> %224 to <4 x i32>
  %226 = shufflevector <8 x i16> %223, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %227 = zext <4 x i16> %226 to <4 x i32>
  %228 = sub nsw <4 x i32> %225, %227
  %229 = sub nsw <4 x i32> zeroinitializer, %228
  %230 = icmp slt <4 x i32> %228, zeroinitializer
  %231 = select <4 x i1> %230, <4 x i32> %229, <4 x i32> %228
  %232 = add nuw nsw <4 x i32> %231, <i32 32, i32 32, i32 32, i32 32>
  %233 = lshr <4 x i32> %232, <i32 6, i32 6, i32 6, i32 6>
  %234 = shufflevector <8 x i16> %221, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %235 = shufflevector <8 x i16> %223, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %236 = bitcast <8 x i16> %234 to <4 x i32>
  %237 = bitcast <8 x i16> %235 to <4 x i32>
  %238 = sub <4 x i32> %236, %237
  %239 = sub <4 x i32> zeroinitializer, %238
  %240 = icmp slt <4 x i32> %238, zeroinitializer
  %241 = select <4 x i1> %240, <4 x i32> %239, <4 x i32> %238
  %242 = add nuw <4 x i32> %241, <i32 32, i32 32, i32 32, i32 32>
  %243 = lshr <4 x i32> %242, <i32 6, i32 6, i32 6, i32 6>
  %244 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %233, <4 x i32> %243) #5
  %245 = lshr <8 x i16> %244, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %246 = getelementptr inbounds i16, i16* %10, i64 56
  %247 = bitcast i16* %246 to <8 x i16>*
  %248 = load <8 x i16>, <8 x i16>* %247, align 16
  %249 = getelementptr inbounds i16, i16* %11, i64 56
  %250 = bitcast i16* %249 to <8 x i16>*
  %251 = load <8 x i16>, <8 x i16>* %250, align 16
  %252 = shufflevector <8 x i16> %248, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %253 = zext <4 x i16> %252 to <4 x i32>
  %254 = shufflevector <8 x i16> %251, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %255 = zext <4 x i16> %254 to <4 x i32>
  %256 = sub nsw <4 x i32> %253, %255
  %257 = sub nsw <4 x i32> zeroinitializer, %256
  %258 = icmp slt <4 x i32> %256, zeroinitializer
  %259 = select <4 x i1> %258, <4 x i32> %257, <4 x i32> %256
  %260 = add nuw nsw <4 x i32> %259, <i32 32, i32 32, i32 32, i32 32>
  %261 = lshr <4 x i32> %260, <i32 6, i32 6, i32 6, i32 6>
  %262 = shufflevector <8 x i16> %248, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %263 = shufflevector <8 x i16> %251, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %264 = bitcast <8 x i16> %262 to <4 x i32>
  %265 = bitcast <8 x i16> %263 to <4 x i32>
  %266 = sub <4 x i32> %264, %265
  %267 = sub <4 x i32> zeroinitializer, %266
  %268 = icmp slt <4 x i32> %266, zeroinitializer
  %269 = select <4 x i1> %268, <4 x i32> %267, <4 x i32> %266
  %270 = add nuw <4 x i32> %269, <i32 32, i32 32, i32 32, i32 32>
  %271 = lshr <4 x i32> %270, <i32 6, i32 6, i32 6, i32 6>
  %272 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %261, <4 x i32> %271) #5
  %273 = lshr <8 x i16> %272, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %274 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %245, <8 x i16> %273) #5
  %275 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %274, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %276 = icmp slt <16 x i8> %275, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %277 = select <16 x i1> %276, <16 x i8> %275, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %278 = bitcast <16 x i8> %277 to <2 x i64>
  %279 = extractelement <2 x i64> %278, i32 0
  %280 = bitcast i8* %219 to i64*
  store i64 %279, i64* %280, align 1
  %281 = getelementptr inbounds i8, i8* %219, i64 %3
  %282 = bitcast <16 x i8> %277 to <4 x float>
  %283 = shufflevector <4 x float> %282, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %284 = bitcast i8* %281 to <2 x float>*
  store <2 x float> %283, <2 x float>* %284, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_125WeightMask8x16_10bpp_SSE4ILb1EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  %7 = shl i64 %3, 1
  br label %8

8:                                                ; preds = %8, %4
  %9 = phi i8* [ %2, %4 ], [ %150, %8 ]
  %10 = phi i16* [ %5, %4 ], [ %148, %8 ]
  %11 = phi i16* [ %6, %4 ], [ %149, %8 ]
  %12 = phi i32 [ 3, %4 ], [ %151, %8 ]
  %13 = bitcast i16* %10 to <8 x i16>*
  %14 = load <8 x i16>, <8 x i16>* %13, align 16
  %15 = bitcast i16* %11 to <8 x i16>*
  %16 = load <8 x i16>, <8 x i16>* %15, align 16
  %17 = shufflevector <8 x i16> %14, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %18 = zext <4 x i16> %17 to <4 x i32>
  %19 = shufflevector <8 x i16> %16, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %20 = zext <4 x i16> %19 to <4 x i32>
  %21 = sub nsw <4 x i32> %18, %20
  %22 = sub nsw <4 x i32> zeroinitializer, %21
  %23 = icmp slt <4 x i32> %21, zeroinitializer
  %24 = select <4 x i1> %23, <4 x i32> %22, <4 x i32> %21
  %25 = add nuw nsw <4 x i32> %24, <i32 32, i32 32, i32 32, i32 32>
  %26 = lshr <4 x i32> %25, <i32 6, i32 6, i32 6, i32 6>
  %27 = shufflevector <8 x i16> %14, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %28 = shufflevector <8 x i16> %16, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %29 = bitcast <8 x i16> %27 to <4 x i32>
  %30 = bitcast <8 x i16> %28 to <4 x i32>
  %31 = sub <4 x i32> %29, %30
  %32 = sub <4 x i32> zeroinitializer, %31
  %33 = icmp slt <4 x i32> %31, zeroinitializer
  %34 = select <4 x i1> %33, <4 x i32> %32, <4 x i32> %31
  %35 = add nuw <4 x i32> %34, <i32 32, i32 32, i32 32, i32 32>
  %36 = lshr <4 x i32> %35, <i32 6, i32 6, i32 6, i32 6>
  %37 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %26, <4 x i32> %36) #5
  %38 = lshr <8 x i16> %37, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %39 = getelementptr inbounds i16, i16* %10, i64 8
  %40 = bitcast i16* %39 to <8 x i16>*
  %41 = load <8 x i16>, <8 x i16>* %40, align 16
  %42 = getelementptr inbounds i16, i16* %11, i64 8
  %43 = bitcast i16* %42 to <8 x i16>*
  %44 = load <8 x i16>, <8 x i16>* %43, align 16
  %45 = shufflevector <8 x i16> %41, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %46 = zext <4 x i16> %45 to <4 x i32>
  %47 = shufflevector <8 x i16> %44, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %48 = zext <4 x i16> %47 to <4 x i32>
  %49 = sub nsw <4 x i32> %46, %48
  %50 = sub nsw <4 x i32> zeroinitializer, %49
  %51 = icmp slt <4 x i32> %49, zeroinitializer
  %52 = select <4 x i1> %51, <4 x i32> %50, <4 x i32> %49
  %53 = add nuw nsw <4 x i32> %52, <i32 32, i32 32, i32 32, i32 32>
  %54 = lshr <4 x i32> %53, <i32 6, i32 6, i32 6, i32 6>
  %55 = shufflevector <8 x i16> %41, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %56 = shufflevector <8 x i16> %44, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %57 = bitcast <8 x i16> %55 to <4 x i32>
  %58 = bitcast <8 x i16> %56 to <4 x i32>
  %59 = sub <4 x i32> %57, %58
  %60 = sub <4 x i32> zeroinitializer, %59
  %61 = icmp slt <4 x i32> %59, zeroinitializer
  %62 = select <4 x i1> %61, <4 x i32> %60, <4 x i32> %59
  %63 = add nuw <4 x i32> %62, <i32 32, i32 32, i32 32, i32 32>
  %64 = lshr <4 x i32> %63, <i32 6, i32 6, i32 6, i32 6>
  %65 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %54, <4 x i32> %64) #5
  %66 = lshr <8 x i16> %65, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %67 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %38, <8 x i16> %66) #5
  %68 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %67, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %69 = icmp slt <16 x i8> %68, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %70 = select <16 x i1> %69, <16 x i8> %68, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %71 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %70
  %72 = bitcast <16 x i8> %71 to <2 x i64>
  %73 = extractelement <2 x i64> %72, i32 0
  %74 = bitcast i8* %9 to i64*
  store i64 %73, i64* %74, align 1
  %75 = getelementptr inbounds i8, i8* %9, i64 %3
  %76 = bitcast <16 x i8> %71 to <4 x float>
  %77 = shufflevector <4 x float> %76, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %78 = bitcast i8* %75 to <2 x float>*
  store <2 x float> %77, <2 x float>* %78, align 1
  %79 = getelementptr inbounds i16, i16* %10, i64 16
  %80 = getelementptr inbounds i16, i16* %11, i64 16
  %81 = getelementptr inbounds i8, i8* %9, i64 %7
  %82 = bitcast i16* %79 to <8 x i16>*
  %83 = load <8 x i16>, <8 x i16>* %82, align 16
  %84 = bitcast i16* %80 to <8 x i16>*
  %85 = load <8 x i16>, <8 x i16>* %84, align 16
  %86 = shufflevector <8 x i16> %83, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %87 = zext <4 x i16> %86 to <4 x i32>
  %88 = shufflevector <8 x i16> %85, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %89 = zext <4 x i16> %88 to <4 x i32>
  %90 = sub nsw <4 x i32> %87, %89
  %91 = sub nsw <4 x i32> zeroinitializer, %90
  %92 = icmp slt <4 x i32> %90, zeroinitializer
  %93 = select <4 x i1> %92, <4 x i32> %91, <4 x i32> %90
  %94 = add nuw nsw <4 x i32> %93, <i32 32, i32 32, i32 32, i32 32>
  %95 = lshr <4 x i32> %94, <i32 6, i32 6, i32 6, i32 6>
  %96 = shufflevector <8 x i16> %83, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %97 = shufflevector <8 x i16> %85, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %98 = bitcast <8 x i16> %96 to <4 x i32>
  %99 = bitcast <8 x i16> %97 to <4 x i32>
  %100 = sub <4 x i32> %98, %99
  %101 = sub <4 x i32> zeroinitializer, %100
  %102 = icmp slt <4 x i32> %100, zeroinitializer
  %103 = select <4 x i1> %102, <4 x i32> %101, <4 x i32> %100
  %104 = add nuw <4 x i32> %103, <i32 32, i32 32, i32 32, i32 32>
  %105 = lshr <4 x i32> %104, <i32 6, i32 6, i32 6, i32 6>
  %106 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %95, <4 x i32> %105) #5
  %107 = lshr <8 x i16> %106, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %108 = getelementptr inbounds i16, i16* %10, i64 24
  %109 = bitcast i16* %108 to <8 x i16>*
  %110 = load <8 x i16>, <8 x i16>* %109, align 16
  %111 = getelementptr inbounds i16, i16* %11, i64 24
  %112 = bitcast i16* %111 to <8 x i16>*
  %113 = load <8 x i16>, <8 x i16>* %112, align 16
  %114 = shufflevector <8 x i16> %110, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %115 = zext <4 x i16> %114 to <4 x i32>
  %116 = shufflevector <8 x i16> %113, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %117 = zext <4 x i16> %116 to <4 x i32>
  %118 = sub nsw <4 x i32> %115, %117
  %119 = sub nsw <4 x i32> zeroinitializer, %118
  %120 = icmp slt <4 x i32> %118, zeroinitializer
  %121 = select <4 x i1> %120, <4 x i32> %119, <4 x i32> %118
  %122 = add nuw nsw <4 x i32> %121, <i32 32, i32 32, i32 32, i32 32>
  %123 = lshr <4 x i32> %122, <i32 6, i32 6, i32 6, i32 6>
  %124 = shufflevector <8 x i16> %110, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %125 = shufflevector <8 x i16> %113, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %126 = bitcast <8 x i16> %124 to <4 x i32>
  %127 = bitcast <8 x i16> %125 to <4 x i32>
  %128 = sub <4 x i32> %126, %127
  %129 = sub <4 x i32> zeroinitializer, %128
  %130 = icmp slt <4 x i32> %128, zeroinitializer
  %131 = select <4 x i1> %130, <4 x i32> %129, <4 x i32> %128
  %132 = add nuw <4 x i32> %131, <i32 32, i32 32, i32 32, i32 32>
  %133 = lshr <4 x i32> %132, <i32 6, i32 6, i32 6, i32 6>
  %134 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %123, <4 x i32> %133) #5
  %135 = lshr <8 x i16> %134, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %136 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %107, <8 x i16> %135) #5
  %137 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %136, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %138 = icmp slt <16 x i8> %137, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %139 = select <16 x i1> %138, <16 x i8> %137, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %140 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %139
  %141 = bitcast <16 x i8> %140 to <2 x i64>
  %142 = extractelement <2 x i64> %141, i32 0
  %143 = bitcast i8* %81 to i64*
  store i64 %142, i64* %143, align 1
  %144 = getelementptr inbounds i8, i8* %81, i64 %3
  %145 = bitcast <16 x i8> %140 to <4 x float>
  %146 = shufflevector <4 x float> %145, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %147 = bitcast i8* %144 to <2 x float>*
  store <2 x float> %146, <2 x float>* %147, align 1
  %148 = getelementptr inbounds i16, i16* %10, i64 32
  %149 = getelementptr inbounds i16, i16* %11, i64 32
  %150 = getelementptr inbounds i8, i8* %81, i64 %7
  %151 = add nsw i32 %12, -1
  %152 = icmp eq i32 %151, 0
  br i1 %152, label %153, label %8

153:                                              ; preds = %8
  %154 = bitcast i16* %148 to <8 x i16>*
  %155 = load <8 x i16>, <8 x i16>* %154, align 16
  %156 = bitcast i16* %149 to <8 x i16>*
  %157 = load <8 x i16>, <8 x i16>* %156, align 16
  %158 = shufflevector <8 x i16> %155, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %159 = zext <4 x i16> %158 to <4 x i32>
  %160 = shufflevector <8 x i16> %157, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %161 = zext <4 x i16> %160 to <4 x i32>
  %162 = sub nsw <4 x i32> %159, %161
  %163 = sub nsw <4 x i32> zeroinitializer, %162
  %164 = icmp slt <4 x i32> %162, zeroinitializer
  %165 = select <4 x i1> %164, <4 x i32> %163, <4 x i32> %162
  %166 = add nuw nsw <4 x i32> %165, <i32 32, i32 32, i32 32, i32 32>
  %167 = lshr <4 x i32> %166, <i32 6, i32 6, i32 6, i32 6>
  %168 = shufflevector <8 x i16> %155, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %169 = shufflevector <8 x i16> %157, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %170 = bitcast <8 x i16> %168 to <4 x i32>
  %171 = bitcast <8 x i16> %169 to <4 x i32>
  %172 = sub <4 x i32> %170, %171
  %173 = sub <4 x i32> zeroinitializer, %172
  %174 = icmp slt <4 x i32> %172, zeroinitializer
  %175 = select <4 x i1> %174, <4 x i32> %173, <4 x i32> %172
  %176 = add nuw <4 x i32> %175, <i32 32, i32 32, i32 32, i32 32>
  %177 = lshr <4 x i32> %176, <i32 6, i32 6, i32 6, i32 6>
  %178 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %167, <4 x i32> %177) #5
  %179 = lshr <8 x i16> %178, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %180 = getelementptr inbounds i16, i16* %10, i64 40
  %181 = bitcast i16* %180 to <8 x i16>*
  %182 = load <8 x i16>, <8 x i16>* %181, align 16
  %183 = getelementptr inbounds i16, i16* %11, i64 40
  %184 = bitcast i16* %183 to <8 x i16>*
  %185 = load <8 x i16>, <8 x i16>* %184, align 16
  %186 = shufflevector <8 x i16> %182, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %187 = zext <4 x i16> %186 to <4 x i32>
  %188 = shufflevector <8 x i16> %185, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %189 = zext <4 x i16> %188 to <4 x i32>
  %190 = sub nsw <4 x i32> %187, %189
  %191 = sub nsw <4 x i32> zeroinitializer, %190
  %192 = icmp slt <4 x i32> %190, zeroinitializer
  %193 = select <4 x i1> %192, <4 x i32> %191, <4 x i32> %190
  %194 = add nuw nsw <4 x i32> %193, <i32 32, i32 32, i32 32, i32 32>
  %195 = lshr <4 x i32> %194, <i32 6, i32 6, i32 6, i32 6>
  %196 = shufflevector <8 x i16> %182, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %197 = shufflevector <8 x i16> %185, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %198 = bitcast <8 x i16> %196 to <4 x i32>
  %199 = bitcast <8 x i16> %197 to <4 x i32>
  %200 = sub <4 x i32> %198, %199
  %201 = sub <4 x i32> zeroinitializer, %200
  %202 = icmp slt <4 x i32> %200, zeroinitializer
  %203 = select <4 x i1> %202, <4 x i32> %201, <4 x i32> %200
  %204 = add nuw <4 x i32> %203, <i32 32, i32 32, i32 32, i32 32>
  %205 = lshr <4 x i32> %204, <i32 6, i32 6, i32 6, i32 6>
  %206 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %195, <4 x i32> %205) #5
  %207 = lshr <8 x i16> %206, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %208 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %179, <8 x i16> %207) #5
  %209 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %208, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %210 = icmp slt <16 x i8> %209, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %211 = select <16 x i1> %210, <16 x i8> %209, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %212 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %211
  %213 = bitcast <16 x i8> %212 to <2 x i64>
  %214 = extractelement <2 x i64> %213, i32 0
  %215 = bitcast i8* %150 to i64*
  store i64 %214, i64* %215, align 1
  %216 = getelementptr inbounds i8, i8* %150, i64 %3
  %217 = bitcast <16 x i8> %212 to <4 x float>
  %218 = shufflevector <4 x float> %217, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %219 = bitcast i8* %216 to <2 x float>*
  store <2 x float> %218, <2 x float>* %219, align 1
  %220 = getelementptr inbounds i16, i16* %10, i64 48
  %221 = getelementptr inbounds i16, i16* %11, i64 48
  %222 = getelementptr inbounds i8, i8* %150, i64 %7
  %223 = bitcast i16* %220 to <8 x i16>*
  %224 = load <8 x i16>, <8 x i16>* %223, align 16
  %225 = bitcast i16* %221 to <8 x i16>*
  %226 = load <8 x i16>, <8 x i16>* %225, align 16
  %227 = shufflevector <8 x i16> %224, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %228 = zext <4 x i16> %227 to <4 x i32>
  %229 = shufflevector <8 x i16> %226, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %230 = zext <4 x i16> %229 to <4 x i32>
  %231 = sub nsw <4 x i32> %228, %230
  %232 = sub nsw <4 x i32> zeroinitializer, %231
  %233 = icmp slt <4 x i32> %231, zeroinitializer
  %234 = select <4 x i1> %233, <4 x i32> %232, <4 x i32> %231
  %235 = add nuw nsw <4 x i32> %234, <i32 32, i32 32, i32 32, i32 32>
  %236 = lshr <4 x i32> %235, <i32 6, i32 6, i32 6, i32 6>
  %237 = shufflevector <8 x i16> %224, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %238 = shufflevector <8 x i16> %226, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %239 = bitcast <8 x i16> %237 to <4 x i32>
  %240 = bitcast <8 x i16> %238 to <4 x i32>
  %241 = sub <4 x i32> %239, %240
  %242 = sub <4 x i32> zeroinitializer, %241
  %243 = icmp slt <4 x i32> %241, zeroinitializer
  %244 = select <4 x i1> %243, <4 x i32> %242, <4 x i32> %241
  %245 = add nuw <4 x i32> %244, <i32 32, i32 32, i32 32, i32 32>
  %246 = lshr <4 x i32> %245, <i32 6, i32 6, i32 6, i32 6>
  %247 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %236, <4 x i32> %246) #5
  %248 = lshr <8 x i16> %247, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %249 = getelementptr inbounds i16, i16* %10, i64 56
  %250 = bitcast i16* %249 to <8 x i16>*
  %251 = load <8 x i16>, <8 x i16>* %250, align 16
  %252 = getelementptr inbounds i16, i16* %11, i64 56
  %253 = bitcast i16* %252 to <8 x i16>*
  %254 = load <8 x i16>, <8 x i16>* %253, align 16
  %255 = shufflevector <8 x i16> %251, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %256 = zext <4 x i16> %255 to <4 x i32>
  %257 = shufflevector <8 x i16> %254, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %258 = zext <4 x i16> %257 to <4 x i32>
  %259 = sub nsw <4 x i32> %256, %258
  %260 = sub nsw <4 x i32> zeroinitializer, %259
  %261 = icmp slt <4 x i32> %259, zeroinitializer
  %262 = select <4 x i1> %261, <4 x i32> %260, <4 x i32> %259
  %263 = add nuw nsw <4 x i32> %262, <i32 32, i32 32, i32 32, i32 32>
  %264 = lshr <4 x i32> %263, <i32 6, i32 6, i32 6, i32 6>
  %265 = shufflevector <8 x i16> %251, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %266 = shufflevector <8 x i16> %254, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %267 = bitcast <8 x i16> %265 to <4 x i32>
  %268 = bitcast <8 x i16> %266 to <4 x i32>
  %269 = sub <4 x i32> %267, %268
  %270 = sub <4 x i32> zeroinitializer, %269
  %271 = icmp slt <4 x i32> %269, zeroinitializer
  %272 = select <4 x i1> %271, <4 x i32> %270, <4 x i32> %269
  %273 = add nuw <4 x i32> %272, <i32 32, i32 32, i32 32, i32 32>
  %274 = lshr <4 x i32> %273, <i32 6, i32 6, i32 6, i32 6>
  %275 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %264, <4 x i32> %274) #5
  %276 = lshr <8 x i16> %275, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %277 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %248, <8 x i16> %276) #5
  %278 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %277, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %279 = icmp slt <16 x i8> %278, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %280 = select <16 x i1> %279, <16 x i8> %278, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %281 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %280
  %282 = bitcast <16 x i8> %281 to <2 x i64>
  %283 = extractelement <2 x i64> %282, i32 0
  %284 = bitcast i8* %222 to i64*
  store i64 %283, i64* %284, align 1
  %285 = getelementptr inbounds i8, i8* %222, i64 %3
  %286 = bitcast <16 x i8> %281 to <4 x float>
  %287 = shufflevector <4 x float> %286, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %288 = bitcast i8* %285 to <2 x float>*
  store <2 x float> %287, <2 x float>* %288, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_125WeightMask8x32_10bpp_SSE4ILb0EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  %7 = shl i64 %3, 1
  br label %8

8:                                                ; preds = %8, %4
  %9 = phi i8* [ %2, %4 ], [ %216, %8 ]
  %10 = phi i16* [ %5, %4 ], [ %214, %8 ]
  %11 = phi i16* [ %6, %4 ], [ %215, %8 ]
  %12 = phi i32 [ 5, %4 ], [ %217, %8 ]
  %13 = bitcast i16* %10 to <8 x i16>*
  %14 = load <8 x i16>, <8 x i16>* %13, align 16
  %15 = bitcast i16* %11 to <8 x i16>*
  %16 = load <8 x i16>, <8 x i16>* %15, align 16
  %17 = shufflevector <8 x i16> %14, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %18 = zext <4 x i16> %17 to <4 x i32>
  %19 = shufflevector <8 x i16> %16, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %20 = zext <4 x i16> %19 to <4 x i32>
  %21 = sub nsw <4 x i32> %18, %20
  %22 = sub nsw <4 x i32> zeroinitializer, %21
  %23 = icmp slt <4 x i32> %21, zeroinitializer
  %24 = select <4 x i1> %23, <4 x i32> %22, <4 x i32> %21
  %25 = add nuw nsw <4 x i32> %24, <i32 32, i32 32, i32 32, i32 32>
  %26 = lshr <4 x i32> %25, <i32 6, i32 6, i32 6, i32 6>
  %27 = shufflevector <8 x i16> %14, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %28 = shufflevector <8 x i16> %16, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %29 = bitcast <8 x i16> %27 to <4 x i32>
  %30 = bitcast <8 x i16> %28 to <4 x i32>
  %31 = sub <4 x i32> %29, %30
  %32 = sub <4 x i32> zeroinitializer, %31
  %33 = icmp slt <4 x i32> %31, zeroinitializer
  %34 = select <4 x i1> %33, <4 x i32> %32, <4 x i32> %31
  %35 = add nuw <4 x i32> %34, <i32 32, i32 32, i32 32, i32 32>
  %36 = lshr <4 x i32> %35, <i32 6, i32 6, i32 6, i32 6>
  %37 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %26, <4 x i32> %36) #5
  %38 = lshr <8 x i16> %37, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %39 = getelementptr inbounds i16, i16* %10, i64 8
  %40 = bitcast i16* %39 to <8 x i16>*
  %41 = load <8 x i16>, <8 x i16>* %40, align 16
  %42 = getelementptr inbounds i16, i16* %11, i64 8
  %43 = bitcast i16* %42 to <8 x i16>*
  %44 = load <8 x i16>, <8 x i16>* %43, align 16
  %45 = shufflevector <8 x i16> %41, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %46 = zext <4 x i16> %45 to <4 x i32>
  %47 = shufflevector <8 x i16> %44, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %48 = zext <4 x i16> %47 to <4 x i32>
  %49 = sub nsw <4 x i32> %46, %48
  %50 = sub nsw <4 x i32> zeroinitializer, %49
  %51 = icmp slt <4 x i32> %49, zeroinitializer
  %52 = select <4 x i1> %51, <4 x i32> %50, <4 x i32> %49
  %53 = add nuw nsw <4 x i32> %52, <i32 32, i32 32, i32 32, i32 32>
  %54 = lshr <4 x i32> %53, <i32 6, i32 6, i32 6, i32 6>
  %55 = shufflevector <8 x i16> %41, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %56 = shufflevector <8 x i16> %44, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %57 = bitcast <8 x i16> %55 to <4 x i32>
  %58 = bitcast <8 x i16> %56 to <4 x i32>
  %59 = sub <4 x i32> %57, %58
  %60 = sub <4 x i32> zeroinitializer, %59
  %61 = icmp slt <4 x i32> %59, zeroinitializer
  %62 = select <4 x i1> %61, <4 x i32> %60, <4 x i32> %59
  %63 = add nuw <4 x i32> %62, <i32 32, i32 32, i32 32, i32 32>
  %64 = lshr <4 x i32> %63, <i32 6, i32 6, i32 6, i32 6>
  %65 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %54, <4 x i32> %64) #5
  %66 = lshr <8 x i16> %65, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %67 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %38, <8 x i16> %66) #5
  %68 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %67, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %69 = icmp slt <16 x i8> %68, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %70 = select <16 x i1> %69, <16 x i8> %68, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %71 = bitcast <16 x i8> %70 to <2 x i64>
  %72 = extractelement <2 x i64> %71, i32 0
  %73 = bitcast i8* %9 to i64*
  store i64 %72, i64* %73, align 1
  %74 = getelementptr inbounds i8, i8* %9, i64 %3
  %75 = bitcast <16 x i8> %70 to <4 x float>
  %76 = shufflevector <4 x float> %75, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %77 = bitcast i8* %74 to <2 x float>*
  store <2 x float> %76, <2 x float>* %77, align 1
  %78 = getelementptr inbounds i16, i16* %10, i64 16
  %79 = getelementptr inbounds i16, i16* %11, i64 16
  %80 = getelementptr inbounds i8, i8* %9, i64 %7
  %81 = bitcast i16* %78 to <8 x i16>*
  %82 = load <8 x i16>, <8 x i16>* %81, align 16
  %83 = bitcast i16* %79 to <8 x i16>*
  %84 = load <8 x i16>, <8 x i16>* %83, align 16
  %85 = shufflevector <8 x i16> %82, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %86 = zext <4 x i16> %85 to <4 x i32>
  %87 = shufflevector <8 x i16> %84, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %88 = zext <4 x i16> %87 to <4 x i32>
  %89 = sub nsw <4 x i32> %86, %88
  %90 = sub nsw <4 x i32> zeroinitializer, %89
  %91 = icmp slt <4 x i32> %89, zeroinitializer
  %92 = select <4 x i1> %91, <4 x i32> %90, <4 x i32> %89
  %93 = add nuw nsw <4 x i32> %92, <i32 32, i32 32, i32 32, i32 32>
  %94 = lshr <4 x i32> %93, <i32 6, i32 6, i32 6, i32 6>
  %95 = shufflevector <8 x i16> %82, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %96 = shufflevector <8 x i16> %84, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %97 = bitcast <8 x i16> %95 to <4 x i32>
  %98 = bitcast <8 x i16> %96 to <4 x i32>
  %99 = sub <4 x i32> %97, %98
  %100 = sub <4 x i32> zeroinitializer, %99
  %101 = icmp slt <4 x i32> %99, zeroinitializer
  %102 = select <4 x i1> %101, <4 x i32> %100, <4 x i32> %99
  %103 = add nuw <4 x i32> %102, <i32 32, i32 32, i32 32, i32 32>
  %104 = lshr <4 x i32> %103, <i32 6, i32 6, i32 6, i32 6>
  %105 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %94, <4 x i32> %104) #5
  %106 = lshr <8 x i16> %105, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %107 = getelementptr inbounds i16, i16* %10, i64 24
  %108 = bitcast i16* %107 to <8 x i16>*
  %109 = load <8 x i16>, <8 x i16>* %108, align 16
  %110 = getelementptr inbounds i16, i16* %11, i64 24
  %111 = bitcast i16* %110 to <8 x i16>*
  %112 = load <8 x i16>, <8 x i16>* %111, align 16
  %113 = shufflevector <8 x i16> %109, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %114 = zext <4 x i16> %113 to <4 x i32>
  %115 = shufflevector <8 x i16> %112, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %116 = zext <4 x i16> %115 to <4 x i32>
  %117 = sub nsw <4 x i32> %114, %116
  %118 = sub nsw <4 x i32> zeroinitializer, %117
  %119 = icmp slt <4 x i32> %117, zeroinitializer
  %120 = select <4 x i1> %119, <4 x i32> %118, <4 x i32> %117
  %121 = add nuw nsw <4 x i32> %120, <i32 32, i32 32, i32 32, i32 32>
  %122 = lshr <4 x i32> %121, <i32 6, i32 6, i32 6, i32 6>
  %123 = shufflevector <8 x i16> %109, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %124 = shufflevector <8 x i16> %112, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %125 = bitcast <8 x i16> %123 to <4 x i32>
  %126 = bitcast <8 x i16> %124 to <4 x i32>
  %127 = sub <4 x i32> %125, %126
  %128 = sub <4 x i32> zeroinitializer, %127
  %129 = icmp slt <4 x i32> %127, zeroinitializer
  %130 = select <4 x i1> %129, <4 x i32> %128, <4 x i32> %127
  %131 = add nuw <4 x i32> %130, <i32 32, i32 32, i32 32, i32 32>
  %132 = lshr <4 x i32> %131, <i32 6, i32 6, i32 6, i32 6>
  %133 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %122, <4 x i32> %132) #5
  %134 = lshr <8 x i16> %133, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %135 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %106, <8 x i16> %134) #5
  %136 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %135, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %137 = icmp slt <16 x i8> %136, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %138 = select <16 x i1> %137, <16 x i8> %136, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %139 = bitcast <16 x i8> %138 to <2 x i64>
  %140 = extractelement <2 x i64> %139, i32 0
  %141 = bitcast i8* %80 to i64*
  store i64 %140, i64* %141, align 1
  %142 = getelementptr inbounds i8, i8* %80, i64 %3
  %143 = bitcast <16 x i8> %138 to <4 x float>
  %144 = shufflevector <4 x float> %143, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %145 = bitcast i8* %142 to <2 x float>*
  store <2 x float> %144, <2 x float>* %145, align 1
  %146 = getelementptr inbounds i16, i16* %10, i64 32
  %147 = getelementptr inbounds i16, i16* %11, i64 32
  %148 = getelementptr inbounds i8, i8* %80, i64 %7
  %149 = bitcast i16* %146 to <8 x i16>*
  %150 = load <8 x i16>, <8 x i16>* %149, align 16
  %151 = bitcast i16* %147 to <8 x i16>*
  %152 = load <8 x i16>, <8 x i16>* %151, align 16
  %153 = shufflevector <8 x i16> %150, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %154 = zext <4 x i16> %153 to <4 x i32>
  %155 = shufflevector <8 x i16> %152, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %156 = zext <4 x i16> %155 to <4 x i32>
  %157 = sub nsw <4 x i32> %154, %156
  %158 = sub nsw <4 x i32> zeroinitializer, %157
  %159 = icmp slt <4 x i32> %157, zeroinitializer
  %160 = select <4 x i1> %159, <4 x i32> %158, <4 x i32> %157
  %161 = add nuw nsw <4 x i32> %160, <i32 32, i32 32, i32 32, i32 32>
  %162 = lshr <4 x i32> %161, <i32 6, i32 6, i32 6, i32 6>
  %163 = shufflevector <8 x i16> %150, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %164 = shufflevector <8 x i16> %152, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %165 = bitcast <8 x i16> %163 to <4 x i32>
  %166 = bitcast <8 x i16> %164 to <4 x i32>
  %167 = sub <4 x i32> %165, %166
  %168 = sub <4 x i32> zeroinitializer, %167
  %169 = icmp slt <4 x i32> %167, zeroinitializer
  %170 = select <4 x i1> %169, <4 x i32> %168, <4 x i32> %167
  %171 = add nuw <4 x i32> %170, <i32 32, i32 32, i32 32, i32 32>
  %172 = lshr <4 x i32> %171, <i32 6, i32 6, i32 6, i32 6>
  %173 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %162, <4 x i32> %172) #5
  %174 = lshr <8 x i16> %173, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %175 = getelementptr inbounds i16, i16* %10, i64 40
  %176 = bitcast i16* %175 to <8 x i16>*
  %177 = load <8 x i16>, <8 x i16>* %176, align 16
  %178 = getelementptr inbounds i16, i16* %11, i64 40
  %179 = bitcast i16* %178 to <8 x i16>*
  %180 = load <8 x i16>, <8 x i16>* %179, align 16
  %181 = shufflevector <8 x i16> %177, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %182 = zext <4 x i16> %181 to <4 x i32>
  %183 = shufflevector <8 x i16> %180, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %184 = zext <4 x i16> %183 to <4 x i32>
  %185 = sub nsw <4 x i32> %182, %184
  %186 = sub nsw <4 x i32> zeroinitializer, %185
  %187 = icmp slt <4 x i32> %185, zeroinitializer
  %188 = select <4 x i1> %187, <4 x i32> %186, <4 x i32> %185
  %189 = add nuw nsw <4 x i32> %188, <i32 32, i32 32, i32 32, i32 32>
  %190 = lshr <4 x i32> %189, <i32 6, i32 6, i32 6, i32 6>
  %191 = shufflevector <8 x i16> %177, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %192 = shufflevector <8 x i16> %180, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %193 = bitcast <8 x i16> %191 to <4 x i32>
  %194 = bitcast <8 x i16> %192 to <4 x i32>
  %195 = sub <4 x i32> %193, %194
  %196 = sub <4 x i32> zeroinitializer, %195
  %197 = icmp slt <4 x i32> %195, zeroinitializer
  %198 = select <4 x i1> %197, <4 x i32> %196, <4 x i32> %195
  %199 = add nuw <4 x i32> %198, <i32 32, i32 32, i32 32, i32 32>
  %200 = lshr <4 x i32> %199, <i32 6, i32 6, i32 6, i32 6>
  %201 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %190, <4 x i32> %200) #5
  %202 = lshr <8 x i16> %201, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %203 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %174, <8 x i16> %202) #5
  %204 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %203, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %205 = icmp slt <16 x i8> %204, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %206 = select <16 x i1> %205, <16 x i8> %204, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %207 = bitcast <16 x i8> %206 to <2 x i64>
  %208 = extractelement <2 x i64> %207, i32 0
  %209 = bitcast i8* %148 to i64*
  store i64 %208, i64* %209, align 1
  %210 = getelementptr inbounds i8, i8* %148, i64 %3
  %211 = bitcast <16 x i8> %206 to <4 x float>
  %212 = shufflevector <4 x float> %211, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %213 = bitcast i8* %210 to <2 x float>*
  store <2 x float> %212, <2 x float>* %213, align 1
  %214 = getelementptr inbounds i16, i16* %10, i64 48
  %215 = getelementptr inbounds i16, i16* %11, i64 48
  %216 = getelementptr inbounds i8, i8* %148, i64 %7
  %217 = add nsw i32 %12, -1
  %218 = icmp eq i32 %217, 0
  br i1 %218, label %219, label %8

219:                                              ; preds = %8
  %220 = bitcast i16* %214 to <8 x i16>*
  %221 = load <8 x i16>, <8 x i16>* %220, align 16
  %222 = bitcast i16* %215 to <8 x i16>*
  %223 = load <8 x i16>, <8 x i16>* %222, align 16
  %224 = shufflevector <8 x i16> %221, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %225 = zext <4 x i16> %224 to <4 x i32>
  %226 = shufflevector <8 x i16> %223, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %227 = zext <4 x i16> %226 to <4 x i32>
  %228 = sub nsw <4 x i32> %225, %227
  %229 = sub nsw <4 x i32> zeroinitializer, %228
  %230 = icmp slt <4 x i32> %228, zeroinitializer
  %231 = select <4 x i1> %230, <4 x i32> %229, <4 x i32> %228
  %232 = add nuw nsw <4 x i32> %231, <i32 32, i32 32, i32 32, i32 32>
  %233 = lshr <4 x i32> %232, <i32 6, i32 6, i32 6, i32 6>
  %234 = shufflevector <8 x i16> %221, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %235 = shufflevector <8 x i16> %223, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %236 = bitcast <8 x i16> %234 to <4 x i32>
  %237 = bitcast <8 x i16> %235 to <4 x i32>
  %238 = sub <4 x i32> %236, %237
  %239 = sub <4 x i32> zeroinitializer, %238
  %240 = icmp slt <4 x i32> %238, zeroinitializer
  %241 = select <4 x i1> %240, <4 x i32> %239, <4 x i32> %238
  %242 = add nuw <4 x i32> %241, <i32 32, i32 32, i32 32, i32 32>
  %243 = lshr <4 x i32> %242, <i32 6, i32 6, i32 6, i32 6>
  %244 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %233, <4 x i32> %243) #5
  %245 = lshr <8 x i16> %244, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %246 = getelementptr inbounds i16, i16* %10, i64 56
  %247 = bitcast i16* %246 to <8 x i16>*
  %248 = load <8 x i16>, <8 x i16>* %247, align 16
  %249 = getelementptr inbounds i16, i16* %11, i64 56
  %250 = bitcast i16* %249 to <8 x i16>*
  %251 = load <8 x i16>, <8 x i16>* %250, align 16
  %252 = shufflevector <8 x i16> %248, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %253 = zext <4 x i16> %252 to <4 x i32>
  %254 = shufflevector <8 x i16> %251, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %255 = zext <4 x i16> %254 to <4 x i32>
  %256 = sub nsw <4 x i32> %253, %255
  %257 = sub nsw <4 x i32> zeroinitializer, %256
  %258 = icmp slt <4 x i32> %256, zeroinitializer
  %259 = select <4 x i1> %258, <4 x i32> %257, <4 x i32> %256
  %260 = add nuw nsw <4 x i32> %259, <i32 32, i32 32, i32 32, i32 32>
  %261 = lshr <4 x i32> %260, <i32 6, i32 6, i32 6, i32 6>
  %262 = shufflevector <8 x i16> %248, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %263 = shufflevector <8 x i16> %251, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %264 = bitcast <8 x i16> %262 to <4 x i32>
  %265 = bitcast <8 x i16> %263 to <4 x i32>
  %266 = sub <4 x i32> %264, %265
  %267 = sub <4 x i32> zeroinitializer, %266
  %268 = icmp slt <4 x i32> %266, zeroinitializer
  %269 = select <4 x i1> %268, <4 x i32> %267, <4 x i32> %266
  %270 = add nuw <4 x i32> %269, <i32 32, i32 32, i32 32, i32 32>
  %271 = lshr <4 x i32> %270, <i32 6, i32 6, i32 6, i32 6>
  %272 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %261, <4 x i32> %271) #5
  %273 = lshr <8 x i16> %272, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %274 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %245, <8 x i16> %273) #5
  %275 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %274, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %276 = icmp slt <16 x i8> %275, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %277 = select <16 x i1> %276, <16 x i8> %275, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %278 = bitcast <16 x i8> %277 to <2 x i64>
  %279 = extractelement <2 x i64> %278, i32 0
  %280 = bitcast i8* %216 to i64*
  store i64 %279, i64* %280, align 1
  %281 = getelementptr inbounds i8, i8* %216, i64 %3
  %282 = bitcast <16 x i8> %277 to <4 x float>
  %283 = shufflevector <4 x float> %282, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %284 = bitcast i8* %281 to <2 x float>*
  store <2 x float> %283, <2 x float>* %284, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_125WeightMask8x32_10bpp_SSE4ILb1EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  %7 = shl i64 %3, 1
  br label %8

8:                                                ; preds = %8, %4
  %9 = phi i8* [ %2, %4 ], [ %219, %8 ]
  %10 = phi i16* [ %5, %4 ], [ %217, %8 ]
  %11 = phi i16* [ %6, %4 ], [ %218, %8 ]
  %12 = phi i32 [ 5, %4 ], [ %220, %8 ]
  %13 = bitcast i16* %10 to <8 x i16>*
  %14 = load <8 x i16>, <8 x i16>* %13, align 16
  %15 = bitcast i16* %11 to <8 x i16>*
  %16 = load <8 x i16>, <8 x i16>* %15, align 16
  %17 = shufflevector <8 x i16> %14, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %18 = zext <4 x i16> %17 to <4 x i32>
  %19 = shufflevector <8 x i16> %16, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %20 = zext <4 x i16> %19 to <4 x i32>
  %21 = sub nsw <4 x i32> %18, %20
  %22 = sub nsw <4 x i32> zeroinitializer, %21
  %23 = icmp slt <4 x i32> %21, zeroinitializer
  %24 = select <4 x i1> %23, <4 x i32> %22, <4 x i32> %21
  %25 = add nuw nsw <4 x i32> %24, <i32 32, i32 32, i32 32, i32 32>
  %26 = lshr <4 x i32> %25, <i32 6, i32 6, i32 6, i32 6>
  %27 = shufflevector <8 x i16> %14, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %28 = shufflevector <8 x i16> %16, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %29 = bitcast <8 x i16> %27 to <4 x i32>
  %30 = bitcast <8 x i16> %28 to <4 x i32>
  %31 = sub <4 x i32> %29, %30
  %32 = sub <4 x i32> zeroinitializer, %31
  %33 = icmp slt <4 x i32> %31, zeroinitializer
  %34 = select <4 x i1> %33, <4 x i32> %32, <4 x i32> %31
  %35 = add nuw <4 x i32> %34, <i32 32, i32 32, i32 32, i32 32>
  %36 = lshr <4 x i32> %35, <i32 6, i32 6, i32 6, i32 6>
  %37 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %26, <4 x i32> %36) #5
  %38 = lshr <8 x i16> %37, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %39 = getelementptr inbounds i16, i16* %10, i64 8
  %40 = bitcast i16* %39 to <8 x i16>*
  %41 = load <8 x i16>, <8 x i16>* %40, align 16
  %42 = getelementptr inbounds i16, i16* %11, i64 8
  %43 = bitcast i16* %42 to <8 x i16>*
  %44 = load <8 x i16>, <8 x i16>* %43, align 16
  %45 = shufflevector <8 x i16> %41, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %46 = zext <4 x i16> %45 to <4 x i32>
  %47 = shufflevector <8 x i16> %44, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %48 = zext <4 x i16> %47 to <4 x i32>
  %49 = sub nsw <4 x i32> %46, %48
  %50 = sub nsw <4 x i32> zeroinitializer, %49
  %51 = icmp slt <4 x i32> %49, zeroinitializer
  %52 = select <4 x i1> %51, <4 x i32> %50, <4 x i32> %49
  %53 = add nuw nsw <4 x i32> %52, <i32 32, i32 32, i32 32, i32 32>
  %54 = lshr <4 x i32> %53, <i32 6, i32 6, i32 6, i32 6>
  %55 = shufflevector <8 x i16> %41, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %56 = shufflevector <8 x i16> %44, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %57 = bitcast <8 x i16> %55 to <4 x i32>
  %58 = bitcast <8 x i16> %56 to <4 x i32>
  %59 = sub <4 x i32> %57, %58
  %60 = sub <4 x i32> zeroinitializer, %59
  %61 = icmp slt <4 x i32> %59, zeroinitializer
  %62 = select <4 x i1> %61, <4 x i32> %60, <4 x i32> %59
  %63 = add nuw <4 x i32> %62, <i32 32, i32 32, i32 32, i32 32>
  %64 = lshr <4 x i32> %63, <i32 6, i32 6, i32 6, i32 6>
  %65 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %54, <4 x i32> %64) #5
  %66 = lshr <8 x i16> %65, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %67 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %38, <8 x i16> %66) #5
  %68 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %67, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %69 = icmp slt <16 x i8> %68, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %70 = select <16 x i1> %69, <16 x i8> %68, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %71 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %70
  %72 = bitcast <16 x i8> %71 to <2 x i64>
  %73 = extractelement <2 x i64> %72, i32 0
  %74 = bitcast i8* %9 to i64*
  store i64 %73, i64* %74, align 1
  %75 = getelementptr inbounds i8, i8* %9, i64 %3
  %76 = bitcast <16 x i8> %71 to <4 x float>
  %77 = shufflevector <4 x float> %76, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %78 = bitcast i8* %75 to <2 x float>*
  store <2 x float> %77, <2 x float>* %78, align 1
  %79 = getelementptr inbounds i16, i16* %10, i64 16
  %80 = getelementptr inbounds i16, i16* %11, i64 16
  %81 = getelementptr inbounds i8, i8* %9, i64 %7
  %82 = bitcast i16* %79 to <8 x i16>*
  %83 = load <8 x i16>, <8 x i16>* %82, align 16
  %84 = bitcast i16* %80 to <8 x i16>*
  %85 = load <8 x i16>, <8 x i16>* %84, align 16
  %86 = shufflevector <8 x i16> %83, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %87 = zext <4 x i16> %86 to <4 x i32>
  %88 = shufflevector <8 x i16> %85, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %89 = zext <4 x i16> %88 to <4 x i32>
  %90 = sub nsw <4 x i32> %87, %89
  %91 = sub nsw <4 x i32> zeroinitializer, %90
  %92 = icmp slt <4 x i32> %90, zeroinitializer
  %93 = select <4 x i1> %92, <4 x i32> %91, <4 x i32> %90
  %94 = add nuw nsw <4 x i32> %93, <i32 32, i32 32, i32 32, i32 32>
  %95 = lshr <4 x i32> %94, <i32 6, i32 6, i32 6, i32 6>
  %96 = shufflevector <8 x i16> %83, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %97 = shufflevector <8 x i16> %85, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %98 = bitcast <8 x i16> %96 to <4 x i32>
  %99 = bitcast <8 x i16> %97 to <4 x i32>
  %100 = sub <4 x i32> %98, %99
  %101 = sub <4 x i32> zeroinitializer, %100
  %102 = icmp slt <4 x i32> %100, zeroinitializer
  %103 = select <4 x i1> %102, <4 x i32> %101, <4 x i32> %100
  %104 = add nuw <4 x i32> %103, <i32 32, i32 32, i32 32, i32 32>
  %105 = lshr <4 x i32> %104, <i32 6, i32 6, i32 6, i32 6>
  %106 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %95, <4 x i32> %105) #5
  %107 = lshr <8 x i16> %106, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %108 = getelementptr inbounds i16, i16* %10, i64 24
  %109 = bitcast i16* %108 to <8 x i16>*
  %110 = load <8 x i16>, <8 x i16>* %109, align 16
  %111 = getelementptr inbounds i16, i16* %11, i64 24
  %112 = bitcast i16* %111 to <8 x i16>*
  %113 = load <8 x i16>, <8 x i16>* %112, align 16
  %114 = shufflevector <8 x i16> %110, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %115 = zext <4 x i16> %114 to <4 x i32>
  %116 = shufflevector <8 x i16> %113, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %117 = zext <4 x i16> %116 to <4 x i32>
  %118 = sub nsw <4 x i32> %115, %117
  %119 = sub nsw <4 x i32> zeroinitializer, %118
  %120 = icmp slt <4 x i32> %118, zeroinitializer
  %121 = select <4 x i1> %120, <4 x i32> %119, <4 x i32> %118
  %122 = add nuw nsw <4 x i32> %121, <i32 32, i32 32, i32 32, i32 32>
  %123 = lshr <4 x i32> %122, <i32 6, i32 6, i32 6, i32 6>
  %124 = shufflevector <8 x i16> %110, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %125 = shufflevector <8 x i16> %113, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %126 = bitcast <8 x i16> %124 to <4 x i32>
  %127 = bitcast <8 x i16> %125 to <4 x i32>
  %128 = sub <4 x i32> %126, %127
  %129 = sub <4 x i32> zeroinitializer, %128
  %130 = icmp slt <4 x i32> %128, zeroinitializer
  %131 = select <4 x i1> %130, <4 x i32> %129, <4 x i32> %128
  %132 = add nuw <4 x i32> %131, <i32 32, i32 32, i32 32, i32 32>
  %133 = lshr <4 x i32> %132, <i32 6, i32 6, i32 6, i32 6>
  %134 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %123, <4 x i32> %133) #5
  %135 = lshr <8 x i16> %134, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %136 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %107, <8 x i16> %135) #5
  %137 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %136, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %138 = icmp slt <16 x i8> %137, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %139 = select <16 x i1> %138, <16 x i8> %137, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %140 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %139
  %141 = bitcast <16 x i8> %140 to <2 x i64>
  %142 = extractelement <2 x i64> %141, i32 0
  %143 = bitcast i8* %81 to i64*
  store i64 %142, i64* %143, align 1
  %144 = getelementptr inbounds i8, i8* %81, i64 %3
  %145 = bitcast <16 x i8> %140 to <4 x float>
  %146 = shufflevector <4 x float> %145, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %147 = bitcast i8* %144 to <2 x float>*
  store <2 x float> %146, <2 x float>* %147, align 1
  %148 = getelementptr inbounds i16, i16* %10, i64 32
  %149 = getelementptr inbounds i16, i16* %11, i64 32
  %150 = getelementptr inbounds i8, i8* %81, i64 %7
  %151 = bitcast i16* %148 to <8 x i16>*
  %152 = load <8 x i16>, <8 x i16>* %151, align 16
  %153 = bitcast i16* %149 to <8 x i16>*
  %154 = load <8 x i16>, <8 x i16>* %153, align 16
  %155 = shufflevector <8 x i16> %152, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %156 = zext <4 x i16> %155 to <4 x i32>
  %157 = shufflevector <8 x i16> %154, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %158 = zext <4 x i16> %157 to <4 x i32>
  %159 = sub nsw <4 x i32> %156, %158
  %160 = sub nsw <4 x i32> zeroinitializer, %159
  %161 = icmp slt <4 x i32> %159, zeroinitializer
  %162 = select <4 x i1> %161, <4 x i32> %160, <4 x i32> %159
  %163 = add nuw nsw <4 x i32> %162, <i32 32, i32 32, i32 32, i32 32>
  %164 = lshr <4 x i32> %163, <i32 6, i32 6, i32 6, i32 6>
  %165 = shufflevector <8 x i16> %152, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %166 = shufflevector <8 x i16> %154, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %167 = bitcast <8 x i16> %165 to <4 x i32>
  %168 = bitcast <8 x i16> %166 to <4 x i32>
  %169 = sub <4 x i32> %167, %168
  %170 = sub <4 x i32> zeroinitializer, %169
  %171 = icmp slt <4 x i32> %169, zeroinitializer
  %172 = select <4 x i1> %171, <4 x i32> %170, <4 x i32> %169
  %173 = add nuw <4 x i32> %172, <i32 32, i32 32, i32 32, i32 32>
  %174 = lshr <4 x i32> %173, <i32 6, i32 6, i32 6, i32 6>
  %175 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %164, <4 x i32> %174) #5
  %176 = lshr <8 x i16> %175, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %177 = getelementptr inbounds i16, i16* %10, i64 40
  %178 = bitcast i16* %177 to <8 x i16>*
  %179 = load <8 x i16>, <8 x i16>* %178, align 16
  %180 = getelementptr inbounds i16, i16* %11, i64 40
  %181 = bitcast i16* %180 to <8 x i16>*
  %182 = load <8 x i16>, <8 x i16>* %181, align 16
  %183 = shufflevector <8 x i16> %179, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %184 = zext <4 x i16> %183 to <4 x i32>
  %185 = shufflevector <8 x i16> %182, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %186 = zext <4 x i16> %185 to <4 x i32>
  %187 = sub nsw <4 x i32> %184, %186
  %188 = sub nsw <4 x i32> zeroinitializer, %187
  %189 = icmp slt <4 x i32> %187, zeroinitializer
  %190 = select <4 x i1> %189, <4 x i32> %188, <4 x i32> %187
  %191 = add nuw nsw <4 x i32> %190, <i32 32, i32 32, i32 32, i32 32>
  %192 = lshr <4 x i32> %191, <i32 6, i32 6, i32 6, i32 6>
  %193 = shufflevector <8 x i16> %179, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %194 = shufflevector <8 x i16> %182, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %195 = bitcast <8 x i16> %193 to <4 x i32>
  %196 = bitcast <8 x i16> %194 to <4 x i32>
  %197 = sub <4 x i32> %195, %196
  %198 = sub <4 x i32> zeroinitializer, %197
  %199 = icmp slt <4 x i32> %197, zeroinitializer
  %200 = select <4 x i1> %199, <4 x i32> %198, <4 x i32> %197
  %201 = add nuw <4 x i32> %200, <i32 32, i32 32, i32 32, i32 32>
  %202 = lshr <4 x i32> %201, <i32 6, i32 6, i32 6, i32 6>
  %203 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %192, <4 x i32> %202) #5
  %204 = lshr <8 x i16> %203, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %205 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %176, <8 x i16> %204) #5
  %206 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %205, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %207 = icmp slt <16 x i8> %206, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %208 = select <16 x i1> %207, <16 x i8> %206, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %209 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %208
  %210 = bitcast <16 x i8> %209 to <2 x i64>
  %211 = extractelement <2 x i64> %210, i32 0
  %212 = bitcast i8* %150 to i64*
  store i64 %211, i64* %212, align 1
  %213 = getelementptr inbounds i8, i8* %150, i64 %3
  %214 = bitcast <16 x i8> %209 to <4 x float>
  %215 = shufflevector <4 x float> %214, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %216 = bitcast i8* %213 to <2 x float>*
  store <2 x float> %215, <2 x float>* %216, align 1
  %217 = getelementptr inbounds i16, i16* %10, i64 48
  %218 = getelementptr inbounds i16, i16* %11, i64 48
  %219 = getelementptr inbounds i8, i8* %150, i64 %7
  %220 = add nsw i32 %12, -1
  %221 = icmp eq i32 %220, 0
  br i1 %221, label %222, label %8

222:                                              ; preds = %8
  %223 = bitcast i16* %217 to <8 x i16>*
  %224 = load <8 x i16>, <8 x i16>* %223, align 16
  %225 = bitcast i16* %218 to <8 x i16>*
  %226 = load <8 x i16>, <8 x i16>* %225, align 16
  %227 = shufflevector <8 x i16> %224, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %228 = zext <4 x i16> %227 to <4 x i32>
  %229 = shufflevector <8 x i16> %226, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %230 = zext <4 x i16> %229 to <4 x i32>
  %231 = sub nsw <4 x i32> %228, %230
  %232 = sub nsw <4 x i32> zeroinitializer, %231
  %233 = icmp slt <4 x i32> %231, zeroinitializer
  %234 = select <4 x i1> %233, <4 x i32> %232, <4 x i32> %231
  %235 = add nuw nsw <4 x i32> %234, <i32 32, i32 32, i32 32, i32 32>
  %236 = lshr <4 x i32> %235, <i32 6, i32 6, i32 6, i32 6>
  %237 = shufflevector <8 x i16> %224, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %238 = shufflevector <8 x i16> %226, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %239 = bitcast <8 x i16> %237 to <4 x i32>
  %240 = bitcast <8 x i16> %238 to <4 x i32>
  %241 = sub <4 x i32> %239, %240
  %242 = sub <4 x i32> zeroinitializer, %241
  %243 = icmp slt <4 x i32> %241, zeroinitializer
  %244 = select <4 x i1> %243, <4 x i32> %242, <4 x i32> %241
  %245 = add nuw <4 x i32> %244, <i32 32, i32 32, i32 32, i32 32>
  %246 = lshr <4 x i32> %245, <i32 6, i32 6, i32 6, i32 6>
  %247 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %236, <4 x i32> %246) #5
  %248 = lshr <8 x i16> %247, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %249 = getelementptr inbounds i16, i16* %10, i64 56
  %250 = bitcast i16* %249 to <8 x i16>*
  %251 = load <8 x i16>, <8 x i16>* %250, align 16
  %252 = getelementptr inbounds i16, i16* %11, i64 56
  %253 = bitcast i16* %252 to <8 x i16>*
  %254 = load <8 x i16>, <8 x i16>* %253, align 16
  %255 = shufflevector <8 x i16> %251, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %256 = zext <4 x i16> %255 to <4 x i32>
  %257 = shufflevector <8 x i16> %254, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %258 = zext <4 x i16> %257 to <4 x i32>
  %259 = sub nsw <4 x i32> %256, %258
  %260 = sub nsw <4 x i32> zeroinitializer, %259
  %261 = icmp slt <4 x i32> %259, zeroinitializer
  %262 = select <4 x i1> %261, <4 x i32> %260, <4 x i32> %259
  %263 = add nuw nsw <4 x i32> %262, <i32 32, i32 32, i32 32, i32 32>
  %264 = lshr <4 x i32> %263, <i32 6, i32 6, i32 6, i32 6>
  %265 = shufflevector <8 x i16> %251, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %266 = shufflevector <8 x i16> %254, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %267 = bitcast <8 x i16> %265 to <4 x i32>
  %268 = bitcast <8 x i16> %266 to <4 x i32>
  %269 = sub <4 x i32> %267, %268
  %270 = sub <4 x i32> zeroinitializer, %269
  %271 = icmp slt <4 x i32> %269, zeroinitializer
  %272 = select <4 x i1> %271, <4 x i32> %270, <4 x i32> %269
  %273 = add nuw <4 x i32> %272, <i32 32, i32 32, i32 32, i32 32>
  %274 = lshr <4 x i32> %273, <i32 6, i32 6, i32 6, i32 6>
  %275 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %264, <4 x i32> %274) #5
  %276 = lshr <8 x i16> %275, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %277 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %248, <8 x i16> %276) #5
  %278 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %277, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %279 = icmp slt <16 x i8> %278, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %280 = select <16 x i1> %279, <16 x i8> %278, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %281 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %280
  %282 = bitcast <16 x i8> %281 to <2 x i64>
  %283 = extractelement <2 x i64> %282, i32 0
  %284 = bitcast i8* %219 to i64*
  store i64 %283, i64* %284, align 1
  %285 = getelementptr inbounds i8, i8* %219, i64 %3
  %286 = bitcast <16 x i8> %281 to <4 x float>
  %287 = shufflevector <4 x float> %286, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %288 = bitcast i8* %285 to <2 x float>*
  store <2 x float> %287, <2 x float>* %288, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_125WeightMask16x8_10bpp_SSE4ILb0EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %73, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %71, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %72, %7 ]
  %11 = phi i32 [ 7, %4 ], [ %74, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = shufflevector <8 x i16> %13, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %17 = zext <4 x i16> %16 to <4 x i32>
  %18 = shufflevector <8 x i16> %15, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %19 = zext <4 x i16> %18 to <4 x i32>
  %20 = sub nsw <4 x i32> %17, %19
  %21 = sub nsw <4 x i32> zeroinitializer, %20
  %22 = icmp slt <4 x i32> %20, zeroinitializer
  %23 = select <4 x i1> %22, <4 x i32> %21, <4 x i32> %20
  %24 = add nuw nsw <4 x i32> %23, <i32 32, i32 32, i32 32, i32 32>
  %25 = lshr <4 x i32> %24, <i32 6, i32 6, i32 6, i32 6>
  %26 = shufflevector <8 x i16> %13, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %27 = shufflevector <8 x i16> %15, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %28 = bitcast <8 x i16> %26 to <4 x i32>
  %29 = bitcast <8 x i16> %27 to <4 x i32>
  %30 = sub <4 x i32> %28, %29
  %31 = sub <4 x i32> zeroinitializer, %30
  %32 = icmp slt <4 x i32> %30, zeroinitializer
  %33 = select <4 x i1> %32, <4 x i32> %31, <4 x i32> %30
  %34 = add nuw <4 x i32> %33, <i32 32, i32 32, i32 32, i32 32>
  %35 = lshr <4 x i32> %34, <i32 6, i32 6, i32 6, i32 6>
  %36 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %25, <4 x i32> %35) #5
  %37 = lshr <8 x i16> %36, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %38 = getelementptr inbounds i16, i16* %9, i64 8
  %39 = bitcast i16* %38 to <8 x i16>*
  %40 = load <8 x i16>, <8 x i16>* %39, align 16
  %41 = getelementptr inbounds i16, i16* %10, i64 8
  %42 = bitcast i16* %41 to <8 x i16>*
  %43 = load <8 x i16>, <8 x i16>* %42, align 16
  %44 = shufflevector <8 x i16> %40, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %45 = zext <4 x i16> %44 to <4 x i32>
  %46 = shufflevector <8 x i16> %43, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %47 = zext <4 x i16> %46 to <4 x i32>
  %48 = sub nsw <4 x i32> %45, %47
  %49 = sub nsw <4 x i32> zeroinitializer, %48
  %50 = icmp slt <4 x i32> %48, zeroinitializer
  %51 = select <4 x i1> %50, <4 x i32> %49, <4 x i32> %48
  %52 = add nuw nsw <4 x i32> %51, <i32 32, i32 32, i32 32, i32 32>
  %53 = lshr <4 x i32> %52, <i32 6, i32 6, i32 6, i32 6>
  %54 = shufflevector <8 x i16> %40, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %55 = shufflevector <8 x i16> %43, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %56 = bitcast <8 x i16> %54 to <4 x i32>
  %57 = bitcast <8 x i16> %55 to <4 x i32>
  %58 = sub <4 x i32> %56, %57
  %59 = sub <4 x i32> zeroinitializer, %58
  %60 = icmp slt <4 x i32> %58, zeroinitializer
  %61 = select <4 x i1> %60, <4 x i32> %59, <4 x i32> %58
  %62 = add nuw <4 x i32> %61, <i32 32, i32 32, i32 32, i32 32>
  %63 = lshr <4 x i32> %62, <i32 6, i32 6, i32 6, i32 6>
  %64 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %53, <4 x i32> %63) #5
  %65 = lshr <8 x i16> %64, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %66 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %37, <8 x i16> %65) #5
  %67 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %66, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %68 = icmp slt <16 x i8> %67, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %69 = select <16 x i1> %68, <16 x i8> %67, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %70 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %69, <16 x i8>* %70, align 16
  %71 = getelementptr inbounds i16, i16* %9, i64 16
  %72 = getelementptr inbounds i16, i16* %10, i64 16
  %73 = getelementptr inbounds i8, i8* %8, i64 %3
  %74 = add nsw i32 %11, -1
  %75 = icmp eq i32 %74, 0
  br i1 %75, label %76, label %7

76:                                               ; preds = %7
  %77 = bitcast i16* %71 to <8 x i16>*
  %78 = load <8 x i16>, <8 x i16>* %77, align 16
  %79 = bitcast i16* %72 to <8 x i16>*
  %80 = load <8 x i16>, <8 x i16>* %79, align 16
  %81 = shufflevector <8 x i16> %78, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %82 = zext <4 x i16> %81 to <4 x i32>
  %83 = shufflevector <8 x i16> %80, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %84 = zext <4 x i16> %83 to <4 x i32>
  %85 = sub nsw <4 x i32> %82, %84
  %86 = sub nsw <4 x i32> zeroinitializer, %85
  %87 = icmp slt <4 x i32> %85, zeroinitializer
  %88 = select <4 x i1> %87, <4 x i32> %86, <4 x i32> %85
  %89 = add nuw nsw <4 x i32> %88, <i32 32, i32 32, i32 32, i32 32>
  %90 = lshr <4 x i32> %89, <i32 6, i32 6, i32 6, i32 6>
  %91 = shufflevector <8 x i16> %78, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %92 = shufflevector <8 x i16> %80, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %93 = bitcast <8 x i16> %91 to <4 x i32>
  %94 = bitcast <8 x i16> %92 to <4 x i32>
  %95 = sub <4 x i32> %93, %94
  %96 = sub <4 x i32> zeroinitializer, %95
  %97 = icmp slt <4 x i32> %95, zeroinitializer
  %98 = select <4 x i1> %97, <4 x i32> %96, <4 x i32> %95
  %99 = add nuw <4 x i32> %98, <i32 32, i32 32, i32 32, i32 32>
  %100 = lshr <4 x i32> %99, <i32 6, i32 6, i32 6, i32 6>
  %101 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %90, <4 x i32> %100) #5
  %102 = lshr <8 x i16> %101, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %103 = getelementptr inbounds i16, i16* %9, i64 24
  %104 = bitcast i16* %103 to <8 x i16>*
  %105 = load <8 x i16>, <8 x i16>* %104, align 16
  %106 = getelementptr inbounds i16, i16* %10, i64 24
  %107 = bitcast i16* %106 to <8 x i16>*
  %108 = load <8 x i16>, <8 x i16>* %107, align 16
  %109 = shufflevector <8 x i16> %105, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %110 = zext <4 x i16> %109 to <4 x i32>
  %111 = shufflevector <8 x i16> %108, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %112 = zext <4 x i16> %111 to <4 x i32>
  %113 = sub nsw <4 x i32> %110, %112
  %114 = sub nsw <4 x i32> zeroinitializer, %113
  %115 = icmp slt <4 x i32> %113, zeroinitializer
  %116 = select <4 x i1> %115, <4 x i32> %114, <4 x i32> %113
  %117 = add nuw nsw <4 x i32> %116, <i32 32, i32 32, i32 32, i32 32>
  %118 = lshr <4 x i32> %117, <i32 6, i32 6, i32 6, i32 6>
  %119 = shufflevector <8 x i16> %105, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %120 = shufflevector <8 x i16> %108, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %121 = bitcast <8 x i16> %119 to <4 x i32>
  %122 = bitcast <8 x i16> %120 to <4 x i32>
  %123 = sub <4 x i32> %121, %122
  %124 = sub <4 x i32> zeroinitializer, %123
  %125 = icmp slt <4 x i32> %123, zeroinitializer
  %126 = select <4 x i1> %125, <4 x i32> %124, <4 x i32> %123
  %127 = add nuw <4 x i32> %126, <i32 32, i32 32, i32 32, i32 32>
  %128 = lshr <4 x i32> %127, <i32 6, i32 6, i32 6, i32 6>
  %129 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %118, <4 x i32> %128) #5
  %130 = lshr <8 x i16> %129, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %131 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %102, <8 x i16> %130) #5
  %132 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %131, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %133 = icmp slt <16 x i8> %132, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %134 = select <16 x i1> %133, <16 x i8> %132, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %135 = bitcast i8* %73 to <16 x i8>*
  store <16 x i8> %134, <16 x i8>* %135, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_125WeightMask16x8_10bpp_SSE4ILb1EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %74, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %72, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %73, %7 ]
  %11 = phi i32 [ 7, %4 ], [ %75, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = shufflevector <8 x i16> %13, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %17 = zext <4 x i16> %16 to <4 x i32>
  %18 = shufflevector <8 x i16> %15, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %19 = zext <4 x i16> %18 to <4 x i32>
  %20 = sub nsw <4 x i32> %17, %19
  %21 = sub nsw <4 x i32> zeroinitializer, %20
  %22 = icmp slt <4 x i32> %20, zeroinitializer
  %23 = select <4 x i1> %22, <4 x i32> %21, <4 x i32> %20
  %24 = add nuw nsw <4 x i32> %23, <i32 32, i32 32, i32 32, i32 32>
  %25 = lshr <4 x i32> %24, <i32 6, i32 6, i32 6, i32 6>
  %26 = shufflevector <8 x i16> %13, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %27 = shufflevector <8 x i16> %15, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %28 = bitcast <8 x i16> %26 to <4 x i32>
  %29 = bitcast <8 x i16> %27 to <4 x i32>
  %30 = sub <4 x i32> %28, %29
  %31 = sub <4 x i32> zeroinitializer, %30
  %32 = icmp slt <4 x i32> %30, zeroinitializer
  %33 = select <4 x i1> %32, <4 x i32> %31, <4 x i32> %30
  %34 = add nuw <4 x i32> %33, <i32 32, i32 32, i32 32, i32 32>
  %35 = lshr <4 x i32> %34, <i32 6, i32 6, i32 6, i32 6>
  %36 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %25, <4 x i32> %35) #5
  %37 = lshr <8 x i16> %36, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %38 = getelementptr inbounds i16, i16* %9, i64 8
  %39 = bitcast i16* %38 to <8 x i16>*
  %40 = load <8 x i16>, <8 x i16>* %39, align 16
  %41 = getelementptr inbounds i16, i16* %10, i64 8
  %42 = bitcast i16* %41 to <8 x i16>*
  %43 = load <8 x i16>, <8 x i16>* %42, align 16
  %44 = shufflevector <8 x i16> %40, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %45 = zext <4 x i16> %44 to <4 x i32>
  %46 = shufflevector <8 x i16> %43, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %47 = zext <4 x i16> %46 to <4 x i32>
  %48 = sub nsw <4 x i32> %45, %47
  %49 = sub nsw <4 x i32> zeroinitializer, %48
  %50 = icmp slt <4 x i32> %48, zeroinitializer
  %51 = select <4 x i1> %50, <4 x i32> %49, <4 x i32> %48
  %52 = add nuw nsw <4 x i32> %51, <i32 32, i32 32, i32 32, i32 32>
  %53 = lshr <4 x i32> %52, <i32 6, i32 6, i32 6, i32 6>
  %54 = shufflevector <8 x i16> %40, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %55 = shufflevector <8 x i16> %43, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %56 = bitcast <8 x i16> %54 to <4 x i32>
  %57 = bitcast <8 x i16> %55 to <4 x i32>
  %58 = sub <4 x i32> %56, %57
  %59 = sub <4 x i32> zeroinitializer, %58
  %60 = icmp slt <4 x i32> %58, zeroinitializer
  %61 = select <4 x i1> %60, <4 x i32> %59, <4 x i32> %58
  %62 = add nuw <4 x i32> %61, <i32 32, i32 32, i32 32, i32 32>
  %63 = lshr <4 x i32> %62, <i32 6, i32 6, i32 6, i32 6>
  %64 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %53, <4 x i32> %63) #5
  %65 = lshr <8 x i16> %64, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %66 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %37, <8 x i16> %65) #5
  %67 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %66, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %68 = icmp slt <16 x i8> %67, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %69 = select <16 x i1> %68, <16 x i8> %67, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %70 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %69
  %71 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %70, <16 x i8>* %71, align 16
  %72 = getelementptr inbounds i16, i16* %9, i64 16
  %73 = getelementptr inbounds i16, i16* %10, i64 16
  %74 = getelementptr inbounds i8, i8* %8, i64 %3
  %75 = add nsw i32 %11, -1
  %76 = icmp eq i32 %75, 0
  br i1 %76, label %77, label %7

77:                                               ; preds = %7
  %78 = bitcast i16* %72 to <8 x i16>*
  %79 = load <8 x i16>, <8 x i16>* %78, align 16
  %80 = bitcast i16* %73 to <8 x i16>*
  %81 = load <8 x i16>, <8 x i16>* %80, align 16
  %82 = shufflevector <8 x i16> %79, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %83 = zext <4 x i16> %82 to <4 x i32>
  %84 = shufflevector <8 x i16> %81, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %85 = zext <4 x i16> %84 to <4 x i32>
  %86 = sub nsw <4 x i32> %83, %85
  %87 = sub nsw <4 x i32> zeroinitializer, %86
  %88 = icmp slt <4 x i32> %86, zeroinitializer
  %89 = select <4 x i1> %88, <4 x i32> %87, <4 x i32> %86
  %90 = add nuw nsw <4 x i32> %89, <i32 32, i32 32, i32 32, i32 32>
  %91 = lshr <4 x i32> %90, <i32 6, i32 6, i32 6, i32 6>
  %92 = shufflevector <8 x i16> %79, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %93 = shufflevector <8 x i16> %81, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %94 = bitcast <8 x i16> %92 to <4 x i32>
  %95 = bitcast <8 x i16> %93 to <4 x i32>
  %96 = sub <4 x i32> %94, %95
  %97 = sub <4 x i32> zeroinitializer, %96
  %98 = icmp slt <4 x i32> %96, zeroinitializer
  %99 = select <4 x i1> %98, <4 x i32> %97, <4 x i32> %96
  %100 = add nuw <4 x i32> %99, <i32 32, i32 32, i32 32, i32 32>
  %101 = lshr <4 x i32> %100, <i32 6, i32 6, i32 6, i32 6>
  %102 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %91, <4 x i32> %101) #5
  %103 = lshr <8 x i16> %102, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %104 = getelementptr inbounds i16, i16* %9, i64 24
  %105 = bitcast i16* %104 to <8 x i16>*
  %106 = load <8 x i16>, <8 x i16>* %105, align 16
  %107 = getelementptr inbounds i16, i16* %10, i64 24
  %108 = bitcast i16* %107 to <8 x i16>*
  %109 = load <8 x i16>, <8 x i16>* %108, align 16
  %110 = shufflevector <8 x i16> %106, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %111 = zext <4 x i16> %110 to <4 x i32>
  %112 = shufflevector <8 x i16> %109, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %113 = zext <4 x i16> %112 to <4 x i32>
  %114 = sub nsw <4 x i32> %111, %113
  %115 = sub nsw <4 x i32> zeroinitializer, %114
  %116 = icmp slt <4 x i32> %114, zeroinitializer
  %117 = select <4 x i1> %116, <4 x i32> %115, <4 x i32> %114
  %118 = add nuw nsw <4 x i32> %117, <i32 32, i32 32, i32 32, i32 32>
  %119 = lshr <4 x i32> %118, <i32 6, i32 6, i32 6, i32 6>
  %120 = shufflevector <8 x i16> %106, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %121 = shufflevector <8 x i16> %109, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %122 = bitcast <8 x i16> %120 to <4 x i32>
  %123 = bitcast <8 x i16> %121 to <4 x i32>
  %124 = sub <4 x i32> %122, %123
  %125 = sub <4 x i32> zeroinitializer, %124
  %126 = icmp slt <4 x i32> %124, zeroinitializer
  %127 = select <4 x i1> %126, <4 x i32> %125, <4 x i32> %124
  %128 = add nuw <4 x i32> %127, <i32 32, i32 32, i32 32, i32 32>
  %129 = lshr <4 x i32> %128, <i32 6, i32 6, i32 6, i32 6>
  %130 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %119, <4 x i32> %129) #5
  %131 = lshr <8 x i16> %130, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %132 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %103, <8 x i16> %131) #5
  %133 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %132, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %134 = icmp slt <16 x i8> %133, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %135 = select <16 x i1> %134, <16 x i8> %133, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %136 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %135
  %137 = bitcast i8* %74 to <16 x i8>*
  store <16 x i8> %136, <16 x i8>* %137, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask16x16_10bpp_SSE4ILb0EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %197, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %195, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %196, %7 ]
  %11 = phi i32 [ 5, %4 ], [ %198, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = shufflevector <8 x i16> %13, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %17 = zext <4 x i16> %16 to <4 x i32>
  %18 = shufflevector <8 x i16> %15, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %19 = zext <4 x i16> %18 to <4 x i32>
  %20 = sub nsw <4 x i32> %17, %19
  %21 = sub nsw <4 x i32> zeroinitializer, %20
  %22 = icmp slt <4 x i32> %20, zeroinitializer
  %23 = select <4 x i1> %22, <4 x i32> %21, <4 x i32> %20
  %24 = add nuw nsw <4 x i32> %23, <i32 32, i32 32, i32 32, i32 32>
  %25 = lshr <4 x i32> %24, <i32 6, i32 6, i32 6, i32 6>
  %26 = shufflevector <8 x i16> %13, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %27 = shufflevector <8 x i16> %15, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %28 = bitcast <8 x i16> %26 to <4 x i32>
  %29 = bitcast <8 x i16> %27 to <4 x i32>
  %30 = sub <4 x i32> %28, %29
  %31 = sub <4 x i32> zeroinitializer, %30
  %32 = icmp slt <4 x i32> %30, zeroinitializer
  %33 = select <4 x i1> %32, <4 x i32> %31, <4 x i32> %30
  %34 = add nuw <4 x i32> %33, <i32 32, i32 32, i32 32, i32 32>
  %35 = lshr <4 x i32> %34, <i32 6, i32 6, i32 6, i32 6>
  %36 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %25, <4 x i32> %35) #5
  %37 = lshr <8 x i16> %36, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %38 = getelementptr inbounds i16, i16* %9, i64 8
  %39 = bitcast i16* %38 to <8 x i16>*
  %40 = load <8 x i16>, <8 x i16>* %39, align 16
  %41 = getelementptr inbounds i16, i16* %10, i64 8
  %42 = bitcast i16* %41 to <8 x i16>*
  %43 = load <8 x i16>, <8 x i16>* %42, align 16
  %44 = shufflevector <8 x i16> %40, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %45 = zext <4 x i16> %44 to <4 x i32>
  %46 = shufflevector <8 x i16> %43, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %47 = zext <4 x i16> %46 to <4 x i32>
  %48 = sub nsw <4 x i32> %45, %47
  %49 = sub nsw <4 x i32> zeroinitializer, %48
  %50 = icmp slt <4 x i32> %48, zeroinitializer
  %51 = select <4 x i1> %50, <4 x i32> %49, <4 x i32> %48
  %52 = add nuw nsw <4 x i32> %51, <i32 32, i32 32, i32 32, i32 32>
  %53 = lshr <4 x i32> %52, <i32 6, i32 6, i32 6, i32 6>
  %54 = shufflevector <8 x i16> %40, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %55 = shufflevector <8 x i16> %43, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %56 = bitcast <8 x i16> %54 to <4 x i32>
  %57 = bitcast <8 x i16> %55 to <4 x i32>
  %58 = sub <4 x i32> %56, %57
  %59 = sub <4 x i32> zeroinitializer, %58
  %60 = icmp slt <4 x i32> %58, zeroinitializer
  %61 = select <4 x i1> %60, <4 x i32> %59, <4 x i32> %58
  %62 = add nuw <4 x i32> %61, <i32 32, i32 32, i32 32, i32 32>
  %63 = lshr <4 x i32> %62, <i32 6, i32 6, i32 6, i32 6>
  %64 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %53, <4 x i32> %63) #5
  %65 = lshr <8 x i16> %64, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %66 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %37, <8 x i16> %65) #5
  %67 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %66, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %68 = icmp slt <16 x i8> %67, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %69 = select <16 x i1> %68, <16 x i8> %67, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %70 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %69, <16 x i8>* %70, align 16
  %71 = getelementptr inbounds i16, i16* %9, i64 16
  %72 = getelementptr inbounds i16, i16* %10, i64 16
  %73 = getelementptr inbounds i8, i8* %8, i64 %3
  %74 = bitcast i16* %71 to <8 x i16>*
  %75 = load <8 x i16>, <8 x i16>* %74, align 16
  %76 = bitcast i16* %72 to <8 x i16>*
  %77 = load <8 x i16>, <8 x i16>* %76, align 16
  %78 = shufflevector <8 x i16> %75, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %79 = zext <4 x i16> %78 to <4 x i32>
  %80 = shufflevector <8 x i16> %77, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %81 = zext <4 x i16> %80 to <4 x i32>
  %82 = sub nsw <4 x i32> %79, %81
  %83 = sub nsw <4 x i32> zeroinitializer, %82
  %84 = icmp slt <4 x i32> %82, zeroinitializer
  %85 = select <4 x i1> %84, <4 x i32> %83, <4 x i32> %82
  %86 = add nuw nsw <4 x i32> %85, <i32 32, i32 32, i32 32, i32 32>
  %87 = lshr <4 x i32> %86, <i32 6, i32 6, i32 6, i32 6>
  %88 = shufflevector <8 x i16> %75, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %89 = shufflevector <8 x i16> %77, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %90 = bitcast <8 x i16> %88 to <4 x i32>
  %91 = bitcast <8 x i16> %89 to <4 x i32>
  %92 = sub <4 x i32> %90, %91
  %93 = sub <4 x i32> zeroinitializer, %92
  %94 = icmp slt <4 x i32> %92, zeroinitializer
  %95 = select <4 x i1> %94, <4 x i32> %93, <4 x i32> %92
  %96 = add nuw <4 x i32> %95, <i32 32, i32 32, i32 32, i32 32>
  %97 = lshr <4 x i32> %96, <i32 6, i32 6, i32 6, i32 6>
  %98 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %87, <4 x i32> %97) #5
  %99 = lshr <8 x i16> %98, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %100 = getelementptr inbounds i16, i16* %9, i64 24
  %101 = bitcast i16* %100 to <8 x i16>*
  %102 = load <8 x i16>, <8 x i16>* %101, align 16
  %103 = getelementptr inbounds i16, i16* %10, i64 24
  %104 = bitcast i16* %103 to <8 x i16>*
  %105 = load <8 x i16>, <8 x i16>* %104, align 16
  %106 = shufflevector <8 x i16> %102, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %107 = zext <4 x i16> %106 to <4 x i32>
  %108 = shufflevector <8 x i16> %105, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %109 = zext <4 x i16> %108 to <4 x i32>
  %110 = sub nsw <4 x i32> %107, %109
  %111 = sub nsw <4 x i32> zeroinitializer, %110
  %112 = icmp slt <4 x i32> %110, zeroinitializer
  %113 = select <4 x i1> %112, <4 x i32> %111, <4 x i32> %110
  %114 = add nuw nsw <4 x i32> %113, <i32 32, i32 32, i32 32, i32 32>
  %115 = lshr <4 x i32> %114, <i32 6, i32 6, i32 6, i32 6>
  %116 = shufflevector <8 x i16> %102, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %117 = shufflevector <8 x i16> %105, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %118 = bitcast <8 x i16> %116 to <4 x i32>
  %119 = bitcast <8 x i16> %117 to <4 x i32>
  %120 = sub <4 x i32> %118, %119
  %121 = sub <4 x i32> zeroinitializer, %120
  %122 = icmp slt <4 x i32> %120, zeroinitializer
  %123 = select <4 x i1> %122, <4 x i32> %121, <4 x i32> %120
  %124 = add nuw <4 x i32> %123, <i32 32, i32 32, i32 32, i32 32>
  %125 = lshr <4 x i32> %124, <i32 6, i32 6, i32 6, i32 6>
  %126 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %115, <4 x i32> %125) #5
  %127 = lshr <8 x i16> %126, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %128 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %99, <8 x i16> %127) #5
  %129 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %128, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %130 = icmp slt <16 x i8> %129, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %131 = select <16 x i1> %130, <16 x i8> %129, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %132 = bitcast i8* %73 to <16 x i8>*
  store <16 x i8> %131, <16 x i8>* %132, align 16
  %133 = getelementptr inbounds i16, i16* %9, i64 32
  %134 = getelementptr inbounds i16, i16* %10, i64 32
  %135 = getelementptr inbounds i8, i8* %73, i64 %3
  %136 = bitcast i16* %133 to <8 x i16>*
  %137 = load <8 x i16>, <8 x i16>* %136, align 16
  %138 = bitcast i16* %134 to <8 x i16>*
  %139 = load <8 x i16>, <8 x i16>* %138, align 16
  %140 = shufflevector <8 x i16> %137, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %141 = zext <4 x i16> %140 to <4 x i32>
  %142 = shufflevector <8 x i16> %139, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %143 = zext <4 x i16> %142 to <4 x i32>
  %144 = sub nsw <4 x i32> %141, %143
  %145 = sub nsw <4 x i32> zeroinitializer, %144
  %146 = icmp slt <4 x i32> %144, zeroinitializer
  %147 = select <4 x i1> %146, <4 x i32> %145, <4 x i32> %144
  %148 = add nuw nsw <4 x i32> %147, <i32 32, i32 32, i32 32, i32 32>
  %149 = lshr <4 x i32> %148, <i32 6, i32 6, i32 6, i32 6>
  %150 = shufflevector <8 x i16> %137, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %151 = shufflevector <8 x i16> %139, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %152 = bitcast <8 x i16> %150 to <4 x i32>
  %153 = bitcast <8 x i16> %151 to <4 x i32>
  %154 = sub <4 x i32> %152, %153
  %155 = sub <4 x i32> zeroinitializer, %154
  %156 = icmp slt <4 x i32> %154, zeroinitializer
  %157 = select <4 x i1> %156, <4 x i32> %155, <4 x i32> %154
  %158 = add nuw <4 x i32> %157, <i32 32, i32 32, i32 32, i32 32>
  %159 = lshr <4 x i32> %158, <i32 6, i32 6, i32 6, i32 6>
  %160 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %149, <4 x i32> %159) #5
  %161 = lshr <8 x i16> %160, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %162 = getelementptr inbounds i16, i16* %9, i64 40
  %163 = bitcast i16* %162 to <8 x i16>*
  %164 = load <8 x i16>, <8 x i16>* %163, align 16
  %165 = getelementptr inbounds i16, i16* %10, i64 40
  %166 = bitcast i16* %165 to <8 x i16>*
  %167 = load <8 x i16>, <8 x i16>* %166, align 16
  %168 = shufflevector <8 x i16> %164, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %169 = zext <4 x i16> %168 to <4 x i32>
  %170 = shufflevector <8 x i16> %167, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %171 = zext <4 x i16> %170 to <4 x i32>
  %172 = sub nsw <4 x i32> %169, %171
  %173 = sub nsw <4 x i32> zeroinitializer, %172
  %174 = icmp slt <4 x i32> %172, zeroinitializer
  %175 = select <4 x i1> %174, <4 x i32> %173, <4 x i32> %172
  %176 = add nuw nsw <4 x i32> %175, <i32 32, i32 32, i32 32, i32 32>
  %177 = lshr <4 x i32> %176, <i32 6, i32 6, i32 6, i32 6>
  %178 = shufflevector <8 x i16> %164, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %179 = shufflevector <8 x i16> %167, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %180 = bitcast <8 x i16> %178 to <4 x i32>
  %181 = bitcast <8 x i16> %179 to <4 x i32>
  %182 = sub <4 x i32> %180, %181
  %183 = sub <4 x i32> zeroinitializer, %182
  %184 = icmp slt <4 x i32> %182, zeroinitializer
  %185 = select <4 x i1> %184, <4 x i32> %183, <4 x i32> %182
  %186 = add nuw <4 x i32> %185, <i32 32, i32 32, i32 32, i32 32>
  %187 = lshr <4 x i32> %186, <i32 6, i32 6, i32 6, i32 6>
  %188 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %177, <4 x i32> %187) #5
  %189 = lshr <8 x i16> %188, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %190 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %161, <8 x i16> %189) #5
  %191 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %190, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %192 = icmp slt <16 x i8> %191, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %193 = select <16 x i1> %192, <16 x i8> %191, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %194 = bitcast i8* %135 to <16 x i8>*
  store <16 x i8> %193, <16 x i8>* %194, align 16
  %195 = getelementptr inbounds i16, i16* %9, i64 48
  %196 = getelementptr inbounds i16, i16* %10, i64 48
  %197 = getelementptr inbounds i8, i8* %135, i64 %3
  %198 = add nsw i32 %11, -1
  %199 = icmp eq i32 %198, 0
  br i1 %199, label %200, label %7

200:                                              ; preds = %7
  %201 = bitcast i16* %195 to <8 x i16>*
  %202 = load <8 x i16>, <8 x i16>* %201, align 16
  %203 = bitcast i16* %196 to <8 x i16>*
  %204 = load <8 x i16>, <8 x i16>* %203, align 16
  %205 = shufflevector <8 x i16> %202, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %206 = zext <4 x i16> %205 to <4 x i32>
  %207 = shufflevector <8 x i16> %204, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %208 = zext <4 x i16> %207 to <4 x i32>
  %209 = sub nsw <4 x i32> %206, %208
  %210 = sub nsw <4 x i32> zeroinitializer, %209
  %211 = icmp slt <4 x i32> %209, zeroinitializer
  %212 = select <4 x i1> %211, <4 x i32> %210, <4 x i32> %209
  %213 = add nuw nsw <4 x i32> %212, <i32 32, i32 32, i32 32, i32 32>
  %214 = lshr <4 x i32> %213, <i32 6, i32 6, i32 6, i32 6>
  %215 = shufflevector <8 x i16> %202, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %216 = shufflevector <8 x i16> %204, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %217 = bitcast <8 x i16> %215 to <4 x i32>
  %218 = bitcast <8 x i16> %216 to <4 x i32>
  %219 = sub <4 x i32> %217, %218
  %220 = sub <4 x i32> zeroinitializer, %219
  %221 = icmp slt <4 x i32> %219, zeroinitializer
  %222 = select <4 x i1> %221, <4 x i32> %220, <4 x i32> %219
  %223 = add nuw <4 x i32> %222, <i32 32, i32 32, i32 32, i32 32>
  %224 = lshr <4 x i32> %223, <i32 6, i32 6, i32 6, i32 6>
  %225 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %214, <4 x i32> %224) #5
  %226 = lshr <8 x i16> %225, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %227 = getelementptr inbounds i16, i16* %9, i64 56
  %228 = bitcast i16* %227 to <8 x i16>*
  %229 = load <8 x i16>, <8 x i16>* %228, align 16
  %230 = getelementptr inbounds i16, i16* %10, i64 56
  %231 = bitcast i16* %230 to <8 x i16>*
  %232 = load <8 x i16>, <8 x i16>* %231, align 16
  %233 = shufflevector <8 x i16> %229, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %234 = zext <4 x i16> %233 to <4 x i32>
  %235 = shufflevector <8 x i16> %232, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %236 = zext <4 x i16> %235 to <4 x i32>
  %237 = sub nsw <4 x i32> %234, %236
  %238 = sub nsw <4 x i32> zeroinitializer, %237
  %239 = icmp slt <4 x i32> %237, zeroinitializer
  %240 = select <4 x i1> %239, <4 x i32> %238, <4 x i32> %237
  %241 = add nuw nsw <4 x i32> %240, <i32 32, i32 32, i32 32, i32 32>
  %242 = lshr <4 x i32> %241, <i32 6, i32 6, i32 6, i32 6>
  %243 = shufflevector <8 x i16> %229, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %244 = shufflevector <8 x i16> %232, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %245 = bitcast <8 x i16> %243 to <4 x i32>
  %246 = bitcast <8 x i16> %244 to <4 x i32>
  %247 = sub <4 x i32> %245, %246
  %248 = sub <4 x i32> zeroinitializer, %247
  %249 = icmp slt <4 x i32> %247, zeroinitializer
  %250 = select <4 x i1> %249, <4 x i32> %248, <4 x i32> %247
  %251 = add nuw <4 x i32> %250, <i32 32, i32 32, i32 32, i32 32>
  %252 = lshr <4 x i32> %251, <i32 6, i32 6, i32 6, i32 6>
  %253 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %242, <4 x i32> %252) #5
  %254 = lshr <8 x i16> %253, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %255 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %226, <8 x i16> %254) #5
  %256 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %255, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %257 = icmp slt <16 x i8> %256, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %258 = select <16 x i1> %257, <16 x i8> %256, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %259 = bitcast i8* %197 to <16 x i8>*
  store <16 x i8> %258, <16 x i8>* %259, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask16x16_10bpp_SSE4ILb1EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %200, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %198, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %199, %7 ]
  %11 = phi i32 [ 5, %4 ], [ %201, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = shufflevector <8 x i16> %13, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %17 = zext <4 x i16> %16 to <4 x i32>
  %18 = shufflevector <8 x i16> %15, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %19 = zext <4 x i16> %18 to <4 x i32>
  %20 = sub nsw <4 x i32> %17, %19
  %21 = sub nsw <4 x i32> zeroinitializer, %20
  %22 = icmp slt <4 x i32> %20, zeroinitializer
  %23 = select <4 x i1> %22, <4 x i32> %21, <4 x i32> %20
  %24 = add nuw nsw <4 x i32> %23, <i32 32, i32 32, i32 32, i32 32>
  %25 = lshr <4 x i32> %24, <i32 6, i32 6, i32 6, i32 6>
  %26 = shufflevector <8 x i16> %13, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %27 = shufflevector <8 x i16> %15, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %28 = bitcast <8 x i16> %26 to <4 x i32>
  %29 = bitcast <8 x i16> %27 to <4 x i32>
  %30 = sub <4 x i32> %28, %29
  %31 = sub <4 x i32> zeroinitializer, %30
  %32 = icmp slt <4 x i32> %30, zeroinitializer
  %33 = select <4 x i1> %32, <4 x i32> %31, <4 x i32> %30
  %34 = add nuw <4 x i32> %33, <i32 32, i32 32, i32 32, i32 32>
  %35 = lshr <4 x i32> %34, <i32 6, i32 6, i32 6, i32 6>
  %36 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %25, <4 x i32> %35) #5
  %37 = lshr <8 x i16> %36, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %38 = getelementptr inbounds i16, i16* %9, i64 8
  %39 = bitcast i16* %38 to <8 x i16>*
  %40 = load <8 x i16>, <8 x i16>* %39, align 16
  %41 = getelementptr inbounds i16, i16* %10, i64 8
  %42 = bitcast i16* %41 to <8 x i16>*
  %43 = load <8 x i16>, <8 x i16>* %42, align 16
  %44 = shufflevector <8 x i16> %40, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %45 = zext <4 x i16> %44 to <4 x i32>
  %46 = shufflevector <8 x i16> %43, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %47 = zext <4 x i16> %46 to <4 x i32>
  %48 = sub nsw <4 x i32> %45, %47
  %49 = sub nsw <4 x i32> zeroinitializer, %48
  %50 = icmp slt <4 x i32> %48, zeroinitializer
  %51 = select <4 x i1> %50, <4 x i32> %49, <4 x i32> %48
  %52 = add nuw nsw <4 x i32> %51, <i32 32, i32 32, i32 32, i32 32>
  %53 = lshr <4 x i32> %52, <i32 6, i32 6, i32 6, i32 6>
  %54 = shufflevector <8 x i16> %40, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %55 = shufflevector <8 x i16> %43, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %56 = bitcast <8 x i16> %54 to <4 x i32>
  %57 = bitcast <8 x i16> %55 to <4 x i32>
  %58 = sub <4 x i32> %56, %57
  %59 = sub <4 x i32> zeroinitializer, %58
  %60 = icmp slt <4 x i32> %58, zeroinitializer
  %61 = select <4 x i1> %60, <4 x i32> %59, <4 x i32> %58
  %62 = add nuw <4 x i32> %61, <i32 32, i32 32, i32 32, i32 32>
  %63 = lshr <4 x i32> %62, <i32 6, i32 6, i32 6, i32 6>
  %64 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %53, <4 x i32> %63) #5
  %65 = lshr <8 x i16> %64, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %66 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %37, <8 x i16> %65) #5
  %67 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %66, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %68 = icmp slt <16 x i8> %67, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %69 = select <16 x i1> %68, <16 x i8> %67, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %70 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %69
  %71 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %70, <16 x i8>* %71, align 16
  %72 = getelementptr inbounds i16, i16* %9, i64 16
  %73 = getelementptr inbounds i16, i16* %10, i64 16
  %74 = getelementptr inbounds i8, i8* %8, i64 %3
  %75 = bitcast i16* %72 to <8 x i16>*
  %76 = load <8 x i16>, <8 x i16>* %75, align 16
  %77 = bitcast i16* %73 to <8 x i16>*
  %78 = load <8 x i16>, <8 x i16>* %77, align 16
  %79 = shufflevector <8 x i16> %76, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %80 = zext <4 x i16> %79 to <4 x i32>
  %81 = shufflevector <8 x i16> %78, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %82 = zext <4 x i16> %81 to <4 x i32>
  %83 = sub nsw <4 x i32> %80, %82
  %84 = sub nsw <4 x i32> zeroinitializer, %83
  %85 = icmp slt <4 x i32> %83, zeroinitializer
  %86 = select <4 x i1> %85, <4 x i32> %84, <4 x i32> %83
  %87 = add nuw nsw <4 x i32> %86, <i32 32, i32 32, i32 32, i32 32>
  %88 = lshr <4 x i32> %87, <i32 6, i32 6, i32 6, i32 6>
  %89 = shufflevector <8 x i16> %76, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %90 = shufflevector <8 x i16> %78, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %91 = bitcast <8 x i16> %89 to <4 x i32>
  %92 = bitcast <8 x i16> %90 to <4 x i32>
  %93 = sub <4 x i32> %91, %92
  %94 = sub <4 x i32> zeroinitializer, %93
  %95 = icmp slt <4 x i32> %93, zeroinitializer
  %96 = select <4 x i1> %95, <4 x i32> %94, <4 x i32> %93
  %97 = add nuw <4 x i32> %96, <i32 32, i32 32, i32 32, i32 32>
  %98 = lshr <4 x i32> %97, <i32 6, i32 6, i32 6, i32 6>
  %99 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %88, <4 x i32> %98) #5
  %100 = lshr <8 x i16> %99, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %101 = getelementptr inbounds i16, i16* %9, i64 24
  %102 = bitcast i16* %101 to <8 x i16>*
  %103 = load <8 x i16>, <8 x i16>* %102, align 16
  %104 = getelementptr inbounds i16, i16* %10, i64 24
  %105 = bitcast i16* %104 to <8 x i16>*
  %106 = load <8 x i16>, <8 x i16>* %105, align 16
  %107 = shufflevector <8 x i16> %103, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %108 = zext <4 x i16> %107 to <4 x i32>
  %109 = shufflevector <8 x i16> %106, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %110 = zext <4 x i16> %109 to <4 x i32>
  %111 = sub nsw <4 x i32> %108, %110
  %112 = sub nsw <4 x i32> zeroinitializer, %111
  %113 = icmp slt <4 x i32> %111, zeroinitializer
  %114 = select <4 x i1> %113, <4 x i32> %112, <4 x i32> %111
  %115 = add nuw nsw <4 x i32> %114, <i32 32, i32 32, i32 32, i32 32>
  %116 = lshr <4 x i32> %115, <i32 6, i32 6, i32 6, i32 6>
  %117 = shufflevector <8 x i16> %103, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %118 = shufflevector <8 x i16> %106, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %119 = bitcast <8 x i16> %117 to <4 x i32>
  %120 = bitcast <8 x i16> %118 to <4 x i32>
  %121 = sub <4 x i32> %119, %120
  %122 = sub <4 x i32> zeroinitializer, %121
  %123 = icmp slt <4 x i32> %121, zeroinitializer
  %124 = select <4 x i1> %123, <4 x i32> %122, <4 x i32> %121
  %125 = add nuw <4 x i32> %124, <i32 32, i32 32, i32 32, i32 32>
  %126 = lshr <4 x i32> %125, <i32 6, i32 6, i32 6, i32 6>
  %127 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %116, <4 x i32> %126) #5
  %128 = lshr <8 x i16> %127, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %129 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %100, <8 x i16> %128) #5
  %130 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %129, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %131 = icmp slt <16 x i8> %130, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %132 = select <16 x i1> %131, <16 x i8> %130, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %133 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %132
  %134 = bitcast i8* %74 to <16 x i8>*
  store <16 x i8> %133, <16 x i8>* %134, align 16
  %135 = getelementptr inbounds i16, i16* %9, i64 32
  %136 = getelementptr inbounds i16, i16* %10, i64 32
  %137 = getelementptr inbounds i8, i8* %74, i64 %3
  %138 = bitcast i16* %135 to <8 x i16>*
  %139 = load <8 x i16>, <8 x i16>* %138, align 16
  %140 = bitcast i16* %136 to <8 x i16>*
  %141 = load <8 x i16>, <8 x i16>* %140, align 16
  %142 = shufflevector <8 x i16> %139, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %143 = zext <4 x i16> %142 to <4 x i32>
  %144 = shufflevector <8 x i16> %141, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %145 = zext <4 x i16> %144 to <4 x i32>
  %146 = sub nsw <4 x i32> %143, %145
  %147 = sub nsw <4 x i32> zeroinitializer, %146
  %148 = icmp slt <4 x i32> %146, zeroinitializer
  %149 = select <4 x i1> %148, <4 x i32> %147, <4 x i32> %146
  %150 = add nuw nsw <4 x i32> %149, <i32 32, i32 32, i32 32, i32 32>
  %151 = lshr <4 x i32> %150, <i32 6, i32 6, i32 6, i32 6>
  %152 = shufflevector <8 x i16> %139, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %153 = shufflevector <8 x i16> %141, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %154 = bitcast <8 x i16> %152 to <4 x i32>
  %155 = bitcast <8 x i16> %153 to <4 x i32>
  %156 = sub <4 x i32> %154, %155
  %157 = sub <4 x i32> zeroinitializer, %156
  %158 = icmp slt <4 x i32> %156, zeroinitializer
  %159 = select <4 x i1> %158, <4 x i32> %157, <4 x i32> %156
  %160 = add nuw <4 x i32> %159, <i32 32, i32 32, i32 32, i32 32>
  %161 = lshr <4 x i32> %160, <i32 6, i32 6, i32 6, i32 6>
  %162 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %151, <4 x i32> %161) #5
  %163 = lshr <8 x i16> %162, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %164 = getelementptr inbounds i16, i16* %9, i64 40
  %165 = bitcast i16* %164 to <8 x i16>*
  %166 = load <8 x i16>, <8 x i16>* %165, align 16
  %167 = getelementptr inbounds i16, i16* %10, i64 40
  %168 = bitcast i16* %167 to <8 x i16>*
  %169 = load <8 x i16>, <8 x i16>* %168, align 16
  %170 = shufflevector <8 x i16> %166, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %171 = zext <4 x i16> %170 to <4 x i32>
  %172 = shufflevector <8 x i16> %169, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %173 = zext <4 x i16> %172 to <4 x i32>
  %174 = sub nsw <4 x i32> %171, %173
  %175 = sub nsw <4 x i32> zeroinitializer, %174
  %176 = icmp slt <4 x i32> %174, zeroinitializer
  %177 = select <4 x i1> %176, <4 x i32> %175, <4 x i32> %174
  %178 = add nuw nsw <4 x i32> %177, <i32 32, i32 32, i32 32, i32 32>
  %179 = lshr <4 x i32> %178, <i32 6, i32 6, i32 6, i32 6>
  %180 = shufflevector <8 x i16> %166, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %181 = shufflevector <8 x i16> %169, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %182 = bitcast <8 x i16> %180 to <4 x i32>
  %183 = bitcast <8 x i16> %181 to <4 x i32>
  %184 = sub <4 x i32> %182, %183
  %185 = sub <4 x i32> zeroinitializer, %184
  %186 = icmp slt <4 x i32> %184, zeroinitializer
  %187 = select <4 x i1> %186, <4 x i32> %185, <4 x i32> %184
  %188 = add nuw <4 x i32> %187, <i32 32, i32 32, i32 32, i32 32>
  %189 = lshr <4 x i32> %188, <i32 6, i32 6, i32 6, i32 6>
  %190 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %179, <4 x i32> %189) #5
  %191 = lshr <8 x i16> %190, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %192 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %163, <8 x i16> %191) #5
  %193 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %192, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %194 = icmp slt <16 x i8> %193, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %195 = select <16 x i1> %194, <16 x i8> %193, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %196 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %195
  %197 = bitcast i8* %137 to <16 x i8>*
  store <16 x i8> %196, <16 x i8>* %197, align 16
  %198 = getelementptr inbounds i16, i16* %9, i64 48
  %199 = getelementptr inbounds i16, i16* %10, i64 48
  %200 = getelementptr inbounds i8, i8* %137, i64 %3
  %201 = add nsw i32 %11, -1
  %202 = icmp eq i32 %201, 0
  br i1 %202, label %203, label %7

203:                                              ; preds = %7
  %204 = bitcast i16* %198 to <8 x i16>*
  %205 = load <8 x i16>, <8 x i16>* %204, align 16
  %206 = bitcast i16* %199 to <8 x i16>*
  %207 = load <8 x i16>, <8 x i16>* %206, align 16
  %208 = shufflevector <8 x i16> %205, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %209 = zext <4 x i16> %208 to <4 x i32>
  %210 = shufflevector <8 x i16> %207, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %211 = zext <4 x i16> %210 to <4 x i32>
  %212 = sub nsw <4 x i32> %209, %211
  %213 = sub nsw <4 x i32> zeroinitializer, %212
  %214 = icmp slt <4 x i32> %212, zeroinitializer
  %215 = select <4 x i1> %214, <4 x i32> %213, <4 x i32> %212
  %216 = add nuw nsw <4 x i32> %215, <i32 32, i32 32, i32 32, i32 32>
  %217 = lshr <4 x i32> %216, <i32 6, i32 6, i32 6, i32 6>
  %218 = shufflevector <8 x i16> %205, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %219 = shufflevector <8 x i16> %207, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %220 = bitcast <8 x i16> %218 to <4 x i32>
  %221 = bitcast <8 x i16> %219 to <4 x i32>
  %222 = sub <4 x i32> %220, %221
  %223 = sub <4 x i32> zeroinitializer, %222
  %224 = icmp slt <4 x i32> %222, zeroinitializer
  %225 = select <4 x i1> %224, <4 x i32> %223, <4 x i32> %222
  %226 = add nuw <4 x i32> %225, <i32 32, i32 32, i32 32, i32 32>
  %227 = lshr <4 x i32> %226, <i32 6, i32 6, i32 6, i32 6>
  %228 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %217, <4 x i32> %227) #5
  %229 = lshr <8 x i16> %228, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %230 = getelementptr inbounds i16, i16* %9, i64 56
  %231 = bitcast i16* %230 to <8 x i16>*
  %232 = load <8 x i16>, <8 x i16>* %231, align 16
  %233 = getelementptr inbounds i16, i16* %10, i64 56
  %234 = bitcast i16* %233 to <8 x i16>*
  %235 = load <8 x i16>, <8 x i16>* %234, align 16
  %236 = shufflevector <8 x i16> %232, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %237 = zext <4 x i16> %236 to <4 x i32>
  %238 = shufflevector <8 x i16> %235, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %239 = zext <4 x i16> %238 to <4 x i32>
  %240 = sub nsw <4 x i32> %237, %239
  %241 = sub nsw <4 x i32> zeroinitializer, %240
  %242 = icmp slt <4 x i32> %240, zeroinitializer
  %243 = select <4 x i1> %242, <4 x i32> %241, <4 x i32> %240
  %244 = add nuw nsw <4 x i32> %243, <i32 32, i32 32, i32 32, i32 32>
  %245 = lshr <4 x i32> %244, <i32 6, i32 6, i32 6, i32 6>
  %246 = shufflevector <8 x i16> %232, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %247 = shufflevector <8 x i16> %235, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %248 = bitcast <8 x i16> %246 to <4 x i32>
  %249 = bitcast <8 x i16> %247 to <4 x i32>
  %250 = sub <4 x i32> %248, %249
  %251 = sub <4 x i32> zeroinitializer, %250
  %252 = icmp slt <4 x i32> %250, zeroinitializer
  %253 = select <4 x i1> %252, <4 x i32> %251, <4 x i32> %250
  %254 = add nuw <4 x i32> %253, <i32 32, i32 32, i32 32, i32 32>
  %255 = lshr <4 x i32> %254, <i32 6, i32 6, i32 6, i32 6>
  %256 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %245, <4 x i32> %255) #5
  %257 = lshr <8 x i16> %256, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %258 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %229, <8 x i16> %257) #5
  %259 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %258, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %260 = icmp slt <16 x i8> %259, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %261 = select <16 x i1> %260, <16 x i8> %259, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %262 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %261
  %263 = bitcast i8* %200 to <16 x i8>*
  store <16 x i8> %262, <16 x i8>* %263, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask16x32_10bpp_SSE4ILb0EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %321, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %319, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %320, %7 ]
  %11 = phi i32 [ 6, %4 ], [ %322, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = shufflevector <8 x i16> %13, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %17 = zext <4 x i16> %16 to <4 x i32>
  %18 = shufflevector <8 x i16> %15, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %19 = zext <4 x i16> %18 to <4 x i32>
  %20 = sub nsw <4 x i32> %17, %19
  %21 = sub nsw <4 x i32> zeroinitializer, %20
  %22 = icmp slt <4 x i32> %20, zeroinitializer
  %23 = select <4 x i1> %22, <4 x i32> %21, <4 x i32> %20
  %24 = add nuw nsw <4 x i32> %23, <i32 32, i32 32, i32 32, i32 32>
  %25 = lshr <4 x i32> %24, <i32 6, i32 6, i32 6, i32 6>
  %26 = shufflevector <8 x i16> %13, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %27 = shufflevector <8 x i16> %15, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %28 = bitcast <8 x i16> %26 to <4 x i32>
  %29 = bitcast <8 x i16> %27 to <4 x i32>
  %30 = sub <4 x i32> %28, %29
  %31 = sub <4 x i32> zeroinitializer, %30
  %32 = icmp slt <4 x i32> %30, zeroinitializer
  %33 = select <4 x i1> %32, <4 x i32> %31, <4 x i32> %30
  %34 = add nuw <4 x i32> %33, <i32 32, i32 32, i32 32, i32 32>
  %35 = lshr <4 x i32> %34, <i32 6, i32 6, i32 6, i32 6>
  %36 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %25, <4 x i32> %35) #5
  %37 = lshr <8 x i16> %36, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %38 = getelementptr inbounds i16, i16* %9, i64 8
  %39 = bitcast i16* %38 to <8 x i16>*
  %40 = load <8 x i16>, <8 x i16>* %39, align 16
  %41 = getelementptr inbounds i16, i16* %10, i64 8
  %42 = bitcast i16* %41 to <8 x i16>*
  %43 = load <8 x i16>, <8 x i16>* %42, align 16
  %44 = shufflevector <8 x i16> %40, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %45 = zext <4 x i16> %44 to <4 x i32>
  %46 = shufflevector <8 x i16> %43, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %47 = zext <4 x i16> %46 to <4 x i32>
  %48 = sub nsw <4 x i32> %45, %47
  %49 = sub nsw <4 x i32> zeroinitializer, %48
  %50 = icmp slt <4 x i32> %48, zeroinitializer
  %51 = select <4 x i1> %50, <4 x i32> %49, <4 x i32> %48
  %52 = add nuw nsw <4 x i32> %51, <i32 32, i32 32, i32 32, i32 32>
  %53 = lshr <4 x i32> %52, <i32 6, i32 6, i32 6, i32 6>
  %54 = shufflevector <8 x i16> %40, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %55 = shufflevector <8 x i16> %43, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %56 = bitcast <8 x i16> %54 to <4 x i32>
  %57 = bitcast <8 x i16> %55 to <4 x i32>
  %58 = sub <4 x i32> %56, %57
  %59 = sub <4 x i32> zeroinitializer, %58
  %60 = icmp slt <4 x i32> %58, zeroinitializer
  %61 = select <4 x i1> %60, <4 x i32> %59, <4 x i32> %58
  %62 = add nuw <4 x i32> %61, <i32 32, i32 32, i32 32, i32 32>
  %63 = lshr <4 x i32> %62, <i32 6, i32 6, i32 6, i32 6>
  %64 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %53, <4 x i32> %63) #5
  %65 = lshr <8 x i16> %64, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %66 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %37, <8 x i16> %65) #5
  %67 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %66, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %68 = icmp slt <16 x i8> %67, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %69 = select <16 x i1> %68, <16 x i8> %67, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %70 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %69, <16 x i8>* %70, align 16
  %71 = getelementptr inbounds i16, i16* %9, i64 16
  %72 = getelementptr inbounds i16, i16* %10, i64 16
  %73 = getelementptr inbounds i8, i8* %8, i64 %3
  %74 = bitcast i16* %71 to <8 x i16>*
  %75 = load <8 x i16>, <8 x i16>* %74, align 16
  %76 = bitcast i16* %72 to <8 x i16>*
  %77 = load <8 x i16>, <8 x i16>* %76, align 16
  %78 = shufflevector <8 x i16> %75, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %79 = zext <4 x i16> %78 to <4 x i32>
  %80 = shufflevector <8 x i16> %77, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %81 = zext <4 x i16> %80 to <4 x i32>
  %82 = sub nsw <4 x i32> %79, %81
  %83 = sub nsw <4 x i32> zeroinitializer, %82
  %84 = icmp slt <4 x i32> %82, zeroinitializer
  %85 = select <4 x i1> %84, <4 x i32> %83, <4 x i32> %82
  %86 = add nuw nsw <4 x i32> %85, <i32 32, i32 32, i32 32, i32 32>
  %87 = lshr <4 x i32> %86, <i32 6, i32 6, i32 6, i32 6>
  %88 = shufflevector <8 x i16> %75, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %89 = shufflevector <8 x i16> %77, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %90 = bitcast <8 x i16> %88 to <4 x i32>
  %91 = bitcast <8 x i16> %89 to <4 x i32>
  %92 = sub <4 x i32> %90, %91
  %93 = sub <4 x i32> zeroinitializer, %92
  %94 = icmp slt <4 x i32> %92, zeroinitializer
  %95 = select <4 x i1> %94, <4 x i32> %93, <4 x i32> %92
  %96 = add nuw <4 x i32> %95, <i32 32, i32 32, i32 32, i32 32>
  %97 = lshr <4 x i32> %96, <i32 6, i32 6, i32 6, i32 6>
  %98 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %87, <4 x i32> %97) #5
  %99 = lshr <8 x i16> %98, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %100 = getelementptr inbounds i16, i16* %9, i64 24
  %101 = bitcast i16* %100 to <8 x i16>*
  %102 = load <8 x i16>, <8 x i16>* %101, align 16
  %103 = getelementptr inbounds i16, i16* %10, i64 24
  %104 = bitcast i16* %103 to <8 x i16>*
  %105 = load <8 x i16>, <8 x i16>* %104, align 16
  %106 = shufflevector <8 x i16> %102, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %107 = zext <4 x i16> %106 to <4 x i32>
  %108 = shufflevector <8 x i16> %105, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %109 = zext <4 x i16> %108 to <4 x i32>
  %110 = sub nsw <4 x i32> %107, %109
  %111 = sub nsw <4 x i32> zeroinitializer, %110
  %112 = icmp slt <4 x i32> %110, zeroinitializer
  %113 = select <4 x i1> %112, <4 x i32> %111, <4 x i32> %110
  %114 = add nuw nsw <4 x i32> %113, <i32 32, i32 32, i32 32, i32 32>
  %115 = lshr <4 x i32> %114, <i32 6, i32 6, i32 6, i32 6>
  %116 = shufflevector <8 x i16> %102, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %117 = shufflevector <8 x i16> %105, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %118 = bitcast <8 x i16> %116 to <4 x i32>
  %119 = bitcast <8 x i16> %117 to <4 x i32>
  %120 = sub <4 x i32> %118, %119
  %121 = sub <4 x i32> zeroinitializer, %120
  %122 = icmp slt <4 x i32> %120, zeroinitializer
  %123 = select <4 x i1> %122, <4 x i32> %121, <4 x i32> %120
  %124 = add nuw <4 x i32> %123, <i32 32, i32 32, i32 32, i32 32>
  %125 = lshr <4 x i32> %124, <i32 6, i32 6, i32 6, i32 6>
  %126 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %115, <4 x i32> %125) #5
  %127 = lshr <8 x i16> %126, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %128 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %99, <8 x i16> %127) #5
  %129 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %128, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %130 = icmp slt <16 x i8> %129, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %131 = select <16 x i1> %130, <16 x i8> %129, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %132 = bitcast i8* %73 to <16 x i8>*
  store <16 x i8> %131, <16 x i8>* %132, align 16
  %133 = getelementptr inbounds i16, i16* %9, i64 32
  %134 = getelementptr inbounds i16, i16* %10, i64 32
  %135 = getelementptr inbounds i8, i8* %73, i64 %3
  %136 = bitcast i16* %133 to <8 x i16>*
  %137 = load <8 x i16>, <8 x i16>* %136, align 16
  %138 = bitcast i16* %134 to <8 x i16>*
  %139 = load <8 x i16>, <8 x i16>* %138, align 16
  %140 = shufflevector <8 x i16> %137, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %141 = zext <4 x i16> %140 to <4 x i32>
  %142 = shufflevector <8 x i16> %139, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %143 = zext <4 x i16> %142 to <4 x i32>
  %144 = sub nsw <4 x i32> %141, %143
  %145 = sub nsw <4 x i32> zeroinitializer, %144
  %146 = icmp slt <4 x i32> %144, zeroinitializer
  %147 = select <4 x i1> %146, <4 x i32> %145, <4 x i32> %144
  %148 = add nuw nsw <4 x i32> %147, <i32 32, i32 32, i32 32, i32 32>
  %149 = lshr <4 x i32> %148, <i32 6, i32 6, i32 6, i32 6>
  %150 = shufflevector <8 x i16> %137, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %151 = shufflevector <8 x i16> %139, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %152 = bitcast <8 x i16> %150 to <4 x i32>
  %153 = bitcast <8 x i16> %151 to <4 x i32>
  %154 = sub <4 x i32> %152, %153
  %155 = sub <4 x i32> zeroinitializer, %154
  %156 = icmp slt <4 x i32> %154, zeroinitializer
  %157 = select <4 x i1> %156, <4 x i32> %155, <4 x i32> %154
  %158 = add nuw <4 x i32> %157, <i32 32, i32 32, i32 32, i32 32>
  %159 = lshr <4 x i32> %158, <i32 6, i32 6, i32 6, i32 6>
  %160 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %149, <4 x i32> %159) #5
  %161 = lshr <8 x i16> %160, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %162 = getelementptr inbounds i16, i16* %9, i64 40
  %163 = bitcast i16* %162 to <8 x i16>*
  %164 = load <8 x i16>, <8 x i16>* %163, align 16
  %165 = getelementptr inbounds i16, i16* %10, i64 40
  %166 = bitcast i16* %165 to <8 x i16>*
  %167 = load <8 x i16>, <8 x i16>* %166, align 16
  %168 = shufflevector <8 x i16> %164, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %169 = zext <4 x i16> %168 to <4 x i32>
  %170 = shufflevector <8 x i16> %167, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %171 = zext <4 x i16> %170 to <4 x i32>
  %172 = sub nsw <4 x i32> %169, %171
  %173 = sub nsw <4 x i32> zeroinitializer, %172
  %174 = icmp slt <4 x i32> %172, zeroinitializer
  %175 = select <4 x i1> %174, <4 x i32> %173, <4 x i32> %172
  %176 = add nuw nsw <4 x i32> %175, <i32 32, i32 32, i32 32, i32 32>
  %177 = lshr <4 x i32> %176, <i32 6, i32 6, i32 6, i32 6>
  %178 = shufflevector <8 x i16> %164, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %179 = shufflevector <8 x i16> %167, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %180 = bitcast <8 x i16> %178 to <4 x i32>
  %181 = bitcast <8 x i16> %179 to <4 x i32>
  %182 = sub <4 x i32> %180, %181
  %183 = sub <4 x i32> zeroinitializer, %182
  %184 = icmp slt <4 x i32> %182, zeroinitializer
  %185 = select <4 x i1> %184, <4 x i32> %183, <4 x i32> %182
  %186 = add nuw <4 x i32> %185, <i32 32, i32 32, i32 32, i32 32>
  %187 = lshr <4 x i32> %186, <i32 6, i32 6, i32 6, i32 6>
  %188 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %177, <4 x i32> %187) #5
  %189 = lshr <8 x i16> %188, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %190 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %161, <8 x i16> %189) #5
  %191 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %190, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %192 = icmp slt <16 x i8> %191, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %193 = select <16 x i1> %192, <16 x i8> %191, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %194 = bitcast i8* %135 to <16 x i8>*
  store <16 x i8> %193, <16 x i8>* %194, align 16
  %195 = getelementptr inbounds i16, i16* %9, i64 48
  %196 = getelementptr inbounds i16, i16* %10, i64 48
  %197 = getelementptr inbounds i8, i8* %135, i64 %3
  %198 = bitcast i16* %195 to <8 x i16>*
  %199 = load <8 x i16>, <8 x i16>* %198, align 16
  %200 = bitcast i16* %196 to <8 x i16>*
  %201 = load <8 x i16>, <8 x i16>* %200, align 16
  %202 = shufflevector <8 x i16> %199, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %203 = zext <4 x i16> %202 to <4 x i32>
  %204 = shufflevector <8 x i16> %201, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %205 = zext <4 x i16> %204 to <4 x i32>
  %206 = sub nsw <4 x i32> %203, %205
  %207 = sub nsw <4 x i32> zeroinitializer, %206
  %208 = icmp slt <4 x i32> %206, zeroinitializer
  %209 = select <4 x i1> %208, <4 x i32> %207, <4 x i32> %206
  %210 = add nuw nsw <4 x i32> %209, <i32 32, i32 32, i32 32, i32 32>
  %211 = lshr <4 x i32> %210, <i32 6, i32 6, i32 6, i32 6>
  %212 = shufflevector <8 x i16> %199, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %213 = shufflevector <8 x i16> %201, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %214 = bitcast <8 x i16> %212 to <4 x i32>
  %215 = bitcast <8 x i16> %213 to <4 x i32>
  %216 = sub <4 x i32> %214, %215
  %217 = sub <4 x i32> zeroinitializer, %216
  %218 = icmp slt <4 x i32> %216, zeroinitializer
  %219 = select <4 x i1> %218, <4 x i32> %217, <4 x i32> %216
  %220 = add nuw <4 x i32> %219, <i32 32, i32 32, i32 32, i32 32>
  %221 = lshr <4 x i32> %220, <i32 6, i32 6, i32 6, i32 6>
  %222 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %211, <4 x i32> %221) #5
  %223 = lshr <8 x i16> %222, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %224 = getelementptr inbounds i16, i16* %9, i64 56
  %225 = bitcast i16* %224 to <8 x i16>*
  %226 = load <8 x i16>, <8 x i16>* %225, align 16
  %227 = getelementptr inbounds i16, i16* %10, i64 56
  %228 = bitcast i16* %227 to <8 x i16>*
  %229 = load <8 x i16>, <8 x i16>* %228, align 16
  %230 = shufflevector <8 x i16> %226, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %231 = zext <4 x i16> %230 to <4 x i32>
  %232 = shufflevector <8 x i16> %229, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %233 = zext <4 x i16> %232 to <4 x i32>
  %234 = sub nsw <4 x i32> %231, %233
  %235 = sub nsw <4 x i32> zeroinitializer, %234
  %236 = icmp slt <4 x i32> %234, zeroinitializer
  %237 = select <4 x i1> %236, <4 x i32> %235, <4 x i32> %234
  %238 = add nuw nsw <4 x i32> %237, <i32 32, i32 32, i32 32, i32 32>
  %239 = lshr <4 x i32> %238, <i32 6, i32 6, i32 6, i32 6>
  %240 = shufflevector <8 x i16> %226, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %241 = shufflevector <8 x i16> %229, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %242 = bitcast <8 x i16> %240 to <4 x i32>
  %243 = bitcast <8 x i16> %241 to <4 x i32>
  %244 = sub <4 x i32> %242, %243
  %245 = sub <4 x i32> zeroinitializer, %244
  %246 = icmp slt <4 x i32> %244, zeroinitializer
  %247 = select <4 x i1> %246, <4 x i32> %245, <4 x i32> %244
  %248 = add nuw <4 x i32> %247, <i32 32, i32 32, i32 32, i32 32>
  %249 = lshr <4 x i32> %248, <i32 6, i32 6, i32 6, i32 6>
  %250 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %239, <4 x i32> %249) #5
  %251 = lshr <8 x i16> %250, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %252 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %223, <8 x i16> %251) #5
  %253 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %252, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %254 = icmp slt <16 x i8> %253, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %255 = select <16 x i1> %254, <16 x i8> %253, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %256 = bitcast i8* %197 to <16 x i8>*
  store <16 x i8> %255, <16 x i8>* %256, align 16
  %257 = getelementptr inbounds i16, i16* %9, i64 64
  %258 = getelementptr inbounds i16, i16* %10, i64 64
  %259 = getelementptr inbounds i8, i8* %197, i64 %3
  %260 = bitcast i16* %257 to <8 x i16>*
  %261 = load <8 x i16>, <8 x i16>* %260, align 16
  %262 = bitcast i16* %258 to <8 x i16>*
  %263 = load <8 x i16>, <8 x i16>* %262, align 16
  %264 = shufflevector <8 x i16> %261, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %265 = zext <4 x i16> %264 to <4 x i32>
  %266 = shufflevector <8 x i16> %263, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %267 = zext <4 x i16> %266 to <4 x i32>
  %268 = sub nsw <4 x i32> %265, %267
  %269 = sub nsw <4 x i32> zeroinitializer, %268
  %270 = icmp slt <4 x i32> %268, zeroinitializer
  %271 = select <4 x i1> %270, <4 x i32> %269, <4 x i32> %268
  %272 = add nuw nsw <4 x i32> %271, <i32 32, i32 32, i32 32, i32 32>
  %273 = lshr <4 x i32> %272, <i32 6, i32 6, i32 6, i32 6>
  %274 = shufflevector <8 x i16> %261, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %275 = shufflevector <8 x i16> %263, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %276 = bitcast <8 x i16> %274 to <4 x i32>
  %277 = bitcast <8 x i16> %275 to <4 x i32>
  %278 = sub <4 x i32> %276, %277
  %279 = sub <4 x i32> zeroinitializer, %278
  %280 = icmp slt <4 x i32> %278, zeroinitializer
  %281 = select <4 x i1> %280, <4 x i32> %279, <4 x i32> %278
  %282 = add nuw <4 x i32> %281, <i32 32, i32 32, i32 32, i32 32>
  %283 = lshr <4 x i32> %282, <i32 6, i32 6, i32 6, i32 6>
  %284 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %273, <4 x i32> %283) #5
  %285 = lshr <8 x i16> %284, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %286 = getelementptr inbounds i16, i16* %9, i64 72
  %287 = bitcast i16* %286 to <8 x i16>*
  %288 = load <8 x i16>, <8 x i16>* %287, align 16
  %289 = getelementptr inbounds i16, i16* %10, i64 72
  %290 = bitcast i16* %289 to <8 x i16>*
  %291 = load <8 x i16>, <8 x i16>* %290, align 16
  %292 = shufflevector <8 x i16> %288, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %293 = zext <4 x i16> %292 to <4 x i32>
  %294 = shufflevector <8 x i16> %291, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %295 = zext <4 x i16> %294 to <4 x i32>
  %296 = sub nsw <4 x i32> %293, %295
  %297 = sub nsw <4 x i32> zeroinitializer, %296
  %298 = icmp slt <4 x i32> %296, zeroinitializer
  %299 = select <4 x i1> %298, <4 x i32> %297, <4 x i32> %296
  %300 = add nuw nsw <4 x i32> %299, <i32 32, i32 32, i32 32, i32 32>
  %301 = lshr <4 x i32> %300, <i32 6, i32 6, i32 6, i32 6>
  %302 = shufflevector <8 x i16> %288, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %303 = shufflevector <8 x i16> %291, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %304 = bitcast <8 x i16> %302 to <4 x i32>
  %305 = bitcast <8 x i16> %303 to <4 x i32>
  %306 = sub <4 x i32> %304, %305
  %307 = sub <4 x i32> zeroinitializer, %306
  %308 = icmp slt <4 x i32> %306, zeroinitializer
  %309 = select <4 x i1> %308, <4 x i32> %307, <4 x i32> %306
  %310 = add nuw <4 x i32> %309, <i32 32, i32 32, i32 32, i32 32>
  %311 = lshr <4 x i32> %310, <i32 6, i32 6, i32 6, i32 6>
  %312 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %301, <4 x i32> %311) #5
  %313 = lshr <8 x i16> %312, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %314 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %285, <8 x i16> %313) #5
  %315 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %314, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %316 = icmp slt <16 x i8> %315, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %317 = select <16 x i1> %316, <16 x i8> %315, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %318 = bitcast i8* %259 to <16 x i8>*
  store <16 x i8> %317, <16 x i8>* %318, align 16
  %319 = getelementptr inbounds i16, i16* %9, i64 80
  %320 = getelementptr inbounds i16, i16* %10, i64 80
  %321 = getelementptr inbounds i8, i8* %259, i64 %3
  %322 = add nsw i32 %11, -1
  %323 = icmp eq i32 %322, 0
  br i1 %323, label %324, label %7

324:                                              ; preds = %7
  %325 = bitcast i16* %319 to <8 x i16>*
  %326 = load <8 x i16>, <8 x i16>* %325, align 16
  %327 = bitcast i16* %320 to <8 x i16>*
  %328 = load <8 x i16>, <8 x i16>* %327, align 16
  %329 = shufflevector <8 x i16> %326, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %330 = zext <4 x i16> %329 to <4 x i32>
  %331 = shufflevector <8 x i16> %328, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %332 = zext <4 x i16> %331 to <4 x i32>
  %333 = sub nsw <4 x i32> %330, %332
  %334 = sub nsw <4 x i32> zeroinitializer, %333
  %335 = icmp slt <4 x i32> %333, zeroinitializer
  %336 = select <4 x i1> %335, <4 x i32> %334, <4 x i32> %333
  %337 = add nuw nsw <4 x i32> %336, <i32 32, i32 32, i32 32, i32 32>
  %338 = lshr <4 x i32> %337, <i32 6, i32 6, i32 6, i32 6>
  %339 = shufflevector <8 x i16> %326, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %340 = shufflevector <8 x i16> %328, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %341 = bitcast <8 x i16> %339 to <4 x i32>
  %342 = bitcast <8 x i16> %340 to <4 x i32>
  %343 = sub <4 x i32> %341, %342
  %344 = sub <4 x i32> zeroinitializer, %343
  %345 = icmp slt <4 x i32> %343, zeroinitializer
  %346 = select <4 x i1> %345, <4 x i32> %344, <4 x i32> %343
  %347 = add nuw <4 x i32> %346, <i32 32, i32 32, i32 32, i32 32>
  %348 = lshr <4 x i32> %347, <i32 6, i32 6, i32 6, i32 6>
  %349 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %338, <4 x i32> %348) #5
  %350 = lshr <8 x i16> %349, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %351 = getelementptr inbounds i16, i16* %9, i64 88
  %352 = bitcast i16* %351 to <8 x i16>*
  %353 = load <8 x i16>, <8 x i16>* %352, align 16
  %354 = getelementptr inbounds i16, i16* %10, i64 88
  %355 = bitcast i16* %354 to <8 x i16>*
  %356 = load <8 x i16>, <8 x i16>* %355, align 16
  %357 = shufflevector <8 x i16> %353, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %358 = zext <4 x i16> %357 to <4 x i32>
  %359 = shufflevector <8 x i16> %356, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %360 = zext <4 x i16> %359 to <4 x i32>
  %361 = sub nsw <4 x i32> %358, %360
  %362 = sub nsw <4 x i32> zeroinitializer, %361
  %363 = icmp slt <4 x i32> %361, zeroinitializer
  %364 = select <4 x i1> %363, <4 x i32> %362, <4 x i32> %361
  %365 = add nuw nsw <4 x i32> %364, <i32 32, i32 32, i32 32, i32 32>
  %366 = lshr <4 x i32> %365, <i32 6, i32 6, i32 6, i32 6>
  %367 = shufflevector <8 x i16> %353, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %368 = shufflevector <8 x i16> %356, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %369 = bitcast <8 x i16> %367 to <4 x i32>
  %370 = bitcast <8 x i16> %368 to <4 x i32>
  %371 = sub <4 x i32> %369, %370
  %372 = sub <4 x i32> zeroinitializer, %371
  %373 = icmp slt <4 x i32> %371, zeroinitializer
  %374 = select <4 x i1> %373, <4 x i32> %372, <4 x i32> %371
  %375 = add nuw <4 x i32> %374, <i32 32, i32 32, i32 32, i32 32>
  %376 = lshr <4 x i32> %375, <i32 6, i32 6, i32 6, i32 6>
  %377 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %366, <4 x i32> %376) #5
  %378 = lshr <8 x i16> %377, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %379 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %350, <8 x i16> %378) #5
  %380 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %379, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %381 = icmp slt <16 x i8> %380, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %382 = select <16 x i1> %381, <16 x i8> %380, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %383 = bitcast i8* %321 to <16 x i8>*
  store <16 x i8> %382, <16 x i8>* %383, align 16
  %384 = getelementptr inbounds i16, i16* %9, i64 96
  %385 = getelementptr inbounds i16, i16* %10, i64 96
  %386 = getelementptr inbounds i8, i8* %321, i64 %3
  %387 = bitcast i16* %384 to <8 x i16>*
  %388 = load <8 x i16>, <8 x i16>* %387, align 16
  %389 = bitcast i16* %385 to <8 x i16>*
  %390 = load <8 x i16>, <8 x i16>* %389, align 16
  %391 = shufflevector <8 x i16> %388, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %392 = zext <4 x i16> %391 to <4 x i32>
  %393 = shufflevector <8 x i16> %390, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %394 = zext <4 x i16> %393 to <4 x i32>
  %395 = sub nsw <4 x i32> %392, %394
  %396 = sub nsw <4 x i32> zeroinitializer, %395
  %397 = icmp slt <4 x i32> %395, zeroinitializer
  %398 = select <4 x i1> %397, <4 x i32> %396, <4 x i32> %395
  %399 = add nuw nsw <4 x i32> %398, <i32 32, i32 32, i32 32, i32 32>
  %400 = lshr <4 x i32> %399, <i32 6, i32 6, i32 6, i32 6>
  %401 = shufflevector <8 x i16> %388, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %402 = shufflevector <8 x i16> %390, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %403 = bitcast <8 x i16> %401 to <4 x i32>
  %404 = bitcast <8 x i16> %402 to <4 x i32>
  %405 = sub <4 x i32> %403, %404
  %406 = sub <4 x i32> zeroinitializer, %405
  %407 = icmp slt <4 x i32> %405, zeroinitializer
  %408 = select <4 x i1> %407, <4 x i32> %406, <4 x i32> %405
  %409 = add nuw <4 x i32> %408, <i32 32, i32 32, i32 32, i32 32>
  %410 = lshr <4 x i32> %409, <i32 6, i32 6, i32 6, i32 6>
  %411 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %400, <4 x i32> %410) #5
  %412 = lshr <8 x i16> %411, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %413 = getelementptr inbounds i16, i16* %9, i64 104
  %414 = bitcast i16* %413 to <8 x i16>*
  %415 = load <8 x i16>, <8 x i16>* %414, align 16
  %416 = getelementptr inbounds i16, i16* %10, i64 104
  %417 = bitcast i16* %416 to <8 x i16>*
  %418 = load <8 x i16>, <8 x i16>* %417, align 16
  %419 = shufflevector <8 x i16> %415, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %420 = zext <4 x i16> %419 to <4 x i32>
  %421 = shufflevector <8 x i16> %418, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %422 = zext <4 x i16> %421 to <4 x i32>
  %423 = sub nsw <4 x i32> %420, %422
  %424 = sub nsw <4 x i32> zeroinitializer, %423
  %425 = icmp slt <4 x i32> %423, zeroinitializer
  %426 = select <4 x i1> %425, <4 x i32> %424, <4 x i32> %423
  %427 = add nuw nsw <4 x i32> %426, <i32 32, i32 32, i32 32, i32 32>
  %428 = lshr <4 x i32> %427, <i32 6, i32 6, i32 6, i32 6>
  %429 = shufflevector <8 x i16> %415, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %430 = shufflevector <8 x i16> %418, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %431 = bitcast <8 x i16> %429 to <4 x i32>
  %432 = bitcast <8 x i16> %430 to <4 x i32>
  %433 = sub <4 x i32> %431, %432
  %434 = sub <4 x i32> zeroinitializer, %433
  %435 = icmp slt <4 x i32> %433, zeroinitializer
  %436 = select <4 x i1> %435, <4 x i32> %434, <4 x i32> %433
  %437 = add nuw <4 x i32> %436, <i32 32, i32 32, i32 32, i32 32>
  %438 = lshr <4 x i32> %437, <i32 6, i32 6, i32 6, i32 6>
  %439 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %428, <4 x i32> %438) #5
  %440 = lshr <8 x i16> %439, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %441 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %412, <8 x i16> %440) #5
  %442 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %441, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %443 = icmp slt <16 x i8> %442, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %444 = select <16 x i1> %443, <16 x i8> %442, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %445 = bitcast i8* %386 to <16 x i8>*
  store <16 x i8> %444, <16 x i8>* %445, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask16x32_10bpp_SSE4ILb1EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %326, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %324, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %325, %7 ]
  %11 = phi i32 [ 6, %4 ], [ %327, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = shufflevector <8 x i16> %13, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %17 = zext <4 x i16> %16 to <4 x i32>
  %18 = shufflevector <8 x i16> %15, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %19 = zext <4 x i16> %18 to <4 x i32>
  %20 = sub nsw <4 x i32> %17, %19
  %21 = sub nsw <4 x i32> zeroinitializer, %20
  %22 = icmp slt <4 x i32> %20, zeroinitializer
  %23 = select <4 x i1> %22, <4 x i32> %21, <4 x i32> %20
  %24 = add nuw nsw <4 x i32> %23, <i32 32, i32 32, i32 32, i32 32>
  %25 = lshr <4 x i32> %24, <i32 6, i32 6, i32 6, i32 6>
  %26 = shufflevector <8 x i16> %13, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %27 = shufflevector <8 x i16> %15, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %28 = bitcast <8 x i16> %26 to <4 x i32>
  %29 = bitcast <8 x i16> %27 to <4 x i32>
  %30 = sub <4 x i32> %28, %29
  %31 = sub <4 x i32> zeroinitializer, %30
  %32 = icmp slt <4 x i32> %30, zeroinitializer
  %33 = select <4 x i1> %32, <4 x i32> %31, <4 x i32> %30
  %34 = add nuw <4 x i32> %33, <i32 32, i32 32, i32 32, i32 32>
  %35 = lshr <4 x i32> %34, <i32 6, i32 6, i32 6, i32 6>
  %36 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %25, <4 x i32> %35) #5
  %37 = lshr <8 x i16> %36, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %38 = getelementptr inbounds i16, i16* %9, i64 8
  %39 = bitcast i16* %38 to <8 x i16>*
  %40 = load <8 x i16>, <8 x i16>* %39, align 16
  %41 = getelementptr inbounds i16, i16* %10, i64 8
  %42 = bitcast i16* %41 to <8 x i16>*
  %43 = load <8 x i16>, <8 x i16>* %42, align 16
  %44 = shufflevector <8 x i16> %40, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %45 = zext <4 x i16> %44 to <4 x i32>
  %46 = shufflevector <8 x i16> %43, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %47 = zext <4 x i16> %46 to <4 x i32>
  %48 = sub nsw <4 x i32> %45, %47
  %49 = sub nsw <4 x i32> zeroinitializer, %48
  %50 = icmp slt <4 x i32> %48, zeroinitializer
  %51 = select <4 x i1> %50, <4 x i32> %49, <4 x i32> %48
  %52 = add nuw nsw <4 x i32> %51, <i32 32, i32 32, i32 32, i32 32>
  %53 = lshr <4 x i32> %52, <i32 6, i32 6, i32 6, i32 6>
  %54 = shufflevector <8 x i16> %40, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %55 = shufflevector <8 x i16> %43, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %56 = bitcast <8 x i16> %54 to <4 x i32>
  %57 = bitcast <8 x i16> %55 to <4 x i32>
  %58 = sub <4 x i32> %56, %57
  %59 = sub <4 x i32> zeroinitializer, %58
  %60 = icmp slt <4 x i32> %58, zeroinitializer
  %61 = select <4 x i1> %60, <4 x i32> %59, <4 x i32> %58
  %62 = add nuw <4 x i32> %61, <i32 32, i32 32, i32 32, i32 32>
  %63 = lshr <4 x i32> %62, <i32 6, i32 6, i32 6, i32 6>
  %64 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %53, <4 x i32> %63) #5
  %65 = lshr <8 x i16> %64, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %66 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %37, <8 x i16> %65) #5
  %67 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %66, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %68 = icmp slt <16 x i8> %67, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %69 = select <16 x i1> %68, <16 x i8> %67, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %70 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %69
  %71 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %70, <16 x i8>* %71, align 16
  %72 = getelementptr inbounds i16, i16* %9, i64 16
  %73 = getelementptr inbounds i16, i16* %10, i64 16
  %74 = getelementptr inbounds i8, i8* %8, i64 %3
  %75 = bitcast i16* %72 to <8 x i16>*
  %76 = load <8 x i16>, <8 x i16>* %75, align 16
  %77 = bitcast i16* %73 to <8 x i16>*
  %78 = load <8 x i16>, <8 x i16>* %77, align 16
  %79 = shufflevector <8 x i16> %76, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %80 = zext <4 x i16> %79 to <4 x i32>
  %81 = shufflevector <8 x i16> %78, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %82 = zext <4 x i16> %81 to <4 x i32>
  %83 = sub nsw <4 x i32> %80, %82
  %84 = sub nsw <4 x i32> zeroinitializer, %83
  %85 = icmp slt <4 x i32> %83, zeroinitializer
  %86 = select <4 x i1> %85, <4 x i32> %84, <4 x i32> %83
  %87 = add nuw nsw <4 x i32> %86, <i32 32, i32 32, i32 32, i32 32>
  %88 = lshr <4 x i32> %87, <i32 6, i32 6, i32 6, i32 6>
  %89 = shufflevector <8 x i16> %76, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %90 = shufflevector <8 x i16> %78, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %91 = bitcast <8 x i16> %89 to <4 x i32>
  %92 = bitcast <8 x i16> %90 to <4 x i32>
  %93 = sub <4 x i32> %91, %92
  %94 = sub <4 x i32> zeroinitializer, %93
  %95 = icmp slt <4 x i32> %93, zeroinitializer
  %96 = select <4 x i1> %95, <4 x i32> %94, <4 x i32> %93
  %97 = add nuw <4 x i32> %96, <i32 32, i32 32, i32 32, i32 32>
  %98 = lshr <4 x i32> %97, <i32 6, i32 6, i32 6, i32 6>
  %99 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %88, <4 x i32> %98) #5
  %100 = lshr <8 x i16> %99, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %101 = getelementptr inbounds i16, i16* %9, i64 24
  %102 = bitcast i16* %101 to <8 x i16>*
  %103 = load <8 x i16>, <8 x i16>* %102, align 16
  %104 = getelementptr inbounds i16, i16* %10, i64 24
  %105 = bitcast i16* %104 to <8 x i16>*
  %106 = load <8 x i16>, <8 x i16>* %105, align 16
  %107 = shufflevector <8 x i16> %103, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %108 = zext <4 x i16> %107 to <4 x i32>
  %109 = shufflevector <8 x i16> %106, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %110 = zext <4 x i16> %109 to <4 x i32>
  %111 = sub nsw <4 x i32> %108, %110
  %112 = sub nsw <4 x i32> zeroinitializer, %111
  %113 = icmp slt <4 x i32> %111, zeroinitializer
  %114 = select <4 x i1> %113, <4 x i32> %112, <4 x i32> %111
  %115 = add nuw nsw <4 x i32> %114, <i32 32, i32 32, i32 32, i32 32>
  %116 = lshr <4 x i32> %115, <i32 6, i32 6, i32 6, i32 6>
  %117 = shufflevector <8 x i16> %103, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %118 = shufflevector <8 x i16> %106, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %119 = bitcast <8 x i16> %117 to <4 x i32>
  %120 = bitcast <8 x i16> %118 to <4 x i32>
  %121 = sub <4 x i32> %119, %120
  %122 = sub <4 x i32> zeroinitializer, %121
  %123 = icmp slt <4 x i32> %121, zeroinitializer
  %124 = select <4 x i1> %123, <4 x i32> %122, <4 x i32> %121
  %125 = add nuw <4 x i32> %124, <i32 32, i32 32, i32 32, i32 32>
  %126 = lshr <4 x i32> %125, <i32 6, i32 6, i32 6, i32 6>
  %127 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %116, <4 x i32> %126) #5
  %128 = lshr <8 x i16> %127, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %129 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %100, <8 x i16> %128) #5
  %130 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %129, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %131 = icmp slt <16 x i8> %130, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %132 = select <16 x i1> %131, <16 x i8> %130, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %133 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %132
  %134 = bitcast i8* %74 to <16 x i8>*
  store <16 x i8> %133, <16 x i8>* %134, align 16
  %135 = getelementptr inbounds i16, i16* %9, i64 32
  %136 = getelementptr inbounds i16, i16* %10, i64 32
  %137 = getelementptr inbounds i8, i8* %74, i64 %3
  %138 = bitcast i16* %135 to <8 x i16>*
  %139 = load <8 x i16>, <8 x i16>* %138, align 16
  %140 = bitcast i16* %136 to <8 x i16>*
  %141 = load <8 x i16>, <8 x i16>* %140, align 16
  %142 = shufflevector <8 x i16> %139, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %143 = zext <4 x i16> %142 to <4 x i32>
  %144 = shufflevector <8 x i16> %141, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %145 = zext <4 x i16> %144 to <4 x i32>
  %146 = sub nsw <4 x i32> %143, %145
  %147 = sub nsw <4 x i32> zeroinitializer, %146
  %148 = icmp slt <4 x i32> %146, zeroinitializer
  %149 = select <4 x i1> %148, <4 x i32> %147, <4 x i32> %146
  %150 = add nuw nsw <4 x i32> %149, <i32 32, i32 32, i32 32, i32 32>
  %151 = lshr <4 x i32> %150, <i32 6, i32 6, i32 6, i32 6>
  %152 = shufflevector <8 x i16> %139, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %153 = shufflevector <8 x i16> %141, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %154 = bitcast <8 x i16> %152 to <4 x i32>
  %155 = bitcast <8 x i16> %153 to <4 x i32>
  %156 = sub <4 x i32> %154, %155
  %157 = sub <4 x i32> zeroinitializer, %156
  %158 = icmp slt <4 x i32> %156, zeroinitializer
  %159 = select <4 x i1> %158, <4 x i32> %157, <4 x i32> %156
  %160 = add nuw <4 x i32> %159, <i32 32, i32 32, i32 32, i32 32>
  %161 = lshr <4 x i32> %160, <i32 6, i32 6, i32 6, i32 6>
  %162 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %151, <4 x i32> %161) #5
  %163 = lshr <8 x i16> %162, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %164 = getelementptr inbounds i16, i16* %9, i64 40
  %165 = bitcast i16* %164 to <8 x i16>*
  %166 = load <8 x i16>, <8 x i16>* %165, align 16
  %167 = getelementptr inbounds i16, i16* %10, i64 40
  %168 = bitcast i16* %167 to <8 x i16>*
  %169 = load <8 x i16>, <8 x i16>* %168, align 16
  %170 = shufflevector <8 x i16> %166, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %171 = zext <4 x i16> %170 to <4 x i32>
  %172 = shufflevector <8 x i16> %169, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %173 = zext <4 x i16> %172 to <4 x i32>
  %174 = sub nsw <4 x i32> %171, %173
  %175 = sub nsw <4 x i32> zeroinitializer, %174
  %176 = icmp slt <4 x i32> %174, zeroinitializer
  %177 = select <4 x i1> %176, <4 x i32> %175, <4 x i32> %174
  %178 = add nuw nsw <4 x i32> %177, <i32 32, i32 32, i32 32, i32 32>
  %179 = lshr <4 x i32> %178, <i32 6, i32 6, i32 6, i32 6>
  %180 = shufflevector <8 x i16> %166, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %181 = shufflevector <8 x i16> %169, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %182 = bitcast <8 x i16> %180 to <4 x i32>
  %183 = bitcast <8 x i16> %181 to <4 x i32>
  %184 = sub <4 x i32> %182, %183
  %185 = sub <4 x i32> zeroinitializer, %184
  %186 = icmp slt <4 x i32> %184, zeroinitializer
  %187 = select <4 x i1> %186, <4 x i32> %185, <4 x i32> %184
  %188 = add nuw <4 x i32> %187, <i32 32, i32 32, i32 32, i32 32>
  %189 = lshr <4 x i32> %188, <i32 6, i32 6, i32 6, i32 6>
  %190 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %179, <4 x i32> %189) #5
  %191 = lshr <8 x i16> %190, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %192 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %163, <8 x i16> %191) #5
  %193 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %192, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %194 = icmp slt <16 x i8> %193, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %195 = select <16 x i1> %194, <16 x i8> %193, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %196 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %195
  %197 = bitcast i8* %137 to <16 x i8>*
  store <16 x i8> %196, <16 x i8>* %197, align 16
  %198 = getelementptr inbounds i16, i16* %9, i64 48
  %199 = getelementptr inbounds i16, i16* %10, i64 48
  %200 = getelementptr inbounds i8, i8* %137, i64 %3
  %201 = bitcast i16* %198 to <8 x i16>*
  %202 = load <8 x i16>, <8 x i16>* %201, align 16
  %203 = bitcast i16* %199 to <8 x i16>*
  %204 = load <8 x i16>, <8 x i16>* %203, align 16
  %205 = shufflevector <8 x i16> %202, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %206 = zext <4 x i16> %205 to <4 x i32>
  %207 = shufflevector <8 x i16> %204, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %208 = zext <4 x i16> %207 to <4 x i32>
  %209 = sub nsw <4 x i32> %206, %208
  %210 = sub nsw <4 x i32> zeroinitializer, %209
  %211 = icmp slt <4 x i32> %209, zeroinitializer
  %212 = select <4 x i1> %211, <4 x i32> %210, <4 x i32> %209
  %213 = add nuw nsw <4 x i32> %212, <i32 32, i32 32, i32 32, i32 32>
  %214 = lshr <4 x i32> %213, <i32 6, i32 6, i32 6, i32 6>
  %215 = shufflevector <8 x i16> %202, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %216 = shufflevector <8 x i16> %204, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %217 = bitcast <8 x i16> %215 to <4 x i32>
  %218 = bitcast <8 x i16> %216 to <4 x i32>
  %219 = sub <4 x i32> %217, %218
  %220 = sub <4 x i32> zeroinitializer, %219
  %221 = icmp slt <4 x i32> %219, zeroinitializer
  %222 = select <4 x i1> %221, <4 x i32> %220, <4 x i32> %219
  %223 = add nuw <4 x i32> %222, <i32 32, i32 32, i32 32, i32 32>
  %224 = lshr <4 x i32> %223, <i32 6, i32 6, i32 6, i32 6>
  %225 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %214, <4 x i32> %224) #5
  %226 = lshr <8 x i16> %225, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %227 = getelementptr inbounds i16, i16* %9, i64 56
  %228 = bitcast i16* %227 to <8 x i16>*
  %229 = load <8 x i16>, <8 x i16>* %228, align 16
  %230 = getelementptr inbounds i16, i16* %10, i64 56
  %231 = bitcast i16* %230 to <8 x i16>*
  %232 = load <8 x i16>, <8 x i16>* %231, align 16
  %233 = shufflevector <8 x i16> %229, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %234 = zext <4 x i16> %233 to <4 x i32>
  %235 = shufflevector <8 x i16> %232, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %236 = zext <4 x i16> %235 to <4 x i32>
  %237 = sub nsw <4 x i32> %234, %236
  %238 = sub nsw <4 x i32> zeroinitializer, %237
  %239 = icmp slt <4 x i32> %237, zeroinitializer
  %240 = select <4 x i1> %239, <4 x i32> %238, <4 x i32> %237
  %241 = add nuw nsw <4 x i32> %240, <i32 32, i32 32, i32 32, i32 32>
  %242 = lshr <4 x i32> %241, <i32 6, i32 6, i32 6, i32 6>
  %243 = shufflevector <8 x i16> %229, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %244 = shufflevector <8 x i16> %232, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %245 = bitcast <8 x i16> %243 to <4 x i32>
  %246 = bitcast <8 x i16> %244 to <4 x i32>
  %247 = sub <4 x i32> %245, %246
  %248 = sub <4 x i32> zeroinitializer, %247
  %249 = icmp slt <4 x i32> %247, zeroinitializer
  %250 = select <4 x i1> %249, <4 x i32> %248, <4 x i32> %247
  %251 = add nuw <4 x i32> %250, <i32 32, i32 32, i32 32, i32 32>
  %252 = lshr <4 x i32> %251, <i32 6, i32 6, i32 6, i32 6>
  %253 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %242, <4 x i32> %252) #5
  %254 = lshr <8 x i16> %253, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %255 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %226, <8 x i16> %254) #5
  %256 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %255, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %257 = icmp slt <16 x i8> %256, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %258 = select <16 x i1> %257, <16 x i8> %256, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %259 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %258
  %260 = bitcast i8* %200 to <16 x i8>*
  store <16 x i8> %259, <16 x i8>* %260, align 16
  %261 = getelementptr inbounds i16, i16* %9, i64 64
  %262 = getelementptr inbounds i16, i16* %10, i64 64
  %263 = getelementptr inbounds i8, i8* %200, i64 %3
  %264 = bitcast i16* %261 to <8 x i16>*
  %265 = load <8 x i16>, <8 x i16>* %264, align 16
  %266 = bitcast i16* %262 to <8 x i16>*
  %267 = load <8 x i16>, <8 x i16>* %266, align 16
  %268 = shufflevector <8 x i16> %265, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %269 = zext <4 x i16> %268 to <4 x i32>
  %270 = shufflevector <8 x i16> %267, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %271 = zext <4 x i16> %270 to <4 x i32>
  %272 = sub nsw <4 x i32> %269, %271
  %273 = sub nsw <4 x i32> zeroinitializer, %272
  %274 = icmp slt <4 x i32> %272, zeroinitializer
  %275 = select <4 x i1> %274, <4 x i32> %273, <4 x i32> %272
  %276 = add nuw nsw <4 x i32> %275, <i32 32, i32 32, i32 32, i32 32>
  %277 = lshr <4 x i32> %276, <i32 6, i32 6, i32 6, i32 6>
  %278 = shufflevector <8 x i16> %265, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %279 = shufflevector <8 x i16> %267, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %280 = bitcast <8 x i16> %278 to <4 x i32>
  %281 = bitcast <8 x i16> %279 to <4 x i32>
  %282 = sub <4 x i32> %280, %281
  %283 = sub <4 x i32> zeroinitializer, %282
  %284 = icmp slt <4 x i32> %282, zeroinitializer
  %285 = select <4 x i1> %284, <4 x i32> %283, <4 x i32> %282
  %286 = add nuw <4 x i32> %285, <i32 32, i32 32, i32 32, i32 32>
  %287 = lshr <4 x i32> %286, <i32 6, i32 6, i32 6, i32 6>
  %288 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %277, <4 x i32> %287) #5
  %289 = lshr <8 x i16> %288, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %290 = getelementptr inbounds i16, i16* %9, i64 72
  %291 = bitcast i16* %290 to <8 x i16>*
  %292 = load <8 x i16>, <8 x i16>* %291, align 16
  %293 = getelementptr inbounds i16, i16* %10, i64 72
  %294 = bitcast i16* %293 to <8 x i16>*
  %295 = load <8 x i16>, <8 x i16>* %294, align 16
  %296 = shufflevector <8 x i16> %292, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %297 = zext <4 x i16> %296 to <4 x i32>
  %298 = shufflevector <8 x i16> %295, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %299 = zext <4 x i16> %298 to <4 x i32>
  %300 = sub nsw <4 x i32> %297, %299
  %301 = sub nsw <4 x i32> zeroinitializer, %300
  %302 = icmp slt <4 x i32> %300, zeroinitializer
  %303 = select <4 x i1> %302, <4 x i32> %301, <4 x i32> %300
  %304 = add nuw nsw <4 x i32> %303, <i32 32, i32 32, i32 32, i32 32>
  %305 = lshr <4 x i32> %304, <i32 6, i32 6, i32 6, i32 6>
  %306 = shufflevector <8 x i16> %292, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %307 = shufflevector <8 x i16> %295, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %308 = bitcast <8 x i16> %306 to <4 x i32>
  %309 = bitcast <8 x i16> %307 to <4 x i32>
  %310 = sub <4 x i32> %308, %309
  %311 = sub <4 x i32> zeroinitializer, %310
  %312 = icmp slt <4 x i32> %310, zeroinitializer
  %313 = select <4 x i1> %312, <4 x i32> %311, <4 x i32> %310
  %314 = add nuw <4 x i32> %313, <i32 32, i32 32, i32 32, i32 32>
  %315 = lshr <4 x i32> %314, <i32 6, i32 6, i32 6, i32 6>
  %316 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %305, <4 x i32> %315) #5
  %317 = lshr <8 x i16> %316, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %318 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %289, <8 x i16> %317) #5
  %319 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %318, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %320 = icmp slt <16 x i8> %319, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %321 = select <16 x i1> %320, <16 x i8> %319, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %322 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %321
  %323 = bitcast i8* %263 to <16 x i8>*
  store <16 x i8> %322, <16 x i8>* %323, align 16
  %324 = getelementptr inbounds i16, i16* %9, i64 80
  %325 = getelementptr inbounds i16, i16* %10, i64 80
  %326 = getelementptr inbounds i8, i8* %263, i64 %3
  %327 = add nsw i32 %11, -1
  %328 = icmp eq i32 %327, 0
  br i1 %328, label %329, label %7

329:                                              ; preds = %7
  %330 = bitcast i16* %324 to <8 x i16>*
  %331 = load <8 x i16>, <8 x i16>* %330, align 16
  %332 = bitcast i16* %325 to <8 x i16>*
  %333 = load <8 x i16>, <8 x i16>* %332, align 16
  %334 = shufflevector <8 x i16> %331, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %335 = zext <4 x i16> %334 to <4 x i32>
  %336 = shufflevector <8 x i16> %333, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %337 = zext <4 x i16> %336 to <4 x i32>
  %338 = sub nsw <4 x i32> %335, %337
  %339 = sub nsw <4 x i32> zeroinitializer, %338
  %340 = icmp slt <4 x i32> %338, zeroinitializer
  %341 = select <4 x i1> %340, <4 x i32> %339, <4 x i32> %338
  %342 = add nuw nsw <4 x i32> %341, <i32 32, i32 32, i32 32, i32 32>
  %343 = lshr <4 x i32> %342, <i32 6, i32 6, i32 6, i32 6>
  %344 = shufflevector <8 x i16> %331, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %345 = shufflevector <8 x i16> %333, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %346 = bitcast <8 x i16> %344 to <4 x i32>
  %347 = bitcast <8 x i16> %345 to <4 x i32>
  %348 = sub <4 x i32> %346, %347
  %349 = sub <4 x i32> zeroinitializer, %348
  %350 = icmp slt <4 x i32> %348, zeroinitializer
  %351 = select <4 x i1> %350, <4 x i32> %349, <4 x i32> %348
  %352 = add nuw <4 x i32> %351, <i32 32, i32 32, i32 32, i32 32>
  %353 = lshr <4 x i32> %352, <i32 6, i32 6, i32 6, i32 6>
  %354 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %343, <4 x i32> %353) #5
  %355 = lshr <8 x i16> %354, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %356 = getelementptr inbounds i16, i16* %9, i64 88
  %357 = bitcast i16* %356 to <8 x i16>*
  %358 = load <8 x i16>, <8 x i16>* %357, align 16
  %359 = getelementptr inbounds i16, i16* %10, i64 88
  %360 = bitcast i16* %359 to <8 x i16>*
  %361 = load <8 x i16>, <8 x i16>* %360, align 16
  %362 = shufflevector <8 x i16> %358, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %363 = zext <4 x i16> %362 to <4 x i32>
  %364 = shufflevector <8 x i16> %361, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %365 = zext <4 x i16> %364 to <4 x i32>
  %366 = sub nsw <4 x i32> %363, %365
  %367 = sub nsw <4 x i32> zeroinitializer, %366
  %368 = icmp slt <4 x i32> %366, zeroinitializer
  %369 = select <4 x i1> %368, <4 x i32> %367, <4 x i32> %366
  %370 = add nuw nsw <4 x i32> %369, <i32 32, i32 32, i32 32, i32 32>
  %371 = lshr <4 x i32> %370, <i32 6, i32 6, i32 6, i32 6>
  %372 = shufflevector <8 x i16> %358, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %373 = shufflevector <8 x i16> %361, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %374 = bitcast <8 x i16> %372 to <4 x i32>
  %375 = bitcast <8 x i16> %373 to <4 x i32>
  %376 = sub <4 x i32> %374, %375
  %377 = sub <4 x i32> zeroinitializer, %376
  %378 = icmp slt <4 x i32> %376, zeroinitializer
  %379 = select <4 x i1> %378, <4 x i32> %377, <4 x i32> %376
  %380 = add nuw <4 x i32> %379, <i32 32, i32 32, i32 32, i32 32>
  %381 = lshr <4 x i32> %380, <i32 6, i32 6, i32 6, i32 6>
  %382 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %371, <4 x i32> %381) #5
  %383 = lshr <8 x i16> %382, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %384 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %355, <8 x i16> %383) #5
  %385 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %384, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %386 = icmp slt <16 x i8> %385, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %387 = select <16 x i1> %386, <16 x i8> %385, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %388 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %387
  %389 = bitcast i8* %326 to <16 x i8>*
  store <16 x i8> %388, <16 x i8>* %389, align 16
  %390 = getelementptr inbounds i16, i16* %9, i64 96
  %391 = getelementptr inbounds i16, i16* %10, i64 96
  %392 = getelementptr inbounds i8, i8* %326, i64 %3
  %393 = bitcast i16* %390 to <8 x i16>*
  %394 = load <8 x i16>, <8 x i16>* %393, align 16
  %395 = bitcast i16* %391 to <8 x i16>*
  %396 = load <8 x i16>, <8 x i16>* %395, align 16
  %397 = shufflevector <8 x i16> %394, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %398 = zext <4 x i16> %397 to <4 x i32>
  %399 = shufflevector <8 x i16> %396, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %400 = zext <4 x i16> %399 to <4 x i32>
  %401 = sub nsw <4 x i32> %398, %400
  %402 = sub nsw <4 x i32> zeroinitializer, %401
  %403 = icmp slt <4 x i32> %401, zeroinitializer
  %404 = select <4 x i1> %403, <4 x i32> %402, <4 x i32> %401
  %405 = add nuw nsw <4 x i32> %404, <i32 32, i32 32, i32 32, i32 32>
  %406 = lshr <4 x i32> %405, <i32 6, i32 6, i32 6, i32 6>
  %407 = shufflevector <8 x i16> %394, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %408 = shufflevector <8 x i16> %396, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %409 = bitcast <8 x i16> %407 to <4 x i32>
  %410 = bitcast <8 x i16> %408 to <4 x i32>
  %411 = sub <4 x i32> %409, %410
  %412 = sub <4 x i32> zeroinitializer, %411
  %413 = icmp slt <4 x i32> %411, zeroinitializer
  %414 = select <4 x i1> %413, <4 x i32> %412, <4 x i32> %411
  %415 = add nuw <4 x i32> %414, <i32 32, i32 32, i32 32, i32 32>
  %416 = lshr <4 x i32> %415, <i32 6, i32 6, i32 6, i32 6>
  %417 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %406, <4 x i32> %416) #5
  %418 = lshr <8 x i16> %417, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %419 = getelementptr inbounds i16, i16* %9, i64 104
  %420 = bitcast i16* %419 to <8 x i16>*
  %421 = load <8 x i16>, <8 x i16>* %420, align 16
  %422 = getelementptr inbounds i16, i16* %10, i64 104
  %423 = bitcast i16* %422 to <8 x i16>*
  %424 = load <8 x i16>, <8 x i16>* %423, align 16
  %425 = shufflevector <8 x i16> %421, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %426 = zext <4 x i16> %425 to <4 x i32>
  %427 = shufflevector <8 x i16> %424, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %428 = zext <4 x i16> %427 to <4 x i32>
  %429 = sub nsw <4 x i32> %426, %428
  %430 = sub nsw <4 x i32> zeroinitializer, %429
  %431 = icmp slt <4 x i32> %429, zeroinitializer
  %432 = select <4 x i1> %431, <4 x i32> %430, <4 x i32> %429
  %433 = add nuw nsw <4 x i32> %432, <i32 32, i32 32, i32 32, i32 32>
  %434 = lshr <4 x i32> %433, <i32 6, i32 6, i32 6, i32 6>
  %435 = shufflevector <8 x i16> %421, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %436 = shufflevector <8 x i16> %424, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %437 = bitcast <8 x i16> %435 to <4 x i32>
  %438 = bitcast <8 x i16> %436 to <4 x i32>
  %439 = sub <4 x i32> %437, %438
  %440 = sub <4 x i32> zeroinitializer, %439
  %441 = icmp slt <4 x i32> %439, zeroinitializer
  %442 = select <4 x i1> %441, <4 x i32> %440, <4 x i32> %439
  %443 = add nuw <4 x i32> %442, <i32 32, i32 32, i32 32, i32 32>
  %444 = lshr <4 x i32> %443, <i32 6, i32 6, i32 6, i32 6>
  %445 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %434, <4 x i32> %444) #5
  %446 = lshr <8 x i16> %445, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %447 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %418, <8 x i16> %446) #5
  %448 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %447, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %449 = icmp slt <16 x i8> %448, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %450 = select <16 x i1> %449, <16 x i8> %448, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %451 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %450
  %452 = bitcast i8* %392 to <16 x i8>*
  store <16 x i8> %451, <16 x i8>* %452, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask16x64_10bpp_SSE4ILb0EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %197, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %195, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %196, %7 ]
  %11 = phi i32 [ 21, %4 ], [ %198, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = shufflevector <8 x i16> %13, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %17 = zext <4 x i16> %16 to <4 x i32>
  %18 = shufflevector <8 x i16> %15, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %19 = zext <4 x i16> %18 to <4 x i32>
  %20 = sub nsw <4 x i32> %17, %19
  %21 = sub nsw <4 x i32> zeroinitializer, %20
  %22 = icmp slt <4 x i32> %20, zeroinitializer
  %23 = select <4 x i1> %22, <4 x i32> %21, <4 x i32> %20
  %24 = add nuw nsw <4 x i32> %23, <i32 32, i32 32, i32 32, i32 32>
  %25 = lshr <4 x i32> %24, <i32 6, i32 6, i32 6, i32 6>
  %26 = shufflevector <8 x i16> %13, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %27 = shufflevector <8 x i16> %15, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %28 = bitcast <8 x i16> %26 to <4 x i32>
  %29 = bitcast <8 x i16> %27 to <4 x i32>
  %30 = sub <4 x i32> %28, %29
  %31 = sub <4 x i32> zeroinitializer, %30
  %32 = icmp slt <4 x i32> %30, zeroinitializer
  %33 = select <4 x i1> %32, <4 x i32> %31, <4 x i32> %30
  %34 = add nuw <4 x i32> %33, <i32 32, i32 32, i32 32, i32 32>
  %35 = lshr <4 x i32> %34, <i32 6, i32 6, i32 6, i32 6>
  %36 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %25, <4 x i32> %35) #5
  %37 = lshr <8 x i16> %36, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %38 = getelementptr inbounds i16, i16* %9, i64 8
  %39 = bitcast i16* %38 to <8 x i16>*
  %40 = load <8 x i16>, <8 x i16>* %39, align 16
  %41 = getelementptr inbounds i16, i16* %10, i64 8
  %42 = bitcast i16* %41 to <8 x i16>*
  %43 = load <8 x i16>, <8 x i16>* %42, align 16
  %44 = shufflevector <8 x i16> %40, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %45 = zext <4 x i16> %44 to <4 x i32>
  %46 = shufflevector <8 x i16> %43, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %47 = zext <4 x i16> %46 to <4 x i32>
  %48 = sub nsw <4 x i32> %45, %47
  %49 = sub nsw <4 x i32> zeroinitializer, %48
  %50 = icmp slt <4 x i32> %48, zeroinitializer
  %51 = select <4 x i1> %50, <4 x i32> %49, <4 x i32> %48
  %52 = add nuw nsw <4 x i32> %51, <i32 32, i32 32, i32 32, i32 32>
  %53 = lshr <4 x i32> %52, <i32 6, i32 6, i32 6, i32 6>
  %54 = shufflevector <8 x i16> %40, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %55 = shufflevector <8 x i16> %43, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %56 = bitcast <8 x i16> %54 to <4 x i32>
  %57 = bitcast <8 x i16> %55 to <4 x i32>
  %58 = sub <4 x i32> %56, %57
  %59 = sub <4 x i32> zeroinitializer, %58
  %60 = icmp slt <4 x i32> %58, zeroinitializer
  %61 = select <4 x i1> %60, <4 x i32> %59, <4 x i32> %58
  %62 = add nuw <4 x i32> %61, <i32 32, i32 32, i32 32, i32 32>
  %63 = lshr <4 x i32> %62, <i32 6, i32 6, i32 6, i32 6>
  %64 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %53, <4 x i32> %63) #5
  %65 = lshr <8 x i16> %64, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %66 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %37, <8 x i16> %65) #5
  %67 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %66, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %68 = icmp slt <16 x i8> %67, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %69 = select <16 x i1> %68, <16 x i8> %67, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %70 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %69, <16 x i8>* %70, align 16
  %71 = getelementptr inbounds i16, i16* %9, i64 16
  %72 = getelementptr inbounds i16, i16* %10, i64 16
  %73 = getelementptr inbounds i8, i8* %8, i64 %3
  %74 = bitcast i16* %71 to <8 x i16>*
  %75 = load <8 x i16>, <8 x i16>* %74, align 16
  %76 = bitcast i16* %72 to <8 x i16>*
  %77 = load <8 x i16>, <8 x i16>* %76, align 16
  %78 = shufflevector <8 x i16> %75, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %79 = zext <4 x i16> %78 to <4 x i32>
  %80 = shufflevector <8 x i16> %77, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %81 = zext <4 x i16> %80 to <4 x i32>
  %82 = sub nsw <4 x i32> %79, %81
  %83 = sub nsw <4 x i32> zeroinitializer, %82
  %84 = icmp slt <4 x i32> %82, zeroinitializer
  %85 = select <4 x i1> %84, <4 x i32> %83, <4 x i32> %82
  %86 = add nuw nsw <4 x i32> %85, <i32 32, i32 32, i32 32, i32 32>
  %87 = lshr <4 x i32> %86, <i32 6, i32 6, i32 6, i32 6>
  %88 = shufflevector <8 x i16> %75, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %89 = shufflevector <8 x i16> %77, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %90 = bitcast <8 x i16> %88 to <4 x i32>
  %91 = bitcast <8 x i16> %89 to <4 x i32>
  %92 = sub <4 x i32> %90, %91
  %93 = sub <4 x i32> zeroinitializer, %92
  %94 = icmp slt <4 x i32> %92, zeroinitializer
  %95 = select <4 x i1> %94, <4 x i32> %93, <4 x i32> %92
  %96 = add nuw <4 x i32> %95, <i32 32, i32 32, i32 32, i32 32>
  %97 = lshr <4 x i32> %96, <i32 6, i32 6, i32 6, i32 6>
  %98 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %87, <4 x i32> %97) #5
  %99 = lshr <8 x i16> %98, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %100 = getelementptr inbounds i16, i16* %9, i64 24
  %101 = bitcast i16* %100 to <8 x i16>*
  %102 = load <8 x i16>, <8 x i16>* %101, align 16
  %103 = getelementptr inbounds i16, i16* %10, i64 24
  %104 = bitcast i16* %103 to <8 x i16>*
  %105 = load <8 x i16>, <8 x i16>* %104, align 16
  %106 = shufflevector <8 x i16> %102, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %107 = zext <4 x i16> %106 to <4 x i32>
  %108 = shufflevector <8 x i16> %105, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %109 = zext <4 x i16> %108 to <4 x i32>
  %110 = sub nsw <4 x i32> %107, %109
  %111 = sub nsw <4 x i32> zeroinitializer, %110
  %112 = icmp slt <4 x i32> %110, zeroinitializer
  %113 = select <4 x i1> %112, <4 x i32> %111, <4 x i32> %110
  %114 = add nuw nsw <4 x i32> %113, <i32 32, i32 32, i32 32, i32 32>
  %115 = lshr <4 x i32> %114, <i32 6, i32 6, i32 6, i32 6>
  %116 = shufflevector <8 x i16> %102, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %117 = shufflevector <8 x i16> %105, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %118 = bitcast <8 x i16> %116 to <4 x i32>
  %119 = bitcast <8 x i16> %117 to <4 x i32>
  %120 = sub <4 x i32> %118, %119
  %121 = sub <4 x i32> zeroinitializer, %120
  %122 = icmp slt <4 x i32> %120, zeroinitializer
  %123 = select <4 x i1> %122, <4 x i32> %121, <4 x i32> %120
  %124 = add nuw <4 x i32> %123, <i32 32, i32 32, i32 32, i32 32>
  %125 = lshr <4 x i32> %124, <i32 6, i32 6, i32 6, i32 6>
  %126 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %115, <4 x i32> %125) #5
  %127 = lshr <8 x i16> %126, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %128 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %99, <8 x i16> %127) #5
  %129 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %128, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %130 = icmp slt <16 x i8> %129, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %131 = select <16 x i1> %130, <16 x i8> %129, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %132 = bitcast i8* %73 to <16 x i8>*
  store <16 x i8> %131, <16 x i8>* %132, align 16
  %133 = getelementptr inbounds i16, i16* %9, i64 32
  %134 = getelementptr inbounds i16, i16* %10, i64 32
  %135 = getelementptr inbounds i8, i8* %73, i64 %3
  %136 = bitcast i16* %133 to <8 x i16>*
  %137 = load <8 x i16>, <8 x i16>* %136, align 16
  %138 = bitcast i16* %134 to <8 x i16>*
  %139 = load <8 x i16>, <8 x i16>* %138, align 16
  %140 = shufflevector <8 x i16> %137, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %141 = zext <4 x i16> %140 to <4 x i32>
  %142 = shufflevector <8 x i16> %139, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %143 = zext <4 x i16> %142 to <4 x i32>
  %144 = sub nsw <4 x i32> %141, %143
  %145 = sub nsw <4 x i32> zeroinitializer, %144
  %146 = icmp slt <4 x i32> %144, zeroinitializer
  %147 = select <4 x i1> %146, <4 x i32> %145, <4 x i32> %144
  %148 = add nuw nsw <4 x i32> %147, <i32 32, i32 32, i32 32, i32 32>
  %149 = lshr <4 x i32> %148, <i32 6, i32 6, i32 6, i32 6>
  %150 = shufflevector <8 x i16> %137, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %151 = shufflevector <8 x i16> %139, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %152 = bitcast <8 x i16> %150 to <4 x i32>
  %153 = bitcast <8 x i16> %151 to <4 x i32>
  %154 = sub <4 x i32> %152, %153
  %155 = sub <4 x i32> zeroinitializer, %154
  %156 = icmp slt <4 x i32> %154, zeroinitializer
  %157 = select <4 x i1> %156, <4 x i32> %155, <4 x i32> %154
  %158 = add nuw <4 x i32> %157, <i32 32, i32 32, i32 32, i32 32>
  %159 = lshr <4 x i32> %158, <i32 6, i32 6, i32 6, i32 6>
  %160 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %149, <4 x i32> %159) #5
  %161 = lshr <8 x i16> %160, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %162 = getelementptr inbounds i16, i16* %9, i64 40
  %163 = bitcast i16* %162 to <8 x i16>*
  %164 = load <8 x i16>, <8 x i16>* %163, align 16
  %165 = getelementptr inbounds i16, i16* %10, i64 40
  %166 = bitcast i16* %165 to <8 x i16>*
  %167 = load <8 x i16>, <8 x i16>* %166, align 16
  %168 = shufflevector <8 x i16> %164, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %169 = zext <4 x i16> %168 to <4 x i32>
  %170 = shufflevector <8 x i16> %167, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %171 = zext <4 x i16> %170 to <4 x i32>
  %172 = sub nsw <4 x i32> %169, %171
  %173 = sub nsw <4 x i32> zeroinitializer, %172
  %174 = icmp slt <4 x i32> %172, zeroinitializer
  %175 = select <4 x i1> %174, <4 x i32> %173, <4 x i32> %172
  %176 = add nuw nsw <4 x i32> %175, <i32 32, i32 32, i32 32, i32 32>
  %177 = lshr <4 x i32> %176, <i32 6, i32 6, i32 6, i32 6>
  %178 = shufflevector <8 x i16> %164, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %179 = shufflevector <8 x i16> %167, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %180 = bitcast <8 x i16> %178 to <4 x i32>
  %181 = bitcast <8 x i16> %179 to <4 x i32>
  %182 = sub <4 x i32> %180, %181
  %183 = sub <4 x i32> zeroinitializer, %182
  %184 = icmp slt <4 x i32> %182, zeroinitializer
  %185 = select <4 x i1> %184, <4 x i32> %183, <4 x i32> %182
  %186 = add nuw <4 x i32> %185, <i32 32, i32 32, i32 32, i32 32>
  %187 = lshr <4 x i32> %186, <i32 6, i32 6, i32 6, i32 6>
  %188 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %177, <4 x i32> %187) #5
  %189 = lshr <8 x i16> %188, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %190 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %161, <8 x i16> %189) #5
  %191 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %190, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %192 = icmp slt <16 x i8> %191, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %193 = select <16 x i1> %192, <16 x i8> %191, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %194 = bitcast i8* %135 to <16 x i8>*
  store <16 x i8> %193, <16 x i8>* %194, align 16
  %195 = getelementptr inbounds i16, i16* %9, i64 48
  %196 = getelementptr inbounds i16, i16* %10, i64 48
  %197 = getelementptr inbounds i8, i8* %135, i64 %3
  %198 = add nsw i32 %11, -1
  %199 = icmp eq i32 %198, 0
  br i1 %199, label %200, label %7

200:                                              ; preds = %7
  %201 = bitcast i16* %195 to <8 x i16>*
  %202 = load <8 x i16>, <8 x i16>* %201, align 16
  %203 = bitcast i16* %196 to <8 x i16>*
  %204 = load <8 x i16>, <8 x i16>* %203, align 16
  %205 = shufflevector <8 x i16> %202, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %206 = zext <4 x i16> %205 to <4 x i32>
  %207 = shufflevector <8 x i16> %204, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %208 = zext <4 x i16> %207 to <4 x i32>
  %209 = sub nsw <4 x i32> %206, %208
  %210 = sub nsw <4 x i32> zeroinitializer, %209
  %211 = icmp slt <4 x i32> %209, zeroinitializer
  %212 = select <4 x i1> %211, <4 x i32> %210, <4 x i32> %209
  %213 = add nuw nsw <4 x i32> %212, <i32 32, i32 32, i32 32, i32 32>
  %214 = lshr <4 x i32> %213, <i32 6, i32 6, i32 6, i32 6>
  %215 = shufflevector <8 x i16> %202, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %216 = shufflevector <8 x i16> %204, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %217 = bitcast <8 x i16> %215 to <4 x i32>
  %218 = bitcast <8 x i16> %216 to <4 x i32>
  %219 = sub <4 x i32> %217, %218
  %220 = sub <4 x i32> zeroinitializer, %219
  %221 = icmp slt <4 x i32> %219, zeroinitializer
  %222 = select <4 x i1> %221, <4 x i32> %220, <4 x i32> %219
  %223 = add nuw <4 x i32> %222, <i32 32, i32 32, i32 32, i32 32>
  %224 = lshr <4 x i32> %223, <i32 6, i32 6, i32 6, i32 6>
  %225 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %214, <4 x i32> %224) #5
  %226 = lshr <8 x i16> %225, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %227 = getelementptr inbounds i16, i16* %9, i64 56
  %228 = bitcast i16* %227 to <8 x i16>*
  %229 = load <8 x i16>, <8 x i16>* %228, align 16
  %230 = getelementptr inbounds i16, i16* %10, i64 56
  %231 = bitcast i16* %230 to <8 x i16>*
  %232 = load <8 x i16>, <8 x i16>* %231, align 16
  %233 = shufflevector <8 x i16> %229, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %234 = zext <4 x i16> %233 to <4 x i32>
  %235 = shufflevector <8 x i16> %232, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %236 = zext <4 x i16> %235 to <4 x i32>
  %237 = sub nsw <4 x i32> %234, %236
  %238 = sub nsw <4 x i32> zeroinitializer, %237
  %239 = icmp slt <4 x i32> %237, zeroinitializer
  %240 = select <4 x i1> %239, <4 x i32> %238, <4 x i32> %237
  %241 = add nuw nsw <4 x i32> %240, <i32 32, i32 32, i32 32, i32 32>
  %242 = lshr <4 x i32> %241, <i32 6, i32 6, i32 6, i32 6>
  %243 = shufflevector <8 x i16> %229, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %244 = shufflevector <8 x i16> %232, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %245 = bitcast <8 x i16> %243 to <4 x i32>
  %246 = bitcast <8 x i16> %244 to <4 x i32>
  %247 = sub <4 x i32> %245, %246
  %248 = sub <4 x i32> zeroinitializer, %247
  %249 = icmp slt <4 x i32> %247, zeroinitializer
  %250 = select <4 x i1> %249, <4 x i32> %248, <4 x i32> %247
  %251 = add nuw <4 x i32> %250, <i32 32, i32 32, i32 32, i32 32>
  %252 = lshr <4 x i32> %251, <i32 6, i32 6, i32 6, i32 6>
  %253 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %242, <4 x i32> %252) #5
  %254 = lshr <8 x i16> %253, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %255 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %226, <8 x i16> %254) #5
  %256 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %255, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %257 = icmp slt <16 x i8> %256, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %258 = select <16 x i1> %257, <16 x i8> %256, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %259 = bitcast i8* %197 to <16 x i8>*
  store <16 x i8> %258, <16 x i8>* %259, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask16x64_10bpp_SSE4ILb1EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %200, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %198, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %199, %7 ]
  %11 = phi i32 [ 21, %4 ], [ %201, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = shufflevector <8 x i16> %13, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %17 = zext <4 x i16> %16 to <4 x i32>
  %18 = shufflevector <8 x i16> %15, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %19 = zext <4 x i16> %18 to <4 x i32>
  %20 = sub nsw <4 x i32> %17, %19
  %21 = sub nsw <4 x i32> zeroinitializer, %20
  %22 = icmp slt <4 x i32> %20, zeroinitializer
  %23 = select <4 x i1> %22, <4 x i32> %21, <4 x i32> %20
  %24 = add nuw nsw <4 x i32> %23, <i32 32, i32 32, i32 32, i32 32>
  %25 = lshr <4 x i32> %24, <i32 6, i32 6, i32 6, i32 6>
  %26 = shufflevector <8 x i16> %13, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %27 = shufflevector <8 x i16> %15, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %28 = bitcast <8 x i16> %26 to <4 x i32>
  %29 = bitcast <8 x i16> %27 to <4 x i32>
  %30 = sub <4 x i32> %28, %29
  %31 = sub <4 x i32> zeroinitializer, %30
  %32 = icmp slt <4 x i32> %30, zeroinitializer
  %33 = select <4 x i1> %32, <4 x i32> %31, <4 x i32> %30
  %34 = add nuw <4 x i32> %33, <i32 32, i32 32, i32 32, i32 32>
  %35 = lshr <4 x i32> %34, <i32 6, i32 6, i32 6, i32 6>
  %36 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %25, <4 x i32> %35) #5
  %37 = lshr <8 x i16> %36, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %38 = getelementptr inbounds i16, i16* %9, i64 8
  %39 = bitcast i16* %38 to <8 x i16>*
  %40 = load <8 x i16>, <8 x i16>* %39, align 16
  %41 = getelementptr inbounds i16, i16* %10, i64 8
  %42 = bitcast i16* %41 to <8 x i16>*
  %43 = load <8 x i16>, <8 x i16>* %42, align 16
  %44 = shufflevector <8 x i16> %40, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %45 = zext <4 x i16> %44 to <4 x i32>
  %46 = shufflevector <8 x i16> %43, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %47 = zext <4 x i16> %46 to <4 x i32>
  %48 = sub nsw <4 x i32> %45, %47
  %49 = sub nsw <4 x i32> zeroinitializer, %48
  %50 = icmp slt <4 x i32> %48, zeroinitializer
  %51 = select <4 x i1> %50, <4 x i32> %49, <4 x i32> %48
  %52 = add nuw nsw <4 x i32> %51, <i32 32, i32 32, i32 32, i32 32>
  %53 = lshr <4 x i32> %52, <i32 6, i32 6, i32 6, i32 6>
  %54 = shufflevector <8 x i16> %40, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %55 = shufflevector <8 x i16> %43, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %56 = bitcast <8 x i16> %54 to <4 x i32>
  %57 = bitcast <8 x i16> %55 to <4 x i32>
  %58 = sub <4 x i32> %56, %57
  %59 = sub <4 x i32> zeroinitializer, %58
  %60 = icmp slt <4 x i32> %58, zeroinitializer
  %61 = select <4 x i1> %60, <4 x i32> %59, <4 x i32> %58
  %62 = add nuw <4 x i32> %61, <i32 32, i32 32, i32 32, i32 32>
  %63 = lshr <4 x i32> %62, <i32 6, i32 6, i32 6, i32 6>
  %64 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %53, <4 x i32> %63) #5
  %65 = lshr <8 x i16> %64, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %66 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %37, <8 x i16> %65) #5
  %67 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %66, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %68 = icmp slt <16 x i8> %67, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %69 = select <16 x i1> %68, <16 x i8> %67, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %70 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %69
  %71 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %70, <16 x i8>* %71, align 16
  %72 = getelementptr inbounds i16, i16* %9, i64 16
  %73 = getelementptr inbounds i16, i16* %10, i64 16
  %74 = getelementptr inbounds i8, i8* %8, i64 %3
  %75 = bitcast i16* %72 to <8 x i16>*
  %76 = load <8 x i16>, <8 x i16>* %75, align 16
  %77 = bitcast i16* %73 to <8 x i16>*
  %78 = load <8 x i16>, <8 x i16>* %77, align 16
  %79 = shufflevector <8 x i16> %76, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %80 = zext <4 x i16> %79 to <4 x i32>
  %81 = shufflevector <8 x i16> %78, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %82 = zext <4 x i16> %81 to <4 x i32>
  %83 = sub nsw <4 x i32> %80, %82
  %84 = sub nsw <4 x i32> zeroinitializer, %83
  %85 = icmp slt <4 x i32> %83, zeroinitializer
  %86 = select <4 x i1> %85, <4 x i32> %84, <4 x i32> %83
  %87 = add nuw nsw <4 x i32> %86, <i32 32, i32 32, i32 32, i32 32>
  %88 = lshr <4 x i32> %87, <i32 6, i32 6, i32 6, i32 6>
  %89 = shufflevector <8 x i16> %76, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %90 = shufflevector <8 x i16> %78, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %91 = bitcast <8 x i16> %89 to <4 x i32>
  %92 = bitcast <8 x i16> %90 to <4 x i32>
  %93 = sub <4 x i32> %91, %92
  %94 = sub <4 x i32> zeroinitializer, %93
  %95 = icmp slt <4 x i32> %93, zeroinitializer
  %96 = select <4 x i1> %95, <4 x i32> %94, <4 x i32> %93
  %97 = add nuw <4 x i32> %96, <i32 32, i32 32, i32 32, i32 32>
  %98 = lshr <4 x i32> %97, <i32 6, i32 6, i32 6, i32 6>
  %99 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %88, <4 x i32> %98) #5
  %100 = lshr <8 x i16> %99, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %101 = getelementptr inbounds i16, i16* %9, i64 24
  %102 = bitcast i16* %101 to <8 x i16>*
  %103 = load <8 x i16>, <8 x i16>* %102, align 16
  %104 = getelementptr inbounds i16, i16* %10, i64 24
  %105 = bitcast i16* %104 to <8 x i16>*
  %106 = load <8 x i16>, <8 x i16>* %105, align 16
  %107 = shufflevector <8 x i16> %103, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %108 = zext <4 x i16> %107 to <4 x i32>
  %109 = shufflevector <8 x i16> %106, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %110 = zext <4 x i16> %109 to <4 x i32>
  %111 = sub nsw <4 x i32> %108, %110
  %112 = sub nsw <4 x i32> zeroinitializer, %111
  %113 = icmp slt <4 x i32> %111, zeroinitializer
  %114 = select <4 x i1> %113, <4 x i32> %112, <4 x i32> %111
  %115 = add nuw nsw <4 x i32> %114, <i32 32, i32 32, i32 32, i32 32>
  %116 = lshr <4 x i32> %115, <i32 6, i32 6, i32 6, i32 6>
  %117 = shufflevector <8 x i16> %103, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %118 = shufflevector <8 x i16> %106, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %119 = bitcast <8 x i16> %117 to <4 x i32>
  %120 = bitcast <8 x i16> %118 to <4 x i32>
  %121 = sub <4 x i32> %119, %120
  %122 = sub <4 x i32> zeroinitializer, %121
  %123 = icmp slt <4 x i32> %121, zeroinitializer
  %124 = select <4 x i1> %123, <4 x i32> %122, <4 x i32> %121
  %125 = add nuw <4 x i32> %124, <i32 32, i32 32, i32 32, i32 32>
  %126 = lshr <4 x i32> %125, <i32 6, i32 6, i32 6, i32 6>
  %127 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %116, <4 x i32> %126) #5
  %128 = lshr <8 x i16> %127, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %129 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %100, <8 x i16> %128) #5
  %130 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %129, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %131 = icmp slt <16 x i8> %130, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %132 = select <16 x i1> %131, <16 x i8> %130, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %133 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %132
  %134 = bitcast i8* %74 to <16 x i8>*
  store <16 x i8> %133, <16 x i8>* %134, align 16
  %135 = getelementptr inbounds i16, i16* %9, i64 32
  %136 = getelementptr inbounds i16, i16* %10, i64 32
  %137 = getelementptr inbounds i8, i8* %74, i64 %3
  %138 = bitcast i16* %135 to <8 x i16>*
  %139 = load <8 x i16>, <8 x i16>* %138, align 16
  %140 = bitcast i16* %136 to <8 x i16>*
  %141 = load <8 x i16>, <8 x i16>* %140, align 16
  %142 = shufflevector <8 x i16> %139, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %143 = zext <4 x i16> %142 to <4 x i32>
  %144 = shufflevector <8 x i16> %141, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %145 = zext <4 x i16> %144 to <4 x i32>
  %146 = sub nsw <4 x i32> %143, %145
  %147 = sub nsw <4 x i32> zeroinitializer, %146
  %148 = icmp slt <4 x i32> %146, zeroinitializer
  %149 = select <4 x i1> %148, <4 x i32> %147, <4 x i32> %146
  %150 = add nuw nsw <4 x i32> %149, <i32 32, i32 32, i32 32, i32 32>
  %151 = lshr <4 x i32> %150, <i32 6, i32 6, i32 6, i32 6>
  %152 = shufflevector <8 x i16> %139, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %153 = shufflevector <8 x i16> %141, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %154 = bitcast <8 x i16> %152 to <4 x i32>
  %155 = bitcast <8 x i16> %153 to <4 x i32>
  %156 = sub <4 x i32> %154, %155
  %157 = sub <4 x i32> zeroinitializer, %156
  %158 = icmp slt <4 x i32> %156, zeroinitializer
  %159 = select <4 x i1> %158, <4 x i32> %157, <4 x i32> %156
  %160 = add nuw <4 x i32> %159, <i32 32, i32 32, i32 32, i32 32>
  %161 = lshr <4 x i32> %160, <i32 6, i32 6, i32 6, i32 6>
  %162 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %151, <4 x i32> %161) #5
  %163 = lshr <8 x i16> %162, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %164 = getelementptr inbounds i16, i16* %9, i64 40
  %165 = bitcast i16* %164 to <8 x i16>*
  %166 = load <8 x i16>, <8 x i16>* %165, align 16
  %167 = getelementptr inbounds i16, i16* %10, i64 40
  %168 = bitcast i16* %167 to <8 x i16>*
  %169 = load <8 x i16>, <8 x i16>* %168, align 16
  %170 = shufflevector <8 x i16> %166, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %171 = zext <4 x i16> %170 to <4 x i32>
  %172 = shufflevector <8 x i16> %169, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %173 = zext <4 x i16> %172 to <4 x i32>
  %174 = sub nsw <4 x i32> %171, %173
  %175 = sub nsw <4 x i32> zeroinitializer, %174
  %176 = icmp slt <4 x i32> %174, zeroinitializer
  %177 = select <4 x i1> %176, <4 x i32> %175, <4 x i32> %174
  %178 = add nuw nsw <4 x i32> %177, <i32 32, i32 32, i32 32, i32 32>
  %179 = lshr <4 x i32> %178, <i32 6, i32 6, i32 6, i32 6>
  %180 = shufflevector <8 x i16> %166, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %181 = shufflevector <8 x i16> %169, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %182 = bitcast <8 x i16> %180 to <4 x i32>
  %183 = bitcast <8 x i16> %181 to <4 x i32>
  %184 = sub <4 x i32> %182, %183
  %185 = sub <4 x i32> zeroinitializer, %184
  %186 = icmp slt <4 x i32> %184, zeroinitializer
  %187 = select <4 x i1> %186, <4 x i32> %185, <4 x i32> %184
  %188 = add nuw <4 x i32> %187, <i32 32, i32 32, i32 32, i32 32>
  %189 = lshr <4 x i32> %188, <i32 6, i32 6, i32 6, i32 6>
  %190 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %179, <4 x i32> %189) #5
  %191 = lshr <8 x i16> %190, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %192 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %163, <8 x i16> %191) #5
  %193 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %192, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %194 = icmp slt <16 x i8> %193, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %195 = select <16 x i1> %194, <16 x i8> %193, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %196 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %195
  %197 = bitcast i8* %137 to <16 x i8>*
  store <16 x i8> %196, <16 x i8>* %197, align 16
  %198 = getelementptr inbounds i16, i16* %9, i64 48
  %199 = getelementptr inbounds i16, i16* %10, i64 48
  %200 = getelementptr inbounds i8, i8* %137, i64 %3
  %201 = add nsw i32 %11, -1
  %202 = icmp eq i32 %201, 0
  br i1 %202, label %203, label %7

203:                                              ; preds = %7
  %204 = bitcast i16* %198 to <8 x i16>*
  %205 = load <8 x i16>, <8 x i16>* %204, align 16
  %206 = bitcast i16* %199 to <8 x i16>*
  %207 = load <8 x i16>, <8 x i16>* %206, align 16
  %208 = shufflevector <8 x i16> %205, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %209 = zext <4 x i16> %208 to <4 x i32>
  %210 = shufflevector <8 x i16> %207, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %211 = zext <4 x i16> %210 to <4 x i32>
  %212 = sub nsw <4 x i32> %209, %211
  %213 = sub nsw <4 x i32> zeroinitializer, %212
  %214 = icmp slt <4 x i32> %212, zeroinitializer
  %215 = select <4 x i1> %214, <4 x i32> %213, <4 x i32> %212
  %216 = add nuw nsw <4 x i32> %215, <i32 32, i32 32, i32 32, i32 32>
  %217 = lshr <4 x i32> %216, <i32 6, i32 6, i32 6, i32 6>
  %218 = shufflevector <8 x i16> %205, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %219 = shufflevector <8 x i16> %207, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %220 = bitcast <8 x i16> %218 to <4 x i32>
  %221 = bitcast <8 x i16> %219 to <4 x i32>
  %222 = sub <4 x i32> %220, %221
  %223 = sub <4 x i32> zeroinitializer, %222
  %224 = icmp slt <4 x i32> %222, zeroinitializer
  %225 = select <4 x i1> %224, <4 x i32> %223, <4 x i32> %222
  %226 = add nuw <4 x i32> %225, <i32 32, i32 32, i32 32, i32 32>
  %227 = lshr <4 x i32> %226, <i32 6, i32 6, i32 6, i32 6>
  %228 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %217, <4 x i32> %227) #5
  %229 = lshr <8 x i16> %228, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %230 = getelementptr inbounds i16, i16* %9, i64 56
  %231 = bitcast i16* %230 to <8 x i16>*
  %232 = load <8 x i16>, <8 x i16>* %231, align 16
  %233 = getelementptr inbounds i16, i16* %10, i64 56
  %234 = bitcast i16* %233 to <8 x i16>*
  %235 = load <8 x i16>, <8 x i16>* %234, align 16
  %236 = shufflevector <8 x i16> %232, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %237 = zext <4 x i16> %236 to <4 x i32>
  %238 = shufflevector <8 x i16> %235, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %239 = zext <4 x i16> %238 to <4 x i32>
  %240 = sub nsw <4 x i32> %237, %239
  %241 = sub nsw <4 x i32> zeroinitializer, %240
  %242 = icmp slt <4 x i32> %240, zeroinitializer
  %243 = select <4 x i1> %242, <4 x i32> %241, <4 x i32> %240
  %244 = add nuw nsw <4 x i32> %243, <i32 32, i32 32, i32 32, i32 32>
  %245 = lshr <4 x i32> %244, <i32 6, i32 6, i32 6, i32 6>
  %246 = shufflevector <8 x i16> %232, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %247 = shufflevector <8 x i16> %235, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %248 = bitcast <8 x i16> %246 to <4 x i32>
  %249 = bitcast <8 x i16> %247 to <4 x i32>
  %250 = sub <4 x i32> %248, %249
  %251 = sub <4 x i32> zeroinitializer, %250
  %252 = icmp slt <4 x i32> %250, zeroinitializer
  %253 = select <4 x i1> %252, <4 x i32> %251, <4 x i32> %250
  %254 = add nuw <4 x i32> %253, <i32 32, i32 32, i32 32, i32 32>
  %255 = lshr <4 x i32> %254, <i32 6, i32 6, i32 6, i32 6>
  %256 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %245, <4 x i32> %255) #5
  %257 = lshr <8 x i16> %256, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %258 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %229, <8 x i16> %257) #5
  %259 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %258, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %260 = icmp slt <16 x i8> %259, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %261 = select <16 x i1> %260, <16 x i8> %259, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %262 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %261
  %263 = bitcast i8* %200 to <16 x i8>*
  store <16 x i8> %262, <16 x i8>* %263, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_125WeightMask32x8_10bpp_SSE4ILb0EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to <8 x i16>*
  %6 = load <8 x i16>, <8 x i16>* %5, align 16
  %7 = bitcast i8* %1 to <8 x i16>*
  %8 = load <8 x i16>, <8 x i16>* %7, align 16
  %9 = shufflevector <8 x i16> %6, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %10 = zext <4 x i16> %9 to <4 x i32>
  %11 = shufflevector <8 x i16> %8, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %12 = zext <4 x i16> %11 to <4 x i32>
  %13 = sub nsw <4 x i32> %10, %12
  %14 = sub nsw <4 x i32> zeroinitializer, %13
  %15 = icmp slt <4 x i32> %13, zeroinitializer
  %16 = select <4 x i1> %15, <4 x i32> %14, <4 x i32> %13
  %17 = add nuw nsw <4 x i32> %16, <i32 32, i32 32, i32 32, i32 32>
  %18 = lshr <4 x i32> %17, <i32 6, i32 6, i32 6, i32 6>
  %19 = shufflevector <8 x i16> %6, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %20 = shufflevector <8 x i16> %8, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %21 = bitcast <8 x i16> %19 to <4 x i32>
  %22 = bitcast <8 x i16> %20 to <4 x i32>
  %23 = sub <4 x i32> %21, %22
  %24 = sub <4 x i32> zeroinitializer, %23
  %25 = icmp slt <4 x i32> %23, zeroinitializer
  %26 = select <4 x i1> %25, <4 x i32> %24, <4 x i32> %23
  %27 = add nuw <4 x i32> %26, <i32 32, i32 32, i32 32, i32 32>
  %28 = lshr <4 x i32> %27, <i32 6, i32 6, i32 6, i32 6>
  %29 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %18, <4 x i32> %28) #5
  %30 = lshr <8 x i16> %29, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %31 = getelementptr inbounds i8, i8* %0, i64 16
  %32 = bitcast i8* %31 to <8 x i16>*
  %33 = load <8 x i16>, <8 x i16>* %32, align 16
  %34 = getelementptr inbounds i8, i8* %1, i64 16
  %35 = bitcast i8* %34 to <8 x i16>*
  %36 = load <8 x i16>, <8 x i16>* %35, align 16
  %37 = shufflevector <8 x i16> %33, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %38 = zext <4 x i16> %37 to <4 x i32>
  %39 = shufflevector <8 x i16> %36, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %40 = zext <4 x i16> %39 to <4 x i32>
  %41 = sub nsw <4 x i32> %38, %40
  %42 = sub nsw <4 x i32> zeroinitializer, %41
  %43 = icmp slt <4 x i32> %41, zeroinitializer
  %44 = select <4 x i1> %43, <4 x i32> %42, <4 x i32> %41
  %45 = add nuw nsw <4 x i32> %44, <i32 32, i32 32, i32 32, i32 32>
  %46 = lshr <4 x i32> %45, <i32 6, i32 6, i32 6, i32 6>
  %47 = shufflevector <8 x i16> %33, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %48 = shufflevector <8 x i16> %36, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %49 = bitcast <8 x i16> %47 to <4 x i32>
  %50 = bitcast <8 x i16> %48 to <4 x i32>
  %51 = sub <4 x i32> %49, %50
  %52 = sub <4 x i32> zeroinitializer, %51
  %53 = icmp slt <4 x i32> %51, zeroinitializer
  %54 = select <4 x i1> %53, <4 x i32> %52, <4 x i32> %51
  %55 = add nuw <4 x i32> %54, <i32 32, i32 32, i32 32, i32 32>
  %56 = lshr <4 x i32> %55, <i32 6, i32 6, i32 6, i32 6>
  %57 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %46, <4 x i32> %56) #5
  %58 = lshr <8 x i16> %57, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %59 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %30, <8 x i16> %58) #5
  %60 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %59, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %61 = icmp slt <16 x i8> %60, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %62 = select <16 x i1> %61, <16 x i8> %60, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %63 = bitcast i8* %2 to <16 x i8>*
  store <16 x i8> %62, <16 x i8>* %63, align 16
  %64 = getelementptr inbounds i8, i8* %0, i64 32
  %65 = getelementptr inbounds i8, i8* %1, i64 32
  %66 = getelementptr inbounds i8, i8* %2, i64 16
  %67 = bitcast i8* %64 to <8 x i16>*
  %68 = load <8 x i16>, <8 x i16>* %67, align 16
  %69 = bitcast i8* %65 to <8 x i16>*
  %70 = load <8 x i16>, <8 x i16>* %69, align 16
  %71 = shufflevector <8 x i16> %68, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %72 = zext <4 x i16> %71 to <4 x i32>
  %73 = shufflevector <8 x i16> %70, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %74 = zext <4 x i16> %73 to <4 x i32>
  %75 = sub nsw <4 x i32> %72, %74
  %76 = sub nsw <4 x i32> zeroinitializer, %75
  %77 = icmp slt <4 x i32> %75, zeroinitializer
  %78 = select <4 x i1> %77, <4 x i32> %76, <4 x i32> %75
  %79 = add nuw nsw <4 x i32> %78, <i32 32, i32 32, i32 32, i32 32>
  %80 = lshr <4 x i32> %79, <i32 6, i32 6, i32 6, i32 6>
  %81 = shufflevector <8 x i16> %68, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %82 = shufflevector <8 x i16> %70, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %83 = bitcast <8 x i16> %81 to <4 x i32>
  %84 = bitcast <8 x i16> %82 to <4 x i32>
  %85 = sub <4 x i32> %83, %84
  %86 = sub <4 x i32> zeroinitializer, %85
  %87 = icmp slt <4 x i32> %85, zeroinitializer
  %88 = select <4 x i1> %87, <4 x i32> %86, <4 x i32> %85
  %89 = add nuw <4 x i32> %88, <i32 32, i32 32, i32 32, i32 32>
  %90 = lshr <4 x i32> %89, <i32 6, i32 6, i32 6, i32 6>
  %91 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %80, <4 x i32> %90) #5
  %92 = lshr <8 x i16> %91, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %93 = getelementptr inbounds i8, i8* %0, i64 48
  %94 = bitcast i8* %93 to <8 x i16>*
  %95 = load <8 x i16>, <8 x i16>* %94, align 16
  %96 = getelementptr inbounds i8, i8* %1, i64 48
  %97 = bitcast i8* %96 to <8 x i16>*
  %98 = load <8 x i16>, <8 x i16>* %97, align 16
  %99 = shufflevector <8 x i16> %95, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %100 = zext <4 x i16> %99 to <4 x i32>
  %101 = shufflevector <8 x i16> %98, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %102 = zext <4 x i16> %101 to <4 x i32>
  %103 = sub nsw <4 x i32> %100, %102
  %104 = sub nsw <4 x i32> zeroinitializer, %103
  %105 = icmp slt <4 x i32> %103, zeroinitializer
  %106 = select <4 x i1> %105, <4 x i32> %104, <4 x i32> %103
  %107 = add nuw nsw <4 x i32> %106, <i32 32, i32 32, i32 32, i32 32>
  %108 = lshr <4 x i32> %107, <i32 6, i32 6, i32 6, i32 6>
  %109 = shufflevector <8 x i16> %95, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %110 = shufflevector <8 x i16> %98, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %111 = bitcast <8 x i16> %109 to <4 x i32>
  %112 = bitcast <8 x i16> %110 to <4 x i32>
  %113 = sub <4 x i32> %111, %112
  %114 = sub <4 x i32> zeroinitializer, %113
  %115 = icmp slt <4 x i32> %113, zeroinitializer
  %116 = select <4 x i1> %115, <4 x i32> %114, <4 x i32> %113
  %117 = add nuw <4 x i32> %116, <i32 32, i32 32, i32 32, i32 32>
  %118 = lshr <4 x i32> %117, <i32 6, i32 6, i32 6, i32 6>
  %119 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %108, <4 x i32> %118) #5
  %120 = lshr <8 x i16> %119, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %121 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %92, <8 x i16> %120) #5
  %122 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %121, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %123 = icmp slt <16 x i8> %122, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %124 = select <16 x i1> %123, <16 x i8> %122, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %125 = bitcast i8* %66 to <16 x i8>*
  store <16 x i8> %124, <16 x i8>* %125, align 16
  %126 = getelementptr inbounds i8, i8* %0, i64 64
  %127 = getelementptr inbounds i8, i8* %1, i64 64
  %128 = getelementptr inbounds i8, i8* %2, i64 %3
  %129 = bitcast i8* %126 to <8 x i16>*
  %130 = load <8 x i16>, <8 x i16>* %129, align 16
  %131 = bitcast i8* %127 to <8 x i16>*
  %132 = load <8 x i16>, <8 x i16>* %131, align 16
  %133 = shufflevector <8 x i16> %130, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %134 = zext <4 x i16> %133 to <4 x i32>
  %135 = shufflevector <8 x i16> %132, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %136 = zext <4 x i16> %135 to <4 x i32>
  %137 = sub nsw <4 x i32> %134, %136
  %138 = sub nsw <4 x i32> zeroinitializer, %137
  %139 = icmp slt <4 x i32> %137, zeroinitializer
  %140 = select <4 x i1> %139, <4 x i32> %138, <4 x i32> %137
  %141 = add nuw nsw <4 x i32> %140, <i32 32, i32 32, i32 32, i32 32>
  %142 = lshr <4 x i32> %141, <i32 6, i32 6, i32 6, i32 6>
  %143 = shufflevector <8 x i16> %130, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %144 = shufflevector <8 x i16> %132, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %145 = bitcast <8 x i16> %143 to <4 x i32>
  %146 = bitcast <8 x i16> %144 to <4 x i32>
  %147 = sub <4 x i32> %145, %146
  %148 = sub <4 x i32> zeroinitializer, %147
  %149 = icmp slt <4 x i32> %147, zeroinitializer
  %150 = select <4 x i1> %149, <4 x i32> %148, <4 x i32> %147
  %151 = add nuw <4 x i32> %150, <i32 32, i32 32, i32 32, i32 32>
  %152 = lshr <4 x i32> %151, <i32 6, i32 6, i32 6, i32 6>
  %153 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %142, <4 x i32> %152) #5
  %154 = lshr <8 x i16> %153, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %155 = getelementptr inbounds i8, i8* %0, i64 80
  %156 = bitcast i8* %155 to <8 x i16>*
  %157 = load <8 x i16>, <8 x i16>* %156, align 16
  %158 = getelementptr inbounds i8, i8* %1, i64 80
  %159 = bitcast i8* %158 to <8 x i16>*
  %160 = load <8 x i16>, <8 x i16>* %159, align 16
  %161 = shufflevector <8 x i16> %157, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %162 = zext <4 x i16> %161 to <4 x i32>
  %163 = shufflevector <8 x i16> %160, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %164 = zext <4 x i16> %163 to <4 x i32>
  %165 = sub nsw <4 x i32> %162, %164
  %166 = sub nsw <4 x i32> zeroinitializer, %165
  %167 = icmp slt <4 x i32> %165, zeroinitializer
  %168 = select <4 x i1> %167, <4 x i32> %166, <4 x i32> %165
  %169 = add nuw nsw <4 x i32> %168, <i32 32, i32 32, i32 32, i32 32>
  %170 = lshr <4 x i32> %169, <i32 6, i32 6, i32 6, i32 6>
  %171 = shufflevector <8 x i16> %157, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %172 = shufflevector <8 x i16> %160, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %173 = bitcast <8 x i16> %171 to <4 x i32>
  %174 = bitcast <8 x i16> %172 to <4 x i32>
  %175 = sub <4 x i32> %173, %174
  %176 = sub <4 x i32> zeroinitializer, %175
  %177 = icmp slt <4 x i32> %175, zeroinitializer
  %178 = select <4 x i1> %177, <4 x i32> %176, <4 x i32> %175
  %179 = add nuw <4 x i32> %178, <i32 32, i32 32, i32 32, i32 32>
  %180 = lshr <4 x i32> %179, <i32 6, i32 6, i32 6, i32 6>
  %181 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %170, <4 x i32> %180) #5
  %182 = lshr <8 x i16> %181, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %183 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %154, <8 x i16> %182) #5
  %184 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %183, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %185 = icmp slt <16 x i8> %184, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %186 = select <16 x i1> %185, <16 x i8> %184, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %187 = bitcast i8* %128 to <16 x i8>*
  store <16 x i8> %186, <16 x i8>* %187, align 16
  %188 = getelementptr inbounds i8, i8* %0, i64 96
  %189 = getelementptr inbounds i8, i8* %1, i64 96
  %190 = getelementptr inbounds i8, i8* %128, i64 16
  %191 = bitcast i8* %188 to <8 x i16>*
  %192 = load <8 x i16>, <8 x i16>* %191, align 16
  %193 = bitcast i8* %189 to <8 x i16>*
  %194 = load <8 x i16>, <8 x i16>* %193, align 16
  %195 = shufflevector <8 x i16> %192, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %196 = zext <4 x i16> %195 to <4 x i32>
  %197 = shufflevector <8 x i16> %194, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %198 = zext <4 x i16> %197 to <4 x i32>
  %199 = sub nsw <4 x i32> %196, %198
  %200 = sub nsw <4 x i32> zeroinitializer, %199
  %201 = icmp slt <4 x i32> %199, zeroinitializer
  %202 = select <4 x i1> %201, <4 x i32> %200, <4 x i32> %199
  %203 = add nuw nsw <4 x i32> %202, <i32 32, i32 32, i32 32, i32 32>
  %204 = lshr <4 x i32> %203, <i32 6, i32 6, i32 6, i32 6>
  %205 = shufflevector <8 x i16> %192, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %206 = shufflevector <8 x i16> %194, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %207 = bitcast <8 x i16> %205 to <4 x i32>
  %208 = bitcast <8 x i16> %206 to <4 x i32>
  %209 = sub <4 x i32> %207, %208
  %210 = sub <4 x i32> zeroinitializer, %209
  %211 = icmp slt <4 x i32> %209, zeroinitializer
  %212 = select <4 x i1> %211, <4 x i32> %210, <4 x i32> %209
  %213 = add nuw <4 x i32> %212, <i32 32, i32 32, i32 32, i32 32>
  %214 = lshr <4 x i32> %213, <i32 6, i32 6, i32 6, i32 6>
  %215 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %204, <4 x i32> %214) #5
  %216 = lshr <8 x i16> %215, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %217 = getelementptr inbounds i8, i8* %0, i64 112
  %218 = bitcast i8* %217 to <8 x i16>*
  %219 = load <8 x i16>, <8 x i16>* %218, align 16
  %220 = getelementptr inbounds i8, i8* %1, i64 112
  %221 = bitcast i8* %220 to <8 x i16>*
  %222 = load <8 x i16>, <8 x i16>* %221, align 16
  %223 = shufflevector <8 x i16> %219, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %224 = zext <4 x i16> %223 to <4 x i32>
  %225 = shufflevector <8 x i16> %222, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %226 = zext <4 x i16> %225 to <4 x i32>
  %227 = sub nsw <4 x i32> %224, %226
  %228 = sub nsw <4 x i32> zeroinitializer, %227
  %229 = icmp slt <4 x i32> %227, zeroinitializer
  %230 = select <4 x i1> %229, <4 x i32> %228, <4 x i32> %227
  %231 = add nuw nsw <4 x i32> %230, <i32 32, i32 32, i32 32, i32 32>
  %232 = lshr <4 x i32> %231, <i32 6, i32 6, i32 6, i32 6>
  %233 = shufflevector <8 x i16> %219, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %234 = shufflevector <8 x i16> %222, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %235 = bitcast <8 x i16> %233 to <4 x i32>
  %236 = bitcast <8 x i16> %234 to <4 x i32>
  %237 = sub <4 x i32> %235, %236
  %238 = sub <4 x i32> zeroinitializer, %237
  %239 = icmp slt <4 x i32> %237, zeroinitializer
  %240 = select <4 x i1> %239, <4 x i32> %238, <4 x i32> %237
  %241 = add nuw <4 x i32> %240, <i32 32, i32 32, i32 32, i32 32>
  %242 = lshr <4 x i32> %241, <i32 6, i32 6, i32 6, i32 6>
  %243 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %232, <4 x i32> %242) #5
  %244 = lshr <8 x i16> %243, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %245 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %216, <8 x i16> %244) #5
  %246 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %245, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %247 = icmp slt <16 x i8> %246, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %248 = select <16 x i1> %247, <16 x i8> %246, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %249 = bitcast i8* %190 to <16 x i8>*
  store <16 x i8> %248, <16 x i8>* %249, align 16
  %250 = getelementptr inbounds i8, i8* %0, i64 128
  %251 = getelementptr inbounds i8, i8* %1, i64 128
  %252 = getelementptr inbounds i8, i8* %128, i64 %3
  %253 = bitcast i8* %250 to <8 x i16>*
  %254 = load <8 x i16>, <8 x i16>* %253, align 16
  %255 = bitcast i8* %251 to <8 x i16>*
  %256 = load <8 x i16>, <8 x i16>* %255, align 16
  %257 = shufflevector <8 x i16> %254, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %258 = zext <4 x i16> %257 to <4 x i32>
  %259 = shufflevector <8 x i16> %256, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %260 = zext <4 x i16> %259 to <4 x i32>
  %261 = sub nsw <4 x i32> %258, %260
  %262 = sub nsw <4 x i32> zeroinitializer, %261
  %263 = icmp slt <4 x i32> %261, zeroinitializer
  %264 = select <4 x i1> %263, <4 x i32> %262, <4 x i32> %261
  %265 = add nuw nsw <4 x i32> %264, <i32 32, i32 32, i32 32, i32 32>
  %266 = lshr <4 x i32> %265, <i32 6, i32 6, i32 6, i32 6>
  %267 = shufflevector <8 x i16> %254, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %268 = shufflevector <8 x i16> %256, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %269 = bitcast <8 x i16> %267 to <4 x i32>
  %270 = bitcast <8 x i16> %268 to <4 x i32>
  %271 = sub <4 x i32> %269, %270
  %272 = sub <4 x i32> zeroinitializer, %271
  %273 = icmp slt <4 x i32> %271, zeroinitializer
  %274 = select <4 x i1> %273, <4 x i32> %272, <4 x i32> %271
  %275 = add nuw <4 x i32> %274, <i32 32, i32 32, i32 32, i32 32>
  %276 = lshr <4 x i32> %275, <i32 6, i32 6, i32 6, i32 6>
  %277 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %266, <4 x i32> %276) #5
  %278 = lshr <8 x i16> %277, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %279 = getelementptr inbounds i8, i8* %0, i64 144
  %280 = bitcast i8* %279 to <8 x i16>*
  %281 = load <8 x i16>, <8 x i16>* %280, align 16
  %282 = getelementptr inbounds i8, i8* %1, i64 144
  %283 = bitcast i8* %282 to <8 x i16>*
  %284 = load <8 x i16>, <8 x i16>* %283, align 16
  %285 = shufflevector <8 x i16> %281, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %286 = zext <4 x i16> %285 to <4 x i32>
  %287 = shufflevector <8 x i16> %284, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %288 = zext <4 x i16> %287 to <4 x i32>
  %289 = sub nsw <4 x i32> %286, %288
  %290 = sub nsw <4 x i32> zeroinitializer, %289
  %291 = icmp slt <4 x i32> %289, zeroinitializer
  %292 = select <4 x i1> %291, <4 x i32> %290, <4 x i32> %289
  %293 = add nuw nsw <4 x i32> %292, <i32 32, i32 32, i32 32, i32 32>
  %294 = lshr <4 x i32> %293, <i32 6, i32 6, i32 6, i32 6>
  %295 = shufflevector <8 x i16> %281, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %296 = shufflevector <8 x i16> %284, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %297 = bitcast <8 x i16> %295 to <4 x i32>
  %298 = bitcast <8 x i16> %296 to <4 x i32>
  %299 = sub <4 x i32> %297, %298
  %300 = sub <4 x i32> zeroinitializer, %299
  %301 = icmp slt <4 x i32> %299, zeroinitializer
  %302 = select <4 x i1> %301, <4 x i32> %300, <4 x i32> %299
  %303 = add nuw <4 x i32> %302, <i32 32, i32 32, i32 32, i32 32>
  %304 = lshr <4 x i32> %303, <i32 6, i32 6, i32 6, i32 6>
  %305 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %294, <4 x i32> %304) #5
  %306 = lshr <8 x i16> %305, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %307 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %278, <8 x i16> %306) #5
  %308 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %307, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %309 = icmp slt <16 x i8> %308, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %310 = select <16 x i1> %309, <16 x i8> %308, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %311 = bitcast i8* %252 to <16 x i8>*
  store <16 x i8> %310, <16 x i8>* %311, align 16
  %312 = getelementptr inbounds i8, i8* %0, i64 160
  %313 = getelementptr inbounds i8, i8* %1, i64 160
  %314 = getelementptr inbounds i8, i8* %252, i64 16
  %315 = bitcast i8* %312 to <8 x i16>*
  %316 = load <8 x i16>, <8 x i16>* %315, align 16
  %317 = bitcast i8* %313 to <8 x i16>*
  %318 = load <8 x i16>, <8 x i16>* %317, align 16
  %319 = shufflevector <8 x i16> %316, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %320 = zext <4 x i16> %319 to <4 x i32>
  %321 = shufflevector <8 x i16> %318, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %322 = zext <4 x i16> %321 to <4 x i32>
  %323 = sub nsw <4 x i32> %320, %322
  %324 = sub nsw <4 x i32> zeroinitializer, %323
  %325 = icmp slt <4 x i32> %323, zeroinitializer
  %326 = select <4 x i1> %325, <4 x i32> %324, <4 x i32> %323
  %327 = add nuw nsw <4 x i32> %326, <i32 32, i32 32, i32 32, i32 32>
  %328 = lshr <4 x i32> %327, <i32 6, i32 6, i32 6, i32 6>
  %329 = shufflevector <8 x i16> %316, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %330 = shufflevector <8 x i16> %318, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %331 = bitcast <8 x i16> %329 to <4 x i32>
  %332 = bitcast <8 x i16> %330 to <4 x i32>
  %333 = sub <4 x i32> %331, %332
  %334 = sub <4 x i32> zeroinitializer, %333
  %335 = icmp slt <4 x i32> %333, zeroinitializer
  %336 = select <4 x i1> %335, <4 x i32> %334, <4 x i32> %333
  %337 = add nuw <4 x i32> %336, <i32 32, i32 32, i32 32, i32 32>
  %338 = lshr <4 x i32> %337, <i32 6, i32 6, i32 6, i32 6>
  %339 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %328, <4 x i32> %338) #5
  %340 = lshr <8 x i16> %339, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %341 = getelementptr inbounds i8, i8* %0, i64 176
  %342 = bitcast i8* %341 to <8 x i16>*
  %343 = load <8 x i16>, <8 x i16>* %342, align 16
  %344 = getelementptr inbounds i8, i8* %1, i64 176
  %345 = bitcast i8* %344 to <8 x i16>*
  %346 = load <8 x i16>, <8 x i16>* %345, align 16
  %347 = shufflevector <8 x i16> %343, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %348 = zext <4 x i16> %347 to <4 x i32>
  %349 = shufflevector <8 x i16> %346, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %350 = zext <4 x i16> %349 to <4 x i32>
  %351 = sub nsw <4 x i32> %348, %350
  %352 = sub nsw <4 x i32> zeroinitializer, %351
  %353 = icmp slt <4 x i32> %351, zeroinitializer
  %354 = select <4 x i1> %353, <4 x i32> %352, <4 x i32> %351
  %355 = add nuw nsw <4 x i32> %354, <i32 32, i32 32, i32 32, i32 32>
  %356 = lshr <4 x i32> %355, <i32 6, i32 6, i32 6, i32 6>
  %357 = shufflevector <8 x i16> %343, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %358 = shufflevector <8 x i16> %346, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %359 = bitcast <8 x i16> %357 to <4 x i32>
  %360 = bitcast <8 x i16> %358 to <4 x i32>
  %361 = sub <4 x i32> %359, %360
  %362 = sub <4 x i32> zeroinitializer, %361
  %363 = icmp slt <4 x i32> %361, zeroinitializer
  %364 = select <4 x i1> %363, <4 x i32> %362, <4 x i32> %361
  %365 = add nuw <4 x i32> %364, <i32 32, i32 32, i32 32, i32 32>
  %366 = lshr <4 x i32> %365, <i32 6, i32 6, i32 6, i32 6>
  %367 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %356, <4 x i32> %366) #5
  %368 = lshr <8 x i16> %367, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %369 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %340, <8 x i16> %368) #5
  %370 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %369, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %371 = icmp slt <16 x i8> %370, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %372 = select <16 x i1> %371, <16 x i8> %370, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %373 = bitcast i8* %314 to <16 x i8>*
  store <16 x i8> %372, <16 x i8>* %373, align 16
  %374 = getelementptr inbounds i8, i8* %0, i64 192
  %375 = getelementptr inbounds i8, i8* %1, i64 192
  %376 = getelementptr inbounds i8, i8* %252, i64 %3
  %377 = bitcast i8* %374 to <8 x i16>*
  %378 = load <8 x i16>, <8 x i16>* %377, align 16
  %379 = bitcast i8* %375 to <8 x i16>*
  %380 = load <8 x i16>, <8 x i16>* %379, align 16
  %381 = shufflevector <8 x i16> %378, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %382 = zext <4 x i16> %381 to <4 x i32>
  %383 = shufflevector <8 x i16> %380, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %384 = zext <4 x i16> %383 to <4 x i32>
  %385 = sub nsw <4 x i32> %382, %384
  %386 = sub nsw <4 x i32> zeroinitializer, %385
  %387 = icmp slt <4 x i32> %385, zeroinitializer
  %388 = select <4 x i1> %387, <4 x i32> %386, <4 x i32> %385
  %389 = add nuw nsw <4 x i32> %388, <i32 32, i32 32, i32 32, i32 32>
  %390 = lshr <4 x i32> %389, <i32 6, i32 6, i32 6, i32 6>
  %391 = shufflevector <8 x i16> %378, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %392 = shufflevector <8 x i16> %380, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %393 = bitcast <8 x i16> %391 to <4 x i32>
  %394 = bitcast <8 x i16> %392 to <4 x i32>
  %395 = sub <4 x i32> %393, %394
  %396 = sub <4 x i32> zeroinitializer, %395
  %397 = icmp slt <4 x i32> %395, zeroinitializer
  %398 = select <4 x i1> %397, <4 x i32> %396, <4 x i32> %395
  %399 = add nuw <4 x i32> %398, <i32 32, i32 32, i32 32, i32 32>
  %400 = lshr <4 x i32> %399, <i32 6, i32 6, i32 6, i32 6>
  %401 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %390, <4 x i32> %400) #5
  %402 = lshr <8 x i16> %401, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %403 = getelementptr inbounds i8, i8* %0, i64 208
  %404 = bitcast i8* %403 to <8 x i16>*
  %405 = load <8 x i16>, <8 x i16>* %404, align 16
  %406 = getelementptr inbounds i8, i8* %1, i64 208
  %407 = bitcast i8* %406 to <8 x i16>*
  %408 = load <8 x i16>, <8 x i16>* %407, align 16
  %409 = shufflevector <8 x i16> %405, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %410 = zext <4 x i16> %409 to <4 x i32>
  %411 = shufflevector <8 x i16> %408, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %412 = zext <4 x i16> %411 to <4 x i32>
  %413 = sub nsw <4 x i32> %410, %412
  %414 = sub nsw <4 x i32> zeroinitializer, %413
  %415 = icmp slt <4 x i32> %413, zeroinitializer
  %416 = select <4 x i1> %415, <4 x i32> %414, <4 x i32> %413
  %417 = add nuw nsw <4 x i32> %416, <i32 32, i32 32, i32 32, i32 32>
  %418 = lshr <4 x i32> %417, <i32 6, i32 6, i32 6, i32 6>
  %419 = shufflevector <8 x i16> %405, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %420 = shufflevector <8 x i16> %408, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %421 = bitcast <8 x i16> %419 to <4 x i32>
  %422 = bitcast <8 x i16> %420 to <4 x i32>
  %423 = sub <4 x i32> %421, %422
  %424 = sub <4 x i32> zeroinitializer, %423
  %425 = icmp slt <4 x i32> %423, zeroinitializer
  %426 = select <4 x i1> %425, <4 x i32> %424, <4 x i32> %423
  %427 = add nuw <4 x i32> %426, <i32 32, i32 32, i32 32, i32 32>
  %428 = lshr <4 x i32> %427, <i32 6, i32 6, i32 6, i32 6>
  %429 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %418, <4 x i32> %428) #5
  %430 = lshr <8 x i16> %429, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %431 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %402, <8 x i16> %430) #5
  %432 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %431, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %433 = icmp slt <16 x i8> %432, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %434 = select <16 x i1> %433, <16 x i8> %432, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %435 = bitcast i8* %376 to <16 x i8>*
  store <16 x i8> %434, <16 x i8>* %435, align 16
  %436 = getelementptr inbounds i8, i8* %0, i64 224
  %437 = getelementptr inbounds i8, i8* %1, i64 224
  %438 = getelementptr inbounds i8, i8* %376, i64 16
  %439 = bitcast i8* %436 to <8 x i16>*
  %440 = load <8 x i16>, <8 x i16>* %439, align 16
  %441 = bitcast i8* %437 to <8 x i16>*
  %442 = load <8 x i16>, <8 x i16>* %441, align 16
  %443 = shufflevector <8 x i16> %440, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %444 = zext <4 x i16> %443 to <4 x i32>
  %445 = shufflevector <8 x i16> %442, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %446 = zext <4 x i16> %445 to <4 x i32>
  %447 = sub nsw <4 x i32> %444, %446
  %448 = sub nsw <4 x i32> zeroinitializer, %447
  %449 = icmp slt <4 x i32> %447, zeroinitializer
  %450 = select <4 x i1> %449, <4 x i32> %448, <4 x i32> %447
  %451 = add nuw nsw <4 x i32> %450, <i32 32, i32 32, i32 32, i32 32>
  %452 = lshr <4 x i32> %451, <i32 6, i32 6, i32 6, i32 6>
  %453 = shufflevector <8 x i16> %440, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %454 = shufflevector <8 x i16> %442, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %455 = bitcast <8 x i16> %453 to <4 x i32>
  %456 = bitcast <8 x i16> %454 to <4 x i32>
  %457 = sub <4 x i32> %455, %456
  %458 = sub <4 x i32> zeroinitializer, %457
  %459 = icmp slt <4 x i32> %457, zeroinitializer
  %460 = select <4 x i1> %459, <4 x i32> %458, <4 x i32> %457
  %461 = add nuw <4 x i32> %460, <i32 32, i32 32, i32 32, i32 32>
  %462 = lshr <4 x i32> %461, <i32 6, i32 6, i32 6, i32 6>
  %463 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %452, <4 x i32> %462) #5
  %464 = lshr <8 x i16> %463, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %465 = getelementptr inbounds i8, i8* %0, i64 240
  %466 = bitcast i8* %465 to <8 x i16>*
  %467 = load <8 x i16>, <8 x i16>* %466, align 16
  %468 = getelementptr inbounds i8, i8* %1, i64 240
  %469 = bitcast i8* %468 to <8 x i16>*
  %470 = load <8 x i16>, <8 x i16>* %469, align 16
  %471 = shufflevector <8 x i16> %467, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %472 = zext <4 x i16> %471 to <4 x i32>
  %473 = shufflevector <8 x i16> %470, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %474 = zext <4 x i16> %473 to <4 x i32>
  %475 = sub nsw <4 x i32> %472, %474
  %476 = sub nsw <4 x i32> zeroinitializer, %475
  %477 = icmp slt <4 x i32> %475, zeroinitializer
  %478 = select <4 x i1> %477, <4 x i32> %476, <4 x i32> %475
  %479 = add nuw nsw <4 x i32> %478, <i32 32, i32 32, i32 32, i32 32>
  %480 = lshr <4 x i32> %479, <i32 6, i32 6, i32 6, i32 6>
  %481 = shufflevector <8 x i16> %467, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %482 = shufflevector <8 x i16> %470, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %483 = bitcast <8 x i16> %481 to <4 x i32>
  %484 = bitcast <8 x i16> %482 to <4 x i32>
  %485 = sub <4 x i32> %483, %484
  %486 = sub <4 x i32> zeroinitializer, %485
  %487 = icmp slt <4 x i32> %485, zeroinitializer
  %488 = select <4 x i1> %487, <4 x i32> %486, <4 x i32> %485
  %489 = add nuw <4 x i32> %488, <i32 32, i32 32, i32 32, i32 32>
  %490 = lshr <4 x i32> %489, <i32 6, i32 6, i32 6, i32 6>
  %491 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %480, <4 x i32> %490) #5
  %492 = lshr <8 x i16> %491, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %493 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %464, <8 x i16> %492) #5
  %494 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %493, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %495 = icmp slt <16 x i8> %494, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %496 = select <16 x i1> %495, <16 x i8> %494, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %497 = bitcast i8* %438 to <16 x i8>*
  store <16 x i8> %496, <16 x i8>* %497, align 16
  %498 = getelementptr inbounds i8, i8* %0, i64 256
  %499 = getelementptr inbounds i8, i8* %1, i64 256
  %500 = getelementptr inbounds i8, i8* %376, i64 %3
  %501 = bitcast i8* %498 to <8 x i16>*
  %502 = load <8 x i16>, <8 x i16>* %501, align 16
  %503 = bitcast i8* %499 to <8 x i16>*
  %504 = load <8 x i16>, <8 x i16>* %503, align 16
  %505 = shufflevector <8 x i16> %502, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %506 = zext <4 x i16> %505 to <4 x i32>
  %507 = shufflevector <8 x i16> %504, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %508 = zext <4 x i16> %507 to <4 x i32>
  %509 = sub nsw <4 x i32> %506, %508
  %510 = sub nsw <4 x i32> zeroinitializer, %509
  %511 = icmp slt <4 x i32> %509, zeroinitializer
  %512 = select <4 x i1> %511, <4 x i32> %510, <4 x i32> %509
  %513 = add nuw nsw <4 x i32> %512, <i32 32, i32 32, i32 32, i32 32>
  %514 = lshr <4 x i32> %513, <i32 6, i32 6, i32 6, i32 6>
  %515 = shufflevector <8 x i16> %502, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %516 = shufflevector <8 x i16> %504, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %517 = bitcast <8 x i16> %515 to <4 x i32>
  %518 = bitcast <8 x i16> %516 to <4 x i32>
  %519 = sub <4 x i32> %517, %518
  %520 = sub <4 x i32> zeroinitializer, %519
  %521 = icmp slt <4 x i32> %519, zeroinitializer
  %522 = select <4 x i1> %521, <4 x i32> %520, <4 x i32> %519
  %523 = add nuw <4 x i32> %522, <i32 32, i32 32, i32 32, i32 32>
  %524 = lshr <4 x i32> %523, <i32 6, i32 6, i32 6, i32 6>
  %525 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %514, <4 x i32> %524) #5
  %526 = lshr <8 x i16> %525, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %527 = getelementptr inbounds i8, i8* %0, i64 272
  %528 = bitcast i8* %527 to <8 x i16>*
  %529 = load <8 x i16>, <8 x i16>* %528, align 16
  %530 = getelementptr inbounds i8, i8* %1, i64 272
  %531 = bitcast i8* %530 to <8 x i16>*
  %532 = load <8 x i16>, <8 x i16>* %531, align 16
  %533 = shufflevector <8 x i16> %529, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %534 = zext <4 x i16> %533 to <4 x i32>
  %535 = shufflevector <8 x i16> %532, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %536 = zext <4 x i16> %535 to <4 x i32>
  %537 = sub nsw <4 x i32> %534, %536
  %538 = sub nsw <4 x i32> zeroinitializer, %537
  %539 = icmp slt <4 x i32> %537, zeroinitializer
  %540 = select <4 x i1> %539, <4 x i32> %538, <4 x i32> %537
  %541 = add nuw nsw <4 x i32> %540, <i32 32, i32 32, i32 32, i32 32>
  %542 = lshr <4 x i32> %541, <i32 6, i32 6, i32 6, i32 6>
  %543 = shufflevector <8 x i16> %529, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %544 = shufflevector <8 x i16> %532, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %545 = bitcast <8 x i16> %543 to <4 x i32>
  %546 = bitcast <8 x i16> %544 to <4 x i32>
  %547 = sub <4 x i32> %545, %546
  %548 = sub <4 x i32> zeroinitializer, %547
  %549 = icmp slt <4 x i32> %547, zeroinitializer
  %550 = select <4 x i1> %549, <4 x i32> %548, <4 x i32> %547
  %551 = add nuw <4 x i32> %550, <i32 32, i32 32, i32 32, i32 32>
  %552 = lshr <4 x i32> %551, <i32 6, i32 6, i32 6, i32 6>
  %553 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %542, <4 x i32> %552) #5
  %554 = lshr <8 x i16> %553, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %555 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %526, <8 x i16> %554) #5
  %556 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %555, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %557 = icmp slt <16 x i8> %556, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %558 = select <16 x i1> %557, <16 x i8> %556, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %559 = bitcast i8* %500 to <16 x i8>*
  store <16 x i8> %558, <16 x i8>* %559, align 16
  %560 = getelementptr inbounds i8, i8* %0, i64 288
  %561 = getelementptr inbounds i8, i8* %1, i64 288
  %562 = getelementptr inbounds i8, i8* %500, i64 16
  %563 = bitcast i8* %560 to <8 x i16>*
  %564 = load <8 x i16>, <8 x i16>* %563, align 16
  %565 = bitcast i8* %561 to <8 x i16>*
  %566 = load <8 x i16>, <8 x i16>* %565, align 16
  %567 = shufflevector <8 x i16> %564, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %568 = zext <4 x i16> %567 to <4 x i32>
  %569 = shufflevector <8 x i16> %566, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %570 = zext <4 x i16> %569 to <4 x i32>
  %571 = sub nsw <4 x i32> %568, %570
  %572 = sub nsw <4 x i32> zeroinitializer, %571
  %573 = icmp slt <4 x i32> %571, zeroinitializer
  %574 = select <4 x i1> %573, <4 x i32> %572, <4 x i32> %571
  %575 = add nuw nsw <4 x i32> %574, <i32 32, i32 32, i32 32, i32 32>
  %576 = lshr <4 x i32> %575, <i32 6, i32 6, i32 6, i32 6>
  %577 = shufflevector <8 x i16> %564, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %578 = shufflevector <8 x i16> %566, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %579 = bitcast <8 x i16> %577 to <4 x i32>
  %580 = bitcast <8 x i16> %578 to <4 x i32>
  %581 = sub <4 x i32> %579, %580
  %582 = sub <4 x i32> zeroinitializer, %581
  %583 = icmp slt <4 x i32> %581, zeroinitializer
  %584 = select <4 x i1> %583, <4 x i32> %582, <4 x i32> %581
  %585 = add nuw <4 x i32> %584, <i32 32, i32 32, i32 32, i32 32>
  %586 = lshr <4 x i32> %585, <i32 6, i32 6, i32 6, i32 6>
  %587 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %576, <4 x i32> %586) #5
  %588 = lshr <8 x i16> %587, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %589 = getelementptr inbounds i8, i8* %0, i64 304
  %590 = bitcast i8* %589 to <8 x i16>*
  %591 = load <8 x i16>, <8 x i16>* %590, align 16
  %592 = getelementptr inbounds i8, i8* %1, i64 304
  %593 = bitcast i8* %592 to <8 x i16>*
  %594 = load <8 x i16>, <8 x i16>* %593, align 16
  %595 = shufflevector <8 x i16> %591, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %596 = zext <4 x i16> %595 to <4 x i32>
  %597 = shufflevector <8 x i16> %594, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %598 = zext <4 x i16> %597 to <4 x i32>
  %599 = sub nsw <4 x i32> %596, %598
  %600 = sub nsw <4 x i32> zeroinitializer, %599
  %601 = icmp slt <4 x i32> %599, zeroinitializer
  %602 = select <4 x i1> %601, <4 x i32> %600, <4 x i32> %599
  %603 = add nuw nsw <4 x i32> %602, <i32 32, i32 32, i32 32, i32 32>
  %604 = lshr <4 x i32> %603, <i32 6, i32 6, i32 6, i32 6>
  %605 = shufflevector <8 x i16> %591, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %606 = shufflevector <8 x i16> %594, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %607 = bitcast <8 x i16> %605 to <4 x i32>
  %608 = bitcast <8 x i16> %606 to <4 x i32>
  %609 = sub <4 x i32> %607, %608
  %610 = sub <4 x i32> zeroinitializer, %609
  %611 = icmp slt <4 x i32> %609, zeroinitializer
  %612 = select <4 x i1> %611, <4 x i32> %610, <4 x i32> %609
  %613 = add nuw <4 x i32> %612, <i32 32, i32 32, i32 32, i32 32>
  %614 = lshr <4 x i32> %613, <i32 6, i32 6, i32 6, i32 6>
  %615 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %604, <4 x i32> %614) #5
  %616 = lshr <8 x i16> %615, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %617 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %588, <8 x i16> %616) #5
  %618 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %617, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %619 = icmp slt <16 x i8> %618, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %620 = select <16 x i1> %619, <16 x i8> %618, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %621 = bitcast i8* %562 to <16 x i8>*
  store <16 x i8> %620, <16 x i8>* %621, align 16
  %622 = getelementptr inbounds i8, i8* %0, i64 320
  %623 = getelementptr inbounds i8, i8* %1, i64 320
  %624 = getelementptr inbounds i8, i8* %500, i64 %3
  %625 = bitcast i8* %622 to <8 x i16>*
  %626 = load <8 x i16>, <8 x i16>* %625, align 16
  %627 = bitcast i8* %623 to <8 x i16>*
  %628 = load <8 x i16>, <8 x i16>* %627, align 16
  %629 = shufflevector <8 x i16> %626, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %630 = zext <4 x i16> %629 to <4 x i32>
  %631 = shufflevector <8 x i16> %628, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %632 = zext <4 x i16> %631 to <4 x i32>
  %633 = sub nsw <4 x i32> %630, %632
  %634 = sub nsw <4 x i32> zeroinitializer, %633
  %635 = icmp slt <4 x i32> %633, zeroinitializer
  %636 = select <4 x i1> %635, <4 x i32> %634, <4 x i32> %633
  %637 = add nuw nsw <4 x i32> %636, <i32 32, i32 32, i32 32, i32 32>
  %638 = lshr <4 x i32> %637, <i32 6, i32 6, i32 6, i32 6>
  %639 = shufflevector <8 x i16> %626, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %640 = shufflevector <8 x i16> %628, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %641 = bitcast <8 x i16> %639 to <4 x i32>
  %642 = bitcast <8 x i16> %640 to <4 x i32>
  %643 = sub <4 x i32> %641, %642
  %644 = sub <4 x i32> zeroinitializer, %643
  %645 = icmp slt <4 x i32> %643, zeroinitializer
  %646 = select <4 x i1> %645, <4 x i32> %644, <4 x i32> %643
  %647 = add nuw <4 x i32> %646, <i32 32, i32 32, i32 32, i32 32>
  %648 = lshr <4 x i32> %647, <i32 6, i32 6, i32 6, i32 6>
  %649 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %638, <4 x i32> %648) #5
  %650 = lshr <8 x i16> %649, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %651 = getelementptr inbounds i8, i8* %0, i64 336
  %652 = bitcast i8* %651 to <8 x i16>*
  %653 = load <8 x i16>, <8 x i16>* %652, align 16
  %654 = getelementptr inbounds i8, i8* %1, i64 336
  %655 = bitcast i8* %654 to <8 x i16>*
  %656 = load <8 x i16>, <8 x i16>* %655, align 16
  %657 = shufflevector <8 x i16> %653, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %658 = zext <4 x i16> %657 to <4 x i32>
  %659 = shufflevector <8 x i16> %656, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %660 = zext <4 x i16> %659 to <4 x i32>
  %661 = sub nsw <4 x i32> %658, %660
  %662 = sub nsw <4 x i32> zeroinitializer, %661
  %663 = icmp slt <4 x i32> %661, zeroinitializer
  %664 = select <4 x i1> %663, <4 x i32> %662, <4 x i32> %661
  %665 = add nuw nsw <4 x i32> %664, <i32 32, i32 32, i32 32, i32 32>
  %666 = lshr <4 x i32> %665, <i32 6, i32 6, i32 6, i32 6>
  %667 = shufflevector <8 x i16> %653, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %668 = shufflevector <8 x i16> %656, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %669 = bitcast <8 x i16> %667 to <4 x i32>
  %670 = bitcast <8 x i16> %668 to <4 x i32>
  %671 = sub <4 x i32> %669, %670
  %672 = sub <4 x i32> zeroinitializer, %671
  %673 = icmp slt <4 x i32> %671, zeroinitializer
  %674 = select <4 x i1> %673, <4 x i32> %672, <4 x i32> %671
  %675 = add nuw <4 x i32> %674, <i32 32, i32 32, i32 32, i32 32>
  %676 = lshr <4 x i32> %675, <i32 6, i32 6, i32 6, i32 6>
  %677 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %666, <4 x i32> %676) #5
  %678 = lshr <8 x i16> %677, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %679 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %650, <8 x i16> %678) #5
  %680 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %679, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %681 = icmp slt <16 x i8> %680, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %682 = select <16 x i1> %681, <16 x i8> %680, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %683 = bitcast i8* %624 to <16 x i8>*
  store <16 x i8> %682, <16 x i8>* %683, align 16
  %684 = getelementptr inbounds i8, i8* %0, i64 352
  %685 = getelementptr inbounds i8, i8* %1, i64 352
  %686 = getelementptr inbounds i8, i8* %624, i64 16
  %687 = bitcast i8* %684 to <8 x i16>*
  %688 = load <8 x i16>, <8 x i16>* %687, align 16
  %689 = bitcast i8* %685 to <8 x i16>*
  %690 = load <8 x i16>, <8 x i16>* %689, align 16
  %691 = shufflevector <8 x i16> %688, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %692 = zext <4 x i16> %691 to <4 x i32>
  %693 = shufflevector <8 x i16> %690, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %694 = zext <4 x i16> %693 to <4 x i32>
  %695 = sub nsw <4 x i32> %692, %694
  %696 = sub nsw <4 x i32> zeroinitializer, %695
  %697 = icmp slt <4 x i32> %695, zeroinitializer
  %698 = select <4 x i1> %697, <4 x i32> %696, <4 x i32> %695
  %699 = add nuw nsw <4 x i32> %698, <i32 32, i32 32, i32 32, i32 32>
  %700 = lshr <4 x i32> %699, <i32 6, i32 6, i32 6, i32 6>
  %701 = shufflevector <8 x i16> %688, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %702 = shufflevector <8 x i16> %690, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %703 = bitcast <8 x i16> %701 to <4 x i32>
  %704 = bitcast <8 x i16> %702 to <4 x i32>
  %705 = sub <4 x i32> %703, %704
  %706 = sub <4 x i32> zeroinitializer, %705
  %707 = icmp slt <4 x i32> %705, zeroinitializer
  %708 = select <4 x i1> %707, <4 x i32> %706, <4 x i32> %705
  %709 = add nuw <4 x i32> %708, <i32 32, i32 32, i32 32, i32 32>
  %710 = lshr <4 x i32> %709, <i32 6, i32 6, i32 6, i32 6>
  %711 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %700, <4 x i32> %710) #5
  %712 = lshr <8 x i16> %711, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %713 = getelementptr inbounds i8, i8* %0, i64 368
  %714 = bitcast i8* %713 to <8 x i16>*
  %715 = load <8 x i16>, <8 x i16>* %714, align 16
  %716 = getelementptr inbounds i8, i8* %1, i64 368
  %717 = bitcast i8* %716 to <8 x i16>*
  %718 = load <8 x i16>, <8 x i16>* %717, align 16
  %719 = shufflevector <8 x i16> %715, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %720 = zext <4 x i16> %719 to <4 x i32>
  %721 = shufflevector <8 x i16> %718, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %722 = zext <4 x i16> %721 to <4 x i32>
  %723 = sub nsw <4 x i32> %720, %722
  %724 = sub nsw <4 x i32> zeroinitializer, %723
  %725 = icmp slt <4 x i32> %723, zeroinitializer
  %726 = select <4 x i1> %725, <4 x i32> %724, <4 x i32> %723
  %727 = add nuw nsw <4 x i32> %726, <i32 32, i32 32, i32 32, i32 32>
  %728 = lshr <4 x i32> %727, <i32 6, i32 6, i32 6, i32 6>
  %729 = shufflevector <8 x i16> %715, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %730 = shufflevector <8 x i16> %718, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %731 = bitcast <8 x i16> %729 to <4 x i32>
  %732 = bitcast <8 x i16> %730 to <4 x i32>
  %733 = sub <4 x i32> %731, %732
  %734 = sub <4 x i32> zeroinitializer, %733
  %735 = icmp slt <4 x i32> %733, zeroinitializer
  %736 = select <4 x i1> %735, <4 x i32> %734, <4 x i32> %733
  %737 = add nuw <4 x i32> %736, <i32 32, i32 32, i32 32, i32 32>
  %738 = lshr <4 x i32> %737, <i32 6, i32 6, i32 6, i32 6>
  %739 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %728, <4 x i32> %738) #5
  %740 = lshr <8 x i16> %739, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %741 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %712, <8 x i16> %740) #5
  %742 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %741, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %743 = icmp slt <16 x i8> %742, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %744 = select <16 x i1> %743, <16 x i8> %742, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %745 = bitcast i8* %686 to <16 x i8>*
  store <16 x i8> %744, <16 x i8>* %745, align 16
  %746 = getelementptr inbounds i8, i8* %0, i64 384
  %747 = getelementptr inbounds i8, i8* %1, i64 384
  %748 = getelementptr inbounds i8, i8* %624, i64 %3
  %749 = bitcast i8* %746 to <8 x i16>*
  %750 = load <8 x i16>, <8 x i16>* %749, align 16
  %751 = bitcast i8* %747 to <8 x i16>*
  %752 = load <8 x i16>, <8 x i16>* %751, align 16
  %753 = shufflevector <8 x i16> %750, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %754 = zext <4 x i16> %753 to <4 x i32>
  %755 = shufflevector <8 x i16> %752, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %756 = zext <4 x i16> %755 to <4 x i32>
  %757 = sub nsw <4 x i32> %754, %756
  %758 = sub nsw <4 x i32> zeroinitializer, %757
  %759 = icmp slt <4 x i32> %757, zeroinitializer
  %760 = select <4 x i1> %759, <4 x i32> %758, <4 x i32> %757
  %761 = add nuw nsw <4 x i32> %760, <i32 32, i32 32, i32 32, i32 32>
  %762 = lshr <4 x i32> %761, <i32 6, i32 6, i32 6, i32 6>
  %763 = shufflevector <8 x i16> %750, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %764 = shufflevector <8 x i16> %752, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %765 = bitcast <8 x i16> %763 to <4 x i32>
  %766 = bitcast <8 x i16> %764 to <4 x i32>
  %767 = sub <4 x i32> %765, %766
  %768 = sub <4 x i32> zeroinitializer, %767
  %769 = icmp slt <4 x i32> %767, zeroinitializer
  %770 = select <4 x i1> %769, <4 x i32> %768, <4 x i32> %767
  %771 = add nuw <4 x i32> %770, <i32 32, i32 32, i32 32, i32 32>
  %772 = lshr <4 x i32> %771, <i32 6, i32 6, i32 6, i32 6>
  %773 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %762, <4 x i32> %772) #5
  %774 = lshr <8 x i16> %773, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %775 = getelementptr inbounds i8, i8* %0, i64 400
  %776 = bitcast i8* %775 to <8 x i16>*
  %777 = load <8 x i16>, <8 x i16>* %776, align 16
  %778 = getelementptr inbounds i8, i8* %1, i64 400
  %779 = bitcast i8* %778 to <8 x i16>*
  %780 = load <8 x i16>, <8 x i16>* %779, align 16
  %781 = shufflevector <8 x i16> %777, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %782 = zext <4 x i16> %781 to <4 x i32>
  %783 = shufflevector <8 x i16> %780, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %784 = zext <4 x i16> %783 to <4 x i32>
  %785 = sub nsw <4 x i32> %782, %784
  %786 = sub nsw <4 x i32> zeroinitializer, %785
  %787 = icmp slt <4 x i32> %785, zeroinitializer
  %788 = select <4 x i1> %787, <4 x i32> %786, <4 x i32> %785
  %789 = add nuw nsw <4 x i32> %788, <i32 32, i32 32, i32 32, i32 32>
  %790 = lshr <4 x i32> %789, <i32 6, i32 6, i32 6, i32 6>
  %791 = shufflevector <8 x i16> %777, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %792 = shufflevector <8 x i16> %780, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %793 = bitcast <8 x i16> %791 to <4 x i32>
  %794 = bitcast <8 x i16> %792 to <4 x i32>
  %795 = sub <4 x i32> %793, %794
  %796 = sub <4 x i32> zeroinitializer, %795
  %797 = icmp slt <4 x i32> %795, zeroinitializer
  %798 = select <4 x i1> %797, <4 x i32> %796, <4 x i32> %795
  %799 = add nuw <4 x i32> %798, <i32 32, i32 32, i32 32, i32 32>
  %800 = lshr <4 x i32> %799, <i32 6, i32 6, i32 6, i32 6>
  %801 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %790, <4 x i32> %800) #5
  %802 = lshr <8 x i16> %801, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %803 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %774, <8 x i16> %802) #5
  %804 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %803, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %805 = icmp slt <16 x i8> %804, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %806 = select <16 x i1> %805, <16 x i8> %804, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %807 = bitcast i8* %748 to <16 x i8>*
  store <16 x i8> %806, <16 x i8>* %807, align 16
  %808 = getelementptr inbounds i8, i8* %0, i64 416
  %809 = getelementptr inbounds i8, i8* %1, i64 416
  %810 = getelementptr inbounds i8, i8* %748, i64 16
  %811 = bitcast i8* %808 to <8 x i16>*
  %812 = load <8 x i16>, <8 x i16>* %811, align 16
  %813 = bitcast i8* %809 to <8 x i16>*
  %814 = load <8 x i16>, <8 x i16>* %813, align 16
  %815 = shufflevector <8 x i16> %812, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %816 = zext <4 x i16> %815 to <4 x i32>
  %817 = shufflevector <8 x i16> %814, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %818 = zext <4 x i16> %817 to <4 x i32>
  %819 = sub nsw <4 x i32> %816, %818
  %820 = sub nsw <4 x i32> zeroinitializer, %819
  %821 = icmp slt <4 x i32> %819, zeroinitializer
  %822 = select <4 x i1> %821, <4 x i32> %820, <4 x i32> %819
  %823 = add nuw nsw <4 x i32> %822, <i32 32, i32 32, i32 32, i32 32>
  %824 = lshr <4 x i32> %823, <i32 6, i32 6, i32 6, i32 6>
  %825 = shufflevector <8 x i16> %812, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %826 = shufflevector <8 x i16> %814, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %827 = bitcast <8 x i16> %825 to <4 x i32>
  %828 = bitcast <8 x i16> %826 to <4 x i32>
  %829 = sub <4 x i32> %827, %828
  %830 = sub <4 x i32> zeroinitializer, %829
  %831 = icmp slt <4 x i32> %829, zeroinitializer
  %832 = select <4 x i1> %831, <4 x i32> %830, <4 x i32> %829
  %833 = add nuw <4 x i32> %832, <i32 32, i32 32, i32 32, i32 32>
  %834 = lshr <4 x i32> %833, <i32 6, i32 6, i32 6, i32 6>
  %835 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %824, <4 x i32> %834) #5
  %836 = lshr <8 x i16> %835, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %837 = getelementptr inbounds i8, i8* %0, i64 432
  %838 = bitcast i8* %837 to <8 x i16>*
  %839 = load <8 x i16>, <8 x i16>* %838, align 16
  %840 = getelementptr inbounds i8, i8* %1, i64 432
  %841 = bitcast i8* %840 to <8 x i16>*
  %842 = load <8 x i16>, <8 x i16>* %841, align 16
  %843 = shufflevector <8 x i16> %839, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %844 = zext <4 x i16> %843 to <4 x i32>
  %845 = shufflevector <8 x i16> %842, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %846 = zext <4 x i16> %845 to <4 x i32>
  %847 = sub nsw <4 x i32> %844, %846
  %848 = sub nsw <4 x i32> zeroinitializer, %847
  %849 = icmp slt <4 x i32> %847, zeroinitializer
  %850 = select <4 x i1> %849, <4 x i32> %848, <4 x i32> %847
  %851 = add nuw nsw <4 x i32> %850, <i32 32, i32 32, i32 32, i32 32>
  %852 = lshr <4 x i32> %851, <i32 6, i32 6, i32 6, i32 6>
  %853 = shufflevector <8 x i16> %839, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %854 = shufflevector <8 x i16> %842, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %855 = bitcast <8 x i16> %853 to <4 x i32>
  %856 = bitcast <8 x i16> %854 to <4 x i32>
  %857 = sub <4 x i32> %855, %856
  %858 = sub <4 x i32> zeroinitializer, %857
  %859 = icmp slt <4 x i32> %857, zeroinitializer
  %860 = select <4 x i1> %859, <4 x i32> %858, <4 x i32> %857
  %861 = add nuw <4 x i32> %860, <i32 32, i32 32, i32 32, i32 32>
  %862 = lshr <4 x i32> %861, <i32 6, i32 6, i32 6, i32 6>
  %863 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %852, <4 x i32> %862) #5
  %864 = lshr <8 x i16> %863, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %865 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %836, <8 x i16> %864) #5
  %866 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %865, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %867 = icmp slt <16 x i8> %866, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %868 = select <16 x i1> %867, <16 x i8> %866, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %869 = bitcast i8* %810 to <16 x i8>*
  store <16 x i8> %868, <16 x i8>* %869, align 16
  %870 = getelementptr inbounds i8, i8* %0, i64 448
  %871 = getelementptr inbounds i8, i8* %1, i64 448
  %872 = getelementptr inbounds i8, i8* %748, i64 %3
  %873 = bitcast i8* %870 to <8 x i16>*
  %874 = load <8 x i16>, <8 x i16>* %873, align 16
  %875 = bitcast i8* %871 to <8 x i16>*
  %876 = load <8 x i16>, <8 x i16>* %875, align 16
  %877 = shufflevector <8 x i16> %874, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %878 = zext <4 x i16> %877 to <4 x i32>
  %879 = shufflevector <8 x i16> %876, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %880 = zext <4 x i16> %879 to <4 x i32>
  %881 = sub nsw <4 x i32> %878, %880
  %882 = sub nsw <4 x i32> zeroinitializer, %881
  %883 = icmp slt <4 x i32> %881, zeroinitializer
  %884 = select <4 x i1> %883, <4 x i32> %882, <4 x i32> %881
  %885 = add nuw nsw <4 x i32> %884, <i32 32, i32 32, i32 32, i32 32>
  %886 = lshr <4 x i32> %885, <i32 6, i32 6, i32 6, i32 6>
  %887 = shufflevector <8 x i16> %874, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %888 = shufflevector <8 x i16> %876, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %889 = bitcast <8 x i16> %887 to <4 x i32>
  %890 = bitcast <8 x i16> %888 to <4 x i32>
  %891 = sub <4 x i32> %889, %890
  %892 = sub <4 x i32> zeroinitializer, %891
  %893 = icmp slt <4 x i32> %891, zeroinitializer
  %894 = select <4 x i1> %893, <4 x i32> %892, <4 x i32> %891
  %895 = add nuw <4 x i32> %894, <i32 32, i32 32, i32 32, i32 32>
  %896 = lshr <4 x i32> %895, <i32 6, i32 6, i32 6, i32 6>
  %897 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %886, <4 x i32> %896) #5
  %898 = lshr <8 x i16> %897, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %899 = getelementptr inbounds i8, i8* %0, i64 464
  %900 = bitcast i8* %899 to <8 x i16>*
  %901 = load <8 x i16>, <8 x i16>* %900, align 16
  %902 = getelementptr inbounds i8, i8* %1, i64 464
  %903 = bitcast i8* %902 to <8 x i16>*
  %904 = load <8 x i16>, <8 x i16>* %903, align 16
  %905 = shufflevector <8 x i16> %901, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %906 = zext <4 x i16> %905 to <4 x i32>
  %907 = shufflevector <8 x i16> %904, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %908 = zext <4 x i16> %907 to <4 x i32>
  %909 = sub nsw <4 x i32> %906, %908
  %910 = sub nsw <4 x i32> zeroinitializer, %909
  %911 = icmp slt <4 x i32> %909, zeroinitializer
  %912 = select <4 x i1> %911, <4 x i32> %910, <4 x i32> %909
  %913 = add nuw nsw <4 x i32> %912, <i32 32, i32 32, i32 32, i32 32>
  %914 = lshr <4 x i32> %913, <i32 6, i32 6, i32 6, i32 6>
  %915 = shufflevector <8 x i16> %901, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %916 = shufflevector <8 x i16> %904, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %917 = bitcast <8 x i16> %915 to <4 x i32>
  %918 = bitcast <8 x i16> %916 to <4 x i32>
  %919 = sub <4 x i32> %917, %918
  %920 = sub <4 x i32> zeroinitializer, %919
  %921 = icmp slt <4 x i32> %919, zeroinitializer
  %922 = select <4 x i1> %921, <4 x i32> %920, <4 x i32> %919
  %923 = add nuw <4 x i32> %922, <i32 32, i32 32, i32 32, i32 32>
  %924 = lshr <4 x i32> %923, <i32 6, i32 6, i32 6, i32 6>
  %925 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %914, <4 x i32> %924) #5
  %926 = lshr <8 x i16> %925, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %927 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %898, <8 x i16> %926) #5
  %928 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %927, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %929 = icmp slt <16 x i8> %928, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %930 = select <16 x i1> %929, <16 x i8> %928, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %931 = bitcast i8* %872 to <16 x i8>*
  store <16 x i8> %930, <16 x i8>* %931, align 16
  %932 = getelementptr inbounds i8, i8* %0, i64 480
  %933 = getelementptr inbounds i8, i8* %1, i64 480
  %934 = getelementptr inbounds i8, i8* %872, i64 16
  %935 = bitcast i8* %932 to <8 x i16>*
  %936 = load <8 x i16>, <8 x i16>* %935, align 16
  %937 = bitcast i8* %933 to <8 x i16>*
  %938 = load <8 x i16>, <8 x i16>* %937, align 16
  %939 = shufflevector <8 x i16> %936, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %940 = zext <4 x i16> %939 to <4 x i32>
  %941 = shufflevector <8 x i16> %938, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %942 = zext <4 x i16> %941 to <4 x i32>
  %943 = sub nsw <4 x i32> %940, %942
  %944 = sub nsw <4 x i32> zeroinitializer, %943
  %945 = icmp slt <4 x i32> %943, zeroinitializer
  %946 = select <4 x i1> %945, <4 x i32> %944, <4 x i32> %943
  %947 = add nuw nsw <4 x i32> %946, <i32 32, i32 32, i32 32, i32 32>
  %948 = lshr <4 x i32> %947, <i32 6, i32 6, i32 6, i32 6>
  %949 = shufflevector <8 x i16> %936, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %950 = shufflevector <8 x i16> %938, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %951 = bitcast <8 x i16> %949 to <4 x i32>
  %952 = bitcast <8 x i16> %950 to <4 x i32>
  %953 = sub <4 x i32> %951, %952
  %954 = sub <4 x i32> zeroinitializer, %953
  %955 = icmp slt <4 x i32> %953, zeroinitializer
  %956 = select <4 x i1> %955, <4 x i32> %954, <4 x i32> %953
  %957 = add nuw <4 x i32> %956, <i32 32, i32 32, i32 32, i32 32>
  %958 = lshr <4 x i32> %957, <i32 6, i32 6, i32 6, i32 6>
  %959 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %948, <4 x i32> %958) #5
  %960 = lshr <8 x i16> %959, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %961 = getelementptr inbounds i8, i8* %0, i64 496
  %962 = bitcast i8* %961 to <8 x i16>*
  %963 = load <8 x i16>, <8 x i16>* %962, align 16
  %964 = getelementptr inbounds i8, i8* %1, i64 496
  %965 = bitcast i8* %964 to <8 x i16>*
  %966 = load <8 x i16>, <8 x i16>* %965, align 16
  %967 = shufflevector <8 x i16> %963, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %968 = zext <4 x i16> %967 to <4 x i32>
  %969 = shufflevector <8 x i16> %966, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %970 = zext <4 x i16> %969 to <4 x i32>
  %971 = sub nsw <4 x i32> %968, %970
  %972 = sub nsw <4 x i32> zeroinitializer, %971
  %973 = icmp slt <4 x i32> %971, zeroinitializer
  %974 = select <4 x i1> %973, <4 x i32> %972, <4 x i32> %971
  %975 = add nuw nsw <4 x i32> %974, <i32 32, i32 32, i32 32, i32 32>
  %976 = lshr <4 x i32> %975, <i32 6, i32 6, i32 6, i32 6>
  %977 = shufflevector <8 x i16> %963, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %978 = shufflevector <8 x i16> %966, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %979 = bitcast <8 x i16> %977 to <4 x i32>
  %980 = bitcast <8 x i16> %978 to <4 x i32>
  %981 = sub <4 x i32> %979, %980
  %982 = sub <4 x i32> zeroinitializer, %981
  %983 = icmp slt <4 x i32> %981, zeroinitializer
  %984 = select <4 x i1> %983, <4 x i32> %982, <4 x i32> %981
  %985 = add nuw <4 x i32> %984, <i32 32, i32 32, i32 32, i32 32>
  %986 = lshr <4 x i32> %985, <i32 6, i32 6, i32 6, i32 6>
  %987 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %976, <4 x i32> %986) #5
  %988 = lshr <8 x i16> %987, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %989 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %960, <8 x i16> %988) #5
  %990 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %989, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %991 = icmp slt <16 x i8> %990, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %992 = select <16 x i1> %991, <16 x i8> %990, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %993 = bitcast i8* %934 to <16 x i8>*
  store <16 x i8> %992, <16 x i8>* %993, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_125WeightMask32x8_10bpp_SSE4ILb1EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to <8 x i16>*
  %6 = load <8 x i16>, <8 x i16>* %5, align 16
  %7 = bitcast i8* %1 to <8 x i16>*
  %8 = load <8 x i16>, <8 x i16>* %7, align 16
  %9 = shufflevector <8 x i16> %6, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %10 = zext <4 x i16> %9 to <4 x i32>
  %11 = shufflevector <8 x i16> %8, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %12 = zext <4 x i16> %11 to <4 x i32>
  %13 = sub nsw <4 x i32> %10, %12
  %14 = sub nsw <4 x i32> zeroinitializer, %13
  %15 = icmp slt <4 x i32> %13, zeroinitializer
  %16 = select <4 x i1> %15, <4 x i32> %14, <4 x i32> %13
  %17 = add nuw nsw <4 x i32> %16, <i32 32, i32 32, i32 32, i32 32>
  %18 = lshr <4 x i32> %17, <i32 6, i32 6, i32 6, i32 6>
  %19 = shufflevector <8 x i16> %6, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %20 = shufflevector <8 x i16> %8, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %21 = bitcast <8 x i16> %19 to <4 x i32>
  %22 = bitcast <8 x i16> %20 to <4 x i32>
  %23 = sub <4 x i32> %21, %22
  %24 = sub <4 x i32> zeroinitializer, %23
  %25 = icmp slt <4 x i32> %23, zeroinitializer
  %26 = select <4 x i1> %25, <4 x i32> %24, <4 x i32> %23
  %27 = add nuw <4 x i32> %26, <i32 32, i32 32, i32 32, i32 32>
  %28 = lshr <4 x i32> %27, <i32 6, i32 6, i32 6, i32 6>
  %29 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %18, <4 x i32> %28) #5
  %30 = lshr <8 x i16> %29, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %31 = getelementptr inbounds i8, i8* %0, i64 16
  %32 = bitcast i8* %31 to <8 x i16>*
  %33 = load <8 x i16>, <8 x i16>* %32, align 16
  %34 = getelementptr inbounds i8, i8* %1, i64 16
  %35 = bitcast i8* %34 to <8 x i16>*
  %36 = load <8 x i16>, <8 x i16>* %35, align 16
  %37 = shufflevector <8 x i16> %33, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %38 = zext <4 x i16> %37 to <4 x i32>
  %39 = shufflevector <8 x i16> %36, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %40 = zext <4 x i16> %39 to <4 x i32>
  %41 = sub nsw <4 x i32> %38, %40
  %42 = sub nsw <4 x i32> zeroinitializer, %41
  %43 = icmp slt <4 x i32> %41, zeroinitializer
  %44 = select <4 x i1> %43, <4 x i32> %42, <4 x i32> %41
  %45 = add nuw nsw <4 x i32> %44, <i32 32, i32 32, i32 32, i32 32>
  %46 = lshr <4 x i32> %45, <i32 6, i32 6, i32 6, i32 6>
  %47 = shufflevector <8 x i16> %33, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %48 = shufflevector <8 x i16> %36, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %49 = bitcast <8 x i16> %47 to <4 x i32>
  %50 = bitcast <8 x i16> %48 to <4 x i32>
  %51 = sub <4 x i32> %49, %50
  %52 = sub <4 x i32> zeroinitializer, %51
  %53 = icmp slt <4 x i32> %51, zeroinitializer
  %54 = select <4 x i1> %53, <4 x i32> %52, <4 x i32> %51
  %55 = add nuw <4 x i32> %54, <i32 32, i32 32, i32 32, i32 32>
  %56 = lshr <4 x i32> %55, <i32 6, i32 6, i32 6, i32 6>
  %57 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %46, <4 x i32> %56) #5
  %58 = lshr <8 x i16> %57, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %59 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %30, <8 x i16> %58) #5
  %60 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %59, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %61 = icmp slt <16 x i8> %60, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %62 = select <16 x i1> %61, <16 x i8> %60, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %63 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %62
  %64 = bitcast i8* %2 to <16 x i8>*
  store <16 x i8> %63, <16 x i8>* %64, align 16
  %65 = getelementptr inbounds i8, i8* %0, i64 32
  %66 = getelementptr inbounds i8, i8* %1, i64 32
  %67 = getelementptr inbounds i8, i8* %2, i64 16
  %68 = bitcast i8* %65 to <8 x i16>*
  %69 = load <8 x i16>, <8 x i16>* %68, align 16
  %70 = bitcast i8* %66 to <8 x i16>*
  %71 = load <8 x i16>, <8 x i16>* %70, align 16
  %72 = shufflevector <8 x i16> %69, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %73 = zext <4 x i16> %72 to <4 x i32>
  %74 = shufflevector <8 x i16> %71, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %75 = zext <4 x i16> %74 to <4 x i32>
  %76 = sub nsw <4 x i32> %73, %75
  %77 = sub nsw <4 x i32> zeroinitializer, %76
  %78 = icmp slt <4 x i32> %76, zeroinitializer
  %79 = select <4 x i1> %78, <4 x i32> %77, <4 x i32> %76
  %80 = add nuw nsw <4 x i32> %79, <i32 32, i32 32, i32 32, i32 32>
  %81 = lshr <4 x i32> %80, <i32 6, i32 6, i32 6, i32 6>
  %82 = shufflevector <8 x i16> %69, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %83 = shufflevector <8 x i16> %71, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %84 = bitcast <8 x i16> %82 to <4 x i32>
  %85 = bitcast <8 x i16> %83 to <4 x i32>
  %86 = sub <4 x i32> %84, %85
  %87 = sub <4 x i32> zeroinitializer, %86
  %88 = icmp slt <4 x i32> %86, zeroinitializer
  %89 = select <4 x i1> %88, <4 x i32> %87, <4 x i32> %86
  %90 = add nuw <4 x i32> %89, <i32 32, i32 32, i32 32, i32 32>
  %91 = lshr <4 x i32> %90, <i32 6, i32 6, i32 6, i32 6>
  %92 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %81, <4 x i32> %91) #5
  %93 = lshr <8 x i16> %92, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %94 = getelementptr inbounds i8, i8* %0, i64 48
  %95 = bitcast i8* %94 to <8 x i16>*
  %96 = load <8 x i16>, <8 x i16>* %95, align 16
  %97 = getelementptr inbounds i8, i8* %1, i64 48
  %98 = bitcast i8* %97 to <8 x i16>*
  %99 = load <8 x i16>, <8 x i16>* %98, align 16
  %100 = shufflevector <8 x i16> %96, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %101 = zext <4 x i16> %100 to <4 x i32>
  %102 = shufflevector <8 x i16> %99, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %103 = zext <4 x i16> %102 to <4 x i32>
  %104 = sub nsw <4 x i32> %101, %103
  %105 = sub nsw <4 x i32> zeroinitializer, %104
  %106 = icmp slt <4 x i32> %104, zeroinitializer
  %107 = select <4 x i1> %106, <4 x i32> %105, <4 x i32> %104
  %108 = add nuw nsw <4 x i32> %107, <i32 32, i32 32, i32 32, i32 32>
  %109 = lshr <4 x i32> %108, <i32 6, i32 6, i32 6, i32 6>
  %110 = shufflevector <8 x i16> %96, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %111 = shufflevector <8 x i16> %99, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %112 = bitcast <8 x i16> %110 to <4 x i32>
  %113 = bitcast <8 x i16> %111 to <4 x i32>
  %114 = sub <4 x i32> %112, %113
  %115 = sub <4 x i32> zeroinitializer, %114
  %116 = icmp slt <4 x i32> %114, zeroinitializer
  %117 = select <4 x i1> %116, <4 x i32> %115, <4 x i32> %114
  %118 = add nuw <4 x i32> %117, <i32 32, i32 32, i32 32, i32 32>
  %119 = lshr <4 x i32> %118, <i32 6, i32 6, i32 6, i32 6>
  %120 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %109, <4 x i32> %119) #5
  %121 = lshr <8 x i16> %120, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %122 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %93, <8 x i16> %121) #5
  %123 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %122, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %124 = icmp slt <16 x i8> %123, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %125 = select <16 x i1> %124, <16 x i8> %123, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %126 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %125
  %127 = bitcast i8* %67 to <16 x i8>*
  store <16 x i8> %126, <16 x i8>* %127, align 16
  %128 = getelementptr inbounds i8, i8* %0, i64 64
  %129 = getelementptr inbounds i8, i8* %1, i64 64
  %130 = getelementptr inbounds i8, i8* %2, i64 %3
  %131 = bitcast i8* %128 to <8 x i16>*
  %132 = load <8 x i16>, <8 x i16>* %131, align 16
  %133 = bitcast i8* %129 to <8 x i16>*
  %134 = load <8 x i16>, <8 x i16>* %133, align 16
  %135 = shufflevector <8 x i16> %132, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %136 = zext <4 x i16> %135 to <4 x i32>
  %137 = shufflevector <8 x i16> %134, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %138 = zext <4 x i16> %137 to <4 x i32>
  %139 = sub nsw <4 x i32> %136, %138
  %140 = sub nsw <4 x i32> zeroinitializer, %139
  %141 = icmp slt <4 x i32> %139, zeroinitializer
  %142 = select <4 x i1> %141, <4 x i32> %140, <4 x i32> %139
  %143 = add nuw nsw <4 x i32> %142, <i32 32, i32 32, i32 32, i32 32>
  %144 = lshr <4 x i32> %143, <i32 6, i32 6, i32 6, i32 6>
  %145 = shufflevector <8 x i16> %132, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %146 = shufflevector <8 x i16> %134, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %147 = bitcast <8 x i16> %145 to <4 x i32>
  %148 = bitcast <8 x i16> %146 to <4 x i32>
  %149 = sub <4 x i32> %147, %148
  %150 = sub <4 x i32> zeroinitializer, %149
  %151 = icmp slt <4 x i32> %149, zeroinitializer
  %152 = select <4 x i1> %151, <4 x i32> %150, <4 x i32> %149
  %153 = add nuw <4 x i32> %152, <i32 32, i32 32, i32 32, i32 32>
  %154 = lshr <4 x i32> %153, <i32 6, i32 6, i32 6, i32 6>
  %155 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %144, <4 x i32> %154) #5
  %156 = lshr <8 x i16> %155, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %157 = getelementptr inbounds i8, i8* %0, i64 80
  %158 = bitcast i8* %157 to <8 x i16>*
  %159 = load <8 x i16>, <8 x i16>* %158, align 16
  %160 = getelementptr inbounds i8, i8* %1, i64 80
  %161 = bitcast i8* %160 to <8 x i16>*
  %162 = load <8 x i16>, <8 x i16>* %161, align 16
  %163 = shufflevector <8 x i16> %159, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %164 = zext <4 x i16> %163 to <4 x i32>
  %165 = shufflevector <8 x i16> %162, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %166 = zext <4 x i16> %165 to <4 x i32>
  %167 = sub nsw <4 x i32> %164, %166
  %168 = sub nsw <4 x i32> zeroinitializer, %167
  %169 = icmp slt <4 x i32> %167, zeroinitializer
  %170 = select <4 x i1> %169, <4 x i32> %168, <4 x i32> %167
  %171 = add nuw nsw <4 x i32> %170, <i32 32, i32 32, i32 32, i32 32>
  %172 = lshr <4 x i32> %171, <i32 6, i32 6, i32 6, i32 6>
  %173 = shufflevector <8 x i16> %159, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %174 = shufflevector <8 x i16> %162, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %175 = bitcast <8 x i16> %173 to <4 x i32>
  %176 = bitcast <8 x i16> %174 to <4 x i32>
  %177 = sub <4 x i32> %175, %176
  %178 = sub <4 x i32> zeroinitializer, %177
  %179 = icmp slt <4 x i32> %177, zeroinitializer
  %180 = select <4 x i1> %179, <4 x i32> %178, <4 x i32> %177
  %181 = add nuw <4 x i32> %180, <i32 32, i32 32, i32 32, i32 32>
  %182 = lshr <4 x i32> %181, <i32 6, i32 6, i32 6, i32 6>
  %183 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %172, <4 x i32> %182) #5
  %184 = lshr <8 x i16> %183, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %185 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %156, <8 x i16> %184) #5
  %186 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %185, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %187 = icmp slt <16 x i8> %186, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %188 = select <16 x i1> %187, <16 x i8> %186, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %189 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %188
  %190 = bitcast i8* %130 to <16 x i8>*
  store <16 x i8> %189, <16 x i8>* %190, align 16
  %191 = getelementptr inbounds i8, i8* %0, i64 96
  %192 = getelementptr inbounds i8, i8* %1, i64 96
  %193 = getelementptr inbounds i8, i8* %130, i64 16
  %194 = bitcast i8* %191 to <8 x i16>*
  %195 = load <8 x i16>, <8 x i16>* %194, align 16
  %196 = bitcast i8* %192 to <8 x i16>*
  %197 = load <8 x i16>, <8 x i16>* %196, align 16
  %198 = shufflevector <8 x i16> %195, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %199 = zext <4 x i16> %198 to <4 x i32>
  %200 = shufflevector <8 x i16> %197, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %201 = zext <4 x i16> %200 to <4 x i32>
  %202 = sub nsw <4 x i32> %199, %201
  %203 = sub nsw <4 x i32> zeroinitializer, %202
  %204 = icmp slt <4 x i32> %202, zeroinitializer
  %205 = select <4 x i1> %204, <4 x i32> %203, <4 x i32> %202
  %206 = add nuw nsw <4 x i32> %205, <i32 32, i32 32, i32 32, i32 32>
  %207 = lshr <4 x i32> %206, <i32 6, i32 6, i32 6, i32 6>
  %208 = shufflevector <8 x i16> %195, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %209 = shufflevector <8 x i16> %197, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %210 = bitcast <8 x i16> %208 to <4 x i32>
  %211 = bitcast <8 x i16> %209 to <4 x i32>
  %212 = sub <4 x i32> %210, %211
  %213 = sub <4 x i32> zeroinitializer, %212
  %214 = icmp slt <4 x i32> %212, zeroinitializer
  %215 = select <4 x i1> %214, <4 x i32> %213, <4 x i32> %212
  %216 = add nuw <4 x i32> %215, <i32 32, i32 32, i32 32, i32 32>
  %217 = lshr <4 x i32> %216, <i32 6, i32 6, i32 6, i32 6>
  %218 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %207, <4 x i32> %217) #5
  %219 = lshr <8 x i16> %218, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %220 = getelementptr inbounds i8, i8* %0, i64 112
  %221 = bitcast i8* %220 to <8 x i16>*
  %222 = load <8 x i16>, <8 x i16>* %221, align 16
  %223 = getelementptr inbounds i8, i8* %1, i64 112
  %224 = bitcast i8* %223 to <8 x i16>*
  %225 = load <8 x i16>, <8 x i16>* %224, align 16
  %226 = shufflevector <8 x i16> %222, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %227 = zext <4 x i16> %226 to <4 x i32>
  %228 = shufflevector <8 x i16> %225, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %229 = zext <4 x i16> %228 to <4 x i32>
  %230 = sub nsw <4 x i32> %227, %229
  %231 = sub nsw <4 x i32> zeroinitializer, %230
  %232 = icmp slt <4 x i32> %230, zeroinitializer
  %233 = select <4 x i1> %232, <4 x i32> %231, <4 x i32> %230
  %234 = add nuw nsw <4 x i32> %233, <i32 32, i32 32, i32 32, i32 32>
  %235 = lshr <4 x i32> %234, <i32 6, i32 6, i32 6, i32 6>
  %236 = shufflevector <8 x i16> %222, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %237 = shufflevector <8 x i16> %225, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %238 = bitcast <8 x i16> %236 to <4 x i32>
  %239 = bitcast <8 x i16> %237 to <4 x i32>
  %240 = sub <4 x i32> %238, %239
  %241 = sub <4 x i32> zeroinitializer, %240
  %242 = icmp slt <4 x i32> %240, zeroinitializer
  %243 = select <4 x i1> %242, <4 x i32> %241, <4 x i32> %240
  %244 = add nuw <4 x i32> %243, <i32 32, i32 32, i32 32, i32 32>
  %245 = lshr <4 x i32> %244, <i32 6, i32 6, i32 6, i32 6>
  %246 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %235, <4 x i32> %245) #5
  %247 = lshr <8 x i16> %246, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %248 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %219, <8 x i16> %247) #5
  %249 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %248, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %250 = icmp slt <16 x i8> %249, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %251 = select <16 x i1> %250, <16 x i8> %249, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %252 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %251
  %253 = bitcast i8* %193 to <16 x i8>*
  store <16 x i8> %252, <16 x i8>* %253, align 16
  %254 = getelementptr inbounds i8, i8* %0, i64 128
  %255 = getelementptr inbounds i8, i8* %1, i64 128
  %256 = getelementptr inbounds i8, i8* %130, i64 %3
  %257 = bitcast i8* %254 to <8 x i16>*
  %258 = load <8 x i16>, <8 x i16>* %257, align 16
  %259 = bitcast i8* %255 to <8 x i16>*
  %260 = load <8 x i16>, <8 x i16>* %259, align 16
  %261 = shufflevector <8 x i16> %258, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %262 = zext <4 x i16> %261 to <4 x i32>
  %263 = shufflevector <8 x i16> %260, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %264 = zext <4 x i16> %263 to <4 x i32>
  %265 = sub nsw <4 x i32> %262, %264
  %266 = sub nsw <4 x i32> zeroinitializer, %265
  %267 = icmp slt <4 x i32> %265, zeroinitializer
  %268 = select <4 x i1> %267, <4 x i32> %266, <4 x i32> %265
  %269 = add nuw nsw <4 x i32> %268, <i32 32, i32 32, i32 32, i32 32>
  %270 = lshr <4 x i32> %269, <i32 6, i32 6, i32 6, i32 6>
  %271 = shufflevector <8 x i16> %258, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %272 = shufflevector <8 x i16> %260, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %273 = bitcast <8 x i16> %271 to <4 x i32>
  %274 = bitcast <8 x i16> %272 to <4 x i32>
  %275 = sub <4 x i32> %273, %274
  %276 = sub <4 x i32> zeroinitializer, %275
  %277 = icmp slt <4 x i32> %275, zeroinitializer
  %278 = select <4 x i1> %277, <4 x i32> %276, <4 x i32> %275
  %279 = add nuw <4 x i32> %278, <i32 32, i32 32, i32 32, i32 32>
  %280 = lshr <4 x i32> %279, <i32 6, i32 6, i32 6, i32 6>
  %281 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %270, <4 x i32> %280) #5
  %282 = lshr <8 x i16> %281, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %283 = getelementptr inbounds i8, i8* %0, i64 144
  %284 = bitcast i8* %283 to <8 x i16>*
  %285 = load <8 x i16>, <8 x i16>* %284, align 16
  %286 = getelementptr inbounds i8, i8* %1, i64 144
  %287 = bitcast i8* %286 to <8 x i16>*
  %288 = load <8 x i16>, <8 x i16>* %287, align 16
  %289 = shufflevector <8 x i16> %285, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %290 = zext <4 x i16> %289 to <4 x i32>
  %291 = shufflevector <8 x i16> %288, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %292 = zext <4 x i16> %291 to <4 x i32>
  %293 = sub nsw <4 x i32> %290, %292
  %294 = sub nsw <4 x i32> zeroinitializer, %293
  %295 = icmp slt <4 x i32> %293, zeroinitializer
  %296 = select <4 x i1> %295, <4 x i32> %294, <4 x i32> %293
  %297 = add nuw nsw <4 x i32> %296, <i32 32, i32 32, i32 32, i32 32>
  %298 = lshr <4 x i32> %297, <i32 6, i32 6, i32 6, i32 6>
  %299 = shufflevector <8 x i16> %285, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %300 = shufflevector <8 x i16> %288, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %301 = bitcast <8 x i16> %299 to <4 x i32>
  %302 = bitcast <8 x i16> %300 to <4 x i32>
  %303 = sub <4 x i32> %301, %302
  %304 = sub <4 x i32> zeroinitializer, %303
  %305 = icmp slt <4 x i32> %303, zeroinitializer
  %306 = select <4 x i1> %305, <4 x i32> %304, <4 x i32> %303
  %307 = add nuw <4 x i32> %306, <i32 32, i32 32, i32 32, i32 32>
  %308 = lshr <4 x i32> %307, <i32 6, i32 6, i32 6, i32 6>
  %309 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %298, <4 x i32> %308) #5
  %310 = lshr <8 x i16> %309, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %311 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %282, <8 x i16> %310) #5
  %312 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %311, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %313 = icmp slt <16 x i8> %312, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %314 = select <16 x i1> %313, <16 x i8> %312, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %315 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %314
  %316 = bitcast i8* %256 to <16 x i8>*
  store <16 x i8> %315, <16 x i8>* %316, align 16
  %317 = getelementptr inbounds i8, i8* %0, i64 160
  %318 = getelementptr inbounds i8, i8* %1, i64 160
  %319 = getelementptr inbounds i8, i8* %256, i64 16
  %320 = bitcast i8* %317 to <8 x i16>*
  %321 = load <8 x i16>, <8 x i16>* %320, align 16
  %322 = bitcast i8* %318 to <8 x i16>*
  %323 = load <8 x i16>, <8 x i16>* %322, align 16
  %324 = shufflevector <8 x i16> %321, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %325 = zext <4 x i16> %324 to <4 x i32>
  %326 = shufflevector <8 x i16> %323, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %327 = zext <4 x i16> %326 to <4 x i32>
  %328 = sub nsw <4 x i32> %325, %327
  %329 = sub nsw <4 x i32> zeroinitializer, %328
  %330 = icmp slt <4 x i32> %328, zeroinitializer
  %331 = select <4 x i1> %330, <4 x i32> %329, <4 x i32> %328
  %332 = add nuw nsw <4 x i32> %331, <i32 32, i32 32, i32 32, i32 32>
  %333 = lshr <4 x i32> %332, <i32 6, i32 6, i32 6, i32 6>
  %334 = shufflevector <8 x i16> %321, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %335 = shufflevector <8 x i16> %323, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %336 = bitcast <8 x i16> %334 to <4 x i32>
  %337 = bitcast <8 x i16> %335 to <4 x i32>
  %338 = sub <4 x i32> %336, %337
  %339 = sub <4 x i32> zeroinitializer, %338
  %340 = icmp slt <4 x i32> %338, zeroinitializer
  %341 = select <4 x i1> %340, <4 x i32> %339, <4 x i32> %338
  %342 = add nuw <4 x i32> %341, <i32 32, i32 32, i32 32, i32 32>
  %343 = lshr <4 x i32> %342, <i32 6, i32 6, i32 6, i32 6>
  %344 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %333, <4 x i32> %343) #5
  %345 = lshr <8 x i16> %344, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %346 = getelementptr inbounds i8, i8* %0, i64 176
  %347 = bitcast i8* %346 to <8 x i16>*
  %348 = load <8 x i16>, <8 x i16>* %347, align 16
  %349 = getelementptr inbounds i8, i8* %1, i64 176
  %350 = bitcast i8* %349 to <8 x i16>*
  %351 = load <8 x i16>, <8 x i16>* %350, align 16
  %352 = shufflevector <8 x i16> %348, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %353 = zext <4 x i16> %352 to <4 x i32>
  %354 = shufflevector <8 x i16> %351, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %355 = zext <4 x i16> %354 to <4 x i32>
  %356 = sub nsw <4 x i32> %353, %355
  %357 = sub nsw <4 x i32> zeroinitializer, %356
  %358 = icmp slt <4 x i32> %356, zeroinitializer
  %359 = select <4 x i1> %358, <4 x i32> %357, <4 x i32> %356
  %360 = add nuw nsw <4 x i32> %359, <i32 32, i32 32, i32 32, i32 32>
  %361 = lshr <4 x i32> %360, <i32 6, i32 6, i32 6, i32 6>
  %362 = shufflevector <8 x i16> %348, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %363 = shufflevector <8 x i16> %351, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %364 = bitcast <8 x i16> %362 to <4 x i32>
  %365 = bitcast <8 x i16> %363 to <4 x i32>
  %366 = sub <4 x i32> %364, %365
  %367 = sub <4 x i32> zeroinitializer, %366
  %368 = icmp slt <4 x i32> %366, zeroinitializer
  %369 = select <4 x i1> %368, <4 x i32> %367, <4 x i32> %366
  %370 = add nuw <4 x i32> %369, <i32 32, i32 32, i32 32, i32 32>
  %371 = lshr <4 x i32> %370, <i32 6, i32 6, i32 6, i32 6>
  %372 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %361, <4 x i32> %371) #5
  %373 = lshr <8 x i16> %372, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %374 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %345, <8 x i16> %373) #5
  %375 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %374, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %376 = icmp slt <16 x i8> %375, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %377 = select <16 x i1> %376, <16 x i8> %375, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %378 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %377
  %379 = bitcast i8* %319 to <16 x i8>*
  store <16 x i8> %378, <16 x i8>* %379, align 16
  %380 = getelementptr inbounds i8, i8* %0, i64 192
  %381 = getelementptr inbounds i8, i8* %1, i64 192
  %382 = getelementptr inbounds i8, i8* %256, i64 %3
  %383 = bitcast i8* %380 to <8 x i16>*
  %384 = load <8 x i16>, <8 x i16>* %383, align 16
  %385 = bitcast i8* %381 to <8 x i16>*
  %386 = load <8 x i16>, <8 x i16>* %385, align 16
  %387 = shufflevector <8 x i16> %384, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %388 = zext <4 x i16> %387 to <4 x i32>
  %389 = shufflevector <8 x i16> %386, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %390 = zext <4 x i16> %389 to <4 x i32>
  %391 = sub nsw <4 x i32> %388, %390
  %392 = sub nsw <4 x i32> zeroinitializer, %391
  %393 = icmp slt <4 x i32> %391, zeroinitializer
  %394 = select <4 x i1> %393, <4 x i32> %392, <4 x i32> %391
  %395 = add nuw nsw <4 x i32> %394, <i32 32, i32 32, i32 32, i32 32>
  %396 = lshr <4 x i32> %395, <i32 6, i32 6, i32 6, i32 6>
  %397 = shufflevector <8 x i16> %384, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %398 = shufflevector <8 x i16> %386, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %399 = bitcast <8 x i16> %397 to <4 x i32>
  %400 = bitcast <8 x i16> %398 to <4 x i32>
  %401 = sub <4 x i32> %399, %400
  %402 = sub <4 x i32> zeroinitializer, %401
  %403 = icmp slt <4 x i32> %401, zeroinitializer
  %404 = select <4 x i1> %403, <4 x i32> %402, <4 x i32> %401
  %405 = add nuw <4 x i32> %404, <i32 32, i32 32, i32 32, i32 32>
  %406 = lshr <4 x i32> %405, <i32 6, i32 6, i32 6, i32 6>
  %407 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %396, <4 x i32> %406) #5
  %408 = lshr <8 x i16> %407, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %409 = getelementptr inbounds i8, i8* %0, i64 208
  %410 = bitcast i8* %409 to <8 x i16>*
  %411 = load <8 x i16>, <8 x i16>* %410, align 16
  %412 = getelementptr inbounds i8, i8* %1, i64 208
  %413 = bitcast i8* %412 to <8 x i16>*
  %414 = load <8 x i16>, <8 x i16>* %413, align 16
  %415 = shufflevector <8 x i16> %411, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %416 = zext <4 x i16> %415 to <4 x i32>
  %417 = shufflevector <8 x i16> %414, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %418 = zext <4 x i16> %417 to <4 x i32>
  %419 = sub nsw <4 x i32> %416, %418
  %420 = sub nsw <4 x i32> zeroinitializer, %419
  %421 = icmp slt <4 x i32> %419, zeroinitializer
  %422 = select <4 x i1> %421, <4 x i32> %420, <4 x i32> %419
  %423 = add nuw nsw <4 x i32> %422, <i32 32, i32 32, i32 32, i32 32>
  %424 = lshr <4 x i32> %423, <i32 6, i32 6, i32 6, i32 6>
  %425 = shufflevector <8 x i16> %411, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %426 = shufflevector <8 x i16> %414, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %427 = bitcast <8 x i16> %425 to <4 x i32>
  %428 = bitcast <8 x i16> %426 to <4 x i32>
  %429 = sub <4 x i32> %427, %428
  %430 = sub <4 x i32> zeroinitializer, %429
  %431 = icmp slt <4 x i32> %429, zeroinitializer
  %432 = select <4 x i1> %431, <4 x i32> %430, <4 x i32> %429
  %433 = add nuw <4 x i32> %432, <i32 32, i32 32, i32 32, i32 32>
  %434 = lshr <4 x i32> %433, <i32 6, i32 6, i32 6, i32 6>
  %435 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %424, <4 x i32> %434) #5
  %436 = lshr <8 x i16> %435, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %437 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %408, <8 x i16> %436) #5
  %438 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %437, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %439 = icmp slt <16 x i8> %438, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %440 = select <16 x i1> %439, <16 x i8> %438, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %441 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %440
  %442 = bitcast i8* %382 to <16 x i8>*
  store <16 x i8> %441, <16 x i8>* %442, align 16
  %443 = getelementptr inbounds i8, i8* %0, i64 224
  %444 = getelementptr inbounds i8, i8* %1, i64 224
  %445 = getelementptr inbounds i8, i8* %382, i64 16
  %446 = bitcast i8* %443 to <8 x i16>*
  %447 = load <8 x i16>, <8 x i16>* %446, align 16
  %448 = bitcast i8* %444 to <8 x i16>*
  %449 = load <8 x i16>, <8 x i16>* %448, align 16
  %450 = shufflevector <8 x i16> %447, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %451 = zext <4 x i16> %450 to <4 x i32>
  %452 = shufflevector <8 x i16> %449, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %453 = zext <4 x i16> %452 to <4 x i32>
  %454 = sub nsw <4 x i32> %451, %453
  %455 = sub nsw <4 x i32> zeroinitializer, %454
  %456 = icmp slt <4 x i32> %454, zeroinitializer
  %457 = select <4 x i1> %456, <4 x i32> %455, <4 x i32> %454
  %458 = add nuw nsw <4 x i32> %457, <i32 32, i32 32, i32 32, i32 32>
  %459 = lshr <4 x i32> %458, <i32 6, i32 6, i32 6, i32 6>
  %460 = shufflevector <8 x i16> %447, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %461 = shufflevector <8 x i16> %449, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %462 = bitcast <8 x i16> %460 to <4 x i32>
  %463 = bitcast <8 x i16> %461 to <4 x i32>
  %464 = sub <4 x i32> %462, %463
  %465 = sub <4 x i32> zeroinitializer, %464
  %466 = icmp slt <4 x i32> %464, zeroinitializer
  %467 = select <4 x i1> %466, <4 x i32> %465, <4 x i32> %464
  %468 = add nuw <4 x i32> %467, <i32 32, i32 32, i32 32, i32 32>
  %469 = lshr <4 x i32> %468, <i32 6, i32 6, i32 6, i32 6>
  %470 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %459, <4 x i32> %469) #5
  %471 = lshr <8 x i16> %470, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %472 = getelementptr inbounds i8, i8* %0, i64 240
  %473 = bitcast i8* %472 to <8 x i16>*
  %474 = load <8 x i16>, <8 x i16>* %473, align 16
  %475 = getelementptr inbounds i8, i8* %1, i64 240
  %476 = bitcast i8* %475 to <8 x i16>*
  %477 = load <8 x i16>, <8 x i16>* %476, align 16
  %478 = shufflevector <8 x i16> %474, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %479 = zext <4 x i16> %478 to <4 x i32>
  %480 = shufflevector <8 x i16> %477, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %481 = zext <4 x i16> %480 to <4 x i32>
  %482 = sub nsw <4 x i32> %479, %481
  %483 = sub nsw <4 x i32> zeroinitializer, %482
  %484 = icmp slt <4 x i32> %482, zeroinitializer
  %485 = select <4 x i1> %484, <4 x i32> %483, <4 x i32> %482
  %486 = add nuw nsw <4 x i32> %485, <i32 32, i32 32, i32 32, i32 32>
  %487 = lshr <4 x i32> %486, <i32 6, i32 6, i32 6, i32 6>
  %488 = shufflevector <8 x i16> %474, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %489 = shufflevector <8 x i16> %477, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %490 = bitcast <8 x i16> %488 to <4 x i32>
  %491 = bitcast <8 x i16> %489 to <4 x i32>
  %492 = sub <4 x i32> %490, %491
  %493 = sub <4 x i32> zeroinitializer, %492
  %494 = icmp slt <4 x i32> %492, zeroinitializer
  %495 = select <4 x i1> %494, <4 x i32> %493, <4 x i32> %492
  %496 = add nuw <4 x i32> %495, <i32 32, i32 32, i32 32, i32 32>
  %497 = lshr <4 x i32> %496, <i32 6, i32 6, i32 6, i32 6>
  %498 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %487, <4 x i32> %497) #5
  %499 = lshr <8 x i16> %498, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %500 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %471, <8 x i16> %499) #5
  %501 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %500, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %502 = icmp slt <16 x i8> %501, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %503 = select <16 x i1> %502, <16 x i8> %501, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %504 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %503
  %505 = bitcast i8* %445 to <16 x i8>*
  store <16 x i8> %504, <16 x i8>* %505, align 16
  %506 = getelementptr inbounds i8, i8* %0, i64 256
  %507 = getelementptr inbounds i8, i8* %1, i64 256
  %508 = getelementptr inbounds i8, i8* %382, i64 %3
  %509 = bitcast i8* %506 to <8 x i16>*
  %510 = load <8 x i16>, <8 x i16>* %509, align 16
  %511 = bitcast i8* %507 to <8 x i16>*
  %512 = load <8 x i16>, <8 x i16>* %511, align 16
  %513 = shufflevector <8 x i16> %510, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %514 = zext <4 x i16> %513 to <4 x i32>
  %515 = shufflevector <8 x i16> %512, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %516 = zext <4 x i16> %515 to <4 x i32>
  %517 = sub nsw <4 x i32> %514, %516
  %518 = sub nsw <4 x i32> zeroinitializer, %517
  %519 = icmp slt <4 x i32> %517, zeroinitializer
  %520 = select <4 x i1> %519, <4 x i32> %518, <4 x i32> %517
  %521 = add nuw nsw <4 x i32> %520, <i32 32, i32 32, i32 32, i32 32>
  %522 = lshr <4 x i32> %521, <i32 6, i32 6, i32 6, i32 6>
  %523 = shufflevector <8 x i16> %510, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %524 = shufflevector <8 x i16> %512, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %525 = bitcast <8 x i16> %523 to <4 x i32>
  %526 = bitcast <8 x i16> %524 to <4 x i32>
  %527 = sub <4 x i32> %525, %526
  %528 = sub <4 x i32> zeroinitializer, %527
  %529 = icmp slt <4 x i32> %527, zeroinitializer
  %530 = select <4 x i1> %529, <4 x i32> %528, <4 x i32> %527
  %531 = add nuw <4 x i32> %530, <i32 32, i32 32, i32 32, i32 32>
  %532 = lshr <4 x i32> %531, <i32 6, i32 6, i32 6, i32 6>
  %533 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %522, <4 x i32> %532) #5
  %534 = lshr <8 x i16> %533, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %535 = getelementptr inbounds i8, i8* %0, i64 272
  %536 = bitcast i8* %535 to <8 x i16>*
  %537 = load <8 x i16>, <8 x i16>* %536, align 16
  %538 = getelementptr inbounds i8, i8* %1, i64 272
  %539 = bitcast i8* %538 to <8 x i16>*
  %540 = load <8 x i16>, <8 x i16>* %539, align 16
  %541 = shufflevector <8 x i16> %537, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %542 = zext <4 x i16> %541 to <4 x i32>
  %543 = shufflevector <8 x i16> %540, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %544 = zext <4 x i16> %543 to <4 x i32>
  %545 = sub nsw <4 x i32> %542, %544
  %546 = sub nsw <4 x i32> zeroinitializer, %545
  %547 = icmp slt <4 x i32> %545, zeroinitializer
  %548 = select <4 x i1> %547, <4 x i32> %546, <4 x i32> %545
  %549 = add nuw nsw <4 x i32> %548, <i32 32, i32 32, i32 32, i32 32>
  %550 = lshr <4 x i32> %549, <i32 6, i32 6, i32 6, i32 6>
  %551 = shufflevector <8 x i16> %537, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %552 = shufflevector <8 x i16> %540, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %553 = bitcast <8 x i16> %551 to <4 x i32>
  %554 = bitcast <8 x i16> %552 to <4 x i32>
  %555 = sub <4 x i32> %553, %554
  %556 = sub <4 x i32> zeroinitializer, %555
  %557 = icmp slt <4 x i32> %555, zeroinitializer
  %558 = select <4 x i1> %557, <4 x i32> %556, <4 x i32> %555
  %559 = add nuw <4 x i32> %558, <i32 32, i32 32, i32 32, i32 32>
  %560 = lshr <4 x i32> %559, <i32 6, i32 6, i32 6, i32 6>
  %561 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %550, <4 x i32> %560) #5
  %562 = lshr <8 x i16> %561, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %563 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %534, <8 x i16> %562) #5
  %564 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %563, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %565 = icmp slt <16 x i8> %564, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %566 = select <16 x i1> %565, <16 x i8> %564, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %567 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %566
  %568 = bitcast i8* %508 to <16 x i8>*
  store <16 x i8> %567, <16 x i8>* %568, align 16
  %569 = getelementptr inbounds i8, i8* %0, i64 288
  %570 = getelementptr inbounds i8, i8* %1, i64 288
  %571 = getelementptr inbounds i8, i8* %508, i64 16
  %572 = bitcast i8* %569 to <8 x i16>*
  %573 = load <8 x i16>, <8 x i16>* %572, align 16
  %574 = bitcast i8* %570 to <8 x i16>*
  %575 = load <8 x i16>, <8 x i16>* %574, align 16
  %576 = shufflevector <8 x i16> %573, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %577 = zext <4 x i16> %576 to <4 x i32>
  %578 = shufflevector <8 x i16> %575, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %579 = zext <4 x i16> %578 to <4 x i32>
  %580 = sub nsw <4 x i32> %577, %579
  %581 = sub nsw <4 x i32> zeroinitializer, %580
  %582 = icmp slt <4 x i32> %580, zeroinitializer
  %583 = select <4 x i1> %582, <4 x i32> %581, <4 x i32> %580
  %584 = add nuw nsw <4 x i32> %583, <i32 32, i32 32, i32 32, i32 32>
  %585 = lshr <4 x i32> %584, <i32 6, i32 6, i32 6, i32 6>
  %586 = shufflevector <8 x i16> %573, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %587 = shufflevector <8 x i16> %575, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %588 = bitcast <8 x i16> %586 to <4 x i32>
  %589 = bitcast <8 x i16> %587 to <4 x i32>
  %590 = sub <4 x i32> %588, %589
  %591 = sub <4 x i32> zeroinitializer, %590
  %592 = icmp slt <4 x i32> %590, zeroinitializer
  %593 = select <4 x i1> %592, <4 x i32> %591, <4 x i32> %590
  %594 = add nuw <4 x i32> %593, <i32 32, i32 32, i32 32, i32 32>
  %595 = lshr <4 x i32> %594, <i32 6, i32 6, i32 6, i32 6>
  %596 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %585, <4 x i32> %595) #5
  %597 = lshr <8 x i16> %596, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %598 = getelementptr inbounds i8, i8* %0, i64 304
  %599 = bitcast i8* %598 to <8 x i16>*
  %600 = load <8 x i16>, <8 x i16>* %599, align 16
  %601 = getelementptr inbounds i8, i8* %1, i64 304
  %602 = bitcast i8* %601 to <8 x i16>*
  %603 = load <8 x i16>, <8 x i16>* %602, align 16
  %604 = shufflevector <8 x i16> %600, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %605 = zext <4 x i16> %604 to <4 x i32>
  %606 = shufflevector <8 x i16> %603, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %607 = zext <4 x i16> %606 to <4 x i32>
  %608 = sub nsw <4 x i32> %605, %607
  %609 = sub nsw <4 x i32> zeroinitializer, %608
  %610 = icmp slt <4 x i32> %608, zeroinitializer
  %611 = select <4 x i1> %610, <4 x i32> %609, <4 x i32> %608
  %612 = add nuw nsw <4 x i32> %611, <i32 32, i32 32, i32 32, i32 32>
  %613 = lshr <4 x i32> %612, <i32 6, i32 6, i32 6, i32 6>
  %614 = shufflevector <8 x i16> %600, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %615 = shufflevector <8 x i16> %603, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %616 = bitcast <8 x i16> %614 to <4 x i32>
  %617 = bitcast <8 x i16> %615 to <4 x i32>
  %618 = sub <4 x i32> %616, %617
  %619 = sub <4 x i32> zeroinitializer, %618
  %620 = icmp slt <4 x i32> %618, zeroinitializer
  %621 = select <4 x i1> %620, <4 x i32> %619, <4 x i32> %618
  %622 = add nuw <4 x i32> %621, <i32 32, i32 32, i32 32, i32 32>
  %623 = lshr <4 x i32> %622, <i32 6, i32 6, i32 6, i32 6>
  %624 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %613, <4 x i32> %623) #5
  %625 = lshr <8 x i16> %624, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %626 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %597, <8 x i16> %625) #5
  %627 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %626, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %628 = icmp slt <16 x i8> %627, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %629 = select <16 x i1> %628, <16 x i8> %627, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %630 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %629
  %631 = bitcast i8* %571 to <16 x i8>*
  store <16 x i8> %630, <16 x i8>* %631, align 16
  %632 = getelementptr inbounds i8, i8* %0, i64 320
  %633 = getelementptr inbounds i8, i8* %1, i64 320
  %634 = getelementptr inbounds i8, i8* %508, i64 %3
  %635 = bitcast i8* %632 to <8 x i16>*
  %636 = load <8 x i16>, <8 x i16>* %635, align 16
  %637 = bitcast i8* %633 to <8 x i16>*
  %638 = load <8 x i16>, <8 x i16>* %637, align 16
  %639 = shufflevector <8 x i16> %636, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %640 = zext <4 x i16> %639 to <4 x i32>
  %641 = shufflevector <8 x i16> %638, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %642 = zext <4 x i16> %641 to <4 x i32>
  %643 = sub nsw <4 x i32> %640, %642
  %644 = sub nsw <4 x i32> zeroinitializer, %643
  %645 = icmp slt <4 x i32> %643, zeroinitializer
  %646 = select <4 x i1> %645, <4 x i32> %644, <4 x i32> %643
  %647 = add nuw nsw <4 x i32> %646, <i32 32, i32 32, i32 32, i32 32>
  %648 = lshr <4 x i32> %647, <i32 6, i32 6, i32 6, i32 6>
  %649 = shufflevector <8 x i16> %636, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %650 = shufflevector <8 x i16> %638, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %651 = bitcast <8 x i16> %649 to <4 x i32>
  %652 = bitcast <8 x i16> %650 to <4 x i32>
  %653 = sub <4 x i32> %651, %652
  %654 = sub <4 x i32> zeroinitializer, %653
  %655 = icmp slt <4 x i32> %653, zeroinitializer
  %656 = select <4 x i1> %655, <4 x i32> %654, <4 x i32> %653
  %657 = add nuw <4 x i32> %656, <i32 32, i32 32, i32 32, i32 32>
  %658 = lshr <4 x i32> %657, <i32 6, i32 6, i32 6, i32 6>
  %659 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %648, <4 x i32> %658) #5
  %660 = lshr <8 x i16> %659, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %661 = getelementptr inbounds i8, i8* %0, i64 336
  %662 = bitcast i8* %661 to <8 x i16>*
  %663 = load <8 x i16>, <8 x i16>* %662, align 16
  %664 = getelementptr inbounds i8, i8* %1, i64 336
  %665 = bitcast i8* %664 to <8 x i16>*
  %666 = load <8 x i16>, <8 x i16>* %665, align 16
  %667 = shufflevector <8 x i16> %663, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %668 = zext <4 x i16> %667 to <4 x i32>
  %669 = shufflevector <8 x i16> %666, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %670 = zext <4 x i16> %669 to <4 x i32>
  %671 = sub nsw <4 x i32> %668, %670
  %672 = sub nsw <4 x i32> zeroinitializer, %671
  %673 = icmp slt <4 x i32> %671, zeroinitializer
  %674 = select <4 x i1> %673, <4 x i32> %672, <4 x i32> %671
  %675 = add nuw nsw <4 x i32> %674, <i32 32, i32 32, i32 32, i32 32>
  %676 = lshr <4 x i32> %675, <i32 6, i32 6, i32 6, i32 6>
  %677 = shufflevector <8 x i16> %663, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %678 = shufflevector <8 x i16> %666, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %679 = bitcast <8 x i16> %677 to <4 x i32>
  %680 = bitcast <8 x i16> %678 to <4 x i32>
  %681 = sub <4 x i32> %679, %680
  %682 = sub <4 x i32> zeroinitializer, %681
  %683 = icmp slt <4 x i32> %681, zeroinitializer
  %684 = select <4 x i1> %683, <4 x i32> %682, <4 x i32> %681
  %685 = add nuw <4 x i32> %684, <i32 32, i32 32, i32 32, i32 32>
  %686 = lshr <4 x i32> %685, <i32 6, i32 6, i32 6, i32 6>
  %687 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %676, <4 x i32> %686) #5
  %688 = lshr <8 x i16> %687, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %689 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %660, <8 x i16> %688) #5
  %690 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %689, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %691 = icmp slt <16 x i8> %690, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %692 = select <16 x i1> %691, <16 x i8> %690, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %693 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %692
  %694 = bitcast i8* %634 to <16 x i8>*
  store <16 x i8> %693, <16 x i8>* %694, align 16
  %695 = getelementptr inbounds i8, i8* %0, i64 352
  %696 = getelementptr inbounds i8, i8* %1, i64 352
  %697 = getelementptr inbounds i8, i8* %634, i64 16
  %698 = bitcast i8* %695 to <8 x i16>*
  %699 = load <8 x i16>, <8 x i16>* %698, align 16
  %700 = bitcast i8* %696 to <8 x i16>*
  %701 = load <8 x i16>, <8 x i16>* %700, align 16
  %702 = shufflevector <8 x i16> %699, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %703 = zext <4 x i16> %702 to <4 x i32>
  %704 = shufflevector <8 x i16> %701, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %705 = zext <4 x i16> %704 to <4 x i32>
  %706 = sub nsw <4 x i32> %703, %705
  %707 = sub nsw <4 x i32> zeroinitializer, %706
  %708 = icmp slt <4 x i32> %706, zeroinitializer
  %709 = select <4 x i1> %708, <4 x i32> %707, <4 x i32> %706
  %710 = add nuw nsw <4 x i32> %709, <i32 32, i32 32, i32 32, i32 32>
  %711 = lshr <4 x i32> %710, <i32 6, i32 6, i32 6, i32 6>
  %712 = shufflevector <8 x i16> %699, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %713 = shufflevector <8 x i16> %701, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %714 = bitcast <8 x i16> %712 to <4 x i32>
  %715 = bitcast <8 x i16> %713 to <4 x i32>
  %716 = sub <4 x i32> %714, %715
  %717 = sub <4 x i32> zeroinitializer, %716
  %718 = icmp slt <4 x i32> %716, zeroinitializer
  %719 = select <4 x i1> %718, <4 x i32> %717, <4 x i32> %716
  %720 = add nuw <4 x i32> %719, <i32 32, i32 32, i32 32, i32 32>
  %721 = lshr <4 x i32> %720, <i32 6, i32 6, i32 6, i32 6>
  %722 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %711, <4 x i32> %721) #5
  %723 = lshr <8 x i16> %722, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %724 = getelementptr inbounds i8, i8* %0, i64 368
  %725 = bitcast i8* %724 to <8 x i16>*
  %726 = load <8 x i16>, <8 x i16>* %725, align 16
  %727 = getelementptr inbounds i8, i8* %1, i64 368
  %728 = bitcast i8* %727 to <8 x i16>*
  %729 = load <8 x i16>, <8 x i16>* %728, align 16
  %730 = shufflevector <8 x i16> %726, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %731 = zext <4 x i16> %730 to <4 x i32>
  %732 = shufflevector <8 x i16> %729, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %733 = zext <4 x i16> %732 to <4 x i32>
  %734 = sub nsw <4 x i32> %731, %733
  %735 = sub nsw <4 x i32> zeroinitializer, %734
  %736 = icmp slt <4 x i32> %734, zeroinitializer
  %737 = select <4 x i1> %736, <4 x i32> %735, <4 x i32> %734
  %738 = add nuw nsw <4 x i32> %737, <i32 32, i32 32, i32 32, i32 32>
  %739 = lshr <4 x i32> %738, <i32 6, i32 6, i32 6, i32 6>
  %740 = shufflevector <8 x i16> %726, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %741 = shufflevector <8 x i16> %729, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %742 = bitcast <8 x i16> %740 to <4 x i32>
  %743 = bitcast <8 x i16> %741 to <4 x i32>
  %744 = sub <4 x i32> %742, %743
  %745 = sub <4 x i32> zeroinitializer, %744
  %746 = icmp slt <4 x i32> %744, zeroinitializer
  %747 = select <4 x i1> %746, <4 x i32> %745, <4 x i32> %744
  %748 = add nuw <4 x i32> %747, <i32 32, i32 32, i32 32, i32 32>
  %749 = lshr <4 x i32> %748, <i32 6, i32 6, i32 6, i32 6>
  %750 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %739, <4 x i32> %749) #5
  %751 = lshr <8 x i16> %750, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %752 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %723, <8 x i16> %751) #5
  %753 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %752, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %754 = icmp slt <16 x i8> %753, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %755 = select <16 x i1> %754, <16 x i8> %753, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %756 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %755
  %757 = bitcast i8* %697 to <16 x i8>*
  store <16 x i8> %756, <16 x i8>* %757, align 16
  %758 = getelementptr inbounds i8, i8* %0, i64 384
  %759 = getelementptr inbounds i8, i8* %1, i64 384
  %760 = getelementptr inbounds i8, i8* %634, i64 %3
  %761 = bitcast i8* %758 to <8 x i16>*
  %762 = load <8 x i16>, <8 x i16>* %761, align 16
  %763 = bitcast i8* %759 to <8 x i16>*
  %764 = load <8 x i16>, <8 x i16>* %763, align 16
  %765 = shufflevector <8 x i16> %762, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %766 = zext <4 x i16> %765 to <4 x i32>
  %767 = shufflevector <8 x i16> %764, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %768 = zext <4 x i16> %767 to <4 x i32>
  %769 = sub nsw <4 x i32> %766, %768
  %770 = sub nsw <4 x i32> zeroinitializer, %769
  %771 = icmp slt <4 x i32> %769, zeroinitializer
  %772 = select <4 x i1> %771, <4 x i32> %770, <4 x i32> %769
  %773 = add nuw nsw <4 x i32> %772, <i32 32, i32 32, i32 32, i32 32>
  %774 = lshr <4 x i32> %773, <i32 6, i32 6, i32 6, i32 6>
  %775 = shufflevector <8 x i16> %762, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %776 = shufflevector <8 x i16> %764, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %777 = bitcast <8 x i16> %775 to <4 x i32>
  %778 = bitcast <8 x i16> %776 to <4 x i32>
  %779 = sub <4 x i32> %777, %778
  %780 = sub <4 x i32> zeroinitializer, %779
  %781 = icmp slt <4 x i32> %779, zeroinitializer
  %782 = select <4 x i1> %781, <4 x i32> %780, <4 x i32> %779
  %783 = add nuw <4 x i32> %782, <i32 32, i32 32, i32 32, i32 32>
  %784 = lshr <4 x i32> %783, <i32 6, i32 6, i32 6, i32 6>
  %785 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %774, <4 x i32> %784) #5
  %786 = lshr <8 x i16> %785, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %787 = getelementptr inbounds i8, i8* %0, i64 400
  %788 = bitcast i8* %787 to <8 x i16>*
  %789 = load <8 x i16>, <8 x i16>* %788, align 16
  %790 = getelementptr inbounds i8, i8* %1, i64 400
  %791 = bitcast i8* %790 to <8 x i16>*
  %792 = load <8 x i16>, <8 x i16>* %791, align 16
  %793 = shufflevector <8 x i16> %789, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %794 = zext <4 x i16> %793 to <4 x i32>
  %795 = shufflevector <8 x i16> %792, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %796 = zext <4 x i16> %795 to <4 x i32>
  %797 = sub nsw <4 x i32> %794, %796
  %798 = sub nsw <4 x i32> zeroinitializer, %797
  %799 = icmp slt <4 x i32> %797, zeroinitializer
  %800 = select <4 x i1> %799, <4 x i32> %798, <4 x i32> %797
  %801 = add nuw nsw <4 x i32> %800, <i32 32, i32 32, i32 32, i32 32>
  %802 = lshr <4 x i32> %801, <i32 6, i32 6, i32 6, i32 6>
  %803 = shufflevector <8 x i16> %789, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %804 = shufflevector <8 x i16> %792, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %805 = bitcast <8 x i16> %803 to <4 x i32>
  %806 = bitcast <8 x i16> %804 to <4 x i32>
  %807 = sub <4 x i32> %805, %806
  %808 = sub <4 x i32> zeroinitializer, %807
  %809 = icmp slt <4 x i32> %807, zeroinitializer
  %810 = select <4 x i1> %809, <4 x i32> %808, <4 x i32> %807
  %811 = add nuw <4 x i32> %810, <i32 32, i32 32, i32 32, i32 32>
  %812 = lshr <4 x i32> %811, <i32 6, i32 6, i32 6, i32 6>
  %813 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %802, <4 x i32> %812) #5
  %814 = lshr <8 x i16> %813, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %815 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %786, <8 x i16> %814) #5
  %816 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %815, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %817 = icmp slt <16 x i8> %816, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %818 = select <16 x i1> %817, <16 x i8> %816, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %819 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %818
  %820 = bitcast i8* %760 to <16 x i8>*
  store <16 x i8> %819, <16 x i8>* %820, align 16
  %821 = getelementptr inbounds i8, i8* %0, i64 416
  %822 = getelementptr inbounds i8, i8* %1, i64 416
  %823 = getelementptr inbounds i8, i8* %760, i64 16
  %824 = bitcast i8* %821 to <8 x i16>*
  %825 = load <8 x i16>, <8 x i16>* %824, align 16
  %826 = bitcast i8* %822 to <8 x i16>*
  %827 = load <8 x i16>, <8 x i16>* %826, align 16
  %828 = shufflevector <8 x i16> %825, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %829 = zext <4 x i16> %828 to <4 x i32>
  %830 = shufflevector <8 x i16> %827, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %831 = zext <4 x i16> %830 to <4 x i32>
  %832 = sub nsw <4 x i32> %829, %831
  %833 = sub nsw <4 x i32> zeroinitializer, %832
  %834 = icmp slt <4 x i32> %832, zeroinitializer
  %835 = select <4 x i1> %834, <4 x i32> %833, <4 x i32> %832
  %836 = add nuw nsw <4 x i32> %835, <i32 32, i32 32, i32 32, i32 32>
  %837 = lshr <4 x i32> %836, <i32 6, i32 6, i32 6, i32 6>
  %838 = shufflevector <8 x i16> %825, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %839 = shufflevector <8 x i16> %827, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %840 = bitcast <8 x i16> %838 to <4 x i32>
  %841 = bitcast <8 x i16> %839 to <4 x i32>
  %842 = sub <4 x i32> %840, %841
  %843 = sub <4 x i32> zeroinitializer, %842
  %844 = icmp slt <4 x i32> %842, zeroinitializer
  %845 = select <4 x i1> %844, <4 x i32> %843, <4 x i32> %842
  %846 = add nuw <4 x i32> %845, <i32 32, i32 32, i32 32, i32 32>
  %847 = lshr <4 x i32> %846, <i32 6, i32 6, i32 6, i32 6>
  %848 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %837, <4 x i32> %847) #5
  %849 = lshr <8 x i16> %848, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %850 = getelementptr inbounds i8, i8* %0, i64 432
  %851 = bitcast i8* %850 to <8 x i16>*
  %852 = load <8 x i16>, <8 x i16>* %851, align 16
  %853 = getelementptr inbounds i8, i8* %1, i64 432
  %854 = bitcast i8* %853 to <8 x i16>*
  %855 = load <8 x i16>, <8 x i16>* %854, align 16
  %856 = shufflevector <8 x i16> %852, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %857 = zext <4 x i16> %856 to <4 x i32>
  %858 = shufflevector <8 x i16> %855, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %859 = zext <4 x i16> %858 to <4 x i32>
  %860 = sub nsw <4 x i32> %857, %859
  %861 = sub nsw <4 x i32> zeroinitializer, %860
  %862 = icmp slt <4 x i32> %860, zeroinitializer
  %863 = select <4 x i1> %862, <4 x i32> %861, <4 x i32> %860
  %864 = add nuw nsw <4 x i32> %863, <i32 32, i32 32, i32 32, i32 32>
  %865 = lshr <4 x i32> %864, <i32 6, i32 6, i32 6, i32 6>
  %866 = shufflevector <8 x i16> %852, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %867 = shufflevector <8 x i16> %855, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %868 = bitcast <8 x i16> %866 to <4 x i32>
  %869 = bitcast <8 x i16> %867 to <4 x i32>
  %870 = sub <4 x i32> %868, %869
  %871 = sub <4 x i32> zeroinitializer, %870
  %872 = icmp slt <4 x i32> %870, zeroinitializer
  %873 = select <4 x i1> %872, <4 x i32> %871, <4 x i32> %870
  %874 = add nuw <4 x i32> %873, <i32 32, i32 32, i32 32, i32 32>
  %875 = lshr <4 x i32> %874, <i32 6, i32 6, i32 6, i32 6>
  %876 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %865, <4 x i32> %875) #5
  %877 = lshr <8 x i16> %876, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %878 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %849, <8 x i16> %877) #5
  %879 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %878, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %880 = icmp slt <16 x i8> %879, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %881 = select <16 x i1> %880, <16 x i8> %879, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %882 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %881
  %883 = bitcast i8* %823 to <16 x i8>*
  store <16 x i8> %882, <16 x i8>* %883, align 16
  %884 = getelementptr inbounds i8, i8* %0, i64 448
  %885 = getelementptr inbounds i8, i8* %1, i64 448
  %886 = getelementptr inbounds i8, i8* %760, i64 %3
  %887 = bitcast i8* %884 to <8 x i16>*
  %888 = load <8 x i16>, <8 x i16>* %887, align 16
  %889 = bitcast i8* %885 to <8 x i16>*
  %890 = load <8 x i16>, <8 x i16>* %889, align 16
  %891 = shufflevector <8 x i16> %888, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %892 = zext <4 x i16> %891 to <4 x i32>
  %893 = shufflevector <8 x i16> %890, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %894 = zext <4 x i16> %893 to <4 x i32>
  %895 = sub nsw <4 x i32> %892, %894
  %896 = sub nsw <4 x i32> zeroinitializer, %895
  %897 = icmp slt <4 x i32> %895, zeroinitializer
  %898 = select <4 x i1> %897, <4 x i32> %896, <4 x i32> %895
  %899 = add nuw nsw <4 x i32> %898, <i32 32, i32 32, i32 32, i32 32>
  %900 = lshr <4 x i32> %899, <i32 6, i32 6, i32 6, i32 6>
  %901 = shufflevector <8 x i16> %888, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %902 = shufflevector <8 x i16> %890, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %903 = bitcast <8 x i16> %901 to <4 x i32>
  %904 = bitcast <8 x i16> %902 to <4 x i32>
  %905 = sub <4 x i32> %903, %904
  %906 = sub <4 x i32> zeroinitializer, %905
  %907 = icmp slt <4 x i32> %905, zeroinitializer
  %908 = select <4 x i1> %907, <4 x i32> %906, <4 x i32> %905
  %909 = add nuw <4 x i32> %908, <i32 32, i32 32, i32 32, i32 32>
  %910 = lshr <4 x i32> %909, <i32 6, i32 6, i32 6, i32 6>
  %911 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %900, <4 x i32> %910) #5
  %912 = lshr <8 x i16> %911, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %913 = getelementptr inbounds i8, i8* %0, i64 464
  %914 = bitcast i8* %913 to <8 x i16>*
  %915 = load <8 x i16>, <8 x i16>* %914, align 16
  %916 = getelementptr inbounds i8, i8* %1, i64 464
  %917 = bitcast i8* %916 to <8 x i16>*
  %918 = load <8 x i16>, <8 x i16>* %917, align 16
  %919 = shufflevector <8 x i16> %915, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %920 = zext <4 x i16> %919 to <4 x i32>
  %921 = shufflevector <8 x i16> %918, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %922 = zext <4 x i16> %921 to <4 x i32>
  %923 = sub nsw <4 x i32> %920, %922
  %924 = sub nsw <4 x i32> zeroinitializer, %923
  %925 = icmp slt <4 x i32> %923, zeroinitializer
  %926 = select <4 x i1> %925, <4 x i32> %924, <4 x i32> %923
  %927 = add nuw nsw <4 x i32> %926, <i32 32, i32 32, i32 32, i32 32>
  %928 = lshr <4 x i32> %927, <i32 6, i32 6, i32 6, i32 6>
  %929 = shufflevector <8 x i16> %915, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %930 = shufflevector <8 x i16> %918, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %931 = bitcast <8 x i16> %929 to <4 x i32>
  %932 = bitcast <8 x i16> %930 to <4 x i32>
  %933 = sub <4 x i32> %931, %932
  %934 = sub <4 x i32> zeroinitializer, %933
  %935 = icmp slt <4 x i32> %933, zeroinitializer
  %936 = select <4 x i1> %935, <4 x i32> %934, <4 x i32> %933
  %937 = add nuw <4 x i32> %936, <i32 32, i32 32, i32 32, i32 32>
  %938 = lshr <4 x i32> %937, <i32 6, i32 6, i32 6, i32 6>
  %939 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %928, <4 x i32> %938) #5
  %940 = lshr <8 x i16> %939, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %941 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %912, <8 x i16> %940) #5
  %942 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %941, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %943 = icmp slt <16 x i8> %942, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %944 = select <16 x i1> %943, <16 x i8> %942, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %945 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %944
  %946 = bitcast i8* %886 to <16 x i8>*
  store <16 x i8> %945, <16 x i8>* %946, align 16
  %947 = getelementptr inbounds i8, i8* %0, i64 480
  %948 = getelementptr inbounds i8, i8* %1, i64 480
  %949 = getelementptr inbounds i8, i8* %886, i64 16
  %950 = bitcast i8* %947 to <8 x i16>*
  %951 = load <8 x i16>, <8 x i16>* %950, align 16
  %952 = bitcast i8* %948 to <8 x i16>*
  %953 = load <8 x i16>, <8 x i16>* %952, align 16
  %954 = shufflevector <8 x i16> %951, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %955 = zext <4 x i16> %954 to <4 x i32>
  %956 = shufflevector <8 x i16> %953, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %957 = zext <4 x i16> %956 to <4 x i32>
  %958 = sub nsw <4 x i32> %955, %957
  %959 = sub nsw <4 x i32> zeroinitializer, %958
  %960 = icmp slt <4 x i32> %958, zeroinitializer
  %961 = select <4 x i1> %960, <4 x i32> %959, <4 x i32> %958
  %962 = add nuw nsw <4 x i32> %961, <i32 32, i32 32, i32 32, i32 32>
  %963 = lshr <4 x i32> %962, <i32 6, i32 6, i32 6, i32 6>
  %964 = shufflevector <8 x i16> %951, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %965 = shufflevector <8 x i16> %953, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %966 = bitcast <8 x i16> %964 to <4 x i32>
  %967 = bitcast <8 x i16> %965 to <4 x i32>
  %968 = sub <4 x i32> %966, %967
  %969 = sub <4 x i32> zeroinitializer, %968
  %970 = icmp slt <4 x i32> %968, zeroinitializer
  %971 = select <4 x i1> %970, <4 x i32> %969, <4 x i32> %968
  %972 = add nuw <4 x i32> %971, <i32 32, i32 32, i32 32, i32 32>
  %973 = lshr <4 x i32> %972, <i32 6, i32 6, i32 6, i32 6>
  %974 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %963, <4 x i32> %973) #5
  %975 = lshr <8 x i16> %974, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %976 = getelementptr inbounds i8, i8* %0, i64 496
  %977 = bitcast i8* %976 to <8 x i16>*
  %978 = load <8 x i16>, <8 x i16>* %977, align 16
  %979 = getelementptr inbounds i8, i8* %1, i64 496
  %980 = bitcast i8* %979 to <8 x i16>*
  %981 = load <8 x i16>, <8 x i16>* %980, align 16
  %982 = shufflevector <8 x i16> %978, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %983 = zext <4 x i16> %982 to <4 x i32>
  %984 = shufflevector <8 x i16> %981, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %985 = zext <4 x i16> %984 to <4 x i32>
  %986 = sub nsw <4 x i32> %983, %985
  %987 = sub nsw <4 x i32> zeroinitializer, %986
  %988 = icmp slt <4 x i32> %986, zeroinitializer
  %989 = select <4 x i1> %988, <4 x i32> %987, <4 x i32> %986
  %990 = add nuw nsw <4 x i32> %989, <i32 32, i32 32, i32 32, i32 32>
  %991 = lshr <4 x i32> %990, <i32 6, i32 6, i32 6, i32 6>
  %992 = shufflevector <8 x i16> %978, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %993 = shufflevector <8 x i16> %981, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %994 = bitcast <8 x i16> %992 to <4 x i32>
  %995 = bitcast <8 x i16> %993 to <4 x i32>
  %996 = sub <4 x i32> %994, %995
  %997 = sub <4 x i32> zeroinitializer, %996
  %998 = icmp slt <4 x i32> %996, zeroinitializer
  %999 = select <4 x i1> %998, <4 x i32> %997, <4 x i32> %996
  %1000 = add nuw <4 x i32> %999, <i32 32, i32 32, i32 32, i32 32>
  %1001 = lshr <4 x i32> %1000, <i32 6, i32 6, i32 6, i32 6>
  %1002 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %991, <4 x i32> %1001) #5
  %1003 = lshr <8 x i16> %1002, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1004 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %975, <8 x i16> %1003) #5
  %1005 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1004, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1006 = icmp slt <16 x i8> %1005, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1007 = select <16 x i1> %1006, <16 x i8> %1005, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1008 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1007
  %1009 = bitcast i8* %949 to <16 x i8>*
  store <16 x i8> %1008, <16 x i8>* %1009, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask32x16_10bpp_SSE4ILb0EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %383, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %381, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %382, %7 ]
  %11 = phi i32 [ 5, %4 ], [ %384, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = shufflevector <8 x i16> %13, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %17 = zext <4 x i16> %16 to <4 x i32>
  %18 = shufflevector <8 x i16> %15, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %19 = zext <4 x i16> %18 to <4 x i32>
  %20 = sub nsw <4 x i32> %17, %19
  %21 = sub nsw <4 x i32> zeroinitializer, %20
  %22 = icmp slt <4 x i32> %20, zeroinitializer
  %23 = select <4 x i1> %22, <4 x i32> %21, <4 x i32> %20
  %24 = add nuw nsw <4 x i32> %23, <i32 32, i32 32, i32 32, i32 32>
  %25 = lshr <4 x i32> %24, <i32 6, i32 6, i32 6, i32 6>
  %26 = shufflevector <8 x i16> %13, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %27 = shufflevector <8 x i16> %15, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %28 = bitcast <8 x i16> %26 to <4 x i32>
  %29 = bitcast <8 x i16> %27 to <4 x i32>
  %30 = sub <4 x i32> %28, %29
  %31 = sub <4 x i32> zeroinitializer, %30
  %32 = icmp slt <4 x i32> %30, zeroinitializer
  %33 = select <4 x i1> %32, <4 x i32> %31, <4 x i32> %30
  %34 = add nuw <4 x i32> %33, <i32 32, i32 32, i32 32, i32 32>
  %35 = lshr <4 x i32> %34, <i32 6, i32 6, i32 6, i32 6>
  %36 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %25, <4 x i32> %35) #5
  %37 = lshr <8 x i16> %36, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %38 = getelementptr inbounds i16, i16* %9, i64 8
  %39 = bitcast i16* %38 to <8 x i16>*
  %40 = load <8 x i16>, <8 x i16>* %39, align 16
  %41 = getelementptr inbounds i16, i16* %10, i64 8
  %42 = bitcast i16* %41 to <8 x i16>*
  %43 = load <8 x i16>, <8 x i16>* %42, align 16
  %44 = shufflevector <8 x i16> %40, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %45 = zext <4 x i16> %44 to <4 x i32>
  %46 = shufflevector <8 x i16> %43, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %47 = zext <4 x i16> %46 to <4 x i32>
  %48 = sub nsw <4 x i32> %45, %47
  %49 = sub nsw <4 x i32> zeroinitializer, %48
  %50 = icmp slt <4 x i32> %48, zeroinitializer
  %51 = select <4 x i1> %50, <4 x i32> %49, <4 x i32> %48
  %52 = add nuw nsw <4 x i32> %51, <i32 32, i32 32, i32 32, i32 32>
  %53 = lshr <4 x i32> %52, <i32 6, i32 6, i32 6, i32 6>
  %54 = shufflevector <8 x i16> %40, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %55 = shufflevector <8 x i16> %43, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %56 = bitcast <8 x i16> %54 to <4 x i32>
  %57 = bitcast <8 x i16> %55 to <4 x i32>
  %58 = sub <4 x i32> %56, %57
  %59 = sub <4 x i32> zeroinitializer, %58
  %60 = icmp slt <4 x i32> %58, zeroinitializer
  %61 = select <4 x i1> %60, <4 x i32> %59, <4 x i32> %58
  %62 = add nuw <4 x i32> %61, <i32 32, i32 32, i32 32, i32 32>
  %63 = lshr <4 x i32> %62, <i32 6, i32 6, i32 6, i32 6>
  %64 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %53, <4 x i32> %63) #5
  %65 = lshr <8 x i16> %64, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %66 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %37, <8 x i16> %65) #5
  %67 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %66, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %68 = icmp slt <16 x i8> %67, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %69 = select <16 x i1> %68, <16 x i8> %67, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %70 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %69, <16 x i8>* %70, align 16
  %71 = getelementptr inbounds i16, i16* %9, i64 16
  %72 = getelementptr inbounds i16, i16* %10, i64 16
  %73 = getelementptr inbounds i8, i8* %8, i64 16
  %74 = bitcast i16* %71 to <8 x i16>*
  %75 = load <8 x i16>, <8 x i16>* %74, align 16
  %76 = bitcast i16* %72 to <8 x i16>*
  %77 = load <8 x i16>, <8 x i16>* %76, align 16
  %78 = shufflevector <8 x i16> %75, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %79 = zext <4 x i16> %78 to <4 x i32>
  %80 = shufflevector <8 x i16> %77, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %81 = zext <4 x i16> %80 to <4 x i32>
  %82 = sub nsw <4 x i32> %79, %81
  %83 = sub nsw <4 x i32> zeroinitializer, %82
  %84 = icmp slt <4 x i32> %82, zeroinitializer
  %85 = select <4 x i1> %84, <4 x i32> %83, <4 x i32> %82
  %86 = add nuw nsw <4 x i32> %85, <i32 32, i32 32, i32 32, i32 32>
  %87 = lshr <4 x i32> %86, <i32 6, i32 6, i32 6, i32 6>
  %88 = shufflevector <8 x i16> %75, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %89 = shufflevector <8 x i16> %77, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %90 = bitcast <8 x i16> %88 to <4 x i32>
  %91 = bitcast <8 x i16> %89 to <4 x i32>
  %92 = sub <4 x i32> %90, %91
  %93 = sub <4 x i32> zeroinitializer, %92
  %94 = icmp slt <4 x i32> %92, zeroinitializer
  %95 = select <4 x i1> %94, <4 x i32> %93, <4 x i32> %92
  %96 = add nuw <4 x i32> %95, <i32 32, i32 32, i32 32, i32 32>
  %97 = lshr <4 x i32> %96, <i32 6, i32 6, i32 6, i32 6>
  %98 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %87, <4 x i32> %97) #5
  %99 = lshr <8 x i16> %98, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %100 = getelementptr inbounds i16, i16* %9, i64 24
  %101 = bitcast i16* %100 to <8 x i16>*
  %102 = load <8 x i16>, <8 x i16>* %101, align 16
  %103 = getelementptr inbounds i16, i16* %10, i64 24
  %104 = bitcast i16* %103 to <8 x i16>*
  %105 = load <8 x i16>, <8 x i16>* %104, align 16
  %106 = shufflevector <8 x i16> %102, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %107 = zext <4 x i16> %106 to <4 x i32>
  %108 = shufflevector <8 x i16> %105, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %109 = zext <4 x i16> %108 to <4 x i32>
  %110 = sub nsw <4 x i32> %107, %109
  %111 = sub nsw <4 x i32> zeroinitializer, %110
  %112 = icmp slt <4 x i32> %110, zeroinitializer
  %113 = select <4 x i1> %112, <4 x i32> %111, <4 x i32> %110
  %114 = add nuw nsw <4 x i32> %113, <i32 32, i32 32, i32 32, i32 32>
  %115 = lshr <4 x i32> %114, <i32 6, i32 6, i32 6, i32 6>
  %116 = shufflevector <8 x i16> %102, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %117 = shufflevector <8 x i16> %105, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %118 = bitcast <8 x i16> %116 to <4 x i32>
  %119 = bitcast <8 x i16> %117 to <4 x i32>
  %120 = sub <4 x i32> %118, %119
  %121 = sub <4 x i32> zeroinitializer, %120
  %122 = icmp slt <4 x i32> %120, zeroinitializer
  %123 = select <4 x i1> %122, <4 x i32> %121, <4 x i32> %120
  %124 = add nuw <4 x i32> %123, <i32 32, i32 32, i32 32, i32 32>
  %125 = lshr <4 x i32> %124, <i32 6, i32 6, i32 6, i32 6>
  %126 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %115, <4 x i32> %125) #5
  %127 = lshr <8 x i16> %126, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %128 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %99, <8 x i16> %127) #5
  %129 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %128, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %130 = icmp slt <16 x i8> %129, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %131 = select <16 x i1> %130, <16 x i8> %129, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %132 = bitcast i8* %73 to <16 x i8>*
  store <16 x i8> %131, <16 x i8>* %132, align 16
  %133 = getelementptr inbounds i16, i16* %9, i64 32
  %134 = getelementptr inbounds i16, i16* %10, i64 32
  %135 = getelementptr inbounds i8, i8* %8, i64 %3
  %136 = bitcast i16* %133 to <8 x i16>*
  %137 = load <8 x i16>, <8 x i16>* %136, align 16
  %138 = bitcast i16* %134 to <8 x i16>*
  %139 = load <8 x i16>, <8 x i16>* %138, align 16
  %140 = shufflevector <8 x i16> %137, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %141 = zext <4 x i16> %140 to <4 x i32>
  %142 = shufflevector <8 x i16> %139, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %143 = zext <4 x i16> %142 to <4 x i32>
  %144 = sub nsw <4 x i32> %141, %143
  %145 = sub nsw <4 x i32> zeroinitializer, %144
  %146 = icmp slt <4 x i32> %144, zeroinitializer
  %147 = select <4 x i1> %146, <4 x i32> %145, <4 x i32> %144
  %148 = add nuw nsw <4 x i32> %147, <i32 32, i32 32, i32 32, i32 32>
  %149 = lshr <4 x i32> %148, <i32 6, i32 6, i32 6, i32 6>
  %150 = shufflevector <8 x i16> %137, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %151 = shufflevector <8 x i16> %139, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %152 = bitcast <8 x i16> %150 to <4 x i32>
  %153 = bitcast <8 x i16> %151 to <4 x i32>
  %154 = sub <4 x i32> %152, %153
  %155 = sub <4 x i32> zeroinitializer, %154
  %156 = icmp slt <4 x i32> %154, zeroinitializer
  %157 = select <4 x i1> %156, <4 x i32> %155, <4 x i32> %154
  %158 = add nuw <4 x i32> %157, <i32 32, i32 32, i32 32, i32 32>
  %159 = lshr <4 x i32> %158, <i32 6, i32 6, i32 6, i32 6>
  %160 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %149, <4 x i32> %159) #5
  %161 = lshr <8 x i16> %160, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %162 = getelementptr inbounds i16, i16* %9, i64 40
  %163 = bitcast i16* %162 to <8 x i16>*
  %164 = load <8 x i16>, <8 x i16>* %163, align 16
  %165 = getelementptr inbounds i16, i16* %10, i64 40
  %166 = bitcast i16* %165 to <8 x i16>*
  %167 = load <8 x i16>, <8 x i16>* %166, align 16
  %168 = shufflevector <8 x i16> %164, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %169 = zext <4 x i16> %168 to <4 x i32>
  %170 = shufflevector <8 x i16> %167, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %171 = zext <4 x i16> %170 to <4 x i32>
  %172 = sub nsw <4 x i32> %169, %171
  %173 = sub nsw <4 x i32> zeroinitializer, %172
  %174 = icmp slt <4 x i32> %172, zeroinitializer
  %175 = select <4 x i1> %174, <4 x i32> %173, <4 x i32> %172
  %176 = add nuw nsw <4 x i32> %175, <i32 32, i32 32, i32 32, i32 32>
  %177 = lshr <4 x i32> %176, <i32 6, i32 6, i32 6, i32 6>
  %178 = shufflevector <8 x i16> %164, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %179 = shufflevector <8 x i16> %167, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %180 = bitcast <8 x i16> %178 to <4 x i32>
  %181 = bitcast <8 x i16> %179 to <4 x i32>
  %182 = sub <4 x i32> %180, %181
  %183 = sub <4 x i32> zeroinitializer, %182
  %184 = icmp slt <4 x i32> %182, zeroinitializer
  %185 = select <4 x i1> %184, <4 x i32> %183, <4 x i32> %182
  %186 = add nuw <4 x i32> %185, <i32 32, i32 32, i32 32, i32 32>
  %187 = lshr <4 x i32> %186, <i32 6, i32 6, i32 6, i32 6>
  %188 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %177, <4 x i32> %187) #5
  %189 = lshr <8 x i16> %188, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %190 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %161, <8 x i16> %189) #5
  %191 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %190, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %192 = icmp slt <16 x i8> %191, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %193 = select <16 x i1> %192, <16 x i8> %191, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %194 = bitcast i8* %135 to <16 x i8>*
  store <16 x i8> %193, <16 x i8>* %194, align 16
  %195 = getelementptr inbounds i16, i16* %9, i64 48
  %196 = getelementptr inbounds i16, i16* %10, i64 48
  %197 = getelementptr inbounds i8, i8* %135, i64 16
  %198 = bitcast i16* %195 to <8 x i16>*
  %199 = load <8 x i16>, <8 x i16>* %198, align 16
  %200 = bitcast i16* %196 to <8 x i16>*
  %201 = load <8 x i16>, <8 x i16>* %200, align 16
  %202 = shufflevector <8 x i16> %199, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %203 = zext <4 x i16> %202 to <4 x i32>
  %204 = shufflevector <8 x i16> %201, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %205 = zext <4 x i16> %204 to <4 x i32>
  %206 = sub nsw <4 x i32> %203, %205
  %207 = sub nsw <4 x i32> zeroinitializer, %206
  %208 = icmp slt <4 x i32> %206, zeroinitializer
  %209 = select <4 x i1> %208, <4 x i32> %207, <4 x i32> %206
  %210 = add nuw nsw <4 x i32> %209, <i32 32, i32 32, i32 32, i32 32>
  %211 = lshr <4 x i32> %210, <i32 6, i32 6, i32 6, i32 6>
  %212 = shufflevector <8 x i16> %199, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %213 = shufflevector <8 x i16> %201, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %214 = bitcast <8 x i16> %212 to <4 x i32>
  %215 = bitcast <8 x i16> %213 to <4 x i32>
  %216 = sub <4 x i32> %214, %215
  %217 = sub <4 x i32> zeroinitializer, %216
  %218 = icmp slt <4 x i32> %216, zeroinitializer
  %219 = select <4 x i1> %218, <4 x i32> %217, <4 x i32> %216
  %220 = add nuw <4 x i32> %219, <i32 32, i32 32, i32 32, i32 32>
  %221 = lshr <4 x i32> %220, <i32 6, i32 6, i32 6, i32 6>
  %222 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %211, <4 x i32> %221) #5
  %223 = lshr <8 x i16> %222, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %224 = getelementptr inbounds i16, i16* %9, i64 56
  %225 = bitcast i16* %224 to <8 x i16>*
  %226 = load <8 x i16>, <8 x i16>* %225, align 16
  %227 = getelementptr inbounds i16, i16* %10, i64 56
  %228 = bitcast i16* %227 to <8 x i16>*
  %229 = load <8 x i16>, <8 x i16>* %228, align 16
  %230 = shufflevector <8 x i16> %226, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %231 = zext <4 x i16> %230 to <4 x i32>
  %232 = shufflevector <8 x i16> %229, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %233 = zext <4 x i16> %232 to <4 x i32>
  %234 = sub nsw <4 x i32> %231, %233
  %235 = sub nsw <4 x i32> zeroinitializer, %234
  %236 = icmp slt <4 x i32> %234, zeroinitializer
  %237 = select <4 x i1> %236, <4 x i32> %235, <4 x i32> %234
  %238 = add nuw nsw <4 x i32> %237, <i32 32, i32 32, i32 32, i32 32>
  %239 = lshr <4 x i32> %238, <i32 6, i32 6, i32 6, i32 6>
  %240 = shufflevector <8 x i16> %226, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %241 = shufflevector <8 x i16> %229, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %242 = bitcast <8 x i16> %240 to <4 x i32>
  %243 = bitcast <8 x i16> %241 to <4 x i32>
  %244 = sub <4 x i32> %242, %243
  %245 = sub <4 x i32> zeroinitializer, %244
  %246 = icmp slt <4 x i32> %244, zeroinitializer
  %247 = select <4 x i1> %246, <4 x i32> %245, <4 x i32> %244
  %248 = add nuw <4 x i32> %247, <i32 32, i32 32, i32 32, i32 32>
  %249 = lshr <4 x i32> %248, <i32 6, i32 6, i32 6, i32 6>
  %250 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %239, <4 x i32> %249) #5
  %251 = lshr <8 x i16> %250, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %252 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %223, <8 x i16> %251) #5
  %253 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %252, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %254 = icmp slt <16 x i8> %253, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %255 = select <16 x i1> %254, <16 x i8> %253, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %256 = bitcast i8* %197 to <16 x i8>*
  store <16 x i8> %255, <16 x i8>* %256, align 16
  %257 = getelementptr inbounds i16, i16* %9, i64 64
  %258 = getelementptr inbounds i16, i16* %10, i64 64
  %259 = getelementptr inbounds i8, i8* %135, i64 %3
  %260 = bitcast i16* %257 to <8 x i16>*
  %261 = load <8 x i16>, <8 x i16>* %260, align 16
  %262 = bitcast i16* %258 to <8 x i16>*
  %263 = load <8 x i16>, <8 x i16>* %262, align 16
  %264 = shufflevector <8 x i16> %261, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %265 = zext <4 x i16> %264 to <4 x i32>
  %266 = shufflevector <8 x i16> %263, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %267 = zext <4 x i16> %266 to <4 x i32>
  %268 = sub nsw <4 x i32> %265, %267
  %269 = sub nsw <4 x i32> zeroinitializer, %268
  %270 = icmp slt <4 x i32> %268, zeroinitializer
  %271 = select <4 x i1> %270, <4 x i32> %269, <4 x i32> %268
  %272 = add nuw nsw <4 x i32> %271, <i32 32, i32 32, i32 32, i32 32>
  %273 = lshr <4 x i32> %272, <i32 6, i32 6, i32 6, i32 6>
  %274 = shufflevector <8 x i16> %261, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %275 = shufflevector <8 x i16> %263, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %276 = bitcast <8 x i16> %274 to <4 x i32>
  %277 = bitcast <8 x i16> %275 to <4 x i32>
  %278 = sub <4 x i32> %276, %277
  %279 = sub <4 x i32> zeroinitializer, %278
  %280 = icmp slt <4 x i32> %278, zeroinitializer
  %281 = select <4 x i1> %280, <4 x i32> %279, <4 x i32> %278
  %282 = add nuw <4 x i32> %281, <i32 32, i32 32, i32 32, i32 32>
  %283 = lshr <4 x i32> %282, <i32 6, i32 6, i32 6, i32 6>
  %284 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %273, <4 x i32> %283) #5
  %285 = lshr <8 x i16> %284, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %286 = getelementptr inbounds i16, i16* %9, i64 72
  %287 = bitcast i16* %286 to <8 x i16>*
  %288 = load <8 x i16>, <8 x i16>* %287, align 16
  %289 = getelementptr inbounds i16, i16* %10, i64 72
  %290 = bitcast i16* %289 to <8 x i16>*
  %291 = load <8 x i16>, <8 x i16>* %290, align 16
  %292 = shufflevector <8 x i16> %288, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %293 = zext <4 x i16> %292 to <4 x i32>
  %294 = shufflevector <8 x i16> %291, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %295 = zext <4 x i16> %294 to <4 x i32>
  %296 = sub nsw <4 x i32> %293, %295
  %297 = sub nsw <4 x i32> zeroinitializer, %296
  %298 = icmp slt <4 x i32> %296, zeroinitializer
  %299 = select <4 x i1> %298, <4 x i32> %297, <4 x i32> %296
  %300 = add nuw nsw <4 x i32> %299, <i32 32, i32 32, i32 32, i32 32>
  %301 = lshr <4 x i32> %300, <i32 6, i32 6, i32 6, i32 6>
  %302 = shufflevector <8 x i16> %288, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %303 = shufflevector <8 x i16> %291, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %304 = bitcast <8 x i16> %302 to <4 x i32>
  %305 = bitcast <8 x i16> %303 to <4 x i32>
  %306 = sub <4 x i32> %304, %305
  %307 = sub <4 x i32> zeroinitializer, %306
  %308 = icmp slt <4 x i32> %306, zeroinitializer
  %309 = select <4 x i1> %308, <4 x i32> %307, <4 x i32> %306
  %310 = add nuw <4 x i32> %309, <i32 32, i32 32, i32 32, i32 32>
  %311 = lshr <4 x i32> %310, <i32 6, i32 6, i32 6, i32 6>
  %312 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %301, <4 x i32> %311) #5
  %313 = lshr <8 x i16> %312, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %314 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %285, <8 x i16> %313) #5
  %315 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %314, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %316 = icmp slt <16 x i8> %315, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %317 = select <16 x i1> %316, <16 x i8> %315, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %318 = bitcast i8* %259 to <16 x i8>*
  store <16 x i8> %317, <16 x i8>* %318, align 16
  %319 = getelementptr inbounds i16, i16* %9, i64 80
  %320 = getelementptr inbounds i16, i16* %10, i64 80
  %321 = getelementptr inbounds i8, i8* %259, i64 16
  %322 = bitcast i16* %319 to <8 x i16>*
  %323 = load <8 x i16>, <8 x i16>* %322, align 16
  %324 = bitcast i16* %320 to <8 x i16>*
  %325 = load <8 x i16>, <8 x i16>* %324, align 16
  %326 = shufflevector <8 x i16> %323, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %327 = zext <4 x i16> %326 to <4 x i32>
  %328 = shufflevector <8 x i16> %325, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %329 = zext <4 x i16> %328 to <4 x i32>
  %330 = sub nsw <4 x i32> %327, %329
  %331 = sub nsw <4 x i32> zeroinitializer, %330
  %332 = icmp slt <4 x i32> %330, zeroinitializer
  %333 = select <4 x i1> %332, <4 x i32> %331, <4 x i32> %330
  %334 = add nuw nsw <4 x i32> %333, <i32 32, i32 32, i32 32, i32 32>
  %335 = lshr <4 x i32> %334, <i32 6, i32 6, i32 6, i32 6>
  %336 = shufflevector <8 x i16> %323, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %337 = shufflevector <8 x i16> %325, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %338 = bitcast <8 x i16> %336 to <4 x i32>
  %339 = bitcast <8 x i16> %337 to <4 x i32>
  %340 = sub <4 x i32> %338, %339
  %341 = sub <4 x i32> zeroinitializer, %340
  %342 = icmp slt <4 x i32> %340, zeroinitializer
  %343 = select <4 x i1> %342, <4 x i32> %341, <4 x i32> %340
  %344 = add nuw <4 x i32> %343, <i32 32, i32 32, i32 32, i32 32>
  %345 = lshr <4 x i32> %344, <i32 6, i32 6, i32 6, i32 6>
  %346 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %335, <4 x i32> %345) #5
  %347 = lshr <8 x i16> %346, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %348 = getelementptr inbounds i16, i16* %9, i64 88
  %349 = bitcast i16* %348 to <8 x i16>*
  %350 = load <8 x i16>, <8 x i16>* %349, align 16
  %351 = getelementptr inbounds i16, i16* %10, i64 88
  %352 = bitcast i16* %351 to <8 x i16>*
  %353 = load <8 x i16>, <8 x i16>* %352, align 16
  %354 = shufflevector <8 x i16> %350, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %355 = zext <4 x i16> %354 to <4 x i32>
  %356 = shufflevector <8 x i16> %353, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %357 = zext <4 x i16> %356 to <4 x i32>
  %358 = sub nsw <4 x i32> %355, %357
  %359 = sub nsw <4 x i32> zeroinitializer, %358
  %360 = icmp slt <4 x i32> %358, zeroinitializer
  %361 = select <4 x i1> %360, <4 x i32> %359, <4 x i32> %358
  %362 = add nuw nsw <4 x i32> %361, <i32 32, i32 32, i32 32, i32 32>
  %363 = lshr <4 x i32> %362, <i32 6, i32 6, i32 6, i32 6>
  %364 = shufflevector <8 x i16> %350, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %365 = shufflevector <8 x i16> %353, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %366 = bitcast <8 x i16> %364 to <4 x i32>
  %367 = bitcast <8 x i16> %365 to <4 x i32>
  %368 = sub <4 x i32> %366, %367
  %369 = sub <4 x i32> zeroinitializer, %368
  %370 = icmp slt <4 x i32> %368, zeroinitializer
  %371 = select <4 x i1> %370, <4 x i32> %369, <4 x i32> %368
  %372 = add nuw <4 x i32> %371, <i32 32, i32 32, i32 32, i32 32>
  %373 = lshr <4 x i32> %372, <i32 6, i32 6, i32 6, i32 6>
  %374 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %363, <4 x i32> %373) #5
  %375 = lshr <8 x i16> %374, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %376 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %347, <8 x i16> %375) #5
  %377 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %376, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %378 = icmp slt <16 x i8> %377, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %379 = select <16 x i1> %378, <16 x i8> %377, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %380 = bitcast i8* %321 to <16 x i8>*
  store <16 x i8> %379, <16 x i8>* %380, align 16
  %381 = getelementptr inbounds i16, i16* %9, i64 96
  %382 = getelementptr inbounds i16, i16* %10, i64 96
  %383 = getelementptr inbounds i8, i8* %259, i64 %3
  %384 = add nsw i32 %11, -1
  %385 = icmp eq i32 %384, 0
  br i1 %385, label %386, label %7

386:                                              ; preds = %7
  %387 = bitcast i16* %381 to <8 x i16>*
  %388 = load <8 x i16>, <8 x i16>* %387, align 16
  %389 = bitcast i16* %382 to <8 x i16>*
  %390 = load <8 x i16>, <8 x i16>* %389, align 16
  %391 = shufflevector <8 x i16> %388, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %392 = zext <4 x i16> %391 to <4 x i32>
  %393 = shufflevector <8 x i16> %390, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %394 = zext <4 x i16> %393 to <4 x i32>
  %395 = sub nsw <4 x i32> %392, %394
  %396 = sub nsw <4 x i32> zeroinitializer, %395
  %397 = icmp slt <4 x i32> %395, zeroinitializer
  %398 = select <4 x i1> %397, <4 x i32> %396, <4 x i32> %395
  %399 = add nuw nsw <4 x i32> %398, <i32 32, i32 32, i32 32, i32 32>
  %400 = lshr <4 x i32> %399, <i32 6, i32 6, i32 6, i32 6>
  %401 = shufflevector <8 x i16> %388, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %402 = shufflevector <8 x i16> %390, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %403 = bitcast <8 x i16> %401 to <4 x i32>
  %404 = bitcast <8 x i16> %402 to <4 x i32>
  %405 = sub <4 x i32> %403, %404
  %406 = sub <4 x i32> zeroinitializer, %405
  %407 = icmp slt <4 x i32> %405, zeroinitializer
  %408 = select <4 x i1> %407, <4 x i32> %406, <4 x i32> %405
  %409 = add nuw <4 x i32> %408, <i32 32, i32 32, i32 32, i32 32>
  %410 = lshr <4 x i32> %409, <i32 6, i32 6, i32 6, i32 6>
  %411 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %400, <4 x i32> %410) #5
  %412 = lshr <8 x i16> %411, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %413 = getelementptr inbounds i16, i16* %9, i64 104
  %414 = bitcast i16* %413 to <8 x i16>*
  %415 = load <8 x i16>, <8 x i16>* %414, align 16
  %416 = getelementptr inbounds i16, i16* %10, i64 104
  %417 = bitcast i16* %416 to <8 x i16>*
  %418 = load <8 x i16>, <8 x i16>* %417, align 16
  %419 = shufflevector <8 x i16> %415, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %420 = zext <4 x i16> %419 to <4 x i32>
  %421 = shufflevector <8 x i16> %418, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %422 = zext <4 x i16> %421 to <4 x i32>
  %423 = sub nsw <4 x i32> %420, %422
  %424 = sub nsw <4 x i32> zeroinitializer, %423
  %425 = icmp slt <4 x i32> %423, zeroinitializer
  %426 = select <4 x i1> %425, <4 x i32> %424, <4 x i32> %423
  %427 = add nuw nsw <4 x i32> %426, <i32 32, i32 32, i32 32, i32 32>
  %428 = lshr <4 x i32> %427, <i32 6, i32 6, i32 6, i32 6>
  %429 = shufflevector <8 x i16> %415, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %430 = shufflevector <8 x i16> %418, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %431 = bitcast <8 x i16> %429 to <4 x i32>
  %432 = bitcast <8 x i16> %430 to <4 x i32>
  %433 = sub <4 x i32> %431, %432
  %434 = sub <4 x i32> zeroinitializer, %433
  %435 = icmp slt <4 x i32> %433, zeroinitializer
  %436 = select <4 x i1> %435, <4 x i32> %434, <4 x i32> %433
  %437 = add nuw <4 x i32> %436, <i32 32, i32 32, i32 32, i32 32>
  %438 = lshr <4 x i32> %437, <i32 6, i32 6, i32 6, i32 6>
  %439 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %428, <4 x i32> %438) #5
  %440 = lshr <8 x i16> %439, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %441 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %412, <8 x i16> %440) #5
  %442 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %441, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %443 = icmp slt <16 x i8> %442, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %444 = select <16 x i1> %443, <16 x i8> %442, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %445 = bitcast i8* %383 to <16 x i8>*
  store <16 x i8> %444, <16 x i8>* %445, align 16
  %446 = getelementptr inbounds i16, i16* %9, i64 112
  %447 = getelementptr inbounds i16, i16* %10, i64 112
  %448 = getelementptr inbounds i8, i8* %383, i64 16
  %449 = bitcast i16* %446 to <8 x i16>*
  %450 = load <8 x i16>, <8 x i16>* %449, align 16
  %451 = bitcast i16* %447 to <8 x i16>*
  %452 = load <8 x i16>, <8 x i16>* %451, align 16
  %453 = shufflevector <8 x i16> %450, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %454 = zext <4 x i16> %453 to <4 x i32>
  %455 = shufflevector <8 x i16> %452, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %456 = zext <4 x i16> %455 to <4 x i32>
  %457 = sub nsw <4 x i32> %454, %456
  %458 = sub nsw <4 x i32> zeroinitializer, %457
  %459 = icmp slt <4 x i32> %457, zeroinitializer
  %460 = select <4 x i1> %459, <4 x i32> %458, <4 x i32> %457
  %461 = add nuw nsw <4 x i32> %460, <i32 32, i32 32, i32 32, i32 32>
  %462 = lshr <4 x i32> %461, <i32 6, i32 6, i32 6, i32 6>
  %463 = shufflevector <8 x i16> %450, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %464 = shufflevector <8 x i16> %452, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %465 = bitcast <8 x i16> %463 to <4 x i32>
  %466 = bitcast <8 x i16> %464 to <4 x i32>
  %467 = sub <4 x i32> %465, %466
  %468 = sub <4 x i32> zeroinitializer, %467
  %469 = icmp slt <4 x i32> %467, zeroinitializer
  %470 = select <4 x i1> %469, <4 x i32> %468, <4 x i32> %467
  %471 = add nuw <4 x i32> %470, <i32 32, i32 32, i32 32, i32 32>
  %472 = lshr <4 x i32> %471, <i32 6, i32 6, i32 6, i32 6>
  %473 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %462, <4 x i32> %472) #5
  %474 = lshr <8 x i16> %473, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %475 = getelementptr inbounds i16, i16* %9, i64 120
  %476 = bitcast i16* %475 to <8 x i16>*
  %477 = load <8 x i16>, <8 x i16>* %476, align 16
  %478 = getelementptr inbounds i16, i16* %10, i64 120
  %479 = bitcast i16* %478 to <8 x i16>*
  %480 = load <8 x i16>, <8 x i16>* %479, align 16
  %481 = shufflevector <8 x i16> %477, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %482 = zext <4 x i16> %481 to <4 x i32>
  %483 = shufflevector <8 x i16> %480, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %484 = zext <4 x i16> %483 to <4 x i32>
  %485 = sub nsw <4 x i32> %482, %484
  %486 = sub nsw <4 x i32> zeroinitializer, %485
  %487 = icmp slt <4 x i32> %485, zeroinitializer
  %488 = select <4 x i1> %487, <4 x i32> %486, <4 x i32> %485
  %489 = add nuw nsw <4 x i32> %488, <i32 32, i32 32, i32 32, i32 32>
  %490 = lshr <4 x i32> %489, <i32 6, i32 6, i32 6, i32 6>
  %491 = shufflevector <8 x i16> %477, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %492 = shufflevector <8 x i16> %480, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %493 = bitcast <8 x i16> %491 to <4 x i32>
  %494 = bitcast <8 x i16> %492 to <4 x i32>
  %495 = sub <4 x i32> %493, %494
  %496 = sub <4 x i32> zeroinitializer, %495
  %497 = icmp slt <4 x i32> %495, zeroinitializer
  %498 = select <4 x i1> %497, <4 x i32> %496, <4 x i32> %495
  %499 = add nuw <4 x i32> %498, <i32 32, i32 32, i32 32, i32 32>
  %500 = lshr <4 x i32> %499, <i32 6, i32 6, i32 6, i32 6>
  %501 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %490, <4 x i32> %500) #5
  %502 = lshr <8 x i16> %501, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %503 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %474, <8 x i16> %502) #5
  %504 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %503, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %505 = icmp slt <16 x i8> %504, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %506 = select <16 x i1> %505, <16 x i8> %504, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %507 = bitcast i8* %448 to <16 x i8>*
  store <16 x i8> %506, <16 x i8>* %507, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask32x16_10bpp_SSE4ILb1EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %389, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %387, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %388, %7 ]
  %11 = phi i32 [ 5, %4 ], [ %390, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = shufflevector <8 x i16> %13, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %17 = zext <4 x i16> %16 to <4 x i32>
  %18 = shufflevector <8 x i16> %15, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %19 = zext <4 x i16> %18 to <4 x i32>
  %20 = sub nsw <4 x i32> %17, %19
  %21 = sub nsw <4 x i32> zeroinitializer, %20
  %22 = icmp slt <4 x i32> %20, zeroinitializer
  %23 = select <4 x i1> %22, <4 x i32> %21, <4 x i32> %20
  %24 = add nuw nsw <4 x i32> %23, <i32 32, i32 32, i32 32, i32 32>
  %25 = lshr <4 x i32> %24, <i32 6, i32 6, i32 6, i32 6>
  %26 = shufflevector <8 x i16> %13, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %27 = shufflevector <8 x i16> %15, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %28 = bitcast <8 x i16> %26 to <4 x i32>
  %29 = bitcast <8 x i16> %27 to <4 x i32>
  %30 = sub <4 x i32> %28, %29
  %31 = sub <4 x i32> zeroinitializer, %30
  %32 = icmp slt <4 x i32> %30, zeroinitializer
  %33 = select <4 x i1> %32, <4 x i32> %31, <4 x i32> %30
  %34 = add nuw <4 x i32> %33, <i32 32, i32 32, i32 32, i32 32>
  %35 = lshr <4 x i32> %34, <i32 6, i32 6, i32 6, i32 6>
  %36 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %25, <4 x i32> %35) #5
  %37 = lshr <8 x i16> %36, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %38 = getelementptr inbounds i16, i16* %9, i64 8
  %39 = bitcast i16* %38 to <8 x i16>*
  %40 = load <8 x i16>, <8 x i16>* %39, align 16
  %41 = getelementptr inbounds i16, i16* %10, i64 8
  %42 = bitcast i16* %41 to <8 x i16>*
  %43 = load <8 x i16>, <8 x i16>* %42, align 16
  %44 = shufflevector <8 x i16> %40, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %45 = zext <4 x i16> %44 to <4 x i32>
  %46 = shufflevector <8 x i16> %43, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %47 = zext <4 x i16> %46 to <4 x i32>
  %48 = sub nsw <4 x i32> %45, %47
  %49 = sub nsw <4 x i32> zeroinitializer, %48
  %50 = icmp slt <4 x i32> %48, zeroinitializer
  %51 = select <4 x i1> %50, <4 x i32> %49, <4 x i32> %48
  %52 = add nuw nsw <4 x i32> %51, <i32 32, i32 32, i32 32, i32 32>
  %53 = lshr <4 x i32> %52, <i32 6, i32 6, i32 6, i32 6>
  %54 = shufflevector <8 x i16> %40, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %55 = shufflevector <8 x i16> %43, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %56 = bitcast <8 x i16> %54 to <4 x i32>
  %57 = bitcast <8 x i16> %55 to <4 x i32>
  %58 = sub <4 x i32> %56, %57
  %59 = sub <4 x i32> zeroinitializer, %58
  %60 = icmp slt <4 x i32> %58, zeroinitializer
  %61 = select <4 x i1> %60, <4 x i32> %59, <4 x i32> %58
  %62 = add nuw <4 x i32> %61, <i32 32, i32 32, i32 32, i32 32>
  %63 = lshr <4 x i32> %62, <i32 6, i32 6, i32 6, i32 6>
  %64 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %53, <4 x i32> %63) #5
  %65 = lshr <8 x i16> %64, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %66 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %37, <8 x i16> %65) #5
  %67 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %66, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %68 = icmp slt <16 x i8> %67, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %69 = select <16 x i1> %68, <16 x i8> %67, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %70 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %69
  %71 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %70, <16 x i8>* %71, align 16
  %72 = getelementptr inbounds i16, i16* %9, i64 16
  %73 = getelementptr inbounds i16, i16* %10, i64 16
  %74 = getelementptr inbounds i8, i8* %8, i64 16
  %75 = bitcast i16* %72 to <8 x i16>*
  %76 = load <8 x i16>, <8 x i16>* %75, align 16
  %77 = bitcast i16* %73 to <8 x i16>*
  %78 = load <8 x i16>, <8 x i16>* %77, align 16
  %79 = shufflevector <8 x i16> %76, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %80 = zext <4 x i16> %79 to <4 x i32>
  %81 = shufflevector <8 x i16> %78, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %82 = zext <4 x i16> %81 to <4 x i32>
  %83 = sub nsw <4 x i32> %80, %82
  %84 = sub nsw <4 x i32> zeroinitializer, %83
  %85 = icmp slt <4 x i32> %83, zeroinitializer
  %86 = select <4 x i1> %85, <4 x i32> %84, <4 x i32> %83
  %87 = add nuw nsw <4 x i32> %86, <i32 32, i32 32, i32 32, i32 32>
  %88 = lshr <4 x i32> %87, <i32 6, i32 6, i32 6, i32 6>
  %89 = shufflevector <8 x i16> %76, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %90 = shufflevector <8 x i16> %78, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %91 = bitcast <8 x i16> %89 to <4 x i32>
  %92 = bitcast <8 x i16> %90 to <4 x i32>
  %93 = sub <4 x i32> %91, %92
  %94 = sub <4 x i32> zeroinitializer, %93
  %95 = icmp slt <4 x i32> %93, zeroinitializer
  %96 = select <4 x i1> %95, <4 x i32> %94, <4 x i32> %93
  %97 = add nuw <4 x i32> %96, <i32 32, i32 32, i32 32, i32 32>
  %98 = lshr <4 x i32> %97, <i32 6, i32 6, i32 6, i32 6>
  %99 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %88, <4 x i32> %98) #5
  %100 = lshr <8 x i16> %99, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %101 = getelementptr inbounds i16, i16* %9, i64 24
  %102 = bitcast i16* %101 to <8 x i16>*
  %103 = load <8 x i16>, <8 x i16>* %102, align 16
  %104 = getelementptr inbounds i16, i16* %10, i64 24
  %105 = bitcast i16* %104 to <8 x i16>*
  %106 = load <8 x i16>, <8 x i16>* %105, align 16
  %107 = shufflevector <8 x i16> %103, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %108 = zext <4 x i16> %107 to <4 x i32>
  %109 = shufflevector <8 x i16> %106, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %110 = zext <4 x i16> %109 to <4 x i32>
  %111 = sub nsw <4 x i32> %108, %110
  %112 = sub nsw <4 x i32> zeroinitializer, %111
  %113 = icmp slt <4 x i32> %111, zeroinitializer
  %114 = select <4 x i1> %113, <4 x i32> %112, <4 x i32> %111
  %115 = add nuw nsw <4 x i32> %114, <i32 32, i32 32, i32 32, i32 32>
  %116 = lshr <4 x i32> %115, <i32 6, i32 6, i32 6, i32 6>
  %117 = shufflevector <8 x i16> %103, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %118 = shufflevector <8 x i16> %106, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %119 = bitcast <8 x i16> %117 to <4 x i32>
  %120 = bitcast <8 x i16> %118 to <4 x i32>
  %121 = sub <4 x i32> %119, %120
  %122 = sub <4 x i32> zeroinitializer, %121
  %123 = icmp slt <4 x i32> %121, zeroinitializer
  %124 = select <4 x i1> %123, <4 x i32> %122, <4 x i32> %121
  %125 = add nuw <4 x i32> %124, <i32 32, i32 32, i32 32, i32 32>
  %126 = lshr <4 x i32> %125, <i32 6, i32 6, i32 6, i32 6>
  %127 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %116, <4 x i32> %126) #5
  %128 = lshr <8 x i16> %127, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %129 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %100, <8 x i16> %128) #5
  %130 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %129, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %131 = icmp slt <16 x i8> %130, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %132 = select <16 x i1> %131, <16 x i8> %130, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %133 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %132
  %134 = bitcast i8* %74 to <16 x i8>*
  store <16 x i8> %133, <16 x i8>* %134, align 16
  %135 = getelementptr inbounds i16, i16* %9, i64 32
  %136 = getelementptr inbounds i16, i16* %10, i64 32
  %137 = getelementptr inbounds i8, i8* %8, i64 %3
  %138 = bitcast i16* %135 to <8 x i16>*
  %139 = load <8 x i16>, <8 x i16>* %138, align 16
  %140 = bitcast i16* %136 to <8 x i16>*
  %141 = load <8 x i16>, <8 x i16>* %140, align 16
  %142 = shufflevector <8 x i16> %139, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %143 = zext <4 x i16> %142 to <4 x i32>
  %144 = shufflevector <8 x i16> %141, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %145 = zext <4 x i16> %144 to <4 x i32>
  %146 = sub nsw <4 x i32> %143, %145
  %147 = sub nsw <4 x i32> zeroinitializer, %146
  %148 = icmp slt <4 x i32> %146, zeroinitializer
  %149 = select <4 x i1> %148, <4 x i32> %147, <4 x i32> %146
  %150 = add nuw nsw <4 x i32> %149, <i32 32, i32 32, i32 32, i32 32>
  %151 = lshr <4 x i32> %150, <i32 6, i32 6, i32 6, i32 6>
  %152 = shufflevector <8 x i16> %139, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %153 = shufflevector <8 x i16> %141, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %154 = bitcast <8 x i16> %152 to <4 x i32>
  %155 = bitcast <8 x i16> %153 to <4 x i32>
  %156 = sub <4 x i32> %154, %155
  %157 = sub <4 x i32> zeroinitializer, %156
  %158 = icmp slt <4 x i32> %156, zeroinitializer
  %159 = select <4 x i1> %158, <4 x i32> %157, <4 x i32> %156
  %160 = add nuw <4 x i32> %159, <i32 32, i32 32, i32 32, i32 32>
  %161 = lshr <4 x i32> %160, <i32 6, i32 6, i32 6, i32 6>
  %162 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %151, <4 x i32> %161) #5
  %163 = lshr <8 x i16> %162, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %164 = getelementptr inbounds i16, i16* %9, i64 40
  %165 = bitcast i16* %164 to <8 x i16>*
  %166 = load <8 x i16>, <8 x i16>* %165, align 16
  %167 = getelementptr inbounds i16, i16* %10, i64 40
  %168 = bitcast i16* %167 to <8 x i16>*
  %169 = load <8 x i16>, <8 x i16>* %168, align 16
  %170 = shufflevector <8 x i16> %166, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %171 = zext <4 x i16> %170 to <4 x i32>
  %172 = shufflevector <8 x i16> %169, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %173 = zext <4 x i16> %172 to <4 x i32>
  %174 = sub nsw <4 x i32> %171, %173
  %175 = sub nsw <4 x i32> zeroinitializer, %174
  %176 = icmp slt <4 x i32> %174, zeroinitializer
  %177 = select <4 x i1> %176, <4 x i32> %175, <4 x i32> %174
  %178 = add nuw nsw <4 x i32> %177, <i32 32, i32 32, i32 32, i32 32>
  %179 = lshr <4 x i32> %178, <i32 6, i32 6, i32 6, i32 6>
  %180 = shufflevector <8 x i16> %166, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %181 = shufflevector <8 x i16> %169, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %182 = bitcast <8 x i16> %180 to <4 x i32>
  %183 = bitcast <8 x i16> %181 to <4 x i32>
  %184 = sub <4 x i32> %182, %183
  %185 = sub <4 x i32> zeroinitializer, %184
  %186 = icmp slt <4 x i32> %184, zeroinitializer
  %187 = select <4 x i1> %186, <4 x i32> %185, <4 x i32> %184
  %188 = add nuw <4 x i32> %187, <i32 32, i32 32, i32 32, i32 32>
  %189 = lshr <4 x i32> %188, <i32 6, i32 6, i32 6, i32 6>
  %190 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %179, <4 x i32> %189) #5
  %191 = lshr <8 x i16> %190, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %192 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %163, <8 x i16> %191) #5
  %193 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %192, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %194 = icmp slt <16 x i8> %193, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %195 = select <16 x i1> %194, <16 x i8> %193, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %196 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %195
  %197 = bitcast i8* %137 to <16 x i8>*
  store <16 x i8> %196, <16 x i8>* %197, align 16
  %198 = getelementptr inbounds i16, i16* %9, i64 48
  %199 = getelementptr inbounds i16, i16* %10, i64 48
  %200 = getelementptr inbounds i8, i8* %137, i64 16
  %201 = bitcast i16* %198 to <8 x i16>*
  %202 = load <8 x i16>, <8 x i16>* %201, align 16
  %203 = bitcast i16* %199 to <8 x i16>*
  %204 = load <8 x i16>, <8 x i16>* %203, align 16
  %205 = shufflevector <8 x i16> %202, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %206 = zext <4 x i16> %205 to <4 x i32>
  %207 = shufflevector <8 x i16> %204, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %208 = zext <4 x i16> %207 to <4 x i32>
  %209 = sub nsw <4 x i32> %206, %208
  %210 = sub nsw <4 x i32> zeroinitializer, %209
  %211 = icmp slt <4 x i32> %209, zeroinitializer
  %212 = select <4 x i1> %211, <4 x i32> %210, <4 x i32> %209
  %213 = add nuw nsw <4 x i32> %212, <i32 32, i32 32, i32 32, i32 32>
  %214 = lshr <4 x i32> %213, <i32 6, i32 6, i32 6, i32 6>
  %215 = shufflevector <8 x i16> %202, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %216 = shufflevector <8 x i16> %204, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %217 = bitcast <8 x i16> %215 to <4 x i32>
  %218 = bitcast <8 x i16> %216 to <4 x i32>
  %219 = sub <4 x i32> %217, %218
  %220 = sub <4 x i32> zeroinitializer, %219
  %221 = icmp slt <4 x i32> %219, zeroinitializer
  %222 = select <4 x i1> %221, <4 x i32> %220, <4 x i32> %219
  %223 = add nuw <4 x i32> %222, <i32 32, i32 32, i32 32, i32 32>
  %224 = lshr <4 x i32> %223, <i32 6, i32 6, i32 6, i32 6>
  %225 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %214, <4 x i32> %224) #5
  %226 = lshr <8 x i16> %225, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %227 = getelementptr inbounds i16, i16* %9, i64 56
  %228 = bitcast i16* %227 to <8 x i16>*
  %229 = load <8 x i16>, <8 x i16>* %228, align 16
  %230 = getelementptr inbounds i16, i16* %10, i64 56
  %231 = bitcast i16* %230 to <8 x i16>*
  %232 = load <8 x i16>, <8 x i16>* %231, align 16
  %233 = shufflevector <8 x i16> %229, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %234 = zext <4 x i16> %233 to <4 x i32>
  %235 = shufflevector <8 x i16> %232, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %236 = zext <4 x i16> %235 to <4 x i32>
  %237 = sub nsw <4 x i32> %234, %236
  %238 = sub nsw <4 x i32> zeroinitializer, %237
  %239 = icmp slt <4 x i32> %237, zeroinitializer
  %240 = select <4 x i1> %239, <4 x i32> %238, <4 x i32> %237
  %241 = add nuw nsw <4 x i32> %240, <i32 32, i32 32, i32 32, i32 32>
  %242 = lshr <4 x i32> %241, <i32 6, i32 6, i32 6, i32 6>
  %243 = shufflevector <8 x i16> %229, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %244 = shufflevector <8 x i16> %232, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %245 = bitcast <8 x i16> %243 to <4 x i32>
  %246 = bitcast <8 x i16> %244 to <4 x i32>
  %247 = sub <4 x i32> %245, %246
  %248 = sub <4 x i32> zeroinitializer, %247
  %249 = icmp slt <4 x i32> %247, zeroinitializer
  %250 = select <4 x i1> %249, <4 x i32> %248, <4 x i32> %247
  %251 = add nuw <4 x i32> %250, <i32 32, i32 32, i32 32, i32 32>
  %252 = lshr <4 x i32> %251, <i32 6, i32 6, i32 6, i32 6>
  %253 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %242, <4 x i32> %252) #5
  %254 = lshr <8 x i16> %253, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %255 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %226, <8 x i16> %254) #5
  %256 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %255, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %257 = icmp slt <16 x i8> %256, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %258 = select <16 x i1> %257, <16 x i8> %256, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %259 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %258
  %260 = bitcast i8* %200 to <16 x i8>*
  store <16 x i8> %259, <16 x i8>* %260, align 16
  %261 = getelementptr inbounds i16, i16* %9, i64 64
  %262 = getelementptr inbounds i16, i16* %10, i64 64
  %263 = getelementptr inbounds i8, i8* %137, i64 %3
  %264 = bitcast i16* %261 to <8 x i16>*
  %265 = load <8 x i16>, <8 x i16>* %264, align 16
  %266 = bitcast i16* %262 to <8 x i16>*
  %267 = load <8 x i16>, <8 x i16>* %266, align 16
  %268 = shufflevector <8 x i16> %265, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %269 = zext <4 x i16> %268 to <4 x i32>
  %270 = shufflevector <8 x i16> %267, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %271 = zext <4 x i16> %270 to <4 x i32>
  %272 = sub nsw <4 x i32> %269, %271
  %273 = sub nsw <4 x i32> zeroinitializer, %272
  %274 = icmp slt <4 x i32> %272, zeroinitializer
  %275 = select <4 x i1> %274, <4 x i32> %273, <4 x i32> %272
  %276 = add nuw nsw <4 x i32> %275, <i32 32, i32 32, i32 32, i32 32>
  %277 = lshr <4 x i32> %276, <i32 6, i32 6, i32 6, i32 6>
  %278 = shufflevector <8 x i16> %265, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %279 = shufflevector <8 x i16> %267, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %280 = bitcast <8 x i16> %278 to <4 x i32>
  %281 = bitcast <8 x i16> %279 to <4 x i32>
  %282 = sub <4 x i32> %280, %281
  %283 = sub <4 x i32> zeroinitializer, %282
  %284 = icmp slt <4 x i32> %282, zeroinitializer
  %285 = select <4 x i1> %284, <4 x i32> %283, <4 x i32> %282
  %286 = add nuw <4 x i32> %285, <i32 32, i32 32, i32 32, i32 32>
  %287 = lshr <4 x i32> %286, <i32 6, i32 6, i32 6, i32 6>
  %288 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %277, <4 x i32> %287) #5
  %289 = lshr <8 x i16> %288, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %290 = getelementptr inbounds i16, i16* %9, i64 72
  %291 = bitcast i16* %290 to <8 x i16>*
  %292 = load <8 x i16>, <8 x i16>* %291, align 16
  %293 = getelementptr inbounds i16, i16* %10, i64 72
  %294 = bitcast i16* %293 to <8 x i16>*
  %295 = load <8 x i16>, <8 x i16>* %294, align 16
  %296 = shufflevector <8 x i16> %292, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %297 = zext <4 x i16> %296 to <4 x i32>
  %298 = shufflevector <8 x i16> %295, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %299 = zext <4 x i16> %298 to <4 x i32>
  %300 = sub nsw <4 x i32> %297, %299
  %301 = sub nsw <4 x i32> zeroinitializer, %300
  %302 = icmp slt <4 x i32> %300, zeroinitializer
  %303 = select <4 x i1> %302, <4 x i32> %301, <4 x i32> %300
  %304 = add nuw nsw <4 x i32> %303, <i32 32, i32 32, i32 32, i32 32>
  %305 = lshr <4 x i32> %304, <i32 6, i32 6, i32 6, i32 6>
  %306 = shufflevector <8 x i16> %292, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %307 = shufflevector <8 x i16> %295, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %308 = bitcast <8 x i16> %306 to <4 x i32>
  %309 = bitcast <8 x i16> %307 to <4 x i32>
  %310 = sub <4 x i32> %308, %309
  %311 = sub <4 x i32> zeroinitializer, %310
  %312 = icmp slt <4 x i32> %310, zeroinitializer
  %313 = select <4 x i1> %312, <4 x i32> %311, <4 x i32> %310
  %314 = add nuw <4 x i32> %313, <i32 32, i32 32, i32 32, i32 32>
  %315 = lshr <4 x i32> %314, <i32 6, i32 6, i32 6, i32 6>
  %316 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %305, <4 x i32> %315) #5
  %317 = lshr <8 x i16> %316, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %318 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %289, <8 x i16> %317) #5
  %319 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %318, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %320 = icmp slt <16 x i8> %319, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %321 = select <16 x i1> %320, <16 x i8> %319, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %322 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %321
  %323 = bitcast i8* %263 to <16 x i8>*
  store <16 x i8> %322, <16 x i8>* %323, align 16
  %324 = getelementptr inbounds i16, i16* %9, i64 80
  %325 = getelementptr inbounds i16, i16* %10, i64 80
  %326 = getelementptr inbounds i8, i8* %263, i64 16
  %327 = bitcast i16* %324 to <8 x i16>*
  %328 = load <8 x i16>, <8 x i16>* %327, align 16
  %329 = bitcast i16* %325 to <8 x i16>*
  %330 = load <8 x i16>, <8 x i16>* %329, align 16
  %331 = shufflevector <8 x i16> %328, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %332 = zext <4 x i16> %331 to <4 x i32>
  %333 = shufflevector <8 x i16> %330, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %334 = zext <4 x i16> %333 to <4 x i32>
  %335 = sub nsw <4 x i32> %332, %334
  %336 = sub nsw <4 x i32> zeroinitializer, %335
  %337 = icmp slt <4 x i32> %335, zeroinitializer
  %338 = select <4 x i1> %337, <4 x i32> %336, <4 x i32> %335
  %339 = add nuw nsw <4 x i32> %338, <i32 32, i32 32, i32 32, i32 32>
  %340 = lshr <4 x i32> %339, <i32 6, i32 6, i32 6, i32 6>
  %341 = shufflevector <8 x i16> %328, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %342 = shufflevector <8 x i16> %330, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %343 = bitcast <8 x i16> %341 to <4 x i32>
  %344 = bitcast <8 x i16> %342 to <4 x i32>
  %345 = sub <4 x i32> %343, %344
  %346 = sub <4 x i32> zeroinitializer, %345
  %347 = icmp slt <4 x i32> %345, zeroinitializer
  %348 = select <4 x i1> %347, <4 x i32> %346, <4 x i32> %345
  %349 = add nuw <4 x i32> %348, <i32 32, i32 32, i32 32, i32 32>
  %350 = lshr <4 x i32> %349, <i32 6, i32 6, i32 6, i32 6>
  %351 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %340, <4 x i32> %350) #5
  %352 = lshr <8 x i16> %351, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %353 = getelementptr inbounds i16, i16* %9, i64 88
  %354 = bitcast i16* %353 to <8 x i16>*
  %355 = load <8 x i16>, <8 x i16>* %354, align 16
  %356 = getelementptr inbounds i16, i16* %10, i64 88
  %357 = bitcast i16* %356 to <8 x i16>*
  %358 = load <8 x i16>, <8 x i16>* %357, align 16
  %359 = shufflevector <8 x i16> %355, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %360 = zext <4 x i16> %359 to <4 x i32>
  %361 = shufflevector <8 x i16> %358, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %362 = zext <4 x i16> %361 to <4 x i32>
  %363 = sub nsw <4 x i32> %360, %362
  %364 = sub nsw <4 x i32> zeroinitializer, %363
  %365 = icmp slt <4 x i32> %363, zeroinitializer
  %366 = select <4 x i1> %365, <4 x i32> %364, <4 x i32> %363
  %367 = add nuw nsw <4 x i32> %366, <i32 32, i32 32, i32 32, i32 32>
  %368 = lshr <4 x i32> %367, <i32 6, i32 6, i32 6, i32 6>
  %369 = shufflevector <8 x i16> %355, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %370 = shufflevector <8 x i16> %358, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %371 = bitcast <8 x i16> %369 to <4 x i32>
  %372 = bitcast <8 x i16> %370 to <4 x i32>
  %373 = sub <4 x i32> %371, %372
  %374 = sub <4 x i32> zeroinitializer, %373
  %375 = icmp slt <4 x i32> %373, zeroinitializer
  %376 = select <4 x i1> %375, <4 x i32> %374, <4 x i32> %373
  %377 = add nuw <4 x i32> %376, <i32 32, i32 32, i32 32, i32 32>
  %378 = lshr <4 x i32> %377, <i32 6, i32 6, i32 6, i32 6>
  %379 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %368, <4 x i32> %378) #5
  %380 = lshr <8 x i16> %379, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %381 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %352, <8 x i16> %380) #5
  %382 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %381, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %383 = icmp slt <16 x i8> %382, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %384 = select <16 x i1> %383, <16 x i8> %382, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %385 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %384
  %386 = bitcast i8* %326 to <16 x i8>*
  store <16 x i8> %385, <16 x i8>* %386, align 16
  %387 = getelementptr inbounds i16, i16* %9, i64 96
  %388 = getelementptr inbounds i16, i16* %10, i64 96
  %389 = getelementptr inbounds i8, i8* %263, i64 %3
  %390 = add nsw i32 %11, -1
  %391 = icmp eq i32 %390, 0
  br i1 %391, label %392, label %7

392:                                              ; preds = %7
  %393 = bitcast i16* %387 to <8 x i16>*
  %394 = load <8 x i16>, <8 x i16>* %393, align 16
  %395 = bitcast i16* %388 to <8 x i16>*
  %396 = load <8 x i16>, <8 x i16>* %395, align 16
  %397 = shufflevector <8 x i16> %394, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %398 = zext <4 x i16> %397 to <4 x i32>
  %399 = shufflevector <8 x i16> %396, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %400 = zext <4 x i16> %399 to <4 x i32>
  %401 = sub nsw <4 x i32> %398, %400
  %402 = sub nsw <4 x i32> zeroinitializer, %401
  %403 = icmp slt <4 x i32> %401, zeroinitializer
  %404 = select <4 x i1> %403, <4 x i32> %402, <4 x i32> %401
  %405 = add nuw nsw <4 x i32> %404, <i32 32, i32 32, i32 32, i32 32>
  %406 = lshr <4 x i32> %405, <i32 6, i32 6, i32 6, i32 6>
  %407 = shufflevector <8 x i16> %394, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %408 = shufflevector <8 x i16> %396, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %409 = bitcast <8 x i16> %407 to <4 x i32>
  %410 = bitcast <8 x i16> %408 to <4 x i32>
  %411 = sub <4 x i32> %409, %410
  %412 = sub <4 x i32> zeroinitializer, %411
  %413 = icmp slt <4 x i32> %411, zeroinitializer
  %414 = select <4 x i1> %413, <4 x i32> %412, <4 x i32> %411
  %415 = add nuw <4 x i32> %414, <i32 32, i32 32, i32 32, i32 32>
  %416 = lshr <4 x i32> %415, <i32 6, i32 6, i32 6, i32 6>
  %417 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %406, <4 x i32> %416) #5
  %418 = lshr <8 x i16> %417, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %419 = getelementptr inbounds i16, i16* %9, i64 104
  %420 = bitcast i16* %419 to <8 x i16>*
  %421 = load <8 x i16>, <8 x i16>* %420, align 16
  %422 = getelementptr inbounds i16, i16* %10, i64 104
  %423 = bitcast i16* %422 to <8 x i16>*
  %424 = load <8 x i16>, <8 x i16>* %423, align 16
  %425 = shufflevector <8 x i16> %421, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %426 = zext <4 x i16> %425 to <4 x i32>
  %427 = shufflevector <8 x i16> %424, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %428 = zext <4 x i16> %427 to <4 x i32>
  %429 = sub nsw <4 x i32> %426, %428
  %430 = sub nsw <4 x i32> zeroinitializer, %429
  %431 = icmp slt <4 x i32> %429, zeroinitializer
  %432 = select <4 x i1> %431, <4 x i32> %430, <4 x i32> %429
  %433 = add nuw nsw <4 x i32> %432, <i32 32, i32 32, i32 32, i32 32>
  %434 = lshr <4 x i32> %433, <i32 6, i32 6, i32 6, i32 6>
  %435 = shufflevector <8 x i16> %421, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %436 = shufflevector <8 x i16> %424, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %437 = bitcast <8 x i16> %435 to <4 x i32>
  %438 = bitcast <8 x i16> %436 to <4 x i32>
  %439 = sub <4 x i32> %437, %438
  %440 = sub <4 x i32> zeroinitializer, %439
  %441 = icmp slt <4 x i32> %439, zeroinitializer
  %442 = select <4 x i1> %441, <4 x i32> %440, <4 x i32> %439
  %443 = add nuw <4 x i32> %442, <i32 32, i32 32, i32 32, i32 32>
  %444 = lshr <4 x i32> %443, <i32 6, i32 6, i32 6, i32 6>
  %445 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %434, <4 x i32> %444) #5
  %446 = lshr <8 x i16> %445, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %447 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %418, <8 x i16> %446) #5
  %448 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %447, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %449 = icmp slt <16 x i8> %448, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %450 = select <16 x i1> %449, <16 x i8> %448, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %451 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %450
  %452 = bitcast i8* %389 to <16 x i8>*
  store <16 x i8> %451, <16 x i8>* %452, align 16
  %453 = getelementptr inbounds i16, i16* %9, i64 112
  %454 = getelementptr inbounds i16, i16* %10, i64 112
  %455 = getelementptr inbounds i8, i8* %389, i64 16
  %456 = bitcast i16* %453 to <8 x i16>*
  %457 = load <8 x i16>, <8 x i16>* %456, align 16
  %458 = bitcast i16* %454 to <8 x i16>*
  %459 = load <8 x i16>, <8 x i16>* %458, align 16
  %460 = shufflevector <8 x i16> %457, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %461 = zext <4 x i16> %460 to <4 x i32>
  %462 = shufflevector <8 x i16> %459, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %463 = zext <4 x i16> %462 to <4 x i32>
  %464 = sub nsw <4 x i32> %461, %463
  %465 = sub nsw <4 x i32> zeroinitializer, %464
  %466 = icmp slt <4 x i32> %464, zeroinitializer
  %467 = select <4 x i1> %466, <4 x i32> %465, <4 x i32> %464
  %468 = add nuw nsw <4 x i32> %467, <i32 32, i32 32, i32 32, i32 32>
  %469 = lshr <4 x i32> %468, <i32 6, i32 6, i32 6, i32 6>
  %470 = shufflevector <8 x i16> %457, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %471 = shufflevector <8 x i16> %459, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %472 = bitcast <8 x i16> %470 to <4 x i32>
  %473 = bitcast <8 x i16> %471 to <4 x i32>
  %474 = sub <4 x i32> %472, %473
  %475 = sub <4 x i32> zeroinitializer, %474
  %476 = icmp slt <4 x i32> %474, zeroinitializer
  %477 = select <4 x i1> %476, <4 x i32> %475, <4 x i32> %474
  %478 = add nuw <4 x i32> %477, <i32 32, i32 32, i32 32, i32 32>
  %479 = lshr <4 x i32> %478, <i32 6, i32 6, i32 6, i32 6>
  %480 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %469, <4 x i32> %479) #5
  %481 = lshr <8 x i16> %480, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %482 = getelementptr inbounds i16, i16* %9, i64 120
  %483 = bitcast i16* %482 to <8 x i16>*
  %484 = load <8 x i16>, <8 x i16>* %483, align 16
  %485 = getelementptr inbounds i16, i16* %10, i64 120
  %486 = bitcast i16* %485 to <8 x i16>*
  %487 = load <8 x i16>, <8 x i16>* %486, align 16
  %488 = shufflevector <8 x i16> %484, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %489 = zext <4 x i16> %488 to <4 x i32>
  %490 = shufflevector <8 x i16> %487, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %491 = zext <4 x i16> %490 to <4 x i32>
  %492 = sub nsw <4 x i32> %489, %491
  %493 = sub nsw <4 x i32> zeroinitializer, %492
  %494 = icmp slt <4 x i32> %492, zeroinitializer
  %495 = select <4 x i1> %494, <4 x i32> %493, <4 x i32> %492
  %496 = add nuw nsw <4 x i32> %495, <i32 32, i32 32, i32 32, i32 32>
  %497 = lshr <4 x i32> %496, <i32 6, i32 6, i32 6, i32 6>
  %498 = shufflevector <8 x i16> %484, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %499 = shufflevector <8 x i16> %487, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %500 = bitcast <8 x i16> %498 to <4 x i32>
  %501 = bitcast <8 x i16> %499 to <4 x i32>
  %502 = sub <4 x i32> %500, %501
  %503 = sub <4 x i32> zeroinitializer, %502
  %504 = icmp slt <4 x i32> %502, zeroinitializer
  %505 = select <4 x i1> %504, <4 x i32> %503, <4 x i32> %502
  %506 = add nuw <4 x i32> %505, <i32 32, i32 32, i32 32, i32 32>
  %507 = lshr <4 x i32> %506, <i32 6, i32 6, i32 6, i32 6>
  %508 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %497, <4 x i32> %507) #5
  %509 = lshr <8 x i16> %508, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %510 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %481, <8 x i16> %509) #5
  %511 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %510, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %512 = icmp slt <16 x i8> %511, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %513 = select <16 x i1> %512, <16 x i8> %511, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %514 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %513
  %515 = bitcast i8* %455 to <16 x i8>*
  store <16 x i8> %514, <16 x i8>* %515, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask32x32_10bpp_SSE4ILb0EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %631, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %629, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %630, %7 ]
  %11 = phi i32 [ 6, %4 ], [ %632, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = shufflevector <8 x i16> %13, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %17 = zext <4 x i16> %16 to <4 x i32>
  %18 = shufflevector <8 x i16> %15, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %19 = zext <4 x i16> %18 to <4 x i32>
  %20 = sub nsw <4 x i32> %17, %19
  %21 = sub nsw <4 x i32> zeroinitializer, %20
  %22 = icmp slt <4 x i32> %20, zeroinitializer
  %23 = select <4 x i1> %22, <4 x i32> %21, <4 x i32> %20
  %24 = add nuw nsw <4 x i32> %23, <i32 32, i32 32, i32 32, i32 32>
  %25 = lshr <4 x i32> %24, <i32 6, i32 6, i32 6, i32 6>
  %26 = shufflevector <8 x i16> %13, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %27 = shufflevector <8 x i16> %15, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %28 = bitcast <8 x i16> %26 to <4 x i32>
  %29 = bitcast <8 x i16> %27 to <4 x i32>
  %30 = sub <4 x i32> %28, %29
  %31 = sub <4 x i32> zeroinitializer, %30
  %32 = icmp slt <4 x i32> %30, zeroinitializer
  %33 = select <4 x i1> %32, <4 x i32> %31, <4 x i32> %30
  %34 = add nuw <4 x i32> %33, <i32 32, i32 32, i32 32, i32 32>
  %35 = lshr <4 x i32> %34, <i32 6, i32 6, i32 6, i32 6>
  %36 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %25, <4 x i32> %35) #5
  %37 = lshr <8 x i16> %36, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %38 = getelementptr inbounds i16, i16* %9, i64 8
  %39 = bitcast i16* %38 to <8 x i16>*
  %40 = load <8 x i16>, <8 x i16>* %39, align 16
  %41 = getelementptr inbounds i16, i16* %10, i64 8
  %42 = bitcast i16* %41 to <8 x i16>*
  %43 = load <8 x i16>, <8 x i16>* %42, align 16
  %44 = shufflevector <8 x i16> %40, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %45 = zext <4 x i16> %44 to <4 x i32>
  %46 = shufflevector <8 x i16> %43, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %47 = zext <4 x i16> %46 to <4 x i32>
  %48 = sub nsw <4 x i32> %45, %47
  %49 = sub nsw <4 x i32> zeroinitializer, %48
  %50 = icmp slt <4 x i32> %48, zeroinitializer
  %51 = select <4 x i1> %50, <4 x i32> %49, <4 x i32> %48
  %52 = add nuw nsw <4 x i32> %51, <i32 32, i32 32, i32 32, i32 32>
  %53 = lshr <4 x i32> %52, <i32 6, i32 6, i32 6, i32 6>
  %54 = shufflevector <8 x i16> %40, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %55 = shufflevector <8 x i16> %43, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %56 = bitcast <8 x i16> %54 to <4 x i32>
  %57 = bitcast <8 x i16> %55 to <4 x i32>
  %58 = sub <4 x i32> %56, %57
  %59 = sub <4 x i32> zeroinitializer, %58
  %60 = icmp slt <4 x i32> %58, zeroinitializer
  %61 = select <4 x i1> %60, <4 x i32> %59, <4 x i32> %58
  %62 = add nuw <4 x i32> %61, <i32 32, i32 32, i32 32, i32 32>
  %63 = lshr <4 x i32> %62, <i32 6, i32 6, i32 6, i32 6>
  %64 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %53, <4 x i32> %63) #5
  %65 = lshr <8 x i16> %64, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %66 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %37, <8 x i16> %65) #5
  %67 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %66, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %68 = icmp slt <16 x i8> %67, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %69 = select <16 x i1> %68, <16 x i8> %67, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %70 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %69, <16 x i8>* %70, align 16
  %71 = getelementptr inbounds i16, i16* %9, i64 16
  %72 = getelementptr inbounds i16, i16* %10, i64 16
  %73 = getelementptr inbounds i8, i8* %8, i64 16
  %74 = bitcast i16* %71 to <8 x i16>*
  %75 = load <8 x i16>, <8 x i16>* %74, align 16
  %76 = bitcast i16* %72 to <8 x i16>*
  %77 = load <8 x i16>, <8 x i16>* %76, align 16
  %78 = shufflevector <8 x i16> %75, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %79 = zext <4 x i16> %78 to <4 x i32>
  %80 = shufflevector <8 x i16> %77, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %81 = zext <4 x i16> %80 to <4 x i32>
  %82 = sub nsw <4 x i32> %79, %81
  %83 = sub nsw <4 x i32> zeroinitializer, %82
  %84 = icmp slt <4 x i32> %82, zeroinitializer
  %85 = select <4 x i1> %84, <4 x i32> %83, <4 x i32> %82
  %86 = add nuw nsw <4 x i32> %85, <i32 32, i32 32, i32 32, i32 32>
  %87 = lshr <4 x i32> %86, <i32 6, i32 6, i32 6, i32 6>
  %88 = shufflevector <8 x i16> %75, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %89 = shufflevector <8 x i16> %77, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %90 = bitcast <8 x i16> %88 to <4 x i32>
  %91 = bitcast <8 x i16> %89 to <4 x i32>
  %92 = sub <4 x i32> %90, %91
  %93 = sub <4 x i32> zeroinitializer, %92
  %94 = icmp slt <4 x i32> %92, zeroinitializer
  %95 = select <4 x i1> %94, <4 x i32> %93, <4 x i32> %92
  %96 = add nuw <4 x i32> %95, <i32 32, i32 32, i32 32, i32 32>
  %97 = lshr <4 x i32> %96, <i32 6, i32 6, i32 6, i32 6>
  %98 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %87, <4 x i32> %97) #5
  %99 = lshr <8 x i16> %98, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %100 = getelementptr inbounds i16, i16* %9, i64 24
  %101 = bitcast i16* %100 to <8 x i16>*
  %102 = load <8 x i16>, <8 x i16>* %101, align 16
  %103 = getelementptr inbounds i16, i16* %10, i64 24
  %104 = bitcast i16* %103 to <8 x i16>*
  %105 = load <8 x i16>, <8 x i16>* %104, align 16
  %106 = shufflevector <8 x i16> %102, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %107 = zext <4 x i16> %106 to <4 x i32>
  %108 = shufflevector <8 x i16> %105, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %109 = zext <4 x i16> %108 to <4 x i32>
  %110 = sub nsw <4 x i32> %107, %109
  %111 = sub nsw <4 x i32> zeroinitializer, %110
  %112 = icmp slt <4 x i32> %110, zeroinitializer
  %113 = select <4 x i1> %112, <4 x i32> %111, <4 x i32> %110
  %114 = add nuw nsw <4 x i32> %113, <i32 32, i32 32, i32 32, i32 32>
  %115 = lshr <4 x i32> %114, <i32 6, i32 6, i32 6, i32 6>
  %116 = shufflevector <8 x i16> %102, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %117 = shufflevector <8 x i16> %105, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %118 = bitcast <8 x i16> %116 to <4 x i32>
  %119 = bitcast <8 x i16> %117 to <4 x i32>
  %120 = sub <4 x i32> %118, %119
  %121 = sub <4 x i32> zeroinitializer, %120
  %122 = icmp slt <4 x i32> %120, zeroinitializer
  %123 = select <4 x i1> %122, <4 x i32> %121, <4 x i32> %120
  %124 = add nuw <4 x i32> %123, <i32 32, i32 32, i32 32, i32 32>
  %125 = lshr <4 x i32> %124, <i32 6, i32 6, i32 6, i32 6>
  %126 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %115, <4 x i32> %125) #5
  %127 = lshr <8 x i16> %126, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %128 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %99, <8 x i16> %127) #5
  %129 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %128, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %130 = icmp slt <16 x i8> %129, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %131 = select <16 x i1> %130, <16 x i8> %129, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %132 = bitcast i8* %73 to <16 x i8>*
  store <16 x i8> %131, <16 x i8>* %132, align 16
  %133 = getelementptr inbounds i16, i16* %9, i64 32
  %134 = getelementptr inbounds i16, i16* %10, i64 32
  %135 = getelementptr inbounds i8, i8* %8, i64 %3
  %136 = bitcast i16* %133 to <8 x i16>*
  %137 = load <8 x i16>, <8 x i16>* %136, align 16
  %138 = bitcast i16* %134 to <8 x i16>*
  %139 = load <8 x i16>, <8 x i16>* %138, align 16
  %140 = shufflevector <8 x i16> %137, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %141 = zext <4 x i16> %140 to <4 x i32>
  %142 = shufflevector <8 x i16> %139, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %143 = zext <4 x i16> %142 to <4 x i32>
  %144 = sub nsw <4 x i32> %141, %143
  %145 = sub nsw <4 x i32> zeroinitializer, %144
  %146 = icmp slt <4 x i32> %144, zeroinitializer
  %147 = select <4 x i1> %146, <4 x i32> %145, <4 x i32> %144
  %148 = add nuw nsw <4 x i32> %147, <i32 32, i32 32, i32 32, i32 32>
  %149 = lshr <4 x i32> %148, <i32 6, i32 6, i32 6, i32 6>
  %150 = shufflevector <8 x i16> %137, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %151 = shufflevector <8 x i16> %139, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %152 = bitcast <8 x i16> %150 to <4 x i32>
  %153 = bitcast <8 x i16> %151 to <4 x i32>
  %154 = sub <4 x i32> %152, %153
  %155 = sub <4 x i32> zeroinitializer, %154
  %156 = icmp slt <4 x i32> %154, zeroinitializer
  %157 = select <4 x i1> %156, <4 x i32> %155, <4 x i32> %154
  %158 = add nuw <4 x i32> %157, <i32 32, i32 32, i32 32, i32 32>
  %159 = lshr <4 x i32> %158, <i32 6, i32 6, i32 6, i32 6>
  %160 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %149, <4 x i32> %159) #5
  %161 = lshr <8 x i16> %160, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %162 = getelementptr inbounds i16, i16* %9, i64 40
  %163 = bitcast i16* %162 to <8 x i16>*
  %164 = load <8 x i16>, <8 x i16>* %163, align 16
  %165 = getelementptr inbounds i16, i16* %10, i64 40
  %166 = bitcast i16* %165 to <8 x i16>*
  %167 = load <8 x i16>, <8 x i16>* %166, align 16
  %168 = shufflevector <8 x i16> %164, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %169 = zext <4 x i16> %168 to <4 x i32>
  %170 = shufflevector <8 x i16> %167, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %171 = zext <4 x i16> %170 to <4 x i32>
  %172 = sub nsw <4 x i32> %169, %171
  %173 = sub nsw <4 x i32> zeroinitializer, %172
  %174 = icmp slt <4 x i32> %172, zeroinitializer
  %175 = select <4 x i1> %174, <4 x i32> %173, <4 x i32> %172
  %176 = add nuw nsw <4 x i32> %175, <i32 32, i32 32, i32 32, i32 32>
  %177 = lshr <4 x i32> %176, <i32 6, i32 6, i32 6, i32 6>
  %178 = shufflevector <8 x i16> %164, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %179 = shufflevector <8 x i16> %167, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %180 = bitcast <8 x i16> %178 to <4 x i32>
  %181 = bitcast <8 x i16> %179 to <4 x i32>
  %182 = sub <4 x i32> %180, %181
  %183 = sub <4 x i32> zeroinitializer, %182
  %184 = icmp slt <4 x i32> %182, zeroinitializer
  %185 = select <4 x i1> %184, <4 x i32> %183, <4 x i32> %182
  %186 = add nuw <4 x i32> %185, <i32 32, i32 32, i32 32, i32 32>
  %187 = lshr <4 x i32> %186, <i32 6, i32 6, i32 6, i32 6>
  %188 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %177, <4 x i32> %187) #5
  %189 = lshr <8 x i16> %188, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %190 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %161, <8 x i16> %189) #5
  %191 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %190, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %192 = icmp slt <16 x i8> %191, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %193 = select <16 x i1> %192, <16 x i8> %191, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %194 = bitcast i8* %135 to <16 x i8>*
  store <16 x i8> %193, <16 x i8>* %194, align 16
  %195 = getelementptr inbounds i16, i16* %9, i64 48
  %196 = getelementptr inbounds i16, i16* %10, i64 48
  %197 = getelementptr inbounds i8, i8* %135, i64 16
  %198 = bitcast i16* %195 to <8 x i16>*
  %199 = load <8 x i16>, <8 x i16>* %198, align 16
  %200 = bitcast i16* %196 to <8 x i16>*
  %201 = load <8 x i16>, <8 x i16>* %200, align 16
  %202 = shufflevector <8 x i16> %199, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %203 = zext <4 x i16> %202 to <4 x i32>
  %204 = shufflevector <8 x i16> %201, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %205 = zext <4 x i16> %204 to <4 x i32>
  %206 = sub nsw <4 x i32> %203, %205
  %207 = sub nsw <4 x i32> zeroinitializer, %206
  %208 = icmp slt <4 x i32> %206, zeroinitializer
  %209 = select <4 x i1> %208, <4 x i32> %207, <4 x i32> %206
  %210 = add nuw nsw <4 x i32> %209, <i32 32, i32 32, i32 32, i32 32>
  %211 = lshr <4 x i32> %210, <i32 6, i32 6, i32 6, i32 6>
  %212 = shufflevector <8 x i16> %199, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %213 = shufflevector <8 x i16> %201, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %214 = bitcast <8 x i16> %212 to <4 x i32>
  %215 = bitcast <8 x i16> %213 to <4 x i32>
  %216 = sub <4 x i32> %214, %215
  %217 = sub <4 x i32> zeroinitializer, %216
  %218 = icmp slt <4 x i32> %216, zeroinitializer
  %219 = select <4 x i1> %218, <4 x i32> %217, <4 x i32> %216
  %220 = add nuw <4 x i32> %219, <i32 32, i32 32, i32 32, i32 32>
  %221 = lshr <4 x i32> %220, <i32 6, i32 6, i32 6, i32 6>
  %222 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %211, <4 x i32> %221) #5
  %223 = lshr <8 x i16> %222, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %224 = getelementptr inbounds i16, i16* %9, i64 56
  %225 = bitcast i16* %224 to <8 x i16>*
  %226 = load <8 x i16>, <8 x i16>* %225, align 16
  %227 = getelementptr inbounds i16, i16* %10, i64 56
  %228 = bitcast i16* %227 to <8 x i16>*
  %229 = load <8 x i16>, <8 x i16>* %228, align 16
  %230 = shufflevector <8 x i16> %226, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %231 = zext <4 x i16> %230 to <4 x i32>
  %232 = shufflevector <8 x i16> %229, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %233 = zext <4 x i16> %232 to <4 x i32>
  %234 = sub nsw <4 x i32> %231, %233
  %235 = sub nsw <4 x i32> zeroinitializer, %234
  %236 = icmp slt <4 x i32> %234, zeroinitializer
  %237 = select <4 x i1> %236, <4 x i32> %235, <4 x i32> %234
  %238 = add nuw nsw <4 x i32> %237, <i32 32, i32 32, i32 32, i32 32>
  %239 = lshr <4 x i32> %238, <i32 6, i32 6, i32 6, i32 6>
  %240 = shufflevector <8 x i16> %226, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %241 = shufflevector <8 x i16> %229, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %242 = bitcast <8 x i16> %240 to <4 x i32>
  %243 = bitcast <8 x i16> %241 to <4 x i32>
  %244 = sub <4 x i32> %242, %243
  %245 = sub <4 x i32> zeroinitializer, %244
  %246 = icmp slt <4 x i32> %244, zeroinitializer
  %247 = select <4 x i1> %246, <4 x i32> %245, <4 x i32> %244
  %248 = add nuw <4 x i32> %247, <i32 32, i32 32, i32 32, i32 32>
  %249 = lshr <4 x i32> %248, <i32 6, i32 6, i32 6, i32 6>
  %250 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %239, <4 x i32> %249) #5
  %251 = lshr <8 x i16> %250, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %252 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %223, <8 x i16> %251) #5
  %253 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %252, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %254 = icmp slt <16 x i8> %253, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %255 = select <16 x i1> %254, <16 x i8> %253, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %256 = bitcast i8* %197 to <16 x i8>*
  store <16 x i8> %255, <16 x i8>* %256, align 16
  %257 = getelementptr inbounds i16, i16* %9, i64 64
  %258 = getelementptr inbounds i16, i16* %10, i64 64
  %259 = getelementptr inbounds i8, i8* %135, i64 %3
  %260 = bitcast i16* %257 to <8 x i16>*
  %261 = load <8 x i16>, <8 x i16>* %260, align 16
  %262 = bitcast i16* %258 to <8 x i16>*
  %263 = load <8 x i16>, <8 x i16>* %262, align 16
  %264 = shufflevector <8 x i16> %261, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %265 = zext <4 x i16> %264 to <4 x i32>
  %266 = shufflevector <8 x i16> %263, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %267 = zext <4 x i16> %266 to <4 x i32>
  %268 = sub nsw <4 x i32> %265, %267
  %269 = sub nsw <4 x i32> zeroinitializer, %268
  %270 = icmp slt <4 x i32> %268, zeroinitializer
  %271 = select <4 x i1> %270, <4 x i32> %269, <4 x i32> %268
  %272 = add nuw nsw <4 x i32> %271, <i32 32, i32 32, i32 32, i32 32>
  %273 = lshr <4 x i32> %272, <i32 6, i32 6, i32 6, i32 6>
  %274 = shufflevector <8 x i16> %261, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %275 = shufflevector <8 x i16> %263, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %276 = bitcast <8 x i16> %274 to <4 x i32>
  %277 = bitcast <8 x i16> %275 to <4 x i32>
  %278 = sub <4 x i32> %276, %277
  %279 = sub <4 x i32> zeroinitializer, %278
  %280 = icmp slt <4 x i32> %278, zeroinitializer
  %281 = select <4 x i1> %280, <4 x i32> %279, <4 x i32> %278
  %282 = add nuw <4 x i32> %281, <i32 32, i32 32, i32 32, i32 32>
  %283 = lshr <4 x i32> %282, <i32 6, i32 6, i32 6, i32 6>
  %284 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %273, <4 x i32> %283) #5
  %285 = lshr <8 x i16> %284, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %286 = getelementptr inbounds i16, i16* %9, i64 72
  %287 = bitcast i16* %286 to <8 x i16>*
  %288 = load <8 x i16>, <8 x i16>* %287, align 16
  %289 = getelementptr inbounds i16, i16* %10, i64 72
  %290 = bitcast i16* %289 to <8 x i16>*
  %291 = load <8 x i16>, <8 x i16>* %290, align 16
  %292 = shufflevector <8 x i16> %288, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %293 = zext <4 x i16> %292 to <4 x i32>
  %294 = shufflevector <8 x i16> %291, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %295 = zext <4 x i16> %294 to <4 x i32>
  %296 = sub nsw <4 x i32> %293, %295
  %297 = sub nsw <4 x i32> zeroinitializer, %296
  %298 = icmp slt <4 x i32> %296, zeroinitializer
  %299 = select <4 x i1> %298, <4 x i32> %297, <4 x i32> %296
  %300 = add nuw nsw <4 x i32> %299, <i32 32, i32 32, i32 32, i32 32>
  %301 = lshr <4 x i32> %300, <i32 6, i32 6, i32 6, i32 6>
  %302 = shufflevector <8 x i16> %288, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %303 = shufflevector <8 x i16> %291, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %304 = bitcast <8 x i16> %302 to <4 x i32>
  %305 = bitcast <8 x i16> %303 to <4 x i32>
  %306 = sub <4 x i32> %304, %305
  %307 = sub <4 x i32> zeroinitializer, %306
  %308 = icmp slt <4 x i32> %306, zeroinitializer
  %309 = select <4 x i1> %308, <4 x i32> %307, <4 x i32> %306
  %310 = add nuw <4 x i32> %309, <i32 32, i32 32, i32 32, i32 32>
  %311 = lshr <4 x i32> %310, <i32 6, i32 6, i32 6, i32 6>
  %312 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %301, <4 x i32> %311) #5
  %313 = lshr <8 x i16> %312, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %314 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %285, <8 x i16> %313) #5
  %315 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %314, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %316 = icmp slt <16 x i8> %315, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %317 = select <16 x i1> %316, <16 x i8> %315, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %318 = bitcast i8* %259 to <16 x i8>*
  store <16 x i8> %317, <16 x i8>* %318, align 16
  %319 = getelementptr inbounds i16, i16* %9, i64 80
  %320 = getelementptr inbounds i16, i16* %10, i64 80
  %321 = getelementptr inbounds i8, i8* %259, i64 16
  %322 = bitcast i16* %319 to <8 x i16>*
  %323 = load <8 x i16>, <8 x i16>* %322, align 16
  %324 = bitcast i16* %320 to <8 x i16>*
  %325 = load <8 x i16>, <8 x i16>* %324, align 16
  %326 = shufflevector <8 x i16> %323, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %327 = zext <4 x i16> %326 to <4 x i32>
  %328 = shufflevector <8 x i16> %325, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %329 = zext <4 x i16> %328 to <4 x i32>
  %330 = sub nsw <4 x i32> %327, %329
  %331 = sub nsw <4 x i32> zeroinitializer, %330
  %332 = icmp slt <4 x i32> %330, zeroinitializer
  %333 = select <4 x i1> %332, <4 x i32> %331, <4 x i32> %330
  %334 = add nuw nsw <4 x i32> %333, <i32 32, i32 32, i32 32, i32 32>
  %335 = lshr <4 x i32> %334, <i32 6, i32 6, i32 6, i32 6>
  %336 = shufflevector <8 x i16> %323, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %337 = shufflevector <8 x i16> %325, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %338 = bitcast <8 x i16> %336 to <4 x i32>
  %339 = bitcast <8 x i16> %337 to <4 x i32>
  %340 = sub <4 x i32> %338, %339
  %341 = sub <4 x i32> zeroinitializer, %340
  %342 = icmp slt <4 x i32> %340, zeroinitializer
  %343 = select <4 x i1> %342, <4 x i32> %341, <4 x i32> %340
  %344 = add nuw <4 x i32> %343, <i32 32, i32 32, i32 32, i32 32>
  %345 = lshr <4 x i32> %344, <i32 6, i32 6, i32 6, i32 6>
  %346 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %335, <4 x i32> %345) #5
  %347 = lshr <8 x i16> %346, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %348 = getelementptr inbounds i16, i16* %9, i64 88
  %349 = bitcast i16* %348 to <8 x i16>*
  %350 = load <8 x i16>, <8 x i16>* %349, align 16
  %351 = getelementptr inbounds i16, i16* %10, i64 88
  %352 = bitcast i16* %351 to <8 x i16>*
  %353 = load <8 x i16>, <8 x i16>* %352, align 16
  %354 = shufflevector <8 x i16> %350, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %355 = zext <4 x i16> %354 to <4 x i32>
  %356 = shufflevector <8 x i16> %353, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %357 = zext <4 x i16> %356 to <4 x i32>
  %358 = sub nsw <4 x i32> %355, %357
  %359 = sub nsw <4 x i32> zeroinitializer, %358
  %360 = icmp slt <4 x i32> %358, zeroinitializer
  %361 = select <4 x i1> %360, <4 x i32> %359, <4 x i32> %358
  %362 = add nuw nsw <4 x i32> %361, <i32 32, i32 32, i32 32, i32 32>
  %363 = lshr <4 x i32> %362, <i32 6, i32 6, i32 6, i32 6>
  %364 = shufflevector <8 x i16> %350, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %365 = shufflevector <8 x i16> %353, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %366 = bitcast <8 x i16> %364 to <4 x i32>
  %367 = bitcast <8 x i16> %365 to <4 x i32>
  %368 = sub <4 x i32> %366, %367
  %369 = sub <4 x i32> zeroinitializer, %368
  %370 = icmp slt <4 x i32> %368, zeroinitializer
  %371 = select <4 x i1> %370, <4 x i32> %369, <4 x i32> %368
  %372 = add nuw <4 x i32> %371, <i32 32, i32 32, i32 32, i32 32>
  %373 = lshr <4 x i32> %372, <i32 6, i32 6, i32 6, i32 6>
  %374 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %363, <4 x i32> %373) #5
  %375 = lshr <8 x i16> %374, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %376 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %347, <8 x i16> %375) #5
  %377 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %376, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %378 = icmp slt <16 x i8> %377, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %379 = select <16 x i1> %378, <16 x i8> %377, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %380 = bitcast i8* %321 to <16 x i8>*
  store <16 x i8> %379, <16 x i8>* %380, align 16
  %381 = getelementptr inbounds i16, i16* %9, i64 96
  %382 = getelementptr inbounds i16, i16* %10, i64 96
  %383 = getelementptr inbounds i8, i8* %259, i64 %3
  %384 = bitcast i16* %381 to <8 x i16>*
  %385 = load <8 x i16>, <8 x i16>* %384, align 16
  %386 = bitcast i16* %382 to <8 x i16>*
  %387 = load <8 x i16>, <8 x i16>* %386, align 16
  %388 = shufflevector <8 x i16> %385, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %389 = zext <4 x i16> %388 to <4 x i32>
  %390 = shufflevector <8 x i16> %387, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %391 = zext <4 x i16> %390 to <4 x i32>
  %392 = sub nsw <4 x i32> %389, %391
  %393 = sub nsw <4 x i32> zeroinitializer, %392
  %394 = icmp slt <4 x i32> %392, zeroinitializer
  %395 = select <4 x i1> %394, <4 x i32> %393, <4 x i32> %392
  %396 = add nuw nsw <4 x i32> %395, <i32 32, i32 32, i32 32, i32 32>
  %397 = lshr <4 x i32> %396, <i32 6, i32 6, i32 6, i32 6>
  %398 = shufflevector <8 x i16> %385, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %399 = shufflevector <8 x i16> %387, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %400 = bitcast <8 x i16> %398 to <4 x i32>
  %401 = bitcast <8 x i16> %399 to <4 x i32>
  %402 = sub <4 x i32> %400, %401
  %403 = sub <4 x i32> zeroinitializer, %402
  %404 = icmp slt <4 x i32> %402, zeroinitializer
  %405 = select <4 x i1> %404, <4 x i32> %403, <4 x i32> %402
  %406 = add nuw <4 x i32> %405, <i32 32, i32 32, i32 32, i32 32>
  %407 = lshr <4 x i32> %406, <i32 6, i32 6, i32 6, i32 6>
  %408 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %397, <4 x i32> %407) #5
  %409 = lshr <8 x i16> %408, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %410 = getelementptr inbounds i16, i16* %9, i64 104
  %411 = bitcast i16* %410 to <8 x i16>*
  %412 = load <8 x i16>, <8 x i16>* %411, align 16
  %413 = getelementptr inbounds i16, i16* %10, i64 104
  %414 = bitcast i16* %413 to <8 x i16>*
  %415 = load <8 x i16>, <8 x i16>* %414, align 16
  %416 = shufflevector <8 x i16> %412, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %417 = zext <4 x i16> %416 to <4 x i32>
  %418 = shufflevector <8 x i16> %415, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %419 = zext <4 x i16> %418 to <4 x i32>
  %420 = sub nsw <4 x i32> %417, %419
  %421 = sub nsw <4 x i32> zeroinitializer, %420
  %422 = icmp slt <4 x i32> %420, zeroinitializer
  %423 = select <4 x i1> %422, <4 x i32> %421, <4 x i32> %420
  %424 = add nuw nsw <4 x i32> %423, <i32 32, i32 32, i32 32, i32 32>
  %425 = lshr <4 x i32> %424, <i32 6, i32 6, i32 6, i32 6>
  %426 = shufflevector <8 x i16> %412, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %427 = shufflevector <8 x i16> %415, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %428 = bitcast <8 x i16> %426 to <4 x i32>
  %429 = bitcast <8 x i16> %427 to <4 x i32>
  %430 = sub <4 x i32> %428, %429
  %431 = sub <4 x i32> zeroinitializer, %430
  %432 = icmp slt <4 x i32> %430, zeroinitializer
  %433 = select <4 x i1> %432, <4 x i32> %431, <4 x i32> %430
  %434 = add nuw <4 x i32> %433, <i32 32, i32 32, i32 32, i32 32>
  %435 = lshr <4 x i32> %434, <i32 6, i32 6, i32 6, i32 6>
  %436 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %425, <4 x i32> %435) #5
  %437 = lshr <8 x i16> %436, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %438 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %409, <8 x i16> %437) #5
  %439 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %438, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %440 = icmp slt <16 x i8> %439, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %441 = select <16 x i1> %440, <16 x i8> %439, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %442 = bitcast i8* %383 to <16 x i8>*
  store <16 x i8> %441, <16 x i8>* %442, align 16
  %443 = getelementptr inbounds i16, i16* %9, i64 112
  %444 = getelementptr inbounds i16, i16* %10, i64 112
  %445 = getelementptr inbounds i8, i8* %383, i64 16
  %446 = bitcast i16* %443 to <8 x i16>*
  %447 = load <8 x i16>, <8 x i16>* %446, align 16
  %448 = bitcast i16* %444 to <8 x i16>*
  %449 = load <8 x i16>, <8 x i16>* %448, align 16
  %450 = shufflevector <8 x i16> %447, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %451 = zext <4 x i16> %450 to <4 x i32>
  %452 = shufflevector <8 x i16> %449, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %453 = zext <4 x i16> %452 to <4 x i32>
  %454 = sub nsw <4 x i32> %451, %453
  %455 = sub nsw <4 x i32> zeroinitializer, %454
  %456 = icmp slt <4 x i32> %454, zeroinitializer
  %457 = select <4 x i1> %456, <4 x i32> %455, <4 x i32> %454
  %458 = add nuw nsw <4 x i32> %457, <i32 32, i32 32, i32 32, i32 32>
  %459 = lshr <4 x i32> %458, <i32 6, i32 6, i32 6, i32 6>
  %460 = shufflevector <8 x i16> %447, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %461 = shufflevector <8 x i16> %449, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %462 = bitcast <8 x i16> %460 to <4 x i32>
  %463 = bitcast <8 x i16> %461 to <4 x i32>
  %464 = sub <4 x i32> %462, %463
  %465 = sub <4 x i32> zeroinitializer, %464
  %466 = icmp slt <4 x i32> %464, zeroinitializer
  %467 = select <4 x i1> %466, <4 x i32> %465, <4 x i32> %464
  %468 = add nuw <4 x i32> %467, <i32 32, i32 32, i32 32, i32 32>
  %469 = lshr <4 x i32> %468, <i32 6, i32 6, i32 6, i32 6>
  %470 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %459, <4 x i32> %469) #5
  %471 = lshr <8 x i16> %470, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %472 = getelementptr inbounds i16, i16* %9, i64 120
  %473 = bitcast i16* %472 to <8 x i16>*
  %474 = load <8 x i16>, <8 x i16>* %473, align 16
  %475 = getelementptr inbounds i16, i16* %10, i64 120
  %476 = bitcast i16* %475 to <8 x i16>*
  %477 = load <8 x i16>, <8 x i16>* %476, align 16
  %478 = shufflevector <8 x i16> %474, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %479 = zext <4 x i16> %478 to <4 x i32>
  %480 = shufflevector <8 x i16> %477, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %481 = zext <4 x i16> %480 to <4 x i32>
  %482 = sub nsw <4 x i32> %479, %481
  %483 = sub nsw <4 x i32> zeroinitializer, %482
  %484 = icmp slt <4 x i32> %482, zeroinitializer
  %485 = select <4 x i1> %484, <4 x i32> %483, <4 x i32> %482
  %486 = add nuw nsw <4 x i32> %485, <i32 32, i32 32, i32 32, i32 32>
  %487 = lshr <4 x i32> %486, <i32 6, i32 6, i32 6, i32 6>
  %488 = shufflevector <8 x i16> %474, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %489 = shufflevector <8 x i16> %477, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %490 = bitcast <8 x i16> %488 to <4 x i32>
  %491 = bitcast <8 x i16> %489 to <4 x i32>
  %492 = sub <4 x i32> %490, %491
  %493 = sub <4 x i32> zeroinitializer, %492
  %494 = icmp slt <4 x i32> %492, zeroinitializer
  %495 = select <4 x i1> %494, <4 x i32> %493, <4 x i32> %492
  %496 = add nuw <4 x i32> %495, <i32 32, i32 32, i32 32, i32 32>
  %497 = lshr <4 x i32> %496, <i32 6, i32 6, i32 6, i32 6>
  %498 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %487, <4 x i32> %497) #5
  %499 = lshr <8 x i16> %498, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %500 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %471, <8 x i16> %499) #5
  %501 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %500, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %502 = icmp slt <16 x i8> %501, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %503 = select <16 x i1> %502, <16 x i8> %501, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %504 = bitcast i8* %445 to <16 x i8>*
  store <16 x i8> %503, <16 x i8>* %504, align 16
  %505 = getelementptr inbounds i16, i16* %9, i64 128
  %506 = getelementptr inbounds i16, i16* %10, i64 128
  %507 = getelementptr inbounds i8, i8* %383, i64 %3
  %508 = bitcast i16* %505 to <8 x i16>*
  %509 = load <8 x i16>, <8 x i16>* %508, align 16
  %510 = bitcast i16* %506 to <8 x i16>*
  %511 = load <8 x i16>, <8 x i16>* %510, align 16
  %512 = shufflevector <8 x i16> %509, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %513 = zext <4 x i16> %512 to <4 x i32>
  %514 = shufflevector <8 x i16> %511, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %515 = zext <4 x i16> %514 to <4 x i32>
  %516 = sub nsw <4 x i32> %513, %515
  %517 = sub nsw <4 x i32> zeroinitializer, %516
  %518 = icmp slt <4 x i32> %516, zeroinitializer
  %519 = select <4 x i1> %518, <4 x i32> %517, <4 x i32> %516
  %520 = add nuw nsw <4 x i32> %519, <i32 32, i32 32, i32 32, i32 32>
  %521 = lshr <4 x i32> %520, <i32 6, i32 6, i32 6, i32 6>
  %522 = shufflevector <8 x i16> %509, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %523 = shufflevector <8 x i16> %511, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %524 = bitcast <8 x i16> %522 to <4 x i32>
  %525 = bitcast <8 x i16> %523 to <4 x i32>
  %526 = sub <4 x i32> %524, %525
  %527 = sub <4 x i32> zeroinitializer, %526
  %528 = icmp slt <4 x i32> %526, zeroinitializer
  %529 = select <4 x i1> %528, <4 x i32> %527, <4 x i32> %526
  %530 = add nuw <4 x i32> %529, <i32 32, i32 32, i32 32, i32 32>
  %531 = lshr <4 x i32> %530, <i32 6, i32 6, i32 6, i32 6>
  %532 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %521, <4 x i32> %531) #5
  %533 = lshr <8 x i16> %532, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %534 = getelementptr inbounds i16, i16* %9, i64 136
  %535 = bitcast i16* %534 to <8 x i16>*
  %536 = load <8 x i16>, <8 x i16>* %535, align 16
  %537 = getelementptr inbounds i16, i16* %10, i64 136
  %538 = bitcast i16* %537 to <8 x i16>*
  %539 = load <8 x i16>, <8 x i16>* %538, align 16
  %540 = shufflevector <8 x i16> %536, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %541 = zext <4 x i16> %540 to <4 x i32>
  %542 = shufflevector <8 x i16> %539, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %543 = zext <4 x i16> %542 to <4 x i32>
  %544 = sub nsw <4 x i32> %541, %543
  %545 = sub nsw <4 x i32> zeroinitializer, %544
  %546 = icmp slt <4 x i32> %544, zeroinitializer
  %547 = select <4 x i1> %546, <4 x i32> %545, <4 x i32> %544
  %548 = add nuw nsw <4 x i32> %547, <i32 32, i32 32, i32 32, i32 32>
  %549 = lshr <4 x i32> %548, <i32 6, i32 6, i32 6, i32 6>
  %550 = shufflevector <8 x i16> %536, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %551 = shufflevector <8 x i16> %539, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %552 = bitcast <8 x i16> %550 to <4 x i32>
  %553 = bitcast <8 x i16> %551 to <4 x i32>
  %554 = sub <4 x i32> %552, %553
  %555 = sub <4 x i32> zeroinitializer, %554
  %556 = icmp slt <4 x i32> %554, zeroinitializer
  %557 = select <4 x i1> %556, <4 x i32> %555, <4 x i32> %554
  %558 = add nuw <4 x i32> %557, <i32 32, i32 32, i32 32, i32 32>
  %559 = lshr <4 x i32> %558, <i32 6, i32 6, i32 6, i32 6>
  %560 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %549, <4 x i32> %559) #5
  %561 = lshr <8 x i16> %560, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %562 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %533, <8 x i16> %561) #5
  %563 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %562, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %564 = icmp slt <16 x i8> %563, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %565 = select <16 x i1> %564, <16 x i8> %563, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %566 = bitcast i8* %507 to <16 x i8>*
  store <16 x i8> %565, <16 x i8>* %566, align 16
  %567 = getelementptr inbounds i16, i16* %9, i64 144
  %568 = getelementptr inbounds i16, i16* %10, i64 144
  %569 = getelementptr inbounds i8, i8* %507, i64 16
  %570 = bitcast i16* %567 to <8 x i16>*
  %571 = load <8 x i16>, <8 x i16>* %570, align 16
  %572 = bitcast i16* %568 to <8 x i16>*
  %573 = load <8 x i16>, <8 x i16>* %572, align 16
  %574 = shufflevector <8 x i16> %571, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %575 = zext <4 x i16> %574 to <4 x i32>
  %576 = shufflevector <8 x i16> %573, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %577 = zext <4 x i16> %576 to <4 x i32>
  %578 = sub nsw <4 x i32> %575, %577
  %579 = sub nsw <4 x i32> zeroinitializer, %578
  %580 = icmp slt <4 x i32> %578, zeroinitializer
  %581 = select <4 x i1> %580, <4 x i32> %579, <4 x i32> %578
  %582 = add nuw nsw <4 x i32> %581, <i32 32, i32 32, i32 32, i32 32>
  %583 = lshr <4 x i32> %582, <i32 6, i32 6, i32 6, i32 6>
  %584 = shufflevector <8 x i16> %571, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %585 = shufflevector <8 x i16> %573, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %586 = bitcast <8 x i16> %584 to <4 x i32>
  %587 = bitcast <8 x i16> %585 to <4 x i32>
  %588 = sub <4 x i32> %586, %587
  %589 = sub <4 x i32> zeroinitializer, %588
  %590 = icmp slt <4 x i32> %588, zeroinitializer
  %591 = select <4 x i1> %590, <4 x i32> %589, <4 x i32> %588
  %592 = add nuw <4 x i32> %591, <i32 32, i32 32, i32 32, i32 32>
  %593 = lshr <4 x i32> %592, <i32 6, i32 6, i32 6, i32 6>
  %594 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %583, <4 x i32> %593) #5
  %595 = lshr <8 x i16> %594, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %596 = getelementptr inbounds i16, i16* %9, i64 152
  %597 = bitcast i16* %596 to <8 x i16>*
  %598 = load <8 x i16>, <8 x i16>* %597, align 16
  %599 = getelementptr inbounds i16, i16* %10, i64 152
  %600 = bitcast i16* %599 to <8 x i16>*
  %601 = load <8 x i16>, <8 x i16>* %600, align 16
  %602 = shufflevector <8 x i16> %598, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %603 = zext <4 x i16> %602 to <4 x i32>
  %604 = shufflevector <8 x i16> %601, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %605 = zext <4 x i16> %604 to <4 x i32>
  %606 = sub nsw <4 x i32> %603, %605
  %607 = sub nsw <4 x i32> zeroinitializer, %606
  %608 = icmp slt <4 x i32> %606, zeroinitializer
  %609 = select <4 x i1> %608, <4 x i32> %607, <4 x i32> %606
  %610 = add nuw nsw <4 x i32> %609, <i32 32, i32 32, i32 32, i32 32>
  %611 = lshr <4 x i32> %610, <i32 6, i32 6, i32 6, i32 6>
  %612 = shufflevector <8 x i16> %598, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %613 = shufflevector <8 x i16> %601, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %614 = bitcast <8 x i16> %612 to <4 x i32>
  %615 = bitcast <8 x i16> %613 to <4 x i32>
  %616 = sub <4 x i32> %614, %615
  %617 = sub <4 x i32> zeroinitializer, %616
  %618 = icmp slt <4 x i32> %616, zeroinitializer
  %619 = select <4 x i1> %618, <4 x i32> %617, <4 x i32> %616
  %620 = add nuw <4 x i32> %619, <i32 32, i32 32, i32 32, i32 32>
  %621 = lshr <4 x i32> %620, <i32 6, i32 6, i32 6, i32 6>
  %622 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %611, <4 x i32> %621) #5
  %623 = lshr <8 x i16> %622, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %624 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %595, <8 x i16> %623) #5
  %625 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %624, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %626 = icmp slt <16 x i8> %625, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %627 = select <16 x i1> %626, <16 x i8> %625, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %628 = bitcast i8* %569 to <16 x i8>*
  store <16 x i8> %627, <16 x i8>* %628, align 16
  %629 = getelementptr inbounds i16, i16* %9, i64 160
  %630 = getelementptr inbounds i16, i16* %10, i64 160
  %631 = getelementptr inbounds i8, i8* %507, i64 %3
  %632 = add nsw i32 %11, -1
  %633 = icmp eq i32 %632, 0
  br i1 %633, label %634, label %7

634:                                              ; preds = %7
  %635 = bitcast i16* %629 to <8 x i16>*
  %636 = load <8 x i16>, <8 x i16>* %635, align 16
  %637 = bitcast i16* %630 to <8 x i16>*
  %638 = load <8 x i16>, <8 x i16>* %637, align 16
  %639 = shufflevector <8 x i16> %636, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %640 = zext <4 x i16> %639 to <4 x i32>
  %641 = shufflevector <8 x i16> %638, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %642 = zext <4 x i16> %641 to <4 x i32>
  %643 = sub nsw <4 x i32> %640, %642
  %644 = sub nsw <4 x i32> zeroinitializer, %643
  %645 = icmp slt <4 x i32> %643, zeroinitializer
  %646 = select <4 x i1> %645, <4 x i32> %644, <4 x i32> %643
  %647 = add nuw nsw <4 x i32> %646, <i32 32, i32 32, i32 32, i32 32>
  %648 = lshr <4 x i32> %647, <i32 6, i32 6, i32 6, i32 6>
  %649 = shufflevector <8 x i16> %636, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %650 = shufflevector <8 x i16> %638, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %651 = bitcast <8 x i16> %649 to <4 x i32>
  %652 = bitcast <8 x i16> %650 to <4 x i32>
  %653 = sub <4 x i32> %651, %652
  %654 = sub <4 x i32> zeroinitializer, %653
  %655 = icmp slt <4 x i32> %653, zeroinitializer
  %656 = select <4 x i1> %655, <4 x i32> %654, <4 x i32> %653
  %657 = add nuw <4 x i32> %656, <i32 32, i32 32, i32 32, i32 32>
  %658 = lshr <4 x i32> %657, <i32 6, i32 6, i32 6, i32 6>
  %659 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %648, <4 x i32> %658) #5
  %660 = lshr <8 x i16> %659, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %661 = getelementptr inbounds i16, i16* %9, i64 168
  %662 = bitcast i16* %661 to <8 x i16>*
  %663 = load <8 x i16>, <8 x i16>* %662, align 16
  %664 = getelementptr inbounds i16, i16* %10, i64 168
  %665 = bitcast i16* %664 to <8 x i16>*
  %666 = load <8 x i16>, <8 x i16>* %665, align 16
  %667 = shufflevector <8 x i16> %663, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %668 = zext <4 x i16> %667 to <4 x i32>
  %669 = shufflevector <8 x i16> %666, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %670 = zext <4 x i16> %669 to <4 x i32>
  %671 = sub nsw <4 x i32> %668, %670
  %672 = sub nsw <4 x i32> zeroinitializer, %671
  %673 = icmp slt <4 x i32> %671, zeroinitializer
  %674 = select <4 x i1> %673, <4 x i32> %672, <4 x i32> %671
  %675 = add nuw nsw <4 x i32> %674, <i32 32, i32 32, i32 32, i32 32>
  %676 = lshr <4 x i32> %675, <i32 6, i32 6, i32 6, i32 6>
  %677 = shufflevector <8 x i16> %663, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %678 = shufflevector <8 x i16> %666, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %679 = bitcast <8 x i16> %677 to <4 x i32>
  %680 = bitcast <8 x i16> %678 to <4 x i32>
  %681 = sub <4 x i32> %679, %680
  %682 = sub <4 x i32> zeroinitializer, %681
  %683 = icmp slt <4 x i32> %681, zeroinitializer
  %684 = select <4 x i1> %683, <4 x i32> %682, <4 x i32> %681
  %685 = add nuw <4 x i32> %684, <i32 32, i32 32, i32 32, i32 32>
  %686 = lshr <4 x i32> %685, <i32 6, i32 6, i32 6, i32 6>
  %687 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %676, <4 x i32> %686) #5
  %688 = lshr <8 x i16> %687, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %689 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %660, <8 x i16> %688) #5
  %690 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %689, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %691 = icmp slt <16 x i8> %690, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %692 = select <16 x i1> %691, <16 x i8> %690, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %693 = bitcast i8* %631 to <16 x i8>*
  store <16 x i8> %692, <16 x i8>* %693, align 16
  %694 = getelementptr inbounds i16, i16* %9, i64 176
  %695 = getelementptr inbounds i16, i16* %10, i64 176
  %696 = getelementptr inbounds i8, i8* %631, i64 16
  %697 = bitcast i16* %694 to <8 x i16>*
  %698 = load <8 x i16>, <8 x i16>* %697, align 16
  %699 = bitcast i16* %695 to <8 x i16>*
  %700 = load <8 x i16>, <8 x i16>* %699, align 16
  %701 = shufflevector <8 x i16> %698, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %702 = zext <4 x i16> %701 to <4 x i32>
  %703 = shufflevector <8 x i16> %700, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %704 = zext <4 x i16> %703 to <4 x i32>
  %705 = sub nsw <4 x i32> %702, %704
  %706 = sub nsw <4 x i32> zeroinitializer, %705
  %707 = icmp slt <4 x i32> %705, zeroinitializer
  %708 = select <4 x i1> %707, <4 x i32> %706, <4 x i32> %705
  %709 = add nuw nsw <4 x i32> %708, <i32 32, i32 32, i32 32, i32 32>
  %710 = lshr <4 x i32> %709, <i32 6, i32 6, i32 6, i32 6>
  %711 = shufflevector <8 x i16> %698, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %712 = shufflevector <8 x i16> %700, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %713 = bitcast <8 x i16> %711 to <4 x i32>
  %714 = bitcast <8 x i16> %712 to <4 x i32>
  %715 = sub <4 x i32> %713, %714
  %716 = sub <4 x i32> zeroinitializer, %715
  %717 = icmp slt <4 x i32> %715, zeroinitializer
  %718 = select <4 x i1> %717, <4 x i32> %716, <4 x i32> %715
  %719 = add nuw <4 x i32> %718, <i32 32, i32 32, i32 32, i32 32>
  %720 = lshr <4 x i32> %719, <i32 6, i32 6, i32 6, i32 6>
  %721 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %710, <4 x i32> %720) #5
  %722 = lshr <8 x i16> %721, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %723 = getelementptr inbounds i16, i16* %9, i64 184
  %724 = bitcast i16* %723 to <8 x i16>*
  %725 = load <8 x i16>, <8 x i16>* %724, align 16
  %726 = getelementptr inbounds i16, i16* %10, i64 184
  %727 = bitcast i16* %726 to <8 x i16>*
  %728 = load <8 x i16>, <8 x i16>* %727, align 16
  %729 = shufflevector <8 x i16> %725, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %730 = zext <4 x i16> %729 to <4 x i32>
  %731 = shufflevector <8 x i16> %728, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %732 = zext <4 x i16> %731 to <4 x i32>
  %733 = sub nsw <4 x i32> %730, %732
  %734 = sub nsw <4 x i32> zeroinitializer, %733
  %735 = icmp slt <4 x i32> %733, zeroinitializer
  %736 = select <4 x i1> %735, <4 x i32> %734, <4 x i32> %733
  %737 = add nuw nsw <4 x i32> %736, <i32 32, i32 32, i32 32, i32 32>
  %738 = lshr <4 x i32> %737, <i32 6, i32 6, i32 6, i32 6>
  %739 = shufflevector <8 x i16> %725, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %740 = shufflevector <8 x i16> %728, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %741 = bitcast <8 x i16> %739 to <4 x i32>
  %742 = bitcast <8 x i16> %740 to <4 x i32>
  %743 = sub <4 x i32> %741, %742
  %744 = sub <4 x i32> zeroinitializer, %743
  %745 = icmp slt <4 x i32> %743, zeroinitializer
  %746 = select <4 x i1> %745, <4 x i32> %744, <4 x i32> %743
  %747 = add nuw <4 x i32> %746, <i32 32, i32 32, i32 32, i32 32>
  %748 = lshr <4 x i32> %747, <i32 6, i32 6, i32 6, i32 6>
  %749 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %738, <4 x i32> %748) #5
  %750 = lshr <8 x i16> %749, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %751 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %722, <8 x i16> %750) #5
  %752 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %751, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %753 = icmp slt <16 x i8> %752, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %754 = select <16 x i1> %753, <16 x i8> %752, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %755 = bitcast i8* %696 to <16 x i8>*
  store <16 x i8> %754, <16 x i8>* %755, align 16
  %756 = getelementptr inbounds i16, i16* %9, i64 192
  %757 = getelementptr inbounds i16, i16* %10, i64 192
  %758 = getelementptr inbounds i8, i8* %631, i64 %3
  %759 = bitcast i16* %756 to <8 x i16>*
  %760 = load <8 x i16>, <8 x i16>* %759, align 16
  %761 = bitcast i16* %757 to <8 x i16>*
  %762 = load <8 x i16>, <8 x i16>* %761, align 16
  %763 = shufflevector <8 x i16> %760, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %764 = zext <4 x i16> %763 to <4 x i32>
  %765 = shufflevector <8 x i16> %762, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %766 = zext <4 x i16> %765 to <4 x i32>
  %767 = sub nsw <4 x i32> %764, %766
  %768 = sub nsw <4 x i32> zeroinitializer, %767
  %769 = icmp slt <4 x i32> %767, zeroinitializer
  %770 = select <4 x i1> %769, <4 x i32> %768, <4 x i32> %767
  %771 = add nuw nsw <4 x i32> %770, <i32 32, i32 32, i32 32, i32 32>
  %772 = lshr <4 x i32> %771, <i32 6, i32 6, i32 6, i32 6>
  %773 = shufflevector <8 x i16> %760, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %774 = shufflevector <8 x i16> %762, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %775 = bitcast <8 x i16> %773 to <4 x i32>
  %776 = bitcast <8 x i16> %774 to <4 x i32>
  %777 = sub <4 x i32> %775, %776
  %778 = sub <4 x i32> zeroinitializer, %777
  %779 = icmp slt <4 x i32> %777, zeroinitializer
  %780 = select <4 x i1> %779, <4 x i32> %778, <4 x i32> %777
  %781 = add nuw <4 x i32> %780, <i32 32, i32 32, i32 32, i32 32>
  %782 = lshr <4 x i32> %781, <i32 6, i32 6, i32 6, i32 6>
  %783 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %772, <4 x i32> %782) #5
  %784 = lshr <8 x i16> %783, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %785 = getelementptr inbounds i16, i16* %9, i64 200
  %786 = bitcast i16* %785 to <8 x i16>*
  %787 = load <8 x i16>, <8 x i16>* %786, align 16
  %788 = getelementptr inbounds i16, i16* %10, i64 200
  %789 = bitcast i16* %788 to <8 x i16>*
  %790 = load <8 x i16>, <8 x i16>* %789, align 16
  %791 = shufflevector <8 x i16> %787, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %792 = zext <4 x i16> %791 to <4 x i32>
  %793 = shufflevector <8 x i16> %790, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %794 = zext <4 x i16> %793 to <4 x i32>
  %795 = sub nsw <4 x i32> %792, %794
  %796 = sub nsw <4 x i32> zeroinitializer, %795
  %797 = icmp slt <4 x i32> %795, zeroinitializer
  %798 = select <4 x i1> %797, <4 x i32> %796, <4 x i32> %795
  %799 = add nuw nsw <4 x i32> %798, <i32 32, i32 32, i32 32, i32 32>
  %800 = lshr <4 x i32> %799, <i32 6, i32 6, i32 6, i32 6>
  %801 = shufflevector <8 x i16> %787, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %802 = shufflevector <8 x i16> %790, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %803 = bitcast <8 x i16> %801 to <4 x i32>
  %804 = bitcast <8 x i16> %802 to <4 x i32>
  %805 = sub <4 x i32> %803, %804
  %806 = sub <4 x i32> zeroinitializer, %805
  %807 = icmp slt <4 x i32> %805, zeroinitializer
  %808 = select <4 x i1> %807, <4 x i32> %806, <4 x i32> %805
  %809 = add nuw <4 x i32> %808, <i32 32, i32 32, i32 32, i32 32>
  %810 = lshr <4 x i32> %809, <i32 6, i32 6, i32 6, i32 6>
  %811 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %800, <4 x i32> %810) #5
  %812 = lshr <8 x i16> %811, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %813 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %784, <8 x i16> %812) #5
  %814 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %813, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %815 = icmp slt <16 x i8> %814, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %816 = select <16 x i1> %815, <16 x i8> %814, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %817 = bitcast i8* %758 to <16 x i8>*
  store <16 x i8> %816, <16 x i8>* %817, align 16
  %818 = getelementptr inbounds i16, i16* %9, i64 208
  %819 = getelementptr inbounds i16, i16* %10, i64 208
  %820 = getelementptr inbounds i8, i8* %758, i64 16
  %821 = bitcast i16* %818 to <8 x i16>*
  %822 = load <8 x i16>, <8 x i16>* %821, align 16
  %823 = bitcast i16* %819 to <8 x i16>*
  %824 = load <8 x i16>, <8 x i16>* %823, align 16
  %825 = shufflevector <8 x i16> %822, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %826 = zext <4 x i16> %825 to <4 x i32>
  %827 = shufflevector <8 x i16> %824, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %828 = zext <4 x i16> %827 to <4 x i32>
  %829 = sub nsw <4 x i32> %826, %828
  %830 = sub nsw <4 x i32> zeroinitializer, %829
  %831 = icmp slt <4 x i32> %829, zeroinitializer
  %832 = select <4 x i1> %831, <4 x i32> %830, <4 x i32> %829
  %833 = add nuw nsw <4 x i32> %832, <i32 32, i32 32, i32 32, i32 32>
  %834 = lshr <4 x i32> %833, <i32 6, i32 6, i32 6, i32 6>
  %835 = shufflevector <8 x i16> %822, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %836 = shufflevector <8 x i16> %824, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %837 = bitcast <8 x i16> %835 to <4 x i32>
  %838 = bitcast <8 x i16> %836 to <4 x i32>
  %839 = sub <4 x i32> %837, %838
  %840 = sub <4 x i32> zeroinitializer, %839
  %841 = icmp slt <4 x i32> %839, zeroinitializer
  %842 = select <4 x i1> %841, <4 x i32> %840, <4 x i32> %839
  %843 = add nuw <4 x i32> %842, <i32 32, i32 32, i32 32, i32 32>
  %844 = lshr <4 x i32> %843, <i32 6, i32 6, i32 6, i32 6>
  %845 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %834, <4 x i32> %844) #5
  %846 = lshr <8 x i16> %845, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %847 = getelementptr inbounds i16, i16* %9, i64 216
  %848 = bitcast i16* %847 to <8 x i16>*
  %849 = load <8 x i16>, <8 x i16>* %848, align 16
  %850 = getelementptr inbounds i16, i16* %10, i64 216
  %851 = bitcast i16* %850 to <8 x i16>*
  %852 = load <8 x i16>, <8 x i16>* %851, align 16
  %853 = shufflevector <8 x i16> %849, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %854 = zext <4 x i16> %853 to <4 x i32>
  %855 = shufflevector <8 x i16> %852, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %856 = zext <4 x i16> %855 to <4 x i32>
  %857 = sub nsw <4 x i32> %854, %856
  %858 = sub nsw <4 x i32> zeroinitializer, %857
  %859 = icmp slt <4 x i32> %857, zeroinitializer
  %860 = select <4 x i1> %859, <4 x i32> %858, <4 x i32> %857
  %861 = add nuw nsw <4 x i32> %860, <i32 32, i32 32, i32 32, i32 32>
  %862 = lshr <4 x i32> %861, <i32 6, i32 6, i32 6, i32 6>
  %863 = shufflevector <8 x i16> %849, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %864 = shufflevector <8 x i16> %852, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %865 = bitcast <8 x i16> %863 to <4 x i32>
  %866 = bitcast <8 x i16> %864 to <4 x i32>
  %867 = sub <4 x i32> %865, %866
  %868 = sub <4 x i32> zeroinitializer, %867
  %869 = icmp slt <4 x i32> %867, zeroinitializer
  %870 = select <4 x i1> %869, <4 x i32> %868, <4 x i32> %867
  %871 = add nuw <4 x i32> %870, <i32 32, i32 32, i32 32, i32 32>
  %872 = lshr <4 x i32> %871, <i32 6, i32 6, i32 6, i32 6>
  %873 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %862, <4 x i32> %872) #5
  %874 = lshr <8 x i16> %873, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %875 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %846, <8 x i16> %874) #5
  %876 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %875, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %877 = icmp slt <16 x i8> %876, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %878 = select <16 x i1> %877, <16 x i8> %876, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %879 = bitcast i8* %820 to <16 x i8>*
  store <16 x i8> %878, <16 x i8>* %879, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask32x32_10bpp_SSE4ILb1EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %641, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %639, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %640, %7 ]
  %11 = phi i32 [ 6, %4 ], [ %642, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = shufflevector <8 x i16> %13, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %17 = zext <4 x i16> %16 to <4 x i32>
  %18 = shufflevector <8 x i16> %15, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %19 = zext <4 x i16> %18 to <4 x i32>
  %20 = sub nsw <4 x i32> %17, %19
  %21 = sub nsw <4 x i32> zeroinitializer, %20
  %22 = icmp slt <4 x i32> %20, zeroinitializer
  %23 = select <4 x i1> %22, <4 x i32> %21, <4 x i32> %20
  %24 = add nuw nsw <4 x i32> %23, <i32 32, i32 32, i32 32, i32 32>
  %25 = lshr <4 x i32> %24, <i32 6, i32 6, i32 6, i32 6>
  %26 = shufflevector <8 x i16> %13, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %27 = shufflevector <8 x i16> %15, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %28 = bitcast <8 x i16> %26 to <4 x i32>
  %29 = bitcast <8 x i16> %27 to <4 x i32>
  %30 = sub <4 x i32> %28, %29
  %31 = sub <4 x i32> zeroinitializer, %30
  %32 = icmp slt <4 x i32> %30, zeroinitializer
  %33 = select <4 x i1> %32, <4 x i32> %31, <4 x i32> %30
  %34 = add nuw <4 x i32> %33, <i32 32, i32 32, i32 32, i32 32>
  %35 = lshr <4 x i32> %34, <i32 6, i32 6, i32 6, i32 6>
  %36 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %25, <4 x i32> %35) #5
  %37 = lshr <8 x i16> %36, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %38 = getelementptr inbounds i16, i16* %9, i64 8
  %39 = bitcast i16* %38 to <8 x i16>*
  %40 = load <8 x i16>, <8 x i16>* %39, align 16
  %41 = getelementptr inbounds i16, i16* %10, i64 8
  %42 = bitcast i16* %41 to <8 x i16>*
  %43 = load <8 x i16>, <8 x i16>* %42, align 16
  %44 = shufflevector <8 x i16> %40, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %45 = zext <4 x i16> %44 to <4 x i32>
  %46 = shufflevector <8 x i16> %43, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %47 = zext <4 x i16> %46 to <4 x i32>
  %48 = sub nsw <4 x i32> %45, %47
  %49 = sub nsw <4 x i32> zeroinitializer, %48
  %50 = icmp slt <4 x i32> %48, zeroinitializer
  %51 = select <4 x i1> %50, <4 x i32> %49, <4 x i32> %48
  %52 = add nuw nsw <4 x i32> %51, <i32 32, i32 32, i32 32, i32 32>
  %53 = lshr <4 x i32> %52, <i32 6, i32 6, i32 6, i32 6>
  %54 = shufflevector <8 x i16> %40, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %55 = shufflevector <8 x i16> %43, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %56 = bitcast <8 x i16> %54 to <4 x i32>
  %57 = bitcast <8 x i16> %55 to <4 x i32>
  %58 = sub <4 x i32> %56, %57
  %59 = sub <4 x i32> zeroinitializer, %58
  %60 = icmp slt <4 x i32> %58, zeroinitializer
  %61 = select <4 x i1> %60, <4 x i32> %59, <4 x i32> %58
  %62 = add nuw <4 x i32> %61, <i32 32, i32 32, i32 32, i32 32>
  %63 = lshr <4 x i32> %62, <i32 6, i32 6, i32 6, i32 6>
  %64 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %53, <4 x i32> %63) #5
  %65 = lshr <8 x i16> %64, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %66 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %37, <8 x i16> %65) #5
  %67 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %66, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %68 = icmp slt <16 x i8> %67, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %69 = select <16 x i1> %68, <16 x i8> %67, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %70 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %69
  %71 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %70, <16 x i8>* %71, align 16
  %72 = getelementptr inbounds i16, i16* %9, i64 16
  %73 = getelementptr inbounds i16, i16* %10, i64 16
  %74 = getelementptr inbounds i8, i8* %8, i64 16
  %75 = bitcast i16* %72 to <8 x i16>*
  %76 = load <8 x i16>, <8 x i16>* %75, align 16
  %77 = bitcast i16* %73 to <8 x i16>*
  %78 = load <8 x i16>, <8 x i16>* %77, align 16
  %79 = shufflevector <8 x i16> %76, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %80 = zext <4 x i16> %79 to <4 x i32>
  %81 = shufflevector <8 x i16> %78, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %82 = zext <4 x i16> %81 to <4 x i32>
  %83 = sub nsw <4 x i32> %80, %82
  %84 = sub nsw <4 x i32> zeroinitializer, %83
  %85 = icmp slt <4 x i32> %83, zeroinitializer
  %86 = select <4 x i1> %85, <4 x i32> %84, <4 x i32> %83
  %87 = add nuw nsw <4 x i32> %86, <i32 32, i32 32, i32 32, i32 32>
  %88 = lshr <4 x i32> %87, <i32 6, i32 6, i32 6, i32 6>
  %89 = shufflevector <8 x i16> %76, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %90 = shufflevector <8 x i16> %78, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %91 = bitcast <8 x i16> %89 to <4 x i32>
  %92 = bitcast <8 x i16> %90 to <4 x i32>
  %93 = sub <4 x i32> %91, %92
  %94 = sub <4 x i32> zeroinitializer, %93
  %95 = icmp slt <4 x i32> %93, zeroinitializer
  %96 = select <4 x i1> %95, <4 x i32> %94, <4 x i32> %93
  %97 = add nuw <4 x i32> %96, <i32 32, i32 32, i32 32, i32 32>
  %98 = lshr <4 x i32> %97, <i32 6, i32 6, i32 6, i32 6>
  %99 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %88, <4 x i32> %98) #5
  %100 = lshr <8 x i16> %99, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %101 = getelementptr inbounds i16, i16* %9, i64 24
  %102 = bitcast i16* %101 to <8 x i16>*
  %103 = load <8 x i16>, <8 x i16>* %102, align 16
  %104 = getelementptr inbounds i16, i16* %10, i64 24
  %105 = bitcast i16* %104 to <8 x i16>*
  %106 = load <8 x i16>, <8 x i16>* %105, align 16
  %107 = shufflevector <8 x i16> %103, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %108 = zext <4 x i16> %107 to <4 x i32>
  %109 = shufflevector <8 x i16> %106, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %110 = zext <4 x i16> %109 to <4 x i32>
  %111 = sub nsw <4 x i32> %108, %110
  %112 = sub nsw <4 x i32> zeroinitializer, %111
  %113 = icmp slt <4 x i32> %111, zeroinitializer
  %114 = select <4 x i1> %113, <4 x i32> %112, <4 x i32> %111
  %115 = add nuw nsw <4 x i32> %114, <i32 32, i32 32, i32 32, i32 32>
  %116 = lshr <4 x i32> %115, <i32 6, i32 6, i32 6, i32 6>
  %117 = shufflevector <8 x i16> %103, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %118 = shufflevector <8 x i16> %106, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %119 = bitcast <8 x i16> %117 to <4 x i32>
  %120 = bitcast <8 x i16> %118 to <4 x i32>
  %121 = sub <4 x i32> %119, %120
  %122 = sub <4 x i32> zeroinitializer, %121
  %123 = icmp slt <4 x i32> %121, zeroinitializer
  %124 = select <4 x i1> %123, <4 x i32> %122, <4 x i32> %121
  %125 = add nuw <4 x i32> %124, <i32 32, i32 32, i32 32, i32 32>
  %126 = lshr <4 x i32> %125, <i32 6, i32 6, i32 6, i32 6>
  %127 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %116, <4 x i32> %126) #5
  %128 = lshr <8 x i16> %127, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %129 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %100, <8 x i16> %128) #5
  %130 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %129, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %131 = icmp slt <16 x i8> %130, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %132 = select <16 x i1> %131, <16 x i8> %130, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %133 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %132
  %134 = bitcast i8* %74 to <16 x i8>*
  store <16 x i8> %133, <16 x i8>* %134, align 16
  %135 = getelementptr inbounds i16, i16* %9, i64 32
  %136 = getelementptr inbounds i16, i16* %10, i64 32
  %137 = getelementptr inbounds i8, i8* %8, i64 %3
  %138 = bitcast i16* %135 to <8 x i16>*
  %139 = load <8 x i16>, <8 x i16>* %138, align 16
  %140 = bitcast i16* %136 to <8 x i16>*
  %141 = load <8 x i16>, <8 x i16>* %140, align 16
  %142 = shufflevector <8 x i16> %139, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %143 = zext <4 x i16> %142 to <4 x i32>
  %144 = shufflevector <8 x i16> %141, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %145 = zext <4 x i16> %144 to <4 x i32>
  %146 = sub nsw <4 x i32> %143, %145
  %147 = sub nsw <4 x i32> zeroinitializer, %146
  %148 = icmp slt <4 x i32> %146, zeroinitializer
  %149 = select <4 x i1> %148, <4 x i32> %147, <4 x i32> %146
  %150 = add nuw nsw <4 x i32> %149, <i32 32, i32 32, i32 32, i32 32>
  %151 = lshr <4 x i32> %150, <i32 6, i32 6, i32 6, i32 6>
  %152 = shufflevector <8 x i16> %139, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %153 = shufflevector <8 x i16> %141, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %154 = bitcast <8 x i16> %152 to <4 x i32>
  %155 = bitcast <8 x i16> %153 to <4 x i32>
  %156 = sub <4 x i32> %154, %155
  %157 = sub <4 x i32> zeroinitializer, %156
  %158 = icmp slt <4 x i32> %156, zeroinitializer
  %159 = select <4 x i1> %158, <4 x i32> %157, <4 x i32> %156
  %160 = add nuw <4 x i32> %159, <i32 32, i32 32, i32 32, i32 32>
  %161 = lshr <4 x i32> %160, <i32 6, i32 6, i32 6, i32 6>
  %162 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %151, <4 x i32> %161) #5
  %163 = lshr <8 x i16> %162, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %164 = getelementptr inbounds i16, i16* %9, i64 40
  %165 = bitcast i16* %164 to <8 x i16>*
  %166 = load <8 x i16>, <8 x i16>* %165, align 16
  %167 = getelementptr inbounds i16, i16* %10, i64 40
  %168 = bitcast i16* %167 to <8 x i16>*
  %169 = load <8 x i16>, <8 x i16>* %168, align 16
  %170 = shufflevector <8 x i16> %166, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %171 = zext <4 x i16> %170 to <4 x i32>
  %172 = shufflevector <8 x i16> %169, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %173 = zext <4 x i16> %172 to <4 x i32>
  %174 = sub nsw <4 x i32> %171, %173
  %175 = sub nsw <4 x i32> zeroinitializer, %174
  %176 = icmp slt <4 x i32> %174, zeroinitializer
  %177 = select <4 x i1> %176, <4 x i32> %175, <4 x i32> %174
  %178 = add nuw nsw <4 x i32> %177, <i32 32, i32 32, i32 32, i32 32>
  %179 = lshr <4 x i32> %178, <i32 6, i32 6, i32 6, i32 6>
  %180 = shufflevector <8 x i16> %166, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %181 = shufflevector <8 x i16> %169, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %182 = bitcast <8 x i16> %180 to <4 x i32>
  %183 = bitcast <8 x i16> %181 to <4 x i32>
  %184 = sub <4 x i32> %182, %183
  %185 = sub <4 x i32> zeroinitializer, %184
  %186 = icmp slt <4 x i32> %184, zeroinitializer
  %187 = select <4 x i1> %186, <4 x i32> %185, <4 x i32> %184
  %188 = add nuw <4 x i32> %187, <i32 32, i32 32, i32 32, i32 32>
  %189 = lshr <4 x i32> %188, <i32 6, i32 6, i32 6, i32 6>
  %190 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %179, <4 x i32> %189) #5
  %191 = lshr <8 x i16> %190, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %192 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %163, <8 x i16> %191) #5
  %193 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %192, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %194 = icmp slt <16 x i8> %193, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %195 = select <16 x i1> %194, <16 x i8> %193, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %196 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %195
  %197 = bitcast i8* %137 to <16 x i8>*
  store <16 x i8> %196, <16 x i8>* %197, align 16
  %198 = getelementptr inbounds i16, i16* %9, i64 48
  %199 = getelementptr inbounds i16, i16* %10, i64 48
  %200 = getelementptr inbounds i8, i8* %137, i64 16
  %201 = bitcast i16* %198 to <8 x i16>*
  %202 = load <8 x i16>, <8 x i16>* %201, align 16
  %203 = bitcast i16* %199 to <8 x i16>*
  %204 = load <8 x i16>, <8 x i16>* %203, align 16
  %205 = shufflevector <8 x i16> %202, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %206 = zext <4 x i16> %205 to <4 x i32>
  %207 = shufflevector <8 x i16> %204, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %208 = zext <4 x i16> %207 to <4 x i32>
  %209 = sub nsw <4 x i32> %206, %208
  %210 = sub nsw <4 x i32> zeroinitializer, %209
  %211 = icmp slt <4 x i32> %209, zeroinitializer
  %212 = select <4 x i1> %211, <4 x i32> %210, <4 x i32> %209
  %213 = add nuw nsw <4 x i32> %212, <i32 32, i32 32, i32 32, i32 32>
  %214 = lshr <4 x i32> %213, <i32 6, i32 6, i32 6, i32 6>
  %215 = shufflevector <8 x i16> %202, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %216 = shufflevector <8 x i16> %204, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %217 = bitcast <8 x i16> %215 to <4 x i32>
  %218 = bitcast <8 x i16> %216 to <4 x i32>
  %219 = sub <4 x i32> %217, %218
  %220 = sub <4 x i32> zeroinitializer, %219
  %221 = icmp slt <4 x i32> %219, zeroinitializer
  %222 = select <4 x i1> %221, <4 x i32> %220, <4 x i32> %219
  %223 = add nuw <4 x i32> %222, <i32 32, i32 32, i32 32, i32 32>
  %224 = lshr <4 x i32> %223, <i32 6, i32 6, i32 6, i32 6>
  %225 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %214, <4 x i32> %224) #5
  %226 = lshr <8 x i16> %225, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %227 = getelementptr inbounds i16, i16* %9, i64 56
  %228 = bitcast i16* %227 to <8 x i16>*
  %229 = load <8 x i16>, <8 x i16>* %228, align 16
  %230 = getelementptr inbounds i16, i16* %10, i64 56
  %231 = bitcast i16* %230 to <8 x i16>*
  %232 = load <8 x i16>, <8 x i16>* %231, align 16
  %233 = shufflevector <8 x i16> %229, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %234 = zext <4 x i16> %233 to <4 x i32>
  %235 = shufflevector <8 x i16> %232, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %236 = zext <4 x i16> %235 to <4 x i32>
  %237 = sub nsw <4 x i32> %234, %236
  %238 = sub nsw <4 x i32> zeroinitializer, %237
  %239 = icmp slt <4 x i32> %237, zeroinitializer
  %240 = select <4 x i1> %239, <4 x i32> %238, <4 x i32> %237
  %241 = add nuw nsw <4 x i32> %240, <i32 32, i32 32, i32 32, i32 32>
  %242 = lshr <4 x i32> %241, <i32 6, i32 6, i32 6, i32 6>
  %243 = shufflevector <8 x i16> %229, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %244 = shufflevector <8 x i16> %232, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %245 = bitcast <8 x i16> %243 to <4 x i32>
  %246 = bitcast <8 x i16> %244 to <4 x i32>
  %247 = sub <4 x i32> %245, %246
  %248 = sub <4 x i32> zeroinitializer, %247
  %249 = icmp slt <4 x i32> %247, zeroinitializer
  %250 = select <4 x i1> %249, <4 x i32> %248, <4 x i32> %247
  %251 = add nuw <4 x i32> %250, <i32 32, i32 32, i32 32, i32 32>
  %252 = lshr <4 x i32> %251, <i32 6, i32 6, i32 6, i32 6>
  %253 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %242, <4 x i32> %252) #5
  %254 = lshr <8 x i16> %253, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %255 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %226, <8 x i16> %254) #5
  %256 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %255, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %257 = icmp slt <16 x i8> %256, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %258 = select <16 x i1> %257, <16 x i8> %256, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %259 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %258
  %260 = bitcast i8* %200 to <16 x i8>*
  store <16 x i8> %259, <16 x i8>* %260, align 16
  %261 = getelementptr inbounds i16, i16* %9, i64 64
  %262 = getelementptr inbounds i16, i16* %10, i64 64
  %263 = getelementptr inbounds i8, i8* %137, i64 %3
  %264 = bitcast i16* %261 to <8 x i16>*
  %265 = load <8 x i16>, <8 x i16>* %264, align 16
  %266 = bitcast i16* %262 to <8 x i16>*
  %267 = load <8 x i16>, <8 x i16>* %266, align 16
  %268 = shufflevector <8 x i16> %265, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %269 = zext <4 x i16> %268 to <4 x i32>
  %270 = shufflevector <8 x i16> %267, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %271 = zext <4 x i16> %270 to <4 x i32>
  %272 = sub nsw <4 x i32> %269, %271
  %273 = sub nsw <4 x i32> zeroinitializer, %272
  %274 = icmp slt <4 x i32> %272, zeroinitializer
  %275 = select <4 x i1> %274, <4 x i32> %273, <4 x i32> %272
  %276 = add nuw nsw <4 x i32> %275, <i32 32, i32 32, i32 32, i32 32>
  %277 = lshr <4 x i32> %276, <i32 6, i32 6, i32 6, i32 6>
  %278 = shufflevector <8 x i16> %265, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %279 = shufflevector <8 x i16> %267, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %280 = bitcast <8 x i16> %278 to <4 x i32>
  %281 = bitcast <8 x i16> %279 to <4 x i32>
  %282 = sub <4 x i32> %280, %281
  %283 = sub <4 x i32> zeroinitializer, %282
  %284 = icmp slt <4 x i32> %282, zeroinitializer
  %285 = select <4 x i1> %284, <4 x i32> %283, <4 x i32> %282
  %286 = add nuw <4 x i32> %285, <i32 32, i32 32, i32 32, i32 32>
  %287 = lshr <4 x i32> %286, <i32 6, i32 6, i32 6, i32 6>
  %288 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %277, <4 x i32> %287) #5
  %289 = lshr <8 x i16> %288, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %290 = getelementptr inbounds i16, i16* %9, i64 72
  %291 = bitcast i16* %290 to <8 x i16>*
  %292 = load <8 x i16>, <8 x i16>* %291, align 16
  %293 = getelementptr inbounds i16, i16* %10, i64 72
  %294 = bitcast i16* %293 to <8 x i16>*
  %295 = load <8 x i16>, <8 x i16>* %294, align 16
  %296 = shufflevector <8 x i16> %292, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %297 = zext <4 x i16> %296 to <4 x i32>
  %298 = shufflevector <8 x i16> %295, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %299 = zext <4 x i16> %298 to <4 x i32>
  %300 = sub nsw <4 x i32> %297, %299
  %301 = sub nsw <4 x i32> zeroinitializer, %300
  %302 = icmp slt <4 x i32> %300, zeroinitializer
  %303 = select <4 x i1> %302, <4 x i32> %301, <4 x i32> %300
  %304 = add nuw nsw <4 x i32> %303, <i32 32, i32 32, i32 32, i32 32>
  %305 = lshr <4 x i32> %304, <i32 6, i32 6, i32 6, i32 6>
  %306 = shufflevector <8 x i16> %292, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %307 = shufflevector <8 x i16> %295, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %308 = bitcast <8 x i16> %306 to <4 x i32>
  %309 = bitcast <8 x i16> %307 to <4 x i32>
  %310 = sub <4 x i32> %308, %309
  %311 = sub <4 x i32> zeroinitializer, %310
  %312 = icmp slt <4 x i32> %310, zeroinitializer
  %313 = select <4 x i1> %312, <4 x i32> %311, <4 x i32> %310
  %314 = add nuw <4 x i32> %313, <i32 32, i32 32, i32 32, i32 32>
  %315 = lshr <4 x i32> %314, <i32 6, i32 6, i32 6, i32 6>
  %316 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %305, <4 x i32> %315) #5
  %317 = lshr <8 x i16> %316, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %318 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %289, <8 x i16> %317) #5
  %319 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %318, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %320 = icmp slt <16 x i8> %319, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %321 = select <16 x i1> %320, <16 x i8> %319, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %322 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %321
  %323 = bitcast i8* %263 to <16 x i8>*
  store <16 x i8> %322, <16 x i8>* %323, align 16
  %324 = getelementptr inbounds i16, i16* %9, i64 80
  %325 = getelementptr inbounds i16, i16* %10, i64 80
  %326 = getelementptr inbounds i8, i8* %263, i64 16
  %327 = bitcast i16* %324 to <8 x i16>*
  %328 = load <8 x i16>, <8 x i16>* %327, align 16
  %329 = bitcast i16* %325 to <8 x i16>*
  %330 = load <8 x i16>, <8 x i16>* %329, align 16
  %331 = shufflevector <8 x i16> %328, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %332 = zext <4 x i16> %331 to <4 x i32>
  %333 = shufflevector <8 x i16> %330, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %334 = zext <4 x i16> %333 to <4 x i32>
  %335 = sub nsw <4 x i32> %332, %334
  %336 = sub nsw <4 x i32> zeroinitializer, %335
  %337 = icmp slt <4 x i32> %335, zeroinitializer
  %338 = select <4 x i1> %337, <4 x i32> %336, <4 x i32> %335
  %339 = add nuw nsw <4 x i32> %338, <i32 32, i32 32, i32 32, i32 32>
  %340 = lshr <4 x i32> %339, <i32 6, i32 6, i32 6, i32 6>
  %341 = shufflevector <8 x i16> %328, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %342 = shufflevector <8 x i16> %330, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %343 = bitcast <8 x i16> %341 to <4 x i32>
  %344 = bitcast <8 x i16> %342 to <4 x i32>
  %345 = sub <4 x i32> %343, %344
  %346 = sub <4 x i32> zeroinitializer, %345
  %347 = icmp slt <4 x i32> %345, zeroinitializer
  %348 = select <4 x i1> %347, <4 x i32> %346, <4 x i32> %345
  %349 = add nuw <4 x i32> %348, <i32 32, i32 32, i32 32, i32 32>
  %350 = lshr <4 x i32> %349, <i32 6, i32 6, i32 6, i32 6>
  %351 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %340, <4 x i32> %350) #5
  %352 = lshr <8 x i16> %351, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %353 = getelementptr inbounds i16, i16* %9, i64 88
  %354 = bitcast i16* %353 to <8 x i16>*
  %355 = load <8 x i16>, <8 x i16>* %354, align 16
  %356 = getelementptr inbounds i16, i16* %10, i64 88
  %357 = bitcast i16* %356 to <8 x i16>*
  %358 = load <8 x i16>, <8 x i16>* %357, align 16
  %359 = shufflevector <8 x i16> %355, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %360 = zext <4 x i16> %359 to <4 x i32>
  %361 = shufflevector <8 x i16> %358, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %362 = zext <4 x i16> %361 to <4 x i32>
  %363 = sub nsw <4 x i32> %360, %362
  %364 = sub nsw <4 x i32> zeroinitializer, %363
  %365 = icmp slt <4 x i32> %363, zeroinitializer
  %366 = select <4 x i1> %365, <4 x i32> %364, <4 x i32> %363
  %367 = add nuw nsw <4 x i32> %366, <i32 32, i32 32, i32 32, i32 32>
  %368 = lshr <4 x i32> %367, <i32 6, i32 6, i32 6, i32 6>
  %369 = shufflevector <8 x i16> %355, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %370 = shufflevector <8 x i16> %358, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %371 = bitcast <8 x i16> %369 to <4 x i32>
  %372 = bitcast <8 x i16> %370 to <4 x i32>
  %373 = sub <4 x i32> %371, %372
  %374 = sub <4 x i32> zeroinitializer, %373
  %375 = icmp slt <4 x i32> %373, zeroinitializer
  %376 = select <4 x i1> %375, <4 x i32> %374, <4 x i32> %373
  %377 = add nuw <4 x i32> %376, <i32 32, i32 32, i32 32, i32 32>
  %378 = lshr <4 x i32> %377, <i32 6, i32 6, i32 6, i32 6>
  %379 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %368, <4 x i32> %378) #5
  %380 = lshr <8 x i16> %379, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %381 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %352, <8 x i16> %380) #5
  %382 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %381, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %383 = icmp slt <16 x i8> %382, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %384 = select <16 x i1> %383, <16 x i8> %382, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %385 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %384
  %386 = bitcast i8* %326 to <16 x i8>*
  store <16 x i8> %385, <16 x i8>* %386, align 16
  %387 = getelementptr inbounds i16, i16* %9, i64 96
  %388 = getelementptr inbounds i16, i16* %10, i64 96
  %389 = getelementptr inbounds i8, i8* %263, i64 %3
  %390 = bitcast i16* %387 to <8 x i16>*
  %391 = load <8 x i16>, <8 x i16>* %390, align 16
  %392 = bitcast i16* %388 to <8 x i16>*
  %393 = load <8 x i16>, <8 x i16>* %392, align 16
  %394 = shufflevector <8 x i16> %391, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %395 = zext <4 x i16> %394 to <4 x i32>
  %396 = shufflevector <8 x i16> %393, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %397 = zext <4 x i16> %396 to <4 x i32>
  %398 = sub nsw <4 x i32> %395, %397
  %399 = sub nsw <4 x i32> zeroinitializer, %398
  %400 = icmp slt <4 x i32> %398, zeroinitializer
  %401 = select <4 x i1> %400, <4 x i32> %399, <4 x i32> %398
  %402 = add nuw nsw <4 x i32> %401, <i32 32, i32 32, i32 32, i32 32>
  %403 = lshr <4 x i32> %402, <i32 6, i32 6, i32 6, i32 6>
  %404 = shufflevector <8 x i16> %391, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %405 = shufflevector <8 x i16> %393, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %406 = bitcast <8 x i16> %404 to <4 x i32>
  %407 = bitcast <8 x i16> %405 to <4 x i32>
  %408 = sub <4 x i32> %406, %407
  %409 = sub <4 x i32> zeroinitializer, %408
  %410 = icmp slt <4 x i32> %408, zeroinitializer
  %411 = select <4 x i1> %410, <4 x i32> %409, <4 x i32> %408
  %412 = add nuw <4 x i32> %411, <i32 32, i32 32, i32 32, i32 32>
  %413 = lshr <4 x i32> %412, <i32 6, i32 6, i32 6, i32 6>
  %414 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %403, <4 x i32> %413) #5
  %415 = lshr <8 x i16> %414, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %416 = getelementptr inbounds i16, i16* %9, i64 104
  %417 = bitcast i16* %416 to <8 x i16>*
  %418 = load <8 x i16>, <8 x i16>* %417, align 16
  %419 = getelementptr inbounds i16, i16* %10, i64 104
  %420 = bitcast i16* %419 to <8 x i16>*
  %421 = load <8 x i16>, <8 x i16>* %420, align 16
  %422 = shufflevector <8 x i16> %418, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %423 = zext <4 x i16> %422 to <4 x i32>
  %424 = shufflevector <8 x i16> %421, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %425 = zext <4 x i16> %424 to <4 x i32>
  %426 = sub nsw <4 x i32> %423, %425
  %427 = sub nsw <4 x i32> zeroinitializer, %426
  %428 = icmp slt <4 x i32> %426, zeroinitializer
  %429 = select <4 x i1> %428, <4 x i32> %427, <4 x i32> %426
  %430 = add nuw nsw <4 x i32> %429, <i32 32, i32 32, i32 32, i32 32>
  %431 = lshr <4 x i32> %430, <i32 6, i32 6, i32 6, i32 6>
  %432 = shufflevector <8 x i16> %418, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %433 = shufflevector <8 x i16> %421, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %434 = bitcast <8 x i16> %432 to <4 x i32>
  %435 = bitcast <8 x i16> %433 to <4 x i32>
  %436 = sub <4 x i32> %434, %435
  %437 = sub <4 x i32> zeroinitializer, %436
  %438 = icmp slt <4 x i32> %436, zeroinitializer
  %439 = select <4 x i1> %438, <4 x i32> %437, <4 x i32> %436
  %440 = add nuw <4 x i32> %439, <i32 32, i32 32, i32 32, i32 32>
  %441 = lshr <4 x i32> %440, <i32 6, i32 6, i32 6, i32 6>
  %442 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %431, <4 x i32> %441) #5
  %443 = lshr <8 x i16> %442, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %444 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %415, <8 x i16> %443) #5
  %445 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %444, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %446 = icmp slt <16 x i8> %445, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %447 = select <16 x i1> %446, <16 x i8> %445, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %448 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %447
  %449 = bitcast i8* %389 to <16 x i8>*
  store <16 x i8> %448, <16 x i8>* %449, align 16
  %450 = getelementptr inbounds i16, i16* %9, i64 112
  %451 = getelementptr inbounds i16, i16* %10, i64 112
  %452 = getelementptr inbounds i8, i8* %389, i64 16
  %453 = bitcast i16* %450 to <8 x i16>*
  %454 = load <8 x i16>, <8 x i16>* %453, align 16
  %455 = bitcast i16* %451 to <8 x i16>*
  %456 = load <8 x i16>, <8 x i16>* %455, align 16
  %457 = shufflevector <8 x i16> %454, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %458 = zext <4 x i16> %457 to <4 x i32>
  %459 = shufflevector <8 x i16> %456, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %460 = zext <4 x i16> %459 to <4 x i32>
  %461 = sub nsw <4 x i32> %458, %460
  %462 = sub nsw <4 x i32> zeroinitializer, %461
  %463 = icmp slt <4 x i32> %461, zeroinitializer
  %464 = select <4 x i1> %463, <4 x i32> %462, <4 x i32> %461
  %465 = add nuw nsw <4 x i32> %464, <i32 32, i32 32, i32 32, i32 32>
  %466 = lshr <4 x i32> %465, <i32 6, i32 6, i32 6, i32 6>
  %467 = shufflevector <8 x i16> %454, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %468 = shufflevector <8 x i16> %456, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %469 = bitcast <8 x i16> %467 to <4 x i32>
  %470 = bitcast <8 x i16> %468 to <4 x i32>
  %471 = sub <4 x i32> %469, %470
  %472 = sub <4 x i32> zeroinitializer, %471
  %473 = icmp slt <4 x i32> %471, zeroinitializer
  %474 = select <4 x i1> %473, <4 x i32> %472, <4 x i32> %471
  %475 = add nuw <4 x i32> %474, <i32 32, i32 32, i32 32, i32 32>
  %476 = lshr <4 x i32> %475, <i32 6, i32 6, i32 6, i32 6>
  %477 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %466, <4 x i32> %476) #5
  %478 = lshr <8 x i16> %477, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %479 = getelementptr inbounds i16, i16* %9, i64 120
  %480 = bitcast i16* %479 to <8 x i16>*
  %481 = load <8 x i16>, <8 x i16>* %480, align 16
  %482 = getelementptr inbounds i16, i16* %10, i64 120
  %483 = bitcast i16* %482 to <8 x i16>*
  %484 = load <8 x i16>, <8 x i16>* %483, align 16
  %485 = shufflevector <8 x i16> %481, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %486 = zext <4 x i16> %485 to <4 x i32>
  %487 = shufflevector <8 x i16> %484, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %488 = zext <4 x i16> %487 to <4 x i32>
  %489 = sub nsw <4 x i32> %486, %488
  %490 = sub nsw <4 x i32> zeroinitializer, %489
  %491 = icmp slt <4 x i32> %489, zeroinitializer
  %492 = select <4 x i1> %491, <4 x i32> %490, <4 x i32> %489
  %493 = add nuw nsw <4 x i32> %492, <i32 32, i32 32, i32 32, i32 32>
  %494 = lshr <4 x i32> %493, <i32 6, i32 6, i32 6, i32 6>
  %495 = shufflevector <8 x i16> %481, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %496 = shufflevector <8 x i16> %484, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %497 = bitcast <8 x i16> %495 to <4 x i32>
  %498 = bitcast <8 x i16> %496 to <4 x i32>
  %499 = sub <4 x i32> %497, %498
  %500 = sub <4 x i32> zeroinitializer, %499
  %501 = icmp slt <4 x i32> %499, zeroinitializer
  %502 = select <4 x i1> %501, <4 x i32> %500, <4 x i32> %499
  %503 = add nuw <4 x i32> %502, <i32 32, i32 32, i32 32, i32 32>
  %504 = lshr <4 x i32> %503, <i32 6, i32 6, i32 6, i32 6>
  %505 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %494, <4 x i32> %504) #5
  %506 = lshr <8 x i16> %505, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %507 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %478, <8 x i16> %506) #5
  %508 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %507, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %509 = icmp slt <16 x i8> %508, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %510 = select <16 x i1> %509, <16 x i8> %508, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %511 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %510
  %512 = bitcast i8* %452 to <16 x i8>*
  store <16 x i8> %511, <16 x i8>* %512, align 16
  %513 = getelementptr inbounds i16, i16* %9, i64 128
  %514 = getelementptr inbounds i16, i16* %10, i64 128
  %515 = getelementptr inbounds i8, i8* %389, i64 %3
  %516 = bitcast i16* %513 to <8 x i16>*
  %517 = load <8 x i16>, <8 x i16>* %516, align 16
  %518 = bitcast i16* %514 to <8 x i16>*
  %519 = load <8 x i16>, <8 x i16>* %518, align 16
  %520 = shufflevector <8 x i16> %517, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %521 = zext <4 x i16> %520 to <4 x i32>
  %522 = shufflevector <8 x i16> %519, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %523 = zext <4 x i16> %522 to <4 x i32>
  %524 = sub nsw <4 x i32> %521, %523
  %525 = sub nsw <4 x i32> zeroinitializer, %524
  %526 = icmp slt <4 x i32> %524, zeroinitializer
  %527 = select <4 x i1> %526, <4 x i32> %525, <4 x i32> %524
  %528 = add nuw nsw <4 x i32> %527, <i32 32, i32 32, i32 32, i32 32>
  %529 = lshr <4 x i32> %528, <i32 6, i32 6, i32 6, i32 6>
  %530 = shufflevector <8 x i16> %517, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %531 = shufflevector <8 x i16> %519, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %532 = bitcast <8 x i16> %530 to <4 x i32>
  %533 = bitcast <8 x i16> %531 to <4 x i32>
  %534 = sub <4 x i32> %532, %533
  %535 = sub <4 x i32> zeroinitializer, %534
  %536 = icmp slt <4 x i32> %534, zeroinitializer
  %537 = select <4 x i1> %536, <4 x i32> %535, <4 x i32> %534
  %538 = add nuw <4 x i32> %537, <i32 32, i32 32, i32 32, i32 32>
  %539 = lshr <4 x i32> %538, <i32 6, i32 6, i32 6, i32 6>
  %540 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %529, <4 x i32> %539) #5
  %541 = lshr <8 x i16> %540, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %542 = getelementptr inbounds i16, i16* %9, i64 136
  %543 = bitcast i16* %542 to <8 x i16>*
  %544 = load <8 x i16>, <8 x i16>* %543, align 16
  %545 = getelementptr inbounds i16, i16* %10, i64 136
  %546 = bitcast i16* %545 to <8 x i16>*
  %547 = load <8 x i16>, <8 x i16>* %546, align 16
  %548 = shufflevector <8 x i16> %544, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %549 = zext <4 x i16> %548 to <4 x i32>
  %550 = shufflevector <8 x i16> %547, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %551 = zext <4 x i16> %550 to <4 x i32>
  %552 = sub nsw <4 x i32> %549, %551
  %553 = sub nsw <4 x i32> zeroinitializer, %552
  %554 = icmp slt <4 x i32> %552, zeroinitializer
  %555 = select <4 x i1> %554, <4 x i32> %553, <4 x i32> %552
  %556 = add nuw nsw <4 x i32> %555, <i32 32, i32 32, i32 32, i32 32>
  %557 = lshr <4 x i32> %556, <i32 6, i32 6, i32 6, i32 6>
  %558 = shufflevector <8 x i16> %544, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %559 = shufflevector <8 x i16> %547, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %560 = bitcast <8 x i16> %558 to <4 x i32>
  %561 = bitcast <8 x i16> %559 to <4 x i32>
  %562 = sub <4 x i32> %560, %561
  %563 = sub <4 x i32> zeroinitializer, %562
  %564 = icmp slt <4 x i32> %562, zeroinitializer
  %565 = select <4 x i1> %564, <4 x i32> %563, <4 x i32> %562
  %566 = add nuw <4 x i32> %565, <i32 32, i32 32, i32 32, i32 32>
  %567 = lshr <4 x i32> %566, <i32 6, i32 6, i32 6, i32 6>
  %568 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %557, <4 x i32> %567) #5
  %569 = lshr <8 x i16> %568, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %570 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %541, <8 x i16> %569) #5
  %571 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %570, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %572 = icmp slt <16 x i8> %571, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %573 = select <16 x i1> %572, <16 x i8> %571, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %574 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %573
  %575 = bitcast i8* %515 to <16 x i8>*
  store <16 x i8> %574, <16 x i8>* %575, align 16
  %576 = getelementptr inbounds i16, i16* %9, i64 144
  %577 = getelementptr inbounds i16, i16* %10, i64 144
  %578 = getelementptr inbounds i8, i8* %515, i64 16
  %579 = bitcast i16* %576 to <8 x i16>*
  %580 = load <8 x i16>, <8 x i16>* %579, align 16
  %581 = bitcast i16* %577 to <8 x i16>*
  %582 = load <8 x i16>, <8 x i16>* %581, align 16
  %583 = shufflevector <8 x i16> %580, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %584 = zext <4 x i16> %583 to <4 x i32>
  %585 = shufflevector <8 x i16> %582, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %586 = zext <4 x i16> %585 to <4 x i32>
  %587 = sub nsw <4 x i32> %584, %586
  %588 = sub nsw <4 x i32> zeroinitializer, %587
  %589 = icmp slt <4 x i32> %587, zeroinitializer
  %590 = select <4 x i1> %589, <4 x i32> %588, <4 x i32> %587
  %591 = add nuw nsw <4 x i32> %590, <i32 32, i32 32, i32 32, i32 32>
  %592 = lshr <4 x i32> %591, <i32 6, i32 6, i32 6, i32 6>
  %593 = shufflevector <8 x i16> %580, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %594 = shufflevector <8 x i16> %582, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %595 = bitcast <8 x i16> %593 to <4 x i32>
  %596 = bitcast <8 x i16> %594 to <4 x i32>
  %597 = sub <4 x i32> %595, %596
  %598 = sub <4 x i32> zeroinitializer, %597
  %599 = icmp slt <4 x i32> %597, zeroinitializer
  %600 = select <4 x i1> %599, <4 x i32> %598, <4 x i32> %597
  %601 = add nuw <4 x i32> %600, <i32 32, i32 32, i32 32, i32 32>
  %602 = lshr <4 x i32> %601, <i32 6, i32 6, i32 6, i32 6>
  %603 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %592, <4 x i32> %602) #5
  %604 = lshr <8 x i16> %603, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %605 = getelementptr inbounds i16, i16* %9, i64 152
  %606 = bitcast i16* %605 to <8 x i16>*
  %607 = load <8 x i16>, <8 x i16>* %606, align 16
  %608 = getelementptr inbounds i16, i16* %10, i64 152
  %609 = bitcast i16* %608 to <8 x i16>*
  %610 = load <8 x i16>, <8 x i16>* %609, align 16
  %611 = shufflevector <8 x i16> %607, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %612 = zext <4 x i16> %611 to <4 x i32>
  %613 = shufflevector <8 x i16> %610, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %614 = zext <4 x i16> %613 to <4 x i32>
  %615 = sub nsw <4 x i32> %612, %614
  %616 = sub nsw <4 x i32> zeroinitializer, %615
  %617 = icmp slt <4 x i32> %615, zeroinitializer
  %618 = select <4 x i1> %617, <4 x i32> %616, <4 x i32> %615
  %619 = add nuw nsw <4 x i32> %618, <i32 32, i32 32, i32 32, i32 32>
  %620 = lshr <4 x i32> %619, <i32 6, i32 6, i32 6, i32 6>
  %621 = shufflevector <8 x i16> %607, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %622 = shufflevector <8 x i16> %610, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %623 = bitcast <8 x i16> %621 to <4 x i32>
  %624 = bitcast <8 x i16> %622 to <4 x i32>
  %625 = sub <4 x i32> %623, %624
  %626 = sub <4 x i32> zeroinitializer, %625
  %627 = icmp slt <4 x i32> %625, zeroinitializer
  %628 = select <4 x i1> %627, <4 x i32> %626, <4 x i32> %625
  %629 = add nuw <4 x i32> %628, <i32 32, i32 32, i32 32, i32 32>
  %630 = lshr <4 x i32> %629, <i32 6, i32 6, i32 6, i32 6>
  %631 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %620, <4 x i32> %630) #5
  %632 = lshr <8 x i16> %631, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %633 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %604, <8 x i16> %632) #5
  %634 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %633, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %635 = icmp slt <16 x i8> %634, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %636 = select <16 x i1> %635, <16 x i8> %634, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %637 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %636
  %638 = bitcast i8* %578 to <16 x i8>*
  store <16 x i8> %637, <16 x i8>* %638, align 16
  %639 = getelementptr inbounds i16, i16* %9, i64 160
  %640 = getelementptr inbounds i16, i16* %10, i64 160
  %641 = getelementptr inbounds i8, i8* %515, i64 %3
  %642 = add nsw i32 %11, -1
  %643 = icmp eq i32 %642, 0
  br i1 %643, label %644, label %7

644:                                              ; preds = %7
  %645 = bitcast i16* %639 to <8 x i16>*
  %646 = load <8 x i16>, <8 x i16>* %645, align 16
  %647 = bitcast i16* %640 to <8 x i16>*
  %648 = load <8 x i16>, <8 x i16>* %647, align 16
  %649 = shufflevector <8 x i16> %646, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %650 = zext <4 x i16> %649 to <4 x i32>
  %651 = shufflevector <8 x i16> %648, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %652 = zext <4 x i16> %651 to <4 x i32>
  %653 = sub nsw <4 x i32> %650, %652
  %654 = sub nsw <4 x i32> zeroinitializer, %653
  %655 = icmp slt <4 x i32> %653, zeroinitializer
  %656 = select <4 x i1> %655, <4 x i32> %654, <4 x i32> %653
  %657 = add nuw nsw <4 x i32> %656, <i32 32, i32 32, i32 32, i32 32>
  %658 = lshr <4 x i32> %657, <i32 6, i32 6, i32 6, i32 6>
  %659 = shufflevector <8 x i16> %646, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %660 = shufflevector <8 x i16> %648, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %661 = bitcast <8 x i16> %659 to <4 x i32>
  %662 = bitcast <8 x i16> %660 to <4 x i32>
  %663 = sub <4 x i32> %661, %662
  %664 = sub <4 x i32> zeroinitializer, %663
  %665 = icmp slt <4 x i32> %663, zeroinitializer
  %666 = select <4 x i1> %665, <4 x i32> %664, <4 x i32> %663
  %667 = add nuw <4 x i32> %666, <i32 32, i32 32, i32 32, i32 32>
  %668 = lshr <4 x i32> %667, <i32 6, i32 6, i32 6, i32 6>
  %669 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %658, <4 x i32> %668) #5
  %670 = lshr <8 x i16> %669, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %671 = getelementptr inbounds i16, i16* %9, i64 168
  %672 = bitcast i16* %671 to <8 x i16>*
  %673 = load <8 x i16>, <8 x i16>* %672, align 16
  %674 = getelementptr inbounds i16, i16* %10, i64 168
  %675 = bitcast i16* %674 to <8 x i16>*
  %676 = load <8 x i16>, <8 x i16>* %675, align 16
  %677 = shufflevector <8 x i16> %673, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %678 = zext <4 x i16> %677 to <4 x i32>
  %679 = shufflevector <8 x i16> %676, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %680 = zext <4 x i16> %679 to <4 x i32>
  %681 = sub nsw <4 x i32> %678, %680
  %682 = sub nsw <4 x i32> zeroinitializer, %681
  %683 = icmp slt <4 x i32> %681, zeroinitializer
  %684 = select <4 x i1> %683, <4 x i32> %682, <4 x i32> %681
  %685 = add nuw nsw <4 x i32> %684, <i32 32, i32 32, i32 32, i32 32>
  %686 = lshr <4 x i32> %685, <i32 6, i32 6, i32 6, i32 6>
  %687 = shufflevector <8 x i16> %673, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %688 = shufflevector <8 x i16> %676, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %689 = bitcast <8 x i16> %687 to <4 x i32>
  %690 = bitcast <8 x i16> %688 to <4 x i32>
  %691 = sub <4 x i32> %689, %690
  %692 = sub <4 x i32> zeroinitializer, %691
  %693 = icmp slt <4 x i32> %691, zeroinitializer
  %694 = select <4 x i1> %693, <4 x i32> %692, <4 x i32> %691
  %695 = add nuw <4 x i32> %694, <i32 32, i32 32, i32 32, i32 32>
  %696 = lshr <4 x i32> %695, <i32 6, i32 6, i32 6, i32 6>
  %697 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %686, <4 x i32> %696) #5
  %698 = lshr <8 x i16> %697, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %699 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %670, <8 x i16> %698) #5
  %700 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %699, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %701 = icmp slt <16 x i8> %700, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %702 = select <16 x i1> %701, <16 x i8> %700, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %703 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %702
  %704 = bitcast i8* %641 to <16 x i8>*
  store <16 x i8> %703, <16 x i8>* %704, align 16
  %705 = getelementptr inbounds i16, i16* %9, i64 176
  %706 = getelementptr inbounds i16, i16* %10, i64 176
  %707 = getelementptr inbounds i8, i8* %641, i64 16
  %708 = bitcast i16* %705 to <8 x i16>*
  %709 = load <8 x i16>, <8 x i16>* %708, align 16
  %710 = bitcast i16* %706 to <8 x i16>*
  %711 = load <8 x i16>, <8 x i16>* %710, align 16
  %712 = shufflevector <8 x i16> %709, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %713 = zext <4 x i16> %712 to <4 x i32>
  %714 = shufflevector <8 x i16> %711, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %715 = zext <4 x i16> %714 to <4 x i32>
  %716 = sub nsw <4 x i32> %713, %715
  %717 = sub nsw <4 x i32> zeroinitializer, %716
  %718 = icmp slt <4 x i32> %716, zeroinitializer
  %719 = select <4 x i1> %718, <4 x i32> %717, <4 x i32> %716
  %720 = add nuw nsw <4 x i32> %719, <i32 32, i32 32, i32 32, i32 32>
  %721 = lshr <4 x i32> %720, <i32 6, i32 6, i32 6, i32 6>
  %722 = shufflevector <8 x i16> %709, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %723 = shufflevector <8 x i16> %711, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %724 = bitcast <8 x i16> %722 to <4 x i32>
  %725 = bitcast <8 x i16> %723 to <4 x i32>
  %726 = sub <4 x i32> %724, %725
  %727 = sub <4 x i32> zeroinitializer, %726
  %728 = icmp slt <4 x i32> %726, zeroinitializer
  %729 = select <4 x i1> %728, <4 x i32> %727, <4 x i32> %726
  %730 = add nuw <4 x i32> %729, <i32 32, i32 32, i32 32, i32 32>
  %731 = lshr <4 x i32> %730, <i32 6, i32 6, i32 6, i32 6>
  %732 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %721, <4 x i32> %731) #5
  %733 = lshr <8 x i16> %732, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %734 = getelementptr inbounds i16, i16* %9, i64 184
  %735 = bitcast i16* %734 to <8 x i16>*
  %736 = load <8 x i16>, <8 x i16>* %735, align 16
  %737 = getelementptr inbounds i16, i16* %10, i64 184
  %738 = bitcast i16* %737 to <8 x i16>*
  %739 = load <8 x i16>, <8 x i16>* %738, align 16
  %740 = shufflevector <8 x i16> %736, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %741 = zext <4 x i16> %740 to <4 x i32>
  %742 = shufflevector <8 x i16> %739, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %743 = zext <4 x i16> %742 to <4 x i32>
  %744 = sub nsw <4 x i32> %741, %743
  %745 = sub nsw <4 x i32> zeroinitializer, %744
  %746 = icmp slt <4 x i32> %744, zeroinitializer
  %747 = select <4 x i1> %746, <4 x i32> %745, <4 x i32> %744
  %748 = add nuw nsw <4 x i32> %747, <i32 32, i32 32, i32 32, i32 32>
  %749 = lshr <4 x i32> %748, <i32 6, i32 6, i32 6, i32 6>
  %750 = shufflevector <8 x i16> %736, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %751 = shufflevector <8 x i16> %739, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %752 = bitcast <8 x i16> %750 to <4 x i32>
  %753 = bitcast <8 x i16> %751 to <4 x i32>
  %754 = sub <4 x i32> %752, %753
  %755 = sub <4 x i32> zeroinitializer, %754
  %756 = icmp slt <4 x i32> %754, zeroinitializer
  %757 = select <4 x i1> %756, <4 x i32> %755, <4 x i32> %754
  %758 = add nuw <4 x i32> %757, <i32 32, i32 32, i32 32, i32 32>
  %759 = lshr <4 x i32> %758, <i32 6, i32 6, i32 6, i32 6>
  %760 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %749, <4 x i32> %759) #5
  %761 = lshr <8 x i16> %760, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %762 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %733, <8 x i16> %761) #5
  %763 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %762, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %764 = icmp slt <16 x i8> %763, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %765 = select <16 x i1> %764, <16 x i8> %763, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %766 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %765
  %767 = bitcast i8* %707 to <16 x i8>*
  store <16 x i8> %766, <16 x i8>* %767, align 16
  %768 = getelementptr inbounds i16, i16* %9, i64 192
  %769 = getelementptr inbounds i16, i16* %10, i64 192
  %770 = getelementptr inbounds i8, i8* %641, i64 %3
  %771 = bitcast i16* %768 to <8 x i16>*
  %772 = load <8 x i16>, <8 x i16>* %771, align 16
  %773 = bitcast i16* %769 to <8 x i16>*
  %774 = load <8 x i16>, <8 x i16>* %773, align 16
  %775 = shufflevector <8 x i16> %772, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %776 = zext <4 x i16> %775 to <4 x i32>
  %777 = shufflevector <8 x i16> %774, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %778 = zext <4 x i16> %777 to <4 x i32>
  %779 = sub nsw <4 x i32> %776, %778
  %780 = sub nsw <4 x i32> zeroinitializer, %779
  %781 = icmp slt <4 x i32> %779, zeroinitializer
  %782 = select <4 x i1> %781, <4 x i32> %780, <4 x i32> %779
  %783 = add nuw nsw <4 x i32> %782, <i32 32, i32 32, i32 32, i32 32>
  %784 = lshr <4 x i32> %783, <i32 6, i32 6, i32 6, i32 6>
  %785 = shufflevector <8 x i16> %772, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %786 = shufflevector <8 x i16> %774, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %787 = bitcast <8 x i16> %785 to <4 x i32>
  %788 = bitcast <8 x i16> %786 to <4 x i32>
  %789 = sub <4 x i32> %787, %788
  %790 = sub <4 x i32> zeroinitializer, %789
  %791 = icmp slt <4 x i32> %789, zeroinitializer
  %792 = select <4 x i1> %791, <4 x i32> %790, <4 x i32> %789
  %793 = add nuw <4 x i32> %792, <i32 32, i32 32, i32 32, i32 32>
  %794 = lshr <4 x i32> %793, <i32 6, i32 6, i32 6, i32 6>
  %795 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %784, <4 x i32> %794) #5
  %796 = lshr <8 x i16> %795, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %797 = getelementptr inbounds i16, i16* %9, i64 200
  %798 = bitcast i16* %797 to <8 x i16>*
  %799 = load <8 x i16>, <8 x i16>* %798, align 16
  %800 = getelementptr inbounds i16, i16* %10, i64 200
  %801 = bitcast i16* %800 to <8 x i16>*
  %802 = load <8 x i16>, <8 x i16>* %801, align 16
  %803 = shufflevector <8 x i16> %799, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %804 = zext <4 x i16> %803 to <4 x i32>
  %805 = shufflevector <8 x i16> %802, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %806 = zext <4 x i16> %805 to <4 x i32>
  %807 = sub nsw <4 x i32> %804, %806
  %808 = sub nsw <4 x i32> zeroinitializer, %807
  %809 = icmp slt <4 x i32> %807, zeroinitializer
  %810 = select <4 x i1> %809, <4 x i32> %808, <4 x i32> %807
  %811 = add nuw nsw <4 x i32> %810, <i32 32, i32 32, i32 32, i32 32>
  %812 = lshr <4 x i32> %811, <i32 6, i32 6, i32 6, i32 6>
  %813 = shufflevector <8 x i16> %799, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %814 = shufflevector <8 x i16> %802, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %815 = bitcast <8 x i16> %813 to <4 x i32>
  %816 = bitcast <8 x i16> %814 to <4 x i32>
  %817 = sub <4 x i32> %815, %816
  %818 = sub <4 x i32> zeroinitializer, %817
  %819 = icmp slt <4 x i32> %817, zeroinitializer
  %820 = select <4 x i1> %819, <4 x i32> %818, <4 x i32> %817
  %821 = add nuw <4 x i32> %820, <i32 32, i32 32, i32 32, i32 32>
  %822 = lshr <4 x i32> %821, <i32 6, i32 6, i32 6, i32 6>
  %823 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %812, <4 x i32> %822) #5
  %824 = lshr <8 x i16> %823, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %825 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %796, <8 x i16> %824) #5
  %826 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %825, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %827 = icmp slt <16 x i8> %826, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %828 = select <16 x i1> %827, <16 x i8> %826, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %829 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %828
  %830 = bitcast i8* %770 to <16 x i8>*
  store <16 x i8> %829, <16 x i8>* %830, align 16
  %831 = getelementptr inbounds i16, i16* %9, i64 208
  %832 = getelementptr inbounds i16, i16* %10, i64 208
  %833 = getelementptr inbounds i8, i8* %770, i64 16
  %834 = bitcast i16* %831 to <8 x i16>*
  %835 = load <8 x i16>, <8 x i16>* %834, align 16
  %836 = bitcast i16* %832 to <8 x i16>*
  %837 = load <8 x i16>, <8 x i16>* %836, align 16
  %838 = shufflevector <8 x i16> %835, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %839 = zext <4 x i16> %838 to <4 x i32>
  %840 = shufflevector <8 x i16> %837, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %841 = zext <4 x i16> %840 to <4 x i32>
  %842 = sub nsw <4 x i32> %839, %841
  %843 = sub nsw <4 x i32> zeroinitializer, %842
  %844 = icmp slt <4 x i32> %842, zeroinitializer
  %845 = select <4 x i1> %844, <4 x i32> %843, <4 x i32> %842
  %846 = add nuw nsw <4 x i32> %845, <i32 32, i32 32, i32 32, i32 32>
  %847 = lshr <4 x i32> %846, <i32 6, i32 6, i32 6, i32 6>
  %848 = shufflevector <8 x i16> %835, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %849 = shufflevector <8 x i16> %837, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %850 = bitcast <8 x i16> %848 to <4 x i32>
  %851 = bitcast <8 x i16> %849 to <4 x i32>
  %852 = sub <4 x i32> %850, %851
  %853 = sub <4 x i32> zeroinitializer, %852
  %854 = icmp slt <4 x i32> %852, zeroinitializer
  %855 = select <4 x i1> %854, <4 x i32> %853, <4 x i32> %852
  %856 = add nuw <4 x i32> %855, <i32 32, i32 32, i32 32, i32 32>
  %857 = lshr <4 x i32> %856, <i32 6, i32 6, i32 6, i32 6>
  %858 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %847, <4 x i32> %857) #5
  %859 = lshr <8 x i16> %858, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %860 = getelementptr inbounds i16, i16* %9, i64 216
  %861 = bitcast i16* %860 to <8 x i16>*
  %862 = load <8 x i16>, <8 x i16>* %861, align 16
  %863 = getelementptr inbounds i16, i16* %10, i64 216
  %864 = bitcast i16* %863 to <8 x i16>*
  %865 = load <8 x i16>, <8 x i16>* %864, align 16
  %866 = shufflevector <8 x i16> %862, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %867 = zext <4 x i16> %866 to <4 x i32>
  %868 = shufflevector <8 x i16> %865, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %869 = zext <4 x i16> %868 to <4 x i32>
  %870 = sub nsw <4 x i32> %867, %869
  %871 = sub nsw <4 x i32> zeroinitializer, %870
  %872 = icmp slt <4 x i32> %870, zeroinitializer
  %873 = select <4 x i1> %872, <4 x i32> %871, <4 x i32> %870
  %874 = add nuw nsw <4 x i32> %873, <i32 32, i32 32, i32 32, i32 32>
  %875 = lshr <4 x i32> %874, <i32 6, i32 6, i32 6, i32 6>
  %876 = shufflevector <8 x i16> %862, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %877 = shufflevector <8 x i16> %865, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %878 = bitcast <8 x i16> %876 to <4 x i32>
  %879 = bitcast <8 x i16> %877 to <4 x i32>
  %880 = sub <4 x i32> %878, %879
  %881 = sub <4 x i32> zeroinitializer, %880
  %882 = icmp slt <4 x i32> %880, zeroinitializer
  %883 = select <4 x i1> %882, <4 x i32> %881, <4 x i32> %880
  %884 = add nuw <4 x i32> %883, <i32 32, i32 32, i32 32, i32 32>
  %885 = lshr <4 x i32> %884, <i32 6, i32 6, i32 6, i32 6>
  %886 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %875, <4 x i32> %885) #5
  %887 = lshr <8 x i16> %886, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %888 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %859, <8 x i16> %887) #5
  %889 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %888, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %890 = icmp slt <16 x i8> %889, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %891 = select <16 x i1> %890, <16 x i8> %889, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %892 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %891
  %893 = bitcast i8* %833 to <16 x i8>*
  store <16 x i8> %892, <16 x i8>* %893, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask32x64_10bpp_SSE4ILb0EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %383, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %381, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %382, %7 ]
  %11 = phi i32 [ 21, %4 ], [ %384, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = shufflevector <8 x i16> %13, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %17 = zext <4 x i16> %16 to <4 x i32>
  %18 = shufflevector <8 x i16> %15, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %19 = zext <4 x i16> %18 to <4 x i32>
  %20 = sub nsw <4 x i32> %17, %19
  %21 = sub nsw <4 x i32> zeroinitializer, %20
  %22 = icmp slt <4 x i32> %20, zeroinitializer
  %23 = select <4 x i1> %22, <4 x i32> %21, <4 x i32> %20
  %24 = add nuw nsw <4 x i32> %23, <i32 32, i32 32, i32 32, i32 32>
  %25 = lshr <4 x i32> %24, <i32 6, i32 6, i32 6, i32 6>
  %26 = shufflevector <8 x i16> %13, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %27 = shufflevector <8 x i16> %15, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %28 = bitcast <8 x i16> %26 to <4 x i32>
  %29 = bitcast <8 x i16> %27 to <4 x i32>
  %30 = sub <4 x i32> %28, %29
  %31 = sub <4 x i32> zeroinitializer, %30
  %32 = icmp slt <4 x i32> %30, zeroinitializer
  %33 = select <4 x i1> %32, <4 x i32> %31, <4 x i32> %30
  %34 = add nuw <4 x i32> %33, <i32 32, i32 32, i32 32, i32 32>
  %35 = lshr <4 x i32> %34, <i32 6, i32 6, i32 6, i32 6>
  %36 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %25, <4 x i32> %35) #5
  %37 = lshr <8 x i16> %36, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %38 = getelementptr inbounds i16, i16* %9, i64 8
  %39 = bitcast i16* %38 to <8 x i16>*
  %40 = load <8 x i16>, <8 x i16>* %39, align 16
  %41 = getelementptr inbounds i16, i16* %10, i64 8
  %42 = bitcast i16* %41 to <8 x i16>*
  %43 = load <8 x i16>, <8 x i16>* %42, align 16
  %44 = shufflevector <8 x i16> %40, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %45 = zext <4 x i16> %44 to <4 x i32>
  %46 = shufflevector <8 x i16> %43, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %47 = zext <4 x i16> %46 to <4 x i32>
  %48 = sub nsw <4 x i32> %45, %47
  %49 = sub nsw <4 x i32> zeroinitializer, %48
  %50 = icmp slt <4 x i32> %48, zeroinitializer
  %51 = select <4 x i1> %50, <4 x i32> %49, <4 x i32> %48
  %52 = add nuw nsw <4 x i32> %51, <i32 32, i32 32, i32 32, i32 32>
  %53 = lshr <4 x i32> %52, <i32 6, i32 6, i32 6, i32 6>
  %54 = shufflevector <8 x i16> %40, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %55 = shufflevector <8 x i16> %43, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %56 = bitcast <8 x i16> %54 to <4 x i32>
  %57 = bitcast <8 x i16> %55 to <4 x i32>
  %58 = sub <4 x i32> %56, %57
  %59 = sub <4 x i32> zeroinitializer, %58
  %60 = icmp slt <4 x i32> %58, zeroinitializer
  %61 = select <4 x i1> %60, <4 x i32> %59, <4 x i32> %58
  %62 = add nuw <4 x i32> %61, <i32 32, i32 32, i32 32, i32 32>
  %63 = lshr <4 x i32> %62, <i32 6, i32 6, i32 6, i32 6>
  %64 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %53, <4 x i32> %63) #5
  %65 = lshr <8 x i16> %64, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %66 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %37, <8 x i16> %65) #5
  %67 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %66, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %68 = icmp slt <16 x i8> %67, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %69 = select <16 x i1> %68, <16 x i8> %67, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %70 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %69, <16 x i8>* %70, align 16
  %71 = getelementptr inbounds i16, i16* %9, i64 16
  %72 = getelementptr inbounds i16, i16* %10, i64 16
  %73 = getelementptr inbounds i8, i8* %8, i64 16
  %74 = bitcast i16* %71 to <8 x i16>*
  %75 = load <8 x i16>, <8 x i16>* %74, align 16
  %76 = bitcast i16* %72 to <8 x i16>*
  %77 = load <8 x i16>, <8 x i16>* %76, align 16
  %78 = shufflevector <8 x i16> %75, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %79 = zext <4 x i16> %78 to <4 x i32>
  %80 = shufflevector <8 x i16> %77, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %81 = zext <4 x i16> %80 to <4 x i32>
  %82 = sub nsw <4 x i32> %79, %81
  %83 = sub nsw <4 x i32> zeroinitializer, %82
  %84 = icmp slt <4 x i32> %82, zeroinitializer
  %85 = select <4 x i1> %84, <4 x i32> %83, <4 x i32> %82
  %86 = add nuw nsw <4 x i32> %85, <i32 32, i32 32, i32 32, i32 32>
  %87 = lshr <4 x i32> %86, <i32 6, i32 6, i32 6, i32 6>
  %88 = shufflevector <8 x i16> %75, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %89 = shufflevector <8 x i16> %77, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %90 = bitcast <8 x i16> %88 to <4 x i32>
  %91 = bitcast <8 x i16> %89 to <4 x i32>
  %92 = sub <4 x i32> %90, %91
  %93 = sub <4 x i32> zeroinitializer, %92
  %94 = icmp slt <4 x i32> %92, zeroinitializer
  %95 = select <4 x i1> %94, <4 x i32> %93, <4 x i32> %92
  %96 = add nuw <4 x i32> %95, <i32 32, i32 32, i32 32, i32 32>
  %97 = lshr <4 x i32> %96, <i32 6, i32 6, i32 6, i32 6>
  %98 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %87, <4 x i32> %97) #5
  %99 = lshr <8 x i16> %98, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %100 = getelementptr inbounds i16, i16* %9, i64 24
  %101 = bitcast i16* %100 to <8 x i16>*
  %102 = load <8 x i16>, <8 x i16>* %101, align 16
  %103 = getelementptr inbounds i16, i16* %10, i64 24
  %104 = bitcast i16* %103 to <8 x i16>*
  %105 = load <8 x i16>, <8 x i16>* %104, align 16
  %106 = shufflevector <8 x i16> %102, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %107 = zext <4 x i16> %106 to <4 x i32>
  %108 = shufflevector <8 x i16> %105, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %109 = zext <4 x i16> %108 to <4 x i32>
  %110 = sub nsw <4 x i32> %107, %109
  %111 = sub nsw <4 x i32> zeroinitializer, %110
  %112 = icmp slt <4 x i32> %110, zeroinitializer
  %113 = select <4 x i1> %112, <4 x i32> %111, <4 x i32> %110
  %114 = add nuw nsw <4 x i32> %113, <i32 32, i32 32, i32 32, i32 32>
  %115 = lshr <4 x i32> %114, <i32 6, i32 6, i32 6, i32 6>
  %116 = shufflevector <8 x i16> %102, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %117 = shufflevector <8 x i16> %105, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %118 = bitcast <8 x i16> %116 to <4 x i32>
  %119 = bitcast <8 x i16> %117 to <4 x i32>
  %120 = sub <4 x i32> %118, %119
  %121 = sub <4 x i32> zeroinitializer, %120
  %122 = icmp slt <4 x i32> %120, zeroinitializer
  %123 = select <4 x i1> %122, <4 x i32> %121, <4 x i32> %120
  %124 = add nuw <4 x i32> %123, <i32 32, i32 32, i32 32, i32 32>
  %125 = lshr <4 x i32> %124, <i32 6, i32 6, i32 6, i32 6>
  %126 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %115, <4 x i32> %125) #5
  %127 = lshr <8 x i16> %126, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %128 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %99, <8 x i16> %127) #5
  %129 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %128, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %130 = icmp slt <16 x i8> %129, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %131 = select <16 x i1> %130, <16 x i8> %129, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %132 = bitcast i8* %73 to <16 x i8>*
  store <16 x i8> %131, <16 x i8>* %132, align 16
  %133 = getelementptr inbounds i16, i16* %9, i64 32
  %134 = getelementptr inbounds i16, i16* %10, i64 32
  %135 = getelementptr inbounds i8, i8* %8, i64 %3
  %136 = bitcast i16* %133 to <8 x i16>*
  %137 = load <8 x i16>, <8 x i16>* %136, align 16
  %138 = bitcast i16* %134 to <8 x i16>*
  %139 = load <8 x i16>, <8 x i16>* %138, align 16
  %140 = shufflevector <8 x i16> %137, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %141 = zext <4 x i16> %140 to <4 x i32>
  %142 = shufflevector <8 x i16> %139, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %143 = zext <4 x i16> %142 to <4 x i32>
  %144 = sub nsw <4 x i32> %141, %143
  %145 = sub nsw <4 x i32> zeroinitializer, %144
  %146 = icmp slt <4 x i32> %144, zeroinitializer
  %147 = select <4 x i1> %146, <4 x i32> %145, <4 x i32> %144
  %148 = add nuw nsw <4 x i32> %147, <i32 32, i32 32, i32 32, i32 32>
  %149 = lshr <4 x i32> %148, <i32 6, i32 6, i32 6, i32 6>
  %150 = shufflevector <8 x i16> %137, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %151 = shufflevector <8 x i16> %139, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %152 = bitcast <8 x i16> %150 to <4 x i32>
  %153 = bitcast <8 x i16> %151 to <4 x i32>
  %154 = sub <4 x i32> %152, %153
  %155 = sub <4 x i32> zeroinitializer, %154
  %156 = icmp slt <4 x i32> %154, zeroinitializer
  %157 = select <4 x i1> %156, <4 x i32> %155, <4 x i32> %154
  %158 = add nuw <4 x i32> %157, <i32 32, i32 32, i32 32, i32 32>
  %159 = lshr <4 x i32> %158, <i32 6, i32 6, i32 6, i32 6>
  %160 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %149, <4 x i32> %159) #5
  %161 = lshr <8 x i16> %160, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %162 = getelementptr inbounds i16, i16* %9, i64 40
  %163 = bitcast i16* %162 to <8 x i16>*
  %164 = load <8 x i16>, <8 x i16>* %163, align 16
  %165 = getelementptr inbounds i16, i16* %10, i64 40
  %166 = bitcast i16* %165 to <8 x i16>*
  %167 = load <8 x i16>, <8 x i16>* %166, align 16
  %168 = shufflevector <8 x i16> %164, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %169 = zext <4 x i16> %168 to <4 x i32>
  %170 = shufflevector <8 x i16> %167, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %171 = zext <4 x i16> %170 to <4 x i32>
  %172 = sub nsw <4 x i32> %169, %171
  %173 = sub nsw <4 x i32> zeroinitializer, %172
  %174 = icmp slt <4 x i32> %172, zeroinitializer
  %175 = select <4 x i1> %174, <4 x i32> %173, <4 x i32> %172
  %176 = add nuw nsw <4 x i32> %175, <i32 32, i32 32, i32 32, i32 32>
  %177 = lshr <4 x i32> %176, <i32 6, i32 6, i32 6, i32 6>
  %178 = shufflevector <8 x i16> %164, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %179 = shufflevector <8 x i16> %167, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %180 = bitcast <8 x i16> %178 to <4 x i32>
  %181 = bitcast <8 x i16> %179 to <4 x i32>
  %182 = sub <4 x i32> %180, %181
  %183 = sub <4 x i32> zeroinitializer, %182
  %184 = icmp slt <4 x i32> %182, zeroinitializer
  %185 = select <4 x i1> %184, <4 x i32> %183, <4 x i32> %182
  %186 = add nuw <4 x i32> %185, <i32 32, i32 32, i32 32, i32 32>
  %187 = lshr <4 x i32> %186, <i32 6, i32 6, i32 6, i32 6>
  %188 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %177, <4 x i32> %187) #5
  %189 = lshr <8 x i16> %188, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %190 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %161, <8 x i16> %189) #5
  %191 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %190, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %192 = icmp slt <16 x i8> %191, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %193 = select <16 x i1> %192, <16 x i8> %191, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %194 = bitcast i8* %135 to <16 x i8>*
  store <16 x i8> %193, <16 x i8>* %194, align 16
  %195 = getelementptr inbounds i16, i16* %9, i64 48
  %196 = getelementptr inbounds i16, i16* %10, i64 48
  %197 = getelementptr inbounds i8, i8* %135, i64 16
  %198 = bitcast i16* %195 to <8 x i16>*
  %199 = load <8 x i16>, <8 x i16>* %198, align 16
  %200 = bitcast i16* %196 to <8 x i16>*
  %201 = load <8 x i16>, <8 x i16>* %200, align 16
  %202 = shufflevector <8 x i16> %199, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %203 = zext <4 x i16> %202 to <4 x i32>
  %204 = shufflevector <8 x i16> %201, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %205 = zext <4 x i16> %204 to <4 x i32>
  %206 = sub nsw <4 x i32> %203, %205
  %207 = sub nsw <4 x i32> zeroinitializer, %206
  %208 = icmp slt <4 x i32> %206, zeroinitializer
  %209 = select <4 x i1> %208, <4 x i32> %207, <4 x i32> %206
  %210 = add nuw nsw <4 x i32> %209, <i32 32, i32 32, i32 32, i32 32>
  %211 = lshr <4 x i32> %210, <i32 6, i32 6, i32 6, i32 6>
  %212 = shufflevector <8 x i16> %199, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %213 = shufflevector <8 x i16> %201, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %214 = bitcast <8 x i16> %212 to <4 x i32>
  %215 = bitcast <8 x i16> %213 to <4 x i32>
  %216 = sub <4 x i32> %214, %215
  %217 = sub <4 x i32> zeroinitializer, %216
  %218 = icmp slt <4 x i32> %216, zeroinitializer
  %219 = select <4 x i1> %218, <4 x i32> %217, <4 x i32> %216
  %220 = add nuw <4 x i32> %219, <i32 32, i32 32, i32 32, i32 32>
  %221 = lshr <4 x i32> %220, <i32 6, i32 6, i32 6, i32 6>
  %222 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %211, <4 x i32> %221) #5
  %223 = lshr <8 x i16> %222, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %224 = getelementptr inbounds i16, i16* %9, i64 56
  %225 = bitcast i16* %224 to <8 x i16>*
  %226 = load <8 x i16>, <8 x i16>* %225, align 16
  %227 = getelementptr inbounds i16, i16* %10, i64 56
  %228 = bitcast i16* %227 to <8 x i16>*
  %229 = load <8 x i16>, <8 x i16>* %228, align 16
  %230 = shufflevector <8 x i16> %226, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %231 = zext <4 x i16> %230 to <4 x i32>
  %232 = shufflevector <8 x i16> %229, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %233 = zext <4 x i16> %232 to <4 x i32>
  %234 = sub nsw <4 x i32> %231, %233
  %235 = sub nsw <4 x i32> zeroinitializer, %234
  %236 = icmp slt <4 x i32> %234, zeroinitializer
  %237 = select <4 x i1> %236, <4 x i32> %235, <4 x i32> %234
  %238 = add nuw nsw <4 x i32> %237, <i32 32, i32 32, i32 32, i32 32>
  %239 = lshr <4 x i32> %238, <i32 6, i32 6, i32 6, i32 6>
  %240 = shufflevector <8 x i16> %226, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %241 = shufflevector <8 x i16> %229, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %242 = bitcast <8 x i16> %240 to <4 x i32>
  %243 = bitcast <8 x i16> %241 to <4 x i32>
  %244 = sub <4 x i32> %242, %243
  %245 = sub <4 x i32> zeroinitializer, %244
  %246 = icmp slt <4 x i32> %244, zeroinitializer
  %247 = select <4 x i1> %246, <4 x i32> %245, <4 x i32> %244
  %248 = add nuw <4 x i32> %247, <i32 32, i32 32, i32 32, i32 32>
  %249 = lshr <4 x i32> %248, <i32 6, i32 6, i32 6, i32 6>
  %250 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %239, <4 x i32> %249) #5
  %251 = lshr <8 x i16> %250, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %252 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %223, <8 x i16> %251) #5
  %253 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %252, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %254 = icmp slt <16 x i8> %253, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %255 = select <16 x i1> %254, <16 x i8> %253, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %256 = bitcast i8* %197 to <16 x i8>*
  store <16 x i8> %255, <16 x i8>* %256, align 16
  %257 = getelementptr inbounds i16, i16* %9, i64 64
  %258 = getelementptr inbounds i16, i16* %10, i64 64
  %259 = getelementptr inbounds i8, i8* %135, i64 %3
  %260 = bitcast i16* %257 to <8 x i16>*
  %261 = load <8 x i16>, <8 x i16>* %260, align 16
  %262 = bitcast i16* %258 to <8 x i16>*
  %263 = load <8 x i16>, <8 x i16>* %262, align 16
  %264 = shufflevector <8 x i16> %261, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %265 = zext <4 x i16> %264 to <4 x i32>
  %266 = shufflevector <8 x i16> %263, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %267 = zext <4 x i16> %266 to <4 x i32>
  %268 = sub nsw <4 x i32> %265, %267
  %269 = sub nsw <4 x i32> zeroinitializer, %268
  %270 = icmp slt <4 x i32> %268, zeroinitializer
  %271 = select <4 x i1> %270, <4 x i32> %269, <4 x i32> %268
  %272 = add nuw nsw <4 x i32> %271, <i32 32, i32 32, i32 32, i32 32>
  %273 = lshr <4 x i32> %272, <i32 6, i32 6, i32 6, i32 6>
  %274 = shufflevector <8 x i16> %261, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %275 = shufflevector <8 x i16> %263, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %276 = bitcast <8 x i16> %274 to <4 x i32>
  %277 = bitcast <8 x i16> %275 to <4 x i32>
  %278 = sub <4 x i32> %276, %277
  %279 = sub <4 x i32> zeroinitializer, %278
  %280 = icmp slt <4 x i32> %278, zeroinitializer
  %281 = select <4 x i1> %280, <4 x i32> %279, <4 x i32> %278
  %282 = add nuw <4 x i32> %281, <i32 32, i32 32, i32 32, i32 32>
  %283 = lshr <4 x i32> %282, <i32 6, i32 6, i32 6, i32 6>
  %284 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %273, <4 x i32> %283) #5
  %285 = lshr <8 x i16> %284, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %286 = getelementptr inbounds i16, i16* %9, i64 72
  %287 = bitcast i16* %286 to <8 x i16>*
  %288 = load <8 x i16>, <8 x i16>* %287, align 16
  %289 = getelementptr inbounds i16, i16* %10, i64 72
  %290 = bitcast i16* %289 to <8 x i16>*
  %291 = load <8 x i16>, <8 x i16>* %290, align 16
  %292 = shufflevector <8 x i16> %288, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %293 = zext <4 x i16> %292 to <4 x i32>
  %294 = shufflevector <8 x i16> %291, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %295 = zext <4 x i16> %294 to <4 x i32>
  %296 = sub nsw <4 x i32> %293, %295
  %297 = sub nsw <4 x i32> zeroinitializer, %296
  %298 = icmp slt <4 x i32> %296, zeroinitializer
  %299 = select <4 x i1> %298, <4 x i32> %297, <4 x i32> %296
  %300 = add nuw nsw <4 x i32> %299, <i32 32, i32 32, i32 32, i32 32>
  %301 = lshr <4 x i32> %300, <i32 6, i32 6, i32 6, i32 6>
  %302 = shufflevector <8 x i16> %288, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %303 = shufflevector <8 x i16> %291, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %304 = bitcast <8 x i16> %302 to <4 x i32>
  %305 = bitcast <8 x i16> %303 to <4 x i32>
  %306 = sub <4 x i32> %304, %305
  %307 = sub <4 x i32> zeroinitializer, %306
  %308 = icmp slt <4 x i32> %306, zeroinitializer
  %309 = select <4 x i1> %308, <4 x i32> %307, <4 x i32> %306
  %310 = add nuw <4 x i32> %309, <i32 32, i32 32, i32 32, i32 32>
  %311 = lshr <4 x i32> %310, <i32 6, i32 6, i32 6, i32 6>
  %312 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %301, <4 x i32> %311) #5
  %313 = lshr <8 x i16> %312, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %314 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %285, <8 x i16> %313) #5
  %315 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %314, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %316 = icmp slt <16 x i8> %315, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %317 = select <16 x i1> %316, <16 x i8> %315, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %318 = bitcast i8* %259 to <16 x i8>*
  store <16 x i8> %317, <16 x i8>* %318, align 16
  %319 = getelementptr inbounds i16, i16* %9, i64 80
  %320 = getelementptr inbounds i16, i16* %10, i64 80
  %321 = getelementptr inbounds i8, i8* %259, i64 16
  %322 = bitcast i16* %319 to <8 x i16>*
  %323 = load <8 x i16>, <8 x i16>* %322, align 16
  %324 = bitcast i16* %320 to <8 x i16>*
  %325 = load <8 x i16>, <8 x i16>* %324, align 16
  %326 = shufflevector <8 x i16> %323, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %327 = zext <4 x i16> %326 to <4 x i32>
  %328 = shufflevector <8 x i16> %325, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %329 = zext <4 x i16> %328 to <4 x i32>
  %330 = sub nsw <4 x i32> %327, %329
  %331 = sub nsw <4 x i32> zeroinitializer, %330
  %332 = icmp slt <4 x i32> %330, zeroinitializer
  %333 = select <4 x i1> %332, <4 x i32> %331, <4 x i32> %330
  %334 = add nuw nsw <4 x i32> %333, <i32 32, i32 32, i32 32, i32 32>
  %335 = lshr <4 x i32> %334, <i32 6, i32 6, i32 6, i32 6>
  %336 = shufflevector <8 x i16> %323, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %337 = shufflevector <8 x i16> %325, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %338 = bitcast <8 x i16> %336 to <4 x i32>
  %339 = bitcast <8 x i16> %337 to <4 x i32>
  %340 = sub <4 x i32> %338, %339
  %341 = sub <4 x i32> zeroinitializer, %340
  %342 = icmp slt <4 x i32> %340, zeroinitializer
  %343 = select <4 x i1> %342, <4 x i32> %341, <4 x i32> %340
  %344 = add nuw <4 x i32> %343, <i32 32, i32 32, i32 32, i32 32>
  %345 = lshr <4 x i32> %344, <i32 6, i32 6, i32 6, i32 6>
  %346 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %335, <4 x i32> %345) #5
  %347 = lshr <8 x i16> %346, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %348 = getelementptr inbounds i16, i16* %9, i64 88
  %349 = bitcast i16* %348 to <8 x i16>*
  %350 = load <8 x i16>, <8 x i16>* %349, align 16
  %351 = getelementptr inbounds i16, i16* %10, i64 88
  %352 = bitcast i16* %351 to <8 x i16>*
  %353 = load <8 x i16>, <8 x i16>* %352, align 16
  %354 = shufflevector <8 x i16> %350, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %355 = zext <4 x i16> %354 to <4 x i32>
  %356 = shufflevector <8 x i16> %353, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %357 = zext <4 x i16> %356 to <4 x i32>
  %358 = sub nsw <4 x i32> %355, %357
  %359 = sub nsw <4 x i32> zeroinitializer, %358
  %360 = icmp slt <4 x i32> %358, zeroinitializer
  %361 = select <4 x i1> %360, <4 x i32> %359, <4 x i32> %358
  %362 = add nuw nsw <4 x i32> %361, <i32 32, i32 32, i32 32, i32 32>
  %363 = lshr <4 x i32> %362, <i32 6, i32 6, i32 6, i32 6>
  %364 = shufflevector <8 x i16> %350, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %365 = shufflevector <8 x i16> %353, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %366 = bitcast <8 x i16> %364 to <4 x i32>
  %367 = bitcast <8 x i16> %365 to <4 x i32>
  %368 = sub <4 x i32> %366, %367
  %369 = sub <4 x i32> zeroinitializer, %368
  %370 = icmp slt <4 x i32> %368, zeroinitializer
  %371 = select <4 x i1> %370, <4 x i32> %369, <4 x i32> %368
  %372 = add nuw <4 x i32> %371, <i32 32, i32 32, i32 32, i32 32>
  %373 = lshr <4 x i32> %372, <i32 6, i32 6, i32 6, i32 6>
  %374 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %363, <4 x i32> %373) #5
  %375 = lshr <8 x i16> %374, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %376 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %347, <8 x i16> %375) #5
  %377 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %376, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %378 = icmp slt <16 x i8> %377, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %379 = select <16 x i1> %378, <16 x i8> %377, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %380 = bitcast i8* %321 to <16 x i8>*
  store <16 x i8> %379, <16 x i8>* %380, align 16
  %381 = getelementptr inbounds i16, i16* %9, i64 96
  %382 = getelementptr inbounds i16, i16* %10, i64 96
  %383 = getelementptr inbounds i8, i8* %259, i64 %3
  %384 = add nsw i32 %11, -1
  %385 = icmp eq i32 %384, 0
  br i1 %385, label %386, label %7

386:                                              ; preds = %7
  %387 = bitcast i16* %381 to <8 x i16>*
  %388 = load <8 x i16>, <8 x i16>* %387, align 16
  %389 = bitcast i16* %382 to <8 x i16>*
  %390 = load <8 x i16>, <8 x i16>* %389, align 16
  %391 = shufflevector <8 x i16> %388, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %392 = zext <4 x i16> %391 to <4 x i32>
  %393 = shufflevector <8 x i16> %390, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %394 = zext <4 x i16> %393 to <4 x i32>
  %395 = sub nsw <4 x i32> %392, %394
  %396 = sub nsw <4 x i32> zeroinitializer, %395
  %397 = icmp slt <4 x i32> %395, zeroinitializer
  %398 = select <4 x i1> %397, <4 x i32> %396, <4 x i32> %395
  %399 = add nuw nsw <4 x i32> %398, <i32 32, i32 32, i32 32, i32 32>
  %400 = lshr <4 x i32> %399, <i32 6, i32 6, i32 6, i32 6>
  %401 = shufflevector <8 x i16> %388, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %402 = shufflevector <8 x i16> %390, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %403 = bitcast <8 x i16> %401 to <4 x i32>
  %404 = bitcast <8 x i16> %402 to <4 x i32>
  %405 = sub <4 x i32> %403, %404
  %406 = sub <4 x i32> zeroinitializer, %405
  %407 = icmp slt <4 x i32> %405, zeroinitializer
  %408 = select <4 x i1> %407, <4 x i32> %406, <4 x i32> %405
  %409 = add nuw <4 x i32> %408, <i32 32, i32 32, i32 32, i32 32>
  %410 = lshr <4 x i32> %409, <i32 6, i32 6, i32 6, i32 6>
  %411 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %400, <4 x i32> %410) #5
  %412 = lshr <8 x i16> %411, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %413 = getelementptr inbounds i16, i16* %9, i64 104
  %414 = bitcast i16* %413 to <8 x i16>*
  %415 = load <8 x i16>, <8 x i16>* %414, align 16
  %416 = getelementptr inbounds i16, i16* %10, i64 104
  %417 = bitcast i16* %416 to <8 x i16>*
  %418 = load <8 x i16>, <8 x i16>* %417, align 16
  %419 = shufflevector <8 x i16> %415, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %420 = zext <4 x i16> %419 to <4 x i32>
  %421 = shufflevector <8 x i16> %418, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %422 = zext <4 x i16> %421 to <4 x i32>
  %423 = sub nsw <4 x i32> %420, %422
  %424 = sub nsw <4 x i32> zeroinitializer, %423
  %425 = icmp slt <4 x i32> %423, zeroinitializer
  %426 = select <4 x i1> %425, <4 x i32> %424, <4 x i32> %423
  %427 = add nuw nsw <4 x i32> %426, <i32 32, i32 32, i32 32, i32 32>
  %428 = lshr <4 x i32> %427, <i32 6, i32 6, i32 6, i32 6>
  %429 = shufflevector <8 x i16> %415, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %430 = shufflevector <8 x i16> %418, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %431 = bitcast <8 x i16> %429 to <4 x i32>
  %432 = bitcast <8 x i16> %430 to <4 x i32>
  %433 = sub <4 x i32> %431, %432
  %434 = sub <4 x i32> zeroinitializer, %433
  %435 = icmp slt <4 x i32> %433, zeroinitializer
  %436 = select <4 x i1> %435, <4 x i32> %434, <4 x i32> %433
  %437 = add nuw <4 x i32> %436, <i32 32, i32 32, i32 32, i32 32>
  %438 = lshr <4 x i32> %437, <i32 6, i32 6, i32 6, i32 6>
  %439 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %428, <4 x i32> %438) #5
  %440 = lshr <8 x i16> %439, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %441 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %412, <8 x i16> %440) #5
  %442 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %441, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %443 = icmp slt <16 x i8> %442, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %444 = select <16 x i1> %443, <16 x i8> %442, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %445 = bitcast i8* %383 to <16 x i8>*
  store <16 x i8> %444, <16 x i8>* %445, align 16
  %446 = getelementptr inbounds i16, i16* %9, i64 112
  %447 = getelementptr inbounds i16, i16* %10, i64 112
  %448 = getelementptr inbounds i8, i8* %383, i64 16
  %449 = bitcast i16* %446 to <8 x i16>*
  %450 = load <8 x i16>, <8 x i16>* %449, align 16
  %451 = bitcast i16* %447 to <8 x i16>*
  %452 = load <8 x i16>, <8 x i16>* %451, align 16
  %453 = shufflevector <8 x i16> %450, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %454 = zext <4 x i16> %453 to <4 x i32>
  %455 = shufflevector <8 x i16> %452, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %456 = zext <4 x i16> %455 to <4 x i32>
  %457 = sub nsw <4 x i32> %454, %456
  %458 = sub nsw <4 x i32> zeroinitializer, %457
  %459 = icmp slt <4 x i32> %457, zeroinitializer
  %460 = select <4 x i1> %459, <4 x i32> %458, <4 x i32> %457
  %461 = add nuw nsw <4 x i32> %460, <i32 32, i32 32, i32 32, i32 32>
  %462 = lshr <4 x i32> %461, <i32 6, i32 6, i32 6, i32 6>
  %463 = shufflevector <8 x i16> %450, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %464 = shufflevector <8 x i16> %452, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %465 = bitcast <8 x i16> %463 to <4 x i32>
  %466 = bitcast <8 x i16> %464 to <4 x i32>
  %467 = sub <4 x i32> %465, %466
  %468 = sub <4 x i32> zeroinitializer, %467
  %469 = icmp slt <4 x i32> %467, zeroinitializer
  %470 = select <4 x i1> %469, <4 x i32> %468, <4 x i32> %467
  %471 = add nuw <4 x i32> %470, <i32 32, i32 32, i32 32, i32 32>
  %472 = lshr <4 x i32> %471, <i32 6, i32 6, i32 6, i32 6>
  %473 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %462, <4 x i32> %472) #5
  %474 = lshr <8 x i16> %473, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %475 = getelementptr inbounds i16, i16* %9, i64 120
  %476 = bitcast i16* %475 to <8 x i16>*
  %477 = load <8 x i16>, <8 x i16>* %476, align 16
  %478 = getelementptr inbounds i16, i16* %10, i64 120
  %479 = bitcast i16* %478 to <8 x i16>*
  %480 = load <8 x i16>, <8 x i16>* %479, align 16
  %481 = shufflevector <8 x i16> %477, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %482 = zext <4 x i16> %481 to <4 x i32>
  %483 = shufflevector <8 x i16> %480, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %484 = zext <4 x i16> %483 to <4 x i32>
  %485 = sub nsw <4 x i32> %482, %484
  %486 = sub nsw <4 x i32> zeroinitializer, %485
  %487 = icmp slt <4 x i32> %485, zeroinitializer
  %488 = select <4 x i1> %487, <4 x i32> %486, <4 x i32> %485
  %489 = add nuw nsw <4 x i32> %488, <i32 32, i32 32, i32 32, i32 32>
  %490 = lshr <4 x i32> %489, <i32 6, i32 6, i32 6, i32 6>
  %491 = shufflevector <8 x i16> %477, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %492 = shufflevector <8 x i16> %480, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %493 = bitcast <8 x i16> %491 to <4 x i32>
  %494 = bitcast <8 x i16> %492 to <4 x i32>
  %495 = sub <4 x i32> %493, %494
  %496 = sub <4 x i32> zeroinitializer, %495
  %497 = icmp slt <4 x i32> %495, zeroinitializer
  %498 = select <4 x i1> %497, <4 x i32> %496, <4 x i32> %495
  %499 = add nuw <4 x i32> %498, <i32 32, i32 32, i32 32, i32 32>
  %500 = lshr <4 x i32> %499, <i32 6, i32 6, i32 6, i32 6>
  %501 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %490, <4 x i32> %500) #5
  %502 = lshr <8 x i16> %501, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %503 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %474, <8 x i16> %502) #5
  %504 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %503, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %505 = icmp slt <16 x i8> %504, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %506 = select <16 x i1> %505, <16 x i8> %504, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %507 = bitcast i8* %448 to <16 x i8>*
  store <16 x i8> %506, <16 x i8>* %507, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask32x64_10bpp_SSE4ILb1EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %389, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %387, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %388, %7 ]
  %11 = phi i32 [ 21, %4 ], [ %390, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = shufflevector <8 x i16> %13, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %17 = zext <4 x i16> %16 to <4 x i32>
  %18 = shufflevector <8 x i16> %15, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %19 = zext <4 x i16> %18 to <4 x i32>
  %20 = sub nsw <4 x i32> %17, %19
  %21 = sub nsw <4 x i32> zeroinitializer, %20
  %22 = icmp slt <4 x i32> %20, zeroinitializer
  %23 = select <4 x i1> %22, <4 x i32> %21, <4 x i32> %20
  %24 = add nuw nsw <4 x i32> %23, <i32 32, i32 32, i32 32, i32 32>
  %25 = lshr <4 x i32> %24, <i32 6, i32 6, i32 6, i32 6>
  %26 = shufflevector <8 x i16> %13, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %27 = shufflevector <8 x i16> %15, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %28 = bitcast <8 x i16> %26 to <4 x i32>
  %29 = bitcast <8 x i16> %27 to <4 x i32>
  %30 = sub <4 x i32> %28, %29
  %31 = sub <4 x i32> zeroinitializer, %30
  %32 = icmp slt <4 x i32> %30, zeroinitializer
  %33 = select <4 x i1> %32, <4 x i32> %31, <4 x i32> %30
  %34 = add nuw <4 x i32> %33, <i32 32, i32 32, i32 32, i32 32>
  %35 = lshr <4 x i32> %34, <i32 6, i32 6, i32 6, i32 6>
  %36 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %25, <4 x i32> %35) #5
  %37 = lshr <8 x i16> %36, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %38 = getelementptr inbounds i16, i16* %9, i64 8
  %39 = bitcast i16* %38 to <8 x i16>*
  %40 = load <8 x i16>, <8 x i16>* %39, align 16
  %41 = getelementptr inbounds i16, i16* %10, i64 8
  %42 = bitcast i16* %41 to <8 x i16>*
  %43 = load <8 x i16>, <8 x i16>* %42, align 16
  %44 = shufflevector <8 x i16> %40, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %45 = zext <4 x i16> %44 to <4 x i32>
  %46 = shufflevector <8 x i16> %43, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %47 = zext <4 x i16> %46 to <4 x i32>
  %48 = sub nsw <4 x i32> %45, %47
  %49 = sub nsw <4 x i32> zeroinitializer, %48
  %50 = icmp slt <4 x i32> %48, zeroinitializer
  %51 = select <4 x i1> %50, <4 x i32> %49, <4 x i32> %48
  %52 = add nuw nsw <4 x i32> %51, <i32 32, i32 32, i32 32, i32 32>
  %53 = lshr <4 x i32> %52, <i32 6, i32 6, i32 6, i32 6>
  %54 = shufflevector <8 x i16> %40, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %55 = shufflevector <8 x i16> %43, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %56 = bitcast <8 x i16> %54 to <4 x i32>
  %57 = bitcast <8 x i16> %55 to <4 x i32>
  %58 = sub <4 x i32> %56, %57
  %59 = sub <4 x i32> zeroinitializer, %58
  %60 = icmp slt <4 x i32> %58, zeroinitializer
  %61 = select <4 x i1> %60, <4 x i32> %59, <4 x i32> %58
  %62 = add nuw <4 x i32> %61, <i32 32, i32 32, i32 32, i32 32>
  %63 = lshr <4 x i32> %62, <i32 6, i32 6, i32 6, i32 6>
  %64 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %53, <4 x i32> %63) #5
  %65 = lshr <8 x i16> %64, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %66 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %37, <8 x i16> %65) #5
  %67 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %66, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %68 = icmp slt <16 x i8> %67, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %69 = select <16 x i1> %68, <16 x i8> %67, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %70 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %69
  %71 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %70, <16 x i8>* %71, align 16
  %72 = getelementptr inbounds i16, i16* %9, i64 16
  %73 = getelementptr inbounds i16, i16* %10, i64 16
  %74 = getelementptr inbounds i8, i8* %8, i64 16
  %75 = bitcast i16* %72 to <8 x i16>*
  %76 = load <8 x i16>, <8 x i16>* %75, align 16
  %77 = bitcast i16* %73 to <8 x i16>*
  %78 = load <8 x i16>, <8 x i16>* %77, align 16
  %79 = shufflevector <8 x i16> %76, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %80 = zext <4 x i16> %79 to <4 x i32>
  %81 = shufflevector <8 x i16> %78, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %82 = zext <4 x i16> %81 to <4 x i32>
  %83 = sub nsw <4 x i32> %80, %82
  %84 = sub nsw <4 x i32> zeroinitializer, %83
  %85 = icmp slt <4 x i32> %83, zeroinitializer
  %86 = select <4 x i1> %85, <4 x i32> %84, <4 x i32> %83
  %87 = add nuw nsw <4 x i32> %86, <i32 32, i32 32, i32 32, i32 32>
  %88 = lshr <4 x i32> %87, <i32 6, i32 6, i32 6, i32 6>
  %89 = shufflevector <8 x i16> %76, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %90 = shufflevector <8 x i16> %78, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %91 = bitcast <8 x i16> %89 to <4 x i32>
  %92 = bitcast <8 x i16> %90 to <4 x i32>
  %93 = sub <4 x i32> %91, %92
  %94 = sub <4 x i32> zeroinitializer, %93
  %95 = icmp slt <4 x i32> %93, zeroinitializer
  %96 = select <4 x i1> %95, <4 x i32> %94, <4 x i32> %93
  %97 = add nuw <4 x i32> %96, <i32 32, i32 32, i32 32, i32 32>
  %98 = lshr <4 x i32> %97, <i32 6, i32 6, i32 6, i32 6>
  %99 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %88, <4 x i32> %98) #5
  %100 = lshr <8 x i16> %99, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %101 = getelementptr inbounds i16, i16* %9, i64 24
  %102 = bitcast i16* %101 to <8 x i16>*
  %103 = load <8 x i16>, <8 x i16>* %102, align 16
  %104 = getelementptr inbounds i16, i16* %10, i64 24
  %105 = bitcast i16* %104 to <8 x i16>*
  %106 = load <8 x i16>, <8 x i16>* %105, align 16
  %107 = shufflevector <8 x i16> %103, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %108 = zext <4 x i16> %107 to <4 x i32>
  %109 = shufflevector <8 x i16> %106, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %110 = zext <4 x i16> %109 to <4 x i32>
  %111 = sub nsw <4 x i32> %108, %110
  %112 = sub nsw <4 x i32> zeroinitializer, %111
  %113 = icmp slt <4 x i32> %111, zeroinitializer
  %114 = select <4 x i1> %113, <4 x i32> %112, <4 x i32> %111
  %115 = add nuw nsw <4 x i32> %114, <i32 32, i32 32, i32 32, i32 32>
  %116 = lshr <4 x i32> %115, <i32 6, i32 6, i32 6, i32 6>
  %117 = shufflevector <8 x i16> %103, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %118 = shufflevector <8 x i16> %106, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %119 = bitcast <8 x i16> %117 to <4 x i32>
  %120 = bitcast <8 x i16> %118 to <4 x i32>
  %121 = sub <4 x i32> %119, %120
  %122 = sub <4 x i32> zeroinitializer, %121
  %123 = icmp slt <4 x i32> %121, zeroinitializer
  %124 = select <4 x i1> %123, <4 x i32> %122, <4 x i32> %121
  %125 = add nuw <4 x i32> %124, <i32 32, i32 32, i32 32, i32 32>
  %126 = lshr <4 x i32> %125, <i32 6, i32 6, i32 6, i32 6>
  %127 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %116, <4 x i32> %126) #5
  %128 = lshr <8 x i16> %127, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %129 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %100, <8 x i16> %128) #5
  %130 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %129, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %131 = icmp slt <16 x i8> %130, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %132 = select <16 x i1> %131, <16 x i8> %130, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %133 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %132
  %134 = bitcast i8* %74 to <16 x i8>*
  store <16 x i8> %133, <16 x i8>* %134, align 16
  %135 = getelementptr inbounds i16, i16* %9, i64 32
  %136 = getelementptr inbounds i16, i16* %10, i64 32
  %137 = getelementptr inbounds i8, i8* %8, i64 %3
  %138 = bitcast i16* %135 to <8 x i16>*
  %139 = load <8 x i16>, <8 x i16>* %138, align 16
  %140 = bitcast i16* %136 to <8 x i16>*
  %141 = load <8 x i16>, <8 x i16>* %140, align 16
  %142 = shufflevector <8 x i16> %139, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %143 = zext <4 x i16> %142 to <4 x i32>
  %144 = shufflevector <8 x i16> %141, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %145 = zext <4 x i16> %144 to <4 x i32>
  %146 = sub nsw <4 x i32> %143, %145
  %147 = sub nsw <4 x i32> zeroinitializer, %146
  %148 = icmp slt <4 x i32> %146, zeroinitializer
  %149 = select <4 x i1> %148, <4 x i32> %147, <4 x i32> %146
  %150 = add nuw nsw <4 x i32> %149, <i32 32, i32 32, i32 32, i32 32>
  %151 = lshr <4 x i32> %150, <i32 6, i32 6, i32 6, i32 6>
  %152 = shufflevector <8 x i16> %139, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %153 = shufflevector <8 x i16> %141, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %154 = bitcast <8 x i16> %152 to <4 x i32>
  %155 = bitcast <8 x i16> %153 to <4 x i32>
  %156 = sub <4 x i32> %154, %155
  %157 = sub <4 x i32> zeroinitializer, %156
  %158 = icmp slt <4 x i32> %156, zeroinitializer
  %159 = select <4 x i1> %158, <4 x i32> %157, <4 x i32> %156
  %160 = add nuw <4 x i32> %159, <i32 32, i32 32, i32 32, i32 32>
  %161 = lshr <4 x i32> %160, <i32 6, i32 6, i32 6, i32 6>
  %162 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %151, <4 x i32> %161) #5
  %163 = lshr <8 x i16> %162, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %164 = getelementptr inbounds i16, i16* %9, i64 40
  %165 = bitcast i16* %164 to <8 x i16>*
  %166 = load <8 x i16>, <8 x i16>* %165, align 16
  %167 = getelementptr inbounds i16, i16* %10, i64 40
  %168 = bitcast i16* %167 to <8 x i16>*
  %169 = load <8 x i16>, <8 x i16>* %168, align 16
  %170 = shufflevector <8 x i16> %166, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %171 = zext <4 x i16> %170 to <4 x i32>
  %172 = shufflevector <8 x i16> %169, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %173 = zext <4 x i16> %172 to <4 x i32>
  %174 = sub nsw <4 x i32> %171, %173
  %175 = sub nsw <4 x i32> zeroinitializer, %174
  %176 = icmp slt <4 x i32> %174, zeroinitializer
  %177 = select <4 x i1> %176, <4 x i32> %175, <4 x i32> %174
  %178 = add nuw nsw <4 x i32> %177, <i32 32, i32 32, i32 32, i32 32>
  %179 = lshr <4 x i32> %178, <i32 6, i32 6, i32 6, i32 6>
  %180 = shufflevector <8 x i16> %166, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %181 = shufflevector <8 x i16> %169, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %182 = bitcast <8 x i16> %180 to <4 x i32>
  %183 = bitcast <8 x i16> %181 to <4 x i32>
  %184 = sub <4 x i32> %182, %183
  %185 = sub <4 x i32> zeroinitializer, %184
  %186 = icmp slt <4 x i32> %184, zeroinitializer
  %187 = select <4 x i1> %186, <4 x i32> %185, <4 x i32> %184
  %188 = add nuw <4 x i32> %187, <i32 32, i32 32, i32 32, i32 32>
  %189 = lshr <4 x i32> %188, <i32 6, i32 6, i32 6, i32 6>
  %190 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %179, <4 x i32> %189) #5
  %191 = lshr <8 x i16> %190, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %192 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %163, <8 x i16> %191) #5
  %193 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %192, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %194 = icmp slt <16 x i8> %193, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %195 = select <16 x i1> %194, <16 x i8> %193, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %196 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %195
  %197 = bitcast i8* %137 to <16 x i8>*
  store <16 x i8> %196, <16 x i8>* %197, align 16
  %198 = getelementptr inbounds i16, i16* %9, i64 48
  %199 = getelementptr inbounds i16, i16* %10, i64 48
  %200 = getelementptr inbounds i8, i8* %137, i64 16
  %201 = bitcast i16* %198 to <8 x i16>*
  %202 = load <8 x i16>, <8 x i16>* %201, align 16
  %203 = bitcast i16* %199 to <8 x i16>*
  %204 = load <8 x i16>, <8 x i16>* %203, align 16
  %205 = shufflevector <8 x i16> %202, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %206 = zext <4 x i16> %205 to <4 x i32>
  %207 = shufflevector <8 x i16> %204, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %208 = zext <4 x i16> %207 to <4 x i32>
  %209 = sub nsw <4 x i32> %206, %208
  %210 = sub nsw <4 x i32> zeroinitializer, %209
  %211 = icmp slt <4 x i32> %209, zeroinitializer
  %212 = select <4 x i1> %211, <4 x i32> %210, <4 x i32> %209
  %213 = add nuw nsw <4 x i32> %212, <i32 32, i32 32, i32 32, i32 32>
  %214 = lshr <4 x i32> %213, <i32 6, i32 6, i32 6, i32 6>
  %215 = shufflevector <8 x i16> %202, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %216 = shufflevector <8 x i16> %204, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %217 = bitcast <8 x i16> %215 to <4 x i32>
  %218 = bitcast <8 x i16> %216 to <4 x i32>
  %219 = sub <4 x i32> %217, %218
  %220 = sub <4 x i32> zeroinitializer, %219
  %221 = icmp slt <4 x i32> %219, zeroinitializer
  %222 = select <4 x i1> %221, <4 x i32> %220, <4 x i32> %219
  %223 = add nuw <4 x i32> %222, <i32 32, i32 32, i32 32, i32 32>
  %224 = lshr <4 x i32> %223, <i32 6, i32 6, i32 6, i32 6>
  %225 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %214, <4 x i32> %224) #5
  %226 = lshr <8 x i16> %225, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %227 = getelementptr inbounds i16, i16* %9, i64 56
  %228 = bitcast i16* %227 to <8 x i16>*
  %229 = load <8 x i16>, <8 x i16>* %228, align 16
  %230 = getelementptr inbounds i16, i16* %10, i64 56
  %231 = bitcast i16* %230 to <8 x i16>*
  %232 = load <8 x i16>, <8 x i16>* %231, align 16
  %233 = shufflevector <8 x i16> %229, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %234 = zext <4 x i16> %233 to <4 x i32>
  %235 = shufflevector <8 x i16> %232, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %236 = zext <4 x i16> %235 to <4 x i32>
  %237 = sub nsw <4 x i32> %234, %236
  %238 = sub nsw <4 x i32> zeroinitializer, %237
  %239 = icmp slt <4 x i32> %237, zeroinitializer
  %240 = select <4 x i1> %239, <4 x i32> %238, <4 x i32> %237
  %241 = add nuw nsw <4 x i32> %240, <i32 32, i32 32, i32 32, i32 32>
  %242 = lshr <4 x i32> %241, <i32 6, i32 6, i32 6, i32 6>
  %243 = shufflevector <8 x i16> %229, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %244 = shufflevector <8 x i16> %232, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %245 = bitcast <8 x i16> %243 to <4 x i32>
  %246 = bitcast <8 x i16> %244 to <4 x i32>
  %247 = sub <4 x i32> %245, %246
  %248 = sub <4 x i32> zeroinitializer, %247
  %249 = icmp slt <4 x i32> %247, zeroinitializer
  %250 = select <4 x i1> %249, <4 x i32> %248, <4 x i32> %247
  %251 = add nuw <4 x i32> %250, <i32 32, i32 32, i32 32, i32 32>
  %252 = lshr <4 x i32> %251, <i32 6, i32 6, i32 6, i32 6>
  %253 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %242, <4 x i32> %252) #5
  %254 = lshr <8 x i16> %253, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %255 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %226, <8 x i16> %254) #5
  %256 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %255, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %257 = icmp slt <16 x i8> %256, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %258 = select <16 x i1> %257, <16 x i8> %256, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %259 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %258
  %260 = bitcast i8* %200 to <16 x i8>*
  store <16 x i8> %259, <16 x i8>* %260, align 16
  %261 = getelementptr inbounds i16, i16* %9, i64 64
  %262 = getelementptr inbounds i16, i16* %10, i64 64
  %263 = getelementptr inbounds i8, i8* %137, i64 %3
  %264 = bitcast i16* %261 to <8 x i16>*
  %265 = load <8 x i16>, <8 x i16>* %264, align 16
  %266 = bitcast i16* %262 to <8 x i16>*
  %267 = load <8 x i16>, <8 x i16>* %266, align 16
  %268 = shufflevector <8 x i16> %265, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %269 = zext <4 x i16> %268 to <4 x i32>
  %270 = shufflevector <8 x i16> %267, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %271 = zext <4 x i16> %270 to <4 x i32>
  %272 = sub nsw <4 x i32> %269, %271
  %273 = sub nsw <4 x i32> zeroinitializer, %272
  %274 = icmp slt <4 x i32> %272, zeroinitializer
  %275 = select <4 x i1> %274, <4 x i32> %273, <4 x i32> %272
  %276 = add nuw nsw <4 x i32> %275, <i32 32, i32 32, i32 32, i32 32>
  %277 = lshr <4 x i32> %276, <i32 6, i32 6, i32 6, i32 6>
  %278 = shufflevector <8 x i16> %265, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %279 = shufflevector <8 x i16> %267, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %280 = bitcast <8 x i16> %278 to <4 x i32>
  %281 = bitcast <8 x i16> %279 to <4 x i32>
  %282 = sub <4 x i32> %280, %281
  %283 = sub <4 x i32> zeroinitializer, %282
  %284 = icmp slt <4 x i32> %282, zeroinitializer
  %285 = select <4 x i1> %284, <4 x i32> %283, <4 x i32> %282
  %286 = add nuw <4 x i32> %285, <i32 32, i32 32, i32 32, i32 32>
  %287 = lshr <4 x i32> %286, <i32 6, i32 6, i32 6, i32 6>
  %288 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %277, <4 x i32> %287) #5
  %289 = lshr <8 x i16> %288, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %290 = getelementptr inbounds i16, i16* %9, i64 72
  %291 = bitcast i16* %290 to <8 x i16>*
  %292 = load <8 x i16>, <8 x i16>* %291, align 16
  %293 = getelementptr inbounds i16, i16* %10, i64 72
  %294 = bitcast i16* %293 to <8 x i16>*
  %295 = load <8 x i16>, <8 x i16>* %294, align 16
  %296 = shufflevector <8 x i16> %292, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %297 = zext <4 x i16> %296 to <4 x i32>
  %298 = shufflevector <8 x i16> %295, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %299 = zext <4 x i16> %298 to <4 x i32>
  %300 = sub nsw <4 x i32> %297, %299
  %301 = sub nsw <4 x i32> zeroinitializer, %300
  %302 = icmp slt <4 x i32> %300, zeroinitializer
  %303 = select <4 x i1> %302, <4 x i32> %301, <4 x i32> %300
  %304 = add nuw nsw <4 x i32> %303, <i32 32, i32 32, i32 32, i32 32>
  %305 = lshr <4 x i32> %304, <i32 6, i32 6, i32 6, i32 6>
  %306 = shufflevector <8 x i16> %292, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %307 = shufflevector <8 x i16> %295, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %308 = bitcast <8 x i16> %306 to <4 x i32>
  %309 = bitcast <8 x i16> %307 to <4 x i32>
  %310 = sub <4 x i32> %308, %309
  %311 = sub <4 x i32> zeroinitializer, %310
  %312 = icmp slt <4 x i32> %310, zeroinitializer
  %313 = select <4 x i1> %312, <4 x i32> %311, <4 x i32> %310
  %314 = add nuw <4 x i32> %313, <i32 32, i32 32, i32 32, i32 32>
  %315 = lshr <4 x i32> %314, <i32 6, i32 6, i32 6, i32 6>
  %316 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %305, <4 x i32> %315) #5
  %317 = lshr <8 x i16> %316, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %318 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %289, <8 x i16> %317) #5
  %319 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %318, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %320 = icmp slt <16 x i8> %319, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %321 = select <16 x i1> %320, <16 x i8> %319, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %322 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %321
  %323 = bitcast i8* %263 to <16 x i8>*
  store <16 x i8> %322, <16 x i8>* %323, align 16
  %324 = getelementptr inbounds i16, i16* %9, i64 80
  %325 = getelementptr inbounds i16, i16* %10, i64 80
  %326 = getelementptr inbounds i8, i8* %263, i64 16
  %327 = bitcast i16* %324 to <8 x i16>*
  %328 = load <8 x i16>, <8 x i16>* %327, align 16
  %329 = bitcast i16* %325 to <8 x i16>*
  %330 = load <8 x i16>, <8 x i16>* %329, align 16
  %331 = shufflevector <8 x i16> %328, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %332 = zext <4 x i16> %331 to <4 x i32>
  %333 = shufflevector <8 x i16> %330, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %334 = zext <4 x i16> %333 to <4 x i32>
  %335 = sub nsw <4 x i32> %332, %334
  %336 = sub nsw <4 x i32> zeroinitializer, %335
  %337 = icmp slt <4 x i32> %335, zeroinitializer
  %338 = select <4 x i1> %337, <4 x i32> %336, <4 x i32> %335
  %339 = add nuw nsw <4 x i32> %338, <i32 32, i32 32, i32 32, i32 32>
  %340 = lshr <4 x i32> %339, <i32 6, i32 6, i32 6, i32 6>
  %341 = shufflevector <8 x i16> %328, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %342 = shufflevector <8 x i16> %330, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %343 = bitcast <8 x i16> %341 to <4 x i32>
  %344 = bitcast <8 x i16> %342 to <4 x i32>
  %345 = sub <4 x i32> %343, %344
  %346 = sub <4 x i32> zeroinitializer, %345
  %347 = icmp slt <4 x i32> %345, zeroinitializer
  %348 = select <4 x i1> %347, <4 x i32> %346, <4 x i32> %345
  %349 = add nuw <4 x i32> %348, <i32 32, i32 32, i32 32, i32 32>
  %350 = lshr <4 x i32> %349, <i32 6, i32 6, i32 6, i32 6>
  %351 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %340, <4 x i32> %350) #5
  %352 = lshr <8 x i16> %351, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %353 = getelementptr inbounds i16, i16* %9, i64 88
  %354 = bitcast i16* %353 to <8 x i16>*
  %355 = load <8 x i16>, <8 x i16>* %354, align 16
  %356 = getelementptr inbounds i16, i16* %10, i64 88
  %357 = bitcast i16* %356 to <8 x i16>*
  %358 = load <8 x i16>, <8 x i16>* %357, align 16
  %359 = shufflevector <8 x i16> %355, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %360 = zext <4 x i16> %359 to <4 x i32>
  %361 = shufflevector <8 x i16> %358, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %362 = zext <4 x i16> %361 to <4 x i32>
  %363 = sub nsw <4 x i32> %360, %362
  %364 = sub nsw <4 x i32> zeroinitializer, %363
  %365 = icmp slt <4 x i32> %363, zeroinitializer
  %366 = select <4 x i1> %365, <4 x i32> %364, <4 x i32> %363
  %367 = add nuw nsw <4 x i32> %366, <i32 32, i32 32, i32 32, i32 32>
  %368 = lshr <4 x i32> %367, <i32 6, i32 6, i32 6, i32 6>
  %369 = shufflevector <8 x i16> %355, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %370 = shufflevector <8 x i16> %358, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %371 = bitcast <8 x i16> %369 to <4 x i32>
  %372 = bitcast <8 x i16> %370 to <4 x i32>
  %373 = sub <4 x i32> %371, %372
  %374 = sub <4 x i32> zeroinitializer, %373
  %375 = icmp slt <4 x i32> %373, zeroinitializer
  %376 = select <4 x i1> %375, <4 x i32> %374, <4 x i32> %373
  %377 = add nuw <4 x i32> %376, <i32 32, i32 32, i32 32, i32 32>
  %378 = lshr <4 x i32> %377, <i32 6, i32 6, i32 6, i32 6>
  %379 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %368, <4 x i32> %378) #5
  %380 = lshr <8 x i16> %379, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %381 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %352, <8 x i16> %380) #5
  %382 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %381, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %383 = icmp slt <16 x i8> %382, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %384 = select <16 x i1> %383, <16 x i8> %382, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %385 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %384
  %386 = bitcast i8* %326 to <16 x i8>*
  store <16 x i8> %385, <16 x i8>* %386, align 16
  %387 = getelementptr inbounds i16, i16* %9, i64 96
  %388 = getelementptr inbounds i16, i16* %10, i64 96
  %389 = getelementptr inbounds i8, i8* %263, i64 %3
  %390 = add nsw i32 %11, -1
  %391 = icmp eq i32 %390, 0
  br i1 %391, label %392, label %7

392:                                              ; preds = %7
  %393 = bitcast i16* %387 to <8 x i16>*
  %394 = load <8 x i16>, <8 x i16>* %393, align 16
  %395 = bitcast i16* %388 to <8 x i16>*
  %396 = load <8 x i16>, <8 x i16>* %395, align 16
  %397 = shufflevector <8 x i16> %394, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %398 = zext <4 x i16> %397 to <4 x i32>
  %399 = shufflevector <8 x i16> %396, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %400 = zext <4 x i16> %399 to <4 x i32>
  %401 = sub nsw <4 x i32> %398, %400
  %402 = sub nsw <4 x i32> zeroinitializer, %401
  %403 = icmp slt <4 x i32> %401, zeroinitializer
  %404 = select <4 x i1> %403, <4 x i32> %402, <4 x i32> %401
  %405 = add nuw nsw <4 x i32> %404, <i32 32, i32 32, i32 32, i32 32>
  %406 = lshr <4 x i32> %405, <i32 6, i32 6, i32 6, i32 6>
  %407 = shufflevector <8 x i16> %394, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %408 = shufflevector <8 x i16> %396, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %409 = bitcast <8 x i16> %407 to <4 x i32>
  %410 = bitcast <8 x i16> %408 to <4 x i32>
  %411 = sub <4 x i32> %409, %410
  %412 = sub <4 x i32> zeroinitializer, %411
  %413 = icmp slt <4 x i32> %411, zeroinitializer
  %414 = select <4 x i1> %413, <4 x i32> %412, <4 x i32> %411
  %415 = add nuw <4 x i32> %414, <i32 32, i32 32, i32 32, i32 32>
  %416 = lshr <4 x i32> %415, <i32 6, i32 6, i32 6, i32 6>
  %417 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %406, <4 x i32> %416) #5
  %418 = lshr <8 x i16> %417, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %419 = getelementptr inbounds i16, i16* %9, i64 104
  %420 = bitcast i16* %419 to <8 x i16>*
  %421 = load <8 x i16>, <8 x i16>* %420, align 16
  %422 = getelementptr inbounds i16, i16* %10, i64 104
  %423 = bitcast i16* %422 to <8 x i16>*
  %424 = load <8 x i16>, <8 x i16>* %423, align 16
  %425 = shufflevector <8 x i16> %421, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %426 = zext <4 x i16> %425 to <4 x i32>
  %427 = shufflevector <8 x i16> %424, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %428 = zext <4 x i16> %427 to <4 x i32>
  %429 = sub nsw <4 x i32> %426, %428
  %430 = sub nsw <4 x i32> zeroinitializer, %429
  %431 = icmp slt <4 x i32> %429, zeroinitializer
  %432 = select <4 x i1> %431, <4 x i32> %430, <4 x i32> %429
  %433 = add nuw nsw <4 x i32> %432, <i32 32, i32 32, i32 32, i32 32>
  %434 = lshr <4 x i32> %433, <i32 6, i32 6, i32 6, i32 6>
  %435 = shufflevector <8 x i16> %421, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %436 = shufflevector <8 x i16> %424, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %437 = bitcast <8 x i16> %435 to <4 x i32>
  %438 = bitcast <8 x i16> %436 to <4 x i32>
  %439 = sub <4 x i32> %437, %438
  %440 = sub <4 x i32> zeroinitializer, %439
  %441 = icmp slt <4 x i32> %439, zeroinitializer
  %442 = select <4 x i1> %441, <4 x i32> %440, <4 x i32> %439
  %443 = add nuw <4 x i32> %442, <i32 32, i32 32, i32 32, i32 32>
  %444 = lshr <4 x i32> %443, <i32 6, i32 6, i32 6, i32 6>
  %445 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %434, <4 x i32> %444) #5
  %446 = lshr <8 x i16> %445, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %447 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %418, <8 x i16> %446) #5
  %448 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %447, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %449 = icmp slt <16 x i8> %448, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %450 = select <16 x i1> %449, <16 x i8> %448, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %451 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %450
  %452 = bitcast i8* %389 to <16 x i8>*
  store <16 x i8> %451, <16 x i8>* %452, align 16
  %453 = getelementptr inbounds i16, i16* %9, i64 112
  %454 = getelementptr inbounds i16, i16* %10, i64 112
  %455 = getelementptr inbounds i8, i8* %389, i64 16
  %456 = bitcast i16* %453 to <8 x i16>*
  %457 = load <8 x i16>, <8 x i16>* %456, align 16
  %458 = bitcast i16* %454 to <8 x i16>*
  %459 = load <8 x i16>, <8 x i16>* %458, align 16
  %460 = shufflevector <8 x i16> %457, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %461 = zext <4 x i16> %460 to <4 x i32>
  %462 = shufflevector <8 x i16> %459, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %463 = zext <4 x i16> %462 to <4 x i32>
  %464 = sub nsw <4 x i32> %461, %463
  %465 = sub nsw <4 x i32> zeroinitializer, %464
  %466 = icmp slt <4 x i32> %464, zeroinitializer
  %467 = select <4 x i1> %466, <4 x i32> %465, <4 x i32> %464
  %468 = add nuw nsw <4 x i32> %467, <i32 32, i32 32, i32 32, i32 32>
  %469 = lshr <4 x i32> %468, <i32 6, i32 6, i32 6, i32 6>
  %470 = shufflevector <8 x i16> %457, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %471 = shufflevector <8 x i16> %459, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %472 = bitcast <8 x i16> %470 to <4 x i32>
  %473 = bitcast <8 x i16> %471 to <4 x i32>
  %474 = sub <4 x i32> %472, %473
  %475 = sub <4 x i32> zeroinitializer, %474
  %476 = icmp slt <4 x i32> %474, zeroinitializer
  %477 = select <4 x i1> %476, <4 x i32> %475, <4 x i32> %474
  %478 = add nuw <4 x i32> %477, <i32 32, i32 32, i32 32, i32 32>
  %479 = lshr <4 x i32> %478, <i32 6, i32 6, i32 6, i32 6>
  %480 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %469, <4 x i32> %479) #5
  %481 = lshr <8 x i16> %480, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %482 = getelementptr inbounds i16, i16* %9, i64 120
  %483 = bitcast i16* %482 to <8 x i16>*
  %484 = load <8 x i16>, <8 x i16>* %483, align 16
  %485 = getelementptr inbounds i16, i16* %10, i64 120
  %486 = bitcast i16* %485 to <8 x i16>*
  %487 = load <8 x i16>, <8 x i16>* %486, align 16
  %488 = shufflevector <8 x i16> %484, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %489 = zext <4 x i16> %488 to <4 x i32>
  %490 = shufflevector <8 x i16> %487, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %491 = zext <4 x i16> %490 to <4 x i32>
  %492 = sub nsw <4 x i32> %489, %491
  %493 = sub nsw <4 x i32> zeroinitializer, %492
  %494 = icmp slt <4 x i32> %492, zeroinitializer
  %495 = select <4 x i1> %494, <4 x i32> %493, <4 x i32> %492
  %496 = add nuw nsw <4 x i32> %495, <i32 32, i32 32, i32 32, i32 32>
  %497 = lshr <4 x i32> %496, <i32 6, i32 6, i32 6, i32 6>
  %498 = shufflevector <8 x i16> %484, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %499 = shufflevector <8 x i16> %487, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %500 = bitcast <8 x i16> %498 to <4 x i32>
  %501 = bitcast <8 x i16> %499 to <4 x i32>
  %502 = sub <4 x i32> %500, %501
  %503 = sub <4 x i32> zeroinitializer, %502
  %504 = icmp slt <4 x i32> %502, zeroinitializer
  %505 = select <4 x i1> %504, <4 x i32> %503, <4 x i32> %502
  %506 = add nuw <4 x i32> %505, <i32 32, i32 32, i32 32, i32 32>
  %507 = lshr <4 x i32> %506, <i32 6, i32 6, i32 6, i32 6>
  %508 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %497, <4 x i32> %507) #5
  %509 = lshr <8 x i16> %508, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %510 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %481, <8 x i16> %509) #5
  %511 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %510, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %512 = icmp slt <16 x i8> %511, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %513 = select <16 x i1> %512, <16 x i8> %511, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %514 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %513
  %515 = bitcast i8* %455 to <16 x i8>*
  store <16 x i8> %514, <16 x i8>* %515, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask64x16_10bpp_SSE4ILb0EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %755, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %753, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %754, %7 ]
  %11 = phi i32 [ 5, %4 ], [ %756, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = shufflevector <8 x i16> %13, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %17 = zext <4 x i16> %16 to <4 x i32>
  %18 = shufflevector <8 x i16> %15, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %19 = zext <4 x i16> %18 to <4 x i32>
  %20 = sub nsw <4 x i32> %17, %19
  %21 = sub nsw <4 x i32> zeroinitializer, %20
  %22 = icmp slt <4 x i32> %20, zeroinitializer
  %23 = select <4 x i1> %22, <4 x i32> %21, <4 x i32> %20
  %24 = add nuw nsw <4 x i32> %23, <i32 32, i32 32, i32 32, i32 32>
  %25 = lshr <4 x i32> %24, <i32 6, i32 6, i32 6, i32 6>
  %26 = shufflevector <8 x i16> %13, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %27 = shufflevector <8 x i16> %15, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %28 = bitcast <8 x i16> %26 to <4 x i32>
  %29 = bitcast <8 x i16> %27 to <4 x i32>
  %30 = sub <4 x i32> %28, %29
  %31 = sub <4 x i32> zeroinitializer, %30
  %32 = icmp slt <4 x i32> %30, zeroinitializer
  %33 = select <4 x i1> %32, <4 x i32> %31, <4 x i32> %30
  %34 = add nuw <4 x i32> %33, <i32 32, i32 32, i32 32, i32 32>
  %35 = lshr <4 x i32> %34, <i32 6, i32 6, i32 6, i32 6>
  %36 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %25, <4 x i32> %35) #5
  %37 = lshr <8 x i16> %36, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %38 = getelementptr inbounds i16, i16* %9, i64 8
  %39 = bitcast i16* %38 to <8 x i16>*
  %40 = load <8 x i16>, <8 x i16>* %39, align 16
  %41 = getelementptr inbounds i16, i16* %10, i64 8
  %42 = bitcast i16* %41 to <8 x i16>*
  %43 = load <8 x i16>, <8 x i16>* %42, align 16
  %44 = shufflevector <8 x i16> %40, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %45 = zext <4 x i16> %44 to <4 x i32>
  %46 = shufflevector <8 x i16> %43, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %47 = zext <4 x i16> %46 to <4 x i32>
  %48 = sub nsw <4 x i32> %45, %47
  %49 = sub nsw <4 x i32> zeroinitializer, %48
  %50 = icmp slt <4 x i32> %48, zeroinitializer
  %51 = select <4 x i1> %50, <4 x i32> %49, <4 x i32> %48
  %52 = add nuw nsw <4 x i32> %51, <i32 32, i32 32, i32 32, i32 32>
  %53 = lshr <4 x i32> %52, <i32 6, i32 6, i32 6, i32 6>
  %54 = shufflevector <8 x i16> %40, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %55 = shufflevector <8 x i16> %43, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %56 = bitcast <8 x i16> %54 to <4 x i32>
  %57 = bitcast <8 x i16> %55 to <4 x i32>
  %58 = sub <4 x i32> %56, %57
  %59 = sub <4 x i32> zeroinitializer, %58
  %60 = icmp slt <4 x i32> %58, zeroinitializer
  %61 = select <4 x i1> %60, <4 x i32> %59, <4 x i32> %58
  %62 = add nuw <4 x i32> %61, <i32 32, i32 32, i32 32, i32 32>
  %63 = lshr <4 x i32> %62, <i32 6, i32 6, i32 6, i32 6>
  %64 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %53, <4 x i32> %63) #5
  %65 = lshr <8 x i16> %64, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %66 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %37, <8 x i16> %65) #5
  %67 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %66, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %68 = icmp slt <16 x i8> %67, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %69 = select <16 x i1> %68, <16 x i8> %67, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %70 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %69, <16 x i8>* %70, align 16
  %71 = getelementptr inbounds i16, i16* %9, i64 16
  %72 = getelementptr inbounds i16, i16* %10, i64 16
  %73 = getelementptr inbounds i8, i8* %8, i64 16
  %74 = bitcast i16* %71 to <8 x i16>*
  %75 = load <8 x i16>, <8 x i16>* %74, align 16
  %76 = bitcast i16* %72 to <8 x i16>*
  %77 = load <8 x i16>, <8 x i16>* %76, align 16
  %78 = shufflevector <8 x i16> %75, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %79 = zext <4 x i16> %78 to <4 x i32>
  %80 = shufflevector <8 x i16> %77, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %81 = zext <4 x i16> %80 to <4 x i32>
  %82 = sub nsw <4 x i32> %79, %81
  %83 = sub nsw <4 x i32> zeroinitializer, %82
  %84 = icmp slt <4 x i32> %82, zeroinitializer
  %85 = select <4 x i1> %84, <4 x i32> %83, <4 x i32> %82
  %86 = add nuw nsw <4 x i32> %85, <i32 32, i32 32, i32 32, i32 32>
  %87 = lshr <4 x i32> %86, <i32 6, i32 6, i32 6, i32 6>
  %88 = shufflevector <8 x i16> %75, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %89 = shufflevector <8 x i16> %77, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %90 = bitcast <8 x i16> %88 to <4 x i32>
  %91 = bitcast <8 x i16> %89 to <4 x i32>
  %92 = sub <4 x i32> %90, %91
  %93 = sub <4 x i32> zeroinitializer, %92
  %94 = icmp slt <4 x i32> %92, zeroinitializer
  %95 = select <4 x i1> %94, <4 x i32> %93, <4 x i32> %92
  %96 = add nuw <4 x i32> %95, <i32 32, i32 32, i32 32, i32 32>
  %97 = lshr <4 x i32> %96, <i32 6, i32 6, i32 6, i32 6>
  %98 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %87, <4 x i32> %97) #5
  %99 = lshr <8 x i16> %98, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %100 = getelementptr inbounds i16, i16* %9, i64 24
  %101 = bitcast i16* %100 to <8 x i16>*
  %102 = load <8 x i16>, <8 x i16>* %101, align 16
  %103 = getelementptr inbounds i16, i16* %10, i64 24
  %104 = bitcast i16* %103 to <8 x i16>*
  %105 = load <8 x i16>, <8 x i16>* %104, align 16
  %106 = shufflevector <8 x i16> %102, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %107 = zext <4 x i16> %106 to <4 x i32>
  %108 = shufflevector <8 x i16> %105, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %109 = zext <4 x i16> %108 to <4 x i32>
  %110 = sub nsw <4 x i32> %107, %109
  %111 = sub nsw <4 x i32> zeroinitializer, %110
  %112 = icmp slt <4 x i32> %110, zeroinitializer
  %113 = select <4 x i1> %112, <4 x i32> %111, <4 x i32> %110
  %114 = add nuw nsw <4 x i32> %113, <i32 32, i32 32, i32 32, i32 32>
  %115 = lshr <4 x i32> %114, <i32 6, i32 6, i32 6, i32 6>
  %116 = shufflevector <8 x i16> %102, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %117 = shufflevector <8 x i16> %105, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %118 = bitcast <8 x i16> %116 to <4 x i32>
  %119 = bitcast <8 x i16> %117 to <4 x i32>
  %120 = sub <4 x i32> %118, %119
  %121 = sub <4 x i32> zeroinitializer, %120
  %122 = icmp slt <4 x i32> %120, zeroinitializer
  %123 = select <4 x i1> %122, <4 x i32> %121, <4 x i32> %120
  %124 = add nuw <4 x i32> %123, <i32 32, i32 32, i32 32, i32 32>
  %125 = lshr <4 x i32> %124, <i32 6, i32 6, i32 6, i32 6>
  %126 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %115, <4 x i32> %125) #5
  %127 = lshr <8 x i16> %126, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %128 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %99, <8 x i16> %127) #5
  %129 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %128, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %130 = icmp slt <16 x i8> %129, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %131 = select <16 x i1> %130, <16 x i8> %129, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %132 = bitcast i8* %73 to <16 x i8>*
  store <16 x i8> %131, <16 x i8>* %132, align 16
  %133 = getelementptr inbounds i16, i16* %9, i64 32
  %134 = getelementptr inbounds i16, i16* %10, i64 32
  %135 = getelementptr inbounds i8, i8* %8, i64 32
  %136 = bitcast i16* %133 to <8 x i16>*
  %137 = load <8 x i16>, <8 x i16>* %136, align 16
  %138 = bitcast i16* %134 to <8 x i16>*
  %139 = load <8 x i16>, <8 x i16>* %138, align 16
  %140 = shufflevector <8 x i16> %137, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %141 = zext <4 x i16> %140 to <4 x i32>
  %142 = shufflevector <8 x i16> %139, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %143 = zext <4 x i16> %142 to <4 x i32>
  %144 = sub nsw <4 x i32> %141, %143
  %145 = sub nsw <4 x i32> zeroinitializer, %144
  %146 = icmp slt <4 x i32> %144, zeroinitializer
  %147 = select <4 x i1> %146, <4 x i32> %145, <4 x i32> %144
  %148 = add nuw nsw <4 x i32> %147, <i32 32, i32 32, i32 32, i32 32>
  %149 = lshr <4 x i32> %148, <i32 6, i32 6, i32 6, i32 6>
  %150 = shufflevector <8 x i16> %137, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %151 = shufflevector <8 x i16> %139, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %152 = bitcast <8 x i16> %150 to <4 x i32>
  %153 = bitcast <8 x i16> %151 to <4 x i32>
  %154 = sub <4 x i32> %152, %153
  %155 = sub <4 x i32> zeroinitializer, %154
  %156 = icmp slt <4 x i32> %154, zeroinitializer
  %157 = select <4 x i1> %156, <4 x i32> %155, <4 x i32> %154
  %158 = add nuw <4 x i32> %157, <i32 32, i32 32, i32 32, i32 32>
  %159 = lshr <4 x i32> %158, <i32 6, i32 6, i32 6, i32 6>
  %160 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %149, <4 x i32> %159) #5
  %161 = lshr <8 x i16> %160, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %162 = getelementptr inbounds i16, i16* %9, i64 40
  %163 = bitcast i16* %162 to <8 x i16>*
  %164 = load <8 x i16>, <8 x i16>* %163, align 16
  %165 = getelementptr inbounds i16, i16* %10, i64 40
  %166 = bitcast i16* %165 to <8 x i16>*
  %167 = load <8 x i16>, <8 x i16>* %166, align 16
  %168 = shufflevector <8 x i16> %164, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %169 = zext <4 x i16> %168 to <4 x i32>
  %170 = shufflevector <8 x i16> %167, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %171 = zext <4 x i16> %170 to <4 x i32>
  %172 = sub nsw <4 x i32> %169, %171
  %173 = sub nsw <4 x i32> zeroinitializer, %172
  %174 = icmp slt <4 x i32> %172, zeroinitializer
  %175 = select <4 x i1> %174, <4 x i32> %173, <4 x i32> %172
  %176 = add nuw nsw <4 x i32> %175, <i32 32, i32 32, i32 32, i32 32>
  %177 = lshr <4 x i32> %176, <i32 6, i32 6, i32 6, i32 6>
  %178 = shufflevector <8 x i16> %164, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %179 = shufflevector <8 x i16> %167, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %180 = bitcast <8 x i16> %178 to <4 x i32>
  %181 = bitcast <8 x i16> %179 to <4 x i32>
  %182 = sub <4 x i32> %180, %181
  %183 = sub <4 x i32> zeroinitializer, %182
  %184 = icmp slt <4 x i32> %182, zeroinitializer
  %185 = select <4 x i1> %184, <4 x i32> %183, <4 x i32> %182
  %186 = add nuw <4 x i32> %185, <i32 32, i32 32, i32 32, i32 32>
  %187 = lshr <4 x i32> %186, <i32 6, i32 6, i32 6, i32 6>
  %188 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %177, <4 x i32> %187) #5
  %189 = lshr <8 x i16> %188, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %190 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %161, <8 x i16> %189) #5
  %191 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %190, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %192 = icmp slt <16 x i8> %191, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %193 = select <16 x i1> %192, <16 x i8> %191, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %194 = bitcast i8* %135 to <16 x i8>*
  store <16 x i8> %193, <16 x i8>* %194, align 16
  %195 = getelementptr inbounds i16, i16* %9, i64 48
  %196 = getelementptr inbounds i16, i16* %10, i64 48
  %197 = getelementptr inbounds i8, i8* %8, i64 48
  %198 = bitcast i16* %195 to <8 x i16>*
  %199 = load <8 x i16>, <8 x i16>* %198, align 16
  %200 = bitcast i16* %196 to <8 x i16>*
  %201 = load <8 x i16>, <8 x i16>* %200, align 16
  %202 = shufflevector <8 x i16> %199, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %203 = zext <4 x i16> %202 to <4 x i32>
  %204 = shufflevector <8 x i16> %201, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %205 = zext <4 x i16> %204 to <4 x i32>
  %206 = sub nsw <4 x i32> %203, %205
  %207 = sub nsw <4 x i32> zeroinitializer, %206
  %208 = icmp slt <4 x i32> %206, zeroinitializer
  %209 = select <4 x i1> %208, <4 x i32> %207, <4 x i32> %206
  %210 = add nuw nsw <4 x i32> %209, <i32 32, i32 32, i32 32, i32 32>
  %211 = lshr <4 x i32> %210, <i32 6, i32 6, i32 6, i32 6>
  %212 = shufflevector <8 x i16> %199, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %213 = shufflevector <8 x i16> %201, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %214 = bitcast <8 x i16> %212 to <4 x i32>
  %215 = bitcast <8 x i16> %213 to <4 x i32>
  %216 = sub <4 x i32> %214, %215
  %217 = sub <4 x i32> zeroinitializer, %216
  %218 = icmp slt <4 x i32> %216, zeroinitializer
  %219 = select <4 x i1> %218, <4 x i32> %217, <4 x i32> %216
  %220 = add nuw <4 x i32> %219, <i32 32, i32 32, i32 32, i32 32>
  %221 = lshr <4 x i32> %220, <i32 6, i32 6, i32 6, i32 6>
  %222 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %211, <4 x i32> %221) #5
  %223 = lshr <8 x i16> %222, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %224 = getelementptr inbounds i16, i16* %9, i64 56
  %225 = bitcast i16* %224 to <8 x i16>*
  %226 = load <8 x i16>, <8 x i16>* %225, align 16
  %227 = getelementptr inbounds i16, i16* %10, i64 56
  %228 = bitcast i16* %227 to <8 x i16>*
  %229 = load <8 x i16>, <8 x i16>* %228, align 16
  %230 = shufflevector <8 x i16> %226, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %231 = zext <4 x i16> %230 to <4 x i32>
  %232 = shufflevector <8 x i16> %229, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %233 = zext <4 x i16> %232 to <4 x i32>
  %234 = sub nsw <4 x i32> %231, %233
  %235 = sub nsw <4 x i32> zeroinitializer, %234
  %236 = icmp slt <4 x i32> %234, zeroinitializer
  %237 = select <4 x i1> %236, <4 x i32> %235, <4 x i32> %234
  %238 = add nuw nsw <4 x i32> %237, <i32 32, i32 32, i32 32, i32 32>
  %239 = lshr <4 x i32> %238, <i32 6, i32 6, i32 6, i32 6>
  %240 = shufflevector <8 x i16> %226, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %241 = shufflevector <8 x i16> %229, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %242 = bitcast <8 x i16> %240 to <4 x i32>
  %243 = bitcast <8 x i16> %241 to <4 x i32>
  %244 = sub <4 x i32> %242, %243
  %245 = sub <4 x i32> zeroinitializer, %244
  %246 = icmp slt <4 x i32> %244, zeroinitializer
  %247 = select <4 x i1> %246, <4 x i32> %245, <4 x i32> %244
  %248 = add nuw <4 x i32> %247, <i32 32, i32 32, i32 32, i32 32>
  %249 = lshr <4 x i32> %248, <i32 6, i32 6, i32 6, i32 6>
  %250 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %239, <4 x i32> %249) #5
  %251 = lshr <8 x i16> %250, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %252 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %223, <8 x i16> %251) #5
  %253 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %252, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %254 = icmp slt <16 x i8> %253, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %255 = select <16 x i1> %254, <16 x i8> %253, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %256 = bitcast i8* %197 to <16 x i8>*
  store <16 x i8> %255, <16 x i8>* %256, align 16
  %257 = getelementptr inbounds i16, i16* %9, i64 64
  %258 = getelementptr inbounds i16, i16* %10, i64 64
  %259 = getelementptr inbounds i8, i8* %8, i64 %3
  %260 = bitcast i16* %257 to <8 x i16>*
  %261 = load <8 x i16>, <8 x i16>* %260, align 16
  %262 = bitcast i16* %258 to <8 x i16>*
  %263 = load <8 x i16>, <8 x i16>* %262, align 16
  %264 = shufflevector <8 x i16> %261, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %265 = zext <4 x i16> %264 to <4 x i32>
  %266 = shufflevector <8 x i16> %263, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %267 = zext <4 x i16> %266 to <4 x i32>
  %268 = sub nsw <4 x i32> %265, %267
  %269 = sub nsw <4 x i32> zeroinitializer, %268
  %270 = icmp slt <4 x i32> %268, zeroinitializer
  %271 = select <4 x i1> %270, <4 x i32> %269, <4 x i32> %268
  %272 = add nuw nsw <4 x i32> %271, <i32 32, i32 32, i32 32, i32 32>
  %273 = lshr <4 x i32> %272, <i32 6, i32 6, i32 6, i32 6>
  %274 = shufflevector <8 x i16> %261, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %275 = shufflevector <8 x i16> %263, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %276 = bitcast <8 x i16> %274 to <4 x i32>
  %277 = bitcast <8 x i16> %275 to <4 x i32>
  %278 = sub <4 x i32> %276, %277
  %279 = sub <4 x i32> zeroinitializer, %278
  %280 = icmp slt <4 x i32> %278, zeroinitializer
  %281 = select <4 x i1> %280, <4 x i32> %279, <4 x i32> %278
  %282 = add nuw <4 x i32> %281, <i32 32, i32 32, i32 32, i32 32>
  %283 = lshr <4 x i32> %282, <i32 6, i32 6, i32 6, i32 6>
  %284 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %273, <4 x i32> %283) #5
  %285 = lshr <8 x i16> %284, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %286 = getelementptr inbounds i16, i16* %9, i64 72
  %287 = bitcast i16* %286 to <8 x i16>*
  %288 = load <8 x i16>, <8 x i16>* %287, align 16
  %289 = getelementptr inbounds i16, i16* %10, i64 72
  %290 = bitcast i16* %289 to <8 x i16>*
  %291 = load <8 x i16>, <8 x i16>* %290, align 16
  %292 = shufflevector <8 x i16> %288, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %293 = zext <4 x i16> %292 to <4 x i32>
  %294 = shufflevector <8 x i16> %291, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %295 = zext <4 x i16> %294 to <4 x i32>
  %296 = sub nsw <4 x i32> %293, %295
  %297 = sub nsw <4 x i32> zeroinitializer, %296
  %298 = icmp slt <4 x i32> %296, zeroinitializer
  %299 = select <4 x i1> %298, <4 x i32> %297, <4 x i32> %296
  %300 = add nuw nsw <4 x i32> %299, <i32 32, i32 32, i32 32, i32 32>
  %301 = lshr <4 x i32> %300, <i32 6, i32 6, i32 6, i32 6>
  %302 = shufflevector <8 x i16> %288, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %303 = shufflevector <8 x i16> %291, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %304 = bitcast <8 x i16> %302 to <4 x i32>
  %305 = bitcast <8 x i16> %303 to <4 x i32>
  %306 = sub <4 x i32> %304, %305
  %307 = sub <4 x i32> zeroinitializer, %306
  %308 = icmp slt <4 x i32> %306, zeroinitializer
  %309 = select <4 x i1> %308, <4 x i32> %307, <4 x i32> %306
  %310 = add nuw <4 x i32> %309, <i32 32, i32 32, i32 32, i32 32>
  %311 = lshr <4 x i32> %310, <i32 6, i32 6, i32 6, i32 6>
  %312 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %301, <4 x i32> %311) #5
  %313 = lshr <8 x i16> %312, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %314 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %285, <8 x i16> %313) #5
  %315 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %314, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %316 = icmp slt <16 x i8> %315, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %317 = select <16 x i1> %316, <16 x i8> %315, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %318 = bitcast i8* %259 to <16 x i8>*
  store <16 x i8> %317, <16 x i8>* %318, align 16
  %319 = getelementptr inbounds i16, i16* %9, i64 80
  %320 = getelementptr inbounds i16, i16* %10, i64 80
  %321 = getelementptr inbounds i8, i8* %259, i64 16
  %322 = bitcast i16* %319 to <8 x i16>*
  %323 = load <8 x i16>, <8 x i16>* %322, align 16
  %324 = bitcast i16* %320 to <8 x i16>*
  %325 = load <8 x i16>, <8 x i16>* %324, align 16
  %326 = shufflevector <8 x i16> %323, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %327 = zext <4 x i16> %326 to <4 x i32>
  %328 = shufflevector <8 x i16> %325, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %329 = zext <4 x i16> %328 to <4 x i32>
  %330 = sub nsw <4 x i32> %327, %329
  %331 = sub nsw <4 x i32> zeroinitializer, %330
  %332 = icmp slt <4 x i32> %330, zeroinitializer
  %333 = select <4 x i1> %332, <4 x i32> %331, <4 x i32> %330
  %334 = add nuw nsw <4 x i32> %333, <i32 32, i32 32, i32 32, i32 32>
  %335 = lshr <4 x i32> %334, <i32 6, i32 6, i32 6, i32 6>
  %336 = shufflevector <8 x i16> %323, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %337 = shufflevector <8 x i16> %325, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %338 = bitcast <8 x i16> %336 to <4 x i32>
  %339 = bitcast <8 x i16> %337 to <4 x i32>
  %340 = sub <4 x i32> %338, %339
  %341 = sub <4 x i32> zeroinitializer, %340
  %342 = icmp slt <4 x i32> %340, zeroinitializer
  %343 = select <4 x i1> %342, <4 x i32> %341, <4 x i32> %340
  %344 = add nuw <4 x i32> %343, <i32 32, i32 32, i32 32, i32 32>
  %345 = lshr <4 x i32> %344, <i32 6, i32 6, i32 6, i32 6>
  %346 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %335, <4 x i32> %345) #5
  %347 = lshr <8 x i16> %346, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %348 = getelementptr inbounds i16, i16* %9, i64 88
  %349 = bitcast i16* %348 to <8 x i16>*
  %350 = load <8 x i16>, <8 x i16>* %349, align 16
  %351 = getelementptr inbounds i16, i16* %10, i64 88
  %352 = bitcast i16* %351 to <8 x i16>*
  %353 = load <8 x i16>, <8 x i16>* %352, align 16
  %354 = shufflevector <8 x i16> %350, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %355 = zext <4 x i16> %354 to <4 x i32>
  %356 = shufflevector <8 x i16> %353, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %357 = zext <4 x i16> %356 to <4 x i32>
  %358 = sub nsw <4 x i32> %355, %357
  %359 = sub nsw <4 x i32> zeroinitializer, %358
  %360 = icmp slt <4 x i32> %358, zeroinitializer
  %361 = select <4 x i1> %360, <4 x i32> %359, <4 x i32> %358
  %362 = add nuw nsw <4 x i32> %361, <i32 32, i32 32, i32 32, i32 32>
  %363 = lshr <4 x i32> %362, <i32 6, i32 6, i32 6, i32 6>
  %364 = shufflevector <8 x i16> %350, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %365 = shufflevector <8 x i16> %353, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %366 = bitcast <8 x i16> %364 to <4 x i32>
  %367 = bitcast <8 x i16> %365 to <4 x i32>
  %368 = sub <4 x i32> %366, %367
  %369 = sub <4 x i32> zeroinitializer, %368
  %370 = icmp slt <4 x i32> %368, zeroinitializer
  %371 = select <4 x i1> %370, <4 x i32> %369, <4 x i32> %368
  %372 = add nuw <4 x i32> %371, <i32 32, i32 32, i32 32, i32 32>
  %373 = lshr <4 x i32> %372, <i32 6, i32 6, i32 6, i32 6>
  %374 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %363, <4 x i32> %373) #5
  %375 = lshr <8 x i16> %374, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %376 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %347, <8 x i16> %375) #5
  %377 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %376, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %378 = icmp slt <16 x i8> %377, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %379 = select <16 x i1> %378, <16 x i8> %377, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %380 = bitcast i8* %321 to <16 x i8>*
  store <16 x i8> %379, <16 x i8>* %380, align 16
  %381 = getelementptr inbounds i16, i16* %9, i64 96
  %382 = getelementptr inbounds i16, i16* %10, i64 96
  %383 = getelementptr inbounds i8, i8* %259, i64 32
  %384 = bitcast i16* %381 to <8 x i16>*
  %385 = load <8 x i16>, <8 x i16>* %384, align 16
  %386 = bitcast i16* %382 to <8 x i16>*
  %387 = load <8 x i16>, <8 x i16>* %386, align 16
  %388 = shufflevector <8 x i16> %385, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %389 = zext <4 x i16> %388 to <4 x i32>
  %390 = shufflevector <8 x i16> %387, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %391 = zext <4 x i16> %390 to <4 x i32>
  %392 = sub nsw <4 x i32> %389, %391
  %393 = sub nsw <4 x i32> zeroinitializer, %392
  %394 = icmp slt <4 x i32> %392, zeroinitializer
  %395 = select <4 x i1> %394, <4 x i32> %393, <4 x i32> %392
  %396 = add nuw nsw <4 x i32> %395, <i32 32, i32 32, i32 32, i32 32>
  %397 = lshr <4 x i32> %396, <i32 6, i32 6, i32 6, i32 6>
  %398 = shufflevector <8 x i16> %385, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %399 = shufflevector <8 x i16> %387, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %400 = bitcast <8 x i16> %398 to <4 x i32>
  %401 = bitcast <8 x i16> %399 to <4 x i32>
  %402 = sub <4 x i32> %400, %401
  %403 = sub <4 x i32> zeroinitializer, %402
  %404 = icmp slt <4 x i32> %402, zeroinitializer
  %405 = select <4 x i1> %404, <4 x i32> %403, <4 x i32> %402
  %406 = add nuw <4 x i32> %405, <i32 32, i32 32, i32 32, i32 32>
  %407 = lshr <4 x i32> %406, <i32 6, i32 6, i32 6, i32 6>
  %408 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %397, <4 x i32> %407) #5
  %409 = lshr <8 x i16> %408, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %410 = getelementptr inbounds i16, i16* %9, i64 104
  %411 = bitcast i16* %410 to <8 x i16>*
  %412 = load <8 x i16>, <8 x i16>* %411, align 16
  %413 = getelementptr inbounds i16, i16* %10, i64 104
  %414 = bitcast i16* %413 to <8 x i16>*
  %415 = load <8 x i16>, <8 x i16>* %414, align 16
  %416 = shufflevector <8 x i16> %412, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %417 = zext <4 x i16> %416 to <4 x i32>
  %418 = shufflevector <8 x i16> %415, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %419 = zext <4 x i16> %418 to <4 x i32>
  %420 = sub nsw <4 x i32> %417, %419
  %421 = sub nsw <4 x i32> zeroinitializer, %420
  %422 = icmp slt <4 x i32> %420, zeroinitializer
  %423 = select <4 x i1> %422, <4 x i32> %421, <4 x i32> %420
  %424 = add nuw nsw <4 x i32> %423, <i32 32, i32 32, i32 32, i32 32>
  %425 = lshr <4 x i32> %424, <i32 6, i32 6, i32 6, i32 6>
  %426 = shufflevector <8 x i16> %412, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %427 = shufflevector <8 x i16> %415, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %428 = bitcast <8 x i16> %426 to <4 x i32>
  %429 = bitcast <8 x i16> %427 to <4 x i32>
  %430 = sub <4 x i32> %428, %429
  %431 = sub <4 x i32> zeroinitializer, %430
  %432 = icmp slt <4 x i32> %430, zeroinitializer
  %433 = select <4 x i1> %432, <4 x i32> %431, <4 x i32> %430
  %434 = add nuw <4 x i32> %433, <i32 32, i32 32, i32 32, i32 32>
  %435 = lshr <4 x i32> %434, <i32 6, i32 6, i32 6, i32 6>
  %436 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %425, <4 x i32> %435) #5
  %437 = lshr <8 x i16> %436, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %438 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %409, <8 x i16> %437) #5
  %439 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %438, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %440 = icmp slt <16 x i8> %439, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %441 = select <16 x i1> %440, <16 x i8> %439, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %442 = bitcast i8* %383 to <16 x i8>*
  store <16 x i8> %441, <16 x i8>* %442, align 16
  %443 = getelementptr inbounds i16, i16* %9, i64 112
  %444 = getelementptr inbounds i16, i16* %10, i64 112
  %445 = getelementptr inbounds i8, i8* %259, i64 48
  %446 = bitcast i16* %443 to <8 x i16>*
  %447 = load <8 x i16>, <8 x i16>* %446, align 16
  %448 = bitcast i16* %444 to <8 x i16>*
  %449 = load <8 x i16>, <8 x i16>* %448, align 16
  %450 = shufflevector <8 x i16> %447, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %451 = zext <4 x i16> %450 to <4 x i32>
  %452 = shufflevector <8 x i16> %449, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %453 = zext <4 x i16> %452 to <4 x i32>
  %454 = sub nsw <4 x i32> %451, %453
  %455 = sub nsw <4 x i32> zeroinitializer, %454
  %456 = icmp slt <4 x i32> %454, zeroinitializer
  %457 = select <4 x i1> %456, <4 x i32> %455, <4 x i32> %454
  %458 = add nuw nsw <4 x i32> %457, <i32 32, i32 32, i32 32, i32 32>
  %459 = lshr <4 x i32> %458, <i32 6, i32 6, i32 6, i32 6>
  %460 = shufflevector <8 x i16> %447, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %461 = shufflevector <8 x i16> %449, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %462 = bitcast <8 x i16> %460 to <4 x i32>
  %463 = bitcast <8 x i16> %461 to <4 x i32>
  %464 = sub <4 x i32> %462, %463
  %465 = sub <4 x i32> zeroinitializer, %464
  %466 = icmp slt <4 x i32> %464, zeroinitializer
  %467 = select <4 x i1> %466, <4 x i32> %465, <4 x i32> %464
  %468 = add nuw <4 x i32> %467, <i32 32, i32 32, i32 32, i32 32>
  %469 = lshr <4 x i32> %468, <i32 6, i32 6, i32 6, i32 6>
  %470 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %459, <4 x i32> %469) #5
  %471 = lshr <8 x i16> %470, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %472 = getelementptr inbounds i16, i16* %9, i64 120
  %473 = bitcast i16* %472 to <8 x i16>*
  %474 = load <8 x i16>, <8 x i16>* %473, align 16
  %475 = getelementptr inbounds i16, i16* %10, i64 120
  %476 = bitcast i16* %475 to <8 x i16>*
  %477 = load <8 x i16>, <8 x i16>* %476, align 16
  %478 = shufflevector <8 x i16> %474, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %479 = zext <4 x i16> %478 to <4 x i32>
  %480 = shufflevector <8 x i16> %477, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %481 = zext <4 x i16> %480 to <4 x i32>
  %482 = sub nsw <4 x i32> %479, %481
  %483 = sub nsw <4 x i32> zeroinitializer, %482
  %484 = icmp slt <4 x i32> %482, zeroinitializer
  %485 = select <4 x i1> %484, <4 x i32> %483, <4 x i32> %482
  %486 = add nuw nsw <4 x i32> %485, <i32 32, i32 32, i32 32, i32 32>
  %487 = lshr <4 x i32> %486, <i32 6, i32 6, i32 6, i32 6>
  %488 = shufflevector <8 x i16> %474, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %489 = shufflevector <8 x i16> %477, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %490 = bitcast <8 x i16> %488 to <4 x i32>
  %491 = bitcast <8 x i16> %489 to <4 x i32>
  %492 = sub <4 x i32> %490, %491
  %493 = sub <4 x i32> zeroinitializer, %492
  %494 = icmp slt <4 x i32> %492, zeroinitializer
  %495 = select <4 x i1> %494, <4 x i32> %493, <4 x i32> %492
  %496 = add nuw <4 x i32> %495, <i32 32, i32 32, i32 32, i32 32>
  %497 = lshr <4 x i32> %496, <i32 6, i32 6, i32 6, i32 6>
  %498 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %487, <4 x i32> %497) #5
  %499 = lshr <8 x i16> %498, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %500 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %471, <8 x i16> %499) #5
  %501 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %500, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %502 = icmp slt <16 x i8> %501, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %503 = select <16 x i1> %502, <16 x i8> %501, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %504 = bitcast i8* %445 to <16 x i8>*
  store <16 x i8> %503, <16 x i8>* %504, align 16
  %505 = getelementptr inbounds i16, i16* %9, i64 128
  %506 = getelementptr inbounds i16, i16* %10, i64 128
  %507 = getelementptr inbounds i8, i8* %259, i64 %3
  %508 = bitcast i16* %505 to <8 x i16>*
  %509 = load <8 x i16>, <8 x i16>* %508, align 16
  %510 = bitcast i16* %506 to <8 x i16>*
  %511 = load <8 x i16>, <8 x i16>* %510, align 16
  %512 = shufflevector <8 x i16> %509, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %513 = zext <4 x i16> %512 to <4 x i32>
  %514 = shufflevector <8 x i16> %511, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %515 = zext <4 x i16> %514 to <4 x i32>
  %516 = sub nsw <4 x i32> %513, %515
  %517 = sub nsw <4 x i32> zeroinitializer, %516
  %518 = icmp slt <4 x i32> %516, zeroinitializer
  %519 = select <4 x i1> %518, <4 x i32> %517, <4 x i32> %516
  %520 = add nuw nsw <4 x i32> %519, <i32 32, i32 32, i32 32, i32 32>
  %521 = lshr <4 x i32> %520, <i32 6, i32 6, i32 6, i32 6>
  %522 = shufflevector <8 x i16> %509, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %523 = shufflevector <8 x i16> %511, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %524 = bitcast <8 x i16> %522 to <4 x i32>
  %525 = bitcast <8 x i16> %523 to <4 x i32>
  %526 = sub <4 x i32> %524, %525
  %527 = sub <4 x i32> zeroinitializer, %526
  %528 = icmp slt <4 x i32> %526, zeroinitializer
  %529 = select <4 x i1> %528, <4 x i32> %527, <4 x i32> %526
  %530 = add nuw <4 x i32> %529, <i32 32, i32 32, i32 32, i32 32>
  %531 = lshr <4 x i32> %530, <i32 6, i32 6, i32 6, i32 6>
  %532 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %521, <4 x i32> %531) #5
  %533 = lshr <8 x i16> %532, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %534 = getelementptr inbounds i16, i16* %9, i64 136
  %535 = bitcast i16* %534 to <8 x i16>*
  %536 = load <8 x i16>, <8 x i16>* %535, align 16
  %537 = getelementptr inbounds i16, i16* %10, i64 136
  %538 = bitcast i16* %537 to <8 x i16>*
  %539 = load <8 x i16>, <8 x i16>* %538, align 16
  %540 = shufflevector <8 x i16> %536, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %541 = zext <4 x i16> %540 to <4 x i32>
  %542 = shufflevector <8 x i16> %539, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %543 = zext <4 x i16> %542 to <4 x i32>
  %544 = sub nsw <4 x i32> %541, %543
  %545 = sub nsw <4 x i32> zeroinitializer, %544
  %546 = icmp slt <4 x i32> %544, zeroinitializer
  %547 = select <4 x i1> %546, <4 x i32> %545, <4 x i32> %544
  %548 = add nuw nsw <4 x i32> %547, <i32 32, i32 32, i32 32, i32 32>
  %549 = lshr <4 x i32> %548, <i32 6, i32 6, i32 6, i32 6>
  %550 = shufflevector <8 x i16> %536, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %551 = shufflevector <8 x i16> %539, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %552 = bitcast <8 x i16> %550 to <4 x i32>
  %553 = bitcast <8 x i16> %551 to <4 x i32>
  %554 = sub <4 x i32> %552, %553
  %555 = sub <4 x i32> zeroinitializer, %554
  %556 = icmp slt <4 x i32> %554, zeroinitializer
  %557 = select <4 x i1> %556, <4 x i32> %555, <4 x i32> %554
  %558 = add nuw <4 x i32> %557, <i32 32, i32 32, i32 32, i32 32>
  %559 = lshr <4 x i32> %558, <i32 6, i32 6, i32 6, i32 6>
  %560 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %549, <4 x i32> %559) #5
  %561 = lshr <8 x i16> %560, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %562 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %533, <8 x i16> %561) #5
  %563 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %562, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %564 = icmp slt <16 x i8> %563, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %565 = select <16 x i1> %564, <16 x i8> %563, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %566 = bitcast i8* %507 to <16 x i8>*
  store <16 x i8> %565, <16 x i8>* %566, align 16
  %567 = getelementptr inbounds i16, i16* %9, i64 144
  %568 = getelementptr inbounds i16, i16* %10, i64 144
  %569 = getelementptr inbounds i8, i8* %507, i64 16
  %570 = bitcast i16* %567 to <8 x i16>*
  %571 = load <8 x i16>, <8 x i16>* %570, align 16
  %572 = bitcast i16* %568 to <8 x i16>*
  %573 = load <8 x i16>, <8 x i16>* %572, align 16
  %574 = shufflevector <8 x i16> %571, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %575 = zext <4 x i16> %574 to <4 x i32>
  %576 = shufflevector <8 x i16> %573, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %577 = zext <4 x i16> %576 to <4 x i32>
  %578 = sub nsw <4 x i32> %575, %577
  %579 = sub nsw <4 x i32> zeroinitializer, %578
  %580 = icmp slt <4 x i32> %578, zeroinitializer
  %581 = select <4 x i1> %580, <4 x i32> %579, <4 x i32> %578
  %582 = add nuw nsw <4 x i32> %581, <i32 32, i32 32, i32 32, i32 32>
  %583 = lshr <4 x i32> %582, <i32 6, i32 6, i32 6, i32 6>
  %584 = shufflevector <8 x i16> %571, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %585 = shufflevector <8 x i16> %573, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %586 = bitcast <8 x i16> %584 to <4 x i32>
  %587 = bitcast <8 x i16> %585 to <4 x i32>
  %588 = sub <4 x i32> %586, %587
  %589 = sub <4 x i32> zeroinitializer, %588
  %590 = icmp slt <4 x i32> %588, zeroinitializer
  %591 = select <4 x i1> %590, <4 x i32> %589, <4 x i32> %588
  %592 = add nuw <4 x i32> %591, <i32 32, i32 32, i32 32, i32 32>
  %593 = lshr <4 x i32> %592, <i32 6, i32 6, i32 6, i32 6>
  %594 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %583, <4 x i32> %593) #5
  %595 = lshr <8 x i16> %594, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %596 = getelementptr inbounds i16, i16* %9, i64 152
  %597 = bitcast i16* %596 to <8 x i16>*
  %598 = load <8 x i16>, <8 x i16>* %597, align 16
  %599 = getelementptr inbounds i16, i16* %10, i64 152
  %600 = bitcast i16* %599 to <8 x i16>*
  %601 = load <8 x i16>, <8 x i16>* %600, align 16
  %602 = shufflevector <8 x i16> %598, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %603 = zext <4 x i16> %602 to <4 x i32>
  %604 = shufflevector <8 x i16> %601, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %605 = zext <4 x i16> %604 to <4 x i32>
  %606 = sub nsw <4 x i32> %603, %605
  %607 = sub nsw <4 x i32> zeroinitializer, %606
  %608 = icmp slt <4 x i32> %606, zeroinitializer
  %609 = select <4 x i1> %608, <4 x i32> %607, <4 x i32> %606
  %610 = add nuw nsw <4 x i32> %609, <i32 32, i32 32, i32 32, i32 32>
  %611 = lshr <4 x i32> %610, <i32 6, i32 6, i32 6, i32 6>
  %612 = shufflevector <8 x i16> %598, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %613 = shufflevector <8 x i16> %601, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %614 = bitcast <8 x i16> %612 to <4 x i32>
  %615 = bitcast <8 x i16> %613 to <4 x i32>
  %616 = sub <4 x i32> %614, %615
  %617 = sub <4 x i32> zeroinitializer, %616
  %618 = icmp slt <4 x i32> %616, zeroinitializer
  %619 = select <4 x i1> %618, <4 x i32> %617, <4 x i32> %616
  %620 = add nuw <4 x i32> %619, <i32 32, i32 32, i32 32, i32 32>
  %621 = lshr <4 x i32> %620, <i32 6, i32 6, i32 6, i32 6>
  %622 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %611, <4 x i32> %621) #5
  %623 = lshr <8 x i16> %622, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %624 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %595, <8 x i16> %623) #5
  %625 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %624, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %626 = icmp slt <16 x i8> %625, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %627 = select <16 x i1> %626, <16 x i8> %625, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %628 = bitcast i8* %569 to <16 x i8>*
  store <16 x i8> %627, <16 x i8>* %628, align 16
  %629 = getelementptr inbounds i16, i16* %9, i64 160
  %630 = getelementptr inbounds i16, i16* %10, i64 160
  %631 = getelementptr inbounds i8, i8* %507, i64 32
  %632 = bitcast i16* %629 to <8 x i16>*
  %633 = load <8 x i16>, <8 x i16>* %632, align 16
  %634 = bitcast i16* %630 to <8 x i16>*
  %635 = load <8 x i16>, <8 x i16>* %634, align 16
  %636 = shufflevector <8 x i16> %633, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %637 = zext <4 x i16> %636 to <4 x i32>
  %638 = shufflevector <8 x i16> %635, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %639 = zext <4 x i16> %638 to <4 x i32>
  %640 = sub nsw <4 x i32> %637, %639
  %641 = sub nsw <4 x i32> zeroinitializer, %640
  %642 = icmp slt <4 x i32> %640, zeroinitializer
  %643 = select <4 x i1> %642, <4 x i32> %641, <4 x i32> %640
  %644 = add nuw nsw <4 x i32> %643, <i32 32, i32 32, i32 32, i32 32>
  %645 = lshr <4 x i32> %644, <i32 6, i32 6, i32 6, i32 6>
  %646 = shufflevector <8 x i16> %633, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %647 = shufflevector <8 x i16> %635, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %648 = bitcast <8 x i16> %646 to <4 x i32>
  %649 = bitcast <8 x i16> %647 to <4 x i32>
  %650 = sub <4 x i32> %648, %649
  %651 = sub <4 x i32> zeroinitializer, %650
  %652 = icmp slt <4 x i32> %650, zeroinitializer
  %653 = select <4 x i1> %652, <4 x i32> %651, <4 x i32> %650
  %654 = add nuw <4 x i32> %653, <i32 32, i32 32, i32 32, i32 32>
  %655 = lshr <4 x i32> %654, <i32 6, i32 6, i32 6, i32 6>
  %656 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %645, <4 x i32> %655) #5
  %657 = lshr <8 x i16> %656, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %658 = getelementptr inbounds i16, i16* %9, i64 168
  %659 = bitcast i16* %658 to <8 x i16>*
  %660 = load <8 x i16>, <8 x i16>* %659, align 16
  %661 = getelementptr inbounds i16, i16* %10, i64 168
  %662 = bitcast i16* %661 to <8 x i16>*
  %663 = load <8 x i16>, <8 x i16>* %662, align 16
  %664 = shufflevector <8 x i16> %660, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %665 = zext <4 x i16> %664 to <4 x i32>
  %666 = shufflevector <8 x i16> %663, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %667 = zext <4 x i16> %666 to <4 x i32>
  %668 = sub nsw <4 x i32> %665, %667
  %669 = sub nsw <4 x i32> zeroinitializer, %668
  %670 = icmp slt <4 x i32> %668, zeroinitializer
  %671 = select <4 x i1> %670, <4 x i32> %669, <4 x i32> %668
  %672 = add nuw nsw <4 x i32> %671, <i32 32, i32 32, i32 32, i32 32>
  %673 = lshr <4 x i32> %672, <i32 6, i32 6, i32 6, i32 6>
  %674 = shufflevector <8 x i16> %660, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %675 = shufflevector <8 x i16> %663, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %676 = bitcast <8 x i16> %674 to <4 x i32>
  %677 = bitcast <8 x i16> %675 to <4 x i32>
  %678 = sub <4 x i32> %676, %677
  %679 = sub <4 x i32> zeroinitializer, %678
  %680 = icmp slt <4 x i32> %678, zeroinitializer
  %681 = select <4 x i1> %680, <4 x i32> %679, <4 x i32> %678
  %682 = add nuw <4 x i32> %681, <i32 32, i32 32, i32 32, i32 32>
  %683 = lshr <4 x i32> %682, <i32 6, i32 6, i32 6, i32 6>
  %684 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %673, <4 x i32> %683) #5
  %685 = lshr <8 x i16> %684, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %686 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %657, <8 x i16> %685) #5
  %687 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %686, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %688 = icmp slt <16 x i8> %687, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %689 = select <16 x i1> %688, <16 x i8> %687, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %690 = bitcast i8* %631 to <16 x i8>*
  store <16 x i8> %689, <16 x i8>* %690, align 16
  %691 = getelementptr inbounds i16, i16* %9, i64 176
  %692 = getelementptr inbounds i16, i16* %10, i64 176
  %693 = getelementptr inbounds i8, i8* %507, i64 48
  %694 = bitcast i16* %691 to <8 x i16>*
  %695 = load <8 x i16>, <8 x i16>* %694, align 16
  %696 = bitcast i16* %692 to <8 x i16>*
  %697 = load <8 x i16>, <8 x i16>* %696, align 16
  %698 = shufflevector <8 x i16> %695, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %699 = zext <4 x i16> %698 to <4 x i32>
  %700 = shufflevector <8 x i16> %697, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %701 = zext <4 x i16> %700 to <4 x i32>
  %702 = sub nsw <4 x i32> %699, %701
  %703 = sub nsw <4 x i32> zeroinitializer, %702
  %704 = icmp slt <4 x i32> %702, zeroinitializer
  %705 = select <4 x i1> %704, <4 x i32> %703, <4 x i32> %702
  %706 = add nuw nsw <4 x i32> %705, <i32 32, i32 32, i32 32, i32 32>
  %707 = lshr <4 x i32> %706, <i32 6, i32 6, i32 6, i32 6>
  %708 = shufflevector <8 x i16> %695, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %709 = shufflevector <8 x i16> %697, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %710 = bitcast <8 x i16> %708 to <4 x i32>
  %711 = bitcast <8 x i16> %709 to <4 x i32>
  %712 = sub <4 x i32> %710, %711
  %713 = sub <4 x i32> zeroinitializer, %712
  %714 = icmp slt <4 x i32> %712, zeroinitializer
  %715 = select <4 x i1> %714, <4 x i32> %713, <4 x i32> %712
  %716 = add nuw <4 x i32> %715, <i32 32, i32 32, i32 32, i32 32>
  %717 = lshr <4 x i32> %716, <i32 6, i32 6, i32 6, i32 6>
  %718 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %707, <4 x i32> %717) #5
  %719 = lshr <8 x i16> %718, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %720 = getelementptr inbounds i16, i16* %9, i64 184
  %721 = bitcast i16* %720 to <8 x i16>*
  %722 = load <8 x i16>, <8 x i16>* %721, align 16
  %723 = getelementptr inbounds i16, i16* %10, i64 184
  %724 = bitcast i16* %723 to <8 x i16>*
  %725 = load <8 x i16>, <8 x i16>* %724, align 16
  %726 = shufflevector <8 x i16> %722, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %727 = zext <4 x i16> %726 to <4 x i32>
  %728 = shufflevector <8 x i16> %725, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %729 = zext <4 x i16> %728 to <4 x i32>
  %730 = sub nsw <4 x i32> %727, %729
  %731 = sub nsw <4 x i32> zeroinitializer, %730
  %732 = icmp slt <4 x i32> %730, zeroinitializer
  %733 = select <4 x i1> %732, <4 x i32> %731, <4 x i32> %730
  %734 = add nuw nsw <4 x i32> %733, <i32 32, i32 32, i32 32, i32 32>
  %735 = lshr <4 x i32> %734, <i32 6, i32 6, i32 6, i32 6>
  %736 = shufflevector <8 x i16> %722, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %737 = shufflevector <8 x i16> %725, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %738 = bitcast <8 x i16> %736 to <4 x i32>
  %739 = bitcast <8 x i16> %737 to <4 x i32>
  %740 = sub <4 x i32> %738, %739
  %741 = sub <4 x i32> zeroinitializer, %740
  %742 = icmp slt <4 x i32> %740, zeroinitializer
  %743 = select <4 x i1> %742, <4 x i32> %741, <4 x i32> %740
  %744 = add nuw <4 x i32> %743, <i32 32, i32 32, i32 32, i32 32>
  %745 = lshr <4 x i32> %744, <i32 6, i32 6, i32 6, i32 6>
  %746 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %735, <4 x i32> %745) #5
  %747 = lshr <8 x i16> %746, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %748 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %719, <8 x i16> %747) #5
  %749 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %748, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %750 = icmp slt <16 x i8> %749, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %751 = select <16 x i1> %750, <16 x i8> %749, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %752 = bitcast i8* %693 to <16 x i8>*
  store <16 x i8> %751, <16 x i8>* %752, align 16
  %753 = getelementptr inbounds i16, i16* %9, i64 192
  %754 = getelementptr inbounds i16, i16* %10, i64 192
  %755 = getelementptr inbounds i8, i8* %507, i64 %3
  %756 = add nsw i32 %11, -1
  %757 = icmp eq i32 %756, 0
  br i1 %757, label %758, label %7

758:                                              ; preds = %7
  %759 = bitcast i16* %753 to <8 x i16>*
  %760 = load <8 x i16>, <8 x i16>* %759, align 16
  %761 = bitcast i16* %754 to <8 x i16>*
  %762 = load <8 x i16>, <8 x i16>* %761, align 16
  %763 = shufflevector <8 x i16> %760, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %764 = zext <4 x i16> %763 to <4 x i32>
  %765 = shufflevector <8 x i16> %762, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %766 = zext <4 x i16> %765 to <4 x i32>
  %767 = sub nsw <4 x i32> %764, %766
  %768 = sub nsw <4 x i32> zeroinitializer, %767
  %769 = icmp slt <4 x i32> %767, zeroinitializer
  %770 = select <4 x i1> %769, <4 x i32> %768, <4 x i32> %767
  %771 = add nuw nsw <4 x i32> %770, <i32 32, i32 32, i32 32, i32 32>
  %772 = lshr <4 x i32> %771, <i32 6, i32 6, i32 6, i32 6>
  %773 = shufflevector <8 x i16> %760, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %774 = shufflevector <8 x i16> %762, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %775 = bitcast <8 x i16> %773 to <4 x i32>
  %776 = bitcast <8 x i16> %774 to <4 x i32>
  %777 = sub <4 x i32> %775, %776
  %778 = sub <4 x i32> zeroinitializer, %777
  %779 = icmp slt <4 x i32> %777, zeroinitializer
  %780 = select <4 x i1> %779, <4 x i32> %778, <4 x i32> %777
  %781 = add nuw <4 x i32> %780, <i32 32, i32 32, i32 32, i32 32>
  %782 = lshr <4 x i32> %781, <i32 6, i32 6, i32 6, i32 6>
  %783 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %772, <4 x i32> %782) #5
  %784 = lshr <8 x i16> %783, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %785 = getelementptr inbounds i16, i16* %9, i64 200
  %786 = bitcast i16* %785 to <8 x i16>*
  %787 = load <8 x i16>, <8 x i16>* %786, align 16
  %788 = getelementptr inbounds i16, i16* %10, i64 200
  %789 = bitcast i16* %788 to <8 x i16>*
  %790 = load <8 x i16>, <8 x i16>* %789, align 16
  %791 = shufflevector <8 x i16> %787, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %792 = zext <4 x i16> %791 to <4 x i32>
  %793 = shufflevector <8 x i16> %790, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %794 = zext <4 x i16> %793 to <4 x i32>
  %795 = sub nsw <4 x i32> %792, %794
  %796 = sub nsw <4 x i32> zeroinitializer, %795
  %797 = icmp slt <4 x i32> %795, zeroinitializer
  %798 = select <4 x i1> %797, <4 x i32> %796, <4 x i32> %795
  %799 = add nuw nsw <4 x i32> %798, <i32 32, i32 32, i32 32, i32 32>
  %800 = lshr <4 x i32> %799, <i32 6, i32 6, i32 6, i32 6>
  %801 = shufflevector <8 x i16> %787, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %802 = shufflevector <8 x i16> %790, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %803 = bitcast <8 x i16> %801 to <4 x i32>
  %804 = bitcast <8 x i16> %802 to <4 x i32>
  %805 = sub <4 x i32> %803, %804
  %806 = sub <4 x i32> zeroinitializer, %805
  %807 = icmp slt <4 x i32> %805, zeroinitializer
  %808 = select <4 x i1> %807, <4 x i32> %806, <4 x i32> %805
  %809 = add nuw <4 x i32> %808, <i32 32, i32 32, i32 32, i32 32>
  %810 = lshr <4 x i32> %809, <i32 6, i32 6, i32 6, i32 6>
  %811 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %800, <4 x i32> %810) #5
  %812 = lshr <8 x i16> %811, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %813 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %784, <8 x i16> %812) #5
  %814 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %813, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %815 = icmp slt <16 x i8> %814, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %816 = select <16 x i1> %815, <16 x i8> %814, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %817 = bitcast i8* %755 to <16 x i8>*
  store <16 x i8> %816, <16 x i8>* %817, align 16
  %818 = getelementptr inbounds i16, i16* %9, i64 208
  %819 = getelementptr inbounds i16, i16* %10, i64 208
  %820 = getelementptr inbounds i8, i8* %755, i64 16
  %821 = bitcast i16* %818 to <8 x i16>*
  %822 = load <8 x i16>, <8 x i16>* %821, align 16
  %823 = bitcast i16* %819 to <8 x i16>*
  %824 = load <8 x i16>, <8 x i16>* %823, align 16
  %825 = shufflevector <8 x i16> %822, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %826 = zext <4 x i16> %825 to <4 x i32>
  %827 = shufflevector <8 x i16> %824, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %828 = zext <4 x i16> %827 to <4 x i32>
  %829 = sub nsw <4 x i32> %826, %828
  %830 = sub nsw <4 x i32> zeroinitializer, %829
  %831 = icmp slt <4 x i32> %829, zeroinitializer
  %832 = select <4 x i1> %831, <4 x i32> %830, <4 x i32> %829
  %833 = add nuw nsw <4 x i32> %832, <i32 32, i32 32, i32 32, i32 32>
  %834 = lshr <4 x i32> %833, <i32 6, i32 6, i32 6, i32 6>
  %835 = shufflevector <8 x i16> %822, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %836 = shufflevector <8 x i16> %824, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %837 = bitcast <8 x i16> %835 to <4 x i32>
  %838 = bitcast <8 x i16> %836 to <4 x i32>
  %839 = sub <4 x i32> %837, %838
  %840 = sub <4 x i32> zeroinitializer, %839
  %841 = icmp slt <4 x i32> %839, zeroinitializer
  %842 = select <4 x i1> %841, <4 x i32> %840, <4 x i32> %839
  %843 = add nuw <4 x i32> %842, <i32 32, i32 32, i32 32, i32 32>
  %844 = lshr <4 x i32> %843, <i32 6, i32 6, i32 6, i32 6>
  %845 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %834, <4 x i32> %844) #5
  %846 = lshr <8 x i16> %845, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %847 = getelementptr inbounds i16, i16* %9, i64 216
  %848 = bitcast i16* %847 to <8 x i16>*
  %849 = load <8 x i16>, <8 x i16>* %848, align 16
  %850 = getelementptr inbounds i16, i16* %10, i64 216
  %851 = bitcast i16* %850 to <8 x i16>*
  %852 = load <8 x i16>, <8 x i16>* %851, align 16
  %853 = shufflevector <8 x i16> %849, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %854 = zext <4 x i16> %853 to <4 x i32>
  %855 = shufflevector <8 x i16> %852, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %856 = zext <4 x i16> %855 to <4 x i32>
  %857 = sub nsw <4 x i32> %854, %856
  %858 = sub nsw <4 x i32> zeroinitializer, %857
  %859 = icmp slt <4 x i32> %857, zeroinitializer
  %860 = select <4 x i1> %859, <4 x i32> %858, <4 x i32> %857
  %861 = add nuw nsw <4 x i32> %860, <i32 32, i32 32, i32 32, i32 32>
  %862 = lshr <4 x i32> %861, <i32 6, i32 6, i32 6, i32 6>
  %863 = shufflevector <8 x i16> %849, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %864 = shufflevector <8 x i16> %852, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %865 = bitcast <8 x i16> %863 to <4 x i32>
  %866 = bitcast <8 x i16> %864 to <4 x i32>
  %867 = sub <4 x i32> %865, %866
  %868 = sub <4 x i32> zeroinitializer, %867
  %869 = icmp slt <4 x i32> %867, zeroinitializer
  %870 = select <4 x i1> %869, <4 x i32> %868, <4 x i32> %867
  %871 = add nuw <4 x i32> %870, <i32 32, i32 32, i32 32, i32 32>
  %872 = lshr <4 x i32> %871, <i32 6, i32 6, i32 6, i32 6>
  %873 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %862, <4 x i32> %872) #5
  %874 = lshr <8 x i16> %873, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %875 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %846, <8 x i16> %874) #5
  %876 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %875, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %877 = icmp slt <16 x i8> %876, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %878 = select <16 x i1> %877, <16 x i8> %876, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %879 = bitcast i8* %820 to <16 x i8>*
  store <16 x i8> %878, <16 x i8>* %879, align 16
  %880 = getelementptr inbounds i16, i16* %9, i64 224
  %881 = getelementptr inbounds i16, i16* %10, i64 224
  %882 = getelementptr inbounds i8, i8* %755, i64 32
  %883 = bitcast i16* %880 to <8 x i16>*
  %884 = load <8 x i16>, <8 x i16>* %883, align 16
  %885 = bitcast i16* %881 to <8 x i16>*
  %886 = load <8 x i16>, <8 x i16>* %885, align 16
  %887 = shufflevector <8 x i16> %884, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %888 = zext <4 x i16> %887 to <4 x i32>
  %889 = shufflevector <8 x i16> %886, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %890 = zext <4 x i16> %889 to <4 x i32>
  %891 = sub nsw <4 x i32> %888, %890
  %892 = sub nsw <4 x i32> zeroinitializer, %891
  %893 = icmp slt <4 x i32> %891, zeroinitializer
  %894 = select <4 x i1> %893, <4 x i32> %892, <4 x i32> %891
  %895 = add nuw nsw <4 x i32> %894, <i32 32, i32 32, i32 32, i32 32>
  %896 = lshr <4 x i32> %895, <i32 6, i32 6, i32 6, i32 6>
  %897 = shufflevector <8 x i16> %884, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %898 = shufflevector <8 x i16> %886, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %899 = bitcast <8 x i16> %897 to <4 x i32>
  %900 = bitcast <8 x i16> %898 to <4 x i32>
  %901 = sub <4 x i32> %899, %900
  %902 = sub <4 x i32> zeroinitializer, %901
  %903 = icmp slt <4 x i32> %901, zeroinitializer
  %904 = select <4 x i1> %903, <4 x i32> %902, <4 x i32> %901
  %905 = add nuw <4 x i32> %904, <i32 32, i32 32, i32 32, i32 32>
  %906 = lshr <4 x i32> %905, <i32 6, i32 6, i32 6, i32 6>
  %907 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %896, <4 x i32> %906) #5
  %908 = lshr <8 x i16> %907, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %909 = getelementptr inbounds i16, i16* %9, i64 232
  %910 = bitcast i16* %909 to <8 x i16>*
  %911 = load <8 x i16>, <8 x i16>* %910, align 16
  %912 = getelementptr inbounds i16, i16* %10, i64 232
  %913 = bitcast i16* %912 to <8 x i16>*
  %914 = load <8 x i16>, <8 x i16>* %913, align 16
  %915 = shufflevector <8 x i16> %911, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %916 = zext <4 x i16> %915 to <4 x i32>
  %917 = shufflevector <8 x i16> %914, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %918 = zext <4 x i16> %917 to <4 x i32>
  %919 = sub nsw <4 x i32> %916, %918
  %920 = sub nsw <4 x i32> zeroinitializer, %919
  %921 = icmp slt <4 x i32> %919, zeroinitializer
  %922 = select <4 x i1> %921, <4 x i32> %920, <4 x i32> %919
  %923 = add nuw nsw <4 x i32> %922, <i32 32, i32 32, i32 32, i32 32>
  %924 = lshr <4 x i32> %923, <i32 6, i32 6, i32 6, i32 6>
  %925 = shufflevector <8 x i16> %911, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %926 = shufflevector <8 x i16> %914, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %927 = bitcast <8 x i16> %925 to <4 x i32>
  %928 = bitcast <8 x i16> %926 to <4 x i32>
  %929 = sub <4 x i32> %927, %928
  %930 = sub <4 x i32> zeroinitializer, %929
  %931 = icmp slt <4 x i32> %929, zeroinitializer
  %932 = select <4 x i1> %931, <4 x i32> %930, <4 x i32> %929
  %933 = add nuw <4 x i32> %932, <i32 32, i32 32, i32 32, i32 32>
  %934 = lshr <4 x i32> %933, <i32 6, i32 6, i32 6, i32 6>
  %935 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %924, <4 x i32> %934) #5
  %936 = lshr <8 x i16> %935, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %937 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %908, <8 x i16> %936) #5
  %938 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %937, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %939 = icmp slt <16 x i8> %938, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %940 = select <16 x i1> %939, <16 x i8> %938, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %941 = bitcast i8* %882 to <16 x i8>*
  store <16 x i8> %940, <16 x i8>* %941, align 16
  %942 = getelementptr inbounds i16, i16* %9, i64 240
  %943 = getelementptr inbounds i16, i16* %10, i64 240
  %944 = getelementptr inbounds i8, i8* %755, i64 48
  %945 = bitcast i16* %942 to <8 x i16>*
  %946 = load <8 x i16>, <8 x i16>* %945, align 16
  %947 = bitcast i16* %943 to <8 x i16>*
  %948 = load <8 x i16>, <8 x i16>* %947, align 16
  %949 = shufflevector <8 x i16> %946, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %950 = zext <4 x i16> %949 to <4 x i32>
  %951 = shufflevector <8 x i16> %948, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %952 = zext <4 x i16> %951 to <4 x i32>
  %953 = sub nsw <4 x i32> %950, %952
  %954 = sub nsw <4 x i32> zeroinitializer, %953
  %955 = icmp slt <4 x i32> %953, zeroinitializer
  %956 = select <4 x i1> %955, <4 x i32> %954, <4 x i32> %953
  %957 = add nuw nsw <4 x i32> %956, <i32 32, i32 32, i32 32, i32 32>
  %958 = lshr <4 x i32> %957, <i32 6, i32 6, i32 6, i32 6>
  %959 = shufflevector <8 x i16> %946, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %960 = shufflevector <8 x i16> %948, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %961 = bitcast <8 x i16> %959 to <4 x i32>
  %962 = bitcast <8 x i16> %960 to <4 x i32>
  %963 = sub <4 x i32> %961, %962
  %964 = sub <4 x i32> zeroinitializer, %963
  %965 = icmp slt <4 x i32> %963, zeroinitializer
  %966 = select <4 x i1> %965, <4 x i32> %964, <4 x i32> %963
  %967 = add nuw <4 x i32> %966, <i32 32, i32 32, i32 32, i32 32>
  %968 = lshr <4 x i32> %967, <i32 6, i32 6, i32 6, i32 6>
  %969 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %958, <4 x i32> %968) #5
  %970 = lshr <8 x i16> %969, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %971 = getelementptr inbounds i16, i16* %9, i64 248
  %972 = bitcast i16* %971 to <8 x i16>*
  %973 = load <8 x i16>, <8 x i16>* %972, align 16
  %974 = getelementptr inbounds i16, i16* %10, i64 248
  %975 = bitcast i16* %974 to <8 x i16>*
  %976 = load <8 x i16>, <8 x i16>* %975, align 16
  %977 = shufflevector <8 x i16> %973, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %978 = zext <4 x i16> %977 to <4 x i32>
  %979 = shufflevector <8 x i16> %976, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %980 = zext <4 x i16> %979 to <4 x i32>
  %981 = sub nsw <4 x i32> %978, %980
  %982 = sub nsw <4 x i32> zeroinitializer, %981
  %983 = icmp slt <4 x i32> %981, zeroinitializer
  %984 = select <4 x i1> %983, <4 x i32> %982, <4 x i32> %981
  %985 = add nuw nsw <4 x i32> %984, <i32 32, i32 32, i32 32, i32 32>
  %986 = lshr <4 x i32> %985, <i32 6, i32 6, i32 6, i32 6>
  %987 = shufflevector <8 x i16> %973, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %988 = shufflevector <8 x i16> %976, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %989 = bitcast <8 x i16> %987 to <4 x i32>
  %990 = bitcast <8 x i16> %988 to <4 x i32>
  %991 = sub <4 x i32> %989, %990
  %992 = sub <4 x i32> zeroinitializer, %991
  %993 = icmp slt <4 x i32> %991, zeroinitializer
  %994 = select <4 x i1> %993, <4 x i32> %992, <4 x i32> %991
  %995 = add nuw <4 x i32> %994, <i32 32, i32 32, i32 32, i32 32>
  %996 = lshr <4 x i32> %995, <i32 6, i32 6, i32 6, i32 6>
  %997 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %986, <4 x i32> %996) #5
  %998 = lshr <8 x i16> %997, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %999 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %970, <8 x i16> %998) #5
  %1000 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %999, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1001 = icmp slt <16 x i8> %1000, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1002 = select <16 x i1> %1001, <16 x i8> %1000, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1003 = bitcast i8* %944 to <16 x i8>*
  store <16 x i8> %1002, <16 x i8>* %1003, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask64x16_10bpp_SSE4ILb1EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %767, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %765, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %766, %7 ]
  %11 = phi i32 [ 5, %4 ], [ %768, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = shufflevector <8 x i16> %13, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %17 = zext <4 x i16> %16 to <4 x i32>
  %18 = shufflevector <8 x i16> %15, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %19 = zext <4 x i16> %18 to <4 x i32>
  %20 = sub nsw <4 x i32> %17, %19
  %21 = sub nsw <4 x i32> zeroinitializer, %20
  %22 = icmp slt <4 x i32> %20, zeroinitializer
  %23 = select <4 x i1> %22, <4 x i32> %21, <4 x i32> %20
  %24 = add nuw nsw <4 x i32> %23, <i32 32, i32 32, i32 32, i32 32>
  %25 = lshr <4 x i32> %24, <i32 6, i32 6, i32 6, i32 6>
  %26 = shufflevector <8 x i16> %13, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %27 = shufflevector <8 x i16> %15, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %28 = bitcast <8 x i16> %26 to <4 x i32>
  %29 = bitcast <8 x i16> %27 to <4 x i32>
  %30 = sub <4 x i32> %28, %29
  %31 = sub <4 x i32> zeroinitializer, %30
  %32 = icmp slt <4 x i32> %30, zeroinitializer
  %33 = select <4 x i1> %32, <4 x i32> %31, <4 x i32> %30
  %34 = add nuw <4 x i32> %33, <i32 32, i32 32, i32 32, i32 32>
  %35 = lshr <4 x i32> %34, <i32 6, i32 6, i32 6, i32 6>
  %36 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %25, <4 x i32> %35) #5
  %37 = lshr <8 x i16> %36, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %38 = getelementptr inbounds i16, i16* %9, i64 8
  %39 = bitcast i16* %38 to <8 x i16>*
  %40 = load <8 x i16>, <8 x i16>* %39, align 16
  %41 = getelementptr inbounds i16, i16* %10, i64 8
  %42 = bitcast i16* %41 to <8 x i16>*
  %43 = load <8 x i16>, <8 x i16>* %42, align 16
  %44 = shufflevector <8 x i16> %40, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %45 = zext <4 x i16> %44 to <4 x i32>
  %46 = shufflevector <8 x i16> %43, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %47 = zext <4 x i16> %46 to <4 x i32>
  %48 = sub nsw <4 x i32> %45, %47
  %49 = sub nsw <4 x i32> zeroinitializer, %48
  %50 = icmp slt <4 x i32> %48, zeroinitializer
  %51 = select <4 x i1> %50, <4 x i32> %49, <4 x i32> %48
  %52 = add nuw nsw <4 x i32> %51, <i32 32, i32 32, i32 32, i32 32>
  %53 = lshr <4 x i32> %52, <i32 6, i32 6, i32 6, i32 6>
  %54 = shufflevector <8 x i16> %40, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %55 = shufflevector <8 x i16> %43, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %56 = bitcast <8 x i16> %54 to <4 x i32>
  %57 = bitcast <8 x i16> %55 to <4 x i32>
  %58 = sub <4 x i32> %56, %57
  %59 = sub <4 x i32> zeroinitializer, %58
  %60 = icmp slt <4 x i32> %58, zeroinitializer
  %61 = select <4 x i1> %60, <4 x i32> %59, <4 x i32> %58
  %62 = add nuw <4 x i32> %61, <i32 32, i32 32, i32 32, i32 32>
  %63 = lshr <4 x i32> %62, <i32 6, i32 6, i32 6, i32 6>
  %64 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %53, <4 x i32> %63) #5
  %65 = lshr <8 x i16> %64, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %66 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %37, <8 x i16> %65) #5
  %67 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %66, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %68 = icmp slt <16 x i8> %67, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %69 = select <16 x i1> %68, <16 x i8> %67, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %70 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %69
  %71 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %70, <16 x i8>* %71, align 16
  %72 = getelementptr inbounds i16, i16* %9, i64 16
  %73 = getelementptr inbounds i16, i16* %10, i64 16
  %74 = getelementptr inbounds i8, i8* %8, i64 16
  %75 = bitcast i16* %72 to <8 x i16>*
  %76 = load <8 x i16>, <8 x i16>* %75, align 16
  %77 = bitcast i16* %73 to <8 x i16>*
  %78 = load <8 x i16>, <8 x i16>* %77, align 16
  %79 = shufflevector <8 x i16> %76, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %80 = zext <4 x i16> %79 to <4 x i32>
  %81 = shufflevector <8 x i16> %78, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %82 = zext <4 x i16> %81 to <4 x i32>
  %83 = sub nsw <4 x i32> %80, %82
  %84 = sub nsw <4 x i32> zeroinitializer, %83
  %85 = icmp slt <4 x i32> %83, zeroinitializer
  %86 = select <4 x i1> %85, <4 x i32> %84, <4 x i32> %83
  %87 = add nuw nsw <4 x i32> %86, <i32 32, i32 32, i32 32, i32 32>
  %88 = lshr <4 x i32> %87, <i32 6, i32 6, i32 6, i32 6>
  %89 = shufflevector <8 x i16> %76, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %90 = shufflevector <8 x i16> %78, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %91 = bitcast <8 x i16> %89 to <4 x i32>
  %92 = bitcast <8 x i16> %90 to <4 x i32>
  %93 = sub <4 x i32> %91, %92
  %94 = sub <4 x i32> zeroinitializer, %93
  %95 = icmp slt <4 x i32> %93, zeroinitializer
  %96 = select <4 x i1> %95, <4 x i32> %94, <4 x i32> %93
  %97 = add nuw <4 x i32> %96, <i32 32, i32 32, i32 32, i32 32>
  %98 = lshr <4 x i32> %97, <i32 6, i32 6, i32 6, i32 6>
  %99 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %88, <4 x i32> %98) #5
  %100 = lshr <8 x i16> %99, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %101 = getelementptr inbounds i16, i16* %9, i64 24
  %102 = bitcast i16* %101 to <8 x i16>*
  %103 = load <8 x i16>, <8 x i16>* %102, align 16
  %104 = getelementptr inbounds i16, i16* %10, i64 24
  %105 = bitcast i16* %104 to <8 x i16>*
  %106 = load <8 x i16>, <8 x i16>* %105, align 16
  %107 = shufflevector <8 x i16> %103, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %108 = zext <4 x i16> %107 to <4 x i32>
  %109 = shufflevector <8 x i16> %106, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %110 = zext <4 x i16> %109 to <4 x i32>
  %111 = sub nsw <4 x i32> %108, %110
  %112 = sub nsw <4 x i32> zeroinitializer, %111
  %113 = icmp slt <4 x i32> %111, zeroinitializer
  %114 = select <4 x i1> %113, <4 x i32> %112, <4 x i32> %111
  %115 = add nuw nsw <4 x i32> %114, <i32 32, i32 32, i32 32, i32 32>
  %116 = lshr <4 x i32> %115, <i32 6, i32 6, i32 6, i32 6>
  %117 = shufflevector <8 x i16> %103, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %118 = shufflevector <8 x i16> %106, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %119 = bitcast <8 x i16> %117 to <4 x i32>
  %120 = bitcast <8 x i16> %118 to <4 x i32>
  %121 = sub <4 x i32> %119, %120
  %122 = sub <4 x i32> zeroinitializer, %121
  %123 = icmp slt <4 x i32> %121, zeroinitializer
  %124 = select <4 x i1> %123, <4 x i32> %122, <4 x i32> %121
  %125 = add nuw <4 x i32> %124, <i32 32, i32 32, i32 32, i32 32>
  %126 = lshr <4 x i32> %125, <i32 6, i32 6, i32 6, i32 6>
  %127 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %116, <4 x i32> %126) #5
  %128 = lshr <8 x i16> %127, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %129 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %100, <8 x i16> %128) #5
  %130 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %129, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %131 = icmp slt <16 x i8> %130, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %132 = select <16 x i1> %131, <16 x i8> %130, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %133 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %132
  %134 = bitcast i8* %74 to <16 x i8>*
  store <16 x i8> %133, <16 x i8>* %134, align 16
  %135 = getelementptr inbounds i16, i16* %9, i64 32
  %136 = getelementptr inbounds i16, i16* %10, i64 32
  %137 = getelementptr inbounds i8, i8* %8, i64 32
  %138 = bitcast i16* %135 to <8 x i16>*
  %139 = load <8 x i16>, <8 x i16>* %138, align 16
  %140 = bitcast i16* %136 to <8 x i16>*
  %141 = load <8 x i16>, <8 x i16>* %140, align 16
  %142 = shufflevector <8 x i16> %139, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %143 = zext <4 x i16> %142 to <4 x i32>
  %144 = shufflevector <8 x i16> %141, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %145 = zext <4 x i16> %144 to <4 x i32>
  %146 = sub nsw <4 x i32> %143, %145
  %147 = sub nsw <4 x i32> zeroinitializer, %146
  %148 = icmp slt <4 x i32> %146, zeroinitializer
  %149 = select <4 x i1> %148, <4 x i32> %147, <4 x i32> %146
  %150 = add nuw nsw <4 x i32> %149, <i32 32, i32 32, i32 32, i32 32>
  %151 = lshr <4 x i32> %150, <i32 6, i32 6, i32 6, i32 6>
  %152 = shufflevector <8 x i16> %139, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %153 = shufflevector <8 x i16> %141, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %154 = bitcast <8 x i16> %152 to <4 x i32>
  %155 = bitcast <8 x i16> %153 to <4 x i32>
  %156 = sub <4 x i32> %154, %155
  %157 = sub <4 x i32> zeroinitializer, %156
  %158 = icmp slt <4 x i32> %156, zeroinitializer
  %159 = select <4 x i1> %158, <4 x i32> %157, <4 x i32> %156
  %160 = add nuw <4 x i32> %159, <i32 32, i32 32, i32 32, i32 32>
  %161 = lshr <4 x i32> %160, <i32 6, i32 6, i32 6, i32 6>
  %162 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %151, <4 x i32> %161) #5
  %163 = lshr <8 x i16> %162, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %164 = getelementptr inbounds i16, i16* %9, i64 40
  %165 = bitcast i16* %164 to <8 x i16>*
  %166 = load <8 x i16>, <8 x i16>* %165, align 16
  %167 = getelementptr inbounds i16, i16* %10, i64 40
  %168 = bitcast i16* %167 to <8 x i16>*
  %169 = load <8 x i16>, <8 x i16>* %168, align 16
  %170 = shufflevector <8 x i16> %166, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %171 = zext <4 x i16> %170 to <4 x i32>
  %172 = shufflevector <8 x i16> %169, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %173 = zext <4 x i16> %172 to <4 x i32>
  %174 = sub nsw <4 x i32> %171, %173
  %175 = sub nsw <4 x i32> zeroinitializer, %174
  %176 = icmp slt <4 x i32> %174, zeroinitializer
  %177 = select <4 x i1> %176, <4 x i32> %175, <4 x i32> %174
  %178 = add nuw nsw <4 x i32> %177, <i32 32, i32 32, i32 32, i32 32>
  %179 = lshr <4 x i32> %178, <i32 6, i32 6, i32 6, i32 6>
  %180 = shufflevector <8 x i16> %166, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %181 = shufflevector <8 x i16> %169, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %182 = bitcast <8 x i16> %180 to <4 x i32>
  %183 = bitcast <8 x i16> %181 to <4 x i32>
  %184 = sub <4 x i32> %182, %183
  %185 = sub <4 x i32> zeroinitializer, %184
  %186 = icmp slt <4 x i32> %184, zeroinitializer
  %187 = select <4 x i1> %186, <4 x i32> %185, <4 x i32> %184
  %188 = add nuw <4 x i32> %187, <i32 32, i32 32, i32 32, i32 32>
  %189 = lshr <4 x i32> %188, <i32 6, i32 6, i32 6, i32 6>
  %190 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %179, <4 x i32> %189) #5
  %191 = lshr <8 x i16> %190, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %192 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %163, <8 x i16> %191) #5
  %193 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %192, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %194 = icmp slt <16 x i8> %193, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %195 = select <16 x i1> %194, <16 x i8> %193, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %196 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %195
  %197 = bitcast i8* %137 to <16 x i8>*
  store <16 x i8> %196, <16 x i8>* %197, align 16
  %198 = getelementptr inbounds i16, i16* %9, i64 48
  %199 = getelementptr inbounds i16, i16* %10, i64 48
  %200 = getelementptr inbounds i8, i8* %8, i64 48
  %201 = bitcast i16* %198 to <8 x i16>*
  %202 = load <8 x i16>, <8 x i16>* %201, align 16
  %203 = bitcast i16* %199 to <8 x i16>*
  %204 = load <8 x i16>, <8 x i16>* %203, align 16
  %205 = shufflevector <8 x i16> %202, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %206 = zext <4 x i16> %205 to <4 x i32>
  %207 = shufflevector <8 x i16> %204, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %208 = zext <4 x i16> %207 to <4 x i32>
  %209 = sub nsw <4 x i32> %206, %208
  %210 = sub nsw <4 x i32> zeroinitializer, %209
  %211 = icmp slt <4 x i32> %209, zeroinitializer
  %212 = select <4 x i1> %211, <4 x i32> %210, <4 x i32> %209
  %213 = add nuw nsw <4 x i32> %212, <i32 32, i32 32, i32 32, i32 32>
  %214 = lshr <4 x i32> %213, <i32 6, i32 6, i32 6, i32 6>
  %215 = shufflevector <8 x i16> %202, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %216 = shufflevector <8 x i16> %204, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %217 = bitcast <8 x i16> %215 to <4 x i32>
  %218 = bitcast <8 x i16> %216 to <4 x i32>
  %219 = sub <4 x i32> %217, %218
  %220 = sub <4 x i32> zeroinitializer, %219
  %221 = icmp slt <4 x i32> %219, zeroinitializer
  %222 = select <4 x i1> %221, <4 x i32> %220, <4 x i32> %219
  %223 = add nuw <4 x i32> %222, <i32 32, i32 32, i32 32, i32 32>
  %224 = lshr <4 x i32> %223, <i32 6, i32 6, i32 6, i32 6>
  %225 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %214, <4 x i32> %224) #5
  %226 = lshr <8 x i16> %225, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %227 = getelementptr inbounds i16, i16* %9, i64 56
  %228 = bitcast i16* %227 to <8 x i16>*
  %229 = load <8 x i16>, <8 x i16>* %228, align 16
  %230 = getelementptr inbounds i16, i16* %10, i64 56
  %231 = bitcast i16* %230 to <8 x i16>*
  %232 = load <8 x i16>, <8 x i16>* %231, align 16
  %233 = shufflevector <8 x i16> %229, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %234 = zext <4 x i16> %233 to <4 x i32>
  %235 = shufflevector <8 x i16> %232, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %236 = zext <4 x i16> %235 to <4 x i32>
  %237 = sub nsw <4 x i32> %234, %236
  %238 = sub nsw <4 x i32> zeroinitializer, %237
  %239 = icmp slt <4 x i32> %237, zeroinitializer
  %240 = select <4 x i1> %239, <4 x i32> %238, <4 x i32> %237
  %241 = add nuw nsw <4 x i32> %240, <i32 32, i32 32, i32 32, i32 32>
  %242 = lshr <4 x i32> %241, <i32 6, i32 6, i32 6, i32 6>
  %243 = shufflevector <8 x i16> %229, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %244 = shufflevector <8 x i16> %232, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %245 = bitcast <8 x i16> %243 to <4 x i32>
  %246 = bitcast <8 x i16> %244 to <4 x i32>
  %247 = sub <4 x i32> %245, %246
  %248 = sub <4 x i32> zeroinitializer, %247
  %249 = icmp slt <4 x i32> %247, zeroinitializer
  %250 = select <4 x i1> %249, <4 x i32> %248, <4 x i32> %247
  %251 = add nuw <4 x i32> %250, <i32 32, i32 32, i32 32, i32 32>
  %252 = lshr <4 x i32> %251, <i32 6, i32 6, i32 6, i32 6>
  %253 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %242, <4 x i32> %252) #5
  %254 = lshr <8 x i16> %253, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %255 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %226, <8 x i16> %254) #5
  %256 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %255, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %257 = icmp slt <16 x i8> %256, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %258 = select <16 x i1> %257, <16 x i8> %256, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %259 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %258
  %260 = bitcast i8* %200 to <16 x i8>*
  store <16 x i8> %259, <16 x i8>* %260, align 16
  %261 = getelementptr inbounds i16, i16* %9, i64 64
  %262 = getelementptr inbounds i16, i16* %10, i64 64
  %263 = getelementptr inbounds i8, i8* %8, i64 %3
  %264 = bitcast i16* %261 to <8 x i16>*
  %265 = load <8 x i16>, <8 x i16>* %264, align 16
  %266 = bitcast i16* %262 to <8 x i16>*
  %267 = load <8 x i16>, <8 x i16>* %266, align 16
  %268 = shufflevector <8 x i16> %265, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %269 = zext <4 x i16> %268 to <4 x i32>
  %270 = shufflevector <8 x i16> %267, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %271 = zext <4 x i16> %270 to <4 x i32>
  %272 = sub nsw <4 x i32> %269, %271
  %273 = sub nsw <4 x i32> zeroinitializer, %272
  %274 = icmp slt <4 x i32> %272, zeroinitializer
  %275 = select <4 x i1> %274, <4 x i32> %273, <4 x i32> %272
  %276 = add nuw nsw <4 x i32> %275, <i32 32, i32 32, i32 32, i32 32>
  %277 = lshr <4 x i32> %276, <i32 6, i32 6, i32 6, i32 6>
  %278 = shufflevector <8 x i16> %265, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %279 = shufflevector <8 x i16> %267, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %280 = bitcast <8 x i16> %278 to <4 x i32>
  %281 = bitcast <8 x i16> %279 to <4 x i32>
  %282 = sub <4 x i32> %280, %281
  %283 = sub <4 x i32> zeroinitializer, %282
  %284 = icmp slt <4 x i32> %282, zeroinitializer
  %285 = select <4 x i1> %284, <4 x i32> %283, <4 x i32> %282
  %286 = add nuw <4 x i32> %285, <i32 32, i32 32, i32 32, i32 32>
  %287 = lshr <4 x i32> %286, <i32 6, i32 6, i32 6, i32 6>
  %288 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %277, <4 x i32> %287) #5
  %289 = lshr <8 x i16> %288, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %290 = getelementptr inbounds i16, i16* %9, i64 72
  %291 = bitcast i16* %290 to <8 x i16>*
  %292 = load <8 x i16>, <8 x i16>* %291, align 16
  %293 = getelementptr inbounds i16, i16* %10, i64 72
  %294 = bitcast i16* %293 to <8 x i16>*
  %295 = load <8 x i16>, <8 x i16>* %294, align 16
  %296 = shufflevector <8 x i16> %292, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %297 = zext <4 x i16> %296 to <4 x i32>
  %298 = shufflevector <8 x i16> %295, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %299 = zext <4 x i16> %298 to <4 x i32>
  %300 = sub nsw <4 x i32> %297, %299
  %301 = sub nsw <4 x i32> zeroinitializer, %300
  %302 = icmp slt <4 x i32> %300, zeroinitializer
  %303 = select <4 x i1> %302, <4 x i32> %301, <4 x i32> %300
  %304 = add nuw nsw <4 x i32> %303, <i32 32, i32 32, i32 32, i32 32>
  %305 = lshr <4 x i32> %304, <i32 6, i32 6, i32 6, i32 6>
  %306 = shufflevector <8 x i16> %292, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %307 = shufflevector <8 x i16> %295, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %308 = bitcast <8 x i16> %306 to <4 x i32>
  %309 = bitcast <8 x i16> %307 to <4 x i32>
  %310 = sub <4 x i32> %308, %309
  %311 = sub <4 x i32> zeroinitializer, %310
  %312 = icmp slt <4 x i32> %310, zeroinitializer
  %313 = select <4 x i1> %312, <4 x i32> %311, <4 x i32> %310
  %314 = add nuw <4 x i32> %313, <i32 32, i32 32, i32 32, i32 32>
  %315 = lshr <4 x i32> %314, <i32 6, i32 6, i32 6, i32 6>
  %316 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %305, <4 x i32> %315) #5
  %317 = lshr <8 x i16> %316, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %318 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %289, <8 x i16> %317) #5
  %319 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %318, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %320 = icmp slt <16 x i8> %319, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %321 = select <16 x i1> %320, <16 x i8> %319, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %322 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %321
  %323 = bitcast i8* %263 to <16 x i8>*
  store <16 x i8> %322, <16 x i8>* %323, align 16
  %324 = getelementptr inbounds i16, i16* %9, i64 80
  %325 = getelementptr inbounds i16, i16* %10, i64 80
  %326 = getelementptr inbounds i8, i8* %263, i64 16
  %327 = bitcast i16* %324 to <8 x i16>*
  %328 = load <8 x i16>, <8 x i16>* %327, align 16
  %329 = bitcast i16* %325 to <8 x i16>*
  %330 = load <8 x i16>, <8 x i16>* %329, align 16
  %331 = shufflevector <8 x i16> %328, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %332 = zext <4 x i16> %331 to <4 x i32>
  %333 = shufflevector <8 x i16> %330, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %334 = zext <4 x i16> %333 to <4 x i32>
  %335 = sub nsw <4 x i32> %332, %334
  %336 = sub nsw <4 x i32> zeroinitializer, %335
  %337 = icmp slt <4 x i32> %335, zeroinitializer
  %338 = select <4 x i1> %337, <4 x i32> %336, <4 x i32> %335
  %339 = add nuw nsw <4 x i32> %338, <i32 32, i32 32, i32 32, i32 32>
  %340 = lshr <4 x i32> %339, <i32 6, i32 6, i32 6, i32 6>
  %341 = shufflevector <8 x i16> %328, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %342 = shufflevector <8 x i16> %330, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %343 = bitcast <8 x i16> %341 to <4 x i32>
  %344 = bitcast <8 x i16> %342 to <4 x i32>
  %345 = sub <4 x i32> %343, %344
  %346 = sub <4 x i32> zeroinitializer, %345
  %347 = icmp slt <4 x i32> %345, zeroinitializer
  %348 = select <4 x i1> %347, <4 x i32> %346, <4 x i32> %345
  %349 = add nuw <4 x i32> %348, <i32 32, i32 32, i32 32, i32 32>
  %350 = lshr <4 x i32> %349, <i32 6, i32 6, i32 6, i32 6>
  %351 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %340, <4 x i32> %350) #5
  %352 = lshr <8 x i16> %351, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %353 = getelementptr inbounds i16, i16* %9, i64 88
  %354 = bitcast i16* %353 to <8 x i16>*
  %355 = load <8 x i16>, <8 x i16>* %354, align 16
  %356 = getelementptr inbounds i16, i16* %10, i64 88
  %357 = bitcast i16* %356 to <8 x i16>*
  %358 = load <8 x i16>, <8 x i16>* %357, align 16
  %359 = shufflevector <8 x i16> %355, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %360 = zext <4 x i16> %359 to <4 x i32>
  %361 = shufflevector <8 x i16> %358, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %362 = zext <4 x i16> %361 to <4 x i32>
  %363 = sub nsw <4 x i32> %360, %362
  %364 = sub nsw <4 x i32> zeroinitializer, %363
  %365 = icmp slt <4 x i32> %363, zeroinitializer
  %366 = select <4 x i1> %365, <4 x i32> %364, <4 x i32> %363
  %367 = add nuw nsw <4 x i32> %366, <i32 32, i32 32, i32 32, i32 32>
  %368 = lshr <4 x i32> %367, <i32 6, i32 6, i32 6, i32 6>
  %369 = shufflevector <8 x i16> %355, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %370 = shufflevector <8 x i16> %358, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %371 = bitcast <8 x i16> %369 to <4 x i32>
  %372 = bitcast <8 x i16> %370 to <4 x i32>
  %373 = sub <4 x i32> %371, %372
  %374 = sub <4 x i32> zeroinitializer, %373
  %375 = icmp slt <4 x i32> %373, zeroinitializer
  %376 = select <4 x i1> %375, <4 x i32> %374, <4 x i32> %373
  %377 = add nuw <4 x i32> %376, <i32 32, i32 32, i32 32, i32 32>
  %378 = lshr <4 x i32> %377, <i32 6, i32 6, i32 6, i32 6>
  %379 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %368, <4 x i32> %378) #5
  %380 = lshr <8 x i16> %379, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %381 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %352, <8 x i16> %380) #5
  %382 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %381, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %383 = icmp slt <16 x i8> %382, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %384 = select <16 x i1> %383, <16 x i8> %382, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %385 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %384
  %386 = bitcast i8* %326 to <16 x i8>*
  store <16 x i8> %385, <16 x i8>* %386, align 16
  %387 = getelementptr inbounds i16, i16* %9, i64 96
  %388 = getelementptr inbounds i16, i16* %10, i64 96
  %389 = getelementptr inbounds i8, i8* %263, i64 32
  %390 = bitcast i16* %387 to <8 x i16>*
  %391 = load <8 x i16>, <8 x i16>* %390, align 16
  %392 = bitcast i16* %388 to <8 x i16>*
  %393 = load <8 x i16>, <8 x i16>* %392, align 16
  %394 = shufflevector <8 x i16> %391, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %395 = zext <4 x i16> %394 to <4 x i32>
  %396 = shufflevector <8 x i16> %393, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %397 = zext <4 x i16> %396 to <4 x i32>
  %398 = sub nsw <4 x i32> %395, %397
  %399 = sub nsw <4 x i32> zeroinitializer, %398
  %400 = icmp slt <4 x i32> %398, zeroinitializer
  %401 = select <4 x i1> %400, <4 x i32> %399, <4 x i32> %398
  %402 = add nuw nsw <4 x i32> %401, <i32 32, i32 32, i32 32, i32 32>
  %403 = lshr <4 x i32> %402, <i32 6, i32 6, i32 6, i32 6>
  %404 = shufflevector <8 x i16> %391, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %405 = shufflevector <8 x i16> %393, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %406 = bitcast <8 x i16> %404 to <4 x i32>
  %407 = bitcast <8 x i16> %405 to <4 x i32>
  %408 = sub <4 x i32> %406, %407
  %409 = sub <4 x i32> zeroinitializer, %408
  %410 = icmp slt <4 x i32> %408, zeroinitializer
  %411 = select <4 x i1> %410, <4 x i32> %409, <4 x i32> %408
  %412 = add nuw <4 x i32> %411, <i32 32, i32 32, i32 32, i32 32>
  %413 = lshr <4 x i32> %412, <i32 6, i32 6, i32 6, i32 6>
  %414 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %403, <4 x i32> %413) #5
  %415 = lshr <8 x i16> %414, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %416 = getelementptr inbounds i16, i16* %9, i64 104
  %417 = bitcast i16* %416 to <8 x i16>*
  %418 = load <8 x i16>, <8 x i16>* %417, align 16
  %419 = getelementptr inbounds i16, i16* %10, i64 104
  %420 = bitcast i16* %419 to <8 x i16>*
  %421 = load <8 x i16>, <8 x i16>* %420, align 16
  %422 = shufflevector <8 x i16> %418, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %423 = zext <4 x i16> %422 to <4 x i32>
  %424 = shufflevector <8 x i16> %421, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %425 = zext <4 x i16> %424 to <4 x i32>
  %426 = sub nsw <4 x i32> %423, %425
  %427 = sub nsw <4 x i32> zeroinitializer, %426
  %428 = icmp slt <4 x i32> %426, zeroinitializer
  %429 = select <4 x i1> %428, <4 x i32> %427, <4 x i32> %426
  %430 = add nuw nsw <4 x i32> %429, <i32 32, i32 32, i32 32, i32 32>
  %431 = lshr <4 x i32> %430, <i32 6, i32 6, i32 6, i32 6>
  %432 = shufflevector <8 x i16> %418, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %433 = shufflevector <8 x i16> %421, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %434 = bitcast <8 x i16> %432 to <4 x i32>
  %435 = bitcast <8 x i16> %433 to <4 x i32>
  %436 = sub <4 x i32> %434, %435
  %437 = sub <4 x i32> zeroinitializer, %436
  %438 = icmp slt <4 x i32> %436, zeroinitializer
  %439 = select <4 x i1> %438, <4 x i32> %437, <4 x i32> %436
  %440 = add nuw <4 x i32> %439, <i32 32, i32 32, i32 32, i32 32>
  %441 = lshr <4 x i32> %440, <i32 6, i32 6, i32 6, i32 6>
  %442 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %431, <4 x i32> %441) #5
  %443 = lshr <8 x i16> %442, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %444 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %415, <8 x i16> %443) #5
  %445 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %444, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %446 = icmp slt <16 x i8> %445, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %447 = select <16 x i1> %446, <16 x i8> %445, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %448 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %447
  %449 = bitcast i8* %389 to <16 x i8>*
  store <16 x i8> %448, <16 x i8>* %449, align 16
  %450 = getelementptr inbounds i16, i16* %9, i64 112
  %451 = getelementptr inbounds i16, i16* %10, i64 112
  %452 = getelementptr inbounds i8, i8* %263, i64 48
  %453 = bitcast i16* %450 to <8 x i16>*
  %454 = load <8 x i16>, <8 x i16>* %453, align 16
  %455 = bitcast i16* %451 to <8 x i16>*
  %456 = load <8 x i16>, <8 x i16>* %455, align 16
  %457 = shufflevector <8 x i16> %454, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %458 = zext <4 x i16> %457 to <4 x i32>
  %459 = shufflevector <8 x i16> %456, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %460 = zext <4 x i16> %459 to <4 x i32>
  %461 = sub nsw <4 x i32> %458, %460
  %462 = sub nsw <4 x i32> zeroinitializer, %461
  %463 = icmp slt <4 x i32> %461, zeroinitializer
  %464 = select <4 x i1> %463, <4 x i32> %462, <4 x i32> %461
  %465 = add nuw nsw <4 x i32> %464, <i32 32, i32 32, i32 32, i32 32>
  %466 = lshr <4 x i32> %465, <i32 6, i32 6, i32 6, i32 6>
  %467 = shufflevector <8 x i16> %454, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %468 = shufflevector <8 x i16> %456, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %469 = bitcast <8 x i16> %467 to <4 x i32>
  %470 = bitcast <8 x i16> %468 to <4 x i32>
  %471 = sub <4 x i32> %469, %470
  %472 = sub <4 x i32> zeroinitializer, %471
  %473 = icmp slt <4 x i32> %471, zeroinitializer
  %474 = select <4 x i1> %473, <4 x i32> %472, <4 x i32> %471
  %475 = add nuw <4 x i32> %474, <i32 32, i32 32, i32 32, i32 32>
  %476 = lshr <4 x i32> %475, <i32 6, i32 6, i32 6, i32 6>
  %477 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %466, <4 x i32> %476) #5
  %478 = lshr <8 x i16> %477, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %479 = getelementptr inbounds i16, i16* %9, i64 120
  %480 = bitcast i16* %479 to <8 x i16>*
  %481 = load <8 x i16>, <8 x i16>* %480, align 16
  %482 = getelementptr inbounds i16, i16* %10, i64 120
  %483 = bitcast i16* %482 to <8 x i16>*
  %484 = load <8 x i16>, <8 x i16>* %483, align 16
  %485 = shufflevector <8 x i16> %481, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %486 = zext <4 x i16> %485 to <4 x i32>
  %487 = shufflevector <8 x i16> %484, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %488 = zext <4 x i16> %487 to <4 x i32>
  %489 = sub nsw <4 x i32> %486, %488
  %490 = sub nsw <4 x i32> zeroinitializer, %489
  %491 = icmp slt <4 x i32> %489, zeroinitializer
  %492 = select <4 x i1> %491, <4 x i32> %490, <4 x i32> %489
  %493 = add nuw nsw <4 x i32> %492, <i32 32, i32 32, i32 32, i32 32>
  %494 = lshr <4 x i32> %493, <i32 6, i32 6, i32 6, i32 6>
  %495 = shufflevector <8 x i16> %481, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %496 = shufflevector <8 x i16> %484, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %497 = bitcast <8 x i16> %495 to <4 x i32>
  %498 = bitcast <8 x i16> %496 to <4 x i32>
  %499 = sub <4 x i32> %497, %498
  %500 = sub <4 x i32> zeroinitializer, %499
  %501 = icmp slt <4 x i32> %499, zeroinitializer
  %502 = select <4 x i1> %501, <4 x i32> %500, <4 x i32> %499
  %503 = add nuw <4 x i32> %502, <i32 32, i32 32, i32 32, i32 32>
  %504 = lshr <4 x i32> %503, <i32 6, i32 6, i32 6, i32 6>
  %505 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %494, <4 x i32> %504) #5
  %506 = lshr <8 x i16> %505, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %507 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %478, <8 x i16> %506) #5
  %508 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %507, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %509 = icmp slt <16 x i8> %508, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %510 = select <16 x i1> %509, <16 x i8> %508, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %511 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %510
  %512 = bitcast i8* %452 to <16 x i8>*
  store <16 x i8> %511, <16 x i8>* %512, align 16
  %513 = getelementptr inbounds i16, i16* %9, i64 128
  %514 = getelementptr inbounds i16, i16* %10, i64 128
  %515 = getelementptr inbounds i8, i8* %263, i64 %3
  %516 = bitcast i16* %513 to <8 x i16>*
  %517 = load <8 x i16>, <8 x i16>* %516, align 16
  %518 = bitcast i16* %514 to <8 x i16>*
  %519 = load <8 x i16>, <8 x i16>* %518, align 16
  %520 = shufflevector <8 x i16> %517, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %521 = zext <4 x i16> %520 to <4 x i32>
  %522 = shufflevector <8 x i16> %519, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %523 = zext <4 x i16> %522 to <4 x i32>
  %524 = sub nsw <4 x i32> %521, %523
  %525 = sub nsw <4 x i32> zeroinitializer, %524
  %526 = icmp slt <4 x i32> %524, zeroinitializer
  %527 = select <4 x i1> %526, <4 x i32> %525, <4 x i32> %524
  %528 = add nuw nsw <4 x i32> %527, <i32 32, i32 32, i32 32, i32 32>
  %529 = lshr <4 x i32> %528, <i32 6, i32 6, i32 6, i32 6>
  %530 = shufflevector <8 x i16> %517, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %531 = shufflevector <8 x i16> %519, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %532 = bitcast <8 x i16> %530 to <4 x i32>
  %533 = bitcast <8 x i16> %531 to <4 x i32>
  %534 = sub <4 x i32> %532, %533
  %535 = sub <4 x i32> zeroinitializer, %534
  %536 = icmp slt <4 x i32> %534, zeroinitializer
  %537 = select <4 x i1> %536, <4 x i32> %535, <4 x i32> %534
  %538 = add nuw <4 x i32> %537, <i32 32, i32 32, i32 32, i32 32>
  %539 = lshr <4 x i32> %538, <i32 6, i32 6, i32 6, i32 6>
  %540 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %529, <4 x i32> %539) #5
  %541 = lshr <8 x i16> %540, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %542 = getelementptr inbounds i16, i16* %9, i64 136
  %543 = bitcast i16* %542 to <8 x i16>*
  %544 = load <8 x i16>, <8 x i16>* %543, align 16
  %545 = getelementptr inbounds i16, i16* %10, i64 136
  %546 = bitcast i16* %545 to <8 x i16>*
  %547 = load <8 x i16>, <8 x i16>* %546, align 16
  %548 = shufflevector <8 x i16> %544, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %549 = zext <4 x i16> %548 to <4 x i32>
  %550 = shufflevector <8 x i16> %547, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %551 = zext <4 x i16> %550 to <4 x i32>
  %552 = sub nsw <4 x i32> %549, %551
  %553 = sub nsw <4 x i32> zeroinitializer, %552
  %554 = icmp slt <4 x i32> %552, zeroinitializer
  %555 = select <4 x i1> %554, <4 x i32> %553, <4 x i32> %552
  %556 = add nuw nsw <4 x i32> %555, <i32 32, i32 32, i32 32, i32 32>
  %557 = lshr <4 x i32> %556, <i32 6, i32 6, i32 6, i32 6>
  %558 = shufflevector <8 x i16> %544, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %559 = shufflevector <8 x i16> %547, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %560 = bitcast <8 x i16> %558 to <4 x i32>
  %561 = bitcast <8 x i16> %559 to <4 x i32>
  %562 = sub <4 x i32> %560, %561
  %563 = sub <4 x i32> zeroinitializer, %562
  %564 = icmp slt <4 x i32> %562, zeroinitializer
  %565 = select <4 x i1> %564, <4 x i32> %563, <4 x i32> %562
  %566 = add nuw <4 x i32> %565, <i32 32, i32 32, i32 32, i32 32>
  %567 = lshr <4 x i32> %566, <i32 6, i32 6, i32 6, i32 6>
  %568 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %557, <4 x i32> %567) #5
  %569 = lshr <8 x i16> %568, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %570 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %541, <8 x i16> %569) #5
  %571 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %570, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %572 = icmp slt <16 x i8> %571, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %573 = select <16 x i1> %572, <16 x i8> %571, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %574 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %573
  %575 = bitcast i8* %515 to <16 x i8>*
  store <16 x i8> %574, <16 x i8>* %575, align 16
  %576 = getelementptr inbounds i16, i16* %9, i64 144
  %577 = getelementptr inbounds i16, i16* %10, i64 144
  %578 = getelementptr inbounds i8, i8* %515, i64 16
  %579 = bitcast i16* %576 to <8 x i16>*
  %580 = load <8 x i16>, <8 x i16>* %579, align 16
  %581 = bitcast i16* %577 to <8 x i16>*
  %582 = load <8 x i16>, <8 x i16>* %581, align 16
  %583 = shufflevector <8 x i16> %580, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %584 = zext <4 x i16> %583 to <4 x i32>
  %585 = shufflevector <8 x i16> %582, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %586 = zext <4 x i16> %585 to <4 x i32>
  %587 = sub nsw <4 x i32> %584, %586
  %588 = sub nsw <4 x i32> zeroinitializer, %587
  %589 = icmp slt <4 x i32> %587, zeroinitializer
  %590 = select <4 x i1> %589, <4 x i32> %588, <4 x i32> %587
  %591 = add nuw nsw <4 x i32> %590, <i32 32, i32 32, i32 32, i32 32>
  %592 = lshr <4 x i32> %591, <i32 6, i32 6, i32 6, i32 6>
  %593 = shufflevector <8 x i16> %580, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %594 = shufflevector <8 x i16> %582, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %595 = bitcast <8 x i16> %593 to <4 x i32>
  %596 = bitcast <8 x i16> %594 to <4 x i32>
  %597 = sub <4 x i32> %595, %596
  %598 = sub <4 x i32> zeroinitializer, %597
  %599 = icmp slt <4 x i32> %597, zeroinitializer
  %600 = select <4 x i1> %599, <4 x i32> %598, <4 x i32> %597
  %601 = add nuw <4 x i32> %600, <i32 32, i32 32, i32 32, i32 32>
  %602 = lshr <4 x i32> %601, <i32 6, i32 6, i32 6, i32 6>
  %603 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %592, <4 x i32> %602) #5
  %604 = lshr <8 x i16> %603, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %605 = getelementptr inbounds i16, i16* %9, i64 152
  %606 = bitcast i16* %605 to <8 x i16>*
  %607 = load <8 x i16>, <8 x i16>* %606, align 16
  %608 = getelementptr inbounds i16, i16* %10, i64 152
  %609 = bitcast i16* %608 to <8 x i16>*
  %610 = load <8 x i16>, <8 x i16>* %609, align 16
  %611 = shufflevector <8 x i16> %607, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %612 = zext <4 x i16> %611 to <4 x i32>
  %613 = shufflevector <8 x i16> %610, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %614 = zext <4 x i16> %613 to <4 x i32>
  %615 = sub nsw <4 x i32> %612, %614
  %616 = sub nsw <4 x i32> zeroinitializer, %615
  %617 = icmp slt <4 x i32> %615, zeroinitializer
  %618 = select <4 x i1> %617, <4 x i32> %616, <4 x i32> %615
  %619 = add nuw nsw <4 x i32> %618, <i32 32, i32 32, i32 32, i32 32>
  %620 = lshr <4 x i32> %619, <i32 6, i32 6, i32 6, i32 6>
  %621 = shufflevector <8 x i16> %607, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %622 = shufflevector <8 x i16> %610, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %623 = bitcast <8 x i16> %621 to <4 x i32>
  %624 = bitcast <8 x i16> %622 to <4 x i32>
  %625 = sub <4 x i32> %623, %624
  %626 = sub <4 x i32> zeroinitializer, %625
  %627 = icmp slt <4 x i32> %625, zeroinitializer
  %628 = select <4 x i1> %627, <4 x i32> %626, <4 x i32> %625
  %629 = add nuw <4 x i32> %628, <i32 32, i32 32, i32 32, i32 32>
  %630 = lshr <4 x i32> %629, <i32 6, i32 6, i32 6, i32 6>
  %631 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %620, <4 x i32> %630) #5
  %632 = lshr <8 x i16> %631, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %633 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %604, <8 x i16> %632) #5
  %634 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %633, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %635 = icmp slt <16 x i8> %634, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %636 = select <16 x i1> %635, <16 x i8> %634, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %637 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %636
  %638 = bitcast i8* %578 to <16 x i8>*
  store <16 x i8> %637, <16 x i8>* %638, align 16
  %639 = getelementptr inbounds i16, i16* %9, i64 160
  %640 = getelementptr inbounds i16, i16* %10, i64 160
  %641 = getelementptr inbounds i8, i8* %515, i64 32
  %642 = bitcast i16* %639 to <8 x i16>*
  %643 = load <8 x i16>, <8 x i16>* %642, align 16
  %644 = bitcast i16* %640 to <8 x i16>*
  %645 = load <8 x i16>, <8 x i16>* %644, align 16
  %646 = shufflevector <8 x i16> %643, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %647 = zext <4 x i16> %646 to <4 x i32>
  %648 = shufflevector <8 x i16> %645, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %649 = zext <4 x i16> %648 to <4 x i32>
  %650 = sub nsw <4 x i32> %647, %649
  %651 = sub nsw <4 x i32> zeroinitializer, %650
  %652 = icmp slt <4 x i32> %650, zeroinitializer
  %653 = select <4 x i1> %652, <4 x i32> %651, <4 x i32> %650
  %654 = add nuw nsw <4 x i32> %653, <i32 32, i32 32, i32 32, i32 32>
  %655 = lshr <4 x i32> %654, <i32 6, i32 6, i32 6, i32 6>
  %656 = shufflevector <8 x i16> %643, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %657 = shufflevector <8 x i16> %645, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %658 = bitcast <8 x i16> %656 to <4 x i32>
  %659 = bitcast <8 x i16> %657 to <4 x i32>
  %660 = sub <4 x i32> %658, %659
  %661 = sub <4 x i32> zeroinitializer, %660
  %662 = icmp slt <4 x i32> %660, zeroinitializer
  %663 = select <4 x i1> %662, <4 x i32> %661, <4 x i32> %660
  %664 = add nuw <4 x i32> %663, <i32 32, i32 32, i32 32, i32 32>
  %665 = lshr <4 x i32> %664, <i32 6, i32 6, i32 6, i32 6>
  %666 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %655, <4 x i32> %665) #5
  %667 = lshr <8 x i16> %666, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %668 = getelementptr inbounds i16, i16* %9, i64 168
  %669 = bitcast i16* %668 to <8 x i16>*
  %670 = load <8 x i16>, <8 x i16>* %669, align 16
  %671 = getelementptr inbounds i16, i16* %10, i64 168
  %672 = bitcast i16* %671 to <8 x i16>*
  %673 = load <8 x i16>, <8 x i16>* %672, align 16
  %674 = shufflevector <8 x i16> %670, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %675 = zext <4 x i16> %674 to <4 x i32>
  %676 = shufflevector <8 x i16> %673, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %677 = zext <4 x i16> %676 to <4 x i32>
  %678 = sub nsw <4 x i32> %675, %677
  %679 = sub nsw <4 x i32> zeroinitializer, %678
  %680 = icmp slt <4 x i32> %678, zeroinitializer
  %681 = select <4 x i1> %680, <4 x i32> %679, <4 x i32> %678
  %682 = add nuw nsw <4 x i32> %681, <i32 32, i32 32, i32 32, i32 32>
  %683 = lshr <4 x i32> %682, <i32 6, i32 6, i32 6, i32 6>
  %684 = shufflevector <8 x i16> %670, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %685 = shufflevector <8 x i16> %673, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %686 = bitcast <8 x i16> %684 to <4 x i32>
  %687 = bitcast <8 x i16> %685 to <4 x i32>
  %688 = sub <4 x i32> %686, %687
  %689 = sub <4 x i32> zeroinitializer, %688
  %690 = icmp slt <4 x i32> %688, zeroinitializer
  %691 = select <4 x i1> %690, <4 x i32> %689, <4 x i32> %688
  %692 = add nuw <4 x i32> %691, <i32 32, i32 32, i32 32, i32 32>
  %693 = lshr <4 x i32> %692, <i32 6, i32 6, i32 6, i32 6>
  %694 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %683, <4 x i32> %693) #5
  %695 = lshr <8 x i16> %694, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %696 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %667, <8 x i16> %695) #5
  %697 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %696, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %698 = icmp slt <16 x i8> %697, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %699 = select <16 x i1> %698, <16 x i8> %697, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %700 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %699
  %701 = bitcast i8* %641 to <16 x i8>*
  store <16 x i8> %700, <16 x i8>* %701, align 16
  %702 = getelementptr inbounds i16, i16* %9, i64 176
  %703 = getelementptr inbounds i16, i16* %10, i64 176
  %704 = getelementptr inbounds i8, i8* %515, i64 48
  %705 = bitcast i16* %702 to <8 x i16>*
  %706 = load <8 x i16>, <8 x i16>* %705, align 16
  %707 = bitcast i16* %703 to <8 x i16>*
  %708 = load <8 x i16>, <8 x i16>* %707, align 16
  %709 = shufflevector <8 x i16> %706, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %710 = zext <4 x i16> %709 to <4 x i32>
  %711 = shufflevector <8 x i16> %708, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %712 = zext <4 x i16> %711 to <4 x i32>
  %713 = sub nsw <4 x i32> %710, %712
  %714 = sub nsw <4 x i32> zeroinitializer, %713
  %715 = icmp slt <4 x i32> %713, zeroinitializer
  %716 = select <4 x i1> %715, <4 x i32> %714, <4 x i32> %713
  %717 = add nuw nsw <4 x i32> %716, <i32 32, i32 32, i32 32, i32 32>
  %718 = lshr <4 x i32> %717, <i32 6, i32 6, i32 6, i32 6>
  %719 = shufflevector <8 x i16> %706, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %720 = shufflevector <8 x i16> %708, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %721 = bitcast <8 x i16> %719 to <4 x i32>
  %722 = bitcast <8 x i16> %720 to <4 x i32>
  %723 = sub <4 x i32> %721, %722
  %724 = sub <4 x i32> zeroinitializer, %723
  %725 = icmp slt <4 x i32> %723, zeroinitializer
  %726 = select <4 x i1> %725, <4 x i32> %724, <4 x i32> %723
  %727 = add nuw <4 x i32> %726, <i32 32, i32 32, i32 32, i32 32>
  %728 = lshr <4 x i32> %727, <i32 6, i32 6, i32 6, i32 6>
  %729 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %718, <4 x i32> %728) #5
  %730 = lshr <8 x i16> %729, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %731 = getelementptr inbounds i16, i16* %9, i64 184
  %732 = bitcast i16* %731 to <8 x i16>*
  %733 = load <8 x i16>, <8 x i16>* %732, align 16
  %734 = getelementptr inbounds i16, i16* %10, i64 184
  %735 = bitcast i16* %734 to <8 x i16>*
  %736 = load <8 x i16>, <8 x i16>* %735, align 16
  %737 = shufflevector <8 x i16> %733, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %738 = zext <4 x i16> %737 to <4 x i32>
  %739 = shufflevector <8 x i16> %736, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %740 = zext <4 x i16> %739 to <4 x i32>
  %741 = sub nsw <4 x i32> %738, %740
  %742 = sub nsw <4 x i32> zeroinitializer, %741
  %743 = icmp slt <4 x i32> %741, zeroinitializer
  %744 = select <4 x i1> %743, <4 x i32> %742, <4 x i32> %741
  %745 = add nuw nsw <4 x i32> %744, <i32 32, i32 32, i32 32, i32 32>
  %746 = lshr <4 x i32> %745, <i32 6, i32 6, i32 6, i32 6>
  %747 = shufflevector <8 x i16> %733, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %748 = shufflevector <8 x i16> %736, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %749 = bitcast <8 x i16> %747 to <4 x i32>
  %750 = bitcast <8 x i16> %748 to <4 x i32>
  %751 = sub <4 x i32> %749, %750
  %752 = sub <4 x i32> zeroinitializer, %751
  %753 = icmp slt <4 x i32> %751, zeroinitializer
  %754 = select <4 x i1> %753, <4 x i32> %752, <4 x i32> %751
  %755 = add nuw <4 x i32> %754, <i32 32, i32 32, i32 32, i32 32>
  %756 = lshr <4 x i32> %755, <i32 6, i32 6, i32 6, i32 6>
  %757 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %746, <4 x i32> %756) #5
  %758 = lshr <8 x i16> %757, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %759 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %730, <8 x i16> %758) #5
  %760 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %759, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %761 = icmp slt <16 x i8> %760, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %762 = select <16 x i1> %761, <16 x i8> %760, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %763 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %762
  %764 = bitcast i8* %704 to <16 x i8>*
  store <16 x i8> %763, <16 x i8>* %764, align 16
  %765 = getelementptr inbounds i16, i16* %9, i64 192
  %766 = getelementptr inbounds i16, i16* %10, i64 192
  %767 = getelementptr inbounds i8, i8* %515, i64 %3
  %768 = add nsw i32 %11, -1
  %769 = icmp eq i32 %768, 0
  br i1 %769, label %770, label %7

770:                                              ; preds = %7
  %771 = bitcast i16* %765 to <8 x i16>*
  %772 = load <8 x i16>, <8 x i16>* %771, align 16
  %773 = bitcast i16* %766 to <8 x i16>*
  %774 = load <8 x i16>, <8 x i16>* %773, align 16
  %775 = shufflevector <8 x i16> %772, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %776 = zext <4 x i16> %775 to <4 x i32>
  %777 = shufflevector <8 x i16> %774, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %778 = zext <4 x i16> %777 to <4 x i32>
  %779 = sub nsw <4 x i32> %776, %778
  %780 = sub nsw <4 x i32> zeroinitializer, %779
  %781 = icmp slt <4 x i32> %779, zeroinitializer
  %782 = select <4 x i1> %781, <4 x i32> %780, <4 x i32> %779
  %783 = add nuw nsw <4 x i32> %782, <i32 32, i32 32, i32 32, i32 32>
  %784 = lshr <4 x i32> %783, <i32 6, i32 6, i32 6, i32 6>
  %785 = shufflevector <8 x i16> %772, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %786 = shufflevector <8 x i16> %774, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %787 = bitcast <8 x i16> %785 to <4 x i32>
  %788 = bitcast <8 x i16> %786 to <4 x i32>
  %789 = sub <4 x i32> %787, %788
  %790 = sub <4 x i32> zeroinitializer, %789
  %791 = icmp slt <4 x i32> %789, zeroinitializer
  %792 = select <4 x i1> %791, <4 x i32> %790, <4 x i32> %789
  %793 = add nuw <4 x i32> %792, <i32 32, i32 32, i32 32, i32 32>
  %794 = lshr <4 x i32> %793, <i32 6, i32 6, i32 6, i32 6>
  %795 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %784, <4 x i32> %794) #5
  %796 = lshr <8 x i16> %795, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %797 = getelementptr inbounds i16, i16* %9, i64 200
  %798 = bitcast i16* %797 to <8 x i16>*
  %799 = load <8 x i16>, <8 x i16>* %798, align 16
  %800 = getelementptr inbounds i16, i16* %10, i64 200
  %801 = bitcast i16* %800 to <8 x i16>*
  %802 = load <8 x i16>, <8 x i16>* %801, align 16
  %803 = shufflevector <8 x i16> %799, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %804 = zext <4 x i16> %803 to <4 x i32>
  %805 = shufflevector <8 x i16> %802, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %806 = zext <4 x i16> %805 to <4 x i32>
  %807 = sub nsw <4 x i32> %804, %806
  %808 = sub nsw <4 x i32> zeroinitializer, %807
  %809 = icmp slt <4 x i32> %807, zeroinitializer
  %810 = select <4 x i1> %809, <4 x i32> %808, <4 x i32> %807
  %811 = add nuw nsw <4 x i32> %810, <i32 32, i32 32, i32 32, i32 32>
  %812 = lshr <4 x i32> %811, <i32 6, i32 6, i32 6, i32 6>
  %813 = shufflevector <8 x i16> %799, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %814 = shufflevector <8 x i16> %802, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %815 = bitcast <8 x i16> %813 to <4 x i32>
  %816 = bitcast <8 x i16> %814 to <4 x i32>
  %817 = sub <4 x i32> %815, %816
  %818 = sub <4 x i32> zeroinitializer, %817
  %819 = icmp slt <4 x i32> %817, zeroinitializer
  %820 = select <4 x i1> %819, <4 x i32> %818, <4 x i32> %817
  %821 = add nuw <4 x i32> %820, <i32 32, i32 32, i32 32, i32 32>
  %822 = lshr <4 x i32> %821, <i32 6, i32 6, i32 6, i32 6>
  %823 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %812, <4 x i32> %822) #5
  %824 = lshr <8 x i16> %823, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %825 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %796, <8 x i16> %824) #5
  %826 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %825, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %827 = icmp slt <16 x i8> %826, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %828 = select <16 x i1> %827, <16 x i8> %826, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %829 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %828
  %830 = bitcast i8* %767 to <16 x i8>*
  store <16 x i8> %829, <16 x i8>* %830, align 16
  %831 = getelementptr inbounds i16, i16* %9, i64 208
  %832 = getelementptr inbounds i16, i16* %10, i64 208
  %833 = getelementptr inbounds i8, i8* %767, i64 16
  %834 = bitcast i16* %831 to <8 x i16>*
  %835 = load <8 x i16>, <8 x i16>* %834, align 16
  %836 = bitcast i16* %832 to <8 x i16>*
  %837 = load <8 x i16>, <8 x i16>* %836, align 16
  %838 = shufflevector <8 x i16> %835, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %839 = zext <4 x i16> %838 to <4 x i32>
  %840 = shufflevector <8 x i16> %837, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %841 = zext <4 x i16> %840 to <4 x i32>
  %842 = sub nsw <4 x i32> %839, %841
  %843 = sub nsw <4 x i32> zeroinitializer, %842
  %844 = icmp slt <4 x i32> %842, zeroinitializer
  %845 = select <4 x i1> %844, <4 x i32> %843, <4 x i32> %842
  %846 = add nuw nsw <4 x i32> %845, <i32 32, i32 32, i32 32, i32 32>
  %847 = lshr <4 x i32> %846, <i32 6, i32 6, i32 6, i32 6>
  %848 = shufflevector <8 x i16> %835, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %849 = shufflevector <8 x i16> %837, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %850 = bitcast <8 x i16> %848 to <4 x i32>
  %851 = bitcast <8 x i16> %849 to <4 x i32>
  %852 = sub <4 x i32> %850, %851
  %853 = sub <4 x i32> zeroinitializer, %852
  %854 = icmp slt <4 x i32> %852, zeroinitializer
  %855 = select <4 x i1> %854, <4 x i32> %853, <4 x i32> %852
  %856 = add nuw <4 x i32> %855, <i32 32, i32 32, i32 32, i32 32>
  %857 = lshr <4 x i32> %856, <i32 6, i32 6, i32 6, i32 6>
  %858 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %847, <4 x i32> %857) #5
  %859 = lshr <8 x i16> %858, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %860 = getelementptr inbounds i16, i16* %9, i64 216
  %861 = bitcast i16* %860 to <8 x i16>*
  %862 = load <8 x i16>, <8 x i16>* %861, align 16
  %863 = getelementptr inbounds i16, i16* %10, i64 216
  %864 = bitcast i16* %863 to <8 x i16>*
  %865 = load <8 x i16>, <8 x i16>* %864, align 16
  %866 = shufflevector <8 x i16> %862, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %867 = zext <4 x i16> %866 to <4 x i32>
  %868 = shufflevector <8 x i16> %865, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %869 = zext <4 x i16> %868 to <4 x i32>
  %870 = sub nsw <4 x i32> %867, %869
  %871 = sub nsw <4 x i32> zeroinitializer, %870
  %872 = icmp slt <4 x i32> %870, zeroinitializer
  %873 = select <4 x i1> %872, <4 x i32> %871, <4 x i32> %870
  %874 = add nuw nsw <4 x i32> %873, <i32 32, i32 32, i32 32, i32 32>
  %875 = lshr <4 x i32> %874, <i32 6, i32 6, i32 6, i32 6>
  %876 = shufflevector <8 x i16> %862, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %877 = shufflevector <8 x i16> %865, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %878 = bitcast <8 x i16> %876 to <4 x i32>
  %879 = bitcast <8 x i16> %877 to <4 x i32>
  %880 = sub <4 x i32> %878, %879
  %881 = sub <4 x i32> zeroinitializer, %880
  %882 = icmp slt <4 x i32> %880, zeroinitializer
  %883 = select <4 x i1> %882, <4 x i32> %881, <4 x i32> %880
  %884 = add nuw <4 x i32> %883, <i32 32, i32 32, i32 32, i32 32>
  %885 = lshr <4 x i32> %884, <i32 6, i32 6, i32 6, i32 6>
  %886 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %875, <4 x i32> %885) #5
  %887 = lshr <8 x i16> %886, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %888 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %859, <8 x i16> %887) #5
  %889 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %888, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %890 = icmp slt <16 x i8> %889, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %891 = select <16 x i1> %890, <16 x i8> %889, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %892 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %891
  %893 = bitcast i8* %833 to <16 x i8>*
  store <16 x i8> %892, <16 x i8>* %893, align 16
  %894 = getelementptr inbounds i16, i16* %9, i64 224
  %895 = getelementptr inbounds i16, i16* %10, i64 224
  %896 = getelementptr inbounds i8, i8* %767, i64 32
  %897 = bitcast i16* %894 to <8 x i16>*
  %898 = load <8 x i16>, <8 x i16>* %897, align 16
  %899 = bitcast i16* %895 to <8 x i16>*
  %900 = load <8 x i16>, <8 x i16>* %899, align 16
  %901 = shufflevector <8 x i16> %898, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %902 = zext <4 x i16> %901 to <4 x i32>
  %903 = shufflevector <8 x i16> %900, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %904 = zext <4 x i16> %903 to <4 x i32>
  %905 = sub nsw <4 x i32> %902, %904
  %906 = sub nsw <4 x i32> zeroinitializer, %905
  %907 = icmp slt <4 x i32> %905, zeroinitializer
  %908 = select <4 x i1> %907, <4 x i32> %906, <4 x i32> %905
  %909 = add nuw nsw <4 x i32> %908, <i32 32, i32 32, i32 32, i32 32>
  %910 = lshr <4 x i32> %909, <i32 6, i32 6, i32 6, i32 6>
  %911 = shufflevector <8 x i16> %898, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %912 = shufflevector <8 x i16> %900, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %913 = bitcast <8 x i16> %911 to <4 x i32>
  %914 = bitcast <8 x i16> %912 to <4 x i32>
  %915 = sub <4 x i32> %913, %914
  %916 = sub <4 x i32> zeroinitializer, %915
  %917 = icmp slt <4 x i32> %915, zeroinitializer
  %918 = select <4 x i1> %917, <4 x i32> %916, <4 x i32> %915
  %919 = add nuw <4 x i32> %918, <i32 32, i32 32, i32 32, i32 32>
  %920 = lshr <4 x i32> %919, <i32 6, i32 6, i32 6, i32 6>
  %921 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %910, <4 x i32> %920) #5
  %922 = lshr <8 x i16> %921, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %923 = getelementptr inbounds i16, i16* %9, i64 232
  %924 = bitcast i16* %923 to <8 x i16>*
  %925 = load <8 x i16>, <8 x i16>* %924, align 16
  %926 = getelementptr inbounds i16, i16* %10, i64 232
  %927 = bitcast i16* %926 to <8 x i16>*
  %928 = load <8 x i16>, <8 x i16>* %927, align 16
  %929 = shufflevector <8 x i16> %925, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %930 = zext <4 x i16> %929 to <4 x i32>
  %931 = shufflevector <8 x i16> %928, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %932 = zext <4 x i16> %931 to <4 x i32>
  %933 = sub nsw <4 x i32> %930, %932
  %934 = sub nsw <4 x i32> zeroinitializer, %933
  %935 = icmp slt <4 x i32> %933, zeroinitializer
  %936 = select <4 x i1> %935, <4 x i32> %934, <4 x i32> %933
  %937 = add nuw nsw <4 x i32> %936, <i32 32, i32 32, i32 32, i32 32>
  %938 = lshr <4 x i32> %937, <i32 6, i32 6, i32 6, i32 6>
  %939 = shufflevector <8 x i16> %925, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %940 = shufflevector <8 x i16> %928, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %941 = bitcast <8 x i16> %939 to <4 x i32>
  %942 = bitcast <8 x i16> %940 to <4 x i32>
  %943 = sub <4 x i32> %941, %942
  %944 = sub <4 x i32> zeroinitializer, %943
  %945 = icmp slt <4 x i32> %943, zeroinitializer
  %946 = select <4 x i1> %945, <4 x i32> %944, <4 x i32> %943
  %947 = add nuw <4 x i32> %946, <i32 32, i32 32, i32 32, i32 32>
  %948 = lshr <4 x i32> %947, <i32 6, i32 6, i32 6, i32 6>
  %949 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %938, <4 x i32> %948) #5
  %950 = lshr <8 x i16> %949, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %951 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %922, <8 x i16> %950) #5
  %952 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %951, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %953 = icmp slt <16 x i8> %952, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %954 = select <16 x i1> %953, <16 x i8> %952, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %955 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %954
  %956 = bitcast i8* %896 to <16 x i8>*
  store <16 x i8> %955, <16 x i8>* %956, align 16
  %957 = getelementptr inbounds i16, i16* %9, i64 240
  %958 = getelementptr inbounds i16, i16* %10, i64 240
  %959 = getelementptr inbounds i8, i8* %767, i64 48
  %960 = bitcast i16* %957 to <8 x i16>*
  %961 = load <8 x i16>, <8 x i16>* %960, align 16
  %962 = bitcast i16* %958 to <8 x i16>*
  %963 = load <8 x i16>, <8 x i16>* %962, align 16
  %964 = shufflevector <8 x i16> %961, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %965 = zext <4 x i16> %964 to <4 x i32>
  %966 = shufflevector <8 x i16> %963, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %967 = zext <4 x i16> %966 to <4 x i32>
  %968 = sub nsw <4 x i32> %965, %967
  %969 = sub nsw <4 x i32> zeroinitializer, %968
  %970 = icmp slt <4 x i32> %968, zeroinitializer
  %971 = select <4 x i1> %970, <4 x i32> %969, <4 x i32> %968
  %972 = add nuw nsw <4 x i32> %971, <i32 32, i32 32, i32 32, i32 32>
  %973 = lshr <4 x i32> %972, <i32 6, i32 6, i32 6, i32 6>
  %974 = shufflevector <8 x i16> %961, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %975 = shufflevector <8 x i16> %963, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %976 = bitcast <8 x i16> %974 to <4 x i32>
  %977 = bitcast <8 x i16> %975 to <4 x i32>
  %978 = sub <4 x i32> %976, %977
  %979 = sub <4 x i32> zeroinitializer, %978
  %980 = icmp slt <4 x i32> %978, zeroinitializer
  %981 = select <4 x i1> %980, <4 x i32> %979, <4 x i32> %978
  %982 = add nuw <4 x i32> %981, <i32 32, i32 32, i32 32, i32 32>
  %983 = lshr <4 x i32> %982, <i32 6, i32 6, i32 6, i32 6>
  %984 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %973, <4 x i32> %983) #5
  %985 = lshr <8 x i16> %984, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %986 = getelementptr inbounds i16, i16* %9, i64 248
  %987 = bitcast i16* %986 to <8 x i16>*
  %988 = load <8 x i16>, <8 x i16>* %987, align 16
  %989 = getelementptr inbounds i16, i16* %10, i64 248
  %990 = bitcast i16* %989 to <8 x i16>*
  %991 = load <8 x i16>, <8 x i16>* %990, align 16
  %992 = shufflevector <8 x i16> %988, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %993 = zext <4 x i16> %992 to <4 x i32>
  %994 = shufflevector <8 x i16> %991, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %995 = zext <4 x i16> %994 to <4 x i32>
  %996 = sub nsw <4 x i32> %993, %995
  %997 = sub nsw <4 x i32> zeroinitializer, %996
  %998 = icmp slt <4 x i32> %996, zeroinitializer
  %999 = select <4 x i1> %998, <4 x i32> %997, <4 x i32> %996
  %1000 = add nuw nsw <4 x i32> %999, <i32 32, i32 32, i32 32, i32 32>
  %1001 = lshr <4 x i32> %1000, <i32 6, i32 6, i32 6, i32 6>
  %1002 = shufflevector <8 x i16> %988, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1003 = shufflevector <8 x i16> %991, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1004 = bitcast <8 x i16> %1002 to <4 x i32>
  %1005 = bitcast <8 x i16> %1003 to <4 x i32>
  %1006 = sub <4 x i32> %1004, %1005
  %1007 = sub <4 x i32> zeroinitializer, %1006
  %1008 = icmp slt <4 x i32> %1006, zeroinitializer
  %1009 = select <4 x i1> %1008, <4 x i32> %1007, <4 x i32> %1006
  %1010 = add nuw <4 x i32> %1009, <i32 32, i32 32, i32 32, i32 32>
  %1011 = lshr <4 x i32> %1010, <i32 6, i32 6, i32 6, i32 6>
  %1012 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1001, <4 x i32> %1011) #5
  %1013 = lshr <8 x i16> %1012, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1014 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %985, <8 x i16> %1013) #5
  %1015 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1014, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1016 = icmp slt <16 x i8> %1015, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1017 = select <16 x i1> %1016, <16 x i8> %1015, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1018 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1017
  %1019 = bitcast i8* %959 to <16 x i8>*
  store <16 x i8> %1018, <16 x i8>* %1019, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask64x32_10bpp_SSE4ILb0EEEvPKvS5_Phl(i8* readonly, i8* readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %1251, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %1249, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %1250, %7 ]
  %11 = phi i32 [ 6, %4 ], [ %1252, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = shufflevector <8 x i16> %13, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %17 = zext <4 x i16> %16 to <4 x i32>
  %18 = shufflevector <8 x i16> %15, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %19 = zext <4 x i16> %18 to <4 x i32>
  %20 = sub nsw <4 x i32> %17, %19
  %21 = sub nsw <4 x i32> zeroinitializer, %20
  %22 = icmp slt <4 x i32> %20, zeroinitializer
  %23 = select <4 x i1> %22, <4 x i32> %21, <4 x i32> %20
  %24 = add nuw nsw <4 x i32> %23, <i32 32, i32 32, i32 32, i32 32>
  %25 = lshr <4 x i32> %24, <i32 6, i32 6, i32 6, i32 6>
  %26 = shufflevector <8 x i16> %13, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %27 = shufflevector <8 x i16> %15, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %28 = bitcast <8 x i16> %26 to <4 x i32>
  %29 = bitcast <8 x i16> %27 to <4 x i32>
  %30 = sub <4 x i32> %28, %29
  %31 = sub <4 x i32> zeroinitializer, %30
  %32 = icmp slt <4 x i32> %30, zeroinitializer
  %33 = select <4 x i1> %32, <4 x i32> %31, <4 x i32> %30
  %34 = add nuw <4 x i32> %33, <i32 32, i32 32, i32 32, i32 32>
  %35 = lshr <4 x i32> %34, <i32 6, i32 6, i32 6, i32 6>
  %36 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %25, <4 x i32> %35) #5
  %37 = lshr <8 x i16> %36, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %38 = getelementptr inbounds i16, i16* %9, i64 8
  %39 = bitcast i16* %38 to <8 x i16>*
  %40 = load <8 x i16>, <8 x i16>* %39, align 16
  %41 = getelementptr inbounds i16, i16* %10, i64 8
  %42 = bitcast i16* %41 to <8 x i16>*
  %43 = load <8 x i16>, <8 x i16>* %42, align 16
  %44 = shufflevector <8 x i16> %40, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %45 = zext <4 x i16> %44 to <4 x i32>
  %46 = shufflevector <8 x i16> %43, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %47 = zext <4 x i16> %46 to <4 x i32>
  %48 = sub nsw <4 x i32> %45, %47
  %49 = sub nsw <4 x i32> zeroinitializer, %48
  %50 = icmp slt <4 x i32> %48, zeroinitializer
  %51 = select <4 x i1> %50, <4 x i32> %49, <4 x i32> %48
  %52 = add nuw nsw <4 x i32> %51, <i32 32, i32 32, i32 32, i32 32>
  %53 = lshr <4 x i32> %52, <i32 6, i32 6, i32 6, i32 6>
  %54 = shufflevector <8 x i16> %40, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %55 = shufflevector <8 x i16> %43, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %56 = bitcast <8 x i16> %54 to <4 x i32>
  %57 = bitcast <8 x i16> %55 to <4 x i32>
  %58 = sub <4 x i32> %56, %57
  %59 = sub <4 x i32> zeroinitializer, %58
  %60 = icmp slt <4 x i32> %58, zeroinitializer
  %61 = select <4 x i1> %60, <4 x i32> %59, <4 x i32> %58
  %62 = add nuw <4 x i32> %61, <i32 32, i32 32, i32 32, i32 32>
  %63 = lshr <4 x i32> %62, <i32 6, i32 6, i32 6, i32 6>
  %64 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %53, <4 x i32> %63) #5
  %65 = lshr <8 x i16> %64, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %66 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %37, <8 x i16> %65) #5
  %67 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %66, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %68 = icmp slt <16 x i8> %67, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %69 = select <16 x i1> %68, <16 x i8> %67, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %70 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %69, <16 x i8>* %70, align 16
  %71 = getelementptr inbounds i16, i16* %9, i64 16
  %72 = getelementptr inbounds i16, i16* %10, i64 16
  %73 = getelementptr inbounds i8, i8* %8, i64 16
  %74 = bitcast i16* %71 to <8 x i16>*
  %75 = load <8 x i16>, <8 x i16>* %74, align 16
  %76 = bitcast i16* %72 to <8 x i16>*
  %77 = load <8 x i16>, <8 x i16>* %76, align 16
  %78 = shufflevector <8 x i16> %75, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %79 = zext <4 x i16> %78 to <4 x i32>
  %80 = shufflevector <8 x i16> %77, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %81 = zext <4 x i16> %80 to <4 x i32>
  %82 = sub nsw <4 x i32> %79, %81
  %83 = sub nsw <4 x i32> zeroinitializer, %82
  %84 = icmp slt <4 x i32> %82, zeroinitializer
  %85 = select <4 x i1> %84, <4 x i32> %83, <4 x i32> %82
  %86 = add nuw nsw <4 x i32> %85, <i32 32, i32 32, i32 32, i32 32>
  %87 = lshr <4 x i32> %86, <i32 6, i32 6, i32 6, i32 6>
  %88 = shufflevector <8 x i16> %75, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %89 = shufflevector <8 x i16> %77, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %90 = bitcast <8 x i16> %88 to <4 x i32>
  %91 = bitcast <8 x i16> %89 to <4 x i32>
  %92 = sub <4 x i32> %90, %91
  %93 = sub <4 x i32> zeroinitializer, %92
  %94 = icmp slt <4 x i32> %92, zeroinitializer
  %95 = select <4 x i1> %94, <4 x i32> %93, <4 x i32> %92
  %96 = add nuw <4 x i32> %95, <i32 32, i32 32, i32 32, i32 32>
  %97 = lshr <4 x i32> %96, <i32 6, i32 6, i32 6, i32 6>
  %98 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %87, <4 x i32> %97) #5
  %99 = lshr <8 x i16> %98, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %100 = getelementptr inbounds i16, i16* %9, i64 24
  %101 = bitcast i16* %100 to <8 x i16>*
  %102 = load <8 x i16>, <8 x i16>* %101, align 16
  %103 = getelementptr inbounds i16, i16* %10, i64 24
  %104 = bitcast i16* %103 to <8 x i16>*
  %105 = load <8 x i16>, <8 x i16>* %104, align 16
  %106 = shufflevector <8 x i16> %102, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %107 = zext <4 x i16> %106 to <4 x i32>
  %108 = shufflevector <8 x i16> %105, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %109 = zext <4 x i16> %108 to <4 x i32>
  %110 = sub nsw <4 x i32> %107, %109
  %111 = sub nsw <4 x i32> zeroinitializer, %110
  %112 = icmp slt <4 x i32> %110, zeroinitializer
  %113 = select <4 x i1> %112, <4 x i32> %111, <4 x i32> %110
  %114 = add nuw nsw <4 x i32> %113, <i32 32, i32 32, i32 32, i32 32>
  %115 = lshr <4 x i32> %114, <i32 6, i32 6, i32 6, i32 6>
  %116 = shufflevector <8 x i16> %102, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %117 = shufflevector <8 x i16> %105, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %118 = bitcast <8 x i16> %116 to <4 x i32>
  %119 = bitcast <8 x i16> %117 to <4 x i32>
  %120 = sub <4 x i32> %118, %119
  %121 = sub <4 x i32> zeroinitializer, %120
  %122 = icmp slt <4 x i32> %120, zeroinitializer
  %123 = select <4 x i1> %122, <4 x i32> %121, <4 x i32> %120
  %124 = add nuw <4 x i32> %123, <i32 32, i32 32, i32 32, i32 32>
  %125 = lshr <4 x i32> %124, <i32 6, i32 6, i32 6, i32 6>
  %126 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %115, <4 x i32> %125) #5
  %127 = lshr <8 x i16> %126, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %128 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %99, <8 x i16> %127) #5
  %129 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %128, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %130 = icmp slt <16 x i8> %129, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %131 = select <16 x i1> %130, <16 x i8> %129, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %132 = bitcast i8* %73 to <16 x i8>*
  store <16 x i8> %131, <16 x i8>* %132, align 16
  %133 = getelementptr inbounds i16, i16* %9, i64 32
  %134 = getelementptr inbounds i16, i16* %10, i64 32
  %135 = getelementptr inbounds i8, i8* %8, i64 32
  %136 = bitcast i16* %133 to <8 x i16>*
  %137 = load <8 x i16>, <8 x i16>* %136, align 16
  %138 = bitcast i16* %134 to <8 x i16>*
  %139 = load <8 x i16>, <8 x i16>* %138, align 16
  %140 = shufflevector <8 x i16> %137, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %141 = zext <4 x i16> %140 to <4 x i32>
  %142 = shufflevector <8 x i16> %139, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %143 = zext <4 x i16> %142 to <4 x i32>
  %144 = sub nsw <4 x i32> %141, %143
  %145 = sub nsw <4 x i32> zeroinitializer, %144
  %146 = icmp slt <4 x i32> %144, zeroinitializer
  %147 = select <4 x i1> %146, <4 x i32> %145, <4 x i32> %144
  %148 = add nuw nsw <4 x i32> %147, <i32 32, i32 32, i32 32, i32 32>
  %149 = lshr <4 x i32> %148, <i32 6, i32 6, i32 6, i32 6>
  %150 = shufflevector <8 x i16> %137, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %151 = shufflevector <8 x i16> %139, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %152 = bitcast <8 x i16> %150 to <4 x i32>
  %153 = bitcast <8 x i16> %151 to <4 x i32>
  %154 = sub <4 x i32> %152, %153
  %155 = sub <4 x i32> zeroinitializer, %154
  %156 = icmp slt <4 x i32> %154, zeroinitializer
  %157 = select <4 x i1> %156, <4 x i32> %155, <4 x i32> %154
  %158 = add nuw <4 x i32> %157, <i32 32, i32 32, i32 32, i32 32>
  %159 = lshr <4 x i32> %158, <i32 6, i32 6, i32 6, i32 6>
  %160 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %149, <4 x i32> %159) #5
  %161 = lshr <8 x i16> %160, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %162 = getelementptr inbounds i16, i16* %9, i64 40
  %163 = bitcast i16* %162 to <8 x i16>*
  %164 = load <8 x i16>, <8 x i16>* %163, align 16
  %165 = getelementptr inbounds i16, i16* %10, i64 40
  %166 = bitcast i16* %165 to <8 x i16>*
  %167 = load <8 x i16>, <8 x i16>* %166, align 16
  %168 = shufflevector <8 x i16> %164, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %169 = zext <4 x i16> %168 to <4 x i32>
  %170 = shufflevector <8 x i16> %167, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %171 = zext <4 x i16> %170 to <4 x i32>
  %172 = sub nsw <4 x i32> %169, %171
  %173 = sub nsw <4 x i32> zeroinitializer, %172
  %174 = icmp slt <4 x i32> %172, zeroinitializer
  %175 = select <4 x i1> %174, <4 x i32> %173, <4 x i32> %172
  %176 = add nuw nsw <4 x i32> %175, <i32 32, i32 32, i32 32, i32 32>
  %177 = lshr <4 x i32> %176, <i32 6, i32 6, i32 6, i32 6>
  %178 = shufflevector <8 x i16> %164, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %179 = shufflevector <8 x i16> %167, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %180 = bitcast <8 x i16> %178 to <4 x i32>
  %181 = bitcast <8 x i16> %179 to <4 x i32>
  %182 = sub <4 x i32> %180, %181
  %183 = sub <4 x i32> zeroinitializer, %182
  %184 = icmp slt <4 x i32> %182, zeroinitializer
  %185 = select <4 x i1> %184, <4 x i32> %183, <4 x i32> %182
  %186 = add nuw <4 x i32> %185, <i32 32, i32 32, i32 32, i32 32>
  %187 = lshr <4 x i32> %186, <i32 6, i32 6, i32 6, i32 6>
  %188 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %177, <4 x i32> %187) #5
  %189 = lshr <8 x i16> %188, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %190 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %161, <8 x i16> %189) #5
  %191 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %190, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %192 = icmp slt <16 x i8> %191, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %193 = select <16 x i1> %192, <16 x i8> %191, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %194 = bitcast i8* %135 to <16 x i8>*
  store <16 x i8> %193, <16 x i8>* %194, align 16
  %195 = getelementptr inbounds i16, i16* %9, i64 48
  %196 = getelementptr inbounds i16, i16* %10, i64 48
  %197 = getelementptr inbounds i8, i8* %8, i64 48
  %198 = bitcast i16* %195 to <8 x i16>*
  %199 = load <8 x i16>, <8 x i16>* %198, align 16
  %200 = bitcast i16* %196 to <8 x i16>*
  %201 = load <8 x i16>, <8 x i16>* %200, align 16
  %202 = shufflevector <8 x i16> %199, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %203 = zext <4 x i16> %202 to <4 x i32>
  %204 = shufflevector <8 x i16> %201, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %205 = zext <4 x i16> %204 to <4 x i32>
  %206 = sub nsw <4 x i32> %203, %205
  %207 = sub nsw <4 x i32> zeroinitializer, %206
  %208 = icmp slt <4 x i32> %206, zeroinitializer
  %209 = select <4 x i1> %208, <4 x i32> %207, <4 x i32> %206
  %210 = add nuw nsw <4 x i32> %209, <i32 32, i32 32, i32 32, i32 32>
  %211 = lshr <4 x i32> %210, <i32 6, i32 6, i32 6, i32 6>
  %212 = shufflevector <8 x i16> %199, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %213 = shufflevector <8 x i16> %201, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %214 = bitcast <8 x i16> %212 to <4 x i32>
  %215 = bitcast <8 x i16> %213 to <4 x i32>
  %216 = sub <4 x i32> %214, %215
  %217 = sub <4 x i32> zeroinitializer, %216
  %218 = icmp slt <4 x i32> %216, zeroinitializer
  %219 = select <4 x i1> %218, <4 x i32> %217, <4 x i32> %216
  %220 = add nuw <4 x i32> %219, <i32 32, i32 32, i32 32, i32 32>
  %221 = lshr <4 x i32> %220, <i32 6, i32 6, i32 6, i32 6>
  %222 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %211, <4 x i32> %221) #5
  %223 = lshr <8 x i16> %222, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %224 = getelementptr inbounds i16, i16* %9, i64 56
  %225 = bitcast i16* %224 to <8 x i16>*
  %226 = load <8 x i16>, <8 x i16>* %225, align 16
  %227 = getelementptr inbounds i16, i16* %10, i64 56
  %228 = bitcast i16* %227 to <8 x i16>*
  %229 = load <8 x i16>, <8 x i16>* %228, align 16
  %230 = shufflevector <8 x i16> %226, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %231 = zext <4 x i16> %230 to <4 x i32>
  %232 = shufflevector <8 x i16> %229, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %233 = zext <4 x i16> %232 to <4 x i32>
  %234 = sub nsw <4 x i32> %231, %233
  %235 = sub nsw <4 x i32> zeroinitializer, %234
  %236 = icmp slt <4 x i32> %234, zeroinitializer
  %237 = select <4 x i1> %236, <4 x i32> %235, <4 x i32> %234
  %238 = add nuw nsw <4 x i32> %237, <i32 32, i32 32, i32 32, i32 32>
  %239 = lshr <4 x i32> %238, <i32 6, i32 6, i32 6, i32 6>
  %240 = shufflevector <8 x i16> %226, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %241 = shufflevector <8 x i16> %229, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %242 = bitcast <8 x i16> %240 to <4 x i32>
  %243 = bitcast <8 x i16> %241 to <4 x i32>
  %244 = sub <4 x i32> %242, %243
  %245 = sub <4 x i32> zeroinitializer, %244
  %246 = icmp slt <4 x i32> %244, zeroinitializer
  %247 = select <4 x i1> %246, <4 x i32> %245, <4 x i32> %244
  %248 = add nuw <4 x i32> %247, <i32 32, i32 32, i32 32, i32 32>
  %249 = lshr <4 x i32> %248, <i32 6, i32 6, i32 6, i32 6>
  %250 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %239, <4 x i32> %249) #5
  %251 = lshr <8 x i16> %250, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %252 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %223, <8 x i16> %251) #5
  %253 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %252, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %254 = icmp slt <16 x i8> %253, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %255 = select <16 x i1> %254, <16 x i8> %253, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %256 = bitcast i8* %197 to <16 x i8>*
  store <16 x i8> %255, <16 x i8>* %256, align 16
  %257 = getelementptr inbounds i16, i16* %9, i64 64
  %258 = getelementptr inbounds i16, i16* %10, i64 64
  %259 = getelementptr inbounds i8, i8* %8, i64 %3
  %260 = bitcast i16* %257 to <8 x i16>*
  %261 = load <8 x i16>, <8 x i16>* %260, align 16
  %262 = bitcast i16* %258 to <8 x i16>*
  %263 = load <8 x i16>, <8 x i16>* %262, align 16
  %264 = shufflevector <8 x i16> %261, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %265 = zext <4 x i16> %264 to <4 x i32>
  %266 = shufflevector <8 x i16> %263, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %267 = zext <4 x i16> %266 to <4 x i32>
  %268 = sub nsw <4 x i32> %265, %267
  %269 = sub nsw <4 x i32> zeroinitializer, %268
  %270 = icmp slt <4 x i32> %268, zeroinitializer
  %271 = select <4 x i1> %270, <4 x i32> %269, <4 x i32> %268
  %272 = add nuw nsw <4 x i32> %271, <i32 32, i32 32, i32 32, i32 32>
  %273 = lshr <4 x i32> %272, <i32 6, i32 6, i32 6, i32 6>
  %274 = shufflevector <8 x i16> %261, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %275 = shufflevector <8 x i16> %263, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %276 = bitcast <8 x i16> %274 to <4 x i32>
  %277 = bitcast <8 x i16> %275 to <4 x i32>
  %278 = sub <4 x i32> %276, %277
  %279 = sub <4 x i32> zeroinitializer, %278
  %280 = icmp slt <4 x i32> %278, zeroinitializer
  %281 = select <4 x i1> %280, <4 x i32> %279, <4 x i32> %278
  %282 = add nuw <4 x i32> %281, <i32 32, i32 32, i32 32, i32 32>
  %283 = lshr <4 x i32> %282, <i32 6, i32 6, i32 6, i32 6>
  %284 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %273, <4 x i32> %283) #5
  %285 = lshr <8 x i16> %284, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %286 = getelementptr inbounds i16, i16* %9, i64 72
  %287 = bitcast i16* %286 to <8 x i16>*
  %288 = load <8 x i16>, <8 x i16>* %287, align 16
  %289 = getelementptr inbounds i16, i16* %10, i64 72
  %290 = bitcast i16* %289 to <8 x i16>*
  %291 = load <8 x i16>, <8 x i16>* %290, align 16
  %292 = shufflevector <8 x i16> %288, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %293 = zext <4 x i16> %292 to <4 x i32>
  %294 = shufflevector <8 x i16> %291, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %295 = zext <4 x i16> %294 to <4 x i32>
  %296 = sub nsw <4 x i32> %293, %295
  %297 = sub nsw <4 x i32> zeroinitializer, %296
  %298 = icmp slt <4 x i32> %296, zeroinitializer
  %299 = select <4 x i1> %298, <4 x i32> %297, <4 x i32> %296
  %300 = add nuw nsw <4 x i32> %299, <i32 32, i32 32, i32 32, i32 32>
  %301 = lshr <4 x i32> %300, <i32 6, i32 6, i32 6, i32 6>
  %302 = shufflevector <8 x i16> %288, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %303 = shufflevector <8 x i16> %291, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %304 = bitcast <8 x i16> %302 to <4 x i32>
  %305 = bitcast <8 x i16> %303 to <4 x i32>
  %306 = sub <4 x i32> %304, %305
  %307 = sub <4 x i32> zeroinitializer, %306
  %308 = icmp slt <4 x i32> %306, zeroinitializer
  %309 = select <4 x i1> %308, <4 x i32> %307, <4 x i32> %306
  %310 = add nuw <4 x i32> %309, <i32 32, i32 32, i32 32, i32 32>
  %311 = lshr <4 x i32> %310, <i32 6, i32 6, i32 6, i32 6>
  %312 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %301, <4 x i32> %311) #5
  %313 = lshr <8 x i16> %312, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %314 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %285, <8 x i16> %313) #5
  %315 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %314, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %316 = icmp slt <16 x i8> %315, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %317 = select <16 x i1> %316, <16 x i8> %315, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %318 = bitcast i8* %259 to <16 x i8>*
  store <16 x i8> %317, <16 x i8>* %318, align 16
  %319 = getelementptr inbounds i16, i16* %9, i64 80
  %320 = getelementptr inbounds i16, i16* %10, i64 80
  %321 = getelementptr inbounds i8, i8* %259, i64 16
  %322 = bitcast i16* %319 to <8 x i16>*
  %323 = load <8 x i16>, <8 x i16>* %322, align 16
  %324 = bitcast i16* %320 to <8 x i16>*
  %325 = load <8 x i16>, <8 x i16>* %324, align 16
  %326 = shufflevector <8 x i16> %323, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %327 = zext <4 x i16> %326 to <4 x i32>
  %328 = shufflevector <8 x i16> %325, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %329 = zext <4 x i16> %328 to <4 x i32>
  %330 = sub nsw <4 x i32> %327, %329
  %331 = sub nsw <4 x i32> zeroinitializer, %330
  %332 = icmp slt <4 x i32> %330, zeroinitializer
  %333 = select <4 x i1> %332, <4 x i32> %331, <4 x i32> %330
  %334 = add nuw nsw <4 x i32> %333, <i32 32, i32 32, i32 32, i32 32>
  %335 = lshr <4 x i32> %334, <i32 6, i32 6, i32 6, i32 6>
  %336 = shufflevector <8 x i16> %323, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %337 = shufflevector <8 x i16> %325, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %338 = bitcast <8 x i16> %336 to <4 x i32>
  %339 = bitcast <8 x i16> %337 to <4 x i32>
  %340 = sub <4 x i32> %338, %339
  %341 = sub <4 x i32> zeroinitializer, %340
  %342 = icmp slt <4 x i32> %340, zeroinitializer
  %343 = select <4 x i1> %342, <4 x i32> %341, <4 x i32> %340
  %344 = add nuw <4 x i32> %343, <i32 32, i32 32, i32 32, i32 32>
  %345 = lshr <4 x i32> %344, <i32 6, i32 6, i32 6, i32 6>
  %346 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %335, <4 x i32> %345) #5
  %347 = lshr <8 x i16> %346, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %348 = getelementptr inbounds i16, i16* %9, i64 88
  %349 = bitcast i16* %348 to <8 x i16>*
  %350 = load <8 x i16>, <8 x i16>* %349, align 16
  %351 = getelementptr inbounds i16, i16* %10, i64 88
  %352 = bitcast i16* %351 to <8 x i16>*
  %353 = load <8 x i16>, <8 x i16>* %352, align 16
  %354 = shufflevector <8 x i16> %350, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %355 = zext <4 x i16> %354 to <4 x i32>
  %356 = shufflevector <8 x i16> %353, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %357 = zext <4 x i16> %356 to <4 x i32>
  %358 = sub nsw <4 x i32> %355, %357
  %359 = sub nsw <4 x i32> zeroinitializer, %358
  %360 = icmp slt <4 x i32> %358, zeroinitializer
  %361 = select <4 x i1> %360, <4 x i32> %359, <4 x i32> %358
  %362 = add nuw nsw <4 x i32> %361, <i32 32, i32 32, i32 32, i32 32>
  %363 = lshr <4 x i32> %362, <i32 6, i32 6, i32 6, i32 6>
  %364 = shufflevector <8 x i16> %350, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %365 = shufflevector <8 x i16> %353, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %366 = bitcast <8 x i16> %364 to <4 x i32>
  %367 = bitcast <8 x i16> %365 to <4 x i32>
  %368 = sub <4 x i32> %366, %367
  %369 = sub <4 x i32> zeroinitializer, %368
  %370 = icmp slt <4 x i32> %368, zeroinitializer
  %371 = select <4 x i1> %370, <4 x i32> %369, <4 x i32> %368
  %372 = add nuw <4 x i32> %371, <i32 32, i32 32, i32 32, i32 32>
  %373 = lshr <4 x i32> %372, <i32 6, i32 6, i32 6, i32 6>
  %374 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %363, <4 x i32> %373) #5
  %375 = lshr <8 x i16> %374, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %376 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %347, <8 x i16> %375) #5
  %377 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %376, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %378 = icmp slt <16 x i8> %377, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %379 = select <16 x i1> %378, <16 x i8> %377, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %380 = bitcast i8* %321 to <16 x i8>*
  store <16 x i8> %379, <16 x i8>* %380, align 16
  %381 = getelementptr inbounds i16, i16* %9, i64 96
  %382 = getelementptr inbounds i16, i16* %10, i64 96
  %383 = getelementptr inbounds i8, i8* %259, i64 32
  %384 = bitcast i16* %381 to <8 x i16>*
  %385 = load <8 x i16>, <8 x i16>* %384, align 16
  %386 = bitcast i16* %382 to <8 x i16>*
  %387 = load <8 x i16>, <8 x i16>* %386, align 16
  %388 = shufflevector <8 x i16> %385, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %389 = zext <4 x i16> %388 to <4 x i32>
  %390 = shufflevector <8 x i16> %387, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %391 = zext <4 x i16> %390 to <4 x i32>
  %392 = sub nsw <4 x i32> %389, %391
  %393 = sub nsw <4 x i32> zeroinitializer, %392
  %394 = icmp slt <4 x i32> %392, zeroinitializer
  %395 = select <4 x i1> %394, <4 x i32> %393, <4 x i32> %392
  %396 = add nuw nsw <4 x i32> %395, <i32 32, i32 32, i32 32, i32 32>
  %397 = lshr <4 x i32> %396, <i32 6, i32 6, i32 6, i32 6>
  %398 = shufflevector <8 x i16> %385, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %399 = shufflevector <8 x i16> %387, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %400 = bitcast <8 x i16> %398 to <4 x i32>
  %401 = bitcast <8 x i16> %399 to <4 x i32>
  %402 = sub <4 x i32> %400, %401
  %403 = sub <4 x i32> zeroinitializer, %402
  %404 = icmp slt <4 x i32> %402, zeroinitializer
  %405 = select <4 x i1> %404, <4 x i32> %403, <4 x i32> %402
  %406 = add nuw <4 x i32> %405, <i32 32, i32 32, i32 32, i32 32>
  %407 = lshr <4 x i32> %406, <i32 6, i32 6, i32 6, i32 6>
  %408 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %397, <4 x i32> %407) #5
  %409 = lshr <8 x i16> %408, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %410 = getelementptr inbounds i16, i16* %9, i64 104
  %411 = bitcast i16* %410 to <8 x i16>*
  %412 = load <8 x i16>, <8 x i16>* %411, align 16
  %413 = getelementptr inbounds i16, i16* %10, i64 104
  %414 = bitcast i16* %413 to <8 x i16>*
  %415 = load <8 x i16>, <8 x i16>* %414, align 16
  %416 = shufflevector <8 x i16> %412, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %417 = zext <4 x i16> %416 to <4 x i32>
  %418 = shufflevector <8 x i16> %415, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %419 = zext <4 x i16> %418 to <4 x i32>
  %420 = sub nsw <4 x i32> %417, %419
  %421 = sub nsw <4 x i32> zeroinitializer, %420
  %422 = icmp slt <4 x i32> %420, zeroinitializer
  %423 = select <4 x i1> %422, <4 x i32> %421, <4 x i32> %420
  %424 = add nuw nsw <4 x i32> %423, <i32 32, i32 32, i32 32, i32 32>
  %425 = lshr <4 x i32> %424, <i32 6, i32 6, i32 6, i32 6>
  %426 = shufflevector <8 x i16> %412, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %427 = shufflevector <8 x i16> %415, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %428 = bitcast <8 x i16> %426 to <4 x i32>
  %429 = bitcast <8 x i16> %427 to <4 x i32>
  %430 = sub <4 x i32> %428, %429
  %431 = sub <4 x i32> zeroinitializer, %430
  %432 = icmp slt <4 x i32> %430, zeroinitializer
  %433 = select <4 x i1> %432, <4 x i32> %431, <4 x i32> %430
  %434 = add nuw <4 x i32> %433, <i32 32, i32 32, i32 32, i32 32>
  %435 = lshr <4 x i32> %434, <i32 6, i32 6, i32 6, i32 6>
  %436 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %425, <4 x i32> %435) #5
  %437 = lshr <8 x i16> %436, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %438 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %409, <8 x i16> %437) #5
  %439 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %438, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %440 = icmp slt <16 x i8> %439, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %441 = select <16 x i1> %440, <16 x i8> %439, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %442 = bitcast i8* %383 to <16 x i8>*
  store <16 x i8> %441, <16 x i8>* %442, align 16
  %443 = getelementptr inbounds i16, i16* %9, i64 112
  %444 = getelementptr inbounds i16, i16* %10, i64 112
  %445 = getelementptr inbounds i8, i8* %259, i64 48
  %446 = bitcast i16* %443 to <8 x i16>*
  %447 = load <8 x i16>, <8 x i16>* %446, align 16
  %448 = bitcast i16* %444 to <8 x i16>*
  %449 = load <8 x i16>, <8 x i16>* %448, align 16
  %450 = shufflevector <8 x i16> %447, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %451 = zext <4 x i16> %450 to <4 x i32>
  %452 = shufflevector <8 x i16> %449, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %453 = zext <4 x i16> %452 to <4 x i32>
  %454 = sub nsw <4 x i32> %451, %453
  %455 = sub nsw <4 x i32> zeroinitializer, %454
  %456 = icmp slt <4 x i32> %454, zeroinitializer
  %457 = select <4 x i1> %456, <4 x i32> %455, <4 x i32> %454
  %458 = add nuw nsw <4 x i32> %457, <i32 32, i32 32, i32 32, i32 32>
  %459 = lshr <4 x i32> %458, <i32 6, i32 6, i32 6, i32 6>
  %460 = shufflevector <8 x i16> %447, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %461 = shufflevector <8 x i16> %449, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %462 = bitcast <8 x i16> %460 to <4 x i32>
  %463 = bitcast <8 x i16> %461 to <4 x i32>
  %464 = sub <4 x i32> %462, %463
  %465 = sub <4 x i32> zeroinitializer, %464
  %466 = icmp slt <4 x i32> %464, zeroinitializer
  %467 = select <4 x i1> %466, <4 x i32> %465, <4 x i32> %464
  %468 = add nuw <4 x i32> %467, <i32 32, i32 32, i32 32, i32 32>
  %469 = lshr <4 x i32> %468, <i32 6, i32 6, i32 6, i32 6>
  %470 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %459, <4 x i32> %469) #5
  %471 = lshr <8 x i16> %470, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %472 = getelementptr inbounds i16, i16* %9, i64 120
  %473 = bitcast i16* %472 to <8 x i16>*
  %474 = load <8 x i16>, <8 x i16>* %473, align 16
  %475 = getelementptr inbounds i16, i16* %10, i64 120
  %476 = bitcast i16* %475 to <8 x i16>*
  %477 = load <8 x i16>, <8 x i16>* %476, align 16
  %478 = shufflevector <8 x i16> %474, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %479 = zext <4 x i16> %478 to <4 x i32>
  %480 = shufflevector <8 x i16> %477, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %481 = zext <4 x i16> %480 to <4 x i32>
  %482 = sub nsw <4 x i32> %479, %481
  %483 = sub nsw <4 x i32> zeroinitializer, %482
  %484 = icmp slt <4 x i32> %482, zeroinitializer
  %485 = select <4 x i1> %484, <4 x i32> %483, <4 x i32> %482
  %486 = add nuw nsw <4 x i32> %485, <i32 32, i32 32, i32 32, i32 32>
  %487 = lshr <4 x i32> %486, <i32 6, i32 6, i32 6, i32 6>
  %488 = shufflevector <8 x i16> %474, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %489 = shufflevector <8 x i16> %477, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %490 = bitcast <8 x i16> %488 to <4 x i32>
  %491 = bitcast <8 x i16> %489 to <4 x i32>
  %492 = sub <4 x i32> %490, %491
  %493 = sub <4 x i32> zeroinitializer, %492
  %494 = icmp slt <4 x i32> %492, zeroinitializer
  %495 = select <4 x i1> %494, <4 x i32> %493, <4 x i32> %492
  %496 = add nuw <4 x i32> %495, <i32 32, i32 32, i32 32, i32 32>
  %497 = lshr <4 x i32> %496, <i32 6, i32 6, i32 6, i32 6>
  %498 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %487, <4 x i32> %497) #5
  %499 = lshr <8 x i16> %498, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %500 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %471, <8 x i16> %499) #5
  %501 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %500, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %502 = icmp slt <16 x i8> %501, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %503 = select <16 x i1> %502, <16 x i8> %501, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %504 = bitcast i8* %445 to <16 x i8>*
  store <16 x i8> %503, <16 x i8>* %504, align 16
  %505 = getelementptr inbounds i16, i16* %9, i64 128
  %506 = getelementptr inbounds i16, i16* %10, i64 128
  %507 = getelementptr inbounds i8, i8* %259, i64 %3
  %508 = bitcast i16* %505 to <8 x i16>*
  %509 = load <8 x i16>, <8 x i16>* %508, align 16
  %510 = bitcast i16* %506 to <8 x i16>*
  %511 = load <8 x i16>, <8 x i16>* %510, align 16
  %512 = shufflevector <8 x i16> %509, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %513 = zext <4 x i16> %512 to <4 x i32>
  %514 = shufflevector <8 x i16> %511, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %515 = zext <4 x i16> %514 to <4 x i32>
  %516 = sub nsw <4 x i32> %513, %515
  %517 = sub nsw <4 x i32> zeroinitializer, %516
  %518 = icmp slt <4 x i32> %516, zeroinitializer
  %519 = select <4 x i1> %518, <4 x i32> %517, <4 x i32> %516
  %520 = add nuw nsw <4 x i32> %519, <i32 32, i32 32, i32 32, i32 32>
  %521 = lshr <4 x i32> %520, <i32 6, i32 6, i32 6, i32 6>
  %522 = shufflevector <8 x i16> %509, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %523 = shufflevector <8 x i16> %511, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %524 = bitcast <8 x i16> %522 to <4 x i32>
  %525 = bitcast <8 x i16> %523 to <4 x i32>
  %526 = sub <4 x i32> %524, %525
  %527 = sub <4 x i32> zeroinitializer, %526
  %528 = icmp slt <4 x i32> %526, zeroinitializer
  %529 = select <4 x i1> %528, <4 x i32> %527, <4 x i32> %526
  %530 = add nuw <4 x i32> %529, <i32 32, i32 32, i32 32, i32 32>
  %531 = lshr <4 x i32> %530, <i32 6, i32 6, i32 6, i32 6>
  %532 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %521, <4 x i32> %531) #5
  %533 = lshr <8 x i16> %532, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %534 = getelementptr inbounds i16, i16* %9, i64 136
  %535 = bitcast i16* %534 to <8 x i16>*
  %536 = load <8 x i16>, <8 x i16>* %535, align 16
  %537 = getelementptr inbounds i16, i16* %10, i64 136
  %538 = bitcast i16* %537 to <8 x i16>*
  %539 = load <8 x i16>, <8 x i16>* %538, align 16
  %540 = shufflevector <8 x i16> %536, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %541 = zext <4 x i16> %540 to <4 x i32>
  %542 = shufflevector <8 x i16> %539, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %543 = zext <4 x i16> %542 to <4 x i32>
  %544 = sub nsw <4 x i32> %541, %543
  %545 = sub nsw <4 x i32> zeroinitializer, %544
  %546 = icmp slt <4 x i32> %544, zeroinitializer
  %547 = select <4 x i1> %546, <4 x i32> %545, <4 x i32> %544
  %548 = add nuw nsw <4 x i32> %547, <i32 32, i32 32, i32 32, i32 32>
  %549 = lshr <4 x i32> %548, <i32 6, i32 6, i32 6, i32 6>
  %550 = shufflevector <8 x i16> %536, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %551 = shufflevector <8 x i16> %539, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %552 = bitcast <8 x i16> %550 to <4 x i32>
  %553 = bitcast <8 x i16> %551 to <4 x i32>
  %554 = sub <4 x i32> %552, %553
  %555 = sub <4 x i32> zeroinitializer, %554
  %556 = icmp slt <4 x i32> %554, zeroinitializer
  %557 = select <4 x i1> %556, <4 x i32> %555, <4 x i32> %554
  %558 = add nuw <4 x i32> %557, <i32 32, i32 32, i32 32, i32 32>
  %559 = lshr <4 x i32> %558, <i32 6, i32 6, i32 6, i32 6>
  %560 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %549, <4 x i32> %559) #5
  %561 = lshr <8 x i16> %560, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %562 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %533, <8 x i16> %561) #5
  %563 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %562, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %564 = icmp slt <16 x i8> %563, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %565 = select <16 x i1> %564, <16 x i8> %563, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %566 = bitcast i8* %507 to <16 x i8>*
  store <16 x i8> %565, <16 x i8>* %566, align 16
  %567 = getelementptr inbounds i16, i16* %9, i64 144
  %568 = getelementptr inbounds i16, i16* %10, i64 144
  %569 = getelementptr inbounds i8, i8* %507, i64 16
  %570 = bitcast i16* %567 to <8 x i16>*
  %571 = load <8 x i16>, <8 x i16>* %570, align 16
  %572 = bitcast i16* %568 to <8 x i16>*
  %573 = load <8 x i16>, <8 x i16>* %572, align 16
  %574 = shufflevector <8 x i16> %571, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %575 = zext <4 x i16> %574 to <4 x i32>
  %576 = shufflevector <8 x i16> %573, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %577 = zext <4 x i16> %576 to <4 x i32>
  %578 = sub nsw <4 x i32> %575, %577
  %579 = sub nsw <4 x i32> zeroinitializer, %578
  %580 = icmp slt <4 x i32> %578, zeroinitializer
  %581 = select <4 x i1> %580, <4 x i32> %579, <4 x i32> %578
  %582 = add nuw nsw <4 x i32> %581, <i32 32, i32 32, i32 32, i32 32>
  %583 = lshr <4 x i32> %582, <i32 6, i32 6, i32 6, i32 6>
  %584 = shufflevector <8 x i16> %571, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %585 = shufflevector <8 x i16> %573, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %586 = bitcast <8 x i16> %584 to <4 x i32>
  %587 = bitcast <8 x i16> %585 to <4 x i32>
  %588 = sub <4 x i32> %586, %587
  %589 = sub <4 x i32> zeroinitializer, %588
  %590 = icmp slt <4 x i32> %588, zeroinitializer
  %591 = select <4 x i1> %590, <4 x i32> %589, <4 x i32> %588
  %592 = add nuw <4 x i32> %591, <i32 32, i32 32, i32 32, i32 32>
  %593 = lshr <4 x i32> %592, <i32 6, i32 6, i32 6, i32 6>
  %594 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %583, <4 x i32> %593) #5
  %595 = lshr <8 x i16> %594, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %596 = getelementptr inbounds i16, i16* %9, i64 152
  %597 = bitcast i16* %596 to <8 x i16>*
  %598 = load <8 x i16>, <8 x i16>* %597, align 16
  %599 = getelementptr inbounds i16, i16* %10, i64 152
  %600 = bitcast i16* %599 to <8 x i16>*
  %601 = load <8 x i16>, <8 x i16>* %600, align 16
  %602 = shufflevector <8 x i16> %598, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %603 = zext <4 x i16> %602 to <4 x i32>
  %604 = shufflevector <8 x i16> %601, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %605 = zext <4 x i16> %604 to <4 x i32>
  %606 = sub nsw <4 x i32> %603, %605
  %607 = sub nsw <4 x i32> zeroinitializer, %606
  %608 = icmp slt <4 x i32> %606, zeroinitializer
  %609 = select <4 x i1> %608, <4 x i32> %607, <4 x i32> %606
  %610 = add nuw nsw <4 x i32> %609, <i32 32, i32 32, i32 32, i32 32>
  %611 = lshr <4 x i32> %610, <i32 6, i32 6, i32 6, i32 6>
  %612 = shufflevector <8 x i16> %598, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %613 = shufflevector <8 x i16> %601, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %614 = bitcast <8 x i16> %612 to <4 x i32>
  %615 = bitcast <8 x i16> %613 to <4 x i32>
  %616 = sub <4 x i32> %614, %615
  %617 = sub <4 x i32> zeroinitializer, %616
  %618 = icmp slt <4 x i32> %616, zeroinitializer
  %619 = select <4 x i1> %618, <4 x i32> %617, <4 x i32> %616
  %620 = add nuw <4 x i32> %619, <i32 32, i32 32, i32 32, i32 32>
  %621 = lshr <4 x i32> %620, <i32 6, i32 6, i32 6, i32 6>
  %622 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %611, <4 x i32> %621) #5
  %623 = lshr <8 x i16> %622, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %624 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %595, <8 x i16> %623) #5
  %625 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %624, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %626 = icmp slt <16 x i8> %625, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %627 = select <16 x i1> %626, <16 x i8> %625, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %628 = bitcast i8* %569 to <16 x i8>*
  store <16 x i8> %627, <16 x i8>* %628, align 16
  %629 = getelementptr inbounds i16, i16* %9, i64 160
  %630 = getelementptr inbounds i16, i16* %10, i64 160
  %631 = getelementptr inbounds i8, i8* %507, i64 32
  %632 = bitcast i16* %629 to <8 x i16>*
  %633 = load <8 x i16>, <8 x i16>* %632, align 16
  %634 = bitcast i16* %630 to <8 x i16>*
  %635 = load <8 x i16>, <8 x i16>* %634, align 16
  %636 = shufflevector <8 x i16> %633, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %637 = zext <4 x i16> %636 to <4 x i32>
  %638 = shufflevector <8 x i16> %635, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %639 = zext <4 x i16> %638 to <4 x i32>
  %640 = sub nsw <4 x i32> %637, %639
  %641 = sub nsw <4 x i32> zeroinitializer, %640
  %642 = icmp slt <4 x i32> %640, zeroinitializer
  %643 = select <4 x i1> %642, <4 x i32> %641, <4 x i32> %640
  %644 = add nuw nsw <4 x i32> %643, <i32 32, i32 32, i32 32, i32 32>
  %645 = lshr <4 x i32> %644, <i32 6, i32 6, i32 6, i32 6>
  %646 = shufflevector <8 x i16> %633, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %647 = shufflevector <8 x i16> %635, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %648 = bitcast <8 x i16> %646 to <4 x i32>
  %649 = bitcast <8 x i16> %647 to <4 x i32>
  %650 = sub <4 x i32> %648, %649
  %651 = sub <4 x i32> zeroinitializer, %650
  %652 = icmp slt <4 x i32> %650, zeroinitializer
  %653 = select <4 x i1> %652, <4 x i32> %651, <4 x i32> %650
  %654 = add nuw <4 x i32> %653, <i32 32, i32 32, i32 32, i32 32>
  %655 = lshr <4 x i32> %654, <i32 6, i32 6, i32 6, i32 6>
  %656 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %645, <4 x i32> %655) #5
  %657 = lshr <8 x i16> %656, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %658 = getelementptr inbounds i16, i16* %9, i64 168
  %659 = bitcast i16* %658 to <8 x i16>*
  %660 = load <8 x i16>, <8 x i16>* %659, align 16
  %661 = getelementptr inbounds i16, i16* %10, i64 168
  %662 = bitcast i16* %661 to <8 x i16>*
  %663 = load <8 x i16>, <8 x i16>* %662, align 16
  %664 = shufflevector <8 x i16> %660, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %665 = zext <4 x i16> %664 to <4 x i32>
  %666 = shufflevector <8 x i16> %663, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %667 = zext <4 x i16> %666 to <4 x i32>
  %668 = sub nsw <4 x i32> %665, %667
  %669 = sub nsw <4 x i32> zeroinitializer, %668
  %670 = icmp slt <4 x i32> %668, zeroinitializer
  %671 = select <4 x i1> %670, <4 x i32> %669, <4 x i32> %668
  %672 = add nuw nsw <4 x i32> %671, <i32 32, i32 32, i32 32, i32 32>
  %673 = lshr <4 x i32> %672, <i32 6, i32 6, i32 6, i32 6>
  %674 = shufflevector <8 x i16> %660, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %675 = shufflevector <8 x i16> %663, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %676 = bitcast <8 x i16> %674 to <4 x i32>
  %677 = bitcast <8 x i16> %675 to <4 x i32>
  %678 = sub <4 x i32> %676, %677
  %679 = sub <4 x i32> zeroinitializer, %678
  %680 = icmp slt <4 x i32> %678, zeroinitializer
  %681 = select <4 x i1> %680, <4 x i32> %679, <4 x i32> %678
  %682 = add nuw <4 x i32> %681, <i32 32, i32 32, i32 32, i32 32>
  %683 = lshr <4 x i32> %682, <i32 6, i32 6, i32 6, i32 6>
  %684 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %673, <4 x i32> %683) #5
  %685 = lshr <8 x i16> %684, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %686 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %657, <8 x i16> %685) #5
  %687 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %686, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %688 = icmp slt <16 x i8> %687, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %689 = select <16 x i1> %688, <16 x i8> %687, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %690 = bitcast i8* %631 to <16 x i8>*
  store <16 x i8> %689, <16 x i8>* %690, align 16
  %691 = getelementptr inbounds i16, i16* %9, i64 176
  %692 = getelementptr inbounds i16, i16* %10, i64 176
  %693 = getelementptr inbounds i8, i8* %507, i64 48
  %694 = bitcast i16* %691 to <8 x i16>*
  %695 = load <8 x i16>, <8 x i16>* %694, align 16
  %696 = bitcast i16* %692 to <8 x i16>*
  %697 = load <8 x i16>, <8 x i16>* %696, align 16
  %698 = shufflevector <8 x i16> %695, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %699 = zext <4 x i16> %698 to <4 x i32>
  %700 = shufflevector <8 x i16> %697, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %701 = zext <4 x i16> %700 to <4 x i32>
  %702 = sub nsw <4 x i32> %699, %701
  %703 = sub nsw <4 x i32> zeroinitializer, %702
  %704 = icmp slt <4 x i32> %702, zeroinitializer
  %705 = select <4 x i1> %704, <4 x i32> %703, <4 x i32> %702
  %706 = add nuw nsw <4 x i32> %705, <i32 32, i32 32, i32 32, i32 32>
  %707 = lshr <4 x i32> %706, <i32 6, i32 6, i32 6, i32 6>
  %708 = shufflevector <8 x i16> %695, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %709 = shufflevector <8 x i16> %697, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %710 = bitcast <8 x i16> %708 to <4 x i32>
  %711 = bitcast <8 x i16> %709 to <4 x i32>
  %712 = sub <4 x i32> %710, %711
  %713 = sub <4 x i32> zeroinitializer, %712
  %714 = icmp slt <4 x i32> %712, zeroinitializer
  %715 = select <4 x i1> %714, <4 x i32> %713, <4 x i32> %712
  %716 = add nuw <4 x i32> %715, <i32 32, i32 32, i32 32, i32 32>
  %717 = lshr <4 x i32> %716, <i32 6, i32 6, i32 6, i32 6>
  %718 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %707, <4 x i32> %717) #5
  %719 = lshr <8 x i16> %718, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %720 = getelementptr inbounds i16, i16* %9, i64 184
  %721 = bitcast i16* %720 to <8 x i16>*
  %722 = load <8 x i16>, <8 x i16>* %721, align 16
  %723 = getelementptr inbounds i16, i16* %10, i64 184
  %724 = bitcast i16* %723 to <8 x i16>*
  %725 = load <8 x i16>, <8 x i16>* %724, align 16
  %726 = shufflevector <8 x i16> %722, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %727 = zext <4 x i16> %726 to <4 x i32>
  %728 = shufflevector <8 x i16> %725, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %729 = zext <4 x i16> %728 to <4 x i32>
  %730 = sub nsw <4 x i32> %727, %729
  %731 = sub nsw <4 x i32> zeroinitializer, %730
  %732 = icmp slt <4 x i32> %730, zeroinitializer
  %733 = select <4 x i1> %732, <4 x i32> %731, <4 x i32> %730
  %734 = add nuw nsw <4 x i32> %733, <i32 32, i32 32, i32 32, i32 32>
  %735 = lshr <4 x i32> %734, <i32 6, i32 6, i32 6, i32 6>
  %736 = shufflevector <8 x i16> %722, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %737 = shufflevector <8 x i16> %725, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %738 = bitcast <8 x i16> %736 to <4 x i32>
  %739 = bitcast <8 x i16> %737 to <4 x i32>
  %740 = sub <4 x i32> %738, %739
  %741 = sub <4 x i32> zeroinitializer, %740
  %742 = icmp slt <4 x i32> %740, zeroinitializer
  %743 = select <4 x i1> %742, <4 x i32> %741, <4 x i32> %740
  %744 = add nuw <4 x i32> %743, <i32 32, i32 32, i32 32, i32 32>
  %745 = lshr <4 x i32> %744, <i32 6, i32 6, i32 6, i32 6>
  %746 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %735, <4 x i32> %745) #5
  %747 = lshr <8 x i16> %746, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %748 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %719, <8 x i16> %747) #5
  %749 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %748, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %750 = icmp slt <16 x i8> %749, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %751 = select <16 x i1> %750, <16 x i8> %749, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %752 = bitcast i8* %693 to <16 x i8>*
  store <16 x i8> %751, <16 x i8>* %752, align 16
  %753 = getelementptr inbounds i16, i16* %9, i64 192
  %754 = getelementptr inbounds i16, i16* %10, i64 192
  %755 = getelementptr inbounds i8, i8* %507, i64 %3
  %756 = bitcast i16* %753 to <8 x i16>*
  %757 = load <8 x i16>, <8 x i16>* %756, align 16
  %758 = bitcast i16* %754 to <8 x i16>*
  %759 = load <8 x i16>, <8 x i16>* %758, align 16
  %760 = shufflevector <8 x i16> %757, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %761 = zext <4 x i16> %760 to <4 x i32>
  %762 = shufflevector <8 x i16> %759, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %763 = zext <4 x i16> %762 to <4 x i32>
  %764 = sub nsw <4 x i32> %761, %763
  %765 = sub nsw <4 x i32> zeroinitializer, %764
  %766 = icmp slt <4 x i32> %764, zeroinitializer
  %767 = select <4 x i1> %766, <4 x i32> %765, <4 x i32> %764
  %768 = add nuw nsw <4 x i32> %767, <i32 32, i32 32, i32 32, i32 32>
  %769 = lshr <4 x i32> %768, <i32 6, i32 6, i32 6, i32 6>
  %770 = shufflevector <8 x i16> %757, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %771 = shufflevector <8 x i16> %759, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %772 = bitcast <8 x i16> %770 to <4 x i32>
  %773 = bitcast <8 x i16> %771 to <4 x i32>
  %774 = sub <4 x i32> %772, %773
  %775 = sub <4 x i32> zeroinitializer, %774
  %776 = icmp slt <4 x i32> %774, zeroinitializer
  %777 = select <4 x i1> %776, <4 x i32> %775, <4 x i32> %774
  %778 = add nuw <4 x i32> %777, <i32 32, i32 32, i32 32, i32 32>
  %779 = lshr <4 x i32> %778, <i32 6, i32 6, i32 6, i32 6>
  %780 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %769, <4 x i32> %779) #5
  %781 = lshr <8 x i16> %780, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %782 = getelementptr inbounds i16, i16* %9, i64 200
  %783 = bitcast i16* %782 to <8 x i16>*
  %784 = load <8 x i16>, <8 x i16>* %783, align 16
  %785 = getelementptr inbounds i16, i16* %10, i64 200
  %786 = bitcast i16* %785 to <8 x i16>*
  %787 = load <8 x i16>, <8 x i16>* %786, align 16
  %788 = shufflevector <8 x i16> %784, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %789 = zext <4 x i16> %788 to <4 x i32>
  %790 = shufflevector <8 x i16> %787, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %791 = zext <4 x i16> %790 to <4 x i32>
  %792 = sub nsw <4 x i32> %789, %791
  %793 = sub nsw <4 x i32> zeroinitializer, %792
  %794 = icmp slt <4 x i32> %792, zeroinitializer
  %795 = select <4 x i1> %794, <4 x i32> %793, <4 x i32> %792
  %796 = add nuw nsw <4 x i32> %795, <i32 32, i32 32, i32 32, i32 32>
  %797 = lshr <4 x i32> %796, <i32 6, i32 6, i32 6, i32 6>
  %798 = shufflevector <8 x i16> %784, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %799 = shufflevector <8 x i16> %787, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %800 = bitcast <8 x i16> %798 to <4 x i32>
  %801 = bitcast <8 x i16> %799 to <4 x i32>
  %802 = sub <4 x i32> %800, %801
  %803 = sub <4 x i32> zeroinitializer, %802
  %804 = icmp slt <4 x i32> %802, zeroinitializer
  %805 = select <4 x i1> %804, <4 x i32> %803, <4 x i32> %802
  %806 = add nuw <4 x i32> %805, <i32 32, i32 32, i32 32, i32 32>
  %807 = lshr <4 x i32> %806, <i32 6, i32 6, i32 6, i32 6>
  %808 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %797, <4 x i32> %807) #5
  %809 = lshr <8 x i16> %808, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %810 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %781, <8 x i16> %809) #5
  %811 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %810, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %812 = icmp slt <16 x i8> %811, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %813 = select <16 x i1> %812, <16 x i8> %811, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %814 = bitcast i8* %755 to <16 x i8>*
  store <16 x i8> %813, <16 x i8>* %814, align 16
  %815 = getelementptr inbounds i16, i16* %9, i64 208
  %816 = getelementptr inbounds i16, i16* %10, i64 208
  %817 = getelementptr inbounds i8, i8* %755, i64 16
  %818 = bitcast i16* %815 to <8 x i16>*
  %819 = load <8 x i16>, <8 x i16>* %818, align 16
  %820 = bitcast i16* %816 to <8 x i16>*
  %821 = load <8 x i16>, <8 x i16>* %820, align 16
  %822 = shufflevector <8 x i16> %819, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %823 = zext <4 x i16> %822 to <4 x i32>
  %824 = shufflevector <8 x i16> %821, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %825 = zext <4 x i16> %824 to <4 x i32>
  %826 = sub nsw <4 x i32> %823, %825
  %827 = sub nsw <4 x i32> zeroinitializer, %826
  %828 = icmp slt <4 x i32> %826, zeroinitializer
  %829 = select <4 x i1> %828, <4 x i32> %827, <4 x i32> %826
  %830 = add nuw nsw <4 x i32> %829, <i32 32, i32 32, i32 32, i32 32>
  %831 = lshr <4 x i32> %830, <i32 6, i32 6, i32 6, i32 6>
  %832 = shufflevector <8 x i16> %819, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %833 = shufflevector <8 x i16> %821, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %834 = bitcast <8 x i16> %832 to <4 x i32>
  %835 = bitcast <8 x i16> %833 to <4 x i32>
  %836 = sub <4 x i32> %834, %835
  %837 = sub <4 x i32> zeroinitializer, %836
  %838 = icmp slt <4 x i32> %836, zeroinitializer
  %839 = select <4 x i1> %838, <4 x i32> %837, <4 x i32> %836
  %840 = add nuw <4 x i32> %839, <i32 32, i32 32, i32 32, i32 32>
  %841 = lshr <4 x i32> %840, <i32 6, i32 6, i32 6, i32 6>
  %842 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %831, <4 x i32> %841) #5
  %843 = lshr <8 x i16> %842, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %844 = getelementptr inbounds i16, i16* %9, i64 216
  %845 = bitcast i16* %844 to <8 x i16>*
  %846 = load <8 x i16>, <8 x i16>* %845, align 16
  %847 = getelementptr inbounds i16, i16* %10, i64 216
  %848 = bitcast i16* %847 to <8 x i16>*
  %849 = load <8 x i16>, <8 x i16>* %848, align 16
  %850 = shufflevector <8 x i16> %846, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %851 = zext <4 x i16> %850 to <4 x i32>
  %852 = shufflevector <8 x i16> %849, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %853 = zext <4 x i16> %852 to <4 x i32>
  %854 = sub nsw <4 x i32> %851, %853
  %855 = sub nsw <4 x i32> zeroinitializer, %854
  %856 = icmp slt <4 x i32> %854, zeroinitializer
  %857 = select <4 x i1> %856, <4 x i32> %855, <4 x i32> %854
  %858 = add nuw nsw <4 x i32> %857, <i32 32, i32 32, i32 32, i32 32>
  %859 = lshr <4 x i32> %858, <i32 6, i32 6, i32 6, i32 6>
  %860 = shufflevector <8 x i16> %846, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %861 = shufflevector <8 x i16> %849, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %862 = bitcast <8 x i16> %860 to <4 x i32>
  %863 = bitcast <8 x i16> %861 to <4 x i32>
  %864 = sub <4 x i32> %862, %863
  %865 = sub <4 x i32> zeroinitializer, %864
  %866 = icmp slt <4 x i32> %864, zeroinitializer
  %867 = select <4 x i1> %866, <4 x i32> %865, <4 x i32> %864
  %868 = add nuw <4 x i32> %867, <i32 32, i32 32, i32 32, i32 32>
  %869 = lshr <4 x i32> %868, <i32 6, i32 6, i32 6, i32 6>
  %870 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %859, <4 x i32> %869) #5
  %871 = lshr <8 x i16> %870, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %872 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %843, <8 x i16> %871) #5
  %873 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %872, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %874 = icmp slt <16 x i8> %873, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %875 = select <16 x i1> %874, <16 x i8> %873, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %876 = bitcast i8* %817 to <16 x i8>*
  store <16 x i8> %875, <16 x i8>* %876, align 16
  %877 = getelementptr inbounds i16, i16* %9, i64 224
  %878 = getelementptr inbounds i16, i16* %10, i64 224
  %879 = getelementptr inbounds i8, i8* %755, i64 32
  %880 = bitcast i16* %877 to <8 x i16>*
  %881 = load <8 x i16>, <8 x i16>* %880, align 16
  %882 = bitcast i16* %878 to <8 x i16>*
  %883 = load <8 x i16>, <8 x i16>* %882, align 16
  %884 = shufflevector <8 x i16> %881, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %885 = zext <4 x i16> %884 to <4 x i32>
  %886 = shufflevector <8 x i16> %883, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %887 = zext <4 x i16> %886 to <4 x i32>
  %888 = sub nsw <4 x i32> %885, %887
  %889 = sub nsw <4 x i32> zeroinitializer, %888
  %890 = icmp slt <4 x i32> %888, zeroinitializer
  %891 = select <4 x i1> %890, <4 x i32> %889, <4 x i32> %888
  %892 = add nuw nsw <4 x i32> %891, <i32 32, i32 32, i32 32, i32 32>
  %893 = lshr <4 x i32> %892, <i32 6, i32 6, i32 6, i32 6>
  %894 = shufflevector <8 x i16> %881, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %895 = shufflevector <8 x i16> %883, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %896 = bitcast <8 x i16> %894 to <4 x i32>
  %897 = bitcast <8 x i16> %895 to <4 x i32>
  %898 = sub <4 x i32> %896, %897
  %899 = sub <4 x i32> zeroinitializer, %898
  %900 = icmp slt <4 x i32> %898, zeroinitializer
  %901 = select <4 x i1> %900, <4 x i32> %899, <4 x i32> %898
  %902 = add nuw <4 x i32> %901, <i32 32, i32 32, i32 32, i32 32>
  %903 = lshr <4 x i32> %902, <i32 6, i32 6, i32 6, i32 6>
  %904 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %893, <4 x i32> %903) #5
  %905 = lshr <8 x i16> %904, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %906 = getelementptr inbounds i16, i16* %9, i64 232
  %907 = bitcast i16* %906 to <8 x i16>*
  %908 = load <8 x i16>, <8 x i16>* %907, align 16
  %909 = getelementptr inbounds i16, i16* %10, i64 232
  %910 = bitcast i16* %909 to <8 x i16>*
  %911 = load <8 x i16>, <8 x i16>* %910, align 16
  %912 = shufflevector <8 x i16> %908, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %913 = zext <4 x i16> %912 to <4 x i32>
  %914 = shufflevector <8 x i16> %911, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %915 = zext <4 x i16> %914 to <4 x i32>
  %916 = sub nsw <4 x i32> %913, %915
  %917 = sub nsw <4 x i32> zeroinitializer, %916
  %918 = icmp slt <4 x i32> %916, zeroinitializer
  %919 = select <4 x i1> %918, <4 x i32> %917, <4 x i32> %916
  %920 = add nuw nsw <4 x i32> %919, <i32 32, i32 32, i32 32, i32 32>
  %921 = lshr <4 x i32> %920, <i32 6, i32 6, i32 6, i32 6>
  %922 = shufflevector <8 x i16> %908, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %923 = shufflevector <8 x i16> %911, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %924 = bitcast <8 x i16> %922 to <4 x i32>
  %925 = bitcast <8 x i16> %923 to <4 x i32>
  %926 = sub <4 x i32> %924, %925
  %927 = sub <4 x i32> zeroinitializer, %926
  %928 = icmp slt <4 x i32> %926, zeroinitializer
  %929 = select <4 x i1> %928, <4 x i32> %927, <4 x i32> %926
  %930 = add nuw <4 x i32> %929, <i32 32, i32 32, i32 32, i32 32>
  %931 = lshr <4 x i32> %930, <i32 6, i32 6, i32 6, i32 6>
  %932 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %921, <4 x i32> %931) #5
  %933 = lshr <8 x i16> %932, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %934 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %905, <8 x i16> %933) #5
  %935 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %934, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %936 = icmp slt <16 x i8> %935, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %937 = select <16 x i1> %936, <16 x i8> %935, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %938 = bitcast i8* %879 to <16 x i8>*
  store <16 x i8> %937, <16 x i8>* %938, align 16
  %939 = getelementptr inbounds i16, i16* %9, i64 240
  %940 = getelementptr inbounds i16, i16* %10, i64 240
  %941 = getelementptr inbounds i8, i8* %755, i64 48
  %942 = bitcast i16* %939 to <8 x i16>*
  %943 = load <8 x i16>, <8 x i16>* %942, align 16
  %944 = bitcast i16* %940 to <8 x i16>*
  %945 = load <8 x i16>, <8 x i16>* %944, align 16
  %946 = shufflevector <8 x i16> %943, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %947 = zext <4 x i16> %946 to <4 x i32>
  %948 = shufflevector <8 x i16> %945, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %949 = zext <4 x i16> %948 to <4 x i32>
  %950 = sub nsw <4 x i32> %947, %949
  %951 = sub nsw <4 x i32> zeroinitializer, %950
  %952 = icmp slt <4 x i32> %950, zeroinitializer
  %953 = select <4 x i1> %952, <4 x i32> %951, <4 x i32> %950
  %954 = add nuw nsw <4 x i32> %953, <i32 32, i32 32, i32 32, i32 32>
  %955 = lshr <4 x i32> %954, <i32 6, i32 6, i32 6, i32 6>
  %956 = shufflevector <8 x i16> %943, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %957 = shufflevector <8 x i16> %945, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %958 = bitcast <8 x i16> %956 to <4 x i32>
  %959 = bitcast <8 x i16> %957 to <4 x i32>
  %960 = sub <4 x i32> %958, %959
  %961 = sub <4 x i32> zeroinitializer, %960
  %962 = icmp slt <4 x i32> %960, zeroinitializer
  %963 = select <4 x i1> %962, <4 x i32> %961, <4 x i32> %960
  %964 = add nuw <4 x i32> %963, <i32 32, i32 32, i32 32, i32 32>
  %965 = lshr <4 x i32> %964, <i32 6, i32 6, i32 6, i32 6>
  %966 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %955, <4 x i32> %965) #5
  %967 = lshr <8 x i16> %966, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %968 = getelementptr inbounds i16, i16* %9, i64 248
  %969 = bitcast i16* %968 to <8 x i16>*
  %970 = load <8 x i16>, <8 x i16>* %969, align 16
  %971 = getelementptr inbounds i16, i16* %10, i64 248
  %972 = bitcast i16* %971 to <8 x i16>*
  %973 = load <8 x i16>, <8 x i16>* %972, align 16
  %974 = shufflevector <8 x i16> %970, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %975 = zext <4 x i16> %974 to <4 x i32>
  %976 = shufflevector <8 x i16> %973, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %977 = zext <4 x i16> %976 to <4 x i32>
  %978 = sub nsw <4 x i32> %975, %977
  %979 = sub nsw <4 x i32> zeroinitializer, %978
  %980 = icmp slt <4 x i32> %978, zeroinitializer
  %981 = select <4 x i1> %980, <4 x i32> %979, <4 x i32> %978
  %982 = add nuw nsw <4 x i32> %981, <i32 32, i32 32, i32 32, i32 32>
  %983 = lshr <4 x i32> %982, <i32 6, i32 6, i32 6, i32 6>
  %984 = shufflevector <8 x i16> %970, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %985 = shufflevector <8 x i16> %973, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %986 = bitcast <8 x i16> %984 to <4 x i32>
  %987 = bitcast <8 x i16> %985 to <4 x i32>
  %988 = sub <4 x i32> %986, %987
  %989 = sub <4 x i32> zeroinitializer, %988
  %990 = icmp slt <4 x i32> %988, zeroinitializer
  %991 = select <4 x i1> %990, <4 x i32> %989, <4 x i32> %988
  %992 = add nuw <4 x i32> %991, <i32 32, i32 32, i32 32, i32 32>
  %993 = lshr <4 x i32> %992, <i32 6, i32 6, i32 6, i32 6>
  %994 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %983, <4 x i32> %993) #5
  %995 = lshr <8 x i16> %994, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %996 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %967, <8 x i16> %995) #5
  %997 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %996, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %998 = icmp slt <16 x i8> %997, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %999 = select <16 x i1> %998, <16 x i8> %997, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1000 = bitcast i8* %941 to <16 x i8>*
  store <16 x i8> %999, <16 x i8>* %1000, align 16
  %1001 = getelementptr inbounds i16, i16* %9, i64 256
  %1002 = getelementptr inbounds i16, i16* %10, i64 256
  %1003 = getelementptr inbounds i8, i8* %755, i64 %3
  %1004 = bitcast i16* %1001 to <8 x i16>*
  %1005 = load <8 x i16>, <8 x i16>* %1004, align 16
  %1006 = bitcast i16* %1002 to <8 x i16>*
  %1007 = load <8 x i16>, <8 x i16>* %1006, align 16
  %1008 = shufflevector <8 x i16> %1005, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1009 = zext <4 x i16> %1008 to <4 x i32>
  %1010 = shufflevector <8 x i16> %1007, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1011 = zext <4 x i16> %1010 to <4 x i32>
  %1012 = sub nsw <4 x i32> %1009, %1011
  %1013 = sub nsw <4 x i32> zeroinitializer, %1012
  %1014 = icmp slt <4 x i32> %1012, zeroinitializer
  %1015 = select <4 x i1> %1014, <4 x i32> %1013, <4 x i32> %1012
  %1016 = add nuw nsw <4 x i32> %1015, <i32 32, i32 32, i32 32, i32 32>
  %1017 = lshr <4 x i32> %1016, <i32 6, i32 6, i32 6, i32 6>
  %1018 = shufflevector <8 x i16> %1005, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1019 = shufflevector <8 x i16> %1007, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1020 = bitcast <8 x i16> %1018 to <4 x i32>
  %1021 = bitcast <8 x i16> %1019 to <4 x i32>
  %1022 = sub <4 x i32> %1020, %1021
  %1023 = sub <4 x i32> zeroinitializer, %1022
  %1024 = icmp slt <4 x i32> %1022, zeroinitializer
  %1025 = select <4 x i1> %1024, <4 x i32> %1023, <4 x i32> %1022
  %1026 = add nuw <4 x i32> %1025, <i32 32, i32 32, i32 32, i32 32>
  %1027 = lshr <4 x i32> %1026, <i32 6, i32 6, i32 6, i32 6>
  %1028 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1017, <4 x i32> %1027) #5
  %1029 = lshr <8 x i16> %1028, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1030 = getelementptr inbounds i16, i16* %9, i64 264
  %1031 = bitcast i16* %1030 to <8 x i16>*
  %1032 = load <8 x i16>, <8 x i16>* %1031, align 16
  %1033 = getelementptr inbounds i16, i16* %10, i64 264
  %1034 = bitcast i16* %1033 to <8 x i16>*
  %1035 = load <8 x i16>, <8 x i16>* %1034, align 16
  %1036 = shufflevector <8 x i16> %1032, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1037 = zext <4 x i16> %1036 to <4 x i32>
  %1038 = shufflevector <8 x i16> %1035, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1039 = zext <4 x i16> %1038 to <4 x i32>
  %1040 = sub nsw <4 x i32> %1037, %1039
  %1041 = sub nsw <4 x i32> zeroinitializer, %1040
  %1042 = icmp slt <4 x i32> %1040, zeroinitializer
  %1043 = select <4 x i1> %1042, <4 x i32> %1041, <4 x i32> %1040
  %1044 = add nuw nsw <4 x i32> %1043, <i32 32, i32 32, i32 32, i32 32>
  %1045 = lshr <4 x i32> %1044, <i32 6, i32 6, i32 6, i32 6>
  %1046 = shufflevector <8 x i16> %1032, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1047 = shufflevector <8 x i16> %1035, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1048 = bitcast <8 x i16> %1046 to <4 x i32>
  %1049 = bitcast <8 x i16> %1047 to <4 x i32>
  %1050 = sub <4 x i32> %1048, %1049
  %1051 = sub <4 x i32> zeroinitializer, %1050
  %1052 = icmp slt <4 x i32> %1050, zeroinitializer
  %1053 = select <4 x i1> %1052, <4 x i32> %1051, <4 x i32> %1050
  %1054 = add nuw <4 x i32> %1053, <i32 32, i32 32, i32 32, i32 32>
  %1055 = lshr <4 x i32> %1054, <i32 6, i32 6, i32 6, i32 6>
  %1056 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1045, <4 x i32> %1055) #5
  %1057 = lshr <8 x i16> %1056, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1058 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1029, <8 x i16> %1057) #5
  %1059 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1058, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1060 = icmp slt <16 x i8> %1059, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1061 = select <16 x i1> %1060, <16 x i8> %1059, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1062 = bitcast i8* %1003 to <16 x i8>*
  store <16 x i8> %1061, <16 x i8>* %1062, align 16
  %1063 = getelementptr inbounds i16, i16* %9, i64 272
  %1064 = getelementptr inbounds i16, i16* %10, i64 272
  %1065 = getelementptr inbounds i8, i8* %1003, i64 16
  %1066 = bitcast i16* %1063 to <8 x i16>*
  %1067 = load <8 x i16>, <8 x i16>* %1066, align 16
  %1068 = bitcast i16* %1064 to <8 x i16>*
  %1069 = load <8 x i16>, <8 x i16>* %1068, align 16
  %1070 = shufflevector <8 x i16> %1067, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1071 = zext <4 x i16> %1070 to <4 x i32>
  %1072 = shufflevector <8 x i16> %1069, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1073 = zext <4 x i16> %1072 to <4 x i32>
  %1074 = sub nsw <4 x i32> %1071, %1073
  %1075 = sub nsw <4 x i32> zeroinitializer, %1074
  %1076 = icmp slt <4 x i32> %1074, zeroinitializer
  %1077 = select <4 x i1> %1076, <4 x i32> %1075, <4 x i32> %1074
  %1078 = add nuw nsw <4 x i32> %1077, <i32 32, i32 32, i32 32, i32 32>
  %1079 = lshr <4 x i32> %1078, <i32 6, i32 6, i32 6, i32 6>
  %1080 = shufflevector <8 x i16> %1067, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1081 = shufflevector <8 x i16> %1069, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1082 = bitcast <8 x i16> %1080 to <4 x i32>
  %1083 = bitcast <8 x i16> %1081 to <4 x i32>
  %1084 = sub <4 x i32> %1082, %1083
  %1085 = sub <4 x i32> zeroinitializer, %1084
  %1086 = icmp slt <4 x i32> %1084, zeroinitializer
  %1087 = select <4 x i1> %1086, <4 x i32> %1085, <4 x i32> %1084
  %1088 = add nuw <4 x i32> %1087, <i32 32, i32 32, i32 32, i32 32>
  %1089 = lshr <4 x i32> %1088, <i32 6, i32 6, i32 6, i32 6>
  %1090 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1079, <4 x i32> %1089) #5
  %1091 = lshr <8 x i16> %1090, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1092 = getelementptr inbounds i16, i16* %9, i64 280
  %1093 = bitcast i16* %1092 to <8 x i16>*
  %1094 = load <8 x i16>, <8 x i16>* %1093, align 16
  %1095 = getelementptr inbounds i16, i16* %10, i64 280
  %1096 = bitcast i16* %1095 to <8 x i16>*
  %1097 = load <8 x i16>, <8 x i16>* %1096, align 16
  %1098 = shufflevector <8 x i16> %1094, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1099 = zext <4 x i16> %1098 to <4 x i32>
  %1100 = shufflevector <8 x i16> %1097, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1101 = zext <4 x i16> %1100 to <4 x i32>
  %1102 = sub nsw <4 x i32> %1099, %1101
  %1103 = sub nsw <4 x i32> zeroinitializer, %1102
  %1104 = icmp slt <4 x i32> %1102, zeroinitializer
  %1105 = select <4 x i1> %1104, <4 x i32> %1103, <4 x i32> %1102
  %1106 = add nuw nsw <4 x i32> %1105, <i32 32, i32 32, i32 32, i32 32>
  %1107 = lshr <4 x i32> %1106, <i32 6, i32 6, i32 6, i32 6>
  %1108 = shufflevector <8 x i16> %1094, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1109 = shufflevector <8 x i16> %1097, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1110 = bitcast <8 x i16> %1108 to <4 x i32>
  %1111 = bitcast <8 x i16> %1109 to <4 x i32>
  %1112 = sub <4 x i32> %1110, %1111
  %1113 = sub <4 x i32> zeroinitializer, %1112
  %1114 = icmp slt <4 x i32> %1112, zeroinitializer
  %1115 = select <4 x i1> %1114, <4 x i32> %1113, <4 x i32> %1112
  %1116 = add nuw <4 x i32> %1115, <i32 32, i32 32, i32 32, i32 32>
  %1117 = lshr <4 x i32> %1116, <i32 6, i32 6, i32 6, i32 6>
  %1118 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1107, <4 x i32> %1117) #5
  %1119 = lshr <8 x i16> %1118, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1120 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1091, <8 x i16> %1119) #5
  %1121 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1120, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1122 = icmp slt <16 x i8> %1121, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1123 = select <16 x i1> %1122, <16 x i8> %1121, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1124 = bitcast i8* %1065 to <16 x i8>*
  store <16 x i8> %1123, <16 x i8>* %1124, align 16
  %1125 = getelementptr inbounds i16, i16* %9, i64 288
  %1126 = getelementptr inbounds i16, i16* %10, i64 288
  %1127 = getelementptr inbounds i8, i8* %1003, i64 32
  %1128 = bitcast i16* %1125 to <8 x i16>*
  %1129 = load <8 x i16>, <8 x i16>* %1128, align 16
  %1130 = bitcast i16* %1126 to <8 x i16>*
  %1131 = load <8 x i16>, <8 x i16>* %1130, align 16
  %1132 = shufflevector <8 x i16> %1129, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1133 = zext <4 x i16> %1132 to <4 x i32>
  %1134 = shufflevector <8 x i16> %1131, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1135 = zext <4 x i16> %1134 to <4 x i32>
  %1136 = sub nsw <4 x i32> %1133, %1135
  %1137 = sub nsw <4 x i32> zeroinitializer, %1136
  %1138 = icmp slt <4 x i32> %1136, zeroinitializer
  %1139 = select <4 x i1> %1138, <4 x i32> %1137, <4 x i32> %1136
  %1140 = add nuw nsw <4 x i32> %1139, <i32 32, i32 32, i32 32, i32 32>
  %1141 = lshr <4 x i32> %1140, <i32 6, i32 6, i32 6, i32 6>
  %1142 = shufflevector <8 x i16> %1129, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1143 = shufflevector <8 x i16> %1131, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1144 = bitcast <8 x i16> %1142 to <4 x i32>
  %1145 = bitcast <8 x i16> %1143 to <4 x i32>
  %1146 = sub <4 x i32> %1144, %1145
  %1147 = sub <4 x i32> zeroinitializer, %1146
  %1148 = icmp slt <4 x i32> %1146, zeroinitializer
  %1149 = select <4 x i1> %1148, <4 x i32> %1147, <4 x i32> %1146
  %1150 = add nuw <4 x i32> %1149, <i32 32, i32 32, i32 32, i32 32>
  %1151 = lshr <4 x i32> %1150, <i32 6, i32 6, i32 6, i32 6>
  %1152 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1141, <4 x i32> %1151) #5
  %1153 = lshr <8 x i16> %1152, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1154 = getelementptr inbounds i16, i16* %9, i64 296
  %1155 = bitcast i16* %1154 to <8 x i16>*
  %1156 = load <8 x i16>, <8 x i16>* %1155, align 16
  %1157 = getelementptr inbounds i16, i16* %10, i64 296
  %1158 = bitcast i16* %1157 to <8 x i16>*
  %1159 = load <8 x i16>, <8 x i16>* %1158, align 16
  %1160 = shufflevector <8 x i16> %1156, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1161 = zext <4 x i16> %1160 to <4 x i32>
  %1162 = shufflevector <8 x i16> %1159, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1163 = zext <4 x i16> %1162 to <4 x i32>
  %1164 = sub nsw <4 x i32> %1161, %1163
  %1165 = sub nsw <4 x i32> zeroinitializer, %1164
  %1166 = icmp slt <4 x i32> %1164, zeroinitializer
  %1167 = select <4 x i1> %1166, <4 x i32> %1165, <4 x i32> %1164
  %1168 = add nuw nsw <4 x i32> %1167, <i32 32, i32 32, i32 32, i32 32>
  %1169 = lshr <4 x i32> %1168, <i32 6, i32 6, i32 6, i32 6>
  %1170 = shufflevector <8 x i16> %1156, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1171 = shufflevector <8 x i16> %1159, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1172 = bitcast <8 x i16> %1170 to <4 x i32>
  %1173 = bitcast <8 x i16> %1171 to <4 x i32>
  %1174 = sub <4 x i32> %1172, %1173
  %1175 = sub <4 x i32> zeroinitializer, %1174
  %1176 = icmp slt <4 x i32> %1174, zeroinitializer
  %1177 = select <4 x i1> %1176, <4 x i32> %1175, <4 x i32> %1174
  %1178 = add nuw <4 x i32> %1177, <i32 32, i32 32, i32 32, i32 32>
  %1179 = lshr <4 x i32> %1178, <i32 6, i32 6, i32 6, i32 6>
  %1180 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1169, <4 x i32> %1179) #5
  %1181 = lshr <8 x i16> %1180, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1182 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1153, <8 x i16> %1181) #5
  %1183 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1182, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1184 = icmp slt <16 x i8> %1183, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1185 = select <16 x i1> %1184, <16 x i8> %1183, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1186 = bitcast i8* %1127 to <16 x i8>*
  store <16 x i8> %1185, <16 x i8>* %1186, align 16
  %1187 = getelementptr inbounds i16, i16* %9, i64 304
  %1188 = getelementptr inbounds i16, i16* %10, i64 304
  %1189 = getelementptr inbounds i8, i8* %1003, i64 48
  %1190 = bitcast i16* %1187 to <8 x i16>*
  %1191 = load <8 x i16>, <8 x i16>* %1190, align 16
  %1192 = bitcast i16* %1188 to <8 x i16>*
  %1193 = load <8 x i16>, <8 x i16>* %1192, align 16
  %1194 = shufflevector <8 x i16> %1191, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1195 = zext <4 x i16> %1194 to <4 x i32>
  %1196 = shufflevector <8 x i16> %1193, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1197 = zext <4 x i16> %1196 to <4 x i32>
  %1198 = sub nsw <4 x i32> %1195, %1197
  %1199 = sub nsw <4 x i32> zeroinitializer, %1198
  %1200 = icmp slt <4 x i32> %1198, zeroinitializer
  %1201 = select <4 x i1> %1200, <4 x i32> %1199, <4 x i32> %1198
  %1202 = add nuw nsw <4 x i32> %1201, <i32 32, i32 32, i32 32, i32 32>
  %1203 = lshr <4 x i32> %1202, <i32 6, i32 6, i32 6, i32 6>
  %1204 = shufflevector <8 x i16> %1191, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1205 = shufflevector <8 x i16> %1193, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1206 = bitcast <8 x i16> %1204 to <4 x i32>
  %1207 = bitcast <8 x i16> %1205 to <4 x i32>
  %1208 = sub <4 x i32> %1206, %1207
  %1209 = sub <4 x i32> zeroinitializer, %1208
  %1210 = icmp slt <4 x i32> %1208, zeroinitializer
  %1211 = select <4 x i1> %1210, <4 x i32> %1209, <4 x i32> %1208
  %1212 = add nuw <4 x i32> %1211, <i32 32, i32 32, i32 32, i32 32>
  %1213 = lshr <4 x i32> %1212, <i32 6, i32 6, i32 6, i32 6>
  %1214 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1203, <4 x i32> %1213) #5
  %1215 = lshr <8 x i16> %1214, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1216 = getelementptr inbounds i16, i16* %9, i64 312
  %1217 = bitcast i16* %1216 to <8 x i16>*
  %1218 = load <8 x i16>, <8 x i16>* %1217, align 16
  %1219 = getelementptr inbounds i16, i16* %10, i64 312
  %1220 = bitcast i16* %1219 to <8 x i16>*
  %1221 = load <8 x i16>, <8 x i16>* %1220, align 16
  %1222 = shufflevector <8 x i16> %1218, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1223 = zext <4 x i16> %1222 to <4 x i32>
  %1224 = shufflevector <8 x i16> %1221, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1225 = zext <4 x i16> %1224 to <4 x i32>
  %1226 = sub nsw <4 x i32> %1223, %1225
  %1227 = sub nsw <4 x i32> zeroinitializer, %1226
  %1228 = icmp slt <4 x i32> %1226, zeroinitializer
  %1229 = select <4 x i1> %1228, <4 x i32> %1227, <4 x i32> %1226
  %1230 = add nuw nsw <4 x i32> %1229, <i32 32, i32 32, i32 32, i32 32>
  %1231 = lshr <4 x i32> %1230, <i32 6, i32 6, i32 6, i32 6>
  %1232 = shufflevector <8 x i16> %1218, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1233 = shufflevector <8 x i16> %1221, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1234 = bitcast <8 x i16> %1232 to <4 x i32>
  %1235 = bitcast <8 x i16> %1233 to <4 x i32>
  %1236 = sub <4 x i32> %1234, %1235
  %1237 = sub <4 x i32> zeroinitializer, %1236
  %1238 = icmp slt <4 x i32> %1236, zeroinitializer
  %1239 = select <4 x i1> %1238, <4 x i32> %1237, <4 x i32> %1236
  %1240 = add nuw <4 x i32> %1239, <i32 32, i32 32, i32 32, i32 32>
  %1241 = lshr <4 x i32> %1240, <i32 6, i32 6, i32 6, i32 6>
  %1242 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1231, <4 x i32> %1241) #5
  %1243 = lshr <8 x i16> %1242, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1244 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1215, <8 x i16> %1243) #5
  %1245 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1244, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1246 = icmp slt <16 x i8> %1245, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1247 = select <16 x i1> %1246, <16 x i8> %1245, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1248 = bitcast i8* %1189 to <16 x i8>*
  store <16 x i8> %1247, <16 x i8>* %1248, align 16
  %1249 = getelementptr inbounds i16, i16* %9, i64 320
  %1250 = getelementptr inbounds i16, i16* %10, i64 320
  %1251 = getelementptr inbounds i8, i8* %1003, i64 %3
  %1252 = add nsw i32 %11, -1
  %1253 = icmp eq i32 %1252, 0
  br i1 %1253, label %1254, label %7

1254:                                             ; preds = %7
  %1255 = bitcast i16* %1249 to <8 x i16>*
  %1256 = load <8 x i16>, <8 x i16>* %1255, align 16
  %1257 = bitcast i16* %1250 to <8 x i16>*
  %1258 = load <8 x i16>, <8 x i16>* %1257, align 16
  %1259 = shufflevector <8 x i16> %1256, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1260 = zext <4 x i16> %1259 to <4 x i32>
  %1261 = shufflevector <8 x i16> %1258, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1262 = zext <4 x i16> %1261 to <4 x i32>
  %1263 = sub nsw <4 x i32> %1260, %1262
  %1264 = sub nsw <4 x i32> zeroinitializer, %1263
  %1265 = icmp slt <4 x i32> %1263, zeroinitializer
  %1266 = select <4 x i1> %1265, <4 x i32> %1264, <4 x i32> %1263
  %1267 = add nuw nsw <4 x i32> %1266, <i32 32, i32 32, i32 32, i32 32>
  %1268 = lshr <4 x i32> %1267, <i32 6, i32 6, i32 6, i32 6>
  %1269 = shufflevector <8 x i16> %1256, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1270 = shufflevector <8 x i16> %1258, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1271 = bitcast <8 x i16> %1269 to <4 x i32>
  %1272 = bitcast <8 x i16> %1270 to <4 x i32>
  %1273 = sub <4 x i32> %1271, %1272
  %1274 = sub <4 x i32> zeroinitializer, %1273
  %1275 = icmp slt <4 x i32> %1273, zeroinitializer
  %1276 = select <4 x i1> %1275, <4 x i32> %1274, <4 x i32> %1273
  %1277 = add nuw <4 x i32> %1276, <i32 32, i32 32, i32 32, i32 32>
  %1278 = lshr <4 x i32> %1277, <i32 6, i32 6, i32 6, i32 6>
  %1279 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1268, <4 x i32> %1278) #5
  %1280 = lshr <8 x i16> %1279, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1281 = getelementptr inbounds i16, i16* %9, i64 328
  %1282 = bitcast i16* %1281 to <8 x i16>*
  %1283 = load <8 x i16>, <8 x i16>* %1282, align 16
  %1284 = getelementptr inbounds i16, i16* %10, i64 328
  %1285 = bitcast i16* %1284 to <8 x i16>*
  %1286 = load <8 x i16>, <8 x i16>* %1285, align 16
  %1287 = shufflevector <8 x i16> %1283, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1288 = zext <4 x i16> %1287 to <4 x i32>
  %1289 = shufflevector <8 x i16> %1286, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1290 = zext <4 x i16> %1289 to <4 x i32>
  %1291 = sub nsw <4 x i32> %1288, %1290
  %1292 = sub nsw <4 x i32> zeroinitializer, %1291
  %1293 = icmp slt <4 x i32> %1291, zeroinitializer
  %1294 = select <4 x i1> %1293, <4 x i32> %1292, <4 x i32> %1291
  %1295 = add nuw nsw <4 x i32> %1294, <i32 32, i32 32, i32 32, i32 32>
  %1296 = lshr <4 x i32> %1295, <i32 6, i32 6, i32 6, i32 6>
  %1297 = shufflevector <8 x i16> %1283, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1298 = shufflevector <8 x i16> %1286, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1299 = bitcast <8 x i16> %1297 to <4 x i32>
  %1300 = bitcast <8 x i16> %1298 to <4 x i32>
  %1301 = sub <4 x i32> %1299, %1300
  %1302 = sub <4 x i32> zeroinitializer, %1301
  %1303 = icmp slt <4 x i32> %1301, zeroinitializer
  %1304 = select <4 x i1> %1303, <4 x i32> %1302, <4 x i32> %1301
  %1305 = add nuw <4 x i32> %1304, <i32 32, i32 32, i32 32, i32 32>
  %1306 = lshr <4 x i32> %1305, <i32 6, i32 6, i32 6, i32 6>
  %1307 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1296, <4 x i32> %1306) #5
  %1308 = lshr <8 x i16> %1307, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1309 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1280, <8 x i16> %1308) #5
  %1310 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1309, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1311 = icmp slt <16 x i8> %1310, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1312 = select <16 x i1> %1311, <16 x i8> %1310, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1313 = bitcast i8* %1251 to <16 x i8>*
  store <16 x i8> %1312, <16 x i8>* %1313, align 16
  %1314 = getelementptr inbounds i16, i16* %9, i64 336
  %1315 = getelementptr inbounds i16, i16* %10, i64 336
  %1316 = getelementptr inbounds i8, i8* %1251, i64 16
  %1317 = bitcast i16* %1314 to <8 x i16>*
  %1318 = load <8 x i16>, <8 x i16>* %1317, align 16
  %1319 = bitcast i16* %1315 to <8 x i16>*
  %1320 = load <8 x i16>, <8 x i16>* %1319, align 16
  %1321 = shufflevector <8 x i16> %1318, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1322 = zext <4 x i16> %1321 to <4 x i32>
  %1323 = shufflevector <8 x i16> %1320, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1324 = zext <4 x i16> %1323 to <4 x i32>
  %1325 = sub nsw <4 x i32> %1322, %1324
  %1326 = sub nsw <4 x i32> zeroinitializer, %1325
  %1327 = icmp slt <4 x i32> %1325, zeroinitializer
  %1328 = select <4 x i1> %1327, <4 x i32> %1326, <4 x i32> %1325
  %1329 = add nuw nsw <4 x i32> %1328, <i32 32, i32 32, i32 32, i32 32>
  %1330 = lshr <4 x i32> %1329, <i32 6, i32 6, i32 6, i32 6>
  %1331 = shufflevector <8 x i16> %1318, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1332 = shufflevector <8 x i16> %1320, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1333 = bitcast <8 x i16> %1331 to <4 x i32>
  %1334 = bitcast <8 x i16> %1332 to <4 x i32>
  %1335 = sub <4 x i32> %1333, %1334
  %1336 = sub <4 x i32> zeroinitializer, %1335
  %1337 = icmp slt <4 x i32> %1335, zeroinitializer
  %1338 = select <4 x i1> %1337, <4 x i32> %1336, <4 x i32> %1335
  %1339 = add nuw <4 x i32> %1338, <i32 32, i32 32, i32 32, i32 32>
  %1340 = lshr <4 x i32> %1339, <i32 6, i32 6, i32 6, i32 6>
  %1341 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1330, <4 x i32> %1340) #5
  %1342 = lshr <8 x i16> %1341, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1343 = getelementptr inbounds i16, i16* %9, i64 344
  %1344 = bitcast i16* %1343 to <8 x i16>*
  %1345 = load <8 x i16>, <8 x i16>* %1344, align 16
  %1346 = getelementptr inbounds i16, i16* %10, i64 344
  %1347 = bitcast i16* %1346 to <8 x i16>*
  %1348 = load <8 x i16>, <8 x i16>* %1347, align 16
  %1349 = shufflevector <8 x i16> %1345, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1350 = zext <4 x i16> %1349 to <4 x i32>
  %1351 = shufflevector <8 x i16> %1348, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1352 = zext <4 x i16> %1351 to <4 x i32>
  %1353 = sub nsw <4 x i32> %1350, %1352
  %1354 = sub nsw <4 x i32> zeroinitializer, %1353
  %1355 = icmp slt <4 x i32> %1353, zeroinitializer
  %1356 = select <4 x i1> %1355, <4 x i32> %1354, <4 x i32> %1353
  %1357 = add nuw nsw <4 x i32> %1356, <i32 32, i32 32, i32 32, i32 32>
  %1358 = lshr <4 x i32> %1357, <i32 6, i32 6, i32 6, i32 6>
  %1359 = shufflevector <8 x i16> %1345, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1360 = shufflevector <8 x i16> %1348, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1361 = bitcast <8 x i16> %1359 to <4 x i32>
  %1362 = bitcast <8 x i16> %1360 to <4 x i32>
  %1363 = sub <4 x i32> %1361, %1362
  %1364 = sub <4 x i32> zeroinitializer, %1363
  %1365 = icmp slt <4 x i32> %1363, zeroinitializer
  %1366 = select <4 x i1> %1365, <4 x i32> %1364, <4 x i32> %1363
  %1367 = add nuw <4 x i32> %1366, <i32 32, i32 32, i32 32, i32 32>
  %1368 = lshr <4 x i32> %1367, <i32 6, i32 6, i32 6, i32 6>
  %1369 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1358, <4 x i32> %1368) #5
  %1370 = lshr <8 x i16> %1369, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1371 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1342, <8 x i16> %1370) #5
  %1372 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1371, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1373 = icmp slt <16 x i8> %1372, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1374 = select <16 x i1> %1373, <16 x i8> %1372, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1375 = bitcast i8* %1316 to <16 x i8>*
  store <16 x i8> %1374, <16 x i8>* %1375, align 16
  %1376 = getelementptr inbounds i16, i16* %9, i64 352
  %1377 = getelementptr inbounds i16, i16* %10, i64 352
  %1378 = getelementptr inbounds i8, i8* %1251, i64 32
  %1379 = bitcast i16* %1376 to <8 x i16>*
  %1380 = load <8 x i16>, <8 x i16>* %1379, align 16
  %1381 = bitcast i16* %1377 to <8 x i16>*
  %1382 = load <8 x i16>, <8 x i16>* %1381, align 16
  %1383 = shufflevector <8 x i16> %1380, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1384 = zext <4 x i16> %1383 to <4 x i32>
  %1385 = shufflevector <8 x i16> %1382, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1386 = zext <4 x i16> %1385 to <4 x i32>
  %1387 = sub nsw <4 x i32> %1384, %1386
  %1388 = sub nsw <4 x i32> zeroinitializer, %1387
  %1389 = icmp slt <4 x i32> %1387, zeroinitializer
  %1390 = select <4 x i1> %1389, <4 x i32> %1388, <4 x i32> %1387
  %1391 = add nuw nsw <4 x i32> %1390, <i32 32, i32 32, i32 32, i32 32>
  %1392 = lshr <4 x i32> %1391, <i32 6, i32 6, i32 6, i32 6>
  %1393 = shufflevector <8 x i16> %1380, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1394 = shufflevector <8 x i16> %1382, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1395 = bitcast <8 x i16> %1393 to <4 x i32>
  %1396 = bitcast <8 x i16> %1394 to <4 x i32>
  %1397 = sub <4 x i32> %1395, %1396
  %1398 = sub <4 x i32> zeroinitializer, %1397
  %1399 = icmp slt <4 x i32> %1397, zeroinitializer
  %1400 = select <4 x i1> %1399, <4 x i32> %1398, <4 x i32> %1397
  %1401 = add nuw <4 x i32> %1400, <i32 32, i32 32, i32 32, i32 32>
  %1402 = lshr <4 x i32> %1401, <i32 6, i32 6, i32 6, i32 6>
  %1403 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1392, <4 x i32> %1402) #5
  %1404 = lshr <8 x i16> %1403, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1405 = getelementptr inbounds i16, i16* %9, i64 360
  %1406 = bitcast i16* %1405 to <8 x i16>*
  %1407 = load <8 x i16>, <8 x i16>* %1406, align 16
  %1408 = getelementptr inbounds i16, i16* %10, i64 360
  %1409 = bitcast i16* %1408 to <8 x i16>*
  %1410 = load <8 x i16>, <8 x i16>* %1409, align 16
  %1411 = shufflevector <8 x i16> %1407, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1412 = zext <4 x i16> %1411 to <4 x i32>
  %1413 = shufflevector <8 x i16> %1410, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1414 = zext <4 x i16> %1413 to <4 x i32>
  %1415 = sub nsw <4 x i32> %1412, %1414
  %1416 = sub nsw <4 x i32> zeroinitializer, %1415
  %1417 = icmp slt <4 x i32> %1415, zeroinitializer
  %1418 = select <4 x i1> %1417, <4 x i32> %1416, <4 x i32> %1415
  %1419 = add nuw nsw <4 x i32> %1418, <i32 32, i32 32, i32 32, i32 32>
  %1420 = lshr <4 x i32> %1419, <i32 6, i32 6, i32 6, i32 6>
  %1421 = shufflevector <8 x i16> %1407, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1422 = shufflevector <8 x i16> %1410, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1423 = bitcast <8 x i16> %1421 to <4 x i32>
  %1424 = bitcast <8 x i16> %1422 to <4 x i32>
  %1425 = sub <4 x i32> %1423, %1424
  %1426 = sub <4 x i32> zeroinitializer, %1425
  %1427 = icmp slt <4 x i32> %1425, zeroinitializer
  %1428 = select <4 x i1> %1427, <4 x i32> %1426, <4 x i32> %1425
  %1429 = add nuw <4 x i32> %1428, <i32 32, i32 32, i32 32, i32 32>
  %1430 = lshr <4 x i32> %1429, <i32 6, i32 6, i32 6, i32 6>
  %1431 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1420, <4 x i32> %1430) #5
  %1432 = lshr <8 x i16> %1431, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1433 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1404, <8 x i16> %1432) #5
  %1434 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1433, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1435 = icmp slt <16 x i8> %1434, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1436 = select <16 x i1> %1435, <16 x i8> %1434, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1437 = bitcast i8* %1378 to <16 x i8>*
  store <16 x i8> %1436, <16 x i8>* %1437, align 16
  %1438 = getelementptr inbounds i16, i16* %9, i64 368
  %1439 = getelementptr inbounds i16, i16* %10, i64 368
  %1440 = getelementptr inbounds i8, i8* %1251, i64 48
  %1441 = bitcast i16* %1438 to <8 x i16>*
  %1442 = load <8 x i16>, <8 x i16>* %1441, align 16
  %1443 = bitcast i16* %1439 to <8 x i16>*
  %1444 = load <8 x i16>, <8 x i16>* %1443, align 16
  %1445 = shufflevector <8 x i16> %1442, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1446 = zext <4 x i16> %1445 to <4 x i32>
  %1447 = shufflevector <8 x i16> %1444, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1448 = zext <4 x i16> %1447 to <4 x i32>
  %1449 = sub nsw <4 x i32> %1446, %1448
  %1450 = sub nsw <4 x i32> zeroinitializer, %1449
  %1451 = icmp slt <4 x i32> %1449, zeroinitializer
  %1452 = select <4 x i1> %1451, <4 x i32> %1450, <4 x i32> %1449
  %1453 = add nuw nsw <4 x i32> %1452, <i32 32, i32 32, i32 32, i32 32>
  %1454 = lshr <4 x i32> %1453, <i32 6, i32 6, i32 6, i32 6>
  %1455 = shufflevector <8 x i16> %1442, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1456 = shufflevector <8 x i16> %1444, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1457 = bitcast <8 x i16> %1455 to <4 x i32>
  %1458 = bitcast <8 x i16> %1456 to <4 x i32>
  %1459 = sub <4 x i32> %1457, %1458
  %1460 = sub <4 x i32> zeroinitializer, %1459
  %1461 = icmp slt <4 x i32> %1459, zeroinitializer
  %1462 = select <4 x i1> %1461, <4 x i32> %1460, <4 x i32> %1459
  %1463 = add nuw <4 x i32> %1462, <i32 32, i32 32, i32 32, i32 32>
  %1464 = lshr <4 x i32> %1463, <i32 6, i32 6, i32 6, i32 6>
  %1465 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1454, <4 x i32> %1464) #5
  %1466 = lshr <8 x i16> %1465, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1467 = getelementptr inbounds i16, i16* %9, i64 376
  %1468 = bitcast i16* %1467 to <8 x i16>*
  %1469 = load <8 x i16>, <8 x i16>* %1468, align 16
  %1470 = getelementptr inbounds i16, i16* %10, i64 376
  %1471 = bitcast i16* %1470 to <8 x i16>*
  %1472 = load <8 x i16>, <8 x i16>* %1471, align 16
  %1473 = shufflevector <8 x i16> %1469, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1474 = zext <4 x i16> %1473 to <4 x i32>
  %1475 = shufflevector <8 x i16> %1472, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1476 = zext <4 x i16> %1475 to <4 x i32>
  %1477 = sub nsw <4 x i32> %1474, %1476
  %1478 = sub nsw <4 x i32> zeroinitializer, %1477
  %1479 = icmp slt <4 x i32> %1477, zeroinitializer
  %1480 = select <4 x i1> %1479, <4 x i32> %1478, <4 x i32> %1477
  %1481 = add nuw nsw <4 x i32> %1480, <i32 32, i32 32, i32 32, i32 32>
  %1482 = lshr <4 x i32> %1481, <i32 6, i32 6, i32 6, i32 6>
  %1483 = shufflevector <8 x i16> %1469, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1484 = shufflevector <8 x i16> %1472, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1485 = bitcast <8 x i16> %1483 to <4 x i32>
  %1486 = bitcast <8 x i16> %1484 to <4 x i32>
  %1487 = sub <4 x i32> %1485, %1486
  %1488 = sub <4 x i32> zeroinitializer, %1487
  %1489 = icmp slt <4 x i32> %1487, zeroinitializer
  %1490 = select <4 x i1> %1489, <4 x i32> %1488, <4 x i32> %1487
  %1491 = add nuw <4 x i32> %1490, <i32 32, i32 32, i32 32, i32 32>
  %1492 = lshr <4 x i32> %1491, <i32 6, i32 6, i32 6, i32 6>
  %1493 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1482, <4 x i32> %1492) #5
  %1494 = lshr <8 x i16> %1493, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1495 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1466, <8 x i16> %1494) #5
  %1496 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1495, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1497 = icmp slt <16 x i8> %1496, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1498 = select <16 x i1> %1497, <16 x i8> %1496, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1499 = bitcast i8* %1440 to <16 x i8>*
  store <16 x i8> %1498, <16 x i8>* %1499, align 16
  %1500 = getelementptr inbounds i16, i16* %9, i64 384
  %1501 = getelementptr inbounds i16, i16* %10, i64 384
  %1502 = getelementptr inbounds i8, i8* %1251, i64 %3
  %1503 = bitcast i16* %1500 to <8 x i16>*
  %1504 = load <8 x i16>, <8 x i16>* %1503, align 16
  %1505 = bitcast i16* %1501 to <8 x i16>*
  %1506 = load <8 x i16>, <8 x i16>* %1505, align 16
  %1507 = shufflevector <8 x i16> %1504, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1508 = zext <4 x i16> %1507 to <4 x i32>
  %1509 = shufflevector <8 x i16> %1506, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1510 = zext <4 x i16> %1509 to <4 x i32>
  %1511 = sub nsw <4 x i32> %1508, %1510
  %1512 = sub nsw <4 x i32> zeroinitializer, %1511
  %1513 = icmp slt <4 x i32> %1511, zeroinitializer
  %1514 = select <4 x i1> %1513, <4 x i32> %1512, <4 x i32> %1511
  %1515 = add nuw nsw <4 x i32> %1514, <i32 32, i32 32, i32 32, i32 32>
  %1516 = lshr <4 x i32> %1515, <i32 6, i32 6, i32 6, i32 6>
  %1517 = shufflevector <8 x i16> %1504, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1518 = shufflevector <8 x i16> %1506, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1519 = bitcast <8 x i16> %1517 to <4 x i32>
  %1520 = bitcast <8 x i16> %1518 to <4 x i32>
  %1521 = sub <4 x i32> %1519, %1520
  %1522 = sub <4 x i32> zeroinitializer, %1521
  %1523 = icmp slt <4 x i32> %1521, zeroinitializer
  %1524 = select <4 x i1> %1523, <4 x i32> %1522, <4 x i32> %1521
  %1525 = add nuw <4 x i32> %1524, <i32 32, i32 32, i32 32, i32 32>
  %1526 = lshr <4 x i32> %1525, <i32 6, i32 6, i32 6, i32 6>
  %1527 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1516, <4 x i32> %1526) #5
  %1528 = lshr <8 x i16> %1527, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1529 = getelementptr inbounds i16, i16* %9, i64 392
  %1530 = bitcast i16* %1529 to <8 x i16>*
  %1531 = load <8 x i16>, <8 x i16>* %1530, align 16
  %1532 = getelementptr inbounds i16, i16* %10, i64 392
  %1533 = bitcast i16* %1532 to <8 x i16>*
  %1534 = load <8 x i16>, <8 x i16>* %1533, align 16
  %1535 = shufflevector <8 x i16> %1531, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1536 = zext <4 x i16> %1535 to <4 x i32>
  %1537 = shufflevector <8 x i16> %1534, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1538 = zext <4 x i16> %1537 to <4 x i32>
  %1539 = sub nsw <4 x i32> %1536, %1538
  %1540 = sub nsw <4 x i32> zeroinitializer, %1539
  %1541 = icmp slt <4 x i32> %1539, zeroinitializer
  %1542 = select <4 x i1> %1541, <4 x i32> %1540, <4 x i32> %1539
  %1543 = add nuw nsw <4 x i32> %1542, <i32 32, i32 32, i32 32, i32 32>
  %1544 = lshr <4 x i32> %1543, <i32 6, i32 6, i32 6, i32 6>
  %1545 = shufflevector <8 x i16> %1531, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1546 = shufflevector <8 x i16> %1534, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1547 = bitcast <8 x i16> %1545 to <4 x i32>
  %1548 = bitcast <8 x i16> %1546 to <4 x i32>
  %1549 = sub <4 x i32> %1547, %1548
  %1550 = sub <4 x i32> zeroinitializer, %1549
  %1551 = icmp slt <4 x i32> %1549, zeroinitializer
  %1552 = select <4 x i1> %1551, <4 x i32> %1550, <4 x i32> %1549
  %1553 = add nuw <4 x i32> %1552, <i32 32, i32 32, i32 32, i32 32>
  %1554 = lshr <4 x i32> %1553, <i32 6, i32 6, i32 6, i32 6>
  %1555 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1544, <4 x i32> %1554) #5
  %1556 = lshr <8 x i16> %1555, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1557 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1528, <8 x i16> %1556) #5
  %1558 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1557, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1559 = icmp slt <16 x i8> %1558, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1560 = select <16 x i1> %1559, <16 x i8> %1558, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1561 = bitcast i8* %1502 to <16 x i8>*
  store <16 x i8> %1560, <16 x i8>* %1561, align 16
  %1562 = getelementptr inbounds i16, i16* %9, i64 400
  %1563 = getelementptr inbounds i16, i16* %10, i64 400
  %1564 = getelementptr inbounds i8, i8* %1502, i64 16
  %1565 = bitcast i16* %1562 to <8 x i16>*
  %1566 = load <8 x i16>, <8 x i16>* %1565, align 16
  %1567 = bitcast i16* %1563 to <8 x i16>*
  %1568 = load <8 x i16>, <8 x i16>* %1567, align 16
  %1569 = shufflevector <8 x i16> %1566, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1570 = zext <4 x i16> %1569 to <4 x i32>
  %1571 = shufflevector <8 x i16> %1568, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1572 = zext <4 x i16> %1571 to <4 x i32>
  %1573 = sub nsw <4 x i32> %1570, %1572
  %1574 = sub nsw <4 x i32> zeroinitializer, %1573
  %1575 = icmp slt <4 x i32> %1573, zeroinitializer
  %1576 = select <4 x i1> %1575, <4 x i32> %1574, <4 x i32> %1573
  %1577 = add nuw nsw <4 x i32> %1576, <i32 32, i32 32, i32 32, i32 32>
  %1578 = lshr <4 x i32> %1577, <i32 6, i32 6, i32 6, i32 6>
  %1579 = shufflevector <8 x i16> %1566, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1580 = shufflevector <8 x i16> %1568, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1581 = bitcast <8 x i16> %1579 to <4 x i32>
  %1582 = bitcast <8 x i16> %1580 to <4 x i32>
  %1583 = sub <4 x i32> %1581, %1582
  %1584 = sub <4 x i32> zeroinitializer, %1583
  %1585 = icmp slt <4 x i32> %1583, zeroinitializer
  %1586 = select <4 x i1> %1585, <4 x i32> %1584, <4 x i32> %1583
  %1587 = add nuw <4 x i32> %1586, <i32 32, i32 32, i32 32, i32 32>
  %1588 = lshr <4 x i32> %1587, <i32 6, i32 6, i32 6, i32 6>
  %1589 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1578, <4 x i32> %1588) #5
  %1590 = lshr <8 x i16> %1589, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1591 = getelementptr inbounds i16, i16* %9, i64 408
  %1592 = bitcast i16* %1591 to <8 x i16>*
  %1593 = load <8 x i16>, <8 x i16>* %1592, align 16
  %1594 = getelementptr inbounds i16, i16* %10, i64 408
  %1595 = bitcast i16* %1594 to <8 x i16>*
  %1596 = load <8 x i16>, <8 x i16>* %1595, align 16
  %1597 = shufflevector <8 x i16> %1593, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1598 = zext <4 x i16> %1597 to <4 x i32>
  %1599 = shufflevector <8 x i16> %1596, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1600 = zext <4 x i16> %1599 to <4 x i32>
  %1601 = sub nsw <4 x i32> %1598, %1600
  %1602 = sub nsw <4 x i32> zeroinitializer, %1601
  %1603 = icmp slt <4 x i32> %1601, zeroinitializer
  %1604 = select <4 x i1> %1603, <4 x i32> %1602, <4 x i32> %1601
  %1605 = add nuw nsw <4 x i32> %1604, <i32 32, i32 32, i32 32, i32 32>
  %1606 = lshr <4 x i32> %1605, <i32 6, i32 6, i32 6, i32 6>
  %1607 = shufflevector <8 x i16> %1593, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1608 = shufflevector <8 x i16> %1596, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1609 = bitcast <8 x i16> %1607 to <4 x i32>
  %1610 = bitcast <8 x i16> %1608 to <4 x i32>
  %1611 = sub <4 x i32> %1609, %1610
  %1612 = sub <4 x i32> zeroinitializer, %1611
  %1613 = icmp slt <4 x i32> %1611, zeroinitializer
  %1614 = select <4 x i1> %1613, <4 x i32> %1612, <4 x i32> %1611
  %1615 = add nuw <4 x i32> %1614, <i32 32, i32 32, i32 32, i32 32>
  %1616 = lshr <4 x i32> %1615, <i32 6, i32 6, i32 6, i32 6>
  %1617 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1606, <4 x i32> %1616) #5
  %1618 = lshr <8 x i16> %1617, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1619 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1590, <8 x i16> %1618) #5
  %1620 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1619, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1621 = icmp slt <16 x i8> %1620, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1622 = select <16 x i1> %1621, <16 x i8> %1620, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1623 = bitcast i8* %1564 to <16 x i8>*
  store <16 x i8> %1622, <16 x i8>* %1623, align 16
  %1624 = getelementptr inbounds i16, i16* %9, i64 416
  %1625 = getelementptr inbounds i16, i16* %10, i64 416
  %1626 = getelementptr inbounds i8, i8* %1502, i64 32
  %1627 = bitcast i16* %1624 to <8 x i16>*
  %1628 = load <8 x i16>, <8 x i16>* %1627, align 16
  %1629 = bitcast i16* %1625 to <8 x i16>*
  %1630 = load <8 x i16>, <8 x i16>* %1629, align 16
  %1631 = shufflevector <8 x i16> %1628, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1632 = zext <4 x i16> %1631 to <4 x i32>
  %1633 = shufflevector <8 x i16> %1630, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1634 = zext <4 x i16> %1633 to <4 x i32>
  %1635 = sub nsw <4 x i32> %1632, %1634
  %1636 = sub nsw <4 x i32> zeroinitializer, %1635
  %1637 = icmp slt <4 x i32> %1635, zeroinitializer
  %1638 = select <4 x i1> %1637, <4 x i32> %1636, <4 x i32> %1635
  %1639 = add nuw nsw <4 x i32> %1638, <i32 32, i32 32, i32 32, i32 32>
  %1640 = lshr <4 x i32> %1639, <i32 6, i32 6, i32 6, i32 6>
  %1641 = shufflevector <8 x i16> %1628, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1642 = shufflevector <8 x i16> %1630, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1643 = bitcast <8 x i16> %1641 to <4 x i32>
  %1644 = bitcast <8 x i16> %1642 to <4 x i32>
  %1645 = sub <4 x i32> %1643, %1644
  %1646 = sub <4 x i32> zeroinitializer, %1645
  %1647 = icmp slt <4 x i32> %1645, zeroinitializer
  %1648 = select <4 x i1> %1647, <4 x i32> %1646, <4 x i32> %1645
  %1649 = add nuw <4 x i32> %1648, <i32 32, i32 32, i32 32, i32 32>
  %1650 = lshr <4 x i32> %1649, <i32 6, i32 6, i32 6, i32 6>
  %1651 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1640, <4 x i32> %1650) #5
  %1652 = lshr <8 x i16> %1651, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1653 = getelementptr inbounds i16, i16* %9, i64 424
  %1654 = bitcast i16* %1653 to <8 x i16>*
  %1655 = load <8 x i16>, <8 x i16>* %1654, align 16
  %1656 = getelementptr inbounds i16, i16* %10, i64 424
  %1657 = bitcast i16* %1656 to <8 x i16>*
  %1658 = load <8 x i16>, <8 x i16>* %1657, align 16
  %1659 = shufflevector <8 x i16> %1655, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1660 = zext <4 x i16> %1659 to <4 x i32>
  %1661 = shufflevector <8 x i16> %1658, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1662 = zext <4 x i16> %1661 to <4 x i32>
  %1663 = sub nsw <4 x i32> %1660, %1662
  %1664 = sub nsw <4 x i32> zeroinitializer, %1663
  %1665 = icmp slt <4 x i32> %1663, zeroinitializer
  %1666 = select <4 x i1> %1665, <4 x i32> %1664, <4 x i32> %1663
  %1667 = add nuw nsw <4 x i32> %1666, <i32 32, i32 32, i32 32, i32 32>
  %1668 = lshr <4 x i32> %1667, <i32 6, i32 6, i32 6, i32 6>
  %1669 = shufflevector <8 x i16> %1655, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1670 = shufflevector <8 x i16> %1658, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1671 = bitcast <8 x i16> %1669 to <4 x i32>
  %1672 = bitcast <8 x i16> %1670 to <4 x i32>
  %1673 = sub <4 x i32> %1671, %1672
  %1674 = sub <4 x i32> zeroinitializer, %1673
  %1675 = icmp slt <4 x i32> %1673, zeroinitializer
  %1676 = select <4 x i1> %1675, <4 x i32> %1674, <4 x i32> %1673
  %1677 = add nuw <4 x i32> %1676, <i32 32, i32 32, i32 32, i32 32>
  %1678 = lshr <4 x i32> %1677, <i32 6, i32 6, i32 6, i32 6>
  %1679 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1668, <4 x i32> %1678) #5
  %1680 = lshr <8 x i16> %1679, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1681 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1652, <8 x i16> %1680) #5
  %1682 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1681, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1683 = icmp slt <16 x i8> %1682, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1684 = select <16 x i1> %1683, <16 x i8> %1682, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1685 = bitcast i8* %1626 to <16 x i8>*
  store <16 x i8> %1684, <16 x i8>* %1685, align 16
  %1686 = getelementptr inbounds i16, i16* %9, i64 432
  %1687 = getelementptr inbounds i16, i16* %10, i64 432
  %1688 = getelementptr inbounds i8, i8* %1502, i64 48
  %1689 = bitcast i16* %1686 to <8 x i16>*
  %1690 = load <8 x i16>, <8 x i16>* %1689, align 16
  %1691 = bitcast i16* %1687 to <8 x i16>*
  %1692 = load <8 x i16>, <8 x i16>* %1691, align 16
  %1693 = shufflevector <8 x i16> %1690, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1694 = zext <4 x i16> %1693 to <4 x i32>
  %1695 = shufflevector <8 x i16> %1692, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1696 = zext <4 x i16> %1695 to <4 x i32>
  %1697 = sub nsw <4 x i32> %1694, %1696
  %1698 = sub nsw <4 x i32> zeroinitializer, %1697
  %1699 = icmp slt <4 x i32> %1697, zeroinitializer
  %1700 = select <4 x i1> %1699, <4 x i32> %1698, <4 x i32> %1697
  %1701 = add nuw nsw <4 x i32> %1700, <i32 32, i32 32, i32 32, i32 32>
  %1702 = lshr <4 x i32> %1701, <i32 6, i32 6, i32 6, i32 6>
  %1703 = shufflevector <8 x i16> %1690, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1704 = shufflevector <8 x i16> %1692, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1705 = bitcast <8 x i16> %1703 to <4 x i32>
  %1706 = bitcast <8 x i16> %1704 to <4 x i32>
  %1707 = sub <4 x i32> %1705, %1706
  %1708 = sub <4 x i32> zeroinitializer, %1707
  %1709 = icmp slt <4 x i32> %1707, zeroinitializer
  %1710 = select <4 x i1> %1709, <4 x i32> %1708, <4 x i32> %1707
  %1711 = add nuw <4 x i32> %1710, <i32 32, i32 32, i32 32, i32 32>
  %1712 = lshr <4 x i32> %1711, <i32 6, i32 6, i32 6, i32 6>
  %1713 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1702, <4 x i32> %1712) #5
  %1714 = lshr <8 x i16> %1713, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1715 = getelementptr inbounds i16, i16* %9, i64 440
  %1716 = bitcast i16* %1715 to <8 x i16>*
  %1717 = load <8 x i16>, <8 x i16>* %1716, align 16
  %1718 = getelementptr inbounds i16, i16* %10, i64 440
  %1719 = bitcast i16* %1718 to <8 x i16>*
  %1720 = load <8 x i16>, <8 x i16>* %1719, align 16
  %1721 = shufflevector <8 x i16> %1717, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1722 = zext <4 x i16> %1721 to <4 x i32>
  %1723 = shufflevector <8 x i16> %1720, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1724 = zext <4 x i16> %1723 to <4 x i32>
  %1725 = sub nsw <4 x i32> %1722, %1724
  %1726 = sub nsw <4 x i32> zeroinitializer, %1725
  %1727 = icmp slt <4 x i32> %1725, zeroinitializer
  %1728 = select <4 x i1> %1727, <4 x i32> %1726, <4 x i32> %1725
  %1729 = add nuw nsw <4 x i32> %1728, <i32 32, i32 32, i32 32, i32 32>
  %1730 = lshr <4 x i32> %1729, <i32 6, i32 6, i32 6, i32 6>
  %1731 = shufflevector <8 x i16> %1717, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1732 = shufflevector <8 x i16> %1720, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1733 = bitcast <8 x i16> %1731 to <4 x i32>
  %1734 = bitcast <8 x i16> %1732 to <4 x i32>
  %1735 = sub <4 x i32> %1733, %1734
  %1736 = sub <4 x i32> zeroinitializer, %1735
  %1737 = icmp slt <4 x i32> %1735, zeroinitializer
  %1738 = select <4 x i1> %1737, <4 x i32> %1736, <4 x i32> %1735
  %1739 = add nuw <4 x i32> %1738, <i32 32, i32 32, i32 32, i32 32>
  %1740 = lshr <4 x i32> %1739, <i32 6, i32 6, i32 6, i32 6>
  %1741 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1730, <4 x i32> %1740) #5
  %1742 = lshr <8 x i16> %1741, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1743 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1714, <8 x i16> %1742) #5
  %1744 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1743, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1745 = icmp slt <16 x i8> %1744, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1746 = select <16 x i1> %1745, <16 x i8> %1744, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1747 = bitcast i8* %1688 to <16 x i8>*
  store <16 x i8> %1746, <16 x i8>* %1747, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask64x32_10bpp_SSE4ILb1EEEvPKvS5_Phl(i8* readonly, i8* readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %1271, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %1269, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %1270, %7 ]
  %11 = phi i32 [ 6, %4 ], [ %1272, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = shufflevector <8 x i16> %13, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %17 = zext <4 x i16> %16 to <4 x i32>
  %18 = shufflevector <8 x i16> %15, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %19 = zext <4 x i16> %18 to <4 x i32>
  %20 = sub nsw <4 x i32> %17, %19
  %21 = sub nsw <4 x i32> zeroinitializer, %20
  %22 = icmp slt <4 x i32> %20, zeroinitializer
  %23 = select <4 x i1> %22, <4 x i32> %21, <4 x i32> %20
  %24 = add nuw nsw <4 x i32> %23, <i32 32, i32 32, i32 32, i32 32>
  %25 = lshr <4 x i32> %24, <i32 6, i32 6, i32 6, i32 6>
  %26 = shufflevector <8 x i16> %13, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %27 = shufflevector <8 x i16> %15, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %28 = bitcast <8 x i16> %26 to <4 x i32>
  %29 = bitcast <8 x i16> %27 to <4 x i32>
  %30 = sub <4 x i32> %28, %29
  %31 = sub <4 x i32> zeroinitializer, %30
  %32 = icmp slt <4 x i32> %30, zeroinitializer
  %33 = select <4 x i1> %32, <4 x i32> %31, <4 x i32> %30
  %34 = add nuw <4 x i32> %33, <i32 32, i32 32, i32 32, i32 32>
  %35 = lshr <4 x i32> %34, <i32 6, i32 6, i32 6, i32 6>
  %36 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %25, <4 x i32> %35) #5
  %37 = lshr <8 x i16> %36, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %38 = getelementptr inbounds i16, i16* %9, i64 8
  %39 = bitcast i16* %38 to <8 x i16>*
  %40 = load <8 x i16>, <8 x i16>* %39, align 16
  %41 = getelementptr inbounds i16, i16* %10, i64 8
  %42 = bitcast i16* %41 to <8 x i16>*
  %43 = load <8 x i16>, <8 x i16>* %42, align 16
  %44 = shufflevector <8 x i16> %40, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %45 = zext <4 x i16> %44 to <4 x i32>
  %46 = shufflevector <8 x i16> %43, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %47 = zext <4 x i16> %46 to <4 x i32>
  %48 = sub nsw <4 x i32> %45, %47
  %49 = sub nsw <4 x i32> zeroinitializer, %48
  %50 = icmp slt <4 x i32> %48, zeroinitializer
  %51 = select <4 x i1> %50, <4 x i32> %49, <4 x i32> %48
  %52 = add nuw nsw <4 x i32> %51, <i32 32, i32 32, i32 32, i32 32>
  %53 = lshr <4 x i32> %52, <i32 6, i32 6, i32 6, i32 6>
  %54 = shufflevector <8 x i16> %40, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %55 = shufflevector <8 x i16> %43, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %56 = bitcast <8 x i16> %54 to <4 x i32>
  %57 = bitcast <8 x i16> %55 to <4 x i32>
  %58 = sub <4 x i32> %56, %57
  %59 = sub <4 x i32> zeroinitializer, %58
  %60 = icmp slt <4 x i32> %58, zeroinitializer
  %61 = select <4 x i1> %60, <4 x i32> %59, <4 x i32> %58
  %62 = add nuw <4 x i32> %61, <i32 32, i32 32, i32 32, i32 32>
  %63 = lshr <4 x i32> %62, <i32 6, i32 6, i32 6, i32 6>
  %64 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %53, <4 x i32> %63) #5
  %65 = lshr <8 x i16> %64, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %66 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %37, <8 x i16> %65) #5
  %67 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %66, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %68 = icmp slt <16 x i8> %67, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %69 = select <16 x i1> %68, <16 x i8> %67, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %70 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %69
  %71 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %70, <16 x i8>* %71, align 16
  %72 = getelementptr inbounds i16, i16* %9, i64 16
  %73 = getelementptr inbounds i16, i16* %10, i64 16
  %74 = getelementptr inbounds i8, i8* %8, i64 16
  %75 = bitcast i16* %72 to <8 x i16>*
  %76 = load <8 x i16>, <8 x i16>* %75, align 16
  %77 = bitcast i16* %73 to <8 x i16>*
  %78 = load <8 x i16>, <8 x i16>* %77, align 16
  %79 = shufflevector <8 x i16> %76, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %80 = zext <4 x i16> %79 to <4 x i32>
  %81 = shufflevector <8 x i16> %78, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %82 = zext <4 x i16> %81 to <4 x i32>
  %83 = sub nsw <4 x i32> %80, %82
  %84 = sub nsw <4 x i32> zeroinitializer, %83
  %85 = icmp slt <4 x i32> %83, zeroinitializer
  %86 = select <4 x i1> %85, <4 x i32> %84, <4 x i32> %83
  %87 = add nuw nsw <4 x i32> %86, <i32 32, i32 32, i32 32, i32 32>
  %88 = lshr <4 x i32> %87, <i32 6, i32 6, i32 6, i32 6>
  %89 = shufflevector <8 x i16> %76, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %90 = shufflevector <8 x i16> %78, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %91 = bitcast <8 x i16> %89 to <4 x i32>
  %92 = bitcast <8 x i16> %90 to <4 x i32>
  %93 = sub <4 x i32> %91, %92
  %94 = sub <4 x i32> zeroinitializer, %93
  %95 = icmp slt <4 x i32> %93, zeroinitializer
  %96 = select <4 x i1> %95, <4 x i32> %94, <4 x i32> %93
  %97 = add nuw <4 x i32> %96, <i32 32, i32 32, i32 32, i32 32>
  %98 = lshr <4 x i32> %97, <i32 6, i32 6, i32 6, i32 6>
  %99 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %88, <4 x i32> %98) #5
  %100 = lshr <8 x i16> %99, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %101 = getelementptr inbounds i16, i16* %9, i64 24
  %102 = bitcast i16* %101 to <8 x i16>*
  %103 = load <8 x i16>, <8 x i16>* %102, align 16
  %104 = getelementptr inbounds i16, i16* %10, i64 24
  %105 = bitcast i16* %104 to <8 x i16>*
  %106 = load <8 x i16>, <8 x i16>* %105, align 16
  %107 = shufflevector <8 x i16> %103, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %108 = zext <4 x i16> %107 to <4 x i32>
  %109 = shufflevector <8 x i16> %106, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %110 = zext <4 x i16> %109 to <4 x i32>
  %111 = sub nsw <4 x i32> %108, %110
  %112 = sub nsw <4 x i32> zeroinitializer, %111
  %113 = icmp slt <4 x i32> %111, zeroinitializer
  %114 = select <4 x i1> %113, <4 x i32> %112, <4 x i32> %111
  %115 = add nuw nsw <4 x i32> %114, <i32 32, i32 32, i32 32, i32 32>
  %116 = lshr <4 x i32> %115, <i32 6, i32 6, i32 6, i32 6>
  %117 = shufflevector <8 x i16> %103, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %118 = shufflevector <8 x i16> %106, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %119 = bitcast <8 x i16> %117 to <4 x i32>
  %120 = bitcast <8 x i16> %118 to <4 x i32>
  %121 = sub <4 x i32> %119, %120
  %122 = sub <4 x i32> zeroinitializer, %121
  %123 = icmp slt <4 x i32> %121, zeroinitializer
  %124 = select <4 x i1> %123, <4 x i32> %122, <4 x i32> %121
  %125 = add nuw <4 x i32> %124, <i32 32, i32 32, i32 32, i32 32>
  %126 = lshr <4 x i32> %125, <i32 6, i32 6, i32 6, i32 6>
  %127 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %116, <4 x i32> %126) #5
  %128 = lshr <8 x i16> %127, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %129 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %100, <8 x i16> %128) #5
  %130 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %129, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %131 = icmp slt <16 x i8> %130, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %132 = select <16 x i1> %131, <16 x i8> %130, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %133 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %132
  %134 = bitcast i8* %74 to <16 x i8>*
  store <16 x i8> %133, <16 x i8>* %134, align 16
  %135 = getelementptr inbounds i16, i16* %9, i64 32
  %136 = getelementptr inbounds i16, i16* %10, i64 32
  %137 = getelementptr inbounds i8, i8* %8, i64 32
  %138 = bitcast i16* %135 to <8 x i16>*
  %139 = load <8 x i16>, <8 x i16>* %138, align 16
  %140 = bitcast i16* %136 to <8 x i16>*
  %141 = load <8 x i16>, <8 x i16>* %140, align 16
  %142 = shufflevector <8 x i16> %139, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %143 = zext <4 x i16> %142 to <4 x i32>
  %144 = shufflevector <8 x i16> %141, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %145 = zext <4 x i16> %144 to <4 x i32>
  %146 = sub nsw <4 x i32> %143, %145
  %147 = sub nsw <4 x i32> zeroinitializer, %146
  %148 = icmp slt <4 x i32> %146, zeroinitializer
  %149 = select <4 x i1> %148, <4 x i32> %147, <4 x i32> %146
  %150 = add nuw nsw <4 x i32> %149, <i32 32, i32 32, i32 32, i32 32>
  %151 = lshr <4 x i32> %150, <i32 6, i32 6, i32 6, i32 6>
  %152 = shufflevector <8 x i16> %139, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %153 = shufflevector <8 x i16> %141, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %154 = bitcast <8 x i16> %152 to <4 x i32>
  %155 = bitcast <8 x i16> %153 to <4 x i32>
  %156 = sub <4 x i32> %154, %155
  %157 = sub <4 x i32> zeroinitializer, %156
  %158 = icmp slt <4 x i32> %156, zeroinitializer
  %159 = select <4 x i1> %158, <4 x i32> %157, <4 x i32> %156
  %160 = add nuw <4 x i32> %159, <i32 32, i32 32, i32 32, i32 32>
  %161 = lshr <4 x i32> %160, <i32 6, i32 6, i32 6, i32 6>
  %162 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %151, <4 x i32> %161) #5
  %163 = lshr <8 x i16> %162, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %164 = getelementptr inbounds i16, i16* %9, i64 40
  %165 = bitcast i16* %164 to <8 x i16>*
  %166 = load <8 x i16>, <8 x i16>* %165, align 16
  %167 = getelementptr inbounds i16, i16* %10, i64 40
  %168 = bitcast i16* %167 to <8 x i16>*
  %169 = load <8 x i16>, <8 x i16>* %168, align 16
  %170 = shufflevector <8 x i16> %166, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %171 = zext <4 x i16> %170 to <4 x i32>
  %172 = shufflevector <8 x i16> %169, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %173 = zext <4 x i16> %172 to <4 x i32>
  %174 = sub nsw <4 x i32> %171, %173
  %175 = sub nsw <4 x i32> zeroinitializer, %174
  %176 = icmp slt <4 x i32> %174, zeroinitializer
  %177 = select <4 x i1> %176, <4 x i32> %175, <4 x i32> %174
  %178 = add nuw nsw <4 x i32> %177, <i32 32, i32 32, i32 32, i32 32>
  %179 = lshr <4 x i32> %178, <i32 6, i32 6, i32 6, i32 6>
  %180 = shufflevector <8 x i16> %166, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %181 = shufflevector <8 x i16> %169, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %182 = bitcast <8 x i16> %180 to <4 x i32>
  %183 = bitcast <8 x i16> %181 to <4 x i32>
  %184 = sub <4 x i32> %182, %183
  %185 = sub <4 x i32> zeroinitializer, %184
  %186 = icmp slt <4 x i32> %184, zeroinitializer
  %187 = select <4 x i1> %186, <4 x i32> %185, <4 x i32> %184
  %188 = add nuw <4 x i32> %187, <i32 32, i32 32, i32 32, i32 32>
  %189 = lshr <4 x i32> %188, <i32 6, i32 6, i32 6, i32 6>
  %190 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %179, <4 x i32> %189) #5
  %191 = lshr <8 x i16> %190, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %192 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %163, <8 x i16> %191) #5
  %193 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %192, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %194 = icmp slt <16 x i8> %193, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %195 = select <16 x i1> %194, <16 x i8> %193, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %196 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %195
  %197 = bitcast i8* %137 to <16 x i8>*
  store <16 x i8> %196, <16 x i8>* %197, align 16
  %198 = getelementptr inbounds i16, i16* %9, i64 48
  %199 = getelementptr inbounds i16, i16* %10, i64 48
  %200 = getelementptr inbounds i8, i8* %8, i64 48
  %201 = bitcast i16* %198 to <8 x i16>*
  %202 = load <8 x i16>, <8 x i16>* %201, align 16
  %203 = bitcast i16* %199 to <8 x i16>*
  %204 = load <8 x i16>, <8 x i16>* %203, align 16
  %205 = shufflevector <8 x i16> %202, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %206 = zext <4 x i16> %205 to <4 x i32>
  %207 = shufflevector <8 x i16> %204, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %208 = zext <4 x i16> %207 to <4 x i32>
  %209 = sub nsw <4 x i32> %206, %208
  %210 = sub nsw <4 x i32> zeroinitializer, %209
  %211 = icmp slt <4 x i32> %209, zeroinitializer
  %212 = select <4 x i1> %211, <4 x i32> %210, <4 x i32> %209
  %213 = add nuw nsw <4 x i32> %212, <i32 32, i32 32, i32 32, i32 32>
  %214 = lshr <4 x i32> %213, <i32 6, i32 6, i32 6, i32 6>
  %215 = shufflevector <8 x i16> %202, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %216 = shufflevector <8 x i16> %204, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %217 = bitcast <8 x i16> %215 to <4 x i32>
  %218 = bitcast <8 x i16> %216 to <4 x i32>
  %219 = sub <4 x i32> %217, %218
  %220 = sub <4 x i32> zeroinitializer, %219
  %221 = icmp slt <4 x i32> %219, zeroinitializer
  %222 = select <4 x i1> %221, <4 x i32> %220, <4 x i32> %219
  %223 = add nuw <4 x i32> %222, <i32 32, i32 32, i32 32, i32 32>
  %224 = lshr <4 x i32> %223, <i32 6, i32 6, i32 6, i32 6>
  %225 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %214, <4 x i32> %224) #5
  %226 = lshr <8 x i16> %225, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %227 = getelementptr inbounds i16, i16* %9, i64 56
  %228 = bitcast i16* %227 to <8 x i16>*
  %229 = load <8 x i16>, <8 x i16>* %228, align 16
  %230 = getelementptr inbounds i16, i16* %10, i64 56
  %231 = bitcast i16* %230 to <8 x i16>*
  %232 = load <8 x i16>, <8 x i16>* %231, align 16
  %233 = shufflevector <8 x i16> %229, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %234 = zext <4 x i16> %233 to <4 x i32>
  %235 = shufflevector <8 x i16> %232, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %236 = zext <4 x i16> %235 to <4 x i32>
  %237 = sub nsw <4 x i32> %234, %236
  %238 = sub nsw <4 x i32> zeroinitializer, %237
  %239 = icmp slt <4 x i32> %237, zeroinitializer
  %240 = select <4 x i1> %239, <4 x i32> %238, <4 x i32> %237
  %241 = add nuw nsw <4 x i32> %240, <i32 32, i32 32, i32 32, i32 32>
  %242 = lshr <4 x i32> %241, <i32 6, i32 6, i32 6, i32 6>
  %243 = shufflevector <8 x i16> %229, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %244 = shufflevector <8 x i16> %232, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %245 = bitcast <8 x i16> %243 to <4 x i32>
  %246 = bitcast <8 x i16> %244 to <4 x i32>
  %247 = sub <4 x i32> %245, %246
  %248 = sub <4 x i32> zeroinitializer, %247
  %249 = icmp slt <4 x i32> %247, zeroinitializer
  %250 = select <4 x i1> %249, <4 x i32> %248, <4 x i32> %247
  %251 = add nuw <4 x i32> %250, <i32 32, i32 32, i32 32, i32 32>
  %252 = lshr <4 x i32> %251, <i32 6, i32 6, i32 6, i32 6>
  %253 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %242, <4 x i32> %252) #5
  %254 = lshr <8 x i16> %253, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %255 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %226, <8 x i16> %254) #5
  %256 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %255, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %257 = icmp slt <16 x i8> %256, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %258 = select <16 x i1> %257, <16 x i8> %256, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %259 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %258
  %260 = bitcast i8* %200 to <16 x i8>*
  store <16 x i8> %259, <16 x i8>* %260, align 16
  %261 = getelementptr inbounds i16, i16* %9, i64 64
  %262 = getelementptr inbounds i16, i16* %10, i64 64
  %263 = getelementptr inbounds i8, i8* %8, i64 %3
  %264 = bitcast i16* %261 to <8 x i16>*
  %265 = load <8 x i16>, <8 x i16>* %264, align 16
  %266 = bitcast i16* %262 to <8 x i16>*
  %267 = load <8 x i16>, <8 x i16>* %266, align 16
  %268 = shufflevector <8 x i16> %265, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %269 = zext <4 x i16> %268 to <4 x i32>
  %270 = shufflevector <8 x i16> %267, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %271 = zext <4 x i16> %270 to <4 x i32>
  %272 = sub nsw <4 x i32> %269, %271
  %273 = sub nsw <4 x i32> zeroinitializer, %272
  %274 = icmp slt <4 x i32> %272, zeroinitializer
  %275 = select <4 x i1> %274, <4 x i32> %273, <4 x i32> %272
  %276 = add nuw nsw <4 x i32> %275, <i32 32, i32 32, i32 32, i32 32>
  %277 = lshr <4 x i32> %276, <i32 6, i32 6, i32 6, i32 6>
  %278 = shufflevector <8 x i16> %265, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %279 = shufflevector <8 x i16> %267, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %280 = bitcast <8 x i16> %278 to <4 x i32>
  %281 = bitcast <8 x i16> %279 to <4 x i32>
  %282 = sub <4 x i32> %280, %281
  %283 = sub <4 x i32> zeroinitializer, %282
  %284 = icmp slt <4 x i32> %282, zeroinitializer
  %285 = select <4 x i1> %284, <4 x i32> %283, <4 x i32> %282
  %286 = add nuw <4 x i32> %285, <i32 32, i32 32, i32 32, i32 32>
  %287 = lshr <4 x i32> %286, <i32 6, i32 6, i32 6, i32 6>
  %288 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %277, <4 x i32> %287) #5
  %289 = lshr <8 x i16> %288, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %290 = getelementptr inbounds i16, i16* %9, i64 72
  %291 = bitcast i16* %290 to <8 x i16>*
  %292 = load <8 x i16>, <8 x i16>* %291, align 16
  %293 = getelementptr inbounds i16, i16* %10, i64 72
  %294 = bitcast i16* %293 to <8 x i16>*
  %295 = load <8 x i16>, <8 x i16>* %294, align 16
  %296 = shufflevector <8 x i16> %292, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %297 = zext <4 x i16> %296 to <4 x i32>
  %298 = shufflevector <8 x i16> %295, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %299 = zext <4 x i16> %298 to <4 x i32>
  %300 = sub nsw <4 x i32> %297, %299
  %301 = sub nsw <4 x i32> zeroinitializer, %300
  %302 = icmp slt <4 x i32> %300, zeroinitializer
  %303 = select <4 x i1> %302, <4 x i32> %301, <4 x i32> %300
  %304 = add nuw nsw <4 x i32> %303, <i32 32, i32 32, i32 32, i32 32>
  %305 = lshr <4 x i32> %304, <i32 6, i32 6, i32 6, i32 6>
  %306 = shufflevector <8 x i16> %292, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %307 = shufflevector <8 x i16> %295, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %308 = bitcast <8 x i16> %306 to <4 x i32>
  %309 = bitcast <8 x i16> %307 to <4 x i32>
  %310 = sub <4 x i32> %308, %309
  %311 = sub <4 x i32> zeroinitializer, %310
  %312 = icmp slt <4 x i32> %310, zeroinitializer
  %313 = select <4 x i1> %312, <4 x i32> %311, <4 x i32> %310
  %314 = add nuw <4 x i32> %313, <i32 32, i32 32, i32 32, i32 32>
  %315 = lshr <4 x i32> %314, <i32 6, i32 6, i32 6, i32 6>
  %316 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %305, <4 x i32> %315) #5
  %317 = lshr <8 x i16> %316, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %318 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %289, <8 x i16> %317) #5
  %319 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %318, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %320 = icmp slt <16 x i8> %319, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %321 = select <16 x i1> %320, <16 x i8> %319, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %322 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %321
  %323 = bitcast i8* %263 to <16 x i8>*
  store <16 x i8> %322, <16 x i8>* %323, align 16
  %324 = getelementptr inbounds i16, i16* %9, i64 80
  %325 = getelementptr inbounds i16, i16* %10, i64 80
  %326 = getelementptr inbounds i8, i8* %263, i64 16
  %327 = bitcast i16* %324 to <8 x i16>*
  %328 = load <8 x i16>, <8 x i16>* %327, align 16
  %329 = bitcast i16* %325 to <8 x i16>*
  %330 = load <8 x i16>, <8 x i16>* %329, align 16
  %331 = shufflevector <8 x i16> %328, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %332 = zext <4 x i16> %331 to <4 x i32>
  %333 = shufflevector <8 x i16> %330, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %334 = zext <4 x i16> %333 to <4 x i32>
  %335 = sub nsw <4 x i32> %332, %334
  %336 = sub nsw <4 x i32> zeroinitializer, %335
  %337 = icmp slt <4 x i32> %335, zeroinitializer
  %338 = select <4 x i1> %337, <4 x i32> %336, <4 x i32> %335
  %339 = add nuw nsw <4 x i32> %338, <i32 32, i32 32, i32 32, i32 32>
  %340 = lshr <4 x i32> %339, <i32 6, i32 6, i32 6, i32 6>
  %341 = shufflevector <8 x i16> %328, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %342 = shufflevector <8 x i16> %330, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %343 = bitcast <8 x i16> %341 to <4 x i32>
  %344 = bitcast <8 x i16> %342 to <4 x i32>
  %345 = sub <4 x i32> %343, %344
  %346 = sub <4 x i32> zeroinitializer, %345
  %347 = icmp slt <4 x i32> %345, zeroinitializer
  %348 = select <4 x i1> %347, <4 x i32> %346, <4 x i32> %345
  %349 = add nuw <4 x i32> %348, <i32 32, i32 32, i32 32, i32 32>
  %350 = lshr <4 x i32> %349, <i32 6, i32 6, i32 6, i32 6>
  %351 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %340, <4 x i32> %350) #5
  %352 = lshr <8 x i16> %351, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %353 = getelementptr inbounds i16, i16* %9, i64 88
  %354 = bitcast i16* %353 to <8 x i16>*
  %355 = load <8 x i16>, <8 x i16>* %354, align 16
  %356 = getelementptr inbounds i16, i16* %10, i64 88
  %357 = bitcast i16* %356 to <8 x i16>*
  %358 = load <8 x i16>, <8 x i16>* %357, align 16
  %359 = shufflevector <8 x i16> %355, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %360 = zext <4 x i16> %359 to <4 x i32>
  %361 = shufflevector <8 x i16> %358, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %362 = zext <4 x i16> %361 to <4 x i32>
  %363 = sub nsw <4 x i32> %360, %362
  %364 = sub nsw <4 x i32> zeroinitializer, %363
  %365 = icmp slt <4 x i32> %363, zeroinitializer
  %366 = select <4 x i1> %365, <4 x i32> %364, <4 x i32> %363
  %367 = add nuw nsw <4 x i32> %366, <i32 32, i32 32, i32 32, i32 32>
  %368 = lshr <4 x i32> %367, <i32 6, i32 6, i32 6, i32 6>
  %369 = shufflevector <8 x i16> %355, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %370 = shufflevector <8 x i16> %358, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %371 = bitcast <8 x i16> %369 to <4 x i32>
  %372 = bitcast <8 x i16> %370 to <4 x i32>
  %373 = sub <4 x i32> %371, %372
  %374 = sub <4 x i32> zeroinitializer, %373
  %375 = icmp slt <4 x i32> %373, zeroinitializer
  %376 = select <4 x i1> %375, <4 x i32> %374, <4 x i32> %373
  %377 = add nuw <4 x i32> %376, <i32 32, i32 32, i32 32, i32 32>
  %378 = lshr <4 x i32> %377, <i32 6, i32 6, i32 6, i32 6>
  %379 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %368, <4 x i32> %378) #5
  %380 = lshr <8 x i16> %379, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %381 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %352, <8 x i16> %380) #5
  %382 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %381, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %383 = icmp slt <16 x i8> %382, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %384 = select <16 x i1> %383, <16 x i8> %382, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %385 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %384
  %386 = bitcast i8* %326 to <16 x i8>*
  store <16 x i8> %385, <16 x i8>* %386, align 16
  %387 = getelementptr inbounds i16, i16* %9, i64 96
  %388 = getelementptr inbounds i16, i16* %10, i64 96
  %389 = getelementptr inbounds i8, i8* %263, i64 32
  %390 = bitcast i16* %387 to <8 x i16>*
  %391 = load <8 x i16>, <8 x i16>* %390, align 16
  %392 = bitcast i16* %388 to <8 x i16>*
  %393 = load <8 x i16>, <8 x i16>* %392, align 16
  %394 = shufflevector <8 x i16> %391, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %395 = zext <4 x i16> %394 to <4 x i32>
  %396 = shufflevector <8 x i16> %393, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %397 = zext <4 x i16> %396 to <4 x i32>
  %398 = sub nsw <4 x i32> %395, %397
  %399 = sub nsw <4 x i32> zeroinitializer, %398
  %400 = icmp slt <4 x i32> %398, zeroinitializer
  %401 = select <4 x i1> %400, <4 x i32> %399, <4 x i32> %398
  %402 = add nuw nsw <4 x i32> %401, <i32 32, i32 32, i32 32, i32 32>
  %403 = lshr <4 x i32> %402, <i32 6, i32 6, i32 6, i32 6>
  %404 = shufflevector <8 x i16> %391, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %405 = shufflevector <8 x i16> %393, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %406 = bitcast <8 x i16> %404 to <4 x i32>
  %407 = bitcast <8 x i16> %405 to <4 x i32>
  %408 = sub <4 x i32> %406, %407
  %409 = sub <4 x i32> zeroinitializer, %408
  %410 = icmp slt <4 x i32> %408, zeroinitializer
  %411 = select <4 x i1> %410, <4 x i32> %409, <4 x i32> %408
  %412 = add nuw <4 x i32> %411, <i32 32, i32 32, i32 32, i32 32>
  %413 = lshr <4 x i32> %412, <i32 6, i32 6, i32 6, i32 6>
  %414 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %403, <4 x i32> %413) #5
  %415 = lshr <8 x i16> %414, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %416 = getelementptr inbounds i16, i16* %9, i64 104
  %417 = bitcast i16* %416 to <8 x i16>*
  %418 = load <8 x i16>, <8 x i16>* %417, align 16
  %419 = getelementptr inbounds i16, i16* %10, i64 104
  %420 = bitcast i16* %419 to <8 x i16>*
  %421 = load <8 x i16>, <8 x i16>* %420, align 16
  %422 = shufflevector <8 x i16> %418, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %423 = zext <4 x i16> %422 to <4 x i32>
  %424 = shufflevector <8 x i16> %421, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %425 = zext <4 x i16> %424 to <4 x i32>
  %426 = sub nsw <4 x i32> %423, %425
  %427 = sub nsw <4 x i32> zeroinitializer, %426
  %428 = icmp slt <4 x i32> %426, zeroinitializer
  %429 = select <4 x i1> %428, <4 x i32> %427, <4 x i32> %426
  %430 = add nuw nsw <4 x i32> %429, <i32 32, i32 32, i32 32, i32 32>
  %431 = lshr <4 x i32> %430, <i32 6, i32 6, i32 6, i32 6>
  %432 = shufflevector <8 x i16> %418, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %433 = shufflevector <8 x i16> %421, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %434 = bitcast <8 x i16> %432 to <4 x i32>
  %435 = bitcast <8 x i16> %433 to <4 x i32>
  %436 = sub <4 x i32> %434, %435
  %437 = sub <4 x i32> zeroinitializer, %436
  %438 = icmp slt <4 x i32> %436, zeroinitializer
  %439 = select <4 x i1> %438, <4 x i32> %437, <4 x i32> %436
  %440 = add nuw <4 x i32> %439, <i32 32, i32 32, i32 32, i32 32>
  %441 = lshr <4 x i32> %440, <i32 6, i32 6, i32 6, i32 6>
  %442 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %431, <4 x i32> %441) #5
  %443 = lshr <8 x i16> %442, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %444 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %415, <8 x i16> %443) #5
  %445 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %444, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %446 = icmp slt <16 x i8> %445, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %447 = select <16 x i1> %446, <16 x i8> %445, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %448 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %447
  %449 = bitcast i8* %389 to <16 x i8>*
  store <16 x i8> %448, <16 x i8>* %449, align 16
  %450 = getelementptr inbounds i16, i16* %9, i64 112
  %451 = getelementptr inbounds i16, i16* %10, i64 112
  %452 = getelementptr inbounds i8, i8* %263, i64 48
  %453 = bitcast i16* %450 to <8 x i16>*
  %454 = load <8 x i16>, <8 x i16>* %453, align 16
  %455 = bitcast i16* %451 to <8 x i16>*
  %456 = load <8 x i16>, <8 x i16>* %455, align 16
  %457 = shufflevector <8 x i16> %454, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %458 = zext <4 x i16> %457 to <4 x i32>
  %459 = shufflevector <8 x i16> %456, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %460 = zext <4 x i16> %459 to <4 x i32>
  %461 = sub nsw <4 x i32> %458, %460
  %462 = sub nsw <4 x i32> zeroinitializer, %461
  %463 = icmp slt <4 x i32> %461, zeroinitializer
  %464 = select <4 x i1> %463, <4 x i32> %462, <4 x i32> %461
  %465 = add nuw nsw <4 x i32> %464, <i32 32, i32 32, i32 32, i32 32>
  %466 = lshr <4 x i32> %465, <i32 6, i32 6, i32 6, i32 6>
  %467 = shufflevector <8 x i16> %454, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %468 = shufflevector <8 x i16> %456, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %469 = bitcast <8 x i16> %467 to <4 x i32>
  %470 = bitcast <8 x i16> %468 to <4 x i32>
  %471 = sub <4 x i32> %469, %470
  %472 = sub <4 x i32> zeroinitializer, %471
  %473 = icmp slt <4 x i32> %471, zeroinitializer
  %474 = select <4 x i1> %473, <4 x i32> %472, <4 x i32> %471
  %475 = add nuw <4 x i32> %474, <i32 32, i32 32, i32 32, i32 32>
  %476 = lshr <4 x i32> %475, <i32 6, i32 6, i32 6, i32 6>
  %477 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %466, <4 x i32> %476) #5
  %478 = lshr <8 x i16> %477, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %479 = getelementptr inbounds i16, i16* %9, i64 120
  %480 = bitcast i16* %479 to <8 x i16>*
  %481 = load <8 x i16>, <8 x i16>* %480, align 16
  %482 = getelementptr inbounds i16, i16* %10, i64 120
  %483 = bitcast i16* %482 to <8 x i16>*
  %484 = load <8 x i16>, <8 x i16>* %483, align 16
  %485 = shufflevector <8 x i16> %481, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %486 = zext <4 x i16> %485 to <4 x i32>
  %487 = shufflevector <8 x i16> %484, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %488 = zext <4 x i16> %487 to <4 x i32>
  %489 = sub nsw <4 x i32> %486, %488
  %490 = sub nsw <4 x i32> zeroinitializer, %489
  %491 = icmp slt <4 x i32> %489, zeroinitializer
  %492 = select <4 x i1> %491, <4 x i32> %490, <4 x i32> %489
  %493 = add nuw nsw <4 x i32> %492, <i32 32, i32 32, i32 32, i32 32>
  %494 = lshr <4 x i32> %493, <i32 6, i32 6, i32 6, i32 6>
  %495 = shufflevector <8 x i16> %481, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %496 = shufflevector <8 x i16> %484, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %497 = bitcast <8 x i16> %495 to <4 x i32>
  %498 = bitcast <8 x i16> %496 to <4 x i32>
  %499 = sub <4 x i32> %497, %498
  %500 = sub <4 x i32> zeroinitializer, %499
  %501 = icmp slt <4 x i32> %499, zeroinitializer
  %502 = select <4 x i1> %501, <4 x i32> %500, <4 x i32> %499
  %503 = add nuw <4 x i32> %502, <i32 32, i32 32, i32 32, i32 32>
  %504 = lshr <4 x i32> %503, <i32 6, i32 6, i32 6, i32 6>
  %505 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %494, <4 x i32> %504) #5
  %506 = lshr <8 x i16> %505, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %507 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %478, <8 x i16> %506) #5
  %508 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %507, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %509 = icmp slt <16 x i8> %508, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %510 = select <16 x i1> %509, <16 x i8> %508, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %511 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %510
  %512 = bitcast i8* %452 to <16 x i8>*
  store <16 x i8> %511, <16 x i8>* %512, align 16
  %513 = getelementptr inbounds i16, i16* %9, i64 128
  %514 = getelementptr inbounds i16, i16* %10, i64 128
  %515 = getelementptr inbounds i8, i8* %263, i64 %3
  %516 = bitcast i16* %513 to <8 x i16>*
  %517 = load <8 x i16>, <8 x i16>* %516, align 16
  %518 = bitcast i16* %514 to <8 x i16>*
  %519 = load <8 x i16>, <8 x i16>* %518, align 16
  %520 = shufflevector <8 x i16> %517, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %521 = zext <4 x i16> %520 to <4 x i32>
  %522 = shufflevector <8 x i16> %519, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %523 = zext <4 x i16> %522 to <4 x i32>
  %524 = sub nsw <4 x i32> %521, %523
  %525 = sub nsw <4 x i32> zeroinitializer, %524
  %526 = icmp slt <4 x i32> %524, zeroinitializer
  %527 = select <4 x i1> %526, <4 x i32> %525, <4 x i32> %524
  %528 = add nuw nsw <4 x i32> %527, <i32 32, i32 32, i32 32, i32 32>
  %529 = lshr <4 x i32> %528, <i32 6, i32 6, i32 6, i32 6>
  %530 = shufflevector <8 x i16> %517, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %531 = shufflevector <8 x i16> %519, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %532 = bitcast <8 x i16> %530 to <4 x i32>
  %533 = bitcast <8 x i16> %531 to <4 x i32>
  %534 = sub <4 x i32> %532, %533
  %535 = sub <4 x i32> zeroinitializer, %534
  %536 = icmp slt <4 x i32> %534, zeroinitializer
  %537 = select <4 x i1> %536, <4 x i32> %535, <4 x i32> %534
  %538 = add nuw <4 x i32> %537, <i32 32, i32 32, i32 32, i32 32>
  %539 = lshr <4 x i32> %538, <i32 6, i32 6, i32 6, i32 6>
  %540 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %529, <4 x i32> %539) #5
  %541 = lshr <8 x i16> %540, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %542 = getelementptr inbounds i16, i16* %9, i64 136
  %543 = bitcast i16* %542 to <8 x i16>*
  %544 = load <8 x i16>, <8 x i16>* %543, align 16
  %545 = getelementptr inbounds i16, i16* %10, i64 136
  %546 = bitcast i16* %545 to <8 x i16>*
  %547 = load <8 x i16>, <8 x i16>* %546, align 16
  %548 = shufflevector <8 x i16> %544, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %549 = zext <4 x i16> %548 to <4 x i32>
  %550 = shufflevector <8 x i16> %547, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %551 = zext <4 x i16> %550 to <4 x i32>
  %552 = sub nsw <4 x i32> %549, %551
  %553 = sub nsw <4 x i32> zeroinitializer, %552
  %554 = icmp slt <4 x i32> %552, zeroinitializer
  %555 = select <4 x i1> %554, <4 x i32> %553, <4 x i32> %552
  %556 = add nuw nsw <4 x i32> %555, <i32 32, i32 32, i32 32, i32 32>
  %557 = lshr <4 x i32> %556, <i32 6, i32 6, i32 6, i32 6>
  %558 = shufflevector <8 x i16> %544, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %559 = shufflevector <8 x i16> %547, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %560 = bitcast <8 x i16> %558 to <4 x i32>
  %561 = bitcast <8 x i16> %559 to <4 x i32>
  %562 = sub <4 x i32> %560, %561
  %563 = sub <4 x i32> zeroinitializer, %562
  %564 = icmp slt <4 x i32> %562, zeroinitializer
  %565 = select <4 x i1> %564, <4 x i32> %563, <4 x i32> %562
  %566 = add nuw <4 x i32> %565, <i32 32, i32 32, i32 32, i32 32>
  %567 = lshr <4 x i32> %566, <i32 6, i32 6, i32 6, i32 6>
  %568 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %557, <4 x i32> %567) #5
  %569 = lshr <8 x i16> %568, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %570 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %541, <8 x i16> %569) #5
  %571 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %570, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %572 = icmp slt <16 x i8> %571, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %573 = select <16 x i1> %572, <16 x i8> %571, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %574 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %573
  %575 = bitcast i8* %515 to <16 x i8>*
  store <16 x i8> %574, <16 x i8>* %575, align 16
  %576 = getelementptr inbounds i16, i16* %9, i64 144
  %577 = getelementptr inbounds i16, i16* %10, i64 144
  %578 = getelementptr inbounds i8, i8* %515, i64 16
  %579 = bitcast i16* %576 to <8 x i16>*
  %580 = load <8 x i16>, <8 x i16>* %579, align 16
  %581 = bitcast i16* %577 to <8 x i16>*
  %582 = load <8 x i16>, <8 x i16>* %581, align 16
  %583 = shufflevector <8 x i16> %580, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %584 = zext <4 x i16> %583 to <4 x i32>
  %585 = shufflevector <8 x i16> %582, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %586 = zext <4 x i16> %585 to <4 x i32>
  %587 = sub nsw <4 x i32> %584, %586
  %588 = sub nsw <4 x i32> zeroinitializer, %587
  %589 = icmp slt <4 x i32> %587, zeroinitializer
  %590 = select <4 x i1> %589, <4 x i32> %588, <4 x i32> %587
  %591 = add nuw nsw <4 x i32> %590, <i32 32, i32 32, i32 32, i32 32>
  %592 = lshr <4 x i32> %591, <i32 6, i32 6, i32 6, i32 6>
  %593 = shufflevector <8 x i16> %580, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %594 = shufflevector <8 x i16> %582, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %595 = bitcast <8 x i16> %593 to <4 x i32>
  %596 = bitcast <8 x i16> %594 to <4 x i32>
  %597 = sub <4 x i32> %595, %596
  %598 = sub <4 x i32> zeroinitializer, %597
  %599 = icmp slt <4 x i32> %597, zeroinitializer
  %600 = select <4 x i1> %599, <4 x i32> %598, <4 x i32> %597
  %601 = add nuw <4 x i32> %600, <i32 32, i32 32, i32 32, i32 32>
  %602 = lshr <4 x i32> %601, <i32 6, i32 6, i32 6, i32 6>
  %603 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %592, <4 x i32> %602) #5
  %604 = lshr <8 x i16> %603, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %605 = getelementptr inbounds i16, i16* %9, i64 152
  %606 = bitcast i16* %605 to <8 x i16>*
  %607 = load <8 x i16>, <8 x i16>* %606, align 16
  %608 = getelementptr inbounds i16, i16* %10, i64 152
  %609 = bitcast i16* %608 to <8 x i16>*
  %610 = load <8 x i16>, <8 x i16>* %609, align 16
  %611 = shufflevector <8 x i16> %607, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %612 = zext <4 x i16> %611 to <4 x i32>
  %613 = shufflevector <8 x i16> %610, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %614 = zext <4 x i16> %613 to <4 x i32>
  %615 = sub nsw <4 x i32> %612, %614
  %616 = sub nsw <4 x i32> zeroinitializer, %615
  %617 = icmp slt <4 x i32> %615, zeroinitializer
  %618 = select <4 x i1> %617, <4 x i32> %616, <4 x i32> %615
  %619 = add nuw nsw <4 x i32> %618, <i32 32, i32 32, i32 32, i32 32>
  %620 = lshr <4 x i32> %619, <i32 6, i32 6, i32 6, i32 6>
  %621 = shufflevector <8 x i16> %607, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %622 = shufflevector <8 x i16> %610, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %623 = bitcast <8 x i16> %621 to <4 x i32>
  %624 = bitcast <8 x i16> %622 to <4 x i32>
  %625 = sub <4 x i32> %623, %624
  %626 = sub <4 x i32> zeroinitializer, %625
  %627 = icmp slt <4 x i32> %625, zeroinitializer
  %628 = select <4 x i1> %627, <4 x i32> %626, <4 x i32> %625
  %629 = add nuw <4 x i32> %628, <i32 32, i32 32, i32 32, i32 32>
  %630 = lshr <4 x i32> %629, <i32 6, i32 6, i32 6, i32 6>
  %631 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %620, <4 x i32> %630) #5
  %632 = lshr <8 x i16> %631, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %633 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %604, <8 x i16> %632) #5
  %634 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %633, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %635 = icmp slt <16 x i8> %634, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %636 = select <16 x i1> %635, <16 x i8> %634, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %637 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %636
  %638 = bitcast i8* %578 to <16 x i8>*
  store <16 x i8> %637, <16 x i8>* %638, align 16
  %639 = getelementptr inbounds i16, i16* %9, i64 160
  %640 = getelementptr inbounds i16, i16* %10, i64 160
  %641 = getelementptr inbounds i8, i8* %515, i64 32
  %642 = bitcast i16* %639 to <8 x i16>*
  %643 = load <8 x i16>, <8 x i16>* %642, align 16
  %644 = bitcast i16* %640 to <8 x i16>*
  %645 = load <8 x i16>, <8 x i16>* %644, align 16
  %646 = shufflevector <8 x i16> %643, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %647 = zext <4 x i16> %646 to <4 x i32>
  %648 = shufflevector <8 x i16> %645, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %649 = zext <4 x i16> %648 to <4 x i32>
  %650 = sub nsw <4 x i32> %647, %649
  %651 = sub nsw <4 x i32> zeroinitializer, %650
  %652 = icmp slt <4 x i32> %650, zeroinitializer
  %653 = select <4 x i1> %652, <4 x i32> %651, <4 x i32> %650
  %654 = add nuw nsw <4 x i32> %653, <i32 32, i32 32, i32 32, i32 32>
  %655 = lshr <4 x i32> %654, <i32 6, i32 6, i32 6, i32 6>
  %656 = shufflevector <8 x i16> %643, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %657 = shufflevector <8 x i16> %645, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %658 = bitcast <8 x i16> %656 to <4 x i32>
  %659 = bitcast <8 x i16> %657 to <4 x i32>
  %660 = sub <4 x i32> %658, %659
  %661 = sub <4 x i32> zeroinitializer, %660
  %662 = icmp slt <4 x i32> %660, zeroinitializer
  %663 = select <4 x i1> %662, <4 x i32> %661, <4 x i32> %660
  %664 = add nuw <4 x i32> %663, <i32 32, i32 32, i32 32, i32 32>
  %665 = lshr <4 x i32> %664, <i32 6, i32 6, i32 6, i32 6>
  %666 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %655, <4 x i32> %665) #5
  %667 = lshr <8 x i16> %666, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %668 = getelementptr inbounds i16, i16* %9, i64 168
  %669 = bitcast i16* %668 to <8 x i16>*
  %670 = load <8 x i16>, <8 x i16>* %669, align 16
  %671 = getelementptr inbounds i16, i16* %10, i64 168
  %672 = bitcast i16* %671 to <8 x i16>*
  %673 = load <8 x i16>, <8 x i16>* %672, align 16
  %674 = shufflevector <8 x i16> %670, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %675 = zext <4 x i16> %674 to <4 x i32>
  %676 = shufflevector <8 x i16> %673, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %677 = zext <4 x i16> %676 to <4 x i32>
  %678 = sub nsw <4 x i32> %675, %677
  %679 = sub nsw <4 x i32> zeroinitializer, %678
  %680 = icmp slt <4 x i32> %678, zeroinitializer
  %681 = select <4 x i1> %680, <4 x i32> %679, <4 x i32> %678
  %682 = add nuw nsw <4 x i32> %681, <i32 32, i32 32, i32 32, i32 32>
  %683 = lshr <4 x i32> %682, <i32 6, i32 6, i32 6, i32 6>
  %684 = shufflevector <8 x i16> %670, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %685 = shufflevector <8 x i16> %673, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %686 = bitcast <8 x i16> %684 to <4 x i32>
  %687 = bitcast <8 x i16> %685 to <4 x i32>
  %688 = sub <4 x i32> %686, %687
  %689 = sub <4 x i32> zeroinitializer, %688
  %690 = icmp slt <4 x i32> %688, zeroinitializer
  %691 = select <4 x i1> %690, <4 x i32> %689, <4 x i32> %688
  %692 = add nuw <4 x i32> %691, <i32 32, i32 32, i32 32, i32 32>
  %693 = lshr <4 x i32> %692, <i32 6, i32 6, i32 6, i32 6>
  %694 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %683, <4 x i32> %693) #5
  %695 = lshr <8 x i16> %694, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %696 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %667, <8 x i16> %695) #5
  %697 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %696, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %698 = icmp slt <16 x i8> %697, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %699 = select <16 x i1> %698, <16 x i8> %697, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %700 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %699
  %701 = bitcast i8* %641 to <16 x i8>*
  store <16 x i8> %700, <16 x i8>* %701, align 16
  %702 = getelementptr inbounds i16, i16* %9, i64 176
  %703 = getelementptr inbounds i16, i16* %10, i64 176
  %704 = getelementptr inbounds i8, i8* %515, i64 48
  %705 = bitcast i16* %702 to <8 x i16>*
  %706 = load <8 x i16>, <8 x i16>* %705, align 16
  %707 = bitcast i16* %703 to <8 x i16>*
  %708 = load <8 x i16>, <8 x i16>* %707, align 16
  %709 = shufflevector <8 x i16> %706, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %710 = zext <4 x i16> %709 to <4 x i32>
  %711 = shufflevector <8 x i16> %708, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %712 = zext <4 x i16> %711 to <4 x i32>
  %713 = sub nsw <4 x i32> %710, %712
  %714 = sub nsw <4 x i32> zeroinitializer, %713
  %715 = icmp slt <4 x i32> %713, zeroinitializer
  %716 = select <4 x i1> %715, <4 x i32> %714, <4 x i32> %713
  %717 = add nuw nsw <4 x i32> %716, <i32 32, i32 32, i32 32, i32 32>
  %718 = lshr <4 x i32> %717, <i32 6, i32 6, i32 6, i32 6>
  %719 = shufflevector <8 x i16> %706, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %720 = shufflevector <8 x i16> %708, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %721 = bitcast <8 x i16> %719 to <4 x i32>
  %722 = bitcast <8 x i16> %720 to <4 x i32>
  %723 = sub <4 x i32> %721, %722
  %724 = sub <4 x i32> zeroinitializer, %723
  %725 = icmp slt <4 x i32> %723, zeroinitializer
  %726 = select <4 x i1> %725, <4 x i32> %724, <4 x i32> %723
  %727 = add nuw <4 x i32> %726, <i32 32, i32 32, i32 32, i32 32>
  %728 = lshr <4 x i32> %727, <i32 6, i32 6, i32 6, i32 6>
  %729 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %718, <4 x i32> %728) #5
  %730 = lshr <8 x i16> %729, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %731 = getelementptr inbounds i16, i16* %9, i64 184
  %732 = bitcast i16* %731 to <8 x i16>*
  %733 = load <8 x i16>, <8 x i16>* %732, align 16
  %734 = getelementptr inbounds i16, i16* %10, i64 184
  %735 = bitcast i16* %734 to <8 x i16>*
  %736 = load <8 x i16>, <8 x i16>* %735, align 16
  %737 = shufflevector <8 x i16> %733, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %738 = zext <4 x i16> %737 to <4 x i32>
  %739 = shufflevector <8 x i16> %736, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %740 = zext <4 x i16> %739 to <4 x i32>
  %741 = sub nsw <4 x i32> %738, %740
  %742 = sub nsw <4 x i32> zeroinitializer, %741
  %743 = icmp slt <4 x i32> %741, zeroinitializer
  %744 = select <4 x i1> %743, <4 x i32> %742, <4 x i32> %741
  %745 = add nuw nsw <4 x i32> %744, <i32 32, i32 32, i32 32, i32 32>
  %746 = lshr <4 x i32> %745, <i32 6, i32 6, i32 6, i32 6>
  %747 = shufflevector <8 x i16> %733, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %748 = shufflevector <8 x i16> %736, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %749 = bitcast <8 x i16> %747 to <4 x i32>
  %750 = bitcast <8 x i16> %748 to <4 x i32>
  %751 = sub <4 x i32> %749, %750
  %752 = sub <4 x i32> zeroinitializer, %751
  %753 = icmp slt <4 x i32> %751, zeroinitializer
  %754 = select <4 x i1> %753, <4 x i32> %752, <4 x i32> %751
  %755 = add nuw <4 x i32> %754, <i32 32, i32 32, i32 32, i32 32>
  %756 = lshr <4 x i32> %755, <i32 6, i32 6, i32 6, i32 6>
  %757 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %746, <4 x i32> %756) #5
  %758 = lshr <8 x i16> %757, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %759 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %730, <8 x i16> %758) #5
  %760 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %759, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %761 = icmp slt <16 x i8> %760, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %762 = select <16 x i1> %761, <16 x i8> %760, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %763 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %762
  %764 = bitcast i8* %704 to <16 x i8>*
  store <16 x i8> %763, <16 x i8>* %764, align 16
  %765 = getelementptr inbounds i16, i16* %9, i64 192
  %766 = getelementptr inbounds i16, i16* %10, i64 192
  %767 = getelementptr inbounds i8, i8* %515, i64 %3
  %768 = bitcast i16* %765 to <8 x i16>*
  %769 = load <8 x i16>, <8 x i16>* %768, align 16
  %770 = bitcast i16* %766 to <8 x i16>*
  %771 = load <8 x i16>, <8 x i16>* %770, align 16
  %772 = shufflevector <8 x i16> %769, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %773 = zext <4 x i16> %772 to <4 x i32>
  %774 = shufflevector <8 x i16> %771, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %775 = zext <4 x i16> %774 to <4 x i32>
  %776 = sub nsw <4 x i32> %773, %775
  %777 = sub nsw <4 x i32> zeroinitializer, %776
  %778 = icmp slt <4 x i32> %776, zeroinitializer
  %779 = select <4 x i1> %778, <4 x i32> %777, <4 x i32> %776
  %780 = add nuw nsw <4 x i32> %779, <i32 32, i32 32, i32 32, i32 32>
  %781 = lshr <4 x i32> %780, <i32 6, i32 6, i32 6, i32 6>
  %782 = shufflevector <8 x i16> %769, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %783 = shufflevector <8 x i16> %771, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %784 = bitcast <8 x i16> %782 to <4 x i32>
  %785 = bitcast <8 x i16> %783 to <4 x i32>
  %786 = sub <4 x i32> %784, %785
  %787 = sub <4 x i32> zeroinitializer, %786
  %788 = icmp slt <4 x i32> %786, zeroinitializer
  %789 = select <4 x i1> %788, <4 x i32> %787, <4 x i32> %786
  %790 = add nuw <4 x i32> %789, <i32 32, i32 32, i32 32, i32 32>
  %791 = lshr <4 x i32> %790, <i32 6, i32 6, i32 6, i32 6>
  %792 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %781, <4 x i32> %791) #5
  %793 = lshr <8 x i16> %792, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %794 = getelementptr inbounds i16, i16* %9, i64 200
  %795 = bitcast i16* %794 to <8 x i16>*
  %796 = load <8 x i16>, <8 x i16>* %795, align 16
  %797 = getelementptr inbounds i16, i16* %10, i64 200
  %798 = bitcast i16* %797 to <8 x i16>*
  %799 = load <8 x i16>, <8 x i16>* %798, align 16
  %800 = shufflevector <8 x i16> %796, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %801 = zext <4 x i16> %800 to <4 x i32>
  %802 = shufflevector <8 x i16> %799, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %803 = zext <4 x i16> %802 to <4 x i32>
  %804 = sub nsw <4 x i32> %801, %803
  %805 = sub nsw <4 x i32> zeroinitializer, %804
  %806 = icmp slt <4 x i32> %804, zeroinitializer
  %807 = select <4 x i1> %806, <4 x i32> %805, <4 x i32> %804
  %808 = add nuw nsw <4 x i32> %807, <i32 32, i32 32, i32 32, i32 32>
  %809 = lshr <4 x i32> %808, <i32 6, i32 6, i32 6, i32 6>
  %810 = shufflevector <8 x i16> %796, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %811 = shufflevector <8 x i16> %799, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %812 = bitcast <8 x i16> %810 to <4 x i32>
  %813 = bitcast <8 x i16> %811 to <4 x i32>
  %814 = sub <4 x i32> %812, %813
  %815 = sub <4 x i32> zeroinitializer, %814
  %816 = icmp slt <4 x i32> %814, zeroinitializer
  %817 = select <4 x i1> %816, <4 x i32> %815, <4 x i32> %814
  %818 = add nuw <4 x i32> %817, <i32 32, i32 32, i32 32, i32 32>
  %819 = lshr <4 x i32> %818, <i32 6, i32 6, i32 6, i32 6>
  %820 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %809, <4 x i32> %819) #5
  %821 = lshr <8 x i16> %820, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %822 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %793, <8 x i16> %821) #5
  %823 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %822, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %824 = icmp slt <16 x i8> %823, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %825 = select <16 x i1> %824, <16 x i8> %823, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %826 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %825
  %827 = bitcast i8* %767 to <16 x i8>*
  store <16 x i8> %826, <16 x i8>* %827, align 16
  %828 = getelementptr inbounds i16, i16* %9, i64 208
  %829 = getelementptr inbounds i16, i16* %10, i64 208
  %830 = getelementptr inbounds i8, i8* %767, i64 16
  %831 = bitcast i16* %828 to <8 x i16>*
  %832 = load <8 x i16>, <8 x i16>* %831, align 16
  %833 = bitcast i16* %829 to <8 x i16>*
  %834 = load <8 x i16>, <8 x i16>* %833, align 16
  %835 = shufflevector <8 x i16> %832, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %836 = zext <4 x i16> %835 to <4 x i32>
  %837 = shufflevector <8 x i16> %834, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %838 = zext <4 x i16> %837 to <4 x i32>
  %839 = sub nsw <4 x i32> %836, %838
  %840 = sub nsw <4 x i32> zeroinitializer, %839
  %841 = icmp slt <4 x i32> %839, zeroinitializer
  %842 = select <4 x i1> %841, <4 x i32> %840, <4 x i32> %839
  %843 = add nuw nsw <4 x i32> %842, <i32 32, i32 32, i32 32, i32 32>
  %844 = lshr <4 x i32> %843, <i32 6, i32 6, i32 6, i32 6>
  %845 = shufflevector <8 x i16> %832, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %846 = shufflevector <8 x i16> %834, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %847 = bitcast <8 x i16> %845 to <4 x i32>
  %848 = bitcast <8 x i16> %846 to <4 x i32>
  %849 = sub <4 x i32> %847, %848
  %850 = sub <4 x i32> zeroinitializer, %849
  %851 = icmp slt <4 x i32> %849, zeroinitializer
  %852 = select <4 x i1> %851, <4 x i32> %850, <4 x i32> %849
  %853 = add nuw <4 x i32> %852, <i32 32, i32 32, i32 32, i32 32>
  %854 = lshr <4 x i32> %853, <i32 6, i32 6, i32 6, i32 6>
  %855 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %844, <4 x i32> %854) #5
  %856 = lshr <8 x i16> %855, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %857 = getelementptr inbounds i16, i16* %9, i64 216
  %858 = bitcast i16* %857 to <8 x i16>*
  %859 = load <8 x i16>, <8 x i16>* %858, align 16
  %860 = getelementptr inbounds i16, i16* %10, i64 216
  %861 = bitcast i16* %860 to <8 x i16>*
  %862 = load <8 x i16>, <8 x i16>* %861, align 16
  %863 = shufflevector <8 x i16> %859, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %864 = zext <4 x i16> %863 to <4 x i32>
  %865 = shufflevector <8 x i16> %862, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %866 = zext <4 x i16> %865 to <4 x i32>
  %867 = sub nsw <4 x i32> %864, %866
  %868 = sub nsw <4 x i32> zeroinitializer, %867
  %869 = icmp slt <4 x i32> %867, zeroinitializer
  %870 = select <4 x i1> %869, <4 x i32> %868, <4 x i32> %867
  %871 = add nuw nsw <4 x i32> %870, <i32 32, i32 32, i32 32, i32 32>
  %872 = lshr <4 x i32> %871, <i32 6, i32 6, i32 6, i32 6>
  %873 = shufflevector <8 x i16> %859, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %874 = shufflevector <8 x i16> %862, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %875 = bitcast <8 x i16> %873 to <4 x i32>
  %876 = bitcast <8 x i16> %874 to <4 x i32>
  %877 = sub <4 x i32> %875, %876
  %878 = sub <4 x i32> zeroinitializer, %877
  %879 = icmp slt <4 x i32> %877, zeroinitializer
  %880 = select <4 x i1> %879, <4 x i32> %878, <4 x i32> %877
  %881 = add nuw <4 x i32> %880, <i32 32, i32 32, i32 32, i32 32>
  %882 = lshr <4 x i32> %881, <i32 6, i32 6, i32 6, i32 6>
  %883 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %872, <4 x i32> %882) #5
  %884 = lshr <8 x i16> %883, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %885 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %856, <8 x i16> %884) #5
  %886 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %885, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %887 = icmp slt <16 x i8> %886, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %888 = select <16 x i1> %887, <16 x i8> %886, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %889 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %888
  %890 = bitcast i8* %830 to <16 x i8>*
  store <16 x i8> %889, <16 x i8>* %890, align 16
  %891 = getelementptr inbounds i16, i16* %9, i64 224
  %892 = getelementptr inbounds i16, i16* %10, i64 224
  %893 = getelementptr inbounds i8, i8* %767, i64 32
  %894 = bitcast i16* %891 to <8 x i16>*
  %895 = load <8 x i16>, <8 x i16>* %894, align 16
  %896 = bitcast i16* %892 to <8 x i16>*
  %897 = load <8 x i16>, <8 x i16>* %896, align 16
  %898 = shufflevector <8 x i16> %895, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %899 = zext <4 x i16> %898 to <4 x i32>
  %900 = shufflevector <8 x i16> %897, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %901 = zext <4 x i16> %900 to <4 x i32>
  %902 = sub nsw <4 x i32> %899, %901
  %903 = sub nsw <4 x i32> zeroinitializer, %902
  %904 = icmp slt <4 x i32> %902, zeroinitializer
  %905 = select <4 x i1> %904, <4 x i32> %903, <4 x i32> %902
  %906 = add nuw nsw <4 x i32> %905, <i32 32, i32 32, i32 32, i32 32>
  %907 = lshr <4 x i32> %906, <i32 6, i32 6, i32 6, i32 6>
  %908 = shufflevector <8 x i16> %895, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %909 = shufflevector <8 x i16> %897, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %910 = bitcast <8 x i16> %908 to <4 x i32>
  %911 = bitcast <8 x i16> %909 to <4 x i32>
  %912 = sub <4 x i32> %910, %911
  %913 = sub <4 x i32> zeroinitializer, %912
  %914 = icmp slt <4 x i32> %912, zeroinitializer
  %915 = select <4 x i1> %914, <4 x i32> %913, <4 x i32> %912
  %916 = add nuw <4 x i32> %915, <i32 32, i32 32, i32 32, i32 32>
  %917 = lshr <4 x i32> %916, <i32 6, i32 6, i32 6, i32 6>
  %918 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %907, <4 x i32> %917) #5
  %919 = lshr <8 x i16> %918, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %920 = getelementptr inbounds i16, i16* %9, i64 232
  %921 = bitcast i16* %920 to <8 x i16>*
  %922 = load <8 x i16>, <8 x i16>* %921, align 16
  %923 = getelementptr inbounds i16, i16* %10, i64 232
  %924 = bitcast i16* %923 to <8 x i16>*
  %925 = load <8 x i16>, <8 x i16>* %924, align 16
  %926 = shufflevector <8 x i16> %922, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %927 = zext <4 x i16> %926 to <4 x i32>
  %928 = shufflevector <8 x i16> %925, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %929 = zext <4 x i16> %928 to <4 x i32>
  %930 = sub nsw <4 x i32> %927, %929
  %931 = sub nsw <4 x i32> zeroinitializer, %930
  %932 = icmp slt <4 x i32> %930, zeroinitializer
  %933 = select <4 x i1> %932, <4 x i32> %931, <4 x i32> %930
  %934 = add nuw nsw <4 x i32> %933, <i32 32, i32 32, i32 32, i32 32>
  %935 = lshr <4 x i32> %934, <i32 6, i32 6, i32 6, i32 6>
  %936 = shufflevector <8 x i16> %922, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %937 = shufflevector <8 x i16> %925, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %938 = bitcast <8 x i16> %936 to <4 x i32>
  %939 = bitcast <8 x i16> %937 to <4 x i32>
  %940 = sub <4 x i32> %938, %939
  %941 = sub <4 x i32> zeroinitializer, %940
  %942 = icmp slt <4 x i32> %940, zeroinitializer
  %943 = select <4 x i1> %942, <4 x i32> %941, <4 x i32> %940
  %944 = add nuw <4 x i32> %943, <i32 32, i32 32, i32 32, i32 32>
  %945 = lshr <4 x i32> %944, <i32 6, i32 6, i32 6, i32 6>
  %946 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %935, <4 x i32> %945) #5
  %947 = lshr <8 x i16> %946, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %948 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %919, <8 x i16> %947) #5
  %949 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %948, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %950 = icmp slt <16 x i8> %949, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %951 = select <16 x i1> %950, <16 x i8> %949, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %952 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %951
  %953 = bitcast i8* %893 to <16 x i8>*
  store <16 x i8> %952, <16 x i8>* %953, align 16
  %954 = getelementptr inbounds i16, i16* %9, i64 240
  %955 = getelementptr inbounds i16, i16* %10, i64 240
  %956 = getelementptr inbounds i8, i8* %767, i64 48
  %957 = bitcast i16* %954 to <8 x i16>*
  %958 = load <8 x i16>, <8 x i16>* %957, align 16
  %959 = bitcast i16* %955 to <8 x i16>*
  %960 = load <8 x i16>, <8 x i16>* %959, align 16
  %961 = shufflevector <8 x i16> %958, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %962 = zext <4 x i16> %961 to <4 x i32>
  %963 = shufflevector <8 x i16> %960, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %964 = zext <4 x i16> %963 to <4 x i32>
  %965 = sub nsw <4 x i32> %962, %964
  %966 = sub nsw <4 x i32> zeroinitializer, %965
  %967 = icmp slt <4 x i32> %965, zeroinitializer
  %968 = select <4 x i1> %967, <4 x i32> %966, <4 x i32> %965
  %969 = add nuw nsw <4 x i32> %968, <i32 32, i32 32, i32 32, i32 32>
  %970 = lshr <4 x i32> %969, <i32 6, i32 6, i32 6, i32 6>
  %971 = shufflevector <8 x i16> %958, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %972 = shufflevector <8 x i16> %960, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %973 = bitcast <8 x i16> %971 to <4 x i32>
  %974 = bitcast <8 x i16> %972 to <4 x i32>
  %975 = sub <4 x i32> %973, %974
  %976 = sub <4 x i32> zeroinitializer, %975
  %977 = icmp slt <4 x i32> %975, zeroinitializer
  %978 = select <4 x i1> %977, <4 x i32> %976, <4 x i32> %975
  %979 = add nuw <4 x i32> %978, <i32 32, i32 32, i32 32, i32 32>
  %980 = lshr <4 x i32> %979, <i32 6, i32 6, i32 6, i32 6>
  %981 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %970, <4 x i32> %980) #5
  %982 = lshr <8 x i16> %981, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %983 = getelementptr inbounds i16, i16* %9, i64 248
  %984 = bitcast i16* %983 to <8 x i16>*
  %985 = load <8 x i16>, <8 x i16>* %984, align 16
  %986 = getelementptr inbounds i16, i16* %10, i64 248
  %987 = bitcast i16* %986 to <8 x i16>*
  %988 = load <8 x i16>, <8 x i16>* %987, align 16
  %989 = shufflevector <8 x i16> %985, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %990 = zext <4 x i16> %989 to <4 x i32>
  %991 = shufflevector <8 x i16> %988, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %992 = zext <4 x i16> %991 to <4 x i32>
  %993 = sub nsw <4 x i32> %990, %992
  %994 = sub nsw <4 x i32> zeroinitializer, %993
  %995 = icmp slt <4 x i32> %993, zeroinitializer
  %996 = select <4 x i1> %995, <4 x i32> %994, <4 x i32> %993
  %997 = add nuw nsw <4 x i32> %996, <i32 32, i32 32, i32 32, i32 32>
  %998 = lshr <4 x i32> %997, <i32 6, i32 6, i32 6, i32 6>
  %999 = shufflevector <8 x i16> %985, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1000 = shufflevector <8 x i16> %988, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1001 = bitcast <8 x i16> %999 to <4 x i32>
  %1002 = bitcast <8 x i16> %1000 to <4 x i32>
  %1003 = sub <4 x i32> %1001, %1002
  %1004 = sub <4 x i32> zeroinitializer, %1003
  %1005 = icmp slt <4 x i32> %1003, zeroinitializer
  %1006 = select <4 x i1> %1005, <4 x i32> %1004, <4 x i32> %1003
  %1007 = add nuw <4 x i32> %1006, <i32 32, i32 32, i32 32, i32 32>
  %1008 = lshr <4 x i32> %1007, <i32 6, i32 6, i32 6, i32 6>
  %1009 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %998, <4 x i32> %1008) #5
  %1010 = lshr <8 x i16> %1009, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1011 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %982, <8 x i16> %1010) #5
  %1012 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1011, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1013 = icmp slt <16 x i8> %1012, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1014 = select <16 x i1> %1013, <16 x i8> %1012, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1015 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1014
  %1016 = bitcast i8* %956 to <16 x i8>*
  store <16 x i8> %1015, <16 x i8>* %1016, align 16
  %1017 = getelementptr inbounds i16, i16* %9, i64 256
  %1018 = getelementptr inbounds i16, i16* %10, i64 256
  %1019 = getelementptr inbounds i8, i8* %767, i64 %3
  %1020 = bitcast i16* %1017 to <8 x i16>*
  %1021 = load <8 x i16>, <8 x i16>* %1020, align 16
  %1022 = bitcast i16* %1018 to <8 x i16>*
  %1023 = load <8 x i16>, <8 x i16>* %1022, align 16
  %1024 = shufflevector <8 x i16> %1021, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1025 = zext <4 x i16> %1024 to <4 x i32>
  %1026 = shufflevector <8 x i16> %1023, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1027 = zext <4 x i16> %1026 to <4 x i32>
  %1028 = sub nsw <4 x i32> %1025, %1027
  %1029 = sub nsw <4 x i32> zeroinitializer, %1028
  %1030 = icmp slt <4 x i32> %1028, zeroinitializer
  %1031 = select <4 x i1> %1030, <4 x i32> %1029, <4 x i32> %1028
  %1032 = add nuw nsw <4 x i32> %1031, <i32 32, i32 32, i32 32, i32 32>
  %1033 = lshr <4 x i32> %1032, <i32 6, i32 6, i32 6, i32 6>
  %1034 = shufflevector <8 x i16> %1021, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1035 = shufflevector <8 x i16> %1023, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1036 = bitcast <8 x i16> %1034 to <4 x i32>
  %1037 = bitcast <8 x i16> %1035 to <4 x i32>
  %1038 = sub <4 x i32> %1036, %1037
  %1039 = sub <4 x i32> zeroinitializer, %1038
  %1040 = icmp slt <4 x i32> %1038, zeroinitializer
  %1041 = select <4 x i1> %1040, <4 x i32> %1039, <4 x i32> %1038
  %1042 = add nuw <4 x i32> %1041, <i32 32, i32 32, i32 32, i32 32>
  %1043 = lshr <4 x i32> %1042, <i32 6, i32 6, i32 6, i32 6>
  %1044 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1033, <4 x i32> %1043) #5
  %1045 = lshr <8 x i16> %1044, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1046 = getelementptr inbounds i16, i16* %9, i64 264
  %1047 = bitcast i16* %1046 to <8 x i16>*
  %1048 = load <8 x i16>, <8 x i16>* %1047, align 16
  %1049 = getelementptr inbounds i16, i16* %10, i64 264
  %1050 = bitcast i16* %1049 to <8 x i16>*
  %1051 = load <8 x i16>, <8 x i16>* %1050, align 16
  %1052 = shufflevector <8 x i16> %1048, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1053 = zext <4 x i16> %1052 to <4 x i32>
  %1054 = shufflevector <8 x i16> %1051, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1055 = zext <4 x i16> %1054 to <4 x i32>
  %1056 = sub nsw <4 x i32> %1053, %1055
  %1057 = sub nsw <4 x i32> zeroinitializer, %1056
  %1058 = icmp slt <4 x i32> %1056, zeroinitializer
  %1059 = select <4 x i1> %1058, <4 x i32> %1057, <4 x i32> %1056
  %1060 = add nuw nsw <4 x i32> %1059, <i32 32, i32 32, i32 32, i32 32>
  %1061 = lshr <4 x i32> %1060, <i32 6, i32 6, i32 6, i32 6>
  %1062 = shufflevector <8 x i16> %1048, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1063 = shufflevector <8 x i16> %1051, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1064 = bitcast <8 x i16> %1062 to <4 x i32>
  %1065 = bitcast <8 x i16> %1063 to <4 x i32>
  %1066 = sub <4 x i32> %1064, %1065
  %1067 = sub <4 x i32> zeroinitializer, %1066
  %1068 = icmp slt <4 x i32> %1066, zeroinitializer
  %1069 = select <4 x i1> %1068, <4 x i32> %1067, <4 x i32> %1066
  %1070 = add nuw <4 x i32> %1069, <i32 32, i32 32, i32 32, i32 32>
  %1071 = lshr <4 x i32> %1070, <i32 6, i32 6, i32 6, i32 6>
  %1072 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1061, <4 x i32> %1071) #5
  %1073 = lshr <8 x i16> %1072, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1074 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1045, <8 x i16> %1073) #5
  %1075 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1074, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1076 = icmp slt <16 x i8> %1075, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1077 = select <16 x i1> %1076, <16 x i8> %1075, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1078 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1077
  %1079 = bitcast i8* %1019 to <16 x i8>*
  store <16 x i8> %1078, <16 x i8>* %1079, align 16
  %1080 = getelementptr inbounds i16, i16* %9, i64 272
  %1081 = getelementptr inbounds i16, i16* %10, i64 272
  %1082 = getelementptr inbounds i8, i8* %1019, i64 16
  %1083 = bitcast i16* %1080 to <8 x i16>*
  %1084 = load <8 x i16>, <8 x i16>* %1083, align 16
  %1085 = bitcast i16* %1081 to <8 x i16>*
  %1086 = load <8 x i16>, <8 x i16>* %1085, align 16
  %1087 = shufflevector <8 x i16> %1084, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1088 = zext <4 x i16> %1087 to <4 x i32>
  %1089 = shufflevector <8 x i16> %1086, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1090 = zext <4 x i16> %1089 to <4 x i32>
  %1091 = sub nsw <4 x i32> %1088, %1090
  %1092 = sub nsw <4 x i32> zeroinitializer, %1091
  %1093 = icmp slt <4 x i32> %1091, zeroinitializer
  %1094 = select <4 x i1> %1093, <4 x i32> %1092, <4 x i32> %1091
  %1095 = add nuw nsw <4 x i32> %1094, <i32 32, i32 32, i32 32, i32 32>
  %1096 = lshr <4 x i32> %1095, <i32 6, i32 6, i32 6, i32 6>
  %1097 = shufflevector <8 x i16> %1084, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1098 = shufflevector <8 x i16> %1086, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1099 = bitcast <8 x i16> %1097 to <4 x i32>
  %1100 = bitcast <8 x i16> %1098 to <4 x i32>
  %1101 = sub <4 x i32> %1099, %1100
  %1102 = sub <4 x i32> zeroinitializer, %1101
  %1103 = icmp slt <4 x i32> %1101, zeroinitializer
  %1104 = select <4 x i1> %1103, <4 x i32> %1102, <4 x i32> %1101
  %1105 = add nuw <4 x i32> %1104, <i32 32, i32 32, i32 32, i32 32>
  %1106 = lshr <4 x i32> %1105, <i32 6, i32 6, i32 6, i32 6>
  %1107 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1096, <4 x i32> %1106) #5
  %1108 = lshr <8 x i16> %1107, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1109 = getelementptr inbounds i16, i16* %9, i64 280
  %1110 = bitcast i16* %1109 to <8 x i16>*
  %1111 = load <8 x i16>, <8 x i16>* %1110, align 16
  %1112 = getelementptr inbounds i16, i16* %10, i64 280
  %1113 = bitcast i16* %1112 to <8 x i16>*
  %1114 = load <8 x i16>, <8 x i16>* %1113, align 16
  %1115 = shufflevector <8 x i16> %1111, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1116 = zext <4 x i16> %1115 to <4 x i32>
  %1117 = shufflevector <8 x i16> %1114, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1118 = zext <4 x i16> %1117 to <4 x i32>
  %1119 = sub nsw <4 x i32> %1116, %1118
  %1120 = sub nsw <4 x i32> zeroinitializer, %1119
  %1121 = icmp slt <4 x i32> %1119, zeroinitializer
  %1122 = select <4 x i1> %1121, <4 x i32> %1120, <4 x i32> %1119
  %1123 = add nuw nsw <4 x i32> %1122, <i32 32, i32 32, i32 32, i32 32>
  %1124 = lshr <4 x i32> %1123, <i32 6, i32 6, i32 6, i32 6>
  %1125 = shufflevector <8 x i16> %1111, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1126 = shufflevector <8 x i16> %1114, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1127 = bitcast <8 x i16> %1125 to <4 x i32>
  %1128 = bitcast <8 x i16> %1126 to <4 x i32>
  %1129 = sub <4 x i32> %1127, %1128
  %1130 = sub <4 x i32> zeroinitializer, %1129
  %1131 = icmp slt <4 x i32> %1129, zeroinitializer
  %1132 = select <4 x i1> %1131, <4 x i32> %1130, <4 x i32> %1129
  %1133 = add nuw <4 x i32> %1132, <i32 32, i32 32, i32 32, i32 32>
  %1134 = lshr <4 x i32> %1133, <i32 6, i32 6, i32 6, i32 6>
  %1135 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1124, <4 x i32> %1134) #5
  %1136 = lshr <8 x i16> %1135, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1137 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1108, <8 x i16> %1136) #5
  %1138 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1137, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1139 = icmp slt <16 x i8> %1138, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1140 = select <16 x i1> %1139, <16 x i8> %1138, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1141 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1140
  %1142 = bitcast i8* %1082 to <16 x i8>*
  store <16 x i8> %1141, <16 x i8>* %1142, align 16
  %1143 = getelementptr inbounds i16, i16* %9, i64 288
  %1144 = getelementptr inbounds i16, i16* %10, i64 288
  %1145 = getelementptr inbounds i8, i8* %1019, i64 32
  %1146 = bitcast i16* %1143 to <8 x i16>*
  %1147 = load <8 x i16>, <8 x i16>* %1146, align 16
  %1148 = bitcast i16* %1144 to <8 x i16>*
  %1149 = load <8 x i16>, <8 x i16>* %1148, align 16
  %1150 = shufflevector <8 x i16> %1147, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1151 = zext <4 x i16> %1150 to <4 x i32>
  %1152 = shufflevector <8 x i16> %1149, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1153 = zext <4 x i16> %1152 to <4 x i32>
  %1154 = sub nsw <4 x i32> %1151, %1153
  %1155 = sub nsw <4 x i32> zeroinitializer, %1154
  %1156 = icmp slt <4 x i32> %1154, zeroinitializer
  %1157 = select <4 x i1> %1156, <4 x i32> %1155, <4 x i32> %1154
  %1158 = add nuw nsw <4 x i32> %1157, <i32 32, i32 32, i32 32, i32 32>
  %1159 = lshr <4 x i32> %1158, <i32 6, i32 6, i32 6, i32 6>
  %1160 = shufflevector <8 x i16> %1147, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1161 = shufflevector <8 x i16> %1149, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1162 = bitcast <8 x i16> %1160 to <4 x i32>
  %1163 = bitcast <8 x i16> %1161 to <4 x i32>
  %1164 = sub <4 x i32> %1162, %1163
  %1165 = sub <4 x i32> zeroinitializer, %1164
  %1166 = icmp slt <4 x i32> %1164, zeroinitializer
  %1167 = select <4 x i1> %1166, <4 x i32> %1165, <4 x i32> %1164
  %1168 = add nuw <4 x i32> %1167, <i32 32, i32 32, i32 32, i32 32>
  %1169 = lshr <4 x i32> %1168, <i32 6, i32 6, i32 6, i32 6>
  %1170 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1159, <4 x i32> %1169) #5
  %1171 = lshr <8 x i16> %1170, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1172 = getelementptr inbounds i16, i16* %9, i64 296
  %1173 = bitcast i16* %1172 to <8 x i16>*
  %1174 = load <8 x i16>, <8 x i16>* %1173, align 16
  %1175 = getelementptr inbounds i16, i16* %10, i64 296
  %1176 = bitcast i16* %1175 to <8 x i16>*
  %1177 = load <8 x i16>, <8 x i16>* %1176, align 16
  %1178 = shufflevector <8 x i16> %1174, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1179 = zext <4 x i16> %1178 to <4 x i32>
  %1180 = shufflevector <8 x i16> %1177, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1181 = zext <4 x i16> %1180 to <4 x i32>
  %1182 = sub nsw <4 x i32> %1179, %1181
  %1183 = sub nsw <4 x i32> zeroinitializer, %1182
  %1184 = icmp slt <4 x i32> %1182, zeroinitializer
  %1185 = select <4 x i1> %1184, <4 x i32> %1183, <4 x i32> %1182
  %1186 = add nuw nsw <4 x i32> %1185, <i32 32, i32 32, i32 32, i32 32>
  %1187 = lshr <4 x i32> %1186, <i32 6, i32 6, i32 6, i32 6>
  %1188 = shufflevector <8 x i16> %1174, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1189 = shufflevector <8 x i16> %1177, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1190 = bitcast <8 x i16> %1188 to <4 x i32>
  %1191 = bitcast <8 x i16> %1189 to <4 x i32>
  %1192 = sub <4 x i32> %1190, %1191
  %1193 = sub <4 x i32> zeroinitializer, %1192
  %1194 = icmp slt <4 x i32> %1192, zeroinitializer
  %1195 = select <4 x i1> %1194, <4 x i32> %1193, <4 x i32> %1192
  %1196 = add nuw <4 x i32> %1195, <i32 32, i32 32, i32 32, i32 32>
  %1197 = lshr <4 x i32> %1196, <i32 6, i32 6, i32 6, i32 6>
  %1198 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1187, <4 x i32> %1197) #5
  %1199 = lshr <8 x i16> %1198, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1200 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1171, <8 x i16> %1199) #5
  %1201 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1200, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1202 = icmp slt <16 x i8> %1201, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1203 = select <16 x i1> %1202, <16 x i8> %1201, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1204 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1203
  %1205 = bitcast i8* %1145 to <16 x i8>*
  store <16 x i8> %1204, <16 x i8>* %1205, align 16
  %1206 = getelementptr inbounds i16, i16* %9, i64 304
  %1207 = getelementptr inbounds i16, i16* %10, i64 304
  %1208 = getelementptr inbounds i8, i8* %1019, i64 48
  %1209 = bitcast i16* %1206 to <8 x i16>*
  %1210 = load <8 x i16>, <8 x i16>* %1209, align 16
  %1211 = bitcast i16* %1207 to <8 x i16>*
  %1212 = load <8 x i16>, <8 x i16>* %1211, align 16
  %1213 = shufflevector <8 x i16> %1210, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1214 = zext <4 x i16> %1213 to <4 x i32>
  %1215 = shufflevector <8 x i16> %1212, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1216 = zext <4 x i16> %1215 to <4 x i32>
  %1217 = sub nsw <4 x i32> %1214, %1216
  %1218 = sub nsw <4 x i32> zeroinitializer, %1217
  %1219 = icmp slt <4 x i32> %1217, zeroinitializer
  %1220 = select <4 x i1> %1219, <4 x i32> %1218, <4 x i32> %1217
  %1221 = add nuw nsw <4 x i32> %1220, <i32 32, i32 32, i32 32, i32 32>
  %1222 = lshr <4 x i32> %1221, <i32 6, i32 6, i32 6, i32 6>
  %1223 = shufflevector <8 x i16> %1210, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1224 = shufflevector <8 x i16> %1212, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1225 = bitcast <8 x i16> %1223 to <4 x i32>
  %1226 = bitcast <8 x i16> %1224 to <4 x i32>
  %1227 = sub <4 x i32> %1225, %1226
  %1228 = sub <4 x i32> zeroinitializer, %1227
  %1229 = icmp slt <4 x i32> %1227, zeroinitializer
  %1230 = select <4 x i1> %1229, <4 x i32> %1228, <4 x i32> %1227
  %1231 = add nuw <4 x i32> %1230, <i32 32, i32 32, i32 32, i32 32>
  %1232 = lshr <4 x i32> %1231, <i32 6, i32 6, i32 6, i32 6>
  %1233 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1222, <4 x i32> %1232) #5
  %1234 = lshr <8 x i16> %1233, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1235 = getelementptr inbounds i16, i16* %9, i64 312
  %1236 = bitcast i16* %1235 to <8 x i16>*
  %1237 = load <8 x i16>, <8 x i16>* %1236, align 16
  %1238 = getelementptr inbounds i16, i16* %10, i64 312
  %1239 = bitcast i16* %1238 to <8 x i16>*
  %1240 = load <8 x i16>, <8 x i16>* %1239, align 16
  %1241 = shufflevector <8 x i16> %1237, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1242 = zext <4 x i16> %1241 to <4 x i32>
  %1243 = shufflevector <8 x i16> %1240, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1244 = zext <4 x i16> %1243 to <4 x i32>
  %1245 = sub nsw <4 x i32> %1242, %1244
  %1246 = sub nsw <4 x i32> zeroinitializer, %1245
  %1247 = icmp slt <4 x i32> %1245, zeroinitializer
  %1248 = select <4 x i1> %1247, <4 x i32> %1246, <4 x i32> %1245
  %1249 = add nuw nsw <4 x i32> %1248, <i32 32, i32 32, i32 32, i32 32>
  %1250 = lshr <4 x i32> %1249, <i32 6, i32 6, i32 6, i32 6>
  %1251 = shufflevector <8 x i16> %1237, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1252 = shufflevector <8 x i16> %1240, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1253 = bitcast <8 x i16> %1251 to <4 x i32>
  %1254 = bitcast <8 x i16> %1252 to <4 x i32>
  %1255 = sub <4 x i32> %1253, %1254
  %1256 = sub <4 x i32> zeroinitializer, %1255
  %1257 = icmp slt <4 x i32> %1255, zeroinitializer
  %1258 = select <4 x i1> %1257, <4 x i32> %1256, <4 x i32> %1255
  %1259 = add nuw <4 x i32> %1258, <i32 32, i32 32, i32 32, i32 32>
  %1260 = lshr <4 x i32> %1259, <i32 6, i32 6, i32 6, i32 6>
  %1261 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1250, <4 x i32> %1260) #5
  %1262 = lshr <8 x i16> %1261, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1263 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1234, <8 x i16> %1262) #5
  %1264 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1263, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1265 = icmp slt <16 x i8> %1264, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1266 = select <16 x i1> %1265, <16 x i8> %1264, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1267 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1266
  %1268 = bitcast i8* %1208 to <16 x i8>*
  store <16 x i8> %1267, <16 x i8>* %1268, align 16
  %1269 = getelementptr inbounds i16, i16* %9, i64 320
  %1270 = getelementptr inbounds i16, i16* %10, i64 320
  %1271 = getelementptr inbounds i8, i8* %1019, i64 %3
  %1272 = add nsw i32 %11, -1
  %1273 = icmp eq i32 %1272, 0
  br i1 %1273, label %1274, label %7

1274:                                             ; preds = %7
  %1275 = bitcast i16* %1269 to <8 x i16>*
  %1276 = load <8 x i16>, <8 x i16>* %1275, align 16
  %1277 = bitcast i16* %1270 to <8 x i16>*
  %1278 = load <8 x i16>, <8 x i16>* %1277, align 16
  %1279 = shufflevector <8 x i16> %1276, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1280 = zext <4 x i16> %1279 to <4 x i32>
  %1281 = shufflevector <8 x i16> %1278, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1282 = zext <4 x i16> %1281 to <4 x i32>
  %1283 = sub nsw <4 x i32> %1280, %1282
  %1284 = sub nsw <4 x i32> zeroinitializer, %1283
  %1285 = icmp slt <4 x i32> %1283, zeroinitializer
  %1286 = select <4 x i1> %1285, <4 x i32> %1284, <4 x i32> %1283
  %1287 = add nuw nsw <4 x i32> %1286, <i32 32, i32 32, i32 32, i32 32>
  %1288 = lshr <4 x i32> %1287, <i32 6, i32 6, i32 6, i32 6>
  %1289 = shufflevector <8 x i16> %1276, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1290 = shufflevector <8 x i16> %1278, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1291 = bitcast <8 x i16> %1289 to <4 x i32>
  %1292 = bitcast <8 x i16> %1290 to <4 x i32>
  %1293 = sub <4 x i32> %1291, %1292
  %1294 = sub <4 x i32> zeroinitializer, %1293
  %1295 = icmp slt <4 x i32> %1293, zeroinitializer
  %1296 = select <4 x i1> %1295, <4 x i32> %1294, <4 x i32> %1293
  %1297 = add nuw <4 x i32> %1296, <i32 32, i32 32, i32 32, i32 32>
  %1298 = lshr <4 x i32> %1297, <i32 6, i32 6, i32 6, i32 6>
  %1299 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1288, <4 x i32> %1298) #5
  %1300 = lshr <8 x i16> %1299, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1301 = getelementptr inbounds i16, i16* %9, i64 328
  %1302 = bitcast i16* %1301 to <8 x i16>*
  %1303 = load <8 x i16>, <8 x i16>* %1302, align 16
  %1304 = getelementptr inbounds i16, i16* %10, i64 328
  %1305 = bitcast i16* %1304 to <8 x i16>*
  %1306 = load <8 x i16>, <8 x i16>* %1305, align 16
  %1307 = shufflevector <8 x i16> %1303, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1308 = zext <4 x i16> %1307 to <4 x i32>
  %1309 = shufflevector <8 x i16> %1306, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1310 = zext <4 x i16> %1309 to <4 x i32>
  %1311 = sub nsw <4 x i32> %1308, %1310
  %1312 = sub nsw <4 x i32> zeroinitializer, %1311
  %1313 = icmp slt <4 x i32> %1311, zeroinitializer
  %1314 = select <4 x i1> %1313, <4 x i32> %1312, <4 x i32> %1311
  %1315 = add nuw nsw <4 x i32> %1314, <i32 32, i32 32, i32 32, i32 32>
  %1316 = lshr <4 x i32> %1315, <i32 6, i32 6, i32 6, i32 6>
  %1317 = shufflevector <8 x i16> %1303, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1318 = shufflevector <8 x i16> %1306, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1319 = bitcast <8 x i16> %1317 to <4 x i32>
  %1320 = bitcast <8 x i16> %1318 to <4 x i32>
  %1321 = sub <4 x i32> %1319, %1320
  %1322 = sub <4 x i32> zeroinitializer, %1321
  %1323 = icmp slt <4 x i32> %1321, zeroinitializer
  %1324 = select <4 x i1> %1323, <4 x i32> %1322, <4 x i32> %1321
  %1325 = add nuw <4 x i32> %1324, <i32 32, i32 32, i32 32, i32 32>
  %1326 = lshr <4 x i32> %1325, <i32 6, i32 6, i32 6, i32 6>
  %1327 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1316, <4 x i32> %1326) #5
  %1328 = lshr <8 x i16> %1327, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1329 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1300, <8 x i16> %1328) #5
  %1330 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1329, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1331 = icmp slt <16 x i8> %1330, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1332 = select <16 x i1> %1331, <16 x i8> %1330, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1333 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1332
  %1334 = bitcast i8* %1271 to <16 x i8>*
  store <16 x i8> %1333, <16 x i8>* %1334, align 16
  %1335 = getelementptr inbounds i16, i16* %9, i64 336
  %1336 = getelementptr inbounds i16, i16* %10, i64 336
  %1337 = getelementptr inbounds i8, i8* %1271, i64 16
  %1338 = bitcast i16* %1335 to <8 x i16>*
  %1339 = load <8 x i16>, <8 x i16>* %1338, align 16
  %1340 = bitcast i16* %1336 to <8 x i16>*
  %1341 = load <8 x i16>, <8 x i16>* %1340, align 16
  %1342 = shufflevector <8 x i16> %1339, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1343 = zext <4 x i16> %1342 to <4 x i32>
  %1344 = shufflevector <8 x i16> %1341, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1345 = zext <4 x i16> %1344 to <4 x i32>
  %1346 = sub nsw <4 x i32> %1343, %1345
  %1347 = sub nsw <4 x i32> zeroinitializer, %1346
  %1348 = icmp slt <4 x i32> %1346, zeroinitializer
  %1349 = select <4 x i1> %1348, <4 x i32> %1347, <4 x i32> %1346
  %1350 = add nuw nsw <4 x i32> %1349, <i32 32, i32 32, i32 32, i32 32>
  %1351 = lshr <4 x i32> %1350, <i32 6, i32 6, i32 6, i32 6>
  %1352 = shufflevector <8 x i16> %1339, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1353 = shufflevector <8 x i16> %1341, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1354 = bitcast <8 x i16> %1352 to <4 x i32>
  %1355 = bitcast <8 x i16> %1353 to <4 x i32>
  %1356 = sub <4 x i32> %1354, %1355
  %1357 = sub <4 x i32> zeroinitializer, %1356
  %1358 = icmp slt <4 x i32> %1356, zeroinitializer
  %1359 = select <4 x i1> %1358, <4 x i32> %1357, <4 x i32> %1356
  %1360 = add nuw <4 x i32> %1359, <i32 32, i32 32, i32 32, i32 32>
  %1361 = lshr <4 x i32> %1360, <i32 6, i32 6, i32 6, i32 6>
  %1362 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1351, <4 x i32> %1361) #5
  %1363 = lshr <8 x i16> %1362, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1364 = getelementptr inbounds i16, i16* %9, i64 344
  %1365 = bitcast i16* %1364 to <8 x i16>*
  %1366 = load <8 x i16>, <8 x i16>* %1365, align 16
  %1367 = getelementptr inbounds i16, i16* %10, i64 344
  %1368 = bitcast i16* %1367 to <8 x i16>*
  %1369 = load <8 x i16>, <8 x i16>* %1368, align 16
  %1370 = shufflevector <8 x i16> %1366, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1371 = zext <4 x i16> %1370 to <4 x i32>
  %1372 = shufflevector <8 x i16> %1369, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1373 = zext <4 x i16> %1372 to <4 x i32>
  %1374 = sub nsw <4 x i32> %1371, %1373
  %1375 = sub nsw <4 x i32> zeroinitializer, %1374
  %1376 = icmp slt <4 x i32> %1374, zeroinitializer
  %1377 = select <4 x i1> %1376, <4 x i32> %1375, <4 x i32> %1374
  %1378 = add nuw nsw <4 x i32> %1377, <i32 32, i32 32, i32 32, i32 32>
  %1379 = lshr <4 x i32> %1378, <i32 6, i32 6, i32 6, i32 6>
  %1380 = shufflevector <8 x i16> %1366, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1381 = shufflevector <8 x i16> %1369, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1382 = bitcast <8 x i16> %1380 to <4 x i32>
  %1383 = bitcast <8 x i16> %1381 to <4 x i32>
  %1384 = sub <4 x i32> %1382, %1383
  %1385 = sub <4 x i32> zeroinitializer, %1384
  %1386 = icmp slt <4 x i32> %1384, zeroinitializer
  %1387 = select <4 x i1> %1386, <4 x i32> %1385, <4 x i32> %1384
  %1388 = add nuw <4 x i32> %1387, <i32 32, i32 32, i32 32, i32 32>
  %1389 = lshr <4 x i32> %1388, <i32 6, i32 6, i32 6, i32 6>
  %1390 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1379, <4 x i32> %1389) #5
  %1391 = lshr <8 x i16> %1390, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1392 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1363, <8 x i16> %1391) #5
  %1393 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1392, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1394 = icmp slt <16 x i8> %1393, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1395 = select <16 x i1> %1394, <16 x i8> %1393, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1396 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1395
  %1397 = bitcast i8* %1337 to <16 x i8>*
  store <16 x i8> %1396, <16 x i8>* %1397, align 16
  %1398 = getelementptr inbounds i16, i16* %9, i64 352
  %1399 = getelementptr inbounds i16, i16* %10, i64 352
  %1400 = getelementptr inbounds i8, i8* %1271, i64 32
  %1401 = bitcast i16* %1398 to <8 x i16>*
  %1402 = load <8 x i16>, <8 x i16>* %1401, align 16
  %1403 = bitcast i16* %1399 to <8 x i16>*
  %1404 = load <8 x i16>, <8 x i16>* %1403, align 16
  %1405 = shufflevector <8 x i16> %1402, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1406 = zext <4 x i16> %1405 to <4 x i32>
  %1407 = shufflevector <8 x i16> %1404, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1408 = zext <4 x i16> %1407 to <4 x i32>
  %1409 = sub nsw <4 x i32> %1406, %1408
  %1410 = sub nsw <4 x i32> zeroinitializer, %1409
  %1411 = icmp slt <4 x i32> %1409, zeroinitializer
  %1412 = select <4 x i1> %1411, <4 x i32> %1410, <4 x i32> %1409
  %1413 = add nuw nsw <4 x i32> %1412, <i32 32, i32 32, i32 32, i32 32>
  %1414 = lshr <4 x i32> %1413, <i32 6, i32 6, i32 6, i32 6>
  %1415 = shufflevector <8 x i16> %1402, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1416 = shufflevector <8 x i16> %1404, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1417 = bitcast <8 x i16> %1415 to <4 x i32>
  %1418 = bitcast <8 x i16> %1416 to <4 x i32>
  %1419 = sub <4 x i32> %1417, %1418
  %1420 = sub <4 x i32> zeroinitializer, %1419
  %1421 = icmp slt <4 x i32> %1419, zeroinitializer
  %1422 = select <4 x i1> %1421, <4 x i32> %1420, <4 x i32> %1419
  %1423 = add nuw <4 x i32> %1422, <i32 32, i32 32, i32 32, i32 32>
  %1424 = lshr <4 x i32> %1423, <i32 6, i32 6, i32 6, i32 6>
  %1425 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1414, <4 x i32> %1424) #5
  %1426 = lshr <8 x i16> %1425, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1427 = getelementptr inbounds i16, i16* %9, i64 360
  %1428 = bitcast i16* %1427 to <8 x i16>*
  %1429 = load <8 x i16>, <8 x i16>* %1428, align 16
  %1430 = getelementptr inbounds i16, i16* %10, i64 360
  %1431 = bitcast i16* %1430 to <8 x i16>*
  %1432 = load <8 x i16>, <8 x i16>* %1431, align 16
  %1433 = shufflevector <8 x i16> %1429, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1434 = zext <4 x i16> %1433 to <4 x i32>
  %1435 = shufflevector <8 x i16> %1432, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1436 = zext <4 x i16> %1435 to <4 x i32>
  %1437 = sub nsw <4 x i32> %1434, %1436
  %1438 = sub nsw <4 x i32> zeroinitializer, %1437
  %1439 = icmp slt <4 x i32> %1437, zeroinitializer
  %1440 = select <4 x i1> %1439, <4 x i32> %1438, <4 x i32> %1437
  %1441 = add nuw nsw <4 x i32> %1440, <i32 32, i32 32, i32 32, i32 32>
  %1442 = lshr <4 x i32> %1441, <i32 6, i32 6, i32 6, i32 6>
  %1443 = shufflevector <8 x i16> %1429, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1444 = shufflevector <8 x i16> %1432, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1445 = bitcast <8 x i16> %1443 to <4 x i32>
  %1446 = bitcast <8 x i16> %1444 to <4 x i32>
  %1447 = sub <4 x i32> %1445, %1446
  %1448 = sub <4 x i32> zeroinitializer, %1447
  %1449 = icmp slt <4 x i32> %1447, zeroinitializer
  %1450 = select <4 x i1> %1449, <4 x i32> %1448, <4 x i32> %1447
  %1451 = add nuw <4 x i32> %1450, <i32 32, i32 32, i32 32, i32 32>
  %1452 = lshr <4 x i32> %1451, <i32 6, i32 6, i32 6, i32 6>
  %1453 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1442, <4 x i32> %1452) #5
  %1454 = lshr <8 x i16> %1453, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1455 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1426, <8 x i16> %1454) #5
  %1456 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1455, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1457 = icmp slt <16 x i8> %1456, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1458 = select <16 x i1> %1457, <16 x i8> %1456, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1459 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1458
  %1460 = bitcast i8* %1400 to <16 x i8>*
  store <16 x i8> %1459, <16 x i8>* %1460, align 16
  %1461 = getelementptr inbounds i16, i16* %9, i64 368
  %1462 = getelementptr inbounds i16, i16* %10, i64 368
  %1463 = getelementptr inbounds i8, i8* %1271, i64 48
  %1464 = bitcast i16* %1461 to <8 x i16>*
  %1465 = load <8 x i16>, <8 x i16>* %1464, align 16
  %1466 = bitcast i16* %1462 to <8 x i16>*
  %1467 = load <8 x i16>, <8 x i16>* %1466, align 16
  %1468 = shufflevector <8 x i16> %1465, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1469 = zext <4 x i16> %1468 to <4 x i32>
  %1470 = shufflevector <8 x i16> %1467, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1471 = zext <4 x i16> %1470 to <4 x i32>
  %1472 = sub nsw <4 x i32> %1469, %1471
  %1473 = sub nsw <4 x i32> zeroinitializer, %1472
  %1474 = icmp slt <4 x i32> %1472, zeroinitializer
  %1475 = select <4 x i1> %1474, <4 x i32> %1473, <4 x i32> %1472
  %1476 = add nuw nsw <4 x i32> %1475, <i32 32, i32 32, i32 32, i32 32>
  %1477 = lshr <4 x i32> %1476, <i32 6, i32 6, i32 6, i32 6>
  %1478 = shufflevector <8 x i16> %1465, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1479 = shufflevector <8 x i16> %1467, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1480 = bitcast <8 x i16> %1478 to <4 x i32>
  %1481 = bitcast <8 x i16> %1479 to <4 x i32>
  %1482 = sub <4 x i32> %1480, %1481
  %1483 = sub <4 x i32> zeroinitializer, %1482
  %1484 = icmp slt <4 x i32> %1482, zeroinitializer
  %1485 = select <4 x i1> %1484, <4 x i32> %1483, <4 x i32> %1482
  %1486 = add nuw <4 x i32> %1485, <i32 32, i32 32, i32 32, i32 32>
  %1487 = lshr <4 x i32> %1486, <i32 6, i32 6, i32 6, i32 6>
  %1488 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1477, <4 x i32> %1487) #5
  %1489 = lshr <8 x i16> %1488, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1490 = getelementptr inbounds i16, i16* %9, i64 376
  %1491 = bitcast i16* %1490 to <8 x i16>*
  %1492 = load <8 x i16>, <8 x i16>* %1491, align 16
  %1493 = getelementptr inbounds i16, i16* %10, i64 376
  %1494 = bitcast i16* %1493 to <8 x i16>*
  %1495 = load <8 x i16>, <8 x i16>* %1494, align 16
  %1496 = shufflevector <8 x i16> %1492, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1497 = zext <4 x i16> %1496 to <4 x i32>
  %1498 = shufflevector <8 x i16> %1495, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1499 = zext <4 x i16> %1498 to <4 x i32>
  %1500 = sub nsw <4 x i32> %1497, %1499
  %1501 = sub nsw <4 x i32> zeroinitializer, %1500
  %1502 = icmp slt <4 x i32> %1500, zeroinitializer
  %1503 = select <4 x i1> %1502, <4 x i32> %1501, <4 x i32> %1500
  %1504 = add nuw nsw <4 x i32> %1503, <i32 32, i32 32, i32 32, i32 32>
  %1505 = lshr <4 x i32> %1504, <i32 6, i32 6, i32 6, i32 6>
  %1506 = shufflevector <8 x i16> %1492, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1507 = shufflevector <8 x i16> %1495, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1508 = bitcast <8 x i16> %1506 to <4 x i32>
  %1509 = bitcast <8 x i16> %1507 to <4 x i32>
  %1510 = sub <4 x i32> %1508, %1509
  %1511 = sub <4 x i32> zeroinitializer, %1510
  %1512 = icmp slt <4 x i32> %1510, zeroinitializer
  %1513 = select <4 x i1> %1512, <4 x i32> %1511, <4 x i32> %1510
  %1514 = add nuw <4 x i32> %1513, <i32 32, i32 32, i32 32, i32 32>
  %1515 = lshr <4 x i32> %1514, <i32 6, i32 6, i32 6, i32 6>
  %1516 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1505, <4 x i32> %1515) #5
  %1517 = lshr <8 x i16> %1516, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1518 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1489, <8 x i16> %1517) #5
  %1519 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1518, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1520 = icmp slt <16 x i8> %1519, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1521 = select <16 x i1> %1520, <16 x i8> %1519, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1522 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1521
  %1523 = bitcast i8* %1463 to <16 x i8>*
  store <16 x i8> %1522, <16 x i8>* %1523, align 16
  %1524 = getelementptr inbounds i16, i16* %9, i64 384
  %1525 = getelementptr inbounds i16, i16* %10, i64 384
  %1526 = getelementptr inbounds i8, i8* %1271, i64 %3
  %1527 = bitcast i16* %1524 to <8 x i16>*
  %1528 = load <8 x i16>, <8 x i16>* %1527, align 16
  %1529 = bitcast i16* %1525 to <8 x i16>*
  %1530 = load <8 x i16>, <8 x i16>* %1529, align 16
  %1531 = shufflevector <8 x i16> %1528, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1532 = zext <4 x i16> %1531 to <4 x i32>
  %1533 = shufflevector <8 x i16> %1530, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1534 = zext <4 x i16> %1533 to <4 x i32>
  %1535 = sub nsw <4 x i32> %1532, %1534
  %1536 = sub nsw <4 x i32> zeroinitializer, %1535
  %1537 = icmp slt <4 x i32> %1535, zeroinitializer
  %1538 = select <4 x i1> %1537, <4 x i32> %1536, <4 x i32> %1535
  %1539 = add nuw nsw <4 x i32> %1538, <i32 32, i32 32, i32 32, i32 32>
  %1540 = lshr <4 x i32> %1539, <i32 6, i32 6, i32 6, i32 6>
  %1541 = shufflevector <8 x i16> %1528, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1542 = shufflevector <8 x i16> %1530, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1543 = bitcast <8 x i16> %1541 to <4 x i32>
  %1544 = bitcast <8 x i16> %1542 to <4 x i32>
  %1545 = sub <4 x i32> %1543, %1544
  %1546 = sub <4 x i32> zeroinitializer, %1545
  %1547 = icmp slt <4 x i32> %1545, zeroinitializer
  %1548 = select <4 x i1> %1547, <4 x i32> %1546, <4 x i32> %1545
  %1549 = add nuw <4 x i32> %1548, <i32 32, i32 32, i32 32, i32 32>
  %1550 = lshr <4 x i32> %1549, <i32 6, i32 6, i32 6, i32 6>
  %1551 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1540, <4 x i32> %1550) #5
  %1552 = lshr <8 x i16> %1551, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1553 = getelementptr inbounds i16, i16* %9, i64 392
  %1554 = bitcast i16* %1553 to <8 x i16>*
  %1555 = load <8 x i16>, <8 x i16>* %1554, align 16
  %1556 = getelementptr inbounds i16, i16* %10, i64 392
  %1557 = bitcast i16* %1556 to <8 x i16>*
  %1558 = load <8 x i16>, <8 x i16>* %1557, align 16
  %1559 = shufflevector <8 x i16> %1555, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1560 = zext <4 x i16> %1559 to <4 x i32>
  %1561 = shufflevector <8 x i16> %1558, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1562 = zext <4 x i16> %1561 to <4 x i32>
  %1563 = sub nsw <4 x i32> %1560, %1562
  %1564 = sub nsw <4 x i32> zeroinitializer, %1563
  %1565 = icmp slt <4 x i32> %1563, zeroinitializer
  %1566 = select <4 x i1> %1565, <4 x i32> %1564, <4 x i32> %1563
  %1567 = add nuw nsw <4 x i32> %1566, <i32 32, i32 32, i32 32, i32 32>
  %1568 = lshr <4 x i32> %1567, <i32 6, i32 6, i32 6, i32 6>
  %1569 = shufflevector <8 x i16> %1555, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1570 = shufflevector <8 x i16> %1558, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1571 = bitcast <8 x i16> %1569 to <4 x i32>
  %1572 = bitcast <8 x i16> %1570 to <4 x i32>
  %1573 = sub <4 x i32> %1571, %1572
  %1574 = sub <4 x i32> zeroinitializer, %1573
  %1575 = icmp slt <4 x i32> %1573, zeroinitializer
  %1576 = select <4 x i1> %1575, <4 x i32> %1574, <4 x i32> %1573
  %1577 = add nuw <4 x i32> %1576, <i32 32, i32 32, i32 32, i32 32>
  %1578 = lshr <4 x i32> %1577, <i32 6, i32 6, i32 6, i32 6>
  %1579 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1568, <4 x i32> %1578) #5
  %1580 = lshr <8 x i16> %1579, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1581 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1552, <8 x i16> %1580) #5
  %1582 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1581, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1583 = icmp slt <16 x i8> %1582, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1584 = select <16 x i1> %1583, <16 x i8> %1582, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1585 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1584
  %1586 = bitcast i8* %1526 to <16 x i8>*
  store <16 x i8> %1585, <16 x i8>* %1586, align 16
  %1587 = getelementptr inbounds i16, i16* %9, i64 400
  %1588 = getelementptr inbounds i16, i16* %10, i64 400
  %1589 = getelementptr inbounds i8, i8* %1526, i64 16
  %1590 = bitcast i16* %1587 to <8 x i16>*
  %1591 = load <8 x i16>, <8 x i16>* %1590, align 16
  %1592 = bitcast i16* %1588 to <8 x i16>*
  %1593 = load <8 x i16>, <8 x i16>* %1592, align 16
  %1594 = shufflevector <8 x i16> %1591, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1595 = zext <4 x i16> %1594 to <4 x i32>
  %1596 = shufflevector <8 x i16> %1593, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1597 = zext <4 x i16> %1596 to <4 x i32>
  %1598 = sub nsw <4 x i32> %1595, %1597
  %1599 = sub nsw <4 x i32> zeroinitializer, %1598
  %1600 = icmp slt <4 x i32> %1598, zeroinitializer
  %1601 = select <4 x i1> %1600, <4 x i32> %1599, <4 x i32> %1598
  %1602 = add nuw nsw <4 x i32> %1601, <i32 32, i32 32, i32 32, i32 32>
  %1603 = lshr <4 x i32> %1602, <i32 6, i32 6, i32 6, i32 6>
  %1604 = shufflevector <8 x i16> %1591, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1605 = shufflevector <8 x i16> %1593, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1606 = bitcast <8 x i16> %1604 to <4 x i32>
  %1607 = bitcast <8 x i16> %1605 to <4 x i32>
  %1608 = sub <4 x i32> %1606, %1607
  %1609 = sub <4 x i32> zeroinitializer, %1608
  %1610 = icmp slt <4 x i32> %1608, zeroinitializer
  %1611 = select <4 x i1> %1610, <4 x i32> %1609, <4 x i32> %1608
  %1612 = add nuw <4 x i32> %1611, <i32 32, i32 32, i32 32, i32 32>
  %1613 = lshr <4 x i32> %1612, <i32 6, i32 6, i32 6, i32 6>
  %1614 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1603, <4 x i32> %1613) #5
  %1615 = lshr <8 x i16> %1614, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1616 = getelementptr inbounds i16, i16* %9, i64 408
  %1617 = bitcast i16* %1616 to <8 x i16>*
  %1618 = load <8 x i16>, <8 x i16>* %1617, align 16
  %1619 = getelementptr inbounds i16, i16* %10, i64 408
  %1620 = bitcast i16* %1619 to <8 x i16>*
  %1621 = load <8 x i16>, <8 x i16>* %1620, align 16
  %1622 = shufflevector <8 x i16> %1618, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1623 = zext <4 x i16> %1622 to <4 x i32>
  %1624 = shufflevector <8 x i16> %1621, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1625 = zext <4 x i16> %1624 to <4 x i32>
  %1626 = sub nsw <4 x i32> %1623, %1625
  %1627 = sub nsw <4 x i32> zeroinitializer, %1626
  %1628 = icmp slt <4 x i32> %1626, zeroinitializer
  %1629 = select <4 x i1> %1628, <4 x i32> %1627, <4 x i32> %1626
  %1630 = add nuw nsw <4 x i32> %1629, <i32 32, i32 32, i32 32, i32 32>
  %1631 = lshr <4 x i32> %1630, <i32 6, i32 6, i32 6, i32 6>
  %1632 = shufflevector <8 x i16> %1618, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1633 = shufflevector <8 x i16> %1621, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1634 = bitcast <8 x i16> %1632 to <4 x i32>
  %1635 = bitcast <8 x i16> %1633 to <4 x i32>
  %1636 = sub <4 x i32> %1634, %1635
  %1637 = sub <4 x i32> zeroinitializer, %1636
  %1638 = icmp slt <4 x i32> %1636, zeroinitializer
  %1639 = select <4 x i1> %1638, <4 x i32> %1637, <4 x i32> %1636
  %1640 = add nuw <4 x i32> %1639, <i32 32, i32 32, i32 32, i32 32>
  %1641 = lshr <4 x i32> %1640, <i32 6, i32 6, i32 6, i32 6>
  %1642 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1631, <4 x i32> %1641) #5
  %1643 = lshr <8 x i16> %1642, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1644 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1615, <8 x i16> %1643) #5
  %1645 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1644, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1646 = icmp slt <16 x i8> %1645, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1647 = select <16 x i1> %1646, <16 x i8> %1645, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1648 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1647
  %1649 = bitcast i8* %1589 to <16 x i8>*
  store <16 x i8> %1648, <16 x i8>* %1649, align 16
  %1650 = getelementptr inbounds i16, i16* %9, i64 416
  %1651 = getelementptr inbounds i16, i16* %10, i64 416
  %1652 = getelementptr inbounds i8, i8* %1526, i64 32
  %1653 = bitcast i16* %1650 to <8 x i16>*
  %1654 = load <8 x i16>, <8 x i16>* %1653, align 16
  %1655 = bitcast i16* %1651 to <8 x i16>*
  %1656 = load <8 x i16>, <8 x i16>* %1655, align 16
  %1657 = shufflevector <8 x i16> %1654, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1658 = zext <4 x i16> %1657 to <4 x i32>
  %1659 = shufflevector <8 x i16> %1656, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1660 = zext <4 x i16> %1659 to <4 x i32>
  %1661 = sub nsw <4 x i32> %1658, %1660
  %1662 = sub nsw <4 x i32> zeroinitializer, %1661
  %1663 = icmp slt <4 x i32> %1661, zeroinitializer
  %1664 = select <4 x i1> %1663, <4 x i32> %1662, <4 x i32> %1661
  %1665 = add nuw nsw <4 x i32> %1664, <i32 32, i32 32, i32 32, i32 32>
  %1666 = lshr <4 x i32> %1665, <i32 6, i32 6, i32 6, i32 6>
  %1667 = shufflevector <8 x i16> %1654, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1668 = shufflevector <8 x i16> %1656, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1669 = bitcast <8 x i16> %1667 to <4 x i32>
  %1670 = bitcast <8 x i16> %1668 to <4 x i32>
  %1671 = sub <4 x i32> %1669, %1670
  %1672 = sub <4 x i32> zeroinitializer, %1671
  %1673 = icmp slt <4 x i32> %1671, zeroinitializer
  %1674 = select <4 x i1> %1673, <4 x i32> %1672, <4 x i32> %1671
  %1675 = add nuw <4 x i32> %1674, <i32 32, i32 32, i32 32, i32 32>
  %1676 = lshr <4 x i32> %1675, <i32 6, i32 6, i32 6, i32 6>
  %1677 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1666, <4 x i32> %1676) #5
  %1678 = lshr <8 x i16> %1677, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1679 = getelementptr inbounds i16, i16* %9, i64 424
  %1680 = bitcast i16* %1679 to <8 x i16>*
  %1681 = load <8 x i16>, <8 x i16>* %1680, align 16
  %1682 = getelementptr inbounds i16, i16* %10, i64 424
  %1683 = bitcast i16* %1682 to <8 x i16>*
  %1684 = load <8 x i16>, <8 x i16>* %1683, align 16
  %1685 = shufflevector <8 x i16> %1681, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1686 = zext <4 x i16> %1685 to <4 x i32>
  %1687 = shufflevector <8 x i16> %1684, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1688 = zext <4 x i16> %1687 to <4 x i32>
  %1689 = sub nsw <4 x i32> %1686, %1688
  %1690 = sub nsw <4 x i32> zeroinitializer, %1689
  %1691 = icmp slt <4 x i32> %1689, zeroinitializer
  %1692 = select <4 x i1> %1691, <4 x i32> %1690, <4 x i32> %1689
  %1693 = add nuw nsw <4 x i32> %1692, <i32 32, i32 32, i32 32, i32 32>
  %1694 = lshr <4 x i32> %1693, <i32 6, i32 6, i32 6, i32 6>
  %1695 = shufflevector <8 x i16> %1681, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1696 = shufflevector <8 x i16> %1684, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1697 = bitcast <8 x i16> %1695 to <4 x i32>
  %1698 = bitcast <8 x i16> %1696 to <4 x i32>
  %1699 = sub <4 x i32> %1697, %1698
  %1700 = sub <4 x i32> zeroinitializer, %1699
  %1701 = icmp slt <4 x i32> %1699, zeroinitializer
  %1702 = select <4 x i1> %1701, <4 x i32> %1700, <4 x i32> %1699
  %1703 = add nuw <4 x i32> %1702, <i32 32, i32 32, i32 32, i32 32>
  %1704 = lshr <4 x i32> %1703, <i32 6, i32 6, i32 6, i32 6>
  %1705 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1694, <4 x i32> %1704) #5
  %1706 = lshr <8 x i16> %1705, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1707 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1678, <8 x i16> %1706) #5
  %1708 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1707, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1709 = icmp slt <16 x i8> %1708, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1710 = select <16 x i1> %1709, <16 x i8> %1708, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1711 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1710
  %1712 = bitcast i8* %1652 to <16 x i8>*
  store <16 x i8> %1711, <16 x i8>* %1712, align 16
  %1713 = getelementptr inbounds i16, i16* %9, i64 432
  %1714 = getelementptr inbounds i16, i16* %10, i64 432
  %1715 = getelementptr inbounds i8, i8* %1526, i64 48
  %1716 = bitcast i16* %1713 to <8 x i16>*
  %1717 = load <8 x i16>, <8 x i16>* %1716, align 16
  %1718 = bitcast i16* %1714 to <8 x i16>*
  %1719 = load <8 x i16>, <8 x i16>* %1718, align 16
  %1720 = shufflevector <8 x i16> %1717, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1721 = zext <4 x i16> %1720 to <4 x i32>
  %1722 = shufflevector <8 x i16> %1719, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1723 = zext <4 x i16> %1722 to <4 x i32>
  %1724 = sub nsw <4 x i32> %1721, %1723
  %1725 = sub nsw <4 x i32> zeroinitializer, %1724
  %1726 = icmp slt <4 x i32> %1724, zeroinitializer
  %1727 = select <4 x i1> %1726, <4 x i32> %1725, <4 x i32> %1724
  %1728 = add nuw nsw <4 x i32> %1727, <i32 32, i32 32, i32 32, i32 32>
  %1729 = lshr <4 x i32> %1728, <i32 6, i32 6, i32 6, i32 6>
  %1730 = shufflevector <8 x i16> %1717, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1731 = shufflevector <8 x i16> %1719, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1732 = bitcast <8 x i16> %1730 to <4 x i32>
  %1733 = bitcast <8 x i16> %1731 to <4 x i32>
  %1734 = sub <4 x i32> %1732, %1733
  %1735 = sub <4 x i32> zeroinitializer, %1734
  %1736 = icmp slt <4 x i32> %1734, zeroinitializer
  %1737 = select <4 x i1> %1736, <4 x i32> %1735, <4 x i32> %1734
  %1738 = add nuw <4 x i32> %1737, <i32 32, i32 32, i32 32, i32 32>
  %1739 = lshr <4 x i32> %1738, <i32 6, i32 6, i32 6, i32 6>
  %1740 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1729, <4 x i32> %1739) #5
  %1741 = lshr <8 x i16> %1740, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1742 = getelementptr inbounds i16, i16* %9, i64 440
  %1743 = bitcast i16* %1742 to <8 x i16>*
  %1744 = load <8 x i16>, <8 x i16>* %1743, align 16
  %1745 = getelementptr inbounds i16, i16* %10, i64 440
  %1746 = bitcast i16* %1745 to <8 x i16>*
  %1747 = load <8 x i16>, <8 x i16>* %1746, align 16
  %1748 = shufflevector <8 x i16> %1744, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1749 = zext <4 x i16> %1748 to <4 x i32>
  %1750 = shufflevector <8 x i16> %1747, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1751 = zext <4 x i16> %1750 to <4 x i32>
  %1752 = sub nsw <4 x i32> %1749, %1751
  %1753 = sub nsw <4 x i32> zeroinitializer, %1752
  %1754 = icmp slt <4 x i32> %1752, zeroinitializer
  %1755 = select <4 x i1> %1754, <4 x i32> %1753, <4 x i32> %1752
  %1756 = add nuw nsw <4 x i32> %1755, <i32 32, i32 32, i32 32, i32 32>
  %1757 = lshr <4 x i32> %1756, <i32 6, i32 6, i32 6, i32 6>
  %1758 = shufflevector <8 x i16> %1744, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1759 = shufflevector <8 x i16> %1747, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1760 = bitcast <8 x i16> %1758 to <4 x i32>
  %1761 = bitcast <8 x i16> %1759 to <4 x i32>
  %1762 = sub <4 x i32> %1760, %1761
  %1763 = sub <4 x i32> zeroinitializer, %1762
  %1764 = icmp slt <4 x i32> %1762, zeroinitializer
  %1765 = select <4 x i1> %1764, <4 x i32> %1763, <4 x i32> %1762
  %1766 = add nuw <4 x i32> %1765, <i32 32, i32 32, i32 32, i32 32>
  %1767 = lshr <4 x i32> %1766, <i32 6, i32 6, i32 6, i32 6>
  %1768 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1757, <4 x i32> %1767) #5
  %1769 = lshr <8 x i16> %1768, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1770 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1741, <8 x i16> %1769) #5
  %1771 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1770, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1772 = icmp slt <16 x i8> %1771, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1773 = select <16 x i1> %1772, <16 x i8> %1771, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1774 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1773
  %1775 = bitcast i8* %1715 to <16 x i8>*
  store <16 x i8> %1774, <16 x i8>* %1775, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask64x64_10bpp_SSE4ILb0EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %755, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %753, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %754, %7 ]
  %11 = phi i32 [ 21, %4 ], [ %756, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = shufflevector <8 x i16> %13, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %17 = zext <4 x i16> %16 to <4 x i32>
  %18 = shufflevector <8 x i16> %15, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %19 = zext <4 x i16> %18 to <4 x i32>
  %20 = sub nsw <4 x i32> %17, %19
  %21 = sub nsw <4 x i32> zeroinitializer, %20
  %22 = icmp slt <4 x i32> %20, zeroinitializer
  %23 = select <4 x i1> %22, <4 x i32> %21, <4 x i32> %20
  %24 = add nuw nsw <4 x i32> %23, <i32 32, i32 32, i32 32, i32 32>
  %25 = lshr <4 x i32> %24, <i32 6, i32 6, i32 6, i32 6>
  %26 = shufflevector <8 x i16> %13, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %27 = shufflevector <8 x i16> %15, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %28 = bitcast <8 x i16> %26 to <4 x i32>
  %29 = bitcast <8 x i16> %27 to <4 x i32>
  %30 = sub <4 x i32> %28, %29
  %31 = sub <4 x i32> zeroinitializer, %30
  %32 = icmp slt <4 x i32> %30, zeroinitializer
  %33 = select <4 x i1> %32, <4 x i32> %31, <4 x i32> %30
  %34 = add nuw <4 x i32> %33, <i32 32, i32 32, i32 32, i32 32>
  %35 = lshr <4 x i32> %34, <i32 6, i32 6, i32 6, i32 6>
  %36 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %25, <4 x i32> %35) #5
  %37 = lshr <8 x i16> %36, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %38 = getelementptr inbounds i16, i16* %9, i64 8
  %39 = bitcast i16* %38 to <8 x i16>*
  %40 = load <8 x i16>, <8 x i16>* %39, align 16
  %41 = getelementptr inbounds i16, i16* %10, i64 8
  %42 = bitcast i16* %41 to <8 x i16>*
  %43 = load <8 x i16>, <8 x i16>* %42, align 16
  %44 = shufflevector <8 x i16> %40, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %45 = zext <4 x i16> %44 to <4 x i32>
  %46 = shufflevector <8 x i16> %43, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %47 = zext <4 x i16> %46 to <4 x i32>
  %48 = sub nsw <4 x i32> %45, %47
  %49 = sub nsw <4 x i32> zeroinitializer, %48
  %50 = icmp slt <4 x i32> %48, zeroinitializer
  %51 = select <4 x i1> %50, <4 x i32> %49, <4 x i32> %48
  %52 = add nuw nsw <4 x i32> %51, <i32 32, i32 32, i32 32, i32 32>
  %53 = lshr <4 x i32> %52, <i32 6, i32 6, i32 6, i32 6>
  %54 = shufflevector <8 x i16> %40, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %55 = shufflevector <8 x i16> %43, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %56 = bitcast <8 x i16> %54 to <4 x i32>
  %57 = bitcast <8 x i16> %55 to <4 x i32>
  %58 = sub <4 x i32> %56, %57
  %59 = sub <4 x i32> zeroinitializer, %58
  %60 = icmp slt <4 x i32> %58, zeroinitializer
  %61 = select <4 x i1> %60, <4 x i32> %59, <4 x i32> %58
  %62 = add nuw <4 x i32> %61, <i32 32, i32 32, i32 32, i32 32>
  %63 = lshr <4 x i32> %62, <i32 6, i32 6, i32 6, i32 6>
  %64 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %53, <4 x i32> %63) #5
  %65 = lshr <8 x i16> %64, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %66 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %37, <8 x i16> %65) #5
  %67 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %66, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %68 = icmp slt <16 x i8> %67, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %69 = select <16 x i1> %68, <16 x i8> %67, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %70 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %69, <16 x i8>* %70, align 16
  %71 = getelementptr inbounds i16, i16* %9, i64 16
  %72 = getelementptr inbounds i16, i16* %10, i64 16
  %73 = getelementptr inbounds i8, i8* %8, i64 16
  %74 = bitcast i16* %71 to <8 x i16>*
  %75 = load <8 x i16>, <8 x i16>* %74, align 16
  %76 = bitcast i16* %72 to <8 x i16>*
  %77 = load <8 x i16>, <8 x i16>* %76, align 16
  %78 = shufflevector <8 x i16> %75, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %79 = zext <4 x i16> %78 to <4 x i32>
  %80 = shufflevector <8 x i16> %77, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %81 = zext <4 x i16> %80 to <4 x i32>
  %82 = sub nsw <4 x i32> %79, %81
  %83 = sub nsw <4 x i32> zeroinitializer, %82
  %84 = icmp slt <4 x i32> %82, zeroinitializer
  %85 = select <4 x i1> %84, <4 x i32> %83, <4 x i32> %82
  %86 = add nuw nsw <4 x i32> %85, <i32 32, i32 32, i32 32, i32 32>
  %87 = lshr <4 x i32> %86, <i32 6, i32 6, i32 6, i32 6>
  %88 = shufflevector <8 x i16> %75, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %89 = shufflevector <8 x i16> %77, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %90 = bitcast <8 x i16> %88 to <4 x i32>
  %91 = bitcast <8 x i16> %89 to <4 x i32>
  %92 = sub <4 x i32> %90, %91
  %93 = sub <4 x i32> zeroinitializer, %92
  %94 = icmp slt <4 x i32> %92, zeroinitializer
  %95 = select <4 x i1> %94, <4 x i32> %93, <4 x i32> %92
  %96 = add nuw <4 x i32> %95, <i32 32, i32 32, i32 32, i32 32>
  %97 = lshr <4 x i32> %96, <i32 6, i32 6, i32 6, i32 6>
  %98 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %87, <4 x i32> %97) #5
  %99 = lshr <8 x i16> %98, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %100 = getelementptr inbounds i16, i16* %9, i64 24
  %101 = bitcast i16* %100 to <8 x i16>*
  %102 = load <8 x i16>, <8 x i16>* %101, align 16
  %103 = getelementptr inbounds i16, i16* %10, i64 24
  %104 = bitcast i16* %103 to <8 x i16>*
  %105 = load <8 x i16>, <8 x i16>* %104, align 16
  %106 = shufflevector <8 x i16> %102, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %107 = zext <4 x i16> %106 to <4 x i32>
  %108 = shufflevector <8 x i16> %105, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %109 = zext <4 x i16> %108 to <4 x i32>
  %110 = sub nsw <4 x i32> %107, %109
  %111 = sub nsw <4 x i32> zeroinitializer, %110
  %112 = icmp slt <4 x i32> %110, zeroinitializer
  %113 = select <4 x i1> %112, <4 x i32> %111, <4 x i32> %110
  %114 = add nuw nsw <4 x i32> %113, <i32 32, i32 32, i32 32, i32 32>
  %115 = lshr <4 x i32> %114, <i32 6, i32 6, i32 6, i32 6>
  %116 = shufflevector <8 x i16> %102, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %117 = shufflevector <8 x i16> %105, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %118 = bitcast <8 x i16> %116 to <4 x i32>
  %119 = bitcast <8 x i16> %117 to <4 x i32>
  %120 = sub <4 x i32> %118, %119
  %121 = sub <4 x i32> zeroinitializer, %120
  %122 = icmp slt <4 x i32> %120, zeroinitializer
  %123 = select <4 x i1> %122, <4 x i32> %121, <4 x i32> %120
  %124 = add nuw <4 x i32> %123, <i32 32, i32 32, i32 32, i32 32>
  %125 = lshr <4 x i32> %124, <i32 6, i32 6, i32 6, i32 6>
  %126 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %115, <4 x i32> %125) #5
  %127 = lshr <8 x i16> %126, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %128 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %99, <8 x i16> %127) #5
  %129 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %128, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %130 = icmp slt <16 x i8> %129, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %131 = select <16 x i1> %130, <16 x i8> %129, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %132 = bitcast i8* %73 to <16 x i8>*
  store <16 x i8> %131, <16 x i8>* %132, align 16
  %133 = getelementptr inbounds i16, i16* %9, i64 32
  %134 = getelementptr inbounds i16, i16* %10, i64 32
  %135 = getelementptr inbounds i8, i8* %8, i64 32
  %136 = bitcast i16* %133 to <8 x i16>*
  %137 = load <8 x i16>, <8 x i16>* %136, align 16
  %138 = bitcast i16* %134 to <8 x i16>*
  %139 = load <8 x i16>, <8 x i16>* %138, align 16
  %140 = shufflevector <8 x i16> %137, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %141 = zext <4 x i16> %140 to <4 x i32>
  %142 = shufflevector <8 x i16> %139, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %143 = zext <4 x i16> %142 to <4 x i32>
  %144 = sub nsw <4 x i32> %141, %143
  %145 = sub nsw <4 x i32> zeroinitializer, %144
  %146 = icmp slt <4 x i32> %144, zeroinitializer
  %147 = select <4 x i1> %146, <4 x i32> %145, <4 x i32> %144
  %148 = add nuw nsw <4 x i32> %147, <i32 32, i32 32, i32 32, i32 32>
  %149 = lshr <4 x i32> %148, <i32 6, i32 6, i32 6, i32 6>
  %150 = shufflevector <8 x i16> %137, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %151 = shufflevector <8 x i16> %139, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %152 = bitcast <8 x i16> %150 to <4 x i32>
  %153 = bitcast <8 x i16> %151 to <4 x i32>
  %154 = sub <4 x i32> %152, %153
  %155 = sub <4 x i32> zeroinitializer, %154
  %156 = icmp slt <4 x i32> %154, zeroinitializer
  %157 = select <4 x i1> %156, <4 x i32> %155, <4 x i32> %154
  %158 = add nuw <4 x i32> %157, <i32 32, i32 32, i32 32, i32 32>
  %159 = lshr <4 x i32> %158, <i32 6, i32 6, i32 6, i32 6>
  %160 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %149, <4 x i32> %159) #5
  %161 = lshr <8 x i16> %160, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %162 = getelementptr inbounds i16, i16* %9, i64 40
  %163 = bitcast i16* %162 to <8 x i16>*
  %164 = load <8 x i16>, <8 x i16>* %163, align 16
  %165 = getelementptr inbounds i16, i16* %10, i64 40
  %166 = bitcast i16* %165 to <8 x i16>*
  %167 = load <8 x i16>, <8 x i16>* %166, align 16
  %168 = shufflevector <8 x i16> %164, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %169 = zext <4 x i16> %168 to <4 x i32>
  %170 = shufflevector <8 x i16> %167, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %171 = zext <4 x i16> %170 to <4 x i32>
  %172 = sub nsw <4 x i32> %169, %171
  %173 = sub nsw <4 x i32> zeroinitializer, %172
  %174 = icmp slt <4 x i32> %172, zeroinitializer
  %175 = select <4 x i1> %174, <4 x i32> %173, <4 x i32> %172
  %176 = add nuw nsw <4 x i32> %175, <i32 32, i32 32, i32 32, i32 32>
  %177 = lshr <4 x i32> %176, <i32 6, i32 6, i32 6, i32 6>
  %178 = shufflevector <8 x i16> %164, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %179 = shufflevector <8 x i16> %167, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %180 = bitcast <8 x i16> %178 to <4 x i32>
  %181 = bitcast <8 x i16> %179 to <4 x i32>
  %182 = sub <4 x i32> %180, %181
  %183 = sub <4 x i32> zeroinitializer, %182
  %184 = icmp slt <4 x i32> %182, zeroinitializer
  %185 = select <4 x i1> %184, <4 x i32> %183, <4 x i32> %182
  %186 = add nuw <4 x i32> %185, <i32 32, i32 32, i32 32, i32 32>
  %187 = lshr <4 x i32> %186, <i32 6, i32 6, i32 6, i32 6>
  %188 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %177, <4 x i32> %187) #5
  %189 = lshr <8 x i16> %188, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %190 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %161, <8 x i16> %189) #5
  %191 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %190, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %192 = icmp slt <16 x i8> %191, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %193 = select <16 x i1> %192, <16 x i8> %191, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %194 = bitcast i8* %135 to <16 x i8>*
  store <16 x i8> %193, <16 x i8>* %194, align 16
  %195 = getelementptr inbounds i16, i16* %9, i64 48
  %196 = getelementptr inbounds i16, i16* %10, i64 48
  %197 = getelementptr inbounds i8, i8* %8, i64 48
  %198 = bitcast i16* %195 to <8 x i16>*
  %199 = load <8 x i16>, <8 x i16>* %198, align 16
  %200 = bitcast i16* %196 to <8 x i16>*
  %201 = load <8 x i16>, <8 x i16>* %200, align 16
  %202 = shufflevector <8 x i16> %199, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %203 = zext <4 x i16> %202 to <4 x i32>
  %204 = shufflevector <8 x i16> %201, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %205 = zext <4 x i16> %204 to <4 x i32>
  %206 = sub nsw <4 x i32> %203, %205
  %207 = sub nsw <4 x i32> zeroinitializer, %206
  %208 = icmp slt <4 x i32> %206, zeroinitializer
  %209 = select <4 x i1> %208, <4 x i32> %207, <4 x i32> %206
  %210 = add nuw nsw <4 x i32> %209, <i32 32, i32 32, i32 32, i32 32>
  %211 = lshr <4 x i32> %210, <i32 6, i32 6, i32 6, i32 6>
  %212 = shufflevector <8 x i16> %199, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %213 = shufflevector <8 x i16> %201, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %214 = bitcast <8 x i16> %212 to <4 x i32>
  %215 = bitcast <8 x i16> %213 to <4 x i32>
  %216 = sub <4 x i32> %214, %215
  %217 = sub <4 x i32> zeroinitializer, %216
  %218 = icmp slt <4 x i32> %216, zeroinitializer
  %219 = select <4 x i1> %218, <4 x i32> %217, <4 x i32> %216
  %220 = add nuw <4 x i32> %219, <i32 32, i32 32, i32 32, i32 32>
  %221 = lshr <4 x i32> %220, <i32 6, i32 6, i32 6, i32 6>
  %222 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %211, <4 x i32> %221) #5
  %223 = lshr <8 x i16> %222, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %224 = getelementptr inbounds i16, i16* %9, i64 56
  %225 = bitcast i16* %224 to <8 x i16>*
  %226 = load <8 x i16>, <8 x i16>* %225, align 16
  %227 = getelementptr inbounds i16, i16* %10, i64 56
  %228 = bitcast i16* %227 to <8 x i16>*
  %229 = load <8 x i16>, <8 x i16>* %228, align 16
  %230 = shufflevector <8 x i16> %226, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %231 = zext <4 x i16> %230 to <4 x i32>
  %232 = shufflevector <8 x i16> %229, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %233 = zext <4 x i16> %232 to <4 x i32>
  %234 = sub nsw <4 x i32> %231, %233
  %235 = sub nsw <4 x i32> zeroinitializer, %234
  %236 = icmp slt <4 x i32> %234, zeroinitializer
  %237 = select <4 x i1> %236, <4 x i32> %235, <4 x i32> %234
  %238 = add nuw nsw <4 x i32> %237, <i32 32, i32 32, i32 32, i32 32>
  %239 = lshr <4 x i32> %238, <i32 6, i32 6, i32 6, i32 6>
  %240 = shufflevector <8 x i16> %226, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %241 = shufflevector <8 x i16> %229, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %242 = bitcast <8 x i16> %240 to <4 x i32>
  %243 = bitcast <8 x i16> %241 to <4 x i32>
  %244 = sub <4 x i32> %242, %243
  %245 = sub <4 x i32> zeroinitializer, %244
  %246 = icmp slt <4 x i32> %244, zeroinitializer
  %247 = select <4 x i1> %246, <4 x i32> %245, <4 x i32> %244
  %248 = add nuw <4 x i32> %247, <i32 32, i32 32, i32 32, i32 32>
  %249 = lshr <4 x i32> %248, <i32 6, i32 6, i32 6, i32 6>
  %250 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %239, <4 x i32> %249) #5
  %251 = lshr <8 x i16> %250, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %252 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %223, <8 x i16> %251) #5
  %253 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %252, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %254 = icmp slt <16 x i8> %253, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %255 = select <16 x i1> %254, <16 x i8> %253, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %256 = bitcast i8* %197 to <16 x i8>*
  store <16 x i8> %255, <16 x i8>* %256, align 16
  %257 = getelementptr inbounds i16, i16* %9, i64 64
  %258 = getelementptr inbounds i16, i16* %10, i64 64
  %259 = getelementptr inbounds i8, i8* %8, i64 %3
  %260 = bitcast i16* %257 to <8 x i16>*
  %261 = load <8 x i16>, <8 x i16>* %260, align 16
  %262 = bitcast i16* %258 to <8 x i16>*
  %263 = load <8 x i16>, <8 x i16>* %262, align 16
  %264 = shufflevector <8 x i16> %261, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %265 = zext <4 x i16> %264 to <4 x i32>
  %266 = shufflevector <8 x i16> %263, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %267 = zext <4 x i16> %266 to <4 x i32>
  %268 = sub nsw <4 x i32> %265, %267
  %269 = sub nsw <4 x i32> zeroinitializer, %268
  %270 = icmp slt <4 x i32> %268, zeroinitializer
  %271 = select <4 x i1> %270, <4 x i32> %269, <4 x i32> %268
  %272 = add nuw nsw <4 x i32> %271, <i32 32, i32 32, i32 32, i32 32>
  %273 = lshr <4 x i32> %272, <i32 6, i32 6, i32 6, i32 6>
  %274 = shufflevector <8 x i16> %261, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %275 = shufflevector <8 x i16> %263, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %276 = bitcast <8 x i16> %274 to <4 x i32>
  %277 = bitcast <8 x i16> %275 to <4 x i32>
  %278 = sub <4 x i32> %276, %277
  %279 = sub <4 x i32> zeroinitializer, %278
  %280 = icmp slt <4 x i32> %278, zeroinitializer
  %281 = select <4 x i1> %280, <4 x i32> %279, <4 x i32> %278
  %282 = add nuw <4 x i32> %281, <i32 32, i32 32, i32 32, i32 32>
  %283 = lshr <4 x i32> %282, <i32 6, i32 6, i32 6, i32 6>
  %284 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %273, <4 x i32> %283) #5
  %285 = lshr <8 x i16> %284, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %286 = getelementptr inbounds i16, i16* %9, i64 72
  %287 = bitcast i16* %286 to <8 x i16>*
  %288 = load <8 x i16>, <8 x i16>* %287, align 16
  %289 = getelementptr inbounds i16, i16* %10, i64 72
  %290 = bitcast i16* %289 to <8 x i16>*
  %291 = load <8 x i16>, <8 x i16>* %290, align 16
  %292 = shufflevector <8 x i16> %288, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %293 = zext <4 x i16> %292 to <4 x i32>
  %294 = shufflevector <8 x i16> %291, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %295 = zext <4 x i16> %294 to <4 x i32>
  %296 = sub nsw <4 x i32> %293, %295
  %297 = sub nsw <4 x i32> zeroinitializer, %296
  %298 = icmp slt <4 x i32> %296, zeroinitializer
  %299 = select <4 x i1> %298, <4 x i32> %297, <4 x i32> %296
  %300 = add nuw nsw <4 x i32> %299, <i32 32, i32 32, i32 32, i32 32>
  %301 = lshr <4 x i32> %300, <i32 6, i32 6, i32 6, i32 6>
  %302 = shufflevector <8 x i16> %288, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %303 = shufflevector <8 x i16> %291, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %304 = bitcast <8 x i16> %302 to <4 x i32>
  %305 = bitcast <8 x i16> %303 to <4 x i32>
  %306 = sub <4 x i32> %304, %305
  %307 = sub <4 x i32> zeroinitializer, %306
  %308 = icmp slt <4 x i32> %306, zeroinitializer
  %309 = select <4 x i1> %308, <4 x i32> %307, <4 x i32> %306
  %310 = add nuw <4 x i32> %309, <i32 32, i32 32, i32 32, i32 32>
  %311 = lshr <4 x i32> %310, <i32 6, i32 6, i32 6, i32 6>
  %312 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %301, <4 x i32> %311) #5
  %313 = lshr <8 x i16> %312, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %314 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %285, <8 x i16> %313) #5
  %315 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %314, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %316 = icmp slt <16 x i8> %315, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %317 = select <16 x i1> %316, <16 x i8> %315, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %318 = bitcast i8* %259 to <16 x i8>*
  store <16 x i8> %317, <16 x i8>* %318, align 16
  %319 = getelementptr inbounds i16, i16* %9, i64 80
  %320 = getelementptr inbounds i16, i16* %10, i64 80
  %321 = getelementptr inbounds i8, i8* %259, i64 16
  %322 = bitcast i16* %319 to <8 x i16>*
  %323 = load <8 x i16>, <8 x i16>* %322, align 16
  %324 = bitcast i16* %320 to <8 x i16>*
  %325 = load <8 x i16>, <8 x i16>* %324, align 16
  %326 = shufflevector <8 x i16> %323, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %327 = zext <4 x i16> %326 to <4 x i32>
  %328 = shufflevector <8 x i16> %325, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %329 = zext <4 x i16> %328 to <4 x i32>
  %330 = sub nsw <4 x i32> %327, %329
  %331 = sub nsw <4 x i32> zeroinitializer, %330
  %332 = icmp slt <4 x i32> %330, zeroinitializer
  %333 = select <4 x i1> %332, <4 x i32> %331, <4 x i32> %330
  %334 = add nuw nsw <4 x i32> %333, <i32 32, i32 32, i32 32, i32 32>
  %335 = lshr <4 x i32> %334, <i32 6, i32 6, i32 6, i32 6>
  %336 = shufflevector <8 x i16> %323, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %337 = shufflevector <8 x i16> %325, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %338 = bitcast <8 x i16> %336 to <4 x i32>
  %339 = bitcast <8 x i16> %337 to <4 x i32>
  %340 = sub <4 x i32> %338, %339
  %341 = sub <4 x i32> zeroinitializer, %340
  %342 = icmp slt <4 x i32> %340, zeroinitializer
  %343 = select <4 x i1> %342, <4 x i32> %341, <4 x i32> %340
  %344 = add nuw <4 x i32> %343, <i32 32, i32 32, i32 32, i32 32>
  %345 = lshr <4 x i32> %344, <i32 6, i32 6, i32 6, i32 6>
  %346 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %335, <4 x i32> %345) #5
  %347 = lshr <8 x i16> %346, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %348 = getelementptr inbounds i16, i16* %9, i64 88
  %349 = bitcast i16* %348 to <8 x i16>*
  %350 = load <8 x i16>, <8 x i16>* %349, align 16
  %351 = getelementptr inbounds i16, i16* %10, i64 88
  %352 = bitcast i16* %351 to <8 x i16>*
  %353 = load <8 x i16>, <8 x i16>* %352, align 16
  %354 = shufflevector <8 x i16> %350, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %355 = zext <4 x i16> %354 to <4 x i32>
  %356 = shufflevector <8 x i16> %353, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %357 = zext <4 x i16> %356 to <4 x i32>
  %358 = sub nsw <4 x i32> %355, %357
  %359 = sub nsw <4 x i32> zeroinitializer, %358
  %360 = icmp slt <4 x i32> %358, zeroinitializer
  %361 = select <4 x i1> %360, <4 x i32> %359, <4 x i32> %358
  %362 = add nuw nsw <4 x i32> %361, <i32 32, i32 32, i32 32, i32 32>
  %363 = lshr <4 x i32> %362, <i32 6, i32 6, i32 6, i32 6>
  %364 = shufflevector <8 x i16> %350, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %365 = shufflevector <8 x i16> %353, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %366 = bitcast <8 x i16> %364 to <4 x i32>
  %367 = bitcast <8 x i16> %365 to <4 x i32>
  %368 = sub <4 x i32> %366, %367
  %369 = sub <4 x i32> zeroinitializer, %368
  %370 = icmp slt <4 x i32> %368, zeroinitializer
  %371 = select <4 x i1> %370, <4 x i32> %369, <4 x i32> %368
  %372 = add nuw <4 x i32> %371, <i32 32, i32 32, i32 32, i32 32>
  %373 = lshr <4 x i32> %372, <i32 6, i32 6, i32 6, i32 6>
  %374 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %363, <4 x i32> %373) #5
  %375 = lshr <8 x i16> %374, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %376 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %347, <8 x i16> %375) #5
  %377 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %376, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %378 = icmp slt <16 x i8> %377, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %379 = select <16 x i1> %378, <16 x i8> %377, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %380 = bitcast i8* %321 to <16 x i8>*
  store <16 x i8> %379, <16 x i8>* %380, align 16
  %381 = getelementptr inbounds i16, i16* %9, i64 96
  %382 = getelementptr inbounds i16, i16* %10, i64 96
  %383 = getelementptr inbounds i8, i8* %259, i64 32
  %384 = bitcast i16* %381 to <8 x i16>*
  %385 = load <8 x i16>, <8 x i16>* %384, align 16
  %386 = bitcast i16* %382 to <8 x i16>*
  %387 = load <8 x i16>, <8 x i16>* %386, align 16
  %388 = shufflevector <8 x i16> %385, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %389 = zext <4 x i16> %388 to <4 x i32>
  %390 = shufflevector <8 x i16> %387, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %391 = zext <4 x i16> %390 to <4 x i32>
  %392 = sub nsw <4 x i32> %389, %391
  %393 = sub nsw <4 x i32> zeroinitializer, %392
  %394 = icmp slt <4 x i32> %392, zeroinitializer
  %395 = select <4 x i1> %394, <4 x i32> %393, <4 x i32> %392
  %396 = add nuw nsw <4 x i32> %395, <i32 32, i32 32, i32 32, i32 32>
  %397 = lshr <4 x i32> %396, <i32 6, i32 6, i32 6, i32 6>
  %398 = shufflevector <8 x i16> %385, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %399 = shufflevector <8 x i16> %387, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %400 = bitcast <8 x i16> %398 to <4 x i32>
  %401 = bitcast <8 x i16> %399 to <4 x i32>
  %402 = sub <4 x i32> %400, %401
  %403 = sub <4 x i32> zeroinitializer, %402
  %404 = icmp slt <4 x i32> %402, zeroinitializer
  %405 = select <4 x i1> %404, <4 x i32> %403, <4 x i32> %402
  %406 = add nuw <4 x i32> %405, <i32 32, i32 32, i32 32, i32 32>
  %407 = lshr <4 x i32> %406, <i32 6, i32 6, i32 6, i32 6>
  %408 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %397, <4 x i32> %407) #5
  %409 = lshr <8 x i16> %408, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %410 = getelementptr inbounds i16, i16* %9, i64 104
  %411 = bitcast i16* %410 to <8 x i16>*
  %412 = load <8 x i16>, <8 x i16>* %411, align 16
  %413 = getelementptr inbounds i16, i16* %10, i64 104
  %414 = bitcast i16* %413 to <8 x i16>*
  %415 = load <8 x i16>, <8 x i16>* %414, align 16
  %416 = shufflevector <8 x i16> %412, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %417 = zext <4 x i16> %416 to <4 x i32>
  %418 = shufflevector <8 x i16> %415, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %419 = zext <4 x i16> %418 to <4 x i32>
  %420 = sub nsw <4 x i32> %417, %419
  %421 = sub nsw <4 x i32> zeroinitializer, %420
  %422 = icmp slt <4 x i32> %420, zeroinitializer
  %423 = select <4 x i1> %422, <4 x i32> %421, <4 x i32> %420
  %424 = add nuw nsw <4 x i32> %423, <i32 32, i32 32, i32 32, i32 32>
  %425 = lshr <4 x i32> %424, <i32 6, i32 6, i32 6, i32 6>
  %426 = shufflevector <8 x i16> %412, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %427 = shufflevector <8 x i16> %415, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %428 = bitcast <8 x i16> %426 to <4 x i32>
  %429 = bitcast <8 x i16> %427 to <4 x i32>
  %430 = sub <4 x i32> %428, %429
  %431 = sub <4 x i32> zeroinitializer, %430
  %432 = icmp slt <4 x i32> %430, zeroinitializer
  %433 = select <4 x i1> %432, <4 x i32> %431, <4 x i32> %430
  %434 = add nuw <4 x i32> %433, <i32 32, i32 32, i32 32, i32 32>
  %435 = lshr <4 x i32> %434, <i32 6, i32 6, i32 6, i32 6>
  %436 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %425, <4 x i32> %435) #5
  %437 = lshr <8 x i16> %436, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %438 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %409, <8 x i16> %437) #5
  %439 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %438, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %440 = icmp slt <16 x i8> %439, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %441 = select <16 x i1> %440, <16 x i8> %439, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %442 = bitcast i8* %383 to <16 x i8>*
  store <16 x i8> %441, <16 x i8>* %442, align 16
  %443 = getelementptr inbounds i16, i16* %9, i64 112
  %444 = getelementptr inbounds i16, i16* %10, i64 112
  %445 = getelementptr inbounds i8, i8* %259, i64 48
  %446 = bitcast i16* %443 to <8 x i16>*
  %447 = load <8 x i16>, <8 x i16>* %446, align 16
  %448 = bitcast i16* %444 to <8 x i16>*
  %449 = load <8 x i16>, <8 x i16>* %448, align 16
  %450 = shufflevector <8 x i16> %447, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %451 = zext <4 x i16> %450 to <4 x i32>
  %452 = shufflevector <8 x i16> %449, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %453 = zext <4 x i16> %452 to <4 x i32>
  %454 = sub nsw <4 x i32> %451, %453
  %455 = sub nsw <4 x i32> zeroinitializer, %454
  %456 = icmp slt <4 x i32> %454, zeroinitializer
  %457 = select <4 x i1> %456, <4 x i32> %455, <4 x i32> %454
  %458 = add nuw nsw <4 x i32> %457, <i32 32, i32 32, i32 32, i32 32>
  %459 = lshr <4 x i32> %458, <i32 6, i32 6, i32 6, i32 6>
  %460 = shufflevector <8 x i16> %447, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %461 = shufflevector <8 x i16> %449, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %462 = bitcast <8 x i16> %460 to <4 x i32>
  %463 = bitcast <8 x i16> %461 to <4 x i32>
  %464 = sub <4 x i32> %462, %463
  %465 = sub <4 x i32> zeroinitializer, %464
  %466 = icmp slt <4 x i32> %464, zeroinitializer
  %467 = select <4 x i1> %466, <4 x i32> %465, <4 x i32> %464
  %468 = add nuw <4 x i32> %467, <i32 32, i32 32, i32 32, i32 32>
  %469 = lshr <4 x i32> %468, <i32 6, i32 6, i32 6, i32 6>
  %470 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %459, <4 x i32> %469) #5
  %471 = lshr <8 x i16> %470, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %472 = getelementptr inbounds i16, i16* %9, i64 120
  %473 = bitcast i16* %472 to <8 x i16>*
  %474 = load <8 x i16>, <8 x i16>* %473, align 16
  %475 = getelementptr inbounds i16, i16* %10, i64 120
  %476 = bitcast i16* %475 to <8 x i16>*
  %477 = load <8 x i16>, <8 x i16>* %476, align 16
  %478 = shufflevector <8 x i16> %474, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %479 = zext <4 x i16> %478 to <4 x i32>
  %480 = shufflevector <8 x i16> %477, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %481 = zext <4 x i16> %480 to <4 x i32>
  %482 = sub nsw <4 x i32> %479, %481
  %483 = sub nsw <4 x i32> zeroinitializer, %482
  %484 = icmp slt <4 x i32> %482, zeroinitializer
  %485 = select <4 x i1> %484, <4 x i32> %483, <4 x i32> %482
  %486 = add nuw nsw <4 x i32> %485, <i32 32, i32 32, i32 32, i32 32>
  %487 = lshr <4 x i32> %486, <i32 6, i32 6, i32 6, i32 6>
  %488 = shufflevector <8 x i16> %474, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %489 = shufflevector <8 x i16> %477, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %490 = bitcast <8 x i16> %488 to <4 x i32>
  %491 = bitcast <8 x i16> %489 to <4 x i32>
  %492 = sub <4 x i32> %490, %491
  %493 = sub <4 x i32> zeroinitializer, %492
  %494 = icmp slt <4 x i32> %492, zeroinitializer
  %495 = select <4 x i1> %494, <4 x i32> %493, <4 x i32> %492
  %496 = add nuw <4 x i32> %495, <i32 32, i32 32, i32 32, i32 32>
  %497 = lshr <4 x i32> %496, <i32 6, i32 6, i32 6, i32 6>
  %498 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %487, <4 x i32> %497) #5
  %499 = lshr <8 x i16> %498, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %500 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %471, <8 x i16> %499) #5
  %501 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %500, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %502 = icmp slt <16 x i8> %501, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %503 = select <16 x i1> %502, <16 x i8> %501, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %504 = bitcast i8* %445 to <16 x i8>*
  store <16 x i8> %503, <16 x i8>* %504, align 16
  %505 = getelementptr inbounds i16, i16* %9, i64 128
  %506 = getelementptr inbounds i16, i16* %10, i64 128
  %507 = getelementptr inbounds i8, i8* %259, i64 %3
  %508 = bitcast i16* %505 to <8 x i16>*
  %509 = load <8 x i16>, <8 x i16>* %508, align 16
  %510 = bitcast i16* %506 to <8 x i16>*
  %511 = load <8 x i16>, <8 x i16>* %510, align 16
  %512 = shufflevector <8 x i16> %509, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %513 = zext <4 x i16> %512 to <4 x i32>
  %514 = shufflevector <8 x i16> %511, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %515 = zext <4 x i16> %514 to <4 x i32>
  %516 = sub nsw <4 x i32> %513, %515
  %517 = sub nsw <4 x i32> zeroinitializer, %516
  %518 = icmp slt <4 x i32> %516, zeroinitializer
  %519 = select <4 x i1> %518, <4 x i32> %517, <4 x i32> %516
  %520 = add nuw nsw <4 x i32> %519, <i32 32, i32 32, i32 32, i32 32>
  %521 = lshr <4 x i32> %520, <i32 6, i32 6, i32 6, i32 6>
  %522 = shufflevector <8 x i16> %509, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %523 = shufflevector <8 x i16> %511, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %524 = bitcast <8 x i16> %522 to <4 x i32>
  %525 = bitcast <8 x i16> %523 to <4 x i32>
  %526 = sub <4 x i32> %524, %525
  %527 = sub <4 x i32> zeroinitializer, %526
  %528 = icmp slt <4 x i32> %526, zeroinitializer
  %529 = select <4 x i1> %528, <4 x i32> %527, <4 x i32> %526
  %530 = add nuw <4 x i32> %529, <i32 32, i32 32, i32 32, i32 32>
  %531 = lshr <4 x i32> %530, <i32 6, i32 6, i32 6, i32 6>
  %532 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %521, <4 x i32> %531) #5
  %533 = lshr <8 x i16> %532, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %534 = getelementptr inbounds i16, i16* %9, i64 136
  %535 = bitcast i16* %534 to <8 x i16>*
  %536 = load <8 x i16>, <8 x i16>* %535, align 16
  %537 = getelementptr inbounds i16, i16* %10, i64 136
  %538 = bitcast i16* %537 to <8 x i16>*
  %539 = load <8 x i16>, <8 x i16>* %538, align 16
  %540 = shufflevector <8 x i16> %536, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %541 = zext <4 x i16> %540 to <4 x i32>
  %542 = shufflevector <8 x i16> %539, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %543 = zext <4 x i16> %542 to <4 x i32>
  %544 = sub nsw <4 x i32> %541, %543
  %545 = sub nsw <4 x i32> zeroinitializer, %544
  %546 = icmp slt <4 x i32> %544, zeroinitializer
  %547 = select <4 x i1> %546, <4 x i32> %545, <4 x i32> %544
  %548 = add nuw nsw <4 x i32> %547, <i32 32, i32 32, i32 32, i32 32>
  %549 = lshr <4 x i32> %548, <i32 6, i32 6, i32 6, i32 6>
  %550 = shufflevector <8 x i16> %536, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %551 = shufflevector <8 x i16> %539, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %552 = bitcast <8 x i16> %550 to <4 x i32>
  %553 = bitcast <8 x i16> %551 to <4 x i32>
  %554 = sub <4 x i32> %552, %553
  %555 = sub <4 x i32> zeroinitializer, %554
  %556 = icmp slt <4 x i32> %554, zeroinitializer
  %557 = select <4 x i1> %556, <4 x i32> %555, <4 x i32> %554
  %558 = add nuw <4 x i32> %557, <i32 32, i32 32, i32 32, i32 32>
  %559 = lshr <4 x i32> %558, <i32 6, i32 6, i32 6, i32 6>
  %560 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %549, <4 x i32> %559) #5
  %561 = lshr <8 x i16> %560, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %562 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %533, <8 x i16> %561) #5
  %563 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %562, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %564 = icmp slt <16 x i8> %563, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %565 = select <16 x i1> %564, <16 x i8> %563, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %566 = bitcast i8* %507 to <16 x i8>*
  store <16 x i8> %565, <16 x i8>* %566, align 16
  %567 = getelementptr inbounds i16, i16* %9, i64 144
  %568 = getelementptr inbounds i16, i16* %10, i64 144
  %569 = getelementptr inbounds i8, i8* %507, i64 16
  %570 = bitcast i16* %567 to <8 x i16>*
  %571 = load <8 x i16>, <8 x i16>* %570, align 16
  %572 = bitcast i16* %568 to <8 x i16>*
  %573 = load <8 x i16>, <8 x i16>* %572, align 16
  %574 = shufflevector <8 x i16> %571, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %575 = zext <4 x i16> %574 to <4 x i32>
  %576 = shufflevector <8 x i16> %573, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %577 = zext <4 x i16> %576 to <4 x i32>
  %578 = sub nsw <4 x i32> %575, %577
  %579 = sub nsw <4 x i32> zeroinitializer, %578
  %580 = icmp slt <4 x i32> %578, zeroinitializer
  %581 = select <4 x i1> %580, <4 x i32> %579, <4 x i32> %578
  %582 = add nuw nsw <4 x i32> %581, <i32 32, i32 32, i32 32, i32 32>
  %583 = lshr <4 x i32> %582, <i32 6, i32 6, i32 6, i32 6>
  %584 = shufflevector <8 x i16> %571, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %585 = shufflevector <8 x i16> %573, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %586 = bitcast <8 x i16> %584 to <4 x i32>
  %587 = bitcast <8 x i16> %585 to <4 x i32>
  %588 = sub <4 x i32> %586, %587
  %589 = sub <4 x i32> zeroinitializer, %588
  %590 = icmp slt <4 x i32> %588, zeroinitializer
  %591 = select <4 x i1> %590, <4 x i32> %589, <4 x i32> %588
  %592 = add nuw <4 x i32> %591, <i32 32, i32 32, i32 32, i32 32>
  %593 = lshr <4 x i32> %592, <i32 6, i32 6, i32 6, i32 6>
  %594 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %583, <4 x i32> %593) #5
  %595 = lshr <8 x i16> %594, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %596 = getelementptr inbounds i16, i16* %9, i64 152
  %597 = bitcast i16* %596 to <8 x i16>*
  %598 = load <8 x i16>, <8 x i16>* %597, align 16
  %599 = getelementptr inbounds i16, i16* %10, i64 152
  %600 = bitcast i16* %599 to <8 x i16>*
  %601 = load <8 x i16>, <8 x i16>* %600, align 16
  %602 = shufflevector <8 x i16> %598, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %603 = zext <4 x i16> %602 to <4 x i32>
  %604 = shufflevector <8 x i16> %601, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %605 = zext <4 x i16> %604 to <4 x i32>
  %606 = sub nsw <4 x i32> %603, %605
  %607 = sub nsw <4 x i32> zeroinitializer, %606
  %608 = icmp slt <4 x i32> %606, zeroinitializer
  %609 = select <4 x i1> %608, <4 x i32> %607, <4 x i32> %606
  %610 = add nuw nsw <4 x i32> %609, <i32 32, i32 32, i32 32, i32 32>
  %611 = lshr <4 x i32> %610, <i32 6, i32 6, i32 6, i32 6>
  %612 = shufflevector <8 x i16> %598, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %613 = shufflevector <8 x i16> %601, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %614 = bitcast <8 x i16> %612 to <4 x i32>
  %615 = bitcast <8 x i16> %613 to <4 x i32>
  %616 = sub <4 x i32> %614, %615
  %617 = sub <4 x i32> zeroinitializer, %616
  %618 = icmp slt <4 x i32> %616, zeroinitializer
  %619 = select <4 x i1> %618, <4 x i32> %617, <4 x i32> %616
  %620 = add nuw <4 x i32> %619, <i32 32, i32 32, i32 32, i32 32>
  %621 = lshr <4 x i32> %620, <i32 6, i32 6, i32 6, i32 6>
  %622 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %611, <4 x i32> %621) #5
  %623 = lshr <8 x i16> %622, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %624 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %595, <8 x i16> %623) #5
  %625 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %624, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %626 = icmp slt <16 x i8> %625, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %627 = select <16 x i1> %626, <16 x i8> %625, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %628 = bitcast i8* %569 to <16 x i8>*
  store <16 x i8> %627, <16 x i8>* %628, align 16
  %629 = getelementptr inbounds i16, i16* %9, i64 160
  %630 = getelementptr inbounds i16, i16* %10, i64 160
  %631 = getelementptr inbounds i8, i8* %507, i64 32
  %632 = bitcast i16* %629 to <8 x i16>*
  %633 = load <8 x i16>, <8 x i16>* %632, align 16
  %634 = bitcast i16* %630 to <8 x i16>*
  %635 = load <8 x i16>, <8 x i16>* %634, align 16
  %636 = shufflevector <8 x i16> %633, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %637 = zext <4 x i16> %636 to <4 x i32>
  %638 = shufflevector <8 x i16> %635, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %639 = zext <4 x i16> %638 to <4 x i32>
  %640 = sub nsw <4 x i32> %637, %639
  %641 = sub nsw <4 x i32> zeroinitializer, %640
  %642 = icmp slt <4 x i32> %640, zeroinitializer
  %643 = select <4 x i1> %642, <4 x i32> %641, <4 x i32> %640
  %644 = add nuw nsw <4 x i32> %643, <i32 32, i32 32, i32 32, i32 32>
  %645 = lshr <4 x i32> %644, <i32 6, i32 6, i32 6, i32 6>
  %646 = shufflevector <8 x i16> %633, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %647 = shufflevector <8 x i16> %635, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %648 = bitcast <8 x i16> %646 to <4 x i32>
  %649 = bitcast <8 x i16> %647 to <4 x i32>
  %650 = sub <4 x i32> %648, %649
  %651 = sub <4 x i32> zeroinitializer, %650
  %652 = icmp slt <4 x i32> %650, zeroinitializer
  %653 = select <4 x i1> %652, <4 x i32> %651, <4 x i32> %650
  %654 = add nuw <4 x i32> %653, <i32 32, i32 32, i32 32, i32 32>
  %655 = lshr <4 x i32> %654, <i32 6, i32 6, i32 6, i32 6>
  %656 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %645, <4 x i32> %655) #5
  %657 = lshr <8 x i16> %656, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %658 = getelementptr inbounds i16, i16* %9, i64 168
  %659 = bitcast i16* %658 to <8 x i16>*
  %660 = load <8 x i16>, <8 x i16>* %659, align 16
  %661 = getelementptr inbounds i16, i16* %10, i64 168
  %662 = bitcast i16* %661 to <8 x i16>*
  %663 = load <8 x i16>, <8 x i16>* %662, align 16
  %664 = shufflevector <8 x i16> %660, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %665 = zext <4 x i16> %664 to <4 x i32>
  %666 = shufflevector <8 x i16> %663, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %667 = zext <4 x i16> %666 to <4 x i32>
  %668 = sub nsw <4 x i32> %665, %667
  %669 = sub nsw <4 x i32> zeroinitializer, %668
  %670 = icmp slt <4 x i32> %668, zeroinitializer
  %671 = select <4 x i1> %670, <4 x i32> %669, <4 x i32> %668
  %672 = add nuw nsw <4 x i32> %671, <i32 32, i32 32, i32 32, i32 32>
  %673 = lshr <4 x i32> %672, <i32 6, i32 6, i32 6, i32 6>
  %674 = shufflevector <8 x i16> %660, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %675 = shufflevector <8 x i16> %663, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %676 = bitcast <8 x i16> %674 to <4 x i32>
  %677 = bitcast <8 x i16> %675 to <4 x i32>
  %678 = sub <4 x i32> %676, %677
  %679 = sub <4 x i32> zeroinitializer, %678
  %680 = icmp slt <4 x i32> %678, zeroinitializer
  %681 = select <4 x i1> %680, <4 x i32> %679, <4 x i32> %678
  %682 = add nuw <4 x i32> %681, <i32 32, i32 32, i32 32, i32 32>
  %683 = lshr <4 x i32> %682, <i32 6, i32 6, i32 6, i32 6>
  %684 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %673, <4 x i32> %683) #5
  %685 = lshr <8 x i16> %684, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %686 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %657, <8 x i16> %685) #5
  %687 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %686, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %688 = icmp slt <16 x i8> %687, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %689 = select <16 x i1> %688, <16 x i8> %687, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %690 = bitcast i8* %631 to <16 x i8>*
  store <16 x i8> %689, <16 x i8>* %690, align 16
  %691 = getelementptr inbounds i16, i16* %9, i64 176
  %692 = getelementptr inbounds i16, i16* %10, i64 176
  %693 = getelementptr inbounds i8, i8* %507, i64 48
  %694 = bitcast i16* %691 to <8 x i16>*
  %695 = load <8 x i16>, <8 x i16>* %694, align 16
  %696 = bitcast i16* %692 to <8 x i16>*
  %697 = load <8 x i16>, <8 x i16>* %696, align 16
  %698 = shufflevector <8 x i16> %695, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %699 = zext <4 x i16> %698 to <4 x i32>
  %700 = shufflevector <8 x i16> %697, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %701 = zext <4 x i16> %700 to <4 x i32>
  %702 = sub nsw <4 x i32> %699, %701
  %703 = sub nsw <4 x i32> zeroinitializer, %702
  %704 = icmp slt <4 x i32> %702, zeroinitializer
  %705 = select <4 x i1> %704, <4 x i32> %703, <4 x i32> %702
  %706 = add nuw nsw <4 x i32> %705, <i32 32, i32 32, i32 32, i32 32>
  %707 = lshr <4 x i32> %706, <i32 6, i32 6, i32 6, i32 6>
  %708 = shufflevector <8 x i16> %695, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %709 = shufflevector <8 x i16> %697, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %710 = bitcast <8 x i16> %708 to <4 x i32>
  %711 = bitcast <8 x i16> %709 to <4 x i32>
  %712 = sub <4 x i32> %710, %711
  %713 = sub <4 x i32> zeroinitializer, %712
  %714 = icmp slt <4 x i32> %712, zeroinitializer
  %715 = select <4 x i1> %714, <4 x i32> %713, <4 x i32> %712
  %716 = add nuw <4 x i32> %715, <i32 32, i32 32, i32 32, i32 32>
  %717 = lshr <4 x i32> %716, <i32 6, i32 6, i32 6, i32 6>
  %718 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %707, <4 x i32> %717) #5
  %719 = lshr <8 x i16> %718, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %720 = getelementptr inbounds i16, i16* %9, i64 184
  %721 = bitcast i16* %720 to <8 x i16>*
  %722 = load <8 x i16>, <8 x i16>* %721, align 16
  %723 = getelementptr inbounds i16, i16* %10, i64 184
  %724 = bitcast i16* %723 to <8 x i16>*
  %725 = load <8 x i16>, <8 x i16>* %724, align 16
  %726 = shufflevector <8 x i16> %722, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %727 = zext <4 x i16> %726 to <4 x i32>
  %728 = shufflevector <8 x i16> %725, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %729 = zext <4 x i16> %728 to <4 x i32>
  %730 = sub nsw <4 x i32> %727, %729
  %731 = sub nsw <4 x i32> zeroinitializer, %730
  %732 = icmp slt <4 x i32> %730, zeroinitializer
  %733 = select <4 x i1> %732, <4 x i32> %731, <4 x i32> %730
  %734 = add nuw nsw <4 x i32> %733, <i32 32, i32 32, i32 32, i32 32>
  %735 = lshr <4 x i32> %734, <i32 6, i32 6, i32 6, i32 6>
  %736 = shufflevector <8 x i16> %722, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %737 = shufflevector <8 x i16> %725, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %738 = bitcast <8 x i16> %736 to <4 x i32>
  %739 = bitcast <8 x i16> %737 to <4 x i32>
  %740 = sub <4 x i32> %738, %739
  %741 = sub <4 x i32> zeroinitializer, %740
  %742 = icmp slt <4 x i32> %740, zeroinitializer
  %743 = select <4 x i1> %742, <4 x i32> %741, <4 x i32> %740
  %744 = add nuw <4 x i32> %743, <i32 32, i32 32, i32 32, i32 32>
  %745 = lshr <4 x i32> %744, <i32 6, i32 6, i32 6, i32 6>
  %746 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %735, <4 x i32> %745) #5
  %747 = lshr <8 x i16> %746, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %748 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %719, <8 x i16> %747) #5
  %749 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %748, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %750 = icmp slt <16 x i8> %749, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %751 = select <16 x i1> %750, <16 x i8> %749, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %752 = bitcast i8* %693 to <16 x i8>*
  store <16 x i8> %751, <16 x i8>* %752, align 16
  %753 = getelementptr inbounds i16, i16* %9, i64 192
  %754 = getelementptr inbounds i16, i16* %10, i64 192
  %755 = getelementptr inbounds i8, i8* %507, i64 %3
  %756 = add nsw i32 %11, -1
  %757 = icmp eq i32 %756, 0
  br i1 %757, label %758, label %7

758:                                              ; preds = %7
  %759 = bitcast i16* %753 to <8 x i16>*
  %760 = load <8 x i16>, <8 x i16>* %759, align 16
  %761 = bitcast i16* %754 to <8 x i16>*
  %762 = load <8 x i16>, <8 x i16>* %761, align 16
  %763 = shufflevector <8 x i16> %760, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %764 = zext <4 x i16> %763 to <4 x i32>
  %765 = shufflevector <8 x i16> %762, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %766 = zext <4 x i16> %765 to <4 x i32>
  %767 = sub nsw <4 x i32> %764, %766
  %768 = sub nsw <4 x i32> zeroinitializer, %767
  %769 = icmp slt <4 x i32> %767, zeroinitializer
  %770 = select <4 x i1> %769, <4 x i32> %768, <4 x i32> %767
  %771 = add nuw nsw <4 x i32> %770, <i32 32, i32 32, i32 32, i32 32>
  %772 = lshr <4 x i32> %771, <i32 6, i32 6, i32 6, i32 6>
  %773 = shufflevector <8 x i16> %760, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %774 = shufflevector <8 x i16> %762, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %775 = bitcast <8 x i16> %773 to <4 x i32>
  %776 = bitcast <8 x i16> %774 to <4 x i32>
  %777 = sub <4 x i32> %775, %776
  %778 = sub <4 x i32> zeroinitializer, %777
  %779 = icmp slt <4 x i32> %777, zeroinitializer
  %780 = select <4 x i1> %779, <4 x i32> %778, <4 x i32> %777
  %781 = add nuw <4 x i32> %780, <i32 32, i32 32, i32 32, i32 32>
  %782 = lshr <4 x i32> %781, <i32 6, i32 6, i32 6, i32 6>
  %783 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %772, <4 x i32> %782) #5
  %784 = lshr <8 x i16> %783, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %785 = getelementptr inbounds i16, i16* %9, i64 200
  %786 = bitcast i16* %785 to <8 x i16>*
  %787 = load <8 x i16>, <8 x i16>* %786, align 16
  %788 = getelementptr inbounds i16, i16* %10, i64 200
  %789 = bitcast i16* %788 to <8 x i16>*
  %790 = load <8 x i16>, <8 x i16>* %789, align 16
  %791 = shufflevector <8 x i16> %787, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %792 = zext <4 x i16> %791 to <4 x i32>
  %793 = shufflevector <8 x i16> %790, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %794 = zext <4 x i16> %793 to <4 x i32>
  %795 = sub nsw <4 x i32> %792, %794
  %796 = sub nsw <4 x i32> zeroinitializer, %795
  %797 = icmp slt <4 x i32> %795, zeroinitializer
  %798 = select <4 x i1> %797, <4 x i32> %796, <4 x i32> %795
  %799 = add nuw nsw <4 x i32> %798, <i32 32, i32 32, i32 32, i32 32>
  %800 = lshr <4 x i32> %799, <i32 6, i32 6, i32 6, i32 6>
  %801 = shufflevector <8 x i16> %787, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %802 = shufflevector <8 x i16> %790, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %803 = bitcast <8 x i16> %801 to <4 x i32>
  %804 = bitcast <8 x i16> %802 to <4 x i32>
  %805 = sub <4 x i32> %803, %804
  %806 = sub <4 x i32> zeroinitializer, %805
  %807 = icmp slt <4 x i32> %805, zeroinitializer
  %808 = select <4 x i1> %807, <4 x i32> %806, <4 x i32> %805
  %809 = add nuw <4 x i32> %808, <i32 32, i32 32, i32 32, i32 32>
  %810 = lshr <4 x i32> %809, <i32 6, i32 6, i32 6, i32 6>
  %811 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %800, <4 x i32> %810) #5
  %812 = lshr <8 x i16> %811, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %813 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %784, <8 x i16> %812) #5
  %814 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %813, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %815 = icmp slt <16 x i8> %814, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %816 = select <16 x i1> %815, <16 x i8> %814, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %817 = bitcast i8* %755 to <16 x i8>*
  store <16 x i8> %816, <16 x i8>* %817, align 16
  %818 = getelementptr inbounds i16, i16* %9, i64 208
  %819 = getelementptr inbounds i16, i16* %10, i64 208
  %820 = getelementptr inbounds i8, i8* %755, i64 16
  %821 = bitcast i16* %818 to <8 x i16>*
  %822 = load <8 x i16>, <8 x i16>* %821, align 16
  %823 = bitcast i16* %819 to <8 x i16>*
  %824 = load <8 x i16>, <8 x i16>* %823, align 16
  %825 = shufflevector <8 x i16> %822, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %826 = zext <4 x i16> %825 to <4 x i32>
  %827 = shufflevector <8 x i16> %824, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %828 = zext <4 x i16> %827 to <4 x i32>
  %829 = sub nsw <4 x i32> %826, %828
  %830 = sub nsw <4 x i32> zeroinitializer, %829
  %831 = icmp slt <4 x i32> %829, zeroinitializer
  %832 = select <4 x i1> %831, <4 x i32> %830, <4 x i32> %829
  %833 = add nuw nsw <4 x i32> %832, <i32 32, i32 32, i32 32, i32 32>
  %834 = lshr <4 x i32> %833, <i32 6, i32 6, i32 6, i32 6>
  %835 = shufflevector <8 x i16> %822, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %836 = shufflevector <8 x i16> %824, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %837 = bitcast <8 x i16> %835 to <4 x i32>
  %838 = bitcast <8 x i16> %836 to <4 x i32>
  %839 = sub <4 x i32> %837, %838
  %840 = sub <4 x i32> zeroinitializer, %839
  %841 = icmp slt <4 x i32> %839, zeroinitializer
  %842 = select <4 x i1> %841, <4 x i32> %840, <4 x i32> %839
  %843 = add nuw <4 x i32> %842, <i32 32, i32 32, i32 32, i32 32>
  %844 = lshr <4 x i32> %843, <i32 6, i32 6, i32 6, i32 6>
  %845 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %834, <4 x i32> %844) #5
  %846 = lshr <8 x i16> %845, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %847 = getelementptr inbounds i16, i16* %9, i64 216
  %848 = bitcast i16* %847 to <8 x i16>*
  %849 = load <8 x i16>, <8 x i16>* %848, align 16
  %850 = getelementptr inbounds i16, i16* %10, i64 216
  %851 = bitcast i16* %850 to <8 x i16>*
  %852 = load <8 x i16>, <8 x i16>* %851, align 16
  %853 = shufflevector <8 x i16> %849, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %854 = zext <4 x i16> %853 to <4 x i32>
  %855 = shufflevector <8 x i16> %852, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %856 = zext <4 x i16> %855 to <4 x i32>
  %857 = sub nsw <4 x i32> %854, %856
  %858 = sub nsw <4 x i32> zeroinitializer, %857
  %859 = icmp slt <4 x i32> %857, zeroinitializer
  %860 = select <4 x i1> %859, <4 x i32> %858, <4 x i32> %857
  %861 = add nuw nsw <4 x i32> %860, <i32 32, i32 32, i32 32, i32 32>
  %862 = lshr <4 x i32> %861, <i32 6, i32 6, i32 6, i32 6>
  %863 = shufflevector <8 x i16> %849, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %864 = shufflevector <8 x i16> %852, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %865 = bitcast <8 x i16> %863 to <4 x i32>
  %866 = bitcast <8 x i16> %864 to <4 x i32>
  %867 = sub <4 x i32> %865, %866
  %868 = sub <4 x i32> zeroinitializer, %867
  %869 = icmp slt <4 x i32> %867, zeroinitializer
  %870 = select <4 x i1> %869, <4 x i32> %868, <4 x i32> %867
  %871 = add nuw <4 x i32> %870, <i32 32, i32 32, i32 32, i32 32>
  %872 = lshr <4 x i32> %871, <i32 6, i32 6, i32 6, i32 6>
  %873 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %862, <4 x i32> %872) #5
  %874 = lshr <8 x i16> %873, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %875 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %846, <8 x i16> %874) #5
  %876 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %875, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %877 = icmp slt <16 x i8> %876, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %878 = select <16 x i1> %877, <16 x i8> %876, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %879 = bitcast i8* %820 to <16 x i8>*
  store <16 x i8> %878, <16 x i8>* %879, align 16
  %880 = getelementptr inbounds i16, i16* %9, i64 224
  %881 = getelementptr inbounds i16, i16* %10, i64 224
  %882 = getelementptr inbounds i8, i8* %755, i64 32
  %883 = bitcast i16* %880 to <8 x i16>*
  %884 = load <8 x i16>, <8 x i16>* %883, align 16
  %885 = bitcast i16* %881 to <8 x i16>*
  %886 = load <8 x i16>, <8 x i16>* %885, align 16
  %887 = shufflevector <8 x i16> %884, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %888 = zext <4 x i16> %887 to <4 x i32>
  %889 = shufflevector <8 x i16> %886, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %890 = zext <4 x i16> %889 to <4 x i32>
  %891 = sub nsw <4 x i32> %888, %890
  %892 = sub nsw <4 x i32> zeroinitializer, %891
  %893 = icmp slt <4 x i32> %891, zeroinitializer
  %894 = select <4 x i1> %893, <4 x i32> %892, <4 x i32> %891
  %895 = add nuw nsw <4 x i32> %894, <i32 32, i32 32, i32 32, i32 32>
  %896 = lshr <4 x i32> %895, <i32 6, i32 6, i32 6, i32 6>
  %897 = shufflevector <8 x i16> %884, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %898 = shufflevector <8 x i16> %886, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %899 = bitcast <8 x i16> %897 to <4 x i32>
  %900 = bitcast <8 x i16> %898 to <4 x i32>
  %901 = sub <4 x i32> %899, %900
  %902 = sub <4 x i32> zeroinitializer, %901
  %903 = icmp slt <4 x i32> %901, zeroinitializer
  %904 = select <4 x i1> %903, <4 x i32> %902, <4 x i32> %901
  %905 = add nuw <4 x i32> %904, <i32 32, i32 32, i32 32, i32 32>
  %906 = lshr <4 x i32> %905, <i32 6, i32 6, i32 6, i32 6>
  %907 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %896, <4 x i32> %906) #5
  %908 = lshr <8 x i16> %907, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %909 = getelementptr inbounds i16, i16* %9, i64 232
  %910 = bitcast i16* %909 to <8 x i16>*
  %911 = load <8 x i16>, <8 x i16>* %910, align 16
  %912 = getelementptr inbounds i16, i16* %10, i64 232
  %913 = bitcast i16* %912 to <8 x i16>*
  %914 = load <8 x i16>, <8 x i16>* %913, align 16
  %915 = shufflevector <8 x i16> %911, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %916 = zext <4 x i16> %915 to <4 x i32>
  %917 = shufflevector <8 x i16> %914, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %918 = zext <4 x i16> %917 to <4 x i32>
  %919 = sub nsw <4 x i32> %916, %918
  %920 = sub nsw <4 x i32> zeroinitializer, %919
  %921 = icmp slt <4 x i32> %919, zeroinitializer
  %922 = select <4 x i1> %921, <4 x i32> %920, <4 x i32> %919
  %923 = add nuw nsw <4 x i32> %922, <i32 32, i32 32, i32 32, i32 32>
  %924 = lshr <4 x i32> %923, <i32 6, i32 6, i32 6, i32 6>
  %925 = shufflevector <8 x i16> %911, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %926 = shufflevector <8 x i16> %914, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %927 = bitcast <8 x i16> %925 to <4 x i32>
  %928 = bitcast <8 x i16> %926 to <4 x i32>
  %929 = sub <4 x i32> %927, %928
  %930 = sub <4 x i32> zeroinitializer, %929
  %931 = icmp slt <4 x i32> %929, zeroinitializer
  %932 = select <4 x i1> %931, <4 x i32> %930, <4 x i32> %929
  %933 = add nuw <4 x i32> %932, <i32 32, i32 32, i32 32, i32 32>
  %934 = lshr <4 x i32> %933, <i32 6, i32 6, i32 6, i32 6>
  %935 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %924, <4 x i32> %934) #5
  %936 = lshr <8 x i16> %935, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %937 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %908, <8 x i16> %936) #5
  %938 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %937, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %939 = icmp slt <16 x i8> %938, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %940 = select <16 x i1> %939, <16 x i8> %938, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %941 = bitcast i8* %882 to <16 x i8>*
  store <16 x i8> %940, <16 x i8>* %941, align 16
  %942 = getelementptr inbounds i16, i16* %9, i64 240
  %943 = getelementptr inbounds i16, i16* %10, i64 240
  %944 = getelementptr inbounds i8, i8* %755, i64 48
  %945 = bitcast i16* %942 to <8 x i16>*
  %946 = load <8 x i16>, <8 x i16>* %945, align 16
  %947 = bitcast i16* %943 to <8 x i16>*
  %948 = load <8 x i16>, <8 x i16>* %947, align 16
  %949 = shufflevector <8 x i16> %946, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %950 = zext <4 x i16> %949 to <4 x i32>
  %951 = shufflevector <8 x i16> %948, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %952 = zext <4 x i16> %951 to <4 x i32>
  %953 = sub nsw <4 x i32> %950, %952
  %954 = sub nsw <4 x i32> zeroinitializer, %953
  %955 = icmp slt <4 x i32> %953, zeroinitializer
  %956 = select <4 x i1> %955, <4 x i32> %954, <4 x i32> %953
  %957 = add nuw nsw <4 x i32> %956, <i32 32, i32 32, i32 32, i32 32>
  %958 = lshr <4 x i32> %957, <i32 6, i32 6, i32 6, i32 6>
  %959 = shufflevector <8 x i16> %946, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %960 = shufflevector <8 x i16> %948, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %961 = bitcast <8 x i16> %959 to <4 x i32>
  %962 = bitcast <8 x i16> %960 to <4 x i32>
  %963 = sub <4 x i32> %961, %962
  %964 = sub <4 x i32> zeroinitializer, %963
  %965 = icmp slt <4 x i32> %963, zeroinitializer
  %966 = select <4 x i1> %965, <4 x i32> %964, <4 x i32> %963
  %967 = add nuw <4 x i32> %966, <i32 32, i32 32, i32 32, i32 32>
  %968 = lshr <4 x i32> %967, <i32 6, i32 6, i32 6, i32 6>
  %969 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %958, <4 x i32> %968) #5
  %970 = lshr <8 x i16> %969, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %971 = getelementptr inbounds i16, i16* %9, i64 248
  %972 = bitcast i16* %971 to <8 x i16>*
  %973 = load <8 x i16>, <8 x i16>* %972, align 16
  %974 = getelementptr inbounds i16, i16* %10, i64 248
  %975 = bitcast i16* %974 to <8 x i16>*
  %976 = load <8 x i16>, <8 x i16>* %975, align 16
  %977 = shufflevector <8 x i16> %973, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %978 = zext <4 x i16> %977 to <4 x i32>
  %979 = shufflevector <8 x i16> %976, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %980 = zext <4 x i16> %979 to <4 x i32>
  %981 = sub nsw <4 x i32> %978, %980
  %982 = sub nsw <4 x i32> zeroinitializer, %981
  %983 = icmp slt <4 x i32> %981, zeroinitializer
  %984 = select <4 x i1> %983, <4 x i32> %982, <4 x i32> %981
  %985 = add nuw nsw <4 x i32> %984, <i32 32, i32 32, i32 32, i32 32>
  %986 = lshr <4 x i32> %985, <i32 6, i32 6, i32 6, i32 6>
  %987 = shufflevector <8 x i16> %973, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %988 = shufflevector <8 x i16> %976, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %989 = bitcast <8 x i16> %987 to <4 x i32>
  %990 = bitcast <8 x i16> %988 to <4 x i32>
  %991 = sub <4 x i32> %989, %990
  %992 = sub <4 x i32> zeroinitializer, %991
  %993 = icmp slt <4 x i32> %991, zeroinitializer
  %994 = select <4 x i1> %993, <4 x i32> %992, <4 x i32> %991
  %995 = add nuw <4 x i32> %994, <i32 32, i32 32, i32 32, i32 32>
  %996 = lshr <4 x i32> %995, <i32 6, i32 6, i32 6, i32 6>
  %997 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %986, <4 x i32> %996) #5
  %998 = lshr <8 x i16> %997, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %999 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %970, <8 x i16> %998) #5
  %1000 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %999, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1001 = icmp slt <16 x i8> %1000, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1002 = select <16 x i1> %1001, <16 x i8> %1000, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1003 = bitcast i8* %944 to <16 x i8>*
  store <16 x i8> %1002, <16 x i8>* %1003, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_126WeightMask64x64_10bpp_SSE4ILb1EEEvPKvS5_Phl(i8* nocapture readonly, i8* nocapture readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %767, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %765, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %766, %7 ]
  %11 = phi i32 [ 21, %4 ], [ %768, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = shufflevector <8 x i16> %13, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %17 = zext <4 x i16> %16 to <4 x i32>
  %18 = shufflevector <8 x i16> %15, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %19 = zext <4 x i16> %18 to <4 x i32>
  %20 = sub nsw <4 x i32> %17, %19
  %21 = sub nsw <4 x i32> zeroinitializer, %20
  %22 = icmp slt <4 x i32> %20, zeroinitializer
  %23 = select <4 x i1> %22, <4 x i32> %21, <4 x i32> %20
  %24 = add nuw nsw <4 x i32> %23, <i32 32, i32 32, i32 32, i32 32>
  %25 = lshr <4 x i32> %24, <i32 6, i32 6, i32 6, i32 6>
  %26 = shufflevector <8 x i16> %13, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %27 = shufflevector <8 x i16> %15, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %28 = bitcast <8 x i16> %26 to <4 x i32>
  %29 = bitcast <8 x i16> %27 to <4 x i32>
  %30 = sub <4 x i32> %28, %29
  %31 = sub <4 x i32> zeroinitializer, %30
  %32 = icmp slt <4 x i32> %30, zeroinitializer
  %33 = select <4 x i1> %32, <4 x i32> %31, <4 x i32> %30
  %34 = add nuw <4 x i32> %33, <i32 32, i32 32, i32 32, i32 32>
  %35 = lshr <4 x i32> %34, <i32 6, i32 6, i32 6, i32 6>
  %36 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %25, <4 x i32> %35) #5
  %37 = lshr <8 x i16> %36, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %38 = getelementptr inbounds i16, i16* %9, i64 8
  %39 = bitcast i16* %38 to <8 x i16>*
  %40 = load <8 x i16>, <8 x i16>* %39, align 16
  %41 = getelementptr inbounds i16, i16* %10, i64 8
  %42 = bitcast i16* %41 to <8 x i16>*
  %43 = load <8 x i16>, <8 x i16>* %42, align 16
  %44 = shufflevector <8 x i16> %40, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %45 = zext <4 x i16> %44 to <4 x i32>
  %46 = shufflevector <8 x i16> %43, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %47 = zext <4 x i16> %46 to <4 x i32>
  %48 = sub nsw <4 x i32> %45, %47
  %49 = sub nsw <4 x i32> zeroinitializer, %48
  %50 = icmp slt <4 x i32> %48, zeroinitializer
  %51 = select <4 x i1> %50, <4 x i32> %49, <4 x i32> %48
  %52 = add nuw nsw <4 x i32> %51, <i32 32, i32 32, i32 32, i32 32>
  %53 = lshr <4 x i32> %52, <i32 6, i32 6, i32 6, i32 6>
  %54 = shufflevector <8 x i16> %40, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %55 = shufflevector <8 x i16> %43, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %56 = bitcast <8 x i16> %54 to <4 x i32>
  %57 = bitcast <8 x i16> %55 to <4 x i32>
  %58 = sub <4 x i32> %56, %57
  %59 = sub <4 x i32> zeroinitializer, %58
  %60 = icmp slt <4 x i32> %58, zeroinitializer
  %61 = select <4 x i1> %60, <4 x i32> %59, <4 x i32> %58
  %62 = add nuw <4 x i32> %61, <i32 32, i32 32, i32 32, i32 32>
  %63 = lshr <4 x i32> %62, <i32 6, i32 6, i32 6, i32 6>
  %64 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %53, <4 x i32> %63) #5
  %65 = lshr <8 x i16> %64, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %66 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %37, <8 x i16> %65) #5
  %67 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %66, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %68 = icmp slt <16 x i8> %67, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %69 = select <16 x i1> %68, <16 x i8> %67, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %70 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %69
  %71 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %70, <16 x i8>* %71, align 16
  %72 = getelementptr inbounds i16, i16* %9, i64 16
  %73 = getelementptr inbounds i16, i16* %10, i64 16
  %74 = getelementptr inbounds i8, i8* %8, i64 16
  %75 = bitcast i16* %72 to <8 x i16>*
  %76 = load <8 x i16>, <8 x i16>* %75, align 16
  %77 = bitcast i16* %73 to <8 x i16>*
  %78 = load <8 x i16>, <8 x i16>* %77, align 16
  %79 = shufflevector <8 x i16> %76, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %80 = zext <4 x i16> %79 to <4 x i32>
  %81 = shufflevector <8 x i16> %78, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %82 = zext <4 x i16> %81 to <4 x i32>
  %83 = sub nsw <4 x i32> %80, %82
  %84 = sub nsw <4 x i32> zeroinitializer, %83
  %85 = icmp slt <4 x i32> %83, zeroinitializer
  %86 = select <4 x i1> %85, <4 x i32> %84, <4 x i32> %83
  %87 = add nuw nsw <4 x i32> %86, <i32 32, i32 32, i32 32, i32 32>
  %88 = lshr <4 x i32> %87, <i32 6, i32 6, i32 6, i32 6>
  %89 = shufflevector <8 x i16> %76, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %90 = shufflevector <8 x i16> %78, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %91 = bitcast <8 x i16> %89 to <4 x i32>
  %92 = bitcast <8 x i16> %90 to <4 x i32>
  %93 = sub <4 x i32> %91, %92
  %94 = sub <4 x i32> zeroinitializer, %93
  %95 = icmp slt <4 x i32> %93, zeroinitializer
  %96 = select <4 x i1> %95, <4 x i32> %94, <4 x i32> %93
  %97 = add nuw <4 x i32> %96, <i32 32, i32 32, i32 32, i32 32>
  %98 = lshr <4 x i32> %97, <i32 6, i32 6, i32 6, i32 6>
  %99 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %88, <4 x i32> %98) #5
  %100 = lshr <8 x i16> %99, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %101 = getelementptr inbounds i16, i16* %9, i64 24
  %102 = bitcast i16* %101 to <8 x i16>*
  %103 = load <8 x i16>, <8 x i16>* %102, align 16
  %104 = getelementptr inbounds i16, i16* %10, i64 24
  %105 = bitcast i16* %104 to <8 x i16>*
  %106 = load <8 x i16>, <8 x i16>* %105, align 16
  %107 = shufflevector <8 x i16> %103, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %108 = zext <4 x i16> %107 to <4 x i32>
  %109 = shufflevector <8 x i16> %106, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %110 = zext <4 x i16> %109 to <4 x i32>
  %111 = sub nsw <4 x i32> %108, %110
  %112 = sub nsw <4 x i32> zeroinitializer, %111
  %113 = icmp slt <4 x i32> %111, zeroinitializer
  %114 = select <4 x i1> %113, <4 x i32> %112, <4 x i32> %111
  %115 = add nuw nsw <4 x i32> %114, <i32 32, i32 32, i32 32, i32 32>
  %116 = lshr <4 x i32> %115, <i32 6, i32 6, i32 6, i32 6>
  %117 = shufflevector <8 x i16> %103, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %118 = shufflevector <8 x i16> %106, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %119 = bitcast <8 x i16> %117 to <4 x i32>
  %120 = bitcast <8 x i16> %118 to <4 x i32>
  %121 = sub <4 x i32> %119, %120
  %122 = sub <4 x i32> zeroinitializer, %121
  %123 = icmp slt <4 x i32> %121, zeroinitializer
  %124 = select <4 x i1> %123, <4 x i32> %122, <4 x i32> %121
  %125 = add nuw <4 x i32> %124, <i32 32, i32 32, i32 32, i32 32>
  %126 = lshr <4 x i32> %125, <i32 6, i32 6, i32 6, i32 6>
  %127 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %116, <4 x i32> %126) #5
  %128 = lshr <8 x i16> %127, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %129 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %100, <8 x i16> %128) #5
  %130 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %129, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %131 = icmp slt <16 x i8> %130, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %132 = select <16 x i1> %131, <16 x i8> %130, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %133 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %132
  %134 = bitcast i8* %74 to <16 x i8>*
  store <16 x i8> %133, <16 x i8>* %134, align 16
  %135 = getelementptr inbounds i16, i16* %9, i64 32
  %136 = getelementptr inbounds i16, i16* %10, i64 32
  %137 = getelementptr inbounds i8, i8* %8, i64 32
  %138 = bitcast i16* %135 to <8 x i16>*
  %139 = load <8 x i16>, <8 x i16>* %138, align 16
  %140 = bitcast i16* %136 to <8 x i16>*
  %141 = load <8 x i16>, <8 x i16>* %140, align 16
  %142 = shufflevector <8 x i16> %139, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %143 = zext <4 x i16> %142 to <4 x i32>
  %144 = shufflevector <8 x i16> %141, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %145 = zext <4 x i16> %144 to <4 x i32>
  %146 = sub nsw <4 x i32> %143, %145
  %147 = sub nsw <4 x i32> zeroinitializer, %146
  %148 = icmp slt <4 x i32> %146, zeroinitializer
  %149 = select <4 x i1> %148, <4 x i32> %147, <4 x i32> %146
  %150 = add nuw nsw <4 x i32> %149, <i32 32, i32 32, i32 32, i32 32>
  %151 = lshr <4 x i32> %150, <i32 6, i32 6, i32 6, i32 6>
  %152 = shufflevector <8 x i16> %139, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %153 = shufflevector <8 x i16> %141, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %154 = bitcast <8 x i16> %152 to <4 x i32>
  %155 = bitcast <8 x i16> %153 to <4 x i32>
  %156 = sub <4 x i32> %154, %155
  %157 = sub <4 x i32> zeroinitializer, %156
  %158 = icmp slt <4 x i32> %156, zeroinitializer
  %159 = select <4 x i1> %158, <4 x i32> %157, <4 x i32> %156
  %160 = add nuw <4 x i32> %159, <i32 32, i32 32, i32 32, i32 32>
  %161 = lshr <4 x i32> %160, <i32 6, i32 6, i32 6, i32 6>
  %162 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %151, <4 x i32> %161) #5
  %163 = lshr <8 x i16> %162, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %164 = getelementptr inbounds i16, i16* %9, i64 40
  %165 = bitcast i16* %164 to <8 x i16>*
  %166 = load <8 x i16>, <8 x i16>* %165, align 16
  %167 = getelementptr inbounds i16, i16* %10, i64 40
  %168 = bitcast i16* %167 to <8 x i16>*
  %169 = load <8 x i16>, <8 x i16>* %168, align 16
  %170 = shufflevector <8 x i16> %166, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %171 = zext <4 x i16> %170 to <4 x i32>
  %172 = shufflevector <8 x i16> %169, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %173 = zext <4 x i16> %172 to <4 x i32>
  %174 = sub nsw <4 x i32> %171, %173
  %175 = sub nsw <4 x i32> zeroinitializer, %174
  %176 = icmp slt <4 x i32> %174, zeroinitializer
  %177 = select <4 x i1> %176, <4 x i32> %175, <4 x i32> %174
  %178 = add nuw nsw <4 x i32> %177, <i32 32, i32 32, i32 32, i32 32>
  %179 = lshr <4 x i32> %178, <i32 6, i32 6, i32 6, i32 6>
  %180 = shufflevector <8 x i16> %166, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %181 = shufflevector <8 x i16> %169, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %182 = bitcast <8 x i16> %180 to <4 x i32>
  %183 = bitcast <8 x i16> %181 to <4 x i32>
  %184 = sub <4 x i32> %182, %183
  %185 = sub <4 x i32> zeroinitializer, %184
  %186 = icmp slt <4 x i32> %184, zeroinitializer
  %187 = select <4 x i1> %186, <4 x i32> %185, <4 x i32> %184
  %188 = add nuw <4 x i32> %187, <i32 32, i32 32, i32 32, i32 32>
  %189 = lshr <4 x i32> %188, <i32 6, i32 6, i32 6, i32 6>
  %190 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %179, <4 x i32> %189) #5
  %191 = lshr <8 x i16> %190, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %192 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %163, <8 x i16> %191) #5
  %193 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %192, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %194 = icmp slt <16 x i8> %193, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %195 = select <16 x i1> %194, <16 x i8> %193, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %196 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %195
  %197 = bitcast i8* %137 to <16 x i8>*
  store <16 x i8> %196, <16 x i8>* %197, align 16
  %198 = getelementptr inbounds i16, i16* %9, i64 48
  %199 = getelementptr inbounds i16, i16* %10, i64 48
  %200 = getelementptr inbounds i8, i8* %8, i64 48
  %201 = bitcast i16* %198 to <8 x i16>*
  %202 = load <8 x i16>, <8 x i16>* %201, align 16
  %203 = bitcast i16* %199 to <8 x i16>*
  %204 = load <8 x i16>, <8 x i16>* %203, align 16
  %205 = shufflevector <8 x i16> %202, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %206 = zext <4 x i16> %205 to <4 x i32>
  %207 = shufflevector <8 x i16> %204, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %208 = zext <4 x i16> %207 to <4 x i32>
  %209 = sub nsw <4 x i32> %206, %208
  %210 = sub nsw <4 x i32> zeroinitializer, %209
  %211 = icmp slt <4 x i32> %209, zeroinitializer
  %212 = select <4 x i1> %211, <4 x i32> %210, <4 x i32> %209
  %213 = add nuw nsw <4 x i32> %212, <i32 32, i32 32, i32 32, i32 32>
  %214 = lshr <4 x i32> %213, <i32 6, i32 6, i32 6, i32 6>
  %215 = shufflevector <8 x i16> %202, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %216 = shufflevector <8 x i16> %204, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %217 = bitcast <8 x i16> %215 to <4 x i32>
  %218 = bitcast <8 x i16> %216 to <4 x i32>
  %219 = sub <4 x i32> %217, %218
  %220 = sub <4 x i32> zeroinitializer, %219
  %221 = icmp slt <4 x i32> %219, zeroinitializer
  %222 = select <4 x i1> %221, <4 x i32> %220, <4 x i32> %219
  %223 = add nuw <4 x i32> %222, <i32 32, i32 32, i32 32, i32 32>
  %224 = lshr <4 x i32> %223, <i32 6, i32 6, i32 6, i32 6>
  %225 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %214, <4 x i32> %224) #5
  %226 = lshr <8 x i16> %225, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %227 = getelementptr inbounds i16, i16* %9, i64 56
  %228 = bitcast i16* %227 to <8 x i16>*
  %229 = load <8 x i16>, <8 x i16>* %228, align 16
  %230 = getelementptr inbounds i16, i16* %10, i64 56
  %231 = bitcast i16* %230 to <8 x i16>*
  %232 = load <8 x i16>, <8 x i16>* %231, align 16
  %233 = shufflevector <8 x i16> %229, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %234 = zext <4 x i16> %233 to <4 x i32>
  %235 = shufflevector <8 x i16> %232, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %236 = zext <4 x i16> %235 to <4 x i32>
  %237 = sub nsw <4 x i32> %234, %236
  %238 = sub nsw <4 x i32> zeroinitializer, %237
  %239 = icmp slt <4 x i32> %237, zeroinitializer
  %240 = select <4 x i1> %239, <4 x i32> %238, <4 x i32> %237
  %241 = add nuw nsw <4 x i32> %240, <i32 32, i32 32, i32 32, i32 32>
  %242 = lshr <4 x i32> %241, <i32 6, i32 6, i32 6, i32 6>
  %243 = shufflevector <8 x i16> %229, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %244 = shufflevector <8 x i16> %232, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %245 = bitcast <8 x i16> %243 to <4 x i32>
  %246 = bitcast <8 x i16> %244 to <4 x i32>
  %247 = sub <4 x i32> %245, %246
  %248 = sub <4 x i32> zeroinitializer, %247
  %249 = icmp slt <4 x i32> %247, zeroinitializer
  %250 = select <4 x i1> %249, <4 x i32> %248, <4 x i32> %247
  %251 = add nuw <4 x i32> %250, <i32 32, i32 32, i32 32, i32 32>
  %252 = lshr <4 x i32> %251, <i32 6, i32 6, i32 6, i32 6>
  %253 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %242, <4 x i32> %252) #5
  %254 = lshr <8 x i16> %253, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %255 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %226, <8 x i16> %254) #5
  %256 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %255, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %257 = icmp slt <16 x i8> %256, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %258 = select <16 x i1> %257, <16 x i8> %256, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %259 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %258
  %260 = bitcast i8* %200 to <16 x i8>*
  store <16 x i8> %259, <16 x i8>* %260, align 16
  %261 = getelementptr inbounds i16, i16* %9, i64 64
  %262 = getelementptr inbounds i16, i16* %10, i64 64
  %263 = getelementptr inbounds i8, i8* %8, i64 %3
  %264 = bitcast i16* %261 to <8 x i16>*
  %265 = load <8 x i16>, <8 x i16>* %264, align 16
  %266 = bitcast i16* %262 to <8 x i16>*
  %267 = load <8 x i16>, <8 x i16>* %266, align 16
  %268 = shufflevector <8 x i16> %265, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %269 = zext <4 x i16> %268 to <4 x i32>
  %270 = shufflevector <8 x i16> %267, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %271 = zext <4 x i16> %270 to <4 x i32>
  %272 = sub nsw <4 x i32> %269, %271
  %273 = sub nsw <4 x i32> zeroinitializer, %272
  %274 = icmp slt <4 x i32> %272, zeroinitializer
  %275 = select <4 x i1> %274, <4 x i32> %273, <4 x i32> %272
  %276 = add nuw nsw <4 x i32> %275, <i32 32, i32 32, i32 32, i32 32>
  %277 = lshr <4 x i32> %276, <i32 6, i32 6, i32 6, i32 6>
  %278 = shufflevector <8 x i16> %265, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %279 = shufflevector <8 x i16> %267, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %280 = bitcast <8 x i16> %278 to <4 x i32>
  %281 = bitcast <8 x i16> %279 to <4 x i32>
  %282 = sub <4 x i32> %280, %281
  %283 = sub <4 x i32> zeroinitializer, %282
  %284 = icmp slt <4 x i32> %282, zeroinitializer
  %285 = select <4 x i1> %284, <4 x i32> %283, <4 x i32> %282
  %286 = add nuw <4 x i32> %285, <i32 32, i32 32, i32 32, i32 32>
  %287 = lshr <4 x i32> %286, <i32 6, i32 6, i32 6, i32 6>
  %288 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %277, <4 x i32> %287) #5
  %289 = lshr <8 x i16> %288, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %290 = getelementptr inbounds i16, i16* %9, i64 72
  %291 = bitcast i16* %290 to <8 x i16>*
  %292 = load <8 x i16>, <8 x i16>* %291, align 16
  %293 = getelementptr inbounds i16, i16* %10, i64 72
  %294 = bitcast i16* %293 to <8 x i16>*
  %295 = load <8 x i16>, <8 x i16>* %294, align 16
  %296 = shufflevector <8 x i16> %292, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %297 = zext <4 x i16> %296 to <4 x i32>
  %298 = shufflevector <8 x i16> %295, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %299 = zext <4 x i16> %298 to <4 x i32>
  %300 = sub nsw <4 x i32> %297, %299
  %301 = sub nsw <4 x i32> zeroinitializer, %300
  %302 = icmp slt <4 x i32> %300, zeroinitializer
  %303 = select <4 x i1> %302, <4 x i32> %301, <4 x i32> %300
  %304 = add nuw nsw <4 x i32> %303, <i32 32, i32 32, i32 32, i32 32>
  %305 = lshr <4 x i32> %304, <i32 6, i32 6, i32 6, i32 6>
  %306 = shufflevector <8 x i16> %292, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %307 = shufflevector <8 x i16> %295, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %308 = bitcast <8 x i16> %306 to <4 x i32>
  %309 = bitcast <8 x i16> %307 to <4 x i32>
  %310 = sub <4 x i32> %308, %309
  %311 = sub <4 x i32> zeroinitializer, %310
  %312 = icmp slt <4 x i32> %310, zeroinitializer
  %313 = select <4 x i1> %312, <4 x i32> %311, <4 x i32> %310
  %314 = add nuw <4 x i32> %313, <i32 32, i32 32, i32 32, i32 32>
  %315 = lshr <4 x i32> %314, <i32 6, i32 6, i32 6, i32 6>
  %316 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %305, <4 x i32> %315) #5
  %317 = lshr <8 x i16> %316, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %318 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %289, <8 x i16> %317) #5
  %319 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %318, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %320 = icmp slt <16 x i8> %319, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %321 = select <16 x i1> %320, <16 x i8> %319, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %322 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %321
  %323 = bitcast i8* %263 to <16 x i8>*
  store <16 x i8> %322, <16 x i8>* %323, align 16
  %324 = getelementptr inbounds i16, i16* %9, i64 80
  %325 = getelementptr inbounds i16, i16* %10, i64 80
  %326 = getelementptr inbounds i8, i8* %263, i64 16
  %327 = bitcast i16* %324 to <8 x i16>*
  %328 = load <8 x i16>, <8 x i16>* %327, align 16
  %329 = bitcast i16* %325 to <8 x i16>*
  %330 = load <8 x i16>, <8 x i16>* %329, align 16
  %331 = shufflevector <8 x i16> %328, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %332 = zext <4 x i16> %331 to <4 x i32>
  %333 = shufflevector <8 x i16> %330, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %334 = zext <4 x i16> %333 to <4 x i32>
  %335 = sub nsw <4 x i32> %332, %334
  %336 = sub nsw <4 x i32> zeroinitializer, %335
  %337 = icmp slt <4 x i32> %335, zeroinitializer
  %338 = select <4 x i1> %337, <4 x i32> %336, <4 x i32> %335
  %339 = add nuw nsw <4 x i32> %338, <i32 32, i32 32, i32 32, i32 32>
  %340 = lshr <4 x i32> %339, <i32 6, i32 6, i32 6, i32 6>
  %341 = shufflevector <8 x i16> %328, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %342 = shufflevector <8 x i16> %330, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %343 = bitcast <8 x i16> %341 to <4 x i32>
  %344 = bitcast <8 x i16> %342 to <4 x i32>
  %345 = sub <4 x i32> %343, %344
  %346 = sub <4 x i32> zeroinitializer, %345
  %347 = icmp slt <4 x i32> %345, zeroinitializer
  %348 = select <4 x i1> %347, <4 x i32> %346, <4 x i32> %345
  %349 = add nuw <4 x i32> %348, <i32 32, i32 32, i32 32, i32 32>
  %350 = lshr <4 x i32> %349, <i32 6, i32 6, i32 6, i32 6>
  %351 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %340, <4 x i32> %350) #5
  %352 = lshr <8 x i16> %351, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %353 = getelementptr inbounds i16, i16* %9, i64 88
  %354 = bitcast i16* %353 to <8 x i16>*
  %355 = load <8 x i16>, <8 x i16>* %354, align 16
  %356 = getelementptr inbounds i16, i16* %10, i64 88
  %357 = bitcast i16* %356 to <8 x i16>*
  %358 = load <8 x i16>, <8 x i16>* %357, align 16
  %359 = shufflevector <8 x i16> %355, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %360 = zext <4 x i16> %359 to <4 x i32>
  %361 = shufflevector <8 x i16> %358, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %362 = zext <4 x i16> %361 to <4 x i32>
  %363 = sub nsw <4 x i32> %360, %362
  %364 = sub nsw <4 x i32> zeroinitializer, %363
  %365 = icmp slt <4 x i32> %363, zeroinitializer
  %366 = select <4 x i1> %365, <4 x i32> %364, <4 x i32> %363
  %367 = add nuw nsw <4 x i32> %366, <i32 32, i32 32, i32 32, i32 32>
  %368 = lshr <4 x i32> %367, <i32 6, i32 6, i32 6, i32 6>
  %369 = shufflevector <8 x i16> %355, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %370 = shufflevector <8 x i16> %358, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %371 = bitcast <8 x i16> %369 to <4 x i32>
  %372 = bitcast <8 x i16> %370 to <4 x i32>
  %373 = sub <4 x i32> %371, %372
  %374 = sub <4 x i32> zeroinitializer, %373
  %375 = icmp slt <4 x i32> %373, zeroinitializer
  %376 = select <4 x i1> %375, <4 x i32> %374, <4 x i32> %373
  %377 = add nuw <4 x i32> %376, <i32 32, i32 32, i32 32, i32 32>
  %378 = lshr <4 x i32> %377, <i32 6, i32 6, i32 6, i32 6>
  %379 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %368, <4 x i32> %378) #5
  %380 = lshr <8 x i16> %379, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %381 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %352, <8 x i16> %380) #5
  %382 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %381, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %383 = icmp slt <16 x i8> %382, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %384 = select <16 x i1> %383, <16 x i8> %382, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %385 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %384
  %386 = bitcast i8* %326 to <16 x i8>*
  store <16 x i8> %385, <16 x i8>* %386, align 16
  %387 = getelementptr inbounds i16, i16* %9, i64 96
  %388 = getelementptr inbounds i16, i16* %10, i64 96
  %389 = getelementptr inbounds i8, i8* %263, i64 32
  %390 = bitcast i16* %387 to <8 x i16>*
  %391 = load <8 x i16>, <8 x i16>* %390, align 16
  %392 = bitcast i16* %388 to <8 x i16>*
  %393 = load <8 x i16>, <8 x i16>* %392, align 16
  %394 = shufflevector <8 x i16> %391, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %395 = zext <4 x i16> %394 to <4 x i32>
  %396 = shufflevector <8 x i16> %393, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %397 = zext <4 x i16> %396 to <4 x i32>
  %398 = sub nsw <4 x i32> %395, %397
  %399 = sub nsw <4 x i32> zeroinitializer, %398
  %400 = icmp slt <4 x i32> %398, zeroinitializer
  %401 = select <4 x i1> %400, <4 x i32> %399, <4 x i32> %398
  %402 = add nuw nsw <4 x i32> %401, <i32 32, i32 32, i32 32, i32 32>
  %403 = lshr <4 x i32> %402, <i32 6, i32 6, i32 6, i32 6>
  %404 = shufflevector <8 x i16> %391, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %405 = shufflevector <8 x i16> %393, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %406 = bitcast <8 x i16> %404 to <4 x i32>
  %407 = bitcast <8 x i16> %405 to <4 x i32>
  %408 = sub <4 x i32> %406, %407
  %409 = sub <4 x i32> zeroinitializer, %408
  %410 = icmp slt <4 x i32> %408, zeroinitializer
  %411 = select <4 x i1> %410, <4 x i32> %409, <4 x i32> %408
  %412 = add nuw <4 x i32> %411, <i32 32, i32 32, i32 32, i32 32>
  %413 = lshr <4 x i32> %412, <i32 6, i32 6, i32 6, i32 6>
  %414 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %403, <4 x i32> %413) #5
  %415 = lshr <8 x i16> %414, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %416 = getelementptr inbounds i16, i16* %9, i64 104
  %417 = bitcast i16* %416 to <8 x i16>*
  %418 = load <8 x i16>, <8 x i16>* %417, align 16
  %419 = getelementptr inbounds i16, i16* %10, i64 104
  %420 = bitcast i16* %419 to <8 x i16>*
  %421 = load <8 x i16>, <8 x i16>* %420, align 16
  %422 = shufflevector <8 x i16> %418, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %423 = zext <4 x i16> %422 to <4 x i32>
  %424 = shufflevector <8 x i16> %421, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %425 = zext <4 x i16> %424 to <4 x i32>
  %426 = sub nsw <4 x i32> %423, %425
  %427 = sub nsw <4 x i32> zeroinitializer, %426
  %428 = icmp slt <4 x i32> %426, zeroinitializer
  %429 = select <4 x i1> %428, <4 x i32> %427, <4 x i32> %426
  %430 = add nuw nsw <4 x i32> %429, <i32 32, i32 32, i32 32, i32 32>
  %431 = lshr <4 x i32> %430, <i32 6, i32 6, i32 6, i32 6>
  %432 = shufflevector <8 x i16> %418, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %433 = shufflevector <8 x i16> %421, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %434 = bitcast <8 x i16> %432 to <4 x i32>
  %435 = bitcast <8 x i16> %433 to <4 x i32>
  %436 = sub <4 x i32> %434, %435
  %437 = sub <4 x i32> zeroinitializer, %436
  %438 = icmp slt <4 x i32> %436, zeroinitializer
  %439 = select <4 x i1> %438, <4 x i32> %437, <4 x i32> %436
  %440 = add nuw <4 x i32> %439, <i32 32, i32 32, i32 32, i32 32>
  %441 = lshr <4 x i32> %440, <i32 6, i32 6, i32 6, i32 6>
  %442 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %431, <4 x i32> %441) #5
  %443 = lshr <8 x i16> %442, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %444 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %415, <8 x i16> %443) #5
  %445 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %444, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %446 = icmp slt <16 x i8> %445, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %447 = select <16 x i1> %446, <16 x i8> %445, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %448 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %447
  %449 = bitcast i8* %389 to <16 x i8>*
  store <16 x i8> %448, <16 x i8>* %449, align 16
  %450 = getelementptr inbounds i16, i16* %9, i64 112
  %451 = getelementptr inbounds i16, i16* %10, i64 112
  %452 = getelementptr inbounds i8, i8* %263, i64 48
  %453 = bitcast i16* %450 to <8 x i16>*
  %454 = load <8 x i16>, <8 x i16>* %453, align 16
  %455 = bitcast i16* %451 to <8 x i16>*
  %456 = load <8 x i16>, <8 x i16>* %455, align 16
  %457 = shufflevector <8 x i16> %454, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %458 = zext <4 x i16> %457 to <4 x i32>
  %459 = shufflevector <8 x i16> %456, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %460 = zext <4 x i16> %459 to <4 x i32>
  %461 = sub nsw <4 x i32> %458, %460
  %462 = sub nsw <4 x i32> zeroinitializer, %461
  %463 = icmp slt <4 x i32> %461, zeroinitializer
  %464 = select <4 x i1> %463, <4 x i32> %462, <4 x i32> %461
  %465 = add nuw nsw <4 x i32> %464, <i32 32, i32 32, i32 32, i32 32>
  %466 = lshr <4 x i32> %465, <i32 6, i32 6, i32 6, i32 6>
  %467 = shufflevector <8 x i16> %454, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %468 = shufflevector <8 x i16> %456, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %469 = bitcast <8 x i16> %467 to <4 x i32>
  %470 = bitcast <8 x i16> %468 to <4 x i32>
  %471 = sub <4 x i32> %469, %470
  %472 = sub <4 x i32> zeroinitializer, %471
  %473 = icmp slt <4 x i32> %471, zeroinitializer
  %474 = select <4 x i1> %473, <4 x i32> %472, <4 x i32> %471
  %475 = add nuw <4 x i32> %474, <i32 32, i32 32, i32 32, i32 32>
  %476 = lshr <4 x i32> %475, <i32 6, i32 6, i32 6, i32 6>
  %477 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %466, <4 x i32> %476) #5
  %478 = lshr <8 x i16> %477, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %479 = getelementptr inbounds i16, i16* %9, i64 120
  %480 = bitcast i16* %479 to <8 x i16>*
  %481 = load <8 x i16>, <8 x i16>* %480, align 16
  %482 = getelementptr inbounds i16, i16* %10, i64 120
  %483 = bitcast i16* %482 to <8 x i16>*
  %484 = load <8 x i16>, <8 x i16>* %483, align 16
  %485 = shufflevector <8 x i16> %481, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %486 = zext <4 x i16> %485 to <4 x i32>
  %487 = shufflevector <8 x i16> %484, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %488 = zext <4 x i16> %487 to <4 x i32>
  %489 = sub nsw <4 x i32> %486, %488
  %490 = sub nsw <4 x i32> zeroinitializer, %489
  %491 = icmp slt <4 x i32> %489, zeroinitializer
  %492 = select <4 x i1> %491, <4 x i32> %490, <4 x i32> %489
  %493 = add nuw nsw <4 x i32> %492, <i32 32, i32 32, i32 32, i32 32>
  %494 = lshr <4 x i32> %493, <i32 6, i32 6, i32 6, i32 6>
  %495 = shufflevector <8 x i16> %481, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %496 = shufflevector <8 x i16> %484, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %497 = bitcast <8 x i16> %495 to <4 x i32>
  %498 = bitcast <8 x i16> %496 to <4 x i32>
  %499 = sub <4 x i32> %497, %498
  %500 = sub <4 x i32> zeroinitializer, %499
  %501 = icmp slt <4 x i32> %499, zeroinitializer
  %502 = select <4 x i1> %501, <4 x i32> %500, <4 x i32> %499
  %503 = add nuw <4 x i32> %502, <i32 32, i32 32, i32 32, i32 32>
  %504 = lshr <4 x i32> %503, <i32 6, i32 6, i32 6, i32 6>
  %505 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %494, <4 x i32> %504) #5
  %506 = lshr <8 x i16> %505, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %507 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %478, <8 x i16> %506) #5
  %508 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %507, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %509 = icmp slt <16 x i8> %508, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %510 = select <16 x i1> %509, <16 x i8> %508, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %511 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %510
  %512 = bitcast i8* %452 to <16 x i8>*
  store <16 x i8> %511, <16 x i8>* %512, align 16
  %513 = getelementptr inbounds i16, i16* %9, i64 128
  %514 = getelementptr inbounds i16, i16* %10, i64 128
  %515 = getelementptr inbounds i8, i8* %263, i64 %3
  %516 = bitcast i16* %513 to <8 x i16>*
  %517 = load <8 x i16>, <8 x i16>* %516, align 16
  %518 = bitcast i16* %514 to <8 x i16>*
  %519 = load <8 x i16>, <8 x i16>* %518, align 16
  %520 = shufflevector <8 x i16> %517, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %521 = zext <4 x i16> %520 to <4 x i32>
  %522 = shufflevector <8 x i16> %519, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %523 = zext <4 x i16> %522 to <4 x i32>
  %524 = sub nsw <4 x i32> %521, %523
  %525 = sub nsw <4 x i32> zeroinitializer, %524
  %526 = icmp slt <4 x i32> %524, zeroinitializer
  %527 = select <4 x i1> %526, <4 x i32> %525, <4 x i32> %524
  %528 = add nuw nsw <4 x i32> %527, <i32 32, i32 32, i32 32, i32 32>
  %529 = lshr <4 x i32> %528, <i32 6, i32 6, i32 6, i32 6>
  %530 = shufflevector <8 x i16> %517, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %531 = shufflevector <8 x i16> %519, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %532 = bitcast <8 x i16> %530 to <4 x i32>
  %533 = bitcast <8 x i16> %531 to <4 x i32>
  %534 = sub <4 x i32> %532, %533
  %535 = sub <4 x i32> zeroinitializer, %534
  %536 = icmp slt <4 x i32> %534, zeroinitializer
  %537 = select <4 x i1> %536, <4 x i32> %535, <4 x i32> %534
  %538 = add nuw <4 x i32> %537, <i32 32, i32 32, i32 32, i32 32>
  %539 = lshr <4 x i32> %538, <i32 6, i32 6, i32 6, i32 6>
  %540 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %529, <4 x i32> %539) #5
  %541 = lshr <8 x i16> %540, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %542 = getelementptr inbounds i16, i16* %9, i64 136
  %543 = bitcast i16* %542 to <8 x i16>*
  %544 = load <8 x i16>, <8 x i16>* %543, align 16
  %545 = getelementptr inbounds i16, i16* %10, i64 136
  %546 = bitcast i16* %545 to <8 x i16>*
  %547 = load <8 x i16>, <8 x i16>* %546, align 16
  %548 = shufflevector <8 x i16> %544, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %549 = zext <4 x i16> %548 to <4 x i32>
  %550 = shufflevector <8 x i16> %547, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %551 = zext <4 x i16> %550 to <4 x i32>
  %552 = sub nsw <4 x i32> %549, %551
  %553 = sub nsw <4 x i32> zeroinitializer, %552
  %554 = icmp slt <4 x i32> %552, zeroinitializer
  %555 = select <4 x i1> %554, <4 x i32> %553, <4 x i32> %552
  %556 = add nuw nsw <4 x i32> %555, <i32 32, i32 32, i32 32, i32 32>
  %557 = lshr <4 x i32> %556, <i32 6, i32 6, i32 6, i32 6>
  %558 = shufflevector <8 x i16> %544, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %559 = shufflevector <8 x i16> %547, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %560 = bitcast <8 x i16> %558 to <4 x i32>
  %561 = bitcast <8 x i16> %559 to <4 x i32>
  %562 = sub <4 x i32> %560, %561
  %563 = sub <4 x i32> zeroinitializer, %562
  %564 = icmp slt <4 x i32> %562, zeroinitializer
  %565 = select <4 x i1> %564, <4 x i32> %563, <4 x i32> %562
  %566 = add nuw <4 x i32> %565, <i32 32, i32 32, i32 32, i32 32>
  %567 = lshr <4 x i32> %566, <i32 6, i32 6, i32 6, i32 6>
  %568 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %557, <4 x i32> %567) #5
  %569 = lshr <8 x i16> %568, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %570 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %541, <8 x i16> %569) #5
  %571 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %570, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %572 = icmp slt <16 x i8> %571, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %573 = select <16 x i1> %572, <16 x i8> %571, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %574 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %573
  %575 = bitcast i8* %515 to <16 x i8>*
  store <16 x i8> %574, <16 x i8>* %575, align 16
  %576 = getelementptr inbounds i16, i16* %9, i64 144
  %577 = getelementptr inbounds i16, i16* %10, i64 144
  %578 = getelementptr inbounds i8, i8* %515, i64 16
  %579 = bitcast i16* %576 to <8 x i16>*
  %580 = load <8 x i16>, <8 x i16>* %579, align 16
  %581 = bitcast i16* %577 to <8 x i16>*
  %582 = load <8 x i16>, <8 x i16>* %581, align 16
  %583 = shufflevector <8 x i16> %580, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %584 = zext <4 x i16> %583 to <4 x i32>
  %585 = shufflevector <8 x i16> %582, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %586 = zext <4 x i16> %585 to <4 x i32>
  %587 = sub nsw <4 x i32> %584, %586
  %588 = sub nsw <4 x i32> zeroinitializer, %587
  %589 = icmp slt <4 x i32> %587, zeroinitializer
  %590 = select <4 x i1> %589, <4 x i32> %588, <4 x i32> %587
  %591 = add nuw nsw <4 x i32> %590, <i32 32, i32 32, i32 32, i32 32>
  %592 = lshr <4 x i32> %591, <i32 6, i32 6, i32 6, i32 6>
  %593 = shufflevector <8 x i16> %580, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %594 = shufflevector <8 x i16> %582, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %595 = bitcast <8 x i16> %593 to <4 x i32>
  %596 = bitcast <8 x i16> %594 to <4 x i32>
  %597 = sub <4 x i32> %595, %596
  %598 = sub <4 x i32> zeroinitializer, %597
  %599 = icmp slt <4 x i32> %597, zeroinitializer
  %600 = select <4 x i1> %599, <4 x i32> %598, <4 x i32> %597
  %601 = add nuw <4 x i32> %600, <i32 32, i32 32, i32 32, i32 32>
  %602 = lshr <4 x i32> %601, <i32 6, i32 6, i32 6, i32 6>
  %603 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %592, <4 x i32> %602) #5
  %604 = lshr <8 x i16> %603, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %605 = getelementptr inbounds i16, i16* %9, i64 152
  %606 = bitcast i16* %605 to <8 x i16>*
  %607 = load <8 x i16>, <8 x i16>* %606, align 16
  %608 = getelementptr inbounds i16, i16* %10, i64 152
  %609 = bitcast i16* %608 to <8 x i16>*
  %610 = load <8 x i16>, <8 x i16>* %609, align 16
  %611 = shufflevector <8 x i16> %607, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %612 = zext <4 x i16> %611 to <4 x i32>
  %613 = shufflevector <8 x i16> %610, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %614 = zext <4 x i16> %613 to <4 x i32>
  %615 = sub nsw <4 x i32> %612, %614
  %616 = sub nsw <4 x i32> zeroinitializer, %615
  %617 = icmp slt <4 x i32> %615, zeroinitializer
  %618 = select <4 x i1> %617, <4 x i32> %616, <4 x i32> %615
  %619 = add nuw nsw <4 x i32> %618, <i32 32, i32 32, i32 32, i32 32>
  %620 = lshr <4 x i32> %619, <i32 6, i32 6, i32 6, i32 6>
  %621 = shufflevector <8 x i16> %607, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %622 = shufflevector <8 x i16> %610, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %623 = bitcast <8 x i16> %621 to <4 x i32>
  %624 = bitcast <8 x i16> %622 to <4 x i32>
  %625 = sub <4 x i32> %623, %624
  %626 = sub <4 x i32> zeroinitializer, %625
  %627 = icmp slt <4 x i32> %625, zeroinitializer
  %628 = select <4 x i1> %627, <4 x i32> %626, <4 x i32> %625
  %629 = add nuw <4 x i32> %628, <i32 32, i32 32, i32 32, i32 32>
  %630 = lshr <4 x i32> %629, <i32 6, i32 6, i32 6, i32 6>
  %631 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %620, <4 x i32> %630) #5
  %632 = lshr <8 x i16> %631, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %633 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %604, <8 x i16> %632) #5
  %634 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %633, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %635 = icmp slt <16 x i8> %634, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %636 = select <16 x i1> %635, <16 x i8> %634, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %637 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %636
  %638 = bitcast i8* %578 to <16 x i8>*
  store <16 x i8> %637, <16 x i8>* %638, align 16
  %639 = getelementptr inbounds i16, i16* %9, i64 160
  %640 = getelementptr inbounds i16, i16* %10, i64 160
  %641 = getelementptr inbounds i8, i8* %515, i64 32
  %642 = bitcast i16* %639 to <8 x i16>*
  %643 = load <8 x i16>, <8 x i16>* %642, align 16
  %644 = bitcast i16* %640 to <8 x i16>*
  %645 = load <8 x i16>, <8 x i16>* %644, align 16
  %646 = shufflevector <8 x i16> %643, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %647 = zext <4 x i16> %646 to <4 x i32>
  %648 = shufflevector <8 x i16> %645, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %649 = zext <4 x i16> %648 to <4 x i32>
  %650 = sub nsw <4 x i32> %647, %649
  %651 = sub nsw <4 x i32> zeroinitializer, %650
  %652 = icmp slt <4 x i32> %650, zeroinitializer
  %653 = select <4 x i1> %652, <4 x i32> %651, <4 x i32> %650
  %654 = add nuw nsw <4 x i32> %653, <i32 32, i32 32, i32 32, i32 32>
  %655 = lshr <4 x i32> %654, <i32 6, i32 6, i32 6, i32 6>
  %656 = shufflevector <8 x i16> %643, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %657 = shufflevector <8 x i16> %645, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %658 = bitcast <8 x i16> %656 to <4 x i32>
  %659 = bitcast <8 x i16> %657 to <4 x i32>
  %660 = sub <4 x i32> %658, %659
  %661 = sub <4 x i32> zeroinitializer, %660
  %662 = icmp slt <4 x i32> %660, zeroinitializer
  %663 = select <4 x i1> %662, <4 x i32> %661, <4 x i32> %660
  %664 = add nuw <4 x i32> %663, <i32 32, i32 32, i32 32, i32 32>
  %665 = lshr <4 x i32> %664, <i32 6, i32 6, i32 6, i32 6>
  %666 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %655, <4 x i32> %665) #5
  %667 = lshr <8 x i16> %666, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %668 = getelementptr inbounds i16, i16* %9, i64 168
  %669 = bitcast i16* %668 to <8 x i16>*
  %670 = load <8 x i16>, <8 x i16>* %669, align 16
  %671 = getelementptr inbounds i16, i16* %10, i64 168
  %672 = bitcast i16* %671 to <8 x i16>*
  %673 = load <8 x i16>, <8 x i16>* %672, align 16
  %674 = shufflevector <8 x i16> %670, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %675 = zext <4 x i16> %674 to <4 x i32>
  %676 = shufflevector <8 x i16> %673, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %677 = zext <4 x i16> %676 to <4 x i32>
  %678 = sub nsw <4 x i32> %675, %677
  %679 = sub nsw <4 x i32> zeroinitializer, %678
  %680 = icmp slt <4 x i32> %678, zeroinitializer
  %681 = select <4 x i1> %680, <4 x i32> %679, <4 x i32> %678
  %682 = add nuw nsw <4 x i32> %681, <i32 32, i32 32, i32 32, i32 32>
  %683 = lshr <4 x i32> %682, <i32 6, i32 6, i32 6, i32 6>
  %684 = shufflevector <8 x i16> %670, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %685 = shufflevector <8 x i16> %673, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %686 = bitcast <8 x i16> %684 to <4 x i32>
  %687 = bitcast <8 x i16> %685 to <4 x i32>
  %688 = sub <4 x i32> %686, %687
  %689 = sub <4 x i32> zeroinitializer, %688
  %690 = icmp slt <4 x i32> %688, zeroinitializer
  %691 = select <4 x i1> %690, <4 x i32> %689, <4 x i32> %688
  %692 = add nuw <4 x i32> %691, <i32 32, i32 32, i32 32, i32 32>
  %693 = lshr <4 x i32> %692, <i32 6, i32 6, i32 6, i32 6>
  %694 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %683, <4 x i32> %693) #5
  %695 = lshr <8 x i16> %694, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %696 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %667, <8 x i16> %695) #5
  %697 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %696, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %698 = icmp slt <16 x i8> %697, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %699 = select <16 x i1> %698, <16 x i8> %697, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %700 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %699
  %701 = bitcast i8* %641 to <16 x i8>*
  store <16 x i8> %700, <16 x i8>* %701, align 16
  %702 = getelementptr inbounds i16, i16* %9, i64 176
  %703 = getelementptr inbounds i16, i16* %10, i64 176
  %704 = getelementptr inbounds i8, i8* %515, i64 48
  %705 = bitcast i16* %702 to <8 x i16>*
  %706 = load <8 x i16>, <8 x i16>* %705, align 16
  %707 = bitcast i16* %703 to <8 x i16>*
  %708 = load <8 x i16>, <8 x i16>* %707, align 16
  %709 = shufflevector <8 x i16> %706, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %710 = zext <4 x i16> %709 to <4 x i32>
  %711 = shufflevector <8 x i16> %708, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %712 = zext <4 x i16> %711 to <4 x i32>
  %713 = sub nsw <4 x i32> %710, %712
  %714 = sub nsw <4 x i32> zeroinitializer, %713
  %715 = icmp slt <4 x i32> %713, zeroinitializer
  %716 = select <4 x i1> %715, <4 x i32> %714, <4 x i32> %713
  %717 = add nuw nsw <4 x i32> %716, <i32 32, i32 32, i32 32, i32 32>
  %718 = lshr <4 x i32> %717, <i32 6, i32 6, i32 6, i32 6>
  %719 = shufflevector <8 x i16> %706, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %720 = shufflevector <8 x i16> %708, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %721 = bitcast <8 x i16> %719 to <4 x i32>
  %722 = bitcast <8 x i16> %720 to <4 x i32>
  %723 = sub <4 x i32> %721, %722
  %724 = sub <4 x i32> zeroinitializer, %723
  %725 = icmp slt <4 x i32> %723, zeroinitializer
  %726 = select <4 x i1> %725, <4 x i32> %724, <4 x i32> %723
  %727 = add nuw <4 x i32> %726, <i32 32, i32 32, i32 32, i32 32>
  %728 = lshr <4 x i32> %727, <i32 6, i32 6, i32 6, i32 6>
  %729 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %718, <4 x i32> %728) #5
  %730 = lshr <8 x i16> %729, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %731 = getelementptr inbounds i16, i16* %9, i64 184
  %732 = bitcast i16* %731 to <8 x i16>*
  %733 = load <8 x i16>, <8 x i16>* %732, align 16
  %734 = getelementptr inbounds i16, i16* %10, i64 184
  %735 = bitcast i16* %734 to <8 x i16>*
  %736 = load <8 x i16>, <8 x i16>* %735, align 16
  %737 = shufflevector <8 x i16> %733, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %738 = zext <4 x i16> %737 to <4 x i32>
  %739 = shufflevector <8 x i16> %736, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %740 = zext <4 x i16> %739 to <4 x i32>
  %741 = sub nsw <4 x i32> %738, %740
  %742 = sub nsw <4 x i32> zeroinitializer, %741
  %743 = icmp slt <4 x i32> %741, zeroinitializer
  %744 = select <4 x i1> %743, <4 x i32> %742, <4 x i32> %741
  %745 = add nuw nsw <4 x i32> %744, <i32 32, i32 32, i32 32, i32 32>
  %746 = lshr <4 x i32> %745, <i32 6, i32 6, i32 6, i32 6>
  %747 = shufflevector <8 x i16> %733, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %748 = shufflevector <8 x i16> %736, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %749 = bitcast <8 x i16> %747 to <4 x i32>
  %750 = bitcast <8 x i16> %748 to <4 x i32>
  %751 = sub <4 x i32> %749, %750
  %752 = sub <4 x i32> zeroinitializer, %751
  %753 = icmp slt <4 x i32> %751, zeroinitializer
  %754 = select <4 x i1> %753, <4 x i32> %752, <4 x i32> %751
  %755 = add nuw <4 x i32> %754, <i32 32, i32 32, i32 32, i32 32>
  %756 = lshr <4 x i32> %755, <i32 6, i32 6, i32 6, i32 6>
  %757 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %746, <4 x i32> %756) #5
  %758 = lshr <8 x i16> %757, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %759 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %730, <8 x i16> %758) #5
  %760 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %759, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %761 = icmp slt <16 x i8> %760, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %762 = select <16 x i1> %761, <16 x i8> %760, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %763 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %762
  %764 = bitcast i8* %704 to <16 x i8>*
  store <16 x i8> %763, <16 x i8>* %764, align 16
  %765 = getelementptr inbounds i16, i16* %9, i64 192
  %766 = getelementptr inbounds i16, i16* %10, i64 192
  %767 = getelementptr inbounds i8, i8* %515, i64 %3
  %768 = add nsw i32 %11, -1
  %769 = icmp eq i32 %768, 0
  br i1 %769, label %770, label %7

770:                                              ; preds = %7
  %771 = bitcast i16* %765 to <8 x i16>*
  %772 = load <8 x i16>, <8 x i16>* %771, align 16
  %773 = bitcast i16* %766 to <8 x i16>*
  %774 = load <8 x i16>, <8 x i16>* %773, align 16
  %775 = shufflevector <8 x i16> %772, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %776 = zext <4 x i16> %775 to <4 x i32>
  %777 = shufflevector <8 x i16> %774, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %778 = zext <4 x i16> %777 to <4 x i32>
  %779 = sub nsw <4 x i32> %776, %778
  %780 = sub nsw <4 x i32> zeroinitializer, %779
  %781 = icmp slt <4 x i32> %779, zeroinitializer
  %782 = select <4 x i1> %781, <4 x i32> %780, <4 x i32> %779
  %783 = add nuw nsw <4 x i32> %782, <i32 32, i32 32, i32 32, i32 32>
  %784 = lshr <4 x i32> %783, <i32 6, i32 6, i32 6, i32 6>
  %785 = shufflevector <8 x i16> %772, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %786 = shufflevector <8 x i16> %774, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %787 = bitcast <8 x i16> %785 to <4 x i32>
  %788 = bitcast <8 x i16> %786 to <4 x i32>
  %789 = sub <4 x i32> %787, %788
  %790 = sub <4 x i32> zeroinitializer, %789
  %791 = icmp slt <4 x i32> %789, zeroinitializer
  %792 = select <4 x i1> %791, <4 x i32> %790, <4 x i32> %789
  %793 = add nuw <4 x i32> %792, <i32 32, i32 32, i32 32, i32 32>
  %794 = lshr <4 x i32> %793, <i32 6, i32 6, i32 6, i32 6>
  %795 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %784, <4 x i32> %794) #5
  %796 = lshr <8 x i16> %795, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %797 = getelementptr inbounds i16, i16* %9, i64 200
  %798 = bitcast i16* %797 to <8 x i16>*
  %799 = load <8 x i16>, <8 x i16>* %798, align 16
  %800 = getelementptr inbounds i16, i16* %10, i64 200
  %801 = bitcast i16* %800 to <8 x i16>*
  %802 = load <8 x i16>, <8 x i16>* %801, align 16
  %803 = shufflevector <8 x i16> %799, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %804 = zext <4 x i16> %803 to <4 x i32>
  %805 = shufflevector <8 x i16> %802, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %806 = zext <4 x i16> %805 to <4 x i32>
  %807 = sub nsw <4 x i32> %804, %806
  %808 = sub nsw <4 x i32> zeroinitializer, %807
  %809 = icmp slt <4 x i32> %807, zeroinitializer
  %810 = select <4 x i1> %809, <4 x i32> %808, <4 x i32> %807
  %811 = add nuw nsw <4 x i32> %810, <i32 32, i32 32, i32 32, i32 32>
  %812 = lshr <4 x i32> %811, <i32 6, i32 6, i32 6, i32 6>
  %813 = shufflevector <8 x i16> %799, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %814 = shufflevector <8 x i16> %802, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %815 = bitcast <8 x i16> %813 to <4 x i32>
  %816 = bitcast <8 x i16> %814 to <4 x i32>
  %817 = sub <4 x i32> %815, %816
  %818 = sub <4 x i32> zeroinitializer, %817
  %819 = icmp slt <4 x i32> %817, zeroinitializer
  %820 = select <4 x i1> %819, <4 x i32> %818, <4 x i32> %817
  %821 = add nuw <4 x i32> %820, <i32 32, i32 32, i32 32, i32 32>
  %822 = lshr <4 x i32> %821, <i32 6, i32 6, i32 6, i32 6>
  %823 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %812, <4 x i32> %822) #5
  %824 = lshr <8 x i16> %823, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %825 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %796, <8 x i16> %824) #5
  %826 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %825, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %827 = icmp slt <16 x i8> %826, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %828 = select <16 x i1> %827, <16 x i8> %826, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %829 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %828
  %830 = bitcast i8* %767 to <16 x i8>*
  store <16 x i8> %829, <16 x i8>* %830, align 16
  %831 = getelementptr inbounds i16, i16* %9, i64 208
  %832 = getelementptr inbounds i16, i16* %10, i64 208
  %833 = getelementptr inbounds i8, i8* %767, i64 16
  %834 = bitcast i16* %831 to <8 x i16>*
  %835 = load <8 x i16>, <8 x i16>* %834, align 16
  %836 = bitcast i16* %832 to <8 x i16>*
  %837 = load <8 x i16>, <8 x i16>* %836, align 16
  %838 = shufflevector <8 x i16> %835, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %839 = zext <4 x i16> %838 to <4 x i32>
  %840 = shufflevector <8 x i16> %837, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %841 = zext <4 x i16> %840 to <4 x i32>
  %842 = sub nsw <4 x i32> %839, %841
  %843 = sub nsw <4 x i32> zeroinitializer, %842
  %844 = icmp slt <4 x i32> %842, zeroinitializer
  %845 = select <4 x i1> %844, <4 x i32> %843, <4 x i32> %842
  %846 = add nuw nsw <4 x i32> %845, <i32 32, i32 32, i32 32, i32 32>
  %847 = lshr <4 x i32> %846, <i32 6, i32 6, i32 6, i32 6>
  %848 = shufflevector <8 x i16> %835, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %849 = shufflevector <8 x i16> %837, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %850 = bitcast <8 x i16> %848 to <4 x i32>
  %851 = bitcast <8 x i16> %849 to <4 x i32>
  %852 = sub <4 x i32> %850, %851
  %853 = sub <4 x i32> zeroinitializer, %852
  %854 = icmp slt <4 x i32> %852, zeroinitializer
  %855 = select <4 x i1> %854, <4 x i32> %853, <4 x i32> %852
  %856 = add nuw <4 x i32> %855, <i32 32, i32 32, i32 32, i32 32>
  %857 = lshr <4 x i32> %856, <i32 6, i32 6, i32 6, i32 6>
  %858 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %847, <4 x i32> %857) #5
  %859 = lshr <8 x i16> %858, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %860 = getelementptr inbounds i16, i16* %9, i64 216
  %861 = bitcast i16* %860 to <8 x i16>*
  %862 = load <8 x i16>, <8 x i16>* %861, align 16
  %863 = getelementptr inbounds i16, i16* %10, i64 216
  %864 = bitcast i16* %863 to <8 x i16>*
  %865 = load <8 x i16>, <8 x i16>* %864, align 16
  %866 = shufflevector <8 x i16> %862, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %867 = zext <4 x i16> %866 to <4 x i32>
  %868 = shufflevector <8 x i16> %865, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %869 = zext <4 x i16> %868 to <4 x i32>
  %870 = sub nsw <4 x i32> %867, %869
  %871 = sub nsw <4 x i32> zeroinitializer, %870
  %872 = icmp slt <4 x i32> %870, zeroinitializer
  %873 = select <4 x i1> %872, <4 x i32> %871, <4 x i32> %870
  %874 = add nuw nsw <4 x i32> %873, <i32 32, i32 32, i32 32, i32 32>
  %875 = lshr <4 x i32> %874, <i32 6, i32 6, i32 6, i32 6>
  %876 = shufflevector <8 x i16> %862, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %877 = shufflevector <8 x i16> %865, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %878 = bitcast <8 x i16> %876 to <4 x i32>
  %879 = bitcast <8 x i16> %877 to <4 x i32>
  %880 = sub <4 x i32> %878, %879
  %881 = sub <4 x i32> zeroinitializer, %880
  %882 = icmp slt <4 x i32> %880, zeroinitializer
  %883 = select <4 x i1> %882, <4 x i32> %881, <4 x i32> %880
  %884 = add nuw <4 x i32> %883, <i32 32, i32 32, i32 32, i32 32>
  %885 = lshr <4 x i32> %884, <i32 6, i32 6, i32 6, i32 6>
  %886 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %875, <4 x i32> %885) #5
  %887 = lshr <8 x i16> %886, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %888 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %859, <8 x i16> %887) #5
  %889 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %888, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %890 = icmp slt <16 x i8> %889, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %891 = select <16 x i1> %890, <16 x i8> %889, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %892 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %891
  %893 = bitcast i8* %833 to <16 x i8>*
  store <16 x i8> %892, <16 x i8>* %893, align 16
  %894 = getelementptr inbounds i16, i16* %9, i64 224
  %895 = getelementptr inbounds i16, i16* %10, i64 224
  %896 = getelementptr inbounds i8, i8* %767, i64 32
  %897 = bitcast i16* %894 to <8 x i16>*
  %898 = load <8 x i16>, <8 x i16>* %897, align 16
  %899 = bitcast i16* %895 to <8 x i16>*
  %900 = load <8 x i16>, <8 x i16>* %899, align 16
  %901 = shufflevector <8 x i16> %898, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %902 = zext <4 x i16> %901 to <4 x i32>
  %903 = shufflevector <8 x i16> %900, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %904 = zext <4 x i16> %903 to <4 x i32>
  %905 = sub nsw <4 x i32> %902, %904
  %906 = sub nsw <4 x i32> zeroinitializer, %905
  %907 = icmp slt <4 x i32> %905, zeroinitializer
  %908 = select <4 x i1> %907, <4 x i32> %906, <4 x i32> %905
  %909 = add nuw nsw <4 x i32> %908, <i32 32, i32 32, i32 32, i32 32>
  %910 = lshr <4 x i32> %909, <i32 6, i32 6, i32 6, i32 6>
  %911 = shufflevector <8 x i16> %898, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %912 = shufflevector <8 x i16> %900, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %913 = bitcast <8 x i16> %911 to <4 x i32>
  %914 = bitcast <8 x i16> %912 to <4 x i32>
  %915 = sub <4 x i32> %913, %914
  %916 = sub <4 x i32> zeroinitializer, %915
  %917 = icmp slt <4 x i32> %915, zeroinitializer
  %918 = select <4 x i1> %917, <4 x i32> %916, <4 x i32> %915
  %919 = add nuw <4 x i32> %918, <i32 32, i32 32, i32 32, i32 32>
  %920 = lshr <4 x i32> %919, <i32 6, i32 6, i32 6, i32 6>
  %921 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %910, <4 x i32> %920) #5
  %922 = lshr <8 x i16> %921, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %923 = getelementptr inbounds i16, i16* %9, i64 232
  %924 = bitcast i16* %923 to <8 x i16>*
  %925 = load <8 x i16>, <8 x i16>* %924, align 16
  %926 = getelementptr inbounds i16, i16* %10, i64 232
  %927 = bitcast i16* %926 to <8 x i16>*
  %928 = load <8 x i16>, <8 x i16>* %927, align 16
  %929 = shufflevector <8 x i16> %925, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %930 = zext <4 x i16> %929 to <4 x i32>
  %931 = shufflevector <8 x i16> %928, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %932 = zext <4 x i16> %931 to <4 x i32>
  %933 = sub nsw <4 x i32> %930, %932
  %934 = sub nsw <4 x i32> zeroinitializer, %933
  %935 = icmp slt <4 x i32> %933, zeroinitializer
  %936 = select <4 x i1> %935, <4 x i32> %934, <4 x i32> %933
  %937 = add nuw nsw <4 x i32> %936, <i32 32, i32 32, i32 32, i32 32>
  %938 = lshr <4 x i32> %937, <i32 6, i32 6, i32 6, i32 6>
  %939 = shufflevector <8 x i16> %925, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %940 = shufflevector <8 x i16> %928, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %941 = bitcast <8 x i16> %939 to <4 x i32>
  %942 = bitcast <8 x i16> %940 to <4 x i32>
  %943 = sub <4 x i32> %941, %942
  %944 = sub <4 x i32> zeroinitializer, %943
  %945 = icmp slt <4 x i32> %943, zeroinitializer
  %946 = select <4 x i1> %945, <4 x i32> %944, <4 x i32> %943
  %947 = add nuw <4 x i32> %946, <i32 32, i32 32, i32 32, i32 32>
  %948 = lshr <4 x i32> %947, <i32 6, i32 6, i32 6, i32 6>
  %949 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %938, <4 x i32> %948) #5
  %950 = lshr <8 x i16> %949, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %951 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %922, <8 x i16> %950) #5
  %952 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %951, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %953 = icmp slt <16 x i8> %952, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %954 = select <16 x i1> %953, <16 x i8> %952, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %955 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %954
  %956 = bitcast i8* %896 to <16 x i8>*
  store <16 x i8> %955, <16 x i8>* %956, align 16
  %957 = getelementptr inbounds i16, i16* %9, i64 240
  %958 = getelementptr inbounds i16, i16* %10, i64 240
  %959 = getelementptr inbounds i8, i8* %767, i64 48
  %960 = bitcast i16* %957 to <8 x i16>*
  %961 = load <8 x i16>, <8 x i16>* %960, align 16
  %962 = bitcast i16* %958 to <8 x i16>*
  %963 = load <8 x i16>, <8 x i16>* %962, align 16
  %964 = shufflevector <8 x i16> %961, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %965 = zext <4 x i16> %964 to <4 x i32>
  %966 = shufflevector <8 x i16> %963, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %967 = zext <4 x i16> %966 to <4 x i32>
  %968 = sub nsw <4 x i32> %965, %967
  %969 = sub nsw <4 x i32> zeroinitializer, %968
  %970 = icmp slt <4 x i32> %968, zeroinitializer
  %971 = select <4 x i1> %970, <4 x i32> %969, <4 x i32> %968
  %972 = add nuw nsw <4 x i32> %971, <i32 32, i32 32, i32 32, i32 32>
  %973 = lshr <4 x i32> %972, <i32 6, i32 6, i32 6, i32 6>
  %974 = shufflevector <8 x i16> %961, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %975 = shufflevector <8 x i16> %963, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %976 = bitcast <8 x i16> %974 to <4 x i32>
  %977 = bitcast <8 x i16> %975 to <4 x i32>
  %978 = sub <4 x i32> %976, %977
  %979 = sub <4 x i32> zeroinitializer, %978
  %980 = icmp slt <4 x i32> %978, zeroinitializer
  %981 = select <4 x i1> %980, <4 x i32> %979, <4 x i32> %978
  %982 = add nuw <4 x i32> %981, <i32 32, i32 32, i32 32, i32 32>
  %983 = lshr <4 x i32> %982, <i32 6, i32 6, i32 6, i32 6>
  %984 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %973, <4 x i32> %983) #5
  %985 = lshr <8 x i16> %984, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %986 = getelementptr inbounds i16, i16* %9, i64 248
  %987 = bitcast i16* %986 to <8 x i16>*
  %988 = load <8 x i16>, <8 x i16>* %987, align 16
  %989 = getelementptr inbounds i16, i16* %10, i64 248
  %990 = bitcast i16* %989 to <8 x i16>*
  %991 = load <8 x i16>, <8 x i16>* %990, align 16
  %992 = shufflevector <8 x i16> %988, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %993 = zext <4 x i16> %992 to <4 x i32>
  %994 = shufflevector <8 x i16> %991, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %995 = zext <4 x i16> %994 to <4 x i32>
  %996 = sub nsw <4 x i32> %993, %995
  %997 = sub nsw <4 x i32> zeroinitializer, %996
  %998 = icmp slt <4 x i32> %996, zeroinitializer
  %999 = select <4 x i1> %998, <4 x i32> %997, <4 x i32> %996
  %1000 = add nuw nsw <4 x i32> %999, <i32 32, i32 32, i32 32, i32 32>
  %1001 = lshr <4 x i32> %1000, <i32 6, i32 6, i32 6, i32 6>
  %1002 = shufflevector <8 x i16> %988, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1003 = shufflevector <8 x i16> %991, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1004 = bitcast <8 x i16> %1002 to <4 x i32>
  %1005 = bitcast <8 x i16> %1003 to <4 x i32>
  %1006 = sub <4 x i32> %1004, %1005
  %1007 = sub <4 x i32> zeroinitializer, %1006
  %1008 = icmp slt <4 x i32> %1006, zeroinitializer
  %1009 = select <4 x i1> %1008, <4 x i32> %1007, <4 x i32> %1006
  %1010 = add nuw <4 x i32> %1009, <i32 32, i32 32, i32 32, i32 32>
  %1011 = lshr <4 x i32> %1010, <i32 6, i32 6, i32 6, i32 6>
  %1012 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1001, <4 x i32> %1011) #5
  %1013 = lshr <8 x i16> %1012, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1014 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %985, <8 x i16> %1013) #5
  %1015 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1014, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1016 = icmp slt <16 x i8> %1015, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1017 = select <16 x i1> %1016, <16 x i8> %1015, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1018 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1017
  %1019 = bitcast i8* %959 to <16 x i8>*
  store <16 x i8> %1018, <16 x i8>* %1019, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_127WeightMask64x128_10bpp_SSE4ILb0EEEvPKvS5_Phl(i8* readonly, i8* readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %755, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %753, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %754, %7 ]
  %11 = phi i32 [ 42, %4 ], [ %756, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = shufflevector <8 x i16> %13, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %17 = zext <4 x i16> %16 to <4 x i32>
  %18 = shufflevector <8 x i16> %15, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %19 = zext <4 x i16> %18 to <4 x i32>
  %20 = sub nsw <4 x i32> %17, %19
  %21 = sub nsw <4 x i32> zeroinitializer, %20
  %22 = icmp slt <4 x i32> %20, zeroinitializer
  %23 = select <4 x i1> %22, <4 x i32> %21, <4 x i32> %20
  %24 = add nuw nsw <4 x i32> %23, <i32 32, i32 32, i32 32, i32 32>
  %25 = lshr <4 x i32> %24, <i32 6, i32 6, i32 6, i32 6>
  %26 = shufflevector <8 x i16> %13, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %27 = shufflevector <8 x i16> %15, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %28 = bitcast <8 x i16> %26 to <4 x i32>
  %29 = bitcast <8 x i16> %27 to <4 x i32>
  %30 = sub <4 x i32> %28, %29
  %31 = sub <4 x i32> zeroinitializer, %30
  %32 = icmp slt <4 x i32> %30, zeroinitializer
  %33 = select <4 x i1> %32, <4 x i32> %31, <4 x i32> %30
  %34 = add nuw <4 x i32> %33, <i32 32, i32 32, i32 32, i32 32>
  %35 = lshr <4 x i32> %34, <i32 6, i32 6, i32 6, i32 6>
  %36 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %25, <4 x i32> %35) #5
  %37 = lshr <8 x i16> %36, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %38 = getelementptr inbounds i16, i16* %9, i64 8
  %39 = bitcast i16* %38 to <8 x i16>*
  %40 = load <8 x i16>, <8 x i16>* %39, align 16
  %41 = getelementptr inbounds i16, i16* %10, i64 8
  %42 = bitcast i16* %41 to <8 x i16>*
  %43 = load <8 x i16>, <8 x i16>* %42, align 16
  %44 = shufflevector <8 x i16> %40, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %45 = zext <4 x i16> %44 to <4 x i32>
  %46 = shufflevector <8 x i16> %43, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %47 = zext <4 x i16> %46 to <4 x i32>
  %48 = sub nsw <4 x i32> %45, %47
  %49 = sub nsw <4 x i32> zeroinitializer, %48
  %50 = icmp slt <4 x i32> %48, zeroinitializer
  %51 = select <4 x i1> %50, <4 x i32> %49, <4 x i32> %48
  %52 = add nuw nsw <4 x i32> %51, <i32 32, i32 32, i32 32, i32 32>
  %53 = lshr <4 x i32> %52, <i32 6, i32 6, i32 6, i32 6>
  %54 = shufflevector <8 x i16> %40, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %55 = shufflevector <8 x i16> %43, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %56 = bitcast <8 x i16> %54 to <4 x i32>
  %57 = bitcast <8 x i16> %55 to <4 x i32>
  %58 = sub <4 x i32> %56, %57
  %59 = sub <4 x i32> zeroinitializer, %58
  %60 = icmp slt <4 x i32> %58, zeroinitializer
  %61 = select <4 x i1> %60, <4 x i32> %59, <4 x i32> %58
  %62 = add nuw <4 x i32> %61, <i32 32, i32 32, i32 32, i32 32>
  %63 = lshr <4 x i32> %62, <i32 6, i32 6, i32 6, i32 6>
  %64 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %53, <4 x i32> %63) #5
  %65 = lshr <8 x i16> %64, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %66 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %37, <8 x i16> %65) #5
  %67 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %66, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %68 = icmp slt <16 x i8> %67, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %69 = select <16 x i1> %68, <16 x i8> %67, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %70 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %69, <16 x i8>* %70, align 16
  %71 = getelementptr inbounds i16, i16* %9, i64 16
  %72 = getelementptr inbounds i16, i16* %10, i64 16
  %73 = getelementptr inbounds i8, i8* %8, i64 16
  %74 = bitcast i16* %71 to <8 x i16>*
  %75 = load <8 x i16>, <8 x i16>* %74, align 16
  %76 = bitcast i16* %72 to <8 x i16>*
  %77 = load <8 x i16>, <8 x i16>* %76, align 16
  %78 = shufflevector <8 x i16> %75, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %79 = zext <4 x i16> %78 to <4 x i32>
  %80 = shufflevector <8 x i16> %77, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %81 = zext <4 x i16> %80 to <4 x i32>
  %82 = sub nsw <4 x i32> %79, %81
  %83 = sub nsw <4 x i32> zeroinitializer, %82
  %84 = icmp slt <4 x i32> %82, zeroinitializer
  %85 = select <4 x i1> %84, <4 x i32> %83, <4 x i32> %82
  %86 = add nuw nsw <4 x i32> %85, <i32 32, i32 32, i32 32, i32 32>
  %87 = lshr <4 x i32> %86, <i32 6, i32 6, i32 6, i32 6>
  %88 = shufflevector <8 x i16> %75, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %89 = shufflevector <8 x i16> %77, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %90 = bitcast <8 x i16> %88 to <4 x i32>
  %91 = bitcast <8 x i16> %89 to <4 x i32>
  %92 = sub <4 x i32> %90, %91
  %93 = sub <4 x i32> zeroinitializer, %92
  %94 = icmp slt <4 x i32> %92, zeroinitializer
  %95 = select <4 x i1> %94, <4 x i32> %93, <4 x i32> %92
  %96 = add nuw <4 x i32> %95, <i32 32, i32 32, i32 32, i32 32>
  %97 = lshr <4 x i32> %96, <i32 6, i32 6, i32 6, i32 6>
  %98 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %87, <4 x i32> %97) #5
  %99 = lshr <8 x i16> %98, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %100 = getelementptr inbounds i16, i16* %9, i64 24
  %101 = bitcast i16* %100 to <8 x i16>*
  %102 = load <8 x i16>, <8 x i16>* %101, align 16
  %103 = getelementptr inbounds i16, i16* %10, i64 24
  %104 = bitcast i16* %103 to <8 x i16>*
  %105 = load <8 x i16>, <8 x i16>* %104, align 16
  %106 = shufflevector <8 x i16> %102, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %107 = zext <4 x i16> %106 to <4 x i32>
  %108 = shufflevector <8 x i16> %105, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %109 = zext <4 x i16> %108 to <4 x i32>
  %110 = sub nsw <4 x i32> %107, %109
  %111 = sub nsw <4 x i32> zeroinitializer, %110
  %112 = icmp slt <4 x i32> %110, zeroinitializer
  %113 = select <4 x i1> %112, <4 x i32> %111, <4 x i32> %110
  %114 = add nuw nsw <4 x i32> %113, <i32 32, i32 32, i32 32, i32 32>
  %115 = lshr <4 x i32> %114, <i32 6, i32 6, i32 6, i32 6>
  %116 = shufflevector <8 x i16> %102, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %117 = shufflevector <8 x i16> %105, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %118 = bitcast <8 x i16> %116 to <4 x i32>
  %119 = bitcast <8 x i16> %117 to <4 x i32>
  %120 = sub <4 x i32> %118, %119
  %121 = sub <4 x i32> zeroinitializer, %120
  %122 = icmp slt <4 x i32> %120, zeroinitializer
  %123 = select <4 x i1> %122, <4 x i32> %121, <4 x i32> %120
  %124 = add nuw <4 x i32> %123, <i32 32, i32 32, i32 32, i32 32>
  %125 = lshr <4 x i32> %124, <i32 6, i32 6, i32 6, i32 6>
  %126 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %115, <4 x i32> %125) #5
  %127 = lshr <8 x i16> %126, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %128 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %99, <8 x i16> %127) #5
  %129 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %128, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %130 = icmp slt <16 x i8> %129, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %131 = select <16 x i1> %130, <16 x i8> %129, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %132 = bitcast i8* %73 to <16 x i8>*
  store <16 x i8> %131, <16 x i8>* %132, align 16
  %133 = getelementptr inbounds i16, i16* %9, i64 32
  %134 = getelementptr inbounds i16, i16* %10, i64 32
  %135 = getelementptr inbounds i8, i8* %8, i64 32
  %136 = bitcast i16* %133 to <8 x i16>*
  %137 = load <8 x i16>, <8 x i16>* %136, align 16
  %138 = bitcast i16* %134 to <8 x i16>*
  %139 = load <8 x i16>, <8 x i16>* %138, align 16
  %140 = shufflevector <8 x i16> %137, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %141 = zext <4 x i16> %140 to <4 x i32>
  %142 = shufflevector <8 x i16> %139, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %143 = zext <4 x i16> %142 to <4 x i32>
  %144 = sub nsw <4 x i32> %141, %143
  %145 = sub nsw <4 x i32> zeroinitializer, %144
  %146 = icmp slt <4 x i32> %144, zeroinitializer
  %147 = select <4 x i1> %146, <4 x i32> %145, <4 x i32> %144
  %148 = add nuw nsw <4 x i32> %147, <i32 32, i32 32, i32 32, i32 32>
  %149 = lshr <4 x i32> %148, <i32 6, i32 6, i32 6, i32 6>
  %150 = shufflevector <8 x i16> %137, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %151 = shufflevector <8 x i16> %139, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %152 = bitcast <8 x i16> %150 to <4 x i32>
  %153 = bitcast <8 x i16> %151 to <4 x i32>
  %154 = sub <4 x i32> %152, %153
  %155 = sub <4 x i32> zeroinitializer, %154
  %156 = icmp slt <4 x i32> %154, zeroinitializer
  %157 = select <4 x i1> %156, <4 x i32> %155, <4 x i32> %154
  %158 = add nuw <4 x i32> %157, <i32 32, i32 32, i32 32, i32 32>
  %159 = lshr <4 x i32> %158, <i32 6, i32 6, i32 6, i32 6>
  %160 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %149, <4 x i32> %159) #5
  %161 = lshr <8 x i16> %160, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %162 = getelementptr inbounds i16, i16* %9, i64 40
  %163 = bitcast i16* %162 to <8 x i16>*
  %164 = load <8 x i16>, <8 x i16>* %163, align 16
  %165 = getelementptr inbounds i16, i16* %10, i64 40
  %166 = bitcast i16* %165 to <8 x i16>*
  %167 = load <8 x i16>, <8 x i16>* %166, align 16
  %168 = shufflevector <8 x i16> %164, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %169 = zext <4 x i16> %168 to <4 x i32>
  %170 = shufflevector <8 x i16> %167, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %171 = zext <4 x i16> %170 to <4 x i32>
  %172 = sub nsw <4 x i32> %169, %171
  %173 = sub nsw <4 x i32> zeroinitializer, %172
  %174 = icmp slt <4 x i32> %172, zeroinitializer
  %175 = select <4 x i1> %174, <4 x i32> %173, <4 x i32> %172
  %176 = add nuw nsw <4 x i32> %175, <i32 32, i32 32, i32 32, i32 32>
  %177 = lshr <4 x i32> %176, <i32 6, i32 6, i32 6, i32 6>
  %178 = shufflevector <8 x i16> %164, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %179 = shufflevector <8 x i16> %167, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %180 = bitcast <8 x i16> %178 to <4 x i32>
  %181 = bitcast <8 x i16> %179 to <4 x i32>
  %182 = sub <4 x i32> %180, %181
  %183 = sub <4 x i32> zeroinitializer, %182
  %184 = icmp slt <4 x i32> %182, zeroinitializer
  %185 = select <4 x i1> %184, <4 x i32> %183, <4 x i32> %182
  %186 = add nuw <4 x i32> %185, <i32 32, i32 32, i32 32, i32 32>
  %187 = lshr <4 x i32> %186, <i32 6, i32 6, i32 6, i32 6>
  %188 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %177, <4 x i32> %187) #5
  %189 = lshr <8 x i16> %188, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %190 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %161, <8 x i16> %189) #5
  %191 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %190, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %192 = icmp slt <16 x i8> %191, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %193 = select <16 x i1> %192, <16 x i8> %191, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %194 = bitcast i8* %135 to <16 x i8>*
  store <16 x i8> %193, <16 x i8>* %194, align 16
  %195 = getelementptr inbounds i16, i16* %9, i64 48
  %196 = getelementptr inbounds i16, i16* %10, i64 48
  %197 = getelementptr inbounds i8, i8* %8, i64 48
  %198 = bitcast i16* %195 to <8 x i16>*
  %199 = load <8 x i16>, <8 x i16>* %198, align 16
  %200 = bitcast i16* %196 to <8 x i16>*
  %201 = load <8 x i16>, <8 x i16>* %200, align 16
  %202 = shufflevector <8 x i16> %199, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %203 = zext <4 x i16> %202 to <4 x i32>
  %204 = shufflevector <8 x i16> %201, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %205 = zext <4 x i16> %204 to <4 x i32>
  %206 = sub nsw <4 x i32> %203, %205
  %207 = sub nsw <4 x i32> zeroinitializer, %206
  %208 = icmp slt <4 x i32> %206, zeroinitializer
  %209 = select <4 x i1> %208, <4 x i32> %207, <4 x i32> %206
  %210 = add nuw nsw <4 x i32> %209, <i32 32, i32 32, i32 32, i32 32>
  %211 = lshr <4 x i32> %210, <i32 6, i32 6, i32 6, i32 6>
  %212 = shufflevector <8 x i16> %199, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %213 = shufflevector <8 x i16> %201, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %214 = bitcast <8 x i16> %212 to <4 x i32>
  %215 = bitcast <8 x i16> %213 to <4 x i32>
  %216 = sub <4 x i32> %214, %215
  %217 = sub <4 x i32> zeroinitializer, %216
  %218 = icmp slt <4 x i32> %216, zeroinitializer
  %219 = select <4 x i1> %218, <4 x i32> %217, <4 x i32> %216
  %220 = add nuw <4 x i32> %219, <i32 32, i32 32, i32 32, i32 32>
  %221 = lshr <4 x i32> %220, <i32 6, i32 6, i32 6, i32 6>
  %222 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %211, <4 x i32> %221) #5
  %223 = lshr <8 x i16> %222, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %224 = getelementptr inbounds i16, i16* %9, i64 56
  %225 = bitcast i16* %224 to <8 x i16>*
  %226 = load <8 x i16>, <8 x i16>* %225, align 16
  %227 = getelementptr inbounds i16, i16* %10, i64 56
  %228 = bitcast i16* %227 to <8 x i16>*
  %229 = load <8 x i16>, <8 x i16>* %228, align 16
  %230 = shufflevector <8 x i16> %226, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %231 = zext <4 x i16> %230 to <4 x i32>
  %232 = shufflevector <8 x i16> %229, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %233 = zext <4 x i16> %232 to <4 x i32>
  %234 = sub nsw <4 x i32> %231, %233
  %235 = sub nsw <4 x i32> zeroinitializer, %234
  %236 = icmp slt <4 x i32> %234, zeroinitializer
  %237 = select <4 x i1> %236, <4 x i32> %235, <4 x i32> %234
  %238 = add nuw nsw <4 x i32> %237, <i32 32, i32 32, i32 32, i32 32>
  %239 = lshr <4 x i32> %238, <i32 6, i32 6, i32 6, i32 6>
  %240 = shufflevector <8 x i16> %226, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %241 = shufflevector <8 x i16> %229, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %242 = bitcast <8 x i16> %240 to <4 x i32>
  %243 = bitcast <8 x i16> %241 to <4 x i32>
  %244 = sub <4 x i32> %242, %243
  %245 = sub <4 x i32> zeroinitializer, %244
  %246 = icmp slt <4 x i32> %244, zeroinitializer
  %247 = select <4 x i1> %246, <4 x i32> %245, <4 x i32> %244
  %248 = add nuw <4 x i32> %247, <i32 32, i32 32, i32 32, i32 32>
  %249 = lshr <4 x i32> %248, <i32 6, i32 6, i32 6, i32 6>
  %250 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %239, <4 x i32> %249) #5
  %251 = lshr <8 x i16> %250, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %252 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %223, <8 x i16> %251) #5
  %253 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %252, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %254 = icmp slt <16 x i8> %253, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %255 = select <16 x i1> %254, <16 x i8> %253, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %256 = bitcast i8* %197 to <16 x i8>*
  store <16 x i8> %255, <16 x i8>* %256, align 16
  %257 = getelementptr inbounds i16, i16* %9, i64 64
  %258 = getelementptr inbounds i16, i16* %10, i64 64
  %259 = getelementptr inbounds i8, i8* %8, i64 %3
  %260 = bitcast i16* %257 to <8 x i16>*
  %261 = load <8 x i16>, <8 x i16>* %260, align 16
  %262 = bitcast i16* %258 to <8 x i16>*
  %263 = load <8 x i16>, <8 x i16>* %262, align 16
  %264 = shufflevector <8 x i16> %261, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %265 = zext <4 x i16> %264 to <4 x i32>
  %266 = shufflevector <8 x i16> %263, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %267 = zext <4 x i16> %266 to <4 x i32>
  %268 = sub nsw <4 x i32> %265, %267
  %269 = sub nsw <4 x i32> zeroinitializer, %268
  %270 = icmp slt <4 x i32> %268, zeroinitializer
  %271 = select <4 x i1> %270, <4 x i32> %269, <4 x i32> %268
  %272 = add nuw nsw <4 x i32> %271, <i32 32, i32 32, i32 32, i32 32>
  %273 = lshr <4 x i32> %272, <i32 6, i32 6, i32 6, i32 6>
  %274 = shufflevector <8 x i16> %261, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %275 = shufflevector <8 x i16> %263, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %276 = bitcast <8 x i16> %274 to <4 x i32>
  %277 = bitcast <8 x i16> %275 to <4 x i32>
  %278 = sub <4 x i32> %276, %277
  %279 = sub <4 x i32> zeroinitializer, %278
  %280 = icmp slt <4 x i32> %278, zeroinitializer
  %281 = select <4 x i1> %280, <4 x i32> %279, <4 x i32> %278
  %282 = add nuw <4 x i32> %281, <i32 32, i32 32, i32 32, i32 32>
  %283 = lshr <4 x i32> %282, <i32 6, i32 6, i32 6, i32 6>
  %284 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %273, <4 x i32> %283) #5
  %285 = lshr <8 x i16> %284, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %286 = getelementptr inbounds i16, i16* %9, i64 72
  %287 = bitcast i16* %286 to <8 x i16>*
  %288 = load <8 x i16>, <8 x i16>* %287, align 16
  %289 = getelementptr inbounds i16, i16* %10, i64 72
  %290 = bitcast i16* %289 to <8 x i16>*
  %291 = load <8 x i16>, <8 x i16>* %290, align 16
  %292 = shufflevector <8 x i16> %288, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %293 = zext <4 x i16> %292 to <4 x i32>
  %294 = shufflevector <8 x i16> %291, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %295 = zext <4 x i16> %294 to <4 x i32>
  %296 = sub nsw <4 x i32> %293, %295
  %297 = sub nsw <4 x i32> zeroinitializer, %296
  %298 = icmp slt <4 x i32> %296, zeroinitializer
  %299 = select <4 x i1> %298, <4 x i32> %297, <4 x i32> %296
  %300 = add nuw nsw <4 x i32> %299, <i32 32, i32 32, i32 32, i32 32>
  %301 = lshr <4 x i32> %300, <i32 6, i32 6, i32 6, i32 6>
  %302 = shufflevector <8 x i16> %288, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %303 = shufflevector <8 x i16> %291, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %304 = bitcast <8 x i16> %302 to <4 x i32>
  %305 = bitcast <8 x i16> %303 to <4 x i32>
  %306 = sub <4 x i32> %304, %305
  %307 = sub <4 x i32> zeroinitializer, %306
  %308 = icmp slt <4 x i32> %306, zeroinitializer
  %309 = select <4 x i1> %308, <4 x i32> %307, <4 x i32> %306
  %310 = add nuw <4 x i32> %309, <i32 32, i32 32, i32 32, i32 32>
  %311 = lshr <4 x i32> %310, <i32 6, i32 6, i32 6, i32 6>
  %312 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %301, <4 x i32> %311) #5
  %313 = lshr <8 x i16> %312, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %314 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %285, <8 x i16> %313) #5
  %315 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %314, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %316 = icmp slt <16 x i8> %315, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %317 = select <16 x i1> %316, <16 x i8> %315, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %318 = bitcast i8* %259 to <16 x i8>*
  store <16 x i8> %317, <16 x i8>* %318, align 16
  %319 = getelementptr inbounds i16, i16* %9, i64 80
  %320 = getelementptr inbounds i16, i16* %10, i64 80
  %321 = getelementptr inbounds i8, i8* %259, i64 16
  %322 = bitcast i16* %319 to <8 x i16>*
  %323 = load <8 x i16>, <8 x i16>* %322, align 16
  %324 = bitcast i16* %320 to <8 x i16>*
  %325 = load <8 x i16>, <8 x i16>* %324, align 16
  %326 = shufflevector <8 x i16> %323, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %327 = zext <4 x i16> %326 to <4 x i32>
  %328 = shufflevector <8 x i16> %325, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %329 = zext <4 x i16> %328 to <4 x i32>
  %330 = sub nsw <4 x i32> %327, %329
  %331 = sub nsw <4 x i32> zeroinitializer, %330
  %332 = icmp slt <4 x i32> %330, zeroinitializer
  %333 = select <4 x i1> %332, <4 x i32> %331, <4 x i32> %330
  %334 = add nuw nsw <4 x i32> %333, <i32 32, i32 32, i32 32, i32 32>
  %335 = lshr <4 x i32> %334, <i32 6, i32 6, i32 6, i32 6>
  %336 = shufflevector <8 x i16> %323, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %337 = shufflevector <8 x i16> %325, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %338 = bitcast <8 x i16> %336 to <4 x i32>
  %339 = bitcast <8 x i16> %337 to <4 x i32>
  %340 = sub <4 x i32> %338, %339
  %341 = sub <4 x i32> zeroinitializer, %340
  %342 = icmp slt <4 x i32> %340, zeroinitializer
  %343 = select <4 x i1> %342, <4 x i32> %341, <4 x i32> %340
  %344 = add nuw <4 x i32> %343, <i32 32, i32 32, i32 32, i32 32>
  %345 = lshr <4 x i32> %344, <i32 6, i32 6, i32 6, i32 6>
  %346 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %335, <4 x i32> %345) #5
  %347 = lshr <8 x i16> %346, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %348 = getelementptr inbounds i16, i16* %9, i64 88
  %349 = bitcast i16* %348 to <8 x i16>*
  %350 = load <8 x i16>, <8 x i16>* %349, align 16
  %351 = getelementptr inbounds i16, i16* %10, i64 88
  %352 = bitcast i16* %351 to <8 x i16>*
  %353 = load <8 x i16>, <8 x i16>* %352, align 16
  %354 = shufflevector <8 x i16> %350, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %355 = zext <4 x i16> %354 to <4 x i32>
  %356 = shufflevector <8 x i16> %353, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %357 = zext <4 x i16> %356 to <4 x i32>
  %358 = sub nsw <4 x i32> %355, %357
  %359 = sub nsw <4 x i32> zeroinitializer, %358
  %360 = icmp slt <4 x i32> %358, zeroinitializer
  %361 = select <4 x i1> %360, <4 x i32> %359, <4 x i32> %358
  %362 = add nuw nsw <4 x i32> %361, <i32 32, i32 32, i32 32, i32 32>
  %363 = lshr <4 x i32> %362, <i32 6, i32 6, i32 6, i32 6>
  %364 = shufflevector <8 x i16> %350, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %365 = shufflevector <8 x i16> %353, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %366 = bitcast <8 x i16> %364 to <4 x i32>
  %367 = bitcast <8 x i16> %365 to <4 x i32>
  %368 = sub <4 x i32> %366, %367
  %369 = sub <4 x i32> zeroinitializer, %368
  %370 = icmp slt <4 x i32> %368, zeroinitializer
  %371 = select <4 x i1> %370, <4 x i32> %369, <4 x i32> %368
  %372 = add nuw <4 x i32> %371, <i32 32, i32 32, i32 32, i32 32>
  %373 = lshr <4 x i32> %372, <i32 6, i32 6, i32 6, i32 6>
  %374 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %363, <4 x i32> %373) #5
  %375 = lshr <8 x i16> %374, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %376 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %347, <8 x i16> %375) #5
  %377 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %376, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %378 = icmp slt <16 x i8> %377, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %379 = select <16 x i1> %378, <16 x i8> %377, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %380 = bitcast i8* %321 to <16 x i8>*
  store <16 x i8> %379, <16 x i8>* %380, align 16
  %381 = getelementptr inbounds i16, i16* %9, i64 96
  %382 = getelementptr inbounds i16, i16* %10, i64 96
  %383 = getelementptr inbounds i8, i8* %259, i64 32
  %384 = bitcast i16* %381 to <8 x i16>*
  %385 = load <8 x i16>, <8 x i16>* %384, align 16
  %386 = bitcast i16* %382 to <8 x i16>*
  %387 = load <8 x i16>, <8 x i16>* %386, align 16
  %388 = shufflevector <8 x i16> %385, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %389 = zext <4 x i16> %388 to <4 x i32>
  %390 = shufflevector <8 x i16> %387, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %391 = zext <4 x i16> %390 to <4 x i32>
  %392 = sub nsw <4 x i32> %389, %391
  %393 = sub nsw <4 x i32> zeroinitializer, %392
  %394 = icmp slt <4 x i32> %392, zeroinitializer
  %395 = select <4 x i1> %394, <4 x i32> %393, <4 x i32> %392
  %396 = add nuw nsw <4 x i32> %395, <i32 32, i32 32, i32 32, i32 32>
  %397 = lshr <4 x i32> %396, <i32 6, i32 6, i32 6, i32 6>
  %398 = shufflevector <8 x i16> %385, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %399 = shufflevector <8 x i16> %387, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %400 = bitcast <8 x i16> %398 to <4 x i32>
  %401 = bitcast <8 x i16> %399 to <4 x i32>
  %402 = sub <4 x i32> %400, %401
  %403 = sub <4 x i32> zeroinitializer, %402
  %404 = icmp slt <4 x i32> %402, zeroinitializer
  %405 = select <4 x i1> %404, <4 x i32> %403, <4 x i32> %402
  %406 = add nuw <4 x i32> %405, <i32 32, i32 32, i32 32, i32 32>
  %407 = lshr <4 x i32> %406, <i32 6, i32 6, i32 6, i32 6>
  %408 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %397, <4 x i32> %407) #5
  %409 = lshr <8 x i16> %408, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %410 = getelementptr inbounds i16, i16* %9, i64 104
  %411 = bitcast i16* %410 to <8 x i16>*
  %412 = load <8 x i16>, <8 x i16>* %411, align 16
  %413 = getelementptr inbounds i16, i16* %10, i64 104
  %414 = bitcast i16* %413 to <8 x i16>*
  %415 = load <8 x i16>, <8 x i16>* %414, align 16
  %416 = shufflevector <8 x i16> %412, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %417 = zext <4 x i16> %416 to <4 x i32>
  %418 = shufflevector <8 x i16> %415, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %419 = zext <4 x i16> %418 to <4 x i32>
  %420 = sub nsw <4 x i32> %417, %419
  %421 = sub nsw <4 x i32> zeroinitializer, %420
  %422 = icmp slt <4 x i32> %420, zeroinitializer
  %423 = select <4 x i1> %422, <4 x i32> %421, <4 x i32> %420
  %424 = add nuw nsw <4 x i32> %423, <i32 32, i32 32, i32 32, i32 32>
  %425 = lshr <4 x i32> %424, <i32 6, i32 6, i32 6, i32 6>
  %426 = shufflevector <8 x i16> %412, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %427 = shufflevector <8 x i16> %415, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %428 = bitcast <8 x i16> %426 to <4 x i32>
  %429 = bitcast <8 x i16> %427 to <4 x i32>
  %430 = sub <4 x i32> %428, %429
  %431 = sub <4 x i32> zeroinitializer, %430
  %432 = icmp slt <4 x i32> %430, zeroinitializer
  %433 = select <4 x i1> %432, <4 x i32> %431, <4 x i32> %430
  %434 = add nuw <4 x i32> %433, <i32 32, i32 32, i32 32, i32 32>
  %435 = lshr <4 x i32> %434, <i32 6, i32 6, i32 6, i32 6>
  %436 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %425, <4 x i32> %435) #5
  %437 = lshr <8 x i16> %436, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %438 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %409, <8 x i16> %437) #5
  %439 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %438, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %440 = icmp slt <16 x i8> %439, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %441 = select <16 x i1> %440, <16 x i8> %439, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %442 = bitcast i8* %383 to <16 x i8>*
  store <16 x i8> %441, <16 x i8>* %442, align 16
  %443 = getelementptr inbounds i16, i16* %9, i64 112
  %444 = getelementptr inbounds i16, i16* %10, i64 112
  %445 = getelementptr inbounds i8, i8* %259, i64 48
  %446 = bitcast i16* %443 to <8 x i16>*
  %447 = load <8 x i16>, <8 x i16>* %446, align 16
  %448 = bitcast i16* %444 to <8 x i16>*
  %449 = load <8 x i16>, <8 x i16>* %448, align 16
  %450 = shufflevector <8 x i16> %447, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %451 = zext <4 x i16> %450 to <4 x i32>
  %452 = shufflevector <8 x i16> %449, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %453 = zext <4 x i16> %452 to <4 x i32>
  %454 = sub nsw <4 x i32> %451, %453
  %455 = sub nsw <4 x i32> zeroinitializer, %454
  %456 = icmp slt <4 x i32> %454, zeroinitializer
  %457 = select <4 x i1> %456, <4 x i32> %455, <4 x i32> %454
  %458 = add nuw nsw <4 x i32> %457, <i32 32, i32 32, i32 32, i32 32>
  %459 = lshr <4 x i32> %458, <i32 6, i32 6, i32 6, i32 6>
  %460 = shufflevector <8 x i16> %447, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %461 = shufflevector <8 x i16> %449, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %462 = bitcast <8 x i16> %460 to <4 x i32>
  %463 = bitcast <8 x i16> %461 to <4 x i32>
  %464 = sub <4 x i32> %462, %463
  %465 = sub <4 x i32> zeroinitializer, %464
  %466 = icmp slt <4 x i32> %464, zeroinitializer
  %467 = select <4 x i1> %466, <4 x i32> %465, <4 x i32> %464
  %468 = add nuw <4 x i32> %467, <i32 32, i32 32, i32 32, i32 32>
  %469 = lshr <4 x i32> %468, <i32 6, i32 6, i32 6, i32 6>
  %470 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %459, <4 x i32> %469) #5
  %471 = lshr <8 x i16> %470, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %472 = getelementptr inbounds i16, i16* %9, i64 120
  %473 = bitcast i16* %472 to <8 x i16>*
  %474 = load <8 x i16>, <8 x i16>* %473, align 16
  %475 = getelementptr inbounds i16, i16* %10, i64 120
  %476 = bitcast i16* %475 to <8 x i16>*
  %477 = load <8 x i16>, <8 x i16>* %476, align 16
  %478 = shufflevector <8 x i16> %474, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %479 = zext <4 x i16> %478 to <4 x i32>
  %480 = shufflevector <8 x i16> %477, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %481 = zext <4 x i16> %480 to <4 x i32>
  %482 = sub nsw <4 x i32> %479, %481
  %483 = sub nsw <4 x i32> zeroinitializer, %482
  %484 = icmp slt <4 x i32> %482, zeroinitializer
  %485 = select <4 x i1> %484, <4 x i32> %483, <4 x i32> %482
  %486 = add nuw nsw <4 x i32> %485, <i32 32, i32 32, i32 32, i32 32>
  %487 = lshr <4 x i32> %486, <i32 6, i32 6, i32 6, i32 6>
  %488 = shufflevector <8 x i16> %474, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %489 = shufflevector <8 x i16> %477, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %490 = bitcast <8 x i16> %488 to <4 x i32>
  %491 = bitcast <8 x i16> %489 to <4 x i32>
  %492 = sub <4 x i32> %490, %491
  %493 = sub <4 x i32> zeroinitializer, %492
  %494 = icmp slt <4 x i32> %492, zeroinitializer
  %495 = select <4 x i1> %494, <4 x i32> %493, <4 x i32> %492
  %496 = add nuw <4 x i32> %495, <i32 32, i32 32, i32 32, i32 32>
  %497 = lshr <4 x i32> %496, <i32 6, i32 6, i32 6, i32 6>
  %498 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %487, <4 x i32> %497) #5
  %499 = lshr <8 x i16> %498, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %500 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %471, <8 x i16> %499) #5
  %501 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %500, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %502 = icmp slt <16 x i8> %501, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %503 = select <16 x i1> %502, <16 x i8> %501, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %504 = bitcast i8* %445 to <16 x i8>*
  store <16 x i8> %503, <16 x i8>* %504, align 16
  %505 = getelementptr inbounds i16, i16* %9, i64 128
  %506 = getelementptr inbounds i16, i16* %10, i64 128
  %507 = getelementptr inbounds i8, i8* %259, i64 %3
  %508 = bitcast i16* %505 to <8 x i16>*
  %509 = load <8 x i16>, <8 x i16>* %508, align 16
  %510 = bitcast i16* %506 to <8 x i16>*
  %511 = load <8 x i16>, <8 x i16>* %510, align 16
  %512 = shufflevector <8 x i16> %509, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %513 = zext <4 x i16> %512 to <4 x i32>
  %514 = shufflevector <8 x i16> %511, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %515 = zext <4 x i16> %514 to <4 x i32>
  %516 = sub nsw <4 x i32> %513, %515
  %517 = sub nsw <4 x i32> zeroinitializer, %516
  %518 = icmp slt <4 x i32> %516, zeroinitializer
  %519 = select <4 x i1> %518, <4 x i32> %517, <4 x i32> %516
  %520 = add nuw nsw <4 x i32> %519, <i32 32, i32 32, i32 32, i32 32>
  %521 = lshr <4 x i32> %520, <i32 6, i32 6, i32 6, i32 6>
  %522 = shufflevector <8 x i16> %509, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %523 = shufflevector <8 x i16> %511, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %524 = bitcast <8 x i16> %522 to <4 x i32>
  %525 = bitcast <8 x i16> %523 to <4 x i32>
  %526 = sub <4 x i32> %524, %525
  %527 = sub <4 x i32> zeroinitializer, %526
  %528 = icmp slt <4 x i32> %526, zeroinitializer
  %529 = select <4 x i1> %528, <4 x i32> %527, <4 x i32> %526
  %530 = add nuw <4 x i32> %529, <i32 32, i32 32, i32 32, i32 32>
  %531 = lshr <4 x i32> %530, <i32 6, i32 6, i32 6, i32 6>
  %532 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %521, <4 x i32> %531) #5
  %533 = lshr <8 x i16> %532, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %534 = getelementptr inbounds i16, i16* %9, i64 136
  %535 = bitcast i16* %534 to <8 x i16>*
  %536 = load <8 x i16>, <8 x i16>* %535, align 16
  %537 = getelementptr inbounds i16, i16* %10, i64 136
  %538 = bitcast i16* %537 to <8 x i16>*
  %539 = load <8 x i16>, <8 x i16>* %538, align 16
  %540 = shufflevector <8 x i16> %536, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %541 = zext <4 x i16> %540 to <4 x i32>
  %542 = shufflevector <8 x i16> %539, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %543 = zext <4 x i16> %542 to <4 x i32>
  %544 = sub nsw <4 x i32> %541, %543
  %545 = sub nsw <4 x i32> zeroinitializer, %544
  %546 = icmp slt <4 x i32> %544, zeroinitializer
  %547 = select <4 x i1> %546, <4 x i32> %545, <4 x i32> %544
  %548 = add nuw nsw <4 x i32> %547, <i32 32, i32 32, i32 32, i32 32>
  %549 = lshr <4 x i32> %548, <i32 6, i32 6, i32 6, i32 6>
  %550 = shufflevector <8 x i16> %536, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %551 = shufflevector <8 x i16> %539, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %552 = bitcast <8 x i16> %550 to <4 x i32>
  %553 = bitcast <8 x i16> %551 to <4 x i32>
  %554 = sub <4 x i32> %552, %553
  %555 = sub <4 x i32> zeroinitializer, %554
  %556 = icmp slt <4 x i32> %554, zeroinitializer
  %557 = select <4 x i1> %556, <4 x i32> %555, <4 x i32> %554
  %558 = add nuw <4 x i32> %557, <i32 32, i32 32, i32 32, i32 32>
  %559 = lshr <4 x i32> %558, <i32 6, i32 6, i32 6, i32 6>
  %560 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %549, <4 x i32> %559) #5
  %561 = lshr <8 x i16> %560, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %562 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %533, <8 x i16> %561) #5
  %563 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %562, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %564 = icmp slt <16 x i8> %563, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %565 = select <16 x i1> %564, <16 x i8> %563, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %566 = bitcast i8* %507 to <16 x i8>*
  store <16 x i8> %565, <16 x i8>* %566, align 16
  %567 = getelementptr inbounds i16, i16* %9, i64 144
  %568 = getelementptr inbounds i16, i16* %10, i64 144
  %569 = getelementptr inbounds i8, i8* %507, i64 16
  %570 = bitcast i16* %567 to <8 x i16>*
  %571 = load <8 x i16>, <8 x i16>* %570, align 16
  %572 = bitcast i16* %568 to <8 x i16>*
  %573 = load <8 x i16>, <8 x i16>* %572, align 16
  %574 = shufflevector <8 x i16> %571, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %575 = zext <4 x i16> %574 to <4 x i32>
  %576 = shufflevector <8 x i16> %573, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %577 = zext <4 x i16> %576 to <4 x i32>
  %578 = sub nsw <4 x i32> %575, %577
  %579 = sub nsw <4 x i32> zeroinitializer, %578
  %580 = icmp slt <4 x i32> %578, zeroinitializer
  %581 = select <4 x i1> %580, <4 x i32> %579, <4 x i32> %578
  %582 = add nuw nsw <4 x i32> %581, <i32 32, i32 32, i32 32, i32 32>
  %583 = lshr <4 x i32> %582, <i32 6, i32 6, i32 6, i32 6>
  %584 = shufflevector <8 x i16> %571, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %585 = shufflevector <8 x i16> %573, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %586 = bitcast <8 x i16> %584 to <4 x i32>
  %587 = bitcast <8 x i16> %585 to <4 x i32>
  %588 = sub <4 x i32> %586, %587
  %589 = sub <4 x i32> zeroinitializer, %588
  %590 = icmp slt <4 x i32> %588, zeroinitializer
  %591 = select <4 x i1> %590, <4 x i32> %589, <4 x i32> %588
  %592 = add nuw <4 x i32> %591, <i32 32, i32 32, i32 32, i32 32>
  %593 = lshr <4 x i32> %592, <i32 6, i32 6, i32 6, i32 6>
  %594 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %583, <4 x i32> %593) #5
  %595 = lshr <8 x i16> %594, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %596 = getelementptr inbounds i16, i16* %9, i64 152
  %597 = bitcast i16* %596 to <8 x i16>*
  %598 = load <8 x i16>, <8 x i16>* %597, align 16
  %599 = getelementptr inbounds i16, i16* %10, i64 152
  %600 = bitcast i16* %599 to <8 x i16>*
  %601 = load <8 x i16>, <8 x i16>* %600, align 16
  %602 = shufflevector <8 x i16> %598, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %603 = zext <4 x i16> %602 to <4 x i32>
  %604 = shufflevector <8 x i16> %601, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %605 = zext <4 x i16> %604 to <4 x i32>
  %606 = sub nsw <4 x i32> %603, %605
  %607 = sub nsw <4 x i32> zeroinitializer, %606
  %608 = icmp slt <4 x i32> %606, zeroinitializer
  %609 = select <4 x i1> %608, <4 x i32> %607, <4 x i32> %606
  %610 = add nuw nsw <4 x i32> %609, <i32 32, i32 32, i32 32, i32 32>
  %611 = lshr <4 x i32> %610, <i32 6, i32 6, i32 6, i32 6>
  %612 = shufflevector <8 x i16> %598, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %613 = shufflevector <8 x i16> %601, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %614 = bitcast <8 x i16> %612 to <4 x i32>
  %615 = bitcast <8 x i16> %613 to <4 x i32>
  %616 = sub <4 x i32> %614, %615
  %617 = sub <4 x i32> zeroinitializer, %616
  %618 = icmp slt <4 x i32> %616, zeroinitializer
  %619 = select <4 x i1> %618, <4 x i32> %617, <4 x i32> %616
  %620 = add nuw <4 x i32> %619, <i32 32, i32 32, i32 32, i32 32>
  %621 = lshr <4 x i32> %620, <i32 6, i32 6, i32 6, i32 6>
  %622 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %611, <4 x i32> %621) #5
  %623 = lshr <8 x i16> %622, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %624 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %595, <8 x i16> %623) #5
  %625 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %624, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %626 = icmp slt <16 x i8> %625, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %627 = select <16 x i1> %626, <16 x i8> %625, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %628 = bitcast i8* %569 to <16 x i8>*
  store <16 x i8> %627, <16 x i8>* %628, align 16
  %629 = getelementptr inbounds i16, i16* %9, i64 160
  %630 = getelementptr inbounds i16, i16* %10, i64 160
  %631 = getelementptr inbounds i8, i8* %507, i64 32
  %632 = bitcast i16* %629 to <8 x i16>*
  %633 = load <8 x i16>, <8 x i16>* %632, align 16
  %634 = bitcast i16* %630 to <8 x i16>*
  %635 = load <8 x i16>, <8 x i16>* %634, align 16
  %636 = shufflevector <8 x i16> %633, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %637 = zext <4 x i16> %636 to <4 x i32>
  %638 = shufflevector <8 x i16> %635, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %639 = zext <4 x i16> %638 to <4 x i32>
  %640 = sub nsw <4 x i32> %637, %639
  %641 = sub nsw <4 x i32> zeroinitializer, %640
  %642 = icmp slt <4 x i32> %640, zeroinitializer
  %643 = select <4 x i1> %642, <4 x i32> %641, <4 x i32> %640
  %644 = add nuw nsw <4 x i32> %643, <i32 32, i32 32, i32 32, i32 32>
  %645 = lshr <4 x i32> %644, <i32 6, i32 6, i32 6, i32 6>
  %646 = shufflevector <8 x i16> %633, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %647 = shufflevector <8 x i16> %635, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %648 = bitcast <8 x i16> %646 to <4 x i32>
  %649 = bitcast <8 x i16> %647 to <4 x i32>
  %650 = sub <4 x i32> %648, %649
  %651 = sub <4 x i32> zeroinitializer, %650
  %652 = icmp slt <4 x i32> %650, zeroinitializer
  %653 = select <4 x i1> %652, <4 x i32> %651, <4 x i32> %650
  %654 = add nuw <4 x i32> %653, <i32 32, i32 32, i32 32, i32 32>
  %655 = lshr <4 x i32> %654, <i32 6, i32 6, i32 6, i32 6>
  %656 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %645, <4 x i32> %655) #5
  %657 = lshr <8 x i16> %656, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %658 = getelementptr inbounds i16, i16* %9, i64 168
  %659 = bitcast i16* %658 to <8 x i16>*
  %660 = load <8 x i16>, <8 x i16>* %659, align 16
  %661 = getelementptr inbounds i16, i16* %10, i64 168
  %662 = bitcast i16* %661 to <8 x i16>*
  %663 = load <8 x i16>, <8 x i16>* %662, align 16
  %664 = shufflevector <8 x i16> %660, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %665 = zext <4 x i16> %664 to <4 x i32>
  %666 = shufflevector <8 x i16> %663, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %667 = zext <4 x i16> %666 to <4 x i32>
  %668 = sub nsw <4 x i32> %665, %667
  %669 = sub nsw <4 x i32> zeroinitializer, %668
  %670 = icmp slt <4 x i32> %668, zeroinitializer
  %671 = select <4 x i1> %670, <4 x i32> %669, <4 x i32> %668
  %672 = add nuw nsw <4 x i32> %671, <i32 32, i32 32, i32 32, i32 32>
  %673 = lshr <4 x i32> %672, <i32 6, i32 6, i32 6, i32 6>
  %674 = shufflevector <8 x i16> %660, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %675 = shufflevector <8 x i16> %663, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %676 = bitcast <8 x i16> %674 to <4 x i32>
  %677 = bitcast <8 x i16> %675 to <4 x i32>
  %678 = sub <4 x i32> %676, %677
  %679 = sub <4 x i32> zeroinitializer, %678
  %680 = icmp slt <4 x i32> %678, zeroinitializer
  %681 = select <4 x i1> %680, <4 x i32> %679, <4 x i32> %678
  %682 = add nuw <4 x i32> %681, <i32 32, i32 32, i32 32, i32 32>
  %683 = lshr <4 x i32> %682, <i32 6, i32 6, i32 6, i32 6>
  %684 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %673, <4 x i32> %683) #5
  %685 = lshr <8 x i16> %684, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %686 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %657, <8 x i16> %685) #5
  %687 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %686, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %688 = icmp slt <16 x i8> %687, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %689 = select <16 x i1> %688, <16 x i8> %687, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %690 = bitcast i8* %631 to <16 x i8>*
  store <16 x i8> %689, <16 x i8>* %690, align 16
  %691 = getelementptr inbounds i16, i16* %9, i64 176
  %692 = getelementptr inbounds i16, i16* %10, i64 176
  %693 = getelementptr inbounds i8, i8* %507, i64 48
  %694 = bitcast i16* %691 to <8 x i16>*
  %695 = load <8 x i16>, <8 x i16>* %694, align 16
  %696 = bitcast i16* %692 to <8 x i16>*
  %697 = load <8 x i16>, <8 x i16>* %696, align 16
  %698 = shufflevector <8 x i16> %695, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %699 = zext <4 x i16> %698 to <4 x i32>
  %700 = shufflevector <8 x i16> %697, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %701 = zext <4 x i16> %700 to <4 x i32>
  %702 = sub nsw <4 x i32> %699, %701
  %703 = sub nsw <4 x i32> zeroinitializer, %702
  %704 = icmp slt <4 x i32> %702, zeroinitializer
  %705 = select <4 x i1> %704, <4 x i32> %703, <4 x i32> %702
  %706 = add nuw nsw <4 x i32> %705, <i32 32, i32 32, i32 32, i32 32>
  %707 = lshr <4 x i32> %706, <i32 6, i32 6, i32 6, i32 6>
  %708 = shufflevector <8 x i16> %695, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %709 = shufflevector <8 x i16> %697, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %710 = bitcast <8 x i16> %708 to <4 x i32>
  %711 = bitcast <8 x i16> %709 to <4 x i32>
  %712 = sub <4 x i32> %710, %711
  %713 = sub <4 x i32> zeroinitializer, %712
  %714 = icmp slt <4 x i32> %712, zeroinitializer
  %715 = select <4 x i1> %714, <4 x i32> %713, <4 x i32> %712
  %716 = add nuw <4 x i32> %715, <i32 32, i32 32, i32 32, i32 32>
  %717 = lshr <4 x i32> %716, <i32 6, i32 6, i32 6, i32 6>
  %718 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %707, <4 x i32> %717) #5
  %719 = lshr <8 x i16> %718, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %720 = getelementptr inbounds i16, i16* %9, i64 184
  %721 = bitcast i16* %720 to <8 x i16>*
  %722 = load <8 x i16>, <8 x i16>* %721, align 16
  %723 = getelementptr inbounds i16, i16* %10, i64 184
  %724 = bitcast i16* %723 to <8 x i16>*
  %725 = load <8 x i16>, <8 x i16>* %724, align 16
  %726 = shufflevector <8 x i16> %722, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %727 = zext <4 x i16> %726 to <4 x i32>
  %728 = shufflevector <8 x i16> %725, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %729 = zext <4 x i16> %728 to <4 x i32>
  %730 = sub nsw <4 x i32> %727, %729
  %731 = sub nsw <4 x i32> zeroinitializer, %730
  %732 = icmp slt <4 x i32> %730, zeroinitializer
  %733 = select <4 x i1> %732, <4 x i32> %731, <4 x i32> %730
  %734 = add nuw nsw <4 x i32> %733, <i32 32, i32 32, i32 32, i32 32>
  %735 = lshr <4 x i32> %734, <i32 6, i32 6, i32 6, i32 6>
  %736 = shufflevector <8 x i16> %722, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %737 = shufflevector <8 x i16> %725, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %738 = bitcast <8 x i16> %736 to <4 x i32>
  %739 = bitcast <8 x i16> %737 to <4 x i32>
  %740 = sub <4 x i32> %738, %739
  %741 = sub <4 x i32> zeroinitializer, %740
  %742 = icmp slt <4 x i32> %740, zeroinitializer
  %743 = select <4 x i1> %742, <4 x i32> %741, <4 x i32> %740
  %744 = add nuw <4 x i32> %743, <i32 32, i32 32, i32 32, i32 32>
  %745 = lshr <4 x i32> %744, <i32 6, i32 6, i32 6, i32 6>
  %746 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %735, <4 x i32> %745) #5
  %747 = lshr <8 x i16> %746, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %748 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %719, <8 x i16> %747) #5
  %749 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %748, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %750 = icmp slt <16 x i8> %749, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %751 = select <16 x i1> %750, <16 x i8> %749, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %752 = bitcast i8* %693 to <16 x i8>*
  store <16 x i8> %751, <16 x i8>* %752, align 16
  %753 = getelementptr inbounds i16, i16* %9, i64 192
  %754 = getelementptr inbounds i16, i16* %10, i64 192
  %755 = getelementptr inbounds i8, i8* %507, i64 %3
  %756 = add nsw i32 %11, -1
  %757 = icmp eq i32 %756, 0
  br i1 %757, label %758, label %7

758:                                              ; preds = %7
  %759 = bitcast i16* %753 to <8 x i16>*
  %760 = load <8 x i16>, <8 x i16>* %759, align 16
  %761 = bitcast i16* %754 to <8 x i16>*
  %762 = load <8 x i16>, <8 x i16>* %761, align 16
  %763 = shufflevector <8 x i16> %760, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %764 = zext <4 x i16> %763 to <4 x i32>
  %765 = shufflevector <8 x i16> %762, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %766 = zext <4 x i16> %765 to <4 x i32>
  %767 = sub nsw <4 x i32> %764, %766
  %768 = sub nsw <4 x i32> zeroinitializer, %767
  %769 = icmp slt <4 x i32> %767, zeroinitializer
  %770 = select <4 x i1> %769, <4 x i32> %768, <4 x i32> %767
  %771 = add nuw nsw <4 x i32> %770, <i32 32, i32 32, i32 32, i32 32>
  %772 = lshr <4 x i32> %771, <i32 6, i32 6, i32 6, i32 6>
  %773 = shufflevector <8 x i16> %760, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %774 = shufflevector <8 x i16> %762, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %775 = bitcast <8 x i16> %773 to <4 x i32>
  %776 = bitcast <8 x i16> %774 to <4 x i32>
  %777 = sub <4 x i32> %775, %776
  %778 = sub <4 x i32> zeroinitializer, %777
  %779 = icmp slt <4 x i32> %777, zeroinitializer
  %780 = select <4 x i1> %779, <4 x i32> %778, <4 x i32> %777
  %781 = add nuw <4 x i32> %780, <i32 32, i32 32, i32 32, i32 32>
  %782 = lshr <4 x i32> %781, <i32 6, i32 6, i32 6, i32 6>
  %783 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %772, <4 x i32> %782) #5
  %784 = lshr <8 x i16> %783, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %785 = getelementptr inbounds i16, i16* %9, i64 200
  %786 = bitcast i16* %785 to <8 x i16>*
  %787 = load <8 x i16>, <8 x i16>* %786, align 16
  %788 = getelementptr inbounds i16, i16* %10, i64 200
  %789 = bitcast i16* %788 to <8 x i16>*
  %790 = load <8 x i16>, <8 x i16>* %789, align 16
  %791 = shufflevector <8 x i16> %787, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %792 = zext <4 x i16> %791 to <4 x i32>
  %793 = shufflevector <8 x i16> %790, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %794 = zext <4 x i16> %793 to <4 x i32>
  %795 = sub nsw <4 x i32> %792, %794
  %796 = sub nsw <4 x i32> zeroinitializer, %795
  %797 = icmp slt <4 x i32> %795, zeroinitializer
  %798 = select <4 x i1> %797, <4 x i32> %796, <4 x i32> %795
  %799 = add nuw nsw <4 x i32> %798, <i32 32, i32 32, i32 32, i32 32>
  %800 = lshr <4 x i32> %799, <i32 6, i32 6, i32 6, i32 6>
  %801 = shufflevector <8 x i16> %787, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %802 = shufflevector <8 x i16> %790, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %803 = bitcast <8 x i16> %801 to <4 x i32>
  %804 = bitcast <8 x i16> %802 to <4 x i32>
  %805 = sub <4 x i32> %803, %804
  %806 = sub <4 x i32> zeroinitializer, %805
  %807 = icmp slt <4 x i32> %805, zeroinitializer
  %808 = select <4 x i1> %807, <4 x i32> %806, <4 x i32> %805
  %809 = add nuw <4 x i32> %808, <i32 32, i32 32, i32 32, i32 32>
  %810 = lshr <4 x i32> %809, <i32 6, i32 6, i32 6, i32 6>
  %811 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %800, <4 x i32> %810) #5
  %812 = lshr <8 x i16> %811, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %813 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %784, <8 x i16> %812) #5
  %814 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %813, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %815 = icmp slt <16 x i8> %814, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %816 = select <16 x i1> %815, <16 x i8> %814, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %817 = bitcast i8* %755 to <16 x i8>*
  store <16 x i8> %816, <16 x i8>* %817, align 16
  %818 = getelementptr inbounds i16, i16* %9, i64 208
  %819 = getelementptr inbounds i16, i16* %10, i64 208
  %820 = getelementptr inbounds i8, i8* %755, i64 16
  %821 = bitcast i16* %818 to <8 x i16>*
  %822 = load <8 x i16>, <8 x i16>* %821, align 16
  %823 = bitcast i16* %819 to <8 x i16>*
  %824 = load <8 x i16>, <8 x i16>* %823, align 16
  %825 = shufflevector <8 x i16> %822, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %826 = zext <4 x i16> %825 to <4 x i32>
  %827 = shufflevector <8 x i16> %824, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %828 = zext <4 x i16> %827 to <4 x i32>
  %829 = sub nsw <4 x i32> %826, %828
  %830 = sub nsw <4 x i32> zeroinitializer, %829
  %831 = icmp slt <4 x i32> %829, zeroinitializer
  %832 = select <4 x i1> %831, <4 x i32> %830, <4 x i32> %829
  %833 = add nuw nsw <4 x i32> %832, <i32 32, i32 32, i32 32, i32 32>
  %834 = lshr <4 x i32> %833, <i32 6, i32 6, i32 6, i32 6>
  %835 = shufflevector <8 x i16> %822, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %836 = shufflevector <8 x i16> %824, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %837 = bitcast <8 x i16> %835 to <4 x i32>
  %838 = bitcast <8 x i16> %836 to <4 x i32>
  %839 = sub <4 x i32> %837, %838
  %840 = sub <4 x i32> zeroinitializer, %839
  %841 = icmp slt <4 x i32> %839, zeroinitializer
  %842 = select <4 x i1> %841, <4 x i32> %840, <4 x i32> %839
  %843 = add nuw <4 x i32> %842, <i32 32, i32 32, i32 32, i32 32>
  %844 = lshr <4 x i32> %843, <i32 6, i32 6, i32 6, i32 6>
  %845 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %834, <4 x i32> %844) #5
  %846 = lshr <8 x i16> %845, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %847 = getelementptr inbounds i16, i16* %9, i64 216
  %848 = bitcast i16* %847 to <8 x i16>*
  %849 = load <8 x i16>, <8 x i16>* %848, align 16
  %850 = getelementptr inbounds i16, i16* %10, i64 216
  %851 = bitcast i16* %850 to <8 x i16>*
  %852 = load <8 x i16>, <8 x i16>* %851, align 16
  %853 = shufflevector <8 x i16> %849, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %854 = zext <4 x i16> %853 to <4 x i32>
  %855 = shufflevector <8 x i16> %852, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %856 = zext <4 x i16> %855 to <4 x i32>
  %857 = sub nsw <4 x i32> %854, %856
  %858 = sub nsw <4 x i32> zeroinitializer, %857
  %859 = icmp slt <4 x i32> %857, zeroinitializer
  %860 = select <4 x i1> %859, <4 x i32> %858, <4 x i32> %857
  %861 = add nuw nsw <4 x i32> %860, <i32 32, i32 32, i32 32, i32 32>
  %862 = lshr <4 x i32> %861, <i32 6, i32 6, i32 6, i32 6>
  %863 = shufflevector <8 x i16> %849, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %864 = shufflevector <8 x i16> %852, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %865 = bitcast <8 x i16> %863 to <4 x i32>
  %866 = bitcast <8 x i16> %864 to <4 x i32>
  %867 = sub <4 x i32> %865, %866
  %868 = sub <4 x i32> zeroinitializer, %867
  %869 = icmp slt <4 x i32> %867, zeroinitializer
  %870 = select <4 x i1> %869, <4 x i32> %868, <4 x i32> %867
  %871 = add nuw <4 x i32> %870, <i32 32, i32 32, i32 32, i32 32>
  %872 = lshr <4 x i32> %871, <i32 6, i32 6, i32 6, i32 6>
  %873 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %862, <4 x i32> %872) #5
  %874 = lshr <8 x i16> %873, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %875 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %846, <8 x i16> %874) #5
  %876 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %875, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %877 = icmp slt <16 x i8> %876, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %878 = select <16 x i1> %877, <16 x i8> %876, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %879 = bitcast i8* %820 to <16 x i8>*
  store <16 x i8> %878, <16 x i8>* %879, align 16
  %880 = getelementptr inbounds i16, i16* %9, i64 224
  %881 = getelementptr inbounds i16, i16* %10, i64 224
  %882 = getelementptr inbounds i8, i8* %755, i64 32
  %883 = bitcast i16* %880 to <8 x i16>*
  %884 = load <8 x i16>, <8 x i16>* %883, align 16
  %885 = bitcast i16* %881 to <8 x i16>*
  %886 = load <8 x i16>, <8 x i16>* %885, align 16
  %887 = shufflevector <8 x i16> %884, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %888 = zext <4 x i16> %887 to <4 x i32>
  %889 = shufflevector <8 x i16> %886, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %890 = zext <4 x i16> %889 to <4 x i32>
  %891 = sub nsw <4 x i32> %888, %890
  %892 = sub nsw <4 x i32> zeroinitializer, %891
  %893 = icmp slt <4 x i32> %891, zeroinitializer
  %894 = select <4 x i1> %893, <4 x i32> %892, <4 x i32> %891
  %895 = add nuw nsw <4 x i32> %894, <i32 32, i32 32, i32 32, i32 32>
  %896 = lshr <4 x i32> %895, <i32 6, i32 6, i32 6, i32 6>
  %897 = shufflevector <8 x i16> %884, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %898 = shufflevector <8 x i16> %886, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %899 = bitcast <8 x i16> %897 to <4 x i32>
  %900 = bitcast <8 x i16> %898 to <4 x i32>
  %901 = sub <4 x i32> %899, %900
  %902 = sub <4 x i32> zeroinitializer, %901
  %903 = icmp slt <4 x i32> %901, zeroinitializer
  %904 = select <4 x i1> %903, <4 x i32> %902, <4 x i32> %901
  %905 = add nuw <4 x i32> %904, <i32 32, i32 32, i32 32, i32 32>
  %906 = lshr <4 x i32> %905, <i32 6, i32 6, i32 6, i32 6>
  %907 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %896, <4 x i32> %906) #5
  %908 = lshr <8 x i16> %907, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %909 = getelementptr inbounds i16, i16* %9, i64 232
  %910 = bitcast i16* %909 to <8 x i16>*
  %911 = load <8 x i16>, <8 x i16>* %910, align 16
  %912 = getelementptr inbounds i16, i16* %10, i64 232
  %913 = bitcast i16* %912 to <8 x i16>*
  %914 = load <8 x i16>, <8 x i16>* %913, align 16
  %915 = shufflevector <8 x i16> %911, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %916 = zext <4 x i16> %915 to <4 x i32>
  %917 = shufflevector <8 x i16> %914, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %918 = zext <4 x i16> %917 to <4 x i32>
  %919 = sub nsw <4 x i32> %916, %918
  %920 = sub nsw <4 x i32> zeroinitializer, %919
  %921 = icmp slt <4 x i32> %919, zeroinitializer
  %922 = select <4 x i1> %921, <4 x i32> %920, <4 x i32> %919
  %923 = add nuw nsw <4 x i32> %922, <i32 32, i32 32, i32 32, i32 32>
  %924 = lshr <4 x i32> %923, <i32 6, i32 6, i32 6, i32 6>
  %925 = shufflevector <8 x i16> %911, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %926 = shufflevector <8 x i16> %914, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %927 = bitcast <8 x i16> %925 to <4 x i32>
  %928 = bitcast <8 x i16> %926 to <4 x i32>
  %929 = sub <4 x i32> %927, %928
  %930 = sub <4 x i32> zeroinitializer, %929
  %931 = icmp slt <4 x i32> %929, zeroinitializer
  %932 = select <4 x i1> %931, <4 x i32> %930, <4 x i32> %929
  %933 = add nuw <4 x i32> %932, <i32 32, i32 32, i32 32, i32 32>
  %934 = lshr <4 x i32> %933, <i32 6, i32 6, i32 6, i32 6>
  %935 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %924, <4 x i32> %934) #5
  %936 = lshr <8 x i16> %935, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %937 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %908, <8 x i16> %936) #5
  %938 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %937, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %939 = icmp slt <16 x i8> %938, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %940 = select <16 x i1> %939, <16 x i8> %938, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %941 = bitcast i8* %882 to <16 x i8>*
  store <16 x i8> %940, <16 x i8>* %941, align 16
  %942 = getelementptr inbounds i16, i16* %9, i64 240
  %943 = getelementptr inbounds i16, i16* %10, i64 240
  %944 = getelementptr inbounds i8, i8* %755, i64 48
  %945 = bitcast i16* %942 to <8 x i16>*
  %946 = load <8 x i16>, <8 x i16>* %945, align 16
  %947 = bitcast i16* %943 to <8 x i16>*
  %948 = load <8 x i16>, <8 x i16>* %947, align 16
  %949 = shufflevector <8 x i16> %946, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %950 = zext <4 x i16> %949 to <4 x i32>
  %951 = shufflevector <8 x i16> %948, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %952 = zext <4 x i16> %951 to <4 x i32>
  %953 = sub nsw <4 x i32> %950, %952
  %954 = sub nsw <4 x i32> zeroinitializer, %953
  %955 = icmp slt <4 x i32> %953, zeroinitializer
  %956 = select <4 x i1> %955, <4 x i32> %954, <4 x i32> %953
  %957 = add nuw nsw <4 x i32> %956, <i32 32, i32 32, i32 32, i32 32>
  %958 = lshr <4 x i32> %957, <i32 6, i32 6, i32 6, i32 6>
  %959 = shufflevector <8 x i16> %946, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %960 = shufflevector <8 x i16> %948, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %961 = bitcast <8 x i16> %959 to <4 x i32>
  %962 = bitcast <8 x i16> %960 to <4 x i32>
  %963 = sub <4 x i32> %961, %962
  %964 = sub <4 x i32> zeroinitializer, %963
  %965 = icmp slt <4 x i32> %963, zeroinitializer
  %966 = select <4 x i1> %965, <4 x i32> %964, <4 x i32> %963
  %967 = add nuw <4 x i32> %966, <i32 32, i32 32, i32 32, i32 32>
  %968 = lshr <4 x i32> %967, <i32 6, i32 6, i32 6, i32 6>
  %969 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %958, <4 x i32> %968) #5
  %970 = lshr <8 x i16> %969, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %971 = getelementptr inbounds i16, i16* %9, i64 248
  %972 = bitcast i16* %971 to <8 x i16>*
  %973 = load <8 x i16>, <8 x i16>* %972, align 16
  %974 = getelementptr inbounds i16, i16* %10, i64 248
  %975 = bitcast i16* %974 to <8 x i16>*
  %976 = load <8 x i16>, <8 x i16>* %975, align 16
  %977 = shufflevector <8 x i16> %973, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %978 = zext <4 x i16> %977 to <4 x i32>
  %979 = shufflevector <8 x i16> %976, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %980 = zext <4 x i16> %979 to <4 x i32>
  %981 = sub nsw <4 x i32> %978, %980
  %982 = sub nsw <4 x i32> zeroinitializer, %981
  %983 = icmp slt <4 x i32> %981, zeroinitializer
  %984 = select <4 x i1> %983, <4 x i32> %982, <4 x i32> %981
  %985 = add nuw nsw <4 x i32> %984, <i32 32, i32 32, i32 32, i32 32>
  %986 = lshr <4 x i32> %985, <i32 6, i32 6, i32 6, i32 6>
  %987 = shufflevector <8 x i16> %973, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %988 = shufflevector <8 x i16> %976, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %989 = bitcast <8 x i16> %987 to <4 x i32>
  %990 = bitcast <8 x i16> %988 to <4 x i32>
  %991 = sub <4 x i32> %989, %990
  %992 = sub <4 x i32> zeroinitializer, %991
  %993 = icmp slt <4 x i32> %991, zeroinitializer
  %994 = select <4 x i1> %993, <4 x i32> %992, <4 x i32> %991
  %995 = add nuw <4 x i32> %994, <i32 32, i32 32, i32 32, i32 32>
  %996 = lshr <4 x i32> %995, <i32 6, i32 6, i32 6, i32 6>
  %997 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %986, <4 x i32> %996) #5
  %998 = lshr <8 x i16> %997, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %999 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %970, <8 x i16> %998) #5
  %1000 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %999, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1001 = icmp slt <16 x i8> %1000, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1002 = select <16 x i1> %1001, <16 x i8> %1000, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1003 = bitcast i8* %944 to <16 x i8>*
  store <16 x i8> %1002, <16 x i8>* %1003, align 16
  %1004 = getelementptr inbounds i16, i16* %9, i64 256
  %1005 = getelementptr inbounds i16, i16* %10, i64 256
  %1006 = getelementptr inbounds i8, i8* %755, i64 %3
  %1007 = bitcast i16* %1004 to <8 x i16>*
  %1008 = load <8 x i16>, <8 x i16>* %1007, align 16
  %1009 = bitcast i16* %1005 to <8 x i16>*
  %1010 = load <8 x i16>, <8 x i16>* %1009, align 16
  %1011 = shufflevector <8 x i16> %1008, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1012 = zext <4 x i16> %1011 to <4 x i32>
  %1013 = shufflevector <8 x i16> %1010, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1014 = zext <4 x i16> %1013 to <4 x i32>
  %1015 = sub nsw <4 x i32> %1012, %1014
  %1016 = sub nsw <4 x i32> zeroinitializer, %1015
  %1017 = icmp slt <4 x i32> %1015, zeroinitializer
  %1018 = select <4 x i1> %1017, <4 x i32> %1016, <4 x i32> %1015
  %1019 = add nuw nsw <4 x i32> %1018, <i32 32, i32 32, i32 32, i32 32>
  %1020 = lshr <4 x i32> %1019, <i32 6, i32 6, i32 6, i32 6>
  %1021 = shufflevector <8 x i16> %1008, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1022 = shufflevector <8 x i16> %1010, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1023 = bitcast <8 x i16> %1021 to <4 x i32>
  %1024 = bitcast <8 x i16> %1022 to <4 x i32>
  %1025 = sub <4 x i32> %1023, %1024
  %1026 = sub <4 x i32> zeroinitializer, %1025
  %1027 = icmp slt <4 x i32> %1025, zeroinitializer
  %1028 = select <4 x i1> %1027, <4 x i32> %1026, <4 x i32> %1025
  %1029 = add nuw <4 x i32> %1028, <i32 32, i32 32, i32 32, i32 32>
  %1030 = lshr <4 x i32> %1029, <i32 6, i32 6, i32 6, i32 6>
  %1031 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1020, <4 x i32> %1030) #5
  %1032 = lshr <8 x i16> %1031, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1033 = getelementptr inbounds i16, i16* %9, i64 264
  %1034 = bitcast i16* %1033 to <8 x i16>*
  %1035 = load <8 x i16>, <8 x i16>* %1034, align 16
  %1036 = getelementptr inbounds i16, i16* %10, i64 264
  %1037 = bitcast i16* %1036 to <8 x i16>*
  %1038 = load <8 x i16>, <8 x i16>* %1037, align 16
  %1039 = shufflevector <8 x i16> %1035, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1040 = zext <4 x i16> %1039 to <4 x i32>
  %1041 = shufflevector <8 x i16> %1038, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1042 = zext <4 x i16> %1041 to <4 x i32>
  %1043 = sub nsw <4 x i32> %1040, %1042
  %1044 = sub nsw <4 x i32> zeroinitializer, %1043
  %1045 = icmp slt <4 x i32> %1043, zeroinitializer
  %1046 = select <4 x i1> %1045, <4 x i32> %1044, <4 x i32> %1043
  %1047 = add nuw nsw <4 x i32> %1046, <i32 32, i32 32, i32 32, i32 32>
  %1048 = lshr <4 x i32> %1047, <i32 6, i32 6, i32 6, i32 6>
  %1049 = shufflevector <8 x i16> %1035, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1050 = shufflevector <8 x i16> %1038, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1051 = bitcast <8 x i16> %1049 to <4 x i32>
  %1052 = bitcast <8 x i16> %1050 to <4 x i32>
  %1053 = sub <4 x i32> %1051, %1052
  %1054 = sub <4 x i32> zeroinitializer, %1053
  %1055 = icmp slt <4 x i32> %1053, zeroinitializer
  %1056 = select <4 x i1> %1055, <4 x i32> %1054, <4 x i32> %1053
  %1057 = add nuw <4 x i32> %1056, <i32 32, i32 32, i32 32, i32 32>
  %1058 = lshr <4 x i32> %1057, <i32 6, i32 6, i32 6, i32 6>
  %1059 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1048, <4 x i32> %1058) #5
  %1060 = lshr <8 x i16> %1059, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1061 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1032, <8 x i16> %1060) #5
  %1062 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1061, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1063 = icmp slt <16 x i8> %1062, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1064 = select <16 x i1> %1063, <16 x i8> %1062, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1065 = bitcast i8* %1006 to <16 x i8>*
  store <16 x i8> %1064, <16 x i8>* %1065, align 16
  %1066 = getelementptr inbounds i16, i16* %9, i64 272
  %1067 = getelementptr inbounds i16, i16* %10, i64 272
  %1068 = getelementptr inbounds i8, i8* %1006, i64 16
  %1069 = bitcast i16* %1066 to <8 x i16>*
  %1070 = load <8 x i16>, <8 x i16>* %1069, align 16
  %1071 = bitcast i16* %1067 to <8 x i16>*
  %1072 = load <8 x i16>, <8 x i16>* %1071, align 16
  %1073 = shufflevector <8 x i16> %1070, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1074 = zext <4 x i16> %1073 to <4 x i32>
  %1075 = shufflevector <8 x i16> %1072, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1076 = zext <4 x i16> %1075 to <4 x i32>
  %1077 = sub nsw <4 x i32> %1074, %1076
  %1078 = sub nsw <4 x i32> zeroinitializer, %1077
  %1079 = icmp slt <4 x i32> %1077, zeroinitializer
  %1080 = select <4 x i1> %1079, <4 x i32> %1078, <4 x i32> %1077
  %1081 = add nuw nsw <4 x i32> %1080, <i32 32, i32 32, i32 32, i32 32>
  %1082 = lshr <4 x i32> %1081, <i32 6, i32 6, i32 6, i32 6>
  %1083 = shufflevector <8 x i16> %1070, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1084 = shufflevector <8 x i16> %1072, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1085 = bitcast <8 x i16> %1083 to <4 x i32>
  %1086 = bitcast <8 x i16> %1084 to <4 x i32>
  %1087 = sub <4 x i32> %1085, %1086
  %1088 = sub <4 x i32> zeroinitializer, %1087
  %1089 = icmp slt <4 x i32> %1087, zeroinitializer
  %1090 = select <4 x i1> %1089, <4 x i32> %1088, <4 x i32> %1087
  %1091 = add nuw <4 x i32> %1090, <i32 32, i32 32, i32 32, i32 32>
  %1092 = lshr <4 x i32> %1091, <i32 6, i32 6, i32 6, i32 6>
  %1093 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1082, <4 x i32> %1092) #5
  %1094 = lshr <8 x i16> %1093, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1095 = getelementptr inbounds i16, i16* %9, i64 280
  %1096 = bitcast i16* %1095 to <8 x i16>*
  %1097 = load <8 x i16>, <8 x i16>* %1096, align 16
  %1098 = getelementptr inbounds i16, i16* %10, i64 280
  %1099 = bitcast i16* %1098 to <8 x i16>*
  %1100 = load <8 x i16>, <8 x i16>* %1099, align 16
  %1101 = shufflevector <8 x i16> %1097, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1102 = zext <4 x i16> %1101 to <4 x i32>
  %1103 = shufflevector <8 x i16> %1100, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1104 = zext <4 x i16> %1103 to <4 x i32>
  %1105 = sub nsw <4 x i32> %1102, %1104
  %1106 = sub nsw <4 x i32> zeroinitializer, %1105
  %1107 = icmp slt <4 x i32> %1105, zeroinitializer
  %1108 = select <4 x i1> %1107, <4 x i32> %1106, <4 x i32> %1105
  %1109 = add nuw nsw <4 x i32> %1108, <i32 32, i32 32, i32 32, i32 32>
  %1110 = lshr <4 x i32> %1109, <i32 6, i32 6, i32 6, i32 6>
  %1111 = shufflevector <8 x i16> %1097, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1112 = shufflevector <8 x i16> %1100, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1113 = bitcast <8 x i16> %1111 to <4 x i32>
  %1114 = bitcast <8 x i16> %1112 to <4 x i32>
  %1115 = sub <4 x i32> %1113, %1114
  %1116 = sub <4 x i32> zeroinitializer, %1115
  %1117 = icmp slt <4 x i32> %1115, zeroinitializer
  %1118 = select <4 x i1> %1117, <4 x i32> %1116, <4 x i32> %1115
  %1119 = add nuw <4 x i32> %1118, <i32 32, i32 32, i32 32, i32 32>
  %1120 = lshr <4 x i32> %1119, <i32 6, i32 6, i32 6, i32 6>
  %1121 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1110, <4 x i32> %1120) #5
  %1122 = lshr <8 x i16> %1121, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1123 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1094, <8 x i16> %1122) #5
  %1124 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1123, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1125 = icmp slt <16 x i8> %1124, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1126 = select <16 x i1> %1125, <16 x i8> %1124, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1127 = bitcast i8* %1068 to <16 x i8>*
  store <16 x i8> %1126, <16 x i8>* %1127, align 16
  %1128 = getelementptr inbounds i16, i16* %9, i64 288
  %1129 = getelementptr inbounds i16, i16* %10, i64 288
  %1130 = getelementptr inbounds i8, i8* %1006, i64 32
  %1131 = bitcast i16* %1128 to <8 x i16>*
  %1132 = load <8 x i16>, <8 x i16>* %1131, align 16
  %1133 = bitcast i16* %1129 to <8 x i16>*
  %1134 = load <8 x i16>, <8 x i16>* %1133, align 16
  %1135 = shufflevector <8 x i16> %1132, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1136 = zext <4 x i16> %1135 to <4 x i32>
  %1137 = shufflevector <8 x i16> %1134, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1138 = zext <4 x i16> %1137 to <4 x i32>
  %1139 = sub nsw <4 x i32> %1136, %1138
  %1140 = sub nsw <4 x i32> zeroinitializer, %1139
  %1141 = icmp slt <4 x i32> %1139, zeroinitializer
  %1142 = select <4 x i1> %1141, <4 x i32> %1140, <4 x i32> %1139
  %1143 = add nuw nsw <4 x i32> %1142, <i32 32, i32 32, i32 32, i32 32>
  %1144 = lshr <4 x i32> %1143, <i32 6, i32 6, i32 6, i32 6>
  %1145 = shufflevector <8 x i16> %1132, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1146 = shufflevector <8 x i16> %1134, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1147 = bitcast <8 x i16> %1145 to <4 x i32>
  %1148 = bitcast <8 x i16> %1146 to <4 x i32>
  %1149 = sub <4 x i32> %1147, %1148
  %1150 = sub <4 x i32> zeroinitializer, %1149
  %1151 = icmp slt <4 x i32> %1149, zeroinitializer
  %1152 = select <4 x i1> %1151, <4 x i32> %1150, <4 x i32> %1149
  %1153 = add nuw <4 x i32> %1152, <i32 32, i32 32, i32 32, i32 32>
  %1154 = lshr <4 x i32> %1153, <i32 6, i32 6, i32 6, i32 6>
  %1155 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1144, <4 x i32> %1154) #5
  %1156 = lshr <8 x i16> %1155, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1157 = getelementptr inbounds i16, i16* %9, i64 296
  %1158 = bitcast i16* %1157 to <8 x i16>*
  %1159 = load <8 x i16>, <8 x i16>* %1158, align 16
  %1160 = getelementptr inbounds i16, i16* %10, i64 296
  %1161 = bitcast i16* %1160 to <8 x i16>*
  %1162 = load <8 x i16>, <8 x i16>* %1161, align 16
  %1163 = shufflevector <8 x i16> %1159, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1164 = zext <4 x i16> %1163 to <4 x i32>
  %1165 = shufflevector <8 x i16> %1162, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1166 = zext <4 x i16> %1165 to <4 x i32>
  %1167 = sub nsw <4 x i32> %1164, %1166
  %1168 = sub nsw <4 x i32> zeroinitializer, %1167
  %1169 = icmp slt <4 x i32> %1167, zeroinitializer
  %1170 = select <4 x i1> %1169, <4 x i32> %1168, <4 x i32> %1167
  %1171 = add nuw nsw <4 x i32> %1170, <i32 32, i32 32, i32 32, i32 32>
  %1172 = lshr <4 x i32> %1171, <i32 6, i32 6, i32 6, i32 6>
  %1173 = shufflevector <8 x i16> %1159, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1174 = shufflevector <8 x i16> %1162, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1175 = bitcast <8 x i16> %1173 to <4 x i32>
  %1176 = bitcast <8 x i16> %1174 to <4 x i32>
  %1177 = sub <4 x i32> %1175, %1176
  %1178 = sub <4 x i32> zeroinitializer, %1177
  %1179 = icmp slt <4 x i32> %1177, zeroinitializer
  %1180 = select <4 x i1> %1179, <4 x i32> %1178, <4 x i32> %1177
  %1181 = add nuw <4 x i32> %1180, <i32 32, i32 32, i32 32, i32 32>
  %1182 = lshr <4 x i32> %1181, <i32 6, i32 6, i32 6, i32 6>
  %1183 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1172, <4 x i32> %1182) #5
  %1184 = lshr <8 x i16> %1183, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1185 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1156, <8 x i16> %1184) #5
  %1186 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1185, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1187 = icmp slt <16 x i8> %1186, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1188 = select <16 x i1> %1187, <16 x i8> %1186, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1189 = bitcast i8* %1130 to <16 x i8>*
  store <16 x i8> %1188, <16 x i8>* %1189, align 16
  %1190 = getelementptr inbounds i16, i16* %9, i64 304
  %1191 = getelementptr inbounds i16, i16* %10, i64 304
  %1192 = getelementptr inbounds i8, i8* %1006, i64 48
  %1193 = bitcast i16* %1190 to <8 x i16>*
  %1194 = load <8 x i16>, <8 x i16>* %1193, align 16
  %1195 = bitcast i16* %1191 to <8 x i16>*
  %1196 = load <8 x i16>, <8 x i16>* %1195, align 16
  %1197 = shufflevector <8 x i16> %1194, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1198 = zext <4 x i16> %1197 to <4 x i32>
  %1199 = shufflevector <8 x i16> %1196, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1200 = zext <4 x i16> %1199 to <4 x i32>
  %1201 = sub nsw <4 x i32> %1198, %1200
  %1202 = sub nsw <4 x i32> zeroinitializer, %1201
  %1203 = icmp slt <4 x i32> %1201, zeroinitializer
  %1204 = select <4 x i1> %1203, <4 x i32> %1202, <4 x i32> %1201
  %1205 = add nuw nsw <4 x i32> %1204, <i32 32, i32 32, i32 32, i32 32>
  %1206 = lshr <4 x i32> %1205, <i32 6, i32 6, i32 6, i32 6>
  %1207 = shufflevector <8 x i16> %1194, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1208 = shufflevector <8 x i16> %1196, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1209 = bitcast <8 x i16> %1207 to <4 x i32>
  %1210 = bitcast <8 x i16> %1208 to <4 x i32>
  %1211 = sub <4 x i32> %1209, %1210
  %1212 = sub <4 x i32> zeroinitializer, %1211
  %1213 = icmp slt <4 x i32> %1211, zeroinitializer
  %1214 = select <4 x i1> %1213, <4 x i32> %1212, <4 x i32> %1211
  %1215 = add nuw <4 x i32> %1214, <i32 32, i32 32, i32 32, i32 32>
  %1216 = lshr <4 x i32> %1215, <i32 6, i32 6, i32 6, i32 6>
  %1217 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1206, <4 x i32> %1216) #5
  %1218 = lshr <8 x i16> %1217, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1219 = getelementptr inbounds i16, i16* %9, i64 312
  %1220 = bitcast i16* %1219 to <8 x i16>*
  %1221 = load <8 x i16>, <8 x i16>* %1220, align 16
  %1222 = getelementptr inbounds i16, i16* %10, i64 312
  %1223 = bitcast i16* %1222 to <8 x i16>*
  %1224 = load <8 x i16>, <8 x i16>* %1223, align 16
  %1225 = shufflevector <8 x i16> %1221, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1226 = zext <4 x i16> %1225 to <4 x i32>
  %1227 = shufflevector <8 x i16> %1224, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1228 = zext <4 x i16> %1227 to <4 x i32>
  %1229 = sub nsw <4 x i32> %1226, %1228
  %1230 = sub nsw <4 x i32> zeroinitializer, %1229
  %1231 = icmp slt <4 x i32> %1229, zeroinitializer
  %1232 = select <4 x i1> %1231, <4 x i32> %1230, <4 x i32> %1229
  %1233 = add nuw nsw <4 x i32> %1232, <i32 32, i32 32, i32 32, i32 32>
  %1234 = lshr <4 x i32> %1233, <i32 6, i32 6, i32 6, i32 6>
  %1235 = shufflevector <8 x i16> %1221, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1236 = shufflevector <8 x i16> %1224, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1237 = bitcast <8 x i16> %1235 to <4 x i32>
  %1238 = bitcast <8 x i16> %1236 to <4 x i32>
  %1239 = sub <4 x i32> %1237, %1238
  %1240 = sub <4 x i32> zeroinitializer, %1239
  %1241 = icmp slt <4 x i32> %1239, zeroinitializer
  %1242 = select <4 x i1> %1241, <4 x i32> %1240, <4 x i32> %1239
  %1243 = add nuw <4 x i32> %1242, <i32 32, i32 32, i32 32, i32 32>
  %1244 = lshr <4 x i32> %1243, <i32 6, i32 6, i32 6, i32 6>
  %1245 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1234, <4 x i32> %1244) #5
  %1246 = lshr <8 x i16> %1245, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1247 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1218, <8 x i16> %1246) #5
  %1248 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1247, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1249 = icmp slt <16 x i8> %1248, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1250 = select <16 x i1> %1249, <16 x i8> %1248, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1251 = bitcast i8* %1192 to <16 x i8>*
  store <16 x i8> %1250, <16 x i8>* %1251, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_127WeightMask64x128_10bpp_SSE4ILb1EEEvPKvS5_Phl(i8* readonly, i8* readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  br label %7

7:                                                ; preds = %7, %4
  %8 = phi i8* [ %2, %4 ], [ %767, %7 ]
  %9 = phi i16* [ %5, %4 ], [ %765, %7 ]
  %10 = phi i16* [ %6, %4 ], [ %766, %7 ]
  %11 = phi i32 [ 42, %4 ], [ %768, %7 ]
  %12 = bitcast i16* %9 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = bitcast i16* %10 to <8 x i16>*
  %15 = load <8 x i16>, <8 x i16>* %14, align 16
  %16 = shufflevector <8 x i16> %13, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %17 = zext <4 x i16> %16 to <4 x i32>
  %18 = shufflevector <8 x i16> %15, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %19 = zext <4 x i16> %18 to <4 x i32>
  %20 = sub nsw <4 x i32> %17, %19
  %21 = sub nsw <4 x i32> zeroinitializer, %20
  %22 = icmp slt <4 x i32> %20, zeroinitializer
  %23 = select <4 x i1> %22, <4 x i32> %21, <4 x i32> %20
  %24 = add nuw nsw <4 x i32> %23, <i32 32, i32 32, i32 32, i32 32>
  %25 = lshr <4 x i32> %24, <i32 6, i32 6, i32 6, i32 6>
  %26 = shufflevector <8 x i16> %13, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %27 = shufflevector <8 x i16> %15, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %28 = bitcast <8 x i16> %26 to <4 x i32>
  %29 = bitcast <8 x i16> %27 to <4 x i32>
  %30 = sub <4 x i32> %28, %29
  %31 = sub <4 x i32> zeroinitializer, %30
  %32 = icmp slt <4 x i32> %30, zeroinitializer
  %33 = select <4 x i1> %32, <4 x i32> %31, <4 x i32> %30
  %34 = add nuw <4 x i32> %33, <i32 32, i32 32, i32 32, i32 32>
  %35 = lshr <4 x i32> %34, <i32 6, i32 6, i32 6, i32 6>
  %36 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %25, <4 x i32> %35) #5
  %37 = lshr <8 x i16> %36, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %38 = getelementptr inbounds i16, i16* %9, i64 8
  %39 = bitcast i16* %38 to <8 x i16>*
  %40 = load <8 x i16>, <8 x i16>* %39, align 16
  %41 = getelementptr inbounds i16, i16* %10, i64 8
  %42 = bitcast i16* %41 to <8 x i16>*
  %43 = load <8 x i16>, <8 x i16>* %42, align 16
  %44 = shufflevector <8 x i16> %40, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %45 = zext <4 x i16> %44 to <4 x i32>
  %46 = shufflevector <8 x i16> %43, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %47 = zext <4 x i16> %46 to <4 x i32>
  %48 = sub nsw <4 x i32> %45, %47
  %49 = sub nsw <4 x i32> zeroinitializer, %48
  %50 = icmp slt <4 x i32> %48, zeroinitializer
  %51 = select <4 x i1> %50, <4 x i32> %49, <4 x i32> %48
  %52 = add nuw nsw <4 x i32> %51, <i32 32, i32 32, i32 32, i32 32>
  %53 = lshr <4 x i32> %52, <i32 6, i32 6, i32 6, i32 6>
  %54 = shufflevector <8 x i16> %40, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %55 = shufflevector <8 x i16> %43, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %56 = bitcast <8 x i16> %54 to <4 x i32>
  %57 = bitcast <8 x i16> %55 to <4 x i32>
  %58 = sub <4 x i32> %56, %57
  %59 = sub <4 x i32> zeroinitializer, %58
  %60 = icmp slt <4 x i32> %58, zeroinitializer
  %61 = select <4 x i1> %60, <4 x i32> %59, <4 x i32> %58
  %62 = add nuw <4 x i32> %61, <i32 32, i32 32, i32 32, i32 32>
  %63 = lshr <4 x i32> %62, <i32 6, i32 6, i32 6, i32 6>
  %64 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %53, <4 x i32> %63) #5
  %65 = lshr <8 x i16> %64, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %66 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %37, <8 x i16> %65) #5
  %67 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %66, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %68 = icmp slt <16 x i8> %67, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %69 = select <16 x i1> %68, <16 x i8> %67, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %70 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %69
  %71 = bitcast i8* %8 to <16 x i8>*
  store <16 x i8> %70, <16 x i8>* %71, align 16
  %72 = getelementptr inbounds i16, i16* %9, i64 16
  %73 = getelementptr inbounds i16, i16* %10, i64 16
  %74 = getelementptr inbounds i8, i8* %8, i64 16
  %75 = bitcast i16* %72 to <8 x i16>*
  %76 = load <8 x i16>, <8 x i16>* %75, align 16
  %77 = bitcast i16* %73 to <8 x i16>*
  %78 = load <8 x i16>, <8 x i16>* %77, align 16
  %79 = shufflevector <8 x i16> %76, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %80 = zext <4 x i16> %79 to <4 x i32>
  %81 = shufflevector <8 x i16> %78, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %82 = zext <4 x i16> %81 to <4 x i32>
  %83 = sub nsw <4 x i32> %80, %82
  %84 = sub nsw <4 x i32> zeroinitializer, %83
  %85 = icmp slt <4 x i32> %83, zeroinitializer
  %86 = select <4 x i1> %85, <4 x i32> %84, <4 x i32> %83
  %87 = add nuw nsw <4 x i32> %86, <i32 32, i32 32, i32 32, i32 32>
  %88 = lshr <4 x i32> %87, <i32 6, i32 6, i32 6, i32 6>
  %89 = shufflevector <8 x i16> %76, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %90 = shufflevector <8 x i16> %78, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %91 = bitcast <8 x i16> %89 to <4 x i32>
  %92 = bitcast <8 x i16> %90 to <4 x i32>
  %93 = sub <4 x i32> %91, %92
  %94 = sub <4 x i32> zeroinitializer, %93
  %95 = icmp slt <4 x i32> %93, zeroinitializer
  %96 = select <4 x i1> %95, <4 x i32> %94, <4 x i32> %93
  %97 = add nuw <4 x i32> %96, <i32 32, i32 32, i32 32, i32 32>
  %98 = lshr <4 x i32> %97, <i32 6, i32 6, i32 6, i32 6>
  %99 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %88, <4 x i32> %98) #5
  %100 = lshr <8 x i16> %99, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %101 = getelementptr inbounds i16, i16* %9, i64 24
  %102 = bitcast i16* %101 to <8 x i16>*
  %103 = load <8 x i16>, <8 x i16>* %102, align 16
  %104 = getelementptr inbounds i16, i16* %10, i64 24
  %105 = bitcast i16* %104 to <8 x i16>*
  %106 = load <8 x i16>, <8 x i16>* %105, align 16
  %107 = shufflevector <8 x i16> %103, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %108 = zext <4 x i16> %107 to <4 x i32>
  %109 = shufflevector <8 x i16> %106, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %110 = zext <4 x i16> %109 to <4 x i32>
  %111 = sub nsw <4 x i32> %108, %110
  %112 = sub nsw <4 x i32> zeroinitializer, %111
  %113 = icmp slt <4 x i32> %111, zeroinitializer
  %114 = select <4 x i1> %113, <4 x i32> %112, <4 x i32> %111
  %115 = add nuw nsw <4 x i32> %114, <i32 32, i32 32, i32 32, i32 32>
  %116 = lshr <4 x i32> %115, <i32 6, i32 6, i32 6, i32 6>
  %117 = shufflevector <8 x i16> %103, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %118 = shufflevector <8 x i16> %106, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %119 = bitcast <8 x i16> %117 to <4 x i32>
  %120 = bitcast <8 x i16> %118 to <4 x i32>
  %121 = sub <4 x i32> %119, %120
  %122 = sub <4 x i32> zeroinitializer, %121
  %123 = icmp slt <4 x i32> %121, zeroinitializer
  %124 = select <4 x i1> %123, <4 x i32> %122, <4 x i32> %121
  %125 = add nuw <4 x i32> %124, <i32 32, i32 32, i32 32, i32 32>
  %126 = lshr <4 x i32> %125, <i32 6, i32 6, i32 6, i32 6>
  %127 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %116, <4 x i32> %126) #5
  %128 = lshr <8 x i16> %127, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %129 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %100, <8 x i16> %128) #5
  %130 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %129, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %131 = icmp slt <16 x i8> %130, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %132 = select <16 x i1> %131, <16 x i8> %130, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %133 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %132
  %134 = bitcast i8* %74 to <16 x i8>*
  store <16 x i8> %133, <16 x i8>* %134, align 16
  %135 = getelementptr inbounds i16, i16* %9, i64 32
  %136 = getelementptr inbounds i16, i16* %10, i64 32
  %137 = getelementptr inbounds i8, i8* %8, i64 32
  %138 = bitcast i16* %135 to <8 x i16>*
  %139 = load <8 x i16>, <8 x i16>* %138, align 16
  %140 = bitcast i16* %136 to <8 x i16>*
  %141 = load <8 x i16>, <8 x i16>* %140, align 16
  %142 = shufflevector <8 x i16> %139, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %143 = zext <4 x i16> %142 to <4 x i32>
  %144 = shufflevector <8 x i16> %141, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %145 = zext <4 x i16> %144 to <4 x i32>
  %146 = sub nsw <4 x i32> %143, %145
  %147 = sub nsw <4 x i32> zeroinitializer, %146
  %148 = icmp slt <4 x i32> %146, zeroinitializer
  %149 = select <4 x i1> %148, <4 x i32> %147, <4 x i32> %146
  %150 = add nuw nsw <4 x i32> %149, <i32 32, i32 32, i32 32, i32 32>
  %151 = lshr <4 x i32> %150, <i32 6, i32 6, i32 6, i32 6>
  %152 = shufflevector <8 x i16> %139, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %153 = shufflevector <8 x i16> %141, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %154 = bitcast <8 x i16> %152 to <4 x i32>
  %155 = bitcast <8 x i16> %153 to <4 x i32>
  %156 = sub <4 x i32> %154, %155
  %157 = sub <4 x i32> zeroinitializer, %156
  %158 = icmp slt <4 x i32> %156, zeroinitializer
  %159 = select <4 x i1> %158, <4 x i32> %157, <4 x i32> %156
  %160 = add nuw <4 x i32> %159, <i32 32, i32 32, i32 32, i32 32>
  %161 = lshr <4 x i32> %160, <i32 6, i32 6, i32 6, i32 6>
  %162 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %151, <4 x i32> %161) #5
  %163 = lshr <8 x i16> %162, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %164 = getelementptr inbounds i16, i16* %9, i64 40
  %165 = bitcast i16* %164 to <8 x i16>*
  %166 = load <8 x i16>, <8 x i16>* %165, align 16
  %167 = getelementptr inbounds i16, i16* %10, i64 40
  %168 = bitcast i16* %167 to <8 x i16>*
  %169 = load <8 x i16>, <8 x i16>* %168, align 16
  %170 = shufflevector <8 x i16> %166, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %171 = zext <4 x i16> %170 to <4 x i32>
  %172 = shufflevector <8 x i16> %169, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %173 = zext <4 x i16> %172 to <4 x i32>
  %174 = sub nsw <4 x i32> %171, %173
  %175 = sub nsw <4 x i32> zeroinitializer, %174
  %176 = icmp slt <4 x i32> %174, zeroinitializer
  %177 = select <4 x i1> %176, <4 x i32> %175, <4 x i32> %174
  %178 = add nuw nsw <4 x i32> %177, <i32 32, i32 32, i32 32, i32 32>
  %179 = lshr <4 x i32> %178, <i32 6, i32 6, i32 6, i32 6>
  %180 = shufflevector <8 x i16> %166, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %181 = shufflevector <8 x i16> %169, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %182 = bitcast <8 x i16> %180 to <4 x i32>
  %183 = bitcast <8 x i16> %181 to <4 x i32>
  %184 = sub <4 x i32> %182, %183
  %185 = sub <4 x i32> zeroinitializer, %184
  %186 = icmp slt <4 x i32> %184, zeroinitializer
  %187 = select <4 x i1> %186, <4 x i32> %185, <4 x i32> %184
  %188 = add nuw <4 x i32> %187, <i32 32, i32 32, i32 32, i32 32>
  %189 = lshr <4 x i32> %188, <i32 6, i32 6, i32 6, i32 6>
  %190 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %179, <4 x i32> %189) #5
  %191 = lshr <8 x i16> %190, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %192 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %163, <8 x i16> %191) #5
  %193 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %192, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %194 = icmp slt <16 x i8> %193, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %195 = select <16 x i1> %194, <16 x i8> %193, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %196 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %195
  %197 = bitcast i8* %137 to <16 x i8>*
  store <16 x i8> %196, <16 x i8>* %197, align 16
  %198 = getelementptr inbounds i16, i16* %9, i64 48
  %199 = getelementptr inbounds i16, i16* %10, i64 48
  %200 = getelementptr inbounds i8, i8* %8, i64 48
  %201 = bitcast i16* %198 to <8 x i16>*
  %202 = load <8 x i16>, <8 x i16>* %201, align 16
  %203 = bitcast i16* %199 to <8 x i16>*
  %204 = load <8 x i16>, <8 x i16>* %203, align 16
  %205 = shufflevector <8 x i16> %202, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %206 = zext <4 x i16> %205 to <4 x i32>
  %207 = shufflevector <8 x i16> %204, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %208 = zext <4 x i16> %207 to <4 x i32>
  %209 = sub nsw <4 x i32> %206, %208
  %210 = sub nsw <4 x i32> zeroinitializer, %209
  %211 = icmp slt <4 x i32> %209, zeroinitializer
  %212 = select <4 x i1> %211, <4 x i32> %210, <4 x i32> %209
  %213 = add nuw nsw <4 x i32> %212, <i32 32, i32 32, i32 32, i32 32>
  %214 = lshr <4 x i32> %213, <i32 6, i32 6, i32 6, i32 6>
  %215 = shufflevector <8 x i16> %202, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %216 = shufflevector <8 x i16> %204, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %217 = bitcast <8 x i16> %215 to <4 x i32>
  %218 = bitcast <8 x i16> %216 to <4 x i32>
  %219 = sub <4 x i32> %217, %218
  %220 = sub <4 x i32> zeroinitializer, %219
  %221 = icmp slt <4 x i32> %219, zeroinitializer
  %222 = select <4 x i1> %221, <4 x i32> %220, <4 x i32> %219
  %223 = add nuw <4 x i32> %222, <i32 32, i32 32, i32 32, i32 32>
  %224 = lshr <4 x i32> %223, <i32 6, i32 6, i32 6, i32 6>
  %225 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %214, <4 x i32> %224) #5
  %226 = lshr <8 x i16> %225, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %227 = getelementptr inbounds i16, i16* %9, i64 56
  %228 = bitcast i16* %227 to <8 x i16>*
  %229 = load <8 x i16>, <8 x i16>* %228, align 16
  %230 = getelementptr inbounds i16, i16* %10, i64 56
  %231 = bitcast i16* %230 to <8 x i16>*
  %232 = load <8 x i16>, <8 x i16>* %231, align 16
  %233 = shufflevector <8 x i16> %229, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %234 = zext <4 x i16> %233 to <4 x i32>
  %235 = shufflevector <8 x i16> %232, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %236 = zext <4 x i16> %235 to <4 x i32>
  %237 = sub nsw <4 x i32> %234, %236
  %238 = sub nsw <4 x i32> zeroinitializer, %237
  %239 = icmp slt <4 x i32> %237, zeroinitializer
  %240 = select <4 x i1> %239, <4 x i32> %238, <4 x i32> %237
  %241 = add nuw nsw <4 x i32> %240, <i32 32, i32 32, i32 32, i32 32>
  %242 = lshr <4 x i32> %241, <i32 6, i32 6, i32 6, i32 6>
  %243 = shufflevector <8 x i16> %229, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %244 = shufflevector <8 x i16> %232, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %245 = bitcast <8 x i16> %243 to <4 x i32>
  %246 = bitcast <8 x i16> %244 to <4 x i32>
  %247 = sub <4 x i32> %245, %246
  %248 = sub <4 x i32> zeroinitializer, %247
  %249 = icmp slt <4 x i32> %247, zeroinitializer
  %250 = select <4 x i1> %249, <4 x i32> %248, <4 x i32> %247
  %251 = add nuw <4 x i32> %250, <i32 32, i32 32, i32 32, i32 32>
  %252 = lshr <4 x i32> %251, <i32 6, i32 6, i32 6, i32 6>
  %253 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %242, <4 x i32> %252) #5
  %254 = lshr <8 x i16> %253, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %255 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %226, <8 x i16> %254) #5
  %256 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %255, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %257 = icmp slt <16 x i8> %256, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %258 = select <16 x i1> %257, <16 x i8> %256, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %259 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %258
  %260 = bitcast i8* %200 to <16 x i8>*
  store <16 x i8> %259, <16 x i8>* %260, align 16
  %261 = getelementptr inbounds i16, i16* %9, i64 64
  %262 = getelementptr inbounds i16, i16* %10, i64 64
  %263 = getelementptr inbounds i8, i8* %8, i64 %3
  %264 = bitcast i16* %261 to <8 x i16>*
  %265 = load <8 x i16>, <8 x i16>* %264, align 16
  %266 = bitcast i16* %262 to <8 x i16>*
  %267 = load <8 x i16>, <8 x i16>* %266, align 16
  %268 = shufflevector <8 x i16> %265, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %269 = zext <4 x i16> %268 to <4 x i32>
  %270 = shufflevector <8 x i16> %267, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %271 = zext <4 x i16> %270 to <4 x i32>
  %272 = sub nsw <4 x i32> %269, %271
  %273 = sub nsw <4 x i32> zeroinitializer, %272
  %274 = icmp slt <4 x i32> %272, zeroinitializer
  %275 = select <4 x i1> %274, <4 x i32> %273, <4 x i32> %272
  %276 = add nuw nsw <4 x i32> %275, <i32 32, i32 32, i32 32, i32 32>
  %277 = lshr <4 x i32> %276, <i32 6, i32 6, i32 6, i32 6>
  %278 = shufflevector <8 x i16> %265, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %279 = shufflevector <8 x i16> %267, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %280 = bitcast <8 x i16> %278 to <4 x i32>
  %281 = bitcast <8 x i16> %279 to <4 x i32>
  %282 = sub <4 x i32> %280, %281
  %283 = sub <4 x i32> zeroinitializer, %282
  %284 = icmp slt <4 x i32> %282, zeroinitializer
  %285 = select <4 x i1> %284, <4 x i32> %283, <4 x i32> %282
  %286 = add nuw <4 x i32> %285, <i32 32, i32 32, i32 32, i32 32>
  %287 = lshr <4 x i32> %286, <i32 6, i32 6, i32 6, i32 6>
  %288 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %277, <4 x i32> %287) #5
  %289 = lshr <8 x i16> %288, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %290 = getelementptr inbounds i16, i16* %9, i64 72
  %291 = bitcast i16* %290 to <8 x i16>*
  %292 = load <8 x i16>, <8 x i16>* %291, align 16
  %293 = getelementptr inbounds i16, i16* %10, i64 72
  %294 = bitcast i16* %293 to <8 x i16>*
  %295 = load <8 x i16>, <8 x i16>* %294, align 16
  %296 = shufflevector <8 x i16> %292, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %297 = zext <4 x i16> %296 to <4 x i32>
  %298 = shufflevector <8 x i16> %295, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %299 = zext <4 x i16> %298 to <4 x i32>
  %300 = sub nsw <4 x i32> %297, %299
  %301 = sub nsw <4 x i32> zeroinitializer, %300
  %302 = icmp slt <4 x i32> %300, zeroinitializer
  %303 = select <4 x i1> %302, <4 x i32> %301, <4 x i32> %300
  %304 = add nuw nsw <4 x i32> %303, <i32 32, i32 32, i32 32, i32 32>
  %305 = lshr <4 x i32> %304, <i32 6, i32 6, i32 6, i32 6>
  %306 = shufflevector <8 x i16> %292, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %307 = shufflevector <8 x i16> %295, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %308 = bitcast <8 x i16> %306 to <4 x i32>
  %309 = bitcast <8 x i16> %307 to <4 x i32>
  %310 = sub <4 x i32> %308, %309
  %311 = sub <4 x i32> zeroinitializer, %310
  %312 = icmp slt <4 x i32> %310, zeroinitializer
  %313 = select <4 x i1> %312, <4 x i32> %311, <4 x i32> %310
  %314 = add nuw <4 x i32> %313, <i32 32, i32 32, i32 32, i32 32>
  %315 = lshr <4 x i32> %314, <i32 6, i32 6, i32 6, i32 6>
  %316 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %305, <4 x i32> %315) #5
  %317 = lshr <8 x i16> %316, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %318 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %289, <8 x i16> %317) #5
  %319 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %318, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %320 = icmp slt <16 x i8> %319, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %321 = select <16 x i1> %320, <16 x i8> %319, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %322 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %321
  %323 = bitcast i8* %263 to <16 x i8>*
  store <16 x i8> %322, <16 x i8>* %323, align 16
  %324 = getelementptr inbounds i16, i16* %9, i64 80
  %325 = getelementptr inbounds i16, i16* %10, i64 80
  %326 = getelementptr inbounds i8, i8* %263, i64 16
  %327 = bitcast i16* %324 to <8 x i16>*
  %328 = load <8 x i16>, <8 x i16>* %327, align 16
  %329 = bitcast i16* %325 to <8 x i16>*
  %330 = load <8 x i16>, <8 x i16>* %329, align 16
  %331 = shufflevector <8 x i16> %328, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %332 = zext <4 x i16> %331 to <4 x i32>
  %333 = shufflevector <8 x i16> %330, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %334 = zext <4 x i16> %333 to <4 x i32>
  %335 = sub nsw <4 x i32> %332, %334
  %336 = sub nsw <4 x i32> zeroinitializer, %335
  %337 = icmp slt <4 x i32> %335, zeroinitializer
  %338 = select <4 x i1> %337, <4 x i32> %336, <4 x i32> %335
  %339 = add nuw nsw <4 x i32> %338, <i32 32, i32 32, i32 32, i32 32>
  %340 = lshr <4 x i32> %339, <i32 6, i32 6, i32 6, i32 6>
  %341 = shufflevector <8 x i16> %328, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %342 = shufflevector <8 x i16> %330, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %343 = bitcast <8 x i16> %341 to <4 x i32>
  %344 = bitcast <8 x i16> %342 to <4 x i32>
  %345 = sub <4 x i32> %343, %344
  %346 = sub <4 x i32> zeroinitializer, %345
  %347 = icmp slt <4 x i32> %345, zeroinitializer
  %348 = select <4 x i1> %347, <4 x i32> %346, <4 x i32> %345
  %349 = add nuw <4 x i32> %348, <i32 32, i32 32, i32 32, i32 32>
  %350 = lshr <4 x i32> %349, <i32 6, i32 6, i32 6, i32 6>
  %351 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %340, <4 x i32> %350) #5
  %352 = lshr <8 x i16> %351, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %353 = getelementptr inbounds i16, i16* %9, i64 88
  %354 = bitcast i16* %353 to <8 x i16>*
  %355 = load <8 x i16>, <8 x i16>* %354, align 16
  %356 = getelementptr inbounds i16, i16* %10, i64 88
  %357 = bitcast i16* %356 to <8 x i16>*
  %358 = load <8 x i16>, <8 x i16>* %357, align 16
  %359 = shufflevector <8 x i16> %355, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %360 = zext <4 x i16> %359 to <4 x i32>
  %361 = shufflevector <8 x i16> %358, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %362 = zext <4 x i16> %361 to <4 x i32>
  %363 = sub nsw <4 x i32> %360, %362
  %364 = sub nsw <4 x i32> zeroinitializer, %363
  %365 = icmp slt <4 x i32> %363, zeroinitializer
  %366 = select <4 x i1> %365, <4 x i32> %364, <4 x i32> %363
  %367 = add nuw nsw <4 x i32> %366, <i32 32, i32 32, i32 32, i32 32>
  %368 = lshr <4 x i32> %367, <i32 6, i32 6, i32 6, i32 6>
  %369 = shufflevector <8 x i16> %355, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %370 = shufflevector <8 x i16> %358, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %371 = bitcast <8 x i16> %369 to <4 x i32>
  %372 = bitcast <8 x i16> %370 to <4 x i32>
  %373 = sub <4 x i32> %371, %372
  %374 = sub <4 x i32> zeroinitializer, %373
  %375 = icmp slt <4 x i32> %373, zeroinitializer
  %376 = select <4 x i1> %375, <4 x i32> %374, <4 x i32> %373
  %377 = add nuw <4 x i32> %376, <i32 32, i32 32, i32 32, i32 32>
  %378 = lshr <4 x i32> %377, <i32 6, i32 6, i32 6, i32 6>
  %379 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %368, <4 x i32> %378) #5
  %380 = lshr <8 x i16> %379, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %381 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %352, <8 x i16> %380) #5
  %382 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %381, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %383 = icmp slt <16 x i8> %382, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %384 = select <16 x i1> %383, <16 x i8> %382, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %385 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %384
  %386 = bitcast i8* %326 to <16 x i8>*
  store <16 x i8> %385, <16 x i8>* %386, align 16
  %387 = getelementptr inbounds i16, i16* %9, i64 96
  %388 = getelementptr inbounds i16, i16* %10, i64 96
  %389 = getelementptr inbounds i8, i8* %263, i64 32
  %390 = bitcast i16* %387 to <8 x i16>*
  %391 = load <8 x i16>, <8 x i16>* %390, align 16
  %392 = bitcast i16* %388 to <8 x i16>*
  %393 = load <8 x i16>, <8 x i16>* %392, align 16
  %394 = shufflevector <8 x i16> %391, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %395 = zext <4 x i16> %394 to <4 x i32>
  %396 = shufflevector <8 x i16> %393, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %397 = zext <4 x i16> %396 to <4 x i32>
  %398 = sub nsw <4 x i32> %395, %397
  %399 = sub nsw <4 x i32> zeroinitializer, %398
  %400 = icmp slt <4 x i32> %398, zeroinitializer
  %401 = select <4 x i1> %400, <4 x i32> %399, <4 x i32> %398
  %402 = add nuw nsw <4 x i32> %401, <i32 32, i32 32, i32 32, i32 32>
  %403 = lshr <4 x i32> %402, <i32 6, i32 6, i32 6, i32 6>
  %404 = shufflevector <8 x i16> %391, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %405 = shufflevector <8 x i16> %393, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %406 = bitcast <8 x i16> %404 to <4 x i32>
  %407 = bitcast <8 x i16> %405 to <4 x i32>
  %408 = sub <4 x i32> %406, %407
  %409 = sub <4 x i32> zeroinitializer, %408
  %410 = icmp slt <4 x i32> %408, zeroinitializer
  %411 = select <4 x i1> %410, <4 x i32> %409, <4 x i32> %408
  %412 = add nuw <4 x i32> %411, <i32 32, i32 32, i32 32, i32 32>
  %413 = lshr <4 x i32> %412, <i32 6, i32 6, i32 6, i32 6>
  %414 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %403, <4 x i32> %413) #5
  %415 = lshr <8 x i16> %414, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %416 = getelementptr inbounds i16, i16* %9, i64 104
  %417 = bitcast i16* %416 to <8 x i16>*
  %418 = load <8 x i16>, <8 x i16>* %417, align 16
  %419 = getelementptr inbounds i16, i16* %10, i64 104
  %420 = bitcast i16* %419 to <8 x i16>*
  %421 = load <8 x i16>, <8 x i16>* %420, align 16
  %422 = shufflevector <8 x i16> %418, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %423 = zext <4 x i16> %422 to <4 x i32>
  %424 = shufflevector <8 x i16> %421, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %425 = zext <4 x i16> %424 to <4 x i32>
  %426 = sub nsw <4 x i32> %423, %425
  %427 = sub nsw <4 x i32> zeroinitializer, %426
  %428 = icmp slt <4 x i32> %426, zeroinitializer
  %429 = select <4 x i1> %428, <4 x i32> %427, <4 x i32> %426
  %430 = add nuw nsw <4 x i32> %429, <i32 32, i32 32, i32 32, i32 32>
  %431 = lshr <4 x i32> %430, <i32 6, i32 6, i32 6, i32 6>
  %432 = shufflevector <8 x i16> %418, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %433 = shufflevector <8 x i16> %421, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %434 = bitcast <8 x i16> %432 to <4 x i32>
  %435 = bitcast <8 x i16> %433 to <4 x i32>
  %436 = sub <4 x i32> %434, %435
  %437 = sub <4 x i32> zeroinitializer, %436
  %438 = icmp slt <4 x i32> %436, zeroinitializer
  %439 = select <4 x i1> %438, <4 x i32> %437, <4 x i32> %436
  %440 = add nuw <4 x i32> %439, <i32 32, i32 32, i32 32, i32 32>
  %441 = lshr <4 x i32> %440, <i32 6, i32 6, i32 6, i32 6>
  %442 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %431, <4 x i32> %441) #5
  %443 = lshr <8 x i16> %442, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %444 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %415, <8 x i16> %443) #5
  %445 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %444, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %446 = icmp slt <16 x i8> %445, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %447 = select <16 x i1> %446, <16 x i8> %445, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %448 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %447
  %449 = bitcast i8* %389 to <16 x i8>*
  store <16 x i8> %448, <16 x i8>* %449, align 16
  %450 = getelementptr inbounds i16, i16* %9, i64 112
  %451 = getelementptr inbounds i16, i16* %10, i64 112
  %452 = getelementptr inbounds i8, i8* %263, i64 48
  %453 = bitcast i16* %450 to <8 x i16>*
  %454 = load <8 x i16>, <8 x i16>* %453, align 16
  %455 = bitcast i16* %451 to <8 x i16>*
  %456 = load <8 x i16>, <8 x i16>* %455, align 16
  %457 = shufflevector <8 x i16> %454, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %458 = zext <4 x i16> %457 to <4 x i32>
  %459 = shufflevector <8 x i16> %456, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %460 = zext <4 x i16> %459 to <4 x i32>
  %461 = sub nsw <4 x i32> %458, %460
  %462 = sub nsw <4 x i32> zeroinitializer, %461
  %463 = icmp slt <4 x i32> %461, zeroinitializer
  %464 = select <4 x i1> %463, <4 x i32> %462, <4 x i32> %461
  %465 = add nuw nsw <4 x i32> %464, <i32 32, i32 32, i32 32, i32 32>
  %466 = lshr <4 x i32> %465, <i32 6, i32 6, i32 6, i32 6>
  %467 = shufflevector <8 x i16> %454, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %468 = shufflevector <8 x i16> %456, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %469 = bitcast <8 x i16> %467 to <4 x i32>
  %470 = bitcast <8 x i16> %468 to <4 x i32>
  %471 = sub <4 x i32> %469, %470
  %472 = sub <4 x i32> zeroinitializer, %471
  %473 = icmp slt <4 x i32> %471, zeroinitializer
  %474 = select <4 x i1> %473, <4 x i32> %472, <4 x i32> %471
  %475 = add nuw <4 x i32> %474, <i32 32, i32 32, i32 32, i32 32>
  %476 = lshr <4 x i32> %475, <i32 6, i32 6, i32 6, i32 6>
  %477 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %466, <4 x i32> %476) #5
  %478 = lshr <8 x i16> %477, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %479 = getelementptr inbounds i16, i16* %9, i64 120
  %480 = bitcast i16* %479 to <8 x i16>*
  %481 = load <8 x i16>, <8 x i16>* %480, align 16
  %482 = getelementptr inbounds i16, i16* %10, i64 120
  %483 = bitcast i16* %482 to <8 x i16>*
  %484 = load <8 x i16>, <8 x i16>* %483, align 16
  %485 = shufflevector <8 x i16> %481, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %486 = zext <4 x i16> %485 to <4 x i32>
  %487 = shufflevector <8 x i16> %484, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %488 = zext <4 x i16> %487 to <4 x i32>
  %489 = sub nsw <4 x i32> %486, %488
  %490 = sub nsw <4 x i32> zeroinitializer, %489
  %491 = icmp slt <4 x i32> %489, zeroinitializer
  %492 = select <4 x i1> %491, <4 x i32> %490, <4 x i32> %489
  %493 = add nuw nsw <4 x i32> %492, <i32 32, i32 32, i32 32, i32 32>
  %494 = lshr <4 x i32> %493, <i32 6, i32 6, i32 6, i32 6>
  %495 = shufflevector <8 x i16> %481, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %496 = shufflevector <8 x i16> %484, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %497 = bitcast <8 x i16> %495 to <4 x i32>
  %498 = bitcast <8 x i16> %496 to <4 x i32>
  %499 = sub <4 x i32> %497, %498
  %500 = sub <4 x i32> zeroinitializer, %499
  %501 = icmp slt <4 x i32> %499, zeroinitializer
  %502 = select <4 x i1> %501, <4 x i32> %500, <4 x i32> %499
  %503 = add nuw <4 x i32> %502, <i32 32, i32 32, i32 32, i32 32>
  %504 = lshr <4 x i32> %503, <i32 6, i32 6, i32 6, i32 6>
  %505 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %494, <4 x i32> %504) #5
  %506 = lshr <8 x i16> %505, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %507 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %478, <8 x i16> %506) #5
  %508 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %507, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %509 = icmp slt <16 x i8> %508, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %510 = select <16 x i1> %509, <16 x i8> %508, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %511 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %510
  %512 = bitcast i8* %452 to <16 x i8>*
  store <16 x i8> %511, <16 x i8>* %512, align 16
  %513 = getelementptr inbounds i16, i16* %9, i64 128
  %514 = getelementptr inbounds i16, i16* %10, i64 128
  %515 = getelementptr inbounds i8, i8* %263, i64 %3
  %516 = bitcast i16* %513 to <8 x i16>*
  %517 = load <8 x i16>, <8 x i16>* %516, align 16
  %518 = bitcast i16* %514 to <8 x i16>*
  %519 = load <8 x i16>, <8 x i16>* %518, align 16
  %520 = shufflevector <8 x i16> %517, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %521 = zext <4 x i16> %520 to <4 x i32>
  %522 = shufflevector <8 x i16> %519, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %523 = zext <4 x i16> %522 to <4 x i32>
  %524 = sub nsw <4 x i32> %521, %523
  %525 = sub nsw <4 x i32> zeroinitializer, %524
  %526 = icmp slt <4 x i32> %524, zeroinitializer
  %527 = select <4 x i1> %526, <4 x i32> %525, <4 x i32> %524
  %528 = add nuw nsw <4 x i32> %527, <i32 32, i32 32, i32 32, i32 32>
  %529 = lshr <4 x i32> %528, <i32 6, i32 6, i32 6, i32 6>
  %530 = shufflevector <8 x i16> %517, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %531 = shufflevector <8 x i16> %519, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %532 = bitcast <8 x i16> %530 to <4 x i32>
  %533 = bitcast <8 x i16> %531 to <4 x i32>
  %534 = sub <4 x i32> %532, %533
  %535 = sub <4 x i32> zeroinitializer, %534
  %536 = icmp slt <4 x i32> %534, zeroinitializer
  %537 = select <4 x i1> %536, <4 x i32> %535, <4 x i32> %534
  %538 = add nuw <4 x i32> %537, <i32 32, i32 32, i32 32, i32 32>
  %539 = lshr <4 x i32> %538, <i32 6, i32 6, i32 6, i32 6>
  %540 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %529, <4 x i32> %539) #5
  %541 = lshr <8 x i16> %540, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %542 = getelementptr inbounds i16, i16* %9, i64 136
  %543 = bitcast i16* %542 to <8 x i16>*
  %544 = load <8 x i16>, <8 x i16>* %543, align 16
  %545 = getelementptr inbounds i16, i16* %10, i64 136
  %546 = bitcast i16* %545 to <8 x i16>*
  %547 = load <8 x i16>, <8 x i16>* %546, align 16
  %548 = shufflevector <8 x i16> %544, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %549 = zext <4 x i16> %548 to <4 x i32>
  %550 = shufflevector <8 x i16> %547, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %551 = zext <4 x i16> %550 to <4 x i32>
  %552 = sub nsw <4 x i32> %549, %551
  %553 = sub nsw <4 x i32> zeroinitializer, %552
  %554 = icmp slt <4 x i32> %552, zeroinitializer
  %555 = select <4 x i1> %554, <4 x i32> %553, <4 x i32> %552
  %556 = add nuw nsw <4 x i32> %555, <i32 32, i32 32, i32 32, i32 32>
  %557 = lshr <4 x i32> %556, <i32 6, i32 6, i32 6, i32 6>
  %558 = shufflevector <8 x i16> %544, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %559 = shufflevector <8 x i16> %547, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %560 = bitcast <8 x i16> %558 to <4 x i32>
  %561 = bitcast <8 x i16> %559 to <4 x i32>
  %562 = sub <4 x i32> %560, %561
  %563 = sub <4 x i32> zeroinitializer, %562
  %564 = icmp slt <4 x i32> %562, zeroinitializer
  %565 = select <4 x i1> %564, <4 x i32> %563, <4 x i32> %562
  %566 = add nuw <4 x i32> %565, <i32 32, i32 32, i32 32, i32 32>
  %567 = lshr <4 x i32> %566, <i32 6, i32 6, i32 6, i32 6>
  %568 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %557, <4 x i32> %567) #5
  %569 = lshr <8 x i16> %568, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %570 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %541, <8 x i16> %569) #5
  %571 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %570, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %572 = icmp slt <16 x i8> %571, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %573 = select <16 x i1> %572, <16 x i8> %571, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %574 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %573
  %575 = bitcast i8* %515 to <16 x i8>*
  store <16 x i8> %574, <16 x i8>* %575, align 16
  %576 = getelementptr inbounds i16, i16* %9, i64 144
  %577 = getelementptr inbounds i16, i16* %10, i64 144
  %578 = getelementptr inbounds i8, i8* %515, i64 16
  %579 = bitcast i16* %576 to <8 x i16>*
  %580 = load <8 x i16>, <8 x i16>* %579, align 16
  %581 = bitcast i16* %577 to <8 x i16>*
  %582 = load <8 x i16>, <8 x i16>* %581, align 16
  %583 = shufflevector <8 x i16> %580, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %584 = zext <4 x i16> %583 to <4 x i32>
  %585 = shufflevector <8 x i16> %582, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %586 = zext <4 x i16> %585 to <4 x i32>
  %587 = sub nsw <4 x i32> %584, %586
  %588 = sub nsw <4 x i32> zeroinitializer, %587
  %589 = icmp slt <4 x i32> %587, zeroinitializer
  %590 = select <4 x i1> %589, <4 x i32> %588, <4 x i32> %587
  %591 = add nuw nsw <4 x i32> %590, <i32 32, i32 32, i32 32, i32 32>
  %592 = lshr <4 x i32> %591, <i32 6, i32 6, i32 6, i32 6>
  %593 = shufflevector <8 x i16> %580, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %594 = shufflevector <8 x i16> %582, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %595 = bitcast <8 x i16> %593 to <4 x i32>
  %596 = bitcast <8 x i16> %594 to <4 x i32>
  %597 = sub <4 x i32> %595, %596
  %598 = sub <4 x i32> zeroinitializer, %597
  %599 = icmp slt <4 x i32> %597, zeroinitializer
  %600 = select <4 x i1> %599, <4 x i32> %598, <4 x i32> %597
  %601 = add nuw <4 x i32> %600, <i32 32, i32 32, i32 32, i32 32>
  %602 = lshr <4 x i32> %601, <i32 6, i32 6, i32 6, i32 6>
  %603 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %592, <4 x i32> %602) #5
  %604 = lshr <8 x i16> %603, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %605 = getelementptr inbounds i16, i16* %9, i64 152
  %606 = bitcast i16* %605 to <8 x i16>*
  %607 = load <8 x i16>, <8 x i16>* %606, align 16
  %608 = getelementptr inbounds i16, i16* %10, i64 152
  %609 = bitcast i16* %608 to <8 x i16>*
  %610 = load <8 x i16>, <8 x i16>* %609, align 16
  %611 = shufflevector <8 x i16> %607, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %612 = zext <4 x i16> %611 to <4 x i32>
  %613 = shufflevector <8 x i16> %610, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %614 = zext <4 x i16> %613 to <4 x i32>
  %615 = sub nsw <4 x i32> %612, %614
  %616 = sub nsw <4 x i32> zeroinitializer, %615
  %617 = icmp slt <4 x i32> %615, zeroinitializer
  %618 = select <4 x i1> %617, <4 x i32> %616, <4 x i32> %615
  %619 = add nuw nsw <4 x i32> %618, <i32 32, i32 32, i32 32, i32 32>
  %620 = lshr <4 x i32> %619, <i32 6, i32 6, i32 6, i32 6>
  %621 = shufflevector <8 x i16> %607, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %622 = shufflevector <8 x i16> %610, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %623 = bitcast <8 x i16> %621 to <4 x i32>
  %624 = bitcast <8 x i16> %622 to <4 x i32>
  %625 = sub <4 x i32> %623, %624
  %626 = sub <4 x i32> zeroinitializer, %625
  %627 = icmp slt <4 x i32> %625, zeroinitializer
  %628 = select <4 x i1> %627, <4 x i32> %626, <4 x i32> %625
  %629 = add nuw <4 x i32> %628, <i32 32, i32 32, i32 32, i32 32>
  %630 = lshr <4 x i32> %629, <i32 6, i32 6, i32 6, i32 6>
  %631 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %620, <4 x i32> %630) #5
  %632 = lshr <8 x i16> %631, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %633 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %604, <8 x i16> %632) #5
  %634 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %633, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %635 = icmp slt <16 x i8> %634, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %636 = select <16 x i1> %635, <16 x i8> %634, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %637 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %636
  %638 = bitcast i8* %578 to <16 x i8>*
  store <16 x i8> %637, <16 x i8>* %638, align 16
  %639 = getelementptr inbounds i16, i16* %9, i64 160
  %640 = getelementptr inbounds i16, i16* %10, i64 160
  %641 = getelementptr inbounds i8, i8* %515, i64 32
  %642 = bitcast i16* %639 to <8 x i16>*
  %643 = load <8 x i16>, <8 x i16>* %642, align 16
  %644 = bitcast i16* %640 to <8 x i16>*
  %645 = load <8 x i16>, <8 x i16>* %644, align 16
  %646 = shufflevector <8 x i16> %643, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %647 = zext <4 x i16> %646 to <4 x i32>
  %648 = shufflevector <8 x i16> %645, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %649 = zext <4 x i16> %648 to <4 x i32>
  %650 = sub nsw <4 x i32> %647, %649
  %651 = sub nsw <4 x i32> zeroinitializer, %650
  %652 = icmp slt <4 x i32> %650, zeroinitializer
  %653 = select <4 x i1> %652, <4 x i32> %651, <4 x i32> %650
  %654 = add nuw nsw <4 x i32> %653, <i32 32, i32 32, i32 32, i32 32>
  %655 = lshr <4 x i32> %654, <i32 6, i32 6, i32 6, i32 6>
  %656 = shufflevector <8 x i16> %643, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %657 = shufflevector <8 x i16> %645, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %658 = bitcast <8 x i16> %656 to <4 x i32>
  %659 = bitcast <8 x i16> %657 to <4 x i32>
  %660 = sub <4 x i32> %658, %659
  %661 = sub <4 x i32> zeroinitializer, %660
  %662 = icmp slt <4 x i32> %660, zeroinitializer
  %663 = select <4 x i1> %662, <4 x i32> %661, <4 x i32> %660
  %664 = add nuw <4 x i32> %663, <i32 32, i32 32, i32 32, i32 32>
  %665 = lshr <4 x i32> %664, <i32 6, i32 6, i32 6, i32 6>
  %666 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %655, <4 x i32> %665) #5
  %667 = lshr <8 x i16> %666, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %668 = getelementptr inbounds i16, i16* %9, i64 168
  %669 = bitcast i16* %668 to <8 x i16>*
  %670 = load <8 x i16>, <8 x i16>* %669, align 16
  %671 = getelementptr inbounds i16, i16* %10, i64 168
  %672 = bitcast i16* %671 to <8 x i16>*
  %673 = load <8 x i16>, <8 x i16>* %672, align 16
  %674 = shufflevector <8 x i16> %670, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %675 = zext <4 x i16> %674 to <4 x i32>
  %676 = shufflevector <8 x i16> %673, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %677 = zext <4 x i16> %676 to <4 x i32>
  %678 = sub nsw <4 x i32> %675, %677
  %679 = sub nsw <4 x i32> zeroinitializer, %678
  %680 = icmp slt <4 x i32> %678, zeroinitializer
  %681 = select <4 x i1> %680, <4 x i32> %679, <4 x i32> %678
  %682 = add nuw nsw <4 x i32> %681, <i32 32, i32 32, i32 32, i32 32>
  %683 = lshr <4 x i32> %682, <i32 6, i32 6, i32 6, i32 6>
  %684 = shufflevector <8 x i16> %670, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %685 = shufflevector <8 x i16> %673, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %686 = bitcast <8 x i16> %684 to <4 x i32>
  %687 = bitcast <8 x i16> %685 to <4 x i32>
  %688 = sub <4 x i32> %686, %687
  %689 = sub <4 x i32> zeroinitializer, %688
  %690 = icmp slt <4 x i32> %688, zeroinitializer
  %691 = select <4 x i1> %690, <4 x i32> %689, <4 x i32> %688
  %692 = add nuw <4 x i32> %691, <i32 32, i32 32, i32 32, i32 32>
  %693 = lshr <4 x i32> %692, <i32 6, i32 6, i32 6, i32 6>
  %694 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %683, <4 x i32> %693) #5
  %695 = lshr <8 x i16> %694, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %696 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %667, <8 x i16> %695) #5
  %697 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %696, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %698 = icmp slt <16 x i8> %697, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %699 = select <16 x i1> %698, <16 x i8> %697, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %700 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %699
  %701 = bitcast i8* %641 to <16 x i8>*
  store <16 x i8> %700, <16 x i8>* %701, align 16
  %702 = getelementptr inbounds i16, i16* %9, i64 176
  %703 = getelementptr inbounds i16, i16* %10, i64 176
  %704 = getelementptr inbounds i8, i8* %515, i64 48
  %705 = bitcast i16* %702 to <8 x i16>*
  %706 = load <8 x i16>, <8 x i16>* %705, align 16
  %707 = bitcast i16* %703 to <8 x i16>*
  %708 = load <8 x i16>, <8 x i16>* %707, align 16
  %709 = shufflevector <8 x i16> %706, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %710 = zext <4 x i16> %709 to <4 x i32>
  %711 = shufflevector <8 x i16> %708, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %712 = zext <4 x i16> %711 to <4 x i32>
  %713 = sub nsw <4 x i32> %710, %712
  %714 = sub nsw <4 x i32> zeroinitializer, %713
  %715 = icmp slt <4 x i32> %713, zeroinitializer
  %716 = select <4 x i1> %715, <4 x i32> %714, <4 x i32> %713
  %717 = add nuw nsw <4 x i32> %716, <i32 32, i32 32, i32 32, i32 32>
  %718 = lshr <4 x i32> %717, <i32 6, i32 6, i32 6, i32 6>
  %719 = shufflevector <8 x i16> %706, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %720 = shufflevector <8 x i16> %708, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %721 = bitcast <8 x i16> %719 to <4 x i32>
  %722 = bitcast <8 x i16> %720 to <4 x i32>
  %723 = sub <4 x i32> %721, %722
  %724 = sub <4 x i32> zeroinitializer, %723
  %725 = icmp slt <4 x i32> %723, zeroinitializer
  %726 = select <4 x i1> %725, <4 x i32> %724, <4 x i32> %723
  %727 = add nuw <4 x i32> %726, <i32 32, i32 32, i32 32, i32 32>
  %728 = lshr <4 x i32> %727, <i32 6, i32 6, i32 6, i32 6>
  %729 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %718, <4 x i32> %728) #5
  %730 = lshr <8 x i16> %729, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %731 = getelementptr inbounds i16, i16* %9, i64 184
  %732 = bitcast i16* %731 to <8 x i16>*
  %733 = load <8 x i16>, <8 x i16>* %732, align 16
  %734 = getelementptr inbounds i16, i16* %10, i64 184
  %735 = bitcast i16* %734 to <8 x i16>*
  %736 = load <8 x i16>, <8 x i16>* %735, align 16
  %737 = shufflevector <8 x i16> %733, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %738 = zext <4 x i16> %737 to <4 x i32>
  %739 = shufflevector <8 x i16> %736, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %740 = zext <4 x i16> %739 to <4 x i32>
  %741 = sub nsw <4 x i32> %738, %740
  %742 = sub nsw <4 x i32> zeroinitializer, %741
  %743 = icmp slt <4 x i32> %741, zeroinitializer
  %744 = select <4 x i1> %743, <4 x i32> %742, <4 x i32> %741
  %745 = add nuw nsw <4 x i32> %744, <i32 32, i32 32, i32 32, i32 32>
  %746 = lshr <4 x i32> %745, <i32 6, i32 6, i32 6, i32 6>
  %747 = shufflevector <8 x i16> %733, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %748 = shufflevector <8 x i16> %736, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %749 = bitcast <8 x i16> %747 to <4 x i32>
  %750 = bitcast <8 x i16> %748 to <4 x i32>
  %751 = sub <4 x i32> %749, %750
  %752 = sub <4 x i32> zeroinitializer, %751
  %753 = icmp slt <4 x i32> %751, zeroinitializer
  %754 = select <4 x i1> %753, <4 x i32> %752, <4 x i32> %751
  %755 = add nuw <4 x i32> %754, <i32 32, i32 32, i32 32, i32 32>
  %756 = lshr <4 x i32> %755, <i32 6, i32 6, i32 6, i32 6>
  %757 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %746, <4 x i32> %756) #5
  %758 = lshr <8 x i16> %757, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %759 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %730, <8 x i16> %758) #5
  %760 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %759, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %761 = icmp slt <16 x i8> %760, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %762 = select <16 x i1> %761, <16 x i8> %760, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %763 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %762
  %764 = bitcast i8* %704 to <16 x i8>*
  store <16 x i8> %763, <16 x i8>* %764, align 16
  %765 = getelementptr inbounds i16, i16* %9, i64 192
  %766 = getelementptr inbounds i16, i16* %10, i64 192
  %767 = getelementptr inbounds i8, i8* %515, i64 %3
  %768 = add nsw i32 %11, -1
  %769 = icmp eq i32 %768, 0
  br i1 %769, label %770, label %7

770:                                              ; preds = %7
  %771 = bitcast i16* %765 to <8 x i16>*
  %772 = load <8 x i16>, <8 x i16>* %771, align 16
  %773 = bitcast i16* %766 to <8 x i16>*
  %774 = load <8 x i16>, <8 x i16>* %773, align 16
  %775 = shufflevector <8 x i16> %772, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %776 = zext <4 x i16> %775 to <4 x i32>
  %777 = shufflevector <8 x i16> %774, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %778 = zext <4 x i16> %777 to <4 x i32>
  %779 = sub nsw <4 x i32> %776, %778
  %780 = sub nsw <4 x i32> zeroinitializer, %779
  %781 = icmp slt <4 x i32> %779, zeroinitializer
  %782 = select <4 x i1> %781, <4 x i32> %780, <4 x i32> %779
  %783 = add nuw nsw <4 x i32> %782, <i32 32, i32 32, i32 32, i32 32>
  %784 = lshr <4 x i32> %783, <i32 6, i32 6, i32 6, i32 6>
  %785 = shufflevector <8 x i16> %772, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %786 = shufflevector <8 x i16> %774, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %787 = bitcast <8 x i16> %785 to <4 x i32>
  %788 = bitcast <8 x i16> %786 to <4 x i32>
  %789 = sub <4 x i32> %787, %788
  %790 = sub <4 x i32> zeroinitializer, %789
  %791 = icmp slt <4 x i32> %789, zeroinitializer
  %792 = select <4 x i1> %791, <4 x i32> %790, <4 x i32> %789
  %793 = add nuw <4 x i32> %792, <i32 32, i32 32, i32 32, i32 32>
  %794 = lshr <4 x i32> %793, <i32 6, i32 6, i32 6, i32 6>
  %795 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %784, <4 x i32> %794) #5
  %796 = lshr <8 x i16> %795, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %797 = getelementptr inbounds i16, i16* %9, i64 200
  %798 = bitcast i16* %797 to <8 x i16>*
  %799 = load <8 x i16>, <8 x i16>* %798, align 16
  %800 = getelementptr inbounds i16, i16* %10, i64 200
  %801 = bitcast i16* %800 to <8 x i16>*
  %802 = load <8 x i16>, <8 x i16>* %801, align 16
  %803 = shufflevector <8 x i16> %799, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %804 = zext <4 x i16> %803 to <4 x i32>
  %805 = shufflevector <8 x i16> %802, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %806 = zext <4 x i16> %805 to <4 x i32>
  %807 = sub nsw <4 x i32> %804, %806
  %808 = sub nsw <4 x i32> zeroinitializer, %807
  %809 = icmp slt <4 x i32> %807, zeroinitializer
  %810 = select <4 x i1> %809, <4 x i32> %808, <4 x i32> %807
  %811 = add nuw nsw <4 x i32> %810, <i32 32, i32 32, i32 32, i32 32>
  %812 = lshr <4 x i32> %811, <i32 6, i32 6, i32 6, i32 6>
  %813 = shufflevector <8 x i16> %799, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %814 = shufflevector <8 x i16> %802, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %815 = bitcast <8 x i16> %813 to <4 x i32>
  %816 = bitcast <8 x i16> %814 to <4 x i32>
  %817 = sub <4 x i32> %815, %816
  %818 = sub <4 x i32> zeroinitializer, %817
  %819 = icmp slt <4 x i32> %817, zeroinitializer
  %820 = select <4 x i1> %819, <4 x i32> %818, <4 x i32> %817
  %821 = add nuw <4 x i32> %820, <i32 32, i32 32, i32 32, i32 32>
  %822 = lshr <4 x i32> %821, <i32 6, i32 6, i32 6, i32 6>
  %823 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %812, <4 x i32> %822) #5
  %824 = lshr <8 x i16> %823, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %825 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %796, <8 x i16> %824) #5
  %826 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %825, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %827 = icmp slt <16 x i8> %826, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %828 = select <16 x i1> %827, <16 x i8> %826, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %829 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %828
  %830 = bitcast i8* %767 to <16 x i8>*
  store <16 x i8> %829, <16 x i8>* %830, align 16
  %831 = getelementptr inbounds i16, i16* %9, i64 208
  %832 = getelementptr inbounds i16, i16* %10, i64 208
  %833 = getelementptr inbounds i8, i8* %767, i64 16
  %834 = bitcast i16* %831 to <8 x i16>*
  %835 = load <8 x i16>, <8 x i16>* %834, align 16
  %836 = bitcast i16* %832 to <8 x i16>*
  %837 = load <8 x i16>, <8 x i16>* %836, align 16
  %838 = shufflevector <8 x i16> %835, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %839 = zext <4 x i16> %838 to <4 x i32>
  %840 = shufflevector <8 x i16> %837, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %841 = zext <4 x i16> %840 to <4 x i32>
  %842 = sub nsw <4 x i32> %839, %841
  %843 = sub nsw <4 x i32> zeroinitializer, %842
  %844 = icmp slt <4 x i32> %842, zeroinitializer
  %845 = select <4 x i1> %844, <4 x i32> %843, <4 x i32> %842
  %846 = add nuw nsw <4 x i32> %845, <i32 32, i32 32, i32 32, i32 32>
  %847 = lshr <4 x i32> %846, <i32 6, i32 6, i32 6, i32 6>
  %848 = shufflevector <8 x i16> %835, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %849 = shufflevector <8 x i16> %837, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %850 = bitcast <8 x i16> %848 to <4 x i32>
  %851 = bitcast <8 x i16> %849 to <4 x i32>
  %852 = sub <4 x i32> %850, %851
  %853 = sub <4 x i32> zeroinitializer, %852
  %854 = icmp slt <4 x i32> %852, zeroinitializer
  %855 = select <4 x i1> %854, <4 x i32> %853, <4 x i32> %852
  %856 = add nuw <4 x i32> %855, <i32 32, i32 32, i32 32, i32 32>
  %857 = lshr <4 x i32> %856, <i32 6, i32 6, i32 6, i32 6>
  %858 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %847, <4 x i32> %857) #5
  %859 = lshr <8 x i16> %858, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %860 = getelementptr inbounds i16, i16* %9, i64 216
  %861 = bitcast i16* %860 to <8 x i16>*
  %862 = load <8 x i16>, <8 x i16>* %861, align 16
  %863 = getelementptr inbounds i16, i16* %10, i64 216
  %864 = bitcast i16* %863 to <8 x i16>*
  %865 = load <8 x i16>, <8 x i16>* %864, align 16
  %866 = shufflevector <8 x i16> %862, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %867 = zext <4 x i16> %866 to <4 x i32>
  %868 = shufflevector <8 x i16> %865, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %869 = zext <4 x i16> %868 to <4 x i32>
  %870 = sub nsw <4 x i32> %867, %869
  %871 = sub nsw <4 x i32> zeroinitializer, %870
  %872 = icmp slt <4 x i32> %870, zeroinitializer
  %873 = select <4 x i1> %872, <4 x i32> %871, <4 x i32> %870
  %874 = add nuw nsw <4 x i32> %873, <i32 32, i32 32, i32 32, i32 32>
  %875 = lshr <4 x i32> %874, <i32 6, i32 6, i32 6, i32 6>
  %876 = shufflevector <8 x i16> %862, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %877 = shufflevector <8 x i16> %865, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %878 = bitcast <8 x i16> %876 to <4 x i32>
  %879 = bitcast <8 x i16> %877 to <4 x i32>
  %880 = sub <4 x i32> %878, %879
  %881 = sub <4 x i32> zeroinitializer, %880
  %882 = icmp slt <4 x i32> %880, zeroinitializer
  %883 = select <4 x i1> %882, <4 x i32> %881, <4 x i32> %880
  %884 = add nuw <4 x i32> %883, <i32 32, i32 32, i32 32, i32 32>
  %885 = lshr <4 x i32> %884, <i32 6, i32 6, i32 6, i32 6>
  %886 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %875, <4 x i32> %885) #5
  %887 = lshr <8 x i16> %886, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %888 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %859, <8 x i16> %887) #5
  %889 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %888, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %890 = icmp slt <16 x i8> %889, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %891 = select <16 x i1> %890, <16 x i8> %889, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %892 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %891
  %893 = bitcast i8* %833 to <16 x i8>*
  store <16 x i8> %892, <16 x i8>* %893, align 16
  %894 = getelementptr inbounds i16, i16* %9, i64 224
  %895 = getelementptr inbounds i16, i16* %10, i64 224
  %896 = getelementptr inbounds i8, i8* %767, i64 32
  %897 = bitcast i16* %894 to <8 x i16>*
  %898 = load <8 x i16>, <8 x i16>* %897, align 16
  %899 = bitcast i16* %895 to <8 x i16>*
  %900 = load <8 x i16>, <8 x i16>* %899, align 16
  %901 = shufflevector <8 x i16> %898, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %902 = zext <4 x i16> %901 to <4 x i32>
  %903 = shufflevector <8 x i16> %900, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %904 = zext <4 x i16> %903 to <4 x i32>
  %905 = sub nsw <4 x i32> %902, %904
  %906 = sub nsw <4 x i32> zeroinitializer, %905
  %907 = icmp slt <4 x i32> %905, zeroinitializer
  %908 = select <4 x i1> %907, <4 x i32> %906, <4 x i32> %905
  %909 = add nuw nsw <4 x i32> %908, <i32 32, i32 32, i32 32, i32 32>
  %910 = lshr <4 x i32> %909, <i32 6, i32 6, i32 6, i32 6>
  %911 = shufflevector <8 x i16> %898, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %912 = shufflevector <8 x i16> %900, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %913 = bitcast <8 x i16> %911 to <4 x i32>
  %914 = bitcast <8 x i16> %912 to <4 x i32>
  %915 = sub <4 x i32> %913, %914
  %916 = sub <4 x i32> zeroinitializer, %915
  %917 = icmp slt <4 x i32> %915, zeroinitializer
  %918 = select <4 x i1> %917, <4 x i32> %916, <4 x i32> %915
  %919 = add nuw <4 x i32> %918, <i32 32, i32 32, i32 32, i32 32>
  %920 = lshr <4 x i32> %919, <i32 6, i32 6, i32 6, i32 6>
  %921 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %910, <4 x i32> %920) #5
  %922 = lshr <8 x i16> %921, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %923 = getelementptr inbounds i16, i16* %9, i64 232
  %924 = bitcast i16* %923 to <8 x i16>*
  %925 = load <8 x i16>, <8 x i16>* %924, align 16
  %926 = getelementptr inbounds i16, i16* %10, i64 232
  %927 = bitcast i16* %926 to <8 x i16>*
  %928 = load <8 x i16>, <8 x i16>* %927, align 16
  %929 = shufflevector <8 x i16> %925, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %930 = zext <4 x i16> %929 to <4 x i32>
  %931 = shufflevector <8 x i16> %928, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %932 = zext <4 x i16> %931 to <4 x i32>
  %933 = sub nsw <4 x i32> %930, %932
  %934 = sub nsw <4 x i32> zeroinitializer, %933
  %935 = icmp slt <4 x i32> %933, zeroinitializer
  %936 = select <4 x i1> %935, <4 x i32> %934, <4 x i32> %933
  %937 = add nuw nsw <4 x i32> %936, <i32 32, i32 32, i32 32, i32 32>
  %938 = lshr <4 x i32> %937, <i32 6, i32 6, i32 6, i32 6>
  %939 = shufflevector <8 x i16> %925, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %940 = shufflevector <8 x i16> %928, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %941 = bitcast <8 x i16> %939 to <4 x i32>
  %942 = bitcast <8 x i16> %940 to <4 x i32>
  %943 = sub <4 x i32> %941, %942
  %944 = sub <4 x i32> zeroinitializer, %943
  %945 = icmp slt <4 x i32> %943, zeroinitializer
  %946 = select <4 x i1> %945, <4 x i32> %944, <4 x i32> %943
  %947 = add nuw <4 x i32> %946, <i32 32, i32 32, i32 32, i32 32>
  %948 = lshr <4 x i32> %947, <i32 6, i32 6, i32 6, i32 6>
  %949 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %938, <4 x i32> %948) #5
  %950 = lshr <8 x i16> %949, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %951 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %922, <8 x i16> %950) #5
  %952 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %951, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %953 = icmp slt <16 x i8> %952, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %954 = select <16 x i1> %953, <16 x i8> %952, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %955 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %954
  %956 = bitcast i8* %896 to <16 x i8>*
  store <16 x i8> %955, <16 x i8>* %956, align 16
  %957 = getelementptr inbounds i16, i16* %9, i64 240
  %958 = getelementptr inbounds i16, i16* %10, i64 240
  %959 = getelementptr inbounds i8, i8* %767, i64 48
  %960 = bitcast i16* %957 to <8 x i16>*
  %961 = load <8 x i16>, <8 x i16>* %960, align 16
  %962 = bitcast i16* %958 to <8 x i16>*
  %963 = load <8 x i16>, <8 x i16>* %962, align 16
  %964 = shufflevector <8 x i16> %961, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %965 = zext <4 x i16> %964 to <4 x i32>
  %966 = shufflevector <8 x i16> %963, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %967 = zext <4 x i16> %966 to <4 x i32>
  %968 = sub nsw <4 x i32> %965, %967
  %969 = sub nsw <4 x i32> zeroinitializer, %968
  %970 = icmp slt <4 x i32> %968, zeroinitializer
  %971 = select <4 x i1> %970, <4 x i32> %969, <4 x i32> %968
  %972 = add nuw nsw <4 x i32> %971, <i32 32, i32 32, i32 32, i32 32>
  %973 = lshr <4 x i32> %972, <i32 6, i32 6, i32 6, i32 6>
  %974 = shufflevector <8 x i16> %961, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %975 = shufflevector <8 x i16> %963, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %976 = bitcast <8 x i16> %974 to <4 x i32>
  %977 = bitcast <8 x i16> %975 to <4 x i32>
  %978 = sub <4 x i32> %976, %977
  %979 = sub <4 x i32> zeroinitializer, %978
  %980 = icmp slt <4 x i32> %978, zeroinitializer
  %981 = select <4 x i1> %980, <4 x i32> %979, <4 x i32> %978
  %982 = add nuw <4 x i32> %981, <i32 32, i32 32, i32 32, i32 32>
  %983 = lshr <4 x i32> %982, <i32 6, i32 6, i32 6, i32 6>
  %984 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %973, <4 x i32> %983) #5
  %985 = lshr <8 x i16> %984, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %986 = getelementptr inbounds i16, i16* %9, i64 248
  %987 = bitcast i16* %986 to <8 x i16>*
  %988 = load <8 x i16>, <8 x i16>* %987, align 16
  %989 = getelementptr inbounds i16, i16* %10, i64 248
  %990 = bitcast i16* %989 to <8 x i16>*
  %991 = load <8 x i16>, <8 x i16>* %990, align 16
  %992 = shufflevector <8 x i16> %988, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %993 = zext <4 x i16> %992 to <4 x i32>
  %994 = shufflevector <8 x i16> %991, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %995 = zext <4 x i16> %994 to <4 x i32>
  %996 = sub nsw <4 x i32> %993, %995
  %997 = sub nsw <4 x i32> zeroinitializer, %996
  %998 = icmp slt <4 x i32> %996, zeroinitializer
  %999 = select <4 x i1> %998, <4 x i32> %997, <4 x i32> %996
  %1000 = add nuw nsw <4 x i32> %999, <i32 32, i32 32, i32 32, i32 32>
  %1001 = lshr <4 x i32> %1000, <i32 6, i32 6, i32 6, i32 6>
  %1002 = shufflevector <8 x i16> %988, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1003 = shufflevector <8 x i16> %991, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1004 = bitcast <8 x i16> %1002 to <4 x i32>
  %1005 = bitcast <8 x i16> %1003 to <4 x i32>
  %1006 = sub <4 x i32> %1004, %1005
  %1007 = sub <4 x i32> zeroinitializer, %1006
  %1008 = icmp slt <4 x i32> %1006, zeroinitializer
  %1009 = select <4 x i1> %1008, <4 x i32> %1007, <4 x i32> %1006
  %1010 = add nuw <4 x i32> %1009, <i32 32, i32 32, i32 32, i32 32>
  %1011 = lshr <4 x i32> %1010, <i32 6, i32 6, i32 6, i32 6>
  %1012 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1001, <4 x i32> %1011) #5
  %1013 = lshr <8 x i16> %1012, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1014 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %985, <8 x i16> %1013) #5
  %1015 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1014, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1016 = icmp slt <16 x i8> %1015, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1017 = select <16 x i1> %1016, <16 x i8> %1015, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1018 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1017
  %1019 = bitcast i8* %959 to <16 x i8>*
  store <16 x i8> %1018, <16 x i8>* %1019, align 16
  %1020 = getelementptr inbounds i16, i16* %9, i64 256
  %1021 = getelementptr inbounds i16, i16* %10, i64 256
  %1022 = getelementptr inbounds i8, i8* %767, i64 %3
  %1023 = bitcast i16* %1020 to <8 x i16>*
  %1024 = load <8 x i16>, <8 x i16>* %1023, align 16
  %1025 = bitcast i16* %1021 to <8 x i16>*
  %1026 = load <8 x i16>, <8 x i16>* %1025, align 16
  %1027 = shufflevector <8 x i16> %1024, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1028 = zext <4 x i16> %1027 to <4 x i32>
  %1029 = shufflevector <8 x i16> %1026, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1030 = zext <4 x i16> %1029 to <4 x i32>
  %1031 = sub nsw <4 x i32> %1028, %1030
  %1032 = sub nsw <4 x i32> zeroinitializer, %1031
  %1033 = icmp slt <4 x i32> %1031, zeroinitializer
  %1034 = select <4 x i1> %1033, <4 x i32> %1032, <4 x i32> %1031
  %1035 = add nuw nsw <4 x i32> %1034, <i32 32, i32 32, i32 32, i32 32>
  %1036 = lshr <4 x i32> %1035, <i32 6, i32 6, i32 6, i32 6>
  %1037 = shufflevector <8 x i16> %1024, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1038 = shufflevector <8 x i16> %1026, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1039 = bitcast <8 x i16> %1037 to <4 x i32>
  %1040 = bitcast <8 x i16> %1038 to <4 x i32>
  %1041 = sub <4 x i32> %1039, %1040
  %1042 = sub <4 x i32> zeroinitializer, %1041
  %1043 = icmp slt <4 x i32> %1041, zeroinitializer
  %1044 = select <4 x i1> %1043, <4 x i32> %1042, <4 x i32> %1041
  %1045 = add nuw <4 x i32> %1044, <i32 32, i32 32, i32 32, i32 32>
  %1046 = lshr <4 x i32> %1045, <i32 6, i32 6, i32 6, i32 6>
  %1047 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1036, <4 x i32> %1046) #5
  %1048 = lshr <8 x i16> %1047, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1049 = getelementptr inbounds i16, i16* %9, i64 264
  %1050 = bitcast i16* %1049 to <8 x i16>*
  %1051 = load <8 x i16>, <8 x i16>* %1050, align 16
  %1052 = getelementptr inbounds i16, i16* %10, i64 264
  %1053 = bitcast i16* %1052 to <8 x i16>*
  %1054 = load <8 x i16>, <8 x i16>* %1053, align 16
  %1055 = shufflevector <8 x i16> %1051, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1056 = zext <4 x i16> %1055 to <4 x i32>
  %1057 = shufflevector <8 x i16> %1054, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1058 = zext <4 x i16> %1057 to <4 x i32>
  %1059 = sub nsw <4 x i32> %1056, %1058
  %1060 = sub nsw <4 x i32> zeroinitializer, %1059
  %1061 = icmp slt <4 x i32> %1059, zeroinitializer
  %1062 = select <4 x i1> %1061, <4 x i32> %1060, <4 x i32> %1059
  %1063 = add nuw nsw <4 x i32> %1062, <i32 32, i32 32, i32 32, i32 32>
  %1064 = lshr <4 x i32> %1063, <i32 6, i32 6, i32 6, i32 6>
  %1065 = shufflevector <8 x i16> %1051, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1066 = shufflevector <8 x i16> %1054, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1067 = bitcast <8 x i16> %1065 to <4 x i32>
  %1068 = bitcast <8 x i16> %1066 to <4 x i32>
  %1069 = sub <4 x i32> %1067, %1068
  %1070 = sub <4 x i32> zeroinitializer, %1069
  %1071 = icmp slt <4 x i32> %1069, zeroinitializer
  %1072 = select <4 x i1> %1071, <4 x i32> %1070, <4 x i32> %1069
  %1073 = add nuw <4 x i32> %1072, <i32 32, i32 32, i32 32, i32 32>
  %1074 = lshr <4 x i32> %1073, <i32 6, i32 6, i32 6, i32 6>
  %1075 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1064, <4 x i32> %1074) #5
  %1076 = lshr <8 x i16> %1075, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1077 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1048, <8 x i16> %1076) #5
  %1078 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1077, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1079 = icmp slt <16 x i8> %1078, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1080 = select <16 x i1> %1079, <16 x i8> %1078, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1081 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1080
  %1082 = bitcast i8* %1022 to <16 x i8>*
  store <16 x i8> %1081, <16 x i8>* %1082, align 16
  %1083 = getelementptr inbounds i16, i16* %9, i64 272
  %1084 = getelementptr inbounds i16, i16* %10, i64 272
  %1085 = getelementptr inbounds i8, i8* %1022, i64 16
  %1086 = bitcast i16* %1083 to <8 x i16>*
  %1087 = load <8 x i16>, <8 x i16>* %1086, align 16
  %1088 = bitcast i16* %1084 to <8 x i16>*
  %1089 = load <8 x i16>, <8 x i16>* %1088, align 16
  %1090 = shufflevector <8 x i16> %1087, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1091 = zext <4 x i16> %1090 to <4 x i32>
  %1092 = shufflevector <8 x i16> %1089, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1093 = zext <4 x i16> %1092 to <4 x i32>
  %1094 = sub nsw <4 x i32> %1091, %1093
  %1095 = sub nsw <4 x i32> zeroinitializer, %1094
  %1096 = icmp slt <4 x i32> %1094, zeroinitializer
  %1097 = select <4 x i1> %1096, <4 x i32> %1095, <4 x i32> %1094
  %1098 = add nuw nsw <4 x i32> %1097, <i32 32, i32 32, i32 32, i32 32>
  %1099 = lshr <4 x i32> %1098, <i32 6, i32 6, i32 6, i32 6>
  %1100 = shufflevector <8 x i16> %1087, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1101 = shufflevector <8 x i16> %1089, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1102 = bitcast <8 x i16> %1100 to <4 x i32>
  %1103 = bitcast <8 x i16> %1101 to <4 x i32>
  %1104 = sub <4 x i32> %1102, %1103
  %1105 = sub <4 x i32> zeroinitializer, %1104
  %1106 = icmp slt <4 x i32> %1104, zeroinitializer
  %1107 = select <4 x i1> %1106, <4 x i32> %1105, <4 x i32> %1104
  %1108 = add nuw <4 x i32> %1107, <i32 32, i32 32, i32 32, i32 32>
  %1109 = lshr <4 x i32> %1108, <i32 6, i32 6, i32 6, i32 6>
  %1110 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1099, <4 x i32> %1109) #5
  %1111 = lshr <8 x i16> %1110, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1112 = getelementptr inbounds i16, i16* %9, i64 280
  %1113 = bitcast i16* %1112 to <8 x i16>*
  %1114 = load <8 x i16>, <8 x i16>* %1113, align 16
  %1115 = getelementptr inbounds i16, i16* %10, i64 280
  %1116 = bitcast i16* %1115 to <8 x i16>*
  %1117 = load <8 x i16>, <8 x i16>* %1116, align 16
  %1118 = shufflevector <8 x i16> %1114, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1119 = zext <4 x i16> %1118 to <4 x i32>
  %1120 = shufflevector <8 x i16> %1117, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1121 = zext <4 x i16> %1120 to <4 x i32>
  %1122 = sub nsw <4 x i32> %1119, %1121
  %1123 = sub nsw <4 x i32> zeroinitializer, %1122
  %1124 = icmp slt <4 x i32> %1122, zeroinitializer
  %1125 = select <4 x i1> %1124, <4 x i32> %1123, <4 x i32> %1122
  %1126 = add nuw nsw <4 x i32> %1125, <i32 32, i32 32, i32 32, i32 32>
  %1127 = lshr <4 x i32> %1126, <i32 6, i32 6, i32 6, i32 6>
  %1128 = shufflevector <8 x i16> %1114, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1129 = shufflevector <8 x i16> %1117, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1130 = bitcast <8 x i16> %1128 to <4 x i32>
  %1131 = bitcast <8 x i16> %1129 to <4 x i32>
  %1132 = sub <4 x i32> %1130, %1131
  %1133 = sub <4 x i32> zeroinitializer, %1132
  %1134 = icmp slt <4 x i32> %1132, zeroinitializer
  %1135 = select <4 x i1> %1134, <4 x i32> %1133, <4 x i32> %1132
  %1136 = add nuw <4 x i32> %1135, <i32 32, i32 32, i32 32, i32 32>
  %1137 = lshr <4 x i32> %1136, <i32 6, i32 6, i32 6, i32 6>
  %1138 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1127, <4 x i32> %1137) #5
  %1139 = lshr <8 x i16> %1138, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1140 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1111, <8 x i16> %1139) #5
  %1141 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1140, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1142 = icmp slt <16 x i8> %1141, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1143 = select <16 x i1> %1142, <16 x i8> %1141, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1144 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1143
  %1145 = bitcast i8* %1085 to <16 x i8>*
  store <16 x i8> %1144, <16 x i8>* %1145, align 16
  %1146 = getelementptr inbounds i16, i16* %9, i64 288
  %1147 = getelementptr inbounds i16, i16* %10, i64 288
  %1148 = getelementptr inbounds i8, i8* %1022, i64 32
  %1149 = bitcast i16* %1146 to <8 x i16>*
  %1150 = load <8 x i16>, <8 x i16>* %1149, align 16
  %1151 = bitcast i16* %1147 to <8 x i16>*
  %1152 = load <8 x i16>, <8 x i16>* %1151, align 16
  %1153 = shufflevector <8 x i16> %1150, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1154 = zext <4 x i16> %1153 to <4 x i32>
  %1155 = shufflevector <8 x i16> %1152, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1156 = zext <4 x i16> %1155 to <4 x i32>
  %1157 = sub nsw <4 x i32> %1154, %1156
  %1158 = sub nsw <4 x i32> zeroinitializer, %1157
  %1159 = icmp slt <4 x i32> %1157, zeroinitializer
  %1160 = select <4 x i1> %1159, <4 x i32> %1158, <4 x i32> %1157
  %1161 = add nuw nsw <4 x i32> %1160, <i32 32, i32 32, i32 32, i32 32>
  %1162 = lshr <4 x i32> %1161, <i32 6, i32 6, i32 6, i32 6>
  %1163 = shufflevector <8 x i16> %1150, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1164 = shufflevector <8 x i16> %1152, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1165 = bitcast <8 x i16> %1163 to <4 x i32>
  %1166 = bitcast <8 x i16> %1164 to <4 x i32>
  %1167 = sub <4 x i32> %1165, %1166
  %1168 = sub <4 x i32> zeroinitializer, %1167
  %1169 = icmp slt <4 x i32> %1167, zeroinitializer
  %1170 = select <4 x i1> %1169, <4 x i32> %1168, <4 x i32> %1167
  %1171 = add nuw <4 x i32> %1170, <i32 32, i32 32, i32 32, i32 32>
  %1172 = lshr <4 x i32> %1171, <i32 6, i32 6, i32 6, i32 6>
  %1173 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1162, <4 x i32> %1172) #5
  %1174 = lshr <8 x i16> %1173, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1175 = getelementptr inbounds i16, i16* %9, i64 296
  %1176 = bitcast i16* %1175 to <8 x i16>*
  %1177 = load <8 x i16>, <8 x i16>* %1176, align 16
  %1178 = getelementptr inbounds i16, i16* %10, i64 296
  %1179 = bitcast i16* %1178 to <8 x i16>*
  %1180 = load <8 x i16>, <8 x i16>* %1179, align 16
  %1181 = shufflevector <8 x i16> %1177, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1182 = zext <4 x i16> %1181 to <4 x i32>
  %1183 = shufflevector <8 x i16> %1180, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1184 = zext <4 x i16> %1183 to <4 x i32>
  %1185 = sub nsw <4 x i32> %1182, %1184
  %1186 = sub nsw <4 x i32> zeroinitializer, %1185
  %1187 = icmp slt <4 x i32> %1185, zeroinitializer
  %1188 = select <4 x i1> %1187, <4 x i32> %1186, <4 x i32> %1185
  %1189 = add nuw nsw <4 x i32> %1188, <i32 32, i32 32, i32 32, i32 32>
  %1190 = lshr <4 x i32> %1189, <i32 6, i32 6, i32 6, i32 6>
  %1191 = shufflevector <8 x i16> %1177, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1192 = shufflevector <8 x i16> %1180, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1193 = bitcast <8 x i16> %1191 to <4 x i32>
  %1194 = bitcast <8 x i16> %1192 to <4 x i32>
  %1195 = sub <4 x i32> %1193, %1194
  %1196 = sub <4 x i32> zeroinitializer, %1195
  %1197 = icmp slt <4 x i32> %1195, zeroinitializer
  %1198 = select <4 x i1> %1197, <4 x i32> %1196, <4 x i32> %1195
  %1199 = add nuw <4 x i32> %1198, <i32 32, i32 32, i32 32, i32 32>
  %1200 = lshr <4 x i32> %1199, <i32 6, i32 6, i32 6, i32 6>
  %1201 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1190, <4 x i32> %1200) #5
  %1202 = lshr <8 x i16> %1201, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1203 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1174, <8 x i16> %1202) #5
  %1204 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1203, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1205 = icmp slt <16 x i8> %1204, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1206 = select <16 x i1> %1205, <16 x i8> %1204, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1207 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1206
  %1208 = bitcast i8* %1148 to <16 x i8>*
  store <16 x i8> %1207, <16 x i8>* %1208, align 16
  %1209 = getelementptr inbounds i16, i16* %9, i64 304
  %1210 = getelementptr inbounds i16, i16* %10, i64 304
  %1211 = getelementptr inbounds i8, i8* %1022, i64 48
  %1212 = bitcast i16* %1209 to <8 x i16>*
  %1213 = load <8 x i16>, <8 x i16>* %1212, align 16
  %1214 = bitcast i16* %1210 to <8 x i16>*
  %1215 = load <8 x i16>, <8 x i16>* %1214, align 16
  %1216 = shufflevector <8 x i16> %1213, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1217 = zext <4 x i16> %1216 to <4 x i32>
  %1218 = shufflevector <8 x i16> %1215, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1219 = zext <4 x i16> %1218 to <4 x i32>
  %1220 = sub nsw <4 x i32> %1217, %1219
  %1221 = sub nsw <4 x i32> zeroinitializer, %1220
  %1222 = icmp slt <4 x i32> %1220, zeroinitializer
  %1223 = select <4 x i1> %1222, <4 x i32> %1221, <4 x i32> %1220
  %1224 = add nuw nsw <4 x i32> %1223, <i32 32, i32 32, i32 32, i32 32>
  %1225 = lshr <4 x i32> %1224, <i32 6, i32 6, i32 6, i32 6>
  %1226 = shufflevector <8 x i16> %1213, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1227 = shufflevector <8 x i16> %1215, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1228 = bitcast <8 x i16> %1226 to <4 x i32>
  %1229 = bitcast <8 x i16> %1227 to <4 x i32>
  %1230 = sub <4 x i32> %1228, %1229
  %1231 = sub <4 x i32> zeroinitializer, %1230
  %1232 = icmp slt <4 x i32> %1230, zeroinitializer
  %1233 = select <4 x i1> %1232, <4 x i32> %1231, <4 x i32> %1230
  %1234 = add nuw <4 x i32> %1233, <i32 32, i32 32, i32 32, i32 32>
  %1235 = lshr <4 x i32> %1234, <i32 6, i32 6, i32 6, i32 6>
  %1236 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1225, <4 x i32> %1235) #5
  %1237 = lshr <8 x i16> %1236, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1238 = getelementptr inbounds i16, i16* %9, i64 312
  %1239 = bitcast i16* %1238 to <8 x i16>*
  %1240 = load <8 x i16>, <8 x i16>* %1239, align 16
  %1241 = getelementptr inbounds i16, i16* %10, i64 312
  %1242 = bitcast i16* %1241 to <8 x i16>*
  %1243 = load <8 x i16>, <8 x i16>* %1242, align 16
  %1244 = shufflevector <8 x i16> %1240, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1245 = zext <4 x i16> %1244 to <4 x i32>
  %1246 = shufflevector <8 x i16> %1243, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1247 = zext <4 x i16> %1246 to <4 x i32>
  %1248 = sub nsw <4 x i32> %1245, %1247
  %1249 = sub nsw <4 x i32> zeroinitializer, %1248
  %1250 = icmp slt <4 x i32> %1248, zeroinitializer
  %1251 = select <4 x i1> %1250, <4 x i32> %1249, <4 x i32> %1248
  %1252 = add nuw nsw <4 x i32> %1251, <i32 32, i32 32, i32 32, i32 32>
  %1253 = lshr <4 x i32> %1252, <i32 6, i32 6, i32 6, i32 6>
  %1254 = shufflevector <8 x i16> %1240, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1255 = shufflevector <8 x i16> %1243, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1256 = bitcast <8 x i16> %1254 to <4 x i32>
  %1257 = bitcast <8 x i16> %1255 to <4 x i32>
  %1258 = sub <4 x i32> %1256, %1257
  %1259 = sub <4 x i32> zeroinitializer, %1258
  %1260 = icmp slt <4 x i32> %1258, zeroinitializer
  %1261 = select <4 x i1> %1260, <4 x i32> %1259, <4 x i32> %1258
  %1262 = add nuw <4 x i32> %1261, <i32 32, i32 32, i32 32, i32 32>
  %1263 = lshr <4 x i32> %1262, <i32 6, i32 6, i32 6, i32 6>
  %1264 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1253, <4 x i32> %1263) #5
  %1265 = lshr <8 x i16> %1264, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1266 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1237, <8 x i16> %1265) #5
  %1267 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1266, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1268 = icmp slt <16 x i8> %1267, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1269 = select <16 x i1> %1268, <16 x i8> %1267, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1270 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1269
  %1271 = bitcast i8* %1211 to <16 x i8>*
  store <16 x i8> %1270, <16 x i8>* %1271, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_127WeightMask128x64_10bpp_SSE4ILb0EEEvPKvS5_Phl(i8* readonly, i8* readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  %7 = add nsw i64 %3, -64
  br label %8

8:                                                ; preds = %8, %4
  %9 = phi i8* [ %2, %4 ], [ %1500, %8 ]
  %10 = phi i16* [ %5, %4 ], [ %1498, %8 ]
  %11 = phi i16* [ %6, %4 ], [ %1499, %8 ]
  %12 = phi i32 [ 21, %4 ], [ %1501, %8 ]
  %13 = bitcast i16* %10 to <8 x i16>*
  %14 = load <8 x i16>, <8 x i16>* %13, align 16
  %15 = bitcast i16* %11 to <8 x i16>*
  %16 = load <8 x i16>, <8 x i16>* %15, align 16
  %17 = shufflevector <8 x i16> %14, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %18 = zext <4 x i16> %17 to <4 x i32>
  %19 = shufflevector <8 x i16> %16, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %20 = zext <4 x i16> %19 to <4 x i32>
  %21 = sub nsw <4 x i32> %18, %20
  %22 = sub nsw <4 x i32> zeroinitializer, %21
  %23 = icmp slt <4 x i32> %21, zeroinitializer
  %24 = select <4 x i1> %23, <4 x i32> %22, <4 x i32> %21
  %25 = add nuw nsw <4 x i32> %24, <i32 32, i32 32, i32 32, i32 32>
  %26 = lshr <4 x i32> %25, <i32 6, i32 6, i32 6, i32 6>
  %27 = shufflevector <8 x i16> %14, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %28 = shufflevector <8 x i16> %16, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %29 = bitcast <8 x i16> %27 to <4 x i32>
  %30 = bitcast <8 x i16> %28 to <4 x i32>
  %31 = sub <4 x i32> %29, %30
  %32 = sub <4 x i32> zeroinitializer, %31
  %33 = icmp slt <4 x i32> %31, zeroinitializer
  %34 = select <4 x i1> %33, <4 x i32> %32, <4 x i32> %31
  %35 = add nuw <4 x i32> %34, <i32 32, i32 32, i32 32, i32 32>
  %36 = lshr <4 x i32> %35, <i32 6, i32 6, i32 6, i32 6>
  %37 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %26, <4 x i32> %36) #5
  %38 = lshr <8 x i16> %37, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %39 = getelementptr inbounds i16, i16* %10, i64 8
  %40 = bitcast i16* %39 to <8 x i16>*
  %41 = load <8 x i16>, <8 x i16>* %40, align 16
  %42 = getelementptr inbounds i16, i16* %11, i64 8
  %43 = bitcast i16* %42 to <8 x i16>*
  %44 = load <8 x i16>, <8 x i16>* %43, align 16
  %45 = shufflevector <8 x i16> %41, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %46 = zext <4 x i16> %45 to <4 x i32>
  %47 = shufflevector <8 x i16> %44, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %48 = zext <4 x i16> %47 to <4 x i32>
  %49 = sub nsw <4 x i32> %46, %48
  %50 = sub nsw <4 x i32> zeroinitializer, %49
  %51 = icmp slt <4 x i32> %49, zeroinitializer
  %52 = select <4 x i1> %51, <4 x i32> %50, <4 x i32> %49
  %53 = add nuw nsw <4 x i32> %52, <i32 32, i32 32, i32 32, i32 32>
  %54 = lshr <4 x i32> %53, <i32 6, i32 6, i32 6, i32 6>
  %55 = shufflevector <8 x i16> %41, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %56 = shufflevector <8 x i16> %44, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %57 = bitcast <8 x i16> %55 to <4 x i32>
  %58 = bitcast <8 x i16> %56 to <4 x i32>
  %59 = sub <4 x i32> %57, %58
  %60 = sub <4 x i32> zeroinitializer, %59
  %61 = icmp slt <4 x i32> %59, zeroinitializer
  %62 = select <4 x i1> %61, <4 x i32> %60, <4 x i32> %59
  %63 = add nuw <4 x i32> %62, <i32 32, i32 32, i32 32, i32 32>
  %64 = lshr <4 x i32> %63, <i32 6, i32 6, i32 6, i32 6>
  %65 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %54, <4 x i32> %64) #5
  %66 = lshr <8 x i16> %65, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %67 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %38, <8 x i16> %66) #5
  %68 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %67, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %69 = icmp slt <16 x i8> %68, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %70 = select <16 x i1> %69, <16 x i8> %68, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %71 = bitcast i8* %9 to <16 x i8>*
  store <16 x i8> %70, <16 x i8>* %71, align 16
  %72 = getelementptr inbounds i16, i16* %10, i64 16
  %73 = getelementptr inbounds i16, i16* %11, i64 16
  %74 = getelementptr inbounds i8, i8* %9, i64 16
  %75 = bitcast i16* %72 to <8 x i16>*
  %76 = load <8 x i16>, <8 x i16>* %75, align 16
  %77 = bitcast i16* %73 to <8 x i16>*
  %78 = load <8 x i16>, <8 x i16>* %77, align 16
  %79 = shufflevector <8 x i16> %76, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %80 = zext <4 x i16> %79 to <4 x i32>
  %81 = shufflevector <8 x i16> %78, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %82 = zext <4 x i16> %81 to <4 x i32>
  %83 = sub nsw <4 x i32> %80, %82
  %84 = sub nsw <4 x i32> zeroinitializer, %83
  %85 = icmp slt <4 x i32> %83, zeroinitializer
  %86 = select <4 x i1> %85, <4 x i32> %84, <4 x i32> %83
  %87 = add nuw nsw <4 x i32> %86, <i32 32, i32 32, i32 32, i32 32>
  %88 = lshr <4 x i32> %87, <i32 6, i32 6, i32 6, i32 6>
  %89 = shufflevector <8 x i16> %76, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %90 = shufflevector <8 x i16> %78, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %91 = bitcast <8 x i16> %89 to <4 x i32>
  %92 = bitcast <8 x i16> %90 to <4 x i32>
  %93 = sub <4 x i32> %91, %92
  %94 = sub <4 x i32> zeroinitializer, %93
  %95 = icmp slt <4 x i32> %93, zeroinitializer
  %96 = select <4 x i1> %95, <4 x i32> %94, <4 x i32> %93
  %97 = add nuw <4 x i32> %96, <i32 32, i32 32, i32 32, i32 32>
  %98 = lshr <4 x i32> %97, <i32 6, i32 6, i32 6, i32 6>
  %99 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %88, <4 x i32> %98) #5
  %100 = lshr <8 x i16> %99, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %101 = getelementptr inbounds i16, i16* %10, i64 24
  %102 = bitcast i16* %101 to <8 x i16>*
  %103 = load <8 x i16>, <8 x i16>* %102, align 16
  %104 = getelementptr inbounds i16, i16* %11, i64 24
  %105 = bitcast i16* %104 to <8 x i16>*
  %106 = load <8 x i16>, <8 x i16>* %105, align 16
  %107 = shufflevector <8 x i16> %103, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %108 = zext <4 x i16> %107 to <4 x i32>
  %109 = shufflevector <8 x i16> %106, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %110 = zext <4 x i16> %109 to <4 x i32>
  %111 = sub nsw <4 x i32> %108, %110
  %112 = sub nsw <4 x i32> zeroinitializer, %111
  %113 = icmp slt <4 x i32> %111, zeroinitializer
  %114 = select <4 x i1> %113, <4 x i32> %112, <4 x i32> %111
  %115 = add nuw nsw <4 x i32> %114, <i32 32, i32 32, i32 32, i32 32>
  %116 = lshr <4 x i32> %115, <i32 6, i32 6, i32 6, i32 6>
  %117 = shufflevector <8 x i16> %103, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %118 = shufflevector <8 x i16> %106, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %119 = bitcast <8 x i16> %117 to <4 x i32>
  %120 = bitcast <8 x i16> %118 to <4 x i32>
  %121 = sub <4 x i32> %119, %120
  %122 = sub <4 x i32> zeroinitializer, %121
  %123 = icmp slt <4 x i32> %121, zeroinitializer
  %124 = select <4 x i1> %123, <4 x i32> %122, <4 x i32> %121
  %125 = add nuw <4 x i32> %124, <i32 32, i32 32, i32 32, i32 32>
  %126 = lshr <4 x i32> %125, <i32 6, i32 6, i32 6, i32 6>
  %127 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %116, <4 x i32> %126) #5
  %128 = lshr <8 x i16> %127, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %129 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %100, <8 x i16> %128) #5
  %130 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %129, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %131 = icmp slt <16 x i8> %130, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %132 = select <16 x i1> %131, <16 x i8> %130, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %133 = bitcast i8* %74 to <16 x i8>*
  store <16 x i8> %132, <16 x i8>* %133, align 16
  %134 = getelementptr inbounds i16, i16* %10, i64 32
  %135 = getelementptr inbounds i16, i16* %11, i64 32
  %136 = getelementptr inbounds i8, i8* %9, i64 32
  %137 = bitcast i16* %134 to <8 x i16>*
  %138 = load <8 x i16>, <8 x i16>* %137, align 16
  %139 = bitcast i16* %135 to <8 x i16>*
  %140 = load <8 x i16>, <8 x i16>* %139, align 16
  %141 = shufflevector <8 x i16> %138, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %142 = zext <4 x i16> %141 to <4 x i32>
  %143 = shufflevector <8 x i16> %140, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %144 = zext <4 x i16> %143 to <4 x i32>
  %145 = sub nsw <4 x i32> %142, %144
  %146 = sub nsw <4 x i32> zeroinitializer, %145
  %147 = icmp slt <4 x i32> %145, zeroinitializer
  %148 = select <4 x i1> %147, <4 x i32> %146, <4 x i32> %145
  %149 = add nuw nsw <4 x i32> %148, <i32 32, i32 32, i32 32, i32 32>
  %150 = lshr <4 x i32> %149, <i32 6, i32 6, i32 6, i32 6>
  %151 = shufflevector <8 x i16> %138, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %152 = shufflevector <8 x i16> %140, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %153 = bitcast <8 x i16> %151 to <4 x i32>
  %154 = bitcast <8 x i16> %152 to <4 x i32>
  %155 = sub <4 x i32> %153, %154
  %156 = sub <4 x i32> zeroinitializer, %155
  %157 = icmp slt <4 x i32> %155, zeroinitializer
  %158 = select <4 x i1> %157, <4 x i32> %156, <4 x i32> %155
  %159 = add nuw <4 x i32> %158, <i32 32, i32 32, i32 32, i32 32>
  %160 = lshr <4 x i32> %159, <i32 6, i32 6, i32 6, i32 6>
  %161 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %150, <4 x i32> %160) #5
  %162 = lshr <8 x i16> %161, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %163 = getelementptr inbounds i16, i16* %10, i64 40
  %164 = bitcast i16* %163 to <8 x i16>*
  %165 = load <8 x i16>, <8 x i16>* %164, align 16
  %166 = getelementptr inbounds i16, i16* %11, i64 40
  %167 = bitcast i16* %166 to <8 x i16>*
  %168 = load <8 x i16>, <8 x i16>* %167, align 16
  %169 = shufflevector <8 x i16> %165, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %170 = zext <4 x i16> %169 to <4 x i32>
  %171 = shufflevector <8 x i16> %168, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %172 = zext <4 x i16> %171 to <4 x i32>
  %173 = sub nsw <4 x i32> %170, %172
  %174 = sub nsw <4 x i32> zeroinitializer, %173
  %175 = icmp slt <4 x i32> %173, zeroinitializer
  %176 = select <4 x i1> %175, <4 x i32> %174, <4 x i32> %173
  %177 = add nuw nsw <4 x i32> %176, <i32 32, i32 32, i32 32, i32 32>
  %178 = lshr <4 x i32> %177, <i32 6, i32 6, i32 6, i32 6>
  %179 = shufflevector <8 x i16> %165, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %180 = shufflevector <8 x i16> %168, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %181 = bitcast <8 x i16> %179 to <4 x i32>
  %182 = bitcast <8 x i16> %180 to <4 x i32>
  %183 = sub <4 x i32> %181, %182
  %184 = sub <4 x i32> zeroinitializer, %183
  %185 = icmp slt <4 x i32> %183, zeroinitializer
  %186 = select <4 x i1> %185, <4 x i32> %184, <4 x i32> %183
  %187 = add nuw <4 x i32> %186, <i32 32, i32 32, i32 32, i32 32>
  %188 = lshr <4 x i32> %187, <i32 6, i32 6, i32 6, i32 6>
  %189 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %178, <4 x i32> %188) #5
  %190 = lshr <8 x i16> %189, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %191 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %162, <8 x i16> %190) #5
  %192 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %191, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %193 = icmp slt <16 x i8> %192, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %194 = select <16 x i1> %193, <16 x i8> %192, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %195 = bitcast i8* %136 to <16 x i8>*
  store <16 x i8> %194, <16 x i8>* %195, align 16
  %196 = getelementptr inbounds i16, i16* %10, i64 48
  %197 = getelementptr inbounds i16, i16* %11, i64 48
  %198 = getelementptr inbounds i8, i8* %9, i64 48
  %199 = bitcast i16* %196 to <8 x i16>*
  %200 = load <8 x i16>, <8 x i16>* %199, align 16
  %201 = bitcast i16* %197 to <8 x i16>*
  %202 = load <8 x i16>, <8 x i16>* %201, align 16
  %203 = shufflevector <8 x i16> %200, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %204 = zext <4 x i16> %203 to <4 x i32>
  %205 = shufflevector <8 x i16> %202, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %206 = zext <4 x i16> %205 to <4 x i32>
  %207 = sub nsw <4 x i32> %204, %206
  %208 = sub nsw <4 x i32> zeroinitializer, %207
  %209 = icmp slt <4 x i32> %207, zeroinitializer
  %210 = select <4 x i1> %209, <4 x i32> %208, <4 x i32> %207
  %211 = add nuw nsw <4 x i32> %210, <i32 32, i32 32, i32 32, i32 32>
  %212 = lshr <4 x i32> %211, <i32 6, i32 6, i32 6, i32 6>
  %213 = shufflevector <8 x i16> %200, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %214 = shufflevector <8 x i16> %202, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %215 = bitcast <8 x i16> %213 to <4 x i32>
  %216 = bitcast <8 x i16> %214 to <4 x i32>
  %217 = sub <4 x i32> %215, %216
  %218 = sub <4 x i32> zeroinitializer, %217
  %219 = icmp slt <4 x i32> %217, zeroinitializer
  %220 = select <4 x i1> %219, <4 x i32> %218, <4 x i32> %217
  %221 = add nuw <4 x i32> %220, <i32 32, i32 32, i32 32, i32 32>
  %222 = lshr <4 x i32> %221, <i32 6, i32 6, i32 6, i32 6>
  %223 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %212, <4 x i32> %222) #5
  %224 = lshr <8 x i16> %223, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %225 = getelementptr inbounds i16, i16* %10, i64 56
  %226 = bitcast i16* %225 to <8 x i16>*
  %227 = load <8 x i16>, <8 x i16>* %226, align 16
  %228 = getelementptr inbounds i16, i16* %11, i64 56
  %229 = bitcast i16* %228 to <8 x i16>*
  %230 = load <8 x i16>, <8 x i16>* %229, align 16
  %231 = shufflevector <8 x i16> %227, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %232 = zext <4 x i16> %231 to <4 x i32>
  %233 = shufflevector <8 x i16> %230, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %234 = zext <4 x i16> %233 to <4 x i32>
  %235 = sub nsw <4 x i32> %232, %234
  %236 = sub nsw <4 x i32> zeroinitializer, %235
  %237 = icmp slt <4 x i32> %235, zeroinitializer
  %238 = select <4 x i1> %237, <4 x i32> %236, <4 x i32> %235
  %239 = add nuw nsw <4 x i32> %238, <i32 32, i32 32, i32 32, i32 32>
  %240 = lshr <4 x i32> %239, <i32 6, i32 6, i32 6, i32 6>
  %241 = shufflevector <8 x i16> %227, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %242 = shufflevector <8 x i16> %230, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %243 = bitcast <8 x i16> %241 to <4 x i32>
  %244 = bitcast <8 x i16> %242 to <4 x i32>
  %245 = sub <4 x i32> %243, %244
  %246 = sub <4 x i32> zeroinitializer, %245
  %247 = icmp slt <4 x i32> %245, zeroinitializer
  %248 = select <4 x i1> %247, <4 x i32> %246, <4 x i32> %245
  %249 = add nuw <4 x i32> %248, <i32 32, i32 32, i32 32, i32 32>
  %250 = lshr <4 x i32> %249, <i32 6, i32 6, i32 6, i32 6>
  %251 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %240, <4 x i32> %250) #5
  %252 = lshr <8 x i16> %251, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %253 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %224, <8 x i16> %252) #5
  %254 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %253, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %255 = icmp slt <16 x i8> %254, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %256 = select <16 x i1> %255, <16 x i8> %254, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %257 = bitcast i8* %198 to <16 x i8>*
  store <16 x i8> %256, <16 x i8>* %257, align 16
  %258 = getelementptr inbounds i16, i16* %10, i64 64
  %259 = getelementptr inbounds i16, i16* %11, i64 64
  %260 = getelementptr inbounds i8, i8* %9, i64 64
  %261 = bitcast i16* %258 to <8 x i16>*
  %262 = load <8 x i16>, <8 x i16>* %261, align 16
  %263 = bitcast i16* %259 to <8 x i16>*
  %264 = load <8 x i16>, <8 x i16>* %263, align 16
  %265 = shufflevector <8 x i16> %262, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %266 = zext <4 x i16> %265 to <4 x i32>
  %267 = shufflevector <8 x i16> %264, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %268 = zext <4 x i16> %267 to <4 x i32>
  %269 = sub nsw <4 x i32> %266, %268
  %270 = sub nsw <4 x i32> zeroinitializer, %269
  %271 = icmp slt <4 x i32> %269, zeroinitializer
  %272 = select <4 x i1> %271, <4 x i32> %270, <4 x i32> %269
  %273 = add nuw nsw <4 x i32> %272, <i32 32, i32 32, i32 32, i32 32>
  %274 = lshr <4 x i32> %273, <i32 6, i32 6, i32 6, i32 6>
  %275 = shufflevector <8 x i16> %262, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %276 = shufflevector <8 x i16> %264, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %277 = bitcast <8 x i16> %275 to <4 x i32>
  %278 = bitcast <8 x i16> %276 to <4 x i32>
  %279 = sub <4 x i32> %277, %278
  %280 = sub <4 x i32> zeroinitializer, %279
  %281 = icmp slt <4 x i32> %279, zeroinitializer
  %282 = select <4 x i1> %281, <4 x i32> %280, <4 x i32> %279
  %283 = add nuw <4 x i32> %282, <i32 32, i32 32, i32 32, i32 32>
  %284 = lshr <4 x i32> %283, <i32 6, i32 6, i32 6, i32 6>
  %285 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %274, <4 x i32> %284) #5
  %286 = lshr <8 x i16> %285, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %287 = getelementptr inbounds i16, i16* %10, i64 72
  %288 = bitcast i16* %287 to <8 x i16>*
  %289 = load <8 x i16>, <8 x i16>* %288, align 16
  %290 = getelementptr inbounds i16, i16* %11, i64 72
  %291 = bitcast i16* %290 to <8 x i16>*
  %292 = load <8 x i16>, <8 x i16>* %291, align 16
  %293 = shufflevector <8 x i16> %289, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %294 = zext <4 x i16> %293 to <4 x i32>
  %295 = shufflevector <8 x i16> %292, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %296 = zext <4 x i16> %295 to <4 x i32>
  %297 = sub nsw <4 x i32> %294, %296
  %298 = sub nsw <4 x i32> zeroinitializer, %297
  %299 = icmp slt <4 x i32> %297, zeroinitializer
  %300 = select <4 x i1> %299, <4 x i32> %298, <4 x i32> %297
  %301 = add nuw nsw <4 x i32> %300, <i32 32, i32 32, i32 32, i32 32>
  %302 = lshr <4 x i32> %301, <i32 6, i32 6, i32 6, i32 6>
  %303 = shufflevector <8 x i16> %289, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %304 = shufflevector <8 x i16> %292, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %305 = bitcast <8 x i16> %303 to <4 x i32>
  %306 = bitcast <8 x i16> %304 to <4 x i32>
  %307 = sub <4 x i32> %305, %306
  %308 = sub <4 x i32> zeroinitializer, %307
  %309 = icmp slt <4 x i32> %307, zeroinitializer
  %310 = select <4 x i1> %309, <4 x i32> %308, <4 x i32> %307
  %311 = add nuw <4 x i32> %310, <i32 32, i32 32, i32 32, i32 32>
  %312 = lshr <4 x i32> %311, <i32 6, i32 6, i32 6, i32 6>
  %313 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %302, <4 x i32> %312) #5
  %314 = lshr <8 x i16> %313, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %315 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %286, <8 x i16> %314) #5
  %316 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %315, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %317 = icmp slt <16 x i8> %316, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %318 = select <16 x i1> %317, <16 x i8> %316, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %319 = bitcast i8* %260 to <16 x i8>*
  store <16 x i8> %318, <16 x i8>* %319, align 16
  %320 = getelementptr inbounds i16, i16* %10, i64 80
  %321 = getelementptr inbounds i16, i16* %11, i64 80
  %322 = getelementptr inbounds i8, i8* %9, i64 80
  %323 = bitcast i16* %320 to <8 x i16>*
  %324 = load <8 x i16>, <8 x i16>* %323, align 16
  %325 = bitcast i16* %321 to <8 x i16>*
  %326 = load <8 x i16>, <8 x i16>* %325, align 16
  %327 = shufflevector <8 x i16> %324, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %328 = zext <4 x i16> %327 to <4 x i32>
  %329 = shufflevector <8 x i16> %326, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %330 = zext <4 x i16> %329 to <4 x i32>
  %331 = sub nsw <4 x i32> %328, %330
  %332 = sub nsw <4 x i32> zeroinitializer, %331
  %333 = icmp slt <4 x i32> %331, zeroinitializer
  %334 = select <4 x i1> %333, <4 x i32> %332, <4 x i32> %331
  %335 = add nuw nsw <4 x i32> %334, <i32 32, i32 32, i32 32, i32 32>
  %336 = lshr <4 x i32> %335, <i32 6, i32 6, i32 6, i32 6>
  %337 = shufflevector <8 x i16> %324, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %338 = shufflevector <8 x i16> %326, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %339 = bitcast <8 x i16> %337 to <4 x i32>
  %340 = bitcast <8 x i16> %338 to <4 x i32>
  %341 = sub <4 x i32> %339, %340
  %342 = sub <4 x i32> zeroinitializer, %341
  %343 = icmp slt <4 x i32> %341, zeroinitializer
  %344 = select <4 x i1> %343, <4 x i32> %342, <4 x i32> %341
  %345 = add nuw <4 x i32> %344, <i32 32, i32 32, i32 32, i32 32>
  %346 = lshr <4 x i32> %345, <i32 6, i32 6, i32 6, i32 6>
  %347 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %336, <4 x i32> %346) #5
  %348 = lshr <8 x i16> %347, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %349 = getelementptr inbounds i16, i16* %10, i64 88
  %350 = bitcast i16* %349 to <8 x i16>*
  %351 = load <8 x i16>, <8 x i16>* %350, align 16
  %352 = getelementptr inbounds i16, i16* %11, i64 88
  %353 = bitcast i16* %352 to <8 x i16>*
  %354 = load <8 x i16>, <8 x i16>* %353, align 16
  %355 = shufflevector <8 x i16> %351, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %356 = zext <4 x i16> %355 to <4 x i32>
  %357 = shufflevector <8 x i16> %354, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %358 = zext <4 x i16> %357 to <4 x i32>
  %359 = sub nsw <4 x i32> %356, %358
  %360 = sub nsw <4 x i32> zeroinitializer, %359
  %361 = icmp slt <4 x i32> %359, zeroinitializer
  %362 = select <4 x i1> %361, <4 x i32> %360, <4 x i32> %359
  %363 = add nuw nsw <4 x i32> %362, <i32 32, i32 32, i32 32, i32 32>
  %364 = lshr <4 x i32> %363, <i32 6, i32 6, i32 6, i32 6>
  %365 = shufflevector <8 x i16> %351, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %366 = shufflevector <8 x i16> %354, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %367 = bitcast <8 x i16> %365 to <4 x i32>
  %368 = bitcast <8 x i16> %366 to <4 x i32>
  %369 = sub <4 x i32> %367, %368
  %370 = sub <4 x i32> zeroinitializer, %369
  %371 = icmp slt <4 x i32> %369, zeroinitializer
  %372 = select <4 x i1> %371, <4 x i32> %370, <4 x i32> %369
  %373 = add nuw <4 x i32> %372, <i32 32, i32 32, i32 32, i32 32>
  %374 = lshr <4 x i32> %373, <i32 6, i32 6, i32 6, i32 6>
  %375 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %364, <4 x i32> %374) #5
  %376 = lshr <8 x i16> %375, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %377 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %348, <8 x i16> %376) #5
  %378 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %377, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %379 = icmp slt <16 x i8> %378, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %380 = select <16 x i1> %379, <16 x i8> %378, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %381 = bitcast i8* %322 to <16 x i8>*
  store <16 x i8> %380, <16 x i8>* %381, align 16
  %382 = getelementptr inbounds i16, i16* %10, i64 96
  %383 = getelementptr inbounds i16, i16* %11, i64 96
  %384 = getelementptr inbounds i8, i8* %9, i64 96
  %385 = bitcast i16* %382 to <8 x i16>*
  %386 = load <8 x i16>, <8 x i16>* %385, align 16
  %387 = bitcast i16* %383 to <8 x i16>*
  %388 = load <8 x i16>, <8 x i16>* %387, align 16
  %389 = shufflevector <8 x i16> %386, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %390 = zext <4 x i16> %389 to <4 x i32>
  %391 = shufflevector <8 x i16> %388, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %392 = zext <4 x i16> %391 to <4 x i32>
  %393 = sub nsw <4 x i32> %390, %392
  %394 = sub nsw <4 x i32> zeroinitializer, %393
  %395 = icmp slt <4 x i32> %393, zeroinitializer
  %396 = select <4 x i1> %395, <4 x i32> %394, <4 x i32> %393
  %397 = add nuw nsw <4 x i32> %396, <i32 32, i32 32, i32 32, i32 32>
  %398 = lshr <4 x i32> %397, <i32 6, i32 6, i32 6, i32 6>
  %399 = shufflevector <8 x i16> %386, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %400 = shufflevector <8 x i16> %388, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %401 = bitcast <8 x i16> %399 to <4 x i32>
  %402 = bitcast <8 x i16> %400 to <4 x i32>
  %403 = sub <4 x i32> %401, %402
  %404 = sub <4 x i32> zeroinitializer, %403
  %405 = icmp slt <4 x i32> %403, zeroinitializer
  %406 = select <4 x i1> %405, <4 x i32> %404, <4 x i32> %403
  %407 = add nuw <4 x i32> %406, <i32 32, i32 32, i32 32, i32 32>
  %408 = lshr <4 x i32> %407, <i32 6, i32 6, i32 6, i32 6>
  %409 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %398, <4 x i32> %408) #5
  %410 = lshr <8 x i16> %409, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %411 = getelementptr inbounds i16, i16* %10, i64 104
  %412 = bitcast i16* %411 to <8 x i16>*
  %413 = load <8 x i16>, <8 x i16>* %412, align 16
  %414 = getelementptr inbounds i16, i16* %11, i64 104
  %415 = bitcast i16* %414 to <8 x i16>*
  %416 = load <8 x i16>, <8 x i16>* %415, align 16
  %417 = shufflevector <8 x i16> %413, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %418 = zext <4 x i16> %417 to <4 x i32>
  %419 = shufflevector <8 x i16> %416, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %420 = zext <4 x i16> %419 to <4 x i32>
  %421 = sub nsw <4 x i32> %418, %420
  %422 = sub nsw <4 x i32> zeroinitializer, %421
  %423 = icmp slt <4 x i32> %421, zeroinitializer
  %424 = select <4 x i1> %423, <4 x i32> %422, <4 x i32> %421
  %425 = add nuw nsw <4 x i32> %424, <i32 32, i32 32, i32 32, i32 32>
  %426 = lshr <4 x i32> %425, <i32 6, i32 6, i32 6, i32 6>
  %427 = shufflevector <8 x i16> %413, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %428 = shufflevector <8 x i16> %416, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %429 = bitcast <8 x i16> %427 to <4 x i32>
  %430 = bitcast <8 x i16> %428 to <4 x i32>
  %431 = sub <4 x i32> %429, %430
  %432 = sub <4 x i32> zeroinitializer, %431
  %433 = icmp slt <4 x i32> %431, zeroinitializer
  %434 = select <4 x i1> %433, <4 x i32> %432, <4 x i32> %431
  %435 = add nuw <4 x i32> %434, <i32 32, i32 32, i32 32, i32 32>
  %436 = lshr <4 x i32> %435, <i32 6, i32 6, i32 6, i32 6>
  %437 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %426, <4 x i32> %436) #5
  %438 = lshr <8 x i16> %437, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %439 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %410, <8 x i16> %438) #5
  %440 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %439, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %441 = icmp slt <16 x i8> %440, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %442 = select <16 x i1> %441, <16 x i8> %440, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %443 = bitcast i8* %384 to <16 x i8>*
  store <16 x i8> %442, <16 x i8>* %443, align 16
  %444 = getelementptr inbounds i16, i16* %10, i64 112
  %445 = getelementptr inbounds i16, i16* %11, i64 112
  %446 = getelementptr inbounds i8, i8* %9, i64 112
  %447 = bitcast i16* %444 to <8 x i16>*
  %448 = load <8 x i16>, <8 x i16>* %447, align 16
  %449 = bitcast i16* %445 to <8 x i16>*
  %450 = load <8 x i16>, <8 x i16>* %449, align 16
  %451 = shufflevector <8 x i16> %448, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %452 = zext <4 x i16> %451 to <4 x i32>
  %453 = shufflevector <8 x i16> %450, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %454 = zext <4 x i16> %453 to <4 x i32>
  %455 = sub nsw <4 x i32> %452, %454
  %456 = sub nsw <4 x i32> zeroinitializer, %455
  %457 = icmp slt <4 x i32> %455, zeroinitializer
  %458 = select <4 x i1> %457, <4 x i32> %456, <4 x i32> %455
  %459 = add nuw nsw <4 x i32> %458, <i32 32, i32 32, i32 32, i32 32>
  %460 = lshr <4 x i32> %459, <i32 6, i32 6, i32 6, i32 6>
  %461 = shufflevector <8 x i16> %448, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %462 = shufflevector <8 x i16> %450, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %463 = bitcast <8 x i16> %461 to <4 x i32>
  %464 = bitcast <8 x i16> %462 to <4 x i32>
  %465 = sub <4 x i32> %463, %464
  %466 = sub <4 x i32> zeroinitializer, %465
  %467 = icmp slt <4 x i32> %465, zeroinitializer
  %468 = select <4 x i1> %467, <4 x i32> %466, <4 x i32> %465
  %469 = add nuw <4 x i32> %468, <i32 32, i32 32, i32 32, i32 32>
  %470 = lshr <4 x i32> %469, <i32 6, i32 6, i32 6, i32 6>
  %471 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %460, <4 x i32> %470) #5
  %472 = lshr <8 x i16> %471, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %473 = getelementptr inbounds i16, i16* %10, i64 120
  %474 = bitcast i16* %473 to <8 x i16>*
  %475 = load <8 x i16>, <8 x i16>* %474, align 16
  %476 = getelementptr inbounds i16, i16* %11, i64 120
  %477 = bitcast i16* %476 to <8 x i16>*
  %478 = load <8 x i16>, <8 x i16>* %477, align 16
  %479 = shufflevector <8 x i16> %475, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %480 = zext <4 x i16> %479 to <4 x i32>
  %481 = shufflevector <8 x i16> %478, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %482 = zext <4 x i16> %481 to <4 x i32>
  %483 = sub nsw <4 x i32> %480, %482
  %484 = sub nsw <4 x i32> zeroinitializer, %483
  %485 = icmp slt <4 x i32> %483, zeroinitializer
  %486 = select <4 x i1> %485, <4 x i32> %484, <4 x i32> %483
  %487 = add nuw nsw <4 x i32> %486, <i32 32, i32 32, i32 32, i32 32>
  %488 = lshr <4 x i32> %487, <i32 6, i32 6, i32 6, i32 6>
  %489 = shufflevector <8 x i16> %475, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %490 = shufflevector <8 x i16> %478, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %491 = bitcast <8 x i16> %489 to <4 x i32>
  %492 = bitcast <8 x i16> %490 to <4 x i32>
  %493 = sub <4 x i32> %491, %492
  %494 = sub <4 x i32> zeroinitializer, %493
  %495 = icmp slt <4 x i32> %493, zeroinitializer
  %496 = select <4 x i1> %495, <4 x i32> %494, <4 x i32> %493
  %497 = add nuw <4 x i32> %496, <i32 32, i32 32, i32 32, i32 32>
  %498 = lshr <4 x i32> %497, <i32 6, i32 6, i32 6, i32 6>
  %499 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %488, <4 x i32> %498) #5
  %500 = lshr <8 x i16> %499, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %501 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %472, <8 x i16> %500) #5
  %502 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %501, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %503 = icmp slt <16 x i8> %502, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %504 = select <16 x i1> %503, <16 x i8> %502, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %505 = bitcast i8* %446 to <16 x i8>*
  store <16 x i8> %504, <16 x i8>* %505, align 16
  %506 = getelementptr inbounds i16, i16* %10, i64 128
  %507 = getelementptr inbounds i16, i16* %11, i64 128
  %508 = getelementptr inbounds i8, i8* %9, i64 %3
  %509 = bitcast i16* %506 to <8 x i16>*
  %510 = load <8 x i16>, <8 x i16>* %509, align 16
  %511 = bitcast i16* %507 to <8 x i16>*
  %512 = load <8 x i16>, <8 x i16>* %511, align 16
  %513 = shufflevector <8 x i16> %510, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %514 = zext <4 x i16> %513 to <4 x i32>
  %515 = shufflevector <8 x i16> %512, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %516 = zext <4 x i16> %515 to <4 x i32>
  %517 = sub nsw <4 x i32> %514, %516
  %518 = sub nsw <4 x i32> zeroinitializer, %517
  %519 = icmp slt <4 x i32> %517, zeroinitializer
  %520 = select <4 x i1> %519, <4 x i32> %518, <4 x i32> %517
  %521 = add nuw nsw <4 x i32> %520, <i32 32, i32 32, i32 32, i32 32>
  %522 = lshr <4 x i32> %521, <i32 6, i32 6, i32 6, i32 6>
  %523 = shufflevector <8 x i16> %510, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %524 = shufflevector <8 x i16> %512, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %525 = bitcast <8 x i16> %523 to <4 x i32>
  %526 = bitcast <8 x i16> %524 to <4 x i32>
  %527 = sub <4 x i32> %525, %526
  %528 = sub <4 x i32> zeroinitializer, %527
  %529 = icmp slt <4 x i32> %527, zeroinitializer
  %530 = select <4 x i1> %529, <4 x i32> %528, <4 x i32> %527
  %531 = add nuw <4 x i32> %530, <i32 32, i32 32, i32 32, i32 32>
  %532 = lshr <4 x i32> %531, <i32 6, i32 6, i32 6, i32 6>
  %533 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %522, <4 x i32> %532) #5
  %534 = lshr <8 x i16> %533, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %535 = getelementptr inbounds i16, i16* %10, i64 136
  %536 = bitcast i16* %535 to <8 x i16>*
  %537 = load <8 x i16>, <8 x i16>* %536, align 16
  %538 = getelementptr inbounds i16, i16* %11, i64 136
  %539 = bitcast i16* %538 to <8 x i16>*
  %540 = load <8 x i16>, <8 x i16>* %539, align 16
  %541 = shufflevector <8 x i16> %537, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %542 = zext <4 x i16> %541 to <4 x i32>
  %543 = shufflevector <8 x i16> %540, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %544 = zext <4 x i16> %543 to <4 x i32>
  %545 = sub nsw <4 x i32> %542, %544
  %546 = sub nsw <4 x i32> zeroinitializer, %545
  %547 = icmp slt <4 x i32> %545, zeroinitializer
  %548 = select <4 x i1> %547, <4 x i32> %546, <4 x i32> %545
  %549 = add nuw nsw <4 x i32> %548, <i32 32, i32 32, i32 32, i32 32>
  %550 = lshr <4 x i32> %549, <i32 6, i32 6, i32 6, i32 6>
  %551 = shufflevector <8 x i16> %537, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %552 = shufflevector <8 x i16> %540, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %553 = bitcast <8 x i16> %551 to <4 x i32>
  %554 = bitcast <8 x i16> %552 to <4 x i32>
  %555 = sub <4 x i32> %553, %554
  %556 = sub <4 x i32> zeroinitializer, %555
  %557 = icmp slt <4 x i32> %555, zeroinitializer
  %558 = select <4 x i1> %557, <4 x i32> %556, <4 x i32> %555
  %559 = add nuw <4 x i32> %558, <i32 32, i32 32, i32 32, i32 32>
  %560 = lshr <4 x i32> %559, <i32 6, i32 6, i32 6, i32 6>
  %561 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %550, <4 x i32> %560) #5
  %562 = lshr <8 x i16> %561, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %563 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %534, <8 x i16> %562) #5
  %564 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %563, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %565 = icmp slt <16 x i8> %564, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %566 = select <16 x i1> %565, <16 x i8> %564, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %567 = bitcast i8* %508 to <16 x i8>*
  store <16 x i8> %566, <16 x i8>* %567, align 16
  %568 = getelementptr inbounds i16, i16* %10, i64 144
  %569 = getelementptr inbounds i16, i16* %11, i64 144
  %570 = getelementptr inbounds i8, i8* %508, i64 16
  %571 = bitcast i16* %568 to <8 x i16>*
  %572 = load <8 x i16>, <8 x i16>* %571, align 16
  %573 = bitcast i16* %569 to <8 x i16>*
  %574 = load <8 x i16>, <8 x i16>* %573, align 16
  %575 = shufflevector <8 x i16> %572, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %576 = zext <4 x i16> %575 to <4 x i32>
  %577 = shufflevector <8 x i16> %574, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %578 = zext <4 x i16> %577 to <4 x i32>
  %579 = sub nsw <4 x i32> %576, %578
  %580 = sub nsw <4 x i32> zeroinitializer, %579
  %581 = icmp slt <4 x i32> %579, zeroinitializer
  %582 = select <4 x i1> %581, <4 x i32> %580, <4 x i32> %579
  %583 = add nuw nsw <4 x i32> %582, <i32 32, i32 32, i32 32, i32 32>
  %584 = lshr <4 x i32> %583, <i32 6, i32 6, i32 6, i32 6>
  %585 = shufflevector <8 x i16> %572, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %586 = shufflevector <8 x i16> %574, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %587 = bitcast <8 x i16> %585 to <4 x i32>
  %588 = bitcast <8 x i16> %586 to <4 x i32>
  %589 = sub <4 x i32> %587, %588
  %590 = sub <4 x i32> zeroinitializer, %589
  %591 = icmp slt <4 x i32> %589, zeroinitializer
  %592 = select <4 x i1> %591, <4 x i32> %590, <4 x i32> %589
  %593 = add nuw <4 x i32> %592, <i32 32, i32 32, i32 32, i32 32>
  %594 = lshr <4 x i32> %593, <i32 6, i32 6, i32 6, i32 6>
  %595 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %584, <4 x i32> %594) #5
  %596 = lshr <8 x i16> %595, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %597 = getelementptr inbounds i16, i16* %10, i64 152
  %598 = bitcast i16* %597 to <8 x i16>*
  %599 = load <8 x i16>, <8 x i16>* %598, align 16
  %600 = getelementptr inbounds i16, i16* %11, i64 152
  %601 = bitcast i16* %600 to <8 x i16>*
  %602 = load <8 x i16>, <8 x i16>* %601, align 16
  %603 = shufflevector <8 x i16> %599, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %604 = zext <4 x i16> %603 to <4 x i32>
  %605 = shufflevector <8 x i16> %602, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %606 = zext <4 x i16> %605 to <4 x i32>
  %607 = sub nsw <4 x i32> %604, %606
  %608 = sub nsw <4 x i32> zeroinitializer, %607
  %609 = icmp slt <4 x i32> %607, zeroinitializer
  %610 = select <4 x i1> %609, <4 x i32> %608, <4 x i32> %607
  %611 = add nuw nsw <4 x i32> %610, <i32 32, i32 32, i32 32, i32 32>
  %612 = lshr <4 x i32> %611, <i32 6, i32 6, i32 6, i32 6>
  %613 = shufflevector <8 x i16> %599, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %614 = shufflevector <8 x i16> %602, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %615 = bitcast <8 x i16> %613 to <4 x i32>
  %616 = bitcast <8 x i16> %614 to <4 x i32>
  %617 = sub <4 x i32> %615, %616
  %618 = sub <4 x i32> zeroinitializer, %617
  %619 = icmp slt <4 x i32> %617, zeroinitializer
  %620 = select <4 x i1> %619, <4 x i32> %618, <4 x i32> %617
  %621 = add nuw <4 x i32> %620, <i32 32, i32 32, i32 32, i32 32>
  %622 = lshr <4 x i32> %621, <i32 6, i32 6, i32 6, i32 6>
  %623 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %612, <4 x i32> %622) #5
  %624 = lshr <8 x i16> %623, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %625 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %596, <8 x i16> %624) #5
  %626 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %625, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %627 = icmp slt <16 x i8> %626, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %628 = select <16 x i1> %627, <16 x i8> %626, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %629 = bitcast i8* %570 to <16 x i8>*
  store <16 x i8> %628, <16 x i8>* %629, align 16
  %630 = getelementptr inbounds i16, i16* %10, i64 160
  %631 = getelementptr inbounds i16, i16* %11, i64 160
  %632 = getelementptr inbounds i8, i8* %508, i64 32
  %633 = bitcast i16* %630 to <8 x i16>*
  %634 = load <8 x i16>, <8 x i16>* %633, align 16
  %635 = bitcast i16* %631 to <8 x i16>*
  %636 = load <8 x i16>, <8 x i16>* %635, align 16
  %637 = shufflevector <8 x i16> %634, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %638 = zext <4 x i16> %637 to <4 x i32>
  %639 = shufflevector <8 x i16> %636, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %640 = zext <4 x i16> %639 to <4 x i32>
  %641 = sub nsw <4 x i32> %638, %640
  %642 = sub nsw <4 x i32> zeroinitializer, %641
  %643 = icmp slt <4 x i32> %641, zeroinitializer
  %644 = select <4 x i1> %643, <4 x i32> %642, <4 x i32> %641
  %645 = add nuw nsw <4 x i32> %644, <i32 32, i32 32, i32 32, i32 32>
  %646 = lshr <4 x i32> %645, <i32 6, i32 6, i32 6, i32 6>
  %647 = shufflevector <8 x i16> %634, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %648 = shufflevector <8 x i16> %636, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %649 = bitcast <8 x i16> %647 to <4 x i32>
  %650 = bitcast <8 x i16> %648 to <4 x i32>
  %651 = sub <4 x i32> %649, %650
  %652 = sub <4 x i32> zeroinitializer, %651
  %653 = icmp slt <4 x i32> %651, zeroinitializer
  %654 = select <4 x i1> %653, <4 x i32> %652, <4 x i32> %651
  %655 = add nuw <4 x i32> %654, <i32 32, i32 32, i32 32, i32 32>
  %656 = lshr <4 x i32> %655, <i32 6, i32 6, i32 6, i32 6>
  %657 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %646, <4 x i32> %656) #5
  %658 = lshr <8 x i16> %657, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %659 = getelementptr inbounds i16, i16* %10, i64 168
  %660 = bitcast i16* %659 to <8 x i16>*
  %661 = load <8 x i16>, <8 x i16>* %660, align 16
  %662 = getelementptr inbounds i16, i16* %11, i64 168
  %663 = bitcast i16* %662 to <8 x i16>*
  %664 = load <8 x i16>, <8 x i16>* %663, align 16
  %665 = shufflevector <8 x i16> %661, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %666 = zext <4 x i16> %665 to <4 x i32>
  %667 = shufflevector <8 x i16> %664, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %668 = zext <4 x i16> %667 to <4 x i32>
  %669 = sub nsw <4 x i32> %666, %668
  %670 = sub nsw <4 x i32> zeroinitializer, %669
  %671 = icmp slt <4 x i32> %669, zeroinitializer
  %672 = select <4 x i1> %671, <4 x i32> %670, <4 x i32> %669
  %673 = add nuw nsw <4 x i32> %672, <i32 32, i32 32, i32 32, i32 32>
  %674 = lshr <4 x i32> %673, <i32 6, i32 6, i32 6, i32 6>
  %675 = shufflevector <8 x i16> %661, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %676 = shufflevector <8 x i16> %664, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %677 = bitcast <8 x i16> %675 to <4 x i32>
  %678 = bitcast <8 x i16> %676 to <4 x i32>
  %679 = sub <4 x i32> %677, %678
  %680 = sub <4 x i32> zeroinitializer, %679
  %681 = icmp slt <4 x i32> %679, zeroinitializer
  %682 = select <4 x i1> %681, <4 x i32> %680, <4 x i32> %679
  %683 = add nuw <4 x i32> %682, <i32 32, i32 32, i32 32, i32 32>
  %684 = lshr <4 x i32> %683, <i32 6, i32 6, i32 6, i32 6>
  %685 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %674, <4 x i32> %684) #5
  %686 = lshr <8 x i16> %685, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %687 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %658, <8 x i16> %686) #5
  %688 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %687, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %689 = icmp slt <16 x i8> %688, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %690 = select <16 x i1> %689, <16 x i8> %688, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %691 = bitcast i8* %632 to <16 x i8>*
  store <16 x i8> %690, <16 x i8>* %691, align 16
  %692 = getelementptr inbounds i16, i16* %10, i64 176
  %693 = getelementptr inbounds i16, i16* %11, i64 176
  %694 = getelementptr inbounds i8, i8* %508, i64 48
  %695 = bitcast i16* %692 to <8 x i16>*
  %696 = load <8 x i16>, <8 x i16>* %695, align 16
  %697 = bitcast i16* %693 to <8 x i16>*
  %698 = load <8 x i16>, <8 x i16>* %697, align 16
  %699 = shufflevector <8 x i16> %696, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %700 = zext <4 x i16> %699 to <4 x i32>
  %701 = shufflevector <8 x i16> %698, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %702 = zext <4 x i16> %701 to <4 x i32>
  %703 = sub nsw <4 x i32> %700, %702
  %704 = sub nsw <4 x i32> zeroinitializer, %703
  %705 = icmp slt <4 x i32> %703, zeroinitializer
  %706 = select <4 x i1> %705, <4 x i32> %704, <4 x i32> %703
  %707 = add nuw nsw <4 x i32> %706, <i32 32, i32 32, i32 32, i32 32>
  %708 = lshr <4 x i32> %707, <i32 6, i32 6, i32 6, i32 6>
  %709 = shufflevector <8 x i16> %696, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %710 = shufflevector <8 x i16> %698, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %711 = bitcast <8 x i16> %709 to <4 x i32>
  %712 = bitcast <8 x i16> %710 to <4 x i32>
  %713 = sub <4 x i32> %711, %712
  %714 = sub <4 x i32> zeroinitializer, %713
  %715 = icmp slt <4 x i32> %713, zeroinitializer
  %716 = select <4 x i1> %715, <4 x i32> %714, <4 x i32> %713
  %717 = add nuw <4 x i32> %716, <i32 32, i32 32, i32 32, i32 32>
  %718 = lshr <4 x i32> %717, <i32 6, i32 6, i32 6, i32 6>
  %719 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %708, <4 x i32> %718) #5
  %720 = lshr <8 x i16> %719, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %721 = getelementptr inbounds i16, i16* %10, i64 184
  %722 = bitcast i16* %721 to <8 x i16>*
  %723 = load <8 x i16>, <8 x i16>* %722, align 16
  %724 = getelementptr inbounds i16, i16* %11, i64 184
  %725 = bitcast i16* %724 to <8 x i16>*
  %726 = load <8 x i16>, <8 x i16>* %725, align 16
  %727 = shufflevector <8 x i16> %723, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %728 = zext <4 x i16> %727 to <4 x i32>
  %729 = shufflevector <8 x i16> %726, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %730 = zext <4 x i16> %729 to <4 x i32>
  %731 = sub nsw <4 x i32> %728, %730
  %732 = sub nsw <4 x i32> zeroinitializer, %731
  %733 = icmp slt <4 x i32> %731, zeroinitializer
  %734 = select <4 x i1> %733, <4 x i32> %732, <4 x i32> %731
  %735 = add nuw nsw <4 x i32> %734, <i32 32, i32 32, i32 32, i32 32>
  %736 = lshr <4 x i32> %735, <i32 6, i32 6, i32 6, i32 6>
  %737 = shufflevector <8 x i16> %723, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %738 = shufflevector <8 x i16> %726, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %739 = bitcast <8 x i16> %737 to <4 x i32>
  %740 = bitcast <8 x i16> %738 to <4 x i32>
  %741 = sub <4 x i32> %739, %740
  %742 = sub <4 x i32> zeroinitializer, %741
  %743 = icmp slt <4 x i32> %741, zeroinitializer
  %744 = select <4 x i1> %743, <4 x i32> %742, <4 x i32> %741
  %745 = add nuw <4 x i32> %744, <i32 32, i32 32, i32 32, i32 32>
  %746 = lshr <4 x i32> %745, <i32 6, i32 6, i32 6, i32 6>
  %747 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %736, <4 x i32> %746) #5
  %748 = lshr <8 x i16> %747, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %749 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %720, <8 x i16> %748) #5
  %750 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %749, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %751 = icmp slt <16 x i8> %750, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %752 = select <16 x i1> %751, <16 x i8> %750, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %753 = bitcast i8* %694 to <16 x i8>*
  store <16 x i8> %752, <16 x i8>* %753, align 16
  %754 = getelementptr inbounds i16, i16* %10, i64 192
  %755 = getelementptr inbounds i16, i16* %11, i64 192
  %756 = getelementptr inbounds i8, i8* %508, i64 64
  %757 = bitcast i16* %754 to <8 x i16>*
  %758 = load <8 x i16>, <8 x i16>* %757, align 16
  %759 = bitcast i16* %755 to <8 x i16>*
  %760 = load <8 x i16>, <8 x i16>* %759, align 16
  %761 = shufflevector <8 x i16> %758, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %762 = zext <4 x i16> %761 to <4 x i32>
  %763 = shufflevector <8 x i16> %760, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %764 = zext <4 x i16> %763 to <4 x i32>
  %765 = sub nsw <4 x i32> %762, %764
  %766 = sub nsw <4 x i32> zeroinitializer, %765
  %767 = icmp slt <4 x i32> %765, zeroinitializer
  %768 = select <4 x i1> %767, <4 x i32> %766, <4 x i32> %765
  %769 = add nuw nsw <4 x i32> %768, <i32 32, i32 32, i32 32, i32 32>
  %770 = lshr <4 x i32> %769, <i32 6, i32 6, i32 6, i32 6>
  %771 = shufflevector <8 x i16> %758, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %772 = shufflevector <8 x i16> %760, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %773 = bitcast <8 x i16> %771 to <4 x i32>
  %774 = bitcast <8 x i16> %772 to <4 x i32>
  %775 = sub <4 x i32> %773, %774
  %776 = sub <4 x i32> zeroinitializer, %775
  %777 = icmp slt <4 x i32> %775, zeroinitializer
  %778 = select <4 x i1> %777, <4 x i32> %776, <4 x i32> %775
  %779 = add nuw <4 x i32> %778, <i32 32, i32 32, i32 32, i32 32>
  %780 = lshr <4 x i32> %779, <i32 6, i32 6, i32 6, i32 6>
  %781 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %770, <4 x i32> %780) #5
  %782 = lshr <8 x i16> %781, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %783 = getelementptr inbounds i16, i16* %10, i64 200
  %784 = bitcast i16* %783 to <8 x i16>*
  %785 = load <8 x i16>, <8 x i16>* %784, align 16
  %786 = getelementptr inbounds i16, i16* %11, i64 200
  %787 = bitcast i16* %786 to <8 x i16>*
  %788 = load <8 x i16>, <8 x i16>* %787, align 16
  %789 = shufflevector <8 x i16> %785, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %790 = zext <4 x i16> %789 to <4 x i32>
  %791 = shufflevector <8 x i16> %788, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %792 = zext <4 x i16> %791 to <4 x i32>
  %793 = sub nsw <4 x i32> %790, %792
  %794 = sub nsw <4 x i32> zeroinitializer, %793
  %795 = icmp slt <4 x i32> %793, zeroinitializer
  %796 = select <4 x i1> %795, <4 x i32> %794, <4 x i32> %793
  %797 = add nuw nsw <4 x i32> %796, <i32 32, i32 32, i32 32, i32 32>
  %798 = lshr <4 x i32> %797, <i32 6, i32 6, i32 6, i32 6>
  %799 = shufflevector <8 x i16> %785, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %800 = shufflevector <8 x i16> %788, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %801 = bitcast <8 x i16> %799 to <4 x i32>
  %802 = bitcast <8 x i16> %800 to <4 x i32>
  %803 = sub <4 x i32> %801, %802
  %804 = sub <4 x i32> zeroinitializer, %803
  %805 = icmp slt <4 x i32> %803, zeroinitializer
  %806 = select <4 x i1> %805, <4 x i32> %804, <4 x i32> %803
  %807 = add nuw <4 x i32> %806, <i32 32, i32 32, i32 32, i32 32>
  %808 = lshr <4 x i32> %807, <i32 6, i32 6, i32 6, i32 6>
  %809 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %798, <4 x i32> %808) #5
  %810 = lshr <8 x i16> %809, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %811 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %782, <8 x i16> %810) #5
  %812 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %811, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %813 = icmp slt <16 x i8> %812, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %814 = select <16 x i1> %813, <16 x i8> %812, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %815 = bitcast i8* %756 to <16 x i8>*
  store <16 x i8> %814, <16 x i8>* %815, align 16
  %816 = getelementptr inbounds i16, i16* %10, i64 208
  %817 = getelementptr inbounds i16, i16* %11, i64 208
  %818 = getelementptr inbounds i8, i8* %756, i64 16
  %819 = bitcast i16* %816 to <8 x i16>*
  %820 = load <8 x i16>, <8 x i16>* %819, align 16
  %821 = bitcast i16* %817 to <8 x i16>*
  %822 = load <8 x i16>, <8 x i16>* %821, align 16
  %823 = shufflevector <8 x i16> %820, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %824 = zext <4 x i16> %823 to <4 x i32>
  %825 = shufflevector <8 x i16> %822, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %826 = zext <4 x i16> %825 to <4 x i32>
  %827 = sub nsw <4 x i32> %824, %826
  %828 = sub nsw <4 x i32> zeroinitializer, %827
  %829 = icmp slt <4 x i32> %827, zeroinitializer
  %830 = select <4 x i1> %829, <4 x i32> %828, <4 x i32> %827
  %831 = add nuw nsw <4 x i32> %830, <i32 32, i32 32, i32 32, i32 32>
  %832 = lshr <4 x i32> %831, <i32 6, i32 6, i32 6, i32 6>
  %833 = shufflevector <8 x i16> %820, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %834 = shufflevector <8 x i16> %822, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %835 = bitcast <8 x i16> %833 to <4 x i32>
  %836 = bitcast <8 x i16> %834 to <4 x i32>
  %837 = sub <4 x i32> %835, %836
  %838 = sub <4 x i32> zeroinitializer, %837
  %839 = icmp slt <4 x i32> %837, zeroinitializer
  %840 = select <4 x i1> %839, <4 x i32> %838, <4 x i32> %837
  %841 = add nuw <4 x i32> %840, <i32 32, i32 32, i32 32, i32 32>
  %842 = lshr <4 x i32> %841, <i32 6, i32 6, i32 6, i32 6>
  %843 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %832, <4 x i32> %842) #5
  %844 = lshr <8 x i16> %843, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %845 = getelementptr inbounds i16, i16* %10, i64 216
  %846 = bitcast i16* %845 to <8 x i16>*
  %847 = load <8 x i16>, <8 x i16>* %846, align 16
  %848 = getelementptr inbounds i16, i16* %11, i64 216
  %849 = bitcast i16* %848 to <8 x i16>*
  %850 = load <8 x i16>, <8 x i16>* %849, align 16
  %851 = shufflevector <8 x i16> %847, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %852 = zext <4 x i16> %851 to <4 x i32>
  %853 = shufflevector <8 x i16> %850, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %854 = zext <4 x i16> %853 to <4 x i32>
  %855 = sub nsw <4 x i32> %852, %854
  %856 = sub nsw <4 x i32> zeroinitializer, %855
  %857 = icmp slt <4 x i32> %855, zeroinitializer
  %858 = select <4 x i1> %857, <4 x i32> %856, <4 x i32> %855
  %859 = add nuw nsw <4 x i32> %858, <i32 32, i32 32, i32 32, i32 32>
  %860 = lshr <4 x i32> %859, <i32 6, i32 6, i32 6, i32 6>
  %861 = shufflevector <8 x i16> %847, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %862 = shufflevector <8 x i16> %850, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %863 = bitcast <8 x i16> %861 to <4 x i32>
  %864 = bitcast <8 x i16> %862 to <4 x i32>
  %865 = sub <4 x i32> %863, %864
  %866 = sub <4 x i32> zeroinitializer, %865
  %867 = icmp slt <4 x i32> %865, zeroinitializer
  %868 = select <4 x i1> %867, <4 x i32> %866, <4 x i32> %865
  %869 = add nuw <4 x i32> %868, <i32 32, i32 32, i32 32, i32 32>
  %870 = lshr <4 x i32> %869, <i32 6, i32 6, i32 6, i32 6>
  %871 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %860, <4 x i32> %870) #5
  %872 = lshr <8 x i16> %871, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %873 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %844, <8 x i16> %872) #5
  %874 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %873, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %875 = icmp slt <16 x i8> %874, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %876 = select <16 x i1> %875, <16 x i8> %874, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %877 = bitcast i8* %818 to <16 x i8>*
  store <16 x i8> %876, <16 x i8>* %877, align 16
  %878 = getelementptr inbounds i16, i16* %10, i64 224
  %879 = getelementptr inbounds i16, i16* %11, i64 224
  %880 = getelementptr inbounds i8, i8* %756, i64 32
  %881 = bitcast i16* %878 to <8 x i16>*
  %882 = load <8 x i16>, <8 x i16>* %881, align 16
  %883 = bitcast i16* %879 to <8 x i16>*
  %884 = load <8 x i16>, <8 x i16>* %883, align 16
  %885 = shufflevector <8 x i16> %882, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %886 = zext <4 x i16> %885 to <4 x i32>
  %887 = shufflevector <8 x i16> %884, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %888 = zext <4 x i16> %887 to <4 x i32>
  %889 = sub nsw <4 x i32> %886, %888
  %890 = sub nsw <4 x i32> zeroinitializer, %889
  %891 = icmp slt <4 x i32> %889, zeroinitializer
  %892 = select <4 x i1> %891, <4 x i32> %890, <4 x i32> %889
  %893 = add nuw nsw <4 x i32> %892, <i32 32, i32 32, i32 32, i32 32>
  %894 = lshr <4 x i32> %893, <i32 6, i32 6, i32 6, i32 6>
  %895 = shufflevector <8 x i16> %882, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %896 = shufflevector <8 x i16> %884, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %897 = bitcast <8 x i16> %895 to <4 x i32>
  %898 = bitcast <8 x i16> %896 to <4 x i32>
  %899 = sub <4 x i32> %897, %898
  %900 = sub <4 x i32> zeroinitializer, %899
  %901 = icmp slt <4 x i32> %899, zeroinitializer
  %902 = select <4 x i1> %901, <4 x i32> %900, <4 x i32> %899
  %903 = add nuw <4 x i32> %902, <i32 32, i32 32, i32 32, i32 32>
  %904 = lshr <4 x i32> %903, <i32 6, i32 6, i32 6, i32 6>
  %905 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %894, <4 x i32> %904) #5
  %906 = lshr <8 x i16> %905, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %907 = getelementptr inbounds i16, i16* %10, i64 232
  %908 = bitcast i16* %907 to <8 x i16>*
  %909 = load <8 x i16>, <8 x i16>* %908, align 16
  %910 = getelementptr inbounds i16, i16* %11, i64 232
  %911 = bitcast i16* %910 to <8 x i16>*
  %912 = load <8 x i16>, <8 x i16>* %911, align 16
  %913 = shufflevector <8 x i16> %909, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %914 = zext <4 x i16> %913 to <4 x i32>
  %915 = shufflevector <8 x i16> %912, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %916 = zext <4 x i16> %915 to <4 x i32>
  %917 = sub nsw <4 x i32> %914, %916
  %918 = sub nsw <4 x i32> zeroinitializer, %917
  %919 = icmp slt <4 x i32> %917, zeroinitializer
  %920 = select <4 x i1> %919, <4 x i32> %918, <4 x i32> %917
  %921 = add nuw nsw <4 x i32> %920, <i32 32, i32 32, i32 32, i32 32>
  %922 = lshr <4 x i32> %921, <i32 6, i32 6, i32 6, i32 6>
  %923 = shufflevector <8 x i16> %909, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %924 = shufflevector <8 x i16> %912, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %925 = bitcast <8 x i16> %923 to <4 x i32>
  %926 = bitcast <8 x i16> %924 to <4 x i32>
  %927 = sub <4 x i32> %925, %926
  %928 = sub <4 x i32> zeroinitializer, %927
  %929 = icmp slt <4 x i32> %927, zeroinitializer
  %930 = select <4 x i1> %929, <4 x i32> %928, <4 x i32> %927
  %931 = add nuw <4 x i32> %930, <i32 32, i32 32, i32 32, i32 32>
  %932 = lshr <4 x i32> %931, <i32 6, i32 6, i32 6, i32 6>
  %933 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %922, <4 x i32> %932) #5
  %934 = lshr <8 x i16> %933, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %935 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %906, <8 x i16> %934) #5
  %936 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %935, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %937 = icmp slt <16 x i8> %936, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %938 = select <16 x i1> %937, <16 x i8> %936, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %939 = bitcast i8* %880 to <16 x i8>*
  store <16 x i8> %938, <16 x i8>* %939, align 16
  %940 = getelementptr inbounds i16, i16* %10, i64 240
  %941 = getelementptr inbounds i16, i16* %11, i64 240
  %942 = getelementptr inbounds i8, i8* %756, i64 48
  %943 = bitcast i16* %940 to <8 x i16>*
  %944 = load <8 x i16>, <8 x i16>* %943, align 16
  %945 = bitcast i16* %941 to <8 x i16>*
  %946 = load <8 x i16>, <8 x i16>* %945, align 16
  %947 = shufflevector <8 x i16> %944, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %948 = zext <4 x i16> %947 to <4 x i32>
  %949 = shufflevector <8 x i16> %946, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %950 = zext <4 x i16> %949 to <4 x i32>
  %951 = sub nsw <4 x i32> %948, %950
  %952 = sub nsw <4 x i32> zeroinitializer, %951
  %953 = icmp slt <4 x i32> %951, zeroinitializer
  %954 = select <4 x i1> %953, <4 x i32> %952, <4 x i32> %951
  %955 = add nuw nsw <4 x i32> %954, <i32 32, i32 32, i32 32, i32 32>
  %956 = lshr <4 x i32> %955, <i32 6, i32 6, i32 6, i32 6>
  %957 = shufflevector <8 x i16> %944, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %958 = shufflevector <8 x i16> %946, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %959 = bitcast <8 x i16> %957 to <4 x i32>
  %960 = bitcast <8 x i16> %958 to <4 x i32>
  %961 = sub <4 x i32> %959, %960
  %962 = sub <4 x i32> zeroinitializer, %961
  %963 = icmp slt <4 x i32> %961, zeroinitializer
  %964 = select <4 x i1> %963, <4 x i32> %962, <4 x i32> %961
  %965 = add nuw <4 x i32> %964, <i32 32, i32 32, i32 32, i32 32>
  %966 = lshr <4 x i32> %965, <i32 6, i32 6, i32 6, i32 6>
  %967 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %956, <4 x i32> %966) #5
  %968 = lshr <8 x i16> %967, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %969 = getelementptr inbounds i16, i16* %10, i64 248
  %970 = bitcast i16* %969 to <8 x i16>*
  %971 = load <8 x i16>, <8 x i16>* %970, align 16
  %972 = getelementptr inbounds i16, i16* %11, i64 248
  %973 = bitcast i16* %972 to <8 x i16>*
  %974 = load <8 x i16>, <8 x i16>* %973, align 16
  %975 = shufflevector <8 x i16> %971, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %976 = zext <4 x i16> %975 to <4 x i32>
  %977 = shufflevector <8 x i16> %974, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %978 = zext <4 x i16> %977 to <4 x i32>
  %979 = sub nsw <4 x i32> %976, %978
  %980 = sub nsw <4 x i32> zeroinitializer, %979
  %981 = icmp slt <4 x i32> %979, zeroinitializer
  %982 = select <4 x i1> %981, <4 x i32> %980, <4 x i32> %979
  %983 = add nuw nsw <4 x i32> %982, <i32 32, i32 32, i32 32, i32 32>
  %984 = lshr <4 x i32> %983, <i32 6, i32 6, i32 6, i32 6>
  %985 = shufflevector <8 x i16> %971, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %986 = shufflevector <8 x i16> %974, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %987 = bitcast <8 x i16> %985 to <4 x i32>
  %988 = bitcast <8 x i16> %986 to <4 x i32>
  %989 = sub <4 x i32> %987, %988
  %990 = sub <4 x i32> zeroinitializer, %989
  %991 = icmp slt <4 x i32> %989, zeroinitializer
  %992 = select <4 x i1> %991, <4 x i32> %990, <4 x i32> %989
  %993 = add nuw <4 x i32> %992, <i32 32, i32 32, i32 32, i32 32>
  %994 = lshr <4 x i32> %993, <i32 6, i32 6, i32 6, i32 6>
  %995 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %984, <4 x i32> %994) #5
  %996 = lshr <8 x i16> %995, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %997 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %968, <8 x i16> %996) #5
  %998 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %997, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %999 = icmp slt <16 x i8> %998, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1000 = select <16 x i1> %999, <16 x i8> %998, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1001 = bitcast i8* %942 to <16 x i8>*
  store <16 x i8> %1000, <16 x i8>* %1001, align 16
  %1002 = getelementptr inbounds i16, i16* %10, i64 256
  %1003 = getelementptr inbounds i16, i16* %11, i64 256
  %1004 = getelementptr inbounds i8, i8* %756, i64 %7
  %1005 = bitcast i16* %1002 to <8 x i16>*
  %1006 = load <8 x i16>, <8 x i16>* %1005, align 16
  %1007 = bitcast i16* %1003 to <8 x i16>*
  %1008 = load <8 x i16>, <8 x i16>* %1007, align 16
  %1009 = shufflevector <8 x i16> %1006, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1010 = zext <4 x i16> %1009 to <4 x i32>
  %1011 = shufflevector <8 x i16> %1008, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1012 = zext <4 x i16> %1011 to <4 x i32>
  %1013 = sub nsw <4 x i32> %1010, %1012
  %1014 = sub nsw <4 x i32> zeroinitializer, %1013
  %1015 = icmp slt <4 x i32> %1013, zeroinitializer
  %1016 = select <4 x i1> %1015, <4 x i32> %1014, <4 x i32> %1013
  %1017 = add nuw nsw <4 x i32> %1016, <i32 32, i32 32, i32 32, i32 32>
  %1018 = lshr <4 x i32> %1017, <i32 6, i32 6, i32 6, i32 6>
  %1019 = shufflevector <8 x i16> %1006, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1020 = shufflevector <8 x i16> %1008, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1021 = bitcast <8 x i16> %1019 to <4 x i32>
  %1022 = bitcast <8 x i16> %1020 to <4 x i32>
  %1023 = sub <4 x i32> %1021, %1022
  %1024 = sub <4 x i32> zeroinitializer, %1023
  %1025 = icmp slt <4 x i32> %1023, zeroinitializer
  %1026 = select <4 x i1> %1025, <4 x i32> %1024, <4 x i32> %1023
  %1027 = add nuw <4 x i32> %1026, <i32 32, i32 32, i32 32, i32 32>
  %1028 = lshr <4 x i32> %1027, <i32 6, i32 6, i32 6, i32 6>
  %1029 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1018, <4 x i32> %1028) #5
  %1030 = lshr <8 x i16> %1029, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1031 = getelementptr inbounds i16, i16* %10, i64 264
  %1032 = bitcast i16* %1031 to <8 x i16>*
  %1033 = load <8 x i16>, <8 x i16>* %1032, align 16
  %1034 = getelementptr inbounds i16, i16* %11, i64 264
  %1035 = bitcast i16* %1034 to <8 x i16>*
  %1036 = load <8 x i16>, <8 x i16>* %1035, align 16
  %1037 = shufflevector <8 x i16> %1033, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1038 = zext <4 x i16> %1037 to <4 x i32>
  %1039 = shufflevector <8 x i16> %1036, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1040 = zext <4 x i16> %1039 to <4 x i32>
  %1041 = sub nsw <4 x i32> %1038, %1040
  %1042 = sub nsw <4 x i32> zeroinitializer, %1041
  %1043 = icmp slt <4 x i32> %1041, zeroinitializer
  %1044 = select <4 x i1> %1043, <4 x i32> %1042, <4 x i32> %1041
  %1045 = add nuw nsw <4 x i32> %1044, <i32 32, i32 32, i32 32, i32 32>
  %1046 = lshr <4 x i32> %1045, <i32 6, i32 6, i32 6, i32 6>
  %1047 = shufflevector <8 x i16> %1033, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1048 = shufflevector <8 x i16> %1036, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1049 = bitcast <8 x i16> %1047 to <4 x i32>
  %1050 = bitcast <8 x i16> %1048 to <4 x i32>
  %1051 = sub <4 x i32> %1049, %1050
  %1052 = sub <4 x i32> zeroinitializer, %1051
  %1053 = icmp slt <4 x i32> %1051, zeroinitializer
  %1054 = select <4 x i1> %1053, <4 x i32> %1052, <4 x i32> %1051
  %1055 = add nuw <4 x i32> %1054, <i32 32, i32 32, i32 32, i32 32>
  %1056 = lshr <4 x i32> %1055, <i32 6, i32 6, i32 6, i32 6>
  %1057 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1046, <4 x i32> %1056) #5
  %1058 = lshr <8 x i16> %1057, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1059 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1030, <8 x i16> %1058) #5
  %1060 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1059, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1061 = icmp slt <16 x i8> %1060, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1062 = select <16 x i1> %1061, <16 x i8> %1060, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1063 = bitcast i8* %1004 to <16 x i8>*
  store <16 x i8> %1062, <16 x i8>* %1063, align 16
  %1064 = getelementptr inbounds i16, i16* %10, i64 272
  %1065 = getelementptr inbounds i16, i16* %11, i64 272
  %1066 = getelementptr inbounds i8, i8* %1004, i64 16
  %1067 = bitcast i16* %1064 to <8 x i16>*
  %1068 = load <8 x i16>, <8 x i16>* %1067, align 16
  %1069 = bitcast i16* %1065 to <8 x i16>*
  %1070 = load <8 x i16>, <8 x i16>* %1069, align 16
  %1071 = shufflevector <8 x i16> %1068, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1072 = zext <4 x i16> %1071 to <4 x i32>
  %1073 = shufflevector <8 x i16> %1070, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1074 = zext <4 x i16> %1073 to <4 x i32>
  %1075 = sub nsw <4 x i32> %1072, %1074
  %1076 = sub nsw <4 x i32> zeroinitializer, %1075
  %1077 = icmp slt <4 x i32> %1075, zeroinitializer
  %1078 = select <4 x i1> %1077, <4 x i32> %1076, <4 x i32> %1075
  %1079 = add nuw nsw <4 x i32> %1078, <i32 32, i32 32, i32 32, i32 32>
  %1080 = lshr <4 x i32> %1079, <i32 6, i32 6, i32 6, i32 6>
  %1081 = shufflevector <8 x i16> %1068, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1082 = shufflevector <8 x i16> %1070, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1083 = bitcast <8 x i16> %1081 to <4 x i32>
  %1084 = bitcast <8 x i16> %1082 to <4 x i32>
  %1085 = sub <4 x i32> %1083, %1084
  %1086 = sub <4 x i32> zeroinitializer, %1085
  %1087 = icmp slt <4 x i32> %1085, zeroinitializer
  %1088 = select <4 x i1> %1087, <4 x i32> %1086, <4 x i32> %1085
  %1089 = add nuw <4 x i32> %1088, <i32 32, i32 32, i32 32, i32 32>
  %1090 = lshr <4 x i32> %1089, <i32 6, i32 6, i32 6, i32 6>
  %1091 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1080, <4 x i32> %1090) #5
  %1092 = lshr <8 x i16> %1091, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1093 = getelementptr inbounds i16, i16* %10, i64 280
  %1094 = bitcast i16* %1093 to <8 x i16>*
  %1095 = load <8 x i16>, <8 x i16>* %1094, align 16
  %1096 = getelementptr inbounds i16, i16* %11, i64 280
  %1097 = bitcast i16* %1096 to <8 x i16>*
  %1098 = load <8 x i16>, <8 x i16>* %1097, align 16
  %1099 = shufflevector <8 x i16> %1095, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1100 = zext <4 x i16> %1099 to <4 x i32>
  %1101 = shufflevector <8 x i16> %1098, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1102 = zext <4 x i16> %1101 to <4 x i32>
  %1103 = sub nsw <4 x i32> %1100, %1102
  %1104 = sub nsw <4 x i32> zeroinitializer, %1103
  %1105 = icmp slt <4 x i32> %1103, zeroinitializer
  %1106 = select <4 x i1> %1105, <4 x i32> %1104, <4 x i32> %1103
  %1107 = add nuw nsw <4 x i32> %1106, <i32 32, i32 32, i32 32, i32 32>
  %1108 = lshr <4 x i32> %1107, <i32 6, i32 6, i32 6, i32 6>
  %1109 = shufflevector <8 x i16> %1095, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1110 = shufflevector <8 x i16> %1098, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1111 = bitcast <8 x i16> %1109 to <4 x i32>
  %1112 = bitcast <8 x i16> %1110 to <4 x i32>
  %1113 = sub <4 x i32> %1111, %1112
  %1114 = sub <4 x i32> zeroinitializer, %1113
  %1115 = icmp slt <4 x i32> %1113, zeroinitializer
  %1116 = select <4 x i1> %1115, <4 x i32> %1114, <4 x i32> %1113
  %1117 = add nuw <4 x i32> %1116, <i32 32, i32 32, i32 32, i32 32>
  %1118 = lshr <4 x i32> %1117, <i32 6, i32 6, i32 6, i32 6>
  %1119 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1108, <4 x i32> %1118) #5
  %1120 = lshr <8 x i16> %1119, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1121 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1092, <8 x i16> %1120) #5
  %1122 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1121, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1123 = icmp slt <16 x i8> %1122, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1124 = select <16 x i1> %1123, <16 x i8> %1122, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1125 = bitcast i8* %1066 to <16 x i8>*
  store <16 x i8> %1124, <16 x i8>* %1125, align 16
  %1126 = getelementptr inbounds i16, i16* %10, i64 288
  %1127 = getelementptr inbounds i16, i16* %11, i64 288
  %1128 = getelementptr inbounds i8, i8* %1004, i64 32
  %1129 = bitcast i16* %1126 to <8 x i16>*
  %1130 = load <8 x i16>, <8 x i16>* %1129, align 16
  %1131 = bitcast i16* %1127 to <8 x i16>*
  %1132 = load <8 x i16>, <8 x i16>* %1131, align 16
  %1133 = shufflevector <8 x i16> %1130, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1134 = zext <4 x i16> %1133 to <4 x i32>
  %1135 = shufflevector <8 x i16> %1132, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1136 = zext <4 x i16> %1135 to <4 x i32>
  %1137 = sub nsw <4 x i32> %1134, %1136
  %1138 = sub nsw <4 x i32> zeroinitializer, %1137
  %1139 = icmp slt <4 x i32> %1137, zeroinitializer
  %1140 = select <4 x i1> %1139, <4 x i32> %1138, <4 x i32> %1137
  %1141 = add nuw nsw <4 x i32> %1140, <i32 32, i32 32, i32 32, i32 32>
  %1142 = lshr <4 x i32> %1141, <i32 6, i32 6, i32 6, i32 6>
  %1143 = shufflevector <8 x i16> %1130, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1144 = shufflevector <8 x i16> %1132, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1145 = bitcast <8 x i16> %1143 to <4 x i32>
  %1146 = bitcast <8 x i16> %1144 to <4 x i32>
  %1147 = sub <4 x i32> %1145, %1146
  %1148 = sub <4 x i32> zeroinitializer, %1147
  %1149 = icmp slt <4 x i32> %1147, zeroinitializer
  %1150 = select <4 x i1> %1149, <4 x i32> %1148, <4 x i32> %1147
  %1151 = add nuw <4 x i32> %1150, <i32 32, i32 32, i32 32, i32 32>
  %1152 = lshr <4 x i32> %1151, <i32 6, i32 6, i32 6, i32 6>
  %1153 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1142, <4 x i32> %1152) #5
  %1154 = lshr <8 x i16> %1153, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1155 = getelementptr inbounds i16, i16* %10, i64 296
  %1156 = bitcast i16* %1155 to <8 x i16>*
  %1157 = load <8 x i16>, <8 x i16>* %1156, align 16
  %1158 = getelementptr inbounds i16, i16* %11, i64 296
  %1159 = bitcast i16* %1158 to <8 x i16>*
  %1160 = load <8 x i16>, <8 x i16>* %1159, align 16
  %1161 = shufflevector <8 x i16> %1157, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1162 = zext <4 x i16> %1161 to <4 x i32>
  %1163 = shufflevector <8 x i16> %1160, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1164 = zext <4 x i16> %1163 to <4 x i32>
  %1165 = sub nsw <4 x i32> %1162, %1164
  %1166 = sub nsw <4 x i32> zeroinitializer, %1165
  %1167 = icmp slt <4 x i32> %1165, zeroinitializer
  %1168 = select <4 x i1> %1167, <4 x i32> %1166, <4 x i32> %1165
  %1169 = add nuw nsw <4 x i32> %1168, <i32 32, i32 32, i32 32, i32 32>
  %1170 = lshr <4 x i32> %1169, <i32 6, i32 6, i32 6, i32 6>
  %1171 = shufflevector <8 x i16> %1157, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1172 = shufflevector <8 x i16> %1160, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1173 = bitcast <8 x i16> %1171 to <4 x i32>
  %1174 = bitcast <8 x i16> %1172 to <4 x i32>
  %1175 = sub <4 x i32> %1173, %1174
  %1176 = sub <4 x i32> zeroinitializer, %1175
  %1177 = icmp slt <4 x i32> %1175, zeroinitializer
  %1178 = select <4 x i1> %1177, <4 x i32> %1176, <4 x i32> %1175
  %1179 = add nuw <4 x i32> %1178, <i32 32, i32 32, i32 32, i32 32>
  %1180 = lshr <4 x i32> %1179, <i32 6, i32 6, i32 6, i32 6>
  %1181 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1170, <4 x i32> %1180) #5
  %1182 = lshr <8 x i16> %1181, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1183 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1154, <8 x i16> %1182) #5
  %1184 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1183, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1185 = icmp slt <16 x i8> %1184, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1186 = select <16 x i1> %1185, <16 x i8> %1184, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1187 = bitcast i8* %1128 to <16 x i8>*
  store <16 x i8> %1186, <16 x i8>* %1187, align 16
  %1188 = getelementptr inbounds i16, i16* %10, i64 304
  %1189 = getelementptr inbounds i16, i16* %11, i64 304
  %1190 = getelementptr inbounds i8, i8* %1004, i64 48
  %1191 = bitcast i16* %1188 to <8 x i16>*
  %1192 = load <8 x i16>, <8 x i16>* %1191, align 16
  %1193 = bitcast i16* %1189 to <8 x i16>*
  %1194 = load <8 x i16>, <8 x i16>* %1193, align 16
  %1195 = shufflevector <8 x i16> %1192, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1196 = zext <4 x i16> %1195 to <4 x i32>
  %1197 = shufflevector <8 x i16> %1194, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1198 = zext <4 x i16> %1197 to <4 x i32>
  %1199 = sub nsw <4 x i32> %1196, %1198
  %1200 = sub nsw <4 x i32> zeroinitializer, %1199
  %1201 = icmp slt <4 x i32> %1199, zeroinitializer
  %1202 = select <4 x i1> %1201, <4 x i32> %1200, <4 x i32> %1199
  %1203 = add nuw nsw <4 x i32> %1202, <i32 32, i32 32, i32 32, i32 32>
  %1204 = lshr <4 x i32> %1203, <i32 6, i32 6, i32 6, i32 6>
  %1205 = shufflevector <8 x i16> %1192, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1206 = shufflevector <8 x i16> %1194, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1207 = bitcast <8 x i16> %1205 to <4 x i32>
  %1208 = bitcast <8 x i16> %1206 to <4 x i32>
  %1209 = sub <4 x i32> %1207, %1208
  %1210 = sub <4 x i32> zeroinitializer, %1209
  %1211 = icmp slt <4 x i32> %1209, zeroinitializer
  %1212 = select <4 x i1> %1211, <4 x i32> %1210, <4 x i32> %1209
  %1213 = add nuw <4 x i32> %1212, <i32 32, i32 32, i32 32, i32 32>
  %1214 = lshr <4 x i32> %1213, <i32 6, i32 6, i32 6, i32 6>
  %1215 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1204, <4 x i32> %1214) #5
  %1216 = lshr <8 x i16> %1215, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1217 = getelementptr inbounds i16, i16* %10, i64 312
  %1218 = bitcast i16* %1217 to <8 x i16>*
  %1219 = load <8 x i16>, <8 x i16>* %1218, align 16
  %1220 = getelementptr inbounds i16, i16* %11, i64 312
  %1221 = bitcast i16* %1220 to <8 x i16>*
  %1222 = load <8 x i16>, <8 x i16>* %1221, align 16
  %1223 = shufflevector <8 x i16> %1219, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1224 = zext <4 x i16> %1223 to <4 x i32>
  %1225 = shufflevector <8 x i16> %1222, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1226 = zext <4 x i16> %1225 to <4 x i32>
  %1227 = sub nsw <4 x i32> %1224, %1226
  %1228 = sub nsw <4 x i32> zeroinitializer, %1227
  %1229 = icmp slt <4 x i32> %1227, zeroinitializer
  %1230 = select <4 x i1> %1229, <4 x i32> %1228, <4 x i32> %1227
  %1231 = add nuw nsw <4 x i32> %1230, <i32 32, i32 32, i32 32, i32 32>
  %1232 = lshr <4 x i32> %1231, <i32 6, i32 6, i32 6, i32 6>
  %1233 = shufflevector <8 x i16> %1219, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1234 = shufflevector <8 x i16> %1222, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1235 = bitcast <8 x i16> %1233 to <4 x i32>
  %1236 = bitcast <8 x i16> %1234 to <4 x i32>
  %1237 = sub <4 x i32> %1235, %1236
  %1238 = sub <4 x i32> zeroinitializer, %1237
  %1239 = icmp slt <4 x i32> %1237, zeroinitializer
  %1240 = select <4 x i1> %1239, <4 x i32> %1238, <4 x i32> %1237
  %1241 = add nuw <4 x i32> %1240, <i32 32, i32 32, i32 32, i32 32>
  %1242 = lshr <4 x i32> %1241, <i32 6, i32 6, i32 6, i32 6>
  %1243 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1232, <4 x i32> %1242) #5
  %1244 = lshr <8 x i16> %1243, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1245 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1216, <8 x i16> %1244) #5
  %1246 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1245, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1247 = icmp slt <16 x i8> %1246, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1248 = select <16 x i1> %1247, <16 x i8> %1246, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1249 = bitcast i8* %1190 to <16 x i8>*
  store <16 x i8> %1248, <16 x i8>* %1249, align 16
  %1250 = getelementptr inbounds i16, i16* %10, i64 320
  %1251 = getelementptr inbounds i16, i16* %11, i64 320
  %1252 = getelementptr inbounds i8, i8* %1004, i64 64
  %1253 = bitcast i16* %1250 to <8 x i16>*
  %1254 = load <8 x i16>, <8 x i16>* %1253, align 16
  %1255 = bitcast i16* %1251 to <8 x i16>*
  %1256 = load <8 x i16>, <8 x i16>* %1255, align 16
  %1257 = shufflevector <8 x i16> %1254, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1258 = zext <4 x i16> %1257 to <4 x i32>
  %1259 = shufflevector <8 x i16> %1256, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1260 = zext <4 x i16> %1259 to <4 x i32>
  %1261 = sub nsw <4 x i32> %1258, %1260
  %1262 = sub nsw <4 x i32> zeroinitializer, %1261
  %1263 = icmp slt <4 x i32> %1261, zeroinitializer
  %1264 = select <4 x i1> %1263, <4 x i32> %1262, <4 x i32> %1261
  %1265 = add nuw nsw <4 x i32> %1264, <i32 32, i32 32, i32 32, i32 32>
  %1266 = lshr <4 x i32> %1265, <i32 6, i32 6, i32 6, i32 6>
  %1267 = shufflevector <8 x i16> %1254, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1268 = shufflevector <8 x i16> %1256, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1269 = bitcast <8 x i16> %1267 to <4 x i32>
  %1270 = bitcast <8 x i16> %1268 to <4 x i32>
  %1271 = sub <4 x i32> %1269, %1270
  %1272 = sub <4 x i32> zeroinitializer, %1271
  %1273 = icmp slt <4 x i32> %1271, zeroinitializer
  %1274 = select <4 x i1> %1273, <4 x i32> %1272, <4 x i32> %1271
  %1275 = add nuw <4 x i32> %1274, <i32 32, i32 32, i32 32, i32 32>
  %1276 = lshr <4 x i32> %1275, <i32 6, i32 6, i32 6, i32 6>
  %1277 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1266, <4 x i32> %1276) #5
  %1278 = lshr <8 x i16> %1277, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1279 = getelementptr inbounds i16, i16* %10, i64 328
  %1280 = bitcast i16* %1279 to <8 x i16>*
  %1281 = load <8 x i16>, <8 x i16>* %1280, align 16
  %1282 = getelementptr inbounds i16, i16* %11, i64 328
  %1283 = bitcast i16* %1282 to <8 x i16>*
  %1284 = load <8 x i16>, <8 x i16>* %1283, align 16
  %1285 = shufflevector <8 x i16> %1281, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1286 = zext <4 x i16> %1285 to <4 x i32>
  %1287 = shufflevector <8 x i16> %1284, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1288 = zext <4 x i16> %1287 to <4 x i32>
  %1289 = sub nsw <4 x i32> %1286, %1288
  %1290 = sub nsw <4 x i32> zeroinitializer, %1289
  %1291 = icmp slt <4 x i32> %1289, zeroinitializer
  %1292 = select <4 x i1> %1291, <4 x i32> %1290, <4 x i32> %1289
  %1293 = add nuw nsw <4 x i32> %1292, <i32 32, i32 32, i32 32, i32 32>
  %1294 = lshr <4 x i32> %1293, <i32 6, i32 6, i32 6, i32 6>
  %1295 = shufflevector <8 x i16> %1281, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1296 = shufflevector <8 x i16> %1284, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1297 = bitcast <8 x i16> %1295 to <4 x i32>
  %1298 = bitcast <8 x i16> %1296 to <4 x i32>
  %1299 = sub <4 x i32> %1297, %1298
  %1300 = sub <4 x i32> zeroinitializer, %1299
  %1301 = icmp slt <4 x i32> %1299, zeroinitializer
  %1302 = select <4 x i1> %1301, <4 x i32> %1300, <4 x i32> %1299
  %1303 = add nuw <4 x i32> %1302, <i32 32, i32 32, i32 32, i32 32>
  %1304 = lshr <4 x i32> %1303, <i32 6, i32 6, i32 6, i32 6>
  %1305 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1294, <4 x i32> %1304) #5
  %1306 = lshr <8 x i16> %1305, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1307 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1278, <8 x i16> %1306) #5
  %1308 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1307, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1309 = icmp slt <16 x i8> %1308, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1310 = select <16 x i1> %1309, <16 x i8> %1308, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1311 = bitcast i8* %1252 to <16 x i8>*
  store <16 x i8> %1310, <16 x i8>* %1311, align 16
  %1312 = getelementptr inbounds i16, i16* %10, i64 336
  %1313 = getelementptr inbounds i16, i16* %11, i64 336
  %1314 = getelementptr inbounds i8, i8* %1252, i64 16
  %1315 = bitcast i16* %1312 to <8 x i16>*
  %1316 = load <8 x i16>, <8 x i16>* %1315, align 16
  %1317 = bitcast i16* %1313 to <8 x i16>*
  %1318 = load <8 x i16>, <8 x i16>* %1317, align 16
  %1319 = shufflevector <8 x i16> %1316, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1320 = zext <4 x i16> %1319 to <4 x i32>
  %1321 = shufflevector <8 x i16> %1318, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1322 = zext <4 x i16> %1321 to <4 x i32>
  %1323 = sub nsw <4 x i32> %1320, %1322
  %1324 = sub nsw <4 x i32> zeroinitializer, %1323
  %1325 = icmp slt <4 x i32> %1323, zeroinitializer
  %1326 = select <4 x i1> %1325, <4 x i32> %1324, <4 x i32> %1323
  %1327 = add nuw nsw <4 x i32> %1326, <i32 32, i32 32, i32 32, i32 32>
  %1328 = lshr <4 x i32> %1327, <i32 6, i32 6, i32 6, i32 6>
  %1329 = shufflevector <8 x i16> %1316, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1330 = shufflevector <8 x i16> %1318, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1331 = bitcast <8 x i16> %1329 to <4 x i32>
  %1332 = bitcast <8 x i16> %1330 to <4 x i32>
  %1333 = sub <4 x i32> %1331, %1332
  %1334 = sub <4 x i32> zeroinitializer, %1333
  %1335 = icmp slt <4 x i32> %1333, zeroinitializer
  %1336 = select <4 x i1> %1335, <4 x i32> %1334, <4 x i32> %1333
  %1337 = add nuw <4 x i32> %1336, <i32 32, i32 32, i32 32, i32 32>
  %1338 = lshr <4 x i32> %1337, <i32 6, i32 6, i32 6, i32 6>
  %1339 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1328, <4 x i32> %1338) #5
  %1340 = lshr <8 x i16> %1339, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1341 = getelementptr inbounds i16, i16* %10, i64 344
  %1342 = bitcast i16* %1341 to <8 x i16>*
  %1343 = load <8 x i16>, <8 x i16>* %1342, align 16
  %1344 = getelementptr inbounds i16, i16* %11, i64 344
  %1345 = bitcast i16* %1344 to <8 x i16>*
  %1346 = load <8 x i16>, <8 x i16>* %1345, align 16
  %1347 = shufflevector <8 x i16> %1343, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1348 = zext <4 x i16> %1347 to <4 x i32>
  %1349 = shufflevector <8 x i16> %1346, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1350 = zext <4 x i16> %1349 to <4 x i32>
  %1351 = sub nsw <4 x i32> %1348, %1350
  %1352 = sub nsw <4 x i32> zeroinitializer, %1351
  %1353 = icmp slt <4 x i32> %1351, zeroinitializer
  %1354 = select <4 x i1> %1353, <4 x i32> %1352, <4 x i32> %1351
  %1355 = add nuw nsw <4 x i32> %1354, <i32 32, i32 32, i32 32, i32 32>
  %1356 = lshr <4 x i32> %1355, <i32 6, i32 6, i32 6, i32 6>
  %1357 = shufflevector <8 x i16> %1343, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1358 = shufflevector <8 x i16> %1346, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1359 = bitcast <8 x i16> %1357 to <4 x i32>
  %1360 = bitcast <8 x i16> %1358 to <4 x i32>
  %1361 = sub <4 x i32> %1359, %1360
  %1362 = sub <4 x i32> zeroinitializer, %1361
  %1363 = icmp slt <4 x i32> %1361, zeroinitializer
  %1364 = select <4 x i1> %1363, <4 x i32> %1362, <4 x i32> %1361
  %1365 = add nuw <4 x i32> %1364, <i32 32, i32 32, i32 32, i32 32>
  %1366 = lshr <4 x i32> %1365, <i32 6, i32 6, i32 6, i32 6>
  %1367 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1356, <4 x i32> %1366) #5
  %1368 = lshr <8 x i16> %1367, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1369 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1340, <8 x i16> %1368) #5
  %1370 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1369, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1371 = icmp slt <16 x i8> %1370, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1372 = select <16 x i1> %1371, <16 x i8> %1370, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1373 = bitcast i8* %1314 to <16 x i8>*
  store <16 x i8> %1372, <16 x i8>* %1373, align 16
  %1374 = getelementptr inbounds i16, i16* %10, i64 352
  %1375 = getelementptr inbounds i16, i16* %11, i64 352
  %1376 = getelementptr inbounds i8, i8* %1252, i64 32
  %1377 = bitcast i16* %1374 to <8 x i16>*
  %1378 = load <8 x i16>, <8 x i16>* %1377, align 16
  %1379 = bitcast i16* %1375 to <8 x i16>*
  %1380 = load <8 x i16>, <8 x i16>* %1379, align 16
  %1381 = shufflevector <8 x i16> %1378, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1382 = zext <4 x i16> %1381 to <4 x i32>
  %1383 = shufflevector <8 x i16> %1380, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1384 = zext <4 x i16> %1383 to <4 x i32>
  %1385 = sub nsw <4 x i32> %1382, %1384
  %1386 = sub nsw <4 x i32> zeroinitializer, %1385
  %1387 = icmp slt <4 x i32> %1385, zeroinitializer
  %1388 = select <4 x i1> %1387, <4 x i32> %1386, <4 x i32> %1385
  %1389 = add nuw nsw <4 x i32> %1388, <i32 32, i32 32, i32 32, i32 32>
  %1390 = lshr <4 x i32> %1389, <i32 6, i32 6, i32 6, i32 6>
  %1391 = shufflevector <8 x i16> %1378, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1392 = shufflevector <8 x i16> %1380, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1393 = bitcast <8 x i16> %1391 to <4 x i32>
  %1394 = bitcast <8 x i16> %1392 to <4 x i32>
  %1395 = sub <4 x i32> %1393, %1394
  %1396 = sub <4 x i32> zeroinitializer, %1395
  %1397 = icmp slt <4 x i32> %1395, zeroinitializer
  %1398 = select <4 x i1> %1397, <4 x i32> %1396, <4 x i32> %1395
  %1399 = add nuw <4 x i32> %1398, <i32 32, i32 32, i32 32, i32 32>
  %1400 = lshr <4 x i32> %1399, <i32 6, i32 6, i32 6, i32 6>
  %1401 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1390, <4 x i32> %1400) #5
  %1402 = lshr <8 x i16> %1401, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1403 = getelementptr inbounds i16, i16* %10, i64 360
  %1404 = bitcast i16* %1403 to <8 x i16>*
  %1405 = load <8 x i16>, <8 x i16>* %1404, align 16
  %1406 = getelementptr inbounds i16, i16* %11, i64 360
  %1407 = bitcast i16* %1406 to <8 x i16>*
  %1408 = load <8 x i16>, <8 x i16>* %1407, align 16
  %1409 = shufflevector <8 x i16> %1405, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1410 = zext <4 x i16> %1409 to <4 x i32>
  %1411 = shufflevector <8 x i16> %1408, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1412 = zext <4 x i16> %1411 to <4 x i32>
  %1413 = sub nsw <4 x i32> %1410, %1412
  %1414 = sub nsw <4 x i32> zeroinitializer, %1413
  %1415 = icmp slt <4 x i32> %1413, zeroinitializer
  %1416 = select <4 x i1> %1415, <4 x i32> %1414, <4 x i32> %1413
  %1417 = add nuw nsw <4 x i32> %1416, <i32 32, i32 32, i32 32, i32 32>
  %1418 = lshr <4 x i32> %1417, <i32 6, i32 6, i32 6, i32 6>
  %1419 = shufflevector <8 x i16> %1405, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1420 = shufflevector <8 x i16> %1408, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1421 = bitcast <8 x i16> %1419 to <4 x i32>
  %1422 = bitcast <8 x i16> %1420 to <4 x i32>
  %1423 = sub <4 x i32> %1421, %1422
  %1424 = sub <4 x i32> zeroinitializer, %1423
  %1425 = icmp slt <4 x i32> %1423, zeroinitializer
  %1426 = select <4 x i1> %1425, <4 x i32> %1424, <4 x i32> %1423
  %1427 = add nuw <4 x i32> %1426, <i32 32, i32 32, i32 32, i32 32>
  %1428 = lshr <4 x i32> %1427, <i32 6, i32 6, i32 6, i32 6>
  %1429 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1418, <4 x i32> %1428) #5
  %1430 = lshr <8 x i16> %1429, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1431 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1402, <8 x i16> %1430) #5
  %1432 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1431, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1433 = icmp slt <16 x i8> %1432, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1434 = select <16 x i1> %1433, <16 x i8> %1432, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1435 = bitcast i8* %1376 to <16 x i8>*
  store <16 x i8> %1434, <16 x i8>* %1435, align 16
  %1436 = getelementptr inbounds i16, i16* %10, i64 368
  %1437 = getelementptr inbounds i16, i16* %11, i64 368
  %1438 = getelementptr inbounds i8, i8* %1252, i64 48
  %1439 = bitcast i16* %1436 to <8 x i16>*
  %1440 = load <8 x i16>, <8 x i16>* %1439, align 16
  %1441 = bitcast i16* %1437 to <8 x i16>*
  %1442 = load <8 x i16>, <8 x i16>* %1441, align 16
  %1443 = shufflevector <8 x i16> %1440, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1444 = zext <4 x i16> %1443 to <4 x i32>
  %1445 = shufflevector <8 x i16> %1442, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1446 = zext <4 x i16> %1445 to <4 x i32>
  %1447 = sub nsw <4 x i32> %1444, %1446
  %1448 = sub nsw <4 x i32> zeroinitializer, %1447
  %1449 = icmp slt <4 x i32> %1447, zeroinitializer
  %1450 = select <4 x i1> %1449, <4 x i32> %1448, <4 x i32> %1447
  %1451 = add nuw nsw <4 x i32> %1450, <i32 32, i32 32, i32 32, i32 32>
  %1452 = lshr <4 x i32> %1451, <i32 6, i32 6, i32 6, i32 6>
  %1453 = shufflevector <8 x i16> %1440, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1454 = shufflevector <8 x i16> %1442, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1455 = bitcast <8 x i16> %1453 to <4 x i32>
  %1456 = bitcast <8 x i16> %1454 to <4 x i32>
  %1457 = sub <4 x i32> %1455, %1456
  %1458 = sub <4 x i32> zeroinitializer, %1457
  %1459 = icmp slt <4 x i32> %1457, zeroinitializer
  %1460 = select <4 x i1> %1459, <4 x i32> %1458, <4 x i32> %1457
  %1461 = add nuw <4 x i32> %1460, <i32 32, i32 32, i32 32, i32 32>
  %1462 = lshr <4 x i32> %1461, <i32 6, i32 6, i32 6, i32 6>
  %1463 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1452, <4 x i32> %1462) #5
  %1464 = lshr <8 x i16> %1463, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1465 = getelementptr inbounds i16, i16* %10, i64 376
  %1466 = bitcast i16* %1465 to <8 x i16>*
  %1467 = load <8 x i16>, <8 x i16>* %1466, align 16
  %1468 = getelementptr inbounds i16, i16* %11, i64 376
  %1469 = bitcast i16* %1468 to <8 x i16>*
  %1470 = load <8 x i16>, <8 x i16>* %1469, align 16
  %1471 = shufflevector <8 x i16> %1467, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1472 = zext <4 x i16> %1471 to <4 x i32>
  %1473 = shufflevector <8 x i16> %1470, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1474 = zext <4 x i16> %1473 to <4 x i32>
  %1475 = sub nsw <4 x i32> %1472, %1474
  %1476 = sub nsw <4 x i32> zeroinitializer, %1475
  %1477 = icmp slt <4 x i32> %1475, zeroinitializer
  %1478 = select <4 x i1> %1477, <4 x i32> %1476, <4 x i32> %1475
  %1479 = add nuw nsw <4 x i32> %1478, <i32 32, i32 32, i32 32, i32 32>
  %1480 = lshr <4 x i32> %1479, <i32 6, i32 6, i32 6, i32 6>
  %1481 = shufflevector <8 x i16> %1467, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1482 = shufflevector <8 x i16> %1470, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1483 = bitcast <8 x i16> %1481 to <4 x i32>
  %1484 = bitcast <8 x i16> %1482 to <4 x i32>
  %1485 = sub <4 x i32> %1483, %1484
  %1486 = sub <4 x i32> zeroinitializer, %1485
  %1487 = icmp slt <4 x i32> %1485, zeroinitializer
  %1488 = select <4 x i1> %1487, <4 x i32> %1486, <4 x i32> %1485
  %1489 = add nuw <4 x i32> %1488, <i32 32, i32 32, i32 32, i32 32>
  %1490 = lshr <4 x i32> %1489, <i32 6, i32 6, i32 6, i32 6>
  %1491 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1480, <4 x i32> %1490) #5
  %1492 = lshr <8 x i16> %1491, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1493 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1464, <8 x i16> %1492) #5
  %1494 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1493, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1495 = icmp slt <16 x i8> %1494, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1496 = select <16 x i1> %1495, <16 x i8> %1494, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1497 = bitcast i8* %1438 to <16 x i8>*
  store <16 x i8> %1496, <16 x i8>* %1497, align 16
  %1498 = getelementptr inbounds i16, i16* %10, i64 384
  %1499 = getelementptr inbounds i16, i16* %11, i64 384
  %1500 = getelementptr inbounds i8, i8* %1252, i64 %7
  %1501 = add nsw i32 %12, -1
  %1502 = icmp eq i32 %1501, 0
  br i1 %1502, label %1503, label %8

1503:                                             ; preds = %8
  %1504 = bitcast i16* %1498 to <8 x i16>*
  %1505 = load <8 x i16>, <8 x i16>* %1504, align 16
  %1506 = bitcast i16* %1499 to <8 x i16>*
  %1507 = load <8 x i16>, <8 x i16>* %1506, align 16
  %1508 = shufflevector <8 x i16> %1505, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1509 = zext <4 x i16> %1508 to <4 x i32>
  %1510 = shufflevector <8 x i16> %1507, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1511 = zext <4 x i16> %1510 to <4 x i32>
  %1512 = sub nsw <4 x i32> %1509, %1511
  %1513 = sub nsw <4 x i32> zeroinitializer, %1512
  %1514 = icmp slt <4 x i32> %1512, zeroinitializer
  %1515 = select <4 x i1> %1514, <4 x i32> %1513, <4 x i32> %1512
  %1516 = add nuw nsw <4 x i32> %1515, <i32 32, i32 32, i32 32, i32 32>
  %1517 = lshr <4 x i32> %1516, <i32 6, i32 6, i32 6, i32 6>
  %1518 = shufflevector <8 x i16> %1505, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1519 = shufflevector <8 x i16> %1507, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1520 = bitcast <8 x i16> %1518 to <4 x i32>
  %1521 = bitcast <8 x i16> %1519 to <4 x i32>
  %1522 = sub <4 x i32> %1520, %1521
  %1523 = sub <4 x i32> zeroinitializer, %1522
  %1524 = icmp slt <4 x i32> %1522, zeroinitializer
  %1525 = select <4 x i1> %1524, <4 x i32> %1523, <4 x i32> %1522
  %1526 = add nuw <4 x i32> %1525, <i32 32, i32 32, i32 32, i32 32>
  %1527 = lshr <4 x i32> %1526, <i32 6, i32 6, i32 6, i32 6>
  %1528 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1517, <4 x i32> %1527) #5
  %1529 = lshr <8 x i16> %1528, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1530 = getelementptr inbounds i16, i16* %10, i64 392
  %1531 = bitcast i16* %1530 to <8 x i16>*
  %1532 = load <8 x i16>, <8 x i16>* %1531, align 16
  %1533 = getelementptr inbounds i16, i16* %11, i64 392
  %1534 = bitcast i16* %1533 to <8 x i16>*
  %1535 = load <8 x i16>, <8 x i16>* %1534, align 16
  %1536 = shufflevector <8 x i16> %1532, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1537 = zext <4 x i16> %1536 to <4 x i32>
  %1538 = shufflevector <8 x i16> %1535, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1539 = zext <4 x i16> %1538 to <4 x i32>
  %1540 = sub nsw <4 x i32> %1537, %1539
  %1541 = sub nsw <4 x i32> zeroinitializer, %1540
  %1542 = icmp slt <4 x i32> %1540, zeroinitializer
  %1543 = select <4 x i1> %1542, <4 x i32> %1541, <4 x i32> %1540
  %1544 = add nuw nsw <4 x i32> %1543, <i32 32, i32 32, i32 32, i32 32>
  %1545 = lshr <4 x i32> %1544, <i32 6, i32 6, i32 6, i32 6>
  %1546 = shufflevector <8 x i16> %1532, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1547 = shufflevector <8 x i16> %1535, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1548 = bitcast <8 x i16> %1546 to <4 x i32>
  %1549 = bitcast <8 x i16> %1547 to <4 x i32>
  %1550 = sub <4 x i32> %1548, %1549
  %1551 = sub <4 x i32> zeroinitializer, %1550
  %1552 = icmp slt <4 x i32> %1550, zeroinitializer
  %1553 = select <4 x i1> %1552, <4 x i32> %1551, <4 x i32> %1550
  %1554 = add nuw <4 x i32> %1553, <i32 32, i32 32, i32 32, i32 32>
  %1555 = lshr <4 x i32> %1554, <i32 6, i32 6, i32 6, i32 6>
  %1556 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1545, <4 x i32> %1555) #5
  %1557 = lshr <8 x i16> %1556, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1558 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1529, <8 x i16> %1557) #5
  %1559 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1558, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1560 = icmp slt <16 x i8> %1559, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1561 = select <16 x i1> %1560, <16 x i8> %1559, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1562 = bitcast i8* %1500 to <16 x i8>*
  store <16 x i8> %1561, <16 x i8>* %1562, align 16
  %1563 = getelementptr inbounds i16, i16* %10, i64 400
  %1564 = getelementptr inbounds i16, i16* %11, i64 400
  %1565 = getelementptr inbounds i8, i8* %1500, i64 16
  %1566 = bitcast i16* %1563 to <8 x i16>*
  %1567 = load <8 x i16>, <8 x i16>* %1566, align 16
  %1568 = bitcast i16* %1564 to <8 x i16>*
  %1569 = load <8 x i16>, <8 x i16>* %1568, align 16
  %1570 = shufflevector <8 x i16> %1567, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1571 = zext <4 x i16> %1570 to <4 x i32>
  %1572 = shufflevector <8 x i16> %1569, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1573 = zext <4 x i16> %1572 to <4 x i32>
  %1574 = sub nsw <4 x i32> %1571, %1573
  %1575 = sub nsw <4 x i32> zeroinitializer, %1574
  %1576 = icmp slt <4 x i32> %1574, zeroinitializer
  %1577 = select <4 x i1> %1576, <4 x i32> %1575, <4 x i32> %1574
  %1578 = add nuw nsw <4 x i32> %1577, <i32 32, i32 32, i32 32, i32 32>
  %1579 = lshr <4 x i32> %1578, <i32 6, i32 6, i32 6, i32 6>
  %1580 = shufflevector <8 x i16> %1567, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1581 = shufflevector <8 x i16> %1569, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1582 = bitcast <8 x i16> %1580 to <4 x i32>
  %1583 = bitcast <8 x i16> %1581 to <4 x i32>
  %1584 = sub <4 x i32> %1582, %1583
  %1585 = sub <4 x i32> zeroinitializer, %1584
  %1586 = icmp slt <4 x i32> %1584, zeroinitializer
  %1587 = select <4 x i1> %1586, <4 x i32> %1585, <4 x i32> %1584
  %1588 = add nuw <4 x i32> %1587, <i32 32, i32 32, i32 32, i32 32>
  %1589 = lshr <4 x i32> %1588, <i32 6, i32 6, i32 6, i32 6>
  %1590 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1579, <4 x i32> %1589) #5
  %1591 = lshr <8 x i16> %1590, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1592 = getelementptr inbounds i16, i16* %10, i64 408
  %1593 = bitcast i16* %1592 to <8 x i16>*
  %1594 = load <8 x i16>, <8 x i16>* %1593, align 16
  %1595 = getelementptr inbounds i16, i16* %11, i64 408
  %1596 = bitcast i16* %1595 to <8 x i16>*
  %1597 = load <8 x i16>, <8 x i16>* %1596, align 16
  %1598 = shufflevector <8 x i16> %1594, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1599 = zext <4 x i16> %1598 to <4 x i32>
  %1600 = shufflevector <8 x i16> %1597, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1601 = zext <4 x i16> %1600 to <4 x i32>
  %1602 = sub nsw <4 x i32> %1599, %1601
  %1603 = sub nsw <4 x i32> zeroinitializer, %1602
  %1604 = icmp slt <4 x i32> %1602, zeroinitializer
  %1605 = select <4 x i1> %1604, <4 x i32> %1603, <4 x i32> %1602
  %1606 = add nuw nsw <4 x i32> %1605, <i32 32, i32 32, i32 32, i32 32>
  %1607 = lshr <4 x i32> %1606, <i32 6, i32 6, i32 6, i32 6>
  %1608 = shufflevector <8 x i16> %1594, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1609 = shufflevector <8 x i16> %1597, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1610 = bitcast <8 x i16> %1608 to <4 x i32>
  %1611 = bitcast <8 x i16> %1609 to <4 x i32>
  %1612 = sub <4 x i32> %1610, %1611
  %1613 = sub <4 x i32> zeroinitializer, %1612
  %1614 = icmp slt <4 x i32> %1612, zeroinitializer
  %1615 = select <4 x i1> %1614, <4 x i32> %1613, <4 x i32> %1612
  %1616 = add nuw <4 x i32> %1615, <i32 32, i32 32, i32 32, i32 32>
  %1617 = lshr <4 x i32> %1616, <i32 6, i32 6, i32 6, i32 6>
  %1618 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1607, <4 x i32> %1617) #5
  %1619 = lshr <8 x i16> %1618, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1620 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1591, <8 x i16> %1619) #5
  %1621 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1620, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1622 = icmp slt <16 x i8> %1621, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1623 = select <16 x i1> %1622, <16 x i8> %1621, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1624 = bitcast i8* %1565 to <16 x i8>*
  store <16 x i8> %1623, <16 x i8>* %1624, align 16
  %1625 = getelementptr inbounds i16, i16* %10, i64 416
  %1626 = getelementptr inbounds i16, i16* %11, i64 416
  %1627 = getelementptr inbounds i8, i8* %1500, i64 32
  %1628 = bitcast i16* %1625 to <8 x i16>*
  %1629 = load <8 x i16>, <8 x i16>* %1628, align 16
  %1630 = bitcast i16* %1626 to <8 x i16>*
  %1631 = load <8 x i16>, <8 x i16>* %1630, align 16
  %1632 = shufflevector <8 x i16> %1629, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1633 = zext <4 x i16> %1632 to <4 x i32>
  %1634 = shufflevector <8 x i16> %1631, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1635 = zext <4 x i16> %1634 to <4 x i32>
  %1636 = sub nsw <4 x i32> %1633, %1635
  %1637 = sub nsw <4 x i32> zeroinitializer, %1636
  %1638 = icmp slt <4 x i32> %1636, zeroinitializer
  %1639 = select <4 x i1> %1638, <4 x i32> %1637, <4 x i32> %1636
  %1640 = add nuw nsw <4 x i32> %1639, <i32 32, i32 32, i32 32, i32 32>
  %1641 = lshr <4 x i32> %1640, <i32 6, i32 6, i32 6, i32 6>
  %1642 = shufflevector <8 x i16> %1629, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1643 = shufflevector <8 x i16> %1631, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1644 = bitcast <8 x i16> %1642 to <4 x i32>
  %1645 = bitcast <8 x i16> %1643 to <4 x i32>
  %1646 = sub <4 x i32> %1644, %1645
  %1647 = sub <4 x i32> zeroinitializer, %1646
  %1648 = icmp slt <4 x i32> %1646, zeroinitializer
  %1649 = select <4 x i1> %1648, <4 x i32> %1647, <4 x i32> %1646
  %1650 = add nuw <4 x i32> %1649, <i32 32, i32 32, i32 32, i32 32>
  %1651 = lshr <4 x i32> %1650, <i32 6, i32 6, i32 6, i32 6>
  %1652 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1641, <4 x i32> %1651) #5
  %1653 = lshr <8 x i16> %1652, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1654 = getelementptr inbounds i16, i16* %10, i64 424
  %1655 = bitcast i16* %1654 to <8 x i16>*
  %1656 = load <8 x i16>, <8 x i16>* %1655, align 16
  %1657 = getelementptr inbounds i16, i16* %11, i64 424
  %1658 = bitcast i16* %1657 to <8 x i16>*
  %1659 = load <8 x i16>, <8 x i16>* %1658, align 16
  %1660 = shufflevector <8 x i16> %1656, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1661 = zext <4 x i16> %1660 to <4 x i32>
  %1662 = shufflevector <8 x i16> %1659, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1663 = zext <4 x i16> %1662 to <4 x i32>
  %1664 = sub nsw <4 x i32> %1661, %1663
  %1665 = sub nsw <4 x i32> zeroinitializer, %1664
  %1666 = icmp slt <4 x i32> %1664, zeroinitializer
  %1667 = select <4 x i1> %1666, <4 x i32> %1665, <4 x i32> %1664
  %1668 = add nuw nsw <4 x i32> %1667, <i32 32, i32 32, i32 32, i32 32>
  %1669 = lshr <4 x i32> %1668, <i32 6, i32 6, i32 6, i32 6>
  %1670 = shufflevector <8 x i16> %1656, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1671 = shufflevector <8 x i16> %1659, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1672 = bitcast <8 x i16> %1670 to <4 x i32>
  %1673 = bitcast <8 x i16> %1671 to <4 x i32>
  %1674 = sub <4 x i32> %1672, %1673
  %1675 = sub <4 x i32> zeroinitializer, %1674
  %1676 = icmp slt <4 x i32> %1674, zeroinitializer
  %1677 = select <4 x i1> %1676, <4 x i32> %1675, <4 x i32> %1674
  %1678 = add nuw <4 x i32> %1677, <i32 32, i32 32, i32 32, i32 32>
  %1679 = lshr <4 x i32> %1678, <i32 6, i32 6, i32 6, i32 6>
  %1680 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1669, <4 x i32> %1679) #5
  %1681 = lshr <8 x i16> %1680, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1682 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1653, <8 x i16> %1681) #5
  %1683 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1682, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1684 = icmp slt <16 x i8> %1683, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1685 = select <16 x i1> %1684, <16 x i8> %1683, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1686 = bitcast i8* %1627 to <16 x i8>*
  store <16 x i8> %1685, <16 x i8>* %1686, align 16
  %1687 = getelementptr inbounds i16, i16* %10, i64 432
  %1688 = getelementptr inbounds i16, i16* %11, i64 432
  %1689 = getelementptr inbounds i8, i8* %1500, i64 48
  %1690 = bitcast i16* %1687 to <8 x i16>*
  %1691 = load <8 x i16>, <8 x i16>* %1690, align 16
  %1692 = bitcast i16* %1688 to <8 x i16>*
  %1693 = load <8 x i16>, <8 x i16>* %1692, align 16
  %1694 = shufflevector <8 x i16> %1691, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1695 = zext <4 x i16> %1694 to <4 x i32>
  %1696 = shufflevector <8 x i16> %1693, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1697 = zext <4 x i16> %1696 to <4 x i32>
  %1698 = sub nsw <4 x i32> %1695, %1697
  %1699 = sub nsw <4 x i32> zeroinitializer, %1698
  %1700 = icmp slt <4 x i32> %1698, zeroinitializer
  %1701 = select <4 x i1> %1700, <4 x i32> %1699, <4 x i32> %1698
  %1702 = add nuw nsw <4 x i32> %1701, <i32 32, i32 32, i32 32, i32 32>
  %1703 = lshr <4 x i32> %1702, <i32 6, i32 6, i32 6, i32 6>
  %1704 = shufflevector <8 x i16> %1691, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1705 = shufflevector <8 x i16> %1693, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1706 = bitcast <8 x i16> %1704 to <4 x i32>
  %1707 = bitcast <8 x i16> %1705 to <4 x i32>
  %1708 = sub <4 x i32> %1706, %1707
  %1709 = sub <4 x i32> zeroinitializer, %1708
  %1710 = icmp slt <4 x i32> %1708, zeroinitializer
  %1711 = select <4 x i1> %1710, <4 x i32> %1709, <4 x i32> %1708
  %1712 = add nuw <4 x i32> %1711, <i32 32, i32 32, i32 32, i32 32>
  %1713 = lshr <4 x i32> %1712, <i32 6, i32 6, i32 6, i32 6>
  %1714 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1703, <4 x i32> %1713) #5
  %1715 = lshr <8 x i16> %1714, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1716 = getelementptr inbounds i16, i16* %10, i64 440
  %1717 = bitcast i16* %1716 to <8 x i16>*
  %1718 = load <8 x i16>, <8 x i16>* %1717, align 16
  %1719 = getelementptr inbounds i16, i16* %11, i64 440
  %1720 = bitcast i16* %1719 to <8 x i16>*
  %1721 = load <8 x i16>, <8 x i16>* %1720, align 16
  %1722 = shufflevector <8 x i16> %1718, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1723 = zext <4 x i16> %1722 to <4 x i32>
  %1724 = shufflevector <8 x i16> %1721, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1725 = zext <4 x i16> %1724 to <4 x i32>
  %1726 = sub nsw <4 x i32> %1723, %1725
  %1727 = sub nsw <4 x i32> zeroinitializer, %1726
  %1728 = icmp slt <4 x i32> %1726, zeroinitializer
  %1729 = select <4 x i1> %1728, <4 x i32> %1727, <4 x i32> %1726
  %1730 = add nuw nsw <4 x i32> %1729, <i32 32, i32 32, i32 32, i32 32>
  %1731 = lshr <4 x i32> %1730, <i32 6, i32 6, i32 6, i32 6>
  %1732 = shufflevector <8 x i16> %1718, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1733 = shufflevector <8 x i16> %1721, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1734 = bitcast <8 x i16> %1732 to <4 x i32>
  %1735 = bitcast <8 x i16> %1733 to <4 x i32>
  %1736 = sub <4 x i32> %1734, %1735
  %1737 = sub <4 x i32> zeroinitializer, %1736
  %1738 = icmp slt <4 x i32> %1736, zeroinitializer
  %1739 = select <4 x i1> %1738, <4 x i32> %1737, <4 x i32> %1736
  %1740 = add nuw <4 x i32> %1739, <i32 32, i32 32, i32 32, i32 32>
  %1741 = lshr <4 x i32> %1740, <i32 6, i32 6, i32 6, i32 6>
  %1742 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1731, <4 x i32> %1741) #5
  %1743 = lshr <8 x i16> %1742, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1744 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1715, <8 x i16> %1743) #5
  %1745 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1744, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1746 = icmp slt <16 x i8> %1745, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1747 = select <16 x i1> %1746, <16 x i8> %1745, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1748 = bitcast i8* %1689 to <16 x i8>*
  store <16 x i8> %1747, <16 x i8>* %1748, align 16
  %1749 = getelementptr inbounds i16, i16* %10, i64 448
  %1750 = getelementptr inbounds i16, i16* %11, i64 448
  %1751 = getelementptr inbounds i8, i8* %1500, i64 64
  %1752 = bitcast i16* %1749 to <8 x i16>*
  %1753 = load <8 x i16>, <8 x i16>* %1752, align 16
  %1754 = bitcast i16* %1750 to <8 x i16>*
  %1755 = load <8 x i16>, <8 x i16>* %1754, align 16
  %1756 = shufflevector <8 x i16> %1753, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1757 = zext <4 x i16> %1756 to <4 x i32>
  %1758 = shufflevector <8 x i16> %1755, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1759 = zext <4 x i16> %1758 to <4 x i32>
  %1760 = sub nsw <4 x i32> %1757, %1759
  %1761 = sub nsw <4 x i32> zeroinitializer, %1760
  %1762 = icmp slt <4 x i32> %1760, zeroinitializer
  %1763 = select <4 x i1> %1762, <4 x i32> %1761, <4 x i32> %1760
  %1764 = add nuw nsw <4 x i32> %1763, <i32 32, i32 32, i32 32, i32 32>
  %1765 = lshr <4 x i32> %1764, <i32 6, i32 6, i32 6, i32 6>
  %1766 = shufflevector <8 x i16> %1753, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1767 = shufflevector <8 x i16> %1755, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1768 = bitcast <8 x i16> %1766 to <4 x i32>
  %1769 = bitcast <8 x i16> %1767 to <4 x i32>
  %1770 = sub <4 x i32> %1768, %1769
  %1771 = sub <4 x i32> zeroinitializer, %1770
  %1772 = icmp slt <4 x i32> %1770, zeroinitializer
  %1773 = select <4 x i1> %1772, <4 x i32> %1771, <4 x i32> %1770
  %1774 = add nuw <4 x i32> %1773, <i32 32, i32 32, i32 32, i32 32>
  %1775 = lshr <4 x i32> %1774, <i32 6, i32 6, i32 6, i32 6>
  %1776 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1765, <4 x i32> %1775) #5
  %1777 = lshr <8 x i16> %1776, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1778 = getelementptr inbounds i16, i16* %10, i64 456
  %1779 = bitcast i16* %1778 to <8 x i16>*
  %1780 = load <8 x i16>, <8 x i16>* %1779, align 16
  %1781 = getelementptr inbounds i16, i16* %11, i64 456
  %1782 = bitcast i16* %1781 to <8 x i16>*
  %1783 = load <8 x i16>, <8 x i16>* %1782, align 16
  %1784 = shufflevector <8 x i16> %1780, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1785 = zext <4 x i16> %1784 to <4 x i32>
  %1786 = shufflevector <8 x i16> %1783, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1787 = zext <4 x i16> %1786 to <4 x i32>
  %1788 = sub nsw <4 x i32> %1785, %1787
  %1789 = sub nsw <4 x i32> zeroinitializer, %1788
  %1790 = icmp slt <4 x i32> %1788, zeroinitializer
  %1791 = select <4 x i1> %1790, <4 x i32> %1789, <4 x i32> %1788
  %1792 = add nuw nsw <4 x i32> %1791, <i32 32, i32 32, i32 32, i32 32>
  %1793 = lshr <4 x i32> %1792, <i32 6, i32 6, i32 6, i32 6>
  %1794 = shufflevector <8 x i16> %1780, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1795 = shufflevector <8 x i16> %1783, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1796 = bitcast <8 x i16> %1794 to <4 x i32>
  %1797 = bitcast <8 x i16> %1795 to <4 x i32>
  %1798 = sub <4 x i32> %1796, %1797
  %1799 = sub <4 x i32> zeroinitializer, %1798
  %1800 = icmp slt <4 x i32> %1798, zeroinitializer
  %1801 = select <4 x i1> %1800, <4 x i32> %1799, <4 x i32> %1798
  %1802 = add nuw <4 x i32> %1801, <i32 32, i32 32, i32 32, i32 32>
  %1803 = lshr <4 x i32> %1802, <i32 6, i32 6, i32 6, i32 6>
  %1804 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1793, <4 x i32> %1803) #5
  %1805 = lshr <8 x i16> %1804, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1806 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1777, <8 x i16> %1805) #5
  %1807 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1806, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1808 = icmp slt <16 x i8> %1807, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1809 = select <16 x i1> %1808, <16 x i8> %1807, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1810 = bitcast i8* %1751 to <16 x i8>*
  store <16 x i8> %1809, <16 x i8>* %1810, align 16
  %1811 = getelementptr inbounds i16, i16* %10, i64 464
  %1812 = getelementptr inbounds i16, i16* %11, i64 464
  %1813 = getelementptr inbounds i8, i8* %1751, i64 16
  %1814 = bitcast i16* %1811 to <8 x i16>*
  %1815 = load <8 x i16>, <8 x i16>* %1814, align 16
  %1816 = bitcast i16* %1812 to <8 x i16>*
  %1817 = load <8 x i16>, <8 x i16>* %1816, align 16
  %1818 = shufflevector <8 x i16> %1815, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1819 = zext <4 x i16> %1818 to <4 x i32>
  %1820 = shufflevector <8 x i16> %1817, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1821 = zext <4 x i16> %1820 to <4 x i32>
  %1822 = sub nsw <4 x i32> %1819, %1821
  %1823 = sub nsw <4 x i32> zeroinitializer, %1822
  %1824 = icmp slt <4 x i32> %1822, zeroinitializer
  %1825 = select <4 x i1> %1824, <4 x i32> %1823, <4 x i32> %1822
  %1826 = add nuw nsw <4 x i32> %1825, <i32 32, i32 32, i32 32, i32 32>
  %1827 = lshr <4 x i32> %1826, <i32 6, i32 6, i32 6, i32 6>
  %1828 = shufflevector <8 x i16> %1815, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1829 = shufflevector <8 x i16> %1817, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1830 = bitcast <8 x i16> %1828 to <4 x i32>
  %1831 = bitcast <8 x i16> %1829 to <4 x i32>
  %1832 = sub <4 x i32> %1830, %1831
  %1833 = sub <4 x i32> zeroinitializer, %1832
  %1834 = icmp slt <4 x i32> %1832, zeroinitializer
  %1835 = select <4 x i1> %1834, <4 x i32> %1833, <4 x i32> %1832
  %1836 = add nuw <4 x i32> %1835, <i32 32, i32 32, i32 32, i32 32>
  %1837 = lshr <4 x i32> %1836, <i32 6, i32 6, i32 6, i32 6>
  %1838 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1827, <4 x i32> %1837) #5
  %1839 = lshr <8 x i16> %1838, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1840 = getelementptr inbounds i16, i16* %10, i64 472
  %1841 = bitcast i16* %1840 to <8 x i16>*
  %1842 = load <8 x i16>, <8 x i16>* %1841, align 16
  %1843 = getelementptr inbounds i16, i16* %11, i64 472
  %1844 = bitcast i16* %1843 to <8 x i16>*
  %1845 = load <8 x i16>, <8 x i16>* %1844, align 16
  %1846 = shufflevector <8 x i16> %1842, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1847 = zext <4 x i16> %1846 to <4 x i32>
  %1848 = shufflevector <8 x i16> %1845, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1849 = zext <4 x i16> %1848 to <4 x i32>
  %1850 = sub nsw <4 x i32> %1847, %1849
  %1851 = sub nsw <4 x i32> zeroinitializer, %1850
  %1852 = icmp slt <4 x i32> %1850, zeroinitializer
  %1853 = select <4 x i1> %1852, <4 x i32> %1851, <4 x i32> %1850
  %1854 = add nuw nsw <4 x i32> %1853, <i32 32, i32 32, i32 32, i32 32>
  %1855 = lshr <4 x i32> %1854, <i32 6, i32 6, i32 6, i32 6>
  %1856 = shufflevector <8 x i16> %1842, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1857 = shufflevector <8 x i16> %1845, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1858 = bitcast <8 x i16> %1856 to <4 x i32>
  %1859 = bitcast <8 x i16> %1857 to <4 x i32>
  %1860 = sub <4 x i32> %1858, %1859
  %1861 = sub <4 x i32> zeroinitializer, %1860
  %1862 = icmp slt <4 x i32> %1860, zeroinitializer
  %1863 = select <4 x i1> %1862, <4 x i32> %1861, <4 x i32> %1860
  %1864 = add nuw <4 x i32> %1863, <i32 32, i32 32, i32 32, i32 32>
  %1865 = lshr <4 x i32> %1864, <i32 6, i32 6, i32 6, i32 6>
  %1866 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1855, <4 x i32> %1865) #5
  %1867 = lshr <8 x i16> %1866, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1868 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1839, <8 x i16> %1867) #5
  %1869 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1868, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1870 = icmp slt <16 x i8> %1869, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1871 = select <16 x i1> %1870, <16 x i8> %1869, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1872 = bitcast i8* %1813 to <16 x i8>*
  store <16 x i8> %1871, <16 x i8>* %1872, align 16
  %1873 = getelementptr inbounds i16, i16* %10, i64 480
  %1874 = getelementptr inbounds i16, i16* %11, i64 480
  %1875 = getelementptr inbounds i8, i8* %1751, i64 32
  %1876 = bitcast i16* %1873 to <8 x i16>*
  %1877 = load <8 x i16>, <8 x i16>* %1876, align 16
  %1878 = bitcast i16* %1874 to <8 x i16>*
  %1879 = load <8 x i16>, <8 x i16>* %1878, align 16
  %1880 = shufflevector <8 x i16> %1877, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1881 = zext <4 x i16> %1880 to <4 x i32>
  %1882 = shufflevector <8 x i16> %1879, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1883 = zext <4 x i16> %1882 to <4 x i32>
  %1884 = sub nsw <4 x i32> %1881, %1883
  %1885 = sub nsw <4 x i32> zeroinitializer, %1884
  %1886 = icmp slt <4 x i32> %1884, zeroinitializer
  %1887 = select <4 x i1> %1886, <4 x i32> %1885, <4 x i32> %1884
  %1888 = add nuw nsw <4 x i32> %1887, <i32 32, i32 32, i32 32, i32 32>
  %1889 = lshr <4 x i32> %1888, <i32 6, i32 6, i32 6, i32 6>
  %1890 = shufflevector <8 x i16> %1877, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1891 = shufflevector <8 x i16> %1879, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1892 = bitcast <8 x i16> %1890 to <4 x i32>
  %1893 = bitcast <8 x i16> %1891 to <4 x i32>
  %1894 = sub <4 x i32> %1892, %1893
  %1895 = sub <4 x i32> zeroinitializer, %1894
  %1896 = icmp slt <4 x i32> %1894, zeroinitializer
  %1897 = select <4 x i1> %1896, <4 x i32> %1895, <4 x i32> %1894
  %1898 = add nuw <4 x i32> %1897, <i32 32, i32 32, i32 32, i32 32>
  %1899 = lshr <4 x i32> %1898, <i32 6, i32 6, i32 6, i32 6>
  %1900 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1889, <4 x i32> %1899) #5
  %1901 = lshr <8 x i16> %1900, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1902 = getelementptr inbounds i16, i16* %10, i64 488
  %1903 = bitcast i16* %1902 to <8 x i16>*
  %1904 = load <8 x i16>, <8 x i16>* %1903, align 16
  %1905 = getelementptr inbounds i16, i16* %11, i64 488
  %1906 = bitcast i16* %1905 to <8 x i16>*
  %1907 = load <8 x i16>, <8 x i16>* %1906, align 16
  %1908 = shufflevector <8 x i16> %1904, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1909 = zext <4 x i16> %1908 to <4 x i32>
  %1910 = shufflevector <8 x i16> %1907, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1911 = zext <4 x i16> %1910 to <4 x i32>
  %1912 = sub nsw <4 x i32> %1909, %1911
  %1913 = sub nsw <4 x i32> zeroinitializer, %1912
  %1914 = icmp slt <4 x i32> %1912, zeroinitializer
  %1915 = select <4 x i1> %1914, <4 x i32> %1913, <4 x i32> %1912
  %1916 = add nuw nsw <4 x i32> %1915, <i32 32, i32 32, i32 32, i32 32>
  %1917 = lshr <4 x i32> %1916, <i32 6, i32 6, i32 6, i32 6>
  %1918 = shufflevector <8 x i16> %1904, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1919 = shufflevector <8 x i16> %1907, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1920 = bitcast <8 x i16> %1918 to <4 x i32>
  %1921 = bitcast <8 x i16> %1919 to <4 x i32>
  %1922 = sub <4 x i32> %1920, %1921
  %1923 = sub <4 x i32> zeroinitializer, %1922
  %1924 = icmp slt <4 x i32> %1922, zeroinitializer
  %1925 = select <4 x i1> %1924, <4 x i32> %1923, <4 x i32> %1922
  %1926 = add nuw <4 x i32> %1925, <i32 32, i32 32, i32 32, i32 32>
  %1927 = lshr <4 x i32> %1926, <i32 6, i32 6, i32 6, i32 6>
  %1928 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1917, <4 x i32> %1927) #5
  %1929 = lshr <8 x i16> %1928, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1930 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1901, <8 x i16> %1929) #5
  %1931 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1930, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1932 = icmp slt <16 x i8> %1931, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1933 = select <16 x i1> %1932, <16 x i8> %1931, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1934 = bitcast i8* %1875 to <16 x i8>*
  store <16 x i8> %1933, <16 x i8>* %1934, align 16
  %1935 = getelementptr inbounds i16, i16* %10, i64 496
  %1936 = getelementptr inbounds i16, i16* %11, i64 496
  %1937 = getelementptr inbounds i8, i8* %1751, i64 48
  %1938 = bitcast i16* %1935 to <8 x i16>*
  %1939 = load <8 x i16>, <8 x i16>* %1938, align 16
  %1940 = bitcast i16* %1936 to <8 x i16>*
  %1941 = load <8 x i16>, <8 x i16>* %1940, align 16
  %1942 = shufflevector <8 x i16> %1939, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1943 = zext <4 x i16> %1942 to <4 x i32>
  %1944 = shufflevector <8 x i16> %1941, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1945 = zext <4 x i16> %1944 to <4 x i32>
  %1946 = sub nsw <4 x i32> %1943, %1945
  %1947 = sub nsw <4 x i32> zeroinitializer, %1946
  %1948 = icmp slt <4 x i32> %1946, zeroinitializer
  %1949 = select <4 x i1> %1948, <4 x i32> %1947, <4 x i32> %1946
  %1950 = add nuw nsw <4 x i32> %1949, <i32 32, i32 32, i32 32, i32 32>
  %1951 = lshr <4 x i32> %1950, <i32 6, i32 6, i32 6, i32 6>
  %1952 = shufflevector <8 x i16> %1939, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1953 = shufflevector <8 x i16> %1941, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1954 = bitcast <8 x i16> %1952 to <4 x i32>
  %1955 = bitcast <8 x i16> %1953 to <4 x i32>
  %1956 = sub <4 x i32> %1954, %1955
  %1957 = sub <4 x i32> zeroinitializer, %1956
  %1958 = icmp slt <4 x i32> %1956, zeroinitializer
  %1959 = select <4 x i1> %1958, <4 x i32> %1957, <4 x i32> %1956
  %1960 = add nuw <4 x i32> %1959, <i32 32, i32 32, i32 32, i32 32>
  %1961 = lshr <4 x i32> %1960, <i32 6, i32 6, i32 6, i32 6>
  %1962 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1951, <4 x i32> %1961) #5
  %1963 = lshr <8 x i16> %1962, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1964 = getelementptr inbounds i16, i16* %10, i64 504
  %1965 = bitcast i16* %1964 to <8 x i16>*
  %1966 = load <8 x i16>, <8 x i16>* %1965, align 16
  %1967 = getelementptr inbounds i16, i16* %11, i64 504
  %1968 = bitcast i16* %1967 to <8 x i16>*
  %1969 = load <8 x i16>, <8 x i16>* %1968, align 16
  %1970 = shufflevector <8 x i16> %1966, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1971 = zext <4 x i16> %1970 to <4 x i32>
  %1972 = shufflevector <8 x i16> %1969, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1973 = zext <4 x i16> %1972 to <4 x i32>
  %1974 = sub nsw <4 x i32> %1971, %1973
  %1975 = sub nsw <4 x i32> zeroinitializer, %1974
  %1976 = icmp slt <4 x i32> %1974, zeroinitializer
  %1977 = select <4 x i1> %1976, <4 x i32> %1975, <4 x i32> %1974
  %1978 = add nuw nsw <4 x i32> %1977, <i32 32, i32 32, i32 32, i32 32>
  %1979 = lshr <4 x i32> %1978, <i32 6, i32 6, i32 6, i32 6>
  %1980 = shufflevector <8 x i16> %1966, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1981 = shufflevector <8 x i16> %1969, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1982 = bitcast <8 x i16> %1980 to <4 x i32>
  %1983 = bitcast <8 x i16> %1981 to <4 x i32>
  %1984 = sub <4 x i32> %1982, %1983
  %1985 = sub <4 x i32> zeroinitializer, %1984
  %1986 = icmp slt <4 x i32> %1984, zeroinitializer
  %1987 = select <4 x i1> %1986, <4 x i32> %1985, <4 x i32> %1984
  %1988 = add nuw <4 x i32> %1987, <i32 32, i32 32, i32 32, i32 32>
  %1989 = lshr <4 x i32> %1988, <i32 6, i32 6, i32 6, i32 6>
  %1990 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1979, <4 x i32> %1989) #5
  %1991 = lshr <8 x i16> %1990, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1992 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1963, <8 x i16> %1991) #5
  %1993 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1992, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1994 = icmp slt <16 x i8> %1993, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1995 = select <16 x i1> %1994, <16 x i8> %1993, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1996 = bitcast i8* %1937 to <16 x i8>*
  store <16 x i8> %1995, <16 x i8>* %1996, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_127WeightMask128x64_10bpp_SSE4ILb1EEEvPKvS5_Phl(i8* readonly, i8* readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  %7 = add nsw i64 %3, -64
  br label %8

8:                                                ; preds = %8, %4
  %9 = phi i8* [ %2, %4 ], [ %1524, %8 ]
  %10 = phi i16* [ %5, %4 ], [ %1522, %8 ]
  %11 = phi i16* [ %6, %4 ], [ %1523, %8 ]
  %12 = phi i32 [ 21, %4 ], [ %1525, %8 ]
  %13 = bitcast i16* %10 to <8 x i16>*
  %14 = load <8 x i16>, <8 x i16>* %13, align 16
  %15 = bitcast i16* %11 to <8 x i16>*
  %16 = load <8 x i16>, <8 x i16>* %15, align 16
  %17 = shufflevector <8 x i16> %14, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %18 = zext <4 x i16> %17 to <4 x i32>
  %19 = shufflevector <8 x i16> %16, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %20 = zext <4 x i16> %19 to <4 x i32>
  %21 = sub nsw <4 x i32> %18, %20
  %22 = sub nsw <4 x i32> zeroinitializer, %21
  %23 = icmp slt <4 x i32> %21, zeroinitializer
  %24 = select <4 x i1> %23, <4 x i32> %22, <4 x i32> %21
  %25 = add nuw nsw <4 x i32> %24, <i32 32, i32 32, i32 32, i32 32>
  %26 = lshr <4 x i32> %25, <i32 6, i32 6, i32 6, i32 6>
  %27 = shufflevector <8 x i16> %14, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %28 = shufflevector <8 x i16> %16, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %29 = bitcast <8 x i16> %27 to <4 x i32>
  %30 = bitcast <8 x i16> %28 to <4 x i32>
  %31 = sub <4 x i32> %29, %30
  %32 = sub <4 x i32> zeroinitializer, %31
  %33 = icmp slt <4 x i32> %31, zeroinitializer
  %34 = select <4 x i1> %33, <4 x i32> %32, <4 x i32> %31
  %35 = add nuw <4 x i32> %34, <i32 32, i32 32, i32 32, i32 32>
  %36 = lshr <4 x i32> %35, <i32 6, i32 6, i32 6, i32 6>
  %37 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %26, <4 x i32> %36) #5
  %38 = lshr <8 x i16> %37, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %39 = getelementptr inbounds i16, i16* %10, i64 8
  %40 = bitcast i16* %39 to <8 x i16>*
  %41 = load <8 x i16>, <8 x i16>* %40, align 16
  %42 = getelementptr inbounds i16, i16* %11, i64 8
  %43 = bitcast i16* %42 to <8 x i16>*
  %44 = load <8 x i16>, <8 x i16>* %43, align 16
  %45 = shufflevector <8 x i16> %41, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %46 = zext <4 x i16> %45 to <4 x i32>
  %47 = shufflevector <8 x i16> %44, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %48 = zext <4 x i16> %47 to <4 x i32>
  %49 = sub nsw <4 x i32> %46, %48
  %50 = sub nsw <4 x i32> zeroinitializer, %49
  %51 = icmp slt <4 x i32> %49, zeroinitializer
  %52 = select <4 x i1> %51, <4 x i32> %50, <4 x i32> %49
  %53 = add nuw nsw <4 x i32> %52, <i32 32, i32 32, i32 32, i32 32>
  %54 = lshr <4 x i32> %53, <i32 6, i32 6, i32 6, i32 6>
  %55 = shufflevector <8 x i16> %41, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %56 = shufflevector <8 x i16> %44, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %57 = bitcast <8 x i16> %55 to <4 x i32>
  %58 = bitcast <8 x i16> %56 to <4 x i32>
  %59 = sub <4 x i32> %57, %58
  %60 = sub <4 x i32> zeroinitializer, %59
  %61 = icmp slt <4 x i32> %59, zeroinitializer
  %62 = select <4 x i1> %61, <4 x i32> %60, <4 x i32> %59
  %63 = add nuw <4 x i32> %62, <i32 32, i32 32, i32 32, i32 32>
  %64 = lshr <4 x i32> %63, <i32 6, i32 6, i32 6, i32 6>
  %65 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %54, <4 x i32> %64) #5
  %66 = lshr <8 x i16> %65, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %67 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %38, <8 x i16> %66) #5
  %68 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %67, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %69 = icmp slt <16 x i8> %68, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %70 = select <16 x i1> %69, <16 x i8> %68, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %71 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %70
  %72 = bitcast i8* %9 to <16 x i8>*
  store <16 x i8> %71, <16 x i8>* %72, align 16
  %73 = getelementptr inbounds i16, i16* %10, i64 16
  %74 = getelementptr inbounds i16, i16* %11, i64 16
  %75 = getelementptr inbounds i8, i8* %9, i64 16
  %76 = bitcast i16* %73 to <8 x i16>*
  %77 = load <8 x i16>, <8 x i16>* %76, align 16
  %78 = bitcast i16* %74 to <8 x i16>*
  %79 = load <8 x i16>, <8 x i16>* %78, align 16
  %80 = shufflevector <8 x i16> %77, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %81 = zext <4 x i16> %80 to <4 x i32>
  %82 = shufflevector <8 x i16> %79, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %83 = zext <4 x i16> %82 to <4 x i32>
  %84 = sub nsw <4 x i32> %81, %83
  %85 = sub nsw <4 x i32> zeroinitializer, %84
  %86 = icmp slt <4 x i32> %84, zeroinitializer
  %87 = select <4 x i1> %86, <4 x i32> %85, <4 x i32> %84
  %88 = add nuw nsw <4 x i32> %87, <i32 32, i32 32, i32 32, i32 32>
  %89 = lshr <4 x i32> %88, <i32 6, i32 6, i32 6, i32 6>
  %90 = shufflevector <8 x i16> %77, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %91 = shufflevector <8 x i16> %79, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %92 = bitcast <8 x i16> %90 to <4 x i32>
  %93 = bitcast <8 x i16> %91 to <4 x i32>
  %94 = sub <4 x i32> %92, %93
  %95 = sub <4 x i32> zeroinitializer, %94
  %96 = icmp slt <4 x i32> %94, zeroinitializer
  %97 = select <4 x i1> %96, <4 x i32> %95, <4 x i32> %94
  %98 = add nuw <4 x i32> %97, <i32 32, i32 32, i32 32, i32 32>
  %99 = lshr <4 x i32> %98, <i32 6, i32 6, i32 6, i32 6>
  %100 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %89, <4 x i32> %99) #5
  %101 = lshr <8 x i16> %100, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %102 = getelementptr inbounds i16, i16* %10, i64 24
  %103 = bitcast i16* %102 to <8 x i16>*
  %104 = load <8 x i16>, <8 x i16>* %103, align 16
  %105 = getelementptr inbounds i16, i16* %11, i64 24
  %106 = bitcast i16* %105 to <8 x i16>*
  %107 = load <8 x i16>, <8 x i16>* %106, align 16
  %108 = shufflevector <8 x i16> %104, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %109 = zext <4 x i16> %108 to <4 x i32>
  %110 = shufflevector <8 x i16> %107, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %111 = zext <4 x i16> %110 to <4 x i32>
  %112 = sub nsw <4 x i32> %109, %111
  %113 = sub nsw <4 x i32> zeroinitializer, %112
  %114 = icmp slt <4 x i32> %112, zeroinitializer
  %115 = select <4 x i1> %114, <4 x i32> %113, <4 x i32> %112
  %116 = add nuw nsw <4 x i32> %115, <i32 32, i32 32, i32 32, i32 32>
  %117 = lshr <4 x i32> %116, <i32 6, i32 6, i32 6, i32 6>
  %118 = shufflevector <8 x i16> %104, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %119 = shufflevector <8 x i16> %107, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %120 = bitcast <8 x i16> %118 to <4 x i32>
  %121 = bitcast <8 x i16> %119 to <4 x i32>
  %122 = sub <4 x i32> %120, %121
  %123 = sub <4 x i32> zeroinitializer, %122
  %124 = icmp slt <4 x i32> %122, zeroinitializer
  %125 = select <4 x i1> %124, <4 x i32> %123, <4 x i32> %122
  %126 = add nuw <4 x i32> %125, <i32 32, i32 32, i32 32, i32 32>
  %127 = lshr <4 x i32> %126, <i32 6, i32 6, i32 6, i32 6>
  %128 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %117, <4 x i32> %127) #5
  %129 = lshr <8 x i16> %128, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %130 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %101, <8 x i16> %129) #5
  %131 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %130, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %132 = icmp slt <16 x i8> %131, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %133 = select <16 x i1> %132, <16 x i8> %131, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %134 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %133
  %135 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %134, <16 x i8>* %135, align 16
  %136 = getelementptr inbounds i16, i16* %10, i64 32
  %137 = getelementptr inbounds i16, i16* %11, i64 32
  %138 = getelementptr inbounds i8, i8* %9, i64 32
  %139 = bitcast i16* %136 to <8 x i16>*
  %140 = load <8 x i16>, <8 x i16>* %139, align 16
  %141 = bitcast i16* %137 to <8 x i16>*
  %142 = load <8 x i16>, <8 x i16>* %141, align 16
  %143 = shufflevector <8 x i16> %140, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %144 = zext <4 x i16> %143 to <4 x i32>
  %145 = shufflevector <8 x i16> %142, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %146 = zext <4 x i16> %145 to <4 x i32>
  %147 = sub nsw <4 x i32> %144, %146
  %148 = sub nsw <4 x i32> zeroinitializer, %147
  %149 = icmp slt <4 x i32> %147, zeroinitializer
  %150 = select <4 x i1> %149, <4 x i32> %148, <4 x i32> %147
  %151 = add nuw nsw <4 x i32> %150, <i32 32, i32 32, i32 32, i32 32>
  %152 = lshr <4 x i32> %151, <i32 6, i32 6, i32 6, i32 6>
  %153 = shufflevector <8 x i16> %140, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %154 = shufflevector <8 x i16> %142, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %155 = bitcast <8 x i16> %153 to <4 x i32>
  %156 = bitcast <8 x i16> %154 to <4 x i32>
  %157 = sub <4 x i32> %155, %156
  %158 = sub <4 x i32> zeroinitializer, %157
  %159 = icmp slt <4 x i32> %157, zeroinitializer
  %160 = select <4 x i1> %159, <4 x i32> %158, <4 x i32> %157
  %161 = add nuw <4 x i32> %160, <i32 32, i32 32, i32 32, i32 32>
  %162 = lshr <4 x i32> %161, <i32 6, i32 6, i32 6, i32 6>
  %163 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %152, <4 x i32> %162) #5
  %164 = lshr <8 x i16> %163, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %165 = getelementptr inbounds i16, i16* %10, i64 40
  %166 = bitcast i16* %165 to <8 x i16>*
  %167 = load <8 x i16>, <8 x i16>* %166, align 16
  %168 = getelementptr inbounds i16, i16* %11, i64 40
  %169 = bitcast i16* %168 to <8 x i16>*
  %170 = load <8 x i16>, <8 x i16>* %169, align 16
  %171 = shufflevector <8 x i16> %167, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %172 = zext <4 x i16> %171 to <4 x i32>
  %173 = shufflevector <8 x i16> %170, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %174 = zext <4 x i16> %173 to <4 x i32>
  %175 = sub nsw <4 x i32> %172, %174
  %176 = sub nsw <4 x i32> zeroinitializer, %175
  %177 = icmp slt <4 x i32> %175, zeroinitializer
  %178 = select <4 x i1> %177, <4 x i32> %176, <4 x i32> %175
  %179 = add nuw nsw <4 x i32> %178, <i32 32, i32 32, i32 32, i32 32>
  %180 = lshr <4 x i32> %179, <i32 6, i32 6, i32 6, i32 6>
  %181 = shufflevector <8 x i16> %167, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %182 = shufflevector <8 x i16> %170, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %183 = bitcast <8 x i16> %181 to <4 x i32>
  %184 = bitcast <8 x i16> %182 to <4 x i32>
  %185 = sub <4 x i32> %183, %184
  %186 = sub <4 x i32> zeroinitializer, %185
  %187 = icmp slt <4 x i32> %185, zeroinitializer
  %188 = select <4 x i1> %187, <4 x i32> %186, <4 x i32> %185
  %189 = add nuw <4 x i32> %188, <i32 32, i32 32, i32 32, i32 32>
  %190 = lshr <4 x i32> %189, <i32 6, i32 6, i32 6, i32 6>
  %191 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %180, <4 x i32> %190) #5
  %192 = lshr <8 x i16> %191, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %193 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %164, <8 x i16> %192) #5
  %194 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %193, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %195 = icmp slt <16 x i8> %194, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %196 = select <16 x i1> %195, <16 x i8> %194, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %197 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %196
  %198 = bitcast i8* %138 to <16 x i8>*
  store <16 x i8> %197, <16 x i8>* %198, align 16
  %199 = getelementptr inbounds i16, i16* %10, i64 48
  %200 = getelementptr inbounds i16, i16* %11, i64 48
  %201 = getelementptr inbounds i8, i8* %9, i64 48
  %202 = bitcast i16* %199 to <8 x i16>*
  %203 = load <8 x i16>, <8 x i16>* %202, align 16
  %204 = bitcast i16* %200 to <8 x i16>*
  %205 = load <8 x i16>, <8 x i16>* %204, align 16
  %206 = shufflevector <8 x i16> %203, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %207 = zext <4 x i16> %206 to <4 x i32>
  %208 = shufflevector <8 x i16> %205, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %209 = zext <4 x i16> %208 to <4 x i32>
  %210 = sub nsw <4 x i32> %207, %209
  %211 = sub nsw <4 x i32> zeroinitializer, %210
  %212 = icmp slt <4 x i32> %210, zeroinitializer
  %213 = select <4 x i1> %212, <4 x i32> %211, <4 x i32> %210
  %214 = add nuw nsw <4 x i32> %213, <i32 32, i32 32, i32 32, i32 32>
  %215 = lshr <4 x i32> %214, <i32 6, i32 6, i32 6, i32 6>
  %216 = shufflevector <8 x i16> %203, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %217 = shufflevector <8 x i16> %205, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %218 = bitcast <8 x i16> %216 to <4 x i32>
  %219 = bitcast <8 x i16> %217 to <4 x i32>
  %220 = sub <4 x i32> %218, %219
  %221 = sub <4 x i32> zeroinitializer, %220
  %222 = icmp slt <4 x i32> %220, zeroinitializer
  %223 = select <4 x i1> %222, <4 x i32> %221, <4 x i32> %220
  %224 = add nuw <4 x i32> %223, <i32 32, i32 32, i32 32, i32 32>
  %225 = lshr <4 x i32> %224, <i32 6, i32 6, i32 6, i32 6>
  %226 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %215, <4 x i32> %225) #5
  %227 = lshr <8 x i16> %226, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %228 = getelementptr inbounds i16, i16* %10, i64 56
  %229 = bitcast i16* %228 to <8 x i16>*
  %230 = load <8 x i16>, <8 x i16>* %229, align 16
  %231 = getelementptr inbounds i16, i16* %11, i64 56
  %232 = bitcast i16* %231 to <8 x i16>*
  %233 = load <8 x i16>, <8 x i16>* %232, align 16
  %234 = shufflevector <8 x i16> %230, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %235 = zext <4 x i16> %234 to <4 x i32>
  %236 = shufflevector <8 x i16> %233, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %237 = zext <4 x i16> %236 to <4 x i32>
  %238 = sub nsw <4 x i32> %235, %237
  %239 = sub nsw <4 x i32> zeroinitializer, %238
  %240 = icmp slt <4 x i32> %238, zeroinitializer
  %241 = select <4 x i1> %240, <4 x i32> %239, <4 x i32> %238
  %242 = add nuw nsw <4 x i32> %241, <i32 32, i32 32, i32 32, i32 32>
  %243 = lshr <4 x i32> %242, <i32 6, i32 6, i32 6, i32 6>
  %244 = shufflevector <8 x i16> %230, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %245 = shufflevector <8 x i16> %233, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %246 = bitcast <8 x i16> %244 to <4 x i32>
  %247 = bitcast <8 x i16> %245 to <4 x i32>
  %248 = sub <4 x i32> %246, %247
  %249 = sub <4 x i32> zeroinitializer, %248
  %250 = icmp slt <4 x i32> %248, zeroinitializer
  %251 = select <4 x i1> %250, <4 x i32> %249, <4 x i32> %248
  %252 = add nuw <4 x i32> %251, <i32 32, i32 32, i32 32, i32 32>
  %253 = lshr <4 x i32> %252, <i32 6, i32 6, i32 6, i32 6>
  %254 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %243, <4 x i32> %253) #5
  %255 = lshr <8 x i16> %254, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %256 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %227, <8 x i16> %255) #5
  %257 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %256, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %258 = icmp slt <16 x i8> %257, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %259 = select <16 x i1> %258, <16 x i8> %257, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %260 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %259
  %261 = bitcast i8* %201 to <16 x i8>*
  store <16 x i8> %260, <16 x i8>* %261, align 16
  %262 = getelementptr inbounds i16, i16* %10, i64 64
  %263 = getelementptr inbounds i16, i16* %11, i64 64
  %264 = getelementptr inbounds i8, i8* %9, i64 64
  %265 = bitcast i16* %262 to <8 x i16>*
  %266 = load <8 x i16>, <8 x i16>* %265, align 16
  %267 = bitcast i16* %263 to <8 x i16>*
  %268 = load <8 x i16>, <8 x i16>* %267, align 16
  %269 = shufflevector <8 x i16> %266, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %270 = zext <4 x i16> %269 to <4 x i32>
  %271 = shufflevector <8 x i16> %268, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %272 = zext <4 x i16> %271 to <4 x i32>
  %273 = sub nsw <4 x i32> %270, %272
  %274 = sub nsw <4 x i32> zeroinitializer, %273
  %275 = icmp slt <4 x i32> %273, zeroinitializer
  %276 = select <4 x i1> %275, <4 x i32> %274, <4 x i32> %273
  %277 = add nuw nsw <4 x i32> %276, <i32 32, i32 32, i32 32, i32 32>
  %278 = lshr <4 x i32> %277, <i32 6, i32 6, i32 6, i32 6>
  %279 = shufflevector <8 x i16> %266, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %280 = shufflevector <8 x i16> %268, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %281 = bitcast <8 x i16> %279 to <4 x i32>
  %282 = bitcast <8 x i16> %280 to <4 x i32>
  %283 = sub <4 x i32> %281, %282
  %284 = sub <4 x i32> zeroinitializer, %283
  %285 = icmp slt <4 x i32> %283, zeroinitializer
  %286 = select <4 x i1> %285, <4 x i32> %284, <4 x i32> %283
  %287 = add nuw <4 x i32> %286, <i32 32, i32 32, i32 32, i32 32>
  %288 = lshr <4 x i32> %287, <i32 6, i32 6, i32 6, i32 6>
  %289 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %278, <4 x i32> %288) #5
  %290 = lshr <8 x i16> %289, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %291 = getelementptr inbounds i16, i16* %10, i64 72
  %292 = bitcast i16* %291 to <8 x i16>*
  %293 = load <8 x i16>, <8 x i16>* %292, align 16
  %294 = getelementptr inbounds i16, i16* %11, i64 72
  %295 = bitcast i16* %294 to <8 x i16>*
  %296 = load <8 x i16>, <8 x i16>* %295, align 16
  %297 = shufflevector <8 x i16> %293, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %298 = zext <4 x i16> %297 to <4 x i32>
  %299 = shufflevector <8 x i16> %296, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %300 = zext <4 x i16> %299 to <4 x i32>
  %301 = sub nsw <4 x i32> %298, %300
  %302 = sub nsw <4 x i32> zeroinitializer, %301
  %303 = icmp slt <4 x i32> %301, zeroinitializer
  %304 = select <4 x i1> %303, <4 x i32> %302, <4 x i32> %301
  %305 = add nuw nsw <4 x i32> %304, <i32 32, i32 32, i32 32, i32 32>
  %306 = lshr <4 x i32> %305, <i32 6, i32 6, i32 6, i32 6>
  %307 = shufflevector <8 x i16> %293, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %308 = shufflevector <8 x i16> %296, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %309 = bitcast <8 x i16> %307 to <4 x i32>
  %310 = bitcast <8 x i16> %308 to <4 x i32>
  %311 = sub <4 x i32> %309, %310
  %312 = sub <4 x i32> zeroinitializer, %311
  %313 = icmp slt <4 x i32> %311, zeroinitializer
  %314 = select <4 x i1> %313, <4 x i32> %312, <4 x i32> %311
  %315 = add nuw <4 x i32> %314, <i32 32, i32 32, i32 32, i32 32>
  %316 = lshr <4 x i32> %315, <i32 6, i32 6, i32 6, i32 6>
  %317 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %306, <4 x i32> %316) #5
  %318 = lshr <8 x i16> %317, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %319 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %290, <8 x i16> %318) #5
  %320 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %319, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %321 = icmp slt <16 x i8> %320, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %322 = select <16 x i1> %321, <16 x i8> %320, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %323 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %322
  %324 = bitcast i8* %264 to <16 x i8>*
  store <16 x i8> %323, <16 x i8>* %324, align 16
  %325 = getelementptr inbounds i16, i16* %10, i64 80
  %326 = getelementptr inbounds i16, i16* %11, i64 80
  %327 = getelementptr inbounds i8, i8* %9, i64 80
  %328 = bitcast i16* %325 to <8 x i16>*
  %329 = load <8 x i16>, <8 x i16>* %328, align 16
  %330 = bitcast i16* %326 to <8 x i16>*
  %331 = load <8 x i16>, <8 x i16>* %330, align 16
  %332 = shufflevector <8 x i16> %329, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %333 = zext <4 x i16> %332 to <4 x i32>
  %334 = shufflevector <8 x i16> %331, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %335 = zext <4 x i16> %334 to <4 x i32>
  %336 = sub nsw <4 x i32> %333, %335
  %337 = sub nsw <4 x i32> zeroinitializer, %336
  %338 = icmp slt <4 x i32> %336, zeroinitializer
  %339 = select <4 x i1> %338, <4 x i32> %337, <4 x i32> %336
  %340 = add nuw nsw <4 x i32> %339, <i32 32, i32 32, i32 32, i32 32>
  %341 = lshr <4 x i32> %340, <i32 6, i32 6, i32 6, i32 6>
  %342 = shufflevector <8 x i16> %329, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %343 = shufflevector <8 x i16> %331, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %344 = bitcast <8 x i16> %342 to <4 x i32>
  %345 = bitcast <8 x i16> %343 to <4 x i32>
  %346 = sub <4 x i32> %344, %345
  %347 = sub <4 x i32> zeroinitializer, %346
  %348 = icmp slt <4 x i32> %346, zeroinitializer
  %349 = select <4 x i1> %348, <4 x i32> %347, <4 x i32> %346
  %350 = add nuw <4 x i32> %349, <i32 32, i32 32, i32 32, i32 32>
  %351 = lshr <4 x i32> %350, <i32 6, i32 6, i32 6, i32 6>
  %352 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %341, <4 x i32> %351) #5
  %353 = lshr <8 x i16> %352, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %354 = getelementptr inbounds i16, i16* %10, i64 88
  %355 = bitcast i16* %354 to <8 x i16>*
  %356 = load <8 x i16>, <8 x i16>* %355, align 16
  %357 = getelementptr inbounds i16, i16* %11, i64 88
  %358 = bitcast i16* %357 to <8 x i16>*
  %359 = load <8 x i16>, <8 x i16>* %358, align 16
  %360 = shufflevector <8 x i16> %356, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %361 = zext <4 x i16> %360 to <4 x i32>
  %362 = shufflevector <8 x i16> %359, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %363 = zext <4 x i16> %362 to <4 x i32>
  %364 = sub nsw <4 x i32> %361, %363
  %365 = sub nsw <4 x i32> zeroinitializer, %364
  %366 = icmp slt <4 x i32> %364, zeroinitializer
  %367 = select <4 x i1> %366, <4 x i32> %365, <4 x i32> %364
  %368 = add nuw nsw <4 x i32> %367, <i32 32, i32 32, i32 32, i32 32>
  %369 = lshr <4 x i32> %368, <i32 6, i32 6, i32 6, i32 6>
  %370 = shufflevector <8 x i16> %356, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %371 = shufflevector <8 x i16> %359, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %372 = bitcast <8 x i16> %370 to <4 x i32>
  %373 = bitcast <8 x i16> %371 to <4 x i32>
  %374 = sub <4 x i32> %372, %373
  %375 = sub <4 x i32> zeroinitializer, %374
  %376 = icmp slt <4 x i32> %374, zeroinitializer
  %377 = select <4 x i1> %376, <4 x i32> %375, <4 x i32> %374
  %378 = add nuw <4 x i32> %377, <i32 32, i32 32, i32 32, i32 32>
  %379 = lshr <4 x i32> %378, <i32 6, i32 6, i32 6, i32 6>
  %380 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %369, <4 x i32> %379) #5
  %381 = lshr <8 x i16> %380, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %382 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %353, <8 x i16> %381) #5
  %383 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %382, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %384 = icmp slt <16 x i8> %383, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %385 = select <16 x i1> %384, <16 x i8> %383, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %386 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %385
  %387 = bitcast i8* %327 to <16 x i8>*
  store <16 x i8> %386, <16 x i8>* %387, align 16
  %388 = getelementptr inbounds i16, i16* %10, i64 96
  %389 = getelementptr inbounds i16, i16* %11, i64 96
  %390 = getelementptr inbounds i8, i8* %9, i64 96
  %391 = bitcast i16* %388 to <8 x i16>*
  %392 = load <8 x i16>, <8 x i16>* %391, align 16
  %393 = bitcast i16* %389 to <8 x i16>*
  %394 = load <8 x i16>, <8 x i16>* %393, align 16
  %395 = shufflevector <8 x i16> %392, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %396 = zext <4 x i16> %395 to <4 x i32>
  %397 = shufflevector <8 x i16> %394, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %398 = zext <4 x i16> %397 to <4 x i32>
  %399 = sub nsw <4 x i32> %396, %398
  %400 = sub nsw <4 x i32> zeroinitializer, %399
  %401 = icmp slt <4 x i32> %399, zeroinitializer
  %402 = select <4 x i1> %401, <4 x i32> %400, <4 x i32> %399
  %403 = add nuw nsw <4 x i32> %402, <i32 32, i32 32, i32 32, i32 32>
  %404 = lshr <4 x i32> %403, <i32 6, i32 6, i32 6, i32 6>
  %405 = shufflevector <8 x i16> %392, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %406 = shufflevector <8 x i16> %394, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %407 = bitcast <8 x i16> %405 to <4 x i32>
  %408 = bitcast <8 x i16> %406 to <4 x i32>
  %409 = sub <4 x i32> %407, %408
  %410 = sub <4 x i32> zeroinitializer, %409
  %411 = icmp slt <4 x i32> %409, zeroinitializer
  %412 = select <4 x i1> %411, <4 x i32> %410, <4 x i32> %409
  %413 = add nuw <4 x i32> %412, <i32 32, i32 32, i32 32, i32 32>
  %414 = lshr <4 x i32> %413, <i32 6, i32 6, i32 6, i32 6>
  %415 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %404, <4 x i32> %414) #5
  %416 = lshr <8 x i16> %415, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %417 = getelementptr inbounds i16, i16* %10, i64 104
  %418 = bitcast i16* %417 to <8 x i16>*
  %419 = load <8 x i16>, <8 x i16>* %418, align 16
  %420 = getelementptr inbounds i16, i16* %11, i64 104
  %421 = bitcast i16* %420 to <8 x i16>*
  %422 = load <8 x i16>, <8 x i16>* %421, align 16
  %423 = shufflevector <8 x i16> %419, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %424 = zext <4 x i16> %423 to <4 x i32>
  %425 = shufflevector <8 x i16> %422, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %426 = zext <4 x i16> %425 to <4 x i32>
  %427 = sub nsw <4 x i32> %424, %426
  %428 = sub nsw <4 x i32> zeroinitializer, %427
  %429 = icmp slt <4 x i32> %427, zeroinitializer
  %430 = select <4 x i1> %429, <4 x i32> %428, <4 x i32> %427
  %431 = add nuw nsw <4 x i32> %430, <i32 32, i32 32, i32 32, i32 32>
  %432 = lshr <4 x i32> %431, <i32 6, i32 6, i32 6, i32 6>
  %433 = shufflevector <8 x i16> %419, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %434 = shufflevector <8 x i16> %422, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %435 = bitcast <8 x i16> %433 to <4 x i32>
  %436 = bitcast <8 x i16> %434 to <4 x i32>
  %437 = sub <4 x i32> %435, %436
  %438 = sub <4 x i32> zeroinitializer, %437
  %439 = icmp slt <4 x i32> %437, zeroinitializer
  %440 = select <4 x i1> %439, <4 x i32> %438, <4 x i32> %437
  %441 = add nuw <4 x i32> %440, <i32 32, i32 32, i32 32, i32 32>
  %442 = lshr <4 x i32> %441, <i32 6, i32 6, i32 6, i32 6>
  %443 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %432, <4 x i32> %442) #5
  %444 = lshr <8 x i16> %443, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %445 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %416, <8 x i16> %444) #5
  %446 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %445, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %447 = icmp slt <16 x i8> %446, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %448 = select <16 x i1> %447, <16 x i8> %446, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %449 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %448
  %450 = bitcast i8* %390 to <16 x i8>*
  store <16 x i8> %449, <16 x i8>* %450, align 16
  %451 = getelementptr inbounds i16, i16* %10, i64 112
  %452 = getelementptr inbounds i16, i16* %11, i64 112
  %453 = getelementptr inbounds i8, i8* %9, i64 112
  %454 = bitcast i16* %451 to <8 x i16>*
  %455 = load <8 x i16>, <8 x i16>* %454, align 16
  %456 = bitcast i16* %452 to <8 x i16>*
  %457 = load <8 x i16>, <8 x i16>* %456, align 16
  %458 = shufflevector <8 x i16> %455, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %459 = zext <4 x i16> %458 to <4 x i32>
  %460 = shufflevector <8 x i16> %457, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %461 = zext <4 x i16> %460 to <4 x i32>
  %462 = sub nsw <4 x i32> %459, %461
  %463 = sub nsw <4 x i32> zeroinitializer, %462
  %464 = icmp slt <4 x i32> %462, zeroinitializer
  %465 = select <4 x i1> %464, <4 x i32> %463, <4 x i32> %462
  %466 = add nuw nsw <4 x i32> %465, <i32 32, i32 32, i32 32, i32 32>
  %467 = lshr <4 x i32> %466, <i32 6, i32 6, i32 6, i32 6>
  %468 = shufflevector <8 x i16> %455, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %469 = shufflevector <8 x i16> %457, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %470 = bitcast <8 x i16> %468 to <4 x i32>
  %471 = bitcast <8 x i16> %469 to <4 x i32>
  %472 = sub <4 x i32> %470, %471
  %473 = sub <4 x i32> zeroinitializer, %472
  %474 = icmp slt <4 x i32> %472, zeroinitializer
  %475 = select <4 x i1> %474, <4 x i32> %473, <4 x i32> %472
  %476 = add nuw <4 x i32> %475, <i32 32, i32 32, i32 32, i32 32>
  %477 = lshr <4 x i32> %476, <i32 6, i32 6, i32 6, i32 6>
  %478 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %467, <4 x i32> %477) #5
  %479 = lshr <8 x i16> %478, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %480 = getelementptr inbounds i16, i16* %10, i64 120
  %481 = bitcast i16* %480 to <8 x i16>*
  %482 = load <8 x i16>, <8 x i16>* %481, align 16
  %483 = getelementptr inbounds i16, i16* %11, i64 120
  %484 = bitcast i16* %483 to <8 x i16>*
  %485 = load <8 x i16>, <8 x i16>* %484, align 16
  %486 = shufflevector <8 x i16> %482, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %487 = zext <4 x i16> %486 to <4 x i32>
  %488 = shufflevector <8 x i16> %485, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %489 = zext <4 x i16> %488 to <4 x i32>
  %490 = sub nsw <4 x i32> %487, %489
  %491 = sub nsw <4 x i32> zeroinitializer, %490
  %492 = icmp slt <4 x i32> %490, zeroinitializer
  %493 = select <4 x i1> %492, <4 x i32> %491, <4 x i32> %490
  %494 = add nuw nsw <4 x i32> %493, <i32 32, i32 32, i32 32, i32 32>
  %495 = lshr <4 x i32> %494, <i32 6, i32 6, i32 6, i32 6>
  %496 = shufflevector <8 x i16> %482, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %497 = shufflevector <8 x i16> %485, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %498 = bitcast <8 x i16> %496 to <4 x i32>
  %499 = bitcast <8 x i16> %497 to <4 x i32>
  %500 = sub <4 x i32> %498, %499
  %501 = sub <4 x i32> zeroinitializer, %500
  %502 = icmp slt <4 x i32> %500, zeroinitializer
  %503 = select <4 x i1> %502, <4 x i32> %501, <4 x i32> %500
  %504 = add nuw <4 x i32> %503, <i32 32, i32 32, i32 32, i32 32>
  %505 = lshr <4 x i32> %504, <i32 6, i32 6, i32 6, i32 6>
  %506 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %495, <4 x i32> %505) #5
  %507 = lshr <8 x i16> %506, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %508 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %479, <8 x i16> %507) #5
  %509 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %508, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %510 = icmp slt <16 x i8> %509, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %511 = select <16 x i1> %510, <16 x i8> %509, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %512 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %511
  %513 = bitcast i8* %453 to <16 x i8>*
  store <16 x i8> %512, <16 x i8>* %513, align 16
  %514 = getelementptr inbounds i16, i16* %10, i64 128
  %515 = getelementptr inbounds i16, i16* %11, i64 128
  %516 = getelementptr inbounds i8, i8* %9, i64 %3
  %517 = bitcast i16* %514 to <8 x i16>*
  %518 = load <8 x i16>, <8 x i16>* %517, align 16
  %519 = bitcast i16* %515 to <8 x i16>*
  %520 = load <8 x i16>, <8 x i16>* %519, align 16
  %521 = shufflevector <8 x i16> %518, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %522 = zext <4 x i16> %521 to <4 x i32>
  %523 = shufflevector <8 x i16> %520, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %524 = zext <4 x i16> %523 to <4 x i32>
  %525 = sub nsw <4 x i32> %522, %524
  %526 = sub nsw <4 x i32> zeroinitializer, %525
  %527 = icmp slt <4 x i32> %525, zeroinitializer
  %528 = select <4 x i1> %527, <4 x i32> %526, <4 x i32> %525
  %529 = add nuw nsw <4 x i32> %528, <i32 32, i32 32, i32 32, i32 32>
  %530 = lshr <4 x i32> %529, <i32 6, i32 6, i32 6, i32 6>
  %531 = shufflevector <8 x i16> %518, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %532 = shufflevector <8 x i16> %520, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %533 = bitcast <8 x i16> %531 to <4 x i32>
  %534 = bitcast <8 x i16> %532 to <4 x i32>
  %535 = sub <4 x i32> %533, %534
  %536 = sub <4 x i32> zeroinitializer, %535
  %537 = icmp slt <4 x i32> %535, zeroinitializer
  %538 = select <4 x i1> %537, <4 x i32> %536, <4 x i32> %535
  %539 = add nuw <4 x i32> %538, <i32 32, i32 32, i32 32, i32 32>
  %540 = lshr <4 x i32> %539, <i32 6, i32 6, i32 6, i32 6>
  %541 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %530, <4 x i32> %540) #5
  %542 = lshr <8 x i16> %541, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %543 = getelementptr inbounds i16, i16* %10, i64 136
  %544 = bitcast i16* %543 to <8 x i16>*
  %545 = load <8 x i16>, <8 x i16>* %544, align 16
  %546 = getelementptr inbounds i16, i16* %11, i64 136
  %547 = bitcast i16* %546 to <8 x i16>*
  %548 = load <8 x i16>, <8 x i16>* %547, align 16
  %549 = shufflevector <8 x i16> %545, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %550 = zext <4 x i16> %549 to <4 x i32>
  %551 = shufflevector <8 x i16> %548, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %552 = zext <4 x i16> %551 to <4 x i32>
  %553 = sub nsw <4 x i32> %550, %552
  %554 = sub nsw <4 x i32> zeroinitializer, %553
  %555 = icmp slt <4 x i32> %553, zeroinitializer
  %556 = select <4 x i1> %555, <4 x i32> %554, <4 x i32> %553
  %557 = add nuw nsw <4 x i32> %556, <i32 32, i32 32, i32 32, i32 32>
  %558 = lshr <4 x i32> %557, <i32 6, i32 6, i32 6, i32 6>
  %559 = shufflevector <8 x i16> %545, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %560 = shufflevector <8 x i16> %548, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %561 = bitcast <8 x i16> %559 to <4 x i32>
  %562 = bitcast <8 x i16> %560 to <4 x i32>
  %563 = sub <4 x i32> %561, %562
  %564 = sub <4 x i32> zeroinitializer, %563
  %565 = icmp slt <4 x i32> %563, zeroinitializer
  %566 = select <4 x i1> %565, <4 x i32> %564, <4 x i32> %563
  %567 = add nuw <4 x i32> %566, <i32 32, i32 32, i32 32, i32 32>
  %568 = lshr <4 x i32> %567, <i32 6, i32 6, i32 6, i32 6>
  %569 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %558, <4 x i32> %568) #5
  %570 = lshr <8 x i16> %569, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %571 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %542, <8 x i16> %570) #5
  %572 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %571, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %573 = icmp slt <16 x i8> %572, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %574 = select <16 x i1> %573, <16 x i8> %572, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %575 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %574
  %576 = bitcast i8* %516 to <16 x i8>*
  store <16 x i8> %575, <16 x i8>* %576, align 16
  %577 = getelementptr inbounds i16, i16* %10, i64 144
  %578 = getelementptr inbounds i16, i16* %11, i64 144
  %579 = getelementptr inbounds i8, i8* %516, i64 16
  %580 = bitcast i16* %577 to <8 x i16>*
  %581 = load <8 x i16>, <8 x i16>* %580, align 16
  %582 = bitcast i16* %578 to <8 x i16>*
  %583 = load <8 x i16>, <8 x i16>* %582, align 16
  %584 = shufflevector <8 x i16> %581, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %585 = zext <4 x i16> %584 to <4 x i32>
  %586 = shufflevector <8 x i16> %583, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %587 = zext <4 x i16> %586 to <4 x i32>
  %588 = sub nsw <4 x i32> %585, %587
  %589 = sub nsw <4 x i32> zeroinitializer, %588
  %590 = icmp slt <4 x i32> %588, zeroinitializer
  %591 = select <4 x i1> %590, <4 x i32> %589, <4 x i32> %588
  %592 = add nuw nsw <4 x i32> %591, <i32 32, i32 32, i32 32, i32 32>
  %593 = lshr <4 x i32> %592, <i32 6, i32 6, i32 6, i32 6>
  %594 = shufflevector <8 x i16> %581, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %595 = shufflevector <8 x i16> %583, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %596 = bitcast <8 x i16> %594 to <4 x i32>
  %597 = bitcast <8 x i16> %595 to <4 x i32>
  %598 = sub <4 x i32> %596, %597
  %599 = sub <4 x i32> zeroinitializer, %598
  %600 = icmp slt <4 x i32> %598, zeroinitializer
  %601 = select <4 x i1> %600, <4 x i32> %599, <4 x i32> %598
  %602 = add nuw <4 x i32> %601, <i32 32, i32 32, i32 32, i32 32>
  %603 = lshr <4 x i32> %602, <i32 6, i32 6, i32 6, i32 6>
  %604 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %593, <4 x i32> %603) #5
  %605 = lshr <8 x i16> %604, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %606 = getelementptr inbounds i16, i16* %10, i64 152
  %607 = bitcast i16* %606 to <8 x i16>*
  %608 = load <8 x i16>, <8 x i16>* %607, align 16
  %609 = getelementptr inbounds i16, i16* %11, i64 152
  %610 = bitcast i16* %609 to <8 x i16>*
  %611 = load <8 x i16>, <8 x i16>* %610, align 16
  %612 = shufflevector <8 x i16> %608, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %613 = zext <4 x i16> %612 to <4 x i32>
  %614 = shufflevector <8 x i16> %611, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %615 = zext <4 x i16> %614 to <4 x i32>
  %616 = sub nsw <4 x i32> %613, %615
  %617 = sub nsw <4 x i32> zeroinitializer, %616
  %618 = icmp slt <4 x i32> %616, zeroinitializer
  %619 = select <4 x i1> %618, <4 x i32> %617, <4 x i32> %616
  %620 = add nuw nsw <4 x i32> %619, <i32 32, i32 32, i32 32, i32 32>
  %621 = lshr <4 x i32> %620, <i32 6, i32 6, i32 6, i32 6>
  %622 = shufflevector <8 x i16> %608, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %623 = shufflevector <8 x i16> %611, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %624 = bitcast <8 x i16> %622 to <4 x i32>
  %625 = bitcast <8 x i16> %623 to <4 x i32>
  %626 = sub <4 x i32> %624, %625
  %627 = sub <4 x i32> zeroinitializer, %626
  %628 = icmp slt <4 x i32> %626, zeroinitializer
  %629 = select <4 x i1> %628, <4 x i32> %627, <4 x i32> %626
  %630 = add nuw <4 x i32> %629, <i32 32, i32 32, i32 32, i32 32>
  %631 = lshr <4 x i32> %630, <i32 6, i32 6, i32 6, i32 6>
  %632 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %621, <4 x i32> %631) #5
  %633 = lshr <8 x i16> %632, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %634 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %605, <8 x i16> %633) #5
  %635 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %634, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %636 = icmp slt <16 x i8> %635, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %637 = select <16 x i1> %636, <16 x i8> %635, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %638 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %637
  %639 = bitcast i8* %579 to <16 x i8>*
  store <16 x i8> %638, <16 x i8>* %639, align 16
  %640 = getelementptr inbounds i16, i16* %10, i64 160
  %641 = getelementptr inbounds i16, i16* %11, i64 160
  %642 = getelementptr inbounds i8, i8* %516, i64 32
  %643 = bitcast i16* %640 to <8 x i16>*
  %644 = load <8 x i16>, <8 x i16>* %643, align 16
  %645 = bitcast i16* %641 to <8 x i16>*
  %646 = load <8 x i16>, <8 x i16>* %645, align 16
  %647 = shufflevector <8 x i16> %644, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %648 = zext <4 x i16> %647 to <4 x i32>
  %649 = shufflevector <8 x i16> %646, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %650 = zext <4 x i16> %649 to <4 x i32>
  %651 = sub nsw <4 x i32> %648, %650
  %652 = sub nsw <4 x i32> zeroinitializer, %651
  %653 = icmp slt <4 x i32> %651, zeroinitializer
  %654 = select <4 x i1> %653, <4 x i32> %652, <4 x i32> %651
  %655 = add nuw nsw <4 x i32> %654, <i32 32, i32 32, i32 32, i32 32>
  %656 = lshr <4 x i32> %655, <i32 6, i32 6, i32 6, i32 6>
  %657 = shufflevector <8 x i16> %644, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %658 = shufflevector <8 x i16> %646, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %659 = bitcast <8 x i16> %657 to <4 x i32>
  %660 = bitcast <8 x i16> %658 to <4 x i32>
  %661 = sub <4 x i32> %659, %660
  %662 = sub <4 x i32> zeroinitializer, %661
  %663 = icmp slt <4 x i32> %661, zeroinitializer
  %664 = select <4 x i1> %663, <4 x i32> %662, <4 x i32> %661
  %665 = add nuw <4 x i32> %664, <i32 32, i32 32, i32 32, i32 32>
  %666 = lshr <4 x i32> %665, <i32 6, i32 6, i32 6, i32 6>
  %667 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %656, <4 x i32> %666) #5
  %668 = lshr <8 x i16> %667, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %669 = getelementptr inbounds i16, i16* %10, i64 168
  %670 = bitcast i16* %669 to <8 x i16>*
  %671 = load <8 x i16>, <8 x i16>* %670, align 16
  %672 = getelementptr inbounds i16, i16* %11, i64 168
  %673 = bitcast i16* %672 to <8 x i16>*
  %674 = load <8 x i16>, <8 x i16>* %673, align 16
  %675 = shufflevector <8 x i16> %671, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %676 = zext <4 x i16> %675 to <4 x i32>
  %677 = shufflevector <8 x i16> %674, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %678 = zext <4 x i16> %677 to <4 x i32>
  %679 = sub nsw <4 x i32> %676, %678
  %680 = sub nsw <4 x i32> zeroinitializer, %679
  %681 = icmp slt <4 x i32> %679, zeroinitializer
  %682 = select <4 x i1> %681, <4 x i32> %680, <4 x i32> %679
  %683 = add nuw nsw <4 x i32> %682, <i32 32, i32 32, i32 32, i32 32>
  %684 = lshr <4 x i32> %683, <i32 6, i32 6, i32 6, i32 6>
  %685 = shufflevector <8 x i16> %671, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %686 = shufflevector <8 x i16> %674, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %687 = bitcast <8 x i16> %685 to <4 x i32>
  %688 = bitcast <8 x i16> %686 to <4 x i32>
  %689 = sub <4 x i32> %687, %688
  %690 = sub <4 x i32> zeroinitializer, %689
  %691 = icmp slt <4 x i32> %689, zeroinitializer
  %692 = select <4 x i1> %691, <4 x i32> %690, <4 x i32> %689
  %693 = add nuw <4 x i32> %692, <i32 32, i32 32, i32 32, i32 32>
  %694 = lshr <4 x i32> %693, <i32 6, i32 6, i32 6, i32 6>
  %695 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %684, <4 x i32> %694) #5
  %696 = lshr <8 x i16> %695, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %697 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %668, <8 x i16> %696) #5
  %698 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %697, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %699 = icmp slt <16 x i8> %698, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %700 = select <16 x i1> %699, <16 x i8> %698, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %701 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %700
  %702 = bitcast i8* %642 to <16 x i8>*
  store <16 x i8> %701, <16 x i8>* %702, align 16
  %703 = getelementptr inbounds i16, i16* %10, i64 176
  %704 = getelementptr inbounds i16, i16* %11, i64 176
  %705 = getelementptr inbounds i8, i8* %516, i64 48
  %706 = bitcast i16* %703 to <8 x i16>*
  %707 = load <8 x i16>, <8 x i16>* %706, align 16
  %708 = bitcast i16* %704 to <8 x i16>*
  %709 = load <8 x i16>, <8 x i16>* %708, align 16
  %710 = shufflevector <8 x i16> %707, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %711 = zext <4 x i16> %710 to <4 x i32>
  %712 = shufflevector <8 x i16> %709, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %713 = zext <4 x i16> %712 to <4 x i32>
  %714 = sub nsw <4 x i32> %711, %713
  %715 = sub nsw <4 x i32> zeroinitializer, %714
  %716 = icmp slt <4 x i32> %714, zeroinitializer
  %717 = select <4 x i1> %716, <4 x i32> %715, <4 x i32> %714
  %718 = add nuw nsw <4 x i32> %717, <i32 32, i32 32, i32 32, i32 32>
  %719 = lshr <4 x i32> %718, <i32 6, i32 6, i32 6, i32 6>
  %720 = shufflevector <8 x i16> %707, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %721 = shufflevector <8 x i16> %709, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %722 = bitcast <8 x i16> %720 to <4 x i32>
  %723 = bitcast <8 x i16> %721 to <4 x i32>
  %724 = sub <4 x i32> %722, %723
  %725 = sub <4 x i32> zeroinitializer, %724
  %726 = icmp slt <4 x i32> %724, zeroinitializer
  %727 = select <4 x i1> %726, <4 x i32> %725, <4 x i32> %724
  %728 = add nuw <4 x i32> %727, <i32 32, i32 32, i32 32, i32 32>
  %729 = lshr <4 x i32> %728, <i32 6, i32 6, i32 6, i32 6>
  %730 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %719, <4 x i32> %729) #5
  %731 = lshr <8 x i16> %730, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %732 = getelementptr inbounds i16, i16* %10, i64 184
  %733 = bitcast i16* %732 to <8 x i16>*
  %734 = load <8 x i16>, <8 x i16>* %733, align 16
  %735 = getelementptr inbounds i16, i16* %11, i64 184
  %736 = bitcast i16* %735 to <8 x i16>*
  %737 = load <8 x i16>, <8 x i16>* %736, align 16
  %738 = shufflevector <8 x i16> %734, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %739 = zext <4 x i16> %738 to <4 x i32>
  %740 = shufflevector <8 x i16> %737, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %741 = zext <4 x i16> %740 to <4 x i32>
  %742 = sub nsw <4 x i32> %739, %741
  %743 = sub nsw <4 x i32> zeroinitializer, %742
  %744 = icmp slt <4 x i32> %742, zeroinitializer
  %745 = select <4 x i1> %744, <4 x i32> %743, <4 x i32> %742
  %746 = add nuw nsw <4 x i32> %745, <i32 32, i32 32, i32 32, i32 32>
  %747 = lshr <4 x i32> %746, <i32 6, i32 6, i32 6, i32 6>
  %748 = shufflevector <8 x i16> %734, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %749 = shufflevector <8 x i16> %737, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %750 = bitcast <8 x i16> %748 to <4 x i32>
  %751 = bitcast <8 x i16> %749 to <4 x i32>
  %752 = sub <4 x i32> %750, %751
  %753 = sub <4 x i32> zeroinitializer, %752
  %754 = icmp slt <4 x i32> %752, zeroinitializer
  %755 = select <4 x i1> %754, <4 x i32> %753, <4 x i32> %752
  %756 = add nuw <4 x i32> %755, <i32 32, i32 32, i32 32, i32 32>
  %757 = lshr <4 x i32> %756, <i32 6, i32 6, i32 6, i32 6>
  %758 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %747, <4 x i32> %757) #5
  %759 = lshr <8 x i16> %758, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %760 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %731, <8 x i16> %759) #5
  %761 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %760, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %762 = icmp slt <16 x i8> %761, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %763 = select <16 x i1> %762, <16 x i8> %761, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %764 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %763
  %765 = bitcast i8* %705 to <16 x i8>*
  store <16 x i8> %764, <16 x i8>* %765, align 16
  %766 = getelementptr inbounds i16, i16* %10, i64 192
  %767 = getelementptr inbounds i16, i16* %11, i64 192
  %768 = getelementptr inbounds i8, i8* %516, i64 64
  %769 = bitcast i16* %766 to <8 x i16>*
  %770 = load <8 x i16>, <8 x i16>* %769, align 16
  %771 = bitcast i16* %767 to <8 x i16>*
  %772 = load <8 x i16>, <8 x i16>* %771, align 16
  %773 = shufflevector <8 x i16> %770, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %774 = zext <4 x i16> %773 to <4 x i32>
  %775 = shufflevector <8 x i16> %772, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %776 = zext <4 x i16> %775 to <4 x i32>
  %777 = sub nsw <4 x i32> %774, %776
  %778 = sub nsw <4 x i32> zeroinitializer, %777
  %779 = icmp slt <4 x i32> %777, zeroinitializer
  %780 = select <4 x i1> %779, <4 x i32> %778, <4 x i32> %777
  %781 = add nuw nsw <4 x i32> %780, <i32 32, i32 32, i32 32, i32 32>
  %782 = lshr <4 x i32> %781, <i32 6, i32 6, i32 6, i32 6>
  %783 = shufflevector <8 x i16> %770, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %784 = shufflevector <8 x i16> %772, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %785 = bitcast <8 x i16> %783 to <4 x i32>
  %786 = bitcast <8 x i16> %784 to <4 x i32>
  %787 = sub <4 x i32> %785, %786
  %788 = sub <4 x i32> zeroinitializer, %787
  %789 = icmp slt <4 x i32> %787, zeroinitializer
  %790 = select <4 x i1> %789, <4 x i32> %788, <4 x i32> %787
  %791 = add nuw <4 x i32> %790, <i32 32, i32 32, i32 32, i32 32>
  %792 = lshr <4 x i32> %791, <i32 6, i32 6, i32 6, i32 6>
  %793 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %782, <4 x i32> %792) #5
  %794 = lshr <8 x i16> %793, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %795 = getelementptr inbounds i16, i16* %10, i64 200
  %796 = bitcast i16* %795 to <8 x i16>*
  %797 = load <8 x i16>, <8 x i16>* %796, align 16
  %798 = getelementptr inbounds i16, i16* %11, i64 200
  %799 = bitcast i16* %798 to <8 x i16>*
  %800 = load <8 x i16>, <8 x i16>* %799, align 16
  %801 = shufflevector <8 x i16> %797, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %802 = zext <4 x i16> %801 to <4 x i32>
  %803 = shufflevector <8 x i16> %800, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %804 = zext <4 x i16> %803 to <4 x i32>
  %805 = sub nsw <4 x i32> %802, %804
  %806 = sub nsw <4 x i32> zeroinitializer, %805
  %807 = icmp slt <4 x i32> %805, zeroinitializer
  %808 = select <4 x i1> %807, <4 x i32> %806, <4 x i32> %805
  %809 = add nuw nsw <4 x i32> %808, <i32 32, i32 32, i32 32, i32 32>
  %810 = lshr <4 x i32> %809, <i32 6, i32 6, i32 6, i32 6>
  %811 = shufflevector <8 x i16> %797, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %812 = shufflevector <8 x i16> %800, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %813 = bitcast <8 x i16> %811 to <4 x i32>
  %814 = bitcast <8 x i16> %812 to <4 x i32>
  %815 = sub <4 x i32> %813, %814
  %816 = sub <4 x i32> zeroinitializer, %815
  %817 = icmp slt <4 x i32> %815, zeroinitializer
  %818 = select <4 x i1> %817, <4 x i32> %816, <4 x i32> %815
  %819 = add nuw <4 x i32> %818, <i32 32, i32 32, i32 32, i32 32>
  %820 = lshr <4 x i32> %819, <i32 6, i32 6, i32 6, i32 6>
  %821 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %810, <4 x i32> %820) #5
  %822 = lshr <8 x i16> %821, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %823 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %794, <8 x i16> %822) #5
  %824 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %823, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %825 = icmp slt <16 x i8> %824, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %826 = select <16 x i1> %825, <16 x i8> %824, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %827 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %826
  %828 = bitcast i8* %768 to <16 x i8>*
  store <16 x i8> %827, <16 x i8>* %828, align 16
  %829 = getelementptr inbounds i16, i16* %10, i64 208
  %830 = getelementptr inbounds i16, i16* %11, i64 208
  %831 = getelementptr inbounds i8, i8* %768, i64 16
  %832 = bitcast i16* %829 to <8 x i16>*
  %833 = load <8 x i16>, <8 x i16>* %832, align 16
  %834 = bitcast i16* %830 to <8 x i16>*
  %835 = load <8 x i16>, <8 x i16>* %834, align 16
  %836 = shufflevector <8 x i16> %833, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %837 = zext <4 x i16> %836 to <4 x i32>
  %838 = shufflevector <8 x i16> %835, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %839 = zext <4 x i16> %838 to <4 x i32>
  %840 = sub nsw <4 x i32> %837, %839
  %841 = sub nsw <4 x i32> zeroinitializer, %840
  %842 = icmp slt <4 x i32> %840, zeroinitializer
  %843 = select <4 x i1> %842, <4 x i32> %841, <4 x i32> %840
  %844 = add nuw nsw <4 x i32> %843, <i32 32, i32 32, i32 32, i32 32>
  %845 = lshr <4 x i32> %844, <i32 6, i32 6, i32 6, i32 6>
  %846 = shufflevector <8 x i16> %833, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %847 = shufflevector <8 x i16> %835, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %848 = bitcast <8 x i16> %846 to <4 x i32>
  %849 = bitcast <8 x i16> %847 to <4 x i32>
  %850 = sub <4 x i32> %848, %849
  %851 = sub <4 x i32> zeroinitializer, %850
  %852 = icmp slt <4 x i32> %850, zeroinitializer
  %853 = select <4 x i1> %852, <4 x i32> %851, <4 x i32> %850
  %854 = add nuw <4 x i32> %853, <i32 32, i32 32, i32 32, i32 32>
  %855 = lshr <4 x i32> %854, <i32 6, i32 6, i32 6, i32 6>
  %856 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %845, <4 x i32> %855) #5
  %857 = lshr <8 x i16> %856, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %858 = getelementptr inbounds i16, i16* %10, i64 216
  %859 = bitcast i16* %858 to <8 x i16>*
  %860 = load <8 x i16>, <8 x i16>* %859, align 16
  %861 = getelementptr inbounds i16, i16* %11, i64 216
  %862 = bitcast i16* %861 to <8 x i16>*
  %863 = load <8 x i16>, <8 x i16>* %862, align 16
  %864 = shufflevector <8 x i16> %860, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %865 = zext <4 x i16> %864 to <4 x i32>
  %866 = shufflevector <8 x i16> %863, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %867 = zext <4 x i16> %866 to <4 x i32>
  %868 = sub nsw <4 x i32> %865, %867
  %869 = sub nsw <4 x i32> zeroinitializer, %868
  %870 = icmp slt <4 x i32> %868, zeroinitializer
  %871 = select <4 x i1> %870, <4 x i32> %869, <4 x i32> %868
  %872 = add nuw nsw <4 x i32> %871, <i32 32, i32 32, i32 32, i32 32>
  %873 = lshr <4 x i32> %872, <i32 6, i32 6, i32 6, i32 6>
  %874 = shufflevector <8 x i16> %860, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %875 = shufflevector <8 x i16> %863, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %876 = bitcast <8 x i16> %874 to <4 x i32>
  %877 = bitcast <8 x i16> %875 to <4 x i32>
  %878 = sub <4 x i32> %876, %877
  %879 = sub <4 x i32> zeroinitializer, %878
  %880 = icmp slt <4 x i32> %878, zeroinitializer
  %881 = select <4 x i1> %880, <4 x i32> %879, <4 x i32> %878
  %882 = add nuw <4 x i32> %881, <i32 32, i32 32, i32 32, i32 32>
  %883 = lshr <4 x i32> %882, <i32 6, i32 6, i32 6, i32 6>
  %884 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %873, <4 x i32> %883) #5
  %885 = lshr <8 x i16> %884, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %886 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %857, <8 x i16> %885) #5
  %887 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %886, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %888 = icmp slt <16 x i8> %887, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %889 = select <16 x i1> %888, <16 x i8> %887, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %890 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %889
  %891 = bitcast i8* %831 to <16 x i8>*
  store <16 x i8> %890, <16 x i8>* %891, align 16
  %892 = getelementptr inbounds i16, i16* %10, i64 224
  %893 = getelementptr inbounds i16, i16* %11, i64 224
  %894 = getelementptr inbounds i8, i8* %768, i64 32
  %895 = bitcast i16* %892 to <8 x i16>*
  %896 = load <8 x i16>, <8 x i16>* %895, align 16
  %897 = bitcast i16* %893 to <8 x i16>*
  %898 = load <8 x i16>, <8 x i16>* %897, align 16
  %899 = shufflevector <8 x i16> %896, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %900 = zext <4 x i16> %899 to <4 x i32>
  %901 = shufflevector <8 x i16> %898, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %902 = zext <4 x i16> %901 to <4 x i32>
  %903 = sub nsw <4 x i32> %900, %902
  %904 = sub nsw <4 x i32> zeroinitializer, %903
  %905 = icmp slt <4 x i32> %903, zeroinitializer
  %906 = select <4 x i1> %905, <4 x i32> %904, <4 x i32> %903
  %907 = add nuw nsw <4 x i32> %906, <i32 32, i32 32, i32 32, i32 32>
  %908 = lshr <4 x i32> %907, <i32 6, i32 6, i32 6, i32 6>
  %909 = shufflevector <8 x i16> %896, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %910 = shufflevector <8 x i16> %898, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %911 = bitcast <8 x i16> %909 to <4 x i32>
  %912 = bitcast <8 x i16> %910 to <4 x i32>
  %913 = sub <4 x i32> %911, %912
  %914 = sub <4 x i32> zeroinitializer, %913
  %915 = icmp slt <4 x i32> %913, zeroinitializer
  %916 = select <4 x i1> %915, <4 x i32> %914, <4 x i32> %913
  %917 = add nuw <4 x i32> %916, <i32 32, i32 32, i32 32, i32 32>
  %918 = lshr <4 x i32> %917, <i32 6, i32 6, i32 6, i32 6>
  %919 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %908, <4 x i32> %918) #5
  %920 = lshr <8 x i16> %919, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %921 = getelementptr inbounds i16, i16* %10, i64 232
  %922 = bitcast i16* %921 to <8 x i16>*
  %923 = load <8 x i16>, <8 x i16>* %922, align 16
  %924 = getelementptr inbounds i16, i16* %11, i64 232
  %925 = bitcast i16* %924 to <8 x i16>*
  %926 = load <8 x i16>, <8 x i16>* %925, align 16
  %927 = shufflevector <8 x i16> %923, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %928 = zext <4 x i16> %927 to <4 x i32>
  %929 = shufflevector <8 x i16> %926, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %930 = zext <4 x i16> %929 to <4 x i32>
  %931 = sub nsw <4 x i32> %928, %930
  %932 = sub nsw <4 x i32> zeroinitializer, %931
  %933 = icmp slt <4 x i32> %931, zeroinitializer
  %934 = select <4 x i1> %933, <4 x i32> %932, <4 x i32> %931
  %935 = add nuw nsw <4 x i32> %934, <i32 32, i32 32, i32 32, i32 32>
  %936 = lshr <4 x i32> %935, <i32 6, i32 6, i32 6, i32 6>
  %937 = shufflevector <8 x i16> %923, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %938 = shufflevector <8 x i16> %926, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %939 = bitcast <8 x i16> %937 to <4 x i32>
  %940 = bitcast <8 x i16> %938 to <4 x i32>
  %941 = sub <4 x i32> %939, %940
  %942 = sub <4 x i32> zeroinitializer, %941
  %943 = icmp slt <4 x i32> %941, zeroinitializer
  %944 = select <4 x i1> %943, <4 x i32> %942, <4 x i32> %941
  %945 = add nuw <4 x i32> %944, <i32 32, i32 32, i32 32, i32 32>
  %946 = lshr <4 x i32> %945, <i32 6, i32 6, i32 6, i32 6>
  %947 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %936, <4 x i32> %946) #5
  %948 = lshr <8 x i16> %947, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %949 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %920, <8 x i16> %948) #5
  %950 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %949, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %951 = icmp slt <16 x i8> %950, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %952 = select <16 x i1> %951, <16 x i8> %950, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %953 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %952
  %954 = bitcast i8* %894 to <16 x i8>*
  store <16 x i8> %953, <16 x i8>* %954, align 16
  %955 = getelementptr inbounds i16, i16* %10, i64 240
  %956 = getelementptr inbounds i16, i16* %11, i64 240
  %957 = getelementptr inbounds i8, i8* %768, i64 48
  %958 = bitcast i16* %955 to <8 x i16>*
  %959 = load <8 x i16>, <8 x i16>* %958, align 16
  %960 = bitcast i16* %956 to <8 x i16>*
  %961 = load <8 x i16>, <8 x i16>* %960, align 16
  %962 = shufflevector <8 x i16> %959, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %963 = zext <4 x i16> %962 to <4 x i32>
  %964 = shufflevector <8 x i16> %961, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %965 = zext <4 x i16> %964 to <4 x i32>
  %966 = sub nsw <4 x i32> %963, %965
  %967 = sub nsw <4 x i32> zeroinitializer, %966
  %968 = icmp slt <4 x i32> %966, zeroinitializer
  %969 = select <4 x i1> %968, <4 x i32> %967, <4 x i32> %966
  %970 = add nuw nsw <4 x i32> %969, <i32 32, i32 32, i32 32, i32 32>
  %971 = lshr <4 x i32> %970, <i32 6, i32 6, i32 6, i32 6>
  %972 = shufflevector <8 x i16> %959, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %973 = shufflevector <8 x i16> %961, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %974 = bitcast <8 x i16> %972 to <4 x i32>
  %975 = bitcast <8 x i16> %973 to <4 x i32>
  %976 = sub <4 x i32> %974, %975
  %977 = sub <4 x i32> zeroinitializer, %976
  %978 = icmp slt <4 x i32> %976, zeroinitializer
  %979 = select <4 x i1> %978, <4 x i32> %977, <4 x i32> %976
  %980 = add nuw <4 x i32> %979, <i32 32, i32 32, i32 32, i32 32>
  %981 = lshr <4 x i32> %980, <i32 6, i32 6, i32 6, i32 6>
  %982 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %971, <4 x i32> %981) #5
  %983 = lshr <8 x i16> %982, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %984 = getelementptr inbounds i16, i16* %10, i64 248
  %985 = bitcast i16* %984 to <8 x i16>*
  %986 = load <8 x i16>, <8 x i16>* %985, align 16
  %987 = getelementptr inbounds i16, i16* %11, i64 248
  %988 = bitcast i16* %987 to <8 x i16>*
  %989 = load <8 x i16>, <8 x i16>* %988, align 16
  %990 = shufflevector <8 x i16> %986, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %991 = zext <4 x i16> %990 to <4 x i32>
  %992 = shufflevector <8 x i16> %989, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %993 = zext <4 x i16> %992 to <4 x i32>
  %994 = sub nsw <4 x i32> %991, %993
  %995 = sub nsw <4 x i32> zeroinitializer, %994
  %996 = icmp slt <4 x i32> %994, zeroinitializer
  %997 = select <4 x i1> %996, <4 x i32> %995, <4 x i32> %994
  %998 = add nuw nsw <4 x i32> %997, <i32 32, i32 32, i32 32, i32 32>
  %999 = lshr <4 x i32> %998, <i32 6, i32 6, i32 6, i32 6>
  %1000 = shufflevector <8 x i16> %986, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1001 = shufflevector <8 x i16> %989, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1002 = bitcast <8 x i16> %1000 to <4 x i32>
  %1003 = bitcast <8 x i16> %1001 to <4 x i32>
  %1004 = sub <4 x i32> %1002, %1003
  %1005 = sub <4 x i32> zeroinitializer, %1004
  %1006 = icmp slt <4 x i32> %1004, zeroinitializer
  %1007 = select <4 x i1> %1006, <4 x i32> %1005, <4 x i32> %1004
  %1008 = add nuw <4 x i32> %1007, <i32 32, i32 32, i32 32, i32 32>
  %1009 = lshr <4 x i32> %1008, <i32 6, i32 6, i32 6, i32 6>
  %1010 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %999, <4 x i32> %1009) #5
  %1011 = lshr <8 x i16> %1010, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1012 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %983, <8 x i16> %1011) #5
  %1013 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1012, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1014 = icmp slt <16 x i8> %1013, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1015 = select <16 x i1> %1014, <16 x i8> %1013, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1016 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1015
  %1017 = bitcast i8* %957 to <16 x i8>*
  store <16 x i8> %1016, <16 x i8>* %1017, align 16
  %1018 = getelementptr inbounds i16, i16* %10, i64 256
  %1019 = getelementptr inbounds i16, i16* %11, i64 256
  %1020 = getelementptr inbounds i8, i8* %768, i64 %7
  %1021 = bitcast i16* %1018 to <8 x i16>*
  %1022 = load <8 x i16>, <8 x i16>* %1021, align 16
  %1023 = bitcast i16* %1019 to <8 x i16>*
  %1024 = load <8 x i16>, <8 x i16>* %1023, align 16
  %1025 = shufflevector <8 x i16> %1022, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1026 = zext <4 x i16> %1025 to <4 x i32>
  %1027 = shufflevector <8 x i16> %1024, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1028 = zext <4 x i16> %1027 to <4 x i32>
  %1029 = sub nsw <4 x i32> %1026, %1028
  %1030 = sub nsw <4 x i32> zeroinitializer, %1029
  %1031 = icmp slt <4 x i32> %1029, zeroinitializer
  %1032 = select <4 x i1> %1031, <4 x i32> %1030, <4 x i32> %1029
  %1033 = add nuw nsw <4 x i32> %1032, <i32 32, i32 32, i32 32, i32 32>
  %1034 = lshr <4 x i32> %1033, <i32 6, i32 6, i32 6, i32 6>
  %1035 = shufflevector <8 x i16> %1022, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1036 = shufflevector <8 x i16> %1024, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1037 = bitcast <8 x i16> %1035 to <4 x i32>
  %1038 = bitcast <8 x i16> %1036 to <4 x i32>
  %1039 = sub <4 x i32> %1037, %1038
  %1040 = sub <4 x i32> zeroinitializer, %1039
  %1041 = icmp slt <4 x i32> %1039, zeroinitializer
  %1042 = select <4 x i1> %1041, <4 x i32> %1040, <4 x i32> %1039
  %1043 = add nuw <4 x i32> %1042, <i32 32, i32 32, i32 32, i32 32>
  %1044 = lshr <4 x i32> %1043, <i32 6, i32 6, i32 6, i32 6>
  %1045 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1034, <4 x i32> %1044) #5
  %1046 = lshr <8 x i16> %1045, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1047 = getelementptr inbounds i16, i16* %10, i64 264
  %1048 = bitcast i16* %1047 to <8 x i16>*
  %1049 = load <8 x i16>, <8 x i16>* %1048, align 16
  %1050 = getelementptr inbounds i16, i16* %11, i64 264
  %1051 = bitcast i16* %1050 to <8 x i16>*
  %1052 = load <8 x i16>, <8 x i16>* %1051, align 16
  %1053 = shufflevector <8 x i16> %1049, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1054 = zext <4 x i16> %1053 to <4 x i32>
  %1055 = shufflevector <8 x i16> %1052, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1056 = zext <4 x i16> %1055 to <4 x i32>
  %1057 = sub nsw <4 x i32> %1054, %1056
  %1058 = sub nsw <4 x i32> zeroinitializer, %1057
  %1059 = icmp slt <4 x i32> %1057, zeroinitializer
  %1060 = select <4 x i1> %1059, <4 x i32> %1058, <4 x i32> %1057
  %1061 = add nuw nsw <4 x i32> %1060, <i32 32, i32 32, i32 32, i32 32>
  %1062 = lshr <4 x i32> %1061, <i32 6, i32 6, i32 6, i32 6>
  %1063 = shufflevector <8 x i16> %1049, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1064 = shufflevector <8 x i16> %1052, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1065 = bitcast <8 x i16> %1063 to <4 x i32>
  %1066 = bitcast <8 x i16> %1064 to <4 x i32>
  %1067 = sub <4 x i32> %1065, %1066
  %1068 = sub <4 x i32> zeroinitializer, %1067
  %1069 = icmp slt <4 x i32> %1067, zeroinitializer
  %1070 = select <4 x i1> %1069, <4 x i32> %1068, <4 x i32> %1067
  %1071 = add nuw <4 x i32> %1070, <i32 32, i32 32, i32 32, i32 32>
  %1072 = lshr <4 x i32> %1071, <i32 6, i32 6, i32 6, i32 6>
  %1073 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1062, <4 x i32> %1072) #5
  %1074 = lshr <8 x i16> %1073, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1075 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1046, <8 x i16> %1074) #5
  %1076 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1075, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1077 = icmp slt <16 x i8> %1076, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1078 = select <16 x i1> %1077, <16 x i8> %1076, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1079 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1078
  %1080 = bitcast i8* %1020 to <16 x i8>*
  store <16 x i8> %1079, <16 x i8>* %1080, align 16
  %1081 = getelementptr inbounds i16, i16* %10, i64 272
  %1082 = getelementptr inbounds i16, i16* %11, i64 272
  %1083 = getelementptr inbounds i8, i8* %1020, i64 16
  %1084 = bitcast i16* %1081 to <8 x i16>*
  %1085 = load <8 x i16>, <8 x i16>* %1084, align 16
  %1086 = bitcast i16* %1082 to <8 x i16>*
  %1087 = load <8 x i16>, <8 x i16>* %1086, align 16
  %1088 = shufflevector <8 x i16> %1085, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1089 = zext <4 x i16> %1088 to <4 x i32>
  %1090 = shufflevector <8 x i16> %1087, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1091 = zext <4 x i16> %1090 to <4 x i32>
  %1092 = sub nsw <4 x i32> %1089, %1091
  %1093 = sub nsw <4 x i32> zeroinitializer, %1092
  %1094 = icmp slt <4 x i32> %1092, zeroinitializer
  %1095 = select <4 x i1> %1094, <4 x i32> %1093, <4 x i32> %1092
  %1096 = add nuw nsw <4 x i32> %1095, <i32 32, i32 32, i32 32, i32 32>
  %1097 = lshr <4 x i32> %1096, <i32 6, i32 6, i32 6, i32 6>
  %1098 = shufflevector <8 x i16> %1085, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1099 = shufflevector <8 x i16> %1087, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1100 = bitcast <8 x i16> %1098 to <4 x i32>
  %1101 = bitcast <8 x i16> %1099 to <4 x i32>
  %1102 = sub <4 x i32> %1100, %1101
  %1103 = sub <4 x i32> zeroinitializer, %1102
  %1104 = icmp slt <4 x i32> %1102, zeroinitializer
  %1105 = select <4 x i1> %1104, <4 x i32> %1103, <4 x i32> %1102
  %1106 = add nuw <4 x i32> %1105, <i32 32, i32 32, i32 32, i32 32>
  %1107 = lshr <4 x i32> %1106, <i32 6, i32 6, i32 6, i32 6>
  %1108 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1097, <4 x i32> %1107) #5
  %1109 = lshr <8 x i16> %1108, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1110 = getelementptr inbounds i16, i16* %10, i64 280
  %1111 = bitcast i16* %1110 to <8 x i16>*
  %1112 = load <8 x i16>, <8 x i16>* %1111, align 16
  %1113 = getelementptr inbounds i16, i16* %11, i64 280
  %1114 = bitcast i16* %1113 to <8 x i16>*
  %1115 = load <8 x i16>, <8 x i16>* %1114, align 16
  %1116 = shufflevector <8 x i16> %1112, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1117 = zext <4 x i16> %1116 to <4 x i32>
  %1118 = shufflevector <8 x i16> %1115, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1119 = zext <4 x i16> %1118 to <4 x i32>
  %1120 = sub nsw <4 x i32> %1117, %1119
  %1121 = sub nsw <4 x i32> zeroinitializer, %1120
  %1122 = icmp slt <4 x i32> %1120, zeroinitializer
  %1123 = select <4 x i1> %1122, <4 x i32> %1121, <4 x i32> %1120
  %1124 = add nuw nsw <4 x i32> %1123, <i32 32, i32 32, i32 32, i32 32>
  %1125 = lshr <4 x i32> %1124, <i32 6, i32 6, i32 6, i32 6>
  %1126 = shufflevector <8 x i16> %1112, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1127 = shufflevector <8 x i16> %1115, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1128 = bitcast <8 x i16> %1126 to <4 x i32>
  %1129 = bitcast <8 x i16> %1127 to <4 x i32>
  %1130 = sub <4 x i32> %1128, %1129
  %1131 = sub <4 x i32> zeroinitializer, %1130
  %1132 = icmp slt <4 x i32> %1130, zeroinitializer
  %1133 = select <4 x i1> %1132, <4 x i32> %1131, <4 x i32> %1130
  %1134 = add nuw <4 x i32> %1133, <i32 32, i32 32, i32 32, i32 32>
  %1135 = lshr <4 x i32> %1134, <i32 6, i32 6, i32 6, i32 6>
  %1136 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1125, <4 x i32> %1135) #5
  %1137 = lshr <8 x i16> %1136, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1138 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1109, <8 x i16> %1137) #5
  %1139 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1138, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1140 = icmp slt <16 x i8> %1139, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1141 = select <16 x i1> %1140, <16 x i8> %1139, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1142 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1141
  %1143 = bitcast i8* %1083 to <16 x i8>*
  store <16 x i8> %1142, <16 x i8>* %1143, align 16
  %1144 = getelementptr inbounds i16, i16* %10, i64 288
  %1145 = getelementptr inbounds i16, i16* %11, i64 288
  %1146 = getelementptr inbounds i8, i8* %1020, i64 32
  %1147 = bitcast i16* %1144 to <8 x i16>*
  %1148 = load <8 x i16>, <8 x i16>* %1147, align 16
  %1149 = bitcast i16* %1145 to <8 x i16>*
  %1150 = load <8 x i16>, <8 x i16>* %1149, align 16
  %1151 = shufflevector <8 x i16> %1148, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1152 = zext <4 x i16> %1151 to <4 x i32>
  %1153 = shufflevector <8 x i16> %1150, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1154 = zext <4 x i16> %1153 to <4 x i32>
  %1155 = sub nsw <4 x i32> %1152, %1154
  %1156 = sub nsw <4 x i32> zeroinitializer, %1155
  %1157 = icmp slt <4 x i32> %1155, zeroinitializer
  %1158 = select <4 x i1> %1157, <4 x i32> %1156, <4 x i32> %1155
  %1159 = add nuw nsw <4 x i32> %1158, <i32 32, i32 32, i32 32, i32 32>
  %1160 = lshr <4 x i32> %1159, <i32 6, i32 6, i32 6, i32 6>
  %1161 = shufflevector <8 x i16> %1148, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1162 = shufflevector <8 x i16> %1150, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1163 = bitcast <8 x i16> %1161 to <4 x i32>
  %1164 = bitcast <8 x i16> %1162 to <4 x i32>
  %1165 = sub <4 x i32> %1163, %1164
  %1166 = sub <4 x i32> zeroinitializer, %1165
  %1167 = icmp slt <4 x i32> %1165, zeroinitializer
  %1168 = select <4 x i1> %1167, <4 x i32> %1166, <4 x i32> %1165
  %1169 = add nuw <4 x i32> %1168, <i32 32, i32 32, i32 32, i32 32>
  %1170 = lshr <4 x i32> %1169, <i32 6, i32 6, i32 6, i32 6>
  %1171 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1160, <4 x i32> %1170) #5
  %1172 = lshr <8 x i16> %1171, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1173 = getelementptr inbounds i16, i16* %10, i64 296
  %1174 = bitcast i16* %1173 to <8 x i16>*
  %1175 = load <8 x i16>, <8 x i16>* %1174, align 16
  %1176 = getelementptr inbounds i16, i16* %11, i64 296
  %1177 = bitcast i16* %1176 to <8 x i16>*
  %1178 = load <8 x i16>, <8 x i16>* %1177, align 16
  %1179 = shufflevector <8 x i16> %1175, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1180 = zext <4 x i16> %1179 to <4 x i32>
  %1181 = shufflevector <8 x i16> %1178, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1182 = zext <4 x i16> %1181 to <4 x i32>
  %1183 = sub nsw <4 x i32> %1180, %1182
  %1184 = sub nsw <4 x i32> zeroinitializer, %1183
  %1185 = icmp slt <4 x i32> %1183, zeroinitializer
  %1186 = select <4 x i1> %1185, <4 x i32> %1184, <4 x i32> %1183
  %1187 = add nuw nsw <4 x i32> %1186, <i32 32, i32 32, i32 32, i32 32>
  %1188 = lshr <4 x i32> %1187, <i32 6, i32 6, i32 6, i32 6>
  %1189 = shufflevector <8 x i16> %1175, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1190 = shufflevector <8 x i16> %1178, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1191 = bitcast <8 x i16> %1189 to <4 x i32>
  %1192 = bitcast <8 x i16> %1190 to <4 x i32>
  %1193 = sub <4 x i32> %1191, %1192
  %1194 = sub <4 x i32> zeroinitializer, %1193
  %1195 = icmp slt <4 x i32> %1193, zeroinitializer
  %1196 = select <4 x i1> %1195, <4 x i32> %1194, <4 x i32> %1193
  %1197 = add nuw <4 x i32> %1196, <i32 32, i32 32, i32 32, i32 32>
  %1198 = lshr <4 x i32> %1197, <i32 6, i32 6, i32 6, i32 6>
  %1199 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1188, <4 x i32> %1198) #5
  %1200 = lshr <8 x i16> %1199, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1201 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1172, <8 x i16> %1200) #5
  %1202 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1201, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1203 = icmp slt <16 x i8> %1202, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1204 = select <16 x i1> %1203, <16 x i8> %1202, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1205 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1204
  %1206 = bitcast i8* %1146 to <16 x i8>*
  store <16 x i8> %1205, <16 x i8>* %1206, align 16
  %1207 = getelementptr inbounds i16, i16* %10, i64 304
  %1208 = getelementptr inbounds i16, i16* %11, i64 304
  %1209 = getelementptr inbounds i8, i8* %1020, i64 48
  %1210 = bitcast i16* %1207 to <8 x i16>*
  %1211 = load <8 x i16>, <8 x i16>* %1210, align 16
  %1212 = bitcast i16* %1208 to <8 x i16>*
  %1213 = load <8 x i16>, <8 x i16>* %1212, align 16
  %1214 = shufflevector <8 x i16> %1211, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1215 = zext <4 x i16> %1214 to <4 x i32>
  %1216 = shufflevector <8 x i16> %1213, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1217 = zext <4 x i16> %1216 to <4 x i32>
  %1218 = sub nsw <4 x i32> %1215, %1217
  %1219 = sub nsw <4 x i32> zeroinitializer, %1218
  %1220 = icmp slt <4 x i32> %1218, zeroinitializer
  %1221 = select <4 x i1> %1220, <4 x i32> %1219, <4 x i32> %1218
  %1222 = add nuw nsw <4 x i32> %1221, <i32 32, i32 32, i32 32, i32 32>
  %1223 = lshr <4 x i32> %1222, <i32 6, i32 6, i32 6, i32 6>
  %1224 = shufflevector <8 x i16> %1211, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1225 = shufflevector <8 x i16> %1213, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1226 = bitcast <8 x i16> %1224 to <4 x i32>
  %1227 = bitcast <8 x i16> %1225 to <4 x i32>
  %1228 = sub <4 x i32> %1226, %1227
  %1229 = sub <4 x i32> zeroinitializer, %1228
  %1230 = icmp slt <4 x i32> %1228, zeroinitializer
  %1231 = select <4 x i1> %1230, <4 x i32> %1229, <4 x i32> %1228
  %1232 = add nuw <4 x i32> %1231, <i32 32, i32 32, i32 32, i32 32>
  %1233 = lshr <4 x i32> %1232, <i32 6, i32 6, i32 6, i32 6>
  %1234 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1223, <4 x i32> %1233) #5
  %1235 = lshr <8 x i16> %1234, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1236 = getelementptr inbounds i16, i16* %10, i64 312
  %1237 = bitcast i16* %1236 to <8 x i16>*
  %1238 = load <8 x i16>, <8 x i16>* %1237, align 16
  %1239 = getelementptr inbounds i16, i16* %11, i64 312
  %1240 = bitcast i16* %1239 to <8 x i16>*
  %1241 = load <8 x i16>, <8 x i16>* %1240, align 16
  %1242 = shufflevector <8 x i16> %1238, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1243 = zext <4 x i16> %1242 to <4 x i32>
  %1244 = shufflevector <8 x i16> %1241, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1245 = zext <4 x i16> %1244 to <4 x i32>
  %1246 = sub nsw <4 x i32> %1243, %1245
  %1247 = sub nsw <4 x i32> zeroinitializer, %1246
  %1248 = icmp slt <4 x i32> %1246, zeroinitializer
  %1249 = select <4 x i1> %1248, <4 x i32> %1247, <4 x i32> %1246
  %1250 = add nuw nsw <4 x i32> %1249, <i32 32, i32 32, i32 32, i32 32>
  %1251 = lshr <4 x i32> %1250, <i32 6, i32 6, i32 6, i32 6>
  %1252 = shufflevector <8 x i16> %1238, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1253 = shufflevector <8 x i16> %1241, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1254 = bitcast <8 x i16> %1252 to <4 x i32>
  %1255 = bitcast <8 x i16> %1253 to <4 x i32>
  %1256 = sub <4 x i32> %1254, %1255
  %1257 = sub <4 x i32> zeroinitializer, %1256
  %1258 = icmp slt <4 x i32> %1256, zeroinitializer
  %1259 = select <4 x i1> %1258, <4 x i32> %1257, <4 x i32> %1256
  %1260 = add nuw <4 x i32> %1259, <i32 32, i32 32, i32 32, i32 32>
  %1261 = lshr <4 x i32> %1260, <i32 6, i32 6, i32 6, i32 6>
  %1262 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1251, <4 x i32> %1261) #5
  %1263 = lshr <8 x i16> %1262, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1264 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1235, <8 x i16> %1263) #5
  %1265 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1264, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1266 = icmp slt <16 x i8> %1265, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1267 = select <16 x i1> %1266, <16 x i8> %1265, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1268 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1267
  %1269 = bitcast i8* %1209 to <16 x i8>*
  store <16 x i8> %1268, <16 x i8>* %1269, align 16
  %1270 = getelementptr inbounds i16, i16* %10, i64 320
  %1271 = getelementptr inbounds i16, i16* %11, i64 320
  %1272 = getelementptr inbounds i8, i8* %1020, i64 64
  %1273 = bitcast i16* %1270 to <8 x i16>*
  %1274 = load <8 x i16>, <8 x i16>* %1273, align 16
  %1275 = bitcast i16* %1271 to <8 x i16>*
  %1276 = load <8 x i16>, <8 x i16>* %1275, align 16
  %1277 = shufflevector <8 x i16> %1274, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1278 = zext <4 x i16> %1277 to <4 x i32>
  %1279 = shufflevector <8 x i16> %1276, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1280 = zext <4 x i16> %1279 to <4 x i32>
  %1281 = sub nsw <4 x i32> %1278, %1280
  %1282 = sub nsw <4 x i32> zeroinitializer, %1281
  %1283 = icmp slt <4 x i32> %1281, zeroinitializer
  %1284 = select <4 x i1> %1283, <4 x i32> %1282, <4 x i32> %1281
  %1285 = add nuw nsw <4 x i32> %1284, <i32 32, i32 32, i32 32, i32 32>
  %1286 = lshr <4 x i32> %1285, <i32 6, i32 6, i32 6, i32 6>
  %1287 = shufflevector <8 x i16> %1274, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1288 = shufflevector <8 x i16> %1276, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1289 = bitcast <8 x i16> %1287 to <4 x i32>
  %1290 = bitcast <8 x i16> %1288 to <4 x i32>
  %1291 = sub <4 x i32> %1289, %1290
  %1292 = sub <4 x i32> zeroinitializer, %1291
  %1293 = icmp slt <4 x i32> %1291, zeroinitializer
  %1294 = select <4 x i1> %1293, <4 x i32> %1292, <4 x i32> %1291
  %1295 = add nuw <4 x i32> %1294, <i32 32, i32 32, i32 32, i32 32>
  %1296 = lshr <4 x i32> %1295, <i32 6, i32 6, i32 6, i32 6>
  %1297 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1286, <4 x i32> %1296) #5
  %1298 = lshr <8 x i16> %1297, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1299 = getelementptr inbounds i16, i16* %10, i64 328
  %1300 = bitcast i16* %1299 to <8 x i16>*
  %1301 = load <8 x i16>, <8 x i16>* %1300, align 16
  %1302 = getelementptr inbounds i16, i16* %11, i64 328
  %1303 = bitcast i16* %1302 to <8 x i16>*
  %1304 = load <8 x i16>, <8 x i16>* %1303, align 16
  %1305 = shufflevector <8 x i16> %1301, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1306 = zext <4 x i16> %1305 to <4 x i32>
  %1307 = shufflevector <8 x i16> %1304, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1308 = zext <4 x i16> %1307 to <4 x i32>
  %1309 = sub nsw <4 x i32> %1306, %1308
  %1310 = sub nsw <4 x i32> zeroinitializer, %1309
  %1311 = icmp slt <4 x i32> %1309, zeroinitializer
  %1312 = select <4 x i1> %1311, <4 x i32> %1310, <4 x i32> %1309
  %1313 = add nuw nsw <4 x i32> %1312, <i32 32, i32 32, i32 32, i32 32>
  %1314 = lshr <4 x i32> %1313, <i32 6, i32 6, i32 6, i32 6>
  %1315 = shufflevector <8 x i16> %1301, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1316 = shufflevector <8 x i16> %1304, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1317 = bitcast <8 x i16> %1315 to <4 x i32>
  %1318 = bitcast <8 x i16> %1316 to <4 x i32>
  %1319 = sub <4 x i32> %1317, %1318
  %1320 = sub <4 x i32> zeroinitializer, %1319
  %1321 = icmp slt <4 x i32> %1319, zeroinitializer
  %1322 = select <4 x i1> %1321, <4 x i32> %1320, <4 x i32> %1319
  %1323 = add nuw <4 x i32> %1322, <i32 32, i32 32, i32 32, i32 32>
  %1324 = lshr <4 x i32> %1323, <i32 6, i32 6, i32 6, i32 6>
  %1325 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1314, <4 x i32> %1324) #5
  %1326 = lshr <8 x i16> %1325, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1327 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1298, <8 x i16> %1326) #5
  %1328 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1327, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1329 = icmp slt <16 x i8> %1328, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1330 = select <16 x i1> %1329, <16 x i8> %1328, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1331 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1330
  %1332 = bitcast i8* %1272 to <16 x i8>*
  store <16 x i8> %1331, <16 x i8>* %1332, align 16
  %1333 = getelementptr inbounds i16, i16* %10, i64 336
  %1334 = getelementptr inbounds i16, i16* %11, i64 336
  %1335 = getelementptr inbounds i8, i8* %1272, i64 16
  %1336 = bitcast i16* %1333 to <8 x i16>*
  %1337 = load <8 x i16>, <8 x i16>* %1336, align 16
  %1338 = bitcast i16* %1334 to <8 x i16>*
  %1339 = load <8 x i16>, <8 x i16>* %1338, align 16
  %1340 = shufflevector <8 x i16> %1337, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1341 = zext <4 x i16> %1340 to <4 x i32>
  %1342 = shufflevector <8 x i16> %1339, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1343 = zext <4 x i16> %1342 to <4 x i32>
  %1344 = sub nsw <4 x i32> %1341, %1343
  %1345 = sub nsw <4 x i32> zeroinitializer, %1344
  %1346 = icmp slt <4 x i32> %1344, zeroinitializer
  %1347 = select <4 x i1> %1346, <4 x i32> %1345, <4 x i32> %1344
  %1348 = add nuw nsw <4 x i32> %1347, <i32 32, i32 32, i32 32, i32 32>
  %1349 = lshr <4 x i32> %1348, <i32 6, i32 6, i32 6, i32 6>
  %1350 = shufflevector <8 x i16> %1337, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1351 = shufflevector <8 x i16> %1339, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1352 = bitcast <8 x i16> %1350 to <4 x i32>
  %1353 = bitcast <8 x i16> %1351 to <4 x i32>
  %1354 = sub <4 x i32> %1352, %1353
  %1355 = sub <4 x i32> zeroinitializer, %1354
  %1356 = icmp slt <4 x i32> %1354, zeroinitializer
  %1357 = select <4 x i1> %1356, <4 x i32> %1355, <4 x i32> %1354
  %1358 = add nuw <4 x i32> %1357, <i32 32, i32 32, i32 32, i32 32>
  %1359 = lshr <4 x i32> %1358, <i32 6, i32 6, i32 6, i32 6>
  %1360 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1349, <4 x i32> %1359) #5
  %1361 = lshr <8 x i16> %1360, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1362 = getelementptr inbounds i16, i16* %10, i64 344
  %1363 = bitcast i16* %1362 to <8 x i16>*
  %1364 = load <8 x i16>, <8 x i16>* %1363, align 16
  %1365 = getelementptr inbounds i16, i16* %11, i64 344
  %1366 = bitcast i16* %1365 to <8 x i16>*
  %1367 = load <8 x i16>, <8 x i16>* %1366, align 16
  %1368 = shufflevector <8 x i16> %1364, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1369 = zext <4 x i16> %1368 to <4 x i32>
  %1370 = shufflevector <8 x i16> %1367, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1371 = zext <4 x i16> %1370 to <4 x i32>
  %1372 = sub nsw <4 x i32> %1369, %1371
  %1373 = sub nsw <4 x i32> zeroinitializer, %1372
  %1374 = icmp slt <4 x i32> %1372, zeroinitializer
  %1375 = select <4 x i1> %1374, <4 x i32> %1373, <4 x i32> %1372
  %1376 = add nuw nsw <4 x i32> %1375, <i32 32, i32 32, i32 32, i32 32>
  %1377 = lshr <4 x i32> %1376, <i32 6, i32 6, i32 6, i32 6>
  %1378 = shufflevector <8 x i16> %1364, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1379 = shufflevector <8 x i16> %1367, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1380 = bitcast <8 x i16> %1378 to <4 x i32>
  %1381 = bitcast <8 x i16> %1379 to <4 x i32>
  %1382 = sub <4 x i32> %1380, %1381
  %1383 = sub <4 x i32> zeroinitializer, %1382
  %1384 = icmp slt <4 x i32> %1382, zeroinitializer
  %1385 = select <4 x i1> %1384, <4 x i32> %1383, <4 x i32> %1382
  %1386 = add nuw <4 x i32> %1385, <i32 32, i32 32, i32 32, i32 32>
  %1387 = lshr <4 x i32> %1386, <i32 6, i32 6, i32 6, i32 6>
  %1388 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1377, <4 x i32> %1387) #5
  %1389 = lshr <8 x i16> %1388, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1390 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1361, <8 x i16> %1389) #5
  %1391 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1390, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1392 = icmp slt <16 x i8> %1391, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1393 = select <16 x i1> %1392, <16 x i8> %1391, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1394 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1393
  %1395 = bitcast i8* %1335 to <16 x i8>*
  store <16 x i8> %1394, <16 x i8>* %1395, align 16
  %1396 = getelementptr inbounds i16, i16* %10, i64 352
  %1397 = getelementptr inbounds i16, i16* %11, i64 352
  %1398 = getelementptr inbounds i8, i8* %1272, i64 32
  %1399 = bitcast i16* %1396 to <8 x i16>*
  %1400 = load <8 x i16>, <8 x i16>* %1399, align 16
  %1401 = bitcast i16* %1397 to <8 x i16>*
  %1402 = load <8 x i16>, <8 x i16>* %1401, align 16
  %1403 = shufflevector <8 x i16> %1400, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1404 = zext <4 x i16> %1403 to <4 x i32>
  %1405 = shufflevector <8 x i16> %1402, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1406 = zext <4 x i16> %1405 to <4 x i32>
  %1407 = sub nsw <4 x i32> %1404, %1406
  %1408 = sub nsw <4 x i32> zeroinitializer, %1407
  %1409 = icmp slt <4 x i32> %1407, zeroinitializer
  %1410 = select <4 x i1> %1409, <4 x i32> %1408, <4 x i32> %1407
  %1411 = add nuw nsw <4 x i32> %1410, <i32 32, i32 32, i32 32, i32 32>
  %1412 = lshr <4 x i32> %1411, <i32 6, i32 6, i32 6, i32 6>
  %1413 = shufflevector <8 x i16> %1400, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1414 = shufflevector <8 x i16> %1402, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1415 = bitcast <8 x i16> %1413 to <4 x i32>
  %1416 = bitcast <8 x i16> %1414 to <4 x i32>
  %1417 = sub <4 x i32> %1415, %1416
  %1418 = sub <4 x i32> zeroinitializer, %1417
  %1419 = icmp slt <4 x i32> %1417, zeroinitializer
  %1420 = select <4 x i1> %1419, <4 x i32> %1418, <4 x i32> %1417
  %1421 = add nuw <4 x i32> %1420, <i32 32, i32 32, i32 32, i32 32>
  %1422 = lshr <4 x i32> %1421, <i32 6, i32 6, i32 6, i32 6>
  %1423 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1412, <4 x i32> %1422) #5
  %1424 = lshr <8 x i16> %1423, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1425 = getelementptr inbounds i16, i16* %10, i64 360
  %1426 = bitcast i16* %1425 to <8 x i16>*
  %1427 = load <8 x i16>, <8 x i16>* %1426, align 16
  %1428 = getelementptr inbounds i16, i16* %11, i64 360
  %1429 = bitcast i16* %1428 to <8 x i16>*
  %1430 = load <8 x i16>, <8 x i16>* %1429, align 16
  %1431 = shufflevector <8 x i16> %1427, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1432 = zext <4 x i16> %1431 to <4 x i32>
  %1433 = shufflevector <8 x i16> %1430, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1434 = zext <4 x i16> %1433 to <4 x i32>
  %1435 = sub nsw <4 x i32> %1432, %1434
  %1436 = sub nsw <4 x i32> zeroinitializer, %1435
  %1437 = icmp slt <4 x i32> %1435, zeroinitializer
  %1438 = select <4 x i1> %1437, <4 x i32> %1436, <4 x i32> %1435
  %1439 = add nuw nsw <4 x i32> %1438, <i32 32, i32 32, i32 32, i32 32>
  %1440 = lshr <4 x i32> %1439, <i32 6, i32 6, i32 6, i32 6>
  %1441 = shufflevector <8 x i16> %1427, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1442 = shufflevector <8 x i16> %1430, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1443 = bitcast <8 x i16> %1441 to <4 x i32>
  %1444 = bitcast <8 x i16> %1442 to <4 x i32>
  %1445 = sub <4 x i32> %1443, %1444
  %1446 = sub <4 x i32> zeroinitializer, %1445
  %1447 = icmp slt <4 x i32> %1445, zeroinitializer
  %1448 = select <4 x i1> %1447, <4 x i32> %1446, <4 x i32> %1445
  %1449 = add nuw <4 x i32> %1448, <i32 32, i32 32, i32 32, i32 32>
  %1450 = lshr <4 x i32> %1449, <i32 6, i32 6, i32 6, i32 6>
  %1451 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1440, <4 x i32> %1450) #5
  %1452 = lshr <8 x i16> %1451, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1453 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1424, <8 x i16> %1452) #5
  %1454 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1453, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1455 = icmp slt <16 x i8> %1454, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1456 = select <16 x i1> %1455, <16 x i8> %1454, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1457 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1456
  %1458 = bitcast i8* %1398 to <16 x i8>*
  store <16 x i8> %1457, <16 x i8>* %1458, align 16
  %1459 = getelementptr inbounds i16, i16* %10, i64 368
  %1460 = getelementptr inbounds i16, i16* %11, i64 368
  %1461 = getelementptr inbounds i8, i8* %1272, i64 48
  %1462 = bitcast i16* %1459 to <8 x i16>*
  %1463 = load <8 x i16>, <8 x i16>* %1462, align 16
  %1464 = bitcast i16* %1460 to <8 x i16>*
  %1465 = load <8 x i16>, <8 x i16>* %1464, align 16
  %1466 = shufflevector <8 x i16> %1463, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1467 = zext <4 x i16> %1466 to <4 x i32>
  %1468 = shufflevector <8 x i16> %1465, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1469 = zext <4 x i16> %1468 to <4 x i32>
  %1470 = sub nsw <4 x i32> %1467, %1469
  %1471 = sub nsw <4 x i32> zeroinitializer, %1470
  %1472 = icmp slt <4 x i32> %1470, zeroinitializer
  %1473 = select <4 x i1> %1472, <4 x i32> %1471, <4 x i32> %1470
  %1474 = add nuw nsw <4 x i32> %1473, <i32 32, i32 32, i32 32, i32 32>
  %1475 = lshr <4 x i32> %1474, <i32 6, i32 6, i32 6, i32 6>
  %1476 = shufflevector <8 x i16> %1463, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1477 = shufflevector <8 x i16> %1465, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1478 = bitcast <8 x i16> %1476 to <4 x i32>
  %1479 = bitcast <8 x i16> %1477 to <4 x i32>
  %1480 = sub <4 x i32> %1478, %1479
  %1481 = sub <4 x i32> zeroinitializer, %1480
  %1482 = icmp slt <4 x i32> %1480, zeroinitializer
  %1483 = select <4 x i1> %1482, <4 x i32> %1481, <4 x i32> %1480
  %1484 = add nuw <4 x i32> %1483, <i32 32, i32 32, i32 32, i32 32>
  %1485 = lshr <4 x i32> %1484, <i32 6, i32 6, i32 6, i32 6>
  %1486 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1475, <4 x i32> %1485) #5
  %1487 = lshr <8 x i16> %1486, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1488 = getelementptr inbounds i16, i16* %10, i64 376
  %1489 = bitcast i16* %1488 to <8 x i16>*
  %1490 = load <8 x i16>, <8 x i16>* %1489, align 16
  %1491 = getelementptr inbounds i16, i16* %11, i64 376
  %1492 = bitcast i16* %1491 to <8 x i16>*
  %1493 = load <8 x i16>, <8 x i16>* %1492, align 16
  %1494 = shufflevector <8 x i16> %1490, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1495 = zext <4 x i16> %1494 to <4 x i32>
  %1496 = shufflevector <8 x i16> %1493, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1497 = zext <4 x i16> %1496 to <4 x i32>
  %1498 = sub nsw <4 x i32> %1495, %1497
  %1499 = sub nsw <4 x i32> zeroinitializer, %1498
  %1500 = icmp slt <4 x i32> %1498, zeroinitializer
  %1501 = select <4 x i1> %1500, <4 x i32> %1499, <4 x i32> %1498
  %1502 = add nuw nsw <4 x i32> %1501, <i32 32, i32 32, i32 32, i32 32>
  %1503 = lshr <4 x i32> %1502, <i32 6, i32 6, i32 6, i32 6>
  %1504 = shufflevector <8 x i16> %1490, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1505 = shufflevector <8 x i16> %1493, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1506 = bitcast <8 x i16> %1504 to <4 x i32>
  %1507 = bitcast <8 x i16> %1505 to <4 x i32>
  %1508 = sub <4 x i32> %1506, %1507
  %1509 = sub <4 x i32> zeroinitializer, %1508
  %1510 = icmp slt <4 x i32> %1508, zeroinitializer
  %1511 = select <4 x i1> %1510, <4 x i32> %1509, <4 x i32> %1508
  %1512 = add nuw <4 x i32> %1511, <i32 32, i32 32, i32 32, i32 32>
  %1513 = lshr <4 x i32> %1512, <i32 6, i32 6, i32 6, i32 6>
  %1514 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1503, <4 x i32> %1513) #5
  %1515 = lshr <8 x i16> %1514, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1516 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1487, <8 x i16> %1515) #5
  %1517 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1516, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1518 = icmp slt <16 x i8> %1517, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1519 = select <16 x i1> %1518, <16 x i8> %1517, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1520 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1519
  %1521 = bitcast i8* %1461 to <16 x i8>*
  store <16 x i8> %1520, <16 x i8>* %1521, align 16
  %1522 = getelementptr inbounds i16, i16* %10, i64 384
  %1523 = getelementptr inbounds i16, i16* %11, i64 384
  %1524 = getelementptr inbounds i8, i8* %1272, i64 %7
  %1525 = add nsw i32 %12, -1
  %1526 = icmp eq i32 %1525, 0
  br i1 %1526, label %1527, label %8

1527:                                             ; preds = %8
  %1528 = bitcast i16* %1522 to <8 x i16>*
  %1529 = load <8 x i16>, <8 x i16>* %1528, align 16
  %1530 = bitcast i16* %1523 to <8 x i16>*
  %1531 = load <8 x i16>, <8 x i16>* %1530, align 16
  %1532 = shufflevector <8 x i16> %1529, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1533 = zext <4 x i16> %1532 to <4 x i32>
  %1534 = shufflevector <8 x i16> %1531, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1535 = zext <4 x i16> %1534 to <4 x i32>
  %1536 = sub nsw <4 x i32> %1533, %1535
  %1537 = sub nsw <4 x i32> zeroinitializer, %1536
  %1538 = icmp slt <4 x i32> %1536, zeroinitializer
  %1539 = select <4 x i1> %1538, <4 x i32> %1537, <4 x i32> %1536
  %1540 = add nuw nsw <4 x i32> %1539, <i32 32, i32 32, i32 32, i32 32>
  %1541 = lshr <4 x i32> %1540, <i32 6, i32 6, i32 6, i32 6>
  %1542 = shufflevector <8 x i16> %1529, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1543 = shufflevector <8 x i16> %1531, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1544 = bitcast <8 x i16> %1542 to <4 x i32>
  %1545 = bitcast <8 x i16> %1543 to <4 x i32>
  %1546 = sub <4 x i32> %1544, %1545
  %1547 = sub <4 x i32> zeroinitializer, %1546
  %1548 = icmp slt <4 x i32> %1546, zeroinitializer
  %1549 = select <4 x i1> %1548, <4 x i32> %1547, <4 x i32> %1546
  %1550 = add nuw <4 x i32> %1549, <i32 32, i32 32, i32 32, i32 32>
  %1551 = lshr <4 x i32> %1550, <i32 6, i32 6, i32 6, i32 6>
  %1552 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1541, <4 x i32> %1551) #5
  %1553 = lshr <8 x i16> %1552, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1554 = getelementptr inbounds i16, i16* %10, i64 392
  %1555 = bitcast i16* %1554 to <8 x i16>*
  %1556 = load <8 x i16>, <8 x i16>* %1555, align 16
  %1557 = getelementptr inbounds i16, i16* %11, i64 392
  %1558 = bitcast i16* %1557 to <8 x i16>*
  %1559 = load <8 x i16>, <8 x i16>* %1558, align 16
  %1560 = shufflevector <8 x i16> %1556, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1561 = zext <4 x i16> %1560 to <4 x i32>
  %1562 = shufflevector <8 x i16> %1559, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1563 = zext <4 x i16> %1562 to <4 x i32>
  %1564 = sub nsw <4 x i32> %1561, %1563
  %1565 = sub nsw <4 x i32> zeroinitializer, %1564
  %1566 = icmp slt <4 x i32> %1564, zeroinitializer
  %1567 = select <4 x i1> %1566, <4 x i32> %1565, <4 x i32> %1564
  %1568 = add nuw nsw <4 x i32> %1567, <i32 32, i32 32, i32 32, i32 32>
  %1569 = lshr <4 x i32> %1568, <i32 6, i32 6, i32 6, i32 6>
  %1570 = shufflevector <8 x i16> %1556, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1571 = shufflevector <8 x i16> %1559, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1572 = bitcast <8 x i16> %1570 to <4 x i32>
  %1573 = bitcast <8 x i16> %1571 to <4 x i32>
  %1574 = sub <4 x i32> %1572, %1573
  %1575 = sub <4 x i32> zeroinitializer, %1574
  %1576 = icmp slt <4 x i32> %1574, zeroinitializer
  %1577 = select <4 x i1> %1576, <4 x i32> %1575, <4 x i32> %1574
  %1578 = add nuw <4 x i32> %1577, <i32 32, i32 32, i32 32, i32 32>
  %1579 = lshr <4 x i32> %1578, <i32 6, i32 6, i32 6, i32 6>
  %1580 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1569, <4 x i32> %1579) #5
  %1581 = lshr <8 x i16> %1580, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1582 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1553, <8 x i16> %1581) #5
  %1583 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1582, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1584 = icmp slt <16 x i8> %1583, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1585 = select <16 x i1> %1584, <16 x i8> %1583, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1586 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1585
  %1587 = bitcast i8* %1524 to <16 x i8>*
  store <16 x i8> %1586, <16 x i8>* %1587, align 16
  %1588 = getelementptr inbounds i16, i16* %10, i64 400
  %1589 = getelementptr inbounds i16, i16* %11, i64 400
  %1590 = getelementptr inbounds i8, i8* %1524, i64 16
  %1591 = bitcast i16* %1588 to <8 x i16>*
  %1592 = load <8 x i16>, <8 x i16>* %1591, align 16
  %1593 = bitcast i16* %1589 to <8 x i16>*
  %1594 = load <8 x i16>, <8 x i16>* %1593, align 16
  %1595 = shufflevector <8 x i16> %1592, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1596 = zext <4 x i16> %1595 to <4 x i32>
  %1597 = shufflevector <8 x i16> %1594, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1598 = zext <4 x i16> %1597 to <4 x i32>
  %1599 = sub nsw <4 x i32> %1596, %1598
  %1600 = sub nsw <4 x i32> zeroinitializer, %1599
  %1601 = icmp slt <4 x i32> %1599, zeroinitializer
  %1602 = select <4 x i1> %1601, <4 x i32> %1600, <4 x i32> %1599
  %1603 = add nuw nsw <4 x i32> %1602, <i32 32, i32 32, i32 32, i32 32>
  %1604 = lshr <4 x i32> %1603, <i32 6, i32 6, i32 6, i32 6>
  %1605 = shufflevector <8 x i16> %1592, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1606 = shufflevector <8 x i16> %1594, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1607 = bitcast <8 x i16> %1605 to <4 x i32>
  %1608 = bitcast <8 x i16> %1606 to <4 x i32>
  %1609 = sub <4 x i32> %1607, %1608
  %1610 = sub <4 x i32> zeroinitializer, %1609
  %1611 = icmp slt <4 x i32> %1609, zeroinitializer
  %1612 = select <4 x i1> %1611, <4 x i32> %1610, <4 x i32> %1609
  %1613 = add nuw <4 x i32> %1612, <i32 32, i32 32, i32 32, i32 32>
  %1614 = lshr <4 x i32> %1613, <i32 6, i32 6, i32 6, i32 6>
  %1615 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1604, <4 x i32> %1614) #5
  %1616 = lshr <8 x i16> %1615, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1617 = getelementptr inbounds i16, i16* %10, i64 408
  %1618 = bitcast i16* %1617 to <8 x i16>*
  %1619 = load <8 x i16>, <8 x i16>* %1618, align 16
  %1620 = getelementptr inbounds i16, i16* %11, i64 408
  %1621 = bitcast i16* %1620 to <8 x i16>*
  %1622 = load <8 x i16>, <8 x i16>* %1621, align 16
  %1623 = shufflevector <8 x i16> %1619, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1624 = zext <4 x i16> %1623 to <4 x i32>
  %1625 = shufflevector <8 x i16> %1622, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1626 = zext <4 x i16> %1625 to <4 x i32>
  %1627 = sub nsw <4 x i32> %1624, %1626
  %1628 = sub nsw <4 x i32> zeroinitializer, %1627
  %1629 = icmp slt <4 x i32> %1627, zeroinitializer
  %1630 = select <4 x i1> %1629, <4 x i32> %1628, <4 x i32> %1627
  %1631 = add nuw nsw <4 x i32> %1630, <i32 32, i32 32, i32 32, i32 32>
  %1632 = lshr <4 x i32> %1631, <i32 6, i32 6, i32 6, i32 6>
  %1633 = shufflevector <8 x i16> %1619, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1634 = shufflevector <8 x i16> %1622, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1635 = bitcast <8 x i16> %1633 to <4 x i32>
  %1636 = bitcast <8 x i16> %1634 to <4 x i32>
  %1637 = sub <4 x i32> %1635, %1636
  %1638 = sub <4 x i32> zeroinitializer, %1637
  %1639 = icmp slt <4 x i32> %1637, zeroinitializer
  %1640 = select <4 x i1> %1639, <4 x i32> %1638, <4 x i32> %1637
  %1641 = add nuw <4 x i32> %1640, <i32 32, i32 32, i32 32, i32 32>
  %1642 = lshr <4 x i32> %1641, <i32 6, i32 6, i32 6, i32 6>
  %1643 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1632, <4 x i32> %1642) #5
  %1644 = lshr <8 x i16> %1643, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1645 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1616, <8 x i16> %1644) #5
  %1646 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1645, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1647 = icmp slt <16 x i8> %1646, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1648 = select <16 x i1> %1647, <16 x i8> %1646, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1649 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1648
  %1650 = bitcast i8* %1590 to <16 x i8>*
  store <16 x i8> %1649, <16 x i8>* %1650, align 16
  %1651 = getelementptr inbounds i16, i16* %10, i64 416
  %1652 = getelementptr inbounds i16, i16* %11, i64 416
  %1653 = getelementptr inbounds i8, i8* %1524, i64 32
  %1654 = bitcast i16* %1651 to <8 x i16>*
  %1655 = load <8 x i16>, <8 x i16>* %1654, align 16
  %1656 = bitcast i16* %1652 to <8 x i16>*
  %1657 = load <8 x i16>, <8 x i16>* %1656, align 16
  %1658 = shufflevector <8 x i16> %1655, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1659 = zext <4 x i16> %1658 to <4 x i32>
  %1660 = shufflevector <8 x i16> %1657, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1661 = zext <4 x i16> %1660 to <4 x i32>
  %1662 = sub nsw <4 x i32> %1659, %1661
  %1663 = sub nsw <4 x i32> zeroinitializer, %1662
  %1664 = icmp slt <4 x i32> %1662, zeroinitializer
  %1665 = select <4 x i1> %1664, <4 x i32> %1663, <4 x i32> %1662
  %1666 = add nuw nsw <4 x i32> %1665, <i32 32, i32 32, i32 32, i32 32>
  %1667 = lshr <4 x i32> %1666, <i32 6, i32 6, i32 6, i32 6>
  %1668 = shufflevector <8 x i16> %1655, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1669 = shufflevector <8 x i16> %1657, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1670 = bitcast <8 x i16> %1668 to <4 x i32>
  %1671 = bitcast <8 x i16> %1669 to <4 x i32>
  %1672 = sub <4 x i32> %1670, %1671
  %1673 = sub <4 x i32> zeroinitializer, %1672
  %1674 = icmp slt <4 x i32> %1672, zeroinitializer
  %1675 = select <4 x i1> %1674, <4 x i32> %1673, <4 x i32> %1672
  %1676 = add nuw <4 x i32> %1675, <i32 32, i32 32, i32 32, i32 32>
  %1677 = lshr <4 x i32> %1676, <i32 6, i32 6, i32 6, i32 6>
  %1678 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1667, <4 x i32> %1677) #5
  %1679 = lshr <8 x i16> %1678, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1680 = getelementptr inbounds i16, i16* %10, i64 424
  %1681 = bitcast i16* %1680 to <8 x i16>*
  %1682 = load <8 x i16>, <8 x i16>* %1681, align 16
  %1683 = getelementptr inbounds i16, i16* %11, i64 424
  %1684 = bitcast i16* %1683 to <8 x i16>*
  %1685 = load <8 x i16>, <8 x i16>* %1684, align 16
  %1686 = shufflevector <8 x i16> %1682, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1687 = zext <4 x i16> %1686 to <4 x i32>
  %1688 = shufflevector <8 x i16> %1685, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1689 = zext <4 x i16> %1688 to <4 x i32>
  %1690 = sub nsw <4 x i32> %1687, %1689
  %1691 = sub nsw <4 x i32> zeroinitializer, %1690
  %1692 = icmp slt <4 x i32> %1690, zeroinitializer
  %1693 = select <4 x i1> %1692, <4 x i32> %1691, <4 x i32> %1690
  %1694 = add nuw nsw <4 x i32> %1693, <i32 32, i32 32, i32 32, i32 32>
  %1695 = lshr <4 x i32> %1694, <i32 6, i32 6, i32 6, i32 6>
  %1696 = shufflevector <8 x i16> %1682, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1697 = shufflevector <8 x i16> %1685, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1698 = bitcast <8 x i16> %1696 to <4 x i32>
  %1699 = bitcast <8 x i16> %1697 to <4 x i32>
  %1700 = sub <4 x i32> %1698, %1699
  %1701 = sub <4 x i32> zeroinitializer, %1700
  %1702 = icmp slt <4 x i32> %1700, zeroinitializer
  %1703 = select <4 x i1> %1702, <4 x i32> %1701, <4 x i32> %1700
  %1704 = add nuw <4 x i32> %1703, <i32 32, i32 32, i32 32, i32 32>
  %1705 = lshr <4 x i32> %1704, <i32 6, i32 6, i32 6, i32 6>
  %1706 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1695, <4 x i32> %1705) #5
  %1707 = lshr <8 x i16> %1706, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1708 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1679, <8 x i16> %1707) #5
  %1709 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1708, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1710 = icmp slt <16 x i8> %1709, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1711 = select <16 x i1> %1710, <16 x i8> %1709, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1712 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1711
  %1713 = bitcast i8* %1653 to <16 x i8>*
  store <16 x i8> %1712, <16 x i8>* %1713, align 16
  %1714 = getelementptr inbounds i16, i16* %10, i64 432
  %1715 = getelementptr inbounds i16, i16* %11, i64 432
  %1716 = getelementptr inbounds i8, i8* %1524, i64 48
  %1717 = bitcast i16* %1714 to <8 x i16>*
  %1718 = load <8 x i16>, <8 x i16>* %1717, align 16
  %1719 = bitcast i16* %1715 to <8 x i16>*
  %1720 = load <8 x i16>, <8 x i16>* %1719, align 16
  %1721 = shufflevector <8 x i16> %1718, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1722 = zext <4 x i16> %1721 to <4 x i32>
  %1723 = shufflevector <8 x i16> %1720, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1724 = zext <4 x i16> %1723 to <4 x i32>
  %1725 = sub nsw <4 x i32> %1722, %1724
  %1726 = sub nsw <4 x i32> zeroinitializer, %1725
  %1727 = icmp slt <4 x i32> %1725, zeroinitializer
  %1728 = select <4 x i1> %1727, <4 x i32> %1726, <4 x i32> %1725
  %1729 = add nuw nsw <4 x i32> %1728, <i32 32, i32 32, i32 32, i32 32>
  %1730 = lshr <4 x i32> %1729, <i32 6, i32 6, i32 6, i32 6>
  %1731 = shufflevector <8 x i16> %1718, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1732 = shufflevector <8 x i16> %1720, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1733 = bitcast <8 x i16> %1731 to <4 x i32>
  %1734 = bitcast <8 x i16> %1732 to <4 x i32>
  %1735 = sub <4 x i32> %1733, %1734
  %1736 = sub <4 x i32> zeroinitializer, %1735
  %1737 = icmp slt <4 x i32> %1735, zeroinitializer
  %1738 = select <4 x i1> %1737, <4 x i32> %1736, <4 x i32> %1735
  %1739 = add nuw <4 x i32> %1738, <i32 32, i32 32, i32 32, i32 32>
  %1740 = lshr <4 x i32> %1739, <i32 6, i32 6, i32 6, i32 6>
  %1741 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1730, <4 x i32> %1740) #5
  %1742 = lshr <8 x i16> %1741, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1743 = getelementptr inbounds i16, i16* %10, i64 440
  %1744 = bitcast i16* %1743 to <8 x i16>*
  %1745 = load <8 x i16>, <8 x i16>* %1744, align 16
  %1746 = getelementptr inbounds i16, i16* %11, i64 440
  %1747 = bitcast i16* %1746 to <8 x i16>*
  %1748 = load <8 x i16>, <8 x i16>* %1747, align 16
  %1749 = shufflevector <8 x i16> %1745, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1750 = zext <4 x i16> %1749 to <4 x i32>
  %1751 = shufflevector <8 x i16> %1748, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1752 = zext <4 x i16> %1751 to <4 x i32>
  %1753 = sub nsw <4 x i32> %1750, %1752
  %1754 = sub nsw <4 x i32> zeroinitializer, %1753
  %1755 = icmp slt <4 x i32> %1753, zeroinitializer
  %1756 = select <4 x i1> %1755, <4 x i32> %1754, <4 x i32> %1753
  %1757 = add nuw nsw <4 x i32> %1756, <i32 32, i32 32, i32 32, i32 32>
  %1758 = lshr <4 x i32> %1757, <i32 6, i32 6, i32 6, i32 6>
  %1759 = shufflevector <8 x i16> %1745, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1760 = shufflevector <8 x i16> %1748, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1761 = bitcast <8 x i16> %1759 to <4 x i32>
  %1762 = bitcast <8 x i16> %1760 to <4 x i32>
  %1763 = sub <4 x i32> %1761, %1762
  %1764 = sub <4 x i32> zeroinitializer, %1763
  %1765 = icmp slt <4 x i32> %1763, zeroinitializer
  %1766 = select <4 x i1> %1765, <4 x i32> %1764, <4 x i32> %1763
  %1767 = add nuw <4 x i32> %1766, <i32 32, i32 32, i32 32, i32 32>
  %1768 = lshr <4 x i32> %1767, <i32 6, i32 6, i32 6, i32 6>
  %1769 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1758, <4 x i32> %1768) #5
  %1770 = lshr <8 x i16> %1769, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1771 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1742, <8 x i16> %1770) #5
  %1772 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1771, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1773 = icmp slt <16 x i8> %1772, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1774 = select <16 x i1> %1773, <16 x i8> %1772, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1775 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1774
  %1776 = bitcast i8* %1716 to <16 x i8>*
  store <16 x i8> %1775, <16 x i8>* %1776, align 16
  %1777 = getelementptr inbounds i16, i16* %10, i64 448
  %1778 = getelementptr inbounds i16, i16* %11, i64 448
  %1779 = getelementptr inbounds i8, i8* %1524, i64 64
  %1780 = bitcast i16* %1777 to <8 x i16>*
  %1781 = load <8 x i16>, <8 x i16>* %1780, align 16
  %1782 = bitcast i16* %1778 to <8 x i16>*
  %1783 = load <8 x i16>, <8 x i16>* %1782, align 16
  %1784 = shufflevector <8 x i16> %1781, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1785 = zext <4 x i16> %1784 to <4 x i32>
  %1786 = shufflevector <8 x i16> %1783, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1787 = zext <4 x i16> %1786 to <4 x i32>
  %1788 = sub nsw <4 x i32> %1785, %1787
  %1789 = sub nsw <4 x i32> zeroinitializer, %1788
  %1790 = icmp slt <4 x i32> %1788, zeroinitializer
  %1791 = select <4 x i1> %1790, <4 x i32> %1789, <4 x i32> %1788
  %1792 = add nuw nsw <4 x i32> %1791, <i32 32, i32 32, i32 32, i32 32>
  %1793 = lshr <4 x i32> %1792, <i32 6, i32 6, i32 6, i32 6>
  %1794 = shufflevector <8 x i16> %1781, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1795 = shufflevector <8 x i16> %1783, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1796 = bitcast <8 x i16> %1794 to <4 x i32>
  %1797 = bitcast <8 x i16> %1795 to <4 x i32>
  %1798 = sub <4 x i32> %1796, %1797
  %1799 = sub <4 x i32> zeroinitializer, %1798
  %1800 = icmp slt <4 x i32> %1798, zeroinitializer
  %1801 = select <4 x i1> %1800, <4 x i32> %1799, <4 x i32> %1798
  %1802 = add nuw <4 x i32> %1801, <i32 32, i32 32, i32 32, i32 32>
  %1803 = lshr <4 x i32> %1802, <i32 6, i32 6, i32 6, i32 6>
  %1804 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1793, <4 x i32> %1803) #5
  %1805 = lshr <8 x i16> %1804, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1806 = getelementptr inbounds i16, i16* %10, i64 456
  %1807 = bitcast i16* %1806 to <8 x i16>*
  %1808 = load <8 x i16>, <8 x i16>* %1807, align 16
  %1809 = getelementptr inbounds i16, i16* %11, i64 456
  %1810 = bitcast i16* %1809 to <8 x i16>*
  %1811 = load <8 x i16>, <8 x i16>* %1810, align 16
  %1812 = shufflevector <8 x i16> %1808, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1813 = zext <4 x i16> %1812 to <4 x i32>
  %1814 = shufflevector <8 x i16> %1811, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1815 = zext <4 x i16> %1814 to <4 x i32>
  %1816 = sub nsw <4 x i32> %1813, %1815
  %1817 = sub nsw <4 x i32> zeroinitializer, %1816
  %1818 = icmp slt <4 x i32> %1816, zeroinitializer
  %1819 = select <4 x i1> %1818, <4 x i32> %1817, <4 x i32> %1816
  %1820 = add nuw nsw <4 x i32> %1819, <i32 32, i32 32, i32 32, i32 32>
  %1821 = lshr <4 x i32> %1820, <i32 6, i32 6, i32 6, i32 6>
  %1822 = shufflevector <8 x i16> %1808, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1823 = shufflevector <8 x i16> %1811, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1824 = bitcast <8 x i16> %1822 to <4 x i32>
  %1825 = bitcast <8 x i16> %1823 to <4 x i32>
  %1826 = sub <4 x i32> %1824, %1825
  %1827 = sub <4 x i32> zeroinitializer, %1826
  %1828 = icmp slt <4 x i32> %1826, zeroinitializer
  %1829 = select <4 x i1> %1828, <4 x i32> %1827, <4 x i32> %1826
  %1830 = add nuw <4 x i32> %1829, <i32 32, i32 32, i32 32, i32 32>
  %1831 = lshr <4 x i32> %1830, <i32 6, i32 6, i32 6, i32 6>
  %1832 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1821, <4 x i32> %1831) #5
  %1833 = lshr <8 x i16> %1832, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1834 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1805, <8 x i16> %1833) #5
  %1835 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1834, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1836 = icmp slt <16 x i8> %1835, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1837 = select <16 x i1> %1836, <16 x i8> %1835, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1838 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1837
  %1839 = bitcast i8* %1779 to <16 x i8>*
  store <16 x i8> %1838, <16 x i8>* %1839, align 16
  %1840 = getelementptr inbounds i16, i16* %10, i64 464
  %1841 = getelementptr inbounds i16, i16* %11, i64 464
  %1842 = getelementptr inbounds i8, i8* %1779, i64 16
  %1843 = bitcast i16* %1840 to <8 x i16>*
  %1844 = load <8 x i16>, <8 x i16>* %1843, align 16
  %1845 = bitcast i16* %1841 to <8 x i16>*
  %1846 = load <8 x i16>, <8 x i16>* %1845, align 16
  %1847 = shufflevector <8 x i16> %1844, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1848 = zext <4 x i16> %1847 to <4 x i32>
  %1849 = shufflevector <8 x i16> %1846, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1850 = zext <4 x i16> %1849 to <4 x i32>
  %1851 = sub nsw <4 x i32> %1848, %1850
  %1852 = sub nsw <4 x i32> zeroinitializer, %1851
  %1853 = icmp slt <4 x i32> %1851, zeroinitializer
  %1854 = select <4 x i1> %1853, <4 x i32> %1852, <4 x i32> %1851
  %1855 = add nuw nsw <4 x i32> %1854, <i32 32, i32 32, i32 32, i32 32>
  %1856 = lshr <4 x i32> %1855, <i32 6, i32 6, i32 6, i32 6>
  %1857 = shufflevector <8 x i16> %1844, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1858 = shufflevector <8 x i16> %1846, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1859 = bitcast <8 x i16> %1857 to <4 x i32>
  %1860 = bitcast <8 x i16> %1858 to <4 x i32>
  %1861 = sub <4 x i32> %1859, %1860
  %1862 = sub <4 x i32> zeroinitializer, %1861
  %1863 = icmp slt <4 x i32> %1861, zeroinitializer
  %1864 = select <4 x i1> %1863, <4 x i32> %1862, <4 x i32> %1861
  %1865 = add nuw <4 x i32> %1864, <i32 32, i32 32, i32 32, i32 32>
  %1866 = lshr <4 x i32> %1865, <i32 6, i32 6, i32 6, i32 6>
  %1867 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1856, <4 x i32> %1866) #5
  %1868 = lshr <8 x i16> %1867, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1869 = getelementptr inbounds i16, i16* %10, i64 472
  %1870 = bitcast i16* %1869 to <8 x i16>*
  %1871 = load <8 x i16>, <8 x i16>* %1870, align 16
  %1872 = getelementptr inbounds i16, i16* %11, i64 472
  %1873 = bitcast i16* %1872 to <8 x i16>*
  %1874 = load <8 x i16>, <8 x i16>* %1873, align 16
  %1875 = shufflevector <8 x i16> %1871, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1876 = zext <4 x i16> %1875 to <4 x i32>
  %1877 = shufflevector <8 x i16> %1874, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1878 = zext <4 x i16> %1877 to <4 x i32>
  %1879 = sub nsw <4 x i32> %1876, %1878
  %1880 = sub nsw <4 x i32> zeroinitializer, %1879
  %1881 = icmp slt <4 x i32> %1879, zeroinitializer
  %1882 = select <4 x i1> %1881, <4 x i32> %1880, <4 x i32> %1879
  %1883 = add nuw nsw <4 x i32> %1882, <i32 32, i32 32, i32 32, i32 32>
  %1884 = lshr <4 x i32> %1883, <i32 6, i32 6, i32 6, i32 6>
  %1885 = shufflevector <8 x i16> %1871, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1886 = shufflevector <8 x i16> %1874, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1887 = bitcast <8 x i16> %1885 to <4 x i32>
  %1888 = bitcast <8 x i16> %1886 to <4 x i32>
  %1889 = sub <4 x i32> %1887, %1888
  %1890 = sub <4 x i32> zeroinitializer, %1889
  %1891 = icmp slt <4 x i32> %1889, zeroinitializer
  %1892 = select <4 x i1> %1891, <4 x i32> %1890, <4 x i32> %1889
  %1893 = add nuw <4 x i32> %1892, <i32 32, i32 32, i32 32, i32 32>
  %1894 = lshr <4 x i32> %1893, <i32 6, i32 6, i32 6, i32 6>
  %1895 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1884, <4 x i32> %1894) #5
  %1896 = lshr <8 x i16> %1895, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1897 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1868, <8 x i16> %1896) #5
  %1898 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1897, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1899 = icmp slt <16 x i8> %1898, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1900 = select <16 x i1> %1899, <16 x i8> %1898, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1901 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1900
  %1902 = bitcast i8* %1842 to <16 x i8>*
  store <16 x i8> %1901, <16 x i8>* %1902, align 16
  %1903 = getelementptr inbounds i16, i16* %10, i64 480
  %1904 = getelementptr inbounds i16, i16* %11, i64 480
  %1905 = getelementptr inbounds i8, i8* %1779, i64 32
  %1906 = bitcast i16* %1903 to <8 x i16>*
  %1907 = load <8 x i16>, <8 x i16>* %1906, align 16
  %1908 = bitcast i16* %1904 to <8 x i16>*
  %1909 = load <8 x i16>, <8 x i16>* %1908, align 16
  %1910 = shufflevector <8 x i16> %1907, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1911 = zext <4 x i16> %1910 to <4 x i32>
  %1912 = shufflevector <8 x i16> %1909, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1913 = zext <4 x i16> %1912 to <4 x i32>
  %1914 = sub nsw <4 x i32> %1911, %1913
  %1915 = sub nsw <4 x i32> zeroinitializer, %1914
  %1916 = icmp slt <4 x i32> %1914, zeroinitializer
  %1917 = select <4 x i1> %1916, <4 x i32> %1915, <4 x i32> %1914
  %1918 = add nuw nsw <4 x i32> %1917, <i32 32, i32 32, i32 32, i32 32>
  %1919 = lshr <4 x i32> %1918, <i32 6, i32 6, i32 6, i32 6>
  %1920 = shufflevector <8 x i16> %1907, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1921 = shufflevector <8 x i16> %1909, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1922 = bitcast <8 x i16> %1920 to <4 x i32>
  %1923 = bitcast <8 x i16> %1921 to <4 x i32>
  %1924 = sub <4 x i32> %1922, %1923
  %1925 = sub <4 x i32> zeroinitializer, %1924
  %1926 = icmp slt <4 x i32> %1924, zeroinitializer
  %1927 = select <4 x i1> %1926, <4 x i32> %1925, <4 x i32> %1924
  %1928 = add nuw <4 x i32> %1927, <i32 32, i32 32, i32 32, i32 32>
  %1929 = lshr <4 x i32> %1928, <i32 6, i32 6, i32 6, i32 6>
  %1930 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1919, <4 x i32> %1929) #5
  %1931 = lshr <8 x i16> %1930, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1932 = getelementptr inbounds i16, i16* %10, i64 488
  %1933 = bitcast i16* %1932 to <8 x i16>*
  %1934 = load <8 x i16>, <8 x i16>* %1933, align 16
  %1935 = getelementptr inbounds i16, i16* %11, i64 488
  %1936 = bitcast i16* %1935 to <8 x i16>*
  %1937 = load <8 x i16>, <8 x i16>* %1936, align 16
  %1938 = shufflevector <8 x i16> %1934, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1939 = zext <4 x i16> %1938 to <4 x i32>
  %1940 = shufflevector <8 x i16> %1937, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1941 = zext <4 x i16> %1940 to <4 x i32>
  %1942 = sub nsw <4 x i32> %1939, %1941
  %1943 = sub nsw <4 x i32> zeroinitializer, %1942
  %1944 = icmp slt <4 x i32> %1942, zeroinitializer
  %1945 = select <4 x i1> %1944, <4 x i32> %1943, <4 x i32> %1942
  %1946 = add nuw nsw <4 x i32> %1945, <i32 32, i32 32, i32 32, i32 32>
  %1947 = lshr <4 x i32> %1946, <i32 6, i32 6, i32 6, i32 6>
  %1948 = shufflevector <8 x i16> %1934, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1949 = shufflevector <8 x i16> %1937, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1950 = bitcast <8 x i16> %1948 to <4 x i32>
  %1951 = bitcast <8 x i16> %1949 to <4 x i32>
  %1952 = sub <4 x i32> %1950, %1951
  %1953 = sub <4 x i32> zeroinitializer, %1952
  %1954 = icmp slt <4 x i32> %1952, zeroinitializer
  %1955 = select <4 x i1> %1954, <4 x i32> %1953, <4 x i32> %1952
  %1956 = add nuw <4 x i32> %1955, <i32 32, i32 32, i32 32, i32 32>
  %1957 = lshr <4 x i32> %1956, <i32 6, i32 6, i32 6, i32 6>
  %1958 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1947, <4 x i32> %1957) #5
  %1959 = lshr <8 x i16> %1958, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1960 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1931, <8 x i16> %1959) #5
  %1961 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1960, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1962 = icmp slt <16 x i8> %1961, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1963 = select <16 x i1> %1962, <16 x i8> %1961, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1964 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1963
  %1965 = bitcast i8* %1905 to <16 x i8>*
  store <16 x i8> %1964, <16 x i8>* %1965, align 16
  %1966 = getelementptr inbounds i16, i16* %10, i64 496
  %1967 = getelementptr inbounds i16, i16* %11, i64 496
  %1968 = getelementptr inbounds i8, i8* %1779, i64 48
  %1969 = bitcast i16* %1966 to <8 x i16>*
  %1970 = load <8 x i16>, <8 x i16>* %1969, align 16
  %1971 = bitcast i16* %1967 to <8 x i16>*
  %1972 = load <8 x i16>, <8 x i16>* %1971, align 16
  %1973 = shufflevector <8 x i16> %1970, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1974 = zext <4 x i16> %1973 to <4 x i32>
  %1975 = shufflevector <8 x i16> %1972, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1976 = zext <4 x i16> %1975 to <4 x i32>
  %1977 = sub nsw <4 x i32> %1974, %1976
  %1978 = sub nsw <4 x i32> zeroinitializer, %1977
  %1979 = icmp slt <4 x i32> %1977, zeroinitializer
  %1980 = select <4 x i1> %1979, <4 x i32> %1978, <4 x i32> %1977
  %1981 = add nuw nsw <4 x i32> %1980, <i32 32, i32 32, i32 32, i32 32>
  %1982 = lshr <4 x i32> %1981, <i32 6, i32 6, i32 6, i32 6>
  %1983 = shufflevector <8 x i16> %1970, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1984 = shufflevector <8 x i16> %1972, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1985 = bitcast <8 x i16> %1983 to <4 x i32>
  %1986 = bitcast <8 x i16> %1984 to <4 x i32>
  %1987 = sub <4 x i32> %1985, %1986
  %1988 = sub <4 x i32> zeroinitializer, %1987
  %1989 = icmp slt <4 x i32> %1987, zeroinitializer
  %1990 = select <4 x i1> %1989, <4 x i32> %1988, <4 x i32> %1987
  %1991 = add nuw <4 x i32> %1990, <i32 32, i32 32, i32 32, i32 32>
  %1992 = lshr <4 x i32> %1991, <i32 6, i32 6, i32 6, i32 6>
  %1993 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1982, <4 x i32> %1992) #5
  %1994 = lshr <8 x i16> %1993, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1995 = getelementptr inbounds i16, i16* %10, i64 504
  %1996 = bitcast i16* %1995 to <8 x i16>*
  %1997 = load <8 x i16>, <8 x i16>* %1996, align 16
  %1998 = getelementptr inbounds i16, i16* %11, i64 504
  %1999 = bitcast i16* %1998 to <8 x i16>*
  %2000 = load <8 x i16>, <8 x i16>* %1999, align 16
  %2001 = shufflevector <8 x i16> %1997, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2002 = zext <4 x i16> %2001 to <4 x i32>
  %2003 = shufflevector <8 x i16> %2000, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2004 = zext <4 x i16> %2003 to <4 x i32>
  %2005 = sub nsw <4 x i32> %2002, %2004
  %2006 = sub nsw <4 x i32> zeroinitializer, %2005
  %2007 = icmp slt <4 x i32> %2005, zeroinitializer
  %2008 = select <4 x i1> %2007, <4 x i32> %2006, <4 x i32> %2005
  %2009 = add nuw nsw <4 x i32> %2008, <i32 32, i32 32, i32 32, i32 32>
  %2010 = lshr <4 x i32> %2009, <i32 6, i32 6, i32 6, i32 6>
  %2011 = shufflevector <8 x i16> %1997, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2012 = shufflevector <8 x i16> %2000, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2013 = bitcast <8 x i16> %2011 to <4 x i32>
  %2014 = bitcast <8 x i16> %2012 to <4 x i32>
  %2015 = sub <4 x i32> %2013, %2014
  %2016 = sub <4 x i32> zeroinitializer, %2015
  %2017 = icmp slt <4 x i32> %2015, zeroinitializer
  %2018 = select <4 x i1> %2017, <4 x i32> %2016, <4 x i32> %2015
  %2019 = add nuw <4 x i32> %2018, <i32 32, i32 32, i32 32, i32 32>
  %2020 = lshr <4 x i32> %2019, <i32 6, i32 6, i32 6, i32 6>
  %2021 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2010, <4 x i32> %2020) #5
  %2022 = lshr <8 x i16> %2021, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2023 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1994, <8 x i16> %2022) #5
  %2024 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %2023, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %2025 = icmp slt <16 x i8> %2024, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2026 = select <16 x i1> %2025, <16 x i8> %2024, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2027 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %2026
  %2028 = bitcast i8* %1968 to <16 x i8>*
  store <16 x i8> %2027, <16 x i8>* %2028, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_128WeightMask128x128_10bpp_SSE4ILb0EEEvPKvS5_Phl(i8* readonly, i8* readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  %7 = add nsw i64 %3, -64
  br label %8

8:                                                ; preds = %8, %4
  %9 = phi i8* [ %2, %4 ], [ %1500, %8 ]
  %10 = phi i16* [ %5, %4 ], [ %1498, %8 ]
  %11 = phi i16* [ %6, %4 ], [ %1499, %8 ]
  %12 = phi i32 [ 42, %4 ], [ %1501, %8 ]
  %13 = bitcast i16* %10 to <8 x i16>*
  %14 = load <8 x i16>, <8 x i16>* %13, align 16
  %15 = bitcast i16* %11 to <8 x i16>*
  %16 = load <8 x i16>, <8 x i16>* %15, align 16
  %17 = shufflevector <8 x i16> %14, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %18 = zext <4 x i16> %17 to <4 x i32>
  %19 = shufflevector <8 x i16> %16, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %20 = zext <4 x i16> %19 to <4 x i32>
  %21 = sub nsw <4 x i32> %18, %20
  %22 = sub nsw <4 x i32> zeroinitializer, %21
  %23 = icmp slt <4 x i32> %21, zeroinitializer
  %24 = select <4 x i1> %23, <4 x i32> %22, <4 x i32> %21
  %25 = add nuw nsw <4 x i32> %24, <i32 32, i32 32, i32 32, i32 32>
  %26 = lshr <4 x i32> %25, <i32 6, i32 6, i32 6, i32 6>
  %27 = shufflevector <8 x i16> %14, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %28 = shufflevector <8 x i16> %16, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %29 = bitcast <8 x i16> %27 to <4 x i32>
  %30 = bitcast <8 x i16> %28 to <4 x i32>
  %31 = sub <4 x i32> %29, %30
  %32 = sub <4 x i32> zeroinitializer, %31
  %33 = icmp slt <4 x i32> %31, zeroinitializer
  %34 = select <4 x i1> %33, <4 x i32> %32, <4 x i32> %31
  %35 = add nuw <4 x i32> %34, <i32 32, i32 32, i32 32, i32 32>
  %36 = lshr <4 x i32> %35, <i32 6, i32 6, i32 6, i32 6>
  %37 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %26, <4 x i32> %36) #5
  %38 = lshr <8 x i16> %37, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %39 = getelementptr inbounds i16, i16* %10, i64 8
  %40 = bitcast i16* %39 to <8 x i16>*
  %41 = load <8 x i16>, <8 x i16>* %40, align 16
  %42 = getelementptr inbounds i16, i16* %11, i64 8
  %43 = bitcast i16* %42 to <8 x i16>*
  %44 = load <8 x i16>, <8 x i16>* %43, align 16
  %45 = shufflevector <8 x i16> %41, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %46 = zext <4 x i16> %45 to <4 x i32>
  %47 = shufflevector <8 x i16> %44, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %48 = zext <4 x i16> %47 to <4 x i32>
  %49 = sub nsw <4 x i32> %46, %48
  %50 = sub nsw <4 x i32> zeroinitializer, %49
  %51 = icmp slt <4 x i32> %49, zeroinitializer
  %52 = select <4 x i1> %51, <4 x i32> %50, <4 x i32> %49
  %53 = add nuw nsw <4 x i32> %52, <i32 32, i32 32, i32 32, i32 32>
  %54 = lshr <4 x i32> %53, <i32 6, i32 6, i32 6, i32 6>
  %55 = shufflevector <8 x i16> %41, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %56 = shufflevector <8 x i16> %44, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %57 = bitcast <8 x i16> %55 to <4 x i32>
  %58 = bitcast <8 x i16> %56 to <4 x i32>
  %59 = sub <4 x i32> %57, %58
  %60 = sub <4 x i32> zeroinitializer, %59
  %61 = icmp slt <4 x i32> %59, zeroinitializer
  %62 = select <4 x i1> %61, <4 x i32> %60, <4 x i32> %59
  %63 = add nuw <4 x i32> %62, <i32 32, i32 32, i32 32, i32 32>
  %64 = lshr <4 x i32> %63, <i32 6, i32 6, i32 6, i32 6>
  %65 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %54, <4 x i32> %64) #5
  %66 = lshr <8 x i16> %65, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %67 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %38, <8 x i16> %66) #5
  %68 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %67, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %69 = icmp slt <16 x i8> %68, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %70 = select <16 x i1> %69, <16 x i8> %68, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %71 = bitcast i8* %9 to <16 x i8>*
  store <16 x i8> %70, <16 x i8>* %71, align 16
  %72 = getelementptr inbounds i16, i16* %10, i64 16
  %73 = getelementptr inbounds i16, i16* %11, i64 16
  %74 = getelementptr inbounds i8, i8* %9, i64 16
  %75 = bitcast i16* %72 to <8 x i16>*
  %76 = load <8 x i16>, <8 x i16>* %75, align 16
  %77 = bitcast i16* %73 to <8 x i16>*
  %78 = load <8 x i16>, <8 x i16>* %77, align 16
  %79 = shufflevector <8 x i16> %76, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %80 = zext <4 x i16> %79 to <4 x i32>
  %81 = shufflevector <8 x i16> %78, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %82 = zext <4 x i16> %81 to <4 x i32>
  %83 = sub nsw <4 x i32> %80, %82
  %84 = sub nsw <4 x i32> zeroinitializer, %83
  %85 = icmp slt <4 x i32> %83, zeroinitializer
  %86 = select <4 x i1> %85, <4 x i32> %84, <4 x i32> %83
  %87 = add nuw nsw <4 x i32> %86, <i32 32, i32 32, i32 32, i32 32>
  %88 = lshr <4 x i32> %87, <i32 6, i32 6, i32 6, i32 6>
  %89 = shufflevector <8 x i16> %76, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %90 = shufflevector <8 x i16> %78, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %91 = bitcast <8 x i16> %89 to <4 x i32>
  %92 = bitcast <8 x i16> %90 to <4 x i32>
  %93 = sub <4 x i32> %91, %92
  %94 = sub <4 x i32> zeroinitializer, %93
  %95 = icmp slt <4 x i32> %93, zeroinitializer
  %96 = select <4 x i1> %95, <4 x i32> %94, <4 x i32> %93
  %97 = add nuw <4 x i32> %96, <i32 32, i32 32, i32 32, i32 32>
  %98 = lshr <4 x i32> %97, <i32 6, i32 6, i32 6, i32 6>
  %99 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %88, <4 x i32> %98) #5
  %100 = lshr <8 x i16> %99, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %101 = getelementptr inbounds i16, i16* %10, i64 24
  %102 = bitcast i16* %101 to <8 x i16>*
  %103 = load <8 x i16>, <8 x i16>* %102, align 16
  %104 = getelementptr inbounds i16, i16* %11, i64 24
  %105 = bitcast i16* %104 to <8 x i16>*
  %106 = load <8 x i16>, <8 x i16>* %105, align 16
  %107 = shufflevector <8 x i16> %103, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %108 = zext <4 x i16> %107 to <4 x i32>
  %109 = shufflevector <8 x i16> %106, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %110 = zext <4 x i16> %109 to <4 x i32>
  %111 = sub nsw <4 x i32> %108, %110
  %112 = sub nsw <4 x i32> zeroinitializer, %111
  %113 = icmp slt <4 x i32> %111, zeroinitializer
  %114 = select <4 x i1> %113, <4 x i32> %112, <4 x i32> %111
  %115 = add nuw nsw <4 x i32> %114, <i32 32, i32 32, i32 32, i32 32>
  %116 = lshr <4 x i32> %115, <i32 6, i32 6, i32 6, i32 6>
  %117 = shufflevector <8 x i16> %103, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %118 = shufflevector <8 x i16> %106, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %119 = bitcast <8 x i16> %117 to <4 x i32>
  %120 = bitcast <8 x i16> %118 to <4 x i32>
  %121 = sub <4 x i32> %119, %120
  %122 = sub <4 x i32> zeroinitializer, %121
  %123 = icmp slt <4 x i32> %121, zeroinitializer
  %124 = select <4 x i1> %123, <4 x i32> %122, <4 x i32> %121
  %125 = add nuw <4 x i32> %124, <i32 32, i32 32, i32 32, i32 32>
  %126 = lshr <4 x i32> %125, <i32 6, i32 6, i32 6, i32 6>
  %127 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %116, <4 x i32> %126) #5
  %128 = lshr <8 x i16> %127, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %129 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %100, <8 x i16> %128) #5
  %130 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %129, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %131 = icmp slt <16 x i8> %130, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %132 = select <16 x i1> %131, <16 x i8> %130, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %133 = bitcast i8* %74 to <16 x i8>*
  store <16 x i8> %132, <16 x i8>* %133, align 16
  %134 = getelementptr inbounds i16, i16* %10, i64 32
  %135 = getelementptr inbounds i16, i16* %11, i64 32
  %136 = getelementptr inbounds i8, i8* %9, i64 32
  %137 = bitcast i16* %134 to <8 x i16>*
  %138 = load <8 x i16>, <8 x i16>* %137, align 16
  %139 = bitcast i16* %135 to <8 x i16>*
  %140 = load <8 x i16>, <8 x i16>* %139, align 16
  %141 = shufflevector <8 x i16> %138, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %142 = zext <4 x i16> %141 to <4 x i32>
  %143 = shufflevector <8 x i16> %140, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %144 = zext <4 x i16> %143 to <4 x i32>
  %145 = sub nsw <4 x i32> %142, %144
  %146 = sub nsw <4 x i32> zeroinitializer, %145
  %147 = icmp slt <4 x i32> %145, zeroinitializer
  %148 = select <4 x i1> %147, <4 x i32> %146, <4 x i32> %145
  %149 = add nuw nsw <4 x i32> %148, <i32 32, i32 32, i32 32, i32 32>
  %150 = lshr <4 x i32> %149, <i32 6, i32 6, i32 6, i32 6>
  %151 = shufflevector <8 x i16> %138, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %152 = shufflevector <8 x i16> %140, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %153 = bitcast <8 x i16> %151 to <4 x i32>
  %154 = bitcast <8 x i16> %152 to <4 x i32>
  %155 = sub <4 x i32> %153, %154
  %156 = sub <4 x i32> zeroinitializer, %155
  %157 = icmp slt <4 x i32> %155, zeroinitializer
  %158 = select <4 x i1> %157, <4 x i32> %156, <4 x i32> %155
  %159 = add nuw <4 x i32> %158, <i32 32, i32 32, i32 32, i32 32>
  %160 = lshr <4 x i32> %159, <i32 6, i32 6, i32 6, i32 6>
  %161 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %150, <4 x i32> %160) #5
  %162 = lshr <8 x i16> %161, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %163 = getelementptr inbounds i16, i16* %10, i64 40
  %164 = bitcast i16* %163 to <8 x i16>*
  %165 = load <8 x i16>, <8 x i16>* %164, align 16
  %166 = getelementptr inbounds i16, i16* %11, i64 40
  %167 = bitcast i16* %166 to <8 x i16>*
  %168 = load <8 x i16>, <8 x i16>* %167, align 16
  %169 = shufflevector <8 x i16> %165, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %170 = zext <4 x i16> %169 to <4 x i32>
  %171 = shufflevector <8 x i16> %168, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %172 = zext <4 x i16> %171 to <4 x i32>
  %173 = sub nsw <4 x i32> %170, %172
  %174 = sub nsw <4 x i32> zeroinitializer, %173
  %175 = icmp slt <4 x i32> %173, zeroinitializer
  %176 = select <4 x i1> %175, <4 x i32> %174, <4 x i32> %173
  %177 = add nuw nsw <4 x i32> %176, <i32 32, i32 32, i32 32, i32 32>
  %178 = lshr <4 x i32> %177, <i32 6, i32 6, i32 6, i32 6>
  %179 = shufflevector <8 x i16> %165, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %180 = shufflevector <8 x i16> %168, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %181 = bitcast <8 x i16> %179 to <4 x i32>
  %182 = bitcast <8 x i16> %180 to <4 x i32>
  %183 = sub <4 x i32> %181, %182
  %184 = sub <4 x i32> zeroinitializer, %183
  %185 = icmp slt <4 x i32> %183, zeroinitializer
  %186 = select <4 x i1> %185, <4 x i32> %184, <4 x i32> %183
  %187 = add nuw <4 x i32> %186, <i32 32, i32 32, i32 32, i32 32>
  %188 = lshr <4 x i32> %187, <i32 6, i32 6, i32 6, i32 6>
  %189 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %178, <4 x i32> %188) #5
  %190 = lshr <8 x i16> %189, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %191 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %162, <8 x i16> %190) #5
  %192 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %191, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %193 = icmp slt <16 x i8> %192, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %194 = select <16 x i1> %193, <16 x i8> %192, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %195 = bitcast i8* %136 to <16 x i8>*
  store <16 x i8> %194, <16 x i8>* %195, align 16
  %196 = getelementptr inbounds i16, i16* %10, i64 48
  %197 = getelementptr inbounds i16, i16* %11, i64 48
  %198 = getelementptr inbounds i8, i8* %9, i64 48
  %199 = bitcast i16* %196 to <8 x i16>*
  %200 = load <8 x i16>, <8 x i16>* %199, align 16
  %201 = bitcast i16* %197 to <8 x i16>*
  %202 = load <8 x i16>, <8 x i16>* %201, align 16
  %203 = shufflevector <8 x i16> %200, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %204 = zext <4 x i16> %203 to <4 x i32>
  %205 = shufflevector <8 x i16> %202, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %206 = zext <4 x i16> %205 to <4 x i32>
  %207 = sub nsw <4 x i32> %204, %206
  %208 = sub nsw <4 x i32> zeroinitializer, %207
  %209 = icmp slt <4 x i32> %207, zeroinitializer
  %210 = select <4 x i1> %209, <4 x i32> %208, <4 x i32> %207
  %211 = add nuw nsw <4 x i32> %210, <i32 32, i32 32, i32 32, i32 32>
  %212 = lshr <4 x i32> %211, <i32 6, i32 6, i32 6, i32 6>
  %213 = shufflevector <8 x i16> %200, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %214 = shufflevector <8 x i16> %202, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %215 = bitcast <8 x i16> %213 to <4 x i32>
  %216 = bitcast <8 x i16> %214 to <4 x i32>
  %217 = sub <4 x i32> %215, %216
  %218 = sub <4 x i32> zeroinitializer, %217
  %219 = icmp slt <4 x i32> %217, zeroinitializer
  %220 = select <4 x i1> %219, <4 x i32> %218, <4 x i32> %217
  %221 = add nuw <4 x i32> %220, <i32 32, i32 32, i32 32, i32 32>
  %222 = lshr <4 x i32> %221, <i32 6, i32 6, i32 6, i32 6>
  %223 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %212, <4 x i32> %222) #5
  %224 = lshr <8 x i16> %223, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %225 = getelementptr inbounds i16, i16* %10, i64 56
  %226 = bitcast i16* %225 to <8 x i16>*
  %227 = load <8 x i16>, <8 x i16>* %226, align 16
  %228 = getelementptr inbounds i16, i16* %11, i64 56
  %229 = bitcast i16* %228 to <8 x i16>*
  %230 = load <8 x i16>, <8 x i16>* %229, align 16
  %231 = shufflevector <8 x i16> %227, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %232 = zext <4 x i16> %231 to <4 x i32>
  %233 = shufflevector <8 x i16> %230, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %234 = zext <4 x i16> %233 to <4 x i32>
  %235 = sub nsw <4 x i32> %232, %234
  %236 = sub nsw <4 x i32> zeroinitializer, %235
  %237 = icmp slt <4 x i32> %235, zeroinitializer
  %238 = select <4 x i1> %237, <4 x i32> %236, <4 x i32> %235
  %239 = add nuw nsw <4 x i32> %238, <i32 32, i32 32, i32 32, i32 32>
  %240 = lshr <4 x i32> %239, <i32 6, i32 6, i32 6, i32 6>
  %241 = shufflevector <8 x i16> %227, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %242 = shufflevector <8 x i16> %230, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %243 = bitcast <8 x i16> %241 to <4 x i32>
  %244 = bitcast <8 x i16> %242 to <4 x i32>
  %245 = sub <4 x i32> %243, %244
  %246 = sub <4 x i32> zeroinitializer, %245
  %247 = icmp slt <4 x i32> %245, zeroinitializer
  %248 = select <4 x i1> %247, <4 x i32> %246, <4 x i32> %245
  %249 = add nuw <4 x i32> %248, <i32 32, i32 32, i32 32, i32 32>
  %250 = lshr <4 x i32> %249, <i32 6, i32 6, i32 6, i32 6>
  %251 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %240, <4 x i32> %250) #5
  %252 = lshr <8 x i16> %251, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %253 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %224, <8 x i16> %252) #5
  %254 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %253, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %255 = icmp slt <16 x i8> %254, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %256 = select <16 x i1> %255, <16 x i8> %254, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %257 = bitcast i8* %198 to <16 x i8>*
  store <16 x i8> %256, <16 x i8>* %257, align 16
  %258 = getelementptr inbounds i16, i16* %10, i64 64
  %259 = getelementptr inbounds i16, i16* %11, i64 64
  %260 = getelementptr inbounds i8, i8* %9, i64 64
  %261 = bitcast i16* %258 to <8 x i16>*
  %262 = load <8 x i16>, <8 x i16>* %261, align 16
  %263 = bitcast i16* %259 to <8 x i16>*
  %264 = load <8 x i16>, <8 x i16>* %263, align 16
  %265 = shufflevector <8 x i16> %262, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %266 = zext <4 x i16> %265 to <4 x i32>
  %267 = shufflevector <8 x i16> %264, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %268 = zext <4 x i16> %267 to <4 x i32>
  %269 = sub nsw <4 x i32> %266, %268
  %270 = sub nsw <4 x i32> zeroinitializer, %269
  %271 = icmp slt <4 x i32> %269, zeroinitializer
  %272 = select <4 x i1> %271, <4 x i32> %270, <4 x i32> %269
  %273 = add nuw nsw <4 x i32> %272, <i32 32, i32 32, i32 32, i32 32>
  %274 = lshr <4 x i32> %273, <i32 6, i32 6, i32 6, i32 6>
  %275 = shufflevector <8 x i16> %262, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %276 = shufflevector <8 x i16> %264, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %277 = bitcast <8 x i16> %275 to <4 x i32>
  %278 = bitcast <8 x i16> %276 to <4 x i32>
  %279 = sub <4 x i32> %277, %278
  %280 = sub <4 x i32> zeroinitializer, %279
  %281 = icmp slt <4 x i32> %279, zeroinitializer
  %282 = select <4 x i1> %281, <4 x i32> %280, <4 x i32> %279
  %283 = add nuw <4 x i32> %282, <i32 32, i32 32, i32 32, i32 32>
  %284 = lshr <4 x i32> %283, <i32 6, i32 6, i32 6, i32 6>
  %285 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %274, <4 x i32> %284) #5
  %286 = lshr <8 x i16> %285, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %287 = getelementptr inbounds i16, i16* %10, i64 72
  %288 = bitcast i16* %287 to <8 x i16>*
  %289 = load <8 x i16>, <8 x i16>* %288, align 16
  %290 = getelementptr inbounds i16, i16* %11, i64 72
  %291 = bitcast i16* %290 to <8 x i16>*
  %292 = load <8 x i16>, <8 x i16>* %291, align 16
  %293 = shufflevector <8 x i16> %289, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %294 = zext <4 x i16> %293 to <4 x i32>
  %295 = shufflevector <8 x i16> %292, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %296 = zext <4 x i16> %295 to <4 x i32>
  %297 = sub nsw <4 x i32> %294, %296
  %298 = sub nsw <4 x i32> zeroinitializer, %297
  %299 = icmp slt <4 x i32> %297, zeroinitializer
  %300 = select <4 x i1> %299, <4 x i32> %298, <4 x i32> %297
  %301 = add nuw nsw <4 x i32> %300, <i32 32, i32 32, i32 32, i32 32>
  %302 = lshr <4 x i32> %301, <i32 6, i32 6, i32 6, i32 6>
  %303 = shufflevector <8 x i16> %289, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %304 = shufflevector <8 x i16> %292, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %305 = bitcast <8 x i16> %303 to <4 x i32>
  %306 = bitcast <8 x i16> %304 to <4 x i32>
  %307 = sub <4 x i32> %305, %306
  %308 = sub <4 x i32> zeroinitializer, %307
  %309 = icmp slt <4 x i32> %307, zeroinitializer
  %310 = select <4 x i1> %309, <4 x i32> %308, <4 x i32> %307
  %311 = add nuw <4 x i32> %310, <i32 32, i32 32, i32 32, i32 32>
  %312 = lshr <4 x i32> %311, <i32 6, i32 6, i32 6, i32 6>
  %313 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %302, <4 x i32> %312) #5
  %314 = lshr <8 x i16> %313, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %315 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %286, <8 x i16> %314) #5
  %316 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %315, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %317 = icmp slt <16 x i8> %316, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %318 = select <16 x i1> %317, <16 x i8> %316, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %319 = bitcast i8* %260 to <16 x i8>*
  store <16 x i8> %318, <16 x i8>* %319, align 16
  %320 = getelementptr inbounds i16, i16* %10, i64 80
  %321 = getelementptr inbounds i16, i16* %11, i64 80
  %322 = getelementptr inbounds i8, i8* %9, i64 80
  %323 = bitcast i16* %320 to <8 x i16>*
  %324 = load <8 x i16>, <8 x i16>* %323, align 16
  %325 = bitcast i16* %321 to <8 x i16>*
  %326 = load <8 x i16>, <8 x i16>* %325, align 16
  %327 = shufflevector <8 x i16> %324, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %328 = zext <4 x i16> %327 to <4 x i32>
  %329 = shufflevector <8 x i16> %326, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %330 = zext <4 x i16> %329 to <4 x i32>
  %331 = sub nsw <4 x i32> %328, %330
  %332 = sub nsw <4 x i32> zeroinitializer, %331
  %333 = icmp slt <4 x i32> %331, zeroinitializer
  %334 = select <4 x i1> %333, <4 x i32> %332, <4 x i32> %331
  %335 = add nuw nsw <4 x i32> %334, <i32 32, i32 32, i32 32, i32 32>
  %336 = lshr <4 x i32> %335, <i32 6, i32 6, i32 6, i32 6>
  %337 = shufflevector <8 x i16> %324, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %338 = shufflevector <8 x i16> %326, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %339 = bitcast <8 x i16> %337 to <4 x i32>
  %340 = bitcast <8 x i16> %338 to <4 x i32>
  %341 = sub <4 x i32> %339, %340
  %342 = sub <4 x i32> zeroinitializer, %341
  %343 = icmp slt <4 x i32> %341, zeroinitializer
  %344 = select <4 x i1> %343, <4 x i32> %342, <4 x i32> %341
  %345 = add nuw <4 x i32> %344, <i32 32, i32 32, i32 32, i32 32>
  %346 = lshr <4 x i32> %345, <i32 6, i32 6, i32 6, i32 6>
  %347 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %336, <4 x i32> %346) #5
  %348 = lshr <8 x i16> %347, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %349 = getelementptr inbounds i16, i16* %10, i64 88
  %350 = bitcast i16* %349 to <8 x i16>*
  %351 = load <8 x i16>, <8 x i16>* %350, align 16
  %352 = getelementptr inbounds i16, i16* %11, i64 88
  %353 = bitcast i16* %352 to <8 x i16>*
  %354 = load <8 x i16>, <8 x i16>* %353, align 16
  %355 = shufflevector <8 x i16> %351, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %356 = zext <4 x i16> %355 to <4 x i32>
  %357 = shufflevector <8 x i16> %354, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %358 = zext <4 x i16> %357 to <4 x i32>
  %359 = sub nsw <4 x i32> %356, %358
  %360 = sub nsw <4 x i32> zeroinitializer, %359
  %361 = icmp slt <4 x i32> %359, zeroinitializer
  %362 = select <4 x i1> %361, <4 x i32> %360, <4 x i32> %359
  %363 = add nuw nsw <4 x i32> %362, <i32 32, i32 32, i32 32, i32 32>
  %364 = lshr <4 x i32> %363, <i32 6, i32 6, i32 6, i32 6>
  %365 = shufflevector <8 x i16> %351, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %366 = shufflevector <8 x i16> %354, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %367 = bitcast <8 x i16> %365 to <4 x i32>
  %368 = bitcast <8 x i16> %366 to <4 x i32>
  %369 = sub <4 x i32> %367, %368
  %370 = sub <4 x i32> zeroinitializer, %369
  %371 = icmp slt <4 x i32> %369, zeroinitializer
  %372 = select <4 x i1> %371, <4 x i32> %370, <4 x i32> %369
  %373 = add nuw <4 x i32> %372, <i32 32, i32 32, i32 32, i32 32>
  %374 = lshr <4 x i32> %373, <i32 6, i32 6, i32 6, i32 6>
  %375 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %364, <4 x i32> %374) #5
  %376 = lshr <8 x i16> %375, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %377 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %348, <8 x i16> %376) #5
  %378 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %377, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %379 = icmp slt <16 x i8> %378, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %380 = select <16 x i1> %379, <16 x i8> %378, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %381 = bitcast i8* %322 to <16 x i8>*
  store <16 x i8> %380, <16 x i8>* %381, align 16
  %382 = getelementptr inbounds i16, i16* %10, i64 96
  %383 = getelementptr inbounds i16, i16* %11, i64 96
  %384 = getelementptr inbounds i8, i8* %9, i64 96
  %385 = bitcast i16* %382 to <8 x i16>*
  %386 = load <8 x i16>, <8 x i16>* %385, align 16
  %387 = bitcast i16* %383 to <8 x i16>*
  %388 = load <8 x i16>, <8 x i16>* %387, align 16
  %389 = shufflevector <8 x i16> %386, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %390 = zext <4 x i16> %389 to <4 x i32>
  %391 = shufflevector <8 x i16> %388, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %392 = zext <4 x i16> %391 to <4 x i32>
  %393 = sub nsw <4 x i32> %390, %392
  %394 = sub nsw <4 x i32> zeroinitializer, %393
  %395 = icmp slt <4 x i32> %393, zeroinitializer
  %396 = select <4 x i1> %395, <4 x i32> %394, <4 x i32> %393
  %397 = add nuw nsw <4 x i32> %396, <i32 32, i32 32, i32 32, i32 32>
  %398 = lshr <4 x i32> %397, <i32 6, i32 6, i32 6, i32 6>
  %399 = shufflevector <8 x i16> %386, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %400 = shufflevector <8 x i16> %388, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %401 = bitcast <8 x i16> %399 to <4 x i32>
  %402 = bitcast <8 x i16> %400 to <4 x i32>
  %403 = sub <4 x i32> %401, %402
  %404 = sub <4 x i32> zeroinitializer, %403
  %405 = icmp slt <4 x i32> %403, zeroinitializer
  %406 = select <4 x i1> %405, <4 x i32> %404, <4 x i32> %403
  %407 = add nuw <4 x i32> %406, <i32 32, i32 32, i32 32, i32 32>
  %408 = lshr <4 x i32> %407, <i32 6, i32 6, i32 6, i32 6>
  %409 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %398, <4 x i32> %408) #5
  %410 = lshr <8 x i16> %409, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %411 = getelementptr inbounds i16, i16* %10, i64 104
  %412 = bitcast i16* %411 to <8 x i16>*
  %413 = load <8 x i16>, <8 x i16>* %412, align 16
  %414 = getelementptr inbounds i16, i16* %11, i64 104
  %415 = bitcast i16* %414 to <8 x i16>*
  %416 = load <8 x i16>, <8 x i16>* %415, align 16
  %417 = shufflevector <8 x i16> %413, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %418 = zext <4 x i16> %417 to <4 x i32>
  %419 = shufflevector <8 x i16> %416, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %420 = zext <4 x i16> %419 to <4 x i32>
  %421 = sub nsw <4 x i32> %418, %420
  %422 = sub nsw <4 x i32> zeroinitializer, %421
  %423 = icmp slt <4 x i32> %421, zeroinitializer
  %424 = select <4 x i1> %423, <4 x i32> %422, <4 x i32> %421
  %425 = add nuw nsw <4 x i32> %424, <i32 32, i32 32, i32 32, i32 32>
  %426 = lshr <4 x i32> %425, <i32 6, i32 6, i32 6, i32 6>
  %427 = shufflevector <8 x i16> %413, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %428 = shufflevector <8 x i16> %416, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %429 = bitcast <8 x i16> %427 to <4 x i32>
  %430 = bitcast <8 x i16> %428 to <4 x i32>
  %431 = sub <4 x i32> %429, %430
  %432 = sub <4 x i32> zeroinitializer, %431
  %433 = icmp slt <4 x i32> %431, zeroinitializer
  %434 = select <4 x i1> %433, <4 x i32> %432, <4 x i32> %431
  %435 = add nuw <4 x i32> %434, <i32 32, i32 32, i32 32, i32 32>
  %436 = lshr <4 x i32> %435, <i32 6, i32 6, i32 6, i32 6>
  %437 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %426, <4 x i32> %436) #5
  %438 = lshr <8 x i16> %437, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %439 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %410, <8 x i16> %438) #5
  %440 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %439, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %441 = icmp slt <16 x i8> %440, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %442 = select <16 x i1> %441, <16 x i8> %440, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %443 = bitcast i8* %384 to <16 x i8>*
  store <16 x i8> %442, <16 x i8>* %443, align 16
  %444 = getelementptr inbounds i16, i16* %10, i64 112
  %445 = getelementptr inbounds i16, i16* %11, i64 112
  %446 = getelementptr inbounds i8, i8* %9, i64 112
  %447 = bitcast i16* %444 to <8 x i16>*
  %448 = load <8 x i16>, <8 x i16>* %447, align 16
  %449 = bitcast i16* %445 to <8 x i16>*
  %450 = load <8 x i16>, <8 x i16>* %449, align 16
  %451 = shufflevector <8 x i16> %448, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %452 = zext <4 x i16> %451 to <4 x i32>
  %453 = shufflevector <8 x i16> %450, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %454 = zext <4 x i16> %453 to <4 x i32>
  %455 = sub nsw <4 x i32> %452, %454
  %456 = sub nsw <4 x i32> zeroinitializer, %455
  %457 = icmp slt <4 x i32> %455, zeroinitializer
  %458 = select <4 x i1> %457, <4 x i32> %456, <4 x i32> %455
  %459 = add nuw nsw <4 x i32> %458, <i32 32, i32 32, i32 32, i32 32>
  %460 = lshr <4 x i32> %459, <i32 6, i32 6, i32 6, i32 6>
  %461 = shufflevector <8 x i16> %448, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %462 = shufflevector <8 x i16> %450, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %463 = bitcast <8 x i16> %461 to <4 x i32>
  %464 = bitcast <8 x i16> %462 to <4 x i32>
  %465 = sub <4 x i32> %463, %464
  %466 = sub <4 x i32> zeroinitializer, %465
  %467 = icmp slt <4 x i32> %465, zeroinitializer
  %468 = select <4 x i1> %467, <4 x i32> %466, <4 x i32> %465
  %469 = add nuw <4 x i32> %468, <i32 32, i32 32, i32 32, i32 32>
  %470 = lshr <4 x i32> %469, <i32 6, i32 6, i32 6, i32 6>
  %471 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %460, <4 x i32> %470) #5
  %472 = lshr <8 x i16> %471, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %473 = getelementptr inbounds i16, i16* %10, i64 120
  %474 = bitcast i16* %473 to <8 x i16>*
  %475 = load <8 x i16>, <8 x i16>* %474, align 16
  %476 = getelementptr inbounds i16, i16* %11, i64 120
  %477 = bitcast i16* %476 to <8 x i16>*
  %478 = load <8 x i16>, <8 x i16>* %477, align 16
  %479 = shufflevector <8 x i16> %475, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %480 = zext <4 x i16> %479 to <4 x i32>
  %481 = shufflevector <8 x i16> %478, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %482 = zext <4 x i16> %481 to <4 x i32>
  %483 = sub nsw <4 x i32> %480, %482
  %484 = sub nsw <4 x i32> zeroinitializer, %483
  %485 = icmp slt <4 x i32> %483, zeroinitializer
  %486 = select <4 x i1> %485, <4 x i32> %484, <4 x i32> %483
  %487 = add nuw nsw <4 x i32> %486, <i32 32, i32 32, i32 32, i32 32>
  %488 = lshr <4 x i32> %487, <i32 6, i32 6, i32 6, i32 6>
  %489 = shufflevector <8 x i16> %475, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %490 = shufflevector <8 x i16> %478, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %491 = bitcast <8 x i16> %489 to <4 x i32>
  %492 = bitcast <8 x i16> %490 to <4 x i32>
  %493 = sub <4 x i32> %491, %492
  %494 = sub <4 x i32> zeroinitializer, %493
  %495 = icmp slt <4 x i32> %493, zeroinitializer
  %496 = select <4 x i1> %495, <4 x i32> %494, <4 x i32> %493
  %497 = add nuw <4 x i32> %496, <i32 32, i32 32, i32 32, i32 32>
  %498 = lshr <4 x i32> %497, <i32 6, i32 6, i32 6, i32 6>
  %499 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %488, <4 x i32> %498) #5
  %500 = lshr <8 x i16> %499, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %501 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %472, <8 x i16> %500) #5
  %502 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %501, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %503 = icmp slt <16 x i8> %502, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %504 = select <16 x i1> %503, <16 x i8> %502, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %505 = bitcast i8* %446 to <16 x i8>*
  store <16 x i8> %504, <16 x i8>* %505, align 16
  %506 = getelementptr inbounds i16, i16* %10, i64 128
  %507 = getelementptr inbounds i16, i16* %11, i64 128
  %508 = getelementptr inbounds i8, i8* %9, i64 %3
  %509 = bitcast i16* %506 to <8 x i16>*
  %510 = load <8 x i16>, <8 x i16>* %509, align 16
  %511 = bitcast i16* %507 to <8 x i16>*
  %512 = load <8 x i16>, <8 x i16>* %511, align 16
  %513 = shufflevector <8 x i16> %510, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %514 = zext <4 x i16> %513 to <4 x i32>
  %515 = shufflevector <8 x i16> %512, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %516 = zext <4 x i16> %515 to <4 x i32>
  %517 = sub nsw <4 x i32> %514, %516
  %518 = sub nsw <4 x i32> zeroinitializer, %517
  %519 = icmp slt <4 x i32> %517, zeroinitializer
  %520 = select <4 x i1> %519, <4 x i32> %518, <4 x i32> %517
  %521 = add nuw nsw <4 x i32> %520, <i32 32, i32 32, i32 32, i32 32>
  %522 = lshr <4 x i32> %521, <i32 6, i32 6, i32 6, i32 6>
  %523 = shufflevector <8 x i16> %510, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %524 = shufflevector <8 x i16> %512, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %525 = bitcast <8 x i16> %523 to <4 x i32>
  %526 = bitcast <8 x i16> %524 to <4 x i32>
  %527 = sub <4 x i32> %525, %526
  %528 = sub <4 x i32> zeroinitializer, %527
  %529 = icmp slt <4 x i32> %527, zeroinitializer
  %530 = select <4 x i1> %529, <4 x i32> %528, <4 x i32> %527
  %531 = add nuw <4 x i32> %530, <i32 32, i32 32, i32 32, i32 32>
  %532 = lshr <4 x i32> %531, <i32 6, i32 6, i32 6, i32 6>
  %533 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %522, <4 x i32> %532) #5
  %534 = lshr <8 x i16> %533, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %535 = getelementptr inbounds i16, i16* %10, i64 136
  %536 = bitcast i16* %535 to <8 x i16>*
  %537 = load <8 x i16>, <8 x i16>* %536, align 16
  %538 = getelementptr inbounds i16, i16* %11, i64 136
  %539 = bitcast i16* %538 to <8 x i16>*
  %540 = load <8 x i16>, <8 x i16>* %539, align 16
  %541 = shufflevector <8 x i16> %537, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %542 = zext <4 x i16> %541 to <4 x i32>
  %543 = shufflevector <8 x i16> %540, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %544 = zext <4 x i16> %543 to <4 x i32>
  %545 = sub nsw <4 x i32> %542, %544
  %546 = sub nsw <4 x i32> zeroinitializer, %545
  %547 = icmp slt <4 x i32> %545, zeroinitializer
  %548 = select <4 x i1> %547, <4 x i32> %546, <4 x i32> %545
  %549 = add nuw nsw <4 x i32> %548, <i32 32, i32 32, i32 32, i32 32>
  %550 = lshr <4 x i32> %549, <i32 6, i32 6, i32 6, i32 6>
  %551 = shufflevector <8 x i16> %537, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %552 = shufflevector <8 x i16> %540, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %553 = bitcast <8 x i16> %551 to <4 x i32>
  %554 = bitcast <8 x i16> %552 to <4 x i32>
  %555 = sub <4 x i32> %553, %554
  %556 = sub <4 x i32> zeroinitializer, %555
  %557 = icmp slt <4 x i32> %555, zeroinitializer
  %558 = select <4 x i1> %557, <4 x i32> %556, <4 x i32> %555
  %559 = add nuw <4 x i32> %558, <i32 32, i32 32, i32 32, i32 32>
  %560 = lshr <4 x i32> %559, <i32 6, i32 6, i32 6, i32 6>
  %561 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %550, <4 x i32> %560) #5
  %562 = lshr <8 x i16> %561, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %563 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %534, <8 x i16> %562) #5
  %564 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %563, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %565 = icmp slt <16 x i8> %564, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %566 = select <16 x i1> %565, <16 x i8> %564, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %567 = bitcast i8* %508 to <16 x i8>*
  store <16 x i8> %566, <16 x i8>* %567, align 16
  %568 = getelementptr inbounds i16, i16* %10, i64 144
  %569 = getelementptr inbounds i16, i16* %11, i64 144
  %570 = getelementptr inbounds i8, i8* %508, i64 16
  %571 = bitcast i16* %568 to <8 x i16>*
  %572 = load <8 x i16>, <8 x i16>* %571, align 16
  %573 = bitcast i16* %569 to <8 x i16>*
  %574 = load <8 x i16>, <8 x i16>* %573, align 16
  %575 = shufflevector <8 x i16> %572, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %576 = zext <4 x i16> %575 to <4 x i32>
  %577 = shufflevector <8 x i16> %574, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %578 = zext <4 x i16> %577 to <4 x i32>
  %579 = sub nsw <4 x i32> %576, %578
  %580 = sub nsw <4 x i32> zeroinitializer, %579
  %581 = icmp slt <4 x i32> %579, zeroinitializer
  %582 = select <4 x i1> %581, <4 x i32> %580, <4 x i32> %579
  %583 = add nuw nsw <4 x i32> %582, <i32 32, i32 32, i32 32, i32 32>
  %584 = lshr <4 x i32> %583, <i32 6, i32 6, i32 6, i32 6>
  %585 = shufflevector <8 x i16> %572, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %586 = shufflevector <8 x i16> %574, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %587 = bitcast <8 x i16> %585 to <4 x i32>
  %588 = bitcast <8 x i16> %586 to <4 x i32>
  %589 = sub <4 x i32> %587, %588
  %590 = sub <4 x i32> zeroinitializer, %589
  %591 = icmp slt <4 x i32> %589, zeroinitializer
  %592 = select <4 x i1> %591, <4 x i32> %590, <4 x i32> %589
  %593 = add nuw <4 x i32> %592, <i32 32, i32 32, i32 32, i32 32>
  %594 = lshr <4 x i32> %593, <i32 6, i32 6, i32 6, i32 6>
  %595 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %584, <4 x i32> %594) #5
  %596 = lshr <8 x i16> %595, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %597 = getelementptr inbounds i16, i16* %10, i64 152
  %598 = bitcast i16* %597 to <8 x i16>*
  %599 = load <8 x i16>, <8 x i16>* %598, align 16
  %600 = getelementptr inbounds i16, i16* %11, i64 152
  %601 = bitcast i16* %600 to <8 x i16>*
  %602 = load <8 x i16>, <8 x i16>* %601, align 16
  %603 = shufflevector <8 x i16> %599, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %604 = zext <4 x i16> %603 to <4 x i32>
  %605 = shufflevector <8 x i16> %602, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %606 = zext <4 x i16> %605 to <4 x i32>
  %607 = sub nsw <4 x i32> %604, %606
  %608 = sub nsw <4 x i32> zeroinitializer, %607
  %609 = icmp slt <4 x i32> %607, zeroinitializer
  %610 = select <4 x i1> %609, <4 x i32> %608, <4 x i32> %607
  %611 = add nuw nsw <4 x i32> %610, <i32 32, i32 32, i32 32, i32 32>
  %612 = lshr <4 x i32> %611, <i32 6, i32 6, i32 6, i32 6>
  %613 = shufflevector <8 x i16> %599, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %614 = shufflevector <8 x i16> %602, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %615 = bitcast <8 x i16> %613 to <4 x i32>
  %616 = bitcast <8 x i16> %614 to <4 x i32>
  %617 = sub <4 x i32> %615, %616
  %618 = sub <4 x i32> zeroinitializer, %617
  %619 = icmp slt <4 x i32> %617, zeroinitializer
  %620 = select <4 x i1> %619, <4 x i32> %618, <4 x i32> %617
  %621 = add nuw <4 x i32> %620, <i32 32, i32 32, i32 32, i32 32>
  %622 = lshr <4 x i32> %621, <i32 6, i32 6, i32 6, i32 6>
  %623 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %612, <4 x i32> %622) #5
  %624 = lshr <8 x i16> %623, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %625 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %596, <8 x i16> %624) #5
  %626 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %625, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %627 = icmp slt <16 x i8> %626, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %628 = select <16 x i1> %627, <16 x i8> %626, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %629 = bitcast i8* %570 to <16 x i8>*
  store <16 x i8> %628, <16 x i8>* %629, align 16
  %630 = getelementptr inbounds i16, i16* %10, i64 160
  %631 = getelementptr inbounds i16, i16* %11, i64 160
  %632 = getelementptr inbounds i8, i8* %508, i64 32
  %633 = bitcast i16* %630 to <8 x i16>*
  %634 = load <8 x i16>, <8 x i16>* %633, align 16
  %635 = bitcast i16* %631 to <8 x i16>*
  %636 = load <8 x i16>, <8 x i16>* %635, align 16
  %637 = shufflevector <8 x i16> %634, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %638 = zext <4 x i16> %637 to <4 x i32>
  %639 = shufflevector <8 x i16> %636, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %640 = zext <4 x i16> %639 to <4 x i32>
  %641 = sub nsw <4 x i32> %638, %640
  %642 = sub nsw <4 x i32> zeroinitializer, %641
  %643 = icmp slt <4 x i32> %641, zeroinitializer
  %644 = select <4 x i1> %643, <4 x i32> %642, <4 x i32> %641
  %645 = add nuw nsw <4 x i32> %644, <i32 32, i32 32, i32 32, i32 32>
  %646 = lshr <4 x i32> %645, <i32 6, i32 6, i32 6, i32 6>
  %647 = shufflevector <8 x i16> %634, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %648 = shufflevector <8 x i16> %636, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %649 = bitcast <8 x i16> %647 to <4 x i32>
  %650 = bitcast <8 x i16> %648 to <4 x i32>
  %651 = sub <4 x i32> %649, %650
  %652 = sub <4 x i32> zeroinitializer, %651
  %653 = icmp slt <4 x i32> %651, zeroinitializer
  %654 = select <4 x i1> %653, <4 x i32> %652, <4 x i32> %651
  %655 = add nuw <4 x i32> %654, <i32 32, i32 32, i32 32, i32 32>
  %656 = lshr <4 x i32> %655, <i32 6, i32 6, i32 6, i32 6>
  %657 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %646, <4 x i32> %656) #5
  %658 = lshr <8 x i16> %657, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %659 = getelementptr inbounds i16, i16* %10, i64 168
  %660 = bitcast i16* %659 to <8 x i16>*
  %661 = load <8 x i16>, <8 x i16>* %660, align 16
  %662 = getelementptr inbounds i16, i16* %11, i64 168
  %663 = bitcast i16* %662 to <8 x i16>*
  %664 = load <8 x i16>, <8 x i16>* %663, align 16
  %665 = shufflevector <8 x i16> %661, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %666 = zext <4 x i16> %665 to <4 x i32>
  %667 = shufflevector <8 x i16> %664, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %668 = zext <4 x i16> %667 to <4 x i32>
  %669 = sub nsw <4 x i32> %666, %668
  %670 = sub nsw <4 x i32> zeroinitializer, %669
  %671 = icmp slt <4 x i32> %669, zeroinitializer
  %672 = select <4 x i1> %671, <4 x i32> %670, <4 x i32> %669
  %673 = add nuw nsw <4 x i32> %672, <i32 32, i32 32, i32 32, i32 32>
  %674 = lshr <4 x i32> %673, <i32 6, i32 6, i32 6, i32 6>
  %675 = shufflevector <8 x i16> %661, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %676 = shufflevector <8 x i16> %664, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %677 = bitcast <8 x i16> %675 to <4 x i32>
  %678 = bitcast <8 x i16> %676 to <4 x i32>
  %679 = sub <4 x i32> %677, %678
  %680 = sub <4 x i32> zeroinitializer, %679
  %681 = icmp slt <4 x i32> %679, zeroinitializer
  %682 = select <4 x i1> %681, <4 x i32> %680, <4 x i32> %679
  %683 = add nuw <4 x i32> %682, <i32 32, i32 32, i32 32, i32 32>
  %684 = lshr <4 x i32> %683, <i32 6, i32 6, i32 6, i32 6>
  %685 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %674, <4 x i32> %684) #5
  %686 = lshr <8 x i16> %685, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %687 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %658, <8 x i16> %686) #5
  %688 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %687, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %689 = icmp slt <16 x i8> %688, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %690 = select <16 x i1> %689, <16 x i8> %688, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %691 = bitcast i8* %632 to <16 x i8>*
  store <16 x i8> %690, <16 x i8>* %691, align 16
  %692 = getelementptr inbounds i16, i16* %10, i64 176
  %693 = getelementptr inbounds i16, i16* %11, i64 176
  %694 = getelementptr inbounds i8, i8* %508, i64 48
  %695 = bitcast i16* %692 to <8 x i16>*
  %696 = load <8 x i16>, <8 x i16>* %695, align 16
  %697 = bitcast i16* %693 to <8 x i16>*
  %698 = load <8 x i16>, <8 x i16>* %697, align 16
  %699 = shufflevector <8 x i16> %696, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %700 = zext <4 x i16> %699 to <4 x i32>
  %701 = shufflevector <8 x i16> %698, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %702 = zext <4 x i16> %701 to <4 x i32>
  %703 = sub nsw <4 x i32> %700, %702
  %704 = sub nsw <4 x i32> zeroinitializer, %703
  %705 = icmp slt <4 x i32> %703, zeroinitializer
  %706 = select <4 x i1> %705, <4 x i32> %704, <4 x i32> %703
  %707 = add nuw nsw <4 x i32> %706, <i32 32, i32 32, i32 32, i32 32>
  %708 = lshr <4 x i32> %707, <i32 6, i32 6, i32 6, i32 6>
  %709 = shufflevector <8 x i16> %696, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %710 = shufflevector <8 x i16> %698, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %711 = bitcast <8 x i16> %709 to <4 x i32>
  %712 = bitcast <8 x i16> %710 to <4 x i32>
  %713 = sub <4 x i32> %711, %712
  %714 = sub <4 x i32> zeroinitializer, %713
  %715 = icmp slt <4 x i32> %713, zeroinitializer
  %716 = select <4 x i1> %715, <4 x i32> %714, <4 x i32> %713
  %717 = add nuw <4 x i32> %716, <i32 32, i32 32, i32 32, i32 32>
  %718 = lshr <4 x i32> %717, <i32 6, i32 6, i32 6, i32 6>
  %719 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %708, <4 x i32> %718) #5
  %720 = lshr <8 x i16> %719, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %721 = getelementptr inbounds i16, i16* %10, i64 184
  %722 = bitcast i16* %721 to <8 x i16>*
  %723 = load <8 x i16>, <8 x i16>* %722, align 16
  %724 = getelementptr inbounds i16, i16* %11, i64 184
  %725 = bitcast i16* %724 to <8 x i16>*
  %726 = load <8 x i16>, <8 x i16>* %725, align 16
  %727 = shufflevector <8 x i16> %723, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %728 = zext <4 x i16> %727 to <4 x i32>
  %729 = shufflevector <8 x i16> %726, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %730 = zext <4 x i16> %729 to <4 x i32>
  %731 = sub nsw <4 x i32> %728, %730
  %732 = sub nsw <4 x i32> zeroinitializer, %731
  %733 = icmp slt <4 x i32> %731, zeroinitializer
  %734 = select <4 x i1> %733, <4 x i32> %732, <4 x i32> %731
  %735 = add nuw nsw <4 x i32> %734, <i32 32, i32 32, i32 32, i32 32>
  %736 = lshr <4 x i32> %735, <i32 6, i32 6, i32 6, i32 6>
  %737 = shufflevector <8 x i16> %723, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %738 = shufflevector <8 x i16> %726, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %739 = bitcast <8 x i16> %737 to <4 x i32>
  %740 = bitcast <8 x i16> %738 to <4 x i32>
  %741 = sub <4 x i32> %739, %740
  %742 = sub <4 x i32> zeroinitializer, %741
  %743 = icmp slt <4 x i32> %741, zeroinitializer
  %744 = select <4 x i1> %743, <4 x i32> %742, <4 x i32> %741
  %745 = add nuw <4 x i32> %744, <i32 32, i32 32, i32 32, i32 32>
  %746 = lshr <4 x i32> %745, <i32 6, i32 6, i32 6, i32 6>
  %747 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %736, <4 x i32> %746) #5
  %748 = lshr <8 x i16> %747, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %749 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %720, <8 x i16> %748) #5
  %750 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %749, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %751 = icmp slt <16 x i8> %750, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %752 = select <16 x i1> %751, <16 x i8> %750, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %753 = bitcast i8* %694 to <16 x i8>*
  store <16 x i8> %752, <16 x i8>* %753, align 16
  %754 = getelementptr inbounds i16, i16* %10, i64 192
  %755 = getelementptr inbounds i16, i16* %11, i64 192
  %756 = getelementptr inbounds i8, i8* %508, i64 64
  %757 = bitcast i16* %754 to <8 x i16>*
  %758 = load <8 x i16>, <8 x i16>* %757, align 16
  %759 = bitcast i16* %755 to <8 x i16>*
  %760 = load <8 x i16>, <8 x i16>* %759, align 16
  %761 = shufflevector <8 x i16> %758, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %762 = zext <4 x i16> %761 to <4 x i32>
  %763 = shufflevector <8 x i16> %760, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %764 = zext <4 x i16> %763 to <4 x i32>
  %765 = sub nsw <4 x i32> %762, %764
  %766 = sub nsw <4 x i32> zeroinitializer, %765
  %767 = icmp slt <4 x i32> %765, zeroinitializer
  %768 = select <4 x i1> %767, <4 x i32> %766, <4 x i32> %765
  %769 = add nuw nsw <4 x i32> %768, <i32 32, i32 32, i32 32, i32 32>
  %770 = lshr <4 x i32> %769, <i32 6, i32 6, i32 6, i32 6>
  %771 = shufflevector <8 x i16> %758, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %772 = shufflevector <8 x i16> %760, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %773 = bitcast <8 x i16> %771 to <4 x i32>
  %774 = bitcast <8 x i16> %772 to <4 x i32>
  %775 = sub <4 x i32> %773, %774
  %776 = sub <4 x i32> zeroinitializer, %775
  %777 = icmp slt <4 x i32> %775, zeroinitializer
  %778 = select <4 x i1> %777, <4 x i32> %776, <4 x i32> %775
  %779 = add nuw <4 x i32> %778, <i32 32, i32 32, i32 32, i32 32>
  %780 = lshr <4 x i32> %779, <i32 6, i32 6, i32 6, i32 6>
  %781 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %770, <4 x i32> %780) #5
  %782 = lshr <8 x i16> %781, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %783 = getelementptr inbounds i16, i16* %10, i64 200
  %784 = bitcast i16* %783 to <8 x i16>*
  %785 = load <8 x i16>, <8 x i16>* %784, align 16
  %786 = getelementptr inbounds i16, i16* %11, i64 200
  %787 = bitcast i16* %786 to <8 x i16>*
  %788 = load <8 x i16>, <8 x i16>* %787, align 16
  %789 = shufflevector <8 x i16> %785, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %790 = zext <4 x i16> %789 to <4 x i32>
  %791 = shufflevector <8 x i16> %788, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %792 = zext <4 x i16> %791 to <4 x i32>
  %793 = sub nsw <4 x i32> %790, %792
  %794 = sub nsw <4 x i32> zeroinitializer, %793
  %795 = icmp slt <4 x i32> %793, zeroinitializer
  %796 = select <4 x i1> %795, <4 x i32> %794, <4 x i32> %793
  %797 = add nuw nsw <4 x i32> %796, <i32 32, i32 32, i32 32, i32 32>
  %798 = lshr <4 x i32> %797, <i32 6, i32 6, i32 6, i32 6>
  %799 = shufflevector <8 x i16> %785, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %800 = shufflevector <8 x i16> %788, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %801 = bitcast <8 x i16> %799 to <4 x i32>
  %802 = bitcast <8 x i16> %800 to <4 x i32>
  %803 = sub <4 x i32> %801, %802
  %804 = sub <4 x i32> zeroinitializer, %803
  %805 = icmp slt <4 x i32> %803, zeroinitializer
  %806 = select <4 x i1> %805, <4 x i32> %804, <4 x i32> %803
  %807 = add nuw <4 x i32> %806, <i32 32, i32 32, i32 32, i32 32>
  %808 = lshr <4 x i32> %807, <i32 6, i32 6, i32 6, i32 6>
  %809 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %798, <4 x i32> %808) #5
  %810 = lshr <8 x i16> %809, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %811 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %782, <8 x i16> %810) #5
  %812 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %811, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %813 = icmp slt <16 x i8> %812, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %814 = select <16 x i1> %813, <16 x i8> %812, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %815 = bitcast i8* %756 to <16 x i8>*
  store <16 x i8> %814, <16 x i8>* %815, align 16
  %816 = getelementptr inbounds i16, i16* %10, i64 208
  %817 = getelementptr inbounds i16, i16* %11, i64 208
  %818 = getelementptr inbounds i8, i8* %756, i64 16
  %819 = bitcast i16* %816 to <8 x i16>*
  %820 = load <8 x i16>, <8 x i16>* %819, align 16
  %821 = bitcast i16* %817 to <8 x i16>*
  %822 = load <8 x i16>, <8 x i16>* %821, align 16
  %823 = shufflevector <8 x i16> %820, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %824 = zext <4 x i16> %823 to <4 x i32>
  %825 = shufflevector <8 x i16> %822, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %826 = zext <4 x i16> %825 to <4 x i32>
  %827 = sub nsw <4 x i32> %824, %826
  %828 = sub nsw <4 x i32> zeroinitializer, %827
  %829 = icmp slt <4 x i32> %827, zeroinitializer
  %830 = select <4 x i1> %829, <4 x i32> %828, <4 x i32> %827
  %831 = add nuw nsw <4 x i32> %830, <i32 32, i32 32, i32 32, i32 32>
  %832 = lshr <4 x i32> %831, <i32 6, i32 6, i32 6, i32 6>
  %833 = shufflevector <8 x i16> %820, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %834 = shufflevector <8 x i16> %822, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %835 = bitcast <8 x i16> %833 to <4 x i32>
  %836 = bitcast <8 x i16> %834 to <4 x i32>
  %837 = sub <4 x i32> %835, %836
  %838 = sub <4 x i32> zeroinitializer, %837
  %839 = icmp slt <4 x i32> %837, zeroinitializer
  %840 = select <4 x i1> %839, <4 x i32> %838, <4 x i32> %837
  %841 = add nuw <4 x i32> %840, <i32 32, i32 32, i32 32, i32 32>
  %842 = lshr <4 x i32> %841, <i32 6, i32 6, i32 6, i32 6>
  %843 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %832, <4 x i32> %842) #5
  %844 = lshr <8 x i16> %843, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %845 = getelementptr inbounds i16, i16* %10, i64 216
  %846 = bitcast i16* %845 to <8 x i16>*
  %847 = load <8 x i16>, <8 x i16>* %846, align 16
  %848 = getelementptr inbounds i16, i16* %11, i64 216
  %849 = bitcast i16* %848 to <8 x i16>*
  %850 = load <8 x i16>, <8 x i16>* %849, align 16
  %851 = shufflevector <8 x i16> %847, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %852 = zext <4 x i16> %851 to <4 x i32>
  %853 = shufflevector <8 x i16> %850, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %854 = zext <4 x i16> %853 to <4 x i32>
  %855 = sub nsw <4 x i32> %852, %854
  %856 = sub nsw <4 x i32> zeroinitializer, %855
  %857 = icmp slt <4 x i32> %855, zeroinitializer
  %858 = select <4 x i1> %857, <4 x i32> %856, <4 x i32> %855
  %859 = add nuw nsw <4 x i32> %858, <i32 32, i32 32, i32 32, i32 32>
  %860 = lshr <4 x i32> %859, <i32 6, i32 6, i32 6, i32 6>
  %861 = shufflevector <8 x i16> %847, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %862 = shufflevector <8 x i16> %850, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %863 = bitcast <8 x i16> %861 to <4 x i32>
  %864 = bitcast <8 x i16> %862 to <4 x i32>
  %865 = sub <4 x i32> %863, %864
  %866 = sub <4 x i32> zeroinitializer, %865
  %867 = icmp slt <4 x i32> %865, zeroinitializer
  %868 = select <4 x i1> %867, <4 x i32> %866, <4 x i32> %865
  %869 = add nuw <4 x i32> %868, <i32 32, i32 32, i32 32, i32 32>
  %870 = lshr <4 x i32> %869, <i32 6, i32 6, i32 6, i32 6>
  %871 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %860, <4 x i32> %870) #5
  %872 = lshr <8 x i16> %871, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %873 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %844, <8 x i16> %872) #5
  %874 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %873, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %875 = icmp slt <16 x i8> %874, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %876 = select <16 x i1> %875, <16 x i8> %874, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %877 = bitcast i8* %818 to <16 x i8>*
  store <16 x i8> %876, <16 x i8>* %877, align 16
  %878 = getelementptr inbounds i16, i16* %10, i64 224
  %879 = getelementptr inbounds i16, i16* %11, i64 224
  %880 = getelementptr inbounds i8, i8* %756, i64 32
  %881 = bitcast i16* %878 to <8 x i16>*
  %882 = load <8 x i16>, <8 x i16>* %881, align 16
  %883 = bitcast i16* %879 to <8 x i16>*
  %884 = load <8 x i16>, <8 x i16>* %883, align 16
  %885 = shufflevector <8 x i16> %882, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %886 = zext <4 x i16> %885 to <4 x i32>
  %887 = shufflevector <8 x i16> %884, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %888 = zext <4 x i16> %887 to <4 x i32>
  %889 = sub nsw <4 x i32> %886, %888
  %890 = sub nsw <4 x i32> zeroinitializer, %889
  %891 = icmp slt <4 x i32> %889, zeroinitializer
  %892 = select <4 x i1> %891, <4 x i32> %890, <4 x i32> %889
  %893 = add nuw nsw <4 x i32> %892, <i32 32, i32 32, i32 32, i32 32>
  %894 = lshr <4 x i32> %893, <i32 6, i32 6, i32 6, i32 6>
  %895 = shufflevector <8 x i16> %882, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %896 = shufflevector <8 x i16> %884, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %897 = bitcast <8 x i16> %895 to <4 x i32>
  %898 = bitcast <8 x i16> %896 to <4 x i32>
  %899 = sub <4 x i32> %897, %898
  %900 = sub <4 x i32> zeroinitializer, %899
  %901 = icmp slt <4 x i32> %899, zeroinitializer
  %902 = select <4 x i1> %901, <4 x i32> %900, <4 x i32> %899
  %903 = add nuw <4 x i32> %902, <i32 32, i32 32, i32 32, i32 32>
  %904 = lshr <4 x i32> %903, <i32 6, i32 6, i32 6, i32 6>
  %905 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %894, <4 x i32> %904) #5
  %906 = lshr <8 x i16> %905, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %907 = getelementptr inbounds i16, i16* %10, i64 232
  %908 = bitcast i16* %907 to <8 x i16>*
  %909 = load <8 x i16>, <8 x i16>* %908, align 16
  %910 = getelementptr inbounds i16, i16* %11, i64 232
  %911 = bitcast i16* %910 to <8 x i16>*
  %912 = load <8 x i16>, <8 x i16>* %911, align 16
  %913 = shufflevector <8 x i16> %909, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %914 = zext <4 x i16> %913 to <4 x i32>
  %915 = shufflevector <8 x i16> %912, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %916 = zext <4 x i16> %915 to <4 x i32>
  %917 = sub nsw <4 x i32> %914, %916
  %918 = sub nsw <4 x i32> zeroinitializer, %917
  %919 = icmp slt <4 x i32> %917, zeroinitializer
  %920 = select <4 x i1> %919, <4 x i32> %918, <4 x i32> %917
  %921 = add nuw nsw <4 x i32> %920, <i32 32, i32 32, i32 32, i32 32>
  %922 = lshr <4 x i32> %921, <i32 6, i32 6, i32 6, i32 6>
  %923 = shufflevector <8 x i16> %909, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %924 = shufflevector <8 x i16> %912, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %925 = bitcast <8 x i16> %923 to <4 x i32>
  %926 = bitcast <8 x i16> %924 to <4 x i32>
  %927 = sub <4 x i32> %925, %926
  %928 = sub <4 x i32> zeroinitializer, %927
  %929 = icmp slt <4 x i32> %927, zeroinitializer
  %930 = select <4 x i1> %929, <4 x i32> %928, <4 x i32> %927
  %931 = add nuw <4 x i32> %930, <i32 32, i32 32, i32 32, i32 32>
  %932 = lshr <4 x i32> %931, <i32 6, i32 6, i32 6, i32 6>
  %933 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %922, <4 x i32> %932) #5
  %934 = lshr <8 x i16> %933, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %935 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %906, <8 x i16> %934) #5
  %936 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %935, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %937 = icmp slt <16 x i8> %936, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %938 = select <16 x i1> %937, <16 x i8> %936, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %939 = bitcast i8* %880 to <16 x i8>*
  store <16 x i8> %938, <16 x i8>* %939, align 16
  %940 = getelementptr inbounds i16, i16* %10, i64 240
  %941 = getelementptr inbounds i16, i16* %11, i64 240
  %942 = getelementptr inbounds i8, i8* %756, i64 48
  %943 = bitcast i16* %940 to <8 x i16>*
  %944 = load <8 x i16>, <8 x i16>* %943, align 16
  %945 = bitcast i16* %941 to <8 x i16>*
  %946 = load <8 x i16>, <8 x i16>* %945, align 16
  %947 = shufflevector <8 x i16> %944, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %948 = zext <4 x i16> %947 to <4 x i32>
  %949 = shufflevector <8 x i16> %946, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %950 = zext <4 x i16> %949 to <4 x i32>
  %951 = sub nsw <4 x i32> %948, %950
  %952 = sub nsw <4 x i32> zeroinitializer, %951
  %953 = icmp slt <4 x i32> %951, zeroinitializer
  %954 = select <4 x i1> %953, <4 x i32> %952, <4 x i32> %951
  %955 = add nuw nsw <4 x i32> %954, <i32 32, i32 32, i32 32, i32 32>
  %956 = lshr <4 x i32> %955, <i32 6, i32 6, i32 6, i32 6>
  %957 = shufflevector <8 x i16> %944, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %958 = shufflevector <8 x i16> %946, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %959 = bitcast <8 x i16> %957 to <4 x i32>
  %960 = bitcast <8 x i16> %958 to <4 x i32>
  %961 = sub <4 x i32> %959, %960
  %962 = sub <4 x i32> zeroinitializer, %961
  %963 = icmp slt <4 x i32> %961, zeroinitializer
  %964 = select <4 x i1> %963, <4 x i32> %962, <4 x i32> %961
  %965 = add nuw <4 x i32> %964, <i32 32, i32 32, i32 32, i32 32>
  %966 = lshr <4 x i32> %965, <i32 6, i32 6, i32 6, i32 6>
  %967 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %956, <4 x i32> %966) #5
  %968 = lshr <8 x i16> %967, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %969 = getelementptr inbounds i16, i16* %10, i64 248
  %970 = bitcast i16* %969 to <8 x i16>*
  %971 = load <8 x i16>, <8 x i16>* %970, align 16
  %972 = getelementptr inbounds i16, i16* %11, i64 248
  %973 = bitcast i16* %972 to <8 x i16>*
  %974 = load <8 x i16>, <8 x i16>* %973, align 16
  %975 = shufflevector <8 x i16> %971, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %976 = zext <4 x i16> %975 to <4 x i32>
  %977 = shufflevector <8 x i16> %974, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %978 = zext <4 x i16> %977 to <4 x i32>
  %979 = sub nsw <4 x i32> %976, %978
  %980 = sub nsw <4 x i32> zeroinitializer, %979
  %981 = icmp slt <4 x i32> %979, zeroinitializer
  %982 = select <4 x i1> %981, <4 x i32> %980, <4 x i32> %979
  %983 = add nuw nsw <4 x i32> %982, <i32 32, i32 32, i32 32, i32 32>
  %984 = lshr <4 x i32> %983, <i32 6, i32 6, i32 6, i32 6>
  %985 = shufflevector <8 x i16> %971, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %986 = shufflevector <8 x i16> %974, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %987 = bitcast <8 x i16> %985 to <4 x i32>
  %988 = bitcast <8 x i16> %986 to <4 x i32>
  %989 = sub <4 x i32> %987, %988
  %990 = sub <4 x i32> zeroinitializer, %989
  %991 = icmp slt <4 x i32> %989, zeroinitializer
  %992 = select <4 x i1> %991, <4 x i32> %990, <4 x i32> %989
  %993 = add nuw <4 x i32> %992, <i32 32, i32 32, i32 32, i32 32>
  %994 = lshr <4 x i32> %993, <i32 6, i32 6, i32 6, i32 6>
  %995 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %984, <4 x i32> %994) #5
  %996 = lshr <8 x i16> %995, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %997 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %968, <8 x i16> %996) #5
  %998 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %997, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %999 = icmp slt <16 x i8> %998, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1000 = select <16 x i1> %999, <16 x i8> %998, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1001 = bitcast i8* %942 to <16 x i8>*
  store <16 x i8> %1000, <16 x i8>* %1001, align 16
  %1002 = getelementptr inbounds i16, i16* %10, i64 256
  %1003 = getelementptr inbounds i16, i16* %11, i64 256
  %1004 = getelementptr inbounds i8, i8* %756, i64 %7
  %1005 = bitcast i16* %1002 to <8 x i16>*
  %1006 = load <8 x i16>, <8 x i16>* %1005, align 16
  %1007 = bitcast i16* %1003 to <8 x i16>*
  %1008 = load <8 x i16>, <8 x i16>* %1007, align 16
  %1009 = shufflevector <8 x i16> %1006, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1010 = zext <4 x i16> %1009 to <4 x i32>
  %1011 = shufflevector <8 x i16> %1008, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1012 = zext <4 x i16> %1011 to <4 x i32>
  %1013 = sub nsw <4 x i32> %1010, %1012
  %1014 = sub nsw <4 x i32> zeroinitializer, %1013
  %1015 = icmp slt <4 x i32> %1013, zeroinitializer
  %1016 = select <4 x i1> %1015, <4 x i32> %1014, <4 x i32> %1013
  %1017 = add nuw nsw <4 x i32> %1016, <i32 32, i32 32, i32 32, i32 32>
  %1018 = lshr <4 x i32> %1017, <i32 6, i32 6, i32 6, i32 6>
  %1019 = shufflevector <8 x i16> %1006, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1020 = shufflevector <8 x i16> %1008, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1021 = bitcast <8 x i16> %1019 to <4 x i32>
  %1022 = bitcast <8 x i16> %1020 to <4 x i32>
  %1023 = sub <4 x i32> %1021, %1022
  %1024 = sub <4 x i32> zeroinitializer, %1023
  %1025 = icmp slt <4 x i32> %1023, zeroinitializer
  %1026 = select <4 x i1> %1025, <4 x i32> %1024, <4 x i32> %1023
  %1027 = add nuw <4 x i32> %1026, <i32 32, i32 32, i32 32, i32 32>
  %1028 = lshr <4 x i32> %1027, <i32 6, i32 6, i32 6, i32 6>
  %1029 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1018, <4 x i32> %1028) #5
  %1030 = lshr <8 x i16> %1029, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1031 = getelementptr inbounds i16, i16* %10, i64 264
  %1032 = bitcast i16* %1031 to <8 x i16>*
  %1033 = load <8 x i16>, <8 x i16>* %1032, align 16
  %1034 = getelementptr inbounds i16, i16* %11, i64 264
  %1035 = bitcast i16* %1034 to <8 x i16>*
  %1036 = load <8 x i16>, <8 x i16>* %1035, align 16
  %1037 = shufflevector <8 x i16> %1033, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1038 = zext <4 x i16> %1037 to <4 x i32>
  %1039 = shufflevector <8 x i16> %1036, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1040 = zext <4 x i16> %1039 to <4 x i32>
  %1041 = sub nsw <4 x i32> %1038, %1040
  %1042 = sub nsw <4 x i32> zeroinitializer, %1041
  %1043 = icmp slt <4 x i32> %1041, zeroinitializer
  %1044 = select <4 x i1> %1043, <4 x i32> %1042, <4 x i32> %1041
  %1045 = add nuw nsw <4 x i32> %1044, <i32 32, i32 32, i32 32, i32 32>
  %1046 = lshr <4 x i32> %1045, <i32 6, i32 6, i32 6, i32 6>
  %1047 = shufflevector <8 x i16> %1033, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1048 = shufflevector <8 x i16> %1036, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1049 = bitcast <8 x i16> %1047 to <4 x i32>
  %1050 = bitcast <8 x i16> %1048 to <4 x i32>
  %1051 = sub <4 x i32> %1049, %1050
  %1052 = sub <4 x i32> zeroinitializer, %1051
  %1053 = icmp slt <4 x i32> %1051, zeroinitializer
  %1054 = select <4 x i1> %1053, <4 x i32> %1052, <4 x i32> %1051
  %1055 = add nuw <4 x i32> %1054, <i32 32, i32 32, i32 32, i32 32>
  %1056 = lshr <4 x i32> %1055, <i32 6, i32 6, i32 6, i32 6>
  %1057 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1046, <4 x i32> %1056) #5
  %1058 = lshr <8 x i16> %1057, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1059 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1030, <8 x i16> %1058) #5
  %1060 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1059, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1061 = icmp slt <16 x i8> %1060, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1062 = select <16 x i1> %1061, <16 x i8> %1060, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1063 = bitcast i8* %1004 to <16 x i8>*
  store <16 x i8> %1062, <16 x i8>* %1063, align 16
  %1064 = getelementptr inbounds i16, i16* %10, i64 272
  %1065 = getelementptr inbounds i16, i16* %11, i64 272
  %1066 = getelementptr inbounds i8, i8* %1004, i64 16
  %1067 = bitcast i16* %1064 to <8 x i16>*
  %1068 = load <8 x i16>, <8 x i16>* %1067, align 16
  %1069 = bitcast i16* %1065 to <8 x i16>*
  %1070 = load <8 x i16>, <8 x i16>* %1069, align 16
  %1071 = shufflevector <8 x i16> %1068, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1072 = zext <4 x i16> %1071 to <4 x i32>
  %1073 = shufflevector <8 x i16> %1070, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1074 = zext <4 x i16> %1073 to <4 x i32>
  %1075 = sub nsw <4 x i32> %1072, %1074
  %1076 = sub nsw <4 x i32> zeroinitializer, %1075
  %1077 = icmp slt <4 x i32> %1075, zeroinitializer
  %1078 = select <4 x i1> %1077, <4 x i32> %1076, <4 x i32> %1075
  %1079 = add nuw nsw <4 x i32> %1078, <i32 32, i32 32, i32 32, i32 32>
  %1080 = lshr <4 x i32> %1079, <i32 6, i32 6, i32 6, i32 6>
  %1081 = shufflevector <8 x i16> %1068, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1082 = shufflevector <8 x i16> %1070, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1083 = bitcast <8 x i16> %1081 to <4 x i32>
  %1084 = bitcast <8 x i16> %1082 to <4 x i32>
  %1085 = sub <4 x i32> %1083, %1084
  %1086 = sub <4 x i32> zeroinitializer, %1085
  %1087 = icmp slt <4 x i32> %1085, zeroinitializer
  %1088 = select <4 x i1> %1087, <4 x i32> %1086, <4 x i32> %1085
  %1089 = add nuw <4 x i32> %1088, <i32 32, i32 32, i32 32, i32 32>
  %1090 = lshr <4 x i32> %1089, <i32 6, i32 6, i32 6, i32 6>
  %1091 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1080, <4 x i32> %1090) #5
  %1092 = lshr <8 x i16> %1091, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1093 = getelementptr inbounds i16, i16* %10, i64 280
  %1094 = bitcast i16* %1093 to <8 x i16>*
  %1095 = load <8 x i16>, <8 x i16>* %1094, align 16
  %1096 = getelementptr inbounds i16, i16* %11, i64 280
  %1097 = bitcast i16* %1096 to <8 x i16>*
  %1098 = load <8 x i16>, <8 x i16>* %1097, align 16
  %1099 = shufflevector <8 x i16> %1095, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1100 = zext <4 x i16> %1099 to <4 x i32>
  %1101 = shufflevector <8 x i16> %1098, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1102 = zext <4 x i16> %1101 to <4 x i32>
  %1103 = sub nsw <4 x i32> %1100, %1102
  %1104 = sub nsw <4 x i32> zeroinitializer, %1103
  %1105 = icmp slt <4 x i32> %1103, zeroinitializer
  %1106 = select <4 x i1> %1105, <4 x i32> %1104, <4 x i32> %1103
  %1107 = add nuw nsw <4 x i32> %1106, <i32 32, i32 32, i32 32, i32 32>
  %1108 = lshr <4 x i32> %1107, <i32 6, i32 6, i32 6, i32 6>
  %1109 = shufflevector <8 x i16> %1095, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1110 = shufflevector <8 x i16> %1098, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1111 = bitcast <8 x i16> %1109 to <4 x i32>
  %1112 = bitcast <8 x i16> %1110 to <4 x i32>
  %1113 = sub <4 x i32> %1111, %1112
  %1114 = sub <4 x i32> zeroinitializer, %1113
  %1115 = icmp slt <4 x i32> %1113, zeroinitializer
  %1116 = select <4 x i1> %1115, <4 x i32> %1114, <4 x i32> %1113
  %1117 = add nuw <4 x i32> %1116, <i32 32, i32 32, i32 32, i32 32>
  %1118 = lshr <4 x i32> %1117, <i32 6, i32 6, i32 6, i32 6>
  %1119 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1108, <4 x i32> %1118) #5
  %1120 = lshr <8 x i16> %1119, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1121 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1092, <8 x i16> %1120) #5
  %1122 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1121, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1123 = icmp slt <16 x i8> %1122, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1124 = select <16 x i1> %1123, <16 x i8> %1122, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1125 = bitcast i8* %1066 to <16 x i8>*
  store <16 x i8> %1124, <16 x i8>* %1125, align 16
  %1126 = getelementptr inbounds i16, i16* %10, i64 288
  %1127 = getelementptr inbounds i16, i16* %11, i64 288
  %1128 = getelementptr inbounds i8, i8* %1004, i64 32
  %1129 = bitcast i16* %1126 to <8 x i16>*
  %1130 = load <8 x i16>, <8 x i16>* %1129, align 16
  %1131 = bitcast i16* %1127 to <8 x i16>*
  %1132 = load <8 x i16>, <8 x i16>* %1131, align 16
  %1133 = shufflevector <8 x i16> %1130, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1134 = zext <4 x i16> %1133 to <4 x i32>
  %1135 = shufflevector <8 x i16> %1132, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1136 = zext <4 x i16> %1135 to <4 x i32>
  %1137 = sub nsw <4 x i32> %1134, %1136
  %1138 = sub nsw <4 x i32> zeroinitializer, %1137
  %1139 = icmp slt <4 x i32> %1137, zeroinitializer
  %1140 = select <4 x i1> %1139, <4 x i32> %1138, <4 x i32> %1137
  %1141 = add nuw nsw <4 x i32> %1140, <i32 32, i32 32, i32 32, i32 32>
  %1142 = lshr <4 x i32> %1141, <i32 6, i32 6, i32 6, i32 6>
  %1143 = shufflevector <8 x i16> %1130, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1144 = shufflevector <8 x i16> %1132, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1145 = bitcast <8 x i16> %1143 to <4 x i32>
  %1146 = bitcast <8 x i16> %1144 to <4 x i32>
  %1147 = sub <4 x i32> %1145, %1146
  %1148 = sub <4 x i32> zeroinitializer, %1147
  %1149 = icmp slt <4 x i32> %1147, zeroinitializer
  %1150 = select <4 x i1> %1149, <4 x i32> %1148, <4 x i32> %1147
  %1151 = add nuw <4 x i32> %1150, <i32 32, i32 32, i32 32, i32 32>
  %1152 = lshr <4 x i32> %1151, <i32 6, i32 6, i32 6, i32 6>
  %1153 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1142, <4 x i32> %1152) #5
  %1154 = lshr <8 x i16> %1153, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1155 = getelementptr inbounds i16, i16* %10, i64 296
  %1156 = bitcast i16* %1155 to <8 x i16>*
  %1157 = load <8 x i16>, <8 x i16>* %1156, align 16
  %1158 = getelementptr inbounds i16, i16* %11, i64 296
  %1159 = bitcast i16* %1158 to <8 x i16>*
  %1160 = load <8 x i16>, <8 x i16>* %1159, align 16
  %1161 = shufflevector <8 x i16> %1157, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1162 = zext <4 x i16> %1161 to <4 x i32>
  %1163 = shufflevector <8 x i16> %1160, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1164 = zext <4 x i16> %1163 to <4 x i32>
  %1165 = sub nsw <4 x i32> %1162, %1164
  %1166 = sub nsw <4 x i32> zeroinitializer, %1165
  %1167 = icmp slt <4 x i32> %1165, zeroinitializer
  %1168 = select <4 x i1> %1167, <4 x i32> %1166, <4 x i32> %1165
  %1169 = add nuw nsw <4 x i32> %1168, <i32 32, i32 32, i32 32, i32 32>
  %1170 = lshr <4 x i32> %1169, <i32 6, i32 6, i32 6, i32 6>
  %1171 = shufflevector <8 x i16> %1157, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1172 = shufflevector <8 x i16> %1160, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1173 = bitcast <8 x i16> %1171 to <4 x i32>
  %1174 = bitcast <8 x i16> %1172 to <4 x i32>
  %1175 = sub <4 x i32> %1173, %1174
  %1176 = sub <4 x i32> zeroinitializer, %1175
  %1177 = icmp slt <4 x i32> %1175, zeroinitializer
  %1178 = select <4 x i1> %1177, <4 x i32> %1176, <4 x i32> %1175
  %1179 = add nuw <4 x i32> %1178, <i32 32, i32 32, i32 32, i32 32>
  %1180 = lshr <4 x i32> %1179, <i32 6, i32 6, i32 6, i32 6>
  %1181 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1170, <4 x i32> %1180) #5
  %1182 = lshr <8 x i16> %1181, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1183 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1154, <8 x i16> %1182) #5
  %1184 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1183, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1185 = icmp slt <16 x i8> %1184, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1186 = select <16 x i1> %1185, <16 x i8> %1184, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1187 = bitcast i8* %1128 to <16 x i8>*
  store <16 x i8> %1186, <16 x i8>* %1187, align 16
  %1188 = getelementptr inbounds i16, i16* %10, i64 304
  %1189 = getelementptr inbounds i16, i16* %11, i64 304
  %1190 = getelementptr inbounds i8, i8* %1004, i64 48
  %1191 = bitcast i16* %1188 to <8 x i16>*
  %1192 = load <8 x i16>, <8 x i16>* %1191, align 16
  %1193 = bitcast i16* %1189 to <8 x i16>*
  %1194 = load <8 x i16>, <8 x i16>* %1193, align 16
  %1195 = shufflevector <8 x i16> %1192, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1196 = zext <4 x i16> %1195 to <4 x i32>
  %1197 = shufflevector <8 x i16> %1194, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1198 = zext <4 x i16> %1197 to <4 x i32>
  %1199 = sub nsw <4 x i32> %1196, %1198
  %1200 = sub nsw <4 x i32> zeroinitializer, %1199
  %1201 = icmp slt <4 x i32> %1199, zeroinitializer
  %1202 = select <4 x i1> %1201, <4 x i32> %1200, <4 x i32> %1199
  %1203 = add nuw nsw <4 x i32> %1202, <i32 32, i32 32, i32 32, i32 32>
  %1204 = lshr <4 x i32> %1203, <i32 6, i32 6, i32 6, i32 6>
  %1205 = shufflevector <8 x i16> %1192, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1206 = shufflevector <8 x i16> %1194, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1207 = bitcast <8 x i16> %1205 to <4 x i32>
  %1208 = bitcast <8 x i16> %1206 to <4 x i32>
  %1209 = sub <4 x i32> %1207, %1208
  %1210 = sub <4 x i32> zeroinitializer, %1209
  %1211 = icmp slt <4 x i32> %1209, zeroinitializer
  %1212 = select <4 x i1> %1211, <4 x i32> %1210, <4 x i32> %1209
  %1213 = add nuw <4 x i32> %1212, <i32 32, i32 32, i32 32, i32 32>
  %1214 = lshr <4 x i32> %1213, <i32 6, i32 6, i32 6, i32 6>
  %1215 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1204, <4 x i32> %1214) #5
  %1216 = lshr <8 x i16> %1215, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1217 = getelementptr inbounds i16, i16* %10, i64 312
  %1218 = bitcast i16* %1217 to <8 x i16>*
  %1219 = load <8 x i16>, <8 x i16>* %1218, align 16
  %1220 = getelementptr inbounds i16, i16* %11, i64 312
  %1221 = bitcast i16* %1220 to <8 x i16>*
  %1222 = load <8 x i16>, <8 x i16>* %1221, align 16
  %1223 = shufflevector <8 x i16> %1219, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1224 = zext <4 x i16> %1223 to <4 x i32>
  %1225 = shufflevector <8 x i16> %1222, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1226 = zext <4 x i16> %1225 to <4 x i32>
  %1227 = sub nsw <4 x i32> %1224, %1226
  %1228 = sub nsw <4 x i32> zeroinitializer, %1227
  %1229 = icmp slt <4 x i32> %1227, zeroinitializer
  %1230 = select <4 x i1> %1229, <4 x i32> %1228, <4 x i32> %1227
  %1231 = add nuw nsw <4 x i32> %1230, <i32 32, i32 32, i32 32, i32 32>
  %1232 = lshr <4 x i32> %1231, <i32 6, i32 6, i32 6, i32 6>
  %1233 = shufflevector <8 x i16> %1219, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1234 = shufflevector <8 x i16> %1222, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1235 = bitcast <8 x i16> %1233 to <4 x i32>
  %1236 = bitcast <8 x i16> %1234 to <4 x i32>
  %1237 = sub <4 x i32> %1235, %1236
  %1238 = sub <4 x i32> zeroinitializer, %1237
  %1239 = icmp slt <4 x i32> %1237, zeroinitializer
  %1240 = select <4 x i1> %1239, <4 x i32> %1238, <4 x i32> %1237
  %1241 = add nuw <4 x i32> %1240, <i32 32, i32 32, i32 32, i32 32>
  %1242 = lshr <4 x i32> %1241, <i32 6, i32 6, i32 6, i32 6>
  %1243 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1232, <4 x i32> %1242) #5
  %1244 = lshr <8 x i16> %1243, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1245 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1216, <8 x i16> %1244) #5
  %1246 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1245, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1247 = icmp slt <16 x i8> %1246, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1248 = select <16 x i1> %1247, <16 x i8> %1246, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1249 = bitcast i8* %1190 to <16 x i8>*
  store <16 x i8> %1248, <16 x i8>* %1249, align 16
  %1250 = getelementptr inbounds i16, i16* %10, i64 320
  %1251 = getelementptr inbounds i16, i16* %11, i64 320
  %1252 = getelementptr inbounds i8, i8* %1004, i64 64
  %1253 = bitcast i16* %1250 to <8 x i16>*
  %1254 = load <8 x i16>, <8 x i16>* %1253, align 16
  %1255 = bitcast i16* %1251 to <8 x i16>*
  %1256 = load <8 x i16>, <8 x i16>* %1255, align 16
  %1257 = shufflevector <8 x i16> %1254, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1258 = zext <4 x i16> %1257 to <4 x i32>
  %1259 = shufflevector <8 x i16> %1256, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1260 = zext <4 x i16> %1259 to <4 x i32>
  %1261 = sub nsw <4 x i32> %1258, %1260
  %1262 = sub nsw <4 x i32> zeroinitializer, %1261
  %1263 = icmp slt <4 x i32> %1261, zeroinitializer
  %1264 = select <4 x i1> %1263, <4 x i32> %1262, <4 x i32> %1261
  %1265 = add nuw nsw <4 x i32> %1264, <i32 32, i32 32, i32 32, i32 32>
  %1266 = lshr <4 x i32> %1265, <i32 6, i32 6, i32 6, i32 6>
  %1267 = shufflevector <8 x i16> %1254, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1268 = shufflevector <8 x i16> %1256, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1269 = bitcast <8 x i16> %1267 to <4 x i32>
  %1270 = bitcast <8 x i16> %1268 to <4 x i32>
  %1271 = sub <4 x i32> %1269, %1270
  %1272 = sub <4 x i32> zeroinitializer, %1271
  %1273 = icmp slt <4 x i32> %1271, zeroinitializer
  %1274 = select <4 x i1> %1273, <4 x i32> %1272, <4 x i32> %1271
  %1275 = add nuw <4 x i32> %1274, <i32 32, i32 32, i32 32, i32 32>
  %1276 = lshr <4 x i32> %1275, <i32 6, i32 6, i32 6, i32 6>
  %1277 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1266, <4 x i32> %1276) #5
  %1278 = lshr <8 x i16> %1277, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1279 = getelementptr inbounds i16, i16* %10, i64 328
  %1280 = bitcast i16* %1279 to <8 x i16>*
  %1281 = load <8 x i16>, <8 x i16>* %1280, align 16
  %1282 = getelementptr inbounds i16, i16* %11, i64 328
  %1283 = bitcast i16* %1282 to <8 x i16>*
  %1284 = load <8 x i16>, <8 x i16>* %1283, align 16
  %1285 = shufflevector <8 x i16> %1281, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1286 = zext <4 x i16> %1285 to <4 x i32>
  %1287 = shufflevector <8 x i16> %1284, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1288 = zext <4 x i16> %1287 to <4 x i32>
  %1289 = sub nsw <4 x i32> %1286, %1288
  %1290 = sub nsw <4 x i32> zeroinitializer, %1289
  %1291 = icmp slt <4 x i32> %1289, zeroinitializer
  %1292 = select <4 x i1> %1291, <4 x i32> %1290, <4 x i32> %1289
  %1293 = add nuw nsw <4 x i32> %1292, <i32 32, i32 32, i32 32, i32 32>
  %1294 = lshr <4 x i32> %1293, <i32 6, i32 6, i32 6, i32 6>
  %1295 = shufflevector <8 x i16> %1281, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1296 = shufflevector <8 x i16> %1284, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1297 = bitcast <8 x i16> %1295 to <4 x i32>
  %1298 = bitcast <8 x i16> %1296 to <4 x i32>
  %1299 = sub <4 x i32> %1297, %1298
  %1300 = sub <4 x i32> zeroinitializer, %1299
  %1301 = icmp slt <4 x i32> %1299, zeroinitializer
  %1302 = select <4 x i1> %1301, <4 x i32> %1300, <4 x i32> %1299
  %1303 = add nuw <4 x i32> %1302, <i32 32, i32 32, i32 32, i32 32>
  %1304 = lshr <4 x i32> %1303, <i32 6, i32 6, i32 6, i32 6>
  %1305 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1294, <4 x i32> %1304) #5
  %1306 = lshr <8 x i16> %1305, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1307 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1278, <8 x i16> %1306) #5
  %1308 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1307, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1309 = icmp slt <16 x i8> %1308, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1310 = select <16 x i1> %1309, <16 x i8> %1308, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1311 = bitcast i8* %1252 to <16 x i8>*
  store <16 x i8> %1310, <16 x i8>* %1311, align 16
  %1312 = getelementptr inbounds i16, i16* %10, i64 336
  %1313 = getelementptr inbounds i16, i16* %11, i64 336
  %1314 = getelementptr inbounds i8, i8* %1252, i64 16
  %1315 = bitcast i16* %1312 to <8 x i16>*
  %1316 = load <8 x i16>, <8 x i16>* %1315, align 16
  %1317 = bitcast i16* %1313 to <8 x i16>*
  %1318 = load <8 x i16>, <8 x i16>* %1317, align 16
  %1319 = shufflevector <8 x i16> %1316, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1320 = zext <4 x i16> %1319 to <4 x i32>
  %1321 = shufflevector <8 x i16> %1318, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1322 = zext <4 x i16> %1321 to <4 x i32>
  %1323 = sub nsw <4 x i32> %1320, %1322
  %1324 = sub nsw <4 x i32> zeroinitializer, %1323
  %1325 = icmp slt <4 x i32> %1323, zeroinitializer
  %1326 = select <4 x i1> %1325, <4 x i32> %1324, <4 x i32> %1323
  %1327 = add nuw nsw <4 x i32> %1326, <i32 32, i32 32, i32 32, i32 32>
  %1328 = lshr <4 x i32> %1327, <i32 6, i32 6, i32 6, i32 6>
  %1329 = shufflevector <8 x i16> %1316, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1330 = shufflevector <8 x i16> %1318, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1331 = bitcast <8 x i16> %1329 to <4 x i32>
  %1332 = bitcast <8 x i16> %1330 to <4 x i32>
  %1333 = sub <4 x i32> %1331, %1332
  %1334 = sub <4 x i32> zeroinitializer, %1333
  %1335 = icmp slt <4 x i32> %1333, zeroinitializer
  %1336 = select <4 x i1> %1335, <4 x i32> %1334, <4 x i32> %1333
  %1337 = add nuw <4 x i32> %1336, <i32 32, i32 32, i32 32, i32 32>
  %1338 = lshr <4 x i32> %1337, <i32 6, i32 6, i32 6, i32 6>
  %1339 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1328, <4 x i32> %1338) #5
  %1340 = lshr <8 x i16> %1339, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1341 = getelementptr inbounds i16, i16* %10, i64 344
  %1342 = bitcast i16* %1341 to <8 x i16>*
  %1343 = load <8 x i16>, <8 x i16>* %1342, align 16
  %1344 = getelementptr inbounds i16, i16* %11, i64 344
  %1345 = bitcast i16* %1344 to <8 x i16>*
  %1346 = load <8 x i16>, <8 x i16>* %1345, align 16
  %1347 = shufflevector <8 x i16> %1343, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1348 = zext <4 x i16> %1347 to <4 x i32>
  %1349 = shufflevector <8 x i16> %1346, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1350 = zext <4 x i16> %1349 to <4 x i32>
  %1351 = sub nsw <4 x i32> %1348, %1350
  %1352 = sub nsw <4 x i32> zeroinitializer, %1351
  %1353 = icmp slt <4 x i32> %1351, zeroinitializer
  %1354 = select <4 x i1> %1353, <4 x i32> %1352, <4 x i32> %1351
  %1355 = add nuw nsw <4 x i32> %1354, <i32 32, i32 32, i32 32, i32 32>
  %1356 = lshr <4 x i32> %1355, <i32 6, i32 6, i32 6, i32 6>
  %1357 = shufflevector <8 x i16> %1343, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1358 = shufflevector <8 x i16> %1346, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1359 = bitcast <8 x i16> %1357 to <4 x i32>
  %1360 = bitcast <8 x i16> %1358 to <4 x i32>
  %1361 = sub <4 x i32> %1359, %1360
  %1362 = sub <4 x i32> zeroinitializer, %1361
  %1363 = icmp slt <4 x i32> %1361, zeroinitializer
  %1364 = select <4 x i1> %1363, <4 x i32> %1362, <4 x i32> %1361
  %1365 = add nuw <4 x i32> %1364, <i32 32, i32 32, i32 32, i32 32>
  %1366 = lshr <4 x i32> %1365, <i32 6, i32 6, i32 6, i32 6>
  %1367 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1356, <4 x i32> %1366) #5
  %1368 = lshr <8 x i16> %1367, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1369 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1340, <8 x i16> %1368) #5
  %1370 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1369, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1371 = icmp slt <16 x i8> %1370, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1372 = select <16 x i1> %1371, <16 x i8> %1370, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1373 = bitcast i8* %1314 to <16 x i8>*
  store <16 x i8> %1372, <16 x i8>* %1373, align 16
  %1374 = getelementptr inbounds i16, i16* %10, i64 352
  %1375 = getelementptr inbounds i16, i16* %11, i64 352
  %1376 = getelementptr inbounds i8, i8* %1252, i64 32
  %1377 = bitcast i16* %1374 to <8 x i16>*
  %1378 = load <8 x i16>, <8 x i16>* %1377, align 16
  %1379 = bitcast i16* %1375 to <8 x i16>*
  %1380 = load <8 x i16>, <8 x i16>* %1379, align 16
  %1381 = shufflevector <8 x i16> %1378, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1382 = zext <4 x i16> %1381 to <4 x i32>
  %1383 = shufflevector <8 x i16> %1380, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1384 = zext <4 x i16> %1383 to <4 x i32>
  %1385 = sub nsw <4 x i32> %1382, %1384
  %1386 = sub nsw <4 x i32> zeroinitializer, %1385
  %1387 = icmp slt <4 x i32> %1385, zeroinitializer
  %1388 = select <4 x i1> %1387, <4 x i32> %1386, <4 x i32> %1385
  %1389 = add nuw nsw <4 x i32> %1388, <i32 32, i32 32, i32 32, i32 32>
  %1390 = lshr <4 x i32> %1389, <i32 6, i32 6, i32 6, i32 6>
  %1391 = shufflevector <8 x i16> %1378, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1392 = shufflevector <8 x i16> %1380, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1393 = bitcast <8 x i16> %1391 to <4 x i32>
  %1394 = bitcast <8 x i16> %1392 to <4 x i32>
  %1395 = sub <4 x i32> %1393, %1394
  %1396 = sub <4 x i32> zeroinitializer, %1395
  %1397 = icmp slt <4 x i32> %1395, zeroinitializer
  %1398 = select <4 x i1> %1397, <4 x i32> %1396, <4 x i32> %1395
  %1399 = add nuw <4 x i32> %1398, <i32 32, i32 32, i32 32, i32 32>
  %1400 = lshr <4 x i32> %1399, <i32 6, i32 6, i32 6, i32 6>
  %1401 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1390, <4 x i32> %1400) #5
  %1402 = lshr <8 x i16> %1401, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1403 = getelementptr inbounds i16, i16* %10, i64 360
  %1404 = bitcast i16* %1403 to <8 x i16>*
  %1405 = load <8 x i16>, <8 x i16>* %1404, align 16
  %1406 = getelementptr inbounds i16, i16* %11, i64 360
  %1407 = bitcast i16* %1406 to <8 x i16>*
  %1408 = load <8 x i16>, <8 x i16>* %1407, align 16
  %1409 = shufflevector <8 x i16> %1405, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1410 = zext <4 x i16> %1409 to <4 x i32>
  %1411 = shufflevector <8 x i16> %1408, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1412 = zext <4 x i16> %1411 to <4 x i32>
  %1413 = sub nsw <4 x i32> %1410, %1412
  %1414 = sub nsw <4 x i32> zeroinitializer, %1413
  %1415 = icmp slt <4 x i32> %1413, zeroinitializer
  %1416 = select <4 x i1> %1415, <4 x i32> %1414, <4 x i32> %1413
  %1417 = add nuw nsw <4 x i32> %1416, <i32 32, i32 32, i32 32, i32 32>
  %1418 = lshr <4 x i32> %1417, <i32 6, i32 6, i32 6, i32 6>
  %1419 = shufflevector <8 x i16> %1405, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1420 = shufflevector <8 x i16> %1408, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1421 = bitcast <8 x i16> %1419 to <4 x i32>
  %1422 = bitcast <8 x i16> %1420 to <4 x i32>
  %1423 = sub <4 x i32> %1421, %1422
  %1424 = sub <4 x i32> zeroinitializer, %1423
  %1425 = icmp slt <4 x i32> %1423, zeroinitializer
  %1426 = select <4 x i1> %1425, <4 x i32> %1424, <4 x i32> %1423
  %1427 = add nuw <4 x i32> %1426, <i32 32, i32 32, i32 32, i32 32>
  %1428 = lshr <4 x i32> %1427, <i32 6, i32 6, i32 6, i32 6>
  %1429 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1418, <4 x i32> %1428) #5
  %1430 = lshr <8 x i16> %1429, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1431 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1402, <8 x i16> %1430) #5
  %1432 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1431, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1433 = icmp slt <16 x i8> %1432, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1434 = select <16 x i1> %1433, <16 x i8> %1432, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1435 = bitcast i8* %1376 to <16 x i8>*
  store <16 x i8> %1434, <16 x i8>* %1435, align 16
  %1436 = getelementptr inbounds i16, i16* %10, i64 368
  %1437 = getelementptr inbounds i16, i16* %11, i64 368
  %1438 = getelementptr inbounds i8, i8* %1252, i64 48
  %1439 = bitcast i16* %1436 to <8 x i16>*
  %1440 = load <8 x i16>, <8 x i16>* %1439, align 16
  %1441 = bitcast i16* %1437 to <8 x i16>*
  %1442 = load <8 x i16>, <8 x i16>* %1441, align 16
  %1443 = shufflevector <8 x i16> %1440, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1444 = zext <4 x i16> %1443 to <4 x i32>
  %1445 = shufflevector <8 x i16> %1442, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1446 = zext <4 x i16> %1445 to <4 x i32>
  %1447 = sub nsw <4 x i32> %1444, %1446
  %1448 = sub nsw <4 x i32> zeroinitializer, %1447
  %1449 = icmp slt <4 x i32> %1447, zeroinitializer
  %1450 = select <4 x i1> %1449, <4 x i32> %1448, <4 x i32> %1447
  %1451 = add nuw nsw <4 x i32> %1450, <i32 32, i32 32, i32 32, i32 32>
  %1452 = lshr <4 x i32> %1451, <i32 6, i32 6, i32 6, i32 6>
  %1453 = shufflevector <8 x i16> %1440, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1454 = shufflevector <8 x i16> %1442, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1455 = bitcast <8 x i16> %1453 to <4 x i32>
  %1456 = bitcast <8 x i16> %1454 to <4 x i32>
  %1457 = sub <4 x i32> %1455, %1456
  %1458 = sub <4 x i32> zeroinitializer, %1457
  %1459 = icmp slt <4 x i32> %1457, zeroinitializer
  %1460 = select <4 x i1> %1459, <4 x i32> %1458, <4 x i32> %1457
  %1461 = add nuw <4 x i32> %1460, <i32 32, i32 32, i32 32, i32 32>
  %1462 = lshr <4 x i32> %1461, <i32 6, i32 6, i32 6, i32 6>
  %1463 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1452, <4 x i32> %1462) #5
  %1464 = lshr <8 x i16> %1463, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1465 = getelementptr inbounds i16, i16* %10, i64 376
  %1466 = bitcast i16* %1465 to <8 x i16>*
  %1467 = load <8 x i16>, <8 x i16>* %1466, align 16
  %1468 = getelementptr inbounds i16, i16* %11, i64 376
  %1469 = bitcast i16* %1468 to <8 x i16>*
  %1470 = load <8 x i16>, <8 x i16>* %1469, align 16
  %1471 = shufflevector <8 x i16> %1467, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1472 = zext <4 x i16> %1471 to <4 x i32>
  %1473 = shufflevector <8 x i16> %1470, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1474 = zext <4 x i16> %1473 to <4 x i32>
  %1475 = sub nsw <4 x i32> %1472, %1474
  %1476 = sub nsw <4 x i32> zeroinitializer, %1475
  %1477 = icmp slt <4 x i32> %1475, zeroinitializer
  %1478 = select <4 x i1> %1477, <4 x i32> %1476, <4 x i32> %1475
  %1479 = add nuw nsw <4 x i32> %1478, <i32 32, i32 32, i32 32, i32 32>
  %1480 = lshr <4 x i32> %1479, <i32 6, i32 6, i32 6, i32 6>
  %1481 = shufflevector <8 x i16> %1467, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1482 = shufflevector <8 x i16> %1470, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1483 = bitcast <8 x i16> %1481 to <4 x i32>
  %1484 = bitcast <8 x i16> %1482 to <4 x i32>
  %1485 = sub <4 x i32> %1483, %1484
  %1486 = sub <4 x i32> zeroinitializer, %1485
  %1487 = icmp slt <4 x i32> %1485, zeroinitializer
  %1488 = select <4 x i1> %1487, <4 x i32> %1486, <4 x i32> %1485
  %1489 = add nuw <4 x i32> %1488, <i32 32, i32 32, i32 32, i32 32>
  %1490 = lshr <4 x i32> %1489, <i32 6, i32 6, i32 6, i32 6>
  %1491 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1480, <4 x i32> %1490) #5
  %1492 = lshr <8 x i16> %1491, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1493 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1464, <8 x i16> %1492) #5
  %1494 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1493, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1495 = icmp slt <16 x i8> %1494, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1496 = select <16 x i1> %1495, <16 x i8> %1494, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1497 = bitcast i8* %1438 to <16 x i8>*
  store <16 x i8> %1496, <16 x i8>* %1497, align 16
  %1498 = getelementptr inbounds i16, i16* %10, i64 384
  %1499 = getelementptr inbounds i16, i16* %11, i64 384
  %1500 = getelementptr inbounds i8, i8* %1252, i64 %7
  %1501 = add nsw i32 %12, -1
  %1502 = icmp eq i32 %1501, 0
  br i1 %1502, label %1503, label %8

1503:                                             ; preds = %8
  %1504 = bitcast i16* %1498 to <8 x i16>*
  %1505 = load <8 x i16>, <8 x i16>* %1504, align 16
  %1506 = bitcast i16* %1499 to <8 x i16>*
  %1507 = load <8 x i16>, <8 x i16>* %1506, align 16
  %1508 = shufflevector <8 x i16> %1505, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1509 = zext <4 x i16> %1508 to <4 x i32>
  %1510 = shufflevector <8 x i16> %1507, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1511 = zext <4 x i16> %1510 to <4 x i32>
  %1512 = sub nsw <4 x i32> %1509, %1511
  %1513 = sub nsw <4 x i32> zeroinitializer, %1512
  %1514 = icmp slt <4 x i32> %1512, zeroinitializer
  %1515 = select <4 x i1> %1514, <4 x i32> %1513, <4 x i32> %1512
  %1516 = add nuw nsw <4 x i32> %1515, <i32 32, i32 32, i32 32, i32 32>
  %1517 = lshr <4 x i32> %1516, <i32 6, i32 6, i32 6, i32 6>
  %1518 = shufflevector <8 x i16> %1505, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1519 = shufflevector <8 x i16> %1507, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1520 = bitcast <8 x i16> %1518 to <4 x i32>
  %1521 = bitcast <8 x i16> %1519 to <4 x i32>
  %1522 = sub <4 x i32> %1520, %1521
  %1523 = sub <4 x i32> zeroinitializer, %1522
  %1524 = icmp slt <4 x i32> %1522, zeroinitializer
  %1525 = select <4 x i1> %1524, <4 x i32> %1523, <4 x i32> %1522
  %1526 = add nuw <4 x i32> %1525, <i32 32, i32 32, i32 32, i32 32>
  %1527 = lshr <4 x i32> %1526, <i32 6, i32 6, i32 6, i32 6>
  %1528 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1517, <4 x i32> %1527) #5
  %1529 = lshr <8 x i16> %1528, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1530 = getelementptr inbounds i16, i16* %10, i64 392
  %1531 = bitcast i16* %1530 to <8 x i16>*
  %1532 = load <8 x i16>, <8 x i16>* %1531, align 16
  %1533 = getelementptr inbounds i16, i16* %11, i64 392
  %1534 = bitcast i16* %1533 to <8 x i16>*
  %1535 = load <8 x i16>, <8 x i16>* %1534, align 16
  %1536 = shufflevector <8 x i16> %1532, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1537 = zext <4 x i16> %1536 to <4 x i32>
  %1538 = shufflevector <8 x i16> %1535, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1539 = zext <4 x i16> %1538 to <4 x i32>
  %1540 = sub nsw <4 x i32> %1537, %1539
  %1541 = sub nsw <4 x i32> zeroinitializer, %1540
  %1542 = icmp slt <4 x i32> %1540, zeroinitializer
  %1543 = select <4 x i1> %1542, <4 x i32> %1541, <4 x i32> %1540
  %1544 = add nuw nsw <4 x i32> %1543, <i32 32, i32 32, i32 32, i32 32>
  %1545 = lshr <4 x i32> %1544, <i32 6, i32 6, i32 6, i32 6>
  %1546 = shufflevector <8 x i16> %1532, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1547 = shufflevector <8 x i16> %1535, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1548 = bitcast <8 x i16> %1546 to <4 x i32>
  %1549 = bitcast <8 x i16> %1547 to <4 x i32>
  %1550 = sub <4 x i32> %1548, %1549
  %1551 = sub <4 x i32> zeroinitializer, %1550
  %1552 = icmp slt <4 x i32> %1550, zeroinitializer
  %1553 = select <4 x i1> %1552, <4 x i32> %1551, <4 x i32> %1550
  %1554 = add nuw <4 x i32> %1553, <i32 32, i32 32, i32 32, i32 32>
  %1555 = lshr <4 x i32> %1554, <i32 6, i32 6, i32 6, i32 6>
  %1556 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1545, <4 x i32> %1555) #5
  %1557 = lshr <8 x i16> %1556, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1558 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1529, <8 x i16> %1557) #5
  %1559 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1558, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1560 = icmp slt <16 x i8> %1559, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1561 = select <16 x i1> %1560, <16 x i8> %1559, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1562 = bitcast i8* %1500 to <16 x i8>*
  store <16 x i8> %1561, <16 x i8>* %1562, align 16
  %1563 = getelementptr inbounds i16, i16* %10, i64 400
  %1564 = getelementptr inbounds i16, i16* %11, i64 400
  %1565 = getelementptr inbounds i8, i8* %1500, i64 16
  %1566 = bitcast i16* %1563 to <8 x i16>*
  %1567 = load <8 x i16>, <8 x i16>* %1566, align 16
  %1568 = bitcast i16* %1564 to <8 x i16>*
  %1569 = load <8 x i16>, <8 x i16>* %1568, align 16
  %1570 = shufflevector <8 x i16> %1567, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1571 = zext <4 x i16> %1570 to <4 x i32>
  %1572 = shufflevector <8 x i16> %1569, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1573 = zext <4 x i16> %1572 to <4 x i32>
  %1574 = sub nsw <4 x i32> %1571, %1573
  %1575 = sub nsw <4 x i32> zeroinitializer, %1574
  %1576 = icmp slt <4 x i32> %1574, zeroinitializer
  %1577 = select <4 x i1> %1576, <4 x i32> %1575, <4 x i32> %1574
  %1578 = add nuw nsw <4 x i32> %1577, <i32 32, i32 32, i32 32, i32 32>
  %1579 = lshr <4 x i32> %1578, <i32 6, i32 6, i32 6, i32 6>
  %1580 = shufflevector <8 x i16> %1567, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1581 = shufflevector <8 x i16> %1569, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1582 = bitcast <8 x i16> %1580 to <4 x i32>
  %1583 = bitcast <8 x i16> %1581 to <4 x i32>
  %1584 = sub <4 x i32> %1582, %1583
  %1585 = sub <4 x i32> zeroinitializer, %1584
  %1586 = icmp slt <4 x i32> %1584, zeroinitializer
  %1587 = select <4 x i1> %1586, <4 x i32> %1585, <4 x i32> %1584
  %1588 = add nuw <4 x i32> %1587, <i32 32, i32 32, i32 32, i32 32>
  %1589 = lshr <4 x i32> %1588, <i32 6, i32 6, i32 6, i32 6>
  %1590 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1579, <4 x i32> %1589) #5
  %1591 = lshr <8 x i16> %1590, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1592 = getelementptr inbounds i16, i16* %10, i64 408
  %1593 = bitcast i16* %1592 to <8 x i16>*
  %1594 = load <8 x i16>, <8 x i16>* %1593, align 16
  %1595 = getelementptr inbounds i16, i16* %11, i64 408
  %1596 = bitcast i16* %1595 to <8 x i16>*
  %1597 = load <8 x i16>, <8 x i16>* %1596, align 16
  %1598 = shufflevector <8 x i16> %1594, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1599 = zext <4 x i16> %1598 to <4 x i32>
  %1600 = shufflevector <8 x i16> %1597, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1601 = zext <4 x i16> %1600 to <4 x i32>
  %1602 = sub nsw <4 x i32> %1599, %1601
  %1603 = sub nsw <4 x i32> zeroinitializer, %1602
  %1604 = icmp slt <4 x i32> %1602, zeroinitializer
  %1605 = select <4 x i1> %1604, <4 x i32> %1603, <4 x i32> %1602
  %1606 = add nuw nsw <4 x i32> %1605, <i32 32, i32 32, i32 32, i32 32>
  %1607 = lshr <4 x i32> %1606, <i32 6, i32 6, i32 6, i32 6>
  %1608 = shufflevector <8 x i16> %1594, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1609 = shufflevector <8 x i16> %1597, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1610 = bitcast <8 x i16> %1608 to <4 x i32>
  %1611 = bitcast <8 x i16> %1609 to <4 x i32>
  %1612 = sub <4 x i32> %1610, %1611
  %1613 = sub <4 x i32> zeroinitializer, %1612
  %1614 = icmp slt <4 x i32> %1612, zeroinitializer
  %1615 = select <4 x i1> %1614, <4 x i32> %1613, <4 x i32> %1612
  %1616 = add nuw <4 x i32> %1615, <i32 32, i32 32, i32 32, i32 32>
  %1617 = lshr <4 x i32> %1616, <i32 6, i32 6, i32 6, i32 6>
  %1618 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1607, <4 x i32> %1617) #5
  %1619 = lshr <8 x i16> %1618, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1620 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1591, <8 x i16> %1619) #5
  %1621 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1620, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1622 = icmp slt <16 x i8> %1621, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1623 = select <16 x i1> %1622, <16 x i8> %1621, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1624 = bitcast i8* %1565 to <16 x i8>*
  store <16 x i8> %1623, <16 x i8>* %1624, align 16
  %1625 = getelementptr inbounds i16, i16* %10, i64 416
  %1626 = getelementptr inbounds i16, i16* %11, i64 416
  %1627 = getelementptr inbounds i8, i8* %1500, i64 32
  %1628 = bitcast i16* %1625 to <8 x i16>*
  %1629 = load <8 x i16>, <8 x i16>* %1628, align 16
  %1630 = bitcast i16* %1626 to <8 x i16>*
  %1631 = load <8 x i16>, <8 x i16>* %1630, align 16
  %1632 = shufflevector <8 x i16> %1629, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1633 = zext <4 x i16> %1632 to <4 x i32>
  %1634 = shufflevector <8 x i16> %1631, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1635 = zext <4 x i16> %1634 to <4 x i32>
  %1636 = sub nsw <4 x i32> %1633, %1635
  %1637 = sub nsw <4 x i32> zeroinitializer, %1636
  %1638 = icmp slt <4 x i32> %1636, zeroinitializer
  %1639 = select <4 x i1> %1638, <4 x i32> %1637, <4 x i32> %1636
  %1640 = add nuw nsw <4 x i32> %1639, <i32 32, i32 32, i32 32, i32 32>
  %1641 = lshr <4 x i32> %1640, <i32 6, i32 6, i32 6, i32 6>
  %1642 = shufflevector <8 x i16> %1629, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1643 = shufflevector <8 x i16> %1631, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1644 = bitcast <8 x i16> %1642 to <4 x i32>
  %1645 = bitcast <8 x i16> %1643 to <4 x i32>
  %1646 = sub <4 x i32> %1644, %1645
  %1647 = sub <4 x i32> zeroinitializer, %1646
  %1648 = icmp slt <4 x i32> %1646, zeroinitializer
  %1649 = select <4 x i1> %1648, <4 x i32> %1647, <4 x i32> %1646
  %1650 = add nuw <4 x i32> %1649, <i32 32, i32 32, i32 32, i32 32>
  %1651 = lshr <4 x i32> %1650, <i32 6, i32 6, i32 6, i32 6>
  %1652 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1641, <4 x i32> %1651) #5
  %1653 = lshr <8 x i16> %1652, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1654 = getelementptr inbounds i16, i16* %10, i64 424
  %1655 = bitcast i16* %1654 to <8 x i16>*
  %1656 = load <8 x i16>, <8 x i16>* %1655, align 16
  %1657 = getelementptr inbounds i16, i16* %11, i64 424
  %1658 = bitcast i16* %1657 to <8 x i16>*
  %1659 = load <8 x i16>, <8 x i16>* %1658, align 16
  %1660 = shufflevector <8 x i16> %1656, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1661 = zext <4 x i16> %1660 to <4 x i32>
  %1662 = shufflevector <8 x i16> %1659, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1663 = zext <4 x i16> %1662 to <4 x i32>
  %1664 = sub nsw <4 x i32> %1661, %1663
  %1665 = sub nsw <4 x i32> zeroinitializer, %1664
  %1666 = icmp slt <4 x i32> %1664, zeroinitializer
  %1667 = select <4 x i1> %1666, <4 x i32> %1665, <4 x i32> %1664
  %1668 = add nuw nsw <4 x i32> %1667, <i32 32, i32 32, i32 32, i32 32>
  %1669 = lshr <4 x i32> %1668, <i32 6, i32 6, i32 6, i32 6>
  %1670 = shufflevector <8 x i16> %1656, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1671 = shufflevector <8 x i16> %1659, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1672 = bitcast <8 x i16> %1670 to <4 x i32>
  %1673 = bitcast <8 x i16> %1671 to <4 x i32>
  %1674 = sub <4 x i32> %1672, %1673
  %1675 = sub <4 x i32> zeroinitializer, %1674
  %1676 = icmp slt <4 x i32> %1674, zeroinitializer
  %1677 = select <4 x i1> %1676, <4 x i32> %1675, <4 x i32> %1674
  %1678 = add nuw <4 x i32> %1677, <i32 32, i32 32, i32 32, i32 32>
  %1679 = lshr <4 x i32> %1678, <i32 6, i32 6, i32 6, i32 6>
  %1680 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1669, <4 x i32> %1679) #5
  %1681 = lshr <8 x i16> %1680, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1682 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1653, <8 x i16> %1681) #5
  %1683 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1682, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1684 = icmp slt <16 x i8> %1683, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1685 = select <16 x i1> %1684, <16 x i8> %1683, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1686 = bitcast i8* %1627 to <16 x i8>*
  store <16 x i8> %1685, <16 x i8>* %1686, align 16
  %1687 = getelementptr inbounds i16, i16* %10, i64 432
  %1688 = getelementptr inbounds i16, i16* %11, i64 432
  %1689 = getelementptr inbounds i8, i8* %1500, i64 48
  %1690 = bitcast i16* %1687 to <8 x i16>*
  %1691 = load <8 x i16>, <8 x i16>* %1690, align 16
  %1692 = bitcast i16* %1688 to <8 x i16>*
  %1693 = load <8 x i16>, <8 x i16>* %1692, align 16
  %1694 = shufflevector <8 x i16> %1691, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1695 = zext <4 x i16> %1694 to <4 x i32>
  %1696 = shufflevector <8 x i16> %1693, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1697 = zext <4 x i16> %1696 to <4 x i32>
  %1698 = sub nsw <4 x i32> %1695, %1697
  %1699 = sub nsw <4 x i32> zeroinitializer, %1698
  %1700 = icmp slt <4 x i32> %1698, zeroinitializer
  %1701 = select <4 x i1> %1700, <4 x i32> %1699, <4 x i32> %1698
  %1702 = add nuw nsw <4 x i32> %1701, <i32 32, i32 32, i32 32, i32 32>
  %1703 = lshr <4 x i32> %1702, <i32 6, i32 6, i32 6, i32 6>
  %1704 = shufflevector <8 x i16> %1691, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1705 = shufflevector <8 x i16> %1693, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1706 = bitcast <8 x i16> %1704 to <4 x i32>
  %1707 = bitcast <8 x i16> %1705 to <4 x i32>
  %1708 = sub <4 x i32> %1706, %1707
  %1709 = sub <4 x i32> zeroinitializer, %1708
  %1710 = icmp slt <4 x i32> %1708, zeroinitializer
  %1711 = select <4 x i1> %1710, <4 x i32> %1709, <4 x i32> %1708
  %1712 = add nuw <4 x i32> %1711, <i32 32, i32 32, i32 32, i32 32>
  %1713 = lshr <4 x i32> %1712, <i32 6, i32 6, i32 6, i32 6>
  %1714 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1703, <4 x i32> %1713) #5
  %1715 = lshr <8 x i16> %1714, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1716 = getelementptr inbounds i16, i16* %10, i64 440
  %1717 = bitcast i16* %1716 to <8 x i16>*
  %1718 = load <8 x i16>, <8 x i16>* %1717, align 16
  %1719 = getelementptr inbounds i16, i16* %11, i64 440
  %1720 = bitcast i16* %1719 to <8 x i16>*
  %1721 = load <8 x i16>, <8 x i16>* %1720, align 16
  %1722 = shufflevector <8 x i16> %1718, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1723 = zext <4 x i16> %1722 to <4 x i32>
  %1724 = shufflevector <8 x i16> %1721, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1725 = zext <4 x i16> %1724 to <4 x i32>
  %1726 = sub nsw <4 x i32> %1723, %1725
  %1727 = sub nsw <4 x i32> zeroinitializer, %1726
  %1728 = icmp slt <4 x i32> %1726, zeroinitializer
  %1729 = select <4 x i1> %1728, <4 x i32> %1727, <4 x i32> %1726
  %1730 = add nuw nsw <4 x i32> %1729, <i32 32, i32 32, i32 32, i32 32>
  %1731 = lshr <4 x i32> %1730, <i32 6, i32 6, i32 6, i32 6>
  %1732 = shufflevector <8 x i16> %1718, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1733 = shufflevector <8 x i16> %1721, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1734 = bitcast <8 x i16> %1732 to <4 x i32>
  %1735 = bitcast <8 x i16> %1733 to <4 x i32>
  %1736 = sub <4 x i32> %1734, %1735
  %1737 = sub <4 x i32> zeroinitializer, %1736
  %1738 = icmp slt <4 x i32> %1736, zeroinitializer
  %1739 = select <4 x i1> %1738, <4 x i32> %1737, <4 x i32> %1736
  %1740 = add nuw <4 x i32> %1739, <i32 32, i32 32, i32 32, i32 32>
  %1741 = lshr <4 x i32> %1740, <i32 6, i32 6, i32 6, i32 6>
  %1742 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1731, <4 x i32> %1741) #5
  %1743 = lshr <8 x i16> %1742, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1744 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1715, <8 x i16> %1743) #5
  %1745 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1744, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1746 = icmp slt <16 x i8> %1745, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1747 = select <16 x i1> %1746, <16 x i8> %1745, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1748 = bitcast i8* %1689 to <16 x i8>*
  store <16 x i8> %1747, <16 x i8>* %1748, align 16
  %1749 = getelementptr inbounds i16, i16* %10, i64 448
  %1750 = getelementptr inbounds i16, i16* %11, i64 448
  %1751 = getelementptr inbounds i8, i8* %1500, i64 64
  %1752 = bitcast i16* %1749 to <8 x i16>*
  %1753 = load <8 x i16>, <8 x i16>* %1752, align 16
  %1754 = bitcast i16* %1750 to <8 x i16>*
  %1755 = load <8 x i16>, <8 x i16>* %1754, align 16
  %1756 = shufflevector <8 x i16> %1753, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1757 = zext <4 x i16> %1756 to <4 x i32>
  %1758 = shufflevector <8 x i16> %1755, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1759 = zext <4 x i16> %1758 to <4 x i32>
  %1760 = sub nsw <4 x i32> %1757, %1759
  %1761 = sub nsw <4 x i32> zeroinitializer, %1760
  %1762 = icmp slt <4 x i32> %1760, zeroinitializer
  %1763 = select <4 x i1> %1762, <4 x i32> %1761, <4 x i32> %1760
  %1764 = add nuw nsw <4 x i32> %1763, <i32 32, i32 32, i32 32, i32 32>
  %1765 = lshr <4 x i32> %1764, <i32 6, i32 6, i32 6, i32 6>
  %1766 = shufflevector <8 x i16> %1753, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1767 = shufflevector <8 x i16> %1755, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1768 = bitcast <8 x i16> %1766 to <4 x i32>
  %1769 = bitcast <8 x i16> %1767 to <4 x i32>
  %1770 = sub <4 x i32> %1768, %1769
  %1771 = sub <4 x i32> zeroinitializer, %1770
  %1772 = icmp slt <4 x i32> %1770, zeroinitializer
  %1773 = select <4 x i1> %1772, <4 x i32> %1771, <4 x i32> %1770
  %1774 = add nuw <4 x i32> %1773, <i32 32, i32 32, i32 32, i32 32>
  %1775 = lshr <4 x i32> %1774, <i32 6, i32 6, i32 6, i32 6>
  %1776 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1765, <4 x i32> %1775) #5
  %1777 = lshr <8 x i16> %1776, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1778 = getelementptr inbounds i16, i16* %10, i64 456
  %1779 = bitcast i16* %1778 to <8 x i16>*
  %1780 = load <8 x i16>, <8 x i16>* %1779, align 16
  %1781 = getelementptr inbounds i16, i16* %11, i64 456
  %1782 = bitcast i16* %1781 to <8 x i16>*
  %1783 = load <8 x i16>, <8 x i16>* %1782, align 16
  %1784 = shufflevector <8 x i16> %1780, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1785 = zext <4 x i16> %1784 to <4 x i32>
  %1786 = shufflevector <8 x i16> %1783, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1787 = zext <4 x i16> %1786 to <4 x i32>
  %1788 = sub nsw <4 x i32> %1785, %1787
  %1789 = sub nsw <4 x i32> zeroinitializer, %1788
  %1790 = icmp slt <4 x i32> %1788, zeroinitializer
  %1791 = select <4 x i1> %1790, <4 x i32> %1789, <4 x i32> %1788
  %1792 = add nuw nsw <4 x i32> %1791, <i32 32, i32 32, i32 32, i32 32>
  %1793 = lshr <4 x i32> %1792, <i32 6, i32 6, i32 6, i32 6>
  %1794 = shufflevector <8 x i16> %1780, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1795 = shufflevector <8 x i16> %1783, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1796 = bitcast <8 x i16> %1794 to <4 x i32>
  %1797 = bitcast <8 x i16> %1795 to <4 x i32>
  %1798 = sub <4 x i32> %1796, %1797
  %1799 = sub <4 x i32> zeroinitializer, %1798
  %1800 = icmp slt <4 x i32> %1798, zeroinitializer
  %1801 = select <4 x i1> %1800, <4 x i32> %1799, <4 x i32> %1798
  %1802 = add nuw <4 x i32> %1801, <i32 32, i32 32, i32 32, i32 32>
  %1803 = lshr <4 x i32> %1802, <i32 6, i32 6, i32 6, i32 6>
  %1804 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1793, <4 x i32> %1803) #5
  %1805 = lshr <8 x i16> %1804, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1806 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1777, <8 x i16> %1805) #5
  %1807 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1806, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1808 = icmp slt <16 x i8> %1807, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1809 = select <16 x i1> %1808, <16 x i8> %1807, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1810 = bitcast i8* %1751 to <16 x i8>*
  store <16 x i8> %1809, <16 x i8>* %1810, align 16
  %1811 = getelementptr inbounds i16, i16* %10, i64 464
  %1812 = getelementptr inbounds i16, i16* %11, i64 464
  %1813 = getelementptr inbounds i8, i8* %1751, i64 16
  %1814 = bitcast i16* %1811 to <8 x i16>*
  %1815 = load <8 x i16>, <8 x i16>* %1814, align 16
  %1816 = bitcast i16* %1812 to <8 x i16>*
  %1817 = load <8 x i16>, <8 x i16>* %1816, align 16
  %1818 = shufflevector <8 x i16> %1815, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1819 = zext <4 x i16> %1818 to <4 x i32>
  %1820 = shufflevector <8 x i16> %1817, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1821 = zext <4 x i16> %1820 to <4 x i32>
  %1822 = sub nsw <4 x i32> %1819, %1821
  %1823 = sub nsw <4 x i32> zeroinitializer, %1822
  %1824 = icmp slt <4 x i32> %1822, zeroinitializer
  %1825 = select <4 x i1> %1824, <4 x i32> %1823, <4 x i32> %1822
  %1826 = add nuw nsw <4 x i32> %1825, <i32 32, i32 32, i32 32, i32 32>
  %1827 = lshr <4 x i32> %1826, <i32 6, i32 6, i32 6, i32 6>
  %1828 = shufflevector <8 x i16> %1815, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1829 = shufflevector <8 x i16> %1817, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1830 = bitcast <8 x i16> %1828 to <4 x i32>
  %1831 = bitcast <8 x i16> %1829 to <4 x i32>
  %1832 = sub <4 x i32> %1830, %1831
  %1833 = sub <4 x i32> zeroinitializer, %1832
  %1834 = icmp slt <4 x i32> %1832, zeroinitializer
  %1835 = select <4 x i1> %1834, <4 x i32> %1833, <4 x i32> %1832
  %1836 = add nuw <4 x i32> %1835, <i32 32, i32 32, i32 32, i32 32>
  %1837 = lshr <4 x i32> %1836, <i32 6, i32 6, i32 6, i32 6>
  %1838 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1827, <4 x i32> %1837) #5
  %1839 = lshr <8 x i16> %1838, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1840 = getelementptr inbounds i16, i16* %10, i64 472
  %1841 = bitcast i16* %1840 to <8 x i16>*
  %1842 = load <8 x i16>, <8 x i16>* %1841, align 16
  %1843 = getelementptr inbounds i16, i16* %11, i64 472
  %1844 = bitcast i16* %1843 to <8 x i16>*
  %1845 = load <8 x i16>, <8 x i16>* %1844, align 16
  %1846 = shufflevector <8 x i16> %1842, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1847 = zext <4 x i16> %1846 to <4 x i32>
  %1848 = shufflevector <8 x i16> %1845, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1849 = zext <4 x i16> %1848 to <4 x i32>
  %1850 = sub nsw <4 x i32> %1847, %1849
  %1851 = sub nsw <4 x i32> zeroinitializer, %1850
  %1852 = icmp slt <4 x i32> %1850, zeroinitializer
  %1853 = select <4 x i1> %1852, <4 x i32> %1851, <4 x i32> %1850
  %1854 = add nuw nsw <4 x i32> %1853, <i32 32, i32 32, i32 32, i32 32>
  %1855 = lshr <4 x i32> %1854, <i32 6, i32 6, i32 6, i32 6>
  %1856 = shufflevector <8 x i16> %1842, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1857 = shufflevector <8 x i16> %1845, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1858 = bitcast <8 x i16> %1856 to <4 x i32>
  %1859 = bitcast <8 x i16> %1857 to <4 x i32>
  %1860 = sub <4 x i32> %1858, %1859
  %1861 = sub <4 x i32> zeroinitializer, %1860
  %1862 = icmp slt <4 x i32> %1860, zeroinitializer
  %1863 = select <4 x i1> %1862, <4 x i32> %1861, <4 x i32> %1860
  %1864 = add nuw <4 x i32> %1863, <i32 32, i32 32, i32 32, i32 32>
  %1865 = lshr <4 x i32> %1864, <i32 6, i32 6, i32 6, i32 6>
  %1866 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1855, <4 x i32> %1865) #5
  %1867 = lshr <8 x i16> %1866, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1868 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1839, <8 x i16> %1867) #5
  %1869 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1868, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1870 = icmp slt <16 x i8> %1869, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1871 = select <16 x i1> %1870, <16 x i8> %1869, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1872 = bitcast i8* %1813 to <16 x i8>*
  store <16 x i8> %1871, <16 x i8>* %1872, align 16
  %1873 = getelementptr inbounds i16, i16* %10, i64 480
  %1874 = getelementptr inbounds i16, i16* %11, i64 480
  %1875 = getelementptr inbounds i8, i8* %1751, i64 32
  %1876 = bitcast i16* %1873 to <8 x i16>*
  %1877 = load <8 x i16>, <8 x i16>* %1876, align 16
  %1878 = bitcast i16* %1874 to <8 x i16>*
  %1879 = load <8 x i16>, <8 x i16>* %1878, align 16
  %1880 = shufflevector <8 x i16> %1877, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1881 = zext <4 x i16> %1880 to <4 x i32>
  %1882 = shufflevector <8 x i16> %1879, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1883 = zext <4 x i16> %1882 to <4 x i32>
  %1884 = sub nsw <4 x i32> %1881, %1883
  %1885 = sub nsw <4 x i32> zeroinitializer, %1884
  %1886 = icmp slt <4 x i32> %1884, zeroinitializer
  %1887 = select <4 x i1> %1886, <4 x i32> %1885, <4 x i32> %1884
  %1888 = add nuw nsw <4 x i32> %1887, <i32 32, i32 32, i32 32, i32 32>
  %1889 = lshr <4 x i32> %1888, <i32 6, i32 6, i32 6, i32 6>
  %1890 = shufflevector <8 x i16> %1877, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1891 = shufflevector <8 x i16> %1879, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1892 = bitcast <8 x i16> %1890 to <4 x i32>
  %1893 = bitcast <8 x i16> %1891 to <4 x i32>
  %1894 = sub <4 x i32> %1892, %1893
  %1895 = sub <4 x i32> zeroinitializer, %1894
  %1896 = icmp slt <4 x i32> %1894, zeroinitializer
  %1897 = select <4 x i1> %1896, <4 x i32> %1895, <4 x i32> %1894
  %1898 = add nuw <4 x i32> %1897, <i32 32, i32 32, i32 32, i32 32>
  %1899 = lshr <4 x i32> %1898, <i32 6, i32 6, i32 6, i32 6>
  %1900 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1889, <4 x i32> %1899) #5
  %1901 = lshr <8 x i16> %1900, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1902 = getelementptr inbounds i16, i16* %10, i64 488
  %1903 = bitcast i16* %1902 to <8 x i16>*
  %1904 = load <8 x i16>, <8 x i16>* %1903, align 16
  %1905 = getelementptr inbounds i16, i16* %11, i64 488
  %1906 = bitcast i16* %1905 to <8 x i16>*
  %1907 = load <8 x i16>, <8 x i16>* %1906, align 16
  %1908 = shufflevector <8 x i16> %1904, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1909 = zext <4 x i16> %1908 to <4 x i32>
  %1910 = shufflevector <8 x i16> %1907, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1911 = zext <4 x i16> %1910 to <4 x i32>
  %1912 = sub nsw <4 x i32> %1909, %1911
  %1913 = sub nsw <4 x i32> zeroinitializer, %1912
  %1914 = icmp slt <4 x i32> %1912, zeroinitializer
  %1915 = select <4 x i1> %1914, <4 x i32> %1913, <4 x i32> %1912
  %1916 = add nuw nsw <4 x i32> %1915, <i32 32, i32 32, i32 32, i32 32>
  %1917 = lshr <4 x i32> %1916, <i32 6, i32 6, i32 6, i32 6>
  %1918 = shufflevector <8 x i16> %1904, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1919 = shufflevector <8 x i16> %1907, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1920 = bitcast <8 x i16> %1918 to <4 x i32>
  %1921 = bitcast <8 x i16> %1919 to <4 x i32>
  %1922 = sub <4 x i32> %1920, %1921
  %1923 = sub <4 x i32> zeroinitializer, %1922
  %1924 = icmp slt <4 x i32> %1922, zeroinitializer
  %1925 = select <4 x i1> %1924, <4 x i32> %1923, <4 x i32> %1922
  %1926 = add nuw <4 x i32> %1925, <i32 32, i32 32, i32 32, i32 32>
  %1927 = lshr <4 x i32> %1926, <i32 6, i32 6, i32 6, i32 6>
  %1928 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1917, <4 x i32> %1927) #5
  %1929 = lshr <8 x i16> %1928, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1930 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1901, <8 x i16> %1929) #5
  %1931 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1930, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1932 = icmp slt <16 x i8> %1931, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1933 = select <16 x i1> %1932, <16 x i8> %1931, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1934 = bitcast i8* %1875 to <16 x i8>*
  store <16 x i8> %1933, <16 x i8>* %1934, align 16
  %1935 = getelementptr inbounds i16, i16* %10, i64 496
  %1936 = getelementptr inbounds i16, i16* %11, i64 496
  %1937 = getelementptr inbounds i8, i8* %1751, i64 48
  %1938 = bitcast i16* %1935 to <8 x i16>*
  %1939 = load <8 x i16>, <8 x i16>* %1938, align 16
  %1940 = bitcast i16* %1936 to <8 x i16>*
  %1941 = load <8 x i16>, <8 x i16>* %1940, align 16
  %1942 = shufflevector <8 x i16> %1939, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1943 = zext <4 x i16> %1942 to <4 x i32>
  %1944 = shufflevector <8 x i16> %1941, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1945 = zext <4 x i16> %1944 to <4 x i32>
  %1946 = sub nsw <4 x i32> %1943, %1945
  %1947 = sub nsw <4 x i32> zeroinitializer, %1946
  %1948 = icmp slt <4 x i32> %1946, zeroinitializer
  %1949 = select <4 x i1> %1948, <4 x i32> %1947, <4 x i32> %1946
  %1950 = add nuw nsw <4 x i32> %1949, <i32 32, i32 32, i32 32, i32 32>
  %1951 = lshr <4 x i32> %1950, <i32 6, i32 6, i32 6, i32 6>
  %1952 = shufflevector <8 x i16> %1939, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1953 = shufflevector <8 x i16> %1941, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1954 = bitcast <8 x i16> %1952 to <4 x i32>
  %1955 = bitcast <8 x i16> %1953 to <4 x i32>
  %1956 = sub <4 x i32> %1954, %1955
  %1957 = sub <4 x i32> zeroinitializer, %1956
  %1958 = icmp slt <4 x i32> %1956, zeroinitializer
  %1959 = select <4 x i1> %1958, <4 x i32> %1957, <4 x i32> %1956
  %1960 = add nuw <4 x i32> %1959, <i32 32, i32 32, i32 32, i32 32>
  %1961 = lshr <4 x i32> %1960, <i32 6, i32 6, i32 6, i32 6>
  %1962 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1951, <4 x i32> %1961) #5
  %1963 = lshr <8 x i16> %1962, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1964 = getelementptr inbounds i16, i16* %10, i64 504
  %1965 = bitcast i16* %1964 to <8 x i16>*
  %1966 = load <8 x i16>, <8 x i16>* %1965, align 16
  %1967 = getelementptr inbounds i16, i16* %11, i64 504
  %1968 = bitcast i16* %1967 to <8 x i16>*
  %1969 = load <8 x i16>, <8 x i16>* %1968, align 16
  %1970 = shufflevector <8 x i16> %1966, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1971 = zext <4 x i16> %1970 to <4 x i32>
  %1972 = shufflevector <8 x i16> %1969, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1973 = zext <4 x i16> %1972 to <4 x i32>
  %1974 = sub nsw <4 x i32> %1971, %1973
  %1975 = sub nsw <4 x i32> zeroinitializer, %1974
  %1976 = icmp slt <4 x i32> %1974, zeroinitializer
  %1977 = select <4 x i1> %1976, <4 x i32> %1975, <4 x i32> %1974
  %1978 = add nuw nsw <4 x i32> %1977, <i32 32, i32 32, i32 32, i32 32>
  %1979 = lshr <4 x i32> %1978, <i32 6, i32 6, i32 6, i32 6>
  %1980 = shufflevector <8 x i16> %1966, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1981 = shufflevector <8 x i16> %1969, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1982 = bitcast <8 x i16> %1980 to <4 x i32>
  %1983 = bitcast <8 x i16> %1981 to <4 x i32>
  %1984 = sub <4 x i32> %1982, %1983
  %1985 = sub <4 x i32> zeroinitializer, %1984
  %1986 = icmp slt <4 x i32> %1984, zeroinitializer
  %1987 = select <4 x i1> %1986, <4 x i32> %1985, <4 x i32> %1984
  %1988 = add nuw <4 x i32> %1987, <i32 32, i32 32, i32 32, i32 32>
  %1989 = lshr <4 x i32> %1988, <i32 6, i32 6, i32 6, i32 6>
  %1990 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1979, <4 x i32> %1989) #5
  %1991 = lshr <8 x i16> %1990, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1992 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1963, <8 x i16> %1991) #5
  %1993 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1992, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1994 = icmp slt <16 x i8> %1993, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1995 = select <16 x i1> %1994, <16 x i8> %1993, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1996 = bitcast i8* %1937 to <16 x i8>*
  store <16 x i8> %1995, <16 x i8>* %1996, align 16
  %1997 = getelementptr inbounds i16, i16* %10, i64 512
  %1998 = getelementptr inbounds i16, i16* %11, i64 512
  %1999 = getelementptr inbounds i8, i8* %1751, i64 %7
  %2000 = bitcast i16* %1997 to <8 x i16>*
  %2001 = load <8 x i16>, <8 x i16>* %2000, align 16
  %2002 = bitcast i16* %1998 to <8 x i16>*
  %2003 = load <8 x i16>, <8 x i16>* %2002, align 16
  %2004 = shufflevector <8 x i16> %2001, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2005 = zext <4 x i16> %2004 to <4 x i32>
  %2006 = shufflevector <8 x i16> %2003, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2007 = zext <4 x i16> %2006 to <4 x i32>
  %2008 = sub nsw <4 x i32> %2005, %2007
  %2009 = sub nsw <4 x i32> zeroinitializer, %2008
  %2010 = icmp slt <4 x i32> %2008, zeroinitializer
  %2011 = select <4 x i1> %2010, <4 x i32> %2009, <4 x i32> %2008
  %2012 = add nuw nsw <4 x i32> %2011, <i32 32, i32 32, i32 32, i32 32>
  %2013 = lshr <4 x i32> %2012, <i32 6, i32 6, i32 6, i32 6>
  %2014 = shufflevector <8 x i16> %2001, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2015 = shufflevector <8 x i16> %2003, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2016 = bitcast <8 x i16> %2014 to <4 x i32>
  %2017 = bitcast <8 x i16> %2015 to <4 x i32>
  %2018 = sub <4 x i32> %2016, %2017
  %2019 = sub <4 x i32> zeroinitializer, %2018
  %2020 = icmp slt <4 x i32> %2018, zeroinitializer
  %2021 = select <4 x i1> %2020, <4 x i32> %2019, <4 x i32> %2018
  %2022 = add nuw <4 x i32> %2021, <i32 32, i32 32, i32 32, i32 32>
  %2023 = lshr <4 x i32> %2022, <i32 6, i32 6, i32 6, i32 6>
  %2024 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2013, <4 x i32> %2023) #5
  %2025 = lshr <8 x i16> %2024, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2026 = getelementptr inbounds i16, i16* %10, i64 520
  %2027 = bitcast i16* %2026 to <8 x i16>*
  %2028 = load <8 x i16>, <8 x i16>* %2027, align 16
  %2029 = getelementptr inbounds i16, i16* %11, i64 520
  %2030 = bitcast i16* %2029 to <8 x i16>*
  %2031 = load <8 x i16>, <8 x i16>* %2030, align 16
  %2032 = shufflevector <8 x i16> %2028, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2033 = zext <4 x i16> %2032 to <4 x i32>
  %2034 = shufflevector <8 x i16> %2031, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2035 = zext <4 x i16> %2034 to <4 x i32>
  %2036 = sub nsw <4 x i32> %2033, %2035
  %2037 = sub nsw <4 x i32> zeroinitializer, %2036
  %2038 = icmp slt <4 x i32> %2036, zeroinitializer
  %2039 = select <4 x i1> %2038, <4 x i32> %2037, <4 x i32> %2036
  %2040 = add nuw nsw <4 x i32> %2039, <i32 32, i32 32, i32 32, i32 32>
  %2041 = lshr <4 x i32> %2040, <i32 6, i32 6, i32 6, i32 6>
  %2042 = shufflevector <8 x i16> %2028, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2043 = shufflevector <8 x i16> %2031, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2044 = bitcast <8 x i16> %2042 to <4 x i32>
  %2045 = bitcast <8 x i16> %2043 to <4 x i32>
  %2046 = sub <4 x i32> %2044, %2045
  %2047 = sub <4 x i32> zeroinitializer, %2046
  %2048 = icmp slt <4 x i32> %2046, zeroinitializer
  %2049 = select <4 x i1> %2048, <4 x i32> %2047, <4 x i32> %2046
  %2050 = add nuw <4 x i32> %2049, <i32 32, i32 32, i32 32, i32 32>
  %2051 = lshr <4 x i32> %2050, <i32 6, i32 6, i32 6, i32 6>
  %2052 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2041, <4 x i32> %2051) #5
  %2053 = lshr <8 x i16> %2052, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2054 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2025, <8 x i16> %2053) #5
  %2055 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %2054, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %2056 = icmp slt <16 x i8> %2055, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2057 = select <16 x i1> %2056, <16 x i8> %2055, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2058 = bitcast i8* %1999 to <16 x i8>*
  store <16 x i8> %2057, <16 x i8>* %2058, align 16
  %2059 = getelementptr inbounds i16, i16* %10, i64 528
  %2060 = getelementptr inbounds i16, i16* %11, i64 528
  %2061 = getelementptr inbounds i8, i8* %1999, i64 16
  %2062 = bitcast i16* %2059 to <8 x i16>*
  %2063 = load <8 x i16>, <8 x i16>* %2062, align 16
  %2064 = bitcast i16* %2060 to <8 x i16>*
  %2065 = load <8 x i16>, <8 x i16>* %2064, align 16
  %2066 = shufflevector <8 x i16> %2063, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2067 = zext <4 x i16> %2066 to <4 x i32>
  %2068 = shufflevector <8 x i16> %2065, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2069 = zext <4 x i16> %2068 to <4 x i32>
  %2070 = sub nsw <4 x i32> %2067, %2069
  %2071 = sub nsw <4 x i32> zeroinitializer, %2070
  %2072 = icmp slt <4 x i32> %2070, zeroinitializer
  %2073 = select <4 x i1> %2072, <4 x i32> %2071, <4 x i32> %2070
  %2074 = add nuw nsw <4 x i32> %2073, <i32 32, i32 32, i32 32, i32 32>
  %2075 = lshr <4 x i32> %2074, <i32 6, i32 6, i32 6, i32 6>
  %2076 = shufflevector <8 x i16> %2063, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2077 = shufflevector <8 x i16> %2065, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2078 = bitcast <8 x i16> %2076 to <4 x i32>
  %2079 = bitcast <8 x i16> %2077 to <4 x i32>
  %2080 = sub <4 x i32> %2078, %2079
  %2081 = sub <4 x i32> zeroinitializer, %2080
  %2082 = icmp slt <4 x i32> %2080, zeroinitializer
  %2083 = select <4 x i1> %2082, <4 x i32> %2081, <4 x i32> %2080
  %2084 = add nuw <4 x i32> %2083, <i32 32, i32 32, i32 32, i32 32>
  %2085 = lshr <4 x i32> %2084, <i32 6, i32 6, i32 6, i32 6>
  %2086 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2075, <4 x i32> %2085) #5
  %2087 = lshr <8 x i16> %2086, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2088 = getelementptr inbounds i16, i16* %10, i64 536
  %2089 = bitcast i16* %2088 to <8 x i16>*
  %2090 = load <8 x i16>, <8 x i16>* %2089, align 16
  %2091 = getelementptr inbounds i16, i16* %11, i64 536
  %2092 = bitcast i16* %2091 to <8 x i16>*
  %2093 = load <8 x i16>, <8 x i16>* %2092, align 16
  %2094 = shufflevector <8 x i16> %2090, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2095 = zext <4 x i16> %2094 to <4 x i32>
  %2096 = shufflevector <8 x i16> %2093, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2097 = zext <4 x i16> %2096 to <4 x i32>
  %2098 = sub nsw <4 x i32> %2095, %2097
  %2099 = sub nsw <4 x i32> zeroinitializer, %2098
  %2100 = icmp slt <4 x i32> %2098, zeroinitializer
  %2101 = select <4 x i1> %2100, <4 x i32> %2099, <4 x i32> %2098
  %2102 = add nuw nsw <4 x i32> %2101, <i32 32, i32 32, i32 32, i32 32>
  %2103 = lshr <4 x i32> %2102, <i32 6, i32 6, i32 6, i32 6>
  %2104 = shufflevector <8 x i16> %2090, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2105 = shufflevector <8 x i16> %2093, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2106 = bitcast <8 x i16> %2104 to <4 x i32>
  %2107 = bitcast <8 x i16> %2105 to <4 x i32>
  %2108 = sub <4 x i32> %2106, %2107
  %2109 = sub <4 x i32> zeroinitializer, %2108
  %2110 = icmp slt <4 x i32> %2108, zeroinitializer
  %2111 = select <4 x i1> %2110, <4 x i32> %2109, <4 x i32> %2108
  %2112 = add nuw <4 x i32> %2111, <i32 32, i32 32, i32 32, i32 32>
  %2113 = lshr <4 x i32> %2112, <i32 6, i32 6, i32 6, i32 6>
  %2114 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2103, <4 x i32> %2113) #5
  %2115 = lshr <8 x i16> %2114, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2116 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2087, <8 x i16> %2115) #5
  %2117 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %2116, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %2118 = icmp slt <16 x i8> %2117, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2119 = select <16 x i1> %2118, <16 x i8> %2117, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2120 = bitcast i8* %2061 to <16 x i8>*
  store <16 x i8> %2119, <16 x i8>* %2120, align 16
  %2121 = getelementptr inbounds i16, i16* %10, i64 544
  %2122 = getelementptr inbounds i16, i16* %11, i64 544
  %2123 = getelementptr inbounds i8, i8* %1999, i64 32
  %2124 = bitcast i16* %2121 to <8 x i16>*
  %2125 = load <8 x i16>, <8 x i16>* %2124, align 16
  %2126 = bitcast i16* %2122 to <8 x i16>*
  %2127 = load <8 x i16>, <8 x i16>* %2126, align 16
  %2128 = shufflevector <8 x i16> %2125, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2129 = zext <4 x i16> %2128 to <4 x i32>
  %2130 = shufflevector <8 x i16> %2127, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2131 = zext <4 x i16> %2130 to <4 x i32>
  %2132 = sub nsw <4 x i32> %2129, %2131
  %2133 = sub nsw <4 x i32> zeroinitializer, %2132
  %2134 = icmp slt <4 x i32> %2132, zeroinitializer
  %2135 = select <4 x i1> %2134, <4 x i32> %2133, <4 x i32> %2132
  %2136 = add nuw nsw <4 x i32> %2135, <i32 32, i32 32, i32 32, i32 32>
  %2137 = lshr <4 x i32> %2136, <i32 6, i32 6, i32 6, i32 6>
  %2138 = shufflevector <8 x i16> %2125, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2139 = shufflevector <8 x i16> %2127, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2140 = bitcast <8 x i16> %2138 to <4 x i32>
  %2141 = bitcast <8 x i16> %2139 to <4 x i32>
  %2142 = sub <4 x i32> %2140, %2141
  %2143 = sub <4 x i32> zeroinitializer, %2142
  %2144 = icmp slt <4 x i32> %2142, zeroinitializer
  %2145 = select <4 x i1> %2144, <4 x i32> %2143, <4 x i32> %2142
  %2146 = add nuw <4 x i32> %2145, <i32 32, i32 32, i32 32, i32 32>
  %2147 = lshr <4 x i32> %2146, <i32 6, i32 6, i32 6, i32 6>
  %2148 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2137, <4 x i32> %2147) #5
  %2149 = lshr <8 x i16> %2148, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2150 = getelementptr inbounds i16, i16* %10, i64 552
  %2151 = bitcast i16* %2150 to <8 x i16>*
  %2152 = load <8 x i16>, <8 x i16>* %2151, align 16
  %2153 = getelementptr inbounds i16, i16* %11, i64 552
  %2154 = bitcast i16* %2153 to <8 x i16>*
  %2155 = load <8 x i16>, <8 x i16>* %2154, align 16
  %2156 = shufflevector <8 x i16> %2152, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2157 = zext <4 x i16> %2156 to <4 x i32>
  %2158 = shufflevector <8 x i16> %2155, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2159 = zext <4 x i16> %2158 to <4 x i32>
  %2160 = sub nsw <4 x i32> %2157, %2159
  %2161 = sub nsw <4 x i32> zeroinitializer, %2160
  %2162 = icmp slt <4 x i32> %2160, zeroinitializer
  %2163 = select <4 x i1> %2162, <4 x i32> %2161, <4 x i32> %2160
  %2164 = add nuw nsw <4 x i32> %2163, <i32 32, i32 32, i32 32, i32 32>
  %2165 = lshr <4 x i32> %2164, <i32 6, i32 6, i32 6, i32 6>
  %2166 = shufflevector <8 x i16> %2152, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2167 = shufflevector <8 x i16> %2155, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2168 = bitcast <8 x i16> %2166 to <4 x i32>
  %2169 = bitcast <8 x i16> %2167 to <4 x i32>
  %2170 = sub <4 x i32> %2168, %2169
  %2171 = sub <4 x i32> zeroinitializer, %2170
  %2172 = icmp slt <4 x i32> %2170, zeroinitializer
  %2173 = select <4 x i1> %2172, <4 x i32> %2171, <4 x i32> %2170
  %2174 = add nuw <4 x i32> %2173, <i32 32, i32 32, i32 32, i32 32>
  %2175 = lshr <4 x i32> %2174, <i32 6, i32 6, i32 6, i32 6>
  %2176 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2165, <4 x i32> %2175) #5
  %2177 = lshr <8 x i16> %2176, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2178 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2149, <8 x i16> %2177) #5
  %2179 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %2178, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %2180 = icmp slt <16 x i8> %2179, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2181 = select <16 x i1> %2180, <16 x i8> %2179, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2182 = bitcast i8* %2123 to <16 x i8>*
  store <16 x i8> %2181, <16 x i8>* %2182, align 16
  %2183 = getelementptr inbounds i16, i16* %10, i64 560
  %2184 = getelementptr inbounds i16, i16* %11, i64 560
  %2185 = getelementptr inbounds i8, i8* %1999, i64 48
  %2186 = bitcast i16* %2183 to <8 x i16>*
  %2187 = load <8 x i16>, <8 x i16>* %2186, align 16
  %2188 = bitcast i16* %2184 to <8 x i16>*
  %2189 = load <8 x i16>, <8 x i16>* %2188, align 16
  %2190 = shufflevector <8 x i16> %2187, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2191 = zext <4 x i16> %2190 to <4 x i32>
  %2192 = shufflevector <8 x i16> %2189, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2193 = zext <4 x i16> %2192 to <4 x i32>
  %2194 = sub nsw <4 x i32> %2191, %2193
  %2195 = sub nsw <4 x i32> zeroinitializer, %2194
  %2196 = icmp slt <4 x i32> %2194, zeroinitializer
  %2197 = select <4 x i1> %2196, <4 x i32> %2195, <4 x i32> %2194
  %2198 = add nuw nsw <4 x i32> %2197, <i32 32, i32 32, i32 32, i32 32>
  %2199 = lshr <4 x i32> %2198, <i32 6, i32 6, i32 6, i32 6>
  %2200 = shufflevector <8 x i16> %2187, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2201 = shufflevector <8 x i16> %2189, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2202 = bitcast <8 x i16> %2200 to <4 x i32>
  %2203 = bitcast <8 x i16> %2201 to <4 x i32>
  %2204 = sub <4 x i32> %2202, %2203
  %2205 = sub <4 x i32> zeroinitializer, %2204
  %2206 = icmp slt <4 x i32> %2204, zeroinitializer
  %2207 = select <4 x i1> %2206, <4 x i32> %2205, <4 x i32> %2204
  %2208 = add nuw <4 x i32> %2207, <i32 32, i32 32, i32 32, i32 32>
  %2209 = lshr <4 x i32> %2208, <i32 6, i32 6, i32 6, i32 6>
  %2210 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2199, <4 x i32> %2209) #5
  %2211 = lshr <8 x i16> %2210, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2212 = getelementptr inbounds i16, i16* %10, i64 568
  %2213 = bitcast i16* %2212 to <8 x i16>*
  %2214 = load <8 x i16>, <8 x i16>* %2213, align 16
  %2215 = getelementptr inbounds i16, i16* %11, i64 568
  %2216 = bitcast i16* %2215 to <8 x i16>*
  %2217 = load <8 x i16>, <8 x i16>* %2216, align 16
  %2218 = shufflevector <8 x i16> %2214, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2219 = zext <4 x i16> %2218 to <4 x i32>
  %2220 = shufflevector <8 x i16> %2217, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2221 = zext <4 x i16> %2220 to <4 x i32>
  %2222 = sub nsw <4 x i32> %2219, %2221
  %2223 = sub nsw <4 x i32> zeroinitializer, %2222
  %2224 = icmp slt <4 x i32> %2222, zeroinitializer
  %2225 = select <4 x i1> %2224, <4 x i32> %2223, <4 x i32> %2222
  %2226 = add nuw nsw <4 x i32> %2225, <i32 32, i32 32, i32 32, i32 32>
  %2227 = lshr <4 x i32> %2226, <i32 6, i32 6, i32 6, i32 6>
  %2228 = shufflevector <8 x i16> %2214, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2229 = shufflevector <8 x i16> %2217, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2230 = bitcast <8 x i16> %2228 to <4 x i32>
  %2231 = bitcast <8 x i16> %2229 to <4 x i32>
  %2232 = sub <4 x i32> %2230, %2231
  %2233 = sub <4 x i32> zeroinitializer, %2232
  %2234 = icmp slt <4 x i32> %2232, zeroinitializer
  %2235 = select <4 x i1> %2234, <4 x i32> %2233, <4 x i32> %2232
  %2236 = add nuw <4 x i32> %2235, <i32 32, i32 32, i32 32, i32 32>
  %2237 = lshr <4 x i32> %2236, <i32 6, i32 6, i32 6, i32 6>
  %2238 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2227, <4 x i32> %2237) #5
  %2239 = lshr <8 x i16> %2238, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2240 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2211, <8 x i16> %2239) #5
  %2241 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %2240, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %2242 = icmp slt <16 x i8> %2241, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2243 = select <16 x i1> %2242, <16 x i8> %2241, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2244 = bitcast i8* %2185 to <16 x i8>*
  store <16 x i8> %2243, <16 x i8>* %2244, align 16
  %2245 = getelementptr inbounds i16, i16* %10, i64 576
  %2246 = getelementptr inbounds i16, i16* %11, i64 576
  %2247 = getelementptr inbounds i8, i8* %1999, i64 64
  %2248 = bitcast i16* %2245 to <8 x i16>*
  %2249 = load <8 x i16>, <8 x i16>* %2248, align 16
  %2250 = bitcast i16* %2246 to <8 x i16>*
  %2251 = load <8 x i16>, <8 x i16>* %2250, align 16
  %2252 = shufflevector <8 x i16> %2249, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2253 = zext <4 x i16> %2252 to <4 x i32>
  %2254 = shufflevector <8 x i16> %2251, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2255 = zext <4 x i16> %2254 to <4 x i32>
  %2256 = sub nsw <4 x i32> %2253, %2255
  %2257 = sub nsw <4 x i32> zeroinitializer, %2256
  %2258 = icmp slt <4 x i32> %2256, zeroinitializer
  %2259 = select <4 x i1> %2258, <4 x i32> %2257, <4 x i32> %2256
  %2260 = add nuw nsw <4 x i32> %2259, <i32 32, i32 32, i32 32, i32 32>
  %2261 = lshr <4 x i32> %2260, <i32 6, i32 6, i32 6, i32 6>
  %2262 = shufflevector <8 x i16> %2249, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2263 = shufflevector <8 x i16> %2251, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2264 = bitcast <8 x i16> %2262 to <4 x i32>
  %2265 = bitcast <8 x i16> %2263 to <4 x i32>
  %2266 = sub <4 x i32> %2264, %2265
  %2267 = sub <4 x i32> zeroinitializer, %2266
  %2268 = icmp slt <4 x i32> %2266, zeroinitializer
  %2269 = select <4 x i1> %2268, <4 x i32> %2267, <4 x i32> %2266
  %2270 = add nuw <4 x i32> %2269, <i32 32, i32 32, i32 32, i32 32>
  %2271 = lshr <4 x i32> %2270, <i32 6, i32 6, i32 6, i32 6>
  %2272 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2261, <4 x i32> %2271) #5
  %2273 = lshr <8 x i16> %2272, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2274 = getelementptr inbounds i16, i16* %10, i64 584
  %2275 = bitcast i16* %2274 to <8 x i16>*
  %2276 = load <8 x i16>, <8 x i16>* %2275, align 16
  %2277 = getelementptr inbounds i16, i16* %11, i64 584
  %2278 = bitcast i16* %2277 to <8 x i16>*
  %2279 = load <8 x i16>, <8 x i16>* %2278, align 16
  %2280 = shufflevector <8 x i16> %2276, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2281 = zext <4 x i16> %2280 to <4 x i32>
  %2282 = shufflevector <8 x i16> %2279, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2283 = zext <4 x i16> %2282 to <4 x i32>
  %2284 = sub nsw <4 x i32> %2281, %2283
  %2285 = sub nsw <4 x i32> zeroinitializer, %2284
  %2286 = icmp slt <4 x i32> %2284, zeroinitializer
  %2287 = select <4 x i1> %2286, <4 x i32> %2285, <4 x i32> %2284
  %2288 = add nuw nsw <4 x i32> %2287, <i32 32, i32 32, i32 32, i32 32>
  %2289 = lshr <4 x i32> %2288, <i32 6, i32 6, i32 6, i32 6>
  %2290 = shufflevector <8 x i16> %2276, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2291 = shufflevector <8 x i16> %2279, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2292 = bitcast <8 x i16> %2290 to <4 x i32>
  %2293 = bitcast <8 x i16> %2291 to <4 x i32>
  %2294 = sub <4 x i32> %2292, %2293
  %2295 = sub <4 x i32> zeroinitializer, %2294
  %2296 = icmp slt <4 x i32> %2294, zeroinitializer
  %2297 = select <4 x i1> %2296, <4 x i32> %2295, <4 x i32> %2294
  %2298 = add nuw <4 x i32> %2297, <i32 32, i32 32, i32 32, i32 32>
  %2299 = lshr <4 x i32> %2298, <i32 6, i32 6, i32 6, i32 6>
  %2300 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2289, <4 x i32> %2299) #5
  %2301 = lshr <8 x i16> %2300, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2302 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2273, <8 x i16> %2301) #5
  %2303 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %2302, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %2304 = icmp slt <16 x i8> %2303, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2305 = select <16 x i1> %2304, <16 x i8> %2303, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2306 = bitcast i8* %2247 to <16 x i8>*
  store <16 x i8> %2305, <16 x i8>* %2306, align 16
  %2307 = getelementptr inbounds i16, i16* %10, i64 592
  %2308 = getelementptr inbounds i16, i16* %11, i64 592
  %2309 = getelementptr inbounds i8, i8* %2247, i64 16
  %2310 = bitcast i16* %2307 to <8 x i16>*
  %2311 = load <8 x i16>, <8 x i16>* %2310, align 16
  %2312 = bitcast i16* %2308 to <8 x i16>*
  %2313 = load <8 x i16>, <8 x i16>* %2312, align 16
  %2314 = shufflevector <8 x i16> %2311, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2315 = zext <4 x i16> %2314 to <4 x i32>
  %2316 = shufflevector <8 x i16> %2313, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2317 = zext <4 x i16> %2316 to <4 x i32>
  %2318 = sub nsw <4 x i32> %2315, %2317
  %2319 = sub nsw <4 x i32> zeroinitializer, %2318
  %2320 = icmp slt <4 x i32> %2318, zeroinitializer
  %2321 = select <4 x i1> %2320, <4 x i32> %2319, <4 x i32> %2318
  %2322 = add nuw nsw <4 x i32> %2321, <i32 32, i32 32, i32 32, i32 32>
  %2323 = lshr <4 x i32> %2322, <i32 6, i32 6, i32 6, i32 6>
  %2324 = shufflevector <8 x i16> %2311, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2325 = shufflevector <8 x i16> %2313, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2326 = bitcast <8 x i16> %2324 to <4 x i32>
  %2327 = bitcast <8 x i16> %2325 to <4 x i32>
  %2328 = sub <4 x i32> %2326, %2327
  %2329 = sub <4 x i32> zeroinitializer, %2328
  %2330 = icmp slt <4 x i32> %2328, zeroinitializer
  %2331 = select <4 x i1> %2330, <4 x i32> %2329, <4 x i32> %2328
  %2332 = add nuw <4 x i32> %2331, <i32 32, i32 32, i32 32, i32 32>
  %2333 = lshr <4 x i32> %2332, <i32 6, i32 6, i32 6, i32 6>
  %2334 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2323, <4 x i32> %2333) #5
  %2335 = lshr <8 x i16> %2334, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2336 = getelementptr inbounds i16, i16* %10, i64 600
  %2337 = bitcast i16* %2336 to <8 x i16>*
  %2338 = load <8 x i16>, <8 x i16>* %2337, align 16
  %2339 = getelementptr inbounds i16, i16* %11, i64 600
  %2340 = bitcast i16* %2339 to <8 x i16>*
  %2341 = load <8 x i16>, <8 x i16>* %2340, align 16
  %2342 = shufflevector <8 x i16> %2338, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2343 = zext <4 x i16> %2342 to <4 x i32>
  %2344 = shufflevector <8 x i16> %2341, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2345 = zext <4 x i16> %2344 to <4 x i32>
  %2346 = sub nsw <4 x i32> %2343, %2345
  %2347 = sub nsw <4 x i32> zeroinitializer, %2346
  %2348 = icmp slt <4 x i32> %2346, zeroinitializer
  %2349 = select <4 x i1> %2348, <4 x i32> %2347, <4 x i32> %2346
  %2350 = add nuw nsw <4 x i32> %2349, <i32 32, i32 32, i32 32, i32 32>
  %2351 = lshr <4 x i32> %2350, <i32 6, i32 6, i32 6, i32 6>
  %2352 = shufflevector <8 x i16> %2338, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2353 = shufflevector <8 x i16> %2341, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2354 = bitcast <8 x i16> %2352 to <4 x i32>
  %2355 = bitcast <8 x i16> %2353 to <4 x i32>
  %2356 = sub <4 x i32> %2354, %2355
  %2357 = sub <4 x i32> zeroinitializer, %2356
  %2358 = icmp slt <4 x i32> %2356, zeroinitializer
  %2359 = select <4 x i1> %2358, <4 x i32> %2357, <4 x i32> %2356
  %2360 = add nuw <4 x i32> %2359, <i32 32, i32 32, i32 32, i32 32>
  %2361 = lshr <4 x i32> %2360, <i32 6, i32 6, i32 6, i32 6>
  %2362 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2351, <4 x i32> %2361) #5
  %2363 = lshr <8 x i16> %2362, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2364 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2335, <8 x i16> %2363) #5
  %2365 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %2364, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %2366 = icmp slt <16 x i8> %2365, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2367 = select <16 x i1> %2366, <16 x i8> %2365, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2368 = bitcast i8* %2309 to <16 x i8>*
  store <16 x i8> %2367, <16 x i8>* %2368, align 16
  %2369 = getelementptr inbounds i16, i16* %10, i64 608
  %2370 = getelementptr inbounds i16, i16* %11, i64 608
  %2371 = getelementptr inbounds i8, i8* %2247, i64 32
  %2372 = bitcast i16* %2369 to <8 x i16>*
  %2373 = load <8 x i16>, <8 x i16>* %2372, align 16
  %2374 = bitcast i16* %2370 to <8 x i16>*
  %2375 = load <8 x i16>, <8 x i16>* %2374, align 16
  %2376 = shufflevector <8 x i16> %2373, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2377 = zext <4 x i16> %2376 to <4 x i32>
  %2378 = shufflevector <8 x i16> %2375, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2379 = zext <4 x i16> %2378 to <4 x i32>
  %2380 = sub nsw <4 x i32> %2377, %2379
  %2381 = sub nsw <4 x i32> zeroinitializer, %2380
  %2382 = icmp slt <4 x i32> %2380, zeroinitializer
  %2383 = select <4 x i1> %2382, <4 x i32> %2381, <4 x i32> %2380
  %2384 = add nuw nsw <4 x i32> %2383, <i32 32, i32 32, i32 32, i32 32>
  %2385 = lshr <4 x i32> %2384, <i32 6, i32 6, i32 6, i32 6>
  %2386 = shufflevector <8 x i16> %2373, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2387 = shufflevector <8 x i16> %2375, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2388 = bitcast <8 x i16> %2386 to <4 x i32>
  %2389 = bitcast <8 x i16> %2387 to <4 x i32>
  %2390 = sub <4 x i32> %2388, %2389
  %2391 = sub <4 x i32> zeroinitializer, %2390
  %2392 = icmp slt <4 x i32> %2390, zeroinitializer
  %2393 = select <4 x i1> %2392, <4 x i32> %2391, <4 x i32> %2390
  %2394 = add nuw <4 x i32> %2393, <i32 32, i32 32, i32 32, i32 32>
  %2395 = lshr <4 x i32> %2394, <i32 6, i32 6, i32 6, i32 6>
  %2396 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2385, <4 x i32> %2395) #5
  %2397 = lshr <8 x i16> %2396, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2398 = getelementptr inbounds i16, i16* %10, i64 616
  %2399 = bitcast i16* %2398 to <8 x i16>*
  %2400 = load <8 x i16>, <8 x i16>* %2399, align 16
  %2401 = getelementptr inbounds i16, i16* %11, i64 616
  %2402 = bitcast i16* %2401 to <8 x i16>*
  %2403 = load <8 x i16>, <8 x i16>* %2402, align 16
  %2404 = shufflevector <8 x i16> %2400, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2405 = zext <4 x i16> %2404 to <4 x i32>
  %2406 = shufflevector <8 x i16> %2403, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2407 = zext <4 x i16> %2406 to <4 x i32>
  %2408 = sub nsw <4 x i32> %2405, %2407
  %2409 = sub nsw <4 x i32> zeroinitializer, %2408
  %2410 = icmp slt <4 x i32> %2408, zeroinitializer
  %2411 = select <4 x i1> %2410, <4 x i32> %2409, <4 x i32> %2408
  %2412 = add nuw nsw <4 x i32> %2411, <i32 32, i32 32, i32 32, i32 32>
  %2413 = lshr <4 x i32> %2412, <i32 6, i32 6, i32 6, i32 6>
  %2414 = shufflevector <8 x i16> %2400, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2415 = shufflevector <8 x i16> %2403, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2416 = bitcast <8 x i16> %2414 to <4 x i32>
  %2417 = bitcast <8 x i16> %2415 to <4 x i32>
  %2418 = sub <4 x i32> %2416, %2417
  %2419 = sub <4 x i32> zeroinitializer, %2418
  %2420 = icmp slt <4 x i32> %2418, zeroinitializer
  %2421 = select <4 x i1> %2420, <4 x i32> %2419, <4 x i32> %2418
  %2422 = add nuw <4 x i32> %2421, <i32 32, i32 32, i32 32, i32 32>
  %2423 = lshr <4 x i32> %2422, <i32 6, i32 6, i32 6, i32 6>
  %2424 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2413, <4 x i32> %2423) #5
  %2425 = lshr <8 x i16> %2424, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2426 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2397, <8 x i16> %2425) #5
  %2427 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %2426, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %2428 = icmp slt <16 x i8> %2427, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2429 = select <16 x i1> %2428, <16 x i8> %2427, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2430 = bitcast i8* %2371 to <16 x i8>*
  store <16 x i8> %2429, <16 x i8>* %2430, align 16
  %2431 = getelementptr inbounds i16, i16* %10, i64 624
  %2432 = getelementptr inbounds i16, i16* %11, i64 624
  %2433 = getelementptr inbounds i8, i8* %2247, i64 48
  %2434 = bitcast i16* %2431 to <8 x i16>*
  %2435 = load <8 x i16>, <8 x i16>* %2434, align 16
  %2436 = bitcast i16* %2432 to <8 x i16>*
  %2437 = load <8 x i16>, <8 x i16>* %2436, align 16
  %2438 = shufflevector <8 x i16> %2435, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2439 = zext <4 x i16> %2438 to <4 x i32>
  %2440 = shufflevector <8 x i16> %2437, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2441 = zext <4 x i16> %2440 to <4 x i32>
  %2442 = sub nsw <4 x i32> %2439, %2441
  %2443 = sub nsw <4 x i32> zeroinitializer, %2442
  %2444 = icmp slt <4 x i32> %2442, zeroinitializer
  %2445 = select <4 x i1> %2444, <4 x i32> %2443, <4 x i32> %2442
  %2446 = add nuw nsw <4 x i32> %2445, <i32 32, i32 32, i32 32, i32 32>
  %2447 = lshr <4 x i32> %2446, <i32 6, i32 6, i32 6, i32 6>
  %2448 = shufflevector <8 x i16> %2435, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2449 = shufflevector <8 x i16> %2437, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2450 = bitcast <8 x i16> %2448 to <4 x i32>
  %2451 = bitcast <8 x i16> %2449 to <4 x i32>
  %2452 = sub <4 x i32> %2450, %2451
  %2453 = sub <4 x i32> zeroinitializer, %2452
  %2454 = icmp slt <4 x i32> %2452, zeroinitializer
  %2455 = select <4 x i1> %2454, <4 x i32> %2453, <4 x i32> %2452
  %2456 = add nuw <4 x i32> %2455, <i32 32, i32 32, i32 32, i32 32>
  %2457 = lshr <4 x i32> %2456, <i32 6, i32 6, i32 6, i32 6>
  %2458 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2447, <4 x i32> %2457) #5
  %2459 = lshr <8 x i16> %2458, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2460 = getelementptr inbounds i16, i16* %10, i64 632
  %2461 = bitcast i16* %2460 to <8 x i16>*
  %2462 = load <8 x i16>, <8 x i16>* %2461, align 16
  %2463 = getelementptr inbounds i16, i16* %11, i64 632
  %2464 = bitcast i16* %2463 to <8 x i16>*
  %2465 = load <8 x i16>, <8 x i16>* %2464, align 16
  %2466 = shufflevector <8 x i16> %2462, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2467 = zext <4 x i16> %2466 to <4 x i32>
  %2468 = shufflevector <8 x i16> %2465, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2469 = zext <4 x i16> %2468 to <4 x i32>
  %2470 = sub nsw <4 x i32> %2467, %2469
  %2471 = sub nsw <4 x i32> zeroinitializer, %2470
  %2472 = icmp slt <4 x i32> %2470, zeroinitializer
  %2473 = select <4 x i1> %2472, <4 x i32> %2471, <4 x i32> %2470
  %2474 = add nuw nsw <4 x i32> %2473, <i32 32, i32 32, i32 32, i32 32>
  %2475 = lshr <4 x i32> %2474, <i32 6, i32 6, i32 6, i32 6>
  %2476 = shufflevector <8 x i16> %2462, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2477 = shufflevector <8 x i16> %2465, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2478 = bitcast <8 x i16> %2476 to <4 x i32>
  %2479 = bitcast <8 x i16> %2477 to <4 x i32>
  %2480 = sub <4 x i32> %2478, %2479
  %2481 = sub <4 x i32> zeroinitializer, %2480
  %2482 = icmp slt <4 x i32> %2480, zeroinitializer
  %2483 = select <4 x i1> %2482, <4 x i32> %2481, <4 x i32> %2480
  %2484 = add nuw <4 x i32> %2483, <i32 32, i32 32, i32 32, i32 32>
  %2485 = lshr <4 x i32> %2484, <i32 6, i32 6, i32 6, i32 6>
  %2486 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2475, <4 x i32> %2485) #5
  %2487 = lshr <8 x i16> %2486, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2488 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2459, <8 x i16> %2487) #5
  %2489 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %2488, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %2490 = icmp slt <16 x i8> %2489, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2491 = select <16 x i1> %2490, <16 x i8> %2489, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2492 = bitcast i8* %2433 to <16 x i8>*
  store <16 x i8> %2491, <16 x i8>* %2492, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @_ZN7libgav13dsp13high_bitdepth12_GLOBAL__N_128WeightMask128x128_10bpp_SSE4ILb1EEEvPKvS5_Phl(i8* readonly, i8* readonly, i8* nocapture, i64) #2 {
  %5 = bitcast i8* %0 to i16*
  %6 = bitcast i8* %1 to i16*
  %7 = add nsw i64 %3, -64
  br label %8

8:                                                ; preds = %8, %4
  %9 = phi i8* [ %2, %4 ], [ %1524, %8 ]
  %10 = phi i16* [ %5, %4 ], [ %1522, %8 ]
  %11 = phi i16* [ %6, %4 ], [ %1523, %8 ]
  %12 = phi i32 [ 42, %4 ], [ %1525, %8 ]
  %13 = bitcast i16* %10 to <8 x i16>*
  %14 = load <8 x i16>, <8 x i16>* %13, align 16
  %15 = bitcast i16* %11 to <8 x i16>*
  %16 = load <8 x i16>, <8 x i16>* %15, align 16
  %17 = shufflevector <8 x i16> %14, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %18 = zext <4 x i16> %17 to <4 x i32>
  %19 = shufflevector <8 x i16> %16, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %20 = zext <4 x i16> %19 to <4 x i32>
  %21 = sub nsw <4 x i32> %18, %20
  %22 = sub nsw <4 x i32> zeroinitializer, %21
  %23 = icmp slt <4 x i32> %21, zeroinitializer
  %24 = select <4 x i1> %23, <4 x i32> %22, <4 x i32> %21
  %25 = add nuw nsw <4 x i32> %24, <i32 32, i32 32, i32 32, i32 32>
  %26 = lshr <4 x i32> %25, <i32 6, i32 6, i32 6, i32 6>
  %27 = shufflevector <8 x i16> %14, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %28 = shufflevector <8 x i16> %16, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %29 = bitcast <8 x i16> %27 to <4 x i32>
  %30 = bitcast <8 x i16> %28 to <4 x i32>
  %31 = sub <4 x i32> %29, %30
  %32 = sub <4 x i32> zeroinitializer, %31
  %33 = icmp slt <4 x i32> %31, zeroinitializer
  %34 = select <4 x i1> %33, <4 x i32> %32, <4 x i32> %31
  %35 = add nuw <4 x i32> %34, <i32 32, i32 32, i32 32, i32 32>
  %36 = lshr <4 x i32> %35, <i32 6, i32 6, i32 6, i32 6>
  %37 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %26, <4 x i32> %36) #5
  %38 = lshr <8 x i16> %37, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %39 = getelementptr inbounds i16, i16* %10, i64 8
  %40 = bitcast i16* %39 to <8 x i16>*
  %41 = load <8 x i16>, <8 x i16>* %40, align 16
  %42 = getelementptr inbounds i16, i16* %11, i64 8
  %43 = bitcast i16* %42 to <8 x i16>*
  %44 = load <8 x i16>, <8 x i16>* %43, align 16
  %45 = shufflevector <8 x i16> %41, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %46 = zext <4 x i16> %45 to <4 x i32>
  %47 = shufflevector <8 x i16> %44, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %48 = zext <4 x i16> %47 to <4 x i32>
  %49 = sub nsw <4 x i32> %46, %48
  %50 = sub nsw <4 x i32> zeroinitializer, %49
  %51 = icmp slt <4 x i32> %49, zeroinitializer
  %52 = select <4 x i1> %51, <4 x i32> %50, <4 x i32> %49
  %53 = add nuw nsw <4 x i32> %52, <i32 32, i32 32, i32 32, i32 32>
  %54 = lshr <4 x i32> %53, <i32 6, i32 6, i32 6, i32 6>
  %55 = shufflevector <8 x i16> %41, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %56 = shufflevector <8 x i16> %44, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %57 = bitcast <8 x i16> %55 to <4 x i32>
  %58 = bitcast <8 x i16> %56 to <4 x i32>
  %59 = sub <4 x i32> %57, %58
  %60 = sub <4 x i32> zeroinitializer, %59
  %61 = icmp slt <4 x i32> %59, zeroinitializer
  %62 = select <4 x i1> %61, <4 x i32> %60, <4 x i32> %59
  %63 = add nuw <4 x i32> %62, <i32 32, i32 32, i32 32, i32 32>
  %64 = lshr <4 x i32> %63, <i32 6, i32 6, i32 6, i32 6>
  %65 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %54, <4 x i32> %64) #5
  %66 = lshr <8 x i16> %65, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %67 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %38, <8 x i16> %66) #5
  %68 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %67, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %69 = icmp slt <16 x i8> %68, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %70 = select <16 x i1> %69, <16 x i8> %68, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %71 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %70
  %72 = bitcast i8* %9 to <16 x i8>*
  store <16 x i8> %71, <16 x i8>* %72, align 16
  %73 = getelementptr inbounds i16, i16* %10, i64 16
  %74 = getelementptr inbounds i16, i16* %11, i64 16
  %75 = getelementptr inbounds i8, i8* %9, i64 16
  %76 = bitcast i16* %73 to <8 x i16>*
  %77 = load <8 x i16>, <8 x i16>* %76, align 16
  %78 = bitcast i16* %74 to <8 x i16>*
  %79 = load <8 x i16>, <8 x i16>* %78, align 16
  %80 = shufflevector <8 x i16> %77, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %81 = zext <4 x i16> %80 to <4 x i32>
  %82 = shufflevector <8 x i16> %79, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %83 = zext <4 x i16> %82 to <4 x i32>
  %84 = sub nsw <4 x i32> %81, %83
  %85 = sub nsw <4 x i32> zeroinitializer, %84
  %86 = icmp slt <4 x i32> %84, zeroinitializer
  %87 = select <4 x i1> %86, <4 x i32> %85, <4 x i32> %84
  %88 = add nuw nsw <4 x i32> %87, <i32 32, i32 32, i32 32, i32 32>
  %89 = lshr <4 x i32> %88, <i32 6, i32 6, i32 6, i32 6>
  %90 = shufflevector <8 x i16> %77, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %91 = shufflevector <8 x i16> %79, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %92 = bitcast <8 x i16> %90 to <4 x i32>
  %93 = bitcast <8 x i16> %91 to <4 x i32>
  %94 = sub <4 x i32> %92, %93
  %95 = sub <4 x i32> zeroinitializer, %94
  %96 = icmp slt <4 x i32> %94, zeroinitializer
  %97 = select <4 x i1> %96, <4 x i32> %95, <4 x i32> %94
  %98 = add nuw <4 x i32> %97, <i32 32, i32 32, i32 32, i32 32>
  %99 = lshr <4 x i32> %98, <i32 6, i32 6, i32 6, i32 6>
  %100 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %89, <4 x i32> %99) #5
  %101 = lshr <8 x i16> %100, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %102 = getelementptr inbounds i16, i16* %10, i64 24
  %103 = bitcast i16* %102 to <8 x i16>*
  %104 = load <8 x i16>, <8 x i16>* %103, align 16
  %105 = getelementptr inbounds i16, i16* %11, i64 24
  %106 = bitcast i16* %105 to <8 x i16>*
  %107 = load <8 x i16>, <8 x i16>* %106, align 16
  %108 = shufflevector <8 x i16> %104, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %109 = zext <4 x i16> %108 to <4 x i32>
  %110 = shufflevector <8 x i16> %107, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %111 = zext <4 x i16> %110 to <4 x i32>
  %112 = sub nsw <4 x i32> %109, %111
  %113 = sub nsw <4 x i32> zeroinitializer, %112
  %114 = icmp slt <4 x i32> %112, zeroinitializer
  %115 = select <4 x i1> %114, <4 x i32> %113, <4 x i32> %112
  %116 = add nuw nsw <4 x i32> %115, <i32 32, i32 32, i32 32, i32 32>
  %117 = lshr <4 x i32> %116, <i32 6, i32 6, i32 6, i32 6>
  %118 = shufflevector <8 x i16> %104, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %119 = shufflevector <8 x i16> %107, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %120 = bitcast <8 x i16> %118 to <4 x i32>
  %121 = bitcast <8 x i16> %119 to <4 x i32>
  %122 = sub <4 x i32> %120, %121
  %123 = sub <4 x i32> zeroinitializer, %122
  %124 = icmp slt <4 x i32> %122, zeroinitializer
  %125 = select <4 x i1> %124, <4 x i32> %123, <4 x i32> %122
  %126 = add nuw <4 x i32> %125, <i32 32, i32 32, i32 32, i32 32>
  %127 = lshr <4 x i32> %126, <i32 6, i32 6, i32 6, i32 6>
  %128 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %117, <4 x i32> %127) #5
  %129 = lshr <8 x i16> %128, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %130 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %101, <8 x i16> %129) #5
  %131 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %130, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %132 = icmp slt <16 x i8> %131, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %133 = select <16 x i1> %132, <16 x i8> %131, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %134 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %133
  %135 = bitcast i8* %75 to <16 x i8>*
  store <16 x i8> %134, <16 x i8>* %135, align 16
  %136 = getelementptr inbounds i16, i16* %10, i64 32
  %137 = getelementptr inbounds i16, i16* %11, i64 32
  %138 = getelementptr inbounds i8, i8* %9, i64 32
  %139 = bitcast i16* %136 to <8 x i16>*
  %140 = load <8 x i16>, <8 x i16>* %139, align 16
  %141 = bitcast i16* %137 to <8 x i16>*
  %142 = load <8 x i16>, <8 x i16>* %141, align 16
  %143 = shufflevector <8 x i16> %140, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %144 = zext <4 x i16> %143 to <4 x i32>
  %145 = shufflevector <8 x i16> %142, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %146 = zext <4 x i16> %145 to <4 x i32>
  %147 = sub nsw <4 x i32> %144, %146
  %148 = sub nsw <4 x i32> zeroinitializer, %147
  %149 = icmp slt <4 x i32> %147, zeroinitializer
  %150 = select <4 x i1> %149, <4 x i32> %148, <4 x i32> %147
  %151 = add nuw nsw <4 x i32> %150, <i32 32, i32 32, i32 32, i32 32>
  %152 = lshr <4 x i32> %151, <i32 6, i32 6, i32 6, i32 6>
  %153 = shufflevector <8 x i16> %140, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %154 = shufflevector <8 x i16> %142, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %155 = bitcast <8 x i16> %153 to <4 x i32>
  %156 = bitcast <8 x i16> %154 to <4 x i32>
  %157 = sub <4 x i32> %155, %156
  %158 = sub <4 x i32> zeroinitializer, %157
  %159 = icmp slt <4 x i32> %157, zeroinitializer
  %160 = select <4 x i1> %159, <4 x i32> %158, <4 x i32> %157
  %161 = add nuw <4 x i32> %160, <i32 32, i32 32, i32 32, i32 32>
  %162 = lshr <4 x i32> %161, <i32 6, i32 6, i32 6, i32 6>
  %163 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %152, <4 x i32> %162) #5
  %164 = lshr <8 x i16> %163, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %165 = getelementptr inbounds i16, i16* %10, i64 40
  %166 = bitcast i16* %165 to <8 x i16>*
  %167 = load <8 x i16>, <8 x i16>* %166, align 16
  %168 = getelementptr inbounds i16, i16* %11, i64 40
  %169 = bitcast i16* %168 to <8 x i16>*
  %170 = load <8 x i16>, <8 x i16>* %169, align 16
  %171 = shufflevector <8 x i16> %167, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %172 = zext <4 x i16> %171 to <4 x i32>
  %173 = shufflevector <8 x i16> %170, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %174 = zext <4 x i16> %173 to <4 x i32>
  %175 = sub nsw <4 x i32> %172, %174
  %176 = sub nsw <4 x i32> zeroinitializer, %175
  %177 = icmp slt <4 x i32> %175, zeroinitializer
  %178 = select <4 x i1> %177, <4 x i32> %176, <4 x i32> %175
  %179 = add nuw nsw <4 x i32> %178, <i32 32, i32 32, i32 32, i32 32>
  %180 = lshr <4 x i32> %179, <i32 6, i32 6, i32 6, i32 6>
  %181 = shufflevector <8 x i16> %167, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %182 = shufflevector <8 x i16> %170, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %183 = bitcast <8 x i16> %181 to <4 x i32>
  %184 = bitcast <8 x i16> %182 to <4 x i32>
  %185 = sub <4 x i32> %183, %184
  %186 = sub <4 x i32> zeroinitializer, %185
  %187 = icmp slt <4 x i32> %185, zeroinitializer
  %188 = select <4 x i1> %187, <4 x i32> %186, <4 x i32> %185
  %189 = add nuw <4 x i32> %188, <i32 32, i32 32, i32 32, i32 32>
  %190 = lshr <4 x i32> %189, <i32 6, i32 6, i32 6, i32 6>
  %191 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %180, <4 x i32> %190) #5
  %192 = lshr <8 x i16> %191, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %193 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %164, <8 x i16> %192) #5
  %194 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %193, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %195 = icmp slt <16 x i8> %194, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %196 = select <16 x i1> %195, <16 x i8> %194, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %197 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %196
  %198 = bitcast i8* %138 to <16 x i8>*
  store <16 x i8> %197, <16 x i8>* %198, align 16
  %199 = getelementptr inbounds i16, i16* %10, i64 48
  %200 = getelementptr inbounds i16, i16* %11, i64 48
  %201 = getelementptr inbounds i8, i8* %9, i64 48
  %202 = bitcast i16* %199 to <8 x i16>*
  %203 = load <8 x i16>, <8 x i16>* %202, align 16
  %204 = bitcast i16* %200 to <8 x i16>*
  %205 = load <8 x i16>, <8 x i16>* %204, align 16
  %206 = shufflevector <8 x i16> %203, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %207 = zext <4 x i16> %206 to <4 x i32>
  %208 = shufflevector <8 x i16> %205, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %209 = zext <4 x i16> %208 to <4 x i32>
  %210 = sub nsw <4 x i32> %207, %209
  %211 = sub nsw <4 x i32> zeroinitializer, %210
  %212 = icmp slt <4 x i32> %210, zeroinitializer
  %213 = select <4 x i1> %212, <4 x i32> %211, <4 x i32> %210
  %214 = add nuw nsw <4 x i32> %213, <i32 32, i32 32, i32 32, i32 32>
  %215 = lshr <4 x i32> %214, <i32 6, i32 6, i32 6, i32 6>
  %216 = shufflevector <8 x i16> %203, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %217 = shufflevector <8 x i16> %205, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %218 = bitcast <8 x i16> %216 to <4 x i32>
  %219 = bitcast <8 x i16> %217 to <4 x i32>
  %220 = sub <4 x i32> %218, %219
  %221 = sub <4 x i32> zeroinitializer, %220
  %222 = icmp slt <4 x i32> %220, zeroinitializer
  %223 = select <4 x i1> %222, <4 x i32> %221, <4 x i32> %220
  %224 = add nuw <4 x i32> %223, <i32 32, i32 32, i32 32, i32 32>
  %225 = lshr <4 x i32> %224, <i32 6, i32 6, i32 6, i32 6>
  %226 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %215, <4 x i32> %225) #5
  %227 = lshr <8 x i16> %226, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %228 = getelementptr inbounds i16, i16* %10, i64 56
  %229 = bitcast i16* %228 to <8 x i16>*
  %230 = load <8 x i16>, <8 x i16>* %229, align 16
  %231 = getelementptr inbounds i16, i16* %11, i64 56
  %232 = bitcast i16* %231 to <8 x i16>*
  %233 = load <8 x i16>, <8 x i16>* %232, align 16
  %234 = shufflevector <8 x i16> %230, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %235 = zext <4 x i16> %234 to <4 x i32>
  %236 = shufflevector <8 x i16> %233, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %237 = zext <4 x i16> %236 to <4 x i32>
  %238 = sub nsw <4 x i32> %235, %237
  %239 = sub nsw <4 x i32> zeroinitializer, %238
  %240 = icmp slt <4 x i32> %238, zeroinitializer
  %241 = select <4 x i1> %240, <4 x i32> %239, <4 x i32> %238
  %242 = add nuw nsw <4 x i32> %241, <i32 32, i32 32, i32 32, i32 32>
  %243 = lshr <4 x i32> %242, <i32 6, i32 6, i32 6, i32 6>
  %244 = shufflevector <8 x i16> %230, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %245 = shufflevector <8 x i16> %233, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %246 = bitcast <8 x i16> %244 to <4 x i32>
  %247 = bitcast <8 x i16> %245 to <4 x i32>
  %248 = sub <4 x i32> %246, %247
  %249 = sub <4 x i32> zeroinitializer, %248
  %250 = icmp slt <4 x i32> %248, zeroinitializer
  %251 = select <4 x i1> %250, <4 x i32> %249, <4 x i32> %248
  %252 = add nuw <4 x i32> %251, <i32 32, i32 32, i32 32, i32 32>
  %253 = lshr <4 x i32> %252, <i32 6, i32 6, i32 6, i32 6>
  %254 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %243, <4 x i32> %253) #5
  %255 = lshr <8 x i16> %254, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %256 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %227, <8 x i16> %255) #5
  %257 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %256, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %258 = icmp slt <16 x i8> %257, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %259 = select <16 x i1> %258, <16 x i8> %257, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %260 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %259
  %261 = bitcast i8* %201 to <16 x i8>*
  store <16 x i8> %260, <16 x i8>* %261, align 16
  %262 = getelementptr inbounds i16, i16* %10, i64 64
  %263 = getelementptr inbounds i16, i16* %11, i64 64
  %264 = getelementptr inbounds i8, i8* %9, i64 64
  %265 = bitcast i16* %262 to <8 x i16>*
  %266 = load <8 x i16>, <8 x i16>* %265, align 16
  %267 = bitcast i16* %263 to <8 x i16>*
  %268 = load <8 x i16>, <8 x i16>* %267, align 16
  %269 = shufflevector <8 x i16> %266, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %270 = zext <4 x i16> %269 to <4 x i32>
  %271 = shufflevector <8 x i16> %268, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %272 = zext <4 x i16> %271 to <4 x i32>
  %273 = sub nsw <4 x i32> %270, %272
  %274 = sub nsw <4 x i32> zeroinitializer, %273
  %275 = icmp slt <4 x i32> %273, zeroinitializer
  %276 = select <4 x i1> %275, <4 x i32> %274, <4 x i32> %273
  %277 = add nuw nsw <4 x i32> %276, <i32 32, i32 32, i32 32, i32 32>
  %278 = lshr <4 x i32> %277, <i32 6, i32 6, i32 6, i32 6>
  %279 = shufflevector <8 x i16> %266, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %280 = shufflevector <8 x i16> %268, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %281 = bitcast <8 x i16> %279 to <4 x i32>
  %282 = bitcast <8 x i16> %280 to <4 x i32>
  %283 = sub <4 x i32> %281, %282
  %284 = sub <4 x i32> zeroinitializer, %283
  %285 = icmp slt <4 x i32> %283, zeroinitializer
  %286 = select <4 x i1> %285, <4 x i32> %284, <4 x i32> %283
  %287 = add nuw <4 x i32> %286, <i32 32, i32 32, i32 32, i32 32>
  %288 = lshr <4 x i32> %287, <i32 6, i32 6, i32 6, i32 6>
  %289 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %278, <4 x i32> %288) #5
  %290 = lshr <8 x i16> %289, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %291 = getelementptr inbounds i16, i16* %10, i64 72
  %292 = bitcast i16* %291 to <8 x i16>*
  %293 = load <8 x i16>, <8 x i16>* %292, align 16
  %294 = getelementptr inbounds i16, i16* %11, i64 72
  %295 = bitcast i16* %294 to <8 x i16>*
  %296 = load <8 x i16>, <8 x i16>* %295, align 16
  %297 = shufflevector <8 x i16> %293, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %298 = zext <4 x i16> %297 to <4 x i32>
  %299 = shufflevector <8 x i16> %296, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %300 = zext <4 x i16> %299 to <4 x i32>
  %301 = sub nsw <4 x i32> %298, %300
  %302 = sub nsw <4 x i32> zeroinitializer, %301
  %303 = icmp slt <4 x i32> %301, zeroinitializer
  %304 = select <4 x i1> %303, <4 x i32> %302, <4 x i32> %301
  %305 = add nuw nsw <4 x i32> %304, <i32 32, i32 32, i32 32, i32 32>
  %306 = lshr <4 x i32> %305, <i32 6, i32 6, i32 6, i32 6>
  %307 = shufflevector <8 x i16> %293, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %308 = shufflevector <8 x i16> %296, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %309 = bitcast <8 x i16> %307 to <4 x i32>
  %310 = bitcast <8 x i16> %308 to <4 x i32>
  %311 = sub <4 x i32> %309, %310
  %312 = sub <4 x i32> zeroinitializer, %311
  %313 = icmp slt <4 x i32> %311, zeroinitializer
  %314 = select <4 x i1> %313, <4 x i32> %312, <4 x i32> %311
  %315 = add nuw <4 x i32> %314, <i32 32, i32 32, i32 32, i32 32>
  %316 = lshr <4 x i32> %315, <i32 6, i32 6, i32 6, i32 6>
  %317 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %306, <4 x i32> %316) #5
  %318 = lshr <8 x i16> %317, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %319 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %290, <8 x i16> %318) #5
  %320 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %319, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %321 = icmp slt <16 x i8> %320, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %322 = select <16 x i1> %321, <16 x i8> %320, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %323 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %322
  %324 = bitcast i8* %264 to <16 x i8>*
  store <16 x i8> %323, <16 x i8>* %324, align 16
  %325 = getelementptr inbounds i16, i16* %10, i64 80
  %326 = getelementptr inbounds i16, i16* %11, i64 80
  %327 = getelementptr inbounds i8, i8* %9, i64 80
  %328 = bitcast i16* %325 to <8 x i16>*
  %329 = load <8 x i16>, <8 x i16>* %328, align 16
  %330 = bitcast i16* %326 to <8 x i16>*
  %331 = load <8 x i16>, <8 x i16>* %330, align 16
  %332 = shufflevector <8 x i16> %329, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %333 = zext <4 x i16> %332 to <4 x i32>
  %334 = shufflevector <8 x i16> %331, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %335 = zext <4 x i16> %334 to <4 x i32>
  %336 = sub nsw <4 x i32> %333, %335
  %337 = sub nsw <4 x i32> zeroinitializer, %336
  %338 = icmp slt <4 x i32> %336, zeroinitializer
  %339 = select <4 x i1> %338, <4 x i32> %337, <4 x i32> %336
  %340 = add nuw nsw <4 x i32> %339, <i32 32, i32 32, i32 32, i32 32>
  %341 = lshr <4 x i32> %340, <i32 6, i32 6, i32 6, i32 6>
  %342 = shufflevector <8 x i16> %329, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %343 = shufflevector <8 x i16> %331, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %344 = bitcast <8 x i16> %342 to <4 x i32>
  %345 = bitcast <8 x i16> %343 to <4 x i32>
  %346 = sub <4 x i32> %344, %345
  %347 = sub <4 x i32> zeroinitializer, %346
  %348 = icmp slt <4 x i32> %346, zeroinitializer
  %349 = select <4 x i1> %348, <4 x i32> %347, <4 x i32> %346
  %350 = add nuw <4 x i32> %349, <i32 32, i32 32, i32 32, i32 32>
  %351 = lshr <4 x i32> %350, <i32 6, i32 6, i32 6, i32 6>
  %352 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %341, <4 x i32> %351) #5
  %353 = lshr <8 x i16> %352, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %354 = getelementptr inbounds i16, i16* %10, i64 88
  %355 = bitcast i16* %354 to <8 x i16>*
  %356 = load <8 x i16>, <8 x i16>* %355, align 16
  %357 = getelementptr inbounds i16, i16* %11, i64 88
  %358 = bitcast i16* %357 to <8 x i16>*
  %359 = load <8 x i16>, <8 x i16>* %358, align 16
  %360 = shufflevector <8 x i16> %356, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %361 = zext <4 x i16> %360 to <4 x i32>
  %362 = shufflevector <8 x i16> %359, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %363 = zext <4 x i16> %362 to <4 x i32>
  %364 = sub nsw <4 x i32> %361, %363
  %365 = sub nsw <4 x i32> zeroinitializer, %364
  %366 = icmp slt <4 x i32> %364, zeroinitializer
  %367 = select <4 x i1> %366, <4 x i32> %365, <4 x i32> %364
  %368 = add nuw nsw <4 x i32> %367, <i32 32, i32 32, i32 32, i32 32>
  %369 = lshr <4 x i32> %368, <i32 6, i32 6, i32 6, i32 6>
  %370 = shufflevector <8 x i16> %356, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %371 = shufflevector <8 x i16> %359, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %372 = bitcast <8 x i16> %370 to <4 x i32>
  %373 = bitcast <8 x i16> %371 to <4 x i32>
  %374 = sub <4 x i32> %372, %373
  %375 = sub <4 x i32> zeroinitializer, %374
  %376 = icmp slt <4 x i32> %374, zeroinitializer
  %377 = select <4 x i1> %376, <4 x i32> %375, <4 x i32> %374
  %378 = add nuw <4 x i32> %377, <i32 32, i32 32, i32 32, i32 32>
  %379 = lshr <4 x i32> %378, <i32 6, i32 6, i32 6, i32 6>
  %380 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %369, <4 x i32> %379) #5
  %381 = lshr <8 x i16> %380, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %382 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %353, <8 x i16> %381) #5
  %383 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %382, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %384 = icmp slt <16 x i8> %383, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %385 = select <16 x i1> %384, <16 x i8> %383, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %386 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %385
  %387 = bitcast i8* %327 to <16 x i8>*
  store <16 x i8> %386, <16 x i8>* %387, align 16
  %388 = getelementptr inbounds i16, i16* %10, i64 96
  %389 = getelementptr inbounds i16, i16* %11, i64 96
  %390 = getelementptr inbounds i8, i8* %9, i64 96
  %391 = bitcast i16* %388 to <8 x i16>*
  %392 = load <8 x i16>, <8 x i16>* %391, align 16
  %393 = bitcast i16* %389 to <8 x i16>*
  %394 = load <8 x i16>, <8 x i16>* %393, align 16
  %395 = shufflevector <8 x i16> %392, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %396 = zext <4 x i16> %395 to <4 x i32>
  %397 = shufflevector <8 x i16> %394, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %398 = zext <4 x i16> %397 to <4 x i32>
  %399 = sub nsw <4 x i32> %396, %398
  %400 = sub nsw <4 x i32> zeroinitializer, %399
  %401 = icmp slt <4 x i32> %399, zeroinitializer
  %402 = select <4 x i1> %401, <4 x i32> %400, <4 x i32> %399
  %403 = add nuw nsw <4 x i32> %402, <i32 32, i32 32, i32 32, i32 32>
  %404 = lshr <4 x i32> %403, <i32 6, i32 6, i32 6, i32 6>
  %405 = shufflevector <8 x i16> %392, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %406 = shufflevector <8 x i16> %394, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %407 = bitcast <8 x i16> %405 to <4 x i32>
  %408 = bitcast <8 x i16> %406 to <4 x i32>
  %409 = sub <4 x i32> %407, %408
  %410 = sub <4 x i32> zeroinitializer, %409
  %411 = icmp slt <4 x i32> %409, zeroinitializer
  %412 = select <4 x i1> %411, <4 x i32> %410, <4 x i32> %409
  %413 = add nuw <4 x i32> %412, <i32 32, i32 32, i32 32, i32 32>
  %414 = lshr <4 x i32> %413, <i32 6, i32 6, i32 6, i32 6>
  %415 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %404, <4 x i32> %414) #5
  %416 = lshr <8 x i16> %415, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %417 = getelementptr inbounds i16, i16* %10, i64 104
  %418 = bitcast i16* %417 to <8 x i16>*
  %419 = load <8 x i16>, <8 x i16>* %418, align 16
  %420 = getelementptr inbounds i16, i16* %11, i64 104
  %421 = bitcast i16* %420 to <8 x i16>*
  %422 = load <8 x i16>, <8 x i16>* %421, align 16
  %423 = shufflevector <8 x i16> %419, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %424 = zext <4 x i16> %423 to <4 x i32>
  %425 = shufflevector <8 x i16> %422, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %426 = zext <4 x i16> %425 to <4 x i32>
  %427 = sub nsw <4 x i32> %424, %426
  %428 = sub nsw <4 x i32> zeroinitializer, %427
  %429 = icmp slt <4 x i32> %427, zeroinitializer
  %430 = select <4 x i1> %429, <4 x i32> %428, <4 x i32> %427
  %431 = add nuw nsw <4 x i32> %430, <i32 32, i32 32, i32 32, i32 32>
  %432 = lshr <4 x i32> %431, <i32 6, i32 6, i32 6, i32 6>
  %433 = shufflevector <8 x i16> %419, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %434 = shufflevector <8 x i16> %422, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %435 = bitcast <8 x i16> %433 to <4 x i32>
  %436 = bitcast <8 x i16> %434 to <4 x i32>
  %437 = sub <4 x i32> %435, %436
  %438 = sub <4 x i32> zeroinitializer, %437
  %439 = icmp slt <4 x i32> %437, zeroinitializer
  %440 = select <4 x i1> %439, <4 x i32> %438, <4 x i32> %437
  %441 = add nuw <4 x i32> %440, <i32 32, i32 32, i32 32, i32 32>
  %442 = lshr <4 x i32> %441, <i32 6, i32 6, i32 6, i32 6>
  %443 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %432, <4 x i32> %442) #5
  %444 = lshr <8 x i16> %443, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %445 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %416, <8 x i16> %444) #5
  %446 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %445, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %447 = icmp slt <16 x i8> %446, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %448 = select <16 x i1> %447, <16 x i8> %446, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %449 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %448
  %450 = bitcast i8* %390 to <16 x i8>*
  store <16 x i8> %449, <16 x i8>* %450, align 16
  %451 = getelementptr inbounds i16, i16* %10, i64 112
  %452 = getelementptr inbounds i16, i16* %11, i64 112
  %453 = getelementptr inbounds i8, i8* %9, i64 112
  %454 = bitcast i16* %451 to <8 x i16>*
  %455 = load <8 x i16>, <8 x i16>* %454, align 16
  %456 = bitcast i16* %452 to <8 x i16>*
  %457 = load <8 x i16>, <8 x i16>* %456, align 16
  %458 = shufflevector <8 x i16> %455, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %459 = zext <4 x i16> %458 to <4 x i32>
  %460 = shufflevector <8 x i16> %457, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %461 = zext <4 x i16> %460 to <4 x i32>
  %462 = sub nsw <4 x i32> %459, %461
  %463 = sub nsw <4 x i32> zeroinitializer, %462
  %464 = icmp slt <4 x i32> %462, zeroinitializer
  %465 = select <4 x i1> %464, <4 x i32> %463, <4 x i32> %462
  %466 = add nuw nsw <4 x i32> %465, <i32 32, i32 32, i32 32, i32 32>
  %467 = lshr <4 x i32> %466, <i32 6, i32 6, i32 6, i32 6>
  %468 = shufflevector <8 x i16> %455, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %469 = shufflevector <8 x i16> %457, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %470 = bitcast <8 x i16> %468 to <4 x i32>
  %471 = bitcast <8 x i16> %469 to <4 x i32>
  %472 = sub <4 x i32> %470, %471
  %473 = sub <4 x i32> zeroinitializer, %472
  %474 = icmp slt <4 x i32> %472, zeroinitializer
  %475 = select <4 x i1> %474, <4 x i32> %473, <4 x i32> %472
  %476 = add nuw <4 x i32> %475, <i32 32, i32 32, i32 32, i32 32>
  %477 = lshr <4 x i32> %476, <i32 6, i32 6, i32 6, i32 6>
  %478 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %467, <4 x i32> %477) #5
  %479 = lshr <8 x i16> %478, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %480 = getelementptr inbounds i16, i16* %10, i64 120
  %481 = bitcast i16* %480 to <8 x i16>*
  %482 = load <8 x i16>, <8 x i16>* %481, align 16
  %483 = getelementptr inbounds i16, i16* %11, i64 120
  %484 = bitcast i16* %483 to <8 x i16>*
  %485 = load <8 x i16>, <8 x i16>* %484, align 16
  %486 = shufflevector <8 x i16> %482, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %487 = zext <4 x i16> %486 to <4 x i32>
  %488 = shufflevector <8 x i16> %485, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %489 = zext <4 x i16> %488 to <4 x i32>
  %490 = sub nsw <4 x i32> %487, %489
  %491 = sub nsw <4 x i32> zeroinitializer, %490
  %492 = icmp slt <4 x i32> %490, zeroinitializer
  %493 = select <4 x i1> %492, <4 x i32> %491, <4 x i32> %490
  %494 = add nuw nsw <4 x i32> %493, <i32 32, i32 32, i32 32, i32 32>
  %495 = lshr <4 x i32> %494, <i32 6, i32 6, i32 6, i32 6>
  %496 = shufflevector <8 x i16> %482, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %497 = shufflevector <8 x i16> %485, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %498 = bitcast <8 x i16> %496 to <4 x i32>
  %499 = bitcast <8 x i16> %497 to <4 x i32>
  %500 = sub <4 x i32> %498, %499
  %501 = sub <4 x i32> zeroinitializer, %500
  %502 = icmp slt <4 x i32> %500, zeroinitializer
  %503 = select <4 x i1> %502, <4 x i32> %501, <4 x i32> %500
  %504 = add nuw <4 x i32> %503, <i32 32, i32 32, i32 32, i32 32>
  %505 = lshr <4 x i32> %504, <i32 6, i32 6, i32 6, i32 6>
  %506 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %495, <4 x i32> %505) #5
  %507 = lshr <8 x i16> %506, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %508 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %479, <8 x i16> %507) #5
  %509 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %508, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %510 = icmp slt <16 x i8> %509, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %511 = select <16 x i1> %510, <16 x i8> %509, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %512 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %511
  %513 = bitcast i8* %453 to <16 x i8>*
  store <16 x i8> %512, <16 x i8>* %513, align 16
  %514 = getelementptr inbounds i16, i16* %10, i64 128
  %515 = getelementptr inbounds i16, i16* %11, i64 128
  %516 = getelementptr inbounds i8, i8* %9, i64 %3
  %517 = bitcast i16* %514 to <8 x i16>*
  %518 = load <8 x i16>, <8 x i16>* %517, align 16
  %519 = bitcast i16* %515 to <8 x i16>*
  %520 = load <8 x i16>, <8 x i16>* %519, align 16
  %521 = shufflevector <8 x i16> %518, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %522 = zext <4 x i16> %521 to <4 x i32>
  %523 = shufflevector <8 x i16> %520, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %524 = zext <4 x i16> %523 to <4 x i32>
  %525 = sub nsw <4 x i32> %522, %524
  %526 = sub nsw <4 x i32> zeroinitializer, %525
  %527 = icmp slt <4 x i32> %525, zeroinitializer
  %528 = select <4 x i1> %527, <4 x i32> %526, <4 x i32> %525
  %529 = add nuw nsw <4 x i32> %528, <i32 32, i32 32, i32 32, i32 32>
  %530 = lshr <4 x i32> %529, <i32 6, i32 6, i32 6, i32 6>
  %531 = shufflevector <8 x i16> %518, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %532 = shufflevector <8 x i16> %520, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %533 = bitcast <8 x i16> %531 to <4 x i32>
  %534 = bitcast <8 x i16> %532 to <4 x i32>
  %535 = sub <4 x i32> %533, %534
  %536 = sub <4 x i32> zeroinitializer, %535
  %537 = icmp slt <4 x i32> %535, zeroinitializer
  %538 = select <4 x i1> %537, <4 x i32> %536, <4 x i32> %535
  %539 = add nuw <4 x i32> %538, <i32 32, i32 32, i32 32, i32 32>
  %540 = lshr <4 x i32> %539, <i32 6, i32 6, i32 6, i32 6>
  %541 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %530, <4 x i32> %540) #5
  %542 = lshr <8 x i16> %541, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %543 = getelementptr inbounds i16, i16* %10, i64 136
  %544 = bitcast i16* %543 to <8 x i16>*
  %545 = load <8 x i16>, <8 x i16>* %544, align 16
  %546 = getelementptr inbounds i16, i16* %11, i64 136
  %547 = bitcast i16* %546 to <8 x i16>*
  %548 = load <8 x i16>, <8 x i16>* %547, align 16
  %549 = shufflevector <8 x i16> %545, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %550 = zext <4 x i16> %549 to <4 x i32>
  %551 = shufflevector <8 x i16> %548, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %552 = zext <4 x i16> %551 to <4 x i32>
  %553 = sub nsw <4 x i32> %550, %552
  %554 = sub nsw <4 x i32> zeroinitializer, %553
  %555 = icmp slt <4 x i32> %553, zeroinitializer
  %556 = select <4 x i1> %555, <4 x i32> %554, <4 x i32> %553
  %557 = add nuw nsw <4 x i32> %556, <i32 32, i32 32, i32 32, i32 32>
  %558 = lshr <4 x i32> %557, <i32 6, i32 6, i32 6, i32 6>
  %559 = shufflevector <8 x i16> %545, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %560 = shufflevector <8 x i16> %548, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %561 = bitcast <8 x i16> %559 to <4 x i32>
  %562 = bitcast <8 x i16> %560 to <4 x i32>
  %563 = sub <4 x i32> %561, %562
  %564 = sub <4 x i32> zeroinitializer, %563
  %565 = icmp slt <4 x i32> %563, zeroinitializer
  %566 = select <4 x i1> %565, <4 x i32> %564, <4 x i32> %563
  %567 = add nuw <4 x i32> %566, <i32 32, i32 32, i32 32, i32 32>
  %568 = lshr <4 x i32> %567, <i32 6, i32 6, i32 6, i32 6>
  %569 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %558, <4 x i32> %568) #5
  %570 = lshr <8 x i16> %569, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %571 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %542, <8 x i16> %570) #5
  %572 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %571, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %573 = icmp slt <16 x i8> %572, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %574 = select <16 x i1> %573, <16 x i8> %572, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %575 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %574
  %576 = bitcast i8* %516 to <16 x i8>*
  store <16 x i8> %575, <16 x i8>* %576, align 16
  %577 = getelementptr inbounds i16, i16* %10, i64 144
  %578 = getelementptr inbounds i16, i16* %11, i64 144
  %579 = getelementptr inbounds i8, i8* %516, i64 16
  %580 = bitcast i16* %577 to <8 x i16>*
  %581 = load <8 x i16>, <8 x i16>* %580, align 16
  %582 = bitcast i16* %578 to <8 x i16>*
  %583 = load <8 x i16>, <8 x i16>* %582, align 16
  %584 = shufflevector <8 x i16> %581, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %585 = zext <4 x i16> %584 to <4 x i32>
  %586 = shufflevector <8 x i16> %583, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %587 = zext <4 x i16> %586 to <4 x i32>
  %588 = sub nsw <4 x i32> %585, %587
  %589 = sub nsw <4 x i32> zeroinitializer, %588
  %590 = icmp slt <4 x i32> %588, zeroinitializer
  %591 = select <4 x i1> %590, <4 x i32> %589, <4 x i32> %588
  %592 = add nuw nsw <4 x i32> %591, <i32 32, i32 32, i32 32, i32 32>
  %593 = lshr <4 x i32> %592, <i32 6, i32 6, i32 6, i32 6>
  %594 = shufflevector <8 x i16> %581, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %595 = shufflevector <8 x i16> %583, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %596 = bitcast <8 x i16> %594 to <4 x i32>
  %597 = bitcast <8 x i16> %595 to <4 x i32>
  %598 = sub <4 x i32> %596, %597
  %599 = sub <4 x i32> zeroinitializer, %598
  %600 = icmp slt <4 x i32> %598, zeroinitializer
  %601 = select <4 x i1> %600, <4 x i32> %599, <4 x i32> %598
  %602 = add nuw <4 x i32> %601, <i32 32, i32 32, i32 32, i32 32>
  %603 = lshr <4 x i32> %602, <i32 6, i32 6, i32 6, i32 6>
  %604 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %593, <4 x i32> %603) #5
  %605 = lshr <8 x i16> %604, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %606 = getelementptr inbounds i16, i16* %10, i64 152
  %607 = bitcast i16* %606 to <8 x i16>*
  %608 = load <8 x i16>, <8 x i16>* %607, align 16
  %609 = getelementptr inbounds i16, i16* %11, i64 152
  %610 = bitcast i16* %609 to <8 x i16>*
  %611 = load <8 x i16>, <8 x i16>* %610, align 16
  %612 = shufflevector <8 x i16> %608, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %613 = zext <4 x i16> %612 to <4 x i32>
  %614 = shufflevector <8 x i16> %611, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %615 = zext <4 x i16> %614 to <4 x i32>
  %616 = sub nsw <4 x i32> %613, %615
  %617 = sub nsw <4 x i32> zeroinitializer, %616
  %618 = icmp slt <4 x i32> %616, zeroinitializer
  %619 = select <4 x i1> %618, <4 x i32> %617, <4 x i32> %616
  %620 = add nuw nsw <4 x i32> %619, <i32 32, i32 32, i32 32, i32 32>
  %621 = lshr <4 x i32> %620, <i32 6, i32 6, i32 6, i32 6>
  %622 = shufflevector <8 x i16> %608, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %623 = shufflevector <8 x i16> %611, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %624 = bitcast <8 x i16> %622 to <4 x i32>
  %625 = bitcast <8 x i16> %623 to <4 x i32>
  %626 = sub <4 x i32> %624, %625
  %627 = sub <4 x i32> zeroinitializer, %626
  %628 = icmp slt <4 x i32> %626, zeroinitializer
  %629 = select <4 x i1> %628, <4 x i32> %627, <4 x i32> %626
  %630 = add nuw <4 x i32> %629, <i32 32, i32 32, i32 32, i32 32>
  %631 = lshr <4 x i32> %630, <i32 6, i32 6, i32 6, i32 6>
  %632 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %621, <4 x i32> %631) #5
  %633 = lshr <8 x i16> %632, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %634 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %605, <8 x i16> %633) #5
  %635 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %634, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %636 = icmp slt <16 x i8> %635, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %637 = select <16 x i1> %636, <16 x i8> %635, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %638 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %637
  %639 = bitcast i8* %579 to <16 x i8>*
  store <16 x i8> %638, <16 x i8>* %639, align 16
  %640 = getelementptr inbounds i16, i16* %10, i64 160
  %641 = getelementptr inbounds i16, i16* %11, i64 160
  %642 = getelementptr inbounds i8, i8* %516, i64 32
  %643 = bitcast i16* %640 to <8 x i16>*
  %644 = load <8 x i16>, <8 x i16>* %643, align 16
  %645 = bitcast i16* %641 to <8 x i16>*
  %646 = load <8 x i16>, <8 x i16>* %645, align 16
  %647 = shufflevector <8 x i16> %644, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %648 = zext <4 x i16> %647 to <4 x i32>
  %649 = shufflevector <8 x i16> %646, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %650 = zext <4 x i16> %649 to <4 x i32>
  %651 = sub nsw <4 x i32> %648, %650
  %652 = sub nsw <4 x i32> zeroinitializer, %651
  %653 = icmp slt <4 x i32> %651, zeroinitializer
  %654 = select <4 x i1> %653, <4 x i32> %652, <4 x i32> %651
  %655 = add nuw nsw <4 x i32> %654, <i32 32, i32 32, i32 32, i32 32>
  %656 = lshr <4 x i32> %655, <i32 6, i32 6, i32 6, i32 6>
  %657 = shufflevector <8 x i16> %644, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %658 = shufflevector <8 x i16> %646, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %659 = bitcast <8 x i16> %657 to <4 x i32>
  %660 = bitcast <8 x i16> %658 to <4 x i32>
  %661 = sub <4 x i32> %659, %660
  %662 = sub <4 x i32> zeroinitializer, %661
  %663 = icmp slt <4 x i32> %661, zeroinitializer
  %664 = select <4 x i1> %663, <4 x i32> %662, <4 x i32> %661
  %665 = add nuw <4 x i32> %664, <i32 32, i32 32, i32 32, i32 32>
  %666 = lshr <4 x i32> %665, <i32 6, i32 6, i32 6, i32 6>
  %667 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %656, <4 x i32> %666) #5
  %668 = lshr <8 x i16> %667, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %669 = getelementptr inbounds i16, i16* %10, i64 168
  %670 = bitcast i16* %669 to <8 x i16>*
  %671 = load <8 x i16>, <8 x i16>* %670, align 16
  %672 = getelementptr inbounds i16, i16* %11, i64 168
  %673 = bitcast i16* %672 to <8 x i16>*
  %674 = load <8 x i16>, <8 x i16>* %673, align 16
  %675 = shufflevector <8 x i16> %671, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %676 = zext <4 x i16> %675 to <4 x i32>
  %677 = shufflevector <8 x i16> %674, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %678 = zext <4 x i16> %677 to <4 x i32>
  %679 = sub nsw <4 x i32> %676, %678
  %680 = sub nsw <4 x i32> zeroinitializer, %679
  %681 = icmp slt <4 x i32> %679, zeroinitializer
  %682 = select <4 x i1> %681, <4 x i32> %680, <4 x i32> %679
  %683 = add nuw nsw <4 x i32> %682, <i32 32, i32 32, i32 32, i32 32>
  %684 = lshr <4 x i32> %683, <i32 6, i32 6, i32 6, i32 6>
  %685 = shufflevector <8 x i16> %671, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %686 = shufflevector <8 x i16> %674, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %687 = bitcast <8 x i16> %685 to <4 x i32>
  %688 = bitcast <8 x i16> %686 to <4 x i32>
  %689 = sub <4 x i32> %687, %688
  %690 = sub <4 x i32> zeroinitializer, %689
  %691 = icmp slt <4 x i32> %689, zeroinitializer
  %692 = select <4 x i1> %691, <4 x i32> %690, <4 x i32> %689
  %693 = add nuw <4 x i32> %692, <i32 32, i32 32, i32 32, i32 32>
  %694 = lshr <4 x i32> %693, <i32 6, i32 6, i32 6, i32 6>
  %695 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %684, <4 x i32> %694) #5
  %696 = lshr <8 x i16> %695, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %697 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %668, <8 x i16> %696) #5
  %698 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %697, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %699 = icmp slt <16 x i8> %698, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %700 = select <16 x i1> %699, <16 x i8> %698, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %701 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %700
  %702 = bitcast i8* %642 to <16 x i8>*
  store <16 x i8> %701, <16 x i8>* %702, align 16
  %703 = getelementptr inbounds i16, i16* %10, i64 176
  %704 = getelementptr inbounds i16, i16* %11, i64 176
  %705 = getelementptr inbounds i8, i8* %516, i64 48
  %706 = bitcast i16* %703 to <8 x i16>*
  %707 = load <8 x i16>, <8 x i16>* %706, align 16
  %708 = bitcast i16* %704 to <8 x i16>*
  %709 = load <8 x i16>, <8 x i16>* %708, align 16
  %710 = shufflevector <8 x i16> %707, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %711 = zext <4 x i16> %710 to <4 x i32>
  %712 = shufflevector <8 x i16> %709, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %713 = zext <4 x i16> %712 to <4 x i32>
  %714 = sub nsw <4 x i32> %711, %713
  %715 = sub nsw <4 x i32> zeroinitializer, %714
  %716 = icmp slt <4 x i32> %714, zeroinitializer
  %717 = select <4 x i1> %716, <4 x i32> %715, <4 x i32> %714
  %718 = add nuw nsw <4 x i32> %717, <i32 32, i32 32, i32 32, i32 32>
  %719 = lshr <4 x i32> %718, <i32 6, i32 6, i32 6, i32 6>
  %720 = shufflevector <8 x i16> %707, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %721 = shufflevector <8 x i16> %709, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %722 = bitcast <8 x i16> %720 to <4 x i32>
  %723 = bitcast <8 x i16> %721 to <4 x i32>
  %724 = sub <4 x i32> %722, %723
  %725 = sub <4 x i32> zeroinitializer, %724
  %726 = icmp slt <4 x i32> %724, zeroinitializer
  %727 = select <4 x i1> %726, <4 x i32> %725, <4 x i32> %724
  %728 = add nuw <4 x i32> %727, <i32 32, i32 32, i32 32, i32 32>
  %729 = lshr <4 x i32> %728, <i32 6, i32 6, i32 6, i32 6>
  %730 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %719, <4 x i32> %729) #5
  %731 = lshr <8 x i16> %730, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %732 = getelementptr inbounds i16, i16* %10, i64 184
  %733 = bitcast i16* %732 to <8 x i16>*
  %734 = load <8 x i16>, <8 x i16>* %733, align 16
  %735 = getelementptr inbounds i16, i16* %11, i64 184
  %736 = bitcast i16* %735 to <8 x i16>*
  %737 = load <8 x i16>, <8 x i16>* %736, align 16
  %738 = shufflevector <8 x i16> %734, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %739 = zext <4 x i16> %738 to <4 x i32>
  %740 = shufflevector <8 x i16> %737, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %741 = zext <4 x i16> %740 to <4 x i32>
  %742 = sub nsw <4 x i32> %739, %741
  %743 = sub nsw <4 x i32> zeroinitializer, %742
  %744 = icmp slt <4 x i32> %742, zeroinitializer
  %745 = select <4 x i1> %744, <4 x i32> %743, <4 x i32> %742
  %746 = add nuw nsw <4 x i32> %745, <i32 32, i32 32, i32 32, i32 32>
  %747 = lshr <4 x i32> %746, <i32 6, i32 6, i32 6, i32 6>
  %748 = shufflevector <8 x i16> %734, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %749 = shufflevector <8 x i16> %737, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %750 = bitcast <8 x i16> %748 to <4 x i32>
  %751 = bitcast <8 x i16> %749 to <4 x i32>
  %752 = sub <4 x i32> %750, %751
  %753 = sub <4 x i32> zeroinitializer, %752
  %754 = icmp slt <4 x i32> %752, zeroinitializer
  %755 = select <4 x i1> %754, <4 x i32> %753, <4 x i32> %752
  %756 = add nuw <4 x i32> %755, <i32 32, i32 32, i32 32, i32 32>
  %757 = lshr <4 x i32> %756, <i32 6, i32 6, i32 6, i32 6>
  %758 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %747, <4 x i32> %757) #5
  %759 = lshr <8 x i16> %758, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %760 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %731, <8 x i16> %759) #5
  %761 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %760, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %762 = icmp slt <16 x i8> %761, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %763 = select <16 x i1> %762, <16 x i8> %761, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %764 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %763
  %765 = bitcast i8* %705 to <16 x i8>*
  store <16 x i8> %764, <16 x i8>* %765, align 16
  %766 = getelementptr inbounds i16, i16* %10, i64 192
  %767 = getelementptr inbounds i16, i16* %11, i64 192
  %768 = getelementptr inbounds i8, i8* %516, i64 64
  %769 = bitcast i16* %766 to <8 x i16>*
  %770 = load <8 x i16>, <8 x i16>* %769, align 16
  %771 = bitcast i16* %767 to <8 x i16>*
  %772 = load <8 x i16>, <8 x i16>* %771, align 16
  %773 = shufflevector <8 x i16> %770, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %774 = zext <4 x i16> %773 to <4 x i32>
  %775 = shufflevector <8 x i16> %772, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %776 = zext <4 x i16> %775 to <4 x i32>
  %777 = sub nsw <4 x i32> %774, %776
  %778 = sub nsw <4 x i32> zeroinitializer, %777
  %779 = icmp slt <4 x i32> %777, zeroinitializer
  %780 = select <4 x i1> %779, <4 x i32> %778, <4 x i32> %777
  %781 = add nuw nsw <4 x i32> %780, <i32 32, i32 32, i32 32, i32 32>
  %782 = lshr <4 x i32> %781, <i32 6, i32 6, i32 6, i32 6>
  %783 = shufflevector <8 x i16> %770, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %784 = shufflevector <8 x i16> %772, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %785 = bitcast <8 x i16> %783 to <4 x i32>
  %786 = bitcast <8 x i16> %784 to <4 x i32>
  %787 = sub <4 x i32> %785, %786
  %788 = sub <4 x i32> zeroinitializer, %787
  %789 = icmp slt <4 x i32> %787, zeroinitializer
  %790 = select <4 x i1> %789, <4 x i32> %788, <4 x i32> %787
  %791 = add nuw <4 x i32> %790, <i32 32, i32 32, i32 32, i32 32>
  %792 = lshr <4 x i32> %791, <i32 6, i32 6, i32 6, i32 6>
  %793 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %782, <4 x i32> %792) #5
  %794 = lshr <8 x i16> %793, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %795 = getelementptr inbounds i16, i16* %10, i64 200
  %796 = bitcast i16* %795 to <8 x i16>*
  %797 = load <8 x i16>, <8 x i16>* %796, align 16
  %798 = getelementptr inbounds i16, i16* %11, i64 200
  %799 = bitcast i16* %798 to <8 x i16>*
  %800 = load <8 x i16>, <8 x i16>* %799, align 16
  %801 = shufflevector <8 x i16> %797, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %802 = zext <4 x i16> %801 to <4 x i32>
  %803 = shufflevector <8 x i16> %800, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %804 = zext <4 x i16> %803 to <4 x i32>
  %805 = sub nsw <4 x i32> %802, %804
  %806 = sub nsw <4 x i32> zeroinitializer, %805
  %807 = icmp slt <4 x i32> %805, zeroinitializer
  %808 = select <4 x i1> %807, <4 x i32> %806, <4 x i32> %805
  %809 = add nuw nsw <4 x i32> %808, <i32 32, i32 32, i32 32, i32 32>
  %810 = lshr <4 x i32> %809, <i32 6, i32 6, i32 6, i32 6>
  %811 = shufflevector <8 x i16> %797, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %812 = shufflevector <8 x i16> %800, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %813 = bitcast <8 x i16> %811 to <4 x i32>
  %814 = bitcast <8 x i16> %812 to <4 x i32>
  %815 = sub <4 x i32> %813, %814
  %816 = sub <4 x i32> zeroinitializer, %815
  %817 = icmp slt <4 x i32> %815, zeroinitializer
  %818 = select <4 x i1> %817, <4 x i32> %816, <4 x i32> %815
  %819 = add nuw <4 x i32> %818, <i32 32, i32 32, i32 32, i32 32>
  %820 = lshr <4 x i32> %819, <i32 6, i32 6, i32 6, i32 6>
  %821 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %810, <4 x i32> %820) #5
  %822 = lshr <8 x i16> %821, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %823 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %794, <8 x i16> %822) #5
  %824 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %823, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %825 = icmp slt <16 x i8> %824, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %826 = select <16 x i1> %825, <16 x i8> %824, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %827 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %826
  %828 = bitcast i8* %768 to <16 x i8>*
  store <16 x i8> %827, <16 x i8>* %828, align 16
  %829 = getelementptr inbounds i16, i16* %10, i64 208
  %830 = getelementptr inbounds i16, i16* %11, i64 208
  %831 = getelementptr inbounds i8, i8* %768, i64 16
  %832 = bitcast i16* %829 to <8 x i16>*
  %833 = load <8 x i16>, <8 x i16>* %832, align 16
  %834 = bitcast i16* %830 to <8 x i16>*
  %835 = load <8 x i16>, <8 x i16>* %834, align 16
  %836 = shufflevector <8 x i16> %833, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %837 = zext <4 x i16> %836 to <4 x i32>
  %838 = shufflevector <8 x i16> %835, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %839 = zext <4 x i16> %838 to <4 x i32>
  %840 = sub nsw <4 x i32> %837, %839
  %841 = sub nsw <4 x i32> zeroinitializer, %840
  %842 = icmp slt <4 x i32> %840, zeroinitializer
  %843 = select <4 x i1> %842, <4 x i32> %841, <4 x i32> %840
  %844 = add nuw nsw <4 x i32> %843, <i32 32, i32 32, i32 32, i32 32>
  %845 = lshr <4 x i32> %844, <i32 6, i32 6, i32 6, i32 6>
  %846 = shufflevector <8 x i16> %833, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %847 = shufflevector <8 x i16> %835, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %848 = bitcast <8 x i16> %846 to <4 x i32>
  %849 = bitcast <8 x i16> %847 to <4 x i32>
  %850 = sub <4 x i32> %848, %849
  %851 = sub <4 x i32> zeroinitializer, %850
  %852 = icmp slt <4 x i32> %850, zeroinitializer
  %853 = select <4 x i1> %852, <4 x i32> %851, <4 x i32> %850
  %854 = add nuw <4 x i32> %853, <i32 32, i32 32, i32 32, i32 32>
  %855 = lshr <4 x i32> %854, <i32 6, i32 6, i32 6, i32 6>
  %856 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %845, <4 x i32> %855) #5
  %857 = lshr <8 x i16> %856, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %858 = getelementptr inbounds i16, i16* %10, i64 216
  %859 = bitcast i16* %858 to <8 x i16>*
  %860 = load <8 x i16>, <8 x i16>* %859, align 16
  %861 = getelementptr inbounds i16, i16* %11, i64 216
  %862 = bitcast i16* %861 to <8 x i16>*
  %863 = load <8 x i16>, <8 x i16>* %862, align 16
  %864 = shufflevector <8 x i16> %860, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %865 = zext <4 x i16> %864 to <4 x i32>
  %866 = shufflevector <8 x i16> %863, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %867 = zext <4 x i16> %866 to <4 x i32>
  %868 = sub nsw <4 x i32> %865, %867
  %869 = sub nsw <4 x i32> zeroinitializer, %868
  %870 = icmp slt <4 x i32> %868, zeroinitializer
  %871 = select <4 x i1> %870, <4 x i32> %869, <4 x i32> %868
  %872 = add nuw nsw <4 x i32> %871, <i32 32, i32 32, i32 32, i32 32>
  %873 = lshr <4 x i32> %872, <i32 6, i32 6, i32 6, i32 6>
  %874 = shufflevector <8 x i16> %860, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %875 = shufflevector <8 x i16> %863, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %876 = bitcast <8 x i16> %874 to <4 x i32>
  %877 = bitcast <8 x i16> %875 to <4 x i32>
  %878 = sub <4 x i32> %876, %877
  %879 = sub <4 x i32> zeroinitializer, %878
  %880 = icmp slt <4 x i32> %878, zeroinitializer
  %881 = select <4 x i1> %880, <4 x i32> %879, <4 x i32> %878
  %882 = add nuw <4 x i32> %881, <i32 32, i32 32, i32 32, i32 32>
  %883 = lshr <4 x i32> %882, <i32 6, i32 6, i32 6, i32 6>
  %884 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %873, <4 x i32> %883) #5
  %885 = lshr <8 x i16> %884, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %886 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %857, <8 x i16> %885) #5
  %887 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %886, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %888 = icmp slt <16 x i8> %887, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %889 = select <16 x i1> %888, <16 x i8> %887, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %890 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %889
  %891 = bitcast i8* %831 to <16 x i8>*
  store <16 x i8> %890, <16 x i8>* %891, align 16
  %892 = getelementptr inbounds i16, i16* %10, i64 224
  %893 = getelementptr inbounds i16, i16* %11, i64 224
  %894 = getelementptr inbounds i8, i8* %768, i64 32
  %895 = bitcast i16* %892 to <8 x i16>*
  %896 = load <8 x i16>, <8 x i16>* %895, align 16
  %897 = bitcast i16* %893 to <8 x i16>*
  %898 = load <8 x i16>, <8 x i16>* %897, align 16
  %899 = shufflevector <8 x i16> %896, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %900 = zext <4 x i16> %899 to <4 x i32>
  %901 = shufflevector <8 x i16> %898, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %902 = zext <4 x i16> %901 to <4 x i32>
  %903 = sub nsw <4 x i32> %900, %902
  %904 = sub nsw <4 x i32> zeroinitializer, %903
  %905 = icmp slt <4 x i32> %903, zeroinitializer
  %906 = select <4 x i1> %905, <4 x i32> %904, <4 x i32> %903
  %907 = add nuw nsw <4 x i32> %906, <i32 32, i32 32, i32 32, i32 32>
  %908 = lshr <4 x i32> %907, <i32 6, i32 6, i32 6, i32 6>
  %909 = shufflevector <8 x i16> %896, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %910 = shufflevector <8 x i16> %898, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %911 = bitcast <8 x i16> %909 to <4 x i32>
  %912 = bitcast <8 x i16> %910 to <4 x i32>
  %913 = sub <4 x i32> %911, %912
  %914 = sub <4 x i32> zeroinitializer, %913
  %915 = icmp slt <4 x i32> %913, zeroinitializer
  %916 = select <4 x i1> %915, <4 x i32> %914, <4 x i32> %913
  %917 = add nuw <4 x i32> %916, <i32 32, i32 32, i32 32, i32 32>
  %918 = lshr <4 x i32> %917, <i32 6, i32 6, i32 6, i32 6>
  %919 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %908, <4 x i32> %918) #5
  %920 = lshr <8 x i16> %919, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %921 = getelementptr inbounds i16, i16* %10, i64 232
  %922 = bitcast i16* %921 to <8 x i16>*
  %923 = load <8 x i16>, <8 x i16>* %922, align 16
  %924 = getelementptr inbounds i16, i16* %11, i64 232
  %925 = bitcast i16* %924 to <8 x i16>*
  %926 = load <8 x i16>, <8 x i16>* %925, align 16
  %927 = shufflevector <8 x i16> %923, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %928 = zext <4 x i16> %927 to <4 x i32>
  %929 = shufflevector <8 x i16> %926, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %930 = zext <4 x i16> %929 to <4 x i32>
  %931 = sub nsw <4 x i32> %928, %930
  %932 = sub nsw <4 x i32> zeroinitializer, %931
  %933 = icmp slt <4 x i32> %931, zeroinitializer
  %934 = select <4 x i1> %933, <4 x i32> %932, <4 x i32> %931
  %935 = add nuw nsw <4 x i32> %934, <i32 32, i32 32, i32 32, i32 32>
  %936 = lshr <4 x i32> %935, <i32 6, i32 6, i32 6, i32 6>
  %937 = shufflevector <8 x i16> %923, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %938 = shufflevector <8 x i16> %926, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %939 = bitcast <8 x i16> %937 to <4 x i32>
  %940 = bitcast <8 x i16> %938 to <4 x i32>
  %941 = sub <4 x i32> %939, %940
  %942 = sub <4 x i32> zeroinitializer, %941
  %943 = icmp slt <4 x i32> %941, zeroinitializer
  %944 = select <4 x i1> %943, <4 x i32> %942, <4 x i32> %941
  %945 = add nuw <4 x i32> %944, <i32 32, i32 32, i32 32, i32 32>
  %946 = lshr <4 x i32> %945, <i32 6, i32 6, i32 6, i32 6>
  %947 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %936, <4 x i32> %946) #5
  %948 = lshr <8 x i16> %947, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %949 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %920, <8 x i16> %948) #5
  %950 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %949, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %951 = icmp slt <16 x i8> %950, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %952 = select <16 x i1> %951, <16 x i8> %950, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %953 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %952
  %954 = bitcast i8* %894 to <16 x i8>*
  store <16 x i8> %953, <16 x i8>* %954, align 16
  %955 = getelementptr inbounds i16, i16* %10, i64 240
  %956 = getelementptr inbounds i16, i16* %11, i64 240
  %957 = getelementptr inbounds i8, i8* %768, i64 48
  %958 = bitcast i16* %955 to <8 x i16>*
  %959 = load <8 x i16>, <8 x i16>* %958, align 16
  %960 = bitcast i16* %956 to <8 x i16>*
  %961 = load <8 x i16>, <8 x i16>* %960, align 16
  %962 = shufflevector <8 x i16> %959, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %963 = zext <4 x i16> %962 to <4 x i32>
  %964 = shufflevector <8 x i16> %961, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %965 = zext <4 x i16> %964 to <4 x i32>
  %966 = sub nsw <4 x i32> %963, %965
  %967 = sub nsw <4 x i32> zeroinitializer, %966
  %968 = icmp slt <4 x i32> %966, zeroinitializer
  %969 = select <4 x i1> %968, <4 x i32> %967, <4 x i32> %966
  %970 = add nuw nsw <4 x i32> %969, <i32 32, i32 32, i32 32, i32 32>
  %971 = lshr <4 x i32> %970, <i32 6, i32 6, i32 6, i32 6>
  %972 = shufflevector <8 x i16> %959, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %973 = shufflevector <8 x i16> %961, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %974 = bitcast <8 x i16> %972 to <4 x i32>
  %975 = bitcast <8 x i16> %973 to <4 x i32>
  %976 = sub <4 x i32> %974, %975
  %977 = sub <4 x i32> zeroinitializer, %976
  %978 = icmp slt <4 x i32> %976, zeroinitializer
  %979 = select <4 x i1> %978, <4 x i32> %977, <4 x i32> %976
  %980 = add nuw <4 x i32> %979, <i32 32, i32 32, i32 32, i32 32>
  %981 = lshr <4 x i32> %980, <i32 6, i32 6, i32 6, i32 6>
  %982 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %971, <4 x i32> %981) #5
  %983 = lshr <8 x i16> %982, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %984 = getelementptr inbounds i16, i16* %10, i64 248
  %985 = bitcast i16* %984 to <8 x i16>*
  %986 = load <8 x i16>, <8 x i16>* %985, align 16
  %987 = getelementptr inbounds i16, i16* %11, i64 248
  %988 = bitcast i16* %987 to <8 x i16>*
  %989 = load <8 x i16>, <8 x i16>* %988, align 16
  %990 = shufflevector <8 x i16> %986, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %991 = zext <4 x i16> %990 to <4 x i32>
  %992 = shufflevector <8 x i16> %989, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %993 = zext <4 x i16> %992 to <4 x i32>
  %994 = sub nsw <4 x i32> %991, %993
  %995 = sub nsw <4 x i32> zeroinitializer, %994
  %996 = icmp slt <4 x i32> %994, zeroinitializer
  %997 = select <4 x i1> %996, <4 x i32> %995, <4 x i32> %994
  %998 = add nuw nsw <4 x i32> %997, <i32 32, i32 32, i32 32, i32 32>
  %999 = lshr <4 x i32> %998, <i32 6, i32 6, i32 6, i32 6>
  %1000 = shufflevector <8 x i16> %986, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1001 = shufflevector <8 x i16> %989, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1002 = bitcast <8 x i16> %1000 to <4 x i32>
  %1003 = bitcast <8 x i16> %1001 to <4 x i32>
  %1004 = sub <4 x i32> %1002, %1003
  %1005 = sub <4 x i32> zeroinitializer, %1004
  %1006 = icmp slt <4 x i32> %1004, zeroinitializer
  %1007 = select <4 x i1> %1006, <4 x i32> %1005, <4 x i32> %1004
  %1008 = add nuw <4 x i32> %1007, <i32 32, i32 32, i32 32, i32 32>
  %1009 = lshr <4 x i32> %1008, <i32 6, i32 6, i32 6, i32 6>
  %1010 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %999, <4 x i32> %1009) #5
  %1011 = lshr <8 x i16> %1010, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1012 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %983, <8 x i16> %1011) #5
  %1013 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1012, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1014 = icmp slt <16 x i8> %1013, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1015 = select <16 x i1> %1014, <16 x i8> %1013, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1016 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1015
  %1017 = bitcast i8* %957 to <16 x i8>*
  store <16 x i8> %1016, <16 x i8>* %1017, align 16
  %1018 = getelementptr inbounds i16, i16* %10, i64 256
  %1019 = getelementptr inbounds i16, i16* %11, i64 256
  %1020 = getelementptr inbounds i8, i8* %768, i64 %7
  %1021 = bitcast i16* %1018 to <8 x i16>*
  %1022 = load <8 x i16>, <8 x i16>* %1021, align 16
  %1023 = bitcast i16* %1019 to <8 x i16>*
  %1024 = load <8 x i16>, <8 x i16>* %1023, align 16
  %1025 = shufflevector <8 x i16> %1022, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1026 = zext <4 x i16> %1025 to <4 x i32>
  %1027 = shufflevector <8 x i16> %1024, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1028 = zext <4 x i16> %1027 to <4 x i32>
  %1029 = sub nsw <4 x i32> %1026, %1028
  %1030 = sub nsw <4 x i32> zeroinitializer, %1029
  %1031 = icmp slt <4 x i32> %1029, zeroinitializer
  %1032 = select <4 x i1> %1031, <4 x i32> %1030, <4 x i32> %1029
  %1033 = add nuw nsw <4 x i32> %1032, <i32 32, i32 32, i32 32, i32 32>
  %1034 = lshr <4 x i32> %1033, <i32 6, i32 6, i32 6, i32 6>
  %1035 = shufflevector <8 x i16> %1022, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1036 = shufflevector <8 x i16> %1024, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1037 = bitcast <8 x i16> %1035 to <4 x i32>
  %1038 = bitcast <8 x i16> %1036 to <4 x i32>
  %1039 = sub <4 x i32> %1037, %1038
  %1040 = sub <4 x i32> zeroinitializer, %1039
  %1041 = icmp slt <4 x i32> %1039, zeroinitializer
  %1042 = select <4 x i1> %1041, <4 x i32> %1040, <4 x i32> %1039
  %1043 = add nuw <4 x i32> %1042, <i32 32, i32 32, i32 32, i32 32>
  %1044 = lshr <4 x i32> %1043, <i32 6, i32 6, i32 6, i32 6>
  %1045 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1034, <4 x i32> %1044) #5
  %1046 = lshr <8 x i16> %1045, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1047 = getelementptr inbounds i16, i16* %10, i64 264
  %1048 = bitcast i16* %1047 to <8 x i16>*
  %1049 = load <8 x i16>, <8 x i16>* %1048, align 16
  %1050 = getelementptr inbounds i16, i16* %11, i64 264
  %1051 = bitcast i16* %1050 to <8 x i16>*
  %1052 = load <8 x i16>, <8 x i16>* %1051, align 16
  %1053 = shufflevector <8 x i16> %1049, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1054 = zext <4 x i16> %1053 to <4 x i32>
  %1055 = shufflevector <8 x i16> %1052, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1056 = zext <4 x i16> %1055 to <4 x i32>
  %1057 = sub nsw <4 x i32> %1054, %1056
  %1058 = sub nsw <4 x i32> zeroinitializer, %1057
  %1059 = icmp slt <4 x i32> %1057, zeroinitializer
  %1060 = select <4 x i1> %1059, <4 x i32> %1058, <4 x i32> %1057
  %1061 = add nuw nsw <4 x i32> %1060, <i32 32, i32 32, i32 32, i32 32>
  %1062 = lshr <4 x i32> %1061, <i32 6, i32 6, i32 6, i32 6>
  %1063 = shufflevector <8 x i16> %1049, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1064 = shufflevector <8 x i16> %1052, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1065 = bitcast <8 x i16> %1063 to <4 x i32>
  %1066 = bitcast <8 x i16> %1064 to <4 x i32>
  %1067 = sub <4 x i32> %1065, %1066
  %1068 = sub <4 x i32> zeroinitializer, %1067
  %1069 = icmp slt <4 x i32> %1067, zeroinitializer
  %1070 = select <4 x i1> %1069, <4 x i32> %1068, <4 x i32> %1067
  %1071 = add nuw <4 x i32> %1070, <i32 32, i32 32, i32 32, i32 32>
  %1072 = lshr <4 x i32> %1071, <i32 6, i32 6, i32 6, i32 6>
  %1073 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1062, <4 x i32> %1072) #5
  %1074 = lshr <8 x i16> %1073, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1075 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1046, <8 x i16> %1074) #5
  %1076 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1075, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1077 = icmp slt <16 x i8> %1076, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1078 = select <16 x i1> %1077, <16 x i8> %1076, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1079 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1078
  %1080 = bitcast i8* %1020 to <16 x i8>*
  store <16 x i8> %1079, <16 x i8>* %1080, align 16
  %1081 = getelementptr inbounds i16, i16* %10, i64 272
  %1082 = getelementptr inbounds i16, i16* %11, i64 272
  %1083 = getelementptr inbounds i8, i8* %1020, i64 16
  %1084 = bitcast i16* %1081 to <8 x i16>*
  %1085 = load <8 x i16>, <8 x i16>* %1084, align 16
  %1086 = bitcast i16* %1082 to <8 x i16>*
  %1087 = load <8 x i16>, <8 x i16>* %1086, align 16
  %1088 = shufflevector <8 x i16> %1085, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1089 = zext <4 x i16> %1088 to <4 x i32>
  %1090 = shufflevector <8 x i16> %1087, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1091 = zext <4 x i16> %1090 to <4 x i32>
  %1092 = sub nsw <4 x i32> %1089, %1091
  %1093 = sub nsw <4 x i32> zeroinitializer, %1092
  %1094 = icmp slt <4 x i32> %1092, zeroinitializer
  %1095 = select <4 x i1> %1094, <4 x i32> %1093, <4 x i32> %1092
  %1096 = add nuw nsw <4 x i32> %1095, <i32 32, i32 32, i32 32, i32 32>
  %1097 = lshr <4 x i32> %1096, <i32 6, i32 6, i32 6, i32 6>
  %1098 = shufflevector <8 x i16> %1085, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1099 = shufflevector <8 x i16> %1087, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1100 = bitcast <8 x i16> %1098 to <4 x i32>
  %1101 = bitcast <8 x i16> %1099 to <4 x i32>
  %1102 = sub <4 x i32> %1100, %1101
  %1103 = sub <4 x i32> zeroinitializer, %1102
  %1104 = icmp slt <4 x i32> %1102, zeroinitializer
  %1105 = select <4 x i1> %1104, <4 x i32> %1103, <4 x i32> %1102
  %1106 = add nuw <4 x i32> %1105, <i32 32, i32 32, i32 32, i32 32>
  %1107 = lshr <4 x i32> %1106, <i32 6, i32 6, i32 6, i32 6>
  %1108 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1097, <4 x i32> %1107) #5
  %1109 = lshr <8 x i16> %1108, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1110 = getelementptr inbounds i16, i16* %10, i64 280
  %1111 = bitcast i16* %1110 to <8 x i16>*
  %1112 = load <8 x i16>, <8 x i16>* %1111, align 16
  %1113 = getelementptr inbounds i16, i16* %11, i64 280
  %1114 = bitcast i16* %1113 to <8 x i16>*
  %1115 = load <8 x i16>, <8 x i16>* %1114, align 16
  %1116 = shufflevector <8 x i16> %1112, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1117 = zext <4 x i16> %1116 to <4 x i32>
  %1118 = shufflevector <8 x i16> %1115, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1119 = zext <4 x i16> %1118 to <4 x i32>
  %1120 = sub nsw <4 x i32> %1117, %1119
  %1121 = sub nsw <4 x i32> zeroinitializer, %1120
  %1122 = icmp slt <4 x i32> %1120, zeroinitializer
  %1123 = select <4 x i1> %1122, <4 x i32> %1121, <4 x i32> %1120
  %1124 = add nuw nsw <4 x i32> %1123, <i32 32, i32 32, i32 32, i32 32>
  %1125 = lshr <4 x i32> %1124, <i32 6, i32 6, i32 6, i32 6>
  %1126 = shufflevector <8 x i16> %1112, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1127 = shufflevector <8 x i16> %1115, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1128 = bitcast <8 x i16> %1126 to <4 x i32>
  %1129 = bitcast <8 x i16> %1127 to <4 x i32>
  %1130 = sub <4 x i32> %1128, %1129
  %1131 = sub <4 x i32> zeroinitializer, %1130
  %1132 = icmp slt <4 x i32> %1130, zeroinitializer
  %1133 = select <4 x i1> %1132, <4 x i32> %1131, <4 x i32> %1130
  %1134 = add nuw <4 x i32> %1133, <i32 32, i32 32, i32 32, i32 32>
  %1135 = lshr <4 x i32> %1134, <i32 6, i32 6, i32 6, i32 6>
  %1136 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1125, <4 x i32> %1135) #5
  %1137 = lshr <8 x i16> %1136, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1138 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1109, <8 x i16> %1137) #5
  %1139 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1138, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1140 = icmp slt <16 x i8> %1139, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1141 = select <16 x i1> %1140, <16 x i8> %1139, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1142 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1141
  %1143 = bitcast i8* %1083 to <16 x i8>*
  store <16 x i8> %1142, <16 x i8>* %1143, align 16
  %1144 = getelementptr inbounds i16, i16* %10, i64 288
  %1145 = getelementptr inbounds i16, i16* %11, i64 288
  %1146 = getelementptr inbounds i8, i8* %1020, i64 32
  %1147 = bitcast i16* %1144 to <8 x i16>*
  %1148 = load <8 x i16>, <8 x i16>* %1147, align 16
  %1149 = bitcast i16* %1145 to <8 x i16>*
  %1150 = load <8 x i16>, <8 x i16>* %1149, align 16
  %1151 = shufflevector <8 x i16> %1148, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1152 = zext <4 x i16> %1151 to <4 x i32>
  %1153 = shufflevector <8 x i16> %1150, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1154 = zext <4 x i16> %1153 to <4 x i32>
  %1155 = sub nsw <4 x i32> %1152, %1154
  %1156 = sub nsw <4 x i32> zeroinitializer, %1155
  %1157 = icmp slt <4 x i32> %1155, zeroinitializer
  %1158 = select <4 x i1> %1157, <4 x i32> %1156, <4 x i32> %1155
  %1159 = add nuw nsw <4 x i32> %1158, <i32 32, i32 32, i32 32, i32 32>
  %1160 = lshr <4 x i32> %1159, <i32 6, i32 6, i32 6, i32 6>
  %1161 = shufflevector <8 x i16> %1148, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1162 = shufflevector <8 x i16> %1150, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1163 = bitcast <8 x i16> %1161 to <4 x i32>
  %1164 = bitcast <8 x i16> %1162 to <4 x i32>
  %1165 = sub <4 x i32> %1163, %1164
  %1166 = sub <4 x i32> zeroinitializer, %1165
  %1167 = icmp slt <4 x i32> %1165, zeroinitializer
  %1168 = select <4 x i1> %1167, <4 x i32> %1166, <4 x i32> %1165
  %1169 = add nuw <4 x i32> %1168, <i32 32, i32 32, i32 32, i32 32>
  %1170 = lshr <4 x i32> %1169, <i32 6, i32 6, i32 6, i32 6>
  %1171 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1160, <4 x i32> %1170) #5
  %1172 = lshr <8 x i16> %1171, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1173 = getelementptr inbounds i16, i16* %10, i64 296
  %1174 = bitcast i16* %1173 to <8 x i16>*
  %1175 = load <8 x i16>, <8 x i16>* %1174, align 16
  %1176 = getelementptr inbounds i16, i16* %11, i64 296
  %1177 = bitcast i16* %1176 to <8 x i16>*
  %1178 = load <8 x i16>, <8 x i16>* %1177, align 16
  %1179 = shufflevector <8 x i16> %1175, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1180 = zext <4 x i16> %1179 to <4 x i32>
  %1181 = shufflevector <8 x i16> %1178, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1182 = zext <4 x i16> %1181 to <4 x i32>
  %1183 = sub nsw <4 x i32> %1180, %1182
  %1184 = sub nsw <4 x i32> zeroinitializer, %1183
  %1185 = icmp slt <4 x i32> %1183, zeroinitializer
  %1186 = select <4 x i1> %1185, <4 x i32> %1184, <4 x i32> %1183
  %1187 = add nuw nsw <4 x i32> %1186, <i32 32, i32 32, i32 32, i32 32>
  %1188 = lshr <4 x i32> %1187, <i32 6, i32 6, i32 6, i32 6>
  %1189 = shufflevector <8 x i16> %1175, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1190 = shufflevector <8 x i16> %1178, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1191 = bitcast <8 x i16> %1189 to <4 x i32>
  %1192 = bitcast <8 x i16> %1190 to <4 x i32>
  %1193 = sub <4 x i32> %1191, %1192
  %1194 = sub <4 x i32> zeroinitializer, %1193
  %1195 = icmp slt <4 x i32> %1193, zeroinitializer
  %1196 = select <4 x i1> %1195, <4 x i32> %1194, <4 x i32> %1193
  %1197 = add nuw <4 x i32> %1196, <i32 32, i32 32, i32 32, i32 32>
  %1198 = lshr <4 x i32> %1197, <i32 6, i32 6, i32 6, i32 6>
  %1199 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1188, <4 x i32> %1198) #5
  %1200 = lshr <8 x i16> %1199, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1201 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1172, <8 x i16> %1200) #5
  %1202 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1201, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1203 = icmp slt <16 x i8> %1202, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1204 = select <16 x i1> %1203, <16 x i8> %1202, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1205 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1204
  %1206 = bitcast i8* %1146 to <16 x i8>*
  store <16 x i8> %1205, <16 x i8>* %1206, align 16
  %1207 = getelementptr inbounds i16, i16* %10, i64 304
  %1208 = getelementptr inbounds i16, i16* %11, i64 304
  %1209 = getelementptr inbounds i8, i8* %1020, i64 48
  %1210 = bitcast i16* %1207 to <8 x i16>*
  %1211 = load <8 x i16>, <8 x i16>* %1210, align 16
  %1212 = bitcast i16* %1208 to <8 x i16>*
  %1213 = load <8 x i16>, <8 x i16>* %1212, align 16
  %1214 = shufflevector <8 x i16> %1211, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1215 = zext <4 x i16> %1214 to <4 x i32>
  %1216 = shufflevector <8 x i16> %1213, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1217 = zext <4 x i16> %1216 to <4 x i32>
  %1218 = sub nsw <4 x i32> %1215, %1217
  %1219 = sub nsw <4 x i32> zeroinitializer, %1218
  %1220 = icmp slt <4 x i32> %1218, zeroinitializer
  %1221 = select <4 x i1> %1220, <4 x i32> %1219, <4 x i32> %1218
  %1222 = add nuw nsw <4 x i32> %1221, <i32 32, i32 32, i32 32, i32 32>
  %1223 = lshr <4 x i32> %1222, <i32 6, i32 6, i32 6, i32 6>
  %1224 = shufflevector <8 x i16> %1211, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1225 = shufflevector <8 x i16> %1213, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1226 = bitcast <8 x i16> %1224 to <4 x i32>
  %1227 = bitcast <8 x i16> %1225 to <4 x i32>
  %1228 = sub <4 x i32> %1226, %1227
  %1229 = sub <4 x i32> zeroinitializer, %1228
  %1230 = icmp slt <4 x i32> %1228, zeroinitializer
  %1231 = select <4 x i1> %1230, <4 x i32> %1229, <4 x i32> %1228
  %1232 = add nuw <4 x i32> %1231, <i32 32, i32 32, i32 32, i32 32>
  %1233 = lshr <4 x i32> %1232, <i32 6, i32 6, i32 6, i32 6>
  %1234 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1223, <4 x i32> %1233) #5
  %1235 = lshr <8 x i16> %1234, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1236 = getelementptr inbounds i16, i16* %10, i64 312
  %1237 = bitcast i16* %1236 to <8 x i16>*
  %1238 = load <8 x i16>, <8 x i16>* %1237, align 16
  %1239 = getelementptr inbounds i16, i16* %11, i64 312
  %1240 = bitcast i16* %1239 to <8 x i16>*
  %1241 = load <8 x i16>, <8 x i16>* %1240, align 16
  %1242 = shufflevector <8 x i16> %1238, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1243 = zext <4 x i16> %1242 to <4 x i32>
  %1244 = shufflevector <8 x i16> %1241, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1245 = zext <4 x i16> %1244 to <4 x i32>
  %1246 = sub nsw <4 x i32> %1243, %1245
  %1247 = sub nsw <4 x i32> zeroinitializer, %1246
  %1248 = icmp slt <4 x i32> %1246, zeroinitializer
  %1249 = select <4 x i1> %1248, <4 x i32> %1247, <4 x i32> %1246
  %1250 = add nuw nsw <4 x i32> %1249, <i32 32, i32 32, i32 32, i32 32>
  %1251 = lshr <4 x i32> %1250, <i32 6, i32 6, i32 6, i32 6>
  %1252 = shufflevector <8 x i16> %1238, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1253 = shufflevector <8 x i16> %1241, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1254 = bitcast <8 x i16> %1252 to <4 x i32>
  %1255 = bitcast <8 x i16> %1253 to <4 x i32>
  %1256 = sub <4 x i32> %1254, %1255
  %1257 = sub <4 x i32> zeroinitializer, %1256
  %1258 = icmp slt <4 x i32> %1256, zeroinitializer
  %1259 = select <4 x i1> %1258, <4 x i32> %1257, <4 x i32> %1256
  %1260 = add nuw <4 x i32> %1259, <i32 32, i32 32, i32 32, i32 32>
  %1261 = lshr <4 x i32> %1260, <i32 6, i32 6, i32 6, i32 6>
  %1262 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1251, <4 x i32> %1261) #5
  %1263 = lshr <8 x i16> %1262, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1264 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1235, <8 x i16> %1263) #5
  %1265 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1264, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1266 = icmp slt <16 x i8> %1265, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1267 = select <16 x i1> %1266, <16 x i8> %1265, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1268 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1267
  %1269 = bitcast i8* %1209 to <16 x i8>*
  store <16 x i8> %1268, <16 x i8>* %1269, align 16
  %1270 = getelementptr inbounds i16, i16* %10, i64 320
  %1271 = getelementptr inbounds i16, i16* %11, i64 320
  %1272 = getelementptr inbounds i8, i8* %1020, i64 64
  %1273 = bitcast i16* %1270 to <8 x i16>*
  %1274 = load <8 x i16>, <8 x i16>* %1273, align 16
  %1275 = bitcast i16* %1271 to <8 x i16>*
  %1276 = load <8 x i16>, <8 x i16>* %1275, align 16
  %1277 = shufflevector <8 x i16> %1274, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1278 = zext <4 x i16> %1277 to <4 x i32>
  %1279 = shufflevector <8 x i16> %1276, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1280 = zext <4 x i16> %1279 to <4 x i32>
  %1281 = sub nsw <4 x i32> %1278, %1280
  %1282 = sub nsw <4 x i32> zeroinitializer, %1281
  %1283 = icmp slt <4 x i32> %1281, zeroinitializer
  %1284 = select <4 x i1> %1283, <4 x i32> %1282, <4 x i32> %1281
  %1285 = add nuw nsw <4 x i32> %1284, <i32 32, i32 32, i32 32, i32 32>
  %1286 = lshr <4 x i32> %1285, <i32 6, i32 6, i32 6, i32 6>
  %1287 = shufflevector <8 x i16> %1274, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1288 = shufflevector <8 x i16> %1276, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1289 = bitcast <8 x i16> %1287 to <4 x i32>
  %1290 = bitcast <8 x i16> %1288 to <4 x i32>
  %1291 = sub <4 x i32> %1289, %1290
  %1292 = sub <4 x i32> zeroinitializer, %1291
  %1293 = icmp slt <4 x i32> %1291, zeroinitializer
  %1294 = select <4 x i1> %1293, <4 x i32> %1292, <4 x i32> %1291
  %1295 = add nuw <4 x i32> %1294, <i32 32, i32 32, i32 32, i32 32>
  %1296 = lshr <4 x i32> %1295, <i32 6, i32 6, i32 6, i32 6>
  %1297 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1286, <4 x i32> %1296) #5
  %1298 = lshr <8 x i16> %1297, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1299 = getelementptr inbounds i16, i16* %10, i64 328
  %1300 = bitcast i16* %1299 to <8 x i16>*
  %1301 = load <8 x i16>, <8 x i16>* %1300, align 16
  %1302 = getelementptr inbounds i16, i16* %11, i64 328
  %1303 = bitcast i16* %1302 to <8 x i16>*
  %1304 = load <8 x i16>, <8 x i16>* %1303, align 16
  %1305 = shufflevector <8 x i16> %1301, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1306 = zext <4 x i16> %1305 to <4 x i32>
  %1307 = shufflevector <8 x i16> %1304, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1308 = zext <4 x i16> %1307 to <4 x i32>
  %1309 = sub nsw <4 x i32> %1306, %1308
  %1310 = sub nsw <4 x i32> zeroinitializer, %1309
  %1311 = icmp slt <4 x i32> %1309, zeroinitializer
  %1312 = select <4 x i1> %1311, <4 x i32> %1310, <4 x i32> %1309
  %1313 = add nuw nsw <4 x i32> %1312, <i32 32, i32 32, i32 32, i32 32>
  %1314 = lshr <4 x i32> %1313, <i32 6, i32 6, i32 6, i32 6>
  %1315 = shufflevector <8 x i16> %1301, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1316 = shufflevector <8 x i16> %1304, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1317 = bitcast <8 x i16> %1315 to <4 x i32>
  %1318 = bitcast <8 x i16> %1316 to <4 x i32>
  %1319 = sub <4 x i32> %1317, %1318
  %1320 = sub <4 x i32> zeroinitializer, %1319
  %1321 = icmp slt <4 x i32> %1319, zeroinitializer
  %1322 = select <4 x i1> %1321, <4 x i32> %1320, <4 x i32> %1319
  %1323 = add nuw <4 x i32> %1322, <i32 32, i32 32, i32 32, i32 32>
  %1324 = lshr <4 x i32> %1323, <i32 6, i32 6, i32 6, i32 6>
  %1325 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1314, <4 x i32> %1324) #5
  %1326 = lshr <8 x i16> %1325, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1327 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1298, <8 x i16> %1326) #5
  %1328 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1327, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1329 = icmp slt <16 x i8> %1328, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1330 = select <16 x i1> %1329, <16 x i8> %1328, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1331 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1330
  %1332 = bitcast i8* %1272 to <16 x i8>*
  store <16 x i8> %1331, <16 x i8>* %1332, align 16
  %1333 = getelementptr inbounds i16, i16* %10, i64 336
  %1334 = getelementptr inbounds i16, i16* %11, i64 336
  %1335 = getelementptr inbounds i8, i8* %1272, i64 16
  %1336 = bitcast i16* %1333 to <8 x i16>*
  %1337 = load <8 x i16>, <8 x i16>* %1336, align 16
  %1338 = bitcast i16* %1334 to <8 x i16>*
  %1339 = load <8 x i16>, <8 x i16>* %1338, align 16
  %1340 = shufflevector <8 x i16> %1337, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1341 = zext <4 x i16> %1340 to <4 x i32>
  %1342 = shufflevector <8 x i16> %1339, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1343 = zext <4 x i16> %1342 to <4 x i32>
  %1344 = sub nsw <4 x i32> %1341, %1343
  %1345 = sub nsw <4 x i32> zeroinitializer, %1344
  %1346 = icmp slt <4 x i32> %1344, zeroinitializer
  %1347 = select <4 x i1> %1346, <4 x i32> %1345, <4 x i32> %1344
  %1348 = add nuw nsw <4 x i32> %1347, <i32 32, i32 32, i32 32, i32 32>
  %1349 = lshr <4 x i32> %1348, <i32 6, i32 6, i32 6, i32 6>
  %1350 = shufflevector <8 x i16> %1337, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1351 = shufflevector <8 x i16> %1339, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1352 = bitcast <8 x i16> %1350 to <4 x i32>
  %1353 = bitcast <8 x i16> %1351 to <4 x i32>
  %1354 = sub <4 x i32> %1352, %1353
  %1355 = sub <4 x i32> zeroinitializer, %1354
  %1356 = icmp slt <4 x i32> %1354, zeroinitializer
  %1357 = select <4 x i1> %1356, <4 x i32> %1355, <4 x i32> %1354
  %1358 = add nuw <4 x i32> %1357, <i32 32, i32 32, i32 32, i32 32>
  %1359 = lshr <4 x i32> %1358, <i32 6, i32 6, i32 6, i32 6>
  %1360 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1349, <4 x i32> %1359) #5
  %1361 = lshr <8 x i16> %1360, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1362 = getelementptr inbounds i16, i16* %10, i64 344
  %1363 = bitcast i16* %1362 to <8 x i16>*
  %1364 = load <8 x i16>, <8 x i16>* %1363, align 16
  %1365 = getelementptr inbounds i16, i16* %11, i64 344
  %1366 = bitcast i16* %1365 to <8 x i16>*
  %1367 = load <8 x i16>, <8 x i16>* %1366, align 16
  %1368 = shufflevector <8 x i16> %1364, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1369 = zext <4 x i16> %1368 to <4 x i32>
  %1370 = shufflevector <8 x i16> %1367, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1371 = zext <4 x i16> %1370 to <4 x i32>
  %1372 = sub nsw <4 x i32> %1369, %1371
  %1373 = sub nsw <4 x i32> zeroinitializer, %1372
  %1374 = icmp slt <4 x i32> %1372, zeroinitializer
  %1375 = select <4 x i1> %1374, <4 x i32> %1373, <4 x i32> %1372
  %1376 = add nuw nsw <4 x i32> %1375, <i32 32, i32 32, i32 32, i32 32>
  %1377 = lshr <4 x i32> %1376, <i32 6, i32 6, i32 6, i32 6>
  %1378 = shufflevector <8 x i16> %1364, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1379 = shufflevector <8 x i16> %1367, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1380 = bitcast <8 x i16> %1378 to <4 x i32>
  %1381 = bitcast <8 x i16> %1379 to <4 x i32>
  %1382 = sub <4 x i32> %1380, %1381
  %1383 = sub <4 x i32> zeroinitializer, %1382
  %1384 = icmp slt <4 x i32> %1382, zeroinitializer
  %1385 = select <4 x i1> %1384, <4 x i32> %1383, <4 x i32> %1382
  %1386 = add nuw <4 x i32> %1385, <i32 32, i32 32, i32 32, i32 32>
  %1387 = lshr <4 x i32> %1386, <i32 6, i32 6, i32 6, i32 6>
  %1388 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1377, <4 x i32> %1387) #5
  %1389 = lshr <8 x i16> %1388, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1390 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1361, <8 x i16> %1389) #5
  %1391 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1390, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1392 = icmp slt <16 x i8> %1391, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1393 = select <16 x i1> %1392, <16 x i8> %1391, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1394 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1393
  %1395 = bitcast i8* %1335 to <16 x i8>*
  store <16 x i8> %1394, <16 x i8>* %1395, align 16
  %1396 = getelementptr inbounds i16, i16* %10, i64 352
  %1397 = getelementptr inbounds i16, i16* %11, i64 352
  %1398 = getelementptr inbounds i8, i8* %1272, i64 32
  %1399 = bitcast i16* %1396 to <8 x i16>*
  %1400 = load <8 x i16>, <8 x i16>* %1399, align 16
  %1401 = bitcast i16* %1397 to <8 x i16>*
  %1402 = load <8 x i16>, <8 x i16>* %1401, align 16
  %1403 = shufflevector <8 x i16> %1400, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1404 = zext <4 x i16> %1403 to <4 x i32>
  %1405 = shufflevector <8 x i16> %1402, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1406 = zext <4 x i16> %1405 to <4 x i32>
  %1407 = sub nsw <4 x i32> %1404, %1406
  %1408 = sub nsw <4 x i32> zeroinitializer, %1407
  %1409 = icmp slt <4 x i32> %1407, zeroinitializer
  %1410 = select <4 x i1> %1409, <4 x i32> %1408, <4 x i32> %1407
  %1411 = add nuw nsw <4 x i32> %1410, <i32 32, i32 32, i32 32, i32 32>
  %1412 = lshr <4 x i32> %1411, <i32 6, i32 6, i32 6, i32 6>
  %1413 = shufflevector <8 x i16> %1400, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1414 = shufflevector <8 x i16> %1402, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1415 = bitcast <8 x i16> %1413 to <4 x i32>
  %1416 = bitcast <8 x i16> %1414 to <4 x i32>
  %1417 = sub <4 x i32> %1415, %1416
  %1418 = sub <4 x i32> zeroinitializer, %1417
  %1419 = icmp slt <4 x i32> %1417, zeroinitializer
  %1420 = select <4 x i1> %1419, <4 x i32> %1418, <4 x i32> %1417
  %1421 = add nuw <4 x i32> %1420, <i32 32, i32 32, i32 32, i32 32>
  %1422 = lshr <4 x i32> %1421, <i32 6, i32 6, i32 6, i32 6>
  %1423 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1412, <4 x i32> %1422) #5
  %1424 = lshr <8 x i16> %1423, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1425 = getelementptr inbounds i16, i16* %10, i64 360
  %1426 = bitcast i16* %1425 to <8 x i16>*
  %1427 = load <8 x i16>, <8 x i16>* %1426, align 16
  %1428 = getelementptr inbounds i16, i16* %11, i64 360
  %1429 = bitcast i16* %1428 to <8 x i16>*
  %1430 = load <8 x i16>, <8 x i16>* %1429, align 16
  %1431 = shufflevector <8 x i16> %1427, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1432 = zext <4 x i16> %1431 to <4 x i32>
  %1433 = shufflevector <8 x i16> %1430, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1434 = zext <4 x i16> %1433 to <4 x i32>
  %1435 = sub nsw <4 x i32> %1432, %1434
  %1436 = sub nsw <4 x i32> zeroinitializer, %1435
  %1437 = icmp slt <4 x i32> %1435, zeroinitializer
  %1438 = select <4 x i1> %1437, <4 x i32> %1436, <4 x i32> %1435
  %1439 = add nuw nsw <4 x i32> %1438, <i32 32, i32 32, i32 32, i32 32>
  %1440 = lshr <4 x i32> %1439, <i32 6, i32 6, i32 6, i32 6>
  %1441 = shufflevector <8 x i16> %1427, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1442 = shufflevector <8 x i16> %1430, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1443 = bitcast <8 x i16> %1441 to <4 x i32>
  %1444 = bitcast <8 x i16> %1442 to <4 x i32>
  %1445 = sub <4 x i32> %1443, %1444
  %1446 = sub <4 x i32> zeroinitializer, %1445
  %1447 = icmp slt <4 x i32> %1445, zeroinitializer
  %1448 = select <4 x i1> %1447, <4 x i32> %1446, <4 x i32> %1445
  %1449 = add nuw <4 x i32> %1448, <i32 32, i32 32, i32 32, i32 32>
  %1450 = lshr <4 x i32> %1449, <i32 6, i32 6, i32 6, i32 6>
  %1451 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1440, <4 x i32> %1450) #5
  %1452 = lshr <8 x i16> %1451, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1453 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1424, <8 x i16> %1452) #5
  %1454 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1453, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1455 = icmp slt <16 x i8> %1454, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1456 = select <16 x i1> %1455, <16 x i8> %1454, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1457 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1456
  %1458 = bitcast i8* %1398 to <16 x i8>*
  store <16 x i8> %1457, <16 x i8>* %1458, align 16
  %1459 = getelementptr inbounds i16, i16* %10, i64 368
  %1460 = getelementptr inbounds i16, i16* %11, i64 368
  %1461 = getelementptr inbounds i8, i8* %1272, i64 48
  %1462 = bitcast i16* %1459 to <8 x i16>*
  %1463 = load <8 x i16>, <8 x i16>* %1462, align 16
  %1464 = bitcast i16* %1460 to <8 x i16>*
  %1465 = load <8 x i16>, <8 x i16>* %1464, align 16
  %1466 = shufflevector <8 x i16> %1463, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1467 = zext <4 x i16> %1466 to <4 x i32>
  %1468 = shufflevector <8 x i16> %1465, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1469 = zext <4 x i16> %1468 to <4 x i32>
  %1470 = sub nsw <4 x i32> %1467, %1469
  %1471 = sub nsw <4 x i32> zeroinitializer, %1470
  %1472 = icmp slt <4 x i32> %1470, zeroinitializer
  %1473 = select <4 x i1> %1472, <4 x i32> %1471, <4 x i32> %1470
  %1474 = add nuw nsw <4 x i32> %1473, <i32 32, i32 32, i32 32, i32 32>
  %1475 = lshr <4 x i32> %1474, <i32 6, i32 6, i32 6, i32 6>
  %1476 = shufflevector <8 x i16> %1463, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1477 = shufflevector <8 x i16> %1465, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1478 = bitcast <8 x i16> %1476 to <4 x i32>
  %1479 = bitcast <8 x i16> %1477 to <4 x i32>
  %1480 = sub <4 x i32> %1478, %1479
  %1481 = sub <4 x i32> zeroinitializer, %1480
  %1482 = icmp slt <4 x i32> %1480, zeroinitializer
  %1483 = select <4 x i1> %1482, <4 x i32> %1481, <4 x i32> %1480
  %1484 = add nuw <4 x i32> %1483, <i32 32, i32 32, i32 32, i32 32>
  %1485 = lshr <4 x i32> %1484, <i32 6, i32 6, i32 6, i32 6>
  %1486 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1475, <4 x i32> %1485) #5
  %1487 = lshr <8 x i16> %1486, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1488 = getelementptr inbounds i16, i16* %10, i64 376
  %1489 = bitcast i16* %1488 to <8 x i16>*
  %1490 = load <8 x i16>, <8 x i16>* %1489, align 16
  %1491 = getelementptr inbounds i16, i16* %11, i64 376
  %1492 = bitcast i16* %1491 to <8 x i16>*
  %1493 = load <8 x i16>, <8 x i16>* %1492, align 16
  %1494 = shufflevector <8 x i16> %1490, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1495 = zext <4 x i16> %1494 to <4 x i32>
  %1496 = shufflevector <8 x i16> %1493, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1497 = zext <4 x i16> %1496 to <4 x i32>
  %1498 = sub nsw <4 x i32> %1495, %1497
  %1499 = sub nsw <4 x i32> zeroinitializer, %1498
  %1500 = icmp slt <4 x i32> %1498, zeroinitializer
  %1501 = select <4 x i1> %1500, <4 x i32> %1499, <4 x i32> %1498
  %1502 = add nuw nsw <4 x i32> %1501, <i32 32, i32 32, i32 32, i32 32>
  %1503 = lshr <4 x i32> %1502, <i32 6, i32 6, i32 6, i32 6>
  %1504 = shufflevector <8 x i16> %1490, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1505 = shufflevector <8 x i16> %1493, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1506 = bitcast <8 x i16> %1504 to <4 x i32>
  %1507 = bitcast <8 x i16> %1505 to <4 x i32>
  %1508 = sub <4 x i32> %1506, %1507
  %1509 = sub <4 x i32> zeroinitializer, %1508
  %1510 = icmp slt <4 x i32> %1508, zeroinitializer
  %1511 = select <4 x i1> %1510, <4 x i32> %1509, <4 x i32> %1508
  %1512 = add nuw <4 x i32> %1511, <i32 32, i32 32, i32 32, i32 32>
  %1513 = lshr <4 x i32> %1512, <i32 6, i32 6, i32 6, i32 6>
  %1514 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1503, <4 x i32> %1513) #5
  %1515 = lshr <8 x i16> %1514, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1516 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1487, <8 x i16> %1515) #5
  %1517 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1516, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1518 = icmp slt <16 x i8> %1517, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1519 = select <16 x i1> %1518, <16 x i8> %1517, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1520 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1519
  %1521 = bitcast i8* %1461 to <16 x i8>*
  store <16 x i8> %1520, <16 x i8>* %1521, align 16
  %1522 = getelementptr inbounds i16, i16* %10, i64 384
  %1523 = getelementptr inbounds i16, i16* %11, i64 384
  %1524 = getelementptr inbounds i8, i8* %1272, i64 %7
  %1525 = add nsw i32 %12, -1
  %1526 = icmp eq i32 %1525, 0
  br i1 %1526, label %1527, label %8

1527:                                             ; preds = %8
  %1528 = bitcast i16* %1522 to <8 x i16>*
  %1529 = load <8 x i16>, <8 x i16>* %1528, align 16
  %1530 = bitcast i16* %1523 to <8 x i16>*
  %1531 = load <8 x i16>, <8 x i16>* %1530, align 16
  %1532 = shufflevector <8 x i16> %1529, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1533 = zext <4 x i16> %1532 to <4 x i32>
  %1534 = shufflevector <8 x i16> %1531, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1535 = zext <4 x i16> %1534 to <4 x i32>
  %1536 = sub nsw <4 x i32> %1533, %1535
  %1537 = sub nsw <4 x i32> zeroinitializer, %1536
  %1538 = icmp slt <4 x i32> %1536, zeroinitializer
  %1539 = select <4 x i1> %1538, <4 x i32> %1537, <4 x i32> %1536
  %1540 = add nuw nsw <4 x i32> %1539, <i32 32, i32 32, i32 32, i32 32>
  %1541 = lshr <4 x i32> %1540, <i32 6, i32 6, i32 6, i32 6>
  %1542 = shufflevector <8 x i16> %1529, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1543 = shufflevector <8 x i16> %1531, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1544 = bitcast <8 x i16> %1542 to <4 x i32>
  %1545 = bitcast <8 x i16> %1543 to <4 x i32>
  %1546 = sub <4 x i32> %1544, %1545
  %1547 = sub <4 x i32> zeroinitializer, %1546
  %1548 = icmp slt <4 x i32> %1546, zeroinitializer
  %1549 = select <4 x i1> %1548, <4 x i32> %1547, <4 x i32> %1546
  %1550 = add nuw <4 x i32> %1549, <i32 32, i32 32, i32 32, i32 32>
  %1551 = lshr <4 x i32> %1550, <i32 6, i32 6, i32 6, i32 6>
  %1552 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1541, <4 x i32> %1551) #5
  %1553 = lshr <8 x i16> %1552, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1554 = getelementptr inbounds i16, i16* %10, i64 392
  %1555 = bitcast i16* %1554 to <8 x i16>*
  %1556 = load <8 x i16>, <8 x i16>* %1555, align 16
  %1557 = getelementptr inbounds i16, i16* %11, i64 392
  %1558 = bitcast i16* %1557 to <8 x i16>*
  %1559 = load <8 x i16>, <8 x i16>* %1558, align 16
  %1560 = shufflevector <8 x i16> %1556, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1561 = zext <4 x i16> %1560 to <4 x i32>
  %1562 = shufflevector <8 x i16> %1559, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1563 = zext <4 x i16> %1562 to <4 x i32>
  %1564 = sub nsw <4 x i32> %1561, %1563
  %1565 = sub nsw <4 x i32> zeroinitializer, %1564
  %1566 = icmp slt <4 x i32> %1564, zeroinitializer
  %1567 = select <4 x i1> %1566, <4 x i32> %1565, <4 x i32> %1564
  %1568 = add nuw nsw <4 x i32> %1567, <i32 32, i32 32, i32 32, i32 32>
  %1569 = lshr <4 x i32> %1568, <i32 6, i32 6, i32 6, i32 6>
  %1570 = shufflevector <8 x i16> %1556, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1571 = shufflevector <8 x i16> %1559, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1572 = bitcast <8 x i16> %1570 to <4 x i32>
  %1573 = bitcast <8 x i16> %1571 to <4 x i32>
  %1574 = sub <4 x i32> %1572, %1573
  %1575 = sub <4 x i32> zeroinitializer, %1574
  %1576 = icmp slt <4 x i32> %1574, zeroinitializer
  %1577 = select <4 x i1> %1576, <4 x i32> %1575, <4 x i32> %1574
  %1578 = add nuw <4 x i32> %1577, <i32 32, i32 32, i32 32, i32 32>
  %1579 = lshr <4 x i32> %1578, <i32 6, i32 6, i32 6, i32 6>
  %1580 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1569, <4 x i32> %1579) #5
  %1581 = lshr <8 x i16> %1580, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1582 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1553, <8 x i16> %1581) #5
  %1583 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1582, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1584 = icmp slt <16 x i8> %1583, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1585 = select <16 x i1> %1584, <16 x i8> %1583, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1586 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1585
  %1587 = bitcast i8* %1524 to <16 x i8>*
  store <16 x i8> %1586, <16 x i8>* %1587, align 16
  %1588 = getelementptr inbounds i16, i16* %10, i64 400
  %1589 = getelementptr inbounds i16, i16* %11, i64 400
  %1590 = getelementptr inbounds i8, i8* %1524, i64 16
  %1591 = bitcast i16* %1588 to <8 x i16>*
  %1592 = load <8 x i16>, <8 x i16>* %1591, align 16
  %1593 = bitcast i16* %1589 to <8 x i16>*
  %1594 = load <8 x i16>, <8 x i16>* %1593, align 16
  %1595 = shufflevector <8 x i16> %1592, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1596 = zext <4 x i16> %1595 to <4 x i32>
  %1597 = shufflevector <8 x i16> %1594, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1598 = zext <4 x i16> %1597 to <4 x i32>
  %1599 = sub nsw <4 x i32> %1596, %1598
  %1600 = sub nsw <4 x i32> zeroinitializer, %1599
  %1601 = icmp slt <4 x i32> %1599, zeroinitializer
  %1602 = select <4 x i1> %1601, <4 x i32> %1600, <4 x i32> %1599
  %1603 = add nuw nsw <4 x i32> %1602, <i32 32, i32 32, i32 32, i32 32>
  %1604 = lshr <4 x i32> %1603, <i32 6, i32 6, i32 6, i32 6>
  %1605 = shufflevector <8 x i16> %1592, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1606 = shufflevector <8 x i16> %1594, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1607 = bitcast <8 x i16> %1605 to <4 x i32>
  %1608 = bitcast <8 x i16> %1606 to <4 x i32>
  %1609 = sub <4 x i32> %1607, %1608
  %1610 = sub <4 x i32> zeroinitializer, %1609
  %1611 = icmp slt <4 x i32> %1609, zeroinitializer
  %1612 = select <4 x i1> %1611, <4 x i32> %1610, <4 x i32> %1609
  %1613 = add nuw <4 x i32> %1612, <i32 32, i32 32, i32 32, i32 32>
  %1614 = lshr <4 x i32> %1613, <i32 6, i32 6, i32 6, i32 6>
  %1615 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1604, <4 x i32> %1614) #5
  %1616 = lshr <8 x i16> %1615, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1617 = getelementptr inbounds i16, i16* %10, i64 408
  %1618 = bitcast i16* %1617 to <8 x i16>*
  %1619 = load <8 x i16>, <8 x i16>* %1618, align 16
  %1620 = getelementptr inbounds i16, i16* %11, i64 408
  %1621 = bitcast i16* %1620 to <8 x i16>*
  %1622 = load <8 x i16>, <8 x i16>* %1621, align 16
  %1623 = shufflevector <8 x i16> %1619, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1624 = zext <4 x i16> %1623 to <4 x i32>
  %1625 = shufflevector <8 x i16> %1622, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1626 = zext <4 x i16> %1625 to <4 x i32>
  %1627 = sub nsw <4 x i32> %1624, %1626
  %1628 = sub nsw <4 x i32> zeroinitializer, %1627
  %1629 = icmp slt <4 x i32> %1627, zeroinitializer
  %1630 = select <4 x i1> %1629, <4 x i32> %1628, <4 x i32> %1627
  %1631 = add nuw nsw <4 x i32> %1630, <i32 32, i32 32, i32 32, i32 32>
  %1632 = lshr <4 x i32> %1631, <i32 6, i32 6, i32 6, i32 6>
  %1633 = shufflevector <8 x i16> %1619, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1634 = shufflevector <8 x i16> %1622, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1635 = bitcast <8 x i16> %1633 to <4 x i32>
  %1636 = bitcast <8 x i16> %1634 to <4 x i32>
  %1637 = sub <4 x i32> %1635, %1636
  %1638 = sub <4 x i32> zeroinitializer, %1637
  %1639 = icmp slt <4 x i32> %1637, zeroinitializer
  %1640 = select <4 x i1> %1639, <4 x i32> %1638, <4 x i32> %1637
  %1641 = add nuw <4 x i32> %1640, <i32 32, i32 32, i32 32, i32 32>
  %1642 = lshr <4 x i32> %1641, <i32 6, i32 6, i32 6, i32 6>
  %1643 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1632, <4 x i32> %1642) #5
  %1644 = lshr <8 x i16> %1643, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1645 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1616, <8 x i16> %1644) #5
  %1646 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1645, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1647 = icmp slt <16 x i8> %1646, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1648 = select <16 x i1> %1647, <16 x i8> %1646, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1649 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1648
  %1650 = bitcast i8* %1590 to <16 x i8>*
  store <16 x i8> %1649, <16 x i8>* %1650, align 16
  %1651 = getelementptr inbounds i16, i16* %10, i64 416
  %1652 = getelementptr inbounds i16, i16* %11, i64 416
  %1653 = getelementptr inbounds i8, i8* %1524, i64 32
  %1654 = bitcast i16* %1651 to <8 x i16>*
  %1655 = load <8 x i16>, <8 x i16>* %1654, align 16
  %1656 = bitcast i16* %1652 to <8 x i16>*
  %1657 = load <8 x i16>, <8 x i16>* %1656, align 16
  %1658 = shufflevector <8 x i16> %1655, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1659 = zext <4 x i16> %1658 to <4 x i32>
  %1660 = shufflevector <8 x i16> %1657, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1661 = zext <4 x i16> %1660 to <4 x i32>
  %1662 = sub nsw <4 x i32> %1659, %1661
  %1663 = sub nsw <4 x i32> zeroinitializer, %1662
  %1664 = icmp slt <4 x i32> %1662, zeroinitializer
  %1665 = select <4 x i1> %1664, <4 x i32> %1663, <4 x i32> %1662
  %1666 = add nuw nsw <4 x i32> %1665, <i32 32, i32 32, i32 32, i32 32>
  %1667 = lshr <4 x i32> %1666, <i32 6, i32 6, i32 6, i32 6>
  %1668 = shufflevector <8 x i16> %1655, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1669 = shufflevector <8 x i16> %1657, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1670 = bitcast <8 x i16> %1668 to <4 x i32>
  %1671 = bitcast <8 x i16> %1669 to <4 x i32>
  %1672 = sub <4 x i32> %1670, %1671
  %1673 = sub <4 x i32> zeroinitializer, %1672
  %1674 = icmp slt <4 x i32> %1672, zeroinitializer
  %1675 = select <4 x i1> %1674, <4 x i32> %1673, <4 x i32> %1672
  %1676 = add nuw <4 x i32> %1675, <i32 32, i32 32, i32 32, i32 32>
  %1677 = lshr <4 x i32> %1676, <i32 6, i32 6, i32 6, i32 6>
  %1678 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1667, <4 x i32> %1677) #5
  %1679 = lshr <8 x i16> %1678, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1680 = getelementptr inbounds i16, i16* %10, i64 424
  %1681 = bitcast i16* %1680 to <8 x i16>*
  %1682 = load <8 x i16>, <8 x i16>* %1681, align 16
  %1683 = getelementptr inbounds i16, i16* %11, i64 424
  %1684 = bitcast i16* %1683 to <8 x i16>*
  %1685 = load <8 x i16>, <8 x i16>* %1684, align 16
  %1686 = shufflevector <8 x i16> %1682, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1687 = zext <4 x i16> %1686 to <4 x i32>
  %1688 = shufflevector <8 x i16> %1685, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1689 = zext <4 x i16> %1688 to <4 x i32>
  %1690 = sub nsw <4 x i32> %1687, %1689
  %1691 = sub nsw <4 x i32> zeroinitializer, %1690
  %1692 = icmp slt <4 x i32> %1690, zeroinitializer
  %1693 = select <4 x i1> %1692, <4 x i32> %1691, <4 x i32> %1690
  %1694 = add nuw nsw <4 x i32> %1693, <i32 32, i32 32, i32 32, i32 32>
  %1695 = lshr <4 x i32> %1694, <i32 6, i32 6, i32 6, i32 6>
  %1696 = shufflevector <8 x i16> %1682, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1697 = shufflevector <8 x i16> %1685, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1698 = bitcast <8 x i16> %1696 to <4 x i32>
  %1699 = bitcast <8 x i16> %1697 to <4 x i32>
  %1700 = sub <4 x i32> %1698, %1699
  %1701 = sub <4 x i32> zeroinitializer, %1700
  %1702 = icmp slt <4 x i32> %1700, zeroinitializer
  %1703 = select <4 x i1> %1702, <4 x i32> %1701, <4 x i32> %1700
  %1704 = add nuw <4 x i32> %1703, <i32 32, i32 32, i32 32, i32 32>
  %1705 = lshr <4 x i32> %1704, <i32 6, i32 6, i32 6, i32 6>
  %1706 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1695, <4 x i32> %1705) #5
  %1707 = lshr <8 x i16> %1706, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1708 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1679, <8 x i16> %1707) #5
  %1709 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1708, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1710 = icmp slt <16 x i8> %1709, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1711 = select <16 x i1> %1710, <16 x i8> %1709, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1712 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1711
  %1713 = bitcast i8* %1653 to <16 x i8>*
  store <16 x i8> %1712, <16 x i8>* %1713, align 16
  %1714 = getelementptr inbounds i16, i16* %10, i64 432
  %1715 = getelementptr inbounds i16, i16* %11, i64 432
  %1716 = getelementptr inbounds i8, i8* %1524, i64 48
  %1717 = bitcast i16* %1714 to <8 x i16>*
  %1718 = load <8 x i16>, <8 x i16>* %1717, align 16
  %1719 = bitcast i16* %1715 to <8 x i16>*
  %1720 = load <8 x i16>, <8 x i16>* %1719, align 16
  %1721 = shufflevector <8 x i16> %1718, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1722 = zext <4 x i16> %1721 to <4 x i32>
  %1723 = shufflevector <8 x i16> %1720, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1724 = zext <4 x i16> %1723 to <4 x i32>
  %1725 = sub nsw <4 x i32> %1722, %1724
  %1726 = sub nsw <4 x i32> zeroinitializer, %1725
  %1727 = icmp slt <4 x i32> %1725, zeroinitializer
  %1728 = select <4 x i1> %1727, <4 x i32> %1726, <4 x i32> %1725
  %1729 = add nuw nsw <4 x i32> %1728, <i32 32, i32 32, i32 32, i32 32>
  %1730 = lshr <4 x i32> %1729, <i32 6, i32 6, i32 6, i32 6>
  %1731 = shufflevector <8 x i16> %1718, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1732 = shufflevector <8 x i16> %1720, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1733 = bitcast <8 x i16> %1731 to <4 x i32>
  %1734 = bitcast <8 x i16> %1732 to <4 x i32>
  %1735 = sub <4 x i32> %1733, %1734
  %1736 = sub <4 x i32> zeroinitializer, %1735
  %1737 = icmp slt <4 x i32> %1735, zeroinitializer
  %1738 = select <4 x i1> %1737, <4 x i32> %1736, <4 x i32> %1735
  %1739 = add nuw <4 x i32> %1738, <i32 32, i32 32, i32 32, i32 32>
  %1740 = lshr <4 x i32> %1739, <i32 6, i32 6, i32 6, i32 6>
  %1741 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1730, <4 x i32> %1740) #5
  %1742 = lshr <8 x i16> %1741, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1743 = getelementptr inbounds i16, i16* %10, i64 440
  %1744 = bitcast i16* %1743 to <8 x i16>*
  %1745 = load <8 x i16>, <8 x i16>* %1744, align 16
  %1746 = getelementptr inbounds i16, i16* %11, i64 440
  %1747 = bitcast i16* %1746 to <8 x i16>*
  %1748 = load <8 x i16>, <8 x i16>* %1747, align 16
  %1749 = shufflevector <8 x i16> %1745, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1750 = zext <4 x i16> %1749 to <4 x i32>
  %1751 = shufflevector <8 x i16> %1748, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1752 = zext <4 x i16> %1751 to <4 x i32>
  %1753 = sub nsw <4 x i32> %1750, %1752
  %1754 = sub nsw <4 x i32> zeroinitializer, %1753
  %1755 = icmp slt <4 x i32> %1753, zeroinitializer
  %1756 = select <4 x i1> %1755, <4 x i32> %1754, <4 x i32> %1753
  %1757 = add nuw nsw <4 x i32> %1756, <i32 32, i32 32, i32 32, i32 32>
  %1758 = lshr <4 x i32> %1757, <i32 6, i32 6, i32 6, i32 6>
  %1759 = shufflevector <8 x i16> %1745, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1760 = shufflevector <8 x i16> %1748, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1761 = bitcast <8 x i16> %1759 to <4 x i32>
  %1762 = bitcast <8 x i16> %1760 to <4 x i32>
  %1763 = sub <4 x i32> %1761, %1762
  %1764 = sub <4 x i32> zeroinitializer, %1763
  %1765 = icmp slt <4 x i32> %1763, zeroinitializer
  %1766 = select <4 x i1> %1765, <4 x i32> %1764, <4 x i32> %1763
  %1767 = add nuw <4 x i32> %1766, <i32 32, i32 32, i32 32, i32 32>
  %1768 = lshr <4 x i32> %1767, <i32 6, i32 6, i32 6, i32 6>
  %1769 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1758, <4 x i32> %1768) #5
  %1770 = lshr <8 x i16> %1769, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1771 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1742, <8 x i16> %1770) #5
  %1772 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1771, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1773 = icmp slt <16 x i8> %1772, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1774 = select <16 x i1> %1773, <16 x i8> %1772, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1775 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1774
  %1776 = bitcast i8* %1716 to <16 x i8>*
  store <16 x i8> %1775, <16 x i8>* %1776, align 16
  %1777 = getelementptr inbounds i16, i16* %10, i64 448
  %1778 = getelementptr inbounds i16, i16* %11, i64 448
  %1779 = getelementptr inbounds i8, i8* %1524, i64 64
  %1780 = bitcast i16* %1777 to <8 x i16>*
  %1781 = load <8 x i16>, <8 x i16>* %1780, align 16
  %1782 = bitcast i16* %1778 to <8 x i16>*
  %1783 = load <8 x i16>, <8 x i16>* %1782, align 16
  %1784 = shufflevector <8 x i16> %1781, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1785 = zext <4 x i16> %1784 to <4 x i32>
  %1786 = shufflevector <8 x i16> %1783, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1787 = zext <4 x i16> %1786 to <4 x i32>
  %1788 = sub nsw <4 x i32> %1785, %1787
  %1789 = sub nsw <4 x i32> zeroinitializer, %1788
  %1790 = icmp slt <4 x i32> %1788, zeroinitializer
  %1791 = select <4 x i1> %1790, <4 x i32> %1789, <4 x i32> %1788
  %1792 = add nuw nsw <4 x i32> %1791, <i32 32, i32 32, i32 32, i32 32>
  %1793 = lshr <4 x i32> %1792, <i32 6, i32 6, i32 6, i32 6>
  %1794 = shufflevector <8 x i16> %1781, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1795 = shufflevector <8 x i16> %1783, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1796 = bitcast <8 x i16> %1794 to <4 x i32>
  %1797 = bitcast <8 x i16> %1795 to <4 x i32>
  %1798 = sub <4 x i32> %1796, %1797
  %1799 = sub <4 x i32> zeroinitializer, %1798
  %1800 = icmp slt <4 x i32> %1798, zeroinitializer
  %1801 = select <4 x i1> %1800, <4 x i32> %1799, <4 x i32> %1798
  %1802 = add nuw <4 x i32> %1801, <i32 32, i32 32, i32 32, i32 32>
  %1803 = lshr <4 x i32> %1802, <i32 6, i32 6, i32 6, i32 6>
  %1804 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1793, <4 x i32> %1803) #5
  %1805 = lshr <8 x i16> %1804, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1806 = getelementptr inbounds i16, i16* %10, i64 456
  %1807 = bitcast i16* %1806 to <8 x i16>*
  %1808 = load <8 x i16>, <8 x i16>* %1807, align 16
  %1809 = getelementptr inbounds i16, i16* %11, i64 456
  %1810 = bitcast i16* %1809 to <8 x i16>*
  %1811 = load <8 x i16>, <8 x i16>* %1810, align 16
  %1812 = shufflevector <8 x i16> %1808, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1813 = zext <4 x i16> %1812 to <4 x i32>
  %1814 = shufflevector <8 x i16> %1811, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1815 = zext <4 x i16> %1814 to <4 x i32>
  %1816 = sub nsw <4 x i32> %1813, %1815
  %1817 = sub nsw <4 x i32> zeroinitializer, %1816
  %1818 = icmp slt <4 x i32> %1816, zeroinitializer
  %1819 = select <4 x i1> %1818, <4 x i32> %1817, <4 x i32> %1816
  %1820 = add nuw nsw <4 x i32> %1819, <i32 32, i32 32, i32 32, i32 32>
  %1821 = lshr <4 x i32> %1820, <i32 6, i32 6, i32 6, i32 6>
  %1822 = shufflevector <8 x i16> %1808, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1823 = shufflevector <8 x i16> %1811, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1824 = bitcast <8 x i16> %1822 to <4 x i32>
  %1825 = bitcast <8 x i16> %1823 to <4 x i32>
  %1826 = sub <4 x i32> %1824, %1825
  %1827 = sub <4 x i32> zeroinitializer, %1826
  %1828 = icmp slt <4 x i32> %1826, zeroinitializer
  %1829 = select <4 x i1> %1828, <4 x i32> %1827, <4 x i32> %1826
  %1830 = add nuw <4 x i32> %1829, <i32 32, i32 32, i32 32, i32 32>
  %1831 = lshr <4 x i32> %1830, <i32 6, i32 6, i32 6, i32 6>
  %1832 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1821, <4 x i32> %1831) #5
  %1833 = lshr <8 x i16> %1832, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1834 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1805, <8 x i16> %1833) #5
  %1835 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1834, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1836 = icmp slt <16 x i8> %1835, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1837 = select <16 x i1> %1836, <16 x i8> %1835, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1838 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1837
  %1839 = bitcast i8* %1779 to <16 x i8>*
  store <16 x i8> %1838, <16 x i8>* %1839, align 16
  %1840 = getelementptr inbounds i16, i16* %10, i64 464
  %1841 = getelementptr inbounds i16, i16* %11, i64 464
  %1842 = getelementptr inbounds i8, i8* %1779, i64 16
  %1843 = bitcast i16* %1840 to <8 x i16>*
  %1844 = load <8 x i16>, <8 x i16>* %1843, align 16
  %1845 = bitcast i16* %1841 to <8 x i16>*
  %1846 = load <8 x i16>, <8 x i16>* %1845, align 16
  %1847 = shufflevector <8 x i16> %1844, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1848 = zext <4 x i16> %1847 to <4 x i32>
  %1849 = shufflevector <8 x i16> %1846, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1850 = zext <4 x i16> %1849 to <4 x i32>
  %1851 = sub nsw <4 x i32> %1848, %1850
  %1852 = sub nsw <4 x i32> zeroinitializer, %1851
  %1853 = icmp slt <4 x i32> %1851, zeroinitializer
  %1854 = select <4 x i1> %1853, <4 x i32> %1852, <4 x i32> %1851
  %1855 = add nuw nsw <4 x i32> %1854, <i32 32, i32 32, i32 32, i32 32>
  %1856 = lshr <4 x i32> %1855, <i32 6, i32 6, i32 6, i32 6>
  %1857 = shufflevector <8 x i16> %1844, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1858 = shufflevector <8 x i16> %1846, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1859 = bitcast <8 x i16> %1857 to <4 x i32>
  %1860 = bitcast <8 x i16> %1858 to <4 x i32>
  %1861 = sub <4 x i32> %1859, %1860
  %1862 = sub <4 x i32> zeroinitializer, %1861
  %1863 = icmp slt <4 x i32> %1861, zeroinitializer
  %1864 = select <4 x i1> %1863, <4 x i32> %1862, <4 x i32> %1861
  %1865 = add nuw <4 x i32> %1864, <i32 32, i32 32, i32 32, i32 32>
  %1866 = lshr <4 x i32> %1865, <i32 6, i32 6, i32 6, i32 6>
  %1867 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1856, <4 x i32> %1866) #5
  %1868 = lshr <8 x i16> %1867, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1869 = getelementptr inbounds i16, i16* %10, i64 472
  %1870 = bitcast i16* %1869 to <8 x i16>*
  %1871 = load <8 x i16>, <8 x i16>* %1870, align 16
  %1872 = getelementptr inbounds i16, i16* %11, i64 472
  %1873 = bitcast i16* %1872 to <8 x i16>*
  %1874 = load <8 x i16>, <8 x i16>* %1873, align 16
  %1875 = shufflevector <8 x i16> %1871, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1876 = zext <4 x i16> %1875 to <4 x i32>
  %1877 = shufflevector <8 x i16> %1874, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1878 = zext <4 x i16> %1877 to <4 x i32>
  %1879 = sub nsw <4 x i32> %1876, %1878
  %1880 = sub nsw <4 x i32> zeroinitializer, %1879
  %1881 = icmp slt <4 x i32> %1879, zeroinitializer
  %1882 = select <4 x i1> %1881, <4 x i32> %1880, <4 x i32> %1879
  %1883 = add nuw nsw <4 x i32> %1882, <i32 32, i32 32, i32 32, i32 32>
  %1884 = lshr <4 x i32> %1883, <i32 6, i32 6, i32 6, i32 6>
  %1885 = shufflevector <8 x i16> %1871, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1886 = shufflevector <8 x i16> %1874, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1887 = bitcast <8 x i16> %1885 to <4 x i32>
  %1888 = bitcast <8 x i16> %1886 to <4 x i32>
  %1889 = sub <4 x i32> %1887, %1888
  %1890 = sub <4 x i32> zeroinitializer, %1889
  %1891 = icmp slt <4 x i32> %1889, zeroinitializer
  %1892 = select <4 x i1> %1891, <4 x i32> %1890, <4 x i32> %1889
  %1893 = add nuw <4 x i32> %1892, <i32 32, i32 32, i32 32, i32 32>
  %1894 = lshr <4 x i32> %1893, <i32 6, i32 6, i32 6, i32 6>
  %1895 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1884, <4 x i32> %1894) #5
  %1896 = lshr <8 x i16> %1895, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1897 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1868, <8 x i16> %1896) #5
  %1898 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1897, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1899 = icmp slt <16 x i8> %1898, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1900 = select <16 x i1> %1899, <16 x i8> %1898, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1901 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1900
  %1902 = bitcast i8* %1842 to <16 x i8>*
  store <16 x i8> %1901, <16 x i8>* %1902, align 16
  %1903 = getelementptr inbounds i16, i16* %10, i64 480
  %1904 = getelementptr inbounds i16, i16* %11, i64 480
  %1905 = getelementptr inbounds i8, i8* %1779, i64 32
  %1906 = bitcast i16* %1903 to <8 x i16>*
  %1907 = load <8 x i16>, <8 x i16>* %1906, align 16
  %1908 = bitcast i16* %1904 to <8 x i16>*
  %1909 = load <8 x i16>, <8 x i16>* %1908, align 16
  %1910 = shufflevector <8 x i16> %1907, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1911 = zext <4 x i16> %1910 to <4 x i32>
  %1912 = shufflevector <8 x i16> %1909, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1913 = zext <4 x i16> %1912 to <4 x i32>
  %1914 = sub nsw <4 x i32> %1911, %1913
  %1915 = sub nsw <4 x i32> zeroinitializer, %1914
  %1916 = icmp slt <4 x i32> %1914, zeroinitializer
  %1917 = select <4 x i1> %1916, <4 x i32> %1915, <4 x i32> %1914
  %1918 = add nuw nsw <4 x i32> %1917, <i32 32, i32 32, i32 32, i32 32>
  %1919 = lshr <4 x i32> %1918, <i32 6, i32 6, i32 6, i32 6>
  %1920 = shufflevector <8 x i16> %1907, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1921 = shufflevector <8 x i16> %1909, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1922 = bitcast <8 x i16> %1920 to <4 x i32>
  %1923 = bitcast <8 x i16> %1921 to <4 x i32>
  %1924 = sub <4 x i32> %1922, %1923
  %1925 = sub <4 x i32> zeroinitializer, %1924
  %1926 = icmp slt <4 x i32> %1924, zeroinitializer
  %1927 = select <4 x i1> %1926, <4 x i32> %1925, <4 x i32> %1924
  %1928 = add nuw <4 x i32> %1927, <i32 32, i32 32, i32 32, i32 32>
  %1929 = lshr <4 x i32> %1928, <i32 6, i32 6, i32 6, i32 6>
  %1930 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1919, <4 x i32> %1929) #5
  %1931 = lshr <8 x i16> %1930, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1932 = getelementptr inbounds i16, i16* %10, i64 488
  %1933 = bitcast i16* %1932 to <8 x i16>*
  %1934 = load <8 x i16>, <8 x i16>* %1933, align 16
  %1935 = getelementptr inbounds i16, i16* %11, i64 488
  %1936 = bitcast i16* %1935 to <8 x i16>*
  %1937 = load <8 x i16>, <8 x i16>* %1936, align 16
  %1938 = shufflevector <8 x i16> %1934, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1939 = zext <4 x i16> %1938 to <4 x i32>
  %1940 = shufflevector <8 x i16> %1937, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1941 = zext <4 x i16> %1940 to <4 x i32>
  %1942 = sub nsw <4 x i32> %1939, %1941
  %1943 = sub nsw <4 x i32> zeroinitializer, %1942
  %1944 = icmp slt <4 x i32> %1942, zeroinitializer
  %1945 = select <4 x i1> %1944, <4 x i32> %1943, <4 x i32> %1942
  %1946 = add nuw nsw <4 x i32> %1945, <i32 32, i32 32, i32 32, i32 32>
  %1947 = lshr <4 x i32> %1946, <i32 6, i32 6, i32 6, i32 6>
  %1948 = shufflevector <8 x i16> %1934, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1949 = shufflevector <8 x i16> %1937, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1950 = bitcast <8 x i16> %1948 to <4 x i32>
  %1951 = bitcast <8 x i16> %1949 to <4 x i32>
  %1952 = sub <4 x i32> %1950, %1951
  %1953 = sub <4 x i32> zeroinitializer, %1952
  %1954 = icmp slt <4 x i32> %1952, zeroinitializer
  %1955 = select <4 x i1> %1954, <4 x i32> %1953, <4 x i32> %1952
  %1956 = add nuw <4 x i32> %1955, <i32 32, i32 32, i32 32, i32 32>
  %1957 = lshr <4 x i32> %1956, <i32 6, i32 6, i32 6, i32 6>
  %1958 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1947, <4 x i32> %1957) #5
  %1959 = lshr <8 x i16> %1958, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1960 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1931, <8 x i16> %1959) #5
  %1961 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %1960, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %1962 = icmp slt <16 x i8> %1961, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1963 = select <16 x i1> %1962, <16 x i8> %1961, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %1964 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %1963
  %1965 = bitcast i8* %1905 to <16 x i8>*
  store <16 x i8> %1964, <16 x i8>* %1965, align 16
  %1966 = getelementptr inbounds i16, i16* %10, i64 496
  %1967 = getelementptr inbounds i16, i16* %11, i64 496
  %1968 = getelementptr inbounds i8, i8* %1779, i64 48
  %1969 = bitcast i16* %1966 to <8 x i16>*
  %1970 = load <8 x i16>, <8 x i16>* %1969, align 16
  %1971 = bitcast i16* %1967 to <8 x i16>*
  %1972 = load <8 x i16>, <8 x i16>* %1971, align 16
  %1973 = shufflevector <8 x i16> %1970, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1974 = zext <4 x i16> %1973 to <4 x i32>
  %1975 = shufflevector <8 x i16> %1972, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %1976 = zext <4 x i16> %1975 to <4 x i32>
  %1977 = sub nsw <4 x i32> %1974, %1976
  %1978 = sub nsw <4 x i32> zeroinitializer, %1977
  %1979 = icmp slt <4 x i32> %1977, zeroinitializer
  %1980 = select <4 x i1> %1979, <4 x i32> %1978, <4 x i32> %1977
  %1981 = add nuw nsw <4 x i32> %1980, <i32 32, i32 32, i32 32, i32 32>
  %1982 = lshr <4 x i32> %1981, <i32 6, i32 6, i32 6, i32 6>
  %1983 = shufflevector <8 x i16> %1970, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1984 = shufflevector <8 x i16> %1972, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1985 = bitcast <8 x i16> %1983 to <4 x i32>
  %1986 = bitcast <8 x i16> %1984 to <4 x i32>
  %1987 = sub <4 x i32> %1985, %1986
  %1988 = sub <4 x i32> zeroinitializer, %1987
  %1989 = icmp slt <4 x i32> %1987, zeroinitializer
  %1990 = select <4 x i1> %1989, <4 x i32> %1988, <4 x i32> %1987
  %1991 = add nuw <4 x i32> %1990, <i32 32, i32 32, i32 32, i32 32>
  %1992 = lshr <4 x i32> %1991, <i32 6, i32 6, i32 6, i32 6>
  %1993 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %1982, <4 x i32> %1992) #5
  %1994 = lshr <8 x i16> %1993, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %1995 = getelementptr inbounds i16, i16* %10, i64 504
  %1996 = bitcast i16* %1995 to <8 x i16>*
  %1997 = load <8 x i16>, <8 x i16>* %1996, align 16
  %1998 = getelementptr inbounds i16, i16* %11, i64 504
  %1999 = bitcast i16* %1998 to <8 x i16>*
  %2000 = load <8 x i16>, <8 x i16>* %1999, align 16
  %2001 = shufflevector <8 x i16> %1997, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2002 = zext <4 x i16> %2001 to <4 x i32>
  %2003 = shufflevector <8 x i16> %2000, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2004 = zext <4 x i16> %2003 to <4 x i32>
  %2005 = sub nsw <4 x i32> %2002, %2004
  %2006 = sub nsw <4 x i32> zeroinitializer, %2005
  %2007 = icmp slt <4 x i32> %2005, zeroinitializer
  %2008 = select <4 x i1> %2007, <4 x i32> %2006, <4 x i32> %2005
  %2009 = add nuw nsw <4 x i32> %2008, <i32 32, i32 32, i32 32, i32 32>
  %2010 = lshr <4 x i32> %2009, <i32 6, i32 6, i32 6, i32 6>
  %2011 = shufflevector <8 x i16> %1997, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2012 = shufflevector <8 x i16> %2000, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2013 = bitcast <8 x i16> %2011 to <4 x i32>
  %2014 = bitcast <8 x i16> %2012 to <4 x i32>
  %2015 = sub <4 x i32> %2013, %2014
  %2016 = sub <4 x i32> zeroinitializer, %2015
  %2017 = icmp slt <4 x i32> %2015, zeroinitializer
  %2018 = select <4 x i1> %2017, <4 x i32> %2016, <4 x i32> %2015
  %2019 = add nuw <4 x i32> %2018, <i32 32, i32 32, i32 32, i32 32>
  %2020 = lshr <4 x i32> %2019, <i32 6, i32 6, i32 6, i32 6>
  %2021 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2010, <4 x i32> %2020) #5
  %2022 = lshr <8 x i16> %2021, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2023 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %1994, <8 x i16> %2022) #5
  %2024 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %2023, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %2025 = icmp slt <16 x i8> %2024, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2026 = select <16 x i1> %2025, <16 x i8> %2024, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2027 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %2026
  %2028 = bitcast i8* %1968 to <16 x i8>*
  store <16 x i8> %2027, <16 x i8>* %2028, align 16
  %2029 = getelementptr inbounds i16, i16* %10, i64 512
  %2030 = getelementptr inbounds i16, i16* %11, i64 512
  %2031 = getelementptr inbounds i8, i8* %1779, i64 %7
  %2032 = bitcast i16* %2029 to <8 x i16>*
  %2033 = load <8 x i16>, <8 x i16>* %2032, align 16
  %2034 = bitcast i16* %2030 to <8 x i16>*
  %2035 = load <8 x i16>, <8 x i16>* %2034, align 16
  %2036 = shufflevector <8 x i16> %2033, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2037 = zext <4 x i16> %2036 to <4 x i32>
  %2038 = shufflevector <8 x i16> %2035, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2039 = zext <4 x i16> %2038 to <4 x i32>
  %2040 = sub nsw <4 x i32> %2037, %2039
  %2041 = sub nsw <4 x i32> zeroinitializer, %2040
  %2042 = icmp slt <4 x i32> %2040, zeroinitializer
  %2043 = select <4 x i1> %2042, <4 x i32> %2041, <4 x i32> %2040
  %2044 = add nuw nsw <4 x i32> %2043, <i32 32, i32 32, i32 32, i32 32>
  %2045 = lshr <4 x i32> %2044, <i32 6, i32 6, i32 6, i32 6>
  %2046 = shufflevector <8 x i16> %2033, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2047 = shufflevector <8 x i16> %2035, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2048 = bitcast <8 x i16> %2046 to <4 x i32>
  %2049 = bitcast <8 x i16> %2047 to <4 x i32>
  %2050 = sub <4 x i32> %2048, %2049
  %2051 = sub <4 x i32> zeroinitializer, %2050
  %2052 = icmp slt <4 x i32> %2050, zeroinitializer
  %2053 = select <4 x i1> %2052, <4 x i32> %2051, <4 x i32> %2050
  %2054 = add nuw <4 x i32> %2053, <i32 32, i32 32, i32 32, i32 32>
  %2055 = lshr <4 x i32> %2054, <i32 6, i32 6, i32 6, i32 6>
  %2056 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2045, <4 x i32> %2055) #5
  %2057 = lshr <8 x i16> %2056, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2058 = getelementptr inbounds i16, i16* %10, i64 520
  %2059 = bitcast i16* %2058 to <8 x i16>*
  %2060 = load <8 x i16>, <8 x i16>* %2059, align 16
  %2061 = getelementptr inbounds i16, i16* %11, i64 520
  %2062 = bitcast i16* %2061 to <8 x i16>*
  %2063 = load <8 x i16>, <8 x i16>* %2062, align 16
  %2064 = shufflevector <8 x i16> %2060, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2065 = zext <4 x i16> %2064 to <4 x i32>
  %2066 = shufflevector <8 x i16> %2063, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2067 = zext <4 x i16> %2066 to <4 x i32>
  %2068 = sub nsw <4 x i32> %2065, %2067
  %2069 = sub nsw <4 x i32> zeroinitializer, %2068
  %2070 = icmp slt <4 x i32> %2068, zeroinitializer
  %2071 = select <4 x i1> %2070, <4 x i32> %2069, <4 x i32> %2068
  %2072 = add nuw nsw <4 x i32> %2071, <i32 32, i32 32, i32 32, i32 32>
  %2073 = lshr <4 x i32> %2072, <i32 6, i32 6, i32 6, i32 6>
  %2074 = shufflevector <8 x i16> %2060, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2075 = shufflevector <8 x i16> %2063, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2076 = bitcast <8 x i16> %2074 to <4 x i32>
  %2077 = bitcast <8 x i16> %2075 to <4 x i32>
  %2078 = sub <4 x i32> %2076, %2077
  %2079 = sub <4 x i32> zeroinitializer, %2078
  %2080 = icmp slt <4 x i32> %2078, zeroinitializer
  %2081 = select <4 x i1> %2080, <4 x i32> %2079, <4 x i32> %2078
  %2082 = add nuw <4 x i32> %2081, <i32 32, i32 32, i32 32, i32 32>
  %2083 = lshr <4 x i32> %2082, <i32 6, i32 6, i32 6, i32 6>
  %2084 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2073, <4 x i32> %2083) #5
  %2085 = lshr <8 x i16> %2084, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2086 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2057, <8 x i16> %2085) #5
  %2087 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %2086, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %2088 = icmp slt <16 x i8> %2087, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2089 = select <16 x i1> %2088, <16 x i8> %2087, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2090 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %2089
  %2091 = bitcast i8* %2031 to <16 x i8>*
  store <16 x i8> %2090, <16 x i8>* %2091, align 16
  %2092 = getelementptr inbounds i16, i16* %10, i64 528
  %2093 = getelementptr inbounds i16, i16* %11, i64 528
  %2094 = getelementptr inbounds i8, i8* %2031, i64 16
  %2095 = bitcast i16* %2092 to <8 x i16>*
  %2096 = load <8 x i16>, <8 x i16>* %2095, align 16
  %2097 = bitcast i16* %2093 to <8 x i16>*
  %2098 = load <8 x i16>, <8 x i16>* %2097, align 16
  %2099 = shufflevector <8 x i16> %2096, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2100 = zext <4 x i16> %2099 to <4 x i32>
  %2101 = shufflevector <8 x i16> %2098, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2102 = zext <4 x i16> %2101 to <4 x i32>
  %2103 = sub nsw <4 x i32> %2100, %2102
  %2104 = sub nsw <4 x i32> zeroinitializer, %2103
  %2105 = icmp slt <4 x i32> %2103, zeroinitializer
  %2106 = select <4 x i1> %2105, <4 x i32> %2104, <4 x i32> %2103
  %2107 = add nuw nsw <4 x i32> %2106, <i32 32, i32 32, i32 32, i32 32>
  %2108 = lshr <4 x i32> %2107, <i32 6, i32 6, i32 6, i32 6>
  %2109 = shufflevector <8 x i16> %2096, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2110 = shufflevector <8 x i16> %2098, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2111 = bitcast <8 x i16> %2109 to <4 x i32>
  %2112 = bitcast <8 x i16> %2110 to <4 x i32>
  %2113 = sub <4 x i32> %2111, %2112
  %2114 = sub <4 x i32> zeroinitializer, %2113
  %2115 = icmp slt <4 x i32> %2113, zeroinitializer
  %2116 = select <4 x i1> %2115, <4 x i32> %2114, <4 x i32> %2113
  %2117 = add nuw <4 x i32> %2116, <i32 32, i32 32, i32 32, i32 32>
  %2118 = lshr <4 x i32> %2117, <i32 6, i32 6, i32 6, i32 6>
  %2119 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2108, <4 x i32> %2118) #5
  %2120 = lshr <8 x i16> %2119, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2121 = getelementptr inbounds i16, i16* %10, i64 536
  %2122 = bitcast i16* %2121 to <8 x i16>*
  %2123 = load <8 x i16>, <8 x i16>* %2122, align 16
  %2124 = getelementptr inbounds i16, i16* %11, i64 536
  %2125 = bitcast i16* %2124 to <8 x i16>*
  %2126 = load <8 x i16>, <8 x i16>* %2125, align 16
  %2127 = shufflevector <8 x i16> %2123, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2128 = zext <4 x i16> %2127 to <4 x i32>
  %2129 = shufflevector <8 x i16> %2126, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2130 = zext <4 x i16> %2129 to <4 x i32>
  %2131 = sub nsw <4 x i32> %2128, %2130
  %2132 = sub nsw <4 x i32> zeroinitializer, %2131
  %2133 = icmp slt <4 x i32> %2131, zeroinitializer
  %2134 = select <4 x i1> %2133, <4 x i32> %2132, <4 x i32> %2131
  %2135 = add nuw nsw <4 x i32> %2134, <i32 32, i32 32, i32 32, i32 32>
  %2136 = lshr <4 x i32> %2135, <i32 6, i32 6, i32 6, i32 6>
  %2137 = shufflevector <8 x i16> %2123, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2138 = shufflevector <8 x i16> %2126, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2139 = bitcast <8 x i16> %2137 to <4 x i32>
  %2140 = bitcast <8 x i16> %2138 to <4 x i32>
  %2141 = sub <4 x i32> %2139, %2140
  %2142 = sub <4 x i32> zeroinitializer, %2141
  %2143 = icmp slt <4 x i32> %2141, zeroinitializer
  %2144 = select <4 x i1> %2143, <4 x i32> %2142, <4 x i32> %2141
  %2145 = add nuw <4 x i32> %2144, <i32 32, i32 32, i32 32, i32 32>
  %2146 = lshr <4 x i32> %2145, <i32 6, i32 6, i32 6, i32 6>
  %2147 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2136, <4 x i32> %2146) #5
  %2148 = lshr <8 x i16> %2147, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2149 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2120, <8 x i16> %2148) #5
  %2150 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %2149, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %2151 = icmp slt <16 x i8> %2150, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2152 = select <16 x i1> %2151, <16 x i8> %2150, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2153 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %2152
  %2154 = bitcast i8* %2094 to <16 x i8>*
  store <16 x i8> %2153, <16 x i8>* %2154, align 16
  %2155 = getelementptr inbounds i16, i16* %10, i64 544
  %2156 = getelementptr inbounds i16, i16* %11, i64 544
  %2157 = getelementptr inbounds i8, i8* %2031, i64 32
  %2158 = bitcast i16* %2155 to <8 x i16>*
  %2159 = load <8 x i16>, <8 x i16>* %2158, align 16
  %2160 = bitcast i16* %2156 to <8 x i16>*
  %2161 = load <8 x i16>, <8 x i16>* %2160, align 16
  %2162 = shufflevector <8 x i16> %2159, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2163 = zext <4 x i16> %2162 to <4 x i32>
  %2164 = shufflevector <8 x i16> %2161, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2165 = zext <4 x i16> %2164 to <4 x i32>
  %2166 = sub nsw <4 x i32> %2163, %2165
  %2167 = sub nsw <4 x i32> zeroinitializer, %2166
  %2168 = icmp slt <4 x i32> %2166, zeroinitializer
  %2169 = select <4 x i1> %2168, <4 x i32> %2167, <4 x i32> %2166
  %2170 = add nuw nsw <4 x i32> %2169, <i32 32, i32 32, i32 32, i32 32>
  %2171 = lshr <4 x i32> %2170, <i32 6, i32 6, i32 6, i32 6>
  %2172 = shufflevector <8 x i16> %2159, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2173 = shufflevector <8 x i16> %2161, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2174 = bitcast <8 x i16> %2172 to <4 x i32>
  %2175 = bitcast <8 x i16> %2173 to <4 x i32>
  %2176 = sub <4 x i32> %2174, %2175
  %2177 = sub <4 x i32> zeroinitializer, %2176
  %2178 = icmp slt <4 x i32> %2176, zeroinitializer
  %2179 = select <4 x i1> %2178, <4 x i32> %2177, <4 x i32> %2176
  %2180 = add nuw <4 x i32> %2179, <i32 32, i32 32, i32 32, i32 32>
  %2181 = lshr <4 x i32> %2180, <i32 6, i32 6, i32 6, i32 6>
  %2182 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2171, <4 x i32> %2181) #5
  %2183 = lshr <8 x i16> %2182, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2184 = getelementptr inbounds i16, i16* %10, i64 552
  %2185 = bitcast i16* %2184 to <8 x i16>*
  %2186 = load <8 x i16>, <8 x i16>* %2185, align 16
  %2187 = getelementptr inbounds i16, i16* %11, i64 552
  %2188 = bitcast i16* %2187 to <8 x i16>*
  %2189 = load <8 x i16>, <8 x i16>* %2188, align 16
  %2190 = shufflevector <8 x i16> %2186, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2191 = zext <4 x i16> %2190 to <4 x i32>
  %2192 = shufflevector <8 x i16> %2189, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2193 = zext <4 x i16> %2192 to <4 x i32>
  %2194 = sub nsw <4 x i32> %2191, %2193
  %2195 = sub nsw <4 x i32> zeroinitializer, %2194
  %2196 = icmp slt <4 x i32> %2194, zeroinitializer
  %2197 = select <4 x i1> %2196, <4 x i32> %2195, <4 x i32> %2194
  %2198 = add nuw nsw <4 x i32> %2197, <i32 32, i32 32, i32 32, i32 32>
  %2199 = lshr <4 x i32> %2198, <i32 6, i32 6, i32 6, i32 6>
  %2200 = shufflevector <8 x i16> %2186, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2201 = shufflevector <8 x i16> %2189, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2202 = bitcast <8 x i16> %2200 to <4 x i32>
  %2203 = bitcast <8 x i16> %2201 to <4 x i32>
  %2204 = sub <4 x i32> %2202, %2203
  %2205 = sub <4 x i32> zeroinitializer, %2204
  %2206 = icmp slt <4 x i32> %2204, zeroinitializer
  %2207 = select <4 x i1> %2206, <4 x i32> %2205, <4 x i32> %2204
  %2208 = add nuw <4 x i32> %2207, <i32 32, i32 32, i32 32, i32 32>
  %2209 = lshr <4 x i32> %2208, <i32 6, i32 6, i32 6, i32 6>
  %2210 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2199, <4 x i32> %2209) #5
  %2211 = lshr <8 x i16> %2210, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2212 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2183, <8 x i16> %2211) #5
  %2213 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %2212, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %2214 = icmp slt <16 x i8> %2213, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2215 = select <16 x i1> %2214, <16 x i8> %2213, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2216 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %2215
  %2217 = bitcast i8* %2157 to <16 x i8>*
  store <16 x i8> %2216, <16 x i8>* %2217, align 16
  %2218 = getelementptr inbounds i16, i16* %10, i64 560
  %2219 = getelementptr inbounds i16, i16* %11, i64 560
  %2220 = getelementptr inbounds i8, i8* %2031, i64 48
  %2221 = bitcast i16* %2218 to <8 x i16>*
  %2222 = load <8 x i16>, <8 x i16>* %2221, align 16
  %2223 = bitcast i16* %2219 to <8 x i16>*
  %2224 = load <8 x i16>, <8 x i16>* %2223, align 16
  %2225 = shufflevector <8 x i16> %2222, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2226 = zext <4 x i16> %2225 to <4 x i32>
  %2227 = shufflevector <8 x i16> %2224, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2228 = zext <4 x i16> %2227 to <4 x i32>
  %2229 = sub nsw <4 x i32> %2226, %2228
  %2230 = sub nsw <4 x i32> zeroinitializer, %2229
  %2231 = icmp slt <4 x i32> %2229, zeroinitializer
  %2232 = select <4 x i1> %2231, <4 x i32> %2230, <4 x i32> %2229
  %2233 = add nuw nsw <4 x i32> %2232, <i32 32, i32 32, i32 32, i32 32>
  %2234 = lshr <4 x i32> %2233, <i32 6, i32 6, i32 6, i32 6>
  %2235 = shufflevector <8 x i16> %2222, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2236 = shufflevector <8 x i16> %2224, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2237 = bitcast <8 x i16> %2235 to <4 x i32>
  %2238 = bitcast <8 x i16> %2236 to <4 x i32>
  %2239 = sub <4 x i32> %2237, %2238
  %2240 = sub <4 x i32> zeroinitializer, %2239
  %2241 = icmp slt <4 x i32> %2239, zeroinitializer
  %2242 = select <4 x i1> %2241, <4 x i32> %2240, <4 x i32> %2239
  %2243 = add nuw <4 x i32> %2242, <i32 32, i32 32, i32 32, i32 32>
  %2244 = lshr <4 x i32> %2243, <i32 6, i32 6, i32 6, i32 6>
  %2245 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2234, <4 x i32> %2244) #5
  %2246 = lshr <8 x i16> %2245, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2247 = getelementptr inbounds i16, i16* %10, i64 568
  %2248 = bitcast i16* %2247 to <8 x i16>*
  %2249 = load <8 x i16>, <8 x i16>* %2248, align 16
  %2250 = getelementptr inbounds i16, i16* %11, i64 568
  %2251 = bitcast i16* %2250 to <8 x i16>*
  %2252 = load <8 x i16>, <8 x i16>* %2251, align 16
  %2253 = shufflevector <8 x i16> %2249, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2254 = zext <4 x i16> %2253 to <4 x i32>
  %2255 = shufflevector <8 x i16> %2252, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2256 = zext <4 x i16> %2255 to <4 x i32>
  %2257 = sub nsw <4 x i32> %2254, %2256
  %2258 = sub nsw <4 x i32> zeroinitializer, %2257
  %2259 = icmp slt <4 x i32> %2257, zeroinitializer
  %2260 = select <4 x i1> %2259, <4 x i32> %2258, <4 x i32> %2257
  %2261 = add nuw nsw <4 x i32> %2260, <i32 32, i32 32, i32 32, i32 32>
  %2262 = lshr <4 x i32> %2261, <i32 6, i32 6, i32 6, i32 6>
  %2263 = shufflevector <8 x i16> %2249, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2264 = shufflevector <8 x i16> %2252, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2265 = bitcast <8 x i16> %2263 to <4 x i32>
  %2266 = bitcast <8 x i16> %2264 to <4 x i32>
  %2267 = sub <4 x i32> %2265, %2266
  %2268 = sub <4 x i32> zeroinitializer, %2267
  %2269 = icmp slt <4 x i32> %2267, zeroinitializer
  %2270 = select <4 x i1> %2269, <4 x i32> %2268, <4 x i32> %2267
  %2271 = add nuw <4 x i32> %2270, <i32 32, i32 32, i32 32, i32 32>
  %2272 = lshr <4 x i32> %2271, <i32 6, i32 6, i32 6, i32 6>
  %2273 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2262, <4 x i32> %2272) #5
  %2274 = lshr <8 x i16> %2273, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2275 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2246, <8 x i16> %2274) #5
  %2276 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %2275, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %2277 = icmp slt <16 x i8> %2276, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2278 = select <16 x i1> %2277, <16 x i8> %2276, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2279 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %2278
  %2280 = bitcast i8* %2220 to <16 x i8>*
  store <16 x i8> %2279, <16 x i8>* %2280, align 16
  %2281 = getelementptr inbounds i16, i16* %10, i64 576
  %2282 = getelementptr inbounds i16, i16* %11, i64 576
  %2283 = getelementptr inbounds i8, i8* %2031, i64 64
  %2284 = bitcast i16* %2281 to <8 x i16>*
  %2285 = load <8 x i16>, <8 x i16>* %2284, align 16
  %2286 = bitcast i16* %2282 to <8 x i16>*
  %2287 = load <8 x i16>, <8 x i16>* %2286, align 16
  %2288 = shufflevector <8 x i16> %2285, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2289 = zext <4 x i16> %2288 to <4 x i32>
  %2290 = shufflevector <8 x i16> %2287, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2291 = zext <4 x i16> %2290 to <4 x i32>
  %2292 = sub nsw <4 x i32> %2289, %2291
  %2293 = sub nsw <4 x i32> zeroinitializer, %2292
  %2294 = icmp slt <4 x i32> %2292, zeroinitializer
  %2295 = select <4 x i1> %2294, <4 x i32> %2293, <4 x i32> %2292
  %2296 = add nuw nsw <4 x i32> %2295, <i32 32, i32 32, i32 32, i32 32>
  %2297 = lshr <4 x i32> %2296, <i32 6, i32 6, i32 6, i32 6>
  %2298 = shufflevector <8 x i16> %2285, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2299 = shufflevector <8 x i16> %2287, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2300 = bitcast <8 x i16> %2298 to <4 x i32>
  %2301 = bitcast <8 x i16> %2299 to <4 x i32>
  %2302 = sub <4 x i32> %2300, %2301
  %2303 = sub <4 x i32> zeroinitializer, %2302
  %2304 = icmp slt <4 x i32> %2302, zeroinitializer
  %2305 = select <4 x i1> %2304, <4 x i32> %2303, <4 x i32> %2302
  %2306 = add nuw <4 x i32> %2305, <i32 32, i32 32, i32 32, i32 32>
  %2307 = lshr <4 x i32> %2306, <i32 6, i32 6, i32 6, i32 6>
  %2308 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2297, <4 x i32> %2307) #5
  %2309 = lshr <8 x i16> %2308, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2310 = getelementptr inbounds i16, i16* %10, i64 584
  %2311 = bitcast i16* %2310 to <8 x i16>*
  %2312 = load <8 x i16>, <8 x i16>* %2311, align 16
  %2313 = getelementptr inbounds i16, i16* %11, i64 584
  %2314 = bitcast i16* %2313 to <8 x i16>*
  %2315 = load <8 x i16>, <8 x i16>* %2314, align 16
  %2316 = shufflevector <8 x i16> %2312, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2317 = zext <4 x i16> %2316 to <4 x i32>
  %2318 = shufflevector <8 x i16> %2315, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2319 = zext <4 x i16> %2318 to <4 x i32>
  %2320 = sub nsw <4 x i32> %2317, %2319
  %2321 = sub nsw <4 x i32> zeroinitializer, %2320
  %2322 = icmp slt <4 x i32> %2320, zeroinitializer
  %2323 = select <4 x i1> %2322, <4 x i32> %2321, <4 x i32> %2320
  %2324 = add nuw nsw <4 x i32> %2323, <i32 32, i32 32, i32 32, i32 32>
  %2325 = lshr <4 x i32> %2324, <i32 6, i32 6, i32 6, i32 6>
  %2326 = shufflevector <8 x i16> %2312, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2327 = shufflevector <8 x i16> %2315, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2328 = bitcast <8 x i16> %2326 to <4 x i32>
  %2329 = bitcast <8 x i16> %2327 to <4 x i32>
  %2330 = sub <4 x i32> %2328, %2329
  %2331 = sub <4 x i32> zeroinitializer, %2330
  %2332 = icmp slt <4 x i32> %2330, zeroinitializer
  %2333 = select <4 x i1> %2332, <4 x i32> %2331, <4 x i32> %2330
  %2334 = add nuw <4 x i32> %2333, <i32 32, i32 32, i32 32, i32 32>
  %2335 = lshr <4 x i32> %2334, <i32 6, i32 6, i32 6, i32 6>
  %2336 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2325, <4 x i32> %2335) #5
  %2337 = lshr <8 x i16> %2336, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2338 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2309, <8 x i16> %2337) #5
  %2339 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %2338, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %2340 = icmp slt <16 x i8> %2339, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2341 = select <16 x i1> %2340, <16 x i8> %2339, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2342 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %2341
  %2343 = bitcast i8* %2283 to <16 x i8>*
  store <16 x i8> %2342, <16 x i8>* %2343, align 16
  %2344 = getelementptr inbounds i16, i16* %10, i64 592
  %2345 = getelementptr inbounds i16, i16* %11, i64 592
  %2346 = getelementptr inbounds i8, i8* %2283, i64 16
  %2347 = bitcast i16* %2344 to <8 x i16>*
  %2348 = load <8 x i16>, <8 x i16>* %2347, align 16
  %2349 = bitcast i16* %2345 to <8 x i16>*
  %2350 = load <8 x i16>, <8 x i16>* %2349, align 16
  %2351 = shufflevector <8 x i16> %2348, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2352 = zext <4 x i16> %2351 to <4 x i32>
  %2353 = shufflevector <8 x i16> %2350, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2354 = zext <4 x i16> %2353 to <4 x i32>
  %2355 = sub nsw <4 x i32> %2352, %2354
  %2356 = sub nsw <4 x i32> zeroinitializer, %2355
  %2357 = icmp slt <4 x i32> %2355, zeroinitializer
  %2358 = select <4 x i1> %2357, <4 x i32> %2356, <4 x i32> %2355
  %2359 = add nuw nsw <4 x i32> %2358, <i32 32, i32 32, i32 32, i32 32>
  %2360 = lshr <4 x i32> %2359, <i32 6, i32 6, i32 6, i32 6>
  %2361 = shufflevector <8 x i16> %2348, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2362 = shufflevector <8 x i16> %2350, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2363 = bitcast <8 x i16> %2361 to <4 x i32>
  %2364 = bitcast <8 x i16> %2362 to <4 x i32>
  %2365 = sub <4 x i32> %2363, %2364
  %2366 = sub <4 x i32> zeroinitializer, %2365
  %2367 = icmp slt <4 x i32> %2365, zeroinitializer
  %2368 = select <4 x i1> %2367, <4 x i32> %2366, <4 x i32> %2365
  %2369 = add nuw <4 x i32> %2368, <i32 32, i32 32, i32 32, i32 32>
  %2370 = lshr <4 x i32> %2369, <i32 6, i32 6, i32 6, i32 6>
  %2371 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2360, <4 x i32> %2370) #5
  %2372 = lshr <8 x i16> %2371, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2373 = getelementptr inbounds i16, i16* %10, i64 600
  %2374 = bitcast i16* %2373 to <8 x i16>*
  %2375 = load <8 x i16>, <8 x i16>* %2374, align 16
  %2376 = getelementptr inbounds i16, i16* %11, i64 600
  %2377 = bitcast i16* %2376 to <8 x i16>*
  %2378 = load <8 x i16>, <8 x i16>* %2377, align 16
  %2379 = shufflevector <8 x i16> %2375, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2380 = zext <4 x i16> %2379 to <4 x i32>
  %2381 = shufflevector <8 x i16> %2378, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2382 = zext <4 x i16> %2381 to <4 x i32>
  %2383 = sub nsw <4 x i32> %2380, %2382
  %2384 = sub nsw <4 x i32> zeroinitializer, %2383
  %2385 = icmp slt <4 x i32> %2383, zeroinitializer
  %2386 = select <4 x i1> %2385, <4 x i32> %2384, <4 x i32> %2383
  %2387 = add nuw nsw <4 x i32> %2386, <i32 32, i32 32, i32 32, i32 32>
  %2388 = lshr <4 x i32> %2387, <i32 6, i32 6, i32 6, i32 6>
  %2389 = shufflevector <8 x i16> %2375, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2390 = shufflevector <8 x i16> %2378, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2391 = bitcast <8 x i16> %2389 to <4 x i32>
  %2392 = bitcast <8 x i16> %2390 to <4 x i32>
  %2393 = sub <4 x i32> %2391, %2392
  %2394 = sub <4 x i32> zeroinitializer, %2393
  %2395 = icmp slt <4 x i32> %2393, zeroinitializer
  %2396 = select <4 x i1> %2395, <4 x i32> %2394, <4 x i32> %2393
  %2397 = add nuw <4 x i32> %2396, <i32 32, i32 32, i32 32, i32 32>
  %2398 = lshr <4 x i32> %2397, <i32 6, i32 6, i32 6, i32 6>
  %2399 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2388, <4 x i32> %2398) #5
  %2400 = lshr <8 x i16> %2399, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2401 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2372, <8 x i16> %2400) #5
  %2402 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %2401, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %2403 = icmp slt <16 x i8> %2402, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2404 = select <16 x i1> %2403, <16 x i8> %2402, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2405 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %2404
  %2406 = bitcast i8* %2346 to <16 x i8>*
  store <16 x i8> %2405, <16 x i8>* %2406, align 16
  %2407 = getelementptr inbounds i16, i16* %10, i64 608
  %2408 = getelementptr inbounds i16, i16* %11, i64 608
  %2409 = getelementptr inbounds i8, i8* %2283, i64 32
  %2410 = bitcast i16* %2407 to <8 x i16>*
  %2411 = load <8 x i16>, <8 x i16>* %2410, align 16
  %2412 = bitcast i16* %2408 to <8 x i16>*
  %2413 = load <8 x i16>, <8 x i16>* %2412, align 16
  %2414 = shufflevector <8 x i16> %2411, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2415 = zext <4 x i16> %2414 to <4 x i32>
  %2416 = shufflevector <8 x i16> %2413, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2417 = zext <4 x i16> %2416 to <4 x i32>
  %2418 = sub nsw <4 x i32> %2415, %2417
  %2419 = sub nsw <4 x i32> zeroinitializer, %2418
  %2420 = icmp slt <4 x i32> %2418, zeroinitializer
  %2421 = select <4 x i1> %2420, <4 x i32> %2419, <4 x i32> %2418
  %2422 = add nuw nsw <4 x i32> %2421, <i32 32, i32 32, i32 32, i32 32>
  %2423 = lshr <4 x i32> %2422, <i32 6, i32 6, i32 6, i32 6>
  %2424 = shufflevector <8 x i16> %2411, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2425 = shufflevector <8 x i16> %2413, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2426 = bitcast <8 x i16> %2424 to <4 x i32>
  %2427 = bitcast <8 x i16> %2425 to <4 x i32>
  %2428 = sub <4 x i32> %2426, %2427
  %2429 = sub <4 x i32> zeroinitializer, %2428
  %2430 = icmp slt <4 x i32> %2428, zeroinitializer
  %2431 = select <4 x i1> %2430, <4 x i32> %2429, <4 x i32> %2428
  %2432 = add nuw <4 x i32> %2431, <i32 32, i32 32, i32 32, i32 32>
  %2433 = lshr <4 x i32> %2432, <i32 6, i32 6, i32 6, i32 6>
  %2434 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2423, <4 x i32> %2433) #5
  %2435 = lshr <8 x i16> %2434, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2436 = getelementptr inbounds i16, i16* %10, i64 616
  %2437 = bitcast i16* %2436 to <8 x i16>*
  %2438 = load <8 x i16>, <8 x i16>* %2437, align 16
  %2439 = getelementptr inbounds i16, i16* %11, i64 616
  %2440 = bitcast i16* %2439 to <8 x i16>*
  %2441 = load <8 x i16>, <8 x i16>* %2440, align 16
  %2442 = shufflevector <8 x i16> %2438, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2443 = zext <4 x i16> %2442 to <4 x i32>
  %2444 = shufflevector <8 x i16> %2441, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2445 = zext <4 x i16> %2444 to <4 x i32>
  %2446 = sub nsw <4 x i32> %2443, %2445
  %2447 = sub nsw <4 x i32> zeroinitializer, %2446
  %2448 = icmp slt <4 x i32> %2446, zeroinitializer
  %2449 = select <4 x i1> %2448, <4 x i32> %2447, <4 x i32> %2446
  %2450 = add nuw nsw <4 x i32> %2449, <i32 32, i32 32, i32 32, i32 32>
  %2451 = lshr <4 x i32> %2450, <i32 6, i32 6, i32 6, i32 6>
  %2452 = shufflevector <8 x i16> %2438, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2453 = shufflevector <8 x i16> %2441, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2454 = bitcast <8 x i16> %2452 to <4 x i32>
  %2455 = bitcast <8 x i16> %2453 to <4 x i32>
  %2456 = sub <4 x i32> %2454, %2455
  %2457 = sub <4 x i32> zeroinitializer, %2456
  %2458 = icmp slt <4 x i32> %2456, zeroinitializer
  %2459 = select <4 x i1> %2458, <4 x i32> %2457, <4 x i32> %2456
  %2460 = add nuw <4 x i32> %2459, <i32 32, i32 32, i32 32, i32 32>
  %2461 = lshr <4 x i32> %2460, <i32 6, i32 6, i32 6, i32 6>
  %2462 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2451, <4 x i32> %2461) #5
  %2463 = lshr <8 x i16> %2462, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2464 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2435, <8 x i16> %2463) #5
  %2465 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %2464, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %2466 = icmp slt <16 x i8> %2465, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2467 = select <16 x i1> %2466, <16 x i8> %2465, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2468 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %2467
  %2469 = bitcast i8* %2409 to <16 x i8>*
  store <16 x i8> %2468, <16 x i8>* %2469, align 16
  %2470 = getelementptr inbounds i16, i16* %10, i64 624
  %2471 = getelementptr inbounds i16, i16* %11, i64 624
  %2472 = getelementptr inbounds i8, i8* %2283, i64 48
  %2473 = bitcast i16* %2470 to <8 x i16>*
  %2474 = load <8 x i16>, <8 x i16>* %2473, align 16
  %2475 = bitcast i16* %2471 to <8 x i16>*
  %2476 = load <8 x i16>, <8 x i16>* %2475, align 16
  %2477 = shufflevector <8 x i16> %2474, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2478 = zext <4 x i16> %2477 to <4 x i32>
  %2479 = shufflevector <8 x i16> %2476, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2480 = zext <4 x i16> %2479 to <4 x i32>
  %2481 = sub nsw <4 x i32> %2478, %2480
  %2482 = sub nsw <4 x i32> zeroinitializer, %2481
  %2483 = icmp slt <4 x i32> %2481, zeroinitializer
  %2484 = select <4 x i1> %2483, <4 x i32> %2482, <4 x i32> %2481
  %2485 = add nuw nsw <4 x i32> %2484, <i32 32, i32 32, i32 32, i32 32>
  %2486 = lshr <4 x i32> %2485, <i32 6, i32 6, i32 6, i32 6>
  %2487 = shufflevector <8 x i16> %2474, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2488 = shufflevector <8 x i16> %2476, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2489 = bitcast <8 x i16> %2487 to <4 x i32>
  %2490 = bitcast <8 x i16> %2488 to <4 x i32>
  %2491 = sub <4 x i32> %2489, %2490
  %2492 = sub <4 x i32> zeroinitializer, %2491
  %2493 = icmp slt <4 x i32> %2491, zeroinitializer
  %2494 = select <4 x i1> %2493, <4 x i32> %2492, <4 x i32> %2491
  %2495 = add nuw <4 x i32> %2494, <i32 32, i32 32, i32 32, i32 32>
  %2496 = lshr <4 x i32> %2495, <i32 6, i32 6, i32 6, i32 6>
  %2497 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2486, <4 x i32> %2496) #5
  %2498 = lshr <8 x i16> %2497, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2499 = getelementptr inbounds i16, i16* %10, i64 632
  %2500 = bitcast i16* %2499 to <8 x i16>*
  %2501 = load <8 x i16>, <8 x i16>* %2500, align 16
  %2502 = getelementptr inbounds i16, i16* %11, i64 632
  %2503 = bitcast i16* %2502 to <8 x i16>*
  %2504 = load <8 x i16>, <8 x i16>* %2503, align 16
  %2505 = shufflevector <8 x i16> %2501, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2506 = zext <4 x i16> %2505 to <4 x i32>
  %2507 = shufflevector <8 x i16> %2504, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
  %2508 = zext <4 x i16> %2507 to <4 x i32>
  %2509 = sub nsw <4 x i32> %2506, %2508
  %2510 = sub nsw <4 x i32> zeroinitializer, %2509
  %2511 = icmp slt <4 x i32> %2509, zeroinitializer
  %2512 = select <4 x i1> %2511, <4 x i32> %2510, <4 x i32> %2509
  %2513 = add nuw nsw <4 x i32> %2512, <i32 32, i32 32, i32 32, i32 32>
  %2514 = lshr <4 x i32> %2513, <i32 6, i32 6, i32 6, i32 6>
  %2515 = shufflevector <8 x i16> %2501, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2516 = shufflevector <8 x i16> %2504, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2517 = bitcast <8 x i16> %2515 to <4 x i32>
  %2518 = bitcast <8 x i16> %2516 to <4 x i32>
  %2519 = sub <4 x i32> %2517, %2518
  %2520 = sub <4 x i32> zeroinitializer, %2519
  %2521 = icmp slt <4 x i32> %2519, zeroinitializer
  %2522 = select <4 x i1> %2521, <4 x i32> %2520, <4 x i32> %2519
  %2523 = add nuw <4 x i32> %2522, <i32 32, i32 32, i32 32, i32 32>
  %2524 = lshr <4 x i32> %2523, <i32 6, i32 6, i32 6, i32 6>
  %2525 = tail call <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32> %2514, <4 x i32> %2524) #5
  %2526 = lshr <8 x i16> %2525, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %2527 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %2498, <8 x i16> %2526) #5
  %2528 = tail call <16 x i8> @llvm.uadd.sat.v16i8(<16 x i8> %2527, <16 x i8> <i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38, i8 38>) #5
  %2529 = icmp slt <16 x i8> %2528, <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2530 = select <16 x i1> %2529, <16 x i8> %2528, <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>
  %2531 = sub <16 x i8> <i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64, i8 64>, %2530
  %2532 = bitcast i8* %2472 to <16 x i8>*
  store <16 x i8> %2531, <16 x i8>* %2532, align 16
  ret void
}

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.sse41.packusdw(<4 x i32>, <4 x i32>) #3

attributes #0 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { nofree nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+sse4.1,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { nounwind readnone }
attributes #4 = { nounwind readnone speculatable }
attributes #5 = { nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
