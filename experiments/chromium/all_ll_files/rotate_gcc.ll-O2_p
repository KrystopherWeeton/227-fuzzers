; ModuleID = '../../third_party/libyuv/source/rotate_gcc.cc'
source_filename = "../../third_party/libyuv/source/rotate_gcc.cc"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

; Function Attrs: nounwind ssp uwtable
define hidden void @TransposeWx8_SSSE3(i8*, i32, i8*, i32, i32) local_unnamed_addr #0 {
  %6 = sext i32 %1 to i64
  %7 = sext i32 %3 to i64
  %8 = tail call { i8*, i8*, i32 } asm sideeffect "1:                                        \0Amovq        ($0),%xmm0                   \0Amovq        ($0,$3),%xmm1                \0Alea         ($0,$3,2),$0                  \0Apunpcklbw   %xmm1,%xmm0                 \0Amovq        ($0),%xmm2                   \0Amovdqa      %xmm0,%xmm1                 \0Apalignr     $$0x8,%xmm1,%xmm1            \0Amovq        ($0,$3),%xmm3                \0Alea         ($0,$3,2),$0                  \0Apunpcklbw   %xmm3,%xmm2                 \0Amovdqa      %xmm2,%xmm3                 \0Amovq        ($0),%xmm4                   \0Apalignr     $$0x8,%xmm3,%xmm3            \0Amovq        ($0,$3),%xmm5                \0Alea         ($0,$3,2),$0                  \0Apunpcklbw   %xmm5,%xmm4                 \0Amovdqa      %xmm4,%xmm5                 \0Amovq        ($0),%xmm6                   \0Apalignr     $$0x8,%xmm5,%xmm5            \0Amovq        ($0,$3),%xmm7                \0Alea         ($0,$3,2),$0                  \0Apunpcklbw   %xmm7,%xmm6                 \0Aneg         $3                            \0Amovdqa      %xmm6,%xmm7                 \0Alea         0x8($0,$3,8),$0               \0Apalignr     $$0x8,%xmm7,%xmm7            \0Aneg         $3                            \0Apunpcklwd   %xmm2,%xmm0                 \0Apunpcklwd   %xmm3,%xmm1                 \0Amovdqa      %xmm0,%xmm2                 \0Amovdqa      %xmm1,%xmm3                 \0Apalignr     $$0x8,%xmm2,%xmm2            \0Apalignr     $$0x8,%xmm3,%xmm3            \0Apunpcklwd   %xmm6,%xmm4                 \0Apunpcklwd   %xmm7,%xmm5                 \0Amovdqa      %xmm4,%xmm6                 \0Amovdqa      %xmm5,%xmm7                 \0Apalignr     $$0x8,%xmm6,%xmm6            \0Apalignr     $$0x8,%xmm7,%xmm7            \0Apunpckldq   %xmm4,%xmm0                 \0Amovq        %xmm0,($1)                   \0Amovdqa      %xmm0,%xmm4                 \0Apalignr     $$0x8,%xmm4,%xmm4            \0Amovq        %xmm4,($1,$4)                \0Alea         ($1,$4,2),$1                  \0Apunpckldq   %xmm6,%xmm2                 \0Amovdqa      %xmm2,%xmm6                 \0Amovq        %xmm2,($1)                   \0Apalignr     $$0x8,%xmm6,%xmm6            \0Apunpckldq   %xmm5,%xmm1                 \0Amovq        %xmm6,($1,$4)                \0Alea         ($1,$4,2),$1                  \0Amovdqa      %xmm1,%xmm5                 \0Amovq        %xmm1,($1)                   \0Apalignr     $$0x8,%xmm5,%xmm5            \0Amovq        %xmm5,($1,$4)                \0Alea         ($1,$4,2),$1                  \0Apunpckldq   %xmm7,%xmm3                 \0Amovq        %xmm3,($1)                   \0Amovdqa      %xmm3,%xmm7                 \0Apalignr     $$0x8,%xmm7,%xmm7            \0Asub         $$0x8,$2                       \0Amovq        %xmm7,($1,$4)                \0Alea         ($1,$4,2),$1                  \0Ajg          1b                            \0A", "=r,=r,=r,r,r,0,1,2,~{memory},~{cc},~{xmm0},~{xmm1},~{xmm2},~{xmm3},~{xmm4},~{xmm5},~{xmm6},~{xmm7},~{dirflag},~{fpsr},~{flags}"(i64 %6, i64 %7, i8* %0, i8* %2, i32 %4) #1, !srcloc !2
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @TransposeWx8_Fast_SSSE3(i8*, i32, i8*, i32, i32) local_unnamed_addr #0 {
  %6 = sext i32 %1 to i64
  %7 = sext i32 %3 to i64
  %8 = tail call { i8*, i8*, i32 } asm sideeffect "1:                                        \0Amovdqu      ($0),%xmm0                   \0Amovdqu      ($0,$3),%xmm1                \0Alea         ($0,$3,2),$0                  \0Amovdqa      %xmm0,%xmm8                 \0Apunpcklbw   %xmm1,%xmm0                 \0Apunpckhbw   %xmm1,%xmm8                 \0Amovdqu      ($0),%xmm2                   \0Amovdqa      %xmm0,%xmm1                 \0Amovdqa      %xmm8,%xmm9                 \0Apalignr     $$0x8,%xmm1,%xmm1            \0Apalignr     $$0x8,%xmm9,%xmm9            \0Amovdqu      ($0,$3),%xmm3                \0Alea         ($0,$3,2),$0                  \0Amovdqa      %xmm2,%xmm10                \0Apunpcklbw   %xmm3,%xmm2                 \0Apunpckhbw   %xmm3,%xmm10                \0Amovdqa      %xmm2,%xmm3                 \0Amovdqa      %xmm10,%xmm11               \0Amovdqu      ($0),%xmm4                   \0Apalignr     $$0x8,%xmm3,%xmm3            \0Apalignr     $$0x8,%xmm11,%xmm11          \0Amovdqu      ($0,$3),%xmm5                \0Alea         ($0,$3,2),$0                  \0Amovdqa      %xmm4,%xmm12                \0Apunpcklbw   %xmm5,%xmm4                 \0Apunpckhbw   %xmm5,%xmm12                \0Amovdqa      %xmm4,%xmm5                 \0Amovdqa      %xmm12,%xmm13               \0Amovdqu      ($0),%xmm6                   \0Apalignr     $$0x8,%xmm5,%xmm5            \0Apalignr     $$0x8,%xmm13,%xmm13          \0Amovdqu      ($0,$3),%xmm7                \0Alea         ($0,$3,2),$0                  \0Amovdqa      %xmm6,%xmm14                \0Apunpcklbw   %xmm7,%xmm6                 \0Apunpckhbw   %xmm7,%xmm14                \0Aneg         $3                            \0Amovdqa      %xmm6,%xmm7                 \0Amovdqa      %xmm14,%xmm15               \0Alea         0x10($0,$3,8),$0              \0Apalignr     $$0x8,%xmm7,%xmm7            \0Apalignr     $$0x8,%xmm15,%xmm15          \0Aneg         $3                            \0Apunpcklwd   %xmm2,%xmm0                 \0Apunpcklwd   %xmm3,%xmm1                 \0Amovdqa      %xmm0,%xmm2                 \0Amovdqa      %xmm1,%xmm3                 \0Apalignr     $$0x8,%xmm2,%xmm2            \0Apalignr     $$0x8,%xmm3,%xmm3            \0Apunpcklwd   %xmm6,%xmm4                 \0Apunpcklwd   %xmm7,%xmm5                 \0Amovdqa      %xmm4,%xmm6                 \0Amovdqa      %xmm5,%xmm7                 \0Apalignr     $$0x8,%xmm6,%xmm6            \0Apalignr     $$0x8,%xmm7,%xmm7            \0Apunpcklwd   %xmm10,%xmm8                \0Apunpcklwd   %xmm11,%xmm9                \0Amovdqa      %xmm8,%xmm10                \0Amovdqa      %xmm9,%xmm11                \0Apalignr     $$0x8,%xmm10,%xmm10          \0Apalignr     $$0x8,%xmm11,%xmm11          \0Apunpcklwd   %xmm14,%xmm12               \0Apunpcklwd   %xmm15,%xmm13               \0Amovdqa      %xmm12,%xmm14               \0Amovdqa      %xmm13,%xmm15               \0Apalignr     $$0x8,%xmm14,%xmm14          \0Apalignr     $$0x8,%xmm15,%xmm15          \0Apunpckldq   %xmm4,%xmm0                 \0Amovq        %xmm0,($1)                   \0Amovdqa      %xmm0,%xmm4                 \0Apalignr     $$0x8,%xmm4,%xmm4            \0Amovq        %xmm4,($1,$4)                \0Alea         ($1,$4,2),$1                  \0Apunpckldq   %xmm6,%xmm2                 \0Amovdqa      %xmm2,%xmm6                 \0Amovq        %xmm2,($1)                   \0Apalignr     $$0x8,%xmm6,%xmm6            \0Apunpckldq   %xmm5,%xmm1                 \0Amovq        %xmm6,($1,$4)                \0Alea         ($1,$4,2),$1                  \0Amovdqa      %xmm1,%xmm5                 \0Amovq        %xmm1,($1)                   \0Apalignr     $$0x8,%xmm5,%xmm5            \0Amovq        %xmm5,($1,$4)                \0Alea         ($1,$4,2),$1                  \0Apunpckldq   %xmm7,%xmm3                 \0Amovq        %xmm3,($1)                   \0Amovdqa      %xmm3,%xmm7                 \0Apalignr     $$0x8,%xmm7,%xmm7            \0Amovq        %xmm7,($1,$4)                \0Alea         ($1,$4,2),$1                  \0Apunpckldq   %xmm12,%xmm8                \0Amovq        %xmm8,($1)                   \0Amovdqa      %xmm8,%xmm12                \0Apalignr     $$0x8,%xmm12,%xmm12          \0Amovq        %xmm12,($1,$4)               \0Alea         ($1,$4,2),$1                  \0Apunpckldq   %xmm14,%xmm10               \0Amovdqa      %xmm10,%xmm14               \0Amovq        %xmm10,($1)                  \0Apalignr     $$0x8,%xmm14,%xmm14          \0Apunpckldq   %xmm13,%xmm9                \0Amovq        %xmm14,($1,$4)               \0Alea         ($1,$4,2),$1                  \0Amovdqa      %xmm9,%xmm13                \0Amovq        %xmm9,($1)                   \0Apalignr     $$0x8,%xmm13,%xmm13          \0Amovq        %xmm13,($1,$4)               \0Alea         ($1,$4,2),$1                  \0Apunpckldq   %xmm15,%xmm11               \0Amovq        %xmm11,($1)                  \0Amovdqa      %xmm11,%xmm15               \0Apalignr     $$0x8,%xmm15,%xmm15          \0Asub         $$0x10,$2                      \0Amovq        %xmm15,($1,$4)               \0Alea         ($1,$4,2),$1                  \0Ajg          1b                            \0A", "=r,=r,=r,r,r,0,1,2,~{memory},~{cc},~{xmm0},~{xmm1},~{xmm2},~{xmm3},~{xmm4},~{xmm5},~{xmm6},~{xmm7},~{xmm8},~{xmm9},~{xmm10},~{xmm11},~{xmm12},~{xmm13},~{xmm14},~{xmm15},~{dirflag},~{fpsr},~{flags}"(i64 %6, i64 %7, i8* %0, i8* %2, i32 %4) #1, !srcloc !3
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @TransposeUVWx8_SSE2(i8*, i32, i8*, i32, i8*, i32, i32) local_unnamed_addr #0 {
  %8 = sext i32 %1 to i64
  %9 = sext i32 %3 to i64
  %10 = sext i32 %5 to i64
  %11 = tail call { i8*, i8*, i8*, i32 } asm sideeffect "1:                                        \0Amovdqu      ($0),%xmm0                   \0Amovdqu      ($0,$4),%xmm1                \0Alea         ($0,$4,2),$0                  \0Amovdqa      %xmm0,%xmm8                 \0Apunpcklbw   %xmm1,%xmm0                 \0Apunpckhbw   %xmm1,%xmm8                 \0Amovdqa      %xmm8,%xmm1                 \0Amovdqu      ($0),%xmm2                   \0Amovdqu      ($0,$4),%xmm3                \0Alea         ($0,$4,2),$0                  \0Amovdqa      %xmm2,%xmm8                 \0Apunpcklbw   %xmm3,%xmm2                 \0Apunpckhbw   %xmm3,%xmm8                 \0Amovdqa      %xmm8,%xmm3                 \0Amovdqu      ($0),%xmm4                   \0Amovdqu      ($0,$4),%xmm5                \0Alea         ($0,$4,2),$0                  \0Amovdqa      %xmm4,%xmm8                 \0Apunpcklbw   %xmm5,%xmm4                 \0Apunpckhbw   %xmm5,%xmm8                 \0Amovdqa      %xmm8,%xmm5                 \0Amovdqu      ($0),%xmm6                   \0Amovdqu      ($0,$4),%xmm7                \0Alea         ($0,$4,2),$0                  \0Amovdqa      %xmm6,%xmm8                 \0Apunpcklbw   %xmm7,%xmm6                 \0Aneg         $4                            \0Alea         0x10($0,$4,8),$0              \0Apunpckhbw   %xmm7,%xmm8                 \0Amovdqa      %xmm8,%xmm7                 \0Aneg         $4                            \0Amovdqa      %xmm0,%xmm8                 \0Amovdqa      %xmm1,%xmm9                 \0Apunpckhwd   %xmm2,%xmm8                 \0Apunpckhwd   %xmm3,%xmm9                 \0Apunpcklwd   %xmm2,%xmm0                 \0Apunpcklwd   %xmm3,%xmm1                 \0Amovdqa      %xmm8,%xmm2                 \0Amovdqa      %xmm9,%xmm3                 \0Amovdqa      %xmm4,%xmm8                 \0Amovdqa      %xmm5,%xmm9                 \0Apunpckhwd   %xmm6,%xmm8                 \0Apunpckhwd   %xmm7,%xmm9                 \0Apunpcklwd   %xmm6,%xmm4                 \0Apunpcklwd   %xmm7,%xmm5                 \0Amovdqa      %xmm8,%xmm6                 \0Amovdqa      %xmm9,%xmm7                 \0Amovdqa      %xmm0,%xmm8                 \0Apunpckldq   %xmm4,%xmm0                 \0Amovlpd      %xmm0,($1)                   \0Amovhpd      %xmm0,($2)                   \0Apunpckhdq   %xmm4,%xmm8                 \0Amovlpd      %xmm8,($1,$5)                \0Alea         ($1,$5,2),$1                  \0Amovhpd      %xmm8,($2,$6)                \0Alea         ($2,$6,2),$2                  \0Amovdqa      %xmm2,%xmm8                 \0Apunpckldq   %xmm6,%xmm2                 \0Amovlpd      %xmm2,($1)                   \0Amovhpd      %xmm2,($2)                   \0Apunpckhdq   %xmm6,%xmm8                 \0Amovlpd      %xmm8,($1,$5)                \0Alea         ($1,$5,2),$1                  \0Amovhpd      %xmm8,($2,$6)                \0Alea         ($2,$6,2),$2                  \0Amovdqa      %xmm1,%xmm8                 \0Apunpckldq   %xmm5,%xmm1                 \0Amovlpd      %xmm1,($1)                   \0Amovhpd      %xmm1,($2)                   \0Apunpckhdq   %xmm5,%xmm8                 \0Amovlpd      %xmm8,($1,$5)                \0Alea         ($1,$5,2),$1                  \0Amovhpd      %xmm8,($2,$6)                \0Alea         ($2,$6,2),$2                  \0Amovdqa      %xmm3,%xmm8                 \0Apunpckldq   %xmm7,%xmm3                 \0Amovlpd      %xmm3,($1)                   \0Amovhpd      %xmm3,($2)                   \0Apunpckhdq   %xmm7,%xmm8                 \0Asub         $$0x8,$3                       \0Amovlpd      %xmm8,($1,$5)                \0Alea         ($1,$5,2),$1                  \0Amovhpd      %xmm8,($2,$6)                \0Alea         ($2,$6,2),$2                  \0Ajg          1b                            \0A", "=r,=r,=r,=r,r,r,r,0,1,2,3,~{memory},~{cc},~{xmm0},~{xmm1},~{xmm2},~{xmm3},~{xmm4},~{xmm5},~{xmm6},~{xmm7},~{xmm8},~{xmm9},~{dirflag},~{fpsr},~{flags}"(i64 %8, i64 %9, i64 %10, i8* %0, i8* %2, i8* %4, i32 %6) #1, !srcloc !4
  ret void
}

attributes #0 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = !{i32 1061, i32 1115, i32 1168, i32 1221, i32 1274, i32 1327, i32 1380, i32 1433, i32 1486, i32 1539, i32 1592, i32 1645, i32 1698, i32 1751, i32 1804, i32 1857, i32 1910, i32 1963, i32 2016, i32 2069, i32 2122, i32 2175, i32 2228, i32 2281, i32 2334, i32 2387, i32 2440, i32 2493, i32 2581, i32 2634, i32 2687, i32 2740, i32 2793, i32 2846, i32 2899, i32 2952, i32 3005, i32 3058, i32 3111, i32 3164, i32 3294, i32 3347, i32 3400, i32 3453, i32 3506, i32 3559, i32 3612, i32 3665, i32 3718, i32 3771, i32 3824, i32 3877, i32 3930, i32 3983, i32 4036, i32 4089, i32 4142, i32 4195, i32 4248, i32 4301, i32 4354, i32 4407, i32 4460, i32 4513, i32 4566, i32 4619}
!3 = !{i32 5443, i32 5497, i32 5550, i32 5603, i32 5656, i32 5709, i32 5762, i32 5815, i32 5868, i32 5921, i32 5974, i32 6027, i32 6080, i32 6133, i32 6186, i32 6239, i32 6292, i32 6345, i32 6398, i32 6451, i32 6504, i32 6557, i32 6610, i32 6663, i32 6716, i32 6769, i32 6822, i32 6875, i32 6928, i32 6981, i32 7034, i32 7087, i32 7140, i32 7193, i32 7246, i32 7299, i32 7352, i32 7405, i32 7458, i32 7511, i32 7564, i32 7617, i32 7670, i32 7723, i32 7811, i32 7864, i32 7917, i32 7970, i32 8023, i32 8076, i32 8129, i32 8182, i32 8235, i32 8288, i32 8341, i32 8394, i32 8447, i32 8500, i32 8553, i32 8606, i32 8659, i32 8712, i32 8765, i32 8818, i32 8871, i32 8924, i32 8977, i32 9030, i32 9160, i32 9213, i32 9266, i32 9319, i32 9372, i32 9425, i32 9478, i32 9531, i32 9584, i32 9637, i32 9690, i32 9743, i32 9796, i32 9849, i32 9902, i32 9955, i32 10008, i32 10061, i32 10114, i32 10167, i32 10220, i32 10273, i32 10326, i32 10379, i32 10432, i32 10485, i32 10538, i32 10591, i32 10644, i32 10697, i32 10750, i32 10803, i32 10856, i32 10909, i32 10962, i32 11015, i32 11068, i32 11121, i32 11174, i32 11227, i32 11280, i32 11333, i32 11386, i32 11439, i32 11492, i32 11545, i32 11598, i32 11651, i32 11704, i32 11757}
!4 = !{i32 12732, i32 12786, i32 12839, i32 12892, i32 12945, i32 12998, i32 13051, i32 13104, i32 13157, i32 13210, i32 13263, i32 13316, i32 13369, i32 13422, i32 13475, i32 13528, i32 13581, i32 13634, i32 13687, i32 13740, i32 13793, i32 13846, i32 13899, i32 13952, i32 14005, i32 14058, i32 14111, i32 14164, i32 14217, i32 14270, i32 14323, i32 14376, i32 14464, i32 14517, i32 14570, i32 14623, i32 14676, i32 14729, i32 14782, i32 14835, i32 14888, i32 14941, i32 14994, i32 15047, i32 15100, i32 15153, i32 15206, i32 15259, i32 15389, i32 15442, i32 15495, i32 15573, i32 15651, i32 15704, i32 15757, i32 15810, i32 15863, i32 15916, i32 15969, i32 16022, i32 16075, i32 16128, i32 16181, i32 16234, i32 16287, i32 16340, i32 16393, i32 16446, i32 16499, i32 16552, i32 16605, i32 16658, i32 16711, i32 16764, i32 16817, i32 16870, i32 16923, i32 16976, i32 17029, i32 17082, i32 17135, i32 17188, i32 17241, i32 17294, i32 17347, i32 17400}
