; ModuleID = '../../third_party/libvpx/source/libvpx/vpx_dsp/x86/inv_txfm_sse2.c'
source_filename = "../../third_party/libvpx/source/libvpx/vpx_dsp/x86/inv_txfm_sse2.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

; Function Attrs: nounwind ssp uwtable
define hidden void @vpx_idct4x4_16_add_sse2(i32* nocapture readonly, i8* nocapture, i32) local_unnamed_addr #0 {
  %4 = bitcast i32* %0 to <4 x i32>*
  %5 = load <4 x i32>, <4 x i32>* %4, align 16
  %6 = getelementptr inbounds i32, i32* %0, i64 4
  %7 = bitcast i32* %6 to <4 x i32>*
  %8 = load <4 x i32>, <4 x i32>* %7, align 16
  %9 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %5, <4 x i32> %8) #6
  %10 = getelementptr inbounds i32, i32* %0, i64 8
  %11 = bitcast i32* %10 to <4 x i32>*
  %12 = load <4 x i32>, <4 x i32>* %11, align 16
  %13 = getelementptr inbounds i32, i32* %0, i64 12
  %14 = bitcast i32* %13 to <4 x i32>*
  %15 = load <4 x i32>, <4 x i32>* %14, align 16
  %16 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %12, <4 x i32> %15) #6
  %17 = shufflevector <8 x i16> %9, <8 x i16> %16, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %18 = shufflevector <8 x i16> %9, <8 x i16> %16, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %19 = shufflevector <8 x i16> %17, <8 x i16> %18, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %20 = shufflevector <8 x i16> %17, <8 x i16> %18, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %21 = shufflevector <8 x i16> %19, <8 x i16> %20, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %22 = shufflevector <8 x i16> %19, <8 x i16> %20, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %23 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>, <8 x i16> %21) #6
  %24 = add <4 x i32> %23, <i32 8192, i32 8192, i32 8192, i32 8192>
  %25 = ashr <4 x i32> %24, <i32 14, i32 14, i32 14, i32 14>
  %26 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>, <8 x i16> %21) #6
  %27 = add <4 x i32> %26, <i32 8192, i32 8192, i32 8192, i32 8192>
  %28 = ashr <4 x i32> %27, <i32 14, i32 14, i32 14, i32 14>
  %29 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %25, <4 x i32> %28) #6
  %30 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>, <8 x i16> %22) #6
  %31 = add <4 x i32> %30, <i32 8192, i32 8192, i32 8192, i32 8192>
  %32 = ashr <4 x i32> %31, <i32 14, i32 14, i32 14, i32 14>
  %33 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>, <8 x i16> %22) #6
  %34 = add <4 x i32> %33, <i32 8192, i32 8192, i32 8192, i32 8192>
  %35 = ashr <4 x i32> %34, <i32 14, i32 14, i32 14, i32 14>
  %36 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %32, <4 x i32> %35) #6
  %37 = add <8 x i16> %36, %29
  %38 = sub <8 x i16> %29, %36
  %39 = bitcast <8 x i16> %38 to <4 x i32>
  %40 = shufflevector <4 x i32> %39, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %41 = bitcast <4 x i32> %40 to <8 x i16>
  %42 = shufflevector <8 x i16> %37, <8 x i16> %41, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %43 = shufflevector <8 x i16> %37, <8 x i16> %41, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %44 = shufflevector <8 x i16> %42, <8 x i16> %43, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %45 = shufflevector <8 x i16> %42, <8 x i16> %43, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %46 = shufflevector <8 x i16> %44, <8 x i16> %45, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %47 = shufflevector <8 x i16> %44, <8 x i16> %45, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %48 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>, <8 x i16> %46) #6
  %49 = add <4 x i32> %48, <i32 8192, i32 8192, i32 8192, i32 8192>
  %50 = ashr <4 x i32> %49, <i32 14, i32 14, i32 14, i32 14>
  %51 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>, <8 x i16> %46) #6
  %52 = add <4 x i32> %51, <i32 8192, i32 8192, i32 8192, i32 8192>
  %53 = ashr <4 x i32> %52, <i32 14, i32 14, i32 14, i32 14>
  %54 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %50, <4 x i32> %53) #6
  %55 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>, <8 x i16> %47) #6
  %56 = add <4 x i32> %55, <i32 8192, i32 8192, i32 8192, i32 8192>
  %57 = ashr <4 x i32> %56, <i32 14, i32 14, i32 14, i32 14>
  %58 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>, <8 x i16> %47) #6
  %59 = add <4 x i32> %58, <i32 8192, i32 8192, i32 8192, i32 8192>
  %60 = ashr <4 x i32> %59, <i32 14, i32 14, i32 14, i32 14>
  %61 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %57, <4 x i32> %60) #6
  %62 = sub <8 x i16> %54, %61
  %63 = bitcast <8 x i16> %62 to <4 x i32>
  %64 = shufflevector <4 x i32> %63, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %65 = add <8 x i16> %54, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %66 = add <8 x i16> %65, %61
  %67 = bitcast <4 x i32> %64 to <8 x i16>
  %68 = add <8 x i16> %67, <i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8, i16 8>
  %69 = ashr <8 x i16> %66, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %70 = ashr <8 x i16> %68, <i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4, i16 4>
  %71 = bitcast i8* %1 to i32*
  %72 = load i32, i32* %71, align 4
  %73 = insertelement <4 x i32> undef, i32 %72, i32 0
  %74 = mul nsw i32 %2, 3
  %75 = sext i32 %74 to i64
  %76 = getelementptr inbounds i8, i8* %1, i64 %75
  %77 = bitcast i8* %76 to i32*
  %78 = load i32, i32* %77, align 4
  %79 = sext i32 %2 to i64
  %80 = getelementptr inbounds i8, i8* %1, i64 %79
  %81 = bitcast i8* %80 to i32*
  %82 = load i32, i32* %81, align 4
  %83 = insertelement <4 x i32> %73, i32 %82, i32 1
  %84 = shl nsw i32 %2, 1
  %85 = sext i32 %84 to i64
  %86 = getelementptr inbounds i8, i8* %1, i64 %85
  %87 = bitcast i8* %86 to i32*
  %88 = load i32, i32* %87, align 4
  %89 = insertelement <4 x i32> undef, i32 %88, i32 0
  %90 = insertelement <4 x i32> %89, i32 %78, i32 1
  %91 = bitcast <4 x i32> %83 to <16 x i8>
  %92 = shufflevector <16 x i8> %91, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %93 = bitcast <4 x i32> %90 to <16 x i8>
  %94 = shufflevector <16 x i8> %93, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %95 = bitcast <16 x i8> %92 to <8 x i16>
  %96 = add <8 x i16> %69, %95
  %97 = bitcast <16 x i8> %94 to <8 x i16>
  %98 = add <8 x i16> %70, %97
  %99 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %96, <8 x i16> %98) #6
  %100 = bitcast <16 x i8> %99 to <4 x i32>
  %101 = extractelement <4 x i32> %100, i32 0
  store i32 %101, i32* %71, align 4
  %102 = shufflevector <16 x i8> %99, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %103 = bitcast <16 x i8> %102 to <4 x i32>
  %104 = extractelement <4 x i32> %103, i32 0
  store i32 %104, i32* %81, align 4
  %105 = shufflevector <16 x i8> %102, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %106 = bitcast <16 x i8> %105 to <4 x i32>
  %107 = extractelement <4 x i32> %106, i32 0
  store i32 %107, i32* %87, align 4
  %108 = shufflevector <16 x i8> %105, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %109 = bitcast <16 x i8> %108 to <4 x i32>
  %110 = extractelement <4 x i32> %109, i32 0
  store i32 %110, i32* %77, align 4
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @idct4_sse2(<2 x i64>* nocapture) local_unnamed_addr #2 {
  %2 = bitcast <2 x i64>* %0 to <8 x i16>*
  %3 = load <8 x i16>, <8 x i16>* %2, align 16
  %4 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %5 = bitcast <2 x i64>* %4 to <8 x i16>*
  %6 = load <8 x i16>, <8 x i16>* %5, align 16
  %7 = shufflevector <8 x i16> %3, <8 x i16> %6, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %8 = shufflevector <8 x i16> %3, <8 x i16> %6, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %9 = shufflevector <8 x i16> %7, <8 x i16> %8, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10 = shufflevector <8 x i16> %7, <8 x i16> %8, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %11 = shufflevector <8 x i16> %9, <8 x i16> %10, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %12 = shufflevector <8 x i16> %9, <8 x i16> %10, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %13 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>, <8 x i16> %11) #6
  %14 = add <4 x i32> %13, <i32 8192, i32 8192, i32 8192, i32 8192>
  %15 = ashr <4 x i32> %14, <i32 14, i32 14, i32 14, i32 14>
  %16 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>, <8 x i16> %11) #6
  %17 = add <4 x i32> %16, <i32 8192, i32 8192, i32 8192, i32 8192>
  %18 = ashr <4 x i32> %17, <i32 14, i32 14, i32 14, i32 14>
  %19 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %15, <4 x i32> %18) #6
  %20 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>, <8 x i16> %12) #6
  %21 = add <4 x i32> %20, <i32 8192, i32 8192, i32 8192, i32 8192>
  %22 = ashr <4 x i32> %21, <i32 14, i32 14, i32 14, i32 14>
  %23 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>, <8 x i16> %12) #6
  %24 = add <4 x i32> %23, <i32 8192, i32 8192, i32 8192, i32 8192>
  %25 = ashr <4 x i32> %24, <i32 14, i32 14, i32 14, i32 14>
  %26 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %22, <4 x i32> %25) #6
  %27 = add <8 x i16> %26, %19
  store <8 x i16> %27, <8 x i16>* %2, align 16
  %28 = sub <8 x i16> %19, %26
  %29 = bitcast <8 x i16> %28 to <4 x i32>
  %30 = shufflevector <4 x i32> %29, <4 x i32> undef, <4 x i32> <i32 2, i32 3, i32 0, i32 1>
  %31 = bitcast <2 x i64>* %4 to <4 x i32>*
  store <4 x i32> %30, <4 x i32>* %31, align 16
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @vpx_idct4x4_1_add_sse2(i32* nocapture readonly, i8* nocapture, i32) local_unnamed_addr #2 {
  %4 = load i32, i32* %0, align 4
  %5 = shl i32 %4, 16
  %6 = ashr exact i32 %5, 16
  %7 = mul nsw i32 %6, 11585
  %8 = add nsw i32 %7, 8192
  %9 = ashr i32 %8, 14
  %10 = sext i32 %9 to i64
  %11 = mul nsw i64 %10, 49757196124160
  %12 = ashr exact i64 %11, 32
  %13 = add nsw i64 %12, 8192
  %14 = lshr i64 %13, 14
  %15 = trunc i64 %14 to i32
  %16 = add i32 %15, 8
  %17 = lshr i32 %16, 4
  %18 = trunc i32 %17 to i16
  %19 = insertelement <8 x i16> undef, i16 %18, i32 0
  %20 = shufflevector <8 x i16> %19, <8 x i16> undef, <8 x i32> zeroinitializer
  %21 = bitcast i8* %1 to i32*
  %22 = load i32, i32* %21, align 4
  %23 = insertelement <4 x i32> undef, i32 %22, i32 0
  %24 = mul nsw i32 %2, 3
  %25 = sext i32 %24 to i64
  %26 = getelementptr inbounds i8, i8* %1, i64 %25
  %27 = bitcast i8* %26 to i32*
  %28 = load i32, i32* %27, align 4
  %29 = sext i32 %2 to i64
  %30 = getelementptr inbounds i8, i8* %1, i64 %29
  %31 = bitcast i8* %30 to i32*
  %32 = load i32, i32* %31, align 4
  %33 = insertelement <4 x i32> %23, i32 %32, i32 1
  %34 = shl nsw i32 %2, 1
  %35 = sext i32 %34 to i64
  %36 = getelementptr inbounds i8, i8* %1, i64 %35
  %37 = bitcast i8* %36 to i32*
  %38 = load i32, i32* %37, align 4
  %39 = insertelement <4 x i32> undef, i32 %38, i32 0
  %40 = insertelement <4 x i32> %39, i32 %28, i32 1
  %41 = bitcast <4 x i32> %33 to <16 x i8>
  %42 = shufflevector <16 x i8> %41, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %43 = bitcast <4 x i32> %40 to <16 x i8>
  %44 = shufflevector <16 x i8> %43, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %45 = bitcast <16 x i8> %42 to <8 x i16>
  %46 = add <8 x i16> %20, %45
  %47 = bitcast <16 x i8> %44 to <8 x i16>
  %48 = add <8 x i16> %20, %47
  %49 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %46, <8 x i16> %48) #6
  %50 = bitcast <16 x i8> %49 to <4 x i32>
  %51 = extractelement <4 x i32> %50, i32 0
  store i32 %51, i32* %21, align 4
  %52 = shufflevector <16 x i8> %49, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %53 = bitcast <16 x i8> %52 to <4 x i32>
  %54 = extractelement <4 x i32> %53, i32 0
  store i32 %54, i32* %31, align 4
  %55 = shufflevector <16 x i8> %52, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19>
  %56 = bitcast <16 x i8> %55 to <4 x i32>
  %57 = extractelement <4 x i32> %56, i32 0
  store i32 %57, i32* %37, align 4
  %58 = shufflevector <16 x i8> %55, <16 x i8> undef, <16 x i32> <i32 4, i32 5, i32 6, i32 7, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef, i32 undef>
  %59 = bitcast <16 x i8> %58 to <4 x i32>
  %60 = extractelement <4 x i32> %59, i32 0
  store i32 %60, i32* %27, align 4
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @iadst4_sse2(<2 x i64>* nocapture) local_unnamed_addr #2 {
  %2 = bitcast <2 x i64>* %0 to <4 x i32>*
  %3 = load <4 x i32>, <4 x i32>* %2, align 16
  %4 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %5 = bitcast <2 x i64>* %4 to <4 x i32>*
  %6 = load <4 x i32>, <4 x i32>* %5, align 16
  %7 = shufflevector <4 x i32> %3, <4 x i32> %6, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %8 = shufflevector <4 x i32> %3, <4 x i32> %6, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %9 = shufflevector <4 x i32> %7, <4 x i32> %8, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %10 = shufflevector <4 x i32> %7, <4 x i32> %8, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %11 = bitcast <4 x i32> %9 to <8 x i16>
  %12 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11, <8 x i16> <i16 5283, i16 13377, i16 5283, i16 13377, i16 5283, i16 13377, i16 5283, i16 13377>) #6
  %13 = bitcast <4 x i32> %10 to <8 x i16>
  %14 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %13, <8 x i16> <i16 15212, i16 9929, i16 15212, i16 9929, i16 15212, i16 9929, i16 15212, i16 9929>) #6
  %15 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11, <8 x i16> <i16 9929, i16 13377, i16 9929, i16 13377, i16 9929, i16 13377, i16 9929, i16 13377>) #6
  %16 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %13, <8 x i16> <i16 5283, i16 15212, i16 5283, i16 15212, i16 5283, i16 15212, i16 5283, i16 15212>) #6
  %17 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11, <8 x i16> <i16 15212, i16 -13377, i16 15212, i16 -13377, i16 15212, i16 -13377, i16 15212, i16 -13377>) #6
  %18 = sub <8 x i16> %11, %13
  %19 = bitcast <2 x i64>* %0 to <8 x i16>*
  %20 = lshr <4 x i32> %10, <i32 16, i32 16, i32 16, i32 16>
  %21 = bitcast <4 x i32> %20 to <8 x i16>
  %22 = add <8 x i16> %18, %21
  %23 = bitcast <8 x i16> %22 to <4 x i32>
  %24 = shl <4 x i32> %23, <i32 16, i32 16, i32 16, i32 16>
  %25 = bitcast <4 x i32> %24 to <8 x i16>
  %26 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %25, <8 x i16> <i16 5283, i16 13377, i16 5283, i16 13377, i16 5283, i16 13377, i16 5283, i16 13377>) #6
  %27 = add <4 x i32> %12, <i32 8192, i32 8192, i32 8192, i32 8192>
  %28 = add <4 x i32> %27, %14
  %29 = ashr <4 x i32> %28, <i32 14, i32 14, i32 14, i32 14>
  %30 = add <4 x i32> %15, <i32 8192, i32 8192, i32 8192, i32 8192>
  %31 = sub <4 x i32> %30, %16
  %32 = ashr <4 x i32> %31, <i32 14, i32 14, i32 14, i32 14>
  %33 = add <4 x i32> %26, <i32 8192, i32 8192, i32 8192, i32 8192>
  %34 = ashr <4 x i32> %33, <i32 14, i32 14, i32 14, i32 14>
  %35 = add <4 x i32> %14, <i32 8192, i32 8192, i32 8192, i32 8192>
  %36 = sub <4 x i32> %35, %16
  %37 = add <4 x i32> %36, %17
  %38 = ashr <4 x i32> %37, <i32 14, i32 14, i32 14, i32 14>
  %39 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %29, <4 x i32> %32) #6
  store <8 x i16> %39, <8 x i16>* %19, align 16
  %40 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %34, <4 x i32> %38) #6
  %41 = bitcast <2 x i64>* %4 to <8 x i16>*
  store <8 x i16> %40, <8 x i16>* %41, align 16
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #1

; Function Attrs: nounwind ssp uwtable
define hidden void @vpx_idct8x8_64_add_sse2(i32* nocapture readonly, i8* nocapture, i32) local_unnamed_addr #0 {
  %4 = bitcast i32* %0 to <4 x i32>*
  %5 = load <4 x i32>, <4 x i32>* %4, align 16
  %6 = getelementptr inbounds i32, i32* %0, i64 4
  %7 = bitcast i32* %6 to <4 x i32>*
  %8 = load <4 x i32>, <4 x i32>* %7, align 16
  %9 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %5, <4 x i32> %8) #6
  %10 = getelementptr inbounds i32, i32* %0, i64 8
  %11 = bitcast i32* %10 to <4 x i32>*
  %12 = load <4 x i32>, <4 x i32>* %11, align 16
  %13 = getelementptr inbounds i32, i32* %0, i64 12
  %14 = bitcast i32* %13 to <4 x i32>*
  %15 = load <4 x i32>, <4 x i32>* %14, align 16
  %16 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %12, <4 x i32> %15) #6
  %17 = getelementptr inbounds i32, i32* %0, i64 16
  %18 = bitcast i32* %17 to <4 x i32>*
  %19 = load <4 x i32>, <4 x i32>* %18, align 16
  %20 = getelementptr inbounds i32, i32* %0, i64 20
  %21 = bitcast i32* %20 to <4 x i32>*
  %22 = load <4 x i32>, <4 x i32>* %21, align 16
  %23 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %19, <4 x i32> %22) #6
  %24 = getelementptr inbounds i32, i32* %0, i64 24
  %25 = bitcast i32* %24 to <4 x i32>*
  %26 = load <4 x i32>, <4 x i32>* %25, align 16
  %27 = getelementptr inbounds i32, i32* %0, i64 28
  %28 = bitcast i32* %27 to <4 x i32>*
  %29 = load <4 x i32>, <4 x i32>* %28, align 16
  %30 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %26, <4 x i32> %29) #6
  %31 = getelementptr inbounds i32, i32* %0, i64 32
  %32 = bitcast i32* %31 to <4 x i32>*
  %33 = load <4 x i32>, <4 x i32>* %32, align 16
  %34 = getelementptr inbounds i32, i32* %0, i64 36
  %35 = bitcast i32* %34 to <4 x i32>*
  %36 = load <4 x i32>, <4 x i32>* %35, align 16
  %37 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %33, <4 x i32> %36) #6
  %38 = getelementptr inbounds i32, i32* %0, i64 40
  %39 = bitcast i32* %38 to <4 x i32>*
  %40 = load <4 x i32>, <4 x i32>* %39, align 16
  %41 = getelementptr inbounds i32, i32* %0, i64 44
  %42 = bitcast i32* %41 to <4 x i32>*
  %43 = load <4 x i32>, <4 x i32>* %42, align 16
  %44 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %40, <4 x i32> %43) #6
  %45 = getelementptr inbounds i32, i32* %0, i64 48
  %46 = bitcast i32* %45 to <4 x i32>*
  %47 = load <4 x i32>, <4 x i32>* %46, align 16
  %48 = getelementptr inbounds i32, i32* %0, i64 52
  %49 = bitcast i32* %48 to <4 x i32>*
  %50 = load <4 x i32>, <4 x i32>* %49, align 16
  %51 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %47, <4 x i32> %50) #6
  %52 = getelementptr inbounds i32, i32* %0, i64 56
  %53 = bitcast i32* %52 to <4 x i32>*
  %54 = load <4 x i32>, <4 x i32>* %53, align 16
  %55 = getelementptr inbounds i32, i32* %0, i64 60
  %56 = bitcast i32* %55 to <4 x i32>*
  %57 = load <4 x i32>, <4 x i32>* %56, align 16
  %58 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %54, <4 x i32> %57) #6
  br label %59

59:                                               ; preds = %59, %3
  %60 = phi i32 [ 0, %3 ], [ %213, %59 ]
  %61 = phi <8 x i16> [ %9, %3 ], [ %205, %59 ]
  %62 = phi <8 x i16> [ %16, %3 ], [ %206, %59 ]
  %63 = phi <8 x i16> [ %23, %3 ], [ %207, %59 ]
  %64 = phi <8 x i16> [ %30, %3 ], [ %208, %59 ]
  %65 = phi <8 x i16> [ %37, %3 ], [ %209, %59 ]
  %66 = phi <8 x i16> [ %44, %3 ], [ %210, %59 ]
  %67 = phi <8 x i16> [ %51, %3 ], [ %211, %59 ]
  %68 = phi <8 x i16> [ %58, %3 ], [ %212, %59 ]
  %69 = shufflevector <8 x i16> %61, <8 x i16> %62, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %70 = shufflevector <8 x i16> %63, <8 x i16> %64, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %71 = shufflevector <8 x i16> %65, <8 x i16> %66, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %72 = shufflevector <8 x i16> %67, <8 x i16> %68, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %73 = shufflevector <8 x i16> %61, <8 x i16> %62, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %74 = shufflevector <8 x i16> %63, <8 x i16> %64, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %75 = shufflevector <8 x i16> %65, <8 x i16> %66, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %76 = shufflevector <8 x i16> %67, <8 x i16> %68, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %77 = bitcast <8 x i16> %69 to <4 x i32>
  %78 = bitcast <8 x i16> %70 to <4 x i32>
  %79 = shufflevector <4 x i32> %77, <4 x i32> %78, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %80 = bitcast <4 x i32> %79 to <2 x i64>
  %81 = bitcast <8 x i16> %71 to <4 x i32>
  %82 = bitcast <8 x i16> %72 to <4 x i32>
  %83 = shufflevector <4 x i32> %81, <4 x i32> %82, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %84 = bitcast <4 x i32> %83 to <2 x i64>
  %85 = bitcast <8 x i16> %73 to <4 x i32>
  %86 = bitcast <8 x i16> %74 to <4 x i32>
  %87 = shufflevector <4 x i32> %85, <4 x i32> %86, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %88 = bitcast <4 x i32> %87 to <2 x i64>
  %89 = bitcast <8 x i16> %75 to <4 x i32>
  %90 = bitcast <8 x i16> %76 to <4 x i32>
  %91 = shufflevector <4 x i32> %89, <4 x i32> %90, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %92 = bitcast <4 x i32> %91 to <2 x i64>
  %93 = shufflevector <4 x i32> %77, <4 x i32> %78, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %94 = bitcast <4 x i32> %93 to <2 x i64>
  %95 = shufflevector <4 x i32> %81, <4 x i32> %82, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %96 = bitcast <4 x i32> %95 to <2 x i64>
  %97 = shufflevector <4 x i32> %85, <4 x i32> %86, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %98 = bitcast <4 x i32> %97 to <2 x i64>
  %99 = shufflevector <4 x i32> %89, <4 x i32> %90, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %100 = bitcast <4 x i32> %99 to <2 x i64>
  %101 = shufflevector <2 x i64> %80, <2 x i64> %84, <2 x i32> <i32 0, i32 2>
  %102 = shufflevector <2 x i64> %80, <2 x i64> %84, <2 x i32> <i32 1, i32 3>
  %103 = shufflevector <2 x i64> %94, <2 x i64> %96, <2 x i32> <i32 0, i32 2>
  %104 = shufflevector <2 x i64> %94, <2 x i64> %96, <2 x i32> <i32 1, i32 3>
  %105 = shufflevector <2 x i64> %88, <2 x i64> %92, <2 x i32> <i32 0, i32 2>
  %106 = shufflevector <2 x i64> %88, <2 x i64> %92, <2 x i32> <i32 1, i32 3>
  %107 = shufflevector <2 x i64> %98, <2 x i64> %100, <2 x i32> <i32 0, i32 2>
  %108 = shufflevector <2 x i64> %98, <2 x i64> %100, <2 x i32> <i32 1, i32 3>
  %109 = bitcast <2 x i64> %102 to <8 x i16>
  %110 = bitcast <2 x i64> %108 to <8 x i16>
  %111 = shufflevector <8 x i16> %109, <8 x i16> %110, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %112 = shufflevector <8 x i16> %109, <8 x i16> %110, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %113 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %111, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #6
  %114 = add <4 x i32> %113, <i32 8192, i32 8192, i32 8192, i32 8192>
  %115 = ashr <4 x i32> %114, <i32 14, i32 14, i32 14, i32 14>
  %116 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %112, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #6
  %117 = add <4 x i32> %116, <i32 8192, i32 8192, i32 8192, i32 8192>
  %118 = ashr <4 x i32> %117, <i32 14, i32 14, i32 14, i32 14>
  %119 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %115, <4 x i32> %118) #6
  %120 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %111, <8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>) #6
  %121 = add <4 x i32> %120, <i32 8192, i32 8192, i32 8192, i32 8192>
  %122 = ashr <4 x i32> %121, <i32 14, i32 14, i32 14, i32 14>
  %123 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %112, <8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>) #6
  %124 = add <4 x i32> %123, <i32 8192, i32 8192, i32 8192, i32 8192>
  %125 = ashr <4 x i32> %124, <i32 14, i32 14, i32 14, i32 14>
  %126 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %122, <4 x i32> %125) #6
  %127 = bitcast <2 x i64> %106 to <8 x i16>
  %128 = bitcast <2 x i64> %104 to <8 x i16>
  %129 = shufflevector <8 x i16> %127, <8 x i16> %128, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %130 = shufflevector <8 x i16> %127, <8 x i16> %128, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %131 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %129, <8 x i16> <i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102>) #6
  %132 = add <4 x i32> %131, <i32 8192, i32 8192, i32 8192, i32 8192>
  %133 = ashr <4 x i32> %132, <i32 14, i32 14, i32 14, i32 14>
  %134 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %130, <8 x i16> <i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102>) #6
  %135 = add <4 x i32> %134, <i32 8192, i32 8192, i32 8192, i32 8192>
  %136 = ashr <4 x i32> %135, <i32 14, i32 14, i32 14, i32 14>
  %137 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %133, <4 x i32> %136) #6
  %138 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %129, <8 x i16> <i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623>) #6
  %139 = add <4 x i32> %138, <i32 8192, i32 8192, i32 8192, i32 8192>
  %140 = ashr <4 x i32> %139, <i32 14, i32 14, i32 14, i32 14>
  %141 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %130, <8 x i16> <i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623>) #6
  %142 = add <4 x i32> %141, <i32 8192, i32 8192, i32 8192, i32 8192>
  %143 = ashr <4 x i32> %142, <i32 14, i32 14, i32 14, i32 14>
  %144 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %140, <4 x i32> %143) #6
  %145 = bitcast <2 x i64> %101 to <8 x i16>
  %146 = bitcast <2 x i64> %105 to <8 x i16>
  %147 = shufflevector <8 x i16> %145, <8 x i16> %146, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %148 = shufflevector <8 x i16> %145, <8 x i16> %146, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %149 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %147, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %150 = add <4 x i32> %149, <i32 8192, i32 8192, i32 8192, i32 8192>
  %151 = ashr <4 x i32> %150, <i32 14, i32 14, i32 14, i32 14>
  %152 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %148, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %153 = add <4 x i32> %152, <i32 8192, i32 8192, i32 8192, i32 8192>
  %154 = ashr <4 x i32> %153, <i32 14, i32 14, i32 14, i32 14>
  %155 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %151, <4 x i32> %154) #6
  %156 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %147, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %157 = add <4 x i32> %156, <i32 8192, i32 8192, i32 8192, i32 8192>
  %158 = ashr <4 x i32> %157, <i32 14, i32 14, i32 14, i32 14>
  %159 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %148, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %160 = add <4 x i32> %159, <i32 8192, i32 8192, i32 8192, i32 8192>
  %161 = ashr <4 x i32> %160, <i32 14, i32 14, i32 14, i32 14>
  %162 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %158, <4 x i32> %161) #6
  %163 = bitcast <2 x i64> %103 to <8 x i16>
  %164 = bitcast <2 x i64> %107 to <8 x i16>
  %165 = shufflevector <8 x i16> %163, <8 x i16> %164, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %166 = shufflevector <8 x i16> %163, <8 x i16> %164, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %167 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %165, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %168 = add <4 x i32> %167, <i32 8192, i32 8192, i32 8192, i32 8192>
  %169 = ashr <4 x i32> %168, <i32 14, i32 14, i32 14, i32 14>
  %170 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %166, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %171 = add <4 x i32> %170, <i32 8192, i32 8192, i32 8192, i32 8192>
  %172 = ashr <4 x i32> %171, <i32 14, i32 14, i32 14, i32 14>
  %173 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %169, <4 x i32> %172) #6
  %174 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %165, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %175 = add <4 x i32> %174, <i32 8192, i32 8192, i32 8192, i32 8192>
  %176 = ashr <4 x i32> %175, <i32 14, i32 14, i32 14, i32 14>
  %177 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %166, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %178 = add <4 x i32> %177, <i32 8192, i32 8192, i32 8192, i32 8192>
  %179 = ashr <4 x i32> %178, <i32 14, i32 14, i32 14, i32 14>
  %180 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %176, <4 x i32> %179) #6
  %181 = add <8 x i16> %137, %119
  %182 = sub <8 x i16> %119, %137
  %183 = sub <8 x i16> %126, %144
  %184 = add <8 x i16> %144, %126
  %185 = add <8 x i16> %180, %162
  %186 = add <8 x i16> %173, %155
  %187 = sub <8 x i16> %155, %173
  %188 = sub <8 x i16> %162, %180
  %189 = shufflevector <8 x i16> %183, <8 x i16> %182, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %190 = shufflevector <8 x i16> %183, <8 x i16> %182, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %191 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %189, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %192 = add <4 x i32> %191, <i32 8192, i32 8192, i32 8192, i32 8192>
  %193 = ashr <4 x i32> %192, <i32 14, i32 14, i32 14, i32 14>
  %194 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %190, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %195 = add <4 x i32> %194, <i32 8192, i32 8192, i32 8192, i32 8192>
  %196 = ashr <4 x i32> %195, <i32 14, i32 14, i32 14, i32 14>
  %197 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %193, <4 x i32> %196) #6
  %198 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %189, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %199 = add <4 x i32> %198, <i32 8192, i32 8192, i32 8192, i32 8192>
  %200 = ashr <4 x i32> %199, <i32 14, i32 14, i32 14, i32 14>
  %201 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %190, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %202 = add <4 x i32> %201, <i32 8192, i32 8192, i32 8192, i32 8192>
  %203 = ashr <4 x i32> %202, <i32 14, i32 14, i32 14, i32 14>
  %204 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %200, <4 x i32> %203) #6
  %205 = add <8 x i16> %185, %184
  %206 = add <8 x i16> %204, %186
  %207 = add <8 x i16> %197, %187
  %208 = add <8 x i16> %188, %181
  %209 = sub <8 x i16> %188, %181
  %210 = sub <8 x i16> %187, %197
  %211 = sub <8 x i16> %186, %204
  %212 = sub <8 x i16> %185, %184
  %213 = add nuw nsw i32 %60, 1
  %214 = icmp eq i32 %213, 2
  br i1 %214, label %215, label %59

215:                                              ; preds = %59
  %216 = add <8 x i16> %205, <i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16>
  %217 = add <8 x i16> %206, <i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16>
  %218 = add <8 x i16> %207, <i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16>
  %219 = add <8 x i16> %208, <i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16>
  %220 = add <8 x i16> %209, <i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16>
  %221 = add <8 x i16> %210, <i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16>
  %222 = add <8 x i16> %211, <i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16>
  %223 = add <8 x i16> %212, <i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16>
  %224 = ashr <8 x i16> %216, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %225 = ashr <8 x i16> %217, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %226 = ashr <8 x i16> %218, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %227 = ashr <8 x i16> %219, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %228 = ashr <8 x i16> %220, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %229 = ashr <8 x i16> %221, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %230 = ashr <8 x i16> %222, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %231 = ashr <8 x i16> %223, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %232 = bitcast i8* %1 to i64*
  %233 = load i64, i64* %232, align 1
  %234 = insertelement <2 x i64> undef, i64 %233, i32 0
  %235 = bitcast <2 x i64> %234 to <16 x i8>
  %236 = shufflevector <16 x i8> %235, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %237 = bitcast <16 x i8> %236 to <8 x i16>
  %238 = add <8 x i16> %224, %237
  %239 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %238, <8 x i16> undef) #6
  %240 = bitcast <16 x i8> %239 to <2 x i64>
  %241 = extractelement <2 x i64> %240, i32 0
  store i64 %241, i64* %232, align 1
  %242 = sext i32 %2 to i64
  %243 = getelementptr inbounds i8, i8* %1, i64 %242
  %244 = bitcast i8* %243 to i64*
  %245 = load i64, i64* %244, align 1
  %246 = insertelement <2 x i64> undef, i64 %245, i32 0
  %247 = bitcast <2 x i64> %246 to <16 x i8>
  %248 = shufflevector <16 x i8> %247, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %249 = bitcast <16 x i8> %248 to <8 x i16>
  %250 = add <8 x i16> %225, %249
  %251 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %250, <8 x i16> undef) #6
  %252 = bitcast <16 x i8> %251 to <2 x i64>
  %253 = extractelement <2 x i64> %252, i32 0
  store i64 %253, i64* %244, align 1
  %254 = shl nsw i32 %2, 1
  %255 = sext i32 %254 to i64
  %256 = getelementptr inbounds i8, i8* %1, i64 %255
  %257 = bitcast i8* %256 to i64*
  %258 = load i64, i64* %257, align 1
  %259 = insertelement <2 x i64> undef, i64 %258, i32 0
  %260 = bitcast <2 x i64> %259 to <16 x i8>
  %261 = shufflevector <16 x i8> %260, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %262 = bitcast <16 x i8> %261 to <8 x i16>
  %263 = add <8 x i16> %226, %262
  %264 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %263, <8 x i16> undef) #6
  %265 = bitcast <16 x i8> %264 to <2 x i64>
  %266 = extractelement <2 x i64> %265, i32 0
  store i64 %266, i64* %257, align 1
  %267 = mul nsw i32 %2, 3
  %268 = sext i32 %267 to i64
  %269 = getelementptr inbounds i8, i8* %1, i64 %268
  %270 = bitcast i8* %269 to i64*
  %271 = load i64, i64* %270, align 1
  %272 = insertelement <2 x i64> undef, i64 %271, i32 0
  %273 = bitcast <2 x i64> %272 to <16 x i8>
  %274 = shufflevector <16 x i8> %273, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %275 = bitcast <16 x i8> %274 to <8 x i16>
  %276 = add <8 x i16> %227, %275
  %277 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %276, <8 x i16> undef) #6
  %278 = bitcast <16 x i8> %277 to <2 x i64>
  %279 = extractelement <2 x i64> %278, i32 0
  store i64 %279, i64* %270, align 1
  %280 = shl nsw i32 %2, 2
  %281 = sext i32 %280 to i64
  %282 = getelementptr inbounds i8, i8* %1, i64 %281
  %283 = bitcast i8* %282 to i64*
  %284 = load i64, i64* %283, align 1
  %285 = insertelement <2 x i64> undef, i64 %284, i32 0
  %286 = bitcast <2 x i64> %285 to <16 x i8>
  %287 = shufflevector <16 x i8> %286, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %288 = bitcast <16 x i8> %287 to <8 x i16>
  %289 = add <8 x i16> %228, %288
  %290 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %289, <8 x i16> undef) #6
  %291 = bitcast <16 x i8> %290 to <2 x i64>
  %292 = extractelement <2 x i64> %291, i32 0
  store i64 %292, i64* %283, align 1
  %293 = mul nsw i32 %2, 5
  %294 = sext i32 %293 to i64
  %295 = getelementptr inbounds i8, i8* %1, i64 %294
  %296 = bitcast i8* %295 to i64*
  %297 = load i64, i64* %296, align 1
  %298 = insertelement <2 x i64> undef, i64 %297, i32 0
  %299 = bitcast <2 x i64> %298 to <16 x i8>
  %300 = shufflevector <16 x i8> %299, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %301 = bitcast <16 x i8> %300 to <8 x i16>
  %302 = add <8 x i16> %229, %301
  %303 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %302, <8 x i16> undef) #6
  %304 = bitcast <16 x i8> %303 to <2 x i64>
  %305 = extractelement <2 x i64> %304, i32 0
  store i64 %305, i64* %296, align 1
  %306 = mul nsw i32 %2, 6
  %307 = sext i32 %306 to i64
  %308 = getelementptr inbounds i8, i8* %1, i64 %307
  %309 = bitcast i8* %308 to i64*
  %310 = load i64, i64* %309, align 1
  %311 = insertelement <2 x i64> undef, i64 %310, i32 0
  %312 = bitcast <2 x i64> %311 to <16 x i8>
  %313 = shufflevector <16 x i8> %312, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %314 = bitcast <16 x i8> %313 to <8 x i16>
  %315 = add <8 x i16> %230, %314
  %316 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %315, <8 x i16> undef) #6
  %317 = bitcast <16 x i8> %316 to <2 x i64>
  %318 = extractelement <2 x i64> %317, i32 0
  store i64 %318, i64* %309, align 1
  %319 = mul nsw i32 %2, 7
  %320 = sext i32 %319 to i64
  %321 = getelementptr inbounds i8, i8* %1, i64 %320
  %322 = bitcast i8* %321 to i64*
  %323 = load i64, i64* %322, align 1
  %324 = insertelement <2 x i64> undef, i64 %323, i32 0
  %325 = bitcast <2 x i64> %324 to <16 x i8>
  %326 = shufflevector <16 x i8> %325, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %327 = bitcast <16 x i8> %326 to <8 x i16>
  %328 = add <8 x i16> %231, %327
  %329 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %328, <8 x i16> undef) #6
  %330 = bitcast <16 x i8> %329 to <2 x i64>
  %331 = extractelement <2 x i64> %330, i32 0
  store i64 %331, i64* %322, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @vpx_idct8_sse2(<2 x i64>*) local_unnamed_addr #2 {
  %2 = bitcast <2 x i64>* %0 to <8 x i16>*
  %3 = load <8 x i16>, <8 x i16>* %2, align 16
  %4 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %5 = bitcast <2 x i64>* %4 to <8 x i16>*
  %6 = load <8 x i16>, <8 x i16>* %5, align 16
  %7 = shufflevector <8 x i16> %3, <8 x i16> %6, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %8 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %9 = bitcast <2 x i64>* %8 to <8 x i16>*
  %10 = load <8 x i16>, <8 x i16>* %9, align 16
  %11 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %12 = bitcast <2 x i64>* %11 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = shufflevector <8 x i16> %10, <8 x i16> %13, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %15 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %16 = bitcast <2 x i64>* %15 to <8 x i16>*
  %17 = load <8 x i16>, <8 x i16>* %16, align 16
  %18 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %19 = bitcast <2 x i64>* %18 to <8 x i16>*
  %20 = load <8 x i16>, <8 x i16>* %19, align 16
  %21 = shufflevector <8 x i16> %17, <8 x i16> %20, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %22 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %23 = bitcast <2 x i64>* %22 to <8 x i16>*
  %24 = load <8 x i16>, <8 x i16>* %23, align 16
  %25 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %26 = bitcast <2 x i64>* %25 to <8 x i16>*
  %27 = load <8 x i16>, <8 x i16>* %26, align 16
  %28 = shufflevector <8 x i16> %24, <8 x i16> %27, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %29 = shufflevector <8 x i16> %3, <8 x i16> %6, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %30 = shufflevector <8 x i16> %10, <8 x i16> %13, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %31 = shufflevector <8 x i16> %17, <8 x i16> %20, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %32 = shufflevector <8 x i16> %24, <8 x i16> %27, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %33 = bitcast <8 x i16> %7 to <4 x i32>
  %34 = bitcast <8 x i16> %14 to <4 x i32>
  %35 = shufflevector <4 x i32> %33, <4 x i32> %34, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %36 = bitcast <4 x i32> %35 to <2 x i64>
  %37 = bitcast <8 x i16> %21 to <4 x i32>
  %38 = bitcast <8 x i16> %28 to <4 x i32>
  %39 = shufflevector <4 x i32> %37, <4 x i32> %38, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %40 = bitcast <4 x i32> %39 to <2 x i64>
  %41 = bitcast <8 x i16> %29 to <4 x i32>
  %42 = bitcast <8 x i16> %30 to <4 x i32>
  %43 = shufflevector <4 x i32> %41, <4 x i32> %42, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %44 = bitcast <4 x i32> %43 to <2 x i64>
  %45 = bitcast <8 x i16> %31 to <4 x i32>
  %46 = bitcast <8 x i16> %32 to <4 x i32>
  %47 = shufflevector <4 x i32> %45, <4 x i32> %46, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %48 = bitcast <4 x i32> %47 to <2 x i64>
  %49 = shufflevector <4 x i32> %33, <4 x i32> %34, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %50 = bitcast <4 x i32> %49 to <2 x i64>
  %51 = shufflevector <4 x i32> %37, <4 x i32> %38, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %52 = bitcast <4 x i32> %51 to <2 x i64>
  %53 = shufflevector <4 x i32> %41, <4 x i32> %42, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %54 = bitcast <4 x i32> %53 to <2 x i64>
  %55 = shufflevector <4 x i32> %45, <4 x i32> %46, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %56 = bitcast <4 x i32> %55 to <2 x i64>
  %57 = shufflevector <2 x i64> %36, <2 x i64> %40, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %57, <2 x i64>* %0, align 16
  %58 = shufflevector <2 x i64> %36, <2 x i64> %40, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %58, <2 x i64>* %4, align 16
  %59 = shufflevector <2 x i64> %50, <2 x i64> %52, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %59, <2 x i64>* %8, align 16
  %60 = shufflevector <2 x i64> %50, <2 x i64> %52, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %60, <2 x i64>* %11, align 16
  %61 = shufflevector <2 x i64> %44, <2 x i64> %48, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %61, <2 x i64>* %15, align 16
  %62 = shufflevector <2 x i64> %44, <2 x i64> %48, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %62, <2 x i64>* %18, align 16
  %63 = shufflevector <2 x i64> %54, <2 x i64> %56, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %63, <2 x i64>* %22, align 16
  %64 = shufflevector <2 x i64> %54, <2 x i64> %56, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %64, <2 x i64>* %25, align 16
  %65 = bitcast <2 x i64> %58 to <8 x i16>
  %66 = bitcast <2 x i64> %64 to <8 x i16>
  %67 = shufflevector <8 x i16> %65, <8 x i16> %66, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %68 = shufflevector <8 x i16> %65, <8 x i16> %66, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %69 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %67, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #6
  %70 = add <4 x i32> %69, <i32 8192, i32 8192, i32 8192, i32 8192>
  %71 = ashr <4 x i32> %70, <i32 14, i32 14, i32 14, i32 14>
  %72 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %68, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #6
  %73 = add <4 x i32> %72, <i32 8192, i32 8192, i32 8192, i32 8192>
  %74 = ashr <4 x i32> %73, <i32 14, i32 14, i32 14, i32 14>
  %75 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %71, <4 x i32> %74) #6
  %76 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %67, <8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>) #6
  %77 = add <4 x i32> %76, <i32 8192, i32 8192, i32 8192, i32 8192>
  %78 = ashr <4 x i32> %77, <i32 14, i32 14, i32 14, i32 14>
  %79 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %68, <8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>) #6
  %80 = add <4 x i32> %79, <i32 8192, i32 8192, i32 8192, i32 8192>
  %81 = ashr <4 x i32> %80, <i32 14, i32 14, i32 14, i32 14>
  %82 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %78, <4 x i32> %81) #6
  %83 = bitcast <2 x i64> %62 to <8 x i16>
  %84 = bitcast <2 x i64> %60 to <8 x i16>
  %85 = shufflevector <8 x i16> %83, <8 x i16> %84, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %86 = shufflevector <8 x i16> %83, <8 x i16> %84, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %87 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %85, <8 x i16> <i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102>) #6
  %88 = add <4 x i32> %87, <i32 8192, i32 8192, i32 8192, i32 8192>
  %89 = ashr <4 x i32> %88, <i32 14, i32 14, i32 14, i32 14>
  %90 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %86, <8 x i16> <i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102>) #6
  %91 = add <4 x i32> %90, <i32 8192, i32 8192, i32 8192, i32 8192>
  %92 = ashr <4 x i32> %91, <i32 14, i32 14, i32 14, i32 14>
  %93 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %89, <4 x i32> %92) #6
  %94 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %85, <8 x i16> <i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623>) #6
  %95 = add <4 x i32> %94, <i32 8192, i32 8192, i32 8192, i32 8192>
  %96 = ashr <4 x i32> %95, <i32 14, i32 14, i32 14, i32 14>
  %97 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %86, <8 x i16> <i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623>) #6
  %98 = add <4 x i32> %97, <i32 8192, i32 8192, i32 8192, i32 8192>
  %99 = ashr <4 x i32> %98, <i32 14, i32 14, i32 14, i32 14>
  %100 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %96, <4 x i32> %99) #6
  %101 = bitcast <2 x i64> %57 to <8 x i16>
  %102 = bitcast <2 x i64> %61 to <8 x i16>
  %103 = shufflevector <8 x i16> %101, <8 x i16> %102, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %104 = shufflevector <8 x i16> %101, <8 x i16> %102, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %105 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %103, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %106 = add <4 x i32> %105, <i32 8192, i32 8192, i32 8192, i32 8192>
  %107 = ashr <4 x i32> %106, <i32 14, i32 14, i32 14, i32 14>
  %108 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %104, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %109 = add <4 x i32> %108, <i32 8192, i32 8192, i32 8192, i32 8192>
  %110 = ashr <4 x i32> %109, <i32 14, i32 14, i32 14, i32 14>
  %111 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %107, <4 x i32> %110) #6
  %112 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %103, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %113 = add <4 x i32> %112, <i32 8192, i32 8192, i32 8192, i32 8192>
  %114 = ashr <4 x i32> %113, <i32 14, i32 14, i32 14, i32 14>
  %115 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %104, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %116 = add <4 x i32> %115, <i32 8192, i32 8192, i32 8192, i32 8192>
  %117 = ashr <4 x i32> %116, <i32 14, i32 14, i32 14, i32 14>
  %118 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %114, <4 x i32> %117) #6
  %119 = bitcast <2 x i64> %59 to <8 x i16>
  %120 = bitcast <2 x i64> %63 to <8 x i16>
  %121 = shufflevector <8 x i16> %119, <8 x i16> %120, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %122 = shufflevector <8 x i16> %119, <8 x i16> %120, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %123 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %121, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %124 = add <4 x i32> %123, <i32 8192, i32 8192, i32 8192, i32 8192>
  %125 = ashr <4 x i32> %124, <i32 14, i32 14, i32 14, i32 14>
  %126 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %122, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %127 = add <4 x i32> %126, <i32 8192, i32 8192, i32 8192, i32 8192>
  %128 = ashr <4 x i32> %127, <i32 14, i32 14, i32 14, i32 14>
  %129 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %125, <4 x i32> %128) #6
  %130 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %121, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %131 = add <4 x i32> %130, <i32 8192, i32 8192, i32 8192, i32 8192>
  %132 = ashr <4 x i32> %131, <i32 14, i32 14, i32 14, i32 14>
  %133 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %122, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %134 = add <4 x i32> %133, <i32 8192, i32 8192, i32 8192, i32 8192>
  %135 = ashr <4 x i32> %134, <i32 14, i32 14, i32 14, i32 14>
  %136 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %132, <4 x i32> %135) #6
  %137 = add <8 x i16> %93, %75
  %138 = sub <8 x i16> %75, %93
  %139 = sub <8 x i16> %82, %100
  %140 = add <8 x i16> %100, %82
  %141 = add <8 x i16> %136, %118
  %142 = add <8 x i16> %129, %111
  %143 = sub <8 x i16> %111, %129
  %144 = sub <8 x i16> %118, %136
  %145 = shufflevector <8 x i16> %139, <8 x i16> %138, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %146 = shufflevector <8 x i16> %139, <8 x i16> %138, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %147 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %145, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %148 = add <4 x i32> %147, <i32 8192, i32 8192, i32 8192, i32 8192>
  %149 = ashr <4 x i32> %148, <i32 14, i32 14, i32 14, i32 14>
  %150 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %146, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %151 = add <4 x i32> %150, <i32 8192, i32 8192, i32 8192, i32 8192>
  %152 = ashr <4 x i32> %151, <i32 14, i32 14, i32 14, i32 14>
  %153 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %149, <4 x i32> %152) #6
  %154 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %145, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %155 = add <4 x i32> %154, <i32 8192, i32 8192, i32 8192, i32 8192>
  %156 = ashr <4 x i32> %155, <i32 14, i32 14, i32 14, i32 14>
  %157 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %146, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %158 = add <4 x i32> %157, <i32 8192, i32 8192, i32 8192, i32 8192>
  %159 = ashr <4 x i32> %158, <i32 14, i32 14, i32 14, i32 14>
  %160 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %156, <4 x i32> %159) #6
  %161 = add <8 x i16> %141, %140
  store <8 x i16> %161, <8 x i16>* %2, align 16
  %162 = add <8 x i16> %160, %142
  store <8 x i16> %162, <8 x i16>* %5, align 16
  %163 = add <8 x i16> %153, %143
  store <8 x i16> %163, <8 x i16>* %9, align 16
  %164 = add <8 x i16> %144, %137
  store <8 x i16> %164, <8 x i16>* %12, align 16
  %165 = sub <8 x i16> %144, %137
  store <8 x i16> %165, <8 x i16>* %16, align 16
  %166 = sub <8 x i16> %143, %153
  store <8 x i16> %166, <8 x i16>* %19, align 16
  %167 = sub <8 x i16> %142, %160
  store <8 x i16> %167, <8 x i16>* %23, align 16
  %168 = sub <8 x i16> %141, %140
  store <8 x i16> %168, <8 x i16>* %26, align 16
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @vpx_idct8x8_12_add_sse2(i32* nocapture readonly, i8* nocapture, i32) local_unnamed_addr #0 {
  %4 = bitcast i32* %0 to <4 x i32>*
  %5 = load <4 x i32>, <4 x i32>* %4, align 16
  %6 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %5, <4 x i32> undef) #6
  %7 = getelementptr inbounds i32, i32* %0, i64 8
  %8 = bitcast i32* %7 to <4 x i32>*
  %9 = load <4 x i32>, <4 x i32>* %8, align 16
  %10 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %9, <4 x i32> undef) #6
  %11 = getelementptr inbounds i32, i32* %0, i64 16
  %12 = bitcast i32* %11 to <4 x i32>*
  %13 = load <4 x i32>, <4 x i32>* %12, align 16
  %14 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %13, <4 x i32> undef) #6
  %15 = getelementptr inbounds i32, i32* %0, i64 24
  %16 = bitcast i32* %15 to <4 x i32>*
  %17 = load <4 x i32>, <4 x i32>* %16, align 16
  %18 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %17, <4 x i32> undef) #6
  %19 = shufflevector <8 x i16> %6, <8 x i16> %10, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %20 = shufflevector <8 x i16> %14, <8 x i16> %18, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %21 = bitcast <8 x i16> %19 to <4 x i32>
  %22 = bitcast <8 x i16> %20 to <4 x i32>
  %23 = shufflevector <4 x i32> %21, <4 x i32> %22, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %24 = shufflevector <4 x i32> %21, <4 x i32> %22, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %25 = bitcast <4 x i32> %23 to <8 x i16>
  %26 = shufflevector <8 x i16> %25, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %27 = bitcast <4 x i32> %24 to <8 x i16>
  %28 = shufflevector <8 x i16> %27, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %29 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>, <8 x i16> %26) #6
  %30 = add <4 x i32> %29, <i32 8192, i32 8192, i32 8192, i32 8192>
  %31 = ashr <4 x i32> %30, <i32 14, i32 14, i32 14, i32 14>
  %32 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>, <8 x i16> %26) #6
  %33 = add <4 x i32> %32, <i32 8192, i32 8192, i32 8192, i32 8192>
  %34 = ashr <4 x i32> %33, <i32 14, i32 14, i32 14, i32 14>
  %35 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %31, <4 x i32> %34) #6
  %36 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623>, <8 x i16> %28) #6
  %37 = add <4 x i32> %36, <i32 8192, i32 8192, i32 8192, i32 8192>
  %38 = ashr <4 x i32> %37, <i32 14, i32 14, i32 14, i32 14>
  %39 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 13623, i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623, i16 9102>, <8 x i16> %28) #6
  %40 = add <4 x i32> %39, <i32 8192, i32 8192, i32 8192, i32 8192>
  %41 = ashr <4 x i32> %40, <i32 14, i32 14, i32 14, i32 14>
  %42 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %38, <4 x i32> %41) #6
  %43 = shufflevector <8 x i16> %25, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %44 = shufflevector <8 x i16> %27, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %45 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>, <8 x i16> %43) #6
  %46 = add <4 x i32> %45, <i32 8192, i32 8192, i32 8192, i32 8192>
  %47 = ashr <4 x i32> %46, <i32 14, i32 14, i32 14, i32 14>
  %48 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %47, <4 x i32> %47) #6
  %49 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>, <8 x i16> %44) #6
  %50 = add <4 x i32> %49, <i32 8192, i32 8192, i32 8192, i32 8192>
  %51 = ashr <4 x i32> %50, <i32 14, i32 14, i32 14, i32 14>
  %52 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>, <8 x i16> %44) #6
  %53 = add <4 x i32> %52, <i32 8192, i32 8192, i32 8192, i32 8192>
  %54 = ashr <4 x i32> %53, <i32 14, i32 14, i32 14, i32 14>
  %55 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %51, <4 x i32> %54) #6
  %56 = add <8 x i16> %42, %35
  %57 = sub <8 x i16> %35, %42
  %58 = bitcast <8 x i16> %57 to <2 x i64>
  %59 = shufflevector <2 x i64> %58, <2 x i64> undef, <2 x i32> <i32 1, i32 undef>
  %60 = bitcast <2 x i64> %59 to <8 x i16>
  %61 = shufflevector <8 x i16> %60, <8 x i16> %57, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %62 = add <8 x i16> %55, %48
  %63 = bitcast <8 x i16> %62 to <2 x i64>
  %64 = sub <8 x i16> %48, %55
  %65 = bitcast <8 x i16> %64 to <2 x i64>
  %66 = shufflevector <2 x i64> %65, <2 x i64> %63, <2 x i32> <i32 1, i32 3>
  %67 = shufflevector <2 x i64> %65, <2 x i64> %63, <2 x i32> <i32 0, i32 2>
  %68 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>, <8 x i16> %61) #6
  %69 = add <4 x i32> %68, <i32 8192, i32 8192, i32 8192, i32 8192>
  %70 = ashr <4 x i32> %69, <i32 14, i32 14, i32 14, i32 14>
  %71 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>, <8 x i16> %61) #6
  %72 = add <4 x i32> %71, <i32 8192, i32 8192, i32 8192, i32 8192>
  %73 = ashr <4 x i32> %72, <i32 14, i32 14, i32 14, i32 14>
  %74 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %70, <4 x i32> %73) #6
  %75 = bitcast <2 x i64> %67 to <8 x i16>
  %76 = add <8 x i16> %56, %75
  %77 = bitcast <2 x i64> %66 to <8 x i16>
  %78 = add <8 x i16> %74, %77
  %79 = sub <8 x i16> %75, %56
  %80 = sub <8 x i16> %77, %74
  %81 = shufflevector <8 x i16> %76, <8 x i16> %78, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %82 = shufflevector <8 x i16> %78, <8 x i16> %76, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %83 = shufflevector <8 x i16> %79, <8 x i16> %80, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %84 = shufflevector <8 x i16> %80, <8 x i16> %79, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %85 = bitcast <8 x i16> %81 to <4 x i32>
  %86 = bitcast <8 x i16> %82 to <4 x i32>
  %87 = shufflevector <4 x i32> %85, <4 x i32> %86, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %88 = bitcast <4 x i32> %87 to <2 x i64>
  %89 = bitcast <8 x i16> %83 to <4 x i32>
  %90 = bitcast <8 x i16> %84 to <4 x i32>
  %91 = shufflevector <4 x i32> %89, <4 x i32> %90, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %92 = bitcast <4 x i32> %91 to <2 x i64>
  %93 = shufflevector <4 x i32> %85, <4 x i32> %86, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %94 = bitcast <4 x i32> %93 to <2 x i64>
  %95 = shufflevector <4 x i32> %89, <4 x i32> %90, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %96 = bitcast <4 x i32> %95 to <2 x i64>
  %97 = shufflevector <2 x i64> %88, <2 x i64> %92, <2 x i32> <i32 0, i32 2>
  %98 = shufflevector <2 x i64> %88, <2 x i64> %92, <2 x i32> <i32 1, i32 3>
  %99 = shufflevector <2 x i64> %94, <2 x i64> %96, <2 x i32> <i32 0, i32 2>
  %100 = shufflevector <2 x i64> %94, <2 x i64> %96, <2 x i32> <i32 1, i32 3>
  %101 = bitcast <2 x i64> %98 to <8 x i16>
  %102 = shufflevector <8 x i16> %101, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %103 = shufflevector <8 x i16> %101, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %104 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %102, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #6
  %105 = add <4 x i32> %104, <i32 8192, i32 8192, i32 8192, i32 8192>
  %106 = ashr <4 x i32> %105, <i32 14, i32 14, i32 14, i32 14>
  %107 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %103, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #6
  %108 = add <4 x i32> %107, <i32 8192, i32 8192, i32 8192, i32 8192>
  %109 = ashr <4 x i32> %108, <i32 14, i32 14, i32 14, i32 14>
  %110 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %106, <4 x i32> %109) #6
  %111 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %102, <8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>) #6
  %112 = add <4 x i32> %111, <i32 8192, i32 8192, i32 8192, i32 8192>
  %113 = ashr <4 x i32> %112, <i32 14, i32 14, i32 14, i32 14>
  %114 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %103, <8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>) #6
  %115 = add <4 x i32> %114, <i32 8192, i32 8192, i32 8192, i32 8192>
  %116 = ashr <4 x i32> %115, <i32 14, i32 14, i32 14, i32 14>
  %117 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %113, <4 x i32> %116) #6
  %118 = bitcast <2 x i64> %100 to <8 x i16>
  %119 = shufflevector <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i16> %118, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %120 = shufflevector <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i16> %118, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %121 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %119, <8 x i16> <i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102>) #6
  %122 = add <4 x i32> %121, <i32 8192, i32 8192, i32 8192, i32 8192>
  %123 = ashr <4 x i32> %122, <i32 14, i32 14, i32 14, i32 14>
  %124 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %120, <8 x i16> <i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102>) #6
  %125 = add <4 x i32> %124, <i32 8192, i32 8192, i32 8192, i32 8192>
  %126 = ashr <4 x i32> %125, <i32 14, i32 14, i32 14, i32 14>
  %127 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %123, <4 x i32> %126) #6
  %128 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %119, <8 x i16> <i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623>) #6
  %129 = add <4 x i32> %128, <i32 8192, i32 8192, i32 8192, i32 8192>
  %130 = ashr <4 x i32> %129, <i32 14, i32 14, i32 14, i32 14>
  %131 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %120, <8 x i16> <i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623>) #6
  %132 = add <4 x i32> %131, <i32 8192, i32 8192, i32 8192, i32 8192>
  %133 = ashr <4 x i32> %132, <i32 14, i32 14, i32 14, i32 14>
  %134 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %130, <4 x i32> %133) #6
  %135 = bitcast <2 x i64> %97 to <8 x i16>
  %136 = shufflevector <8 x i16> %135, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %137 = shufflevector <8 x i16> %135, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %138 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %136, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %139 = add <4 x i32> %138, <i32 8192, i32 8192, i32 8192, i32 8192>
  %140 = ashr <4 x i32> %139, <i32 14, i32 14, i32 14, i32 14>
  %141 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %137, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %142 = add <4 x i32> %141, <i32 8192, i32 8192, i32 8192, i32 8192>
  %143 = ashr <4 x i32> %142, <i32 14, i32 14, i32 14, i32 14>
  %144 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %140, <4 x i32> %143) #6
  %145 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %136, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %146 = add <4 x i32> %145, <i32 8192, i32 8192, i32 8192, i32 8192>
  %147 = ashr <4 x i32> %146, <i32 14, i32 14, i32 14, i32 14>
  %148 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %137, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %149 = add <4 x i32> %148, <i32 8192, i32 8192, i32 8192, i32 8192>
  %150 = ashr <4 x i32> %149, <i32 14, i32 14, i32 14, i32 14>
  %151 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %147, <4 x i32> %150) #6
  %152 = bitcast <2 x i64> %99 to <8 x i16>
  %153 = shufflevector <8 x i16> %152, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %154 = shufflevector <8 x i16> %152, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %155 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %153, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %156 = add <4 x i32> %155, <i32 8192, i32 8192, i32 8192, i32 8192>
  %157 = ashr <4 x i32> %156, <i32 14, i32 14, i32 14, i32 14>
  %158 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %154, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %159 = add <4 x i32> %158, <i32 8192, i32 8192, i32 8192, i32 8192>
  %160 = ashr <4 x i32> %159, <i32 14, i32 14, i32 14, i32 14>
  %161 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %157, <4 x i32> %160) #6
  %162 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %153, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %163 = add <4 x i32> %162, <i32 8192, i32 8192, i32 8192, i32 8192>
  %164 = ashr <4 x i32> %163, <i32 14, i32 14, i32 14, i32 14>
  %165 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %154, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %166 = add <4 x i32> %165, <i32 8192, i32 8192, i32 8192, i32 8192>
  %167 = ashr <4 x i32> %166, <i32 14, i32 14, i32 14, i32 14>
  %168 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %164, <4 x i32> %167) #6
  %169 = add <8 x i16> %127, %110
  %170 = sub <8 x i16> %110, %127
  %171 = sub <8 x i16> %117, %134
  %172 = add <8 x i16> %134, %117
  %173 = add <8 x i16> %168, %151
  %174 = add <8 x i16> %161, %144
  %175 = sub <8 x i16> %144, %161
  %176 = sub <8 x i16> %151, %168
  %177 = shufflevector <8 x i16> %171, <8 x i16> %170, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %178 = shufflevector <8 x i16> %171, <8 x i16> %170, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %179 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %177, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %180 = add <4 x i32> %179, <i32 8192, i32 8192, i32 8192, i32 8192>
  %181 = ashr <4 x i32> %180, <i32 14, i32 14, i32 14, i32 14>
  %182 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %178, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %183 = add <4 x i32> %182, <i32 8192, i32 8192, i32 8192, i32 8192>
  %184 = ashr <4 x i32> %183, <i32 14, i32 14, i32 14, i32 14>
  %185 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %181, <4 x i32> %184) #6
  %186 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %177, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %187 = add <4 x i32> %186, <i32 8192, i32 8192, i32 8192, i32 8192>
  %188 = ashr <4 x i32> %187, <i32 14, i32 14, i32 14, i32 14>
  %189 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %178, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %190 = add <4 x i32> %189, <i32 8192, i32 8192, i32 8192, i32 8192>
  %191 = ashr <4 x i32> %190, <i32 14, i32 14, i32 14, i32 14>
  %192 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %188, <4 x i32> %191) #6
  %193 = add <8 x i16> %172, <i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16>
  %194 = add <8 x i16> %193, %173
  %195 = add <8 x i16> %174, <i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16>
  %196 = add <8 x i16> %195, %192
  %197 = add <8 x i16> %175, <i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16>
  %198 = add <8 x i16> %197, %185
  %199 = add <8 x i16> %169, <i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16>
  %200 = add <8 x i16> %199, %176
  %201 = sub <8 x i16> <i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16>, %169
  %202 = add <8 x i16> %201, %176
  %203 = sub <8 x i16> %197, %185
  %204 = sub <8 x i16> %195, %192
  %205 = sub <8 x i16> <i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16>, %172
  %206 = add <8 x i16> %205, %173
  %207 = ashr <8 x i16> %194, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %208 = ashr <8 x i16> %196, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %209 = ashr <8 x i16> %198, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %210 = ashr <8 x i16> %200, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %211 = ashr <8 x i16> %202, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %212 = ashr <8 x i16> %203, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %213 = ashr <8 x i16> %204, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %214 = ashr <8 x i16> %206, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %215 = bitcast i8* %1 to i64*
  %216 = load i64, i64* %215, align 1
  %217 = insertelement <2 x i64> undef, i64 %216, i32 0
  %218 = bitcast <2 x i64> %217 to <16 x i8>
  %219 = shufflevector <16 x i8> %218, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %220 = bitcast <16 x i8> %219 to <8 x i16>
  %221 = add <8 x i16> %207, %220
  %222 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %221, <8 x i16> undef) #6
  %223 = bitcast <16 x i8> %222 to <2 x i64>
  %224 = extractelement <2 x i64> %223, i32 0
  store i64 %224, i64* %215, align 1
  %225 = sext i32 %2 to i64
  %226 = getelementptr inbounds i8, i8* %1, i64 %225
  %227 = bitcast i8* %226 to i64*
  %228 = load i64, i64* %227, align 1
  %229 = insertelement <2 x i64> undef, i64 %228, i32 0
  %230 = bitcast <2 x i64> %229 to <16 x i8>
  %231 = shufflevector <16 x i8> %230, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %232 = bitcast <16 x i8> %231 to <8 x i16>
  %233 = add <8 x i16> %208, %232
  %234 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %233, <8 x i16> undef) #6
  %235 = bitcast <16 x i8> %234 to <2 x i64>
  %236 = extractelement <2 x i64> %235, i32 0
  store i64 %236, i64* %227, align 1
  %237 = shl nsw i32 %2, 1
  %238 = sext i32 %237 to i64
  %239 = getelementptr inbounds i8, i8* %1, i64 %238
  %240 = bitcast i8* %239 to i64*
  %241 = load i64, i64* %240, align 1
  %242 = insertelement <2 x i64> undef, i64 %241, i32 0
  %243 = bitcast <2 x i64> %242 to <16 x i8>
  %244 = shufflevector <16 x i8> %243, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %245 = bitcast <16 x i8> %244 to <8 x i16>
  %246 = add <8 x i16> %209, %245
  %247 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %246, <8 x i16> undef) #6
  %248 = bitcast <16 x i8> %247 to <2 x i64>
  %249 = extractelement <2 x i64> %248, i32 0
  store i64 %249, i64* %240, align 1
  %250 = mul nsw i32 %2, 3
  %251 = sext i32 %250 to i64
  %252 = getelementptr inbounds i8, i8* %1, i64 %251
  %253 = bitcast i8* %252 to i64*
  %254 = load i64, i64* %253, align 1
  %255 = insertelement <2 x i64> undef, i64 %254, i32 0
  %256 = bitcast <2 x i64> %255 to <16 x i8>
  %257 = shufflevector <16 x i8> %256, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %258 = bitcast <16 x i8> %257 to <8 x i16>
  %259 = add <8 x i16> %210, %258
  %260 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %259, <8 x i16> undef) #6
  %261 = bitcast <16 x i8> %260 to <2 x i64>
  %262 = extractelement <2 x i64> %261, i32 0
  store i64 %262, i64* %253, align 1
  %263 = shl nsw i32 %2, 2
  %264 = sext i32 %263 to i64
  %265 = getelementptr inbounds i8, i8* %1, i64 %264
  %266 = bitcast i8* %265 to i64*
  %267 = load i64, i64* %266, align 1
  %268 = insertelement <2 x i64> undef, i64 %267, i32 0
  %269 = bitcast <2 x i64> %268 to <16 x i8>
  %270 = shufflevector <16 x i8> %269, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %271 = bitcast <16 x i8> %270 to <8 x i16>
  %272 = add <8 x i16> %211, %271
  %273 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %272, <8 x i16> undef) #6
  %274 = bitcast <16 x i8> %273 to <2 x i64>
  %275 = extractelement <2 x i64> %274, i32 0
  store i64 %275, i64* %266, align 1
  %276 = mul nsw i32 %2, 5
  %277 = sext i32 %276 to i64
  %278 = getelementptr inbounds i8, i8* %1, i64 %277
  %279 = bitcast i8* %278 to i64*
  %280 = load i64, i64* %279, align 1
  %281 = insertelement <2 x i64> undef, i64 %280, i32 0
  %282 = bitcast <2 x i64> %281 to <16 x i8>
  %283 = shufflevector <16 x i8> %282, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %284 = bitcast <16 x i8> %283 to <8 x i16>
  %285 = add <8 x i16> %212, %284
  %286 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %285, <8 x i16> undef) #6
  %287 = bitcast <16 x i8> %286 to <2 x i64>
  %288 = extractelement <2 x i64> %287, i32 0
  store i64 %288, i64* %279, align 1
  %289 = mul nsw i32 %2, 6
  %290 = sext i32 %289 to i64
  %291 = getelementptr inbounds i8, i8* %1, i64 %290
  %292 = bitcast i8* %291 to i64*
  %293 = load i64, i64* %292, align 1
  %294 = insertelement <2 x i64> undef, i64 %293, i32 0
  %295 = bitcast <2 x i64> %294 to <16 x i8>
  %296 = shufflevector <16 x i8> %295, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %297 = bitcast <16 x i8> %296 to <8 x i16>
  %298 = add <8 x i16> %213, %297
  %299 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %298, <8 x i16> undef) #6
  %300 = bitcast <16 x i8> %299 to <2 x i64>
  %301 = extractelement <2 x i64> %300, i32 0
  store i64 %301, i64* %292, align 1
  %302 = mul nsw i32 %2, 7
  %303 = sext i32 %302 to i64
  %304 = getelementptr inbounds i8, i8* %1, i64 %303
  %305 = bitcast i8* %304 to i64*
  %306 = load i64, i64* %305, align 1
  %307 = insertelement <2 x i64> undef, i64 %306, i32 0
  %308 = bitcast <2 x i64> %307 to <16 x i8>
  %309 = shufflevector <16 x i8> %308, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %310 = bitcast <16 x i8> %309 to <8 x i16>
  %311 = add <8 x i16> %214, %310
  %312 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %311, <8 x i16> undef) #6
  %313 = bitcast <16 x i8> %312 to <2 x i64>
  %314 = extractelement <2 x i64> %313, i32 0
  store i64 %314, i64* %305, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @vpx_idct8x8_1_add_sse2(i32* nocapture readonly, i8* nocapture, i32) local_unnamed_addr #2 {
  %4 = load i32, i32* %0, align 4
  %5 = shl i32 %4, 16
  %6 = ashr exact i32 %5, 16
  %7 = mul nsw i32 %6, 11585
  %8 = add nsw i32 %7, 8192
  %9 = ashr i32 %8, 14
  %10 = sext i32 %9 to i64
  %11 = mul nsw i64 %10, 49757196124160
  %12 = ashr exact i64 %11, 32
  %13 = add nsw i64 %12, 8192
  %14 = lshr i64 %13, 14
  %15 = trunc i64 %14 to i32
  %16 = add i32 %15, 16
  %17 = lshr i32 %16, 5
  %18 = trunc i32 %17 to i16
  %19 = insertelement <8 x i16> undef, i16 %18, i32 0
  %20 = shufflevector <8 x i16> %19, <8 x i16> undef, <8 x i32> zeroinitializer
  %21 = bitcast i8* %1 to i64*
  %22 = load i64, i64* %21, align 1
  %23 = insertelement <2 x i64> undef, i64 %22, i32 0
  %24 = sext i32 %2 to i64
  %25 = getelementptr inbounds i8, i8* %1, i64 %24
  %26 = bitcast i8* %25 to i64*
  %27 = load i64, i64* %26, align 1
  %28 = insertelement <2 x i64> undef, i64 %27, i32 0
  %29 = bitcast <2 x i64> %23 to <16 x i8>
  %30 = shufflevector <16 x i8> %29, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %31 = bitcast <2 x i64> %28 to <16 x i8>
  %32 = shufflevector <16 x i8> %31, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %33 = bitcast <16 x i8> %30 to <8 x i16>
  %34 = add <8 x i16> %20, %33
  %35 = bitcast <16 x i8> %32 to <8 x i16>
  %36 = add <8 x i16> %20, %35
  %37 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %34, <8 x i16> %36) #6
  %38 = bitcast <16 x i8> %37 to <2 x i64>
  %39 = extractelement <2 x i64> %38, i32 0
  store i64 %39, i64* %21, align 1
  %40 = bitcast <16 x i8> %37 to <4 x float>
  %41 = shufflevector <4 x float> %40, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %42 = bitcast i8* %25 to <2 x float>*
  store <2 x float> %41, <2 x float>* %42, align 1
  %43 = shl nsw i32 %2, 1
  %44 = sext i32 %43 to i64
  %45 = getelementptr inbounds i8, i8* %1, i64 %44
  %46 = bitcast i8* %45 to i64*
  %47 = load i64, i64* %46, align 1
  %48 = insertelement <2 x i64> undef, i64 %47, i32 0
  %49 = getelementptr inbounds i8, i8* %45, i64 %24
  %50 = bitcast i8* %49 to i64*
  %51 = load i64, i64* %50, align 1
  %52 = insertelement <2 x i64> undef, i64 %51, i32 0
  %53 = bitcast <2 x i64> %48 to <16 x i8>
  %54 = shufflevector <16 x i8> %53, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %55 = bitcast <2 x i64> %52 to <16 x i8>
  %56 = shufflevector <16 x i8> %55, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %57 = bitcast <16 x i8> %54 to <8 x i16>
  %58 = add <8 x i16> %20, %57
  %59 = bitcast <16 x i8> %56 to <8 x i16>
  %60 = add <8 x i16> %20, %59
  %61 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %58, <8 x i16> %60) #6
  %62 = bitcast <16 x i8> %61 to <2 x i64>
  %63 = extractelement <2 x i64> %62, i32 0
  store i64 %63, i64* %46, align 1
  %64 = bitcast <16 x i8> %61 to <4 x float>
  %65 = shufflevector <4 x float> %64, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %66 = bitcast i8* %49 to <2 x float>*
  store <2 x float> %65, <2 x float>* %66, align 1
  %67 = getelementptr inbounds i8, i8* %45, i64 %44
  %68 = bitcast i8* %67 to i64*
  %69 = load i64, i64* %68, align 1
  %70 = insertelement <2 x i64> undef, i64 %69, i32 0
  %71 = getelementptr inbounds i8, i8* %67, i64 %24
  %72 = bitcast i8* %71 to i64*
  %73 = load i64, i64* %72, align 1
  %74 = insertelement <2 x i64> undef, i64 %73, i32 0
  %75 = bitcast <2 x i64> %70 to <16 x i8>
  %76 = shufflevector <16 x i8> %75, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %77 = bitcast <2 x i64> %74 to <16 x i8>
  %78 = shufflevector <16 x i8> %77, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %79 = bitcast <16 x i8> %76 to <8 x i16>
  %80 = add <8 x i16> %20, %79
  %81 = bitcast <16 x i8> %78 to <8 x i16>
  %82 = add <8 x i16> %20, %81
  %83 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %80, <8 x i16> %82) #6
  %84 = bitcast <16 x i8> %83 to <2 x i64>
  %85 = extractelement <2 x i64> %84, i32 0
  store i64 %85, i64* %68, align 1
  %86 = bitcast <16 x i8> %83 to <4 x float>
  %87 = shufflevector <4 x float> %86, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %88 = bitcast i8* %71 to <2 x float>*
  store <2 x float> %87, <2 x float>* %88, align 1
  %89 = getelementptr inbounds i8, i8* %67, i64 %44
  %90 = bitcast i8* %89 to i64*
  %91 = load i64, i64* %90, align 1
  %92 = insertelement <2 x i64> undef, i64 %91, i32 0
  %93 = getelementptr inbounds i8, i8* %89, i64 %24
  %94 = bitcast i8* %93 to i64*
  %95 = load i64, i64* %94, align 1
  %96 = insertelement <2 x i64> undef, i64 %95, i32 0
  %97 = bitcast <2 x i64> %92 to <16 x i8>
  %98 = shufflevector <16 x i8> %97, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %99 = bitcast <2 x i64> %96 to <16 x i8>
  %100 = shufflevector <16 x i8> %99, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %101 = bitcast <16 x i8> %98 to <8 x i16>
  %102 = add <8 x i16> %20, %101
  %103 = bitcast <16 x i8> %100 to <8 x i16>
  %104 = add <8 x i16> %20, %103
  %105 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %102, <8 x i16> %104) #6
  %106 = bitcast <16 x i8> %105 to <2 x i64>
  %107 = extractelement <2 x i64> %106, i32 0
  store i64 %107, i64* %90, align 1
  %108 = bitcast <16 x i8> %105 to <4 x float>
  %109 = shufflevector <4 x float> %108, <4 x float> undef, <2 x i32> <i32 2, i32 3>
  %110 = bitcast i8* %93 to <2 x float>*
  store <2 x float> %109, <2 x float>* %110, align 1
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @iadst8_sse2(<2 x i64>*) local_unnamed_addr #2 {
  %2 = bitcast <2 x i64>* %0 to <8 x i16>*
  %3 = load <8 x i16>, <8 x i16>* %2, align 16
  %4 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %5 = bitcast <2 x i64>* %4 to <8 x i16>*
  %6 = load <8 x i16>, <8 x i16>* %5, align 16
  %7 = shufflevector <8 x i16> %3, <8 x i16> %6, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %8 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %9 = bitcast <2 x i64>* %8 to <8 x i16>*
  %10 = load <8 x i16>, <8 x i16>* %9, align 16
  %11 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %12 = bitcast <2 x i64>* %11 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = shufflevector <8 x i16> %10, <8 x i16> %13, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %15 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %16 = bitcast <2 x i64>* %15 to <8 x i16>*
  %17 = load <8 x i16>, <8 x i16>* %16, align 16
  %18 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %19 = bitcast <2 x i64>* %18 to <8 x i16>*
  %20 = load <8 x i16>, <8 x i16>* %19, align 16
  %21 = shufflevector <8 x i16> %17, <8 x i16> %20, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %22 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %23 = bitcast <2 x i64>* %22 to <8 x i16>*
  %24 = load <8 x i16>, <8 x i16>* %23, align 16
  %25 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %26 = bitcast <2 x i64>* %25 to <8 x i16>*
  %27 = load <8 x i16>, <8 x i16>* %26, align 16
  %28 = shufflevector <8 x i16> %24, <8 x i16> %27, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %29 = shufflevector <8 x i16> %3, <8 x i16> %6, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %30 = shufflevector <8 x i16> %10, <8 x i16> %13, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %31 = shufflevector <8 x i16> %17, <8 x i16> %20, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %32 = shufflevector <8 x i16> %24, <8 x i16> %27, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %33 = bitcast <8 x i16> %7 to <4 x i32>
  %34 = bitcast <8 x i16> %14 to <4 x i32>
  %35 = shufflevector <4 x i32> %33, <4 x i32> %34, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %36 = bitcast <4 x i32> %35 to <2 x i64>
  %37 = bitcast <8 x i16> %21 to <4 x i32>
  %38 = bitcast <8 x i16> %28 to <4 x i32>
  %39 = shufflevector <4 x i32> %37, <4 x i32> %38, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %40 = bitcast <4 x i32> %39 to <2 x i64>
  %41 = bitcast <8 x i16> %29 to <4 x i32>
  %42 = bitcast <8 x i16> %30 to <4 x i32>
  %43 = shufflevector <4 x i32> %41, <4 x i32> %42, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %44 = bitcast <4 x i32> %43 to <2 x i64>
  %45 = bitcast <8 x i16> %31 to <4 x i32>
  %46 = bitcast <8 x i16> %32 to <4 x i32>
  %47 = shufflevector <4 x i32> %45, <4 x i32> %46, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %48 = bitcast <4 x i32> %47 to <2 x i64>
  %49 = shufflevector <4 x i32> %33, <4 x i32> %34, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %50 = bitcast <4 x i32> %49 to <2 x i64>
  %51 = shufflevector <4 x i32> %37, <4 x i32> %38, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %52 = bitcast <4 x i32> %51 to <2 x i64>
  %53 = shufflevector <4 x i32> %41, <4 x i32> %42, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %54 = bitcast <4 x i32> %53 to <2 x i64>
  %55 = shufflevector <4 x i32> %45, <4 x i32> %46, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %56 = bitcast <4 x i32> %55 to <2 x i64>
  %57 = shufflevector <2 x i64> %36, <2 x i64> %40, <2 x i32> <i32 0, i32 2>
  %58 = shufflevector <2 x i64> %36, <2 x i64> %40, <2 x i32> <i32 1, i32 3>
  %59 = shufflevector <2 x i64> %50, <2 x i64> %52, <2 x i32> <i32 0, i32 2>
  %60 = shufflevector <2 x i64> %50, <2 x i64> %52, <2 x i32> <i32 1, i32 3>
  %61 = shufflevector <2 x i64> %44, <2 x i64> %48, <2 x i32> <i32 0, i32 2>
  %62 = shufflevector <2 x i64> %44, <2 x i64> %48, <2 x i32> <i32 1, i32 3>
  %63 = shufflevector <2 x i64> %54, <2 x i64> %56, <2 x i32> <i32 0, i32 2>
  %64 = shufflevector <2 x i64> %54, <2 x i64> %56, <2 x i32> <i32 1, i32 3>
  %65 = bitcast <2 x i64> %64 to <8 x i16>
  %66 = bitcast <2 x i64> %57 to <8 x i16>
  %67 = shufflevector <8 x i16> %65, <8 x i16> %66, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %68 = shufflevector <8 x i16> %65, <8 x i16> %66, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %69 = bitcast <2 x i64> %62 to <8 x i16>
  %70 = bitcast <2 x i64> %59 to <8 x i16>
  %71 = shufflevector <8 x i16> %69, <8 x i16> %70, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %72 = shufflevector <8 x i16> %69, <8 x i16> %70, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %73 = bitcast <2 x i64> %60 to <8 x i16>
  %74 = bitcast <2 x i64> %61 to <8 x i16>
  %75 = shufflevector <8 x i16> %73, <8 x i16> %74, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %76 = shufflevector <8 x i16> %73, <8 x i16> %74, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %77 = bitcast <2 x i64> %58 to <8 x i16>
  %78 = bitcast <2 x i64> %63 to <8 x i16>
  %79 = shufflevector <8 x i16> %77, <8 x i16> %78, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %80 = shufflevector <8 x i16> %77, <8 x i16> %78, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %81 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %67, <8 x i16> <i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606>) #6
  %82 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %68, <8 x i16> <i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606>) #6
  %83 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %67, <8 x i16> <i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305>) #6
  %84 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %68, <8 x i16> <i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305>) #6
  %85 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %71, <8 x i16> <i16 14449, i16 7723, i16 14449, i16 7723, i16 14449, i16 7723, i16 14449, i16 7723>) #6
  %86 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %72, <8 x i16> <i16 14449, i16 7723, i16 14449, i16 7723, i16 14449, i16 7723, i16 14449, i16 7723>) #6
  %87 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %71, <8 x i16> <i16 7723, i16 -14449, i16 7723, i16 -14449, i16 7723, i16 -14449, i16 7723, i16 -14449>) #6
  %88 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %72, <8 x i16> <i16 7723, i16 -14449, i16 7723, i16 -14449, i16 7723, i16 -14449, i16 7723, i16 -14449>) #6
  %89 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %75, <8 x i16> <i16 10394, i16 12665, i16 10394, i16 12665, i16 10394, i16 12665, i16 10394, i16 12665>) #6
  %90 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %76, <8 x i16> <i16 10394, i16 12665, i16 10394, i16 12665, i16 10394, i16 12665, i16 10394, i16 12665>) #6
  %91 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %75, <8 x i16> <i16 12665, i16 -10394, i16 12665, i16 -10394, i16 12665, i16 -10394, i16 12665, i16 -10394>) #6
  %92 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %76, <8 x i16> <i16 12665, i16 -10394, i16 12665, i16 -10394, i16 12665, i16 -10394, i16 12665, i16 -10394>) #6
  %93 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %79, <8 x i16> <i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679>) #6
  %94 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %80, <8 x i16> <i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679>) #6
  %95 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %79, <8 x i16> <i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756>) #6
  %96 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %80, <8 x i16> <i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756>) #6
  %97 = add <4 x i32> %81, <i32 8192, i32 8192, i32 8192, i32 8192>
  %98 = add <4 x i32> %97, %89
  %99 = ashr <4 x i32> %98, <i32 14, i32 14, i32 14, i32 14>
  %100 = add <4 x i32> %82, <i32 8192, i32 8192, i32 8192, i32 8192>
  %101 = add <4 x i32> %100, %90
  %102 = ashr <4 x i32> %101, <i32 14, i32 14, i32 14, i32 14>
  %103 = add <4 x i32> %83, <i32 8192, i32 8192, i32 8192, i32 8192>
  %104 = add <4 x i32> %103, %91
  %105 = ashr <4 x i32> %104, <i32 14, i32 14, i32 14, i32 14>
  %106 = add <4 x i32> %84, <i32 8192, i32 8192, i32 8192, i32 8192>
  %107 = add <4 x i32> %106, %92
  %108 = ashr <4 x i32> %107, <i32 14, i32 14, i32 14, i32 14>
  %109 = add <4 x i32> %85, <i32 8192, i32 8192, i32 8192, i32 8192>
  %110 = add <4 x i32> %109, %93
  %111 = ashr <4 x i32> %110, <i32 14, i32 14, i32 14, i32 14>
  %112 = add <4 x i32> %86, <i32 8192, i32 8192, i32 8192, i32 8192>
  %113 = add <4 x i32> %112, %94
  %114 = ashr <4 x i32> %113, <i32 14, i32 14, i32 14, i32 14>
  %115 = add <4 x i32> %87, <i32 8192, i32 8192, i32 8192, i32 8192>
  %116 = add <4 x i32> %115, %95
  %117 = ashr <4 x i32> %116, <i32 14, i32 14, i32 14, i32 14>
  %118 = add <4 x i32> %88, <i32 8192, i32 8192, i32 8192, i32 8192>
  %119 = add <4 x i32> %118, %96
  %120 = ashr <4 x i32> %119, <i32 14, i32 14, i32 14, i32 14>
  %121 = sub <4 x i32> %97, %89
  %122 = ashr <4 x i32> %121, <i32 14, i32 14, i32 14, i32 14>
  %123 = sub <4 x i32> %100, %90
  %124 = ashr <4 x i32> %123, <i32 14, i32 14, i32 14, i32 14>
  %125 = sub <4 x i32> %103, %91
  %126 = ashr <4 x i32> %125, <i32 14, i32 14, i32 14, i32 14>
  %127 = sub <4 x i32> %106, %92
  %128 = ashr <4 x i32> %127, <i32 14, i32 14, i32 14, i32 14>
  %129 = sub <4 x i32> %109, %93
  %130 = ashr <4 x i32> %129, <i32 14, i32 14, i32 14, i32 14>
  %131 = sub <4 x i32> %112, %94
  %132 = ashr <4 x i32> %131, <i32 14, i32 14, i32 14, i32 14>
  %133 = sub <4 x i32> %115, %95
  %134 = ashr <4 x i32> %133, <i32 14, i32 14, i32 14, i32 14>
  %135 = sub <4 x i32> %118, %96
  %136 = ashr <4 x i32> %135, <i32 14, i32 14, i32 14, i32 14>
  %137 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %99, <4 x i32> %102) #6
  %138 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %105, <4 x i32> %108) #6
  %139 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %111, <4 x i32> %114) #6
  %140 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %117, <4 x i32> %120) #6
  %141 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %122, <4 x i32> %124) #6
  %142 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %126, <4 x i32> %128) #6
  %143 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %130, <4 x i32> %132) #6
  %144 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %134, <4 x i32> %136) #6
  %145 = add <8 x i16> %139, %137
  %146 = add <8 x i16> %138, %140
  %147 = sub <8 x i16> %137, %139
  %148 = sub <8 x i16> %138, %140
  %149 = shufflevector <8 x i16> %141, <8 x i16> %142, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %150 = shufflevector <8 x i16> %141, <8 x i16> %142, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %151 = shufflevector <8 x i16> %143, <8 x i16> %144, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %152 = shufflevector <8 x i16> %143, <8 x i16> %144, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %153 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %149, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %154 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %150, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %155 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %149, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %156 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %150, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %157 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %151, <8 x i16> <i16 -6270, i16 15137, i16 -6270, i16 15137, i16 -6270, i16 15137, i16 -6270, i16 15137>) #6
  %158 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %152, <8 x i16> <i16 -6270, i16 15137, i16 -6270, i16 15137, i16 -6270, i16 15137, i16 -6270, i16 15137>) #6
  %159 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %151, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %160 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %152, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %161 = add <4 x i32> %153, <i32 8192, i32 8192, i32 8192, i32 8192>
  %162 = add <4 x i32> %161, %157
  %163 = ashr <4 x i32> %162, <i32 14, i32 14, i32 14, i32 14>
  %164 = add <4 x i32> %154, <i32 8192, i32 8192, i32 8192, i32 8192>
  %165 = add <4 x i32> %164, %158
  %166 = ashr <4 x i32> %165, <i32 14, i32 14, i32 14, i32 14>
  %167 = add <4 x i32> %155, <i32 8192, i32 8192, i32 8192, i32 8192>
  %168 = add <4 x i32> %167, %159
  %169 = ashr <4 x i32> %168, <i32 14, i32 14, i32 14, i32 14>
  %170 = add <4 x i32> %156, <i32 8192, i32 8192, i32 8192, i32 8192>
  %171 = add <4 x i32> %170, %160
  %172 = ashr <4 x i32> %171, <i32 14, i32 14, i32 14, i32 14>
  %173 = sub <4 x i32> %161, %157
  %174 = ashr <4 x i32> %173, <i32 14, i32 14, i32 14, i32 14>
  %175 = sub <4 x i32> %164, %158
  %176 = ashr <4 x i32> %175, <i32 14, i32 14, i32 14, i32 14>
  %177 = sub <4 x i32> %167, %159
  %178 = ashr <4 x i32> %177, <i32 14, i32 14, i32 14, i32 14>
  %179 = sub <4 x i32> %170, %160
  %180 = ashr <4 x i32> %179, <i32 14, i32 14, i32 14, i32 14>
  %181 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %163, <4 x i32> %166) #6
  %182 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %169, <4 x i32> %172) #6
  %183 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %174, <4 x i32> %176) #6
  %184 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %178, <4 x i32> %180) #6
  %185 = shufflevector <8 x i16> %147, <8 x i16> %148, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %186 = shufflevector <8 x i16> %147, <8 x i16> %148, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %187 = shufflevector <8 x i16> %183, <8 x i16> %184, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %188 = shufflevector <8 x i16> %183, <8 x i16> %184, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %189 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %185, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %190 = add <4 x i32> %189, <i32 8192, i32 8192, i32 8192, i32 8192>
  %191 = ashr <4 x i32> %190, <i32 14, i32 14, i32 14, i32 14>
  %192 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %186, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %193 = add <4 x i32> %192, <i32 8192, i32 8192, i32 8192, i32 8192>
  %194 = ashr <4 x i32> %193, <i32 14, i32 14, i32 14, i32 14>
  %195 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %191, <4 x i32> %194) #6
  %196 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %185, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %197 = add <4 x i32> %196, <i32 8192, i32 8192, i32 8192, i32 8192>
  %198 = ashr <4 x i32> %197, <i32 14, i32 14, i32 14, i32 14>
  %199 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %186, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %200 = add <4 x i32> %199, <i32 8192, i32 8192, i32 8192, i32 8192>
  %201 = ashr <4 x i32> %200, <i32 14, i32 14, i32 14, i32 14>
  %202 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %198, <4 x i32> %201) #6
  %203 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %187, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %204 = add <4 x i32> %203, <i32 8192, i32 8192, i32 8192, i32 8192>
  %205 = ashr <4 x i32> %204, <i32 14, i32 14, i32 14, i32 14>
  %206 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %188, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %207 = add <4 x i32> %206, <i32 8192, i32 8192, i32 8192, i32 8192>
  %208 = ashr <4 x i32> %207, <i32 14, i32 14, i32 14, i32 14>
  %209 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %205, <4 x i32> %208) #6
  %210 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %187, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %211 = add <4 x i32> %210, <i32 8192, i32 8192, i32 8192, i32 8192>
  %212 = ashr <4 x i32> %211, <i32 14, i32 14, i32 14, i32 14>
  %213 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %188, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %214 = add <4 x i32> %213, <i32 8192, i32 8192, i32 8192, i32 8192>
  %215 = ashr <4 x i32> %214, <i32 14, i32 14, i32 14, i32 14>
  %216 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %212, <4 x i32> %215) #6
  store <8 x i16> %145, <8 x i16>* %2, align 16
  %217 = sub <8 x i16> zeroinitializer, %181
  store <8 x i16> %217, <8 x i16>* %5, align 16
  store <8 x i16> %209, <8 x i16>* %9, align 16
  %218 = sub <8 x i16> zeroinitializer, %195
  store <8 x i16> %218, <8 x i16>* %12, align 16
  store <8 x i16> %202, <8 x i16>* %16, align 16
  %219 = sub <8 x i16> zeroinitializer, %216
  store <8 x i16> %219, <8 x i16>* %19, align 16
  store <8 x i16> %182, <8 x i16>* %23, align 16
  %220 = sub <8 x i16> zeroinitializer, %146
  store <8 x i16> %220, <8 x i16>* %26, align 16
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @vpx_idct16x16_256_add_sse2(i32* nocapture readonly, i8* nocapture, i32) local_unnamed_addr #0 {
  %4 = alloca [16 x <2 x i64>], align 16
  %5 = alloca [16 x <2 x i64>], align 16
  %6 = alloca [16 x <2 x i64>], align 16
  %7 = bitcast [16 x <2 x i64>]* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %7) #6
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %7, i8 -86, i64 256, i1 false)
  %8 = bitcast [16 x <2 x i64>]* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %8) #6
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %8, i8 -86, i64 256, i1 false)
  %9 = bitcast [16 x <2 x i64>]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %9) #6
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 256, i1 false)
  %10 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %4, i64 0, i64 0
  %11 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 0
  br label %30

12:                                               ; preds = %30
  %13 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 0
  %14 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 1
  %15 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 2
  %16 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 3
  %17 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 4
  %18 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 5
  %19 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 6
  %20 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 7
  %21 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 8
  %22 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 9
  %23 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 10
  %24 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 11
  %25 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 12
  %26 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 13
  %27 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 14
  %28 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 15
  %29 = sext i32 %2 to i64
  br label %257

30:                                               ; preds = %30, %3
  %31 = phi i32 [ 0, %3 ], [ %255, %30 ]
  %32 = phi <2 x i64>* [ %10, %3 ], [ %11, %30 ]
  %33 = phi i32* [ %0, %3 ], [ %254, %30 ]
  %34 = bitcast i32* %33 to <4 x i32>*
  %35 = load <4 x i32>, <4 x i32>* %34, align 16
  %36 = getelementptr inbounds i32, i32* %33, i64 4
  %37 = bitcast i32* %36 to <4 x i32>*
  %38 = load <4 x i32>, <4 x i32>* %37, align 16
  %39 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %35, <4 x i32> %38) #6
  %40 = bitcast <2 x i64>* %32 to <8 x i16>*
  store <8 x i16> %39, <8 x i16>* %40, align 16
  %41 = getelementptr inbounds i32, i32* %33, i64 16
  %42 = bitcast i32* %41 to <4 x i32>*
  %43 = load <4 x i32>, <4 x i32>* %42, align 16
  %44 = getelementptr inbounds i32, i32* %33, i64 20
  %45 = bitcast i32* %44 to <4 x i32>*
  %46 = load <4 x i32>, <4 x i32>* %45, align 16
  %47 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %43, <4 x i32> %46) #6
  %48 = getelementptr inbounds <2 x i64>, <2 x i64>* %32, i64 1
  %49 = bitcast <2 x i64>* %48 to <8 x i16>*
  store <8 x i16> %47, <8 x i16>* %49, align 16
  %50 = getelementptr inbounds i32, i32* %33, i64 32
  %51 = bitcast i32* %50 to <4 x i32>*
  %52 = load <4 x i32>, <4 x i32>* %51, align 16
  %53 = getelementptr inbounds i32, i32* %33, i64 36
  %54 = bitcast i32* %53 to <4 x i32>*
  %55 = load <4 x i32>, <4 x i32>* %54, align 16
  %56 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %52, <4 x i32> %55) #6
  %57 = getelementptr inbounds <2 x i64>, <2 x i64>* %32, i64 2
  %58 = bitcast <2 x i64>* %57 to <8 x i16>*
  store <8 x i16> %56, <8 x i16>* %58, align 16
  %59 = getelementptr inbounds i32, i32* %33, i64 48
  %60 = bitcast i32* %59 to <4 x i32>*
  %61 = load <4 x i32>, <4 x i32>* %60, align 16
  %62 = getelementptr inbounds i32, i32* %33, i64 52
  %63 = bitcast i32* %62 to <4 x i32>*
  %64 = load <4 x i32>, <4 x i32>* %63, align 16
  %65 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %61, <4 x i32> %64) #6
  %66 = getelementptr inbounds <2 x i64>, <2 x i64>* %32, i64 3
  %67 = bitcast <2 x i64>* %66 to <8 x i16>*
  store <8 x i16> %65, <8 x i16>* %67, align 16
  %68 = getelementptr inbounds i32, i32* %33, i64 64
  %69 = bitcast i32* %68 to <4 x i32>*
  %70 = load <4 x i32>, <4 x i32>* %69, align 16
  %71 = getelementptr inbounds i32, i32* %33, i64 68
  %72 = bitcast i32* %71 to <4 x i32>*
  %73 = load <4 x i32>, <4 x i32>* %72, align 16
  %74 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %70, <4 x i32> %73) #6
  %75 = getelementptr inbounds <2 x i64>, <2 x i64>* %32, i64 4
  %76 = bitcast <2 x i64>* %75 to <8 x i16>*
  store <8 x i16> %74, <8 x i16>* %76, align 16
  %77 = getelementptr inbounds i32, i32* %33, i64 80
  %78 = bitcast i32* %77 to <4 x i32>*
  %79 = load <4 x i32>, <4 x i32>* %78, align 16
  %80 = getelementptr inbounds i32, i32* %33, i64 84
  %81 = bitcast i32* %80 to <4 x i32>*
  %82 = load <4 x i32>, <4 x i32>* %81, align 16
  %83 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %79, <4 x i32> %82) #6
  %84 = getelementptr inbounds <2 x i64>, <2 x i64>* %32, i64 5
  %85 = bitcast <2 x i64>* %84 to <8 x i16>*
  store <8 x i16> %83, <8 x i16>* %85, align 16
  %86 = getelementptr inbounds i32, i32* %33, i64 96
  %87 = bitcast i32* %86 to <4 x i32>*
  %88 = load <4 x i32>, <4 x i32>* %87, align 16
  %89 = getelementptr inbounds i32, i32* %33, i64 100
  %90 = bitcast i32* %89 to <4 x i32>*
  %91 = load <4 x i32>, <4 x i32>* %90, align 16
  %92 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %88, <4 x i32> %91) #6
  %93 = getelementptr inbounds <2 x i64>, <2 x i64>* %32, i64 6
  %94 = bitcast <2 x i64>* %93 to <8 x i16>*
  store <8 x i16> %92, <8 x i16>* %94, align 16
  %95 = getelementptr inbounds i32, i32* %33, i64 112
  %96 = bitcast i32* %95 to <4 x i32>*
  %97 = load <4 x i32>, <4 x i32>* %96, align 16
  %98 = getelementptr inbounds i32, i32* %33, i64 116
  %99 = bitcast i32* %98 to <4 x i32>*
  %100 = load <4 x i32>, <4 x i32>* %99, align 16
  %101 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %97, <4 x i32> %100) #6
  %102 = getelementptr inbounds <2 x i64>, <2 x i64>* %32, i64 7
  %103 = shufflevector <8 x i16> %39, <8 x i16> %47, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %104 = shufflevector <8 x i16> %56, <8 x i16> %65, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %105 = shufflevector <8 x i16> %74, <8 x i16> %83, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %106 = shufflevector <8 x i16> %92, <8 x i16> %101, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %107 = shufflevector <8 x i16> %39, <8 x i16> %47, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %108 = shufflevector <8 x i16> %56, <8 x i16> %65, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %109 = shufflevector <8 x i16> %74, <8 x i16> %83, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %110 = shufflevector <8 x i16> %92, <8 x i16> %101, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %111 = bitcast <8 x i16> %103 to <4 x i32>
  %112 = bitcast <8 x i16> %104 to <4 x i32>
  %113 = shufflevector <4 x i32> %111, <4 x i32> %112, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %114 = bitcast <4 x i32> %113 to <2 x i64>
  %115 = bitcast <8 x i16> %105 to <4 x i32>
  %116 = bitcast <8 x i16> %106 to <4 x i32>
  %117 = shufflevector <4 x i32> %115, <4 x i32> %116, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %118 = bitcast <4 x i32> %117 to <2 x i64>
  %119 = bitcast <8 x i16> %107 to <4 x i32>
  %120 = bitcast <8 x i16> %108 to <4 x i32>
  %121 = shufflevector <4 x i32> %119, <4 x i32> %120, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %122 = bitcast <4 x i32> %121 to <2 x i64>
  %123 = bitcast <8 x i16> %109 to <4 x i32>
  %124 = bitcast <8 x i16> %110 to <4 x i32>
  %125 = shufflevector <4 x i32> %123, <4 x i32> %124, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %126 = bitcast <4 x i32> %125 to <2 x i64>
  %127 = shufflevector <4 x i32> %111, <4 x i32> %112, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %128 = bitcast <4 x i32> %127 to <2 x i64>
  %129 = shufflevector <4 x i32> %115, <4 x i32> %116, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %130 = bitcast <4 x i32> %129 to <2 x i64>
  %131 = shufflevector <4 x i32> %119, <4 x i32> %120, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %132 = bitcast <4 x i32> %131 to <2 x i64>
  %133 = shufflevector <4 x i32> %123, <4 x i32> %124, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %134 = bitcast <4 x i32> %133 to <2 x i64>
  %135 = shufflevector <2 x i64> %114, <2 x i64> %118, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %135, <2 x i64>* %32, align 16
  %136 = shufflevector <2 x i64> %114, <2 x i64> %118, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %136, <2 x i64>* %48, align 16
  %137 = shufflevector <2 x i64> %128, <2 x i64> %130, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %137, <2 x i64>* %57, align 16
  %138 = shufflevector <2 x i64> %128, <2 x i64> %130, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %138, <2 x i64>* %66, align 16
  %139 = shufflevector <2 x i64> %122, <2 x i64> %126, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %139, <2 x i64>* %75, align 16
  %140 = shufflevector <2 x i64> %122, <2 x i64> %126, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %140, <2 x i64>* %84, align 16
  %141 = shufflevector <2 x i64> %132, <2 x i64> %134, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %141, <2 x i64>* %93, align 16
  %142 = shufflevector <2 x i64> %132, <2 x i64> %134, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %142, <2 x i64>* %102, align 16
  %143 = getelementptr inbounds i32, i32* %33, i64 8
  %144 = getelementptr inbounds <2 x i64>, <2 x i64>* %32, i64 8
  %145 = bitcast i32* %143 to <4 x i32>*
  %146 = load <4 x i32>, <4 x i32>* %145, align 16
  %147 = getelementptr inbounds i32, i32* %33, i64 12
  %148 = bitcast i32* %147 to <4 x i32>*
  %149 = load <4 x i32>, <4 x i32>* %148, align 16
  %150 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %146, <4 x i32> %149) #6
  %151 = bitcast <2 x i64>* %144 to <8 x i16>*
  store <8 x i16> %150, <8 x i16>* %151, align 16
  %152 = getelementptr inbounds i32, i32* %33, i64 24
  %153 = bitcast i32* %152 to <4 x i32>*
  %154 = load <4 x i32>, <4 x i32>* %153, align 16
  %155 = getelementptr inbounds i32, i32* %33, i64 28
  %156 = bitcast i32* %155 to <4 x i32>*
  %157 = load <4 x i32>, <4 x i32>* %156, align 16
  %158 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %154, <4 x i32> %157) #6
  %159 = getelementptr inbounds <2 x i64>, <2 x i64>* %32, i64 9
  %160 = bitcast <2 x i64>* %159 to <8 x i16>*
  store <8 x i16> %158, <8 x i16>* %160, align 16
  %161 = getelementptr inbounds i32, i32* %33, i64 40
  %162 = bitcast i32* %161 to <4 x i32>*
  %163 = load <4 x i32>, <4 x i32>* %162, align 16
  %164 = getelementptr inbounds i32, i32* %33, i64 44
  %165 = bitcast i32* %164 to <4 x i32>*
  %166 = load <4 x i32>, <4 x i32>* %165, align 16
  %167 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %163, <4 x i32> %166) #6
  %168 = getelementptr inbounds <2 x i64>, <2 x i64>* %32, i64 10
  %169 = bitcast <2 x i64>* %168 to <8 x i16>*
  store <8 x i16> %167, <8 x i16>* %169, align 16
  %170 = getelementptr inbounds i32, i32* %33, i64 56
  %171 = bitcast i32* %170 to <4 x i32>*
  %172 = load <4 x i32>, <4 x i32>* %171, align 16
  %173 = getelementptr inbounds i32, i32* %33, i64 60
  %174 = bitcast i32* %173 to <4 x i32>*
  %175 = load <4 x i32>, <4 x i32>* %174, align 16
  %176 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %172, <4 x i32> %175) #6
  %177 = getelementptr inbounds <2 x i64>, <2 x i64>* %32, i64 11
  %178 = bitcast <2 x i64>* %177 to <8 x i16>*
  store <8 x i16> %176, <8 x i16>* %178, align 16
  %179 = getelementptr inbounds i32, i32* %33, i64 72
  %180 = bitcast i32* %179 to <4 x i32>*
  %181 = load <4 x i32>, <4 x i32>* %180, align 16
  %182 = getelementptr inbounds i32, i32* %33, i64 76
  %183 = bitcast i32* %182 to <4 x i32>*
  %184 = load <4 x i32>, <4 x i32>* %183, align 16
  %185 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %181, <4 x i32> %184) #6
  %186 = getelementptr inbounds <2 x i64>, <2 x i64>* %32, i64 12
  %187 = bitcast <2 x i64>* %186 to <8 x i16>*
  store <8 x i16> %185, <8 x i16>* %187, align 16
  %188 = getelementptr inbounds i32, i32* %33, i64 88
  %189 = bitcast i32* %188 to <4 x i32>*
  %190 = load <4 x i32>, <4 x i32>* %189, align 16
  %191 = getelementptr inbounds i32, i32* %33, i64 92
  %192 = bitcast i32* %191 to <4 x i32>*
  %193 = load <4 x i32>, <4 x i32>* %192, align 16
  %194 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %190, <4 x i32> %193) #6
  %195 = getelementptr inbounds <2 x i64>, <2 x i64>* %32, i64 13
  %196 = bitcast <2 x i64>* %195 to <8 x i16>*
  store <8 x i16> %194, <8 x i16>* %196, align 16
  %197 = getelementptr inbounds i32, i32* %33, i64 104
  %198 = bitcast i32* %197 to <4 x i32>*
  %199 = load <4 x i32>, <4 x i32>* %198, align 16
  %200 = getelementptr inbounds i32, i32* %33, i64 108
  %201 = bitcast i32* %200 to <4 x i32>*
  %202 = load <4 x i32>, <4 x i32>* %201, align 16
  %203 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %199, <4 x i32> %202) #6
  %204 = getelementptr inbounds <2 x i64>, <2 x i64>* %32, i64 14
  %205 = bitcast <2 x i64>* %204 to <8 x i16>*
  store <8 x i16> %203, <8 x i16>* %205, align 16
  %206 = getelementptr inbounds i32, i32* %33, i64 120
  %207 = bitcast i32* %206 to <4 x i32>*
  %208 = load <4 x i32>, <4 x i32>* %207, align 16
  %209 = getelementptr inbounds i32, i32* %33, i64 124
  %210 = bitcast i32* %209 to <4 x i32>*
  %211 = load <4 x i32>, <4 x i32>* %210, align 16
  %212 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %208, <4 x i32> %211) #6
  %213 = getelementptr inbounds <2 x i64>, <2 x i64>* %32, i64 15
  %214 = shufflevector <8 x i16> %150, <8 x i16> %158, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %215 = shufflevector <8 x i16> %167, <8 x i16> %176, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %216 = shufflevector <8 x i16> %185, <8 x i16> %194, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %217 = shufflevector <8 x i16> %203, <8 x i16> %212, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %218 = shufflevector <8 x i16> %150, <8 x i16> %158, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %219 = shufflevector <8 x i16> %167, <8 x i16> %176, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %220 = shufflevector <8 x i16> %185, <8 x i16> %194, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %221 = shufflevector <8 x i16> %203, <8 x i16> %212, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %222 = bitcast <8 x i16> %214 to <4 x i32>
  %223 = bitcast <8 x i16> %215 to <4 x i32>
  %224 = shufflevector <4 x i32> %222, <4 x i32> %223, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %225 = bitcast <4 x i32> %224 to <2 x i64>
  %226 = bitcast <8 x i16> %216 to <4 x i32>
  %227 = bitcast <8 x i16> %217 to <4 x i32>
  %228 = shufflevector <4 x i32> %226, <4 x i32> %227, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %229 = bitcast <4 x i32> %228 to <2 x i64>
  %230 = bitcast <8 x i16> %218 to <4 x i32>
  %231 = bitcast <8 x i16> %219 to <4 x i32>
  %232 = shufflevector <4 x i32> %230, <4 x i32> %231, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %233 = bitcast <4 x i32> %232 to <2 x i64>
  %234 = bitcast <8 x i16> %220 to <4 x i32>
  %235 = bitcast <8 x i16> %221 to <4 x i32>
  %236 = shufflevector <4 x i32> %234, <4 x i32> %235, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %237 = bitcast <4 x i32> %236 to <2 x i64>
  %238 = shufflevector <4 x i32> %222, <4 x i32> %223, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %239 = bitcast <4 x i32> %238 to <2 x i64>
  %240 = shufflevector <4 x i32> %226, <4 x i32> %227, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %241 = bitcast <4 x i32> %240 to <2 x i64>
  %242 = shufflevector <4 x i32> %230, <4 x i32> %231, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %243 = bitcast <4 x i32> %242 to <2 x i64>
  %244 = shufflevector <4 x i32> %234, <4 x i32> %235, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %245 = bitcast <4 x i32> %244 to <2 x i64>
  %246 = shufflevector <2 x i64> %225, <2 x i64> %229, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %246, <2 x i64>* %144, align 16
  %247 = shufflevector <2 x i64> %225, <2 x i64> %229, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %247, <2 x i64>* %159, align 16
  %248 = shufflevector <2 x i64> %239, <2 x i64> %241, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %248, <2 x i64>* %168, align 16
  %249 = shufflevector <2 x i64> %239, <2 x i64> %241, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %249, <2 x i64>* %177, align 16
  %250 = shufflevector <2 x i64> %233, <2 x i64> %237, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %250, <2 x i64>* %186, align 16
  %251 = shufflevector <2 x i64> %233, <2 x i64> %237, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %251, <2 x i64>* %195, align 16
  %252 = shufflevector <2 x i64> %243, <2 x i64> %245, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %252, <2 x i64>* %204, align 16
  %253 = shufflevector <2 x i64> %243, <2 x i64> %245, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %253, <2 x i64>* %213, align 16
  call fastcc void @idct16_8col(<2 x i64>* %32, <2 x i64>* %32)
  %254 = getelementptr inbounds i32, i32* %33, i64 128
  %255 = add nuw nsw i32 %31, 1
  %256 = icmp eq i32 %255, 2
  br i1 %256, label %12, label %30

257:                                              ; preds = %12, %409
  %258 = phi i64 [ 0, %12 ], [ %411, %409 ]
  %259 = phi i8* [ %1, %12 ], [ %410, %409 ]
  %260 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %4, i64 0, i64 %258
  %261 = bitcast <2 x i64>* %260 to <8 x i16>*
  %262 = load <8 x i16>, <8 x i16>* %261, align 16
  %263 = getelementptr inbounds <2 x i64>, <2 x i64>* %260, i64 1
  %264 = bitcast <2 x i64>* %263 to <8 x i16>*
  %265 = load <8 x i16>, <8 x i16>* %264, align 16
  %266 = shufflevector <8 x i16> %262, <8 x i16> %265, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %267 = getelementptr inbounds <2 x i64>, <2 x i64>* %260, i64 2
  %268 = bitcast <2 x i64>* %267 to <8 x i16>*
  %269 = load <8 x i16>, <8 x i16>* %268, align 16
  %270 = getelementptr inbounds <2 x i64>, <2 x i64>* %260, i64 3
  %271 = bitcast <2 x i64>* %270 to <8 x i16>*
  %272 = load <8 x i16>, <8 x i16>* %271, align 16
  %273 = shufflevector <8 x i16> %269, <8 x i16> %272, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %274 = getelementptr inbounds <2 x i64>, <2 x i64>* %260, i64 4
  %275 = bitcast <2 x i64>* %274 to <8 x i16>*
  %276 = load <8 x i16>, <8 x i16>* %275, align 16
  %277 = getelementptr inbounds <2 x i64>, <2 x i64>* %260, i64 5
  %278 = bitcast <2 x i64>* %277 to <8 x i16>*
  %279 = load <8 x i16>, <8 x i16>* %278, align 16
  %280 = shufflevector <8 x i16> %276, <8 x i16> %279, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %281 = getelementptr inbounds <2 x i64>, <2 x i64>* %260, i64 6
  %282 = bitcast <2 x i64>* %281 to <8 x i16>*
  %283 = load <8 x i16>, <8 x i16>* %282, align 16
  %284 = getelementptr inbounds <2 x i64>, <2 x i64>* %260, i64 7
  %285 = bitcast <2 x i64>* %284 to <8 x i16>*
  %286 = load <8 x i16>, <8 x i16>* %285, align 16
  %287 = shufflevector <8 x i16> %283, <8 x i16> %286, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %288 = shufflevector <8 x i16> %262, <8 x i16> %265, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %289 = shufflevector <8 x i16> %269, <8 x i16> %272, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %290 = shufflevector <8 x i16> %276, <8 x i16> %279, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %291 = shufflevector <8 x i16> %283, <8 x i16> %286, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %292 = bitcast <8 x i16> %266 to <4 x i32>
  %293 = bitcast <8 x i16> %273 to <4 x i32>
  %294 = shufflevector <4 x i32> %292, <4 x i32> %293, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %295 = bitcast <4 x i32> %294 to <2 x i64>
  %296 = bitcast <8 x i16> %280 to <4 x i32>
  %297 = bitcast <8 x i16> %287 to <4 x i32>
  %298 = shufflevector <4 x i32> %296, <4 x i32> %297, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %299 = bitcast <4 x i32> %298 to <2 x i64>
  %300 = bitcast <8 x i16> %288 to <4 x i32>
  %301 = bitcast <8 x i16> %289 to <4 x i32>
  %302 = shufflevector <4 x i32> %300, <4 x i32> %301, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %303 = bitcast <4 x i32> %302 to <2 x i64>
  %304 = bitcast <8 x i16> %290 to <4 x i32>
  %305 = bitcast <8 x i16> %291 to <4 x i32>
  %306 = shufflevector <4 x i32> %304, <4 x i32> %305, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %307 = bitcast <4 x i32> %306 to <2 x i64>
  %308 = shufflevector <4 x i32> %292, <4 x i32> %293, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %309 = bitcast <4 x i32> %308 to <2 x i64>
  %310 = shufflevector <4 x i32> %296, <4 x i32> %297, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %311 = bitcast <4 x i32> %310 to <2 x i64>
  %312 = shufflevector <4 x i32> %300, <4 x i32> %301, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %313 = bitcast <4 x i32> %312 to <2 x i64>
  %314 = shufflevector <4 x i32> %304, <4 x i32> %305, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %315 = bitcast <4 x i32> %314 to <2 x i64>
  %316 = shufflevector <2 x i64> %295, <2 x i64> %299, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %316, <2 x i64>* %13, align 16
  %317 = shufflevector <2 x i64> %295, <2 x i64> %299, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %317, <2 x i64>* %14, align 16
  %318 = shufflevector <2 x i64> %309, <2 x i64> %311, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %318, <2 x i64>* %15, align 16
  %319 = shufflevector <2 x i64> %309, <2 x i64> %311, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %319, <2 x i64>* %16, align 16
  %320 = shufflevector <2 x i64> %303, <2 x i64> %307, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %320, <2 x i64>* %17, align 16
  %321 = shufflevector <2 x i64> %303, <2 x i64> %307, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %321, <2 x i64>* %18, align 16
  %322 = shufflevector <2 x i64> %313, <2 x i64> %315, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %322, <2 x i64>* %19, align 16
  %323 = shufflevector <2 x i64> %313, <2 x i64> %315, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %323, <2 x i64>* %20, align 16
  %324 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %258
  %325 = bitcast <2 x i64>* %324 to <8 x i16>*
  %326 = load <8 x i16>, <8 x i16>* %325, align 16
  %327 = getelementptr inbounds <2 x i64>, <2 x i64>* %324, i64 1
  %328 = bitcast <2 x i64>* %327 to <8 x i16>*
  %329 = load <8 x i16>, <8 x i16>* %328, align 16
  %330 = shufflevector <8 x i16> %326, <8 x i16> %329, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %331 = getelementptr inbounds <2 x i64>, <2 x i64>* %324, i64 2
  %332 = bitcast <2 x i64>* %331 to <8 x i16>*
  %333 = load <8 x i16>, <8 x i16>* %332, align 16
  %334 = getelementptr inbounds <2 x i64>, <2 x i64>* %324, i64 3
  %335 = bitcast <2 x i64>* %334 to <8 x i16>*
  %336 = load <8 x i16>, <8 x i16>* %335, align 16
  %337 = shufflevector <8 x i16> %333, <8 x i16> %336, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %338 = getelementptr inbounds <2 x i64>, <2 x i64>* %324, i64 4
  %339 = bitcast <2 x i64>* %338 to <8 x i16>*
  %340 = load <8 x i16>, <8 x i16>* %339, align 16
  %341 = getelementptr inbounds <2 x i64>, <2 x i64>* %324, i64 5
  %342 = bitcast <2 x i64>* %341 to <8 x i16>*
  %343 = load <8 x i16>, <8 x i16>* %342, align 16
  %344 = shufflevector <8 x i16> %340, <8 x i16> %343, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %345 = getelementptr inbounds <2 x i64>, <2 x i64>* %324, i64 6
  %346 = bitcast <2 x i64>* %345 to <8 x i16>*
  %347 = load <8 x i16>, <8 x i16>* %346, align 16
  %348 = getelementptr inbounds <2 x i64>, <2 x i64>* %324, i64 7
  %349 = bitcast <2 x i64>* %348 to <8 x i16>*
  %350 = load <8 x i16>, <8 x i16>* %349, align 16
  %351 = shufflevector <8 x i16> %347, <8 x i16> %350, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %352 = shufflevector <8 x i16> %326, <8 x i16> %329, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %353 = shufflevector <8 x i16> %333, <8 x i16> %336, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %354 = shufflevector <8 x i16> %340, <8 x i16> %343, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %355 = shufflevector <8 x i16> %347, <8 x i16> %350, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %356 = bitcast <8 x i16> %330 to <4 x i32>
  %357 = bitcast <8 x i16> %337 to <4 x i32>
  %358 = shufflevector <4 x i32> %356, <4 x i32> %357, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %359 = bitcast <4 x i32> %358 to <2 x i64>
  %360 = bitcast <8 x i16> %344 to <4 x i32>
  %361 = bitcast <8 x i16> %351 to <4 x i32>
  %362 = shufflevector <4 x i32> %360, <4 x i32> %361, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %363 = bitcast <4 x i32> %362 to <2 x i64>
  %364 = bitcast <8 x i16> %352 to <4 x i32>
  %365 = bitcast <8 x i16> %353 to <4 x i32>
  %366 = shufflevector <4 x i32> %364, <4 x i32> %365, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %367 = bitcast <4 x i32> %366 to <2 x i64>
  %368 = bitcast <8 x i16> %354 to <4 x i32>
  %369 = bitcast <8 x i16> %355 to <4 x i32>
  %370 = shufflevector <4 x i32> %368, <4 x i32> %369, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %371 = bitcast <4 x i32> %370 to <2 x i64>
  %372 = shufflevector <4 x i32> %356, <4 x i32> %357, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %373 = bitcast <4 x i32> %372 to <2 x i64>
  %374 = shufflevector <4 x i32> %360, <4 x i32> %361, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %375 = bitcast <4 x i32> %374 to <2 x i64>
  %376 = shufflevector <4 x i32> %364, <4 x i32> %365, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %377 = bitcast <4 x i32> %376 to <2 x i64>
  %378 = shufflevector <4 x i32> %368, <4 x i32> %369, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %379 = bitcast <4 x i32> %378 to <2 x i64>
  %380 = shufflevector <2 x i64> %359, <2 x i64> %363, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %380, <2 x i64>* %21, align 16
  %381 = shufflevector <2 x i64> %359, <2 x i64> %363, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %381, <2 x i64>* %22, align 16
  %382 = shufflevector <2 x i64> %373, <2 x i64> %375, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %382, <2 x i64>* %23, align 16
  %383 = shufflevector <2 x i64> %373, <2 x i64> %375, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %383, <2 x i64>* %24, align 16
  %384 = shufflevector <2 x i64> %367, <2 x i64> %371, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %384, <2 x i64>* %25, align 16
  %385 = shufflevector <2 x i64> %367, <2 x i64> %371, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %385, <2 x i64>* %26, align 16
  %386 = shufflevector <2 x i64> %377, <2 x i64> %379, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %386, <2 x i64>* %27, align 16
  %387 = shufflevector <2 x i64> %377, <2 x i64> %379, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %387, <2 x i64>* %28, align 16
  call fastcc void @idct16_8col(<2 x i64>* nonnull %13, <2 x i64>* nonnull %13)
  br label %388

388:                                              ; preds = %388, %257
  %389 = phi i64 [ 0, %257 ], [ %407, %388 ]
  %390 = mul nsw i64 %389, %29
  %391 = getelementptr inbounds i8, i8* %259, i64 %390
  %392 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 %389
  %393 = bitcast <2 x i64>* %392 to <8 x i16>*
  %394 = load <8 x i16>, <8 x i16>* %393, align 16
  %395 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %394, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #6
  %396 = ashr <8 x i16> %395, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %397 = bitcast i8* %391 to i64*
  %398 = load i64, i64* %397, align 1
  %399 = insertelement <2 x i64> undef, i64 %398, i32 0
  %400 = bitcast <2 x i64> %399 to <16 x i8>
  %401 = shufflevector <16 x i8> %400, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %402 = bitcast <16 x i8> %401 to <8 x i16>
  %403 = add <8 x i16> %396, %402
  %404 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %403, <8 x i16> undef) #6
  %405 = bitcast <16 x i8> %404 to <2 x i64>
  %406 = extractelement <2 x i64> %405, i32 0
  store i64 %406, i64* %397, align 1
  %407 = add nuw nsw i64 %389, 1
  %408 = icmp eq i64 %407, 16
  br i1 %408, label %409, label %388

409:                                              ; preds = %388
  %410 = getelementptr inbounds i8, i8* %259, i64 8
  %411 = add nuw nsw i64 %258, 8
  %412 = icmp ult i64 %411, 16
  br i1 %412, label %257, label %413

413:                                              ; preds = %409
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %9) #6
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %8) #6
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %7) #6
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define internal fastcc void @idct16_8col(<2 x i64>* nocapture readonly, <2 x i64>* nocapture) unnamed_addr #3 {
  %3 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %4 = bitcast <2 x i64>* %3 to <8 x i16>*
  %5 = load <8 x i16>, <8 x i16>* %4, align 16
  %6 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 15
  %7 = bitcast <2 x i64>* %6 to <8 x i16>*
  %8 = load <8 x i16>, <8 x i16>* %7, align 16
  %9 = shufflevector <8 x i16> %5, <8 x i16> %8, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %10 = shufflevector <8 x i16> %5, <8 x i16> %8, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %11 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9, <8 x i16> <i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305>) #6
  %12 = add <4 x i32> %11, <i32 8192, i32 8192, i32 8192, i32 8192>
  %13 = ashr <4 x i32> %12, <i32 14, i32 14, i32 14, i32 14>
  %14 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10, <8 x i16> <i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305>) #6
  %15 = add <4 x i32> %14, <i32 8192, i32 8192, i32 8192, i32 8192>
  %16 = ashr <4 x i32> %15, <i32 14, i32 14, i32 14, i32 14>
  %17 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %13, <4 x i32> %16) #6
  %18 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9, <8 x i16> <i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606>) #6
  %19 = add <4 x i32> %18, <i32 8192, i32 8192, i32 8192, i32 8192>
  %20 = ashr <4 x i32> %19, <i32 14, i32 14, i32 14, i32 14>
  %21 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10, <8 x i16> <i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606>) #6
  %22 = add <4 x i32> %21, <i32 8192, i32 8192, i32 8192, i32 8192>
  %23 = ashr <4 x i32> %22, <i32 14, i32 14, i32 14, i32 14>
  %24 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %20, <4 x i32> %23) #6
  %25 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 9
  %26 = bitcast <2 x i64>* %25 to <8 x i16>*
  %27 = load <8 x i16>, <8 x i16>* %26, align 16
  %28 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %29 = bitcast <2 x i64>* %28 to <8 x i16>*
  %30 = load <8 x i16>, <8 x i16>* %29, align 16
  %31 = shufflevector <8 x i16> %27, <8 x i16> %30, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %32 = shufflevector <8 x i16> %27, <8 x i16> %30, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %33 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %31, <8 x i16> <i16 12665, i16 -10394, i16 12665, i16 -10394, i16 12665, i16 -10394, i16 12665, i16 -10394>) #6
  %34 = add <4 x i32> %33, <i32 8192, i32 8192, i32 8192, i32 8192>
  %35 = ashr <4 x i32> %34, <i32 14, i32 14, i32 14, i32 14>
  %36 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %32, <8 x i16> <i16 12665, i16 -10394, i16 12665, i16 -10394, i16 12665, i16 -10394, i16 12665, i16 -10394>) #6
  %37 = add <4 x i32> %36, <i32 8192, i32 8192, i32 8192, i32 8192>
  %38 = ashr <4 x i32> %37, <i32 14, i32 14, i32 14, i32 14>
  %39 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %35, <4 x i32> %38) #6
  %40 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %31, <8 x i16> <i16 10394, i16 12665, i16 10394, i16 12665, i16 10394, i16 12665, i16 10394, i16 12665>) #6
  %41 = add <4 x i32> %40, <i32 8192, i32 8192, i32 8192, i32 8192>
  %42 = ashr <4 x i32> %41, <i32 14, i32 14, i32 14, i32 14>
  %43 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %32, <8 x i16> <i16 10394, i16 12665, i16 10394, i16 12665, i16 10394, i16 12665, i16 10394, i16 12665>) #6
  %44 = add <4 x i32> %43, <i32 8192, i32 8192, i32 8192, i32 8192>
  %45 = ashr <4 x i32> %44, <i32 14, i32 14, i32 14, i32 14>
  %46 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %42, <4 x i32> %45) #6
  %47 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %48 = bitcast <2 x i64>* %47 to <8 x i16>*
  %49 = load <8 x i16>, <8 x i16>* %48, align 16
  %50 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 11
  %51 = bitcast <2 x i64>* %50 to <8 x i16>*
  %52 = load <8 x i16>, <8 x i16>* %51, align 16
  %53 = shufflevector <8 x i16> %49, <8 x i16> %52, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %54 = shufflevector <8 x i16> %49, <8 x i16> %52, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %55 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %53, <8 x i16> <i16 7723, i16 -14449, i16 7723, i16 -14449, i16 7723, i16 -14449, i16 7723, i16 -14449>) #6
  %56 = add <4 x i32> %55, <i32 8192, i32 8192, i32 8192, i32 8192>
  %57 = ashr <4 x i32> %56, <i32 14, i32 14, i32 14, i32 14>
  %58 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %54, <8 x i16> <i16 7723, i16 -14449, i16 7723, i16 -14449, i16 7723, i16 -14449, i16 7723, i16 -14449>) #6
  %59 = add <4 x i32> %58, <i32 8192, i32 8192, i32 8192, i32 8192>
  %60 = ashr <4 x i32> %59, <i32 14, i32 14, i32 14, i32 14>
  %61 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %57, <4 x i32> %60) #6
  %62 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %53, <8 x i16> <i16 14449, i16 7723, i16 14449, i16 7723, i16 14449, i16 7723, i16 14449, i16 7723>) #6
  %63 = add <4 x i32> %62, <i32 8192, i32 8192, i32 8192, i32 8192>
  %64 = ashr <4 x i32> %63, <i32 14, i32 14, i32 14, i32 14>
  %65 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %54, <8 x i16> <i16 14449, i16 7723, i16 14449, i16 7723, i16 14449, i16 7723, i16 14449, i16 7723>) #6
  %66 = add <4 x i32> %65, <i32 8192, i32 8192, i32 8192, i32 8192>
  %67 = ashr <4 x i32> %66, <i32 14, i32 14, i32 14, i32 14>
  %68 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %64, <4 x i32> %67) #6
  %69 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 13
  %70 = bitcast <2 x i64>* %69 to <8 x i16>*
  %71 = load <8 x i16>, <8 x i16>* %70, align 16
  %72 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %73 = bitcast <2 x i64>* %72 to <8 x i16>*
  %74 = load <8 x i16>, <8 x i16>* %73, align 16
  %75 = shufflevector <8 x i16> %71, <8 x i16> %74, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %76 = shufflevector <8 x i16> %71, <8 x i16> %74, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %77 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %75, <8 x i16> <i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756>) #6
  %78 = add <4 x i32> %77, <i32 8192, i32 8192, i32 8192, i32 8192>
  %79 = ashr <4 x i32> %78, <i32 14, i32 14, i32 14, i32 14>
  %80 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %76, <8 x i16> <i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756>) #6
  %81 = add <4 x i32> %80, <i32 8192, i32 8192, i32 8192, i32 8192>
  %82 = ashr <4 x i32> %81, <i32 14, i32 14, i32 14, i32 14>
  %83 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %79, <4 x i32> %82) #6
  %84 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %75, <8 x i16> <i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679>) #6
  %85 = add <4 x i32> %84, <i32 8192, i32 8192, i32 8192, i32 8192>
  %86 = ashr <4 x i32> %85, <i32 14, i32 14, i32 14, i32 14>
  %87 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %76, <8 x i16> <i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679>) #6
  %88 = add <4 x i32> %87, <i32 8192, i32 8192, i32 8192, i32 8192>
  %89 = ashr <4 x i32> %88, <i32 14, i32 14, i32 14, i32 14>
  %90 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %86, <4 x i32> %89) #6
  %91 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %92 = bitcast <2 x i64>* %91 to <8 x i16>*
  %93 = load <8 x i16>, <8 x i16>* %92, align 16
  %94 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 14
  %95 = bitcast <2 x i64>* %94 to <8 x i16>*
  %96 = load <8 x i16>, <8 x i16>* %95, align 16
  %97 = shufflevector <8 x i16> %93, <8 x i16> %96, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %98 = shufflevector <8 x i16> %93, <8 x i16> %96, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %99 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %97, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #6
  %100 = add <4 x i32> %99, <i32 8192, i32 8192, i32 8192, i32 8192>
  %101 = ashr <4 x i32> %100, <i32 14, i32 14, i32 14, i32 14>
  %102 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %98, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #6
  %103 = add <4 x i32> %102, <i32 8192, i32 8192, i32 8192, i32 8192>
  %104 = ashr <4 x i32> %103, <i32 14, i32 14, i32 14, i32 14>
  %105 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %101, <4 x i32> %104) #6
  %106 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %97, <8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>) #6
  %107 = add <4 x i32> %106, <i32 8192, i32 8192, i32 8192, i32 8192>
  %108 = ashr <4 x i32> %107, <i32 14, i32 14, i32 14, i32 14>
  %109 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %98, <8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>) #6
  %110 = add <4 x i32> %109, <i32 8192, i32 8192, i32 8192, i32 8192>
  %111 = ashr <4 x i32> %110, <i32 14, i32 14, i32 14, i32 14>
  %112 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %108, <4 x i32> %111) #6
  %113 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 10
  %114 = bitcast <2 x i64>* %113 to <8 x i16>*
  %115 = load <8 x i16>, <8 x i16>* %114, align 16
  %116 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %117 = bitcast <2 x i64>* %116 to <8 x i16>*
  %118 = load <8 x i16>, <8 x i16>* %117, align 16
  %119 = shufflevector <8 x i16> %115, <8 x i16> %118, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %120 = shufflevector <8 x i16> %115, <8 x i16> %118, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %121 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %119, <8 x i16> <i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102>) #6
  %122 = add <4 x i32> %121, <i32 8192, i32 8192, i32 8192, i32 8192>
  %123 = ashr <4 x i32> %122, <i32 14, i32 14, i32 14, i32 14>
  %124 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %120, <8 x i16> <i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102>) #6
  %125 = add <4 x i32> %124, <i32 8192, i32 8192, i32 8192, i32 8192>
  %126 = ashr <4 x i32> %125, <i32 14, i32 14, i32 14, i32 14>
  %127 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %123, <4 x i32> %126) #6
  %128 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %119, <8 x i16> <i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623>) #6
  %129 = add <4 x i32> %128, <i32 8192, i32 8192, i32 8192, i32 8192>
  %130 = ashr <4 x i32> %129, <i32 14, i32 14, i32 14, i32 14>
  %131 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %120, <8 x i16> <i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623>) #6
  %132 = add <4 x i32> %131, <i32 8192, i32 8192, i32 8192, i32 8192>
  %133 = ashr <4 x i32> %132, <i32 14, i32 14, i32 14, i32 14>
  %134 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %130, <4 x i32> %133) #6
  %135 = add <8 x i16> %39, %17
  %136 = sub <8 x i16> %17, %39
  %137 = sub <8 x i16> %83, %61
  %138 = add <8 x i16> %83, %61
  %139 = add <8 x i16> %90, %68
  %140 = sub <8 x i16> %90, %68
  %141 = sub <8 x i16> %24, %46
  %142 = add <8 x i16> %46, %24
  %143 = bitcast <2 x i64>* %0 to <8 x i16>*
  %144 = load <8 x i16>, <8 x i16>* %143, align 16
  %145 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 8
  %146 = bitcast <2 x i64>* %145 to <8 x i16>*
  %147 = load <8 x i16>, <8 x i16>* %146, align 16
  %148 = shufflevector <8 x i16> %144, <8 x i16> %147, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %149 = shufflevector <8 x i16> %144, <8 x i16> %147, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %150 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %148, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %151 = add <4 x i32> %150, <i32 8192, i32 8192, i32 8192, i32 8192>
  %152 = ashr <4 x i32> %151, <i32 14, i32 14, i32 14, i32 14>
  %153 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %149, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %154 = add <4 x i32> %153, <i32 8192, i32 8192, i32 8192, i32 8192>
  %155 = ashr <4 x i32> %154, <i32 14, i32 14, i32 14, i32 14>
  %156 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %152, <4 x i32> %155) #6
  %157 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %148, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %158 = add <4 x i32> %157, <i32 8192, i32 8192, i32 8192, i32 8192>
  %159 = ashr <4 x i32> %158, <i32 14, i32 14, i32 14, i32 14>
  %160 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %149, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %161 = add <4 x i32> %160, <i32 8192, i32 8192, i32 8192, i32 8192>
  %162 = ashr <4 x i32> %161, <i32 14, i32 14, i32 14, i32 14>
  %163 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %159, <4 x i32> %162) #6
  %164 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %165 = bitcast <2 x i64>* %164 to <8 x i16>*
  %166 = load <8 x i16>, <8 x i16>* %165, align 16
  %167 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 12
  %168 = bitcast <2 x i64>* %167 to <8 x i16>*
  %169 = load <8 x i16>, <8 x i16>* %168, align 16
  %170 = shufflevector <8 x i16> %166, <8 x i16> %169, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %171 = shufflevector <8 x i16> %166, <8 x i16> %169, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %172 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %170, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %173 = add <4 x i32> %172, <i32 8192, i32 8192, i32 8192, i32 8192>
  %174 = ashr <4 x i32> %173, <i32 14, i32 14, i32 14, i32 14>
  %175 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %171, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %176 = add <4 x i32> %175, <i32 8192, i32 8192, i32 8192, i32 8192>
  %177 = ashr <4 x i32> %176, <i32 14, i32 14, i32 14, i32 14>
  %178 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %174, <4 x i32> %177) #6
  %179 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %170, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %180 = add <4 x i32> %179, <i32 8192, i32 8192, i32 8192, i32 8192>
  %181 = ashr <4 x i32> %180, <i32 14, i32 14, i32 14, i32 14>
  %182 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %171, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %183 = add <4 x i32> %182, <i32 8192, i32 8192, i32 8192, i32 8192>
  %184 = ashr <4 x i32> %183, <i32 14, i32 14, i32 14, i32 14>
  %185 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %181, <4 x i32> %184) #6
  %186 = shufflevector <8 x i16> %141, <8 x i16> %136, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %187 = shufflevector <8 x i16> %141, <8 x i16> %136, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %188 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %186, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %189 = add <4 x i32> %188, <i32 8192, i32 8192, i32 8192, i32 8192>
  %190 = ashr <4 x i32> %189, <i32 14, i32 14, i32 14, i32 14>
  %191 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %187, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %192 = add <4 x i32> %191, <i32 8192, i32 8192, i32 8192, i32 8192>
  %193 = ashr <4 x i32> %192, <i32 14, i32 14, i32 14, i32 14>
  %194 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %190, <4 x i32> %193) #6
  %195 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %186, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %196 = add <4 x i32> %195, <i32 8192, i32 8192, i32 8192, i32 8192>
  %197 = ashr <4 x i32> %196, <i32 14, i32 14, i32 14, i32 14>
  %198 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %187, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %199 = add <4 x i32> %198, <i32 8192, i32 8192, i32 8192, i32 8192>
  %200 = ashr <4 x i32> %199, <i32 14, i32 14, i32 14, i32 14>
  %201 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %197, <4 x i32> %200) #6
  %202 = shufflevector <8 x i16> %137, <8 x i16> %140, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %203 = shufflevector <8 x i16> %137, <8 x i16> %140, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %204 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %202, <8 x i16> <i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270>) #6
  %205 = add <4 x i32> %204, <i32 8192, i32 8192, i32 8192, i32 8192>
  %206 = ashr <4 x i32> %205, <i32 14, i32 14, i32 14, i32 14>
  %207 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %203, <8 x i16> <i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270>) #6
  %208 = add <4 x i32> %207, <i32 8192, i32 8192, i32 8192, i32 8192>
  %209 = ashr <4 x i32> %208, <i32 14, i32 14, i32 14, i32 14>
  %210 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %206, <4 x i32> %209) #6
  %211 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %202, <8 x i16> <i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137>) #6
  %212 = add <4 x i32> %211, <i32 8192, i32 8192, i32 8192, i32 8192>
  %213 = ashr <4 x i32> %212, <i32 14, i32 14, i32 14, i32 14>
  %214 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %203, <8 x i16> <i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137>) #6
  %215 = add <4 x i32> %214, <i32 8192, i32 8192, i32 8192, i32 8192>
  %216 = ashr <4 x i32> %215, <i32 14, i32 14, i32 14, i32 14>
  %217 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %213, <4 x i32> %216) #6
  %218 = sub <8 x i16> %105, %127
  %219 = add <8 x i16> %127, %105
  %220 = sub <8 x i16> %112, %134
  %221 = add <8 x i16> %134, %112
  %222 = add <8 x i16> %185, %163
  %223 = add <8 x i16> %178, %156
  %224 = sub <8 x i16> %156, %178
  %225 = sub <8 x i16> %163, %185
  %226 = shufflevector <8 x i16> %220, <8 x i16> %218, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %227 = shufflevector <8 x i16> %220, <8 x i16> %218, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %228 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %226, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %229 = add <4 x i32> %228, <i32 8192, i32 8192, i32 8192, i32 8192>
  %230 = ashr <4 x i32> %229, <i32 14, i32 14, i32 14, i32 14>
  %231 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %227, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %232 = add <4 x i32> %231, <i32 8192, i32 8192, i32 8192, i32 8192>
  %233 = ashr <4 x i32> %232, <i32 14, i32 14, i32 14, i32 14>
  %234 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %230, <4 x i32> %233) #6
  %235 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %226, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %236 = add <4 x i32> %235, <i32 8192, i32 8192, i32 8192, i32 8192>
  %237 = ashr <4 x i32> %236, <i32 14, i32 14, i32 14, i32 14>
  %238 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %227, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %239 = add <4 x i32> %238, <i32 8192, i32 8192, i32 8192, i32 8192>
  %240 = ashr <4 x i32> %239, <i32 14, i32 14, i32 14, i32 14>
  %241 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %237, <4 x i32> %240) #6
  %242 = add <8 x i16> %138, %135
  %243 = add <8 x i16> %217, %194
  %244 = sub <8 x i16> %194, %217
  %245 = sub <8 x i16> %135, %138
  %246 = sub <8 x i16> %142, %139
  %247 = sub <8 x i16> %201, %210
  %248 = add <8 x i16> %210, %201
  %249 = add <8 x i16> %139, %142
  %250 = add <8 x i16> %222, %221
  %251 = add <8 x i16> %241, %223
  %252 = add <8 x i16> %234, %224
  %253 = add <8 x i16> %225, %219
  %254 = sub <8 x i16> %225, %219
  %255 = sub <8 x i16> %224, %234
  %256 = sub <8 x i16> %223, %241
  %257 = sub <8 x i16> %222, %221
  %258 = shufflevector <8 x i16> %247, <8 x i16> %244, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %259 = shufflevector <8 x i16> %247, <8 x i16> %244, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %260 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %258, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %261 = add <4 x i32> %260, <i32 8192, i32 8192, i32 8192, i32 8192>
  %262 = ashr <4 x i32> %261, <i32 14, i32 14, i32 14, i32 14>
  %263 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %259, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %264 = add <4 x i32> %263, <i32 8192, i32 8192, i32 8192, i32 8192>
  %265 = ashr <4 x i32> %264, <i32 14, i32 14, i32 14, i32 14>
  %266 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %262, <4 x i32> %265) #6
  %267 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %258, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %268 = add <4 x i32> %267, <i32 8192, i32 8192, i32 8192, i32 8192>
  %269 = ashr <4 x i32> %268, <i32 14, i32 14, i32 14, i32 14>
  %270 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %259, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %271 = add <4 x i32> %270, <i32 8192, i32 8192, i32 8192, i32 8192>
  %272 = ashr <4 x i32> %271, <i32 14, i32 14, i32 14, i32 14>
  %273 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %269, <4 x i32> %272) #6
  %274 = shufflevector <8 x i16> %246, <8 x i16> %245, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %275 = shufflevector <8 x i16> %246, <8 x i16> %245, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %276 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %274, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %277 = add <4 x i32> %276, <i32 8192, i32 8192, i32 8192, i32 8192>
  %278 = ashr <4 x i32> %277, <i32 14, i32 14, i32 14, i32 14>
  %279 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %275, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %280 = add <4 x i32> %279, <i32 8192, i32 8192, i32 8192, i32 8192>
  %281 = ashr <4 x i32> %280, <i32 14, i32 14, i32 14, i32 14>
  %282 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %278, <4 x i32> %281) #6
  %283 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %274, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %284 = add <4 x i32> %283, <i32 8192, i32 8192, i32 8192, i32 8192>
  %285 = ashr <4 x i32> %284, <i32 14, i32 14, i32 14, i32 14>
  %286 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %275, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %287 = add <4 x i32> %286, <i32 8192, i32 8192, i32 8192, i32 8192>
  %288 = ashr <4 x i32> %287, <i32 14, i32 14, i32 14, i32 14>
  %289 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %285, <4 x i32> %288) #6
  %290 = add <8 x i16> %250, %249
  %291 = bitcast <2 x i64>* %1 to <8 x i16>*
  store <8 x i16> %290, <8 x i16>* %291, align 16
  %292 = add <8 x i16> %251, %248
  %293 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %294 = bitcast <2 x i64>* %293 to <8 x i16>*
  store <8 x i16> %292, <8 x i16>* %294, align 16
  %295 = add <8 x i16> %273, %252
  %296 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %297 = bitcast <2 x i64>* %296 to <8 x i16>*
  store <8 x i16> %295, <8 x i16>* %297, align 16
  %298 = add <8 x i16> %289, %253
  %299 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %300 = bitcast <2 x i64>* %299 to <8 x i16>*
  store <8 x i16> %298, <8 x i16>* %300, align 16
  %301 = add <8 x i16> %282, %254
  %302 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %303 = bitcast <2 x i64>* %302 to <8 x i16>*
  store <8 x i16> %301, <8 x i16>* %303, align 16
  %304 = add <8 x i16> %266, %255
  %305 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %306 = bitcast <2 x i64>* %305 to <8 x i16>*
  store <8 x i16> %304, <8 x i16>* %306, align 16
  %307 = add <8 x i16> %256, %243
  %308 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %309 = bitcast <2 x i64>* %308 to <8 x i16>*
  store <8 x i16> %307, <8 x i16>* %309, align 16
  %310 = add <8 x i16> %257, %242
  %311 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %312 = bitcast <2 x i64>* %311 to <8 x i16>*
  store <8 x i16> %310, <8 x i16>* %312, align 16
  %313 = sub <8 x i16> %257, %242
  %314 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 8
  %315 = bitcast <2 x i64>* %314 to <8 x i16>*
  store <8 x i16> %313, <8 x i16>* %315, align 16
  %316 = sub <8 x i16> %256, %243
  %317 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 9
  %318 = bitcast <2 x i64>* %317 to <8 x i16>*
  store <8 x i16> %316, <8 x i16>* %318, align 16
  %319 = sub <8 x i16> %255, %266
  %320 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 10
  %321 = bitcast <2 x i64>* %320 to <8 x i16>*
  store <8 x i16> %319, <8 x i16>* %321, align 16
  %322 = sub <8 x i16> %254, %282
  %323 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 11
  %324 = bitcast <2 x i64>* %323 to <8 x i16>*
  store <8 x i16> %322, <8 x i16>* %324, align 16
  %325 = sub <8 x i16> %253, %289
  %326 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 12
  %327 = bitcast <2 x i64>* %326 to <8 x i16>*
  store <8 x i16> %325, <8 x i16>* %327, align 16
  %328 = sub <8 x i16> %252, %273
  %329 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 13
  %330 = bitcast <2 x i64>* %329 to <8 x i16>*
  store <8 x i16> %328, <8 x i16>* %330, align 16
  %331 = sub <8 x i16> %251, %248
  %332 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 14
  %333 = bitcast <2 x i64>* %332 to <8 x i16>*
  store <8 x i16> %331, <8 x i16>* %333, align 16
  %334 = sub <8 x i16> %250, %249
  %335 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 15
  %336 = bitcast <2 x i64>* %335 to <8 x i16>*
  store <8 x i16> %334, <8 x i16>* %336, align 16
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @vpx_idct16x16_38_add_sse2(i32* nocapture readonly, i8* nocapture, i32) local_unnamed_addr #0 {
  %4 = alloca [16 x <2 x i64>], align 16
  %5 = alloca [16 x <2 x i64>], align 16
  %6 = alloca [16 x <2 x i64>], align 16
  %7 = bitcast [16 x <2 x i64>]* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %7) #6
  %8 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %4, i64 0, i64 8
  %9 = bitcast <2 x i64>* %8 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 128, i1 false)
  %10 = bitcast [16 x <2 x i64>]* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %10) #6
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %10, i8 -86, i64 256, i1 false)
  %11 = bitcast [16 x <2 x i64>]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %11) #6
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %11, i8 -86, i64 256, i1 false)
  %12 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %4, i64 0, i64 0
  %13 = bitcast i32* %0 to <4 x i32>*
  %14 = load <4 x i32>, <4 x i32>* %13, align 16
  %15 = getelementptr inbounds i32, i32* %0, i64 4
  %16 = bitcast i32* %15 to <4 x i32>*
  %17 = load <4 x i32>, <4 x i32>* %16, align 16
  %18 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %14, <4 x i32> %17) #6
  %19 = bitcast [16 x <2 x i64>]* %4 to <8 x i16>*
  store <8 x i16> %18, <8 x i16>* %19, align 16
  %20 = getelementptr inbounds i32, i32* %0, i64 16
  %21 = bitcast i32* %20 to <4 x i32>*
  %22 = load <4 x i32>, <4 x i32>* %21, align 16
  %23 = getelementptr inbounds i32, i32* %0, i64 20
  %24 = bitcast i32* %23 to <4 x i32>*
  %25 = load <4 x i32>, <4 x i32>* %24, align 16
  %26 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %22, <4 x i32> %25) #6
  %27 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %4, i64 0, i64 1
  %28 = getelementptr inbounds i32, i32* %0, i64 32
  %29 = bitcast i32* %28 to <4 x i32>*
  %30 = load <4 x i32>, <4 x i32>* %29, align 16
  %31 = getelementptr inbounds i32, i32* %0, i64 36
  %32 = bitcast i32* %31 to <4 x i32>*
  %33 = load <4 x i32>, <4 x i32>* %32, align 16
  %34 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %30, <4 x i32> %33) #6
  %35 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %4, i64 0, i64 2
  %36 = getelementptr inbounds i32, i32* %0, i64 48
  %37 = bitcast i32* %36 to <4 x i32>*
  %38 = load <4 x i32>, <4 x i32>* %37, align 16
  %39 = getelementptr inbounds i32, i32* %0, i64 52
  %40 = bitcast i32* %39 to <4 x i32>*
  %41 = load <4 x i32>, <4 x i32>* %40, align 16
  %42 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %38, <4 x i32> %41) #6
  %43 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %4, i64 0, i64 3
  %44 = getelementptr inbounds i32, i32* %0, i64 64
  %45 = bitcast i32* %44 to <4 x i32>*
  %46 = load <4 x i32>, <4 x i32>* %45, align 16
  %47 = getelementptr inbounds i32, i32* %0, i64 68
  %48 = bitcast i32* %47 to <4 x i32>*
  %49 = load <4 x i32>, <4 x i32>* %48, align 16
  %50 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %46, <4 x i32> %49) #6
  %51 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %4, i64 0, i64 4
  %52 = getelementptr inbounds i32, i32* %0, i64 80
  %53 = bitcast i32* %52 to <4 x i32>*
  %54 = load <4 x i32>, <4 x i32>* %53, align 16
  %55 = getelementptr inbounds i32, i32* %0, i64 84
  %56 = bitcast i32* %55 to <4 x i32>*
  %57 = load <4 x i32>, <4 x i32>* %56, align 16
  %58 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %54, <4 x i32> %57) #6
  %59 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %4, i64 0, i64 5
  %60 = getelementptr inbounds i32, i32* %0, i64 96
  %61 = bitcast i32* %60 to <4 x i32>*
  %62 = load <4 x i32>, <4 x i32>* %61, align 16
  %63 = getelementptr inbounds i32, i32* %0, i64 100
  %64 = bitcast i32* %63 to <4 x i32>*
  %65 = load <4 x i32>, <4 x i32>* %64, align 16
  %66 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %62, <4 x i32> %65) #6
  %67 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %4, i64 0, i64 6
  %68 = getelementptr inbounds i32, i32* %0, i64 112
  %69 = bitcast i32* %68 to <4 x i32>*
  %70 = load <4 x i32>, <4 x i32>* %69, align 16
  %71 = getelementptr inbounds i32, i32* %0, i64 116
  %72 = bitcast i32* %71 to <4 x i32>*
  %73 = load <4 x i32>, <4 x i32>* %72, align 16
  %74 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %70, <4 x i32> %73) #6
  %75 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %4, i64 0, i64 7
  %76 = shufflevector <8 x i16> %18, <8 x i16> %26, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %77 = shufflevector <8 x i16> %34, <8 x i16> %42, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %78 = shufflevector <8 x i16> %50, <8 x i16> %58, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %79 = shufflevector <8 x i16> %66, <8 x i16> %74, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %80 = shufflevector <8 x i16> %18, <8 x i16> %26, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %81 = shufflevector <8 x i16> %34, <8 x i16> %42, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %82 = shufflevector <8 x i16> %50, <8 x i16> %58, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %83 = shufflevector <8 x i16> %66, <8 x i16> %74, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %84 = bitcast <8 x i16> %76 to <4 x i32>
  %85 = bitcast <8 x i16> %77 to <4 x i32>
  %86 = shufflevector <4 x i32> %84, <4 x i32> %85, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %87 = bitcast <4 x i32> %86 to <2 x i64>
  %88 = bitcast <8 x i16> %78 to <4 x i32>
  %89 = bitcast <8 x i16> %79 to <4 x i32>
  %90 = shufflevector <4 x i32> %88, <4 x i32> %89, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %91 = bitcast <4 x i32> %90 to <2 x i64>
  %92 = bitcast <8 x i16> %80 to <4 x i32>
  %93 = bitcast <8 x i16> %81 to <4 x i32>
  %94 = shufflevector <4 x i32> %92, <4 x i32> %93, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %95 = bitcast <4 x i32> %94 to <2 x i64>
  %96 = bitcast <8 x i16> %82 to <4 x i32>
  %97 = bitcast <8 x i16> %83 to <4 x i32>
  %98 = shufflevector <4 x i32> %96, <4 x i32> %97, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %99 = bitcast <4 x i32> %98 to <2 x i64>
  %100 = shufflevector <4 x i32> %84, <4 x i32> %85, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %101 = bitcast <4 x i32> %100 to <2 x i64>
  %102 = shufflevector <4 x i32> %88, <4 x i32> %89, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %103 = bitcast <4 x i32> %102 to <2 x i64>
  %104 = shufflevector <4 x i32> %92, <4 x i32> %93, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %105 = bitcast <4 x i32> %104 to <2 x i64>
  %106 = shufflevector <4 x i32> %96, <4 x i32> %97, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %107 = bitcast <4 x i32> %106 to <2 x i64>
  %108 = shufflevector <2 x i64> %87, <2 x i64> %91, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %108, <2 x i64>* %12, align 16
  %109 = shufflevector <2 x i64> %87, <2 x i64> %91, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %109, <2 x i64>* %27, align 16
  %110 = shufflevector <2 x i64> %101, <2 x i64> %103, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %110, <2 x i64>* %35, align 16
  %111 = shufflevector <2 x i64> %101, <2 x i64> %103, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %111, <2 x i64>* %43, align 16
  %112 = shufflevector <2 x i64> %95, <2 x i64> %99, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %112, <2 x i64>* %51, align 16
  %113 = shufflevector <2 x i64> %95, <2 x i64> %99, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %113, <2 x i64>* %59, align 16
  %114 = shufflevector <2 x i64> %105, <2 x i64> %107, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %114, <2 x i64>* %67, align 16
  %115 = shufflevector <2 x i64> %105, <2 x i64> %107, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %115, <2 x i64>* %75, align 16
  %116 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %4, i64 0, i64 8
  %117 = bitcast <2 x i64>* %116 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 16 %117, i8 0, i64 128, i1 false)
  %118 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 0
  call fastcc void @idct16_8col(<2 x i64>* nonnull %12, <2 x i64>* nonnull %118)
  %119 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 0
  %120 = sext i32 %2 to i64
  br label %121

121:                                              ; preds = %3, %209
  %122 = phi i64 [ 0, %3 ], [ %211, %209 ]
  %123 = phi i8* [ %1, %3 ], [ %210, %209 ]
  %124 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %122
  %125 = bitcast <2 x i64>* %124 to <8 x i16>*
  %126 = load <8 x i16>, <8 x i16>* %125, align 16
  %127 = getelementptr inbounds <2 x i64>, <2 x i64>* %124, i64 1
  %128 = bitcast <2 x i64>* %127 to <8 x i16>*
  %129 = load <8 x i16>, <8 x i16>* %128, align 16
  %130 = shufflevector <8 x i16> %126, <8 x i16> %129, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %131 = getelementptr inbounds <2 x i64>, <2 x i64>* %124, i64 2
  %132 = bitcast <2 x i64>* %131 to <8 x i16>*
  %133 = load <8 x i16>, <8 x i16>* %132, align 16
  %134 = getelementptr inbounds <2 x i64>, <2 x i64>* %124, i64 3
  %135 = bitcast <2 x i64>* %134 to <8 x i16>*
  %136 = load <8 x i16>, <8 x i16>* %135, align 16
  %137 = shufflevector <8 x i16> %133, <8 x i16> %136, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %138 = getelementptr inbounds <2 x i64>, <2 x i64>* %124, i64 4
  %139 = bitcast <2 x i64>* %138 to <8 x i16>*
  %140 = load <8 x i16>, <8 x i16>* %139, align 16
  %141 = getelementptr inbounds <2 x i64>, <2 x i64>* %124, i64 5
  %142 = bitcast <2 x i64>* %141 to <8 x i16>*
  %143 = load <8 x i16>, <8 x i16>* %142, align 16
  %144 = shufflevector <8 x i16> %140, <8 x i16> %143, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %145 = getelementptr inbounds <2 x i64>, <2 x i64>* %124, i64 6
  %146 = bitcast <2 x i64>* %145 to <8 x i16>*
  %147 = load <8 x i16>, <8 x i16>* %146, align 16
  %148 = getelementptr inbounds <2 x i64>, <2 x i64>* %124, i64 7
  %149 = bitcast <2 x i64>* %148 to <8 x i16>*
  %150 = load <8 x i16>, <8 x i16>* %149, align 16
  %151 = shufflevector <8 x i16> %147, <8 x i16> %150, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %152 = shufflevector <8 x i16> %126, <8 x i16> %129, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %153 = shufflevector <8 x i16> %133, <8 x i16> %136, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %154 = shufflevector <8 x i16> %140, <8 x i16> %143, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %155 = shufflevector <8 x i16> %147, <8 x i16> %150, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %156 = bitcast <8 x i16> %130 to <4 x i32>
  %157 = bitcast <8 x i16> %137 to <4 x i32>
  %158 = shufflevector <4 x i32> %156, <4 x i32> %157, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %159 = bitcast <4 x i32> %158 to <2 x i64>
  %160 = bitcast <8 x i16> %144 to <4 x i32>
  %161 = bitcast <8 x i16> %151 to <4 x i32>
  %162 = shufflevector <4 x i32> %160, <4 x i32> %161, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %163 = bitcast <4 x i32> %162 to <2 x i64>
  %164 = bitcast <8 x i16> %152 to <4 x i32>
  %165 = bitcast <8 x i16> %153 to <4 x i32>
  %166 = shufflevector <4 x i32> %164, <4 x i32> %165, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %167 = bitcast <4 x i32> %166 to <2 x i64>
  %168 = bitcast <8 x i16> %154 to <4 x i32>
  %169 = bitcast <8 x i16> %155 to <4 x i32>
  %170 = shufflevector <4 x i32> %168, <4 x i32> %169, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %171 = bitcast <4 x i32> %170 to <2 x i64>
  %172 = shufflevector <4 x i32> %156, <4 x i32> %157, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %173 = bitcast <4 x i32> %172 to <2 x i64>
  %174 = shufflevector <4 x i32> %160, <4 x i32> %161, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %175 = bitcast <4 x i32> %174 to <2 x i64>
  %176 = shufflevector <4 x i32> %164, <4 x i32> %165, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %177 = bitcast <4 x i32> %176 to <2 x i64>
  %178 = shufflevector <4 x i32> %168, <4 x i32> %169, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %179 = bitcast <4 x i32> %178 to <2 x i64>
  %180 = shufflevector <2 x i64> %159, <2 x i64> %163, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %180, <2 x i64>* %12, align 16
  %181 = shufflevector <2 x i64> %159, <2 x i64> %163, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %181, <2 x i64>* %27, align 16
  %182 = shufflevector <2 x i64> %173, <2 x i64> %175, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %182, <2 x i64>* %35, align 16
  %183 = shufflevector <2 x i64> %173, <2 x i64> %175, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %183, <2 x i64>* %43, align 16
  %184 = shufflevector <2 x i64> %167, <2 x i64> %171, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %184, <2 x i64>* %51, align 16
  %185 = shufflevector <2 x i64> %167, <2 x i64> %171, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %185, <2 x i64>* %59, align 16
  %186 = shufflevector <2 x i64> %177, <2 x i64> %179, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %186, <2 x i64>* %67, align 16
  %187 = shufflevector <2 x i64> %177, <2 x i64> %179, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %187, <2 x i64>* %75, align 16
  call fastcc void @idct16_8col(<2 x i64>* nonnull %12, <2 x i64>* nonnull %119)
  br label %188

188:                                              ; preds = %188, %121
  %189 = phi i64 [ 0, %121 ], [ %207, %188 ]
  %190 = mul nsw i64 %189, %120
  %191 = getelementptr inbounds i8, i8* %123, i64 %190
  %192 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 %189
  %193 = bitcast <2 x i64>* %192 to <8 x i16>*
  %194 = load <8 x i16>, <8 x i16>* %193, align 16
  %195 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %194, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #6
  %196 = ashr <8 x i16> %195, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %197 = bitcast i8* %191 to i64*
  %198 = load i64, i64* %197, align 1
  %199 = insertelement <2 x i64> undef, i64 %198, i32 0
  %200 = bitcast <2 x i64> %199 to <16 x i8>
  %201 = shufflevector <16 x i8> %200, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %202 = bitcast <16 x i8> %201 to <8 x i16>
  %203 = add <8 x i16> %196, %202
  %204 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %203, <8 x i16> undef) #6
  %205 = bitcast <16 x i8> %204 to <2 x i64>
  %206 = extractelement <2 x i64> %205, i32 0
  store i64 %206, i64* %197, align 1
  %207 = add nuw nsw i64 %189, 1
  %208 = icmp eq i64 %207, 16
  br i1 %208, label %209, label %188

209:                                              ; preds = %188
  %210 = getelementptr inbounds i8, i8* %123, i64 8
  %211 = add nuw nsw i64 %122, 8
  %212 = icmp ult i64 %211, 16
  br i1 %212, label %121, label %213

213:                                              ; preds = %209
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %11) #6
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %10) #6
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %7) #6
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @vpx_idct16x16_10_add_sse2(i32* nocapture readonly, i8* nocapture, i32) local_unnamed_addr #0 {
  %4 = alloca [16 x <2 x i64>], align 16
  %5 = alloca [16 x <2 x i64>], align 16
  %6 = bitcast [16 x <2 x i64>]* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %6) #6
  %7 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %4, i64 0, i64 4
  %8 = bitcast <2 x i64>* %7 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %8, i8 -86, i64 192, i1 false)
  %9 = bitcast [16 x <2 x i64>]* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %9) #6
  %10 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 2
  %11 = bitcast <2 x i64>* %10 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %11, i8 -86, i64 224, i1 false)
  %12 = bitcast i32* %0 to <4 x i32>*
  %13 = load <4 x i32>, <4 x i32>* %12, align 16
  %14 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %13, <4 x i32> zeroinitializer) #6
  %15 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %4, i64 0, i64 0
  %16 = bitcast [16 x <2 x i64>]* %4 to <8 x i16>*
  store <8 x i16> %14, <8 x i16>* %16, align 16
  %17 = getelementptr inbounds i32, i32* %0, i64 16
  %18 = bitcast i32* %17 to <4 x i32>*
  %19 = load <4 x i32>, <4 x i32>* %18, align 16
  %20 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %19, <4 x i32> zeroinitializer) #6
  %21 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %4, i64 0, i64 1
  %22 = bitcast <2 x i64>* %21 to <8 x i16>*
  store <8 x i16> %20, <8 x i16>* %22, align 16
  %23 = getelementptr inbounds i32, i32* %0, i64 32
  %24 = bitcast i32* %23 to <4 x i32>*
  %25 = load <4 x i32>, <4 x i32>* %24, align 16
  %26 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %25, <4 x i32> zeroinitializer) #6
  %27 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %4, i64 0, i64 2
  %28 = bitcast <2 x i64>* %27 to <8 x i16>*
  store <8 x i16> %26, <8 x i16>* %28, align 16
  %29 = getelementptr inbounds i32, i32* %0, i64 48
  %30 = bitcast i32* %29 to <4 x i32>*
  %31 = load <4 x i32>, <4 x i32>* %30, align 16
  %32 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %31, <4 x i32> zeroinitializer) #6
  %33 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %4, i64 0, i64 3
  %34 = bitcast <2 x i64>* %33 to <8 x i16>*
  store <8 x i16> %32, <8 x i16>* %34, align 16
  %35 = shufflevector <8 x i16> %14, <8 x i16> %20, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %36 = shufflevector <8 x i16> %26, <8 x i16> %32, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %37 = bitcast <8 x i16> %35 to <4 x i32>
  %38 = bitcast <8 x i16> %36 to <4 x i32>
  %39 = shufflevector <4 x i32> %37, <4 x i32> %38, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %40 = bitcast [16 x <2 x i64>]* %5 to <4 x i32>*
  store <4 x i32> %39, <4 x i32>* %40, align 16
  %41 = shufflevector <4 x i32> %37, <4 x i32> %38, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %42 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 1
  %43 = bitcast <2 x i64>* %42 to <4 x i32>*
  store <4 x i32> %41, <4 x i32>* %43, align 16
  %44 = bitcast <4 x i32> %39 to <8 x i16>
  %45 = shufflevector <8 x i16> %44, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %46 = bitcast <4 x i32> %41 to <8 x i16>
  %47 = shufflevector <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i16> %46, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %48 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305>, <8 x i16> %45) #6
  %49 = add <4 x i32> %48, <i32 8192, i32 8192, i32 8192, i32 8192>
  %50 = ashr <4 x i32> %49, <i32 14, i32 14, i32 14, i32 14>
  %51 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606>, <8 x i16> %45) #6
  %52 = add <4 x i32> %51, <i32 8192, i32 8192, i32 8192, i32 8192>
  %53 = ashr <4 x i32> %52, <i32 14, i32 14, i32 14, i32 14>
  %54 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %50, <4 x i32> %53) #6
  %55 = bitcast <8 x i16> %54 to <2 x i64>
  %56 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756>, <8 x i16> %47) #6
  %57 = add <4 x i32> %56, <i32 8192, i32 8192, i32 8192, i32 8192>
  %58 = ashr <4 x i32> %57, <i32 14, i32 14, i32 14, i32 14>
  %59 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679>, <8 x i16> %47) #6
  %60 = add <4 x i32> %59, <i32 8192, i32 8192, i32 8192, i32 8192>
  %61 = ashr <4 x i32> %60, <i32 14, i32 14, i32 14, i32 14>
  %62 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %58, <4 x i32> %61) #6
  %63 = bitcast <8 x i16> %62 to <2 x i64>
  %64 = shufflevector <8 x i16> %46, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %65 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>, <8 x i16> %64) #6
  %66 = add <4 x i32> %65, <i32 8192, i32 8192, i32 8192, i32 8192>
  %67 = ashr <4 x i32> %66, <i32 14, i32 14, i32 14, i32 14>
  %68 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>, <8 x i16> %64) #6
  %69 = add <4 x i32> %68, <i32 8192, i32 8192, i32 8192, i32 8192>
  %70 = ashr <4 x i32> %69, <i32 14, i32 14, i32 14, i32 14>
  %71 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %67, <4 x i32> %70) #6
  %72 = bitcast <8 x i16> %71 to <2 x i64>
  %73 = shufflevector <2 x i64> %63, <2 x i64> undef, <2 x i32> <i32 1, i32 undef>
  %74 = shufflevector <2 x i64> %55, <2 x i64> undef, <2 x i32> <i32 1, i32 undef>
  %75 = shufflevector <8 x i16> %44, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %76 = bitcast <2 x i64> %74 to <8 x i16>
  %77 = shufflevector <8 x i16> %54, <8 x i16> %76, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %78 = bitcast <2 x i64> %73 to <8 x i16>
  %79 = shufflevector <8 x i16> %62, <8 x i16> %78, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %80 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %75, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %81 = add <4 x i32> %80, <i32 8192, i32 8192, i32 8192, i32 8192>
  %82 = ashr <4 x i32> %81, <i32 14, i32 14, i32 14, i32 14>
  %83 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %82, <4 x i32> %82) #6
  %84 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270>, <8 x i16> %77) #6
  %85 = add <4 x i32> %84, <i32 8192, i32 8192, i32 8192, i32 8192>
  %86 = ashr <4 x i32> %85, <i32 14, i32 14, i32 14, i32 14>
  %87 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137>, <8 x i16> %77) #6
  %88 = add <4 x i32> %87, <i32 8192, i32 8192, i32 8192, i32 8192>
  %89 = ashr <4 x i32> %88, <i32 14, i32 14, i32 14, i32 14>
  %90 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %86, <4 x i32> %89) #6
  %91 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137>, <8 x i16> %79) #6
  %92 = add <4 x i32> %91, <i32 8192, i32 8192, i32 8192, i32 8192>
  %93 = ashr <4 x i32> %92, <i32 14, i32 14, i32 14, i32 14>
  %94 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270>, <8 x i16> %79) #6
  %95 = add <4 x i32> %94, <i32 8192, i32 8192, i32 8192, i32 8192>
  %96 = ashr <4 x i32> %95, <i32 14, i32 14, i32 14, i32 14>
  %97 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %93, <4 x i32> %96) #6
  %98 = shufflevector <2 x i64> %72, <2 x i64> undef, <2 x i32> <i32 1, i32 undef>
  %99 = bitcast <2 x i64> %98 to <8 x i16>
  %100 = shufflevector <8 x i16> %71, <8 x i16> %99, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %101 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>, <8 x i16> %100) #6
  %102 = add <4 x i32> %101, <i32 8192, i32 8192, i32 8192, i32 8192>
  %103 = ashr <4 x i32> %102, <i32 14, i32 14, i32 14, i32 14>
  %104 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585>, <8 x i16> %100) #6
  %105 = add <4 x i32> %104, <i32 8192, i32 8192, i32 8192, i32 8192>
  %106 = ashr <4 x i32> %105, <i32 14, i32 14, i32 14, i32 14>
  %107 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %103, <4 x i32> %106) #6
  %108 = add <8 x i16> %62, %54
  %109 = bitcast <8 x i16> %108 to <2 x i64>
  %110 = add <8 x i16> %97, %90
  %111 = bitcast <8 x i16> %110 to <2 x i64>
  %112 = sub <8 x i16> %90, %97
  %113 = bitcast <8 x i16> %112 to <2 x i64>
  %114 = sub <8 x i16> %54, %62
  %115 = bitcast <8 x i16> %114 to <2 x i64>
  %116 = shufflevector <2 x i64> %115, <2 x i64> undef, <2 x i32> <i32 1, i32 undef>
  %117 = shufflevector <2 x i64> %113, <2 x i64> undef, <2 x i32> <i32 1, i32 undef>
  %118 = shufflevector <2 x i64> %111, <2 x i64> <i64 undef, i64 0>, <2 x i32> <i32 1, i32 3>
  %119 = shufflevector <2 x i64> %109, <2 x i64> <i64 undef, i64 0>, <2 x i32> <i32 1, i32 3>
  %120 = bitcast <2 x i64> %117 to <8 x i16>
  %121 = shufflevector <8 x i16> %112, <8 x i16> %120, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %122 = bitcast <2 x i64> %116 to <8 x i16>
  %123 = shufflevector <8 x i16> %114, <8 x i16> %122, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %124 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585>, <8 x i16> %121) #6
  %125 = add <4 x i32> %124, <i32 8192, i32 8192, i32 8192, i32 8192>
  %126 = ashr <4 x i32> %125, <i32 14, i32 14, i32 14, i32 14>
  %127 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>, <8 x i16> %121) #6
  %128 = add <4 x i32> %127, <i32 8192, i32 8192, i32 8192, i32 8192>
  %129 = ashr <4 x i32> %128, <i32 14, i32 14, i32 14, i32 14>
  %130 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %126, <4 x i32> %129) #6
  %131 = bitcast <8 x i16> %130 to <2 x i64>
  %132 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585>, <8 x i16> %123) #6
  %133 = add <4 x i32> %132, <i32 8192, i32 8192, i32 8192, i32 8192>
  %134 = ashr <4 x i32> %133, <i32 14, i32 14, i32 14, i32 14>
  %135 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>, <8 x i16> %123) #6
  %136 = add <4 x i32> %135, <i32 8192, i32 8192, i32 8192, i32 8192>
  %137 = ashr <4 x i32> %136, <i32 14, i32 14, i32 14, i32 14>
  %138 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %134, <4 x i32> %137) #6
  %139 = bitcast <8 x i16> %138 to <2 x i64>
  %140 = shufflevector <2 x i64> %131, <2 x i64> <i64 undef, i64 0>, <2 x i32> <i32 1, i32 3>
  %141 = shufflevector <2 x i64> %139, <2 x i64> <i64 undef, i64 0>, <2 x i32> <i32 1, i32 3>
  %142 = add <8 x i16> %83, %71
  %143 = bitcast <8 x i16> %142 to <2 x i64>
  %144 = add <8 x i16> %107, %83
  %145 = bitcast <8 x i16> %144 to <2 x i64>
  %146 = sub <8 x i16> %83, %107
  %147 = bitcast <8 x i16> %146 to <2 x i64>
  %148 = sub <8 x i16> %83, %71
  %149 = bitcast <8 x i16> %148 to <2 x i64>
  %150 = shufflevector <2 x i64> %143, <2 x i64> <i64 undef, i64 0>, <2 x i32> <i32 1, i32 3>
  %151 = shufflevector <2 x i64> %145, <2 x i64> <i64 undef, i64 0>, <2 x i32> <i32 1, i32 3>
  %152 = shufflevector <2 x i64> %147, <2 x i64> <i64 undef, i64 0>, <2 x i32> <i32 1, i32 3>
  %153 = shufflevector <2 x i64> %149, <2 x i64> <i64 undef, i64 0>, <2 x i32> <i32 1, i32 3>
  %154 = bitcast <2 x i64> %150 to <8 x i16>
  %155 = bitcast <2 x i64> %119 to <8 x i16>
  %156 = add <8 x i16> %154, %155
  %157 = bitcast [16 x <2 x i64>]* %5 to <8 x i16>*
  store <8 x i16> %156, <8 x i16>* %157, align 16
  %158 = bitcast <2 x i64> %118 to <8 x i16>
  %159 = add <8 x i16> %144, %158
  %160 = bitcast <2 x i64>* %42 to <8 x i16>*
  store <8 x i16> %159, <8 x i16>* %160, align 16
  %161 = bitcast <2 x i64> %151 to <8 x i16>
  %162 = bitcast <2 x i64> %140 to <8 x i16>
  %163 = add <8 x i16> %162, %161
  %164 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 2
  %165 = bitcast <2 x i64>* %164 to <8 x i16>*
  store <8 x i16> %163, <8 x i16>* %165, align 16
  %166 = bitcast <2 x i64> %141 to <8 x i16>
  %167 = add <8 x i16> %142, %166
  %168 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 3
  %169 = bitcast <2 x i64>* %168 to <8 x i16>*
  store <8 x i16> %167, <8 x i16>* %169, align 16
  %170 = add <8 x i16> %138, %148
  %171 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 4
  %172 = bitcast <2 x i64>* %171 to <8 x i16>*
  store <8 x i16> %170, <8 x i16>* %172, align 16
  %173 = bitcast <2 x i64> %152 to <8 x i16>
  %174 = add <8 x i16> %130, %173
  %175 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 5
  %176 = bitcast <2 x i64>* %175 to <8 x i16>*
  store <8 x i16> %174, <8 x i16>* %176, align 16
  %177 = add <8 x i16> %146, %110
  %178 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 6
  %179 = bitcast <2 x i64>* %178 to <8 x i16>*
  store <8 x i16> %177, <8 x i16>* %179, align 16
  %180 = bitcast <2 x i64> %153 to <8 x i16>
  %181 = add <8 x i16> %108, %180
  %182 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 7
  %183 = bitcast <2 x i64>* %182 to <8 x i16>*
  store <8 x i16> %181, <8 x i16>* %183, align 16
  %184 = sub <8 x i16> %180, %108
  %185 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 8
  %186 = bitcast <2 x i64>* %185 to <8 x i16>*
  store <8 x i16> %184, <8 x i16>* %186, align 16
  %187 = sub <8 x i16> %146, %110
  %188 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 9
  %189 = bitcast <2 x i64>* %188 to <8 x i16>*
  store <8 x i16> %187, <8 x i16>* %189, align 16
  %190 = sub <8 x i16> %173, %130
  %191 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 10
  %192 = bitcast <2 x i64>* %191 to <8 x i16>*
  store <8 x i16> %190, <8 x i16>* %192, align 16
  %193 = sub <8 x i16> %148, %138
  %194 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 11
  %195 = bitcast <2 x i64>* %194 to <8 x i16>*
  store <8 x i16> %193, <8 x i16>* %195, align 16
  %196 = sub <8 x i16> %142, %166
  %197 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 12
  %198 = bitcast <2 x i64>* %197 to <8 x i16>*
  store <8 x i16> %196, <8 x i16>* %198, align 16
  %199 = sub <8 x i16> %161, %162
  %200 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 13
  %201 = bitcast <2 x i64>* %200 to <8 x i16>*
  store <8 x i16> %199, <8 x i16>* %201, align 16
  %202 = sub <8 x i16> %144, %158
  %203 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 14
  %204 = bitcast <2 x i64>* %203 to <8 x i16>*
  store <8 x i16> %202, <8 x i16>* %204, align 16
  %205 = sub <8 x i16> %154, %155
  %206 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 15
  %207 = bitcast <2 x i64>* %206 to <8 x i16>*
  store <8 x i16> %205, <8 x i16>* %207, align 16
  %208 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %4, i64 0, i64 4
  %209 = bitcast <2 x i64>* %208 to <8 x i16>*
  %210 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %4, i64 0, i64 5
  %211 = bitcast <2 x i64>* %210 to <8 x i16>*
  %212 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %4, i64 0, i64 6
  %213 = bitcast <2 x i64>* %212 to <8 x i16>*
  %214 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %4, i64 0, i64 7
  %215 = bitcast <2 x i64>* %214 to <8 x i16>*
  %216 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %4, i64 0, i64 8
  %217 = bitcast <2 x i64>* %216 to <8 x i16>*
  %218 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %4, i64 0, i64 9
  %219 = bitcast <2 x i64>* %218 to <8 x i16>*
  %220 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %4, i64 0, i64 10
  %221 = bitcast <2 x i64>* %220 to <8 x i16>*
  %222 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %4, i64 0, i64 11
  %223 = bitcast <2 x i64>* %222 to <8 x i16>*
  %224 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %4, i64 0, i64 12
  %225 = bitcast <2 x i64>* %224 to <8 x i16>*
  %226 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %4, i64 0, i64 13
  %227 = bitcast <2 x i64>* %226 to <8 x i16>*
  %228 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %4, i64 0, i64 14
  %229 = bitcast <2 x i64>* %228 to <8 x i16>*
  %230 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %4, i64 0, i64 15
  %231 = bitcast <2 x i64>* %230 to <8 x i16>*
  %232 = sext i32 %2 to i64
  br label %233

233:                                              ; preds = %3, %474
  %234 = phi i64 [ 0, %3 ], [ %476, %474 ]
  %235 = phi i8* [ %1, %3 ], [ %475, %474 ]
  %236 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %5, i64 0, i64 %234
  %237 = bitcast <2 x i64>* %236 to <8 x i16>*
  %238 = load <8 x i16>, <8 x i16>* %237, align 16
  %239 = getelementptr inbounds <2 x i64>, <2 x i64>* %236, i64 1
  %240 = bitcast <2 x i64>* %239 to <8 x i16>*
  %241 = load <8 x i16>, <8 x i16>* %240, align 16
  %242 = shufflevector <8 x i16> %238, <8 x i16> %241, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %243 = getelementptr inbounds <2 x i64>, <2 x i64>* %236, i64 2
  %244 = bitcast <2 x i64>* %243 to <8 x i16>*
  %245 = load <8 x i16>, <8 x i16>* %244, align 16
  %246 = getelementptr inbounds <2 x i64>, <2 x i64>* %236, i64 3
  %247 = bitcast <2 x i64>* %246 to <8 x i16>*
  %248 = load <8 x i16>, <8 x i16>* %247, align 16
  %249 = shufflevector <8 x i16> %245, <8 x i16> %248, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %250 = getelementptr inbounds <2 x i64>, <2 x i64>* %236, i64 4
  %251 = bitcast <2 x i64>* %250 to <8 x i16>*
  %252 = load <8 x i16>, <8 x i16>* %251, align 16
  %253 = getelementptr inbounds <2 x i64>, <2 x i64>* %236, i64 5
  %254 = bitcast <2 x i64>* %253 to <8 x i16>*
  %255 = load <8 x i16>, <8 x i16>* %254, align 16
  %256 = shufflevector <8 x i16> %252, <8 x i16> %255, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %257 = getelementptr inbounds <2 x i64>, <2 x i64>* %236, i64 6
  %258 = bitcast <2 x i64>* %257 to <8 x i16>*
  %259 = load <8 x i16>, <8 x i16>* %258, align 16
  %260 = getelementptr inbounds <2 x i64>, <2 x i64>* %236, i64 7
  %261 = bitcast <2 x i64>* %260 to <8 x i16>*
  %262 = load <8 x i16>, <8 x i16>* %261, align 16
  %263 = shufflevector <8 x i16> %259, <8 x i16> %262, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %264 = bitcast <8 x i16> %242 to <4 x i32>
  %265 = bitcast <8 x i16> %249 to <4 x i32>
  %266 = shufflevector <4 x i32> %264, <4 x i32> %265, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %267 = bitcast <4 x i32> %266 to <2 x i64>
  %268 = bitcast <8 x i16> %256 to <4 x i32>
  %269 = bitcast <8 x i16> %263 to <4 x i32>
  %270 = shufflevector <4 x i32> %268, <4 x i32> %269, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %271 = bitcast <4 x i32> %270 to <2 x i64>
  %272 = shufflevector <4 x i32> %264, <4 x i32> %265, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %273 = bitcast <4 x i32> %272 to <2 x i64>
  %274 = shufflevector <4 x i32> %268, <4 x i32> %269, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %275 = bitcast <4 x i32> %274 to <2 x i64>
  %276 = shufflevector <2 x i64> %267, <2 x i64> %271, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %276, <2 x i64>* %15, align 16
  %277 = shufflevector <2 x i64> %267, <2 x i64> %271, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %277, <2 x i64>* %21, align 16
  %278 = shufflevector <2 x i64> %273, <2 x i64> %275, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %278, <2 x i64>* %27, align 16
  %279 = shufflevector <2 x i64> %273, <2 x i64> %275, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %279, <2 x i64>* %33, align 16
  %280 = bitcast <2 x i64> %277 to <8 x i16>
  %281 = shufflevector <8 x i16> %280, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %282 = shufflevector <8 x i16> %280, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %283 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %281, <8 x i16> <i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305>) #6
  %284 = add <4 x i32> %283, <i32 8192, i32 8192, i32 8192, i32 8192>
  %285 = ashr <4 x i32> %284, <i32 14, i32 14, i32 14, i32 14>
  %286 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %282, <8 x i16> <i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305>) #6
  %287 = add <4 x i32> %286, <i32 8192, i32 8192, i32 8192, i32 8192>
  %288 = ashr <4 x i32> %287, <i32 14, i32 14, i32 14, i32 14>
  %289 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %285, <4 x i32> %288) #6
  %290 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %281, <8 x i16> <i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606>) #6
  %291 = add <4 x i32> %290, <i32 8192, i32 8192, i32 8192, i32 8192>
  %292 = ashr <4 x i32> %291, <i32 14, i32 14, i32 14, i32 14>
  %293 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %282, <8 x i16> <i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606>) #6
  %294 = add <4 x i32> %293, <i32 8192, i32 8192, i32 8192, i32 8192>
  %295 = ashr <4 x i32> %294, <i32 14, i32 14, i32 14, i32 14>
  %296 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %292, <4 x i32> %295) #6
  %297 = bitcast <2 x i64> %279 to <8 x i16>
  %298 = shufflevector <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i16> %297, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %299 = shufflevector <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i16> %297, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %300 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %298, <8 x i16> <i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756>) #6
  %301 = add <4 x i32> %300, <i32 8192, i32 8192, i32 8192, i32 8192>
  %302 = ashr <4 x i32> %301, <i32 14, i32 14, i32 14, i32 14>
  %303 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %299, <8 x i16> <i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756>) #6
  %304 = add <4 x i32> %303, <i32 8192, i32 8192, i32 8192, i32 8192>
  %305 = ashr <4 x i32> %304, <i32 14, i32 14, i32 14, i32 14>
  %306 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %302, <4 x i32> %305) #6
  %307 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %298, <8 x i16> <i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679>) #6
  %308 = add <4 x i32> %307, <i32 8192, i32 8192, i32 8192, i32 8192>
  %309 = ashr <4 x i32> %308, <i32 14, i32 14, i32 14, i32 14>
  %310 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %299, <8 x i16> <i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679>) #6
  %311 = add <4 x i32> %310, <i32 8192, i32 8192, i32 8192, i32 8192>
  %312 = ashr <4 x i32> %311, <i32 14, i32 14, i32 14, i32 14>
  %313 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %309, <4 x i32> %312) #6
  %314 = bitcast <2 x i64> %278 to <8 x i16>
  %315 = shufflevector <8 x i16> %314, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %316 = shufflevector <8 x i16> %314, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %317 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %315, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #6
  %318 = add <4 x i32> %317, <i32 8192, i32 8192, i32 8192, i32 8192>
  %319 = ashr <4 x i32> %318, <i32 14, i32 14, i32 14, i32 14>
  %320 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %316, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #6
  %321 = add <4 x i32> %320, <i32 8192, i32 8192, i32 8192, i32 8192>
  %322 = ashr <4 x i32> %321, <i32 14, i32 14, i32 14, i32 14>
  %323 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %319, <4 x i32> %322) #6
  %324 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %315, <8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>) #6
  %325 = add <4 x i32> %324, <i32 8192, i32 8192, i32 8192, i32 8192>
  %326 = ashr <4 x i32> %325, <i32 14, i32 14, i32 14, i32 14>
  %327 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %316, <8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>) #6
  %328 = add <4 x i32> %327, <i32 8192, i32 8192, i32 8192, i32 8192>
  %329 = ashr <4 x i32> %328, <i32 14, i32 14, i32 14, i32 14>
  %330 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %326, <4 x i32> %329) #6
  %331 = bitcast <2 x i64> %276 to <8 x i16>
  %332 = shufflevector <8 x i16> %331, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %333 = shufflevector <8 x i16> %331, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %334 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %332, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %335 = add <4 x i32> %334, <i32 8192, i32 8192, i32 8192, i32 8192>
  %336 = ashr <4 x i32> %335, <i32 14, i32 14, i32 14, i32 14>
  %337 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %333, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %338 = add <4 x i32> %337, <i32 8192, i32 8192, i32 8192, i32 8192>
  %339 = ashr <4 x i32> %338, <i32 14, i32 14, i32 14, i32 14>
  %340 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %336, <4 x i32> %339) #6
  %341 = shufflevector <8 x i16> %296, <8 x i16> %289, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %342 = shufflevector <8 x i16> %296, <8 x i16> %289, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %343 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %341, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %344 = add <4 x i32> %343, <i32 8192, i32 8192, i32 8192, i32 8192>
  %345 = ashr <4 x i32> %344, <i32 14, i32 14, i32 14, i32 14>
  %346 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %342, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %347 = add <4 x i32> %346, <i32 8192, i32 8192, i32 8192, i32 8192>
  %348 = ashr <4 x i32> %347, <i32 14, i32 14, i32 14, i32 14>
  %349 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %345, <4 x i32> %348) #6
  %350 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %341, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %351 = add <4 x i32> %350, <i32 8192, i32 8192, i32 8192, i32 8192>
  %352 = ashr <4 x i32> %351, <i32 14, i32 14, i32 14, i32 14>
  %353 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %342, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %354 = add <4 x i32> %353, <i32 8192, i32 8192, i32 8192, i32 8192>
  %355 = ashr <4 x i32> %354, <i32 14, i32 14, i32 14, i32 14>
  %356 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %352, <4 x i32> %355) #6
  %357 = shufflevector <8 x i16> %306, <8 x i16> %313, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %358 = shufflevector <8 x i16> %306, <8 x i16> %313, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %359 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %357, <8 x i16> <i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270>) #6
  %360 = add <4 x i32> %359, <i32 8192, i32 8192, i32 8192, i32 8192>
  %361 = ashr <4 x i32> %360, <i32 14, i32 14, i32 14, i32 14>
  %362 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %358, <8 x i16> <i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270>) #6
  %363 = add <4 x i32> %362, <i32 8192, i32 8192, i32 8192, i32 8192>
  %364 = ashr <4 x i32> %363, <i32 14, i32 14, i32 14, i32 14>
  %365 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %361, <4 x i32> %364) #6
  %366 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %357, <8 x i16> <i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137>) #6
  %367 = add <4 x i32> %366, <i32 8192, i32 8192, i32 8192, i32 8192>
  %368 = ashr <4 x i32> %367, <i32 14, i32 14, i32 14, i32 14>
  %369 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %358, <8 x i16> <i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137>) #6
  %370 = add <4 x i32> %369, <i32 8192, i32 8192, i32 8192, i32 8192>
  %371 = ashr <4 x i32> %370, <i32 14, i32 14, i32 14, i32 14>
  %372 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %368, <4 x i32> %371) #6
  %373 = shufflevector <8 x i16> %330, <8 x i16> %323, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %374 = shufflevector <8 x i16> %330, <8 x i16> %323, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %375 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %373, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %376 = add <4 x i32> %375, <i32 8192, i32 8192, i32 8192, i32 8192>
  %377 = ashr <4 x i32> %376, <i32 14, i32 14, i32 14, i32 14>
  %378 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %374, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %379 = add <4 x i32> %378, <i32 8192, i32 8192, i32 8192, i32 8192>
  %380 = ashr <4 x i32> %379, <i32 14, i32 14, i32 14, i32 14>
  %381 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %377, <4 x i32> %380) #6
  %382 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %373, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %383 = add <4 x i32> %382, <i32 8192, i32 8192, i32 8192, i32 8192>
  %384 = ashr <4 x i32> %383, <i32 14, i32 14, i32 14, i32 14>
  %385 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %374, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %386 = add <4 x i32> %385, <i32 8192, i32 8192, i32 8192, i32 8192>
  %387 = ashr <4 x i32> %386, <i32 14, i32 14, i32 14, i32 14>
  %388 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %384, <4 x i32> %387) #6
  %389 = add <8 x i16> %306, %289
  %390 = add <8 x i16> %372, %349
  %391 = sub <8 x i16> %349, %372
  %392 = sub <8 x i16> %289, %306
  %393 = sub <8 x i16> %296, %313
  %394 = sub <8 x i16> %356, %365
  %395 = add <8 x i16> %365, %356
  %396 = add <8 x i16> %313, %296
  %397 = add <8 x i16> %340, %330
  %398 = add <8 x i16> %388, %340
  %399 = add <8 x i16> %381, %340
  %400 = add <8 x i16> %340, %323
  %401 = sub <8 x i16> %340, %323
  %402 = sub <8 x i16> %340, %381
  %403 = sub <8 x i16> %340, %388
  %404 = sub <8 x i16> %340, %330
  %405 = shufflevector <8 x i16> %394, <8 x i16> %391, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %406 = shufflevector <8 x i16> %394, <8 x i16> %391, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %407 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %405, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %408 = add <4 x i32> %407, <i32 8192, i32 8192, i32 8192, i32 8192>
  %409 = ashr <4 x i32> %408, <i32 14, i32 14, i32 14, i32 14>
  %410 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %406, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %411 = add <4 x i32> %410, <i32 8192, i32 8192, i32 8192, i32 8192>
  %412 = ashr <4 x i32> %411, <i32 14, i32 14, i32 14, i32 14>
  %413 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %409, <4 x i32> %412) #6
  %414 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %405, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %415 = add <4 x i32> %414, <i32 8192, i32 8192, i32 8192, i32 8192>
  %416 = ashr <4 x i32> %415, <i32 14, i32 14, i32 14, i32 14>
  %417 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %406, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %418 = add <4 x i32> %417, <i32 8192, i32 8192, i32 8192, i32 8192>
  %419 = ashr <4 x i32> %418, <i32 14, i32 14, i32 14, i32 14>
  %420 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %416, <4 x i32> %419) #6
  %421 = shufflevector <8 x i16> %393, <8 x i16> %392, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %422 = shufflevector <8 x i16> %393, <8 x i16> %392, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %423 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %421, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %424 = add <4 x i32> %423, <i32 8192, i32 8192, i32 8192, i32 8192>
  %425 = ashr <4 x i32> %424, <i32 14, i32 14, i32 14, i32 14>
  %426 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %422, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %427 = add <4 x i32> %426, <i32 8192, i32 8192, i32 8192, i32 8192>
  %428 = ashr <4 x i32> %427, <i32 14, i32 14, i32 14, i32 14>
  %429 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %425, <4 x i32> %428) #6
  %430 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %421, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %431 = add <4 x i32> %430, <i32 8192, i32 8192, i32 8192, i32 8192>
  %432 = ashr <4 x i32> %431, <i32 14, i32 14, i32 14, i32 14>
  %433 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %422, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %434 = add <4 x i32> %433, <i32 8192, i32 8192, i32 8192, i32 8192>
  %435 = ashr <4 x i32> %434, <i32 14, i32 14, i32 14, i32 14>
  %436 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %432, <4 x i32> %435) #6
  %437 = add <8 x i16> %397, %396
  store <8 x i16> %437, <8 x i16>* %16, align 16
  %438 = add <8 x i16> %398, %395
  store <8 x i16> %438, <8 x i16>* %22, align 16
  %439 = add <8 x i16> %420, %399
  store <8 x i16> %439, <8 x i16>* %28, align 16
  %440 = add <8 x i16> %436, %400
  store <8 x i16> %440, <8 x i16>* %34, align 16
  %441 = add <8 x i16> %429, %401
  store <8 x i16> %441, <8 x i16>* %209, align 16
  %442 = add <8 x i16> %413, %402
  store <8 x i16> %442, <8 x i16>* %211, align 16
  %443 = add <8 x i16> %403, %390
  store <8 x i16> %443, <8 x i16>* %213, align 16
  %444 = add <8 x i16> %404, %389
  store <8 x i16> %444, <8 x i16>* %215, align 16
  %445 = sub <8 x i16> %404, %389
  store <8 x i16> %445, <8 x i16>* %217, align 16
  %446 = sub <8 x i16> %403, %390
  store <8 x i16> %446, <8 x i16>* %219, align 16
  %447 = sub <8 x i16> %402, %413
  store <8 x i16> %447, <8 x i16>* %221, align 16
  %448 = sub <8 x i16> %401, %429
  store <8 x i16> %448, <8 x i16>* %223, align 16
  %449 = sub <8 x i16> %400, %436
  store <8 x i16> %449, <8 x i16>* %225, align 16
  %450 = sub <8 x i16> %399, %420
  store <8 x i16> %450, <8 x i16>* %227, align 16
  %451 = sub <8 x i16> %398, %395
  store <8 x i16> %451, <8 x i16>* %229, align 16
  %452 = sub <8 x i16> %397, %396
  store <8 x i16> %452, <8 x i16>* %231, align 16
  br label %453

453:                                              ; preds = %453, %233
  %454 = phi i64 [ 0, %233 ], [ %472, %453 ]
  %455 = mul nsw i64 %454, %232
  %456 = getelementptr inbounds i8, i8* %235, i64 %455
  %457 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %4, i64 0, i64 %454
  %458 = bitcast <2 x i64>* %457 to <8 x i16>*
  %459 = load <8 x i16>, <8 x i16>* %458, align 16
  %460 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %459, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #6
  %461 = ashr <8 x i16> %460, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %462 = bitcast i8* %456 to i64*
  %463 = load i64, i64* %462, align 1
  %464 = insertelement <2 x i64> undef, i64 %463, i32 0
  %465 = bitcast <2 x i64> %464 to <16 x i8>
  %466 = shufflevector <16 x i8> %465, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %467 = bitcast <16 x i8> %466 to <8 x i16>
  %468 = add <8 x i16> %461, %467
  %469 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %468, <8 x i16> undef) #6
  %470 = bitcast <16 x i8> %469 to <2 x i64>
  %471 = extractelement <2 x i64> %470, i32 0
  store i64 %471, i64* %462, align 1
  %472 = add nuw nsw i64 %454, 1
  %473 = icmp eq i64 %472, 16
  br i1 %473, label %474, label %453

474:                                              ; preds = %453
  %475 = getelementptr inbounds i8, i8* %235, i64 8
  %476 = add nuw nsw i64 %234, 8
  %477 = icmp ult i64 %476, 16
  br i1 %477, label %233, label %478

478:                                              ; preds = %474
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %9) #6
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %6) #6
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @vpx_idct16x16_1_add_sse2(i32* nocapture readonly, i8* nocapture, i32) local_unnamed_addr #2 {
  %4 = load i32, i32* %0, align 4
  %5 = shl i32 %4, 16
  %6 = ashr exact i32 %5, 16
  %7 = mul nsw i32 %6, 11585
  %8 = add nsw i32 %7, 8192
  %9 = ashr i32 %8, 14
  %10 = sext i32 %9 to i64
  %11 = mul nsw i64 %10, 49757196124160
  %12 = ashr exact i64 %11, 32
  %13 = add nsw i64 %12, 8192
  %14 = lshr i64 %13, 14
  %15 = trunc i64 %14 to i32
  %16 = add i32 %15, 32
  %17 = lshr i32 %16, 6
  %18 = trunc i32 %17 to i16
  %19 = insertelement <8 x i16> undef, i16 %18, i32 0
  %20 = shufflevector <8 x i16> %19, <8 x i16> undef, <8 x i32> zeroinitializer
  %21 = sext i32 %2 to i64
  br label %22

22:                                               ; preds = %22, %3
  %23 = phi i8* [ %1, %3 ], [ %44, %22 ]
  %24 = phi i32 [ 0, %3 ], [ %45, %22 ]
  %25 = bitcast i8* %23 to <16 x i8>*
  %26 = load <16 x i8>, <16 x i8>* %25, align 16
  %27 = shufflevector <16 x i8> %26, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %28 = shufflevector <16 x i8> %26, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %29 = bitcast <16 x i8> %28 to <8 x i16>
  %30 = add <8 x i16> %20, %29
  %31 = bitcast <16 x i8> %27 to <8 x i16>
  %32 = add <8 x i16> %20, %31
  %33 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %30, <8 x i16> %32) #6
  store <16 x i8> %33, <16 x i8>* %25, align 16
  %34 = getelementptr inbounds i8, i8* %23, i64 %21
  %35 = bitcast i8* %34 to <16 x i8>*
  %36 = load <16 x i8>, <16 x i8>* %35, align 16
  %37 = shufflevector <16 x i8> %36, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %38 = shufflevector <16 x i8> %36, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %39 = bitcast <16 x i8> %38 to <8 x i16>
  %40 = add <8 x i16> %20, %39
  %41 = bitcast <16 x i8> %37 to <8 x i16>
  %42 = add <8 x i16> %20, %41
  %43 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %40, <8 x i16> %42) #6
  store <16 x i8> %43, <16 x i8>* %35, align 16
  %44 = getelementptr inbounds i8, i8* %34, i64 %21
  %45 = add nuw nsw i32 %24, 2
  %46 = icmp eq i32 %45, 16
  br i1 %46, label %47, label %22

47:                                               ; preds = %22
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @vpx_iadst16_8col_sse2(<2 x i64>* nocapture) local_unnamed_addr #2 {
  %2 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 15
  %3 = bitcast <2 x i64>* %2 to <8 x i16>*
  %4 = load <8 x i16>, <8 x i16>* %3, align 16
  %5 = bitcast <2 x i64>* %0 to <8 x i16>*
  %6 = load <8 x i16>, <8 x i16>* %5, align 16
  %7 = shufflevector <8 x i16> %4, <8 x i16> %6, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %8 = shufflevector <8 x i16> %4, <8 x i16> %6, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %9 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 13
  %10 = bitcast <2 x i64>* %9 to <8 x i16>*
  %11 = load <8 x i16>, <8 x i16>* %10, align 16
  %12 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %13 = bitcast <2 x i64>* %12 to <8 x i16>*
  %14 = load <8 x i16>, <8 x i16>* %13, align 16
  %15 = shufflevector <8 x i16> %11, <8 x i16> %14, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %16 = shufflevector <8 x i16> %11, <8 x i16> %14, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %17 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 11
  %18 = bitcast <2 x i64>* %17 to <8 x i16>*
  %19 = load <8 x i16>, <8 x i16>* %18, align 16
  %20 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %21 = bitcast <2 x i64>* %20 to <8 x i16>*
  %22 = load <8 x i16>, <8 x i16>* %21, align 16
  %23 = shufflevector <8 x i16> %19, <8 x i16> %22, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %24 = shufflevector <8 x i16> %19, <8 x i16> %22, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %25 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 9
  %26 = bitcast <2 x i64>* %25 to <8 x i16>*
  %27 = load <8 x i16>, <8 x i16>* %26, align 16
  %28 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %29 = bitcast <2 x i64>* %28 to <8 x i16>*
  %30 = load <8 x i16>, <8 x i16>* %29, align 16
  %31 = shufflevector <8 x i16> %27, <8 x i16> %30, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %32 = shufflevector <8 x i16> %27, <8 x i16> %30, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %33 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %34 = bitcast <2 x i64>* %33 to <8 x i16>*
  %35 = load <8 x i16>, <8 x i16>* %34, align 16
  %36 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 8
  %37 = bitcast <2 x i64>* %36 to <8 x i16>*
  %38 = load <8 x i16>, <8 x i16>* %37, align 16
  %39 = shufflevector <8 x i16> %35, <8 x i16> %38, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %40 = shufflevector <8 x i16> %35, <8 x i16> %38, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %41 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %42 = bitcast <2 x i64>* %41 to <8 x i16>*
  %43 = load <8 x i16>, <8 x i16>* %42, align 16
  %44 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 10
  %45 = bitcast <2 x i64>* %44 to <8 x i16>*
  %46 = load <8 x i16>, <8 x i16>* %45, align 16
  %47 = shufflevector <8 x i16> %43, <8 x i16> %46, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %48 = shufflevector <8 x i16> %43, <8 x i16> %46, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %49 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %50 = bitcast <2 x i64>* %49 to <8 x i16>*
  %51 = load <8 x i16>, <8 x i16>* %50, align 16
  %52 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 12
  %53 = bitcast <2 x i64>* %52 to <8 x i16>*
  %54 = load <8 x i16>, <8 x i16>* %53, align 16
  %55 = shufflevector <8 x i16> %51, <8 x i16> %54, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %56 = shufflevector <8 x i16> %51, <8 x i16> %54, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %57 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %58 = bitcast <2 x i64>* %57 to <8 x i16>*
  %59 = load <8 x i16>, <8 x i16>* %58, align 16
  %60 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 14
  %61 = bitcast <2 x i64>* %60 to <8 x i16>*
  %62 = load <8 x i16>, <8 x i16>* %61, align 16
  %63 = shufflevector <8 x i16> %59, <8 x i16> %62, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %64 = shufflevector <8 x i16> %59, <8 x i16> %62, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %65 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7, <8 x i16> <i16 16364, i16 804, i16 16364, i16 804, i16 16364, i16 804, i16 16364, i16 804>) #6
  %66 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8, <8 x i16> <i16 16364, i16 804, i16 16364, i16 804, i16 16364, i16 804, i16 16364, i16 804>) #6
  %67 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7, <8 x i16> <i16 804, i16 -16364, i16 804, i16 -16364, i16 804, i16 -16364, i16 804, i16 -16364>) #6
  %68 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8, <8 x i16> <i16 804, i16 -16364, i16 804, i16 -16364, i16 804, i16 -16364, i16 804, i16 -16364>) #6
  %69 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %15, <8 x i16> <i16 15893, i16 3981, i16 15893, i16 3981, i16 15893, i16 3981, i16 15893, i16 3981>) #6
  %70 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 15893, i16 3981, i16 15893, i16 3981, i16 15893, i16 3981, i16 15893, i16 3981>) #6
  %71 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %15, <8 x i16> <i16 3981, i16 -15893, i16 3981, i16 -15893, i16 3981, i16 -15893, i16 3981, i16 -15893>) #6
  %72 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %16, <8 x i16> <i16 3981, i16 -15893, i16 3981, i16 -15893, i16 3981, i16 -15893, i16 3981, i16 -15893>) #6
  %73 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %23, <8 x i16> <i16 14811, i16 7005, i16 14811, i16 7005, i16 14811, i16 7005, i16 14811, i16 7005>) #6
  %74 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %24, <8 x i16> <i16 14811, i16 7005, i16 14811, i16 7005, i16 14811, i16 7005, i16 14811, i16 7005>) #6
  %75 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %23, <8 x i16> <i16 7005, i16 -14811, i16 7005, i16 -14811, i16 7005, i16 -14811, i16 7005, i16 -14811>) #6
  %76 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %24, <8 x i16> <i16 7005, i16 -14811, i16 7005, i16 -14811, i16 7005, i16 -14811, i16 7005, i16 -14811>) #6
  %77 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %31, <8 x i16> <i16 13160, i16 9760, i16 13160, i16 9760, i16 13160, i16 9760, i16 13160, i16 9760>) #6
  %78 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %32, <8 x i16> <i16 13160, i16 9760, i16 13160, i16 9760, i16 13160, i16 9760, i16 13160, i16 9760>) #6
  %79 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %31, <8 x i16> <i16 9760, i16 -13160, i16 9760, i16 -13160, i16 9760, i16 -13160, i16 9760, i16 -13160>) #6
  %80 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %32, <8 x i16> <i16 9760, i16 -13160, i16 9760, i16 -13160, i16 9760, i16 -13160, i16 9760, i16 -13160>) #6
  %81 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %39, <8 x i16> <i16 11003, i16 12140, i16 11003, i16 12140, i16 11003, i16 12140, i16 11003, i16 12140>) #6
  %82 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %40, <8 x i16> <i16 11003, i16 12140, i16 11003, i16 12140, i16 11003, i16 12140, i16 11003, i16 12140>) #6
  %83 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %39, <8 x i16> <i16 12140, i16 -11003, i16 12140, i16 -11003, i16 12140, i16 -11003, i16 12140, i16 -11003>) #6
  %84 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %40, <8 x i16> <i16 12140, i16 -11003, i16 12140, i16 -11003, i16 12140, i16 -11003, i16 12140, i16 -11003>) #6
  %85 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %47, <8 x i16> <i16 8423, i16 14053, i16 8423, i16 14053, i16 8423, i16 14053, i16 8423, i16 14053>) #6
  %86 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %48, <8 x i16> <i16 8423, i16 14053, i16 8423, i16 14053, i16 8423, i16 14053, i16 8423, i16 14053>) #6
  %87 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %47, <8 x i16> <i16 14053, i16 -8423, i16 14053, i16 -8423, i16 14053, i16 -8423, i16 14053, i16 -8423>) #6
  %88 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %48, <8 x i16> <i16 14053, i16 -8423, i16 14053, i16 -8423, i16 14053, i16 -8423, i16 14053, i16 -8423>) #6
  %89 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %55, <8 x i16> <i16 5520, i16 15426, i16 5520, i16 15426, i16 5520, i16 15426, i16 5520, i16 15426>) #6
  %90 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %56, <8 x i16> <i16 5520, i16 15426, i16 5520, i16 15426, i16 5520, i16 15426, i16 5520, i16 15426>) #6
  %91 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %55, <8 x i16> <i16 15426, i16 -5520, i16 15426, i16 -5520, i16 15426, i16 -5520, i16 15426, i16 -5520>) #6
  %92 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %56, <8 x i16> <i16 15426, i16 -5520, i16 15426, i16 -5520, i16 15426, i16 -5520, i16 15426, i16 -5520>) #6
  %93 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %63, <8 x i16> <i16 2404, i16 16207, i16 2404, i16 16207, i16 2404, i16 16207, i16 2404, i16 16207>) #6
  %94 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %64, <8 x i16> <i16 2404, i16 16207, i16 2404, i16 16207, i16 2404, i16 16207, i16 2404, i16 16207>) #6
  %95 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %63, <8 x i16> <i16 16207, i16 -2404, i16 16207, i16 -2404, i16 16207, i16 -2404, i16 16207, i16 -2404>) #6
  %96 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %64, <8 x i16> <i16 16207, i16 -2404, i16 16207, i16 -2404, i16 16207, i16 -2404, i16 16207, i16 -2404>) #6
  %97 = add <4 x i32> %65, <i32 8192, i32 8192, i32 8192, i32 8192>
  %98 = add <4 x i32> %97, %81
  %99 = ashr <4 x i32> %98, <i32 14, i32 14, i32 14, i32 14>
  %100 = add <4 x i32> %66, <i32 8192, i32 8192, i32 8192, i32 8192>
  %101 = add <4 x i32> %100, %82
  %102 = ashr <4 x i32> %101, <i32 14, i32 14, i32 14, i32 14>
  %103 = add <4 x i32> %67, <i32 8192, i32 8192, i32 8192, i32 8192>
  %104 = add <4 x i32> %103, %83
  %105 = ashr <4 x i32> %104, <i32 14, i32 14, i32 14, i32 14>
  %106 = add <4 x i32> %68, <i32 8192, i32 8192, i32 8192, i32 8192>
  %107 = add <4 x i32> %106, %84
  %108 = ashr <4 x i32> %107, <i32 14, i32 14, i32 14, i32 14>
  %109 = add <4 x i32> %69, <i32 8192, i32 8192, i32 8192, i32 8192>
  %110 = add <4 x i32> %109, %85
  %111 = ashr <4 x i32> %110, <i32 14, i32 14, i32 14, i32 14>
  %112 = add <4 x i32> %70, <i32 8192, i32 8192, i32 8192, i32 8192>
  %113 = add <4 x i32> %112, %86
  %114 = ashr <4 x i32> %113, <i32 14, i32 14, i32 14, i32 14>
  %115 = add <4 x i32> %71, <i32 8192, i32 8192, i32 8192, i32 8192>
  %116 = add <4 x i32> %115, %87
  %117 = ashr <4 x i32> %116, <i32 14, i32 14, i32 14, i32 14>
  %118 = add <4 x i32> %72, <i32 8192, i32 8192, i32 8192, i32 8192>
  %119 = add <4 x i32> %118, %88
  %120 = ashr <4 x i32> %119, <i32 14, i32 14, i32 14, i32 14>
  %121 = add <4 x i32> %73, <i32 8192, i32 8192, i32 8192, i32 8192>
  %122 = add <4 x i32> %121, %89
  %123 = ashr <4 x i32> %122, <i32 14, i32 14, i32 14, i32 14>
  %124 = add <4 x i32> %74, <i32 8192, i32 8192, i32 8192, i32 8192>
  %125 = add <4 x i32> %124, %90
  %126 = ashr <4 x i32> %125, <i32 14, i32 14, i32 14, i32 14>
  %127 = add <4 x i32> %75, <i32 8192, i32 8192, i32 8192, i32 8192>
  %128 = add <4 x i32> %127, %91
  %129 = ashr <4 x i32> %128, <i32 14, i32 14, i32 14, i32 14>
  %130 = add <4 x i32> %76, <i32 8192, i32 8192, i32 8192, i32 8192>
  %131 = add <4 x i32> %130, %92
  %132 = ashr <4 x i32> %131, <i32 14, i32 14, i32 14, i32 14>
  %133 = add <4 x i32> %77, <i32 8192, i32 8192, i32 8192, i32 8192>
  %134 = add <4 x i32> %133, %93
  %135 = ashr <4 x i32> %134, <i32 14, i32 14, i32 14, i32 14>
  %136 = add <4 x i32> %78, <i32 8192, i32 8192, i32 8192, i32 8192>
  %137 = add <4 x i32> %136, %94
  %138 = ashr <4 x i32> %137, <i32 14, i32 14, i32 14, i32 14>
  %139 = add <4 x i32> %79, <i32 8192, i32 8192, i32 8192, i32 8192>
  %140 = add <4 x i32> %139, %95
  %141 = ashr <4 x i32> %140, <i32 14, i32 14, i32 14, i32 14>
  %142 = add <4 x i32> %80, <i32 8192, i32 8192, i32 8192, i32 8192>
  %143 = add <4 x i32> %142, %96
  %144 = ashr <4 x i32> %143, <i32 14, i32 14, i32 14, i32 14>
  %145 = sub <4 x i32> %97, %81
  %146 = ashr <4 x i32> %145, <i32 14, i32 14, i32 14, i32 14>
  %147 = sub <4 x i32> %100, %82
  %148 = ashr <4 x i32> %147, <i32 14, i32 14, i32 14, i32 14>
  %149 = sub <4 x i32> %103, %83
  %150 = ashr <4 x i32> %149, <i32 14, i32 14, i32 14, i32 14>
  %151 = sub <4 x i32> %106, %84
  %152 = ashr <4 x i32> %151, <i32 14, i32 14, i32 14, i32 14>
  %153 = sub <4 x i32> %109, %85
  %154 = ashr <4 x i32> %153, <i32 14, i32 14, i32 14, i32 14>
  %155 = sub <4 x i32> %112, %86
  %156 = ashr <4 x i32> %155, <i32 14, i32 14, i32 14, i32 14>
  %157 = sub <4 x i32> %115, %87
  %158 = ashr <4 x i32> %157, <i32 14, i32 14, i32 14, i32 14>
  %159 = sub <4 x i32> %118, %88
  %160 = ashr <4 x i32> %159, <i32 14, i32 14, i32 14, i32 14>
  %161 = sub <4 x i32> %121, %89
  %162 = ashr <4 x i32> %161, <i32 14, i32 14, i32 14, i32 14>
  %163 = sub <4 x i32> %124, %90
  %164 = ashr <4 x i32> %163, <i32 14, i32 14, i32 14, i32 14>
  %165 = sub <4 x i32> %127, %91
  %166 = ashr <4 x i32> %165, <i32 14, i32 14, i32 14, i32 14>
  %167 = sub <4 x i32> %130, %92
  %168 = ashr <4 x i32> %167, <i32 14, i32 14, i32 14, i32 14>
  %169 = sub <4 x i32> %133, %93
  %170 = ashr <4 x i32> %169, <i32 14, i32 14, i32 14, i32 14>
  %171 = sub <4 x i32> %136, %94
  %172 = ashr <4 x i32> %171, <i32 14, i32 14, i32 14, i32 14>
  %173 = sub <4 x i32> %139, %95
  %174 = ashr <4 x i32> %173, <i32 14, i32 14, i32 14, i32 14>
  %175 = sub <4 x i32> %142, %96
  %176 = ashr <4 x i32> %175, <i32 14, i32 14, i32 14, i32 14>
  %177 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %99, <4 x i32> %102) #6
  %178 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %105, <4 x i32> %108) #6
  %179 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %111, <4 x i32> %114) #6
  %180 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %117, <4 x i32> %120) #6
  %181 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %123, <4 x i32> %126) #6
  %182 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %129, <4 x i32> %132) #6
  %183 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %135, <4 x i32> %138) #6
  %184 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %141, <4 x i32> %144) #6
  %185 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %146, <4 x i32> %148) #6
  %186 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %150, <4 x i32> %152) #6
  %187 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %154, <4 x i32> %156) #6
  %188 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %158, <4 x i32> %160) #6
  %189 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %162, <4 x i32> %164) #6
  %190 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %166, <4 x i32> %168) #6
  %191 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %170, <4 x i32> %172) #6
  %192 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %174, <4 x i32> %176) #6
  %193 = shufflevector <8 x i16> %185, <8 x i16> %186, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %194 = shufflevector <8 x i16> %185, <8 x i16> %186, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %195 = shufflevector <8 x i16> %187, <8 x i16> %188, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %196 = shufflevector <8 x i16> %187, <8 x i16> %188, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %197 = shufflevector <8 x i16> %189, <8 x i16> %190, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %198 = shufflevector <8 x i16> %189, <8 x i16> %190, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %199 = shufflevector <8 x i16> %191, <8 x i16> %192, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %200 = shufflevector <8 x i16> %191, <8 x i16> %192, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %201 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %193, <8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>) #6
  %202 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %194, <8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>) #6
  %203 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %193, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #6
  %204 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %194, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #6
  %205 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %195, <8 x i16> <i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623>) #6
  %206 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %196, <8 x i16> <i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623>) #6
  %207 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %195, <8 x i16> <i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102>) #6
  %208 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %196, <8 x i16> <i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102>) #6
  %209 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %197, <8 x i16> <i16 -3196, i16 16069, i16 -3196, i16 16069, i16 -3196, i16 16069, i16 -3196, i16 16069>) #6
  %210 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %198, <8 x i16> <i16 -3196, i16 16069, i16 -3196, i16 16069, i16 -3196, i16 16069, i16 -3196, i16 16069>) #6
  %211 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %197, <8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>) #6
  %212 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %198, <8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>) #6
  %213 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %199, <8 x i16> <i16 -13623, i16 9102, i16 -13623, i16 9102, i16 -13623, i16 9102, i16 -13623, i16 9102>) #6
  %214 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %200, <8 x i16> <i16 -13623, i16 9102, i16 -13623, i16 9102, i16 -13623, i16 9102, i16 -13623, i16 9102>) #6
  %215 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %199, <8 x i16> <i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623>) #6
  %216 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %200, <8 x i16> <i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623>) #6
  %217 = add <4 x i32> %201, <i32 8192, i32 8192, i32 8192, i32 8192>
  %218 = add <4 x i32> %217, %209
  %219 = ashr <4 x i32> %218, <i32 14, i32 14, i32 14, i32 14>
  %220 = add <4 x i32> %202, <i32 8192, i32 8192, i32 8192, i32 8192>
  %221 = add <4 x i32> %220, %210
  %222 = ashr <4 x i32> %221, <i32 14, i32 14, i32 14, i32 14>
  %223 = add <4 x i32> %203, <i32 8192, i32 8192, i32 8192, i32 8192>
  %224 = add <4 x i32> %223, %211
  %225 = ashr <4 x i32> %224, <i32 14, i32 14, i32 14, i32 14>
  %226 = add <4 x i32> %204, <i32 8192, i32 8192, i32 8192, i32 8192>
  %227 = add <4 x i32> %226, %212
  %228 = ashr <4 x i32> %227, <i32 14, i32 14, i32 14, i32 14>
  %229 = add <4 x i32> %205, <i32 8192, i32 8192, i32 8192, i32 8192>
  %230 = add <4 x i32> %229, %213
  %231 = ashr <4 x i32> %230, <i32 14, i32 14, i32 14, i32 14>
  %232 = add <4 x i32> %206, <i32 8192, i32 8192, i32 8192, i32 8192>
  %233 = add <4 x i32> %232, %214
  %234 = ashr <4 x i32> %233, <i32 14, i32 14, i32 14, i32 14>
  %235 = add <4 x i32> %207, <i32 8192, i32 8192, i32 8192, i32 8192>
  %236 = add <4 x i32> %235, %215
  %237 = ashr <4 x i32> %236, <i32 14, i32 14, i32 14, i32 14>
  %238 = add <4 x i32> %208, <i32 8192, i32 8192, i32 8192, i32 8192>
  %239 = add <4 x i32> %238, %216
  %240 = ashr <4 x i32> %239, <i32 14, i32 14, i32 14, i32 14>
  %241 = sub <4 x i32> %217, %209
  %242 = ashr <4 x i32> %241, <i32 14, i32 14, i32 14, i32 14>
  %243 = sub <4 x i32> %220, %210
  %244 = ashr <4 x i32> %243, <i32 14, i32 14, i32 14, i32 14>
  %245 = sub <4 x i32> %223, %211
  %246 = ashr <4 x i32> %245, <i32 14, i32 14, i32 14, i32 14>
  %247 = sub <4 x i32> %226, %212
  %248 = ashr <4 x i32> %247, <i32 14, i32 14, i32 14, i32 14>
  %249 = sub <4 x i32> %229, %213
  %250 = ashr <4 x i32> %249, <i32 14, i32 14, i32 14, i32 14>
  %251 = sub <4 x i32> %232, %214
  %252 = ashr <4 x i32> %251, <i32 14, i32 14, i32 14, i32 14>
  %253 = sub <4 x i32> %235, %215
  %254 = ashr <4 x i32> %253, <i32 14, i32 14, i32 14, i32 14>
  %255 = sub <4 x i32> %238, %216
  %256 = ashr <4 x i32> %255, <i32 14, i32 14, i32 14, i32 14>
  %257 = add <8 x i16> %181, %177
  %258 = add <8 x i16> %182, %178
  %259 = add <8 x i16> %183, %179
  %260 = add <8 x i16> %184, %180
  %261 = sub <8 x i16> %177, %181
  %262 = sub <8 x i16> %178, %182
  %263 = sub <8 x i16> %179, %183
  %264 = sub <8 x i16> %180, %184
  %265 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %219, <4 x i32> %222) #6
  %266 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %225, <4 x i32> %228) #6
  %267 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %231, <4 x i32> %234) #6
  %268 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %237, <4 x i32> %240) #6
  %269 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %242, <4 x i32> %244) #6
  %270 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %246, <4 x i32> %248) #6
  %271 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %250, <4 x i32> %252) #6
  %272 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %254, <4 x i32> %256) #6
  %273 = shufflevector <8 x i16> %261, <8 x i16> %262, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %274 = shufflevector <8 x i16> %261, <8 x i16> %262, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %275 = shufflevector <8 x i16> %263, <8 x i16> %264, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %276 = shufflevector <8 x i16> %263, <8 x i16> %264, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %277 = shufflevector <8 x i16> %269, <8 x i16> %270, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %278 = shufflevector <8 x i16> %269, <8 x i16> %270, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %279 = shufflevector <8 x i16> %271, <8 x i16> %272, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %280 = shufflevector <8 x i16> %271, <8 x i16> %272, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %281 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %273, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %282 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %274, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %283 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %273, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %284 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %274, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %285 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %275, <8 x i16> <i16 -6270, i16 15137, i16 -6270, i16 15137, i16 -6270, i16 15137, i16 -6270, i16 15137>) #6
  %286 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %276, <8 x i16> <i16 -6270, i16 15137, i16 -6270, i16 15137, i16 -6270, i16 15137, i16 -6270, i16 15137>) #6
  %287 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %275, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %288 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %276, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %289 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %277, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %290 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %278, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %291 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %277, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %292 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %278, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %293 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %279, <8 x i16> <i16 -6270, i16 15137, i16 -6270, i16 15137, i16 -6270, i16 15137, i16 -6270, i16 15137>) #6
  %294 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %280, <8 x i16> <i16 -6270, i16 15137, i16 -6270, i16 15137, i16 -6270, i16 15137, i16 -6270, i16 15137>) #6
  %295 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %279, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %296 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %280, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %297 = add <4 x i32> %281, <i32 8192, i32 8192, i32 8192, i32 8192>
  %298 = add <4 x i32> %297, %285
  %299 = ashr <4 x i32> %298, <i32 14, i32 14, i32 14, i32 14>
  %300 = add <4 x i32> %282, <i32 8192, i32 8192, i32 8192, i32 8192>
  %301 = add <4 x i32> %300, %286
  %302 = ashr <4 x i32> %301, <i32 14, i32 14, i32 14, i32 14>
  %303 = add <4 x i32> %283, <i32 8192, i32 8192, i32 8192, i32 8192>
  %304 = add <4 x i32> %303, %287
  %305 = ashr <4 x i32> %304, <i32 14, i32 14, i32 14, i32 14>
  %306 = add <4 x i32> %284, <i32 8192, i32 8192, i32 8192, i32 8192>
  %307 = add <4 x i32> %306, %288
  %308 = ashr <4 x i32> %307, <i32 14, i32 14, i32 14, i32 14>
  %309 = sub <4 x i32> %297, %285
  %310 = ashr <4 x i32> %309, <i32 14, i32 14, i32 14, i32 14>
  %311 = sub <4 x i32> %300, %286
  %312 = ashr <4 x i32> %311, <i32 14, i32 14, i32 14, i32 14>
  %313 = sub <4 x i32> %303, %287
  %314 = ashr <4 x i32> %313, <i32 14, i32 14, i32 14, i32 14>
  %315 = sub <4 x i32> %306, %288
  %316 = ashr <4 x i32> %315, <i32 14, i32 14, i32 14, i32 14>
  %317 = add <4 x i32> %289, <i32 8192, i32 8192, i32 8192, i32 8192>
  %318 = add <4 x i32> %317, %293
  %319 = ashr <4 x i32> %318, <i32 14, i32 14, i32 14, i32 14>
  %320 = add <4 x i32> %290, <i32 8192, i32 8192, i32 8192, i32 8192>
  %321 = add <4 x i32> %320, %294
  %322 = ashr <4 x i32> %321, <i32 14, i32 14, i32 14, i32 14>
  %323 = add <4 x i32> %291, <i32 8192, i32 8192, i32 8192, i32 8192>
  %324 = add <4 x i32> %323, %295
  %325 = ashr <4 x i32> %324, <i32 14, i32 14, i32 14, i32 14>
  %326 = add <4 x i32> %292, <i32 8192, i32 8192, i32 8192, i32 8192>
  %327 = add <4 x i32> %326, %296
  %328 = ashr <4 x i32> %327, <i32 14, i32 14, i32 14, i32 14>
  %329 = sub <4 x i32> %317, %293
  %330 = ashr <4 x i32> %329, <i32 14, i32 14, i32 14, i32 14>
  %331 = sub <4 x i32> %320, %294
  %332 = ashr <4 x i32> %331, <i32 14, i32 14, i32 14, i32 14>
  %333 = sub <4 x i32> %323, %295
  %334 = ashr <4 x i32> %333, <i32 14, i32 14, i32 14, i32 14>
  %335 = sub <4 x i32> %326, %296
  %336 = ashr <4 x i32> %335, <i32 14, i32 14, i32 14, i32 14>
  %337 = add <8 x i16> %259, %257
  %338 = add <8 x i16> %258, %260
  %339 = sub <8 x i16> %257, %259
  %340 = sub <8 x i16> %258, %260
  %341 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %299, <4 x i32> %302) #6
  %342 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %305, <4 x i32> %308) #6
  %343 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %310, <4 x i32> %312) #6
  %344 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %314, <4 x i32> %316) #6
  %345 = add <8 x i16> %265, %267
  %346 = add <8 x i16> %268, %266
  %347 = sub <8 x i16> %265, %267
  %348 = sub <8 x i16> %266, %268
  %349 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %319, <4 x i32> %322) #6
  %350 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %325, <4 x i32> %328) #6
  %351 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %330, <4 x i32> %332) #6
  %352 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %334, <4 x i32> %336) #6
  %353 = shufflevector <8 x i16> %339, <8 x i16> %340, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %354 = shufflevector <8 x i16> %339, <8 x i16> %340, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %355 = shufflevector <8 x i16> %343, <8 x i16> %344, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %356 = shufflevector <8 x i16> %343, <8 x i16> %344, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %357 = shufflevector <8 x i16> %347, <8 x i16> %348, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %358 = shufflevector <8 x i16> %347, <8 x i16> %348, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %359 = shufflevector <8 x i16> %351, <8 x i16> %352, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %360 = shufflevector <8 x i16> %351, <8 x i16> %352, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %361 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %353, <8 x i16> <i16 -11585, i16 -11585, i16 -11585, i16 -11585, i16 -11585, i16 -11585, i16 -11585, i16 -11585>) #6
  %362 = add <4 x i32> %361, <i32 8192, i32 8192, i32 8192, i32 8192>
  %363 = ashr <4 x i32> %362, <i32 14, i32 14, i32 14, i32 14>
  %364 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %354, <8 x i16> <i16 -11585, i16 -11585, i16 -11585, i16 -11585, i16 -11585, i16 -11585, i16 -11585, i16 -11585>) #6
  %365 = add <4 x i32> %364, <i32 8192, i32 8192, i32 8192, i32 8192>
  %366 = ashr <4 x i32> %365, <i32 14, i32 14, i32 14, i32 14>
  %367 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %363, <4 x i32> %366) #6
  store <8 x i16> %367, <8 x i16>* %34, align 16
  %368 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %353, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %369 = add <4 x i32> %368, <i32 8192, i32 8192, i32 8192, i32 8192>
  %370 = ashr <4 x i32> %369, <i32 14, i32 14, i32 14, i32 14>
  %371 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %354, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %372 = add <4 x i32> %371, <i32 8192, i32 8192, i32 8192, i32 8192>
  %373 = ashr <4 x i32> %372, <i32 14, i32 14, i32 14, i32 14>
  %374 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %370, <4 x i32> %373) #6
  store <8 x i16> %374, <8 x i16>* %37, align 16
  %375 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %355, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %376 = add <4 x i32> %375, <i32 8192, i32 8192, i32 8192, i32 8192>
  %377 = ashr <4 x i32> %376, <i32 14, i32 14, i32 14, i32 14>
  %378 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %356, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %379 = add <4 x i32> %378, <i32 8192, i32 8192, i32 8192, i32 8192>
  %380 = ashr <4 x i32> %379, <i32 14, i32 14, i32 14, i32 14>
  %381 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %377, <4 x i32> %380) #6
  store <8 x i16> %381, <8 x i16>* %21, align 16
  %382 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %355, <8 x i16> <i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585>) #6
  %383 = add <4 x i32> %382, <i32 8192, i32 8192, i32 8192, i32 8192>
  %384 = ashr <4 x i32> %383, <i32 14, i32 14, i32 14, i32 14>
  %385 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %356, <8 x i16> <i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585>) #6
  %386 = add <4 x i32> %385, <i32 8192, i32 8192, i32 8192, i32 8192>
  %387 = ashr <4 x i32> %386, <i32 14, i32 14, i32 14, i32 14>
  %388 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %384, <4 x i32> %387) #6
  store <8 x i16> %388, <8 x i16>* %18, align 16
  %389 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %357, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %390 = add <4 x i32> %389, <i32 8192, i32 8192, i32 8192, i32 8192>
  %391 = ashr <4 x i32> %390, <i32 14, i32 14, i32 14, i32 14>
  %392 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %358, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %393 = add <4 x i32> %392, <i32 8192, i32 8192, i32 8192, i32 8192>
  %394 = ashr <4 x i32> %393, <i32 14, i32 14, i32 14, i32 14>
  %395 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %391, <4 x i32> %394) #6
  store <8 x i16> %395, <8 x i16>* %29, align 16
  %396 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %357, <8 x i16> <i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585>) #6
  %397 = add <4 x i32> %396, <i32 8192, i32 8192, i32 8192, i32 8192>
  %398 = ashr <4 x i32> %397, <i32 14, i32 14, i32 14, i32 14>
  %399 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %358, <8 x i16> <i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585>) #6
  %400 = add <4 x i32> %399, <i32 8192, i32 8192, i32 8192, i32 8192>
  %401 = ashr <4 x i32> %400, <i32 14, i32 14, i32 14, i32 14>
  %402 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %398, <4 x i32> %401) #6
  store <8 x i16> %402, <8 x i16>* %26, align 16
  %403 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %359, <8 x i16> <i16 -11585, i16 -11585, i16 -11585, i16 -11585, i16 -11585, i16 -11585, i16 -11585, i16 -11585>) #6
  %404 = add <4 x i32> %403, <i32 8192, i32 8192, i32 8192, i32 8192>
  %405 = ashr <4 x i32> %404, <i32 14, i32 14, i32 14, i32 14>
  %406 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %360, <8 x i16> <i16 -11585, i16 -11585, i16 -11585, i16 -11585, i16 -11585, i16 -11585, i16 -11585, i16 -11585>) #6
  %407 = add <4 x i32> %406, <i32 8192, i32 8192, i32 8192, i32 8192>
  %408 = ashr <4 x i32> %407, <i32 14, i32 14, i32 14, i32 14>
  %409 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %405, <4 x i32> %408) #6
  store <8 x i16> %409, <8 x i16>* %42, align 16
  %410 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %359, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %411 = add <4 x i32> %410, <i32 8192, i32 8192, i32 8192, i32 8192>
  %412 = ashr <4 x i32> %411, <i32 14, i32 14, i32 14, i32 14>
  %413 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %360, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %414 = add <4 x i32> %413, <i32 8192, i32 8192, i32 8192, i32 8192>
  %415 = ashr <4 x i32> %414, <i32 14, i32 14, i32 14, i32 14>
  %416 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %412, <4 x i32> %415) #6
  store <8 x i16> %416, <8 x i16>* %45, align 16
  store <8 x i16> %337, <8 x i16>* %5, align 16
  %417 = sub <8 x i16> zeroinitializer, %345
  store <8 x i16> %417, <8 x i16>* %58, align 16
  store <8 x i16> %349, <8 x i16>* %13, align 16
  %418 = sub <8 x i16> zeroinitializer, %341
  store <8 x i16> %418, <8 x i16>* %50, align 16
  store <8 x i16> %342, <8 x i16>* %53, align 16
  %419 = sub <8 x i16> zeroinitializer, %350
  store <8 x i16> %419, <8 x i16>* %10, align 16
  store <8 x i16> %346, <8 x i16>* %61, align 16
  %420 = sub <8 x i16> zeroinitializer, %338
  store <8 x i16> %420, <8 x i16>* %3, align 16
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @idct16_sse2(<2 x i64>* nocapture, <2 x i64>* nocapture) local_unnamed_addr #0 {
  %3 = bitcast <2 x i64>* %0 to <8 x i16>*
  %4 = load <8 x i16>, <8 x i16>* %3, align 16
  %5 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %6 = bitcast <2 x i64>* %5 to <8 x i16>*
  %7 = load <8 x i16>, <8 x i16>* %6, align 16
  %8 = shufflevector <8 x i16> %4, <8 x i16> %7, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %9 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %10 = bitcast <2 x i64>* %9 to <8 x i16>*
  %11 = load <8 x i16>, <8 x i16>* %10, align 16
  %12 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %13 = bitcast <2 x i64>* %12 to <8 x i16>*
  %14 = load <8 x i16>, <8 x i16>* %13, align 16
  %15 = shufflevector <8 x i16> %11, <8 x i16> %14, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %16 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %17 = bitcast <2 x i64>* %16 to <8 x i16>*
  %18 = load <8 x i16>, <8 x i16>* %17, align 16
  %19 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %20 = bitcast <2 x i64>* %19 to <8 x i16>*
  %21 = load <8 x i16>, <8 x i16>* %20, align 16
  %22 = shufflevector <8 x i16> %18, <8 x i16> %21, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %23 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %24 = bitcast <2 x i64>* %23 to <8 x i16>*
  %25 = load <8 x i16>, <8 x i16>* %24, align 16
  %26 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %27 = bitcast <2 x i64>* %26 to <8 x i16>*
  %28 = load <8 x i16>, <8 x i16>* %27, align 16
  %29 = shufflevector <8 x i16> %25, <8 x i16> %28, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %30 = shufflevector <8 x i16> %4, <8 x i16> %7, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %31 = shufflevector <8 x i16> %11, <8 x i16> %14, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %32 = shufflevector <8 x i16> %18, <8 x i16> %21, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %33 = shufflevector <8 x i16> %25, <8 x i16> %28, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %34 = bitcast <8 x i16> %8 to <4 x i32>
  %35 = bitcast <8 x i16> %15 to <4 x i32>
  %36 = shufflevector <4 x i32> %34, <4 x i32> %35, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %37 = bitcast <4 x i32> %36 to <2 x i64>
  %38 = bitcast <8 x i16> %22 to <4 x i32>
  %39 = bitcast <8 x i16> %29 to <4 x i32>
  %40 = shufflevector <4 x i32> %38, <4 x i32> %39, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %41 = bitcast <4 x i32> %40 to <2 x i64>
  %42 = bitcast <8 x i16> %30 to <4 x i32>
  %43 = bitcast <8 x i16> %31 to <4 x i32>
  %44 = shufflevector <4 x i32> %42, <4 x i32> %43, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %45 = bitcast <4 x i32> %44 to <2 x i64>
  %46 = bitcast <8 x i16> %32 to <4 x i32>
  %47 = bitcast <8 x i16> %33 to <4 x i32>
  %48 = shufflevector <4 x i32> %46, <4 x i32> %47, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %49 = bitcast <4 x i32> %48 to <2 x i64>
  %50 = shufflevector <4 x i32> %34, <4 x i32> %35, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %51 = bitcast <4 x i32> %50 to <2 x i64>
  %52 = shufflevector <4 x i32> %38, <4 x i32> %39, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %53 = bitcast <4 x i32> %52 to <2 x i64>
  %54 = shufflevector <4 x i32> %42, <4 x i32> %43, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %55 = bitcast <4 x i32> %54 to <2 x i64>
  %56 = shufflevector <4 x i32> %46, <4 x i32> %47, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %57 = bitcast <4 x i32> %56 to <2 x i64>
  %58 = shufflevector <2 x i64> %37, <2 x i64> %41, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %58, <2 x i64>* %0, align 16
  %59 = shufflevector <2 x i64> %37, <2 x i64> %41, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %59, <2 x i64>* %5, align 16
  %60 = shufflevector <2 x i64> %51, <2 x i64> %53, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %60, <2 x i64>* %9, align 16
  %61 = shufflevector <2 x i64> %51, <2 x i64> %53, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %61, <2 x i64>* %12, align 16
  %62 = shufflevector <2 x i64> %45, <2 x i64> %49, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %62, <2 x i64>* %16, align 16
  %63 = shufflevector <2 x i64> %45, <2 x i64> %49, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %63, <2 x i64>* %19, align 16
  %64 = shufflevector <2 x i64> %55, <2 x i64> %57, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %64, <2 x i64>* %23, align 16
  %65 = shufflevector <2 x i64> %55, <2 x i64> %57, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %65, <2 x i64>* %26, align 16
  %66 = bitcast <2 x i64>* %1 to <8 x i16>*
  %67 = load <8 x i16>, <8 x i16>* %66, align 16
  %68 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %69 = bitcast <2 x i64>* %68 to <8 x i16>*
  %70 = load <8 x i16>, <8 x i16>* %69, align 16
  %71 = shufflevector <8 x i16> %67, <8 x i16> %70, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %72 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %73 = bitcast <2 x i64>* %72 to <8 x i16>*
  %74 = load <8 x i16>, <8 x i16>* %73, align 16
  %75 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %76 = bitcast <2 x i64>* %75 to <8 x i16>*
  %77 = load <8 x i16>, <8 x i16>* %76, align 16
  %78 = shufflevector <8 x i16> %74, <8 x i16> %77, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %79 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %80 = bitcast <2 x i64>* %79 to <8 x i16>*
  %81 = load <8 x i16>, <8 x i16>* %80, align 16
  %82 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %83 = bitcast <2 x i64>* %82 to <8 x i16>*
  %84 = load <8 x i16>, <8 x i16>* %83, align 16
  %85 = shufflevector <8 x i16> %81, <8 x i16> %84, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %86 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %87 = bitcast <2 x i64>* %86 to <8 x i16>*
  %88 = load <8 x i16>, <8 x i16>* %87, align 16
  %89 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %90 = bitcast <2 x i64>* %89 to <8 x i16>*
  %91 = load <8 x i16>, <8 x i16>* %90, align 16
  %92 = shufflevector <8 x i16> %88, <8 x i16> %91, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %93 = shufflevector <8 x i16> %67, <8 x i16> %70, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %94 = shufflevector <8 x i16> %74, <8 x i16> %77, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %95 = shufflevector <8 x i16> %81, <8 x i16> %84, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %96 = shufflevector <8 x i16> %88, <8 x i16> %91, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %97 = bitcast <8 x i16> %71 to <4 x i32>
  %98 = bitcast <8 x i16> %78 to <4 x i32>
  %99 = shufflevector <4 x i32> %97, <4 x i32> %98, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %100 = bitcast <4 x i32> %99 to <2 x i64>
  %101 = bitcast <8 x i16> %85 to <4 x i32>
  %102 = bitcast <8 x i16> %92 to <4 x i32>
  %103 = shufflevector <4 x i32> %101, <4 x i32> %102, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %104 = bitcast <4 x i32> %103 to <2 x i64>
  %105 = bitcast <8 x i16> %93 to <4 x i32>
  %106 = bitcast <8 x i16> %94 to <4 x i32>
  %107 = shufflevector <4 x i32> %105, <4 x i32> %106, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %108 = bitcast <4 x i32> %107 to <2 x i64>
  %109 = bitcast <8 x i16> %95 to <4 x i32>
  %110 = bitcast <8 x i16> %96 to <4 x i32>
  %111 = shufflevector <4 x i32> %109, <4 x i32> %110, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %112 = bitcast <4 x i32> %111 to <2 x i64>
  %113 = shufflevector <4 x i32> %97, <4 x i32> %98, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %114 = bitcast <4 x i32> %113 to <2 x i64>
  %115 = shufflevector <4 x i32> %101, <4 x i32> %102, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %116 = bitcast <4 x i32> %115 to <2 x i64>
  %117 = shufflevector <4 x i32> %105, <4 x i32> %106, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %118 = bitcast <4 x i32> %117 to <2 x i64>
  %119 = shufflevector <4 x i32> %109, <4 x i32> %110, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %120 = bitcast <4 x i32> %119 to <2 x i64>
  %121 = shufflevector <2 x i64> %100, <2 x i64> %104, <2 x i32> <i32 0, i32 2>
  %122 = shufflevector <2 x i64> %100, <2 x i64> %104, <2 x i32> <i32 1, i32 3>
  %123 = shufflevector <2 x i64> %114, <2 x i64> %116, <2 x i32> <i32 0, i32 2>
  %124 = shufflevector <2 x i64> %114, <2 x i64> %116, <2 x i32> <i32 1, i32 3>
  %125 = shufflevector <2 x i64> %108, <2 x i64> %112, <2 x i32> <i32 0, i32 2>
  %126 = shufflevector <2 x i64> %108, <2 x i64> %112, <2 x i32> <i32 1, i32 3>
  %127 = shufflevector <2 x i64> %118, <2 x i64> %120, <2 x i32> <i32 0, i32 2>
  %128 = shufflevector <2 x i64> %118, <2 x i64> %120, <2 x i32> <i32 1, i32 3>
  %129 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 8
  %130 = bitcast <2 x i64>* %129 to <8 x i16>*
  %131 = load <8 x i16>, <8 x i16>* %130, align 16
  %132 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 9
  %133 = bitcast <2 x i64>* %132 to <8 x i16>*
  %134 = load <8 x i16>, <8 x i16>* %133, align 16
  %135 = shufflevector <8 x i16> %131, <8 x i16> %134, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %136 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 10
  %137 = bitcast <2 x i64>* %136 to <8 x i16>*
  %138 = load <8 x i16>, <8 x i16>* %137, align 16
  %139 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 11
  %140 = bitcast <2 x i64>* %139 to <8 x i16>*
  %141 = load <8 x i16>, <8 x i16>* %140, align 16
  %142 = shufflevector <8 x i16> %138, <8 x i16> %141, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %143 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 12
  %144 = bitcast <2 x i64>* %143 to <8 x i16>*
  %145 = load <8 x i16>, <8 x i16>* %144, align 16
  %146 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 13
  %147 = bitcast <2 x i64>* %146 to <8 x i16>*
  %148 = load <8 x i16>, <8 x i16>* %147, align 16
  %149 = shufflevector <8 x i16> %145, <8 x i16> %148, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %150 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 14
  %151 = bitcast <2 x i64>* %150 to <8 x i16>*
  %152 = load <8 x i16>, <8 x i16>* %151, align 16
  %153 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 15
  %154 = bitcast <2 x i64>* %153 to <8 x i16>*
  %155 = load <8 x i16>, <8 x i16>* %154, align 16
  %156 = shufflevector <8 x i16> %152, <8 x i16> %155, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %157 = shufflevector <8 x i16> %131, <8 x i16> %134, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %158 = shufflevector <8 x i16> %138, <8 x i16> %141, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %159 = shufflevector <8 x i16> %145, <8 x i16> %148, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %160 = shufflevector <8 x i16> %152, <8 x i16> %155, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %161 = bitcast <8 x i16> %135 to <4 x i32>
  %162 = bitcast <8 x i16> %142 to <4 x i32>
  %163 = shufflevector <4 x i32> %161, <4 x i32> %162, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %164 = bitcast <4 x i32> %163 to <2 x i64>
  %165 = bitcast <8 x i16> %149 to <4 x i32>
  %166 = bitcast <8 x i16> %156 to <4 x i32>
  %167 = shufflevector <4 x i32> %165, <4 x i32> %166, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %168 = bitcast <4 x i32> %167 to <2 x i64>
  %169 = bitcast <8 x i16> %157 to <4 x i32>
  %170 = bitcast <8 x i16> %158 to <4 x i32>
  %171 = shufflevector <4 x i32> %169, <4 x i32> %170, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %172 = bitcast <4 x i32> %171 to <2 x i64>
  %173 = bitcast <8 x i16> %159 to <4 x i32>
  %174 = bitcast <8 x i16> %160 to <4 x i32>
  %175 = shufflevector <4 x i32> %173, <4 x i32> %174, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %176 = bitcast <4 x i32> %175 to <2 x i64>
  %177 = shufflevector <4 x i32> %161, <4 x i32> %162, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %178 = bitcast <4 x i32> %177 to <2 x i64>
  %179 = shufflevector <4 x i32> %165, <4 x i32> %166, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %180 = bitcast <4 x i32> %179 to <2 x i64>
  %181 = shufflevector <4 x i32> %169, <4 x i32> %170, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %182 = bitcast <4 x i32> %181 to <2 x i64>
  %183 = shufflevector <4 x i32> %173, <4 x i32> %174, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %184 = bitcast <4 x i32> %183 to <2 x i64>
  %185 = shufflevector <2 x i64> %164, <2 x i64> %168, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %185, <2 x i64>* %1, align 16
  %186 = shufflevector <2 x i64> %164, <2 x i64> %168, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %186, <2 x i64>* %68, align 16
  %187 = shufflevector <2 x i64> %178, <2 x i64> %180, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %187, <2 x i64>* %72, align 16
  %188 = shufflevector <2 x i64> %178, <2 x i64> %180, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %188, <2 x i64>* %75, align 16
  %189 = shufflevector <2 x i64> %172, <2 x i64> %176, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %189, <2 x i64>* %79, align 16
  %190 = shufflevector <2 x i64> %172, <2 x i64> %176, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %190, <2 x i64>* %82, align 16
  %191 = shufflevector <2 x i64> %182, <2 x i64> %184, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %191, <2 x i64>* %86, align 16
  %192 = shufflevector <2 x i64> %182, <2 x i64> %184, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %192, <2 x i64>* %89, align 16
  %193 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 8
  %194 = bitcast <2 x i64>* %193 to <8 x i16>*
  %195 = load <8 x i16>, <8 x i16>* %194, align 16
  %196 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 9
  %197 = bitcast <2 x i64>* %196 to <8 x i16>*
  %198 = load <8 x i16>, <8 x i16>* %197, align 16
  %199 = shufflevector <8 x i16> %195, <8 x i16> %198, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %200 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 10
  %201 = bitcast <2 x i64>* %200 to <8 x i16>*
  %202 = load <8 x i16>, <8 x i16>* %201, align 16
  %203 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 11
  %204 = bitcast <2 x i64>* %203 to <8 x i16>*
  %205 = load <8 x i16>, <8 x i16>* %204, align 16
  %206 = shufflevector <8 x i16> %202, <8 x i16> %205, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %207 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 12
  %208 = bitcast <2 x i64>* %207 to <8 x i16>*
  %209 = load <8 x i16>, <8 x i16>* %208, align 16
  %210 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 13
  %211 = bitcast <2 x i64>* %210 to <8 x i16>*
  %212 = load <8 x i16>, <8 x i16>* %211, align 16
  %213 = shufflevector <8 x i16> %209, <8 x i16> %212, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %214 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 14
  %215 = bitcast <2 x i64>* %214 to <8 x i16>*
  %216 = load <8 x i16>, <8 x i16>* %215, align 16
  %217 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 15
  %218 = bitcast <2 x i64>* %217 to <8 x i16>*
  %219 = load <8 x i16>, <8 x i16>* %218, align 16
  %220 = shufflevector <8 x i16> %216, <8 x i16> %219, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %221 = shufflevector <8 x i16> %195, <8 x i16> %198, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %222 = shufflevector <8 x i16> %202, <8 x i16> %205, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %223 = shufflevector <8 x i16> %209, <8 x i16> %212, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %224 = shufflevector <8 x i16> %216, <8 x i16> %219, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %225 = bitcast <8 x i16> %199 to <4 x i32>
  %226 = bitcast <8 x i16> %206 to <4 x i32>
  %227 = shufflevector <4 x i32> %225, <4 x i32> %226, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %228 = bitcast <4 x i32> %227 to <2 x i64>
  %229 = bitcast <8 x i16> %213 to <4 x i32>
  %230 = bitcast <8 x i16> %220 to <4 x i32>
  %231 = shufflevector <4 x i32> %229, <4 x i32> %230, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %232 = bitcast <4 x i32> %231 to <2 x i64>
  %233 = bitcast <8 x i16> %221 to <4 x i32>
  %234 = bitcast <8 x i16> %222 to <4 x i32>
  %235 = shufflevector <4 x i32> %233, <4 x i32> %234, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %236 = bitcast <4 x i32> %235 to <2 x i64>
  %237 = bitcast <8 x i16> %223 to <4 x i32>
  %238 = bitcast <8 x i16> %224 to <4 x i32>
  %239 = shufflevector <4 x i32> %237, <4 x i32> %238, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %240 = bitcast <4 x i32> %239 to <2 x i64>
  %241 = shufflevector <4 x i32> %225, <4 x i32> %226, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %242 = bitcast <4 x i32> %241 to <2 x i64>
  %243 = shufflevector <4 x i32> %229, <4 x i32> %230, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %244 = bitcast <4 x i32> %243 to <2 x i64>
  %245 = shufflevector <4 x i32> %233, <4 x i32> %234, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %246 = bitcast <4 x i32> %245 to <2 x i64>
  %247 = shufflevector <4 x i32> %237, <4 x i32> %238, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %248 = bitcast <4 x i32> %247 to <2 x i64>
  %249 = shufflevector <2 x i64> %228, <2 x i64> %232, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %249, <2 x i64>* %193, align 16
  %250 = shufflevector <2 x i64> %228, <2 x i64> %232, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %250, <2 x i64>* %196, align 16
  %251 = shufflevector <2 x i64> %242, <2 x i64> %244, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %251, <2 x i64>* %200, align 16
  %252 = shufflevector <2 x i64> %242, <2 x i64> %244, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %252, <2 x i64>* %203, align 16
  %253 = shufflevector <2 x i64> %236, <2 x i64> %240, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %253, <2 x i64>* %207, align 16
  %254 = shufflevector <2 x i64> %236, <2 x i64> %240, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %254, <2 x i64>* %210, align 16
  %255 = shufflevector <2 x i64> %246, <2 x i64> %248, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %255, <2 x i64>* %214, align 16
  %256 = shufflevector <2 x i64> %246, <2 x i64> %248, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %256, <2 x i64>* %217, align 16
  store <2 x i64> %121, <2 x i64>* %129, align 16
  store <2 x i64> %122, <2 x i64>* %132, align 16
  store <2 x i64> %123, <2 x i64>* %136, align 16
  store <2 x i64> %124, <2 x i64>* %139, align 16
  store <2 x i64> %125, <2 x i64>* %143, align 16
  store <2 x i64> %126, <2 x i64>* %146, align 16
  store <2 x i64> %127, <2 x i64>* %150, align 16
  store <2 x i64> %128, <2 x i64>* %153, align 16
  tail call fastcc void @idct16_8col(<2 x i64>* %0, <2 x i64>* %0)
  tail call fastcc void @idct16_8col(<2 x i64>* %1, <2 x i64>* %1)
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @iadst16_sse2(<2 x i64>* nocapture, <2 x i64>* nocapture) local_unnamed_addr #2 {
  %3 = bitcast <2 x i64>* %0 to <8 x i16>*
  %4 = load <8 x i16>, <8 x i16>* %3, align 16
  %5 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %6 = bitcast <2 x i64>* %5 to <8 x i16>*
  %7 = load <8 x i16>, <8 x i16>* %6, align 16
  %8 = shufflevector <8 x i16> %4, <8 x i16> %7, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %9 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %10 = bitcast <2 x i64>* %9 to <8 x i16>*
  %11 = load <8 x i16>, <8 x i16>* %10, align 16
  %12 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %13 = bitcast <2 x i64>* %12 to <8 x i16>*
  %14 = load <8 x i16>, <8 x i16>* %13, align 16
  %15 = shufflevector <8 x i16> %11, <8 x i16> %14, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %16 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %17 = bitcast <2 x i64>* %16 to <8 x i16>*
  %18 = load <8 x i16>, <8 x i16>* %17, align 16
  %19 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %20 = bitcast <2 x i64>* %19 to <8 x i16>*
  %21 = load <8 x i16>, <8 x i16>* %20, align 16
  %22 = shufflevector <8 x i16> %18, <8 x i16> %21, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %23 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %24 = bitcast <2 x i64>* %23 to <8 x i16>*
  %25 = load <8 x i16>, <8 x i16>* %24, align 16
  %26 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %27 = bitcast <2 x i64>* %26 to <8 x i16>*
  %28 = load <8 x i16>, <8 x i16>* %27, align 16
  %29 = shufflevector <8 x i16> %25, <8 x i16> %28, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %30 = shufflevector <8 x i16> %4, <8 x i16> %7, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %31 = shufflevector <8 x i16> %11, <8 x i16> %14, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %32 = shufflevector <8 x i16> %18, <8 x i16> %21, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %33 = shufflevector <8 x i16> %25, <8 x i16> %28, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %34 = bitcast <8 x i16> %8 to <4 x i32>
  %35 = bitcast <8 x i16> %15 to <4 x i32>
  %36 = shufflevector <4 x i32> %34, <4 x i32> %35, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %37 = bitcast <4 x i32> %36 to <2 x i64>
  %38 = bitcast <8 x i16> %22 to <4 x i32>
  %39 = bitcast <8 x i16> %29 to <4 x i32>
  %40 = shufflevector <4 x i32> %38, <4 x i32> %39, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %41 = bitcast <4 x i32> %40 to <2 x i64>
  %42 = bitcast <8 x i16> %30 to <4 x i32>
  %43 = bitcast <8 x i16> %31 to <4 x i32>
  %44 = shufflevector <4 x i32> %42, <4 x i32> %43, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %45 = bitcast <4 x i32> %44 to <2 x i64>
  %46 = bitcast <8 x i16> %32 to <4 x i32>
  %47 = bitcast <8 x i16> %33 to <4 x i32>
  %48 = shufflevector <4 x i32> %46, <4 x i32> %47, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %49 = bitcast <4 x i32> %48 to <2 x i64>
  %50 = shufflevector <4 x i32> %34, <4 x i32> %35, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %51 = bitcast <4 x i32> %50 to <2 x i64>
  %52 = shufflevector <4 x i32> %38, <4 x i32> %39, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %53 = bitcast <4 x i32> %52 to <2 x i64>
  %54 = shufflevector <4 x i32> %42, <4 x i32> %43, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %55 = bitcast <4 x i32> %54 to <2 x i64>
  %56 = shufflevector <4 x i32> %46, <4 x i32> %47, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %57 = bitcast <4 x i32> %56 to <2 x i64>
  %58 = shufflevector <2 x i64> %37, <2 x i64> %41, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %58, <2 x i64>* %0, align 16
  %59 = shufflevector <2 x i64> %37, <2 x i64> %41, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %59, <2 x i64>* %5, align 16
  %60 = shufflevector <2 x i64> %51, <2 x i64> %53, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %60, <2 x i64>* %9, align 16
  %61 = shufflevector <2 x i64> %51, <2 x i64> %53, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %61, <2 x i64>* %12, align 16
  %62 = shufflevector <2 x i64> %45, <2 x i64> %49, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %62, <2 x i64>* %16, align 16
  %63 = shufflevector <2 x i64> %45, <2 x i64> %49, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %63, <2 x i64>* %19, align 16
  %64 = shufflevector <2 x i64> %55, <2 x i64> %57, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %64, <2 x i64>* %23, align 16
  %65 = shufflevector <2 x i64> %55, <2 x i64> %57, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %65, <2 x i64>* %26, align 16
  %66 = bitcast <2 x i64>* %1 to <8 x i16>*
  %67 = load <8 x i16>, <8 x i16>* %66, align 16
  %68 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %69 = bitcast <2 x i64>* %68 to <8 x i16>*
  %70 = load <8 x i16>, <8 x i16>* %69, align 16
  %71 = shufflevector <8 x i16> %67, <8 x i16> %70, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %72 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %73 = bitcast <2 x i64>* %72 to <8 x i16>*
  %74 = load <8 x i16>, <8 x i16>* %73, align 16
  %75 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %76 = bitcast <2 x i64>* %75 to <8 x i16>*
  %77 = load <8 x i16>, <8 x i16>* %76, align 16
  %78 = shufflevector <8 x i16> %74, <8 x i16> %77, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %79 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %80 = bitcast <2 x i64>* %79 to <8 x i16>*
  %81 = load <8 x i16>, <8 x i16>* %80, align 16
  %82 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %83 = bitcast <2 x i64>* %82 to <8 x i16>*
  %84 = load <8 x i16>, <8 x i16>* %83, align 16
  %85 = shufflevector <8 x i16> %81, <8 x i16> %84, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %86 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %87 = bitcast <2 x i64>* %86 to <8 x i16>*
  %88 = load <8 x i16>, <8 x i16>* %87, align 16
  %89 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %90 = bitcast <2 x i64>* %89 to <8 x i16>*
  %91 = load <8 x i16>, <8 x i16>* %90, align 16
  %92 = shufflevector <8 x i16> %88, <8 x i16> %91, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %93 = shufflevector <8 x i16> %67, <8 x i16> %70, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %94 = shufflevector <8 x i16> %74, <8 x i16> %77, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %95 = shufflevector <8 x i16> %81, <8 x i16> %84, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %96 = shufflevector <8 x i16> %88, <8 x i16> %91, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %97 = bitcast <8 x i16> %71 to <4 x i32>
  %98 = bitcast <8 x i16> %78 to <4 x i32>
  %99 = shufflevector <4 x i32> %97, <4 x i32> %98, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %100 = bitcast <4 x i32> %99 to <2 x i64>
  %101 = bitcast <8 x i16> %85 to <4 x i32>
  %102 = bitcast <8 x i16> %92 to <4 x i32>
  %103 = shufflevector <4 x i32> %101, <4 x i32> %102, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %104 = bitcast <4 x i32> %103 to <2 x i64>
  %105 = bitcast <8 x i16> %93 to <4 x i32>
  %106 = bitcast <8 x i16> %94 to <4 x i32>
  %107 = shufflevector <4 x i32> %105, <4 x i32> %106, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %108 = bitcast <4 x i32> %107 to <2 x i64>
  %109 = bitcast <8 x i16> %95 to <4 x i32>
  %110 = bitcast <8 x i16> %96 to <4 x i32>
  %111 = shufflevector <4 x i32> %109, <4 x i32> %110, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %112 = bitcast <4 x i32> %111 to <2 x i64>
  %113 = shufflevector <4 x i32> %97, <4 x i32> %98, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %114 = bitcast <4 x i32> %113 to <2 x i64>
  %115 = shufflevector <4 x i32> %101, <4 x i32> %102, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %116 = bitcast <4 x i32> %115 to <2 x i64>
  %117 = shufflevector <4 x i32> %105, <4 x i32> %106, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %118 = bitcast <4 x i32> %117 to <2 x i64>
  %119 = shufflevector <4 x i32> %109, <4 x i32> %110, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %120 = bitcast <4 x i32> %119 to <2 x i64>
  %121 = shufflevector <2 x i64> %100, <2 x i64> %104, <2 x i32> <i32 0, i32 2>
  %122 = shufflevector <2 x i64> %100, <2 x i64> %104, <2 x i32> <i32 1, i32 3>
  %123 = shufflevector <2 x i64> %114, <2 x i64> %116, <2 x i32> <i32 0, i32 2>
  %124 = shufflevector <2 x i64> %114, <2 x i64> %116, <2 x i32> <i32 1, i32 3>
  %125 = shufflevector <2 x i64> %108, <2 x i64> %112, <2 x i32> <i32 0, i32 2>
  %126 = shufflevector <2 x i64> %108, <2 x i64> %112, <2 x i32> <i32 1, i32 3>
  %127 = shufflevector <2 x i64> %118, <2 x i64> %120, <2 x i32> <i32 0, i32 2>
  %128 = shufflevector <2 x i64> %118, <2 x i64> %120, <2 x i32> <i32 1, i32 3>
  %129 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 8
  %130 = bitcast <2 x i64>* %129 to <8 x i16>*
  %131 = load <8 x i16>, <8 x i16>* %130, align 16
  %132 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 9
  %133 = bitcast <2 x i64>* %132 to <8 x i16>*
  %134 = load <8 x i16>, <8 x i16>* %133, align 16
  %135 = shufflevector <8 x i16> %131, <8 x i16> %134, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %136 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 10
  %137 = bitcast <2 x i64>* %136 to <8 x i16>*
  %138 = load <8 x i16>, <8 x i16>* %137, align 16
  %139 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 11
  %140 = bitcast <2 x i64>* %139 to <8 x i16>*
  %141 = load <8 x i16>, <8 x i16>* %140, align 16
  %142 = shufflevector <8 x i16> %138, <8 x i16> %141, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %143 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 12
  %144 = bitcast <2 x i64>* %143 to <8 x i16>*
  %145 = load <8 x i16>, <8 x i16>* %144, align 16
  %146 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 13
  %147 = bitcast <2 x i64>* %146 to <8 x i16>*
  %148 = load <8 x i16>, <8 x i16>* %147, align 16
  %149 = shufflevector <8 x i16> %145, <8 x i16> %148, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %150 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 14
  %151 = bitcast <2 x i64>* %150 to <8 x i16>*
  %152 = load <8 x i16>, <8 x i16>* %151, align 16
  %153 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 15
  %154 = bitcast <2 x i64>* %153 to <8 x i16>*
  %155 = load <8 x i16>, <8 x i16>* %154, align 16
  %156 = shufflevector <8 x i16> %152, <8 x i16> %155, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %157 = shufflevector <8 x i16> %131, <8 x i16> %134, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %158 = shufflevector <8 x i16> %138, <8 x i16> %141, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %159 = shufflevector <8 x i16> %145, <8 x i16> %148, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %160 = shufflevector <8 x i16> %152, <8 x i16> %155, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %161 = bitcast <8 x i16> %135 to <4 x i32>
  %162 = bitcast <8 x i16> %142 to <4 x i32>
  %163 = shufflevector <4 x i32> %161, <4 x i32> %162, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %164 = bitcast <4 x i32> %163 to <2 x i64>
  %165 = bitcast <8 x i16> %149 to <4 x i32>
  %166 = bitcast <8 x i16> %156 to <4 x i32>
  %167 = shufflevector <4 x i32> %165, <4 x i32> %166, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %168 = bitcast <4 x i32> %167 to <2 x i64>
  %169 = bitcast <8 x i16> %157 to <4 x i32>
  %170 = bitcast <8 x i16> %158 to <4 x i32>
  %171 = shufflevector <4 x i32> %169, <4 x i32> %170, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %172 = bitcast <4 x i32> %171 to <2 x i64>
  %173 = bitcast <8 x i16> %159 to <4 x i32>
  %174 = bitcast <8 x i16> %160 to <4 x i32>
  %175 = shufflevector <4 x i32> %173, <4 x i32> %174, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %176 = bitcast <4 x i32> %175 to <2 x i64>
  %177 = shufflevector <4 x i32> %161, <4 x i32> %162, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %178 = bitcast <4 x i32> %177 to <2 x i64>
  %179 = shufflevector <4 x i32> %165, <4 x i32> %166, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %180 = bitcast <4 x i32> %179 to <2 x i64>
  %181 = shufflevector <4 x i32> %169, <4 x i32> %170, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %182 = bitcast <4 x i32> %181 to <2 x i64>
  %183 = shufflevector <4 x i32> %173, <4 x i32> %174, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %184 = bitcast <4 x i32> %183 to <2 x i64>
  %185 = shufflevector <2 x i64> %164, <2 x i64> %168, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %185, <2 x i64>* %1, align 16
  %186 = shufflevector <2 x i64> %164, <2 x i64> %168, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %186, <2 x i64>* %68, align 16
  %187 = shufflevector <2 x i64> %178, <2 x i64> %180, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %187, <2 x i64>* %72, align 16
  %188 = shufflevector <2 x i64> %178, <2 x i64> %180, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %188, <2 x i64>* %75, align 16
  %189 = shufflevector <2 x i64> %172, <2 x i64> %176, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %189, <2 x i64>* %79, align 16
  %190 = shufflevector <2 x i64> %172, <2 x i64> %176, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %190, <2 x i64>* %82, align 16
  %191 = shufflevector <2 x i64> %182, <2 x i64> %184, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %191, <2 x i64>* %86, align 16
  %192 = shufflevector <2 x i64> %182, <2 x i64> %184, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %192, <2 x i64>* %89, align 16
  %193 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 8
  %194 = bitcast <2 x i64>* %193 to <8 x i16>*
  %195 = load <8 x i16>, <8 x i16>* %194, align 16
  %196 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 9
  %197 = bitcast <2 x i64>* %196 to <8 x i16>*
  %198 = load <8 x i16>, <8 x i16>* %197, align 16
  %199 = shufflevector <8 x i16> %195, <8 x i16> %198, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %200 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 10
  %201 = bitcast <2 x i64>* %200 to <8 x i16>*
  %202 = load <8 x i16>, <8 x i16>* %201, align 16
  %203 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 11
  %204 = bitcast <2 x i64>* %203 to <8 x i16>*
  %205 = load <8 x i16>, <8 x i16>* %204, align 16
  %206 = shufflevector <8 x i16> %202, <8 x i16> %205, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %207 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 12
  %208 = bitcast <2 x i64>* %207 to <8 x i16>*
  %209 = load <8 x i16>, <8 x i16>* %208, align 16
  %210 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 13
  %211 = bitcast <2 x i64>* %210 to <8 x i16>*
  %212 = load <8 x i16>, <8 x i16>* %211, align 16
  %213 = shufflevector <8 x i16> %209, <8 x i16> %212, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %214 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 14
  %215 = bitcast <2 x i64>* %214 to <8 x i16>*
  %216 = load <8 x i16>, <8 x i16>* %215, align 16
  %217 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 15
  %218 = bitcast <2 x i64>* %217 to <8 x i16>*
  %219 = load <8 x i16>, <8 x i16>* %218, align 16
  %220 = shufflevector <8 x i16> %216, <8 x i16> %219, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %221 = shufflevector <8 x i16> %195, <8 x i16> %198, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %222 = shufflevector <8 x i16> %202, <8 x i16> %205, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %223 = shufflevector <8 x i16> %209, <8 x i16> %212, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %224 = shufflevector <8 x i16> %216, <8 x i16> %219, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %225 = bitcast <8 x i16> %199 to <4 x i32>
  %226 = bitcast <8 x i16> %206 to <4 x i32>
  %227 = shufflevector <4 x i32> %225, <4 x i32> %226, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %228 = bitcast <4 x i32> %227 to <2 x i64>
  %229 = bitcast <8 x i16> %213 to <4 x i32>
  %230 = bitcast <8 x i16> %220 to <4 x i32>
  %231 = shufflevector <4 x i32> %229, <4 x i32> %230, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %232 = bitcast <4 x i32> %231 to <2 x i64>
  %233 = bitcast <8 x i16> %221 to <4 x i32>
  %234 = bitcast <8 x i16> %222 to <4 x i32>
  %235 = shufflevector <4 x i32> %233, <4 x i32> %234, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %236 = bitcast <4 x i32> %235 to <2 x i64>
  %237 = bitcast <8 x i16> %223 to <4 x i32>
  %238 = bitcast <8 x i16> %224 to <4 x i32>
  %239 = shufflevector <4 x i32> %237, <4 x i32> %238, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %240 = bitcast <4 x i32> %239 to <2 x i64>
  %241 = shufflevector <4 x i32> %225, <4 x i32> %226, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %242 = bitcast <4 x i32> %241 to <2 x i64>
  %243 = shufflevector <4 x i32> %229, <4 x i32> %230, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %244 = bitcast <4 x i32> %243 to <2 x i64>
  %245 = shufflevector <4 x i32> %233, <4 x i32> %234, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %246 = bitcast <4 x i32> %245 to <2 x i64>
  %247 = shufflevector <4 x i32> %237, <4 x i32> %238, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %248 = bitcast <4 x i32> %247 to <2 x i64>
  %249 = shufflevector <2 x i64> %228, <2 x i64> %232, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %249, <2 x i64>* %193, align 16
  %250 = shufflevector <2 x i64> %228, <2 x i64> %232, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %250, <2 x i64>* %196, align 16
  %251 = shufflevector <2 x i64> %242, <2 x i64> %244, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %251, <2 x i64>* %200, align 16
  %252 = shufflevector <2 x i64> %242, <2 x i64> %244, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %252, <2 x i64>* %203, align 16
  %253 = shufflevector <2 x i64> %236, <2 x i64> %240, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %253, <2 x i64>* %207, align 16
  %254 = shufflevector <2 x i64> %236, <2 x i64> %240, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %254, <2 x i64>* %210, align 16
  %255 = shufflevector <2 x i64> %246, <2 x i64> %248, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %255, <2 x i64>* %214, align 16
  %256 = shufflevector <2 x i64> %246, <2 x i64> %248, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %256, <2 x i64>* %217, align 16
  store <2 x i64> %121, <2 x i64>* %129, align 16
  store <2 x i64> %122, <2 x i64>* %132, align 16
  store <2 x i64> %123, <2 x i64>* %136, align 16
  store <2 x i64> %124, <2 x i64>* %139, align 16
  store <2 x i64> %125, <2 x i64>* %143, align 16
  store <2 x i64> %126, <2 x i64>* %146, align 16
  store <2 x i64> %127, <2 x i64>* %150, align 16
  store <2 x i64> %128, <2 x i64>* %153, align 16
  tail call void @vpx_iadst16_8col_sse2(<2 x i64>* %0)
  tail call void @vpx_iadst16_8col_sse2(<2 x i64>* %1)
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @idct32_34_8x32_sse2(<2 x i64>* nocapture readonly, <2 x i64>* nocapture) local_unnamed_addr #0 {
  %3 = alloca [32 x <2 x i64>], align 16
  %4 = bitcast [32 x <2 x i64>]* %3 to i8*
  call void @llvm.lifetime.start.p0i8(i64 512, i8* nonnull %4) #6
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %4, i8 -86, i64 512, i1 false)
  %5 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %6 = bitcast <2 x i64>* %5 to <8 x i16>*
  %7 = load <8 x i16>, <8 x i16>* %6, align 16
  %8 = shufflevector <8 x i16> %7, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %9 = shufflevector <8 x i16> %7, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %10 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #6
  %11 = add <4 x i32> %10, <i32 8192, i32 8192, i32 8192, i32 8192>
  %12 = ashr <4 x i32> %11, <i32 14, i32 14, i32 14, i32 14>
  %13 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #6
  %14 = add <4 x i32> %13, <i32 8192, i32 8192, i32 8192, i32 8192>
  %15 = ashr <4 x i32> %14, <i32 14, i32 14, i32 14, i32 14>
  %16 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %12, <4 x i32> %15) #6
  %17 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %8, <8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>) #6
  %18 = add <4 x i32> %17, <i32 8192, i32 8192, i32 8192, i32 8192>
  %19 = ashr <4 x i32> %18, <i32 14, i32 14, i32 14, i32 14>
  %20 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %9, <8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>) #6
  %21 = add <4 x i32> %20, <i32 8192, i32 8192, i32 8192, i32 8192>
  %22 = ashr <4 x i32> %21, <i32 14, i32 14, i32 14, i32 14>
  %23 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %19, <4 x i32> %22) #6
  %24 = bitcast <2 x i64>* %0 to <8 x i16>*
  %25 = load <8 x i16>, <8 x i16>* %24, align 16
  %26 = shufflevector <8 x i16> %25, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %27 = shufflevector <8 x i16> %25, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %28 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %26, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %29 = add <4 x i32> %28, <i32 8192, i32 8192, i32 8192, i32 8192>
  %30 = ashr <4 x i32> %29, <i32 14, i32 14, i32 14, i32 14>
  %31 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %27, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %32 = add <4 x i32> %31, <i32 8192, i32 8192, i32 8192, i32 8192>
  %33 = ashr <4 x i32> %32, <i32 14, i32 14, i32 14, i32 14>
  %34 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %30, <4 x i32> %33) #6
  %35 = shufflevector <8 x i16> %23, <8 x i16> %16, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %36 = shufflevector <8 x i16> %23, <8 x i16> %16, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %37 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %35, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %38 = add <4 x i32> %37, <i32 8192, i32 8192, i32 8192, i32 8192>
  %39 = ashr <4 x i32> %38, <i32 14, i32 14, i32 14, i32 14>
  %40 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %36, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %41 = add <4 x i32> %40, <i32 8192, i32 8192, i32 8192, i32 8192>
  %42 = ashr <4 x i32> %41, <i32 14, i32 14, i32 14, i32 14>
  %43 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %39, <4 x i32> %42) #6
  %44 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %35, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %45 = add <4 x i32> %44, <i32 8192, i32 8192, i32 8192, i32 8192>
  %46 = ashr <4 x i32> %45, <i32 14, i32 14, i32 14, i32 14>
  %47 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %36, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %48 = add <4 x i32> %47, <i32 8192, i32 8192, i32 8192, i32 8192>
  %49 = ashr <4 x i32> %48, <i32 14, i32 14, i32 14, i32 14>
  %50 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %46, <4 x i32> %49) #6
  %51 = add <8 x i16> %34, %23
  %52 = add <8 x i16> %50, %34
  %53 = add <8 x i16> %43, %34
  %54 = add <8 x i16> %34, %16
  %55 = sub <8 x i16> %34, %16
  %56 = sub <8 x i16> %34, %43
  %57 = sub <8 x i16> %34, %50
  %58 = sub <8 x i16> %34, %23
  %59 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %60 = bitcast <2 x i64>* %59 to <8 x i16>*
  %61 = load <8 x i16>, <8 x i16>* %60, align 16
  %62 = shufflevector <8 x i16> %61, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %63 = shufflevector <8 x i16> %61, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %64 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %62, <8 x i16> <i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305>) #6
  %65 = add <4 x i32> %64, <i32 8192, i32 8192, i32 8192, i32 8192>
  %66 = ashr <4 x i32> %65, <i32 14, i32 14, i32 14, i32 14>
  %67 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %63, <8 x i16> <i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305>) #6
  %68 = add <4 x i32> %67, <i32 8192, i32 8192, i32 8192, i32 8192>
  %69 = ashr <4 x i32> %68, <i32 14, i32 14, i32 14, i32 14>
  %70 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %66, <4 x i32> %69) #6
  %71 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %62, <8 x i16> <i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606>) #6
  %72 = add <4 x i32> %71, <i32 8192, i32 8192, i32 8192, i32 8192>
  %73 = ashr <4 x i32> %72, <i32 14, i32 14, i32 14, i32 14>
  %74 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %63, <8 x i16> <i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606>) #6
  %75 = add <4 x i32> %74, <i32 8192, i32 8192, i32 8192, i32 8192>
  %76 = ashr <4 x i32> %75, <i32 14, i32 14, i32 14, i32 14>
  %77 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %73, <4 x i32> %76) #6
  %78 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %79 = bitcast <2 x i64>* %78 to <8 x i16>*
  %80 = load <8 x i16>, <8 x i16>* %79, align 16
  %81 = shufflevector <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i16> %80, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %82 = shufflevector <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i16> %80, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %83 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %81, <8 x i16> <i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756>) #6
  %84 = add <4 x i32> %83, <i32 8192, i32 8192, i32 8192, i32 8192>
  %85 = ashr <4 x i32> %84, <i32 14, i32 14, i32 14, i32 14>
  %86 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %82, <8 x i16> <i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756>) #6
  %87 = add <4 x i32> %86, <i32 8192, i32 8192, i32 8192, i32 8192>
  %88 = ashr <4 x i32> %87, <i32 14, i32 14, i32 14, i32 14>
  %89 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %85, <4 x i32> %88) #6
  %90 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %81, <8 x i16> <i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679>) #6
  %91 = add <4 x i32> %90, <i32 8192, i32 8192, i32 8192, i32 8192>
  %92 = ashr <4 x i32> %91, <i32 14, i32 14, i32 14, i32 14>
  %93 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %82, <8 x i16> <i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679>) #6
  %94 = add <4 x i32> %93, <i32 8192, i32 8192, i32 8192, i32 8192>
  %95 = ashr <4 x i32> %94, <i32 14, i32 14, i32 14, i32 14>
  %96 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %92, <4 x i32> %95) #6
  %97 = shufflevector <8 x i16> %77, <8 x i16> %70, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %98 = shufflevector <8 x i16> %77, <8 x i16> %70, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %99 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %97, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %100 = add <4 x i32> %99, <i32 8192, i32 8192, i32 8192, i32 8192>
  %101 = ashr <4 x i32> %100, <i32 14, i32 14, i32 14, i32 14>
  %102 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %98, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %103 = add <4 x i32> %102, <i32 8192, i32 8192, i32 8192, i32 8192>
  %104 = ashr <4 x i32> %103, <i32 14, i32 14, i32 14, i32 14>
  %105 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %101, <4 x i32> %104) #6
  %106 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %97, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %107 = add <4 x i32> %106, <i32 8192, i32 8192, i32 8192, i32 8192>
  %108 = ashr <4 x i32> %107, <i32 14, i32 14, i32 14, i32 14>
  %109 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %98, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %110 = add <4 x i32> %109, <i32 8192, i32 8192, i32 8192, i32 8192>
  %111 = ashr <4 x i32> %110, <i32 14, i32 14, i32 14, i32 14>
  %112 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %108, <4 x i32> %111) #6
  %113 = shufflevector <8 x i16> %96, <8 x i16> %89, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %114 = shufflevector <8 x i16> %96, <8 x i16> %89, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %115 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %113, <8 x i16> <i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270>) #6
  %116 = add <4 x i32> %115, <i32 8192, i32 8192, i32 8192, i32 8192>
  %117 = ashr <4 x i32> %116, <i32 14, i32 14, i32 14, i32 14>
  %118 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %114, <8 x i16> <i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270>) #6
  %119 = add <4 x i32> %118, <i32 8192, i32 8192, i32 8192, i32 8192>
  %120 = ashr <4 x i32> %119, <i32 14, i32 14, i32 14, i32 14>
  %121 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %117, <4 x i32> %120) #6
  %122 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %113, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %123 = add <4 x i32> %122, <i32 8192, i32 8192, i32 8192, i32 8192>
  %124 = ashr <4 x i32> %123, <i32 14, i32 14, i32 14, i32 14>
  %125 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %114, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %126 = add <4 x i32> %125, <i32 8192, i32 8192, i32 8192, i32 8192>
  %127 = ashr <4 x i32> %126, <i32 14, i32 14, i32 14, i32 14>
  %128 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %124, <4 x i32> %127) #6
  %129 = add <8 x i16> %89, %70
  %130 = add <8 x i16> %121, %105
  %131 = sub <8 x i16> %105, %121
  %132 = sub <8 x i16> %70, %89
  %133 = sub <8 x i16> %77, %96
  %134 = sub <8 x i16> %112, %128
  %135 = add <8 x i16> %128, %112
  %136 = add <8 x i16> %96, %77
  %137 = shufflevector <8 x i16> %134, <8 x i16> %131, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %138 = shufflevector <8 x i16> %134, <8 x i16> %131, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %139 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %137, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %140 = add <4 x i32> %139, <i32 8192, i32 8192, i32 8192, i32 8192>
  %141 = ashr <4 x i32> %140, <i32 14, i32 14, i32 14, i32 14>
  %142 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %138, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %143 = add <4 x i32> %142, <i32 8192, i32 8192, i32 8192, i32 8192>
  %144 = ashr <4 x i32> %143, <i32 14, i32 14, i32 14, i32 14>
  %145 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %141, <4 x i32> %144) #6
  %146 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %137, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %147 = add <4 x i32> %146, <i32 8192, i32 8192, i32 8192, i32 8192>
  %148 = ashr <4 x i32> %147, <i32 14, i32 14, i32 14, i32 14>
  %149 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %138, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %150 = add <4 x i32> %149, <i32 8192, i32 8192, i32 8192, i32 8192>
  %151 = ashr <4 x i32> %150, <i32 14, i32 14, i32 14, i32 14>
  %152 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %148, <4 x i32> %151) #6
  %153 = shufflevector <8 x i16> %133, <8 x i16> %132, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %154 = shufflevector <8 x i16> %133, <8 x i16> %132, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %155 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %153, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %156 = add <4 x i32> %155, <i32 8192, i32 8192, i32 8192, i32 8192>
  %157 = ashr <4 x i32> %156, <i32 14, i32 14, i32 14, i32 14>
  %158 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %154, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %159 = add <4 x i32> %158, <i32 8192, i32 8192, i32 8192, i32 8192>
  %160 = ashr <4 x i32> %159, <i32 14, i32 14, i32 14, i32 14>
  %161 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %157, <4 x i32> %160) #6
  %162 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %153, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %163 = add <4 x i32> %162, <i32 8192, i32 8192, i32 8192, i32 8192>
  %164 = ashr <4 x i32> %163, <i32 14, i32 14, i32 14, i32 14>
  %165 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %154, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %166 = add <4 x i32> %165, <i32 8192, i32 8192, i32 8192, i32 8192>
  %167 = ashr <4 x i32> %166, <i32 14, i32 14, i32 14, i32 14>
  %168 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %164, <4 x i32> %167) #6
  %169 = add <8 x i16> %136, %51
  %170 = bitcast [32 x <2 x i64>]* %3 to <8 x i16>*
  store <8 x i16> %169, <8 x i16>* %170, align 16
  %171 = sub <8 x i16> %51, %136
  %172 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 15
  %173 = bitcast <2 x i64>* %172 to <8 x i16>*
  store <8 x i16> %171, <8 x i16>* %173, align 16
  %174 = add <8 x i16> %135, %52
  %175 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 1
  %176 = bitcast <2 x i64>* %175 to <8 x i16>*
  store <8 x i16> %174, <8 x i16>* %176, align 16
  %177 = sub <8 x i16> %52, %135
  %178 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 14
  %179 = bitcast <2 x i64>* %178 to <8 x i16>*
  store <8 x i16> %177, <8 x i16>* %179, align 16
  %180 = add <8 x i16> %152, %53
  %181 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 2
  %182 = bitcast <2 x i64>* %181 to <8 x i16>*
  store <8 x i16> %180, <8 x i16>* %182, align 16
  %183 = sub <8 x i16> %53, %152
  %184 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 13
  %185 = bitcast <2 x i64>* %184 to <8 x i16>*
  store <8 x i16> %183, <8 x i16>* %185, align 16
  %186 = add <8 x i16> %168, %54
  %187 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 3
  %188 = bitcast <2 x i64>* %187 to <8 x i16>*
  store <8 x i16> %186, <8 x i16>* %188, align 16
  %189 = sub <8 x i16> %54, %168
  %190 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 12
  %191 = bitcast <2 x i64>* %190 to <8 x i16>*
  store <8 x i16> %189, <8 x i16>* %191, align 16
  %192 = add <8 x i16> %161, %55
  %193 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 4
  %194 = bitcast <2 x i64>* %193 to <8 x i16>*
  store <8 x i16> %192, <8 x i16>* %194, align 16
  %195 = sub <8 x i16> %55, %161
  %196 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 11
  %197 = bitcast <2 x i64>* %196 to <8 x i16>*
  store <8 x i16> %195, <8 x i16>* %197, align 16
  %198 = add <8 x i16> %145, %56
  %199 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 5
  %200 = bitcast <2 x i64>* %199 to <8 x i16>*
  store <8 x i16> %198, <8 x i16>* %200, align 16
  %201 = sub <8 x i16> %56, %145
  %202 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 10
  %203 = bitcast <2 x i64>* %202 to <8 x i16>*
  store <8 x i16> %201, <8 x i16>* %203, align 16
  %204 = add <8 x i16> %130, %57
  %205 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 6
  %206 = bitcast <2 x i64>* %205 to <8 x i16>*
  store <8 x i16> %204, <8 x i16>* %206, align 16
  %207 = sub <8 x i16> %57, %130
  %208 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 9
  %209 = bitcast <2 x i64>* %208 to <8 x i16>*
  store <8 x i16> %207, <8 x i16>* %209, align 16
  %210 = add <8 x i16> %129, %58
  %211 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 7
  %212 = bitcast <2 x i64>* %211 to <8 x i16>*
  store <8 x i16> %210, <8 x i16>* %212, align 16
  %213 = sub <8 x i16> %58, %129
  %214 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 8
  %215 = bitcast <2 x i64>* %214 to <8 x i16>*
  store <8 x i16> %213, <8 x i16>* %215, align 16
  %216 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %217 = bitcast <2 x i64>* %216 to <8 x i16>*
  %218 = load <8 x i16>, <8 x i16>* %217, align 16
  %219 = shufflevector <8 x i16> %218, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %220 = shufflevector <8 x i16> %218, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %221 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %219, <8 x i16> <i16 804, i16 -16364, i16 804, i16 -16364, i16 804, i16 -16364, i16 804, i16 -16364>) #6
  %222 = add <4 x i32> %221, <i32 8192, i32 8192, i32 8192, i32 8192>
  %223 = ashr <4 x i32> %222, <i32 14, i32 14, i32 14, i32 14>
  %224 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %220, <8 x i16> <i16 804, i16 -16364, i16 804, i16 -16364, i16 804, i16 -16364, i16 804, i16 -16364>) #6
  %225 = add <4 x i32> %224, <i32 8192, i32 8192, i32 8192, i32 8192>
  %226 = ashr <4 x i32> %225, <i32 14, i32 14, i32 14, i32 14>
  %227 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %223, <4 x i32> %226) #6
  %228 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %219, <8 x i16> <i16 16364, i16 804, i16 16364, i16 804, i16 16364, i16 804, i16 16364, i16 804>) #6
  %229 = add <4 x i32> %228, <i32 8192, i32 8192, i32 8192, i32 8192>
  %230 = ashr <4 x i32> %229, <i32 14, i32 14, i32 14, i32 14>
  %231 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %220, <8 x i16> <i16 16364, i16 804, i16 16364, i16 804, i16 16364, i16 804, i16 16364, i16 804>) #6
  %232 = add <4 x i32> %231, <i32 8192, i32 8192, i32 8192, i32 8192>
  %233 = ashr <4 x i32> %232, <i32 14, i32 14, i32 14, i32 14>
  %234 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %230, <4 x i32> %233) #6
  %235 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %236 = bitcast <2 x i64>* %235 to <8 x i16>*
  %237 = load <8 x i16>, <8 x i16>* %236, align 16
  %238 = shufflevector <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i16> %237, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %239 = shufflevector <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i16> %237, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %240 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %238, <8 x i16> <i16 15426, i16 -5520, i16 15426, i16 -5520, i16 15426, i16 -5520, i16 15426, i16 -5520>) #6
  %241 = add <4 x i32> %240, <i32 8192, i32 8192, i32 8192, i32 8192>
  %242 = ashr <4 x i32> %241, <i32 14, i32 14, i32 14, i32 14>
  %243 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %239, <8 x i16> <i16 15426, i16 -5520, i16 15426, i16 -5520, i16 15426, i16 -5520, i16 15426, i16 -5520>) #6
  %244 = add <4 x i32> %243, <i32 8192, i32 8192, i32 8192, i32 8192>
  %245 = ashr <4 x i32> %244, <i32 14, i32 14, i32 14, i32 14>
  %246 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %242, <4 x i32> %245) #6
  %247 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %238, <8 x i16> <i16 5520, i16 15426, i16 5520, i16 15426, i16 5520, i16 15426, i16 5520, i16 15426>) #6
  %248 = add <4 x i32> %247, <i32 8192, i32 8192, i32 8192, i32 8192>
  %249 = ashr <4 x i32> %248, <i32 14, i32 14, i32 14, i32 14>
  %250 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %239, <8 x i16> <i16 5520, i16 15426, i16 5520, i16 15426, i16 5520, i16 15426, i16 5520, i16 15426>) #6
  %251 = add <4 x i32> %250, <i32 8192, i32 8192, i32 8192, i32 8192>
  %252 = ashr <4 x i32> %251, <i32 14, i32 14, i32 14, i32 14>
  %253 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %249, <4 x i32> %252) #6
  %254 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %255 = bitcast <2 x i64>* %254 to <8 x i16>*
  %256 = load <8 x i16>, <8 x i16>* %255, align 16
  %257 = shufflevector <8 x i16> %256, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %258 = shufflevector <8 x i16> %256, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %259 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %257, <8 x i16> <i16 3981, i16 -15893, i16 3981, i16 -15893, i16 3981, i16 -15893, i16 3981, i16 -15893>) #6
  %260 = add <4 x i32> %259, <i32 8192, i32 8192, i32 8192, i32 8192>
  %261 = ashr <4 x i32> %260, <i32 14, i32 14, i32 14, i32 14>
  %262 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %258, <8 x i16> <i16 3981, i16 -15893, i16 3981, i16 -15893, i16 3981, i16 -15893, i16 3981, i16 -15893>) #6
  %263 = add <4 x i32> %262, <i32 8192, i32 8192, i32 8192, i32 8192>
  %264 = ashr <4 x i32> %263, <i32 14, i32 14, i32 14, i32 14>
  %265 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %261, <4 x i32> %264) #6
  %266 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %257, <8 x i16> <i16 15893, i16 3981, i16 15893, i16 3981, i16 15893, i16 3981, i16 15893, i16 3981>) #6
  %267 = add <4 x i32> %266, <i32 8192, i32 8192, i32 8192, i32 8192>
  %268 = ashr <4 x i32> %267, <i32 14, i32 14, i32 14, i32 14>
  %269 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %258, <8 x i16> <i16 15893, i16 3981, i16 15893, i16 3981, i16 15893, i16 3981, i16 15893, i16 3981>) #6
  %270 = add <4 x i32> %269, <i32 8192, i32 8192, i32 8192, i32 8192>
  %271 = ashr <4 x i32> %270, <i32 14, i32 14, i32 14, i32 14>
  %272 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %268, <4 x i32> %271) #6
  %273 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %274 = bitcast <2 x i64>* %273 to <8 x i16>*
  %275 = load <8 x i16>, <8 x i16>* %274, align 16
  %276 = shufflevector <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i16> %275, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %277 = shufflevector <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i16> %275, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %278 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %276, <8 x i16> <i16 16207, i16 -2404, i16 16207, i16 -2404, i16 16207, i16 -2404, i16 16207, i16 -2404>) #6
  %279 = add <4 x i32> %278, <i32 8192, i32 8192, i32 8192, i32 8192>
  %280 = ashr <4 x i32> %279, <i32 14, i32 14, i32 14, i32 14>
  %281 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %277, <8 x i16> <i16 16207, i16 -2404, i16 16207, i16 -2404, i16 16207, i16 -2404, i16 16207, i16 -2404>) #6
  %282 = add <4 x i32> %281, <i32 8192, i32 8192, i32 8192, i32 8192>
  %283 = ashr <4 x i32> %282, <i32 14, i32 14, i32 14, i32 14>
  %284 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %280, <4 x i32> %283) #6
  %285 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %276, <8 x i16> <i16 2404, i16 16207, i16 2404, i16 16207, i16 2404, i16 16207, i16 2404, i16 16207>) #6
  %286 = add <4 x i32> %285, <i32 8192, i32 8192, i32 8192, i32 8192>
  %287 = ashr <4 x i32> %286, <i32 14, i32 14, i32 14, i32 14>
  %288 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %277, <8 x i16> <i16 2404, i16 16207, i16 2404, i16 16207, i16 2404, i16 16207, i16 2404, i16 16207>) #6
  %289 = add <4 x i32> %288, <i32 8192, i32 8192, i32 8192, i32 8192>
  %290 = ashr <4 x i32> %289, <i32 14, i32 14, i32 14, i32 14>
  %291 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %287, <4 x i32> %290) #6
  %292 = shufflevector <8 x i16> %234, <8 x i16> %227, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %293 = shufflevector <8 x i16> %234, <8 x i16> %227, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %294 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %292, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #6
  %295 = add <4 x i32> %294, <i32 8192, i32 8192, i32 8192, i32 8192>
  %296 = ashr <4 x i32> %295, <i32 14, i32 14, i32 14, i32 14>
  %297 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %293, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #6
  %298 = add <4 x i32> %297, <i32 8192, i32 8192, i32 8192, i32 8192>
  %299 = ashr <4 x i32> %298, <i32 14, i32 14, i32 14, i32 14>
  %300 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %296, <4 x i32> %299) #6
  %301 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %292, <8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>) #6
  %302 = add <4 x i32> %301, <i32 8192, i32 8192, i32 8192, i32 8192>
  %303 = ashr <4 x i32> %302, <i32 14, i32 14, i32 14, i32 14>
  %304 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %293, <8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>) #6
  %305 = add <4 x i32> %304, <i32 8192, i32 8192, i32 8192, i32 8192>
  %306 = ashr <4 x i32> %305, <i32 14, i32 14, i32 14, i32 14>
  %307 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %303, <4 x i32> %306) #6
  %308 = shufflevector <8 x i16> %253, <8 x i16> %246, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %309 = shufflevector <8 x i16> %253, <8 x i16> %246, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %310 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %308, <8 x i16> <i16 -16069, i16 -3196, i16 -16069, i16 -3196, i16 -16069, i16 -3196, i16 -16069, i16 -3196>) #6
  %311 = add <4 x i32> %310, <i32 8192, i32 8192, i32 8192, i32 8192>
  %312 = ashr <4 x i32> %311, <i32 14, i32 14, i32 14, i32 14>
  %313 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %309, <8 x i16> <i16 -16069, i16 -3196, i16 -16069, i16 -3196, i16 -16069, i16 -3196, i16 -16069, i16 -3196>) #6
  %314 = add <4 x i32> %313, <i32 8192, i32 8192, i32 8192, i32 8192>
  %315 = ashr <4 x i32> %314, <i32 14, i32 14, i32 14, i32 14>
  %316 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %312, <4 x i32> %315) #6
  %317 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %308, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #6
  %318 = add <4 x i32> %317, <i32 8192, i32 8192, i32 8192, i32 8192>
  %319 = ashr <4 x i32> %318, <i32 14, i32 14, i32 14, i32 14>
  %320 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %309, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #6
  %321 = add <4 x i32> %320, <i32 8192, i32 8192, i32 8192, i32 8192>
  %322 = ashr <4 x i32> %321, <i32 14, i32 14, i32 14, i32 14>
  %323 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %319, <4 x i32> %322) #6
  %324 = shufflevector <8 x i16> %272, <8 x i16> %265, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %325 = shufflevector <8 x i16> %272, <8 x i16> %265, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %326 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %324, <8 x i16> <i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102>) #6
  %327 = add <4 x i32> %326, <i32 8192, i32 8192, i32 8192, i32 8192>
  %328 = ashr <4 x i32> %327, <i32 14, i32 14, i32 14, i32 14>
  %329 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %325, <8 x i16> <i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102>) #6
  %330 = add <4 x i32> %329, <i32 8192, i32 8192, i32 8192, i32 8192>
  %331 = ashr <4 x i32> %330, <i32 14, i32 14, i32 14, i32 14>
  %332 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %328, <4 x i32> %331) #6
  %333 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %324, <8 x i16> <i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623>) #6
  %334 = add <4 x i32> %333, <i32 8192, i32 8192, i32 8192, i32 8192>
  %335 = ashr <4 x i32> %334, <i32 14, i32 14, i32 14, i32 14>
  %336 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %325, <8 x i16> <i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623>) #6
  %337 = add <4 x i32> %336, <i32 8192, i32 8192, i32 8192, i32 8192>
  %338 = ashr <4 x i32> %337, <i32 14, i32 14, i32 14, i32 14>
  %339 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %335, <4 x i32> %338) #6
  %340 = shufflevector <8 x i16> %291, <8 x i16> %284, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %341 = shufflevector <8 x i16> %291, <8 x i16> %284, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %342 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %340, <8 x i16> <i16 -9102, i16 -13623, i16 -9102, i16 -13623, i16 -9102, i16 -13623, i16 -9102, i16 -13623>) #6
  %343 = add <4 x i32> %342, <i32 8192, i32 8192, i32 8192, i32 8192>
  %344 = ashr <4 x i32> %343, <i32 14, i32 14, i32 14, i32 14>
  %345 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %341, <8 x i16> <i16 -9102, i16 -13623, i16 -9102, i16 -13623, i16 -9102, i16 -13623, i16 -9102, i16 -13623>) #6
  %346 = add <4 x i32> %345, <i32 8192, i32 8192, i32 8192, i32 8192>
  %347 = ashr <4 x i32> %346, <i32 14, i32 14, i32 14, i32 14>
  %348 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %344, <4 x i32> %347) #6
  %349 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %340, <8 x i16> <i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102>) #6
  %350 = add <4 x i32> %349, <i32 8192, i32 8192, i32 8192, i32 8192>
  %351 = ashr <4 x i32> %350, <i32 14, i32 14, i32 14, i32 14>
  %352 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %341, <8 x i16> <i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102>) #6
  %353 = add <4 x i32> %352, <i32 8192, i32 8192, i32 8192, i32 8192>
  %354 = ashr <4 x i32> %353, <i32 14, i32 14, i32 14, i32 14>
  %355 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %351, <4 x i32> %354) #6
  %356 = add <8 x i16> %246, %227
  %357 = add <8 x i16> %316, %300
  %358 = sub <8 x i16> %300, %316
  %359 = sub <8 x i16> %227, %246
  %360 = sub <8 x i16> %284, %265
  %361 = sub <8 x i16> %348, %332
  %362 = add <8 x i16> %348, %332
  %363 = add <8 x i16> %284, %265
  %364 = add <8 x i16> %291, %272
  %365 = add <8 x i16> %355, %339
  %366 = sub <8 x i16> %355, %339
  %367 = sub <8 x i16> %291, %272
  %368 = sub <8 x i16> %234, %253
  %369 = sub <8 x i16> %307, %323
  %370 = add <8 x i16> %323, %307
  %371 = add <8 x i16> %253, %234
  %372 = shufflevector <8 x i16> %369, <8 x i16> %358, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %373 = shufflevector <8 x i16> %369, <8 x i16> %358, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %374 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %372, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %375 = add <4 x i32> %374, <i32 8192, i32 8192, i32 8192, i32 8192>
  %376 = ashr <4 x i32> %375, <i32 14, i32 14, i32 14, i32 14>
  %377 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %373, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %378 = add <4 x i32> %377, <i32 8192, i32 8192, i32 8192, i32 8192>
  %379 = ashr <4 x i32> %378, <i32 14, i32 14, i32 14, i32 14>
  %380 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %376, <4 x i32> %379) #6
  %381 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %372, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %382 = add <4 x i32> %381, <i32 8192, i32 8192, i32 8192, i32 8192>
  %383 = ashr <4 x i32> %382, <i32 14, i32 14, i32 14, i32 14>
  %384 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %373, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %385 = add <4 x i32> %384, <i32 8192, i32 8192, i32 8192, i32 8192>
  %386 = ashr <4 x i32> %385, <i32 14, i32 14, i32 14, i32 14>
  %387 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %383, <4 x i32> %386) #6
  %388 = shufflevector <8 x i16> %368, <8 x i16> %359, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %389 = shufflevector <8 x i16> %368, <8 x i16> %359, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %390 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %388, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %391 = add <4 x i32> %390, <i32 8192, i32 8192, i32 8192, i32 8192>
  %392 = ashr <4 x i32> %391, <i32 14, i32 14, i32 14, i32 14>
  %393 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %389, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %394 = add <4 x i32> %393, <i32 8192, i32 8192, i32 8192, i32 8192>
  %395 = ashr <4 x i32> %394, <i32 14, i32 14, i32 14, i32 14>
  %396 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %392, <4 x i32> %395) #6
  %397 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %388, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %398 = add <4 x i32> %397, <i32 8192, i32 8192, i32 8192, i32 8192>
  %399 = ashr <4 x i32> %398, <i32 14, i32 14, i32 14, i32 14>
  %400 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %389, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %401 = add <4 x i32> %400, <i32 8192, i32 8192, i32 8192, i32 8192>
  %402 = ashr <4 x i32> %401, <i32 14, i32 14, i32 14, i32 14>
  %403 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %399, <4 x i32> %402) #6
  %404 = shufflevector <8 x i16> %367, <8 x i16> %360, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %405 = shufflevector <8 x i16> %367, <8 x i16> %360, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %406 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %404, <8 x i16> <i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270>) #6
  %407 = add <4 x i32> %406, <i32 8192, i32 8192, i32 8192, i32 8192>
  %408 = ashr <4 x i32> %407, <i32 14, i32 14, i32 14, i32 14>
  %409 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %405, <8 x i16> <i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270>) #6
  %410 = add <4 x i32> %409, <i32 8192, i32 8192, i32 8192, i32 8192>
  %411 = ashr <4 x i32> %410, <i32 14, i32 14, i32 14, i32 14>
  %412 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %408, <4 x i32> %411) #6
  %413 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %404, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %414 = add <4 x i32> %413, <i32 8192, i32 8192, i32 8192, i32 8192>
  %415 = ashr <4 x i32> %414, <i32 14, i32 14, i32 14, i32 14>
  %416 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %405, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %417 = add <4 x i32> %416, <i32 8192, i32 8192, i32 8192, i32 8192>
  %418 = ashr <4 x i32> %417, <i32 14, i32 14, i32 14, i32 14>
  %419 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %415, <4 x i32> %418) #6
  %420 = shufflevector <8 x i16> %366, <8 x i16> %361, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %421 = shufflevector <8 x i16> %366, <8 x i16> %361, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %422 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %420, <8 x i16> <i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270>) #6
  %423 = add <4 x i32> %422, <i32 8192, i32 8192, i32 8192, i32 8192>
  %424 = ashr <4 x i32> %423, <i32 14, i32 14, i32 14, i32 14>
  %425 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %421, <8 x i16> <i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270>) #6
  %426 = add <4 x i32> %425, <i32 8192, i32 8192, i32 8192, i32 8192>
  %427 = ashr <4 x i32> %426, <i32 14, i32 14, i32 14, i32 14>
  %428 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %424, <4 x i32> %427) #6
  %429 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %420, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %430 = add <4 x i32> %429, <i32 8192, i32 8192, i32 8192, i32 8192>
  %431 = ashr <4 x i32> %430, <i32 14, i32 14, i32 14, i32 14>
  %432 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %421, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %433 = add <4 x i32> %432, <i32 8192, i32 8192, i32 8192, i32 8192>
  %434 = ashr <4 x i32> %433, <i32 14, i32 14, i32 14, i32 14>
  %435 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %431, <4 x i32> %434) #6
  %436 = add <8 x i16> %363, %356
  %437 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 16
  %438 = bitcast <2 x i64>* %437 to <8 x i16>*
  store <8 x i16> %436, <8 x i16>* %438, align 16
  %439 = add <8 x i16> %362, %357
  %440 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 17
  %441 = bitcast <2 x i64>* %440 to <8 x i16>*
  store <8 x i16> %439, <8 x i16>* %441, align 16
  %442 = add <8 x i16> %428, %380
  %443 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 18
  %444 = bitcast <2 x i64>* %443 to <8 x i16>*
  store <8 x i16> %442, <8 x i16>* %444, align 16
  %445 = add <8 x i16> %412, %396
  %446 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 19
  %447 = bitcast <2 x i64>* %446 to <8 x i16>*
  store <8 x i16> %445, <8 x i16>* %447, align 16
  %448 = sub <8 x i16> %396, %412
  %449 = sub <8 x i16> %380, %428
  %450 = sub <8 x i16> %357, %362
  %451 = sub <8 x i16> %356, %363
  %452 = sub <8 x i16> %371, %364
  %453 = sub <8 x i16> %370, %365
  %454 = sub <8 x i16> %387, %435
  %455 = sub <8 x i16> %403, %419
  %456 = add <8 x i16> %419, %403
  %457 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 28
  %458 = bitcast <2 x i64>* %457 to <8 x i16>*
  store <8 x i16> %456, <8 x i16>* %458, align 16
  %459 = add <8 x i16> %435, %387
  %460 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 29
  %461 = bitcast <2 x i64>* %460 to <8 x i16>*
  store <8 x i16> %459, <8 x i16>* %461, align 16
  %462 = add <8 x i16> %365, %370
  %463 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 30
  %464 = bitcast <2 x i64>* %463 to <8 x i16>*
  store <8 x i16> %462, <8 x i16>* %464, align 16
  %465 = add <8 x i16> %364, %371
  %466 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 31
  %467 = bitcast <2 x i64>* %466 to <8 x i16>*
  store <8 x i16> %465, <8 x i16>* %467, align 16
  %468 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 20
  %469 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 27
  %470 = shufflevector <8 x i16> %455, <8 x i16> %448, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %471 = shufflevector <8 x i16> %455, <8 x i16> %448, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %472 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %470, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %473 = add <4 x i32> %472, <i32 8192, i32 8192, i32 8192, i32 8192>
  %474 = ashr <4 x i32> %473, <i32 14, i32 14, i32 14, i32 14>
  %475 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %471, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %476 = add <4 x i32> %475, <i32 8192, i32 8192, i32 8192, i32 8192>
  %477 = ashr <4 x i32> %476, <i32 14, i32 14, i32 14, i32 14>
  %478 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %474, <4 x i32> %477) #6
  %479 = bitcast <2 x i64>* %468 to <8 x i16>*
  store <8 x i16> %478, <8 x i16>* %479, align 16
  %480 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %470, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %481 = add <4 x i32> %480, <i32 8192, i32 8192, i32 8192, i32 8192>
  %482 = ashr <4 x i32> %481, <i32 14, i32 14, i32 14, i32 14>
  %483 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %471, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %484 = add <4 x i32> %483, <i32 8192, i32 8192, i32 8192, i32 8192>
  %485 = ashr <4 x i32> %484, <i32 14, i32 14, i32 14, i32 14>
  %486 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %482, <4 x i32> %485) #6
  %487 = bitcast <2 x i64>* %469 to <8 x i16>*
  store <8 x i16> %486, <8 x i16>* %487, align 16
  %488 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 21
  %489 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 26
  %490 = shufflevector <8 x i16> %454, <8 x i16> %449, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %491 = shufflevector <8 x i16> %454, <8 x i16> %449, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %492 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %490, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %493 = add <4 x i32> %492, <i32 8192, i32 8192, i32 8192, i32 8192>
  %494 = ashr <4 x i32> %493, <i32 14, i32 14, i32 14, i32 14>
  %495 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %491, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %496 = add <4 x i32> %495, <i32 8192, i32 8192, i32 8192, i32 8192>
  %497 = ashr <4 x i32> %496, <i32 14, i32 14, i32 14, i32 14>
  %498 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %494, <4 x i32> %497) #6
  %499 = bitcast <2 x i64>* %488 to <8 x i16>*
  store <8 x i16> %498, <8 x i16>* %499, align 16
  %500 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %490, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %501 = add <4 x i32> %500, <i32 8192, i32 8192, i32 8192, i32 8192>
  %502 = ashr <4 x i32> %501, <i32 14, i32 14, i32 14, i32 14>
  %503 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %491, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %504 = add <4 x i32> %503, <i32 8192, i32 8192, i32 8192, i32 8192>
  %505 = ashr <4 x i32> %504, <i32 14, i32 14, i32 14, i32 14>
  %506 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %502, <4 x i32> %505) #6
  %507 = bitcast <2 x i64>* %489 to <8 x i16>*
  store <8 x i16> %506, <8 x i16>* %507, align 16
  %508 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 22
  %509 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 25
  %510 = shufflevector <8 x i16> %453, <8 x i16> %450, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %511 = shufflevector <8 x i16> %453, <8 x i16> %450, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %512 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %510, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %513 = add <4 x i32> %512, <i32 8192, i32 8192, i32 8192, i32 8192>
  %514 = ashr <4 x i32> %513, <i32 14, i32 14, i32 14, i32 14>
  %515 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %511, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %516 = add <4 x i32> %515, <i32 8192, i32 8192, i32 8192, i32 8192>
  %517 = ashr <4 x i32> %516, <i32 14, i32 14, i32 14, i32 14>
  %518 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %514, <4 x i32> %517) #6
  %519 = bitcast <2 x i64>* %508 to <8 x i16>*
  store <8 x i16> %518, <8 x i16>* %519, align 16
  %520 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %510, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %521 = add <4 x i32> %520, <i32 8192, i32 8192, i32 8192, i32 8192>
  %522 = ashr <4 x i32> %521, <i32 14, i32 14, i32 14, i32 14>
  %523 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %511, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %524 = add <4 x i32> %523, <i32 8192, i32 8192, i32 8192, i32 8192>
  %525 = ashr <4 x i32> %524, <i32 14, i32 14, i32 14, i32 14>
  %526 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %522, <4 x i32> %525) #6
  %527 = bitcast <2 x i64>* %509 to <8 x i16>*
  store <8 x i16> %526, <8 x i16>* %527, align 16
  %528 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 23
  %529 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 24
  %530 = shufflevector <8 x i16> %452, <8 x i16> %451, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %531 = shufflevector <8 x i16> %452, <8 x i16> %451, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %532 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %530, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %533 = add <4 x i32> %532, <i32 8192, i32 8192, i32 8192, i32 8192>
  %534 = ashr <4 x i32> %533, <i32 14, i32 14, i32 14, i32 14>
  %535 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %531, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %536 = add <4 x i32> %535, <i32 8192, i32 8192, i32 8192, i32 8192>
  %537 = ashr <4 x i32> %536, <i32 14, i32 14, i32 14, i32 14>
  %538 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %534, <4 x i32> %537) #6
  %539 = bitcast <2 x i64>* %528 to <8 x i16>*
  store <8 x i16> %538, <8 x i16>* %539, align 16
  %540 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %530, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %541 = add <4 x i32> %540, <i32 8192, i32 8192, i32 8192, i32 8192>
  %542 = ashr <4 x i32> %541, <i32 14, i32 14, i32 14, i32 14>
  %543 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %531, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %544 = add <4 x i32> %543, <i32 8192, i32 8192, i32 8192, i32 8192>
  %545 = ashr <4 x i32> %544, <i32 14, i32 14, i32 14, i32 14>
  %546 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %542, <4 x i32> %545) #6
  %547 = bitcast <2 x i64>* %529 to <8 x i16>*
  store <8 x i16> %546, <8 x i16>* %547, align 16
  br label %548

548:                                              ; preds = %548, %2
  %549 = phi i64 [ 0, %2 ], [ %565, %548 ]
  %550 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 %549
  %551 = bitcast <2 x i64>* %550 to <8 x i16>*
  %552 = load <8 x i16>, <8 x i16>* %551, align 16
  %553 = shl i64 %549, 32
  %554 = sub nuw nsw i64 133143986176, %553
  %555 = ashr exact i64 %554, 32
  %556 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 %555
  %557 = bitcast <2 x i64>* %556 to <8 x i16>*
  %558 = load <8 x i16>, <8 x i16>* %557, align 16
  %559 = add <8 x i16> %558, %552
  %560 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %549
  %561 = bitcast <2 x i64>* %560 to <8 x i16>*
  store <8 x i16> %559, <8 x i16>* %561, align 16
  %562 = sub <8 x i16> %552, %558
  %563 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %555
  %564 = bitcast <2 x i64>* %563 to <8 x i16>*
  store <8 x i16> %562, <8 x i16>* %564, align 16
  %565 = add nuw nsw i64 %549, 1
  %566 = icmp eq i64 %565, 16
  br i1 %566, label %567, label %548

567:                                              ; preds = %548
  call void @llvm.lifetime.end.p0i8(i64 512, i8* nonnull %4) #6
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @vpx_idct32x32_34_add_sse2(i32* nocapture readonly, i8* nocapture, i32) local_unnamed_addr #0 {
  %4 = alloca [32 x <2 x i64>], align 16
  %5 = alloca [32 x <2 x i64>], align 16
  %6 = bitcast [32 x <2 x i64>]* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 512, i8* nonnull %6) #6
  %7 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %4, i64 0, i64 7
  %8 = bitcast <2 x i64>* %7 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %8, i8 -86, i64 400, i1 false)
  %9 = bitcast [32 x <2 x i64>]* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 512, i8* nonnull %9) #6
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 512, i1 false)
  %10 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %4, i64 0, i64 0
  %11 = bitcast i32* %0 to <4 x i32>*
  %12 = load <4 x i32>, <4 x i32>* %11, align 16
  %13 = getelementptr inbounds i32, i32* %0, i64 4
  %14 = bitcast i32* %13 to <4 x i32>*
  %15 = load <4 x i32>, <4 x i32>* %14, align 16
  %16 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %12, <4 x i32> %15) #6
  %17 = bitcast [32 x <2 x i64>]* %4 to <8 x i16>*
  store <8 x i16> %16, <8 x i16>* %17, align 16
  %18 = getelementptr inbounds i32, i32* %0, i64 32
  %19 = bitcast i32* %18 to <4 x i32>*
  %20 = load <4 x i32>, <4 x i32>* %19, align 16
  %21 = getelementptr inbounds i32, i32* %0, i64 36
  %22 = bitcast i32* %21 to <4 x i32>*
  %23 = load <4 x i32>, <4 x i32>* %22, align 16
  %24 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %20, <4 x i32> %23) #6
  %25 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %4, i64 0, i64 1
  %26 = getelementptr inbounds i32, i32* %0, i64 64
  %27 = bitcast i32* %26 to <4 x i32>*
  %28 = load <4 x i32>, <4 x i32>* %27, align 16
  %29 = getelementptr inbounds i32, i32* %0, i64 68
  %30 = bitcast i32* %29 to <4 x i32>*
  %31 = load <4 x i32>, <4 x i32>* %30, align 16
  %32 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %28, <4 x i32> %31) #6
  %33 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %4, i64 0, i64 2
  %34 = getelementptr inbounds i32, i32* %0, i64 96
  %35 = bitcast i32* %34 to <4 x i32>*
  %36 = load <4 x i32>, <4 x i32>* %35, align 16
  %37 = getelementptr inbounds i32, i32* %0, i64 100
  %38 = bitcast i32* %37 to <4 x i32>*
  %39 = load <4 x i32>, <4 x i32>* %38, align 16
  %40 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %36, <4 x i32> %39) #6
  %41 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %4, i64 0, i64 3
  %42 = getelementptr inbounds i32, i32* %0, i64 128
  %43 = bitcast i32* %42 to <4 x i32>*
  %44 = load <4 x i32>, <4 x i32>* %43, align 16
  %45 = getelementptr inbounds i32, i32* %0, i64 132
  %46 = bitcast i32* %45 to <4 x i32>*
  %47 = load <4 x i32>, <4 x i32>* %46, align 16
  %48 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %44, <4 x i32> %47) #6
  %49 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %4, i64 0, i64 4
  %50 = getelementptr inbounds i32, i32* %0, i64 160
  %51 = bitcast i32* %50 to <4 x i32>*
  %52 = load <4 x i32>, <4 x i32>* %51, align 16
  %53 = getelementptr inbounds i32, i32* %0, i64 164
  %54 = bitcast i32* %53 to <4 x i32>*
  %55 = load <4 x i32>, <4 x i32>* %54, align 16
  %56 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %52, <4 x i32> %55) #6
  %57 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %4, i64 0, i64 5
  %58 = getelementptr inbounds i32, i32* %0, i64 192
  %59 = bitcast i32* %58 to <4 x i32>*
  %60 = load <4 x i32>, <4 x i32>* %59, align 16
  %61 = getelementptr inbounds i32, i32* %0, i64 196
  %62 = bitcast i32* %61 to <4 x i32>*
  %63 = load <4 x i32>, <4 x i32>* %62, align 16
  %64 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %60, <4 x i32> %63) #6
  %65 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %4, i64 0, i64 6
  %66 = getelementptr inbounds i32, i32* %0, i64 224
  %67 = bitcast i32* %66 to <4 x i32>*
  %68 = load <4 x i32>, <4 x i32>* %67, align 16
  %69 = getelementptr inbounds i32, i32* %0, i64 228
  %70 = bitcast i32* %69 to <4 x i32>*
  %71 = load <4 x i32>, <4 x i32>* %70, align 16
  %72 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %68, <4 x i32> %71) #6
  %73 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %4, i64 0, i64 7
  %74 = shufflevector <8 x i16> %16, <8 x i16> %24, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %75 = shufflevector <8 x i16> %32, <8 x i16> %40, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %76 = shufflevector <8 x i16> %48, <8 x i16> %56, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %77 = shufflevector <8 x i16> %64, <8 x i16> %72, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %78 = shufflevector <8 x i16> %16, <8 x i16> %24, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %79 = shufflevector <8 x i16> %32, <8 x i16> %40, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %80 = shufflevector <8 x i16> %48, <8 x i16> %56, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %81 = shufflevector <8 x i16> %64, <8 x i16> %72, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %82 = bitcast <8 x i16> %74 to <4 x i32>
  %83 = bitcast <8 x i16> %75 to <4 x i32>
  %84 = shufflevector <4 x i32> %82, <4 x i32> %83, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %85 = bitcast <4 x i32> %84 to <2 x i64>
  %86 = bitcast <8 x i16> %76 to <4 x i32>
  %87 = bitcast <8 x i16> %77 to <4 x i32>
  %88 = shufflevector <4 x i32> %86, <4 x i32> %87, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %89 = bitcast <4 x i32> %88 to <2 x i64>
  %90 = bitcast <8 x i16> %78 to <4 x i32>
  %91 = bitcast <8 x i16> %79 to <4 x i32>
  %92 = shufflevector <4 x i32> %90, <4 x i32> %91, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %93 = bitcast <4 x i32> %92 to <2 x i64>
  %94 = bitcast <8 x i16> %80 to <4 x i32>
  %95 = bitcast <8 x i16> %81 to <4 x i32>
  %96 = shufflevector <4 x i32> %94, <4 x i32> %95, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %97 = bitcast <4 x i32> %96 to <2 x i64>
  %98 = shufflevector <4 x i32> %82, <4 x i32> %83, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %99 = bitcast <4 x i32> %98 to <2 x i64>
  %100 = shufflevector <4 x i32> %86, <4 x i32> %87, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %101 = bitcast <4 x i32> %100 to <2 x i64>
  %102 = shufflevector <4 x i32> %90, <4 x i32> %91, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %103 = bitcast <4 x i32> %102 to <2 x i64>
  %104 = shufflevector <4 x i32> %94, <4 x i32> %95, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %105 = bitcast <4 x i32> %104 to <2 x i64>
  %106 = shufflevector <2 x i64> %85, <2 x i64> %89, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %106, <2 x i64>* %10, align 16
  %107 = shufflevector <2 x i64> %85, <2 x i64> %89, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %107, <2 x i64>* %25, align 16
  %108 = shufflevector <2 x i64> %99, <2 x i64> %101, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %108, <2 x i64>* %33, align 16
  %109 = shufflevector <2 x i64> %99, <2 x i64> %101, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %109, <2 x i64>* %41, align 16
  %110 = shufflevector <2 x i64> %93, <2 x i64> %97, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %110, <2 x i64>* %49, align 16
  %111 = shufflevector <2 x i64> %93, <2 x i64> %97, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %111, <2 x i64>* %57, align 16
  %112 = shufflevector <2 x i64> %103, <2 x i64> %105, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %112, <2 x i64>* %65, align 16
  %113 = shufflevector <2 x i64> %103, <2 x i64> %105, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %113, <2 x i64>* %73, align 16
  %114 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 0
  call void @idct32_34_8x32_sse2(<2 x i64>* nonnull %10, <2 x i64>* nonnull %114)
  %115 = sext i32 %2 to i64
  br label %116

116:                                              ; preds = %3, %204
  %117 = phi i64 [ 0, %3 ], [ %206, %204 ]
  %118 = phi i8* [ %1, %3 ], [ %205, %204 ]
  %119 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 %117
  %120 = bitcast <2 x i64>* %119 to <8 x i16>*
  %121 = load <8 x i16>, <8 x i16>* %120, align 16
  %122 = getelementptr inbounds <2 x i64>, <2 x i64>* %119, i64 1
  %123 = bitcast <2 x i64>* %122 to <8 x i16>*
  %124 = load <8 x i16>, <8 x i16>* %123, align 16
  %125 = shufflevector <8 x i16> %121, <8 x i16> %124, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %126 = getelementptr inbounds <2 x i64>, <2 x i64>* %119, i64 2
  %127 = bitcast <2 x i64>* %126 to <8 x i16>*
  %128 = load <8 x i16>, <8 x i16>* %127, align 16
  %129 = getelementptr inbounds <2 x i64>, <2 x i64>* %119, i64 3
  %130 = bitcast <2 x i64>* %129 to <8 x i16>*
  %131 = load <8 x i16>, <8 x i16>* %130, align 16
  %132 = shufflevector <8 x i16> %128, <8 x i16> %131, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %133 = getelementptr inbounds <2 x i64>, <2 x i64>* %119, i64 4
  %134 = bitcast <2 x i64>* %133 to <8 x i16>*
  %135 = load <8 x i16>, <8 x i16>* %134, align 16
  %136 = getelementptr inbounds <2 x i64>, <2 x i64>* %119, i64 5
  %137 = bitcast <2 x i64>* %136 to <8 x i16>*
  %138 = load <8 x i16>, <8 x i16>* %137, align 16
  %139 = shufflevector <8 x i16> %135, <8 x i16> %138, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %140 = getelementptr inbounds <2 x i64>, <2 x i64>* %119, i64 6
  %141 = bitcast <2 x i64>* %140 to <8 x i16>*
  %142 = load <8 x i16>, <8 x i16>* %141, align 16
  %143 = getelementptr inbounds <2 x i64>, <2 x i64>* %119, i64 7
  %144 = bitcast <2 x i64>* %143 to <8 x i16>*
  %145 = load <8 x i16>, <8 x i16>* %144, align 16
  %146 = shufflevector <8 x i16> %142, <8 x i16> %145, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %147 = shufflevector <8 x i16> %121, <8 x i16> %124, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %148 = shufflevector <8 x i16> %128, <8 x i16> %131, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %149 = shufflevector <8 x i16> %135, <8 x i16> %138, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %150 = shufflevector <8 x i16> %142, <8 x i16> %145, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %151 = bitcast <8 x i16> %125 to <4 x i32>
  %152 = bitcast <8 x i16> %132 to <4 x i32>
  %153 = shufflevector <4 x i32> %151, <4 x i32> %152, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %154 = bitcast <4 x i32> %153 to <2 x i64>
  %155 = bitcast <8 x i16> %139 to <4 x i32>
  %156 = bitcast <8 x i16> %146 to <4 x i32>
  %157 = shufflevector <4 x i32> %155, <4 x i32> %156, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %158 = bitcast <4 x i32> %157 to <2 x i64>
  %159 = bitcast <8 x i16> %147 to <4 x i32>
  %160 = bitcast <8 x i16> %148 to <4 x i32>
  %161 = shufflevector <4 x i32> %159, <4 x i32> %160, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %162 = bitcast <4 x i32> %161 to <2 x i64>
  %163 = bitcast <8 x i16> %149 to <4 x i32>
  %164 = bitcast <8 x i16> %150 to <4 x i32>
  %165 = shufflevector <4 x i32> %163, <4 x i32> %164, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %166 = bitcast <4 x i32> %165 to <2 x i64>
  %167 = shufflevector <4 x i32> %151, <4 x i32> %152, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %168 = bitcast <4 x i32> %167 to <2 x i64>
  %169 = shufflevector <4 x i32> %155, <4 x i32> %156, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %170 = bitcast <4 x i32> %169 to <2 x i64>
  %171 = shufflevector <4 x i32> %159, <4 x i32> %160, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %172 = bitcast <4 x i32> %171 to <2 x i64>
  %173 = shufflevector <4 x i32> %163, <4 x i32> %164, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %174 = bitcast <4 x i32> %173 to <2 x i64>
  %175 = shufflevector <2 x i64> %154, <2 x i64> %158, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %175, <2 x i64>* %10, align 16
  %176 = shufflevector <2 x i64> %154, <2 x i64> %158, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %176, <2 x i64>* %25, align 16
  %177 = shufflevector <2 x i64> %168, <2 x i64> %170, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %177, <2 x i64>* %33, align 16
  %178 = shufflevector <2 x i64> %168, <2 x i64> %170, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %178, <2 x i64>* %41, align 16
  %179 = shufflevector <2 x i64> %162, <2 x i64> %166, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %179, <2 x i64>* %49, align 16
  %180 = shufflevector <2 x i64> %162, <2 x i64> %166, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %180, <2 x i64>* %57, align 16
  %181 = shufflevector <2 x i64> %172, <2 x i64> %174, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %181, <2 x i64>* %65, align 16
  %182 = shufflevector <2 x i64> %172, <2 x i64> %174, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %182, <2 x i64>* %73, align 16
  call void @idct32_34_8x32_sse2(<2 x i64>* nonnull %10, <2 x i64>* nonnull %10)
  br label %183

183:                                              ; preds = %183, %116
  %184 = phi i64 [ 0, %116 ], [ %202, %183 ]
  %185 = mul nsw i64 %184, %115
  %186 = getelementptr inbounds i8, i8* %118, i64 %185
  %187 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %4, i64 0, i64 %184
  %188 = bitcast <2 x i64>* %187 to <8 x i16>*
  %189 = load <8 x i16>, <8 x i16>* %188, align 16
  %190 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %189, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #6
  %191 = ashr <8 x i16> %190, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %192 = bitcast i8* %186 to i64*
  %193 = load i64, i64* %192, align 1
  %194 = insertelement <2 x i64> undef, i64 %193, i32 0
  %195 = bitcast <2 x i64> %194 to <16 x i8>
  %196 = shufflevector <16 x i8> %195, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %197 = bitcast <16 x i8> %196 to <8 x i16>
  %198 = add <8 x i16> %191, %197
  %199 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %198, <8 x i16> undef) #6
  %200 = bitcast <16 x i8> %199 to <2 x i64>
  %201 = extractelement <2 x i64> %200, i32 0
  store i64 %201, i64* %192, align 1
  %202 = add nuw nsw i64 %184, 1
  %203 = icmp eq i64 %202, 32
  br i1 %203, label %204, label %183

204:                                              ; preds = %183
  %205 = getelementptr inbounds i8, i8* %118, i64 8
  %206 = add nuw nsw i64 %117, 8
  %207 = icmp ult i64 %206, 32
  br i1 %207, label %116, label %208

208:                                              ; preds = %204
  call void @llvm.lifetime.end.p0i8(i64 512, i8* nonnull %9) #6
  call void @llvm.lifetime.end.p0i8(i64 512, i8* nonnull %6) #6
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @idct32_1024_8x32(<2 x i64>* readonly, <2 x i64>* nocapture) local_unnamed_addr #0 {
  %3 = alloca [32 x <2 x i64>], align 16
  %4 = bitcast [32 x <2 x i64>]* %3 to i8*
  call void @llvm.lifetime.start.p0i8(i64 512, i8* nonnull %4) #6
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %4, i8 -86, i64 512, i1 false)
  %5 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %6 = bitcast <2 x i64>* %5 to <8 x i16>*
  %7 = load <8 x i16>, <8 x i16>* %6, align 16
  %8 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 28
  %9 = bitcast <2 x i64>* %8 to <8 x i16>*
  %10 = load <8 x i16>, <8 x i16>* %9, align 16
  %11 = shufflevector <8 x i16> %7, <8 x i16> %10, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %12 = shufflevector <8 x i16> %7, <8 x i16> %10, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %13 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #6
  %14 = add <4 x i32> %13, <i32 8192, i32 8192, i32 8192, i32 8192>
  %15 = ashr <4 x i32> %14, <i32 14, i32 14, i32 14, i32 14>
  %16 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %12, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #6
  %17 = add <4 x i32> %16, <i32 8192, i32 8192, i32 8192, i32 8192>
  %18 = ashr <4 x i32> %17, <i32 14, i32 14, i32 14, i32 14>
  %19 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %15, <4 x i32> %18) #6
  %20 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11, <8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>) #6
  %21 = add <4 x i32> %20, <i32 8192, i32 8192, i32 8192, i32 8192>
  %22 = ashr <4 x i32> %21, <i32 14, i32 14, i32 14, i32 14>
  %23 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %12, <8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>) #6
  %24 = add <4 x i32> %23, <i32 8192, i32 8192, i32 8192, i32 8192>
  %25 = ashr <4 x i32> %24, <i32 14, i32 14, i32 14, i32 14>
  %26 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %22, <4 x i32> %25) #6
  %27 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 20
  %28 = bitcast <2 x i64>* %27 to <8 x i16>*
  %29 = load <8 x i16>, <8 x i16>* %28, align 16
  %30 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 12
  %31 = bitcast <2 x i64>* %30 to <8 x i16>*
  %32 = load <8 x i16>, <8 x i16>* %31, align 16
  %33 = shufflevector <8 x i16> %29, <8 x i16> %32, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %34 = shufflevector <8 x i16> %29, <8 x i16> %32, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %35 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %33, <8 x i16> <i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102>) #6
  %36 = add <4 x i32> %35, <i32 8192, i32 8192, i32 8192, i32 8192>
  %37 = ashr <4 x i32> %36, <i32 14, i32 14, i32 14, i32 14>
  %38 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %34, <8 x i16> <i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102>) #6
  %39 = add <4 x i32> %38, <i32 8192, i32 8192, i32 8192, i32 8192>
  %40 = ashr <4 x i32> %39, <i32 14, i32 14, i32 14, i32 14>
  %41 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %37, <4 x i32> %40) #6
  %42 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %33, <8 x i16> <i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623>) #6
  %43 = add <4 x i32> %42, <i32 8192, i32 8192, i32 8192, i32 8192>
  %44 = ashr <4 x i32> %43, <i32 14, i32 14, i32 14, i32 14>
  %45 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %34, <8 x i16> <i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623>) #6
  %46 = add <4 x i32> %45, <i32 8192, i32 8192, i32 8192, i32 8192>
  %47 = ashr <4 x i32> %46, <i32 14, i32 14, i32 14, i32 14>
  %48 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %44, <4 x i32> %47) #6
  %49 = bitcast <2 x i64>* %0 to <8 x i16>*
  %50 = load <8 x i16>, <8 x i16>* %49, align 16
  %51 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 16
  %52 = bitcast <2 x i64>* %51 to <8 x i16>*
  %53 = load <8 x i16>, <8 x i16>* %52, align 16
  %54 = shufflevector <8 x i16> %50, <8 x i16> %53, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %55 = shufflevector <8 x i16> %50, <8 x i16> %53, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %56 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %54, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %57 = add <4 x i32> %56, <i32 8192, i32 8192, i32 8192, i32 8192>
  %58 = ashr <4 x i32> %57, <i32 14, i32 14, i32 14, i32 14>
  %59 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %55, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %60 = add <4 x i32> %59, <i32 8192, i32 8192, i32 8192, i32 8192>
  %61 = ashr <4 x i32> %60, <i32 14, i32 14, i32 14, i32 14>
  %62 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %58, <4 x i32> %61) #6
  %63 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %54, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %64 = add <4 x i32> %63, <i32 8192, i32 8192, i32 8192, i32 8192>
  %65 = ashr <4 x i32> %64, <i32 14, i32 14, i32 14, i32 14>
  %66 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %55, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %67 = add <4 x i32> %66, <i32 8192, i32 8192, i32 8192, i32 8192>
  %68 = ashr <4 x i32> %67, <i32 14, i32 14, i32 14, i32 14>
  %69 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %65, <4 x i32> %68) #6
  %70 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 8
  %71 = bitcast <2 x i64>* %70 to <8 x i16>*
  %72 = load <8 x i16>, <8 x i16>* %71, align 16
  %73 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 24
  %74 = bitcast <2 x i64>* %73 to <8 x i16>*
  %75 = load <8 x i16>, <8 x i16>* %74, align 16
  %76 = shufflevector <8 x i16> %72, <8 x i16> %75, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %77 = shufflevector <8 x i16> %72, <8 x i16> %75, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %78 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %76, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %79 = add <4 x i32> %78, <i32 8192, i32 8192, i32 8192, i32 8192>
  %80 = ashr <4 x i32> %79, <i32 14, i32 14, i32 14, i32 14>
  %81 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %77, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %82 = add <4 x i32> %81, <i32 8192, i32 8192, i32 8192, i32 8192>
  %83 = ashr <4 x i32> %82, <i32 14, i32 14, i32 14, i32 14>
  %84 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %80, <4 x i32> %83) #6
  %85 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %76, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %86 = add <4 x i32> %85, <i32 8192, i32 8192, i32 8192, i32 8192>
  %87 = ashr <4 x i32> %86, <i32 14, i32 14, i32 14, i32 14>
  %88 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %77, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %89 = add <4 x i32> %88, <i32 8192, i32 8192, i32 8192, i32 8192>
  %90 = ashr <4 x i32> %89, <i32 14, i32 14, i32 14, i32 14>
  %91 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %87, <4 x i32> %90) #6
  %92 = add <8 x i16> %41, %19
  %93 = sub <8 x i16> %19, %41
  %94 = sub <8 x i16> %26, %48
  %95 = add <8 x i16> %48, %26
  %96 = add <8 x i16> %91, %69
  %97 = add <8 x i16> %84, %62
  %98 = sub <8 x i16> %62, %84
  %99 = sub <8 x i16> %69, %91
  %100 = shufflevector <8 x i16> %94, <8 x i16> %93, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %101 = shufflevector <8 x i16> %94, <8 x i16> %93, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %102 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %100, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %103 = add <4 x i32> %102, <i32 8192, i32 8192, i32 8192, i32 8192>
  %104 = ashr <4 x i32> %103, <i32 14, i32 14, i32 14, i32 14>
  %105 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %101, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %106 = add <4 x i32> %105, <i32 8192, i32 8192, i32 8192, i32 8192>
  %107 = ashr <4 x i32> %106, <i32 14, i32 14, i32 14, i32 14>
  %108 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %104, <4 x i32> %107) #6
  %109 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %100, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %110 = add <4 x i32> %109, <i32 8192, i32 8192, i32 8192, i32 8192>
  %111 = ashr <4 x i32> %110, <i32 14, i32 14, i32 14, i32 14>
  %112 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %101, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %113 = add <4 x i32> %112, <i32 8192, i32 8192, i32 8192, i32 8192>
  %114 = ashr <4 x i32> %113, <i32 14, i32 14, i32 14, i32 14>
  %115 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %111, <4 x i32> %114) #6
  %116 = add <8 x i16> %96, %95
  %117 = add <8 x i16> %115, %97
  %118 = add <8 x i16> %108, %98
  %119 = add <8 x i16> %99, %92
  %120 = sub <8 x i16> %99, %92
  %121 = sub <8 x i16> %98, %108
  %122 = sub <8 x i16> %97, %115
  %123 = sub <8 x i16> %96, %95
  %124 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %125 = bitcast <2 x i64>* %124 to <8 x i16>*
  %126 = load <8 x i16>, <8 x i16>* %125, align 16
  %127 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 30
  %128 = bitcast <2 x i64>* %127 to <8 x i16>*
  %129 = load <8 x i16>, <8 x i16>* %128, align 16
  %130 = shufflevector <8 x i16> %126, <8 x i16> %129, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %131 = shufflevector <8 x i16> %126, <8 x i16> %129, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %132 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %130, <8 x i16> <i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305>) #6
  %133 = add <4 x i32> %132, <i32 8192, i32 8192, i32 8192, i32 8192>
  %134 = ashr <4 x i32> %133, <i32 14, i32 14, i32 14, i32 14>
  %135 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %131, <8 x i16> <i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305, i16 1606, i16 -16305>) #6
  %136 = add <4 x i32> %135, <i32 8192, i32 8192, i32 8192, i32 8192>
  %137 = ashr <4 x i32> %136, <i32 14, i32 14, i32 14, i32 14>
  %138 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %134, <4 x i32> %137) #6
  %139 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %130, <8 x i16> <i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606>) #6
  %140 = add <4 x i32> %139, <i32 8192, i32 8192, i32 8192, i32 8192>
  %141 = ashr <4 x i32> %140, <i32 14, i32 14, i32 14, i32 14>
  %142 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %131, <8 x i16> <i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606, i16 16305, i16 1606>) #6
  %143 = add <4 x i32> %142, <i32 8192, i32 8192, i32 8192, i32 8192>
  %144 = ashr <4 x i32> %143, <i32 14, i32 14, i32 14, i32 14>
  %145 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %141, <4 x i32> %144) #6
  %146 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 18
  %147 = bitcast <2 x i64>* %146 to <8 x i16>*
  %148 = load <8 x i16>, <8 x i16>* %147, align 16
  %149 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 14
  %150 = bitcast <2 x i64>* %149 to <8 x i16>*
  %151 = load <8 x i16>, <8 x i16>* %150, align 16
  %152 = shufflevector <8 x i16> %148, <8 x i16> %151, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %153 = shufflevector <8 x i16> %148, <8 x i16> %151, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %154 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %152, <8 x i16> <i16 12665, i16 -10394, i16 12665, i16 -10394, i16 12665, i16 -10394, i16 12665, i16 -10394>) #6
  %155 = add <4 x i32> %154, <i32 8192, i32 8192, i32 8192, i32 8192>
  %156 = ashr <4 x i32> %155, <i32 14, i32 14, i32 14, i32 14>
  %157 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %153, <8 x i16> <i16 12665, i16 -10394, i16 12665, i16 -10394, i16 12665, i16 -10394, i16 12665, i16 -10394>) #6
  %158 = add <4 x i32> %157, <i32 8192, i32 8192, i32 8192, i32 8192>
  %159 = ashr <4 x i32> %158, <i32 14, i32 14, i32 14, i32 14>
  %160 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %156, <4 x i32> %159) #6
  %161 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %152, <8 x i16> <i16 10394, i16 12665, i16 10394, i16 12665, i16 10394, i16 12665, i16 10394, i16 12665>) #6
  %162 = add <4 x i32> %161, <i32 8192, i32 8192, i32 8192, i32 8192>
  %163 = ashr <4 x i32> %162, <i32 14, i32 14, i32 14, i32 14>
  %164 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %153, <8 x i16> <i16 10394, i16 12665, i16 10394, i16 12665, i16 10394, i16 12665, i16 10394, i16 12665>) #6
  %165 = add <4 x i32> %164, <i32 8192, i32 8192, i32 8192, i32 8192>
  %166 = ashr <4 x i32> %165, <i32 14, i32 14, i32 14, i32 14>
  %167 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %163, <4 x i32> %166) #6
  %168 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 10
  %169 = bitcast <2 x i64>* %168 to <8 x i16>*
  %170 = load <8 x i16>, <8 x i16>* %169, align 16
  %171 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 22
  %172 = bitcast <2 x i64>* %171 to <8 x i16>*
  %173 = load <8 x i16>, <8 x i16>* %172, align 16
  %174 = shufflevector <8 x i16> %170, <8 x i16> %173, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %175 = shufflevector <8 x i16> %170, <8 x i16> %173, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %176 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %174, <8 x i16> <i16 7723, i16 -14449, i16 7723, i16 -14449, i16 7723, i16 -14449, i16 7723, i16 -14449>) #6
  %177 = add <4 x i32> %176, <i32 8192, i32 8192, i32 8192, i32 8192>
  %178 = ashr <4 x i32> %177, <i32 14, i32 14, i32 14, i32 14>
  %179 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %175, <8 x i16> <i16 7723, i16 -14449, i16 7723, i16 -14449, i16 7723, i16 -14449, i16 7723, i16 -14449>) #6
  %180 = add <4 x i32> %179, <i32 8192, i32 8192, i32 8192, i32 8192>
  %181 = ashr <4 x i32> %180, <i32 14, i32 14, i32 14, i32 14>
  %182 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %178, <4 x i32> %181) #6
  %183 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %174, <8 x i16> <i16 14449, i16 7723, i16 14449, i16 7723, i16 14449, i16 7723, i16 14449, i16 7723>) #6
  %184 = add <4 x i32> %183, <i32 8192, i32 8192, i32 8192, i32 8192>
  %185 = ashr <4 x i32> %184, <i32 14, i32 14, i32 14, i32 14>
  %186 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %175, <8 x i16> <i16 14449, i16 7723, i16 14449, i16 7723, i16 14449, i16 7723, i16 14449, i16 7723>) #6
  %187 = add <4 x i32> %186, <i32 8192, i32 8192, i32 8192, i32 8192>
  %188 = ashr <4 x i32> %187, <i32 14, i32 14, i32 14, i32 14>
  %189 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %185, <4 x i32> %188) #6
  %190 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 26
  %191 = bitcast <2 x i64>* %190 to <8 x i16>*
  %192 = load <8 x i16>, <8 x i16>* %191, align 16
  %193 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %194 = bitcast <2 x i64>* %193 to <8 x i16>*
  %195 = load <8 x i16>, <8 x i16>* %194, align 16
  %196 = shufflevector <8 x i16> %192, <8 x i16> %195, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %197 = shufflevector <8 x i16> %192, <8 x i16> %195, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %198 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %196, <8 x i16> <i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756>) #6
  %199 = add <4 x i32> %198, <i32 8192, i32 8192, i32 8192, i32 8192>
  %200 = ashr <4 x i32> %199, <i32 14, i32 14, i32 14, i32 14>
  %201 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %197, <8 x i16> <i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756, i16 15679, i16 -4756>) #6
  %202 = add <4 x i32> %201, <i32 8192, i32 8192, i32 8192, i32 8192>
  %203 = ashr <4 x i32> %202, <i32 14, i32 14, i32 14, i32 14>
  %204 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %200, <4 x i32> %203) #6
  %205 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %196, <8 x i16> <i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679>) #6
  %206 = add <4 x i32> %205, <i32 8192, i32 8192, i32 8192, i32 8192>
  %207 = ashr <4 x i32> %206, <i32 14, i32 14, i32 14, i32 14>
  %208 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %197, <8 x i16> <i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679, i16 4756, i16 15679>) #6
  %209 = add <4 x i32> %208, <i32 8192, i32 8192, i32 8192, i32 8192>
  %210 = ashr <4 x i32> %209, <i32 14, i32 14, i32 14, i32 14>
  %211 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %207, <4 x i32> %210) #6
  %212 = add <8 x i16> %160, %138
  %213 = sub <8 x i16> %138, %160
  %214 = sub <8 x i16> %204, %182
  %215 = add <8 x i16> %204, %182
  %216 = add <8 x i16> %211, %189
  %217 = sub <8 x i16> %211, %189
  %218 = sub <8 x i16> %145, %167
  %219 = add <8 x i16> %167, %145
  %220 = shufflevector <8 x i16> %218, <8 x i16> %213, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %221 = shufflevector <8 x i16> %218, <8 x i16> %213, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %222 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %220, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %223 = add <4 x i32> %222, <i32 8192, i32 8192, i32 8192, i32 8192>
  %224 = ashr <4 x i32> %223, <i32 14, i32 14, i32 14, i32 14>
  %225 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %221, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %226 = add <4 x i32> %225, <i32 8192, i32 8192, i32 8192, i32 8192>
  %227 = ashr <4 x i32> %226, <i32 14, i32 14, i32 14, i32 14>
  %228 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %224, <4 x i32> %227) #6
  %229 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %220, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %230 = add <4 x i32> %229, <i32 8192, i32 8192, i32 8192, i32 8192>
  %231 = ashr <4 x i32> %230, <i32 14, i32 14, i32 14, i32 14>
  %232 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %221, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %233 = add <4 x i32> %232, <i32 8192, i32 8192, i32 8192, i32 8192>
  %234 = ashr <4 x i32> %233, <i32 14, i32 14, i32 14, i32 14>
  %235 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %231, <4 x i32> %234) #6
  %236 = shufflevector <8 x i16> %217, <8 x i16> %214, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %237 = shufflevector <8 x i16> %217, <8 x i16> %214, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %238 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %236, <8 x i16> <i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270>) #6
  %239 = add <4 x i32> %238, <i32 8192, i32 8192, i32 8192, i32 8192>
  %240 = ashr <4 x i32> %239, <i32 14, i32 14, i32 14, i32 14>
  %241 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %237, <8 x i16> <i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270>) #6
  %242 = add <4 x i32> %241, <i32 8192, i32 8192, i32 8192, i32 8192>
  %243 = ashr <4 x i32> %242, <i32 14, i32 14, i32 14, i32 14>
  %244 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %240, <4 x i32> %243) #6
  %245 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %236, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %246 = add <4 x i32> %245, <i32 8192, i32 8192, i32 8192, i32 8192>
  %247 = ashr <4 x i32> %246, <i32 14, i32 14, i32 14, i32 14>
  %248 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %237, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %249 = add <4 x i32> %248, <i32 8192, i32 8192, i32 8192, i32 8192>
  %250 = ashr <4 x i32> %249, <i32 14, i32 14, i32 14, i32 14>
  %251 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %247, <4 x i32> %250) #6
  %252 = add <8 x i16> %215, %212
  %253 = add <8 x i16> %244, %228
  %254 = sub <8 x i16> %228, %244
  %255 = sub <8 x i16> %212, %215
  %256 = sub <8 x i16> %219, %216
  %257 = sub <8 x i16> %235, %251
  %258 = add <8 x i16> %251, %235
  %259 = add <8 x i16> %216, %219
  %260 = shufflevector <8 x i16> %257, <8 x i16> %254, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %261 = shufflevector <8 x i16> %257, <8 x i16> %254, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %262 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %260, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %263 = add <4 x i32> %262, <i32 8192, i32 8192, i32 8192, i32 8192>
  %264 = ashr <4 x i32> %263, <i32 14, i32 14, i32 14, i32 14>
  %265 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %261, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %266 = add <4 x i32> %265, <i32 8192, i32 8192, i32 8192, i32 8192>
  %267 = ashr <4 x i32> %266, <i32 14, i32 14, i32 14, i32 14>
  %268 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %264, <4 x i32> %267) #6
  %269 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %260, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %270 = add <4 x i32> %269, <i32 8192, i32 8192, i32 8192, i32 8192>
  %271 = ashr <4 x i32> %270, <i32 14, i32 14, i32 14, i32 14>
  %272 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %261, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %273 = add <4 x i32> %272, <i32 8192, i32 8192, i32 8192, i32 8192>
  %274 = ashr <4 x i32> %273, <i32 14, i32 14, i32 14, i32 14>
  %275 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %271, <4 x i32> %274) #6
  %276 = shufflevector <8 x i16> %256, <8 x i16> %255, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %277 = shufflevector <8 x i16> %256, <8 x i16> %255, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %278 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %276, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %279 = add <4 x i32> %278, <i32 8192, i32 8192, i32 8192, i32 8192>
  %280 = ashr <4 x i32> %279, <i32 14, i32 14, i32 14, i32 14>
  %281 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %277, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %282 = add <4 x i32> %281, <i32 8192, i32 8192, i32 8192, i32 8192>
  %283 = ashr <4 x i32> %282, <i32 14, i32 14, i32 14, i32 14>
  %284 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %280, <4 x i32> %283) #6
  %285 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %276, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %286 = add <4 x i32> %285, <i32 8192, i32 8192, i32 8192, i32 8192>
  %287 = ashr <4 x i32> %286, <i32 14, i32 14, i32 14, i32 14>
  %288 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %277, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %289 = add <4 x i32> %288, <i32 8192, i32 8192, i32 8192, i32 8192>
  %290 = ashr <4 x i32> %289, <i32 14, i32 14, i32 14, i32 14>
  %291 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %287, <4 x i32> %290) #6
  %292 = add <8 x i16> %259, %116
  %293 = bitcast [32 x <2 x i64>]* %3 to <8 x i16>*
  store <8 x i16> %292, <8 x i16>* %293, align 16
  %294 = sub <8 x i16> %116, %259
  %295 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 15
  %296 = bitcast <2 x i64>* %295 to <8 x i16>*
  store <8 x i16> %294, <8 x i16>* %296, align 16
  %297 = add <8 x i16> %258, %117
  %298 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 1
  %299 = bitcast <2 x i64>* %298 to <8 x i16>*
  store <8 x i16> %297, <8 x i16>* %299, align 16
  %300 = sub <8 x i16> %117, %258
  %301 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 14
  %302 = bitcast <2 x i64>* %301 to <8 x i16>*
  store <8 x i16> %300, <8 x i16>* %302, align 16
  %303 = add <8 x i16> %275, %118
  %304 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 2
  %305 = bitcast <2 x i64>* %304 to <8 x i16>*
  store <8 x i16> %303, <8 x i16>* %305, align 16
  %306 = sub <8 x i16> %118, %275
  %307 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 13
  %308 = bitcast <2 x i64>* %307 to <8 x i16>*
  store <8 x i16> %306, <8 x i16>* %308, align 16
  %309 = add <8 x i16> %291, %119
  %310 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 3
  %311 = bitcast <2 x i64>* %310 to <8 x i16>*
  store <8 x i16> %309, <8 x i16>* %311, align 16
  %312 = sub <8 x i16> %119, %291
  %313 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 12
  %314 = bitcast <2 x i64>* %313 to <8 x i16>*
  store <8 x i16> %312, <8 x i16>* %314, align 16
  %315 = add <8 x i16> %284, %120
  %316 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 4
  %317 = bitcast <2 x i64>* %316 to <8 x i16>*
  store <8 x i16> %315, <8 x i16>* %317, align 16
  %318 = sub <8 x i16> %120, %284
  %319 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 11
  %320 = bitcast <2 x i64>* %319 to <8 x i16>*
  store <8 x i16> %318, <8 x i16>* %320, align 16
  %321 = add <8 x i16> %268, %121
  %322 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 5
  %323 = bitcast <2 x i64>* %322 to <8 x i16>*
  store <8 x i16> %321, <8 x i16>* %323, align 16
  %324 = sub <8 x i16> %121, %268
  %325 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 10
  %326 = bitcast <2 x i64>* %325 to <8 x i16>*
  store <8 x i16> %324, <8 x i16>* %326, align 16
  %327 = add <8 x i16> %253, %122
  %328 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 6
  %329 = bitcast <2 x i64>* %328 to <8 x i16>*
  store <8 x i16> %327, <8 x i16>* %329, align 16
  %330 = sub <8 x i16> %122, %253
  %331 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 9
  %332 = bitcast <2 x i64>* %331 to <8 x i16>*
  store <8 x i16> %330, <8 x i16>* %332, align 16
  %333 = add <8 x i16> %252, %123
  %334 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 7
  %335 = bitcast <2 x i64>* %334 to <8 x i16>*
  store <8 x i16> %333, <8 x i16>* %335, align 16
  %336 = sub <8 x i16> %123, %252
  %337 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 8
  %338 = bitcast <2 x i64>* %337 to <8 x i16>*
  store <8 x i16> %336, <8 x i16>* %338, align 16
  %339 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %340 = bitcast <2 x i64>* %339 to <8 x i16>*
  %341 = load <8 x i16>, <8 x i16>* %340, align 16
  %342 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 31
  %343 = bitcast <2 x i64>* %342 to <8 x i16>*
  %344 = load <8 x i16>, <8 x i16>* %343, align 16
  %345 = shufflevector <8 x i16> %341, <8 x i16> %344, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %346 = shufflevector <8 x i16> %341, <8 x i16> %344, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %347 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %345, <8 x i16> <i16 804, i16 -16364, i16 804, i16 -16364, i16 804, i16 -16364, i16 804, i16 -16364>) #6
  %348 = add <4 x i32> %347, <i32 8192, i32 8192, i32 8192, i32 8192>
  %349 = ashr <4 x i32> %348, <i32 14, i32 14, i32 14, i32 14>
  %350 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %346, <8 x i16> <i16 804, i16 -16364, i16 804, i16 -16364, i16 804, i16 -16364, i16 804, i16 -16364>) #6
  %351 = add <4 x i32> %350, <i32 8192, i32 8192, i32 8192, i32 8192>
  %352 = ashr <4 x i32> %351, <i32 14, i32 14, i32 14, i32 14>
  %353 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %349, <4 x i32> %352) #6
  %354 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %345, <8 x i16> <i16 16364, i16 804, i16 16364, i16 804, i16 16364, i16 804, i16 16364, i16 804>) #6
  %355 = add <4 x i32> %354, <i32 8192, i32 8192, i32 8192, i32 8192>
  %356 = ashr <4 x i32> %355, <i32 14, i32 14, i32 14, i32 14>
  %357 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %346, <8 x i16> <i16 16364, i16 804, i16 16364, i16 804, i16 16364, i16 804, i16 16364, i16 804>) #6
  %358 = add <4 x i32> %357, <i32 8192, i32 8192, i32 8192, i32 8192>
  %359 = ashr <4 x i32> %358, <i32 14, i32 14, i32 14, i32 14>
  %360 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %356, <4 x i32> %359) #6
  %361 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 17
  %362 = bitcast <2 x i64>* %361 to <8 x i16>*
  %363 = load <8 x i16>, <8 x i16>* %362, align 16
  %364 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 15
  %365 = bitcast <2 x i64>* %364 to <8 x i16>*
  %366 = load <8 x i16>, <8 x i16>* %365, align 16
  %367 = shufflevector <8 x i16> %363, <8 x i16> %366, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %368 = shufflevector <8 x i16> %363, <8 x i16> %366, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %369 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %367, <8 x i16> <i16 12140, i16 -11003, i16 12140, i16 -11003, i16 12140, i16 -11003, i16 12140, i16 -11003>) #6
  %370 = add <4 x i32> %369, <i32 8192, i32 8192, i32 8192, i32 8192>
  %371 = ashr <4 x i32> %370, <i32 14, i32 14, i32 14, i32 14>
  %372 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %368, <8 x i16> <i16 12140, i16 -11003, i16 12140, i16 -11003, i16 12140, i16 -11003, i16 12140, i16 -11003>) #6
  %373 = add <4 x i32> %372, <i32 8192, i32 8192, i32 8192, i32 8192>
  %374 = ashr <4 x i32> %373, <i32 14, i32 14, i32 14, i32 14>
  %375 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %371, <4 x i32> %374) #6
  %376 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %367, <8 x i16> <i16 11003, i16 12140, i16 11003, i16 12140, i16 11003, i16 12140, i16 11003, i16 12140>) #6
  %377 = add <4 x i32> %376, <i32 8192, i32 8192, i32 8192, i32 8192>
  %378 = ashr <4 x i32> %377, <i32 14, i32 14, i32 14, i32 14>
  %379 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %368, <8 x i16> <i16 11003, i16 12140, i16 11003, i16 12140, i16 11003, i16 12140, i16 11003, i16 12140>) #6
  %380 = add <4 x i32> %379, <i32 8192, i32 8192, i32 8192, i32 8192>
  %381 = ashr <4 x i32> %380, <i32 14, i32 14, i32 14, i32 14>
  %382 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %378, <4 x i32> %381) #6
  %383 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 9
  %384 = bitcast <2 x i64>* %383 to <8 x i16>*
  %385 = load <8 x i16>, <8 x i16>* %384, align 16
  %386 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 23
  %387 = bitcast <2 x i64>* %386 to <8 x i16>*
  %388 = load <8 x i16>, <8 x i16>* %387, align 16
  %389 = shufflevector <8 x i16> %385, <8 x i16> %388, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %390 = shufflevector <8 x i16> %385, <8 x i16> %388, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %391 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %389, <8 x i16> <i16 7005, i16 -14811, i16 7005, i16 -14811, i16 7005, i16 -14811, i16 7005, i16 -14811>) #6
  %392 = add <4 x i32> %391, <i32 8192, i32 8192, i32 8192, i32 8192>
  %393 = ashr <4 x i32> %392, <i32 14, i32 14, i32 14, i32 14>
  %394 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %390, <8 x i16> <i16 7005, i16 -14811, i16 7005, i16 -14811, i16 7005, i16 -14811, i16 7005, i16 -14811>) #6
  %395 = add <4 x i32> %394, <i32 8192, i32 8192, i32 8192, i32 8192>
  %396 = ashr <4 x i32> %395, <i32 14, i32 14, i32 14, i32 14>
  %397 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %393, <4 x i32> %396) #6
  %398 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %389, <8 x i16> <i16 14811, i16 7005, i16 14811, i16 7005, i16 14811, i16 7005, i16 14811, i16 7005>) #6
  %399 = add <4 x i32> %398, <i32 8192, i32 8192, i32 8192, i32 8192>
  %400 = ashr <4 x i32> %399, <i32 14, i32 14, i32 14, i32 14>
  %401 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %390, <8 x i16> <i16 14811, i16 7005, i16 14811, i16 7005, i16 14811, i16 7005, i16 14811, i16 7005>) #6
  %402 = add <4 x i32> %401, <i32 8192, i32 8192, i32 8192, i32 8192>
  %403 = ashr <4 x i32> %402, <i32 14, i32 14, i32 14, i32 14>
  %404 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %400, <4 x i32> %403) #6
  %405 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 25
  %406 = bitcast <2 x i64>* %405 to <8 x i16>*
  %407 = load <8 x i16>, <8 x i16>* %406, align 16
  %408 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %409 = bitcast <2 x i64>* %408 to <8 x i16>*
  %410 = load <8 x i16>, <8 x i16>* %409, align 16
  %411 = shufflevector <8 x i16> %407, <8 x i16> %410, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %412 = shufflevector <8 x i16> %407, <8 x i16> %410, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %413 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %411, <8 x i16> <i16 15426, i16 -5520, i16 15426, i16 -5520, i16 15426, i16 -5520, i16 15426, i16 -5520>) #6
  %414 = add <4 x i32> %413, <i32 8192, i32 8192, i32 8192, i32 8192>
  %415 = ashr <4 x i32> %414, <i32 14, i32 14, i32 14, i32 14>
  %416 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %412, <8 x i16> <i16 15426, i16 -5520, i16 15426, i16 -5520, i16 15426, i16 -5520, i16 15426, i16 -5520>) #6
  %417 = add <4 x i32> %416, <i32 8192, i32 8192, i32 8192, i32 8192>
  %418 = ashr <4 x i32> %417, <i32 14, i32 14, i32 14, i32 14>
  %419 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %415, <4 x i32> %418) #6
  %420 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %411, <8 x i16> <i16 5520, i16 15426, i16 5520, i16 15426, i16 5520, i16 15426, i16 5520, i16 15426>) #6
  %421 = add <4 x i32> %420, <i32 8192, i32 8192, i32 8192, i32 8192>
  %422 = ashr <4 x i32> %421, <i32 14, i32 14, i32 14, i32 14>
  %423 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %412, <8 x i16> <i16 5520, i16 15426, i16 5520, i16 15426, i16 5520, i16 15426, i16 5520, i16 15426>) #6
  %424 = add <4 x i32> %423, <i32 8192, i32 8192, i32 8192, i32 8192>
  %425 = ashr <4 x i32> %424, <i32 14, i32 14, i32 14, i32 14>
  %426 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %422, <4 x i32> %425) #6
  %427 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %428 = bitcast <2 x i64>* %427 to <8 x i16>*
  %429 = load <8 x i16>, <8 x i16>* %428, align 16
  %430 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 27
  %431 = bitcast <2 x i64>* %430 to <8 x i16>*
  %432 = load <8 x i16>, <8 x i16>* %431, align 16
  %433 = shufflevector <8 x i16> %429, <8 x i16> %432, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %434 = shufflevector <8 x i16> %429, <8 x i16> %432, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %435 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %433, <8 x i16> <i16 3981, i16 -15893, i16 3981, i16 -15893, i16 3981, i16 -15893, i16 3981, i16 -15893>) #6
  %436 = add <4 x i32> %435, <i32 8192, i32 8192, i32 8192, i32 8192>
  %437 = ashr <4 x i32> %436, <i32 14, i32 14, i32 14, i32 14>
  %438 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %434, <8 x i16> <i16 3981, i16 -15893, i16 3981, i16 -15893, i16 3981, i16 -15893, i16 3981, i16 -15893>) #6
  %439 = add <4 x i32> %438, <i32 8192, i32 8192, i32 8192, i32 8192>
  %440 = ashr <4 x i32> %439, <i32 14, i32 14, i32 14, i32 14>
  %441 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %437, <4 x i32> %440) #6
  %442 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %433, <8 x i16> <i16 15893, i16 3981, i16 15893, i16 3981, i16 15893, i16 3981, i16 15893, i16 3981>) #6
  %443 = add <4 x i32> %442, <i32 8192, i32 8192, i32 8192, i32 8192>
  %444 = ashr <4 x i32> %443, <i32 14, i32 14, i32 14, i32 14>
  %445 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %434, <8 x i16> <i16 15893, i16 3981, i16 15893, i16 3981, i16 15893, i16 3981, i16 15893, i16 3981>) #6
  %446 = add <4 x i32> %445, <i32 8192, i32 8192, i32 8192, i32 8192>
  %447 = ashr <4 x i32> %446, <i32 14, i32 14, i32 14, i32 14>
  %448 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %444, <4 x i32> %447) #6
  %449 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 21
  %450 = bitcast <2 x i64>* %449 to <8 x i16>*
  %451 = load <8 x i16>, <8 x i16>* %450, align 16
  %452 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 11
  %453 = bitcast <2 x i64>* %452 to <8 x i16>*
  %454 = load <8 x i16>, <8 x i16>* %453, align 16
  %455 = shufflevector <8 x i16> %451, <8 x i16> %454, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %456 = shufflevector <8 x i16> %451, <8 x i16> %454, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %457 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %455, <8 x i16> <i16 14053, i16 -8423, i16 14053, i16 -8423, i16 14053, i16 -8423, i16 14053, i16 -8423>) #6
  %458 = add <4 x i32> %457, <i32 8192, i32 8192, i32 8192, i32 8192>
  %459 = ashr <4 x i32> %458, <i32 14, i32 14, i32 14, i32 14>
  %460 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %456, <8 x i16> <i16 14053, i16 -8423, i16 14053, i16 -8423, i16 14053, i16 -8423, i16 14053, i16 -8423>) #6
  %461 = add <4 x i32> %460, <i32 8192, i32 8192, i32 8192, i32 8192>
  %462 = ashr <4 x i32> %461, <i32 14, i32 14, i32 14, i32 14>
  %463 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %459, <4 x i32> %462) #6
  %464 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %455, <8 x i16> <i16 8423, i16 14053, i16 8423, i16 14053, i16 8423, i16 14053, i16 8423, i16 14053>) #6
  %465 = add <4 x i32> %464, <i32 8192, i32 8192, i32 8192, i32 8192>
  %466 = ashr <4 x i32> %465, <i32 14, i32 14, i32 14, i32 14>
  %467 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %456, <8 x i16> <i16 8423, i16 14053, i16 8423, i16 14053, i16 8423, i16 14053, i16 8423, i16 14053>) #6
  %468 = add <4 x i32> %467, <i32 8192, i32 8192, i32 8192, i32 8192>
  %469 = ashr <4 x i32> %468, <i32 14, i32 14, i32 14, i32 14>
  %470 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %466, <4 x i32> %469) #6
  %471 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 13
  %472 = bitcast <2 x i64>* %471 to <8 x i16>*
  %473 = load <8 x i16>, <8 x i16>* %472, align 16
  %474 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 19
  %475 = bitcast <2 x i64>* %474 to <8 x i16>*
  %476 = load <8 x i16>, <8 x i16>* %475, align 16
  %477 = shufflevector <8 x i16> %473, <8 x i16> %476, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %478 = shufflevector <8 x i16> %473, <8 x i16> %476, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %479 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %477, <8 x i16> <i16 9760, i16 -13160, i16 9760, i16 -13160, i16 9760, i16 -13160, i16 9760, i16 -13160>) #6
  %480 = add <4 x i32> %479, <i32 8192, i32 8192, i32 8192, i32 8192>
  %481 = ashr <4 x i32> %480, <i32 14, i32 14, i32 14, i32 14>
  %482 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %478, <8 x i16> <i16 9760, i16 -13160, i16 9760, i16 -13160, i16 9760, i16 -13160, i16 9760, i16 -13160>) #6
  %483 = add <4 x i32> %482, <i32 8192, i32 8192, i32 8192, i32 8192>
  %484 = ashr <4 x i32> %483, <i32 14, i32 14, i32 14, i32 14>
  %485 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %481, <4 x i32> %484) #6
  %486 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %477, <8 x i16> <i16 13160, i16 9760, i16 13160, i16 9760, i16 13160, i16 9760, i16 13160, i16 9760>) #6
  %487 = add <4 x i32> %486, <i32 8192, i32 8192, i32 8192, i32 8192>
  %488 = ashr <4 x i32> %487, <i32 14, i32 14, i32 14, i32 14>
  %489 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %478, <8 x i16> <i16 13160, i16 9760, i16 13160, i16 9760, i16 13160, i16 9760, i16 13160, i16 9760>) #6
  %490 = add <4 x i32> %489, <i32 8192, i32 8192, i32 8192, i32 8192>
  %491 = ashr <4 x i32> %490, <i32 14, i32 14, i32 14, i32 14>
  %492 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %488, <4 x i32> %491) #6
  %493 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 29
  %494 = bitcast <2 x i64>* %493 to <8 x i16>*
  %495 = load <8 x i16>, <8 x i16>* %494, align 16
  %496 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %497 = bitcast <2 x i64>* %496 to <8 x i16>*
  %498 = load <8 x i16>, <8 x i16>* %497, align 16
  %499 = shufflevector <8 x i16> %495, <8 x i16> %498, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %500 = shufflevector <8 x i16> %495, <8 x i16> %498, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %501 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %499, <8 x i16> <i16 16207, i16 -2404, i16 16207, i16 -2404, i16 16207, i16 -2404, i16 16207, i16 -2404>) #6
  %502 = add <4 x i32> %501, <i32 8192, i32 8192, i32 8192, i32 8192>
  %503 = ashr <4 x i32> %502, <i32 14, i32 14, i32 14, i32 14>
  %504 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %500, <8 x i16> <i16 16207, i16 -2404, i16 16207, i16 -2404, i16 16207, i16 -2404, i16 16207, i16 -2404>) #6
  %505 = add <4 x i32> %504, <i32 8192, i32 8192, i32 8192, i32 8192>
  %506 = ashr <4 x i32> %505, <i32 14, i32 14, i32 14, i32 14>
  %507 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %503, <4 x i32> %506) #6
  %508 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %499, <8 x i16> <i16 2404, i16 16207, i16 2404, i16 16207, i16 2404, i16 16207, i16 2404, i16 16207>) #6
  %509 = add <4 x i32> %508, <i32 8192, i32 8192, i32 8192, i32 8192>
  %510 = ashr <4 x i32> %509, <i32 14, i32 14, i32 14, i32 14>
  %511 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %500, <8 x i16> <i16 2404, i16 16207, i16 2404, i16 16207, i16 2404, i16 16207, i16 2404, i16 16207>) #6
  %512 = add <4 x i32> %511, <i32 8192, i32 8192, i32 8192, i32 8192>
  %513 = ashr <4 x i32> %512, <i32 14, i32 14, i32 14, i32 14>
  %514 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %510, <4 x i32> %513) #6
  %515 = add <8 x i16> %375, %353
  %516 = sub <8 x i16> %353, %375
  %517 = sub <8 x i16> %419, %397
  %518 = add <8 x i16> %419, %397
  %519 = add <8 x i16> %463, %441
  %520 = sub <8 x i16> %441, %463
  %521 = sub <8 x i16> %507, %485
  %522 = add <8 x i16> %507, %485
  %523 = add <8 x i16> %514, %492
  %524 = sub <8 x i16> %514, %492
  %525 = sub <8 x i16> %448, %470
  %526 = add <8 x i16> %470, %448
  %527 = add <8 x i16> %426, %404
  %528 = sub <8 x i16> %426, %404
  %529 = sub <8 x i16> %360, %382
  %530 = add <8 x i16> %382, %360
  %531 = shufflevector <8 x i16> %529, <8 x i16> %516, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %532 = shufflevector <8 x i16> %529, <8 x i16> %516, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %533 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %531, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #6
  %534 = add <4 x i32> %533, <i32 8192, i32 8192, i32 8192, i32 8192>
  %535 = ashr <4 x i32> %534, <i32 14, i32 14, i32 14, i32 14>
  %536 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %532, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #6
  %537 = add <4 x i32> %536, <i32 8192, i32 8192, i32 8192, i32 8192>
  %538 = ashr <4 x i32> %537, <i32 14, i32 14, i32 14, i32 14>
  %539 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %535, <4 x i32> %538) #6
  %540 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %531, <8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>) #6
  %541 = add <4 x i32> %540, <i32 8192, i32 8192, i32 8192, i32 8192>
  %542 = ashr <4 x i32> %541, <i32 14, i32 14, i32 14, i32 14>
  %543 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %532, <8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>) #6
  %544 = add <4 x i32> %543, <i32 8192, i32 8192, i32 8192, i32 8192>
  %545 = ashr <4 x i32> %544, <i32 14, i32 14, i32 14, i32 14>
  %546 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %542, <4 x i32> %545) #6
  %547 = shufflevector <8 x i16> %528, <8 x i16> %517, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %548 = shufflevector <8 x i16> %528, <8 x i16> %517, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %549 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %547, <8 x i16> <i16 -16069, i16 -3196, i16 -16069, i16 -3196, i16 -16069, i16 -3196, i16 -16069, i16 -3196>) #6
  %550 = add <4 x i32> %549, <i32 8192, i32 8192, i32 8192, i32 8192>
  %551 = ashr <4 x i32> %550, <i32 14, i32 14, i32 14, i32 14>
  %552 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %548, <8 x i16> <i16 -16069, i16 -3196, i16 -16069, i16 -3196, i16 -16069, i16 -3196, i16 -16069, i16 -3196>) #6
  %553 = add <4 x i32> %552, <i32 8192, i32 8192, i32 8192, i32 8192>
  %554 = ashr <4 x i32> %553, <i32 14, i32 14, i32 14, i32 14>
  %555 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %551, <4 x i32> %554) #6
  %556 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %547, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #6
  %557 = add <4 x i32> %556, <i32 8192, i32 8192, i32 8192, i32 8192>
  %558 = ashr <4 x i32> %557, <i32 14, i32 14, i32 14, i32 14>
  %559 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %548, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #6
  %560 = add <4 x i32> %559, <i32 8192, i32 8192, i32 8192, i32 8192>
  %561 = ashr <4 x i32> %560, <i32 14, i32 14, i32 14, i32 14>
  %562 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %558, <4 x i32> %561) #6
  %563 = shufflevector <8 x i16> %525, <8 x i16> %520, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %564 = shufflevector <8 x i16> %525, <8 x i16> %520, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %565 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %563, <8 x i16> <i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102>) #6
  %566 = add <4 x i32> %565, <i32 8192, i32 8192, i32 8192, i32 8192>
  %567 = ashr <4 x i32> %566, <i32 14, i32 14, i32 14, i32 14>
  %568 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %564, <8 x i16> <i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102>) #6
  %569 = add <4 x i32> %568, <i32 8192, i32 8192, i32 8192, i32 8192>
  %570 = ashr <4 x i32> %569, <i32 14, i32 14, i32 14, i32 14>
  %571 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %567, <4 x i32> %570) #6
  %572 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %563, <8 x i16> <i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623>) #6
  %573 = add <4 x i32> %572, <i32 8192, i32 8192, i32 8192, i32 8192>
  %574 = ashr <4 x i32> %573, <i32 14, i32 14, i32 14, i32 14>
  %575 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %564, <8 x i16> <i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623>) #6
  %576 = add <4 x i32> %575, <i32 8192, i32 8192, i32 8192, i32 8192>
  %577 = ashr <4 x i32> %576, <i32 14, i32 14, i32 14, i32 14>
  %578 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %574, <4 x i32> %577) #6
  %579 = shufflevector <8 x i16> %524, <8 x i16> %521, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %580 = shufflevector <8 x i16> %524, <8 x i16> %521, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %581 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %579, <8 x i16> <i16 -9102, i16 -13623, i16 -9102, i16 -13623, i16 -9102, i16 -13623, i16 -9102, i16 -13623>) #6
  %582 = add <4 x i32> %581, <i32 8192, i32 8192, i32 8192, i32 8192>
  %583 = ashr <4 x i32> %582, <i32 14, i32 14, i32 14, i32 14>
  %584 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %580, <8 x i16> <i16 -9102, i16 -13623, i16 -9102, i16 -13623, i16 -9102, i16 -13623, i16 -9102, i16 -13623>) #6
  %585 = add <4 x i32> %584, <i32 8192, i32 8192, i32 8192, i32 8192>
  %586 = ashr <4 x i32> %585, <i32 14, i32 14, i32 14, i32 14>
  %587 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %583, <4 x i32> %586) #6
  %588 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %579, <8 x i16> <i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102>) #6
  %589 = add <4 x i32> %588, <i32 8192, i32 8192, i32 8192, i32 8192>
  %590 = ashr <4 x i32> %589, <i32 14, i32 14, i32 14, i32 14>
  %591 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %580, <8 x i16> <i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102>) #6
  %592 = add <4 x i32> %591, <i32 8192, i32 8192, i32 8192, i32 8192>
  %593 = ashr <4 x i32> %592, <i32 14, i32 14, i32 14, i32 14>
  %594 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %590, <4 x i32> %593) #6
  %595 = add <8 x i16> %518, %515
  %596 = add <8 x i16> %555, %539
  %597 = sub <8 x i16> %539, %555
  %598 = sub <8 x i16> %515, %518
  %599 = sub <8 x i16> %522, %519
  %600 = sub <8 x i16> %587, %571
  %601 = add <8 x i16> %587, %571
  %602 = add <8 x i16> %522, %519
  %603 = add <8 x i16> %523, %526
  %604 = add <8 x i16> %594, %578
  %605 = sub <8 x i16> %594, %578
  %606 = sub <8 x i16> %523, %526
  %607 = sub <8 x i16> %530, %527
  %608 = sub <8 x i16> %546, %562
  %609 = add <8 x i16> %562, %546
  %610 = add <8 x i16> %527, %530
  %611 = shufflevector <8 x i16> %608, <8 x i16> %597, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %612 = shufflevector <8 x i16> %608, <8 x i16> %597, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %613 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %611, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %614 = add <4 x i32> %613, <i32 8192, i32 8192, i32 8192, i32 8192>
  %615 = ashr <4 x i32> %614, <i32 14, i32 14, i32 14, i32 14>
  %616 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %612, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %617 = add <4 x i32> %616, <i32 8192, i32 8192, i32 8192, i32 8192>
  %618 = ashr <4 x i32> %617, <i32 14, i32 14, i32 14, i32 14>
  %619 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %615, <4 x i32> %618) #6
  %620 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %611, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %621 = add <4 x i32> %620, <i32 8192, i32 8192, i32 8192, i32 8192>
  %622 = ashr <4 x i32> %621, <i32 14, i32 14, i32 14, i32 14>
  %623 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %612, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %624 = add <4 x i32> %623, <i32 8192, i32 8192, i32 8192, i32 8192>
  %625 = ashr <4 x i32> %624, <i32 14, i32 14, i32 14, i32 14>
  %626 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %622, <4 x i32> %625) #6
  %627 = shufflevector <8 x i16> %607, <8 x i16> %598, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %628 = shufflevector <8 x i16> %607, <8 x i16> %598, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %629 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %627, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %630 = add <4 x i32> %629, <i32 8192, i32 8192, i32 8192, i32 8192>
  %631 = ashr <4 x i32> %630, <i32 14, i32 14, i32 14, i32 14>
  %632 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %628, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %633 = add <4 x i32> %632, <i32 8192, i32 8192, i32 8192, i32 8192>
  %634 = ashr <4 x i32> %633, <i32 14, i32 14, i32 14, i32 14>
  %635 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %631, <4 x i32> %634) #6
  %636 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %627, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %637 = add <4 x i32> %636, <i32 8192, i32 8192, i32 8192, i32 8192>
  %638 = ashr <4 x i32> %637, <i32 14, i32 14, i32 14, i32 14>
  %639 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %628, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #6
  %640 = add <4 x i32> %639, <i32 8192, i32 8192, i32 8192, i32 8192>
  %641 = ashr <4 x i32> %640, <i32 14, i32 14, i32 14, i32 14>
  %642 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %638, <4 x i32> %641) #6
  %643 = shufflevector <8 x i16> %606, <8 x i16> %599, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %644 = shufflevector <8 x i16> %606, <8 x i16> %599, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %645 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %643, <8 x i16> <i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270>) #6
  %646 = add <4 x i32> %645, <i32 8192, i32 8192, i32 8192, i32 8192>
  %647 = ashr <4 x i32> %646, <i32 14, i32 14, i32 14, i32 14>
  %648 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %644, <8 x i16> <i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270>) #6
  %649 = add <4 x i32> %648, <i32 8192, i32 8192, i32 8192, i32 8192>
  %650 = ashr <4 x i32> %649, <i32 14, i32 14, i32 14, i32 14>
  %651 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %647, <4 x i32> %650) #6
  %652 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %643, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %653 = add <4 x i32> %652, <i32 8192, i32 8192, i32 8192, i32 8192>
  %654 = ashr <4 x i32> %653, <i32 14, i32 14, i32 14, i32 14>
  %655 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %644, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %656 = add <4 x i32> %655, <i32 8192, i32 8192, i32 8192, i32 8192>
  %657 = ashr <4 x i32> %656, <i32 14, i32 14, i32 14, i32 14>
  %658 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %654, <4 x i32> %657) #6
  %659 = shufflevector <8 x i16> %605, <8 x i16> %600, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %660 = shufflevector <8 x i16> %605, <8 x i16> %600, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %661 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %659, <8 x i16> <i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270>) #6
  %662 = add <4 x i32> %661, <i32 8192, i32 8192, i32 8192, i32 8192>
  %663 = ashr <4 x i32> %662, <i32 14, i32 14, i32 14, i32 14>
  %664 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %660, <8 x i16> <i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270>) #6
  %665 = add <4 x i32> %664, <i32 8192, i32 8192, i32 8192, i32 8192>
  %666 = ashr <4 x i32> %665, <i32 14, i32 14, i32 14, i32 14>
  %667 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %663, <4 x i32> %666) #6
  %668 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %659, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %669 = add <4 x i32> %668, <i32 8192, i32 8192, i32 8192, i32 8192>
  %670 = ashr <4 x i32> %669, <i32 14, i32 14, i32 14, i32 14>
  %671 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %660, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #6
  %672 = add <4 x i32> %671, <i32 8192, i32 8192, i32 8192, i32 8192>
  %673 = ashr <4 x i32> %672, <i32 14, i32 14, i32 14, i32 14>
  %674 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %670, <4 x i32> %673) #6
  %675 = add <8 x i16> %602, %595
  %676 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 16
  %677 = bitcast <2 x i64>* %676 to <8 x i16>*
  store <8 x i16> %675, <8 x i16>* %677, align 16
  %678 = add <8 x i16> %601, %596
  %679 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 17
  %680 = bitcast <2 x i64>* %679 to <8 x i16>*
  store <8 x i16> %678, <8 x i16>* %680, align 16
  %681 = add <8 x i16> %667, %619
  %682 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 18
  %683 = bitcast <2 x i64>* %682 to <8 x i16>*
  store <8 x i16> %681, <8 x i16>* %683, align 16
  %684 = add <8 x i16> %651, %635
  %685 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 19
  %686 = bitcast <2 x i64>* %685 to <8 x i16>*
  store <8 x i16> %684, <8 x i16>* %686, align 16
  %687 = sub <8 x i16> %635, %651
  %688 = sub <8 x i16> %619, %667
  %689 = sub <8 x i16> %596, %601
  %690 = sub <8 x i16> %595, %602
  %691 = sub <8 x i16> %610, %603
  %692 = sub <8 x i16> %609, %604
  %693 = sub <8 x i16> %626, %674
  %694 = sub <8 x i16> %642, %658
  %695 = add <8 x i16> %658, %642
  %696 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 28
  %697 = bitcast <2 x i64>* %696 to <8 x i16>*
  store <8 x i16> %695, <8 x i16>* %697, align 16
  %698 = add <8 x i16> %674, %626
  %699 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 29
  %700 = bitcast <2 x i64>* %699 to <8 x i16>*
  store <8 x i16> %698, <8 x i16>* %700, align 16
  %701 = add <8 x i16> %604, %609
  %702 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 30
  %703 = bitcast <2 x i64>* %702 to <8 x i16>*
  store <8 x i16> %701, <8 x i16>* %703, align 16
  %704 = add <8 x i16> %603, %610
  %705 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 31
  %706 = bitcast <2 x i64>* %705 to <8 x i16>*
  store <8 x i16> %704, <8 x i16>* %706, align 16
  %707 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 20
  %708 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 27
  %709 = shufflevector <8 x i16> %694, <8 x i16> %687, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %710 = shufflevector <8 x i16> %694, <8 x i16> %687, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %711 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %709, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %712 = add <4 x i32> %711, <i32 8192, i32 8192, i32 8192, i32 8192>
  %713 = ashr <4 x i32> %712, <i32 14, i32 14, i32 14, i32 14>
  %714 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %710, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %715 = add <4 x i32> %714, <i32 8192, i32 8192, i32 8192, i32 8192>
  %716 = ashr <4 x i32> %715, <i32 14, i32 14, i32 14, i32 14>
  %717 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %713, <4 x i32> %716) #6
  %718 = bitcast <2 x i64>* %707 to <8 x i16>*
  store <8 x i16> %717, <8 x i16>* %718, align 16
  %719 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %709, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %720 = add <4 x i32> %719, <i32 8192, i32 8192, i32 8192, i32 8192>
  %721 = ashr <4 x i32> %720, <i32 14, i32 14, i32 14, i32 14>
  %722 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %710, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %723 = add <4 x i32> %722, <i32 8192, i32 8192, i32 8192, i32 8192>
  %724 = ashr <4 x i32> %723, <i32 14, i32 14, i32 14, i32 14>
  %725 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %721, <4 x i32> %724) #6
  %726 = bitcast <2 x i64>* %708 to <8 x i16>*
  store <8 x i16> %725, <8 x i16>* %726, align 16
  %727 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 21
  %728 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 26
  %729 = shufflevector <8 x i16> %693, <8 x i16> %688, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %730 = shufflevector <8 x i16> %693, <8 x i16> %688, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %731 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %729, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %732 = add <4 x i32> %731, <i32 8192, i32 8192, i32 8192, i32 8192>
  %733 = ashr <4 x i32> %732, <i32 14, i32 14, i32 14, i32 14>
  %734 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %730, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %735 = add <4 x i32> %734, <i32 8192, i32 8192, i32 8192, i32 8192>
  %736 = ashr <4 x i32> %735, <i32 14, i32 14, i32 14, i32 14>
  %737 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %733, <4 x i32> %736) #6
  %738 = bitcast <2 x i64>* %727 to <8 x i16>*
  store <8 x i16> %737, <8 x i16>* %738, align 16
  %739 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %729, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %740 = add <4 x i32> %739, <i32 8192, i32 8192, i32 8192, i32 8192>
  %741 = ashr <4 x i32> %740, <i32 14, i32 14, i32 14, i32 14>
  %742 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %730, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %743 = add <4 x i32> %742, <i32 8192, i32 8192, i32 8192, i32 8192>
  %744 = ashr <4 x i32> %743, <i32 14, i32 14, i32 14, i32 14>
  %745 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %741, <4 x i32> %744) #6
  %746 = bitcast <2 x i64>* %728 to <8 x i16>*
  store <8 x i16> %745, <8 x i16>* %746, align 16
  %747 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 22
  %748 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 25
  %749 = shufflevector <8 x i16> %692, <8 x i16> %689, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %750 = shufflevector <8 x i16> %692, <8 x i16> %689, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %751 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %749, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %752 = add <4 x i32> %751, <i32 8192, i32 8192, i32 8192, i32 8192>
  %753 = ashr <4 x i32> %752, <i32 14, i32 14, i32 14, i32 14>
  %754 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %750, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %755 = add <4 x i32> %754, <i32 8192, i32 8192, i32 8192, i32 8192>
  %756 = ashr <4 x i32> %755, <i32 14, i32 14, i32 14, i32 14>
  %757 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %753, <4 x i32> %756) #6
  %758 = bitcast <2 x i64>* %747 to <8 x i16>*
  store <8 x i16> %757, <8 x i16>* %758, align 16
  %759 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %749, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %760 = add <4 x i32> %759, <i32 8192, i32 8192, i32 8192, i32 8192>
  %761 = ashr <4 x i32> %760, <i32 14, i32 14, i32 14, i32 14>
  %762 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %750, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %763 = add <4 x i32> %762, <i32 8192, i32 8192, i32 8192, i32 8192>
  %764 = ashr <4 x i32> %763, <i32 14, i32 14, i32 14, i32 14>
  %765 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %761, <4 x i32> %764) #6
  %766 = bitcast <2 x i64>* %748 to <8 x i16>*
  store <8 x i16> %765, <8 x i16>* %766, align 16
  %767 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 23
  %768 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 24
  %769 = shufflevector <8 x i16> %691, <8 x i16> %690, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %770 = shufflevector <8 x i16> %691, <8 x i16> %690, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %771 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %769, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %772 = add <4 x i32> %771, <i32 8192, i32 8192, i32 8192, i32 8192>
  %773 = ashr <4 x i32> %772, <i32 14, i32 14, i32 14, i32 14>
  %774 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %770, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #6
  %775 = add <4 x i32> %774, <i32 8192, i32 8192, i32 8192, i32 8192>
  %776 = ashr <4 x i32> %775, <i32 14, i32 14, i32 14, i32 14>
  %777 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %773, <4 x i32> %776) #6
  %778 = bitcast <2 x i64>* %767 to <8 x i16>*
  store <8 x i16> %777, <8 x i16>* %778, align 16
  %779 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %769, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %780 = add <4 x i32> %779, <i32 8192, i32 8192, i32 8192, i32 8192>
  %781 = ashr <4 x i32> %780, <i32 14, i32 14, i32 14, i32 14>
  %782 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %770, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #6
  %783 = add <4 x i32> %782, <i32 8192, i32 8192, i32 8192, i32 8192>
  %784 = ashr <4 x i32> %783, <i32 14, i32 14, i32 14, i32 14>
  %785 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %781, <4 x i32> %784) #6
  %786 = bitcast <2 x i64>* %768 to <8 x i16>*
  store <8 x i16> %785, <8 x i16>* %786, align 16
  br label %787

787:                                              ; preds = %787, %2
  %788 = phi i64 [ 0, %2 ], [ %804, %787 ]
  %789 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 %788
  %790 = bitcast <2 x i64>* %789 to <8 x i16>*
  %791 = load <8 x i16>, <8 x i16>* %790, align 16
  %792 = shl i64 %788, 32
  %793 = sub nuw nsw i64 133143986176, %792
  %794 = ashr exact i64 %793, 32
  %795 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 %794
  %796 = bitcast <2 x i64>* %795 to <8 x i16>*
  %797 = load <8 x i16>, <8 x i16>* %796, align 16
  %798 = add <8 x i16> %797, %791
  %799 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %788
  %800 = bitcast <2 x i64>* %799 to <8 x i16>*
  store <8 x i16> %798, <8 x i16>* %800, align 16
  %801 = sub <8 x i16> %791, %797
  %802 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %794
  %803 = bitcast <2 x i64>* %802 to <8 x i16>*
  store <8 x i16> %801, <8 x i16>* %803, align 16
  %804 = add nuw nsw i64 %788, 1
  %805 = icmp eq i64 %804, 16
  br i1 %805, label %806, label %787

806:                                              ; preds = %787
  call void @llvm.lifetime.end.p0i8(i64 512, i8* nonnull %4) #6
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @vpx_idct32x32_1024_add_sse2(i32* nocapture readonly, i8* nocapture, i32) local_unnamed_addr #0 {
  %4 = alloca [4 x [32 x <2 x i64>]], align 16
  %5 = alloca [32 x <2 x i64>], align 16
  %6 = bitcast [4 x [32 x <2 x i64>]]* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 2048, i8* nonnull %6) #6
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %6, i8 -86, i64 2048, i1 false)
  %7 = bitcast [32 x <2 x i64>]* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 512, i8* nonnull %7) #6
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %7, i8 -86, i64 512, i1 false)
  %8 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 0
  %9 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 1
  %10 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 2
  %11 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 3
  %12 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 4
  %13 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 5
  %14 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 6
  %15 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 7
  %16 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 8
  %17 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 9
  %18 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 10
  %19 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 11
  %20 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 12
  %21 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 13
  %22 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 14
  %23 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 15
  %24 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 16
  %25 = bitcast <2 x i64>* %24 to <8 x i16>*
  %26 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 17
  %27 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 18
  %28 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 19
  %29 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 20
  %30 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 21
  %31 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 22
  %32 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 23
  %33 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 24
  %34 = bitcast <2 x i64>* %33 to <8 x i16>*
  %35 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 25
  %36 = bitcast <2 x i64>* %35 to <8 x i16>*
  %37 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 26
  %38 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 27
  %39 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 28
  %40 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 29
  %41 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 30
  %42 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 31
  br label %45

43:                                               ; preds = %45
  %44 = sext i32 %2 to i64
  br label %435

45:                                               ; preds = %45, %3
  %46 = phi i64 [ 0, %3 ], [ %433, %45 ]
  %47 = phi i32* [ %0, %3 ], [ %432, %45 ]
  %48 = bitcast i32* %47 to <4 x i32>*
  %49 = load <4 x i32>, <4 x i32>* %48, align 16
  %50 = getelementptr inbounds i32, i32* %47, i64 4
  %51 = bitcast i32* %50 to <4 x i32>*
  %52 = load <4 x i32>, <4 x i32>* %51, align 16
  %53 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %49, <4 x i32> %52) #6
  %54 = getelementptr inbounds i32, i32* %47, i64 32
  %55 = bitcast i32* %54 to <4 x i32>*
  %56 = load <4 x i32>, <4 x i32>* %55, align 16
  %57 = getelementptr inbounds i32, i32* %47, i64 36
  %58 = bitcast i32* %57 to <4 x i32>*
  %59 = load <4 x i32>, <4 x i32>* %58, align 16
  %60 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %56, <4 x i32> %59) #6
  %61 = getelementptr inbounds i32, i32* %47, i64 64
  %62 = bitcast i32* %61 to <4 x i32>*
  %63 = load <4 x i32>, <4 x i32>* %62, align 16
  %64 = getelementptr inbounds i32, i32* %47, i64 68
  %65 = bitcast i32* %64 to <4 x i32>*
  %66 = load <4 x i32>, <4 x i32>* %65, align 16
  %67 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %63, <4 x i32> %66) #6
  %68 = getelementptr inbounds i32, i32* %47, i64 96
  %69 = bitcast i32* %68 to <4 x i32>*
  %70 = load <4 x i32>, <4 x i32>* %69, align 16
  %71 = getelementptr inbounds i32, i32* %47, i64 100
  %72 = bitcast i32* %71 to <4 x i32>*
  %73 = load <4 x i32>, <4 x i32>* %72, align 16
  %74 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %70, <4 x i32> %73) #6
  %75 = getelementptr inbounds i32, i32* %47, i64 128
  %76 = bitcast i32* %75 to <4 x i32>*
  %77 = load <4 x i32>, <4 x i32>* %76, align 16
  %78 = getelementptr inbounds i32, i32* %47, i64 132
  %79 = bitcast i32* %78 to <4 x i32>*
  %80 = load <4 x i32>, <4 x i32>* %79, align 16
  %81 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %77, <4 x i32> %80) #6
  %82 = getelementptr inbounds i32, i32* %47, i64 160
  %83 = bitcast i32* %82 to <4 x i32>*
  %84 = load <4 x i32>, <4 x i32>* %83, align 16
  %85 = getelementptr inbounds i32, i32* %47, i64 164
  %86 = bitcast i32* %85 to <4 x i32>*
  %87 = load <4 x i32>, <4 x i32>* %86, align 16
  %88 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %84, <4 x i32> %87) #6
  %89 = getelementptr inbounds i32, i32* %47, i64 192
  %90 = bitcast i32* %89 to <4 x i32>*
  %91 = load <4 x i32>, <4 x i32>* %90, align 16
  %92 = getelementptr inbounds i32, i32* %47, i64 196
  %93 = bitcast i32* %92 to <4 x i32>*
  %94 = load <4 x i32>, <4 x i32>* %93, align 16
  %95 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %91, <4 x i32> %94) #6
  %96 = getelementptr inbounds i32, i32* %47, i64 224
  %97 = bitcast i32* %96 to <4 x i32>*
  %98 = load <4 x i32>, <4 x i32>* %97, align 16
  %99 = getelementptr inbounds i32, i32* %47, i64 228
  %100 = bitcast i32* %99 to <4 x i32>*
  %101 = load <4 x i32>, <4 x i32>* %100, align 16
  %102 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %98, <4 x i32> %101) #6
  %103 = shufflevector <8 x i16> %53, <8 x i16> %60, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %104 = shufflevector <8 x i16> %67, <8 x i16> %74, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %105 = shufflevector <8 x i16> %81, <8 x i16> %88, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %106 = shufflevector <8 x i16> %95, <8 x i16> %102, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %107 = shufflevector <8 x i16> %53, <8 x i16> %60, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %108 = shufflevector <8 x i16> %67, <8 x i16> %74, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %109 = shufflevector <8 x i16> %81, <8 x i16> %88, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %110 = shufflevector <8 x i16> %95, <8 x i16> %102, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %111 = bitcast <8 x i16> %103 to <4 x i32>
  %112 = bitcast <8 x i16> %104 to <4 x i32>
  %113 = shufflevector <4 x i32> %111, <4 x i32> %112, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %114 = bitcast <4 x i32> %113 to <2 x i64>
  %115 = bitcast <8 x i16> %105 to <4 x i32>
  %116 = bitcast <8 x i16> %106 to <4 x i32>
  %117 = shufflevector <4 x i32> %115, <4 x i32> %116, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %118 = bitcast <4 x i32> %117 to <2 x i64>
  %119 = bitcast <8 x i16> %107 to <4 x i32>
  %120 = bitcast <8 x i16> %108 to <4 x i32>
  %121 = shufflevector <4 x i32> %119, <4 x i32> %120, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %122 = bitcast <4 x i32> %121 to <2 x i64>
  %123 = bitcast <8 x i16> %109 to <4 x i32>
  %124 = bitcast <8 x i16> %110 to <4 x i32>
  %125 = shufflevector <4 x i32> %123, <4 x i32> %124, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %126 = bitcast <4 x i32> %125 to <2 x i64>
  %127 = shufflevector <4 x i32> %111, <4 x i32> %112, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %128 = bitcast <4 x i32> %127 to <2 x i64>
  %129 = shufflevector <4 x i32> %115, <4 x i32> %116, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %130 = bitcast <4 x i32> %129 to <2 x i64>
  %131 = shufflevector <4 x i32> %119, <4 x i32> %120, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %132 = bitcast <4 x i32> %131 to <2 x i64>
  %133 = shufflevector <4 x i32> %123, <4 x i32> %124, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %134 = bitcast <4 x i32> %133 to <2 x i64>
  %135 = shufflevector <2 x i64> %114, <2 x i64> %118, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %135, <2 x i64>* %8, align 16
  %136 = shufflevector <2 x i64> %114, <2 x i64> %118, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %136, <2 x i64>* %9, align 16
  %137 = shufflevector <2 x i64> %128, <2 x i64> %130, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %137, <2 x i64>* %10, align 16
  %138 = shufflevector <2 x i64> %128, <2 x i64> %130, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %138, <2 x i64>* %11, align 16
  %139 = shufflevector <2 x i64> %122, <2 x i64> %126, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %139, <2 x i64>* %12, align 16
  %140 = shufflevector <2 x i64> %122, <2 x i64> %126, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %140, <2 x i64>* %13, align 16
  %141 = shufflevector <2 x i64> %132, <2 x i64> %134, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %141, <2 x i64>* %14, align 16
  %142 = shufflevector <2 x i64> %132, <2 x i64> %134, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %142, <2 x i64>* %15, align 16
  %143 = getelementptr inbounds i32, i32* %47, i64 8
  %144 = bitcast i32* %143 to <4 x i32>*
  %145 = load <4 x i32>, <4 x i32>* %144, align 16
  %146 = getelementptr inbounds i32, i32* %47, i64 12
  %147 = bitcast i32* %146 to <4 x i32>*
  %148 = load <4 x i32>, <4 x i32>* %147, align 16
  %149 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %145, <4 x i32> %148) #6
  %150 = getelementptr inbounds i32, i32* %47, i64 40
  %151 = bitcast i32* %150 to <4 x i32>*
  %152 = load <4 x i32>, <4 x i32>* %151, align 16
  %153 = getelementptr inbounds i32, i32* %47, i64 44
  %154 = bitcast i32* %153 to <4 x i32>*
  %155 = load <4 x i32>, <4 x i32>* %154, align 16
  %156 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %152, <4 x i32> %155) #6
  %157 = getelementptr inbounds i32, i32* %47, i64 72
  %158 = bitcast i32* %157 to <4 x i32>*
  %159 = load <4 x i32>, <4 x i32>* %158, align 16
  %160 = getelementptr inbounds i32, i32* %47, i64 76
  %161 = bitcast i32* %160 to <4 x i32>*
  %162 = load <4 x i32>, <4 x i32>* %161, align 16
  %163 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %159, <4 x i32> %162) #6
  %164 = getelementptr inbounds i32, i32* %47, i64 104
  %165 = bitcast i32* %164 to <4 x i32>*
  %166 = load <4 x i32>, <4 x i32>* %165, align 16
  %167 = getelementptr inbounds i32, i32* %47, i64 108
  %168 = bitcast i32* %167 to <4 x i32>*
  %169 = load <4 x i32>, <4 x i32>* %168, align 16
  %170 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %166, <4 x i32> %169) #6
  %171 = getelementptr inbounds i32, i32* %47, i64 136
  %172 = bitcast i32* %171 to <4 x i32>*
  %173 = load <4 x i32>, <4 x i32>* %172, align 16
  %174 = getelementptr inbounds i32, i32* %47, i64 140
  %175 = bitcast i32* %174 to <4 x i32>*
  %176 = load <4 x i32>, <4 x i32>* %175, align 16
  %177 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %173, <4 x i32> %176) #6
  %178 = getelementptr inbounds i32, i32* %47, i64 168
  %179 = bitcast i32* %178 to <4 x i32>*
  %180 = load <4 x i32>, <4 x i32>* %179, align 16
  %181 = getelementptr inbounds i32, i32* %47, i64 172
  %182 = bitcast i32* %181 to <4 x i32>*
  %183 = load <4 x i32>, <4 x i32>* %182, align 16
  %184 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %180, <4 x i32> %183) #6
  %185 = getelementptr inbounds i32, i32* %47, i64 200
  %186 = bitcast i32* %185 to <4 x i32>*
  %187 = load <4 x i32>, <4 x i32>* %186, align 16
  %188 = getelementptr inbounds i32, i32* %47, i64 204
  %189 = bitcast i32* %188 to <4 x i32>*
  %190 = load <4 x i32>, <4 x i32>* %189, align 16
  %191 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %187, <4 x i32> %190) #6
  %192 = getelementptr inbounds i32, i32* %47, i64 232
  %193 = bitcast i32* %192 to <4 x i32>*
  %194 = load <4 x i32>, <4 x i32>* %193, align 16
  %195 = getelementptr inbounds i32, i32* %47, i64 236
  %196 = bitcast i32* %195 to <4 x i32>*
  %197 = load <4 x i32>, <4 x i32>* %196, align 16
  %198 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %194, <4 x i32> %197) #6
  %199 = shufflevector <8 x i16> %149, <8 x i16> %156, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %200 = shufflevector <8 x i16> %163, <8 x i16> %170, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %201 = shufflevector <8 x i16> %177, <8 x i16> %184, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %202 = shufflevector <8 x i16> %191, <8 x i16> %198, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %203 = shufflevector <8 x i16> %149, <8 x i16> %156, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %204 = shufflevector <8 x i16> %163, <8 x i16> %170, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %205 = shufflevector <8 x i16> %177, <8 x i16> %184, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %206 = shufflevector <8 x i16> %191, <8 x i16> %198, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %207 = bitcast <8 x i16> %199 to <4 x i32>
  %208 = bitcast <8 x i16> %200 to <4 x i32>
  %209 = shufflevector <4 x i32> %207, <4 x i32> %208, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %210 = bitcast <4 x i32> %209 to <2 x i64>
  %211 = bitcast <8 x i16> %201 to <4 x i32>
  %212 = bitcast <8 x i16> %202 to <4 x i32>
  %213 = shufflevector <4 x i32> %211, <4 x i32> %212, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %214 = bitcast <4 x i32> %213 to <2 x i64>
  %215 = bitcast <8 x i16> %203 to <4 x i32>
  %216 = bitcast <8 x i16> %204 to <4 x i32>
  %217 = shufflevector <4 x i32> %215, <4 x i32> %216, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %218 = bitcast <4 x i32> %217 to <2 x i64>
  %219 = bitcast <8 x i16> %205 to <4 x i32>
  %220 = bitcast <8 x i16> %206 to <4 x i32>
  %221 = shufflevector <4 x i32> %219, <4 x i32> %220, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %222 = bitcast <4 x i32> %221 to <2 x i64>
  %223 = shufflevector <4 x i32> %207, <4 x i32> %208, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %224 = bitcast <4 x i32> %223 to <2 x i64>
  %225 = shufflevector <4 x i32> %211, <4 x i32> %212, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %226 = bitcast <4 x i32> %225 to <2 x i64>
  %227 = shufflevector <4 x i32> %215, <4 x i32> %216, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %228 = bitcast <4 x i32> %227 to <2 x i64>
  %229 = shufflevector <4 x i32> %219, <4 x i32> %220, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %230 = bitcast <4 x i32> %229 to <2 x i64>
  %231 = shufflevector <2 x i64> %210, <2 x i64> %214, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %231, <2 x i64>* %16, align 16
  %232 = shufflevector <2 x i64> %210, <2 x i64> %214, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %232, <2 x i64>* %17, align 16
  %233 = shufflevector <2 x i64> %224, <2 x i64> %226, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %233, <2 x i64>* %18, align 16
  %234 = shufflevector <2 x i64> %224, <2 x i64> %226, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %234, <2 x i64>* %19, align 16
  %235 = shufflevector <2 x i64> %218, <2 x i64> %222, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %235, <2 x i64>* %20, align 16
  %236 = shufflevector <2 x i64> %218, <2 x i64> %222, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %236, <2 x i64>* %21, align 16
  %237 = shufflevector <2 x i64> %228, <2 x i64> %230, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %237, <2 x i64>* %22, align 16
  %238 = shufflevector <2 x i64> %228, <2 x i64> %230, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %238, <2 x i64>* %23, align 16
  %239 = getelementptr inbounds i32, i32* %47, i64 16
  %240 = bitcast i32* %239 to <4 x i32>*
  %241 = load <4 x i32>, <4 x i32>* %240, align 16
  %242 = getelementptr inbounds i32, i32* %47, i64 20
  %243 = bitcast i32* %242 to <4 x i32>*
  %244 = load <4 x i32>, <4 x i32>* %243, align 16
  %245 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %241, <4 x i32> %244) #6
  store <8 x i16> %245, <8 x i16>* %25, align 16
  %246 = getelementptr inbounds i32, i32* %47, i64 48
  %247 = bitcast i32* %246 to <4 x i32>*
  %248 = load <4 x i32>, <4 x i32>* %247, align 16
  %249 = getelementptr inbounds i32, i32* %47, i64 52
  %250 = bitcast i32* %249 to <4 x i32>*
  %251 = load <4 x i32>, <4 x i32>* %250, align 16
  %252 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %248, <4 x i32> %251) #6
  %253 = getelementptr inbounds i32, i32* %47, i64 80
  %254 = bitcast i32* %253 to <4 x i32>*
  %255 = load <4 x i32>, <4 x i32>* %254, align 16
  %256 = getelementptr inbounds i32, i32* %47, i64 84
  %257 = bitcast i32* %256 to <4 x i32>*
  %258 = load <4 x i32>, <4 x i32>* %257, align 16
  %259 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %255, <4 x i32> %258) #6
  %260 = getelementptr inbounds i32, i32* %47, i64 112
  %261 = bitcast i32* %260 to <4 x i32>*
  %262 = load <4 x i32>, <4 x i32>* %261, align 16
  %263 = getelementptr inbounds i32, i32* %47, i64 116
  %264 = bitcast i32* %263 to <4 x i32>*
  %265 = load <4 x i32>, <4 x i32>* %264, align 16
  %266 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %262, <4 x i32> %265) #6
  %267 = getelementptr inbounds i32, i32* %47, i64 144
  %268 = bitcast i32* %267 to <4 x i32>*
  %269 = load <4 x i32>, <4 x i32>* %268, align 16
  %270 = getelementptr inbounds i32, i32* %47, i64 148
  %271 = bitcast i32* %270 to <4 x i32>*
  %272 = load <4 x i32>, <4 x i32>* %271, align 16
  %273 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %269, <4 x i32> %272) #6
  %274 = getelementptr inbounds i32, i32* %47, i64 176
  %275 = bitcast i32* %274 to <4 x i32>*
  %276 = load <4 x i32>, <4 x i32>* %275, align 16
  %277 = getelementptr inbounds i32, i32* %47, i64 180
  %278 = bitcast i32* %277 to <4 x i32>*
  %279 = load <4 x i32>, <4 x i32>* %278, align 16
  %280 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %276, <4 x i32> %279) #6
  %281 = getelementptr inbounds i32, i32* %47, i64 208
  %282 = bitcast i32* %281 to <4 x i32>*
  %283 = load <4 x i32>, <4 x i32>* %282, align 16
  %284 = getelementptr inbounds i32, i32* %47, i64 212
  %285 = bitcast i32* %284 to <4 x i32>*
  %286 = load <4 x i32>, <4 x i32>* %285, align 16
  %287 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %283, <4 x i32> %286) #6
  %288 = getelementptr inbounds i32, i32* %47, i64 240
  %289 = bitcast i32* %288 to <4 x i32>*
  %290 = load <4 x i32>, <4 x i32>* %289, align 16
  %291 = getelementptr inbounds i32, i32* %47, i64 244
  %292 = bitcast i32* %291 to <4 x i32>*
  %293 = load <4 x i32>, <4 x i32>* %292, align 16
  %294 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %290, <4 x i32> %293) #6
  %295 = shufflevector <8 x i16> %245, <8 x i16> %252, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %296 = shufflevector <8 x i16> %259, <8 x i16> %266, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %297 = shufflevector <8 x i16> %273, <8 x i16> %280, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %298 = shufflevector <8 x i16> %287, <8 x i16> %294, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %299 = shufflevector <8 x i16> %245, <8 x i16> %252, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %300 = shufflevector <8 x i16> %259, <8 x i16> %266, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %301 = shufflevector <8 x i16> %273, <8 x i16> %280, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %302 = shufflevector <8 x i16> %287, <8 x i16> %294, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %303 = bitcast <8 x i16> %295 to <4 x i32>
  %304 = bitcast <8 x i16> %296 to <4 x i32>
  %305 = shufflevector <4 x i32> %303, <4 x i32> %304, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %306 = bitcast <4 x i32> %305 to <2 x i64>
  %307 = bitcast <8 x i16> %297 to <4 x i32>
  %308 = bitcast <8 x i16> %298 to <4 x i32>
  %309 = shufflevector <4 x i32> %307, <4 x i32> %308, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %310 = bitcast <4 x i32> %309 to <2 x i64>
  %311 = bitcast <8 x i16> %299 to <4 x i32>
  %312 = bitcast <8 x i16> %300 to <4 x i32>
  %313 = shufflevector <4 x i32> %311, <4 x i32> %312, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %314 = bitcast <4 x i32> %313 to <2 x i64>
  %315 = bitcast <8 x i16> %301 to <4 x i32>
  %316 = bitcast <8 x i16> %302 to <4 x i32>
  %317 = shufflevector <4 x i32> %315, <4 x i32> %316, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %318 = bitcast <4 x i32> %317 to <2 x i64>
  %319 = shufflevector <4 x i32> %303, <4 x i32> %304, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %320 = bitcast <4 x i32> %319 to <2 x i64>
  %321 = shufflevector <4 x i32> %307, <4 x i32> %308, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %322 = bitcast <4 x i32> %321 to <2 x i64>
  %323 = shufflevector <4 x i32> %311, <4 x i32> %312, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %324 = bitcast <4 x i32> %323 to <2 x i64>
  %325 = shufflevector <4 x i32> %315, <4 x i32> %316, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %326 = bitcast <4 x i32> %325 to <2 x i64>
  %327 = shufflevector <2 x i64> %306, <2 x i64> %310, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %327, <2 x i64>* %24, align 16
  %328 = shufflevector <2 x i64> %306, <2 x i64> %310, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %328, <2 x i64>* %26, align 16
  %329 = shufflevector <2 x i64> %320, <2 x i64> %322, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %329, <2 x i64>* %27, align 16
  %330 = shufflevector <2 x i64> %320, <2 x i64> %322, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %330, <2 x i64>* %28, align 16
  %331 = shufflevector <2 x i64> %314, <2 x i64> %318, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %331, <2 x i64>* %29, align 16
  %332 = shufflevector <2 x i64> %314, <2 x i64> %318, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %332, <2 x i64>* %30, align 16
  %333 = shufflevector <2 x i64> %324, <2 x i64> %326, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %333, <2 x i64>* %31, align 16
  %334 = shufflevector <2 x i64> %324, <2 x i64> %326, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %334, <2 x i64>* %32, align 16
  %335 = getelementptr inbounds i32, i32* %47, i64 24
  %336 = bitcast i32* %335 to <4 x i32>*
  %337 = load <4 x i32>, <4 x i32>* %336, align 16
  %338 = getelementptr inbounds i32, i32* %47, i64 28
  %339 = bitcast i32* %338 to <4 x i32>*
  %340 = load <4 x i32>, <4 x i32>* %339, align 16
  %341 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %337, <4 x i32> %340) #6
  store <8 x i16> %341, <8 x i16>* %34, align 16
  %342 = getelementptr inbounds i32, i32* %47, i64 56
  %343 = bitcast i32* %342 to <4 x i32>*
  %344 = load <4 x i32>, <4 x i32>* %343, align 16
  %345 = getelementptr inbounds i32, i32* %47, i64 60
  %346 = bitcast i32* %345 to <4 x i32>*
  %347 = load <4 x i32>, <4 x i32>* %346, align 16
  %348 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %344, <4 x i32> %347) #6
  store <8 x i16> %348, <8 x i16>* %36, align 16
  %349 = getelementptr inbounds i32, i32* %47, i64 88
  %350 = bitcast i32* %349 to <4 x i32>*
  %351 = load <4 x i32>, <4 x i32>* %350, align 16
  %352 = getelementptr inbounds i32, i32* %47, i64 92
  %353 = bitcast i32* %352 to <4 x i32>*
  %354 = load <4 x i32>, <4 x i32>* %353, align 16
  %355 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %351, <4 x i32> %354) #6
  %356 = getelementptr inbounds i32, i32* %47, i64 120
  %357 = bitcast i32* %356 to <4 x i32>*
  %358 = load <4 x i32>, <4 x i32>* %357, align 16
  %359 = getelementptr inbounds i32, i32* %47, i64 124
  %360 = bitcast i32* %359 to <4 x i32>*
  %361 = load <4 x i32>, <4 x i32>* %360, align 16
  %362 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %358, <4 x i32> %361) #6
  %363 = getelementptr inbounds i32, i32* %47, i64 152
  %364 = bitcast i32* %363 to <4 x i32>*
  %365 = load <4 x i32>, <4 x i32>* %364, align 16
  %366 = getelementptr inbounds i32, i32* %47, i64 156
  %367 = bitcast i32* %366 to <4 x i32>*
  %368 = load <4 x i32>, <4 x i32>* %367, align 16
  %369 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %365, <4 x i32> %368) #6
  %370 = getelementptr inbounds i32, i32* %47, i64 184
  %371 = bitcast i32* %370 to <4 x i32>*
  %372 = load <4 x i32>, <4 x i32>* %371, align 16
  %373 = getelementptr inbounds i32, i32* %47, i64 188
  %374 = bitcast i32* %373 to <4 x i32>*
  %375 = load <4 x i32>, <4 x i32>* %374, align 16
  %376 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %372, <4 x i32> %375) #6
  %377 = getelementptr inbounds i32, i32* %47, i64 216
  %378 = bitcast i32* %377 to <4 x i32>*
  %379 = load <4 x i32>, <4 x i32>* %378, align 16
  %380 = getelementptr inbounds i32, i32* %47, i64 220
  %381 = bitcast i32* %380 to <4 x i32>*
  %382 = load <4 x i32>, <4 x i32>* %381, align 16
  %383 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %379, <4 x i32> %382) #6
  %384 = getelementptr inbounds i32, i32* %47, i64 248
  %385 = bitcast i32* %384 to <4 x i32>*
  %386 = load <4 x i32>, <4 x i32>* %385, align 16
  %387 = getelementptr inbounds i32, i32* %47, i64 252
  %388 = bitcast i32* %387 to <4 x i32>*
  %389 = load <4 x i32>, <4 x i32>* %388, align 16
  %390 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %386, <4 x i32> %389) #6
  %391 = shufflevector <8 x i16> %341, <8 x i16> %348, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %392 = shufflevector <8 x i16> %355, <8 x i16> %362, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %393 = shufflevector <8 x i16> %369, <8 x i16> %376, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %394 = shufflevector <8 x i16> %383, <8 x i16> %390, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %395 = shufflevector <8 x i16> %341, <8 x i16> %348, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %396 = shufflevector <8 x i16> %355, <8 x i16> %362, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %397 = shufflevector <8 x i16> %369, <8 x i16> %376, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %398 = shufflevector <8 x i16> %383, <8 x i16> %390, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %399 = bitcast <8 x i16> %391 to <4 x i32>
  %400 = bitcast <8 x i16> %392 to <4 x i32>
  %401 = shufflevector <4 x i32> %399, <4 x i32> %400, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %402 = bitcast <4 x i32> %401 to <2 x i64>
  %403 = bitcast <8 x i16> %393 to <4 x i32>
  %404 = bitcast <8 x i16> %394 to <4 x i32>
  %405 = shufflevector <4 x i32> %403, <4 x i32> %404, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %406 = bitcast <4 x i32> %405 to <2 x i64>
  %407 = bitcast <8 x i16> %395 to <4 x i32>
  %408 = bitcast <8 x i16> %396 to <4 x i32>
  %409 = shufflevector <4 x i32> %407, <4 x i32> %408, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %410 = bitcast <4 x i32> %409 to <2 x i64>
  %411 = bitcast <8 x i16> %397 to <4 x i32>
  %412 = bitcast <8 x i16> %398 to <4 x i32>
  %413 = shufflevector <4 x i32> %411, <4 x i32> %412, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %414 = bitcast <4 x i32> %413 to <2 x i64>
  %415 = shufflevector <4 x i32> %399, <4 x i32> %400, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %416 = bitcast <4 x i32> %415 to <2 x i64>
  %417 = shufflevector <4 x i32> %403, <4 x i32> %404, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %418 = bitcast <4 x i32> %417 to <2 x i64>
  %419 = shufflevector <4 x i32> %407, <4 x i32> %408, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %420 = bitcast <4 x i32> %419 to <2 x i64>
  %421 = shufflevector <4 x i32> %411, <4 x i32> %412, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %422 = bitcast <4 x i32> %421 to <2 x i64>
  %423 = shufflevector <2 x i64> %402, <2 x i64> %406, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %423, <2 x i64>* %33, align 16
  %424 = shufflevector <2 x i64> %402, <2 x i64> %406, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %424, <2 x i64>* %35, align 16
  %425 = shufflevector <2 x i64> %416, <2 x i64> %418, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %425, <2 x i64>* %37, align 16
  %426 = shufflevector <2 x i64> %416, <2 x i64> %418, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %426, <2 x i64>* %38, align 16
  %427 = shufflevector <2 x i64> %410, <2 x i64> %414, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %427, <2 x i64>* %39, align 16
  %428 = shufflevector <2 x i64> %410, <2 x i64> %414, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %428, <2 x i64>* %40, align 16
  %429 = shufflevector <2 x i64> %420, <2 x i64> %422, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %429, <2 x i64>* %41, align 16
  %430 = shufflevector <2 x i64> %420, <2 x i64> %422, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %430, <2 x i64>* %42, align 16
  %431 = getelementptr inbounds [4 x [32 x <2 x i64>]], [4 x [32 x <2 x i64>]]* %4, i64 0, i64 %46, i64 0
  call void @idct32_1024_8x32(<2 x i64>* nonnull %8, <2 x i64>* %431)
  %432 = getelementptr inbounds i32, i32* %47, i64 256
  %433 = add nuw nsw i64 %46, 1
  %434 = icmp eq i64 %433, 4
  br i1 %434, label %43, label %45

435:                                              ; preds = %43, %733
  %436 = phi i64 [ 0, %43 ], [ %735, %733 ]
  %437 = phi i8* [ %1, %43 ], [ %734, %733 ]
  %438 = getelementptr inbounds [4 x [32 x <2 x i64>]], [4 x [32 x <2 x i64>]]* %4, i64 0, i64 0, i64 %436
  %439 = bitcast <2 x i64>* %438 to <8 x i16>*
  %440 = load <8 x i16>, <8 x i16>* %439, align 16
  %441 = getelementptr inbounds <2 x i64>, <2 x i64>* %438, i64 1
  %442 = bitcast <2 x i64>* %441 to <8 x i16>*
  %443 = load <8 x i16>, <8 x i16>* %442, align 16
  %444 = shufflevector <8 x i16> %440, <8 x i16> %443, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %445 = getelementptr inbounds <2 x i64>, <2 x i64>* %438, i64 2
  %446 = bitcast <2 x i64>* %445 to <8 x i16>*
  %447 = load <8 x i16>, <8 x i16>* %446, align 16
  %448 = getelementptr inbounds <2 x i64>, <2 x i64>* %438, i64 3
  %449 = bitcast <2 x i64>* %448 to <8 x i16>*
  %450 = load <8 x i16>, <8 x i16>* %449, align 16
  %451 = shufflevector <8 x i16> %447, <8 x i16> %450, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %452 = getelementptr inbounds <2 x i64>, <2 x i64>* %438, i64 4
  %453 = bitcast <2 x i64>* %452 to <8 x i16>*
  %454 = load <8 x i16>, <8 x i16>* %453, align 16
  %455 = getelementptr inbounds <2 x i64>, <2 x i64>* %438, i64 5
  %456 = bitcast <2 x i64>* %455 to <8 x i16>*
  %457 = load <8 x i16>, <8 x i16>* %456, align 16
  %458 = shufflevector <8 x i16> %454, <8 x i16> %457, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %459 = getelementptr inbounds <2 x i64>, <2 x i64>* %438, i64 6
  %460 = bitcast <2 x i64>* %459 to <8 x i16>*
  %461 = load <8 x i16>, <8 x i16>* %460, align 16
  %462 = getelementptr inbounds <2 x i64>, <2 x i64>* %438, i64 7
  %463 = bitcast <2 x i64>* %462 to <8 x i16>*
  %464 = load <8 x i16>, <8 x i16>* %463, align 16
  %465 = shufflevector <8 x i16> %461, <8 x i16> %464, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %466 = shufflevector <8 x i16> %440, <8 x i16> %443, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %467 = shufflevector <8 x i16> %447, <8 x i16> %450, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %468 = shufflevector <8 x i16> %454, <8 x i16> %457, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %469 = shufflevector <8 x i16> %461, <8 x i16> %464, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %470 = bitcast <8 x i16> %444 to <4 x i32>
  %471 = bitcast <8 x i16> %451 to <4 x i32>
  %472 = shufflevector <4 x i32> %470, <4 x i32> %471, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %473 = bitcast <4 x i32> %472 to <2 x i64>
  %474 = bitcast <8 x i16> %458 to <4 x i32>
  %475 = bitcast <8 x i16> %465 to <4 x i32>
  %476 = shufflevector <4 x i32> %474, <4 x i32> %475, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %477 = bitcast <4 x i32> %476 to <2 x i64>
  %478 = bitcast <8 x i16> %466 to <4 x i32>
  %479 = bitcast <8 x i16> %467 to <4 x i32>
  %480 = shufflevector <4 x i32> %478, <4 x i32> %479, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %481 = bitcast <4 x i32> %480 to <2 x i64>
  %482 = bitcast <8 x i16> %468 to <4 x i32>
  %483 = bitcast <8 x i16> %469 to <4 x i32>
  %484 = shufflevector <4 x i32> %482, <4 x i32> %483, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %485 = bitcast <4 x i32> %484 to <2 x i64>
  %486 = shufflevector <4 x i32> %470, <4 x i32> %471, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %487 = bitcast <4 x i32> %486 to <2 x i64>
  %488 = shufflevector <4 x i32> %474, <4 x i32> %475, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %489 = bitcast <4 x i32> %488 to <2 x i64>
  %490 = shufflevector <4 x i32> %478, <4 x i32> %479, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %491 = bitcast <4 x i32> %490 to <2 x i64>
  %492 = shufflevector <4 x i32> %482, <4 x i32> %483, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %493 = bitcast <4 x i32> %492 to <2 x i64>
  %494 = shufflevector <2 x i64> %473, <2 x i64> %477, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %494, <2 x i64>* %8, align 16
  %495 = shufflevector <2 x i64> %473, <2 x i64> %477, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %495, <2 x i64>* %9, align 16
  %496 = shufflevector <2 x i64> %487, <2 x i64> %489, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %496, <2 x i64>* %10, align 16
  %497 = shufflevector <2 x i64> %487, <2 x i64> %489, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %497, <2 x i64>* %11, align 16
  %498 = shufflevector <2 x i64> %481, <2 x i64> %485, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %498, <2 x i64>* %12, align 16
  %499 = shufflevector <2 x i64> %481, <2 x i64> %485, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %499, <2 x i64>* %13, align 16
  %500 = shufflevector <2 x i64> %491, <2 x i64> %493, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %500, <2 x i64>* %14, align 16
  %501 = shufflevector <2 x i64> %491, <2 x i64> %493, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %501, <2 x i64>* %15, align 16
  %502 = getelementptr inbounds [4 x [32 x <2 x i64>]], [4 x [32 x <2 x i64>]]* %4, i64 0, i64 1, i64 %436
  %503 = bitcast <2 x i64>* %502 to <8 x i16>*
  %504 = load <8 x i16>, <8 x i16>* %503, align 16
  %505 = getelementptr inbounds <2 x i64>, <2 x i64>* %502, i64 1
  %506 = bitcast <2 x i64>* %505 to <8 x i16>*
  %507 = load <8 x i16>, <8 x i16>* %506, align 16
  %508 = shufflevector <8 x i16> %504, <8 x i16> %507, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %509 = getelementptr inbounds <2 x i64>, <2 x i64>* %502, i64 2
  %510 = bitcast <2 x i64>* %509 to <8 x i16>*
  %511 = load <8 x i16>, <8 x i16>* %510, align 16
  %512 = getelementptr inbounds <2 x i64>, <2 x i64>* %502, i64 3
  %513 = bitcast <2 x i64>* %512 to <8 x i16>*
  %514 = load <8 x i16>, <8 x i16>* %513, align 16
  %515 = shufflevector <8 x i16> %511, <8 x i16> %514, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %516 = getelementptr inbounds <2 x i64>, <2 x i64>* %502, i64 4
  %517 = bitcast <2 x i64>* %516 to <8 x i16>*
  %518 = load <8 x i16>, <8 x i16>* %517, align 16
  %519 = getelementptr inbounds <2 x i64>, <2 x i64>* %502, i64 5
  %520 = bitcast <2 x i64>* %519 to <8 x i16>*
  %521 = load <8 x i16>, <8 x i16>* %520, align 16
  %522 = shufflevector <8 x i16> %518, <8 x i16> %521, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %523 = getelementptr inbounds <2 x i64>, <2 x i64>* %502, i64 6
  %524 = bitcast <2 x i64>* %523 to <8 x i16>*
  %525 = load <8 x i16>, <8 x i16>* %524, align 16
  %526 = getelementptr inbounds <2 x i64>, <2 x i64>* %502, i64 7
  %527 = bitcast <2 x i64>* %526 to <8 x i16>*
  %528 = load <8 x i16>, <8 x i16>* %527, align 16
  %529 = shufflevector <8 x i16> %525, <8 x i16> %528, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %530 = shufflevector <8 x i16> %504, <8 x i16> %507, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %531 = shufflevector <8 x i16> %511, <8 x i16> %514, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %532 = shufflevector <8 x i16> %518, <8 x i16> %521, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %533 = shufflevector <8 x i16> %525, <8 x i16> %528, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %534 = bitcast <8 x i16> %508 to <4 x i32>
  %535 = bitcast <8 x i16> %515 to <4 x i32>
  %536 = shufflevector <4 x i32> %534, <4 x i32> %535, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %537 = bitcast <4 x i32> %536 to <2 x i64>
  %538 = bitcast <8 x i16> %522 to <4 x i32>
  %539 = bitcast <8 x i16> %529 to <4 x i32>
  %540 = shufflevector <4 x i32> %538, <4 x i32> %539, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %541 = bitcast <4 x i32> %540 to <2 x i64>
  %542 = bitcast <8 x i16> %530 to <4 x i32>
  %543 = bitcast <8 x i16> %531 to <4 x i32>
  %544 = shufflevector <4 x i32> %542, <4 x i32> %543, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %545 = bitcast <4 x i32> %544 to <2 x i64>
  %546 = bitcast <8 x i16> %532 to <4 x i32>
  %547 = bitcast <8 x i16> %533 to <4 x i32>
  %548 = shufflevector <4 x i32> %546, <4 x i32> %547, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %549 = bitcast <4 x i32> %548 to <2 x i64>
  %550 = shufflevector <4 x i32> %534, <4 x i32> %535, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %551 = bitcast <4 x i32> %550 to <2 x i64>
  %552 = shufflevector <4 x i32> %538, <4 x i32> %539, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %553 = bitcast <4 x i32> %552 to <2 x i64>
  %554 = shufflevector <4 x i32> %542, <4 x i32> %543, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %555 = bitcast <4 x i32> %554 to <2 x i64>
  %556 = shufflevector <4 x i32> %546, <4 x i32> %547, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %557 = bitcast <4 x i32> %556 to <2 x i64>
  %558 = shufflevector <2 x i64> %537, <2 x i64> %541, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %558, <2 x i64>* %16, align 16
  %559 = shufflevector <2 x i64> %537, <2 x i64> %541, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %559, <2 x i64>* %17, align 16
  %560 = shufflevector <2 x i64> %551, <2 x i64> %553, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %560, <2 x i64>* %18, align 16
  %561 = shufflevector <2 x i64> %551, <2 x i64> %553, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %561, <2 x i64>* %19, align 16
  %562 = shufflevector <2 x i64> %545, <2 x i64> %549, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %562, <2 x i64>* %20, align 16
  %563 = shufflevector <2 x i64> %545, <2 x i64> %549, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %563, <2 x i64>* %21, align 16
  %564 = shufflevector <2 x i64> %555, <2 x i64> %557, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %564, <2 x i64>* %22, align 16
  %565 = shufflevector <2 x i64> %555, <2 x i64> %557, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %565, <2 x i64>* %23, align 16
  %566 = getelementptr inbounds [4 x [32 x <2 x i64>]], [4 x [32 x <2 x i64>]]* %4, i64 0, i64 2, i64 %436
  %567 = bitcast <2 x i64>* %566 to <8 x i16>*
  %568 = load <8 x i16>, <8 x i16>* %567, align 16
  %569 = getelementptr inbounds <2 x i64>, <2 x i64>* %566, i64 1
  %570 = bitcast <2 x i64>* %569 to <8 x i16>*
  %571 = load <8 x i16>, <8 x i16>* %570, align 16
  %572 = shufflevector <8 x i16> %568, <8 x i16> %571, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %573 = getelementptr inbounds <2 x i64>, <2 x i64>* %566, i64 2
  %574 = bitcast <2 x i64>* %573 to <8 x i16>*
  %575 = load <8 x i16>, <8 x i16>* %574, align 16
  %576 = getelementptr inbounds <2 x i64>, <2 x i64>* %566, i64 3
  %577 = bitcast <2 x i64>* %576 to <8 x i16>*
  %578 = load <8 x i16>, <8 x i16>* %577, align 16
  %579 = shufflevector <8 x i16> %575, <8 x i16> %578, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %580 = getelementptr inbounds <2 x i64>, <2 x i64>* %566, i64 4
  %581 = bitcast <2 x i64>* %580 to <8 x i16>*
  %582 = load <8 x i16>, <8 x i16>* %581, align 16
  %583 = getelementptr inbounds <2 x i64>, <2 x i64>* %566, i64 5
  %584 = bitcast <2 x i64>* %583 to <8 x i16>*
  %585 = load <8 x i16>, <8 x i16>* %584, align 16
  %586 = shufflevector <8 x i16> %582, <8 x i16> %585, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %587 = getelementptr inbounds <2 x i64>, <2 x i64>* %566, i64 6
  %588 = bitcast <2 x i64>* %587 to <8 x i16>*
  %589 = load <8 x i16>, <8 x i16>* %588, align 16
  %590 = getelementptr inbounds <2 x i64>, <2 x i64>* %566, i64 7
  %591 = bitcast <2 x i64>* %590 to <8 x i16>*
  %592 = load <8 x i16>, <8 x i16>* %591, align 16
  %593 = shufflevector <8 x i16> %589, <8 x i16> %592, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %594 = shufflevector <8 x i16> %568, <8 x i16> %571, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %595 = shufflevector <8 x i16> %575, <8 x i16> %578, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %596 = shufflevector <8 x i16> %582, <8 x i16> %585, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %597 = shufflevector <8 x i16> %589, <8 x i16> %592, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %598 = bitcast <8 x i16> %572 to <4 x i32>
  %599 = bitcast <8 x i16> %579 to <4 x i32>
  %600 = shufflevector <4 x i32> %598, <4 x i32> %599, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %601 = bitcast <4 x i32> %600 to <2 x i64>
  %602 = bitcast <8 x i16> %586 to <4 x i32>
  %603 = bitcast <8 x i16> %593 to <4 x i32>
  %604 = shufflevector <4 x i32> %602, <4 x i32> %603, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %605 = bitcast <4 x i32> %604 to <2 x i64>
  %606 = bitcast <8 x i16> %594 to <4 x i32>
  %607 = bitcast <8 x i16> %595 to <4 x i32>
  %608 = shufflevector <4 x i32> %606, <4 x i32> %607, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %609 = bitcast <4 x i32> %608 to <2 x i64>
  %610 = bitcast <8 x i16> %596 to <4 x i32>
  %611 = bitcast <8 x i16> %597 to <4 x i32>
  %612 = shufflevector <4 x i32> %610, <4 x i32> %611, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %613 = bitcast <4 x i32> %612 to <2 x i64>
  %614 = shufflevector <4 x i32> %598, <4 x i32> %599, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %615 = bitcast <4 x i32> %614 to <2 x i64>
  %616 = shufflevector <4 x i32> %602, <4 x i32> %603, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %617 = bitcast <4 x i32> %616 to <2 x i64>
  %618 = shufflevector <4 x i32> %606, <4 x i32> %607, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %619 = bitcast <4 x i32> %618 to <2 x i64>
  %620 = shufflevector <4 x i32> %610, <4 x i32> %611, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %621 = bitcast <4 x i32> %620 to <2 x i64>
  %622 = shufflevector <2 x i64> %601, <2 x i64> %605, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %622, <2 x i64>* %24, align 16
  %623 = shufflevector <2 x i64> %601, <2 x i64> %605, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %623, <2 x i64>* %26, align 16
  %624 = shufflevector <2 x i64> %615, <2 x i64> %617, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %624, <2 x i64>* %27, align 16
  %625 = shufflevector <2 x i64> %615, <2 x i64> %617, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %625, <2 x i64>* %28, align 16
  %626 = shufflevector <2 x i64> %609, <2 x i64> %613, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %626, <2 x i64>* %29, align 16
  %627 = shufflevector <2 x i64> %609, <2 x i64> %613, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %627, <2 x i64>* %30, align 16
  %628 = shufflevector <2 x i64> %619, <2 x i64> %621, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %628, <2 x i64>* %31, align 16
  %629 = shufflevector <2 x i64> %619, <2 x i64> %621, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %629, <2 x i64>* %32, align 16
  %630 = getelementptr inbounds [4 x [32 x <2 x i64>]], [4 x [32 x <2 x i64>]]* %4, i64 0, i64 3, i64 %436
  %631 = bitcast <2 x i64>* %630 to <8 x i16>*
  %632 = load <8 x i16>, <8 x i16>* %631, align 16
  %633 = getelementptr inbounds <2 x i64>, <2 x i64>* %630, i64 1
  %634 = bitcast <2 x i64>* %633 to <8 x i16>*
  %635 = load <8 x i16>, <8 x i16>* %634, align 16
  %636 = shufflevector <8 x i16> %632, <8 x i16> %635, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %637 = getelementptr inbounds <2 x i64>, <2 x i64>* %630, i64 2
  %638 = bitcast <2 x i64>* %637 to <8 x i16>*
  %639 = load <8 x i16>, <8 x i16>* %638, align 16
  %640 = getelementptr inbounds <2 x i64>, <2 x i64>* %630, i64 3
  %641 = bitcast <2 x i64>* %640 to <8 x i16>*
  %642 = load <8 x i16>, <8 x i16>* %641, align 16
  %643 = shufflevector <8 x i16> %639, <8 x i16> %642, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %644 = getelementptr inbounds <2 x i64>, <2 x i64>* %630, i64 4
  %645 = bitcast <2 x i64>* %644 to <8 x i16>*
  %646 = load <8 x i16>, <8 x i16>* %645, align 16
  %647 = getelementptr inbounds <2 x i64>, <2 x i64>* %630, i64 5
  %648 = bitcast <2 x i64>* %647 to <8 x i16>*
  %649 = load <8 x i16>, <8 x i16>* %648, align 16
  %650 = shufflevector <8 x i16> %646, <8 x i16> %649, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %651 = getelementptr inbounds <2 x i64>, <2 x i64>* %630, i64 6
  %652 = bitcast <2 x i64>* %651 to <8 x i16>*
  %653 = load <8 x i16>, <8 x i16>* %652, align 16
  %654 = getelementptr inbounds <2 x i64>, <2 x i64>* %630, i64 7
  %655 = bitcast <2 x i64>* %654 to <8 x i16>*
  %656 = load <8 x i16>, <8 x i16>* %655, align 16
  %657 = shufflevector <8 x i16> %653, <8 x i16> %656, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %658 = shufflevector <8 x i16> %632, <8 x i16> %635, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %659 = shufflevector <8 x i16> %639, <8 x i16> %642, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %660 = shufflevector <8 x i16> %646, <8 x i16> %649, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %661 = shufflevector <8 x i16> %653, <8 x i16> %656, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %662 = bitcast <8 x i16> %636 to <4 x i32>
  %663 = bitcast <8 x i16> %643 to <4 x i32>
  %664 = shufflevector <4 x i32> %662, <4 x i32> %663, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %665 = bitcast <4 x i32> %664 to <2 x i64>
  %666 = bitcast <8 x i16> %650 to <4 x i32>
  %667 = bitcast <8 x i16> %657 to <4 x i32>
  %668 = shufflevector <4 x i32> %666, <4 x i32> %667, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %669 = bitcast <4 x i32> %668 to <2 x i64>
  %670 = bitcast <8 x i16> %658 to <4 x i32>
  %671 = bitcast <8 x i16> %659 to <4 x i32>
  %672 = shufflevector <4 x i32> %670, <4 x i32> %671, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %673 = bitcast <4 x i32> %672 to <2 x i64>
  %674 = bitcast <8 x i16> %660 to <4 x i32>
  %675 = bitcast <8 x i16> %661 to <4 x i32>
  %676 = shufflevector <4 x i32> %674, <4 x i32> %675, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %677 = bitcast <4 x i32> %676 to <2 x i64>
  %678 = shufflevector <4 x i32> %662, <4 x i32> %663, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %679 = bitcast <4 x i32> %678 to <2 x i64>
  %680 = shufflevector <4 x i32> %666, <4 x i32> %667, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %681 = bitcast <4 x i32> %680 to <2 x i64>
  %682 = shufflevector <4 x i32> %670, <4 x i32> %671, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %683 = bitcast <4 x i32> %682 to <2 x i64>
  %684 = shufflevector <4 x i32> %674, <4 x i32> %675, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %685 = bitcast <4 x i32> %684 to <2 x i64>
  %686 = shufflevector <2 x i64> %665, <2 x i64> %669, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %686, <2 x i64>* %33, align 16
  %687 = shufflevector <2 x i64> %665, <2 x i64> %669, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %687, <2 x i64>* %35, align 16
  %688 = shufflevector <2 x i64> %679, <2 x i64> %681, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %688, <2 x i64>* %37, align 16
  %689 = shufflevector <2 x i64> %679, <2 x i64> %681, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %689, <2 x i64>* %38, align 16
  %690 = shufflevector <2 x i64> %673, <2 x i64> %677, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %690, <2 x i64>* %39, align 16
  %691 = shufflevector <2 x i64> %673, <2 x i64> %677, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %691, <2 x i64>* %40, align 16
  %692 = shufflevector <2 x i64> %683, <2 x i64> %685, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %692, <2 x i64>* %41, align 16
  %693 = shufflevector <2 x i64> %683, <2 x i64> %685, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %693, <2 x i64>* %42, align 16
  call void @idct32_1024_8x32(<2 x i64>* nonnull %8, <2 x i64>* nonnull %8)
  br label %694

694:                                              ; preds = %694, %435
  %695 = phi i64 [ 0, %435 ], [ %731, %694 ]
  %696 = phi i8* [ %437, %435 ], [ %730, %694 ]
  %697 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 %695
  %698 = bitcast <2 x i64>* %697 to <8 x i16>*
  %699 = load <8 x i16>, <8 x i16>* %698, align 16
  %700 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %699, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #6
  %701 = or i64 %695, 1
  %702 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 %701
  %703 = bitcast <2 x i64>* %702 to <8 x i16>*
  %704 = load <8 x i16>, <8 x i16>* %703, align 16
  %705 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %704, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #6
  %706 = ashr <8 x i16> %700, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %706, <8 x i16>* %698, align 16
  %707 = ashr <8 x i16> %705, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %707, <8 x i16>* %703, align 16
  %708 = bitcast i8* %696 to i64*
  %709 = load i64, i64* %708, align 1
  %710 = insertelement <2 x i64> undef, i64 %709, i32 0
  %711 = bitcast <2 x i64> %710 to <16 x i8>
  %712 = shufflevector <16 x i8> %711, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %713 = bitcast <16 x i8> %712 to <8 x i16>
  %714 = add <8 x i16> %706, %713
  %715 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %714, <8 x i16> undef) #6
  %716 = bitcast <16 x i8> %715 to <2 x i64>
  %717 = extractelement <2 x i64> %716, i32 0
  store i64 %717, i64* %708, align 1
  %718 = getelementptr inbounds i8, i8* %696, i64 %44
  %719 = load <8 x i16>, <8 x i16>* %703, align 16
  %720 = bitcast i8* %718 to i64*
  %721 = load i64, i64* %720, align 1
  %722 = insertelement <2 x i64> undef, i64 %721, i32 0
  %723 = bitcast <2 x i64> %722 to <16 x i8>
  %724 = shufflevector <16 x i8> %723, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %725 = bitcast <16 x i8> %724 to <8 x i16>
  %726 = add <8 x i16> %719, %725
  %727 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %726, <8 x i16> undef) #6
  %728 = bitcast <16 x i8> %727 to <2 x i64>
  %729 = extractelement <2 x i64> %728, i32 0
  store i64 %729, i64* %720, align 1
  %730 = getelementptr inbounds i8, i8* %718, i64 %44
  %731 = add nuw nsw i64 %695, 2
  %732 = icmp ult i64 %731, 32
  br i1 %732, label %694, label %733

733:                                              ; preds = %694
  %734 = getelementptr inbounds i8, i8* %437, i64 8
  %735 = add nuw nsw i64 %436, 8
  %736 = icmp ult i64 %735, 32
  br i1 %736, label %435, label %737

737:                                              ; preds = %733
  call void @llvm.lifetime.end.p0i8(i64 512, i8* nonnull %7) #6
  call void @llvm.lifetime.end.p0i8(i64 2048, i8* nonnull %6) #6
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @vpx_idct32x32_135_add_sse2(i32* nocapture readonly, i8* nocapture, i32) local_unnamed_addr #0 {
  %4 = alloca [2 x [32 x <2 x i64>]], align 16
  %5 = alloca [32 x <2 x i64>], align 16
  %6 = alloca [32 x <2 x i64>], align 16
  %7 = bitcast [2 x [32 x <2 x i64>]]* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1024, i8* nonnull %7) #6
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %7, i8 -86, i64 1024, i1 false)
  %8 = bitcast [32 x <2 x i64>]* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 512, i8* nonnull %8) #6
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %8, i8 -86, i64 256, i1 false)
  %9 = bitcast [32 x <2 x i64>]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 512, i8* nonnull %9) #6
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 512, i1 false)
  %10 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 16
  %11 = bitcast <2 x i64>* %10 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 16 %11, i8 0, i64 256, i1 false)
  %12 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 0
  %13 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 1
  %14 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 2
  %15 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 3
  %16 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 4
  %17 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 5
  %18 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 6
  %19 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 7
  %20 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 8
  %21 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 9
  %22 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 10
  %23 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 11
  %24 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 12
  %25 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 13
  %26 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 14
  %27 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 15
  br label %31

28:                                               ; preds = %31
  %29 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 0
  %30 = sext i32 %2 to i64
  br label %229

31:                                               ; preds = %31, %3
  %32 = phi i64 [ 0, %3 ], [ %227, %31 ]
  %33 = phi i32* [ %0, %3 ], [ %226, %31 ]
  %34 = bitcast i32* %33 to <4 x i32>*
  %35 = load <4 x i32>, <4 x i32>* %34, align 16
  %36 = getelementptr inbounds i32, i32* %33, i64 4
  %37 = bitcast i32* %36 to <4 x i32>*
  %38 = load <4 x i32>, <4 x i32>* %37, align 16
  %39 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %35, <4 x i32> %38) #6
  %40 = getelementptr inbounds i32, i32* %33, i64 32
  %41 = bitcast i32* %40 to <4 x i32>*
  %42 = load <4 x i32>, <4 x i32>* %41, align 16
  %43 = getelementptr inbounds i32, i32* %33, i64 36
  %44 = bitcast i32* %43 to <4 x i32>*
  %45 = load <4 x i32>, <4 x i32>* %44, align 16
  %46 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %42, <4 x i32> %45) #6
  %47 = getelementptr inbounds i32, i32* %33, i64 64
  %48 = bitcast i32* %47 to <4 x i32>*
  %49 = load <4 x i32>, <4 x i32>* %48, align 16
  %50 = getelementptr inbounds i32, i32* %33, i64 68
  %51 = bitcast i32* %50 to <4 x i32>*
  %52 = load <4 x i32>, <4 x i32>* %51, align 16
  %53 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %49, <4 x i32> %52) #6
  %54 = getelementptr inbounds i32, i32* %33, i64 96
  %55 = bitcast i32* %54 to <4 x i32>*
  %56 = load <4 x i32>, <4 x i32>* %55, align 16
  %57 = getelementptr inbounds i32, i32* %33, i64 100
  %58 = bitcast i32* %57 to <4 x i32>*
  %59 = load <4 x i32>, <4 x i32>* %58, align 16
  %60 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %56, <4 x i32> %59) #6
  %61 = getelementptr inbounds i32, i32* %33, i64 128
  %62 = bitcast i32* %61 to <4 x i32>*
  %63 = load <4 x i32>, <4 x i32>* %62, align 16
  %64 = getelementptr inbounds i32, i32* %33, i64 132
  %65 = bitcast i32* %64 to <4 x i32>*
  %66 = load <4 x i32>, <4 x i32>* %65, align 16
  %67 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %63, <4 x i32> %66) #6
  %68 = getelementptr inbounds i32, i32* %33, i64 160
  %69 = bitcast i32* %68 to <4 x i32>*
  %70 = load <4 x i32>, <4 x i32>* %69, align 16
  %71 = getelementptr inbounds i32, i32* %33, i64 164
  %72 = bitcast i32* %71 to <4 x i32>*
  %73 = load <4 x i32>, <4 x i32>* %72, align 16
  %74 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %70, <4 x i32> %73) #6
  %75 = getelementptr inbounds i32, i32* %33, i64 192
  %76 = bitcast i32* %75 to <4 x i32>*
  %77 = load <4 x i32>, <4 x i32>* %76, align 16
  %78 = getelementptr inbounds i32, i32* %33, i64 196
  %79 = bitcast i32* %78 to <4 x i32>*
  %80 = load <4 x i32>, <4 x i32>* %79, align 16
  %81 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %77, <4 x i32> %80) #6
  %82 = getelementptr inbounds i32, i32* %33, i64 224
  %83 = bitcast i32* %82 to <4 x i32>*
  %84 = load <4 x i32>, <4 x i32>* %83, align 16
  %85 = getelementptr inbounds i32, i32* %33, i64 228
  %86 = bitcast i32* %85 to <4 x i32>*
  %87 = load <4 x i32>, <4 x i32>* %86, align 16
  %88 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %84, <4 x i32> %87) #6
  %89 = shufflevector <8 x i16> %39, <8 x i16> %46, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %90 = shufflevector <8 x i16> %53, <8 x i16> %60, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %91 = shufflevector <8 x i16> %67, <8 x i16> %74, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %92 = shufflevector <8 x i16> %81, <8 x i16> %88, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %93 = shufflevector <8 x i16> %39, <8 x i16> %46, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %94 = shufflevector <8 x i16> %53, <8 x i16> %60, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %95 = shufflevector <8 x i16> %67, <8 x i16> %74, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %96 = shufflevector <8 x i16> %81, <8 x i16> %88, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %97 = bitcast <8 x i16> %89 to <4 x i32>
  %98 = bitcast <8 x i16> %90 to <4 x i32>
  %99 = shufflevector <4 x i32> %97, <4 x i32> %98, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %100 = bitcast <4 x i32> %99 to <2 x i64>
  %101 = bitcast <8 x i16> %91 to <4 x i32>
  %102 = bitcast <8 x i16> %92 to <4 x i32>
  %103 = shufflevector <4 x i32> %101, <4 x i32> %102, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %104 = bitcast <4 x i32> %103 to <2 x i64>
  %105 = bitcast <8 x i16> %93 to <4 x i32>
  %106 = bitcast <8 x i16> %94 to <4 x i32>
  %107 = shufflevector <4 x i32> %105, <4 x i32> %106, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %108 = bitcast <4 x i32> %107 to <2 x i64>
  %109 = bitcast <8 x i16> %95 to <4 x i32>
  %110 = bitcast <8 x i16> %96 to <4 x i32>
  %111 = shufflevector <4 x i32> %109, <4 x i32> %110, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %112 = bitcast <4 x i32> %111 to <2 x i64>
  %113 = shufflevector <4 x i32> %97, <4 x i32> %98, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %114 = bitcast <4 x i32> %113 to <2 x i64>
  %115 = shufflevector <4 x i32> %101, <4 x i32> %102, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %116 = bitcast <4 x i32> %115 to <2 x i64>
  %117 = shufflevector <4 x i32> %105, <4 x i32> %106, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %118 = bitcast <4 x i32> %117 to <2 x i64>
  %119 = shufflevector <4 x i32> %109, <4 x i32> %110, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %120 = bitcast <4 x i32> %119 to <2 x i64>
  %121 = shufflevector <2 x i64> %100, <2 x i64> %104, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %121, <2 x i64>* %12, align 16
  %122 = shufflevector <2 x i64> %100, <2 x i64> %104, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %122, <2 x i64>* %13, align 16
  %123 = shufflevector <2 x i64> %114, <2 x i64> %116, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %123, <2 x i64>* %14, align 16
  %124 = shufflevector <2 x i64> %114, <2 x i64> %116, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %124, <2 x i64>* %15, align 16
  %125 = shufflevector <2 x i64> %108, <2 x i64> %112, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %125, <2 x i64>* %16, align 16
  %126 = shufflevector <2 x i64> %108, <2 x i64> %112, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %126, <2 x i64>* %17, align 16
  %127 = shufflevector <2 x i64> %118, <2 x i64> %120, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %127, <2 x i64>* %18, align 16
  %128 = shufflevector <2 x i64> %118, <2 x i64> %120, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %128, <2 x i64>* %19, align 16
  %129 = getelementptr inbounds i32, i32* %33, i64 8
  %130 = bitcast i32* %129 to <4 x i32>*
  %131 = load <4 x i32>, <4 x i32>* %130, align 16
  %132 = getelementptr inbounds i32, i32* %33, i64 12
  %133 = bitcast i32* %132 to <4 x i32>*
  %134 = load <4 x i32>, <4 x i32>* %133, align 16
  %135 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %131, <4 x i32> %134) #6
  %136 = getelementptr inbounds i32, i32* %33, i64 40
  %137 = bitcast i32* %136 to <4 x i32>*
  %138 = load <4 x i32>, <4 x i32>* %137, align 16
  %139 = getelementptr inbounds i32, i32* %33, i64 44
  %140 = bitcast i32* %139 to <4 x i32>*
  %141 = load <4 x i32>, <4 x i32>* %140, align 16
  %142 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %138, <4 x i32> %141) #6
  %143 = getelementptr inbounds i32, i32* %33, i64 72
  %144 = bitcast i32* %143 to <4 x i32>*
  %145 = load <4 x i32>, <4 x i32>* %144, align 16
  %146 = getelementptr inbounds i32, i32* %33, i64 76
  %147 = bitcast i32* %146 to <4 x i32>*
  %148 = load <4 x i32>, <4 x i32>* %147, align 16
  %149 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %145, <4 x i32> %148) #6
  %150 = getelementptr inbounds i32, i32* %33, i64 104
  %151 = bitcast i32* %150 to <4 x i32>*
  %152 = load <4 x i32>, <4 x i32>* %151, align 16
  %153 = getelementptr inbounds i32, i32* %33, i64 108
  %154 = bitcast i32* %153 to <4 x i32>*
  %155 = load <4 x i32>, <4 x i32>* %154, align 16
  %156 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %152, <4 x i32> %155) #6
  %157 = getelementptr inbounds i32, i32* %33, i64 136
  %158 = bitcast i32* %157 to <4 x i32>*
  %159 = load <4 x i32>, <4 x i32>* %158, align 16
  %160 = getelementptr inbounds i32, i32* %33, i64 140
  %161 = bitcast i32* %160 to <4 x i32>*
  %162 = load <4 x i32>, <4 x i32>* %161, align 16
  %163 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %159, <4 x i32> %162) #6
  %164 = getelementptr inbounds i32, i32* %33, i64 168
  %165 = bitcast i32* %164 to <4 x i32>*
  %166 = load <4 x i32>, <4 x i32>* %165, align 16
  %167 = getelementptr inbounds i32, i32* %33, i64 172
  %168 = bitcast i32* %167 to <4 x i32>*
  %169 = load <4 x i32>, <4 x i32>* %168, align 16
  %170 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %166, <4 x i32> %169) #6
  %171 = getelementptr inbounds i32, i32* %33, i64 200
  %172 = bitcast i32* %171 to <4 x i32>*
  %173 = load <4 x i32>, <4 x i32>* %172, align 16
  %174 = getelementptr inbounds i32, i32* %33, i64 204
  %175 = bitcast i32* %174 to <4 x i32>*
  %176 = load <4 x i32>, <4 x i32>* %175, align 16
  %177 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %173, <4 x i32> %176) #6
  %178 = getelementptr inbounds i32, i32* %33, i64 232
  %179 = bitcast i32* %178 to <4 x i32>*
  %180 = load <4 x i32>, <4 x i32>* %179, align 16
  %181 = getelementptr inbounds i32, i32* %33, i64 236
  %182 = bitcast i32* %181 to <4 x i32>*
  %183 = load <4 x i32>, <4 x i32>* %182, align 16
  %184 = call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %180, <4 x i32> %183) #6
  %185 = shufflevector <8 x i16> %135, <8 x i16> %142, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %186 = shufflevector <8 x i16> %149, <8 x i16> %156, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %187 = shufflevector <8 x i16> %163, <8 x i16> %170, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %188 = shufflevector <8 x i16> %177, <8 x i16> %184, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %189 = shufflevector <8 x i16> %135, <8 x i16> %142, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %190 = shufflevector <8 x i16> %149, <8 x i16> %156, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %191 = shufflevector <8 x i16> %163, <8 x i16> %170, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %192 = shufflevector <8 x i16> %177, <8 x i16> %184, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %193 = bitcast <8 x i16> %185 to <4 x i32>
  %194 = bitcast <8 x i16> %186 to <4 x i32>
  %195 = shufflevector <4 x i32> %193, <4 x i32> %194, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %196 = bitcast <4 x i32> %195 to <2 x i64>
  %197 = bitcast <8 x i16> %187 to <4 x i32>
  %198 = bitcast <8 x i16> %188 to <4 x i32>
  %199 = shufflevector <4 x i32> %197, <4 x i32> %198, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %200 = bitcast <4 x i32> %199 to <2 x i64>
  %201 = bitcast <8 x i16> %189 to <4 x i32>
  %202 = bitcast <8 x i16> %190 to <4 x i32>
  %203 = shufflevector <4 x i32> %201, <4 x i32> %202, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %204 = bitcast <4 x i32> %203 to <2 x i64>
  %205 = bitcast <8 x i16> %191 to <4 x i32>
  %206 = bitcast <8 x i16> %192 to <4 x i32>
  %207 = shufflevector <4 x i32> %205, <4 x i32> %206, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %208 = bitcast <4 x i32> %207 to <2 x i64>
  %209 = shufflevector <4 x i32> %193, <4 x i32> %194, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %210 = bitcast <4 x i32> %209 to <2 x i64>
  %211 = shufflevector <4 x i32> %197, <4 x i32> %198, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %212 = bitcast <4 x i32> %211 to <2 x i64>
  %213 = shufflevector <4 x i32> %201, <4 x i32> %202, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %214 = bitcast <4 x i32> %213 to <2 x i64>
  %215 = shufflevector <4 x i32> %205, <4 x i32> %206, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %216 = bitcast <4 x i32> %215 to <2 x i64>
  %217 = shufflevector <2 x i64> %196, <2 x i64> %200, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %217, <2 x i64>* %20, align 16
  %218 = shufflevector <2 x i64> %196, <2 x i64> %200, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %218, <2 x i64>* %21, align 16
  %219 = shufflevector <2 x i64> %210, <2 x i64> %212, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %219, <2 x i64>* %22, align 16
  %220 = shufflevector <2 x i64> %210, <2 x i64> %212, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %220, <2 x i64>* %23, align 16
  %221 = shufflevector <2 x i64> %204, <2 x i64> %208, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %221, <2 x i64>* %24, align 16
  %222 = shufflevector <2 x i64> %204, <2 x i64> %208, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %222, <2 x i64>* %25, align 16
  %223 = shufflevector <2 x i64> %214, <2 x i64> %216, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %223, <2 x i64>* %26, align 16
  %224 = shufflevector <2 x i64> %214, <2 x i64> %216, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %224, <2 x i64>* %27, align 16
  %225 = getelementptr inbounds [2 x [32 x <2 x i64>]], [2 x [32 x <2 x i64>]]* %4, i64 0, i64 %32, i64 0
  call void @idct32_1024_8x32(<2 x i64>* nonnull %12, <2 x i64>* %225)
  %226 = getelementptr inbounds i32, i32* %33, i64 256
  %227 = add nuw nsw i64 %32, 1
  %228 = icmp eq i64 %227, 2
  br i1 %228, label %28, label %31

229:                                              ; preds = %28, %399
  %230 = phi i64 [ 0, %28 ], [ %401, %399 ]
  %231 = phi i8* [ %1, %28 ], [ %400, %399 ]
  %232 = getelementptr inbounds [2 x [32 x <2 x i64>]], [2 x [32 x <2 x i64>]]* %4, i64 0, i64 0, i64 %230
  %233 = bitcast <2 x i64>* %232 to <8 x i16>*
  %234 = load <8 x i16>, <8 x i16>* %233, align 16
  %235 = getelementptr inbounds <2 x i64>, <2 x i64>* %232, i64 1
  %236 = bitcast <2 x i64>* %235 to <8 x i16>*
  %237 = load <8 x i16>, <8 x i16>* %236, align 16
  %238 = shufflevector <8 x i16> %234, <8 x i16> %237, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %239 = getelementptr inbounds <2 x i64>, <2 x i64>* %232, i64 2
  %240 = bitcast <2 x i64>* %239 to <8 x i16>*
  %241 = load <8 x i16>, <8 x i16>* %240, align 16
  %242 = getelementptr inbounds <2 x i64>, <2 x i64>* %232, i64 3
  %243 = bitcast <2 x i64>* %242 to <8 x i16>*
  %244 = load <8 x i16>, <8 x i16>* %243, align 16
  %245 = shufflevector <8 x i16> %241, <8 x i16> %244, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %246 = getelementptr inbounds <2 x i64>, <2 x i64>* %232, i64 4
  %247 = bitcast <2 x i64>* %246 to <8 x i16>*
  %248 = load <8 x i16>, <8 x i16>* %247, align 16
  %249 = getelementptr inbounds <2 x i64>, <2 x i64>* %232, i64 5
  %250 = bitcast <2 x i64>* %249 to <8 x i16>*
  %251 = load <8 x i16>, <8 x i16>* %250, align 16
  %252 = shufflevector <8 x i16> %248, <8 x i16> %251, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %253 = getelementptr inbounds <2 x i64>, <2 x i64>* %232, i64 6
  %254 = bitcast <2 x i64>* %253 to <8 x i16>*
  %255 = load <8 x i16>, <8 x i16>* %254, align 16
  %256 = getelementptr inbounds <2 x i64>, <2 x i64>* %232, i64 7
  %257 = bitcast <2 x i64>* %256 to <8 x i16>*
  %258 = load <8 x i16>, <8 x i16>* %257, align 16
  %259 = shufflevector <8 x i16> %255, <8 x i16> %258, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %260 = shufflevector <8 x i16> %234, <8 x i16> %237, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %261 = shufflevector <8 x i16> %241, <8 x i16> %244, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %262 = shufflevector <8 x i16> %248, <8 x i16> %251, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %263 = shufflevector <8 x i16> %255, <8 x i16> %258, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %264 = bitcast <8 x i16> %238 to <4 x i32>
  %265 = bitcast <8 x i16> %245 to <4 x i32>
  %266 = shufflevector <4 x i32> %264, <4 x i32> %265, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %267 = bitcast <4 x i32> %266 to <2 x i64>
  %268 = bitcast <8 x i16> %252 to <4 x i32>
  %269 = bitcast <8 x i16> %259 to <4 x i32>
  %270 = shufflevector <4 x i32> %268, <4 x i32> %269, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %271 = bitcast <4 x i32> %270 to <2 x i64>
  %272 = bitcast <8 x i16> %260 to <4 x i32>
  %273 = bitcast <8 x i16> %261 to <4 x i32>
  %274 = shufflevector <4 x i32> %272, <4 x i32> %273, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %275 = bitcast <4 x i32> %274 to <2 x i64>
  %276 = bitcast <8 x i16> %262 to <4 x i32>
  %277 = bitcast <8 x i16> %263 to <4 x i32>
  %278 = shufflevector <4 x i32> %276, <4 x i32> %277, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %279 = bitcast <4 x i32> %278 to <2 x i64>
  %280 = shufflevector <4 x i32> %264, <4 x i32> %265, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %281 = bitcast <4 x i32> %280 to <2 x i64>
  %282 = shufflevector <4 x i32> %268, <4 x i32> %269, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %283 = bitcast <4 x i32> %282 to <2 x i64>
  %284 = shufflevector <4 x i32> %272, <4 x i32> %273, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %285 = bitcast <4 x i32> %284 to <2 x i64>
  %286 = shufflevector <4 x i32> %276, <4 x i32> %277, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %287 = bitcast <4 x i32> %286 to <2 x i64>
  %288 = shufflevector <2 x i64> %267, <2 x i64> %271, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %288, <2 x i64>* %12, align 16
  %289 = shufflevector <2 x i64> %267, <2 x i64> %271, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %289, <2 x i64>* %13, align 16
  %290 = shufflevector <2 x i64> %281, <2 x i64> %283, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %290, <2 x i64>* %14, align 16
  %291 = shufflevector <2 x i64> %281, <2 x i64> %283, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %291, <2 x i64>* %15, align 16
  %292 = shufflevector <2 x i64> %275, <2 x i64> %279, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %292, <2 x i64>* %16, align 16
  %293 = shufflevector <2 x i64> %275, <2 x i64> %279, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %293, <2 x i64>* %17, align 16
  %294 = shufflevector <2 x i64> %285, <2 x i64> %287, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %294, <2 x i64>* %18, align 16
  %295 = shufflevector <2 x i64> %285, <2 x i64> %287, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %295, <2 x i64>* %19, align 16
  %296 = getelementptr inbounds [2 x [32 x <2 x i64>]], [2 x [32 x <2 x i64>]]* %4, i64 0, i64 1, i64 %230
  %297 = bitcast <2 x i64>* %296 to <8 x i16>*
  %298 = load <8 x i16>, <8 x i16>* %297, align 16
  %299 = getelementptr inbounds <2 x i64>, <2 x i64>* %296, i64 1
  %300 = bitcast <2 x i64>* %299 to <8 x i16>*
  %301 = load <8 x i16>, <8 x i16>* %300, align 16
  %302 = shufflevector <8 x i16> %298, <8 x i16> %301, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %303 = getelementptr inbounds <2 x i64>, <2 x i64>* %296, i64 2
  %304 = bitcast <2 x i64>* %303 to <8 x i16>*
  %305 = load <8 x i16>, <8 x i16>* %304, align 16
  %306 = getelementptr inbounds <2 x i64>, <2 x i64>* %296, i64 3
  %307 = bitcast <2 x i64>* %306 to <8 x i16>*
  %308 = load <8 x i16>, <8 x i16>* %307, align 16
  %309 = shufflevector <8 x i16> %305, <8 x i16> %308, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %310 = getelementptr inbounds <2 x i64>, <2 x i64>* %296, i64 4
  %311 = bitcast <2 x i64>* %310 to <8 x i16>*
  %312 = load <8 x i16>, <8 x i16>* %311, align 16
  %313 = getelementptr inbounds <2 x i64>, <2 x i64>* %296, i64 5
  %314 = bitcast <2 x i64>* %313 to <8 x i16>*
  %315 = load <8 x i16>, <8 x i16>* %314, align 16
  %316 = shufflevector <8 x i16> %312, <8 x i16> %315, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %317 = getelementptr inbounds <2 x i64>, <2 x i64>* %296, i64 6
  %318 = bitcast <2 x i64>* %317 to <8 x i16>*
  %319 = load <8 x i16>, <8 x i16>* %318, align 16
  %320 = getelementptr inbounds <2 x i64>, <2 x i64>* %296, i64 7
  %321 = bitcast <2 x i64>* %320 to <8 x i16>*
  %322 = load <8 x i16>, <8 x i16>* %321, align 16
  %323 = shufflevector <8 x i16> %319, <8 x i16> %322, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %324 = shufflevector <8 x i16> %298, <8 x i16> %301, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %325 = shufflevector <8 x i16> %305, <8 x i16> %308, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %326 = shufflevector <8 x i16> %312, <8 x i16> %315, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %327 = shufflevector <8 x i16> %319, <8 x i16> %322, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %328 = bitcast <8 x i16> %302 to <4 x i32>
  %329 = bitcast <8 x i16> %309 to <4 x i32>
  %330 = shufflevector <4 x i32> %328, <4 x i32> %329, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %331 = bitcast <4 x i32> %330 to <2 x i64>
  %332 = bitcast <8 x i16> %316 to <4 x i32>
  %333 = bitcast <8 x i16> %323 to <4 x i32>
  %334 = shufflevector <4 x i32> %332, <4 x i32> %333, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %335 = bitcast <4 x i32> %334 to <2 x i64>
  %336 = bitcast <8 x i16> %324 to <4 x i32>
  %337 = bitcast <8 x i16> %325 to <4 x i32>
  %338 = shufflevector <4 x i32> %336, <4 x i32> %337, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %339 = bitcast <4 x i32> %338 to <2 x i64>
  %340 = bitcast <8 x i16> %326 to <4 x i32>
  %341 = bitcast <8 x i16> %327 to <4 x i32>
  %342 = shufflevector <4 x i32> %340, <4 x i32> %341, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %343 = bitcast <4 x i32> %342 to <2 x i64>
  %344 = shufflevector <4 x i32> %328, <4 x i32> %329, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %345 = bitcast <4 x i32> %344 to <2 x i64>
  %346 = shufflevector <4 x i32> %332, <4 x i32> %333, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %347 = bitcast <4 x i32> %346 to <2 x i64>
  %348 = shufflevector <4 x i32> %336, <4 x i32> %337, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %349 = bitcast <4 x i32> %348 to <2 x i64>
  %350 = shufflevector <4 x i32> %340, <4 x i32> %341, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %351 = bitcast <4 x i32> %350 to <2 x i64>
  %352 = shufflevector <2 x i64> %331, <2 x i64> %335, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %352, <2 x i64>* %20, align 16
  %353 = shufflevector <2 x i64> %331, <2 x i64> %335, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %353, <2 x i64>* %21, align 16
  %354 = shufflevector <2 x i64> %345, <2 x i64> %347, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %354, <2 x i64>* %22, align 16
  %355 = shufflevector <2 x i64> %345, <2 x i64> %347, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %355, <2 x i64>* %23, align 16
  %356 = shufflevector <2 x i64> %339, <2 x i64> %343, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %356, <2 x i64>* %24, align 16
  %357 = shufflevector <2 x i64> %339, <2 x i64> %343, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %357, <2 x i64>* %25, align 16
  %358 = shufflevector <2 x i64> %349, <2 x i64> %351, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %358, <2 x i64>* %26, align 16
  %359 = shufflevector <2 x i64> %349, <2 x i64> %351, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %359, <2 x i64>* %27, align 16
  call void @idct32_1024_8x32(<2 x i64>* nonnull %12, <2 x i64>* nonnull %29)
  br label %360

360:                                              ; preds = %360, %229
  %361 = phi i64 [ 0, %229 ], [ %397, %360 ]
  %362 = phi i8* [ %231, %229 ], [ %396, %360 ]
  %363 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %361
  %364 = bitcast <2 x i64>* %363 to <8 x i16>*
  %365 = load <8 x i16>, <8 x i16>* %364, align 16
  %366 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %365, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #6
  %367 = or i64 %361, 1
  %368 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %367
  %369 = bitcast <2 x i64>* %368 to <8 x i16>*
  %370 = load <8 x i16>, <8 x i16>* %369, align 16
  %371 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %370, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #6
  %372 = ashr <8 x i16> %366, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %372, <8 x i16>* %364, align 16
  %373 = ashr <8 x i16> %371, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %373, <8 x i16>* %369, align 16
  %374 = bitcast i8* %362 to i64*
  %375 = load i64, i64* %374, align 1
  %376 = insertelement <2 x i64> undef, i64 %375, i32 0
  %377 = bitcast <2 x i64> %376 to <16 x i8>
  %378 = shufflevector <16 x i8> %377, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %379 = bitcast <16 x i8> %378 to <8 x i16>
  %380 = add <8 x i16> %372, %379
  %381 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %380, <8 x i16> undef) #6
  %382 = bitcast <16 x i8> %381 to <2 x i64>
  %383 = extractelement <2 x i64> %382, i32 0
  store i64 %383, i64* %374, align 1
  %384 = getelementptr inbounds i8, i8* %362, i64 %30
  %385 = load <8 x i16>, <8 x i16>* %369, align 16
  %386 = bitcast i8* %384 to i64*
  %387 = load i64, i64* %386, align 1
  %388 = insertelement <2 x i64> undef, i64 %387, i32 0
  %389 = bitcast <2 x i64> %388 to <16 x i8>
  %390 = shufflevector <16 x i8> %389, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %391 = bitcast <16 x i8> %390 to <8 x i16>
  %392 = add <8 x i16> %385, %391
  %393 = call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %392, <8 x i16> undef) #6
  %394 = bitcast <16 x i8> %393 to <2 x i64>
  %395 = extractelement <2 x i64> %394, i32 0
  store i64 %395, i64* %386, align 1
  %396 = getelementptr inbounds i8, i8* %384, i64 %30
  %397 = add nuw nsw i64 %361, 2
  %398 = icmp ult i64 %397, 32
  br i1 %398, label %360, label %399

399:                                              ; preds = %360
  %400 = getelementptr inbounds i8, i8* %231, i64 8
  %401 = add nuw nsw i64 %230, 8
  %402 = icmp ult i64 %401, 32
  br i1 %402, label %229, label %403

403:                                              ; preds = %399
  call void @llvm.lifetime.end.p0i8(i64 512, i8* nonnull %9) #6
  call void @llvm.lifetime.end.p0i8(i64 512, i8* nonnull %8) #6
  call void @llvm.lifetime.end.p0i8(i64 1024, i8* nonnull %7) #6
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @vpx_idct32x32_1_add_sse2(i32* nocapture readonly, i8* nocapture, i32) local_unnamed_addr #2 {
  %4 = load i32, i32* %0, align 4
  %5 = shl i32 %4, 16
  %6 = ashr exact i32 %5, 16
  %7 = mul nsw i32 %6, 11585
  %8 = add nsw i32 %7, 8192
  %9 = ashr i32 %8, 14
  %10 = sext i32 %9 to i64
  %11 = mul nsw i64 %10, 49757196124160
  %12 = ashr exact i64 %11, 32
  %13 = add nsw i64 %12, 8192
  %14 = lshr i64 %13, 14
  %15 = trunc i64 %14 to i32
  %16 = add i32 %15, 32
  %17 = lshr i32 %16, 6
  %18 = trunc i32 %17 to i16
  %19 = insertelement <8 x i16> undef, i16 %18, i32 0
  %20 = shufflevector <8 x i16> %19, <8 x i16> undef, <8 x i32> zeroinitializer
  %21 = sext i32 %2 to i64
  br label %22

22:                                               ; preds = %22, %3
  %23 = phi i64 [ 0, %3 ], [ %45, %22 ]
  %24 = mul nsw i64 %23, %21
  %25 = getelementptr inbounds i8, i8* %1, i64 %24
  %26 = bitcast i8* %25 to <16 x i8>*
  %27 = load <16 x i8>, <16 x i8>* %26, align 16
  %28 = shufflevector <16 x i8> %27, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %29 = shufflevector <16 x i8> %27, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %30 = bitcast <16 x i8> %29 to <8 x i16>
  %31 = add <8 x i16> %20, %30
  %32 = bitcast <16 x i8> %28 to <8 x i16>
  %33 = add <8 x i16> %20, %32
  %34 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %31, <8 x i16> %33) #6
  store <16 x i8> %34, <16 x i8>* %26, align 16
  %35 = getelementptr inbounds i8, i8* %25, i64 16
  %36 = bitcast i8* %35 to <16 x i8>*
  %37 = load <16 x i8>, <16 x i8>* %36, align 16
  %38 = shufflevector <16 x i8> %37, <16 x i8> <i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0>, <16 x i32> <i32 8, i32 24, i32 9, i32 25, i32 10, i32 26, i32 11, i32 27, i32 12, i32 28, i32 13, i32 29, i32 14, i32 30, i32 15, i32 31>
  %39 = shufflevector <16 x i8> %37, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %40 = bitcast <16 x i8> %39 to <8 x i16>
  %41 = add <8 x i16> %20, %40
  %42 = bitcast <16 x i8> %38 to <8 x i16>
  %43 = add <8 x i16> %20, %42
  %44 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %41, <8 x i16> %43) #6
  store <16 x i8> %44, <16 x i8>* %36, align 16
  %45 = add nuw nsw i64 %23, 1
  %46 = icmp eq i64 %45, 32
  br i1 %46, label %47, label %22

47:                                               ; preds = %22
  ret void
}

; Function Attrs: nounwind readnone
declare <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16>, <8 x i16>) #4

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16>, <8 x i16>) #4

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32>, <4 x i32>) #4

; Function Attrs: nounwind readnone speculatable
declare <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16>, <8 x i16>) #5

attributes #0 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind }
attributes #2 = { nofree nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { inlinehint nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { nounwind readnone }
attributes #5 = { nounwind readnone speculatable }
attributes #6 = { nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
