; ModuleID = '../../third_party/libaom/source/libaom/av1/encoder/x86/av1_fwd_txfm_sse2.c'
source_filename = "../../third_party/libaom/source/libaom/av1/encoder/x86/av1_fwd_txfm_sse2.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"

%struct.txfm_param = type { i8, i8, i32, i32, i32, i8, i32 }

@av1_fwd_txfm_shift_ls = external local_unnamed_addr global [19 x i8*], align 16
@av1_fwd_cos_bit_col = external local_unnamed_addr constant [5 x [5 x i8]], align 16
@av1_fwd_cos_bit_row = external local_unnamed_addr constant [5 x [5 x i8]], align 16
@col_txfm4x4_arr = internal unnamed_addr constant [16 x void (<2 x i64>*, <2 x i64>*, i8)*] [void (<2 x i64>*, <2 x i64>*, i8)* @fdct4x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst4x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fdct4x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst4x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst4x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fdct4x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst4x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst4x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst4x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity4x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fdct4x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity4x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst4x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity4x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst4x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity4x4_new_sse2], align 16
@row_txfm4x4_arr = internal unnamed_addr constant [16 x void (<2 x i64>*, <2 x i64>*, i8)*] [void (<2 x i64>*, <2 x i64>*, i8)* @fdct4x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fdct4x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst4x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst4x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fdct4x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst4x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst4x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst4x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst4x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity4x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity4x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fdct4x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity4x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst4x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity4x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst4x4_new_sse2], align 16
@col_txfm4x8_arr = internal unnamed_addr constant [16 x void (<2 x i64>*, <2 x i64>*, i8)*] [void (<2 x i64>*, <2 x i64>*, i8)* @fdct4x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst4x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fdct4x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst4x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst4x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fdct4x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst4x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst4x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst4x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fdct4x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst4x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst4x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x8_new_sse2], align 16
@row_txfm8x4_arr = internal unnamed_addr constant [16 x void (<2 x i64>*, <2 x i64>*, i8)*] [void (<2 x i64>*, <2 x i64>*, i8)* @fdct8x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fdct8x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fdct8x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fdct8x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x4_new_sse2], align 16
@col_txfm8x16_arr = internal unnamed_addr constant [16 x void (<2 x i64>*, <2 x i64>*, i8)*] [void (<2 x i64>*, <2 x i64>*, i8)* @fdct8x16_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x16_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fdct8x16_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x16_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x16_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fdct8x16_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x16_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x16_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x16_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x16_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fdct8x16_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x16_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x16_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x16_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x16_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x16_new_sse2], align 16
@col_txfm8x4_arr = internal unnamed_addr constant [16 x void (<2 x i64>*, <2 x i64>*, i8)*] [void (<2 x i64>*, <2 x i64>*, i8)* @fdct8x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fdct8x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fdct8x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fdct8x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x4_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x4_new_sse2], align 16
@row_txfm4x8_arr = internal unnamed_addr constant [16 x void (<2 x i64>*, <2 x i64>*, i8)*] [void (<2 x i64>*, <2 x i64>*, i8)* @fdct4x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fdct4x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst4x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst4x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fdct4x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst4x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst4x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst4x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst4x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fdct4x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst4x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst4x8_new_sse2], align 16
@col_txfm8x8_arr = internal unnamed_addr constant [16 x void (<2 x i64>*, <2 x i64>*, i8)*] [void (<2 x i64>*, <2 x i64>*, i8)* @fdct8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fdct8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fdct8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fdct8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x8_new_sse2], align 16
@row_txfm8x8_arr = internal unnamed_addr constant [16 x void (<2 x i64>*, <2 x i64>*, i8)*] [void (<2 x i64>*, <2 x i64>*, i8)* @fdct8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fdct8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fdct8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fdct8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x8_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x8_new_sse2], align 16
@col_txfm8x32_arr = internal unnamed_addr constant [16 x void (<2 x i64>*, <2 x i64>*, i8)*] [void (<2 x i64>*, <2 x i64>*, i8)* @av1_fdct8x32_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* null, void (<2 x i64>*, <2 x i64>*, i8)* null, void (<2 x i64>*, <2 x i64>*, i8)* null, void (<2 x i64>*, <2 x i64>*, i8)* null, void (<2 x i64>*, <2 x i64>*, i8)* null, void (<2 x i64>*, <2 x i64>*, i8)* null, void (<2 x i64>*, <2 x i64>*, i8)* null, void (<2 x i64>*, <2 x i64>*, i8)* null, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x32_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @av1_fdct8x32_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x32_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* null, void (<2 x i64>*, <2 x i64>*, i8)* null, void (<2 x i64>*, <2 x i64>*, i8)* null, void (<2 x i64>*, <2 x i64>*, i8)* null], align 16
@row_txfm8x16_arr = internal unnamed_addr constant [16 x void (<2 x i64>*, <2 x i64>*, i8)*] [void (<2 x i64>*, <2 x i64>*, i8)* @fdct8x16_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fdct8x16_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x16_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x16_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fdct8x16_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x16_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x16_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x16_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x16_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x16_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x16_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fdct8x16_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x16_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x16_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x16_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fadst8x16_new_sse2], align 16
@row_txfm8x32_arr = internal unnamed_addr constant [16 x void (<2 x i64>*, <2 x i64>*, i8)*] [void (<2 x i64>*, <2 x i64>*, i8)* @av1_fdct8x32_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* null, void (<2 x i64>*, <2 x i64>*, i8)* null, void (<2 x i64>*, <2 x i64>*, i8)* null, void (<2 x i64>*, <2 x i64>*, i8)* null, void (<2 x i64>*, <2 x i64>*, i8)* null, void (<2 x i64>*, <2 x i64>*, i8)* null, void (<2 x i64>*, <2 x i64>*, i8)* null, void (<2 x i64>*, <2 x i64>*, i8)* null, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x32_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @fidentity8x32_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* @av1_fdct8x32_new_sse2, void (<2 x i64>*, <2 x i64>*, i8)* null, void (<2 x i64>*, <2 x i64>*, i8)* null, void (<2 x i64>*, <2 x i64>*, i8)* null, void (<2 x i64>*, <2 x i64>*, i8)* null], align 16
@fwd_txfm2d_func_ls = internal unnamed_addr constant [19 x void (i16*, i32*, i32, i8, i32)*] [void (i16*, i32*, i32, i8, i32)* @av1_lowbd_fwd_txfm2d_4x4_sse2, void (i16*, i32*, i32, i8, i32)* @av1_lowbd_fwd_txfm2d_8x8_sse2, void (i16*, i32*, i32, i8, i32)* @av1_lowbd_fwd_txfm2d_16x16_sse2, void (i16*, i32*, i32, i8, i32)* @av1_lowbd_fwd_txfm2d_32x32_sse2, void (i16*, i32*, i32, i8, i32)* null, void (i16*, i32*, i32, i8, i32)* @av1_lowbd_fwd_txfm2d_4x8_sse2, void (i16*, i32*, i32, i8, i32)* @av1_lowbd_fwd_txfm2d_8x4_sse2, void (i16*, i32*, i32, i8, i32)* @av1_lowbd_fwd_txfm2d_8x16_sse2, void (i16*, i32*, i32, i8, i32)* @av1_lowbd_fwd_txfm2d_16x8_sse2, void (i16*, i32*, i32, i8, i32)* @av1_lowbd_fwd_txfm2d_16x32_sse2, void (i16*, i32*, i32, i8, i32)* @av1_lowbd_fwd_txfm2d_32x16_sse2, void (i16*, i32*, i32, i8, i32)* null, void (i16*, i32*, i32, i8, i32)* null, void (i16*, i32*, i32, i8, i32)* @av1_lowbd_fwd_txfm2d_4x16_sse2, void (i16*, i32*, i32, i8, i32)* @av1_lowbd_fwd_txfm2d_16x4_sse2, void (i16*, i32*, i32, i8, i32)* @av1_lowbd_fwd_txfm2d_8x32_sse2, void (i16*, i32*, i32, i8, i32)* @av1_lowbd_fwd_txfm2d_32x8_sse2, void (i16*, i32*, i32, i8, i32)* @av1_lowbd_fwd_txfm2d_16x64_sse2, void (i16*, i32*, i32, i8, i32)* @av1_lowbd_fwd_txfm2d_64x16_sse2], align 16
@av1_cospi_arr_data = external local_unnamed_addr constant [7 x [64 x i32]], align 16
@av1_sinpi_arr_data = external local_unnamed_addr constant [7 x [5 x i32]], align 16

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @av1_fdct8x32_new_sse2(<2 x i64>* readonly, <2 x i64>*, i8 signext) #0 {
  %4 = sext i8 %2 to i32
  %5 = add nsw i32 %4, -10
  %6 = sext i32 %5 to i64
  %7 = add nsw i32 %4, -1
  %8 = shl i32 1, %7
  %9 = insertelement <4 x i32> undef, i32 %8, i32 0
  %10 = shufflevector <4 x i32> %9, <4 x i32> undef, <4 x i32> zeroinitializer
  %11 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 32
  %12 = load i32, i32* %11, align 16
  %13 = sub i32 0, %12
  %14 = and i32 %13, 65535
  %15 = shl i32 %12, 16
  %16 = or i32 %14, %15
  %17 = insertelement <4 x i32> undef, i32 %16, i32 0
  %18 = shufflevector <4 x i32> %17, <4 x i32> undef, <4 x i32> zeroinitializer
  %19 = and i32 %12, 65535
  %20 = or i32 %19, %15
  %21 = insertelement <4 x i32> undef, i32 %20, i32 0
  %22 = shufflevector <4 x i32> %21, <4 x i32> undef, <4 x i32> zeroinitializer
  %23 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 16
  %24 = load i32, i32* %23, align 16
  %25 = sub i32 0, %24
  %26 = and i32 %25, 65535
  %27 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 48
  %28 = load i32, i32* %27, align 16
  %29 = shl i32 %28, 16
  %30 = or i32 %29, %26
  %31 = insertelement <4 x i32> undef, i32 %30, i32 0
  %32 = shufflevector <4 x i32> %31, <4 x i32> undef, <4 x i32> zeroinitializer
  %33 = and i32 %28, 65535
  %34 = shl i32 %24, 16
  %35 = or i32 %33, %34
  %36 = insertelement <4 x i32> undef, i32 %35, i32 0
  %37 = shufflevector <4 x i32> %36, <4 x i32> undef, <4 x i32> zeroinitializer
  %38 = sub i32 0, %28
  %39 = and i32 %38, 65535
  %40 = sub i32 0, %34
  %41 = or i32 %39, %40
  %42 = insertelement <4 x i32> undef, i32 %41, i32 0
  %43 = shufflevector <4 x i32> %42, <4 x i32> undef, <4 x i32> zeroinitializer
  %44 = sub i32 0, %15
  %45 = or i32 %19, %44
  %46 = insertelement <4 x i32> undef, i32 %45, i32 0
  %47 = shufflevector <4 x i32> %46, <4 x i32> undef, <4 x i32> zeroinitializer
  %48 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 56
  %49 = load i32, i32* %48, align 16
  %50 = and i32 %49, 65535
  %51 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 8
  %52 = load i32, i32* %51, align 16
  %53 = shl i32 %52, 16
  %54 = or i32 %53, %50
  %55 = insertelement <4 x i32> undef, i32 %54, i32 0
  %56 = shufflevector <4 x i32> %55, <4 x i32> undef, <4 x i32> zeroinitializer
  %57 = sub i32 0, %52
  %58 = and i32 %57, 65535
  %59 = shl i32 %49, 16
  %60 = or i32 %58, %59
  %61 = insertelement <4 x i32> undef, i32 %60, i32 0
  %62 = shufflevector <4 x i32> %61, <4 x i32> undef, <4 x i32> zeroinitializer
  %63 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 24
  %64 = load i32, i32* %63, align 16
  %65 = and i32 %64, 65535
  %66 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 40
  %67 = load i32, i32* %66, align 16
  %68 = shl i32 %67, 16
  %69 = or i32 %68, %65
  %70 = insertelement <4 x i32> undef, i32 %69, i32 0
  %71 = shufflevector <4 x i32> %70, <4 x i32> undef, <4 x i32> zeroinitializer
  %72 = sub i32 0, %67
  %73 = and i32 %72, 65535
  %74 = shl i32 %64, 16
  %75 = or i32 %73, %74
  %76 = insertelement <4 x i32> undef, i32 %75, i32 0
  %77 = shufflevector <4 x i32> %76, <4 x i32> undef, <4 x i32> zeroinitializer
  %78 = sub i32 0, %49
  %79 = and i32 %78, 65535
  %80 = sub i32 0, %53
  %81 = or i32 %79, %80
  %82 = insertelement <4 x i32> undef, i32 %81, i32 0
  %83 = shufflevector <4 x i32> %82, <4 x i32> undef, <4 x i32> zeroinitializer
  %84 = sub i32 0, %64
  %85 = and i32 %84, 65535
  %86 = sub i32 0, %68
  %87 = or i32 %85, %86
  %88 = insertelement <4 x i32> undef, i32 %87, i32 0
  %89 = shufflevector <4 x i32> %88, <4 x i32> undef, <4 x i32> zeroinitializer
  %90 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 60
  %91 = load i32, i32* %90, align 16
  %92 = and i32 %91, 65535
  %93 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 4
  %94 = load i32, i32* %93, align 16
  %95 = shl i32 %94, 16
  %96 = or i32 %95, %92
  %97 = insertelement <4 x i32> undef, i32 %96, i32 0
  %98 = shufflevector <4 x i32> %97, <4 x i32> undef, <4 x i32> zeroinitializer
  %99 = sub i32 0, %94
  %100 = and i32 %99, 65535
  %101 = shl i32 %91, 16
  %102 = or i32 %100, %101
  %103 = insertelement <4 x i32> undef, i32 %102, i32 0
  %104 = shufflevector <4 x i32> %103, <4 x i32> undef, <4 x i32> zeroinitializer
  %105 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 28
  %106 = load i32, i32* %105, align 16
  %107 = and i32 %106, 65535
  %108 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 36
  %109 = load i32, i32* %108, align 16
  %110 = shl i32 %109, 16
  %111 = or i32 %110, %107
  %112 = insertelement <4 x i32> undef, i32 %111, i32 0
  %113 = shufflevector <4 x i32> %112, <4 x i32> undef, <4 x i32> zeroinitializer
  %114 = sub i32 0, %109
  %115 = and i32 %114, 65535
  %116 = shl i32 %106, 16
  %117 = or i32 %115, %116
  %118 = insertelement <4 x i32> undef, i32 %117, i32 0
  %119 = shufflevector <4 x i32> %118, <4 x i32> undef, <4 x i32> zeroinitializer
  %120 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 44
  %121 = load i32, i32* %120, align 16
  %122 = and i32 %121, 65535
  %123 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 20
  %124 = load i32, i32* %123, align 16
  %125 = shl i32 %124, 16
  %126 = or i32 %125, %122
  %127 = insertelement <4 x i32> undef, i32 %126, i32 0
  %128 = shufflevector <4 x i32> %127, <4 x i32> undef, <4 x i32> zeroinitializer
  %129 = sub i32 0, %124
  %130 = and i32 %129, 65535
  %131 = shl i32 %121, 16
  %132 = or i32 %130, %131
  %133 = insertelement <4 x i32> undef, i32 %132, i32 0
  %134 = shufflevector <4 x i32> %133, <4 x i32> undef, <4 x i32> zeroinitializer
  %135 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 12
  %136 = load i32, i32* %135, align 16
  %137 = and i32 %136, 65535
  %138 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 52
  %139 = load i32, i32* %138, align 16
  %140 = shl i32 %139, 16
  %141 = or i32 %140, %137
  %142 = insertelement <4 x i32> undef, i32 %141, i32 0
  %143 = shufflevector <4 x i32> %142, <4 x i32> undef, <4 x i32> zeroinitializer
  %144 = sub i32 0, %139
  %145 = and i32 %144, 65535
  %146 = shl i32 %136, 16
  %147 = or i32 %145, %146
  %148 = insertelement <4 x i32> undef, i32 %147, i32 0
  %149 = shufflevector <4 x i32> %148, <4 x i32> undef, <4 x i32> zeroinitializer
  %150 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 62
  %151 = load i32, i32* %150, align 8
  %152 = and i32 %151, 65535
  %153 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 2
  %154 = load i32, i32* %153, align 8
  %155 = shl i32 %154, 16
  %156 = or i32 %155, %152
  %157 = insertelement <4 x i32> undef, i32 %156, i32 0
  %158 = shufflevector <4 x i32> %157, <4 x i32> undef, <4 x i32> zeroinitializer
  %159 = sub i32 0, %154
  %160 = and i32 %159, 65535
  %161 = shl i32 %151, 16
  %162 = or i32 %160, %161
  %163 = insertelement <4 x i32> undef, i32 %162, i32 0
  %164 = shufflevector <4 x i32> %163, <4 x i32> undef, <4 x i32> zeroinitializer
  %165 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 30
  %166 = load i32, i32* %165, align 8
  %167 = and i32 %166, 65535
  %168 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 34
  %169 = load i32, i32* %168, align 8
  %170 = shl i32 %169, 16
  %171 = or i32 %170, %167
  %172 = insertelement <4 x i32> undef, i32 %171, i32 0
  %173 = shufflevector <4 x i32> %172, <4 x i32> undef, <4 x i32> zeroinitializer
  %174 = sub i32 0, %169
  %175 = and i32 %174, 65535
  %176 = shl i32 %166, 16
  %177 = or i32 %175, %176
  %178 = insertelement <4 x i32> undef, i32 %177, i32 0
  %179 = shufflevector <4 x i32> %178, <4 x i32> undef, <4 x i32> zeroinitializer
  %180 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 46
  %181 = load i32, i32* %180, align 8
  %182 = and i32 %181, 65535
  %183 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 18
  %184 = load i32, i32* %183, align 8
  %185 = shl i32 %184, 16
  %186 = or i32 %185, %182
  %187 = insertelement <4 x i32> undef, i32 %186, i32 0
  %188 = shufflevector <4 x i32> %187, <4 x i32> undef, <4 x i32> zeroinitializer
  %189 = sub i32 0, %184
  %190 = and i32 %189, 65535
  %191 = shl i32 %181, 16
  %192 = or i32 %190, %191
  %193 = insertelement <4 x i32> undef, i32 %192, i32 0
  %194 = shufflevector <4 x i32> %193, <4 x i32> undef, <4 x i32> zeroinitializer
  %195 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 14
  %196 = load i32, i32* %195, align 8
  %197 = and i32 %196, 65535
  %198 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 50
  %199 = load i32, i32* %198, align 8
  %200 = shl i32 %199, 16
  %201 = or i32 %200, %197
  %202 = insertelement <4 x i32> undef, i32 %201, i32 0
  %203 = shufflevector <4 x i32> %202, <4 x i32> undef, <4 x i32> zeroinitializer
  %204 = sub i32 0, %199
  %205 = and i32 %204, 65535
  %206 = shl i32 %196, 16
  %207 = or i32 %205, %206
  %208 = insertelement <4 x i32> undef, i32 %207, i32 0
  %209 = shufflevector <4 x i32> %208, <4 x i32> undef, <4 x i32> zeroinitializer
  %210 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 54
  %211 = load i32, i32* %210, align 8
  %212 = and i32 %211, 65535
  %213 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 10
  %214 = load i32, i32* %213, align 8
  %215 = shl i32 %214, 16
  %216 = or i32 %215, %212
  %217 = insertelement <4 x i32> undef, i32 %216, i32 0
  %218 = shufflevector <4 x i32> %217, <4 x i32> undef, <4 x i32> zeroinitializer
  %219 = sub i32 0, %214
  %220 = and i32 %219, 65535
  %221 = shl i32 %211, 16
  %222 = or i32 %220, %221
  %223 = insertelement <4 x i32> undef, i32 %222, i32 0
  %224 = shufflevector <4 x i32> %223, <4 x i32> undef, <4 x i32> zeroinitializer
  %225 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 22
  %226 = load i32, i32* %225, align 8
  %227 = and i32 %226, 65535
  %228 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 42
  %229 = load i32, i32* %228, align 8
  %230 = shl i32 %229, 16
  %231 = or i32 %230, %227
  %232 = insertelement <4 x i32> undef, i32 %231, i32 0
  %233 = shufflevector <4 x i32> %232, <4 x i32> undef, <4 x i32> zeroinitializer
  %234 = sub i32 0, %229
  %235 = and i32 %234, 65535
  %236 = shl i32 %226, 16
  %237 = or i32 %235, %236
  %238 = insertelement <4 x i32> undef, i32 %237, i32 0
  %239 = shufflevector <4 x i32> %238, <4 x i32> undef, <4 x i32> zeroinitializer
  %240 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 38
  %241 = load i32, i32* %240, align 8
  %242 = and i32 %241, 65535
  %243 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 26
  %244 = load i32, i32* %243, align 8
  %245 = shl i32 %244, 16
  %246 = or i32 %245, %242
  %247 = insertelement <4 x i32> undef, i32 %246, i32 0
  %248 = shufflevector <4 x i32> %247, <4 x i32> undef, <4 x i32> zeroinitializer
  %249 = sub i32 0, %244
  %250 = and i32 %249, 65535
  %251 = shl i32 %241, 16
  %252 = or i32 %250, %251
  %253 = insertelement <4 x i32> undef, i32 %252, i32 0
  %254 = shufflevector <4 x i32> %253, <4 x i32> undef, <4 x i32> zeroinitializer
  %255 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 6
  %256 = load i32, i32* %255, align 8
  %257 = and i32 %256, 65535
  %258 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 58
  %259 = load i32, i32* %258, align 8
  %260 = shl i32 %259, 16
  %261 = or i32 %260, %257
  %262 = insertelement <4 x i32> undef, i32 %261, i32 0
  %263 = shufflevector <4 x i32> %262, <4 x i32> undef, <4 x i32> zeroinitializer
  %264 = sub i32 0, %259
  %265 = and i32 %264, 65535
  %266 = shl i32 %256, 16
  %267 = or i32 %265, %266
  %268 = insertelement <4 x i32> undef, i32 %267, i32 0
  %269 = shufflevector <4 x i32> %268, <4 x i32> undef, <4 x i32> zeroinitializer
  %270 = bitcast <2 x i64>* %0 to <8 x i16>*
  %271 = load <8 x i16>, <8 x i16>* %270, align 16
  %272 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 31
  %273 = bitcast <2 x i64>* %272 to <8 x i16>*
  %274 = load <8 x i16>, <8 x i16>* %273, align 16
  %275 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %271, <8 x i16> %274) #8
  %276 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %271, <8 x i16> %274) #8
  %277 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %278 = bitcast <2 x i64>* %277 to <8 x i16>*
  %279 = load <8 x i16>, <8 x i16>* %278, align 16
  %280 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 30
  %281 = bitcast <2 x i64>* %280 to <8 x i16>*
  %282 = load <8 x i16>, <8 x i16>* %281, align 16
  %283 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %279, <8 x i16> %282) #8
  %284 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %279, <8 x i16> %282) #8
  %285 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %286 = bitcast <2 x i64>* %285 to <8 x i16>*
  %287 = load <8 x i16>, <8 x i16>* %286, align 16
  %288 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 29
  %289 = bitcast <2 x i64>* %288 to <8 x i16>*
  %290 = load <8 x i16>, <8 x i16>* %289, align 16
  %291 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %287, <8 x i16> %290) #8
  %292 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %287, <8 x i16> %290) #8
  %293 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %294 = bitcast <2 x i64>* %293 to <8 x i16>*
  %295 = load <8 x i16>, <8 x i16>* %294, align 16
  %296 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 28
  %297 = bitcast <2 x i64>* %296 to <8 x i16>*
  %298 = load <8 x i16>, <8 x i16>* %297, align 16
  %299 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %295, <8 x i16> %298) #8
  %300 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %295, <8 x i16> %298) #8
  %301 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %302 = bitcast <2 x i64>* %301 to <8 x i16>*
  %303 = load <8 x i16>, <8 x i16>* %302, align 16
  %304 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 27
  %305 = bitcast <2 x i64>* %304 to <8 x i16>*
  %306 = load <8 x i16>, <8 x i16>* %305, align 16
  %307 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %303, <8 x i16> %306) #8
  %308 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %303, <8 x i16> %306) #8
  %309 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %310 = bitcast <2 x i64>* %309 to <8 x i16>*
  %311 = load <8 x i16>, <8 x i16>* %310, align 16
  %312 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 26
  %313 = bitcast <2 x i64>* %312 to <8 x i16>*
  %314 = load <8 x i16>, <8 x i16>* %313, align 16
  %315 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %311, <8 x i16> %314) #8
  %316 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %311, <8 x i16> %314) #8
  %317 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %318 = bitcast <2 x i64>* %317 to <8 x i16>*
  %319 = load <8 x i16>, <8 x i16>* %318, align 16
  %320 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 25
  %321 = bitcast <2 x i64>* %320 to <8 x i16>*
  %322 = load <8 x i16>, <8 x i16>* %321, align 16
  %323 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %319, <8 x i16> %322) #8
  %324 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %319, <8 x i16> %322) #8
  %325 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %326 = bitcast <2 x i64>* %325 to <8 x i16>*
  %327 = load <8 x i16>, <8 x i16>* %326, align 16
  %328 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 24
  %329 = bitcast <2 x i64>* %328 to <8 x i16>*
  %330 = load <8 x i16>, <8 x i16>* %329, align 16
  %331 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %327, <8 x i16> %330) #8
  %332 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %327, <8 x i16> %330) #8
  %333 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 8
  %334 = bitcast <2 x i64>* %333 to <8 x i16>*
  %335 = load <8 x i16>, <8 x i16>* %334, align 16
  %336 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 23
  %337 = bitcast <2 x i64>* %336 to <8 x i16>*
  %338 = load <8 x i16>, <8 x i16>* %337, align 16
  %339 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %335, <8 x i16> %338) #8
  %340 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %335, <8 x i16> %338) #8
  %341 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 9
  %342 = bitcast <2 x i64>* %341 to <8 x i16>*
  %343 = load <8 x i16>, <8 x i16>* %342, align 16
  %344 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 22
  %345 = bitcast <2 x i64>* %344 to <8 x i16>*
  %346 = load <8 x i16>, <8 x i16>* %345, align 16
  %347 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %343, <8 x i16> %346) #8
  %348 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %343, <8 x i16> %346) #8
  %349 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 10
  %350 = bitcast <2 x i64>* %349 to <8 x i16>*
  %351 = load <8 x i16>, <8 x i16>* %350, align 16
  %352 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 21
  %353 = bitcast <2 x i64>* %352 to <8 x i16>*
  %354 = load <8 x i16>, <8 x i16>* %353, align 16
  %355 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %351, <8 x i16> %354) #8
  %356 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %351, <8 x i16> %354) #8
  %357 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 11
  %358 = bitcast <2 x i64>* %357 to <8 x i16>*
  %359 = load <8 x i16>, <8 x i16>* %358, align 16
  %360 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 20
  %361 = bitcast <2 x i64>* %360 to <8 x i16>*
  %362 = load <8 x i16>, <8 x i16>* %361, align 16
  %363 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %359, <8 x i16> %362) #8
  %364 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %359, <8 x i16> %362) #8
  %365 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 12
  %366 = bitcast <2 x i64>* %365 to <8 x i16>*
  %367 = load <8 x i16>, <8 x i16>* %366, align 16
  %368 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 19
  %369 = bitcast <2 x i64>* %368 to <8 x i16>*
  %370 = load <8 x i16>, <8 x i16>* %369, align 16
  %371 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %367, <8 x i16> %370) #8
  %372 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %367, <8 x i16> %370) #8
  %373 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 13
  %374 = bitcast <2 x i64>* %373 to <8 x i16>*
  %375 = load <8 x i16>, <8 x i16>* %374, align 16
  %376 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 18
  %377 = bitcast <2 x i64>* %376 to <8 x i16>*
  %378 = load <8 x i16>, <8 x i16>* %377, align 16
  %379 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %375, <8 x i16> %378) #8
  %380 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %375, <8 x i16> %378) #8
  %381 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 14
  %382 = bitcast <2 x i64>* %381 to <8 x i16>*
  %383 = load <8 x i16>, <8 x i16>* %382, align 16
  %384 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 17
  %385 = bitcast <2 x i64>* %384 to <8 x i16>*
  %386 = load <8 x i16>, <8 x i16>* %385, align 16
  %387 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %383, <8 x i16> %386) #8
  %388 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %383, <8 x i16> %386) #8
  %389 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 15
  %390 = bitcast <2 x i64>* %389 to <8 x i16>*
  %391 = load <8 x i16>, <8 x i16>* %390, align 16
  %392 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 16
  %393 = bitcast <2 x i64>* %392 to <8 x i16>*
  %394 = load <8 x i16>, <8 x i16>* %393, align 16
  %395 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %391, <8 x i16> %394) #8
  %396 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %391, <8 x i16> %394) #8
  %397 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %275, <8 x i16> %395) #8
  %398 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %275, <8 x i16> %395) #8
  %399 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %283, <8 x i16> %387) #8
  %400 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %283, <8 x i16> %387) #8
  %401 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %291, <8 x i16> %379) #8
  %402 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %291, <8 x i16> %379) #8
  %403 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %299, <8 x i16> %371) #8
  %404 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %299, <8 x i16> %371) #8
  %405 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %307, <8 x i16> %363) #8
  %406 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %307, <8 x i16> %363) #8
  %407 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %315, <8 x i16> %355) #8
  %408 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %315, <8 x i16> %355) #8
  %409 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %323, <8 x i16> %347) #8
  %410 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %323, <8 x i16> %347) #8
  %411 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %331, <8 x i16> %339) #8
  %412 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %331, <8 x i16> %339) #8
  %413 = shufflevector <8 x i16> %364, <8 x i16> %308, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %414 = shufflevector <8 x i16> %364, <8 x i16> %308, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %415 = bitcast <4 x i32> %18 to <8 x i16>
  %416 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %413, <8 x i16> %415) #8
  %417 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %414, <8 x i16> %415) #8
  %418 = bitcast <4 x i32> %22 to <8 x i16>
  %419 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %413, <8 x i16> %418) #8
  %420 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %414, <8 x i16> %418) #8
  %421 = add <4 x i32> %416, %10
  %422 = add <4 x i32> %417, %10
  %423 = add <4 x i32> %419, %10
  %424 = add <4 x i32> %420, %10
  %425 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %421, i32 %4) #8
  %426 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %422, i32 %4) #8
  %427 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %423, i32 %4) #8
  %428 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %424, i32 %4) #8
  %429 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %425, <4 x i32> %426) #8
  %430 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %427, <4 x i32> %428) #8
  %431 = shufflevector <8 x i16> %356, <8 x i16> %316, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %432 = shufflevector <8 x i16> %356, <8 x i16> %316, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %433 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %431, <8 x i16> %415) #8
  %434 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %432, <8 x i16> %415) #8
  %435 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %431, <8 x i16> %418) #8
  %436 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %432, <8 x i16> %418) #8
  %437 = add <4 x i32> %433, %10
  %438 = add <4 x i32> %434, %10
  %439 = add <4 x i32> %435, %10
  %440 = add <4 x i32> %436, %10
  %441 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %437, i32 %4) #8
  %442 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %438, i32 %4) #8
  %443 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %439, i32 %4) #8
  %444 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %440, i32 %4) #8
  %445 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %441, <4 x i32> %442) #8
  %446 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %443, <4 x i32> %444) #8
  %447 = shufflevector <8 x i16> %348, <8 x i16> %324, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %448 = shufflevector <8 x i16> %348, <8 x i16> %324, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %449 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %447, <8 x i16> %415) #8
  %450 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %448, <8 x i16> %415) #8
  %451 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %447, <8 x i16> %418) #8
  %452 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %448, <8 x i16> %418) #8
  %453 = add <4 x i32> %449, %10
  %454 = add <4 x i32> %450, %10
  %455 = add <4 x i32> %451, %10
  %456 = add <4 x i32> %452, %10
  %457 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %453, i32 %4) #8
  %458 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %454, i32 %4) #8
  %459 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %455, i32 %4) #8
  %460 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %456, i32 %4) #8
  %461 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %457, <4 x i32> %458) #8
  %462 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %459, <4 x i32> %460) #8
  %463 = shufflevector <8 x i16> %340, <8 x i16> %332, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %464 = shufflevector <8 x i16> %340, <8 x i16> %332, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %465 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %463, <8 x i16> %415) #8
  %466 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %464, <8 x i16> %415) #8
  %467 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %463, <8 x i16> %418) #8
  %468 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %464, <8 x i16> %418) #8
  %469 = add <4 x i32> %465, %10
  %470 = add <4 x i32> %466, %10
  %471 = add <4 x i32> %467, %10
  %472 = add <4 x i32> %468, %10
  %473 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %469, i32 %4) #8
  %474 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %470, i32 %4) #8
  %475 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %471, i32 %4) #8
  %476 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %472, i32 %4) #8
  %477 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %473, <4 x i32> %474) #8
  %478 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %475, <4 x i32> %476) #8
  %479 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %397, <8 x i16> %411) #8
  %480 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %397, <8 x i16> %411) #8
  %481 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %399, <8 x i16> %409) #8
  %482 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %399, <8 x i16> %409) #8
  %483 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %401, <8 x i16> %407) #8
  %484 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %401, <8 x i16> %407) #8
  %485 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %403, <8 x i16> %405) #8
  %486 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %403, <8 x i16> %405) #8
  %487 = shufflevector <8 x i16> %408, <8 x i16> %402, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %488 = shufflevector <8 x i16> %408, <8 x i16> %402, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %489 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %487, <8 x i16> %415) #8
  %490 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %488, <8 x i16> %415) #8
  %491 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %487, <8 x i16> %418) #8
  %492 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %488, <8 x i16> %418) #8
  %493 = add <4 x i32> %489, %10
  %494 = add <4 x i32> %490, %10
  %495 = add <4 x i32> %491, %10
  %496 = add <4 x i32> %492, %10
  %497 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %493, i32 %4) #8
  %498 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %494, i32 %4) #8
  %499 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %495, i32 %4) #8
  %500 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %496, i32 %4) #8
  %501 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %497, <4 x i32> %498) #8
  %502 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %499, <4 x i32> %500) #8
  %503 = shufflevector <8 x i16> %406, <8 x i16> %404, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %504 = shufflevector <8 x i16> %406, <8 x i16> %404, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %505 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %503, <8 x i16> %415) #8
  %506 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %504, <8 x i16> %415) #8
  %507 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %503, <8 x i16> %418) #8
  %508 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %504, <8 x i16> %418) #8
  %509 = add <4 x i32> %505, %10
  %510 = add <4 x i32> %506, %10
  %511 = add <4 x i32> %507, %10
  %512 = add <4 x i32> %508, %10
  %513 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %509, i32 %4) #8
  %514 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %510, i32 %4) #8
  %515 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %511, i32 %4) #8
  %516 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %512, i32 %4) #8
  %517 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %513, <4 x i32> %514) #8
  %518 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %515, <4 x i32> %516) #8
  %519 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %396, <8 x i16> %477) #8
  %520 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %396, <8 x i16> %477) #8
  %521 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %388, <8 x i16> %461) #8
  %522 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %388, <8 x i16> %461) #8
  %523 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %380, <8 x i16> %445) #8
  %524 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %380, <8 x i16> %445) #8
  %525 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %372, <8 x i16> %429) #8
  %526 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %372, <8 x i16> %429) #8
  %527 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %276, <8 x i16> %478) #8
  %528 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %276, <8 x i16> %478) #8
  %529 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %284, <8 x i16> %462) #8
  %530 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %284, <8 x i16> %462) #8
  %531 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %292, <8 x i16> %446) #8
  %532 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %292, <8 x i16> %446) #8
  %533 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %300, <8 x i16> %430) #8
  %534 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %300, <8 x i16> %430) #8
  %535 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %479, <8 x i16> %485) #8
  %536 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %479, <8 x i16> %485) #8
  %537 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %481, <8 x i16> %483) #8
  %538 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %481, <8 x i16> %483) #8
  %539 = shufflevector <8 x i16> %484, <8 x i16> %482, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %540 = shufflevector <8 x i16> %484, <8 x i16> %482, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %541 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %539, <8 x i16> %415) #8
  %542 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %540, <8 x i16> %415) #8
  %543 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %539, <8 x i16> %418) #8
  %544 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %540, <8 x i16> %418) #8
  %545 = add <4 x i32> %541, %10
  %546 = add <4 x i32> %542, %10
  %547 = add <4 x i32> %543, %10
  %548 = add <4 x i32> %544, %10
  %549 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %545, i32 %4) #8
  %550 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %546, i32 %4) #8
  %551 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %547, i32 %4) #8
  %552 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %548, i32 %4) #8
  %553 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %549, <4 x i32> %550) #8
  %554 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %551, <4 x i32> %552) #8
  %555 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %412, <8 x i16> %517) #8
  %556 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %412, <8 x i16> %517) #8
  %557 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %410, <8 x i16> %501) #8
  %558 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %410, <8 x i16> %501) #8
  %559 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %398, <8 x i16> %518) #8
  %560 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %398, <8 x i16> %518) #8
  %561 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %400, <8 x i16> %502) #8
  %562 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %400, <8 x i16> %502) #8
  %563 = shufflevector <8 x i16> %523, <8 x i16> %532, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %564 = shufflevector <8 x i16> %523, <8 x i16> %532, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %565 = bitcast <4 x i32> %32 to <8 x i16>
  %566 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %563, <8 x i16> %565) #8
  %567 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %564, <8 x i16> %565) #8
  %568 = bitcast <4 x i32> %37 to <8 x i16>
  %569 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %563, <8 x i16> %568) #8
  %570 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %564, <8 x i16> %568) #8
  %571 = add <4 x i32> %566, %10
  %572 = add <4 x i32> %567, %10
  %573 = add <4 x i32> %569, %10
  %574 = add <4 x i32> %570, %10
  %575 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %571, i32 %4) #8
  %576 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %572, i32 %4) #8
  %577 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %573, i32 %4) #8
  %578 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %574, i32 %4) #8
  %579 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %575, <4 x i32> %576) #8
  %580 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %577, <4 x i32> %578) #8
  %581 = shufflevector <8 x i16> %525, <8 x i16> %534, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %582 = shufflevector <8 x i16> %525, <8 x i16> %534, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %583 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %581, <8 x i16> %565) #8
  %584 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %582, <8 x i16> %565) #8
  %585 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %581, <8 x i16> %568) #8
  %586 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %582, <8 x i16> %568) #8
  %587 = add <4 x i32> %583, %10
  %588 = add <4 x i32> %584, %10
  %589 = add <4 x i32> %585, %10
  %590 = add <4 x i32> %586, %10
  %591 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %587, i32 %4) #8
  %592 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %588, i32 %4) #8
  %593 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %589, i32 %4) #8
  %594 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %590, i32 %4) #8
  %595 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %591, <4 x i32> %592) #8
  %596 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %593, <4 x i32> %594) #8
  %597 = shufflevector <8 x i16> %526, <8 x i16> %533, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %598 = shufflevector <8 x i16> %526, <8 x i16> %533, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %599 = bitcast <4 x i32> %43 to <8 x i16>
  %600 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %597, <8 x i16> %599) #8
  %601 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %598, <8 x i16> %599) #8
  %602 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %597, <8 x i16> %565) #8
  %603 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %598, <8 x i16> %565) #8
  %604 = add <4 x i32> %600, %10
  %605 = add <4 x i32> %601, %10
  %606 = add <4 x i32> %602, %10
  %607 = add <4 x i32> %603, %10
  %608 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %604, i32 %4) #8
  %609 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %605, i32 %4) #8
  %610 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %606, i32 %4) #8
  %611 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %607, i32 %4) #8
  %612 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %608, <4 x i32> %609) #8
  %613 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %610, <4 x i32> %611) #8
  %614 = shufflevector <8 x i16> %524, <8 x i16> %531, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %615 = shufflevector <8 x i16> %524, <8 x i16> %531, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %616 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %614, <8 x i16> %599) #8
  %617 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %615, <8 x i16> %599) #8
  %618 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %614, <8 x i16> %565) #8
  %619 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %615, <8 x i16> %565) #8
  %620 = add <4 x i32> %616, %10
  %621 = add <4 x i32> %617, %10
  %622 = add <4 x i32> %618, %10
  %623 = add <4 x i32> %619, %10
  %624 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %620, i32 %4) #8
  %625 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %621, i32 %4) #8
  %626 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %622, i32 %4) #8
  %627 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %623, i32 %4) #8
  %628 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %624, <4 x i32> %625) #8
  %629 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %626, <4 x i32> %627) #8
  %630 = shufflevector <8 x i16> %535, <8 x i16> %537, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %631 = shufflevector <8 x i16> %535, <8 x i16> %537, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %632 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %630, <8 x i16> %418) #8
  %633 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %631, <8 x i16> %418) #8
  %634 = bitcast <4 x i32> %47 to <8 x i16>
  %635 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %630, <8 x i16> %634) #8
  %636 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %631, <8 x i16> %634) #8
  %637 = add <4 x i32> %632, %10
  %638 = add <4 x i32> %633, %10
  %639 = add <4 x i32> %635, %10
  %640 = add <4 x i32> %636, %10
  %641 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %637, i32 %4) #8
  %642 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %638, i32 %4) #8
  %643 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %639, i32 %4) #8
  %644 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %640, i32 %4) #8
  %645 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %641, <4 x i32> %642) #8
  %646 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %643, <4 x i32> %644) #8
  %647 = shufflevector <8 x i16> %538, <8 x i16> %536, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %648 = shufflevector <8 x i16> %538, <8 x i16> %536, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %649 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %647, <8 x i16> %568) #8
  %650 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %648, <8 x i16> %568) #8
  %651 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %647, <8 x i16> %565) #8
  %652 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %648, <8 x i16> %565) #8
  %653 = add <4 x i32> %649, %10
  %654 = add <4 x i32> %650, %10
  %655 = add <4 x i32> %651, %10
  %656 = add <4 x i32> %652, %10
  %657 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %653, i32 %4) #8
  %658 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %654, i32 %4) #8
  %659 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %655, i32 %4) #8
  %660 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %656, i32 %4) #8
  %661 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %657, <4 x i32> %658) #8
  %662 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %659, <4 x i32> %660) #8
  %663 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %486, <8 x i16> %553) #8
  %664 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %486, <8 x i16> %553) #8
  %665 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %480, <8 x i16> %554) #8
  %666 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %480, <8 x i16> %554) #8
  %667 = shufflevector <8 x i16> %557, <8 x i16> %562, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %668 = shufflevector <8 x i16> %557, <8 x i16> %562, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %669 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %667, <8 x i16> %565) #8
  %670 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %668, <8 x i16> %565) #8
  %671 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %667, <8 x i16> %568) #8
  %672 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %668, <8 x i16> %568) #8
  %673 = add <4 x i32> %669, %10
  %674 = add <4 x i32> %670, %10
  %675 = add <4 x i32> %671, %10
  %676 = add <4 x i32> %672, %10
  %677 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %673, i32 %4) #8
  %678 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %674, i32 %4) #8
  %679 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %675, i32 %4) #8
  %680 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %676, i32 %4) #8
  %681 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %677, <4 x i32> %678) #8
  %682 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %679, <4 x i32> %680) #8
  %683 = shufflevector <8 x i16> %558, <8 x i16> %561, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %684 = shufflevector <8 x i16> %558, <8 x i16> %561, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %685 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %683, <8 x i16> %599) #8
  %686 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %684, <8 x i16> %599) #8
  %687 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %683, <8 x i16> %565) #8
  %688 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %684, <8 x i16> %565) #8
  %689 = add <4 x i32> %685, %10
  %690 = add <4 x i32> %686, %10
  %691 = add <4 x i32> %687, %10
  %692 = add <4 x i32> %688, %10
  %693 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %689, i32 %4) #8
  %694 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %690, i32 %4) #8
  %695 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %691, i32 %4) #8
  %696 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %692, i32 %4) #8
  %697 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %693, <4 x i32> %694) #8
  %698 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %695, <4 x i32> %696) #8
  %699 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %519, <8 x i16> %595) #8
  %700 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %519, <8 x i16> %595) #8
  %701 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %521, <8 x i16> %579) #8
  %702 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %521, <8 x i16> %579) #8
  %703 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %520, <8 x i16> %612) #8
  %704 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %520, <8 x i16> %612) #8
  %705 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %522, <8 x i16> %628) #8
  %706 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %522, <8 x i16> %628) #8
  %707 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %527, <8 x i16> %613) #8
  %708 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %527, <8 x i16> %613) #8
  %709 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %529, <8 x i16> %629) #8
  %710 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %529, <8 x i16> %629) #8
  %711 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %528, <8 x i16> %596) #8
  %712 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %528, <8 x i16> %596) #8
  %713 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %530, <8 x i16> %580) #8
  %714 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %530, <8 x i16> %580) #8
  %715 = shufflevector <8 x i16> %663, <8 x i16> %666, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %716 = shufflevector <8 x i16> %663, <8 x i16> %666, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %717 = bitcast <4 x i32> %56 to <8 x i16>
  %718 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %715, <8 x i16> %717) #8
  %719 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %716, <8 x i16> %717) #8
  %720 = bitcast <4 x i32> %62 to <8 x i16>
  %721 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %715, <8 x i16> %720) #8
  %722 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %716, <8 x i16> %720) #8
  %723 = add <4 x i32> %718, %10
  %724 = add <4 x i32> %719, %10
  %725 = add <4 x i32> %721, %10
  %726 = add <4 x i32> %722, %10
  %727 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %723, i32 %4) #8
  %728 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %724, i32 %4) #8
  %729 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %725, i32 %4) #8
  %730 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %726, i32 %4) #8
  %731 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %727, <4 x i32> %728) #8
  %732 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %729, <4 x i32> %730) #8
  %733 = shufflevector <8 x i16> %664, <8 x i16> %665, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %734 = shufflevector <8 x i16> %664, <8 x i16> %665, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %735 = bitcast <4 x i32> %71 to <8 x i16>
  %736 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %733, <8 x i16> %735) #8
  %737 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %734, <8 x i16> %735) #8
  %738 = bitcast <4 x i32> %77 to <8 x i16>
  %739 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %733, <8 x i16> %738) #8
  %740 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %734, <8 x i16> %738) #8
  %741 = add <4 x i32> %736, %10
  %742 = add <4 x i32> %737, %10
  %743 = add <4 x i32> %739, %10
  %744 = add <4 x i32> %740, %10
  %745 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %741, i32 %4) #8
  %746 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %742, i32 %4) #8
  %747 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %743, i32 %4) #8
  %748 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %744, i32 %4) #8
  %749 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %745, <4 x i32> %746) #8
  %750 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %747, <4 x i32> %748) #8
  %751 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %555, <8 x i16> %681) #8
  %752 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %555, <8 x i16> %681) #8
  %753 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %556, <8 x i16> %697) #8
  %754 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %556, <8 x i16> %697) #8
  %755 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %559, <8 x i16> %698) #8
  %756 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %559, <8 x i16> %698) #8
  %757 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %560, <8 x i16> %682) #8
  %758 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %560, <8 x i16> %682) #8
  %759 = shufflevector <8 x i16> %701, <8 x i16> %714, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %760 = shufflevector <8 x i16> %701, <8 x i16> %714, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %761 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %759, <8 x i16> %720) #8
  %762 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %760, <8 x i16> %720) #8
  %763 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %759, <8 x i16> %717) #8
  %764 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %760, <8 x i16> %717) #8
  %765 = add <4 x i32> %761, %10
  %766 = add <4 x i32> %762, %10
  %767 = add <4 x i32> %763, %10
  %768 = add <4 x i32> %764, %10
  %769 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %765, i32 %4) #8
  %770 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %766, i32 %4) #8
  %771 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %767, i32 %4) #8
  %772 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %768, i32 %4) #8
  %773 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %769, <4 x i32> %770) #8
  %774 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %771, <4 x i32> %772) #8
  %775 = shufflevector <8 x i16> %702, <8 x i16> %713, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %776 = shufflevector <8 x i16> %702, <8 x i16> %713, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %777 = bitcast <4 x i32> %83 to <8 x i16>
  %778 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %775, <8 x i16> %777) #8
  %779 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %776, <8 x i16> %777) #8
  %780 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %775, <8 x i16> %720) #8
  %781 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %776, <8 x i16> %720) #8
  %782 = add <4 x i32> %778, %10
  %783 = add <4 x i32> %779, %10
  %784 = add <4 x i32> %780, %10
  %785 = add <4 x i32> %781, %10
  %786 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %782, i32 %4) #8
  %787 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %783, i32 %4) #8
  %788 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %784, i32 %4) #8
  %789 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %785, i32 %4) #8
  %790 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %786, <4 x i32> %787) #8
  %791 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %788, <4 x i32> %789) #8
  %792 = shufflevector <8 x i16> %705, <8 x i16> %710, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %793 = shufflevector <8 x i16> %705, <8 x i16> %710, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %794 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %792, <8 x i16> %738) #8
  %795 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %793, <8 x i16> %738) #8
  %796 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %792, <8 x i16> %735) #8
  %797 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %793, <8 x i16> %735) #8
  %798 = add <4 x i32> %794, %10
  %799 = add <4 x i32> %795, %10
  %800 = add <4 x i32> %796, %10
  %801 = add <4 x i32> %797, %10
  %802 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %798, i32 %4) #8
  %803 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %799, i32 %4) #8
  %804 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %800, i32 %4) #8
  %805 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %801, i32 %4) #8
  %806 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %802, <4 x i32> %803) #8
  %807 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %804, <4 x i32> %805) #8
  %808 = shufflevector <8 x i16> %706, <8 x i16> %709, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %809 = shufflevector <8 x i16> %706, <8 x i16> %709, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %810 = bitcast <4 x i32> %89 to <8 x i16>
  %811 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %808, <8 x i16> %810) #8
  %812 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %809, <8 x i16> %810) #8
  %813 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %808, <8 x i16> %738) #8
  %814 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %809, <8 x i16> %738) #8
  %815 = add <4 x i32> %811, %10
  %816 = add <4 x i32> %812, %10
  %817 = add <4 x i32> %813, %10
  %818 = add <4 x i32> %814, %10
  %819 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %815, i32 %4) #8
  %820 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %816, i32 %4) #8
  %821 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %817, i32 %4) #8
  %822 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %818, i32 %4) #8
  %823 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %819, <4 x i32> %820) #8
  %824 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %821, <4 x i32> %822) #8
  %825 = shufflevector <8 x i16> %751, <8 x i16> %758, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %826 = shufflevector <8 x i16> %751, <8 x i16> %758, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %827 = bitcast <4 x i32> %98 to <8 x i16>
  %828 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %825, <8 x i16> %827) #8
  %829 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %826, <8 x i16> %827) #8
  %830 = bitcast <4 x i32> %104 to <8 x i16>
  %831 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %825, <8 x i16> %830) #8
  %832 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %826, <8 x i16> %830) #8
  %833 = add <4 x i32> %828, %10
  %834 = add <4 x i32> %829, %10
  %835 = add <4 x i32> %831, %10
  %836 = add <4 x i32> %832, %10
  %837 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %833, i32 %4) #8
  %838 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %834, i32 %4) #8
  %839 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %835, i32 %4) #8
  %840 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %836, i32 %4) #8
  %841 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %837, <4 x i32> %838) #8
  %842 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %839, <4 x i32> %840) #8
  %843 = shufflevector <8 x i16> %752, <8 x i16> %757, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %844 = shufflevector <8 x i16> %752, <8 x i16> %757, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %845 = bitcast <4 x i32> %113 to <8 x i16>
  %846 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %843, <8 x i16> %845) #8
  %847 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %844, <8 x i16> %845) #8
  %848 = bitcast <4 x i32> %119 to <8 x i16>
  %849 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %843, <8 x i16> %848) #8
  %850 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %844, <8 x i16> %848) #8
  %851 = add <4 x i32> %846, %10
  %852 = add <4 x i32> %847, %10
  %853 = add <4 x i32> %849, %10
  %854 = add <4 x i32> %850, %10
  %855 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %851, i32 %4) #8
  %856 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %852, i32 %4) #8
  %857 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %853, i32 %4) #8
  %858 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %854, i32 %4) #8
  %859 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %855, <4 x i32> %856) #8
  %860 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %857, <4 x i32> %858) #8
  %861 = shufflevector <8 x i16> %753, <8 x i16> %756, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %862 = shufflevector <8 x i16> %753, <8 x i16> %756, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %863 = bitcast <4 x i32> %128 to <8 x i16>
  %864 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %861, <8 x i16> %863) #8
  %865 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %862, <8 x i16> %863) #8
  %866 = bitcast <4 x i32> %134 to <8 x i16>
  %867 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %861, <8 x i16> %866) #8
  %868 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %862, <8 x i16> %866) #8
  %869 = add <4 x i32> %864, %10
  %870 = add <4 x i32> %865, %10
  %871 = add <4 x i32> %867, %10
  %872 = add <4 x i32> %868, %10
  %873 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %869, i32 %4) #8
  %874 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %870, i32 %4) #8
  %875 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %871, i32 %4) #8
  %876 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %872, i32 %4) #8
  %877 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %873, <4 x i32> %874) #8
  %878 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %875, <4 x i32> %876) #8
  %879 = shufflevector <8 x i16> %754, <8 x i16> %755, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %880 = shufflevector <8 x i16> %754, <8 x i16> %755, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %881 = bitcast <4 x i32> %143 to <8 x i16>
  %882 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %879, <8 x i16> %881) #8
  %883 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %880, <8 x i16> %881) #8
  %884 = bitcast <4 x i32> %149 to <8 x i16>
  %885 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %879, <8 x i16> %884) #8
  %886 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %880, <8 x i16> %884) #8
  %887 = add <4 x i32> %882, %10
  %888 = add <4 x i32> %883, %10
  %889 = add <4 x i32> %885, %10
  %890 = add <4 x i32> %886, %10
  %891 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %887, i32 %4) #8
  %892 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %888, i32 %4) #8
  %893 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %889, i32 %4) #8
  %894 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %890, i32 %4) #8
  %895 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %891, <4 x i32> %892) #8
  %896 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %893, <4 x i32> %894) #8
  %897 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %699, <8 x i16> %773) #8
  %898 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %699, <8 x i16> %773) #8
  %899 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %700, <8 x i16> %790) #8
  %900 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %700, <8 x i16> %790) #8
  %901 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %703, <8 x i16> %806) #8
  %902 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %703, <8 x i16> %806) #8
  %903 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %704, <8 x i16> %823) #8
  %904 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %704, <8 x i16> %823) #8
  %905 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %707, <8 x i16> %824) #8
  %906 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %707, <8 x i16> %824) #8
  %907 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %708, <8 x i16> %807) #8
  %908 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %708, <8 x i16> %807) #8
  %909 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %711, <8 x i16> %791) #8
  %910 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %711, <8 x i16> %791) #8
  %911 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %712, <8 x i16> %774) #8
  %912 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %712, <8 x i16> %774) #8
  %913 = shufflevector <8 x i16> %897, <8 x i16> %912, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %914 = shufflevector <8 x i16> %897, <8 x i16> %912, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %915 = bitcast <4 x i32> %158 to <8 x i16>
  %916 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %913, <8 x i16> %915) #8
  %917 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %914, <8 x i16> %915) #8
  %918 = bitcast <4 x i32> %164 to <8 x i16>
  %919 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %913, <8 x i16> %918) #8
  %920 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %914, <8 x i16> %918) #8
  %921 = add <4 x i32> %916, %10
  %922 = add <4 x i32> %917, %10
  %923 = add <4 x i32> %919, %10
  %924 = add <4 x i32> %920, %10
  %925 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %921, i32 %4) #8
  %926 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %922, i32 %4) #8
  %927 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %923, i32 %4) #8
  %928 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %924, i32 %4) #8
  %929 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %925, <4 x i32> %926) #8
  %930 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %927, <4 x i32> %928) #8
  %931 = shufflevector <8 x i16> %898, <8 x i16> %911, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %932 = shufflevector <8 x i16> %898, <8 x i16> %911, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %933 = bitcast <4 x i32> %173 to <8 x i16>
  %934 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %931, <8 x i16> %933) #8
  %935 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %932, <8 x i16> %933) #8
  %936 = bitcast <4 x i32> %179 to <8 x i16>
  %937 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %931, <8 x i16> %936) #8
  %938 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %932, <8 x i16> %936) #8
  %939 = add <4 x i32> %934, %10
  %940 = add <4 x i32> %935, %10
  %941 = add <4 x i32> %937, %10
  %942 = add <4 x i32> %938, %10
  %943 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %939, i32 %4) #8
  %944 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %940, i32 %4) #8
  %945 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %941, i32 %4) #8
  %946 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %942, i32 %4) #8
  %947 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %943, <4 x i32> %944) #8
  %948 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %945, <4 x i32> %946) #8
  %949 = shufflevector <8 x i16> %899, <8 x i16> %910, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %950 = shufflevector <8 x i16> %899, <8 x i16> %910, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %951 = bitcast <4 x i32> %188 to <8 x i16>
  %952 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %949, <8 x i16> %951) #8
  %953 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %950, <8 x i16> %951) #8
  %954 = bitcast <4 x i32> %194 to <8 x i16>
  %955 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %949, <8 x i16> %954) #8
  %956 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %950, <8 x i16> %954) #8
  %957 = add <4 x i32> %952, %10
  %958 = add <4 x i32> %953, %10
  %959 = add <4 x i32> %955, %10
  %960 = add <4 x i32> %956, %10
  %961 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %957, i32 %4) #8
  %962 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %958, i32 %4) #8
  %963 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %959, i32 %4) #8
  %964 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %960, i32 %4) #8
  %965 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %961, <4 x i32> %962) #8
  %966 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %963, <4 x i32> %964) #8
  %967 = shufflevector <8 x i16> %900, <8 x i16> %909, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %968 = shufflevector <8 x i16> %900, <8 x i16> %909, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %969 = bitcast <4 x i32> %203 to <8 x i16>
  %970 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %967, <8 x i16> %969) #8
  %971 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %968, <8 x i16> %969) #8
  %972 = bitcast <4 x i32> %209 to <8 x i16>
  %973 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %967, <8 x i16> %972) #8
  %974 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %968, <8 x i16> %972) #8
  %975 = add <4 x i32> %970, %10
  %976 = add <4 x i32> %971, %10
  %977 = add <4 x i32> %973, %10
  %978 = add <4 x i32> %974, %10
  %979 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %975, i32 %4) #8
  %980 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %976, i32 %4) #8
  %981 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %977, i32 %4) #8
  %982 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %978, i32 %4) #8
  %983 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %979, <4 x i32> %980) #8
  %984 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %981, <4 x i32> %982) #8
  %985 = shufflevector <8 x i16> %901, <8 x i16> %908, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %986 = shufflevector <8 x i16> %901, <8 x i16> %908, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %987 = bitcast <4 x i32> %218 to <8 x i16>
  %988 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %985, <8 x i16> %987) #8
  %989 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %986, <8 x i16> %987) #8
  %990 = bitcast <4 x i32> %224 to <8 x i16>
  %991 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %985, <8 x i16> %990) #8
  %992 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %986, <8 x i16> %990) #8
  %993 = add <4 x i32> %988, %10
  %994 = add <4 x i32> %989, %10
  %995 = add <4 x i32> %991, %10
  %996 = add <4 x i32> %992, %10
  %997 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %993, i32 %4) #8
  %998 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %994, i32 %4) #8
  %999 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %995, i32 %4) #8
  %1000 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %996, i32 %4) #8
  %1001 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %997, <4 x i32> %998) #8
  %1002 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %999, <4 x i32> %1000) #8
  %1003 = shufflevector <8 x i16> %902, <8 x i16> %907, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1004 = shufflevector <8 x i16> %902, <8 x i16> %907, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1005 = bitcast <4 x i32> %233 to <8 x i16>
  %1006 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1003, <8 x i16> %1005) #8
  %1007 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1004, <8 x i16> %1005) #8
  %1008 = bitcast <4 x i32> %239 to <8 x i16>
  %1009 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1003, <8 x i16> %1008) #8
  %1010 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1004, <8 x i16> %1008) #8
  %1011 = add <4 x i32> %1006, %10
  %1012 = add <4 x i32> %1007, %10
  %1013 = add <4 x i32> %1009, %10
  %1014 = add <4 x i32> %1010, %10
  %1015 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1011, i32 %4) #8
  %1016 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1012, i32 %4) #8
  %1017 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1013, i32 %4) #8
  %1018 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1014, i32 %4) #8
  %1019 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1015, <4 x i32> %1016) #8
  %1020 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1017, <4 x i32> %1018) #8
  %1021 = shufflevector <8 x i16> %903, <8 x i16> %906, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1022 = shufflevector <8 x i16> %903, <8 x i16> %906, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1023 = bitcast <4 x i32> %248 to <8 x i16>
  %1024 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1021, <8 x i16> %1023) #8
  %1025 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1022, <8 x i16> %1023) #8
  %1026 = bitcast <4 x i32> %254 to <8 x i16>
  %1027 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1021, <8 x i16> %1026) #8
  %1028 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1022, <8 x i16> %1026) #8
  %1029 = add <4 x i32> %1024, %10
  %1030 = add <4 x i32> %1025, %10
  %1031 = add <4 x i32> %1027, %10
  %1032 = add <4 x i32> %1028, %10
  %1033 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1029, i32 %4) #8
  %1034 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1030, i32 %4) #8
  %1035 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1031, i32 %4) #8
  %1036 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1032, i32 %4) #8
  %1037 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1033, <4 x i32> %1034) #8
  %1038 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1035, <4 x i32> %1036) #8
  %1039 = shufflevector <8 x i16> %904, <8 x i16> %905, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1040 = shufflevector <8 x i16> %904, <8 x i16> %905, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1041 = bitcast <4 x i32> %263 to <8 x i16>
  %1042 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1039, <8 x i16> %1041) #8
  %1043 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1040, <8 x i16> %1041) #8
  %1044 = bitcast <4 x i32> %269 to <8 x i16>
  %1045 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1039, <8 x i16> %1044) #8
  %1046 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1040, <8 x i16> %1044) #8
  %1047 = add <4 x i32> %1042, %10
  %1048 = add <4 x i32> %1043, %10
  %1049 = add <4 x i32> %1045, %10
  %1050 = add <4 x i32> %1046, %10
  %1051 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1047, i32 %4) #8
  %1052 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1048, i32 %4) #8
  %1053 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1049, i32 %4) #8
  %1054 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1050, i32 %4) #8
  %1055 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1051, <4 x i32> %1052) #8
  %1056 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1053, <4 x i32> %1054) #8
  %1057 = bitcast <2 x i64>* %1 to <8 x i16>*
  store <8 x i16> %645, <8 x i16>* %1057, align 16
  %1058 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %1059 = bitcast <2 x i64>* %1058 to <8 x i16>*
  store <8 x i16> %929, <8 x i16>* %1059, align 16
  %1060 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %1061 = bitcast <2 x i64>* %1060 to <8 x i16>*
  store <8 x i16> %841, <8 x i16>* %1061, align 16
  %1062 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %1063 = bitcast <2 x i64>* %1062 to <8 x i16>*
  store <8 x i16> %1056, <8 x i16>* %1063, align 16
  %1064 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %1065 = bitcast <2 x i64>* %1064 to <8 x i16>*
  store <8 x i16> %731, <8 x i16>* %1065, align 16
  %1066 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %1067 = bitcast <2 x i64>* %1066 to <8 x i16>*
  store <8 x i16> %1001, <8 x i16>* %1067, align 16
  %1068 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %1069 = bitcast <2 x i64>* %1068 to <8 x i16>*
  store <8 x i16> %896, <8 x i16>* %1069, align 16
  %1070 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %1071 = bitcast <2 x i64>* %1070 to <8 x i16>*
  store <8 x i16> %984, <8 x i16>* %1071, align 16
  %1072 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 8
  %1073 = bitcast <2 x i64>* %1072 to <8 x i16>*
  store <8 x i16> %661, <8 x i16>* %1073, align 16
  %1074 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 9
  %1075 = bitcast <2 x i64>* %1074 to <8 x i16>*
  store <8 x i16> %965, <8 x i16>* %1075, align 16
  %1076 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 10
  %1077 = bitcast <2 x i64>* %1076 to <8 x i16>*
  store <8 x i16> %877, <8 x i16>* %1077, align 16
  %1078 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 11
  %1079 = bitcast <2 x i64>* %1078 to <8 x i16>*
  store <8 x i16> %1020, <8 x i16>* %1079, align 16
  %1080 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 12
  %1081 = bitcast <2 x i64>* %1080 to <8 x i16>*
  store <8 x i16> %750, <8 x i16>* %1081, align 16
  %1082 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 13
  %1083 = bitcast <2 x i64>* %1082 to <8 x i16>*
  store <8 x i16> %1037, <8 x i16>* %1083, align 16
  %1084 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 14
  %1085 = bitcast <2 x i64>* %1084 to <8 x i16>*
  store <8 x i16> %860, <8 x i16>* %1085, align 16
  %1086 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 15
  %1087 = bitcast <2 x i64>* %1086 to <8 x i16>*
  store <8 x i16> %948, <8 x i16>* %1087, align 16
  %1088 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 16
  %1089 = bitcast <2 x i64>* %1088 to <8 x i16>*
  store <8 x i16> %646, <8 x i16>* %1089, align 16
  %1090 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 17
  %1091 = bitcast <2 x i64>* %1090 to <8 x i16>*
  store <8 x i16> %947, <8 x i16>* %1091, align 16
  %1092 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 18
  %1093 = bitcast <2 x i64>* %1092 to <8 x i16>*
  store <8 x i16> %859, <8 x i16>* %1093, align 16
  %1094 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 19
  %1095 = bitcast <2 x i64>* %1094 to <8 x i16>*
  store <8 x i16> %1038, <8 x i16>* %1095, align 16
  %1096 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 20
  %1097 = bitcast <2 x i64>* %1096 to <8 x i16>*
  store <8 x i16> %749, <8 x i16>* %1097, align 16
  %1098 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 21
  %1099 = bitcast <2 x i64>* %1098 to <8 x i16>*
  store <8 x i16> %1019, <8 x i16>* %1099, align 16
  %1100 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 22
  %1101 = bitcast <2 x i64>* %1100 to <8 x i16>*
  store <8 x i16> %878, <8 x i16>* %1101, align 16
  %1102 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 23
  %1103 = bitcast <2 x i64>* %1102 to <8 x i16>*
  store <8 x i16> %966, <8 x i16>* %1103, align 16
  %1104 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 24
  %1105 = bitcast <2 x i64>* %1104 to <8 x i16>*
  store <8 x i16> %662, <8 x i16>* %1105, align 16
  %1106 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 25
  %1107 = bitcast <2 x i64>* %1106 to <8 x i16>*
  store <8 x i16> %983, <8 x i16>* %1107, align 16
  %1108 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 26
  %1109 = bitcast <2 x i64>* %1108 to <8 x i16>*
  store <8 x i16> %895, <8 x i16>* %1109, align 16
  %1110 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 27
  %1111 = bitcast <2 x i64>* %1110 to <8 x i16>*
  store <8 x i16> %1002, <8 x i16>* %1111, align 16
  %1112 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 28
  %1113 = bitcast <2 x i64>* %1112 to <8 x i16>*
  store <8 x i16> %732, <8 x i16>* %1113, align 16
  %1114 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 29
  %1115 = bitcast <2 x i64>* %1114 to <8 x i16>*
  store <8 x i16> %1055, <8 x i16>* %1115, align 16
  %1116 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 30
  %1117 = bitcast <2 x i64>* %1116 to <8 x i16>*
  store <8 x i16> %842, <8 x i16>* %1117, align 16
  %1118 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 31
  %1119 = bitcast <2 x i64>* %1118 to <8 x i16>*
  store <8 x i16> %930, <8 x i16>* %1119, align 16
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #1

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: nofree nounwind ssp uwtable
define hidden void @av1_fdct8x64_new_sse2(<2 x i64>* readonly, <2 x i64>*, i8 signext) local_unnamed_addr #0 {
  %4 = sext i8 %2 to i32
  %5 = add nsw i32 %4, -10
  %6 = sext i32 %5 to i64
  %7 = add nsw i32 %4, -1
  %8 = shl i32 1, %7
  %9 = insertelement <4 x i32> undef, i32 %8, i32 0
  %10 = shufflevector <4 x i32> %9, <4 x i32> undef, <4 x i32> zeroinitializer
  %11 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 32
  %12 = load i32, i32* %11, align 16
  %13 = sub i32 0, %12
  %14 = and i32 %13, 65535
  %15 = shl i32 %12, 16
  %16 = or i32 %14, %15
  %17 = insertelement <4 x i32> undef, i32 %16, i32 0
  %18 = shufflevector <4 x i32> %17, <4 x i32> undef, <4 x i32> zeroinitializer
  %19 = and i32 %12, 65535
  %20 = or i32 %19, %15
  %21 = insertelement <4 x i32> undef, i32 %20, i32 0
  %22 = shufflevector <4 x i32> %21, <4 x i32> undef, <4 x i32> zeroinitializer
  %23 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 16
  %24 = load i32, i32* %23, align 16
  %25 = sub i32 0, %24
  %26 = and i32 %25, 65535
  %27 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 48
  %28 = load i32, i32* %27, align 16
  %29 = shl i32 %28, 16
  %30 = or i32 %29, %26
  %31 = insertelement <4 x i32> undef, i32 %30, i32 0
  %32 = shufflevector <4 x i32> %31, <4 x i32> undef, <4 x i32> zeroinitializer
  %33 = and i32 %28, 65535
  %34 = shl i32 %24, 16
  %35 = or i32 %33, %34
  %36 = insertelement <4 x i32> undef, i32 %35, i32 0
  %37 = shufflevector <4 x i32> %36, <4 x i32> undef, <4 x i32> zeroinitializer
  %38 = sub i32 0, %28
  %39 = and i32 %38, 65535
  %40 = sub i32 0, %34
  %41 = or i32 %39, %40
  %42 = insertelement <4 x i32> undef, i32 %41, i32 0
  %43 = shufflevector <4 x i32> %42, <4 x i32> undef, <4 x i32> zeroinitializer
  %44 = sub i32 0, %15
  %45 = or i32 %19, %44
  %46 = insertelement <4 x i32> undef, i32 %45, i32 0
  %47 = shufflevector <4 x i32> %46, <4 x i32> undef, <4 x i32> zeroinitializer
  %48 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 8
  %49 = load i32, i32* %48, align 16
  %50 = sub i32 0, %49
  %51 = and i32 %50, 65535
  %52 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 56
  %53 = load i32, i32* %52, align 16
  %54 = shl i32 %53, 16
  %55 = or i32 %54, %51
  %56 = insertelement <4 x i32> undef, i32 %55, i32 0
  %57 = shufflevector <4 x i32> %56, <4 x i32> undef, <4 x i32> zeroinitializer
  %58 = and i32 %53, 65535
  %59 = shl i32 %49, 16
  %60 = or i32 %58, %59
  %61 = insertelement <4 x i32> undef, i32 %60, i32 0
  %62 = shufflevector <4 x i32> %61, <4 x i32> undef, <4 x i32> zeroinitializer
  %63 = sub i32 0, %53
  %64 = and i32 %63, 65535
  %65 = sub i32 0, %59
  %66 = or i32 %64, %65
  %67 = insertelement <4 x i32> undef, i32 %66, i32 0
  %68 = shufflevector <4 x i32> %67, <4 x i32> undef, <4 x i32> zeroinitializer
  %69 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 40
  %70 = load i32, i32* %69, align 16
  %71 = sub i32 0, %70
  %72 = and i32 %71, 65535
  %73 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 24
  %74 = load i32, i32* %73, align 16
  %75 = shl i32 %74, 16
  %76 = or i32 %75, %72
  %77 = insertelement <4 x i32> undef, i32 %76, i32 0
  %78 = shufflevector <4 x i32> %77, <4 x i32> undef, <4 x i32> zeroinitializer
  %79 = and i32 %74, 65535
  %80 = shl i32 %70, 16
  %81 = or i32 %79, %80
  %82 = insertelement <4 x i32> undef, i32 %81, i32 0
  %83 = shufflevector <4 x i32> %82, <4 x i32> undef, <4 x i32> zeroinitializer
  %84 = sub i32 0, %74
  %85 = and i32 %84, 65535
  %86 = sub i32 0, %80
  %87 = or i32 %85, %86
  %88 = insertelement <4 x i32> undef, i32 %87, i32 0
  %89 = shufflevector <4 x i32> %88, <4 x i32> undef, <4 x i32> zeroinitializer
  %90 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 60
  %91 = load i32, i32* %90, align 16
  %92 = and i32 %91, 65535
  %93 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 4
  %94 = load i32, i32* %93, align 16
  %95 = shl i32 %94, 16
  %96 = or i32 %95, %92
  %97 = insertelement <4 x i32> undef, i32 %96, i32 0
  %98 = shufflevector <4 x i32> %97, <4 x i32> undef, <4 x i32> zeroinitializer
  %99 = sub i32 0, %94
  %100 = and i32 %99, 65535
  %101 = shl i32 %91, 16
  %102 = or i32 %100, %101
  %103 = insertelement <4 x i32> undef, i32 %102, i32 0
  %104 = shufflevector <4 x i32> %103, <4 x i32> undef, <4 x i32> zeroinitializer
  %105 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 28
  %106 = load i32, i32* %105, align 16
  %107 = and i32 %106, 65535
  %108 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 36
  %109 = load i32, i32* %108, align 16
  %110 = shl i32 %109, 16
  %111 = or i32 %110, %107
  %112 = insertelement <4 x i32> undef, i32 %111, i32 0
  %113 = shufflevector <4 x i32> %112, <4 x i32> undef, <4 x i32> zeroinitializer
  %114 = sub i32 0, %109
  %115 = and i32 %114, 65535
  %116 = shl i32 %106, 16
  %117 = or i32 %115, %116
  %118 = insertelement <4 x i32> undef, i32 %117, i32 0
  %119 = shufflevector <4 x i32> %118, <4 x i32> undef, <4 x i32> zeroinitializer
  %120 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 44
  %121 = load i32, i32* %120, align 16
  %122 = and i32 %121, 65535
  %123 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 20
  %124 = load i32, i32* %123, align 16
  %125 = shl i32 %124, 16
  %126 = or i32 %125, %122
  %127 = insertelement <4 x i32> undef, i32 %126, i32 0
  %128 = shufflevector <4 x i32> %127, <4 x i32> undef, <4 x i32> zeroinitializer
  %129 = sub i32 0, %124
  %130 = and i32 %129, 65535
  %131 = shl i32 %121, 16
  %132 = or i32 %130, %131
  %133 = insertelement <4 x i32> undef, i32 %132, i32 0
  %134 = shufflevector <4 x i32> %133, <4 x i32> undef, <4 x i32> zeroinitializer
  %135 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 12
  %136 = load i32, i32* %135, align 16
  %137 = and i32 %136, 65535
  %138 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 52
  %139 = load i32, i32* %138, align 16
  %140 = shl i32 %139, 16
  %141 = or i32 %140, %137
  %142 = insertelement <4 x i32> undef, i32 %141, i32 0
  %143 = shufflevector <4 x i32> %142, <4 x i32> undef, <4 x i32> zeroinitializer
  %144 = sub i32 0, %139
  %145 = and i32 %144, 65535
  %146 = shl i32 %136, 16
  %147 = or i32 %145, %146
  %148 = insertelement <4 x i32> undef, i32 %147, i32 0
  %149 = shufflevector <4 x i32> %148, <4 x i32> undef, <4 x i32> zeroinitializer
  %150 = sub i32 0, %91
  %151 = and i32 %150, 65535
  %152 = sub i32 0, %95
  %153 = or i32 %151, %152
  %154 = insertelement <4 x i32> undef, i32 %153, i32 0
  %155 = shufflevector <4 x i32> %154, <4 x i32> undef, <4 x i32> zeroinitializer
  %156 = sub i32 0, %106
  %157 = and i32 %156, 65535
  %158 = sub i32 0, %110
  %159 = or i32 %157, %158
  %160 = insertelement <4 x i32> undef, i32 %159, i32 0
  %161 = shufflevector <4 x i32> %160, <4 x i32> undef, <4 x i32> zeroinitializer
  %162 = sub i32 0, %121
  %163 = and i32 %162, 65535
  %164 = sub i32 0, %125
  %165 = or i32 %163, %164
  %166 = insertelement <4 x i32> undef, i32 %165, i32 0
  %167 = shufflevector <4 x i32> %166, <4 x i32> undef, <4 x i32> zeroinitializer
  %168 = sub i32 0, %136
  %169 = and i32 %168, 65535
  %170 = sub i32 0, %140
  %171 = or i32 %169, %170
  %172 = insertelement <4 x i32> undef, i32 %171, i32 0
  %173 = shufflevector <4 x i32> %172, <4 x i32> undef, <4 x i32> zeroinitializer
  %174 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 62
  %175 = load i32, i32* %174, align 8
  %176 = and i32 %175, 65535
  %177 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 2
  %178 = load i32, i32* %177, align 8
  %179 = shl i32 %178, 16
  %180 = or i32 %179, %176
  %181 = insertelement <4 x i32> undef, i32 %180, i32 0
  %182 = shufflevector <4 x i32> %181, <4 x i32> undef, <4 x i32> zeroinitializer
  %183 = sub i32 0, %178
  %184 = and i32 %183, 65535
  %185 = shl i32 %175, 16
  %186 = or i32 %184, %185
  %187 = insertelement <4 x i32> undef, i32 %186, i32 0
  %188 = shufflevector <4 x i32> %187, <4 x i32> undef, <4 x i32> zeroinitializer
  %189 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 30
  %190 = load i32, i32* %189, align 8
  %191 = and i32 %190, 65535
  %192 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 34
  %193 = load i32, i32* %192, align 8
  %194 = shl i32 %193, 16
  %195 = or i32 %194, %191
  %196 = insertelement <4 x i32> undef, i32 %195, i32 0
  %197 = shufflevector <4 x i32> %196, <4 x i32> undef, <4 x i32> zeroinitializer
  %198 = sub i32 0, %193
  %199 = and i32 %198, 65535
  %200 = shl i32 %190, 16
  %201 = or i32 %199, %200
  %202 = insertelement <4 x i32> undef, i32 %201, i32 0
  %203 = shufflevector <4 x i32> %202, <4 x i32> undef, <4 x i32> zeroinitializer
  %204 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 46
  %205 = load i32, i32* %204, align 8
  %206 = and i32 %205, 65535
  %207 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 18
  %208 = load i32, i32* %207, align 8
  %209 = shl i32 %208, 16
  %210 = or i32 %209, %206
  %211 = insertelement <4 x i32> undef, i32 %210, i32 0
  %212 = shufflevector <4 x i32> %211, <4 x i32> undef, <4 x i32> zeroinitializer
  %213 = sub i32 0, %208
  %214 = and i32 %213, 65535
  %215 = shl i32 %205, 16
  %216 = or i32 %214, %215
  %217 = insertelement <4 x i32> undef, i32 %216, i32 0
  %218 = shufflevector <4 x i32> %217, <4 x i32> undef, <4 x i32> zeroinitializer
  %219 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 14
  %220 = load i32, i32* %219, align 8
  %221 = and i32 %220, 65535
  %222 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 50
  %223 = load i32, i32* %222, align 8
  %224 = shl i32 %223, 16
  %225 = or i32 %224, %221
  %226 = insertelement <4 x i32> undef, i32 %225, i32 0
  %227 = shufflevector <4 x i32> %226, <4 x i32> undef, <4 x i32> zeroinitializer
  %228 = sub i32 0, %223
  %229 = and i32 %228, 65535
  %230 = shl i32 %220, 16
  %231 = or i32 %229, %230
  %232 = insertelement <4 x i32> undef, i32 %231, i32 0
  %233 = shufflevector <4 x i32> %232, <4 x i32> undef, <4 x i32> zeroinitializer
  %234 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 54
  %235 = load i32, i32* %234, align 8
  %236 = and i32 %235, 65535
  %237 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 10
  %238 = load i32, i32* %237, align 8
  %239 = shl i32 %238, 16
  %240 = or i32 %239, %236
  %241 = insertelement <4 x i32> undef, i32 %240, i32 0
  %242 = shufflevector <4 x i32> %241, <4 x i32> undef, <4 x i32> zeroinitializer
  %243 = sub i32 0, %238
  %244 = and i32 %243, 65535
  %245 = shl i32 %235, 16
  %246 = or i32 %244, %245
  %247 = insertelement <4 x i32> undef, i32 %246, i32 0
  %248 = shufflevector <4 x i32> %247, <4 x i32> undef, <4 x i32> zeroinitializer
  %249 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 22
  %250 = load i32, i32* %249, align 8
  %251 = and i32 %250, 65535
  %252 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 42
  %253 = load i32, i32* %252, align 8
  %254 = shl i32 %253, 16
  %255 = or i32 %254, %251
  %256 = insertelement <4 x i32> undef, i32 %255, i32 0
  %257 = shufflevector <4 x i32> %256, <4 x i32> undef, <4 x i32> zeroinitializer
  %258 = sub i32 0, %253
  %259 = and i32 %258, 65535
  %260 = shl i32 %250, 16
  %261 = or i32 %259, %260
  %262 = insertelement <4 x i32> undef, i32 %261, i32 0
  %263 = shufflevector <4 x i32> %262, <4 x i32> undef, <4 x i32> zeroinitializer
  %264 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 38
  %265 = load i32, i32* %264, align 8
  %266 = and i32 %265, 65535
  %267 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 26
  %268 = load i32, i32* %267, align 8
  %269 = shl i32 %268, 16
  %270 = or i32 %269, %266
  %271 = insertelement <4 x i32> undef, i32 %270, i32 0
  %272 = shufflevector <4 x i32> %271, <4 x i32> undef, <4 x i32> zeroinitializer
  %273 = sub i32 0, %268
  %274 = and i32 %273, 65535
  %275 = shl i32 %265, 16
  %276 = or i32 %274, %275
  %277 = insertelement <4 x i32> undef, i32 %276, i32 0
  %278 = shufflevector <4 x i32> %277, <4 x i32> undef, <4 x i32> zeroinitializer
  %279 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 6
  %280 = load i32, i32* %279, align 8
  %281 = and i32 %280, 65535
  %282 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 58
  %283 = load i32, i32* %282, align 8
  %284 = shl i32 %283, 16
  %285 = or i32 %284, %281
  %286 = insertelement <4 x i32> undef, i32 %285, i32 0
  %287 = shufflevector <4 x i32> %286, <4 x i32> undef, <4 x i32> zeroinitializer
  %288 = sub i32 0, %283
  %289 = and i32 %288, 65535
  %290 = shl i32 %280, 16
  %291 = or i32 %289, %290
  %292 = insertelement <4 x i32> undef, i32 %291, i32 0
  %293 = shufflevector <4 x i32> %292, <4 x i32> undef, <4 x i32> zeroinitializer
  %294 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 63
  %295 = load i32, i32* %294, align 4
  %296 = and i32 %295, 65535
  %297 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 1
  %298 = load i32, i32* %297, align 4
  %299 = shl i32 %298, 16
  %300 = or i32 %299, %296
  %301 = insertelement <4 x i32> undef, i32 %300, i32 0
  %302 = shufflevector <4 x i32> %301, <4 x i32> undef, <4 x i32> zeroinitializer
  %303 = sub i32 0, %298
  %304 = and i32 %303, 65535
  %305 = shl i32 %295, 16
  %306 = or i32 %304, %305
  %307 = insertelement <4 x i32> undef, i32 %306, i32 0
  %308 = shufflevector <4 x i32> %307, <4 x i32> undef, <4 x i32> zeroinitializer
  %309 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 31
  %310 = load i32, i32* %309, align 4
  %311 = and i32 %310, 65535
  %312 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 33
  %313 = load i32, i32* %312, align 4
  %314 = shl i32 %313, 16
  %315 = or i32 %314, %311
  %316 = insertelement <4 x i32> undef, i32 %315, i32 0
  %317 = shufflevector <4 x i32> %316, <4 x i32> undef, <4 x i32> zeroinitializer
  %318 = sub i32 0, %313
  %319 = and i32 %318, 65535
  %320 = shl i32 %310, 16
  %321 = or i32 %319, %320
  %322 = insertelement <4 x i32> undef, i32 %321, i32 0
  %323 = shufflevector <4 x i32> %322, <4 x i32> undef, <4 x i32> zeroinitializer
  %324 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 47
  %325 = load i32, i32* %324, align 4
  %326 = and i32 %325, 65535
  %327 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 17
  %328 = load i32, i32* %327, align 4
  %329 = shl i32 %328, 16
  %330 = or i32 %329, %326
  %331 = insertelement <4 x i32> undef, i32 %330, i32 0
  %332 = shufflevector <4 x i32> %331, <4 x i32> undef, <4 x i32> zeroinitializer
  %333 = sub i32 0, %328
  %334 = and i32 %333, 65535
  %335 = shl i32 %325, 16
  %336 = or i32 %334, %335
  %337 = insertelement <4 x i32> undef, i32 %336, i32 0
  %338 = shufflevector <4 x i32> %337, <4 x i32> undef, <4 x i32> zeroinitializer
  %339 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 15
  %340 = load i32, i32* %339, align 4
  %341 = and i32 %340, 65535
  %342 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 49
  %343 = load i32, i32* %342, align 4
  %344 = shl i32 %343, 16
  %345 = or i32 %344, %341
  %346 = insertelement <4 x i32> undef, i32 %345, i32 0
  %347 = shufflevector <4 x i32> %346, <4 x i32> undef, <4 x i32> zeroinitializer
  %348 = sub i32 0, %343
  %349 = and i32 %348, 65535
  %350 = shl i32 %340, 16
  %351 = or i32 %349, %350
  %352 = insertelement <4 x i32> undef, i32 %351, i32 0
  %353 = shufflevector <4 x i32> %352, <4 x i32> undef, <4 x i32> zeroinitializer
  %354 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 55
  %355 = load i32, i32* %354, align 4
  %356 = and i32 %355, 65535
  %357 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 9
  %358 = load i32, i32* %357, align 4
  %359 = shl i32 %358, 16
  %360 = or i32 %359, %356
  %361 = insertelement <4 x i32> undef, i32 %360, i32 0
  %362 = shufflevector <4 x i32> %361, <4 x i32> undef, <4 x i32> zeroinitializer
  %363 = sub i32 0, %358
  %364 = and i32 %363, 65535
  %365 = shl i32 %355, 16
  %366 = or i32 %364, %365
  %367 = insertelement <4 x i32> undef, i32 %366, i32 0
  %368 = shufflevector <4 x i32> %367, <4 x i32> undef, <4 x i32> zeroinitializer
  %369 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 23
  %370 = load i32, i32* %369, align 4
  %371 = and i32 %370, 65535
  %372 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 41
  %373 = load i32, i32* %372, align 4
  %374 = shl i32 %373, 16
  %375 = or i32 %374, %371
  %376 = insertelement <4 x i32> undef, i32 %375, i32 0
  %377 = shufflevector <4 x i32> %376, <4 x i32> undef, <4 x i32> zeroinitializer
  %378 = sub i32 0, %373
  %379 = and i32 %378, 65535
  %380 = shl i32 %370, 16
  %381 = or i32 %379, %380
  %382 = insertelement <4 x i32> undef, i32 %381, i32 0
  %383 = shufflevector <4 x i32> %382, <4 x i32> undef, <4 x i32> zeroinitializer
  %384 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 39
  %385 = load i32, i32* %384, align 4
  %386 = and i32 %385, 65535
  %387 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 25
  %388 = load i32, i32* %387, align 4
  %389 = shl i32 %388, 16
  %390 = or i32 %389, %386
  %391 = insertelement <4 x i32> undef, i32 %390, i32 0
  %392 = shufflevector <4 x i32> %391, <4 x i32> undef, <4 x i32> zeroinitializer
  %393 = sub i32 0, %388
  %394 = and i32 %393, 65535
  %395 = shl i32 %385, 16
  %396 = or i32 %394, %395
  %397 = insertelement <4 x i32> undef, i32 %396, i32 0
  %398 = shufflevector <4 x i32> %397, <4 x i32> undef, <4 x i32> zeroinitializer
  %399 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 7
  %400 = load i32, i32* %399, align 4
  %401 = and i32 %400, 65535
  %402 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 57
  %403 = load i32, i32* %402, align 4
  %404 = shl i32 %403, 16
  %405 = or i32 %404, %401
  %406 = insertelement <4 x i32> undef, i32 %405, i32 0
  %407 = shufflevector <4 x i32> %406, <4 x i32> undef, <4 x i32> zeroinitializer
  %408 = sub i32 0, %403
  %409 = and i32 %408, 65535
  %410 = shl i32 %400, 16
  %411 = or i32 %409, %410
  %412 = insertelement <4 x i32> undef, i32 %411, i32 0
  %413 = shufflevector <4 x i32> %412, <4 x i32> undef, <4 x i32> zeroinitializer
  %414 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 59
  %415 = load i32, i32* %414, align 4
  %416 = and i32 %415, 65535
  %417 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 5
  %418 = load i32, i32* %417, align 4
  %419 = shl i32 %418, 16
  %420 = or i32 %419, %416
  %421 = insertelement <4 x i32> undef, i32 %420, i32 0
  %422 = shufflevector <4 x i32> %421, <4 x i32> undef, <4 x i32> zeroinitializer
  %423 = sub i32 0, %418
  %424 = and i32 %423, 65535
  %425 = shl i32 %415, 16
  %426 = or i32 %424, %425
  %427 = insertelement <4 x i32> undef, i32 %426, i32 0
  %428 = shufflevector <4 x i32> %427, <4 x i32> undef, <4 x i32> zeroinitializer
  %429 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 27
  %430 = load i32, i32* %429, align 4
  %431 = and i32 %430, 65535
  %432 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 37
  %433 = load i32, i32* %432, align 4
  %434 = shl i32 %433, 16
  %435 = or i32 %434, %431
  %436 = insertelement <4 x i32> undef, i32 %435, i32 0
  %437 = shufflevector <4 x i32> %436, <4 x i32> undef, <4 x i32> zeroinitializer
  %438 = sub i32 0, %433
  %439 = and i32 %438, 65535
  %440 = shl i32 %430, 16
  %441 = or i32 %439, %440
  %442 = insertelement <4 x i32> undef, i32 %441, i32 0
  %443 = shufflevector <4 x i32> %442, <4 x i32> undef, <4 x i32> zeroinitializer
  %444 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 43
  %445 = load i32, i32* %444, align 4
  %446 = and i32 %445, 65535
  %447 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 21
  %448 = load i32, i32* %447, align 4
  %449 = shl i32 %448, 16
  %450 = or i32 %449, %446
  %451 = insertelement <4 x i32> undef, i32 %450, i32 0
  %452 = shufflevector <4 x i32> %451, <4 x i32> undef, <4 x i32> zeroinitializer
  %453 = sub i32 0, %448
  %454 = and i32 %453, 65535
  %455 = shl i32 %445, 16
  %456 = or i32 %454, %455
  %457 = insertelement <4 x i32> undef, i32 %456, i32 0
  %458 = shufflevector <4 x i32> %457, <4 x i32> undef, <4 x i32> zeroinitializer
  %459 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 11
  %460 = load i32, i32* %459, align 4
  %461 = and i32 %460, 65535
  %462 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 53
  %463 = load i32, i32* %462, align 4
  %464 = shl i32 %463, 16
  %465 = or i32 %464, %461
  %466 = insertelement <4 x i32> undef, i32 %465, i32 0
  %467 = shufflevector <4 x i32> %466, <4 x i32> undef, <4 x i32> zeroinitializer
  %468 = sub i32 0, %463
  %469 = and i32 %468, 65535
  %470 = shl i32 %460, 16
  %471 = or i32 %469, %470
  %472 = insertelement <4 x i32> undef, i32 %471, i32 0
  %473 = shufflevector <4 x i32> %472, <4 x i32> undef, <4 x i32> zeroinitializer
  %474 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 51
  %475 = load i32, i32* %474, align 4
  %476 = and i32 %475, 65535
  %477 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 13
  %478 = load i32, i32* %477, align 4
  %479 = shl i32 %478, 16
  %480 = or i32 %479, %476
  %481 = insertelement <4 x i32> undef, i32 %480, i32 0
  %482 = shufflevector <4 x i32> %481, <4 x i32> undef, <4 x i32> zeroinitializer
  %483 = sub i32 0, %478
  %484 = and i32 %483, 65535
  %485 = shl i32 %475, 16
  %486 = or i32 %484, %485
  %487 = insertelement <4 x i32> undef, i32 %486, i32 0
  %488 = shufflevector <4 x i32> %487, <4 x i32> undef, <4 x i32> zeroinitializer
  %489 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 19
  %490 = load i32, i32* %489, align 4
  %491 = and i32 %490, 65535
  %492 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 45
  %493 = load i32, i32* %492, align 4
  %494 = shl i32 %493, 16
  %495 = or i32 %494, %491
  %496 = insertelement <4 x i32> undef, i32 %495, i32 0
  %497 = shufflevector <4 x i32> %496, <4 x i32> undef, <4 x i32> zeroinitializer
  %498 = sub i32 0, %493
  %499 = and i32 %498, 65535
  %500 = shl i32 %490, 16
  %501 = or i32 %499, %500
  %502 = insertelement <4 x i32> undef, i32 %501, i32 0
  %503 = shufflevector <4 x i32> %502, <4 x i32> undef, <4 x i32> zeroinitializer
  %504 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 35
  %505 = load i32, i32* %504, align 4
  %506 = and i32 %505, 65535
  %507 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 29
  %508 = load i32, i32* %507, align 4
  %509 = shl i32 %508, 16
  %510 = or i32 %509, %506
  %511 = insertelement <4 x i32> undef, i32 %510, i32 0
  %512 = shufflevector <4 x i32> %511, <4 x i32> undef, <4 x i32> zeroinitializer
  %513 = sub i32 0, %508
  %514 = and i32 %513, 65535
  %515 = shl i32 %505, 16
  %516 = or i32 %514, %515
  %517 = insertelement <4 x i32> undef, i32 %516, i32 0
  %518 = shufflevector <4 x i32> %517, <4 x i32> undef, <4 x i32> zeroinitializer
  %519 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 3
  %520 = load i32, i32* %519, align 4
  %521 = and i32 %520, 65535
  %522 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 61
  %523 = load i32, i32* %522, align 4
  %524 = shl i32 %523, 16
  %525 = or i32 %524, %521
  %526 = insertelement <4 x i32> undef, i32 %525, i32 0
  %527 = shufflevector <4 x i32> %526, <4 x i32> undef, <4 x i32> zeroinitializer
  %528 = sub i32 0, %523
  %529 = and i32 %528, 65535
  %530 = shl i32 %520, 16
  %531 = or i32 %529, %530
  %532 = insertelement <4 x i32> undef, i32 %531, i32 0
  %533 = shufflevector <4 x i32> %532, <4 x i32> undef, <4 x i32> zeroinitializer
  %534 = bitcast <2 x i64>* %0 to <8 x i16>*
  %535 = load <8 x i16>, <8 x i16>* %534, align 16
  %536 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 63
  %537 = bitcast <2 x i64>* %536 to <8 x i16>*
  %538 = load <8 x i16>, <8 x i16>* %537, align 16
  %539 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %535, <8 x i16> %538) #8
  %540 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %535, <8 x i16> %538) #8
  %541 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %542 = bitcast <2 x i64>* %541 to <8 x i16>*
  %543 = load <8 x i16>, <8 x i16>* %542, align 16
  %544 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 62
  %545 = bitcast <2 x i64>* %544 to <8 x i16>*
  %546 = load <8 x i16>, <8 x i16>* %545, align 16
  %547 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %543, <8 x i16> %546) #8
  %548 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %543, <8 x i16> %546) #8
  %549 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %550 = bitcast <2 x i64>* %549 to <8 x i16>*
  %551 = load <8 x i16>, <8 x i16>* %550, align 16
  %552 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 61
  %553 = bitcast <2 x i64>* %552 to <8 x i16>*
  %554 = load <8 x i16>, <8 x i16>* %553, align 16
  %555 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %551, <8 x i16> %554) #8
  %556 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %551, <8 x i16> %554) #8
  %557 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %558 = bitcast <2 x i64>* %557 to <8 x i16>*
  %559 = load <8 x i16>, <8 x i16>* %558, align 16
  %560 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 60
  %561 = bitcast <2 x i64>* %560 to <8 x i16>*
  %562 = load <8 x i16>, <8 x i16>* %561, align 16
  %563 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %559, <8 x i16> %562) #8
  %564 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %559, <8 x i16> %562) #8
  %565 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %566 = bitcast <2 x i64>* %565 to <8 x i16>*
  %567 = load <8 x i16>, <8 x i16>* %566, align 16
  %568 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 59
  %569 = bitcast <2 x i64>* %568 to <8 x i16>*
  %570 = load <8 x i16>, <8 x i16>* %569, align 16
  %571 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %567, <8 x i16> %570) #8
  %572 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %567, <8 x i16> %570) #8
  %573 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %574 = bitcast <2 x i64>* %573 to <8 x i16>*
  %575 = load <8 x i16>, <8 x i16>* %574, align 16
  %576 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 58
  %577 = bitcast <2 x i64>* %576 to <8 x i16>*
  %578 = load <8 x i16>, <8 x i16>* %577, align 16
  %579 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %575, <8 x i16> %578) #8
  %580 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %575, <8 x i16> %578) #8
  %581 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %582 = bitcast <2 x i64>* %581 to <8 x i16>*
  %583 = load <8 x i16>, <8 x i16>* %582, align 16
  %584 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 57
  %585 = bitcast <2 x i64>* %584 to <8 x i16>*
  %586 = load <8 x i16>, <8 x i16>* %585, align 16
  %587 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %583, <8 x i16> %586) #8
  %588 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %583, <8 x i16> %586) #8
  %589 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %590 = bitcast <2 x i64>* %589 to <8 x i16>*
  %591 = load <8 x i16>, <8 x i16>* %590, align 16
  %592 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 56
  %593 = bitcast <2 x i64>* %592 to <8 x i16>*
  %594 = load <8 x i16>, <8 x i16>* %593, align 16
  %595 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %591, <8 x i16> %594) #8
  %596 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %591, <8 x i16> %594) #8
  %597 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 8
  %598 = bitcast <2 x i64>* %597 to <8 x i16>*
  %599 = load <8 x i16>, <8 x i16>* %598, align 16
  %600 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 55
  %601 = bitcast <2 x i64>* %600 to <8 x i16>*
  %602 = load <8 x i16>, <8 x i16>* %601, align 16
  %603 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %599, <8 x i16> %602) #8
  %604 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %599, <8 x i16> %602) #8
  %605 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 9
  %606 = bitcast <2 x i64>* %605 to <8 x i16>*
  %607 = load <8 x i16>, <8 x i16>* %606, align 16
  %608 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 54
  %609 = bitcast <2 x i64>* %608 to <8 x i16>*
  %610 = load <8 x i16>, <8 x i16>* %609, align 16
  %611 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %607, <8 x i16> %610) #8
  %612 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %607, <8 x i16> %610) #8
  %613 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 10
  %614 = bitcast <2 x i64>* %613 to <8 x i16>*
  %615 = load <8 x i16>, <8 x i16>* %614, align 16
  %616 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 53
  %617 = bitcast <2 x i64>* %616 to <8 x i16>*
  %618 = load <8 x i16>, <8 x i16>* %617, align 16
  %619 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %615, <8 x i16> %618) #8
  %620 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %615, <8 x i16> %618) #8
  %621 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 11
  %622 = bitcast <2 x i64>* %621 to <8 x i16>*
  %623 = load <8 x i16>, <8 x i16>* %622, align 16
  %624 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 52
  %625 = bitcast <2 x i64>* %624 to <8 x i16>*
  %626 = load <8 x i16>, <8 x i16>* %625, align 16
  %627 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %623, <8 x i16> %626) #8
  %628 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %623, <8 x i16> %626) #8
  %629 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 12
  %630 = bitcast <2 x i64>* %629 to <8 x i16>*
  %631 = load <8 x i16>, <8 x i16>* %630, align 16
  %632 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 51
  %633 = bitcast <2 x i64>* %632 to <8 x i16>*
  %634 = load <8 x i16>, <8 x i16>* %633, align 16
  %635 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %631, <8 x i16> %634) #8
  %636 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %631, <8 x i16> %634) #8
  %637 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 13
  %638 = bitcast <2 x i64>* %637 to <8 x i16>*
  %639 = load <8 x i16>, <8 x i16>* %638, align 16
  %640 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 50
  %641 = bitcast <2 x i64>* %640 to <8 x i16>*
  %642 = load <8 x i16>, <8 x i16>* %641, align 16
  %643 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %639, <8 x i16> %642) #8
  %644 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %639, <8 x i16> %642) #8
  %645 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 14
  %646 = bitcast <2 x i64>* %645 to <8 x i16>*
  %647 = load <8 x i16>, <8 x i16>* %646, align 16
  %648 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 49
  %649 = bitcast <2 x i64>* %648 to <8 x i16>*
  %650 = load <8 x i16>, <8 x i16>* %649, align 16
  %651 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %647, <8 x i16> %650) #8
  %652 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %647, <8 x i16> %650) #8
  %653 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 15
  %654 = bitcast <2 x i64>* %653 to <8 x i16>*
  %655 = load <8 x i16>, <8 x i16>* %654, align 16
  %656 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 48
  %657 = bitcast <2 x i64>* %656 to <8 x i16>*
  %658 = load <8 x i16>, <8 x i16>* %657, align 16
  %659 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %655, <8 x i16> %658) #8
  %660 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %655, <8 x i16> %658) #8
  %661 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 16
  %662 = bitcast <2 x i64>* %661 to <8 x i16>*
  %663 = load <8 x i16>, <8 x i16>* %662, align 16
  %664 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 47
  %665 = bitcast <2 x i64>* %664 to <8 x i16>*
  %666 = load <8 x i16>, <8 x i16>* %665, align 16
  %667 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %663, <8 x i16> %666) #8
  %668 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %663, <8 x i16> %666) #8
  %669 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 17
  %670 = bitcast <2 x i64>* %669 to <8 x i16>*
  %671 = load <8 x i16>, <8 x i16>* %670, align 16
  %672 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 46
  %673 = bitcast <2 x i64>* %672 to <8 x i16>*
  %674 = load <8 x i16>, <8 x i16>* %673, align 16
  %675 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %671, <8 x i16> %674) #8
  %676 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %671, <8 x i16> %674) #8
  %677 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 18
  %678 = bitcast <2 x i64>* %677 to <8 x i16>*
  %679 = load <8 x i16>, <8 x i16>* %678, align 16
  %680 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 45
  %681 = bitcast <2 x i64>* %680 to <8 x i16>*
  %682 = load <8 x i16>, <8 x i16>* %681, align 16
  %683 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %679, <8 x i16> %682) #8
  %684 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %679, <8 x i16> %682) #8
  %685 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 19
  %686 = bitcast <2 x i64>* %685 to <8 x i16>*
  %687 = load <8 x i16>, <8 x i16>* %686, align 16
  %688 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 44
  %689 = bitcast <2 x i64>* %688 to <8 x i16>*
  %690 = load <8 x i16>, <8 x i16>* %689, align 16
  %691 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %687, <8 x i16> %690) #8
  %692 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %687, <8 x i16> %690) #8
  %693 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 20
  %694 = bitcast <2 x i64>* %693 to <8 x i16>*
  %695 = load <8 x i16>, <8 x i16>* %694, align 16
  %696 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 43
  %697 = bitcast <2 x i64>* %696 to <8 x i16>*
  %698 = load <8 x i16>, <8 x i16>* %697, align 16
  %699 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %695, <8 x i16> %698) #8
  %700 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %695, <8 x i16> %698) #8
  %701 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 21
  %702 = bitcast <2 x i64>* %701 to <8 x i16>*
  %703 = load <8 x i16>, <8 x i16>* %702, align 16
  %704 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 42
  %705 = bitcast <2 x i64>* %704 to <8 x i16>*
  %706 = load <8 x i16>, <8 x i16>* %705, align 16
  %707 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %703, <8 x i16> %706) #8
  %708 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %703, <8 x i16> %706) #8
  %709 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 22
  %710 = bitcast <2 x i64>* %709 to <8 x i16>*
  %711 = load <8 x i16>, <8 x i16>* %710, align 16
  %712 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 41
  %713 = bitcast <2 x i64>* %712 to <8 x i16>*
  %714 = load <8 x i16>, <8 x i16>* %713, align 16
  %715 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %711, <8 x i16> %714) #8
  %716 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %711, <8 x i16> %714) #8
  %717 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 23
  %718 = bitcast <2 x i64>* %717 to <8 x i16>*
  %719 = load <8 x i16>, <8 x i16>* %718, align 16
  %720 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 40
  %721 = bitcast <2 x i64>* %720 to <8 x i16>*
  %722 = load <8 x i16>, <8 x i16>* %721, align 16
  %723 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %719, <8 x i16> %722) #8
  %724 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %719, <8 x i16> %722) #8
  %725 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 24
  %726 = bitcast <2 x i64>* %725 to <8 x i16>*
  %727 = load <8 x i16>, <8 x i16>* %726, align 16
  %728 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 39
  %729 = bitcast <2 x i64>* %728 to <8 x i16>*
  %730 = load <8 x i16>, <8 x i16>* %729, align 16
  %731 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %727, <8 x i16> %730) #8
  %732 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %727, <8 x i16> %730) #8
  %733 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 25
  %734 = bitcast <2 x i64>* %733 to <8 x i16>*
  %735 = load <8 x i16>, <8 x i16>* %734, align 16
  %736 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 38
  %737 = bitcast <2 x i64>* %736 to <8 x i16>*
  %738 = load <8 x i16>, <8 x i16>* %737, align 16
  %739 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %735, <8 x i16> %738) #8
  %740 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %735, <8 x i16> %738) #8
  %741 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 26
  %742 = bitcast <2 x i64>* %741 to <8 x i16>*
  %743 = load <8 x i16>, <8 x i16>* %742, align 16
  %744 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 37
  %745 = bitcast <2 x i64>* %744 to <8 x i16>*
  %746 = load <8 x i16>, <8 x i16>* %745, align 16
  %747 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %743, <8 x i16> %746) #8
  %748 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %743, <8 x i16> %746) #8
  %749 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 27
  %750 = bitcast <2 x i64>* %749 to <8 x i16>*
  %751 = load <8 x i16>, <8 x i16>* %750, align 16
  %752 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 36
  %753 = bitcast <2 x i64>* %752 to <8 x i16>*
  %754 = load <8 x i16>, <8 x i16>* %753, align 16
  %755 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %751, <8 x i16> %754) #8
  %756 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %751, <8 x i16> %754) #8
  %757 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 28
  %758 = bitcast <2 x i64>* %757 to <8 x i16>*
  %759 = load <8 x i16>, <8 x i16>* %758, align 16
  %760 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 35
  %761 = bitcast <2 x i64>* %760 to <8 x i16>*
  %762 = load <8 x i16>, <8 x i16>* %761, align 16
  %763 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %759, <8 x i16> %762) #8
  %764 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %759, <8 x i16> %762) #8
  %765 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 29
  %766 = bitcast <2 x i64>* %765 to <8 x i16>*
  %767 = load <8 x i16>, <8 x i16>* %766, align 16
  %768 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 34
  %769 = bitcast <2 x i64>* %768 to <8 x i16>*
  %770 = load <8 x i16>, <8 x i16>* %769, align 16
  %771 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %767, <8 x i16> %770) #8
  %772 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %767, <8 x i16> %770) #8
  %773 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 30
  %774 = bitcast <2 x i64>* %773 to <8 x i16>*
  %775 = load <8 x i16>, <8 x i16>* %774, align 16
  %776 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 33
  %777 = bitcast <2 x i64>* %776 to <8 x i16>*
  %778 = load <8 x i16>, <8 x i16>* %777, align 16
  %779 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %775, <8 x i16> %778) #8
  %780 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %775, <8 x i16> %778) #8
  %781 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 31
  %782 = bitcast <2 x i64>* %781 to <8 x i16>*
  %783 = load <8 x i16>, <8 x i16>* %782, align 16
  %784 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 32
  %785 = bitcast <2 x i64>* %784 to <8 x i16>*
  %786 = load <8 x i16>, <8 x i16>* %785, align 16
  %787 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %783, <8 x i16> %786) #8
  %788 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %783, <8 x i16> %786) #8
  %789 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %539, <8 x i16> %787) #8
  %790 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %539, <8 x i16> %787) #8
  %791 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %547, <8 x i16> %779) #8
  %792 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %547, <8 x i16> %779) #8
  %793 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %555, <8 x i16> %771) #8
  %794 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %555, <8 x i16> %771) #8
  %795 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %563, <8 x i16> %763) #8
  %796 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %563, <8 x i16> %763) #8
  %797 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %571, <8 x i16> %755) #8
  %798 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %571, <8 x i16> %755) #8
  %799 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %579, <8 x i16> %747) #8
  %800 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %579, <8 x i16> %747) #8
  %801 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %587, <8 x i16> %739) #8
  %802 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %587, <8 x i16> %739) #8
  %803 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %595, <8 x i16> %731) #8
  %804 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %595, <8 x i16> %731) #8
  %805 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %603, <8 x i16> %723) #8
  %806 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %603, <8 x i16> %723) #8
  %807 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %611, <8 x i16> %715) #8
  %808 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %611, <8 x i16> %715) #8
  %809 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %619, <8 x i16> %707) #8
  %810 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %619, <8 x i16> %707) #8
  %811 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %627, <8 x i16> %699) #8
  %812 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %627, <8 x i16> %699) #8
  %813 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %635, <8 x i16> %691) #8
  %814 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %635, <8 x i16> %691) #8
  %815 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %643, <8 x i16> %683) #8
  %816 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %643, <8 x i16> %683) #8
  %817 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %651, <8 x i16> %675) #8
  %818 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %651, <8 x i16> %675) #8
  %819 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %659, <8 x i16> %667) #8
  %820 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %659, <8 x i16> %667) #8
  %821 = shufflevector <8 x i16> %724, <8 x i16> %604, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %822 = shufflevector <8 x i16> %724, <8 x i16> %604, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %823 = bitcast <4 x i32> %18 to <8 x i16>
  %824 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %821, <8 x i16> %823) #8
  %825 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %822, <8 x i16> %823) #8
  %826 = bitcast <4 x i32> %22 to <8 x i16>
  %827 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %821, <8 x i16> %826) #8
  %828 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %822, <8 x i16> %826) #8
  %829 = add <4 x i32> %824, %10
  %830 = add <4 x i32> %825, %10
  %831 = add <4 x i32> %827, %10
  %832 = add <4 x i32> %828, %10
  %833 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %829, i32 %4) #8
  %834 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %830, i32 %4) #8
  %835 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %831, i32 %4) #8
  %836 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %832, i32 %4) #8
  %837 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %833, <4 x i32> %834) #8
  %838 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %835, <4 x i32> %836) #8
  %839 = shufflevector <8 x i16> %716, <8 x i16> %612, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %840 = shufflevector <8 x i16> %716, <8 x i16> %612, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %841 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %839, <8 x i16> %823) #8
  %842 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %840, <8 x i16> %823) #8
  %843 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %839, <8 x i16> %826) #8
  %844 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %840, <8 x i16> %826) #8
  %845 = add <4 x i32> %841, %10
  %846 = add <4 x i32> %842, %10
  %847 = add <4 x i32> %843, %10
  %848 = add <4 x i32> %844, %10
  %849 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %845, i32 %4) #8
  %850 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %846, i32 %4) #8
  %851 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %847, i32 %4) #8
  %852 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %848, i32 %4) #8
  %853 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %849, <4 x i32> %850) #8
  %854 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %851, <4 x i32> %852) #8
  %855 = shufflevector <8 x i16> %708, <8 x i16> %620, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %856 = shufflevector <8 x i16> %708, <8 x i16> %620, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %857 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %855, <8 x i16> %823) #8
  %858 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %856, <8 x i16> %823) #8
  %859 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %855, <8 x i16> %826) #8
  %860 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %856, <8 x i16> %826) #8
  %861 = add <4 x i32> %857, %10
  %862 = add <4 x i32> %858, %10
  %863 = add <4 x i32> %859, %10
  %864 = add <4 x i32> %860, %10
  %865 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %861, i32 %4) #8
  %866 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %862, i32 %4) #8
  %867 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %863, i32 %4) #8
  %868 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %864, i32 %4) #8
  %869 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %865, <4 x i32> %866) #8
  %870 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %867, <4 x i32> %868) #8
  %871 = shufflevector <8 x i16> %700, <8 x i16> %628, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %872 = shufflevector <8 x i16> %700, <8 x i16> %628, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %873 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %871, <8 x i16> %823) #8
  %874 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %872, <8 x i16> %823) #8
  %875 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %871, <8 x i16> %826) #8
  %876 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %872, <8 x i16> %826) #8
  %877 = add <4 x i32> %873, %10
  %878 = add <4 x i32> %874, %10
  %879 = add <4 x i32> %875, %10
  %880 = add <4 x i32> %876, %10
  %881 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %877, i32 %4) #8
  %882 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %878, i32 %4) #8
  %883 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %879, i32 %4) #8
  %884 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %880, i32 %4) #8
  %885 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %881, <4 x i32> %882) #8
  %886 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %883, <4 x i32> %884) #8
  %887 = shufflevector <8 x i16> %692, <8 x i16> %636, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %888 = shufflevector <8 x i16> %692, <8 x i16> %636, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %889 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %887, <8 x i16> %823) #8
  %890 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %888, <8 x i16> %823) #8
  %891 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %887, <8 x i16> %826) #8
  %892 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %888, <8 x i16> %826) #8
  %893 = add <4 x i32> %889, %10
  %894 = add <4 x i32> %890, %10
  %895 = add <4 x i32> %891, %10
  %896 = add <4 x i32> %892, %10
  %897 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %893, i32 %4) #8
  %898 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %894, i32 %4) #8
  %899 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %895, i32 %4) #8
  %900 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %896, i32 %4) #8
  %901 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %897, <4 x i32> %898) #8
  %902 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %899, <4 x i32> %900) #8
  %903 = shufflevector <8 x i16> %684, <8 x i16> %644, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %904 = shufflevector <8 x i16> %684, <8 x i16> %644, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %905 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %903, <8 x i16> %823) #8
  %906 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %904, <8 x i16> %823) #8
  %907 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %903, <8 x i16> %826) #8
  %908 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %904, <8 x i16> %826) #8
  %909 = add <4 x i32> %905, %10
  %910 = add <4 x i32> %906, %10
  %911 = add <4 x i32> %907, %10
  %912 = add <4 x i32> %908, %10
  %913 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %909, i32 %4) #8
  %914 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %910, i32 %4) #8
  %915 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %911, i32 %4) #8
  %916 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %912, i32 %4) #8
  %917 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %913, <4 x i32> %914) #8
  %918 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %915, <4 x i32> %916) #8
  %919 = shufflevector <8 x i16> %676, <8 x i16> %652, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %920 = shufflevector <8 x i16> %676, <8 x i16> %652, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %921 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %919, <8 x i16> %823) #8
  %922 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %920, <8 x i16> %823) #8
  %923 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %919, <8 x i16> %826) #8
  %924 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %920, <8 x i16> %826) #8
  %925 = add <4 x i32> %921, %10
  %926 = add <4 x i32> %922, %10
  %927 = add <4 x i32> %923, %10
  %928 = add <4 x i32> %924, %10
  %929 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %925, i32 %4) #8
  %930 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %926, i32 %4) #8
  %931 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %927, i32 %4) #8
  %932 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %928, i32 %4) #8
  %933 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %929, <4 x i32> %930) #8
  %934 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %931, <4 x i32> %932) #8
  %935 = shufflevector <8 x i16> %668, <8 x i16> %660, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %936 = shufflevector <8 x i16> %668, <8 x i16> %660, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %937 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %935, <8 x i16> %823) #8
  %938 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %936, <8 x i16> %823) #8
  %939 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %935, <8 x i16> %826) #8
  %940 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %936, <8 x i16> %826) #8
  %941 = add <4 x i32> %937, %10
  %942 = add <4 x i32> %938, %10
  %943 = add <4 x i32> %939, %10
  %944 = add <4 x i32> %940, %10
  %945 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %941, i32 %4) #8
  %946 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %942, i32 %4) #8
  %947 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %943, i32 %4) #8
  %948 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %944, i32 %4) #8
  %949 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %945, <4 x i32> %946) #8
  %950 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %947, <4 x i32> %948) #8
  %951 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %789, <8 x i16> %819) #8
  %952 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %789, <8 x i16> %819) #8
  %953 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %791, <8 x i16> %817) #8
  %954 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %791, <8 x i16> %817) #8
  %955 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %793, <8 x i16> %815) #8
  %956 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %793, <8 x i16> %815) #8
  %957 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %795, <8 x i16> %813) #8
  %958 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %795, <8 x i16> %813) #8
  %959 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %797, <8 x i16> %811) #8
  %960 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %797, <8 x i16> %811) #8
  %961 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %799, <8 x i16> %809) #8
  %962 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %799, <8 x i16> %809) #8
  %963 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %801, <8 x i16> %807) #8
  %964 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %801, <8 x i16> %807) #8
  %965 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %803, <8 x i16> %805) #8
  %966 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %803, <8 x i16> %805) #8
  %967 = shufflevector <8 x i16> %812, <8 x i16> %798, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %968 = shufflevector <8 x i16> %812, <8 x i16> %798, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %969 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %967, <8 x i16> %823) #8
  %970 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %968, <8 x i16> %823) #8
  %971 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %967, <8 x i16> %826) #8
  %972 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %968, <8 x i16> %826) #8
  %973 = add <4 x i32> %969, %10
  %974 = add <4 x i32> %970, %10
  %975 = add <4 x i32> %971, %10
  %976 = add <4 x i32> %972, %10
  %977 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %973, i32 %4) #8
  %978 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %974, i32 %4) #8
  %979 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %975, i32 %4) #8
  %980 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %976, i32 %4) #8
  %981 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %977, <4 x i32> %978) #8
  %982 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %979, <4 x i32> %980) #8
  %983 = shufflevector <8 x i16> %810, <8 x i16> %800, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %984 = shufflevector <8 x i16> %810, <8 x i16> %800, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %985 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %983, <8 x i16> %823) #8
  %986 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %984, <8 x i16> %823) #8
  %987 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %983, <8 x i16> %826) #8
  %988 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %984, <8 x i16> %826) #8
  %989 = add <4 x i32> %985, %10
  %990 = add <4 x i32> %986, %10
  %991 = add <4 x i32> %987, %10
  %992 = add <4 x i32> %988, %10
  %993 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %989, i32 %4) #8
  %994 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %990, i32 %4) #8
  %995 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %991, i32 %4) #8
  %996 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %992, i32 %4) #8
  %997 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %993, <4 x i32> %994) #8
  %998 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %995, <4 x i32> %996) #8
  %999 = shufflevector <8 x i16> %808, <8 x i16> %802, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1000 = shufflevector <8 x i16> %808, <8 x i16> %802, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1001 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %999, <8 x i16> %823) #8
  %1002 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1000, <8 x i16> %823) #8
  %1003 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %999, <8 x i16> %826) #8
  %1004 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1000, <8 x i16> %826) #8
  %1005 = add <4 x i32> %1001, %10
  %1006 = add <4 x i32> %1002, %10
  %1007 = add <4 x i32> %1003, %10
  %1008 = add <4 x i32> %1004, %10
  %1009 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1005, i32 %4) #8
  %1010 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1006, i32 %4) #8
  %1011 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1007, i32 %4) #8
  %1012 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1008, i32 %4) #8
  %1013 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1009, <4 x i32> %1010) #8
  %1014 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1011, <4 x i32> %1012) #8
  %1015 = shufflevector <8 x i16> %806, <8 x i16> %804, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1016 = shufflevector <8 x i16> %806, <8 x i16> %804, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1017 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1015, <8 x i16> %823) #8
  %1018 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1016, <8 x i16> %823) #8
  %1019 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1015, <8 x i16> %826) #8
  %1020 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1016, <8 x i16> %826) #8
  %1021 = add <4 x i32> %1017, %10
  %1022 = add <4 x i32> %1018, %10
  %1023 = add <4 x i32> %1019, %10
  %1024 = add <4 x i32> %1020, %10
  %1025 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1021, i32 %4) #8
  %1026 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1022, i32 %4) #8
  %1027 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1023, i32 %4) #8
  %1028 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1024, i32 %4) #8
  %1029 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1025, <4 x i32> %1026) #8
  %1030 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1027, <4 x i32> %1028) #8
  %1031 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %788, <8 x i16> %949) #8
  %1032 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %788, <8 x i16> %949) #8
  %1033 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %780, <8 x i16> %933) #8
  %1034 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %780, <8 x i16> %933) #8
  %1035 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %772, <8 x i16> %917) #8
  %1036 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %772, <8 x i16> %917) #8
  %1037 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %764, <8 x i16> %901) #8
  %1038 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %764, <8 x i16> %901) #8
  %1039 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %756, <8 x i16> %885) #8
  %1040 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %756, <8 x i16> %885) #8
  %1041 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %748, <8 x i16> %869) #8
  %1042 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %748, <8 x i16> %869) #8
  %1043 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %740, <8 x i16> %853) #8
  %1044 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %740, <8 x i16> %853) #8
  %1045 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %732, <8 x i16> %837) #8
  %1046 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %732, <8 x i16> %837) #8
  %1047 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %540, <8 x i16> %950) #8
  %1048 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %540, <8 x i16> %950) #8
  %1049 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %548, <8 x i16> %934) #8
  %1050 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %548, <8 x i16> %934) #8
  %1051 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %556, <8 x i16> %918) #8
  %1052 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %556, <8 x i16> %918) #8
  %1053 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %564, <8 x i16> %902) #8
  %1054 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %564, <8 x i16> %902) #8
  %1055 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %572, <8 x i16> %886) #8
  %1056 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %572, <8 x i16> %886) #8
  %1057 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %580, <8 x i16> %870) #8
  %1058 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %580, <8 x i16> %870) #8
  %1059 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %588, <8 x i16> %854) #8
  %1060 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %588, <8 x i16> %854) #8
  %1061 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %596, <8 x i16> %838) #8
  %1062 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %596, <8 x i16> %838) #8
  %1063 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %951, <8 x i16> %965) #8
  %1064 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %951, <8 x i16> %965) #8
  %1065 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %953, <8 x i16> %963) #8
  %1066 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %953, <8 x i16> %963) #8
  %1067 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %955, <8 x i16> %961) #8
  %1068 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %955, <8 x i16> %961) #8
  %1069 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %957, <8 x i16> %959) #8
  %1070 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %957, <8 x i16> %959) #8
  %1071 = shufflevector <8 x i16> %962, <8 x i16> %956, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1072 = shufflevector <8 x i16> %962, <8 x i16> %956, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1073 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1071, <8 x i16> %823) #8
  %1074 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1072, <8 x i16> %823) #8
  %1075 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1071, <8 x i16> %826) #8
  %1076 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1072, <8 x i16> %826) #8
  %1077 = add <4 x i32> %1073, %10
  %1078 = add <4 x i32> %1074, %10
  %1079 = add <4 x i32> %1075, %10
  %1080 = add <4 x i32> %1076, %10
  %1081 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1077, i32 %4) #8
  %1082 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1078, i32 %4) #8
  %1083 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1079, i32 %4) #8
  %1084 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1080, i32 %4) #8
  %1085 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1081, <4 x i32> %1082) #8
  %1086 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1083, <4 x i32> %1084) #8
  %1087 = shufflevector <8 x i16> %960, <8 x i16> %958, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1088 = shufflevector <8 x i16> %960, <8 x i16> %958, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1089 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1087, <8 x i16> %823) #8
  %1090 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1088, <8 x i16> %823) #8
  %1091 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1087, <8 x i16> %826) #8
  %1092 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1088, <8 x i16> %826) #8
  %1093 = add <4 x i32> %1089, %10
  %1094 = add <4 x i32> %1090, %10
  %1095 = add <4 x i32> %1091, %10
  %1096 = add <4 x i32> %1092, %10
  %1097 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1093, i32 %4) #8
  %1098 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1094, i32 %4) #8
  %1099 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1095, i32 %4) #8
  %1100 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1096, i32 %4) #8
  %1101 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1097, <4 x i32> %1098) #8
  %1102 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1099, <4 x i32> %1100) #8
  %1103 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %820, <8 x i16> %1029) #8
  %1104 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %820, <8 x i16> %1029) #8
  %1105 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %818, <8 x i16> %1013) #8
  %1106 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %818, <8 x i16> %1013) #8
  %1107 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %816, <8 x i16> %997) #8
  %1108 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %816, <8 x i16> %997) #8
  %1109 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %814, <8 x i16> %981) #8
  %1110 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %814, <8 x i16> %981) #8
  %1111 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %790, <8 x i16> %1030) #8
  %1112 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %790, <8 x i16> %1030) #8
  %1113 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %792, <8 x i16> %1014) #8
  %1114 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %792, <8 x i16> %1014) #8
  %1115 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %794, <8 x i16> %998) #8
  %1116 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %794, <8 x i16> %998) #8
  %1117 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %796, <8 x i16> %982) #8
  %1118 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %796, <8 x i16> %982) #8
  %1119 = shufflevector <8 x i16> %1039, <8 x i16> %1056, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1120 = shufflevector <8 x i16> %1039, <8 x i16> %1056, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1121 = bitcast <4 x i32> %32 to <8 x i16>
  %1122 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1119, <8 x i16> %1121) #8
  %1123 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1120, <8 x i16> %1121) #8
  %1124 = bitcast <4 x i32> %37 to <8 x i16>
  %1125 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1119, <8 x i16> %1124) #8
  %1126 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1120, <8 x i16> %1124) #8
  %1127 = add <4 x i32> %1122, %10
  %1128 = add <4 x i32> %1123, %10
  %1129 = add <4 x i32> %1125, %10
  %1130 = add <4 x i32> %1126, %10
  %1131 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1127, i32 %4) #8
  %1132 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1128, i32 %4) #8
  %1133 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1129, i32 %4) #8
  %1134 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1130, i32 %4) #8
  %1135 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1131, <4 x i32> %1132) #8
  %1136 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1133, <4 x i32> %1134) #8
  %1137 = shufflevector <8 x i16> %1041, <8 x i16> %1058, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1138 = shufflevector <8 x i16> %1041, <8 x i16> %1058, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1139 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1137, <8 x i16> %1121) #8
  %1140 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1138, <8 x i16> %1121) #8
  %1141 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1137, <8 x i16> %1124) #8
  %1142 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1138, <8 x i16> %1124) #8
  %1143 = add <4 x i32> %1139, %10
  %1144 = add <4 x i32> %1140, %10
  %1145 = add <4 x i32> %1141, %10
  %1146 = add <4 x i32> %1142, %10
  %1147 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1143, i32 %4) #8
  %1148 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1144, i32 %4) #8
  %1149 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1145, i32 %4) #8
  %1150 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1146, i32 %4) #8
  %1151 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1147, <4 x i32> %1148) #8
  %1152 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1149, <4 x i32> %1150) #8
  %1153 = shufflevector <8 x i16> %1043, <8 x i16> %1060, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1154 = shufflevector <8 x i16> %1043, <8 x i16> %1060, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1155 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1153, <8 x i16> %1121) #8
  %1156 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1154, <8 x i16> %1121) #8
  %1157 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1153, <8 x i16> %1124) #8
  %1158 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1154, <8 x i16> %1124) #8
  %1159 = add <4 x i32> %1155, %10
  %1160 = add <4 x i32> %1156, %10
  %1161 = add <4 x i32> %1157, %10
  %1162 = add <4 x i32> %1158, %10
  %1163 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1159, i32 %4) #8
  %1164 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1160, i32 %4) #8
  %1165 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1161, i32 %4) #8
  %1166 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1162, i32 %4) #8
  %1167 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1163, <4 x i32> %1164) #8
  %1168 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1165, <4 x i32> %1166) #8
  %1169 = shufflevector <8 x i16> %1045, <8 x i16> %1062, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1170 = shufflevector <8 x i16> %1045, <8 x i16> %1062, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1171 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1169, <8 x i16> %1121) #8
  %1172 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1170, <8 x i16> %1121) #8
  %1173 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1169, <8 x i16> %1124) #8
  %1174 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1170, <8 x i16> %1124) #8
  %1175 = add <4 x i32> %1171, %10
  %1176 = add <4 x i32> %1172, %10
  %1177 = add <4 x i32> %1173, %10
  %1178 = add <4 x i32> %1174, %10
  %1179 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1175, i32 %4) #8
  %1180 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1176, i32 %4) #8
  %1181 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1177, i32 %4) #8
  %1182 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1178, i32 %4) #8
  %1183 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1179, <4 x i32> %1180) #8
  %1184 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1181, <4 x i32> %1182) #8
  %1185 = shufflevector <8 x i16> %1046, <8 x i16> %1061, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1186 = shufflevector <8 x i16> %1046, <8 x i16> %1061, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1187 = bitcast <4 x i32> %43 to <8 x i16>
  %1188 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1185, <8 x i16> %1187) #8
  %1189 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1186, <8 x i16> %1187) #8
  %1190 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1185, <8 x i16> %1121) #8
  %1191 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1186, <8 x i16> %1121) #8
  %1192 = add <4 x i32> %1188, %10
  %1193 = add <4 x i32> %1189, %10
  %1194 = add <4 x i32> %1190, %10
  %1195 = add <4 x i32> %1191, %10
  %1196 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1192, i32 %4) #8
  %1197 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1193, i32 %4) #8
  %1198 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1194, i32 %4) #8
  %1199 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1195, i32 %4) #8
  %1200 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1196, <4 x i32> %1197) #8
  %1201 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1198, <4 x i32> %1199) #8
  %1202 = shufflevector <8 x i16> %1044, <8 x i16> %1059, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1203 = shufflevector <8 x i16> %1044, <8 x i16> %1059, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1204 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1202, <8 x i16> %1187) #8
  %1205 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1203, <8 x i16> %1187) #8
  %1206 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1202, <8 x i16> %1121) #8
  %1207 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1203, <8 x i16> %1121) #8
  %1208 = add <4 x i32> %1204, %10
  %1209 = add <4 x i32> %1205, %10
  %1210 = add <4 x i32> %1206, %10
  %1211 = add <4 x i32> %1207, %10
  %1212 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1208, i32 %4) #8
  %1213 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1209, i32 %4) #8
  %1214 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1210, i32 %4) #8
  %1215 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1211, i32 %4) #8
  %1216 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1212, <4 x i32> %1213) #8
  %1217 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1214, <4 x i32> %1215) #8
  %1218 = shufflevector <8 x i16> %1042, <8 x i16> %1057, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1219 = shufflevector <8 x i16> %1042, <8 x i16> %1057, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1220 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1218, <8 x i16> %1187) #8
  %1221 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1219, <8 x i16> %1187) #8
  %1222 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1218, <8 x i16> %1121) #8
  %1223 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1219, <8 x i16> %1121) #8
  %1224 = add <4 x i32> %1220, %10
  %1225 = add <4 x i32> %1221, %10
  %1226 = add <4 x i32> %1222, %10
  %1227 = add <4 x i32> %1223, %10
  %1228 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1224, i32 %4) #8
  %1229 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1225, i32 %4) #8
  %1230 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1226, i32 %4) #8
  %1231 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1227, i32 %4) #8
  %1232 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1228, <4 x i32> %1229) #8
  %1233 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1230, <4 x i32> %1231) #8
  %1234 = shufflevector <8 x i16> %1040, <8 x i16> %1055, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1235 = shufflevector <8 x i16> %1040, <8 x i16> %1055, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1236 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1234, <8 x i16> %1187) #8
  %1237 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1235, <8 x i16> %1187) #8
  %1238 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1234, <8 x i16> %1121) #8
  %1239 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1235, <8 x i16> %1121) #8
  %1240 = add <4 x i32> %1236, %10
  %1241 = add <4 x i32> %1237, %10
  %1242 = add <4 x i32> %1238, %10
  %1243 = add <4 x i32> %1239, %10
  %1244 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1240, i32 %4) #8
  %1245 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1241, i32 %4) #8
  %1246 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1242, i32 %4) #8
  %1247 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1243, i32 %4) #8
  %1248 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1244, <4 x i32> %1245) #8
  %1249 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1246, <4 x i32> %1247) #8
  %1250 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1063, <8 x i16> %1069) #8
  %1251 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1063, <8 x i16> %1069) #8
  %1252 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1065, <8 x i16> %1067) #8
  %1253 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1065, <8 x i16> %1067) #8
  %1254 = shufflevector <8 x i16> %1068, <8 x i16> %1066, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1255 = shufflevector <8 x i16> %1068, <8 x i16> %1066, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1256 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1254, <8 x i16> %823) #8
  %1257 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1255, <8 x i16> %823) #8
  %1258 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1254, <8 x i16> %826) #8
  %1259 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1255, <8 x i16> %826) #8
  %1260 = add <4 x i32> %1256, %10
  %1261 = add <4 x i32> %1257, %10
  %1262 = add <4 x i32> %1258, %10
  %1263 = add <4 x i32> %1259, %10
  %1264 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1260, i32 %4) #8
  %1265 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1261, i32 %4) #8
  %1266 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1262, i32 %4) #8
  %1267 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1263, i32 %4) #8
  %1268 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1264, <4 x i32> %1265) #8
  %1269 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1266, <4 x i32> %1267) #8
  %1270 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %966, <8 x i16> %1101) #8
  %1271 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %966, <8 x i16> %1101) #8
  %1272 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %964, <8 x i16> %1085) #8
  %1273 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %964, <8 x i16> %1085) #8
  %1274 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %952, <8 x i16> %1102) #8
  %1275 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %952, <8 x i16> %1102) #8
  %1276 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %954, <8 x i16> %1086) #8
  %1277 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %954, <8 x i16> %1086) #8
  %1278 = shufflevector <8 x i16> %1107, <8 x i16> %1116, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1279 = shufflevector <8 x i16> %1107, <8 x i16> %1116, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1280 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1278, <8 x i16> %1121) #8
  %1281 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1279, <8 x i16> %1121) #8
  %1282 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1278, <8 x i16> %1124) #8
  %1283 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1279, <8 x i16> %1124) #8
  %1284 = add <4 x i32> %1280, %10
  %1285 = add <4 x i32> %1281, %10
  %1286 = add <4 x i32> %1282, %10
  %1287 = add <4 x i32> %1283, %10
  %1288 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1284, i32 %4) #8
  %1289 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1285, i32 %4) #8
  %1290 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1286, i32 %4) #8
  %1291 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1287, i32 %4) #8
  %1292 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1288, <4 x i32> %1289) #8
  %1293 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1290, <4 x i32> %1291) #8
  %1294 = shufflevector <8 x i16> %1109, <8 x i16> %1118, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1295 = shufflevector <8 x i16> %1109, <8 x i16> %1118, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1296 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1294, <8 x i16> %1121) #8
  %1297 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1295, <8 x i16> %1121) #8
  %1298 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1294, <8 x i16> %1124) #8
  %1299 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1295, <8 x i16> %1124) #8
  %1300 = add <4 x i32> %1296, %10
  %1301 = add <4 x i32> %1297, %10
  %1302 = add <4 x i32> %1298, %10
  %1303 = add <4 x i32> %1299, %10
  %1304 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1300, i32 %4) #8
  %1305 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1301, i32 %4) #8
  %1306 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1302, i32 %4) #8
  %1307 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1303, i32 %4) #8
  %1308 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1304, <4 x i32> %1305) #8
  %1309 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1306, <4 x i32> %1307) #8
  %1310 = shufflevector <8 x i16> %1110, <8 x i16> %1117, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1311 = shufflevector <8 x i16> %1110, <8 x i16> %1117, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1312 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1310, <8 x i16> %1187) #8
  %1313 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1311, <8 x i16> %1187) #8
  %1314 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1310, <8 x i16> %1121) #8
  %1315 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1311, <8 x i16> %1121) #8
  %1316 = add <4 x i32> %1312, %10
  %1317 = add <4 x i32> %1313, %10
  %1318 = add <4 x i32> %1314, %10
  %1319 = add <4 x i32> %1315, %10
  %1320 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1316, i32 %4) #8
  %1321 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1317, i32 %4) #8
  %1322 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1318, i32 %4) #8
  %1323 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1319, i32 %4) #8
  %1324 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1320, <4 x i32> %1321) #8
  %1325 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1322, <4 x i32> %1323) #8
  %1326 = shufflevector <8 x i16> %1108, <8 x i16> %1115, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1327 = shufflevector <8 x i16> %1108, <8 x i16> %1115, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1328 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1326, <8 x i16> %1187) #8
  %1329 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1327, <8 x i16> %1187) #8
  %1330 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1326, <8 x i16> %1121) #8
  %1331 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1327, <8 x i16> %1121) #8
  %1332 = add <4 x i32> %1328, %10
  %1333 = add <4 x i32> %1329, %10
  %1334 = add <4 x i32> %1330, %10
  %1335 = add <4 x i32> %1331, %10
  %1336 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1332, i32 %4) #8
  %1337 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1333, i32 %4) #8
  %1338 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1334, i32 %4) #8
  %1339 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1335, i32 %4) #8
  %1340 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1336, <4 x i32> %1337) #8
  %1341 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1338, <4 x i32> %1339) #8
  %1342 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1031, <8 x i16> %1183) #8
  %1343 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1031, <8 x i16> %1183) #8
  %1344 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1033, <8 x i16> %1167) #8
  %1345 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1033, <8 x i16> %1167) #8
  %1346 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1035, <8 x i16> %1151) #8
  %1347 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1035, <8 x i16> %1151) #8
  %1348 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1037, <8 x i16> %1135) #8
  %1349 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1037, <8 x i16> %1135) #8
  %1350 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1032, <8 x i16> %1200) #8
  %1351 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1032, <8 x i16> %1200) #8
  %1352 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1034, <8 x i16> %1216) #8
  %1353 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1034, <8 x i16> %1216) #8
  %1354 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1036, <8 x i16> %1232) #8
  %1355 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1036, <8 x i16> %1232) #8
  %1356 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1038, <8 x i16> %1248) #8
  %1357 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1038, <8 x i16> %1248) #8
  %1358 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1047, <8 x i16> %1201) #8
  %1359 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1047, <8 x i16> %1201) #8
  %1360 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1049, <8 x i16> %1217) #8
  %1361 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1049, <8 x i16> %1217) #8
  %1362 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1051, <8 x i16> %1233) #8
  %1363 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1051, <8 x i16> %1233) #8
  %1364 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1053, <8 x i16> %1249) #8
  %1365 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1053, <8 x i16> %1249) #8
  %1366 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1048, <8 x i16> %1184) #8
  %1367 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1048, <8 x i16> %1184) #8
  %1368 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1050, <8 x i16> %1168) #8
  %1369 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1050, <8 x i16> %1168) #8
  %1370 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1052, <8 x i16> %1152) #8
  %1371 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1052, <8 x i16> %1152) #8
  %1372 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1054, <8 x i16> %1136) #8
  %1373 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1054, <8 x i16> %1136) #8
  %1374 = shufflevector <8 x i16> %1250, <8 x i16> %1252, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1375 = shufflevector <8 x i16> %1250, <8 x i16> %1252, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1376 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1374, <8 x i16> %826) #8
  %1377 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1375, <8 x i16> %826) #8
  %1378 = bitcast <4 x i32> %47 to <8 x i16>
  %1379 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1374, <8 x i16> %1378) #8
  %1380 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1375, <8 x i16> %1378) #8
  %1381 = add <4 x i32> %1376, %10
  %1382 = add <4 x i32> %1377, %10
  %1383 = add <4 x i32> %1379, %10
  %1384 = add <4 x i32> %1380, %10
  %1385 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1381, i32 %4) #8
  %1386 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1382, i32 %4) #8
  %1387 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1383, i32 %4) #8
  %1388 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1384, i32 %4) #8
  %1389 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1385, <4 x i32> %1386) #8
  %1390 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1387, <4 x i32> %1388) #8
  %1391 = shufflevector <8 x i16> %1253, <8 x i16> %1251, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1392 = shufflevector <8 x i16> %1253, <8 x i16> %1251, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1393 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1391, <8 x i16> %1124) #8
  %1394 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1392, <8 x i16> %1124) #8
  %1395 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1391, <8 x i16> %1121) #8
  %1396 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1392, <8 x i16> %1121) #8
  %1397 = add <4 x i32> %1393, %10
  %1398 = add <4 x i32> %1394, %10
  %1399 = add <4 x i32> %1395, %10
  %1400 = add <4 x i32> %1396, %10
  %1401 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1397, i32 %4) #8
  %1402 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1398, i32 %4) #8
  %1403 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1399, i32 %4) #8
  %1404 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1400, i32 %4) #8
  %1405 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1401, <4 x i32> %1402) #8
  %1406 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1403, <4 x i32> %1404) #8
  %1407 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1070, <8 x i16> %1268) #8
  %1408 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1070, <8 x i16> %1268) #8
  %1409 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1064, <8 x i16> %1269) #8
  %1410 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1064, <8 x i16> %1269) #8
  %1411 = shufflevector <8 x i16> %1272, <8 x i16> %1277, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1412 = shufflevector <8 x i16> %1272, <8 x i16> %1277, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1413 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1411, <8 x i16> %1121) #8
  %1414 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1412, <8 x i16> %1121) #8
  %1415 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1411, <8 x i16> %1124) #8
  %1416 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1412, <8 x i16> %1124) #8
  %1417 = add <4 x i32> %1413, %10
  %1418 = add <4 x i32> %1414, %10
  %1419 = add <4 x i32> %1415, %10
  %1420 = add <4 x i32> %1416, %10
  %1421 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1417, i32 %4) #8
  %1422 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1418, i32 %4) #8
  %1423 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1419, i32 %4) #8
  %1424 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1420, i32 %4) #8
  %1425 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1421, <4 x i32> %1422) #8
  %1426 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1423, <4 x i32> %1424) #8
  %1427 = shufflevector <8 x i16> %1273, <8 x i16> %1276, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1428 = shufflevector <8 x i16> %1273, <8 x i16> %1276, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1429 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1427, <8 x i16> %1187) #8
  %1430 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1428, <8 x i16> %1187) #8
  %1431 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1427, <8 x i16> %1121) #8
  %1432 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1428, <8 x i16> %1121) #8
  %1433 = add <4 x i32> %1429, %10
  %1434 = add <4 x i32> %1430, %10
  %1435 = add <4 x i32> %1431, %10
  %1436 = add <4 x i32> %1432, %10
  %1437 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1433, i32 %4) #8
  %1438 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1434, i32 %4) #8
  %1439 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1435, i32 %4) #8
  %1440 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1436, i32 %4) #8
  %1441 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1437, <4 x i32> %1438) #8
  %1442 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1439, <4 x i32> %1440) #8
  %1443 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1103, <8 x i16> %1308) #8
  %1444 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1103, <8 x i16> %1308) #8
  %1445 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1105, <8 x i16> %1292) #8
  %1446 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1105, <8 x i16> %1292) #8
  %1447 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1104, <8 x i16> %1324) #8
  %1448 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1104, <8 x i16> %1324) #8
  %1449 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1106, <8 x i16> %1340) #8
  %1450 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1106, <8 x i16> %1340) #8
  %1451 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1111, <8 x i16> %1325) #8
  %1452 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1111, <8 x i16> %1325) #8
  %1453 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1113, <8 x i16> %1341) #8
  %1454 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1113, <8 x i16> %1341) #8
  %1455 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1112, <8 x i16> %1309) #8
  %1456 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1112, <8 x i16> %1309) #8
  %1457 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1114, <8 x i16> %1293) #8
  %1458 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1114, <8 x i16> %1293) #8
  %1459 = shufflevector <8 x i16> %1346, <8 x i16> %1371, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1460 = shufflevector <8 x i16> %1346, <8 x i16> %1371, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1461 = bitcast <4 x i32> %57 to <8 x i16>
  %1462 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1459, <8 x i16> %1461) #8
  %1463 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1460, <8 x i16> %1461) #8
  %1464 = bitcast <4 x i32> %62 to <8 x i16>
  %1465 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1459, <8 x i16> %1464) #8
  %1466 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1460, <8 x i16> %1464) #8
  %1467 = add <4 x i32> %1462, %10
  %1468 = add <4 x i32> %1463, %10
  %1469 = add <4 x i32> %1465, %10
  %1470 = add <4 x i32> %1466, %10
  %1471 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1467, i32 %4) #8
  %1472 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1468, i32 %4) #8
  %1473 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1469, i32 %4) #8
  %1474 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1470, i32 %4) #8
  %1475 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1471, <4 x i32> %1472) #8
  %1476 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1473, <4 x i32> %1474) #8
  %1477 = shufflevector <8 x i16> %1348, <8 x i16> %1373, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1478 = shufflevector <8 x i16> %1348, <8 x i16> %1373, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1479 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1477, <8 x i16> %1461) #8
  %1480 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1478, <8 x i16> %1461) #8
  %1481 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1477, <8 x i16> %1464) #8
  %1482 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1478, <8 x i16> %1464) #8
  %1483 = add <4 x i32> %1479, %10
  %1484 = add <4 x i32> %1480, %10
  %1485 = add <4 x i32> %1481, %10
  %1486 = add <4 x i32> %1482, %10
  %1487 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1483, i32 %4) #8
  %1488 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1484, i32 %4) #8
  %1489 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1485, i32 %4) #8
  %1490 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1486, i32 %4) #8
  %1491 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1487, <4 x i32> %1488) #8
  %1492 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1489, <4 x i32> %1490) #8
  %1493 = shufflevector <8 x i16> %1349, <8 x i16> %1372, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1494 = shufflevector <8 x i16> %1349, <8 x i16> %1372, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1495 = bitcast <4 x i32> %68 to <8 x i16>
  %1496 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1493, <8 x i16> %1495) #8
  %1497 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1494, <8 x i16> %1495) #8
  %1498 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1493, <8 x i16> %1461) #8
  %1499 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1494, <8 x i16> %1461) #8
  %1500 = add <4 x i32> %1496, %10
  %1501 = add <4 x i32> %1497, %10
  %1502 = add <4 x i32> %1498, %10
  %1503 = add <4 x i32> %1499, %10
  %1504 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1500, i32 %4) #8
  %1505 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1501, i32 %4) #8
  %1506 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1502, i32 %4) #8
  %1507 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1503, i32 %4) #8
  %1508 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1504, <4 x i32> %1505) #8
  %1509 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1506, <4 x i32> %1507) #8
  %1510 = shufflevector <8 x i16> %1347, <8 x i16> %1370, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1511 = shufflevector <8 x i16> %1347, <8 x i16> %1370, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1512 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1510, <8 x i16> %1495) #8
  %1513 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1511, <8 x i16> %1495) #8
  %1514 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1510, <8 x i16> %1461) #8
  %1515 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1511, <8 x i16> %1461) #8
  %1516 = add <4 x i32> %1512, %10
  %1517 = add <4 x i32> %1513, %10
  %1518 = add <4 x i32> %1514, %10
  %1519 = add <4 x i32> %1515, %10
  %1520 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1516, i32 %4) #8
  %1521 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1517, i32 %4) #8
  %1522 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1518, i32 %4) #8
  %1523 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1519, i32 %4) #8
  %1524 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1520, <4 x i32> %1521) #8
  %1525 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1522, <4 x i32> %1523) #8
  %1526 = shufflevector <8 x i16> %1354, <8 x i16> %1363, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1527 = shufflevector <8 x i16> %1354, <8 x i16> %1363, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1528 = bitcast <4 x i32> %78 to <8 x i16>
  %1529 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1526, <8 x i16> %1528) #8
  %1530 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1527, <8 x i16> %1528) #8
  %1531 = bitcast <4 x i32> %83 to <8 x i16>
  %1532 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1526, <8 x i16> %1531) #8
  %1533 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1527, <8 x i16> %1531) #8
  %1534 = add <4 x i32> %1529, %10
  %1535 = add <4 x i32> %1530, %10
  %1536 = add <4 x i32> %1532, %10
  %1537 = add <4 x i32> %1533, %10
  %1538 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1534, i32 %4) #8
  %1539 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1535, i32 %4) #8
  %1540 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1536, i32 %4) #8
  %1541 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1537, i32 %4) #8
  %1542 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1538, <4 x i32> %1539) #8
  %1543 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1540, <4 x i32> %1541) #8
  %1544 = shufflevector <8 x i16> %1356, <8 x i16> %1365, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1545 = shufflevector <8 x i16> %1356, <8 x i16> %1365, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1546 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1544, <8 x i16> %1528) #8
  %1547 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1545, <8 x i16> %1528) #8
  %1548 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1544, <8 x i16> %1531) #8
  %1549 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1545, <8 x i16> %1531) #8
  %1550 = add <4 x i32> %1546, %10
  %1551 = add <4 x i32> %1547, %10
  %1552 = add <4 x i32> %1548, %10
  %1553 = add <4 x i32> %1549, %10
  %1554 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1550, i32 %4) #8
  %1555 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1551, i32 %4) #8
  %1556 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1552, i32 %4) #8
  %1557 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1553, i32 %4) #8
  %1558 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1554, <4 x i32> %1555) #8
  %1559 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1556, <4 x i32> %1557) #8
  %1560 = shufflevector <8 x i16> %1357, <8 x i16> %1364, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1561 = shufflevector <8 x i16> %1357, <8 x i16> %1364, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1562 = bitcast <4 x i32> %89 to <8 x i16>
  %1563 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1560, <8 x i16> %1562) #8
  %1564 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1561, <8 x i16> %1562) #8
  %1565 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1560, <8 x i16> %1528) #8
  %1566 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1561, <8 x i16> %1528) #8
  %1567 = add <4 x i32> %1563, %10
  %1568 = add <4 x i32> %1564, %10
  %1569 = add <4 x i32> %1565, %10
  %1570 = add <4 x i32> %1566, %10
  %1571 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1567, i32 %4) #8
  %1572 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1568, i32 %4) #8
  %1573 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1569, i32 %4) #8
  %1574 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1570, i32 %4) #8
  %1575 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1571, <4 x i32> %1572) #8
  %1576 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1573, <4 x i32> %1574) #8
  %1577 = shufflevector <8 x i16> %1355, <8 x i16> %1362, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1578 = shufflevector <8 x i16> %1355, <8 x i16> %1362, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1579 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1577, <8 x i16> %1562) #8
  %1580 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1578, <8 x i16> %1562) #8
  %1581 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1577, <8 x i16> %1528) #8
  %1582 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1578, <8 x i16> %1528) #8
  %1583 = add <4 x i32> %1579, %10
  %1584 = add <4 x i32> %1580, %10
  %1585 = add <4 x i32> %1581, %10
  %1586 = add <4 x i32> %1582, %10
  %1587 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1583, i32 %4) #8
  %1588 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1584, i32 %4) #8
  %1589 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1585, i32 %4) #8
  %1590 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1586, i32 %4) #8
  %1591 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1587, <4 x i32> %1588) #8
  %1592 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1589, <4 x i32> %1590) #8
  %1593 = shufflevector <8 x i16> %1407, <8 x i16> %1410, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1594 = shufflevector <8 x i16> %1407, <8 x i16> %1410, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1595 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1593, <8 x i16> %1464) #8
  %1596 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1594, <8 x i16> %1464) #8
  %1597 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1593, <8 x i16> %1461) #8
  %1598 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1594, <8 x i16> %1461) #8
  %1599 = add <4 x i32> %1595, %10
  %1600 = add <4 x i32> %1596, %10
  %1601 = add <4 x i32> %1597, %10
  %1602 = add <4 x i32> %1598, %10
  %1603 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1599, i32 %4) #8
  %1604 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1600, i32 %4) #8
  %1605 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1601, i32 %4) #8
  %1606 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1602, i32 %4) #8
  %1607 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1603, <4 x i32> %1604) #8
  %1608 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1605, <4 x i32> %1606) #8
  %1609 = shufflevector <8 x i16> %1408, <8 x i16> %1409, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1610 = shufflevector <8 x i16> %1408, <8 x i16> %1409, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1611 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1609, <8 x i16> %1531) #8
  %1612 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1610, <8 x i16> %1531) #8
  %1613 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1609, <8 x i16> %1528) #8
  %1614 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1610, <8 x i16> %1528) #8
  %1615 = add <4 x i32> %1611, %10
  %1616 = add <4 x i32> %1612, %10
  %1617 = add <4 x i32> %1613, %10
  %1618 = add <4 x i32> %1614, %10
  %1619 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1615, i32 %4) #8
  %1620 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1616, i32 %4) #8
  %1621 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1617, i32 %4) #8
  %1622 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1618, i32 %4) #8
  %1623 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1619, <4 x i32> %1620) #8
  %1624 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1621, <4 x i32> %1622) #8
  %1625 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1270, <8 x i16> %1425) #8
  %1626 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1270, <8 x i16> %1425) #8
  %1627 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1271, <8 x i16> %1441) #8
  %1628 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1271, <8 x i16> %1441) #8
  %1629 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1274, <8 x i16> %1442) #8
  %1630 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1274, <8 x i16> %1442) #8
  %1631 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1275, <8 x i16> %1426) #8
  %1632 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1275, <8 x i16> %1426) #8
  %1633 = shufflevector <8 x i16> %1445, <8 x i16> %1458, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1634 = shufflevector <8 x i16> %1445, <8 x i16> %1458, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1635 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1633, <8 x i16> %1461) #8
  %1636 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1634, <8 x i16> %1461) #8
  %1637 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1633, <8 x i16> %1464) #8
  %1638 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1634, <8 x i16> %1464) #8
  %1639 = add <4 x i32> %1635, %10
  %1640 = add <4 x i32> %1636, %10
  %1641 = add <4 x i32> %1637, %10
  %1642 = add <4 x i32> %1638, %10
  %1643 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1639, i32 %4) #8
  %1644 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1640, i32 %4) #8
  %1645 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1641, i32 %4) #8
  %1646 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1642, i32 %4) #8
  %1647 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1643, <4 x i32> %1644) #8
  %1648 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1645, <4 x i32> %1646) #8
  %1649 = shufflevector <8 x i16> %1446, <8 x i16> %1457, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1650 = shufflevector <8 x i16> %1446, <8 x i16> %1457, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1651 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1649, <8 x i16> %1495) #8
  %1652 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1650, <8 x i16> %1495) #8
  %1653 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1649, <8 x i16> %1461) #8
  %1654 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1650, <8 x i16> %1461) #8
  %1655 = add <4 x i32> %1651, %10
  %1656 = add <4 x i32> %1652, %10
  %1657 = add <4 x i32> %1653, %10
  %1658 = add <4 x i32> %1654, %10
  %1659 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1655, i32 %4) #8
  %1660 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1656, i32 %4) #8
  %1661 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1657, i32 %4) #8
  %1662 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1658, i32 %4) #8
  %1663 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1659, <4 x i32> %1660) #8
  %1664 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1661, <4 x i32> %1662) #8
  %1665 = shufflevector <8 x i16> %1449, <8 x i16> %1454, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1666 = shufflevector <8 x i16> %1449, <8 x i16> %1454, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1667 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1665, <8 x i16> %1528) #8
  %1668 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1666, <8 x i16> %1528) #8
  %1669 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1665, <8 x i16> %1531) #8
  %1670 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1666, <8 x i16> %1531) #8
  %1671 = add <4 x i32> %1667, %10
  %1672 = add <4 x i32> %1668, %10
  %1673 = add <4 x i32> %1669, %10
  %1674 = add <4 x i32> %1670, %10
  %1675 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1671, i32 %4) #8
  %1676 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1672, i32 %4) #8
  %1677 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1673, i32 %4) #8
  %1678 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1674, i32 %4) #8
  %1679 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1675, <4 x i32> %1676) #8
  %1680 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1677, <4 x i32> %1678) #8
  %1681 = shufflevector <8 x i16> %1450, <8 x i16> %1453, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1682 = shufflevector <8 x i16> %1450, <8 x i16> %1453, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1683 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1681, <8 x i16> %1562) #8
  %1684 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1682, <8 x i16> %1562) #8
  %1685 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1681, <8 x i16> %1528) #8
  %1686 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1682, <8 x i16> %1528) #8
  %1687 = add <4 x i32> %1683, %10
  %1688 = add <4 x i32> %1684, %10
  %1689 = add <4 x i32> %1685, %10
  %1690 = add <4 x i32> %1686, %10
  %1691 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1687, i32 %4) #8
  %1692 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1688, i32 %4) #8
  %1693 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1689, i32 %4) #8
  %1694 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1690, i32 %4) #8
  %1695 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1691, <4 x i32> %1692) #8
  %1696 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1693, <4 x i32> %1694) #8
  %1697 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1342, <8 x i16> %1491) #8
  %1698 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1342, <8 x i16> %1491) #8
  %1699 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1344, <8 x i16> %1475) #8
  %1700 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1344, <8 x i16> %1475) #8
  %1701 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1343, <8 x i16> %1508) #8
  %1702 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1343, <8 x i16> %1508) #8
  %1703 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1345, <8 x i16> %1524) #8
  %1704 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1345, <8 x i16> %1524) #8
  %1705 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1350, <8 x i16> %1558) #8
  %1706 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1350, <8 x i16> %1558) #8
  %1707 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1352, <8 x i16> %1542) #8
  %1708 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1352, <8 x i16> %1542) #8
  %1709 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1351, <8 x i16> %1575) #8
  %1710 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1351, <8 x i16> %1575) #8
  %1711 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1353, <8 x i16> %1591) #8
  %1712 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1353, <8 x i16> %1591) #8
  %1713 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1358, <8 x i16> %1576) #8
  %1714 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1358, <8 x i16> %1576) #8
  %1715 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1360, <8 x i16> %1592) #8
  %1716 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1360, <8 x i16> %1592) #8
  %1717 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1359, <8 x i16> %1559) #8
  %1718 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1359, <8 x i16> %1559) #8
  %1719 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1361, <8 x i16> %1543) #8
  %1720 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1361, <8 x i16> %1543) #8
  %1721 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1366, <8 x i16> %1509) #8
  %1722 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1366, <8 x i16> %1509) #8
  %1723 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1368, <8 x i16> %1525) #8
  %1724 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1368, <8 x i16> %1525) #8
  %1725 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1367, <8 x i16> %1492) #8
  %1726 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1367, <8 x i16> %1492) #8
  %1727 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1369, <8 x i16> %1476) #8
  %1728 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1369, <8 x i16> %1476) #8
  %1729 = shufflevector <8 x i16> %1625, <8 x i16> %1632, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1730 = shufflevector <8 x i16> %1625, <8 x i16> %1632, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1731 = bitcast <4 x i32> %98 to <8 x i16>
  %1732 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1729, <8 x i16> %1731) #8
  %1733 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1730, <8 x i16> %1731) #8
  %1734 = bitcast <4 x i32> %104 to <8 x i16>
  %1735 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1729, <8 x i16> %1734) #8
  %1736 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1730, <8 x i16> %1734) #8
  %1737 = add <4 x i32> %1732, %10
  %1738 = add <4 x i32> %1733, %10
  %1739 = add <4 x i32> %1735, %10
  %1740 = add <4 x i32> %1736, %10
  %1741 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1737, i32 %4) #8
  %1742 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1738, i32 %4) #8
  %1743 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1739, i32 %4) #8
  %1744 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1740, i32 %4) #8
  %1745 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1741, <4 x i32> %1742) #8
  %1746 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1743, <4 x i32> %1744) #8
  %1747 = shufflevector <8 x i16> %1626, <8 x i16> %1631, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1748 = shufflevector <8 x i16> %1626, <8 x i16> %1631, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1749 = bitcast <4 x i32> %113 to <8 x i16>
  %1750 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1747, <8 x i16> %1749) #8
  %1751 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1748, <8 x i16> %1749) #8
  %1752 = bitcast <4 x i32> %119 to <8 x i16>
  %1753 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1747, <8 x i16> %1752) #8
  %1754 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1748, <8 x i16> %1752) #8
  %1755 = add <4 x i32> %1750, %10
  %1756 = add <4 x i32> %1751, %10
  %1757 = add <4 x i32> %1753, %10
  %1758 = add <4 x i32> %1754, %10
  %1759 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1755, i32 %4) #8
  %1760 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1756, i32 %4) #8
  %1761 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1757, i32 %4) #8
  %1762 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1758, i32 %4) #8
  %1763 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1759, <4 x i32> %1760) #8
  %1764 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1761, <4 x i32> %1762) #8
  %1765 = shufflevector <8 x i16> %1627, <8 x i16> %1630, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1766 = shufflevector <8 x i16> %1627, <8 x i16> %1630, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1767 = bitcast <4 x i32> %128 to <8 x i16>
  %1768 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1765, <8 x i16> %1767) #8
  %1769 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1766, <8 x i16> %1767) #8
  %1770 = bitcast <4 x i32> %134 to <8 x i16>
  %1771 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1765, <8 x i16> %1770) #8
  %1772 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1766, <8 x i16> %1770) #8
  %1773 = add <4 x i32> %1768, %10
  %1774 = add <4 x i32> %1769, %10
  %1775 = add <4 x i32> %1771, %10
  %1776 = add <4 x i32> %1772, %10
  %1777 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1773, i32 %4) #8
  %1778 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1774, i32 %4) #8
  %1779 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1775, i32 %4) #8
  %1780 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1776, i32 %4) #8
  %1781 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1777, <4 x i32> %1778) #8
  %1782 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1779, <4 x i32> %1780) #8
  %1783 = shufflevector <8 x i16> %1628, <8 x i16> %1629, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1784 = shufflevector <8 x i16> %1628, <8 x i16> %1629, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1785 = bitcast <4 x i32> %143 to <8 x i16>
  %1786 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1783, <8 x i16> %1785) #8
  %1787 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1784, <8 x i16> %1785) #8
  %1788 = bitcast <4 x i32> %149 to <8 x i16>
  %1789 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1783, <8 x i16> %1788) #8
  %1790 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1784, <8 x i16> %1788) #8
  %1791 = add <4 x i32> %1786, %10
  %1792 = add <4 x i32> %1787, %10
  %1793 = add <4 x i32> %1789, %10
  %1794 = add <4 x i32> %1790, %10
  %1795 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1791, i32 %4) #8
  %1796 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1792, i32 %4) #8
  %1797 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1793, i32 %4) #8
  %1798 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1794, i32 %4) #8
  %1799 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1795, <4 x i32> %1796) #8
  %1800 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1797, <4 x i32> %1798) #8
  %1801 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1443, <8 x i16> %1647) #8
  %1802 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1443, <8 x i16> %1647) #8
  %1803 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1444, <8 x i16> %1663) #8
  %1804 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1444, <8 x i16> %1663) #8
  %1805 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1447, <8 x i16> %1679) #8
  %1806 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1447, <8 x i16> %1679) #8
  %1807 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1448, <8 x i16> %1695) #8
  %1808 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1448, <8 x i16> %1695) #8
  %1809 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1451, <8 x i16> %1696) #8
  %1810 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1451, <8 x i16> %1696) #8
  %1811 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1452, <8 x i16> %1680) #8
  %1812 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1452, <8 x i16> %1680) #8
  %1813 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1455, <8 x i16> %1664) #8
  %1814 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1455, <8 x i16> %1664) #8
  %1815 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1456, <8 x i16> %1648) #8
  %1816 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1456, <8 x i16> %1648) #8
  %1817 = shufflevector <8 x i16> %1699, <8 x i16> %1728, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1818 = shufflevector <8 x i16> %1699, <8 x i16> %1728, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1819 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1817, <8 x i16> %1734) #8
  %1820 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1818, <8 x i16> %1734) #8
  %1821 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1817, <8 x i16> %1731) #8
  %1822 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1818, <8 x i16> %1731) #8
  %1823 = add <4 x i32> %1819, %10
  %1824 = add <4 x i32> %1820, %10
  %1825 = add <4 x i32> %1821, %10
  %1826 = add <4 x i32> %1822, %10
  %1827 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1823, i32 %4) #8
  %1828 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1824, i32 %4) #8
  %1829 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1825, i32 %4) #8
  %1830 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1826, i32 %4) #8
  %1831 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1827, <4 x i32> %1828) #8
  %1832 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1829, <4 x i32> %1830) #8
  %1833 = shufflevector <8 x i16> %1700, <8 x i16> %1727, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1834 = shufflevector <8 x i16> %1700, <8 x i16> %1727, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1835 = bitcast <4 x i32> %155 to <8 x i16>
  %1836 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1833, <8 x i16> %1835) #8
  %1837 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1834, <8 x i16> %1835) #8
  %1838 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1833, <8 x i16> %1734) #8
  %1839 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1834, <8 x i16> %1734) #8
  %1840 = add <4 x i32> %1836, %10
  %1841 = add <4 x i32> %1837, %10
  %1842 = add <4 x i32> %1838, %10
  %1843 = add <4 x i32> %1839, %10
  %1844 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1840, i32 %4) #8
  %1845 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1841, i32 %4) #8
  %1846 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1842, i32 %4) #8
  %1847 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1843, i32 %4) #8
  %1848 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1844, <4 x i32> %1845) #8
  %1849 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1846, <4 x i32> %1847) #8
  %1850 = shufflevector <8 x i16> %1703, <8 x i16> %1724, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1851 = shufflevector <8 x i16> %1703, <8 x i16> %1724, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1852 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1850, <8 x i16> %1752) #8
  %1853 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1851, <8 x i16> %1752) #8
  %1854 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1850, <8 x i16> %1749) #8
  %1855 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1851, <8 x i16> %1749) #8
  %1856 = add <4 x i32> %1852, %10
  %1857 = add <4 x i32> %1853, %10
  %1858 = add <4 x i32> %1854, %10
  %1859 = add <4 x i32> %1855, %10
  %1860 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1856, i32 %4) #8
  %1861 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1857, i32 %4) #8
  %1862 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1858, i32 %4) #8
  %1863 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1859, i32 %4) #8
  %1864 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1860, <4 x i32> %1861) #8
  %1865 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1862, <4 x i32> %1863) #8
  %1866 = shufflevector <8 x i16> %1704, <8 x i16> %1723, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1867 = shufflevector <8 x i16> %1704, <8 x i16> %1723, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1868 = bitcast <4 x i32> %161 to <8 x i16>
  %1869 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1866, <8 x i16> %1868) #8
  %1870 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1867, <8 x i16> %1868) #8
  %1871 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1866, <8 x i16> %1752) #8
  %1872 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1867, <8 x i16> %1752) #8
  %1873 = add <4 x i32> %1869, %10
  %1874 = add <4 x i32> %1870, %10
  %1875 = add <4 x i32> %1871, %10
  %1876 = add <4 x i32> %1872, %10
  %1877 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1873, i32 %4) #8
  %1878 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1874, i32 %4) #8
  %1879 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1875, i32 %4) #8
  %1880 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1876, i32 %4) #8
  %1881 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1877, <4 x i32> %1878) #8
  %1882 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1879, <4 x i32> %1880) #8
  %1883 = shufflevector <8 x i16> %1707, <8 x i16> %1720, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1884 = shufflevector <8 x i16> %1707, <8 x i16> %1720, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1885 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1883, <8 x i16> %1770) #8
  %1886 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1884, <8 x i16> %1770) #8
  %1887 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1883, <8 x i16> %1767) #8
  %1888 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1884, <8 x i16> %1767) #8
  %1889 = add <4 x i32> %1885, %10
  %1890 = add <4 x i32> %1886, %10
  %1891 = add <4 x i32> %1887, %10
  %1892 = add <4 x i32> %1888, %10
  %1893 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1889, i32 %4) #8
  %1894 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1890, i32 %4) #8
  %1895 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1891, i32 %4) #8
  %1896 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1892, i32 %4) #8
  %1897 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1893, <4 x i32> %1894) #8
  %1898 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1895, <4 x i32> %1896) #8
  %1899 = shufflevector <8 x i16> %1708, <8 x i16> %1719, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1900 = shufflevector <8 x i16> %1708, <8 x i16> %1719, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1901 = bitcast <4 x i32> %167 to <8 x i16>
  %1902 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1899, <8 x i16> %1901) #8
  %1903 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1900, <8 x i16> %1901) #8
  %1904 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1899, <8 x i16> %1770) #8
  %1905 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1900, <8 x i16> %1770) #8
  %1906 = add <4 x i32> %1902, %10
  %1907 = add <4 x i32> %1903, %10
  %1908 = add <4 x i32> %1904, %10
  %1909 = add <4 x i32> %1905, %10
  %1910 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1906, i32 %4) #8
  %1911 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1907, i32 %4) #8
  %1912 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1908, i32 %4) #8
  %1913 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1909, i32 %4) #8
  %1914 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1910, <4 x i32> %1911) #8
  %1915 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1912, <4 x i32> %1913) #8
  %1916 = shufflevector <8 x i16> %1711, <8 x i16> %1716, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1917 = shufflevector <8 x i16> %1711, <8 x i16> %1716, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1918 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1916, <8 x i16> %1788) #8
  %1919 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1917, <8 x i16> %1788) #8
  %1920 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1916, <8 x i16> %1785) #8
  %1921 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1917, <8 x i16> %1785) #8
  %1922 = add <4 x i32> %1918, %10
  %1923 = add <4 x i32> %1919, %10
  %1924 = add <4 x i32> %1920, %10
  %1925 = add <4 x i32> %1921, %10
  %1926 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1922, i32 %4) #8
  %1927 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1923, i32 %4) #8
  %1928 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1924, i32 %4) #8
  %1929 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1925, i32 %4) #8
  %1930 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1926, <4 x i32> %1927) #8
  %1931 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1928, <4 x i32> %1929) #8
  %1932 = shufflevector <8 x i16> %1712, <8 x i16> %1715, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1933 = shufflevector <8 x i16> %1712, <8 x i16> %1715, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1934 = bitcast <4 x i32> %173 to <8 x i16>
  %1935 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1932, <8 x i16> %1934) #8
  %1936 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1933, <8 x i16> %1934) #8
  %1937 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1932, <8 x i16> %1788) #8
  %1938 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1933, <8 x i16> %1788) #8
  %1939 = add <4 x i32> %1935, %10
  %1940 = add <4 x i32> %1936, %10
  %1941 = add <4 x i32> %1937, %10
  %1942 = add <4 x i32> %1938, %10
  %1943 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1939, i32 %4) #8
  %1944 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1940, i32 %4) #8
  %1945 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1941, i32 %4) #8
  %1946 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1942, i32 %4) #8
  %1947 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1943, <4 x i32> %1944) #8
  %1948 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1945, <4 x i32> %1946) #8
  %1949 = shufflevector <8 x i16> %1801, <8 x i16> %1816, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1950 = shufflevector <8 x i16> %1801, <8 x i16> %1816, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1951 = bitcast <4 x i32> %182 to <8 x i16>
  %1952 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1949, <8 x i16> %1951) #8
  %1953 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1950, <8 x i16> %1951) #8
  %1954 = bitcast <4 x i32> %188 to <8 x i16>
  %1955 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1949, <8 x i16> %1954) #8
  %1956 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1950, <8 x i16> %1954) #8
  %1957 = add <4 x i32> %1952, %10
  %1958 = add <4 x i32> %1953, %10
  %1959 = add <4 x i32> %1955, %10
  %1960 = add <4 x i32> %1956, %10
  %1961 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1957, i32 %4) #8
  %1962 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1958, i32 %4) #8
  %1963 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1959, i32 %4) #8
  %1964 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1960, i32 %4) #8
  %1965 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1961, <4 x i32> %1962) #8
  %1966 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1963, <4 x i32> %1964) #8
  %1967 = shufflevector <8 x i16> %1802, <8 x i16> %1815, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1968 = shufflevector <8 x i16> %1802, <8 x i16> %1815, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1969 = bitcast <4 x i32> %197 to <8 x i16>
  %1970 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1967, <8 x i16> %1969) #8
  %1971 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1968, <8 x i16> %1969) #8
  %1972 = bitcast <4 x i32> %203 to <8 x i16>
  %1973 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1967, <8 x i16> %1972) #8
  %1974 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1968, <8 x i16> %1972) #8
  %1975 = add <4 x i32> %1970, %10
  %1976 = add <4 x i32> %1971, %10
  %1977 = add <4 x i32> %1973, %10
  %1978 = add <4 x i32> %1974, %10
  %1979 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1975, i32 %4) #8
  %1980 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1976, i32 %4) #8
  %1981 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1977, i32 %4) #8
  %1982 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1978, i32 %4) #8
  %1983 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1979, <4 x i32> %1980) #8
  %1984 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1981, <4 x i32> %1982) #8
  %1985 = shufflevector <8 x i16> %1803, <8 x i16> %1814, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1986 = shufflevector <8 x i16> %1803, <8 x i16> %1814, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1987 = bitcast <4 x i32> %212 to <8 x i16>
  %1988 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1985, <8 x i16> %1987) #8
  %1989 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1986, <8 x i16> %1987) #8
  %1990 = bitcast <4 x i32> %218 to <8 x i16>
  %1991 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1985, <8 x i16> %1990) #8
  %1992 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1986, <8 x i16> %1990) #8
  %1993 = add <4 x i32> %1988, %10
  %1994 = add <4 x i32> %1989, %10
  %1995 = add <4 x i32> %1991, %10
  %1996 = add <4 x i32> %1992, %10
  %1997 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1993, i32 %4) #8
  %1998 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1994, i32 %4) #8
  %1999 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1995, i32 %4) #8
  %2000 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %1996, i32 %4) #8
  %2001 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1997, <4 x i32> %1998) #8
  %2002 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %1999, <4 x i32> %2000) #8
  %2003 = shufflevector <8 x i16> %1804, <8 x i16> %1813, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2004 = shufflevector <8 x i16> %1804, <8 x i16> %1813, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2005 = bitcast <4 x i32> %227 to <8 x i16>
  %2006 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2003, <8 x i16> %2005) #8
  %2007 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2004, <8 x i16> %2005) #8
  %2008 = bitcast <4 x i32> %233 to <8 x i16>
  %2009 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2003, <8 x i16> %2008) #8
  %2010 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2004, <8 x i16> %2008) #8
  %2011 = add <4 x i32> %2006, %10
  %2012 = add <4 x i32> %2007, %10
  %2013 = add <4 x i32> %2009, %10
  %2014 = add <4 x i32> %2010, %10
  %2015 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2011, i32 %4) #8
  %2016 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2012, i32 %4) #8
  %2017 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2013, i32 %4) #8
  %2018 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2014, i32 %4) #8
  %2019 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2015, <4 x i32> %2016) #8
  %2020 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2017, <4 x i32> %2018) #8
  %2021 = shufflevector <8 x i16> %1805, <8 x i16> %1812, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2022 = shufflevector <8 x i16> %1805, <8 x i16> %1812, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2023 = bitcast <4 x i32> %242 to <8 x i16>
  %2024 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2021, <8 x i16> %2023) #8
  %2025 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2022, <8 x i16> %2023) #8
  %2026 = bitcast <4 x i32> %248 to <8 x i16>
  %2027 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2021, <8 x i16> %2026) #8
  %2028 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2022, <8 x i16> %2026) #8
  %2029 = add <4 x i32> %2024, %10
  %2030 = add <4 x i32> %2025, %10
  %2031 = add <4 x i32> %2027, %10
  %2032 = add <4 x i32> %2028, %10
  %2033 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2029, i32 %4) #8
  %2034 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2030, i32 %4) #8
  %2035 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2031, i32 %4) #8
  %2036 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2032, i32 %4) #8
  %2037 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2033, <4 x i32> %2034) #8
  %2038 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2035, <4 x i32> %2036) #8
  %2039 = shufflevector <8 x i16> %1806, <8 x i16> %1811, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2040 = shufflevector <8 x i16> %1806, <8 x i16> %1811, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2041 = bitcast <4 x i32> %257 to <8 x i16>
  %2042 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2039, <8 x i16> %2041) #8
  %2043 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2040, <8 x i16> %2041) #8
  %2044 = bitcast <4 x i32> %263 to <8 x i16>
  %2045 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2039, <8 x i16> %2044) #8
  %2046 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2040, <8 x i16> %2044) #8
  %2047 = add <4 x i32> %2042, %10
  %2048 = add <4 x i32> %2043, %10
  %2049 = add <4 x i32> %2045, %10
  %2050 = add <4 x i32> %2046, %10
  %2051 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2047, i32 %4) #8
  %2052 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2048, i32 %4) #8
  %2053 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2049, i32 %4) #8
  %2054 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2050, i32 %4) #8
  %2055 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2051, <4 x i32> %2052) #8
  %2056 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2053, <4 x i32> %2054) #8
  %2057 = shufflevector <8 x i16> %1807, <8 x i16> %1810, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2058 = shufflevector <8 x i16> %1807, <8 x i16> %1810, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2059 = bitcast <4 x i32> %272 to <8 x i16>
  %2060 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2057, <8 x i16> %2059) #8
  %2061 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2058, <8 x i16> %2059) #8
  %2062 = bitcast <4 x i32> %278 to <8 x i16>
  %2063 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2057, <8 x i16> %2062) #8
  %2064 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2058, <8 x i16> %2062) #8
  %2065 = add <4 x i32> %2060, %10
  %2066 = add <4 x i32> %2061, %10
  %2067 = add <4 x i32> %2063, %10
  %2068 = add <4 x i32> %2064, %10
  %2069 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2065, i32 %4) #8
  %2070 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2066, i32 %4) #8
  %2071 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2067, i32 %4) #8
  %2072 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2068, i32 %4) #8
  %2073 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2069, <4 x i32> %2070) #8
  %2074 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2071, <4 x i32> %2072) #8
  %2075 = shufflevector <8 x i16> %1808, <8 x i16> %1809, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2076 = shufflevector <8 x i16> %1808, <8 x i16> %1809, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2077 = bitcast <4 x i32> %287 to <8 x i16>
  %2078 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2075, <8 x i16> %2077) #8
  %2079 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2076, <8 x i16> %2077) #8
  %2080 = bitcast <4 x i32> %293 to <8 x i16>
  %2081 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2075, <8 x i16> %2080) #8
  %2082 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2076, <8 x i16> %2080) #8
  %2083 = add <4 x i32> %2078, %10
  %2084 = add <4 x i32> %2079, %10
  %2085 = add <4 x i32> %2081, %10
  %2086 = add <4 x i32> %2082, %10
  %2087 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2083, i32 %4) #8
  %2088 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2084, i32 %4) #8
  %2089 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2085, i32 %4) #8
  %2090 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2086, i32 %4) #8
  %2091 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2087, <4 x i32> %2088) #8
  %2092 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2089, <4 x i32> %2090) #8
  %2093 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1697, <8 x i16> %1831) #8
  %2094 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1697, <8 x i16> %1831) #8
  %2095 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1698, <8 x i16> %1848) #8
  %2096 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1698, <8 x i16> %1848) #8
  %2097 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1701, <8 x i16> %1864) #8
  %2098 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1701, <8 x i16> %1864) #8
  %2099 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1702, <8 x i16> %1881) #8
  %2100 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1702, <8 x i16> %1881) #8
  %2101 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1705, <8 x i16> %1897) #8
  %2102 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1705, <8 x i16> %1897) #8
  %2103 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1706, <8 x i16> %1914) #8
  %2104 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1706, <8 x i16> %1914) #8
  %2105 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1709, <8 x i16> %1930) #8
  %2106 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1709, <8 x i16> %1930) #8
  %2107 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1710, <8 x i16> %1947) #8
  %2108 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1710, <8 x i16> %1947) #8
  %2109 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1713, <8 x i16> %1948) #8
  %2110 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1713, <8 x i16> %1948) #8
  %2111 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1714, <8 x i16> %1931) #8
  %2112 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1714, <8 x i16> %1931) #8
  %2113 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1717, <8 x i16> %1915) #8
  %2114 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1717, <8 x i16> %1915) #8
  %2115 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1718, <8 x i16> %1898) #8
  %2116 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1718, <8 x i16> %1898) #8
  %2117 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1721, <8 x i16> %1882) #8
  %2118 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1721, <8 x i16> %1882) #8
  %2119 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1722, <8 x i16> %1865) #8
  %2120 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1722, <8 x i16> %1865) #8
  %2121 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1725, <8 x i16> %1849) #8
  %2122 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1725, <8 x i16> %1849) #8
  %2123 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %1726, <8 x i16> %1832) #8
  %2124 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %1726, <8 x i16> %1832) #8
  %2125 = shufflevector <8 x i16> %2093, <8 x i16> %2124, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2126 = shufflevector <8 x i16> %2093, <8 x i16> %2124, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2127 = bitcast <4 x i32> %302 to <8 x i16>
  %2128 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2125, <8 x i16> %2127) #8
  %2129 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2126, <8 x i16> %2127) #8
  %2130 = bitcast <4 x i32> %308 to <8 x i16>
  %2131 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2125, <8 x i16> %2130) #8
  %2132 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2126, <8 x i16> %2130) #8
  %2133 = add <4 x i32> %2128, %10
  %2134 = add <4 x i32> %2129, %10
  %2135 = add <4 x i32> %2131, %10
  %2136 = add <4 x i32> %2132, %10
  %2137 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2133, i32 %4) #8
  %2138 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2134, i32 %4) #8
  %2139 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2135, i32 %4) #8
  %2140 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2136, i32 %4) #8
  %2141 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2137, <4 x i32> %2138) #8
  %2142 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2139, <4 x i32> %2140) #8
  %2143 = shufflevector <8 x i16> %2094, <8 x i16> %2123, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2144 = shufflevector <8 x i16> %2094, <8 x i16> %2123, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2145 = bitcast <4 x i32> %317 to <8 x i16>
  %2146 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2143, <8 x i16> %2145) #8
  %2147 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2144, <8 x i16> %2145) #8
  %2148 = bitcast <4 x i32> %323 to <8 x i16>
  %2149 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2143, <8 x i16> %2148) #8
  %2150 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2144, <8 x i16> %2148) #8
  %2151 = add <4 x i32> %2146, %10
  %2152 = add <4 x i32> %2147, %10
  %2153 = add <4 x i32> %2149, %10
  %2154 = add <4 x i32> %2150, %10
  %2155 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2151, i32 %4) #8
  %2156 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2152, i32 %4) #8
  %2157 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2153, i32 %4) #8
  %2158 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2154, i32 %4) #8
  %2159 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2155, <4 x i32> %2156) #8
  %2160 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2157, <4 x i32> %2158) #8
  %2161 = shufflevector <8 x i16> %2095, <8 x i16> %2122, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2162 = shufflevector <8 x i16> %2095, <8 x i16> %2122, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2163 = bitcast <4 x i32> %332 to <8 x i16>
  %2164 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2161, <8 x i16> %2163) #8
  %2165 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2162, <8 x i16> %2163) #8
  %2166 = bitcast <4 x i32> %338 to <8 x i16>
  %2167 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2161, <8 x i16> %2166) #8
  %2168 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2162, <8 x i16> %2166) #8
  %2169 = add <4 x i32> %2164, %10
  %2170 = add <4 x i32> %2165, %10
  %2171 = add <4 x i32> %2167, %10
  %2172 = add <4 x i32> %2168, %10
  %2173 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2169, i32 %4) #8
  %2174 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2170, i32 %4) #8
  %2175 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2171, i32 %4) #8
  %2176 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2172, i32 %4) #8
  %2177 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2173, <4 x i32> %2174) #8
  %2178 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2175, <4 x i32> %2176) #8
  %2179 = shufflevector <8 x i16> %2096, <8 x i16> %2121, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2180 = shufflevector <8 x i16> %2096, <8 x i16> %2121, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2181 = bitcast <4 x i32> %347 to <8 x i16>
  %2182 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2179, <8 x i16> %2181) #8
  %2183 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2180, <8 x i16> %2181) #8
  %2184 = bitcast <4 x i32> %353 to <8 x i16>
  %2185 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2179, <8 x i16> %2184) #8
  %2186 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2180, <8 x i16> %2184) #8
  %2187 = add <4 x i32> %2182, %10
  %2188 = add <4 x i32> %2183, %10
  %2189 = add <4 x i32> %2185, %10
  %2190 = add <4 x i32> %2186, %10
  %2191 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2187, i32 %4) #8
  %2192 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2188, i32 %4) #8
  %2193 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2189, i32 %4) #8
  %2194 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2190, i32 %4) #8
  %2195 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2191, <4 x i32> %2192) #8
  %2196 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2193, <4 x i32> %2194) #8
  %2197 = shufflevector <8 x i16> %2097, <8 x i16> %2120, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2198 = shufflevector <8 x i16> %2097, <8 x i16> %2120, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2199 = bitcast <4 x i32> %362 to <8 x i16>
  %2200 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2197, <8 x i16> %2199) #8
  %2201 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2198, <8 x i16> %2199) #8
  %2202 = bitcast <4 x i32> %368 to <8 x i16>
  %2203 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2197, <8 x i16> %2202) #8
  %2204 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2198, <8 x i16> %2202) #8
  %2205 = add <4 x i32> %2200, %10
  %2206 = add <4 x i32> %2201, %10
  %2207 = add <4 x i32> %2203, %10
  %2208 = add <4 x i32> %2204, %10
  %2209 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2205, i32 %4) #8
  %2210 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2206, i32 %4) #8
  %2211 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2207, i32 %4) #8
  %2212 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2208, i32 %4) #8
  %2213 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2209, <4 x i32> %2210) #8
  %2214 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2211, <4 x i32> %2212) #8
  %2215 = shufflevector <8 x i16> %2098, <8 x i16> %2119, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2216 = shufflevector <8 x i16> %2098, <8 x i16> %2119, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2217 = bitcast <4 x i32> %377 to <8 x i16>
  %2218 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2215, <8 x i16> %2217) #8
  %2219 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2216, <8 x i16> %2217) #8
  %2220 = bitcast <4 x i32> %383 to <8 x i16>
  %2221 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2215, <8 x i16> %2220) #8
  %2222 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2216, <8 x i16> %2220) #8
  %2223 = add <4 x i32> %2218, %10
  %2224 = add <4 x i32> %2219, %10
  %2225 = add <4 x i32> %2221, %10
  %2226 = add <4 x i32> %2222, %10
  %2227 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2223, i32 %4) #8
  %2228 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2224, i32 %4) #8
  %2229 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2225, i32 %4) #8
  %2230 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2226, i32 %4) #8
  %2231 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2227, <4 x i32> %2228) #8
  %2232 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2229, <4 x i32> %2230) #8
  %2233 = shufflevector <8 x i16> %2099, <8 x i16> %2118, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2234 = shufflevector <8 x i16> %2099, <8 x i16> %2118, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2235 = bitcast <4 x i32> %392 to <8 x i16>
  %2236 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2233, <8 x i16> %2235) #8
  %2237 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2234, <8 x i16> %2235) #8
  %2238 = bitcast <4 x i32> %398 to <8 x i16>
  %2239 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2233, <8 x i16> %2238) #8
  %2240 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2234, <8 x i16> %2238) #8
  %2241 = add <4 x i32> %2236, %10
  %2242 = add <4 x i32> %2237, %10
  %2243 = add <4 x i32> %2239, %10
  %2244 = add <4 x i32> %2240, %10
  %2245 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2241, i32 %4) #8
  %2246 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2242, i32 %4) #8
  %2247 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2243, i32 %4) #8
  %2248 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2244, i32 %4) #8
  %2249 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2245, <4 x i32> %2246) #8
  %2250 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2247, <4 x i32> %2248) #8
  %2251 = shufflevector <8 x i16> %2100, <8 x i16> %2117, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2252 = shufflevector <8 x i16> %2100, <8 x i16> %2117, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2253 = bitcast <4 x i32> %407 to <8 x i16>
  %2254 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2251, <8 x i16> %2253) #8
  %2255 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2252, <8 x i16> %2253) #8
  %2256 = bitcast <4 x i32> %413 to <8 x i16>
  %2257 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2251, <8 x i16> %2256) #8
  %2258 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2252, <8 x i16> %2256) #8
  %2259 = add <4 x i32> %2254, %10
  %2260 = add <4 x i32> %2255, %10
  %2261 = add <4 x i32> %2257, %10
  %2262 = add <4 x i32> %2258, %10
  %2263 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2259, i32 %4) #8
  %2264 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2260, i32 %4) #8
  %2265 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2261, i32 %4) #8
  %2266 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2262, i32 %4) #8
  %2267 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2263, <4 x i32> %2264) #8
  %2268 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2265, <4 x i32> %2266) #8
  %2269 = shufflevector <8 x i16> %2101, <8 x i16> %2116, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2270 = shufflevector <8 x i16> %2101, <8 x i16> %2116, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2271 = bitcast <4 x i32> %422 to <8 x i16>
  %2272 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2269, <8 x i16> %2271) #8
  %2273 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2270, <8 x i16> %2271) #8
  %2274 = bitcast <4 x i32> %428 to <8 x i16>
  %2275 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2269, <8 x i16> %2274) #8
  %2276 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2270, <8 x i16> %2274) #8
  %2277 = add <4 x i32> %2272, %10
  %2278 = add <4 x i32> %2273, %10
  %2279 = add <4 x i32> %2275, %10
  %2280 = add <4 x i32> %2276, %10
  %2281 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2277, i32 %4) #8
  %2282 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2278, i32 %4) #8
  %2283 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2279, i32 %4) #8
  %2284 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2280, i32 %4) #8
  %2285 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2281, <4 x i32> %2282) #8
  %2286 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2283, <4 x i32> %2284) #8
  %2287 = shufflevector <8 x i16> %2102, <8 x i16> %2115, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2288 = shufflevector <8 x i16> %2102, <8 x i16> %2115, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2289 = bitcast <4 x i32> %437 to <8 x i16>
  %2290 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2287, <8 x i16> %2289) #8
  %2291 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2288, <8 x i16> %2289) #8
  %2292 = bitcast <4 x i32> %443 to <8 x i16>
  %2293 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2287, <8 x i16> %2292) #8
  %2294 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2288, <8 x i16> %2292) #8
  %2295 = add <4 x i32> %2290, %10
  %2296 = add <4 x i32> %2291, %10
  %2297 = add <4 x i32> %2293, %10
  %2298 = add <4 x i32> %2294, %10
  %2299 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2295, i32 %4) #8
  %2300 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2296, i32 %4) #8
  %2301 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2297, i32 %4) #8
  %2302 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2298, i32 %4) #8
  %2303 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2299, <4 x i32> %2300) #8
  %2304 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2301, <4 x i32> %2302) #8
  %2305 = shufflevector <8 x i16> %2103, <8 x i16> %2114, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2306 = shufflevector <8 x i16> %2103, <8 x i16> %2114, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2307 = bitcast <4 x i32> %452 to <8 x i16>
  %2308 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2305, <8 x i16> %2307) #8
  %2309 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2306, <8 x i16> %2307) #8
  %2310 = bitcast <4 x i32> %458 to <8 x i16>
  %2311 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2305, <8 x i16> %2310) #8
  %2312 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2306, <8 x i16> %2310) #8
  %2313 = add <4 x i32> %2308, %10
  %2314 = add <4 x i32> %2309, %10
  %2315 = add <4 x i32> %2311, %10
  %2316 = add <4 x i32> %2312, %10
  %2317 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2313, i32 %4) #8
  %2318 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2314, i32 %4) #8
  %2319 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2315, i32 %4) #8
  %2320 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2316, i32 %4) #8
  %2321 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2317, <4 x i32> %2318) #8
  %2322 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2319, <4 x i32> %2320) #8
  %2323 = shufflevector <8 x i16> %2104, <8 x i16> %2113, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2324 = shufflevector <8 x i16> %2104, <8 x i16> %2113, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2325 = bitcast <4 x i32> %467 to <8 x i16>
  %2326 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2323, <8 x i16> %2325) #8
  %2327 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2324, <8 x i16> %2325) #8
  %2328 = bitcast <4 x i32> %473 to <8 x i16>
  %2329 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2323, <8 x i16> %2328) #8
  %2330 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2324, <8 x i16> %2328) #8
  %2331 = add <4 x i32> %2326, %10
  %2332 = add <4 x i32> %2327, %10
  %2333 = add <4 x i32> %2329, %10
  %2334 = add <4 x i32> %2330, %10
  %2335 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2331, i32 %4) #8
  %2336 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2332, i32 %4) #8
  %2337 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2333, i32 %4) #8
  %2338 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2334, i32 %4) #8
  %2339 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2335, <4 x i32> %2336) #8
  %2340 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2337, <4 x i32> %2338) #8
  %2341 = shufflevector <8 x i16> %2105, <8 x i16> %2112, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2342 = shufflevector <8 x i16> %2105, <8 x i16> %2112, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2343 = bitcast <4 x i32> %482 to <8 x i16>
  %2344 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2341, <8 x i16> %2343) #8
  %2345 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2342, <8 x i16> %2343) #8
  %2346 = bitcast <4 x i32> %488 to <8 x i16>
  %2347 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2341, <8 x i16> %2346) #8
  %2348 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2342, <8 x i16> %2346) #8
  %2349 = add <4 x i32> %2344, %10
  %2350 = add <4 x i32> %2345, %10
  %2351 = add <4 x i32> %2347, %10
  %2352 = add <4 x i32> %2348, %10
  %2353 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2349, i32 %4) #8
  %2354 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2350, i32 %4) #8
  %2355 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2351, i32 %4) #8
  %2356 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2352, i32 %4) #8
  %2357 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2353, <4 x i32> %2354) #8
  %2358 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2355, <4 x i32> %2356) #8
  %2359 = shufflevector <8 x i16> %2106, <8 x i16> %2111, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2360 = shufflevector <8 x i16> %2106, <8 x i16> %2111, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2361 = bitcast <4 x i32> %497 to <8 x i16>
  %2362 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2359, <8 x i16> %2361) #8
  %2363 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2360, <8 x i16> %2361) #8
  %2364 = bitcast <4 x i32> %503 to <8 x i16>
  %2365 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2359, <8 x i16> %2364) #8
  %2366 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2360, <8 x i16> %2364) #8
  %2367 = add <4 x i32> %2362, %10
  %2368 = add <4 x i32> %2363, %10
  %2369 = add <4 x i32> %2365, %10
  %2370 = add <4 x i32> %2366, %10
  %2371 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2367, i32 %4) #8
  %2372 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2368, i32 %4) #8
  %2373 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2369, i32 %4) #8
  %2374 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2370, i32 %4) #8
  %2375 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2371, <4 x i32> %2372) #8
  %2376 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2373, <4 x i32> %2374) #8
  %2377 = shufflevector <8 x i16> %2107, <8 x i16> %2110, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2378 = shufflevector <8 x i16> %2107, <8 x i16> %2110, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2379 = bitcast <4 x i32> %512 to <8 x i16>
  %2380 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2377, <8 x i16> %2379) #8
  %2381 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2378, <8 x i16> %2379) #8
  %2382 = bitcast <4 x i32> %518 to <8 x i16>
  %2383 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2377, <8 x i16> %2382) #8
  %2384 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2378, <8 x i16> %2382) #8
  %2385 = add <4 x i32> %2380, %10
  %2386 = add <4 x i32> %2381, %10
  %2387 = add <4 x i32> %2383, %10
  %2388 = add <4 x i32> %2384, %10
  %2389 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2385, i32 %4) #8
  %2390 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2386, i32 %4) #8
  %2391 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2387, i32 %4) #8
  %2392 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2388, i32 %4) #8
  %2393 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2389, <4 x i32> %2390) #8
  %2394 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2391, <4 x i32> %2392) #8
  %2395 = shufflevector <8 x i16> %2108, <8 x i16> %2109, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %2396 = shufflevector <8 x i16> %2108, <8 x i16> %2109, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %2397 = bitcast <4 x i32> %527 to <8 x i16>
  %2398 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2395, <8 x i16> %2397) #8
  %2399 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2396, <8 x i16> %2397) #8
  %2400 = bitcast <4 x i32> %533 to <8 x i16>
  %2401 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2395, <8 x i16> %2400) #8
  %2402 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %2396, <8 x i16> %2400) #8
  %2403 = add <4 x i32> %2398, %10
  %2404 = add <4 x i32> %2399, %10
  %2405 = add <4 x i32> %2401, %10
  %2406 = add <4 x i32> %2402, %10
  %2407 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2403, i32 %4) #8
  %2408 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2404, i32 %4) #8
  %2409 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2405, i32 %4) #8
  %2410 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %2406, i32 %4) #8
  %2411 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2407, <4 x i32> %2408) #8
  %2412 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %2409, <4 x i32> %2410) #8
  %2413 = bitcast <2 x i64>* %1 to <8 x i16>*
  store <8 x i16> %1389, <8 x i16>* %2413, align 16
  %2414 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %2415 = bitcast <2 x i64>* %2414 to <8 x i16>*
  store <8 x i16> %2141, <8 x i16>* %2415, align 16
  %2416 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %2417 = bitcast <2 x i64>* %2416 to <8 x i16>*
  store <8 x i16> %1965, <8 x i16>* %2417, align 16
  %2418 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %2419 = bitcast <2 x i64>* %2418 to <8 x i16>*
  store <8 x i16> %2412, <8 x i16>* %2419, align 16
  %2420 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %2421 = bitcast <2 x i64>* %2420 to <8 x i16>*
  store <8 x i16> %1745, <8 x i16>* %2421, align 16
  %2422 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %2423 = bitcast <2 x i64>* %2422 to <8 x i16>*
  store <8 x i16> %2285, <8 x i16>* %2423, align 16
  %2424 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %2425 = bitcast <2 x i64>* %2424 to <8 x i16>*
  store <8 x i16> %2092, <8 x i16>* %2425, align 16
  %2426 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %2427 = bitcast <2 x i64>* %2426 to <8 x i16>*
  store <8 x i16> %2268, <8 x i16>* %2427, align 16
  %2428 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 8
  %2429 = bitcast <2 x i64>* %2428 to <8 x i16>*
  store <8 x i16> %1607, <8 x i16>* %2429, align 16
  %2430 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 9
  %2431 = bitcast <2 x i64>* %2430 to <8 x i16>*
  store <8 x i16> %2213, <8 x i16>* %2431, align 16
  %2432 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 10
  %2433 = bitcast <2 x i64>* %2432 to <8 x i16>*
  store <8 x i16> %2037, <8 x i16>* %2433, align 16
  %2434 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 11
  %2435 = bitcast <2 x i64>* %2434 to <8 x i16>*
  store <8 x i16> %2340, <8 x i16>* %2435, align 16
  %2436 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 12
  %2437 = bitcast <2 x i64>* %2436 to <8 x i16>*
  store <8 x i16> %1800, <8 x i16>* %2437, align 16
  %2438 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 13
  %2439 = bitcast <2 x i64>* %2438 to <8 x i16>*
  store <8 x i16> %2357, <8 x i16>* %2439, align 16
  %2440 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 14
  %2441 = bitcast <2 x i64>* %2440 to <8 x i16>*
  store <8 x i16> %2020, <8 x i16>* %2441, align 16
  %2442 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 15
  %2443 = bitcast <2 x i64>* %2442 to <8 x i16>*
  store <8 x i16> %2196, <8 x i16>* %2443, align 16
  %2444 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 16
  %2445 = bitcast <2 x i64>* %2444 to <8 x i16>*
  store <8 x i16> %1405, <8 x i16>* %2445, align 16
  %2446 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 17
  %2447 = bitcast <2 x i64>* %2446 to <8 x i16>*
  store <8 x i16> %2177, <8 x i16>* %2447, align 16
  %2448 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 18
  %2449 = bitcast <2 x i64>* %2448 to <8 x i16>*
  store <8 x i16> %2001, <8 x i16>* %2449, align 16
  %2450 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 19
  %2451 = bitcast <2 x i64>* %2450 to <8 x i16>*
  store <8 x i16> %2376, <8 x i16>* %2451, align 16
  %2452 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 20
  %2453 = bitcast <2 x i64>* %2452 to <8 x i16>*
  store <8 x i16> %1781, <8 x i16>* %2453, align 16
  %2454 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 21
  %2455 = bitcast <2 x i64>* %2454 to <8 x i16>*
  store <8 x i16> %2321, <8 x i16>* %2455, align 16
  %2456 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 22
  %2457 = bitcast <2 x i64>* %2456 to <8 x i16>*
  store <8 x i16> %2056, <8 x i16>* %2457, align 16
  %2458 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 23
  %2459 = bitcast <2 x i64>* %2458 to <8 x i16>*
  store <8 x i16> %2232, <8 x i16>* %2459, align 16
  %2460 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 24
  %2461 = bitcast <2 x i64>* %2460 to <8 x i16>*
  store <8 x i16> %1624, <8 x i16>* %2461, align 16
  %2462 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 25
  %2463 = bitcast <2 x i64>* %2462 to <8 x i16>*
  store <8 x i16> %2249, <8 x i16>* %2463, align 16
  %2464 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 26
  %2465 = bitcast <2 x i64>* %2464 to <8 x i16>*
  store <8 x i16> %2073, <8 x i16>* %2465, align 16
  %2466 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 27
  %2467 = bitcast <2 x i64>* %2466 to <8 x i16>*
  store <8 x i16> %2304, <8 x i16>* %2467, align 16
  %2468 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 28
  %2469 = bitcast <2 x i64>* %2468 to <8 x i16>*
  store <8 x i16> %1764, <8 x i16>* %2469, align 16
  %2470 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 29
  %2471 = bitcast <2 x i64>* %2470 to <8 x i16>*
  store <8 x i16> %2393, <8 x i16>* %2471, align 16
  %2472 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 30
  %2473 = bitcast <2 x i64>* %2472 to <8 x i16>*
  store <8 x i16> %1984, <8 x i16>* %2473, align 16
  %2474 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 31
  %2475 = bitcast <2 x i64>* %2474 to <8 x i16>*
  store <8 x i16> %2160, <8 x i16>* %2475, align 16
  %2476 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 32
  %2477 = bitcast <2 x i64>* %2476 to <8 x i16>*
  store <8 x i16> %1390, <8 x i16>* %2477, align 16
  %2478 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 33
  %2479 = bitcast <2 x i64>* %2478 to <8 x i16>*
  store <8 x i16> %2159, <8 x i16>* %2479, align 16
  %2480 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 34
  %2481 = bitcast <2 x i64>* %2480 to <8 x i16>*
  store <8 x i16> %1983, <8 x i16>* %2481, align 16
  %2482 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 35
  %2483 = bitcast <2 x i64>* %2482 to <8 x i16>*
  store <8 x i16> %2394, <8 x i16>* %2483, align 16
  %2484 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 36
  %2485 = bitcast <2 x i64>* %2484 to <8 x i16>*
  store <8 x i16> %1763, <8 x i16>* %2485, align 16
  %2486 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 37
  %2487 = bitcast <2 x i64>* %2486 to <8 x i16>*
  store <8 x i16> %2303, <8 x i16>* %2487, align 16
  %2488 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 38
  %2489 = bitcast <2 x i64>* %2488 to <8 x i16>*
  store <8 x i16> %2074, <8 x i16>* %2489, align 16
  %2490 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 39
  %2491 = bitcast <2 x i64>* %2490 to <8 x i16>*
  store <8 x i16> %2250, <8 x i16>* %2491, align 16
  %2492 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 40
  %2493 = bitcast <2 x i64>* %2492 to <8 x i16>*
  store <8 x i16> %1623, <8 x i16>* %2493, align 16
  %2494 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 41
  %2495 = bitcast <2 x i64>* %2494 to <8 x i16>*
  store <8 x i16> %2231, <8 x i16>* %2495, align 16
  %2496 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 42
  %2497 = bitcast <2 x i64>* %2496 to <8 x i16>*
  store <8 x i16> %2055, <8 x i16>* %2497, align 16
  %2498 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 43
  %2499 = bitcast <2 x i64>* %2498 to <8 x i16>*
  store <8 x i16> %2322, <8 x i16>* %2499, align 16
  %2500 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 44
  %2501 = bitcast <2 x i64>* %2500 to <8 x i16>*
  store <8 x i16> %1782, <8 x i16>* %2501, align 16
  %2502 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 45
  %2503 = bitcast <2 x i64>* %2502 to <8 x i16>*
  store <8 x i16> %2375, <8 x i16>* %2503, align 16
  %2504 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 46
  %2505 = bitcast <2 x i64>* %2504 to <8 x i16>*
  store <8 x i16> %2002, <8 x i16>* %2505, align 16
  %2506 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 47
  %2507 = bitcast <2 x i64>* %2506 to <8 x i16>*
  store <8 x i16> %2178, <8 x i16>* %2507, align 16
  %2508 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 48
  %2509 = bitcast <2 x i64>* %2508 to <8 x i16>*
  store <8 x i16> %1406, <8 x i16>* %2509, align 16
  %2510 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 49
  %2511 = bitcast <2 x i64>* %2510 to <8 x i16>*
  store <8 x i16> %2195, <8 x i16>* %2511, align 16
  %2512 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 50
  %2513 = bitcast <2 x i64>* %2512 to <8 x i16>*
  store <8 x i16> %2019, <8 x i16>* %2513, align 16
  %2514 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 51
  %2515 = bitcast <2 x i64>* %2514 to <8 x i16>*
  store <8 x i16> %2358, <8 x i16>* %2515, align 16
  %2516 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 52
  %2517 = bitcast <2 x i64>* %2516 to <8 x i16>*
  store <8 x i16> %1799, <8 x i16>* %2517, align 16
  %2518 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 53
  %2519 = bitcast <2 x i64>* %2518 to <8 x i16>*
  store <8 x i16> %2339, <8 x i16>* %2519, align 16
  %2520 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 54
  %2521 = bitcast <2 x i64>* %2520 to <8 x i16>*
  store <8 x i16> %2038, <8 x i16>* %2521, align 16
  %2522 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 55
  %2523 = bitcast <2 x i64>* %2522 to <8 x i16>*
  store <8 x i16> %2214, <8 x i16>* %2523, align 16
  %2524 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 56
  %2525 = bitcast <2 x i64>* %2524 to <8 x i16>*
  store <8 x i16> %1608, <8 x i16>* %2525, align 16
  %2526 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 57
  %2527 = bitcast <2 x i64>* %2526 to <8 x i16>*
  store <8 x i16> %2267, <8 x i16>* %2527, align 16
  %2528 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 58
  %2529 = bitcast <2 x i64>* %2528 to <8 x i16>*
  store <8 x i16> %2091, <8 x i16>* %2529, align 16
  %2530 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 59
  %2531 = bitcast <2 x i64>* %2530 to <8 x i16>*
  store <8 x i16> %2286, <8 x i16>* %2531, align 16
  %2532 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 60
  %2533 = bitcast <2 x i64>* %2532 to <8 x i16>*
  store <8 x i16> %1746, <8 x i16>* %2533, align 16
  %2534 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 61
  %2535 = bitcast <2 x i64>* %2534 to <8 x i16>*
  store <8 x i16> %2411, <8 x i16>* %2535, align 16
  %2536 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 62
  %2537 = bitcast <2 x i64>* %2536 to <8 x i16>*
  store <8 x i16> %1966, <8 x i16>* %2537, align 16
  %2538 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 63
  %2539 = bitcast <2 x i64>* %2538 to <8 x i16>*
  store <8 x i16> %2142, <8 x i16>* %2539, align 16
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @av1_lowbd_fwd_txfm2d_4x4_sse2(i16* nocapture readonly, i32* nocapture, i32, i8 zeroext, i32) #2 {
  %6 = alloca [4 x <2 x i64>], align 16
  %7 = alloca [4 x <2 x i64>], align 16
  %8 = bitcast [4 x <2 x i64>]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %8) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %8, i8 -86, i64 64, i1 false)
  %9 = bitcast [4 x <2 x i64>]* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %9) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 64, i1 false)
  %10 = load i8*, i8** getelementptr inbounds ([19 x i8*], [19 x i8*]* @av1_fwd_txfm_shift_ls, i64 0, i64 0), align 16
  %11 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_fwd_cos_bit_col, i64 0, i64 0, i64 0), align 16
  %12 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_fwd_cos_bit_row, i64 0, i64 0, i64 0), align 16
  %13 = zext i8 %3 to i64
  %14 = getelementptr inbounds [16 x void (<2 x i64>*, <2 x i64>*, i8)*], [16 x void (<2 x i64>*, <2 x i64>*, i8)*]* @col_txfm4x4_arr, i64 0, i64 %13
  %15 = load void (<2 x i64>*, <2 x i64>*, i8)*, void (<2 x i64>*, <2 x i64>*, i8)** %14, align 8
  %16 = getelementptr inbounds [16 x void (<2 x i64>*, <2 x i64>*, i8)*], [16 x void (<2 x i64>*, <2 x i64>*, i8)*]* @row_txfm4x4_arr, i64 0, i64 %13
  %17 = load void (<2 x i64>*, <2 x i64>*, i8)*, void (<2 x i64>*, <2 x i64>*, i8)** %16, align 8
  switch i8 %3, label %44 [
    i8 6, label %19
    i8 15, label %18
    i8 7, label %18
    i8 5, label %18
    i8 14, label %20
    i8 8, label %20
    i8 4, label %20
  ]

18:                                               ; preds = %5, %5, %5
  br label %44

19:                                               ; preds = %5
  br label %20

20:                                               ; preds = %5, %5, %5, %19
  %21 = phi i32 [ 1, %19 ], [ 0, %5 ], [ 0, %5 ], [ 0, %5 ]
  %22 = sext i32 %2 to i64
  %23 = bitcast i16* %0 to i64*
  %24 = load i64, i64* %23, align 1
  %25 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %24, i32 0
  %26 = getelementptr inbounds [4 x <2 x i64>], [4 x <2 x i64>]* %6, i64 0, i64 3
  store <2 x i64> %25, <2 x i64>* %26, align 16
  %27 = getelementptr inbounds i16, i16* %0, i64 %22
  %28 = bitcast i16* %27 to i64*
  %29 = load i64, i64* %28, align 1
  %30 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %29, i32 0
  %31 = getelementptr inbounds [4 x <2 x i64>], [4 x <2 x i64>]* %6, i64 0, i64 2
  store <2 x i64> %30, <2 x i64>* %31, align 16
  %32 = shl nsw i64 %22, 1
  %33 = getelementptr inbounds i16, i16* %0, i64 %32
  %34 = bitcast i16* %33 to i64*
  %35 = load i64, i64* %34, align 1
  %36 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %35, i32 0
  %37 = getelementptr inbounds [4 x <2 x i64>], [4 x <2 x i64>]* %6, i64 0, i64 1
  store <2 x i64> %36, <2 x i64>* %37, align 16
  %38 = mul nsw i64 %22, 3
  %39 = getelementptr inbounds i16, i16* %0, i64 %38
  %40 = bitcast i16* %39 to i64*
  %41 = load i64, i64* %40, align 1
  %42 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %41, i32 0
  %43 = getelementptr inbounds [4 x <2 x i64>], [4 x <2 x i64>]* %6, i64 0, i64 0
  store <2 x i64> %42, <2 x i64>* %43, align 16
  br label %68

44:                                               ; preds = %18, %5
  %45 = phi i32 [ 0, %5 ], [ 1, %18 ]
  %46 = sext i32 %2 to i64
  %47 = bitcast i16* %0 to i64*
  %48 = load i64, i64* %47, align 1
  %49 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %48, i32 0
  %50 = getelementptr inbounds [4 x <2 x i64>], [4 x <2 x i64>]* %6, i64 0, i64 0
  store <2 x i64> %49, <2 x i64>* %50, align 16
  %51 = getelementptr inbounds i16, i16* %0, i64 %46
  %52 = bitcast i16* %51 to i64*
  %53 = load i64, i64* %52, align 1
  %54 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %53, i32 0
  %55 = getelementptr inbounds [4 x <2 x i64>], [4 x <2 x i64>]* %6, i64 0, i64 1
  store <2 x i64> %54, <2 x i64>* %55, align 16
  %56 = shl nsw i64 %46, 1
  %57 = getelementptr inbounds i16, i16* %0, i64 %56
  %58 = bitcast i16* %57 to i64*
  %59 = load i64, i64* %58, align 1
  %60 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %59, i32 0
  %61 = getelementptr inbounds [4 x <2 x i64>], [4 x <2 x i64>]* %6, i64 0, i64 2
  store <2 x i64> %60, <2 x i64>* %61, align 16
  %62 = mul nsw i64 %46, 3
  %63 = getelementptr inbounds i16, i16* %0, i64 %62
  %64 = bitcast i16* %63 to i64*
  %65 = load i64, i64* %64, align 1
  %66 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %65, i32 0
  %67 = getelementptr inbounds [4 x <2 x i64>], [4 x <2 x i64>]* %6, i64 0, i64 3
  store <2 x i64> %66, <2 x i64>* %67, align 16
  br label %68

68:                                               ; preds = %20, %44
  %69 = phi <2 x i64> [ %66, %44 ], [ %25, %20 ]
  %70 = phi <2 x i64> [ %60, %44 ], [ %30, %20 ]
  %71 = phi <2 x i64> [ %54, %44 ], [ %36, %20 ]
  %72 = phi <2 x i64> [ %49, %44 ], [ %42, %20 ]
  %73 = phi <2 x i64>* [ %50, %44 ], [ %43, %20 ]
  %74 = phi i32 [ %45, %44 ], [ %21, %20 ]
  %75 = bitcast <2 x i64> %72 to <8 x i16>
  %76 = bitcast <2 x i64> %71 to <8 x i16>
  %77 = bitcast <2 x i64> %70 to <8 x i16>
  %78 = bitcast <2 x i64> %69 to <8 x i16>
  %79 = load i8, i8* %10, align 1
  %80 = sext i8 %79 to i32
  %81 = icmp slt i8 %79, 0
  br i1 %81, label %82, label %104

82:                                               ; preds = %68
  %83 = sub nsw i32 0, %80
  %84 = xor i32 %80, -1
  %85 = shl i32 1, %84
  %86 = trunc i32 %85 to i16
  %87 = insertelement <8 x i16> undef, i16 %86, i32 0
  %88 = shufflevector <8 x i16> %87, <8 x i16> undef, <8 x i32> zeroinitializer
  %89 = bitcast [4 x <2 x i64>]* %6 to <8 x i16>*
  %90 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %75, <8 x i16> %88) #8
  %91 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %90, i32 %83) #8
  store <8 x i16> %91, <8 x i16>* %89, align 16
  %92 = getelementptr inbounds [4 x <2 x i64>], [4 x <2 x i64>]* %6, i64 0, i64 1
  %93 = bitcast <2 x i64>* %92 to <8 x i16>*
  %94 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %76, <8 x i16> %88) #8
  %95 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %94, i32 %83) #8
  store <8 x i16> %95, <8 x i16>* %93, align 16
  %96 = getelementptr inbounds [4 x <2 x i64>], [4 x <2 x i64>]* %6, i64 0, i64 2
  %97 = bitcast <2 x i64>* %96 to <8 x i16>*
  %98 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %77, <8 x i16> %88) #8
  %99 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %98, i32 %83) #8
  store <8 x i16> %99, <8 x i16>* %97, align 16
  %100 = getelementptr inbounds [4 x <2 x i64>], [4 x <2 x i64>]* %6, i64 0, i64 3
  %101 = bitcast <2 x i64>* %100 to <8 x i16>*
  %102 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %78, <8 x i16> %88) #8
  %103 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %102, i32 %83) #8
  store <8 x i16> %103, <8 x i16>* %101, align 16
  br label %118

104:                                              ; preds = %68
  %105 = icmp eq i8 %79, 0
  br i1 %105, label %118, label %106

106:                                              ; preds = %104
  %107 = bitcast [4 x <2 x i64>]* %6 to <8 x i16>*
  %108 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %75, i32 %80) #8
  store <8 x i16> %108, <8 x i16>* %107, align 16
  %109 = getelementptr inbounds [4 x <2 x i64>], [4 x <2 x i64>]* %6, i64 0, i64 1
  %110 = bitcast <2 x i64>* %109 to <8 x i16>*
  %111 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %76, i32 %80) #8
  store <8 x i16> %111, <8 x i16>* %110, align 16
  %112 = getelementptr inbounds [4 x <2 x i64>], [4 x <2 x i64>]* %6, i64 0, i64 2
  %113 = bitcast <2 x i64>* %112 to <8 x i16>*
  %114 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %77, i32 %80) #8
  store <8 x i16> %114, <8 x i16>* %113, align 16
  %115 = getelementptr inbounds [4 x <2 x i64>], [4 x <2 x i64>]* %6, i64 0, i64 3
  %116 = bitcast <2 x i64>* %115 to <8 x i16>*
  %117 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %78, i32 %80) #8
  store <8 x i16> %117, <8 x i16>* %116, align 16
  br label %118

118:                                              ; preds = %106, %82, %104
  call void %15(<2 x i64>* %73, <2 x i64>* %73, i8 signext %11) #8
  %119 = getelementptr inbounds i8, i8* %10, i64 1
  %120 = load i8, i8* %119, align 1
  %121 = sext i8 %120 to i32
  %122 = icmp slt i8 %120, 0
  br i1 %122, label %123, label %149

123:                                              ; preds = %118
  %124 = sub nsw i32 0, %121
  %125 = xor i32 %121, -1
  %126 = shl i32 1, %125
  %127 = trunc i32 %126 to i16
  %128 = insertelement <8 x i16> undef, i16 %127, i32 0
  %129 = shufflevector <8 x i16> %128, <8 x i16> undef, <8 x i32> zeroinitializer
  %130 = bitcast [4 x <2 x i64>]* %6 to <8 x i16>*
  %131 = load <8 x i16>, <8 x i16>* %130, align 16
  %132 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %131, <8 x i16> %129) #8
  %133 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %132, i32 %124) #8
  store <8 x i16> %133, <8 x i16>* %130, align 16
  %134 = getelementptr inbounds [4 x <2 x i64>], [4 x <2 x i64>]* %6, i64 0, i64 1
  %135 = bitcast <2 x i64>* %134 to <8 x i16>*
  %136 = load <8 x i16>, <8 x i16>* %135, align 16
  %137 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %136, <8 x i16> %129) #8
  %138 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %137, i32 %124) #8
  store <8 x i16> %138, <8 x i16>* %135, align 16
  %139 = getelementptr inbounds [4 x <2 x i64>], [4 x <2 x i64>]* %6, i64 0, i64 2
  %140 = bitcast <2 x i64>* %139 to <8 x i16>*
  %141 = load <8 x i16>, <8 x i16>* %140, align 16
  %142 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %141, <8 x i16> %129) #8
  %143 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %142, i32 %124) #8
  store <8 x i16> %143, <8 x i16>* %140, align 16
  %144 = getelementptr inbounds [4 x <2 x i64>], [4 x <2 x i64>]* %6, i64 0, i64 3
  %145 = bitcast <2 x i64>* %144 to <8 x i16>*
  %146 = load <8 x i16>, <8 x i16>* %145, align 16
  %147 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %146, <8 x i16> %129) #8
  %148 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %147, i32 %124) #8
  store <8 x i16> %148, <8 x i16>* %145, align 16
  br label %179

149:                                              ; preds = %118
  %150 = icmp eq i8 %120, 0
  br i1 %150, label %151, label %163

151:                                              ; preds = %149
  %152 = bitcast <2 x i64>* %73 to <8 x i16>*
  %153 = load <8 x i16>, <8 x i16>* %152, align 16
  %154 = getelementptr inbounds [4 x <2 x i64>], [4 x <2 x i64>]* %6, i64 0, i64 1
  %155 = bitcast <2 x i64>* %154 to <8 x i16>*
  %156 = load <8 x i16>, <8 x i16>* %155, align 16
  %157 = getelementptr inbounds [4 x <2 x i64>], [4 x <2 x i64>]* %6, i64 0, i64 2
  %158 = bitcast <2 x i64>* %157 to <8 x i16>*
  %159 = load <8 x i16>, <8 x i16>* %158, align 16
  %160 = getelementptr inbounds [4 x <2 x i64>], [4 x <2 x i64>]* %6, i64 0, i64 3
  %161 = bitcast <2 x i64>* %160 to <8 x i16>*
  %162 = load <8 x i16>, <8 x i16>* %161, align 16
  br label %179

163:                                              ; preds = %149
  %164 = bitcast [4 x <2 x i64>]* %6 to <8 x i16>*
  %165 = load <8 x i16>, <8 x i16>* %164, align 16
  %166 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %165, i32 %121) #8
  store <8 x i16> %166, <8 x i16>* %164, align 16
  %167 = getelementptr inbounds [4 x <2 x i64>], [4 x <2 x i64>]* %6, i64 0, i64 1
  %168 = bitcast <2 x i64>* %167 to <8 x i16>*
  %169 = load <8 x i16>, <8 x i16>* %168, align 16
  %170 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %169, i32 %121) #8
  store <8 x i16> %170, <8 x i16>* %168, align 16
  %171 = getelementptr inbounds [4 x <2 x i64>], [4 x <2 x i64>]* %6, i64 0, i64 2
  %172 = bitcast <2 x i64>* %171 to <8 x i16>*
  %173 = load <8 x i16>, <8 x i16>* %172, align 16
  %174 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %173, i32 %121) #8
  store <8 x i16> %174, <8 x i16>* %172, align 16
  %175 = getelementptr inbounds [4 x <2 x i64>], [4 x <2 x i64>]* %6, i64 0, i64 3
  %176 = bitcast <2 x i64>* %175 to <8 x i16>*
  %177 = load <8 x i16>, <8 x i16>* %176, align 16
  %178 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %177, i32 %121) #8
  store <8 x i16> %178, <8 x i16>* %176, align 16
  br label %179

179:                                              ; preds = %151, %163, %123
  %180 = phi <8 x i16> [ %162, %151 ], [ %178, %163 ], [ %148, %123 ]
  %181 = phi <8 x i16> [ %159, %151 ], [ %174, %163 ], [ %143, %123 ]
  %182 = phi <8 x i16> [ %156, %151 ], [ %170, %163 ], [ %138, %123 ]
  %183 = phi <8 x i16> [ %153, %151 ], [ %166, %163 ], [ %133, %123 ]
  %184 = getelementptr inbounds [4 x <2 x i64>], [4 x <2 x i64>]* %7, i64 0, i64 0
  %185 = shufflevector <8 x i16> %183, <8 x i16> %182, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %186 = shufflevector <8 x i16> %181, <8 x i16> %180, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %187 = bitcast <8 x i16> %185 to <4 x i32>
  %188 = bitcast <8 x i16> %186 to <4 x i32>
  %189 = shufflevector <4 x i32> %187, <4 x i32> %188, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %190 = bitcast [4 x <2 x i64>]* %7 to <4 x i32>*
  store <4 x i32> %189, <4 x i32>* %190, align 16
  %191 = bitcast <4 x i32> %189 to <16 x i8>
  %192 = shufflevector <16 x i8> %191, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %193 = getelementptr inbounds [4 x <2 x i64>], [4 x <2 x i64>]* %7, i64 0, i64 1
  %194 = bitcast <2 x i64>* %193 to <16 x i8>*
  store <16 x i8> %192, <16 x i8>* %194, align 16
  %195 = shufflevector <4 x i32> %187, <4 x i32> %188, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %196 = getelementptr inbounds [4 x <2 x i64>], [4 x <2 x i64>]* %7, i64 0, i64 2
  %197 = bitcast <2 x i64>* %196 to <4 x i32>*
  store <4 x i32> %195, <4 x i32>* %197, align 16
  %198 = bitcast <4 x i32> %195 to <16 x i8>
  %199 = shufflevector <16 x i8> %198, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %200 = getelementptr inbounds [4 x <2 x i64>], [4 x <2 x i64>]* %7, i64 0, i64 3
  %201 = bitcast <2 x i64>* %200 to <16 x i8>*
  store <16 x i8> %199, <16 x i8>* %201, align 16
  %202 = icmp eq i32 %74, 0
  br i1 %202, label %211, label %203

203:                                              ; preds = %179
  %204 = getelementptr inbounds [4 x <2 x i64>], [4 x <2 x i64>]* %6, i64 0, i64 3
  %205 = getelementptr inbounds [4 x <2 x i64>], [4 x <2 x i64>]* %6, i64 0, i64 2
  %206 = getelementptr inbounds [4 x <2 x i64>], [4 x <2 x i64>]* %6, i64 0, i64 1
  %207 = bitcast <2 x i64>* %204 to <4 x i32>*
  store <4 x i32> %189, <4 x i32>* %207, align 16
  %208 = bitcast <2 x i64>* %205 to <16 x i8>*
  store <16 x i8> %192, <16 x i8>* %208, align 16
  %209 = bitcast <2 x i64>* %206 to <4 x i32>*
  store <4 x i32> %195, <4 x i32>* %209, align 16
  %210 = bitcast [4 x <2 x i64>]* %6 to <16 x i8>*
  store <16 x i8> %199, <16 x i8>* %210, align 16
  br label %211

211:                                              ; preds = %203, %179
  %212 = phi <2 x i64>* [ %184, %179 ], [ %73, %203 ]
  call void %17(<2 x i64>* %212, <2 x i64>* %212, i8 signext %12) #8
  %213 = getelementptr inbounds i8, i8* %10, i64 2
  %214 = load i8, i8* %213, align 1
  %215 = sext i8 %214 to i32
  %216 = icmp slt i8 %214, 0
  br i1 %216, label %217, label %243

217:                                              ; preds = %211
  %218 = sub nsw i32 0, %215
  %219 = xor i32 %215, -1
  %220 = shl i32 1, %219
  %221 = trunc i32 %220 to i16
  %222 = insertelement <8 x i16> undef, i16 %221, i32 0
  %223 = shufflevector <8 x i16> %222, <8 x i16> undef, <8 x i32> zeroinitializer
  %224 = bitcast <2 x i64>* %212 to <8 x i16>*
  %225 = load <8 x i16>, <8 x i16>* %224, align 16
  %226 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %225, <8 x i16> %223) #8
  %227 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %226, i32 %218) #8
  store <8 x i16> %227, <8 x i16>* %224, align 16
  %228 = getelementptr inbounds <2 x i64>, <2 x i64>* %212, i64 1
  %229 = bitcast <2 x i64>* %228 to <8 x i16>*
  %230 = load <8 x i16>, <8 x i16>* %229, align 16
  %231 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %230, <8 x i16> %223) #8
  %232 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %231, i32 %218) #8
  store <8 x i16> %232, <8 x i16>* %229, align 16
  %233 = getelementptr inbounds <2 x i64>, <2 x i64>* %212, i64 2
  %234 = bitcast <2 x i64>* %233 to <8 x i16>*
  %235 = load <8 x i16>, <8 x i16>* %234, align 16
  %236 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %235, <8 x i16> %223) #8
  %237 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %236, i32 %218) #8
  store <8 x i16> %237, <8 x i16>* %234, align 16
  %238 = getelementptr inbounds <2 x i64>, <2 x i64>* %212, i64 3
  %239 = bitcast <2 x i64>* %238 to <8 x i16>*
  %240 = load <8 x i16>, <8 x i16>* %239, align 16
  %241 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %240, <8 x i16> %223) #8
  %242 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %241, i32 %218) #8
  store <8 x i16> %242, <8 x i16>* %239, align 16
  br label %271

243:                                              ; preds = %211
  %244 = icmp eq i8 %214, 0
  %245 = bitcast <2 x i64>* %212 to <8 x i16>*
  %246 = load <8 x i16>, <8 x i16>* %245, align 16
  br i1 %244, label %247, label %257

247:                                              ; preds = %243
  %248 = getelementptr inbounds <2 x i64>, <2 x i64>* %212, i64 1
  %249 = bitcast <2 x i64>* %248 to <8 x i16>*
  %250 = load <8 x i16>, <8 x i16>* %249, align 16
  %251 = getelementptr inbounds <2 x i64>, <2 x i64>* %212, i64 2
  %252 = bitcast <2 x i64>* %251 to <8 x i16>*
  %253 = load <8 x i16>, <8 x i16>* %252, align 16
  %254 = getelementptr inbounds <2 x i64>, <2 x i64>* %212, i64 3
  %255 = bitcast <2 x i64>* %254 to <8 x i16>*
  %256 = load <8 x i16>, <8 x i16>* %255, align 16
  br label %271

257:                                              ; preds = %243
  %258 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %246, i32 %215) #8
  store <8 x i16> %258, <8 x i16>* %245, align 16
  %259 = getelementptr inbounds <2 x i64>, <2 x i64>* %212, i64 1
  %260 = bitcast <2 x i64>* %259 to <8 x i16>*
  %261 = load <8 x i16>, <8 x i16>* %260, align 16
  %262 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %261, i32 %215) #8
  store <8 x i16> %262, <8 x i16>* %260, align 16
  %263 = getelementptr inbounds <2 x i64>, <2 x i64>* %212, i64 2
  %264 = bitcast <2 x i64>* %263 to <8 x i16>*
  %265 = load <8 x i16>, <8 x i16>* %264, align 16
  %266 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %265, i32 %215) #8
  store <8 x i16> %266, <8 x i16>* %264, align 16
  %267 = getelementptr inbounds <2 x i64>, <2 x i64>* %212, i64 3
  %268 = bitcast <2 x i64>* %267 to <8 x i16>*
  %269 = load <8 x i16>, <8 x i16>* %268, align 16
  %270 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %269, i32 %215) #8
  store <8 x i16> %270, <8 x i16>* %268, align 16
  br label %271

271:                                              ; preds = %247, %257, %217
  %272 = phi <8 x i16> [ %256, %247 ], [ %270, %257 ], [ %242, %217 ]
  %273 = phi <8 x i16> [ %253, %247 ], [ %266, %257 ], [ %237, %217 ]
  %274 = phi <8 x i16> [ %250, %247 ], [ %262, %257 ], [ %232, %217 ]
  %275 = phi <8 x i16> [ %246, %247 ], [ %258, %257 ], [ %227, %217 ]
  %276 = getelementptr inbounds <2 x i64>, <2 x i64>* %212, i64 1
  %277 = shufflevector <8 x i16> %275, <8 x i16> %274, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %278 = getelementptr inbounds <2 x i64>, <2 x i64>* %212, i64 2
  %279 = getelementptr inbounds <2 x i64>, <2 x i64>* %212, i64 3
  %280 = shufflevector <8 x i16> %273, <8 x i16> %272, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %281 = bitcast <8 x i16> %277 to <4 x i32>
  %282 = bitcast <8 x i16> %280 to <4 x i32>
  %283 = shufflevector <4 x i32> %281, <4 x i32> %282, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %284 = bitcast <2 x i64>* %212 to <4 x i32>*
  store <4 x i32> %283, <4 x i32>* %284, align 16
  %285 = bitcast <4 x i32> %283 to <16 x i8>
  %286 = shufflevector <16 x i8> %285, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %287 = bitcast <2 x i64>* %276 to <16 x i8>*
  store <16 x i8> %286, <16 x i8>* %287, align 16
  %288 = shufflevector <4 x i32> %281, <4 x i32> %282, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %289 = bitcast <2 x i64>* %278 to <4 x i32>*
  store <4 x i32> %288, <4 x i32>* %289, align 16
  %290 = bitcast <4 x i32> %288 to <16 x i8>
  %291 = shufflevector <16 x i8> %290, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %292 = bitcast <2 x i64>* %279 to <16 x i8>*
  store <16 x i8> %291, <16 x i8>* %292, align 16
  %293 = bitcast <4 x i32> %283 to <8 x i16>
  %294 = shufflevector <8 x i16> %293, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %295 = bitcast <8 x i16> %294 to <4 x i32>
  %296 = ashr <4 x i32> %295, <i32 16, i32 16, i32 16, i32 16>
  %297 = bitcast i32* %1 to <4 x i32>*
  store <4 x i32> %296, <4 x i32>* %297, align 16
  %298 = bitcast <16 x i8> %286 to <8 x i16>
  %299 = getelementptr inbounds i32, i32* %1, i64 4
  %300 = shufflevector <8 x i16> %298, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %301 = bitcast <8 x i16> %300 to <4 x i32>
  %302 = ashr <4 x i32> %301, <i32 16, i32 16, i32 16, i32 16>
  %303 = bitcast i32* %299 to <4 x i32>*
  store <4 x i32> %302, <4 x i32>* %303, align 16
  %304 = bitcast <4 x i32> %288 to <8 x i16>
  %305 = getelementptr inbounds i32, i32* %1, i64 8
  %306 = shufflevector <8 x i16> %304, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %307 = bitcast <8 x i16> %306 to <4 x i32>
  %308 = ashr <4 x i32> %307, <i32 16, i32 16, i32 16, i32 16>
  %309 = bitcast i32* %305 to <4 x i32>*
  store <4 x i32> %308, <4 x i32>* %309, align 16
  %310 = bitcast <16 x i8> %291 to <8 x i16>
  %311 = getelementptr inbounds i32, i32* %1, i64 12
  %312 = shufflevector <8 x i16> %310, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %313 = bitcast <8 x i16> %312 to <4 x i32>
  %314 = ashr <4 x i32> %313, <i32 16, i32 16, i32 16, i32 16>
  %315 = bitcast i32* %311 to <4 x i32>*
  store <4 x i32> %314, <4 x i32>* %315, align 16
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %9) #8
  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %8) #8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @av1_lowbd_fwd_txfm2d_4x8_sse2(i16* nocapture readonly, i32* nocapture, i32, i8 zeroext, i32) #2 {
  %6 = alloca [8 x <2 x i64>], align 16
  %7 = alloca [8 x <2 x i64>], align 16
  %8 = bitcast [8 x <2 x i64>]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %8) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %8, i8 -86, i64 128, i1 false)
  %9 = bitcast [8 x <2 x i64>]* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %9) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 128, i1 false)
  %10 = load i8*, i8** getelementptr inbounds ([19 x i8*], [19 x i8*]* @av1_fwd_txfm_shift_ls, i64 0, i64 5), align 8
  %11 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_fwd_cos_bit_col, i64 0, i64 0, i64 1), align 1
  %12 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_fwd_cos_bit_row, i64 0, i64 0, i64 1), align 1
  %13 = zext i8 %3 to i64
  %14 = getelementptr inbounds [16 x void (<2 x i64>*, <2 x i64>*, i8)*], [16 x void (<2 x i64>*, <2 x i64>*, i8)*]* @col_txfm4x8_arr, i64 0, i64 %13
  %15 = load void (<2 x i64>*, <2 x i64>*, i8)*, void (<2 x i64>*, <2 x i64>*, i8)** %14, align 8
  %16 = getelementptr inbounds [16 x void (<2 x i64>*, <2 x i64>*, i8)*], [16 x void (<2 x i64>*, <2 x i64>*, i8)*]* @row_txfm8x4_arr, i64 0, i64 %13
  %17 = load void (<2 x i64>*, <2 x i64>*, i8)*, void (<2 x i64>*, <2 x i64>*, i8)** %16, align 8
  switch i8 %3, label %68 [
    i8 6, label %19
    i8 15, label %18
    i8 7, label %18
    i8 5, label %18
    i8 14, label %20
    i8 8, label %20
    i8 4, label %20
  ]

18:                                               ; preds = %5, %5, %5
  br label %68

19:                                               ; preds = %5
  br label %20

20:                                               ; preds = %5, %5, %5, %19
  %21 = phi i32 [ 1, %19 ], [ 0, %5 ], [ 0, %5 ], [ 0, %5 ]
  %22 = sext i32 %2 to i64
  %23 = bitcast i16* %0 to i64*
  %24 = load i64, i64* %23, align 1
  %25 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %24, i32 0
  %26 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 7
  store <2 x i64> %25, <2 x i64>* %26, align 16
  %27 = getelementptr inbounds i16, i16* %0, i64 %22
  %28 = bitcast i16* %27 to i64*
  %29 = load i64, i64* %28, align 1
  %30 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %29, i32 0
  %31 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 6
  store <2 x i64> %30, <2 x i64>* %31, align 16
  %32 = shl nsw i64 %22, 1
  %33 = getelementptr inbounds i16, i16* %0, i64 %32
  %34 = bitcast i16* %33 to i64*
  %35 = load i64, i64* %34, align 1
  %36 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %35, i32 0
  %37 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 5
  store <2 x i64> %36, <2 x i64>* %37, align 16
  %38 = mul nsw i64 %22, 3
  %39 = getelementptr inbounds i16, i16* %0, i64 %38
  %40 = bitcast i16* %39 to i64*
  %41 = load i64, i64* %40, align 1
  %42 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %41, i32 0
  %43 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 4
  store <2 x i64> %42, <2 x i64>* %43, align 16
  %44 = shl nsw i64 %22, 2
  %45 = getelementptr inbounds i16, i16* %0, i64 %44
  %46 = bitcast i16* %45 to i64*
  %47 = load i64, i64* %46, align 1
  %48 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %47, i32 0
  %49 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 3
  store <2 x i64> %48, <2 x i64>* %49, align 16
  %50 = mul nsw i64 %22, 5
  %51 = getelementptr inbounds i16, i16* %0, i64 %50
  %52 = bitcast i16* %51 to i64*
  %53 = load i64, i64* %52, align 1
  %54 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %53, i32 0
  %55 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 2
  store <2 x i64> %54, <2 x i64>* %55, align 16
  %56 = mul nsw i64 %22, 6
  %57 = getelementptr inbounds i16, i16* %0, i64 %56
  %58 = bitcast i16* %57 to i64*
  %59 = load i64, i64* %58, align 1
  %60 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %59, i32 0
  %61 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 1
  store <2 x i64> %60, <2 x i64>* %61, align 16
  %62 = mul nsw i64 %22, 7
  %63 = getelementptr inbounds i16, i16* %0, i64 %62
  %64 = bitcast i16* %63 to i64*
  %65 = load i64, i64* %64, align 1
  %66 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %65, i32 0
  %67 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 0
  store <2 x i64> %66, <2 x i64>* %67, align 16
  br label %116

68:                                               ; preds = %18, %5
  %69 = phi i32 [ 0, %5 ], [ 1, %18 ]
  %70 = sext i32 %2 to i64
  %71 = bitcast i16* %0 to i64*
  %72 = load i64, i64* %71, align 1
  %73 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %72, i32 0
  %74 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 0
  store <2 x i64> %73, <2 x i64>* %74, align 16
  %75 = getelementptr inbounds i16, i16* %0, i64 %70
  %76 = bitcast i16* %75 to i64*
  %77 = load i64, i64* %76, align 1
  %78 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %77, i32 0
  %79 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 1
  store <2 x i64> %78, <2 x i64>* %79, align 16
  %80 = shl nsw i64 %70, 1
  %81 = getelementptr inbounds i16, i16* %0, i64 %80
  %82 = bitcast i16* %81 to i64*
  %83 = load i64, i64* %82, align 1
  %84 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %83, i32 0
  %85 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 2
  store <2 x i64> %84, <2 x i64>* %85, align 16
  %86 = mul nsw i64 %70, 3
  %87 = getelementptr inbounds i16, i16* %0, i64 %86
  %88 = bitcast i16* %87 to i64*
  %89 = load i64, i64* %88, align 1
  %90 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %89, i32 0
  %91 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 3
  store <2 x i64> %90, <2 x i64>* %91, align 16
  %92 = shl nsw i64 %70, 2
  %93 = getelementptr inbounds i16, i16* %0, i64 %92
  %94 = bitcast i16* %93 to i64*
  %95 = load i64, i64* %94, align 1
  %96 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %95, i32 0
  %97 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 4
  store <2 x i64> %96, <2 x i64>* %97, align 16
  %98 = mul nsw i64 %70, 5
  %99 = getelementptr inbounds i16, i16* %0, i64 %98
  %100 = bitcast i16* %99 to i64*
  %101 = load i64, i64* %100, align 1
  %102 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %101, i32 0
  %103 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 5
  store <2 x i64> %102, <2 x i64>* %103, align 16
  %104 = mul nsw i64 %70, 6
  %105 = getelementptr inbounds i16, i16* %0, i64 %104
  %106 = bitcast i16* %105 to i64*
  %107 = load i64, i64* %106, align 1
  %108 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %107, i32 0
  %109 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 6
  store <2 x i64> %108, <2 x i64>* %109, align 16
  %110 = mul nsw i64 %70, 7
  %111 = getelementptr inbounds i16, i16* %0, i64 %110
  %112 = bitcast i16* %111 to i64*
  %113 = load i64, i64* %112, align 1
  %114 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %113, i32 0
  %115 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 7
  store <2 x i64> %114, <2 x i64>* %115, align 16
  br label %116

116:                                              ; preds = %20, %68
  %117 = phi <2 x i64> [ %114, %68 ], [ %25, %20 ]
  %118 = phi <2 x i64> [ %108, %68 ], [ %30, %20 ]
  %119 = phi <2 x i64> [ %102, %68 ], [ %36, %20 ]
  %120 = phi <2 x i64> [ %96, %68 ], [ %42, %20 ]
  %121 = phi <2 x i64> [ %90, %68 ], [ %48, %20 ]
  %122 = phi <2 x i64> [ %84, %68 ], [ %54, %20 ]
  %123 = phi <2 x i64> [ %78, %68 ], [ %60, %20 ]
  %124 = phi <2 x i64> [ %73, %68 ], [ %66, %20 ]
  %125 = phi <2 x i64>* [ %74, %68 ], [ %67, %20 ]
  %126 = phi i32 [ %69, %68 ], [ %21, %20 ]
  %127 = bitcast <2 x i64> %124 to <8 x i16>
  %128 = bitcast <2 x i64> %123 to <8 x i16>
  %129 = bitcast <2 x i64> %122 to <8 x i16>
  %130 = bitcast <2 x i64> %121 to <8 x i16>
  %131 = bitcast <2 x i64> %120 to <8 x i16>
  %132 = bitcast <2 x i64> %119 to <8 x i16>
  %133 = bitcast <2 x i64> %118 to <8 x i16>
  %134 = bitcast <2 x i64> %117 to <8 x i16>
  %135 = load i8, i8* %10, align 1
  %136 = sext i8 %135 to i32
  %137 = icmp slt i8 %135, 0
  br i1 %137, label %138, label %176

138:                                              ; preds = %116
  %139 = sub nsw i32 0, %136
  %140 = xor i32 %136, -1
  %141 = shl i32 1, %140
  %142 = trunc i32 %141 to i16
  %143 = insertelement <8 x i16> undef, i16 %142, i32 0
  %144 = shufflevector <8 x i16> %143, <8 x i16> undef, <8 x i32> zeroinitializer
  %145 = bitcast [8 x <2 x i64>]* %6 to <8 x i16>*
  %146 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %127, <8 x i16> %144) #8
  %147 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %146, i32 %139) #8
  store <8 x i16> %147, <8 x i16>* %145, align 16
  %148 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 1
  %149 = bitcast <2 x i64>* %148 to <8 x i16>*
  %150 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %128, <8 x i16> %144) #8
  %151 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %150, i32 %139) #8
  store <8 x i16> %151, <8 x i16>* %149, align 16
  %152 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 2
  %153 = bitcast <2 x i64>* %152 to <8 x i16>*
  %154 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %129, <8 x i16> %144) #8
  %155 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %154, i32 %139) #8
  store <8 x i16> %155, <8 x i16>* %153, align 16
  %156 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 3
  %157 = bitcast <2 x i64>* %156 to <8 x i16>*
  %158 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %130, <8 x i16> %144) #8
  %159 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %158, i32 %139) #8
  store <8 x i16> %159, <8 x i16>* %157, align 16
  %160 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 4
  %161 = bitcast <2 x i64>* %160 to <8 x i16>*
  %162 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %131, <8 x i16> %144) #8
  %163 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %162, i32 %139) #8
  store <8 x i16> %163, <8 x i16>* %161, align 16
  %164 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 5
  %165 = bitcast <2 x i64>* %164 to <8 x i16>*
  %166 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %132, <8 x i16> %144) #8
  %167 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %166, i32 %139) #8
  store <8 x i16> %167, <8 x i16>* %165, align 16
  %168 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 6
  %169 = bitcast <2 x i64>* %168 to <8 x i16>*
  %170 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %133, <8 x i16> %144) #8
  %171 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %170, i32 %139) #8
  store <8 x i16> %171, <8 x i16>* %169, align 16
  %172 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 7
  %173 = bitcast <2 x i64>* %172 to <8 x i16>*
  %174 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %134, <8 x i16> %144) #8
  %175 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %174, i32 %139) #8
  store <8 x i16> %175, <8 x i16>* %173, align 16
  br label %202

176:                                              ; preds = %116
  %177 = icmp eq i8 %135, 0
  br i1 %177, label %202, label %178

178:                                              ; preds = %176
  %179 = bitcast [8 x <2 x i64>]* %6 to <8 x i16>*
  %180 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %127, i32 %136) #8
  store <8 x i16> %180, <8 x i16>* %179, align 16
  %181 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 1
  %182 = bitcast <2 x i64>* %181 to <8 x i16>*
  %183 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %128, i32 %136) #8
  store <8 x i16> %183, <8 x i16>* %182, align 16
  %184 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 2
  %185 = bitcast <2 x i64>* %184 to <8 x i16>*
  %186 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %129, i32 %136) #8
  store <8 x i16> %186, <8 x i16>* %185, align 16
  %187 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 3
  %188 = bitcast <2 x i64>* %187 to <8 x i16>*
  %189 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %130, i32 %136) #8
  store <8 x i16> %189, <8 x i16>* %188, align 16
  %190 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 4
  %191 = bitcast <2 x i64>* %190 to <8 x i16>*
  %192 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %131, i32 %136) #8
  store <8 x i16> %192, <8 x i16>* %191, align 16
  %193 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 5
  %194 = bitcast <2 x i64>* %193 to <8 x i16>*
  %195 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %132, i32 %136) #8
  store <8 x i16> %195, <8 x i16>* %194, align 16
  %196 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 6
  %197 = bitcast <2 x i64>* %196 to <8 x i16>*
  %198 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %133, i32 %136) #8
  store <8 x i16> %198, <8 x i16>* %197, align 16
  %199 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 7
  %200 = bitcast <2 x i64>* %199 to <8 x i16>*
  %201 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %134, i32 %136) #8
  store <8 x i16> %201, <8 x i16>* %200, align 16
  br label %202

202:                                              ; preds = %178, %138, %176
  call void %15(<2 x i64>* %125, <2 x i64>* %125, i8 signext %11) #8
  %203 = getelementptr inbounds i8, i8* %10, i64 1
  %204 = load i8, i8* %203, align 1
  %205 = sext i8 %204 to i32
  %206 = icmp slt i8 %204, 0
  br i1 %206, label %207, label %253

207:                                              ; preds = %202
  %208 = sub nsw i32 0, %205
  %209 = xor i32 %205, -1
  %210 = shl i32 1, %209
  %211 = trunc i32 %210 to i16
  %212 = insertelement <8 x i16> undef, i16 %211, i32 0
  %213 = shufflevector <8 x i16> %212, <8 x i16> undef, <8 x i32> zeroinitializer
  %214 = bitcast [8 x <2 x i64>]* %6 to <8 x i16>*
  %215 = load <8 x i16>, <8 x i16>* %214, align 16
  %216 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %215, <8 x i16> %213) #8
  %217 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %216, i32 %208) #8
  store <8 x i16> %217, <8 x i16>* %214, align 16
  %218 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 1
  %219 = bitcast <2 x i64>* %218 to <8 x i16>*
  %220 = load <8 x i16>, <8 x i16>* %219, align 16
  %221 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %220, <8 x i16> %213) #8
  %222 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %221, i32 %208) #8
  store <8 x i16> %222, <8 x i16>* %219, align 16
  %223 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 2
  %224 = bitcast <2 x i64>* %223 to <8 x i16>*
  %225 = load <8 x i16>, <8 x i16>* %224, align 16
  %226 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %225, <8 x i16> %213) #8
  %227 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %226, i32 %208) #8
  store <8 x i16> %227, <8 x i16>* %224, align 16
  %228 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 3
  %229 = bitcast <2 x i64>* %228 to <8 x i16>*
  %230 = load <8 x i16>, <8 x i16>* %229, align 16
  %231 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %230, <8 x i16> %213) #8
  %232 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %231, i32 %208) #8
  store <8 x i16> %232, <8 x i16>* %229, align 16
  %233 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 4
  %234 = bitcast <2 x i64>* %233 to <8 x i16>*
  %235 = load <8 x i16>, <8 x i16>* %234, align 16
  %236 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %235, <8 x i16> %213) #8
  %237 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %236, i32 %208) #8
  store <8 x i16> %237, <8 x i16>* %234, align 16
  %238 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 5
  %239 = bitcast <2 x i64>* %238 to <8 x i16>*
  %240 = load <8 x i16>, <8 x i16>* %239, align 16
  %241 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %240, <8 x i16> %213) #8
  %242 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %241, i32 %208) #8
  store <8 x i16> %242, <8 x i16>* %239, align 16
  %243 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 6
  %244 = bitcast <2 x i64>* %243 to <8 x i16>*
  %245 = load <8 x i16>, <8 x i16>* %244, align 16
  %246 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %245, <8 x i16> %213) #8
  %247 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %246, i32 %208) #8
  store <8 x i16> %247, <8 x i16>* %244, align 16
  %248 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 7
  %249 = bitcast <2 x i64>* %248 to <8 x i16>*
  %250 = load <8 x i16>, <8 x i16>* %249, align 16
  %251 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %250, <8 x i16> %213) #8
  %252 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %251, i32 %208) #8
  store <8 x i16> %252, <8 x i16>* %249, align 16
  br label %311

253:                                              ; preds = %202
  %254 = icmp eq i8 %204, 0
  br i1 %254, label %255, label %279

255:                                              ; preds = %253
  %256 = bitcast <2 x i64>* %125 to <8 x i16>*
  %257 = load <8 x i16>, <8 x i16>* %256, align 16
  %258 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 1
  %259 = bitcast <2 x i64>* %258 to <8 x i16>*
  %260 = load <8 x i16>, <8 x i16>* %259, align 16
  %261 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 2
  %262 = bitcast <2 x i64>* %261 to <8 x i16>*
  %263 = load <8 x i16>, <8 x i16>* %262, align 16
  %264 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 3
  %265 = bitcast <2 x i64>* %264 to <8 x i16>*
  %266 = load <8 x i16>, <8 x i16>* %265, align 16
  %267 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 4
  %268 = bitcast <2 x i64>* %267 to <8 x i16>*
  %269 = load <8 x i16>, <8 x i16>* %268, align 16
  %270 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 5
  %271 = bitcast <2 x i64>* %270 to <8 x i16>*
  %272 = load <8 x i16>, <8 x i16>* %271, align 16
  %273 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 6
  %274 = bitcast <2 x i64>* %273 to <8 x i16>*
  %275 = load <8 x i16>, <8 x i16>* %274, align 16
  %276 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 7
  %277 = bitcast <2 x i64>* %276 to <8 x i16>*
  %278 = load <8 x i16>, <8 x i16>* %277, align 16
  br label %311

279:                                              ; preds = %253
  %280 = bitcast [8 x <2 x i64>]* %6 to <8 x i16>*
  %281 = load <8 x i16>, <8 x i16>* %280, align 16
  %282 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %281, i32 %205) #8
  store <8 x i16> %282, <8 x i16>* %280, align 16
  %283 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 1
  %284 = bitcast <2 x i64>* %283 to <8 x i16>*
  %285 = load <8 x i16>, <8 x i16>* %284, align 16
  %286 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %285, i32 %205) #8
  store <8 x i16> %286, <8 x i16>* %284, align 16
  %287 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 2
  %288 = bitcast <2 x i64>* %287 to <8 x i16>*
  %289 = load <8 x i16>, <8 x i16>* %288, align 16
  %290 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %289, i32 %205) #8
  store <8 x i16> %290, <8 x i16>* %288, align 16
  %291 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 3
  %292 = bitcast <2 x i64>* %291 to <8 x i16>*
  %293 = load <8 x i16>, <8 x i16>* %292, align 16
  %294 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %293, i32 %205) #8
  store <8 x i16> %294, <8 x i16>* %292, align 16
  %295 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 4
  %296 = bitcast <2 x i64>* %295 to <8 x i16>*
  %297 = load <8 x i16>, <8 x i16>* %296, align 16
  %298 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %297, i32 %205) #8
  store <8 x i16> %298, <8 x i16>* %296, align 16
  %299 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 5
  %300 = bitcast <2 x i64>* %299 to <8 x i16>*
  %301 = load <8 x i16>, <8 x i16>* %300, align 16
  %302 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %301, i32 %205) #8
  store <8 x i16> %302, <8 x i16>* %300, align 16
  %303 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 6
  %304 = bitcast <2 x i64>* %303 to <8 x i16>*
  %305 = load <8 x i16>, <8 x i16>* %304, align 16
  %306 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %305, i32 %205) #8
  store <8 x i16> %306, <8 x i16>* %304, align 16
  %307 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 7
  %308 = bitcast <2 x i64>* %307 to <8 x i16>*
  %309 = load <8 x i16>, <8 x i16>* %308, align 16
  %310 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %309, i32 %205) #8
  store <8 x i16> %310, <8 x i16>* %308, align 16
  br label %311

311:                                              ; preds = %255, %279, %207
  %312 = phi <8 x i16> [ %278, %255 ], [ %310, %279 ], [ %252, %207 ]
  %313 = phi <8 x i16> [ %275, %255 ], [ %306, %279 ], [ %247, %207 ]
  %314 = phi <8 x i16> [ %272, %255 ], [ %302, %279 ], [ %242, %207 ]
  %315 = phi <8 x i16> [ %269, %255 ], [ %298, %279 ], [ %237, %207 ]
  %316 = phi <8 x i16> [ %266, %255 ], [ %294, %279 ], [ %232, %207 ]
  %317 = phi <8 x i16> [ %263, %255 ], [ %290, %279 ], [ %227, %207 ]
  %318 = phi <8 x i16> [ %260, %255 ], [ %286, %279 ], [ %222, %207 ]
  %319 = phi <8 x i16> [ %257, %255 ], [ %282, %279 ], [ %217, %207 ]
  %320 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %7, i64 0, i64 0
  %321 = shufflevector <8 x i16> %319, <8 x i16> %318, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %322 = shufflevector <8 x i16> %317, <8 x i16> %316, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %323 = shufflevector <8 x i16> %315, <8 x i16> %314, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %324 = shufflevector <8 x i16> %313, <8 x i16> %312, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %325 = bitcast <8 x i16> %321 to <4 x i32>
  %326 = bitcast <8 x i16> %322 to <4 x i32>
  %327 = shufflevector <4 x i32> %325, <4 x i32> %326, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %328 = bitcast <4 x i32> %327 to <2 x i64>
  %329 = bitcast <8 x i16> %323 to <4 x i32>
  %330 = bitcast <8 x i16> %324 to <4 x i32>
  %331 = shufflevector <4 x i32> %329, <4 x i32> %330, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %332 = bitcast <4 x i32> %331 to <2 x i64>
  %333 = shufflevector <4 x i32> %325, <4 x i32> %326, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %334 = bitcast <4 x i32> %333 to <2 x i64>
  %335 = shufflevector <4 x i32> %329, <4 x i32> %330, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %336 = bitcast <4 x i32> %335 to <2 x i64>
  %337 = shufflevector <2 x i64> %328, <2 x i64> %332, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %337, <2 x i64>* %320, align 16
  %338 = shufflevector <2 x i64> %328, <2 x i64> %332, <2 x i32> <i32 1, i32 3>
  %339 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %7, i64 0, i64 1
  store <2 x i64> %338, <2 x i64>* %339, align 16
  %340 = shufflevector <2 x i64> %334, <2 x i64> %336, <2 x i32> <i32 0, i32 2>
  %341 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %7, i64 0, i64 2
  store <2 x i64> %340, <2 x i64>* %341, align 16
  %342 = shufflevector <2 x i64> %334, <2 x i64> %336, <2 x i32> <i32 1, i32 3>
  %343 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %7, i64 0, i64 3
  store <2 x i64> %342, <2 x i64>* %343, align 16
  %344 = icmp eq i32 %126, 0
  br i1 %344, label %350, label %345

345:                                              ; preds = %311
  %346 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 3
  %347 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 2
  %348 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 1
  store <2 x i64> %337, <2 x i64>* %346, align 16
  store <2 x i64> %338, <2 x i64>* %347, align 16
  store <2 x i64> %340, <2 x i64>* %348, align 16
  %349 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 0
  store <2 x i64> %342, <2 x i64>* %349, align 16
  br label %350

350:                                              ; preds = %345, %311
  %351 = phi <2 x i64>* [ %320, %311 ], [ %125, %345 ]
  call void %17(<2 x i64>* %351, <2 x i64>* %351, i8 signext %12) #8
  %352 = getelementptr inbounds i8, i8* %10, i64 2
  %353 = load i8, i8* %352, align 1
  %354 = sext i8 %353 to i32
  %355 = icmp slt i8 %353, 0
  br i1 %355, label %356, label %382

356:                                              ; preds = %350
  %357 = sub nsw i32 0, %354
  %358 = xor i32 %354, -1
  %359 = shl i32 1, %358
  %360 = trunc i32 %359 to i16
  %361 = insertelement <8 x i16> undef, i16 %360, i32 0
  %362 = shufflevector <8 x i16> %361, <8 x i16> undef, <8 x i32> zeroinitializer
  %363 = bitcast <2 x i64>* %351 to <8 x i16>*
  %364 = load <8 x i16>, <8 x i16>* %363, align 16
  %365 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %364, <8 x i16> %362) #8
  %366 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %365, i32 %357) #8
  store <8 x i16> %366, <8 x i16>* %363, align 16
  %367 = getelementptr inbounds <2 x i64>, <2 x i64>* %351, i64 1
  %368 = bitcast <2 x i64>* %367 to <8 x i16>*
  %369 = load <8 x i16>, <8 x i16>* %368, align 16
  %370 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %369, <8 x i16> %362) #8
  %371 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %370, i32 %357) #8
  store <8 x i16> %371, <8 x i16>* %368, align 16
  %372 = getelementptr inbounds <2 x i64>, <2 x i64>* %351, i64 2
  %373 = bitcast <2 x i64>* %372 to <8 x i16>*
  %374 = load <8 x i16>, <8 x i16>* %373, align 16
  %375 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %374, <8 x i16> %362) #8
  %376 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %375, i32 %357) #8
  store <8 x i16> %376, <8 x i16>* %373, align 16
  %377 = getelementptr inbounds <2 x i64>, <2 x i64>* %351, i64 3
  %378 = bitcast <2 x i64>* %377 to <8 x i16>*
  %379 = load <8 x i16>, <8 x i16>* %378, align 16
  %380 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %379, <8 x i16> %362) #8
  %381 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %380, i32 %357) #8
  store <8 x i16> %381, <8 x i16>* %378, align 16
  br label %410

382:                                              ; preds = %350
  %383 = icmp eq i8 %353, 0
  %384 = bitcast <2 x i64>* %351 to <8 x i16>*
  %385 = load <8 x i16>, <8 x i16>* %384, align 16
  br i1 %383, label %386, label %396

386:                                              ; preds = %382
  %387 = getelementptr inbounds <2 x i64>, <2 x i64>* %351, i64 1
  %388 = bitcast <2 x i64>* %387 to <8 x i16>*
  %389 = load <8 x i16>, <8 x i16>* %388, align 16
  %390 = getelementptr inbounds <2 x i64>, <2 x i64>* %351, i64 2
  %391 = bitcast <2 x i64>* %390 to <8 x i16>*
  %392 = load <8 x i16>, <8 x i16>* %391, align 16
  %393 = getelementptr inbounds <2 x i64>, <2 x i64>* %351, i64 3
  %394 = bitcast <2 x i64>* %393 to <8 x i16>*
  %395 = load <8 x i16>, <8 x i16>* %394, align 16
  br label %410

396:                                              ; preds = %382
  %397 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %385, i32 %354) #8
  store <8 x i16> %397, <8 x i16>* %384, align 16
  %398 = getelementptr inbounds <2 x i64>, <2 x i64>* %351, i64 1
  %399 = bitcast <2 x i64>* %398 to <8 x i16>*
  %400 = load <8 x i16>, <8 x i16>* %399, align 16
  %401 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %400, i32 %354) #8
  store <8 x i16> %401, <8 x i16>* %399, align 16
  %402 = getelementptr inbounds <2 x i64>, <2 x i64>* %351, i64 2
  %403 = bitcast <2 x i64>* %402 to <8 x i16>*
  %404 = load <8 x i16>, <8 x i16>* %403, align 16
  %405 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %404, i32 %354) #8
  store <8 x i16> %405, <8 x i16>* %403, align 16
  %406 = getelementptr inbounds <2 x i64>, <2 x i64>* %351, i64 3
  %407 = bitcast <2 x i64>* %406 to <8 x i16>*
  %408 = load <8 x i16>, <8 x i16>* %407, align 16
  %409 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %408, i32 %354) #8
  store <8 x i16> %409, <8 x i16>* %407, align 16
  br label %410

410:                                              ; preds = %386, %396, %356
  %411 = phi <8 x i16> [ %395, %386 ], [ %409, %396 ], [ %381, %356 ]
  %412 = phi <8 x i16> [ %392, %386 ], [ %405, %396 ], [ %376, %356 ]
  %413 = phi <8 x i16> [ %389, %386 ], [ %401, %396 ], [ %371, %356 ]
  %414 = phi <8 x i16> [ %385, %386 ], [ %397, %396 ], [ %366, %356 ]
  %415 = getelementptr inbounds <2 x i64>, <2 x i64>* %351, i64 1
  %416 = shufflevector <8 x i16> %414, <8 x i16> %413, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %417 = getelementptr inbounds <2 x i64>, <2 x i64>* %351, i64 2
  %418 = getelementptr inbounds <2 x i64>, <2 x i64>* %351, i64 3
  %419 = shufflevector <8 x i16> %412, <8 x i16> %411, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %420 = shufflevector <8 x i16> %414, <8 x i16> %413, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %421 = shufflevector <8 x i16> %412, <8 x i16> %411, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %422 = bitcast <8 x i16> %416 to <4 x i32>
  %423 = bitcast <8 x i16> %419 to <4 x i32>
  %424 = shufflevector <4 x i32> %422, <4 x i32> %423, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %425 = bitcast <4 x i32> %424 to <2 x i64>
  %426 = bitcast <8 x i16> %420 to <4 x i32>
  %427 = bitcast <8 x i16> %421 to <4 x i32>
  %428 = shufflevector <4 x i32> %426, <4 x i32> %427, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %429 = bitcast <4 x i32> %428 to <2 x i64>
  %430 = shufflevector <4 x i32> %422, <4 x i32> %423, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %431 = bitcast <4 x i32> %430 to <2 x i64>
  %432 = shufflevector <4 x i32> %426, <4 x i32> %427, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %433 = bitcast <4 x i32> %432 to <2 x i64>
  %434 = insertelement <2 x i64> %425, i64 0, i32 1
  store <2 x i64> %434, <2 x i64>* %351, align 16
  %435 = shufflevector <2 x i64> %425, <2 x i64> <i64 undef, i64 0>, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %435, <2 x i64>* %415, align 16
  %436 = insertelement <2 x i64> %431, i64 0, i32 1
  store <2 x i64> %436, <2 x i64>* %417, align 16
  %437 = shufflevector <2 x i64> %431, <2 x i64> <i64 undef, i64 0>, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %437, <2 x i64>* %418, align 16
  %438 = insertelement <2 x i64> %429, i64 0, i32 1
  %439 = getelementptr inbounds <2 x i64>, <2 x i64>* %351, i64 4
  store <2 x i64> %438, <2 x i64>* %439, align 16
  %440 = shufflevector <2 x i64> %429, <2 x i64> <i64 undef, i64 0>, <2 x i32> <i32 1, i32 3>
  %441 = getelementptr inbounds <2 x i64>, <2 x i64>* %351, i64 5
  store <2 x i64> %440, <2 x i64>* %441, align 16
  %442 = insertelement <2 x i64> %433, i64 0, i32 1
  %443 = getelementptr inbounds <2 x i64>, <2 x i64>* %351, i64 6
  store <2 x i64> %442, <2 x i64>* %443, align 16
  %444 = shufflevector <2 x i64> %433, <2 x i64> <i64 undef, i64 0>, <2 x i32> <i32 1, i32 3>
  %445 = getelementptr inbounds <2 x i64>, <2 x i64>* %351, i64 7
  store <2 x i64> %444, <2 x i64>* %445, align 16
  %446 = bitcast <2 x i64> %434 to <8 x i16>
  %447 = shufflevector <8 x i16> %446, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %448 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %447, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %449 = ashr <4 x i32> %448, <i32 12, i32 12, i32 12, i32 12>
  %450 = bitcast i32* %1 to <4 x i32>*
  store <4 x i32> %449, <4 x i32>* %450, align 16
  %451 = bitcast <2 x i64> %435 to <8 x i16>
  %452 = getelementptr inbounds i32, i32* %1, i64 4
  %453 = shufflevector <8 x i16> %451, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %454 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %453, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %455 = ashr <4 x i32> %454, <i32 12, i32 12, i32 12, i32 12>
  %456 = bitcast i32* %452 to <4 x i32>*
  store <4 x i32> %455, <4 x i32>* %456, align 16
  %457 = bitcast <2 x i64> %436 to <8 x i16>
  %458 = getelementptr inbounds i32, i32* %1, i64 8
  %459 = shufflevector <8 x i16> %457, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %460 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %459, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %461 = ashr <4 x i32> %460, <i32 12, i32 12, i32 12, i32 12>
  %462 = bitcast i32* %458 to <4 x i32>*
  store <4 x i32> %461, <4 x i32>* %462, align 16
  %463 = bitcast <2 x i64> %437 to <8 x i16>
  %464 = getelementptr inbounds i32, i32* %1, i64 12
  %465 = shufflevector <8 x i16> %463, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %466 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %465, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %467 = ashr <4 x i32> %466, <i32 12, i32 12, i32 12, i32 12>
  %468 = bitcast i32* %464 to <4 x i32>*
  store <4 x i32> %467, <4 x i32>* %468, align 16
  %469 = bitcast <2 x i64> %438 to <8 x i16>
  %470 = getelementptr inbounds i32, i32* %1, i64 16
  %471 = shufflevector <8 x i16> %469, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %472 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %471, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %473 = ashr <4 x i32> %472, <i32 12, i32 12, i32 12, i32 12>
  %474 = bitcast i32* %470 to <4 x i32>*
  store <4 x i32> %473, <4 x i32>* %474, align 16
  %475 = bitcast <2 x i64> %440 to <8 x i16>
  %476 = getelementptr inbounds i32, i32* %1, i64 20
  %477 = shufflevector <8 x i16> %475, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %478 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %477, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %479 = ashr <4 x i32> %478, <i32 12, i32 12, i32 12, i32 12>
  %480 = bitcast i32* %476 to <4 x i32>*
  store <4 x i32> %479, <4 x i32>* %480, align 16
  %481 = bitcast <2 x i64> %442 to <8 x i16>
  %482 = getelementptr inbounds i32, i32* %1, i64 24
  %483 = shufflevector <8 x i16> %481, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %484 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %483, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %485 = ashr <4 x i32> %484, <i32 12, i32 12, i32 12, i32 12>
  %486 = bitcast i32* %482 to <4 x i32>*
  store <4 x i32> %485, <4 x i32>* %486, align 16
  %487 = bitcast <2 x i64> %444 to <8 x i16>
  %488 = getelementptr inbounds i32, i32* %1, i64 28
  %489 = shufflevector <8 x i16> %487, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %490 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %489, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %491 = ashr <4 x i32> %490, <i32 12, i32 12, i32 12, i32 12>
  %492 = bitcast i32* %488 to <4 x i32>*
  store <4 x i32> %491, <4 x i32>* %492, align 16
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %9) #8
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %8) #8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @av1_lowbd_fwd_txfm2d_4x16_sse2(i16* nocapture readonly, i32* nocapture, i32, i8 zeroext, i32) #2 {
  %6 = alloca [16 x <2 x i64>], align 16
  %7 = alloca [16 x <2 x i64>], align 16
  %8 = bitcast [16 x <2 x i64>]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %8) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %8, i8 -86, i64 256, i1 false)
  %9 = bitcast [16 x <2 x i64>]* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %9) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 256, i1 false)
  %10 = load i8*, i8** getelementptr inbounds ([19 x i8*], [19 x i8*]* @av1_fwd_txfm_shift_ls, i64 0, i64 13), align 8
  %11 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_fwd_cos_bit_col, i64 0, i64 0, i64 2), align 2
  %12 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_fwd_cos_bit_row, i64 0, i64 0, i64 2), align 2
  %13 = zext i8 %3 to i64
  %14 = getelementptr inbounds [16 x void (<2 x i64>*, <2 x i64>*, i8)*], [16 x void (<2 x i64>*, <2 x i64>*, i8)*]* @col_txfm8x16_arr, i64 0, i64 %13
  %15 = load void (<2 x i64>*, <2 x i64>*, i8)*, void (<2 x i64>*, <2 x i64>*, i8)** %14, align 8
  %16 = getelementptr inbounds [16 x void (<2 x i64>*, <2 x i64>*, i8)*], [16 x void (<2 x i64>*, <2 x i64>*, i8)*]* @row_txfm8x4_arr, i64 0, i64 %13
  %17 = load void (<2 x i64>*, <2 x i64>*, i8)*, void (<2 x i64>*, <2 x i64>*, i8)** %16, align 8
  switch i8 %3, label %46 [
    i8 6, label %19
    i8 15, label %18
    i8 7, label %18
    i8 5, label %18
    i8 14, label %20
    i8 8, label %20
    i8 4, label %20
  ]

18:                                               ; preds = %5, %5, %5
  br label %46

19:                                               ; preds = %5
  br label %20

20:                                               ; preds = %5, %5, %5, %19
  %21 = phi i32 [ 1, %19 ], [ 0, %5 ], [ 0, %5 ], [ 0, %5 ]
  %22 = sext i32 %2 to i64
  br label %23

23:                                               ; preds = %23, %20
  %24 = phi i64 [ 0, %20 ], [ %44, %23 ]
  %25 = mul nsw i64 %24, %22
  %26 = getelementptr inbounds i16, i16* %0, i64 %25
  %27 = bitcast i16* %26 to i64*
  %28 = load i64, i64* %27, align 1
  %29 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %28, i32 0
  %30 = shl i64 %24, 32
  %31 = sub nuw nsw i64 64424509440, %30
  %32 = ashr exact i64 %31, 32
  %33 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 %32
  store <2 x i64> %29, <2 x i64>* %33, align 16
  %34 = or i64 %24, 1
  %35 = mul nsw i64 %34, %22
  %36 = getelementptr inbounds i16, i16* %0, i64 %35
  %37 = bitcast i16* %36 to i64*
  %38 = load i64, i64* %37, align 1
  %39 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %38, i32 0
  %40 = shl i64 %34, 32
  %41 = sub nuw nsw i64 64424509440, %40
  %42 = ashr exact i64 %41, 32
  %43 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 %42
  store <2 x i64> %39, <2 x i64>* %43, align 16
  %44 = add nuw nsw i64 %24, 2
  %45 = icmp eq i64 %44, 16
  br i1 %45, label %142, label %23

46:                                               ; preds = %18, %5
  %47 = phi i32 [ 0, %5 ], [ 1, %18 ]
  %48 = sext i32 %2 to i64
  %49 = bitcast i16* %0 to i64*
  %50 = load i64, i64* %49, align 1
  %51 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %50, i32 0
  %52 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 0
  store <2 x i64> %51, <2 x i64>* %52, align 16
  %53 = getelementptr inbounds i16, i16* %0, i64 %48
  %54 = bitcast i16* %53 to i64*
  %55 = load i64, i64* %54, align 1
  %56 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %55, i32 0
  %57 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 1
  store <2 x i64> %56, <2 x i64>* %57, align 16
  %58 = shl nsw i64 %48, 1
  %59 = getelementptr inbounds i16, i16* %0, i64 %58
  %60 = bitcast i16* %59 to i64*
  %61 = load i64, i64* %60, align 1
  %62 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %61, i32 0
  %63 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 2
  store <2 x i64> %62, <2 x i64>* %63, align 16
  %64 = mul nsw i64 %48, 3
  %65 = getelementptr inbounds i16, i16* %0, i64 %64
  %66 = bitcast i16* %65 to i64*
  %67 = load i64, i64* %66, align 1
  %68 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %67, i32 0
  %69 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 3
  store <2 x i64> %68, <2 x i64>* %69, align 16
  %70 = shl nsw i64 %48, 2
  %71 = getelementptr inbounds i16, i16* %0, i64 %70
  %72 = bitcast i16* %71 to i64*
  %73 = load i64, i64* %72, align 1
  %74 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %73, i32 0
  %75 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 4
  store <2 x i64> %74, <2 x i64>* %75, align 16
  %76 = mul nsw i64 %48, 5
  %77 = getelementptr inbounds i16, i16* %0, i64 %76
  %78 = bitcast i16* %77 to i64*
  %79 = load i64, i64* %78, align 1
  %80 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %79, i32 0
  %81 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 5
  store <2 x i64> %80, <2 x i64>* %81, align 16
  %82 = mul nsw i64 %48, 6
  %83 = getelementptr inbounds i16, i16* %0, i64 %82
  %84 = bitcast i16* %83 to i64*
  %85 = load i64, i64* %84, align 1
  %86 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %85, i32 0
  %87 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 6
  store <2 x i64> %86, <2 x i64>* %87, align 16
  %88 = mul nsw i64 %48, 7
  %89 = getelementptr inbounds i16, i16* %0, i64 %88
  %90 = bitcast i16* %89 to i64*
  %91 = load i64, i64* %90, align 1
  %92 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %91, i32 0
  %93 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 7
  store <2 x i64> %92, <2 x i64>* %93, align 16
  %94 = shl nsw i64 %48, 3
  %95 = getelementptr inbounds i16, i16* %0, i64 %94
  %96 = bitcast i16* %95 to i64*
  %97 = load i64, i64* %96, align 1
  %98 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %97, i32 0
  %99 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 8
  store <2 x i64> %98, <2 x i64>* %99, align 16
  %100 = mul nsw i64 %48, 9
  %101 = getelementptr inbounds i16, i16* %0, i64 %100
  %102 = bitcast i16* %101 to i64*
  %103 = load i64, i64* %102, align 1
  %104 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %103, i32 0
  %105 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 9
  store <2 x i64> %104, <2 x i64>* %105, align 16
  %106 = mul nsw i64 %48, 10
  %107 = getelementptr inbounds i16, i16* %0, i64 %106
  %108 = bitcast i16* %107 to i64*
  %109 = load i64, i64* %108, align 1
  %110 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %109, i32 0
  %111 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 10
  store <2 x i64> %110, <2 x i64>* %111, align 16
  %112 = mul nsw i64 %48, 11
  %113 = getelementptr inbounds i16, i16* %0, i64 %112
  %114 = bitcast i16* %113 to i64*
  %115 = load i64, i64* %114, align 1
  %116 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %115, i32 0
  %117 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 11
  store <2 x i64> %116, <2 x i64>* %117, align 16
  %118 = mul nsw i64 %48, 12
  %119 = getelementptr inbounds i16, i16* %0, i64 %118
  %120 = bitcast i16* %119 to i64*
  %121 = load i64, i64* %120, align 1
  %122 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %121, i32 0
  %123 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 12
  store <2 x i64> %122, <2 x i64>* %123, align 16
  %124 = mul nsw i64 %48, 13
  %125 = getelementptr inbounds i16, i16* %0, i64 %124
  %126 = bitcast i16* %125 to i64*
  %127 = load i64, i64* %126, align 1
  %128 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %127, i32 0
  %129 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 13
  store <2 x i64> %128, <2 x i64>* %129, align 16
  %130 = mul nsw i64 %48, 14
  %131 = getelementptr inbounds i16, i16* %0, i64 %130
  %132 = bitcast i16* %131 to i64*
  %133 = load i64, i64* %132, align 1
  %134 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %133, i32 0
  %135 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 14
  store <2 x i64> %134, <2 x i64>* %135, align 16
  %136 = mul nsw i64 %48, 15
  %137 = getelementptr inbounds i16, i16* %0, i64 %136
  %138 = bitcast i16* %137 to i64*
  %139 = load i64, i64* %138, align 1
  %140 = insertelement <2 x i64> <i64 undef, i64 0>, i64 %139, i32 0
  %141 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 15
  store <2 x i64> %140, <2 x i64>* %141, align 16
  br label %144

142:                                              ; preds = %23
  %143 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 0
  br label %144

144:                                              ; preds = %142, %46
  %145 = phi <2 x i64>* [ %52, %46 ], [ %143, %142 ]
  %146 = phi i32 [ %47, %46 ], [ %21, %142 ]
  %147 = load i8, i8* %10, align 1
  %148 = sext i8 %147 to i32
  %149 = icmp slt i8 %147, 0
  br i1 %149, label %150, label %236

150:                                              ; preds = %144
  %151 = sub nsw i32 0, %148
  %152 = xor i32 %148, -1
  %153 = shl i32 1, %152
  %154 = trunc i32 %153 to i16
  %155 = insertelement <8 x i16> undef, i16 %154, i32 0
  %156 = shufflevector <8 x i16> %155, <8 x i16> undef, <8 x i32> zeroinitializer
  %157 = bitcast [16 x <2 x i64>]* %6 to <8 x i16>*
  %158 = load <8 x i16>, <8 x i16>* %157, align 16
  %159 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %158, <8 x i16> %156) #8
  %160 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %159, i32 %151) #8
  store <8 x i16> %160, <8 x i16>* %157, align 16
  %161 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 1
  %162 = bitcast <2 x i64>* %161 to <8 x i16>*
  %163 = load <8 x i16>, <8 x i16>* %162, align 16
  %164 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %163, <8 x i16> %156) #8
  %165 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %164, i32 %151) #8
  store <8 x i16> %165, <8 x i16>* %162, align 16
  %166 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 2
  %167 = bitcast <2 x i64>* %166 to <8 x i16>*
  %168 = load <8 x i16>, <8 x i16>* %167, align 16
  %169 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %168, <8 x i16> %156) #8
  %170 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %169, i32 %151) #8
  store <8 x i16> %170, <8 x i16>* %167, align 16
  %171 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 3
  %172 = bitcast <2 x i64>* %171 to <8 x i16>*
  %173 = load <8 x i16>, <8 x i16>* %172, align 16
  %174 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %173, <8 x i16> %156) #8
  %175 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %174, i32 %151) #8
  store <8 x i16> %175, <8 x i16>* %172, align 16
  %176 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 4
  %177 = bitcast <2 x i64>* %176 to <8 x i16>*
  %178 = load <8 x i16>, <8 x i16>* %177, align 16
  %179 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %178, <8 x i16> %156) #8
  %180 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %179, i32 %151) #8
  store <8 x i16> %180, <8 x i16>* %177, align 16
  %181 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 5
  %182 = bitcast <2 x i64>* %181 to <8 x i16>*
  %183 = load <8 x i16>, <8 x i16>* %182, align 16
  %184 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %183, <8 x i16> %156) #8
  %185 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %184, i32 %151) #8
  store <8 x i16> %185, <8 x i16>* %182, align 16
  %186 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 6
  %187 = bitcast <2 x i64>* %186 to <8 x i16>*
  %188 = load <8 x i16>, <8 x i16>* %187, align 16
  %189 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %188, <8 x i16> %156) #8
  %190 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %189, i32 %151) #8
  store <8 x i16> %190, <8 x i16>* %187, align 16
  %191 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 7
  %192 = bitcast <2 x i64>* %191 to <8 x i16>*
  %193 = load <8 x i16>, <8 x i16>* %192, align 16
  %194 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %193, <8 x i16> %156) #8
  %195 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %194, i32 %151) #8
  store <8 x i16> %195, <8 x i16>* %192, align 16
  %196 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 8
  %197 = bitcast <2 x i64>* %196 to <8 x i16>*
  %198 = load <8 x i16>, <8 x i16>* %197, align 16
  %199 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %198, <8 x i16> %156) #8
  %200 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %199, i32 %151) #8
  store <8 x i16> %200, <8 x i16>* %197, align 16
  %201 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 9
  %202 = bitcast <2 x i64>* %201 to <8 x i16>*
  %203 = load <8 x i16>, <8 x i16>* %202, align 16
  %204 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %203, <8 x i16> %156) #8
  %205 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %204, i32 %151) #8
  store <8 x i16> %205, <8 x i16>* %202, align 16
  %206 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 10
  %207 = bitcast <2 x i64>* %206 to <8 x i16>*
  %208 = load <8 x i16>, <8 x i16>* %207, align 16
  %209 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %208, <8 x i16> %156) #8
  %210 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %209, i32 %151) #8
  store <8 x i16> %210, <8 x i16>* %207, align 16
  %211 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 11
  %212 = bitcast <2 x i64>* %211 to <8 x i16>*
  %213 = load <8 x i16>, <8 x i16>* %212, align 16
  %214 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %213, <8 x i16> %156) #8
  %215 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %214, i32 %151) #8
  store <8 x i16> %215, <8 x i16>* %212, align 16
  %216 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 12
  %217 = bitcast <2 x i64>* %216 to <8 x i16>*
  %218 = load <8 x i16>, <8 x i16>* %217, align 16
  %219 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %218, <8 x i16> %156) #8
  %220 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %219, i32 %151) #8
  store <8 x i16> %220, <8 x i16>* %217, align 16
  %221 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 13
  %222 = bitcast <2 x i64>* %221 to <8 x i16>*
  %223 = load <8 x i16>, <8 x i16>* %222, align 16
  %224 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %223, <8 x i16> %156) #8
  %225 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %224, i32 %151) #8
  store <8 x i16> %225, <8 x i16>* %222, align 16
  %226 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 14
  %227 = bitcast <2 x i64>* %226 to <8 x i16>*
  %228 = load <8 x i16>, <8 x i16>* %227, align 16
  %229 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %228, <8 x i16> %156) #8
  %230 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %229, i32 %151) #8
  store <8 x i16> %230, <8 x i16>* %227, align 16
  %231 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 15
  %232 = bitcast <2 x i64>* %231 to <8 x i16>*
  %233 = load <8 x i16>, <8 x i16>* %232, align 16
  %234 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %233, <8 x i16> %156) #8
  %235 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %234, i32 %151) #8
  store <8 x i16> %235, <8 x i16>* %232, align 16
  br label %302

236:                                              ; preds = %144
  %237 = icmp eq i8 %147, 0
  br i1 %237, label %302, label %238

238:                                              ; preds = %236
  %239 = bitcast [16 x <2 x i64>]* %6 to <8 x i16>*
  %240 = load <8 x i16>, <8 x i16>* %239, align 16
  %241 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %240, i32 %148) #8
  store <8 x i16> %241, <8 x i16>* %239, align 16
  %242 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 1
  %243 = bitcast <2 x i64>* %242 to <8 x i16>*
  %244 = load <8 x i16>, <8 x i16>* %243, align 16
  %245 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %244, i32 %148) #8
  store <8 x i16> %245, <8 x i16>* %243, align 16
  %246 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 2
  %247 = bitcast <2 x i64>* %246 to <8 x i16>*
  %248 = load <8 x i16>, <8 x i16>* %247, align 16
  %249 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %248, i32 %148) #8
  store <8 x i16> %249, <8 x i16>* %247, align 16
  %250 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 3
  %251 = bitcast <2 x i64>* %250 to <8 x i16>*
  %252 = load <8 x i16>, <8 x i16>* %251, align 16
  %253 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %252, i32 %148) #8
  store <8 x i16> %253, <8 x i16>* %251, align 16
  %254 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 4
  %255 = bitcast <2 x i64>* %254 to <8 x i16>*
  %256 = load <8 x i16>, <8 x i16>* %255, align 16
  %257 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %256, i32 %148) #8
  store <8 x i16> %257, <8 x i16>* %255, align 16
  %258 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 5
  %259 = bitcast <2 x i64>* %258 to <8 x i16>*
  %260 = load <8 x i16>, <8 x i16>* %259, align 16
  %261 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %260, i32 %148) #8
  store <8 x i16> %261, <8 x i16>* %259, align 16
  %262 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 6
  %263 = bitcast <2 x i64>* %262 to <8 x i16>*
  %264 = load <8 x i16>, <8 x i16>* %263, align 16
  %265 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %264, i32 %148) #8
  store <8 x i16> %265, <8 x i16>* %263, align 16
  %266 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 7
  %267 = bitcast <2 x i64>* %266 to <8 x i16>*
  %268 = load <8 x i16>, <8 x i16>* %267, align 16
  %269 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %268, i32 %148) #8
  store <8 x i16> %269, <8 x i16>* %267, align 16
  %270 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 8
  %271 = bitcast <2 x i64>* %270 to <8 x i16>*
  %272 = load <8 x i16>, <8 x i16>* %271, align 16
  %273 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %272, i32 %148) #8
  store <8 x i16> %273, <8 x i16>* %271, align 16
  %274 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 9
  %275 = bitcast <2 x i64>* %274 to <8 x i16>*
  %276 = load <8 x i16>, <8 x i16>* %275, align 16
  %277 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %276, i32 %148) #8
  store <8 x i16> %277, <8 x i16>* %275, align 16
  %278 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 10
  %279 = bitcast <2 x i64>* %278 to <8 x i16>*
  %280 = load <8 x i16>, <8 x i16>* %279, align 16
  %281 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %280, i32 %148) #8
  store <8 x i16> %281, <8 x i16>* %279, align 16
  %282 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 11
  %283 = bitcast <2 x i64>* %282 to <8 x i16>*
  %284 = load <8 x i16>, <8 x i16>* %283, align 16
  %285 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %284, i32 %148) #8
  store <8 x i16> %285, <8 x i16>* %283, align 16
  %286 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 12
  %287 = bitcast <2 x i64>* %286 to <8 x i16>*
  %288 = load <8 x i16>, <8 x i16>* %287, align 16
  %289 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %288, i32 %148) #8
  store <8 x i16> %289, <8 x i16>* %287, align 16
  %290 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 13
  %291 = bitcast <2 x i64>* %290 to <8 x i16>*
  %292 = load <8 x i16>, <8 x i16>* %291, align 16
  %293 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %292, i32 %148) #8
  store <8 x i16> %293, <8 x i16>* %291, align 16
  %294 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 14
  %295 = bitcast <2 x i64>* %294 to <8 x i16>*
  %296 = load <8 x i16>, <8 x i16>* %295, align 16
  %297 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %296, i32 %148) #8
  store <8 x i16> %297, <8 x i16>* %295, align 16
  %298 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 15
  %299 = bitcast <2 x i64>* %298 to <8 x i16>*
  %300 = load <8 x i16>, <8 x i16>* %299, align 16
  %301 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %300, i32 %148) #8
  store <8 x i16> %301, <8 x i16>* %299, align 16
  br label %302

302:                                              ; preds = %238, %150, %236
  call void %15(<2 x i64>* %145, <2 x i64>* %145, i8 signext %11) #8
  %303 = getelementptr inbounds i8, i8* %10, i64 1
  %304 = load i8, i8* %303, align 1
  %305 = sext i8 %304 to i32
  %306 = icmp slt i8 %304, 0
  br i1 %306, label %307, label %393

307:                                              ; preds = %302
  %308 = sub nsw i32 0, %305
  %309 = xor i32 %305, -1
  %310 = shl i32 1, %309
  %311 = trunc i32 %310 to i16
  %312 = insertelement <8 x i16> undef, i16 %311, i32 0
  %313 = shufflevector <8 x i16> %312, <8 x i16> undef, <8 x i32> zeroinitializer
  %314 = bitcast [16 x <2 x i64>]* %6 to <8 x i16>*
  %315 = load <8 x i16>, <8 x i16>* %314, align 16
  %316 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %315, <8 x i16> %313) #8
  %317 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %316, i32 %308) #8
  store <8 x i16> %317, <8 x i16>* %314, align 16
  %318 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 1
  %319 = bitcast <2 x i64>* %318 to <8 x i16>*
  %320 = load <8 x i16>, <8 x i16>* %319, align 16
  %321 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %320, <8 x i16> %313) #8
  %322 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %321, i32 %308) #8
  store <8 x i16> %322, <8 x i16>* %319, align 16
  %323 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 2
  %324 = bitcast <2 x i64>* %323 to <8 x i16>*
  %325 = load <8 x i16>, <8 x i16>* %324, align 16
  %326 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %325, <8 x i16> %313) #8
  %327 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %326, i32 %308) #8
  store <8 x i16> %327, <8 x i16>* %324, align 16
  %328 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 3
  %329 = bitcast <2 x i64>* %328 to <8 x i16>*
  %330 = load <8 x i16>, <8 x i16>* %329, align 16
  %331 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %330, <8 x i16> %313) #8
  %332 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %331, i32 %308) #8
  store <8 x i16> %332, <8 x i16>* %329, align 16
  %333 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 4
  %334 = bitcast <2 x i64>* %333 to <8 x i16>*
  %335 = load <8 x i16>, <8 x i16>* %334, align 16
  %336 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %335, <8 x i16> %313) #8
  %337 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %336, i32 %308) #8
  store <8 x i16> %337, <8 x i16>* %334, align 16
  %338 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 5
  %339 = bitcast <2 x i64>* %338 to <8 x i16>*
  %340 = load <8 x i16>, <8 x i16>* %339, align 16
  %341 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %340, <8 x i16> %313) #8
  %342 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %341, i32 %308) #8
  store <8 x i16> %342, <8 x i16>* %339, align 16
  %343 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 6
  %344 = bitcast <2 x i64>* %343 to <8 x i16>*
  %345 = load <8 x i16>, <8 x i16>* %344, align 16
  %346 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %345, <8 x i16> %313) #8
  %347 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %346, i32 %308) #8
  store <8 x i16> %347, <8 x i16>* %344, align 16
  %348 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 7
  %349 = bitcast <2 x i64>* %348 to <8 x i16>*
  %350 = load <8 x i16>, <8 x i16>* %349, align 16
  %351 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %350, <8 x i16> %313) #8
  %352 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %351, i32 %308) #8
  store <8 x i16> %352, <8 x i16>* %349, align 16
  %353 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 8
  %354 = bitcast <2 x i64>* %353 to <8 x i16>*
  %355 = load <8 x i16>, <8 x i16>* %354, align 16
  %356 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %355, <8 x i16> %313) #8
  %357 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %356, i32 %308) #8
  store <8 x i16> %357, <8 x i16>* %354, align 16
  %358 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 9
  %359 = bitcast <2 x i64>* %358 to <8 x i16>*
  %360 = load <8 x i16>, <8 x i16>* %359, align 16
  %361 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %360, <8 x i16> %313) #8
  %362 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %361, i32 %308) #8
  store <8 x i16> %362, <8 x i16>* %359, align 16
  %363 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 10
  %364 = bitcast <2 x i64>* %363 to <8 x i16>*
  %365 = load <8 x i16>, <8 x i16>* %364, align 16
  %366 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %365, <8 x i16> %313) #8
  %367 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %366, i32 %308) #8
  store <8 x i16> %367, <8 x i16>* %364, align 16
  %368 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 11
  %369 = bitcast <2 x i64>* %368 to <8 x i16>*
  %370 = load <8 x i16>, <8 x i16>* %369, align 16
  %371 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %370, <8 x i16> %313) #8
  %372 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %371, i32 %308) #8
  store <8 x i16> %372, <8 x i16>* %369, align 16
  %373 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 12
  %374 = bitcast <2 x i64>* %373 to <8 x i16>*
  %375 = load <8 x i16>, <8 x i16>* %374, align 16
  %376 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %375, <8 x i16> %313) #8
  %377 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %376, i32 %308) #8
  store <8 x i16> %377, <8 x i16>* %374, align 16
  %378 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 13
  %379 = bitcast <2 x i64>* %378 to <8 x i16>*
  %380 = load <8 x i16>, <8 x i16>* %379, align 16
  %381 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %380, <8 x i16> %313) #8
  %382 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %381, i32 %308) #8
  store <8 x i16> %382, <8 x i16>* %379, align 16
  %383 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 14
  %384 = bitcast <2 x i64>* %383 to <8 x i16>*
  %385 = load <8 x i16>, <8 x i16>* %384, align 16
  %386 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %385, <8 x i16> %313) #8
  %387 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %386, i32 %308) #8
  store <8 x i16> %387, <8 x i16>* %384, align 16
  %388 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 15
  %389 = bitcast <2 x i64>* %388 to <8 x i16>*
  %390 = load <8 x i16>, <8 x i16>* %389, align 16
  %391 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %390, <8 x i16> %313) #8
  %392 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %391, i32 %308) #8
  store <8 x i16> %392, <8 x i16>* %389, align 16
  br label %507

393:                                              ; preds = %302
  %394 = icmp eq i8 %304, 0
  br i1 %394, label %395, label %443

395:                                              ; preds = %393
  %396 = bitcast <2 x i64>* %145 to <8 x i16>*
  %397 = load <8 x i16>, <8 x i16>* %396, align 16
  %398 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 1
  %399 = bitcast <2 x i64>* %398 to <8 x i16>*
  %400 = load <8 x i16>, <8 x i16>* %399, align 16
  %401 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 2
  %402 = bitcast <2 x i64>* %401 to <8 x i16>*
  %403 = load <8 x i16>, <8 x i16>* %402, align 16
  %404 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 3
  %405 = bitcast <2 x i64>* %404 to <8 x i16>*
  %406 = load <8 x i16>, <8 x i16>* %405, align 16
  %407 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 4
  %408 = bitcast <2 x i64>* %407 to <8 x i16>*
  %409 = load <8 x i16>, <8 x i16>* %408, align 16
  %410 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 5
  %411 = bitcast <2 x i64>* %410 to <8 x i16>*
  %412 = load <8 x i16>, <8 x i16>* %411, align 16
  %413 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 6
  %414 = bitcast <2 x i64>* %413 to <8 x i16>*
  %415 = load <8 x i16>, <8 x i16>* %414, align 16
  %416 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 7
  %417 = bitcast <2 x i64>* %416 to <8 x i16>*
  %418 = load <8 x i16>, <8 x i16>* %417, align 16
  %419 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 8
  %420 = bitcast <2 x i64>* %419 to <8 x i16>*
  %421 = load <8 x i16>, <8 x i16>* %420, align 16
  %422 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 9
  %423 = bitcast <2 x i64>* %422 to <8 x i16>*
  %424 = load <8 x i16>, <8 x i16>* %423, align 16
  %425 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 10
  %426 = bitcast <2 x i64>* %425 to <8 x i16>*
  %427 = load <8 x i16>, <8 x i16>* %426, align 16
  %428 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 11
  %429 = bitcast <2 x i64>* %428 to <8 x i16>*
  %430 = load <8 x i16>, <8 x i16>* %429, align 16
  %431 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 12
  %432 = bitcast <2 x i64>* %431 to <8 x i16>*
  %433 = load <8 x i16>, <8 x i16>* %432, align 16
  %434 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 13
  %435 = bitcast <2 x i64>* %434 to <8 x i16>*
  %436 = load <8 x i16>, <8 x i16>* %435, align 16
  %437 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 14
  %438 = bitcast <2 x i64>* %437 to <8 x i16>*
  %439 = load <8 x i16>, <8 x i16>* %438, align 16
  %440 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 15
  %441 = bitcast <2 x i64>* %440 to <8 x i16>*
  %442 = load <8 x i16>, <8 x i16>* %441, align 16
  br label %507

443:                                              ; preds = %393
  %444 = bitcast [16 x <2 x i64>]* %6 to <8 x i16>*
  %445 = load <8 x i16>, <8 x i16>* %444, align 16
  %446 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %445, i32 %305) #8
  store <8 x i16> %446, <8 x i16>* %444, align 16
  %447 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 1
  %448 = bitcast <2 x i64>* %447 to <8 x i16>*
  %449 = load <8 x i16>, <8 x i16>* %448, align 16
  %450 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %449, i32 %305) #8
  store <8 x i16> %450, <8 x i16>* %448, align 16
  %451 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 2
  %452 = bitcast <2 x i64>* %451 to <8 x i16>*
  %453 = load <8 x i16>, <8 x i16>* %452, align 16
  %454 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %453, i32 %305) #8
  store <8 x i16> %454, <8 x i16>* %452, align 16
  %455 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 3
  %456 = bitcast <2 x i64>* %455 to <8 x i16>*
  %457 = load <8 x i16>, <8 x i16>* %456, align 16
  %458 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %457, i32 %305) #8
  store <8 x i16> %458, <8 x i16>* %456, align 16
  %459 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 4
  %460 = bitcast <2 x i64>* %459 to <8 x i16>*
  %461 = load <8 x i16>, <8 x i16>* %460, align 16
  %462 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %461, i32 %305) #8
  store <8 x i16> %462, <8 x i16>* %460, align 16
  %463 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 5
  %464 = bitcast <2 x i64>* %463 to <8 x i16>*
  %465 = load <8 x i16>, <8 x i16>* %464, align 16
  %466 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %465, i32 %305) #8
  store <8 x i16> %466, <8 x i16>* %464, align 16
  %467 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 6
  %468 = bitcast <2 x i64>* %467 to <8 x i16>*
  %469 = load <8 x i16>, <8 x i16>* %468, align 16
  %470 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %469, i32 %305) #8
  store <8 x i16> %470, <8 x i16>* %468, align 16
  %471 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 7
  %472 = bitcast <2 x i64>* %471 to <8 x i16>*
  %473 = load <8 x i16>, <8 x i16>* %472, align 16
  %474 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %473, i32 %305) #8
  store <8 x i16> %474, <8 x i16>* %472, align 16
  %475 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 8
  %476 = bitcast <2 x i64>* %475 to <8 x i16>*
  %477 = load <8 x i16>, <8 x i16>* %476, align 16
  %478 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %477, i32 %305) #8
  store <8 x i16> %478, <8 x i16>* %476, align 16
  %479 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 9
  %480 = bitcast <2 x i64>* %479 to <8 x i16>*
  %481 = load <8 x i16>, <8 x i16>* %480, align 16
  %482 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %481, i32 %305) #8
  store <8 x i16> %482, <8 x i16>* %480, align 16
  %483 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 10
  %484 = bitcast <2 x i64>* %483 to <8 x i16>*
  %485 = load <8 x i16>, <8 x i16>* %484, align 16
  %486 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %485, i32 %305) #8
  store <8 x i16> %486, <8 x i16>* %484, align 16
  %487 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 11
  %488 = bitcast <2 x i64>* %487 to <8 x i16>*
  %489 = load <8 x i16>, <8 x i16>* %488, align 16
  %490 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %489, i32 %305) #8
  store <8 x i16> %490, <8 x i16>* %488, align 16
  %491 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 12
  %492 = bitcast <2 x i64>* %491 to <8 x i16>*
  %493 = load <8 x i16>, <8 x i16>* %492, align 16
  %494 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %493, i32 %305) #8
  store <8 x i16> %494, <8 x i16>* %492, align 16
  %495 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 13
  %496 = bitcast <2 x i64>* %495 to <8 x i16>*
  %497 = load <8 x i16>, <8 x i16>* %496, align 16
  %498 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %497, i32 %305) #8
  store <8 x i16> %498, <8 x i16>* %496, align 16
  %499 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 14
  %500 = bitcast <2 x i64>* %499 to <8 x i16>*
  %501 = load <8 x i16>, <8 x i16>* %500, align 16
  %502 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %501, i32 %305) #8
  store <8 x i16> %502, <8 x i16>* %500, align 16
  %503 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 15
  %504 = bitcast <2 x i64>* %503 to <8 x i16>*
  %505 = load <8 x i16>, <8 x i16>* %504, align 16
  %506 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %505, i32 %305) #8
  store <8 x i16> %506, <8 x i16>* %504, align 16
  br label %507

507:                                              ; preds = %395, %443, %307
  %508 = phi <8 x i16> [ %442, %395 ], [ %506, %443 ], [ %392, %307 ]
  %509 = phi <8 x i16> [ %439, %395 ], [ %502, %443 ], [ %387, %307 ]
  %510 = phi <8 x i16> [ %436, %395 ], [ %498, %443 ], [ %382, %307 ]
  %511 = phi <8 x i16> [ %433, %395 ], [ %494, %443 ], [ %377, %307 ]
  %512 = phi <8 x i16> [ %430, %395 ], [ %490, %443 ], [ %372, %307 ]
  %513 = phi <8 x i16> [ %427, %395 ], [ %486, %443 ], [ %367, %307 ]
  %514 = phi <8 x i16> [ %424, %395 ], [ %482, %443 ], [ %362, %307 ]
  %515 = phi <8 x i16> [ %421, %395 ], [ %478, %443 ], [ %357, %307 ]
  %516 = phi <8 x i16> [ %418, %395 ], [ %474, %443 ], [ %352, %307 ]
  %517 = phi <8 x i16> [ %415, %395 ], [ %470, %443 ], [ %347, %307 ]
  %518 = phi <8 x i16> [ %412, %395 ], [ %466, %443 ], [ %342, %307 ]
  %519 = phi <8 x i16> [ %409, %395 ], [ %462, %443 ], [ %337, %307 ]
  %520 = phi <8 x i16> [ %406, %395 ], [ %458, %443 ], [ %332, %307 ]
  %521 = phi <8 x i16> [ %403, %395 ], [ %454, %443 ], [ %327, %307 ]
  %522 = phi <8 x i16> [ %400, %395 ], [ %450, %443 ], [ %322, %307 ]
  %523 = phi <8 x i16> [ %397, %395 ], [ %446, %443 ], [ %317, %307 ]
  %524 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 0
  %525 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 1
  %526 = shufflevector <8 x i16> %523, <8 x i16> %522, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %527 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 2
  %528 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 3
  %529 = shufflevector <8 x i16> %521, <8 x i16> %520, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %530 = shufflevector <8 x i16> %519, <8 x i16> %518, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %531 = shufflevector <8 x i16> %517, <8 x i16> %516, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %532 = bitcast <8 x i16> %526 to <4 x i32>
  %533 = bitcast <8 x i16> %529 to <4 x i32>
  %534 = shufflevector <4 x i32> %532, <4 x i32> %533, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %535 = bitcast <4 x i32> %534 to <2 x i64>
  %536 = bitcast <8 x i16> %530 to <4 x i32>
  %537 = bitcast <8 x i16> %531 to <4 x i32>
  %538 = shufflevector <4 x i32> %536, <4 x i32> %537, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %539 = bitcast <4 x i32> %538 to <2 x i64>
  %540 = shufflevector <4 x i32> %532, <4 x i32> %533, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %541 = bitcast <4 x i32> %540 to <2 x i64>
  %542 = shufflevector <4 x i32> %536, <4 x i32> %537, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %543 = bitcast <4 x i32> %542 to <2 x i64>
  %544 = shufflevector <2 x i64> %535, <2 x i64> %539, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %544, <2 x i64>* %524, align 16
  %545 = shufflevector <2 x i64> %535, <2 x i64> %539, <2 x i32> <i32 1, i32 3>
  %546 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 1
  store <2 x i64> %545, <2 x i64>* %546, align 16
  %547 = shufflevector <2 x i64> %541, <2 x i64> %543, <2 x i32> <i32 0, i32 2>
  %548 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 2
  store <2 x i64> %547, <2 x i64>* %548, align 16
  %549 = shufflevector <2 x i64> %541, <2 x i64> %543, <2 x i32> <i32 1, i32 3>
  %550 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 3
  store <2 x i64> %549, <2 x i64>* %550, align 16
  %551 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 8
  %552 = shufflevector <8 x i16> %515, <8 x i16> %514, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %553 = shufflevector <8 x i16> %513, <8 x i16> %512, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %554 = shufflevector <8 x i16> %511, <8 x i16> %510, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %555 = shufflevector <8 x i16> %509, <8 x i16> %508, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %556 = bitcast <8 x i16> %552 to <4 x i32>
  %557 = bitcast <8 x i16> %553 to <4 x i32>
  %558 = shufflevector <4 x i32> %556, <4 x i32> %557, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %559 = bitcast <4 x i32> %558 to <2 x i64>
  %560 = bitcast <8 x i16> %554 to <4 x i32>
  %561 = bitcast <8 x i16> %555 to <4 x i32>
  %562 = shufflevector <4 x i32> %560, <4 x i32> %561, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %563 = bitcast <4 x i32> %562 to <2 x i64>
  %564 = shufflevector <4 x i32> %556, <4 x i32> %557, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %565 = bitcast <4 x i32> %564 to <2 x i64>
  %566 = shufflevector <4 x i32> %560, <4 x i32> %561, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %567 = bitcast <4 x i32> %566 to <2 x i64>
  %568 = shufflevector <2 x i64> %559, <2 x i64> %563, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %568, <2 x i64>* %551, align 16
  %569 = shufflevector <2 x i64> %559, <2 x i64> %563, <2 x i32> <i32 1, i32 3>
  %570 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 9
  store <2 x i64> %569, <2 x i64>* %570, align 16
  %571 = shufflevector <2 x i64> %565, <2 x i64> %567, <2 x i32> <i32 0, i32 2>
  %572 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 10
  store <2 x i64> %571, <2 x i64>* %572, align 16
  %573 = shufflevector <2 x i64> %565, <2 x i64> %567, <2 x i32> <i32 1, i32 3>
  %574 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 11
  store <2 x i64> %573, <2 x i64>* %574, align 16
  %575 = icmp eq i32 %146, 0
  %576 = getelementptr inbounds i8, i8* %10, i64 2
  %577 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 0
  br label %579

578:                                              ; preds = %650
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %9) #8
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %8) #8
  ret void

579:                                              ; preds = %650, %507
  %580 = phi i64 [ 0, %507 ], [ %735, %650 ]
  %581 = shl nsw i64 %580, 3
  %582 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 %581
  br i1 %575, label %591, label %583

583:                                              ; preds = %579
  %584 = load <2 x i64>, <2 x i64>* %582, align 16
  store <2 x i64> %584, <2 x i64>* %528, align 16
  %585 = getelementptr inbounds <2 x i64>, <2 x i64>* %582, i64 1
  %586 = load <2 x i64>, <2 x i64>* %585, align 16
  store <2 x i64> %586, <2 x i64>* %527, align 16
  %587 = getelementptr inbounds <2 x i64>, <2 x i64>* %582, i64 2
  %588 = load <2 x i64>, <2 x i64>* %587, align 16
  store <2 x i64> %588, <2 x i64>* %525, align 16
  %589 = getelementptr inbounds <2 x i64>, <2 x i64>* %582, i64 3
  %590 = load <2 x i64>, <2 x i64>* %589, align 16
  store <2 x i64> %590, <2 x i64>* %577, align 16
  br label %591

591:                                              ; preds = %583, %579
  %592 = phi <2 x i64>* [ %582, %579 ], [ %145, %583 ]
  call void %17(<2 x i64>* %592, <2 x i64>* %592, i8 signext %12) #8
  %593 = load i8, i8* %576, align 1
  %594 = sext i8 %593 to i32
  %595 = icmp slt i8 %593, 0
  br i1 %595, label %596, label %622

596:                                              ; preds = %591
  %597 = sub nsw i32 0, %594
  %598 = xor i32 %594, -1
  %599 = shl i32 1, %598
  %600 = trunc i32 %599 to i16
  %601 = insertelement <8 x i16> undef, i16 %600, i32 0
  %602 = shufflevector <8 x i16> %601, <8 x i16> undef, <8 x i32> zeroinitializer
  %603 = bitcast <2 x i64>* %592 to <8 x i16>*
  %604 = load <8 x i16>, <8 x i16>* %603, align 16
  %605 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %604, <8 x i16> %602) #8
  %606 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %605, i32 %597) #8
  store <8 x i16> %606, <8 x i16>* %603, align 16
  %607 = getelementptr inbounds <2 x i64>, <2 x i64>* %592, i64 1
  %608 = bitcast <2 x i64>* %607 to <8 x i16>*
  %609 = load <8 x i16>, <8 x i16>* %608, align 16
  %610 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %609, <8 x i16> %602) #8
  %611 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %610, i32 %597) #8
  store <8 x i16> %611, <8 x i16>* %608, align 16
  %612 = getelementptr inbounds <2 x i64>, <2 x i64>* %592, i64 2
  %613 = bitcast <2 x i64>* %612 to <8 x i16>*
  %614 = load <8 x i16>, <8 x i16>* %613, align 16
  %615 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %614, <8 x i16> %602) #8
  %616 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %615, i32 %597) #8
  store <8 x i16> %616, <8 x i16>* %613, align 16
  %617 = getelementptr inbounds <2 x i64>, <2 x i64>* %592, i64 3
  %618 = bitcast <2 x i64>* %617 to <8 x i16>*
  %619 = load <8 x i16>, <8 x i16>* %618, align 16
  %620 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %619, <8 x i16> %602) #8
  %621 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %620, i32 %597) #8
  store <8 x i16> %621, <8 x i16>* %618, align 16
  br label %650

622:                                              ; preds = %591
  %623 = icmp eq i8 %593, 0
  %624 = bitcast <2 x i64>* %592 to <8 x i16>*
  %625 = load <8 x i16>, <8 x i16>* %624, align 16
  br i1 %623, label %626, label %636

626:                                              ; preds = %622
  %627 = getelementptr inbounds <2 x i64>, <2 x i64>* %592, i64 1
  %628 = bitcast <2 x i64>* %627 to <8 x i16>*
  %629 = load <8 x i16>, <8 x i16>* %628, align 16
  %630 = getelementptr inbounds <2 x i64>, <2 x i64>* %592, i64 2
  %631 = bitcast <2 x i64>* %630 to <8 x i16>*
  %632 = load <8 x i16>, <8 x i16>* %631, align 16
  %633 = getelementptr inbounds <2 x i64>, <2 x i64>* %592, i64 3
  %634 = bitcast <2 x i64>* %633 to <8 x i16>*
  %635 = load <8 x i16>, <8 x i16>* %634, align 16
  br label %650

636:                                              ; preds = %622
  %637 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %625, i32 %594) #8
  store <8 x i16> %637, <8 x i16>* %624, align 16
  %638 = getelementptr inbounds <2 x i64>, <2 x i64>* %592, i64 1
  %639 = bitcast <2 x i64>* %638 to <8 x i16>*
  %640 = load <8 x i16>, <8 x i16>* %639, align 16
  %641 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %640, i32 %594) #8
  store <8 x i16> %641, <8 x i16>* %639, align 16
  %642 = getelementptr inbounds <2 x i64>, <2 x i64>* %592, i64 2
  %643 = bitcast <2 x i64>* %642 to <8 x i16>*
  %644 = load <8 x i16>, <8 x i16>* %643, align 16
  %645 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %644, i32 %594) #8
  store <8 x i16> %645, <8 x i16>* %643, align 16
  %646 = getelementptr inbounds <2 x i64>, <2 x i64>* %592, i64 3
  %647 = bitcast <2 x i64>* %646 to <8 x i16>*
  %648 = load <8 x i16>, <8 x i16>* %647, align 16
  %649 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %648, i32 %594) #8
  store <8 x i16> %649, <8 x i16>* %647, align 16
  br label %650

650:                                              ; preds = %626, %636, %596
  %651 = phi <8 x i16> [ %635, %626 ], [ %649, %636 ], [ %621, %596 ]
  %652 = phi <8 x i16> [ %632, %626 ], [ %645, %636 ], [ %616, %596 ]
  %653 = phi <8 x i16> [ %629, %626 ], [ %641, %636 ], [ %611, %596 ]
  %654 = phi <8 x i16> [ %625, %626 ], [ %637, %636 ], [ %606, %596 ]
  %655 = getelementptr inbounds <2 x i64>, <2 x i64>* %592, i64 1
  %656 = shufflevector <8 x i16> %654, <8 x i16> %653, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %657 = getelementptr inbounds <2 x i64>, <2 x i64>* %592, i64 2
  %658 = getelementptr inbounds <2 x i64>, <2 x i64>* %592, i64 3
  %659 = shufflevector <8 x i16> %652, <8 x i16> %651, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %660 = shufflevector <8 x i16> %654, <8 x i16> %653, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %661 = shufflevector <8 x i16> %652, <8 x i16> %651, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %662 = bitcast <8 x i16> %656 to <4 x i32>
  %663 = bitcast <8 x i16> %659 to <4 x i32>
  %664 = shufflevector <4 x i32> %662, <4 x i32> %663, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %665 = bitcast <4 x i32> %664 to <2 x i64>
  %666 = bitcast <8 x i16> %660 to <4 x i32>
  %667 = bitcast <8 x i16> %661 to <4 x i32>
  %668 = shufflevector <4 x i32> %666, <4 x i32> %667, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %669 = bitcast <4 x i32> %668 to <2 x i64>
  %670 = shufflevector <4 x i32> %662, <4 x i32> %663, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %671 = bitcast <4 x i32> %670 to <2 x i64>
  %672 = shufflevector <4 x i32> %666, <4 x i32> %667, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %673 = bitcast <4 x i32> %672 to <2 x i64>
  %674 = insertelement <2 x i64> %665, i64 0, i32 1
  store <2 x i64> %674, <2 x i64>* %592, align 16
  %675 = shufflevector <2 x i64> %665, <2 x i64> <i64 undef, i64 0>, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %675, <2 x i64>* %655, align 16
  %676 = insertelement <2 x i64> %671, i64 0, i32 1
  store <2 x i64> %676, <2 x i64>* %657, align 16
  %677 = shufflevector <2 x i64> %671, <2 x i64> <i64 undef, i64 0>, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %677, <2 x i64>* %658, align 16
  %678 = insertelement <2 x i64> %669, i64 0, i32 1
  %679 = getelementptr inbounds <2 x i64>, <2 x i64>* %592, i64 4
  store <2 x i64> %678, <2 x i64>* %679, align 16
  %680 = shufflevector <2 x i64> %669, <2 x i64> <i64 undef, i64 0>, <2 x i32> <i32 1, i32 3>
  %681 = getelementptr inbounds <2 x i64>, <2 x i64>* %592, i64 5
  store <2 x i64> %680, <2 x i64>* %681, align 16
  %682 = insertelement <2 x i64> %673, i64 0, i32 1
  %683 = getelementptr inbounds <2 x i64>, <2 x i64>* %592, i64 6
  store <2 x i64> %682, <2 x i64>* %683, align 16
  %684 = shufflevector <2 x i64> %673, <2 x i64> <i64 undef, i64 0>, <2 x i32> <i32 1, i32 3>
  %685 = getelementptr inbounds <2 x i64>, <2 x i64>* %592, i64 7
  store <2 x i64> %684, <2 x i64>* %685, align 16
  %686 = shl nsw i64 %580, 5
  %687 = getelementptr inbounds i32, i32* %1, i64 %686
  %688 = bitcast <2 x i64> %674 to <8 x i16>
  %689 = shufflevector <8 x i16> %688, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %690 = bitcast <8 x i16> %689 to <4 x i32>
  %691 = ashr <4 x i32> %690, <i32 16, i32 16, i32 16, i32 16>
  %692 = bitcast i32* %687 to <4 x i32>*
  store <4 x i32> %691, <4 x i32>* %692, align 16
  %693 = bitcast <2 x i64> %675 to <8 x i16>
  %694 = getelementptr inbounds i32, i32* %687, i64 4
  %695 = shufflevector <8 x i16> %693, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %696 = bitcast <8 x i16> %695 to <4 x i32>
  %697 = ashr <4 x i32> %696, <i32 16, i32 16, i32 16, i32 16>
  %698 = bitcast i32* %694 to <4 x i32>*
  store <4 x i32> %697, <4 x i32>* %698, align 16
  %699 = bitcast <2 x i64> %676 to <8 x i16>
  %700 = getelementptr inbounds i32, i32* %687, i64 8
  %701 = shufflevector <8 x i16> %699, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %702 = bitcast <8 x i16> %701 to <4 x i32>
  %703 = ashr <4 x i32> %702, <i32 16, i32 16, i32 16, i32 16>
  %704 = bitcast i32* %700 to <4 x i32>*
  store <4 x i32> %703, <4 x i32>* %704, align 16
  %705 = bitcast <2 x i64> %677 to <8 x i16>
  %706 = getelementptr inbounds i32, i32* %687, i64 12
  %707 = shufflevector <8 x i16> %705, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %708 = bitcast <8 x i16> %707 to <4 x i32>
  %709 = ashr <4 x i32> %708, <i32 16, i32 16, i32 16, i32 16>
  %710 = bitcast i32* %706 to <4 x i32>*
  store <4 x i32> %709, <4 x i32>* %710, align 16
  %711 = bitcast <2 x i64> %678 to <8 x i16>
  %712 = getelementptr inbounds i32, i32* %687, i64 16
  %713 = shufflevector <8 x i16> %711, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %714 = bitcast <8 x i16> %713 to <4 x i32>
  %715 = ashr <4 x i32> %714, <i32 16, i32 16, i32 16, i32 16>
  %716 = bitcast i32* %712 to <4 x i32>*
  store <4 x i32> %715, <4 x i32>* %716, align 16
  %717 = bitcast <2 x i64> %680 to <8 x i16>
  %718 = getelementptr inbounds i32, i32* %687, i64 20
  %719 = shufflevector <8 x i16> %717, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %720 = bitcast <8 x i16> %719 to <4 x i32>
  %721 = ashr <4 x i32> %720, <i32 16, i32 16, i32 16, i32 16>
  %722 = bitcast i32* %718 to <4 x i32>*
  store <4 x i32> %721, <4 x i32>* %722, align 16
  %723 = bitcast <2 x i64> %682 to <8 x i16>
  %724 = getelementptr inbounds i32, i32* %687, i64 24
  %725 = shufflevector <8 x i16> %723, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %726 = bitcast <8 x i16> %725 to <4 x i32>
  %727 = ashr <4 x i32> %726, <i32 16, i32 16, i32 16, i32 16>
  %728 = bitcast i32* %724 to <4 x i32>*
  store <4 x i32> %727, <4 x i32>* %728, align 16
  %729 = bitcast <2 x i64> %684 to <8 x i16>
  %730 = getelementptr inbounds i32, i32* %687, i64 28
  %731 = shufflevector <8 x i16> %729, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %732 = bitcast <8 x i16> %731 to <4 x i32>
  %733 = ashr <4 x i32> %732, <i32 16, i32 16, i32 16, i32 16>
  %734 = bitcast i32* %730 to <4 x i32>*
  store <4 x i32> %733, <4 x i32>* %734, align 16
  %735 = add nuw nsw i64 %580, 1
  %736 = icmp eq i64 %735, 2
  br i1 %736, label %578, label %579
}

; Function Attrs: nounwind ssp uwtable
define hidden void @av1_lowbd_fwd_txfm2d_8x4_sse2(i16* nocapture readonly, i32* nocapture, i32, i8 zeroext, i32) #2 {
  %6 = alloca [8 x <2 x i64>], align 16
  %7 = alloca [8 x <2 x i64>], align 16
  %8 = bitcast [8 x <2 x i64>]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %8) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %8, i8 -86, i64 128, i1 false)
  %9 = bitcast [8 x <2 x i64>]* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %9) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 128, i1 false)
  %10 = load i8*, i8** getelementptr inbounds ([19 x i8*], [19 x i8*]* @av1_fwd_txfm_shift_ls, i64 0, i64 6), align 16
  %11 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_fwd_cos_bit_col, i64 0, i64 1, i64 0), align 1
  %12 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_fwd_cos_bit_row, i64 0, i64 1, i64 0), align 1
  %13 = zext i8 %3 to i64
  %14 = getelementptr inbounds [16 x void (<2 x i64>*, <2 x i64>*, i8)*], [16 x void (<2 x i64>*, <2 x i64>*, i8)*]* @col_txfm8x4_arr, i64 0, i64 %13
  %15 = load void (<2 x i64>*, <2 x i64>*, i8)*, void (<2 x i64>*, <2 x i64>*, i8)** %14, align 8
  %16 = getelementptr inbounds [16 x void (<2 x i64>*, <2 x i64>*, i8)*], [16 x void (<2 x i64>*, <2 x i64>*, i8)*]* @row_txfm4x8_arr, i64 0, i64 %13
  %17 = load void (<2 x i64>*, <2 x i64>*, i8)*, void (<2 x i64>*, <2 x i64>*, i8)** %16, align 8
  switch i8 %3, label %40 [
    i8 6, label %19
    i8 15, label %18
    i8 7, label %18
    i8 5, label %18
    i8 14, label %20
    i8 8, label %20
    i8 4, label %20
  ]

18:                                               ; preds = %5, %5, %5
  br label %40

19:                                               ; preds = %5
  br label %20

20:                                               ; preds = %5, %5, %5, %19
  %21 = phi i32 [ 1, %19 ], [ 0, %5 ], [ 0, %5 ], [ 0, %5 ]
  %22 = sext i32 %2 to i64
  %23 = bitcast i16* %0 to <2 x i64>*
  %24 = load <2 x i64>, <2 x i64>* %23, align 16
  %25 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 3
  store <2 x i64> %24, <2 x i64>* %25, align 16
  %26 = getelementptr inbounds i16, i16* %0, i64 %22
  %27 = bitcast i16* %26 to <2 x i64>*
  %28 = load <2 x i64>, <2 x i64>* %27, align 16
  %29 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 2
  store <2 x i64> %28, <2 x i64>* %29, align 16
  %30 = shl nsw i64 %22, 1
  %31 = getelementptr inbounds i16, i16* %0, i64 %30
  %32 = bitcast i16* %31 to <2 x i64>*
  %33 = load <2 x i64>, <2 x i64>* %32, align 16
  %34 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 1
  store <2 x i64> %33, <2 x i64>* %34, align 16
  %35 = mul nsw i64 %22, 3
  %36 = getelementptr inbounds i16, i16* %0, i64 %35
  %37 = bitcast i16* %36 to <2 x i64>*
  %38 = load <2 x i64>, <2 x i64>* %37, align 16
  %39 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 0
  store <2 x i64> %38, <2 x i64>* %39, align 16
  br label %60

40:                                               ; preds = %18, %5
  %41 = phi i32 [ 0, %5 ], [ 1, %18 ]
  %42 = sext i32 %2 to i64
  %43 = bitcast i16* %0 to <2 x i64>*
  %44 = load <2 x i64>, <2 x i64>* %43, align 16
  %45 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 0
  store <2 x i64> %44, <2 x i64>* %45, align 16
  %46 = getelementptr inbounds i16, i16* %0, i64 %42
  %47 = bitcast i16* %46 to <2 x i64>*
  %48 = load <2 x i64>, <2 x i64>* %47, align 16
  %49 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 1
  store <2 x i64> %48, <2 x i64>* %49, align 16
  %50 = shl nsw i64 %42, 1
  %51 = getelementptr inbounds i16, i16* %0, i64 %50
  %52 = bitcast i16* %51 to <2 x i64>*
  %53 = load <2 x i64>, <2 x i64>* %52, align 16
  %54 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 2
  store <2 x i64> %53, <2 x i64>* %54, align 16
  %55 = mul nsw i64 %42, 3
  %56 = getelementptr inbounds i16, i16* %0, i64 %55
  %57 = bitcast i16* %56 to <2 x i64>*
  %58 = load <2 x i64>, <2 x i64>* %57, align 16
  %59 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 3
  store <2 x i64> %58, <2 x i64>* %59, align 16
  br label %60

60:                                               ; preds = %20, %40
  %61 = phi <2 x i64> [ %58, %40 ], [ %24, %20 ]
  %62 = phi <2 x i64> [ %53, %40 ], [ %28, %20 ]
  %63 = phi <2 x i64> [ %48, %40 ], [ %33, %20 ]
  %64 = phi <2 x i64> [ %44, %40 ], [ %38, %20 ]
  %65 = phi <2 x i64>* [ %45, %40 ], [ %39, %20 ]
  %66 = phi i32 [ %41, %40 ], [ %21, %20 ]
  %67 = bitcast <2 x i64> %64 to <8 x i16>
  %68 = bitcast <2 x i64> %63 to <8 x i16>
  %69 = bitcast <2 x i64> %62 to <8 x i16>
  %70 = bitcast <2 x i64> %61 to <8 x i16>
  %71 = load i8, i8* %10, align 1
  %72 = sext i8 %71 to i32
  %73 = icmp slt i8 %71, 0
  br i1 %73, label %74, label %96

74:                                               ; preds = %60
  %75 = sub nsw i32 0, %72
  %76 = xor i32 %72, -1
  %77 = shl i32 1, %76
  %78 = trunc i32 %77 to i16
  %79 = insertelement <8 x i16> undef, i16 %78, i32 0
  %80 = shufflevector <8 x i16> %79, <8 x i16> undef, <8 x i32> zeroinitializer
  %81 = bitcast [8 x <2 x i64>]* %6 to <8 x i16>*
  %82 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %67, <8 x i16> %80) #8
  %83 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %82, i32 %75) #8
  store <8 x i16> %83, <8 x i16>* %81, align 16
  %84 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 1
  %85 = bitcast <2 x i64>* %84 to <8 x i16>*
  %86 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %68, <8 x i16> %80) #8
  %87 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %86, i32 %75) #8
  store <8 x i16> %87, <8 x i16>* %85, align 16
  %88 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 2
  %89 = bitcast <2 x i64>* %88 to <8 x i16>*
  %90 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %69, <8 x i16> %80) #8
  %91 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %90, i32 %75) #8
  store <8 x i16> %91, <8 x i16>* %89, align 16
  %92 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 3
  %93 = bitcast <2 x i64>* %92 to <8 x i16>*
  %94 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %70, <8 x i16> %80) #8
  %95 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %94, i32 %75) #8
  store <8 x i16> %95, <8 x i16>* %93, align 16
  br label %110

96:                                               ; preds = %60
  %97 = icmp eq i8 %71, 0
  br i1 %97, label %110, label %98

98:                                               ; preds = %96
  %99 = bitcast [8 x <2 x i64>]* %6 to <8 x i16>*
  %100 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %67, i32 %72) #8
  store <8 x i16> %100, <8 x i16>* %99, align 16
  %101 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 1
  %102 = bitcast <2 x i64>* %101 to <8 x i16>*
  %103 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %68, i32 %72) #8
  store <8 x i16> %103, <8 x i16>* %102, align 16
  %104 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 2
  %105 = bitcast <2 x i64>* %104 to <8 x i16>*
  %106 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %69, i32 %72) #8
  store <8 x i16> %106, <8 x i16>* %105, align 16
  %107 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 3
  %108 = bitcast <2 x i64>* %107 to <8 x i16>*
  %109 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %70, i32 %72) #8
  store <8 x i16> %109, <8 x i16>* %108, align 16
  br label %110

110:                                              ; preds = %98, %74, %96
  call void %15(<2 x i64>* %65, <2 x i64>* %65, i8 signext %11) #8
  %111 = getelementptr inbounds i8, i8* %10, i64 1
  %112 = load i8, i8* %111, align 1
  %113 = sext i8 %112 to i32
  %114 = icmp slt i8 %112, 0
  br i1 %114, label %115, label %141

115:                                              ; preds = %110
  %116 = sub nsw i32 0, %113
  %117 = xor i32 %113, -1
  %118 = shl i32 1, %117
  %119 = trunc i32 %118 to i16
  %120 = insertelement <8 x i16> undef, i16 %119, i32 0
  %121 = shufflevector <8 x i16> %120, <8 x i16> undef, <8 x i32> zeroinitializer
  %122 = bitcast [8 x <2 x i64>]* %6 to <8 x i16>*
  %123 = load <8 x i16>, <8 x i16>* %122, align 16
  %124 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %123, <8 x i16> %121) #8
  %125 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %124, i32 %116) #8
  store <8 x i16> %125, <8 x i16>* %122, align 16
  %126 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 1
  %127 = bitcast <2 x i64>* %126 to <8 x i16>*
  %128 = load <8 x i16>, <8 x i16>* %127, align 16
  %129 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %128, <8 x i16> %121) #8
  %130 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %129, i32 %116) #8
  store <8 x i16> %130, <8 x i16>* %127, align 16
  %131 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 2
  %132 = bitcast <2 x i64>* %131 to <8 x i16>*
  %133 = load <8 x i16>, <8 x i16>* %132, align 16
  %134 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %133, <8 x i16> %121) #8
  %135 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %134, i32 %116) #8
  store <8 x i16> %135, <8 x i16>* %132, align 16
  %136 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 3
  %137 = bitcast <2 x i64>* %136 to <8 x i16>*
  %138 = load <8 x i16>, <8 x i16>* %137, align 16
  %139 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %138, <8 x i16> %121) #8
  %140 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %139, i32 %116) #8
  store <8 x i16> %140, <8 x i16>* %137, align 16
  br label %171

141:                                              ; preds = %110
  %142 = icmp eq i8 %112, 0
  br i1 %142, label %143, label %155

143:                                              ; preds = %141
  %144 = bitcast <2 x i64>* %65 to <8 x i16>*
  %145 = load <8 x i16>, <8 x i16>* %144, align 16
  %146 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 1
  %147 = bitcast <2 x i64>* %146 to <8 x i16>*
  %148 = load <8 x i16>, <8 x i16>* %147, align 16
  %149 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 2
  %150 = bitcast <2 x i64>* %149 to <8 x i16>*
  %151 = load <8 x i16>, <8 x i16>* %150, align 16
  %152 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 3
  %153 = bitcast <2 x i64>* %152 to <8 x i16>*
  %154 = load <8 x i16>, <8 x i16>* %153, align 16
  br label %171

155:                                              ; preds = %141
  %156 = bitcast [8 x <2 x i64>]* %6 to <8 x i16>*
  %157 = load <8 x i16>, <8 x i16>* %156, align 16
  %158 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %157, i32 %113) #8
  store <8 x i16> %158, <8 x i16>* %156, align 16
  %159 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 1
  %160 = bitcast <2 x i64>* %159 to <8 x i16>*
  %161 = load <8 x i16>, <8 x i16>* %160, align 16
  %162 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %161, i32 %113) #8
  store <8 x i16> %162, <8 x i16>* %160, align 16
  %163 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 2
  %164 = bitcast <2 x i64>* %163 to <8 x i16>*
  %165 = load <8 x i16>, <8 x i16>* %164, align 16
  %166 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %165, i32 %113) #8
  store <8 x i16> %166, <8 x i16>* %164, align 16
  %167 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 3
  %168 = bitcast <2 x i64>* %167 to <8 x i16>*
  %169 = load <8 x i16>, <8 x i16>* %168, align 16
  %170 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %169, i32 %113) #8
  store <8 x i16> %170, <8 x i16>* %168, align 16
  br label %171

171:                                              ; preds = %143, %155, %115
  %172 = phi <8 x i16> [ %154, %143 ], [ %170, %155 ], [ %140, %115 ]
  %173 = phi <8 x i16> [ %151, %143 ], [ %166, %155 ], [ %135, %115 ]
  %174 = phi <8 x i16> [ %148, %143 ], [ %162, %155 ], [ %130, %115 ]
  %175 = phi <8 x i16> [ %145, %143 ], [ %158, %155 ], [ %125, %115 ]
  %176 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %7, i64 0, i64 0
  %177 = shufflevector <8 x i16> %175, <8 x i16> %174, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %178 = shufflevector <8 x i16> %173, <8 x i16> %172, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %179 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 4
  %180 = bitcast <2 x i64>* %179 to <8 x i16>*
  %181 = load <8 x i16>, <8 x i16>* %180, align 16
  %182 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 5
  %183 = bitcast <2 x i64>* %182 to <8 x i16>*
  %184 = load <8 x i16>, <8 x i16>* %183, align 16
  %185 = shufflevector <8 x i16> %181, <8 x i16> %184, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %186 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 6
  %187 = bitcast <2 x i64>* %186 to <8 x i16>*
  %188 = load <8 x i16>, <8 x i16>* %187, align 16
  %189 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 7
  %190 = bitcast <2 x i64>* %189 to <8 x i16>*
  %191 = load <8 x i16>, <8 x i16>* %190, align 16
  %192 = shufflevector <8 x i16> %188, <8 x i16> %191, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %193 = shufflevector <8 x i16> %175, <8 x i16> %174, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %194 = shufflevector <8 x i16> %173, <8 x i16> %172, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %195 = shufflevector <8 x i16> %181, <8 x i16> %184, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %196 = shufflevector <8 x i16> %188, <8 x i16> %191, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %197 = bitcast <8 x i16> %177 to <4 x i32>
  %198 = bitcast <8 x i16> %178 to <4 x i32>
  %199 = shufflevector <4 x i32> %197, <4 x i32> %198, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %200 = bitcast <4 x i32> %199 to <2 x i64>
  %201 = bitcast <8 x i16> %185 to <4 x i32>
  %202 = bitcast <8 x i16> %192 to <4 x i32>
  %203 = shufflevector <4 x i32> %201, <4 x i32> %202, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %204 = bitcast <4 x i32> %203 to <2 x i64>
  %205 = bitcast <8 x i16> %193 to <4 x i32>
  %206 = bitcast <8 x i16> %194 to <4 x i32>
  %207 = shufflevector <4 x i32> %205, <4 x i32> %206, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %208 = bitcast <4 x i32> %207 to <2 x i64>
  %209 = bitcast <8 x i16> %195 to <4 x i32>
  %210 = bitcast <8 x i16> %196 to <4 x i32>
  %211 = shufflevector <4 x i32> %209, <4 x i32> %210, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %212 = bitcast <4 x i32> %211 to <2 x i64>
  %213 = shufflevector <4 x i32> %197, <4 x i32> %198, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %214 = bitcast <4 x i32> %213 to <2 x i64>
  %215 = shufflevector <4 x i32> %201, <4 x i32> %202, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %216 = bitcast <4 x i32> %215 to <2 x i64>
  %217 = shufflevector <4 x i32> %205, <4 x i32> %206, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %218 = bitcast <4 x i32> %217 to <2 x i64>
  %219 = shufflevector <4 x i32> %209, <4 x i32> %210, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %220 = bitcast <4 x i32> %219 to <2 x i64>
  %221 = shufflevector <2 x i64> %200, <2 x i64> %204, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %221, <2 x i64>* %176, align 16
  %222 = shufflevector <2 x i64> %200, <2 x i64> %204, <2 x i32> <i32 1, i32 3>
  %223 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %7, i64 0, i64 1
  store <2 x i64> %222, <2 x i64>* %223, align 16
  %224 = shufflevector <2 x i64> %214, <2 x i64> %216, <2 x i32> <i32 0, i32 2>
  %225 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %7, i64 0, i64 2
  store <2 x i64> %224, <2 x i64>* %225, align 16
  %226 = shufflevector <2 x i64> %214, <2 x i64> %216, <2 x i32> <i32 1, i32 3>
  %227 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %7, i64 0, i64 3
  store <2 x i64> %226, <2 x i64>* %227, align 16
  %228 = shufflevector <2 x i64> %208, <2 x i64> %212, <2 x i32> <i32 0, i32 2>
  %229 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %7, i64 0, i64 4
  store <2 x i64> %228, <2 x i64>* %229, align 16
  %230 = shufflevector <2 x i64> %208, <2 x i64> %212, <2 x i32> <i32 1, i32 3>
  %231 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %7, i64 0, i64 5
  store <2 x i64> %230, <2 x i64>* %231, align 16
  %232 = shufflevector <2 x i64> %218, <2 x i64> %220, <2 x i32> <i32 0, i32 2>
  %233 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %7, i64 0, i64 6
  store <2 x i64> %232, <2 x i64>* %233, align 16
  %234 = shufflevector <2 x i64> %218, <2 x i64> %220, <2 x i32> <i32 1, i32 3>
  %235 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %7, i64 0, i64 7
  store <2 x i64> %234, <2 x i64>* %235, align 16
  %236 = icmp eq i32 %66, 0
  br i1 %236, label %242, label %237

237:                                              ; preds = %171
  %238 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 3
  %239 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 2
  %240 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 1
  store <2 x i64> %221, <2 x i64>* %189, align 16
  store <2 x i64> %222, <2 x i64>* %186, align 16
  store <2 x i64> %224, <2 x i64>* %182, align 16
  store <2 x i64> %226, <2 x i64>* %179, align 16
  store <2 x i64> %228, <2 x i64>* %238, align 16
  store <2 x i64> %230, <2 x i64>* %239, align 16
  store <2 x i64> %232, <2 x i64>* %240, align 16
  %241 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 0
  store <2 x i64> %234, <2 x i64>* %241, align 16
  br label %242

242:                                              ; preds = %237, %171
  %243 = phi <2 x i64>* [ %176, %171 ], [ %65, %237 ]
  call void %17(<2 x i64>* %243, <2 x i64>* %243, i8 signext %12) #8
  %244 = getelementptr inbounds i8, i8* %10, i64 2
  %245 = load i8, i8* %244, align 1
  %246 = sext i8 %245 to i32
  %247 = icmp slt i8 %245, 0
  br i1 %247, label %248, label %294

248:                                              ; preds = %242
  %249 = sub nsw i32 0, %246
  %250 = xor i32 %246, -1
  %251 = shl i32 1, %250
  %252 = trunc i32 %251 to i16
  %253 = insertelement <8 x i16> undef, i16 %252, i32 0
  %254 = shufflevector <8 x i16> %253, <8 x i16> undef, <8 x i32> zeroinitializer
  %255 = bitcast <2 x i64>* %243 to <8 x i16>*
  %256 = load <8 x i16>, <8 x i16>* %255, align 16
  %257 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %256, <8 x i16> %254) #8
  %258 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %257, i32 %249) #8
  store <8 x i16> %258, <8 x i16>* %255, align 16
  %259 = getelementptr inbounds <2 x i64>, <2 x i64>* %243, i64 1
  %260 = bitcast <2 x i64>* %259 to <8 x i16>*
  %261 = load <8 x i16>, <8 x i16>* %260, align 16
  %262 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %261, <8 x i16> %254) #8
  %263 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %262, i32 %249) #8
  store <8 x i16> %263, <8 x i16>* %260, align 16
  %264 = getelementptr inbounds <2 x i64>, <2 x i64>* %243, i64 2
  %265 = bitcast <2 x i64>* %264 to <8 x i16>*
  %266 = load <8 x i16>, <8 x i16>* %265, align 16
  %267 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %266, <8 x i16> %254) #8
  %268 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %267, i32 %249) #8
  store <8 x i16> %268, <8 x i16>* %265, align 16
  %269 = getelementptr inbounds <2 x i64>, <2 x i64>* %243, i64 3
  %270 = bitcast <2 x i64>* %269 to <8 x i16>*
  %271 = load <8 x i16>, <8 x i16>* %270, align 16
  %272 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %271, <8 x i16> %254) #8
  %273 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %272, i32 %249) #8
  store <8 x i16> %273, <8 x i16>* %270, align 16
  %274 = getelementptr inbounds <2 x i64>, <2 x i64>* %243, i64 4
  %275 = bitcast <2 x i64>* %274 to <8 x i16>*
  %276 = load <8 x i16>, <8 x i16>* %275, align 16
  %277 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %276, <8 x i16> %254) #8
  %278 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %277, i32 %249) #8
  store <8 x i16> %278, <8 x i16>* %275, align 16
  %279 = getelementptr inbounds <2 x i64>, <2 x i64>* %243, i64 5
  %280 = bitcast <2 x i64>* %279 to <8 x i16>*
  %281 = load <8 x i16>, <8 x i16>* %280, align 16
  %282 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %281, <8 x i16> %254) #8
  %283 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %282, i32 %249) #8
  store <8 x i16> %283, <8 x i16>* %280, align 16
  %284 = getelementptr inbounds <2 x i64>, <2 x i64>* %243, i64 6
  %285 = bitcast <2 x i64>* %284 to <8 x i16>*
  %286 = load <8 x i16>, <8 x i16>* %285, align 16
  %287 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %286, <8 x i16> %254) #8
  %288 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %287, i32 %249) #8
  store <8 x i16> %288, <8 x i16>* %285, align 16
  %289 = getelementptr inbounds <2 x i64>, <2 x i64>* %243, i64 7
  %290 = bitcast <2 x i64>* %289 to <8 x i16>*
  %291 = load <8 x i16>, <8 x i16>* %290, align 16
  %292 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %291, <8 x i16> %254) #8
  %293 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %292, i32 %249) #8
  store <8 x i16> %293, <8 x i16>* %290, align 16
  br label %350

294:                                              ; preds = %242
  %295 = icmp eq i8 %245, 0
  %296 = bitcast <2 x i64>* %243 to <8 x i16>*
  %297 = load <8 x i16>, <8 x i16>* %296, align 16
  br i1 %295, label %298, label %320

298:                                              ; preds = %294
  %299 = getelementptr inbounds <2 x i64>, <2 x i64>* %243, i64 1
  %300 = bitcast <2 x i64>* %299 to <8 x i16>*
  %301 = load <8 x i16>, <8 x i16>* %300, align 16
  %302 = getelementptr inbounds <2 x i64>, <2 x i64>* %243, i64 2
  %303 = bitcast <2 x i64>* %302 to <8 x i16>*
  %304 = load <8 x i16>, <8 x i16>* %303, align 16
  %305 = getelementptr inbounds <2 x i64>, <2 x i64>* %243, i64 3
  %306 = bitcast <2 x i64>* %305 to <8 x i16>*
  %307 = load <8 x i16>, <8 x i16>* %306, align 16
  %308 = getelementptr inbounds <2 x i64>, <2 x i64>* %243, i64 4
  %309 = bitcast <2 x i64>* %308 to <8 x i16>*
  %310 = load <8 x i16>, <8 x i16>* %309, align 16
  %311 = getelementptr inbounds <2 x i64>, <2 x i64>* %243, i64 5
  %312 = bitcast <2 x i64>* %311 to <8 x i16>*
  %313 = load <8 x i16>, <8 x i16>* %312, align 16
  %314 = getelementptr inbounds <2 x i64>, <2 x i64>* %243, i64 6
  %315 = bitcast <2 x i64>* %314 to <8 x i16>*
  %316 = load <8 x i16>, <8 x i16>* %315, align 16
  %317 = getelementptr inbounds <2 x i64>, <2 x i64>* %243, i64 7
  %318 = bitcast <2 x i64>* %317 to <8 x i16>*
  %319 = load <8 x i16>, <8 x i16>* %318, align 16
  br label %350

320:                                              ; preds = %294
  %321 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %297, i32 %246) #8
  store <8 x i16> %321, <8 x i16>* %296, align 16
  %322 = getelementptr inbounds <2 x i64>, <2 x i64>* %243, i64 1
  %323 = bitcast <2 x i64>* %322 to <8 x i16>*
  %324 = load <8 x i16>, <8 x i16>* %323, align 16
  %325 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %324, i32 %246) #8
  store <8 x i16> %325, <8 x i16>* %323, align 16
  %326 = getelementptr inbounds <2 x i64>, <2 x i64>* %243, i64 2
  %327 = bitcast <2 x i64>* %326 to <8 x i16>*
  %328 = load <8 x i16>, <8 x i16>* %327, align 16
  %329 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %328, i32 %246) #8
  store <8 x i16> %329, <8 x i16>* %327, align 16
  %330 = getelementptr inbounds <2 x i64>, <2 x i64>* %243, i64 3
  %331 = bitcast <2 x i64>* %330 to <8 x i16>*
  %332 = load <8 x i16>, <8 x i16>* %331, align 16
  %333 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %332, i32 %246) #8
  store <8 x i16> %333, <8 x i16>* %331, align 16
  %334 = getelementptr inbounds <2 x i64>, <2 x i64>* %243, i64 4
  %335 = bitcast <2 x i64>* %334 to <8 x i16>*
  %336 = load <8 x i16>, <8 x i16>* %335, align 16
  %337 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %336, i32 %246) #8
  store <8 x i16> %337, <8 x i16>* %335, align 16
  %338 = getelementptr inbounds <2 x i64>, <2 x i64>* %243, i64 5
  %339 = bitcast <2 x i64>* %338 to <8 x i16>*
  %340 = load <8 x i16>, <8 x i16>* %339, align 16
  %341 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %340, i32 %246) #8
  store <8 x i16> %341, <8 x i16>* %339, align 16
  %342 = getelementptr inbounds <2 x i64>, <2 x i64>* %243, i64 6
  %343 = bitcast <2 x i64>* %342 to <8 x i16>*
  %344 = load <8 x i16>, <8 x i16>* %343, align 16
  %345 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %344, i32 %246) #8
  store <8 x i16> %345, <8 x i16>* %343, align 16
  %346 = getelementptr inbounds <2 x i64>, <2 x i64>* %243, i64 7
  %347 = bitcast <2 x i64>* %346 to <8 x i16>*
  %348 = load <8 x i16>, <8 x i16>* %347, align 16
  %349 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %348, i32 %246) #8
  store <8 x i16> %349, <8 x i16>* %347, align 16
  br label %350

350:                                              ; preds = %298, %320, %248
  %351 = phi <8 x i16> [ %319, %298 ], [ %349, %320 ], [ %293, %248 ]
  %352 = phi <8 x i16> [ %316, %298 ], [ %345, %320 ], [ %288, %248 ]
  %353 = phi <8 x i16> [ %313, %298 ], [ %341, %320 ], [ %283, %248 ]
  %354 = phi <8 x i16> [ %310, %298 ], [ %337, %320 ], [ %278, %248 ]
  %355 = phi <8 x i16> [ %307, %298 ], [ %333, %320 ], [ %273, %248 ]
  %356 = phi <8 x i16> [ %304, %298 ], [ %329, %320 ], [ %268, %248 ]
  %357 = phi <8 x i16> [ %301, %298 ], [ %325, %320 ], [ %263, %248 ]
  %358 = phi <8 x i16> [ %297, %298 ], [ %321, %320 ], [ %258, %248 ]
  %359 = getelementptr inbounds <2 x i64>, <2 x i64>* %243, i64 1
  %360 = shufflevector <8 x i16> %358, <8 x i16> %357, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %361 = getelementptr inbounds <2 x i64>, <2 x i64>* %243, i64 2
  %362 = getelementptr inbounds <2 x i64>, <2 x i64>* %243, i64 3
  %363 = shufflevector <8 x i16> %356, <8 x i16> %355, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %364 = getelementptr inbounds <2 x i64>, <2 x i64>* %243, i64 4
  %365 = getelementptr inbounds <2 x i64>, <2 x i64>* %243, i64 5
  %366 = shufflevector <8 x i16> %354, <8 x i16> %353, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %367 = getelementptr inbounds <2 x i64>, <2 x i64>* %243, i64 6
  %368 = getelementptr inbounds <2 x i64>, <2 x i64>* %243, i64 7
  %369 = shufflevector <8 x i16> %352, <8 x i16> %351, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %370 = shufflevector <8 x i16> %358, <8 x i16> %357, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %371 = shufflevector <8 x i16> %356, <8 x i16> %355, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %372 = shufflevector <8 x i16> %354, <8 x i16> %353, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %373 = shufflevector <8 x i16> %352, <8 x i16> %351, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %374 = bitcast <8 x i16> %360 to <4 x i32>
  %375 = bitcast <8 x i16> %363 to <4 x i32>
  %376 = shufflevector <4 x i32> %374, <4 x i32> %375, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %377 = bitcast <4 x i32> %376 to <2 x i64>
  %378 = bitcast <8 x i16> %366 to <4 x i32>
  %379 = bitcast <8 x i16> %369 to <4 x i32>
  %380 = shufflevector <4 x i32> %378, <4 x i32> %379, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %381 = bitcast <4 x i32> %380 to <2 x i64>
  %382 = bitcast <8 x i16> %370 to <4 x i32>
  %383 = bitcast <8 x i16> %371 to <4 x i32>
  %384 = shufflevector <4 x i32> %382, <4 x i32> %383, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %385 = bitcast <4 x i32> %384 to <2 x i64>
  %386 = bitcast <8 x i16> %372 to <4 x i32>
  %387 = bitcast <8 x i16> %373 to <4 x i32>
  %388 = shufflevector <4 x i32> %386, <4 x i32> %387, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %389 = bitcast <4 x i32> %388 to <2 x i64>
  %390 = shufflevector <4 x i32> %374, <4 x i32> %375, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %391 = bitcast <4 x i32> %390 to <2 x i64>
  %392 = shufflevector <4 x i32> %378, <4 x i32> %379, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %393 = bitcast <4 x i32> %392 to <2 x i64>
  %394 = shufflevector <4 x i32> %382, <4 x i32> %383, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %395 = bitcast <4 x i32> %394 to <2 x i64>
  %396 = shufflevector <4 x i32> %386, <4 x i32> %387, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %397 = bitcast <4 x i32> %396 to <2 x i64>
  %398 = shufflevector <2 x i64> %377, <2 x i64> %381, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %398, <2 x i64>* %243, align 16
  %399 = shufflevector <2 x i64> %377, <2 x i64> %381, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %399, <2 x i64>* %359, align 16
  %400 = shufflevector <2 x i64> %391, <2 x i64> %393, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %400, <2 x i64>* %361, align 16
  %401 = shufflevector <2 x i64> %391, <2 x i64> %393, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %401, <2 x i64>* %362, align 16
  %402 = shufflevector <2 x i64> %385, <2 x i64> %389, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %402, <2 x i64>* %364, align 16
  %403 = shufflevector <2 x i64> %385, <2 x i64> %389, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %403, <2 x i64>* %365, align 16
  %404 = shufflevector <2 x i64> %395, <2 x i64> %397, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %404, <2 x i64>* %367, align 16
  %405 = shufflevector <2 x i64> %395, <2 x i64> %397, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %405, <2 x i64>* %368, align 16
  %406 = bitcast <2 x i64> %398 to <8 x i16>
  %407 = shufflevector <8 x i16> %406, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %408 = shufflevector <8 x i16> %406, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %409 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %407, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %410 = ashr <4 x i32> %409, <i32 12, i32 12, i32 12, i32 12>
  %411 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %408, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %412 = ashr <4 x i32> %411, <i32 12, i32 12, i32 12, i32 12>
  %413 = bitcast i32* %1 to <4 x i32>*
  store <4 x i32> %410, <4 x i32>* %413, align 16
  %414 = getelementptr inbounds i32, i32* %1, i64 4
  %415 = bitcast i32* %414 to <4 x i32>*
  store <4 x i32> %412, <4 x i32>* %415, align 16
  %416 = bitcast <2 x i64> %399 to <8 x i16>
  %417 = getelementptr inbounds i32, i32* %1, i64 8
  %418 = shufflevector <8 x i16> %416, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %419 = shufflevector <8 x i16> %416, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %420 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %418, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %421 = ashr <4 x i32> %420, <i32 12, i32 12, i32 12, i32 12>
  %422 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %419, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %423 = ashr <4 x i32> %422, <i32 12, i32 12, i32 12, i32 12>
  %424 = bitcast i32* %417 to <4 x i32>*
  store <4 x i32> %421, <4 x i32>* %424, align 16
  %425 = getelementptr inbounds i32, i32* %1, i64 12
  %426 = bitcast i32* %425 to <4 x i32>*
  store <4 x i32> %423, <4 x i32>* %426, align 16
  %427 = bitcast <2 x i64> %400 to <8 x i16>
  %428 = getelementptr inbounds i32, i32* %1, i64 16
  %429 = shufflevector <8 x i16> %427, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %430 = shufflevector <8 x i16> %427, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %431 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %429, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %432 = ashr <4 x i32> %431, <i32 12, i32 12, i32 12, i32 12>
  %433 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %430, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %434 = ashr <4 x i32> %433, <i32 12, i32 12, i32 12, i32 12>
  %435 = bitcast i32* %428 to <4 x i32>*
  store <4 x i32> %432, <4 x i32>* %435, align 16
  %436 = getelementptr inbounds i32, i32* %1, i64 20
  %437 = bitcast i32* %436 to <4 x i32>*
  store <4 x i32> %434, <4 x i32>* %437, align 16
  %438 = bitcast <2 x i64> %401 to <8 x i16>
  %439 = getelementptr inbounds i32, i32* %1, i64 24
  %440 = shufflevector <8 x i16> %438, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %441 = shufflevector <8 x i16> %438, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %442 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %440, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %443 = ashr <4 x i32> %442, <i32 12, i32 12, i32 12, i32 12>
  %444 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %441, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %445 = ashr <4 x i32> %444, <i32 12, i32 12, i32 12, i32 12>
  %446 = bitcast i32* %439 to <4 x i32>*
  store <4 x i32> %443, <4 x i32>* %446, align 16
  %447 = getelementptr inbounds i32, i32* %1, i64 28
  %448 = bitcast i32* %447 to <4 x i32>*
  store <4 x i32> %445, <4 x i32>* %448, align 16
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %9) #8
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %8) #8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @av1_lowbd_fwd_txfm2d_8x8_sse2(i16* nocapture readonly, i32* nocapture, i32, i8 zeroext, i32) #2 {
  %6 = alloca [8 x <2 x i64>], align 16
  %7 = alloca [8 x <2 x i64>], align 16
  %8 = bitcast [8 x <2 x i64>]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %8) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %8, i8 -86, i64 128, i1 false)
  %9 = bitcast [8 x <2 x i64>]* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 128, i8* nonnull %9) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 128, i1 false)
  %10 = load i8*, i8** getelementptr inbounds ([19 x i8*], [19 x i8*]* @av1_fwd_txfm_shift_ls, i64 0, i64 1), align 8
  %11 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_fwd_cos_bit_col, i64 0, i64 1, i64 1), align 1
  %12 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_fwd_cos_bit_row, i64 0, i64 1, i64 1), align 1
  %13 = zext i8 %3 to i64
  %14 = getelementptr inbounds [16 x void (<2 x i64>*, <2 x i64>*, i8)*], [16 x void (<2 x i64>*, <2 x i64>*, i8)*]* @col_txfm8x8_arr, i64 0, i64 %13
  %15 = load void (<2 x i64>*, <2 x i64>*, i8)*, void (<2 x i64>*, <2 x i64>*, i8)** %14, align 8
  %16 = getelementptr inbounds [16 x void (<2 x i64>*, <2 x i64>*, i8)*], [16 x void (<2 x i64>*, <2 x i64>*, i8)*]* @row_txfm8x8_arr, i64 0, i64 %13
  %17 = load void (<2 x i64>*, <2 x i64>*, i8)*, void (<2 x i64>*, <2 x i64>*, i8)** %16, align 8
  switch i8 %3, label %60 [
    i8 6, label %19
    i8 15, label %18
    i8 7, label %18
    i8 5, label %18
    i8 14, label %20
    i8 8, label %20
    i8 4, label %20
  ]

18:                                               ; preds = %5, %5, %5
  br label %60

19:                                               ; preds = %5
  br label %20

20:                                               ; preds = %5, %5, %5, %19
  %21 = phi i32 [ 1, %19 ], [ 0, %5 ], [ 0, %5 ], [ 0, %5 ]
  %22 = sext i32 %2 to i64
  %23 = bitcast i16* %0 to <2 x i64>*
  %24 = load <2 x i64>, <2 x i64>* %23, align 16
  %25 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 7
  store <2 x i64> %24, <2 x i64>* %25, align 16
  %26 = getelementptr inbounds i16, i16* %0, i64 %22
  %27 = bitcast i16* %26 to <2 x i64>*
  %28 = load <2 x i64>, <2 x i64>* %27, align 16
  %29 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 6
  store <2 x i64> %28, <2 x i64>* %29, align 16
  %30 = shl nsw i64 %22, 1
  %31 = getelementptr inbounds i16, i16* %0, i64 %30
  %32 = bitcast i16* %31 to <2 x i64>*
  %33 = load <2 x i64>, <2 x i64>* %32, align 16
  %34 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 5
  store <2 x i64> %33, <2 x i64>* %34, align 16
  %35 = mul nsw i64 %22, 3
  %36 = getelementptr inbounds i16, i16* %0, i64 %35
  %37 = bitcast i16* %36 to <2 x i64>*
  %38 = load <2 x i64>, <2 x i64>* %37, align 16
  %39 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 4
  store <2 x i64> %38, <2 x i64>* %39, align 16
  %40 = shl nsw i64 %22, 2
  %41 = getelementptr inbounds i16, i16* %0, i64 %40
  %42 = bitcast i16* %41 to <2 x i64>*
  %43 = load <2 x i64>, <2 x i64>* %42, align 16
  %44 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 3
  store <2 x i64> %43, <2 x i64>* %44, align 16
  %45 = mul nsw i64 %22, 5
  %46 = getelementptr inbounds i16, i16* %0, i64 %45
  %47 = bitcast i16* %46 to <2 x i64>*
  %48 = load <2 x i64>, <2 x i64>* %47, align 16
  %49 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 2
  store <2 x i64> %48, <2 x i64>* %49, align 16
  %50 = mul nsw i64 %22, 6
  %51 = getelementptr inbounds i16, i16* %0, i64 %50
  %52 = bitcast i16* %51 to <2 x i64>*
  %53 = load <2 x i64>, <2 x i64>* %52, align 16
  %54 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 1
  store <2 x i64> %53, <2 x i64>* %54, align 16
  %55 = mul nsw i64 %22, 7
  %56 = getelementptr inbounds i16, i16* %0, i64 %55
  %57 = bitcast i16* %56 to <2 x i64>*
  %58 = load <2 x i64>, <2 x i64>* %57, align 16
  %59 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 0
  store <2 x i64> %58, <2 x i64>* %59, align 16
  br label %100

60:                                               ; preds = %18, %5
  %61 = phi i32 [ 0, %5 ], [ 1, %18 ]
  %62 = sext i32 %2 to i64
  %63 = bitcast i16* %0 to <2 x i64>*
  %64 = load <2 x i64>, <2 x i64>* %63, align 16
  %65 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 0
  store <2 x i64> %64, <2 x i64>* %65, align 16
  %66 = getelementptr inbounds i16, i16* %0, i64 %62
  %67 = bitcast i16* %66 to <2 x i64>*
  %68 = load <2 x i64>, <2 x i64>* %67, align 16
  %69 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 1
  store <2 x i64> %68, <2 x i64>* %69, align 16
  %70 = shl nsw i64 %62, 1
  %71 = getelementptr inbounds i16, i16* %0, i64 %70
  %72 = bitcast i16* %71 to <2 x i64>*
  %73 = load <2 x i64>, <2 x i64>* %72, align 16
  %74 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 2
  store <2 x i64> %73, <2 x i64>* %74, align 16
  %75 = mul nsw i64 %62, 3
  %76 = getelementptr inbounds i16, i16* %0, i64 %75
  %77 = bitcast i16* %76 to <2 x i64>*
  %78 = load <2 x i64>, <2 x i64>* %77, align 16
  %79 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 3
  store <2 x i64> %78, <2 x i64>* %79, align 16
  %80 = shl nsw i64 %62, 2
  %81 = getelementptr inbounds i16, i16* %0, i64 %80
  %82 = bitcast i16* %81 to <2 x i64>*
  %83 = load <2 x i64>, <2 x i64>* %82, align 16
  %84 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 4
  store <2 x i64> %83, <2 x i64>* %84, align 16
  %85 = mul nsw i64 %62, 5
  %86 = getelementptr inbounds i16, i16* %0, i64 %85
  %87 = bitcast i16* %86 to <2 x i64>*
  %88 = load <2 x i64>, <2 x i64>* %87, align 16
  %89 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 5
  store <2 x i64> %88, <2 x i64>* %89, align 16
  %90 = mul nsw i64 %62, 6
  %91 = getelementptr inbounds i16, i16* %0, i64 %90
  %92 = bitcast i16* %91 to <2 x i64>*
  %93 = load <2 x i64>, <2 x i64>* %92, align 16
  %94 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 6
  store <2 x i64> %93, <2 x i64>* %94, align 16
  %95 = mul nsw i64 %62, 7
  %96 = getelementptr inbounds i16, i16* %0, i64 %95
  %97 = bitcast i16* %96 to <2 x i64>*
  %98 = load <2 x i64>, <2 x i64>* %97, align 16
  %99 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 7
  store <2 x i64> %98, <2 x i64>* %99, align 16
  br label %100

100:                                              ; preds = %20, %60
  %101 = phi <2 x i64> [ %98, %60 ], [ %24, %20 ]
  %102 = phi <2 x i64> [ %93, %60 ], [ %28, %20 ]
  %103 = phi <2 x i64> [ %88, %60 ], [ %33, %20 ]
  %104 = phi <2 x i64> [ %83, %60 ], [ %38, %20 ]
  %105 = phi <2 x i64> [ %78, %60 ], [ %43, %20 ]
  %106 = phi <2 x i64> [ %73, %60 ], [ %48, %20 ]
  %107 = phi <2 x i64> [ %68, %60 ], [ %53, %20 ]
  %108 = phi <2 x i64> [ %64, %60 ], [ %58, %20 ]
  %109 = phi <2 x i64>* [ %65, %60 ], [ %59, %20 ]
  %110 = phi i32 [ %61, %60 ], [ %21, %20 ]
  %111 = bitcast <2 x i64> %108 to <8 x i16>
  %112 = bitcast <2 x i64> %107 to <8 x i16>
  %113 = bitcast <2 x i64> %106 to <8 x i16>
  %114 = bitcast <2 x i64> %105 to <8 x i16>
  %115 = bitcast <2 x i64> %104 to <8 x i16>
  %116 = bitcast <2 x i64> %103 to <8 x i16>
  %117 = bitcast <2 x i64> %102 to <8 x i16>
  %118 = bitcast <2 x i64> %101 to <8 x i16>
  %119 = load i8, i8* %10, align 1
  %120 = sext i8 %119 to i32
  %121 = icmp slt i8 %119, 0
  br i1 %121, label %122, label %160

122:                                              ; preds = %100
  %123 = sub nsw i32 0, %120
  %124 = xor i32 %120, -1
  %125 = shl i32 1, %124
  %126 = trunc i32 %125 to i16
  %127 = insertelement <8 x i16> undef, i16 %126, i32 0
  %128 = shufflevector <8 x i16> %127, <8 x i16> undef, <8 x i32> zeroinitializer
  %129 = bitcast [8 x <2 x i64>]* %6 to <8 x i16>*
  %130 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %111, <8 x i16> %128) #8
  %131 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %130, i32 %123) #8
  store <8 x i16> %131, <8 x i16>* %129, align 16
  %132 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 1
  %133 = bitcast <2 x i64>* %132 to <8 x i16>*
  %134 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %112, <8 x i16> %128) #8
  %135 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %134, i32 %123) #8
  store <8 x i16> %135, <8 x i16>* %133, align 16
  %136 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 2
  %137 = bitcast <2 x i64>* %136 to <8 x i16>*
  %138 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %113, <8 x i16> %128) #8
  %139 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %138, i32 %123) #8
  store <8 x i16> %139, <8 x i16>* %137, align 16
  %140 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 3
  %141 = bitcast <2 x i64>* %140 to <8 x i16>*
  %142 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %114, <8 x i16> %128) #8
  %143 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %142, i32 %123) #8
  store <8 x i16> %143, <8 x i16>* %141, align 16
  %144 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 4
  %145 = bitcast <2 x i64>* %144 to <8 x i16>*
  %146 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %115, <8 x i16> %128) #8
  %147 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %146, i32 %123) #8
  store <8 x i16> %147, <8 x i16>* %145, align 16
  %148 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 5
  %149 = bitcast <2 x i64>* %148 to <8 x i16>*
  %150 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %116, <8 x i16> %128) #8
  %151 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %150, i32 %123) #8
  store <8 x i16> %151, <8 x i16>* %149, align 16
  %152 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 6
  %153 = bitcast <2 x i64>* %152 to <8 x i16>*
  %154 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %117, <8 x i16> %128) #8
  %155 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %154, i32 %123) #8
  store <8 x i16> %155, <8 x i16>* %153, align 16
  %156 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 7
  %157 = bitcast <2 x i64>* %156 to <8 x i16>*
  %158 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %118, <8 x i16> %128) #8
  %159 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %158, i32 %123) #8
  store <8 x i16> %159, <8 x i16>* %157, align 16
  br label %186

160:                                              ; preds = %100
  %161 = icmp eq i8 %119, 0
  br i1 %161, label %186, label %162

162:                                              ; preds = %160
  %163 = bitcast [8 x <2 x i64>]* %6 to <8 x i16>*
  %164 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %111, i32 %120) #8
  store <8 x i16> %164, <8 x i16>* %163, align 16
  %165 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 1
  %166 = bitcast <2 x i64>* %165 to <8 x i16>*
  %167 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %112, i32 %120) #8
  store <8 x i16> %167, <8 x i16>* %166, align 16
  %168 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 2
  %169 = bitcast <2 x i64>* %168 to <8 x i16>*
  %170 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %113, i32 %120) #8
  store <8 x i16> %170, <8 x i16>* %169, align 16
  %171 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 3
  %172 = bitcast <2 x i64>* %171 to <8 x i16>*
  %173 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %114, i32 %120) #8
  store <8 x i16> %173, <8 x i16>* %172, align 16
  %174 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 4
  %175 = bitcast <2 x i64>* %174 to <8 x i16>*
  %176 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %115, i32 %120) #8
  store <8 x i16> %176, <8 x i16>* %175, align 16
  %177 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 5
  %178 = bitcast <2 x i64>* %177 to <8 x i16>*
  %179 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %116, i32 %120) #8
  store <8 x i16> %179, <8 x i16>* %178, align 16
  %180 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 6
  %181 = bitcast <2 x i64>* %180 to <8 x i16>*
  %182 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %117, i32 %120) #8
  store <8 x i16> %182, <8 x i16>* %181, align 16
  %183 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 7
  %184 = bitcast <2 x i64>* %183 to <8 x i16>*
  %185 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %118, i32 %120) #8
  store <8 x i16> %185, <8 x i16>* %184, align 16
  br label %186

186:                                              ; preds = %162, %122, %160
  call void %15(<2 x i64>* %109, <2 x i64>* %109, i8 signext %11) #8
  %187 = getelementptr inbounds i8, i8* %10, i64 1
  %188 = load i8, i8* %187, align 1
  %189 = sext i8 %188 to i32
  %190 = icmp slt i8 %188, 0
  br i1 %190, label %191, label %237

191:                                              ; preds = %186
  %192 = sub nsw i32 0, %189
  %193 = xor i32 %189, -1
  %194 = shl i32 1, %193
  %195 = trunc i32 %194 to i16
  %196 = insertelement <8 x i16> undef, i16 %195, i32 0
  %197 = shufflevector <8 x i16> %196, <8 x i16> undef, <8 x i32> zeroinitializer
  %198 = bitcast [8 x <2 x i64>]* %6 to <8 x i16>*
  %199 = load <8 x i16>, <8 x i16>* %198, align 16
  %200 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %199, <8 x i16> %197) #8
  %201 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %200, i32 %192) #8
  store <8 x i16> %201, <8 x i16>* %198, align 16
  %202 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 1
  %203 = bitcast <2 x i64>* %202 to <8 x i16>*
  %204 = load <8 x i16>, <8 x i16>* %203, align 16
  %205 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %204, <8 x i16> %197) #8
  %206 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %205, i32 %192) #8
  store <8 x i16> %206, <8 x i16>* %203, align 16
  %207 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 2
  %208 = bitcast <2 x i64>* %207 to <8 x i16>*
  %209 = load <8 x i16>, <8 x i16>* %208, align 16
  %210 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %209, <8 x i16> %197) #8
  %211 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %210, i32 %192) #8
  store <8 x i16> %211, <8 x i16>* %208, align 16
  %212 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 3
  %213 = bitcast <2 x i64>* %212 to <8 x i16>*
  %214 = load <8 x i16>, <8 x i16>* %213, align 16
  %215 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %214, <8 x i16> %197) #8
  %216 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %215, i32 %192) #8
  store <8 x i16> %216, <8 x i16>* %213, align 16
  %217 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 4
  %218 = bitcast <2 x i64>* %217 to <8 x i16>*
  %219 = load <8 x i16>, <8 x i16>* %218, align 16
  %220 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %219, <8 x i16> %197) #8
  %221 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %220, i32 %192) #8
  store <8 x i16> %221, <8 x i16>* %218, align 16
  %222 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 5
  %223 = bitcast <2 x i64>* %222 to <8 x i16>*
  %224 = load <8 x i16>, <8 x i16>* %223, align 16
  %225 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %224, <8 x i16> %197) #8
  %226 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %225, i32 %192) #8
  store <8 x i16> %226, <8 x i16>* %223, align 16
  %227 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 6
  %228 = bitcast <2 x i64>* %227 to <8 x i16>*
  %229 = load <8 x i16>, <8 x i16>* %228, align 16
  %230 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %229, <8 x i16> %197) #8
  %231 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %230, i32 %192) #8
  store <8 x i16> %231, <8 x i16>* %228, align 16
  %232 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 7
  %233 = bitcast <2 x i64>* %232 to <8 x i16>*
  %234 = load <8 x i16>, <8 x i16>* %233, align 16
  %235 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %234, <8 x i16> %197) #8
  %236 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %235, i32 %192) #8
  store <8 x i16> %236, <8 x i16>* %233, align 16
  br label %295

237:                                              ; preds = %186
  %238 = icmp eq i8 %188, 0
  br i1 %238, label %239, label %263

239:                                              ; preds = %237
  %240 = bitcast <2 x i64>* %109 to <8 x i16>*
  %241 = load <8 x i16>, <8 x i16>* %240, align 16
  %242 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 1
  %243 = bitcast <2 x i64>* %242 to <8 x i16>*
  %244 = load <8 x i16>, <8 x i16>* %243, align 16
  %245 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 2
  %246 = bitcast <2 x i64>* %245 to <8 x i16>*
  %247 = load <8 x i16>, <8 x i16>* %246, align 16
  %248 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 3
  %249 = bitcast <2 x i64>* %248 to <8 x i16>*
  %250 = load <8 x i16>, <8 x i16>* %249, align 16
  %251 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 4
  %252 = bitcast <2 x i64>* %251 to <8 x i16>*
  %253 = load <8 x i16>, <8 x i16>* %252, align 16
  %254 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 5
  %255 = bitcast <2 x i64>* %254 to <8 x i16>*
  %256 = load <8 x i16>, <8 x i16>* %255, align 16
  %257 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 6
  %258 = bitcast <2 x i64>* %257 to <8 x i16>*
  %259 = load <8 x i16>, <8 x i16>* %258, align 16
  %260 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 7
  %261 = bitcast <2 x i64>* %260 to <8 x i16>*
  %262 = load <8 x i16>, <8 x i16>* %261, align 16
  br label %295

263:                                              ; preds = %237
  %264 = bitcast [8 x <2 x i64>]* %6 to <8 x i16>*
  %265 = load <8 x i16>, <8 x i16>* %264, align 16
  %266 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %265, i32 %189) #8
  store <8 x i16> %266, <8 x i16>* %264, align 16
  %267 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 1
  %268 = bitcast <2 x i64>* %267 to <8 x i16>*
  %269 = load <8 x i16>, <8 x i16>* %268, align 16
  %270 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %269, i32 %189) #8
  store <8 x i16> %270, <8 x i16>* %268, align 16
  %271 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 2
  %272 = bitcast <2 x i64>* %271 to <8 x i16>*
  %273 = load <8 x i16>, <8 x i16>* %272, align 16
  %274 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %273, i32 %189) #8
  store <8 x i16> %274, <8 x i16>* %272, align 16
  %275 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 3
  %276 = bitcast <2 x i64>* %275 to <8 x i16>*
  %277 = load <8 x i16>, <8 x i16>* %276, align 16
  %278 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %277, i32 %189) #8
  store <8 x i16> %278, <8 x i16>* %276, align 16
  %279 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 4
  %280 = bitcast <2 x i64>* %279 to <8 x i16>*
  %281 = load <8 x i16>, <8 x i16>* %280, align 16
  %282 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %281, i32 %189) #8
  store <8 x i16> %282, <8 x i16>* %280, align 16
  %283 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 5
  %284 = bitcast <2 x i64>* %283 to <8 x i16>*
  %285 = load <8 x i16>, <8 x i16>* %284, align 16
  %286 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %285, i32 %189) #8
  store <8 x i16> %286, <8 x i16>* %284, align 16
  %287 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 6
  %288 = bitcast <2 x i64>* %287 to <8 x i16>*
  %289 = load <8 x i16>, <8 x i16>* %288, align 16
  %290 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %289, i32 %189) #8
  store <8 x i16> %290, <8 x i16>* %288, align 16
  %291 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 7
  %292 = bitcast <2 x i64>* %291 to <8 x i16>*
  %293 = load <8 x i16>, <8 x i16>* %292, align 16
  %294 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %293, i32 %189) #8
  store <8 x i16> %294, <8 x i16>* %292, align 16
  br label %295

295:                                              ; preds = %239, %263, %191
  %296 = phi <8 x i16> [ %262, %239 ], [ %294, %263 ], [ %236, %191 ]
  %297 = phi <8 x i16> [ %259, %239 ], [ %290, %263 ], [ %231, %191 ]
  %298 = phi <8 x i16> [ %256, %239 ], [ %286, %263 ], [ %226, %191 ]
  %299 = phi <8 x i16> [ %253, %239 ], [ %282, %263 ], [ %221, %191 ]
  %300 = phi <8 x i16> [ %250, %239 ], [ %278, %263 ], [ %216, %191 ]
  %301 = phi <8 x i16> [ %247, %239 ], [ %274, %263 ], [ %211, %191 ]
  %302 = phi <8 x i16> [ %244, %239 ], [ %270, %263 ], [ %206, %191 ]
  %303 = phi <8 x i16> [ %241, %239 ], [ %266, %263 ], [ %201, %191 ]
  %304 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %7, i64 0, i64 0
  %305 = shufflevector <8 x i16> %303, <8 x i16> %302, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %306 = shufflevector <8 x i16> %301, <8 x i16> %300, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %307 = shufflevector <8 x i16> %299, <8 x i16> %298, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %308 = shufflevector <8 x i16> %297, <8 x i16> %296, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %309 = shufflevector <8 x i16> %303, <8 x i16> %302, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %310 = shufflevector <8 x i16> %301, <8 x i16> %300, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %311 = shufflevector <8 x i16> %299, <8 x i16> %298, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %312 = shufflevector <8 x i16> %297, <8 x i16> %296, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %313 = bitcast <8 x i16> %305 to <4 x i32>
  %314 = bitcast <8 x i16> %306 to <4 x i32>
  %315 = shufflevector <4 x i32> %313, <4 x i32> %314, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %316 = bitcast <4 x i32> %315 to <2 x i64>
  %317 = bitcast <8 x i16> %307 to <4 x i32>
  %318 = bitcast <8 x i16> %308 to <4 x i32>
  %319 = shufflevector <4 x i32> %317, <4 x i32> %318, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %320 = bitcast <4 x i32> %319 to <2 x i64>
  %321 = bitcast <8 x i16> %309 to <4 x i32>
  %322 = bitcast <8 x i16> %310 to <4 x i32>
  %323 = shufflevector <4 x i32> %321, <4 x i32> %322, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %324 = bitcast <4 x i32> %323 to <2 x i64>
  %325 = bitcast <8 x i16> %311 to <4 x i32>
  %326 = bitcast <8 x i16> %312 to <4 x i32>
  %327 = shufflevector <4 x i32> %325, <4 x i32> %326, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %328 = bitcast <4 x i32> %327 to <2 x i64>
  %329 = shufflevector <4 x i32> %313, <4 x i32> %314, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %330 = bitcast <4 x i32> %329 to <2 x i64>
  %331 = shufflevector <4 x i32> %317, <4 x i32> %318, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %332 = bitcast <4 x i32> %331 to <2 x i64>
  %333 = shufflevector <4 x i32> %321, <4 x i32> %322, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %334 = bitcast <4 x i32> %333 to <2 x i64>
  %335 = shufflevector <4 x i32> %325, <4 x i32> %326, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %336 = bitcast <4 x i32> %335 to <2 x i64>
  %337 = shufflevector <2 x i64> %316, <2 x i64> %320, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %337, <2 x i64>* %304, align 16
  %338 = shufflevector <2 x i64> %316, <2 x i64> %320, <2 x i32> <i32 1, i32 3>
  %339 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %7, i64 0, i64 1
  store <2 x i64> %338, <2 x i64>* %339, align 16
  %340 = shufflevector <2 x i64> %330, <2 x i64> %332, <2 x i32> <i32 0, i32 2>
  %341 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %7, i64 0, i64 2
  store <2 x i64> %340, <2 x i64>* %341, align 16
  %342 = shufflevector <2 x i64> %330, <2 x i64> %332, <2 x i32> <i32 1, i32 3>
  %343 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %7, i64 0, i64 3
  store <2 x i64> %342, <2 x i64>* %343, align 16
  %344 = shufflevector <2 x i64> %324, <2 x i64> %328, <2 x i32> <i32 0, i32 2>
  %345 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %7, i64 0, i64 4
  store <2 x i64> %344, <2 x i64>* %345, align 16
  %346 = shufflevector <2 x i64> %324, <2 x i64> %328, <2 x i32> <i32 1, i32 3>
  %347 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %7, i64 0, i64 5
  store <2 x i64> %346, <2 x i64>* %347, align 16
  %348 = shufflevector <2 x i64> %334, <2 x i64> %336, <2 x i32> <i32 0, i32 2>
  %349 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %7, i64 0, i64 6
  store <2 x i64> %348, <2 x i64>* %349, align 16
  %350 = shufflevector <2 x i64> %334, <2 x i64> %336, <2 x i32> <i32 1, i32 3>
  %351 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %7, i64 0, i64 7
  store <2 x i64> %350, <2 x i64>* %351, align 16
  %352 = icmp eq i32 %110, 0
  br i1 %352, label %362, label %353

353:                                              ; preds = %295
  %354 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 7
  %355 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 6
  %356 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 5
  %357 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 4
  %358 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 3
  %359 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 2
  %360 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 1
  store <2 x i64> %337, <2 x i64>* %354, align 16
  store <2 x i64> %338, <2 x i64>* %355, align 16
  store <2 x i64> %340, <2 x i64>* %356, align 16
  store <2 x i64> %342, <2 x i64>* %357, align 16
  store <2 x i64> %344, <2 x i64>* %358, align 16
  store <2 x i64> %346, <2 x i64>* %359, align 16
  store <2 x i64> %348, <2 x i64>* %360, align 16
  %361 = getelementptr inbounds [8 x <2 x i64>], [8 x <2 x i64>]* %6, i64 0, i64 0
  store <2 x i64> %350, <2 x i64>* %361, align 16
  br label %362

362:                                              ; preds = %353, %295
  %363 = phi <2 x i64>* [ %304, %295 ], [ %109, %353 ]
  call void %17(<2 x i64>* %363, <2 x i64>* %363, i8 signext %12) #8
  %364 = getelementptr inbounds i8, i8* %10, i64 2
  %365 = load i8, i8* %364, align 1
  %366 = sext i8 %365 to i32
  %367 = icmp slt i8 %365, 0
  br i1 %367, label %368, label %414

368:                                              ; preds = %362
  %369 = sub nsw i32 0, %366
  %370 = xor i32 %366, -1
  %371 = shl i32 1, %370
  %372 = trunc i32 %371 to i16
  %373 = insertelement <8 x i16> undef, i16 %372, i32 0
  %374 = shufflevector <8 x i16> %373, <8 x i16> undef, <8 x i32> zeroinitializer
  %375 = bitcast <2 x i64>* %363 to <8 x i16>*
  %376 = load <8 x i16>, <8 x i16>* %375, align 16
  %377 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %376, <8 x i16> %374) #8
  %378 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %377, i32 %369) #8
  store <8 x i16> %378, <8 x i16>* %375, align 16
  %379 = getelementptr inbounds <2 x i64>, <2 x i64>* %363, i64 1
  %380 = bitcast <2 x i64>* %379 to <8 x i16>*
  %381 = load <8 x i16>, <8 x i16>* %380, align 16
  %382 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %381, <8 x i16> %374) #8
  %383 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %382, i32 %369) #8
  store <8 x i16> %383, <8 x i16>* %380, align 16
  %384 = getelementptr inbounds <2 x i64>, <2 x i64>* %363, i64 2
  %385 = bitcast <2 x i64>* %384 to <8 x i16>*
  %386 = load <8 x i16>, <8 x i16>* %385, align 16
  %387 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %386, <8 x i16> %374) #8
  %388 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %387, i32 %369) #8
  store <8 x i16> %388, <8 x i16>* %385, align 16
  %389 = getelementptr inbounds <2 x i64>, <2 x i64>* %363, i64 3
  %390 = bitcast <2 x i64>* %389 to <8 x i16>*
  %391 = load <8 x i16>, <8 x i16>* %390, align 16
  %392 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %391, <8 x i16> %374) #8
  %393 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %392, i32 %369) #8
  store <8 x i16> %393, <8 x i16>* %390, align 16
  %394 = getelementptr inbounds <2 x i64>, <2 x i64>* %363, i64 4
  %395 = bitcast <2 x i64>* %394 to <8 x i16>*
  %396 = load <8 x i16>, <8 x i16>* %395, align 16
  %397 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %396, <8 x i16> %374) #8
  %398 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %397, i32 %369) #8
  store <8 x i16> %398, <8 x i16>* %395, align 16
  %399 = getelementptr inbounds <2 x i64>, <2 x i64>* %363, i64 5
  %400 = bitcast <2 x i64>* %399 to <8 x i16>*
  %401 = load <8 x i16>, <8 x i16>* %400, align 16
  %402 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %401, <8 x i16> %374) #8
  %403 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %402, i32 %369) #8
  store <8 x i16> %403, <8 x i16>* %400, align 16
  %404 = getelementptr inbounds <2 x i64>, <2 x i64>* %363, i64 6
  %405 = bitcast <2 x i64>* %404 to <8 x i16>*
  %406 = load <8 x i16>, <8 x i16>* %405, align 16
  %407 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %406, <8 x i16> %374) #8
  %408 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %407, i32 %369) #8
  store <8 x i16> %408, <8 x i16>* %405, align 16
  %409 = getelementptr inbounds <2 x i64>, <2 x i64>* %363, i64 7
  %410 = bitcast <2 x i64>* %409 to <8 x i16>*
  %411 = load <8 x i16>, <8 x i16>* %410, align 16
  %412 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %411, <8 x i16> %374) #8
  %413 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %412, i32 %369) #8
  store <8 x i16> %413, <8 x i16>* %410, align 16
  br label %470

414:                                              ; preds = %362
  %415 = icmp eq i8 %365, 0
  %416 = bitcast <2 x i64>* %363 to <8 x i16>*
  %417 = load <8 x i16>, <8 x i16>* %416, align 16
  br i1 %415, label %418, label %440

418:                                              ; preds = %414
  %419 = getelementptr inbounds <2 x i64>, <2 x i64>* %363, i64 1
  %420 = bitcast <2 x i64>* %419 to <8 x i16>*
  %421 = load <8 x i16>, <8 x i16>* %420, align 16
  %422 = getelementptr inbounds <2 x i64>, <2 x i64>* %363, i64 2
  %423 = bitcast <2 x i64>* %422 to <8 x i16>*
  %424 = load <8 x i16>, <8 x i16>* %423, align 16
  %425 = getelementptr inbounds <2 x i64>, <2 x i64>* %363, i64 3
  %426 = bitcast <2 x i64>* %425 to <8 x i16>*
  %427 = load <8 x i16>, <8 x i16>* %426, align 16
  %428 = getelementptr inbounds <2 x i64>, <2 x i64>* %363, i64 4
  %429 = bitcast <2 x i64>* %428 to <8 x i16>*
  %430 = load <8 x i16>, <8 x i16>* %429, align 16
  %431 = getelementptr inbounds <2 x i64>, <2 x i64>* %363, i64 5
  %432 = bitcast <2 x i64>* %431 to <8 x i16>*
  %433 = load <8 x i16>, <8 x i16>* %432, align 16
  %434 = getelementptr inbounds <2 x i64>, <2 x i64>* %363, i64 6
  %435 = bitcast <2 x i64>* %434 to <8 x i16>*
  %436 = load <8 x i16>, <8 x i16>* %435, align 16
  %437 = getelementptr inbounds <2 x i64>, <2 x i64>* %363, i64 7
  %438 = bitcast <2 x i64>* %437 to <8 x i16>*
  %439 = load <8 x i16>, <8 x i16>* %438, align 16
  br label %470

440:                                              ; preds = %414
  %441 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %417, i32 %366) #8
  store <8 x i16> %441, <8 x i16>* %416, align 16
  %442 = getelementptr inbounds <2 x i64>, <2 x i64>* %363, i64 1
  %443 = bitcast <2 x i64>* %442 to <8 x i16>*
  %444 = load <8 x i16>, <8 x i16>* %443, align 16
  %445 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %444, i32 %366) #8
  store <8 x i16> %445, <8 x i16>* %443, align 16
  %446 = getelementptr inbounds <2 x i64>, <2 x i64>* %363, i64 2
  %447 = bitcast <2 x i64>* %446 to <8 x i16>*
  %448 = load <8 x i16>, <8 x i16>* %447, align 16
  %449 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %448, i32 %366) #8
  store <8 x i16> %449, <8 x i16>* %447, align 16
  %450 = getelementptr inbounds <2 x i64>, <2 x i64>* %363, i64 3
  %451 = bitcast <2 x i64>* %450 to <8 x i16>*
  %452 = load <8 x i16>, <8 x i16>* %451, align 16
  %453 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %452, i32 %366) #8
  store <8 x i16> %453, <8 x i16>* %451, align 16
  %454 = getelementptr inbounds <2 x i64>, <2 x i64>* %363, i64 4
  %455 = bitcast <2 x i64>* %454 to <8 x i16>*
  %456 = load <8 x i16>, <8 x i16>* %455, align 16
  %457 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %456, i32 %366) #8
  store <8 x i16> %457, <8 x i16>* %455, align 16
  %458 = getelementptr inbounds <2 x i64>, <2 x i64>* %363, i64 5
  %459 = bitcast <2 x i64>* %458 to <8 x i16>*
  %460 = load <8 x i16>, <8 x i16>* %459, align 16
  %461 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %460, i32 %366) #8
  store <8 x i16> %461, <8 x i16>* %459, align 16
  %462 = getelementptr inbounds <2 x i64>, <2 x i64>* %363, i64 6
  %463 = bitcast <2 x i64>* %462 to <8 x i16>*
  %464 = load <8 x i16>, <8 x i16>* %463, align 16
  %465 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %464, i32 %366) #8
  store <8 x i16> %465, <8 x i16>* %463, align 16
  %466 = getelementptr inbounds <2 x i64>, <2 x i64>* %363, i64 7
  %467 = bitcast <2 x i64>* %466 to <8 x i16>*
  %468 = load <8 x i16>, <8 x i16>* %467, align 16
  %469 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %468, i32 %366) #8
  store <8 x i16> %469, <8 x i16>* %467, align 16
  br label %470

470:                                              ; preds = %418, %440, %368
  %471 = phi <8 x i16> [ %439, %418 ], [ %469, %440 ], [ %413, %368 ]
  %472 = phi <8 x i16> [ %436, %418 ], [ %465, %440 ], [ %408, %368 ]
  %473 = phi <8 x i16> [ %433, %418 ], [ %461, %440 ], [ %403, %368 ]
  %474 = phi <8 x i16> [ %430, %418 ], [ %457, %440 ], [ %398, %368 ]
  %475 = phi <8 x i16> [ %427, %418 ], [ %453, %440 ], [ %393, %368 ]
  %476 = phi <8 x i16> [ %424, %418 ], [ %449, %440 ], [ %388, %368 ]
  %477 = phi <8 x i16> [ %421, %418 ], [ %445, %440 ], [ %383, %368 ]
  %478 = phi <8 x i16> [ %417, %418 ], [ %441, %440 ], [ %378, %368 ]
  %479 = getelementptr inbounds <2 x i64>, <2 x i64>* %363, i64 1
  %480 = shufflevector <8 x i16> %478, <8 x i16> %477, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %481 = getelementptr inbounds <2 x i64>, <2 x i64>* %363, i64 2
  %482 = getelementptr inbounds <2 x i64>, <2 x i64>* %363, i64 3
  %483 = shufflevector <8 x i16> %476, <8 x i16> %475, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %484 = getelementptr inbounds <2 x i64>, <2 x i64>* %363, i64 4
  %485 = getelementptr inbounds <2 x i64>, <2 x i64>* %363, i64 5
  %486 = shufflevector <8 x i16> %474, <8 x i16> %473, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %487 = getelementptr inbounds <2 x i64>, <2 x i64>* %363, i64 6
  %488 = getelementptr inbounds <2 x i64>, <2 x i64>* %363, i64 7
  %489 = shufflevector <8 x i16> %472, <8 x i16> %471, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %490 = shufflevector <8 x i16> %478, <8 x i16> %477, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %491 = shufflevector <8 x i16> %476, <8 x i16> %475, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %492 = shufflevector <8 x i16> %474, <8 x i16> %473, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %493 = shufflevector <8 x i16> %472, <8 x i16> %471, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %494 = bitcast <8 x i16> %480 to <4 x i32>
  %495 = bitcast <8 x i16> %483 to <4 x i32>
  %496 = shufflevector <4 x i32> %494, <4 x i32> %495, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %497 = bitcast <4 x i32> %496 to <2 x i64>
  %498 = bitcast <8 x i16> %486 to <4 x i32>
  %499 = bitcast <8 x i16> %489 to <4 x i32>
  %500 = shufflevector <4 x i32> %498, <4 x i32> %499, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %501 = bitcast <4 x i32> %500 to <2 x i64>
  %502 = bitcast <8 x i16> %490 to <4 x i32>
  %503 = bitcast <8 x i16> %491 to <4 x i32>
  %504 = shufflevector <4 x i32> %502, <4 x i32> %503, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %505 = bitcast <4 x i32> %504 to <2 x i64>
  %506 = bitcast <8 x i16> %492 to <4 x i32>
  %507 = bitcast <8 x i16> %493 to <4 x i32>
  %508 = shufflevector <4 x i32> %506, <4 x i32> %507, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %509 = bitcast <4 x i32> %508 to <2 x i64>
  %510 = shufflevector <4 x i32> %494, <4 x i32> %495, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %511 = bitcast <4 x i32> %510 to <2 x i64>
  %512 = shufflevector <4 x i32> %498, <4 x i32> %499, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %513 = bitcast <4 x i32> %512 to <2 x i64>
  %514 = shufflevector <4 x i32> %502, <4 x i32> %503, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %515 = bitcast <4 x i32> %514 to <2 x i64>
  %516 = shufflevector <4 x i32> %506, <4 x i32> %507, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %517 = bitcast <4 x i32> %516 to <2 x i64>
  %518 = shufflevector <2 x i64> %497, <2 x i64> %501, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %518, <2 x i64>* %363, align 16
  %519 = shufflevector <2 x i64> %497, <2 x i64> %501, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %519, <2 x i64>* %479, align 16
  %520 = shufflevector <2 x i64> %511, <2 x i64> %513, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %520, <2 x i64>* %481, align 16
  %521 = shufflevector <2 x i64> %511, <2 x i64> %513, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %521, <2 x i64>* %482, align 16
  %522 = shufflevector <2 x i64> %505, <2 x i64> %509, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %522, <2 x i64>* %484, align 16
  %523 = shufflevector <2 x i64> %505, <2 x i64> %509, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %523, <2 x i64>* %485, align 16
  %524 = shufflevector <2 x i64> %515, <2 x i64> %517, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %524, <2 x i64>* %487, align 16
  %525 = shufflevector <2 x i64> %515, <2 x i64> %517, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %525, <2 x i64>* %488, align 16
  %526 = bitcast <2 x i64> %518 to <8 x i16>
  %527 = shufflevector <8 x i16> %526, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %528 = shufflevector <8 x i16> %526, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %529 = bitcast <8 x i16> %527 to <4 x i32>
  %530 = ashr <4 x i32> %529, <i32 16, i32 16, i32 16, i32 16>
  %531 = bitcast <8 x i16> %528 to <4 x i32>
  %532 = ashr <4 x i32> %531, <i32 16, i32 16, i32 16, i32 16>
  %533 = bitcast i32* %1 to <4 x i32>*
  store <4 x i32> %530, <4 x i32>* %533, align 16
  %534 = getelementptr inbounds i32, i32* %1, i64 4
  %535 = bitcast i32* %534 to <4 x i32>*
  store <4 x i32> %532, <4 x i32>* %535, align 16
  %536 = bitcast <2 x i64> %519 to <8 x i16>
  %537 = getelementptr inbounds i32, i32* %1, i64 8
  %538 = shufflevector <8 x i16> %536, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %539 = shufflevector <8 x i16> %536, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %540 = bitcast <8 x i16> %538 to <4 x i32>
  %541 = ashr <4 x i32> %540, <i32 16, i32 16, i32 16, i32 16>
  %542 = bitcast <8 x i16> %539 to <4 x i32>
  %543 = ashr <4 x i32> %542, <i32 16, i32 16, i32 16, i32 16>
  %544 = bitcast i32* %537 to <4 x i32>*
  store <4 x i32> %541, <4 x i32>* %544, align 16
  %545 = getelementptr inbounds i32, i32* %1, i64 12
  %546 = bitcast i32* %545 to <4 x i32>*
  store <4 x i32> %543, <4 x i32>* %546, align 16
  %547 = bitcast <2 x i64> %520 to <8 x i16>
  %548 = getelementptr inbounds i32, i32* %1, i64 16
  %549 = shufflevector <8 x i16> %547, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %550 = shufflevector <8 x i16> %547, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %551 = bitcast <8 x i16> %549 to <4 x i32>
  %552 = ashr <4 x i32> %551, <i32 16, i32 16, i32 16, i32 16>
  %553 = bitcast <8 x i16> %550 to <4 x i32>
  %554 = ashr <4 x i32> %553, <i32 16, i32 16, i32 16, i32 16>
  %555 = bitcast i32* %548 to <4 x i32>*
  store <4 x i32> %552, <4 x i32>* %555, align 16
  %556 = getelementptr inbounds i32, i32* %1, i64 20
  %557 = bitcast i32* %556 to <4 x i32>*
  store <4 x i32> %554, <4 x i32>* %557, align 16
  %558 = bitcast <2 x i64> %521 to <8 x i16>
  %559 = getelementptr inbounds i32, i32* %1, i64 24
  %560 = shufflevector <8 x i16> %558, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %561 = shufflevector <8 x i16> %558, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %562 = bitcast <8 x i16> %560 to <4 x i32>
  %563 = ashr <4 x i32> %562, <i32 16, i32 16, i32 16, i32 16>
  %564 = bitcast <8 x i16> %561 to <4 x i32>
  %565 = ashr <4 x i32> %564, <i32 16, i32 16, i32 16, i32 16>
  %566 = bitcast i32* %559 to <4 x i32>*
  store <4 x i32> %563, <4 x i32>* %566, align 16
  %567 = getelementptr inbounds i32, i32* %1, i64 28
  %568 = bitcast i32* %567 to <4 x i32>*
  store <4 x i32> %565, <4 x i32>* %568, align 16
  %569 = bitcast <2 x i64> %522 to <8 x i16>
  %570 = getelementptr inbounds i32, i32* %1, i64 32
  %571 = shufflevector <8 x i16> %569, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %572 = shufflevector <8 x i16> %569, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %573 = bitcast <8 x i16> %571 to <4 x i32>
  %574 = ashr <4 x i32> %573, <i32 16, i32 16, i32 16, i32 16>
  %575 = bitcast <8 x i16> %572 to <4 x i32>
  %576 = ashr <4 x i32> %575, <i32 16, i32 16, i32 16, i32 16>
  %577 = bitcast i32* %570 to <4 x i32>*
  store <4 x i32> %574, <4 x i32>* %577, align 16
  %578 = getelementptr inbounds i32, i32* %1, i64 36
  %579 = bitcast i32* %578 to <4 x i32>*
  store <4 x i32> %576, <4 x i32>* %579, align 16
  %580 = bitcast <2 x i64> %523 to <8 x i16>
  %581 = getelementptr inbounds i32, i32* %1, i64 40
  %582 = shufflevector <8 x i16> %580, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %583 = shufflevector <8 x i16> %580, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %584 = bitcast <8 x i16> %582 to <4 x i32>
  %585 = ashr <4 x i32> %584, <i32 16, i32 16, i32 16, i32 16>
  %586 = bitcast <8 x i16> %583 to <4 x i32>
  %587 = ashr <4 x i32> %586, <i32 16, i32 16, i32 16, i32 16>
  %588 = bitcast i32* %581 to <4 x i32>*
  store <4 x i32> %585, <4 x i32>* %588, align 16
  %589 = getelementptr inbounds i32, i32* %1, i64 44
  %590 = bitcast i32* %589 to <4 x i32>*
  store <4 x i32> %587, <4 x i32>* %590, align 16
  %591 = bitcast <2 x i64> %524 to <8 x i16>
  %592 = getelementptr inbounds i32, i32* %1, i64 48
  %593 = shufflevector <8 x i16> %591, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %594 = shufflevector <8 x i16> %591, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %595 = bitcast <8 x i16> %593 to <4 x i32>
  %596 = ashr <4 x i32> %595, <i32 16, i32 16, i32 16, i32 16>
  %597 = bitcast <8 x i16> %594 to <4 x i32>
  %598 = ashr <4 x i32> %597, <i32 16, i32 16, i32 16, i32 16>
  %599 = bitcast i32* %592 to <4 x i32>*
  store <4 x i32> %596, <4 x i32>* %599, align 16
  %600 = getelementptr inbounds i32, i32* %1, i64 52
  %601 = bitcast i32* %600 to <4 x i32>*
  store <4 x i32> %598, <4 x i32>* %601, align 16
  %602 = bitcast <2 x i64> %525 to <8 x i16>
  %603 = getelementptr inbounds i32, i32* %1, i64 56
  %604 = shufflevector <8 x i16> %602, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %605 = shufflevector <8 x i16> %602, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %606 = bitcast <8 x i16> %604 to <4 x i32>
  %607 = ashr <4 x i32> %606, <i32 16, i32 16, i32 16, i32 16>
  %608 = bitcast <8 x i16> %605 to <4 x i32>
  %609 = ashr <4 x i32> %608, <i32 16, i32 16, i32 16, i32 16>
  %610 = bitcast i32* %603 to <4 x i32>*
  store <4 x i32> %607, <4 x i32>* %610, align 16
  %611 = getelementptr inbounds i32, i32* %1, i64 60
  %612 = bitcast i32* %611 to <4 x i32>*
  store <4 x i32> %609, <4 x i32>* %612, align 16
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %9) #8
  call void @llvm.lifetime.end.p0i8(i64 128, i8* nonnull %8) #8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @av1_lowbd_fwd_txfm2d_8x16_sse2(i16* nocapture readonly, i32* nocapture, i32, i8 zeroext, i32) #2 {
  %6 = alloca [16 x <2 x i64>], align 16
  %7 = alloca [16 x <2 x i64>], align 16
  %8 = bitcast [16 x <2 x i64>]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %8) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %8, i8 -86, i64 256, i1 false)
  %9 = bitcast [16 x <2 x i64>]* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %9) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 256, i1 false)
  %10 = load i8*, i8** getelementptr inbounds ([19 x i8*], [19 x i8*]* @av1_fwd_txfm_shift_ls, i64 0, i64 7), align 8
  %11 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_fwd_cos_bit_col, i64 0, i64 1, i64 2), align 1
  %12 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_fwd_cos_bit_row, i64 0, i64 1, i64 2), align 1
  %13 = zext i8 %3 to i64
  %14 = getelementptr inbounds [16 x void (<2 x i64>*, <2 x i64>*, i8)*], [16 x void (<2 x i64>*, <2 x i64>*, i8)*]* @col_txfm8x16_arr, i64 0, i64 %13
  %15 = load void (<2 x i64>*, <2 x i64>*, i8)*, void (<2 x i64>*, <2 x i64>*, i8)** %14, align 8
  %16 = getelementptr inbounds [16 x void (<2 x i64>*, <2 x i64>*, i8)*], [16 x void (<2 x i64>*, <2 x i64>*, i8)*]* @row_txfm8x8_arr, i64 0, i64 %13
  %17 = load void (<2 x i64>*, <2 x i64>*, i8)*, void (<2 x i64>*, <2 x i64>*, i8)** %16, align 8
  switch i8 %3, label %100 [
    i8 6, label %19
    i8 15, label %18
    i8 7, label %18
    i8 5, label %18
    i8 14, label %20
    i8 8, label %20
    i8 4, label %20
  ]

18:                                               ; preds = %5, %5, %5
  br label %100

19:                                               ; preds = %5
  br label %20

20:                                               ; preds = %5, %5, %5, %19
  %21 = phi i32 [ 1, %19 ], [ 0, %5 ], [ 0, %5 ], [ 0, %5 ]
  %22 = sext i32 %2 to i64
  %23 = bitcast i16* %0 to <2 x i64>*
  %24 = load <2 x i64>, <2 x i64>* %23, align 16
  %25 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 15
  store <2 x i64> %24, <2 x i64>* %25, align 16
  %26 = getelementptr inbounds i16, i16* %0, i64 %22
  %27 = bitcast i16* %26 to <2 x i64>*
  %28 = load <2 x i64>, <2 x i64>* %27, align 16
  %29 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 14
  store <2 x i64> %28, <2 x i64>* %29, align 16
  %30 = shl nsw i64 %22, 1
  %31 = getelementptr inbounds i16, i16* %0, i64 %30
  %32 = bitcast i16* %31 to <2 x i64>*
  %33 = load <2 x i64>, <2 x i64>* %32, align 16
  %34 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 13
  store <2 x i64> %33, <2 x i64>* %34, align 16
  %35 = mul nsw i64 %22, 3
  %36 = getelementptr inbounds i16, i16* %0, i64 %35
  %37 = bitcast i16* %36 to <2 x i64>*
  %38 = load <2 x i64>, <2 x i64>* %37, align 16
  %39 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 12
  store <2 x i64> %38, <2 x i64>* %39, align 16
  %40 = shl nsw i64 %22, 2
  %41 = getelementptr inbounds i16, i16* %0, i64 %40
  %42 = bitcast i16* %41 to <2 x i64>*
  %43 = load <2 x i64>, <2 x i64>* %42, align 16
  %44 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 11
  store <2 x i64> %43, <2 x i64>* %44, align 16
  %45 = mul nsw i64 %22, 5
  %46 = getelementptr inbounds i16, i16* %0, i64 %45
  %47 = bitcast i16* %46 to <2 x i64>*
  %48 = load <2 x i64>, <2 x i64>* %47, align 16
  %49 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 10
  store <2 x i64> %48, <2 x i64>* %49, align 16
  %50 = mul nsw i64 %22, 6
  %51 = getelementptr inbounds i16, i16* %0, i64 %50
  %52 = bitcast i16* %51 to <2 x i64>*
  %53 = load <2 x i64>, <2 x i64>* %52, align 16
  %54 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 9
  store <2 x i64> %53, <2 x i64>* %54, align 16
  %55 = mul nsw i64 %22, 7
  %56 = getelementptr inbounds i16, i16* %0, i64 %55
  %57 = bitcast i16* %56 to <2 x i64>*
  %58 = load <2 x i64>, <2 x i64>* %57, align 16
  %59 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 8
  store <2 x i64> %58, <2 x i64>* %59, align 16
  %60 = shl nsw i64 %22, 3
  %61 = getelementptr inbounds i16, i16* %0, i64 %60
  %62 = bitcast i16* %61 to <2 x i64>*
  %63 = load <2 x i64>, <2 x i64>* %62, align 16
  %64 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 7
  store <2 x i64> %63, <2 x i64>* %64, align 16
  %65 = mul nsw i64 %22, 9
  %66 = getelementptr inbounds i16, i16* %0, i64 %65
  %67 = bitcast i16* %66 to <2 x i64>*
  %68 = load <2 x i64>, <2 x i64>* %67, align 16
  %69 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 6
  store <2 x i64> %68, <2 x i64>* %69, align 16
  %70 = mul nsw i64 %22, 10
  %71 = getelementptr inbounds i16, i16* %0, i64 %70
  %72 = bitcast i16* %71 to <2 x i64>*
  %73 = load <2 x i64>, <2 x i64>* %72, align 16
  %74 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 5
  store <2 x i64> %73, <2 x i64>* %74, align 16
  %75 = mul nsw i64 %22, 11
  %76 = getelementptr inbounds i16, i16* %0, i64 %75
  %77 = bitcast i16* %76 to <2 x i64>*
  %78 = load <2 x i64>, <2 x i64>* %77, align 16
  %79 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 4
  store <2 x i64> %78, <2 x i64>* %79, align 16
  %80 = mul nsw i64 %22, 12
  %81 = getelementptr inbounds i16, i16* %0, i64 %80
  %82 = bitcast i16* %81 to <2 x i64>*
  %83 = load <2 x i64>, <2 x i64>* %82, align 16
  %84 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 3
  store <2 x i64> %83, <2 x i64>* %84, align 16
  %85 = mul nsw i64 %22, 13
  %86 = getelementptr inbounds i16, i16* %0, i64 %85
  %87 = bitcast i16* %86 to <2 x i64>*
  %88 = load <2 x i64>, <2 x i64>* %87, align 16
  %89 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 2
  store <2 x i64> %88, <2 x i64>* %89, align 16
  %90 = mul nsw i64 %22, 14
  %91 = getelementptr inbounds i16, i16* %0, i64 %90
  %92 = bitcast i16* %91 to <2 x i64>*
  %93 = load <2 x i64>, <2 x i64>* %92, align 16
  %94 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 1
  store <2 x i64> %93, <2 x i64>* %94, align 16
  %95 = mul nsw i64 %22, 15
  %96 = getelementptr inbounds i16, i16* %0, i64 %95
  %97 = bitcast i16* %96 to <2 x i64>*
  %98 = load <2 x i64>, <2 x i64>* %97, align 16
  %99 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 0
  store <2 x i64> %98, <2 x i64>* %99, align 16
  br label %180

100:                                              ; preds = %18, %5
  %101 = phi i32 [ 0, %5 ], [ 1, %18 ]
  %102 = sext i32 %2 to i64
  %103 = bitcast i16* %0 to <2 x i64>*
  %104 = load <2 x i64>, <2 x i64>* %103, align 16
  %105 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 0
  store <2 x i64> %104, <2 x i64>* %105, align 16
  %106 = getelementptr inbounds i16, i16* %0, i64 %102
  %107 = bitcast i16* %106 to <2 x i64>*
  %108 = load <2 x i64>, <2 x i64>* %107, align 16
  %109 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 1
  store <2 x i64> %108, <2 x i64>* %109, align 16
  %110 = shl nsw i64 %102, 1
  %111 = getelementptr inbounds i16, i16* %0, i64 %110
  %112 = bitcast i16* %111 to <2 x i64>*
  %113 = load <2 x i64>, <2 x i64>* %112, align 16
  %114 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 2
  store <2 x i64> %113, <2 x i64>* %114, align 16
  %115 = mul nsw i64 %102, 3
  %116 = getelementptr inbounds i16, i16* %0, i64 %115
  %117 = bitcast i16* %116 to <2 x i64>*
  %118 = load <2 x i64>, <2 x i64>* %117, align 16
  %119 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 3
  store <2 x i64> %118, <2 x i64>* %119, align 16
  %120 = shl nsw i64 %102, 2
  %121 = getelementptr inbounds i16, i16* %0, i64 %120
  %122 = bitcast i16* %121 to <2 x i64>*
  %123 = load <2 x i64>, <2 x i64>* %122, align 16
  %124 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 4
  store <2 x i64> %123, <2 x i64>* %124, align 16
  %125 = mul nsw i64 %102, 5
  %126 = getelementptr inbounds i16, i16* %0, i64 %125
  %127 = bitcast i16* %126 to <2 x i64>*
  %128 = load <2 x i64>, <2 x i64>* %127, align 16
  %129 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 5
  store <2 x i64> %128, <2 x i64>* %129, align 16
  %130 = mul nsw i64 %102, 6
  %131 = getelementptr inbounds i16, i16* %0, i64 %130
  %132 = bitcast i16* %131 to <2 x i64>*
  %133 = load <2 x i64>, <2 x i64>* %132, align 16
  %134 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 6
  store <2 x i64> %133, <2 x i64>* %134, align 16
  %135 = mul nsw i64 %102, 7
  %136 = getelementptr inbounds i16, i16* %0, i64 %135
  %137 = bitcast i16* %136 to <2 x i64>*
  %138 = load <2 x i64>, <2 x i64>* %137, align 16
  %139 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 7
  store <2 x i64> %138, <2 x i64>* %139, align 16
  %140 = shl nsw i64 %102, 3
  %141 = getelementptr inbounds i16, i16* %0, i64 %140
  %142 = bitcast i16* %141 to <2 x i64>*
  %143 = load <2 x i64>, <2 x i64>* %142, align 16
  %144 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 8
  store <2 x i64> %143, <2 x i64>* %144, align 16
  %145 = mul nsw i64 %102, 9
  %146 = getelementptr inbounds i16, i16* %0, i64 %145
  %147 = bitcast i16* %146 to <2 x i64>*
  %148 = load <2 x i64>, <2 x i64>* %147, align 16
  %149 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 9
  store <2 x i64> %148, <2 x i64>* %149, align 16
  %150 = mul nsw i64 %102, 10
  %151 = getelementptr inbounds i16, i16* %0, i64 %150
  %152 = bitcast i16* %151 to <2 x i64>*
  %153 = load <2 x i64>, <2 x i64>* %152, align 16
  %154 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 10
  store <2 x i64> %153, <2 x i64>* %154, align 16
  %155 = mul nsw i64 %102, 11
  %156 = getelementptr inbounds i16, i16* %0, i64 %155
  %157 = bitcast i16* %156 to <2 x i64>*
  %158 = load <2 x i64>, <2 x i64>* %157, align 16
  %159 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 11
  store <2 x i64> %158, <2 x i64>* %159, align 16
  %160 = mul nsw i64 %102, 12
  %161 = getelementptr inbounds i16, i16* %0, i64 %160
  %162 = bitcast i16* %161 to <2 x i64>*
  %163 = load <2 x i64>, <2 x i64>* %162, align 16
  %164 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 12
  store <2 x i64> %163, <2 x i64>* %164, align 16
  %165 = mul nsw i64 %102, 13
  %166 = getelementptr inbounds i16, i16* %0, i64 %165
  %167 = bitcast i16* %166 to <2 x i64>*
  %168 = load <2 x i64>, <2 x i64>* %167, align 16
  %169 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 13
  store <2 x i64> %168, <2 x i64>* %169, align 16
  %170 = mul nsw i64 %102, 14
  %171 = getelementptr inbounds i16, i16* %0, i64 %170
  %172 = bitcast i16* %171 to <2 x i64>*
  %173 = load <2 x i64>, <2 x i64>* %172, align 16
  %174 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 14
  store <2 x i64> %173, <2 x i64>* %174, align 16
  %175 = mul nsw i64 %102, 15
  %176 = getelementptr inbounds i16, i16* %0, i64 %175
  %177 = bitcast i16* %176 to <2 x i64>*
  %178 = load <2 x i64>, <2 x i64>* %177, align 16
  %179 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 15
  store <2 x i64> %178, <2 x i64>* %179, align 16
  br label %180

180:                                              ; preds = %20, %100
  %181 = phi <2 x i64> [ %148, %100 ], [ %53, %20 ]
  %182 = phi <2 x i64> [ %143, %100 ], [ %58, %20 ]
  %183 = phi <2 x i64> [ %138, %100 ], [ %63, %20 ]
  %184 = phi <2 x i64> [ %133, %100 ], [ %68, %20 ]
  %185 = phi <2 x i64> [ %128, %100 ], [ %73, %20 ]
  %186 = phi <2 x i64> [ %123, %100 ], [ %78, %20 ]
  %187 = phi <2 x i64> [ %163, %100 ], [ %38, %20 ]
  %188 = phi <2 x i64> [ %158, %100 ], [ %43, %20 ]
  %189 = phi <2 x i64> [ %153, %100 ], [ %48, %20 ]
  %190 = phi <2 x i64> [ %118, %100 ], [ %83, %20 ]
  %191 = phi <2 x i64> [ %113, %100 ], [ %88, %20 ]
  %192 = phi <2 x i64> [ %108, %100 ], [ %93, %20 ]
  %193 = phi <2 x i64> [ %104, %100 ], [ %98, %20 ]
  %194 = phi <2 x i64>* [ %105, %100 ], [ %99, %20 ]
  %195 = phi i32 [ %101, %100 ], [ %21, %20 ]
  %196 = bitcast <2 x i64> %186 to <8 x i16>
  %197 = bitcast <2 x i64> %185 to <8 x i16>
  %198 = bitcast <2 x i64> %184 to <8 x i16>
  %199 = bitcast <2 x i64> %183 to <8 x i16>
  %200 = bitcast <2 x i64> %182 to <8 x i16>
  %201 = bitcast <2 x i64> %181 to <8 x i16>
  %202 = bitcast <2 x i64> %187 to <8 x i16>
  %203 = bitcast <2 x i64> %188 to <8 x i16>
  %204 = bitcast <2 x i64> %189 to <8 x i16>
  %205 = bitcast <2 x i64> %190 to <8 x i16>
  %206 = bitcast <2 x i64> %191 to <8 x i16>
  %207 = bitcast <2 x i64> %192 to <8 x i16>
  %208 = bitcast <2 x i64> %193 to <8 x i16>
  %209 = load i8, i8* %10, align 1
  %210 = sext i8 %209 to i32
  %211 = icmp slt i8 %209, 0
  br i1 %211, label %212, label %292

212:                                              ; preds = %180
  %213 = sub nsw i32 0, %210
  %214 = xor i32 %210, -1
  %215 = shl i32 1, %214
  %216 = trunc i32 %215 to i16
  %217 = insertelement <8 x i16> undef, i16 %216, i32 0
  %218 = shufflevector <8 x i16> %217, <8 x i16> undef, <8 x i32> zeroinitializer
  %219 = bitcast [16 x <2 x i64>]* %6 to <8 x i16>*
  %220 = load <8 x i16>, <8 x i16>* %219, align 16
  %221 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %220, <8 x i16> %218) #8
  %222 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %221, i32 %213) #8
  store <8 x i16> %222, <8 x i16>* %219, align 16
  %223 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 1
  %224 = bitcast <2 x i64>* %223 to <8 x i16>*
  %225 = load <8 x i16>, <8 x i16>* %224, align 16
  %226 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %225, <8 x i16> %218) #8
  %227 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %226, i32 %213) #8
  store <8 x i16> %227, <8 x i16>* %224, align 16
  %228 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 2
  %229 = bitcast <2 x i64>* %228 to <8 x i16>*
  %230 = load <8 x i16>, <8 x i16>* %229, align 16
  %231 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %230, <8 x i16> %218) #8
  %232 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %231, i32 %213) #8
  store <8 x i16> %232, <8 x i16>* %229, align 16
  %233 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 3
  %234 = bitcast <2 x i64>* %233 to <8 x i16>*
  %235 = load <8 x i16>, <8 x i16>* %234, align 16
  %236 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %235, <8 x i16> %218) #8
  %237 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %236, i32 %213) #8
  store <8 x i16> %237, <8 x i16>* %234, align 16
  %238 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 4
  %239 = bitcast <2 x i64>* %238 to <8 x i16>*
  %240 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %196, <8 x i16> %218) #8
  %241 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %240, i32 %213) #8
  store <8 x i16> %241, <8 x i16>* %239, align 16
  %242 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 5
  %243 = bitcast <2 x i64>* %242 to <8 x i16>*
  %244 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %197, <8 x i16> %218) #8
  %245 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %244, i32 %213) #8
  store <8 x i16> %245, <8 x i16>* %243, align 16
  %246 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 6
  %247 = bitcast <2 x i64>* %246 to <8 x i16>*
  %248 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %198, <8 x i16> %218) #8
  %249 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %248, i32 %213) #8
  store <8 x i16> %249, <8 x i16>* %247, align 16
  %250 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 7
  %251 = bitcast <2 x i64>* %250 to <8 x i16>*
  %252 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %199, <8 x i16> %218) #8
  %253 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %252, i32 %213) #8
  store <8 x i16> %253, <8 x i16>* %251, align 16
  %254 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 8
  %255 = bitcast <2 x i64>* %254 to <8 x i16>*
  %256 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %200, <8 x i16> %218) #8
  %257 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %256, i32 %213) #8
  store <8 x i16> %257, <8 x i16>* %255, align 16
  %258 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 9
  %259 = bitcast <2 x i64>* %258 to <8 x i16>*
  %260 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %201, <8 x i16> %218) #8
  %261 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %260, i32 %213) #8
  store <8 x i16> %261, <8 x i16>* %259, align 16
  %262 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 10
  %263 = bitcast <2 x i64>* %262 to <8 x i16>*
  %264 = load <8 x i16>, <8 x i16>* %263, align 16
  %265 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %264, <8 x i16> %218) #8
  %266 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %265, i32 %213) #8
  store <8 x i16> %266, <8 x i16>* %263, align 16
  %267 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 11
  %268 = bitcast <2 x i64>* %267 to <8 x i16>*
  %269 = load <8 x i16>, <8 x i16>* %268, align 16
  %270 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %269, <8 x i16> %218) #8
  %271 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %270, i32 %213) #8
  store <8 x i16> %271, <8 x i16>* %268, align 16
  %272 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 12
  %273 = bitcast <2 x i64>* %272 to <8 x i16>*
  %274 = load <8 x i16>, <8 x i16>* %273, align 16
  %275 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %274, <8 x i16> %218) #8
  %276 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %275, i32 %213) #8
  store <8 x i16> %276, <8 x i16>* %273, align 16
  %277 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 13
  %278 = bitcast <2 x i64>* %277 to <8 x i16>*
  %279 = load <8 x i16>, <8 x i16>* %278, align 16
  %280 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %279, <8 x i16> %218) #8
  %281 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %280, i32 %213) #8
  store <8 x i16> %281, <8 x i16>* %278, align 16
  %282 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 14
  %283 = bitcast <2 x i64>* %282 to <8 x i16>*
  %284 = load <8 x i16>, <8 x i16>* %283, align 16
  %285 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %284, <8 x i16> %218) #8
  %286 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %285, i32 %213) #8
  store <8 x i16> %286, <8 x i16>* %283, align 16
  %287 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 15
  %288 = bitcast <2 x i64>* %287 to <8 x i16>*
  %289 = load <8 x i16>, <8 x i16>* %288, align 16
  %290 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %289, <8 x i16> %218) #8
  %291 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %290, i32 %213) #8
  store <8 x i16> %291, <8 x i16>* %288, align 16
  br label %345

292:                                              ; preds = %180
  %293 = icmp eq i8 %209, 0
  br i1 %293, label %345, label %294

294:                                              ; preds = %292
  %295 = bitcast [16 x <2 x i64>]* %6 to <8 x i16>*
  %296 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %208, i32 %210) #8
  store <8 x i16> %296, <8 x i16>* %295, align 16
  %297 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 1
  %298 = bitcast <2 x i64>* %297 to <8 x i16>*
  %299 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %207, i32 %210) #8
  store <8 x i16> %299, <8 x i16>* %298, align 16
  %300 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 2
  %301 = bitcast <2 x i64>* %300 to <8 x i16>*
  %302 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %206, i32 %210) #8
  store <8 x i16> %302, <8 x i16>* %301, align 16
  %303 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 3
  %304 = bitcast <2 x i64>* %303 to <8 x i16>*
  %305 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %205, i32 %210) #8
  store <8 x i16> %305, <8 x i16>* %304, align 16
  %306 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 4
  %307 = bitcast <2 x i64>* %306 to <8 x i16>*
  %308 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %196, i32 %210) #8
  store <8 x i16> %308, <8 x i16>* %307, align 16
  %309 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 5
  %310 = bitcast <2 x i64>* %309 to <8 x i16>*
  %311 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %197, i32 %210) #8
  store <8 x i16> %311, <8 x i16>* %310, align 16
  %312 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 6
  %313 = bitcast <2 x i64>* %312 to <8 x i16>*
  %314 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %198, i32 %210) #8
  store <8 x i16> %314, <8 x i16>* %313, align 16
  %315 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 7
  %316 = bitcast <2 x i64>* %315 to <8 x i16>*
  %317 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %199, i32 %210) #8
  store <8 x i16> %317, <8 x i16>* %316, align 16
  %318 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 8
  %319 = bitcast <2 x i64>* %318 to <8 x i16>*
  %320 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %200, i32 %210) #8
  store <8 x i16> %320, <8 x i16>* %319, align 16
  %321 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 9
  %322 = bitcast <2 x i64>* %321 to <8 x i16>*
  %323 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %201, i32 %210) #8
  store <8 x i16> %323, <8 x i16>* %322, align 16
  %324 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 10
  %325 = bitcast <2 x i64>* %324 to <8 x i16>*
  %326 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %204, i32 %210) #8
  store <8 x i16> %326, <8 x i16>* %325, align 16
  %327 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 11
  %328 = bitcast <2 x i64>* %327 to <8 x i16>*
  %329 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %203, i32 %210) #8
  store <8 x i16> %329, <8 x i16>* %328, align 16
  %330 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 12
  %331 = bitcast <2 x i64>* %330 to <8 x i16>*
  %332 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %202, i32 %210) #8
  store <8 x i16> %332, <8 x i16>* %331, align 16
  %333 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 13
  %334 = bitcast <2 x i64>* %333 to <8 x i16>*
  %335 = load <8 x i16>, <8 x i16>* %334, align 16
  %336 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %335, i32 %210) #8
  store <8 x i16> %336, <8 x i16>* %334, align 16
  %337 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 14
  %338 = bitcast <2 x i64>* %337 to <8 x i16>*
  %339 = load <8 x i16>, <8 x i16>* %338, align 16
  %340 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %339, i32 %210) #8
  store <8 x i16> %340, <8 x i16>* %338, align 16
  %341 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 15
  %342 = bitcast <2 x i64>* %341 to <8 x i16>*
  %343 = load <8 x i16>, <8 x i16>* %342, align 16
  %344 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %343, i32 %210) #8
  store <8 x i16> %344, <8 x i16>* %342, align 16
  br label %345

345:                                              ; preds = %294, %212, %292
  call void %15(<2 x i64>* %194, <2 x i64>* %194, i8 signext %11) #8
  %346 = getelementptr inbounds i8, i8* %10, i64 1
  %347 = load i8, i8* %346, align 1
  %348 = sext i8 %347 to i32
  %349 = icmp slt i8 %347, 0
  br i1 %349, label %350, label %436

350:                                              ; preds = %345
  %351 = sub nsw i32 0, %348
  %352 = xor i32 %348, -1
  %353 = shl i32 1, %352
  %354 = trunc i32 %353 to i16
  %355 = insertelement <8 x i16> undef, i16 %354, i32 0
  %356 = shufflevector <8 x i16> %355, <8 x i16> undef, <8 x i32> zeroinitializer
  %357 = bitcast [16 x <2 x i64>]* %6 to <8 x i16>*
  %358 = load <8 x i16>, <8 x i16>* %357, align 16
  %359 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %358, <8 x i16> %356) #8
  %360 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %359, i32 %351) #8
  store <8 x i16> %360, <8 x i16>* %357, align 16
  %361 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 1
  %362 = bitcast <2 x i64>* %361 to <8 x i16>*
  %363 = load <8 x i16>, <8 x i16>* %362, align 16
  %364 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %363, <8 x i16> %356) #8
  %365 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %364, i32 %351) #8
  store <8 x i16> %365, <8 x i16>* %362, align 16
  %366 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 2
  %367 = bitcast <2 x i64>* %366 to <8 x i16>*
  %368 = load <8 x i16>, <8 x i16>* %367, align 16
  %369 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %368, <8 x i16> %356) #8
  %370 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %369, i32 %351) #8
  store <8 x i16> %370, <8 x i16>* %367, align 16
  %371 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 3
  %372 = bitcast <2 x i64>* %371 to <8 x i16>*
  %373 = load <8 x i16>, <8 x i16>* %372, align 16
  %374 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %373, <8 x i16> %356) #8
  %375 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %374, i32 %351) #8
  store <8 x i16> %375, <8 x i16>* %372, align 16
  %376 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 4
  %377 = bitcast <2 x i64>* %376 to <8 x i16>*
  %378 = load <8 x i16>, <8 x i16>* %377, align 16
  %379 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %378, <8 x i16> %356) #8
  %380 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %379, i32 %351) #8
  store <8 x i16> %380, <8 x i16>* %377, align 16
  %381 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 5
  %382 = bitcast <2 x i64>* %381 to <8 x i16>*
  %383 = load <8 x i16>, <8 x i16>* %382, align 16
  %384 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %383, <8 x i16> %356) #8
  %385 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %384, i32 %351) #8
  store <8 x i16> %385, <8 x i16>* %382, align 16
  %386 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 6
  %387 = bitcast <2 x i64>* %386 to <8 x i16>*
  %388 = load <8 x i16>, <8 x i16>* %387, align 16
  %389 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %388, <8 x i16> %356) #8
  %390 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %389, i32 %351) #8
  store <8 x i16> %390, <8 x i16>* %387, align 16
  %391 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 7
  %392 = bitcast <2 x i64>* %391 to <8 x i16>*
  %393 = load <8 x i16>, <8 x i16>* %392, align 16
  %394 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %393, <8 x i16> %356) #8
  %395 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %394, i32 %351) #8
  store <8 x i16> %395, <8 x i16>* %392, align 16
  %396 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 8
  %397 = bitcast <2 x i64>* %396 to <8 x i16>*
  %398 = load <8 x i16>, <8 x i16>* %397, align 16
  %399 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %398, <8 x i16> %356) #8
  %400 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %399, i32 %351) #8
  store <8 x i16> %400, <8 x i16>* %397, align 16
  %401 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 9
  %402 = bitcast <2 x i64>* %401 to <8 x i16>*
  %403 = load <8 x i16>, <8 x i16>* %402, align 16
  %404 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %403, <8 x i16> %356) #8
  %405 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %404, i32 %351) #8
  store <8 x i16> %405, <8 x i16>* %402, align 16
  %406 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 10
  %407 = bitcast <2 x i64>* %406 to <8 x i16>*
  %408 = load <8 x i16>, <8 x i16>* %407, align 16
  %409 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %408, <8 x i16> %356) #8
  %410 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %409, i32 %351) #8
  store <8 x i16> %410, <8 x i16>* %407, align 16
  %411 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 11
  %412 = bitcast <2 x i64>* %411 to <8 x i16>*
  %413 = load <8 x i16>, <8 x i16>* %412, align 16
  %414 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %413, <8 x i16> %356) #8
  %415 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %414, i32 %351) #8
  store <8 x i16> %415, <8 x i16>* %412, align 16
  %416 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 12
  %417 = bitcast <2 x i64>* %416 to <8 x i16>*
  %418 = load <8 x i16>, <8 x i16>* %417, align 16
  %419 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %418, <8 x i16> %356) #8
  %420 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %419, i32 %351) #8
  store <8 x i16> %420, <8 x i16>* %417, align 16
  %421 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 13
  %422 = bitcast <2 x i64>* %421 to <8 x i16>*
  %423 = load <8 x i16>, <8 x i16>* %422, align 16
  %424 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %423, <8 x i16> %356) #8
  %425 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %424, i32 %351) #8
  store <8 x i16> %425, <8 x i16>* %422, align 16
  %426 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 14
  %427 = bitcast <2 x i64>* %426 to <8 x i16>*
  %428 = load <8 x i16>, <8 x i16>* %427, align 16
  %429 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %428, <8 x i16> %356) #8
  %430 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %429, i32 %351) #8
  store <8 x i16> %430, <8 x i16>* %427, align 16
  %431 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 15
  %432 = bitcast <2 x i64>* %431 to <8 x i16>*
  %433 = load <8 x i16>, <8 x i16>* %432, align 16
  %434 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %433, <8 x i16> %356) #8
  %435 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %434, i32 %351) #8
  store <8 x i16> %435, <8 x i16>* %432, align 16
  br label %544

436:                                              ; preds = %345
  %437 = icmp eq i8 %347, 0
  br i1 %437, label %438, label %480

438:                                              ; preds = %436
  %439 = bitcast <2 x i64>* %194 to <8 x i16>*
  %440 = load <8 x i16>, <8 x i16>* %439, align 16
  %441 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 1
  %442 = bitcast <2 x i64>* %441 to <8 x i16>*
  %443 = load <8 x i16>, <8 x i16>* %442, align 16
  %444 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 2
  %445 = bitcast <2 x i64>* %444 to <8 x i16>*
  %446 = load <8 x i16>, <8 x i16>* %445, align 16
  %447 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 3
  %448 = bitcast <2 x i64>* %447 to <8 x i16>*
  %449 = load <8 x i16>, <8 x i16>* %448, align 16
  %450 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 4
  %451 = bitcast <2 x i64>* %450 to <8 x i16>*
  %452 = load <8 x i16>, <8 x i16>* %451, align 16
  %453 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 5
  %454 = bitcast <2 x i64>* %453 to <8 x i16>*
  %455 = load <8 x i16>, <8 x i16>* %454, align 16
  %456 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 6
  %457 = bitcast <2 x i64>* %456 to <8 x i16>*
  %458 = load <8 x i16>, <8 x i16>* %457, align 16
  %459 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 7
  %460 = bitcast <2 x i64>* %459 to <8 x i16>*
  %461 = load <8 x i16>, <8 x i16>* %460, align 16
  %462 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 8
  %463 = bitcast <2 x i64>* %462 to <8 x i16>*
  %464 = load <8 x i16>, <8 x i16>* %463, align 16
  %465 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 9
  %466 = bitcast <2 x i64>* %465 to <8 x i16>*
  %467 = load <8 x i16>, <8 x i16>* %466, align 16
  %468 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 10
  %469 = bitcast <2 x i64>* %468 to <8 x i16>*
  %470 = load <8 x i16>, <8 x i16>* %469, align 16
  %471 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 11
  %472 = bitcast <2 x i64>* %471 to <8 x i16>*
  %473 = load <8 x i16>, <8 x i16>* %472, align 16
  %474 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 12
  %475 = bitcast <2 x i64>* %474 to <8 x i16>*
  %476 = load <8 x i16>, <8 x i16>* %475, align 16
  %477 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 13
  %478 = bitcast <2 x i64>* %477 to <8 x i16>*
  %479 = load <8 x i16>, <8 x i16>* %478, align 16
  br label %544

480:                                              ; preds = %436
  %481 = bitcast [16 x <2 x i64>]* %6 to <8 x i16>*
  %482 = load <8 x i16>, <8 x i16>* %481, align 16
  %483 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %482, i32 %348) #8
  store <8 x i16> %483, <8 x i16>* %481, align 16
  %484 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 1
  %485 = bitcast <2 x i64>* %484 to <8 x i16>*
  %486 = load <8 x i16>, <8 x i16>* %485, align 16
  %487 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %486, i32 %348) #8
  store <8 x i16> %487, <8 x i16>* %485, align 16
  %488 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 2
  %489 = bitcast <2 x i64>* %488 to <8 x i16>*
  %490 = load <8 x i16>, <8 x i16>* %489, align 16
  %491 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %490, i32 %348) #8
  store <8 x i16> %491, <8 x i16>* %489, align 16
  %492 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 3
  %493 = bitcast <2 x i64>* %492 to <8 x i16>*
  %494 = load <8 x i16>, <8 x i16>* %493, align 16
  %495 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %494, i32 %348) #8
  store <8 x i16> %495, <8 x i16>* %493, align 16
  %496 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 4
  %497 = bitcast <2 x i64>* %496 to <8 x i16>*
  %498 = load <8 x i16>, <8 x i16>* %497, align 16
  %499 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %498, i32 %348) #8
  store <8 x i16> %499, <8 x i16>* %497, align 16
  %500 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 5
  %501 = bitcast <2 x i64>* %500 to <8 x i16>*
  %502 = load <8 x i16>, <8 x i16>* %501, align 16
  %503 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %502, i32 %348) #8
  store <8 x i16> %503, <8 x i16>* %501, align 16
  %504 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 6
  %505 = bitcast <2 x i64>* %504 to <8 x i16>*
  %506 = load <8 x i16>, <8 x i16>* %505, align 16
  %507 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %506, i32 %348) #8
  store <8 x i16> %507, <8 x i16>* %505, align 16
  %508 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 7
  %509 = bitcast <2 x i64>* %508 to <8 x i16>*
  %510 = load <8 x i16>, <8 x i16>* %509, align 16
  %511 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %510, i32 %348) #8
  store <8 x i16> %511, <8 x i16>* %509, align 16
  %512 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 8
  %513 = bitcast <2 x i64>* %512 to <8 x i16>*
  %514 = load <8 x i16>, <8 x i16>* %513, align 16
  %515 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %514, i32 %348) #8
  store <8 x i16> %515, <8 x i16>* %513, align 16
  %516 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 9
  %517 = bitcast <2 x i64>* %516 to <8 x i16>*
  %518 = load <8 x i16>, <8 x i16>* %517, align 16
  %519 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %518, i32 %348) #8
  store <8 x i16> %519, <8 x i16>* %517, align 16
  %520 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 10
  %521 = bitcast <2 x i64>* %520 to <8 x i16>*
  %522 = load <8 x i16>, <8 x i16>* %521, align 16
  %523 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %522, i32 %348) #8
  store <8 x i16> %523, <8 x i16>* %521, align 16
  %524 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 11
  %525 = bitcast <2 x i64>* %524 to <8 x i16>*
  %526 = load <8 x i16>, <8 x i16>* %525, align 16
  %527 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %526, i32 %348) #8
  store <8 x i16> %527, <8 x i16>* %525, align 16
  %528 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 12
  %529 = bitcast <2 x i64>* %528 to <8 x i16>*
  %530 = load <8 x i16>, <8 x i16>* %529, align 16
  %531 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %530, i32 %348) #8
  store <8 x i16> %531, <8 x i16>* %529, align 16
  %532 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 13
  %533 = bitcast <2 x i64>* %532 to <8 x i16>*
  %534 = load <8 x i16>, <8 x i16>* %533, align 16
  %535 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %534, i32 %348) #8
  store <8 x i16> %535, <8 x i16>* %533, align 16
  %536 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 14
  %537 = bitcast <2 x i64>* %536 to <8 x i16>*
  %538 = load <8 x i16>, <8 x i16>* %537, align 16
  %539 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %538, i32 %348) #8
  store <8 x i16> %539, <8 x i16>* %537, align 16
  %540 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 15
  %541 = bitcast <2 x i64>* %540 to <8 x i16>*
  %542 = load <8 x i16>, <8 x i16>* %541, align 16
  %543 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %542, i32 %348) #8
  store <8 x i16> %543, <8 x i16>* %541, align 16
  br label %544

544:                                              ; preds = %438, %480, %350
  %545 = phi <8 x i16> [ %479, %438 ], [ %535, %480 ], [ %425, %350 ]
  %546 = phi <8 x i16> [ %476, %438 ], [ %531, %480 ], [ %420, %350 ]
  %547 = phi <8 x i16> [ %473, %438 ], [ %527, %480 ], [ %415, %350 ]
  %548 = phi <8 x i16> [ %470, %438 ], [ %523, %480 ], [ %410, %350 ]
  %549 = phi <8 x i16> [ %467, %438 ], [ %519, %480 ], [ %405, %350 ]
  %550 = phi <8 x i16> [ %464, %438 ], [ %515, %480 ], [ %400, %350 ]
  %551 = phi <8 x i16> [ %461, %438 ], [ %511, %480 ], [ %395, %350 ]
  %552 = phi <8 x i16> [ %458, %438 ], [ %507, %480 ], [ %390, %350 ]
  %553 = phi <8 x i16> [ %455, %438 ], [ %503, %480 ], [ %385, %350 ]
  %554 = phi <8 x i16> [ %452, %438 ], [ %499, %480 ], [ %380, %350 ]
  %555 = phi <8 x i16> [ %449, %438 ], [ %495, %480 ], [ %375, %350 ]
  %556 = phi <8 x i16> [ %446, %438 ], [ %491, %480 ], [ %370, %350 ]
  %557 = phi <8 x i16> [ %443, %438 ], [ %487, %480 ], [ %365, %350 ]
  %558 = phi <8 x i16> [ %440, %438 ], [ %483, %480 ], [ %360, %350 ]
  %559 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 0
  %560 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 1
  %561 = shufflevector <8 x i16> %558, <8 x i16> %557, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %562 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 2
  %563 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 3
  %564 = shufflevector <8 x i16> %556, <8 x i16> %555, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %565 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 4
  %566 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 5
  %567 = shufflevector <8 x i16> %554, <8 x i16> %553, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %568 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 6
  %569 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 7
  %570 = shufflevector <8 x i16> %552, <8 x i16> %551, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %571 = shufflevector <8 x i16> %558, <8 x i16> %557, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %572 = shufflevector <8 x i16> %556, <8 x i16> %555, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %573 = shufflevector <8 x i16> %554, <8 x i16> %553, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %574 = shufflevector <8 x i16> %552, <8 x i16> %551, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %575 = bitcast <8 x i16> %561 to <4 x i32>
  %576 = bitcast <8 x i16> %564 to <4 x i32>
  %577 = shufflevector <4 x i32> %575, <4 x i32> %576, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %578 = bitcast <4 x i32> %577 to <2 x i64>
  %579 = bitcast <8 x i16> %567 to <4 x i32>
  %580 = bitcast <8 x i16> %570 to <4 x i32>
  %581 = shufflevector <4 x i32> %579, <4 x i32> %580, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %582 = bitcast <4 x i32> %581 to <2 x i64>
  %583 = bitcast <8 x i16> %571 to <4 x i32>
  %584 = bitcast <8 x i16> %572 to <4 x i32>
  %585 = shufflevector <4 x i32> %583, <4 x i32> %584, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %586 = bitcast <4 x i32> %585 to <2 x i64>
  %587 = bitcast <8 x i16> %573 to <4 x i32>
  %588 = bitcast <8 x i16> %574 to <4 x i32>
  %589 = shufflevector <4 x i32> %587, <4 x i32> %588, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %590 = bitcast <4 x i32> %589 to <2 x i64>
  %591 = shufflevector <4 x i32> %575, <4 x i32> %576, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %592 = bitcast <4 x i32> %591 to <2 x i64>
  %593 = shufflevector <4 x i32> %579, <4 x i32> %580, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %594 = bitcast <4 x i32> %593 to <2 x i64>
  %595 = shufflevector <4 x i32> %583, <4 x i32> %584, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %596 = bitcast <4 x i32> %595 to <2 x i64>
  %597 = shufflevector <4 x i32> %587, <4 x i32> %588, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %598 = bitcast <4 x i32> %597 to <2 x i64>
  %599 = shufflevector <2 x i64> %578, <2 x i64> %582, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %599, <2 x i64>* %559, align 16
  %600 = shufflevector <2 x i64> %578, <2 x i64> %582, <2 x i32> <i32 1, i32 3>
  %601 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 1
  store <2 x i64> %600, <2 x i64>* %601, align 16
  %602 = shufflevector <2 x i64> %592, <2 x i64> %594, <2 x i32> <i32 0, i32 2>
  %603 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 2
  store <2 x i64> %602, <2 x i64>* %603, align 16
  %604 = shufflevector <2 x i64> %592, <2 x i64> %594, <2 x i32> <i32 1, i32 3>
  %605 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 3
  store <2 x i64> %604, <2 x i64>* %605, align 16
  %606 = shufflevector <2 x i64> %586, <2 x i64> %590, <2 x i32> <i32 0, i32 2>
  %607 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 4
  store <2 x i64> %606, <2 x i64>* %607, align 16
  %608 = shufflevector <2 x i64> %586, <2 x i64> %590, <2 x i32> <i32 1, i32 3>
  %609 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 5
  store <2 x i64> %608, <2 x i64>* %609, align 16
  %610 = shufflevector <2 x i64> %596, <2 x i64> %598, <2 x i32> <i32 0, i32 2>
  %611 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 6
  store <2 x i64> %610, <2 x i64>* %611, align 16
  %612 = shufflevector <2 x i64> %596, <2 x i64> %598, <2 x i32> <i32 1, i32 3>
  %613 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 7
  store <2 x i64> %612, <2 x i64>* %613, align 16
  %614 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 8
  %615 = shufflevector <8 x i16> %550, <8 x i16> %549, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %616 = shufflevector <8 x i16> %548, <8 x i16> %547, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %617 = shufflevector <8 x i16> %546, <8 x i16> %545, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %618 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 14
  %619 = bitcast <2 x i64>* %618 to <8 x i16>*
  %620 = load <8 x i16>, <8 x i16>* %619, align 16
  %621 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 15
  %622 = bitcast <2 x i64>* %621 to <8 x i16>*
  %623 = load <8 x i16>, <8 x i16>* %622, align 16
  %624 = shufflevector <8 x i16> %620, <8 x i16> %623, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %625 = shufflevector <8 x i16> %550, <8 x i16> %549, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %626 = shufflevector <8 x i16> %548, <8 x i16> %547, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %627 = shufflevector <8 x i16> %546, <8 x i16> %545, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %628 = shufflevector <8 x i16> %620, <8 x i16> %623, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %629 = bitcast <8 x i16> %615 to <4 x i32>
  %630 = bitcast <8 x i16> %616 to <4 x i32>
  %631 = shufflevector <4 x i32> %629, <4 x i32> %630, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %632 = bitcast <4 x i32> %631 to <2 x i64>
  %633 = bitcast <8 x i16> %617 to <4 x i32>
  %634 = bitcast <8 x i16> %624 to <4 x i32>
  %635 = shufflevector <4 x i32> %633, <4 x i32> %634, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %636 = bitcast <4 x i32> %635 to <2 x i64>
  %637 = bitcast <8 x i16> %625 to <4 x i32>
  %638 = bitcast <8 x i16> %626 to <4 x i32>
  %639 = shufflevector <4 x i32> %637, <4 x i32> %638, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %640 = bitcast <4 x i32> %639 to <2 x i64>
  %641 = bitcast <8 x i16> %627 to <4 x i32>
  %642 = bitcast <8 x i16> %628 to <4 x i32>
  %643 = shufflevector <4 x i32> %641, <4 x i32> %642, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %644 = bitcast <4 x i32> %643 to <2 x i64>
  %645 = shufflevector <4 x i32> %629, <4 x i32> %630, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %646 = bitcast <4 x i32> %645 to <2 x i64>
  %647 = shufflevector <4 x i32> %633, <4 x i32> %634, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %648 = bitcast <4 x i32> %647 to <2 x i64>
  %649 = shufflevector <4 x i32> %637, <4 x i32> %638, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %650 = bitcast <4 x i32> %649 to <2 x i64>
  %651 = shufflevector <4 x i32> %641, <4 x i32> %642, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %652 = bitcast <4 x i32> %651 to <2 x i64>
  %653 = shufflevector <2 x i64> %632, <2 x i64> %636, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %653, <2 x i64>* %614, align 16
  %654 = shufflevector <2 x i64> %632, <2 x i64> %636, <2 x i32> <i32 1, i32 3>
  %655 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 9
  store <2 x i64> %654, <2 x i64>* %655, align 16
  %656 = shufflevector <2 x i64> %646, <2 x i64> %648, <2 x i32> <i32 0, i32 2>
  %657 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 10
  store <2 x i64> %656, <2 x i64>* %657, align 16
  %658 = shufflevector <2 x i64> %646, <2 x i64> %648, <2 x i32> <i32 1, i32 3>
  %659 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 11
  store <2 x i64> %658, <2 x i64>* %659, align 16
  %660 = shufflevector <2 x i64> %640, <2 x i64> %644, <2 x i32> <i32 0, i32 2>
  %661 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 12
  store <2 x i64> %660, <2 x i64>* %661, align 16
  %662 = shufflevector <2 x i64> %640, <2 x i64> %644, <2 x i32> <i32 1, i32 3>
  %663 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 13
  store <2 x i64> %662, <2 x i64>* %663, align 16
  %664 = shufflevector <2 x i64> %650, <2 x i64> %652, <2 x i32> <i32 0, i32 2>
  %665 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 14
  store <2 x i64> %664, <2 x i64>* %665, align 16
  %666 = shufflevector <2 x i64> %650, <2 x i64> %652, <2 x i32> <i32 1, i32 3>
  %667 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 15
  store <2 x i64> %666, <2 x i64>* %667, align 16
  %668 = icmp eq i32 %195, 0
  %669 = getelementptr inbounds i8, i8* %10, i64 2
  %670 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 0
  br label %672

671:                                              ; preds = %799
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %9) #8
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %8) #8
  ret void

672:                                              ; preds = %799, %544
  %673 = phi i64 [ 0, %544 ], [ %945, %799 ]
  %674 = shl nsw i64 %673, 3
  %675 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 %674
  br i1 %668, label %692, label %676

676:                                              ; preds = %672
  %677 = load <2 x i64>, <2 x i64>* %675, align 16
  store <2 x i64> %677, <2 x i64>* %569, align 16
  %678 = getelementptr inbounds <2 x i64>, <2 x i64>* %675, i64 1
  %679 = load <2 x i64>, <2 x i64>* %678, align 16
  store <2 x i64> %679, <2 x i64>* %568, align 16
  %680 = getelementptr inbounds <2 x i64>, <2 x i64>* %675, i64 2
  %681 = load <2 x i64>, <2 x i64>* %680, align 16
  store <2 x i64> %681, <2 x i64>* %566, align 16
  %682 = getelementptr inbounds <2 x i64>, <2 x i64>* %675, i64 3
  %683 = load <2 x i64>, <2 x i64>* %682, align 16
  store <2 x i64> %683, <2 x i64>* %565, align 16
  %684 = getelementptr inbounds <2 x i64>, <2 x i64>* %675, i64 4
  %685 = load <2 x i64>, <2 x i64>* %684, align 16
  store <2 x i64> %685, <2 x i64>* %563, align 16
  %686 = getelementptr inbounds <2 x i64>, <2 x i64>* %675, i64 5
  %687 = load <2 x i64>, <2 x i64>* %686, align 16
  store <2 x i64> %687, <2 x i64>* %562, align 16
  %688 = getelementptr inbounds <2 x i64>, <2 x i64>* %675, i64 6
  %689 = load <2 x i64>, <2 x i64>* %688, align 16
  store <2 x i64> %689, <2 x i64>* %560, align 16
  %690 = getelementptr inbounds <2 x i64>, <2 x i64>* %675, i64 7
  %691 = load <2 x i64>, <2 x i64>* %690, align 16
  store <2 x i64> %691, <2 x i64>* %670, align 16
  br label %692

692:                                              ; preds = %676, %672
  %693 = phi <2 x i64>* [ %675, %672 ], [ %194, %676 ]
  call void %17(<2 x i64>* %693, <2 x i64>* %693, i8 signext %12) #8
  %694 = load i8, i8* %669, align 1
  %695 = sext i8 %694 to i32
  %696 = icmp slt i8 %694, 0
  br i1 %696, label %697, label %743

697:                                              ; preds = %692
  %698 = sub nsw i32 0, %695
  %699 = xor i32 %695, -1
  %700 = shl i32 1, %699
  %701 = trunc i32 %700 to i16
  %702 = insertelement <8 x i16> undef, i16 %701, i32 0
  %703 = shufflevector <8 x i16> %702, <8 x i16> undef, <8 x i32> zeroinitializer
  %704 = bitcast <2 x i64>* %693 to <8 x i16>*
  %705 = load <8 x i16>, <8 x i16>* %704, align 16
  %706 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %705, <8 x i16> %703) #8
  %707 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %706, i32 %698) #8
  store <8 x i16> %707, <8 x i16>* %704, align 16
  %708 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 1
  %709 = bitcast <2 x i64>* %708 to <8 x i16>*
  %710 = load <8 x i16>, <8 x i16>* %709, align 16
  %711 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %710, <8 x i16> %703) #8
  %712 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %711, i32 %698) #8
  store <8 x i16> %712, <8 x i16>* %709, align 16
  %713 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 2
  %714 = bitcast <2 x i64>* %713 to <8 x i16>*
  %715 = load <8 x i16>, <8 x i16>* %714, align 16
  %716 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %715, <8 x i16> %703) #8
  %717 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %716, i32 %698) #8
  store <8 x i16> %717, <8 x i16>* %714, align 16
  %718 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 3
  %719 = bitcast <2 x i64>* %718 to <8 x i16>*
  %720 = load <8 x i16>, <8 x i16>* %719, align 16
  %721 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %720, <8 x i16> %703) #8
  %722 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %721, i32 %698) #8
  store <8 x i16> %722, <8 x i16>* %719, align 16
  %723 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 4
  %724 = bitcast <2 x i64>* %723 to <8 x i16>*
  %725 = load <8 x i16>, <8 x i16>* %724, align 16
  %726 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %725, <8 x i16> %703) #8
  %727 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %726, i32 %698) #8
  store <8 x i16> %727, <8 x i16>* %724, align 16
  %728 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 5
  %729 = bitcast <2 x i64>* %728 to <8 x i16>*
  %730 = load <8 x i16>, <8 x i16>* %729, align 16
  %731 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %730, <8 x i16> %703) #8
  %732 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %731, i32 %698) #8
  store <8 x i16> %732, <8 x i16>* %729, align 16
  %733 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 6
  %734 = bitcast <2 x i64>* %733 to <8 x i16>*
  %735 = load <8 x i16>, <8 x i16>* %734, align 16
  %736 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %735, <8 x i16> %703) #8
  %737 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %736, i32 %698) #8
  store <8 x i16> %737, <8 x i16>* %734, align 16
  %738 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 7
  %739 = bitcast <2 x i64>* %738 to <8 x i16>*
  %740 = load <8 x i16>, <8 x i16>* %739, align 16
  %741 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %740, <8 x i16> %703) #8
  %742 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %741, i32 %698) #8
  store <8 x i16> %742, <8 x i16>* %739, align 16
  br label %799

743:                                              ; preds = %692
  %744 = icmp eq i8 %694, 0
  %745 = bitcast <2 x i64>* %693 to <8 x i16>*
  %746 = load <8 x i16>, <8 x i16>* %745, align 16
  br i1 %744, label %747, label %769

747:                                              ; preds = %743
  %748 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 1
  %749 = bitcast <2 x i64>* %748 to <8 x i16>*
  %750 = load <8 x i16>, <8 x i16>* %749, align 16
  %751 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 2
  %752 = bitcast <2 x i64>* %751 to <8 x i16>*
  %753 = load <8 x i16>, <8 x i16>* %752, align 16
  %754 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 3
  %755 = bitcast <2 x i64>* %754 to <8 x i16>*
  %756 = load <8 x i16>, <8 x i16>* %755, align 16
  %757 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 4
  %758 = bitcast <2 x i64>* %757 to <8 x i16>*
  %759 = load <8 x i16>, <8 x i16>* %758, align 16
  %760 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 5
  %761 = bitcast <2 x i64>* %760 to <8 x i16>*
  %762 = load <8 x i16>, <8 x i16>* %761, align 16
  %763 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 6
  %764 = bitcast <2 x i64>* %763 to <8 x i16>*
  %765 = load <8 x i16>, <8 x i16>* %764, align 16
  %766 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 7
  %767 = bitcast <2 x i64>* %766 to <8 x i16>*
  %768 = load <8 x i16>, <8 x i16>* %767, align 16
  br label %799

769:                                              ; preds = %743
  %770 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %746, i32 %695) #8
  store <8 x i16> %770, <8 x i16>* %745, align 16
  %771 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 1
  %772 = bitcast <2 x i64>* %771 to <8 x i16>*
  %773 = load <8 x i16>, <8 x i16>* %772, align 16
  %774 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %773, i32 %695) #8
  store <8 x i16> %774, <8 x i16>* %772, align 16
  %775 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 2
  %776 = bitcast <2 x i64>* %775 to <8 x i16>*
  %777 = load <8 x i16>, <8 x i16>* %776, align 16
  %778 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %777, i32 %695) #8
  store <8 x i16> %778, <8 x i16>* %776, align 16
  %779 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 3
  %780 = bitcast <2 x i64>* %779 to <8 x i16>*
  %781 = load <8 x i16>, <8 x i16>* %780, align 16
  %782 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %781, i32 %695) #8
  store <8 x i16> %782, <8 x i16>* %780, align 16
  %783 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 4
  %784 = bitcast <2 x i64>* %783 to <8 x i16>*
  %785 = load <8 x i16>, <8 x i16>* %784, align 16
  %786 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %785, i32 %695) #8
  store <8 x i16> %786, <8 x i16>* %784, align 16
  %787 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 5
  %788 = bitcast <2 x i64>* %787 to <8 x i16>*
  %789 = load <8 x i16>, <8 x i16>* %788, align 16
  %790 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %789, i32 %695) #8
  store <8 x i16> %790, <8 x i16>* %788, align 16
  %791 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 6
  %792 = bitcast <2 x i64>* %791 to <8 x i16>*
  %793 = load <8 x i16>, <8 x i16>* %792, align 16
  %794 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %793, i32 %695) #8
  store <8 x i16> %794, <8 x i16>* %792, align 16
  %795 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 7
  %796 = bitcast <2 x i64>* %795 to <8 x i16>*
  %797 = load <8 x i16>, <8 x i16>* %796, align 16
  %798 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %797, i32 %695) #8
  store <8 x i16> %798, <8 x i16>* %796, align 16
  br label %799

799:                                              ; preds = %747, %769, %697
  %800 = phi <8 x i16>* [ %767, %747 ], [ %796, %769 ], [ %739, %697 ]
  %801 = phi <8 x i16> [ %768, %747 ], [ %798, %769 ], [ %742, %697 ]
  %802 = phi <8 x i16> [ %765, %747 ], [ %794, %769 ], [ %737, %697 ]
  %803 = phi <8 x i16> [ %762, %747 ], [ %790, %769 ], [ %732, %697 ]
  %804 = phi <8 x i16> [ %759, %747 ], [ %786, %769 ], [ %727, %697 ]
  %805 = phi <8 x i16> [ %756, %747 ], [ %782, %769 ], [ %722, %697 ]
  %806 = phi <8 x i16> [ %753, %747 ], [ %778, %769 ], [ %717, %697 ]
  %807 = phi <8 x i16> [ %750, %747 ], [ %774, %769 ], [ %712, %697 ]
  %808 = phi <8 x i16> [ %746, %747 ], [ %770, %769 ], [ %707, %697 ]
  %809 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 1
  %810 = shufflevector <8 x i16> %808, <8 x i16> %807, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %811 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 2
  %812 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 3
  %813 = shufflevector <8 x i16> %806, <8 x i16> %805, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %814 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 4
  %815 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 5
  %816 = shufflevector <8 x i16> %804, <8 x i16> %803, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %817 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 6
  %818 = getelementptr inbounds <2 x i64>, <2 x i64>* %693, i64 7
  %819 = shufflevector <8 x i16> %802, <8 x i16> %801, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %820 = shufflevector <8 x i16> %808, <8 x i16> %807, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %821 = shufflevector <8 x i16> %806, <8 x i16> %805, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %822 = shufflevector <8 x i16> %804, <8 x i16> %803, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %823 = shufflevector <8 x i16> %802, <8 x i16> %801, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %824 = bitcast <8 x i16> %810 to <4 x i32>
  %825 = bitcast <8 x i16> %813 to <4 x i32>
  %826 = shufflevector <4 x i32> %824, <4 x i32> %825, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %827 = bitcast <4 x i32> %826 to <2 x i64>
  %828 = bitcast <8 x i16> %816 to <4 x i32>
  %829 = bitcast <8 x i16> %819 to <4 x i32>
  %830 = shufflevector <4 x i32> %828, <4 x i32> %829, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %831 = bitcast <4 x i32> %830 to <2 x i64>
  %832 = bitcast <8 x i16> %820 to <4 x i32>
  %833 = bitcast <8 x i16> %821 to <4 x i32>
  %834 = shufflevector <4 x i32> %832, <4 x i32> %833, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %835 = bitcast <4 x i32> %834 to <2 x i64>
  %836 = bitcast <8 x i16> %822 to <4 x i32>
  %837 = bitcast <8 x i16> %823 to <4 x i32>
  %838 = shufflevector <4 x i32> %836, <4 x i32> %837, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %839 = bitcast <4 x i32> %838 to <2 x i64>
  %840 = shufflevector <4 x i32> %824, <4 x i32> %825, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %841 = bitcast <4 x i32> %840 to <2 x i64>
  %842 = shufflevector <4 x i32> %828, <4 x i32> %829, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %843 = bitcast <4 x i32> %842 to <2 x i64>
  %844 = shufflevector <4 x i32> %832, <4 x i32> %833, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %845 = bitcast <4 x i32> %844 to <2 x i64>
  %846 = shufflevector <4 x i32> %836, <4 x i32> %837, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %847 = bitcast <4 x i32> %846 to <2 x i64>
  %848 = shufflevector <2 x i64> %827, <2 x i64> %831, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %848, <2 x i64>* %693, align 16
  %849 = shufflevector <2 x i64> %827, <2 x i64> %831, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %849, <2 x i64>* %809, align 16
  %850 = shufflevector <2 x i64> %841, <2 x i64> %843, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %850, <2 x i64>* %811, align 16
  %851 = shufflevector <2 x i64> %841, <2 x i64> %843, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %851, <2 x i64>* %812, align 16
  %852 = shufflevector <2 x i64> %835, <2 x i64> %839, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %852, <2 x i64>* %814, align 16
  %853 = shufflevector <2 x i64> %835, <2 x i64> %839, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %853, <2 x i64>* %815, align 16
  %854 = shufflevector <2 x i64> %845, <2 x i64> %847, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %854, <2 x i64>* %817, align 16
  %855 = shufflevector <2 x i64> %845, <2 x i64> %847, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %855, <2 x i64>* %818, align 16
  %856 = shl nsw i64 %673, 6
  %857 = getelementptr inbounds i32, i32* %1, i64 %856
  %858 = bitcast <2 x i64> %848 to <8 x i16>
  %859 = shufflevector <8 x i16> %858, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %860 = shufflevector <8 x i16> %858, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %861 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %859, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %862 = ashr <4 x i32> %861, <i32 12, i32 12, i32 12, i32 12>
  %863 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %860, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %864 = ashr <4 x i32> %863, <i32 12, i32 12, i32 12, i32 12>
  %865 = bitcast i32* %857 to <4 x i32>*
  store <4 x i32> %862, <4 x i32>* %865, align 16
  %866 = getelementptr inbounds i32, i32* %857, i64 4
  %867 = bitcast i32* %866 to <4 x i32>*
  store <4 x i32> %864, <4 x i32>* %867, align 16
  %868 = bitcast <2 x i64> %849 to <8 x i16>
  %869 = getelementptr inbounds i32, i32* %857, i64 8
  %870 = shufflevector <8 x i16> %868, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %871 = shufflevector <8 x i16> %868, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %872 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %870, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %873 = ashr <4 x i32> %872, <i32 12, i32 12, i32 12, i32 12>
  %874 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %871, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %875 = ashr <4 x i32> %874, <i32 12, i32 12, i32 12, i32 12>
  %876 = bitcast i32* %869 to <4 x i32>*
  store <4 x i32> %873, <4 x i32>* %876, align 16
  %877 = getelementptr inbounds i32, i32* %869, i64 4
  %878 = bitcast i32* %877 to <4 x i32>*
  store <4 x i32> %875, <4 x i32>* %878, align 16
  %879 = bitcast <2 x i64> %850 to <8 x i16>
  %880 = getelementptr inbounds i32, i32* %857, i64 16
  %881 = shufflevector <8 x i16> %879, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %882 = shufflevector <8 x i16> %879, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %883 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %881, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %884 = ashr <4 x i32> %883, <i32 12, i32 12, i32 12, i32 12>
  %885 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %882, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %886 = ashr <4 x i32> %885, <i32 12, i32 12, i32 12, i32 12>
  %887 = bitcast i32* %880 to <4 x i32>*
  store <4 x i32> %884, <4 x i32>* %887, align 16
  %888 = getelementptr inbounds i32, i32* %880, i64 4
  %889 = bitcast i32* %888 to <4 x i32>*
  store <4 x i32> %886, <4 x i32>* %889, align 16
  %890 = bitcast <2 x i64> %851 to <8 x i16>
  %891 = getelementptr inbounds i32, i32* %857, i64 24
  %892 = shufflevector <8 x i16> %890, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %893 = shufflevector <8 x i16> %890, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %894 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %892, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %895 = ashr <4 x i32> %894, <i32 12, i32 12, i32 12, i32 12>
  %896 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %893, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %897 = ashr <4 x i32> %896, <i32 12, i32 12, i32 12, i32 12>
  %898 = bitcast i32* %891 to <4 x i32>*
  store <4 x i32> %895, <4 x i32>* %898, align 16
  %899 = getelementptr inbounds i32, i32* %891, i64 4
  %900 = bitcast i32* %899 to <4 x i32>*
  store <4 x i32> %897, <4 x i32>* %900, align 16
  %901 = bitcast <2 x i64> %852 to <8 x i16>
  %902 = getelementptr inbounds i32, i32* %857, i64 32
  %903 = shufflevector <8 x i16> %901, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %904 = shufflevector <8 x i16> %901, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %905 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %903, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %906 = ashr <4 x i32> %905, <i32 12, i32 12, i32 12, i32 12>
  %907 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %904, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %908 = ashr <4 x i32> %907, <i32 12, i32 12, i32 12, i32 12>
  %909 = bitcast i32* %902 to <4 x i32>*
  store <4 x i32> %906, <4 x i32>* %909, align 16
  %910 = getelementptr inbounds i32, i32* %902, i64 4
  %911 = bitcast i32* %910 to <4 x i32>*
  store <4 x i32> %908, <4 x i32>* %911, align 16
  %912 = bitcast <2 x i64> %853 to <8 x i16>
  %913 = getelementptr inbounds i32, i32* %857, i64 40
  %914 = shufflevector <8 x i16> %912, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %915 = shufflevector <8 x i16> %912, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %916 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %914, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %917 = ashr <4 x i32> %916, <i32 12, i32 12, i32 12, i32 12>
  %918 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %915, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %919 = ashr <4 x i32> %918, <i32 12, i32 12, i32 12, i32 12>
  %920 = bitcast i32* %913 to <4 x i32>*
  store <4 x i32> %917, <4 x i32>* %920, align 16
  %921 = getelementptr inbounds i32, i32* %913, i64 4
  %922 = bitcast i32* %921 to <4 x i32>*
  store <4 x i32> %919, <4 x i32>* %922, align 16
  %923 = bitcast <2 x i64> %854 to <8 x i16>
  %924 = getelementptr inbounds i32, i32* %857, i64 48
  %925 = shufflevector <8 x i16> %923, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %926 = shufflevector <8 x i16> %923, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %927 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %925, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %928 = ashr <4 x i32> %927, <i32 12, i32 12, i32 12, i32 12>
  %929 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %926, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %930 = ashr <4 x i32> %929, <i32 12, i32 12, i32 12, i32 12>
  %931 = bitcast i32* %924 to <4 x i32>*
  store <4 x i32> %928, <4 x i32>* %931, align 16
  %932 = getelementptr inbounds i32, i32* %924, i64 4
  %933 = bitcast i32* %932 to <4 x i32>*
  store <4 x i32> %930, <4 x i32>* %933, align 16
  %934 = load <8 x i16>, <8 x i16>* %800, align 16
  %935 = getelementptr inbounds i32, i32* %857, i64 56
  %936 = shufflevector <8 x i16> %934, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %937 = shufflevector <8 x i16> %934, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %938 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %936, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %939 = ashr <4 x i32> %938, <i32 12, i32 12, i32 12, i32 12>
  %940 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %937, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %941 = ashr <4 x i32> %940, <i32 12, i32 12, i32 12, i32 12>
  %942 = bitcast i32* %935 to <4 x i32>*
  store <4 x i32> %939, <4 x i32>* %942, align 16
  %943 = getelementptr inbounds i32, i32* %935, i64 4
  %944 = bitcast i32* %943 to <4 x i32>*
  store <4 x i32> %941, <4 x i32>* %944, align 16
  %945 = add nuw nsw i64 %673, 1
  %946 = icmp eq i64 %945, 2
  br i1 %946, label %671, label %672
}

; Function Attrs: nounwind ssp uwtable
define hidden void @av1_lowbd_fwd_txfm2d_8x32_sse2(i16* nocapture readonly, i32* nocapture, i32, i8 zeroext, i32) #2 {
  %6 = alloca [32 x <2 x i64>], align 16
  %7 = alloca [32 x <2 x i64>], align 16
  %8 = bitcast [32 x <2 x i64>]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 512, i8* nonnull %8) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %8, i8 -86, i64 512, i1 false)
  %9 = bitcast [32 x <2 x i64>]* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 512, i8* nonnull %9) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 512, i1 false)
  %10 = load i8*, i8** getelementptr inbounds ([19 x i8*], [19 x i8*]* @av1_fwd_txfm_shift_ls, i64 0, i64 15), align 8
  %11 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_fwd_cos_bit_col, i64 0, i64 1, i64 3), align 1
  %12 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_fwd_cos_bit_row, i64 0, i64 1, i64 3), align 1
  %13 = zext i8 %3 to i64
  %14 = getelementptr inbounds [16 x void (<2 x i64>*, <2 x i64>*, i8)*], [16 x void (<2 x i64>*, <2 x i64>*, i8)*]* @col_txfm8x32_arr, i64 0, i64 %13
  %15 = load void (<2 x i64>*, <2 x i64>*, i8)*, void (<2 x i64>*, <2 x i64>*, i8)** %14, align 8
  %16 = getelementptr inbounds [16 x void (<2 x i64>*, <2 x i64>*, i8)*], [16 x void (<2 x i64>*, <2 x i64>*, i8)*]* @row_txfm8x8_arr, i64 0, i64 %13
  %17 = load void (<2 x i64>*, <2 x i64>*, i8)*, void (<2 x i64>*, <2 x i64>*, i8)** %16, align 8
  switch i8 %3, label %44 [
    i8 6, label %19
    i8 15, label %18
    i8 7, label %18
    i8 5, label %18
    i8 14, label %20
    i8 8, label %20
    i8 4, label %20
  ]

18:                                               ; preds = %5, %5, %5
  br label %44

19:                                               ; preds = %5
  br label %20

20:                                               ; preds = %5, %5, %5, %19
  %21 = phi i32 [ 1, %19 ], [ 0, %5 ], [ 0, %5 ], [ 0, %5 ]
  %22 = sext i32 %2 to i64
  br label %23

23:                                               ; preds = %23, %20
  %24 = phi i64 [ 0, %20 ], [ %42, %23 ]
  %25 = mul nsw i64 %24, %22
  %26 = getelementptr inbounds i16, i16* %0, i64 %25
  %27 = bitcast i16* %26 to <2 x i64>*
  %28 = load <2 x i64>, <2 x i64>* %27, align 16
  %29 = shl i64 %24, 32
  %30 = sub nuw nsw i64 133143986176, %29
  %31 = ashr exact i64 %30, 32
  %32 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %31
  store <2 x i64> %28, <2 x i64>* %32, align 16
  %33 = or i64 %24, 1
  %34 = mul nsw i64 %33, %22
  %35 = getelementptr inbounds i16, i16* %0, i64 %34
  %36 = bitcast i16* %35 to <2 x i64>*
  %37 = load <2 x i64>, <2 x i64>* %36, align 16
  %38 = shl i64 %33, 32
  %39 = sub nuw nsw i64 133143986176, %38
  %40 = ashr exact i64 %39, 32
  %41 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %40
  store <2 x i64> %37, <2 x i64>* %41, align 16
  %42 = add nuw nsw i64 %24, 2
  %43 = icmp eq i64 %42, 32
  br i1 %43, label %74, label %23

44:                                               ; preds = %18, %5
  %45 = phi i32 [ 0, %5 ], [ 1, %18 ]
  %46 = sext i32 %2 to i64
  br label %47

47:                                               ; preds = %47, %44
  %48 = phi i64 [ 0, %44 ], [ %72, %47 ]
  %49 = mul nsw i64 %48, %46
  %50 = getelementptr inbounds i16, i16* %0, i64 %49
  %51 = bitcast i16* %50 to <2 x i64>*
  %52 = load <2 x i64>, <2 x i64>* %51, align 16
  %53 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %48
  store <2 x i64> %52, <2 x i64>* %53, align 16
  %54 = or i64 %48, 1
  %55 = mul nsw i64 %54, %46
  %56 = getelementptr inbounds i16, i16* %0, i64 %55
  %57 = bitcast i16* %56 to <2 x i64>*
  %58 = load <2 x i64>, <2 x i64>* %57, align 16
  %59 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %54
  store <2 x i64> %58, <2 x i64>* %59, align 16
  %60 = or i64 %48, 2
  %61 = mul nsw i64 %60, %46
  %62 = getelementptr inbounds i16, i16* %0, i64 %61
  %63 = bitcast i16* %62 to <2 x i64>*
  %64 = load <2 x i64>, <2 x i64>* %63, align 16
  %65 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %60
  store <2 x i64> %64, <2 x i64>* %65, align 16
  %66 = or i64 %48, 3
  %67 = mul nsw i64 %66, %46
  %68 = getelementptr inbounds i16, i16* %0, i64 %67
  %69 = bitcast i16* %68 to <2 x i64>*
  %70 = load <2 x i64>, <2 x i64>* %69, align 16
  %71 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %66
  store <2 x i64> %70, <2 x i64>* %71, align 16
  %72 = add nuw nsw i64 %48, 4
  %73 = icmp eq i64 %72, 32
  br i1 %73, label %74, label %47

74:                                               ; preds = %23, %47
  %75 = phi i32 [ %45, %47 ], [ %21, %23 ]
  %76 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 0
  %77 = load i8, i8* %10, align 1
  %78 = sext i8 %77 to i32
  %79 = icmp slt i8 %77, 0
  br i1 %79, label %80, label %114

80:                                               ; preds = %74
  %81 = sub nsw i32 0, %78
  %82 = xor i32 %78, -1
  %83 = shl i32 1, %82
  %84 = trunc i32 %83 to i16
  %85 = insertelement <8 x i16> undef, i16 %84, i32 0
  %86 = shufflevector <8 x i16> %85, <8 x i16> undef, <8 x i32> zeroinitializer
  br label %87

87:                                               ; preds = %87, %80
  %88 = phi i64 [ 0, %80 ], [ %112, %87 ]
  %89 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %88
  %90 = bitcast <2 x i64>* %89 to <8 x i16>*
  %91 = load <8 x i16>, <8 x i16>* %90, align 16
  %92 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %91, <8 x i16> %86) #8
  %93 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %92, i32 %81) #8
  store <8 x i16> %93, <8 x i16>* %90, align 16
  %94 = or i64 %88, 1
  %95 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %94
  %96 = bitcast <2 x i64>* %95 to <8 x i16>*
  %97 = load <8 x i16>, <8 x i16>* %96, align 16
  %98 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %97, <8 x i16> %86) #8
  %99 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %98, i32 %81) #8
  store <8 x i16> %99, <8 x i16>* %96, align 16
  %100 = or i64 %88, 2
  %101 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %100
  %102 = bitcast <2 x i64>* %101 to <8 x i16>*
  %103 = load <8 x i16>, <8 x i16>* %102, align 16
  %104 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %103, <8 x i16> %86) #8
  %105 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %104, i32 %81) #8
  store <8 x i16> %105, <8 x i16>* %102, align 16
  %106 = or i64 %88, 3
  %107 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %106
  %108 = bitcast <2 x i64>* %107 to <8 x i16>*
  %109 = load <8 x i16>, <8 x i16>* %108, align 16
  %110 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %109, <8 x i16> %86) #8
  %111 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %110, i32 %81) #8
  store <8 x i16> %111, <8 x i16>* %108, align 16
  %112 = add nuw nsw i64 %88, 4
  %113 = icmp eq i64 %112, 32
  br i1 %113, label %139, label %87

114:                                              ; preds = %74
  %115 = icmp eq i8 %77, 0
  br i1 %115, label %139, label %116

116:                                              ; preds = %114, %116
  %117 = phi i64 [ %137, %116 ], [ 0, %114 ]
  %118 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %117
  %119 = bitcast <2 x i64>* %118 to <8 x i16>*
  %120 = load <8 x i16>, <8 x i16>* %119, align 16
  %121 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %120, i32 %78) #8
  store <8 x i16> %121, <8 x i16>* %119, align 16
  %122 = or i64 %117, 1
  %123 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %122
  %124 = bitcast <2 x i64>* %123 to <8 x i16>*
  %125 = load <8 x i16>, <8 x i16>* %124, align 16
  %126 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %125, i32 %78) #8
  store <8 x i16> %126, <8 x i16>* %124, align 16
  %127 = or i64 %117, 2
  %128 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %127
  %129 = bitcast <2 x i64>* %128 to <8 x i16>*
  %130 = load <8 x i16>, <8 x i16>* %129, align 16
  %131 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %130, i32 %78) #8
  store <8 x i16> %131, <8 x i16>* %129, align 16
  %132 = or i64 %117, 3
  %133 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %132
  %134 = bitcast <2 x i64>* %133 to <8 x i16>*
  %135 = load <8 x i16>, <8 x i16>* %134, align 16
  %136 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %135, i32 %78) #8
  store <8 x i16> %136, <8 x i16>* %134, align 16
  %137 = add nuw nsw i64 %117, 4
  %138 = icmp eq i64 %137, 32
  br i1 %138, label %139, label %116

139:                                              ; preds = %116, %87, %114
  call void %15(<2 x i64>* %76, <2 x i64>* %76, i8 signext %11) #8
  %140 = getelementptr inbounds i8, i8* %10, i64 1
  %141 = load i8, i8* %140, align 1
  %142 = sext i8 %141 to i32
  %143 = icmp slt i8 %141, 0
  br i1 %143, label %144, label %178

144:                                              ; preds = %139
  %145 = sub nsw i32 0, %142
  %146 = xor i32 %142, -1
  %147 = shl i32 1, %146
  %148 = trunc i32 %147 to i16
  %149 = insertelement <8 x i16> undef, i16 %148, i32 0
  %150 = shufflevector <8 x i16> %149, <8 x i16> undef, <8 x i32> zeroinitializer
  br label %151

151:                                              ; preds = %151, %144
  %152 = phi i64 [ 0, %144 ], [ %176, %151 ]
  %153 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %152
  %154 = bitcast <2 x i64>* %153 to <8 x i16>*
  %155 = load <8 x i16>, <8 x i16>* %154, align 16
  %156 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %155, <8 x i16> %150) #8
  %157 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %156, i32 %145) #8
  store <8 x i16> %157, <8 x i16>* %154, align 16
  %158 = or i64 %152, 1
  %159 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %158
  %160 = bitcast <2 x i64>* %159 to <8 x i16>*
  %161 = load <8 x i16>, <8 x i16>* %160, align 16
  %162 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %161, <8 x i16> %150) #8
  %163 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %162, i32 %145) #8
  store <8 x i16> %163, <8 x i16>* %160, align 16
  %164 = or i64 %152, 2
  %165 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %164
  %166 = bitcast <2 x i64>* %165 to <8 x i16>*
  %167 = load <8 x i16>, <8 x i16>* %166, align 16
  %168 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %167, <8 x i16> %150) #8
  %169 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %168, i32 %145) #8
  store <8 x i16> %169, <8 x i16>* %166, align 16
  %170 = or i64 %152, 3
  %171 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %170
  %172 = bitcast <2 x i64>* %171 to <8 x i16>*
  %173 = load <8 x i16>, <8 x i16>* %172, align 16
  %174 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %173, <8 x i16> %150) #8
  %175 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %174, i32 %145) #8
  store <8 x i16> %175, <8 x i16>* %172, align 16
  %176 = add nuw nsw i64 %152, 4
  %177 = icmp eq i64 %176, 32
  br i1 %177, label %203, label %151

178:                                              ; preds = %139
  %179 = icmp eq i8 %141, 0
  br i1 %179, label %203, label %180

180:                                              ; preds = %178, %180
  %181 = phi i64 [ %201, %180 ], [ 0, %178 ]
  %182 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %181
  %183 = bitcast <2 x i64>* %182 to <8 x i16>*
  %184 = load <8 x i16>, <8 x i16>* %183, align 16
  %185 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %184, i32 %142) #8
  store <8 x i16> %185, <8 x i16>* %183, align 16
  %186 = or i64 %181, 1
  %187 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %186
  %188 = bitcast <2 x i64>* %187 to <8 x i16>*
  %189 = load <8 x i16>, <8 x i16>* %188, align 16
  %190 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %189, i32 %142) #8
  store <8 x i16> %190, <8 x i16>* %188, align 16
  %191 = or i64 %181, 2
  %192 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %191
  %193 = bitcast <2 x i64>* %192 to <8 x i16>*
  %194 = load <8 x i16>, <8 x i16>* %193, align 16
  %195 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %194, i32 %142) #8
  store <8 x i16> %195, <8 x i16>* %193, align 16
  %196 = or i64 %181, 3
  %197 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %196
  %198 = bitcast <2 x i64>* %197 to <8 x i16>*
  %199 = load <8 x i16>, <8 x i16>* %198, align 16
  %200 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %199, i32 %142) #8
  store <8 x i16> %200, <8 x i16>* %198, align 16
  %201 = add nuw nsw i64 %181, 4
  %202 = icmp eq i64 %201, 32
  br i1 %202, label %203, label %180

203:                                              ; preds = %180, %151, %178
  %204 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 0
  %205 = bitcast [32 x <2 x i64>]* %6 to <8 x i16>*
  %206 = load <8 x i16>, <8 x i16>* %205, align 16
  %207 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 1
  %208 = bitcast <2 x i64>* %207 to <8 x i16>*
  %209 = load <8 x i16>, <8 x i16>* %208, align 16
  %210 = shufflevector <8 x i16> %206, <8 x i16> %209, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %211 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 2
  %212 = bitcast <2 x i64>* %211 to <8 x i16>*
  %213 = load <8 x i16>, <8 x i16>* %212, align 16
  %214 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 3
  %215 = bitcast <2 x i64>* %214 to <8 x i16>*
  %216 = load <8 x i16>, <8 x i16>* %215, align 16
  %217 = shufflevector <8 x i16> %213, <8 x i16> %216, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %218 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 4
  %219 = bitcast <2 x i64>* %218 to <8 x i16>*
  %220 = load <8 x i16>, <8 x i16>* %219, align 16
  %221 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 5
  %222 = bitcast <2 x i64>* %221 to <8 x i16>*
  %223 = load <8 x i16>, <8 x i16>* %222, align 16
  %224 = shufflevector <8 x i16> %220, <8 x i16> %223, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %225 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 6
  %226 = bitcast <2 x i64>* %225 to <8 x i16>*
  %227 = load <8 x i16>, <8 x i16>* %226, align 16
  %228 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 7
  %229 = bitcast <2 x i64>* %228 to <8 x i16>*
  %230 = load <8 x i16>, <8 x i16>* %229, align 16
  %231 = shufflevector <8 x i16> %227, <8 x i16> %230, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %232 = shufflevector <8 x i16> %206, <8 x i16> %209, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %233 = shufflevector <8 x i16> %213, <8 x i16> %216, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %234 = shufflevector <8 x i16> %220, <8 x i16> %223, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %235 = shufflevector <8 x i16> %227, <8 x i16> %230, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %236 = bitcast <8 x i16> %210 to <4 x i32>
  %237 = bitcast <8 x i16> %217 to <4 x i32>
  %238 = shufflevector <4 x i32> %236, <4 x i32> %237, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %239 = bitcast <4 x i32> %238 to <2 x i64>
  %240 = bitcast <8 x i16> %224 to <4 x i32>
  %241 = bitcast <8 x i16> %231 to <4 x i32>
  %242 = shufflevector <4 x i32> %240, <4 x i32> %241, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %243 = bitcast <4 x i32> %242 to <2 x i64>
  %244 = bitcast <8 x i16> %232 to <4 x i32>
  %245 = bitcast <8 x i16> %233 to <4 x i32>
  %246 = shufflevector <4 x i32> %244, <4 x i32> %245, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %247 = bitcast <4 x i32> %246 to <2 x i64>
  %248 = bitcast <8 x i16> %234 to <4 x i32>
  %249 = bitcast <8 x i16> %235 to <4 x i32>
  %250 = shufflevector <4 x i32> %248, <4 x i32> %249, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %251 = bitcast <4 x i32> %250 to <2 x i64>
  %252 = shufflevector <4 x i32> %236, <4 x i32> %237, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %253 = bitcast <4 x i32> %252 to <2 x i64>
  %254 = shufflevector <4 x i32> %240, <4 x i32> %241, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %255 = bitcast <4 x i32> %254 to <2 x i64>
  %256 = shufflevector <4 x i32> %244, <4 x i32> %245, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %257 = bitcast <4 x i32> %256 to <2 x i64>
  %258 = shufflevector <4 x i32> %248, <4 x i32> %249, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %259 = bitcast <4 x i32> %258 to <2 x i64>
  %260 = shufflevector <2 x i64> %239, <2 x i64> %243, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %260, <2 x i64>* %204, align 16
  %261 = shufflevector <2 x i64> %239, <2 x i64> %243, <2 x i32> <i32 1, i32 3>
  %262 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 1
  store <2 x i64> %261, <2 x i64>* %262, align 16
  %263 = shufflevector <2 x i64> %253, <2 x i64> %255, <2 x i32> <i32 0, i32 2>
  %264 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 2
  store <2 x i64> %263, <2 x i64>* %264, align 16
  %265 = shufflevector <2 x i64> %253, <2 x i64> %255, <2 x i32> <i32 1, i32 3>
  %266 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 3
  store <2 x i64> %265, <2 x i64>* %266, align 16
  %267 = shufflevector <2 x i64> %247, <2 x i64> %251, <2 x i32> <i32 0, i32 2>
  %268 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 4
  store <2 x i64> %267, <2 x i64>* %268, align 16
  %269 = shufflevector <2 x i64> %247, <2 x i64> %251, <2 x i32> <i32 1, i32 3>
  %270 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 5
  store <2 x i64> %269, <2 x i64>* %270, align 16
  %271 = shufflevector <2 x i64> %257, <2 x i64> %259, <2 x i32> <i32 0, i32 2>
  %272 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 6
  store <2 x i64> %271, <2 x i64>* %272, align 16
  %273 = shufflevector <2 x i64> %257, <2 x i64> %259, <2 x i32> <i32 1, i32 3>
  %274 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 7
  store <2 x i64> %273, <2 x i64>* %274, align 16
  %275 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 8
  %276 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 8
  %277 = bitcast <2 x i64>* %275 to <8 x i16>*
  %278 = load <8 x i16>, <8 x i16>* %277, align 16
  %279 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 9
  %280 = bitcast <2 x i64>* %279 to <8 x i16>*
  %281 = load <8 x i16>, <8 x i16>* %280, align 16
  %282 = shufflevector <8 x i16> %278, <8 x i16> %281, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %283 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 10
  %284 = bitcast <2 x i64>* %283 to <8 x i16>*
  %285 = load <8 x i16>, <8 x i16>* %284, align 16
  %286 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 11
  %287 = bitcast <2 x i64>* %286 to <8 x i16>*
  %288 = load <8 x i16>, <8 x i16>* %287, align 16
  %289 = shufflevector <8 x i16> %285, <8 x i16> %288, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %290 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 12
  %291 = bitcast <2 x i64>* %290 to <8 x i16>*
  %292 = load <8 x i16>, <8 x i16>* %291, align 16
  %293 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 13
  %294 = bitcast <2 x i64>* %293 to <8 x i16>*
  %295 = load <8 x i16>, <8 x i16>* %294, align 16
  %296 = shufflevector <8 x i16> %292, <8 x i16> %295, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %297 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 14
  %298 = bitcast <2 x i64>* %297 to <8 x i16>*
  %299 = load <8 x i16>, <8 x i16>* %298, align 16
  %300 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 15
  %301 = bitcast <2 x i64>* %300 to <8 x i16>*
  %302 = load <8 x i16>, <8 x i16>* %301, align 16
  %303 = shufflevector <8 x i16> %299, <8 x i16> %302, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %304 = shufflevector <8 x i16> %278, <8 x i16> %281, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %305 = shufflevector <8 x i16> %285, <8 x i16> %288, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %306 = shufflevector <8 x i16> %292, <8 x i16> %295, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %307 = shufflevector <8 x i16> %299, <8 x i16> %302, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %308 = bitcast <8 x i16> %282 to <4 x i32>
  %309 = bitcast <8 x i16> %289 to <4 x i32>
  %310 = shufflevector <4 x i32> %308, <4 x i32> %309, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %311 = bitcast <4 x i32> %310 to <2 x i64>
  %312 = bitcast <8 x i16> %296 to <4 x i32>
  %313 = bitcast <8 x i16> %303 to <4 x i32>
  %314 = shufflevector <4 x i32> %312, <4 x i32> %313, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %315 = bitcast <4 x i32> %314 to <2 x i64>
  %316 = bitcast <8 x i16> %304 to <4 x i32>
  %317 = bitcast <8 x i16> %305 to <4 x i32>
  %318 = shufflevector <4 x i32> %316, <4 x i32> %317, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %319 = bitcast <4 x i32> %318 to <2 x i64>
  %320 = bitcast <8 x i16> %306 to <4 x i32>
  %321 = bitcast <8 x i16> %307 to <4 x i32>
  %322 = shufflevector <4 x i32> %320, <4 x i32> %321, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %323 = bitcast <4 x i32> %322 to <2 x i64>
  %324 = shufflevector <4 x i32> %308, <4 x i32> %309, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %325 = bitcast <4 x i32> %324 to <2 x i64>
  %326 = shufflevector <4 x i32> %312, <4 x i32> %313, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %327 = bitcast <4 x i32> %326 to <2 x i64>
  %328 = shufflevector <4 x i32> %316, <4 x i32> %317, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %329 = bitcast <4 x i32> %328 to <2 x i64>
  %330 = shufflevector <4 x i32> %320, <4 x i32> %321, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %331 = bitcast <4 x i32> %330 to <2 x i64>
  %332 = shufflevector <2 x i64> %311, <2 x i64> %315, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %332, <2 x i64>* %276, align 16
  %333 = shufflevector <2 x i64> %311, <2 x i64> %315, <2 x i32> <i32 1, i32 3>
  %334 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 9
  store <2 x i64> %333, <2 x i64>* %334, align 16
  %335 = shufflevector <2 x i64> %325, <2 x i64> %327, <2 x i32> <i32 0, i32 2>
  %336 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 10
  store <2 x i64> %335, <2 x i64>* %336, align 16
  %337 = shufflevector <2 x i64> %325, <2 x i64> %327, <2 x i32> <i32 1, i32 3>
  %338 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 11
  store <2 x i64> %337, <2 x i64>* %338, align 16
  %339 = shufflevector <2 x i64> %319, <2 x i64> %323, <2 x i32> <i32 0, i32 2>
  %340 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 12
  store <2 x i64> %339, <2 x i64>* %340, align 16
  %341 = shufflevector <2 x i64> %319, <2 x i64> %323, <2 x i32> <i32 1, i32 3>
  %342 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 13
  store <2 x i64> %341, <2 x i64>* %342, align 16
  %343 = shufflevector <2 x i64> %329, <2 x i64> %331, <2 x i32> <i32 0, i32 2>
  %344 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 14
  store <2 x i64> %343, <2 x i64>* %344, align 16
  %345 = shufflevector <2 x i64> %329, <2 x i64> %331, <2 x i32> <i32 1, i32 3>
  %346 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 15
  store <2 x i64> %345, <2 x i64>* %346, align 16
  %347 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 16
  %348 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 16
  %349 = bitcast <2 x i64>* %347 to <8 x i16>*
  %350 = load <8 x i16>, <8 x i16>* %349, align 16
  %351 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 17
  %352 = bitcast <2 x i64>* %351 to <8 x i16>*
  %353 = load <8 x i16>, <8 x i16>* %352, align 16
  %354 = shufflevector <8 x i16> %350, <8 x i16> %353, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %355 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 18
  %356 = bitcast <2 x i64>* %355 to <8 x i16>*
  %357 = load <8 x i16>, <8 x i16>* %356, align 16
  %358 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 19
  %359 = bitcast <2 x i64>* %358 to <8 x i16>*
  %360 = load <8 x i16>, <8 x i16>* %359, align 16
  %361 = shufflevector <8 x i16> %357, <8 x i16> %360, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %362 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 20
  %363 = bitcast <2 x i64>* %362 to <8 x i16>*
  %364 = load <8 x i16>, <8 x i16>* %363, align 16
  %365 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 21
  %366 = bitcast <2 x i64>* %365 to <8 x i16>*
  %367 = load <8 x i16>, <8 x i16>* %366, align 16
  %368 = shufflevector <8 x i16> %364, <8 x i16> %367, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %369 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 22
  %370 = bitcast <2 x i64>* %369 to <8 x i16>*
  %371 = load <8 x i16>, <8 x i16>* %370, align 16
  %372 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 23
  %373 = bitcast <2 x i64>* %372 to <8 x i16>*
  %374 = load <8 x i16>, <8 x i16>* %373, align 16
  %375 = shufflevector <8 x i16> %371, <8 x i16> %374, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %376 = shufflevector <8 x i16> %350, <8 x i16> %353, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %377 = shufflevector <8 x i16> %357, <8 x i16> %360, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %378 = shufflevector <8 x i16> %364, <8 x i16> %367, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %379 = shufflevector <8 x i16> %371, <8 x i16> %374, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %380 = bitcast <8 x i16> %354 to <4 x i32>
  %381 = bitcast <8 x i16> %361 to <4 x i32>
  %382 = shufflevector <4 x i32> %380, <4 x i32> %381, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %383 = bitcast <4 x i32> %382 to <2 x i64>
  %384 = bitcast <8 x i16> %368 to <4 x i32>
  %385 = bitcast <8 x i16> %375 to <4 x i32>
  %386 = shufflevector <4 x i32> %384, <4 x i32> %385, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %387 = bitcast <4 x i32> %386 to <2 x i64>
  %388 = bitcast <8 x i16> %376 to <4 x i32>
  %389 = bitcast <8 x i16> %377 to <4 x i32>
  %390 = shufflevector <4 x i32> %388, <4 x i32> %389, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %391 = bitcast <4 x i32> %390 to <2 x i64>
  %392 = bitcast <8 x i16> %378 to <4 x i32>
  %393 = bitcast <8 x i16> %379 to <4 x i32>
  %394 = shufflevector <4 x i32> %392, <4 x i32> %393, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %395 = bitcast <4 x i32> %394 to <2 x i64>
  %396 = shufflevector <4 x i32> %380, <4 x i32> %381, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %397 = bitcast <4 x i32> %396 to <2 x i64>
  %398 = shufflevector <4 x i32> %384, <4 x i32> %385, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %399 = bitcast <4 x i32> %398 to <2 x i64>
  %400 = shufflevector <4 x i32> %388, <4 x i32> %389, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %401 = bitcast <4 x i32> %400 to <2 x i64>
  %402 = shufflevector <4 x i32> %392, <4 x i32> %393, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %403 = bitcast <4 x i32> %402 to <2 x i64>
  %404 = shufflevector <2 x i64> %383, <2 x i64> %387, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %404, <2 x i64>* %348, align 16
  %405 = shufflevector <2 x i64> %383, <2 x i64> %387, <2 x i32> <i32 1, i32 3>
  %406 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 17
  store <2 x i64> %405, <2 x i64>* %406, align 16
  %407 = shufflevector <2 x i64> %397, <2 x i64> %399, <2 x i32> <i32 0, i32 2>
  %408 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 18
  store <2 x i64> %407, <2 x i64>* %408, align 16
  %409 = shufflevector <2 x i64> %397, <2 x i64> %399, <2 x i32> <i32 1, i32 3>
  %410 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 19
  store <2 x i64> %409, <2 x i64>* %410, align 16
  %411 = shufflevector <2 x i64> %391, <2 x i64> %395, <2 x i32> <i32 0, i32 2>
  %412 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 20
  store <2 x i64> %411, <2 x i64>* %412, align 16
  %413 = shufflevector <2 x i64> %391, <2 x i64> %395, <2 x i32> <i32 1, i32 3>
  %414 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 21
  store <2 x i64> %413, <2 x i64>* %414, align 16
  %415 = shufflevector <2 x i64> %401, <2 x i64> %403, <2 x i32> <i32 0, i32 2>
  %416 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 22
  store <2 x i64> %415, <2 x i64>* %416, align 16
  %417 = shufflevector <2 x i64> %401, <2 x i64> %403, <2 x i32> <i32 1, i32 3>
  %418 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 23
  store <2 x i64> %417, <2 x i64>* %418, align 16
  %419 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 24
  %420 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 24
  %421 = bitcast <2 x i64>* %419 to <8 x i16>*
  %422 = load <8 x i16>, <8 x i16>* %421, align 16
  %423 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 25
  %424 = bitcast <2 x i64>* %423 to <8 x i16>*
  %425 = load <8 x i16>, <8 x i16>* %424, align 16
  %426 = shufflevector <8 x i16> %422, <8 x i16> %425, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %427 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 26
  %428 = bitcast <2 x i64>* %427 to <8 x i16>*
  %429 = load <8 x i16>, <8 x i16>* %428, align 16
  %430 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 27
  %431 = bitcast <2 x i64>* %430 to <8 x i16>*
  %432 = load <8 x i16>, <8 x i16>* %431, align 16
  %433 = shufflevector <8 x i16> %429, <8 x i16> %432, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %434 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 28
  %435 = bitcast <2 x i64>* %434 to <8 x i16>*
  %436 = load <8 x i16>, <8 x i16>* %435, align 16
  %437 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 29
  %438 = bitcast <2 x i64>* %437 to <8 x i16>*
  %439 = load <8 x i16>, <8 x i16>* %438, align 16
  %440 = shufflevector <8 x i16> %436, <8 x i16> %439, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %441 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 30
  %442 = bitcast <2 x i64>* %441 to <8 x i16>*
  %443 = load <8 x i16>, <8 x i16>* %442, align 16
  %444 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 31
  %445 = bitcast <2 x i64>* %444 to <8 x i16>*
  %446 = load <8 x i16>, <8 x i16>* %445, align 16
  %447 = shufflevector <8 x i16> %443, <8 x i16> %446, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %448 = shufflevector <8 x i16> %422, <8 x i16> %425, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %449 = shufflevector <8 x i16> %429, <8 x i16> %432, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %450 = shufflevector <8 x i16> %436, <8 x i16> %439, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %451 = shufflevector <8 x i16> %443, <8 x i16> %446, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %452 = bitcast <8 x i16> %426 to <4 x i32>
  %453 = bitcast <8 x i16> %433 to <4 x i32>
  %454 = shufflevector <4 x i32> %452, <4 x i32> %453, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %455 = bitcast <4 x i32> %454 to <2 x i64>
  %456 = bitcast <8 x i16> %440 to <4 x i32>
  %457 = bitcast <8 x i16> %447 to <4 x i32>
  %458 = shufflevector <4 x i32> %456, <4 x i32> %457, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %459 = bitcast <4 x i32> %458 to <2 x i64>
  %460 = bitcast <8 x i16> %448 to <4 x i32>
  %461 = bitcast <8 x i16> %449 to <4 x i32>
  %462 = shufflevector <4 x i32> %460, <4 x i32> %461, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %463 = bitcast <4 x i32> %462 to <2 x i64>
  %464 = bitcast <8 x i16> %450 to <4 x i32>
  %465 = bitcast <8 x i16> %451 to <4 x i32>
  %466 = shufflevector <4 x i32> %464, <4 x i32> %465, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %467 = bitcast <4 x i32> %466 to <2 x i64>
  %468 = shufflevector <4 x i32> %452, <4 x i32> %453, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %469 = bitcast <4 x i32> %468 to <2 x i64>
  %470 = shufflevector <4 x i32> %456, <4 x i32> %457, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %471 = bitcast <4 x i32> %470 to <2 x i64>
  %472 = shufflevector <4 x i32> %460, <4 x i32> %461, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %473 = bitcast <4 x i32> %472 to <2 x i64>
  %474 = shufflevector <4 x i32> %464, <4 x i32> %465, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %475 = bitcast <4 x i32> %474 to <2 x i64>
  %476 = shufflevector <2 x i64> %455, <2 x i64> %459, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %476, <2 x i64>* %420, align 16
  %477 = shufflevector <2 x i64> %455, <2 x i64> %459, <2 x i32> <i32 1, i32 3>
  %478 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 25
  store <2 x i64> %477, <2 x i64>* %478, align 16
  %479 = shufflevector <2 x i64> %469, <2 x i64> %471, <2 x i32> <i32 0, i32 2>
  %480 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 26
  store <2 x i64> %479, <2 x i64>* %480, align 16
  %481 = shufflevector <2 x i64> %469, <2 x i64> %471, <2 x i32> <i32 1, i32 3>
  %482 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 27
  store <2 x i64> %481, <2 x i64>* %482, align 16
  %483 = shufflevector <2 x i64> %463, <2 x i64> %467, <2 x i32> <i32 0, i32 2>
  %484 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 28
  store <2 x i64> %483, <2 x i64>* %484, align 16
  %485 = shufflevector <2 x i64> %463, <2 x i64> %467, <2 x i32> <i32 1, i32 3>
  %486 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 29
  store <2 x i64> %485, <2 x i64>* %486, align 16
  %487 = shufflevector <2 x i64> %473, <2 x i64> %475, <2 x i32> <i32 0, i32 2>
  %488 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 30
  store <2 x i64> %487, <2 x i64>* %488, align 16
  %489 = shufflevector <2 x i64> %473, <2 x i64> %475, <2 x i32> <i32 1, i32 3>
  %490 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 31
  store <2 x i64> %489, <2 x i64>* %490, align 16
  %491 = icmp eq i32 %75, 0
  %492 = getelementptr inbounds i8, i8* %10, i64 2
  %493 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 0
  br label %495

494:                                              ; preds = %622
  call void @llvm.lifetime.end.p0i8(i64 512, i8* nonnull %9) #8
  call void @llvm.lifetime.end.p0i8(i64 512, i8* nonnull %8) #8
  ret void

495:                                              ; preds = %622, %203
  %496 = phi i64 [ 0, %203 ], [ %768, %622 ]
  %497 = shl nsw i64 %496, 3
  %498 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 %497
  br i1 %491, label %515, label %499

499:                                              ; preds = %495
  %500 = load <2 x i64>, <2 x i64>* %498, align 16
  store <2 x i64> %500, <2 x i64>* %228, align 16
  %501 = getelementptr inbounds <2 x i64>, <2 x i64>* %498, i64 1
  %502 = load <2 x i64>, <2 x i64>* %501, align 16
  store <2 x i64> %502, <2 x i64>* %225, align 16
  %503 = getelementptr inbounds <2 x i64>, <2 x i64>* %498, i64 2
  %504 = load <2 x i64>, <2 x i64>* %503, align 16
  store <2 x i64> %504, <2 x i64>* %221, align 16
  %505 = getelementptr inbounds <2 x i64>, <2 x i64>* %498, i64 3
  %506 = load <2 x i64>, <2 x i64>* %505, align 16
  store <2 x i64> %506, <2 x i64>* %218, align 16
  %507 = getelementptr inbounds <2 x i64>, <2 x i64>* %498, i64 4
  %508 = load <2 x i64>, <2 x i64>* %507, align 16
  store <2 x i64> %508, <2 x i64>* %214, align 16
  %509 = getelementptr inbounds <2 x i64>, <2 x i64>* %498, i64 5
  %510 = load <2 x i64>, <2 x i64>* %509, align 16
  store <2 x i64> %510, <2 x i64>* %211, align 16
  %511 = getelementptr inbounds <2 x i64>, <2 x i64>* %498, i64 6
  %512 = load <2 x i64>, <2 x i64>* %511, align 16
  store <2 x i64> %512, <2 x i64>* %207, align 16
  %513 = getelementptr inbounds <2 x i64>, <2 x i64>* %498, i64 7
  %514 = load <2 x i64>, <2 x i64>* %513, align 16
  store <2 x i64> %514, <2 x i64>* %493, align 16
  br label %515

515:                                              ; preds = %499, %495
  %516 = phi <2 x i64>* [ %498, %495 ], [ %76, %499 ]
  call void %17(<2 x i64>* %516, <2 x i64>* %516, i8 signext %12) #8
  %517 = load i8, i8* %492, align 1
  %518 = sext i8 %517 to i32
  %519 = icmp slt i8 %517, 0
  br i1 %519, label %520, label %566

520:                                              ; preds = %515
  %521 = sub nsw i32 0, %518
  %522 = xor i32 %518, -1
  %523 = shl i32 1, %522
  %524 = trunc i32 %523 to i16
  %525 = insertelement <8 x i16> undef, i16 %524, i32 0
  %526 = shufflevector <8 x i16> %525, <8 x i16> undef, <8 x i32> zeroinitializer
  %527 = bitcast <2 x i64>* %516 to <8 x i16>*
  %528 = load <8 x i16>, <8 x i16>* %527, align 16
  %529 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %528, <8 x i16> %526) #8
  %530 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %529, i32 %521) #8
  store <8 x i16> %530, <8 x i16>* %527, align 16
  %531 = getelementptr inbounds <2 x i64>, <2 x i64>* %516, i64 1
  %532 = bitcast <2 x i64>* %531 to <8 x i16>*
  %533 = load <8 x i16>, <8 x i16>* %532, align 16
  %534 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %533, <8 x i16> %526) #8
  %535 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %534, i32 %521) #8
  store <8 x i16> %535, <8 x i16>* %532, align 16
  %536 = getelementptr inbounds <2 x i64>, <2 x i64>* %516, i64 2
  %537 = bitcast <2 x i64>* %536 to <8 x i16>*
  %538 = load <8 x i16>, <8 x i16>* %537, align 16
  %539 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %538, <8 x i16> %526) #8
  %540 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %539, i32 %521) #8
  store <8 x i16> %540, <8 x i16>* %537, align 16
  %541 = getelementptr inbounds <2 x i64>, <2 x i64>* %516, i64 3
  %542 = bitcast <2 x i64>* %541 to <8 x i16>*
  %543 = load <8 x i16>, <8 x i16>* %542, align 16
  %544 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %543, <8 x i16> %526) #8
  %545 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %544, i32 %521) #8
  store <8 x i16> %545, <8 x i16>* %542, align 16
  %546 = getelementptr inbounds <2 x i64>, <2 x i64>* %516, i64 4
  %547 = bitcast <2 x i64>* %546 to <8 x i16>*
  %548 = load <8 x i16>, <8 x i16>* %547, align 16
  %549 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %548, <8 x i16> %526) #8
  %550 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %549, i32 %521) #8
  store <8 x i16> %550, <8 x i16>* %547, align 16
  %551 = getelementptr inbounds <2 x i64>, <2 x i64>* %516, i64 5
  %552 = bitcast <2 x i64>* %551 to <8 x i16>*
  %553 = load <8 x i16>, <8 x i16>* %552, align 16
  %554 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %553, <8 x i16> %526) #8
  %555 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %554, i32 %521) #8
  store <8 x i16> %555, <8 x i16>* %552, align 16
  %556 = getelementptr inbounds <2 x i64>, <2 x i64>* %516, i64 6
  %557 = bitcast <2 x i64>* %556 to <8 x i16>*
  %558 = load <8 x i16>, <8 x i16>* %557, align 16
  %559 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %558, <8 x i16> %526) #8
  %560 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %559, i32 %521) #8
  store <8 x i16> %560, <8 x i16>* %557, align 16
  %561 = getelementptr inbounds <2 x i64>, <2 x i64>* %516, i64 7
  %562 = bitcast <2 x i64>* %561 to <8 x i16>*
  %563 = load <8 x i16>, <8 x i16>* %562, align 16
  %564 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %563, <8 x i16> %526) #8
  %565 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %564, i32 %521) #8
  store <8 x i16> %565, <8 x i16>* %562, align 16
  br label %622

566:                                              ; preds = %515
  %567 = icmp eq i8 %517, 0
  %568 = bitcast <2 x i64>* %516 to <8 x i16>*
  %569 = load <8 x i16>, <8 x i16>* %568, align 16
  br i1 %567, label %570, label %592

570:                                              ; preds = %566
  %571 = getelementptr inbounds <2 x i64>, <2 x i64>* %516, i64 1
  %572 = bitcast <2 x i64>* %571 to <8 x i16>*
  %573 = load <8 x i16>, <8 x i16>* %572, align 16
  %574 = getelementptr inbounds <2 x i64>, <2 x i64>* %516, i64 2
  %575 = bitcast <2 x i64>* %574 to <8 x i16>*
  %576 = load <8 x i16>, <8 x i16>* %575, align 16
  %577 = getelementptr inbounds <2 x i64>, <2 x i64>* %516, i64 3
  %578 = bitcast <2 x i64>* %577 to <8 x i16>*
  %579 = load <8 x i16>, <8 x i16>* %578, align 16
  %580 = getelementptr inbounds <2 x i64>, <2 x i64>* %516, i64 4
  %581 = bitcast <2 x i64>* %580 to <8 x i16>*
  %582 = load <8 x i16>, <8 x i16>* %581, align 16
  %583 = getelementptr inbounds <2 x i64>, <2 x i64>* %516, i64 5
  %584 = bitcast <2 x i64>* %583 to <8 x i16>*
  %585 = load <8 x i16>, <8 x i16>* %584, align 16
  %586 = getelementptr inbounds <2 x i64>, <2 x i64>* %516, i64 6
  %587 = bitcast <2 x i64>* %586 to <8 x i16>*
  %588 = load <8 x i16>, <8 x i16>* %587, align 16
  %589 = getelementptr inbounds <2 x i64>, <2 x i64>* %516, i64 7
  %590 = bitcast <2 x i64>* %589 to <8 x i16>*
  %591 = load <8 x i16>, <8 x i16>* %590, align 16
  br label %622

592:                                              ; preds = %566
  %593 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %569, i32 %518) #8
  store <8 x i16> %593, <8 x i16>* %568, align 16
  %594 = getelementptr inbounds <2 x i64>, <2 x i64>* %516, i64 1
  %595 = bitcast <2 x i64>* %594 to <8 x i16>*
  %596 = load <8 x i16>, <8 x i16>* %595, align 16
  %597 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %596, i32 %518) #8
  store <8 x i16> %597, <8 x i16>* %595, align 16
  %598 = getelementptr inbounds <2 x i64>, <2 x i64>* %516, i64 2
  %599 = bitcast <2 x i64>* %598 to <8 x i16>*
  %600 = load <8 x i16>, <8 x i16>* %599, align 16
  %601 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %600, i32 %518) #8
  store <8 x i16> %601, <8 x i16>* %599, align 16
  %602 = getelementptr inbounds <2 x i64>, <2 x i64>* %516, i64 3
  %603 = bitcast <2 x i64>* %602 to <8 x i16>*
  %604 = load <8 x i16>, <8 x i16>* %603, align 16
  %605 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %604, i32 %518) #8
  store <8 x i16> %605, <8 x i16>* %603, align 16
  %606 = getelementptr inbounds <2 x i64>, <2 x i64>* %516, i64 4
  %607 = bitcast <2 x i64>* %606 to <8 x i16>*
  %608 = load <8 x i16>, <8 x i16>* %607, align 16
  %609 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %608, i32 %518) #8
  store <8 x i16> %609, <8 x i16>* %607, align 16
  %610 = getelementptr inbounds <2 x i64>, <2 x i64>* %516, i64 5
  %611 = bitcast <2 x i64>* %610 to <8 x i16>*
  %612 = load <8 x i16>, <8 x i16>* %611, align 16
  %613 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %612, i32 %518) #8
  store <8 x i16> %613, <8 x i16>* %611, align 16
  %614 = getelementptr inbounds <2 x i64>, <2 x i64>* %516, i64 6
  %615 = bitcast <2 x i64>* %614 to <8 x i16>*
  %616 = load <8 x i16>, <8 x i16>* %615, align 16
  %617 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %616, i32 %518) #8
  store <8 x i16> %617, <8 x i16>* %615, align 16
  %618 = getelementptr inbounds <2 x i64>, <2 x i64>* %516, i64 7
  %619 = bitcast <2 x i64>* %618 to <8 x i16>*
  %620 = load <8 x i16>, <8 x i16>* %619, align 16
  %621 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %620, i32 %518) #8
  store <8 x i16> %621, <8 x i16>* %619, align 16
  br label %622

622:                                              ; preds = %570, %592, %520
  %623 = phi <8 x i16>* [ %590, %570 ], [ %619, %592 ], [ %562, %520 ]
  %624 = phi <8 x i16> [ %591, %570 ], [ %621, %592 ], [ %565, %520 ]
  %625 = phi <8 x i16> [ %588, %570 ], [ %617, %592 ], [ %560, %520 ]
  %626 = phi <8 x i16> [ %585, %570 ], [ %613, %592 ], [ %555, %520 ]
  %627 = phi <8 x i16> [ %582, %570 ], [ %609, %592 ], [ %550, %520 ]
  %628 = phi <8 x i16> [ %579, %570 ], [ %605, %592 ], [ %545, %520 ]
  %629 = phi <8 x i16> [ %576, %570 ], [ %601, %592 ], [ %540, %520 ]
  %630 = phi <8 x i16> [ %573, %570 ], [ %597, %592 ], [ %535, %520 ]
  %631 = phi <8 x i16> [ %569, %570 ], [ %593, %592 ], [ %530, %520 ]
  %632 = getelementptr inbounds <2 x i64>, <2 x i64>* %516, i64 1
  %633 = shufflevector <8 x i16> %631, <8 x i16> %630, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %634 = getelementptr inbounds <2 x i64>, <2 x i64>* %516, i64 2
  %635 = getelementptr inbounds <2 x i64>, <2 x i64>* %516, i64 3
  %636 = shufflevector <8 x i16> %629, <8 x i16> %628, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %637 = getelementptr inbounds <2 x i64>, <2 x i64>* %516, i64 4
  %638 = getelementptr inbounds <2 x i64>, <2 x i64>* %516, i64 5
  %639 = shufflevector <8 x i16> %627, <8 x i16> %626, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %640 = getelementptr inbounds <2 x i64>, <2 x i64>* %516, i64 6
  %641 = getelementptr inbounds <2 x i64>, <2 x i64>* %516, i64 7
  %642 = shufflevector <8 x i16> %625, <8 x i16> %624, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %643 = shufflevector <8 x i16> %631, <8 x i16> %630, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %644 = shufflevector <8 x i16> %629, <8 x i16> %628, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %645 = shufflevector <8 x i16> %627, <8 x i16> %626, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %646 = shufflevector <8 x i16> %625, <8 x i16> %624, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %647 = bitcast <8 x i16> %633 to <4 x i32>
  %648 = bitcast <8 x i16> %636 to <4 x i32>
  %649 = shufflevector <4 x i32> %647, <4 x i32> %648, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %650 = bitcast <4 x i32> %649 to <2 x i64>
  %651 = bitcast <8 x i16> %639 to <4 x i32>
  %652 = bitcast <8 x i16> %642 to <4 x i32>
  %653 = shufflevector <4 x i32> %651, <4 x i32> %652, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %654 = bitcast <4 x i32> %653 to <2 x i64>
  %655 = bitcast <8 x i16> %643 to <4 x i32>
  %656 = bitcast <8 x i16> %644 to <4 x i32>
  %657 = shufflevector <4 x i32> %655, <4 x i32> %656, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %658 = bitcast <4 x i32> %657 to <2 x i64>
  %659 = bitcast <8 x i16> %645 to <4 x i32>
  %660 = bitcast <8 x i16> %646 to <4 x i32>
  %661 = shufflevector <4 x i32> %659, <4 x i32> %660, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %662 = bitcast <4 x i32> %661 to <2 x i64>
  %663 = shufflevector <4 x i32> %647, <4 x i32> %648, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %664 = bitcast <4 x i32> %663 to <2 x i64>
  %665 = shufflevector <4 x i32> %651, <4 x i32> %652, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %666 = bitcast <4 x i32> %665 to <2 x i64>
  %667 = shufflevector <4 x i32> %655, <4 x i32> %656, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %668 = bitcast <4 x i32> %667 to <2 x i64>
  %669 = shufflevector <4 x i32> %659, <4 x i32> %660, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %670 = bitcast <4 x i32> %669 to <2 x i64>
  %671 = shufflevector <2 x i64> %650, <2 x i64> %654, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %671, <2 x i64>* %516, align 16
  %672 = shufflevector <2 x i64> %650, <2 x i64> %654, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %672, <2 x i64>* %632, align 16
  %673 = shufflevector <2 x i64> %664, <2 x i64> %666, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %673, <2 x i64>* %634, align 16
  %674 = shufflevector <2 x i64> %664, <2 x i64> %666, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %674, <2 x i64>* %635, align 16
  %675 = shufflevector <2 x i64> %658, <2 x i64> %662, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %675, <2 x i64>* %637, align 16
  %676 = shufflevector <2 x i64> %658, <2 x i64> %662, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %676, <2 x i64>* %638, align 16
  %677 = shufflevector <2 x i64> %668, <2 x i64> %670, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %677, <2 x i64>* %640, align 16
  %678 = shufflevector <2 x i64> %668, <2 x i64> %670, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %678, <2 x i64>* %641, align 16
  %679 = shl nsw i64 %496, 6
  %680 = getelementptr inbounds i32, i32* %1, i64 %679
  %681 = bitcast <2 x i64> %671 to <8 x i16>
  %682 = shufflevector <8 x i16> %681, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %683 = shufflevector <8 x i16> %681, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %684 = bitcast <8 x i16> %682 to <4 x i32>
  %685 = ashr <4 x i32> %684, <i32 16, i32 16, i32 16, i32 16>
  %686 = bitcast <8 x i16> %683 to <4 x i32>
  %687 = ashr <4 x i32> %686, <i32 16, i32 16, i32 16, i32 16>
  %688 = bitcast i32* %680 to <4 x i32>*
  store <4 x i32> %685, <4 x i32>* %688, align 16
  %689 = getelementptr inbounds i32, i32* %680, i64 4
  %690 = bitcast i32* %689 to <4 x i32>*
  store <4 x i32> %687, <4 x i32>* %690, align 16
  %691 = bitcast <2 x i64> %672 to <8 x i16>
  %692 = getelementptr inbounds i32, i32* %680, i64 8
  %693 = shufflevector <8 x i16> %691, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %694 = shufflevector <8 x i16> %691, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %695 = bitcast <8 x i16> %693 to <4 x i32>
  %696 = ashr <4 x i32> %695, <i32 16, i32 16, i32 16, i32 16>
  %697 = bitcast <8 x i16> %694 to <4 x i32>
  %698 = ashr <4 x i32> %697, <i32 16, i32 16, i32 16, i32 16>
  %699 = bitcast i32* %692 to <4 x i32>*
  store <4 x i32> %696, <4 x i32>* %699, align 16
  %700 = getelementptr inbounds i32, i32* %692, i64 4
  %701 = bitcast i32* %700 to <4 x i32>*
  store <4 x i32> %698, <4 x i32>* %701, align 16
  %702 = bitcast <2 x i64> %673 to <8 x i16>
  %703 = getelementptr inbounds i32, i32* %680, i64 16
  %704 = shufflevector <8 x i16> %702, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %705 = shufflevector <8 x i16> %702, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %706 = bitcast <8 x i16> %704 to <4 x i32>
  %707 = ashr <4 x i32> %706, <i32 16, i32 16, i32 16, i32 16>
  %708 = bitcast <8 x i16> %705 to <4 x i32>
  %709 = ashr <4 x i32> %708, <i32 16, i32 16, i32 16, i32 16>
  %710 = bitcast i32* %703 to <4 x i32>*
  store <4 x i32> %707, <4 x i32>* %710, align 16
  %711 = getelementptr inbounds i32, i32* %703, i64 4
  %712 = bitcast i32* %711 to <4 x i32>*
  store <4 x i32> %709, <4 x i32>* %712, align 16
  %713 = bitcast <2 x i64> %674 to <8 x i16>
  %714 = getelementptr inbounds i32, i32* %680, i64 24
  %715 = shufflevector <8 x i16> %713, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %716 = shufflevector <8 x i16> %713, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %717 = bitcast <8 x i16> %715 to <4 x i32>
  %718 = ashr <4 x i32> %717, <i32 16, i32 16, i32 16, i32 16>
  %719 = bitcast <8 x i16> %716 to <4 x i32>
  %720 = ashr <4 x i32> %719, <i32 16, i32 16, i32 16, i32 16>
  %721 = bitcast i32* %714 to <4 x i32>*
  store <4 x i32> %718, <4 x i32>* %721, align 16
  %722 = getelementptr inbounds i32, i32* %714, i64 4
  %723 = bitcast i32* %722 to <4 x i32>*
  store <4 x i32> %720, <4 x i32>* %723, align 16
  %724 = bitcast <2 x i64> %675 to <8 x i16>
  %725 = getelementptr inbounds i32, i32* %680, i64 32
  %726 = shufflevector <8 x i16> %724, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %727 = shufflevector <8 x i16> %724, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %728 = bitcast <8 x i16> %726 to <4 x i32>
  %729 = ashr <4 x i32> %728, <i32 16, i32 16, i32 16, i32 16>
  %730 = bitcast <8 x i16> %727 to <4 x i32>
  %731 = ashr <4 x i32> %730, <i32 16, i32 16, i32 16, i32 16>
  %732 = bitcast i32* %725 to <4 x i32>*
  store <4 x i32> %729, <4 x i32>* %732, align 16
  %733 = getelementptr inbounds i32, i32* %725, i64 4
  %734 = bitcast i32* %733 to <4 x i32>*
  store <4 x i32> %731, <4 x i32>* %734, align 16
  %735 = bitcast <2 x i64> %676 to <8 x i16>
  %736 = getelementptr inbounds i32, i32* %680, i64 40
  %737 = shufflevector <8 x i16> %735, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %738 = shufflevector <8 x i16> %735, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %739 = bitcast <8 x i16> %737 to <4 x i32>
  %740 = ashr <4 x i32> %739, <i32 16, i32 16, i32 16, i32 16>
  %741 = bitcast <8 x i16> %738 to <4 x i32>
  %742 = ashr <4 x i32> %741, <i32 16, i32 16, i32 16, i32 16>
  %743 = bitcast i32* %736 to <4 x i32>*
  store <4 x i32> %740, <4 x i32>* %743, align 16
  %744 = getelementptr inbounds i32, i32* %736, i64 4
  %745 = bitcast i32* %744 to <4 x i32>*
  store <4 x i32> %742, <4 x i32>* %745, align 16
  %746 = bitcast <2 x i64> %677 to <8 x i16>
  %747 = getelementptr inbounds i32, i32* %680, i64 48
  %748 = shufflevector <8 x i16> %746, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %749 = shufflevector <8 x i16> %746, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %750 = bitcast <8 x i16> %748 to <4 x i32>
  %751 = ashr <4 x i32> %750, <i32 16, i32 16, i32 16, i32 16>
  %752 = bitcast <8 x i16> %749 to <4 x i32>
  %753 = ashr <4 x i32> %752, <i32 16, i32 16, i32 16, i32 16>
  %754 = bitcast i32* %747 to <4 x i32>*
  store <4 x i32> %751, <4 x i32>* %754, align 16
  %755 = getelementptr inbounds i32, i32* %747, i64 4
  %756 = bitcast i32* %755 to <4 x i32>*
  store <4 x i32> %753, <4 x i32>* %756, align 16
  %757 = load <8 x i16>, <8 x i16>* %623, align 16
  %758 = getelementptr inbounds i32, i32* %680, i64 56
  %759 = shufflevector <8 x i16> %757, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %760 = shufflevector <8 x i16> %757, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %761 = bitcast <8 x i16> %759 to <4 x i32>
  %762 = ashr <4 x i32> %761, <i32 16, i32 16, i32 16, i32 16>
  %763 = bitcast <8 x i16> %760 to <4 x i32>
  %764 = ashr <4 x i32> %763, <i32 16, i32 16, i32 16, i32 16>
  %765 = bitcast i32* %758 to <4 x i32>*
  store <4 x i32> %762, <4 x i32>* %765, align 16
  %766 = getelementptr inbounds i32, i32* %758, i64 4
  %767 = bitcast i32* %766 to <4 x i32>*
  store <4 x i32> %764, <4 x i32>* %767, align 16
  %768 = add nuw nsw i64 %496, 1
  %769 = icmp eq i64 %768, 4
  br i1 %769, label %494, label %495
}

; Function Attrs: nounwind ssp uwtable
define hidden void @av1_lowbd_fwd_txfm2d_16x4_sse2(i16* nocapture readonly, i32* nocapture, i32, i8 zeroext, i32) #2 {
  %6 = alloca [16 x <2 x i64>], align 16
  %7 = alloca [16 x <2 x i64>], align 16
  %8 = bitcast [16 x <2 x i64>]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %8) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %8, i8 -86, i64 256, i1 false)
  %9 = bitcast [16 x <2 x i64>]* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %9) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 256, i1 false)
  %10 = load i8*, i8** getelementptr inbounds ([19 x i8*], [19 x i8*]* @av1_fwd_txfm_shift_ls, i64 0, i64 14), align 16
  %11 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_fwd_cos_bit_col, i64 0, i64 2, i64 0), align 2
  %12 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_fwd_cos_bit_row, i64 0, i64 2, i64 0), align 2
  %13 = zext i8 %3 to i64
  %14 = getelementptr inbounds [16 x void (<2 x i64>*, <2 x i64>*, i8)*], [16 x void (<2 x i64>*, <2 x i64>*, i8)*]* @col_txfm8x4_arr, i64 0, i64 %13
  %15 = load void (<2 x i64>*, <2 x i64>*, i8)*, void (<2 x i64>*, <2 x i64>*, i8)** %14, align 8
  %16 = getelementptr inbounds [16 x void (<2 x i64>*, <2 x i64>*, i8)*], [16 x void (<2 x i64>*, <2 x i64>*, i8)*]* @row_txfm8x16_arr, i64 0, i64 %13
  %17 = load void (<2 x i64>*, <2 x i64>*, i8)*, void (<2 x i64>*, <2 x i64>*, i8)** %16, align 8
  switch i8 %3, label %21 [
    i8 6, label %20
    i8 15, label %19
    i8 7, label %19
    i8 5, label %19
    i8 14, label %18
    i8 8, label %18
    i8 4, label %18
  ]

18:                                               ; preds = %5, %5, %5
  br label %21

19:                                               ; preds = %5, %5, %5
  br label %21

20:                                               ; preds = %5
  br label %21

21:                                               ; preds = %5, %18, %19, %20
  %22 = phi i1 [ false, %20 ], [ true, %19 ], [ false, %18 ], [ true, %5 ]
  %23 = phi i32 [ 1, %20 ], [ 1, %19 ], [ 0, %18 ], [ 0, %5 ]
  %24 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 0
  %25 = sext i32 %2 to i64
  %26 = getelementptr inbounds i8, i8* %10, i64 1
  %27 = bitcast [16 x <2 x i64>]* %6 to <8 x i16>*
  %28 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 1
  %29 = bitcast <2 x i64>* %28 to <8 x i16>*
  %30 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 2
  %31 = bitcast <2 x i64>* %30 to <8 x i16>*
  %32 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 3
  %33 = bitcast <2 x i64>* %32 to <8 x i16>*
  %34 = shl nsw i64 %25, 1
  %35 = mul nsw i64 %25, 3
  %36 = shl nsw i64 %25, 1
  %37 = mul nsw i64 %25, 3
  %38 = bitcast [16 x <2 x i64>]* %6 to <8 x i16>*
  %39 = bitcast [16 x <2 x i64>]* %6 to <8 x i16>*
  %40 = bitcast [16 x <2 x i64>]* %6 to <8 x i16>*
  %41 = bitcast [16 x <2 x i64>]* %6 to <8 x i16>*
  br label %45

42:                                               ; preds = %146
  %43 = icmp eq i32 %23, 0
  %44 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 0
  br i1 %43, label %229, label %185

45:                                               ; preds = %146, %21
  %46 = phi i64 [ 0, %21 ], [ %183, %146 ]
  %47 = shl nsw i64 %46, 3
  %48 = getelementptr inbounds i16, i16* %0, i64 %47
  %49 = bitcast i16* %48 to <2 x i64>*
  %50 = load <2 x i64>, <2 x i64>* %49, align 16
  br i1 %22, label %61, label %51

51:                                               ; preds = %45
  store <2 x i64> %50, <2 x i64>* %32, align 16
  %52 = getelementptr inbounds i16, i16* %48, i64 %25
  %53 = bitcast i16* %52 to <2 x i64>*
  %54 = load <2 x i64>, <2 x i64>* %53, align 16
  store <2 x i64> %54, <2 x i64>* %30, align 16
  %55 = getelementptr inbounds i16, i16* %48, i64 %34
  %56 = bitcast i16* %55 to <2 x i64>*
  %57 = load <2 x i64>, <2 x i64>* %56, align 16
  store <2 x i64> %57, <2 x i64>* %28, align 16
  %58 = getelementptr inbounds i16, i16* %48, i64 %35
  %59 = bitcast i16* %58 to <2 x i64>*
  %60 = load <2 x i64>, <2 x i64>* %59, align 16
  store <2 x i64> %60, <2 x i64>* %24, align 16
  br label %71

61:                                               ; preds = %45
  store <2 x i64> %50, <2 x i64>* %24, align 16
  %62 = getelementptr inbounds i16, i16* %48, i64 %25
  %63 = bitcast i16* %62 to <2 x i64>*
  %64 = load <2 x i64>, <2 x i64>* %63, align 16
  store <2 x i64> %64, <2 x i64>* %28, align 16
  %65 = getelementptr inbounds i16, i16* %48, i64 %36
  %66 = bitcast i16* %65 to <2 x i64>*
  %67 = load <2 x i64>, <2 x i64>* %66, align 16
  store <2 x i64> %67, <2 x i64>* %30, align 16
  %68 = getelementptr inbounds i16, i16* %48, i64 %37
  %69 = bitcast i16* %68 to <2 x i64>*
  %70 = load <2 x i64>, <2 x i64>* %69, align 16
  store <2 x i64> %70, <2 x i64>* %32, align 16
  br label %71

71:                                               ; preds = %51, %61
  %72 = phi <2 x i64> [ %50, %51 ], [ %70, %61 ]
  %73 = phi <2 x i64> [ %54, %51 ], [ %67, %61 ]
  %74 = phi <2 x i64> [ %57, %51 ], [ %64, %61 ]
  %75 = phi <2 x i64> [ %60, %51 ], [ %50, %61 ]
  %76 = bitcast <2 x i64> %75 to <8 x i16>
  %77 = bitcast <2 x i64> %74 to <8 x i16>
  %78 = bitcast <2 x i64> %73 to <8 x i16>
  %79 = bitcast <2 x i64> %72 to <8 x i16>
  %80 = load i8, i8* %10, align 1
  %81 = sext i8 %80 to i32
  %82 = icmp slt i8 %80, 0
  br i1 %82, label %83, label %98

83:                                               ; preds = %71
  %84 = sub nsw i32 0, %81
  %85 = xor i32 %81, -1
  %86 = shl i32 1, %85
  %87 = trunc i32 %86 to i16
  %88 = insertelement <8 x i16> undef, i16 %87, i32 0
  %89 = shufflevector <8 x i16> %88, <8 x i16> undef, <8 x i32> zeroinitializer
  %90 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %76, <8 x i16> %89) #8
  %91 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %90, i32 %84) #8
  store <8 x i16> %91, <8 x i16>* %39, align 16
  %92 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %77, <8 x i16> %89) #8
  %93 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %92, i32 %84) #8
  store <8 x i16> %93, <8 x i16>* %29, align 16
  %94 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %78, <8 x i16> %89) #8
  %95 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %94, i32 %84) #8
  store <8 x i16> %95, <8 x i16>* %31, align 16
  %96 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %79, <8 x i16> %89) #8
  %97 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %96, i32 %84) #8
  br label %105

98:                                               ; preds = %71
  %99 = icmp eq i8 %80, 0
  br i1 %99, label %107, label %100

100:                                              ; preds = %98
  %101 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %76, i32 %81) #8
  store <8 x i16> %101, <8 x i16>* %38, align 16
  %102 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %77, i32 %81) #8
  store <8 x i16> %102, <8 x i16>* %29, align 16
  %103 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %78, i32 %81) #8
  store <8 x i16> %103, <8 x i16>* %31, align 16
  %104 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %79, i32 %81) #8
  br label %105

105:                                              ; preds = %83, %100
  %106 = phi <8 x i16> [ %104, %100 ], [ %97, %83 ]
  store <8 x i16> %106, <8 x i16>* %33, align 16
  br label %107

107:                                              ; preds = %105, %98
  call void %15(<2 x i64>* nonnull %24, <2 x i64>* nonnull %24, i8 signext %11) #8
  %108 = load i8, i8* %26, align 1
  %109 = sext i8 %108 to i32
  %110 = icmp slt i8 %108, 0
  br i1 %110, label %111, label %130

111:                                              ; preds = %107
  %112 = sub nsw i32 0, %109
  %113 = xor i32 %109, -1
  %114 = shl i32 1, %113
  %115 = trunc i32 %114 to i16
  %116 = insertelement <8 x i16> undef, i16 %115, i32 0
  %117 = shufflevector <8 x i16> %116, <8 x i16> undef, <8 x i32> zeroinitializer
  %118 = load <8 x i16>, <8 x i16>* %41, align 16
  %119 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %118, <8 x i16> %117) #8
  %120 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %119, i32 %112) #8
  store <8 x i16> %120, <8 x i16>* %41, align 16
  %121 = load <8 x i16>, <8 x i16>* %29, align 16
  %122 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %121, <8 x i16> %117) #8
  %123 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %122, i32 %112) #8
  store <8 x i16> %123, <8 x i16>* %29, align 16
  %124 = load <8 x i16>, <8 x i16>* %31, align 16
  %125 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %124, <8 x i16> %117) #8
  %126 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %125, i32 %112) #8
  store <8 x i16> %126, <8 x i16>* %31, align 16
  %127 = load <8 x i16>, <8 x i16>* %33, align 16
  %128 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %127, <8 x i16> %117) #8
  %129 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %128, i32 %112) #8
  store <8 x i16> %129, <8 x i16>* %33, align 16
  br label %146

130:                                              ; preds = %107
  %131 = icmp eq i8 %108, 0
  br i1 %131, label %132, label %137

132:                                              ; preds = %130
  %133 = load <8 x i16>, <8 x i16>* %27, align 16
  %134 = load <8 x i16>, <8 x i16>* %29, align 16
  %135 = load <8 x i16>, <8 x i16>* %31, align 16
  %136 = load <8 x i16>, <8 x i16>* %33, align 16
  br label %146

137:                                              ; preds = %130
  %138 = load <8 x i16>, <8 x i16>* %40, align 16
  %139 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %138, i32 %109) #8
  store <8 x i16> %139, <8 x i16>* %40, align 16
  %140 = load <8 x i16>, <8 x i16>* %29, align 16
  %141 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %140, i32 %109) #8
  store <8 x i16> %141, <8 x i16>* %29, align 16
  %142 = load <8 x i16>, <8 x i16>* %31, align 16
  %143 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %142, i32 %109) #8
  store <8 x i16> %143, <8 x i16>* %31, align 16
  %144 = load <8 x i16>, <8 x i16>* %33, align 16
  %145 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %144, i32 %109) #8
  store <8 x i16> %145, <8 x i16>* %33, align 16
  br label %146

146:                                              ; preds = %132, %137, %111
  %147 = phi <8 x i16> [ %136, %132 ], [ %145, %137 ], [ %129, %111 ]
  %148 = phi <8 x i16> [ %135, %132 ], [ %143, %137 ], [ %126, %111 ]
  %149 = phi <8 x i16> [ %134, %132 ], [ %141, %137 ], [ %123, %111 ]
  %150 = phi <8 x i16> [ %133, %132 ], [ %139, %137 ], [ %120, %111 ]
  %151 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 %47
  %152 = shufflevector <8 x i16> %150, <8 x i16> %149, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %153 = shufflevector <8 x i16> %148, <8 x i16> %147, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %154 = shufflevector <8 x i16> %150, <8 x i16> %149, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %155 = shufflevector <8 x i16> %148, <8 x i16> %147, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %156 = bitcast <8 x i16> %152 to <4 x i32>
  %157 = bitcast <8 x i16> %153 to <4 x i32>
  %158 = shufflevector <4 x i32> %156, <4 x i32> %157, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %159 = bitcast <4 x i32> %158 to <2 x i64>
  %160 = bitcast <8 x i16> %154 to <4 x i32>
  %161 = bitcast <8 x i16> %155 to <4 x i32>
  %162 = shufflevector <4 x i32> %160, <4 x i32> %161, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %163 = bitcast <4 x i32> %162 to <2 x i64>
  %164 = shufflevector <4 x i32> %156, <4 x i32> %157, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %165 = bitcast <4 x i32> %164 to <2 x i64>
  %166 = shufflevector <4 x i32> %160, <4 x i32> %161, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %167 = bitcast <4 x i32> %166 to <2 x i64>
  %168 = insertelement <2 x i64> %159, i64 0, i32 1
  store <2 x i64> %168, <2 x i64>* %151, align 16
  %169 = shufflevector <2 x i64> %159, <2 x i64> <i64 undef, i64 0>, <2 x i32> <i32 1, i32 3>
  %170 = getelementptr inbounds <2 x i64>, <2 x i64>* %151, i64 1
  store <2 x i64> %169, <2 x i64>* %170, align 16
  %171 = insertelement <2 x i64> %165, i64 0, i32 1
  %172 = getelementptr inbounds <2 x i64>, <2 x i64>* %151, i64 2
  store <2 x i64> %171, <2 x i64>* %172, align 16
  %173 = shufflevector <2 x i64> %165, <2 x i64> <i64 undef, i64 0>, <2 x i32> <i32 1, i32 3>
  %174 = getelementptr inbounds <2 x i64>, <2 x i64>* %151, i64 3
  store <2 x i64> %173, <2 x i64>* %174, align 16
  %175 = insertelement <2 x i64> %163, i64 0, i32 1
  %176 = getelementptr inbounds <2 x i64>, <2 x i64>* %151, i64 4
  store <2 x i64> %175, <2 x i64>* %176, align 16
  %177 = shufflevector <2 x i64> %163, <2 x i64> <i64 undef, i64 0>, <2 x i32> <i32 1, i32 3>
  %178 = getelementptr inbounds <2 x i64>, <2 x i64>* %151, i64 5
  store <2 x i64> %177, <2 x i64>* %178, align 16
  %179 = insertelement <2 x i64> %167, i64 0, i32 1
  %180 = getelementptr inbounds <2 x i64>, <2 x i64>* %151, i64 6
  store <2 x i64> %179, <2 x i64>* %180, align 16
  %181 = shufflevector <2 x i64> %167, <2 x i64> <i64 undef, i64 0>, <2 x i32> <i32 1, i32 3>
  %182 = getelementptr inbounds <2 x i64>, <2 x i64>* %151, i64 7
  store <2 x i64> %181, <2 x i64>* %182, align 16
  %183 = add nuw nsw i64 %46, 1
  %184 = icmp eq i64 %183, 2
  br i1 %184, label %42, label %45

185:                                              ; preds = %42
  %186 = load <2 x i64>, <2 x i64>* %44, align 16
  %187 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 15
  store <2 x i64> %186, <2 x i64>* %187, align 16
  %188 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 1
  %189 = load <2 x i64>, <2 x i64>* %188, align 16
  %190 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 14
  store <2 x i64> %189, <2 x i64>* %190, align 16
  %191 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 2
  %192 = load <2 x i64>, <2 x i64>* %191, align 16
  %193 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 13
  store <2 x i64> %192, <2 x i64>* %193, align 16
  %194 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 3
  %195 = load <2 x i64>, <2 x i64>* %194, align 16
  %196 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 12
  store <2 x i64> %195, <2 x i64>* %196, align 16
  %197 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 4
  %198 = load <2 x i64>, <2 x i64>* %197, align 16
  %199 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 11
  store <2 x i64> %198, <2 x i64>* %199, align 16
  %200 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 5
  %201 = load <2 x i64>, <2 x i64>* %200, align 16
  %202 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 10
  store <2 x i64> %201, <2 x i64>* %202, align 16
  %203 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 6
  %204 = load <2 x i64>, <2 x i64>* %203, align 16
  %205 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 9
  store <2 x i64> %204, <2 x i64>* %205, align 16
  %206 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 7
  %207 = load <2 x i64>, <2 x i64>* %206, align 16
  %208 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 8
  store <2 x i64> %207, <2 x i64>* %208, align 16
  %209 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 8
  %210 = load <2 x i64>, <2 x i64>* %209, align 16
  %211 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 7
  store <2 x i64> %210, <2 x i64>* %211, align 16
  %212 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 9
  %213 = load <2 x i64>, <2 x i64>* %212, align 16
  %214 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 6
  store <2 x i64> %213, <2 x i64>* %214, align 16
  %215 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 10
  %216 = load <2 x i64>, <2 x i64>* %215, align 16
  %217 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 5
  store <2 x i64> %216, <2 x i64>* %217, align 16
  %218 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 11
  %219 = load <2 x i64>, <2 x i64>* %218, align 16
  %220 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 4
  store <2 x i64> %219, <2 x i64>* %220, align 16
  %221 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 12
  %222 = load <2 x i64>, <2 x i64>* %221, align 16
  store <2 x i64> %222, <2 x i64>* %32, align 16
  %223 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 13
  %224 = load <2 x i64>, <2 x i64>* %223, align 16
  store <2 x i64> %224, <2 x i64>* %30, align 16
  %225 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 14
  %226 = load <2 x i64>, <2 x i64>* %225, align 16
  store <2 x i64> %226, <2 x i64>* %28, align 16
  %227 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 15
  %228 = load <2 x i64>, <2 x i64>* %227, align 16
  store <2 x i64> %228, <2 x i64>* %24, align 16
  br label %229

229:                                              ; preds = %42, %185
  %230 = phi <2 x i64>* [ %24, %185 ], [ %44, %42 ]
  call void %17(<2 x i64>* %230, <2 x i64>* %230, i8 signext %12) #8
  %231 = getelementptr inbounds i8, i8* %10, i64 2
  %232 = load i8, i8* %231, align 1
  %233 = sext i8 %232 to i32
  %234 = icmp slt i8 %232, 0
  br i1 %234, label %235, label %321

235:                                              ; preds = %229
  %236 = sub nsw i32 0, %233
  %237 = xor i32 %233, -1
  %238 = shl i32 1, %237
  %239 = trunc i32 %238 to i16
  %240 = insertelement <8 x i16> undef, i16 %239, i32 0
  %241 = shufflevector <8 x i16> %240, <8 x i16> undef, <8 x i32> zeroinitializer
  %242 = bitcast <2 x i64>* %230 to <8 x i16>*
  %243 = load <8 x i16>, <8 x i16>* %242, align 16
  %244 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %243, <8 x i16> %241) #8
  %245 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %244, i32 %236) #8
  store <8 x i16> %245, <8 x i16>* %242, align 16
  %246 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 1
  %247 = bitcast <2 x i64>* %246 to <8 x i16>*
  %248 = load <8 x i16>, <8 x i16>* %247, align 16
  %249 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %248, <8 x i16> %241) #8
  %250 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %249, i32 %236) #8
  store <8 x i16> %250, <8 x i16>* %247, align 16
  %251 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 2
  %252 = bitcast <2 x i64>* %251 to <8 x i16>*
  %253 = load <8 x i16>, <8 x i16>* %252, align 16
  %254 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %253, <8 x i16> %241) #8
  %255 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %254, i32 %236) #8
  store <8 x i16> %255, <8 x i16>* %252, align 16
  %256 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 3
  %257 = bitcast <2 x i64>* %256 to <8 x i16>*
  %258 = load <8 x i16>, <8 x i16>* %257, align 16
  %259 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %258, <8 x i16> %241) #8
  %260 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %259, i32 %236) #8
  store <8 x i16> %260, <8 x i16>* %257, align 16
  %261 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 4
  %262 = bitcast <2 x i64>* %261 to <8 x i16>*
  %263 = load <8 x i16>, <8 x i16>* %262, align 16
  %264 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %263, <8 x i16> %241) #8
  %265 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %264, i32 %236) #8
  store <8 x i16> %265, <8 x i16>* %262, align 16
  %266 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 5
  %267 = bitcast <2 x i64>* %266 to <8 x i16>*
  %268 = load <8 x i16>, <8 x i16>* %267, align 16
  %269 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %268, <8 x i16> %241) #8
  %270 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %269, i32 %236) #8
  store <8 x i16> %270, <8 x i16>* %267, align 16
  %271 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 6
  %272 = bitcast <2 x i64>* %271 to <8 x i16>*
  %273 = load <8 x i16>, <8 x i16>* %272, align 16
  %274 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %273, <8 x i16> %241) #8
  %275 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %274, i32 %236) #8
  store <8 x i16> %275, <8 x i16>* %272, align 16
  %276 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 7
  %277 = bitcast <2 x i64>* %276 to <8 x i16>*
  %278 = load <8 x i16>, <8 x i16>* %277, align 16
  %279 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %278, <8 x i16> %241) #8
  %280 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %279, i32 %236) #8
  store <8 x i16> %280, <8 x i16>* %277, align 16
  %281 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 8
  %282 = bitcast <2 x i64>* %281 to <8 x i16>*
  %283 = load <8 x i16>, <8 x i16>* %282, align 16
  %284 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %283, <8 x i16> %241) #8
  %285 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %284, i32 %236) #8
  store <8 x i16> %285, <8 x i16>* %282, align 16
  %286 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 9
  %287 = bitcast <2 x i64>* %286 to <8 x i16>*
  %288 = load <8 x i16>, <8 x i16>* %287, align 16
  %289 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %288, <8 x i16> %241) #8
  %290 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %289, i32 %236) #8
  store <8 x i16> %290, <8 x i16>* %287, align 16
  %291 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 10
  %292 = bitcast <2 x i64>* %291 to <8 x i16>*
  %293 = load <8 x i16>, <8 x i16>* %292, align 16
  %294 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %293, <8 x i16> %241) #8
  %295 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %294, i32 %236) #8
  store <8 x i16> %295, <8 x i16>* %292, align 16
  %296 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 11
  %297 = bitcast <2 x i64>* %296 to <8 x i16>*
  %298 = load <8 x i16>, <8 x i16>* %297, align 16
  %299 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %298, <8 x i16> %241) #8
  %300 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %299, i32 %236) #8
  store <8 x i16> %300, <8 x i16>* %297, align 16
  %301 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 12
  %302 = bitcast <2 x i64>* %301 to <8 x i16>*
  %303 = load <8 x i16>, <8 x i16>* %302, align 16
  %304 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %303, <8 x i16> %241) #8
  %305 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %304, i32 %236) #8
  store <8 x i16> %305, <8 x i16>* %302, align 16
  %306 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 13
  %307 = bitcast <2 x i64>* %306 to <8 x i16>*
  %308 = load <8 x i16>, <8 x i16>* %307, align 16
  %309 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %308, <8 x i16> %241) #8
  %310 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %309, i32 %236) #8
  store <8 x i16> %310, <8 x i16>* %307, align 16
  %311 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 14
  %312 = bitcast <2 x i64>* %311 to <8 x i16>*
  %313 = load <8 x i16>, <8 x i16>* %312, align 16
  %314 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %313, <8 x i16> %241) #8
  %315 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %314, i32 %236) #8
  store <8 x i16> %315, <8 x i16>* %312, align 16
  %316 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 15
  %317 = bitcast <2 x i64>* %316 to <8 x i16>*
  %318 = load <8 x i16>, <8 x i16>* %317, align 16
  %319 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %318, <8 x i16> %241) #8
  %320 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %319, i32 %236) #8
  store <8 x i16> %320, <8 x i16>* %317, align 16
  br label %409

321:                                              ; preds = %229
  %322 = icmp eq i8 %232, 0
  %323 = bitcast <2 x i64>* %230 to <8 x i16>*
  %324 = load <8 x i16>, <8 x i16>* %323, align 16
  br i1 %322, label %325, label %347

325:                                              ; preds = %321
  %326 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 1
  %327 = bitcast <2 x i64>* %326 to <8 x i16>*
  %328 = load <8 x i16>, <8 x i16>* %327, align 16
  %329 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 2
  %330 = bitcast <2 x i64>* %329 to <8 x i16>*
  %331 = load <8 x i16>, <8 x i16>* %330, align 16
  %332 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 3
  %333 = bitcast <2 x i64>* %332 to <8 x i16>*
  %334 = load <8 x i16>, <8 x i16>* %333, align 16
  %335 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 4
  %336 = bitcast <2 x i64>* %335 to <8 x i16>*
  %337 = load <8 x i16>, <8 x i16>* %336, align 16
  %338 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 5
  %339 = bitcast <2 x i64>* %338 to <8 x i16>*
  %340 = load <8 x i16>, <8 x i16>* %339, align 16
  %341 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 6
  %342 = bitcast <2 x i64>* %341 to <8 x i16>*
  %343 = load <8 x i16>, <8 x i16>* %342, align 16
  %344 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 7
  %345 = bitcast <2 x i64>* %344 to <8 x i16>*
  %346 = load <8 x i16>, <8 x i16>* %345, align 16
  br label %409

347:                                              ; preds = %321
  %348 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %324, i32 %233) #8
  store <8 x i16> %348, <8 x i16>* %323, align 16
  %349 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 1
  %350 = bitcast <2 x i64>* %349 to <8 x i16>*
  %351 = load <8 x i16>, <8 x i16>* %350, align 16
  %352 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %351, i32 %233) #8
  store <8 x i16> %352, <8 x i16>* %350, align 16
  %353 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 2
  %354 = bitcast <2 x i64>* %353 to <8 x i16>*
  %355 = load <8 x i16>, <8 x i16>* %354, align 16
  %356 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %355, i32 %233) #8
  store <8 x i16> %356, <8 x i16>* %354, align 16
  %357 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 3
  %358 = bitcast <2 x i64>* %357 to <8 x i16>*
  %359 = load <8 x i16>, <8 x i16>* %358, align 16
  %360 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %359, i32 %233) #8
  store <8 x i16> %360, <8 x i16>* %358, align 16
  %361 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 4
  %362 = bitcast <2 x i64>* %361 to <8 x i16>*
  %363 = load <8 x i16>, <8 x i16>* %362, align 16
  %364 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %363, i32 %233) #8
  store <8 x i16> %364, <8 x i16>* %362, align 16
  %365 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 5
  %366 = bitcast <2 x i64>* %365 to <8 x i16>*
  %367 = load <8 x i16>, <8 x i16>* %366, align 16
  %368 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %367, i32 %233) #8
  store <8 x i16> %368, <8 x i16>* %366, align 16
  %369 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 6
  %370 = bitcast <2 x i64>* %369 to <8 x i16>*
  %371 = load <8 x i16>, <8 x i16>* %370, align 16
  %372 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %371, i32 %233) #8
  store <8 x i16> %372, <8 x i16>* %370, align 16
  %373 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 7
  %374 = bitcast <2 x i64>* %373 to <8 x i16>*
  %375 = load <8 x i16>, <8 x i16>* %374, align 16
  %376 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %375, i32 %233) #8
  store <8 x i16> %376, <8 x i16>* %374, align 16
  %377 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 8
  %378 = bitcast <2 x i64>* %377 to <8 x i16>*
  %379 = load <8 x i16>, <8 x i16>* %378, align 16
  %380 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %379, i32 %233) #8
  store <8 x i16> %380, <8 x i16>* %378, align 16
  %381 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 9
  %382 = bitcast <2 x i64>* %381 to <8 x i16>*
  %383 = load <8 x i16>, <8 x i16>* %382, align 16
  %384 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %383, i32 %233) #8
  store <8 x i16> %384, <8 x i16>* %382, align 16
  %385 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 10
  %386 = bitcast <2 x i64>* %385 to <8 x i16>*
  %387 = load <8 x i16>, <8 x i16>* %386, align 16
  %388 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %387, i32 %233) #8
  store <8 x i16> %388, <8 x i16>* %386, align 16
  %389 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 11
  %390 = bitcast <2 x i64>* %389 to <8 x i16>*
  %391 = load <8 x i16>, <8 x i16>* %390, align 16
  %392 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %391, i32 %233) #8
  store <8 x i16> %392, <8 x i16>* %390, align 16
  %393 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 12
  %394 = bitcast <2 x i64>* %393 to <8 x i16>*
  %395 = load <8 x i16>, <8 x i16>* %394, align 16
  %396 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %395, i32 %233) #8
  store <8 x i16> %396, <8 x i16>* %394, align 16
  %397 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 13
  %398 = bitcast <2 x i64>* %397 to <8 x i16>*
  %399 = load <8 x i16>, <8 x i16>* %398, align 16
  %400 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %399, i32 %233) #8
  store <8 x i16> %400, <8 x i16>* %398, align 16
  %401 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 14
  %402 = bitcast <2 x i64>* %401 to <8 x i16>*
  %403 = load <8 x i16>, <8 x i16>* %402, align 16
  %404 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %403, i32 %233) #8
  store <8 x i16> %404, <8 x i16>* %402, align 16
  %405 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 15
  %406 = bitcast <2 x i64>* %405 to <8 x i16>*
  %407 = load <8 x i16>, <8 x i16>* %406, align 16
  %408 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %407, i32 %233) #8
  store <8 x i16> %408, <8 x i16>* %406, align 16
  br label %409

409:                                              ; preds = %325, %347, %235
  %410 = phi <8 x i16> [ %346, %325 ], [ %376, %347 ], [ %280, %235 ]
  %411 = phi <8 x i16> [ %343, %325 ], [ %372, %347 ], [ %275, %235 ]
  %412 = phi <8 x i16> [ %340, %325 ], [ %368, %347 ], [ %270, %235 ]
  %413 = phi <8 x i16> [ %337, %325 ], [ %364, %347 ], [ %265, %235 ]
  %414 = phi <8 x i16> [ %334, %325 ], [ %360, %347 ], [ %260, %235 ]
  %415 = phi <8 x i16> [ %331, %325 ], [ %356, %347 ], [ %255, %235 ]
  %416 = phi <8 x i16> [ %328, %325 ], [ %352, %347 ], [ %250, %235 ]
  %417 = phi <8 x i16> [ %324, %325 ], [ %348, %347 ], [ %245, %235 ]
  %418 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 1
  %419 = shufflevector <8 x i16> %417, <8 x i16> %416, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %420 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 2
  %421 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 3
  %422 = shufflevector <8 x i16> %415, <8 x i16> %414, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %423 = shufflevector <8 x i16> %413, <8 x i16> %412, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %424 = shufflevector <8 x i16> %411, <8 x i16> %410, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %425 = bitcast <8 x i16> %419 to <4 x i32>
  %426 = bitcast <8 x i16> %422 to <4 x i32>
  %427 = shufflevector <4 x i32> %425, <4 x i32> %426, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %428 = bitcast <4 x i32> %427 to <2 x i64>
  %429 = bitcast <8 x i16> %423 to <4 x i32>
  %430 = bitcast <8 x i16> %424 to <4 x i32>
  %431 = shufflevector <4 x i32> %429, <4 x i32> %430, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %432 = bitcast <4 x i32> %431 to <2 x i64>
  %433 = shufflevector <4 x i32> %425, <4 x i32> %426, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %434 = bitcast <4 x i32> %433 to <2 x i64>
  %435 = shufflevector <4 x i32> %429, <4 x i32> %430, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %436 = bitcast <4 x i32> %435 to <2 x i64>
  %437 = shufflevector <2 x i64> %428, <2 x i64> %432, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %437, <2 x i64>* %230, align 16
  %438 = shufflevector <2 x i64> %428, <2 x i64> %432, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %438, <2 x i64>* %418, align 16
  %439 = shufflevector <2 x i64> %434, <2 x i64> %436, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %439, <2 x i64>* %420, align 16
  %440 = shufflevector <2 x i64> %434, <2 x i64> %436, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %440, <2 x i64>* %421, align 16
  %441 = bitcast <2 x i64> %437 to <8 x i16>
  %442 = shufflevector <8 x i16> %441, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %443 = shufflevector <8 x i16> %441, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %444 = bitcast <8 x i16> %442 to <4 x i32>
  %445 = ashr <4 x i32> %444, <i32 16, i32 16, i32 16, i32 16>
  %446 = bitcast <8 x i16> %443 to <4 x i32>
  %447 = ashr <4 x i32> %446, <i32 16, i32 16, i32 16, i32 16>
  %448 = bitcast i32* %1 to <4 x i32>*
  store <4 x i32> %445, <4 x i32>* %448, align 16
  %449 = getelementptr inbounds i32, i32* %1, i64 4
  %450 = bitcast i32* %449 to <4 x i32>*
  store <4 x i32> %447, <4 x i32>* %450, align 16
  %451 = bitcast <2 x i64> %438 to <8 x i16>
  %452 = getelementptr inbounds i32, i32* %1, i64 16
  %453 = shufflevector <8 x i16> %451, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %454 = shufflevector <8 x i16> %451, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %455 = bitcast <8 x i16> %453 to <4 x i32>
  %456 = ashr <4 x i32> %455, <i32 16, i32 16, i32 16, i32 16>
  %457 = bitcast <8 x i16> %454 to <4 x i32>
  %458 = ashr <4 x i32> %457, <i32 16, i32 16, i32 16, i32 16>
  %459 = bitcast i32* %452 to <4 x i32>*
  store <4 x i32> %456, <4 x i32>* %459, align 16
  %460 = getelementptr inbounds i32, i32* %1, i64 20
  %461 = bitcast i32* %460 to <4 x i32>*
  store <4 x i32> %458, <4 x i32>* %461, align 16
  %462 = bitcast <2 x i64> %439 to <8 x i16>
  %463 = getelementptr inbounds i32, i32* %1, i64 32
  %464 = shufflevector <8 x i16> %462, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %465 = shufflevector <8 x i16> %462, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %466 = bitcast <8 x i16> %464 to <4 x i32>
  %467 = ashr <4 x i32> %466, <i32 16, i32 16, i32 16, i32 16>
  %468 = bitcast <8 x i16> %465 to <4 x i32>
  %469 = ashr <4 x i32> %468, <i32 16, i32 16, i32 16, i32 16>
  %470 = bitcast i32* %463 to <4 x i32>*
  store <4 x i32> %467, <4 x i32>* %470, align 16
  %471 = getelementptr inbounds i32, i32* %1, i64 36
  %472 = bitcast i32* %471 to <4 x i32>*
  store <4 x i32> %469, <4 x i32>* %472, align 16
  %473 = bitcast <2 x i64> %440 to <8 x i16>
  %474 = getelementptr inbounds i32, i32* %1, i64 48
  %475 = shufflevector <8 x i16> %473, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %476 = shufflevector <8 x i16> %473, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %477 = bitcast <8 x i16> %475 to <4 x i32>
  %478 = ashr <4 x i32> %477, <i32 16, i32 16, i32 16, i32 16>
  %479 = bitcast <8 x i16> %476 to <4 x i32>
  %480 = ashr <4 x i32> %479, <i32 16, i32 16, i32 16, i32 16>
  %481 = bitcast i32* %474 to <4 x i32>*
  store <4 x i32> %478, <4 x i32>* %481, align 16
  %482 = getelementptr inbounds i32, i32* %1, i64 52
  %483 = bitcast i32* %482 to <4 x i32>*
  store <4 x i32> %480, <4 x i32>* %483, align 16
  %484 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 8
  %485 = bitcast <2 x i64>* %484 to <8 x i16>*
  %486 = load <8 x i16>, <8 x i16>* %485, align 16
  %487 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 9
  %488 = bitcast <2 x i64>* %487 to <8 x i16>*
  %489 = load <8 x i16>, <8 x i16>* %488, align 16
  %490 = shufflevector <8 x i16> %486, <8 x i16> %489, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %491 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 10
  %492 = bitcast <2 x i64>* %491 to <8 x i16>*
  %493 = load <8 x i16>, <8 x i16>* %492, align 16
  %494 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 11
  %495 = bitcast <2 x i64>* %494 to <8 x i16>*
  %496 = load <8 x i16>, <8 x i16>* %495, align 16
  %497 = shufflevector <8 x i16> %493, <8 x i16> %496, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %498 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 12
  %499 = bitcast <2 x i64>* %498 to <8 x i16>*
  %500 = load <8 x i16>, <8 x i16>* %499, align 16
  %501 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 13
  %502 = bitcast <2 x i64>* %501 to <8 x i16>*
  %503 = load <8 x i16>, <8 x i16>* %502, align 16
  %504 = shufflevector <8 x i16> %500, <8 x i16> %503, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %505 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 14
  %506 = bitcast <2 x i64>* %505 to <8 x i16>*
  %507 = load <8 x i16>, <8 x i16>* %506, align 16
  %508 = getelementptr inbounds <2 x i64>, <2 x i64>* %230, i64 15
  %509 = bitcast <2 x i64>* %508 to <8 x i16>*
  %510 = load <8 x i16>, <8 x i16>* %509, align 16
  %511 = shufflevector <8 x i16> %507, <8 x i16> %510, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %512 = bitcast <8 x i16> %490 to <4 x i32>
  %513 = bitcast <8 x i16> %497 to <4 x i32>
  %514 = shufflevector <4 x i32> %512, <4 x i32> %513, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %515 = bitcast <4 x i32> %514 to <2 x i64>
  %516 = bitcast <8 x i16> %504 to <4 x i32>
  %517 = bitcast <8 x i16> %511 to <4 x i32>
  %518 = shufflevector <4 x i32> %516, <4 x i32> %517, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %519 = bitcast <4 x i32> %518 to <2 x i64>
  %520 = shufflevector <4 x i32> %512, <4 x i32> %513, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %521 = bitcast <4 x i32> %520 to <2 x i64>
  %522 = shufflevector <4 x i32> %516, <4 x i32> %517, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %523 = bitcast <4 x i32> %522 to <2 x i64>
  %524 = shufflevector <2 x i64> %515, <2 x i64> %519, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %524, <2 x i64>* %484, align 16
  %525 = shufflevector <2 x i64> %515, <2 x i64> %519, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %525, <2 x i64>* %487, align 16
  %526 = shufflevector <2 x i64> %521, <2 x i64> %523, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %526, <2 x i64>* %491, align 16
  %527 = shufflevector <2 x i64> %521, <2 x i64> %523, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %527, <2 x i64>* %494, align 16
  %528 = getelementptr inbounds i32, i32* %1, i64 8
  %529 = bitcast <2 x i64> %524 to <8 x i16>
  %530 = shufflevector <8 x i16> %529, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %531 = shufflevector <8 x i16> %529, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %532 = bitcast <8 x i16> %530 to <4 x i32>
  %533 = ashr <4 x i32> %532, <i32 16, i32 16, i32 16, i32 16>
  %534 = bitcast <8 x i16> %531 to <4 x i32>
  %535 = ashr <4 x i32> %534, <i32 16, i32 16, i32 16, i32 16>
  %536 = bitcast i32* %528 to <4 x i32>*
  store <4 x i32> %533, <4 x i32>* %536, align 16
  %537 = getelementptr inbounds i32, i32* %1, i64 12
  %538 = bitcast i32* %537 to <4 x i32>*
  store <4 x i32> %535, <4 x i32>* %538, align 16
  %539 = bitcast <2 x i64> %525 to <8 x i16>
  %540 = getelementptr inbounds i32, i32* %1, i64 24
  %541 = shufflevector <8 x i16> %539, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %542 = shufflevector <8 x i16> %539, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %543 = bitcast <8 x i16> %541 to <4 x i32>
  %544 = ashr <4 x i32> %543, <i32 16, i32 16, i32 16, i32 16>
  %545 = bitcast <8 x i16> %542 to <4 x i32>
  %546 = ashr <4 x i32> %545, <i32 16, i32 16, i32 16, i32 16>
  %547 = bitcast i32* %540 to <4 x i32>*
  store <4 x i32> %544, <4 x i32>* %547, align 16
  %548 = getelementptr inbounds i32, i32* %1, i64 28
  %549 = bitcast i32* %548 to <4 x i32>*
  store <4 x i32> %546, <4 x i32>* %549, align 16
  %550 = bitcast <2 x i64> %526 to <8 x i16>
  %551 = getelementptr inbounds i32, i32* %1, i64 40
  %552 = shufflevector <8 x i16> %550, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %553 = shufflevector <8 x i16> %550, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %554 = bitcast <8 x i16> %552 to <4 x i32>
  %555 = ashr <4 x i32> %554, <i32 16, i32 16, i32 16, i32 16>
  %556 = bitcast <8 x i16> %553 to <4 x i32>
  %557 = ashr <4 x i32> %556, <i32 16, i32 16, i32 16, i32 16>
  %558 = bitcast i32* %551 to <4 x i32>*
  store <4 x i32> %555, <4 x i32>* %558, align 16
  %559 = getelementptr inbounds i32, i32* %1, i64 44
  %560 = bitcast i32* %559 to <4 x i32>*
  store <4 x i32> %557, <4 x i32>* %560, align 16
  %561 = bitcast <2 x i64> %527 to <8 x i16>
  %562 = getelementptr inbounds i32, i32* %1, i64 56
  %563 = shufflevector <8 x i16> %561, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %564 = shufflevector <8 x i16> %561, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %565 = bitcast <8 x i16> %563 to <4 x i32>
  %566 = ashr <4 x i32> %565, <i32 16, i32 16, i32 16, i32 16>
  %567 = bitcast <8 x i16> %564 to <4 x i32>
  %568 = ashr <4 x i32> %567, <i32 16, i32 16, i32 16, i32 16>
  %569 = bitcast i32* %562 to <4 x i32>*
  store <4 x i32> %566, <4 x i32>* %569, align 16
  %570 = getelementptr inbounds i32, i32* %1, i64 60
  %571 = bitcast i32* %570 to <4 x i32>*
  store <4 x i32> %568, <4 x i32>* %571, align 16
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %9) #8
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %8) #8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @av1_lowbd_fwd_txfm2d_16x8_sse2(i16* nocapture readonly, i32* nocapture, i32, i8 zeroext, i32) #2 {
  %6 = alloca [16 x <2 x i64>], align 16
  %7 = alloca [16 x <2 x i64>], align 16
  %8 = bitcast [16 x <2 x i64>]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %8) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %8, i8 -86, i64 256, i1 false)
  %9 = bitcast [16 x <2 x i64>]* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %9) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 256, i1 false)
  %10 = load i8*, i8** getelementptr inbounds ([19 x i8*], [19 x i8*]* @av1_fwd_txfm_shift_ls, i64 0, i64 8), align 16
  %11 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_fwd_cos_bit_col, i64 0, i64 2, i64 1), align 1
  %12 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_fwd_cos_bit_row, i64 0, i64 2, i64 1), align 1
  %13 = zext i8 %3 to i64
  %14 = getelementptr inbounds [16 x void (<2 x i64>*, <2 x i64>*, i8)*], [16 x void (<2 x i64>*, <2 x i64>*, i8)*]* @col_txfm8x8_arr, i64 0, i64 %13
  %15 = load void (<2 x i64>*, <2 x i64>*, i8)*, void (<2 x i64>*, <2 x i64>*, i8)** %14, align 8
  %16 = getelementptr inbounds [16 x void (<2 x i64>*, <2 x i64>*, i8)*], [16 x void (<2 x i64>*, <2 x i64>*, i8)*]* @row_txfm8x16_arr, i64 0, i64 %13
  %17 = load void (<2 x i64>*, <2 x i64>*, i8)*, void (<2 x i64>*, <2 x i64>*, i8)** %16, align 8
  switch i8 %3, label %21 [
    i8 6, label %20
    i8 15, label %19
    i8 7, label %19
    i8 5, label %19
    i8 14, label %18
    i8 8, label %18
    i8 4, label %18
  ]

18:                                               ; preds = %5, %5, %5
  br label %21

19:                                               ; preds = %5, %5, %5
  br label %21

20:                                               ; preds = %5
  br label %21

21:                                               ; preds = %5, %18, %19, %20
  %22 = phi i1 [ false, %20 ], [ true, %19 ], [ false, %18 ], [ true, %5 ]
  %23 = phi i32 [ 1, %20 ], [ 1, %19 ], [ 0, %18 ], [ 0, %5 ]
  %24 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 0
  %25 = sext i32 %2 to i64
  %26 = getelementptr inbounds i8, i8* %10, i64 1
  %27 = bitcast [16 x <2 x i64>]* %6 to <8 x i16>*
  %28 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 1
  %29 = bitcast <2 x i64>* %28 to <8 x i16>*
  %30 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 2
  %31 = bitcast <2 x i64>* %30 to <8 x i16>*
  %32 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 3
  %33 = bitcast <2 x i64>* %32 to <8 x i16>*
  %34 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 4
  %35 = bitcast <2 x i64>* %34 to <8 x i16>*
  %36 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 5
  %37 = bitcast <2 x i64>* %36 to <8 x i16>*
  %38 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 6
  %39 = bitcast <2 x i64>* %38 to <8 x i16>*
  %40 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 7
  %41 = bitcast <2 x i64>* %40 to <8 x i16>*
  %42 = shl nsw i64 %25, 1
  %43 = mul nsw i64 %25, 3
  %44 = shl nsw i64 %25, 2
  %45 = mul nsw i64 %25, 5
  %46 = mul nsw i64 %25, 6
  %47 = mul nsw i64 %25, 7
  %48 = shl nsw i64 %25, 1
  %49 = mul nsw i64 %25, 3
  %50 = shl nsw i64 %25, 2
  %51 = mul nsw i64 %25, 5
  %52 = mul nsw i64 %25, 6
  %53 = mul nsw i64 %25, 7
  %54 = bitcast [16 x <2 x i64>]* %6 to <8 x i16>*
  %55 = bitcast [16 x <2 x i64>]* %6 to <8 x i16>*
  %56 = bitcast [16 x <2 x i64>]* %6 to <8 x i16>*
  %57 = bitcast [16 x <2 x i64>]* %6 to <8 x i16>*
  br label %61

58:                                               ; preds = %230
  %59 = icmp eq i32 %23, 0
  %60 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 0
  br i1 %59, label %329, label %289

61:                                               ; preds = %230, %21
  %62 = phi i64 [ 0, %21 ], [ %287, %230 ]
  %63 = shl nsw i64 %62, 3
  %64 = getelementptr inbounds i16, i16* %0, i64 %63
  %65 = bitcast i16* %64 to <2 x i64>*
  %66 = load <2 x i64>, <2 x i64>* %65, align 16
  br i1 %22, label %89, label %67

67:                                               ; preds = %61
  store <2 x i64> %66, <2 x i64>* %40, align 16
  %68 = getelementptr inbounds i16, i16* %64, i64 %25
  %69 = bitcast i16* %68 to <2 x i64>*
  %70 = load <2 x i64>, <2 x i64>* %69, align 16
  store <2 x i64> %70, <2 x i64>* %38, align 16
  %71 = getelementptr inbounds i16, i16* %64, i64 %42
  %72 = bitcast i16* %71 to <2 x i64>*
  %73 = load <2 x i64>, <2 x i64>* %72, align 16
  store <2 x i64> %73, <2 x i64>* %36, align 16
  %74 = getelementptr inbounds i16, i16* %64, i64 %43
  %75 = bitcast i16* %74 to <2 x i64>*
  %76 = load <2 x i64>, <2 x i64>* %75, align 16
  store <2 x i64> %76, <2 x i64>* %34, align 16
  %77 = getelementptr inbounds i16, i16* %64, i64 %44
  %78 = bitcast i16* %77 to <2 x i64>*
  %79 = load <2 x i64>, <2 x i64>* %78, align 16
  store <2 x i64> %79, <2 x i64>* %32, align 16
  %80 = getelementptr inbounds i16, i16* %64, i64 %45
  %81 = bitcast i16* %80 to <2 x i64>*
  %82 = load <2 x i64>, <2 x i64>* %81, align 16
  store <2 x i64> %82, <2 x i64>* %30, align 16
  %83 = getelementptr inbounds i16, i16* %64, i64 %46
  %84 = bitcast i16* %83 to <2 x i64>*
  %85 = load <2 x i64>, <2 x i64>* %84, align 16
  store <2 x i64> %85, <2 x i64>* %28, align 16
  %86 = getelementptr inbounds i16, i16* %64, i64 %47
  %87 = bitcast i16* %86 to <2 x i64>*
  %88 = load <2 x i64>, <2 x i64>* %87, align 16
  store <2 x i64> %88, <2 x i64>* %24, align 16
  br label %111

89:                                               ; preds = %61
  store <2 x i64> %66, <2 x i64>* %24, align 16
  %90 = getelementptr inbounds i16, i16* %64, i64 %25
  %91 = bitcast i16* %90 to <2 x i64>*
  %92 = load <2 x i64>, <2 x i64>* %91, align 16
  store <2 x i64> %92, <2 x i64>* %28, align 16
  %93 = getelementptr inbounds i16, i16* %64, i64 %48
  %94 = bitcast i16* %93 to <2 x i64>*
  %95 = load <2 x i64>, <2 x i64>* %94, align 16
  store <2 x i64> %95, <2 x i64>* %30, align 16
  %96 = getelementptr inbounds i16, i16* %64, i64 %49
  %97 = bitcast i16* %96 to <2 x i64>*
  %98 = load <2 x i64>, <2 x i64>* %97, align 16
  store <2 x i64> %98, <2 x i64>* %32, align 16
  %99 = getelementptr inbounds i16, i16* %64, i64 %50
  %100 = bitcast i16* %99 to <2 x i64>*
  %101 = load <2 x i64>, <2 x i64>* %100, align 16
  store <2 x i64> %101, <2 x i64>* %34, align 16
  %102 = getelementptr inbounds i16, i16* %64, i64 %51
  %103 = bitcast i16* %102 to <2 x i64>*
  %104 = load <2 x i64>, <2 x i64>* %103, align 16
  store <2 x i64> %104, <2 x i64>* %36, align 16
  %105 = getelementptr inbounds i16, i16* %64, i64 %52
  %106 = bitcast i16* %105 to <2 x i64>*
  %107 = load <2 x i64>, <2 x i64>* %106, align 16
  store <2 x i64> %107, <2 x i64>* %38, align 16
  %108 = getelementptr inbounds i16, i16* %64, i64 %53
  %109 = bitcast i16* %108 to <2 x i64>*
  %110 = load <2 x i64>, <2 x i64>* %109, align 16
  store <2 x i64> %110, <2 x i64>* %40, align 16
  br label %111

111:                                              ; preds = %67, %89
  %112 = phi <2 x i64> [ %66, %67 ], [ %110, %89 ]
  %113 = phi <2 x i64> [ %70, %67 ], [ %107, %89 ]
  %114 = phi <2 x i64> [ %73, %67 ], [ %104, %89 ]
  %115 = phi <2 x i64> [ %76, %67 ], [ %101, %89 ]
  %116 = phi <2 x i64> [ %79, %67 ], [ %98, %89 ]
  %117 = phi <2 x i64> [ %82, %67 ], [ %95, %89 ]
  %118 = phi <2 x i64> [ %85, %67 ], [ %92, %89 ]
  %119 = phi <2 x i64> [ %88, %67 ], [ %66, %89 ]
  %120 = bitcast <2 x i64> %119 to <8 x i16>
  %121 = bitcast <2 x i64> %118 to <8 x i16>
  %122 = bitcast <2 x i64> %117 to <8 x i16>
  %123 = bitcast <2 x i64> %116 to <8 x i16>
  %124 = bitcast <2 x i64> %115 to <8 x i16>
  %125 = bitcast <2 x i64> %114 to <8 x i16>
  %126 = bitcast <2 x i64> %113 to <8 x i16>
  %127 = bitcast <2 x i64> %112 to <8 x i16>
  %128 = load i8, i8* %10, align 1
  %129 = sext i8 %128 to i32
  %130 = icmp slt i8 %128, 0
  br i1 %130, label %131, label %154

131:                                              ; preds = %111
  %132 = sub nsw i32 0, %129
  %133 = xor i32 %129, -1
  %134 = shl i32 1, %133
  %135 = trunc i32 %134 to i16
  %136 = insertelement <8 x i16> undef, i16 %135, i32 0
  %137 = shufflevector <8 x i16> %136, <8 x i16> undef, <8 x i32> zeroinitializer
  %138 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %120, <8 x i16> %137) #8
  %139 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %138, i32 %132) #8
  store <8 x i16> %139, <8 x i16>* %55, align 16
  %140 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %121, <8 x i16> %137) #8
  %141 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %140, i32 %132) #8
  store <8 x i16> %141, <8 x i16>* %29, align 16
  %142 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %122, <8 x i16> %137) #8
  %143 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %142, i32 %132) #8
  store <8 x i16> %143, <8 x i16>* %31, align 16
  %144 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %123, <8 x i16> %137) #8
  %145 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %144, i32 %132) #8
  store <8 x i16> %145, <8 x i16>* %33, align 16
  %146 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %124, <8 x i16> %137) #8
  %147 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %146, i32 %132) #8
  store <8 x i16> %147, <8 x i16>* %35, align 16
  %148 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %125, <8 x i16> %137) #8
  %149 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %148, i32 %132) #8
  store <8 x i16> %149, <8 x i16>* %37, align 16
  %150 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %126, <8 x i16> %137) #8
  %151 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %150, i32 %132) #8
  store <8 x i16> %151, <8 x i16>* %39, align 16
  %152 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %127, <8 x i16> %137) #8
  %153 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %152, i32 %132) #8
  br label %165

154:                                              ; preds = %111
  %155 = icmp eq i8 %128, 0
  br i1 %155, label %167, label %156

156:                                              ; preds = %154
  %157 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %120, i32 %129) #8
  store <8 x i16> %157, <8 x i16>* %54, align 16
  %158 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %121, i32 %129) #8
  store <8 x i16> %158, <8 x i16>* %29, align 16
  %159 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %122, i32 %129) #8
  store <8 x i16> %159, <8 x i16>* %31, align 16
  %160 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %123, i32 %129) #8
  store <8 x i16> %160, <8 x i16>* %33, align 16
  %161 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %124, i32 %129) #8
  store <8 x i16> %161, <8 x i16>* %35, align 16
  %162 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %125, i32 %129) #8
  store <8 x i16> %162, <8 x i16>* %37, align 16
  %163 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %126, i32 %129) #8
  store <8 x i16> %163, <8 x i16>* %39, align 16
  %164 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %127, i32 %129) #8
  br label %165

165:                                              ; preds = %131, %156
  %166 = phi <8 x i16> [ %164, %156 ], [ %153, %131 ]
  store <8 x i16> %166, <8 x i16>* %41, align 16
  br label %167

167:                                              ; preds = %165, %154
  call void %15(<2 x i64>* nonnull %24, <2 x i64>* nonnull %24, i8 signext %11) #8
  %168 = load i8, i8* %26, align 1
  %169 = sext i8 %168 to i32
  %170 = icmp slt i8 %168, 0
  br i1 %170, label %171, label %202

171:                                              ; preds = %167
  %172 = sub nsw i32 0, %169
  %173 = xor i32 %169, -1
  %174 = shl i32 1, %173
  %175 = trunc i32 %174 to i16
  %176 = insertelement <8 x i16> undef, i16 %175, i32 0
  %177 = shufflevector <8 x i16> %176, <8 x i16> undef, <8 x i32> zeroinitializer
  %178 = load <8 x i16>, <8 x i16>* %57, align 16
  %179 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %178, <8 x i16> %177) #8
  %180 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %179, i32 %172) #8
  store <8 x i16> %180, <8 x i16>* %57, align 16
  %181 = load <8 x i16>, <8 x i16>* %29, align 16
  %182 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %181, <8 x i16> %177) #8
  %183 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %182, i32 %172) #8
  store <8 x i16> %183, <8 x i16>* %29, align 16
  %184 = load <8 x i16>, <8 x i16>* %31, align 16
  %185 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %184, <8 x i16> %177) #8
  %186 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %185, i32 %172) #8
  store <8 x i16> %186, <8 x i16>* %31, align 16
  %187 = load <8 x i16>, <8 x i16>* %33, align 16
  %188 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %187, <8 x i16> %177) #8
  %189 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %188, i32 %172) #8
  store <8 x i16> %189, <8 x i16>* %33, align 16
  %190 = load <8 x i16>, <8 x i16>* %35, align 16
  %191 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %190, <8 x i16> %177) #8
  %192 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %191, i32 %172) #8
  store <8 x i16> %192, <8 x i16>* %35, align 16
  %193 = load <8 x i16>, <8 x i16>* %37, align 16
  %194 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %193, <8 x i16> %177) #8
  %195 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %194, i32 %172) #8
  store <8 x i16> %195, <8 x i16>* %37, align 16
  %196 = load <8 x i16>, <8 x i16>* %39, align 16
  %197 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %196, <8 x i16> %177) #8
  %198 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %197, i32 %172) #8
  store <8 x i16> %198, <8 x i16>* %39, align 16
  %199 = load <8 x i16>, <8 x i16>* %41, align 16
  %200 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %199, <8 x i16> %177) #8
  %201 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %200, i32 %172) #8
  store <8 x i16> %201, <8 x i16>* %41, align 16
  br label %230

202:                                              ; preds = %167
  %203 = icmp eq i8 %168, 0
  br i1 %203, label %204, label %213

204:                                              ; preds = %202
  %205 = load <8 x i16>, <8 x i16>* %27, align 16
  %206 = load <8 x i16>, <8 x i16>* %29, align 16
  %207 = load <8 x i16>, <8 x i16>* %31, align 16
  %208 = load <8 x i16>, <8 x i16>* %33, align 16
  %209 = load <8 x i16>, <8 x i16>* %35, align 16
  %210 = load <8 x i16>, <8 x i16>* %37, align 16
  %211 = load <8 x i16>, <8 x i16>* %39, align 16
  %212 = load <8 x i16>, <8 x i16>* %41, align 16
  br label %230

213:                                              ; preds = %202
  %214 = load <8 x i16>, <8 x i16>* %56, align 16
  %215 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %214, i32 %169) #8
  store <8 x i16> %215, <8 x i16>* %56, align 16
  %216 = load <8 x i16>, <8 x i16>* %29, align 16
  %217 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %216, i32 %169) #8
  store <8 x i16> %217, <8 x i16>* %29, align 16
  %218 = load <8 x i16>, <8 x i16>* %31, align 16
  %219 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %218, i32 %169) #8
  store <8 x i16> %219, <8 x i16>* %31, align 16
  %220 = load <8 x i16>, <8 x i16>* %33, align 16
  %221 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %220, i32 %169) #8
  store <8 x i16> %221, <8 x i16>* %33, align 16
  %222 = load <8 x i16>, <8 x i16>* %35, align 16
  %223 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %222, i32 %169) #8
  store <8 x i16> %223, <8 x i16>* %35, align 16
  %224 = load <8 x i16>, <8 x i16>* %37, align 16
  %225 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %224, i32 %169) #8
  store <8 x i16> %225, <8 x i16>* %37, align 16
  %226 = load <8 x i16>, <8 x i16>* %39, align 16
  %227 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %226, i32 %169) #8
  store <8 x i16> %227, <8 x i16>* %39, align 16
  %228 = load <8 x i16>, <8 x i16>* %41, align 16
  %229 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %228, i32 %169) #8
  store <8 x i16> %229, <8 x i16>* %41, align 16
  br label %230

230:                                              ; preds = %204, %213, %171
  %231 = phi <8 x i16> [ %212, %204 ], [ %229, %213 ], [ %201, %171 ]
  %232 = phi <8 x i16> [ %211, %204 ], [ %227, %213 ], [ %198, %171 ]
  %233 = phi <8 x i16> [ %210, %204 ], [ %225, %213 ], [ %195, %171 ]
  %234 = phi <8 x i16> [ %209, %204 ], [ %223, %213 ], [ %192, %171 ]
  %235 = phi <8 x i16> [ %208, %204 ], [ %221, %213 ], [ %189, %171 ]
  %236 = phi <8 x i16> [ %207, %204 ], [ %219, %213 ], [ %186, %171 ]
  %237 = phi <8 x i16> [ %206, %204 ], [ %217, %213 ], [ %183, %171 ]
  %238 = phi <8 x i16> [ %205, %204 ], [ %215, %213 ], [ %180, %171 ]
  %239 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 %63
  %240 = shufflevector <8 x i16> %238, <8 x i16> %237, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %241 = shufflevector <8 x i16> %236, <8 x i16> %235, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %242 = shufflevector <8 x i16> %234, <8 x i16> %233, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %243 = shufflevector <8 x i16> %232, <8 x i16> %231, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %244 = shufflevector <8 x i16> %238, <8 x i16> %237, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %245 = shufflevector <8 x i16> %236, <8 x i16> %235, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %246 = shufflevector <8 x i16> %234, <8 x i16> %233, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %247 = shufflevector <8 x i16> %232, <8 x i16> %231, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %248 = bitcast <8 x i16> %240 to <4 x i32>
  %249 = bitcast <8 x i16> %241 to <4 x i32>
  %250 = shufflevector <4 x i32> %248, <4 x i32> %249, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %251 = bitcast <4 x i32> %250 to <2 x i64>
  %252 = bitcast <8 x i16> %242 to <4 x i32>
  %253 = bitcast <8 x i16> %243 to <4 x i32>
  %254 = shufflevector <4 x i32> %252, <4 x i32> %253, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %255 = bitcast <4 x i32> %254 to <2 x i64>
  %256 = bitcast <8 x i16> %244 to <4 x i32>
  %257 = bitcast <8 x i16> %245 to <4 x i32>
  %258 = shufflevector <4 x i32> %256, <4 x i32> %257, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %259 = bitcast <4 x i32> %258 to <2 x i64>
  %260 = bitcast <8 x i16> %246 to <4 x i32>
  %261 = bitcast <8 x i16> %247 to <4 x i32>
  %262 = shufflevector <4 x i32> %260, <4 x i32> %261, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %263 = bitcast <4 x i32> %262 to <2 x i64>
  %264 = shufflevector <4 x i32> %248, <4 x i32> %249, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %265 = bitcast <4 x i32> %264 to <2 x i64>
  %266 = shufflevector <4 x i32> %252, <4 x i32> %253, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %267 = bitcast <4 x i32> %266 to <2 x i64>
  %268 = shufflevector <4 x i32> %256, <4 x i32> %257, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %269 = bitcast <4 x i32> %268 to <2 x i64>
  %270 = shufflevector <4 x i32> %260, <4 x i32> %261, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %271 = bitcast <4 x i32> %270 to <2 x i64>
  %272 = shufflevector <2 x i64> %251, <2 x i64> %255, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %272, <2 x i64>* %239, align 16
  %273 = shufflevector <2 x i64> %251, <2 x i64> %255, <2 x i32> <i32 1, i32 3>
  %274 = getelementptr inbounds <2 x i64>, <2 x i64>* %239, i64 1
  store <2 x i64> %273, <2 x i64>* %274, align 16
  %275 = shufflevector <2 x i64> %265, <2 x i64> %267, <2 x i32> <i32 0, i32 2>
  %276 = getelementptr inbounds <2 x i64>, <2 x i64>* %239, i64 2
  store <2 x i64> %275, <2 x i64>* %276, align 16
  %277 = shufflevector <2 x i64> %265, <2 x i64> %267, <2 x i32> <i32 1, i32 3>
  %278 = getelementptr inbounds <2 x i64>, <2 x i64>* %239, i64 3
  store <2 x i64> %277, <2 x i64>* %278, align 16
  %279 = shufflevector <2 x i64> %259, <2 x i64> %263, <2 x i32> <i32 0, i32 2>
  %280 = getelementptr inbounds <2 x i64>, <2 x i64>* %239, i64 4
  store <2 x i64> %279, <2 x i64>* %280, align 16
  %281 = shufflevector <2 x i64> %259, <2 x i64> %263, <2 x i32> <i32 1, i32 3>
  %282 = getelementptr inbounds <2 x i64>, <2 x i64>* %239, i64 5
  store <2 x i64> %281, <2 x i64>* %282, align 16
  %283 = shufflevector <2 x i64> %269, <2 x i64> %271, <2 x i32> <i32 0, i32 2>
  %284 = getelementptr inbounds <2 x i64>, <2 x i64>* %239, i64 6
  store <2 x i64> %283, <2 x i64>* %284, align 16
  %285 = shufflevector <2 x i64> %269, <2 x i64> %271, <2 x i32> <i32 1, i32 3>
  %286 = getelementptr inbounds <2 x i64>, <2 x i64>* %239, i64 7
  store <2 x i64> %285, <2 x i64>* %286, align 16
  %287 = add nuw nsw i64 %62, 1
  %288 = icmp eq i64 %287, 2
  br i1 %288, label %58, label %61

289:                                              ; preds = %58
  %290 = load <2 x i64>, <2 x i64>* %60, align 16
  %291 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 15
  store <2 x i64> %290, <2 x i64>* %291, align 16
  %292 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 1
  %293 = load <2 x i64>, <2 x i64>* %292, align 16
  %294 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 14
  store <2 x i64> %293, <2 x i64>* %294, align 16
  %295 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 2
  %296 = load <2 x i64>, <2 x i64>* %295, align 16
  %297 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 13
  store <2 x i64> %296, <2 x i64>* %297, align 16
  %298 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 3
  %299 = load <2 x i64>, <2 x i64>* %298, align 16
  %300 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 12
  store <2 x i64> %299, <2 x i64>* %300, align 16
  %301 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 4
  %302 = load <2 x i64>, <2 x i64>* %301, align 16
  %303 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 11
  store <2 x i64> %302, <2 x i64>* %303, align 16
  %304 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 5
  %305 = load <2 x i64>, <2 x i64>* %304, align 16
  %306 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 10
  store <2 x i64> %305, <2 x i64>* %306, align 16
  %307 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 6
  %308 = load <2 x i64>, <2 x i64>* %307, align 16
  %309 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 9
  store <2 x i64> %308, <2 x i64>* %309, align 16
  %310 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 7
  %311 = load <2 x i64>, <2 x i64>* %310, align 16
  %312 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 8
  store <2 x i64> %311, <2 x i64>* %312, align 16
  %313 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 8
  %314 = load <2 x i64>, <2 x i64>* %313, align 16
  store <2 x i64> %314, <2 x i64>* %40, align 16
  %315 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 9
  %316 = load <2 x i64>, <2 x i64>* %315, align 16
  store <2 x i64> %316, <2 x i64>* %38, align 16
  %317 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 10
  %318 = load <2 x i64>, <2 x i64>* %317, align 16
  store <2 x i64> %318, <2 x i64>* %36, align 16
  %319 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 11
  %320 = load <2 x i64>, <2 x i64>* %319, align 16
  store <2 x i64> %320, <2 x i64>* %34, align 16
  %321 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 12
  %322 = load <2 x i64>, <2 x i64>* %321, align 16
  store <2 x i64> %322, <2 x i64>* %32, align 16
  %323 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 13
  %324 = load <2 x i64>, <2 x i64>* %323, align 16
  store <2 x i64> %324, <2 x i64>* %30, align 16
  %325 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 14
  %326 = load <2 x i64>, <2 x i64>* %325, align 16
  store <2 x i64> %326, <2 x i64>* %28, align 16
  %327 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %7, i64 0, i64 15
  %328 = load <2 x i64>, <2 x i64>* %327, align 16
  store <2 x i64> %328, <2 x i64>* %24, align 16
  br label %329

329:                                              ; preds = %58, %289
  %330 = phi <2 x i64>* [ %24, %289 ], [ %60, %58 ]
  call void %17(<2 x i64>* %330, <2 x i64>* %330, i8 signext %12) #8
  %331 = getelementptr inbounds i8, i8* %10, i64 2
  %332 = load i8, i8* %331, align 1
  %333 = sext i8 %332 to i32
  %334 = icmp slt i8 %332, 0
  br i1 %334, label %335, label %421

335:                                              ; preds = %329
  %336 = sub nsw i32 0, %333
  %337 = xor i32 %333, -1
  %338 = shl i32 1, %337
  %339 = trunc i32 %338 to i16
  %340 = insertelement <8 x i16> undef, i16 %339, i32 0
  %341 = shufflevector <8 x i16> %340, <8 x i16> undef, <8 x i32> zeroinitializer
  %342 = bitcast <2 x i64>* %330 to <8 x i16>*
  %343 = load <8 x i16>, <8 x i16>* %342, align 16
  %344 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %343, <8 x i16> %341) #8
  %345 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %344, i32 %336) #8
  store <8 x i16> %345, <8 x i16>* %342, align 16
  %346 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 1
  %347 = bitcast <2 x i64>* %346 to <8 x i16>*
  %348 = load <8 x i16>, <8 x i16>* %347, align 16
  %349 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %348, <8 x i16> %341) #8
  %350 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %349, i32 %336) #8
  store <8 x i16> %350, <8 x i16>* %347, align 16
  %351 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 2
  %352 = bitcast <2 x i64>* %351 to <8 x i16>*
  %353 = load <8 x i16>, <8 x i16>* %352, align 16
  %354 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %353, <8 x i16> %341) #8
  %355 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %354, i32 %336) #8
  store <8 x i16> %355, <8 x i16>* %352, align 16
  %356 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 3
  %357 = bitcast <2 x i64>* %356 to <8 x i16>*
  %358 = load <8 x i16>, <8 x i16>* %357, align 16
  %359 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %358, <8 x i16> %341) #8
  %360 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %359, i32 %336) #8
  store <8 x i16> %360, <8 x i16>* %357, align 16
  %361 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 4
  %362 = bitcast <2 x i64>* %361 to <8 x i16>*
  %363 = load <8 x i16>, <8 x i16>* %362, align 16
  %364 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %363, <8 x i16> %341) #8
  %365 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %364, i32 %336) #8
  store <8 x i16> %365, <8 x i16>* %362, align 16
  %366 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 5
  %367 = bitcast <2 x i64>* %366 to <8 x i16>*
  %368 = load <8 x i16>, <8 x i16>* %367, align 16
  %369 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %368, <8 x i16> %341) #8
  %370 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %369, i32 %336) #8
  store <8 x i16> %370, <8 x i16>* %367, align 16
  %371 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 6
  %372 = bitcast <2 x i64>* %371 to <8 x i16>*
  %373 = load <8 x i16>, <8 x i16>* %372, align 16
  %374 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %373, <8 x i16> %341) #8
  %375 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %374, i32 %336) #8
  store <8 x i16> %375, <8 x i16>* %372, align 16
  %376 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 7
  %377 = bitcast <2 x i64>* %376 to <8 x i16>*
  %378 = load <8 x i16>, <8 x i16>* %377, align 16
  %379 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %378, <8 x i16> %341) #8
  %380 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %379, i32 %336) #8
  store <8 x i16> %380, <8 x i16>* %377, align 16
  %381 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 8
  %382 = bitcast <2 x i64>* %381 to <8 x i16>*
  %383 = load <8 x i16>, <8 x i16>* %382, align 16
  %384 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %383, <8 x i16> %341) #8
  %385 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %384, i32 %336) #8
  store <8 x i16> %385, <8 x i16>* %382, align 16
  %386 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 9
  %387 = bitcast <2 x i64>* %386 to <8 x i16>*
  %388 = load <8 x i16>, <8 x i16>* %387, align 16
  %389 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %388, <8 x i16> %341) #8
  %390 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %389, i32 %336) #8
  store <8 x i16> %390, <8 x i16>* %387, align 16
  %391 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 10
  %392 = bitcast <2 x i64>* %391 to <8 x i16>*
  %393 = load <8 x i16>, <8 x i16>* %392, align 16
  %394 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %393, <8 x i16> %341) #8
  %395 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %394, i32 %336) #8
  store <8 x i16> %395, <8 x i16>* %392, align 16
  %396 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 11
  %397 = bitcast <2 x i64>* %396 to <8 x i16>*
  %398 = load <8 x i16>, <8 x i16>* %397, align 16
  %399 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %398, <8 x i16> %341) #8
  %400 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %399, i32 %336) #8
  store <8 x i16> %400, <8 x i16>* %397, align 16
  %401 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 12
  %402 = bitcast <2 x i64>* %401 to <8 x i16>*
  %403 = load <8 x i16>, <8 x i16>* %402, align 16
  %404 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %403, <8 x i16> %341) #8
  %405 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %404, i32 %336) #8
  store <8 x i16> %405, <8 x i16>* %402, align 16
  %406 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 13
  %407 = bitcast <2 x i64>* %406 to <8 x i16>*
  %408 = load <8 x i16>, <8 x i16>* %407, align 16
  %409 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %408, <8 x i16> %341) #8
  %410 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %409, i32 %336) #8
  store <8 x i16> %410, <8 x i16>* %407, align 16
  %411 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 14
  %412 = bitcast <2 x i64>* %411 to <8 x i16>*
  %413 = load <8 x i16>, <8 x i16>* %412, align 16
  %414 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %413, <8 x i16> %341) #8
  %415 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %414, i32 %336) #8
  store <8 x i16> %415, <8 x i16>* %412, align 16
  %416 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 15
  %417 = bitcast <2 x i64>* %416 to <8 x i16>*
  %418 = load <8 x i16>, <8 x i16>* %417, align 16
  %419 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %418, <8 x i16> %341) #8
  %420 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %419, i32 %336) #8
  store <8 x i16> %420, <8 x i16>* %417, align 16
  br label %509

421:                                              ; preds = %329
  %422 = icmp eq i8 %332, 0
  %423 = bitcast <2 x i64>* %330 to <8 x i16>*
  %424 = load <8 x i16>, <8 x i16>* %423, align 16
  br i1 %422, label %425, label %447

425:                                              ; preds = %421
  %426 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 1
  %427 = bitcast <2 x i64>* %426 to <8 x i16>*
  %428 = load <8 x i16>, <8 x i16>* %427, align 16
  %429 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 2
  %430 = bitcast <2 x i64>* %429 to <8 x i16>*
  %431 = load <8 x i16>, <8 x i16>* %430, align 16
  %432 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 3
  %433 = bitcast <2 x i64>* %432 to <8 x i16>*
  %434 = load <8 x i16>, <8 x i16>* %433, align 16
  %435 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 4
  %436 = bitcast <2 x i64>* %435 to <8 x i16>*
  %437 = load <8 x i16>, <8 x i16>* %436, align 16
  %438 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 5
  %439 = bitcast <2 x i64>* %438 to <8 x i16>*
  %440 = load <8 x i16>, <8 x i16>* %439, align 16
  %441 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 6
  %442 = bitcast <2 x i64>* %441 to <8 x i16>*
  %443 = load <8 x i16>, <8 x i16>* %442, align 16
  %444 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 7
  %445 = bitcast <2 x i64>* %444 to <8 x i16>*
  %446 = load <8 x i16>, <8 x i16>* %445, align 16
  br label %509

447:                                              ; preds = %421
  %448 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %424, i32 %333) #8
  store <8 x i16> %448, <8 x i16>* %423, align 16
  %449 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 1
  %450 = bitcast <2 x i64>* %449 to <8 x i16>*
  %451 = load <8 x i16>, <8 x i16>* %450, align 16
  %452 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %451, i32 %333) #8
  store <8 x i16> %452, <8 x i16>* %450, align 16
  %453 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 2
  %454 = bitcast <2 x i64>* %453 to <8 x i16>*
  %455 = load <8 x i16>, <8 x i16>* %454, align 16
  %456 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %455, i32 %333) #8
  store <8 x i16> %456, <8 x i16>* %454, align 16
  %457 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 3
  %458 = bitcast <2 x i64>* %457 to <8 x i16>*
  %459 = load <8 x i16>, <8 x i16>* %458, align 16
  %460 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %459, i32 %333) #8
  store <8 x i16> %460, <8 x i16>* %458, align 16
  %461 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 4
  %462 = bitcast <2 x i64>* %461 to <8 x i16>*
  %463 = load <8 x i16>, <8 x i16>* %462, align 16
  %464 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %463, i32 %333) #8
  store <8 x i16> %464, <8 x i16>* %462, align 16
  %465 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 5
  %466 = bitcast <2 x i64>* %465 to <8 x i16>*
  %467 = load <8 x i16>, <8 x i16>* %466, align 16
  %468 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %467, i32 %333) #8
  store <8 x i16> %468, <8 x i16>* %466, align 16
  %469 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 6
  %470 = bitcast <2 x i64>* %469 to <8 x i16>*
  %471 = load <8 x i16>, <8 x i16>* %470, align 16
  %472 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %471, i32 %333) #8
  store <8 x i16> %472, <8 x i16>* %470, align 16
  %473 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 7
  %474 = bitcast <2 x i64>* %473 to <8 x i16>*
  %475 = load <8 x i16>, <8 x i16>* %474, align 16
  %476 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %475, i32 %333) #8
  store <8 x i16> %476, <8 x i16>* %474, align 16
  %477 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 8
  %478 = bitcast <2 x i64>* %477 to <8 x i16>*
  %479 = load <8 x i16>, <8 x i16>* %478, align 16
  %480 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %479, i32 %333) #8
  store <8 x i16> %480, <8 x i16>* %478, align 16
  %481 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 9
  %482 = bitcast <2 x i64>* %481 to <8 x i16>*
  %483 = load <8 x i16>, <8 x i16>* %482, align 16
  %484 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %483, i32 %333) #8
  store <8 x i16> %484, <8 x i16>* %482, align 16
  %485 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 10
  %486 = bitcast <2 x i64>* %485 to <8 x i16>*
  %487 = load <8 x i16>, <8 x i16>* %486, align 16
  %488 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %487, i32 %333) #8
  store <8 x i16> %488, <8 x i16>* %486, align 16
  %489 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 11
  %490 = bitcast <2 x i64>* %489 to <8 x i16>*
  %491 = load <8 x i16>, <8 x i16>* %490, align 16
  %492 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %491, i32 %333) #8
  store <8 x i16> %492, <8 x i16>* %490, align 16
  %493 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 12
  %494 = bitcast <2 x i64>* %493 to <8 x i16>*
  %495 = load <8 x i16>, <8 x i16>* %494, align 16
  %496 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %495, i32 %333) #8
  store <8 x i16> %496, <8 x i16>* %494, align 16
  %497 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 13
  %498 = bitcast <2 x i64>* %497 to <8 x i16>*
  %499 = load <8 x i16>, <8 x i16>* %498, align 16
  %500 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %499, i32 %333) #8
  store <8 x i16> %500, <8 x i16>* %498, align 16
  %501 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 14
  %502 = bitcast <2 x i64>* %501 to <8 x i16>*
  %503 = load <8 x i16>, <8 x i16>* %502, align 16
  %504 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %503, i32 %333) #8
  store <8 x i16> %504, <8 x i16>* %502, align 16
  %505 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 15
  %506 = bitcast <2 x i64>* %505 to <8 x i16>*
  %507 = load <8 x i16>, <8 x i16>* %506, align 16
  %508 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %507, i32 %333) #8
  store <8 x i16> %508, <8 x i16>* %506, align 16
  br label %509

509:                                              ; preds = %425, %447, %335
  %510 = phi <8 x i16> [ %446, %425 ], [ %476, %447 ], [ %380, %335 ]
  %511 = phi <8 x i16> [ %443, %425 ], [ %472, %447 ], [ %375, %335 ]
  %512 = phi <8 x i16> [ %440, %425 ], [ %468, %447 ], [ %370, %335 ]
  %513 = phi <8 x i16> [ %437, %425 ], [ %464, %447 ], [ %365, %335 ]
  %514 = phi <8 x i16> [ %434, %425 ], [ %460, %447 ], [ %360, %335 ]
  %515 = phi <8 x i16> [ %431, %425 ], [ %456, %447 ], [ %355, %335 ]
  %516 = phi <8 x i16> [ %428, %425 ], [ %452, %447 ], [ %350, %335 ]
  %517 = phi <8 x i16> [ %424, %425 ], [ %448, %447 ], [ %345, %335 ]
  %518 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 1
  %519 = shufflevector <8 x i16> %517, <8 x i16> %516, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %520 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 2
  %521 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 3
  %522 = shufflevector <8 x i16> %515, <8 x i16> %514, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %523 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 4
  %524 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 5
  %525 = shufflevector <8 x i16> %513, <8 x i16> %512, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %526 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 6
  %527 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 7
  %528 = shufflevector <8 x i16> %511, <8 x i16> %510, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %529 = shufflevector <8 x i16> %517, <8 x i16> %516, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %530 = shufflevector <8 x i16> %515, <8 x i16> %514, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %531 = shufflevector <8 x i16> %513, <8 x i16> %512, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %532 = shufflevector <8 x i16> %511, <8 x i16> %510, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %533 = bitcast <8 x i16> %519 to <4 x i32>
  %534 = bitcast <8 x i16> %522 to <4 x i32>
  %535 = shufflevector <4 x i32> %533, <4 x i32> %534, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %536 = bitcast <4 x i32> %535 to <2 x i64>
  %537 = bitcast <8 x i16> %525 to <4 x i32>
  %538 = bitcast <8 x i16> %528 to <4 x i32>
  %539 = shufflevector <4 x i32> %537, <4 x i32> %538, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %540 = bitcast <4 x i32> %539 to <2 x i64>
  %541 = bitcast <8 x i16> %529 to <4 x i32>
  %542 = bitcast <8 x i16> %530 to <4 x i32>
  %543 = shufflevector <4 x i32> %541, <4 x i32> %542, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %544 = bitcast <4 x i32> %543 to <2 x i64>
  %545 = bitcast <8 x i16> %531 to <4 x i32>
  %546 = bitcast <8 x i16> %532 to <4 x i32>
  %547 = shufflevector <4 x i32> %545, <4 x i32> %546, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %548 = bitcast <4 x i32> %547 to <2 x i64>
  %549 = shufflevector <4 x i32> %533, <4 x i32> %534, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %550 = bitcast <4 x i32> %549 to <2 x i64>
  %551 = shufflevector <4 x i32> %537, <4 x i32> %538, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %552 = bitcast <4 x i32> %551 to <2 x i64>
  %553 = shufflevector <4 x i32> %541, <4 x i32> %542, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %554 = bitcast <4 x i32> %553 to <2 x i64>
  %555 = shufflevector <4 x i32> %545, <4 x i32> %546, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %556 = bitcast <4 x i32> %555 to <2 x i64>
  %557 = shufflevector <2 x i64> %536, <2 x i64> %540, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %557, <2 x i64>* %330, align 16
  %558 = shufflevector <2 x i64> %536, <2 x i64> %540, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %558, <2 x i64>* %518, align 16
  %559 = shufflevector <2 x i64> %550, <2 x i64> %552, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %559, <2 x i64>* %520, align 16
  %560 = shufflevector <2 x i64> %550, <2 x i64> %552, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %560, <2 x i64>* %521, align 16
  %561 = shufflevector <2 x i64> %544, <2 x i64> %548, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %561, <2 x i64>* %523, align 16
  %562 = shufflevector <2 x i64> %544, <2 x i64> %548, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %562, <2 x i64>* %524, align 16
  %563 = shufflevector <2 x i64> %554, <2 x i64> %556, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %563, <2 x i64>* %526, align 16
  %564 = shufflevector <2 x i64> %554, <2 x i64> %556, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %564, <2 x i64>* %527, align 16
  %565 = bitcast <2 x i64> %557 to <8 x i16>
  %566 = shufflevector <8 x i16> %565, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %567 = shufflevector <8 x i16> %565, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %568 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %566, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %569 = ashr <4 x i32> %568, <i32 12, i32 12, i32 12, i32 12>
  %570 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %567, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %571 = ashr <4 x i32> %570, <i32 12, i32 12, i32 12, i32 12>
  %572 = bitcast i32* %1 to <4 x i32>*
  store <4 x i32> %569, <4 x i32>* %572, align 16
  %573 = getelementptr inbounds i32, i32* %1, i64 4
  %574 = bitcast i32* %573 to <4 x i32>*
  store <4 x i32> %571, <4 x i32>* %574, align 16
  %575 = bitcast <2 x i64> %558 to <8 x i16>
  %576 = getelementptr inbounds i32, i32* %1, i64 16
  %577 = shufflevector <8 x i16> %575, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %578 = shufflevector <8 x i16> %575, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %579 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %577, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %580 = ashr <4 x i32> %579, <i32 12, i32 12, i32 12, i32 12>
  %581 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %578, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %582 = ashr <4 x i32> %581, <i32 12, i32 12, i32 12, i32 12>
  %583 = bitcast i32* %576 to <4 x i32>*
  store <4 x i32> %580, <4 x i32>* %583, align 16
  %584 = getelementptr inbounds i32, i32* %1, i64 20
  %585 = bitcast i32* %584 to <4 x i32>*
  store <4 x i32> %582, <4 x i32>* %585, align 16
  %586 = bitcast <2 x i64> %559 to <8 x i16>
  %587 = getelementptr inbounds i32, i32* %1, i64 32
  %588 = shufflevector <8 x i16> %586, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %589 = shufflevector <8 x i16> %586, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %590 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %588, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %591 = ashr <4 x i32> %590, <i32 12, i32 12, i32 12, i32 12>
  %592 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %589, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %593 = ashr <4 x i32> %592, <i32 12, i32 12, i32 12, i32 12>
  %594 = bitcast i32* %587 to <4 x i32>*
  store <4 x i32> %591, <4 x i32>* %594, align 16
  %595 = getelementptr inbounds i32, i32* %1, i64 36
  %596 = bitcast i32* %595 to <4 x i32>*
  store <4 x i32> %593, <4 x i32>* %596, align 16
  %597 = bitcast <2 x i64> %560 to <8 x i16>
  %598 = getelementptr inbounds i32, i32* %1, i64 48
  %599 = shufflevector <8 x i16> %597, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %600 = shufflevector <8 x i16> %597, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %601 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %599, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %602 = ashr <4 x i32> %601, <i32 12, i32 12, i32 12, i32 12>
  %603 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %600, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %604 = ashr <4 x i32> %603, <i32 12, i32 12, i32 12, i32 12>
  %605 = bitcast i32* %598 to <4 x i32>*
  store <4 x i32> %602, <4 x i32>* %605, align 16
  %606 = getelementptr inbounds i32, i32* %1, i64 52
  %607 = bitcast i32* %606 to <4 x i32>*
  store <4 x i32> %604, <4 x i32>* %607, align 16
  %608 = bitcast <2 x i64> %561 to <8 x i16>
  %609 = getelementptr inbounds i32, i32* %1, i64 64
  %610 = shufflevector <8 x i16> %608, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %611 = shufflevector <8 x i16> %608, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %612 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %610, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %613 = ashr <4 x i32> %612, <i32 12, i32 12, i32 12, i32 12>
  %614 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %611, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %615 = ashr <4 x i32> %614, <i32 12, i32 12, i32 12, i32 12>
  %616 = bitcast i32* %609 to <4 x i32>*
  store <4 x i32> %613, <4 x i32>* %616, align 16
  %617 = getelementptr inbounds i32, i32* %1, i64 68
  %618 = bitcast i32* %617 to <4 x i32>*
  store <4 x i32> %615, <4 x i32>* %618, align 16
  %619 = bitcast <2 x i64> %562 to <8 x i16>
  %620 = getelementptr inbounds i32, i32* %1, i64 80
  %621 = shufflevector <8 x i16> %619, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %622 = shufflevector <8 x i16> %619, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %623 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %621, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %624 = ashr <4 x i32> %623, <i32 12, i32 12, i32 12, i32 12>
  %625 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %622, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %626 = ashr <4 x i32> %625, <i32 12, i32 12, i32 12, i32 12>
  %627 = bitcast i32* %620 to <4 x i32>*
  store <4 x i32> %624, <4 x i32>* %627, align 16
  %628 = getelementptr inbounds i32, i32* %1, i64 84
  %629 = bitcast i32* %628 to <4 x i32>*
  store <4 x i32> %626, <4 x i32>* %629, align 16
  %630 = bitcast <2 x i64> %563 to <8 x i16>
  %631 = getelementptr inbounds i32, i32* %1, i64 96
  %632 = shufflevector <8 x i16> %630, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %633 = shufflevector <8 x i16> %630, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %634 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %632, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %635 = ashr <4 x i32> %634, <i32 12, i32 12, i32 12, i32 12>
  %636 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %633, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %637 = ashr <4 x i32> %636, <i32 12, i32 12, i32 12, i32 12>
  %638 = bitcast i32* %631 to <4 x i32>*
  store <4 x i32> %635, <4 x i32>* %638, align 16
  %639 = getelementptr inbounds i32, i32* %1, i64 100
  %640 = bitcast i32* %639 to <4 x i32>*
  store <4 x i32> %637, <4 x i32>* %640, align 16
  %641 = bitcast <2 x i64> %564 to <8 x i16>
  %642 = getelementptr inbounds i32, i32* %1, i64 112
  %643 = shufflevector <8 x i16> %641, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %644 = shufflevector <8 x i16> %641, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %645 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %643, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %646 = ashr <4 x i32> %645, <i32 12, i32 12, i32 12, i32 12>
  %647 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %644, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %648 = ashr <4 x i32> %647, <i32 12, i32 12, i32 12, i32 12>
  %649 = bitcast i32* %642 to <4 x i32>*
  store <4 x i32> %646, <4 x i32>* %649, align 16
  %650 = getelementptr inbounds i32, i32* %1, i64 116
  %651 = bitcast i32* %650 to <4 x i32>*
  store <4 x i32> %648, <4 x i32>* %651, align 16
  %652 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 8
  %653 = bitcast <2 x i64>* %652 to <8 x i16>*
  %654 = load <8 x i16>, <8 x i16>* %653, align 16
  %655 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 9
  %656 = bitcast <2 x i64>* %655 to <8 x i16>*
  %657 = load <8 x i16>, <8 x i16>* %656, align 16
  %658 = shufflevector <8 x i16> %654, <8 x i16> %657, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %659 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 10
  %660 = bitcast <2 x i64>* %659 to <8 x i16>*
  %661 = load <8 x i16>, <8 x i16>* %660, align 16
  %662 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 11
  %663 = bitcast <2 x i64>* %662 to <8 x i16>*
  %664 = load <8 x i16>, <8 x i16>* %663, align 16
  %665 = shufflevector <8 x i16> %661, <8 x i16> %664, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %666 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 12
  %667 = bitcast <2 x i64>* %666 to <8 x i16>*
  %668 = load <8 x i16>, <8 x i16>* %667, align 16
  %669 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 13
  %670 = bitcast <2 x i64>* %669 to <8 x i16>*
  %671 = load <8 x i16>, <8 x i16>* %670, align 16
  %672 = shufflevector <8 x i16> %668, <8 x i16> %671, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %673 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 14
  %674 = bitcast <2 x i64>* %673 to <8 x i16>*
  %675 = load <8 x i16>, <8 x i16>* %674, align 16
  %676 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 15
  %677 = bitcast <2 x i64>* %676 to <8 x i16>*
  %678 = load <8 x i16>, <8 x i16>* %677, align 16
  %679 = shufflevector <8 x i16> %675, <8 x i16> %678, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %680 = shufflevector <8 x i16> %654, <8 x i16> %657, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %681 = shufflevector <8 x i16> %661, <8 x i16> %664, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %682 = shufflevector <8 x i16> %668, <8 x i16> %671, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %683 = shufflevector <8 x i16> %675, <8 x i16> %678, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %684 = bitcast <8 x i16> %658 to <4 x i32>
  %685 = bitcast <8 x i16> %665 to <4 x i32>
  %686 = shufflevector <4 x i32> %684, <4 x i32> %685, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %687 = bitcast <4 x i32> %686 to <2 x i64>
  %688 = bitcast <8 x i16> %672 to <4 x i32>
  %689 = bitcast <8 x i16> %679 to <4 x i32>
  %690 = shufflevector <4 x i32> %688, <4 x i32> %689, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %691 = bitcast <4 x i32> %690 to <2 x i64>
  %692 = bitcast <8 x i16> %680 to <4 x i32>
  %693 = bitcast <8 x i16> %681 to <4 x i32>
  %694 = shufflevector <4 x i32> %692, <4 x i32> %693, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %695 = bitcast <4 x i32> %694 to <2 x i64>
  %696 = bitcast <8 x i16> %682 to <4 x i32>
  %697 = bitcast <8 x i16> %683 to <4 x i32>
  %698 = shufflevector <4 x i32> %696, <4 x i32> %697, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %699 = bitcast <4 x i32> %698 to <2 x i64>
  %700 = shufflevector <4 x i32> %684, <4 x i32> %685, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %701 = bitcast <4 x i32> %700 to <2 x i64>
  %702 = shufflevector <4 x i32> %688, <4 x i32> %689, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %703 = bitcast <4 x i32> %702 to <2 x i64>
  %704 = shufflevector <4 x i32> %692, <4 x i32> %693, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %705 = bitcast <4 x i32> %704 to <2 x i64>
  %706 = shufflevector <4 x i32> %696, <4 x i32> %697, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %707 = bitcast <4 x i32> %706 to <2 x i64>
  %708 = shufflevector <2 x i64> %687, <2 x i64> %691, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %708, <2 x i64>* %652, align 16
  %709 = shufflevector <2 x i64> %687, <2 x i64> %691, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %709, <2 x i64>* %655, align 16
  %710 = shufflevector <2 x i64> %701, <2 x i64> %703, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %710, <2 x i64>* %659, align 16
  %711 = shufflevector <2 x i64> %701, <2 x i64> %703, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %711, <2 x i64>* %662, align 16
  %712 = shufflevector <2 x i64> %695, <2 x i64> %699, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %712, <2 x i64>* %666, align 16
  %713 = shufflevector <2 x i64> %695, <2 x i64> %699, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %713, <2 x i64>* %669, align 16
  %714 = shufflevector <2 x i64> %705, <2 x i64> %707, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %714, <2 x i64>* %673, align 16
  %715 = shufflevector <2 x i64> %705, <2 x i64> %707, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %715, <2 x i64>* %676, align 16
  %716 = getelementptr inbounds i32, i32* %1, i64 8
  %717 = bitcast <2 x i64> %708 to <8 x i16>
  %718 = shufflevector <8 x i16> %717, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %719 = shufflevector <8 x i16> %717, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %720 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %718, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %721 = ashr <4 x i32> %720, <i32 12, i32 12, i32 12, i32 12>
  %722 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %719, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %723 = ashr <4 x i32> %722, <i32 12, i32 12, i32 12, i32 12>
  %724 = bitcast i32* %716 to <4 x i32>*
  store <4 x i32> %721, <4 x i32>* %724, align 16
  %725 = getelementptr inbounds i32, i32* %1, i64 12
  %726 = bitcast i32* %725 to <4 x i32>*
  store <4 x i32> %723, <4 x i32>* %726, align 16
  %727 = bitcast <2 x i64> %709 to <8 x i16>
  %728 = getelementptr inbounds i32, i32* %1, i64 24
  %729 = shufflevector <8 x i16> %727, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %730 = shufflevector <8 x i16> %727, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %731 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %729, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %732 = ashr <4 x i32> %731, <i32 12, i32 12, i32 12, i32 12>
  %733 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %730, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %734 = ashr <4 x i32> %733, <i32 12, i32 12, i32 12, i32 12>
  %735 = bitcast i32* %728 to <4 x i32>*
  store <4 x i32> %732, <4 x i32>* %735, align 16
  %736 = getelementptr inbounds i32, i32* %1, i64 28
  %737 = bitcast i32* %736 to <4 x i32>*
  store <4 x i32> %734, <4 x i32>* %737, align 16
  %738 = bitcast <2 x i64> %710 to <8 x i16>
  %739 = getelementptr inbounds i32, i32* %1, i64 40
  %740 = shufflevector <8 x i16> %738, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %741 = shufflevector <8 x i16> %738, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %742 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %740, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %743 = ashr <4 x i32> %742, <i32 12, i32 12, i32 12, i32 12>
  %744 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %741, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %745 = ashr <4 x i32> %744, <i32 12, i32 12, i32 12, i32 12>
  %746 = bitcast i32* %739 to <4 x i32>*
  store <4 x i32> %743, <4 x i32>* %746, align 16
  %747 = getelementptr inbounds i32, i32* %1, i64 44
  %748 = bitcast i32* %747 to <4 x i32>*
  store <4 x i32> %745, <4 x i32>* %748, align 16
  %749 = bitcast <2 x i64> %711 to <8 x i16>
  %750 = getelementptr inbounds i32, i32* %1, i64 56
  %751 = shufflevector <8 x i16> %749, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %752 = shufflevector <8 x i16> %749, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %753 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %751, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %754 = ashr <4 x i32> %753, <i32 12, i32 12, i32 12, i32 12>
  %755 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %752, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %756 = ashr <4 x i32> %755, <i32 12, i32 12, i32 12, i32 12>
  %757 = bitcast i32* %750 to <4 x i32>*
  store <4 x i32> %754, <4 x i32>* %757, align 16
  %758 = getelementptr inbounds i32, i32* %1, i64 60
  %759 = bitcast i32* %758 to <4 x i32>*
  store <4 x i32> %756, <4 x i32>* %759, align 16
  %760 = bitcast <2 x i64> %712 to <8 x i16>
  %761 = getelementptr inbounds i32, i32* %1, i64 72
  %762 = shufflevector <8 x i16> %760, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %763 = shufflevector <8 x i16> %760, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %764 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %762, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %765 = ashr <4 x i32> %764, <i32 12, i32 12, i32 12, i32 12>
  %766 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %763, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %767 = ashr <4 x i32> %766, <i32 12, i32 12, i32 12, i32 12>
  %768 = bitcast i32* %761 to <4 x i32>*
  store <4 x i32> %765, <4 x i32>* %768, align 16
  %769 = getelementptr inbounds i32, i32* %1, i64 76
  %770 = bitcast i32* %769 to <4 x i32>*
  store <4 x i32> %767, <4 x i32>* %770, align 16
  %771 = bitcast <2 x i64> %713 to <8 x i16>
  %772 = getelementptr inbounds i32, i32* %1, i64 88
  %773 = shufflevector <8 x i16> %771, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %774 = shufflevector <8 x i16> %771, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %775 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %773, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %776 = ashr <4 x i32> %775, <i32 12, i32 12, i32 12, i32 12>
  %777 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %774, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %778 = ashr <4 x i32> %777, <i32 12, i32 12, i32 12, i32 12>
  %779 = bitcast i32* %772 to <4 x i32>*
  store <4 x i32> %776, <4 x i32>* %779, align 16
  %780 = getelementptr inbounds i32, i32* %1, i64 92
  %781 = bitcast i32* %780 to <4 x i32>*
  store <4 x i32> %778, <4 x i32>* %781, align 16
  %782 = bitcast <2 x i64> %714 to <8 x i16>
  %783 = getelementptr inbounds i32, i32* %1, i64 104
  %784 = shufflevector <8 x i16> %782, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %785 = shufflevector <8 x i16> %782, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %786 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %784, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %787 = ashr <4 x i32> %786, <i32 12, i32 12, i32 12, i32 12>
  %788 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %785, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %789 = ashr <4 x i32> %788, <i32 12, i32 12, i32 12, i32 12>
  %790 = bitcast i32* %783 to <4 x i32>*
  store <4 x i32> %787, <4 x i32>* %790, align 16
  %791 = getelementptr inbounds i32, i32* %1, i64 108
  %792 = bitcast i32* %791 to <4 x i32>*
  store <4 x i32> %789, <4 x i32>* %792, align 16
  %793 = getelementptr inbounds <2 x i64>, <2 x i64>* %330, i64 15
  %794 = bitcast <2 x i64>* %793 to <8 x i16>*
  %795 = load <8 x i16>, <8 x i16>* %794, align 16
  %796 = getelementptr inbounds i32, i32* %1, i64 120
  %797 = shufflevector <8 x i16> %795, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %798 = shufflevector <8 x i16> %795, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %799 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %797, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %800 = ashr <4 x i32> %799, <i32 12, i32 12, i32 12, i32 12>
  %801 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %798, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %802 = ashr <4 x i32> %801, <i32 12, i32 12, i32 12, i32 12>
  %803 = bitcast i32* %796 to <4 x i32>*
  store <4 x i32> %800, <4 x i32>* %803, align 16
  %804 = getelementptr inbounds i32, i32* %1, i64 124
  %805 = bitcast i32* %804 to <4 x i32>*
  store <4 x i32> %802, <4 x i32>* %805, align 16
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %9) #8
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %8) #8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @av1_lowbd_fwd_txfm2d_16x16_sse2(i16* nocapture readonly, i32* nocapture, i32, i8 zeroext, i32) #2 {
  %6 = alloca [16 x <2 x i64>], align 16
  %7 = alloca [32 x <2 x i64>], align 16
  %8 = bitcast [16 x <2 x i64>]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %8) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %8, i8 -86, i64 256, i1 false)
  %9 = bitcast [32 x <2 x i64>]* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 512, i8* nonnull %9) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 512, i1 false)
  %10 = load i8*, i8** getelementptr inbounds ([19 x i8*], [19 x i8*]* @av1_fwd_txfm_shift_ls, i64 0, i64 2), align 16
  %11 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_fwd_cos_bit_col, i64 0, i64 2, i64 2), align 2
  %12 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_fwd_cos_bit_row, i64 0, i64 2, i64 2), align 2
  %13 = zext i8 %3 to i64
  %14 = getelementptr inbounds [16 x void (<2 x i64>*, <2 x i64>*, i8)*], [16 x void (<2 x i64>*, <2 x i64>*, i8)*]* @col_txfm8x16_arr, i64 0, i64 %13
  %15 = load void (<2 x i64>*, <2 x i64>*, i8)*, void (<2 x i64>*, <2 x i64>*, i8)** %14, align 8
  %16 = getelementptr inbounds [16 x void (<2 x i64>*, <2 x i64>*, i8)*], [16 x void (<2 x i64>*, <2 x i64>*, i8)*]* @row_txfm8x16_arr, i64 0, i64 %13
  %17 = load void (<2 x i64>*, <2 x i64>*, i8)*, void (<2 x i64>*, <2 x i64>*, i8)** %16, align 8
  switch i8 %3, label %21 [
    i8 6, label %20
    i8 15, label %19
    i8 7, label %19
    i8 5, label %19
    i8 14, label %18
    i8 8, label %18
    i8 4, label %18
  ]

18:                                               ; preds = %5, %5, %5
  br label %21

19:                                               ; preds = %5, %5, %5
  br label %21

20:                                               ; preds = %5
  br label %21

21:                                               ; preds = %5, %18, %19, %20
  %22 = phi i1 [ false, %20 ], [ true, %19 ], [ false, %18 ], [ true, %5 ]
  %23 = phi i32 [ 1, %20 ], [ 1, %19 ], [ 0, %18 ], [ 0, %5 ]
  %24 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 0
  %25 = sext i32 %2 to i64
  %26 = getelementptr inbounds i8, i8* %10, i64 1
  %27 = bitcast [16 x <2 x i64>]* %6 to <8 x i16>*
  %28 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 1
  %29 = bitcast <2 x i64>* %28 to <8 x i16>*
  %30 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 2
  %31 = bitcast <2 x i64>* %30 to <8 x i16>*
  %32 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 3
  %33 = bitcast <2 x i64>* %32 to <8 x i16>*
  %34 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 4
  %35 = bitcast <2 x i64>* %34 to <8 x i16>*
  %36 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 5
  %37 = bitcast <2 x i64>* %36 to <8 x i16>*
  %38 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 6
  %39 = bitcast <2 x i64>* %38 to <8 x i16>*
  %40 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 7
  %41 = bitcast <2 x i64>* %40 to <8 x i16>*
  %42 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 8
  %43 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 16
  %44 = bitcast <2 x i64>* %42 to <8 x i16>*
  %45 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 9
  %46 = bitcast <2 x i64>* %45 to <8 x i16>*
  %47 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 10
  %48 = bitcast <2 x i64>* %47 to <8 x i16>*
  %49 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 11
  %50 = bitcast <2 x i64>* %49 to <8 x i16>*
  %51 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 12
  %52 = bitcast <2 x i64>* %51 to <8 x i16>*
  %53 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 13
  %54 = bitcast <2 x i64>* %53 to <8 x i16>*
  %55 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 14
  %56 = bitcast <2 x i64>* %55 to <8 x i16>*
  %57 = getelementptr inbounds [16 x <2 x i64>], [16 x <2 x i64>]* %6, i64 0, i64 15
  %58 = bitcast <2 x i64>* %57 to <8 x i16>*
  %59 = shl nsw i64 %25, 1
  %60 = mul nsw i64 %25, 3
  %61 = shl nsw i64 %25, 2
  %62 = mul nsw i64 %25, 5
  %63 = mul nsw i64 %25, 6
  %64 = mul nsw i64 %25, 7
  %65 = shl nsw i64 %25, 3
  %66 = mul nsw i64 %25, 9
  %67 = mul nsw i64 %25, 10
  %68 = mul nsw i64 %25, 11
  %69 = mul nsw i64 %25, 12
  %70 = mul nsw i64 %25, 13
  %71 = mul nsw i64 %25, 14
  %72 = mul nsw i64 %25, 15
  %73 = shl nsw i64 %25, 1
  %74 = mul nsw i64 %25, 3
  %75 = shl nsw i64 %25, 2
  %76 = mul nsw i64 %25, 5
  %77 = mul nsw i64 %25, 6
  %78 = mul nsw i64 %25, 7
  %79 = shl nsw i64 %25, 3
  %80 = mul nsw i64 %25, 9
  %81 = mul nsw i64 %25, 10
  %82 = mul nsw i64 %25, 11
  %83 = mul nsw i64 %25, 12
  %84 = mul nsw i64 %25, 13
  %85 = mul nsw i64 %25, 14
  %86 = mul nsw i64 %25, 15
  %87 = bitcast [16 x <2 x i64>]* %6 to <8 x i16>*
  %88 = bitcast [16 x <2 x i64>]* %6 to <8 x i16>*
  %89 = bitcast [16 x <2 x i64>]* %6 to <8 x i16>*
  %90 = bitcast [16 x <2 x i64>]* %6 to <8 x i16>*
  br label %94

91:                                               ; preds = %401
  %92 = icmp eq i32 %23, 0
  %93 = getelementptr inbounds i8, i8* %10, i64 2
  br label %517

94:                                               ; preds = %401, %21
  %95 = phi i64 [ 0, %21 ], [ %514, %401 ]
  %96 = shl nsw i64 %95, 3
  %97 = getelementptr inbounds i16, i16* %0, i64 %96
  %98 = bitcast i16* %97 to <2 x i64>*
  %99 = load <2 x i64>, <2 x i64>* %98, align 16
  br i1 %22, label %146, label %100

100:                                              ; preds = %94
  store <2 x i64> %99, <2 x i64>* %57, align 16
  %101 = getelementptr inbounds i16, i16* %97, i64 %25
  %102 = bitcast i16* %101 to <2 x i64>*
  %103 = load <2 x i64>, <2 x i64>* %102, align 16
  store <2 x i64> %103, <2 x i64>* %55, align 16
  %104 = getelementptr inbounds i16, i16* %97, i64 %59
  %105 = bitcast i16* %104 to <2 x i64>*
  %106 = load <2 x i64>, <2 x i64>* %105, align 16
  store <2 x i64> %106, <2 x i64>* %53, align 16
  %107 = getelementptr inbounds i16, i16* %97, i64 %60
  %108 = bitcast i16* %107 to <2 x i64>*
  %109 = load <2 x i64>, <2 x i64>* %108, align 16
  store <2 x i64> %109, <2 x i64>* %51, align 16
  %110 = getelementptr inbounds i16, i16* %97, i64 %61
  %111 = bitcast i16* %110 to <2 x i64>*
  %112 = load <2 x i64>, <2 x i64>* %111, align 16
  store <2 x i64> %112, <2 x i64>* %49, align 16
  %113 = getelementptr inbounds i16, i16* %97, i64 %62
  %114 = bitcast i16* %113 to <2 x i64>*
  %115 = load <2 x i64>, <2 x i64>* %114, align 16
  store <2 x i64> %115, <2 x i64>* %47, align 16
  %116 = getelementptr inbounds i16, i16* %97, i64 %63
  %117 = bitcast i16* %116 to <2 x i64>*
  %118 = load <2 x i64>, <2 x i64>* %117, align 16
  store <2 x i64> %118, <2 x i64>* %45, align 16
  %119 = getelementptr inbounds i16, i16* %97, i64 %64
  %120 = bitcast i16* %119 to <2 x i64>*
  %121 = load <2 x i64>, <2 x i64>* %120, align 16
  store <2 x i64> %121, <2 x i64>* %42, align 16
  %122 = getelementptr inbounds i16, i16* %97, i64 %65
  %123 = bitcast i16* %122 to <2 x i64>*
  %124 = load <2 x i64>, <2 x i64>* %123, align 16
  store <2 x i64> %124, <2 x i64>* %40, align 16
  %125 = getelementptr inbounds i16, i16* %97, i64 %66
  %126 = bitcast i16* %125 to <2 x i64>*
  %127 = load <2 x i64>, <2 x i64>* %126, align 16
  store <2 x i64> %127, <2 x i64>* %38, align 16
  %128 = getelementptr inbounds i16, i16* %97, i64 %67
  %129 = bitcast i16* %128 to <2 x i64>*
  %130 = load <2 x i64>, <2 x i64>* %129, align 16
  store <2 x i64> %130, <2 x i64>* %36, align 16
  %131 = getelementptr inbounds i16, i16* %97, i64 %68
  %132 = bitcast i16* %131 to <2 x i64>*
  %133 = load <2 x i64>, <2 x i64>* %132, align 16
  store <2 x i64> %133, <2 x i64>* %34, align 16
  %134 = getelementptr inbounds i16, i16* %97, i64 %69
  %135 = bitcast i16* %134 to <2 x i64>*
  %136 = load <2 x i64>, <2 x i64>* %135, align 16
  store <2 x i64> %136, <2 x i64>* %32, align 16
  %137 = getelementptr inbounds i16, i16* %97, i64 %70
  %138 = bitcast i16* %137 to <2 x i64>*
  %139 = load <2 x i64>, <2 x i64>* %138, align 16
  store <2 x i64> %139, <2 x i64>* %30, align 16
  %140 = getelementptr inbounds i16, i16* %97, i64 %71
  %141 = bitcast i16* %140 to <2 x i64>*
  %142 = load <2 x i64>, <2 x i64>* %141, align 16
  store <2 x i64> %142, <2 x i64>* %28, align 16
  %143 = getelementptr inbounds i16, i16* %97, i64 %72
  %144 = bitcast i16* %143 to <2 x i64>*
  %145 = load <2 x i64>, <2 x i64>* %144, align 16
  store <2 x i64> %145, <2 x i64>* %24, align 16
  br label %192

146:                                              ; preds = %94
  store <2 x i64> %99, <2 x i64>* %24, align 16
  %147 = getelementptr inbounds i16, i16* %97, i64 %25
  %148 = bitcast i16* %147 to <2 x i64>*
  %149 = load <2 x i64>, <2 x i64>* %148, align 16
  store <2 x i64> %149, <2 x i64>* %28, align 16
  %150 = getelementptr inbounds i16, i16* %97, i64 %73
  %151 = bitcast i16* %150 to <2 x i64>*
  %152 = load <2 x i64>, <2 x i64>* %151, align 16
  store <2 x i64> %152, <2 x i64>* %30, align 16
  %153 = getelementptr inbounds i16, i16* %97, i64 %74
  %154 = bitcast i16* %153 to <2 x i64>*
  %155 = load <2 x i64>, <2 x i64>* %154, align 16
  store <2 x i64> %155, <2 x i64>* %32, align 16
  %156 = getelementptr inbounds i16, i16* %97, i64 %75
  %157 = bitcast i16* %156 to <2 x i64>*
  %158 = load <2 x i64>, <2 x i64>* %157, align 16
  store <2 x i64> %158, <2 x i64>* %34, align 16
  %159 = getelementptr inbounds i16, i16* %97, i64 %76
  %160 = bitcast i16* %159 to <2 x i64>*
  %161 = load <2 x i64>, <2 x i64>* %160, align 16
  store <2 x i64> %161, <2 x i64>* %36, align 16
  %162 = getelementptr inbounds i16, i16* %97, i64 %77
  %163 = bitcast i16* %162 to <2 x i64>*
  %164 = load <2 x i64>, <2 x i64>* %163, align 16
  store <2 x i64> %164, <2 x i64>* %38, align 16
  %165 = getelementptr inbounds i16, i16* %97, i64 %78
  %166 = bitcast i16* %165 to <2 x i64>*
  %167 = load <2 x i64>, <2 x i64>* %166, align 16
  store <2 x i64> %167, <2 x i64>* %40, align 16
  %168 = getelementptr inbounds i16, i16* %97, i64 %79
  %169 = bitcast i16* %168 to <2 x i64>*
  %170 = load <2 x i64>, <2 x i64>* %169, align 16
  store <2 x i64> %170, <2 x i64>* %42, align 16
  %171 = getelementptr inbounds i16, i16* %97, i64 %80
  %172 = bitcast i16* %171 to <2 x i64>*
  %173 = load <2 x i64>, <2 x i64>* %172, align 16
  store <2 x i64> %173, <2 x i64>* %45, align 16
  %174 = getelementptr inbounds i16, i16* %97, i64 %81
  %175 = bitcast i16* %174 to <2 x i64>*
  %176 = load <2 x i64>, <2 x i64>* %175, align 16
  store <2 x i64> %176, <2 x i64>* %47, align 16
  %177 = getelementptr inbounds i16, i16* %97, i64 %82
  %178 = bitcast i16* %177 to <2 x i64>*
  %179 = load <2 x i64>, <2 x i64>* %178, align 16
  store <2 x i64> %179, <2 x i64>* %49, align 16
  %180 = getelementptr inbounds i16, i16* %97, i64 %83
  %181 = bitcast i16* %180 to <2 x i64>*
  %182 = load <2 x i64>, <2 x i64>* %181, align 16
  store <2 x i64> %182, <2 x i64>* %51, align 16
  %183 = getelementptr inbounds i16, i16* %97, i64 %84
  %184 = bitcast i16* %183 to <2 x i64>*
  %185 = load <2 x i64>, <2 x i64>* %184, align 16
  store <2 x i64> %185, <2 x i64>* %53, align 16
  %186 = getelementptr inbounds i16, i16* %97, i64 %85
  %187 = bitcast i16* %186 to <2 x i64>*
  %188 = load <2 x i64>, <2 x i64>* %187, align 16
  store <2 x i64> %188, <2 x i64>* %55, align 16
  %189 = getelementptr inbounds i16, i16* %97, i64 %86
  %190 = bitcast i16* %189 to <2 x i64>*
  %191 = load <2 x i64>, <2 x i64>* %190, align 16
  store <2 x i64> %191, <2 x i64>* %57, align 16
  br label %192

192:                                              ; preds = %100, %146
  %193 = phi <2 x i64> [ %106, %100 ], [ %185, %146 ]
  %194 = phi <2 x i64> [ %109, %100 ], [ %182, %146 ]
  %195 = phi <2 x i64> [ %112, %100 ], [ %179, %146 ]
  %196 = phi <2 x i64> [ %115, %100 ], [ %176, %146 ]
  %197 = phi <2 x i64> [ %118, %100 ], [ %173, %146 ]
  %198 = phi <2 x i64> [ %121, %100 ], [ %170, %146 ]
  %199 = phi <2 x i64> [ %124, %100 ], [ %167, %146 ]
  %200 = phi <2 x i64> [ %127, %100 ], [ %164, %146 ]
  %201 = phi <2 x i64> [ %130, %100 ], [ %161, %146 ]
  %202 = phi <2 x i64> [ %133, %100 ], [ %158, %146 ]
  %203 = phi <2 x i64> [ %136, %100 ], [ %155, %146 ]
  %204 = phi <2 x i64> [ %139, %100 ], [ %152, %146 ]
  %205 = phi <2 x i64> [ %142, %100 ], [ %149, %146 ]
  %206 = phi <2 x i64> [ %145, %100 ], [ %99, %146 ]
  %207 = bitcast <2 x i64> %204 to <8 x i16>
  %208 = bitcast <2 x i64> %203 to <8 x i16>
  %209 = bitcast <2 x i64> %202 to <8 x i16>
  %210 = bitcast <2 x i64> %201 to <8 x i16>
  %211 = bitcast <2 x i64> %200 to <8 x i16>
  %212 = bitcast <2 x i64> %199 to <8 x i16>
  %213 = bitcast <2 x i64> %198 to <8 x i16>
  %214 = bitcast <2 x i64> %197 to <8 x i16>
  %215 = bitcast <2 x i64> %196 to <8 x i16>
  %216 = bitcast <2 x i64> %195 to <8 x i16>
  %217 = bitcast <2 x i64> %194 to <8 x i16>
  %218 = bitcast <2 x i64> %193 to <8 x i16>
  %219 = bitcast <2 x i64> %205 to <8 x i16>
  %220 = bitcast <2 x i64> %206 to <8 x i16>
  %221 = load i8, i8* %10, align 1
  %222 = sext i8 %221 to i32
  %223 = icmp slt i8 %221, 0
  br i1 %223, label %224, label %267

224:                                              ; preds = %192
  %225 = sub nsw i32 0, %222
  %226 = xor i32 %222, -1
  %227 = shl i32 1, %226
  %228 = trunc i32 %227 to i16
  %229 = insertelement <8 x i16> undef, i16 %228, i32 0
  %230 = shufflevector <8 x i16> %229, <8 x i16> undef, <8 x i32> zeroinitializer
  %231 = load <8 x i16>, <8 x i16>* %88, align 16
  %232 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %231, <8 x i16> %230) #8
  %233 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %232, i32 %225) #8
  store <8 x i16> %233, <8 x i16>* %88, align 16
  %234 = load <8 x i16>, <8 x i16>* %29, align 16
  %235 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %234, <8 x i16> %230) #8
  %236 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %235, i32 %225) #8
  store <8 x i16> %236, <8 x i16>* %29, align 16
  %237 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %207, <8 x i16> %230) #8
  %238 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %237, i32 %225) #8
  store <8 x i16> %238, <8 x i16>* %31, align 16
  %239 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %208, <8 x i16> %230) #8
  %240 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %239, i32 %225) #8
  store <8 x i16> %240, <8 x i16>* %33, align 16
  %241 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %209, <8 x i16> %230) #8
  %242 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %241, i32 %225) #8
  store <8 x i16> %242, <8 x i16>* %35, align 16
  %243 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %210, <8 x i16> %230) #8
  %244 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %243, i32 %225) #8
  store <8 x i16> %244, <8 x i16>* %37, align 16
  %245 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %211, <8 x i16> %230) #8
  %246 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %245, i32 %225) #8
  store <8 x i16> %246, <8 x i16>* %39, align 16
  %247 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %212, <8 x i16> %230) #8
  %248 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %247, i32 %225) #8
  store <8 x i16> %248, <8 x i16>* %41, align 16
  %249 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %213, <8 x i16> %230) #8
  %250 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %249, i32 %225) #8
  store <8 x i16> %250, <8 x i16>* %44, align 16
  %251 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %214, <8 x i16> %230) #8
  %252 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %251, i32 %225) #8
  store <8 x i16> %252, <8 x i16>* %46, align 16
  %253 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %215, <8 x i16> %230) #8
  %254 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %253, i32 %225) #8
  store <8 x i16> %254, <8 x i16>* %48, align 16
  %255 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %216, <8 x i16> %230) #8
  %256 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %255, i32 %225) #8
  store <8 x i16> %256, <8 x i16>* %50, align 16
  %257 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %217, <8 x i16> %230) #8
  %258 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %257, i32 %225) #8
  store <8 x i16> %258, <8 x i16>* %52, align 16
  %259 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %218, <8 x i16> %230) #8
  %260 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %259, i32 %225) #8
  store <8 x i16> %260, <8 x i16>* %54, align 16
  %261 = load <8 x i16>, <8 x i16>* %56, align 16
  %262 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %261, <8 x i16> %230) #8
  %263 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %262, i32 %225) #8
  store <8 x i16> %263, <8 x i16>* %56, align 16
  %264 = load <8 x i16>, <8 x i16>* %58, align 16
  %265 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %264, <8 x i16> %230) #8
  %266 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %265, i32 %225) #8
  br label %288

267:                                              ; preds = %192
  %268 = icmp eq i8 %221, 0
  br i1 %268, label %290, label %269

269:                                              ; preds = %267
  %270 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %220, i32 %222) #8
  store <8 x i16> %270, <8 x i16>* %87, align 16
  %271 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %219, i32 %222) #8
  store <8 x i16> %271, <8 x i16>* %29, align 16
  %272 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %207, i32 %222) #8
  store <8 x i16> %272, <8 x i16>* %31, align 16
  %273 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %208, i32 %222) #8
  store <8 x i16> %273, <8 x i16>* %33, align 16
  %274 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %209, i32 %222) #8
  store <8 x i16> %274, <8 x i16>* %35, align 16
  %275 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %210, i32 %222) #8
  store <8 x i16> %275, <8 x i16>* %37, align 16
  %276 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %211, i32 %222) #8
  store <8 x i16> %276, <8 x i16>* %39, align 16
  %277 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %212, i32 %222) #8
  store <8 x i16> %277, <8 x i16>* %41, align 16
  %278 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %213, i32 %222) #8
  store <8 x i16> %278, <8 x i16>* %44, align 16
  %279 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %214, i32 %222) #8
  store <8 x i16> %279, <8 x i16>* %46, align 16
  %280 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %215, i32 %222) #8
  store <8 x i16> %280, <8 x i16>* %48, align 16
  %281 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %216, i32 %222) #8
  store <8 x i16> %281, <8 x i16>* %50, align 16
  %282 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %217, i32 %222) #8
  store <8 x i16> %282, <8 x i16>* %52, align 16
  %283 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %218, i32 %222) #8
  store <8 x i16> %283, <8 x i16>* %54, align 16
  %284 = load <8 x i16>, <8 x i16>* %56, align 16
  %285 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %284, i32 %222) #8
  store <8 x i16> %285, <8 x i16>* %56, align 16
  %286 = load <8 x i16>, <8 x i16>* %58, align 16
  %287 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %286, i32 %222) #8
  br label %288

288:                                              ; preds = %224, %269
  %289 = phi <8 x i16> [ %287, %269 ], [ %266, %224 ]
  store <8 x i16> %289, <8 x i16>* %58, align 16
  br label %290

290:                                              ; preds = %288, %267
  call void %15(<2 x i64>* nonnull %24, <2 x i64>* nonnull %24, i8 signext %11) #8
  %291 = load i8, i8* %26, align 1
  %292 = sext i8 %291 to i32
  %293 = icmp slt i8 %291, 0
  br i1 %293, label %294, label %349

294:                                              ; preds = %290
  %295 = sub nsw i32 0, %292
  %296 = xor i32 %292, -1
  %297 = shl i32 1, %296
  %298 = trunc i32 %297 to i16
  %299 = insertelement <8 x i16> undef, i16 %298, i32 0
  %300 = shufflevector <8 x i16> %299, <8 x i16> undef, <8 x i32> zeroinitializer
  %301 = load <8 x i16>, <8 x i16>* %90, align 16
  %302 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %301, <8 x i16> %300) #8
  %303 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %302, i32 %295) #8
  store <8 x i16> %303, <8 x i16>* %90, align 16
  %304 = load <8 x i16>, <8 x i16>* %29, align 16
  %305 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %304, <8 x i16> %300) #8
  %306 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %305, i32 %295) #8
  store <8 x i16> %306, <8 x i16>* %29, align 16
  %307 = load <8 x i16>, <8 x i16>* %31, align 16
  %308 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %307, <8 x i16> %300) #8
  %309 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %308, i32 %295) #8
  store <8 x i16> %309, <8 x i16>* %31, align 16
  %310 = load <8 x i16>, <8 x i16>* %33, align 16
  %311 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %310, <8 x i16> %300) #8
  %312 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %311, i32 %295) #8
  store <8 x i16> %312, <8 x i16>* %33, align 16
  %313 = load <8 x i16>, <8 x i16>* %35, align 16
  %314 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %313, <8 x i16> %300) #8
  %315 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %314, i32 %295) #8
  store <8 x i16> %315, <8 x i16>* %35, align 16
  %316 = load <8 x i16>, <8 x i16>* %37, align 16
  %317 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %316, <8 x i16> %300) #8
  %318 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %317, i32 %295) #8
  store <8 x i16> %318, <8 x i16>* %37, align 16
  %319 = load <8 x i16>, <8 x i16>* %39, align 16
  %320 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %319, <8 x i16> %300) #8
  %321 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %320, i32 %295) #8
  store <8 x i16> %321, <8 x i16>* %39, align 16
  %322 = load <8 x i16>, <8 x i16>* %41, align 16
  %323 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %322, <8 x i16> %300) #8
  %324 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %323, i32 %295) #8
  store <8 x i16> %324, <8 x i16>* %41, align 16
  %325 = load <8 x i16>, <8 x i16>* %44, align 16
  %326 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %325, <8 x i16> %300) #8
  %327 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %326, i32 %295) #8
  store <8 x i16> %327, <8 x i16>* %44, align 16
  %328 = load <8 x i16>, <8 x i16>* %46, align 16
  %329 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %328, <8 x i16> %300) #8
  %330 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %329, i32 %295) #8
  store <8 x i16> %330, <8 x i16>* %46, align 16
  %331 = load <8 x i16>, <8 x i16>* %48, align 16
  %332 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %331, <8 x i16> %300) #8
  %333 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %332, i32 %295) #8
  store <8 x i16> %333, <8 x i16>* %48, align 16
  %334 = load <8 x i16>, <8 x i16>* %50, align 16
  %335 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %334, <8 x i16> %300) #8
  %336 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %335, i32 %295) #8
  store <8 x i16> %336, <8 x i16>* %50, align 16
  %337 = load <8 x i16>, <8 x i16>* %52, align 16
  %338 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %337, <8 x i16> %300) #8
  %339 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %338, i32 %295) #8
  store <8 x i16> %339, <8 x i16>* %52, align 16
  %340 = load <8 x i16>, <8 x i16>* %54, align 16
  %341 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %340, <8 x i16> %300) #8
  %342 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %341, i32 %295) #8
  store <8 x i16> %342, <8 x i16>* %54, align 16
  %343 = load <8 x i16>, <8 x i16>* %56, align 16
  %344 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %343, <8 x i16> %300) #8
  %345 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %344, i32 %295) #8
  store <8 x i16> %345, <8 x i16>* %56, align 16
  %346 = load <8 x i16>, <8 x i16>* %58, align 16
  %347 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %346, <8 x i16> %300) #8
  %348 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %347, i32 %295) #8
  store <8 x i16> %348, <8 x i16>* %58, align 16
  br label %401

349:                                              ; preds = %290
  %350 = icmp eq i8 %291, 0
  br i1 %350, label %351, label %368

351:                                              ; preds = %349
  %352 = load <8 x i16>, <8 x i16>* %27, align 16
  %353 = load <8 x i16>, <8 x i16>* %29, align 16
  %354 = load <8 x i16>, <8 x i16>* %31, align 16
  %355 = load <8 x i16>, <8 x i16>* %33, align 16
  %356 = load <8 x i16>, <8 x i16>* %35, align 16
  %357 = load <8 x i16>, <8 x i16>* %37, align 16
  %358 = load <8 x i16>, <8 x i16>* %39, align 16
  %359 = load <8 x i16>, <8 x i16>* %41, align 16
  %360 = load <8 x i16>, <8 x i16>* %44, align 16
  %361 = load <8 x i16>, <8 x i16>* %46, align 16
  %362 = load <8 x i16>, <8 x i16>* %48, align 16
  %363 = load <8 x i16>, <8 x i16>* %50, align 16
  %364 = load <8 x i16>, <8 x i16>* %52, align 16
  %365 = load <8 x i16>, <8 x i16>* %54, align 16
  %366 = load <8 x i16>, <8 x i16>* %56, align 16
  %367 = load <8 x i16>, <8 x i16>* %58, align 16
  br label %401

368:                                              ; preds = %349
  %369 = load <8 x i16>, <8 x i16>* %89, align 16
  %370 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %369, i32 %292) #8
  store <8 x i16> %370, <8 x i16>* %89, align 16
  %371 = load <8 x i16>, <8 x i16>* %29, align 16
  %372 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %371, i32 %292) #8
  store <8 x i16> %372, <8 x i16>* %29, align 16
  %373 = load <8 x i16>, <8 x i16>* %31, align 16
  %374 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %373, i32 %292) #8
  store <8 x i16> %374, <8 x i16>* %31, align 16
  %375 = load <8 x i16>, <8 x i16>* %33, align 16
  %376 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %375, i32 %292) #8
  store <8 x i16> %376, <8 x i16>* %33, align 16
  %377 = load <8 x i16>, <8 x i16>* %35, align 16
  %378 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %377, i32 %292) #8
  store <8 x i16> %378, <8 x i16>* %35, align 16
  %379 = load <8 x i16>, <8 x i16>* %37, align 16
  %380 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %379, i32 %292) #8
  store <8 x i16> %380, <8 x i16>* %37, align 16
  %381 = load <8 x i16>, <8 x i16>* %39, align 16
  %382 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %381, i32 %292) #8
  store <8 x i16> %382, <8 x i16>* %39, align 16
  %383 = load <8 x i16>, <8 x i16>* %41, align 16
  %384 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %383, i32 %292) #8
  store <8 x i16> %384, <8 x i16>* %41, align 16
  %385 = load <8 x i16>, <8 x i16>* %44, align 16
  %386 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %385, i32 %292) #8
  store <8 x i16> %386, <8 x i16>* %44, align 16
  %387 = load <8 x i16>, <8 x i16>* %46, align 16
  %388 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %387, i32 %292) #8
  store <8 x i16> %388, <8 x i16>* %46, align 16
  %389 = load <8 x i16>, <8 x i16>* %48, align 16
  %390 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %389, i32 %292) #8
  store <8 x i16> %390, <8 x i16>* %48, align 16
  %391 = load <8 x i16>, <8 x i16>* %50, align 16
  %392 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %391, i32 %292) #8
  store <8 x i16> %392, <8 x i16>* %50, align 16
  %393 = load <8 x i16>, <8 x i16>* %52, align 16
  %394 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %393, i32 %292) #8
  store <8 x i16> %394, <8 x i16>* %52, align 16
  %395 = load <8 x i16>, <8 x i16>* %54, align 16
  %396 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %395, i32 %292) #8
  store <8 x i16> %396, <8 x i16>* %54, align 16
  %397 = load <8 x i16>, <8 x i16>* %56, align 16
  %398 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %397, i32 %292) #8
  store <8 x i16> %398, <8 x i16>* %56, align 16
  %399 = load <8 x i16>, <8 x i16>* %58, align 16
  %400 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %399, i32 %292) #8
  store <8 x i16> %400, <8 x i16>* %58, align 16
  br label %401

401:                                              ; preds = %351, %368, %294
  %402 = phi <8 x i16> [ %367, %351 ], [ %400, %368 ], [ %348, %294 ]
  %403 = phi <8 x i16> [ %366, %351 ], [ %398, %368 ], [ %345, %294 ]
  %404 = phi <8 x i16> [ %365, %351 ], [ %396, %368 ], [ %342, %294 ]
  %405 = phi <8 x i16> [ %364, %351 ], [ %394, %368 ], [ %339, %294 ]
  %406 = phi <8 x i16> [ %363, %351 ], [ %392, %368 ], [ %336, %294 ]
  %407 = phi <8 x i16> [ %362, %351 ], [ %390, %368 ], [ %333, %294 ]
  %408 = phi <8 x i16> [ %361, %351 ], [ %388, %368 ], [ %330, %294 ]
  %409 = phi <8 x i16> [ %360, %351 ], [ %386, %368 ], [ %327, %294 ]
  %410 = phi <8 x i16> [ %359, %351 ], [ %384, %368 ], [ %324, %294 ]
  %411 = phi <8 x i16> [ %358, %351 ], [ %382, %368 ], [ %321, %294 ]
  %412 = phi <8 x i16> [ %357, %351 ], [ %380, %368 ], [ %318, %294 ]
  %413 = phi <8 x i16> [ %356, %351 ], [ %378, %368 ], [ %315, %294 ]
  %414 = phi <8 x i16> [ %355, %351 ], [ %376, %368 ], [ %312, %294 ]
  %415 = phi <8 x i16> [ %354, %351 ], [ %374, %368 ], [ %309, %294 ]
  %416 = phi <8 x i16> [ %353, %351 ], [ %372, %368 ], [ %306, %294 ]
  %417 = phi <8 x i16> [ %352, %351 ], [ %370, %368 ], [ %303, %294 ]
  %418 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 %96
  %419 = shufflevector <8 x i16> %417, <8 x i16> %416, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %420 = shufflevector <8 x i16> %415, <8 x i16> %414, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %421 = shufflevector <8 x i16> %413, <8 x i16> %412, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %422 = shufflevector <8 x i16> %411, <8 x i16> %410, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %423 = shufflevector <8 x i16> %417, <8 x i16> %416, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %424 = shufflevector <8 x i16> %415, <8 x i16> %414, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %425 = shufflevector <8 x i16> %413, <8 x i16> %412, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %426 = shufflevector <8 x i16> %411, <8 x i16> %410, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %427 = bitcast <8 x i16> %419 to <4 x i32>
  %428 = bitcast <8 x i16> %420 to <4 x i32>
  %429 = shufflevector <4 x i32> %427, <4 x i32> %428, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %430 = bitcast <4 x i32> %429 to <2 x i64>
  %431 = bitcast <8 x i16> %421 to <4 x i32>
  %432 = bitcast <8 x i16> %422 to <4 x i32>
  %433 = shufflevector <4 x i32> %431, <4 x i32> %432, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %434 = bitcast <4 x i32> %433 to <2 x i64>
  %435 = bitcast <8 x i16> %423 to <4 x i32>
  %436 = bitcast <8 x i16> %424 to <4 x i32>
  %437 = shufflevector <4 x i32> %435, <4 x i32> %436, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %438 = bitcast <4 x i32> %437 to <2 x i64>
  %439 = bitcast <8 x i16> %425 to <4 x i32>
  %440 = bitcast <8 x i16> %426 to <4 x i32>
  %441 = shufflevector <4 x i32> %439, <4 x i32> %440, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %442 = bitcast <4 x i32> %441 to <2 x i64>
  %443 = shufflevector <4 x i32> %427, <4 x i32> %428, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %444 = bitcast <4 x i32> %443 to <2 x i64>
  %445 = shufflevector <4 x i32> %431, <4 x i32> %432, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %446 = bitcast <4 x i32> %445 to <2 x i64>
  %447 = shufflevector <4 x i32> %435, <4 x i32> %436, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %448 = bitcast <4 x i32> %447 to <2 x i64>
  %449 = shufflevector <4 x i32> %439, <4 x i32> %440, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %450 = bitcast <4 x i32> %449 to <2 x i64>
  %451 = shufflevector <2 x i64> %430, <2 x i64> %434, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %451, <2 x i64>* %418, align 16
  %452 = shufflevector <2 x i64> %430, <2 x i64> %434, <2 x i32> <i32 1, i32 3>
  %453 = getelementptr inbounds <2 x i64>, <2 x i64>* %418, i64 1
  store <2 x i64> %452, <2 x i64>* %453, align 16
  %454 = shufflevector <2 x i64> %444, <2 x i64> %446, <2 x i32> <i32 0, i32 2>
  %455 = getelementptr inbounds <2 x i64>, <2 x i64>* %418, i64 2
  store <2 x i64> %454, <2 x i64>* %455, align 16
  %456 = shufflevector <2 x i64> %444, <2 x i64> %446, <2 x i32> <i32 1, i32 3>
  %457 = getelementptr inbounds <2 x i64>, <2 x i64>* %418, i64 3
  store <2 x i64> %456, <2 x i64>* %457, align 16
  %458 = shufflevector <2 x i64> %438, <2 x i64> %442, <2 x i32> <i32 0, i32 2>
  %459 = getelementptr inbounds <2 x i64>, <2 x i64>* %418, i64 4
  store <2 x i64> %458, <2 x i64>* %459, align 16
  %460 = shufflevector <2 x i64> %438, <2 x i64> %442, <2 x i32> <i32 1, i32 3>
  %461 = getelementptr inbounds <2 x i64>, <2 x i64>* %418, i64 5
  store <2 x i64> %460, <2 x i64>* %461, align 16
  %462 = shufflevector <2 x i64> %448, <2 x i64> %450, <2 x i32> <i32 0, i32 2>
  %463 = getelementptr inbounds <2 x i64>, <2 x i64>* %418, i64 6
  store <2 x i64> %462, <2 x i64>* %463, align 16
  %464 = shufflevector <2 x i64> %448, <2 x i64> %450, <2 x i32> <i32 1, i32 3>
  %465 = getelementptr inbounds <2 x i64>, <2 x i64>* %418, i64 7
  store <2 x i64> %464, <2 x i64>* %465, align 16
  %466 = getelementptr inbounds <2 x i64>, <2 x i64>* %43, i64 %96
  %467 = shufflevector <8 x i16> %409, <8 x i16> %408, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %468 = shufflevector <8 x i16> %407, <8 x i16> %406, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %469 = shufflevector <8 x i16> %405, <8 x i16> %404, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %470 = shufflevector <8 x i16> %403, <8 x i16> %402, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %471 = shufflevector <8 x i16> %409, <8 x i16> %408, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %472 = shufflevector <8 x i16> %407, <8 x i16> %406, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %473 = shufflevector <8 x i16> %405, <8 x i16> %404, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %474 = shufflevector <8 x i16> %403, <8 x i16> %402, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %475 = bitcast <8 x i16> %467 to <4 x i32>
  %476 = bitcast <8 x i16> %468 to <4 x i32>
  %477 = shufflevector <4 x i32> %475, <4 x i32> %476, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %478 = bitcast <4 x i32> %477 to <2 x i64>
  %479 = bitcast <8 x i16> %469 to <4 x i32>
  %480 = bitcast <8 x i16> %470 to <4 x i32>
  %481 = shufflevector <4 x i32> %479, <4 x i32> %480, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %482 = bitcast <4 x i32> %481 to <2 x i64>
  %483 = bitcast <8 x i16> %471 to <4 x i32>
  %484 = bitcast <8 x i16> %472 to <4 x i32>
  %485 = shufflevector <4 x i32> %483, <4 x i32> %484, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %486 = bitcast <4 x i32> %485 to <2 x i64>
  %487 = bitcast <8 x i16> %473 to <4 x i32>
  %488 = bitcast <8 x i16> %474 to <4 x i32>
  %489 = shufflevector <4 x i32> %487, <4 x i32> %488, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %490 = bitcast <4 x i32> %489 to <2 x i64>
  %491 = shufflevector <4 x i32> %475, <4 x i32> %476, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %492 = bitcast <4 x i32> %491 to <2 x i64>
  %493 = shufflevector <4 x i32> %479, <4 x i32> %480, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %494 = bitcast <4 x i32> %493 to <2 x i64>
  %495 = shufflevector <4 x i32> %483, <4 x i32> %484, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %496 = bitcast <4 x i32> %495 to <2 x i64>
  %497 = shufflevector <4 x i32> %487, <4 x i32> %488, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %498 = bitcast <4 x i32> %497 to <2 x i64>
  %499 = shufflevector <2 x i64> %478, <2 x i64> %482, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %499, <2 x i64>* %466, align 16
  %500 = shufflevector <2 x i64> %478, <2 x i64> %482, <2 x i32> <i32 1, i32 3>
  %501 = getelementptr inbounds <2 x i64>, <2 x i64>* %466, i64 1
  store <2 x i64> %500, <2 x i64>* %501, align 16
  %502 = shufflevector <2 x i64> %492, <2 x i64> %494, <2 x i32> <i32 0, i32 2>
  %503 = getelementptr inbounds <2 x i64>, <2 x i64>* %466, i64 2
  store <2 x i64> %502, <2 x i64>* %503, align 16
  %504 = shufflevector <2 x i64> %492, <2 x i64> %494, <2 x i32> <i32 1, i32 3>
  %505 = getelementptr inbounds <2 x i64>, <2 x i64>* %466, i64 3
  store <2 x i64> %504, <2 x i64>* %505, align 16
  %506 = shufflevector <2 x i64> %486, <2 x i64> %490, <2 x i32> <i32 0, i32 2>
  %507 = getelementptr inbounds <2 x i64>, <2 x i64>* %466, i64 4
  store <2 x i64> %506, <2 x i64>* %507, align 16
  %508 = shufflevector <2 x i64> %486, <2 x i64> %490, <2 x i32> <i32 1, i32 3>
  %509 = getelementptr inbounds <2 x i64>, <2 x i64>* %466, i64 5
  store <2 x i64> %508, <2 x i64>* %509, align 16
  %510 = shufflevector <2 x i64> %496, <2 x i64> %498, <2 x i32> <i32 0, i32 2>
  %511 = getelementptr inbounds <2 x i64>, <2 x i64>* %466, i64 6
  store <2 x i64> %510, <2 x i64>* %511, align 16
  %512 = shufflevector <2 x i64> %496, <2 x i64> %498, <2 x i32> <i32 1, i32 3>
  %513 = getelementptr inbounds <2 x i64>, <2 x i64>* %466, i64 7
  store <2 x i64> %512, <2 x i64>* %513, align 16
  %514 = add nuw nsw i64 %95, 1
  %515 = icmp eq i64 %514, 2
  br i1 %515, label %91, label %94

516:                                              ; preds = %732
  call void @llvm.lifetime.end.p0i8(i64 512, i8* nonnull %9) #8
  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %8) #8
  ret void

517:                                              ; preds = %732, %91
  %518 = phi i64 [ 0, %91 ], [ %1032, %732 ]
  %519 = shl nsw i64 %518, 4
  %520 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 %519
  br i1 %92, label %553, label %521

521:                                              ; preds = %517
  %522 = load <2 x i64>, <2 x i64>* %520, align 16
  store <2 x i64> %522, <2 x i64>* %57, align 16
  %523 = getelementptr inbounds <2 x i64>, <2 x i64>* %520, i64 1
  %524 = load <2 x i64>, <2 x i64>* %523, align 16
  store <2 x i64> %524, <2 x i64>* %55, align 16
  %525 = getelementptr inbounds <2 x i64>, <2 x i64>* %520, i64 2
  %526 = load <2 x i64>, <2 x i64>* %525, align 16
  store <2 x i64> %526, <2 x i64>* %53, align 16
  %527 = getelementptr inbounds <2 x i64>, <2 x i64>* %520, i64 3
  %528 = load <2 x i64>, <2 x i64>* %527, align 16
  store <2 x i64> %528, <2 x i64>* %51, align 16
  %529 = getelementptr inbounds <2 x i64>, <2 x i64>* %520, i64 4
  %530 = load <2 x i64>, <2 x i64>* %529, align 16
  store <2 x i64> %530, <2 x i64>* %49, align 16
  %531 = getelementptr inbounds <2 x i64>, <2 x i64>* %520, i64 5
  %532 = load <2 x i64>, <2 x i64>* %531, align 16
  store <2 x i64> %532, <2 x i64>* %47, align 16
  %533 = getelementptr inbounds <2 x i64>, <2 x i64>* %520, i64 6
  %534 = load <2 x i64>, <2 x i64>* %533, align 16
  store <2 x i64> %534, <2 x i64>* %45, align 16
  %535 = getelementptr inbounds <2 x i64>, <2 x i64>* %520, i64 7
  %536 = load <2 x i64>, <2 x i64>* %535, align 16
  store <2 x i64> %536, <2 x i64>* %42, align 16
  %537 = getelementptr inbounds <2 x i64>, <2 x i64>* %520, i64 8
  %538 = load <2 x i64>, <2 x i64>* %537, align 16
  store <2 x i64> %538, <2 x i64>* %40, align 16
  %539 = getelementptr inbounds <2 x i64>, <2 x i64>* %520, i64 9
  %540 = load <2 x i64>, <2 x i64>* %539, align 16
  store <2 x i64> %540, <2 x i64>* %38, align 16
  %541 = getelementptr inbounds <2 x i64>, <2 x i64>* %520, i64 10
  %542 = load <2 x i64>, <2 x i64>* %541, align 16
  store <2 x i64> %542, <2 x i64>* %36, align 16
  %543 = getelementptr inbounds <2 x i64>, <2 x i64>* %520, i64 11
  %544 = load <2 x i64>, <2 x i64>* %543, align 16
  store <2 x i64> %544, <2 x i64>* %34, align 16
  %545 = getelementptr inbounds <2 x i64>, <2 x i64>* %520, i64 12
  %546 = load <2 x i64>, <2 x i64>* %545, align 16
  store <2 x i64> %546, <2 x i64>* %32, align 16
  %547 = getelementptr inbounds <2 x i64>, <2 x i64>* %520, i64 13
  %548 = load <2 x i64>, <2 x i64>* %547, align 16
  store <2 x i64> %548, <2 x i64>* %30, align 16
  %549 = getelementptr inbounds <2 x i64>, <2 x i64>* %520, i64 14
  %550 = load <2 x i64>, <2 x i64>* %549, align 16
  store <2 x i64> %550, <2 x i64>* %28, align 16
  %551 = getelementptr inbounds <2 x i64>, <2 x i64>* %520, i64 15
  %552 = load <2 x i64>, <2 x i64>* %551, align 16
  store <2 x i64> %552, <2 x i64>* %24, align 16
  br label %553

553:                                              ; preds = %521, %517
  %554 = phi <2 x i64>* [ %520, %517 ], [ %24, %521 ]
  call void %17(<2 x i64>* %554, <2 x i64>* %554, i8 signext %12) #8
  %555 = load i8, i8* %93, align 1
  %556 = sext i8 %555 to i32
  %557 = icmp slt i8 %555, 0
  br i1 %557, label %558, label %644

558:                                              ; preds = %553
  %559 = sub nsw i32 0, %556
  %560 = xor i32 %556, -1
  %561 = shl i32 1, %560
  %562 = trunc i32 %561 to i16
  %563 = insertelement <8 x i16> undef, i16 %562, i32 0
  %564 = shufflevector <8 x i16> %563, <8 x i16> undef, <8 x i32> zeroinitializer
  %565 = bitcast <2 x i64>* %554 to <8 x i16>*
  %566 = load <8 x i16>, <8 x i16>* %565, align 16
  %567 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %566, <8 x i16> %564) #8
  %568 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %567, i32 %559) #8
  store <8 x i16> %568, <8 x i16>* %565, align 16
  %569 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 1
  %570 = bitcast <2 x i64>* %569 to <8 x i16>*
  %571 = load <8 x i16>, <8 x i16>* %570, align 16
  %572 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %571, <8 x i16> %564) #8
  %573 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %572, i32 %559) #8
  store <8 x i16> %573, <8 x i16>* %570, align 16
  %574 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 2
  %575 = bitcast <2 x i64>* %574 to <8 x i16>*
  %576 = load <8 x i16>, <8 x i16>* %575, align 16
  %577 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %576, <8 x i16> %564) #8
  %578 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %577, i32 %559) #8
  store <8 x i16> %578, <8 x i16>* %575, align 16
  %579 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 3
  %580 = bitcast <2 x i64>* %579 to <8 x i16>*
  %581 = load <8 x i16>, <8 x i16>* %580, align 16
  %582 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %581, <8 x i16> %564) #8
  %583 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %582, i32 %559) #8
  store <8 x i16> %583, <8 x i16>* %580, align 16
  %584 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 4
  %585 = bitcast <2 x i64>* %584 to <8 x i16>*
  %586 = load <8 x i16>, <8 x i16>* %585, align 16
  %587 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %586, <8 x i16> %564) #8
  %588 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %587, i32 %559) #8
  store <8 x i16> %588, <8 x i16>* %585, align 16
  %589 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 5
  %590 = bitcast <2 x i64>* %589 to <8 x i16>*
  %591 = load <8 x i16>, <8 x i16>* %590, align 16
  %592 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %591, <8 x i16> %564) #8
  %593 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %592, i32 %559) #8
  store <8 x i16> %593, <8 x i16>* %590, align 16
  %594 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 6
  %595 = bitcast <2 x i64>* %594 to <8 x i16>*
  %596 = load <8 x i16>, <8 x i16>* %595, align 16
  %597 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %596, <8 x i16> %564) #8
  %598 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %597, i32 %559) #8
  store <8 x i16> %598, <8 x i16>* %595, align 16
  %599 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 7
  %600 = bitcast <2 x i64>* %599 to <8 x i16>*
  %601 = load <8 x i16>, <8 x i16>* %600, align 16
  %602 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %601, <8 x i16> %564) #8
  %603 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %602, i32 %559) #8
  store <8 x i16> %603, <8 x i16>* %600, align 16
  %604 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 8
  %605 = bitcast <2 x i64>* %604 to <8 x i16>*
  %606 = load <8 x i16>, <8 x i16>* %605, align 16
  %607 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %606, <8 x i16> %564) #8
  %608 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %607, i32 %559) #8
  store <8 x i16> %608, <8 x i16>* %605, align 16
  %609 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 9
  %610 = bitcast <2 x i64>* %609 to <8 x i16>*
  %611 = load <8 x i16>, <8 x i16>* %610, align 16
  %612 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %611, <8 x i16> %564) #8
  %613 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %612, i32 %559) #8
  store <8 x i16> %613, <8 x i16>* %610, align 16
  %614 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 10
  %615 = bitcast <2 x i64>* %614 to <8 x i16>*
  %616 = load <8 x i16>, <8 x i16>* %615, align 16
  %617 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %616, <8 x i16> %564) #8
  %618 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %617, i32 %559) #8
  store <8 x i16> %618, <8 x i16>* %615, align 16
  %619 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 11
  %620 = bitcast <2 x i64>* %619 to <8 x i16>*
  %621 = load <8 x i16>, <8 x i16>* %620, align 16
  %622 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %621, <8 x i16> %564) #8
  %623 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %622, i32 %559) #8
  store <8 x i16> %623, <8 x i16>* %620, align 16
  %624 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 12
  %625 = bitcast <2 x i64>* %624 to <8 x i16>*
  %626 = load <8 x i16>, <8 x i16>* %625, align 16
  %627 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %626, <8 x i16> %564) #8
  %628 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %627, i32 %559) #8
  store <8 x i16> %628, <8 x i16>* %625, align 16
  %629 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 13
  %630 = bitcast <2 x i64>* %629 to <8 x i16>*
  %631 = load <8 x i16>, <8 x i16>* %630, align 16
  %632 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %631, <8 x i16> %564) #8
  %633 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %632, i32 %559) #8
  store <8 x i16> %633, <8 x i16>* %630, align 16
  %634 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 14
  %635 = bitcast <2 x i64>* %634 to <8 x i16>*
  %636 = load <8 x i16>, <8 x i16>* %635, align 16
  %637 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %636, <8 x i16> %564) #8
  %638 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %637, i32 %559) #8
  store <8 x i16> %638, <8 x i16>* %635, align 16
  %639 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 15
  %640 = bitcast <2 x i64>* %639 to <8 x i16>*
  %641 = load <8 x i16>, <8 x i16>* %640, align 16
  %642 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %641, <8 x i16> %564) #8
  %643 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %642, i32 %559) #8
  store <8 x i16> %643, <8 x i16>* %640, align 16
  br label %732

644:                                              ; preds = %553
  %645 = icmp eq i8 %555, 0
  %646 = bitcast <2 x i64>* %554 to <8 x i16>*
  %647 = load <8 x i16>, <8 x i16>* %646, align 16
  br i1 %645, label %648, label %670

648:                                              ; preds = %644
  %649 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 1
  %650 = bitcast <2 x i64>* %649 to <8 x i16>*
  %651 = load <8 x i16>, <8 x i16>* %650, align 16
  %652 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 2
  %653 = bitcast <2 x i64>* %652 to <8 x i16>*
  %654 = load <8 x i16>, <8 x i16>* %653, align 16
  %655 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 3
  %656 = bitcast <2 x i64>* %655 to <8 x i16>*
  %657 = load <8 x i16>, <8 x i16>* %656, align 16
  %658 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 4
  %659 = bitcast <2 x i64>* %658 to <8 x i16>*
  %660 = load <8 x i16>, <8 x i16>* %659, align 16
  %661 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 5
  %662 = bitcast <2 x i64>* %661 to <8 x i16>*
  %663 = load <8 x i16>, <8 x i16>* %662, align 16
  %664 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 6
  %665 = bitcast <2 x i64>* %664 to <8 x i16>*
  %666 = load <8 x i16>, <8 x i16>* %665, align 16
  %667 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 7
  %668 = bitcast <2 x i64>* %667 to <8 x i16>*
  %669 = load <8 x i16>, <8 x i16>* %668, align 16
  br label %732

670:                                              ; preds = %644
  %671 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %647, i32 %556) #8
  store <8 x i16> %671, <8 x i16>* %646, align 16
  %672 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 1
  %673 = bitcast <2 x i64>* %672 to <8 x i16>*
  %674 = load <8 x i16>, <8 x i16>* %673, align 16
  %675 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %674, i32 %556) #8
  store <8 x i16> %675, <8 x i16>* %673, align 16
  %676 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 2
  %677 = bitcast <2 x i64>* %676 to <8 x i16>*
  %678 = load <8 x i16>, <8 x i16>* %677, align 16
  %679 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %678, i32 %556) #8
  store <8 x i16> %679, <8 x i16>* %677, align 16
  %680 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 3
  %681 = bitcast <2 x i64>* %680 to <8 x i16>*
  %682 = load <8 x i16>, <8 x i16>* %681, align 16
  %683 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %682, i32 %556) #8
  store <8 x i16> %683, <8 x i16>* %681, align 16
  %684 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 4
  %685 = bitcast <2 x i64>* %684 to <8 x i16>*
  %686 = load <8 x i16>, <8 x i16>* %685, align 16
  %687 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %686, i32 %556) #8
  store <8 x i16> %687, <8 x i16>* %685, align 16
  %688 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 5
  %689 = bitcast <2 x i64>* %688 to <8 x i16>*
  %690 = load <8 x i16>, <8 x i16>* %689, align 16
  %691 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %690, i32 %556) #8
  store <8 x i16> %691, <8 x i16>* %689, align 16
  %692 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 6
  %693 = bitcast <2 x i64>* %692 to <8 x i16>*
  %694 = load <8 x i16>, <8 x i16>* %693, align 16
  %695 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %694, i32 %556) #8
  store <8 x i16> %695, <8 x i16>* %693, align 16
  %696 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 7
  %697 = bitcast <2 x i64>* %696 to <8 x i16>*
  %698 = load <8 x i16>, <8 x i16>* %697, align 16
  %699 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %698, i32 %556) #8
  store <8 x i16> %699, <8 x i16>* %697, align 16
  %700 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 8
  %701 = bitcast <2 x i64>* %700 to <8 x i16>*
  %702 = load <8 x i16>, <8 x i16>* %701, align 16
  %703 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %702, i32 %556) #8
  store <8 x i16> %703, <8 x i16>* %701, align 16
  %704 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 9
  %705 = bitcast <2 x i64>* %704 to <8 x i16>*
  %706 = load <8 x i16>, <8 x i16>* %705, align 16
  %707 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %706, i32 %556) #8
  store <8 x i16> %707, <8 x i16>* %705, align 16
  %708 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 10
  %709 = bitcast <2 x i64>* %708 to <8 x i16>*
  %710 = load <8 x i16>, <8 x i16>* %709, align 16
  %711 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %710, i32 %556) #8
  store <8 x i16> %711, <8 x i16>* %709, align 16
  %712 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 11
  %713 = bitcast <2 x i64>* %712 to <8 x i16>*
  %714 = load <8 x i16>, <8 x i16>* %713, align 16
  %715 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %714, i32 %556) #8
  store <8 x i16> %715, <8 x i16>* %713, align 16
  %716 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 12
  %717 = bitcast <2 x i64>* %716 to <8 x i16>*
  %718 = load <8 x i16>, <8 x i16>* %717, align 16
  %719 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %718, i32 %556) #8
  store <8 x i16> %719, <8 x i16>* %717, align 16
  %720 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 13
  %721 = bitcast <2 x i64>* %720 to <8 x i16>*
  %722 = load <8 x i16>, <8 x i16>* %721, align 16
  %723 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %722, i32 %556) #8
  store <8 x i16> %723, <8 x i16>* %721, align 16
  %724 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 14
  %725 = bitcast <2 x i64>* %724 to <8 x i16>*
  %726 = load <8 x i16>, <8 x i16>* %725, align 16
  %727 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %726, i32 %556) #8
  store <8 x i16> %727, <8 x i16>* %725, align 16
  %728 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 15
  %729 = bitcast <2 x i64>* %728 to <8 x i16>*
  %730 = load <8 x i16>, <8 x i16>* %729, align 16
  %731 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %730, i32 %556) #8
  store <8 x i16> %731, <8 x i16>* %729, align 16
  br label %732

732:                                              ; preds = %648, %670, %558
  %733 = phi <8 x i16>* [ %668, %648 ], [ %697, %670 ], [ %600, %558 ]
  %734 = phi <8 x i16> [ %669, %648 ], [ %699, %670 ], [ %603, %558 ]
  %735 = phi <8 x i16> [ %666, %648 ], [ %695, %670 ], [ %598, %558 ]
  %736 = phi <8 x i16> [ %663, %648 ], [ %691, %670 ], [ %593, %558 ]
  %737 = phi <8 x i16> [ %660, %648 ], [ %687, %670 ], [ %588, %558 ]
  %738 = phi <8 x i16> [ %657, %648 ], [ %683, %670 ], [ %583, %558 ]
  %739 = phi <8 x i16> [ %654, %648 ], [ %679, %670 ], [ %578, %558 ]
  %740 = phi <8 x i16> [ %651, %648 ], [ %675, %670 ], [ %573, %558 ]
  %741 = phi <8 x i16> [ %647, %648 ], [ %671, %670 ], [ %568, %558 ]
  %742 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 1
  %743 = shufflevector <8 x i16> %741, <8 x i16> %740, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %744 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 2
  %745 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 3
  %746 = shufflevector <8 x i16> %739, <8 x i16> %738, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %747 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 4
  %748 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 5
  %749 = shufflevector <8 x i16> %737, <8 x i16> %736, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %750 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 6
  %751 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 7
  %752 = shufflevector <8 x i16> %735, <8 x i16> %734, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %753 = shufflevector <8 x i16> %741, <8 x i16> %740, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %754 = shufflevector <8 x i16> %739, <8 x i16> %738, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %755 = shufflevector <8 x i16> %737, <8 x i16> %736, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %756 = shufflevector <8 x i16> %735, <8 x i16> %734, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %757 = bitcast <8 x i16> %743 to <4 x i32>
  %758 = bitcast <8 x i16> %746 to <4 x i32>
  %759 = shufflevector <4 x i32> %757, <4 x i32> %758, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %760 = bitcast <4 x i32> %759 to <2 x i64>
  %761 = bitcast <8 x i16> %749 to <4 x i32>
  %762 = bitcast <8 x i16> %752 to <4 x i32>
  %763 = shufflevector <4 x i32> %761, <4 x i32> %762, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %764 = bitcast <4 x i32> %763 to <2 x i64>
  %765 = bitcast <8 x i16> %753 to <4 x i32>
  %766 = bitcast <8 x i16> %754 to <4 x i32>
  %767 = shufflevector <4 x i32> %765, <4 x i32> %766, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %768 = bitcast <4 x i32> %767 to <2 x i64>
  %769 = bitcast <8 x i16> %755 to <4 x i32>
  %770 = bitcast <8 x i16> %756 to <4 x i32>
  %771 = shufflevector <4 x i32> %769, <4 x i32> %770, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %772 = bitcast <4 x i32> %771 to <2 x i64>
  %773 = shufflevector <4 x i32> %757, <4 x i32> %758, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %774 = bitcast <4 x i32> %773 to <2 x i64>
  %775 = shufflevector <4 x i32> %761, <4 x i32> %762, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %776 = bitcast <4 x i32> %775 to <2 x i64>
  %777 = shufflevector <4 x i32> %765, <4 x i32> %766, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %778 = bitcast <4 x i32> %777 to <2 x i64>
  %779 = shufflevector <4 x i32> %769, <4 x i32> %770, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %780 = bitcast <4 x i32> %779 to <2 x i64>
  %781 = shufflevector <2 x i64> %760, <2 x i64> %764, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %781, <2 x i64>* %554, align 16
  %782 = shufflevector <2 x i64> %760, <2 x i64> %764, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %782, <2 x i64>* %742, align 16
  %783 = shufflevector <2 x i64> %774, <2 x i64> %776, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %783, <2 x i64>* %744, align 16
  %784 = shufflevector <2 x i64> %774, <2 x i64> %776, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %784, <2 x i64>* %745, align 16
  %785 = shufflevector <2 x i64> %768, <2 x i64> %772, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %785, <2 x i64>* %747, align 16
  %786 = shufflevector <2 x i64> %768, <2 x i64> %772, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %786, <2 x i64>* %748, align 16
  %787 = shufflevector <2 x i64> %778, <2 x i64> %780, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %787, <2 x i64>* %750, align 16
  %788 = shufflevector <2 x i64> %778, <2 x i64> %780, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %788, <2 x i64>* %751, align 16
  %789 = shl nsw i64 %518, 7
  %790 = getelementptr inbounds i32, i32* %1, i64 %789
  %791 = bitcast <2 x i64> %781 to <8 x i16>
  %792 = shufflevector <8 x i16> %791, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %793 = shufflevector <8 x i16> %791, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %794 = bitcast <8 x i16> %792 to <4 x i32>
  %795 = ashr <4 x i32> %794, <i32 16, i32 16, i32 16, i32 16>
  %796 = bitcast <8 x i16> %793 to <4 x i32>
  %797 = ashr <4 x i32> %796, <i32 16, i32 16, i32 16, i32 16>
  %798 = bitcast i32* %790 to <4 x i32>*
  store <4 x i32> %795, <4 x i32>* %798, align 16
  %799 = getelementptr inbounds i32, i32* %790, i64 4
  %800 = bitcast i32* %799 to <4 x i32>*
  store <4 x i32> %797, <4 x i32>* %800, align 16
  %801 = bitcast <2 x i64> %782 to <8 x i16>
  %802 = getelementptr inbounds i32, i32* %790, i64 16
  %803 = shufflevector <8 x i16> %801, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %804 = shufflevector <8 x i16> %801, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %805 = bitcast <8 x i16> %803 to <4 x i32>
  %806 = ashr <4 x i32> %805, <i32 16, i32 16, i32 16, i32 16>
  %807 = bitcast <8 x i16> %804 to <4 x i32>
  %808 = ashr <4 x i32> %807, <i32 16, i32 16, i32 16, i32 16>
  %809 = bitcast i32* %802 to <4 x i32>*
  store <4 x i32> %806, <4 x i32>* %809, align 16
  %810 = getelementptr inbounds i32, i32* %802, i64 4
  %811 = bitcast i32* %810 to <4 x i32>*
  store <4 x i32> %808, <4 x i32>* %811, align 16
  %812 = bitcast <2 x i64> %783 to <8 x i16>
  %813 = getelementptr inbounds i32, i32* %790, i64 32
  %814 = shufflevector <8 x i16> %812, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %815 = shufflevector <8 x i16> %812, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %816 = bitcast <8 x i16> %814 to <4 x i32>
  %817 = ashr <4 x i32> %816, <i32 16, i32 16, i32 16, i32 16>
  %818 = bitcast <8 x i16> %815 to <4 x i32>
  %819 = ashr <4 x i32> %818, <i32 16, i32 16, i32 16, i32 16>
  %820 = bitcast i32* %813 to <4 x i32>*
  store <4 x i32> %817, <4 x i32>* %820, align 16
  %821 = getelementptr inbounds i32, i32* %813, i64 4
  %822 = bitcast i32* %821 to <4 x i32>*
  store <4 x i32> %819, <4 x i32>* %822, align 16
  %823 = bitcast <2 x i64> %784 to <8 x i16>
  %824 = getelementptr inbounds i32, i32* %790, i64 48
  %825 = shufflevector <8 x i16> %823, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %826 = shufflevector <8 x i16> %823, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %827 = bitcast <8 x i16> %825 to <4 x i32>
  %828 = ashr <4 x i32> %827, <i32 16, i32 16, i32 16, i32 16>
  %829 = bitcast <8 x i16> %826 to <4 x i32>
  %830 = ashr <4 x i32> %829, <i32 16, i32 16, i32 16, i32 16>
  %831 = bitcast i32* %824 to <4 x i32>*
  store <4 x i32> %828, <4 x i32>* %831, align 16
  %832 = getelementptr inbounds i32, i32* %824, i64 4
  %833 = bitcast i32* %832 to <4 x i32>*
  store <4 x i32> %830, <4 x i32>* %833, align 16
  %834 = bitcast <2 x i64> %785 to <8 x i16>
  %835 = getelementptr inbounds i32, i32* %790, i64 64
  %836 = shufflevector <8 x i16> %834, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %837 = shufflevector <8 x i16> %834, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %838 = bitcast <8 x i16> %836 to <4 x i32>
  %839 = ashr <4 x i32> %838, <i32 16, i32 16, i32 16, i32 16>
  %840 = bitcast <8 x i16> %837 to <4 x i32>
  %841 = ashr <4 x i32> %840, <i32 16, i32 16, i32 16, i32 16>
  %842 = bitcast i32* %835 to <4 x i32>*
  store <4 x i32> %839, <4 x i32>* %842, align 16
  %843 = getelementptr inbounds i32, i32* %835, i64 4
  %844 = bitcast i32* %843 to <4 x i32>*
  store <4 x i32> %841, <4 x i32>* %844, align 16
  %845 = bitcast <2 x i64> %786 to <8 x i16>
  %846 = getelementptr inbounds i32, i32* %790, i64 80
  %847 = shufflevector <8 x i16> %845, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %848 = shufflevector <8 x i16> %845, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %849 = bitcast <8 x i16> %847 to <4 x i32>
  %850 = ashr <4 x i32> %849, <i32 16, i32 16, i32 16, i32 16>
  %851 = bitcast <8 x i16> %848 to <4 x i32>
  %852 = ashr <4 x i32> %851, <i32 16, i32 16, i32 16, i32 16>
  %853 = bitcast i32* %846 to <4 x i32>*
  store <4 x i32> %850, <4 x i32>* %853, align 16
  %854 = getelementptr inbounds i32, i32* %846, i64 4
  %855 = bitcast i32* %854 to <4 x i32>*
  store <4 x i32> %852, <4 x i32>* %855, align 16
  %856 = bitcast <2 x i64> %787 to <8 x i16>
  %857 = getelementptr inbounds i32, i32* %790, i64 96
  %858 = shufflevector <8 x i16> %856, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %859 = shufflevector <8 x i16> %856, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %860 = bitcast <8 x i16> %858 to <4 x i32>
  %861 = ashr <4 x i32> %860, <i32 16, i32 16, i32 16, i32 16>
  %862 = bitcast <8 x i16> %859 to <4 x i32>
  %863 = ashr <4 x i32> %862, <i32 16, i32 16, i32 16, i32 16>
  %864 = bitcast i32* %857 to <4 x i32>*
  store <4 x i32> %861, <4 x i32>* %864, align 16
  %865 = getelementptr inbounds i32, i32* %857, i64 4
  %866 = bitcast i32* %865 to <4 x i32>*
  store <4 x i32> %863, <4 x i32>* %866, align 16
  %867 = load <8 x i16>, <8 x i16>* %733, align 16
  %868 = getelementptr inbounds i32, i32* %790, i64 112
  %869 = shufflevector <8 x i16> %867, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %870 = shufflevector <8 x i16> %867, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %871 = bitcast <8 x i16> %869 to <4 x i32>
  %872 = ashr <4 x i32> %871, <i32 16, i32 16, i32 16, i32 16>
  %873 = bitcast <8 x i16> %870 to <4 x i32>
  %874 = ashr <4 x i32> %873, <i32 16, i32 16, i32 16, i32 16>
  %875 = bitcast i32* %868 to <4 x i32>*
  store <4 x i32> %872, <4 x i32>* %875, align 16
  %876 = getelementptr inbounds i32, i32* %868, i64 4
  %877 = bitcast i32* %876 to <4 x i32>*
  store <4 x i32> %874, <4 x i32>* %877, align 16
  %878 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 8
  %879 = bitcast <2 x i64>* %878 to <8 x i16>*
  %880 = load <8 x i16>, <8 x i16>* %879, align 16
  %881 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 9
  %882 = bitcast <2 x i64>* %881 to <8 x i16>*
  %883 = load <8 x i16>, <8 x i16>* %882, align 16
  %884 = shufflevector <8 x i16> %880, <8 x i16> %883, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %885 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 10
  %886 = bitcast <2 x i64>* %885 to <8 x i16>*
  %887 = load <8 x i16>, <8 x i16>* %886, align 16
  %888 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 11
  %889 = bitcast <2 x i64>* %888 to <8 x i16>*
  %890 = load <8 x i16>, <8 x i16>* %889, align 16
  %891 = shufflevector <8 x i16> %887, <8 x i16> %890, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %892 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 12
  %893 = bitcast <2 x i64>* %892 to <8 x i16>*
  %894 = load <8 x i16>, <8 x i16>* %893, align 16
  %895 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 13
  %896 = bitcast <2 x i64>* %895 to <8 x i16>*
  %897 = load <8 x i16>, <8 x i16>* %896, align 16
  %898 = shufflevector <8 x i16> %894, <8 x i16> %897, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %899 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 14
  %900 = bitcast <2 x i64>* %899 to <8 x i16>*
  %901 = load <8 x i16>, <8 x i16>* %900, align 16
  %902 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 15
  %903 = bitcast <2 x i64>* %902 to <8 x i16>*
  %904 = load <8 x i16>, <8 x i16>* %903, align 16
  %905 = shufflevector <8 x i16> %901, <8 x i16> %904, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %906 = shufflevector <8 x i16> %880, <8 x i16> %883, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %907 = shufflevector <8 x i16> %887, <8 x i16> %890, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %908 = shufflevector <8 x i16> %894, <8 x i16> %897, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %909 = shufflevector <8 x i16> %901, <8 x i16> %904, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %910 = bitcast <8 x i16> %884 to <4 x i32>
  %911 = bitcast <8 x i16> %891 to <4 x i32>
  %912 = shufflevector <4 x i32> %910, <4 x i32> %911, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %913 = bitcast <4 x i32> %912 to <2 x i64>
  %914 = bitcast <8 x i16> %898 to <4 x i32>
  %915 = bitcast <8 x i16> %905 to <4 x i32>
  %916 = shufflevector <4 x i32> %914, <4 x i32> %915, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %917 = bitcast <4 x i32> %916 to <2 x i64>
  %918 = bitcast <8 x i16> %906 to <4 x i32>
  %919 = bitcast <8 x i16> %907 to <4 x i32>
  %920 = shufflevector <4 x i32> %918, <4 x i32> %919, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %921 = bitcast <4 x i32> %920 to <2 x i64>
  %922 = bitcast <8 x i16> %908 to <4 x i32>
  %923 = bitcast <8 x i16> %909 to <4 x i32>
  %924 = shufflevector <4 x i32> %922, <4 x i32> %923, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %925 = bitcast <4 x i32> %924 to <2 x i64>
  %926 = shufflevector <4 x i32> %910, <4 x i32> %911, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %927 = bitcast <4 x i32> %926 to <2 x i64>
  %928 = shufflevector <4 x i32> %914, <4 x i32> %915, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %929 = bitcast <4 x i32> %928 to <2 x i64>
  %930 = shufflevector <4 x i32> %918, <4 x i32> %919, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %931 = bitcast <4 x i32> %930 to <2 x i64>
  %932 = shufflevector <4 x i32> %922, <4 x i32> %923, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %933 = bitcast <4 x i32> %932 to <2 x i64>
  %934 = shufflevector <2 x i64> %913, <2 x i64> %917, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %934, <2 x i64>* %878, align 16
  %935 = shufflevector <2 x i64> %913, <2 x i64> %917, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %935, <2 x i64>* %881, align 16
  %936 = shufflevector <2 x i64> %927, <2 x i64> %929, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %936, <2 x i64>* %885, align 16
  %937 = shufflevector <2 x i64> %927, <2 x i64> %929, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %937, <2 x i64>* %888, align 16
  %938 = shufflevector <2 x i64> %921, <2 x i64> %925, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %938, <2 x i64>* %892, align 16
  %939 = shufflevector <2 x i64> %921, <2 x i64> %925, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %939, <2 x i64>* %895, align 16
  %940 = shufflevector <2 x i64> %931, <2 x i64> %933, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %940, <2 x i64>* %899, align 16
  %941 = shufflevector <2 x i64> %931, <2 x i64> %933, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %941, <2 x i64>* %902, align 16
  %942 = getelementptr inbounds i32, i32* %790, i64 8
  %943 = bitcast <2 x i64> %934 to <8 x i16>
  %944 = shufflevector <8 x i16> %943, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %945 = shufflevector <8 x i16> %943, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %946 = bitcast <8 x i16> %944 to <4 x i32>
  %947 = ashr <4 x i32> %946, <i32 16, i32 16, i32 16, i32 16>
  %948 = bitcast <8 x i16> %945 to <4 x i32>
  %949 = ashr <4 x i32> %948, <i32 16, i32 16, i32 16, i32 16>
  %950 = bitcast i32* %942 to <4 x i32>*
  store <4 x i32> %947, <4 x i32>* %950, align 16
  %951 = getelementptr inbounds i32, i32* %942, i64 4
  %952 = bitcast i32* %951 to <4 x i32>*
  store <4 x i32> %949, <4 x i32>* %952, align 16
  %953 = bitcast <2 x i64> %935 to <8 x i16>
  %954 = getelementptr inbounds i32, i32* %942, i64 16
  %955 = shufflevector <8 x i16> %953, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %956 = shufflevector <8 x i16> %953, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %957 = bitcast <8 x i16> %955 to <4 x i32>
  %958 = ashr <4 x i32> %957, <i32 16, i32 16, i32 16, i32 16>
  %959 = bitcast <8 x i16> %956 to <4 x i32>
  %960 = ashr <4 x i32> %959, <i32 16, i32 16, i32 16, i32 16>
  %961 = bitcast i32* %954 to <4 x i32>*
  store <4 x i32> %958, <4 x i32>* %961, align 16
  %962 = getelementptr inbounds i32, i32* %954, i64 4
  %963 = bitcast i32* %962 to <4 x i32>*
  store <4 x i32> %960, <4 x i32>* %963, align 16
  %964 = bitcast <2 x i64> %936 to <8 x i16>
  %965 = getelementptr inbounds i32, i32* %942, i64 32
  %966 = shufflevector <8 x i16> %964, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %967 = shufflevector <8 x i16> %964, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %968 = bitcast <8 x i16> %966 to <4 x i32>
  %969 = ashr <4 x i32> %968, <i32 16, i32 16, i32 16, i32 16>
  %970 = bitcast <8 x i16> %967 to <4 x i32>
  %971 = ashr <4 x i32> %970, <i32 16, i32 16, i32 16, i32 16>
  %972 = bitcast i32* %965 to <4 x i32>*
  store <4 x i32> %969, <4 x i32>* %972, align 16
  %973 = getelementptr inbounds i32, i32* %965, i64 4
  %974 = bitcast i32* %973 to <4 x i32>*
  store <4 x i32> %971, <4 x i32>* %974, align 16
  %975 = bitcast <2 x i64> %937 to <8 x i16>
  %976 = getelementptr inbounds i32, i32* %942, i64 48
  %977 = shufflevector <8 x i16> %975, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %978 = shufflevector <8 x i16> %975, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %979 = bitcast <8 x i16> %977 to <4 x i32>
  %980 = ashr <4 x i32> %979, <i32 16, i32 16, i32 16, i32 16>
  %981 = bitcast <8 x i16> %978 to <4 x i32>
  %982 = ashr <4 x i32> %981, <i32 16, i32 16, i32 16, i32 16>
  %983 = bitcast i32* %976 to <4 x i32>*
  store <4 x i32> %980, <4 x i32>* %983, align 16
  %984 = getelementptr inbounds i32, i32* %976, i64 4
  %985 = bitcast i32* %984 to <4 x i32>*
  store <4 x i32> %982, <4 x i32>* %985, align 16
  %986 = bitcast <2 x i64> %938 to <8 x i16>
  %987 = getelementptr inbounds i32, i32* %942, i64 64
  %988 = shufflevector <8 x i16> %986, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %989 = shufflevector <8 x i16> %986, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %990 = bitcast <8 x i16> %988 to <4 x i32>
  %991 = ashr <4 x i32> %990, <i32 16, i32 16, i32 16, i32 16>
  %992 = bitcast <8 x i16> %989 to <4 x i32>
  %993 = ashr <4 x i32> %992, <i32 16, i32 16, i32 16, i32 16>
  %994 = bitcast i32* %987 to <4 x i32>*
  store <4 x i32> %991, <4 x i32>* %994, align 16
  %995 = getelementptr inbounds i32, i32* %987, i64 4
  %996 = bitcast i32* %995 to <4 x i32>*
  store <4 x i32> %993, <4 x i32>* %996, align 16
  %997 = bitcast <2 x i64> %939 to <8 x i16>
  %998 = getelementptr inbounds i32, i32* %942, i64 80
  %999 = shufflevector <8 x i16> %997, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %1000 = shufflevector <8 x i16> %997, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %1001 = bitcast <8 x i16> %999 to <4 x i32>
  %1002 = ashr <4 x i32> %1001, <i32 16, i32 16, i32 16, i32 16>
  %1003 = bitcast <8 x i16> %1000 to <4 x i32>
  %1004 = ashr <4 x i32> %1003, <i32 16, i32 16, i32 16, i32 16>
  %1005 = bitcast i32* %998 to <4 x i32>*
  store <4 x i32> %1002, <4 x i32>* %1005, align 16
  %1006 = getelementptr inbounds i32, i32* %998, i64 4
  %1007 = bitcast i32* %1006 to <4 x i32>*
  store <4 x i32> %1004, <4 x i32>* %1007, align 16
  %1008 = bitcast <2 x i64> %940 to <8 x i16>
  %1009 = getelementptr inbounds i32, i32* %942, i64 96
  %1010 = shufflevector <8 x i16> %1008, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %1011 = shufflevector <8 x i16> %1008, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %1012 = bitcast <8 x i16> %1010 to <4 x i32>
  %1013 = ashr <4 x i32> %1012, <i32 16, i32 16, i32 16, i32 16>
  %1014 = bitcast <8 x i16> %1011 to <4 x i32>
  %1015 = ashr <4 x i32> %1014, <i32 16, i32 16, i32 16, i32 16>
  %1016 = bitcast i32* %1009 to <4 x i32>*
  store <4 x i32> %1013, <4 x i32>* %1016, align 16
  %1017 = getelementptr inbounds i32, i32* %1009, i64 4
  %1018 = bitcast i32* %1017 to <4 x i32>*
  store <4 x i32> %1015, <4 x i32>* %1018, align 16
  %1019 = getelementptr inbounds <2 x i64>, <2 x i64>* %554, i64 15
  %1020 = bitcast <2 x i64>* %1019 to <8 x i16>*
  %1021 = load <8 x i16>, <8 x i16>* %1020, align 16
  %1022 = getelementptr inbounds i32, i32* %942, i64 112
  %1023 = shufflevector <8 x i16> %1021, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %1024 = shufflevector <8 x i16> %1021, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %1025 = bitcast <8 x i16> %1023 to <4 x i32>
  %1026 = ashr <4 x i32> %1025, <i32 16, i32 16, i32 16, i32 16>
  %1027 = bitcast <8 x i16> %1024 to <4 x i32>
  %1028 = ashr <4 x i32> %1027, <i32 16, i32 16, i32 16, i32 16>
  %1029 = bitcast i32* %1022 to <4 x i32>*
  store <4 x i32> %1026, <4 x i32>* %1029, align 16
  %1030 = getelementptr inbounds i32, i32* %1022, i64 4
  %1031 = bitcast i32* %1030 to <4 x i32>*
  store <4 x i32> %1028, <4 x i32>* %1031, align 16
  %1032 = add nuw nsw i64 %518, 1
  %1033 = icmp eq i64 %1032, 2
  br i1 %1033, label %516, label %517
}

; Function Attrs: nounwind ssp uwtable
define hidden void @av1_lowbd_fwd_txfm2d_16x32_sse2(i16*, i32*, i32, i8 zeroext, i32) #2 {
  %6 = alloca [32 x <2 x i64>], align 16
  %7 = alloca [64 x <2 x i64>], align 16
  %8 = bitcast [32 x <2 x i64>]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 512, i8* nonnull %8) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %8, i8 -86, i64 512, i1 false)
  %9 = bitcast [64 x <2 x i64>]* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1024, i8* nonnull %9) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 1024, i1 false)
  %10 = load i8*, i8** getelementptr inbounds ([19 x i8*], [19 x i8*]* @av1_fwd_txfm_shift_ls, i64 0, i64 9), align 8
  %11 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_fwd_cos_bit_col, i64 0, i64 2, i64 3), align 1
  %12 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_fwd_cos_bit_row, i64 0, i64 2, i64 3), align 1
  %13 = zext i8 %3 to i64
  %14 = getelementptr inbounds [16 x void (<2 x i64>*, <2 x i64>*, i8)*], [16 x void (<2 x i64>*, <2 x i64>*, i8)*]* @col_txfm8x32_arr, i64 0, i64 %13
  %15 = load void (<2 x i64>*, <2 x i64>*, i8)*, void (<2 x i64>*, <2 x i64>*, i8)** %14, align 8
  %16 = getelementptr inbounds [16 x void (<2 x i64>*, <2 x i64>*, i8)*], [16 x void (<2 x i64>*, <2 x i64>*, i8)*]* @row_txfm8x16_arr, i64 0, i64 %13
  %17 = load void (<2 x i64>*, <2 x i64>*, i8)*, void (<2 x i64>*, <2 x i64>*, i8)** %16, align 8
  %18 = lshr i64 3585, %13
  %19 = and i64 %18, 1
  %20 = icmp eq i64 %19, 0
  br i1 %20, label %1022, label %21

21:                                               ; preds = %5
  switch i8 %3, label %25 [
    i8 6, label %24
    i8 15, label %23
    i8 7, label %23
    i8 5, label %23
    i8 14, label %22
    i8 8, label %22
    i8 4, label %22
  ]

22:                                               ; preds = %21, %21, %21
  br label %25

23:                                               ; preds = %21, %21, %21
  br label %25

24:                                               ; preds = %21
  br label %25

25:                                               ; preds = %21, %22, %23, %24
  %26 = phi i1 [ false, %24 ], [ true, %23 ], [ false, %22 ], [ true, %21 ]
  %27 = phi i32 [ 1, %24 ], [ 1, %23 ], [ 0, %22 ], [ 0, %21 ]
  %28 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 0
  %29 = sext i32 %2 to i64
  %30 = getelementptr inbounds i8, i8* %10, i64 1
  %31 = bitcast [32 x <2 x i64>]* %6 to <8 x i16>*
  %32 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 1
  %33 = bitcast <2 x i64>* %32 to <8 x i16>*
  %34 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 2
  %35 = bitcast <2 x i64>* %34 to <8 x i16>*
  %36 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 3
  %37 = bitcast <2 x i64>* %36 to <8 x i16>*
  %38 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 4
  %39 = bitcast <2 x i64>* %38 to <8 x i16>*
  %40 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 5
  %41 = bitcast <2 x i64>* %40 to <8 x i16>*
  %42 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 6
  %43 = bitcast <2 x i64>* %42 to <8 x i16>*
  %44 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 7
  %45 = bitcast <2 x i64>* %44 to <8 x i16>*
  %46 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 8
  %47 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 16
  %48 = bitcast <2 x i64>* %46 to <8 x i16>*
  %49 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 9
  %50 = bitcast <2 x i64>* %49 to <8 x i16>*
  %51 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 10
  %52 = bitcast <2 x i64>* %51 to <8 x i16>*
  %53 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 11
  %54 = bitcast <2 x i64>* %53 to <8 x i16>*
  %55 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 12
  %56 = bitcast <2 x i64>* %55 to <8 x i16>*
  %57 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 13
  %58 = bitcast <2 x i64>* %57 to <8 x i16>*
  %59 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 14
  %60 = bitcast <2 x i64>* %59 to <8 x i16>*
  %61 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 15
  %62 = bitcast <2 x i64>* %61 to <8 x i16>*
  %63 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 16
  %64 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 32
  %65 = bitcast <2 x i64>* %63 to <8 x i16>*
  %66 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 17
  %67 = bitcast <2 x i64>* %66 to <8 x i16>*
  %68 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 18
  %69 = bitcast <2 x i64>* %68 to <8 x i16>*
  %70 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 19
  %71 = bitcast <2 x i64>* %70 to <8 x i16>*
  %72 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 20
  %73 = bitcast <2 x i64>* %72 to <8 x i16>*
  %74 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 21
  %75 = bitcast <2 x i64>* %74 to <8 x i16>*
  %76 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 22
  %77 = bitcast <2 x i64>* %76 to <8 x i16>*
  %78 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 23
  %79 = bitcast <2 x i64>* %78 to <8 x i16>*
  %80 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 24
  %81 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 48
  %82 = bitcast <2 x i64>* %80 to <8 x i16>*
  %83 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 25
  %84 = bitcast <2 x i64>* %83 to <8 x i16>*
  %85 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 26
  %86 = bitcast <2 x i64>* %85 to <8 x i16>*
  %87 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 27
  %88 = bitcast <2 x i64>* %87 to <8 x i16>*
  %89 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 28
  %90 = bitcast <2 x i64>* %89 to <8 x i16>*
  %91 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 29
  %92 = bitcast <2 x i64>* %91 to <8 x i16>*
  %93 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 30
  %94 = bitcast <2 x i64>* %93 to <8 x i16>*
  %95 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 31
  %96 = bitcast <2 x i64>* %95 to <8 x i16>*
  br label %100

97:                                               ; preds = %278
  %98 = icmp eq i32 %27, 0
  %99 = getelementptr inbounds i8, i8* %10, i64 2
  br label %505

100:                                              ; preds = %278, %25
  %101 = phi i64 [ 0, %25 ], [ %503, %278 ]
  %102 = shl nsw i64 %101, 3
  %103 = getelementptr inbounds i16, i16* %0, i64 %102
  br i1 %26, label %125, label %104

104:                                              ; preds = %100, %104
  %105 = phi i64 [ %123, %104 ], [ 0, %100 ]
  %106 = mul nsw i64 %105, %29
  %107 = getelementptr inbounds i16, i16* %103, i64 %106
  %108 = bitcast i16* %107 to <2 x i64>*
  %109 = load <2 x i64>, <2 x i64>* %108, align 16
  %110 = shl i64 %105, 32
  %111 = sub nuw nsw i64 133143986176, %110
  %112 = ashr exact i64 %111, 32
  %113 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %112
  store <2 x i64> %109, <2 x i64>* %113, align 16
  %114 = or i64 %105, 1
  %115 = mul nsw i64 %114, %29
  %116 = getelementptr inbounds i16, i16* %103, i64 %115
  %117 = bitcast i16* %116 to <2 x i64>*
  %118 = load <2 x i64>, <2 x i64>* %117, align 16
  %119 = shl i64 %114, 32
  %120 = sub nuw nsw i64 133143986176, %119
  %121 = ashr exact i64 %120, 32
  %122 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %121
  store <2 x i64> %118, <2 x i64>* %122, align 16
  %123 = add nuw nsw i64 %105, 2
  %124 = icmp eq i64 %123, 32
  br i1 %124, label %152, label %104

125:                                              ; preds = %100, %125
  %126 = phi i64 [ %150, %125 ], [ 0, %100 ]
  %127 = mul nsw i64 %126, %29
  %128 = getelementptr inbounds i16, i16* %103, i64 %127
  %129 = bitcast i16* %128 to <2 x i64>*
  %130 = load <2 x i64>, <2 x i64>* %129, align 16
  %131 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %126
  store <2 x i64> %130, <2 x i64>* %131, align 16
  %132 = or i64 %126, 1
  %133 = mul nsw i64 %132, %29
  %134 = getelementptr inbounds i16, i16* %103, i64 %133
  %135 = bitcast i16* %134 to <2 x i64>*
  %136 = load <2 x i64>, <2 x i64>* %135, align 16
  %137 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %132
  store <2 x i64> %136, <2 x i64>* %137, align 16
  %138 = or i64 %126, 2
  %139 = mul nsw i64 %138, %29
  %140 = getelementptr inbounds i16, i16* %103, i64 %139
  %141 = bitcast i16* %140 to <2 x i64>*
  %142 = load <2 x i64>, <2 x i64>* %141, align 16
  %143 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %138
  store <2 x i64> %142, <2 x i64>* %143, align 16
  %144 = or i64 %126, 3
  %145 = mul nsw i64 %144, %29
  %146 = getelementptr inbounds i16, i16* %103, i64 %145
  %147 = bitcast i16* %146 to <2 x i64>*
  %148 = load <2 x i64>, <2 x i64>* %147, align 16
  %149 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %144
  store <2 x i64> %148, <2 x i64>* %149, align 16
  %150 = add nuw nsw i64 %126, 4
  %151 = icmp eq i64 %150, 32
  br i1 %151, label %152, label %125

152:                                              ; preds = %104, %125
  %153 = load i8, i8* %10, align 1
  %154 = sext i8 %153 to i32
  %155 = icmp slt i8 %153, 0
  br i1 %155, label %156, label %190

156:                                              ; preds = %152
  %157 = sub nsw i32 0, %154
  %158 = xor i32 %154, -1
  %159 = shl i32 1, %158
  %160 = trunc i32 %159 to i16
  %161 = insertelement <8 x i16> undef, i16 %160, i32 0
  %162 = shufflevector <8 x i16> %161, <8 x i16> undef, <8 x i32> zeroinitializer
  br label %163

163:                                              ; preds = %163, %156
  %164 = phi i64 [ 0, %156 ], [ %188, %163 ]
  %165 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %164
  %166 = bitcast <2 x i64>* %165 to <8 x i16>*
  %167 = load <8 x i16>, <8 x i16>* %166, align 16
  %168 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %167, <8 x i16> %162) #8
  %169 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %168, i32 %157) #8
  store <8 x i16> %169, <8 x i16>* %166, align 16
  %170 = or i64 %164, 1
  %171 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %170
  %172 = bitcast <2 x i64>* %171 to <8 x i16>*
  %173 = load <8 x i16>, <8 x i16>* %172, align 16
  %174 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %173, <8 x i16> %162) #8
  %175 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %174, i32 %157) #8
  store <8 x i16> %175, <8 x i16>* %172, align 16
  %176 = or i64 %164, 2
  %177 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %176
  %178 = bitcast <2 x i64>* %177 to <8 x i16>*
  %179 = load <8 x i16>, <8 x i16>* %178, align 16
  %180 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %179, <8 x i16> %162) #8
  %181 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %180, i32 %157) #8
  store <8 x i16> %181, <8 x i16>* %178, align 16
  %182 = or i64 %164, 3
  %183 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %182
  %184 = bitcast <2 x i64>* %183 to <8 x i16>*
  %185 = load <8 x i16>, <8 x i16>* %184, align 16
  %186 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %185, <8 x i16> %162) #8
  %187 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %186, i32 %157) #8
  store <8 x i16> %187, <8 x i16>* %184, align 16
  %188 = add nuw nsw i64 %164, 4
  %189 = icmp eq i64 %188, 32
  br i1 %189, label %215, label %163

190:                                              ; preds = %152
  %191 = icmp eq i8 %153, 0
  br i1 %191, label %215, label %192

192:                                              ; preds = %190, %192
  %193 = phi i64 [ %213, %192 ], [ 0, %190 ]
  %194 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %193
  %195 = bitcast <2 x i64>* %194 to <8 x i16>*
  %196 = load <8 x i16>, <8 x i16>* %195, align 16
  %197 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %196, i32 %154) #8
  store <8 x i16> %197, <8 x i16>* %195, align 16
  %198 = or i64 %193, 1
  %199 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %198
  %200 = bitcast <2 x i64>* %199 to <8 x i16>*
  %201 = load <8 x i16>, <8 x i16>* %200, align 16
  %202 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %201, i32 %154) #8
  store <8 x i16> %202, <8 x i16>* %200, align 16
  %203 = or i64 %193, 2
  %204 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %203
  %205 = bitcast <2 x i64>* %204 to <8 x i16>*
  %206 = load <8 x i16>, <8 x i16>* %205, align 16
  %207 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %206, i32 %154) #8
  store <8 x i16> %207, <8 x i16>* %205, align 16
  %208 = or i64 %193, 3
  %209 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %208
  %210 = bitcast <2 x i64>* %209 to <8 x i16>*
  %211 = load <8 x i16>, <8 x i16>* %210, align 16
  %212 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %211, i32 %154) #8
  store <8 x i16> %212, <8 x i16>* %210, align 16
  %213 = add nuw nsw i64 %193, 4
  %214 = icmp eq i64 %213, 32
  br i1 %214, label %215, label %192

215:                                              ; preds = %192, %163, %190
  call void %15(<2 x i64>* nonnull %28, <2 x i64>* nonnull %28, i8 signext %11) #8
  %216 = load i8, i8* %30, align 1
  %217 = sext i8 %216 to i32
  %218 = icmp slt i8 %216, 0
  br i1 %218, label %219, label %253

219:                                              ; preds = %215
  %220 = sub nsw i32 0, %217
  %221 = xor i32 %217, -1
  %222 = shl i32 1, %221
  %223 = trunc i32 %222 to i16
  %224 = insertelement <8 x i16> undef, i16 %223, i32 0
  %225 = shufflevector <8 x i16> %224, <8 x i16> undef, <8 x i32> zeroinitializer
  br label %226

226:                                              ; preds = %226, %219
  %227 = phi i64 [ 0, %219 ], [ %251, %226 ]
  %228 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %227
  %229 = bitcast <2 x i64>* %228 to <8 x i16>*
  %230 = load <8 x i16>, <8 x i16>* %229, align 16
  %231 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %230, <8 x i16> %225) #8
  %232 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %231, i32 %220) #8
  store <8 x i16> %232, <8 x i16>* %229, align 16
  %233 = or i64 %227, 1
  %234 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %233
  %235 = bitcast <2 x i64>* %234 to <8 x i16>*
  %236 = load <8 x i16>, <8 x i16>* %235, align 16
  %237 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %236, <8 x i16> %225) #8
  %238 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %237, i32 %220) #8
  store <8 x i16> %238, <8 x i16>* %235, align 16
  %239 = or i64 %227, 2
  %240 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %239
  %241 = bitcast <2 x i64>* %240 to <8 x i16>*
  %242 = load <8 x i16>, <8 x i16>* %241, align 16
  %243 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %242, <8 x i16> %225) #8
  %244 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %243, i32 %220) #8
  store <8 x i16> %244, <8 x i16>* %241, align 16
  %245 = or i64 %227, 3
  %246 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %245
  %247 = bitcast <2 x i64>* %246 to <8 x i16>*
  %248 = load <8 x i16>, <8 x i16>* %247, align 16
  %249 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %248, <8 x i16> %225) #8
  %250 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %249, i32 %220) #8
  store <8 x i16> %250, <8 x i16>* %247, align 16
  %251 = add nuw nsw i64 %227, 4
  %252 = icmp eq i64 %251, 32
  br i1 %252, label %278, label %226

253:                                              ; preds = %215
  %254 = icmp eq i8 %216, 0
  br i1 %254, label %278, label %255

255:                                              ; preds = %253, %255
  %256 = phi i64 [ %276, %255 ], [ 0, %253 ]
  %257 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %256
  %258 = bitcast <2 x i64>* %257 to <8 x i16>*
  %259 = load <8 x i16>, <8 x i16>* %258, align 16
  %260 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %259, i32 %217) #8
  store <8 x i16> %260, <8 x i16>* %258, align 16
  %261 = or i64 %256, 1
  %262 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %261
  %263 = bitcast <2 x i64>* %262 to <8 x i16>*
  %264 = load <8 x i16>, <8 x i16>* %263, align 16
  %265 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %264, i32 %217) #8
  store <8 x i16> %265, <8 x i16>* %263, align 16
  %266 = or i64 %256, 2
  %267 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %266
  %268 = bitcast <2 x i64>* %267 to <8 x i16>*
  %269 = load <8 x i16>, <8 x i16>* %268, align 16
  %270 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %269, i32 %217) #8
  store <8 x i16> %270, <8 x i16>* %268, align 16
  %271 = or i64 %256, 3
  %272 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %271
  %273 = bitcast <2 x i64>* %272 to <8 x i16>*
  %274 = load <8 x i16>, <8 x i16>* %273, align 16
  %275 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %274, i32 %217) #8
  store <8 x i16> %275, <8 x i16>* %273, align 16
  %276 = add nuw nsw i64 %256, 4
  %277 = icmp eq i64 %276, 32
  br i1 %277, label %278, label %255

278:                                              ; preds = %255, %226, %253
  %279 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 %102
  %280 = load <8 x i16>, <8 x i16>* %31, align 16
  %281 = load <8 x i16>, <8 x i16>* %33, align 16
  %282 = shufflevector <8 x i16> %280, <8 x i16> %281, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %283 = load <8 x i16>, <8 x i16>* %35, align 16
  %284 = load <8 x i16>, <8 x i16>* %37, align 16
  %285 = shufflevector <8 x i16> %283, <8 x i16> %284, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %286 = load <8 x i16>, <8 x i16>* %39, align 16
  %287 = load <8 x i16>, <8 x i16>* %41, align 16
  %288 = shufflevector <8 x i16> %286, <8 x i16> %287, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %289 = load <8 x i16>, <8 x i16>* %43, align 16
  %290 = load <8 x i16>, <8 x i16>* %45, align 16
  %291 = shufflevector <8 x i16> %289, <8 x i16> %290, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %292 = shufflevector <8 x i16> %280, <8 x i16> %281, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %293 = shufflevector <8 x i16> %283, <8 x i16> %284, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %294 = shufflevector <8 x i16> %286, <8 x i16> %287, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %295 = shufflevector <8 x i16> %289, <8 x i16> %290, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %296 = bitcast <8 x i16> %282 to <4 x i32>
  %297 = bitcast <8 x i16> %285 to <4 x i32>
  %298 = shufflevector <4 x i32> %296, <4 x i32> %297, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %299 = bitcast <4 x i32> %298 to <2 x i64>
  %300 = bitcast <8 x i16> %288 to <4 x i32>
  %301 = bitcast <8 x i16> %291 to <4 x i32>
  %302 = shufflevector <4 x i32> %300, <4 x i32> %301, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %303 = bitcast <4 x i32> %302 to <2 x i64>
  %304 = bitcast <8 x i16> %292 to <4 x i32>
  %305 = bitcast <8 x i16> %293 to <4 x i32>
  %306 = shufflevector <4 x i32> %304, <4 x i32> %305, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %307 = bitcast <4 x i32> %306 to <2 x i64>
  %308 = bitcast <8 x i16> %294 to <4 x i32>
  %309 = bitcast <8 x i16> %295 to <4 x i32>
  %310 = shufflevector <4 x i32> %308, <4 x i32> %309, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %311 = bitcast <4 x i32> %310 to <2 x i64>
  %312 = shufflevector <4 x i32> %296, <4 x i32> %297, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %313 = bitcast <4 x i32> %312 to <2 x i64>
  %314 = shufflevector <4 x i32> %300, <4 x i32> %301, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %315 = bitcast <4 x i32> %314 to <2 x i64>
  %316 = shufflevector <4 x i32> %304, <4 x i32> %305, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %317 = bitcast <4 x i32> %316 to <2 x i64>
  %318 = shufflevector <4 x i32> %308, <4 x i32> %309, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %319 = bitcast <4 x i32> %318 to <2 x i64>
  %320 = shufflevector <2 x i64> %299, <2 x i64> %303, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %320, <2 x i64>* %279, align 16
  %321 = shufflevector <2 x i64> %299, <2 x i64> %303, <2 x i32> <i32 1, i32 3>
  %322 = getelementptr inbounds <2 x i64>, <2 x i64>* %279, i64 1
  store <2 x i64> %321, <2 x i64>* %322, align 16
  %323 = shufflevector <2 x i64> %313, <2 x i64> %315, <2 x i32> <i32 0, i32 2>
  %324 = getelementptr inbounds <2 x i64>, <2 x i64>* %279, i64 2
  store <2 x i64> %323, <2 x i64>* %324, align 16
  %325 = shufflevector <2 x i64> %313, <2 x i64> %315, <2 x i32> <i32 1, i32 3>
  %326 = getelementptr inbounds <2 x i64>, <2 x i64>* %279, i64 3
  store <2 x i64> %325, <2 x i64>* %326, align 16
  %327 = shufflevector <2 x i64> %307, <2 x i64> %311, <2 x i32> <i32 0, i32 2>
  %328 = getelementptr inbounds <2 x i64>, <2 x i64>* %279, i64 4
  store <2 x i64> %327, <2 x i64>* %328, align 16
  %329 = shufflevector <2 x i64> %307, <2 x i64> %311, <2 x i32> <i32 1, i32 3>
  %330 = getelementptr inbounds <2 x i64>, <2 x i64>* %279, i64 5
  store <2 x i64> %329, <2 x i64>* %330, align 16
  %331 = shufflevector <2 x i64> %317, <2 x i64> %319, <2 x i32> <i32 0, i32 2>
  %332 = getelementptr inbounds <2 x i64>, <2 x i64>* %279, i64 6
  store <2 x i64> %331, <2 x i64>* %332, align 16
  %333 = shufflevector <2 x i64> %317, <2 x i64> %319, <2 x i32> <i32 1, i32 3>
  %334 = getelementptr inbounds <2 x i64>, <2 x i64>* %279, i64 7
  store <2 x i64> %333, <2 x i64>* %334, align 16
  %335 = getelementptr inbounds <2 x i64>, <2 x i64>* %47, i64 %102
  %336 = load <8 x i16>, <8 x i16>* %48, align 16
  %337 = load <8 x i16>, <8 x i16>* %50, align 16
  %338 = shufflevector <8 x i16> %336, <8 x i16> %337, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %339 = load <8 x i16>, <8 x i16>* %52, align 16
  %340 = load <8 x i16>, <8 x i16>* %54, align 16
  %341 = shufflevector <8 x i16> %339, <8 x i16> %340, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %342 = load <8 x i16>, <8 x i16>* %56, align 16
  %343 = load <8 x i16>, <8 x i16>* %58, align 16
  %344 = shufflevector <8 x i16> %342, <8 x i16> %343, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %345 = load <8 x i16>, <8 x i16>* %60, align 16
  %346 = load <8 x i16>, <8 x i16>* %62, align 16
  %347 = shufflevector <8 x i16> %345, <8 x i16> %346, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %348 = shufflevector <8 x i16> %336, <8 x i16> %337, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %349 = shufflevector <8 x i16> %339, <8 x i16> %340, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %350 = shufflevector <8 x i16> %342, <8 x i16> %343, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %351 = shufflevector <8 x i16> %345, <8 x i16> %346, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %352 = bitcast <8 x i16> %338 to <4 x i32>
  %353 = bitcast <8 x i16> %341 to <4 x i32>
  %354 = shufflevector <4 x i32> %352, <4 x i32> %353, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %355 = bitcast <4 x i32> %354 to <2 x i64>
  %356 = bitcast <8 x i16> %344 to <4 x i32>
  %357 = bitcast <8 x i16> %347 to <4 x i32>
  %358 = shufflevector <4 x i32> %356, <4 x i32> %357, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %359 = bitcast <4 x i32> %358 to <2 x i64>
  %360 = bitcast <8 x i16> %348 to <4 x i32>
  %361 = bitcast <8 x i16> %349 to <4 x i32>
  %362 = shufflevector <4 x i32> %360, <4 x i32> %361, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %363 = bitcast <4 x i32> %362 to <2 x i64>
  %364 = bitcast <8 x i16> %350 to <4 x i32>
  %365 = bitcast <8 x i16> %351 to <4 x i32>
  %366 = shufflevector <4 x i32> %364, <4 x i32> %365, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %367 = bitcast <4 x i32> %366 to <2 x i64>
  %368 = shufflevector <4 x i32> %352, <4 x i32> %353, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %369 = bitcast <4 x i32> %368 to <2 x i64>
  %370 = shufflevector <4 x i32> %356, <4 x i32> %357, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %371 = bitcast <4 x i32> %370 to <2 x i64>
  %372 = shufflevector <4 x i32> %360, <4 x i32> %361, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %373 = bitcast <4 x i32> %372 to <2 x i64>
  %374 = shufflevector <4 x i32> %364, <4 x i32> %365, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %375 = bitcast <4 x i32> %374 to <2 x i64>
  %376 = shufflevector <2 x i64> %355, <2 x i64> %359, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %376, <2 x i64>* %335, align 16
  %377 = shufflevector <2 x i64> %355, <2 x i64> %359, <2 x i32> <i32 1, i32 3>
  %378 = getelementptr inbounds <2 x i64>, <2 x i64>* %335, i64 1
  store <2 x i64> %377, <2 x i64>* %378, align 16
  %379 = shufflevector <2 x i64> %369, <2 x i64> %371, <2 x i32> <i32 0, i32 2>
  %380 = getelementptr inbounds <2 x i64>, <2 x i64>* %335, i64 2
  store <2 x i64> %379, <2 x i64>* %380, align 16
  %381 = shufflevector <2 x i64> %369, <2 x i64> %371, <2 x i32> <i32 1, i32 3>
  %382 = getelementptr inbounds <2 x i64>, <2 x i64>* %335, i64 3
  store <2 x i64> %381, <2 x i64>* %382, align 16
  %383 = shufflevector <2 x i64> %363, <2 x i64> %367, <2 x i32> <i32 0, i32 2>
  %384 = getelementptr inbounds <2 x i64>, <2 x i64>* %335, i64 4
  store <2 x i64> %383, <2 x i64>* %384, align 16
  %385 = shufflevector <2 x i64> %363, <2 x i64> %367, <2 x i32> <i32 1, i32 3>
  %386 = getelementptr inbounds <2 x i64>, <2 x i64>* %335, i64 5
  store <2 x i64> %385, <2 x i64>* %386, align 16
  %387 = shufflevector <2 x i64> %373, <2 x i64> %375, <2 x i32> <i32 0, i32 2>
  %388 = getelementptr inbounds <2 x i64>, <2 x i64>* %335, i64 6
  store <2 x i64> %387, <2 x i64>* %388, align 16
  %389 = shufflevector <2 x i64> %373, <2 x i64> %375, <2 x i32> <i32 1, i32 3>
  %390 = getelementptr inbounds <2 x i64>, <2 x i64>* %335, i64 7
  store <2 x i64> %389, <2 x i64>* %390, align 16
  %391 = getelementptr inbounds <2 x i64>, <2 x i64>* %64, i64 %102
  %392 = load <8 x i16>, <8 x i16>* %65, align 16
  %393 = load <8 x i16>, <8 x i16>* %67, align 16
  %394 = shufflevector <8 x i16> %392, <8 x i16> %393, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %395 = load <8 x i16>, <8 x i16>* %69, align 16
  %396 = load <8 x i16>, <8 x i16>* %71, align 16
  %397 = shufflevector <8 x i16> %395, <8 x i16> %396, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %398 = load <8 x i16>, <8 x i16>* %73, align 16
  %399 = load <8 x i16>, <8 x i16>* %75, align 16
  %400 = shufflevector <8 x i16> %398, <8 x i16> %399, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %401 = load <8 x i16>, <8 x i16>* %77, align 16
  %402 = load <8 x i16>, <8 x i16>* %79, align 16
  %403 = shufflevector <8 x i16> %401, <8 x i16> %402, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %404 = shufflevector <8 x i16> %392, <8 x i16> %393, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %405 = shufflevector <8 x i16> %395, <8 x i16> %396, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %406 = shufflevector <8 x i16> %398, <8 x i16> %399, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %407 = shufflevector <8 x i16> %401, <8 x i16> %402, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %408 = bitcast <8 x i16> %394 to <4 x i32>
  %409 = bitcast <8 x i16> %397 to <4 x i32>
  %410 = shufflevector <4 x i32> %408, <4 x i32> %409, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %411 = bitcast <4 x i32> %410 to <2 x i64>
  %412 = bitcast <8 x i16> %400 to <4 x i32>
  %413 = bitcast <8 x i16> %403 to <4 x i32>
  %414 = shufflevector <4 x i32> %412, <4 x i32> %413, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %415 = bitcast <4 x i32> %414 to <2 x i64>
  %416 = bitcast <8 x i16> %404 to <4 x i32>
  %417 = bitcast <8 x i16> %405 to <4 x i32>
  %418 = shufflevector <4 x i32> %416, <4 x i32> %417, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %419 = bitcast <4 x i32> %418 to <2 x i64>
  %420 = bitcast <8 x i16> %406 to <4 x i32>
  %421 = bitcast <8 x i16> %407 to <4 x i32>
  %422 = shufflevector <4 x i32> %420, <4 x i32> %421, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %423 = bitcast <4 x i32> %422 to <2 x i64>
  %424 = shufflevector <4 x i32> %408, <4 x i32> %409, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %425 = bitcast <4 x i32> %424 to <2 x i64>
  %426 = shufflevector <4 x i32> %412, <4 x i32> %413, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %427 = bitcast <4 x i32> %426 to <2 x i64>
  %428 = shufflevector <4 x i32> %416, <4 x i32> %417, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %429 = bitcast <4 x i32> %428 to <2 x i64>
  %430 = shufflevector <4 x i32> %420, <4 x i32> %421, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %431 = bitcast <4 x i32> %430 to <2 x i64>
  %432 = shufflevector <2 x i64> %411, <2 x i64> %415, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %432, <2 x i64>* %391, align 16
  %433 = shufflevector <2 x i64> %411, <2 x i64> %415, <2 x i32> <i32 1, i32 3>
  %434 = getelementptr inbounds <2 x i64>, <2 x i64>* %391, i64 1
  store <2 x i64> %433, <2 x i64>* %434, align 16
  %435 = shufflevector <2 x i64> %425, <2 x i64> %427, <2 x i32> <i32 0, i32 2>
  %436 = getelementptr inbounds <2 x i64>, <2 x i64>* %391, i64 2
  store <2 x i64> %435, <2 x i64>* %436, align 16
  %437 = shufflevector <2 x i64> %425, <2 x i64> %427, <2 x i32> <i32 1, i32 3>
  %438 = getelementptr inbounds <2 x i64>, <2 x i64>* %391, i64 3
  store <2 x i64> %437, <2 x i64>* %438, align 16
  %439 = shufflevector <2 x i64> %419, <2 x i64> %423, <2 x i32> <i32 0, i32 2>
  %440 = getelementptr inbounds <2 x i64>, <2 x i64>* %391, i64 4
  store <2 x i64> %439, <2 x i64>* %440, align 16
  %441 = shufflevector <2 x i64> %419, <2 x i64> %423, <2 x i32> <i32 1, i32 3>
  %442 = getelementptr inbounds <2 x i64>, <2 x i64>* %391, i64 5
  store <2 x i64> %441, <2 x i64>* %442, align 16
  %443 = shufflevector <2 x i64> %429, <2 x i64> %431, <2 x i32> <i32 0, i32 2>
  %444 = getelementptr inbounds <2 x i64>, <2 x i64>* %391, i64 6
  store <2 x i64> %443, <2 x i64>* %444, align 16
  %445 = shufflevector <2 x i64> %429, <2 x i64> %431, <2 x i32> <i32 1, i32 3>
  %446 = getelementptr inbounds <2 x i64>, <2 x i64>* %391, i64 7
  store <2 x i64> %445, <2 x i64>* %446, align 16
  %447 = getelementptr inbounds <2 x i64>, <2 x i64>* %81, i64 %102
  %448 = load <8 x i16>, <8 x i16>* %82, align 16
  %449 = load <8 x i16>, <8 x i16>* %84, align 16
  %450 = shufflevector <8 x i16> %448, <8 x i16> %449, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %451 = load <8 x i16>, <8 x i16>* %86, align 16
  %452 = load <8 x i16>, <8 x i16>* %88, align 16
  %453 = shufflevector <8 x i16> %451, <8 x i16> %452, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %454 = load <8 x i16>, <8 x i16>* %90, align 16
  %455 = load <8 x i16>, <8 x i16>* %92, align 16
  %456 = shufflevector <8 x i16> %454, <8 x i16> %455, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %457 = load <8 x i16>, <8 x i16>* %94, align 16
  %458 = load <8 x i16>, <8 x i16>* %96, align 16
  %459 = shufflevector <8 x i16> %457, <8 x i16> %458, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %460 = shufflevector <8 x i16> %448, <8 x i16> %449, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %461 = shufflevector <8 x i16> %451, <8 x i16> %452, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %462 = shufflevector <8 x i16> %454, <8 x i16> %455, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %463 = shufflevector <8 x i16> %457, <8 x i16> %458, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %464 = bitcast <8 x i16> %450 to <4 x i32>
  %465 = bitcast <8 x i16> %453 to <4 x i32>
  %466 = shufflevector <4 x i32> %464, <4 x i32> %465, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %467 = bitcast <4 x i32> %466 to <2 x i64>
  %468 = bitcast <8 x i16> %456 to <4 x i32>
  %469 = bitcast <8 x i16> %459 to <4 x i32>
  %470 = shufflevector <4 x i32> %468, <4 x i32> %469, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %471 = bitcast <4 x i32> %470 to <2 x i64>
  %472 = bitcast <8 x i16> %460 to <4 x i32>
  %473 = bitcast <8 x i16> %461 to <4 x i32>
  %474 = shufflevector <4 x i32> %472, <4 x i32> %473, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %475 = bitcast <4 x i32> %474 to <2 x i64>
  %476 = bitcast <8 x i16> %462 to <4 x i32>
  %477 = bitcast <8 x i16> %463 to <4 x i32>
  %478 = shufflevector <4 x i32> %476, <4 x i32> %477, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %479 = bitcast <4 x i32> %478 to <2 x i64>
  %480 = shufflevector <4 x i32> %464, <4 x i32> %465, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %481 = bitcast <4 x i32> %480 to <2 x i64>
  %482 = shufflevector <4 x i32> %468, <4 x i32> %469, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %483 = bitcast <4 x i32> %482 to <2 x i64>
  %484 = shufflevector <4 x i32> %472, <4 x i32> %473, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %485 = bitcast <4 x i32> %484 to <2 x i64>
  %486 = shufflevector <4 x i32> %476, <4 x i32> %477, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %487 = bitcast <4 x i32> %486 to <2 x i64>
  %488 = shufflevector <2 x i64> %467, <2 x i64> %471, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %488, <2 x i64>* %447, align 16
  %489 = shufflevector <2 x i64> %467, <2 x i64> %471, <2 x i32> <i32 1, i32 3>
  %490 = getelementptr inbounds <2 x i64>, <2 x i64>* %447, i64 1
  store <2 x i64> %489, <2 x i64>* %490, align 16
  %491 = shufflevector <2 x i64> %481, <2 x i64> %483, <2 x i32> <i32 0, i32 2>
  %492 = getelementptr inbounds <2 x i64>, <2 x i64>* %447, i64 2
  store <2 x i64> %491, <2 x i64>* %492, align 16
  %493 = shufflevector <2 x i64> %481, <2 x i64> %483, <2 x i32> <i32 1, i32 3>
  %494 = getelementptr inbounds <2 x i64>, <2 x i64>* %447, i64 3
  store <2 x i64> %493, <2 x i64>* %494, align 16
  %495 = shufflevector <2 x i64> %475, <2 x i64> %479, <2 x i32> <i32 0, i32 2>
  %496 = getelementptr inbounds <2 x i64>, <2 x i64>* %447, i64 4
  store <2 x i64> %495, <2 x i64>* %496, align 16
  %497 = shufflevector <2 x i64> %475, <2 x i64> %479, <2 x i32> <i32 1, i32 3>
  %498 = getelementptr inbounds <2 x i64>, <2 x i64>* %447, i64 5
  store <2 x i64> %497, <2 x i64>* %498, align 16
  %499 = shufflevector <2 x i64> %485, <2 x i64> %487, <2 x i32> <i32 0, i32 2>
  %500 = getelementptr inbounds <2 x i64>, <2 x i64>* %447, i64 6
  store <2 x i64> %499, <2 x i64>* %500, align 16
  %501 = shufflevector <2 x i64> %485, <2 x i64> %487, <2 x i32> <i32 1, i32 3>
  %502 = getelementptr inbounds <2 x i64>, <2 x i64>* %447, i64 7
  store <2 x i64> %501, <2 x i64>* %502, align 16
  %503 = add nuw nsw i64 %101, 1
  %504 = icmp eq i64 %503, 2
  br i1 %504, label %97, label %100

505:                                              ; preds = %720, %97
  %506 = phi i64 [ 0, %97 ], [ %1020, %720 ]
  %507 = shl nsw i64 %506, 4
  %508 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 %507
  br i1 %98, label %541, label %509

509:                                              ; preds = %505
  %510 = load <2 x i64>, <2 x i64>* %508, align 16
  store <2 x i64> %510, <2 x i64>* %61, align 16
  %511 = getelementptr inbounds <2 x i64>, <2 x i64>* %508, i64 1
  %512 = load <2 x i64>, <2 x i64>* %511, align 16
  store <2 x i64> %512, <2 x i64>* %59, align 16
  %513 = getelementptr inbounds <2 x i64>, <2 x i64>* %508, i64 2
  %514 = load <2 x i64>, <2 x i64>* %513, align 16
  store <2 x i64> %514, <2 x i64>* %57, align 16
  %515 = getelementptr inbounds <2 x i64>, <2 x i64>* %508, i64 3
  %516 = load <2 x i64>, <2 x i64>* %515, align 16
  store <2 x i64> %516, <2 x i64>* %55, align 16
  %517 = getelementptr inbounds <2 x i64>, <2 x i64>* %508, i64 4
  %518 = load <2 x i64>, <2 x i64>* %517, align 16
  store <2 x i64> %518, <2 x i64>* %53, align 16
  %519 = getelementptr inbounds <2 x i64>, <2 x i64>* %508, i64 5
  %520 = load <2 x i64>, <2 x i64>* %519, align 16
  store <2 x i64> %520, <2 x i64>* %51, align 16
  %521 = getelementptr inbounds <2 x i64>, <2 x i64>* %508, i64 6
  %522 = load <2 x i64>, <2 x i64>* %521, align 16
  store <2 x i64> %522, <2 x i64>* %49, align 16
  %523 = getelementptr inbounds <2 x i64>, <2 x i64>* %508, i64 7
  %524 = load <2 x i64>, <2 x i64>* %523, align 16
  store <2 x i64> %524, <2 x i64>* %46, align 16
  %525 = getelementptr inbounds <2 x i64>, <2 x i64>* %508, i64 8
  %526 = load <2 x i64>, <2 x i64>* %525, align 16
  store <2 x i64> %526, <2 x i64>* %44, align 16
  %527 = getelementptr inbounds <2 x i64>, <2 x i64>* %508, i64 9
  %528 = load <2 x i64>, <2 x i64>* %527, align 16
  store <2 x i64> %528, <2 x i64>* %42, align 16
  %529 = getelementptr inbounds <2 x i64>, <2 x i64>* %508, i64 10
  %530 = load <2 x i64>, <2 x i64>* %529, align 16
  store <2 x i64> %530, <2 x i64>* %40, align 16
  %531 = getelementptr inbounds <2 x i64>, <2 x i64>* %508, i64 11
  %532 = load <2 x i64>, <2 x i64>* %531, align 16
  store <2 x i64> %532, <2 x i64>* %38, align 16
  %533 = getelementptr inbounds <2 x i64>, <2 x i64>* %508, i64 12
  %534 = load <2 x i64>, <2 x i64>* %533, align 16
  store <2 x i64> %534, <2 x i64>* %36, align 16
  %535 = getelementptr inbounds <2 x i64>, <2 x i64>* %508, i64 13
  %536 = load <2 x i64>, <2 x i64>* %535, align 16
  store <2 x i64> %536, <2 x i64>* %34, align 16
  %537 = getelementptr inbounds <2 x i64>, <2 x i64>* %508, i64 14
  %538 = load <2 x i64>, <2 x i64>* %537, align 16
  store <2 x i64> %538, <2 x i64>* %32, align 16
  %539 = getelementptr inbounds <2 x i64>, <2 x i64>* %508, i64 15
  %540 = load <2 x i64>, <2 x i64>* %539, align 16
  store <2 x i64> %540, <2 x i64>* %28, align 16
  br label %541

541:                                              ; preds = %509, %505
  %542 = phi <2 x i64>* [ %508, %505 ], [ %28, %509 ]
  call void %17(<2 x i64>* %542, <2 x i64>* %542, i8 signext %12) #8
  %543 = load i8, i8* %99, align 1
  %544 = sext i8 %543 to i32
  %545 = icmp slt i8 %543, 0
  br i1 %545, label %546, label %632

546:                                              ; preds = %541
  %547 = sub nsw i32 0, %544
  %548 = xor i32 %544, -1
  %549 = shl i32 1, %548
  %550 = trunc i32 %549 to i16
  %551 = insertelement <8 x i16> undef, i16 %550, i32 0
  %552 = shufflevector <8 x i16> %551, <8 x i16> undef, <8 x i32> zeroinitializer
  %553 = bitcast <2 x i64>* %542 to <8 x i16>*
  %554 = load <8 x i16>, <8 x i16>* %553, align 16
  %555 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %554, <8 x i16> %552) #8
  %556 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %555, i32 %547) #8
  store <8 x i16> %556, <8 x i16>* %553, align 16
  %557 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 1
  %558 = bitcast <2 x i64>* %557 to <8 x i16>*
  %559 = load <8 x i16>, <8 x i16>* %558, align 16
  %560 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %559, <8 x i16> %552) #8
  %561 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %560, i32 %547) #8
  store <8 x i16> %561, <8 x i16>* %558, align 16
  %562 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 2
  %563 = bitcast <2 x i64>* %562 to <8 x i16>*
  %564 = load <8 x i16>, <8 x i16>* %563, align 16
  %565 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %564, <8 x i16> %552) #8
  %566 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %565, i32 %547) #8
  store <8 x i16> %566, <8 x i16>* %563, align 16
  %567 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 3
  %568 = bitcast <2 x i64>* %567 to <8 x i16>*
  %569 = load <8 x i16>, <8 x i16>* %568, align 16
  %570 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %569, <8 x i16> %552) #8
  %571 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %570, i32 %547) #8
  store <8 x i16> %571, <8 x i16>* %568, align 16
  %572 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 4
  %573 = bitcast <2 x i64>* %572 to <8 x i16>*
  %574 = load <8 x i16>, <8 x i16>* %573, align 16
  %575 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %574, <8 x i16> %552) #8
  %576 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %575, i32 %547) #8
  store <8 x i16> %576, <8 x i16>* %573, align 16
  %577 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 5
  %578 = bitcast <2 x i64>* %577 to <8 x i16>*
  %579 = load <8 x i16>, <8 x i16>* %578, align 16
  %580 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %579, <8 x i16> %552) #8
  %581 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %580, i32 %547) #8
  store <8 x i16> %581, <8 x i16>* %578, align 16
  %582 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 6
  %583 = bitcast <2 x i64>* %582 to <8 x i16>*
  %584 = load <8 x i16>, <8 x i16>* %583, align 16
  %585 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %584, <8 x i16> %552) #8
  %586 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %585, i32 %547) #8
  store <8 x i16> %586, <8 x i16>* %583, align 16
  %587 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 7
  %588 = bitcast <2 x i64>* %587 to <8 x i16>*
  %589 = load <8 x i16>, <8 x i16>* %588, align 16
  %590 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %589, <8 x i16> %552) #8
  %591 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %590, i32 %547) #8
  store <8 x i16> %591, <8 x i16>* %588, align 16
  %592 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 8
  %593 = bitcast <2 x i64>* %592 to <8 x i16>*
  %594 = load <8 x i16>, <8 x i16>* %593, align 16
  %595 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %594, <8 x i16> %552) #8
  %596 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %595, i32 %547) #8
  store <8 x i16> %596, <8 x i16>* %593, align 16
  %597 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 9
  %598 = bitcast <2 x i64>* %597 to <8 x i16>*
  %599 = load <8 x i16>, <8 x i16>* %598, align 16
  %600 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %599, <8 x i16> %552) #8
  %601 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %600, i32 %547) #8
  store <8 x i16> %601, <8 x i16>* %598, align 16
  %602 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 10
  %603 = bitcast <2 x i64>* %602 to <8 x i16>*
  %604 = load <8 x i16>, <8 x i16>* %603, align 16
  %605 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %604, <8 x i16> %552) #8
  %606 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %605, i32 %547) #8
  store <8 x i16> %606, <8 x i16>* %603, align 16
  %607 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 11
  %608 = bitcast <2 x i64>* %607 to <8 x i16>*
  %609 = load <8 x i16>, <8 x i16>* %608, align 16
  %610 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %609, <8 x i16> %552) #8
  %611 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %610, i32 %547) #8
  store <8 x i16> %611, <8 x i16>* %608, align 16
  %612 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 12
  %613 = bitcast <2 x i64>* %612 to <8 x i16>*
  %614 = load <8 x i16>, <8 x i16>* %613, align 16
  %615 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %614, <8 x i16> %552) #8
  %616 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %615, i32 %547) #8
  store <8 x i16> %616, <8 x i16>* %613, align 16
  %617 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 13
  %618 = bitcast <2 x i64>* %617 to <8 x i16>*
  %619 = load <8 x i16>, <8 x i16>* %618, align 16
  %620 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %619, <8 x i16> %552) #8
  %621 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %620, i32 %547) #8
  store <8 x i16> %621, <8 x i16>* %618, align 16
  %622 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 14
  %623 = bitcast <2 x i64>* %622 to <8 x i16>*
  %624 = load <8 x i16>, <8 x i16>* %623, align 16
  %625 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %624, <8 x i16> %552) #8
  %626 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %625, i32 %547) #8
  store <8 x i16> %626, <8 x i16>* %623, align 16
  %627 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 15
  %628 = bitcast <2 x i64>* %627 to <8 x i16>*
  %629 = load <8 x i16>, <8 x i16>* %628, align 16
  %630 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %629, <8 x i16> %552) #8
  %631 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %630, i32 %547) #8
  store <8 x i16> %631, <8 x i16>* %628, align 16
  br label %720

632:                                              ; preds = %541
  %633 = icmp eq i8 %543, 0
  %634 = bitcast <2 x i64>* %542 to <8 x i16>*
  %635 = load <8 x i16>, <8 x i16>* %634, align 16
  br i1 %633, label %636, label %658

636:                                              ; preds = %632
  %637 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 1
  %638 = bitcast <2 x i64>* %637 to <8 x i16>*
  %639 = load <8 x i16>, <8 x i16>* %638, align 16
  %640 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 2
  %641 = bitcast <2 x i64>* %640 to <8 x i16>*
  %642 = load <8 x i16>, <8 x i16>* %641, align 16
  %643 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 3
  %644 = bitcast <2 x i64>* %643 to <8 x i16>*
  %645 = load <8 x i16>, <8 x i16>* %644, align 16
  %646 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 4
  %647 = bitcast <2 x i64>* %646 to <8 x i16>*
  %648 = load <8 x i16>, <8 x i16>* %647, align 16
  %649 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 5
  %650 = bitcast <2 x i64>* %649 to <8 x i16>*
  %651 = load <8 x i16>, <8 x i16>* %650, align 16
  %652 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 6
  %653 = bitcast <2 x i64>* %652 to <8 x i16>*
  %654 = load <8 x i16>, <8 x i16>* %653, align 16
  %655 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 7
  %656 = bitcast <2 x i64>* %655 to <8 x i16>*
  %657 = load <8 x i16>, <8 x i16>* %656, align 16
  br label %720

658:                                              ; preds = %632
  %659 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %635, i32 %544) #8
  store <8 x i16> %659, <8 x i16>* %634, align 16
  %660 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 1
  %661 = bitcast <2 x i64>* %660 to <8 x i16>*
  %662 = load <8 x i16>, <8 x i16>* %661, align 16
  %663 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %662, i32 %544) #8
  store <8 x i16> %663, <8 x i16>* %661, align 16
  %664 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 2
  %665 = bitcast <2 x i64>* %664 to <8 x i16>*
  %666 = load <8 x i16>, <8 x i16>* %665, align 16
  %667 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %666, i32 %544) #8
  store <8 x i16> %667, <8 x i16>* %665, align 16
  %668 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 3
  %669 = bitcast <2 x i64>* %668 to <8 x i16>*
  %670 = load <8 x i16>, <8 x i16>* %669, align 16
  %671 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %670, i32 %544) #8
  store <8 x i16> %671, <8 x i16>* %669, align 16
  %672 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 4
  %673 = bitcast <2 x i64>* %672 to <8 x i16>*
  %674 = load <8 x i16>, <8 x i16>* %673, align 16
  %675 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %674, i32 %544) #8
  store <8 x i16> %675, <8 x i16>* %673, align 16
  %676 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 5
  %677 = bitcast <2 x i64>* %676 to <8 x i16>*
  %678 = load <8 x i16>, <8 x i16>* %677, align 16
  %679 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %678, i32 %544) #8
  store <8 x i16> %679, <8 x i16>* %677, align 16
  %680 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 6
  %681 = bitcast <2 x i64>* %680 to <8 x i16>*
  %682 = load <8 x i16>, <8 x i16>* %681, align 16
  %683 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %682, i32 %544) #8
  store <8 x i16> %683, <8 x i16>* %681, align 16
  %684 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 7
  %685 = bitcast <2 x i64>* %684 to <8 x i16>*
  %686 = load <8 x i16>, <8 x i16>* %685, align 16
  %687 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %686, i32 %544) #8
  store <8 x i16> %687, <8 x i16>* %685, align 16
  %688 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 8
  %689 = bitcast <2 x i64>* %688 to <8 x i16>*
  %690 = load <8 x i16>, <8 x i16>* %689, align 16
  %691 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %690, i32 %544) #8
  store <8 x i16> %691, <8 x i16>* %689, align 16
  %692 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 9
  %693 = bitcast <2 x i64>* %692 to <8 x i16>*
  %694 = load <8 x i16>, <8 x i16>* %693, align 16
  %695 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %694, i32 %544) #8
  store <8 x i16> %695, <8 x i16>* %693, align 16
  %696 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 10
  %697 = bitcast <2 x i64>* %696 to <8 x i16>*
  %698 = load <8 x i16>, <8 x i16>* %697, align 16
  %699 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %698, i32 %544) #8
  store <8 x i16> %699, <8 x i16>* %697, align 16
  %700 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 11
  %701 = bitcast <2 x i64>* %700 to <8 x i16>*
  %702 = load <8 x i16>, <8 x i16>* %701, align 16
  %703 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %702, i32 %544) #8
  store <8 x i16> %703, <8 x i16>* %701, align 16
  %704 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 12
  %705 = bitcast <2 x i64>* %704 to <8 x i16>*
  %706 = load <8 x i16>, <8 x i16>* %705, align 16
  %707 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %706, i32 %544) #8
  store <8 x i16> %707, <8 x i16>* %705, align 16
  %708 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 13
  %709 = bitcast <2 x i64>* %708 to <8 x i16>*
  %710 = load <8 x i16>, <8 x i16>* %709, align 16
  %711 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %710, i32 %544) #8
  store <8 x i16> %711, <8 x i16>* %709, align 16
  %712 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 14
  %713 = bitcast <2 x i64>* %712 to <8 x i16>*
  %714 = load <8 x i16>, <8 x i16>* %713, align 16
  %715 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %714, i32 %544) #8
  store <8 x i16> %715, <8 x i16>* %713, align 16
  %716 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 15
  %717 = bitcast <2 x i64>* %716 to <8 x i16>*
  %718 = load <8 x i16>, <8 x i16>* %717, align 16
  %719 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %718, i32 %544) #8
  store <8 x i16> %719, <8 x i16>* %717, align 16
  br label %720

720:                                              ; preds = %636, %658, %546
  %721 = phi <8 x i16>* [ %656, %636 ], [ %685, %658 ], [ %588, %546 ]
  %722 = phi <8 x i16> [ %657, %636 ], [ %687, %658 ], [ %591, %546 ]
  %723 = phi <8 x i16> [ %654, %636 ], [ %683, %658 ], [ %586, %546 ]
  %724 = phi <8 x i16> [ %651, %636 ], [ %679, %658 ], [ %581, %546 ]
  %725 = phi <8 x i16> [ %648, %636 ], [ %675, %658 ], [ %576, %546 ]
  %726 = phi <8 x i16> [ %645, %636 ], [ %671, %658 ], [ %571, %546 ]
  %727 = phi <8 x i16> [ %642, %636 ], [ %667, %658 ], [ %566, %546 ]
  %728 = phi <8 x i16> [ %639, %636 ], [ %663, %658 ], [ %561, %546 ]
  %729 = phi <8 x i16> [ %635, %636 ], [ %659, %658 ], [ %556, %546 ]
  %730 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 1
  %731 = shufflevector <8 x i16> %729, <8 x i16> %728, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %732 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 2
  %733 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 3
  %734 = shufflevector <8 x i16> %727, <8 x i16> %726, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %735 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 4
  %736 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 5
  %737 = shufflevector <8 x i16> %725, <8 x i16> %724, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %738 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 6
  %739 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 7
  %740 = shufflevector <8 x i16> %723, <8 x i16> %722, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %741 = shufflevector <8 x i16> %729, <8 x i16> %728, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %742 = shufflevector <8 x i16> %727, <8 x i16> %726, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %743 = shufflevector <8 x i16> %725, <8 x i16> %724, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %744 = shufflevector <8 x i16> %723, <8 x i16> %722, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %745 = bitcast <8 x i16> %731 to <4 x i32>
  %746 = bitcast <8 x i16> %734 to <4 x i32>
  %747 = shufflevector <4 x i32> %745, <4 x i32> %746, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %748 = bitcast <4 x i32> %747 to <2 x i64>
  %749 = bitcast <8 x i16> %737 to <4 x i32>
  %750 = bitcast <8 x i16> %740 to <4 x i32>
  %751 = shufflevector <4 x i32> %749, <4 x i32> %750, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %752 = bitcast <4 x i32> %751 to <2 x i64>
  %753 = bitcast <8 x i16> %741 to <4 x i32>
  %754 = bitcast <8 x i16> %742 to <4 x i32>
  %755 = shufflevector <4 x i32> %753, <4 x i32> %754, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %756 = bitcast <4 x i32> %755 to <2 x i64>
  %757 = bitcast <8 x i16> %743 to <4 x i32>
  %758 = bitcast <8 x i16> %744 to <4 x i32>
  %759 = shufflevector <4 x i32> %757, <4 x i32> %758, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %760 = bitcast <4 x i32> %759 to <2 x i64>
  %761 = shufflevector <4 x i32> %745, <4 x i32> %746, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %762 = bitcast <4 x i32> %761 to <2 x i64>
  %763 = shufflevector <4 x i32> %749, <4 x i32> %750, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %764 = bitcast <4 x i32> %763 to <2 x i64>
  %765 = shufflevector <4 x i32> %753, <4 x i32> %754, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %766 = bitcast <4 x i32> %765 to <2 x i64>
  %767 = shufflevector <4 x i32> %757, <4 x i32> %758, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %768 = bitcast <4 x i32> %767 to <2 x i64>
  %769 = shufflevector <2 x i64> %748, <2 x i64> %752, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %769, <2 x i64>* %542, align 16
  %770 = shufflevector <2 x i64> %748, <2 x i64> %752, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %770, <2 x i64>* %730, align 16
  %771 = shufflevector <2 x i64> %762, <2 x i64> %764, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %771, <2 x i64>* %732, align 16
  %772 = shufflevector <2 x i64> %762, <2 x i64> %764, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %772, <2 x i64>* %733, align 16
  %773 = shufflevector <2 x i64> %756, <2 x i64> %760, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %773, <2 x i64>* %735, align 16
  %774 = shufflevector <2 x i64> %756, <2 x i64> %760, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %774, <2 x i64>* %736, align 16
  %775 = shufflevector <2 x i64> %766, <2 x i64> %768, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %775, <2 x i64>* %738, align 16
  %776 = shufflevector <2 x i64> %766, <2 x i64> %768, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %776, <2 x i64>* %739, align 16
  %777 = shl nsw i64 %506, 7
  %778 = getelementptr inbounds i32, i32* %1, i64 %777
  %779 = bitcast <2 x i64> %769 to <8 x i16>
  %780 = shufflevector <8 x i16> %779, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %781 = shufflevector <8 x i16> %779, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %782 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %780, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %783 = ashr <4 x i32> %782, <i32 12, i32 12, i32 12, i32 12>
  %784 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %781, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %785 = ashr <4 x i32> %784, <i32 12, i32 12, i32 12, i32 12>
  %786 = bitcast i32* %778 to <4 x i32>*
  store <4 x i32> %783, <4 x i32>* %786, align 16
  %787 = getelementptr inbounds i32, i32* %778, i64 4
  %788 = bitcast i32* %787 to <4 x i32>*
  store <4 x i32> %785, <4 x i32>* %788, align 16
  %789 = bitcast <2 x i64> %770 to <8 x i16>
  %790 = getelementptr inbounds i32, i32* %778, i64 16
  %791 = shufflevector <8 x i16> %789, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %792 = shufflevector <8 x i16> %789, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %793 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %791, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %794 = ashr <4 x i32> %793, <i32 12, i32 12, i32 12, i32 12>
  %795 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %792, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %796 = ashr <4 x i32> %795, <i32 12, i32 12, i32 12, i32 12>
  %797 = bitcast i32* %790 to <4 x i32>*
  store <4 x i32> %794, <4 x i32>* %797, align 16
  %798 = getelementptr inbounds i32, i32* %790, i64 4
  %799 = bitcast i32* %798 to <4 x i32>*
  store <4 x i32> %796, <4 x i32>* %799, align 16
  %800 = bitcast <2 x i64> %771 to <8 x i16>
  %801 = getelementptr inbounds i32, i32* %778, i64 32
  %802 = shufflevector <8 x i16> %800, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %803 = shufflevector <8 x i16> %800, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %804 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %802, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %805 = ashr <4 x i32> %804, <i32 12, i32 12, i32 12, i32 12>
  %806 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %803, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %807 = ashr <4 x i32> %806, <i32 12, i32 12, i32 12, i32 12>
  %808 = bitcast i32* %801 to <4 x i32>*
  store <4 x i32> %805, <4 x i32>* %808, align 16
  %809 = getelementptr inbounds i32, i32* %801, i64 4
  %810 = bitcast i32* %809 to <4 x i32>*
  store <4 x i32> %807, <4 x i32>* %810, align 16
  %811 = bitcast <2 x i64> %772 to <8 x i16>
  %812 = getelementptr inbounds i32, i32* %778, i64 48
  %813 = shufflevector <8 x i16> %811, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %814 = shufflevector <8 x i16> %811, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %815 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %813, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %816 = ashr <4 x i32> %815, <i32 12, i32 12, i32 12, i32 12>
  %817 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %814, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %818 = ashr <4 x i32> %817, <i32 12, i32 12, i32 12, i32 12>
  %819 = bitcast i32* %812 to <4 x i32>*
  store <4 x i32> %816, <4 x i32>* %819, align 16
  %820 = getelementptr inbounds i32, i32* %812, i64 4
  %821 = bitcast i32* %820 to <4 x i32>*
  store <4 x i32> %818, <4 x i32>* %821, align 16
  %822 = bitcast <2 x i64> %773 to <8 x i16>
  %823 = getelementptr inbounds i32, i32* %778, i64 64
  %824 = shufflevector <8 x i16> %822, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %825 = shufflevector <8 x i16> %822, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %826 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %824, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %827 = ashr <4 x i32> %826, <i32 12, i32 12, i32 12, i32 12>
  %828 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %825, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %829 = ashr <4 x i32> %828, <i32 12, i32 12, i32 12, i32 12>
  %830 = bitcast i32* %823 to <4 x i32>*
  store <4 x i32> %827, <4 x i32>* %830, align 16
  %831 = getelementptr inbounds i32, i32* %823, i64 4
  %832 = bitcast i32* %831 to <4 x i32>*
  store <4 x i32> %829, <4 x i32>* %832, align 16
  %833 = bitcast <2 x i64> %774 to <8 x i16>
  %834 = getelementptr inbounds i32, i32* %778, i64 80
  %835 = shufflevector <8 x i16> %833, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %836 = shufflevector <8 x i16> %833, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %837 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %835, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %838 = ashr <4 x i32> %837, <i32 12, i32 12, i32 12, i32 12>
  %839 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %836, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %840 = ashr <4 x i32> %839, <i32 12, i32 12, i32 12, i32 12>
  %841 = bitcast i32* %834 to <4 x i32>*
  store <4 x i32> %838, <4 x i32>* %841, align 16
  %842 = getelementptr inbounds i32, i32* %834, i64 4
  %843 = bitcast i32* %842 to <4 x i32>*
  store <4 x i32> %840, <4 x i32>* %843, align 16
  %844 = bitcast <2 x i64> %775 to <8 x i16>
  %845 = getelementptr inbounds i32, i32* %778, i64 96
  %846 = shufflevector <8 x i16> %844, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %847 = shufflevector <8 x i16> %844, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %848 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %846, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %849 = ashr <4 x i32> %848, <i32 12, i32 12, i32 12, i32 12>
  %850 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %847, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %851 = ashr <4 x i32> %850, <i32 12, i32 12, i32 12, i32 12>
  %852 = bitcast i32* %845 to <4 x i32>*
  store <4 x i32> %849, <4 x i32>* %852, align 16
  %853 = getelementptr inbounds i32, i32* %845, i64 4
  %854 = bitcast i32* %853 to <4 x i32>*
  store <4 x i32> %851, <4 x i32>* %854, align 16
  %855 = load <8 x i16>, <8 x i16>* %721, align 16
  %856 = getelementptr inbounds i32, i32* %778, i64 112
  %857 = shufflevector <8 x i16> %855, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %858 = shufflevector <8 x i16> %855, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %859 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %857, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %860 = ashr <4 x i32> %859, <i32 12, i32 12, i32 12, i32 12>
  %861 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %858, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %862 = ashr <4 x i32> %861, <i32 12, i32 12, i32 12, i32 12>
  %863 = bitcast i32* %856 to <4 x i32>*
  store <4 x i32> %860, <4 x i32>* %863, align 16
  %864 = getelementptr inbounds i32, i32* %856, i64 4
  %865 = bitcast i32* %864 to <4 x i32>*
  store <4 x i32> %862, <4 x i32>* %865, align 16
  %866 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 8
  %867 = bitcast <2 x i64>* %866 to <8 x i16>*
  %868 = load <8 x i16>, <8 x i16>* %867, align 16
  %869 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 9
  %870 = bitcast <2 x i64>* %869 to <8 x i16>*
  %871 = load <8 x i16>, <8 x i16>* %870, align 16
  %872 = shufflevector <8 x i16> %868, <8 x i16> %871, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %873 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 10
  %874 = bitcast <2 x i64>* %873 to <8 x i16>*
  %875 = load <8 x i16>, <8 x i16>* %874, align 16
  %876 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 11
  %877 = bitcast <2 x i64>* %876 to <8 x i16>*
  %878 = load <8 x i16>, <8 x i16>* %877, align 16
  %879 = shufflevector <8 x i16> %875, <8 x i16> %878, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %880 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 12
  %881 = bitcast <2 x i64>* %880 to <8 x i16>*
  %882 = load <8 x i16>, <8 x i16>* %881, align 16
  %883 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 13
  %884 = bitcast <2 x i64>* %883 to <8 x i16>*
  %885 = load <8 x i16>, <8 x i16>* %884, align 16
  %886 = shufflevector <8 x i16> %882, <8 x i16> %885, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %887 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 14
  %888 = bitcast <2 x i64>* %887 to <8 x i16>*
  %889 = load <8 x i16>, <8 x i16>* %888, align 16
  %890 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 15
  %891 = bitcast <2 x i64>* %890 to <8 x i16>*
  %892 = load <8 x i16>, <8 x i16>* %891, align 16
  %893 = shufflevector <8 x i16> %889, <8 x i16> %892, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %894 = shufflevector <8 x i16> %868, <8 x i16> %871, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %895 = shufflevector <8 x i16> %875, <8 x i16> %878, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %896 = shufflevector <8 x i16> %882, <8 x i16> %885, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %897 = shufflevector <8 x i16> %889, <8 x i16> %892, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %898 = bitcast <8 x i16> %872 to <4 x i32>
  %899 = bitcast <8 x i16> %879 to <4 x i32>
  %900 = shufflevector <4 x i32> %898, <4 x i32> %899, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %901 = bitcast <4 x i32> %900 to <2 x i64>
  %902 = bitcast <8 x i16> %886 to <4 x i32>
  %903 = bitcast <8 x i16> %893 to <4 x i32>
  %904 = shufflevector <4 x i32> %902, <4 x i32> %903, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %905 = bitcast <4 x i32> %904 to <2 x i64>
  %906 = bitcast <8 x i16> %894 to <4 x i32>
  %907 = bitcast <8 x i16> %895 to <4 x i32>
  %908 = shufflevector <4 x i32> %906, <4 x i32> %907, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %909 = bitcast <4 x i32> %908 to <2 x i64>
  %910 = bitcast <8 x i16> %896 to <4 x i32>
  %911 = bitcast <8 x i16> %897 to <4 x i32>
  %912 = shufflevector <4 x i32> %910, <4 x i32> %911, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %913 = bitcast <4 x i32> %912 to <2 x i64>
  %914 = shufflevector <4 x i32> %898, <4 x i32> %899, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %915 = bitcast <4 x i32> %914 to <2 x i64>
  %916 = shufflevector <4 x i32> %902, <4 x i32> %903, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %917 = bitcast <4 x i32> %916 to <2 x i64>
  %918 = shufflevector <4 x i32> %906, <4 x i32> %907, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %919 = bitcast <4 x i32> %918 to <2 x i64>
  %920 = shufflevector <4 x i32> %910, <4 x i32> %911, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %921 = bitcast <4 x i32> %920 to <2 x i64>
  %922 = shufflevector <2 x i64> %901, <2 x i64> %905, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %922, <2 x i64>* %866, align 16
  %923 = shufflevector <2 x i64> %901, <2 x i64> %905, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %923, <2 x i64>* %869, align 16
  %924 = shufflevector <2 x i64> %915, <2 x i64> %917, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %924, <2 x i64>* %873, align 16
  %925 = shufflevector <2 x i64> %915, <2 x i64> %917, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %925, <2 x i64>* %876, align 16
  %926 = shufflevector <2 x i64> %909, <2 x i64> %913, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %926, <2 x i64>* %880, align 16
  %927 = shufflevector <2 x i64> %909, <2 x i64> %913, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %927, <2 x i64>* %883, align 16
  %928 = shufflevector <2 x i64> %919, <2 x i64> %921, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %928, <2 x i64>* %887, align 16
  %929 = shufflevector <2 x i64> %919, <2 x i64> %921, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %929, <2 x i64>* %890, align 16
  %930 = getelementptr inbounds i32, i32* %778, i64 8
  %931 = bitcast <2 x i64> %922 to <8 x i16>
  %932 = shufflevector <8 x i16> %931, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %933 = shufflevector <8 x i16> %931, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %934 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %932, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %935 = ashr <4 x i32> %934, <i32 12, i32 12, i32 12, i32 12>
  %936 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %933, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %937 = ashr <4 x i32> %936, <i32 12, i32 12, i32 12, i32 12>
  %938 = bitcast i32* %930 to <4 x i32>*
  store <4 x i32> %935, <4 x i32>* %938, align 16
  %939 = getelementptr inbounds i32, i32* %930, i64 4
  %940 = bitcast i32* %939 to <4 x i32>*
  store <4 x i32> %937, <4 x i32>* %940, align 16
  %941 = bitcast <2 x i64> %923 to <8 x i16>
  %942 = getelementptr inbounds i32, i32* %930, i64 16
  %943 = shufflevector <8 x i16> %941, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %944 = shufflevector <8 x i16> %941, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %945 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %943, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %946 = ashr <4 x i32> %945, <i32 12, i32 12, i32 12, i32 12>
  %947 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %944, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %948 = ashr <4 x i32> %947, <i32 12, i32 12, i32 12, i32 12>
  %949 = bitcast i32* %942 to <4 x i32>*
  store <4 x i32> %946, <4 x i32>* %949, align 16
  %950 = getelementptr inbounds i32, i32* %942, i64 4
  %951 = bitcast i32* %950 to <4 x i32>*
  store <4 x i32> %948, <4 x i32>* %951, align 16
  %952 = bitcast <2 x i64> %924 to <8 x i16>
  %953 = getelementptr inbounds i32, i32* %930, i64 32
  %954 = shufflevector <8 x i16> %952, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %955 = shufflevector <8 x i16> %952, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %956 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %954, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %957 = ashr <4 x i32> %956, <i32 12, i32 12, i32 12, i32 12>
  %958 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %955, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %959 = ashr <4 x i32> %958, <i32 12, i32 12, i32 12, i32 12>
  %960 = bitcast i32* %953 to <4 x i32>*
  store <4 x i32> %957, <4 x i32>* %960, align 16
  %961 = getelementptr inbounds i32, i32* %953, i64 4
  %962 = bitcast i32* %961 to <4 x i32>*
  store <4 x i32> %959, <4 x i32>* %962, align 16
  %963 = bitcast <2 x i64> %925 to <8 x i16>
  %964 = getelementptr inbounds i32, i32* %930, i64 48
  %965 = shufflevector <8 x i16> %963, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %966 = shufflevector <8 x i16> %963, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %967 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %965, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %968 = ashr <4 x i32> %967, <i32 12, i32 12, i32 12, i32 12>
  %969 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %966, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %970 = ashr <4 x i32> %969, <i32 12, i32 12, i32 12, i32 12>
  %971 = bitcast i32* %964 to <4 x i32>*
  store <4 x i32> %968, <4 x i32>* %971, align 16
  %972 = getelementptr inbounds i32, i32* %964, i64 4
  %973 = bitcast i32* %972 to <4 x i32>*
  store <4 x i32> %970, <4 x i32>* %973, align 16
  %974 = bitcast <2 x i64> %926 to <8 x i16>
  %975 = getelementptr inbounds i32, i32* %930, i64 64
  %976 = shufflevector <8 x i16> %974, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %977 = shufflevector <8 x i16> %974, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %978 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %976, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %979 = ashr <4 x i32> %978, <i32 12, i32 12, i32 12, i32 12>
  %980 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %977, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %981 = ashr <4 x i32> %980, <i32 12, i32 12, i32 12, i32 12>
  %982 = bitcast i32* %975 to <4 x i32>*
  store <4 x i32> %979, <4 x i32>* %982, align 16
  %983 = getelementptr inbounds i32, i32* %975, i64 4
  %984 = bitcast i32* %983 to <4 x i32>*
  store <4 x i32> %981, <4 x i32>* %984, align 16
  %985 = bitcast <2 x i64> %927 to <8 x i16>
  %986 = getelementptr inbounds i32, i32* %930, i64 80
  %987 = shufflevector <8 x i16> %985, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %988 = shufflevector <8 x i16> %985, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %989 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %987, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %990 = ashr <4 x i32> %989, <i32 12, i32 12, i32 12, i32 12>
  %991 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %988, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %992 = ashr <4 x i32> %991, <i32 12, i32 12, i32 12, i32 12>
  %993 = bitcast i32* %986 to <4 x i32>*
  store <4 x i32> %990, <4 x i32>* %993, align 16
  %994 = getelementptr inbounds i32, i32* %986, i64 4
  %995 = bitcast i32* %994 to <4 x i32>*
  store <4 x i32> %992, <4 x i32>* %995, align 16
  %996 = bitcast <2 x i64> %928 to <8 x i16>
  %997 = getelementptr inbounds i32, i32* %930, i64 96
  %998 = shufflevector <8 x i16> %996, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %999 = shufflevector <8 x i16> %996, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1000 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %998, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %1001 = ashr <4 x i32> %1000, <i32 12, i32 12, i32 12, i32 12>
  %1002 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %999, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %1003 = ashr <4 x i32> %1002, <i32 12, i32 12, i32 12, i32 12>
  %1004 = bitcast i32* %997 to <4 x i32>*
  store <4 x i32> %1001, <4 x i32>* %1004, align 16
  %1005 = getelementptr inbounds i32, i32* %997, i64 4
  %1006 = bitcast i32* %1005 to <4 x i32>*
  store <4 x i32> %1003, <4 x i32>* %1006, align 16
  %1007 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 15
  %1008 = bitcast <2 x i64>* %1007 to <8 x i16>*
  %1009 = load <8 x i16>, <8 x i16>* %1008, align 16
  %1010 = getelementptr inbounds i32, i32* %930, i64 112
  %1011 = shufflevector <8 x i16> %1009, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1012 = shufflevector <8 x i16> %1009, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1013 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1011, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %1014 = ashr <4 x i32> %1013, <i32 12, i32 12, i32 12, i32 12>
  %1015 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1012, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %1016 = ashr <4 x i32> %1015, <i32 12, i32 12, i32 12, i32 12>
  %1017 = bitcast i32* %1010 to <4 x i32>*
  store <4 x i32> %1014, <4 x i32>* %1017, align 16
  %1018 = getelementptr inbounds i32, i32* %1010, i64 4
  %1019 = bitcast i32* %1018 to <4 x i32>*
  store <4 x i32> %1016, <4 x i32>* %1019, align 16
  %1020 = add nuw nsw i64 %506, 1
  %1021 = icmp eq i64 %1020, 4
  br i1 %1021, label %1023, label %505

1022:                                             ; preds = %5
  tail call void @av1_fwd_txfm2d_16x32_c(i16* %0, i32* %1, i32 %2, i8 zeroext %3, i32 %4) #8
  br label %1023

1023:                                             ; preds = %720, %1022
  call void @llvm.lifetime.end.p0i8(i64 1024, i8* nonnull %9) #8
  call void @llvm.lifetime.end.p0i8(i64 512, i8* nonnull %8) #8
  ret void
}

declare void @av1_fwd_txfm2d_16x32_c(i16*, i32*, i32, i8 zeroext, i32) local_unnamed_addr #3

; Function Attrs: nounwind ssp uwtable
define hidden void @av1_lowbd_fwd_txfm2d_32x8_sse2(i16*, i32*, i32, i8 zeroext, i32) #2 {
  %6 = alloca [32 x <2 x i64>], align 16
  %7 = alloca [32 x <2 x i64>], align 16
  %8 = bitcast [32 x <2 x i64>]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 512, i8* nonnull %8) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %8, i8 -86, i64 512, i1 false)
  %9 = bitcast [32 x <2 x i64>]* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 512, i8* nonnull %9) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 512, i1 false)
  %10 = load i8*, i8** getelementptr inbounds ([19 x i8*], [19 x i8*]* @av1_fwd_txfm_shift_ls, i64 0, i64 16), align 16
  %11 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_fwd_cos_bit_col, i64 0, i64 3, i64 1), align 1
  %12 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_fwd_cos_bit_row, i64 0, i64 3, i64 1), align 1
  %13 = zext i8 %3 to i64
  %14 = getelementptr inbounds [16 x void (<2 x i64>*, <2 x i64>*, i8)*], [16 x void (<2 x i64>*, <2 x i64>*, i8)*]* @col_txfm8x8_arr, i64 0, i64 %13
  %15 = load void (<2 x i64>*, <2 x i64>*, i8)*, void (<2 x i64>*, <2 x i64>*, i8)** %14, align 8
  %16 = getelementptr inbounds [16 x void (<2 x i64>*, <2 x i64>*, i8)*], [16 x void (<2 x i64>*, <2 x i64>*, i8)*]* @row_txfm8x32_arr, i64 0, i64 %13
  %17 = load void (<2 x i64>*, <2 x i64>*, i8)*, void (<2 x i64>*, <2 x i64>*, i8)** %16, align 8
  %18 = lshr i64 3585, %13
  %19 = and i64 %18, 1
  %20 = icmp eq i64 %19, 0
  br i1 %20, label %375, label %21

21:                                               ; preds = %5
  switch i8 %3, label %25 [
    i8 6, label %24
    i8 15, label %23
    i8 7, label %23
    i8 5, label %23
    i8 14, label %22
    i8 8, label %22
    i8 4, label %22
  ]

22:                                               ; preds = %21, %21, %21
  br label %25

23:                                               ; preds = %21, %21, %21
  br label %25

24:                                               ; preds = %21
  br label %25

25:                                               ; preds = %21, %22, %23, %24
  %26 = phi i1 [ false, %24 ], [ true, %23 ], [ false, %22 ], [ true, %21 ]
  %27 = phi i32 [ 1, %24 ], [ 1, %23 ], [ 0, %22 ], [ 0, %21 ]
  %28 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 0
  %29 = sext i32 %2 to i64
  %30 = getelementptr inbounds i8, i8* %10, i64 1
  %31 = bitcast [32 x <2 x i64>]* %6 to <8 x i16>*
  %32 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 1
  %33 = bitcast <2 x i64>* %32 to <8 x i16>*
  %34 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 2
  %35 = bitcast <2 x i64>* %34 to <8 x i16>*
  %36 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 3
  %37 = bitcast <2 x i64>* %36 to <8 x i16>*
  %38 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 4
  %39 = bitcast <2 x i64>* %38 to <8 x i16>*
  %40 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 5
  %41 = bitcast <2 x i64>* %40 to <8 x i16>*
  %42 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 6
  %43 = bitcast <2 x i64>* %42 to <8 x i16>*
  %44 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 7
  %45 = bitcast <2 x i64>* %44 to <8 x i16>*
  %46 = shl nsw i64 %29, 1
  %47 = mul nsw i64 %29, 3
  %48 = shl nsw i64 %29, 2
  %49 = mul nsw i64 %29, 5
  %50 = mul nsw i64 %29, 6
  %51 = mul nsw i64 %29, 7
  %52 = shl nsw i64 %29, 1
  %53 = mul nsw i64 %29, 3
  %54 = shl nsw i64 %29, 2
  %55 = mul nsw i64 %29, 5
  %56 = mul nsw i64 %29, 6
  %57 = mul nsw i64 %29, 7
  %58 = bitcast [32 x <2 x i64>]* %6 to <8 x i16>*
  %59 = bitcast [32 x <2 x i64>]* %6 to <8 x i16>*
  %60 = bitcast [32 x <2 x i64>]* %6 to <8 x i16>*
  %61 = bitcast [32 x <2 x i64>]* %6 to <8 x i16>*
  br label %62

62:                                               ; preds = %231, %25
  %63 = phi i64 [ 0, %25 ], [ %288, %231 ]
  %64 = shl nsw i64 %63, 3
  %65 = getelementptr inbounds i16, i16* %0, i64 %64
  %66 = bitcast i16* %65 to <2 x i64>*
  %67 = load <2 x i64>, <2 x i64>* %66, align 16
  br i1 %26, label %90, label %68

68:                                               ; preds = %62
  store <2 x i64> %67, <2 x i64>* %44, align 16
  %69 = getelementptr inbounds i16, i16* %65, i64 %29
  %70 = bitcast i16* %69 to <2 x i64>*
  %71 = load <2 x i64>, <2 x i64>* %70, align 16
  store <2 x i64> %71, <2 x i64>* %42, align 16
  %72 = getelementptr inbounds i16, i16* %65, i64 %46
  %73 = bitcast i16* %72 to <2 x i64>*
  %74 = load <2 x i64>, <2 x i64>* %73, align 16
  store <2 x i64> %74, <2 x i64>* %40, align 16
  %75 = getelementptr inbounds i16, i16* %65, i64 %47
  %76 = bitcast i16* %75 to <2 x i64>*
  %77 = load <2 x i64>, <2 x i64>* %76, align 16
  store <2 x i64> %77, <2 x i64>* %38, align 16
  %78 = getelementptr inbounds i16, i16* %65, i64 %48
  %79 = bitcast i16* %78 to <2 x i64>*
  %80 = load <2 x i64>, <2 x i64>* %79, align 16
  store <2 x i64> %80, <2 x i64>* %36, align 16
  %81 = getelementptr inbounds i16, i16* %65, i64 %49
  %82 = bitcast i16* %81 to <2 x i64>*
  %83 = load <2 x i64>, <2 x i64>* %82, align 16
  store <2 x i64> %83, <2 x i64>* %34, align 16
  %84 = getelementptr inbounds i16, i16* %65, i64 %50
  %85 = bitcast i16* %84 to <2 x i64>*
  %86 = load <2 x i64>, <2 x i64>* %85, align 16
  store <2 x i64> %86, <2 x i64>* %32, align 16
  %87 = getelementptr inbounds i16, i16* %65, i64 %51
  %88 = bitcast i16* %87 to <2 x i64>*
  %89 = load <2 x i64>, <2 x i64>* %88, align 16
  store <2 x i64> %89, <2 x i64>* %28, align 16
  br label %112

90:                                               ; preds = %62
  store <2 x i64> %67, <2 x i64>* %28, align 16
  %91 = getelementptr inbounds i16, i16* %65, i64 %29
  %92 = bitcast i16* %91 to <2 x i64>*
  %93 = load <2 x i64>, <2 x i64>* %92, align 16
  store <2 x i64> %93, <2 x i64>* %32, align 16
  %94 = getelementptr inbounds i16, i16* %65, i64 %52
  %95 = bitcast i16* %94 to <2 x i64>*
  %96 = load <2 x i64>, <2 x i64>* %95, align 16
  store <2 x i64> %96, <2 x i64>* %34, align 16
  %97 = getelementptr inbounds i16, i16* %65, i64 %53
  %98 = bitcast i16* %97 to <2 x i64>*
  %99 = load <2 x i64>, <2 x i64>* %98, align 16
  store <2 x i64> %99, <2 x i64>* %36, align 16
  %100 = getelementptr inbounds i16, i16* %65, i64 %54
  %101 = bitcast i16* %100 to <2 x i64>*
  %102 = load <2 x i64>, <2 x i64>* %101, align 16
  store <2 x i64> %102, <2 x i64>* %38, align 16
  %103 = getelementptr inbounds i16, i16* %65, i64 %55
  %104 = bitcast i16* %103 to <2 x i64>*
  %105 = load <2 x i64>, <2 x i64>* %104, align 16
  store <2 x i64> %105, <2 x i64>* %40, align 16
  %106 = getelementptr inbounds i16, i16* %65, i64 %56
  %107 = bitcast i16* %106 to <2 x i64>*
  %108 = load <2 x i64>, <2 x i64>* %107, align 16
  store <2 x i64> %108, <2 x i64>* %42, align 16
  %109 = getelementptr inbounds i16, i16* %65, i64 %57
  %110 = bitcast i16* %109 to <2 x i64>*
  %111 = load <2 x i64>, <2 x i64>* %110, align 16
  store <2 x i64> %111, <2 x i64>* %44, align 16
  br label %112

112:                                              ; preds = %68, %90
  %113 = phi <2 x i64> [ %67, %68 ], [ %111, %90 ]
  %114 = phi <2 x i64> [ %71, %68 ], [ %108, %90 ]
  %115 = phi <2 x i64> [ %74, %68 ], [ %105, %90 ]
  %116 = phi <2 x i64> [ %77, %68 ], [ %102, %90 ]
  %117 = phi <2 x i64> [ %80, %68 ], [ %99, %90 ]
  %118 = phi <2 x i64> [ %83, %68 ], [ %96, %90 ]
  %119 = phi <2 x i64> [ %86, %68 ], [ %93, %90 ]
  %120 = phi <2 x i64> [ %89, %68 ], [ %67, %90 ]
  %121 = bitcast <2 x i64> %120 to <8 x i16>
  %122 = bitcast <2 x i64> %119 to <8 x i16>
  %123 = bitcast <2 x i64> %118 to <8 x i16>
  %124 = bitcast <2 x i64> %117 to <8 x i16>
  %125 = bitcast <2 x i64> %116 to <8 x i16>
  %126 = bitcast <2 x i64> %115 to <8 x i16>
  %127 = bitcast <2 x i64> %114 to <8 x i16>
  %128 = bitcast <2 x i64> %113 to <8 x i16>
  %129 = load i8, i8* %10, align 1
  %130 = sext i8 %129 to i32
  %131 = icmp slt i8 %129, 0
  br i1 %131, label %132, label %155

132:                                              ; preds = %112
  %133 = sub nsw i32 0, %130
  %134 = xor i32 %130, -1
  %135 = shl i32 1, %134
  %136 = trunc i32 %135 to i16
  %137 = insertelement <8 x i16> undef, i16 %136, i32 0
  %138 = shufflevector <8 x i16> %137, <8 x i16> undef, <8 x i32> zeroinitializer
  %139 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %121, <8 x i16> %138) #8
  %140 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %139, i32 %133) #8
  store <8 x i16> %140, <8 x i16>* %59, align 16
  %141 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %122, <8 x i16> %138) #8
  %142 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %141, i32 %133) #8
  store <8 x i16> %142, <8 x i16>* %33, align 16
  %143 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %123, <8 x i16> %138) #8
  %144 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %143, i32 %133) #8
  store <8 x i16> %144, <8 x i16>* %35, align 16
  %145 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %124, <8 x i16> %138) #8
  %146 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %145, i32 %133) #8
  store <8 x i16> %146, <8 x i16>* %37, align 16
  %147 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %125, <8 x i16> %138) #8
  %148 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %147, i32 %133) #8
  store <8 x i16> %148, <8 x i16>* %39, align 16
  %149 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %126, <8 x i16> %138) #8
  %150 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %149, i32 %133) #8
  store <8 x i16> %150, <8 x i16>* %41, align 16
  %151 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %127, <8 x i16> %138) #8
  %152 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %151, i32 %133) #8
  store <8 x i16> %152, <8 x i16>* %43, align 16
  %153 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %128, <8 x i16> %138) #8
  %154 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %153, i32 %133) #8
  br label %166

155:                                              ; preds = %112
  %156 = icmp eq i8 %129, 0
  br i1 %156, label %168, label %157

157:                                              ; preds = %155
  %158 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %121, i32 %130) #8
  store <8 x i16> %158, <8 x i16>* %58, align 16
  %159 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %122, i32 %130) #8
  store <8 x i16> %159, <8 x i16>* %33, align 16
  %160 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %123, i32 %130) #8
  store <8 x i16> %160, <8 x i16>* %35, align 16
  %161 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %124, i32 %130) #8
  store <8 x i16> %161, <8 x i16>* %37, align 16
  %162 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %125, i32 %130) #8
  store <8 x i16> %162, <8 x i16>* %39, align 16
  %163 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %126, i32 %130) #8
  store <8 x i16> %163, <8 x i16>* %41, align 16
  %164 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %127, i32 %130) #8
  store <8 x i16> %164, <8 x i16>* %43, align 16
  %165 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %128, i32 %130) #8
  br label %166

166:                                              ; preds = %132, %157
  %167 = phi <8 x i16> [ %165, %157 ], [ %154, %132 ]
  store <8 x i16> %167, <8 x i16>* %45, align 16
  br label %168

168:                                              ; preds = %166, %155
  call void %15(<2 x i64>* nonnull %28, <2 x i64>* nonnull %28, i8 signext %11) #8
  %169 = load i8, i8* %30, align 1
  %170 = sext i8 %169 to i32
  %171 = icmp slt i8 %169, 0
  br i1 %171, label %172, label %203

172:                                              ; preds = %168
  %173 = sub nsw i32 0, %170
  %174 = xor i32 %170, -1
  %175 = shl i32 1, %174
  %176 = trunc i32 %175 to i16
  %177 = insertelement <8 x i16> undef, i16 %176, i32 0
  %178 = shufflevector <8 x i16> %177, <8 x i16> undef, <8 x i32> zeroinitializer
  %179 = load <8 x i16>, <8 x i16>* %61, align 16
  %180 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %179, <8 x i16> %178) #8
  %181 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %180, i32 %173) #8
  store <8 x i16> %181, <8 x i16>* %61, align 16
  %182 = load <8 x i16>, <8 x i16>* %33, align 16
  %183 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %182, <8 x i16> %178) #8
  %184 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %183, i32 %173) #8
  store <8 x i16> %184, <8 x i16>* %33, align 16
  %185 = load <8 x i16>, <8 x i16>* %35, align 16
  %186 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %185, <8 x i16> %178) #8
  %187 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %186, i32 %173) #8
  store <8 x i16> %187, <8 x i16>* %35, align 16
  %188 = load <8 x i16>, <8 x i16>* %37, align 16
  %189 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %188, <8 x i16> %178) #8
  %190 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %189, i32 %173) #8
  store <8 x i16> %190, <8 x i16>* %37, align 16
  %191 = load <8 x i16>, <8 x i16>* %39, align 16
  %192 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %191, <8 x i16> %178) #8
  %193 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %192, i32 %173) #8
  store <8 x i16> %193, <8 x i16>* %39, align 16
  %194 = load <8 x i16>, <8 x i16>* %41, align 16
  %195 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %194, <8 x i16> %178) #8
  %196 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %195, i32 %173) #8
  store <8 x i16> %196, <8 x i16>* %41, align 16
  %197 = load <8 x i16>, <8 x i16>* %43, align 16
  %198 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %197, <8 x i16> %178) #8
  %199 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %198, i32 %173) #8
  store <8 x i16> %199, <8 x i16>* %43, align 16
  %200 = load <8 x i16>, <8 x i16>* %45, align 16
  %201 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %200, <8 x i16> %178) #8
  %202 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %201, i32 %173) #8
  store <8 x i16> %202, <8 x i16>* %45, align 16
  br label %231

203:                                              ; preds = %168
  %204 = icmp eq i8 %169, 0
  br i1 %204, label %205, label %214

205:                                              ; preds = %203
  %206 = load <8 x i16>, <8 x i16>* %31, align 16
  %207 = load <8 x i16>, <8 x i16>* %33, align 16
  %208 = load <8 x i16>, <8 x i16>* %35, align 16
  %209 = load <8 x i16>, <8 x i16>* %37, align 16
  %210 = load <8 x i16>, <8 x i16>* %39, align 16
  %211 = load <8 x i16>, <8 x i16>* %41, align 16
  %212 = load <8 x i16>, <8 x i16>* %43, align 16
  %213 = load <8 x i16>, <8 x i16>* %45, align 16
  br label %231

214:                                              ; preds = %203
  %215 = load <8 x i16>, <8 x i16>* %60, align 16
  %216 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %215, i32 %170) #8
  store <8 x i16> %216, <8 x i16>* %60, align 16
  %217 = load <8 x i16>, <8 x i16>* %33, align 16
  %218 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %217, i32 %170) #8
  store <8 x i16> %218, <8 x i16>* %33, align 16
  %219 = load <8 x i16>, <8 x i16>* %35, align 16
  %220 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %219, i32 %170) #8
  store <8 x i16> %220, <8 x i16>* %35, align 16
  %221 = load <8 x i16>, <8 x i16>* %37, align 16
  %222 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %221, i32 %170) #8
  store <8 x i16> %222, <8 x i16>* %37, align 16
  %223 = load <8 x i16>, <8 x i16>* %39, align 16
  %224 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %223, i32 %170) #8
  store <8 x i16> %224, <8 x i16>* %39, align 16
  %225 = load <8 x i16>, <8 x i16>* %41, align 16
  %226 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %225, i32 %170) #8
  store <8 x i16> %226, <8 x i16>* %41, align 16
  %227 = load <8 x i16>, <8 x i16>* %43, align 16
  %228 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %227, i32 %170) #8
  store <8 x i16> %228, <8 x i16>* %43, align 16
  %229 = load <8 x i16>, <8 x i16>* %45, align 16
  %230 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %229, i32 %170) #8
  store <8 x i16> %230, <8 x i16>* %45, align 16
  br label %231

231:                                              ; preds = %205, %214, %172
  %232 = phi <8 x i16> [ %213, %205 ], [ %230, %214 ], [ %202, %172 ]
  %233 = phi <8 x i16> [ %212, %205 ], [ %228, %214 ], [ %199, %172 ]
  %234 = phi <8 x i16> [ %211, %205 ], [ %226, %214 ], [ %196, %172 ]
  %235 = phi <8 x i16> [ %210, %205 ], [ %224, %214 ], [ %193, %172 ]
  %236 = phi <8 x i16> [ %209, %205 ], [ %222, %214 ], [ %190, %172 ]
  %237 = phi <8 x i16> [ %208, %205 ], [ %220, %214 ], [ %187, %172 ]
  %238 = phi <8 x i16> [ %207, %205 ], [ %218, %214 ], [ %184, %172 ]
  %239 = phi <8 x i16> [ %206, %205 ], [ %216, %214 ], [ %181, %172 ]
  %240 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 %64
  %241 = shufflevector <8 x i16> %239, <8 x i16> %238, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %242 = shufflevector <8 x i16> %237, <8 x i16> %236, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %243 = shufflevector <8 x i16> %235, <8 x i16> %234, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %244 = shufflevector <8 x i16> %233, <8 x i16> %232, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %245 = shufflevector <8 x i16> %239, <8 x i16> %238, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %246 = shufflevector <8 x i16> %237, <8 x i16> %236, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %247 = shufflevector <8 x i16> %235, <8 x i16> %234, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %248 = shufflevector <8 x i16> %233, <8 x i16> %232, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %249 = bitcast <8 x i16> %241 to <4 x i32>
  %250 = bitcast <8 x i16> %242 to <4 x i32>
  %251 = shufflevector <4 x i32> %249, <4 x i32> %250, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %252 = bitcast <4 x i32> %251 to <2 x i64>
  %253 = bitcast <8 x i16> %243 to <4 x i32>
  %254 = bitcast <8 x i16> %244 to <4 x i32>
  %255 = shufflevector <4 x i32> %253, <4 x i32> %254, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %256 = bitcast <4 x i32> %255 to <2 x i64>
  %257 = bitcast <8 x i16> %245 to <4 x i32>
  %258 = bitcast <8 x i16> %246 to <4 x i32>
  %259 = shufflevector <4 x i32> %257, <4 x i32> %258, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %260 = bitcast <4 x i32> %259 to <2 x i64>
  %261 = bitcast <8 x i16> %247 to <4 x i32>
  %262 = bitcast <8 x i16> %248 to <4 x i32>
  %263 = shufflevector <4 x i32> %261, <4 x i32> %262, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %264 = bitcast <4 x i32> %263 to <2 x i64>
  %265 = shufflevector <4 x i32> %249, <4 x i32> %250, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %266 = bitcast <4 x i32> %265 to <2 x i64>
  %267 = shufflevector <4 x i32> %253, <4 x i32> %254, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %268 = bitcast <4 x i32> %267 to <2 x i64>
  %269 = shufflevector <4 x i32> %257, <4 x i32> %258, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %270 = bitcast <4 x i32> %269 to <2 x i64>
  %271 = shufflevector <4 x i32> %261, <4 x i32> %262, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %272 = bitcast <4 x i32> %271 to <2 x i64>
  %273 = shufflevector <2 x i64> %252, <2 x i64> %256, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %273, <2 x i64>* %240, align 16
  %274 = shufflevector <2 x i64> %252, <2 x i64> %256, <2 x i32> <i32 1, i32 3>
  %275 = getelementptr inbounds <2 x i64>, <2 x i64>* %240, i64 1
  store <2 x i64> %274, <2 x i64>* %275, align 16
  %276 = shufflevector <2 x i64> %266, <2 x i64> %268, <2 x i32> <i32 0, i32 2>
  %277 = getelementptr inbounds <2 x i64>, <2 x i64>* %240, i64 2
  store <2 x i64> %276, <2 x i64>* %277, align 16
  %278 = shufflevector <2 x i64> %266, <2 x i64> %268, <2 x i32> <i32 1, i32 3>
  %279 = getelementptr inbounds <2 x i64>, <2 x i64>* %240, i64 3
  store <2 x i64> %278, <2 x i64>* %279, align 16
  %280 = shufflevector <2 x i64> %260, <2 x i64> %264, <2 x i32> <i32 0, i32 2>
  %281 = getelementptr inbounds <2 x i64>, <2 x i64>* %240, i64 4
  store <2 x i64> %280, <2 x i64>* %281, align 16
  %282 = shufflevector <2 x i64> %260, <2 x i64> %264, <2 x i32> <i32 1, i32 3>
  %283 = getelementptr inbounds <2 x i64>, <2 x i64>* %240, i64 5
  store <2 x i64> %282, <2 x i64>* %283, align 16
  %284 = shufflevector <2 x i64> %270, <2 x i64> %272, <2 x i32> <i32 0, i32 2>
  %285 = getelementptr inbounds <2 x i64>, <2 x i64>* %240, i64 6
  store <2 x i64> %284, <2 x i64>* %285, align 16
  %286 = shufflevector <2 x i64> %270, <2 x i64> %272, <2 x i32> <i32 1, i32 3>
  %287 = getelementptr inbounds <2 x i64>, <2 x i64>* %240, i64 7
  store <2 x i64> %286, <2 x i64>* %287, align 16
  %288 = add nuw nsw i64 %63, 1
  %289 = icmp eq i64 %288, 4
  br i1 %289, label %290, label %62

290:                                              ; preds = %231
  %291 = icmp eq i32 %27, 0
  %292 = getelementptr inbounds i8, i8* %10, i64 2
  %293 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 0
  br i1 %291, label %311, label %294

294:                                              ; preds = %290, %294
  %295 = phi i64 [ %309, %294 ], [ 0, %290 ]
  %296 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 %295
  %297 = load <2 x i64>, <2 x i64>* %296, align 16
  %298 = shl i64 %295, 32
  %299 = sub nuw nsw i64 133143986176, %298
  %300 = ashr exact i64 %299, 32
  %301 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %300
  store <2 x i64> %297, <2 x i64>* %301, align 16
  %302 = or i64 %295, 1
  %303 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %7, i64 0, i64 %302
  %304 = load <2 x i64>, <2 x i64>* %303, align 16
  %305 = shl i64 %302, 32
  %306 = sub nuw nsw i64 133143986176, %305
  %307 = ashr exact i64 %306, 32
  %308 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %307
  store <2 x i64> %304, <2 x i64>* %308, align 16
  %309 = add nuw nsw i64 %295, 2
  %310 = icmp eq i64 %309, 32
  br i1 %310, label %311, label %294

311:                                              ; preds = %294, %290
  %312 = phi <2 x i64>* [ %293, %290 ], [ %28, %294 ]
  call void %17(<2 x i64>* %312, <2 x i64>* %312, i8 signext %12) #8
  %313 = load i8, i8* %292, align 1
  %314 = sext i8 %313 to i32
  %315 = icmp slt i8 %313, 0
  br i1 %315, label %316, label %350

316:                                              ; preds = %311
  %317 = sub nsw i32 0, %314
  %318 = xor i32 %314, -1
  %319 = shl i32 1, %318
  %320 = trunc i32 %319 to i16
  %321 = insertelement <8 x i16> undef, i16 %320, i32 0
  %322 = shufflevector <8 x i16> %321, <8 x i16> undef, <8 x i32> zeroinitializer
  br label %323

323:                                              ; preds = %323, %316
  %324 = phi i64 [ 0, %316 ], [ %348, %323 ]
  %325 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 %324
  %326 = bitcast <2 x i64>* %325 to <8 x i16>*
  %327 = load <8 x i16>, <8 x i16>* %326, align 16
  %328 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %327, <8 x i16> %322) #8
  %329 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %328, i32 %317) #8
  store <8 x i16> %329, <8 x i16>* %326, align 16
  %330 = or i64 %324, 1
  %331 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 %330
  %332 = bitcast <2 x i64>* %331 to <8 x i16>*
  %333 = load <8 x i16>, <8 x i16>* %332, align 16
  %334 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %333, <8 x i16> %322) #8
  %335 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %334, i32 %317) #8
  store <8 x i16> %335, <8 x i16>* %332, align 16
  %336 = or i64 %324, 2
  %337 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 %336
  %338 = bitcast <2 x i64>* %337 to <8 x i16>*
  %339 = load <8 x i16>, <8 x i16>* %338, align 16
  %340 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %339, <8 x i16> %322) #8
  %341 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %340, i32 %317) #8
  store <8 x i16> %341, <8 x i16>* %338, align 16
  %342 = or i64 %324, 3
  %343 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 %342
  %344 = bitcast <2 x i64>* %343 to <8 x i16>*
  %345 = load <8 x i16>, <8 x i16>* %344, align 16
  %346 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %345, <8 x i16> %322) #8
  %347 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %346, i32 %317) #8
  store <8 x i16> %347, <8 x i16>* %344, align 16
  %348 = add nuw nsw i64 %324, 4
  %349 = icmp eq i64 %348, 32
  br i1 %349, label %376, label %323

350:                                              ; preds = %311
  %351 = icmp eq i8 %313, 0
  br i1 %351, label %376, label %352

352:                                              ; preds = %350, %352
  %353 = phi i64 [ %373, %352 ], [ 0, %350 ]
  %354 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 %353
  %355 = bitcast <2 x i64>* %354 to <8 x i16>*
  %356 = load <8 x i16>, <8 x i16>* %355, align 16
  %357 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %356, i32 %314) #8
  store <8 x i16> %357, <8 x i16>* %355, align 16
  %358 = or i64 %353, 1
  %359 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 %358
  %360 = bitcast <2 x i64>* %359 to <8 x i16>*
  %361 = load <8 x i16>, <8 x i16>* %360, align 16
  %362 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %361, i32 %314) #8
  store <8 x i16> %362, <8 x i16>* %360, align 16
  %363 = or i64 %353, 2
  %364 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 %363
  %365 = bitcast <2 x i64>* %364 to <8 x i16>*
  %366 = load <8 x i16>, <8 x i16>* %365, align 16
  %367 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %366, i32 %314) #8
  store <8 x i16> %367, <8 x i16>* %365, align 16
  %368 = or i64 %353, 3
  %369 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 %368
  %370 = bitcast <2 x i64>* %369 to <8 x i16>*
  %371 = load <8 x i16>, <8 x i16>* %370, align 16
  %372 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %371, i32 %314) #8
  store <8 x i16> %372, <8 x i16>* %370, align 16
  %373 = add nuw nsw i64 %353, 4
  %374 = icmp eq i64 %373, 32
  br i1 %374, label %376, label %352

375:                                              ; preds = %5
  tail call void @av1_fwd_txfm2d_32x16_c(i16* %0, i32* %1, i32 %2, i8 zeroext %3, i32 %4) #8
  br label %989

376:                                              ; preds = %352, %323, %350
  %377 = bitcast <2 x i64>* %312 to <8 x i16>*
  %378 = load <8 x i16>, <8 x i16>* %377, align 16
  %379 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 1
  %380 = bitcast <2 x i64>* %379 to <8 x i16>*
  %381 = load <8 x i16>, <8 x i16>* %380, align 16
  %382 = shufflevector <8 x i16> %378, <8 x i16> %381, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %383 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 2
  %384 = bitcast <2 x i64>* %383 to <8 x i16>*
  %385 = load <8 x i16>, <8 x i16>* %384, align 16
  %386 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 3
  %387 = bitcast <2 x i64>* %386 to <8 x i16>*
  %388 = load <8 x i16>, <8 x i16>* %387, align 16
  %389 = shufflevector <8 x i16> %385, <8 x i16> %388, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %390 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 4
  %391 = bitcast <2 x i64>* %390 to <8 x i16>*
  %392 = load <8 x i16>, <8 x i16>* %391, align 16
  %393 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 5
  %394 = bitcast <2 x i64>* %393 to <8 x i16>*
  %395 = load <8 x i16>, <8 x i16>* %394, align 16
  %396 = shufflevector <8 x i16> %392, <8 x i16> %395, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %397 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 6
  %398 = bitcast <2 x i64>* %397 to <8 x i16>*
  %399 = load <8 x i16>, <8 x i16>* %398, align 16
  %400 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 7
  %401 = bitcast <2 x i64>* %400 to <8 x i16>*
  %402 = load <8 x i16>, <8 x i16>* %401, align 16
  %403 = shufflevector <8 x i16> %399, <8 x i16> %402, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %404 = shufflevector <8 x i16> %378, <8 x i16> %381, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %405 = shufflevector <8 x i16> %385, <8 x i16> %388, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %406 = shufflevector <8 x i16> %392, <8 x i16> %395, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %407 = shufflevector <8 x i16> %399, <8 x i16> %402, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %408 = bitcast <8 x i16> %382 to <4 x i32>
  %409 = bitcast <8 x i16> %389 to <4 x i32>
  %410 = shufflevector <4 x i32> %408, <4 x i32> %409, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %411 = bitcast <4 x i32> %410 to <2 x i64>
  %412 = bitcast <8 x i16> %396 to <4 x i32>
  %413 = bitcast <8 x i16> %403 to <4 x i32>
  %414 = shufflevector <4 x i32> %412, <4 x i32> %413, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %415 = bitcast <4 x i32> %414 to <2 x i64>
  %416 = bitcast <8 x i16> %404 to <4 x i32>
  %417 = bitcast <8 x i16> %405 to <4 x i32>
  %418 = shufflevector <4 x i32> %416, <4 x i32> %417, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %419 = bitcast <4 x i32> %418 to <2 x i64>
  %420 = bitcast <8 x i16> %406 to <4 x i32>
  %421 = bitcast <8 x i16> %407 to <4 x i32>
  %422 = shufflevector <4 x i32> %420, <4 x i32> %421, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %423 = bitcast <4 x i32> %422 to <2 x i64>
  %424 = shufflevector <4 x i32> %408, <4 x i32> %409, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %425 = bitcast <4 x i32> %424 to <2 x i64>
  %426 = shufflevector <4 x i32> %412, <4 x i32> %413, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %427 = bitcast <4 x i32> %426 to <2 x i64>
  %428 = shufflevector <4 x i32> %416, <4 x i32> %417, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %429 = bitcast <4 x i32> %428 to <2 x i64>
  %430 = shufflevector <4 x i32> %420, <4 x i32> %421, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %431 = bitcast <4 x i32> %430 to <2 x i64>
  %432 = shufflevector <2 x i64> %411, <2 x i64> %415, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %432, <2 x i64>* %312, align 16
  %433 = shufflevector <2 x i64> %411, <2 x i64> %415, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %433, <2 x i64>* %379, align 16
  %434 = shufflevector <2 x i64> %425, <2 x i64> %427, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %434, <2 x i64>* %383, align 16
  %435 = shufflevector <2 x i64> %425, <2 x i64> %427, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %435, <2 x i64>* %386, align 16
  %436 = shufflevector <2 x i64> %419, <2 x i64> %423, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %436, <2 x i64>* %390, align 16
  %437 = shufflevector <2 x i64> %419, <2 x i64> %423, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %437, <2 x i64>* %393, align 16
  %438 = shufflevector <2 x i64> %429, <2 x i64> %431, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %438, <2 x i64>* %397, align 16
  %439 = shufflevector <2 x i64> %429, <2 x i64> %431, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %439, <2 x i64>* %400, align 16
  %440 = bitcast <2 x i64> %432 to <8 x i16>
  %441 = shufflevector <8 x i16> %440, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %442 = shufflevector <8 x i16> %440, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %443 = bitcast <8 x i16> %441 to <4 x i32>
  %444 = ashr <4 x i32> %443, <i32 16, i32 16, i32 16, i32 16>
  %445 = bitcast <8 x i16> %442 to <4 x i32>
  %446 = ashr <4 x i32> %445, <i32 16, i32 16, i32 16, i32 16>
  %447 = bitcast i32* %1 to <4 x i32>*
  store <4 x i32> %444, <4 x i32>* %447, align 16
  %448 = getelementptr inbounds i32, i32* %1, i64 4
  %449 = bitcast i32* %448 to <4 x i32>*
  store <4 x i32> %446, <4 x i32>* %449, align 16
  %450 = bitcast <2 x i64> %433 to <8 x i16>
  %451 = getelementptr inbounds i32, i32* %1, i64 32
  %452 = shufflevector <8 x i16> %450, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %453 = shufflevector <8 x i16> %450, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %454 = bitcast <8 x i16> %452 to <4 x i32>
  %455 = ashr <4 x i32> %454, <i32 16, i32 16, i32 16, i32 16>
  %456 = bitcast <8 x i16> %453 to <4 x i32>
  %457 = ashr <4 x i32> %456, <i32 16, i32 16, i32 16, i32 16>
  %458 = bitcast i32* %451 to <4 x i32>*
  store <4 x i32> %455, <4 x i32>* %458, align 16
  %459 = getelementptr inbounds i32, i32* %1, i64 36
  %460 = bitcast i32* %459 to <4 x i32>*
  store <4 x i32> %457, <4 x i32>* %460, align 16
  %461 = bitcast <2 x i64> %434 to <8 x i16>
  %462 = getelementptr inbounds i32, i32* %1, i64 64
  %463 = shufflevector <8 x i16> %461, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %464 = shufflevector <8 x i16> %461, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %465 = bitcast <8 x i16> %463 to <4 x i32>
  %466 = ashr <4 x i32> %465, <i32 16, i32 16, i32 16, i32 16>
  %467 = bitcast <8 x i16> %464 to <4 x i32>
  %468 = ashr <4 x i32> %467, <i32 16, i32 16, i32 16, i32 16>
  %469 = bitcast i32* %462 to <4 x i32>*
  store <4 x i32> %466, <4 x i32>* %469, align 16
  %470 = getelementptr inbounds i32, i32* %1, i64 68
  %471 = bitcast i32* %470 to <4 x i32>*
  store <4 x i32> %468, <4 x i32>* %471, align 16
  %472 = bitcast <2 x i64> %435 to <8 x i16>
  %473 = getelementptr inbounds i32, i32* %1, i64 96
  %474 = shufflevector <8 x i16> %472, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %475 = shufflevector <8 x i16> %472, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %476 = bitcast <8 x i16> %474 to <4 x i32>
  %477 = ashr <4 x i32> %476, <i32 16, i32 16, i32 16, i32 16>
  %478 = bitcast <8 x i16> %475 to <4 x i32>
  %479 = ashr <4 x i32> %478, <i32 16, i32 16, i32 16, i32 16>
  %480 = bitcast i32* %473 to <4 x i32>*
  store <4 x i32> %477, <4 x i32>* %480, align 16
  %481 = getelementptr inbounds i32, i32* %1, i64 100
  %482 = bitcast i32* %481 to <4 x i32>*
  store <4 x i32> %479, <4 x i32>* %482, align 16
  %483 = bitcast <2 x i64> %436 to <8 x i16>
  %484 = getelementptr inbounds i32, i32* %1, i64 128
  %485 = shufflevector <8 x i16> %483, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %486 = shufflevector <8 x i16> %483, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %487 = bitcast <8 x i16> %485 to <4 x i32>
  %488 = ashr <4 x i32> %487, <i32 16, i32 16, i32 16, i32 16>
  %489 = bitcast <8 x i16> %486 to <4 x i32>
  %490 = ashr <4 x i32> %489, <i32 16, i32 16, i32 16, i32 16>
  %491 = bitcast i32* %484 to <4 x i32>*
  store <4 x i32> %488, <4 x i32>* %491, align 16
  %492 = getelementptr inbounds i32, i32* %1, i64 132
  %493 = bitcast i32* %492 to <4 x i32>*
  store <4 x i32> %490, <4 x i32>* %493, align 16
  %494 = bitcast <2 x i64> %437 to <8 x i16>
  %495 = getelementptr inbounds i32, i32* %1, i64 160
  %496 = shufflevector <8 x i16> %494, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %497 = shufflevector <8 x i16> %494, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %498 = bitcast <8 x i16> %496 to <4 x i32>
  %499 = ashr <4 x i32> %498, <i32 16, i32 16, i32 16, i32 16>
  %500 = bitcast <8 x i16> %497 to <4 x i32>
  %501 = ashr <4 x i32> %500, <i32 16, i32 16, i32 16, i32 16>
  %502 = bitcast i32* %495 to <4 x i32>*
  store <4 x i32> %499, <4 x i32>* %502, align 16
  %503 = getelementptr inbounds i32, i32* %1, i64 164
  %504 = bitcast i32* %503 to <4 x i32>*
  store <4 x i32> %501, <4 x i32>* %504, align 16
  %505 = bitcast <2 x i64> %438 to <8 x i16>
  %506 = getelementptr inbounds i32, i32* %1, i64 192
  %507 = shufflevector <8 x i16> %505, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %508 = shufflevector <8 x i16> %505, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %509 = bitcast <8 x i16> %507 to <4 x i32>
  %510 = ashr <4 x i32> %509, <i32 16, i32 16, i32 16, i32 16>
  %511 = bitcast <8 x i16> %508 to <4 x i32>
  %512 = ashr <4 x i32> %511, <i32 16, i32 16, i32 16, i32 16>
  %513 = bitcast i32* %506 to <4 x i32>*
  store <4 x i32> %510, <4 x i32>* %513, align 16
  %514 = getelementptr inbounds i32, i32* %1, i64 196
  %515 = bitcast i32* %514 to <4 x i32>*
  store <4 x i32> %512, <4 x i32>* %515, align 16
  %516 = load <8 x i16>, <8 x i16>* %401, align 16
  %517 = getelementptr inbounds i32, i32* %1, i64 224
  %518 = shufflevector <8 x i16> %516, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %519 = shufflevector <8 x i16> %516, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %520 = bitcast <8 x i16> %518 to <4 x i32>
  %521 = ashr <4 x i32> %520, <i32 16, i32 16, i32 16, i32 16>
  %522 = bitcast <8 x i16> %519 to <4 x i32>
  %523 = ashr <4 x i32> %522, <i32 16, i32 16, i32 16, i32 16>
  %524 = bitcast i32* %517 to <4 x i32>*
  store <4 x i32> %521, <4 x i32>* %524, align 16
  %525 = getelementptr inbounds i32, i32* %1, i64 228
  %526 = bitcast i32* %525 to <4 x i32>*
  store <4 x i32> %523, <4 x i32>* %526, align 16
  %527 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 8
  %528 = bitcast <2 x i64>* %527 to <8 x i16>*
  %529 = load <8 x i16>, <8 x i16>* %528, align 16
  %530 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 9
  %531 = bitcast <2 x i64>* %530 to <8 x i16>*
  %532 = load <8 x i16>, <8 x i16>* %531, align 16
  %533 = shufflevector <8 x i16> %529, <8 x i16> %532, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %534 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 10
  %535 = bitcast <2 x i64>* %534 to <8 x i16>*
  %536 = load <8 x i16>, <8 x i16>* %535, align 16
  %537 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 11
  %538 = bitcast <2 x i64>* %537 to <8 x i16>*
  %539 = load <8 x i16>, <8 x i16>* %538, align 16
  %540 = shufflevector <8 x i16> %536, <8 x i16> %539, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %541 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 12
  %542 = bitcast <2 x i64>* %541 to <8 x i16>*
  %543 = load <8 x i16>, <8 x i16>* %542, align 16
  %544 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 13
  %545 = bitcast <2 x i64>* %544 to <8 x i16>*
  %546 = load <8 x i16>, <8 x i16>* %545, align 16
  %547 = shufflevector <8 x i16> %543, <8 x i16> %546, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %548 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 14
  %549 = bitcast <2 x i64>* %548 to <8 x i16>*
  %550 = load <8 x i16>, <8 x i16>* %549, align 16
  %551 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 15
  %552 = bitcast <2 x i64>* %551 to <8 x i16>*
  %553 = load <8 x i16>, <8 x i16>* %552, align 16
  %554 = shufflevector <8 x i16> %550, <8 x i16> %553, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %555 = shufflevector <8 x i16> %529, <8 x i16> %532, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %556 = shufflevector <8 x i16> %536, <8 x i16> %539, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %557 = shufflevector <8 x i16> %543, <8 x i16> %546, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %558 = shufflevector <8 x i16> %550, <8 x i16> %553, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %559 = bitcast <8 x i16> %533 to <4 x i32>
  %560 = bitcast <8 x i16> %540 to <4 x i32>
  %561 = shufflevector <4 x i32> %559, <4 x i32> %560, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %562 = bitcast <4 x i32> %561 to <2 x i64>
  %563 = bitcast <8 x i16> %547 to <4 x i32>
  %564 = bitcast <8 x i16> %554 to <4 x i32>
  %565 = shufflevector <4 x i32> %563, <4 x i32> %564, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %566 = bitcast <4 x i32> %565 to <2 x i64>
  %567 = bitcast <8 x i16> %555 to <4 x i32>
  %568 = bitcast <8 x i16> %556 to <4 x i32>
  %569 = shufflevector <4 x i32> %567, <4 x i32> %568, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %570 = bitcast <4 x i32> %569 to <2 x i64>
  %571 = bitcast <8 x i16> %557 to <4 x i32>
  %572 = bitcast <8 x i16> %558 to <4 x i32>
  %573 = shufflevector <4 x i32> %571, <4 x i32> %572, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %574 = bitcast <4 x i32> %573 to <2 x i64>
  %575 = shufflevector <4 x i32> %559, <4 x i32> %560, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %576 = bitcast <4 x i32> %575 to <2 x i64>
  %577 = shufflevector <4 x i32> %563, <4 x i32> %564, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %578 = bitcast <4 x i32> %577 to <2 x i64>
  %579 = shufflevector <4 x i32> %567, <4 x i32> %568, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %580 = bitcast <4 x i32> %579 to <2 x i64>
  %581 = shufflevector <4 x i32> %571, <4 x i32> %572, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %582 = bitcast <4 x i32> %581 to <2 x i64>
  %583 = shufflevector <2 x i64> %562, <2 x i64> %566, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %583, <2 x i64>* %527, align 16
  %584 = shufflevector <2 x i64> %562, <2 x i64> %566, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %584, <2 x i64>* %530, align 16
  %585 = shufflevector <2 x i64> %576, <2 x i64> %578, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %585, <2 x i64>* %534, align 16
  %586 = shufflevector <2 x i64> %576, <2 x i64> %578, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %586, <2 x i64>* %537, align 16
  %587 = shufflevector <2 x i64> %570, <2 x i64> %574, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %587, <2 x i64>* %541, align 16
  %588 = shufflevector <2 x i64> %570, <2 x i64> %574, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %588, <2 x i64>* %544, align 16
  %589 = shufflevector <2 x i64> %580, <2 x i64> %582, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %589, <2 x i64>* %548, align 16
  %590 = shufflevector <2 x i64> %580, <2 x i64> %582, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %590, <2 x i64>* %551, align 16
  %591 = getelementptr inbounds i32, i32* %1, i64 8
  %592 = bitcast <2 x i64> %583 to <8 x i16>
  %593 = shufflevector <8 x i16> %592, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %594 = shufflevector <8 x i16> %592, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %595 = bitcast <8 x i16> %593 to <4 x i32>
  %596 = ashr <4 x i32> %595, <i32 16, i32 16, i32 16, i32 16>
  %597 = bitcast <8 x i16> %594 to <4 x i32>
  %598 = ashr <4 x i32> %597, <i32 16, i32 16, i32 16, i32 16>
  %599 = bitcast i32* %591 to <4 x i32>*
  store <4 x i32> %596, <4 x i32>* %599, align 16
  %600 = getelementptr inbounds i32, i32* %1, i64 12
  %601 = bitcast i32* %600 to <4 x i32>*
  store <4 x i32> %598, <4 x i32>* %601, align 16
  %602 = bitcast <2 x i64> %584 to <8 x i16>
  %603 = getelementptr inbounds i32, i32* %1, i64 40
  %604 = shufflevector <8 x i16> %602, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %605 = shufflevector <8 x i16> %602, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %606 = bitcast <8 x i16> %604 to <4 x i32>
  %607 = ashr <4 x i32> %606, <i32 16, i32 16, i32 16, i32 16>
  %608 = bitcast <8 x i16> %605 to <4 x i32>
  %609 = ashr <4 x i32> %608, <i32 16, i32 16, i32 16, i32 16>
  %610 = bitcast i32* %603 to <4 x i32>*
  store <4 x i32> %607, <4 x i32>* %610, align 16
  %611 = getelementptr inbounds i32, i32* %1, i64 44
  %612 = bitcast i32* %611 to <4 x i32>*
  store <4 x i32> %609, <4 x i32>* %612, align 16
  %613 = bitcast <2 x i64> %585 to <8 x i16>
  %614 = getelementptr inbounds i32, i32* %1, i64 72
  %615 = shufflevector <8 x i16> %613, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %616 = shufflevector <8 x i16> %613, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %617 = bitcast <8 x i16> %615 to <4 x i32>
  %618 = ashr <4 x i32> %617, <i32 16, i32 16, i32 16, i32 16>
  %619 = bitcast <8 x i16> %616 to <4 x i32>
  %620 = ashr <4 x i32> %619, <i32 16, i32 16, i32 16, i32 16>
  %621 = bitcast i32* %614 to <4 x i32>*
  store <4 x i32> %618, <4 x i32>* %621, align 16
  %622 = getelementptr inbounds i32, i32* %1, i64 76
  %623 = bitcast i32* %622 to <4 x i32>*
  store <4 x i32> %620, <4 x i32>* %623, align 16
  %624 = bitcast <2 x i64> %586 to <8 x i16>
  %625 = getelementptr inbounds i32, i32* %1, i64 104
  %626 = shufflevector <8 x i16> %624, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %627 = shufflevector <8 x i16> %624, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %628 = bitcast <8 x i16> %626 to <4 x i32>
  %629 = ashr <4 x i32> %628, <i32 16, i32 16, i32 16, i32 16>
  %630 = bitcast <8 x i16> %627 to <4 x i32>
  %631 = ashr <4 x i32> %630, <i32 16, i32 16, i32 16, i32 16>
  %632 = bitcast i32* %625 to <4 x i32>*
  store <4 x i32> %629, <4 x i32>* %632, align 16
  %633 = getelementptr inbounds i32, i32* %1, i64 108
  %634 = bitcast i32* %633 to <4 x i32>*
  store <4 x i32> %631, <4 x i32>* %634, align 16
  %635 = bitcast <2 x i64> %587 to <8 x i16>
  %636 = getelementptr inbounds i32, i32* %1, i64 136
  %637 = shufflevector <8 x i16> %635, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %638 = shufflevector <8 x i16> %635, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %639 = bitcast <8 x i16> %637 to <4 x i32>
  %640 = ashr <4 x i32> %639, <i32 16, i32 16, i32 16, i32 16>
  %641 = bitcast <8 x i16> %638 to <4 x i32>
  %642 = ashr <4 x i32> %641, <i32 16, i32 16, i32 16, i32 16>
  %643 = bitcast i32* %636 to <4 x i32>*
  store <4 x i32> %640, <4 x i32>* %643, align 16
  %644 = getelementptr inbounds i32, i32* %1, i64 140
  %645 = bitcast i32* %644 to <4 x i32>*
  store <4 x i32> %642, <4 x i32>* %645, align 16
  %646 = bitcast <2 x i64> %588 to <8 x i16>
  %647 = getelementptr inbounds i32, i32* %1, i64 168
  %648 = shufflevector <8 x i16> %646, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %649 = shufflevector <8 x i16> %646, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %650 = bitcast <8 x i16> %648 to <4 x i32>
  %651 = ashr <4 x i32> %650, <i32 16, i32 16, i32 16, i32 16>
  %652 = bitcast <8 x i16> %649 to <4 x i32>
  %653 = ashr <4 x i32> %652, <i32 16, i32 16, i32 16, i32 16>
  %654 = bitcast i32* %647 to <4 x i32>*
  store <4 x i32> %651, <4 x i32>* %654, align 16
  %655 = getelementptr inbounds i32, i32* %1, i64 172
  %656 = bitcast i32* %655 to <4 x i32>*
  store <4 x i32> %653, <4 x i32>* %656, align 16
  %657 = bitcast <2 x i64> %589 to <8 x i16>
  %658 = getelementptr inbounds i32, i32* %1, i64 200
  %659 = shufflevector <8 x i16> %657, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %660 = shufflevector <8 x i16> %657, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %661 = bitcast <8 x i16> %659 to <4 x i32>
  %662 = ashr <4 x i32> %661, <i32 16, i32 16, i32 16, i32 16>
  %663 = bitcast <8 x i16> %660 to <4 x i32>
  %664 = ashr <4 x i32> %663, <i32 16, i32 16, i32 16, i32 16>
  %665 = bitcast i32* %658 to <4 x i32>*
  store <4 x i32> %662, <4 x i32>* %665, align 16
  %666 = getelementptr inbounds i32, i32* %1, i64 204
  %667 = bitcast i32* %666 to <4 x i32>*
  store <4 x i32> %664, <4 x i32>* %667, align 16
  %668 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 15
  %669 = bitcast <2 x i64>* %668 to <8 x i16>*
  %670 = load <8 x i16>, <8 x i16>* %669, align 16
  %671 = getelementptr inbounds i32, i32* %1, i64 232
  %672 = shufflevector <8 x i16> %670, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %673 = shufflevector <8 x i16> %670, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %674 = bitcast <8 x i16> %672 to <4 x i32>
  %675 = ashr <4 x i32> %674, <i32 16, i32 16, i32 16, i32 16>
  %676 = bitcast <8 x i16> %673 to <4 x i32>
  %677 = ashr <4 x i32> %676, <i32 16, i32 16, i32 16, i32 16>
  %678 = bitcast i32* %671 to <4 x i32>*
  store <4 x i32> %675, <4 x i32>* %678, align 16
  %679 = getelementptr inbounds i32, i32* %1, i64 236
  %680 = bitcast i32* %679 to <4 x i32>*
  store <4 x i32> %677, <4 x i32>* %680, align 16
  %681 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 16
  %682 = bitcast <2 x i64>* %681 to <8 x i16>*
  %683 = load <8 x i16>, <8 x i16>* %682, align 16
  %684 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 17
  %685 = bitcast <2 x i64>* %684 to <8 x i16>*
  %686 = load <8 x i16>, <8 x i16>* %685, align 16
  %687 = shufflevector <8 x i16> %683, <8 x i16> %686, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %688 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 18
  %689 = bitcast <2 x i64>* %688 to <8 x i16>*
  %690 = load <8 x i16>, <8 x i16>* %689, align 16
  %691 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 19
  %692 = bitcast <2 x i64>* %691 to <8 x i16>*
  %693 = load <8 x i16>, <8 x i16>* %692, align 16
  %694 = shufflevector <8 x i16> %690, <8 x i16> %693, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %695 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 20
  %696 = bitcast <2 x i64>* %695 to <8 x i16>*
  %697 = load <8 x i16>, <8 x i16>* %696, align 16
  %698 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 21
  %699 = bitcast <2 x i64>* %698 to <8 x i16>*
  %700 = load <8 x i16>, <8 x i16>* %699, align 16
  %701 = shufflevector <8 x i16> %697, <8 x i16> %700, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %702 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 22
  %703 = bitcast <2 x i64>* %702 to <8 x i16>*
  %704 = load <8 x i16>, <8 x i16>* %703, align 16
  %705 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 23
  %706 = bitcast <2 x i64>* %705 to <8 x i16>*
  %707 = load <8 x i16>, <8 x i16>* %706, align 16
  %708 = shufflevector <8 x i16> %704, <8 x i16> %707, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %709 = shufflevector <8 x i16> %683, <8 x i16> %686, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %710 = shufflevector <8 x i16> %690, <8 x i16> %693, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %711 = shufflevector <8 x i16> %697, <8 x i16> %700, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %712 = shufflevector <8 x i16> %704, <8 x i16> %707, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %713 = bitcast <8 x i16> %687 to <4 x i32>
  %714 = bitcast <8 x i16> %694 to <4 x i32>
  %715 = shufflevector <4 x i32> %713, <4 x i32> %714, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %716 = bitcast <4 x i32> %715 to <2 x i64>
  %717 = bitcast <8 x i16> %701 to <4 x i32>
  %718 = bitcast <8 x i16> %708 to <4 x i32>
  %719 = shufflevector <4 x i32> %717, <4 x i32> %718, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %720 = bitcast <4 x i32> %719 to <2 x i64>
  %721 = bitcast <8 x i16> %709 to <4 x i32>
  %722 = bitcast <8 x i16> %710 to <4 x i32>
  %723 = shufflevector <4 x i32> %721, <4 x i32> %722, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %724 = bitcast <4 x i32> %723 to <2 x i64>
  %725 = bitcast <8 x i16> %711 to <4 x i32>
  %726 = bitcast <8 x i16> %712 to <4 x i32>
  %727 = shufflevector <4 x i32> %725, <4 x i32> %726, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %728 = bitcast <4 x i32> %727 to <2 x i64>
  %729 = shufflevector <4 x i32> %713, <4 x i32> %714, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %730 = bitcast <4 x i32> %729 to <2 x i64>
  %731 = shufflevector <4 x i32> %717, <4 x i32> %718, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %732 = bitcast <4 x i32> %731 to <2 x i64>
  %733 = shufflevector <4 x i32> %721, <4 x i32> %722, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %734 = bitcast <4 x i32> %733 to <2 x i64>
  %735 = shufflevector <4 x i32> %725, <4 x i32> %726, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %736 = bitcast <4 x i32> %735 to <2 x i64>
  %737 = shufflevector <2 x i64> %716, <2 x i64> %720, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %737, <2 x i64>* %681, align 16
  %738 = shufflevector <2 x i64> %716, <2 x i64> %720, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %738, <2 x i64>* %684, align 16
  %739 = shufflevector <2 x i64> %730, <2 x i64> %732, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %739, <2 x i64>* %688, align 16
  %740 = shufflevector <2 x i64> %730, <2 x i64> %732, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %740, <2 x i64>* %691, align 16
  %741 = shufflevector <2 x i64> %724, <2 x i64> %728, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %741, <2 x i64>* %695, align 16
  %742 = shufflevector <2 x i64> %724, <2 x i64> %728, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %742, <2 x i64>* %698, align 16
  %743 = shufflevector <2 x i64> %734, <2 x i64> %736, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %743, <2 x i64>* %702, align 16
  %744 = shufflevector <2 x i64> %734, <2 x i64> %736, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %744, <2 x i64>* %705, align 16
  %745 = getelementptr inbounds i32, i32* %1, i64 16
  %746 = bitcast <2 x i64> %737 to <8 x i16>
  %747 = shufflevector <8 x i16> %746, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %748 = shufflevector <8 x i16> %746, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %749 = bitcast <8 x i16> %747 to <4 x i32>
  %750 = ashr <4 x i32> %749, <i32 16, i32 16, i32 16, i32 16>
  %751 = bitcast <8 x i16> %748 to <4 x i32>
  %752 = ashr <4 x i32> %751, <i32 16, i32 16, i32 16, i32 16>
  %753 = bitcast i32* %745 to <4 x i32>*
  store <4 x i32> %750, <4 x i32>* %753, align 16
  %754 = getelementptr inbounds i32, i32* %1, i64 20
  %755 = bitcast i32* %754 to <4 x i32>*
  store <4 x i32> %752, <4 x i32>* %755, align 16
  %756 = bitcast <2 x i64> %738 to <8 x i16>
  %757 = getelementptr inbounds i32, i32* %1, i64 48
  %758 = shufflevector <8 x i16> %756, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %759 = shufflevector <8 x i16> %756, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %760 = bitcast <8 x i16> %758 to <4 x i32>
  %761 = ashr <4 x i32> %760, <i32 16, i32 16, i32 16, i32 16>
  %762 = bitcast <8 x i16> %759 to <4 x i32>
  %763 = ashr <4 x i32> %762, <i32 16, i32 16, i32 16, i32 16>
  %764 = bitcast i32* %757 to <4 x i32>*
  store <4 x i32> %761, <4 x i32>* %764, align 16
  %765 = getelementptr inbounds i32, i32* %1, i64 52
  %766 = bitcast i32* %765 to <4 x i32>*
  store <4 x i32> %763, <4 x i32>* %766, align 16
  %767 = bitcast <2 x i64> %739 to <8 x i16>
  %768 = getelementptr inbounds i32, i32* %1, i64 80
  %769 = shufflevector <8 x i16> %767, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %770 = shufflevector <8 x i16> %767, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %771 = bitcast <8 x i16> %769 to <4 x i32>
  %772 = ashr <4 x i32> %771, <i32 16, i32 16, i32 16, i32 16>
  %773 = bitcast <8 x i16> %770 to <4 x i32>
  %774 = ashr <4 x i32> %773, <i32 16, i32 16, i32 16, i32 16>
  %775 = bitcast i32* %768 to <4 x i32>*
  store <4 x i32> %772, <4 x i32>* %775, align 16
  %776 = getelementptr inbounds i32, i32* %1, i64 84
  %777 = bitcast i32* %776 to <4 x i32>*
  store <4 x i32> %774, <4 x i32>* %777, align 16
  %778 = bitcast <2 x i64> %740 to <8 x i16>
  %779 = getelementptr inbounds i32, i32* %1, i64 112
  %780 = shufflevector <8 x i16> %778, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %781 = shufflevector <8 x i16> %778, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %782 = bitcast <8 x i16> %780 to <4 x i32>
  %783 = ashr <4 x i32> %782, <i32 16, i32 16, i32 16, i32 16>
  %784 = bitcast <8 x i16> %781 to <4 x i32>
  %785 = ashr <4 x i32> %784, <i32 16, i32 16, i32 16, i32 16>
  %786 = bitcast i32* %779 to <4 x i32>*
  store <4 x i32> %783, <4 x i32>* %786, align 16
  %787 = getelementptr inbounds i32, i32* %1, i64 116
  %788 = bitcast i32* %787 to <4 x i32>*
  store <4 x i32> %785, <4 x i32>* %788, align 16
  %789 = bitcast <2 x i64> %741 to <8 x i16>
  %790 = getelementptr inbounds i32, i32* %1, i64 144
  %791 = shufflevector <8 x i16> %789, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %792 = shufflevector <8 x i16> %789, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %793 = bitcast <8 x i16> %791 to <4 x i32>
  %794 = ashr <4 x i32> %793, <i32 16, i32 16, i32 16, i32 16>
  %795 = bitcast <8 x i16> %792 to <4 x i32>
  %796 = ashr <4 x i32> %795, <i32 16, i32 16, i32 16, i32 16>
  %797 = bitcast i32* %790 to <4 x i32>*
  store <4 x i32> %794, <4 x i32>* %797, align 16
  %798 = getelementptr inbounds i32, i32* %1, i64 148
  %799 = bitcast i32* %798 to <4 x i32>*
  store <4 x i32> %796, <4 x i32>* %799, align 16
  %800 = bitcast <2 x i64> %742 to <8 x i16>
  %801 = getelementptr inbounds i32, i32* %1, i64 176
  %802 = shufflevector <8 x i16> %800, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %803 = shufflevector <8 x i16> %800, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %804 = bitcast <8 x i16> %802 to <4 x i32>
  %805 = ashr <4 x i32> %804, <i32 16, i32 16, i32 16, i32 16>
  %806 = bitcast <8 x i16> %803 to <4 x i32>
  %807 = ashr <4 x i32> %806, <i32 16, i32 16, i32 16, i32 16>
  %808 = bitcast i32* %801 to <4 x i32>*
  store <4 x i32> %805, <4 x i32>* %808, align 16
  %809 = getelementptr inbounds i32, i32* %1, i64 180
  %810 = bitcast i32* %809 to <4 x i32>*
  store <4 x i32> %807, <4 x i32>* %810, align 16
  %811 = bitcast <2 x i64> %743 to <8 x i16>
  %812 = getelementptr inbounds i32, i32* %1, i64 208
  %813 = shufflevector <8 x i16> %811, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %814 = shufflevector <8 x i16> %811, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %815 = bitcast <8 x i16> %813 to <4 x i32>
  %816 = ashr <4 x i32> %815, <i32 16, i32 16, i32 16, i32 16>
  %817 = bitcast <8 x i16> %814 to <4 x i32>
  %818 = ashr <4 x i32> %817, <i32 16, i32 16, i32 16, i32 16>
  %819 = bitcast i32* %812 to <4 x i32>*
  store <4 x i32> %816, <4 x i32>* %819, align 16
  %820 = getelementptr inbounds i32, i32* %1, i64 212
  %821 = bitcast i32* %820 to <4 x i32>*
  store <4 x i32> %818, <4 x i32>* %821, align 16
  %822 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 23
  %823 = bitcast <2 x i64>* %822 to <8 x i16>*
  %824 = load <8 x i16>, <8 x i16>* %823, align 16
  %825 = getelementptr inbounds i32, i32* %1, i64 240
  %826 = shufflevector <8 x i16> %824, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %827 = shufflevector <8 x i16> %824, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %828 = bitcast <8 x i16> %826 to <4 x i32>
  %829 = ashr <4 x i32> %828, <i32 16, i32 16, i32 16, i32 16>
  %830 = bitcast <8 x i16> %827 to <4 x i32>
  %831 = ashr <4 x i32> %830, <i32 16, i32 16, i32 16, i32 16>
  %832 = bitcast i32* %825 to <4 x i32>*
  store <4 x i32> %829, <4 x i32>* %832, align 16
  %833 = getelementptr inbounds i32, i32* %1, i64 244
  %834 = bitcast i32* %833 to <4 x i32>*
  store <4 x i32> %831, <4 x i32>* %834, align 16
  %835 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 24
  %836 = bitcast <2 x i64>* %835 to <8 x i16>*
  %837 = load <8 x i16>, <8 x i16>* %836, align 16
  %838 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 25
  %839 = bitcast <2 x i64>* %838 to <8 x i16>*
  %840 = load <8 x i16>, <8 x i16>* %839, align 16
  %841 = shufflevector <8 x i16> %837, <8 x i16> %840, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %842 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 26
  %843 = bitcast <2 x i64>* %842 to <8 x i16>*
  %844 = load <8 x i16>, <8 x i16>* %843, align 16
  %845 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 27
  %846 = bitcast <2 x i64>* %845 to <8 x i16>*
  %847 = load <8 x i16>, <8 x i16>* %846, align 16
  %848 = shufflevector <8 x i16> %844, <8 x i16> %847, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %849 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 28
  %850 = bitcast <2 x i64>* %849 to <8 x i16>*
  %851 = load <8 x i16>, <8 x i16>* %850, align 16
  %852 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 29
  %853 = bitcast <2 x i64>* %852 to <8 x i16>*
  %854 = load <8 x i16>, <8 x i16>* %853, align 16
  %855 = shufflevector <8 x i16> %851, <8 x i16> %854, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %856 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 30
  %857 = bitcast <2 x i64>* %856 to <8 x i16>*
  %858 = load <8 x i16>, <8 x i16>* %857, align 16
  %859 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 31
  %860 = bitcast <2 x i64>* %859 to <8 x i16>*
  %861 = load <8 x i16>, <8 x i16>* %860, align 16
  %862 = shufflevector <8 x i16> %858, <8 x i16> %861, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %863 = shufflevector <8 x i16> %837, <8 x i16> %840, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %864 = shufflevector <8 x i16> %844, <8 x i16> %847, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %865 = shufflevector <8 x i16> %851, <8 x i16> %854, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %866 = shufflevector <8 x i16> %858, <8 x i16> %861, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %867 = bitcast <8 x i16> %841 to <4 x i32>
  %868 = bitcast <8 x i16> %848 to <4 x i32>
  %869 = shufflevector <4 x i32> %867, <4 x i32> %868, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %870 = bitcast <4 x i32> %869 to <2 x i64>
  %871 = bitcast <8 x i16> %855 to <4 x i32>
  %872 = bitcast <8 x i16> %862 to <4 x i32>
  %873 = shufflevector <4 x i32> %871, <4 x i32> %872, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %874 = bitcast <4 x i32> %873 to <2 x i64>
  %875 = bitcast <8 x i16> %863 to <4 x i32>
  %876 = bitcast <8 x i16> %864 to <4 x i32>
  %877 = shufflevector <4 x i32> %875, <4 x i32> %876, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %878 = bitcast <4 x i32> %877 to <2 x i64>
  %879 = bitcast <8 x i16> %865 to <4 x i32>
  %880 = bitcast <8 x i16> %866 to <4 x i32>
  %881 = shufflevector <4 x i32> %879, <4 x i32> %880, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %882 = bitcast <4 x i32> %881 to <2 x i64>
  %883 = shufflevector <4 x i32> %867, <4 x i32> %868, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %884 = bitcast <4 x i32> %883 to <2 x i64>
  %885 = shufflevector <4 x i32> %871, <4 x i32> %872, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %886 = bitcast <4 x i32> %885 to <2 x i64>
  %887 = shufflevector <4 x i32> %875, <4 x i32> %876, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %888 = bitcast <4 x i32> %887 to <2 x i64>
  %889 = shufflevector <4 x i32> %879, <4 x i32> %880, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %890 = bitcast <4 x i32> %889 to <2 x i64>
  %891 = shufflevector <2 x i64> %870, <2 x i64> %874, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %891, <2 x i64>* %835, align 16
  %892 = shufflevector <2 x i64> %870, <2 x i64> %874, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %892, <2 x i64>* %838, align 16
  %893 = shufflevector <2 x i64> %884, <2 x i64> %886, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %893, <2 x i64>* %842, align 16
  %894 = shufflevector <2 x i64> %884, <2 x i64> %886, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %894, <2 x i64>* %845, align 16
  %895 = shufflevector <2 x i64> %878, <2 x i64> %882, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %895, <2 x i64>* %849, align 16
  %896 = shufflevector <2 x i64> %878, <2 x i64> %882, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %896, <2 x i64>* %852, align 16
  %897 = shufflevector <2 x i64> %888, <2 x i64> %890, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %897, <2 x i64>* %856, align 16
  %898 = shufflevector <2 x i64> %888, <2 x i64> %890, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %898, <2 x i64>* %859, align 16
  %899 = getelementptr inbounds i32, i32* %1, i64 24
  %900 = bitcast <2 x i64> %891 to <8 x i16>
  %901 = shufflevector <8 x i16> %900, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %902 = shufflevector <8 x i16> %900, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %903 = bitcast <8 x i16> %901 to <4 x i32>
  %904 = ashr <4 x i32> %903, <i32 16, i32 16, i32 16, i32 16>
  %905 = bitcast <8 x i16> %902 to <4 x i32>
  %906 = ashr <4 x i32> %905, <i32 16, i32 16, i32 16, i32 16>
  %907 = bitcast i32* %899 to <4 x i32>*
  store <4 x i32> %904, <4 x i32>* %907, align 16
  %908 = getelementptr inbounds i32, i32* %1, i64 28
  %909 = bitcast i32* %908 to <4 x i32>*
  store <4 x i32> %906, <4 x i32>* %909, align 16
  %910 = bitcast <2 x i64> %892 to <8 x i16>
  %911 = getelementptr inbounds i32, i32* %1, i64 56
  %912 = shufflevector <8 x i16> %910, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %913 = shufflevector <8 x i16> %910, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %914 = bitcast <8 x i16> %912 to <4 x i32>
  %915 = ashr <4 x i32> %914, <i32 16, i32 16, i32 16, i32 16>
  %916 = bitcast <8 x i16> %913 to <4 x i32>
  %917 = ashr <4 x i32> %916, <i32 16, i32 16, i32 16, i32 16>
  %918 = bitcast i32* %911 to <4 x i32>*
  store <4 x i32> %915, <4 x i32>* %918, align 16
  %919 = getelementptr inbounds i32, i32* %1, i64 60
  %920 = bitcast i32* %919 to <4 x i32>*
  store <4 x i32> %917, <4 x i32>* %920, align 16
  %921 = bitcast <2 x i64> %893 to <8 x i16>
  %922 = getelementptr inbounds i32, i32* %1, i64 88
  %923 = shufflevector <8 x i16> %921, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %924 = shufflevector <8 x i16> %921, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %925 = bitcast <8 x i16> %923 to <4 x i32>
  %926 = ashr <4 x i32> %925, <i32 16, i32 16, i32 16, i32 16>
  %927 = bitcast <8 x i16> %924 to <4 x i32>
  %928 = ashr <4 x i32> %927, <i32 16, i32 16, i32 16, i32 16>
  %929 = bitcast i32* %922 to <4 x i32>*
  store <4 x i32> %926, <4 x i32>* %929, align 16
  %930 = getelementptr inbounds i32, i32* %1, i64 92
  %931 = bitcast i32* %930 to <4 x i32>*
  store <4 x i32> %928, <4 x i32>* %931, align 16
  %932 = bitcast <2 x i64> %894 to <8 x i16>
  %933 = getelementptr inbounds i32, i32* %1, i64 120
  %934 = shufflevector <8 x i16> %932, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %935 = shufflevector <8 x i16> %932, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %936 = bitcast <8 x i16> %934 to <4 x i32>
  %937 = ashr <4 x i32> %936, <i32 16, i32 16, i32 16, i32 16>
  %938 = bitcast <8 x i16> %935 to <4 x i32>
  %939 = ashr <4 x i32> %938, <i32 16, i32 16, i32 16, i32 16>
  %940 = bitcast i32* %933 to <4 x i32>*
  store <4 x i32> %937, <4 x i32>* %940, align 16
  %941 = getelementptr inbounds i32, i32* %1, i64 124
  %942 = bitcast i32* %941 to <4 x i32>*
  store <4 x i32> %939, <4 x i32>* %942, align 16
  %943 = bitcast <2 x i64> %895 to <8 x i16>
  %944 = getelementptr inbounds i32, i32* %1, i64 152
  %945 = shufflevector <8 x i16> %943, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %946 = shufflevector <8 x i16> %943, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %947 = bitcast <8 x i16> %945 to <4 x i32>
  %948 = ashr <4 x i32> %947, <i32 16, i32 16, i32 16, i32 16>
  %949 = bitcast <8 x i16> %946 to <4 x i32>
  %950 = ashr <4 x i32> %949, <i32 16, i32 16, i32 16, i32 16>
  %951 = bitcast i32* %944 to <4 x i32>*
  store <4 x i32> %948, <4 x i32>* %951, align 16
  %952 = getelementptr inbounds i32, i32* %1, i64 156
  %953 = bitcast i32* %952 to <4 x i32>*
  store <4 x i32> %950, <4 x i32>* %953, align 16
  %954 = bitcast <2 x i64> %896 to <8 x i16>
  %955 = getelementptr inbounds i32, i32* %1, i64 184
  %956 = shufflevector <8 x i16> %954, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %957 = shufflevector <8 x i16> %954, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %958 = bitcast <8 x i16> %956 to <4 x i32>
  %959 = ashr <4 x i32> %958, <i32 16, i32 16, i32 16, i32 16>
  %960 = bitcast <8 x i16> %957 to <4 x i32>
  %961 = ashr <4 x i32> %960, <i32 16, i32 16, i32 16, i32 16>
  %962 = bitcast i32* %955 to <4 x i32>*
  store <4 x i32> %959, <4 x i32>* %962, align 16
  %963 = getelementptr inbounds i32, i32* %1, i64 188
  %964 = bitcast i32* %963 to <4 x i32>*
  store <4 x i32> %961, <4 x i32>* %964, align 16
  %965 = bitcast <2 x i64> %897 to <8 x i16>
  %966 = getelementptr inbounds i32, i32* %1, i64 216
  %967 = shufflevector <8 x i16> %965, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %968 = shufflevector <8 x i16> %965, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %969 = bitcast <8 x i16> %967 to <4 x i32>
  %970 = ashr <4 x i32> %969, <i32 16, i32 16, i32 16, i32 16>
  %971 = bitcast <8 x i16> %968 to <4 x i32>
  %972 = ashr <4 x i32> %971, <i32 16, i32 16, i32 16, i32 16>
  %973 = bitcast i32* %966 to <4 x i32>*
  store <4 x i32> %970, <4 x i32>* %973, align 16
  %974 = getelementptr inbounds i32, i32* %1, i64 220
  %975 = bitcast i32* %974 to <4 x i32>*
  store <4 x i32> %972, <4 x i32>* %975, align 16
  %976 = getelementptr inbounds <2 x i64>, <2 x i64>* %312, i64 31
  %977 = bitcast <2 x i64>* %976 to <8 x i16>*
  %978 = load <8 x i16>, <8 x i16>* %977, align 16
  %979 = getelementptr inbounds i32, i32* %1, i64 248
  %980 = shufflevector <8 x i16> %978, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %981 = shufflevector <8 x i16> %978, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %982 = bitcast <8 x i16> %980 to <4 x i32>
  %983 = ashr <4 x i32> %982, <i32 16, i32 16, i32 16, i32 16>
  %984 = bitcast <8 x i16> %981 to <4 x i32>
  %985 = ashr <4 x i32> %984, <i32 16, i32 16, i32 16, i32 16>
  %986 = bitcast i32* %979 to <4 x i32>*
  store <4 x i32> %983, <4 x i32>* %986, align 16
  %987 = getelementptr inbounds i32, i32* %1, i64 252
  %988 = bitcast i32* %987 to <4 x i32>*
  store <4 x i32> %985, <4 x i32>* %988, align 16
  br label %989

989:                                              ; preds = %376, %375
  call void @llvm.lifetime.end.p0i8(i64 512, i8* nonnull %9) #8
  call void @llvm.lifetime.end.p0i8(i64 512, i8* nonnull %8) #8
  ret void
}

declare void @av1_fwd_txfm2d_32x16_c(i16*, i32*, i32, i8 zeroext, i32) local_unnamed_addr #3

; Function Attrs: nounwind ssp uwtable
define hidden void @av1_lowbd_fwd_txfm2d_32x16_sse2(i16*, i32*, i32, i8 zeroext, i32) #2 {
  %6 = alloca [32 x <2 x i64>], align 16
  %7 = alloca [64 x <2 x i64>], align 16
  %8 = bitcast [32 x <2 x i64>]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 512, i8* nonnull %8) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %8, i8 -86, i64 512, i1 false)
  %9 = bitcast [64 x <2 x i64>]* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1024, i8* nonnull %9) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 1024, i1 false)
  %10 = load i8*, i8** getelementptr inbounds ([19 x i8*], [19 x i8*]* @av1_fwd_txfm_shift_ls, i64 0, i64 10), align 16
  %11 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_fwd_cos_bit_col, i64 0, i64 3, i64 2), align 1
  %12 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_fwd_cos_bit_row, i64 0, i64 3, i64 2), align 1
  %13 = zext i8 %3 to i64
  %14 = getelementptr inbounds [16 x void (<2 x i64>*, <2 x i64>*, i8)*], [16 x void (<2 x i64>*, <2 x i64>*, i8)*]* @col_txfm8x16_arr, i64 0, i64 %13
  %15 = load void (<2 x i64>*, <2 x i64>*, i8)*, void (<2 x i64>*, <2 x i64>*, i8)** %14, align 8
  %16 = getelementptr inbounds [16 x void (<2 x i64>*, <2 x i64>*, i8)*], [16 x void (<2 x i64>*, <2 x i64>*, i8)*]* @row_txfm8x32_arr, i64 0, i64 %13
  %17 = load void (<2 x i64>*, <2 x i64>*, i8)*, void (<2 x i64>*, <2 x i64>*, i8)** %16, align 8
  %18 = lshr i64 3585, %13
  %19 = and i64 %18, 1
  %20 = icmp eq i64 %19, 0
  br i1 %20, label %1222, label %21

21:                                               ; preds = %5
  switch i8 %3, label %25 [
    i8 6, label %24
    i8 15, label %23
    i8 7, label %23
    i8 5, label %23
    i8 14, label %22
    i8 8, label %22
    i8 4, label %22
  ]

22:                                               ; preds = %21, %21, %21
  br label %25

23:                                               ; preds = %21, %21, %21
  br label %25

24:                                               ; preds = %21
  br label %25

25:                                               ; preds = %21, %22, %23, %24
  %26 = phi i1 [ false, %24 ], [ true, %23 ], [ false, %22 ], [ true, %21 ]
  %27 = phi i32 [ 1, %24 ], [ 1, %23 ], [ 0, %22 ], [ 0, %21 ]
  %28 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 0
  %29 = sext i32 %2 to i64
  %30 = getelementptr inbounds i8, i8* %10, i64 1
  %31 = bitcast [32 x <2 x i64>]* %6 to <8 x i16>*
  %32 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 1
  %33 = bitcast <2 x i64>* %32 to <8 x i16>*
  %34 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 2
  %35 = bitcast <2 x i64>* %34 to <8 x i16>*
  %36 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 3
  %37 = bitcast <2 x i64>* %36 to <8 x i16>*
  %38 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 4
  %39 = bitcast <2 x i64>* %38 to <8 x i16>*
  %40 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 5
  %41 = bitcast <2 x i64>* %40 to <8 x i16>*
  %42 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 6
  %43 = bitcast <2 x i64>* %42 to <8 x i16>*
  %44 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 7
  %45 = bitcast <2 x i64>* %44 to <8 x i16>*
  %46 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 8
  %47 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 32
  %48 = bitcast <2 x i64>* %46 to <8 x i16>*
  %49 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 9
  %50 = bitcast <2 x i64>* %49 to <8 x i16>*
  %51 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 10
  %52 = bitcast <2 x i64>* %51 to <8 x i16>*
  %53 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 11
  %54 = bitcast <2 x i64>* %53 to <8 x i16>*
  %55 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 12
  %56 = bitcast <2 x i64>* %55 to <8 x i16>*
  %57 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 13
  %58 = bitcast <2 x i64>* %57 to <8 x i16>*
  %59 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 14
  %60 = bitcast <2 x i64>* %59 to <8 x i16>*
  %61 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 15
  %62 = bitcast <2 x i64>* %61 to <8 x i16>*
  %63 = shl nsw i64 %29, 1
  %64 = mul nsw i64 %29, 3
  %65 = shl nsw i64 %29, 2
  %66 = mul nsw i64 %29, 5
  %67 = mul nsw i64 %29, 6
  %68 = mul nsw i64 %29, 7
  %69 = shl nsw i64 %29, 3
  %70 = mul nsw i64 %29, 9
  %71 = mul nsw i64 %29, 10
  %72 = mul nsw i64 %29, 11
  %73 = mul nsw i64 %29, 12
  %74 = mul nsw i64 %29, 13
  %75 = mul nsw i64 %29, 14
  %76 = mul nsw i64 %29, 15
  %77 = shl nsw i64 %29, 1
  %78 = mul nsw i64 %29, 3
  %79 = shl nsw i64 %29, 2
  %80 = mul nsw i64 %29, 5
  %81 = mul nsw i64 %29, 6
  %82 = mul nsw i64 %29, 7
  %83 = shl nsw i64 %29, 3
  %84 = mul nsw i64 %29, 9
  %85 = mul nsw i64 %29, 10
  %86 = mul nsw i64 %29, 11
  %87 = mul nsw i64 %29, 12
  %88 = mul nsw i64 %29, 13
  %89 = mul nsw i64 %29, 14
  %90 = mul nsw i64 %29, 15
  %91 = bitcast [32 x <2 x i64>]* %6 to <8 x i16>*
  %92 = bitcast [32 x <2 x i64>]* %6 to <8 x i16>*
  %93 = bitcast [32 x <2 x i64>]* %6 to <8 x i16>*
  %94 = bitcast [32 x <2 x i64>]* %6 to <8 x i16>*
  br label %98

95:                                               ; preds = %405
  %96 = icmp eq i32 %27, 0
  %97 = getelementptr inbounds i8, i8* %10, i64 2
  br label %520

98:                                               ; preds = %405, %25
  %99 = phi i64 [ 0, %25 ], [ %518, %405 ]
  %100 = shl nsw i64 %99, 3
  %101 = getelementptr inbounds i16, i16* %0, i64 %100
  %102 = bitcast i16* %101 to <2 x i64>*
  %103 = load <2 x i64>, <2 x i64>* %102, align 16
  br i1 %26, label %150, label %104

104:                                              ; preds = %98
  store <2 x i64> %103, <2 x i64>* %61, align 16
  %105 = getelementptr inbounds i16, i16* %101, i64 %29
  %106 = bitcast i16* %105 to <2 x i64>*
  %107 = load <2 x i64>, <2 x i64>* %106, align 16
  store <2 x i64> %107, <2 x i64>* %59, align 16
  %108 = getelementptr inbounds i16, i16* %101, i64 %63
  %109 = bitcast i16* %108 to <2 x i64>*
  %110 = load <2 x i64>, <2 x i64>* %109, align 16
  store <2 x i64> %110, <2 x i64>* %57, align 16
  %111 = getelementptr inbounds i16, i16* %101, i64 %64
  %112 = bitcast i16* %111 to <2 x i64>*
  %113 = load <2 x i64>, <2 x i64>* %112, align 16
  store <2 x i64> %113, <2 x i64>* %55, align 16
  %114 = getelementptr inbounds i16, i16* %101, i64 %65
  %115 = bitcast i16* %114 to <2 x i64>*
  %116 = load <2 x i64>, <2 x i64>* %115, align 16
  store <2 x i64> %116, <2 x i64>* %53, align 16
  %117 = getelementptr inbounds i16, i16* %101, i64 %66
  %118 = bitcast i16* %117 to <2 x i64>*
  %119 = load <2 x i64>, <2 x i64>* %118, align 16
  store <2 x i64> %119, <2 x i64>* %51, align 16
  %120 = getelementptr inbounds i16, i16* %101, i64 %67
  %121 = bitcast i16* %120 to <2 x i64>*
  %122 = load <2 x i64>, <2 x i64>* %121, align 16
  store <2 x i64> %122, <2 x i64>* %49, align 16
  %123 = getelementptr inbounds i16, i16* %101, i64 %68
  %124 = bitcast i16* %123 to <2 x i64>*
  %125 = load <2 x i64>, <2 x i64>* %124, align 16
  store <2 x i64> %125, <2 x i64>* %46, align 16
  %126 = getelementptr inbounds i16, i16* %101, i64 %69
  %127 = bitcast i16* %126 to <2 x i64>*
  %128 = load <2 x i64>, <2 x i64>* %127, align 16
  store <2 x i64> %128, <2 x i64>* %44, align 16
  %129 = getelementptr inbounds i16, i16* %101, i64 %70
  %130 = bitcast i16* %129 to <2 x i64>*
  %131 = load <2 x i64>, <2 x i64>* %130, align 16
  store <2 x i64> %131, <2 x i64>* %42, align 16
  %132 = getelementptr inbounds i16, i16* %101, i64 %71
  %133 = bitcast i16* %132 to <2 x i64>*
  %134 = load <2 x i64>, <2 x i64>* %133, align 16
  store <2 x i64> %134, <2 x i64>* %40, align 16
  %135 = getelementptr inbounds i16, i16* %101, i64 %72
  %136 = bitcast i16* %135 to <2 x i64>*
  %137 = load <2 x i64>, <2 x i64>* %136, align 16
  store <2 x i64> %137, <2 x i64>* %38, align 16
  %138 = getelementptr inbounds i16, i16* %101, i64 %73
  %139 = bitcast i16* %138 to <2 x i64>*
  %140 = load <2 x i64>, <2 x i64>* %139, align 16
  store <2 x i64> %140, <2 x i64>* %36, align 16
  %141 = getelementptr inbounds i16, i16* %101, i64 %74
  %142 = bitcast i16* %141 to <2 x i64>*
  %143 = load <2 x i64>, <2 x i64>* %142, align 16
  store <2 x i64> %143, <2 x i64>* %34, align 16
  %144 = getelementptr inbounds i16, i16* %101, i64 %75
  %145 = bitcast i16* %144 to <2 x i64>*
  %146 = load <2 x i64>, <2 x i64>* %145, align 16
  store <2 x i64> %146, <2 x i64>* %32, align 16
  %147 = getelementptr inbounds i16, i16* %101, i64 %76
  %148 = bitcast i16* %147 to <2 x i64>*
  %149 = load <2 x i64>, <2 x i64>* %148, align 16
  store <2 x i64> %149, <2 x i64>* %28, align 16
  br label %196

150:                                              ; preds = %98
  store <2 x i64> %103, <2 x i64>* %28, align 16
  %151 = getelementptr inbounds i16, i16* %101, i64 %29
  %152 = bitcast i16* %151 to <2 x i64>*
  %153 = load <2 x i64>, <2 x i64>* %152, align 16
  store <2 x i64> %153, <2 x i64>* %32, align 16
  %154 = getelementptr inbounds i16, i16* %101, i64 %77
  %155 = bitcast i16* %154 to <2 x i64>*
  %156 = load <2 x i64>, <2 x i64>* %155, align 16
  store <2 x i64> %156, <2 x i64>* %34, align 16
  %157 = getelementptr inbounds i16, i16* %101, i64 %78
  %158 = bitcast i16* %157 to <2 x i64>*
  %159 = load <2 x i64>, <2 x i64>* %158, align 16
  store <2 x i64> %159, <2 x i64>* %36, align 16
  %160 = getelementptr inbounds i16, i16* %101, i64 %79
  %161 = bitcast i16* %160 to <2 x i64>*
  %162 = load <2 x i64>, <2 x i64>* %161, align 16
  store <2 x i64> %162, <2 x i64>* %38, align 16
  %163 = getelementptr inbounds i16, i16* %101, i64 %80
  %164 = bitcast i16* %163 to <2 x i64>*
  %165 = load <2 x i64>, <2 x i64>* %164, align 16
  store <2 x i64> %165, <2 x i64>* %40, align 16
  %166 = getelementptr inbounds i16, i16* %101, i64 %81
  %167 = bitcast i16* %166 to <2 x i64>*
  %168 = load <2 x i64>, <2 x i64>* %167, align 16
  store <2 x i64> %168, <2 x i64>* %42, align 16
  %169 = getelementptr inbounds i16, i16* %101, i64 %82
  %170 = bitcast i16* %169 to <2 x i64>*
  %171 = load <2 x i64>, <2 x i64>* %170, align 16
  store <2 x i64> %171, <2 x i64>* %44, align 16
  %172 = getelementptr inbounds i16, i16* %101, i64 %83
  %173 = bitcast i16* %172 to <2 x i64>*
  %174 = load <2 x i64>, <2 x i64>* %173, align 16
  store <2 x i64> %174, <2 x i64>* %46, align 16
  %175 = getelementptr inbounds i16, i16* %101, i64 %84
  %176 = bitcast i16* %175 to <2 x i64>*
  %177 = load <2 x i64>, <2 x i64>* %176, align 16
  store <2 x i64> %177, <2 x i64>* %49, align 16
  %178 = getelementptr inbounds i16, i16* %101, i64 %85
  %179 = bitcast i16* %178 to <2 x i64>*
  %180 = load <2 x i64>, <2 x i64>* %179, align 16
  store <2 x i64> %180, <2 x i64>* %51, align 16
  %181 = getelementptr inbounds i16, i16* %101, i64 %86
  %182 = bitcast i16* %181 to <2 x i64>*
  %183 = load <2 x i64>, <2 x i64>* %182, align 16
  store <2 x i64> %183, <2 x i64>* %53, align 16
  %184 = getelementptr inbounds i16, i16* %101, i64 %87
  %185 = bitcast i16* %184 to <2 x i64>*
  %186 = load <2 x i64>, <2 x i64>* %185, align 16
  store <2 x i64> %186, <2 x i64>* %55, align 16
  %187 = getelementptr inbounds i16, i16* %101, i64 %88
  %188 = bitcast i16* %187 to <2 x i64>*
  %189 = load <2 x i64>, <2 x i64>* %188, align 16
  store <2 x i64> %189, <2 x i64>* %57, align 16
  %190 = getelementptr inbounds i16, i16* %101, i64 %89
  %191 = bitcast i16* %190 to <2 x i64>*
  %192 = load <2 x i64>, <2 x i64>* %191, align 16
  store <2 x i64> %192, <2 x i64>* %59, align 16
  %193 = getelementptr inbounds i16, i16* %101, i64 %90
  %194 = bitcast i16* %193 to <2 x i64>*
  %195 = load <2 x i64>, <2 x i64>* %194, align 16
  store <2 x i64> %195, <2 x i64>* %61, align 16
  br label %196

196:                                              ; preds = %104, %150
  %197 = phi <2 x i64> [ %110, %104 ], [ %189, %150 ]
  %198 = phi <2 x i64> [ %113, %104 ], [ %186, %150 ]
  %199 = phi <2 x i64> [ %116, %104 ], [ %183, %150 ]
  %200 = phi <2 x i64> [ %119, %104 ], [ %180, %150 ]
  %201 = phi <2 x i64> [ %122, %104 ], [ %177, %150 ]
  %202 = phi <2 x i64> [ %125, %104 ], [ %174, %150 ]
  %203 = phi <2 x i64> [ %128, %104 ], [ %171, %150 ]
  %204 = phi <2 x i64> [ %131, %104 ], [ %168, %150 ]
  %205 = phi <2 x i64> [ %134, %104 ], [ %165, %150 ]
  %206 = phi <2 x i64> [ %137, %104 ], [ %162, %150 ]
  %207 = phi <2 x i64> [ %140, %104 ], [ %159, %150 ]
  %208 = phi <2 x i64> [ %143, %104 ], [ %156, %150 ]
  %209 = phi <2 x i64> [ %146, %104 ], [ %153, %150 ]
  %210 = phi <2 x i64> [ %149, %104 ], [ %103, %150 ]
  %211 = bitcast <2 x i64> %208 to <8 x i16>
  %212 = bitcast <2 x i64> %207 to <8 x i16>
  %213 = bitcast <2 x i64> %206 to <8 x i16>
  %214 = bitcast <2 x i64> %205 to <8 x i16>
  %215 = bitcast <2 x i64> %204 to <8 x i16>
  %216 = bitcast <2 x i64> %203 to <8 x i16>
  %217 = bitcast <2 x i64> %202 to <8 x i16>
  %218 = bitcast <2 x i64> %201 to <8 x i16>
  %219 = bitcast <2 x i64> %200 to <8 x i16>
  %220 = bitcast <2 x i64> %199 to <8 x i16>
  %221 = bitcast <2 x i64> %198 to <8 x i16>
  %222 = bitcast <2 x i64> %197 to <8 x i16>
  %223 = bitcast <2 x i64> %209 to <8 x i16>
  %224 = bitcast <2 x i64> %210 to <8 x i16>
  %225 = load i8, i8* %10, align 1
  %226 = sext i8 %225 to i32
  %227 = icmp slt i8 %225, 0
  br i1 %227, label %228, label %271

228:                                              ; preds = %196
  %229 = sub nsw i32 0, %226
  %230 = xor i32 %226, -1
  %231 = shl i32 1, %230
  %232 = trunc i32 %231 to i16
  %233 = insertelement <8 x i16> undef, i16 %232, i32 0
  %234 = shufflevector <8 x i16> %233, <8 x i16> undef, <8 x i32> zeroinitializer
  %235 = load <8 x i16>, <8 x i16>* %92, align 16
  %236 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %235, <8 x i16> %234) #8
  %237 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %236, i32 %229) #8
  store <8 x i16> %237, <8 x i16>* %92, align 16
  %238 = load <8 x i16>, <8 x i16>* %33, align 16
  %239 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %238, <8 x i16> %234) #8
  %240 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %239, i32 %229) #8
  store <8 x i16> %240, <8 x i16>* %33, align 16
  %241 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %211, <8 x i16> %234) #8
  %242 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %241, i32 %229) #8
  store <8 x i16> %242, <8 x i16>* %35, align 16
  %243 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %212, <8 x i16> %234) #8
  %244 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %243, i32 %229) #8
  store <8 x i16> %244, <8 x i16>* %37, align 16
  %245 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %213, <8 x i16> %234) #8
  %246 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %245, i32 %229) #8
  store <8 x i16> %246, <8 x i16>* %39, align 16
  %247 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %214, <8 x i16> %234) #8
  %248 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %247, i32 %229) #8
  store <8 x i16> %248, <8 x i16>* %41, align 16
  %249 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %215, <8 x i16> %234) #8
  %250 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %249, i32 %229) #8
  store <8 x i16> %250, <8 x i16>* %43, align 16
  %251 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %216, <8 x i16> %234) #8
  %252 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %251, i32 %229) #8
  store <8 x i16> %252, <8 x i16>* %45, align 16
  %253 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %217, <8 x i16> %234) #8
  %254 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %253, i32 %229) #8
  store <8 x i16> %254, <8 x i16>* %48, align 16
  %255 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %218, <8 x i16> %234) #8
  %256 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %255, i32 %229) #8
  store <8 x i16> %256, <8 x i16>* %50, align 16
  %257 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %219, <8 x i16> %234) #8
  %258 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %257, i32 %229) #8
  store <8 x i16> %258, <8 x i16>* %52, align 16
  %259 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %220, <8 x i16> %234) #8
  %260 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %259, i32 %229) #8
  store <8 x i16> %260, <8 x i16>* %54, align 16
  %261 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %221, <8 x i16> %234) #8
  %262 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %261, i32 %229) #8
  store <8 x i16> %262, <8 x i16>* %56, align 16
  %263 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %222, <8 x i16> %234) #8
  %264 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %263, i32 %229) #8
  store <8 x i16> %264, <8 x i16>* %58, align 16
  %265 = load <8 x i16>, <8 x i16>* %60, align 16
  %266 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %265, <8 x i16> %234) #8
  %267 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %266, i32 %229) #8
  store <8 x i16> %267, <8 x i16>* %60, align 16
  %268 = load <8 x i16>, <8 x i16>* %62, align 16
  %269 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %268, <8 x i16> %234) #8
  %270 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %269, i32 %229) #8
  br label %292

271:                                              ; preds = %196
  %272 = icmp eq i8 %225, 0
  br i1 %272, label %294, label %273

273:                                              ; preds = %271
  %274 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %224, i32 %226) #8
  store <8 x i16> %274, <8 x i16>* %91, align 16
  %275 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %223, i32 %226) #8
  store <8 x i16> %275, <8 x i16>* %33, align 16
  %276 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %211, i32 %226) #8
  store <8 x i16> %276, <8 x i16>* %35, align 16
  %277 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %212, i32 %226) #8
  store <8 x i16> %277, <8 x i16>* %37, align 16
  %278 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %213, i32 %226) #8
  store <8 x i16> %278, <8 x i16>* %39, align 16
  %279 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %214, i32 %226) #8
  store <8 x i16> %279, <8 x i16>* %41, align 16
  %280 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %215, i32 %226) #8
  store <8 x i16> %280, <8 x i16>* %43, align 16
  %281 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %216, i32 %226) #8
  store <8 x i16> %281, <8 x i16>* %45, align 16
  %282 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %217, i32 %226) #8
  store <8 x i16> %282, <8 x i16>* %48, align 16
  %283 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %218, i32 %226) #8
  store <8 x i16> %283, <8 x i16>* %50, align 16
  %284 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %219, i32 %226) #8
  store <8 x i16> %284, <8 x i16>* %52, align 16
  %285 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %220, i32 %226) #8
  store <8 x i16> %285, <8 x i16>* %54, align 16
  %286 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %221, i32 %226) #8
  store <8 x i16> %286, <8 x i16>* %56, align 16
  %287 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %222, i32 %226) #8
  store <8 x i16> %287, <8 x i16>* %58, align 16
  %288 = load <8 x i16>, <8 x i16>* %60, align 16
  %289 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %288, i32 %226) #8
  store <8 x i16> %289, <8 x i16>* %60, align 16
  %290 = load <8 x i16>, <8 x i16>* %62, align 16
  %291 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %290, i32 %226) #8
  br label %292

292:                                              ; preds = %228, %273
  %293 = phi <8 x i16> [ %291, %273 ], [ %270, %228 ]
  store <8 x i16> %293, <8 x i16>* %62, align 16
  br label %294

294:                                              ; preds = %292, %271
  call void %15(<2 x i64>* nonnull %28, <2 x i64>* nonnull %28, i8 signext %11) #8
  %295 = load i8, i8* %30, align 1
  %296 = sext i8 %295 to i32
  %297 = icmp slt i8 %295, 0
  br i1 %297, label %298, label %353

298:                                              ; preds = %294
  %299 = sub nsw i32 0, %296
  %300 = xor i32 %296, -1
  %301 = shl i32 1, %300
  %302 = trunc i32 %301 to i16
  %303 = insertelement <8 x i16> undef, i16 %302, i32 0
  %304 = shufflevector <8 x i16> %303, <8 x i16> undef, <8 x i32> zeroinitializer
  %305 = load <8 x i16>, <8 x i16>* %94, align 16
  %306 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %305, <8 x i16> %304) #8
  %307 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %306, i32 %299) #8
  store <8 x i16> %307, <8 x i16>* %94, align 16
  %308 = load <8 x i16>, <8 x i16>* %33, align 16
  %309 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %308, <8 x i16> %304) #8
  %310 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %309, i32 %299) #8
  store <8 x i16> %310, <8 x i16>* %33, align 16
  %311 = load <8 x i16>, <8 x i16>* %35, align 16
  %312 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %311, <8 x i16> %304) #8
  %313 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %312, i32 %299) #8
  store <8 x i16> %313, <8 x i16>* %35, align 16
  %314 = load <8 x i16>, <8 x i16>* %37, align 16
  %315 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %314, <8 x i16> %304) #8
  %316 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %315, i32 %299) #8
  store <8 x i16> %316, <8 x i16>* %37, align 16
  %317 = load <8 x i16>, <8 x i16>* %39, align 16
  %318 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %317, <8 x i16> %304) #8
  %319 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %318, i32 %299) #8
  store <8 x i16> %319, <8 x i16>* %39, align 16
  %320 = load <8 x i16>, <8 x i16>* %41, align 16
  %321 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %320, <8 x i16> %304) #8
  %322 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %321, i32 %299) #8
  store <8 x i16> %322, <8 x i16>* %41, align 16
  %323 = load <8 x i16>, <8 x i16>* %43, align 16
  %324 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %323, <8 x i16> %304) #8
  %325 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %324, i32 %299) #8
  store <8 x i16> %325, <8 x i16>* %43, align 16
  %326 = load <8 x i16>, <8 x i16>* %45, align 16
  %327 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %326, <8 x i16> %304) #8
  %328 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %327, i32 %299) #8
  store <8 x i16> %328, <8 x i16>* %45, align 16
  %329 = load <8 x i16>, <8 x i16>* %48, align 16
  %330 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %329, <8 x i16> %304) #8
  %331 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %330, i32 %299) #8
  store <8 x i16> %331, <8 x i16>* %48, align 16
  %332 = load <8 x i16>, <8 x i16>* %50, align 16
  %333 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %332, <8 x i16> %304) #8
  %334 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %333, i32 %299) #8
  store <8 x i16> %334, <8 x i16>* %50, align 16
  %335 = load <8 x i16>, <8 x i16>* %52, align 16
  %336 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %335, <8 x i16> %304) #8
  %337 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %336, i32 %299) #8
  store <8 x i16> %337, <8 x i16>* %52, align 16
  %338 = load <8 x i16>, <8 x i16>* %54, align 16
  %339 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %338, <8 x i16> %304) #8
  %340 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %339, i32 %299) #8
  store <8 x i16> %340, <8 x i16>* %54, align 16
  %341 = load <8 x i16>, <8 x i16>* %56, align 16
  %342 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %341, <8 x i16> %304) #8
  %343 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %342, i32 %299) #8
  store <8 x i16> %343, <8 x i16>* %56, align 16
  %344 = load <8 x i16>, <8 x i16>* %58, align 16
  %345 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %344, <8 x i16> %304) #8
  %346 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %345, i32 %299) #8
  store <8 x i16> %346, <8 x i16>* %58, align 16
  %347 = load <8 x i16>, <8 x i16>* %60, align 16
  %348 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %347, <8 x i16> %304) #8
  %349 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %348, i32 %299) #8
  store <8 x i16> %349, <8 x i16>* %60, align 16
  %350 = load <8 x i16>, <8 x i16>* %62, align 16
  %351 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %350, <8 x i16> %304) #8
  %352 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %351, i32 %299) #8
  store <8 x i16> %352, <8 x i16>* %62, align 16
  br label %405

353:                                              ; preds = %294
  %354 = icmp eq i8 %295, 0
  br i1 %354, label %355, label %372

355:                                              ; preds = %353
  %356 = load <8 x i16>, <8 x i16>* %31, align 16
  %357 = load <8 x i16>, <8 x i16>* %33, align 16
  %358 = load <8 x i16>, <8 x i16>* %35, align 16
  %359 = load <8 x i16>, <8 x i16>* %37, align 16
  %360 = load <8 x i16>, <8 x i16>* %39, align 16
  %361 = load <8 x i16>, <8 x i16>* %41, align 16
  %362 = load <8 x i16>, <8 x i16>* %43, align 16
  %363 = load <8 x i16>, <8 x i16>* %45, align 16
  %364 = load <8 x i16>, <8 x i16>* %48, align 16
  %365 = load <8 x i16>, <8 x i16>* %50, align 16
  %366 = load <8 x i16>, <8 x i16>* %52, align 16
  %367 = load <8 x i16>, <8 x i16>* %54, align 16
  %368 = load <8 x i16>, <8 x i16>* %56, align 16
  %369 = load <8 x i16>, <8 x i16>* %58, align 16
  %370 = load <8 x i16>, <8 x i16>* %60, align 16
  %371 = load <8 x i16>, <8 x i16>* %62, align 16
  br label %405

372:                                              ; preds = %353
  %373 = load <8 x i16>, <8 x i16>* %93, align 16
  %374 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %373, i32 %296) #8
  store <8 x i16> %374, <8 x i16>* %93, align 16
  %375 = load <8 x i16>, <8 x i16>* %33, align 16
  %376 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %375, i32 %296) #8
  store <8 x i16> %376, <8 x i16>* %33, align 16
  %377 = load <8 x i16>, <8 x i16>* %35, align 16
  %378 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %377, i32 %296) #8
  store <8 x i16> %378, <8 x i16>* %35, align 16
  %379 = load <8 x i16>, <8 x i16>* %37, align 16
  %380 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %379, i32 %296) #8
  store <8 x i16> %380, <8 x i16>* %37, align 16
  %381 = load <8 x i16>, <8 x i16>* %39, align 16
  %382 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %381, i32 %296) #8
  store <8 x i16> %382, <8 x i16>* %39, align 16
  %383 = load <8 x i16>, <8 x i16>* %41, align 16
  %384 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %383, i32 %296) #8
  store <8 x i16> %384, <8 x i16>* %41, align 16
  %385 = load <8 x i16>, <8 x i16>* %43, align 16
  %386 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %385, i32 %296) #8
  store <8 x i16> %386, <8 x i16>* %43, align 16
  %387 = load <8 x i16>, <8 x i16>* %45, align 16
  %388 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %387, i32 %296) #8
  store <8 x i16> %388, <8 x i16>* %45, align 16
  %389 = load <8 x i16>, <8 x i16>* %48, align 16
  %390 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %389, i32 %296) #8
  store <8 x i16> %390, <8 x i16>* %48, align 16
  %391 = load <8 x i16>, <8 x i16>* %50, align 16
  %392 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %391, i32 %296) #8
  store <8 x i16> %392, <8 x i16>* %50, align 16
  %393 = load <8 x i16>, <8 x i16>* %52, align 16
  %394 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %393, i32 %296) #8
  store <8 x i16> %394, <8 x i16>* %52, align 16
  %395 = load <8 x i16>, <8 x i16>* %54, align 16
  %396 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %395, i32 %296) #8
  store <8 x i16> %396, <8 x i16>* %54, align 16
  %397 = load <8 x i16>, <8 x i16>* %56, align 16
  %398 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %397, i32 %296) #8
  store <8 x i16> %398, <8 x i16>* %56, align 16
  %399 = load <8 x i16>, <8 x i16>* %58, align 16
  %400 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %399, i32 %296) #8
  store <8 x i16> %400, <8 x i16>* %58, align 16
  %401 = load <8 x i16>, <8 x i16>* %60, align 16
  %402 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %401, i32 %296) #8
  store <8 x i16> %402, <8 x i16>* %60, align 16
  %403 = load <8 x i16>, <8 x i16>* %62, align 16
  %404 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %403, i32 %296) #8
  store <8 x i16> %404, <8 x i16>* %62, align 16
  br label %405

405:                                              ; preds = %355, %372, %298
  %406 = phi <8 x i16> [ %371, %355 ], [ %404, %372 ], [ %352, %298 ]
  %407 = phi <8 x i16> [ %370, %355 ], [ %402, %372 ], [ %349, %298 ]
  %408 = phi <8 x i16> [ %369, %355 ], [ %400, %372 ], [ %346, %298 ]
  %409 = phi <8 x i16> [ %368, %355 ], [ %398, %372 ], [ %343, %298 ]
  %410 = phi <8 x i16> [ %367, %355 ], [ %396, %372 ], [ %340, %298 ]
  %411 = phi <8 x i16> [ %366, %355 ], [ %394, %372 ], [ %337, %298 ]
  %412 = phi <8 x i16> [ %365, %355 ], [ %392, %372 ], [ %334, %298 ]
  %413 = phi <8 x i16> [ %364, %355 ], [ %390, %372 ], [ %331, %298 ]
  %414 = phi <8 x i16> [ %363, %355 ], [ %388, %372 ], [ %328, %298 ]
  %415 = phi <8 x i16> [ %362, %355 ], [ %386, %372 ], [ %325, %298 ]
  %416 = phi <8 x i16> [ %361, %355 ], [ %384, %372 ], [ %322, %298 ]
  %417 = phi <8 x i16> [ %360, %355 ], [ %382, %372 ], [ %319, %298 ]
  %418 = phi <8 x i16> [ %359, %355 ], [ %380, %372 ], [ %316, %298 ]
  %419 = phi <8 x i16> [ %358, %355 ], [ %378, %372 ], [ %313, %298 ]
  %420 = phi <8 x i16> [ %357, %355 ], [ %376, %372 ], [ %310, %298 ]
  %421 = phi <8 x i16> [ %356, %355 ], [ %374, %372 ], [ %307, %298 ]
  %422 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 %100
  %423 = shufflevector <8 x i16> %421, <8 x i16> %420, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %424 = shufflevector <8 x i16> %419, <8 x i16> %418, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %425 = shufflevector <8 x i16> %417, <8 x i16> %416, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %426 = shufflevector <8 x i16> %415, <8 x i16> %414, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %427 = shufflevector <8 x i16> %421, <8 x i16> %420, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %428 = shufflevector <8 x i16> %419, <8 x i16> %418, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %429 = shufflevector <8 x i16> %417, <8 x i16> %416, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %430 = shufflevector <8 x i16> %415, <8 x i16> %414, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %431 = bitcast <8 x i16> %423 to <4 x i32>
  %432 = bitcast <8 x i16> %424 to <4 x i32>
  %433 = shufflevector <4 x i32> %431, <4 x i32> %432, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %434 = bitcast <4 x i32> %433 to <2 x i64>
  %435 = bitcast <8 x i16> %425 to <4 x i32>
  %436 = bitcast <8 x i16> %426 to <4 x i32>
  %437 = shufflevector <4 x i32> %435, <4 x i32> %436, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %438 = bitcast <4 x i32> %437 to <2 x i64>
  %439 = bitcast <8 x i16> %427 to <4 x i32>
  %440 = bitcast <8 x i16> %428 to <4 x i32>
  %441 = shufflevector <4 x i32> %439, <4 x i32> %440, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %442 = bitcast <4 x i32> %441 to <2 x i64>
  %443 = bitcast <8 x i16> %429 to <4 x i32>
  %444 = bitcast <8 x i16> %430 to <4 x i32>
  %445 = shufflevector <4 x i32> %443, <4 x i32> %444, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %446 = bitcast <4 x i32> %445 to <2 x i64>
  %447 = shufflevector <4 x i32> %431, <4 x i32> %432, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %448 = bitcast <4 x i32> %447 to <2 x i64>
  %449 = shufflevector <4 x i32> %435, <4 x i32> %436, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %450 = bitcast <4 x i32> %449 to <2 x i64>
  %451 = shufflevector <4 x i32> %439, <4 x i32> %440, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %452 = bitcast <4 x i32> %451 to <2 x i64>
  %453 = shufflevector <4 x i32> %443, <4 x i32> %444, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %454 = bitcast <4 x i32> %453 to <2 x i64>
  %455 = shufflevector <2 x i64> %434, <2 x i64> %438, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %455, <2 x i64>* %422, align 16
  %456 = shufflevector <2 x i64> %434, <2 x i64> %438, <2 x i32> <i32 1, i32 3>
  %457 = getelementptr inbounds <2 x i64>, <2 x i64>* %422, i64 1
  store <2 x i64> %456, <2 x i64>* %457, align 16
  %458 = shufflevector <2 x i64> %448, <2 x i64> %450, <2 x i32> <i32 0, i32 2>
  %459 = getelementptr inbounds <2 x i64>, <2 x i64>* %422, i64 2
  store <2 x i64> %458, <2 x i64>* %459, align 16
  %460 = shufflevector <2 x i64> %448, <2 x i64> %450, <2 x i32> <i32 1, i32 3>
  %461 = getelementptr inbounds <2 x i64>, <2 x i64>* %422, i64 3
  store <2 x i64> %460, <2 x i64>* %461, align 16
  %462 = shufflevector <2 x i64> %442, <2 x i64> %446, <2 x i32> <i32 0, i32 2>
  %463 = getelementptr inbounds <2 x i64>, <2 x i64>* %422, i64 4
  store <2 x i64> %462, <2 x i64>* %463, align 16
  %464 = shufflevector <2 x i64> %442, <2 x i64> %446, <2 x i32> <i32 1, i32 3>
  %465 = getelementptr inbounds <2 x i64>, <2 x i64>* %422, i64 5
  store <2 x i64> %464, <2 x i64>* %465, align 16
  %466 = shufflevector <2 x i64> %452, <2 x i64> %454, <2 x i32> <i32 0, i32 2>
  %467 = getelementptr inbounds <2 x i64>, <2 x i64>* %422, i64 6
  store <2 x i64> %466, <2 x i64>* %467, align 16
  %468 = shufflevector <2 x i64> %452, <2 x i64> %454, <2 x i32> <i32 1, i32 3>
  %469 = getelementptr inbounds <2 x i64>, <2 x i64>* %422, i64 7
  store <2 x i64> %468, <2 x i64>* %469, align 16
  %470 = getelementptr inbounds <2 x i64>, <2 x i64>* %47, i64 %100
  %471 = shufflevector <8 x i16> %413, <8 x i16> %412, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %472 = shufflevector <8 x i16> %411, <8 x i16> %410, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %473 = shufflevector <8 x i16> %409, <8 x i16> %408, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %474 = shufflevector <8 x i16> %407, <8 x i16> %406, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %475 = shufflevector <8 x i16> %413, <8 x i16> %412, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %476 = shufflevector <8 x i16> %411, <8 x i16> %410, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %477 = shufflevector <8 x i16> %409, <8 x i16> %408, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %478 = shufflevector <8 x i16> %407, <8 x i16> %406, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %479 = bitcast <8 x i16> %471 to <4 x i32>
  %480 = bitcast <8 x i16> %472 to <4 x i32>
  %481 = shufflevector <4 x i32> %479, <4 x i32> %480, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %482 = bitcast <4 x i32> %481 to <2 x i64>
  %483 = bitcast <8 x i16> %473 to <4 x i32>
  %484 = bitcast <8 x i16> %474 to <4 x i32>
  %485 = shufflevector <4 x i32> %483, <4 x i32> %484, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %486 = bitcast <4 x i32> %485 to <2 x i64>
  %487 = bitcast <8 x i16> %475 to <4 x i32>
  %488 = bitcast <8 x i16> %476 to <4 x i32>
  %489 = shufflevector <4 x i32> %487, <4 x i32> %488, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %490 = bitcast <4 x i32> %489 to <2 x i64>
  %491 = bitcast <8 x i16> %477 to <4 x i32>
  %492 = bitcast <8 x i16> %478 to <4 x i32>
  %493 = shufflevector <4 x i32> %491, <4 x i32> %492, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %494 = bitcast <4 x i32> %493 to <2 x i64>
  %495 = shufflevector <4 x i32> %479, <4 x i32> %480, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %496 = bitcast <4 x i32> %495 to <2 x i64>
  %497 = shufflevector <4 x i32> %483, <4 x i32> %484, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %498 = bitcast <4 x i32> %497 to <2 x i64>
  %499 = shufflevector <4 x i32> %487, <4 x i32> %488, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %500 = bitcast <4 x i32> %499 to <2 x i64>
  %501 = shufflevector <4 x i32> %491, <4 x i32> %492, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %502 = bitcast <4 x i32> %501 to <2 x i64>
  %503 = shufflevector <2 x i64> %482, <2 x i64> %486, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %503, <2 x i64>* %470, align 16
  %504 = shufflevector <2 x i64> %482, <2 x i64> %486, <2 x i32> <i32 1, i32 3>
  %505 = getelementptr inbounds <2 x i64>, <2 x i64>* %470, i64 1
  store <2 x i64> %504, <2 x i64>* %505, align 16
  %506 = shufflevector <2 x i64> %496, <2 x i64> %498, <2 x i32> <i32 0, i32 2>
  %507 = getelementptr inbounds <2 x i64>, <2 x i64>* %470, i64 2
  store <2 x i64> %506, <2 x i64>* %507, align 16
  %508 = shufflevector <2 x i64> %496, <2 x i64> %498, <2 x i32> <i32 1, i32 3>
  %509 = getelementptr inbounds <2 x i64>, <2 x i64>* %470, i64 3
  store <2 x i64> %508, <2 x i64>* %509, align 16
  %510 = shufflevector <2 x i64> %490, <2 x i64> %494, <2 x i32> <i32 0, i32 2>
  %511 = getelementptr inbounds <2 x i64>, <2 x i64>* %470, i64 4
  store <2 x i64> %510, <2 x i64>* %511, align 16
  %512 = shufflevector <2 x i64> %490, <2 x i64> %494, <2 x i32> <i32 1, i32 3>
  %513 = getelementptr inbounds <2 x i64>, <2 x i64>* %470, i64 5
  store <2 x i64> %512, <2 x i64>* %513, align 16
  %514 = shufflevector <2 x i64> %500, <2 x i64> %502, <2 x i32> <i32 0, i32 2>
  %515 = getelementptr inbounds <2 x i64>, <2 x i64>* %470, i64 6
  store <2 x i64> %514, <2 x i64>* %515, align 16
  %516 = shufflevector <2 x i64> %500, <2 x i64> %502, <2 x i32> <i32 1, i32 3>
  %517 = getelementptr inbounds <2 x i64>, <2 x i64>* %470, i64 7
  store <2 x i64> %516, <2 x i64>* %517, align 16
  %518 = add nuw nsw i64 %99, 1
  %519 = icmp eq i64 %518, 4
  br i1 %519, label %95, label %98

520:                                              ; preds = %605, %95
  %521 = phi i64 [ 0, %95 ], [ %1220, %605 ]
  %522 = shl nsw i64 %521, 5
  %523 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %7, i64 0, i64 %522
  br i1 %96, label %541, label %524

524:                                              ; preds = %520, %524
  %525 = phi i64 [ %539, %524 ], [ 0, %520 ]
  %526 = getelementptr inbounds <2 x i64>, <2 x i64>* %523, i64 %525
  %527 = load <2 x i64>, <2 x i64>* %526, align 16
  %528 = shl i64 %525, 32
  %529 = sub nuw nsw i64 133143986176, %528
  %530 = ashr exact i64 %529, 32
  %531 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %530
  store <2 x i64> %527, <2 x i64>* %531, align 16
  %532 = or i64 %525, 1
  %533 = getelementptr inbounds <2 x i64>, <2 x i64>* %523, i64 %532
  %534 = load <2 x i64>, <2 x i64>* %533, align 16
  %535 = shl i64 %532, 32
  %536 = sub nuw nsw i64 133143986176, %535
  %537 = ashr exact i64 %536, 32
  %538 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %537
  store <2 x i64> %534, <2 x i64>* %538, align 16
  %539 = add nuw nsw i64 %525, 2
  %540 = icmp eq i64 %539, 32
  br i1 %540, label %541, label %524

541:                                              ; preds = %524, %520
  %542 = phi <2 x i64>* [ %523, %520 ], [ %28, %524 ]
  call void %17(<2 x i64>* %542, <2 x i64>* %542, i8 signext %12) #8
  %543 = load i8, i8* %97, align 1
  %544 = sext i8 %543 to i32
  %545 = icmp slt i8 %543, 0
  br i1 %545, label %546, label %580

546:                                              ; preds = %541
  %547 = sub nsw i32 0, %544
  %548 = xor i32 %544, -1
  %549 = shl i32 1, %548
  %550 = trunc i32 %549 to i16
  %551 = insertelement <8 x i16> undef, i16 %550, i32 0
  %552 = shufflevector <8 x i16> %551, <8 x i16> undef, <8 x i32> zeroinitializer
  br label %553

553:                                              ; preds = %553, %546
  %554 = phi i64 [ 0, %546 ], [ %578, %553 ]
  %555 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 %554
  %556 = bitcast <2 x i64>* %555 to <8 x i16>*
  %557 = load <8 x i16>, <8 x i16>* %556, align 16
  %558 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %557, <8 x i16> %552) #8
  %559 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %558, i32 %547) #8
  store <8 x i16> %559, <8 x i16>* %556, align 16
  %560 = or i64 %554, 1
  %561 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 %560
  %562 = bitcast <2 x i64>* %561 to <8 x i16>*
  %563 = load <8 x i16>, <8 x i16>* %562, align 16
  %564 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %563, <8 x i16> %552) #8
  %565 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %564, i32 %547) #8
  store <8 x i16> %565, <8 x i16>* %562, align 16
  %566 = or i64 %554, 2
  %567 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 %566
  %568 = bitcast <2 x i64>* %567 to <8 x i16>*
  %569 = load <8 x i16>, <8 x i16>* %568, align 16
  %570 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %569, <8 x i16> %552) #8
  %571 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %570, i32 %547) #8
  store <8 x i16> %571, <8 x i16>* %568, align 16
  %572 = or i64 %554, 3
  %573 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 %572
  %574 = bitcast <2 x i64>* %573 to <8 x i16>*
  %575 = load <8 x i16>, <8 x i16>* %574, align 16
  %576 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %575, <8 x i16> %552) #8
  %577 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %576, i32 %547) #8
  store <8 x i16> %577, <8 x i16>* %574, align 16
  %578 = add nuw nsw i64 %554, 4
  %579 = icmp eq i64 %578, 32
  br i1 %579, label %605, label %553

580:                                              ; preds = %541
  %581 = icmp eq i8 %543, 0
  br i1 %581, label %605, label %582

582:                                              ; preds = %580, %582
  %583 = phi i64 [ %603, %582 ], [ 0, %580 ]
  %584 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 %583
  %585 = bitcast <2 x i64>* %584 to <8 x i16>*
  %586 = load <8 x i16>, <8 x i16>* %585, align 16
  %587 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %586, i32 %544) #8
  store <8 x i16> %587, <8 x i16>* %585, align 16
  %588 = or i64 %583, 1
  %589 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 %588
  %590 = bitcast <2 x i64>* %589 to <8 x i16>*
  %591 = load <8 x i16>, <8 x i16>* %590, align 16
  %592 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %591, i32 %544) #8
  store <8 x i16> %592, <8 x i16>* %590, align 16
  %593 = or i64 %583, 2
  %594 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 %593
  %595 = bitcast <2 x i64>* %594 to <8 x i16>*
  %596 = load <8 x i16>, <8 x i16>* %595, align 16
  %597 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %596, i32 %544) #8
  store <8 x i16> %597, <8 x i16>* %595, align 16
  %598 = or i64 %583, 3
  %599 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 %598
  %600 = bitcast <2 x i64>* %599 to <8 x i16>*
  %601 = load <8 x i16>, <8 x i16>* %600, align 16
  %602 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %601, i32 %544) #8
  store <8 x i16> %602, <8 x i16>* %600, align 16
  %603 = add nuw nsw i64 %583, 4
  %604 = icmp eq i64 %603, 32
  br i1 %604, label %605, label %582

605:                                              ; preds = %582, %553, %580
  %606 = bitcast <2 x i64>* %542 to <8 x i16>*
  %607 = load <8 x i16>, <8 x i16>* %606, align 16
  %608 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 1
  %609 = bitcast <2 x i64>* %608 to <8 x i16>*
  %610 = load <8 x i16>, <8 x i16>* %609, align 16
  %611 = shufflevector <8 x i16> %607, <8 x i16> %610, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %612 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 2
  %613 = bitcast <2 x i64>* %612 to <8 x i16>*
  %614 = load <8 x i16>, <8 x i16>* %613, align 16
  %615 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 3
  %616 = bitcast <2 x i64>* %615 to <8 x i16>*
  %617 = load <8 x i16>, <8 x i16>* %616, align 16
  %618 = shufflevector <8 x i16> %614, <8 x i16> %617, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %619 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 4
  %620 = bitcast <2 x i64>* %619 to <8 x i16>*
  %621 = load <8 x i16>, <8 x i16>* %620, align 16
  %622 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 5
  %623 = bitcast <2 x i64>* %622 to <8 x i16>*
  %624 = load <8 x i16>, <8 x i16>* %623, align 16
  %625 = shufflevector <8 x i16> %621, <8 x i16> %624, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %626 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 6
  %627 = bitcast <2 x i64>* %626 to <8 x i16>*
  %628 = load <8 x i16>, <8 x i16>* %627, align 16
  %629 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 7
  %630 = bitcast <2 x i64>* %629 to <8 x i16>*
  %631 = load <8 x i16>, <8 x i16>* %630, align 16
  %632 = shufflevector <8 x i16> %628, <8 x i16> %631, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %633 = shufflevector <8 x i16> %607, <8 x i16> %610, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %634 = shufflevector <8 x i16> %614, <8 x i16> %617, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %635 = shufflevector <8 x i16> %621, <8 x i16> %624, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %636 = shufflevector <8 x i16> %628, <8 x i16> %631, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %637 = bitcast <8 x i16> %611 to <4 x i32>
  %638 = bitcast <8 x i16> %618 to <4 x i32>
  %639 = shufflevector <4 x i32> %637, <4 x i32> %638, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %640 = bitcast <4 x i32> %639 to <2 x i64>
  %641 = bitcast <8 x i16> %625 to <4 x i32>
  %642 = bitcast <8 x i16> %632 to <4 x i32>
  %643 = shufflevector <4 x i32> %641, <4 x i32> %642, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %644 = bitcast <4 x i32> %643 to <2 x i64>
  %645 = bitcast <8 x i16> %633 to <4 x i32>
  %646 = bitcast <8 x i16> %634 to <4 x i32>
  %647 = shufflevector <4 x i32> %645, <4 x i32> %646, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %648 = bitcast <4 x i32> %647 to <2 x i64>
  %649 = bitcast <8 x i16> %635 to <4 x i32>
  %650 = bitcast <8 x i16> %636 to <4 x i32>
  %651 = shufflevector <4 x i32> %649, <4 x i32> %650, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %652 = bitcast <4 x i32> %651 to <2 x i64>
  %653 = shufflevector <4 x i32> %637, <4 x i32> %638, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %654 = bitcast <4 x i32> %653 to <2 x i64>
  %655 = shufflevector <4 x i32> %641, <4 x i32> %642, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %656 = bitcast <4 x i32> %655 to <2 x i64>
  %657 = shufflevector <4 x i32> %645, <4 x i32> %646, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %658 = bitcast <4 x i32> %657 to <2 x i64>
  %659 = shufflevector <4 x i32> %649, <4 x i32> %650, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %660 = bitcast <4 x i32> %659 to <2 x i64>
  %661 = shufflevector <2 x i64> %640, <2 x i64> %644, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %661, <2 x i64>* %542, align 16
  %662 = shufflevector <2 x i64> %640, <2 x i64> %644, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %662, <2 x i64>* %608, align 16
  %663 = shufflevector <2 x i64> %654, <2 x i64> %656, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %663, <2 x i64>* %612, align 16
  %664 = shufflevector <2 x i64> %654, <2 x i64> %656, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %664, <2 x i64>* %615, align 16
  %665 = shufflevector <2 x i64> %648, <2 x i64> %652, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %665, <2 x i64>* %619, align 16
  %666 = shufflevector <2 x i64> %648, <2 x i64> %652, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %666, <2 x i64>* %622, align 16
  %667 = shufflevector <2 x i64> %658, <2 x i64> %660, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %667, <2 x i64>* %626, align 16
  %668 = shufflevector <2 x i64> %658, <2 x i64> %660, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %668, <2 x i64>* %629, align 16
  %669 = shl nsw i64 %521, 8
  %670 = getelementptr inbounds i32, i32* %1, i64 %669
  %671 = bitcast <2 x i64> %661 to <8 x i16>
  %672 = shufflevector <8 x i16> %671, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %673 = shufflevector <8 x i16> %671, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %674 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %672, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %675 = ashr <4 x i32> %674, <i32 12, i32 12, i32 12, i32 12>
  %676 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %673, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %677 = ashr <4 x i32> %676, <i32 12, i32 12, i32 12, i32 12>
  %678 = bitcast i32* %670 to <4 x i32>*
  store <4 x i32> %675, <4 x i32>* %678, align 16
  %679 = getelementptr inbounds i32, i32* %670, i64 4
  %680 = bitcast i32* %679 to <4 x i32>*
  store <4 x i32> %677, <4 x i32>* %680, align 16
  %681 = bitcast <2 x i64> %662 to <8 x i16>
  %682 = getelementptr inbounds i32, i32* %670, i64 32
  %683 = shufflevector <8 x i16> %681, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %684 = shufflevector <8 x i16> %681, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %685 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %683, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %686 = ashr <4 x i32> %685, <i32 12, i32 12, i32 12, i32 12>
  %687 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %684, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %688 = ashr <4 x i32> %687, <i32 12, i32 12, i32 12, i32 12>
  %689 = bitcast i32* %682 to <4 x i32>*
  store <4 x i32> %686, <4 x i32>* %689, align 16
  %690 = getelementptr inbounds i32, i32* %682, i64 4
  %691 = bitcast i32* %690 to <4 x i32>*
  store <4 x i32> %688, <4 x i32>* %691, align 16
  %692 = bitcast <2 x i64> %663 to <8 x i16>
  %693 = getelementptr inbounds i32, i32* %670, i64 64
  %694 = shufflevector <8 x i16> %692, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %695 = shufflevector <8 x i16> %692, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %696 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %694, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %697 = ashr <4 x i32> %696, <i32 12, i32 12, i32 12, i32 12>
  %698 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %695, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %699 = ashr <4 x i32> %698, <i32 12, i32 12, i32 12, i32 12>
  %700 = bitcast i32* %693 to <4 x i32>*
  store <4 x i32> %697, <4 x i32>* %700, align 16
  %701 = getelementptr inbounds i32, i32* %693, i64 4
  %702 = bitcast i32* %701 to <4 x i32>*
  store <4 x i32> %699, <4 x i32>* %702, align 16
  %703 = bitcast <2 x i64> %664 to <8 x i16>
  %704 = getelementptr inbounds i32, i32* %670, i64 96
  %705 = shufflevector <8 x i16> %703, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %706 = shufflevector <8 x i16> %703, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %707 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %705, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %708 = ashr <4 x i32> %707, <i32 12, i32 12, i32 12, i32 12>
  %709 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %706, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %710 = ashr <4 x i32> %709, <i32 12, i32 12, i32 12, i32 12>
  %711 = bitcast i32* %704 to <4 x i32>*
  store <4 x i32> %708, <4 x i32>* %711, align 16
  %712 = getelementptr inbounds i32, i32* %704, i64 4
  %713 = bitcast i32* %712 to <4 x i32>*
  store <4 x i32> %710, <4 x i32>* %713, align 16
  %714 = bitcast <2 x i64> %665 to <8 x i16>
  %715 = getelementptr inbounds i32, i32* %670, i64 128
  %716 = shufflevector <8 x i16> %714, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %717 = shufflevector <8 x i16> %714, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %718 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %716, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %719 = ashr <4 x i32> %718, <i32 12, i32 12, i32 12, i32 12>
  %720 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %717, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %721 = ashr <4 x i32> %720, <i32 12, i32 12, i32 12, i32 12>
  %722 = bitcast i32* %715 to <4 x i32>*
  store <4 x i32> %719, <4 x i32>* %722, align 16
  %723 = getelementptr inbounds i32, i32* %715, i64 4
  %724 = bitcast i32* %723 to <4 x i32>*
  store <4 x i32> %721, <4 x i32>* %724, align 16
  %725 = bitcast <2 x i64> %666 to <8 x i16>
  %726 = getelementptr inbounds i32, i32* %670, i64 160
  %727 = shufflevector <8 x i16> %725, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %728 = shufflevector <8 x i16> %725, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %729 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %727, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %730 = ashr <4 x i32> %729, <i32 12, i32 12, i32 12, i32 12>
  %731 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %728, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %732 = ashr <4 x i32> %731, <i32 12, i32 12, i32 12, i32 12>
  %733 = bitcast i32* %726 to <4 x i32>*
  store <4 x i32> %730, <4 x i32>* %733, align 16
  %734 = getelementptr inbounds i32, i32* %726, i64 4
  %735 = bitcast i32* %734 to <4 x i32>*
  store <4 x i32> %732, <4 x i32>* %735, align 16
  %736 = bitcast <2 x i64> %667 to <8 x i16>
  %737 = getelementptr inbounds i32, i32* %670, i64 192
  %738 = shufflevector <8 x i16> %736, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %739 = shufflevector <8 x i16> %736, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %740 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %738, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %741 = ashr <4 x i32> %740, <i32 12, i32 12, i32 12, i32 12>
  %742 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %739, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %743 = ashr <4 x i32> %742, <i32 12, i32 12, i32 12, i32 12>
  %744 = bitcast i32* %737 to <4 x i32>*
  store <4 x i32> %741, <4 x i32>* %744, align 16
  %745 = getelementptr inbounds i32, i32* %737, i64 4
  %746 = bitcast i32* %745 to <4 x i32>*
  store <4 x i32> %743, <4 x i32>* %746, align 16
  %747 = load <8 x i16>, <8 x i16>* %630, align 16
  %748 = getelementptr inbounds i32, i32* %670, i64 224
  %749 = shufflevector <8 x i16> %747, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %750 = shufflevector <8 x i16> %747, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %751 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %749, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %752 = ashr <4 x i32> %751, <i32 12, i32 12, i32 12, i32 12>
  %753 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %750, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %754 = ashr <4 x i32> %753, <i32 12, i32 12, i32 12, i32 12>
  %755 = bitcast i32* %748 to <4 x i32>*
  store <4 x i32> %752, <4 x i32>* %755, align 16
  %756 = getelementptr inbounds i32, i32* %748, i64 4
  %757 = bitcast i32* %756 to <4 x i32>*
  store <4 x i32> %754, <4 x i32>* %757, align 16
  %758 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 8
  %759 = bitcast <2 x i64>* %758 to <8 x i16>*
  %760 = load <8 x i16>, <8 x i16>* %759, align 16
  %761 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 9
  %762 = bitcast <2 x i64>* %761 to <8 x i16>*
  %763 = load <8 x i16>, <8 x i16>* %762, align 16
  %764 = shufflevector <8 x i16> %760, <8 x i16> %763, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %765 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 10
  %766 = bitcast <2 x i64>* %765 to <8 x i16>*
  %767 = load <8 x i16>, <8 x i16>* %766, align 16
  %768 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 11
  %769 = bitcast <2 x i64>* %768 to <8 x i16>*
  %770 = load <8 x i16>, <8 x i16>* %769, align 16
  %771 = shufflevector <8 x i16> %767, <8 x i16> %770, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %772 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 12
  %773 = bitcast <2 x i64>* %772 to <8 x i16>*
  %774 = load <8 x i16>, <8 x i16>* %773, align 16
  %775 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 13
  %776 = bitcast <2 x i64>* %775 to <8 x i16>*
  %777 = load <8 x i16>, <8 x i16>* %776, align 16
  %778 = shufflevector <8 x i16> %774, <8 x i16> %777, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %779 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 14
  %780 = bitcast <2 x i64>* %779 to <8 x i16>*
  %781 = load <8 x i16>, <8 x i16>* %780, align 16
  %782 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 15
  %783 = bitcast <2 x i64>* %782 to <8 x i16>*
  %784 = load <8 x i16>, <8 x i16>* %783, align 16
  %785 = shufflevector <8 x i16> %781, <8 x i16> %784, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %786 = shufflevector <8 x i16> %760, <8 x i16> %763, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %787 = shufflevector <8 x i16> %767, <8 x i16> %770, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %788 = shufflevector <8 x i16> %774, <8 x i16> %777, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %789 = shufflevector <8 x i16> %781, <8 x i16> %784, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %790 = bitcast <8 x i16> %764 to <4 x i32>
  %791 = bitcast <8 x i16> %771 to <4 x i32>
  %792 = shufflevector <4 x i32> %790, <4 x i32> %791, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %793 = bitcast <4 x i32> %792 to <2 x i64>
  %794 = bitcast <8 x i16> %778 to <4 x i32>
  %795 = bitcast <8 x i16> %785 to <4 x i32>
  %796 = shufflevector <4 x i32> %794, <4 x i32> %795, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %797 = bitcast <4 x i32> %796 to <2 x i64>
  %798 = bitcast <8 x i16> %786 to <4 x i32>
  %799 = bitcast <8 x i16> %787 to <4 x i32>
  %800 = shufflevector <4 x i32> %798, <4 x i32> %799, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %801 = bitcast <4 x i32> %800 to <2 x i64>
  %802 = bitcast <8 x i16> %788 to <4 x i32>
  %803 = bitcast <8 x i16> %789 to <4 x i32>
  %804 = shufflevector <4 x i32> %802, <4 x i32> %803, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %805 = bitcast <4 x i32> %804 to <2 x i64>
  %806 = shufflevector <4 x i32> %790, <4 x i32> %791, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %807 = bitcast <4 x i32> %806 to <2 x i64>
  %808 = shufflevector <4 x i32> %794, <4 x i32> %795, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %809 = bitcast <4 x i32> %808 to <2 x i64>
  %810 = shufflevector <4 x i32> %798, <4 x i32> %799, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %811 = bitcast <4 x i32> %810 to <2 x i64>
  %812 = shufflevector <4 x i32> %802, <4 x i32> %803, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %813 = bitcast <4 x i32> %812 to <2 x i64>
  %814 = shufflevector <2 x i64> %793, <2 x i64> %797, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %814, <2 x i64>* %758, align 16
  %815 = shufflevector <2 x i64> %793, <2 x i64> %797, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %815, <2 x i64>* %761, align 16
  %816 = shufflevector <2 x i64> %807, <2 x i64> %809, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %816, <2 x i64>* %765, align 16
  %817 = shufflevector <2 x i64> %807, <2 x i64> %809, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %817, <2 x i64>* %768, align 16
  %818 = shufflevector <2 x i64> %801, <2 x i64> %805, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %818, <2 x i64>* %772, align 16
  %819 = shufflevector <2 x i64> %801, <2 x i64> %805, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %819, <2 x i64>* %775, align 16
  %820 = shufflevector <2 x i64> %811, <2 x i64> %813, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %820, <2 x i64>* %779, align 16
  %821 = shufflevector <2 x i64> %811, <2 x i64> %813, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %821, <2 x i64>* %782, align 16
  %822 = getelementptr inbounds i32, i32* %670, i64 8
  %823 = bitcast <2 x i64> %814 to <8 x i16>
  %824 = shufflevector <8 x i16> %823, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %825 = shufflevector <8 x i16> %823, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %826 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %824, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %827 = ashr <4 x i32> %826, <i32 12, i32 12, i32 12, i32 12>
  %828 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %825, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %829 = ashr <4 x i32> %828, <i32 12, i32 12, i32 12, i32 12>
  %830 = bitcast i32* %822 to <4 x i32>*
  store <4 x i32> %827, <4 x i32>* %830, align 16
  %831 = getelementptr inbounds i32, i32* %822, i64 4
  %832 = bitcast i32* %831 to <4 x i32>*
  store <4 x i32> %829, <4 x i32>* %832, align 16
  %833 = bitcast <2 x i64> %815 to <8 x i16>
  %834 = getelementptr inbounds i32, i32* %822, i64 32
  %835 = shufflevector <8 x i16> %833, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %836 = shufflevector <8 x i16> %833, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %837 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %835, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %838 = ashr <4 x i32> %837, <i32 12, i32 12, i32 12, i32 12>
  %839 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %836, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %840 = ashr <4 x i32> %839, <i32 12, i32 12, i32 12, i32 12>
  %841 = bitcast i32* %834 to <4 x i32>*
  store <4 x i32> %838, <4 x i32>* %841, align 16
  %842 = getelementptr inbounds i32, i32* %834, i64 4
  %843 = bitcast i32* %842 to <4 x i32>*
  store <4 x i32> %840, <4 x i32>* %843, align 16
  %844 = bitcast <2 x i64> %816 to <8 x i16>
  %845 = getelementptr inbounds i32, i32* %822, i64 64
  %846 = shufflevector <8 x i16> %844, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %847 = shufflevector <8 x i16> %844, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %848 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %846, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %849 = ashr <4 x i32> %848, <i32 12, i32 12, i32 12, i32 12>
  %850 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %847, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %851 = ashr <4 x i32> %850, <i32 12, i32 12, i32 12, i32 12>
  %852 = bitcast i32* %845 to <4 x i32>*
  store <4 x i32> %849, <4 x i32>* %852, align 16
  %853 = getelementptr inbounds i32, i32* %845, i64 4
  %854 = bitcast i32* %853 to <4 x i32>*
  store <4 x i32> %851, <4 x i32>* %854, align 16
  %855 = bitcast <2 x i64> %817 to <8 x i16>
  %856 = getelementptr inbounds i32, i32* %822, i64 96
  %857 = shufflevector <8 x i16> %855, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %858 = shufflevector <8 x i16> %855, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %859 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %857, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %860 = ashr <4 x i32> %859, <i32 12, i32 12, i32 12, i32 12>
  %861 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %858, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %862 = ashr <4 x i32> %861, <i32 12, i32 12, i32 12, i32 12>
  %863 = bitcast i32* %856 to <4 x i32>*
  store <4 x i32> %860, <4 x i32>* %863, align 16
  %864 = getelementptr inbounds i32, i32* %856, i64 4
  %865 = bitcast i32* %864 to <4 x i32>*
  store <4 x i32> %862, <4 x i32>* %865, align 16
  %866 = bitcast <2 x i64> %818 to <8 x i16>
  %867 = getelementptr inbounds i32, i32* %822, i64 128
  %868 = shufflevector <8 x i16> %866, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %869 = shufflevector <8 x i16> %866, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %870 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %868, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %871 = ashr <4 x i32> %870, <i32 12, i32 12, i32 12, i32 12>
  %872 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %869, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %873 = ashr <4 x i32> %872, <i32 12, i32 12, i32 12, i32 12>
  %874 = bitcast i32* %867 to <4 x i32>*
  store <4 x i32> %871, <4 x i32>* %874, align 16
  %875 = getelementptr inbounds i32, i32* %867, i64 4
  %876 = bitcast i32* %875 to <4 x i32>*
  store <4 x i32> %873, <4 x i32>* %876, align 16
  %877 = bitcast <2 x i64> %819 to <8 x i16>
  %878 = getelementptr inbounds i32, i32* %822, i64 160
  %879 = shufflevector <8 x i16> %877, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %880 = shufflevector <8 x i16> %877, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %881 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %879, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %882 = ashr <4 x i32> %881, <i32 12, i32 12, i32 12, i32 12>
  %883 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %880, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %884 = ashr <4 x i32> %883, <i32 12, i32 12, i32 12, i32 12>
  %885 = bitcast i32* %878 to <4 x i32>*
  store <4 x i32> %882, <4 x i32>* %885, align 16
  %886 = getelementptr inbounds i32, i32* %878, i64 4
  %887 = bitcast i32* %886 to <4 x i32>*
  store <4 x i32> %884, <4 x i32>* %887, align 16
  %888 = bitcast <2 x i64> %820 to <8 x i16>
  %889 = getelementptr inbounds i32, i32* %822, i64 192
  %890 = shufflevector <8 x i16> %888, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %891 = shufflevector <8 x i16> %888, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %892 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %890, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %893 = ashr <4 x i32> %892, <i32 12, i32 12, i32 12, i32 12>
  %894 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %891, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %895 = ashr <4 x i32> %894, <i32 12, i32 12, i32 12, i32 12>
  %896 = bitcast i32* %889 to <4 x i32>*
  store <4 x i32> %893, <4 x i32>* %896, align 16
  %897 = getelementptr inbounds i32, i32* %889, i64 4
  %898 = bitcast i32* %897 to <4 x i32>*
  store <4 x i32> %895, <4 x i32>* %898, align 16
  %899 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 15
  %900 = bitcast <2 x i64>* %899 to <8 x i16>*
  %901 = load <8 x i16>, <8 x i16>* %900, align 16
  %902 = getelementptr inbounds i32, i32* %822, i64 224
  %903 = shufflevector <8 x i16> %901, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %904 = shufflevector <8 x i16> %901, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %905 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %903, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %906 = ashr <4 x i32> %905, <i32 12, i32 12, i32 12, i32 12>
  %907 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %904, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %908 = ashr <4 x i32> %907, <i32 12, i32 12, i32 12, i32 12>
  %909 = bitcast i32* %902 to <4 x i32>*
  store <4 x i32> %906, <4 x i32>* %909, align 16
  %910 = getelementptr inbounds i32, i32* %902, i64 4
  %911 = bitcast i32* %910 to <4 x i32>*
  store <4 x i32> %908, <4 x i32>* %911, align 16
  %912 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 16
  %913 = bitcast <2 x i64>* %912 to <8 x i16>*
  %914 = load <8 x i16>, <8 x i16>* %913, align 16
  %915 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 17
  %916 = bitcast <2 x i64>* %915 to <8 x i16>*
  %917 = load <8 x i16>, <8 x i16>* %916, align 16
  %918 = shufflevector <8 x i16> %914, <8 x i16> %917, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %919 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 18
  %920 = bitcast <2 x i64>* %919 to <8 x i16>*
  %921 = load <8 x i16>, <8 x i16>* %920, align 16
  %922 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 19
  %923 = bitcast <2 x i64>* %922 to <8 x i16>*
  %924 = load <8 x i16>, <8 x i16>* %923, align 16
  %925 = shufflevector <8 x i16> %921, <8 x i16> %924, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %926 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 20
  %927 = bitcast <2 x i64>* %926 to <8 x i16>*
  %928 = load <8 x i16>, <8 x i16>* %927, align 16
  %929 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 21
  %930 = bitcast <2 x i64>* %929 to <8 x i16>*
  %931 = load <8 x i16>, <8 x i16>* %930, align 16
  %932 = shufflevector <8 x i16> %928, <8 x i16> %931, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %933 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 22
  %934 = bitcast <2 x i64>* %933 to <8 x i16>*
  %935 = load <8 x i16>, <8 x i16>* %934, align 16
  %936 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 23
  %937 = bitcast <2 x i64>* %936 to <8 x i16>*
  %938 = load <8 x i16>, <8 x i16>* %937, align 16
  %939 = shufflevector <8 x i16> %935, <8 x i16> %938, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %940 = shufflevector <8 x i16> %914, <8 x i16> %917, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %941 = shufflevector <8 x i16> %921, <8 x i16> %924, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %942 = shufflevector <8 x i16> %928, <8 x i16> %931, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %943 = shufflevector <8 x i16> %935, <8 x i16> %938, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %944 = bitcast <8 x i16> %918 to <4 x i32>
  %945 = bitcast <8 x i16> %925 to <4 x i32>
  %946 = shufflevector <4 x i32> %944, <4 x i32> %945, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %947 = bitcast <4 x i32> %946 to <2 x i64>
  %948 = bitcast <8 x i16> %932 to <4 x i32>
  %949 = bitcast <8 x i16> %939 to <4 x i32>
  %950 = shufflevector <4 x i32> %948, <4 x i32> %949, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %951 = bitcast <4 x i32> %950 to <2 x i64>
  %952 = bitcast <8 x i16> %940 to <4 x i32>
  %953 = bitcast <8 x i16> %941 to <4 x i32>
  %954 = shufflevector <4 x i32> %952, <4 x i32> %953, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %955 = bitcast <4 x i32> %954 to <2 x i64>
  %956 = bitcast <8 x i16> %942 to <4 x i32>
  %957 = bitcast <8 x i16> %943 to <4 x i32>
  %958 = shufflevector <4 x i32> %956, <4 x i32> %957, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %959 = bitcast <4 x i32> %958 to <2 x i64>
  %960 = shufflevector <4 x i32> %944, <4 x i32> %945, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %961 = bitcast <4 x i32> %960 to <2 x i64>
  %962 = shufflevector <4 x i32> %948, <4 x i32> %949, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %963 = bitcast <4 x i32> %962 to <2 x i64>
  %964 = shufflevector <4 x i32> %952, <4 x i32> %953, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %965 = bitcast <4 x i32> %964 to <2 x i64>
  %966 = shufflevector <4 x i32> %956, <4 x i32> %957, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %967 = bitcast <4 x i32> %966 to <2 x i64>
  %968 = shufflevector <2 x i64> %947, <2 x i64> %951, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %968, <2 x i64>* %912, align 16
  %969 = shufflevector <2 x i64> %947, <2 x i64> %951, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %969, <2 x i64>* %915, align 16
  %970 = shufflevector <2 x i64> %961, <2 x i64> %963, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %970, <2 x i64>* %919, align 16
  %971 = shufflevector <2 x i64> %961, <2 x i64> %963, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %971, <2 x i64>* %922, align 16
  %972 = shufflevector <2 x i64> %955, <2 x i64> %959, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %972, <2 x i64>* %926, align 16
  %973 = shufflevector <2 x i64> %955, <2 x i64> %959, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %973, <2 x i64>* %929, align 16
  %974 = shufflevector <2 x i64> %965, <2 x i64> %967, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %974, <2 x i64>* %933, align 16
  %975 = shufflevector <2 x i64> %965, <2 x i64> %967, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %975, <2 x i64>* %936, align 16
  %976 = getelementptr inbounds i32, i32* %670, i64 16
  %977 = bitcast <2 x i64> %968 to <8 x i16>
  %978 = shufflevector <8 x i16> %977, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %979 = shufflevector <8 x i16> %977, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %980 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %978, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %981 = ashr <4 x i32> %980, <i32 12, i32 12, i32 12, i32 12>
  %982 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %979, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %983 = ashr <4 x i32> %982, <i32 12, i32 12, i32 12, i32 12>
  %984 = bitcast i32* %976 to <4 x i32>*
  store <4 x i32> %981, <4 x i32>* %984, align 16
  %985 = getelementptr inbounds i32, i32* %976, i64 4
  %986 = bitcast i32* %985 to <4 x i32>*
  store <4 x i32> %983, <4 x i32>* %986, align 16
  %987 = bitcast <2 x i64> %969 to <8 x i16>
  %988 = getelementptr inbounds i32, i32* %976, i64 32
  %989 = shufflevector <8 x i16> %987, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %990 = shufflevector <8 x i16> %987, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %991 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %989, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %992 = ashr <4 x i32> %991, <i32 12, i32 12, i32 12, i32 12>
  %993 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %990, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %994 = ashr <4 x i32> %993, <i32 12, i32 12, i32 12, i32 12>
  %995 = bitcast i32* %988 to <4 x i32>*
  store <4 x i32> %992, <4 x i32>* %995, align 16
  %996 = getelementptr inbounds i32, i32* %988, i64 4
  %997 = bitcast i32* %996 to <4 x i32>*
  store <4 x i32> %994, <4 x i32>* %997, align 16
  %998 = bitcast <2 x i64> %970 to <8 x i16>
  %999 = getelementptr inbounds i32, i32* %976, i64 64
  %1000 = shufflevector <8 x i16> %998, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1001 = shufflevector <8 x i16> %998, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1002 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1000, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %1003 = ashr <4 x i32> %1002, <i32 12, i32 12, i32 12, i32 12>
  %1004 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1001, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %1005 = ashr <4 x i32> %1004, <i32 12, i32 12, i32 12, i32 12>
  %1006 = bitcast i32* %999 to <4 x i32>*
  store <4 x i32> %1003, <4 x i32>* %1006, align 16
  %1007 = getelementptr inbounds i32, i32* %999, i64 4
  %1008 = bitcast i32* %1007 to <4 x i32>*
  store <4 x i32> %1005, <4 x i32>* %1008, align 16
  %1009 = bitcast <2 x i64> %971 to <8 x i16>
  %1010 = getelementptr inbounds i32, i32* %976, i64 96
  %1011 = shufflevector <8 x i16> %1009, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1012 = shufflevector <8 x i16> %1009, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1013 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1011, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %1014 = ashr <4 x i32> %1013, <i32 12, i32 12, i32 12, i32 12>
  %1015 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1012, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %1016 = ashr <4 x i32> %1015, <i32 12, i32 12, i32 12, i32 12>
  %1017 = bitcast i32* %1010 to <4 x i32>*
  store <4 x i32> %1014, <4 x i32>* %1017, align 16
  %1018 = getelementptr inbounds i32, i32* %1010, i64 4
  %1019 = bitcast i32* %1018 to <4 x i32>*
  store <4 x i32> %1016, <4 x i32>* %1019, align 16
  %1020 = bitcast <2 x i64> %972 to <8 x i16>
  %1021 = getelementptr inbounds i32, i32* %976, i64 128
  %1022 = shufflevector <8 x i16> %1020, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1023 = shufflevector <8 x i16> %1020, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1024 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1022, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %1025 = ashr <4 x i32> %1024, <i32 12, i32 12, i32 12, i32 12>
  %1026 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1023, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %1027 = ashr <4 x i32> %1026, <i32 12, i32 12, i32 12, i32 12>
  %1028 = bitcast i32* %1021 to <4 x i32>*
  store <4 x i32> %1025, <4 x i32>* %1028, align 16
  %1029 = getelementptr inbounds i32, i32* %1021, i64 4
  %1030 = bitcast i32* %1029 to <4 x i32>*
  store <4 x i32> %1027, <4 x i32>* %1030, align 16
  %1031 = bitcast <2 x i64> %973 to <8 x i16>
  %1032 = getelementptr inbounds i32, i32* %976, i64 160
  %1033 = shufflevector <8 x i16> %1031, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1034 = shufflevector <8 x i16> %1031, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1035 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1033, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %1036 = ashr <4 x i32> %1035, <i32 12, i32 12, i32 12, i32 12>
  %1037 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1034, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %1038 = ashr <4 x i32> %1037, <i32 12, i32 12, i32 12, i32 12>
  %1039 = bitcast i32* %1032 to <4 x i32>*
  store <4 x i32> %1036, <4 x i32>* %1039, align 16
  %1040 = getelementptr inbounds i32, i32* %1032, i64 4
  %1041 = bitcast i32* %1040 to <4 x i32>*
  store <4 x i32> %1038, <4 x i32>* %1041, align 16
  %1042 = bitcast <2 x i64> %974 to <8 x i16>
  %1043 = getelementptr inbounds i32, i32* %976, i64 192
  %1044 = shufflevector <8 x i16> %1042, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1045 = shufflevector <8 x i16> %1042, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1046 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1044, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %1047 = ashr <4 x i32> %1046, <i32 12, i32 12, i32 12, i32 12>
  %1048 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1045, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %1049 = ashr <4 x i32> %1048, <i32 12, i32 12, i32 12, i32 12>
  %1050 = bitcast i32* %1043 to <4 x i32>*
  store <4 x i32> %1047, <4 x i32>* %1050, align 16
  %1051 = getelementptr inbounds i32, i32* %1043, i64 4
  %1052 = bitcast i32* %1051 to <4 x i32>*
  store <4 x i32> %1049, <4 x i32>* %1052, align 16
  %1053 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 23
  %1054 = bitcast <2 x i64>* %1053 to <8 x i16>*
  %1055 = load <8 x i16>, <8 x i16>* %1054, align 16
  %1056 = getelementptr inbounds i32, i32* %976, i64 224
  %1057 = shufflevector <8 x i16> %1055, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1058 = shufflevector <8 x i16> %1055, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1059 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1057, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %1060 = ashr <4 x i32> %1059, <i32 12, i32 12, i32 12, i32 12>
  %1061 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1058, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %1062 = ashr <4 x i32> %1061, <i32 12, i32 12, i32 12, i32 12>
  %1063 = bitcast i32* %1056 to <4 x i32>*
  store <4 x i32> %1060, <4 x i32>* %1063, align 16
  %1064 = getelementptr inbounds i32, i32* %1056, i64 4
  %1065 = bitcast i32* %1064 to <4 x i32>*
  store <4 x i32> %1062, <4 x i32>* %1065, align 16
  %1066 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 24
  %1067 = bitcast <2 x i64>* %1066 to <8 x i16>*
  %1068 = load <8 x i16>, <8 x i16>* %1067, align 16
  %1069 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 25
  %1070 = bitcast <2 x i64>* %1069 to <8 x i16>*
  %1071 = load <8 x i16>, <8 x i16>* %1070, align 16
  %1072 = shufflevector <8 x i16> %1068, <8 x i16> %1071, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1073 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 26
  %1074 = bitcast <2 x i64>* %1073 to <8 x i16>*
  %1075 = load <8 x i16>, <8 x i16>* %1074, align 16
  %1076 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 27
  %1077 = bitcast <2 x i64>* %1076 to <8 x i16>*
  %1078 = load <8 x i16>, <8 x i16>* %1077, align 16
  %1079 = shufflevector <8 x i16> %1075, <8 x i16> %1078, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1080 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 28
  %1081 = bitcast <2 x i64>* %1080 to <8 x i16>*
  %1082 = load <8 x i16>, <8 x i16>* %1081, align 16
  %1083 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 29
  %1084 = bitcast <2 x i64>* %1083 to <8 x i16>*
  %1085 = load <8 x i16>, <8 x i16>* %1084, align 16
  %1086 = shufflevector <8 x i16> %1082, <8 x i16> %1085, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1087 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 30
  %1088 = bitcast <2 x i64>* %1087 to <8 x i16>*
  %1089 = load <8 x i16>, <8 x i16>* %1088, align 16
  %1090 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 31
  %1091 = bitcast <2 x i64>* %1090 to <8 x i16>*
  %1092 = load <8 x i16>, <8 x i16>* %1091, align 16
  %1093 = shufflevector <8 x i16> %1089, <8 x i16> %1092, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1094 = shufflevector <8 x i16> %1068, <8 x i16> %1071, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1095 = shufflevector <8 x i16> %1075, <8 x i16> %1078, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1096 = shufflevector <8 x i16> %1082, <8 x i16> %1085, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1097 = shufflevector <8 x i16> %1089, <8 x i16> %1092, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1098 = bitcast <8 x i16> %1072 to <4 x i32>
  %1099 = bitcast <8 x i16> %1079 to <4 x i32>
  %1100 = shufflevector <4 x i32> %1098, <4 x i32> %1099, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1101 = bitcast <4 x i32> %1100 to <2 x i64>
  %1102 = bitcast <8 x i16> %1086 to <4 x i32>
  %1103 = bitcast <8 x i16> %1093 to <4 x i32>
  %1104 = shufflevector <4 x i32> %1102, <4 x i32> %1103, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1105 = bitcast <4 x i32> %1104 to <2 x i64>
  %1106 = bitcast <8 x i16> %1094 to <4 x i32>
  %1107 = bitcast <8 x i16> %1095 to <4 x i32>
  %1108 = shufflevector <4 x i32> %1106, <4 x i32> %1107, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1109 = bitcast <4 x i32> %1108 to <2 x i64>
  %1110 = bitcast <8 x i16> %1096 to <4 x i32>
  %1111 = bitcast <8 x i16> %1097 to <4 x i32>
  %1112 = shufflevector <4 x i32> %1110, <4 x i32> %1111, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1113 = bitcast <4 x i32> %1112 to <2 x i64>
  %1114 = shufflevector <4 x i32> %1098, <4 x i32> %1099, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1115 = bitcast <4 x i32> %1114 to <2 x i64>
  %1116 = shufflevector <4 x i32> %1102, <4 x i32> %1103, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1117 = bitcast <4 x i32> %1116 to <2 x i64>
  %1118 = shufflevector <4 x i32> %1106, <4 x i32> %1107, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1119 = bitcast <4 x i32> %1118 to <2 x i64>
  %1120 = shufflevector <4 x i32> %1110, <4 x i32> %1111, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1121 = bitcast <4 x i32> %1120 to <2 x i64>
  %1122 = shufflevector <2 x i64> %1101, <2 x i64> %1105, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1122, <2 x i64>* %1066, align 16
  %1123 = shufflevector <2 x i64> %1101, <2 x i64> %1105, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1123, <2 x i64>* %1069, align 16
  %1124 = shufflevector <2 x i64> %1115, <2 x i64> %1117, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1124, <2 x i64>* %1073, align 16
  %1125 = shufflevector <2 x i64> %1115, <2 x i64> %1117, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1125, <2 x i64>* %1076, align 16
  %1126 = shufflevector <2 x i64> %1109, <2 x i64> %1113, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1126, <2 x i64>* %1080, align 16
  %1127 = shufflevector <2 x i64> %1109, <2 x i64> %1113, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1127, <2 x i64>* %1083, align 16
  %1128 = shufflevector <2 x i64> %1119, <2 x i64> %1121, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1128, <2 x i64>* %1087, align 16
  %1129 = shufflevector <2 x i64> %1119, <2 x i64> %1121, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1129, <2 x i64>* %1090, align 16
  %1130 = getelementptr inbounds i32, i32* %670, i64 24
  %1131 = bitcast <2 x i64> %1122 to <8 x i16>
  %1132 = shufflevector <8 x i16> %1131, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1133 = shufflevector <8 x i16> %1131, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1134 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1132, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %1135 = ashr <4 x i32> %1134, <i32 12, i32 12, i32 12, i32 12>
  %1136 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1133, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %1137 = ashr <4 x i32> %1136, <i32 12, i32 12, i32 12, i32 12>
  %1138 = bitcast i32* %1130 to <4 x i32>*
  store <4 x i32> %1135, <4 x i32>* %1138, align 16
  %1139 = getelementptr inbounds i32, i32* %1130, i64 4
  %1140 = bitcast i32* %1139 to <4 x i32>*
  store <4 x i32> %1137, <4 x i32>* %1140, align 16
  %1141 = bitcast <2 x i64> %1123 to <8 x i16>
  %1142 = getelementptr inbounds i32, i32* %1130, i64 32
  %1143 = shufflevector <8 x i16> %1141, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1144 = shufflevector <8 x i16> %1141, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1145 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1143, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %1146 = ashr <4 x i32> %1145, <i32 12, i32 12, i32 12, i32 12>
  %1147 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1144, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %1148 = ashr <4 x i32> %1147, <i32 12, i32 12, i32 12, i32 12>
  %1149 = bitcast i32* %1142 to <4 x i32>*
  store <4 x i32> %1146, <4 x i32>* %1149, align 16
  %1150 = getelementptr inbounds i32, i32* %1142, i64 4
  %1151 = bitcast i32* %1150 to <4 x i32>*
  store <4 x i32> %1148, <4 x i32>* %1151, align 16
  %1152 = bitcast <2 x i64> %1124 to <8 x i16>
  %1153 = getelementptr inbounds i32, i32* %1130, i64 64
  %1154 = shufflevector <8 x i16> %1152, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1155 = shufflevector <8 x i16> %1152, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1156 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1154, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %1157 = ashr <4 x i32> %1156, <i32 12, i32 12, i32 12, i32 12>
  %1158 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1155, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %1159 = ashr <4 x i32> %1158, <i32 12, i32 12, i32 12, i32 12>
  %1160 = bitcast i32* %1153 to <4 x i32>*
  store <4 x i32> %1157, <4 x i32>* %1160, align 16
  %1161 = getelementptr inbounds i32, i32* %1153, i64 4
  %1162 = bitcast i32* %1161 to <4 x i32>*
  store <4 x i32> %1159, <4 x i32>* %1162, align 16
  %1163 = bitcast <2 x i64> %1125 to <8 x i16>
  %1164 = getelementptr inbounds i32, i32* %1130, i64 96
  %1165 = shufflevector <8 x i16> %1163, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1166 = shufflevector <8 x i16> %1163, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1167 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1165, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %1168 = ashr <4 x i32> %1167, <i32 12, i32 12, i32 12, i32 12>
  %1169 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1166, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %1170 = ashr <4 x i32> %1169, <i32 12, i32 12, i32 12, i32 12>
  %1171 = bitcast i32* %1164 to <4 x i32>*
  store <4 x i32> %1168, <4 x i32>* %1171, align 16
  %1172 = getelementptr inbounds i32, i32* %1164, i64 4
  %1173 = bitcast i32* %1172 to <4 x i32>*
  store <4 x i32> %1170, <4 x i32>* %1173, align 16
  %1174 = bitcast <2 x i64> %1126 to <8 x i16>
  %1175 = getelementptr inbounds i32, i32* %1130, i64 128
  %1176 = shufflevector <8 x i16> %1174, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1177 = shufflevector <8 x i16> %1174, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1178 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1176, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %1179 = ashr <4 x i32> %1178, <i32 12, i32 12, i32 12, i32 12>
  %1180 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1177, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %1181 = ashr <4 x i32> %1180, <i32 12, i32 12, i32 12, i32 12>
  %1182 = bitcast i32* %1175 to <4 x i32>*
  store <4 x i32> %1179, <4 x i32>* %1182, align 16
  %1183 = getelementptr inbounds i32, i32* %1175, i64 4
  %1184 = bitcast i32* %1183 to <4 x i32>*
  store <4 x i32> %1181, <4 x i32>* %1184, align 16
  %1185 = bitcast <2 x i64> %1127 to <8 x i16>
  %1186 = getelementptr inbounds i32, i32* %1130, i64 160
  %1187 = shufflevector <8 x i16> %1185, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1188 = shufflevector <8 x i16> %1185, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1189 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1187, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %1190 = ashr <4 x i32> %1189, <i32 12, i32 12, i32 12, i32 12>
  %1191 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1188, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %1192 = ashr <4 x i32> %1191, <i32 12, i32 12, i32 12, i32 12>
  %1193 = bitcast i32* %1186 to <4 x i32>*
  store <4 x i32> %1190, <4 x i32>* %1193, align 16
  %1194 = getelementptr inbounds i32, i32* %1186, i64 4
  %1195 = bitcast i32* %1194 to <4 x i32>*
  store <4 x i32> %1192, <4 x i32>* %1195, align 16
  %1196 = bitcast <2 x i64> %1128 to <8 x i16>
  %1197 = getelementptr inbounds i32, i32* %1130, i64 192
  %1198 = shufflevector <8 x i16> %1196, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1199 = shufflevector <8 x i16> %1196, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1200 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1198, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %1201 = ashr <4 x i32> %1200, <i32 12, i32 12, i32 12, i32 12>
  %1202 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1199, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %1203 = ashr <4 x i32> %1202, <i32 12, i32 12, i32 12, i32 12>
  %1204 = bitcast i32* %1197 to <4 x i32>*
  store <4 x i32> %1201, <4 x i32>* %1204, align 16
  %1205 = getelementptr inbounds i32, i32* %1197, i64 4
  %1206 = bitcast i32* %1205 to <4 x i32>*
  store <4 x i32> %1203, <4 x i32>* %1206, align 16
  %1207 = getelementptr inbounds <2 x i64>, <2 x i64>* %542, i64 31
  %1208 = bitcast <2 x i64>* %1207 to <8 x i16>*
  %1209 = load <8 x i16>, <8 x i16>* %1208, align 16
  %1210 = getelementptr inbounds i32, i32* %1130, i64 224
  %1211 = shufflevector <8 x i16> %1209, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1212 = shufflevector <8 x i16> %1209, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1213 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1211, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %1214 = ashr <4 x i32> %1213, <i32 12, i32 12, i32 12, i32 12>
  %1215 = call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %1212, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %1216 = ashr <4 x i32> %1215, <i32 12, i32 12, i32 12, i32 12>
  %1217 = bitcast i32* %1210 to <4 x i32>*
  store <4 x i32> %1214, <4 x i32>* %1217, align 16
  %1218 = getelementptr inbounds i32, i32* %1210, i64 4
  %1219 = bitcast i32* %1218 to <4 x i32>*
  store <4 x i32> %1216, <4 x i32>* %1219, align 16
  %1220 = add nuw nsw i64 %521, 1
  %1221 = icmp eq i64 %1220, 2
  br i1 %1221, label %1223, label %520

1222:                                             ; preds = %5
  tail call void @av1_fwd_txfm2d_32x16_c(i16* %0, i32* %1, i32 %2, i8 zeroext %3, i32 %4) #8
  br label %1223

1223:                                             ; preds = %605, %1222
  call void @llvm.lifetime.end.p0i8(i64 1024, i8* nonnull %9) #8
  call void @llvm.lifetime.end.p0i8(i64 512, i8* nonnull %8) #8
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @av1_lowbd_fwd_txfm2d_32x32_sse2(i16*, i32*, i32, i8 zeroext, i32) #2 {
  %6 = alloca [32 x <2 x i64>], align 16
  %7 = alloca [128 x <2 x i64>], align 16
  %8 = bitcast [32 x <2 x i64>]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 512, i8* nonnull %8) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %8, i8 -86, i64 512, i1 false)
  %9 = bitcast [128 x <2 x i64>]* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 2048, i8* nonnull %9) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 2048, i1 false)
  %10 = load i8*, i8** getelementptr inbounds ([19 x i8*], [19 x i8*]* @av1_fwd_txfm_shift_ls, i64 0, i64 3), align 8
  %11 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_fwd_cos_bit_col, i64 0, i64 3, i64 3), align 1
  %12 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_fwd_cos_bit_row, i64 0, i64 3, i64 3), align 1
  %13 = zext i8 %3 to i64
  %14 = getelementptr inbounds [16 x void (<2 x i64>*, <2 x i64>*, i8)*], [16 x void (<2 x i64>*, <2 x i64>*, i8)*]* @col_txfm8x32_arr, i64 0, i64 %13
  %15 = load void (<2 x i64>*, <2 x i64>*, i8)*, void (<2 x i64>*, <2 x i64>*, i8)** %14, align 8
  %16 = getelementptr inbounds [16 x void (<2 x i64>*, <2 x i64>*, i8)*], [16 x void (<2 x i64>*, <2 x i64>*, i8)*]* @row_txfm8x32_arr, i64 0, i64 %13
  %17 = load void (<2 x i64>*, <2 x i64>*, i8)*, void (<2 x i64>*, <2 x i64>*, i8)** %16, align 8
  %18 = lshr i64 3585, %13
  %19 = and i64 %18, 1
  %20 = icmp eq i64 %19, 0
  br i1 %20, label %1207, label %21

21:                                               ; preds = %5
  switch i8 %3, label %25 [
    i8 6, label %24
    i8 15, label %23
    i8 7, label %23
    i8 5, label %23
    i8 14, label %22
    i8 8, label %22
    i8 4, label %22
  ]

22:                                               ; preds = %21, %21, %21
  br label %25

23:                                               ; preds = %21, %21, %21
  br label %25

24:                                               ; preds = %21
  br label %25

25:                                               ; preds = %21, %22, %23, %24
  %26 = phi i1 [ false, %24 ], [ true, %23 ], [ false, %22 ], [ true, %21 ]
  %27 = phi i32 [ 1, %24 ], [ 1, %23 ], [ 0, %22 ], [ 0, %21 ]
  %28 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 0
  %29 = sext i32 %2 to i64
  %30 = getelementptr inbounds i8, i8* %10, i64 1
  %31 = bitcast [32 x <2 x i64>]* %6 to <8 x i16>*
  %32 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 1
  %33 = bitcast <2 x i64>* %32 to <8 x i16>*
  %34 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 2
  %35 = bitcast <2 x i64>* %34 to <8 x i16>*
  %36 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 3
  %37 = bitcast <2 x i64>* %36 to <8 x i16>*
  %38 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 4
  %39 = bitcast <2 x i64>* %38 to <8 x i16>*
  %40 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 5
  %41 = bitcast <2 x i64>* %40 to <8 x i16>*
  %42 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 6
  %43 = bitcast <2 x i64>* %42 to <8 x i16>*
  %44 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 7
  %45 = bitcast <2 x i64>* %44 to <8 x i16>*
  %46 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 8
  %47 = getelementptr inbounds [128 x <2 x i64>], [128 x <2 x i64>]* %7, i64 0, i64 32
  %48 = bitcast <2 x i64>* %46 to <8 x i16>*
  %49 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 9
  %50 = bitcast <2 x i64>* %49 to <8 x i16>*
  %51 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 10
  %52 = bitcast <2 x i64>* %51 to <8 x i16>*
  %53 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 11
  %54 = bitcast <2 x i64>* %53 to <8 x i16>*
  %55 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 12
  %56 = bitcast <2 x i64>* %55 to <8 x i16>*
  %57 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 13
  %58 = bitcast <2 x i64>* %57 to <8 x i16>*
  %59 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 14
  %60 = bitcast <2 x i64>* %59 to <8 x i16>*
  %61 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 15
  %62 = bitcast <2 x i64>* %61 to <8 x i16>*
  %63 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 16
  %64 = getelementptr inbounds [128 x <2 x i64>], [128 x <2 x i64>]* %7, i64 0, i64 64
  %65 = bitcast <2 x i64>* %63 to <8 x i16>*
  %66 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 17
  %67 = bitcast <2 x i64>* %66 to <8 x i16>*
  %68 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 18
  %69 = bitcast <2 x i64>* %68 to <8 x i16>*
  %70 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 19
  %71 = bitcast <2 x i64>* %70 to <8 x i16>*
  %72 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 20
  %73 = bitcast <2 x i64>* %72 to <8 x i16>*
  %74 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 21
  %75 = bitcast <2 x i64>* %74 to <8 x i16>*
  %76 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 22
  %77 = bitcast <2 x i64>* %76 to <8 x i16>*
  %78 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 23
  %79 = bitcast <2 x i64>* %78 to <8 x i16>*
  %80 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 24
  %81 = getelementptr inbounds [128 x <2 x i64>], [128 x <2 x i64>]* %7, i64 0, i64 96
  %82 = bitcast <2 x i64>* %80 to <8 x i16>*
  %83 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 25
  %84 = bitcast <2 x i64>* %83 to <8 x i16>*
  %85 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 26
  %86 = bitcast <2 x i64>* %85 to <8 x i16>*
  %87 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 27
  %88 = bitcast <2 x i64>* %87 to <8 x i16>*
  %89 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 28
  %90 = bitcast <2 x i64>* %89 to <8 x i16>*
  %91 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 29
  %92 = bitcast <2 x i64>* %91 to <8 x i16>*
  %93 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 30
  %94 = bitcast <2 x i64>* %93 to <8 x i16>*
  %95 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 31
  %96 = bitcast <2 x i64>* %95 to <8 x i16>*
  br label %100

97:                                               ; preds = %278
  %98 = icmp eq i32 %27, 0
  %99 = getelementptr inbounds i8, i8* %10, i64 2
  br label %505

100:                                              ; preds = %278, %25
  %101 = phi i64 [ 0, %25 ], [ %503, %278 ]
  %102 = shl nsw i64 %101, 3
  %103 = getelementptr inbounds i16, i16* %0, i64 %102
  br i1 %26, label %125, label %104

104:                                              ; preds = %100, %104
  %105 = phi i64 [ %123, %104 ], [ 0, %100 ]
  %106 = mul nsw i64 %105, %29
  %107 = getelementptr inbounds i16, i16* %103, i64 %106
  %108 = bitcast i16* %107 to <2 x i64>*
  %109 = load <2 x i64>, <2 x i64>* %108, align 16
  %110 = shl i64 %105, 32
  %111 = sub nuw nsw i64 133143986176, %110
  %112 = ashr exact i64 %111, 32
  %113 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %112
  store <2 x i64> %109, <2 x i64>* %113, align 16
  %114 = or i64 %105, 1
  %115 = mul nsw i64 %114, %29
  %116 = getelementptr inbounds i16, i16* %103, i64 %115
  %117 = bitcast i16* %116 to <2 x i64>*
  %118 = load <2 x i64>, <2 x i64>* %117, align 16
  %119 = shl i64 %114, 32
  %120 = sub nuw nsw i64 133143986176, %119
  %121 = ashr exact i64 %120, 32
  %122 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %121
  store <2 x i64> %118, <2 x i64>* %122, align 16
  %123 = add nuw nsw i64 %105, 2
  %124 = icmp eq i64 %123, 32
  br i1 %124, label %152, label %104

125:                                              ; preds = %100, %125
  %126 = phi i64 [ %150, %125 ], [ 0, %100 ]
  %127 = mul nsw i64 %126, %29
  %128 = getelementptr inbounds i16, i16* %103, i64 %127
  %129 = bitcast i16* %128 to <2 x i64>*
  %130 = load <2 x i64>, <2 x i64>* %129, align 16
  %131 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %126
  store <2 x i64> %130, <2 x i64>* %131, align 16
  %132 = or i64 %126, 1
  %133 = mul nsw i64 %132, %29
  %134 = getelementptr inbounds i16, i16* %103, i64 %133
  %135 = bitcast i16* %134 to <2 x i64>*
  %136 = load <2 x i64>, <2 x i64>* %135, align 16
  %137 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %132
  store <2 x i64> %136, <2 x i64>* %137, align 16
  %138 = or i64 %126, 2
  %139 = mul nsw i64 %138, %29
  %140 = getelementptr inbounds i16, i16* %103, i64 %139
  %141 = bitcast i16* %140 to <2 x i64>*
  %142 = load <2 x i64>, <2 x i64>* %141, align 16
  %143 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %138
  store <2 x i64> %142, <2 x i64>* %143, align 16
  %144 = or i64 %126, 3
  %145 = mul nsw i64 %144, %29
  %146 = getelementptr inbounds i16, i16* %103, i64 %145
  %147 = bitcast i16* %146 to <2 x i64>*
  %148 = load <2 x i64>, <2 x i64>* %147, align 16
  %149 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %144
  store <2 x i64> %148, <2 x i64>* %149, align 16
  %150 = add nuw nsw i64 %126, 4
  %151 = icmp eq i64 %150, 32
  br i1 %151, label %152, label %125

152:                                              ; preds = %104, %125
  %153 = load i8, i8* %10, align 1
  %154 = sext i8 %153 to i32
  %155 = icmp slt i8 %153, 0
  br i1 %155, label %156, label %190

156:                                              ; preds = %152
  %157 = sub nsw i32 0, %154
  %158 = xor i32 %154, -1
  %159 = shl i32 1, %158
  %160 = trunc i32 %159 to i16
  %161 = insertelement <8 x i16> undef, i16 %160, i32 0
  %162 = shufflevector <8 x i16> %161, <8 x i16> undef, <8 x i32> zeroinitializer
  br label %163

163:                                              ; preds = %163, %156
  %164 = phi i64 [ 0, %156 ], [ %188, %163 ]
  %165 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %164
  %166 = bitcast <2 x i64>* %165 to <8 x i16>*
  %167 = load <8 x i16>, <8 x i16>* %166, align 16
  %168 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %167, <8 x i16> %162) #8
  %169 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %168, i32 %157) #8
  store <8 x i16> %169, <8 x i16>* %166, align 16
  %170 = or i64 %164, 1
  %171 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %170
  %172 = bitcast <2 x i64>* %171 to <8 x i16>*
  %173 = load <8 x i16>, <8 x i16>* %172, align 16
  %174 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %173, <8 x i16> %162) #8
  %175 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %174, i32 %157) #8
  store <8 x i16> %175, <8 x i16>* %172, align 16
  %176 = or i64 %164, 2
  %177 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %176
  %178 = bitcast <2 x i64>* %177 to <8 x i16>*
  %179 = load <8 x i16>, <8 x i16>* %178, align 16
  %180 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %179, <8 x i16> %162) #8
  %181 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %180, i32 %157) #8
  store <8 x i16> %181, <8 x i16>* %178, align 16
  %182 = or i64 %164, 3
  %183 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %182
  %184 = bitcast <2 x i64>* %183 to <8 x i16>*
  %185 = load <8 x i16>, <8 x i16>* %184, align 16
  %186 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %185, <8 x i16> %162) #8
  %187 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %186, i32 %157) #8
  store <8 x i16> %187, <8 x i16>* %184, align 16
  %188 = add nuw nsw i64 %164, 4
  %189 = icmp eq i64 %188, 32
  br i1 %189, label %215, label %163

190:                                              ; preds = %152
  %191 = icmp eq i8 %153, 0
  br i1 %191, label %215, label %192

192:                                              ; preds = %190, %192
  %193 = phi i64 [ %213, %192 ], [ 0, %190 ]
  %194 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %193
  %195 = bitcast <2 x i64>* %194 to <8 x i16>*
  %196 = load <8 x i16>, <8 x i16>* %195, align 16
  %197 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %196, i32 %154) #8
  store <8 x i16> %197, <8 x i16>* %195, align 16
  %198 = or i64 %193, 1
  %199 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %198
  %200 = bitcast <2 x i64>* %199 to <8 x i16>*
  %201 = load <8 x i16>, <8 x i16>* %200, align 16
  %202 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %201, i32 %154) #8
  store <8 x i16> %202, <8 x i16>* %200, align 16
  %203 = or i64 %193, 2
  %204 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %203
  %205 = bitcast <2 x i64>* %204 to <8 x i16>*
  %206 = load <8 x i16>, <8 x i16>* %205, align 16
  %207 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %206, i32 %154) #8
  store <8 x i16> %207, <8 x i16>* %205, align 16
  %208 = or i64 %193, 3
  %209 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %208
  %210 = bitcast <2 x i64>* %209 to <8 x i16>*
  %211 = load <8 x i16>, <8 x i16>* %210, align 16
  %212 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %211, i32 %154) #8
  store <8 x i16> %212, <8 x i16>* %210, align 16
  %213 = add nuw nsw i64 %193, 4
  %214 = icmp eq i64 %213, 32
  br i1 %214, label %215, label %192

215:                                              ; preds = %192, %163, %190
  call void %15(<2 x i64>* nonnull %28, <2 x i64>* nonnull %28, i8 signext %11) #8
  %216 = load i8, i8* %30, align 1
  %217 = sext i8 %216 to i32
  %218 = icmp slt i8 %216, 0
  br i1 %218, label %219, label %253

219:                                              ; preds = %215
  %220 = sub nsw i32 0, %217
  %221 = xor i32 %217, -1
  %222 = shl i32 1, %221
  %223 = trunc i32 %222 to i16
  %224 = insertelement <8 x i16> undef, i16 %223, i32 0
  %225 = shufflevector <8 x i16> %224, <8 x i16> undef, <8 x i32> zeroinitializer
  br label %226

226:                                              ; preds = %226, %219
  %227 = phi i64 [ 0, %219 ], [ %251, %226 ]
  %228 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %227
  %229 = bitcast <2 x i64>* %228 to <8 x i16>*
  %230 = load <8 x i16>, <8 x i16>* %229, align 16
  %231 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %230, <8 x i16> %225) #8
  %232 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %231, i32 %220) #8
  store <8 x i16> %232, <8 x i16>* %229, align 16
  %233 = or i64 %227, 1
  %234 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %233
  %235 = bitcast <2 x i64>* %234 to <8 x i16>*
  %236 = load <8 x i16>, <8 x i16>* %235, align 16
  %237 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %236, <8 x i16> %225) #8
  %238 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %237, i32 %220) #8
  store <8 x i16> %238, <8 x i16>* %235, align 16
  %239 = or i64 %227, 2
  %240 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %239
  %241 = bitcast <2 x i64>* %240 to <8 x i16>*
  %242 = load <8 x i16>, <8 x i16>* %241, align 16
  %243 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %242, <8 x i16> %225) #8
  %244 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %243, i32 %220) #8
  store <8 x i16> %244, <8 x i16>* %241, align 16
  %245 = or i64 %227, 3
  %246 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %245
  %247 = bitcast <2 x i64>* %246 to <8 x i16>*
  %248 = load <8 x i16>, <8 x i16>* %247, align 16
  %249 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %248, <8 x i16> %225) #8
  %250 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %249, i32 %220) #8
  store <8 x i16> %250, <8 x i16>* %247, align 16
  %251 = add nuw nsw i64 %227, 4
  %252 = icmp eq i64 %251, 32
  br i1 %252, label %278, label %226

253:                                              ; preds = %215
  %254 = icmp eq i8 %216, 0
  br i1 %254, label %278, label %255

255:                                              ; preds = %253, %255
  %256 = phi i64 [ %276, %255 ], [ 0, %253 ]
  %257 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %256
  %258 = bitcast <2 x i64>* %257 to <8 x i16>*
  %259 = load <8 x i16>, <8 x i16>* %258, align 16
  %260 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %259, i32 %217) #8
  store <8 x i16> %260, <8 x i16>* %258, align 16
  %261 = or i64 %256, 1
  %262 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %261
  %263 = bitcast <2 x i64>* %262 to <8 x i16>*
  %264 = load <8 x i16>, <8 x i16>* %263, align 16
  %265 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %264, i32 %217) #8
  store <8 x i16> %265, <8 x i16>* %263, align 16
  %266 = or i64 %256, 2
  %267 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %266
  %268 = bitcast <2 x i64>* %267 to <8 x i16>*
  %269 = load <8 x i16>, <8 x i16>* %268, align 16
  %270 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %269, i32 %217) #8
  store <8 x i16> %270, <8 x i16>* %268, align 16
  %271 = or i64 %256, 3
  %272 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %271
  %273 = bitcast <2 x i64>* %272 to <8 x i16>*
  %274 = load <8 x i16>, <8 x i16>* %273, align 16
  %275 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %274, i32 %217) #8
  store <8 x i16> %275, <8 x i16>* %273, align 16
  %276 = add nuw nsw i64 %256, 4
  %277 = icmp eq i64 %276, 32
  br i1 %277, label %278, label %255

278:                                              ; preds = %255, %226, %253
  %279 = getelementptr inbounds [128 x <2 x i64>], [128 x <2 x i64>]* %7, i64 0, i64 %102
  %280 = load <8 x i16>, <8 x i16>* %31, align 16
  %281 = load <8 x i16>, <8 x i16>* %33, align 16
  %282 = shufflevector <8 x i16> %280, <8 x i16> %281, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %283 = load <8 x i16>, <8 x i16>* %35, align 16
  %284 = load <8 x i16>, <8 x i16>* %37, align 16
  %285 = shufflevector <8 x i16> %283, <8 x i16> %284, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %286 = load <8 x i16>, <8 x i16>* %39, align 16
  %287 = load <8 x i16>, <8 x i16>* %41, align 16
  %288 = shufflevector <8 x i16> %286, <8 x i16> %287, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %289 = load <8 x i16>, <8 x i16>* %43, align 16
  %290 = load <8 x i16>, <8 x i16>* %45, align 16
  %291 = shufflevector <8 x i16> %289, <8 x i16> %290, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %292 = shufflevector <8 x i16> %280, <8 x i16> %281, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %293 = shufflevector <8 x i16> %283, <8 x i16> %284, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %294 = shufflevector <8 x i16> %286, <8 x i16> %287, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %295 = shufflevector <8 x i16> %289, <8 x i16> %290, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %296 = bitcast <8 x i16> %282 to <4 x i32>
  %297 = bitcast <8 x i16> %285 to <4 x i32>
  %298 = shufflevector <4 x i32> %296, <4 x i32> %297, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %299 = bitcast <4 x i32> %298 to <2 x i64>
  %300 = bitcast <8 x i16> %288 to <4 x i32>
  %301 = bitcast <8 x i16> %291 to <4 x i32>
  %302 = shufflevector <4 x i32> %300, <4 x i32> %301, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %303 = bitcast <4 x i32> %302 to <2 x i64>
  %304 = bitcast <8 x i16> %292 to <4 x i32>
  %305 = bitcast <8 x i16> %293 to <4 x i32>
  %306 = shufflevector <4 x i32> %304, <4 x i32> %305, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %307 = bitcast <4 x i32> %306 to <2 x i64>
  %308 = bitcast <8 x i16> %294 to <4 x i32>
  %309 = bitcast <8 x i16> %295 to <4 x i32>
  %310 = shufflevector <4 x i32> %308, <4 x i32> %309, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %311 = bitcast <4 x i32> %310 to <2 x i64>
  %312 = shufflevector <4 x i32> %296, <4 x i32> %297, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %313 = bitcast <4 x i32> %312 to <2 x i64>
  %314 = shufflevector <4 x i32> %300, <4 x i32> %301, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %315 = bitcast <4 x i32> %314 to <2 x i64>
  %316 = shufflevector <4 x i32> %304, <4 x i32> %305, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %317 = bitcast <4 x i32> %316 to <2 x i64>
  %318 = shufflevector <4 x i32> %308, <4 x i32> %309, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %319 = bitcast <4 x i32> %318 to <2 x i64>
  %320 = shufflevector <2 x i64> %299, <2 x i64> %303, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %320, <2 x i64>* %279, align 16
  %321 = shufflevector <2 x i64> %299, <2 x i64> %303, <2 x i32> <i32 1, i32 3>
  %322 = getelementptr inbounds <2 x i64>, <2 x i64>* %279, i64 1
  store <2 x i64> %321, <2 x i64>* %322, align 16
  %323 = shufflevector <2 x i64> %313, <2 x i64> %315, <2 x i32> <i32 0, i32 2>
  %324 = getelementptr inbounds <2 x i64>, <2 x i64>* %279, i64 2
  store <2 x i64> %323, <2 x i64>* %324, align 16
  %325 = shufflevector <2 x i64> %313, <2 x i64> %315, <2 x i32> <i32 1, i32 3>
  %326 = getelementptr inbounds <2 x i64>, <2 x i64>* %279, i64 3
  store <2 x i64> %325, <2 x i64>* %326, align 16
  %327 = shufflevector <2 x i64> %307, <2 x i64> %311, <2 x i32> <i32 0, i32 2>
  %328 = getelementptr inbounds <2 x i64>, <2 x i64>* %279, i64 4
  store <2 x i64> %327, <2 x i64>* %328, align 16
  %329 = shufflevector <2 x i64> %307, <2 x i64> %311, <2 x i32> <i32 1, i32 3>
  %330 = getelementptr inbounds <2 x i64>, <2 x i64>* %279, i64 5
  store <2 x i64> %329, <2 x i64>* %330, align 16
  %331 = shufflevector <2 x i64> %317, <2 x i64> %319, <2 x i32> <i32 0, i32 2>
  %332 = getelementptr inbounds <2 x i64>, <2 x i64>* %279, i64 6
  store <2 x i64> %331, <2 x i64>* %332, align 16
  %333 = shufflevector <2 x i64> %317, <2 x i64> %319, <2 x i32> <i32 1, i32 3>
  %334 = getelementptr inbounds <2 x i64>, <2 x i64>* %279, i64 7
  store <2 x i64> %333, <2 x i64>* %334, align 16
  %335 = getelementptr inbounds <2 x i64>, <2 x i64>* %47, i64 %102
  %336 = load <8 x i16>, <8 x i16>* %48, align 16
  %337 = load <8 x i16>, <8 x i16>* %50, align 16
  %338 = shufflevector <8 x i16> %336, <8 x i16> %337, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %339 = load <8 x i16>, <8 x i16>* %52, align 16
  %340 = load <8 x i16>, <8 x i16>* %54, align 16
  %341 = shufflevector <8 x i16> %339, <8 x i16> %340, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %342 = load <8 x i16>, <8 x i16>* %56, align 16
  %343 = load <8 x i16>, <8 x i16>* %58, align 16
  %344 = shufflevector <8 x i16> %342, <8 x i16> %343, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %345 = load <8 x i16>, <8 x i16>* %60, align 16
  %346 = load <8 x i16>, <8 x i16>* %62, align 16
  %347 = shufflevector <8 x i16> %345, <8 x i16> %346, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %348 = shufflevector <8 x i16> %336, <8 x i16> %337, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %349 = shufflevector <8 x i16> %339, <8 x i16> %340, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %350 = shufflevector <8 x i16> %342, <8 x i16> %343, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %351 = shufflevector <8 x i16> %345, <8 x i16> %346, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %352 = bitcast <8 x i16> %338 to <4 x i32>
  %353 = bitcast <8 x i16> %341 to <4 x i32>
  %354 = shufflevector <4 x i32> %352, <4 x i32> %353, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %355 = bitcast <4 x i32> %354 to <2 x i64>
  %356 = bitcast <8 x i16> %344 to <4 x i32>
  %357 = bitcast <8 x i16> %347 to <4 x i32>
  %358 = shufflevector <4 x i32> %356, <4 x i32> %357, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %359 = bitcast <4 x i32> %358 to <2 x i64>
  %360 = bitcast <8 x i16> %348 to <4 x i32>
  %361 = bitcast <8 x i16> %349 to <4 x i32>
  %362 = shufflevector <4 x i32> %360, <4 x i32> %361, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %363 = bitcast <4 x i32> %362 to <2 x i64>
  %364 = bitcast <8 x i16> %350 to <4 x i32>
  %365 = bitcast <8 x i16> %351 to <4 x i32>
  %366 = shufflevector <4 x i32> %364, <4 x i32> %365, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %367 = bitcast <4 x i32> %366 to <2 x i64>
  %368 = shufflevector <4 x i32> %352, <4 x i32> %353, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %369 = bitcast <4 x i32> %368 to <2 x i64>
  %370 = shufflevector <4 x i32> %356, <4 x i32> %357, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %371 = bitcast <4 x i32> %370 to <2 x i64>
  %372 = shufflevector <4 x i32> %360, <4 x i32> %361, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %373 = bitcast <4 x i32> %372 to <2 x i64>
  %374 = shufflevector <4 x i32> %364, <4 x i32> %365, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %375 = bitcast <4 x i32> %374 to <2 x i64>
  %376 = shufflevector <2 x i64> %355, <2 x i64> %359, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %376, <2 x i64>* %335, align 16
  %377 = shufflevector <2 x i64> %355, <2 x i64> %359, <2 x i32> <i32 1, i32 3>
  %378 = getelementptr inbounds <2 x i64>, <2 x i64>* %335, i64 1
  store <2 x i64> %377, <2 x i64>* %378, align 16
  %379 = shufflevector <2 x i64> %369, <2 x i64> %371, <2 x i32> <i32 0, i32 2>
  %380 = getelementptr inbounds <2 x i64>, <2 x i64>* %335, i64 2
  store <2 x i64> %379, <2 x i64>* %380, align 16
  %381 = shufflevector <2 x i64> %369, <2 x i64> %371, <2 x i32> <i32 1, i32 3>
  %382 = getelementptr inbounds <2 x i64>, <2 x i64>* %335, i64 3
  store <2 x i64> %381, <2 x i64>* %382, align 16
  %383 = shufflevector <2 x i64> %363, <2 x i64> %367, <2 x i32> <i32 0, i32 2>
  %384 = getelementptr inbounds <2 x i64>, <2 x i64>* %335, i64 4
  store <2 x i64> %383, <2 x i64>* %384, align 16
  %385 = shufflevector <2 x i64> %363, <2 x i64> %367, <2 x i32> <i32 1, i32 3>
  %386 = getelementptr inbounds <2 x i64>, <2 x i64>* %335, i64 5
  store <2 x i64> %385, <2 x i64>* %386, align 16
  %387 = shufflevector <2 x i64> %373, <2 x i64> %375, <2 x i32> <i32 0, i32 2>
  %388 = getelementptr inbounds <2 x i64>, <2 x i64>* %335, i64 6
  store <2 x i64> %387, <2 x i64>* %388, align 16
  %389 = shufflevector <2 x i64> %373, <2 x i64> %375, <2 x i32> <i32 1, i32 3>
  %390 = getelementptr inbounds <2 x i64>, <2 x i64>* %335, i64 7
  store <2 x i64> %389, <2 x i64>* %390, align 16
  %391 = getelementptr inbounds <2 x i64>, <2 x i64>* %64, i64 %102
  %392 = load <8 x i16>, <8 x i16>* %65, align 16
  %393 = load <8 x i16>, <8 x i16>* %67, align 16
  %394 = shufflevector <8 x i16> %392, <8 x i16> %393, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %395 = load <8 x i16>, <8 x i16>* %69, align 16
  %396 = load <8 x i16>, <8 x i16>* %71, align 16
  %397 = shufflevector <8 x i16> %395, <8 x i16> %396, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %398 = load <8 x i16>, <8 x i16>* %73, align 16
  %399 = load <8 x i16>, <8 x i16>* %75, align 16
  %400 = shufflevector <8 x i16> %398, <8 x i16> %399, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %401 = load <8 x i16>, <8 x i16>* %77, align 16
  %402 = load <8 x i16>, <8 x i16>* %79, align 16
  %403 = shufflevector <8 x i16> %401, <8 x i16> %402, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %404 = shufflevector <8 x i16> %392, <8 x i16> %393, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %405 = shufflevector <8 x i16> %395, <8 x i16> %396, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %406 = shufflevector <8 x i16> %398, <8 x i16> %399, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %407 = shufflevector <8 x i16> %401, <8 x i16> %402, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %408 = bitcast <8 x i16> %394 to <4 x i32>
  %409 = bitcast <8 x i16> %397 to <4 x i32>
  %410 = shufflevector <4 x i32> %408, <4 x i32> %409, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %411 = bitcast <4 x i32> %410 to <2 x i64>
  %412 = bitcast <8 x i16> %400 to <4 x i32>
  %413 = bitcast <8 x i16> %403 to <4 x i32>
  %414 = shufflevector <4 x i32> %412, <4 x i32> %413, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %415 = bitcast <4 x i32> %414 to <2 x i64>
  %416 = bitcast <8 x i16> %404 to <4 x i32>
  %417 = bitcast <8 x i16> %405 to <4 x i32>
  %418 = shufflevector <4 x i32> %416, <4 x i32> %417, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %419 = bitcast <4 x i32> %418 to <2 x i64>
  %420 = bitcast <8 x i16> %406 to <4 x i32>
  %421 = bitcast <8 x i16> %407 to <4 x i32>
  %422 = shufflevector <4 x i32> %420, <4 x i32> %421, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %423 = bitcast <4 x i32> %422 to <2 x i64>
  %424 = shufflevector <4 x i32> %408, <4 x i32> %409, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %425 = bitcast <4 x i32> %424 to <2 x i64>
  %426 = shufflevector <4 x i32> %412, <4 x i32> %413, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %427 = bitcast <4 x i32> %426 to <2 x i64>
  %428 = shufflevector <4 x i32> %416, <4 x i32> %417, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %429 = bitcast <4 x i32> %428 to <2 x i64>
  %430 = shufflevector <4 x i32> %420, <4 x i32> %421, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %431 = bitcast <4 x i32> %430 to <2 x i64>
  %432 = shufflevector <2 x i64> %411, <2 x i64> %415, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %432, <2 x i64>* %391, align 16
  %433 = shufflevector <2 x i64> %411, <2 x i64> %415, <2 x i32> <i32 1, i32 3>
  %434 = getelementptr inbounds <2 x i64>, <2 x i64>* %391, i64 1
  store <2 x i64> %433, <2 x i64>* %434, align 16
  %435 = shufflevector <2 x i64> %425, <2 x i64> %427, <2 x i32> <i32 0, i32 2>
  %436 = getelementptr inbounds <2 x i64>, <2 x i64>* %391, i64 2
  store <2 x i64> %435, <2 x i64>* %436, align 16
  %437 = shufflevector <2 x i64> %425, <2 x i64> %427, <2 x i32> <i32 1, i32 3>
  %438 = getelementptr inbounds <2 x i64>, <2 x i64>* %391, i64 3
  store <2 x i64> %437, <2 x i64>* %438, align 16
  %439 = shufflevector <2 x i64> %419, <2 x i64> %423, <2 x i32> <i32 0, i32 2>
  %440 = getelementptr inbounds <2 x i64>, <2 x i64>* %391, i64 4
  store <2 x i64> %439, <2 x i64>* %440, align 16
  %441 = shufflevector <2 x i64> %419, <2 x i64> %423, <2 x i32> <i32 1, i32 3>
  %442 = getelementptr inbounds <2 x i64>, <2 x i64>* %391, i64 5
  store <2 x i64> %441, <2 x i64>* %442, align 16
  %443 = shufflevector <2 x i64> %429, <2 x i64> %431, <2 x i32> <i32 0, i32 2>
  %444 = getelementptr inbounds <2 x i64>, <2 x i64>* %391, i64 6
  store <2 x i64> %443, <2 x i64>* %444, align 16
  %445 = shufflevector <2 x i64> %429, <2 x i64> %431, <2 x i32> <i32 1, i32 3>
  %446 = getelementptr inbounds <2 x i64>, <2 x i64>* %391, i64 7
  store <2 x i64> %445, <2 x i64>* %446, align 16
  %447 = getelementptr inbounds <2 x i64>, <2 x i64>* %81, i64 %102
  %448 = load <8 x i16>, <8 x i16>* %82, align 16
  %449 = load <8 x i16>, <8 x i16>* %84, align 16
  %450 = shufflevector <8 x i16> %448, <8 x i16> %449, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %451 = load <8 x i16>, <8 x i16>* %86, align 16
  %452 = load <8 x i16>, <8 x i16>* %88, align 16
  %453 = shufflevector <8 x i16> %451, <8 x i16> %452, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %454 = load <8 x i16>, <8 x i16>* %90, align 16
  %455 = load <8 x i16>, <8 x i16>* %92, align 16
  %456 = shufflevector <8 x i16> %454, <8 x i16> %455, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %457 = load <8 x i16>, <8 x i16>* %94, align 16
  %458 = load <8 x i16>, <8 x i16>* %96, align 16
  %459 = shufflevector <8 x i16> %457, <8 x i16> %458, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %460 = shufflevector <8 x i16> %448, <8 x i16> %449, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %461 = shufflevector <8 x i16> %451, <8 x i16> %452, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %462 = shufflevector <8 x i16> %454, <8 x i16> %455, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %463 = shufflevector <8 x i16> %457, <8 x i16> %458, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %464 = bitcast <8 x i16> %450 to <4 x i32>
  %465 = bitcast <8 x i16> %453 to <4 x i32>
  %466 = shufflevector <4 x i32> %464, <4 x i32> %465, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %467 = bitcast <4 x i32> %466 to <2 x i64>
  %468 = bitcast <8 x i16> %456 to <4 x i32>
  %469 = bitcast <8 x i16> %459 to <4 x i32>
  %470 = shufflevector <4 x i32> %468, <4 x i32> %469, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %471 = bitcast <4 x i32> %470 to <2 x i64>
  %472 = bitcast <8 x i16> %460 to <4 x i32>
  %473 = bitcast <8 x i16> %461 to <4 x i32>
  %474 = shufflevector <4 x i32> %472, <4 x i32> %473, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %475 = bitcast <4 x i32> %474 to <2 x i64>
  %476 = bitcast <8 x i16> %462 to <4 x i32>
  %477 = bitcast <8 x i16> %463 to <4 x i32>
  %478 = shufflevector <4 x i32> %476, <4 x i32> %477, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %479 = bitcast <4 x i32> %478 to <2 x i64>
  %480 = shufflevector <4 x i32> %464, <4 x i32> %465, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %481 = bitcast <4 x i32> %480 to <2 x i64>
  %482 = shufflevector <4 x i32> %468, <4 x i32> %469, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %483 = bitcast <4 x i32> %482 to <2 x i64>
  %484 = shufflevector <4 x i32> %472, <4 x i32> %473, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %485 = bitcast <4 x i32> %484 to <2 x i64>
  %486 = shufflevector <4 x i32> %476, <4 x i32> %477, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %487 = bitcast <4 x i32> %486 to <2 x i64>
  %488 = shufflevector <2 x i64> %467, <2 x i64> %471, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %488, <2 x i64>* %447, align 16
  %489 = shufflevector <2 x i64> %467, <2 x i64> %471, <2 x i32> <i32 1, i32 3>
  %490 = getelementptr inbounds <2 x i64>, <2 x i64>* %447, i64 1
  store <2 x i64> %489, <2 x i64>* %490, align 16
  %491 = shufflevector <2 x i64> %481, <2 x i64> %483, <2 x i32> <i32 0, i32 2>
  %492 = getelementptr inbounds <2 x i64>, <2 x i64>* %447, i64 2
  store <2 x i64> %491, <2 x i64>* %492, align 16
  %493 = shufflevector <2 x i64> %481, <2 x i64> %483, <2 x i32> <i32 1, i32 3>
  %494 = getelementptr inbounds <2 x i64>, <2 x i64>* %447, i64 3
  store <2 x i64> %493, <2 x i64>* %494, align 16
  %495 = shufflevector <2 x i64> %475, <2 x i64> %479, <2 x i32> <i32 0, i32 2>
  %496 = getelementptr inbounds <2 x i64>, <2 x i64>* %447, i64 4
  store <2 x i64> %495, <2 x i64>* %496, align 16
  %497 = shufflevector <2 x i64> %475, <2 x i64> %479, <2 x i32> <i32 1, i32 3>
  %498 = getelementptr inbounds <2 x i64>, <2 x i64>* %447, i64 5
  store <2 x i64> %497, <2 x i64>* %498, align 16
  %499 = shufflevector <2 x i64> %485, <2 x i64> %487, <2 x i32> <i32 0, i32 2>
  %500 = getelementptr inbounds <2 x i64>, <2 x i64>* %447, i64 6
  store <2 x i64> %499, <2 x i64>* %500, align 16
  %501 = shufflevector <2 x i64> %485, <2 x i64> %487, <2 x i32> <i32 1, i32 3>
  %502 = getelementptr inbounds <2 x i64>, <2 x i64>* %447, i64 7
  store <2 x i64> %501, <2 x i64>* %502, align 16
  %503 = add nuw nsw i64 %101, 1
  %504 = icmp eq i64 %503, 4
  br i1 %504, label %97, label %100

505:                                              ; preds = %590, %97
  %506 = phi i64 [ 0, %97 ], [ %1205, %590 ]
  %507 = shl nsw i64 %506, 5
  %508 = getelementptr inbounds [128 x <2 x i64>], [128 x <2 x i64>]* %7, i64 0, i64 %507
  br i1 %98, label %526, label %509

509:                                              ; preds = %505, %509
  %510 = phi i64 [ %524, %509 ], [ 0, %505 ]
  %511 = getelementptr inbounds <2 x i64>, <2 x i64>* %508, i64 %510
  %512 = load <2 x i64>, <2 x i64>* %511, align 16
  %513 = shl i64 %510, 32
  %514 = sub nuw nsw i64 133143986176, %513
  %515 = ashr exact i64 %514, 32
  %516 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %515
  store <2 x i64> %512, <2 x i64>* %516, align 16
  %517 = or i64 %510, 1
  %518 = getelementptr inbounds <2 x i64>, <2 x i64>* %508, i64 %517
  %519 = load <2 x i64>, <2 x i64>* %518, align 16
  %520 = shl i64 %517, 32
  %521 = sub nuw nsw i64 133143986176, %520
  %522 = ashr exact i64 %521, 32
  %523 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %6, i64 0, i64 %522
  store <2 x i64> %519, <2 x i64>* %523, align 16
  %524 = add nuw nsw i64 %510, 2
  %525 = icmp eq i64 %524, 32
  br i1 %525, label %526, label %509

526:                                              ; preds = %509, %505
  %527 = phi <2 x i64>* [ %508, %505 ], [ %28, %509 ]
  call void %17(<2 x i64>* %527, <2 x i64>* %527, i8 signext %12) #8
  %528 = load i8, i8* %99, align 1
  %529 = sext i8 %528 to i32
  %530 = icmp slt i8 %528, 0
  br i1 %530, label %531, label %565

531:                                              ; preds = %526
  %532 = sub nsw i32 0, %529
  %533 = xor i32 %529, -1
  %534 = shl i32 1, %533
  %535 = trunc i32 %534 to i16
  %536 = insertelement <8 x i16> undef, i16 %535, i32 0
  %537 = shufflevector <8 x i16> %536, <8 x i16> undef, <8 x i32> zeroinitializer
  br label %538

538:                                              ; preds = %538, %531
  %539 = phi i64 [ 0, %531 ], [ %563, %538 ]
  %540 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 %539
  %541 = bitcast <2 x i64>* %540 to <8 x i16>*
  %542 = load <8 x i16>, <8 x i16>* %541, align 16
  %543 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %542, <8 x i16> %537) #8
  %544 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %543, i32 %532) #8
  store <8 x i16> %544, <8 x i16>* %541, align 16
  %545 = or i64 %539, 1
  %546 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 %545
  %547 = bitcast <2 x i64>* %546 to <8 x i16>*
  %548 = load <8 x i16>, <8 x i16>* %547, align 16
  %549 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %548, <8 x i16> %537) #8
  %550 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %549, i32 %532) #8
  store <8 x i16> %550, <8 x i16>* %547, align 16
  %551 = or i64 %539, 2
  %552 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 %551
  %553 = bitcast <2 x i64>* %552 to <8 x i16>*
  %554 = load <8 x i16>, <8 x i16>* %553, align 16
  %555 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %554, <8 x i16> %537) #8
  %556 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %555, i32 %532) #8
  store <8 x i16> %556, <8 x i16>* %553, align 16
  %557 = or i64 %539, 3
  %558 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 %557
  %559 = bitcast <2 x i64>* %558 to <8 x i16>*
  %560 = load <8 x i16>, <8 x i16>* %559, align 16
  %561 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %560, <8 x i16> %537) #8
  %562 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %561, i32 %532) #8
  store <8 x i16> %562, <8 x i16>* %559, align 16
  %563 = add nuw nsw i64 %539, 4
  %564 = icmp eq i64 %563, 32
  br i1 %564, label %590, label %538

565:                                              ; preds = %526
  %566 = icmp eq i8 %528, 0
  br i1 %566, label %590, label %567

567:                                              ; preds = %565, %567
  %568 = phi i64 [ %588, %567 ], [ 0, %565 ]
  %569 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 %568
  %570 = bitcast <2 x i64>* %569 to <8 x i16>*
  %571 = load <8 x i16>, <8 x i16>* %570, align 16
  %572 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %571, i32 %529) #8
  store <8 x i16> %572, <8 x i16>* %570, align 16
  %573 = or i64 %568, 1
  %574 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 %573
  %575 = bitcast <2 x i64>* %574 to <8 x i16>*
  %576 = load <8 x i16>, <8 x i16>* %575, align 16
  %577 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %576, i32 %529) #8
  store <8 x i16> %577, <8 x i16>* %575, align 16
  %578 = or i64 %568, 2
  %579 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 %578
  %580 = bitcast <2 x i64>* %579 to <8 x i16>*
  %581 = load <8 x i16>, <8 x i16>* %580, align 16
  %582 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %581, i32 %529) #8
  store <8 x i16> %582, <8 x i16>* %580, align 16
  %583 = or i64 %568, 3
  %584 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 %583
  %585 = bitcast <2 x i64>* %584 to <8 x i16>*
  %586 = load <8 x i16>, <8 x i16>* %585, align 16
  %587 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %586, i32 %529) #8
  store <8 x i16> %587, <8 x i16>* %585, align 16
  %588 = add nuw nsw i64 %568, 4
  %589 = icmp eq i64 %588, 32
  br i1 %589, label %590, label %567

590:                                              ; preds = %567, %538, %565
  %591 = bitcast <2 x i64>* %527 to <8 x i16>*
  %592 = load <8 x i16>, <8 x i16>* %591, align 16
  %593 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 1
  %594 = bitcast <2 x i64>* %593 to <8 x i16>*
  %595 = load <8 x i16>, <8 x i16>* %594, align 16
  %596 = shufflevector <8 x i16> %592, <8 x i16> %595, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %597 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 2
  %598 = bitcast <2 x i64>* %597 to <8 x i16>*
  %599 = load <8 x i16>, <8 x i16>* %598, align 16
  %600 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 3
  %601 = bitcast <2 x i64>* %600 to <8 x i16>*
  %602 = load <8 x i16>, <8 x i16>* %601, align 16
  %603 = shufflevector <8 x i16> %599, <8 x i16> %602, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %604 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 4
  %605 = bitcast <2 x i64>* %604 to <8 x i16>*
  %606 = load <8 x i16>, <8 x i16>* %605, align 16
  %607 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 5
  %608 = bitcast <2 x i64>* %607 to <8 x i16>*
  %609 = load <8 x i16>, <8 x i16>* %608, align 16
  %610 = shufflevector <8 x i16> %606, <8 x i16> %609, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %611 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 6
  %612 = bitcast <2 x i64>* %611 to <8 x i16>*
  %613 = load <8 x i16>, <8 x i16>* %612, align 16
  %614 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 7
  %615 = bitcast <2 x i64>* %614 to <8 x i16>*
  %616 = load <8 x i16>, <8 x i16>* %615, align 16
  %617 = shufflevector <8 x i16> %613, <8 x i16> %616, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %618 = shufflevector <8 x i16> %592, <8 x i16> %595, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %619 = shufflevector <8 x i16> %599, <8 x i16> %602, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %620 = shufflevector <8 x i16> %606, <8 x i16> %609, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %621 = shufflevector <8 x i16> %613, <8 x i16> %616, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %622 = bitcast <8 x i16> %596 to <4 x i32>
  %623 = bitcast <8 x i16> %603 to <4 x i32>
  %624 = shufflevector <4 x i32> %622, <4 x i32> %623, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %625 = bitcast <4 x i32> %624 to <2 x i64>
  %626 = bitcast <8 x i16> %610 to <4 x i32>
  %627 = bitcast <8 x i16> %617 to <4 x i32>
  %628 = shufflevector <4 x i32> %626, <4 x i32> %627, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %629 = bitcast <4 x i32> %628 to <2 x i64>
  %630 = bitcast <8 x i16> %618 to <4 x i32>
  %631 = bitcast <8 x i16> %619 to <4 x i32>
  %632 = shufflevector <4 x i32> %630, <4 x i32> %631, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %633 = bitcast <4 x i32> %632 to <2 x i64>
  %634 = bitcast <8 x i16> %620 to <4 x i32>
  %635 = bitcast <8 x i16> %621 to <4 x i32>
  %636 = shufflevector <4 x i32> %634, <4 x i32> %635, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %637 = bitcast <4 x i32> %636 to <2 x i64>
  %638 = shufflevector <4 x i32> %622, <4 x i32> %623, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %639 = bitcast <4 x i32> %638 to <2 x i64>
  %640 = shufflevector <4 x i32> %626, <4 x i32> %627, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %641 = bitcast <4 x i32> %640 to <2 x i64>
  %642 = shufflevector <4 x i32> %630, <4 x i32> %631, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %643 = bitcast <4 x i32> %642 to <2 x i64>
  %644 = shufflevector <4 x i32> %634, <4 x i32> %635, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %645 = bitcast <4 x i32> %644 to <2 x i64>
  %646 = shufflevector <2 x i64> %625, <2 x i64> %629, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %646, <2 x i64>* %527, align 16
  %647 = shufflevector <2 x i64> %625, <2 x i64> %629, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %647, <2 x i64>* %593, align 16
  %648 = shufflevector <2 x i64> %639, <2 x i64> %641, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %648, <2 x i64>* %597, align 16
  %649 = shufflevector <2 x i64> %639, <2 x i64> %641, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %649, <2 x i64>* %600, align 16
  %650 = shufflevector <2 x i64> %633, <2 x i64> %637, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %650, <2 x i64>* %604, align 16
  %651 = shufflevector <2 x i64> %633, <2 x i64> %637, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %651, <2 x i64>* %607, align 16
  %652 = shufflevector <2 x i64> %643, <2 x i64> %645, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %652, <2 x i64>* %611, align 16
  %653 = shufflevector <2 x i64> %643, <2 x i64> %645, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %653, <2 x i64>* %614, align 16
  %654 = shl nsw i64 %506, 8
  %655 = getelementptr inbounds i32, i32* %1, i64 %654
  %656 = bitcast <2 x i64> %646 to <8 x i16>
  %657 = shufflevector <8 x i16> %656, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %658 = shufflevector <8 x i16> %656, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %659 = bitcast <8 x i16> %657 to <4 x i32>
  %660 = ashr <4 x i32> %659, <i32 16, i32 16, i32 16, i32 16>
  %661 = bitcast <8 x i16> %658 to <4 x i32>
  %662 = ashr <4 x i32> %661, <i32 16, i32 16, i32 16, i32 16>
  %663 = bitcast i32* %655 to <4 x i32>*
  store <4 x i32> %660, <4 x i32>* %663, align 16
  %664 = getelementptr inbounds i32, i32* %655, i64 4
  %665 = bitcast i32* %664 to <4 x i32>*
  store <4 x i32> %662, <4 x i32>* %665, align 16
  %666 = bitcast <2 x i64> %647 to <8 x i16>
  %667 = getelementptr inbounds i32, i32* %655, i64 32
  %668 = shufflevector <8 x i16> %666, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %669 = shufflevector <8 x i16> %666, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %670 = bitcast <8 x i16> %668 to <4 x i32>
  %671 = ashr <4 x i32> %670, <i32 16, i32 16, i32 16, i32 16>
  %672 = bitcast <8 x i16> %669 to <4 x i32>
  %673 = ashr <4 x i32> %672, <i32 16, i32 16, i32 16, i32 16>
  %674 = bitcast i32* %667 to <4 x i32>*
  store <4 x i32> %671, <4 x i32>* %674, align 16
  %675 = getelementptr inbounds i32, i32* %667, i64 4
  %676 = bitcast i32* %675 to <4 x i32>*
  store <4 x i32> %673, <4 x i32>* %676, align 16
  %677 = bitcast <2 x i64> %648 to <8 x i16>
  %678 = getelementptr inbounds i32, i32* %655, i64 64
  %679 = shufflevector <8 x i16> %677, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %680 = shufflevector <8 x i16> %677, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %681 = bitcast <8 x i16> %679 to <4 x i32>
  %682 = ashr <4 x i32> %681, <i32 16, i32 16, i32 16, i32 16>
  %683 = bitcast <8 x i16> %680 to <4 x i32>
  %684 = ashr <4 x i32> %683, <i32 16, i32 16, i32 16, i32 16>
  %685 = bitcast i32* %678 to <4 x i32>*
  store <4 x i32> %682, <4 x i32>* %685, align 16
  %686 = getelementptr inbounds i32, i32* %678, i64 4
  %687 = bitcast i32* %686 to <4 x i32>*
  store <4 x i32> %684, <4 x i32>* %687, align 16
  %688 = bitcast <2 x i64> %649 to <8 x i16>
  %689 = getelementptr inbounds i32, i32* %655, i64 96
  %690 = shufflevector <8 x i16> %688, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %691 = shufflevector <8 x i16> %688, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %692 = bitcast <8 x i16> %690 to <4 x i32>
  %693 = ashr <4 x i32> %692, <i32 16, i32 16, i32 16, i32 16>
  %694 = bitcast <8 x i16> %691 to <4 x i32>
  %695 = ashr <4 x i32> %694, <i32 16, i32 16, i32 16, i32 16>
  %696 = bitcast i32* %689 to <4 x i32>*
  store <4 x i32> %693, <4 x i32>* %696, align 16
  %697 = getelementptr inbounds i32, i32* %689, i64 4
  %698 = bitcast i32* %697 to <4 x i32>*
  store <4 x i32> %695, <4 x i32>* %698, align 16
  %699 = bitcast <2 x i64> %650 to <8 x i16>
  %700 = getelementptr inbounds i32, i32* %655, i64 128
  %701 = shufflevector <8 x i16> %699, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %702 = shufflevector <8 x i16> %699, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %703 = bitcast <8 x i16> %701 to <4 x i32>
  %704 = ashr <4 x i32> %703, <i32 16, i32 16, i32 16, i32 16>
  %705 = bitcast <8 x i16> %702 to <4 x i32>
  %706 = ashr <4 x i32> %705, <i32 16, i32 16, i32 16, i32 16>
  %707 = bitcast i32* %700 to <4 x i32>*
  store <4 x i32> %704, <4 x i32>* %707, align 16
  %708 = getelementptr inbounds i32, i32* %700, i64 4
  %709 = bitcast i32* %708 to <4 x i32>*
  store <4 x i32> %706, <4 x i32>* %709, align 16
  %710 = bitcast <2 x i64> %651 to <8 x i16>
  %711 = getelementptr inbounds i32, i32* %655, i64 160
  %712 = shufflevector <8 x i16> %710, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %713 = shufflevector <8 x i16> %710, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %714 = bitcast <8 x i16> %712 to <4 x i32>
  %715 = ashr <4 x i32> %714, <i32 16, i32 16, i32 16, i32 16>
  %716 = bitcast <8 x i16> %713 to <4 x i32>
  %717 = ashr <4 x i32> %716, <i32 16, i32 16, i32 16, i32 16>
  %718 = bitcast i32* %711 to <4 x i32>*
  store <4 x i32> %715, <4 x i32>* %718, align 16
  %719 = getelementptr inbounds i32, i32* %711, i64 4
  %720 = bitcast i32* %719 to <4 x i32>*
  store <4 x i32> %717, <4 x i32>* %720, align 16
  %721 = bitcast <2 x i64> %652 to <8 x i16>
  %722 = getelementptr inbounds i32, i32* %655, i64 192
  %723 = shufflevector <8 x i16> %721, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %724 = shufflevector <8 x i16> %721, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %725 = bitcast <8 x i16> %723 to <4 x i32>
  %726 = ashr <4 x i32> %725, <i32 16, i32 16, i32 16, i32 16>
  %727 = bitcast <8 x i16> %724 to <4 x i32>
  %728 = ashr <4 x i32> %727, <i32 16, i32 16, i32 16, i32 16>
  %729 = bitcast i32* %722 to <4 x i32>*
  store <4 x i32> %726, <4 x i32>* %729, align 16
  %730 = getelementptr inbounds i32, i32* %722, i64 4
  %731 = bitcast i32* %730 to <4 x i32>*
  store <4 x i32> %728, <4 x i32>* %731, align 16
  %732 = load <8 x i16>, <8 x i16>* %615, align 16
  %733 = getelementptr inbounds i32, i32* %655, i64 224
  %734 = shufflevector <8 x i16> %732, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %735 = shufflevector <8 x i16> %732, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %736 = bitcast <8 x i16> %734 to <4 x i32>
  %737 = ashr <4 x i32> %736, <i32 16, i32 16, i32 16, i32 16>
  %738 = bitcast <8 x i16> %735 to <4 x i32>
  %739 = ashr <4 x i32> %738, <i32 16, i32 16, i32 16, i32 16>
  %740 = bitcast i32* %733 to <4 x i32>*
  store <4 x i32> %737, <4 x i32>* %740, align 16
  %741 = getelementptr inbounds i32, i32* %733, i64 4
  %742 = bitcast i32* %741 to <4 x i32>*
  store <4 x i32> %739, <4 x i32>* %742, align 16
  %743 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 8
  %744 = bitcast <2 x i64>* %743 to <8 x i16>*
  %745 = load <8 x i16>, <8 x i16>* %744, align 16
  %746 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 9
  %747 = bitcast <2 x i64>* %746 to <8 x i16>*
  %748 = load <8 x i16>, <8 x i16>* %747, align 16
  %749 = shufflevector <8 x i16> %745, <8 x i16> %748, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %750 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 10
  %751 = bitcast <2 x i64>* %750 to <8 x i16>*
  %752 = load <8 x i16>, <8 x i16>* %751, align 16
  %753 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 11
  %754 = bitcast <2 x i64>* %753 to <8 x i16>*
  %755 = load <8 x i16>, <8 x i16>* %754, align 16
  %756 = shufflevector <8 x i16> %752, <8 x i16> %755, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %757 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 12
  %758 = bitcast <2 x i64>* %757 to <8 x i16>*
  %759 = load <8 x i16>, <8 x i16>* %758, align 16
  %760 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 13
  %761 = bitcast <2 x i64>* %760 to <8 x i16>*
  %762 = load <8 x i16>, <8 x i16>* %761, align 16
  %763 = shufflevector <8 x i16> %759, <8 x i16> %762, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %764 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 14
  %765 = bitcast <2 x i64>* %764 to <8 x i16>*
  %766 = load <8 x i16>, <8 x i16>* %765, align 16
  %767 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 15
  %768 = bitcast <2 x i64>* %767 to <8 x i16>*
  %769 = load <8 x i16>, <8 x i16>* %768, align 16
  %770 = shufflevector <8 x i16> %766, <8 x i16> %769, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %771 = shufflevector <8 x i16> %745, <8 x i16> %748, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %772 = shufflevector <8 x i16> %752, <8 x i16> %755, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %773 = shufflevector <8 x i16> %759, <8 x i16> %762, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %774 = shufflevector <8 x i16> %766, <8 x i16> %769, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %775 = bitcast <8 x i16> %749 to <4 x i32>
  %776 = bitcast <8 x i16> %756 to <4 x i32>
  %777 = shufflevector <4 x i32> %775, <4 x i32> %776, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %778 = bitcast <4 x i32> %777 to <2 x i64>
  %779 = bitcast <8 x i16> %763 to <4 x i32>
  %780 = bitcast <8 x i16> %770 to <4 x i32>
  %781 = shufflevector <4 x i32> %779, <4 x i32> %780, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %782 = bitcast <4 x i32> %781 to <2 x i64>
  %783 = bitcast <8 x i16> %771 to <4 x i32>
  %784 = bitcast <8 x i16> %772 to <4 x i32>
  %785 = shufflevector <4 x i32> %783, <4 x i32> %784, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %786 = bitcast <4 x i32> %785 to <2 x i64>
  %787 = bitcast <8 x i16> %773 to <4 x i32>
  %788 = bitcast <8 x i16> %774 to <4 x i32>
  %789 = shufflevector <4 x i32> %787, <4 x i32> %788, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %790 = bitcast <4 x i32> %789 to <2 x i64>
  %791 = shufflevector <4 x i32> %775, <4 x i32> %776, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %792 = bitcast <4 x i32> %791 to <2 x i64>
  %793 = shufflevector <4 x i32> %779, <4 x i32> %780, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %794 = bitcast <4 x i32> %793 to <2 x i64>
  %795 = shufflevector <4 x i32> %783, <4 x i32> %784, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %796 = bitcast <4 x i32> %795 to <2 x i64>
  %797 = shufflevector <4 x i32> %787, <4 x i32> %788, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %798 = bitcast <4 x i32> %797 to <2 x i64>
  %799 = shufflevector <2 x i64> %778, <2 x i64> %782, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %799, <2 x i64>* %743, align 16
  %800 = shufflevector <2 x i64> %778, <2 x i64> %782, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %800, <2 x i64>* %746, align 16
  %801 = shufflevector <2 x i64> %792, <2 x i64> %794, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %801, <2 x i64>* %750, align 16
  %802 = shufflevector <2 x i64> %792, <2 x i64> %794, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %802, <2 x i64>* %753, align 16
  %803 = shufflevector <2 x i64> %786, <2 x i64> %790, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %803, <2 x i64>* %757, align 16
  %804 = shufflevector <2 x i64> %786, <2 x i64> %790, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %804, <2 x i64>* %760, align 16
  %805 = shufflevector <2 x i64> %796, <2 x i64> %798, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %805, <2 x i64>* %764, align 16
  %806 = shufflevector <2 x i64> %796, <2 x i64> %798, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %806, <2 x i64>* %767, align 16
  %807 = getelementptr inbounds i32, i32* %655, i64 8
  %808 = bitcast <2 x i64> %799 to <8 x i16>
  %809 = shufflevector <8 x i16> %808, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %810 = shufflevector <8 x i16> %808, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %811 = bitcast <8 x i16> %809 to <4 x i32>
  %812 = ashr <4 x i32> %811, <i32 16, i32 16, i32 16, i32 16>
  %813 = bitcast <8 x i16> %810 to <4 x i32>
  %814 = ashr <4 x i32> %813, <i32 16, i32 16, i32 16, i32 16>
  %815 = bitcast i32* %807 to <4 x i32>*
  store <4 x i32> %812, <4 x i32>* %815, align 16
  %816 = getelementptr inbounds i32, i32* %807, i64 4
  %817 = bitcast i32* %816 to <4 x i32>*
  store <4 x i32> %814, <4 x i32>* %817, align 16
  %818 = bitcast <2 x i64> %800 to <8 x i16>
  %819 = getelementptr inbounds i32, i32* %807, i64 32
  %820 = shufflevector <8 x i16> %818, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %821 = shufflevector <8 x i16> %818, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %822 = bitcast <8 x i16> %820 to <4 x i32>
  %823 = ashr <4 x i32> %822, <i32 16, i32 16, i32 16, i32 16>
  %824 = bitcast <8 x i16> %821 to <4 x i32>
  %825 = ashr <4 x i32> %824, <i32 16, i32 16, i32 16, i32 16>
  %826 = bitcast i32* %819 to <4 x i32>*
  store <4 x i32> %823, <4 x i32>* %826, align 16
  %827 = getelementptr inbounds i32, i32* %819, i64 4
  %828 = bitcast i32* %827 to <4 x i32>*
  store <4 x i32> %825, <4 x i32>* %828, align 16
  %829 = bitcast <2 x i64> %801 to <8 x i16>
  %830 = getelementptr inbounds i32, i32* %807, i64 64
  %831 = shufflevector <8 x i16> %829, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %832 = shufflevector <8 x i16> %829, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %833 = bitcast <8 x i16> %831 to <4 x i32>
  %834 = ashr <4 x i32> %833, <i32 16, i32 16, i32 16, i32 16>
  %835 = bitcast <8 x i16> %832 to <4 x i32>
  %836 = ashr <4 x i32> %835, <i32 16, i32 16, i32 16, i32 16>
  %837 = bitcast i32* %830 to <4 x i32>*
  store <4 x i32> %834, <4 x i32>* %837, align 16
  %838 = getelementptr inbounds i32, i32* %830, i64 4
  %839 = bitcast i32* %838 to <4 x i32>*
  store <4 x i32> %836, <4 x i32>* %839, align 16
  %840 = bitcast <2 x i64> %802 to <8 x i16>
  %841 = getelementptr inbounds i32, i32* %807, i64 96
  %842 = shufflevector <8 x i16> %840, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %843 = shufflevector <8 x i16> %840, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %844 = bitcast <8 x i16> %842 to <4 x i32>
  %845 = ashr <4 x i32> %844, <i32 16, i32 16, i32 16, i32 16>
  %846 = bitcast <8 x i16> %843 to <4 x i32>
  %847 = ashr <4 x i32> %846, <i32 16, i32 16, i32 16, i32 16>
  %848 = bitcast i32* %841 to <4 x i32>*
  store <4 x i32> %845, <4 x i32>* %848, align 16
  %849 = getelementptr inbounds i32, i32* %841, i64 4
  %850 = bitcast i32* %849 to <4 x i32>*
  store <4 x i32> %847, <4 x i32>* %850, align 16
  %851 = bitcast <2 x i64> %803 to <8 x i16>
  %852 = getelementptr inbounds i32, i32* %807, i64 128
  %853 = shufflevector <8 x i16> %851, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %854 = shufflevector <8 x i16> %851, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %855 = bitcast <8 x i16> %853 to <4 x i32>
  %856 = ashr <4 x i32> %855, <i32 16, i32 16, i32 16, i32 16>
  %857 = bitcast <8 x i16> %854 to <4 x i32>
  %858 = ashr <4 x i32> %857, <i32 16, i32 16, i32 16, i32 16>
  %859 = bitcast i32* %852 to <4 x i32>*
  store <4 x i32> %856, <4 x i32>* %859, align 16
  %860 = getelementptr inbounds i32, i32* %852, i64 4
  %861 = bitcast i32* %860 to <4 x i32>*
  store <4 x i32> %858, <4 x i32>* %861, align 16
  %862 = bitcast <2 x i64> %804 to <8 x i16>
  %863 = getelementptr inbounds i32, i32* %807, i64 160
  %864 = shufflevector <8 x i16> %862, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %865 = shufflevector <8 x i16> %862, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %866 = bitcast <8 x i16> %864 to <4 x i32>
  %867 = ashr <4 x i32> %866, <i32 16, i32 16, i32 16, i32 16>
  %868 = bitcast <8 x i16> %865 to <4 x i32>
  %869 = ashr <4 x i32> %868, <i32 16, i32 16, i32 16, i32 16>
  %870 = bitcast i32* %863 to <4 x i32>*
  store <4 x i32> %867, <4 x i32>* %870, align 16
  %871 = getelementptr inbounds i32, i32* %863, i64 4
  %872 = bitcast i32* %871 to <4 x i32>*
  store <4 x i32> %869, <4 x i32>* %872, align 16
  %873 = bitcast <2 x i64> %805 to <8 x i16>
  %874 = getelementptr inbounds i32, i32* %807, i64 192
  %875 = shufflevector <8 x i16> %873, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %876 = shufflevector <8 x i16> %873, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %877 = bitcast <8 x i16> %875 to <4 x i32>
  %878 = ashr <4 x i32> %877, <i32 16, i32 16, i32 16, i32 16>
  %879 = bitcast <8 x i16> %876 to <4 x i32>
  %880 = ashr <4 x i32> %879, <i32 16, i32 16, i32 16, i32 16>
  %881 = bitcast i32* %874 to <4 x i32>*
  store <4 x i32> %878, <4 x i32>* %881, align 16
  %882 = getelementptr inbounds i32, i32* %874, i64 4
  %883 = bitcast i32* %882 to <4 x i32>*
  store <4 x i32> %880, <4 x i32>* %883, align 16
  %884 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 15
  %885 = bitcast <2 x i64>* %884 to <8 x i16>*
  %886 = load <8 x i16>, <8 x i16>* %885, align 16
  %887 = getelementptr inbounds i32, i32* %807, i64 224
  %888 = shufflevector <8 x i16> %886, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %889 = shufflevector <8 x i16> %886, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %890 = bitcast <8 x i16> %888 to <4 x i32>
  %891 = ashr <4 x i32> %890, <i32 16, i32 16, i32 16, i32 16>
  %892 = bitcast <8 x i16> %889 to <4 x i32>
  %893 = ashr <4 x i32> %892, <i32 16, i32 16, i32 16, i32 16>
  %894 = bitcast i32* %887 to <4 x i32>*
  store <4 x i32> %891, <4 x i32>* %894, align 16
  %895 = getelementptr inbounds i32, i32* %887, i64 4
  %896 = bitcast i32* %895 to <4 x i32>*
  store <4 x i32> %893, <4 x i32>* %896, align 16
  %897 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 16
  %898 = bitcast <2 x i64>* %897 to <8 x i16>*
  %899 = load <8 x i16>, <8 x i16>* %898, align 16
  %900 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 17
  %901 = bitcast <2 x i64>* %900 to <8 x i16>*
  %902 = load <8 x i16>, <8 x i16>* %901, align 16
  %903 = shufflevector <8 x i16> %899, <8 x i16> %902, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %904 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 18
  %905 = bitcast <2 x i64>* %904 to <8 x i16>*
  %906 = load <8 x i16>, <8 x i16>* %905, align 16
  %907 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 19
  %908 = bitcast <2 x i64>* %907 to <8 x i16>*
  %909 = load <8 x i16>, <8 x i16>* %908, align 16
  %910 = shufflevector <8 x i16> %906, <8 x i16> %909, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %911 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 20
  %912 = bitcast <2 x i64>* %911 to <8 x i16>*
  %913 = load <8 x i16>, <8 x i16>* %912, align 16
  %914 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 21
  %915 = bitcast <2 x i64>* %914 to <8 x i16>*
  %916 = load <8 x i16>, <8 x i16>* %915, align 16
  %917 = shufflevector <8 x i16> %913, <8 x i16> %916, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %918 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 22
  %919 = bitcast <2 x i64>* %918 to <8 x i16>*
  %920 = load <8 x i16>, <8 x i16>* %919, align 16
  %921 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 23
  %922 = bitcast <2 x i64>* %921 to <8 x i16>*
  %923 = load <8 x i16>, <8 x i16>* %922, align 16
  %924 = shufflevector <8 x i16> %920, <8 x i16> %923, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %925 = shufflevector <8 x i16> %899, <8 x i16> %902, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %926 = shufflevector <8 x i16> %906, <8 x i16> %909, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %927 = shufflevector <8 x i16> %913, <8 x i16> %916, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %928 = shufflevector <8 x i16> %920, <8 x i16> %923, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %929 = bitcast <8 x i16> %903 to <4 x i32>
  %930 = bitcast <8 x i16> %910 to <4 x i32>
  %931 = shufflevector <4 x i32> %929, <4 x i32> %930, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %932 = bitcast <4 x i32> %931 to <2 x i64>
  %933 = bitcast <8 x i16> %917 to <4 x i32>
  %934 = bitcast <8 x i16> %924 to <4 x i32>
  %935 = shufflevector <4 x i32> %933, <4 x i32> %934, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %936 = bitcast <4 x i32> %935 to <2 x i64>
  %937 = bitcast <8 x i16> %925 to <4 x i32>
  %938 = bitcast <8 x i16> %926 to <4 x i32>
  %939 = shufflevector <4 x i32> %937, <4 x i32> %938, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %940 = bitcast <4 x i32> %939 to <2 x i64>
  %941 = bitcast <8 x i16> %927 to <4 x i32>
  %942 = bitcast <8 x i16> %928 to <4 x i32>
  %943 = shufflevector <4 x i32> %941, <4 x i32> %942, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %944 = bitcast <4 x i32> %943 to <2 x i64>
  %945 = shufflevector <4 x i32> %929, <4 x i32> %930, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %946 = bitcast <4 x i32> %945 to <2 x i64>
  %947 = shufflevector <4 x i32> %933, <4 x i32> %934, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %948 = bitcast <4 x i32> %947 to <2 x i64>
  %949 = shufflevector <4 x i32> %937, <4 x i32> %938, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %950 = bitcast <4 x i32> %949 to <2 x i64>
  %951 = shufflevector <4 x i32> %941, <4 x i32> %942, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %952 = bitcast <4 x i32> %951 to <2 x i64>
  %953 = shufflevector <2 x i64> %932, <2 x i64> %936, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %953, <2 x i64>* %897, align 16
  %954 = shufflevector <2 x i64> %932, <2 x i64> %936, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %954, <2 x i64>* %900, align 16
  %955 = shufflevector <2 x i64> %946, <2 x i64> %948, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %955, <2 x i64>* %904, align 16
  %956 = shufflevector <2 x i64> %946, <2 x i64> %948, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %956, <2 x i64>* %907, align 16
  %957 = shufflevector <2 x i64> %940, <2 x i64> %944, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %957, <2 x i64>* %911, align 16
  %958 = shufflevector <2 x i64> %940, <2 x i64> %944, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %958, <2 x i64>* %914, align 16
  %959 = shufflevector <2 x i64> %950, <2 x i64> %952, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %959, <2 x i64>* %918, align 16
  %960 = shufflevector <2 x i64> %950, <2 x i64> %952, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %960, <2 x i64>* %921, align 16
  %961 = getelementptr inbounds i32, i32* %655, i64 16
  %962 = bitcast <2 x i64> %953 to <8 x i16>
  %963 = shufflevector <8 x i16> %962, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %964 = shufflevector <8 x i16> %962, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %965 = bitcast <8 x i16> %963 to <4 x i32>
  %966 = ashr <4 x i32> %965, <i32 16, i32 16, i32 16, i32 16>
  %967 = bitcast <8 x i16> %964 to <4 x i32>
  %968 = ashr <4 x i32> %967, <i32 16, i32 16, i32 16, i32 16>
  %969 = bitcast i32* %961 to <4 x i32>*
  store <4 x i32> %966, <4 x i32>* %969, align 16
  %970 = getelementptr inbounds i32, i32* %961, i64 4
  %971 = bitcast i32* %970 to <4 x i32>*
  store <4 x i32> %968, <4 x i32>* %971, align 16
  %972 = bitcast <2 x i64> %954 to <8 x i16>
  %973 = getelementptr inbounds i32, i32* %961, i64 32
  %974 = shufflevector <8 x i16> %972, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %975 = shufflevector <8 x i16> %972, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %976 = bitcast <8 x i16> %974 to <4 x i32>
  %977 = ashr <4 x i32> %976, <i32 16, i32 16, i32 16, i32 16>
  %978 = bitcast <8 x i16> %975 to <4 x i32>
  %979 = ashr <4 x i32> %978, <i32 16, i32 16, i32 16, i32 16>
  %980 = bitcast i32* %973 to <4 x i32>*
  store <4 x i32> %977, <4 x i32>* %980, align 16
  %981 = getelementptr inbounds i32, i32* %973, i64 4
  %982 = bitcast i32* %981 to <4 x i32>*
  store <4 x i32> %979, <4 x i32>* %982, align 16
  %983 = bitcast <2 x i64> %955 to <8 x i16>
  %984 = getelementptr inbounds i32, i32* %961, i64 64
  %985 = shufflevector <8 x i16> %983, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %986 = shufflevector <8 x i16> %983, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %987 = bitcast <8 x i16> %985 to <4 x i32>
  %988 = ashr <4 x i32> %987, <i32 16, i32 16, i32 16, i32 16>
  %989 = bitcast <8 x i16> %986 to <4 x i32>
  %990 = ashr <4 x i32> %989, <i32 16, i32 16, i32 16, i32 16>
  %991 = bitcast i32* %984 to <4 x i32>*
  store <4 x i32> %988, <4 x i32>* %991, align 16
  %992 = getelementptr inbounds i32, i32* %984, i64 4
  %993 = bitcast i32* %992 to <4 x i32>*
  store <4 x i32> %990, <4 x i32>* %993, align 16
  %994 = bitcast <2 x i64> %956 to <8 x i16>
  %995 = getelementptr inbounds i32, i32* %961, i64 96
  %996 = shufflevector <8 x i16> %994, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %997 = shufflevector <8 x i16> %994, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %998 = bitcast <8 x i16> %996 to <4 x i32>
  %999 = ashr <4 x i32> %998, <i32 16, i32 16, i32 16, i32 16>
  %1000 = bitcast <8 x i16> %997 to <4 x i32>
  %1001 = ashr <4 x i32> %1000, <i32 16, i32 16, i32 16, i32 16>
  %1002 = bitcast i32* %995 to <4 x i32>*
  store <4 x i32> %999, <4 x i32>* %1002, align 16
  %1003 = getelementptr inbounds i32, i32* %995, i64 4
  %1004 = bitcast i32* %1003 to <4 x i32>*
  store <4 x i32> %1001, <4 x i32>* %1004, align 16
  %1005 = bitcast <2 x i64> %957 to <8 x i16>
  %1006 = getelementptr inbounds i32, i32* %961, i64 128
  %1007 = shufflevector <8 x i16> %1005, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %1008 = shufflevector <8 x i16> %1005, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %1009 = bitcast <8 x i16> %1007 to <4 x i32>
  %1010 = ashr <4 x i32> %1009, <i32 16, i32 16, i32 16, i32 16>
  %1011 = bitcast <8 x i16> %1008 to <4 x i32>
  %1012 = ashr <4 x i32> %1011, <i32 16, i32 16, i32 16, i32 16>
  %1013 = bitcast i32* %1006 to <4 x i32>*
  store <4 x i32> %1010, <4 x i32>* %1013, align 16
  %1014 = getelementptr inbounds i32, i32* %1006, i64 4
  %1015 = bitcast i32* %1014 to <4 x i32>*
  store <4 x i32> %1012, <4 x i32>* %1015, align 16
  %1016 = bitcast <2 x i64> %958 to <8 x i16>
  %1017 = getelementptr inbounds i32, i32* %961, i64 160
  %1018 = shufflevector <8 x i16> %1016, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %1019 = shufflevector <8 x i16> %1016, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %1020 = bitcast <8 x i16> %1018 to <4 x i32>
  %1021 = ashr <4 x i32> %1020, <i32 16, i32 16, i32 16, i32 16>
  %1022 = bitcast <8 x i16> %1019 to <4 x i32>
  %1023 = ashr <4 x i32> %1022, <i32 16, i32 16, i32 16, i32 16>
  %1024 = bitcast i32* %1017 to <4 x i32>*
  store <4 x i32> %1021, <4 x i32>* %1024, align 16
  %1025 = getelementptr inbounds i32, i32* %1017, i64 4
  %1026 = bitcast i32* %1025 to <4 x i32>*
  store <4 x i32> %1023, <4 x i32>* %1026, align 16
  %1027 = bitcast <2 x i64> %959 to <8 x i16>
  %1028 = getelementptr inbounds i32, i32* %961, i64 192
  %1029 = shufflevector <8 x i16> %1027, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %1030 = shufflevector <8 x i16> %1027, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %1031 = bitcast <8 x i16> %1029 to <4 x i32>
  %1032 = ashr <4 x i32> %1031, <i32 16, i32 16, i32 16, i32 16>
  %1033 = bitcast <8 x i16> %1030 to <4 x i32>
  %1034 = ashr <4 x i32> %1033, <i32 16, i32 16, i32 16, i32 16>
  %1035 = bitcast i32* %1028 to <4 x i32>*
  store <4 x i32> %1032, <4 x i32>* %1035, align 16
  %1036 = getelementptr inbounds i32, i32* %1028, i64 4
  %1037 = bitcast i32* %1036 to <4 x i32>*
  store <4 x i32> %1034, <4 x i32>* %1037, align 16
  %1038 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 23
  %1039 = bitcast <2 x i64>* %1038 to <8 x i16>*
  %1040 = load <8 x i16>, <8 x i16>* %1039, align 16
  %1041 = getelementptr inbounds i32, i32* %961, i64 224
  %1042 = shufflevector <8 x i16> %1040, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %1043 = shufflevector <8 x i16> %1040, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %1044 = bitcast <8 x i16> %1042 to <4 x i32>
  %1045 = ashr <4 x i32> %1044, <i32 16, i32 16, i32 16, i32 16>
  %1046 = bitcast <8 x i16> %1043 to <4 x i32>
  %1047 = ashr <4 x i32> %1046, <i32 16, i32 16, i32 16, i32 16>
  %1048 = bitcast i32* %1041 to <4 x i32>*
  store <4 x i32> %1045, <4 x i32>* %1048, align 16
  %1049 = getelementptr inbounds i32, i32* %1041, i64 4
  %1050 = bitcast i32* %1049 to <4 x i32>*
  store <4 x i32> %1047, <4 x i32>* %1050, align 16
  %1051 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 24
  %1052 = bitcast <2 x i64>* %1051 to <8 x i16>*
  %1053 = load <8 x i16>, <8 x i16>* %1052, align 16
  %1054 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 25
  %1055 = bitcast <2 x i64>* %1054 to <8 x i16>*
  %1056 = load <8 x i16>, <8 x i16>* %1055, align 16
  %1057 = shufflevector <8 x i16> %1053, <8 x i16> %1056, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1058 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 26
  %1059 = bitcast <2 x i64>* %1058 to <8 x i16>*
  %1060 = load <8 x i16>, <8 x i16>* %1059, align 16
  %1061 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 27
  %1062 = bitcast <2 x i64>* %1061 to <8 x i16>*
  %1063 = load <8 x i16>, <8 x i16>* %1062, align 16
  %1064 = shufflevector <8 x i16> %1060, <8 x i16> %1063, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1065 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 28
  %1066 = bitcast <2 x i64>* %1065 to <8 x i16>*
  %1067 = load <8 x i16>, <8 x i16>* %1066, align 16
  %1068 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 29
  %1069 = bitcast <2 x i64>* %1068 to <8 x i16>*
  %1070 = load <8 x i16>, <8 x i16>* %1069, align 16
  %1071 = shufflevector <8 x i16> %1067, <8 x i16> %1070, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1072 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 30
  %1073 = bitcast <2 x i64>* %1072 to <8 x i16>*
  %1074 = load <8 x i16>, <8 x i16>* %1073, align 16
  %1075 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 31
  %1076 = bitcast <2 x i64>* %1075 to <8 x i16>*
  %1077 = load <8 x i16>, <8 x i16>* %1076, align 16
  %1078 = shufflevector <8 x i16> %1074, <8 x i16> %1077, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %1079 = shufflevector <8 x i16> %1053, <8 x i16> %1056, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1080 = shufflevector <8 x i16> %1060, <8 x i16> %1063, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1081 = shufflevector <8 x i16> %1067, <8 x i16> %1070, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1082 = shufflevector <8 x i16> %1074, <8 x i16> %1077, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %1083 = bitcast <8 x i16> %1057 to <4 x i32>
  %1084 = bitcast <8 x i16> %1064 to <4 x i32>
  %1085 = shufflevector <4 x i32> %1083, <4 x i32> %1084, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1086 = bitcast <4 x i32> %1085 to <2 x i64>
  %1087 = bitcast <8 x i16> %1071 to <4 x i32>
  %1088 = bitcast <8 x i16> %1078 to <4 x i32>
  %1089 = shufflevector <4 x i32> %1087, <4 x i32> %1088, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1090 = bitcast <4 x i32> %1089 to <2 x i64>
  %1091 = bitcast <8 x i16> %1079 to <4 x i32>
  %1092 = bitcast <8 x i16> %1080 to <4 x i32>
  %1093 = shufflevector <4 x i32> %1091, <4 x i32> %1092, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1094 = bitcast <4 x i32> %1093 to <2 x i64>
  %1095 = bitcast <8 x i16> %1081 to <4 x i32>
  %1096 = bitcast <8 x i16> %1082 to <4 x i32>
  %1097 = shufflevector <4 x i32> %1095, <4 x i32> %1096, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %1098 = bitcast <4 x i32> %1097 to <2 x i64>
  %1099 = shufflevector <4 x i32> %1083, <4 x i32> %1084, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1100 = bitcast <4 x i32> %1099 to <2 x i64>
  %1101 = shufflevector <4 x i32> %1087, <4 x i32> %1088, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1102 = bitcast <4 x i32> %1101 to <2 x i64>
  %1103 = shufflevector <4 x i32> %1091, <4 x i32> %1092, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1104 = bitcast <4 x i32> %1103 to <2 x i64>
  %1105 = shufflevector <4 x i32> %1095, <4 x i32> %1096, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %1106 = bitcast <4 x i32> %1105 to <2 x i64>
  %1107 = shufflevector <2 x i64> %1086, <2 x i64> %1090, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1107, <2 x i64>* %1051, align 16
  %1108 = shufflevector <2 x i64> %1086, <2 x i64> %1090, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1108, <2 x i64>* %1054, align 16
  %1109 = shufflevector <2 x i64> %1100, <2 x i64> %1102, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1109, <2 x i64>* %1058, align 16
  %1110 = shufflevector <2 x i64> %1100, <2 x i64> %1102, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1110, <2 x i64>* %1061, align 16
  %1111 = shufflevector <2 x i64> %1094, <2 x i64> %1098, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1111, <2 x i64>* %1065, align 16
  %1112 = shufflevector <2 x i64> %1094, <2 x i64> %1098, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1112, <2 x i64>* %1068, align 16
  %1113 = shufflevector <2 x i64> %1104, <2 x i64> %1106, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %1113, <2 x i64>* %1072, align 16
  %1114 = shufflevector <2 x i64> %1104, <2 x i64> %1106, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %1114, <2 x i64>* %1075, align 16
  %1115 = getelementptr inbounds i32, i32* %655, i64 24
  %1116 = bitcast <2 x i64> %1107 to <8 x i16>
  %1117 = shufflevector <8 x i16> %1116, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %1118 = shufflevector <8 x i16> %1116, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %1119 = bitcast <8 x i16> %1117 to <4 x i32>
  %1120 = ashr <4 x i32> %1119, <i32 16, i32 16, i32 16, i32 16>
  %1121 = bitcast <8 x i16> %1118 to <4 x i32>
  %1122 = ashr <4 x i32> %1121, <i32 16, i32 16, i32 16, i32 16>
  %1123 = bitcast i32* %1115 to <4 x i32>*
  store <4 x i32> %1120, <4 x i32>* %1123, align 16
  %1124 = getelementptr inbounds i32, i32* %1115, i64 4
  %1125 = bitcast i32* %1124 to <4 x i32>*
  store <4 x i32> %1122, <4 x i32>* %1125, align 16
  %1126 = bitcast <2 x i64> %1108 to <8 x i16>
  %1127 = getelementptr inbounds i32, i32* %1115, i64 32
  %1128 = shufflevector <8 x i16> %1126, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %1129 = shufflevector <8 x i16> %1126, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %1130 = bitcast <8 x i16> %1128 to <4 x i32>
  %1131 = ashr <4 x i32> %1130, <i32 16, i32 16, i32 16, i32 16>
  %1132 = bitcast <8 x i16> %1129 to <4 x i32>
  %1133 = ashr <4 x i32> %1132, <i32 16, i32 16, i32 16, i32 16>
  %1134 = bitcast i32* %1127 to <4 x i32>*
  store <4 x i32> %1131, <4 x i32>* %1134, align 16
  %1135 = getelementptr inbounds i32, i32* %1127, i64 4
  %1136 = bitcast i32* %1135 to <4 x i32>*
  store <4 x i32> %1133, <4 x i32>* %1136, align 16
  %1137 = bitcast <2 x i64> %1109 to <8 x i16>
  %1138 = getelementptr inbounds i32, i32* %1115, i64 64
  %1139 = shufflevector <8 x i16> %1137, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %1140 = shufflevector <8 x i16> %1137, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %1141 = bitcast <8 x i16> %1139 to <4 x i32>
  %1142 = ashr <4 x i32> %1141, <i32 16, i32 16, i32 16, i32 16>
  %1143 = bitcast <8 x i16> %1140 to <4 x i32>
  %1144 = ashr <4 x i32> %1143, <i32 16, i32 16, i32 16, i32 16>
  %1145 = bitcast i32* %1138 to <4 x i32>*
  store <4 x i32> %1142, <4 x i32>* %1145, align 16
  %1146 = getelementptr inbounds i32, i32* %1138, i64 4
  %1147 = bitcast i32* %1146 to <4 x i32>*
  store <4 x i32> %1144, <4 x i32>* %1147, align 16
  %1148 = bitcast <2 x i64> %1110 to <8 x i16>
  %1149 = getelementptr inbounds i32, i32* %1115, i64 96
  %1150 = shufflevector <8 x i16> %1148, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %1151 = shufflevector <8 x i16> %1148, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %1152 = bitcast <8 x i16> %1150 to <4 x i32>
  %1153 = ashr <4 x i32> %1152, <i32 16, i32 16, i32 16, i32 16>
  %1154 = bitcast <8 x i16> %1151 to <4 x i32>
  %1155 = ashr <4 x i32> %1154, <i32 16, i32 16, i32 16, i32 16>
  %1156 = bitcast i32* %1149 to <4 x i32>*
  store <4 x i32> %1153, <4 x i32>* %1156, align 16
  %1157 = getelementptr inbounds i32, i32* %1149, i64 4
  %1158 = bitcast i32* %1157 to <4 x i32>*
  store <4 x i32> %1155, <4 x i32>* %1158, align 16
  %1159 = bitcast <2 x i64> %1111 to <8 x i16>
  %1160 = getelementptr inbounds i32, i32* %1115, i64 128
  %1161 = shufflevector <8 x i16> %1159, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %1162 = shufflevector <8 x i16> %1159, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %1163 = bitcast <8 x i16> %1161 to <4 x i32>
  %1164 = ashr <4 x i32> %1163, <i32 16, i32 16, i32 16, i32 16>
  %1165 = bitcast <8 x i16> %1162 to <4 x i32>
  %1166 = ashr <4 x i32> %1165, <i32 16, i32 16, i32 16, i32 16>
  %1167 = bitcast i32* %1160 to <4 x i32>*
  store <4 x i32> %1164, <4 x i32>* %1167, align 16
  %1168 = getelementptr inbounds i32, i32* %1160, i64 4
  %1169 = bitcast i32* %1168 to <4 x i32>*
  store <4 x i32> %1166, <4 x i32>* %1169, align 16
  %1170 = bitcast <2 x i64> %1112 to <8 x i16>
  %1171 = getelementptr inbounds i32, i32* %1115, i64 160
  %1172 = shufflevector <8 x i16> %1170, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %1173 = shufflevector <8 x i16> %1170, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %1174 = bitcast <8 x i16> %1172 to <4 x i32>
  %1175 = ashr <4 x i32> %1174, <i32 16, i32 16, i32 16, i32 16>
  %1176 = bitcast <8 x i16> %1173 to <4 x i32>
  %1177 = ashr <4 x i32> %1176, <i32 16, i32 16, i32 16, i32 16>
  %1178 = bitcast i32* %1171 to <4 x i32>*
  store <4 x i32> %1175, <4 x i32>* %1178, align 16
  %1179 = getelementptr inbounds i32, i32* %1171, i64 4
  %1180 = bitcast i32* %1179 to <4 x i32>*
  store <4 x i32> %1177, <4 x i32>* %1180, align 16
  %1181 = bitcast <2 x i64> %1113 to <8 x i16>
  %1182 = getelementptr inbounds i32, i32* %1115, i64 192
  %1183 = shufflevector <8 x i16> %1181, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %1184 = shufflevector <8 x i16> %1181, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %1185 = bitcast <8 x i16> %1183 to <4 x i32>
  %1186 = ashr <4 x i32> %1185, <i32 16, i32 16, i32 16, i32 16>
  %1187 = bitcast <8 x i16> %1184 to <4 x i32>
  %1188 = ashr <4 x i32> %1187, <i32 16, i32 16, i32 16, i32 16>
  %1189 = bitcast i32* %1182 to <4 x i32>*
  store <4 x i32> %1186, <4 x i32>* %1189, align 16
  %1190 = getelementptr inbounds i32, i32* %1182, i64 4
  %1191 = bitcast i32* %1190 to <4 x i32>*
  store <4 x i32> %1188, <4 x i32>* %1191, align 16
  %1192 = getelementptr inbounds <2 x i64>, <2 x i64>* %527, i64 31
  %1193 = bitcast <2 x i64>* %1192 to <8 x i16>*
  %1194 = load <8 x i16>, <8 x i16>* %1193, align 16
  %1195 = getelementptr inbounds i32, i32* %1115, i64 224
  %1196 = shufflevector <8 x i16> %1194, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %1197 = shufflevector <8 x i16> %1194, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %1198 = bitcast <8 x i16> %1196 to <4 x i32>
  %1199 = ashr <4 x i32> %1198, <i32 16, i32 16, i32 16, i32 16>
  %1200 = bitcast <8 x i16> %1197 to <4 x i32>
  %1201 = ashr <4 x i32> %1200, <i32 16, i32 16, i32 16, i32 16>
  %1202 = bitcast i32* %1195 to <4 x i32>*
  store <4 x i32> %1199, <4 x i32>* %1202, align 16
  %1203 = getelementptr inbounds i32, i32* %1195, i64 4
  %1204 = bitcast i32* %1203 to <4 x i32>*
  store <4 x i32> %1201, <4 x i32>* %1204, align 16
  %1205 = add nuw nsw i64 %506, 1
  %1206 = icmp eq i64 %1205, 4
  br i1 %1206, label %1208, label %505

1207:                                             ; preds = %5
  tail call void @av1_fwd_txfm2d_32x32_c(i16* %0, i32* %1, i32 %2, i8 zeroext %3, i32 %4) #8
  br label %1208

1208:                                             ; preds = %590, %1207
  call void @llvm.lifetime.end.p0i8(i64 2048, i8* nonnull %9) #8
  call void @llvm.lifetime.end.p0i8(i64 512, i8* nonnull %8) #8
  ret void
}

declare void @av1_fwd_txfm2d_32x32_c(i16*, i32*, i32, i8 zeroext, i32) local_unnamed_addr #3

; Function Attrs: nounwind ssp uwtable
define hidden void @av1_lowbd_fwd_txfm2d_64x16_sse2(i16* nocapture readonly, i32* nocapture, i32, i8 zeroext, i32) #2 {
  %6 = alloca [64 x <2 x i64>], align 16
  %7 = alloca [128 x <2 x i64>], align 16
  %8 = bitcast [64 x <2 x i64>]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1024, i8* nonnull %8) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %8, i8 -86, i64 1024, i1 false)
  %9 = bitcast [128 x <2 x i64>]* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 2048, i8* nonnull %9) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 2048, i1 false)
  %10 = load i8*, i8** getelementptr inbounds ([19 x i8*], [19 x i8*]* @av1_fwd_txfm_shift_ls, i64 0, i64 18), align 16
  %11 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_fwd_cos_bit_col, i64 0, i64 4, i64 2), align 2
  %12 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_fwd_cos_bit_row, i64 0, i64 4, i64 2), align 2
  %13 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 0
  %14 = sext i32 %2 to i64
  %15 = getelementptr inbounds i8, i8* %10, i64 1
  %16 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 1
  %17 = shl nsw i64 %14, 1
  %18 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 2
  %19 = mul nsw i64 %14, 3
  %20 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 3
  %21 = shl nsw i64 %14, 2
  %22 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 4
  %23 = mul nsw i64 %14, 5
  %24 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 5
  %25 = mul nsw i64 %14, 6
  %26 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 6
  %27 = mul nsw i64 %14, 7
  %28 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 7
  %29 = shl nsw i64 %14, 3
  %30 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 8
  %31 = mul nsw i64 %14, 9
  %32 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 9
  %33 = mul nsw i64 %14, 10
  %34 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 10
  %35 = mul nsw i64 %14, 11
  %36 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 11
  %37 = mul nsw i64 %14, 12
  %38 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 12
  %39 = mul nsw i64 %14, 13
  %40 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 13
  %41 = mul nsw i64 %14, 14
  %42 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 14
  %43 = mul nsw i64 %14, 15
  %44 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 15
  %45 = bitcast [64 x <2 x i64>]* %6 to <8 x i16>*
  %46 = bitcast <2 x i64>* %16 to <8 x i16>*
  %47 = bitcast <2 x i64>* %18 to <8 x i16>*
  %48 = bitcast <2 x i64>* %20 to <8 x i16>*
  %49 = bitcast <2 x i64>* %22 to <8 x i16>*
  %50 = bitcast <2 x i64>* %24 to <8 x i16>*
  %51 = bitcast <2 x i64>* %26 to <8 x i16>*
  %52 = bitcast <2 x i64>* %28 to <8 x i16>*
  %53 = bitcast <2 x i64>* %30 to <8 x i16>*
  %54 = bitcast <2 x i64>* %32 to <8 x i16>*
  %55 = bitcast <2 x i64>* %34 to <8 x i16>*
  %56 = bitcast <2 x i64>* %36 to <8 x i16>*
  %57 = bitcast <2 x i64>* %38 to <8 x i16>*
  %58 = bitcast <2 x i64>* %40 to <8 x i16>*
  %59 = bitcast <2 x i64>* %42 to <8 x i16>*
  %60 = bitcast <2 x i64>* %44 to <8 x i16>*
  %61 = bitcast [64 x <2 x i64>]* %6 to <8 x i16>*
  %62 = bitcast <2 x i64>* %16 to <8 x i16>*
  %63 = bitcast <2 x i64>* %18 to <8 x i16>*
  %64 = bitcast <2 x i64>* %20 to <8 x i16>*
  %65 = bitcast <2 x i64>* %22 to <8 x i16>*
  %66 = bitcast <2 x i64>* %24 to <8 x i16>*
  %67 = bitcast <2 x i64>* %26 to <8 x i16>*
  %68 = bitcast <2 x i64>* %28 to <8 x i16>*
  %69 = bitcast <2 x i64>* %30 to <8 x i16>*
  %70 = bitcast <2 x i64>* %32 to <8 x i16>*
  %71 = bitcast <2 x i64>* %34 to <8 x i16>*
  %72 = bitcast <2 x i64>* %36 to <8 x i16>*
  %73 = bitcast <2 x i64>* %38 to <8 x i16>*
  %74 = bitcast <2 x i64>* %40 to <8 x i16>*
  %75 = bitcast <2 x i64>* %42 to <8 x i16>*
  %76 = bitcast <2 x i64>* %44 to <8 x i16>*
  %77 = bitcast [64 x <2 x i64>]* %6 to <8 x i16>*
  %78 = bitcast <2 x i64>* %16 to <8 x i16>*
  %79 = bitcast <2 x i64>* %18 to <8 x i16>*
  %80 = bitcast <2 x i64>* %20 to <8 x i16>*
  %81 = bitcast <2 x i64>* %22 to <8 x i16>*
  %82 = bitcast <2 x i64>* %24 to <8 x i16>*
  %83 = bitcast <2 x i64>* %26 to <8 x i16>*
  %84 = bitcast <2 x i64>* %28 to <8 x i16>*
  %85 = bitcast <2 x i64>* %30 to <8 x i16>*
  %86 = bitcast <2 x i64>* %32 to <8 x i16>*
  %87 = bitcast <2 x i64>* %34 to <8 x i16>*
  %88 = bitcast <2 x i64>* %36 to <8 x i16>*
  %89 = bitcast <2 x i64>* %38 to <8 x i16>*
  %90 = bitcast <2 x i64>* %40 to <8 x i16>*
  %91 = bitcast <2 x i64>* %42 to <8 x i16>*
  %92 = bitcast <2 x i64>* %44 to <8 x i16>*
  %93 = bitcast [64 x <2 x i64>]* %6 to <8 x i16>*
  %94 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 1
  %95 = bitcast <2 x i64>* %94 to <8 x i16>*
  %96 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 2
  %97 = bitcast <2 x i64>* %96 to <8 x i16>*
  %98 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 3
  %99 = bitcast <2 x i64>* %98 to <8 x i16>*
  %100 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 4
  %101 = bitcast <2 x i64>* %100 to <8 x i16>*
  %102 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 5
  %103 = bitcast <2 x i64>* %102 to <8 x i16>*
  %104 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 6
  %105 = bitcast <2 x i64>* %104 to <8 x i16>*
  %106 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 7
  %107 = bitcast <2 x i64>* %106 to <8 x i16>*
  %108 = bitcast <2 x i64>* %30 to <8 x i16>*
  %109 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 9
  %110 = bitcast <2 x i64>* %109 to <8 x i16>*
  %111 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 10
  %112 = bitcast <2 x i64>* %111 to <8 x i16>*
  %113 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 11
  %114 = bitcast <2 x i64>* %113 to <8 x i16>*
  %115 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 12
  %116 = bitcast <2 x i64>* %115 to <8 x i16>*
  %117 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 13
  %118 = bitcast <2 x i64>* %117 to <8 x i16>*
  %119 = bitcast [64 x <2 x i64>]* %6 to <8 x i16>*
  %120 = bitcast <2 x i64>* %16 to <8 x i16>*
  %121 = bitcast <2 x i64>* %18 to <8 x i16>*
  %122 = bitcast <2 x i64>* %20 to <8 x i16>*
  %123 = bitcast <2 x i64>* %22 to <8 x i16>*
  %124 = bitcast <2 x i64>* %24 to <8 x i16>*
  %125 = bitcast <2 x i64>* %26 to <8 x i16>*
  %126 = bitcast <2 x i64>* %28 to <8 x i16>*
  %127 = bitcast <2 x i64>* %30 to <8 x i16>*
  %128 = bitcast <2 x i64>* %32 to <8 x i16>*
  %129 = bitcast <2 x i64>* %34 to <8 x i16>*
  %130 = bitcast <2 x i64>* %36 to <8 x i16>*
  %131 = bitcast <2 x i64>* %38 to <8 x i16>*
  %132 = bitcast <2 x i64>* %40 to <8 x i16>*
  %133 = bitcast <2 x i64>* %42 to <8 x i16>*
  %134 = bitcast <2 x i64>* %44 to <8 x i16>*
  %135 = getelementptr inbounds [128 x <2 x i64>], [128 x <2 x i64>]* %7, i64 0, i64 64
  %136 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 14
  %137 = bitcast <2 x i64>* %136 to <8 x i16>*
  %138 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 15
  %139 = bitcast <2 x i64>* %138 to <8 x i16>*
  br label %142

140:                                              ; preds = %384
  %141 = getelementptr inbounds i8, i8* %10, i64 2
  br label %500

142:                                              ; preds = %384, %5
  %143 = phi i64 [ 0, %5 ], [ %497, %384 ]
  %144 = shl nsw i64 %143, 3
  %145 = getelementptr inbounds i16, i16* %0, i64 %144
  %146 = bitcast i16* %145 to <2 x i64>*
  %147 = load <2 x i64>, <2 x i64>* %146, align 16
  store <2 x i64> %147, <2 x i64>* %13, align 16
  %148 = getelementptr inbounds i16, i16* %145, i64 %14
  %149 = bitcast i16* %148 to <2 x i64>*
  %150 = load <2 x i64>, <2 x i64>* %149, align 16
  store <2 x i64> %150, <2 x i64>* %16, align 16
  %151 = getelementptr inbounds i16, i16* %145, i64 %17
  %152 = bitcast i16* %151 to <2 x i64>*
  %153 = load <2 x i64>, <2 x i64>* %152, align 16
  store <2 x i64> %153, <2 x i64>* %18, align 16
  %154 = getelementptr inbounds i16, i16* %145, i64 %19
  %155 = bitcast i16* %154 to <2 x i64>*
  %156 = load <2 x i64>, <2 x i64>* %155, align 16
  store <2 x i64> %156, <2 x i64>* %20, align 16
  %157 = getelementptr inbounds i16, i16* %145, i64 %21
  %158 = bitcast i16* %157 to <2 x i64>*
  %159 = load <2 x i64>, <2 x i64>* %158, align 16
  store <2 x i64> %159, <2 x i64>* %22, align 16
  %160 = getelementptr inbounds i16, i16* %145, i64 %23
  %161 = bitcast i16* %160 to <2 x i64>*
  %162 = load <2 x i64>, <2 x i64>* %161, align 16
  store <2 x i64> %162, <2 x i64>* %24, align 16
  %163 = getelementptr inbounds i16, i16* %145, i64 %25
  %164 = bitcast i16* %163 to <2 x i64>*
  %165 = load <2 x i64>, <2 x i64>* %164, align 16
  store <2 x i64> %165, <2 x i64>* %26, align 16
  %166 = getelementptr inbounds i16, i16* %145, i64 %27
  %167 = bitcast i16* %166 to <2 x i64>*
  %168 = load <2 x i64>, <2 x i64>* %167, align 16
  store <2 x i64> %168, <2 x i64>* %28, align 16
  %169 = getelementptr inbounds i16, i16* %145, i64 %29
  %170 = bitcast i16* %169 to <2 x i64>*
  %171 = load <2 x i64>, <2 x i64>* %170, align 16
  store <2 x i64> %171, <2 x i64>* %30, align 16
  %172 = getelementptr inbounds i16, i16* %145, i64 %31
  %173 = bitcast i16* %172 to <2 x i64>*
  %174 = load <2 x i64>, <2 x i64>* %173, align 16
  store <2 x i64> %174, <2 x i64>* %32, align 16
  %175 = getelementptr inbounds i16, i16* %145, i64 %33
  %176 = bitcast i16* %175 to <2 x i64>*
  %177 = load <2 x i64>, <2 x i64>* %176, align 16
  store <2 x i64> %177, <2 x i64>* %34, align 16
  %178 = getelementptr inbounds i16, i16* %145, i64 %35
  %179 = bitcast i16* %178 to <2 x i64>*
  %180 = load <2 x i64>, <2 x i64>* %179, align 16
  store <2 x i64> %180, <2 x i64>* %36, align 16
  %181 = getelementptr inbounds i16, i16* %145, i64 %37
  %182 = bitcast i16* %181 to <2 x i64>*
  %183 = load <2 x i64>, <2 x i64>* %182, align 16
  store <2 x i64> %183, <2 x i64>* %38, align 16
  %184 = getelementptr inbounds i16, i16* %145, i64 %39
  %185 = bitcast i16* %184 to <2 x i64>*
  %186 = load <2 x i64>, <2 x i64>* %185, align 16
  store <2 x i64> %186, <2 x i64>* %40, align 16
  %187 = getelementptr inbounds i16, i16* %145, i64 %41
  %188 = bitcast i16* %187 to <2 x i64>*
  %189 = load <2 x i64>, <2 x i64>* %188, align 16
  store <2 x i64> %189, <2 x i64>* %42, align 16
  %190 = getelementptr inbounds i16, i16* %145, i64 %43
  %191 = bitcast i16* %190 to <2 x i64>*
  %192 = load <2 x i64>, <2 x i64>* %191, align 16
  store <2 x i64> %192, <2 x i64>* %44, align 16
  %193 = load i8, i8* %10, align 1
  %194 = sext i8 %193 to i32
  %195 = icmp slt i8 %193, 0
  %196 = bitcast <2 x i64> %147 to <8 x i16>
  %197 = bitcast <2 x i64> %150 to <8 x i16>
  %198 = bitcast <2 x i64> %153 to <8 x i16>
  %199 = bitcast <2 x i64> %156 to <8 x i16>
  %200 = bitcast <2 x i64> %159 to <8 x i16>
  %201 = bitcast <2 x i64> %162 to <8 x i16>
  %202 = bitcast <2 x i64> %165 to <8 x i16>
  %203 = bitcast <2 x i64> %168 to <8 x i16>
  %204 = bitcast <2 x i64> %171 to <8 x i16>
  %205 = bitcast <2 x i64> %174 to <8 x i16>
  %206 = bitcast <2 x i64> %177 to <8 x i16>
  %207 = bitcast <2 x i64> %180 to <8 x i16>
  %208 = bitcast <2 x i64> %183 to <8 x i16>
  %209 = bitcast <2 x i64> %186 to <8 x i16>
  %210 = bitcast <2 x i64> %189 to <8 x i16>
  %211 = bitcast <2 x i64> %192 to <8 x i16>
  br i1 %195, label %212, label %256

212:                                              ; preds = %142
  %213 = sub nsw i32 0, %194
  %214 = xor i32 %194, -1
  %215 = shl i32 1, %214
  %216 = trunc i32 %215 to i16
  %217 = insertelement <8 x i16> undef, i16 %216, i32 0
  %218 = shufflevector <8 x i16> %217, <8 x i16> undef, <8 x i32> zeroinitializer
  %219 = load <8 x i16>, <8 x i16>* %61, align 16
  %220 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %219, <8 x i16> %218) #8
  %221 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %220, i32 %213) #8
  store <8 x i16> %221, <8 x i16>* %61, align 16
  %222 = load <8 x i16>, <8 x i16>* %62, align 16
  %223 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %222, <8 x i16> %218) #8
  %224 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %223, i32 %213) #8
  store <8 x i16> %224, <8 x i16>* %62, align 16
  %225 = load <8 x i16>, <8 x i16>* %63, align 16
  %226 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %225, <8 x i16> %218) #8
  %227 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %226, i32 %213) #8
  store <8 x i16> %227, <8 x i16>* %63, align 16
  %228 = load <8 x i16>, <8 x i16>* %64, align 16
  %229 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %228, <8 x i16> %218) #8
  %230 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %229, i32 %213) #8
  store <8 x i16> %230, <8 x i16>* %64, align 16
  %231 = load <8 x i16>, <8 x i16>* %65, align 16
  %232 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %231, <8 x i16> %218) #8
  %233 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %232, i32 %213) #8
  store <8 x i16> %233, <8 x i16>* %65, align 16
  %234 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %201, <8 x i16> %218) #8
  %235 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %234, i32 %213) #8
  store <8 x i16> %235, <8 x i16>* %66, align 16
  %236 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %202, <8 x i16> %218) #8
  %237 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %236, i32 %213) #8
  store <8 x i16> %237, <8 x i16>* %67, align 16
  %238 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %203, <8 x i16> %218) #8
  %239 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %238, i32 %213) #8
  store <8 x i16> %239, <8 x i16>* %68, align 16
  %240 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %204, <8 x i16> %218) #8
  %241 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %240, i32 %213) #8
  store <8 x i16> %241, <8 x i16>* %69, align 16
  %242 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %205, <8 x i16> %218) #8
  %243 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %242, i32 %213) #8
  store <8 x i16> %243, <8 x i16>* %70, align 16
  %244 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %206, <8 x i16> %218) #8
  %245 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %244, i32 %213) #8
  store <8 x i16> %245, <8 x i16>* %71, align 16
  %246 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %207, <8 x i16> %218) #8
  %247 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %246, i32 %213) #8
  store <8 x i16> %247, <8 x i16>* %72, align 16
  %248 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %208, <8 x i16> %218) #8
  %249 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %248, i32 %213) #8
  store <8 x i16> %249, <8 x i16>* %73, align 16
  %250 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %209, <8 x i16> %218) #8
  %251 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %250, i32 %213) #8
  store <8 x i16> %251, <8 x i16>* %74, align 16
  %252 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %210, <8 x i16> %218) #8
  %253 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %252, i32 %213) #8
  store <8 x i16> %253, <8 x i16>* %75, align 16
  %254 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %211, <8 x i16> %218) #8
  %255 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %254, i32 %213) #8
  store <8 x i16> %255, <8 x i16>* %76, align 16
  br label %275

256:                                              ; preds = %142
  %257 = icmp eq i8 %193, 0
  br i1 %257, label %275, label %258

258:                                              ; preds = %256
  %259 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %196, i32 %194) #8
  store <8 x i16> %259, <8 x i16>* %45, align 16
  %260 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %197, i32 %194) #8
  store <8 x i16> %260, <8 x i16>* %46, align 16
  %261 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %198, i32 %194) #8
  store <8 x i16> %261, <8 x i16>* %47, align 16
  %262 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %199, i32 %194) #8
  store <8 x i16> %262, <8 x i16>* %48, align 16
  %263 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %200, i32 %194) #8
  store <8 x i16> %263, <8 x i16>* %49, align 16
  %264 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %201, i32 %194) #8
  store <8 x i16> %264, <8 x i16>* %50, align 16
  %265 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %202, i32 %194) #8
  store <8 x i16> %265, <8 x i16>* %51, align 16
  %266 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %203, i32 %194) #8
  store <8 x i16> %266, <8 x i16>* %52, align 16
  %267 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %204, i32 %194) #8
  store <8 x i16> %267, <8 x i16>* %53, align 16
  %268 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %205, i32 %194) #8
  store <8 x i16> %268, <8 x i16>* %54, align 16
  %269 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %206, i32 %194) #8
  store <8 x i16> %269, <8 x i16>* %55, align 16
  %270 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %207, i32 %194) #8
  store <8 x i16> %270, <8 x i16>* %56, align 16
  %271 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %208, i32 %194) #8
  store <8 x i16> %271, <8 x i16>* %57, align 16
  %272 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %209, i32 %194) #8
  store <8 x i16> %272, <8 x i16>* %58, align 16
  %273 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %210, i32 %194) #8
  store <8 x i16> %273, <8 x i16>* %59, align 16
  %274 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %211, i32 %194) #8
  store <8 x i16> %274, <8 x i16>* %60, align 16
  br label %275

275:                                              ; preds = %258, %212, %256
  call void @fdct8x16_new_sse2(<2 x i64>* nonnull %13, <2 x i64>* nonnull %13, i8 signext %11)
  %276 = load i8, i8* %15, align 1
  %277 = sext i8 %276 to i32
  %278 = icmp slt i8 %276, 0
  br i1 %278, label %279, label %334

279:                                              ; preds = %275
  %280 = sub nsw i32 0, %277
  %281 = xor i32 %277, -1
  %282 = shl i32 1, %281
  %283 = trunc i32 %282 to i16
  %284 = insertelement <8 x i16> undef, i16 %283, i32 0
  %285 = shufflevector <8 x i16> %284, <8 x i16> undef, <8 x i32> zeroinitializer
  %286 = load <8 x i16>, <8 x i16>* %119, align 16
  %287 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %286, <8 x i16> %285) #8
  %288 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %287, i32 %280) #8
  store <8 x i16> %288, <8 x i16>* %119, align 16
  %289 = load <8 x i16>, <8 x i16>* %120, align 16
  %290 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %289, <8 x i16> %285) #8
  %291 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %290, i32 %280) #8
  store <8 x i16> %291, <8 x i16>* %120, align 16
  %292 = load <8 x i16>, <8 x i16>* %121, align 16
  %293 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %292, <8 x i16> %285) #8
  %294 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %293, i32 %280) #8
  store <8 x i16> %294, <8 x i16>* %121, align 16
  %295 = load <8 x i16>, <8 x i16>* %122, align 16
  %296 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %295, <8 x i16> %285) #8
  %297 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %296, i32 %280) #8
  store <8 x i16> %297, <8 x i16>* %122, align 16
  %298 = load <8 x i16>, <8 x i16>* %123, align 16
  %299 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %298, <8 x i16> %285) #8
  %300 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %299, i32 %280) #8
  store <8 x i16> %300, <8 x i16>* %123, align 16
  %301 = load <8 x i16>, <8 x i16>* %124, align 16
  %302 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %301, <8 x i16> %285) #8
  %303 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %302, i32 %280) #8
  store <8 x i16> %303, <8 x i16>* %124, align 16
  %304 = load <8 x i16>, <8 x i16>* %125, align 16
  %305 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %304, <8 x i16> %285) #8
  %306 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %305, i32 %280) #8
  store <8 x i16> %306, <8 x i16>* %125, align 16
  %307 = load <8 x i16>, <8 x i16>* %126, align 16
  %308 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %307, <8 x i16> %285) #8
  %309 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %308, i32 %280) #8
  store <8 x i16> %309, <8 x i16>* %126, align 16
  %310 = load <8 x i16>, <8 x i16>* %127, align 16
  %311 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %310, <8 x i16> %285) #8
  %312 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %311, i32 %280) #8
  store <8 x i16> %312, <8 x i16>* %127, align 16
  %313 = load <8 x i16>, <8 x i16>* %128, align 16
  %314 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %313, <8 x i16> %285) #8
  %315 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %314, i32 %280) #8
  store <8 x i16> %315, <8 x i16>* %128, align 16
  %316 = load <8 x i16>, <8 x i16>* %129, align 16
  %317 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %316, <8 x i16> %285) #8
  %318 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %317, i32 %280) #8
  store <8 x i16> %318, <8 x i16>* %129, align 16
  %319 = load <8 x i16>, <8 x i16>* %130, align 16
  %320 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %319, <8 x i16> %285) #8
  %321 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %320, i32 %280) #8
  store <8 x i16> %321, <8 x i16>* %130, align 16
  %322 = load <8 x i16>, <8 x i16>* %131, align 16
  %323 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %322, <8 x i16> %285) #8
  %324 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %323, i32 %280) #8
  store <8 x i16> %324, <8 x i16>* %131, align 16
  %325 = load <8 x i16>, <8 x i16>* %132, align 16
  %326 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %325, <8 x i16> %285) #8
  %327 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %326, i32 %280) #8
  store <8 x i16> %327, <8 x i16>* %132, align 16
  %328 = load <8 x i16>, <8 x i16>* %133, align 16
  %329 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %328, <8 x i16> %285) #8
  %330 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %329, i32 %280) #8
  store <8 x i16> %330, <8 x i16>* %133, align 16
  %331 = load <8 x i16>, <8 x i16>* %134, align 16
  %332 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %331, <8 x i16> %285) #8
  %333 = tail call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %332, i32 %280) #8
  store <8 x i16> %333, <8 x i16>* %134, align 16
  br label %384

334:                                              ; preds = %275
  %335 = icmp eq i8 %276, 0
  br i1 %335, label %336, label %351

336:                                              ; preds = %334
  %337 = load <8 x i16>, <8 x i16>* %93, align 16
  %338 = load <8 x i16>, <8 x i16>* %95, align 16
  %339 = load <8 x i16>, <8 x i16>* %97, align 16
  %340 = load <8 x i16>, <8 x i16>* %99, align 16
  %341 = load <8 x i16>, <8 x i16>* %101, align 16
  %342 = load <8 x i16>, <8 x i16>* %103, align 16
  %343 = load <8 x i16>, <8 x i16>* %105, align 16
  %344 = load <8 x i16>, <8 x i16>* %107, align 16
  %345 = load <8 x i16>, <8 x i16>* %108, align 16
  %346 = load <8 x i16>, <8 x i16>* %110, align 16
  %347 = load <8 x i16>, <8 x i16>* %112, align 16
  %348 = load <8 x i16>, <8 x i16>* %114, align 16
  %349 = load <8 x i16>, <8 x i16>* %116, align 16
  %350 = load <8 x i16>, <8 x i16>* %118, align 16
  br label %384

351:                                              ; preds = %334
  %352 = load <8 x i16>, <8 x i16>* %77, align 16
  %353 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %352, i32 %277) #8
  store <8 x i16> %353, <8 x i16>* %77, align 16
  %354 = load <8 x i16>, <8 x i16>* %78, align 16
  %355 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %354, i32 %277) #8
  store <8 x i16> %355, <8 x i16>* %78, align 16
  %356 = load <8 x i16>, <8 x i16>* %79, align 16
  %357 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %356, i32 %277) #8
  store <8 x i16> %357, <8 x i16>* %79, align 16
  %358 = load <8 x i16>, <8 x i16>* %80, align 16
  %359 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %358, i32 %277) #8
  store <8 x i16> %359, <8 x i16>* %80, align 16
  %360 = load <8 x i16>, <8 x i16>* %81, align 16
  %361 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %360, i32 %277) #8
  store <8 x i16> %361, <8 x i16>* %81, align 16
  %362 = load <8 x i16>, <8 x i16>* %82, align 16
  %363 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %362, i32 %277) #8
  store <8 x i16> %363, <8 x i16>* %82, align 16
  %364 = load <8 x i16>, <8 x i16>* %83, align 16
  %365 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %364, i32 %277) #8
  store <8 x i16> %365, <8 x i16>* %83, align 16
  %366 = load <8 x i16>, <8 x i16>* %84, align 16
  %367 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %366, i32 %277) #8
  store <8 x i16> %367, <8 x i16>* %84, align 16
  %368 = load <8 x i16>, <8 x i16>* %85, align 16
  %369 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %368, i32 %277) #8
  store <8 x i16> %369, <8 x i16>* %85, align 16
  %370 = load <8 x i16>, <8 x i16>* %86, align 16
  %371 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %370, i32 %277) #8
  store <8 x i16> %371, <8 x i16>* %86, align 16
  %372 = load <8 x i16>, <8 x i16>* %87, align 16
  %373 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %372, i32 %277) #8
  store <8 x i16> %373, <8 x i16>* %87, align 16
  %374 = load <8 x i16>, <8 x i16>* %88, align 16
  %375 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %374, i32 %277) #8
  store <8 x i16> %375, <8 x i16>* %88, align 16
  %376 = load <8 x i16>, <8 x i16>* %89, align 16
  %377 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %376, i32 %277) #8
  store <8 x i16> %377, <8 x i16>* %89, align 16
  %378 = load <8 x i16>, <8 x i16>* %90, align 16
  %379 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %378, i32 %277) #8
  store <8 x i16> %379, <8 x i16>* %90, align 16
  %380 = load <8 x i16>, <8 x i16>* %91, align 16
  %381 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %380, i32 %277) #8
  store <8 x i16> %381, <8 x i16>* %91, align 16
  %382 = load <8 x i16>, <8 x i16>* %92, align 16
  %383 = tail call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %382, i32 %277) #8
  store <8 x i16> %383, <8 x i16>* %92, align 16
  br label %384

384:                                              ; preds = %336, %351, %279
  %385 = phi <8 x i16> [ %350, %336 ], [ %379, %351 ], [ %327, %279 ]
  %386 = phi <8 x i16> [ %349, %336 ], [ %377, %351 ], [ %324, %279 ]
  %387 = phi <8 x i16> [ %348, %336 ], [ %375, %351 ], [ %321, %279 ]
  %388 = phi <8 x i16> [ %347, %336 ], [ %373, %351 ], [ %318, %279 ]
  %389 = phi <8 x i16> [ %346, %336 ], [ %371, %351 ], [ %315, %279 ]
  %390 = phi <8 x i16> [ %345, %336 ], [ %369, %351 ], [ %312, %279 ]
  %391 = phi <8 x i16> [ %344, %336 ], [ %367, %351 ], [ %309, %279 ]
  %392 = phi <8 x i16> [ %343, %336 ], [ %365, %351 ], [ %306, %279 ]
  %393 = phi <8 x i16> [ %342, %336 ], [ %363, %351 ], [ %303, %279 ]
  %394 = phi <8 x i16> [ %341, %336 ], [ %361, %351 ], [ %300, %279 ]
  %395 = phi <8 x i16> [ %340, %336 ], [ %359, %351 ], [ %297, %279 ]
  %396 = phi <8 x i16> [ %339, %336 ], [ %357, %351 ], [ %294, %279 ]
  %397 = phi <8 x i16> [ %338, %336 ], [ %355, %351 ], [ %291, %279 ]
  %398 = phi <8 x i16> [ %337, %336 ], [ %353, %351 ], [ %288, %279 ]
  %399 = getelementptr inbounds [128 x <2 x i64>], [128 x <2 x i64>]* %7, i64 0, i64 %144
  %400 = shufflevector <8 x i16> %398, <8 x i16> %397, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %401 = shufflevector <8 x i16> %396, <8 x i16> %395, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %402 = shufflevector <8 x i16> %394, <8 x i16> %393, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %403 = shufflevector <8 x i16> %392, <8 x i16> %391, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %404 = shufflevector <8 x i16> %398, <8 x i16> %397, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %405 = shufflevector <8 x i16> %396, <8 x i16> %395, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %406 = shufflevector <8 x i16> %394, <8 x i16> %393, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %407 = shufflevector <8 x i16> %392, <8 x i16> %391, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %408 = bitcast <8 x i16> %400 to <4 x i32>
  %409 = bitcast <8 x i16> %401 to <4 x i32>
  %410 = shufflevector <4 x i32> %408, <4 x i32> %409, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %411 = bitcast <4 x i32> %410 to <2 x i64>
  %412 = bitcast <8 x i16> %402 to <4 x i32>
  %413 = bitcast <8 x i16> %403 to <4 x i32>
  %414 = shufflevector <4 x i32> %412, <4 x i32> %413, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %415 = bitcast <4 x i32> %414 to <2 x i64>
  %416 = bitcast <8 x i16> %404 to <4 x i32>
  %417 = bitcast <8 x i16> %405 to <4 x i32>
  %418 = shufflevector <4 x i32> %416, <4 x i32> %417, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %419 = bitcast <4 x i32> %418 to <2 x i64>
  %420 = bitcast <8 x i16> %406 to <4 x i32>
  %421 = bitcast <8 x i16> %407 to <4 x i32>
  %422 = shufflevector <4 x i32> %420, <4 x i32> %421, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %423 = bitcast <4 x i32> %422 to <2 x i64>
  %424 = shufflevector <4 x i32> %408, <4 x i32> %409, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %425 = bitcast <4 x i32> %424 to <2 x i64>
  %426 = shufflevector <4 x i32> %412, <4 x i32> %413, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %427 = bitcast <4 x i32> %426 to <2 x i64>
  %428 = shufflevector <4 x i32> %416, <4 x i32> %417, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %429 = bitcast <4 x i32> %428 to <2 x i64>
  %430 = shufflevector <4 x i32> %420, <4 x i32> %421, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %431 = bitcast <4 x i32> %430 to <2 x i64>
  %432 = shufflevector <2 x i64> %411, <2 x i64> %415, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %432, <2 x i64>* %399, align 16
  %433 = shufflevector <2 x i64> %411, <2 x i64> %415, <2 x i32> <i32 1, i32 3>
  %434 = getelementptr inbounds <2 x i64>, <2 x i64>* %399, i64 1
  store <2 x i64> %433, <2 x i64>* %434, align 16
  %435 = shufflevector <2 x i64> %425, <2 x i64> %427, <2 x i32> <i32 0, i32 2>
  %436 = getelementptr inbounds <2 x i64>, <2 x i64>* %399, i64 2
  store <2 x i64> %435, <2 x i64>* %436, align 16
  %437 = shufflevector <2 x i64> %425, <2 x i64> %427, <2 x i32> <i32 1, i32 3>
  %438 = getelementptr inbounds <2 x i64>, <2 x i64>* %399, i64 3
  store <2 x i64> %437, <2 x i64>* %438, align 16
  %439 = shufflevector <2 x i64> %419, <2 x i64> %423, <2 x i32> <i32 0, i32 2>
  %440 = getelementptr inbounds <2 x i64>, <2 x i64>* %399, i64 4
  store <2 x i64> %439, <2 x i64>* %440, align 16
  %441 = shufflevector <2 x i64> %419, <2 x i64> %423, <2 x i32> <i32 1, i32 3>
  %442 = getelementptr inbounds <2 x i64>, <2 x i64>* %399, i64 5
  store <2 x i64> %441, <2 x i64>* %442, align 16
  %443 = shufflevector <2 x i64> %429, <2 x i64> %431, <2 x i32> <i32 0, i32 2>
  %444 = getelementptr inbounds <2 x i64>, <2 x i64>* %399, i64 6
  store <2 x i64> %443, <2 x i64>* %444, align 16
  %445 = shufflevector <2 x i64> %429, <2 x i64> %431, <2 x i32> <i32 1, i32 3>
  %446 = getelementptr inbounds <2 x i64>, <2 x i64>* %399, i64 7
  store <2 x i64> %445, <2 x i64>* %446, align 16
  %447 = getelementptr inbounds <2 x i64>, <2 x i64>* %135, i64 %144
  %448 = shufflevector <8 x i16> %390, <8 x i16> %389, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %449 = shufflevector <8 x i16> %388, <8 x i16> %387, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %450 = shufflevector <8 x i16> %386, <8 x i16> %385, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %451 = load <8 x i16>, <8 x i16>* %137, align 16
  %452 = load <8 x i16>, <8 x i16>* %139, align 16
  %453 = shufflevector <8 x i16> %451, <8 x i16> %452, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %454 = shufflevector <8 x i16> %390, <8 x i16> %389, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %455 = shufflevector <8 x i16> %388, <8 x i16> %387, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %456 = shufflevector <8 x i16> %386, <8 x i16> %385, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %457 = shufflevector <8 x i16> %451, <8 x i16> %452, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %458 = bitcast <8 x i16> %448 to <4 x i32>
  %459 = bitcast <8 x i16> %449 to <4 x i32>
  %460 = shufflevector <4 x i32> %458, <4 x i32> %459, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %461 = bitcast <4 x i32> %460 to <2 x i64>
  %462 = bitcast <8 x i16> %450 to <4 x i32>
  %463 = bitcast <8 x i16> %453 to <4 x i32>
  %464 = shufflevector <4 x i32> %462, <4 x i32> %463, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %465 = bitcast <4 x i32> %464 to <2 x i64>
  %466 = bitcast <8 x i16> %454 to <4 x i32>
  %467 = bitcast <8 x i16> %455 to <4 x i32>
  %468 = shufflevector <4 x i32> %466, <4 x i32> %467, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %469 = bitcast <4 x i32> %468 to <2 x i64>
  %470 = bitcast <8 x i16> %456 to <4 x i32>
  %471 = bitcast <8 x i16> %457 to <4 x i32>
  %472 = shufflevector <4 x i32> %470, <4 x i32> %471, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %473 = bitcast <4 x i32> %472 to <2 x i64>
  %474 = shufflevector <4 x i32> %458, <4 x i32> %459, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %475 = bitcast <4 x i32> %474 to <2 x i64>
  %476 = shufflevector <4 x i32> %462, <4 x i32> %463, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %477 = bitcast <4 x i32> %476 to <2 x i64>
  %478 = shufflevector <4 x i32> %466, <4 x i32> %467, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %479 = bitcast <4 x i32> %478 to <2 x i64>
  %480 = shufflevector <4 x i32> %470, <4 x i32> %471, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %481 = bitcast <4 x i32> %480 to <2 x i64>
  %482 = shufflevector <2 x i64> %461, <2 x i64> %465, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %482, <2 x i64>* %447, align 16
  %483 = shufflevector <2 x i64> %461, <2 x i64> %465, <2 x i32> <i32 1, i32 3>
  %484 = getelementptr inbounds <2 x i64>, <2 x i64>* %447, i64 1
  store <2 x i64> %483, <2 x i64>* %484, align 16
  %485 = shufflevector <2 x i64> %475, <2 x i64> %477, <2 x i32> <i32 0, i32 2>
  %486 = getelementptr inbounds <2 x i64>, <2 x i64>* %447, i64 2
  store <2 x i64> %485, <2 x i64>* %486, align 16
  %487 = shufflevector <2 x i64> %475, <2 x i64> %477, <2 x i32> <i32 1, i32 3>
  %488 = getelementptr inbounds <2 x i64>, <2 x i64>* %447, i64 3
  store <2 x i64> %487, <2 x i64>* %488, align 16
  %489 = shufflevector <2 x i64> %469, <2 x i64> %473, <2 x i32> <i32 0, i32 2>
  %490 = getelementptr inbounds <2 x i64>, <2 x i64>* %447, i64 4
  store <2 x i64> %489, <2 x i64>* %490, align 16
  %491 = shufflevector <2 x i64> %469, <2 x i64> %473, <2 x i32> <i32 1, i32 3>
  %492 = getelementptr inbounds <2 x i64>, <2 x i64>* %447, i64 5
  store <2 x i64> %491, <2 x i64>* %492, align 16
  %493 = shufflevector <2 x i64> %479, <2 x i64> %481, <2 x i32> <i32 0, i32 2>
  %494 = getelementptr inbounds <2 x i64>, <2 x i64>* %447, i64 6
  store <2 x i64> %493, <2 x i64>* %494, align 16
  %495 = shufflevector <2 x i64> %479, <2 x i64> %481, <2 x i32> <i32 1, i32 3>
  %496 = getelementptr inbounds <2 x i64>, <2 x i64>* %447, i64 7
  store <2 x i64> %495, <2 x i64>* %496, align 16
  %497 = add nuw nsw i64 %143, 1
  %498 = icmp eq i64 %497, 8
  br i1 %498, label %140, label %142

499:                                              ; preds = %569
  call void @llvm.lifetime.end.p0i8(i64 2048, i8* nonnull %9) #8
  call void @llvm.lifetime.end.p0i8(i64 1024, i8* nonnull %8) #8
  ret void

500:                                              ; preds = %569, %140
  %501 = phi i64 [ 0, %140 ], [ %570, %569 ]
  %502 = shl nsw i64 %501, 6
  %503 = getelementptr inbounds [128 x <2 x i64>], [128 x <2 x i64>]* %7, i64 0, i64 %502
  call void @av1_fdct8x64_new_sse2(<2 x i64>* %503, <2 x i64>* %503, i8 signext %12)
  %504 = load i8, i8* %141, align 1
  %505 = sext i8 %504 to i32
  %506 = icmp slt i8 %504, 0
  br i1 %506, label %507, label %541

507:                                              ; preds = %500
  %508 = sub nsw i32 0, %505
  %509 = xor i32 %505, -1
  %510 = shl i32 1, %509
  %511 = trunc i32 %510 to i16
  %512 = insertelement <8 x i16> undef, i16 %511, i32 0
  %513 = shufflevector <8 x i16> %512, <8 x i16> undef, <8 x i32> zeroinitializer
  br label %514

514:                                              ; preds = %514, %507
  %515 = phi i64 [ 0, %507 ], [ %539, %514 ]
  %516 = getelementptr inbounds <2 x i64>, <2 x i64>* %503, i64 %515
  %517 = bitcast <2 x i64>* %516 to <8 x i16>*
  %518 = load <8 x i16>, <8 x i16>* %517, align 16
  %519 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %518, <8 x i16> %513) #8
  %520 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %519, i32 %508) #8
  store <8 x i16> %520, <8 x i16>* %517, align 16
  %521 = or i64 %515, 1
  %522 = getelementptr inbounds <2 x i64>, <2 x i64>* %503, i64 %521
  %523 = bitcast <2 x i64>* %522 to <8 x i16>*
  %524 = load <8 x i16>, <8 x i16>* %523, align 16
  %525 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %524, <8 x i16> %513) #8
  %526 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %525, i32 %508) #8
  store <8 x i16> %526, <8 x i16>* %523, align 16
  %527 = or i64 %515, 2
  %528 = getelementptr inbounds <2 x i64>, <2 x i64>* %503, i64 %527
  %529 = bitcast <2 x i64>* %528 to <8 x i16>*
  %530 = load <8 x i16>, <8 x i16>* %529, align 16
  %531 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %530, <8 x i16> %513) #8
  %532 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %531, i32 %508) #8
  store <8 x i16> %532, <8 x i16>* %529, align 16
  %533 = or i64 %515, 3
  %534 = getelementptr inbounds <2 x i64>, <2 x i64>* %503, i64 %533
  %535 = bitcast <2 x i64>* %534 to <8 x i16>*
  %536 = load <8 x i16>, <8 x i16>* %535, align 16
  %537 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %536, <8 x i16> %513) #8
  %538 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %537, i32 %508) #8
  store <8 x i16> %538, <8 x i16>* %535, align 16
  %539 = add nuw nsw i64 %515, 4
  %540 = icmp eq i64 %539, 64
  br i1 %540, label %566, label %514

541:                                              ; preds = %500
  %542 = icmp eq i8 %504, 0
  br i1 %542, label %566, label %543

543:                                              ; preds = %541, %543
  %544 = phi i64 [ %564, %543 ], [ 0, %541 ]
  %545 = getelementptr inbounds <2 x i64>, <2 x i64>* %503, i64 %544
  %546 = bitcast <2 x i64>* %545 to <8 x i16>*
  %547 = load <8 x i16>, <8 x i16>* %546, align 16
  %548 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %547, i32 %505) #8
  store <8 x i16> %548, <8 x i16>* %546, align 16
  %549 = or i64 %544, 1
  %550 = getelementptr inbounds <2 x i64>, <2 x i64>* %503, i64 %549
  %551 = bitcast <2 x i64>* %550 to <8 x i16>*
  %552 = load <8 x i16>, <8 x i16>* %551, align 16
  %553 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %552, i32 %505) #8
  store <8 x i16> %553, <8 x i16>* %551, align 16
  %554 = or i64 %544, 2
  %555 = getelementptr inbounds <2 x i64>, <2 x i64>* %503, i64 %554
  %556 = bitcast <2 x i64>* %555 to <8 x i16>*
  %557 = load <8 x i16>, <8 x i16>* %556, align 16
  %558 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %557, i32 %505) #8
  store <8 x i16> %558, <8 x i16>* %556, align 16
  %559 = or i64 %544, 3
  %560 = getelementptr inbounds <2 x i64>, <2 x i64>* %503, i64 %559
  %561 = bitcast <2 x i64>* %560 to <8 x i16>*
  %562 = load <8 x i16>, <8 x i16>* %561, align 16
  %563 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %562, i32 %505) #8
  store <8 x i16> %563, <8 x i16>* %561, align 16
  %564 = add nuw nsw i64 %544, 4
  %565 = icmp eq i64 %564, 64
  br i1 %565, label %566, label %543

566:                                              ; preds = %543, %514, %541
  %567 = shl nsw i64 %501, 8
  %568 = getelementptr inbounds i32, i32* %1, i64 %567
  br label %572

569:                                              ; preds = %572
  %570 = add nuw nsw i64 %501, 1
  %571 = icmp eq i64 %570, 2
  br i1 %571, label %499, label %500

572:                                              ; preds = %572, %566
  %573 = phi i64 [ 0, %566 ], [ %727, %572 ]
  %574 = shl nsw i64 %573, 3
  %575 = getelementptr inbounds <2 x i64>, <2 x i64>* %503, i64 %574
  %576 = bitcast <2 x i64>* %575 to <8 x i16>*
  %577 = load <8 x i16>, <8 x i16>* %576, align 16
  %578 = getelementptr inbounds <2 x i64>, <2 x i64>* %575, i64 1
  %579 = bitcast <2 x i64>* %578 to <8 x i16>*
  %580 = load <8 x i16>, <8 x i16>* %579, align 16
  %581 = shufflevector <8 x i16> %577, <8 x i16> %580, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %582 = getelementptr inbounds <2 x i64>, <2 x i64>* %575, i64 2
  %583 = bitcast <2 x i64>* %582 to <8 x i16>*
  %584 = load <8 x i16>, <8 x i16>* %583, align 16
  %585 = getelementptr inbounds <2 x i64>, <2 x i64>* %575, i64 3
  %586 = bitcast <2 x i64>* %585 to <8 x i16>*
  %587 = load <8 x i16>, <8 x i16>* %586, align 16
  %588 = shufflevector <8 x i16> %584, <8 x i16> %587, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %589 = getelementptr inbounds <2 x i64>, <2 x i64>* %575, i64 4
  %590 = bitcast <2 x i64>* %589 to <8 x i16>*
  %591 = load <8 x i16>, <8 x i16>* %590, align 16
  %592 = getelementptr inbounds <2 x i64>, <2 x i64>* %575, i64 5
  %593 = bitcast <2 x i64>* %592 to <8 x i16>*
  %594 = load <8 x i16>, <8 x i16>* %593, align 16
  %595 = shufflevector <8 x i16> %591, <8 x i16> %594, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %596 = getelementptr inbounds <2 x i64>, <2 x i64>* %575, i64 6
  %597 = bitcast <2 x i64>* %596 to <8 x i16>*
  %598 = load <8 x i16>, <8 x i16>* %597, align 16
  %599 = getelementptr inbounds <2 x i64>, <2 x i64>* %575, i64 7
  %600 = bitcast <2 x i64>* %599 to <8 x i16>*
  %601 = load <8 x i16>, <8 x i16>* %600, align 16
  %602 = shufflevector <8 x i16> %598, <8 x i16> %601, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %603 = shufflevector <8 x i16> %577, <8 x i16> %580, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %604 = shufflevector <8 x i16> %584, <8 x i16> %587, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %605 = shufflevector <8 x i16> %591, <8 x i16> %594, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %606 = shufflevector <8 x i16> %598, <8 x i16> %601, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %607 = bitcast <8 x i16> %581 to <4 x i32>
  %608 = bitcast <8 x i16> %588 to <4 x i32>
  %609 = shufflevector <4 x i32> %607, <4 x i32> %608, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %610 = bitcast <4 x i32> %609 to <2 x i64>
  %611 = bitcast <8 x i16> %595 to <4 x i32>
  %612 = bitcast <8 x i16> %602 to <4 x i32>
  %613 = shufflevector <4 x i32> %611, <4 x i32> %612, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %614 = bitcast <4 x i32> %613 to <2 x i64>
  %615 = bitcast <8 x i16> %603 to <4 x i32>
  %616 = bitcast <8 x i16> %604 to <4 x i32>
  %617 = shufflevector <4 x i32> %615, <4 x i32> %616, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %618 = bitcast <4 x i32> %617 to <2 x i64>
  %619 = bitcast <8 x i16> %605 to <4 x i32>
  %620 = bitcast <8 x i16> %606 to <4 x i32>
  %621 = shufflevector <4 x i32> %619, <4 x i32> %620, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %622 = bitcast <4 x i32> %621 to <2 x i64>
  %623 = shufflevector <4 x i32> %607, <4 x i32> %608, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %624 = bitcast <4 x i32> %623 to <2 x i64>
  %625 = shufflevector <4 x i32> %611, <4 x i32> %612, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %626 = bitcast <4 x i32> %625 to <2 x i64>
  %627 = shufflevector <4 x i32> %615, <4 x i32> %616, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %628 = bitcast <4 x i32> %627 to <2 x i64>
  %629 = shufflevector <4 x i32> %619, <4 x i32> %620, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %630 = bitcast <4 x i32> %629 to <2 x i64>
  %631 = shufflevector <2 x i64> %610, <2 x i64> %614, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %631, <2 x i64>* %575, align 16
  %632 = shufflevector <2 x i64> %610, <2 x i64> %614, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %632, <2 x i64>* %578, align 16
  %633 = shufflevector <2 x i64> %624, <2 x i64> %626, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %633, <2 x i64>* %582, align 16
  %634 = shufflevector <2 x i64> %624, <2 x i64> %626, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %634, <2 x i64>* %585, align 16
  %635 = shufflevector <2 x i64> %618, <2 x i64> %622, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %635, <2 x i64>* %589, align 16
  %636 = shufflevector <2 x i64> %618, <2 x i64> %622, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %636, <2 x i64>* %592, align 16
  %637 = shufflevector <2 x i64> %628, <2 x i64> %630, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %637, <2 x i64>* %596, align 16
  %638 = shufflevector <2 x i64> %628, <2 x i64> %630, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %638, <2 x i64>* %599, align 16
  %639 = getelementptr inbounds i32, i32* %568, i64 %574
  %640 = bitcast <2 x i64> %631 to <8 x i16>
  %641 = shufflevector <8 x i16> %640, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %642 = shufflevector <8 x i16> %640, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %643 = bitcast <8 x i16> %641 to <4 x i32>
  %644 = ashr <4 x i32> %643, <i32 16, i32 16, i32 16, i32 16>
  %645 = bitcast <8 x i16> %642 to <4 x i32>
  %646 = ashr <4 x i32> %645, <i32 16, i32 16, i32 16, i32 16>
  %647 = bitcast i32* %639 to <4 x i32>*
  store <4 x i32> %644, <4 x i32>* %647, align 16
  %648 = getelementptr inbounds i32, i32* %639, i64 4
  %649 = bitcast i32* %648 to <4 x i32>*
  store <4 x i32> %646, <4 x i32>* %649, align 16
  %650 = bitcast <2 x i64> %632 to <8 x i16>
  %651 = getelementptr inbounds i32, i32* %639, i64 32
  %652 = shufflevector <8 x i16> %650, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %653 = shufflevector <8 x i16> %650, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %654 = bitcast <8 x i16> %652 to <4 x i32>
  %655 = ashr <4 x i32> %654, <i32 16, i32 16, i32 16, i32 16>
  %656 = bitcast <8 x i16> %653 to <4 x i32>
  %657 = ashr <4 x i32> %656, <i32 16, i32 16, i32 16, i32 16>
  %658 = bitcast i32* %651 to <4 x i32>*
  store <4 x i32> %655, <4 x i32>* %658, align 16
  %659 = getelementptr inbounds i32, i32* %651, i64 4
  %660 = bitcast i32* %659 to <4 x i32>*
  store <4 x i32> %657, <4 x i32>* %660, align 16
  %661 = bitcast <2 x i64> %633 to <8 x i16>
  %662 = getelementptr inbounds i32, i32* %639, i64 64
  %663 = shufflevector <8 x i16> %661, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %664 = shufflevector <8 x i16> %661, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %665 = bitcast <8 x i16> %663 to <4 x i32>
  %666 = ashr <4 x i32> %665, <i32 16, i32 16, i32 16, i32 16>
  %667 = bitcast <8 x i16> %664 to <4 x i32>
  %668 = ashr <4 x i32> %667, <i32 16, i32 16, i32 16, i32 16>
  %669 = bitcast i32* %662 to <4 x i32>*
  store <4 x i32> %666, <4 x i32>* %669, align 16
  %670 = getelementptr inbounds i32, i32* %662, i64 4
  %671 = bitcast i32* %670 to <4 x i32>*
  store <4 x i32> %668, <4 x i32>* %671, align 16
  %672 = bitcast <2 x i64> %634 to <8 x i16>
  %673 = getelementptr inbounds i32, i32* %639, i64 96
  %674 = shufflevector <8 x i16> %672, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %675 = shufflevector <8 x i16> %672, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %676 = bitcast <8 x i16> %674 to <4 x i32>
  %677 = ashr <4 x i32> %676, <i32 16, i32 16, i32 16, i32 16>
  %678 = bitcast <8 x i16> %675 to <4 x i32>
  %679 = ashr <4 x i32> %678, <i32 16, i32 16, i32 16, i32 16>
  %680 = bitcast i32* %673 to <4 x i32>*
  store <4 x i32> %677, <4 x i32>* %680, align 16
  %681 = getelementptr inbounds i32, i32* %673, i64 4
  %682 = bitcast i32* %681 to <4 x i32>*
  store <4 x i32> %679, <4 x i32>* %682, align 16
  %683 = bitcast <2 x i64> %635 to <8 x i16>
  %684 = getelementptr inbounds i32, i32* %639, i64 128
  %685 = shufflevector <8 x i16> %683, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %686 = shufflevector <8 x i16> %683, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %687 = bitcast <8 x i16> %685 to <4 x i32>
  %688 = ashr <4 x i32> %687, <i32 16, i32 16, i32 16, i32 16>
  %689 = bitcast <8 x i16> %686 to <4 x i32>
  %690 = ashr <4 x i32> %689, <i32 16, i32 16, i32 16, i32 16>
  %691 = bitcast i32* %684 to <4 x i32>*
  store <4 x i32> %688, <4 x i32>* %691, align 16
  %692 = getelementptr inbounds i32, i32* %684, i64 4
  %693 = bitcast i32* %692 to <4 x i32>*
  store <4 x i32> %690, <4 x i32>* %693, align 16
  %694 = bitcast <2 x i64> %636 to <8 x i16>
  %695 = getelementptr inbounds i32, i32* %639, i64 160
  %696 = shufflevector <8 x i16> %694, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %697 = shufflevector <8 x i16> %694, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %698 = bitcast <8 x i16> %696 to <4 x i32>
  %699 = ashr <4 x i32> %698, <i32 16, i32 16, i32 16, i32 16>
  %700 = bitcast <8 x i16> %697 to <4 x i32>
  %701 = ashr <4 x i32> %700, <i32 16, i32 16, i32 16, i32 16>
  %702 = bitcast i32* %695 to <4 x i32>*
  store <4 x i32> %699, <4 x i32>* %702, align 16
  %703 = getelementptr inbounds i32, i32* %695, i64 4
  %704 = bitcast i32* %703 to <4 x i32>*
  store <4 x i32> %701, <4 x i32>* %704, align 16
  %705 = bitcast <2 x i64> %637 to <8 x i16>
  %706 = getelementptr inbounds i32, i32* %639, i64 192
  %707 = shufflevector <8 x i16> %705, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %708 = shufflevector <8 x i16> %705, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %709 = bitcast <8 x i16> %707 to <4 x i32>
  %710 = ashr <4 x i32> %709, <i32 16, i32 16, i32 16, i32 16>
  %711 = bitcast <8 x i16> %708 to <4 x i32>
  %712 = ashr <4 x i32> %711, <i32 16, i32 16, i32 16, i32 16>
  %713 = bitcast i32* %706 to <4 x i32>*
  store <4 x i32> %710, <4 x i32>* %713, align 16
  %714 = getelementptr inbounds i32, i32* %706, i64 4
  %715 = bitcast i32* %714 to <4 x i32>*
  store <4 x i32> %712, <4 x i32>* %715, align 16
  %716 = bitcast <2 x i64> %638 to <8 x i16>
  %717 = getelementptr inbounds i32, i32* %639, i64 224
  %718 = shufflevector <8 x i16> %716, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %719 = shufflevector <8 x i16> %716, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %720 = bitcast <8 x i16> %718 to <4 x i32>
  %721 = ashr <4 x i32> %720, <i32 16, i32 16, i32 16, i32 16>
  %722 = bitcast <8 x i16> %719 to <4 x i32>
  %723 = ashr <4 x i32> %722, <i32 16, i32 16, i32 16, i32 16>
  %724 = bitcast i32* %717 to <4 x i32>*
  store <4 x i32> %721, <4 x i32>* %724, align 16
  %725 = getelementptr inbounds i32, i32* %717, i64 4
  %726 = bitcast i32* %725 to <4 x i32>*
  store <4 x i32> %723, <4 x i32>* %726, align 16
  %727 = add nuw nsw i64 %573, 1
  %728 = icmp eq i64 %727, 4
  br i1 %728, label %569, label %572
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @fdct8x16_new_sse2(<2 x i64>* nocapture readonly, <2 x i64>* nocapture, i8 signext) #0 {
  %4 = sext i8 %2 to i32
  %5 = add nsw i32 %4, -10
  %6 = sext i32 %5 to i64
  %7 = add nsw i32 %4, -1
  %8 = shl i32 1, %7
  %9 = insertelement <4 x i32> undef, i32 %8, i32 0
  %10 = shufflevector <4 x i32> %9, <4 x i32> undef, <4 x i32> zeroinitializer
  %11 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 32
  %12 = load i32, i32* %11, align 16
  %13 = sub i32 0, %12
  %14 = and i32 %13, 65535
  %15 = shl i32 %12, 16
  %16 = or i32 %14, %15
  %17 = insertelement <4 x i32> undef, i32 %16, i32 0
  %18 = shufflevector <4 x i32> %17, <4 x i32> undef, <4 x i32> zeroinitializer
  %19 = and i32 %12, 65535
  %20 = or i32 %19, %15
  %21 = insertelement <4 x i32> undef, i32 %20, i32 0
  %22 = shufflevector <4 x i32> %21, <4 x i32> undef, <4 x i32> zeroinitializer
  %23 = sub i32 0, %15
  %24 = or i32 %19, %23
  %25 = insertelement <4 x i32> undef, i32 %24, i32 0
  %26 = shufflevector <4 x i32> %25, <4 x i32> undef, <4 x i32> zeroinitializer
  %27 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 48
  %28 = load i32, i32* %27, align 16
  %29 = and i32 %28, 65535
  %30 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 16
  %31 = load i32, i32* %30, align 16
  %32 = shl i32 %31, 16
  %33 = or i32 %32, %29
  %34 = insertelement <4 x i32> undef, i32 %33, i32 0
  %35 = shufflevector <4 x i32> %34, <4 x i32> undef, <4 x i32> zeroinitializer
  %36 = sub i32 0, %31
  %37 = and i32 %36, 65535
  %38 = shl i32 %28, 16
  %39 = or i32 %37, %38
  %40 = insertelement <4 x i32> undef, i32 %39, i32 0
  %41 = shufflevector <4 x i32> %40, <4 x i32> undef, <4 x i32> zeroinitializer
  %42 = sub i32 0, %28
  %43 = and i32 %42, 65535
  %44 = sub i32 0, %32
  %45 = or i32 %43, %44
  %46 = insertelement <4 x i32> undef, i32 %45, i32 0
  %47 = shufflevector <4 x i32> %46, <4 x i32> undef, <4 x i32> zeroinitializer
  %48 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 56
  %49 = load i32, i32* %48, align 16
  %50 = and i32 %49, 65535
  %51 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 8
  %52 = load i32, i32* %51, align 16
  %53 = shl i32 %52, 16
  %54 = or i32 %53, %50
  %55 = insertelement <4 x i32> undef, i32 %54, i32 0
  %56 = shufflevector <4 x i32> %55, <4 x i32> undef, <4 x i32> zeroinitializer
  %57 = sub i32 0, %52
  %58 = and i32 %57, 65535
  %59 = shl i32 %49, 16
  %60 = or i32 %58, %59
  %61 = insertelement <4 x i32> undef, i32 %60, i32 0
  %62 = shufflevector <4 x i32> %61, <4 x i32> undef, <4 x i32> zeroinitializer
  %63 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 24
  %64 = load i32, i32* %63, align 16
  %65 = and i32 %64, 65535
  %66 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 40
  %67 = load i32, i32* %66, align 16
  %68 = shl i32 %67, 16
  %69 = or i32 %68, %65
  %70 = insertelement <4 x i32> undef, i32 %69, i32 0
  %71 = shufflevector <4 x i32> %70, <4 x i32> undef, <4 x i32> zeroinitializer
  %72 = sub i32 0, %67
  %73 = and i32 %72, 65535
  %74 = shl i32 %64, 16
  %75 = or i32 %73, %74
  %76 = insertelement <4 x i32> undef, i32 %75, i32 0
  %77 = shufflevector <4 x i32> %76, <4 x i32> undef, <4 x i32> zeroinitializer
  %78 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 60
  %79 = load i32, i32* %78, align 16
  %80 = and i32 %79, 65535
  %81 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 4
  %82 = load i32, i32* %81, align 16
  %83 = shl i32 %82, 16
  %84 = or i32 %83, %80
  %85 = insertelement <4 x i32> undef, i32 %84, i32 0
  %86 = shufflevector <4 x i32> %85, <4 x i32> undef, <4 x i32> zeroinitializer
  %87 = sub i32 0, %82
  %88 = and i32 %87, 65535
  %89 = shl i32 %79, 16
  %90 = or i32 %88, %89
  %91 = insertelement <4 x i32> undef, i32 %90, i32 0
  %92 = shufflevector <4 x i32> %91, <4 x i32> undef, <4 x i32> zeroinitializer
  %93 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 28
  %94 = load i32, i32* %93, align 16
  %95 = and i32 %94, 65535
  %96 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 36
  %97 = load i32, i32* %96, align 16
  %98 = shl i32 %97, 16
  %99 = or i32 %98, %95
  %100 = insertelement <4 x i32> undef, i32 %99, i32 0
  %101 = shufflevector <4 x i32> %100, <4 x i32> undef, <4 x i32> zeroinitializer
  %102 = sub i32 0, %97
  %103 = and i32 %102, 65535
  %104 = shl i32 %94, 16
  %105 = or i32 %103, %104
  %106 = insertelement <4 x i32> undef, i32 %105, i32 0
  %107 = shufflevector <4 x i32> %106, <4 x i32> undef, <4 x i32> zeroinitializer
  %108 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 44
  %109 = load i32, i32* %108, align 16
  %110 = and i32 %109, 65535
  %111 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 20
  %112 = load i32, i32* %111, align 16
  %113 = shl i32 %112, 16
  %114 = or i32 %113, %110
  %115 = insertelement <4 x i32> undef, i32 %114, i32 0
  %116 = shufflevector <4 x i32> %115, <4 x i32> undef, <4 x i32> zeroinitializer
  %117 = sub i32 0, %112
  %118 = and i32 %117, 65535
  %119 = shl i32 %109, 16
  %120 = or i32 %118, %119
  %121 = insertelement <4 x i32> undef, i32 %120, i32 0
  %122 = shufflevector <4 x i32> %121, <4 x i32> undef, <4 x i32> zeroinitializer
  %123 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 12
  %124 = load i32, i32* %123, align 16
  %125 = and i32 %124, 65535
  %126 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 52
  %127 = load i32, i32* %126, align 16
  %128 = shl i32 %127, 16
  %129 = or i32 %128, %125
  %130 = insertelement <4 x i32> undef, i32 %129, i32 0
  %131 = shufflevector <4 x i32> %130, <4 x i32> undef, <4 x i32> zeroinitializer
  %132 = sub i32 0, %127
  %133 = and i32 %132, 65535
  %134 = shl i32 %124, 16
  %135 = or i32 %133, %134
  %136 = insertelement <4 x i32> undef, i32 %135, i32 0
  %137 = shufflevector <4 x i32> %136, <4 x i32> undef, <4 x i32> zeroinitializer
  %138 = bitcast <2 x i64>* %0 to <8 x i16>*
  %139 = load <8 x i16>, <8 x i16>* %138, align 16
  %140 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 15
  %141 = bitcast <2 x i64>* %140 to <8 x i16>*
  %142 = load <8 x i16>, <8 x i16>* %141, align 16
  %143 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %139, <8 x i16> %142) #8
  %144 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %139, <8 x i16> %142) #8
  %145 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %146 = bitcast <2 x i64>* %145 to <8 x i16>*
  %147 = load <8 x i16>, <8 x i16>* %146, align 16
  %148 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 14
  %149 = bitcast <2 x i64>* %148 to <8 x i16>*
  %150 = load <8 x i16>, <8 x i16>* %149, align 16
  %151 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %147, <8 x i16> %150) #8
  %152 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %147, <8 x i16> %150) #8
  %153 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %154 = bitcast <2 x i64>* %153 to <8 x i16>*
  %155 = load <8 x i16>, <8 x i16>* %154, align 16
  %156 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 13
  %157 = bitcast <2 x i64>* %156 to <8 x i16>*
  %158 = load <8 x i16>, <8 x i16>* %157, align 16
  %159 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %155, <8 x i16> %158) #8
  %160 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %155, <8 x i16> %158) #8
  %161 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %162 = bitcast <2 x i64>* %161 to <8 x i16>*
  %163 = load <8 x i16>, <8 x i16>* %162, align 16
  %164 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 12
  %165 = bitcast <2 x i64>* %164 to <8 x i16>*
  %166 = load <8 x i16>, <8 x i16>* %165, align 16
  %167 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %163, <8 x i16> %166) #8
  %168 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %163, <8 x i16> %166) #8
  %169 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %170 = bitcast <2 x i64>* %169 to <8 x i16>*
  %171 = load <8 x i16>, <8 x i16>* %170, align 16
  %172 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 11
  %173 = bitcast <2 x i64>* %172 to <8 x i16>*
  %174 = load <8 x i16>, <8 x i16>* %173, align 16
  %175 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %171, <8 x i16> %174) #8
  %176 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %171, <8 x i16> %174) #8
  %177 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %178 = bitcast <2 x i64>* %177 to <8 x i16>*
  %179 = load <8 x i16>, <8 x i16>* %178, align 16
  %180 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 10
  %181 = bitcast <2 x i64>* %180 to <8 x i16>*
  %182 = load <8 x i16>, <8 x i16>* %181, align 16
  %183 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %179, <8 x i16> %182) #8
  %184 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %179, <8 x i16> %182) #8
  %185 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %186 = bitcast <2 x i64>* %185 to <8 x i16>*
  %187 = load <8 x i16>, <8 x i16>* %186, align 16
  %188 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 9
  %189 = bitcast <2 x i64>* %188 to <8 x i16>*
  %190 = load <8 x i16>, <8 x i16>* %189, align 16
  %191 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %187, <8 x i16> %190) #8
  %192 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %187, <8 x i16> %190) #8
  %193 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %194 = bitcast <2 x i64>* %193 to <8 x i16>*
  %195 = load <8 x i16>, <8 x i16>* %194, align 16
  %196 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 8
  %197 = bitcast <2 x i64>* %196 to <8 x i16>*
  %198 = load <8 x i16>, <8 x i16>* %197, align 16
  %199 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %195, <8 x i16> %198) #8
  %200 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %195, <8 x i16> %198) #8
  %201 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %143, <8 x i16> %199) #8
  %202 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %143, <8 x i16> %199) #8
  %203 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %151, <8 x i16> %191) #8
  %204 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %151, <8 x i16> %191) #8
  %205 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %159, <8 x i16> %183) #8
  %206 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %159, <8 x i16> %183) #8
  %207 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %167, <8 x i16> %175) #8
  %208 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %167, <8 x i16> %175) #8
  %209 = shufflevector <8 x i16> %184, <8 x i16> %160, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %210 = shufflevector <8 x i16> %184, <8 x i16> %160, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %211 = bitcast <4 x i32> %18 to <8 x i16>
  %212 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %209, <8 x i16> %211) #8
  %213 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %210, <8 x i16> %211) #8
  %214 = bitcast <4 x i32> %22 to <8 x i16>
  %215 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %209, <8 x i16> %214) #8
  %216 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %210, <8 x i16> %214) #8
  %217 = add <4 x i32> %212, %10
  %218 = add <4 x i32> %213, %10
  %219 = add <4 x i32> %215, %10
  %220 = add <4 x i32> %216, %10
  %221 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %217, i32 %4) #8
  %222 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %218, i32 %4) #8
  %223 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %219, i32 %4) #8
  %224 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %220, i32 %4) #8
  %225 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %221, <4 x i32> %222) #8
  %226 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %223, <4 x i32> %224) #8
  %227 = shufflevector <8 x i16> %176, <8 x i16> %168, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %228 = shufflevector <8 x i16> %176, <8 x i16> %168, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %229 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %227, <8 x i16> %211) #8
  %230 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %228, <8 x i16> %211) #8
  %231 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %227, <8 x i16> %214) #8
  %232 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %228, <8 x i16> %214) #8
  %233 = add <4 x i32> %229, %10
  %234 = add <4 x i32> %230, %10
  %235 = add <4 x i32> %231, %10
  %236 = add <4 x i32> %232, %10
  %237 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %233, i32 %4) #8
  %238 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %234, i32 %4) #8
  %239 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %235, i32 %4) #8
  %240 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %236, i32 %4) #8
  %241 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %237, <4 x i32> %238) #8
  %242 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %239, <4 x i32> %240) #8
  %243 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %201, <8 x i16> %207) #8
  %244 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %201, <8 x i16> %207) #8
  %245 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %203, <8 x i16> %205) #8
  %246 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %203, <8 x i16> %205) #8
  %247 = shufflevector <8 x i16> %206, <8 x i16> %204, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %248 = shufflevector <8 x i16> %206, <8 x i16> %204, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %249 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %247, <8 x i16> %211) #8
  %250 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %248, <8 x i16> %211) #8
  %251 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %247, <8 x i16> %214) #8
  %252 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %248, <8 x i16> %214) #8
  %253 = add <4 x i32> %249, %10
  %254 = add <4 x i32> %250, %10
  %255 = add <4 x i32> %251, %10
  %256 = add <4 x i32> %252, %10
  %257 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %253, i32 %4) #8
  %258 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %254, i32 %4) #8
  %259 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %255, i32 %4) #8
  %260 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %256, i32 %4) #8
  %261 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %257, <4 x i32> %258) #8
  %262 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %259, <4 x i32> %260) #8
  %263 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %200, <8 x i16> %241) #8
  %264 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %200, <8 x i16> %241) #8
  %265 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %192, <8 x i16> %225) #8
  %266 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %192, <8 x i16> %225) #8
  %267 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %144, <8 x i16> %242) #8
  %268 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %144, <8 x i16> %242) #8
  %269 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %152, <8 x i16> %226) #8
  %270 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %152, <8 x i16> %226) #8
  %271 = shufflevector <8 x i16> %243, <8 x i16> %245, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %272 = shufflevector <8 x i16> %243, <8 x i16> %245, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %273 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %271, <8 x i16> %214) #8
  %274 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %272, <8 x i16> %214) #8
  %275 = bitcast <4 x i32> %26 to <8 x i16>
  %276 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %271, <8 x i16> %275) #8
  %277 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %272, <8 x i16> %275) #8
  %278 = add <4 x i32> %273, %10
  %279 = add <4 x i32> %274, %10
  %280 = add <4 x i32> %276, %10
  %281 = add <4 x i32> %277, %10
  %282 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %278, i32 %4) #8
  %283 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %279, i32 %4) #8
  %284 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %280, i32 %4) #8
  %285 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %281, i32 %4) #8
  %286 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %282, <4 x i32> %283) #8
  %287 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %284, <4 x i32> %285) #8
  %288 = shufflevector <8 x i16> %246, <8 x i16> %244, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %289 = shufflevector <8 x i16> %246, <8 x i16> %244, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %290 = bitcast <4 x i32> %35 to <8 x i16>
  %291 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %288, <8 x i16> %290) #8
  %292 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %289, <8 x i16> %290) #8
  %293 = bitcast <4 x i32> %41 to <8 x i16>
  %294 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %288, <8 x i16> %293) #8
  %295 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %289, <8 x i16> %293) #8
  %296 = add <4 x i32> %291, %10
  %297 = add <4 x i32> %292, %10
  %298 = add <4 x i32> %294, %10
  %299 = add <4 x i32> %295, %10
  %300 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %296, i32 %4) #8
  %301 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %297, i32 %4) #8
  %302 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %298, i32 %4) #8
  %303 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %299, i32 %4) #8
  %304 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %300, <4 x i32> %301) #8
  %305 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %302, <4 x i32> %303) #8
  %306 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %208, <8 x i16> %261) #8
  %307 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %208, <8 x i16> %261) #8
  %308 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %202, <8 x i16> %262) #8
  %309 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %202, <8 x i16> %262) #8
  %310 = shufflevector <8 x i16> %265, <8 x i16> %270, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %311 = shufflevector <8 x i16> %265, <8 x i16> %270, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %312 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %310, <8 x i16> %293) #8
  %313 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %311, <8 x i16> %293) #8
  %314 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %310, <8 x i16> %290) #8
  %315 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %311, <8 x i16> %290) #8
  %316 = add <4 x i32> %312, %10
  %317 = add <4 x i32> %313, %10
  %318 = add <4 x i32> %314, %10
  %319 = add <4 x i32> %315, %10
  %320 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %316, i32 %4) #8
  %321 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %317, i32 %4) #8
  %322 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %318, i32 %4) #8
  %323 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %319, i32 %4) #8
  %324 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %320, <4 x i32> %321) #8
  %325 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %322, <4 x i32> %323) #8
  %326 = shufflevector <8 x i16> %266, <8 x i16> %269, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %327 = shufflevector <8 x i16> %266, <8 x i16> %269, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %328 = bitcast <4 x i32> %47 to <8 x i16>
  %329 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %326, <8 x i16> %328) #8
  %330 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %327, <8 x i16> %328) #8
  %331 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %326, <8 x i16> %293) #8
  %332 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %327, <8 x i16> %293) #8
  %333 = add <4 x i32> %329, %10
  %334 = add <4 x i32> %330, %10
  %335 = add <4 x i32> %331, %10
  %336 = add <4 x i32> %332, %10
  %337 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %333, i32 %4) #8
  %338 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %334, i32 %4) #8
  %339 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %335, i32 %4) #8
  %340 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %336, i32 %4) #8
  %341 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %337, <4 x i32> %338) #8
  %342 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %339, <4 x i32> %340) #8
  %343 = shufflevector <8 x i16> %306, <8 x i16> %309, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %344 = shufflevector <8 x i16> %306, <8 x i16> %309, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %345 = bitcast <4 x i32> %56 to <8 x i16>
  %346 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %343, <8 x i16> %345) #8
  %347 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %344, <8 x i16> %345) #8
  %348 = bitcast <4 x i32> %62 to <8 x i16>
  %349 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %343, <8 x i16> %348) #8
  %350 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %344, <8 x i16> %348) #8
  %351 = add <4 x i32> %346, %10
  %352 = add <4 x i32> %347, %10
  %353 = add <4 x i32> %349, %10
  %354 = add <4 x i32> %350, %10
  %355 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %351, i32 %4) #8
  %356 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %352, i32 %4) #8
  %357 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %353, i32 %4) #8
  %358 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %354, i32 %4) #8
  %359 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %355, <4 x i32> %356) #8
  %360 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %357, <4 x i32> %358) #8
  %361 = shufflevector <8 x i16> %307, <8 x i16> %308, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %362 = shufflevector <8 x i16> %307, <8 x i16> %308, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %363 = bitcast <4 x i32> %71 to <8 x i16>
  %364 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %361, <8 x i16> %363) #8
  %365 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %362, <8 x i16> %363) #8
  %366 = bitcast <4 x i32> %77 to <8 x i16>
  %367 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %361, <8 x i16> %366) #8
  %368 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %362, <8 x i16> %366) #8
  %369 = add <4 x i32> %364, %10
  %370 = add <4 x i32> %365, %10
  %371 = add <4 x i32> %367, %10
  %372 = add <4 x i32> %368, %10
  %373 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %369, i32 %4) #8
  %374 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %370, i32 %4) #8
  %375 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %371, i32 %4) #8
  %376 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %372, i32 %4) #8
  %377 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %373, <4 x i32> %374) #8
  %378 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %375, <4 x i32> %376) #8
  %379 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %263, <8 x i16> %324) #8
  %380 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %263, <8 x i16> %324) #8
  %381 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %264, <8 x i16> %341) #8
  %382 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %264, <8 x i16> %341) #8
  %383 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %267, <8 x i16> %342) #8
  %384 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %267, <8 x i16> %342) #8
  %385 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %268, <8 x i16> %325) #8
  %386 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %268, <8 x i16> %325) #8
  %387 = shufflevector <8 x i16> %379, <8 x i16> %386, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %388 = shufflevector <8 x i16> %379, <8 x i16> %386, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %389 = bitcast <4 x i32> %86 to <8 x i16>
  %390 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %387, <8 x i16> %389) #8
  %391 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %388, <8 x i16> %389) #8
  %392 = bitcast <4 x i32> %92 to <8 x i16>
  %393 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %387, <8 x i16> %392) #8
  %394 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %388, <8 x i16> %392) #8
  %395 = add <4 x i32> %390, %10
  %396 = add <4 x i32> %391, %10
  %397 = add <4 x i32> %393, %10
  %398 = add <4 x i32> %394, %10
  %399 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %395, i32 %4) #8
  %400 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %396, i32 %4) #8
  %401 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %397, i32 %4) #8
  %402 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %398, i32 %4) #8
  %403 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %399, <4 x i32> %400) #8
  %404 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %401, <4 x i32> %402) #8
  %405 = shufflevector <8 x i16> %380, <8 x i16> %385, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %406 = shufflevector <8 x i16> %380, <8 x i16> %385, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %407 = bitcast <4 x i32> %101 to <8 x i16>
  %408 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %405, <8 x i16> %407) #8
  %409 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %406, <8 x i16> %407) #8
  %410 = bitcast <4 x i32> %107 to <8 x i16>
  %411 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %405, <8 x i16> %410) #8
  %412 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %406, <8 x i16> %410) #8
  %413 = add <4 x i32> %408, %10
  %414 = add <4 x i32> %409, %10
  %415 = add <4 x i32> %411, %10
  %416 = add <4 x i32> %412, %10
  %417 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %413, i32 %4) #8
  %418 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %414, i32 %4) #8
  %419 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %415, i32 %4) #8
  %420 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %416, i32 %4) #8
  %421 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %417, <4 x i32> %418) #8
  %422 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %419, <4 x i32> %420) #8
  %423 = shufflevector <8 x i16> %381, <8 x i16> %384, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %424 = shufflevector <8 x i16> %381, <8 x i16> %384, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %425 = bitcast <4 x i32> %116 to <8 x i16>
  %426 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %423, <8 x i16> %425) #8
  %427 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %424, <8 x i16> %425) #8
  %428 = bitcast <4 x i32> %122 to <8 x i16>
  %429 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %423, <8 x i16> %428) #8
  %430 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %424, <8 x i16> %428) #8
  %431 = add <4 x i32> %426, %10
  %432 = add <4 x i32> %427, %10
  %433 = add <4 x i32> %429, %10
  %434 = add <4 x i32> %430, %10
  %435 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %431, i32 %4) #8
  %436 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %432, i32 %4) #8
  %437 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %433, i32 %4) #8
  %438 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %434, i32 %4) #8
  %439 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %435, <4 x i32> %436) #8
  %440 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %437, <4 x i32> %438) #8
  %441 = shufflevector <8 x i16> %382, <8 x i16> %383, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %442 = shufflevector <8 x i16> %382, <8 x i16> %383, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %443 = bitcast <4 x i32> %131 to <8 x i16>
  %444 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %441, <8 x i16> %443) #8
  %445 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %442, <8 x i16> %443) #8
  %446 = bitcast <4 x i32> %137 to <8 x i16>
  %447 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %441, <8 x i16> %446) #8
  %448 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %442, <8 x i16> %446) #8
  %449 = add <4 x i32> %444, %10
  %450 = add <4 x i32> %445, %10
  %451 = add <4 x i32> %447, %10
  %452 = add <4 x i32> %448, %10
  %453 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %449, i32 %4) #8
  %454 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %450, i32 %4) #8
  %455 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %451, i32 %4) #8
  %456 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %452, i32 %4) #8
  %457 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %453, <4 x i32> %454) #8
  %458 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %455, <4 x i32> %456) #8
  %459 = bitcast <2 x i64>* %1 to <8 x i16>*
  store <8 x i16> %286, <8 x i16>* %459, align 16
  %460 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %461 = bitcast <2 x i64>* %460 to <8 x i16>*
  store <8 x i16> %403, <8 x i16>* %461, align 16
  %462 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %463 = bitcast <2 x i64>* %462 to <8 x i16>*
  store <8 x i16> %359, <8 x i16>* %463, align 16
  %464 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %465 = bitcast <2 x i64>* %464 to <8 x i16>*
  store <8 x i16> %458, <8 x i16>* %465, align 16
  %466 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %467 = bitcast <2 x i64>* %466 to <8 x i16>*
  store <8 x i16> %304, <8 x i16>* %467, align 16
  %468 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %469 = bitcast <2 x i64>* %468 to <8 x i16>*
  store <8 x i16> %439, <8 x i16>* %469, align 16
  %470 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %471 = bitcast <2 x i64>* %470 to <8 x i16>*
  store <8 x i16> %378, <8 x i16>* %471, align 16
  %472 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %473 = bitcast <2 x i64>* %472 to <8 x i16>*
  store <8 x i16> %422, <8 x i16>* %473, align 16
  %474 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 8
  %475 = bitcast <2 x i64>* %474 to <8 x i16>*
  store <8 x i16> %287, <8 x i16>* %475, align 16
  %476 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 9
  %477 = bitcast <2 x i64>* %476 to <8 x i16>*
  store <8 x i16> %421, <8 x i16>* %477, align 16
  %478 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 10
  %479 = bitcast <2 x i64>* %478 to <8 x i16>*
  store <8 x i16> %377, <8 x i16>* %479, align 16
  %480 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 11
  %481 = bitcast <2 x i64>* %480 to <8 x i16>*
  store <8 x i16> %440, <8 x i16>* %481, align 16
  %482 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 12
  %483 = bitcast <2 x i64>* %482 to <8 x i16>*
  store <8 x i16> %305, <8 x i16>* %483, align 16
  %484 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 13
  %485 = bitcast <2 x i64>* %484 to <8 x i16>*
  store <8 x i16> %457, <8 x i16>* %485, align 16
  %486 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 14
  %487 = bitcast <2 x i64>* %486 to <8 x i16>*
  store <8 x i16> %360, <8 x i16>* %487, align 16
  %488 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 15
  %489 = bitcast <2 x i64>* %488 to <8 x i16>*
  store <8 x i16> %404, <8 x i16>* %489, align 16
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @av1_lowbd_fwd_txfm2d_16x64_sse2(i16* nocapture readonly, i32* nocapture, i32, i8 zeroext, i32) #2 {
  %6 = alloca [64 x <2 x i64>], align 16
  %7 = alloca [128 x <2 x i64>], align 16
  %8 = bitcast [64 x <2 x i64>]* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1024, i8* nonnull %8) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %8, i8 -86, i64 1024, i1 false)
  %9 = bitcast [128 x <2 x i64>]* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 2048, i8* nonnull %9) #8
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 2048, i1 false)
  %10 = load i8*, i8** getelementptr inbounds ([19 x i8*], [19 x i8*]* @av1_fwd_txfm_shift_ls, i64 0, i64 17), align 8
  %11 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_fwd_cos_bit_col, i64 0, i64 2, i64 4), align 2
  %12 = load i8, i8* getelementptr inbounds ([5 x [5 x i8]], [5 x [5 x i8]]* @av1_fwd_cos_bit_row, i64 0, i64 2, i64 4), align 2
  %13 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 0
  %14 = sext i32 %2 to i64
  %15 = getelementptr inbounds i8, i8* %10, i64 1
  br label %18

16:                                               ; preds = %176
  %17 = getelementptr inbounds i8, i8* %10, i64 2
  br label %261

18:                                               ; preds = %176, %5
  %19 = phi i64 [ 0, %5 ], [ %177, %176 ]
  %20 = shl nsw i64 %19, 3
  %21 = getelementptr inbounds i16, i16* %0, i64 %20
  br label %22

22:                                               ; preds = %22, %18
  %23 = phi i64 [ 0, %18 ], [ %47, %22 ]
  %24 = mul nsw i64 %23, %14
  %25 = getelementptr inbounds i16, i16* %21, i64 %24
  %26 = bitcast i16* %25 to <2 x i64>*
  %27 = load <2 x i64>, <2 x i64>* %26, align 16
  %28 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 %23
  store <2 x i64> %27, <2 x i64>* %28, align 16
  %29 = or i64 %23, 1
  %30 = mul nsw i64 %29, %14
  %31 = getelementptr inbounds i16, i16* %21, i64 %30
  %32 = bitcast i16* %31 to <2 x i64>*
  %33 = load <2 x i64>, <2 x i64>* %32, align 16
  %34 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 %29
  store <2 x i64> %33, <2 x i64>* %34, align 16
  %35 = or i64 %23, 2
  %36 = mul nsw i64 %35, %14
  %37 = getelementptr inbounds i16, i16* %21, i64 %36
  %38 = bitcast i16* %37 to <2 x i64>*
  %39 = load <2 x i64>, <2 x i64>* %38, align 16
  %40 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 %35
  store <2 x i64> %39, <2 x i64>* %40, align 16
  %41 = or i64 %23, 3
  %42 = mul nsw i64 %41, %14
  %43 = getelementptr inbounds i16, i16* %21, i64 %42
  %44 = bitcast i16* %43 to <2 x i64>*
  %45 = load <2 x i64>, <2 x i64>* %44, align 16
  %46 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 %41
  store <2 x i64> %45, <2 x i64>* %46, align 16
  %47 = add nuw nsw i64 %23, 4
  %48 = icmp eq i64 %47, 64
  br i1 %48, label %49, label %22

49:                                               ; preds = %22
  %50 = load i8, i8* %10, align 1
  %51 = sext i8 %50 to i32
  %52 = icmp slt i8 %50, 0
  br i1 %52, label %53, label %87

53:                                               ; preds = %49
  %54 = sub nsw i32 0, %51
  %55 = xor i32 %51, -1
  %56 = shl i32 1, %55
  %57 = trunc i32 %56 to i16
  %58 = insertelement <8 x i16> undef, i16 %57, i32 0
  %59 = shufflevector <8 x i16> %58, <8 x i16> undef, <8 x i32> zeroinitializer
  br label %60

60:                                               ; preds = %60, %53
  %61 = phi i64 [ 0, %53 ], [ %85, %60 ]
  %62 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 %61
  %63 = bitcast <2 x i64>* %62 to <8 x i16>*
  %64 = load <8 x i16>, <8 x i16>* %63, align 16
  %65 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %64, <8 x i16> %59) #8
  %66 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %65, i32 %54) #8
  store <8 x i16> %66, <8 x i16>* %63, align 16
  %67 = or i64 %61, 1
  %68 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 %67
  %69 = bitcast <2 x i64>* %68 to <8 x i16>*
  %70 = load <8 x i16>, <8 x i16>* %69, align 16
  %71 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %70, <8 x i16> %59) #8
  %72 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %71, i32 %54) #8
  store <8 x i16> %72, <8 x i16>* %69, align 16
  %73 = or i64 %61, 2
  %74 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 %73
  %75 = bitcast <2 x i64>* %74 to <8 x i16>*
  %76 = load <8 x i16>, <8 x i16>* %75, align 16
  %77 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %76, <8 x i16> %59) #8
  %78 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %77, i32 %54) #8
  store <8 x i16> %78, <8 x i16>* %75, align 16
  %79 = or i64 %61, 3
  %80 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 %79
  %81 = bitcast <2 x i64>* %80 to <8 x i16>*
  %82 = load <8 x i16>, <8 x i16>* %81, align 16
  %83 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %82, <8 x i16> %59) #8
  %84 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %83, i32 %54) #8
  store <8 x i16> %84, <8 x i16>* %81, align 16
  %85 = add nuw nsw i64 %61, 4
  %86 = icmp eq i64 %85, 64
  br i1 %86, label %112, label %60

87:                                               ; preds = %49
  %88 = icmp eq i8 %50, 0
  br i1 %88, label %112, label %89

89:                                               ; preds = %87, %89
  %90 = phi i64 [ %110, %89 ], [ 0, %87 ]
  %91 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 %90
  %92 = bitcast <2 x i64>* %91 to <8 x i16>*
  %93 = load <8 x i16>, <8 x i16>* %92, align 16
  %94 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %93, i32 %51) #8
  store <8 x i16> %94, <8 x i16>* %92, align 16
  %95 = or i64 %90, 1
  %96 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 %95
  %97 = bitcast <2 x i64>* %96 to <8 x i16>*
  %98 = load <8 x i16>, <8 x i16>* %97, align 16
  %99 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %98, i32 %51) #8
  store <8 x i16> %99, <8 x i16>* %97, align 16
  %100 = or i64 %90, 2
  %101 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 %100
  %102 = bitcast <2 x i64>* %101 to <8 x i16>*
  %103 = load <8 x i16>, <8 x i16>* %102, align 16
  %104 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %103, i32 %51) #8
  store <8 x i16> %104, <8 x i16>* %102, align 16
  %105 = or i64 %90, 3
  %106 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 %105
  %107 = bitcast <2 x i64>* %106 to <8 x i16>*
  %108 = load <8 x i16>, <8 x i16>* %107, align 16
  %109 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %108, i32 %51) #8
  store <8 x i16> %109, <8 x i16>* %107, align 16
  %110 = add nuw nsw i64 %90, 4
  %111 = icmp eq i64 %110, 64
  br i1 %111, label %112, label %89

112:                                              ; preds = %89, %60, %87
  call void @av1_fdct8x64_new_sse2(<2 x i64>* nonnull %13, <2 x i64>* nonnull %13, i8 signext %11)
  %113 = load i8, i8* %15, align 1
  %114 = sext i8 %113 to i32
  %115 = icmp slt i8 %113, 0
  br i1 %115, label %116, label %150

116:                                              ; preds = %112
  %117 = sub nsw i32 0, %114
  %118 = xor i32 %114, -1
  %119 = shl i32 1, %118
  %120 = trunc i32 %119 to i16
  %121 = insertelement <8 x i16> undef, i16 %120, i32 0
  %122 = shufflevector <8 x i16> %121, <8 x i16> undef, <8 x i32> zeroinitializer
  br label %123

123:                                              ; preds = %123, %116
  %124 = phi i64 [ 0, %116 ], [ %148, %123 ]
  %125 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 %124
  %126 = bitcast <2 x i64>* %125 to <8 x i16>*
  %127 = load <8 x i16>, <8 x i16>* %126, align 16
  %128 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %127, <8 x i16> %122) #8
  %129 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %128, i32 %117) #8
  store <8 x i16> %129, <8 x i16>* %126, align 16
  %130 = or i64 %124, 1
  %131 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 %130
  %132 = bitcast <2 x i64>* %131 to <8 x i16>*
  %133 = load <8 x i16>, <8 x i16>* %132, align 16
  %134 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %133, <8 x i16> %122) #8
  %135 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %134, i32 %117) #8
  store <8 x i16> %135, <8 x i16>* %132, align 16
  %136 = or i64 %124, 2
  %137 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 %136
  %138 = bitcast <2 x i64>* %137 to <8 x i16>*
  %139 = load <8 x i16>, <8 x i16>* %138, align 16
  %140 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %139, <8 x i16> %122) #8
  %141 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %140, i32 %117) #8
  store <8 x i16> %141, <8 x i16>* %138, align 16
  %142 = or i64 %124, 3
  %143 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 %142
  %144 = bitcast <2 x i64>* %143 to <8 x i16>*
  %145 = load <8 x i16>, <8 x i16>* %144, align 16
  %146 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %145, <8 x i16> %122) #8
  %147 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %146, i32 %117) #8
  store <8 x i16> %147, <8 x i16>* %144, align 16
  %148 = add nuw nsw i64 %124, 4
  %149 = icmp eq i64 %148, 64
  br i1 %149, label %152, label %123

150:                                              ; preds = %112
  %151 = icmp eq i8 %113, 0
  br i1 %151, label %152, label %153

152:                                              ; preds = %153, %123, %150
  br label %179

153:                                              ; preds = %150, %153
  %154 = phi i64 [ %174, %153 ], [ 0, %150 ]
  %155 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 %154
  %156 = bitcast <2 x i64>* %155 to <8 x i16>*
  %157 = load <8 x i16>, <8 x i16>* %156, align 16
  %158 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %157, i32 %114) #8
  store <8 x i16> %158, <8 x i16>* %156, align 16
  %159 = or i64 %154, 1
  %160 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 %159
  %161 = bitcast <2 x i64>* %160 to <8 x i16>*
  %162 = load <8 x i16>, <8 x i16>* %161, align 16
  %163 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %162, i32 %114) #8
  store <8 x i16> %163, <8 x i16>* %161, align 16
  %164 = or i64 %154, 2
  %165 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 %164
  %166 = bitcast <2 x i64>* %165 to <8 x i16>*
  %167 = load <8 x i16>, <8 x i16>* %166, align 16
  %168 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %167, i32 %114) #8
  store <8 x i16> %168, <8 x i16>* %166, align 16
  %169 = or i64 %154, 3
  %170 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 %169
  %171 = bitcast <2 x i64>* %170 to <8 x i16>*
  %172 = load <8 x i16>, <8 x i16>* %171, align 16
  %173 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %172, i32 %114) #8
  store <8 x i16> %173, <8 x i16>* %171, align 16
  %174 = add nuw nsw i64 %154, 4
  %175 = icmp eq i64 %174, 64
  br i1 %175, label %152, label %153

176:                                              ; preds = %179
  %177 = add nuw nsw i64 %19, 1
  %178 = icmp eq i64 %177, 2
  br i1 %178, label %16, label %18

179:                                              ; preds = %152, %179
  %180 = phi i64 [ %256, %179 ], [ 0, %152 ]
  %181 = shl nsw i64 %180, 3
  %182 = getelementptr inbounds [64 x <2 x i64>], [64 x <2 x i64>]* %6, i64 0, i64 %181
  %183 = shl nsw i64 %180, 4
  %184 = getelementptr inbounds [128 x <2 x i64>], [128 x <2 x i64>]* %7, i64 0, i64 %183
  %185 = getelementptr inbounds <2 x i64>, <2 x i64>* %184, i64 %20
  %186 = bitcast <2 x i64>* %182 to <8 x i16>*
  %187 = load <8 x i16>, <8 x i16>* %186, align 16
  %188 = getelementptr inbounds <2 x i64>, <2 x i64>* %182, i64 1
  %189 = bitcast <2 x i64>* %188 to <8 x i16>*
  %190 = load <8 x i16>, <8 x i16>* %189, align 16
  %191 = shufflevector <8 x i16> %187, <8 x i16> %190, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %192 = getelementptr inbounds <2 x i64>, <2 x i64>* %182, i64 2
  %193 = bitcast <2 x i64>* %192 to <8 x i16>*
  %194 = load <8 x i16>, <8 x i16>* %193, align 16
  %195 = getelementptr inbounds <2 x i64>, <2 x i64>* %182, i64 3
  %196 = bitcast <2 x i64>* %195 to <8 x i16>*
  %197 = load <8 x i16>, <8 x i16>* %196, align 16
  %198 = shufflevector <8 x i16> %194, <8 x i16> %197, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %199 = getelementptr inbounds <2 x i64>, <2 x i64>* %182, i64 4
  %200 = bitcast <2 x i64>* %199 to <8 x i16>*
  %201 = load <8 x i16>, <8 x i16>* %200, align 16
  %202 = getelementptr inbounds <2 x i64>, <2 x i64>* %182, i64 5
  %203 = bitcast <2 x i64>* %202 to <8 x i16>*
  %204 = load <8 x i16>, <8 x i16>* %203, align 16
  %205 = shufflevector <8 x i16> %201, <8 x i16> %204, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %206 = getelementptr inbounds <2 x i64>, <2 x i64>* %182, i64 6
  %207 = bitcast <2 x i64>* %206 to <8 x i16>*
  %208 = load <8 x i16>, <8 x i16>* %207, align 16
  %209 = getelementptr inbounds <2 x i64>, <2 x i64>* %182, i64 7
  %210 = bitcast <2 x i64>* %209 to <8 x i16>*
  %211 = load <8 x i16>, <8 x i16>* %210, align 16
  %212 = shufflevector <8 x i16> %208, <8 x i16> %211, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %213 = shufflevector <8 x i16> %187, <8 x i16> %190, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %214 = shufflevector <8 x i16> %194, <8 x i16> %197, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %215 = shufflevector <8 x i16> %201, <8 x i16> %204, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %216 = shufflevector <8 x i16> %208, <8 x i16> %211, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %217 = bitcast <8 x i16> %191 to <4 x i32>
  %218 = bitcast <8 x i16> %198 to <4 x i32>
  %219 = shufflevector <4 x i32> %217, <4 x i32> %218, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %220 = bitcast <4 x i32> %219 to <2 x i64>
  %221 = bitcast <8 x i16> %205 to <4 x i32>
  %222 = bitcast <8 x i16> %212 to <4 x i32>
  %223 = shufflevector <4 x i32> %221, <4 x i32> %222, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %224 = bitcast <4 x i32> %223 to <2 x i64>
  %225 = bitcast <8 x i16> %213 to <4 x i32>
  %226 = bitcast <8 x i16> %214 to <4 x i32>
  %227 = shufflevector <4 x i32> %225, <4 x i32> %226, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %228 = bitcast <4 x i32> %227 to <2 x i64>
  %229 = bitcast <8 x i16> %215 to <4 x i32>
  %230 = bitcast <8 x i16> %216 to <4 x i32>
  %231 = shufflevector <4 x i32> %229, <4 x i32> %230, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %232 = bitcast <4 x i32> %231 to <2 x i64>
  %233 = shufflevector <4 x i32> %217, <4 x i32> %218, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %234 = bitcast <4 x i32> %233 to <2 x i64>
  %235 = shufflevector <4 x i32> %221, <4 x i32> %222, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %236 = bitcast <4 x i32> %235 to <2 x i64>
  %237 = shufflevector <4 x i32> %225, <4 x i32> %226, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %238 = bitcast <4 x i32> %237 to <2 x i64>
  %239 = shufflevector <4 x i32> %229, <4 x i32> %230, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %240 = bitcast <4 x i32> %239 to <2 x i64>
  %241 = shufflevector <2 x i64> %220, <2 x i64> %224, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %241, <2 x i64>* %185, align 16
  %242 = shufflevector <2 x i64> %220, <2 x i64> %224, <2 x i32> <i32 1, i32 3>
  %243 = getelementptr inbounds <2 x i64>, <2 x i64>* %185, i64 1
  store <2 x i64> %242, <2 x i64>* %243, align 16
  %244 = shufflevector <2 x i64> %234, <2 x i64> %236, <2 x i32> <i32 0, i32 2>
  %245 = getelementptr inbounds <2 x i64>, <2 x i64>* %185, i64 2
  store <2 x i64> %244, <2 x i64>* %245, align 16
  %246 = shufflevector <2 x i64> %234, <2 x i64> %236, <2 x i32> <i32 1, i32 3>
  %247 = getelementptr inbounds <2 x i64>, <2 x i64>* %185, i64 3
  store <2 x i64> %246, <2 x i64>* %247, align 16
  %248 = shufflevector <2 x i64> %228, <2 x i64> %232, <2 x i32> <i32 0, i32 2>
  %249 = getelementptr inbounds <2 x i64>, <2 x i64>* %185, i64 4
  store <2 x i64> %248, <2 x i64>* %249, align 16
  %250 = shufflevector <2 x i64> %228, <2 x i64> %232, <2 x i32> <i32 1, i32 3>
  %251 = getelementptr inbounds <2 x i64>, <2 x i64>* %185, i64 5
  store <2 x i64> %250, <2 x i64>* %251, align 16
  %252 = shufflevector <2 x i64> %238, <2 x i64> %240, <2 x i32> <i32 0, i32 2>
  %253 = getelementptr inbounds <2 x i64>, <2 x i64>* %185, i64 6
  store <2 x i64> %252, <2 x i64>* %253, align 16
  %254 = shufflevector <2 x i64> %238, <2 x i64> %240, <2 x i32> <i32 1, i32 3>
  %255 = getelementptr inbounds <2 x i64>, <2 x i64>* %185, i64 7
  store <2 x i64> %254, <2 x i64>* %255, align 16
  %256 = add nuw nsw i64 %180, 1
  %257 = icmp eq i64 %256, 8
  br i1 %257, label %176, label %179

258:                                              ; preds = %423
  %259 = getelementptr inbounds i32, i32* %1, i64 512
  %260 = bitcast i32* %259 to i8*
  call void @llvm.memset.p0i8.i64(i8* align 4 %260, i8 0, i64 2048, i1 false)
  call void @llvm.lifetime.end.p0i8(i64 2048, i8* nonnull %9) #8
  call void @llvm.lifetime.end.p0i8(i64 1024, i8* nonnull %8) #8
  ret void

261:                                              ; preds = %423, %16
  %262 = phi i64 [ 0, %16 ], [ %424, %423 ]
  %263 = shl nsw i64 %262, 4
  %264 = getelementptr inbounds [128 x <2 x i64>], [128 x <2 x i64>]* %7, i64 0, i64 %263
  call void @fdct8x16_new_sse2(<2 x i64>* %264, <2 x i64>* %264, i8 signext %12)
  %265 = load i8, i8* %17, align 1
  %266 = sext i8 %265 to i32
  %267 = icmp slt i8 %265, 0
  br i1 %267, label %268, label %354

268:                                              ; preds = %261
  %269 = sub nsw i32 0, %266
  %270 = xor i32 %266, -1
  %271 = shl i32 1, %270
  %272 = trunc i32 %271 to i16
  %273 = insertelement <8 x i16> undef, i16 %272, i32 0
  %274 = shufflevector <8 x i16> %273, <8 x i16> undef, <8 x i32> zeroinitializer
  %275 = bitcast <2 x i64>* %264 to <8 x i16>*
  %276 = load <8 x i16>, <8 x i16>* %275, align 16
  %277 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %276, <8 x i16> %274) #8
  %278 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %277, i32 %269) #8
  store <8 x i16> %278, <8 x i16>* %275, align 16
  %279 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 1
  %280 = bitcast <2 x i64>* %279 to <8 x i16>*
  %281 = load <8 x i16>, <8 x i16>* %280, align 16
  %282 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %281, <8 x i16> %274) #8
  %283 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %282, i32 %269) #8
  store <8 x i16> %283, <8 x i16>* %280, align 16
  %284 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 2
  %285 = bitcast <2 x i64>* %284 to <8 x i16>*
  %286 = load <8 x i16>, <8 x i16>* %285, align 16
  %287 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %286, <8 x i16> %274) #8
  %288 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %287, i32 %269) #8
  store <8 x i16> %288, <8 x i16>* %285, align 16
  %289 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 3
  %290 = bitcast <2 x i64>* %289 to <8 x i16>*
  %291 = load <8 x i16>, <8 x i16>* %290, align 16
  %292 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %291, <8 x i16> %274) #8
  %293 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %292, i32 %269) #8
  store <8 x i16> %293, <8 x i16>* %290, align 16
  %294 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 4
  %295 = bitcast <2 x i64>* %294 to <8 x i16>*
  %296 = load <8 x i16>, <8 x i16>* %295, align 16
  %297 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %296, <8 x i16> %274) #8
  %298 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %297, i32 %269) #8
  store <8 x i16> %298, <8 x i16>* %295, align 16
  %299 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 5
  %300 = bitcast <2 x i64>* %299 to <8 x i16>*
  %301 = load <8 x i16>, <8 x i16>* %300, align 16
  %302 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %301, <8 x i16> %274) #8
  %303 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %302, i32 %269) #8
  store <8 x i16> %303, <8 x i16>* %300, align 16
  %304 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 6
  %305 = bitcast <2 x i64>* %304 to <8 x i16>*
  %306 = load <8 x i16>, <8 x i16>* %305, align 16
  %307 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %306, <8 x i16> %274) #8
  %308 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %307, i32 %269) #8
  store <8 x i16> %308, <8 x i16>* %305, align 16
  %309 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 7
  %310 = bitcast <2 x i64>* %309 to <8 x i16>*
  %311 = load <8 x i16>, <8 x i16>* %310, align 16
  %312 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %311, <8 x i16> %274) #8
  %313 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %312, i32 %269) #8
  store <8 x i16> %313, <8 x i16>* %310, align 16
  %314 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 8
  %315 = bitcast <2 x i64>* %314 to <8 x i16>*
  %316 = load <8 x i16>, <8 x i16>* %315, align 16
  %317 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %316, <8 x i16> %274) #8
  %318 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %317, i32 %269) #8
  store <8 x i16> %318, <8 x i16>* %315, align 16
  %319 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 9
  %320 = bitcast <2 x i64>* %319 to <8 x i16>*
  %321 = load <8 x i16>, <8 x i16>* %320, align 16
  %322 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %321, <8 x i16> %274) #8
  %323 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %322, i32 %269) #8
  store <8 x i16> %323, <8 x i16>* %320, align 16
  %324 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 10
  %325 = bitcast <2 x i64>* %324 to <8 x i16>*
  %326 = load <8 x i16>, <8 x i16>* %325, align 16
  %327 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %326, <8 x i16> %274) #8
  %328 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %327, i32 %269) #8
  store <8 x i16> %328, <8 x i16>* %325, align 16
  %329 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 11
  %330 = bitcast <2 x i64>* %329 to <8 x i16>*
  %331 = load <8 x i16>, <8 x i16>* %330, align 16
  %332 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %331, <8 x i16> %274) #8
  %333 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %332, i32 %269) #8
  store <8 x i16> %333, <8 x i16>* %330, align 16
  %334 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 12
  %335 = bitcast <2 x i64>* %334 to <8 x i16>*
  %336 = load <8 x i16>, <8 x i16>* %335, align 16
  %337 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %336, <8 x i16> %274) #8
  %338 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %337, i32 %269) #8
  store <8 x i16> %338, <8 x i16>* %335, align 16
  %339 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 13
  %340 = bitcast <2 x i64>* %339 to <8 x i16>*
  %341 = load <8 x i16>, <8 x i16>* %340, align 16
  %342 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %341, <8 x i16> %274) #8
  %343 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %342, i32 %269) #8
  store <8 x i16> %343, <8 x i16>* %340, align 16
  %344 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 14
  %345 = bitcast <2 x i64>* %344 to <8 x i16>*
  %346 = load <8 x i16>, <8 x i16>* %345, align 16
  %347 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %346, <8 x i16> %274) #8
  %348 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %347, i32 %269) #8
  store <8 x i16> %348, <8 x i16>* %345, align 16
  %349 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 15
  %350 = bitcast <2 x i64>* %349 to <8 x i16>*
  %351 = load <8 x i16>, <8 x i16>* %350, align 16
  %352 = call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %351, <8 x i16> %274) #8
  %353 = call <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16> %352, i32 %269) #8
  store <8 x i16> %353, <8 x i16>* %350, align 16
  br label %420

354:                                              ; preds = %261
  %355 = icmp eq i8 %265, 0
  br i1 %355, label %420, label %356

356:                                              ; preds = %354
  %357 = bitcast <2 x i64>* %264 to <8 x i16>*
  %358 = load <8 x i16>, <8 x i16>* %357, align 16
  %359 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %358, i32 %266) #8
  store <8 x i16> %359, <8 x i16>* %357, align 16
  %360 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 1
  %361 = bitcast <2 x i64>* %360 to <8 x i16>*
  %362 = load <8 x i16>, <8 x i16>* %361, align 16
  %363 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %362, i32 %266) #8
  store <8 x i16> %363, <8 x i16>* %361, align 16
  %364 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 2
  %365 = bitcast <2 x i64>* %364 to <8 x i16>*
  %366 = load <8 x i16>, <8 x i16>* %365, align 16
  %367 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %366, i32 %266) #8
  store <8 x i16> %367, <8 x i16>* %365, align 16
  %368 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 3
  %369 = bitcast <2 x i64>* %368 to <8 x i16>*
  %370 = load <8 x i16>, <8 x i16>* %369, align 16
  %371 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %370, i32 %266) #8
  store <8 x i16> %371, <8 x i16>* %369, align 16
  %372 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 4
  %373 = bitcast <2 x i64>* %372 to <8 x i16>*
  %374 = load <8 x i16>, <8 x i16>* %373, align 16
  %375 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %374, i32 %266) #8
  store <8 x i16> %375, <8 x i16>* %373, align 16
  %376 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 5
  %377 = bitcast <2 x i64>* %376 to <8 x i16>*
  %378 = load <8 x i16>, <8 x i16>* %377, align 16
  %379 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %378, i32 %266) #8
  store <8 x i16> %379, <8 x i16>* %377, align 16
  %380 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 6
  %381 = bitcast <2 x i64>* %380 to <8 x i16>*
  %382 = load <8 x i16>, <8 x i16>* %381, align 16
  %383 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %382, i32 %266) #8
  store <8 x i16> %383, <8 x i16>* %381, align 16
  %384 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 7
  %385 = bitcast <2 x i64>* %384 to <8 x i16>*
  %386 = load <8 x i16>, <8 x i16>* %385, align 16
  %387 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %386, i32 %266) #8
  store <8 x i16> %387, <8 x i16>* %385, align 16
  %388 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 8
  %389 = bitcast <2 x i64>* %388 to <8 x i16>*
  %390 = load <8 x i16>, <8 x i16>* %389, align 16
  %391 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %390, i32 %266) #8
  store <8 x i16> %391, <8 x i16>* %389, align 16
  %392 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 9
  %393 = bitcast <2 x i64>* %392 to <8 x i16>*
  %394 = load <8 x i16>, <8 x i16>* %393, align 16
  %395 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %394, i32 %266) #8
  store <8 x i16> %395, <8 x i16>* %393, align 16
  %396 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 10
  %397 = bitcast <2 x i64>* %396 to <8 x i16>*
  %398 = load <8 x i16>, <8 x i16>* %397, align 16
  %399 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %398, i32 %266) #8
  store <8 x i16> %399, <8 x i16>* %397, align 16
  %400 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 11
  %401 = bitcast <2 x i64>* %400 to <8 x i16>*
  %402 = load <8 x i16>, <8 x i16>* %401, align 16
  %403 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %402, i32 %266) #8
  store <8 x i16> %403, <8 x i16>* %401, align 16
  %404 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 12
  %405 = bitcast <2 x i64>* %404 to <8 x i16>*
  %406 = load <8 x i16>, <8 x i16>* %405, align 16
  %407 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %406, i32 %266) #8
  store <8 x i16> %407, <8 x i16>* %405, align 16
  %408 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 13
  %409 = bitcast <2 x i64>* %408 to <8 x i16>*
  %410 = load <8 x i16>, <8 x i16>* %409, align 16
  %411 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %410, i32 %266) #8
  store <8 x i16> %411, <8 x i16>* %409, align 16
  %412 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 14
  %413 = bitcast <2 x i64>* %412 to <8 x i16>*
  %414 = load <8 x i16>, <8 x i16>* %413, align 16
  %415 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %414, i32 %266) #8
  store <8 x i16> %415, <8 x i16>* %413, align 16
  %416 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 15
  %417 = bitcast <2 x i64>* %416 to <8 x i16>*
  %418 = load <8 x i16>, <8 x i16>* %417, align 16
  %419 = call <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16> %418, i32 %266) #8
  store <8 x i16> %419, <8 x i16>* %417, align 16
  br label %420

420:                                              ; preds = %356, %268, %354
  %421 = shl nsw i64 %262, 7
  %422 = getelementptr inbounds i32, i32* %1, i64 %421
  br label %426

423:                                              ; preds = %426
  %424 = add nuw nsw i64 %262, 1
  %425 = icmp eq i64 %424, 4
  br i1 %425, label %258, label %261

426:                                              ; preds = %426, %420
  %427 = phi i64 [ 0, %420 ], [ %581, %426 ]
  %428 = shl nsw i64 %427, 3
  %429 = getelementptr inbounds <2 x i64>, <2 x i64>* %264, i64 %428
  %430 = bitcast <2 x i64>* %429 to <8 x i16>*
  %431 = load <8 x i16>, <8 x i16>* %430, align 16
  %432 = getelementptr inbounds <2 x i64>, <2 x i64>* %429, i64 1
  %433 = bitcast <2 x i64>* %432 to <8 x i16>*
  %434 = load <8 x i16>, <8 x i16>* %433, align 16
  %435 = shufflevector <8 x i16> %431, <8 x i16> %434, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %436 = getelementptr inbounds <2 x i64>, <2 x i64>* %429, i64 2
  %437 = bitcast <2 x i64>* %436 to <8 x i16>*
  %438 = load <8 x i16>, <8 x i16>* %437, align 16
  %439 = getelementptr inbounds <2 x i64>, <2 x i64>* %429, i64 3
  %440 = bitcast <2 x i64>* %439 to <8 x i16>*
  %441 = load <8 x i16>, <8 x i16>* %440, align 16
  %442 = shufflevector <8 x i16> %438, <8 x i16> %441, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %443 = getelementptr inbounds <2 x i64>, <2 x i64>* %429, i64 4
  %444 = bitcast <2 x i64>* %443 to <8 x i16>*
  %445 = load <8 x i16>, <8 x i16>* %444, align 16
  %446 = getelementptr inbounds <2 x i64>, <2 x i64>* %429, i64 5
  %447 = bitcast <2 x i64>* %446 to <8 x i16>*
  %448 = load <8 x i16>, <8 x i16>* %447, align 16
  %449 = shufflevector <8 x i16> %445, <8 x i16> %448, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %450 = getelementptr inbounds <2 x i64>, <2 x i64>* %429, i64 6
  %451 = bitcast <2 x i64>* %450 to <8 x i16>*
  %452 = load <8 x i16>, <8 x i16>* %451, align 16
  %453 = getelementptr inbounds <2 x i64>, <2 x i64>* %429, i64 7
  %454 = bitcast <2 x i64>* %453 to <8 x i16>*
  %455 = load <8 x i16>, <8 x i16>* %454, align 16
  %456 = shufflevector <8 x i16> %452, <8 x i16> %455, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %457 = shufflevector <8 x i16> %431, <8 x i16> %434, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %458 = shufflevector <8 x i16> %438, <8 x i16> %441, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %459 = shufflevector <8 x i16> %445, <8 x i16> %448, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %460 = shufflevector <8 x i16> %452, <8 x i16> %455, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %461 = bitcast <8 x i16> %435 to <4 x i32>
  %462 = bitcast <8 x i16> %442 to <4 x i32>
  %463 = shufflevector <4 x i32> %461, <4 x i32> %462, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %464 = bitcast <4 x i32> %463 to <2 x i64>
  %465 = bitcast <8 x i16> %449 to <4 x i32>
  %466 = bitcast <8 x i16> %456 to <4 x i32>
  %467 = shufflevector <4 x i32> %465, <4 x i32> %466, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %468 = bitcast <4 x i32> %467 to <2 x i64>
  %469 = bitcast <8 x i16> %457 to <4 x i32>
  %470 = bitcast <8 x i16> %458 to <4 x i32>
  %471 = shufflevector <4 x i32> %469, <4 x i32> %470, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %472 = bitcast <4 x i32> %471 to <2 x i64>
  %473 = bitcast <8 x i16> %459 to <4 x i32>
  %474 = bitcast <8 x i16> %460 to <4 x i32>
  %475 = shufflevector <4 x i32> %473, <4 x i32> %474, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %476 = bitcast <4 x i32> %475 to <2 x i64>
  %477 = shufflevector <4 x i32> %461, <4 x i32> %462, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %478 = bitcast <4 x i32> %477 to <2 x i64>
  %479 = shufflevector <4 x i32> %465, <4 x i32> %466, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %480 = bitcast <4 x i32> %479 to <2 x i64>
  %481 = shufflevector <4 x i32> %469, <4 x i32> %470, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %482 = bitcast <4 x i32> %481 to <2 x i64>
  %483 = shufflevector <4 x i32> %473, <4 x i32> %474, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %484 = bitcast <4 x i32> %483 to <2 x i64>
  %485 = shufflevector <2 x i64> %464, <2 x i64> %468, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %485, <2 x i64>* %429, align 16
  %486 = shufflevector <2 x i64> %464, <2 x i64> %468, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %486, <2 x i64>* %432, align 16
  %487 = shufflevector <2 x i64> %478, <2 x i64> %480, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %487, <2 x i64>* %436, align 16
  %488 = shufflevector <2 x i64> %478, <2 x i64> %480, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %488, <2 x i64>* %439, align 16
  %489 = shufflevector <2 x i64> %472, <2 x i64> %476, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %489, <2 x i64>* %443, align 16
  %490 = shufflevector <2 x i64> %472, <2 x i64> %476, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %490, <2 x i64>* %446, align 16
  %491 = shufflevector <2 x i64> %482, <2 x i64> %484, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %491, <2 x i64>* %450, align 16
  %492 = shufflevector <2 x i64> %482, <2 x i64> %484, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %492, <2 x i64>* %453, align 16
  %493 = getelementptr inbounds i32, i32* %422, i64 %428
  %494 = bitcast <2 x i64> %485 to <8 x i16>
  %495 = shufflevector <8 x i16> %494, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %496 = shufflevector <8 x i16> %494, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %497 = bitcast <8 x i16> %495 to <4 x i32>
  %498 = ashr <4 x i32> %497, <i32 16, i32 16, i32 16, i32 16>
  %499 = bitcast <8 x i16> %496 to <4 x i32>
  %500 = ashr <4 x i32> %499, <i32 16, i32 16, i32 16, i32 16>
  %501 = bitcast i32* %493 to <4 x i32>*
  store <4 x i32> %498, <4 x i32>* %501, align 16
  %502 = getelementptr inbounds i32, i32* %493, i64 4
  %503 = bitcast i32* %502 to <4 x i32>*
  store <4 x i32> %500, <4 x i32>* %503, align 16
  %504 = bitcast <2 x i64> %486 to <8 x i16>
  %505 = getelementptr inbounds i32, i32* %493, i64 16
  %506 = shufflevector <8 x i16> %504, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %507 = shufflevector <8 x i16> %504, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %508 = bitcast <8 x i16> %506 to <4 x i32>
  %509 = ashr <4 x i32> %508, <i32 16, i32 16, i32 16, i32 16>
  %510 = bitcast <8 x i16> %507 to <4 x i32>
  %511 = ashr <4 x i32> %510, <i32 16, i32 16, i32 16, i32 16>
  %512 = bitcast i32* %505 to <4 x i32>*
  store <4 x i32> %509, <4 x i32>* %512, align 16
  %513 = getelementptr inbounds i32, i32* %505, i64 4
  %514 = bitcast i32* %513 to <4 x i32>*
  store <4 x i32> %511, <4 x i32>* %514, align 16
  %515 = bitcast <2 x i64> %487 to <8 x i16>
  %516 = getelementptr inbounds i32, i32* %493, i64 32
  %517 = shufflevector <8 x i16> %515, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %518 = shufflevector <8 x i16> %515, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %519 = bitcast <8 x i16> %517 to <4 x i32>
  %520 = ashr <4 x i32> %519, <i32 16, i32 16, i32 16, i32 16>
  %521 = bitcast <8 x i16> %518 to <4 x i32>
  %522 = ashr <4 x i32> %521, <i32 16, i32 16, i32 16, i32 16>
  %523 = bitcast i32* %516 to <4 x i32>*
  store <4 x i32> %520, <4 x i32>* %523, align 16
  %524 = getelementptr inbounds i32, i32* %516, i64 4
  %525 = bitcast i32* %524 to <4 x i32>*
  store <4 x i32> %522, <4 x i32>* %525, align 16
  %526 = bitcast <2 x i64> %488 to <8 x i16>
  %527 = getelementptr inbounds i32, i32* %493, i64 48
  %528 = shufflevector <8 x i16> %526, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %529 = shufflevector <8 x i16> %526, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %530 = bitcast <8 x i16> %528 to <4 x i32>
  %531 = ashr <4 x i32> %530, <i32 16, i32 16, i32 16, i32 16>
  %532 = bitcast <8 x i16> %529 to <4 x i32>
  %533 = ashr <4 x i32> %532, <i32 16, i32 16, i32 16, i32 16>
  %534 = bitcast i32* %527 to <4 x i32>*
  store <4 x i32> %531, <4 x i32>* %534, align 16
  %535 = getelementptr inbounds i32, i32* %527, i64 4
  %536 = bitcast i32* %535 to <4 x i32>*
  store <4 x i32> %533, <4 x i32>* %536, align 16
  %537 = bitcast <2 x i64> %489 to <8 x i16>
  %538 = getelementptr inbounds i32, i32* %493, i64 64
  %539 = shufflevector <8 x i16> %537, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %540 = shufflevector <8 x i16> %537, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %541 = bitcast <8 x i16> %539 to <4 x i32>
  %542 = ashr <4 x i32> %541, <i32 16, i32 16, i32 16, i32 16>
  %543 = bitcast <8 x i16> %540 to <4 x i32>
  %544 = ashr <4 x i32> %543, <i32 16, i32 16, i32 16, i32 16>
  %545 = bitcast i32* %538 to <4 x i32>*
  store <4 x i32> %542, <4 x i32>* %545, align 16
  %546 = getelementptr inbounds i32, i32* %538, i64 4
  %547 = bitcast i32* %546 to <4 x i32>*
  store <4 x i32> %544, <4 x i32>* %547, align 16
  %548 = bitcast <2 x i64> %490 to <8 x i16>
  %549 = getelementptr inbounds i32, i32* %493, i64 80
  %550 = shufflevector <8 x i16> %548, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %551 = shufflevector <8 x i16> %548, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %552 = bitcast <8 x i16> %550 to <4 x i32>
  %553 = ashr <4 x i32> %552, <i32 16, i32 16, i32 16, i32 16>
  %554 = bitcast <8 x i16> %551 to <4 x i32>
  %555 = ashr <4 x i32> %554, <i32 16, i32 16, i32 16, i32 16>
  %556 = bitcast i32* %549 to <4 x i32>*
  store <4 x i32> %553, <4 x i32>* %556, align 16
  %557 = getelementptr inbounds i32, i32* %549, i64 4
  %558 = bitcast i32* %557 to <4 x i32>*
  store <4 x i32> %555, <4 x i32>* %558, align 16
  %559 = bitcast <2 x i64> %491 to <8 x i16>
  %560 = getelementptr inbounds i32, i32* %493, i64 96
  %561 = shufflevector <8 x i16> %559, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %562 = shufflevector <8 x i16> %559, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %563 = bitcast <8 x i16> %561 to <4 x i32>
  %564 = ashr <4 x i32> %563, <i32 16, i32 16, i32 16, i32 16>
  %565 = bitcast <8 x i16> %562 to <4 x i32>
  %566 = ashr <4 x i32> %565, <i32 16, i32 16, i32 16, i32 16>
  %567 = bitcast i32* %560 to <4 x i32>*
  store <4 x i32> %564, <4 x i32>* %567, align 16
  %568 = getelementptr inbounds i32, i32* %560, i64 4
  %569 = bitcast i32* %568 to <4 x i32>*
  store <4 x i32> %566, <4 x i32>* %569, align 16
  %570 = bitcast <2 x i64> %492 to <8 x i16>
  %571 = getelementptr inbounds i32, i32* %493, i64 112
  %572 = shufflevector <8 x i16> %570, <8 x i16> undef, <8 x i32> <i32 0, i32 0, i32 1, i32 1, i32 2, i32 2, i32 3, i32 3>
  %573 = shufflevector <8 x i16> %570, <8 x i16> undef, <8 x i32> <i32 4, i32 4, i32 5, i32 5, i32 6, i32 6, i32 7, i32 7>
  %574 = bitcast <8 x i16> %572 to <4 x i32>
  %575 = ashr <4 x i32> %574, <i32 16, i32 16, i32 16, i32 16>
  %576 = bitcast <8 x i16> %573 to <4 x i32>
  %577 = ashr <4 x i32> %576, <i32 16, i32 16, i32 16, i32 16>
  %578 = bitcast i32* %571 to <4 x i32>*
  store <4 x i32> %575, <4 x i32>* %578, align 16
  %579 = getelementptr inbounds i32, i32* %571, i64 4
  %580 = bitcast i32* %579 to <4 x i32>*
  store <4 x i32> %577, <4 x i32>* %580, align 16
  %581 = add nuw nsw i64 %427, 1
  %582 = icmp eq i64 %581, 2
  br i1 %582, label %423, label %426
}

; Function Attrs: nounwind ssp uwtable
define hidden void @av1_lowbd_fwd_txfm_sse2(i16*, i32*, i32, %struct.txfm_param*) local_unnamed_addr #4 {
  %5 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 1
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i64
  %8 = getelementptr inbounds [19 x void (i16*, i32*, i32, i8, i32)*], [19 x void (i16*, i32*, i32, i8, i32)*]* @fwd_txfm2d_func_ls, i64 0, i64 %7
  %9 = load void (i16*, i32*, i32, i8, i32)*, void (i16*, i32*, i32, i8, i32)** %8, align 8
  %10 = lshr i64 6160, %7
  %11 = and i64 %10, 1
  %12 = icmp eq i64 %11, 0
  br i1 %12, label %13, label %19

13:                                               ; preds = %4
  %14 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 2
  %15 = load i32, i32* %14, align 4
  %16 = icmp ne i32 %15, 0
  %17 = icmp eq i8 %6, 0
  %18 = and i1 %17, %16
  br i1 %18, label %19, label %20

19:                                               ; preds = %13, %4
  tail call void @av1_lowbd_fwd_txfm_c(i16* %0, i32* %1, i32 %2, %struct.txfm_param* %3) #8
  br label %25

20:                                               ; preds = %13
  %21 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 0
  %22 = load i8, i8* %21, align 4
  %23 = getelementptr inbounds %struct.txfm_param, %struct.txfm_param* %3, i64 0, i32 3
  %24 = load i32, i32* %23, align 4
  tail call void %9(i16* %0, i32* %1, i32 %2, i8 zeroext %22, i32 %24) #8
  br label %25

25:                                               ; preds = %20, %19
  ret void
}

declare void @av1_lowbd_fwd_txfm_c(i16*, i32*, i32, %struct.txfm_param*) local_unnamed_addr #3

; Function Attrs: nounwind readnone speculatable
declare <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16>, <8 x i16>) #5

; Function Attrs: nounwind readnone speculatable
declare <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16>, <8 x i16>) #5

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16>, <8 x i16>) #6

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32>, i32) #6

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32>, <4 x i32>) #6

; Function Attrs: nofree nounwind ssp uwtable
define internal void @fdct4x4_new_sse2(<2 x i64>* nocapture readonly, <2 x i64>* nocapture, i8 signext) #0 {
  %4 = sext i8 %2 to i32
  %5 = add nsw i32 %4, -10
  %6 = sext i32 %5 to i64
  %7 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 32
  %8 = load i32, i32* %7, align 16
  %9 = and i32 %8, 65535
  %10 = shl i32 %8, 16
  %11 = or i32 %9, %10
  %12 = insertelement <4 x i32> undef, i32 %11, i32 0
  %13 = shufflevector <4 x i32> %12, <4 x i32> undef, <4 x i32> zeroinitializer
  %14 = sub i32 0, %10
  %15 = or i32 %9, %14
  %16 = insertelement <4 x i32> undef, i32 %15, i32 0
  %17 = shufflevector <4 x i32> %16, <4 x i32> undef, <4 x i32> zeroinitializer
  %18 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 16
  %19 = load i32, i32* %18, align 16
  %20 = and i32 %19, 65535
  %21 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 48
  %22 = load i32, i32* %21, align 16
  %23 = shl i32 %22, 16
  %24 = or i32 %23, %20
  %25 = insertelement <4 x i32> undef, i32 %24, i32 0
  %26 = shufflevector <4 x i32> %25, <4 x i32> undef, <4 x i32> zeroinitializer
  %27 = and i32 %22, 65535
  %28 = shl i32 %19, 16
  %29 = sub i32 0, %28
  %30 = or i32 %27, %29
  %31 = insertelement <4 x i32> undef, i32 %30, i32 0
  %32 = shufflevector <4 x i32> %31, <4 x i32> undef, <4 x i32> zeroinitializer
  %33 = add nsw i32 %4, -1
  %34 = shl i32 1, %33
  %35 = insertelement <4 x i32> undef, i32 %34, i32 0
  %36 = shufflevector <4 x i32> %35, <4 x i32> undef, <4 x i32> zeroinitializer
  %37 = bitcast <2 x i64>* %0 to <8 x i16>*
  %38 = load <8 x i16>, <8 x i16>* %37, align 16
  %39 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %40 = bitcast <2 x i64>* %39 to <8 x i16>*
  %41 = load <8 x i16>, <8 x i16>* %40, align 16
  %42 = shufflevector <8 x i16> %38, <8 x i16> %41, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %43 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %44 = bitcast <2 x i64>* %43 to <8 x i16>*
  %45 = load <8 x i16>, <8 x i16>* %44, align 16
  %46 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %47 = bitcast <2 x i64>* %46 to <8 x i16>*
  %48 = load <8 x i16>, <8 x i16>* %47, align 16
  %49 = shufflevector <8 x i16> %45, <8 x i16> %48, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %50 = add <8 x i16> %49, %42
  %51 = sub <8 x i16> %42, %49
  %52 = bitcast <4 x i32> %13 to <8 x i16>
  %53 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %50, <8 x i16> %52) #8
  %54 = bitcast <4 x i32> %17 to <8 x i16>
  %55 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %50, <8 x i16> %54) #8
  %56 = bitcast <4 x i32> %26 to <8 x i16>
  %57 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %51, <8 x i16> %56) #8
  %58 = bitcast <4 x i32> %32 to <8 x i16>
  %59 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %51, <8 x i16> %58) #8
  %60 = add <4 x i32> %53, %36
  %61 = add <4 x i32> %55, %36
  %62 = add <4 x i32> %57, %36
  %63 = add <4 x i32> %59, %36
  %64 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %60, i32 %4) #8
  %65 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %61, i32 %4) #8
  %66 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %62, i32 %4) #8
  %67 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %63, i32 %4) #8
  %68 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %64, <4 x i32> %65) #8
  %69 = bitcast <2 x i64>* %1 to <8 x i16>*
  store <8 x i16> %68, <8 x i16>* %69, align 16
  %70 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %66, <4 x i32> %67) #8
  %71 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %72 = bitcast <2 x i64>* %71 to <8 x i16>*
  store <8 x i16> %70, <8 x i16>* %72, align 16
  %73 = bitcast <8 x i16> %68 to <16 x i8>
  %74 = shufflevector <16 x i8> %73, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %75 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %76 = bitcast <2 x i64>* %75 to <16 x i8>*
  store <16 x i8> %74, <16 x i8>* %76, align 16
  %77 = bitcast <8 x i16> %70 to <16 x i8>
  %78 = shufflevector <16 x i8> %77, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %79 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %80 = bitcast <2 x i64>* %79 to <16 x i8>*
  store <16 x i8> %78, <16 x i8>* %80, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @fadst4x4_new_sse2(<2 x i64>* nocapture readonly, <2 x i64>* nocapture, i8 signext) #0 {
  %4 = sext i8 %2 to i32
  %5 = add nsw i32 %4, -10
  %6 = sext i32 %5 to i64
  %7 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %6, i64 1
  %8 = load i32, i32* %7, align 4
  %9 = and i32 %8, 65535
  %10 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %6, i64 2
  %11 = load i32, i32* %10, align 4
  %12 = shl i32 %11, 16
  %13 = or i32 %12, %9
  %14 = insertelement <4 x i32> undef, i32 %13, i32 0
  %15 = shufflevector <4 x i32> %14, <4 x i32> undef, <4 x i32> zeroinitializer
  %16 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %6, i64 4
  %17 = load i32, i32* %16, align 4
  %18 = and i32 %17, 65535
  %19 = shl i32 %8, 16
  %20 = sub i32 0, %19
  %21 = or i32 %18, %20
  %22 = insertelement <4 x i32> undef, i32 %21, i32 0
  %23 = shufflevector <4 x i32> %22, <4 x i32> undef, <4 x i32> zeroinitializer
  %24 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %6, i64 3
  %25 = load i32, i32* %24, align 4
  %26 = and i32 %25, 65535
  %27 = shl i32 %17, 16
  %28 = or i32 %26, %27
  %29 = insertelement <4 x i32> undef, i32 %28, i32 0
  %30 = shufflevector <4 x i32> %29, <4 x i32> undef, <4 x i32> zeroinitializer
  %31 = sub i32 0, %25
  %32 = and i32 %31, 65535
  %33 = or i32 %32, %12
  %34 = insertelement <4 x i32> undef, i32 %33, i32 0
  %35 = shufflevector <4 x i32> %34, <4 x i32> undef, <4 x i32> zeroinitializer
  %36 = trunc i32 %25 to i16
  %37 = insertelement <8 x i16> undef, i16 %36, i32 0
  %38 = shufflevector <8 x i16> %37, <8 x i16> undef, <8 x i32> zeroinitializer
  %39 = add nsw i32 %4, -1
  %40 = shl i32 1, %39
  %41 = insertelement <4 x i32> undef, i32 %40, i32 0
  %42 = shufflevector <4 x i32> %41, <4 x i32> undef, <4 x i32> zeroinitializer
  %43 = bitcast <2 x i64>* %0 to <8 x i16>*
  %44 = load <8 x i16>, <8 x i16>* %43, align 16
  %45 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %46 = bitcast <2 x i64>* %45 to <8 x i16>*
  %47 = load <8 x i16>, <8 x i16>* %46, align 16
  %48 = add <8 x i16> %47, %44
  %49 = shufflevector <8 x i16> %44, <8 x i16> %47, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %50 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %51 = bitcast <2 x i64>* %50 to <8 x i16>*
  %52 = load <8 x i16>, <8 x i16>* %51, align 16
  %53 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %54 = bitcast <2 x i64>* %53 to <8 x i16>*
  %55 = load <8 x i16>, <8 x i16>* %54, align 16
  %56 = shufflevector <8 x i16> %52, <8 x i16> %55, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %57 = shufflevector <8 x i16> %48, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %58 = shufflevector <8 x i16> %52, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %59 = shufflevector <8 x i16> %55, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %60 = bitcast <4 x i32> %15 to <8 x i16>
  %61 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %49, <8 x i16> %60) #8
  %62 = bitcast <4 x i32> %30 to <8 x i16>
  %63 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %56, <8 x i16> %62) #8
  %64 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %57, <8 x i16> %38) #8
  %65 = bitcast <4 x i32> %23 to <8 x i16>
  %66 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %49, <8 x i16> %65) #8
  %67 = bitcast <4 x i32> %35 to <8 x i16>
  %68 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %56, <8 x i16> %67) #8
  %69 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %58, <8 x i16> %38) #8
  %70 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %59, <8 x i16> %38) #8
  %71 = add <4 x i32> %63, %61
  %72 = add <4 x i32> %68, %66
  %73 = mul <4 x i32> %69, <i32 3, i32 3, i32 3, i32 3>
  %74 = add <4 x i32> %71, %42
  %75 = add <4 x i32> %64, %42
  %76 = sub <4 x i32> %75, %70
  %77 = add <4 x i32> %72, %42
  %78 = sub <4 x i32> %42, %71
  %79 = add <4 x i32> %78, %72
  %80 = add <4 x i32> %79, %73
  %81 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %74, i32 %4) #8
  %82 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %76, i32 %4) #8
  %83 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %77, i32 %4) #8
  %84 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %80, i32 %4) #8
  %85 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %81, <4 x i32> %83) #8
  %86 = bitcast <2 x i64>* %1 to <8 x i16>*
  store <8 x i16> %85, <8 x i16>* %86, align 16
  %87 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %82, <4 x i32> %84) #8
  %88 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %89 = bitcast <2 x i64>* %88 to <8 x i16>*
  store <8 x i16> %87, <8 x i16>* %89, align 16
  %90 = bitcast <8 x i16> %85 to <16 x i8>
  %91 = shufflevector <16 x i8> %90, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %92 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %93 = bitcast <2 x i64>* %92 to <16 x i8>*
  store <16 x i8> %91, <16 x i8>* %93, align 16
  %94 = bitcast <8 x i16> %87 to <16 x i8>
  %95 = shufflevector <16 x i8> %94, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 8, i32 9, i32 10, i32 11, i32 12, i32 13, i32 14, i32 15, i32 16, i32 17, i32 18, i32 19, i32 20, i32 21, i32 22, i32 23>
  %96 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %97 = bitcast <2 x i64>* %96 to <16 x i8>*
  store <16 x i8> %95, <16 x i8>* %97, align 16
  ret void
}

; Function Attrs: inlinehint nofree nounwind ssp uwtable
define internal void @fidentity4x4_new_sse2(<2 x i64>* nocapture readonly, <2 x i64>* nocapture, i8 signext) #7 {
  %4 = bitcast <2 x i64>* %0 to <8 x i16>*
  %5 = load <8 x i16>, <8 x i16>* %4, align 16
  %6 = shufflevector <8 x i16> %5, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %7 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %8 = ashr <4 x i32> %7, <i32 12, i32 12, i32 12, i32 12>
  %9 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %8, <4 x i32> %8) #8
  %10 = bitcast <2 x i64>* %1 to <8 x i16>*
  store <8 x i16> %9, <8 x i16>* %10, align 16
  %11 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %12 = bitcast <2 x i64>* %11 to <8 x i16>*
  %13 = load <8 x i16>, <8 x i16>* %12, align 16
  %14 = shufflevector <8 x i16> %13, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %15 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %14, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %16 = ashr <4 x i32> %15, <i32 12, i32 12, i32 12, i32 12>
  %17 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %16, <4 x i32> %16) #8
  %18 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %19 = bitcast <2 x i64>* %18 to <8 x i16>*
  store <8 x i16> %17, <8 x i16>* %19, align 16
  %20 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %21 = bitcast <2 x i64>* %20 to <8 x i16>*
  %22 = load <8 x i16>, <8 x i16>* %21, align 16
  %23 = shufflevector <8 x i16> %22, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %24 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %23, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %25 = ashr <4 x i32> %24, <i32 12, i32 12, i32 12, i32 12>
  %26 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %25, <4 x i32> %25) #8
  %27 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %28 = bitcast <2 x i64>* %27 to <8 x i16>*
  store <8 x i16> %26, <8 x i16>* %28, align 16
  %29 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %30 = bitcast <2 x i64>* %29 to <8 x i16>*
  %31 = load <8 x i16>, <8 x i16>* %30, align 16
  %32 = shufflevector <8 x i16> %31, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %33 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %32, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %34 = ashr <4 x i32> %33, <i32 12, i32 12, i32 12, i32 12>
  %35 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %34, <4 x i32> %34) #8
  %36 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %37 = bitcast <2 x i64>* %36 to <8 x i16>*
  store <8 x i16> %35, <8 x i16>* %37, align 16
  ret void
}

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.sse2.psrai.w(<8 x i16>, i32) #6

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.sse2.pslli.w(<8 x i16>, i32) #6

; Function Attrs: nounwind ssp uwtable
define internal void @fdct4x8_new_sse2(<2 x i64>* nocapture readonly, <2 x i64>* nocapture, i8 signext) #2 {
  %4 = sext i8 %2 to i32
  %5 = add nsw i32 %4, -10
  %6 = sext i32 %5 to i64
  %7 = add nsw i32 %4, -1
  %8 = shl i32 1, %7
  %9 = insertelement <4 x i32> undef, i32 %8, i32 0
  %10 = shufflevector <4 x i32> %9, <4 x i32> undef, <4 x i32> zeroinitializer
  %11 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 32
  %12 = load i32, i32* %11, align 16
  %13 = sub i32 0, %12
  %14 = and i32 %13, 65535
  %15 = shl i32 %12, 16
  %16 = or i32 %14, %15
  %17 = insertelement <4 x i32> undef, i32 %16, i32 0
  %18 = shufflevector <4 x i32> %17, <4 x i32> undef, <4 x i32> zeroinitializer
  %19 = and i32 %12, 65535
  %20 = or i32 %19, %15
  %21 = insertelement <4 x i32> undef, i32 %20, i32 0
  %22 = shufflevector <4 x i32> %21, <4 x i32> undef, <4 x i32> zeroinitializer
  %23 = sub i32 0, %15
  %24 = or i32 %19, %23
  %25 = insertelement <4 x i32> undef, i32 %24, i32 0
  %26 = shufflevector <4 x i32> %25, <4 x i32> undef, <4 x i32> zeroinitializer
  %27 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 48
  %28 = load i32, i32* %27, align 16
  %29 = and i32 %28, 65535
  %30 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 16
  %31 = load i32, i32* %30, align 16
  %32 = shl i32 %31, 16
  %33 = or i32 %32, %29
  %34 = insertelement <4 x i32> undef, i32 %33, i32 0
  %35 = shufflevector <4 x i32> %34, <4 x i32> undef, <4 x i32> zeroinitializer
  %36 = sub i32 0, %31
  %37 = and i32 %36, 65535
  %38 = shl i32 %28, 16
  %39 = or i32 %37, %38
  %40 = insertelement <4 x i32> undef, i32 %39, i32 0
  %41 = shufflevector <4 x i32> %40, <4 x i32> undef, <4 x i32> zeroinitializer
  %42 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 56
  %43 = load i32, i32* %42, align 16
  %44 = and i32 %43, 65535
  %45 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 8
  %46 = load i32, i32* %45, align 16
  %47 = shl i32 %46, 16
  %48 = or i32 %47, %44
  %49 = insertelement <4 x i32> undef, i32 %48, i32 0
  %50 = shufflevector <4 x i32> %49, <4 x i32> undef, <4 x i32> zeroinitializer
  %51 = sub i32 0, %46
  %52 = and i32 %51, 65535
  %53 = shl i32 %43, 16
  %54 = or i32 %52, %53
  %55 = insertelement <4 x i32> undef, i32 %54, i32 0
  %56 = shufflevector <4 x i32> %55, <4 x i32> undef, <4 x i32> zeroinitializer
  %57 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 24
  %58 = load i32, i32* %57, align 16
  %59 = and i32 %58, 65535
  %60 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 40
  %61 = load i32, i32* %60, align 16
  %62 = shl i32 %61, 16
  %63 = or i32 %62, %59
  %64 = insertelement <4 x i32> undef, i32 %63, i32 0
  %65 = shufflevector <4 x i32> %64, <4 x i32> undef, <4 x i32> zeroinitializer
  %66 = sub i32 0, %61
  %67 = and i32 %66, 65535
  %68 = shl i32 %58, 16
  %69 = or i32 %67, %68
  %70 = insertelement <4 x i32> undef, i32 %69, i32 0
  %71 = shufflevector <4 x i32> %70, <4 x i32> undef, <4 x i32> zeroinitializer
  %72 = bitcast <2 x i64>* %0 to <8 x i16>*
  %73 = load <8 x i16>, <8 x i16>* %72, align 16
  %74 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %75 = bitcast <2 x i64>* %74 to <8 x i16>*
  %76 = load <8 x i16>, <8 x i16>* %75, align 16
  %77 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %73, <8 x i16> %76) #8
  %78 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %73, <8 x i16> %76) #8
  %79 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %80 = bitcast <2 x i64>* %79 to <8 x i16>*
  %81 = load <8 x i16>, <8 x i16>* %80, align 16
  %82 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %83 = bitcast <2 x i64>* %82 to <8 x i16>*
  %84 = load <8 x i16>, <8 x i16>* %83, align 16
  %85 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %81, <8 x i16> %84) #8
  %86 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %81, <8 x i16> %84) #8
  %87 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %88 = bitcast <2 x i64>* %87 to <8 x i16>*
  %89 = load <8 x i16>, <8 x i16>* %88, align 16
  %90 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %91 = bitcast <2 x i64>* %90 to <8 x i16>*
  %92 = load <8 x i16>, <8 x i16>* %91, align 16
  %93 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %89, <8 x i16> %92) #8
  %94 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %89, <8 x i16> %92) #8
  %95 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %96 = bitcast <2 x i64>* %95 to <8 x i16>*
  %97 = load <8 x i16>, <8 x i16>* %96, align 16
  %98 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %99 = bitcast <2 x i64>* %98 to <8 x i16>*
  %100 = load <8 x i16>, <8 x i16>* %99, align 16
  %101 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %97, <8 x i16> %100) #8
  %102 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %97, <8 x i16> %100) #8
  %103 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %77, <8 x i16> %101) #8
  %104 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %77, <8 x i16> %101) #8
  %105 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %85, <8 x i16> %93) #8
  %106 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %85, <8 x i16> %93) #8
  %107 = shufflevector <8 x i16> %94, <8 x i16> %86, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %108 = bitcast <4 x i32> %18 to <8 x i16>
  %109 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %107, <8 x i16> %108) #8
  %110 = bitcast <4 x i32> %22 to <8 x i16>
  %111 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %107, <8 x i16> %110) #8
  %112 = add <4 x i32> %109, %10
  %113 = add <4 x i32> %111, %10
  %114 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %112, i32 %4) #8
  %115 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %113, i32 %4) #8
  %116 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %114, <4 x i32> %114) #8
  %117 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %115, <4 x i32> %114) #8
  %118 = shufflevector <8 x i16> %103, <8 x i16> %105, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %119 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %118, <8 x i16> %110) #8
  %120 = bitcast <4 x i32> %26 to <8 x i16>
  %121 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %118, <8 x i16> %120) #8
  %122 = add <4 x i32> %119, %10
  %123 = add <4 x i32> %121, %10
  %124 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %122, i32 %4) #8
  %125 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %123, i32 %4) #8
  %126 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %124, <4 x i32> %124) #8
  %127 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %125, <4 x i32> %124) #8
  %128 = shufflevector <8 x i16> %106, <8 x i16> %104, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %129 = bitcast <4 x i32> %35 to <8 x i16>
  %130 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %128, <8 x i16> %129) #8
  %131 = bitcast <4 x i32> %41 to <8 x i16>
  %132 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %128, <8 x i16> %131) #8
  %133 = add <4 x i32> %130, %10
  %134 = add <4 x i32> %132, %10
  %135 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %133, i32 %4) #8
  %136 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %134, i32 %4) #8
  %137 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %135, <4 x i32> %135) #8
  %138 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %136, <4 x i32> %135) #8
  %139 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %102, <8 x i16> %116) #8
  %140 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %102, <8 x i16> %116) #8
  %141 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %78, <8 x i16> %117) #8
  %142 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %78, <8 x i16> %117) #8
  %143 = shufflevector <8 x i16> %139, <8 x i16> %142, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %144 = bitcast <4 x i32> %50 to <8 x i16>
  %145 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %143, <8 x i16> %144) #8
  %146 = bitcast <4 x i32> %56 to <8 x i16>
  %147 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %143, <8 x i16> %146) #8
  %148 = add <4 x i32> %145, %10
  %149 = add <4 x i32> %147, %10
  %150 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %148, i32 %4) #8
  %151 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %149, i32 %4) #8
  %152 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %150, <4 x i32> %150) #8
  %153 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %151, <4 x i32> %150) #8
  %154 = shufflevector <8 x i16> %140, <8 x i16> %141, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %155 = bitcast <4 x i32> %65 to <8 x i16>
  %156 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %154, <8 x i16> %155) #8
  %157 = bitcast <4 x i32> %71 to <8 x i16>
  %158 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %154, <8 x i16> %157) #8
  %159 = add <4 x i32> %156, %10
  %160 = add <4 x i32> %158, %10
  %161 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %159, i32 %4) #8
  %162 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %160, i32 %4) #8
  %163 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %161, <4 x i32> %161) #8
  %164 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %162, <4 x i32> %161) #8
  %165 = bitcast <2 x i64>* %1 to <8 x i16>*
  store <8 x i16> %126, <8 x i16>* %165, align 16
  %166 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %167 = bitcast <2 x i64>* %166 to <8 x i16>*
  store <8 x i16> %152, <8 x i16>* %167, align 16
  %168 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %169 = bitcast <2 x i64>* %168 to <8 x i16>*
  store <8 x i16> %137, <8 x i16>* %169, align 16
  %170 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %171 = bitcast <2 x i64>* %170 to <8 x i16>*
  store <8 x i16> %164, <8 x i16>* %171, align 16
  %172 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %173 = bitcast <2 x i64>* %172 to <8 x i16>*
  store <8 x i16> %127, <8 x i16>* %173, align 16
  %174 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %175 = bitcast <2 x i64>* %174 to <8 x i16>*
  store <8 x i16> %163, <8 x i16>* %175, align 16
  %176 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %177 = bitcast <2 x i64>* %176 to <8 x i16>*
  store <8 x i16> %138, <8 x i16>* %177, align 16
  %178 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %179 = bitcast <2 x i64>* %178 to <8 x i16>*
  store <8 x i16> %153, <8 x i16>* %179, align 16
  ret void
}

; Function Attrs: nounwind ssp uwtable
define internal void @fadst4x8_new_sse2(<2 x i64>* nocapture readonly, <2 x i64>* nocapture, i8 signext) #2 {
  %4 = sext i8 %2 to i32
  %5 = add nsw i32 %4, -10
  %6 = sext i32 %5 to i64
  %7 = add nsw i32 %4, -1
  %8 = shl i32 1, %7
  %9 = insertelement <4 x i32> undef, i32 %8, i32 0
  %10 = shufflevector <4 x i32> %9, <4 x i32> undef, <4 x i32> zeroinitializer
  %11 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 32
  %12 = load i32, i32* %11, align 16
  %13 = and i32 %12, 65535
  %14 = shl i32 %12, 16
  %15 = or i32 %13, %14
  %16 = insertelement <4 x i32> undef, i32 %15, i32 0
  %17 = shufflevector <4 x i32> %16, <4 x i32> undef, <4 x i32> zeroinitializer
  %18 = sub i32 0, %14
  %19 = or i32 %13, %18
  %20 = insertelement <4 x i32> undef, i32 %19, i32 0
  %21 = shufflevector <4 x i32> %20, <4 x i32> undef, <4 x i32> zeroinitializer
  %22 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 16
  %23 = load i32, i32* %22, align 16
  %24 = and i32 %23, 65535
  %25 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 48
  %26 = load i32, i32* %25, align 16
  %27 = shl i32 %26, 16
  %28 = or i32 %27, %24
  %29 = insertelement <4 x i32> undef, i32 %28, i32 0
  %30 = shufflevector <4 x i32> %29, <4 x i32> undef, <4 x i32> zeroinitializer
  %31 = and i32 %26, 65535
  %32 = shl i32 %23, 16
  %33 = sub i32 0, %32
  %34 = or i32 %31, %33
  %35 = insertelement <4 x i32> undef, i32 %34, i32 0
  %36 = shufflevector <4 x i32> %35, <4 x i32> undef, <4 x i32> zeroinitializer
  %37 = sub i32 0, %26
  %38 = and i32 %37, 65535
  %39 = or i32 %38, %32
  %40 = insertelement <4 x i32> undef, i32 %39, i32 0
  %41 = shufflevector <4 x i32> %40, <4 x i32> undef, <4 x i32> zeroinitializer
  %42 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 4
  %43 = load i32, i32* %42, align 16
  %44 = and i32 %43, 65535
  %45 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 60
  %46 = load i32, i32* %45, align 16
  %47 = shl i32 %46, 16
  %48 = or i32 %47, %44
  %49 = insertelement <4 x i32> undef, i32 %48, i32 0
  %50 = shufflevector <4 x i32> %49, <4 x i32> undef, <4 x i32> zeroinitializer
  %51 = and i32 %46, 65535
  %52 = shl i32 %43, 16
  %53 = sub i32 0, %52
  %54 = or i32 %51, %53
  %55 = insertelement <4 x i32> undef, i32 %54, i32 0
  %56 = shufflevector <4 x i32> %55, <4 x i32> undef, <4 x i32> zeroinitializer
  %57 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 20
  %58 = load i32, i32* %57, align 16
  %59 = and i32 %58, 65535
  %60 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 44
  %61 = load i32, i32* %60, align 16
  %62 = shl i32 %61, 16
  %63 = or i32 %62, %59
  %64 = insertelement <4 x i32> undef, i32 %63, i32 0
  %65 = shufflevector <4 x i32> %64, <4 x i32> undef, <4 x i32> zeroinitializer
  %66 = and i32 %61, 65535
  %67 = shl i32 %58, 16
  %68 = sub i32 0, %67
  %69 = or i32 %66, %68
  %70 = insertelement <4 x i32> undef, i32 %69, i32 0
  %71 = shufflevector <4 x i32> %70, <4 x i32> undef, <4 x i32> zeroinitializer
  %72 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 36
  %73 = load i32, i32* %72, align 16
  %74 = and i32 %73, 65535
  %75 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 28
  %76 = load i32, i32* %75, align 16
  %77 = shl i32 %76, 16
  %78 = or i32 %77, %74
  %79 = insertelement <4 x i32> undef, i32 %78, i32 0
  %80 = shufflevector <4 x i32> %79, <4 x i32> undef, <4 x i32> zeroinitializer
  %81 = and i32 %76, 65535
  %82 = shl i32 %73, 16
  %83 = sub i32 0, %82
  %84 = or i32 %81, %83
  %85 = insertelement <4 x i32> undef, i32 %84, i32 0
  %86 = shufflevector <4 x i32> %85, <4 x i32> undef, <4 x i32> zeroinitializer
  %87 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 52
  %88 = load i32, i32* %87, align 16
  %89 = and i32 %88, 65535
  %90 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 12
  %91 = load i32, i32* %90, align 16
  %92 = shl i32 %91, 16
  %93 = or i32 %92, %89
  %94 = insertelement <4 x i32> undef, i32 %93, i32 0
  %95 = shufflevector <4 x i32> %94, <4 x i32> undef, <4 x i32> zeroinitializer
  %96 = and i32 %91, 65535
  %97 = shl i32 %88, 16
  %98 = sub i32 0, %97
  %99 = or i32 %96, %98
  %100 = insertelement <4 x i32> undef, i32 %99, i32 0
  %101 = shufflevector <4 x i32> %100, <4 x i32> undef, <4 x i32> zeroinitializer
  %102 = bitcast <2 x i64>* %0 to <8 x i16>*
  %103 = load <8 x i16>, <8 x i16>* %102, align 16
  %104 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %105 = bitcast <2 x i64>* %104 to <8 x i16>*
  %106 = load <8 x i16>, <8 x i16>* %105, align 16
  %107 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> zeroinitializer, <8 x i16> %106) #8
  %108 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %109 = bitcast <2 x i64>* %108 to <8 x i16>*
  %110 = load <8 x i16>, <8 x i16>* %109, align 16
  %111 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> zeroinitializer, <8 x i16> %110) #8
  %112 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %113 = bitcast <2 x i64>* %112 to <8 x i16>*
  %114 = load <8 x i16>, <8 x i16>* %113, align 16
  %115 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %116 = bitcast <2 x i64>* %115 to <8 x i16>*
  %117 = load <8 x i16>, <8 x i16>* %116, align 16
  %118 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> zeroinitializer, <8 x i16> %117) #8
  %119 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %120 = bitcast <2 x i64>* %119 to <8 x i16>*
  %121 = load <8 x i16>, <8 x i16>* %120, align 16
  %122 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %123 = bitcast <2 x i64>* %122 to <8 x i16>*
  %124 = load <8 x i16>, <8 x i16>* %123, align 16
  %125 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %126 = bitcast <2 x i64>* %125 to <8 x i16>*
  %127 = load <8 x i16>, <8 x i16>* %126, align 16
  %128 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> zeroinitializer, <8 x i16> %127) #8
  %129 = shufflevector <8 x i16> %111, <8 x i16> %114, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %130 = bitcast <4 x i32> %17 to <8 x i16>
  %131 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %129, <8 x i16> %130) #8
  %132 = bitcast <4 x i32> %21 to <8 x i16>
  %133 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %129, <8 x i16> %132) #8
  %134 = add <4 x i32> %131, %10
  %135 = add <4 x i32> %133, %10
  %136 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %134, i32 %4) #8
  %137 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %135, i32 %4) #8
  %138 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %136, <4 x i32> %136) #8
  %139 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %137, <4 x i32> %136) #8
  %140 = shufflevector <8 x i16> %124, <8 x i16> %128, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %141 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %140, <8 x i16> %130) #8
  %142 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %140, <8 x i16> %132) #8
  %143 = add <4 x i32> %141, %10
  %144 = add <4 x i32> %142, %10
  %145 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %143, i32 %4) #8
  %146 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %144, i32 %4) #8
  %147 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %145, <4 x i32> %145) #8
  %148 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %146, <4 x i32> %145) #8
  %149 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %103, <8 x i16> %138) #8
  %150 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %103, <8 x i16> %138) #8
  %151 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %107, <8 x i16> %139) #8
  %152 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %107, <8 x i16> %139) #8
  %153 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %118, <8 x i16> %147) #8
  %154 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %118, <8 x i16> %147) #8
  %155 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %121, <8 x i16> %148) #8
  %156 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %121, <8 x i16> %148) #8
  %157 = shufflevector <8 x i16> %153, <8 x i16> %155, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %158 = bitcast <4 x i32> %30 to <8 x i16>
  %159 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %157, <8 x i16> %158) #8
  %160 = bitcast <4 x i32> %36 to <8 x i16>
  %161 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %157, <8 x i16> %160) #8
  %162 = add <4 x i32> %159, %10
  %163 = add <4 x i32> %161, %10
  %164 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %162, i32 %4) #8
  %165 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %163, i32 %4) #8
  %166 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %164, <4 x i32> %164) #8
  %167 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %165, <4 x i32> %164) #8
  %168 = shufflevector <8 x i16> %154, <8 x i16> %156, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %169 = bitcast <4 x i32> %41 to <8 x i16>
  %170 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %168, <8 x i16> %169) #8
  %171 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %168, <8 x i16> %158) #8
  %172 = add <4 x i32> %170, %10
  %173 = add <4 x i32> %171, %10
  %174 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %172, i32 %4) #8
  %175 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %173, i32 %4) #8
  %176 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %174, <4 x i32> %174) #8
  %177 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %175, <4 x i32> %174) #8
  %178 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %149, <8 x i16> %166) #8
  %179 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %149, <8 x i16> %166) #8
  %180 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %151, <8 x i16> %167) #8
  %181 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %151, <8 x i16> %167) #8
  %182 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %150, <8 x i16> %176) #8
  %183 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %150, <8 x i16> %176) #8
  %184 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %152, <8 x i16> %177) #8
  %185 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %152, <8 x i16> %177) #8
  %186 = shufflevector <8 x i16> %178, <8 x i16> %180, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %187 = bitcast <4 x i32> %50 to <8 x i16>
  %188 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %186, <8 x i16> %187) #8
  %189 = bitcast <4 x i32> %56 to <8 x i16>
  %190 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %186, <8 x i16> %189) #8
  %191 = add <4 x i32> %188, %10
  %192 = add <4 x i32> %190, %10
  %193 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %191, i32 %4) #8
  %194 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %192, i32 %4) #8
  %195 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %193, <4 x i32> %193) #8
  %196 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %194, <4 x i32> %193) #8
  %197 = shufflevector <8 x i16> %182, <8 x i16> %184, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %198 = bitcast <4 x i32> %65 to <8 x i16>
  %199 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %197, <8 x i16> %198) #8
  %200 = bitcast <4 x i32> %71 to <8 x i16>
  %201 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %197, <8 x i16> %200) #8
  %202 = add <4 x i32> %199, %10
  %203 = add <4 x i32> %201, %10
  %204 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %202, i32 %4) #8
  %205 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %203, i32 %4) #8
  %206 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %204, <4 x i32> %204) #8
  %207 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %205, <4 x i32> %204) #8
  %208 = shufflevector <8 x i16> %179, <8 x i16> %181, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %209 = bitcast <4 x i32> %80 to <8 x i16>
  %210 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %208, <8 x i16> %209) #8
  %211 = bitcast <4 x i32> %86 to <8 x i16>
  %212 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %208, <8 x i16> %211) #8
  %213 = add <4 x i32> %210, %10
  %214 = add <4 x i32> %212, %10
  %215 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %213, i32 %4) #8
  %216 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %214, i32 %4) #8
  %217 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %215, <4 x i32> %215) #8
  %218 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %216, <4 x i32> %215) #8
  %219 = shufflevector <8 x i16> %183, <8 x i16> %185, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %220 = bitcast <4 x i32> %95 to <8 x i16>
  %221 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %219, <8 x i16> %220) #8
  %222 = bitcast <4 x i32> %101 to <8 x i16>
  %223 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %219, <8 x i16> %222) #8
  %224 = add <4 x i32> %221, %10
  %225 = add <4 x i32> %223, %10
  %226 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %224, i32 %4) #8
  %227 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %225, i32 %4) #8
  %228 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %226, <4 x i32> %226) #8
  %229 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %227, <4 x i32> %226) #8
  %230 = bitcast <2 x i64>* %1 to <8 x i16>*
  store <8 x i16> %196, <8 x i16>* %230, align 16
  %231 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %232 = bitcast <2 x i64>* %231 to <8 x i16>*
  store <8 x i16> %228, <8 x i16>* %232, align 16
  %233 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %234 = bitcast <2 x i64>* %233 to <8 x i16>*
  store <8 x i16> %207, <8 x i16>* %234, align 16
  %235 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %236 = bitcast <2 x i64>* %235 to <8 x i16>*
  store <8 x i16> %217, <8 x i16>* %236, align 16
  %237 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %238 = bitcast <2 x i64>* %237 to <8 x i16>*
  store <8 x i16> %218, <8 x i16>* %238, align 16
  %239 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %240 = bitcast <2 x i64>* %239 to <8 x i16>*
  store <8 x i16> %206, <8 x i16>* %240, align 16
  %241 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %242 = bitcast <2 x i64>* %241 to <8 x i16>*
  store <8 x i16> %229, <8 x i16>* %242, align 16
  %243 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %244 = bitcast <2 x i64>* %243 to <8 x i16>*
  store <8 x i16> %195, <8 x i16>* %244, align 16
  ret void
}

; Function Attrs: inlinehint nofree nounwind ssp uwtable
define internal void @fidentity8x8_new_sse2(<2 x i64>* nocapture readonly, <2 x i64>* nocapture, i8 signext) #7 {
  %4 = bitcast <2 x i64>* %0 to <8 x i16>*
  %5 = load <8 x i16>, <8 x i16>* %4, align 16
  %6 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %5, <8 x i16> %5) #8
  %7 = bitcast <2 x i64>* %1 to <8 x i16>*
  store <8 x i16> %6, <8 x i16>* %7, align 16
  %8 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %9 = bitcast <2 x i64>* %8 to <8 x i16>*
  %10 = load <8 x i16>, <8 x i16>* %9, align 16
  %11 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %10, <8 x i16> %10) #8
  %12 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %13 = bitcast <2 x i64>* %12 to <8 x i16>*
  store <8 x i16> %11, <8 x i16>* %13, align 16
  %14 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %15 = bitcast <2 x i64>* %14 to <8 x i16>*
  %16 = load <8 x i16>, <8 x i16>* %15, align 16
  %17 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %16, <8 x i16> %16) #8
  %18 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %19 = bitcast <2 x i64>* %18 to <8 x i16>*
  store <8 x i16> %17, <8 x i16>* %19, align 16
  %20 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %21 = bitcast <2 x i64>* %20 to <8 x i16>*
  %22 = load <8 x i16>, <8 x i16>* %21, align 16
  %23 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %22, <8 x i16> %22) #8
  %24 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %25 = bitcast <2 x i64>* %24 to <8 x i16>*
  store <8 x i16> %23, <8 x i16>* %25, align 16
  %26 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %27 = bitcast <2 x i64>* %26 to <8 x i16>*
  %28 = load <8 x i16>, <8 x i16>* %27, align 16
  %29 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %28, <8 x i16> %28) #8
  %30 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %31 = bitcast <2 x i64>* %30 to <8 x i16>*
  store <8 x i16> %29, <8 x i16>* %31, align 16
  %32 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %33 = bitcast <2 x i64>* %32 to <8 x i16>*
  %34 = load <8 x i16>, <8 x i16>* %33, align 16
  %35 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %34, <8 x i16> %34) #8
  %36 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %37 = bitcast <2 x i64>* %36 to <8 x i16>*
  store <8 x i16> %35, <8 x i16>* %37, align 16
  %38 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %39 = bitcast <2 x i64>* %38 to <8 x i16>*
  %40 = load <8 x i16>, <8 x i16>* %39, align 16
  %41 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %40, <8 x i16> %40) #8
  %42 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %43 = bitcast <2 x i64>* %42 to <8 x i16>*
  store <8 x i16> %41, <8 x i16>* %43, align 16
  %44 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %45 = bitcast <2 x i64>* %44 to <8 x i16>*
  %46 = load <8 x i16>, <8 x i16>* %45, align 16
  %47 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %46, <8 x i16> %46) #8
  %48 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %49 = bitcast <2 x i64>* %48 to <8 x i16>*
  store <8 x i16> %47, <8 x i16>* %49, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @fdct8x4_new_sse2(<2 x i64>* nocapture readonly, <2 x i64>* nocapture, i8 signext) #0 {
  %4 = sext i8 %2 to i32
  %5 = add nsw i32 %4, -10
  %6 = sext i32 %5 to i64
  %7 = add nsw i32 %4, -1
  %8 = shl i32 1, %7
  %9 = insertelement <4 x i32> undef, i32 %8, i32 0
  %10 = shufflevector <4 x i32> %9, <4 x i32> undef, <4 x i32> zeroinitializer
  %11 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 32
  %12 = load i32, i32* %11, align 16
  %13 = and i32 %12, 65535
  %14 = shl i32 %12, 16
  %15 = or i32 %13, %14
  %16 = insertelement <4 x i32> undef, i32 %15, i32 0
  %17 = shufflevector <4 x i32> %16, <4 x i32> undef, <4 x i32> zeroinitializer
  %18 = sub i32 0, %14
  %19 = or i32 %13, %18
  %20 = insertelement <4 x i32> undef, i32 %19, i32 0
  %21 = shufflevector <4 x i32> %20, <4 x i32> undef, <4 x i32> zeroinitializer
  %22 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 48
  %23 = load i32, i32* %22, align 16
  %24 = and i32 %23, 65535
  %25 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 16
  %26 = load i32, i32* %25, align 16
  %27 = shl i32 %26, 16
  %28 = or i32 %27, %24
  %29 = insertelement <4 x i32> undef, i32 %28, i32 0
  %30 = shufflevector <4 x i32> %29, <4 x i32> undef, <4 x i32> zeroinitializer
  %31 = sub i32 0, %26
  %32 = and i32 %31, 65535
  %33 = shl i32 %23, 16
  %34 = or i32 %32, %33
  %35 = insertelement <4 x i32> undef, i32 %34, i32 0
  %36 = shufflevector <4 x i32> %35, <4 x i32> undef, <4 x i32> zeroinitializer
  %37 = bitcast <2 x i64>* %0 to <8 x i16>*
  %38 = load <8 x i16>, <8 x i16>* %37, align 16
  %39 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %40 = bitcast <2 x i64>* %39 to <8 x i16>*
  %41 = load <8 x i16>, <8 x i16>* %40, align 16
  %42 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %38, <8 x i16> %41) #8
  %43 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %38, <8 x i16> %41) #8
  %44 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %45 = bitcast <2 x i64>* %44 to <8 x i16>*
  %46 = load <8 x i16>, <8 x i16>* %45, align 16
  %47 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %48 = bitcast <2 x i64>* %47 to <8 x i16>*
  %49 = load <8 x i16>, <8 x i16>* %48, align 16
  %50 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %46, <8 x i16> %49) #8
  %51 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %46, <8 x i16> %49) #8
  %52 = shufflevector <8 x i16> %42, <8 x i16> %50, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %53 = shufflevector <8 x i16> %42, <8 x i16> %50, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %54 = bitcast <4 x i32> %17 to <8 x i16>
  %55 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %52, <8 x i16> %54) #8
  %56 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %53, <8 x i16> %54) #8
  %57 = bitcast <4 x i32> %21 to <8 x i16>
  %58 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %52, <8 x i16> %57) #8
  %59 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %53, <8 x i16> %57) #8
  %60 = add <4 x i32> %55, %10
  %61 = add <4 x i32> %56, %10
  %62 = add <4 x i32> %58, %10
  %63 = add <4 x i32> %59, %10
  %64 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %60, i32 %4) #8
  %65 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %61, i32 %4) #8
  %66 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %62, i32 %4) #8
  %67 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %63, i32 %4) #8
  %68 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %64, <4 x i32> %65) #8
  %69 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %66, <4 x i32> %67) #8
  %70 = shufflevector <8 x i16> %51, <8 x i16> %43, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %71 = shufflevector <8 x i16> %51, <8 x i16> %43, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %72 = bitcast <4 x i32> %30 to <8 x i16>
  %73 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %70, <8 x i16> %72) #8
  %74 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %71, <8 x i16> %72) #8
  %75 = bitcast <4 x i32> %36 to <8 x i16>
  %76 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %70, <8 x i16> %75) #8
  %77 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %71, <8 x i16> %75) #8
  %78 = add <4 x i32> %73, %10
  %79 = add <4 x i32> %74, %10
  %80 = add <4 x i32> %76, %10
  %81 = add <4 x i32> %77, %10
  %82 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %78, i32 %4) #8
  %83 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %79, i32 %4) #8
  %84 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %80, i32 %4) #8
  %85 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %81, i32 %4) #8
  %86 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %82, <4 x i32> %83) #8
  %87 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %84, <4 x i32> %85) #8
  %88 = bitcast <2 x i64>* %1 to <8 x i16>*
  store <8 x i16> %68, <8 x i16>* %88, align 16
  %89 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %90 = bitcast <2 x i64>* %89 to <8 x i16>*
  store <8 x i16> %86, <8 x i16>* %90, align 16
  %91 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %92 = bitcast <2 x i64>* %91 to <8 x i16>*
  store <8 x i16> %69, <8 x i16>* %92, align 16
  %93 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %94 = bitcast <2 x i64>* %93 to <8 x i16>*
  store <8 x i16> %87, <8 x i16>* %94, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @fadst8x4_new_sse2(<2 x i64>* nocapture readonly, <2 x i64>* nocapture, i8 signext) #0 {
  %4 = sext i8 %2 to i32
  %5 = add nsw i32 %4, -10
  %6 = sext i32 %5 to i64
  %7 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %6, i64 1
  %8 = load i32, i32* %7, align 4
  %9 = and i32 %8, 65535
  %10 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %6, i64 2
  %11 = load i32, i32* %10, align 4
  %12 = shl i32 %11, 16
  %13 = or i32 %12, %9
  %14 = insertelement <4 x i32> undef, i32 %13, i32 0
  %15 = shufflevector <4 x i32> %14, <4 x i32> undef, <4 x i32> zeroinitializer
  %16 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %6, i64 4
  %17 = load i32, i32* %16, align 4
  %18 = and i32 %17, 65535
  %19 = shl i32 %8, 16
  %20 = sub i32 0, %19
  %21 = or i32 %18, %20
  %22 = insertelement <4 x i32> undef, i32 %21, i32 0
  %23 = shufflevector <4 x i32> %22, <4 x i32> undef, <4 x i32> zeroinitializer
  %24 = getelementptr inbounds [7 x [5 x i32]], [7 x [5 x i32]]* @av1_sinpi_arr_data, i64 0, i64 %6, i64 3
  %25 = load i32, i32* %24, align 4
  %26 = and i32 %25, 65535
  %27 = shl i32 %17, 16
  %28 = or i32 %26, %27
  %29 = insertelement <4 x i32> undef, i32 %28, i32 0
  %30 = shufflevector <4 x i32> %29, <4 x i32> undef, <4 x i32> zeroinitializer
  %31 = sub i32 0, %25
  %32 = and i32 %31, 65535
  %33 = or i32 %32, %12
  %34 = insertelement <4 x i32> undef, i32 %33, i32 0
  %35 = shufflevector <4 x i32> %34, <4 x i32> undef, <4 x i32> zeroinitializer
  %36 = trunc i32 %25 to i16
  %37 = insertelement <8 x i16> undef, i16 %36, i32 0
  %38 = shufflevector <8 x i16> %37, <8 x i16> undef, <8 x i32> zeroinitializer
  %39 = add nsw i32 %4, -1
  %40 = shl i32 1, %39
  %41 = insertelement <4 x i32> undef, i32 %40, i32 0
  %42 = shufflevector <4 x i32> %41, <4 x i32> undef, <4 x i32> zeroinitializer
  %43 = bitcast <2 x i64>* %0 to <8 x i16>*
  %44 = load <8 x i16>, <8 x i16>* %43, align 16
  %45 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %46 = bitcast <2 x i64>* %45 to <8 x i16>*
  %47 = load <8 x i16>, <8 x i16>* %46, align 16
  %48 = add <8 x i16> %47, %44
  %49 = shufflevector <8 x i16> %44, <8 x i16> %47, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %50 = shufflevector <8 x i16> %44, <8 x i16> %47, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %51 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %52 = bitcast <2 x i64>* %51 to <8 x i16>*
  %53 = load <8 x i16>, <8 x i16>* %52, align 16
  %54 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %55 = bitcast <2 x i64>* %54 to <8 x i16>*
  %56 = load <8 x i16>, <8 x i16>* %55, align 16
  %57 = shufflevector <8 x i16> %53, <8 x i16> %56, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %58 = shufflevector <8 x i16> %53, <8 x i16> %56, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %59 = shufflevector <8 x i16> %48, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %60 = shufflevector <8 x i16> %48, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %61 = shufflevector <8 x i16> %53, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %62 = shufflevector <8 x i16> %53, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %63 = shufflevector <8 x i16> %56, <8 x i16> <i16 0, i16 0, i16 0, i16 0, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %64 = shufflevector <8 x i16> %56, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 0, i16 0, i16 0, i16 0>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %65 = bitcast <4 x i32> %15 to <8 x i16>
  %66 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %49, <8 x i16> %65) #8
  %67 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %50, <8 x i16> %65) #8
  %68 = bitcast <4 x i32> %30 to <8 x i16>
  %69 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %57, <8 x i16> %68) #8
  %70 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %58, <8 x i16> %68) #8
  %71 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %59, <8 x i16> %38) #8
  %72 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %60, <8 x i16> %38) #8
  %73 = bitcast <4 x i32> %23 to <8 x i16>
  %74 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %49, <8 x i16> %73) #8
  %75 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %50, <8 x i16> %73) #8
  %76 = bitcast <4 x i32> %35 to <8 x i16>
  %77 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %57, <8 x i16> %76) #8
  %78 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %58, <8 x i16> %76) #8
  %79 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %61, <8 x i16> %38) #8
  %80 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %62, <8 x i16> %38) #8
  %81 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %63, <8 x i16> %38) #8
  %82 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %64, <8 x i16> %38) #8
  %83 = add <4 x i32> %69, %66
  %84 = add <4 x i32> %70, %67
  %85 = add <4 x i32> %77, %74
  %86 = add <4 x i32> %78, %75
  %87 = mul <4 x i32> %79, <i32 3, i32 3, i32 3, i32 3>
  %88 = mul <4 x i32> %80, <i32 3, i32 3, i32 3, i32 3>
  %89 = add <4 x i32> %83, %42
  %90 = add <4 x i32> %84, %42
  %91 = add <4 x i32> %71, %42
  %92 = sub <4 x i32> %91, %81
  %93 = add <4 x i32> %72, %42
  %94 = sub <4 x i32> %93, %82
  %95 = add <4 x i32> %85, %42
  %96 = add <4 x i32> %86, %42
  %97 = sub <4 x i32> %42, %83
  %98 = add <4 x i32> %97, %85
  %99 = add <4 x i32> %98, %87
  %100 = sub <4 x i32> %42, %84
  %101 = add <4 x i32> %100, %86
  %102 = add <4 x i32> %101, %88
  %103 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %89, i32 %4) #8
  %104 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %90, i32 %4) #8
  %105 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %92, i32 %4) #8
  %106 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %94, i32 %4) #8
  %107 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %95, i32 %4) #8
  %108 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %96, i32 %4) #8
  %109 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %99, i32 %4) #8
  %110 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %102, i32 %4) #8
  %111 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %103, <4 x i32> %104) #8
  %112 = bitcast <2 x i64>* %1 to <8 x i16>*
  store <8 x i16> %111, <8 x i16>* %112, align 16
  %113 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %105, <4 x i32> %106) #8
  %114 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %115 = bitcast <2 x i64>* %114 to <8 x i16>*
  store <8 x i16> %113, <8 x i16>* %115, align 16
  %116 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %107, <4 x i32> %108) #8
  %117 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %118 = bitcast <2 x i64>* %117 to <8 x i16>*
  store <8 x i16> %116, <8 x i16>* %118, align 16
  %119 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %109, <4 x i32> %110) #8
  %120 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %121 = bitcast <2 x i64>* %120 to <8 x i16>*
  store <8 x i16> %119, <8 x i16>* %121, align 16
  ret void
}

; Function Attrs: inlinehint nofree nounwind ssp uwtable
define internal void @fidentity8x4_new_sse2(<2 x i64>* nocapture readonly, <2 x i64>* nocapture, i8 signext) #7 {
  %4 = bitcast <2 x i64>* %0 to <8 x i16>*
  %5 = load <8 x i16>, <8 x i16>* %4, align 16
  %6 = shufflevector <8 x i16> %5, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %7 = shufflevector <8 x i16> %5, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %8 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %6, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %9 = ashr <4 x i32> %8, <i32 12, i32 12, i32 12, i32 12>
  %10 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %7, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %11 = ashr <4 x i32> %10, <i32 12, i32 12, i32 12, i32 12>
  %12 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %9, <4 x i32> %11) #8
  %13 = bitcast <2 x i64>* %1 to <8 x i16>*
  store <8 x i16> %12, <8 x i16>* %13, align 16
  %14 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %15 = bitcast <2 x i64>* %14 to <8 x i16>*
  %16 = load <8 x i16>, <8 x i16>* %15, align 16
  %17 = shufflevector <8 x i16> %16, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %18 = shufflevector <8 x i16> %16, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %19 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %17, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %20 = ashr <4 x i32> %19, <i32 12, i32 12, i32 12, i32 12>
  %21 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %18, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %22 = ashr <4 x i32> %21, <i32 12, i32 12, i32 12, i32 12>
  %23 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %20, <4 x i32> %22) #8
  %24 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %25 = bitcast <2 x i64>* %24 to <8 x i16>*
  store <8 x i16> %23, <8 x i16>* %25, align 16
  %26 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %27 = bitcast <2 x i64>* %26 to <8 x i16>*
  %28 = load <8 x i16>, <8 x i16>* %27, align 16
  %29 = shufflevector <8 x i16> %28, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %30 = shufflevector <8 x i16> %28, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %31 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %29, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %32 = ashr <4 x i32> %31, <i32 12, i32 12, i32 12, i32 12>
  %33 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %30, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %34 = ashr <4 x i32> %33, <i32 12, i32 12, i32 12, i32 12>
  %35 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %32, <4 x i32> %34) #8
  %36 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %37 = bitcast <2 x i64>* %36 to <8 x i16>*
  store <8 x i16> %35, <8 x i16>* %37, align 16
  %38 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %39 = bitcast <2 x i64>* %38 to <8 x i16>*
  %40 = load <8 x i16>, <8 x i16>* %39, align 16
  %41 = shufflevector <8 x i16> %40, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %42 = shufflevector <8 x i16> %40, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %43 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %41, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %44 = ashr <4 x i32> %43, <i32 12, i32 12, i32 12, i32 12>
  %45 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %42, <8 x i16> <i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048, i16 5793, i16 2048>) #8
  %46 = ashr <4 x i32> %45, <i32 12, i32 12, i32 12, i32 12>
  %47 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %44, <4 x i32> %46) #8
  %48 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %49 = bitcast <2 x i64>* %48 to <8 x i16>*
  store <8 x i16> %47, <8 x i16>* %49, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @fadst8x16_new_sse2(<2 x i64>* nocapture readonly, <2 x i64>* nocapture, i8 signext) #0 {
  %4 = sext i8 %2 to i32
  %5 = add nsw i32 %4, -10
  %6 = sext i32 %5 to i64
  %7 = add nsw i32 %4, -1
  %8 = shl i32 1, %7
  %9 = insertelement <4 x i32> undef, i32 %8, i32 0
  %10 = shufflevector <4 x i32> %9, <4 x i32> undef, <4 x i32> zeroinitializer
  %11 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 32
  %12 = load i32, i32* %11, align 16
  %13 = and i32 %12, 65535
  %14 = shl i32 %12, 16
  %15 = or i32 %13, %14
  %16 = insertelement <4 x i32> undef, i32 %15, i32 0
  %17 = shufflevector <4 x i32> %16, <4 x i32> undef, <4 x i32> zeroinitializer
  %18 = sub i32 0, %14
  %19 = or i32 %13, %18
  %20 = insertelement <4 x i32> undef, i32 %19, i32 0
  %21 = shufflevector <4 x i32> %20, <4 x i32> undef, <4 x i32> zeroinitializer
  %22 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 16
  %23 = load i32, i32* %22, align 16
  %24 = and i32 %23, 65535
  %25 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 48
  %26 = load i32, i32* %25, align 16
  %27 = shl i32 %26, 16
  %28 = or i32 %27, %24
  %29 = insertelement <4 x i32> undef, i32 %28, i32 0
  %30 = shufflevector <4 x i32> %29, <4 x i32> undef, <4 x i32> zeroinitializer
  %31 = and i32 %26, 65535
  %32 = shl i32 %23, 16
  %33 = sub i32 0, %32
  %34 = or i32 %31, %33
  %35 = insertelement <4 x i32> undef, i32 %34, i32 0
  %36 = shufflevector <4 x i32> %35, <4 x i32> undef, <4 x i32> zeroinitializer
  %37 = sub i32 0, %26
  %38 = and i32 %37, 65535
  %39 = or i32 %38, %32
  %40 = insertelement <4 x i32> undef, i32 %39, i32 0
  %41 = shufflevector <4 x i32> %40, <4 x i32> undef, <4 x i32> zeroinitializer
  %42 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 8
  %43 = load i32, i32* %42, align 16
  %44 = and i32 %43, 65535
  %45 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 56
  %46 = load i32, i32* %45, align 16
  %47 = shl i32 %46, 16
  %48 = or i32 %47, %44
  %49 = insertelement <4 x i32> undef, i32 %48, i32 0
  %50 = shufflevector <4 x i32> %49, <4 x i32> undef, <4 x i32> zeroinitializer
  %51 = and i32 %46, 65535
  %52 = shl i32 %43, 16
  %53 = sub i32 0, %52
  %54 = or i32 %51, %53
  %55 = insertelement <4 x i32> undef, i32 %54, i32 0
  %56 = shufflevector <4 x i32> %55, <4 x i32> undef, <4 x i32> zeroinitializer
  %57 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 40
  %58 = load i32, i32* %57, align 16
  %59 = and i32 %58, 65535
  %60 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 24
  %61 = load i32, i32* %60, align 16
  %62 = shl i32 %61, 16
  %63 = or i32 %62, %59
  %64 = insertelement <4 x i32> undef, i32 %63, i32 0
  %65 = shufflevector <4 x i32> %64, <4 x i32> undef, <4 x i32> zeroinitializer
  %66 = and i32 %61, 65535
  %67 = shl i32 %58, 16
  %68 = sub i32 0, %67
  %69 = or i32 %66, %68
  %70 = insertelement <4 x i32> undef, i32 %69, i32 0
  %71 = shufflevector <4 x i32> %70, <4 x i32> undef, <4 x i32> zeroinitializer
  %72 = sub i32 0, %46
  %73 = and i32 %72, 65535
  %74 = or i32 %73, %52
  %75 = insertelement <4 x i32> undef, i32 %74, i32 0
  %76 = shufflevector <4 x i32> %75, <4 x i32> undef, <4 x i32> zeroinitializer
  %77 = sub i32 0, %61
  %78 = and i32 %77, 65535
  %79 = or i32 %78, %67
  %80 = insertelement <4 x i32> undef, i32 %79, i32 0
  %81 = shufflevector <4 x i32> %80, <4 x i32> undef, <4 x i32> zeroinitializer
  %82 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 2
  %83 = load i32, i32* %82, align 8
  %84 = and i32 %83, 65535
  %85 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 62
  %86 = load i32, i32* %85, align 8
  %87 = shl i32 %86, 16
  %88 = or i32 %87, %84
  %89 = insertelement <4 x i32> undef, i32 %88, i32 0
  %90 = shufflevector <4 x i32> %89, <4 x i32> undef, <4 x i32> zeroinitializer
  %91 = and i32 %86, 65535
  %92 = shl i32 %83, 16
  %93 = sub i32 0, %92
  %94 = or i32 %91, %93
  %95 = insertelement <4 x i32> undef, i32 %94, i32 0
  %96 = shufflevector <4 x i32> %95, <4 x i32> undef, <4 x i32> zeroinitializer
  %97 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 10
  %98 = load i32, i32* %97, align 8
  %99 = and i32 %98, 65535
  %100 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 54
  %101 = load i32, i32* %100, align 8
  %102 = shl i32 %101, 16
  %103 = or i32 %102, %99
  %104 = insertelement <4 x i32> undef, i32 %103, i32 0
  %105 = shufflevector <4 x i32> %104, <4 x i32> undef, <4 x i32> zeroinitializer
  %106 = and i32 %101, 65535
  %107 = shl i32 %98, 16
  %108 = sub i32 0, %107
  %109 = or i32 %106, %108
  %110 = insertelement <4 x i32> undef, i32 %109, i32 0
  %111 = shufflevector <4 x i32> %110, <4 x i32> undef, <4 x i32> zeroinitializer
  %112 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 18
  %113 = load i32, i32* %112, align 8
  %114 = and i32 %113, 65535
  %115 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 46
  %116 = load i32, i32* %115, align 8
  %117 = shl i32 %116, 16
  %118 = or i32 %117, %114
  %119 = insertelement <4 x i32> undef, i32 %118, i32 0
  %120 = shufflevector <4 x i32> %119, <4 x i32> undef, <4 x i32> zeroinitializer
  %121 = and i32 %116, 65535
  %122 = shl i32 %113, 16
  %123 = sub i32 0, %122
  %124 = or i32 %121, %123
  %125 = insertelement <4 x i32> undef, i32 %124, i32 0
  %126 = shufflevector <4 x i32> %125, <4 x i32> undef, <4 x i32> zeroinitializer
  %127 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 26
  %128 = load i32, i32* %127, align 8
  %129 = and i32 %128, 65535
  %130 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 38
  %131 = load i32, i32* %130, align 8
  %132 = shl i32 %131, 16
  %133 = or i32 %132, %129
  %134 = insertelement <4 x i32> undef, i32 %133, i32 0
  %135 = shufflevector <4 x i32> %134, <4 x i32> undef, <4 x i32> zeroinitializer
  %136 = and i32 %131, 65535
  %137 = shl i32 %128, 16
  %138 = sub i32 0, %137
  %139 = or i32 %136, %138
  %140 = insertelement <4 x i32> undef, i32 %139, i32 0
  %141 = shufflevector <4 x i32> %140, <4 x i32> undef, <4 x i32> zeroinitializer
  %142 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 34
  %143 = load i32, i32* %142, align 8
  %144 = and i32 %143, 65535
  %145 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 30
  %146 = load i32, i32* %145, align 8
  %147 = shl i32 %146, 16
  %148 = or i32 %147, %144
  %149 = insertelement <4 x i32> undef, i32 %148, i32 0
  %150 = shufflevector <4 x i32> %149, <4 x i32> undef, <4 x i32> zeroinitializer
  %151 = and i32 %146, 65535
  %152 = shl i32 %143, 16
  %153 = sub i32 0, %152
  %154 = or i32 %151, %153
  %155 = insertelement <4 x i32> undef, i32 %154, i32 0
  %156 = shufflevector <4 x i32> %155, <4 x i32> undef, <4 x i32> zeroinitializer
  %157 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 42
  %158 = load i32, i32* %157, align 8
  %159 = and i32 %158, 65535
  %160 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 22
  %161 = load i32, i32* %160, align 8
  %162 = shl i32 %161, 16
  %163 = or i32 %162, %159
  %164 = insertelement <4 x i32> undef, i32 %163, i32 0
  %165 = shufflevector <4 x i32> %164, <4 x i32> undef, <4 x i32> zeroinitializer
  %166 = and i32 %161, 65535
  %167 = shl i32 %158, 16
  %168 = sub i32 0, %167
  %169 = or i32 %166, %168
  %170 = insertelement <4 x i32> undef, i32 %169, i32 0
  %171 = shufflevector <4 x i32> %170, <4 x i32> undef, <4 x i32> zeroinitializer
  %172 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 50
  %173 = load i32, i32* %172, align 8
  %174 = and i32 %173, 65535
  %175 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 14
  %176 = load i32, i32* %175, align 8
  %177 = shl i32 %176, 16
  %178 = or i32 %177, %174
  %179 = insertelement <4 x i32> undef, i32 %178, i32 0
  %180 = shufflevector <4 x i32> %179, <4 x i32> undef, <4 x i32> zeroinitializer
  %181 = and i32 %176, 65535
  %182 = shl i32 %173, 16
  %183 = sub i32 0, %182
  %184 = or i32 %181, %183
  %185 = insertelement <4 x i32> undef, i32 %184, i32 0
  %186 = shufflevector <4 x i32> %185, <4 x i32> undef, <4 x i32> zeroinitializer
  %187 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 58
  %188 = load i32, i32* %187, align 8
  %189 = and i32 %188, 65535
  %190 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 6
  %191 = load i32, i32* %190, align 8
  %192 = shl i32 %191, 16
  %193 = or i32 %192, %189
  %194 = insertelement <4 x i32> undef, i32 %193, i32 0
  %195 = shufflevector <4 x i32> %194, <4 x i32> undef, <4 x i32> zeroinitializer
  %196 = and i32 %191, 65535
  %197 = shl i32 %188, 16
  %198 = sub i32 0, %197
  %199 = or i32 %196, %198
  %200 = insertelement <4 x i32> undef, i32 %199, i32 0
  %201 = shufflevector <4 x i32> %200, <4 x i32> undef, <4 x i32> zeroinitializer
  %202 = bitcast <2 x i64>* %0 to <8 x i16>*
  %203 = load <8 x i16>, <8 x i16>* %202, align 16
  %204 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 15
  %205 = bitcast <2 x i64>* %204 to <8 x i16>*
  %206 = load <8 x i16>, <8 x i16>* %205, align 16
  %207 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> zeroinitializer, <8 x i16> %206) #8
  %208 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %209 = bitcast <2 x i64>* %208 to <8 x i16>*
  %210 = load <8 x i16>, <8 x i16>* %209, align 16
  %211 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> zeroinitializer, <8 x i16> %210) #8
  %212 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 8
  %213 = bitcast <2 x i64>* %212 to <8 x i16>*
  %214 = load <8 x i16>, <8 x i16>* %213, align 16
  %215 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %216 = bitcast <2 x i64>* %215 to <8 x i16>*
  %217 = load <8 x i16>, <8 x i16>* %216, align 16
  %218 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> zeroinitializer, <8 x i16> %217) #8
  %219 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 12
  %220 = bitcast <2 x i64>* %219 to <8 x i16>*
  %221 = load <8 x i16>, <8 x i16>* %220, align 16
  %222 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %223 = bitcast <2 x i64>* %222 to <8 x i16>*
  %224 = load <8 x i16>, <8 x i16>* %223, align 16
  %225 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 11
  %226 = bitcast <2 x i64>* %225 to <8 x i16>*
  %227 = load <8 x i16>, <8 x i16>* %226, align 16
  %228 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> zeroinitializer, <8 x i16> %227) #8
  %229 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %230 = bitcast <2 x i64>* %229 to <8 x i16>*
  %231 = load <8 x i16>, <8 x i16>* %230, align 16
  %232 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> zeroinitializer, <8 x i16> %231) #8
  %233 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 14
  %234 = bitcast <2 x i64>* %233 to <8 x i16>*
  %235 = load <8 x i16>, <8 x i16>* %234, align 16
  %236 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %237 = bitcast <2 x i64>* %236 to <8 x i16>*
  %238 = load <8 x i16>, <8 x i16>* %237, align 16
  %239 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 9
  %240 = bitcast <2 x i64>* %239 to <8 x i16>*
  %241 = load <8 x i16>, <8 x i16>* %240, align 16
  %242 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> zeroinitializer, <8 x i16> %241) #8
  %243 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %244 = bitcast <2 x i64>* %243 to <8 x i16>*
  %245 = load <8 x i16>, <8 x i16>* %244, align 16
  %246 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 13
  %247 = bitcast <2 x i64>* %246 to <8 x i16>*
  %248 = load <8 x i16>, <8 x i16>* %247, align 16
  %249 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> zeroinitializer, <8 x i16> %248) #8
  %250 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %251 = bitcast <2 x i64>* %250 to <8 x i16>*
  %252 = load <8 x i16>, <8 x i16>* %251, align 16
  %253 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> zeroinitializer, <8 x i16> %252) #8
  %254 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 10
  %255 = bitcast <2 x i64>* %254 to <8 x i16>*
  %256 = load <8 x i16>, <8 x i16>* %255, align 16
  %257 = shufflevector <8 x i16> %211, <8 x i16> %214, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %258 = shufflevector <8 x i16> %211, <8 x i16> %214, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %259 = bitcast <4 x i32> %17 to <8 x i16>
  %260 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %257, <8 x i16> %259) #8
  %261 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %258, <8 x i16> %259) #8
  %262 = bitcast <4 x i32> %21 to <8 x i16>
  %263 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %257, <8 x i16> %262) #8
  %264 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %258, <8 x i16> %262) #8
  %265 = add <4 x i32> %260, %10
  %266 = add <4 x i32> %261, %10
  %267 = add <4 x i32> %263, %10
  %268 = add <4 x i32> %264, %10
  %269 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %265, i32 %4) #8
  %270 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %266, i32 %4) #8
  %271 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %267, i32 %4) #8
  %272 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %268, i32 %4) #8
  %273 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %269, <4 x i32> %270) #8
  %274 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %271, <4 x i32> %272) #8
  %275 = shufflevector <8 x i16> %224, <8 x i16> %228, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %276 = shufflevector <8 x i16> %224, <8 x i16> %228, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %277 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %275, <8 x i16> %259) #8
  %278 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %276, <8 x i16> %259) #8
  %279 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %275, <8 x i16> %262) #8
  %280 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %276, <8 x i16> %262) #8
  %281 = add <4 x i32> %277, %10
  %282 = add <4 x i32> %278, %10
  %283 = add <4 x i32> %279, %10
  %284 = add <4 x i32> %280, %10
  %285 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %281, i32 %4) #8
  %286 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %282, i32 %4) #8
  %287 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %283, i32 %4) #8
  %288 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %284, i32 %4) #8
  %289 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %285, <4 x i32> %286) #8
  %290 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %287, <4 x i32> %288) #8
  %291 = shufflevector <8 x i16> %238, <8 x i16> %242, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %292 = shufflevector <8 x i16> %238, <8 x i16> %242, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %293 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %291, <8 x i16> %259) #8
  %294 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %292, <8 x i16> %259) #8
  %295 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %291, <8 x i16> %262) #8
  %296 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %292, <8 x i16> %262) #8
  %297 = add <4 x i32> %293, %10
  %298 = add <4 x i32> %294, %10
  %299 = add <4 x i32> %295, %10
  %300 = add <4 x i32> %296, %10
  %301 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %297, i32 %4) #8
  %302 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %298, i32 %4) #8
  %303 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %299, i32 %4) #8
  %304 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %300, i32 %4) #8
  %305 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %301, <4 x i32> %302) #8
  %306 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %303, <4 x i32> %304) #8
  %307 = shufflevector <8 x i16> %253, <8 x i16> %256, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %308 = shufflevector <8 x i16> %253, <8 x i16> %256, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %309 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %307, <8 x i16> %259) #8
  %310 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %308, <8 x i16> %259) #8
  %311 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %307, <8 x i16> %262) #8
  %312 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %308, <8 x i16> %262) #8
  %313 = add <4 x i32> %309, %10
  %314 = add <4 x i32> %310, %10
  %315 = add <4 x i32> %311, %10
  %316 = add <4 x i32> %312, %10
  %317 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %313, i32 %4) #8
  %318 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %314, i32 %4) #8
  %319 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %315, i32 %4) #8
  %320 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %316, i32 %4) #8
  %321 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %317, <4 x i32> %318) #8
  %322 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %319, <4 x i32> %320) #8
  %323 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %203, <8 x i16> %273) #8
  %324 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %203, <8 x i16> %273) #8
  %325 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %207, <8 x i16> %274) #8
  %326 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %207, <8 x i16> %274) #8
  %327 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %218, <8 x i16> %289) #8
  %328 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %218, <8 x i16> %289) #8
  %329 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %221, <8 x i16> %290) #8
  %330 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %221, <8 x i16> %290) #8
  %331 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %232, <8 x i16> %305) #8
  %332 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %232, <8 x i16> %305) #8
  %333 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %235, <8 x i16> %306) #8
  %334 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %235, <8 x i16> %306) #8
  %335 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %245, <8 x i16> %321) #8
  %336 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %245, <8 x i16> %321) #8
  %337 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %249, <8 x i16> %322) #8
  %338 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %249, <8 x i16> %322) #8
  %339 = shufflevector <8 x i16> %327, <8 x i16> %329, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %340 = shufflevector <8 x i16> %327, <8 x i16> %329, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %341 = bitcast <4 x i32> %30 to <8 x i16>
  %342 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %339, <8 x i16> %341) #8
  %343 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %340, <8 x i16> %341) #8
  %344 = bitcast <4 x i32> %36 to <8 x i16>
  %345 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %339, <8 x i16> %344) #8
  %346 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %340, <8 x i16> %344) #8
  %347 = add <4 x i32> %342, %10
  %348 = add <4 x i32> %343, %10
  %349 = add <4 x i32> %345, %10
  %350 = add <4 x i32> %346, %10
  %351 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %347, i32 %4) #8
  %352 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %348, i32 %4) #8
  %353 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %349, i32 %4) #8
  %354 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %350, i32 %4) #8
  %355 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %351, <4 x i32> %352) #8
  %356 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %353, <4 x i32> %354) #8
  %357 = shufflevector <8 x i16> %328, <8 x i16> %330, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %358 = shufflevector <8 x i16> %328, <8 x i16> %330, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %359 = bitcast <4 x i32> %41 to <8 x i16>
  %360 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %357, <8 x i16> %359) #8
  %361 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %358, <8 x i16> %359) #8
  %362 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %357, <8 x i16> %341) #8
  %363 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %358, <8 x i16> %341) #8
  %364 = add <4 x i32> %360, %10
  %365 = add <4 x i32> %361, %10
  %366 = add <4 x i32> %362, %10
  %367 = add <4 x i32> %363, %10
  %368 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %364, i32 %4) #8
  %369 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %365, i32 %4) #8
  %370 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %366, i32 %4) #8
  %371 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %367, i32 %4) #8
  %372 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %368, <4 x i32> %369) #8
  %373 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %370, <4 x i32> %371) #8
  %374 = shufflevector <8 x i16> %335, <8 x i16> %337, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %375 = shufflevector <8 x i16> %335, <8 x i16> %337, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %376 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %374, <8 x i16> %341) #8
  %377 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %375, <8 x i16> %341) #8
  %378 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %374, <8 x i16> %344) #8
  %379 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %375, <8 x i16> %344) #8
  %380 = add <4 x i32> %376, %10
  %381 = add <4 x i32> %377, %10
  %382 = add <4 x i32> %378, %10
  %383 = add <4 x i32> %379, %10
  %384 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %380, i32 %4) #8
  %385 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %381, i32 %4) #8
  %386 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %382, i32 %4) #8
  %387 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %383, i32 %4) #8
  %388 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %384, <4 x i32> %385) #8
  %389 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %386, <4 x i32> %387) #8
  %390 = shufflevector <8 x i16> %336, <8 x i16> %338, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %391 = shufflevector <8 x i16> %336, <8 x i16> %338, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %392 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %390, <8 x i16> %359) #8
  %393 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %391, <8 x i16> %359) #8
  %394 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %390, <8 x i16> %341) #8
  %395 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %391, <8 x i16> %341) #8
  %396 = add <4 x i32> %392, %10
  %397 = add <4 x i32> %393, %10
  %398 = add <4 x i32> %394, %10
  %399 = add <4 x i32> %395, %10
  %400 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %396, i32 %4) #8
  %401 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %397, i32 %4) #8
  %402 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %398, i32 %4) #8
  %403 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %399, i32 %4) #8
  %404 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %400, <4 x i32> %401) #8
  %405 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %402, <4 x i32> %403) #8
  %406 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %323, <8 x i16> %355) #8
  %407 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %323, <8 x i16> %355) #8
  %408 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %325, <8 x i16> %356) #8
  %409 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %325, <8 x i16> %356) #8
  %410 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %324, <8 x i16> %372) #8
  %411 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %324, <8 x i16> %372) #8
  %412 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %326, <8 x i16> %373) #8
  %413 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %326, <8 x i16> %373) #8
  %414 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %331, <8 x i16> %388) #8
  %415 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %331, <8 x i16> %388) #8
  %416 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %333, <8 x i16> %389) #8
  %417 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %333, <8 x i16> %389) #8
  %418 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %332, <8 x i16> %404) #8
  %419 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %332, <8 x i16> %404) #8
  %420 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %334, <8 x i16> %405) #8
  %421 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %334, <8 x i16> %405) #8
  %422 = shufflevector <8 x i16> %414, <8 x i16> %416, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %423 = shufflevector <8 x i16> %414, <8 x i16> %416, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %424 = bitcast <4 x i32> %50 to <8 x i16>
  %425 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %422, <8 x i16> %424) #8
  %426 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %423, <8 x i16> %424) #8
  %427 = bitcast <4 x i32> %56 to <8 x i16>
  %428 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %422, <8 x i16> %427) #8
  %429 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %423, <8 x i16> %427) #8
  %430 = add <4 x i32> %425, %10
  %431 = add <4 x i32> %426, %10
  %432 = add <4 x i32> %428, %10
  %433 = add <4 x i32> %429, %10
  %434 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %430, i32 %4) #8
  %435 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %431, i32 %4) #8
  %436 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %432, i32 %4) #8
  %437 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %433, i32 %4) #8
  %438 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %434, <4 x i32> %435) #8
  %439 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %436, <4 x i32> %437) #8
  %440 = shufflevector <8 x i16> %418, <8 x i16> %420, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %441 = shufflevector <8 x i16> %418, <8 x i16> %420, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %442 = bitcast <4 x i32> %65 to <8 x i16>
  %443 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %440, <8 x i16> %442) #8
  %444 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %441, <8 x i16> %442) #8
  %445 = bitcast <4 x i32> %71 to <8 x i16>
  %446 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %440, <8 x i16> %445) #8
  %447 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %441, <8 x i16> %445) #8
  %448 = add <4 x i32> %443, %10
  %449 = add <4 x i32> %444, %10
  %450 = add <4 x i32> %446, %10
  %451 = add <4 x i32> %447, %10
  %452 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %448, i32 %4) #8
  %453 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %449, i32 %4) #8
  %454 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %450, i32 %4) #8
  %455 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %451, i32 %4) #8
  %456 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %452, <4 x i32> %453) #8
  %457 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %454, <4 x i32> %455) #8
  %458 = shufflevector <8 x i16> %415, <8 x i16> %417, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %459 = shufflevector <8 x i16> %415, <8 x i16> %417, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %460 = bitcast <4 x i32> %76 to <8 x i16>
  %461 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %458, <8 x i16> %460) #8
  %462 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %459, <8 x i16> %460) #8
  %463 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %458, <8 x i16> %424) #8
  %464 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %459, <8 x i16> %424) #8
  %465 = add <4 x i32> %461, %10
  %466 = add <4 x i32> %462, %10
  %467 = add <4 x i32> %463, %10
  %468 = add <4 x i32> %464, %10
  %469 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %465, i32 %4) #8
  %470 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %466, i32 %4) #8
  %471 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %467, i32 %4) #8
  %472 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %468, i32 %4) #8
  %473 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %469, <4 x i32> %470) #8
  %474 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %471, <4 x i32> %472) #8
  %475 = shufflevector <8 x i16> %419, <8 x i16> %421, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %476 = shufflevector <8 x i16> %419, <8 x i16> %421, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %477 = bitcast <4 x i32> %81 to <8 x i16>
  %478 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %475, <8 x i16> %477) #8
  %479 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %476, <8 x i16> %477) #8
  %480 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %475, <8 x i16> %442) #8
  %481 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %476, <8 x i16> %442) #8
  %482 = add <4 x i32> %478, %10
  %483 = add <4 x i32> %479, %10
  %484 = add <4 x i32> %480, %10
  %485 = add <4 x i32> %481, %10
  %486 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %482, i32 %4) #8
  %487 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %483, i32 %4) #8
  %488 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %484, i32 %4) #8
  %489 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %485, i32 %4) #8
  %490 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %486, <4 x i32> %487) #8
  %491 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %488, <4 x i32> %489) #8
  %492 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %406, <8 x i16> %438) #8
  %493 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %406, <8 x i16> %438) #8
  %494 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %408, <8 x i16> %439) #8
  %495 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %408, <8 x i16> %439) #8
  %496 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %410, <8 x i16> %456) #8
  %497 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %410, <8 x i16> %456) #8
  %498 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %412, <8 x i16> %457) #8
  %499 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %412, <8 x i16> %457) #8
  %500 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %407, <8 x i16> %473) #8
  %501 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %407, <8 x i16> %473) #8
  %502 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %409, <8 x i16> %474) #8
  %503 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %409, <8 x i16> %474) #8
  %504 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %411, <8 x i16> %490) #8
  %505 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %411, <8 x i16> %490) #8
  %506 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %413, <8 x i16> %491) #8
  %507 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %413, <8 x i16> %491) #8
  %508 = shufflevector <8 x i16> %492, <8 x i16> %494, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %509 = shufflevector <8 x i16> %492, <8 x i16> %494, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %510 = bitcast <4 x i32> %90 to <8 x i16>
  %511 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %508, <8 x i16> %510) #8
  %512 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %509, <8 x i16> %510) #8
  %513 = bitcast <4 x i32> %96 to <8 x i16>
  %514 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %508, <8 x i16> %513) #8
  %515 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %509, <8 x i16> %513) #8
  %516 = add <4 x i32> %511, %10
  %517 = add <4 x i32> %512, %10
  %518 = add <4 x i32> %514, %10
  %519 = add <4 x i32> %515, %10
  %520 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %516, i32 %4) #8
  %521 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %517, i32 %4) #8
  %522 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %518, i32 %4) #8
  %523 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %519, i32 %4) #8
  %524 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %520, <4 x i32> %521) #8
  %525 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %522, <4 x i32> %523) #8
  %526 = shufflevector <8 x i16> %496, <8 x i16> %498, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %527 = shufflevector <8 x i16> %496, <8 x i16> %498, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %528 = bitcast <4 x i32> %105 to <8 x i16>
  %529 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %526, <8 x i16> %528) #8
  %530 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %527, <8 x i16> %528) #8
  %531 = bitcast <4 x i32> %111 to <8 x i16>
  %532 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %526, <8 x i16> %531) #8
  %533 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %527, <8 x i16> %531) #8
  %534 = add <4 x i32> %529, %10
  %535 = add <4 x i32> %530, %10
  %536 = add <4 x i32> %532, %10
  %537 = add <4 x i32> %533, %10
  %538 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %534, i32 %4) #8
  %539 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %535, i32 %4) #8
  %540 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %536, i32 %4) #8
  %541 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %537, i32 %4) #8
  %542 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %538, <4 x i32> %539) #8
  %543 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %540, <4 x i32> %541) #8
  %544 = shufflevector <8 x i16> %500, <8 x i16> %502, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %545 = shufflevector <8 x i16> %500, <8 x i16> %502, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %546 = bitcast <4 x i32> %120 to <8 x i16>
  %547 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %544, <8 x i16> %546) #8
  %548 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %545, <8 x i16> %546) #8
  %549 = bitcast <4 x i32> %126 to <8 x i16>
  %550 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %544, <8 x i16> %549) #8
  %551 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %545, <8 x i16> %549) #8
  %552 = add <4 x i32> %547, %10
  %553 = add <4 x i32> %548, %10
  %554 = add <4 x i32> %550, %10
  %555 = add <4 x i32> %551, %10
  %556 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %552, i32 %4) #8
  %557 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %553, i32 %4) #8
  %558 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %554, i32 %4) #8
  %559 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %555, i32 %4) #8
  %560 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %556, <4 x i32> %557) #8
  %561 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %558, <4 x i32> %559) #8
  %562 = shufflevector <8 x i16> %504, <8 x i16> %506, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %563 = shufflevector <8 x i16> %504, <8 x i16> %506, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %564 = bitcast <4 x i32> %135 to <8 x i16>
  %565 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %562, <8 x i16> %564) #8
  %566 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %563, <8 x i16> %564) #8
  %567 = bitcast <4 x i32> %141 to <8 x i16>
  %568 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %562, <8 x i16> %567) #8
  %569 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %563, <8 x i16> %567) #8
  %570 = add <4 x i32> %565, %10
  %571 = add <4 x i32> %566, %10
  %572 = add <4 x i32> %568, %10
  %573 = add <4 x i32> %569, %10
  %574 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %570, i32 %4) #8
  %575 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %571, i32 %4) #8
  %576 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %572, i32 %4) #8
  %577 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %573, i32 %4) #8
  %578 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %574, <4 x i32> %575) #8
  %579 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %576, <4 x i32> %577) #8
  %580 = shufflevector <8 x i16> %493, <8 x i16> %495, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %581 = shufflevector <8 x i16> %493, <8 x i16> %495, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %582 = bitcast <4 x i32> %150 to <8 x i16>
  %583 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %580, <8 x i16> %582) #8
  %584 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %581, <8 x i16> %582) #8
  %585 = bitcast <4 x i32> %156 to <8 x i16>
  %586 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %580, <8 x i16> %585) #8
  %587 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %581, <8 x i16> %585) #8
  %588 = add <4 x i32> %583, %10
  %589 = add <4 x i32> %584, %10
  %590 = add <4 x i32> %586, %10
  %591 = add <4 x i32> %587, %10
  %592 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %588, i32 %4) #8
  %593 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %589, i32 %4) #8
  %594 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %590, i32 %4) #8
  %595 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %591, i32 %4) #8
  %596 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %592, <4 x i32> %593) #8
  %597 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %594, <4 x i32> %595) #8
  %598 = shufflevector <8 x i16> %497, <8 x i16> %499, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %599 = shufflevector <8 x i16> %497, <8 x i16> %499, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %600 = bitcast <4 x i32> %165 to <8 x i16>
  %601 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %598, <8 x i16> %600) #8
  %602 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %599, <8 x i16> %600) #8
  %603 = bitcast <4 x i32> %171 to <8 x i16>
  %604 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %598, <8 x i16> %603) #8
  %605 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %599, <8 x i16> %603) #8
  %606 = add <4 x i32> %601, %10
  %607 = add <4 x i32> %602, %10
  %608 = add <4 x i32> %604, %10
  %609 = add <4 x i32> %605, %10
  %610 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %606, i32 %4) #8
  %611 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %607, i32 %4) #8
  %612 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %608, i32 %4) #8
  %613 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %609, i32 %4) #8
  %614 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %610, <4 x i32> %611) #8
  %615 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %612, <4 x i32> %613) #8
  %616 = shufflevector <8 x i16> %501, <8 x i16> %503, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %617 = shufflevector <8 x i16> %501, <8 x i16> %503, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %618 = bitcast <4 x i32> %180 to <8 x i16>
  %619 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %616, <8 x i16> %618) #8
  %620 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %617, <8 x i16> %618) #8
  %621 = bitcast <4 x i32> %186 to <8 x i16>
  %622 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %616, <8 x i16> %621) #8
  %623 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %617, <8 x i16> %621) #8
  %624 = add <4 x i32> %619, %10
  %625 = add <4 x i32> %620, %10
  %626 = add <4 x i32> %622, %10
  %627 = add <4 x i32> %623, %10
  %628 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %624, i32 %4) #8
  %629 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %625, i32 %4) #8
  %630 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %626, i32 %4) #8
  %631 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %627, i32 %4) #8
  %632 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %628, <4 x i32> %629) #8
  %633 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %630, <4 x i32> %631) #8
  %634 = shufflevector <8 x i16> %505, <8 x i16> %507, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %635 = shufflevector <8 x i16> %505, <8 x i16> %507, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %636 = bitcast <4 x i32> %195 to <8 x i16>
  %637 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %634, <8 x i16> %636) #8
  %638 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %635, <8 x i16> %636) #8
  %639 = bitcast <4 x i32> %201 to <8 x i16>
  %640 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %634, <8 x i16> %639) #8
  %641 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %635, <8 x i16> %639) #8
  %642 = add <4 x i32> %637, %10
  %643 = add <4 x i32> %638, %10
  %644 = add <4 x i32> %640, %10
  %645 = add <4 x i32> %641, %10
  %646 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %642, i32 %4) #8
  %647 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %643, i32 %4) #8
  %648 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %644, i32 %4) #8
  %649 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %645, i32 %4) #8
  %650 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %646, <4 x i32> %647) #8
  %651 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %648, <4 x i32> %649) #8
  %652 = bitcast <2 x i64>* %1 to <8 x i16>*
  store <8 x i16> %525, <8 x i16>* %652, align 16
  %653 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %654 = bitcast <2 x i64>* %653 to <8 x i16>*
  store <8 x i16> %650, <8 x i16>* %654, align 16
  %655 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %656 = bitcast <2 x i64>* %655 to <8 x i16>*
  store <8 x i16> %543, <8 x i16>* %656, align 16
  %657 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %658 = bitcast <2 x i64>* %657 to <8 x i16>*
  store <8 x i16> %632, <8 x i16>* %658, align 16
  %659 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %660 = bitcast <2 x i64>* %659 to <8 x i16>*
  store <8 x i16> %561, <8 x i16>* %660, align 16
  %661 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %662 = bitcast <2 x i64>* %661 to <8 x i16>*
  store <8 x i16> %614, <8 x i16>* %662, align 16
  %663 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %664 = bitcast <2 x i64>* %663 to <8 x i16>*
  store <8 x i16> %579, <8 x i16>* %664, align 16
  %665 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %666 = bitcast <2 x i64>* %665 to <8 x i16>*
  store <8 x i16> %596, <8 x i16>* %666, align 16
  %667 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 8
  %668 = bitcast <2 x i64>* %667 to <8 x i16>*
  store <8 x i16> %597, <8 x i16>* %668, align 16
  %669 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 9
  %670 = bitcast <2 x i64>* %669 to <8 x i16>*
  store <8 x i16> %578, <8 x i16>* %670, align 16
  %671 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 10
  %672 = bitcast <2 x i64>* %671 to <8 x i16>*
  store <8 x i16> %615, <8 x i16>* %672, align 16
  %673 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 11
  %674 = bitcast <2 x i64>* %673 to <8 x i16>*
  store <8 x i16> %560, <8 x i16>* %674, align 16
  %675 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 12
  %676 = bitcast <2 x i64>* %675 to <8 x i16>*
  store <8 x i16> %633, <8 x i16>* %676, align 16
  %677 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 13
  %678 = bitcast <2 x i64>* %677 to <8 x i16>*
  store <8 x i16> %542, <8 x i16>* %678, align 16
  %679 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 14
  %680 = bitcast <2 x i64>* %679 to <8 x i16>*
  store <8 x i16> %651, <8 x i16>* %680, align 16
  %681 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 15
  %682 = bitcast <2 x i64>* %681 to <8 x i16>*
  store <8 x i16> %524, <8 x i16>* %682, align 16
  ret void
}

; Function Attrs: inlinehint nofree nounwind ssp uwtable
define internal void @fidentity8x16_new_sse2(<2 x i64>* nocapture readonly, <2 x i64>* nocapture, i8 signext) #7 {
  br label %5

4:                                                ; preds = %5
  ret void

5:                                                ; preds = %5, %3
  %6 = phi i64 [ 0, %3 ], [ %32, %5 ]
  %7 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 %6
  %8 = bitcast <2 x i64>* %7 to <8 x i16>*
  %9 = load <8 x i16>, <8 x i16>* %8, align 16
  %10 = shufflevector <8 x i16> %9, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %11 = shufflevector <8 x i16> %9, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %12 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %10, <8 x i16> <i16 11586, i16 2048, i16 11586, i16 2048, i16 11586, i16 2048, i16 11586, i16 2048>) #8
  %13 = ashr <4 x i32> %12, <i32 12, i32 12, i32 12, i32 12>
  %14 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %11, <8 x i16> <i16 11586, i16 2048, i16 11586, i16 2048, i16 11586, i16 2048, i16 11586, i16 2048>) #8
  %15 = ashr <4 x i32> %14, <i32 12, i32 12, i32 12, i32 12>
  %16 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %13, <4 x i32> %15) #8
  %17 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %6
  %18 = bitcast <2 x i64>* %17 to <8 x i16>*
  store <8 x i16> %16, <8 x i16>* %18, align 16
  %19 = or i64 %6, 1
  %20 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 %19
  %21 = bitcast <2 x i64>* %20 to <8 x i16>*
  %22 = load <8 x i16>, <8 x i16>* %21, align 16
  %23 = shufflevector <8 x i16> %22, <8 x i16> <i16 1, i16 1, i16 1, i16 1, i16 undef, i16 undef, i16 undef, i16 undef>, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %24 = shufflevector <8 x i16> %22, <8 x i16> <i16 undef, i16 undef, i16 undef, i16 undef, i16 1, i16 1, i16 1, i16 1>, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %25 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %23, <8 x i16> <i16 11586, i16 2048, i16 11586, i16 2048, i16 11586, i16 2048, i16 11586, i16 2048>) #8
  %26 = ashr <4 x i32> %25, <i32 12, i32 12, i32 12, i32 12>
  %27 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %24, <8 x i16> <i16 11586, i16 2048, i16 11586, i16 2048, i16 11586, i16 2048, i16 11586, i16 2048>) #8
  %28 = ashr <4 x i32> %27, <i32 12, i32 12, i32 12, i32 12>
  %29 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %26, <4 x i32> %28) #8
  %30 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %19
  %31 = bitcast <2 x i64>* %30 to <8 x i16>*
  store <8 x i16> %29, <8 x i16>* %31, align 16
  %32 = add nuw nsw i64 %6, 2
  %33 = icmp eq i64 %32, 16
  br i1 %33, label %4, label %5
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @fdct8x8_new_sse2(<2 x i64>* nocapture readonly, <2 x i64>* nocapture, i8 signext) #0 {
  %4 = sext i8 %2 to i32
  %5 = add nsw i32 %4, -10
  %6 = sext i32 %5 to i64
  %7 = add nsw i32 %4, -1
  %8 = shl i32 1, %7
  %9 = insertelement <4 x i32> undef, i32 %8, i32 0
  %10 = shufflevector <4 x i32> %9, <4 x i32> undef, <4 x i32> zeroinitializer
  %11 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 32
  %12 = load i32, i32* %11, align 16
  %13 = sub i32 0, %12
  %14 = and i32 %13, 65535
  %15 = shl i32 %12, 16
  %16 = or i32 %14, %15
  %17 = insertelement <4 x i32> undef, i32 %16, i32 0
  %18 = shufflevector <4 x i32> %17, <4 x i32> undef, <4 x i32> zeroinitializer
  %19 = and i32 %12, 65535
  %20 = or i32 %19, %15
  %21 = insertelement <4 x i32> undef, i32 %20, i32 0
  %22 = shufflevector <4 x i32> %21, <4 x i32> undef, <4 x i32> zeroinitializer
  %23 = sub i32 0, %15
  %24 = or i32 %19, %23
  %25 = insertelement <4 x i32> undef, i32 %24, i32 0
  %26 = shufflevector <4 x i32> %25, <4 x i32> undef, <4 x i32> zeroinitializer
  %27 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 48
  %28 = load i32, i32* %27, align 16
  %29 = and i32 %28, 65535
  %30 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 16
  %31 = load i32, i32* %30, align 16
  %32 = shl i32 %31, 16
  %33 = or i32 %32, %29
  %34 = insertelement <4 x i32> undef, i32 %33, i32 0
  %35 = shufflevector <4 x i32> %34, <4 x i32> undef, <4 x i32> zeroinitializer
  %36 = sub i32 0, %31
  %37 = and i32 %36, 65535
  %38 = shl i32 %28, 16
  %39 = or i32 %37, %38
  %40 = insertelement <4 x i32> undef, i32 %39, i32 0
  %41 = shufflevector <4 x i32> %40, <4 x i32> undef, <4 x i32> zeroinitializer
  %42 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 56
  %43 = load i32, i32* %42, align 16
  %44 = and i32 %43, 65535
  %45 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 8
  %46 = load i32, i32* %45, align 16
  %47 = shl i32 %46, 16
  %48 = or i32 %47, %44
  %49 = insertelement <4 x i32> undef, i32 %48, i32 0
  %50 = shufflevector <4 x i32> %49, <4 x i32> undef, <4 x i32> zeroinitializer
  %51 = sub i32 0, %46
  %52 = and i32 %51, 65535
  %53 = shl i32 %43, 16
  %54 = or i32 %52, %53
  %55 = insertelement <4 x i32> undef, i32 %54, i32 0
  %56 = shufflevector <4 x i32> %55, <4 x i32> undef, <4 x i32> zeroinitializer
  %57 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 24
  %58 = load i32, i32* %57, align 16
  %59 = and i32 %58, 65535
  %60 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 40
  %61 = load i32, i32* %60, align 16
  %62 = shl i32 %61, 16
  %63 = or i32 %62, %59
  %64 = insertelement <4 x i32> undef, i32 %63, i32 0
  %65 = shufflevector <4 x i32> %64, <4 x i32> undef, <4 x i32> zeroinitializer
  %66 = sub i32 0, %61
  %67 = and i32 %66, 65535
  %68 = shl i32 %58, 16
  %69 = or i32 %67, %68
  %70 = insertelement <4 x i32> undef, i32 %69, i32 0
  %71 = shufflevector <4 x i32> %70, <4 x i32> undef, <4 x i32> zeroinitializer
  %72 = bitcast <2 x i64>* %0 to <8 x i16>*
  %73 = load <8 x i16>, <8 x i16>* %72, align 16
  %74 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %75 = bitcast <2 x i64>* %74 to <8 x i16>*
  %76 = load <8 x i16>, <8 x i16>* %75, align 16
  %77 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %73, <8 x i16> %76) #8
  %78 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %73, <8 x i16> %76) #8
  %79 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %80 = bitcast <2 x i64>* %79 to <8 x i16>*
  %81 = load <8 x i16>, <8 x i16>* %80, align 16
  %82 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %83 = bitcast <2 x i64>* %82 to <8 x i16>*
  %84 = load <8 x i16>, <8 x i16>* %83, align 16
  %85 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %81, <8 x i16> %84) #8
  %86 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %81, <8 x i16> %84) #8
  %87 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %88 = bitcast <2 x i64>* %87 to <8 x i16>*
  %89 = load <8 x i16>, <8 x i16>* %88, align 16
  %90 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %91 = bitcast <2 x i64>* %90 to <8 x i16>*
  %92 = load <8 x i16>, <8 x i16>* %91, align 16
  %93 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %89, <8 x i16> %92) #8
  %94 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %89, <8 x i16> %92) #8
  %95 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %96 = bitcast <2 x i64>* %95 to <8 x i16>*
  %97 = load <8 x i16>, <8 x i16>* %96, align 16
  %98 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %99 = bitcast <2 x i64>* %98 to <8 x i16>*
  %100 = load <8 x i16>, <8 x i16>* %99, align 16
  %101 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %97, <8 x i16> %100) #8
  %102 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %97, <8 x i16> %100) #8
  %103 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %77, <8 x i16> %101) #8
  %104 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %77, <8 x i16> %101) #8
  %105 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %85, <8 x i16> %93) #8
  %106 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %85, <8 x i16> %93) #8
  %107 = shufflevector <8 x i16> %94, <8 x i16> %86, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %108 = shufflevector <8 x i16> %94, <8 x i16> %86, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %109 = bitcast <4 x i32> %18 to <8 x i16>
  %110 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %107, <8 x i16> %109) #8
  %111 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %108, <8 x i16> %109) #8
  %112 = bitcast <4 x i32> %22 to <8 x i16>
  %113 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %107, <8 x i16> %112) #8
  %114 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %108, <8 x i16> %112) #8
  %115 = add <4 x i32> %110, %10
  %116 = add <4 x i32> %111, %10
  %117 = add <4 x i32> %113, %10
  %118 = add <4 x i32> %114, %10
  %119 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %115, i32 %4) #8
  %120 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %116, i32 %4) #8
  %121 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %117, i32 %4) #8
  %122 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %118, i32 %4) #8
  %123 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %119, <4 x i32> %120) #8
  %124 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %121, <4 x i32> %122) #8
  %125 = shufflevector <8 x i16> %103, <8 x i16> %105, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %126 = shufflevector <8 x i16> %103, <8 x i16> %105, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %127 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %125, <8 x i16> %112) #8
  %128 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %126, <8 x i16> %112) #8
  %129 = bitcast <4 x i32> %26 to <8 x i16>
  %130 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %125, <8 x i16> %129) #8
  %131 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %126, <8 x i16> %129) #8
  %132 = add <4 x i32> %127, %10
  %133 = add <4 x i32> %128, %10
  %134 = add <4 x i32> %130, %10
  %135 = add <4 x i32> %131, %10
  %136 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %132, i32 %4) #8
  %137 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %133, i32 %4) #8
  %138 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %134, i32 %4) #8
  %139 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %135, i32 %4) #8
  %140 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %136, <4 x i32> %137) #8
  %141 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %138, <4 x i32> %139) #8
  %142 = shufflevector <8 x i16> %106, <8 x i16> %104, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %143 = shufflevector <8 x i16> %106, <8 x i16> %104, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %144 = bitcast <4 x i32> %35 to <8 x i16>
  %145 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %142, <8 x i16> %144) #8
  %146 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %143, <8 x i16> %144) #8
  %147 = bitcast <4 x i32> %41 to <8 x i16>
  %148 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %142, <8 x i16> %147) #8
  %149 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %143, <8 x i16> %147) #8
  %150 = add <4 x i32> %145, %10
  %151 = add <4 x i32> %146, %10
  %152 = add <4 x i32> %148, %10
  %153 = add <4 x i32> %149, %10
  %154 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %150, i32 %4) #8
  %155 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %151, i32 %4) #8
  %156 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %152, i32 %4) #8
  %157 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %153, i32 %4) #8
  %158 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %154, <4 x i32> %155) #8
  %159 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %156, <4 x i32> %157) #8
  %160 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %102, <8 x i16> %123) #8
  %161 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %102, <8 x i16> %123) #8
  %162 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %78, <8 x i16> %124) #8
  %163 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %78, <8 x i16> %124) #8
  %164 = shufflevector <8 x i16> %160, <8 x i16> %163, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %165 = shufflevector <8 x i16> %160, <8 x i16> %163, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %166 = bitcast <4 x i32> %50 to <8 x i16>
  %167 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %164, <8 x i16> %166) #8
  %168 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %165, <8 x i16> %166) #8
  %169 = bitcast <4 x i32> %56 to <8 x i16>
  %170 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %164, <8 x i16> %169) #8
  %171 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %165, <8 x i16> %169) #8
  %172 = add <4 x i32> %167, %10
  %173 = add <4 x i32> %168, %10
  %174 = add <4 x i32> %170, %10
  %175 = add <4 x i32> %171, %10
  %176 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %172, i32 %4) #8
  %177 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %173, i32 %4) #8
  %178 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %174, i32 %4) #8
  %179 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %175, i32 %4) #8
  %180 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %176, <4 x i32> %177) #8
  %181 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %178, <4 x i32> %179) #8
  %182 = shufflevector <8 x i16> %161, <8 x i16> %162, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %183 = shufflevector <8 x i16> %161, <8 x i16> %162, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %184 = bitcast <4 x i32> %65 to <8 x i16>
  %185 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %182, <8 x i16> %184) #8
  %186 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %183, <8 x i16> %184) #8
  %187 = bitcast <4 x i32> %71 to <8 x i16>
  %188 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %182, <8 x i16> %187) #8
  %189 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %183, <8 x i16> %187) #8
  %190 = add <4 x i32> %185, %10
  %191 = add <4 x i32> %186, %10
  %192 = add <4 x i32> %188, %10
  %193 = add <4 x i32> %189, %10
  %194 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %190, i32 %4) #8
  %195 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %191, i32 %4) #8
  %196 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %192, i32 %4) #8
  %197 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %193, i32 %4) #8
  %198 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %194, <4 x i32> %195) #8
  %199 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %196, <4 x i32> %197) #8
  %200 = bitcast <2 x i64>* %1 to <8 x i16>*
  store <8 x i16> %140, <8 x i16>* %200, align 16
  %201 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %202 = bitcast <2 x i64>* %201 to <8 x i16>*
  store <8 x i16> %180, <8 x i16>* %202, align 16
  %203 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %204 = bitcast <2 x i64>* %203 to <8 x i16>*
  store <8 x i16> %158, <8 x i16>* %204, align 16
  %205 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %206 = bitcast <2 x i64>* %205 to <8 x i16>*
  store <8 x i16> %199, <8 x i16>* %206, align 16
  %207 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %208 = bitcast <2 x i64>* %207 to <8 x i16>*
  store <8 x i16> %141, <8 x i16>* %208, align 16
  %209 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %210 = bitcast <2 x i64>* %209 to <8 x i16>*
  store <8 x i16> %198, <8 x i16>* %210, align 16
  %211 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %212 = bitcast <2 x i64>* %211 to <8 x i16>*
  store <8 x i16> %159, <8 x i16>* %212, align 16
  %213 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %214 = bitcast <2 x i64>* %213 to <8 x i16>*
  store <8 x i16> %181, <8 x i16>* %214, align 16
  ret void
}

; Function Attrs: nofree nounwind ssp uwtable
define internal void @fadst8x8_new_sse2(<2 x i64>* nocapture readonly, <2 x i64>* nocapture, i8 signext) #0 {
  %4 = sext i8 %2 to i32
  %5 = add nsw i32 %4, -10
  %6 = sext i32 %5 to i64
  %7 = add nsw i32 %4, -1
  %8 = shl i32 1, %7
  %9 = insertelement <4 x i32> undef, i32 %8, i32 0
  %10 = shufflevector <4 x i32> %9, <4 x i32> undef, <4 x i32> zeroinitializer
  %11 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 32
  %12 = load i32, i32* %11, align 16
  %13 = and i32 %12, 65535
  %14 = shl i32 %12, 16
  %15 = or i32 %13, %14
  %16 = insertelement <4 x i32> undef, i32 %15, i32 0
  %17 = shufflevector <4 x i32> %16, <4 x i32> undef, <4 x i32> zeroinitializer
  %18 = sub i32 0, %14
  %19 = or i32 %13, %18
  %20 = insertelement <4 x i32> undef, i32 %19, i32 0
  %21 = shufflevector <4 x i32> %20, <4 x i32> undef, <4 x i32> zeroinitializer
  %22 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 16
  %23 = load i32, i32* %22, align 16
  %24 = and i32 %23, 65535
  %25 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 48
  %26 = load i32, i32* %25, align 16
  %27 = shl i32 %26, 16
  %28 = or i32 %27, %24
  %29 = insertelement <4 x i32> undef, i32 %28, i32 0
  %30 = shufflevector <4 x i32> %29, <4 x i32> undef, <4 x i32> zeroinitializer
  %31 = and i32 %26, 65535
  %32 = shl i32 %23, 16
  %33 = sub i32 0, %32
  %34 = or i32 %31, %33
  %35 = insertelement <4 x i32> undef, i32 %34, i32 0
  %36 = shufflevector <4 x i32> %35, <4 x i32> undef, <4 x i32> zeroinitializer
  %37 = sub i32 0, %26
  %38 = and i32 %37, 65535
  %39 = or i32 %38, %32
  %40 = insertelement <4 x i32> undef, i32 %39, i32 0
  %41 = shufflevector <4 x i32> %40, <4 x i32> undef, <4 x i32> zeroinitializer
  %42 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 4
  %43 = load i32, i32* %42, align 16
  %44 = and i32 %43, 65535
  %45 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 60
  %46 = load i32, i32* %45, align 16
  %47 = shl i32 %46, 16
  %48 = or i32 %47, %44
  %49 = insertelement <4 x i32> undef, i32 %48, i32 0
  %50 = shufflevector <4 x i32> %49, <4 x i32> undef, <4 x i32> zeroinitializer
  %51 = and i32 %46, 65535
  %52 = shl i32 %43, 16
  %53 = sub i32 0, %52
  %54 = or i32 %51, %53
  %55 = insertelement <4 x i32> undef, i32 %54, i32 0
  %56 = shufflevector <4 x i32> %55, <4 x i32> undef, <4 x i32> zeroinitializer
  %57 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 20
  %58 = load i32, i32* %57, align 16
  %59 = and i32 %58, 65535
  %60 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 44
  %61 = load i32, i32* %60, align 16
  %62 = shl i32 %61, 16
  %63 = or i32 %62, %59
  %64 = insertelement <4 x i32> undef, i32 %63, i32 0
  %65 = shufflevector <4 x i32> %64, <4 x i32> undef, <4 x i32> zeroinitializer
  %66 = and i32 %61, 65535
  %67 = shl i32 %58, 16
  %68 = sub i32 0, %67
  %69 = or i32 %66, %68
  %70 = insertelement <4 x i32> undef, i32 %69, i32 0
  %71 = shufflevector <4 x i32> %70, <4 x i32> undef, <4 x i32> zeroinitializer
  %72 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 36
  %73 = load i32, i32* %72, align 16
  %74 = and i32 %73, 65535
  %75 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 28
  %76 = load i32, i32* %75, align 16
  %77 = shl i32 %76, 16
  %78 = or i32 %77, %74
  %79 = insertelement <4 x i32> undef, i32 %78, i32 0
  %80 = shufflevector <4 x i32> %79, <4 x i32> undef, <4 x i32> zeroinitializer
  %81 = and i32 %76, 65535
  %82 = shl i32 %73, 16
  %83 = sub i32 0, %82
  %84 = or i32 %81, %83
  %85 = insertelement <4 x i32> undef, i32 %84, i32 0
  %86 = shufflevector <4 x i32> %85, <4 x i32> undef, <4 x i32> zeroinitializer
  %87 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 52
  %88 = load i32, i32* %87, align 16
  %89 = and i32 %88, 65535
  %90 = getelementptr inbounds [7 x [64 x i32]], [7 x [64 x i32]]* @av1_cospi_arr_data, i64 0, i64 %6, i64 12
  %91 = load i32, i32* %90, align 16
  %92 = shl i32 %91, 16
  %93 = or i32 %92, %89
  %94 = insertelement <4 x i32> undef, i32 %93, i32 0
  %95 = shufflevector <4 x i32> %94, <4 x i32> undef, <4 x i32> zeroinitializer
  %96 = and i32 %91, 65535
  %97 = shl i32 %88, 16
  %98 = sub i32 0, %97
  %99 = or i32 %96, %98
  %100 = insertelement <4 x i32> undef, i32 %99, i32 0
  %101 = shufflevector <4 x i32> %100, <4 x i32> undef, <4 x i32> zeroinitializer
  %102 = bitcast <2 x i64>* %0 to <8 x i16>*
  %103 = load <8 x i16>, <8 x i16>* %102, align 16
  %104 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %105 = bitcast <2 x i64>* %104 to <8 x i16>*
  %106 = load <8 x i16>, <8 x i16>* %105, align 16
  %107 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> zeroinitializer, <8 x i16> %106) #8
  %108 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %109 = bitcast <2 x i64>* %108 to <8 x i16>*
  %110 = load <8 x i16>, <8 x i16>* %109, align 16
  %111 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> zeroinitializer, <8 x i16> %110) #8
  %112 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %113 = bitcast <2 x i64>* %112 to <8 x i16>*
  %114 = load <8 x i16>, <8 x i16>* %113, align 16
  %115 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %116 = bitcast <2 x i64>* %115 to <8 x i16>*
  %117 = load <8 x i16>, <8 x i16>* %116, align 16
  %118 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> zeroinitializer, <8 x i16> %117) #8
  %119 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %120 = bitcast <2 x i64>* %119 to <8 x i16>*
  %121 = load <8 x i16>, <8 x i16>* %120, align 16
  %122 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %123 = bitcast <2 x i64>* %122 to <8 x i16>*
  %124 = load <8 x i16>, <8 x i16>* %123, align 16
  %125 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %126 = bitcast <2 x i64>* %125 to <8 x i16>*
  %127 = load <8 x i16>, <8 x i16>* %126, align 16
  %128 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> zeroinitializer, <8 x i16> %127) #8
  %129 = shufflevector <8 x i16> %111, <8 x i16> %114, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %130 = shufflevector <8 x i16> %111, <8 x i16> %114, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %131 = bitcast <4 x i32> %17 to <8 x i16>
  %132 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %129, <8 x i16> %131) #8
  %133 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %130, <8 x i16> %131) #8
  %134 = bitcast <4 x i32> %21 to <8 x i16>
  %135 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %129, <8 x i16> %134) #8
  %136 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %130, <8 x i16> %134) #8
  %137 = add <4 x i32> %132, %10
  %138 = add <4 x i32> %133, %10
  %139 = add <4 x i32> %135, %10
  %140 = add <4 x i32> %136, %10
  %141 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %137, i32 %4) #8
  %142 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %138, i32 %4) #8
  %143 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %139, i32 %4) #8
  %144 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %140, i32 %4) #8
  %145 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %141, <4 x i32> %142) #8
  %146 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %143, <4 x i32> %144) #8
  %147 = shufflevector <8 x i16> %124, <8 x i16> %128, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %148 = shufflevector <8 x i16> %124, <8 x i16> %128, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %149 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %147, <8 x i16> %131) #8
  %150 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %148, <8 x i16> %131) #8
  %151 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %147, <8 x i16> %134) #8
  %152 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %148, <8 x i16> %134) #8
  %153 = add <4 x i32> %149, %10
  %154 = add <4 x i32> %150, %10
  %155 = add <4 x i32> %151, %10
  %156 = add <4 x i32> %152, %10
  %157 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %153, i32 %4) #8
  %158 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %154, i32 %4) #8
  %159 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %155, i32 %4) #8
  %160 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %156, i32 %4) #8
  %161 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %157, <4 x i32> %158) #8
  %162 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %159, <4 x i32> %160) #8
  %163 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %103, <8 x i16> %145) #8
  %164 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %103, <8 x i16> %145) #8
  %165 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %107, <8 x i16> %146) #8
  %166 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %107, <8 x i16> %146) #8
  %167 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %118, <8 x i16> %161) #8
  %168 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %118, <8 x i16> %161) #8
  %169 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %121, <8 x i16> %162) #8
  %170 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %121, <8 x i16> %162) #8
  %171 = shufflevector <8 x i16> %167, <8 x i16> %169, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %172 = shufflevector <8 x i16> %167, <8 x i16> %169, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %173 = bitcast <4 x i32> %30 to <8 x i16>
  %174 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %171, <8 x i16> %173) #8
  %175 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %172, <8 x i16> %173) #8
  %176 = bitcast <4 x i32> %36 to <8 x i16>
  %177 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %171, <8 x i16> %176) #8
  %178 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %172, <8 x i16> %176) #8
  %179 = add <4 x i32> %174, %10
  %180 = add <4 x i32> %175, %10
  %181 = add <4 x i32> %177, %10
  %182 = add <4 x i32> %178, %10
  %183 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %179, i32 %4) #8
  %184 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %180, i32 %4) #8
  %185 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %181, i32 %4) #8
  %186 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %182, i32 %4) #8
  %187 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %183, <4 x i32> %184) #8
  %188 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %185, <4 x i32> %186) #8
  %189 = shufflevector <8 x i16> %168, <8 x i16> %170, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %190 = shufflevector <8 x i16> %168, <8 x i16> %170, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %191 = bitcast <4 x i32> %41 to <8 x i16>
  %192 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %189, <8 x i16> %191) #8
  %193 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %190, <8 x i16> %191) #8
  %194 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %189, <8 x i16> %173) #8
  %195 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %190, <8 x i16> %173) #8
  %196 = add <4 x i32> %192, %10
  %197 = add <4 x i32> %193, %10
  %198 = add <4 x i32> %194, %10
  %199 = add <4 x i32> %195, %10
  %200 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %196, i32 %4) #8
  %201 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %197, i32 %4) #8
  %202 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %198, i32 %4) #8
  %203 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %199, i32 %4) #8
  %204 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %200, <4 x i32> %201) #8
  %205 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %202, <4 x i32> %203) #8
  %206 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %163, <8 x i16> %187) #8
  %207 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %163, <8 x i16> %187) #8
  %208 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %165, <8 x i16> %188) #8
  %209 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %165, <8 x i16> %188) #8
  %210 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %164, <8 x i16> %204) #8
  %211 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %164, <8 x i16> %204) #8
  %212 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %166, <8 x i16> %205) #8
  %213 = tail call <8 x i16> @llvm.ssub.sat.v8i16(<8 x i16> %166, <8 x i16> %205) #8
  %214 = shufflevector <8 x i16> %206, <8 x i16> %208, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %215 = shufflevector <8 x i16> %206, <8 x i16> %208, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %216 = bitcast <4 x i32> %50 to <8 x i16>
  %217 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %214, <8 x i16> %216) #8
  %218 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %215, <8 x i16> %216) #8
  %219 = bitcast <4 x i32> %56 to <8 x i16>
  %220 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %214, <8 x i16> %219) #8
  %221 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %215, <8 x i16> %219) #8
  %222 = add <4 x i32> %217, %10
  %223 = add <4 x i32> %218, %10
  %224 = add <4 x i32> %220, %10
  %225 = add <4 x i32> %221, %10
  %226 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %222, i32 %4) #8
  %227 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %223, i32 %4) #8
  %228 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %224, i32 %4) #8
  %229 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %225, i32 %4) #8
  %230 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %226, <4 x i32> %227) #8
  %231 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %228, <4 x i32> %229) #8
  %232 = shufflevector <8 x i16> %210, <8 x i16> %212, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %233 = shufflevector <8 x i16> %210, <8 x i16> %212, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %234 = bitcast <4 x i32> %65 to <8 x i16>
  %235 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %232, <8 x i16> %234) #8
  %236 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %233, <8 x i16> %234) #8
  %237 = bitcast <4 x i32> %71 to <8 x i16>
  %238 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %232, <8 x i16> %237) #8
  %239 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %233, <8 x i16> %237) #8
  %240 = add <4 x i32> %235, %10
  %241 = add <4 x i32> %236, %10
  %242 = add <4 x i32> %238, %10
  %243 = add <4 x i32> %239, %10
  %244 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %240, i32 %4) #8
  %245 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %241, i32 %4) #8
  %246 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %242, i32 %4) #8
  %247 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %243, i32 %4) #8
  %248 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %244, <4 x i32> %245) #8
  %249 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %246, <4 x i32> %247) #8
  %250 = shufflevector <8 x i16> %207, <8 x i16> %209, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %251 = shufflevector <8 x i16> %207, <8 x i16> %209, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %252 = bitcast <4 x i32> %80 to <8 x i16>
  %253 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %250, <8 x i16> %252) #8
  %254 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %251, <8 x i16> %252) #8
  %255 = bitcast <4 x i32> %86 to <8 x i16>
  %256 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %250, <8 x i16> %255) #8
  %257 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %251, <8 x i16> %255) #8
  %258 = add <4 x i32> %253, %10
  %259 = add <4 x i32> %254, %10
  %260 = add <4 x i32> %256, %10
  %261 = add <4 x i32> %257, %10
  %262 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %258, i32 %4) #8
  %263 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %259, i32 %4) #8
  %264 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %260, i32 %4) #8
  %265 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %261, i32 %4) #8
  %266 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %262, <4 x i32> %263) #8
  %267 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %264, <4 x i32> %265) #8
  %268 = shufflevector <8 x i16> %211, <8 x i16> %213, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %269 = shufflevector <8 x i16> %211, <8 x i16> %213, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %270 = bitcast <4 x i32> %95 to <8 x i16>
  %271 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %268, <8 x i16> %270) #8
  %272 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %269, <8 x i16> %270) #8
  %273 = bitcast <4 x i32> %101 to <8 x i16>
  %274 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %268, <8 x i16> %273) #8
  %275 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %269, <8 x i16> %273) #8
  %276 = add <4 x i32> %271, %10
  %277 = add <4 x i32> %272, %10
  %278 = add <4 x i32> %274, %10
  %279 = add <4 x i32> %275, %10
  %280 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %276, i32 %4) #8
  %281 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %277, i32 %4) #8
  %282 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %278, i32 %4) #8
  %283 = tail call <4 x i32> @llvm.x86.sse2.psrai.d(<4 x i32> %279, i32 %4) #8
  %284 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %280, <4 x i32> %281) #8
  %285 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %282, <4 x i32> %283) #8
  %286 = bitcast <2 x i64>* %1 to <8 x i16>*
  store <8 x i16> %231, <8 x i16>* %286, align 16
  %287 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 1
  %288 = bitcast <2 x i64>* %287 to <8 x i16>*
  store <8 x i16> %284, <8 x i16>* %288, align 16
  %289 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 2
  %290 = bitcast <2 x i64>* %289 to <8 x i16>*
  store <8 x i16> %249, <8 x i16>* %290, align 16
  %291 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 3
  %292 = bitcast <2 x i64>* %291 to <8 x i16>*
  store <8 x i16> %266, <8 x i16>* %292, align 16
  %293 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 4
  %294 = bitcast <2 x i64>* %293 to <8 x i16>*
  store <8 x i16> %267, <8 x i16>* %294, align 16
  %295 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 5
  %296 = bitcast <2 x i64>* %295 to <8 x i16>*
  store <8 x i16> %248, <8 x i16>* %296, align 16
  %297 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 6
  %298 = bitcast <2 x i64>* %297 to <8 x i16>*
  store <8 x i16> %285, <8 x i16>* %298, align 16
  %299 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 7
  %300 = bitcast <2 x i64>* %299 to <8 x i16>*
  store <8 x i16> %230, <8 x i16>* %300, align 16
  ret void
}

; Function Attrs: inlinehint nofree nounwind ssp uwtable
define internal void @fidentity8x32_new_sse2(<2 x i64>* nocapture readonly, <2 x i64>* nocapture, i8 signext) #7 {
  br label %5

4:                                                ; preds = %5
  ret void

5:                                                ; preds = %5, %3
  %6 = phi i64 [ 0, %3 ], [ %34, %5 ]
  %7 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 %6
  %8 = bitcast <2 x i64>* %7 to <8 x i16>*
  %9 = load <8 x i16>, <8 x i16>* %8, align 16
  %10 = shl <8 x i16> %9, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %11 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %6
  %12 = bitcast <2 x i64>* %11 to <8 x i16>*
  store <8 x i16> %10, <8 x i16>* %12, align 16
  %13 = or i64 %6, 1
  %14 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 %13
  %15 = bitcast <2 x i64>* %14 to <8 x i16>*
  %16 = load <8 x i16>, <8 x i16>* %15, align 16
  %17 = shl <8 x i16> %16, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %18 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %13
  %19 = bitcast <2 x i64>* %18 to <8 x i16>*
  store <8 x i16> %17, <8 x i16>* %19, align 16
  %20 = or i64 %6, 2
  %21 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 %20
  %22 = bitcast <2 x i64>* %21 to <8 x i16>*
  %23 = load <8 x i16>, <8 x i16>* %22, align 16
  %24 = shl <8 x i16> %23, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %25 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %20
  %26 = bitcast <2 x i64>* %25 to <8 x i16>*
  store <8 x i16> %24, <8 x i16>* %26, align 16
  %27 = or i64 %6, 3
  %28 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 %27
  %29 = bitcast <2 x i64>* %28 to <8 x i16>*
  %30 = load <8 x i16>, <8 x i16>* %29, align 16
  %31 = shl <8 x i16> %30, <i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2, i16 2>
  %32 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %27
  %33 = bitcast <2 x i64>* %32 to <8 x i16>*
  store <8 x i16> %31, <8 x i16>* %33, align 16
  %34 = add nuw nsw i64 %6, 4
  %35 = icmp eq i64 %34, 32
  br i1 %35, label %4, label %5
}

attributes #0 = { nofree nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind }
attributes #2 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { nounwind readnone speculatable }
attributes #6 = { nounwind readnone }
attributes #7 = { inlinehint nofree nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #8 = { nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
