; ModuleID = '../../third_party/dav1d/libdav1d/src/x86/mc_init_tmpl.c'
source_filename = "../../third_party/dav1d/libdav1d/src/x86/mc_init_tmpl.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

%struct.Dav1dMCDSPContext = type { [10 x void (i8*, i64, i8*, i64, i32, i32, i32, i32)*], [10 x void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)*], [10 x void (i16*, i8*, i64, i32, i32, i32, i32)*], [10 x void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)*], void (i8*, i64, i16*, i16*, i32, i32)*, void (i8*, i64, i16*, i16*, i32, i32, i32)*, void (i8*, i64, i16*, i16*, i32, i32, i8*)*, [3 x void (i8*, i64, i16*, i16*, i32, i32, i8*, i32)*], void (i8*, i64, i8*, i32, i32, i8*)*, void (i8*, i64, i8*, i32, i32)*, void (i8*, i64, i8*, i32, i32)*, void (i8*, i64, i8*, i64, i16*, i32, i32)*, void (i16*, i64, i8*, i64, i16*, i32, i32)*, void (i64, i64, i64, i64, i64, i64, i8*, i64, i8*, i64)*, void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32)* }

; Function Attrs: cold nounwind optsize ssp uwtable
define hidden void @dav1d_mc_dsp_init_x86_8bpc(%struct.Dav1dMCDSPContext*) local_unnamed_addr #0 {
  %2 = tail call i32 @dav1d_get_cpu_flags() #2
  %3 = and i32 %2, 1
  %4 = icmp eq i32 %3, 0
  br i1 %4, label %101, label %5

5:                                                ; preds = %1
  %6 = getelementptr inbounds %struct.Dav1dMCDSPContext, %struct.Dav1dMCDSPContext* %0, i64 0, i32 2, i64 9
  %7 = getelementptr inbounds %struct.Dav1dMCDSPContext, %struct.Dav1dMCDSPContext* %0, i64 0, i32 2, i64 0
  %8 = bitcast void (i16*, i8*, i64, i32, i32, i32, i32)** %7 to <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*>*
  store <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*> <void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_regular_sse2, void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_regular_smooth_sse2>, <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*>* %8, align 8
  %9 = getelementptr inbounds %struct.Dav1dMCDSPContext, %struct.Dav1dMCDSPContext* %0, i64 0, i32 2, i64 2
  %10 = getelementptr inbounds %struct.Dav1dMCDSPContext, %struct.Dav1dMCDSPContext* %0, i64 0, i32 2, i64 6
  %11 = bitcast void (i16*, i8*, i64, i32, i32, i32, i32)** %10 to <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*>*
  store <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*> <void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_smooth_regular_sse2, void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_smooth_sse2>, <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*>* %11, align 8
  %12 = getelementptr inbounds %struct.Dav1dMCDSPContext, %struct.Dav1dMCDSPContext* %0, i64 0, i32 2, i64 8
  %13 = bitcast void (i16*, i8*, i64, i32, i32, i32, i32)** %12 to <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*>*
  store <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*> <void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_smooth_sharp_sse2, void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_bilin_sse2>, <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*>* %13, align 8
  %14 = getelementptr inbounds %struct.Dav1dMCDSPContext, %struct.Dav1dMCDSPContext* %0, i64 0, i32 2, i64 3
  %15 = bitcast void (i16*, i8*, i64, i32, i32, i32, i32)** %9 to <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*>*
  store <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*> <void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_regular_sharp_sse2, void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_sharp_regular_sse2>, <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*>* %15, align 8
  %16 = getelementptr inbounds %struct.Dav1dMCDSPContext, %struct.Dav1dMCDSPContext* %0, i64 0, i32 2, i64 4
  %17 = getelementptr inbounds %struct.Dav1dMCDSPContext, %struct.Dav1dMCDSPContext* %0, i64 0, i32 2, i64 5
  %18 = bitcast void (i16*, i8*, i64, i32, i32, i32, i32)** %16 to <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*>*
  store <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*> <void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_sharp_smooth_sse2, void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_sharp_sse2>, <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*>* %18, align 8
  %19 = getelementptr inbounds %struct.Dav1dMCDSPContext, %struct.Dav1dMCDSPContext* %0, i64 0, i32 11
  store void (i8*, i64, i8*, i64, i16*, i32, i32)* @dav1d_warp_affine_8x8_sse2, void (i8*, i64, i8*, i64, i16*, i32, i32)** %19, align 8
  %20 = getelementptr inbounds %struct.Dav1dMCDSPContext, %struct.Dav1dMCDSPContext* %0, i64 0, i32 12
  store void (i16*, i64, i8*, i64, i16*, i32, i32)* @dav1d_warp_affine_8x8t_sse2, void (i16*, i64, i8*, i64, i16*, i32, i32)** %20, align 8
  %21 = and i32 %2, 2
  %22 = icmp eq i32 %21, 0
  br i1 %22, label %101, label %23

23:                                               ; preds = %5
  %24 = bitcast %struct.Dav1dMCDSPContext* %0 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32, i32)* @dav1d_put_8tap_regular_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32, i32)* @dav1d_put_8tap_regular_smooth_ssse3>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32)*>* %24, align 8
  %25 = getelementptr inbounds %struct.Dav1dMCDSPContext, %struct.Dav1dMCDSPContext* %0, i64 0, i32 0, i64 2
  %26 = getelementptr inbounds %struct.Dav1dMCDSPContext, %struct.Dav1dMCDSPContext* %0, i64 0, i32 0, i64 6
  %27 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32, i32)** %26 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32, i32)* @dav1d_put_8tap_smooth_regular_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32, i32)* @dav1d_put_8tap_smooth_ssse3>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32)*>* %27, align 8
  %28 = getelementptr inbounds %struct.Dav1dMCDSPContext, %struct.Dav1dMCDSPContext* %0, i64 0, i32 0, i64 8
  %29 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32, i32)** %28 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32, i32)* @dav1d_put_8tap_smooth_sharp_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32, i32)* @dav1d_put_bilin_ssse3>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32)*>* %29, align 8
  %30 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32, i32)** %25 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32, i32)* @dav1d_put_8tap_regular_sharp_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32, i32)* @dav1d_put_8tap_sharp_regular_ssse3>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32)*>* %30, align 8
  %31 = getelementptr inbounds %struct.Dav1dMCDSPContext, %struct.Dav1dMCDSPContext* %0, i64 0, i32 0, i64 4
  %32 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32, i32)** %31 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32, i32)* @dav1d_put_8tap_sharp_smooth_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32, i32)* @dav1d_put_8tap_sharp_ssse3>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32)*>* %32, align 8
  store void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_bilin_ssse3, void (i16*, i8*, i64, i32, i32, i32, i32)** %6, align 8
  %33 = bitcast void (i16*, i8*, i64, i32, i32, i32, i32)** %7 to <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*>*
  store <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*> <void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_regular_ssse3, void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_regular_smooth_ssse3>, <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*>* %33, align 8
  store void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_regular_sharp_ssse3, void (i16*, i8*, i64, i32, i32, i32, i32)** %9, align 8
  %34 = bitcast void (i16*, i8*, i64, i32, i32, i32, i32)** %10 to <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*>*
  store <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*> <void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_smooth_regular_ssse3, void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_smooth_ssse3>, <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*>* %34, align 8
  store void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_smooth_sharp_ssse3, void (i16*, i8*, i64, i32, i32, i32, i32)** %12, align 8
  %35 = bitcast void (i16*, i8*, i64, i32, i32, i32, i32)** %14 to <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*>*
  store <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*> <void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_sharp_regular_ssse3, void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_sharp_smooth_ssse3>, <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*>* %35, align 8
  store void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_sharp_ssse3, void (i16*, i8*, i64, i32, i32, i32, i32)** %17, align 8
  %36 = getelementptr inbounds %struct.Dav1dMCDSPContext, %struct.Dav1dMCDSPContext* %0, i64 0, i32 1, i64 0
  %37 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)** %36 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_put_8tap_scaled_regular_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_put_8tap_scaled_regular_smooth_ssse3>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)*>* %37, align 8
  %38 = getelementptr inbounds %struct.Dav1dMCDSPContext, %struct.Dav1dMCDSPContext* %0, i64 0, i32 1, i64 2
  %39 = getelementptr inbounds %struct.Dav1dMCDSPContext, %struct.Dav1dMCDSPContext* %0, i64 0, i32 1, i64 6
  %40 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)** %39 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_put_8tap_scaled_smooth_regular_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_put_8tap_scaled_smooth_ssse3>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)*>* %40, align 8
  %41 = getelementptr inbounds %struct.Dav1dMCDSPContext, %struct.Dav1dMCDSPContext* %0, i64 0, i32 1, i64 8
  %42 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)** %38 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_put_8tap_scaled_regular_sharp_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_put_8tap_scaled_sharp_regular_ssse3>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)*>* %42, align 8
  %43 = getelementptr inbounds %struct.Dav1dMCDSPContext, %struct.Dav1dMCDSPContext* %0, i64 0, i32 1, i64 4
  %44 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)** %43 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_put_8tap_scaled_sharp_smooth_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_put_8tap_scaled_sharp_ssse3>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)*>* %44, align 8
  %45 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)** %41 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_put_8tap_scaled_smooth_sharp_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_put_bilin_scaled_ssse3>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)*>* %45, align 8
  %46 = getelementptr inbounds %struct.Dav1dMCDSPContext, %struct.Dav1dMCDSPContext* %0, i64 0, i32 3, i64 0
  %47 = bitcast void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)** %46 to <2 x void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)*>*
  store <2 x void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)*> <void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_prep_8tap_scaled_regular_ssse3, void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_prep_8tap_scaled_regular_smooth_ssse3>, <2 x void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)*>* %47, align 8
  %48 = getelementptr inbounds %struct.Dav1dMCDSPContext, %struct.Dav1dMCDSPContext* %0, i64 0, i32 3, i64 2
  %49 = getelementptr inbounds %struct.Dav1dMCDSPContext, %struct.Dav1dMCDSPContext* %0, i64 0, i32 3, i64 6
  %50 = bitcast void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)** %49 to <2 x void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)*>*
  store <2 x void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)*> <void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_prep_8tap_scaled_smooth_regular_ssse3, void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_prep_8tap_scaled_smooth_ssse3>, <2 x void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)*>* %50, align 8
  %51 = getelementptr inbounds %struct.Dav1dMCDSPContext, %struct.Dav1dMCDSPContext* %0, i64 0, i32 3, i64 8
  %52 = bitcast void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)** %48 to <2 x void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)*>*
  store <2 x void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)*> <void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_prep_8tap_scaled_regular_sharp_ssse3, void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_prep_8tap_scaled_sharp_regular_ssse3>, <2 x void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)*>* %52, align 8
  %53 = getelementptr inbounds %struct.Dav1dMCDSPContext, %struct.Dav1dMCDSPContext* %0, i64 0, i32 3, i64 4
  %54 = bitcast void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)** %53 to <2 x void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)*>*
  store <2 x void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)*> <void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_prep_8tap_scaled_sharp_smooth_ssse3, void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_prep_8tap_scaled_sharp_ssse3>, <2 x void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)*>* %54, align 8
  %55 = bitcast void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)** %51 to <2 x void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)*>*
  store <2 x void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)*> <void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_prep_8tap_scaled_smooth_sharp_ssse3, void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_prep_bilin_scaled_ssse3>, <2 x void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)*>* %55, align 8
  %56 = getelementptr inbounds %struct.Dav1dMCDSPContext, %struct.Dav1dMCDSPContext* %0, i64 0, i32 4
  store void (i8*, i64, i16*, i16*, i32, i32)* @dav1d_avg_ssse3, void (i8*, i64, i16*, i16*, i32, i32)** %56, align 8
  %57 = getelementptr inbounds %struct.Dav1dMCDSPContext, %struct.Dav1dMCDSPContext* %0, i64 0, i32 5
  store void (i8*, i64, i16*, i16*, i32, i32, i32)* @dav1d_w_avg_ssse3, void (i8*, i64, i16*, i16*, i32, i32, i32)** %57, align 8
  %58 = getelementptr inbounds %struct.Dav1dMCDSPContext, %struct.Dav1dMCDSPContext* %0, i64 0, i32 6
  store void (i8*, i64, i16*, i16*, i32, i32, i8*)* @dav1d_mask_ssse3, void (i8*, i64, i16*, i16*, i32, i32, i8*)** %58, align 8
  %59 = getelementptr inbounds %struct.Dav1dMCDSPContext, %struct.Dav1dMCDSPContext* %0, i64 0, i32 7, i64 2
  store void (i8*, i64, i16*, i16*, i32, i32, i8*, i32)* @dav1d_w_mask_420_ssse3, void (i8*, i64, i16*, i16*, i32, i32, i8*, i32)** %59, align 8
  %60 = getelementptr inbounds %struct.Dav1dMCDSPContext, %struct.Dav1dMCDSPContext* %0, i64 0, i32 8
  store void (i8*, i64, i8*, i32, i32, i8*)* @dav1d_blend_ssse3, void (i8*, i64, i8*, i32, i32, i8*)** %60, align 8
  %61 = getelementptr inbounds %struct.Dav1dMCDSPContext, %struct.Dav1dMCDSPContext* %0, i64 0, i32 9
  %62 = getelementptr inbounds %struct.Dav1dMCDSPContext, %struct.Dav1dMCDSPContext* %0, i64 0, i32 10
  %63 = bitcast void (i8*, i64, i8*, i32, i32)** %61 to <2 x void (i8*, i64, i8*, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i32, i32)*> <void (i8*, i64, i8*, i32, i32)* @dav1d_blend_v_ssse3, void (i8*, i64, i8*, i32, i32)* @dav1d_blend_h_ssse3>, <2 x void (i8*, i64, i8*, i32, i32)*>* %63, align 8
  store void (i8*, i64, i8*, i64, i16*, i32, i32)* @dav1d_warp_affine_8x8_ssse3, void (i8*, i64, i8*, i64, i16*, i32, i32)** %19, align 8
  store void (i16*, i64, i8*, i64, i16*, i32, i32)* @dav1d_warp_affine_8x8t_ssse3, void (i16*, i64, i8*, i64, i16*, i32, i32)** %20, align 8
  %64 = getelementptr inbounds %struct.Dav1dMCDSPContext, %struct.Dav1dMCDSPContext* %0, i64 0, i32 13
  store void (i64, i64, i64, i64, i64, i64, i8*, i64, i8*, i64)* @dav1d_emu_edge_ssse3, void (i64, i64, i64, i64, i64, i64, i8*, i64, i8*, i64)** %64, align 8
  %65 = getelementptr inbounds %struct.Dav1dMCDSPContext, %struct.Dav1dMCDSPContext* %0, i64 0, i32 14
  store void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32)* @dav1d_resize_ssse3, void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32)** %65, align 8
  %66 = and i32 %2, 4
  %67 = icmp eq i32 %66, 0
  br i1 %67, label %101, label %68

68:                                               ; preds = %23
  store void (i8*, i64, i8*, i64, i16*, i32, i32)* @dav1d_warp_affine_8x8_sse4, void (i8*, i64, i8*, i64, i16*, i32, i32)** %19, align 8
  store void (i16*, i64, i8*, i64, i16*, i32, i32)* @dav1d_warp_affine_8x8t_sse4, void (i16*, i64, i8*, i64, i16*, i32, i32)** %20, align 8
  %69 = and i32 %2, 8
  %70 = icmp eq i32 %69, 0
  br i1 %70, label %101, label %71

71:                                               ; preds = %68
  %72 = bitcast %struct.Dav1dMCDSPContext* %0 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32, i32)* @dav1d_put_8tap_regular_avx2, void (i8*, i64, i8*, i64, i32, i32, i32, i32)* @dav1d_put_8tap_regular_smooth_avx2>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32)*>* %72, align 8
  %73 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32, i32)** %26 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32, i32)* @dav1d_put_8tap_smooth_regular_avx2, void (i8*, i64, i8*, i64, i32, i32, i32, i32)* @dav1d_put_8tap_smooth_avx2>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32)*>* %73, align 8
  %74 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32, i32)** %25 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32, i32)* @dav1d_put_8tap_regular_sharp_avx2, void (i8*, i64, i8*, i64, i32, i32, i32, i32)* @dav1d_put_8tap_sharp_regular_avx2>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32)*>* %74, align 8
  %75 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32, i32)** %31 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32, i32)* @dav1d_put_8tap_sharp_smooth_avx2, void (i8*, i64, i8*, i64, i32, i32, i32, i32)* @dav1d_put_8tap_sharp_avx2>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32)*>* %75, align 8
  %76 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32, i32)** %28 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32, i32)* @dav1d_put_8tap_smooth_sharp_avx2, void (i8*, i64, i8*, i64, i32, i32, i32, i32)* @dav1d_put_bilin_avx2>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32)*>* %76, align 8
  %77 = bitcast void (i16*, i8*, i64, i32, i32, i32, i32)** %7 to <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*>*
  store <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*> <void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_regular_avx2, void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_regular_smooth_avx2>, <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*>* %77, align 8
  store void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_regular_sharp_avx2, void (i16*, i8*, i64, i32, i32, i32, i32)** %9, align 8
  %78 = bitcast void (i16*, i8*, i64, i32, i32, i32, i32)** %10 to <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*>*
  store <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*> <void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_smooth_regular_avx2, void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_smooth_avx2>, <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*>* %78, align 8
  store void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_smooth_sharp_avx2, void (i16*, i8*, i64, i32, i32, i32, i32)** %12, align 8
  %79 = bitcast void (i16*, i8*, i64, i32, i32, i32, i32)** %14 to <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*>*
  store <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*> <void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_sharp_regular_avx2, void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_sharp_smooth_avx2>, <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*>* %79, align 8
  store void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_sharp_avx2, void (i16*, i8*, i64, i32, i32, i32, i32)** %17, align 8
  store void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_bilin_avx2, void (i16*, i8*, i64, i32, i32, i32, i32)** %6, align 8
  %80 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)** %36 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_put_8tap_scaled_regular_avx2, void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_put_8tap_scaled_regular_smooth_avx2>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)*>* %80, align 8
  %81 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)** %39 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_put_8tap_scaled_smooth_regular_avx2, void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_put_8tap_scaled_smooth_avx2>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)*>* %81, align 8
  %82 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)** %38 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_put_8tap_scaled_regular_sharp_avx2, void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_put_8tap_scaled_sharp_regular_avx2>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)*>* %82, align 8
  %83 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)** %43 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_put_8tap_scaled_sharp_smooth_avx2, void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_put_8tap_scaled_sharp_avx2>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)*>* %83, align 8
  %84 = bitcast void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)** %41 to <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)*>*
  store <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)*> <void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_put_8tap_scaled_smooth_sharp_avx2, void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_put_bilin_scaled_avx2>, <2 x void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32)*>* %84, align 8
  %85 = bitcast void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)** %46 to <2 x void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)*>*
  store <2 x void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)*> <void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_prep_8tap_scaled_regular_avx2, void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_prep_8tap_scaled_regular_smooth_avx2>, <2 x void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)*>* %85, align 8
  %86 = bitcast void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)** %49 to <2 x void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)*>*
  store <2 x void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)*> <void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_prep_8tap_scaled_smooth_regular_avx2, void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_prep_8tap_scaled_smooth_avx2>, <2 x void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)*>* %86, align 8
  %87 = bitcast void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)** %48 to <2 x void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)*>*
  store <2 x void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)*> <void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_prep_8tap_scaled_regular_sharp_avx2, void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_prep_8tap_scaled_sharp_regular_avx2>, <2 x void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)*>* %87, align 8
  %88 = bitcast void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)** %53 to <2 x void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)*>*
  store <2 x void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)*> <void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_prep_8tap_scaled_sharp_smooth_avx2, void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_prep_8tap_scaled_sharp_avx2>, <2 x void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)*>* %88, align 8
  %89 = bitcast void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)** %51 to <2 x void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)*>*
  store <2 x void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)*> <void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_prep_8tap_scaled_smooth_sharp_avx2, void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)* @dav1d_prep_bilin_scaled_avx2>, <2 x void (i16*, i8*, i64, i32, i32, i32, i32, i32, i32)*>* %89, align 8
  store void (i8*, i64, i16*, i16*, i32, i32)* @dav1d_avg_avx2, void (i8*, i64, i16*, i16*, i32, i32)** %56, align 8
  store void (i8*, i64, i16*, i16*, i32, i32, i32)* @dav1d_w_avg_avx2, void (i8*, i64, i16*, i16*, i32, i32, i32)** %57, align 8
  store void (i8*, i64, i16*, i16*, i32, i32, i8*)* @dav1d_mask_avx2, void (i8*, i64, i16*, i16*, i32, i32, i8*)** %58, align 8
  %90 = getelementptr inbounds %struct.Dav1dMCDSPContext, %struct.Dav1dMCDSPContext* %0, i64 0, i32 7, i64 0
  %91 = bitcast void (i8*, i64, i16*, i16*, i32, i32, i8*, i32)** %90 to <2 x void (i8*, i64, i16*, i16*, i32, i32, i8*, i32)*>*
  store <2 x void (i8*, i64, i16*, i16*, i32, i32, i8*, i32)*> <void (i8*, i64, i16*, i16*, i32, i32, i8*, i32)* @dav1d_w_mask_444_avx2, void (i8*, i64, i16*, i16*, i32, i32, i8*, i32)* @dav1d_w_mask_422_avx2>, <2 x void (i8*, i64, i16*, i16*, i32, i32, i8*, i32)*>* %91, align 8
  store void (i8*, i64, i16*, i16*, i32, i32, i8*, i32)* @dav1d_w_mask_420_avx2, void (i8*, i64, i16*, i16*, i32, i32, i8*, i32)** %59, align 8
  store void (i8*, i64, i8*, i32, i32, i8*)* @dav1d_blend_avx2, void (i8*, i64, i8*, i32, i32, i8*)** %60, align 8
  store void (i8*, i64, i8*, i32, i32)* @dav1d_blend_v_avx2, void (i8*, i64, i8*, i32, i32)** %61, align 8
  store void (i8*, i64, i8*, i32, i32)* @dav1d_blend_h_avx2, void (i8*, i64, i8*, i32, i32)** %62, align 8
  store void (i8*, i64, i8*, i64, i16*, i32, i32)* @dav1d_warp_affine_8x8_avx2, void (i8*, i64, i8*, i64, i16*, i32, i32)** %19, align 8
  store void (i16*, i64, i8*, i64, i16*, i32, i32)* @dav1d_warp_affine_8x8t_avx2, void (i16*, i64, i8*, i64, i16*, i32, i32)** %20, align 8
  store void (i64, i64, i64, i64, i64, i64, i8*, i64, i8*, i64)* @dav1d_emu_edge_avx2, void (i64, i64, i64, i64, i64, i64, i8*, i64, i8*, i64)** %64, align 8
  store void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32)* @dav1d_resize_avx2, void (i8*, i64, i8*, i64, i32, i32, i32, i32, i32)** %65, align 8
  %92 = and i32 %2, 16
  %93 = icmp eq i32 %92, 0
  br i1 %93, label %101, label %94

94:                                               ; preds = %71
  %95 = bitcast void (i16*, i8*, i64, i32, i32, i32, i32)** %7 to <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*>*
  store <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*> <void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_regular_avx512icl, void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_regular_smooth_avx512icl>, <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*>* %95, align 8
  %96 = bitcast void (i16*, i8*, i64, i32, i32, i32, i32)** %10 to <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*>*
  store <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*> <void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_smooth_regular_avx512icl, void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_smooth_avx512icl>, <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*>* %96, align 8
  %97 = bitcast void (i16*, i8*, i64, i32, i32, i32, i32)** %9 to <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*>*
  store <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*> <void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_regular_sharp_avx512icl, void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_sharp_regular_avx512icl>, <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*>* %97, align 8
  %98 = bitcast void (i16*, i8*, i64, i32, i32, i32, i32)** %16 to <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*>*
  store <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*> <void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_sharp_smooth_avx512icl, void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_sharp_avx512icl>, <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*>* %98, align 8
  %99 = bitcast void (i16*, i8*, i64, i32, i32, i32, i32)** %12 to <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*>*
  store <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*> <void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_8tap_smooth_sharp_avx512icl, void (i16*, i8*, i64, i32, i32, i32, i32)* @dav1d_prep_bilin_avx512icl>, <2 x void (i16*, i8*, i64, i32, i32, i32, i32)*>* %99, align 8
  store void (i8*, i64, i16*, i16*, i32, i32)* @dav1d_avg_avx512icl, void (i8*, i64, i16*, i16*, i32, i32)** %56, align 8
  store void (i8*, i64, i16*, i16*, i32, i32, i32)* @dav1d_w_avg_avx512icl, void (i8*, i64, i16*, i16*, i32, i32, i32)** %57, align 8
  store void (i8*, i64, i16*, i16*, i32, i32, i8*)* @dav1d_mask_avx512icl, void (i8*, i64, i16*, i16*, i32, i32, i8*)** %58, align 8
  %100 = bitcast void (i8*, i64, i16*, i16*, i32, i32, i8*, i32)** %90 to <2 x void (i8*, i64, i16*, i16*, i32, i32, i8*, i32)*>*
  store <2 x void (i8*, i64, i16*, i16*, i32, i32, i8*, i32)*> <void (i8*, i64, i16*, i16*, i32, i32, i8*, i32)* @dav1d_w_mask_444_avx512icl, void (i8*, i64, i16*, i16*, i32, i32, i8*, i32)* @dav1d_w_mask_422_avx512icl>, <2 x void (i8*, i64, i16*, i16*, i32, i32, i8*, i32)*>* %100, align 8
  store void (i8*, i64, i16*, i16*, i32, i32, i8*, i32)* @dav1d_w_mask_420_avx512icl, void (i8*, i64, i16*, i16*, i32, i32, i8*, i32)** %59, align 8
  br label %101

101:                                              ; preds = %71, %68, %23, %5, %1, %94
  ret void
}

declare i32 @dav1d_get_cpu_flags() local_unnamed_addr #1

declare void @dav1d_prep_bilin_sse2(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_regular_sse2(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_regular_smooth_sse2(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_regular_sharp_sse2(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_smooth_regular_sse2(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_smooth_sse2(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_smooth_sharp_sse2(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_sharp_regular_sse2(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_sharp_smooth_sse2(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_sharp_sse2(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_warp_affine_8x8_sse2(i8*, i64, i8*, i64, i16*, i32, i32) #1

declare void @dav1d_warp_affine_8x8t_sse2(i16*, i64, i8*, i64, i16*, i32, i32) #1

declare void @dav1d_put_bilin_ssse3(i8*, i64, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_regular_ssse3(i8*, i64, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_regular_smooth_ssse3(i8*, i64, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_regular_sharp_ssse3(i8*, i64, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_smooth_regular_ssse3(i8*, i64, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_smooth_ssse3(i8*, i64, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_smooth_sharp_ssse3(i8*, i64, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_sharp_regular_ssse3(i8*, i64, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_sharp_smooth_ssse3(i8*, i64, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_sharp_ssse3(i8*, i64, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_bilin_ssse3(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_regular_ssse3(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_regular_smooth_ssse3(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_regular_sharp_ssse3(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_smooth_regular_ssse3(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_smooth_ssse3(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_smooth_sharp_ssse3(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_sharp_regular_ssse3(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_sharp_smooth_ssse3(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_sharp_ssse3(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_scaled_regular_ssse3(i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_scaled_regular_smooth_ssse3(i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_scaled_regular_sharp_ssse3(i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_scaled_smooth_regular_ssse3(i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_scaled_smooth_ssse3(i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_scaled_smooth_sharp_ssse3(i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_scaled_sharp_regular_ssse3(i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_scaled_sharp_smooth_ssse3(i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_scaled_sharp_ssse3(i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_put_bilin_scaled_ssse3(i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_scaled_regular_ssse3(i16*, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_scaled_regular_smooth_ssse3(i16*, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_scaled_regular_sharp_ssse3(i16*, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_scaled_smooth_regular_ssse3(i16*, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_scaled_smooth_ssse3(i16*, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_scaled_smooth_sharp_ssse3(i16*, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_scaled_sharp_regular_ssse3(i16*, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_scaled_sharp_smooth_ssse3(i16*, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_scaled_sharp_ssse3(i16*, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_prep_bilin_scaled_ssse3(i16*, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_avg_ssse3(i8*, i64, i16*, i16*, i32, i32) #1

declare void @dav1d_w_avg_ssse3(i8*, i64, i16*, i16*, i32, i32, i32) #1

declare void @dav1d_mask_ssse3(i8*, i64, i16*, i16*, i32, i32, i8*) #1

declare void @dav1d_w_mask_420_ssse3(i8*, i64, i16*, i16*, i32, i32, i8*, i32) #1

declare void @dav1d_blend_ssse3(i8*, i64, i8*, i32, i32, i8*) #1

declare void @dav1d_blend_v_ssse3(i8*, i64, i8*, i32, i32) #1

declare void @dav1d_blend_h_ssse3(i8*, i64, i8*, i32, i32) #1

declare void @dav1d_warp_affine_8x8_ssse3(i8*, i64, i8*, i64, i16*, i32, i32) #1

declare void @dav1d_warp_affine_8x8t_ssse3(i16*, i64, i8*, i64, i16*, i32, i32) #1

declare void @dav1d_emu_edge_ssse3(i64, i64, i64, i64, i64, i64, i8*, i64, i8*, i64) #1

declare void @dav1d_resize_ssse3(i8*, i64, i8*, i64, i32, i32, i32, i32, i32) #1

declare void @dav1d_warp_affine_8x8_sse4(i8*, i64, i8*, i64, i16*, i32, i32) #1

declare void @dav1d_warp_affine_8x8t_sse4(i16*, i64, i8*, i64, i16*, i32, i32) #1

declare void @dav1d_put_8tap_regular_avx2(i8*, i64, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_regular_smooth_avx2(i8*, i64, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_regular_sharp_avx2(i8*, i64, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_smooth_regular_avx2(i8*, i64, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_smooth_avx2(i8*, i64, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_smooth_sharp_avx2(i8*, i64, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_sharp_regular_avx2(i8*, i64, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_sharp_smooth_avx2(i8*, i64, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_sharp_avx2(i8*, i64, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_put_bilin_avx2(i8*, i64, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_regular_avx2(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_regular_smooth_avx2(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_regular_sharp_avx2(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_smooth_regular_avx2(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_smooth_avx2(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_smooth_sharp_avx2(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_sharp_regular_avx2(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_sharp_smooth_avx2(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_sharp_avx2(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_bilin_avx2(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_scaled_regular_avx2(i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_scaled_regular_smooth_avx2(i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_scaled_regular_sharp_avx2(i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_scaled_smooth_regular_avx2(i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_scaled_smooth_avx2(i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_scaled_smooth_sharp_avx2(i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_scaled_sharp_regular_avx2(i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_scaled_sharp_smooth_avx2(i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_put_8tap_scaled_sharp_avx2(i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_put_bilin_scaled_avx2(i8*, i64, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_scaled_regular_avx2(i16*, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_scaled_regular_smooth_avx2(i16*, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_scaled_regular_sharp_avx2(i16*, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_scaled_smooth_regular_avx2(i16*, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_scaled_smooth_avx2(i16*, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_scaled_smooth_sharp_avx2(i16*, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_scaled_sharp_regular_avx2(i16*, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_scaled_sharp_smooth_avx2(i16*, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_scaled_sharp_avx2(i16*, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_prep_bilin_scaled_avx2(i16*, i8*, i64, i32, i32, i32, i32, i32, i32) #1

declare void @dav1d_avg_avx2(i8*, i64, i16*, i16*, i32, i32) #1

declare void @dav1d_w_avg_avx2(i8*, i64, i16*, i16*, i32, i32, i32) #1

declare void @dav1d_mask_avx2(i8*, i64, i16*, i16*, i32, i32, i8*) #1

declare void @dav1d_w_mask_444_avx2(i8*, i64, i16*, i16*, i32, i32, i8*, i32) #1

declare void @dav1d_w_mask_422_avx2(i8*, i64, i16*, i16*, i32, i32, i8*, i32) #1

declare void @dav1d_w_mask_420_avx2(i8*, i64, i16*, i16*, i32, i32, i8*, i32) #1

declare void @dav1d_blend_avx2(i8*, i64, i8*, i32, i32, i8*) #1

declare void @dav1d_blend_v_avx2(i8*, i64, i8*, i32, i32) #1

declare void @dav1d_blend_h_avx2(i8*, i64, i8*, i32, i32) #1

declare void @dav1d_warp_affine_8x8_avx2(i8*, i64, i8*, i64, i16*, i32, i32) #1

declare void @dav1d_warp_affine_8x8t_avx2(i16*, i64, i8*, i64, i16*, i32, i32) #1

declare void @dav1d_emu_edge_avx2(i64, i64, i64, i64, i64, i64, i8*, i64, i8*, i64) #1

declare void @dav1d_resize_avx2(i8*, i64, i8*, i64, i32, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_regular_avx512icl(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_regular_smooth_avx512icl(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_regular_sharp_avx512icl(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_smooth_regular_avx512icl(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_smooth_avx512icl(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_smooth_sharp_avx512icl(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_sharp_regular_avx512icl(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_sharp_smooth_avx512icl(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_8tap_sharp_avx512icl(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_prep_bilin_avx512icl(i16*, i8*, i64, i32, i32, i32, i32) #1

declare void @dav1d_avg_avx512icl(i8*, i64, i16*, i16*, i32, i32) #1

declare void @dav1d_w_avg_avx512icl(i8*, i64, i16*, i16*, i32, i32, i32) #1

declare void @dav1d_mask_avx512icl(i8*, i64, i16*, i16*, i32, i32, i8*) #1

declare void @dav1d_w_mask_444_avx512icl(i8*, i64, i16*, i16*, i32, i32, i8*, i32) #1

declare void @dav1d_w_mask_422_avx512icl(i8*, i64, i16*, i16*, i32, i32, i8*, i32) #1

declare void @dav1d_w_mask_420_avx512icl(i8*, i64, i16*, i16*, i32, i32, i8*, i32) #1

attributes #0 = { cold nounwind optsize ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
