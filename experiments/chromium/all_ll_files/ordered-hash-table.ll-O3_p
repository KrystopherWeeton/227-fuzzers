; ModuleID = '../../v8/src/objects/ordered-hash-table.cc'
source_filename = "../../v8/src/objects/ordered-hash-table.cc"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

module asm ".symver exp, exp@GLIBC_2.2.5"
module asm ".symver exp2, exp2@GLIBC_2.2.5"
module asm ".symver exp2f, exp2f@GLIBC_2.2.5"
module asm ".symver expf, expf@GLIBC_2.2.5"
module asm ".symver lgamma, lgamma@GLIBC_2.2.5"
module asm ".symver lgammaf, lgammaf@GLIBC_2.2.5"
module asm ".symver lgammal, lgammal@GLIBC_2.2.5"
module asm ".symver log, log@GLIBC_2.2.5"
module asm ".symver log2, log2@GLIBC_2.2.5"
module asm ".symver log2f, log2f@GLIBC_2.2.5"
module asm ".symver logf, logf@GLIBC_2.2.5"
module asm ".symver pow, pow@GLIBC_2.2.5"
module asm ".symver powf, powf@GLIBC_2.2.5"

%"class.v8::internal::SoleReadOnlyHeap" = type { %"class.v8::internal::ReadOnlyHeap", [587 x i64] }
%"class.v8::internal::ReadOnlyHeap" = type { i32 (...)**, i8, %"class.v8::internal::ReadOnlySpace"*, %"class.std::__1::vector.541" }
%"class.v8::internal::ReadOnlySpace" = type { %"class.v8::internal::BaseSpace", i8, %"class.v8::internal::AllocationStats", %"class.std::__1::vector.139", i64, i64, i8, i64, i64 }
%"class.v8::internal::BaseSpace" = type { i32 (...)**, %"class.v8::internal::Heap"*, i32, %"struct.std::__1::atomic.19", i64 }
%"class.v8::internal::Heap" = type { %"class.std::__1::unordered_map", %"struct.std::__1::atomic.19", %"class.v8::internal::Heap::ExternalMemoryAccounting", %"class.v8::internal::Isolate"*, i64, i64, i64, i64, %"struct.std::__1::atomic.19", i64, i64, i64, i64, i64, i8, i64, i64, %"struct.std::__1::atomic.19", i64, i64, %"struct.std::__1::atomic.19", %"struct.std::__1::atomic.29", %"class.std::__1::vector", i32, %"class.v8::internal::NewSpace"*, %"class.v8::internal::OldSpace"*, %"class.v8::internal::CodeSpace"*, %"class.v8::internal::MapSpace"*, %"class.v8::internal::OldLargeObjectSpace"*, %"class.v8::internal::CodeLargeObjectSpace"*, %"class.v8::internal::NewLargeObjectSpace"*, %"class.v8::internal::ReadOnlySpace"*, %"class.v8::internal::OldSpace"*, %"class.v8::internal::MapSpace"*, %"class.std::__1::unique_ptr.146", %"class.std::__1::unique_ptr.146", [8 x %"class.v8::internal::Space"*], %"class.v8::internal::LocalHeap"*, %"class.v8::internal::ArrayBufferExtension"*, %"class.v8::internal::ArrayBufferExtension"*, i8, i64, %"struct.std::__1::atomic.161", i32, i32, i32, i32, %"class.v8::internal::AllocationObserver"*, %"class.v8::internal::StressScavengeObserver"*, double, i32, i32, i32, i64, i32, [128 x i64], %"struct.std::__1::atomic.19", i64, i8, %"struct.std::__1::atomic.19", %"class.v8::internal::Object", %"class.v8::internal::Object", %"class.v8::internal::Object", %"class.std::__1::vector.165", %"class.std::__1::vector.165", i64 ()*, [113 x i32], i64, double, double, i64, i64, double, i32, i32, i32, i32, double, double, double, %"class.std::__1::unique_ptr.172", %"class.std::__1::unique_ptr.178", %"class.v8::internal::MinorMarkCompactCollector"*, %"class.std::__1::unique_ptr.308", %"class.std::__1::unique_ptr.314", %"class.std::__1::unique_ptr.320", %"class.std::__1::unique_ptr.359", %"class.std::__1::unique_ptr.398", %"class.std::__1::unique_ptr.428", %"class.std::__1::unique_ptr.434", %"class.std::__1::unique_ptr.444", %"class.std::__1::unique_ptr.450", %"class.std::__1::unique_ptr.450", %"class.std::__1::unique_ptr.456", %"class.std::__1::unique_ptr.462", %"class.std::__1::unique_ptr.462", %"class.std::__1::unique_ptr.468", %"class.std::__1::unique_ptr.474", %"class.std::__1::shared_ptr.480", %"class.v8::CppHeap"*, %"class.v8::EmbedderRootsHandler"*, %"class.v8::internal::StrongRootsEntry"*, %"class.v8::base::Mutex", i8, i64, i64, i64, i64, %"class.std::__1::unordered_map.503", %"class.std::__1::unique_ptr.529", [512 x i8], i8, i8, i64, i8, i32, i32, %"class.std::__1::unique_ptr.535", i8, %"class.v8::internal::Heap::ExternalStringTable", %"class.v8::base::Mutex", %"class.std::__1::unique_ptr.548", i32, i8, i8, i8, i8, i8, %"class.v8::internal::HeapObject", %"class.v8::base::SharedMutex", %"class.v8::base::Mutex", %"class.std::__1::unordered_set.330", i8, [7 x i8], %"class.std::__1::unordered_map.554", %"class.std::__1::unordered_map.580", %"class.std::__1::unordered_map.554", %"class.std::__1::unordered_map.604", %"class.std::__1::vector.632", i8, %"class.std::__1::unique_ptr.639", i32, i32 }
%"class.std::__1::unordered_map" = type { %"class.std::__1::__hash_table" }
%"class.std::__1::__hash_table" = type <{ %"class.std::__1::unique_ptr.2", %"class.std::__1::__compressed_pair.9", %"class.std::__1::__compressed_pair.14", %"class.std::__1::__compressed_pair.16", [4 x i8] }>
%"class.std::__1::unique_ptr.2" = type { %"class.std::__1::__compressed_pair.3" }
%"class.std::__1::__compressed_pair.3" = type { %"struct.std::__1::__compressed_pair_elem.4", %"struct.std::__1::__compressed_pair_elem.5" }
%"struct.std::__1::__compressed_pair_elem.4" = type { %"struct.std::__1::__hash_node_base"** }
%"struct.std::__1::__hash_node_base" = type { %"struct.std::__1::__hash_node_base"* }
%"struct.std::__1::__compressed_pair_elem.5" = type { %"class.std::__1::__bucket_list_deallocator" }
%"class.std::__1::__bucket_list_deallocator" = type { %"class.std::__1::__compressed_pair.6" }
%"class.std::__1::__compressed_pair.6" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"struct.std::__1::__compressed_pair_elem.7" = type { i64 }
%"class.std::__1::__compressed_pair.9" = type { %"struct.std::__1::__compressed_pair_elem.10" }
%"struct.std::__1::__compressed_pair_elem.10" = type { %"struct.std::__1::__hash_node_base" }
%"class.std::__1::__compressed_pair.14" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.16" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"struct.std::__1::__compressed_pair_elem.17" = type { float }
%"class.v8::internal::Heap::ExternalMemoryAccounting" = type { %"struct.std::__1::atomic.24", %"struct.std::__1::atomic.24", %"struct.std::__1::atomic.24" }
%"struct.std::__1::atomic.24" = type { %"struct.std::__1::__atomic_base.25" }
%"struct.std::__1::__atomic_base.25" = type { %"struct.std::__1::__atomic_base.26" }
%"struct.std::__1::__atomic_base.26" = type { %"struct.std::__1::__cxx_atomic_impl.27" }
%"struct.std::__1::__cxx_atomic_impl.27" = type { %"struct.std::__1::__cxx_atomic_base_impl.28" }
%"struct.std::__1::__cxx_atomic_base_impl.28" = type { i64 }
%"class.v8::internal::Isolate" = type { %"class.v8::internal::IsolateData", %"class.std::__1::unique_ptr", %"class.v8::internal::Heap", %"class.v8::internal::ReadOnlyHeap"*, %"class.std::__1::shared_ptr.645", %"class.std::__1::unique_ptr.666", i32, %"class.v8::internal::Isolate::EntryStackItem"*, i32, %"class.v8::internal::StringStream"*, [13 x i64], %"class.v8::internal::Bootstrapper"*, %"class.v8::internal::RuntimeProfiler"*, %"class.v8::internal::CompilationCache"*, %"class.std::__1::shared_ptr.676", %"class.v8::base::RecursiveMutex", %"class.v8::base::SharedMutex", %"class.v8::base::SharedMutex", %"class.v8::base::SharedMutex", %"class.v8::base::SharedMutex", %"class.v8::base::SharedMutex", %"class.v8::internal::Logger"*, %"class.v8::internal::StubCache"*, %"class.v8::internal::StubCache"*, %"class.v8::internal::Deoptimizer"*, i8, %"class.v8::internal::MaterializedObjectStore"*, i8, i32, i32, %"class.v8::internal::DescriptorLookupCache"*, %"struct.v8::internal::HandleScopeData", %"class.v8::internal::HandleScopeImplementer"*, %"class.v8::internal::UnicodeCache"*, %"class.v8::internal::AccountingAllocator"*, %"class.v8::internal::InnerPointerToCodeCache"*, %"class.v8::internal::GlobalHandles"*, %"class.v8::internal::EternalHandles"*, %"class.v8::internal::ThreadManager"*, %"class.v8::bigint::Processor"*, %"class.v8::internal::RuntimeState", %"class.v8::internal::Builtins", %"class.v8::internal::SetupIsolateDelegate"*, %"class.v8::internal::RegExpStack"*, %"class.std::__1::vector.815", %"class.v8::internal::DateCache"*, %"class.v8::base::RandomNumberGenerator"*, %"class.v8::base::RandomNumberGenerator"*, %"struct.std::__1::atomic.828", {}*, i8*, void (i32, %"class.v8::Promise"*, %"class.v8::Value"*)*, {}*, {}*, %"struct.std::__1::atomic.838", {}*, %"class.v8::base::Mutex", double, %"class.std::__1::basic_string", %"class.std::__1::unordered_map.849", %"struct.std::__1::atomic.152", i8, i8, i8, i8, i8, i8, double, %"class.v8::internal::Debug"*, %"class.v8::internal::HeapProfiler"*, %"class.std::__1::unique_ptr.924", %"class.v8::internal::AstStringConstants"*, %"class.v8::internal::interpreter::Interpreter"*, %"class.v8::internal::compiler::PerIsolateCompilerCache"*, %"class.v8::internal::Zone"*, %"class.v8::internal::CompilerDispatcher"*, %"class.std::__1::queue", void (i8*, i8*)*, void (i8*, i1)*, void (i8*, i32)*, i1 (%"class.v8::Context"*, %"class.v8::String"*)*, { i8, %"class.v8::String"* } (%"class.v8::Context"*, %"class.v8::Value"*)*, { i8, %"class.v8::String"* } (%"class.v8::Context"*, %"class.v8::Value"*, i1)*, i1 (%"class.v8::Context"*, %"class.v8::String"*)*, i1 (%"class.v8::FunctionCallbackInfo"*)*, i1 (%"class.v8::FunctionCallbackInfo"*)*, i1 (%"class.v8::Context"*)*, void (%"class.v8::FunctionCallbackInfo"*)*, %"class.v8::String"* (%"class.v8::Isolate"*, i8*)*, i1 (%"class.v8::Context"*)*, i1 (%"class.v8::Context"*)*, %"class.v8::internal::Relocatable"*, %"class.std::__1::vector.967"*, %"class.v8::internal::Object", i64*, %"class.v8::internal::AddressToIndexHashMap"*, %"class.v8::internal::HeapObjectToIndexHashMap"*, %"class.v8::internal::MicrotaskQueue"*, %"class.v8::internal::CompilationStatistics"*, %"class.v8::internal::CodeTracer"*, i32, void (%"class.v8::PromiseRejectMessage"*)*, %"class.v8::StartupData"*, i32, i32, i32, i64, i8, i8, i32, i8, i32, %"class.v8_inspector::V8Inspector"*, i8, i8, i8, i32, i32, %"class.v8::internal::compiler::NodeObserver"*, i8, [128 x i32], [256 x i32], [251 x i32], [251 x i32], %"class.v8::internal::OptimizingCompileDispatcher"*, %"class.std::__1::unique_ptr.975", i32, i8, i8, i32, i32, %"class.std::__1::vector.981", %"class.std::__1::vector.981", void (%"class.v8::Isolate"*, i32)*, %"class.std::__1::shared_ptr.988", i64, %"class.std::__1::unordered_map.989", i64, %"struct.v8::metrics::LongTaskStats", %"class.std::__1::vector.541", %"class.v8::internal::BuiltinsConstantsTableBuilder"*, i8*, i32, i8*, i32, %"class.v8::ArrayBuffer::Allocator"*, %"class.std::__1::shared_ptr.160", %"class.v8::internal::FutexWaitListNode", %"class.v8::internal::CancelableTaskManager"*, %"class.v8::debug::ConsoleDelegate"*, %"class.v8::debug::AsyncEventDelegate"*, i32, i32, %"class.std::__1::unique_ptr.1045", i1 (%"class.v8::Isolate"*)*, i8, %"class.v8::base::Mutex", %"struct.v8::internal::ManagedPtrDestructor"*, i64, i64, %"class.v8::internal::wasm::WasmEngine"*, %"class.std::__1::unique_ptr.1083", %"class.v8::internal::EmbeddedFileWriterInterface"*, %"class.v8::Context::BackupIncumbentScope"*, {}*, %"class.v8::base::Mutex", %"class.v8::internal::Isolate::ThreadDataTable", i8, %"class.v8::internal::Isolate"*, %"class.v8::base::Mutex", %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate"*, %"struct.std::__1::atomic.1117", %"class.std::__1::vector.1121", %"class.std::__1::vector.1121", void (i32, %"class.std::__1::basic_string"*)* }
%"class.v8::internal::IsolateData" = type { [4 x i8*], i64, i64, i64, i64, i64, %"class.v8::internal::StackGuard", %"class.v8::internal::RootsTable", %"class.v8::internal::ExternalReferenceTable", %"class.v8::internal::ThreadLocalTop", [1711 x i64], [1711 x i64], i8, [15 x i8] }
%"class.v8::internal::StackGuard" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::StackGuard::ThreadLocal" }
%"class.v8::internal::StackGuard::ThreadLocal" = type { i64, i64, i64, i64, %"class.v8::internal::InterruptsScope"*, i64 }
%"class.v8::internal::InterruptsScope" = type { i32 (...)**, %"class.v8::internal::StackGuard"*, i64, i64, i32, %"class.v8::internal::InterruptsScope"* }
%"class.v8::internal::RootsTable" = type { [669 x i64] }
%"class.v8::internal::ExternalReferenceTable" = type { [1042 x i64], i32, i32 }
%"class.v8::internal::ThreadLocalTop" = type { %"class.v8::TryCatch"*, %"class.v8::internal::Isolate"*, %"class.v8::internal::Context", %"struct.std::__1::atomic", %"class.v8::internal::Object", %"class.v8::internal::Context", i64, i64, i64, i64, i64, %"class.v8::internal::Object", i8, i8, %"class.v8::internal::Object", i64, i64, i64, %"class.v8::internal::PromiseOnStack"*, %"class.v8::internal::Simulator"*, i64, %"class.v8::internal::ExternalCallbackScope"*, i32, void (%"class.v8::Object"*, i32, %"class.v8::Value"*)*, i64 }
%"class.v8::TryCatch" = type <{ %"class.v8::internal::Isolate"*, %"class.v8::TryCatch"*, i8*, i8*, i8*, i8, [7 x i8] }>
%"struct.std::__1::atomic" = type { %"struct.std::__1::__atomic_base" }
%"struct.std::__1::__atomic_base" = type { %"struct.std::__1::__cxx_atomic_impl" }
%"struct.std::__1::__cxx_atomic_impl" = type { %"struct.std::__1::__cxx_atomic_base_impl" }
%"struct.std::__1::__cxx_atomic_base_impl" = type { %"class.v8::internal::ThreadId" }
%"class.v8::internal::ThreadId" = type { i32 }
%"class.v8::internal::Context" = type { %"class.v8::internal::TorqueGeneratedContext" }
%"class.v8::internal::TorqueGeneratedContext" = type { %"class.v8::internal::HeapObject" }
%"class.v8::internal::PromiseOnStack" = type { %"class.v8::internal::Handle", %"class.v8::internal::PromiseOnStack"* }
%"class.v8::internal::Handle" = type { %"class.v8::internal::HandleBase" }
%"class.v8::internal::HandleBase" = type { i64* }
%"class.v8::internal::Simulator" = type opaque
%"class.v8::internal::ExternalCallbackScope" = type opaque
%"class.v8::Object" = type { i8 }
%"class.v8::Value" = type { i8 }
%"class.std::__1::unique_ptr" = type { %"class.std::__1::__compressed_pair" }
%"class.std::__1::__compressed_pair" = type { %"struct.std::__1::__compressed_pair_elem" }
%"struct.std::__1::__compressed_pair_elem" = type { %"class.v8::internal::IsolateAllocator"* }
%"class.v8::internal::IsolateAllocator" = type { i8*, %"class.v8::PageAllocator"* }
%"class.v8::PageAllocator" = type { i32 (...)** }
%"class.std::__1::shared_ptr.645" = type { %"class.v8::internal::ReadOnlyArtifacts"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::ReadOnlyArtifacts" = type { i32 (...)**, %"class.std::__1::vector.139", %"class.v8::internal::AllocationStats", %"class.std::__1::unique_ptr.646", %"class.std::__1::unique_ptr.660" }
%"class.std::__1::unique_ptr.646" = type { %"class.std::__1::__compressed_pair.647" }
%"class.std::__1::__compressed_pair.647" = type { %"struct.std::__1::__compressed_pair_elem.648" }
%"struct.std::__1::__compressed_pair_elem.648" = type { %"class.v8::internal::SharedReadOnlySpace"* }
%"class.v8::internal::SharedReadOnlySpace" = type { %"class.v8::internal::ReadOnlySpace", %"class.std::__1::vector.649" }
%"class.std::__1::vector.649" = type { %"class.std::__1::__vector_base.650" }
%"class.std::__1::__vector_base.650" = type { %"class.std::__1::unique_ptr.651"*, %"class.std::__1::unique_ptr.651"*, %"class.std::__1::__compressed_pair.652" }
%"class.std::__1::unique_ptr.651" = type { %"class.std::__1::__compressed_pair.1153" }
%"class.std::__1::__compressed_pair.1153" = type { %"struct.std::__1::__compressed_pair_elem.1154" }
%"struct.std::__1::__compressed_pair_elem.1154" = type { %"class.v8::PageAllocator::SharedMemoryMapping"* }
%"class.v8::PageAllocator::SharedMemoryMapping" = type { i32 (...)** }
%"class.std::__1::__compressed_pair.652" = type { %"struct.std::__1::__compressed_pair_elem.653" }
%"struct.std::__1::__compressed_pair_elem.653" = type { %"class.std::__1::unique_ptr.651"* }
%"class.std::__1::unique_ptr.660" = type { %"class.std::__1::__compressed_pair.661" }
%"class.std::__1::__compressed_pair.661" = type { %"struct.std::__1::__compressed_pair_elem.662" }
%"struct.std::__1::__compressed_pair_elem.662" = type { %"class.v8::internal::ReadOnlyHeap"* }
%"class.std::__1::__shared_weak_count" = type { %"class.std::__1::__shared_count", i64 }
%"class.std::__1::__shared_count" = type { i32 (...)**, i64 }
%"class.std::__1::unique_ptr.666" = type { %"class.std::__1::__compressed_pair.667" }
%"class.std::__1::__compressed_pair.667" = type { %"struct.std::__1::__compressed_pair_elem.668" }
%"struct.std::__1::__compressed_pair_elem.668" = type { %"class.v8::internal::StringTable"* }
%"class.v8::internal::StringTable" = type { %"struct.std::__1::atomic.669", %"class.v8::base::Mutex" }
%"struct.std::__1::atomic.669" = type { %"struct.std::__1::__atomic_base.670" }
%"struct.std::__1::__atomic_base.670" = type { %"struct.std::__1::__cxx_atomic_impl.671" }
%"struct.std::__1::__cxx_atomic_impl.671" = type { %"struct.std::__1::__cxx_atomic_base_impl.672" }
%"struct.std::__1::__cxx_atomic_base_impl.672" = type { %"class.v8::internal::StringTable::Data"* }
%"class.v8::internal::StringTable::Data" = type opaque
%"class.v8::internal::Isolate::EntryStackItem" = type { i32, %"class.v8::internal::Isolate::PerIsolateThreadData"*, %"class.v8::internal::Isolate"*, %"class.v8::internal::Isolate::EntryStackItem"* }
%"class.v8::internal::Isolate::PerIsolateThreadData" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::ThreadId", i64, %"class.v8::internal::ThreadState"* }
%"class.v8::internal::ThreadState" = type opaque
%"class.v8::internal::StringStream" = type opaque
%"class.v8::internal::Bootstrapper" = type { %"class.v8::internal::Isolate"*, i32, %"class.v8::internal::SourceCodeCache" }
%"class.v8::internal::SourceCodeCache" = type { i32, %"class.v8::internal::FixedArray" }
%"class.v8::internal::FixedArray" = type { %"class.v8::internal::TorqueGeneratedFixedArray" }
%"class.v8::internal::TorqueGeneratedFixedArray" = type { %"class.v8::internal::FixedArrayBase" }
%"class.v8::internal::FixedArrayBase" = type { %"class.v8::internal::TorqueGeneratedFixedArrayBase" }
%"class.v8::internal::TorqueGeneratedFixedArrayBase" = type { %"class.v8::internal::HeapObject" }
%"class.v8::internal::RuntimeProfiler" = type opaque
%"class.v8::internal::CompilationCache" = type opaque
%"class.std::__1::shared_ptr.676" = type { %"class.v8::internal::Counters"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::Counters" = type { %"class.std::__1::enable_shared_from_this", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::HistogramTimer", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::TimedHistogram", %"class.v8::internal::AggregatableHistogramTimer", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::Histogram", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounterThreadSafe", %"class.v8::internal::StatsCounterThreadSafe", %"class.v8::internal::StatsCounterThreadSafe", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::StatsCounter", %"class.v8::internal::RuntimeCallStats", %"class.v8::internal::WorkerThreadRuntimeCallStats", %"class.v8::internal::Isolate"*, %"class.v8::internal::StatsTable" }
%"class.std::__1::enable_shared_from_this" = type { %"class.std::__1::weak_ptr" }
%"class.std::__1::weak_ptr" = type { %"class.v8::internal::Counters"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::HistogramTimer" = type { %"class.v8::internal::TimedHistogram.base", %"class.v8::base::ElapsedTimer" }
%"class.v8::internal::TimedHistogram.base" = type <{ %"class.v8::internal::Histogram", i32 }>
%"class.v8::base::ElapsedTimer" = type { %"class.v8::base::TimeTicks" }
%"class.v8::base::TimeTicks" = type { %"class.v8::base::time_internal::TimeBase" }
%"class.v8::base::time_internal::TimeBase" = type { i64 }
%"class.v8::internal::TimedHistogram" = type <{ %"class.v8::internal::Histogram", i32, [4 x i8] }>
%"class.v8::internal::AggregatableHistogramTimer" = type { %"class.v8::internal::Histogram", %"class.v8::base::TimeDelta" }
%"class.v8::base::TimeDelta" = type { i64 }
%"class.v8::internal::Histogram" = type { i8*, i32, i32, i32, i8*, %"class.v8::internal::Counters"* }
%"class.v8::internal::StatsCounterThreadSafe" = type { %"class.v8::internal::StatsCounterBase", %"class.v8::base::Mutex" }
%"class.v8::internal::StatsCounterBase" = type { %"class.v8::internal::Counters"*, i8*, i32* }
%"class.v8::internal::StatsCounter" = type <{ %"class.v8::internal::StatsCounterBase", i8, [7 x i8] }>
%"class.v8::internal::RuntimeCallStats" = type { %"class.v8::base::AtomicValue", %"class.v8::base::AtomicValue.677", i8, i32, %"class.v8::internal::ThreadId", [1370 x %"class.v8::internal::RuntimeCallCounter"] }
%"class.v8::base::AtomicValue" = type { i64 }
%"class.v8::base::AtomicValue.677" = type { i64 }
%"class.v8::internal::RuntimeCallCounter" = type { i8*, i64, i64 }
%"class.v8::internal::WorkerThreadRuntimeCallStats" = type <{ %"class.v8::base::Mutex", %"class.std::__1::vector.678", %"class.v8::base::Optional", %"class.v8::internal::ThreadId", [4 x i8] }>
%"class.std::__1::vector.678" = type { %"class.std::__1::__vector_base.679" }
%"class.std::__1::__vector_base.679" = type { %"class.std::__1::unique_ptr.680"*, %"class.std::__1::unique_ptr.680"*, %"class.std::__1::__compressed_pair.681" }
%"class.std::__1::unique_ptr.680" = type opaque
%"class.std::__1::__compressed_pair.681" = type { %"struct.std::__1::__compressed_pair_elem.682" }
%"struct.std::__1::__compressed_pair_elem.682" = type { %"class.std::__1::unique_ptr.680"* }
%"class.v8::base::Optional" = type { %"class.v8::base::internal::OptionalBase" }
%"class.v8::base::internal::OptionalBase" = type { %"struct.v8::base::internal::OptionalStorage" }
%"struct.v8::base::internal::OptionalStorage" = type { %"struct.v8::base::internal::OptionalStorageBase" }
%"struct.v8::base::internal::OptionalStorageBase" = type { i8, %union.anon }
%union.anon = type { i32 }
%"class.v8::internal::StatsTable" = type { i32* (i8*)*, i8* (i8*, i32, i32, i64)*, void (i8*, i32)* }
%"class.v8::base::RecursiveMutex" = type { %union.pthread_mutex_t }
%union.pthread_mutex_t = type { %struct.__pthread_mutex_s }
%struct.__pthread_mutex_s = type { i32, i32, i32, i32, i32, i16, i16, %struct.__pthread_internal_list }
%struct.__pthread_internal_list = type { %struct.__pthread_internal_list*, %struct.__pthread_internal_list* }
%"class.v8::internal::Logger" = type { %"class.v8::internal::CodeEventListener", %"class.v8::internal::Isolate"*, %"class.std::__1::unique_ptr.686", %"class.std::__1::unique_ptr.692", %"struct.std::__1::atomic.152", %"class.std::__1::unique_ptr.698", %"class.std::__1::unique_ptr.704", %"class.std::__1::unique_ptr.710", %"class.std::__1::unique_ptr.716", %"class.std::__1::unique_ptr.722", %"class.std::__1::set.728", i32, i8, %"class.v8::internal::ExistingCodeLogger", %"class.v8::base::ElapsedTimer" }
%"class.v8::internal::CodeEventListener" = type { i32 (...)** }
%"class.std::__1::unique_ptr.686" = type { %"class.std::__1::__compressed_pair.687" }
%"class.std::__1::__compressed_pair.687" = type { %"struct.std::__1::__compressed_pair_elem.688" }
%"struct.std::__1::__compressed_pair_elem.688" = type { %"class.v8::internal::Ticker"* }
%"class.v8::internal::Ticker" = type opaque
%"class.std::__1::unique_ptr.692" = type { %"class.std::__1::__compressed_pair.693" }
%"class.std::__1::__compressed_pair.693" = type { %"struct.std::__1::__compressed_pair_elem.694" }
%"struct.std::__1::__compressed_pair_elem.694" = type { %"class.v8::internal::Profiler"* }
%"class.v8::internal::Profiler" = type opaque
%"class.std::__1::unique_ptr.698" = type { %"class.std::__1::__compressed_pair.699" }
%"class.std::__1::__compressed_pair.699" = type { %"struct.std::__1::__compressed_pair_elem.700" }
%"struct.std::__1::__compressed_pair_elem.700" = type { %"class.v8::internal::Log"* }
%"class.v8::internal::Log" = type opaque
%"class.std::__1::unique_ptr.704" = type { %"class.std::__1::__compressed_pair.705" }
%"class.std::__1::__compressed_pair.705" = type { %"struct.std::__1::__compressed_pair_elem.706" }
%"struct.std::__1::__compressed_pair_elem.706" = type { %"class.v8::internal::PerfBasicLogger"* }
%"class.v8::internal::PerfBasicLogger" = type opaque
%"class.std::__1::unique_ptr.710" = type { %"class.std::__1::__compressed_pair.711" }
%"class.std::__1::__compressed_pair.711" = type { %"struct.std::__1::__compressed_pair_elem.712" }
%"struct.std::__1::__compressed_pair_elem.712" = type { %"class.v8::internal::PerfJitLogger"* }
%"class.v8::internal::PerfJitLogger" = type opaque
%"class.std::__1::unique_ptr.716" = type { %"class.std::__1::__compressed_pair.717" }
%"class.std::__1::__compressed_pair.717" = type { %"struct.std::__1::__compressed_pair_elem.718" }
%"struct.std::__1::__compressed_pair_elem.718" = type { %"class.v8::internal::LowLevelLogger"* }
%"class.v8::internal::LowLevelLogger" = type opaque
%"class.std::__1::unique_ptr.722" = type { %"class.std::__1::__compressed_pair.723" }
%"class.std::__1::__compressed_pair.723" = type { %"struct.std::__1::__compressed_pair_elem.724" }
%"struct.std::__1::__compressed_pair_elem.724" = type { %"class.v8::internal::JitLogger"* }
%"class.v8::internal::JitLogger" = type opaque
%"class.std::__1::set.728" = type { %"class.std::__1::__tree.729" }
%"class.std::__1::__tree.729" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair.730", %"class.std::__1::__compressed_pair.734" }
%"class.std::__1::__tree_end_node" = type { %"class.std::__1::__tree_node_base"* }
%"class.std::__1::__tree_node_base" = type <{ %"class.std::__1::__tree_end_node", %"class.std::__1::__tree_node_base"*, %"class.std::__1::__tree_end_node"*, i8, [7 x i8] }>
%"class.std::__1::__compressed_pair.730" = type { %"struct.std::__1::__compressed_pair_elem.80" }
%"struct.std::__1::__compressed_pair_elem.80" = type { %"class.std::__1::__tree_end_node" }
%"class.std::__1::__compressed_pair.734" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.v8::internal::ExistingCodeLogger" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::CodeEventListener"* }
%"class.v8::internal::StubCache" = type { [2048 x %"struct.v8::internal::StubCache::Entry"], [512 x %"struct.v8::internal::StubCache::Entry"], %"class.v8::internal::Isolate"* }
%"struct.v8::internal::StubCache::Entry" = type { %"class.v8::internal::StrongTaggedValue", %"class.v8::internal::TaggedValue", %"class.v8::internal::StrongTaggedValue" }
%"class.v8::internal::TaggedValue" = type { %"class.v8::internal::TaggedImpl.737" }
%"class.v8::internal::TaggedImpl.737" = type { i32 }
%"class.v8::internal::StrongTaggedValue" = type { %"class.v8::internal::TaggedImpl.736" }
%"class.v8::internal::TaggedImpl.736" = type { i32 }
%"class.v8::internal::Deoptimizer" = type opaque
%"class.v8::internal::MaterializedObjectStore" = type opaque
%"class.v8::internal::DescriptorLookupCache" = type { [64 x %"struct.v8::internal::DescriptorLookupCache::Key"], [64 x i32] }
%"struct.v8::internal::DescriptorLookupCache::Key" = type { %"class.v8::internal::Map", %"class.v8::internal::Name" }
%"class.v8::internal::Map" = type { %"class.v8::internal::HeapObject" }
%"class.v8::internal::Name" = type { %"class.v8::internal::TorqueGeneratedName" }
%"class.v8::internal::TorqueGeneratedName" = type { %"class.v8::internal::PrimitiveHeapObject" }
%"class.v8::internal::PrimitiveHeapObject" = type { %"class.v8::internal::TorqueGeneratedPrimitiveHeapObject" }
%"class.v8::internal::TorqueGeneratedPrimitiveHeapObject" = type { %"class.v8::internal::HeapObject" }
%"struct.v8::internal::HandleScopeData" = type { i64*, i64*, i32, i32, %"class.v8::internal::CanonicalHandleScope"* }
%"class.v8::internal::CanonicalHandleScope" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::OptimizedCompilationInfo"*, %"class.v8::internal::Zone"*, %"class.v8::internal::RootIndexMap"*, %"class.std::__1::unique_ptr.744", i32, %"class.v8::internal::CanonicalHandleScope"* }
%"class.v8::internal::OptimizedCompilationInfo" = type opaque
%"class.v8::internal::RootIndexMap" = type opaque
%"class.std::__1::unique_ptr.744" = type { %"class.std::__1::__compressed_pair.745" }
%"class.std::__1::__compressed_pair.745" = type { %"struct.std::__1::__compressed_pair_elem.746" }
%"struct.std::__1::__compressed_pair_elem.746" = type { %"class.v8::internal::IdentityMap"* }
%"class.v8::internal::IdentityMap" = type opaque
%"class.v8::internal::HandleScopeImplementer" = type { %"class.v8::internal::Isolate"*, %"class.v8::internal::DetachableVector", %"class.v8::internal::DetachableVector.750", %"class.v8::internal::DetachableVector.751", %"class.v8::internal::DetachableVector.750", i64*, i64*, %"struct.v8::internal::HandleScopeData" }
%"class.v8::internal::DetachableVector" = type { %"class.v8::internal::DetachableVectorBase" }
%"class.v8::internal::DetachableVectorBase" = type { i8*, i64, i64 }
%"class.v8::internal::DetachableVector.751" = type { %"class.v8::internal::DetachableVectorBase" }
%"class.v8::internal::DetachableVector.750" = type { %"class.v8::internal::DetachableVectorBase" }
%"class.v8::internal::UnicodeCache" = type opaque
%"class.v8::internal::AccountingAllocator" = type { i32 (...)**, %"struct.std::__1::atomic.19", %"struct.std::__1::atomic.19", %"class.std::__1::unique_ptr.738", %"class.std::__1::unique_ptr.481" }
%"class.std::__1::unique_ptr.738" = type { %"class.std::__1::__compressed_pair.739" }
%"class.std::__1::__compressed_pair.739" = type { %"struct.std::__1::__compressed_pair_elem.740" }
%"struct.std::__1::__compressed_pair_elem.740" = type { %"class.v8::internal::VirtualMemory"* }
%"class.v8::internal::VirtualMemory" = type { %"class.v8::PageAllocator"*, %"class.v8::base::AddressRegion" }
%"class.v8::base::AddressRegion" = type { i64, i64 }
%"class.std::__1::unique_ptr.481" = type { %"class.std::__1::__compressed_pair.482" }
%"class.std::__1::__compressed_pair.482" = type { %"struct.std::__1::__compressed_pair_elem.483" }
%"struct.std::__1::__compressed_pair_elem.483" = type { %"class.v8::base::BoundedPageAllocator"* }
%"class.v8::base::BoundedPageAllocator" = type { %"class.v8::PageAllocator", %"class.v8::base::Mutex", i64, i64, %"class.v8::PageAllocator"*, %"class.v8::base::RegionAllocator" }
%"class.v8::base::RegionAllocator" = type { %"class.v8::base::RegionAllocator::Region", i64, i64, i64, i64, %"class.std::__1::set.484", %"class.std::__1::set.492" }
%"class.v8::base::RegionAllocator::Region" = type <{ %"class.v8::base::AddressRegion", i32, [4 x i8] }>
%"class.std::__1::set.484" = type { %"class.std::__1::__tree.485" }
%"class.std::__1::__tree.485" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair.486", %"class.std::__1::__compressed_pair.490" }
%"class.std::__1::__compressed_pair.486" = type { %"struct.std::__1::__compressed_pair_elem.80" }
%"class.std::__1::__compressed_pair.490" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::set.492" = type { %"class.std::__1::__tree.493" }
%"class.std::__1::__tree.493" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair.486", %"class.std::__1::__compressed_pair.494" }
%"class.std::__1::__compressed_pair.494" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.v8::internal::InnerPointerToCodeCache" = type opaque
%"class.v8::internal::GlobalHandles" = type { %"class.v8::internal::Isolate"*, %"class.std::__1::unique_ptr.752", %"class.std::__1::vector.758", %"class.std::__1::unique_ptr.765", %"class.std::__1::vector.772", %"class.std::__1::unique_ptr.779", i64, %"class.std::__1::vector.785", %"class.std::__1::vector.793", %"class.std::__1::vector.801", i8, i8, i32 }
%"class.std::__1::unique_ptr.752" = type { %"class.std::__1::__compressed_pair.753" }
%"class.std::__1::__compressed_pair.753" = type { %"struct.std::__1::__compressed_pair_elem.754" }
%"struct.std::__1::__compressed_pair_elem.754" = type { %"class.v8::internal::GlobalHandles::NodeSpace"* }
%"class.v8::internal::GlobalHandles::NodeSpace" = type opaque
%"class.std::__1::vector.758" = type { %"class.std::__1::__vector_base.759" }
%"class.std::__1::__vector_base.759" = type { %"class.v8::internal::GlobalHandles::Node"**, %"class.v8::internal::GlobalHandles::Node"**, %"class.std::__1::__compressed_pair.760" }
%"class.v8::internal::GlobalHandles::Node" = type opaque
%"class.std::__1::__compressed_pair.760" = type { %"struct.std::__1::__compressed_pair_elem.761" }
%"struct.std::__1::__compressed_pair_elem.761" = type { %"class.v8::internal::GlobalHandles::Node"** }
%"class.std::__1::unique_ptr.765" = type { %"class.std::__1::__compressed_pair.766" }
%"class.std::__1::__compressed_pair.766" = type { %"struct.std::__1::__compressed_pair_elem.767" }
%"struct.std::__1::__compressed_pair_elem.767" = type { %"class.v8::internal::GlobalHandles::NodeSpace.768"* }
%"class.v8::internal::GlobalHandles::NodeSpace.768" = type opaque
%"class.std::__1::vector.772" = type { %"class.std::__1::__vector_base.773" }
%"class.std::__1::__vector_base.773" = type { %"class.v8::internal::GlobalHandles::TracedNode"**, %"class.v8::internal::GlobalHandles::TracedNode"**, %"class.std::__1::__compressed_pair.774" }
%"class.v8::internal::GlobalHandles::TracedNode" = type opaque
%"class.std::__1::__compressed_pair.774" = type { %"struct.std::__1::__compressed_pair_elem.775" }
%"struct.std::__1::__compressed_pair_elem.775" = type { %"class.v8::internal::GlobalHandles::TracedNode"** }
%"class.std::__1::unique_ptr.779" = type { %"class.std::__1::__compressed_pair.780" }
%"class.std::__1::__compressed_pair.780" = type { %"struct.std::__1::__compressed_pair_elem.781" }
%"struct.std::__1::__compressed_pair_elem.781" = type { %"class.v8::internal::GlobalHandles::OnStackTracedNodeSpace"* }
%"class.v8::internal::GlobalHandles::OnStackTracedNodeSpace" = type opaque
%"class.std::__1::vector.785" = type { %"class.std::__1::__vector_base.786" }
%"class.std::__1::__vector_base.786" = type { %"struct.std::__1::pair.787"*, %"struct.std::__1::pair.787"*, %"class.std::__1::__compressed_pair.788" }
%"struct.std::__1::pair.787" = type opaque
%"class.std::__1::__compressed_pair.788" = type { %"struct.std::__1::__compressed_pair_elem.789" }
%"struct.std::__1::__compressed_pair_elem.789" = type { %"struct.std::__1::pair.787"* }
%"class.std::__1::vector.793" = type { %"class.std::__1::__vector_base.794" }
%"class.std::__1::__vector_base.794" = type { %"struct.std::__1::pair.795"*, %"struct.std::__1::pair.795"*, %"class.std::__1::__compressed_pair.796" }
%"struct.std::__1::pair.795" = type opaque
%"class.std::__1::__compressed_pair.796" = type { %"struct.std::__1::__compressed_pair_elem.797" }
%"struct.std::__1::__compressed_pair_elem.797" = type { %"struct.std::__1::pair.795"* }
%"class.std::__1::vector.801" = type { %"class.std::__1::__vector_base.802" }
%"class.std::__1::__vector_base.802" = type { %"class.v8::internal::GlobalHandles::PendingPhantomCallback"*, %"class.v8::internal::GlobalHandles::PendingPhantomCallback"*, %"class.std::__1::__compressed_pair.803" }
%"class.v8::internal::GlobalHandles::PendingPhantomCallback" = type { void (%"class.v8::WeakCallbackInfo"*)*, i8*, [2 x i8*] }
%"class.v8::WeakCallbackInfo" = type { %"class.v8::Isolate"*, i8*, {}**, [2 x i8*] }
%"class.v8::Isolate" = type { i8 }
%"class.std::__1::__compressed_pair.803" = type { %"struct.std::__1::__compressed_pair_elem.804" }
%"struct.std::__1::__compressed_pair_elem.804" = type { %"class.v8::internal::GlobalHandles::PendingPhantomCallback"* }
%"class.v8::internal::EternalHandles" = type { i32, %"class.std::__1::vector.808", %"class.std::__1::vector.815" }
%"class.std::__1::vector.808" = type { %"class.std::__1::__vector_base.809" }
%"class.std::__1::__vector_base.809" = type { i64**, i64**, %"class.std::__1::__compressed_pair.810" }
%"class.std::__1::__compressed_pair.810" = type { %"struct.std::__1::__compressed_pair_elem.811" }
%"struct.std::__1::__compressed_pair_elem.811" = type { i64** }
%"class.v8::internal::ThreadManager" = type opaque
%"class.v8::bigint::Processor" = type opaque
%"class.v8::internal::RuntimeState" = type { %"class.std::__1::unique_ptr.822" }
%"class.std::__1::unique_ptr.822" = type { %"class.std::__1::__compressed_pair.823" }
%"class.std::__1::__compressed_pair.823" = type { %"struct.std::__1::__compressed_pair_elem.824" }
%"struct.std::__1::__compressed_pair_elem.824" = type { %"struct.v8::internal::Runtime::Function"* }
%"struct.v8::internal::Runtime::Function" = type { i32, i32, i8*, i64, i8, i8 }
%"class.v8::internal::Builtins" = type { %"class.v8::internal::Isolate"*, i8, i32 }
%"class.v8::internal::SetupIsolateDelegate" = type opaque
%"class.v8::internal::RegExpStack" = type opaque
%"class.std::__1::vector.815" = type { %"class.std::__1::__vector_base.816" }
%"class.std::__1::__vector_base.816" = type { i32*, i32*, %"class.std::__1::__compressed_pair.817" }
%"class.std::__1::__compressed_pair.817" = type { %"struct.std::__1::__compressed_pair_elem.818" }
%"struct.std::__1::__compressed_pair_elem.818" = type { i32* }
%"class.v8::internal::DateCache" = type opaque
%"class.v8::base::RandomNumberGenerator" = type { i64, i64, i64 }
%"struct.std::__1::atomic.828" = type { %"struct.std::__1::__atomic_base.829" }
%"struct.std::__1::__atomic_base.829" = type { %"struct.std::__1::__cxx_atomic_impl.830" }
%"struct.std::__1::__cxx_atomic_impl.830" = type { %"struct.std::__1::__cxx_atomic_base_impl.831" }
%"struct.std::__1::__cxx_atomic_base_impl.831" = type { i32 }
%"class.v8::Promise" = type { i8 }
%"struct.std::__1::atomic.838" = type { %"struct.std::__1::__atomic_base.839" }
%"struct.std::__1::__atomic_base.839" = type { %"struct.std::__1::__cxx_atomic_impl.840" }
%"struct.std::__1::__cxx_atomic_impl.840" = type { %"struct.std::__1::__cxx_atomic_base_impl.841" }
%"struct.std::__1::__cxx_atomic_base_impl.841" = type { i32 }
%"class.std::__1::basic_string" = type { %"class.std::__1::__compressed_pair.843" }
%"class.std::__1::__compressed_pair.843" = type { %"struct.std::__1::__compressed_pair_elem.844" }
%"struct.std::__1::__compressed_pair_elem.844" = type { %"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep" }
%"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__rep" = type { %union.anon.845 }
%union.anon.845 = type { %"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__long" }
%"struct.std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::__long" = type { i8*, i64, i64 }
%"class.std::__1::unordered_map.849" = type { %"class.std::__1::__hash_table.850" }
%"class.std::__1::__hash_table.850" = type <{ %"class.std::__1::unique_ptr.851", %"class.std::__1::__compressed_pair.861", %"class.std::__1::__compressed_pair.866", %"class.std::__1::__compressed_pair.869", [4 x i8] }>
%"class.std::__1::unique_ptr.851" = type { %"class.std::__1::__compressed_pair.852" }
%"class.std::__1::__compressed_pair.852" = type { %"struct.std::__1::__compressed_pair_elem.853", %"struct.std::__1::__compressed_pair_elem.855" }
%"struct.std::__1::__compressed_pair_elem.853" = type { %"struct.std::__1::__hash_node_base.854"** }
%"struct.std::__1::__hash_node_base.854" = type { %"struct.std::__1::__hash_node_base.854"* }
%"struct.std::__1::__compressed_pair_elem.855" = type { %"class.std::__1::__bucket_list_deallocator.856" }
%"class.std::__1::__bucket_list_deallocator.856" = type { %"class.std::__1::__compressed_pair.857" }
%"class.std::__1::__compressed_pair.857" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.861" = type { %"struct.std::__1::__compressed_pair_elem.862" }
%"struct.std::__1::__compressed_pair_elem.862" = type { %"struct.std::__1::__hash_node_base.854" }
%"class.std::__1::__compressed_pair.866" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.869" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"struct.std::__1::atomic.152" = type { %"struct.std::__1::__atomic_base.153" }
%"struct.std::__1::__atomic_base.153" = type { %"struct.std::__1::__cxx_atomic_impl.154" }
%"struct.std::__1::__cxx_atomic_impl.154" = type { %"struct.std::__1::__cxx_atomic_base_impl.155" }
%"struct.std::__1::__cxx_atomic_base_impl.155" = type { i8 }
%"class.v8::internal::Debug" = type { %"class.v8::debug::DebugDelegate"*, i8, i8, i8, i8, i8, i8, i8, i8, i8, %"class.v8::internal::DebugInfoListNode"*, %"class.std::__1::unique_ptr.875", %"class.v8::internal::Handle.881", %"class.v8::internal::DebugFeatureTracker", %"class.v8::internal::Debug::ThreadLocal", %"class.v8::internal::Handle.882", %"class.v8::internal::Isolate"* }
%"class.v8::debug::DebugDelegate" = type { i32 (...)** }
%"class.v8::internal::DebugInfoListNode" = type { i64*, %"class.v8::internal::DebugInfoListNode"* }
%"class.std::__1::unique_ptr.875" = type { %"class.std::__1::__compressed_pair.876" }
%"class.std::__1::__compressed_pair.876" = type { %"struct.std::__1::__compressed_pair_elem.877" }
%"struct.std::__1::__compressed_pair_elem.877" = type { %"class.v8::internal::Debug::TemporaryObjectsTracker"* }
%"class.v8::internal::Debug::TemporaryObjectsTracker" = type opaque
%"class.v8::internal::Handle.881" = type { %"class.v8::internal::HandleBase" }
%"class.v8::internal::DebugFeatureTracker" = type <{ %"class.v8::internal::Isolate"*, i32, [4 x i8] }>
%"class.v8::internal::Debug::ThreadLocal" = type <{ i64, i32, i8, [3 x i8], %"class.v8::internal::Object", i8, [3 x i8], i32, i32, i32, %"class.v8::internal::Object", %"class.v8::internal::Object", i32, i8, [3 x i8] }>
%"class.v8::internal::Handle.882" = type { %"class.v8::internal::HandleBase" }
%"class.v8::internal::HeapProfiler" = type { %"class.v8::internal::HeapObjectAllocationTracker", %"class.std::__1::unique_ptr.883", %"class.std::__1::vector.889", %"class.std::__1::unique_ptr.897", %"class.std::__1::unique_ptr.903", i8, i8, %"class.v8::base::Mutex", %"class.std::__1::unique_ptr.909", %"class.std::__1::vector.915", %"struct.std::__1::pair.923" }
%"class.v8::internal::HeapObjectAllocationTracker" = type { i32 (...)** }
%"class.std::__1::unique_ptr.883" = type { %"class.std::__1::__compressed_pair.884" }
%"class.std::__1::__compressed_pair.884" = type { %"struct.std::__1::__compressed_pair_elem.885" }
%"struct.std::__1::__compressed_pair_elem.885" = type { %"class.v8::internal::HeapObjectsMap"* }
%"class.v8::internal::HeapObjectsMap" = type opaque
%"class.std::__1::vector.889" = type { %"class.std::__1::__vector_base.890" }
%"class.std::__1::__vector_base.890" = type { %"class.std::__1::unique_ptr.891"*, %"class.std::__1::unique_ptr.891"*, %"class.std::__1::__compressed_pair.892" }
%"class.std::__1::unique_ptr.891" = type opaque
%"class.std::__1::__compressed_pair.892" = type { %"struct.std::__1::__compressed_pair_elem.893" }
%"struct.std::__1::__compressed_pair_elem.893" = type { %"class.std::__1::unique_ptr.891"* }
%"class.std::__1::unique_ptr.897" = type { %"class.std::__1::__compressed_pair.898" }
%"class.std::__1::__compressed_pair.898" = type { %"struct.std::__1::__compressed_pair_elem.899" }
%"struct.std::__1::__compressed_pair_elem.899" = type { %"class.v8::internal::StringsStorage"* }
%"class.v8::internal::StringsStorage" = type opaque
%"class.std::__1::unique_ptr.903" = type { %"class.std::__1::__compressed_pair.904" }
%"class.std::__1::__compressed_pair.904" = type { %"struct.std::__1::__compressed_pair_elem.905" }
%"struct.std::__1::__compressed_pair_elem.905" = type { %"class.v8::internal::AllocationTracker"* }
%"class.v8::internal::AllocationTracker" = type opaque
%"class.std::__1::unique_ptr.909" = type { %"class.std::__1::__compressed_pair.910" }
%"class.std::__1::__compressed_pair.910" = type { %"struct.std::__1::__compressed_pair_elem.911" }
%"struct.std::__1::__compressed_pair_elem.911" = type { %"class.v8::internal::SamplingHeapProfiler"* }
%"class.v8::internal::SamplingHeapProfiler" = type opaque
%"class.std::__1::vector.915" = type { %"class.std::__1::__vector_base.916" }
%"class.std::__1::__vector_base.916" = type { %"struct.std::__1::pair.917"*, %"struct.std::__1::pair.917"*, %"class.std::__1::__compressed_pair.918" }
%"struct.std::__1::pair.917" = type opaque
%"class.std::__1::__compressed_pair.918" = type { %"struct.std::__1::__compressed_pair_elem.919" }
%"struct.std::__1::__compressed_pair_elem.919" = type { %"struct.std::__1::pair.917"* }
%"struct.std::__1::pair.923" = type { i8 (%"class.v8::Isolate"*, %"class.v8::Local.0"*, i16, i8*)*, i8* }
%"class.v8::Local.0" = type { %"class.v8::Value"* }
%"class.std::__1::unique_ptr.924" = type { %"class.std::__1::__compressed_pair.925" }
%"class.std::__1::__compressed_pair.925" = type { %"struct.std::__1::__compressed_pair_elem.926" }
%"struct.std::__1::__compressed_pair_elem.926" = type { %"class.v8::internal::CodeEventDispatcher"* }
%"class.v8::internal::CodeEventDispatcher" = type { %"class.v8::internal::CodeEventListener", %"class.std::__1::unordered_set.927", %"class.v8::base::Mutex" }
%"class.std::__1::unordered_set.927" = type { %"class.std::__1::__hash_table.928" }
%"class.std::__1::__hash_table.928" = type <{ %"class.std::__1::unique_ptr.929", %"class.std::__1::__compressed_pair.939", %"class.std::__1::__compressed_pair.944", %"class.std::__1::__compressed_pair.948", [4 x i8] }>
%"class.std::__1::unique_ptr.929" = type { %"class.std::__1::__compressed_pair.930" }
%"class.std::__1::__compressed_pair.930" = type { %"struct.std::__1::__compressed_pair_elem.931", %"struct.std::__1::__compressed_pair_elem.933" }
%"struct.std::__1::__compressed_pair_elem.931" = type { %"struct.std::__1::__hash_node_base.932"** }
%"struct.std::__1::__hash_node_base.932" = type { %"struct.std::__1::__hash_node_base.932"* }
%"struct.std::__1::__compressed_pair_elem.933" = type { %"class.std::__1::__bucket_list_deallocator.934" }
%"class.std::__1::__bucket_list_deallocator.934" = type { %"class.std::__1::__compressed_pair.935" }
%"class.std::__1::__compressed_pair.935" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.939" = type { %"struct.std::__1::__compressed_pair_elem.940" }
%"struct.std::__1::__compressed_pair_elem.940" = type { %"struct.std::__1::__hash_node_base.932" }
%"class.std::__1::__compressed_pair.944" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.948" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.v8::internal::AstStringConstants" = type opaque
%"class.v8::internal::interpreter::Interpreter" = type opaque
%"class.v8::internal::compiler::PerIsolateCompilerCache" = type opaque
%"class.v8::internal::Zone" = type <{ i64, i64, i64, i64, %"class.v8::internal::AccountingAllocator"*, %"class.v8::internal::Segment"*, i8*, i8, i8, [6 x i8] }>
%"class.v8::internal::Segment" = type { %"class.v8::internal::Zone"*, %"class.v8::internal::Segment"*, i64 }
%"class.v8::internal::CompilerDispatcher" = type opaque
%"class.std::__1::queue" = type { %"class.std::__1::deque" }
%"class.std::__1::deque" = type { %"class.std::__1::__deque_base" }
%"class.std::__1::__deque_base" = type { %"struct.std::__1::__split_buffer", i64, %"class.std::__1::__compressed_pair.962" }
%"struct.std::__1::__split_buffer" = type { %"struct.std::__1::pair.956"**, %"struct.std::__1::pair.956"**, %"struct.std::__1::pair.956"**, %"class.std::__1::__compressed_pair.957" }
%"struct.std::__1::pair.956" = type opaque
%"class.std::__1::__compressed_pair.957" = type { %"struct.std::__1::__compressed_pair_elem.958" }
%"struct.std::__1::__compressed_pair_elem.958" = type { %"struct.std::__1::pair.956"** }
%"class.std::__1::__compressed_pair.962" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.v8::String" = type { i8 }
%"class.v8::Context" = type { i8 }
%"class.v8::FunctionCallbackInfo" = type <{ i64*, i64*, i32, [4 x i8] }>
%"class.v8::internal::Relocatable" = type { i32 (...)**, %"class.v8::internal::Isolate"*, %"class.v8::internal::Relocatable"* }
%"class.std::__1::vector.967" = type { %"class.std::__1::__vector_base.968" }
%"class.std::__1::__vector_base.968" = type { %"class.v8::internal::Handle.969"*, %"class.v8::internal::Handle.969"*, %"class.std::__1::__compressed_pair.970" }
%"class.v8::internal::Handle.969" = type { %"class.v8::internal::HandleBase" }
%"class.std::__1::__compressed_pair.970" = type { %"struct.std::__1::__compressed_pair_elem.971" }
%"struct.std::__1::__compressed_pair_elem.971" = type { %"class.v8::internal::Handle.969"* }
%"class.v8::internal::AddressToIndexHashMap" = type opaque
%"class.v8::internal::HeapObjectToIndexHashMap" = type opaque
%"class.v8::internal::MicrotaskQueue" = type opaque
%"class.v8::internal::CompilationStatistics" = type opaque
%"class.v8::internal::CodeTracer" = type <{ %"class.v8::internal::EmbeddedVector", %struct._IO_FILE*, i32, [4 x i8] }>
%"class.v8::internal::EmbeddedVector" = type { %"class.v8::internal::Vector", [128 x i8] }
%"class.v8::internal::Vector" = type { i8*, i64 }
%struct._IO_FILE = type { i32, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, i8*, %struct._IO_marker*, %struct._IO_FILE*, i32, i32, i64, i16, i8, [1 x i8], i8*, i64, %struct._IO_codecvt*, %struct._IO_wide_data*, %struct._IO_FILE*, i8*, i64, i32, [20 x i8] }
%struct._IO_marker = type opaque
%struct._IO_codecvt = type opaque
%struct._IO_wide_data = type opaque
%"class.v8::PromiseRejectMessage" = type { %"class.v8::Local.833", i32, %"class.v8::Local.0" }
%"class.v8::Local.833" = type { %"class.v8::Promise"* }
%"class.v8::StartupData" = type { i8*, i32 }
%"class.v8_inspector::V8Inspector" = type opaque
%"class.v8::internal::compiler::NodeObserver" = type opaque
%"class.v8::internal::OptimizingCompileDispatcher" = type opaque
%"class.std::__1::unique_ptr.975" = type { %"class.std::__1::__compressed_pair.976" }
%"class.std::__1::__compressed_pair.976" = type { %"struct.std::__1::__compressed_pair_elem.977" }
%"struct.std::__1::__compressed_pair_elem.977" = type { %"class.v8::internal::PersistentHandlesList"* }
%"class.v8::internal::PersistentHandlesList" = type { %"class.v8::base::Mutex", %"class.v8::internal::PersistentHandles"* }
%"class.v8::internal::PersistentHandles" = type { %"class.v8::internal::Isolate"*, %"class.std::__1::vector.808", i64*, i64*, %"class.v8::internal::PersistentHandles"*, %"class.v8::internal::PersistentHandles"* }
%"class.std::__1::vector.981" = type { %"class.std::__1::__vector_base.982" }
%"class.std::__1::__vector_base.982" = type { void (%"class.v8::Isolate"*)**, void (%"class.v8::Isolate"*)**, %"class.std::__1::__compressed_pair.983" }
%"class.std::__1::__compressed_pair.983" = type { %"struct.std::__1::__compressed_pair_elem.984" }
%"struct.std::__1::__compressed_pair_elem.984" = type { void (%"class.v8::Isolate"*)** }
%"class.std::__1::shared_ptr.988" = type { %"class.v8::internal::metrics::Recorder"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::metrics::Recorder" = type opaque
%"class.std::__1::unordered_map.989" = type { %"class.std::__1::__hash_table.990" }
%"class.std::__1::__hash_table.990" = type <{ %"class.std::__1::unique_ptr.991", %"class.std::__1::__compressed_pair.1001", %"class.std::__1::__compressed_pair.1006", %"class.std::__1::__compressed_pair.1009", [4 x i8] }>
%"class.std::__1::unique_ptr.991" = type { %"class.std::__1::__compressed_pair.992" }
%"class.std::__1::__compressed_pair.992" = type { %"struct.std::__1::__compressed_pair_elem.993", %"struct.std::__1::__compressed_pair_elem.995" }
%"struct.std::__1::__compressed_pair_elem.993" = type { %"struct.std::__1::__hash_node_base.994"** }
%"struct.std::__1::__hash_node_base.994" = type { %"struct.std::__1::__hash_node_base.994"* }
%"struct.std::__1::__compressed_pair_elem.995" = type { %"class.std::__1::__bucket_list_deallocator.996" }
%"class.std::__1::__bucket_list_deallocator.996" = type { %"class.std::__1::__compressed_pair.997" }
%"class.std::__1::__compressed_pair.997" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.1001" = type { %"struct.std::__1::__compressed_pair_elem.1002" }
%"struct.std::__1::__compressed_pair_elem.1002" = type { %"struct.std::__1::__hash_node_base.994" }
%"class.std::__1::__compressed_pair.1006" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.1009" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"struct.v8::metrics::LongTaskStats" = type { i64, i64, i64 }
%"class.v8::internal::BuiltinsConstantsTableBuilder" = type opaque
%"class.v8::ArrayBuffer::Allocator" = type { i32 (...)** }
%"class.std::__1::shared_ptr.160" = type { %"class.v8::ArrayBuffer::Allocator"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::FutexWaitListNode" = type { %"class.v8::internal::Isolate"*, %"class.std::__1::shared_ptr.1013", %"class.v8::internal::CancelableTaskManager"*, %"class.v8::base::ConditionVariable", %"class.v8::internal::FutexWaitListNode"*, %"class.v8::internal::FutexWaitListNode"*, %"class.std::__1::weak_ptr.1042", i64, i8*, i8, i8, %"class.v8::Global", %"class.v8::Global.1043", %"class.v8::base::TimeTicks", i64 }
%"class.std::__1::shared_ptr.1013" = type { %"class.v8::TaskRunner"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::TaskRunner" = type { i32 (...)** }
%"class.v8::base::ConditionVariable" = type { %union.pthread_cond_t }
%union.pthread_cond_t = type { %struct.__pthread_cond_s }
%struct.__pthread_cond_s = type { %union.anon.1038, %union.anon.1040, [2 x i32], [2 x i32], i32, i32, [2 x i32] }
%union.anon.1038 = type { i64 }
%union.anon.1040 = type { i64 }
%"class.std::__1::weak_ptr.1042" = type { %"class.v8::internal::BackingStore"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::BackingStore" = type <{ i8*, %"struct.std::__1::atomic.19", i64, %"union.v8::internal::BackingStore::TypeSpecificData", i16, [6 x i8] }>
%"union.v8::internal::BackingStore::TypeSpecificData" = type { %"class.std::__1::shared_ptr.160" }
%"class.v8::Global" = type { %"class.v8::PersistentBase" }
%"class.v8::PersistentBase" = type { %"class.v8::Promise"* }
%"class.v8::Global.1043" = type { %"class.v8::PersistentBase.1044" }
%"class.v8::PersistentBase.1044" = type { %"class.v8::Context"* }
%"class.v8::internal::CancelableTaskManager" = type <{ i64, %"class.std::__1::unordered_map.1014", %"class.v8::base::ConditionVariable", %"class.v8::base::Mutex", i8, [7 x i8] }>
%"class.std::__1::unordered_map.1014" = type { %"class.std::__1::__hash_table.1015" }
%"class.std::__1::__hash_table.1015" = type <{ %"class.std::__1::unique_ptr.1016", %"class.std::__1::__compressed_pair.1026", %"class.std::__1::__compressed_pair.1031", %"class.std::__1::__compressed_pair.1034", [4 x i8] }>
%"class.std::__1::unique_ptr.1016" = type { %"class.std::__1::__compressed_pair.1017" }
%"class.std::__1::__compressed_pair.1017" = type { %"struct.std::__1::__compressed_pair_elem.1018", %"struct.std::__1::__compressed_pair_elem.1020" }
%"struct.std::__1::__compressed_pair_elem.1018" = type { %"struct.std::__1::__hash_node_base.1019"** }
%"struct.std::__1::__hash_node_base.1019" = type { %"struct.std::__1::__hash_node_base.1019"* }
%"struct.std::__1::__compressed_pair_elem.1020" = type { %"class.std::__1::__bucket_list_deallocator.1021" }
%"class.std::__1::__bucket_list_deallocator.1021" = type { %"class.std::__1::__compressed_pair.1022" }
%"class.std::__1::__compressed_pair.1022" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.1026" = type { %"struct.std::__1::__compressed_pair_elem.1027" }
%"struct.std::__1::__compressed_pair_elem.1027" = type { %"struct.std::__1::__hash_node_base.1019" }
%"class.std::__1::__compressed_pair.1031" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.1034" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.v8::debug::ConsoleDelegate" = type { i32 (...)** }
%"class.v8::debug::AsyncEventDelegate" = type { i32 (...)** }
%"class.std::__1::unique_ptr.1045" = type { %"class.std::__1::__compressed_pair.1046" }
%"class.std::__1::__compressed_pair.1046" = type { %"struct.std::__1::__compressed_pair_elem.1047" }
%"struct.std::__1::__compressed_pair_elem.1047" = type { %"class.v8::internal::LocalIsolate"* }
%"class.v8::internal::LocalIsolate" = type { %"class.v8::internal::HiddenLocalFactory", %"class.v8::internal::LocalHeap", %"class.v8::internal::Isolate"*, %"class.std::__1::unique_ptr.1074", %"class.v8::internal::ThreadId", i64, %"class.v8::internal::RuntimeCallStats"* }
%"class.v8::internal::HiddenLocalFactory" = type { %"class.v8::internal::LocalFactory" }
%"class.v8::internal::LocalFactory" = type { %"class.v8::internal::ReadOnlyRoots" }
%"class.v8::internal::ReadOnlyRoots" = type { i64* }
%"class.v8::internal::LocalHeap" = type { %"class.v8::internal::Heap"*, i8, %"struct.std::__1::atomic.1050", i8, i8, %"class.v8::internal::LocalHeap"*, %"class.v8::internal::LocalHeap"*, %"class.std::__1::unique_ptr.1054", %"class.std::__1::unique_ptr.1060", %"class.std::__1::unique_ptr.474", %"class.std::__1::vector.1066", %"class.v8::internal::ConcurrentAllocator" }
%"struct.std::__1::atomic.1050" = type { %"struct.std::__1::__atomic_base.1051" }
%"struct.std::__1::__atomic_base.1051" = type { %"struct.std::__1::__cxx_atomic_impl.1052" }
%"struct.std::__1::__cxx_atomic_impl.1052" = type { %"struct.std::__1::__cxx_atomic_base_impl.1053" }
%"struct.std::__1::__cxx_atomic_base_impl.1053" = type { i32 }
%"class.std::__1::unique_ptr.1054" = type { %"class.std::__1::__compressed_pair.1055" }
%"class.std::__1::__compressed_pair.1055" = type { %"struct.std::__1::__compressed_pair_elem.1056" }
%"struct.std::__1::__compressed_pair_elem.1056" = type { %"class.v8::internal::LocalHandles"* }
%"class.v8::internal::LocalHandles" = type { %"struct.v8::internal::HandleScopeData", %"class.std::__1::vector.808" }
%"class.std::__1::unique_ptr.1060" = type { %"class.std::__1::__compressed_pair.1061" }
%"class.std::__1::__compressed_pair.1061" = type { %"struct.std::__1::__compressed_pair_elem.1062" }
%"struct.std::__1::__compressed_pair_elem.1062" = type { %"class.v8::internal::PersistentHandles"* }
%"class.std::__1::vector.1066" = type { %"class.std::__1::__vector_base.1067" }
%"class.std::__1::__vector_base.1067" = type { %"struct.std::__1::pair.1068"*, %"struct.std::__1::pair.1068"*, %"class.std::__1::__compressed_pair.1069" }
%"struct.std::__1::pair.1068" = type opaque
%"class.std::__1::__compressed_pair.1069" = type { %"struct.std::__1::__compressed_pair_elem.1070" }
%"struct.std::__1::__compressed_pair_elem.1070" = type { %"struct.std::__1::pair.1068"* }
%"class.v8::internal::ConcurrentAllocator" = type { %"class.v8::internal::LocalHeap"*, %"class.v8::internal::PagedSpace"*, %"class.v8::internal::LocalAllocationBuffer" }
%"class.v8::internal::PagedSpace" = type { %"class.v8::internal::SpaceWithLinearArea", i32, i32, i64, %"class.v8::internal::AllocationStats", %"class.v8::base::Mutex", i64, i64 }
%"class.v8::internal::SpaceWithLinearArea" = type { %"class.v8::internal::Space", %"class.v8::internal::LinearAllocationArea", [3 x i64] }
%"class.v8::internal::Space" = type { %"class.v8::internal::BaseSpace", %"class.v8::internal::AllocationCounter", %"class.v8::internal::heap::List", %"struct.std::__1::atomic.19"*, %"class.std::__1::unique_ptr.97" }
%"class.v8::internal::AllocationCounter" = type <{ %"class.std::__1::vector.38", %"class.std::__1::vector.38", %"class.std::__1::unordered_set", i8, [7 x i8], i64, i64, i8, [7 x i8] }>
%"class.std::__1::vector.38" = type { %"class.std::__1::__vector_base.39" }
%"class.std::__1::__vector_base.39" = type { %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"*, %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"*, %"class.std::__1::__compressed_pair.40" }
%"struct.v8::internal::AllocationCounter::AllocationObserverCounter" = type { %"class.v8::internal::AllocationObserver"*, i64, i64 }
%"class.std::__1::__compressed_pair.40" = type { %"struct.std::__1::__compressed_pair_elem.41" }
%"struct.std::__1::__compressed_pair_elem.41" = type { %"struct.v8::internal::AllocationCounter::AllocationObserverCounter"* }
%"class.std::__1::unordered_set" = type { %"class.std::__1::__hash_table.45" }
%"class.std::__1::__hash_table.45" = type <{ %"class.std::__1::unique_ptr.46", %"class.std::__1::__compressed_pair.56", %"class.std::__1::__compressed_pair.61", %"class.std::__1::__compressed_pair.63", [4 x i8] }>
%"class.std::__1::unique_ptr.46" = type { %"class.std::__1::__compressed_pair.47" }
%"class.std::__1::__compressed_pair.47" = type { %"struct.std::__1::__compressed_pair_elem.48", %"struct.std::__1::__compressed_pair_elem.50" }
%"struct.std::__1::__compressed_pair_elem.48" = type { %"struct.std::__1::__hash_node_base.49"** }
%"struct.std::__1::__hash_node_base.49" = type { %"struct.std::__1::__hash_node_base.49"* }
%"struct.std::__1::__compressed_pair_elem.50" = type { %"class.std::__1::__bucket_list_deallocator.51" }
%"class.std::__1::__bucket_list_deallocator.51" = type { %"class.std::__1::__compressed_pair.52" }
%"class.std::__1::__compressed_pair.52" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.56" = type { %"struct.std::__1::__compressed_pair_elem.57" }
%"struct.std::__1::__compressed_pair_elem.57" = type { %"struct.std::__1::__hash_node_base.49" }
%"class.std::__1::__compressed_pair.61" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.63" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.v8::internal::heap::List" = type { %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"* }
%"class.v8::internal::MemoryChunk" = type { %"class.v8::internal::BasicMemoryChunk", [2 x %"class.v8::internal::SlotSet"*], %"struct.std::__1::atomic.19", %"struct.std::__1::atomic.24", %"class.v8::internal::SlotSet"*, [2 x %"class.v8::internal::TypedSlotSet"*], [2 x %"class.std::__1::set"*], %"class.v8::base::Mutex"*, %"struct.std::__1::atomic.86", %"class.v8::base::Mutex"*, i64, [2 x %"struct.std::__1::atomic.19"], %"class.v8::internal::heap::ListNode", %"class.v8::internal::FreeListCategory"**, %"struct.std::__1::atomic.24", %"class.v8::internal::Bitmap"*, %"class.v8::internal::CodeObjectRegistry"*, %"class.v8::internal::PossiblyEmptyBuckets" }
%"class.v8::internal::BasicMemoryChunk" = type { i64, i64, %"class.v8::internal::Heap"*, i64, i64, i64, i64, %"struct.std::__1::atomic.24", %"struct.std::__1::atomic.68", %"class.v8::internal::VirtualMemory" }
%"struct.std::__1::atomic.68" = type { %"struct.std::__1::__atomic_base.69" }
%"struct.std::__1::__atomic_base.69" = type { %"struct.std::__1::__cxx_atomic_impl.70" }
%"struct.std::__1::__cxx_atomic_impl.70" = type { %"struct.std::__1::__cxx_atomic_base_impl.71" }
%"struct.std::__1::__cxx_atomic_base_impl.71" = type { %"class.v8::internal::BaseSpace"* }
%"class.v8::internal::SlotSet" = type { i8 }
%"class.v8::internal::TypedSlotSet" = type { %"class.v8::internal::TypedSlots", i64 }
%"class.v8::internal::TypedSlots" = type { i32 (...)**, %"struct.v8::internal::TypedSlots::Chunk"*, %"struct.v8::internal::TypedSlots::Chunk"* }
%"struct.v8::internal::TypedSlots::Chunk" = type { %"struct.v8::internal::TypedSlots::Chunk"*, %"class.std::__1::vector.72" }
%"class.std::__1::vector.72" = type { %"class.std::__1::__vector_base.73" }
%"class.std::__1::__vector_base.73" = type { %"struct.v8::internal::TypedSlots::TypedSlot"*, %"struct.v8::internal::TypedSlots::TypedSlot"*, %"class.std::__1::__compressed_pair.74" }
%"struct.v8::internal::TypedSlots::TypedSlot" = type { i32 }
%"class.std::__1::__compressed_pair.74" = type { %"struct.std::__1::__compressed_pair_elem.75" }
%"struct.std::__1::__compressed_pair_elem.75" = type { %"struct.v8::internal::TypedSlots::TypedSlot"* }
%"class.std::__1::set" = type { %"class.std::__1::__tree" }
%"class.std::__1::__tree" = type { %"class.std::__1::__tree_end_node"*, %"class.std::__1::__compressed_pair.79", %"class.std::__1::__compressed_pair.84" }
%"class.std::__1::__compressed_pair.79" = type { %"struct.std::__1::__compressed_pair_elem.80" }
%"class.std::__1::__compressed_pair.84" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"struct.std::__1::atomic.86" = type { %"struct.std::__1::__atomic_base.87" }
%"struct.std::__1::__atomic_base.87" = type { %"struct.std::__1::__cxx_atomic_impl.88" }
%"struct.std::__1::__cxx_atomic_impl.88" = type { %"struct.std::__1::__cxx_atomic_base_impl.89" }
%"struct.std::__1::__cxx_atomic_base_impl.89" = type { i64 }
%"class.v8::internal::heap::ListNode" = type { %"class.v8::internal::MemoryChunk"*, %"class.v8::internal::MemoryChunk"* }
%"class.v8::internal::FreeListCategory" = type { i32, i32, %"class.v8::internal::FreeSpace", %"class.v8::internal::FreeListCategory"*, %"class.v8::internal::FreeListCategory"* }
%"class.v8::internal::FreeSpace" = type { %"class.v8::internal::TorqueGeneratedFreeSpace" }
%"class.v8::internal::TorqueGeneratedFreeSpace" = type { %"class.v8::internal::HeapObject" }
%"class.v8::internal::Bitmap" = type { i8 }
%"class.v8::internal::CodeObjectRegistry" = type <{ %"class.std::__1::vector.90", i8, [7 x i8] }>
%"class.std::__1::vector.90" = type { %"class.std::__1::__vector_base.91" }
%"class.std::__1::__vector_base.91" = type { i64*, i64*, %"class.std::__1::__compressed_pair.92" }
%"class.std::__1::__compressed_pair.92" = type { %"struct.std::__1::__compressed_pair_elem.93" }
%"struct.std::__1::__compressed_pair_elem.93" = type { i64* }
%"class.v8::internal::PossiblyEmptyBuckets" = type { i64 }
%"class.std::__1::unique_ptr.97" = type { %"class.std::__1::__compressed_pair.98" }
%"class.std::__1::__compressed_pair.98" = type { %"struct.std::__1::__compressed_pair_elem.99" }
%"struct.std::__1::__compressed_pair_elem.99" = type { %"class.v8::internal::FreeList"* }
%"class.v8::internal::FreeList" = type { i32 (...)**, i32, i32, i64, %"struct.std::__1::atomic.19", %"class.v8::internal::FreeListCategory"**, i64 }
%"class.v8::internal::LinearAllocationArea" = type { i64, i64, i64 }
%"class.v8::internal::LocalAllocationBuffer" = type { %"class.v8::internal::Heap"*, %"class.v8::internal::LinearAllocationArea" }
%"class.std::__1::unique_ptr.1074" = type { %"class.std::__1::__compressed_pair.1075" }
%"class.std::__1::__compressed_pair.1075" = type { %"struct.std::__1::__compressed_pair_elem.1076" }
%"struct.std::__1::__compressed_pair_elem.1076" = type { %"class.v8::internal::LocalLogger"* }
%"class.v8::internal::LocalLogger" = type opaque
%"struct.v8::internal::ManagedPtrDestructor" = type { i64, %"struct.v8::internal::ManagedPtrDestructor"*, %"struct.v8::internal::ManagedPtrDestructor"*, i8*, void (i8*)*, i64* }
%"class.v8::internal::wasm::WasmEngine" = type opaque
%"class.std::__1::unique_ptr.1083" = type { %"class.std::__1::__compressed_pair.1084" }
%"class.std::__1::__compressed_pair.1084" = type { %"struct.std::__1::__compressed_pair_elem.1085" }
%"struct.std::__1::__compressed_pair_elem.1085" = type { %"class.v8::internal::TracingCpuProfilerImpl"* }
%"class.v8::internal::TracingCpuProfilerImpl" = type opaque
%"class.v8::internal::EmbeddedFileWriterInterface" = type opaque
%"class.v8::Context::BackupIncumbentScope" = type { %"class.v8::Local.834", i64, %"class.v8::Context::BackupIncumbentScope"* }
%"class.v8::Local.834" = type { %"class.v8::Context"* }
%"class.v8::internal::Isolate::ThreadDataTable" = type { %"class.std::__1::unordered_map.1091" }
%"class.std::__1::unordered_map.1091" = type { %"class.std::__1::__hash_table.1092" }
%"class.std::__1::__hash_table.1092" = type <{ %"class.std::__1::unique_ptr.1093", %"class.std::__1::__compressed_pair.1103", %"class.std::__1::__compressed_pair.1108", %"class.std::__1::__compressed_pair.1111", [4 x i8] }>
%"class.std::__1::unique_ptr.1093" = type { %"class.std::__1::__compressed_pair.1094" }
%"class.std::__1::__compressed_pair.1094" = type { %"struct.std::__1::__compressed_pair_elem.1095", %"struct.std::__1::__compressed_pair_elem.1097" }
%"struct.std::__1::__compressed_pair_elem.1095" = type { %"struct.std::__1::__hash_node_base.1096"** }
%"struct.std::__1::__hash_node_base.1096" = type { %"struct.std::__1::__hash_node_base.1096"* }
%"struct.std::__1::__compressed_pair_elem.1097" = type { %"class.std::__1::__bucket_list_deallocator.1098" }
%"class.std::__1::__bucket_list_deallocator.1098" = type { %"class.std::__1::__compressed_pair.1099" }
%"class.std::__1::__compressed_pair.1099" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.1103" = type { %"struct.std::__1::__compressed_pair_elem.1104" }
%"struct.std::__1::__compressed_pair_elem.1104" = type { %"struct.std::__1::__hash_node_base.1096" }
%"class.std::__1::__compressed_pair.1108" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.1111" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"struct.std::__1::atomic.1117" = type { %"struct.std::__1::__atomic_base.1118" }
%"struct.std::__1::__atomic_base.1118" = type { %"struct.std::__1::__cxx_atomic_impl.1119" }
%"struct.std::__1::__cxx_atomic_impl.1119" = type { %"struct.std::__1::__cxx_atomic_base_impl.1120" }
%"struct.std::__1::__cxx_atomic_base_impl.1120" = type { %"class.std::__1::vector.1121"* }
%"class.std::__1::vector.1121" = type { %"class.std::__1::__vector_base.1122" }
%"class.std::__1::__vector_base.1122" = type { %"struct.v8::MemoryRange"*, %"struct.v8::MemoryRange"*, %"class.std::__1::__compressed_pair.1123" }
%"struct.v8::MemoryRange" = type { i8*, i64 }
%"class.std::__1::__compressed_pair.1123" = type { %"struct.std::__1::__compressed_pair_elem.1124" }
%"struct.std::__1::__compressed_pair_elem.1124" = type { %"struct.v8::MemoryRange"* }
%"struct.std::__1::atomic.29" = type { %"struct.std::__1::__atomic_base.30" }
%"struct.std::__1::__atomic_base.30" = type { %"struct.std::__1::__cxx_atomic_impl.31" }
%"struct.std::__1::__cxx_atomic_impl.31" = type { %"struct.std::__1::__cxx_atomic_base_impl.32" }
%"struct.std::__1::__cxx_atomic_base_impl.32" = type { i32 }
%"class.std::__1::vector" = type { %"class.std::__1::__vector_base" }
%"class.std::__1::__vector_base" = type { %"struct.std::__1::pair"*, %"struct.std::__1::pair"*, %"class.std::__1::__compressed_pair.33" }
%"struct.std::__1::pair" = type opaque
%"class.std::__1::__compressed_pair.33" = type { %"struct.std::__1::__compressed_pair_elem.34" }
%"struct.std::__1::__compressed_pair_elem.34" = type { %"struct.std::__1::pair"* }
%"class.v8::internal::NewSpace" = type { %"class.v8::internal::SpaceWithLinearArea", %"class.v8::base::Mutex", %"struct.std::__1::atomic.19", %"struct.std::__1::atomic.19", %"class.v8::internal::SemiSpace", %"class.v8::internal::SemiSpace", %"class.v8::internal::VirtualMemory", %"class.std::__1::vector.103" }
%"class.v8::internal::SemiSpace" = type { %"class.v8::internal::Space", i64, i64, i64, i64, i64, i32, %"class.v8::internal::Page"* }
%"class.v8::internal::Page" = type { %"class.v8::internal::MemoryChunk" }
%"class.std::__1::vector.103" = type { %"class.std::__1::__vector_base.104" }
%"class.std::__1::__vector_base.104" = type { %"struct.std::__1::pair.105"*, %"struct.std::__1::pair.105"*, %"class.std::__1::__compressed_pair.106" }
%"struct.std::__1::pair.105" = type { i32, i64 }
%"class.std::__1::__compressed_pair.106" = type { %"struct.std::__1::__compressed_pair_elem.107" }
%"struct.std::__1::__compressed_pair_elem.107" = type { %"struct.std::__1::pair.105"* }
%"class.v8::internal::CodeSpace" = type { %"class.v8::internal::PagedSpace" }
%"class.v8::internal::OldLargeObjectSpace" = type { %"class.v8::internal::LargeObjectSpace" }
%"class.v8::internal::LargeObjectSpace" = type { %"class.v8::internal::Space", %"struct.std::__1::atomic.19", i32, %"struct.std::__1::atomic.19", %"class.v8::base::Mutex", %"struct.std::__1::atomic.19" }
%"class.v8::internal::CodeLargeObjectSpace" = type { %"class.v8::internal::OldLargeObjectSpace", %"class.std::__1::unordered_map.111" }
%"class.std::__1::unordered_map.111" = type { %"class.std::__1::__hash_table.112" }
%"class.std::__1::__hash_table.112" = type <{ %"class.std::__1::unique_ptr.113", %"class.std::__1::__compressed_pair.123", %"class.std::__1::__compressed_pair.128", %"class.std::__1::__compressed_pair.133", [4 x i8] }>
%"class.std::__1::unique_ptr.113" = type { %"class.std::__1::__compressed_pair.114" }
%"class.std::__1::__compressed_pair.114" = type { %"struct.std::__1::__compressed_pair_elem.115", %"struct.std::__1::__compressed_pair_elem.117" }
%"struct.std::__1::__compressed_pair_elem.115" = type { %"struct.std::__1::__hash_node_base.116"** }
%"struct.std::__1::__hash_node_base.116" = type { %"struct.std::__1::__hash_node_base.116"* }
%"struct.std::__1::__compressed_pair_elem.117" = type { %"class.std::__1::__bucket_list_deallocator.118" }
%"class.std::__1::__bucket_list_deallocator.118" = type { %"class.std::__1::__compressed_pair.119" }
%"class.std::__1::__compressed_pair.119" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.123" = type { %"struct.std::__1::__compressed_pair_elem.124" }
%"struct.std::__1::__compressed_pair_elem.124" = type { %"struct.std::__1::__hash_node_base.116" }
%"class.std::__1::__compressed_pair.128" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.133" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.v8::internal::NewLargeObjectSpace" = type { %"class.v8::internal::LargeObjectSpace", i64 }
%"class.v8::internal::OldSpace" = type { %"class.v8::internal::PagedSpace" }
%"class.v8::internal::MapSpace" = type { %"class.v8::internal::PagedSpace" }
%"class.std::__1::unique_ptr.146" = type { %"class.std::__1::__compressed_pair.147" }
%"class.std::__1::__compressed_pair.147" = type { %"struct.std::__1::__compressed_pair_elem.148" }
%"struct.std::__1::__compressed_pair_elem.148" = type { %"class.v8::internal::ConcurrentAllocator"* }
%"class.v8::internal::ArrayBufferExtension" = type { %"struct.std::__1::atomic.152", %"struct.std::__1::atomic.156", %"class.std::__1::shared_ptr", %"class.v8::internal::ArrayBufferExtension"*, %"struct.std::__1::atomic.19" }
%"struct.std::__1::atomic.156" = type { %"struct.std::__1::__atomic_base.157" }
%"struct.std::__1::__atomic_base.157" = type { %"struct.std::__1::__cxx_atomic_impl.158" }
%"struct.std::__1::__cxx_atomic_impl.158" = type { %"struct.std::__1::__cxx_atomic_base_impl.159" }
%"struct.std::__1::__cxx_atomic_base_impl.159" = type { i8 }
%"class.std::__1::shared_ptr" = type { %"class.v8::internal::BackingStore"*, %"class.std::__1::__shared_weak_count"* }
%"struct.std::__1::atomic.161" = type { %"struct.std::__1::__atomic_base.162" }
%"struct.std::__1::__atomic_base.162" = type { %"struct.std::__1::__cxx_atomic_impl.163" }
%"struct.std::__1::__cxx_atomic_impl.163" = type { %"struct.std::__1::__cxx_atomic_base_impl.164" }
%"struct.std::__1::__cxx_atomic_base_impl.164" = type { i32 }
%"class.v8::internal::AllocationObserver" = type { i32 (...)**, i64 }
%"class.v8::internal::StressScavengeObserver" = type opaque
%"class.v8::internal::Object" = type { %"class.v8::internal::TaggedImpl" }
%"class.v8::internal::TaggedImpl" = type { i64 }
%"class.std::__1::vector.165" = type { %"class.std::__1::__vector_base.166" }
%"class.std::__1::__vector_base.166" = type { %"struct.v8::internal::Heap::GCCallbackTuple"*, %"struct.v8::internal::Heap::GCCallbackTuple"*, %"class.std::__1::__compressed_pair.167" }
%"struct.v8::internal::Heap::GCCallbackTuple" = type { void (%"class.v8::Isolate"*, i32, i32, i8*)*, i32, i8* }
%"class.std::__1::__compressed_pair.167" = type { %"struct.std::__1::__compressed_pair_elem.168" }
%"struct.std::__1::__compressed_pair_elem.168" = type { %"struct.v8::internal::Heap::GCCallbackTuple"* }
%"class.std::__1::unique_ptr.172" = type { %"class.std::__1::__compressed_pair.173" }
%"class.std::__1::__compressed_pair.173" = type { %"struct.std::__1::__compressed_pair_elem.174" }
%"struct.std::__1::__compressed_pair_elem.174" = type { %"class.v8::internal::GCTracer"* }
%"class.v8::internal::GCTracer" = type opaque
%"class.std::__1::unique_ptr.178" = type { %"class.std::__1::__compressed_pair.179" }
%"class.std::__1::__compressed_pair.179" = type { %"struct.std::__1::__compressed_pair_elem.180" }
%"struct.std::__1::__compressed_pair_elem.180" = type { %"class.v8::internal::MarkCompactCollector"* }
%"class.v8::internal::MarkCompactCollector" = type <{ %"class.v8::internal::MarkCompactCollectorBase", %"class.v8::base::Mutex", %"class.v8::base::Semaphore", i8, i8, i8, i8, i8, i8, [2 x i8], %"class.v8::internal::MarkingWorklists", %"class.v8::internal::WeakObjects", %"struct.v8::internal::EphemeronMarking", %"class.std::__1::unique_ptr.220", %"class.std::__1::unique_ptr.226", %"class.v8::internal::NativeContextInferrer", [7 x i8], %"class.v8::internal::NativeContextStats", %"class.std::__1::vector.280", %"class.std::__1::vector.280", %"class.std::__1::vector.280", %"class.std::__1::vector.287", %"class.v8::internal::Sweeper"*, %"class.v8::internal::MajorMarkingState", %"class.v8::internal::MajorNonAtomicMarkingState", [2 x i8], i32, i32, [4 x i8] }>
%"class.v8::internal::MarkCompactCollectorBase" = type { i32 (...)**, %"class.v8::internal::Heap"* }
%"class.v8::base::Semaphore" = type { %union.sem_t }
%union.sem_t = type { i64, [24 x i8] }
%"class.v8::internal::MarkingWorklists" = type { %"class.heap::base::Worklist", %"class.heap::base::Worklist", %"class.heap::base::Worklist.181", %"class.std::__1::vector.182", %"class.std::__1::vector.189", %"class.heap::base::Worklist" }
%"class.heap::base::Worklist.181" = type { %"class.v8::base::Mutex", %"class.heap::base::Worklist<v8::internal::HeapObject, 16>::Segment"*, %"struct.std::__1::atomic.19" }
%"class.heap::base::Worklist<v8::internal::HeapObject, 16>::Segment" = type opaque
%"class.std::__1::vector.182" = type { %"class.std::__1::__vector_base.183" }
%"class.std::__1::__vector_base.183" = type { %"struct.v8::internal::ContextWorklistPair"*, %"struct.v8::internal::ContextWorklistPair"*, %"class.std::__1::__compressed_pair.184" }
%"struct.v8::internal::ContextWorklistPair" = type { i64, %"class.heap::base::Worklist"* }
%"class.std::__1::__compressed_pair.184" = type { %"struct.std::__1::__compressed_pair_elem.185" }
%"struct.std::__1::__compressed_pair_elem.185" = type { %"struct.v8::internal::ContextWorklistPair"* }
%"class.std::__1::vector.189" = type { %"class.std::__1::__vector_base.190" }
%"class.std::__1::__vector_base.190" = type { %"class.std::__1::unique_ptr.191"*, %"class.std::__1::unique_ptr.191"*, %"class.std::__1::__compressed_pair.192" }
%"class.std::__1::unique_ptr.191" = type opaque
%"class.std::__1::__compressed_pair.192" = type { %"struct.std::__1::__compressed_pair_elem.193" }
%"struct.std::__1::__compressed_pair_elem.193" = type { %"class.std::__1::unique_ptr.191"* }
%"class.heap::base::Worklist" = type { %"class.v8::base::Mutex", %"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Segment"*, %"struct.std::__1::atomic.19" }
%"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Segment" = type opaque
%"class.v8::internal::WeakObjects" = type { %"class.v8::internal::Worklist", %"class.v8::internal::Worklist.197", %"class.v8::internal::Worklist.199", %"class.v8::internal::Worklist.199", %"class.v8::internal::Worklist.199", %"class.v8::internal::Worklist.201", %"class.v8::internal::Worklist.203", %"class.v8::internal::Worklist.205", %"class.v8::internal::Worklist.207", %"class.v8::internal::Worklist.209", %"class.v8::internal::Worklist.211" }
%"class.v8::internal::Worklist" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::TransitionArray, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::TransitionArray, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::TransitionArray, 64>::Segment"*, %"struct.std::__1::atomic.19" }
%"class.v8::internal::Worklist.197" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::EphemeronHashTable, 64>::Segment"*, %"struct.std::__1::atomic.19" }
%"class.v8::internal::Worklist.199" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::Ephemeron, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::Ephemeron, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::Ephemeron, 64>::Segment"*, %"struct.std::__1::atomic.19" }
%"class.v8::internal::Worklist.201" = type <{ [8 x %"struct.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::Segment"*, %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::CompressedHeapObjectSlot>, 64>::Segment"*, %"struct.std::__1::atomic.19" }
%"class.v8::internal::Worklist.203" = type <{ [8 x %"struct.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::Segment"*, %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<std::__1::pair<v8::internal::HeapObject, v8::internal::Code>, 64>::Segment"*, %"struct.std::__1::atomic.19" }
%"class.v8::internal::Worklist.205" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::JSWeakRef, 64>::Segment"*, %"struct.std::__1::atomic.19" }
%"class.v8::internal::Worklist.207" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::WeakCell, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::WeakCell, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::WeakCell, 64>::Segment"*, %"struct.std::__1::atomic.19" }
%"class.v8::internal::Worklist.209" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::SharedFunctionInfo, 64>::Segment"*, %"struct.std::__1::atomic.19" }
%"class.v8::internal::Worklist.211" = type <{ [8 x %"struct.v8::internal::Worklist<v8::internal::JSFunction, 64>::PrivateSegmentHolder"], %"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::GlobalPool", i32, [4 x i8] }>
%"struct.v8::internal::Worklist<v8::internal::JSFunction, 64>::PrivateSegmentHolder" = type { %"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::Segment"*, %"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::Segment"*, [64 x i8] }
%"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::Segment" = type opaque
%"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::GlobalPool" = type { %"class.v8::base::Mutex", %"class.v8::internal::Worklist<v8::internal::JSFunction, 64>::Segment"*, %"struct.std::__1::atomic.19" }
%"struct.v8::internal::EphemeronMarking" = type { %"class.std::__1::vector.213", i8, i64 }
%"class.std::__1::vector.213" = type { %"class.std::__1::__vector_base.214" }
%"class.std::__1::__vector_base.214" = type { %"class.v8::internal::HeapObject"*, %"class.v8::internal::HeapObject"*, %"class.std::__1::__compressed_pair.215" }
%"class.std::__1::__compressed_pair.215" = type { %"struct.std::__1::__compressed_pair_elem.216" }
%"struct.std::__1::__compressed_pair_elem.216" = type { %"class.v8::internal::HeapObject"* }
%"class.std::__1::unique_ptr.220" = type { %"class.std::__1::__compressed_pair.221" }
%"class.std::__1::__compressed_pair.221" = type { %"struct.std::__1::__compressed_pair_elem.222" }
%"struct.std::__1::__compressed_pair_elem.222" = type { %"class.v8::internal::MainMarkingVisitor"* }
%"class.v8::internal::MainMarkingVisitor" = type opaque
%"class.std::__1::unique_ptr.226" = type { %"class.std::__1::__compressed_pair.227" }
%"class.std::__1::__compressed_pair.227" = type { %"struct.std::__1::__compressed_pair_elem.228" }
%"struct.std::__1::__compressed_pair_elem.228" = type { %"class.v8::internal::MarkingWorklists::Local"* }
%"class.v8::internal::MarkingWorklists::Local" = type { %"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Local", %"class.heap::base::Worklist<v8::internal::HeapObject, 16>::Local", %"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Local", i64, %"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Local"*, i8, [7 x i8], %"class.std::__1::unordered_map.229" }
%"class.heap::base::Worklist<v8::internal::HeapObject, 16>::Local" = type { %"class.heap::base::Worklist.181"*, %"class.heap::base::internal::SegmentBase"*, %"class.heap::base::internal::SegmentBase"* }
%"class.heap::base::internal::SegmentBase" = type { i16, i16 }
%"class.heap::base::Worklist<v8::internal::HeapObject, 64>::Local" = type { %"class.heap::base::Worklist"*, %"class.heap::base::internal::SegmentBase"*, %"class.heap::base::internal::SegmentBase"* }
%"class.std::__1::unordered_map.229" = type { %"class.std::__1::__hash_table.230" }
%"class.std::__1::__hash_table.230" = type <{ %"class.std::__1::unique_ptr.231", %"class.std::__1::__compressed_pair.241", %"class.std::__1::__compressed_pair.246", %"class.std::__1::__compressed_pair.249", [4 x i8] }>
%"class.std::__1::unique_ptr.231" = type { %"class.std::__1::__compressed_pair.232" }
%"class.std::__1::__compressed_pair.232" = type { %"struct.std::__1::__compressed_pair_elem.233", %"struct.std::__1::__compressed_pair_elem.235" }
%"struct.std::__1::__compressed_pair_elem.233" = type { %"struct.std::__1::__hash_node_base.234"** }
%"struct.std::__1::__hash_node_base.234" = type { %"struct.std::__1::__hash_node_base.234"* }
%"struct.std::__1::__compressed_pair_elem.235" = type { %"class.std::__1::__bucket_list_deallocator.236" }
%"class.std::__1::__bucket_list_deallocator.236" = type { %"class.std::__1::__compressed_pair.237" }
%"class.std::__1::__compressed_pair.237" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.241" = type { %"struct.std::__1::__compressed_pair_elem.242" }
%"struct.std::__1::__compressed_pair_elem.242" = type { %"struct.std::__1::__hash_node_base.234" }
%"class.std::__1::__compressed_pair.246" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.249" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.v8::internal::NativeContextInferrer" = type { i8 }
%"class.v8::internal::NativeContextStats" = type { %"class.std::__1::unordered_map.256" }
%"class.std::__1::unordered_map.256" = type { %"class.std::__1::__hash_table.257" }
%"class.std::__1::__hash_table.257" = type <{ %"class.std::__1::unique_ptr.258", %"class.std::__1::__compressed_pair.268", %"class.std::__1::__compressed_pair.273", %"class.std::__1::__compressed_pair.276", [4 x i8] }>
%"class.std::__1::unique_ptr.258" = type { %"class.std::__1::__compressed_pair.259" }
%"class.std::__1::__compressed_pair.259" = type { %"struct.std::__1::__compressed_pair_elem.260", %"struct.std::__1::__compressed_pair_elem.262" }
%"struct.std::__1::__compressed_pair_elem.260" = type { %"struct.std::__1::__hash_node_base.261"** }
%"struct.std::__1::__hash_node_base.261" = type { %"struct.std::__1::__hash_node_base.261"* }
%"struct.std::__1::__compressed_pair_elem.262" = type { %"class.std::__1::__bucket_list_deallocator.263" }
%"class.std::__1::__bucket_list_deallocator.263" = type { %"class.std::__1::__compressed_pair.264" }
%"class.std::__1::__compressed_pair.264" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.268" = type { %"struct.std::__1::__compressed_pair_elem.269" }
%"struct.std::__1::__compressed_pair_elem.269" = type { %"struct.std::__1::__hash_node_base.261" }
%"class.std::__1::__compressed_pair.273" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.276" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.std::__1::vector.280" = type { %"class.std::__1::__vector_base.281" }
%"class.std::__1::__vector_base.281" = type { %"class.v8::internal::Page"**, %"class.v8::internal::Page"**, %"class.std::__1::__compressed_pair.282" }
%"class.std::__1::__compressed_pair.282" = type { %"struct.std::__1::__compressed_pair_elem.283" }
%"struct.std::__1::__compressed_pair_elem.283" = type { %"class.v8::internal::Page"** }
%"class.std::__1::vector.287" = type { %"class.std::__1::__vector_base.288" }
%"class.std::__1::__vector_base.288" = type { %"struct.std::__1::pair.289"*, %"struct.std::__1::pair.289"*, %"class.std::__1::__compressed_pair.290" }
%"struct.std::__1::pair.289" = type opaque
%"class.std::__1::__compressed_pair.290" = type { %"struct.std::__1::__compressed_pair_elem.291" }
%"struct.std::__1::__compressed_pair_elem.291" = type { %"struct.std::__1::pair.289"* }
%"class.v8::internal::Sweeper" = type <{ %"class.v8::internal::Heap"*, %"class.v8::internal::MajorNonAtomicMarkingState"*, %"class.std::__1::unique_ptr.295", %"class.v8::base::Mutex", [3 x %"class.std::__1::vector.280"], [3 x %"class.std::__1::vector.280"], i8, %"struct.std::__1::atomic.152", [6 x i8], %"class.std::__1::vector.280", i64, %"class.v8::base::Semaphore", i8, i8, i8, [5 x i8] }>
%"class.std::__1::unique_ptr.295" = type { %"class.std::__1::__compressed_pair.296" }
%"class.std::__1::__compressed_pair.296" = type { %"struct.std::__1::__compressed_pair_elem.297" }
%"struct.std::__1::__compressed_pair_elem.297" = type { %"class.v8::JobHandle"* }
%"class.v8::JobHandle" = type { i32 (...)** }
%"class.v8::internal::MajorMarkingState" = type { i8 }
%"class.v8::internal::MajorNonAtomicMarkingState" = type { i8 }
%"class.v8::internal::MinorMarkCompactCollector" = type <{ %"class.v8::internal::MarkCompactCollectorBase", %"class.v8::internal::Worklist.305"*, %"class.v8::internal::YoungGenerationMarkingVisitor"*, %"class.v8::base::Semaphore", %"class.std::__1::vector.280", %"class.std::__1::vector.280", %"class.v8::internal::MinorMarkingState", %"class.v8::internal::MinorNonAtomicMarkingState", [6 x i8] }>
%"class.v8::internal::Worklist.305" = type opaque
%"class.v8::internal::YoungGenerationMarkingVisitor" = type opaque
%"class.v8::internal::MinorMarkingState" = type { i8 }
%"class.v8::internal::MinorNonAtomicMarkingState" = type { i8 }
%"class.std::__1::unique_ptr.308" = type { %"class.std::__1::__compressed_pair.309" }
%"class.std::__1::__compressed_pair.309" = type { %"struct.std::__1::__compressed_pair_elem.310" }
%"struct.std::__1::__compressed_pair_elem.310" = type { %"class.v8::internal::ScavengerCollector"* }
%"class.v8::internal::ScavengerCollector" = type opaque
%"class.std::__1::unique_ptr.314" = type { %"class.std::__1::__compressed_pair.315" }
%"class.std::__1::__compressed_pair.315" = type { %"struct.std::__1::__compressed_pair_elem.316" }
%"struct.std::__1::__compressed_pair_elem.316" = type { %"class.v8::internal::ArrayBufferSweeper"* }
%"class.v8::internal::ArrayBufferSweeper" = type opaque
%"class.std::__1::unique_ptr.320" = type { %"class.std::__1::__compressed_pair.321" }
%"class.std::__1::__compressed_pair.321" = type { %"struct.std::__1::__compressed_pair_elem.322" }
%"struct.std::__1::__compressed_pair_elem.322" = type { %"class.v8::internal::MemoryAllocator"* }
%"class.v8::internal::MemoryAllocator" = type { %"class.v8::internal::Isolate"*, %"class.v8::PageAllocator"*, %"class.v8::PageAllocator"*, i64, %"struct.std::__1::atomic.19", %"struct.std::__1::atomic.19", %"struct.std::__1::atomic.19", %"struct.std::__1::atomic.19", %"class.v8::internal::VirtualMemory", %"class.v8::internal::MemoryAllocator::Unmapper", %"class.std::__1::unordered_set.330", %"class.v8::base::Mutex" }
%"class.v8::internal::MemoryAllocator::Unmapper" = type { %"class.v8::internal::Heap"*, %"class.v8::internal::MemoryAllocator"*, %"class.v8::base::Mutex", [3 x %"class.std::__1::vector.323"], %"class.std::__1::unique_ptr.295" }
%"class.std::__1::vector.323" = type { %"class.std::__1::__vector_base.324" }
%"class.std::__1::__vector_base.324" = type { %"class.v8::internal::MemoryChunk"**, %"class.v8::internal::MemoryChunk"**, %"class.std::__1::__compressed_pair.325" }
%"class.std::__1::__compressed_pair.325" = type { %"struct.std::__1::__compressed_pair_elem.326" }
%"struct.std::__1::__compressed_pair_elem.326" = type { %"class.v8::internal::MemoryChunk"** }
%"class.std::__1::unique_ptr.359" = type { %"class.std::__1::__compressed_pair.360" }
%"class.std::__1::__compressed_pair.360" = type { %"struct.std::__1::__compressed_pair_elem.361" }
%"struct.std::__1::__compressed_pair_elem.361" = type { %"class.v8::internal::IncrementalMarking"* }
%"class.v8::internal::IncrementalMarking" = type { %"class.v8::internal::Heap"*, %"class.v8::internal::MarkCompactCollector"*, %"class.v8::internal::WeakObjects"*, double, double, i64, i64, i64, i64, double, i64, %"struct.std::__1::atomic.362", i8, i8, i8, i8, [3 x i8], %"class.v8::internal::IncrementalMarkingJob", %"struct.std::__1::atomic.366", %"class.v8::internal::IncrementalMarking::Observer", %"class.v8::internal::IncrementalMarking::Observer", %"class.v8::internal::MajorMarkingState", %"class.v8::internal::MajorAtomicMarkingState", %"class.v8::internal::MajorNonAtomicMarkingState", %"class.v8::base::Mutex", %"class.std::__1::unordered_map.371" }
%"struct.std::__1::atomic.362" = type { %"struct.std::__1::__atomic_base.363" }
%"struct.std::__1::__atomic_base.363" = type { %"struct.std::__1::__cxx_atomic_impl.364" }
%"struct.std::__1::__cxx_atomic_impl.364" = type { %"struct.std::__1::__cxx_atomic_base_impl.365" }
%"struct.std::__1::__cxx_atomic_base_impl.365" = type { i8 }
%"class.v8::internal::IncrementalMarkingJob" = type <{ %"class.v8::base::Mutex", double, i8, i8, [6 x i8] }>
%"struct.std::__1::atomic.366" = type { %"struct.std::__1::__atomic_base.367" }
%"struct.std::__1::__atomic_base.367" = type { %"struct.std::__1::__cxx_atomic_impl.368" }
%"struct.std::__1::__cxx_atomic_impl.368" = type { %"struct.std::__1::__cxx_atomic_base_impl.369" }
%"struct.std::__1::__cxx_atomic_base_impl.369" = type { i32 }
%"class.v8::internal::IncrementalMarking::Observer" = type { %"class.v8::internal::AllocationObserver", %"class.v8::internal::IncrementalMarking"* }
%"class.v8::internal::MajorAtomicMarkingState" = type { i8 }
%"class.std::__1::unordered_map.371" = type { %"class.std::__1::__hash_table.372" }
%"class.std::__1::__hash_table.372" = type <{ %"class.std::__1::unique_ptr.373", %"class.std::__1::__compressed_pair.383", %"class.std::__1::__compressed_pair.388", %"class.std::__1::__compressed_pair.391", [4 x i8] }>
%"class.std::__1::unique_ptr.373" = type { %"class.std::__1::__compressed_pair.374" }
%"class.std::__1::__compressed_pair.374" = type { %"struct.std::__1::__compressed_pair_elem.375", %"struct.std::__1::__compressed_pair_elem.377" }
%"struct.std::__1::__compressed_pair_elem.375" = type { %"struct.std::__1::__hash_node_base.376"** }
%"struct.std::__1::__hash_node_base.376" = type { %"struct.std::__1::__hash_node_base.376"* }
%"struct.std::__1::__compressed_pair_elem.377" = type { %"class.std::__1::__bucket_list_deallocator.378" }
%"class.std::__1::__bucket_list_deallocator.378" = type { %"class.std::__1::__compressed_pair.379" }
%"class.std::__1::__compressed_pair.379" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.383" = type { %"struct.std::__1::__compressed_pair_elem.384" }
%"struct.std::__1::__compressed_pair_elem.384" = type { %"struct.std::__1::__hash_node_base.376" }
%"class.std::__1::__compressed_pair.388" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.391" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.std::__1::unique_ptr.398" = type { %"class.std::__1::__compressed_pair.399" }
%"class.std::__1::__compressed_pair.399" = type { %"struct.std::__1::__compressed_pair_elem.400" }
%"struct.std::__1::__compressed_pair_elem.400" = type { %"class.v8::internal::ConcurrentMarking"* }
%"class.v8::internal::ConcurrentMarking" = type <{ %"class.std::__1::unique_ptr.295", %"class.v8::internal::Heap"*, %"class.v8::internal::MarkingWorklists"*, %"class.v8::internal::WeakObjects"*, [8 x %"struct.v8::internal::ConcurrentMarking::TaskState"], %"struct.std::__1::atomic.19", %"struct.std::__1::atomic.152", [7 x i8] }>
%"struct.v8::internal::ConcurrentMarking::TaskState" = type { i64, %"class.std::__1::unordered_map.401", %"class.v8::internal::NativeContextInferrer", [7 x i8], %"class.v8::internal::NativeContextStats", [64 x i8] }
%"class.std::__1::unordered_map.401" = type { %"class.std::__1::__hash_table.402" }
%"class.std::__1::__hash_table.402" = type <{ %"class.std::__1::unique_ptr.403", %"class.std::__1::__compressed_pair.413", %"class.std::__1::__compressed_pair.418", %"class.std::__1::__compressed_pair.421", [4 x i8] }>
%"class.std::__1::unique_ptr.403" = type { %"class.std::__1::__compressed_pair.404" }
%"class.std::__1::__compressed_pair.404" = type { %"struct.std::__1::__compressed_pair_elem.405", %"struct.std::__1::__compressed_pair_elem.407" }
%"struct.std::__1::__compressed_pair_elem.405" = type { %"struct.std::__1::__hash_node_base.406"** }
%"struct.std::__1::__hash_node_base.406" = type { %"struct.std::__1::__hash_node_base.406"* }
%"struct.std::__1::__compressed_pair_elem.407" = type { %"class.std::__1::__bucket_list_deallocator.408" }
%"class.std::__1::__bucket_list_deallocator.408" = type { %"class.std::__1::__compressed_pair.409" }
%"class.std::__1::__compressed_pair.409" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.413" = type { %"struct.std::__1::__compressed_pair_elem.414" }
%"struct.std::__1::__compressed_pair_elem.414" = type { %"struct.std::__1::__hash_node_base.406" }
%"class.std::__1::__compressed_pair.418" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.421" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.std::__1::unique_ptr.428" = type { %"class.std::__1::__compressed_pair.429" }
%"class.std::__1::__compressed_pair.429" = type { %"struct.std::__1::__compressed_pair_elem.430" }
%"struct.std::__1::__compressed_pair_elem.430" = type { %"class.v8::internal::GCIdleTimeHandler"* }
%"class.v8::internal::GCIdleTimeHandler" = type opaque
%"class.std::__1::unique_ptr.434" = type { %"class.std::__1::__compressed_pair.435" }
%"class.std::__1::__compressed_pair.435" = type { %"struct.std::__1::__compressed_pair_elem.436" }
%"struct.std::__1::__compressed_pair_elem.436" = type { %"class.v8::internal::MemoryMeasurement"* }
%"class.v8::internal::MemoryMeasurement" = type { %"class.std::__1::list", %"class.std::__1::list", %"class.std::__1::list", %"class.v8::internal::Isolate"*, i8, i8, i8, %"class.v8::base::RandomNumberGenerator" }
%"class.std::__1::list" = type { %"class.std::__1::__list_imp" }
%"class.std::__1::__list_imp" = type { %"struct.std::__1::__list_node_base", %"class.std::__1::__compressed_pair.437" }
%"struct.std::__1::__list_node_base" = type { %"struct.std::__1::__list_node_base"*, %"struct.std::__1::__list_node_base"* }
%"class.std::__1::__compressed_pair.437" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::unique_ptr.444" = type { %"class.std::__1::__compressed_pair.445" }
%"class.std::__1::__compressed_pair.445" = type { %"struct.std::__1::__compressed_pair_elem.446" }
%"struct.std::__1::__compressed_pair_elem.446" = type { %"class.v8::internal::MemoryReducer"* }
%"class.v8::internal::MemoryReducer" = type opaque
%"class.std::__1::unique_ptr.450" = type { %"class.std::__1::__compressed_pair.451" }
%"class.std::__1::__compressed_pair.451" = type { %"struct.std::__1::__compressed_pair_elem.452" }
%"struct.std::__1::__compressed_pair_elem.452" = type { %"class.v8::internal::ObjectStats"* }
%"class.v8::internal::ObjectStats" = type opaque
%"class.std::__1::unique_ptr.456" = type { %"class.std::__1::__compressed_pair.457" }
%"class.std::__1::__compressed_pair.457" = type { %"struct.std::__1::__compressed_pair_elem.458" }
%"struct.std::__1::__compressed_pair_elem.458" = type { %"class.v8::internal::ScavengeJob"* }
%"class.v8::internal::ScavengeJob" = type opaque
%"class.std::__1::unique_ptr.462" = type { %"class.std::__1::__compressed_pair.463" }
%"class.std::__1::__compressed_pair.463" = type { %"struct.std::__1::__compressed_pair_elem.464" }
%"struct.std::__1::__compressed_pair_elem.464" = type { %"class.v8::internal::AllocationObserver"* }
%"class.std::__1::unique_ptr.468" = type { %"class.std::__1::__compressed_pair.469" }
%"class.std::__1::__compressed_pair.469" = type { %"struct.std::__1::__compressed_pair_elem.470" }
%"struct.std::__1::__compressed_pair_elem.470" = type { %"class.v8::internal::LocalEmbedderHeapTracer"* }
%"class.v8::internal::LocalEmbedderHeapTracer" = type opaque
%"class.std::__1::unique_ptr.474" = type { %"class.std::__1::__compressed_pair.475" }
%"class.std::__1::__compressed_pair.475" = type { %"struct.std::__1::__compressed_pair_elem.476" }
%"struct.std::__1::__compressed_pair_elem.476" = type { %"class.v8::internal::MarkingBarrier"* }
%"class.v8::internal::MarkingBarrier" = type opaque
%"class.std::__1::shared_ptr.480" = type { %"class.v8::internal::CodeRange"*, %"class.std::__1::__shared_weak_count"* }
%"class.v8::internal::CodeRange" = type { %"class.v8::internal::VirtualMemoryCage", %"struct.std::__1::atomic.499", %"class.v8::base::Mutex" }
%"class.v8::internal::VirtualMemoryCage" = type { i32 (...)**, i64, %"class.std::__1::unique_ptr.481", %"class.v8::internal::VirtualMemory" }
%"struct.std::__1::atomic.499" = type { %"struct.std::__1::__atomic_base.500" }
%"struct.std::__1::__atomic_base.500" = type { %"struct.std::__1::__cxx_atomic_impl.501" }
%"struct.std::__1::__cxx_atomic_impl.501" = type { %"struct.std::__1::__cxx_atomic_base_impl.502" }
%"struct.std::__1::__cxx_atomic_base_impl.502" = type { i8* }
%"class.v8::CppHeap" = type opaque
%"class.v8::EmbedderRootsHandler" = type { i32 (...)** }
%"class.v8::internal::StrongRootsEntry" = type { %"class.v8::internal::FullObjectSlot", %"class.v8::internal::FullObjectSlot", %"class.v8::internal::StrongRootsEntry"*, %"class.v8::internal::StrongRootsEntry"* }
%"class.v8::internal::FullObjectSlot" = type { %"class.v8::internal::SlotBase" }
%"class.v8::internal::SlotBase" = type { i64 }
%"class.std::__1::unordered_map.503" = type { %"class.std::__1::__hash_table.504" }
%"class.std::__1::__hash_table.504" = type <{ %"class.std::__1::unique_ptr.505", %"class.std::__1::__compressed_pair.515", %"class.std::__1::__compressed_pair.520", %"class.std::__1::__compressed_pair.523", [4 x i8] }>
%"class.std::__1::unique_ptr.505" = type { %"class.std::__1::__compressed_pair.506" }
%"class.std::__1::__compressed_pair.506" = type { %"struct.std::__1::__compressed_pair_elem.507", %"struct.std::__1::__compressed_pair_elem.509" }
%"struct.std::__1::__compressed_pair_elem.507" = type { %"struct.std::__1::__hash_node_base.508"** }
%"struct.std::__1::__hash_node_base.508" = type { %"struct.std::__1::__hash_node_base.508"* }
%"struct.std::__1::__compressed_pair_elem.509" = type { %"class.std::__1::__bucket_list_deallocator.510" }
%"class.std::__1::__bucket_list_deallocator.510" = type { %"class.std::__1::__compressed_pair.511" }
%"class.std::__1::__compressed_pair.511" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.515" = type { %"struct.std::__1::__compressed_pair_elem.516" }
%"struct.std::__1::__compressed_pair_elem.516" = type { %"struct.std::__1::__hash_node_base.508" }
%"class.std::__1::__compressed_pair.520" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.523" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.std::__1::unique_ptr.529" = type { %"class.std::__1::__compressed_pair.530" }
%"class.std::__1::__compressed_pair.530" = type { %"struct.std::__1::__compressed_pair_elem.531" }
%"struct.std::__1::__compressed_pair_elem.531" = type { %"class.v8::internal::GlobalHandleVector"* }
%"class.v8::internal::GlobalHandleVector" = type opaque
%"class.std::__1::unique_ptr.535" = type { %"class.std::__1::__compressed_pair.536" }
%"class.std::__1::__compressed_pair.536" = type { %"struct.std::__1::__compressed_pair_elem.537" }
%"struct.std::__1::__compressed_pair_elem.537" = type { %"class.v8::internal::GlobalSafepoint"* }
%"class.v8::internal::GlobalSafepoint" = type opaque
%"class.v8::internal::Heap::ExternalStringTable" = type { %"class.v8::internal::Heap"*, %"class.std::__1::vector.541", %"class.std::__1::vector.541" }
%"class.std::__1::unique_ptr.548" = type { %"class.std::__1::__compressed_pair.549" }
%"class.std::__1::__compressed_pair.549" = type { %"struct.std::__1::__compressed_pair_elem.550" }
%"struct.std::__1::__compressed_pair_elem.550" = type { %"class.v8::internal::CollectionBarrier"* }
%"class.v8::internal::CollectionBarrier" = type opaque
%"class.v8::internal::HeapObject" = type { %"class.v8::internal::Object" }
%"class.v8::base::SharedMutex" = type { %union.pthread_rwlock_t }
%union.pthread_rwlock_t = type { %struct.__pthread_rwlock_arch_t }
%struct.__pthread_rwlock_arch_t = type { i32, i32, i32, i32, i32, i32, i32, i32, i8, [7 x i8], i64, i32 }
%"class.v8::base::Mutex" = type { %union.pthread_mutex_t }
%"class.std::__1::unordered_set.330" = type { %"class.std::__1::__hash_table.331" }
%"class.std::__1::__hash_table.331" = type <{ %"class.std::__1::unique_ptr.332", %"class.std::__1::__compressed_pair.342", %"class.std::__1::__compressed_pair.347", %"class.std::__1::__compressed_pair.351", [4 x i8] }>
%"class.std::__1::unique_ptr.332" = type { %"class.std::__1::__compressed_pair.333" }
%"class.std::__1::__compressed_pair.333" = type { %"struct.std::__1::__compressed_pair_elem.334", %"struct.std::__1::__compressed_pair_elem.336" }
%"struct.std::__1::__compressed_pair_elem.334" = type { %"struct.std::__1::__hash_node_base.335"** }
%"struct.std::__1::__hash_node_base.335" = type { %"struct.std::__1::__hash_node_base.335"* }
%"struct.std::__1::__compressed_pair_elem.336" = type { %"class.std::__1::__bucket_list_deallocator.337" }
%"class.std::__1::__bucket_list_deallocator.337" = type { %"class.std::__1::__compressed_pair.338" }
%"class.std::__1::__compressed_pair.338" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.342" = type { %"struct.std::__1::__compressed_pair_elem.343" }
%"struct.std::__1::__compressed_pair_elem.343" = type { %"struct.std::__1::__hash_node_base.335" }
%"class.std::__1::__compressed_pair.347" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.351" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.std::__1::unordered_map.580" = type { %"class.std::__1::__hash_table.581" }
%"class.std::__1::__hash_table.581" = type <{ %"class.std::__1::unique_ptr.582", %"class.std::__1::__compressed_pair.592", %"class.std::__1::__compressed_pair.597", %"class.std::__1::__compressed_pair.600", [4 x i8] }>
%"class.std::__1::unique_ptr.582" = type { %"class.std::__1::__compressed_pair.583" }
%"class.std::__1::__compressed_pair.583" = type { %"struct.std::__1::__compressed_pair_elem.584", %"struct.std::__1::__compressed_pair_elem.586" }
%"struct.std::__1::__compressed_pair_elem.584" = type { %"struct.std::__1::__hash_node_base.585"** }
%"struct.std::__1::__hash_node_base.585" = type { %"struct.std::__1::__hash_node_base.585"* }
%"struct.std::__1::__compressed_pair_elem.586" = type { %"class.std::__1::__bucket_list_deallocator.587" }
%"class.std::__1::__bucket_list_deallocator.587" = type { %"class.std::__1::__compressed_pair.588" }
%"class.std::__1::__compressed_pair.588" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.592" = type { %"struct.std::__1::__compressed_pair_elem.593" }
%"struct.std::__1::__compressed_pair_elem.593" = type { %"struct.std::__1::__hash_node_base.585" }
%"class.std::__1::__compressed_pair.597" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.600" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.std::__1::unordered_map.554" = type { %"class.std::__1::__hash_table.555" }
%"class.std::__1::__hash_table.555" = type <{ %"class.std::__1::unique_ptr.556", %"class.std::__1::__compressed_pair.566", %"class.std::__1::__compressed_pair.571", %"class.std::__1::__compressed_pair.574", [4 x i8] }>
%"class.std::__1::unique_ptr.556" = type { %"class.std::__1::__compressed_pair.557" }
%"class.std::__1::__compressed_pair.557" = type { %"struct.std::__1::__compressed_pair_elem.558", %"struct.std::__1::__compressed_pair_elem.560" }
%"struct.std::__1::__compressed_pair_elem.558" = type { %"struct.std::__1::__hash_node_base.559"** }
%"struct.std::__1::__hash_node_base.559" = type { %"struct.std::__1::__hash_node_base.559"* }
%"struct.std::__1::__compressed_pair_elem.560" = type { %"class.std::__1::__bucket_list_deallocator.561" }
%"class.std::__1::__bucket_list_deallocator.561" = type { %"class.std::__1::__compressed_pair.562" }
%"class.std::__1::__compressed_pair.562" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.566" = type { %"struct.std::__1::__compressed_pair_elem.567" }
%"struct.std::__1::__compressed_pair_elem.567" = type { %"struct.std::__1::__hash_node_base.559" }
%"class.std::__1::__compressed_pair.571" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.574" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.std::__1::unordered_map.604" = type { %"class.std::__1::__hash_table.605" }
%"class.std::__1::__hash_table.605" = type <{ %"class.std::__1::unique_ptr.606", %"class.std::__1::__compressed_pair.616", %"class.std::__1::__compressed_pair.621", %"class.std::__1::__compressed_pair.626", [4 x i8] }>
%"class.std::__1::unique_ptr.606" = type { %"class.std::__1::__compressed_pair.607" }
%"class.std::__1::__compressed_pair.607" = type { %"struct.std::__1::__compressed_pair_elem.608", %"struct.std::__1::__compressed_pair_elem.610" }
%"struct.std::__1::__compressed_pair_elem.608" = type { %"struct.std::__1::__hash_node_base.609"** }
%"struct.std::__1::__hash_node_base.609" = type { %"struct.std::__1::__hash_node_base.609"* }
%"struct.std::__1::__compressed_pair_elem.610" = type { %"class.std::__1::__bucket_list_deallocator.611" }
%"class.std::__1::__bucket_list_deallocator.611" = type { %"class.std::__1::__compressed_pair.612" }
%"class.std::__1::__compressed_pair.612" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.616" = type { %"struct.std::__1::__compressed_pair_elem.617" }
%"struct.std::__1::__compressed_pair_elem.617" = type { %"struct.std::__1::__hash_node_base.609" }
%"class.std::__1::__compressed_pair.621" = type { %"struct.std::__1::__compressed_pair_elem.7" }
%"class.std::__1::__compressed_pair.626" = type { %"struct.std::__1::__compressed_pair_elem.17" }
%"class.std::__1::vector.632" = type { %"class.std::__1::__vector_base.633" }
%"class.std::__1::__vector_base.633" = type { %"class.v8::internal::HeapObjectAllocationTracker"**, %"class.v8::internal::HeapObjectAllocationTracker"**, %"class.std::__1::__compressed_pair.634" }
%"class.std::__1::__compressed_pair.634" = type { %"struct.std::__1::__compressed_pair_elem.635" }
%"struct.std::__1::__compressed_pair_elem.635" = type { %"class.v8::internal::HeapObjectAllocationTracker"** }
%"class.std::__1::unique_ptr.639" = type { %"class.std::__1::__compressed_pair.640" }
%"class.std::__1::__compressed_pair.640" = type { %"struct.std::__1::__compressed_pair_elem.641" }
%"struct.std::__1::__compressed_pair_elem.641" = type { %"class.v8::internal::third_party_heap::Heap"* }
%"class.v8::internal::third_party_heap::Heap" = type { i8 }
%"struct.std::__1::atomic.19" = type { %"struct.std::__1::__atomic_base.20" }
%"struct.std::__1::__atomic_base.20" = type { %"struct.std::__1::__atomic_base.21" }
%"struct.std::__1::__atomic_base.21" = type { %"struct.std::__1::__cxx_atomic_impl.22" }
%"struct.std::__1::__cxx_atomic_impl.22" = type { %"struct.std::__1::__cxx_atomic_base_impl.23" }
%"struct.std::__1::__cxx_atomic_base_impl.23" = type { i64 }
%"class.v8::internal::AllocationStats" = type { %"struct.std::__1::atomic.19", i64, %"struct.std::__1::atomic.19" }
%"class.std::__1::vector.139" = type { %"class.std::__1::__vector_base.140" }
%"class.std::__1::__vector_base.140" = type { %"class.v8::internal::ReadOnlyPage"**, %"class.v8::internal::ReadOnlyPage"**, %"class.std::__1::__compressed_pair.141" }
%"class.v8::internal::ReadOnlyPage" = type { %"class.v8::internal::BasicMemoryChunk" }
%"class.std::__1::__compressed_pair.141" = type { %"struct.std::__1::__compressed_pair_elem.142" }
%"struct.std::__1::__compressed_pair_elem.142" = type { %"class.v8::internal::ReadOnlyPage"** }
%"class.std::__1::vector.541" = type { %"class.std::__1::__vector_base.542" }
%"class.std::__1::__vector_base.542" = type { %"class.v8::internal::Object"*, %"class.v8::internal::Object"*, %"class.std::__1::__compressed_pair.543" }
%"class.std::__1::__compressed_pair.543" = type { %"struct.std::__1::__compressed_pair_elem.544" }
%"struct.std::__1::__compressed_pair_elem.544" = type { %"class.v8::internal::Object"* }
%"class.v8::internal::FactoryBase" = type { i8 }
%"class.v8::internal::OrderedHashSet" = type { %"class.v8::internal::OrderedHashTable" }
%"class.v8::internal::OrderedHashTable" = type { %"class.v8::internal::FixedArray" }
%"class.v8::internal::JSReceiver" = type { %"class.v8::internal::HeapObject" }
%"class.v8::internal::OrderedHashMap" = type { %"class.v8::internal::OrderedHashTable.1134" }
%"class.v8::internal::OrderedHashTable.1134" = type { %"class.v8::internal::FixedArray" }
%"class.v8::internal::FactoryBase.1048" = type { i8 }
%"class.v8::internal::OrderedNameDictionary" = type { %"class.v8::internal::OrderedHashTable.1136" }
%"class.v8::internal::OrderedHashTable.1136" = type { %"class.v8::internal::FixedArray" }
%"class.v8::internal::SmallOrderedHashTable" = type { %"class.v8::internal::HeapObject" }
%"class.v8::internal::Factory" = type { i8 }
%"class.v8::internal::SmallOrderedHashSet" = type { %"class.v8::internal::SmallOrderedHashTable" }
%"class.v8::internal::SmallOrderedHashTable.1143" = type { %"class.v8::internal::HeapObject" }
%"class.v8::internal::SmallOrderedHashMap" = type { %"class.v8::internal::SmallOrderedHashTable.1143" }
%"class.v8::internal::SmallOrderedHashTable.1146" = type { %"class.v8::internal::HeapObject" }
%"class.v8::internal::Handle<v8::internal::SmallOrderedHashSet>::ObjectRef" = type { %"class.v8::internal::SmallOrderedHashSet" }
%"class.v8::internal::Handle<v8::internal::SmallOrderedHashMap>::ObjectRef" = type { %"class.v8::internal::SmallOrderedHashMap" }
%"class.v8::internal::OrderedHashTableIterator" = type { %"class.v8::internal::JSCollectionIterator" }
%"class.v8::internal::JSCollectionIterator" = type { %"class.v8::internal::TorqueGeneratedJSCollectionIterator" }
%"class.v8::internal::TorqueGeneratedJSCollectionIterator" = type { %"class.v8::internal::JSObject" }
%"class.v8::internal::JSObject" = type { %"class.v8::internal::TorqueGeneratedJSObject" }
%"class.v8::internal::TorqueGeneratedJSObject" = type { %"class.v8::internal::JSReceiver" }
%"class.v8::internal::OrderedHashTableIterator.1149" = type { %"class.v8::internal::JSCollectionIterator" }
%"class.v8::internal::Handle<v8::internal::Object>::ObjectRef" = type { %"class.v8::internal::Object" }
%"class.v8::internal::Handle<v8::internal::OrderedNameDictionary>::ObjectRef" = type { %"class.v8::internal::OrderedNameDictionary" }
%"class.v8::internal::SmallOrderedNameDictionary" = type { %"class.v8::internal::SmallOrderedHashTable.1146" }
%"class.v8::internal::Handle<v8::internal::SmallOrderedNameDictionary>::ObjectRef" = type { %"class.v8::internal::SmallOrderedNameDictionary" }
%"class.v8::internal::String" = type { %"class.v8::internal::TorqueGeneratedString" }
%"class.v8::internal::TorqueGeneratedString" = type { %"class.v8::internal::Name" }
%"class.v8::internal::SharedFunctionInfo" = type { %"class.v8::internal::TorqueGeneratedSharedFunctionInfo" }
%"class.v8::internal::TorqueGeneratedSharedFunctionInfo" = type { %"class.v8::internal::HeapObject" }

$_ZN2v88internal16OrderedHashTableINS0_14OrderedHashSetELi1EE14EnsureGrowableINS0_7IsolateEEENS0_11MaybeHandleIS2_EEPT_NS0_6HandleIS2_EE = comdat any

$_ZN2v88internal16OrderedHashTableINS0_14OrderedHashSetELi1EE6ShrinkEPNS0_7IsolateENS0_6HandleIS2_EE = comdat any

$_ZN2v88internal16OrderedHashTableINS0_14OrderedHashSetELi1EE5ClearEPNS0_7IsolateENS0_6HandleIS2_EE = comdat any

$_ZN2v88internal14OrderedHashSet8AllocateINS0_7IsolateEEENS0_11MaybeHandleIS1_EEPT_iNS0_14AllocationTypeE = comdat any

$_ZN2v88internal16OrderedHashTableINS0_14OrderedHashSetELi1EE6HasKeyEPNS0_7IsolateES2_NS0_6ObjectE = comdat any

$_ZN2v88internal16OrderedHashTableINS0_14OrderedHashSetELi1EE9FindEntryEPNS0_7IsolateENS0_6ObjectE = comdat any

$_ZN2v88internal16OrderedHashTableINS0_14OrderedHashSetELi1EE6DeleteEPNS0_7IsolateES2_NS0_6ObjectE = comdat any

$_ZN2v88internal16OrderedHashTableINS0_14OrderedHashMapELi2EE14EnsureGrowableINS0_7IsolateEEENS0_11MaybeHandleIS2_EEPT_NS0_6HandleIS2_EE = comdat any

$_ZN2v88internal16OrderedHashTableINS0_14OrderedHashMapELi2EE6ShrinkEPNS0_7IsolateENS0_6HandleIS2_EE = comdat any

$_ZN2v88internal16OrderedHashTableINS0_14OrderedHashMapELi2EE5ClearEPNS0_7IsolateENS0_6HandleIS2_EE = comdat any

$_ZN2v88internal14OrderedHashMap8AllocateINS0_7IsolateEEENS0_11MaybeHandleIS1_EEPT_iNS0_14AllocationTypeE = comdat any

$_ZN2v88internal16OrderedHashTableINS0_14OrderedHashMapELi2EE6HasKeyEPNS0_7IsolateES2_NS0_6ObjectE = comdat any

$_ZN2v88internal16OrderedHashTableINS0_14OrderedHashMapELi2EE9FindEntryEPNS0_7IsolateENS0_6ObjectE = comdat any

$_ZN2v88internal16OrderedHashTableINS0_14OrderedHashMapELi2EE6DeleteEPNS0_7IsolateES2_NS0_6ObjectE = comdat any

$_ZN2v88internal16OrderedHashTableINS0_21OrderedNameDictionaryELi3EE6ShrinkEPNS0_7IsolateENS0_6HandleIS2_EE = comdat any

$_ZN2v88internal21OrderedNameDictionary6RehashINS0_7IsolateEEENS0_11MaybeHandleIS1_EEPT_NS0_6HandleIS1_EEi = comdat any

$_ZN2v88internal16OrderedHashTableINS0_21OrderedNameDictionaryELi3EE14EnsureGrowableINS0_7IsolateEEENS0_11MaybeHandleIS2_EEPT_NS0_6HandleIS2_EE = comdat any

$_ZN2v88internal21OrderedNameDictionary8AllocateINS0_7IsolateEEENS0_11MaybeHandleIS1_EEPT_iNS0_14AllocationTypeE = comdat any

$_ZN2v88internal21OrderedNameDictionary8AllocateINS0_12LocalIsolateEEENS0_11MaybeHandleIS1_EEPT_iNS0_14AllocationTypeE = comdat any

$_ZN2v88internal16OrderedHashTableINS0_21OrderedNameDictionaryELi3EE6RehashINS0_7IsolateEEENS0_11MaybeHandleIS2_EEPT_NS0_6HandleIS2_EEi = comdat any

$_ZN2v88internal21OrderedNameDictionary9FindEntryINS0_7IsolateEEENS0_13InternalIndexEPT_NS0_6ObjectE = comdat any

$_ZN2v88internal21OrderedNameDictionary9FindEntryINS0_12LocalIsolateEEENS0_13InternalIndexEPT_NS0_6ObjectE = comdat any

$_ZN2v88internal21OrderedNameDictionary3AddINS0_7IsolateEEENS0_11MaybeHandleIS1_EEPT_NS0_6HandleIS1_EENS8_INS0_4NameEEENS8_INS0_6ObjectEEENS0_15PropertyDetailsE = comdat any

$_ZN2v88internal21OrderedNameDictionary3AddINS0_12LocalIsolateEEENS0_11MaybeHandleIS1_EEPT_NS0_6HandleIS1_EENS8_INS0_4NameEEENS8_INS0_6ObjectEEENS0_15PropertyDetailsE = comdat any

$_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashSetEE6HasKeyEPNS0_7IsolateENS0_6HandleINS0_6ObjectEEE = comdat any

$_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashSetEE9FindEntryEPNS0_7IsolateENS0_6ObjectE = comdat any

$_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashSetEE6RehashEPNS0_7IsolateENS0_6HandleIS2_EEi = comdat any

$_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashSetEE6ShrinkEPNS0_7IsolateENS0_6HandleIS2_EE = comdat any

$_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashSetEE4GrowEPNS0_7IsolateENS0_6HandleIS2_EE = comdat any

$_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashSetEE10InitializeEPNS0_7IsolateEi = comdat any

$_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashSetEE6DeleteEPNS0_7IsolateES2_NS0_6ObjectE = comdat any

$_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashMapEE6HasKeyEPNS0_7IsolateENS0_6HandleINS0_6ObjectEEE = comdat any

$_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashMapEE9FindEntryEPNS0_7IsolateENS0_6ObjectE = comdat any

$_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashMapEE6RehashEPNS0_7IsolateENS0_6HandleIS2_EEi = comdat any

$_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashMapEE6ShrinkEPNS0_7IsolateENS0_6HandleIS2_EE = comdat any

$_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashMapEE4GrowEPNS0_7IsolateENS0_6HandleIS2_EE = comdat any

$_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashMapEE10InitializeEPNS0_7IsolateEi = comdat any

$_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashMapEE6DeleteEPNS0_7IsolateES2_NS0_6ObjectE = comdat any

$_ZN2v88internal21SmallOrderedHashTableINS0_26SmallOrderedNameDictionaryEE10InitializeEPNS0_7IsolateEi = comdat any

$_ZN2v88internal21SmallOrderedHashTableINS0_26SmallOrderedNameDictionaryEE6ShrinkEPNS0_7IsolateENS0_6HandleIS2_EE = comdat any

$_ZN2v88internal23OrderedHashTableHandlerINS0_19SmallOrderedHashSetENS0_14OrderedHashSetEE8AllocateEPNS0_7IsolateEi = comdat any

$_ZN2v88internal23OrderedHashTableHandlerINS0_19SmallOrderedHashMapENS0_14OrderedHashMapEE8AllocateEPNS0_7IsolateEi = comdat any

$_ZN2v88internal23OrderedHashTableHandlerINS0_26SmallOrderedNameDictionaryENS0_21OrderedNameDictionaryEE8AllocateEPNS0_7IsolateEi = comdat any

$_ZN2v88internal23OrderedHashTableHandlerINS0_19SmallOrderedHashSetENS0_14OrderedHashSetEE6HasKeyEPNS0_7IsolateENS0_6HandleINS0_10HeapObjectEEENS7_INS0_6ObjectEEE = comdat any

$_ZN2v88internal23OrderedHashTableHandlerINS0_19SmallOrderedHashMapENS0_14OrderedHashMapEE6HasKeyEPNS0_7IsolateENS0_6HandleINS0_10HeapObjectEEENS7_INS0_6ObjectEEE = comdat any

$_ZN2v88internal23OrderedHashTableHandlerINS0_19SmallOrderedHashSetENS0_14OrderedHashSetEE6DeleteEPNS0_7IsolateENS0_6HandleINS0_10HeapObjectEEENS7_INS0_6ObjectEEE = comdat any

$_ZN2v88internal23OrderedHashTableHandlerINS0_19SmallOrderedHashMapENS0_14OrderedHashMapEE6DeleteEPNS0_7IsolateENS0_6HandleINS0_10HeapObjectEEENS7_INS0_6ObjectEEE = comdat any

$_ZN2v88internal23OrderedHashTableHandlerINS0_26SmallOrderedNameDictionaryENS0_21OrderedNameDictionaryEE6DeleteEPNS0_7IsolateENS0_6HandleINS0_10HeapObjectEEENS7_INS0_6ObjectEEE = comdat any

$_ZN2v88internal21SmallOrderedHashTableINS0_26SmallOrderedNameDictionaryEE6DeleteEPNS0_7IsolateES2_NS0_6ObjectE = comdat any

$_ZN2v88internal16OrderedHashTableINS0_21OrderedNameDictionaryELi3EE6DeleteEPNS0_7IsolateES2_NS0_6ObjectE = comdat any

$_ZN2v88internal24OrderedHashTableIteratorINS0_13JSSetIteratorENS0_14OrderedHashSetEE7HasMoreEv = comdat any

$_ZN2v88internal24OrderedHashTableIteratorINS0_13JSSetIteratorENS0_14OrderedHashSetEE10TransitionEv = comdat any

$_ZN2v88internal24OrderedHashTableIteratorINS0_13JSSetIteratorENS0_14OrderedHashSetEE8MoveNextEv = comdat any

$_ZN2v88internal24OrderedHashTableIteratorINS0_13JSSetIteratorENS0_14OrderedHashSetEE10CurrentKeyEv = comdat any

$_ZN2v88internal24OrderedHashTableIteratorINS0_13JSMapIteratorENS0_14OrderedHashMapEE7HasMoreEv = comdat any

$_ZN2v88internal24OrderedHashTableIteratorINS0_13JSMapIteratorENS0_14OrderedHashMapEE10TransitionEv = comdat any

$_ZN2v88internal24OrderedHashTableIteratorINS0_13JSMapIteratorENS0_14OrderedHashMapEE8MoveNextEv = comdat any

$_ZN2v88internal24OrderedHashTableIteratorINS0_13JSMapIteratorENS0_14OrderedHashMapEE10CurrentKeyEv = comdat any

$_ZN2v88internal16OrderedHashTableINS0_14OrderedHashSetELi1EE6RehashINS0_7IsolateEEENS0_11MaybeHandleIS2_EEPT_NS0_6HandleIS2_EEi = comdat any

$_ZN2v88internal16OrderedHashTableINS0_14OrderedHashMapELi2EE6RehashINS0_7IsolateEEENS0_11MaybeHandleIS2_EEPT_NS0_6HandleIS2_EEi = comdat any

$_ZN2v88internal21SmallOrderedHashTableINS0_26SmallOrderedNameDictionaryEE6RehashEPNS0_7IsolateENS0_6HandleIS2_EEi = comdat any

$_ZN2v88internal6Object13GetSimpleHashES1_ = comdat any

$_ZN2v88internal16OrderedHashTableINS0_21OrderedNameDictionaryELi3EE6RehashINS0_12LocalIsolateEEENS0_11MaybeHandleIS2_EEPT_NS0_6HandleIS2_EEi = comdat any

@.str = private unnamed_addr constant [18 x i8] c"Check failed: %s.\00", align 1
@.str.1 = private unnamed_addr constant [13 x i8] c"key.IsName()\00", align 1
@_ZN2v88internal16SoleReadOnlyHeap15shared_ro_heap_E = external local_unnamed_addr global %"class.v8::internal::SoleReadOnlyHeap"*, align 8
@.str.2 = private unnamed_addr constant [23 x i8] c"(location_) != nullptr\00", align 1

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal16OrderedHashTableINS0_14OrderedHashSetELi1EE14EnsureGrowableINS0_7IsolateEEENS0_11MaybeHandleIS2_EEPT_NS0_6HandleIS2_EE(%"class.v8::internal::Isolate"*, i64*) local_unnamed_addr #0 comdat align 2 {
  %3 = load i64, i64* %1, align 8
  %4 = add i64 %3, 7
  %5 = inttoptr i64 %4 to i32*
  %6 = load atomic i32, i32* %5 monotonic, align 4
  %7 = ashr i32 %6, 1
  %8 = add i64 %3, 11
  %9 = inttoptr i64 %8 to i32*
  %10 = load atomic i32, i32* %9 monotonic, align 4
  %11 = ashr i32 %10, 1
  %12 = add i64 %3, 15
  %13 = inttoptr i64 %12 to i32*
  %14 = load atomic i32, i32* %13 monotonic, align 4
  %15 = and i32 %14, -2
  %16 = add nsw i32 %11, %7
  %17 = icmp slt i32 %16, %15
  br i1 %17, label %28, label %18

18:                                               ; preds = %2
  %19 = icmp eq i32 %15, 0
  br i1 %19, label %25, label %20

20:                                               ; preds = %18
  %21 = ashr i32 %14, 1
  %22 = icmp slt i32 %11, %21
  %23 = zext i1 %22 to i32
  %24 = shl i32 %15, %23
  br label %25

25:                                               ; preds = %20, %18
  %26 = phi i32 [ 4, %18 ], [ %24, %20 ]
  %27 = tail call i64* @_ZN2v88internal16OrderedHashTableINS0_14OrderedHashSetELi1EE6RehashINS0_7IsolateEEENS0_11MaybeHandleIS2_EEPT_NS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"* %0, i64* %1, i32 %26) #7
  br label %28

28:                                               ; preds = %2, %25
  %29 = phi i64* [ %27, %25 ], [ %1, %2 ]
  ret i64* %29
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: nounwind ssp uwtable
define hidden i64* @_ZN2v88internal14OrderedHashSet6RehashEPNS0_7IsolateENS0_6HandleIS1_EEi(%"class.v8::internal::Isolate"*, i64*, i32) local_unnamed_addr #0 align 2 {
  %4 = tail call i64* @_ZN2v88internal16OrderedHashTableINS0_14OrderedHashSetELi1EE6RehashINS0_7IsolateEEENS0_11MaybeHandleIS2_EEPT_NS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"* %0, i64* %1, i32 %2)
  ret i64* %4
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal16OrderedHashTableINS0_14OrderedHashSetELi1EE6ShrinkEPNS0_7IsolateENS0_6HandleIS2_EE(%"class.v8::internal::Isolate"*, i64*) local_unnamed_addr #0 comdat align 2 {
  %3 = load i64, i64* %1, align 8
  %4 = add i64 %3, 7
  %5 = inttoptr i64 %4 to i32*
  %6 = load atomic i32, i32* %5 monotonic, align 4
  %7 = ashr i32 %6, 1
  %8 = add i64 %3, 15
  %9 = inttoptr i64 %8 to i32*
  %10 = load atomic i32, i32* %9 monotonic, align 4
  %11 = ashr i32 %10, 2
  %12 = icmp slt i32 %7, %11
  br i1 %12, label %13, label %19

13:                                               ; preds = %2
  %14 = and i32 %10, -2
  %15 = sdiv i32 %14, 2
  %16 = tail call i64* @_ZN2v88internal16OrderedHashTableINS0_14OrderedHashSetELi1EE6RehashINS0_7IsolateEEENS0_11MaybeHandleIS2_EEPT_NS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"* %0, i64* %1, i32 %15) #7
  %17 = icmp eq i64* %16, null
  br i1 %17, label %18, label %19, !prof !2

18:                                               ; preds = %13
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.2, i64 0, i64 0)) #8
  unreachable

19:                                               ; preds = %13, %2
  %20 = phi i64* [ %1, %2 ], [ %16, %13 ]
  ret i64* %20
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal16OrderedHashTableINS0_14OrderedHashSetELi1EE5ClearEPNS0_7IsolateENS0_6HandleIS2_EE(%"class.v8::internal::Isolate"*, i64*) local_unnamed_addr #0 comdat align 2 {
  %3 = load i64, i64* %1, align 8
  %4 = and i64 %3, -262144
  %5 = inttoptr i64 %4 to %"class.v8::internal::BasicMemoryChunk"*
  %6 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %5, i64 0, i32 1
  %7 = load i64, i64* %6, align 8
  %8 = tail call i32 @_ZN2v84base4bits21RoundUpToPowerOfTwo32Ej(i32 4) #7
  %9 = icmp sgt i32 %8, 26843544
  br i1 %9, label %81, label %10

10:                                               ; preds = %2
  %11 = and i64 %7, 24
  %12 = icmp eq i64 %11, 0
  %13 = zext i1 %12 to i8
  %14 = sdiv i32 %8, 2
  %15 = bitcast %"class.v8::internal::Isolate"* %0 to %"class.v8::internal::FactoryBase"*
  %16 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 55
  %17 = add nsw i32 %14, 3
  %18 = shl i32 %8, 1
  %19 = add nsw i32 %17, %18
  %20 = tail call i64* @_ZN2v88internal11FactoryBaseINS0_7FactoryEE20NewFixedArrayWithMapENS0_6HandleINS0_3MapEEEiNS0_14AllocationTypeE(%"class.v8::internal::FactoryBase"* %15, i64* %16, i32 %19, i8 zeroext %13) #7
  %21 = icmp sgt i32 %8, 1
  %22 = load i64, i64* %20, align 8
  br i1 %21, label %23, label %69

23:                                               ; preds = %10
  %24 = zext i32 %14 to i64
  %25 = and i64 %24, 1
  %26 = and i32 %8, -2
  %27 = icmp eq i32 %26, 2
  br i1 %27, label %59, label %28

28:                                               ; preds = %23
  %29 = sub nsw i64 %24, %25
  br label %30

30:                                               ; preds = %30, %28
  %31 = phi i64 [ 0, %28 ], [ %50, %30 ]
  %32 = phi i64 [ %22, %28 ], [ %51, %30 ]
  %33 = phi i64 [ %29, %28 ], [ %52, %30 ]
  %34 = trunc i64 %31 to i32
  %35 = shl i32 %34, 2
  %36 = add i32 %35, 12
  %37 = sext i32 %36 to i64
  %38 = add i64 %32, 7
  %39 = add i64 %38, %37
  %40 = inttoptr i64 %39 to i32*
  store atomic volatile i32 -2, i32* %40 monotonic, align 4
  %41 = load i64, i64* %20, align 8
  %42 = trunc i64 %31 to i32
  %43 = shl i32 %42, 2
  %44 = or i32 %43, 4
  %45 = add i32 %44, 12
  %46 = sext i32 %45 to i64
  %47 = add i64 %41, 7
  %48 = add i64 %47, %46
  %49 = inttoptr i64 %48 to i32*
  store atomic volatile i32 -2, i32* %49 monotonic, align 4
  %50 = add nuw nsw i64 %31, 2
  %51 = load i64, i64* %20, align 8
  %52 = add i64 %33, -2
  %53 = icmp eq i64 %52, 0
  br i1 %53, label %54, label %30

54:                                               ; preds = %30
  %55 = trunc i64 %50 to i32
  %56 = shl i32 %55, 2
  %57 = add i32 %56, 12
  %58 = sext i32 %57 to i64
  br label %59

59:                                               ; preds = %54, %23
  %60 = phi i64 [ undef, %23 ], [ %51, %54 ]
  %61 = phi i64 [ 12, %23 ], [ %58, %54 ]
  %62 = phi i64 [ %22, %23 ], [ %51, %54 ]
  %63 = icmp eq i64 %25, 0
  br i1 %63, label %69, label %64

64:                                               ; preds = %59
  %65 = add i64 %62, 7
  %66 = add i64 %65, %61
  %67 = inttoptr i64 %66 to i32*
  store atomic volatile i32 -2, i32* %67 monotonic, align 4
  %68 = load i64, i64* %20, align 8
  br label %69

69:                                               ; preds = %64, %59, %10
  %70 = phi i64 [ %22, %10 ], [ %60, %59 ], [ %68, %64 ]
  %71 = shl nsw i32 %14, 1
  %72 = add i64 %70, 15
  %73 = inttoptr i64 %72 to i32*
  store atomic volatile i32 %71, i32* %73 monotonic, align 4
  %74 = load i64, i64* %20, align 8
  %75 = add i64 %74, 7
  %76 = inttoptr i64 %75 to i32*
  store atomic volatile i32 0, i32* %76 monotonic, align 4
  %77 = load i64, i64* %20, align 8
  %78 = add i64 %77, 11
  %79 = inttoptr i64 %78 to i32*
  store atomic volatile i32 0, i32* %79 monotonic, align 4
  %80 = icmp eq i64* %20, null
  br i1 %80, label %81, label %82, !prof !2

81:                                               ; preds = %2, %69
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.2, i64 0, i64 0)) #8
  unreachable

82:                                               ; preds = %69
  %83 = load i64, i64* %1, align 8
  %84 = add i64 %83, 15
  %85 = inttoptr i64 %84 to i32*
  %86 = load atomic i32, i32* %85 monotonic, align 4
  %87 = icmp sgt i32 %86, 1
  br i1 %87, label %88, label %122

88:                                               ; preds = %82
  %89 = load i64, i64* %20, align 8
  %90 = add i64 %83, 7
  %91 = inttoptr i64 %90 to i32*
  %92 = trunc i64 %89 to i32
  store atomic volatile i32 %92, i32* %91 monotonic, align 4
  %93 = and i64 %89, 1
  %94 = icmp eq i64 %93, 0
  br i1 %94, label %118, label %95

95:                                               ; preds = %88
  %96 = and i64 %83, -262144
  %97 = or i64 %96, 8
  %98 = inttoptr i64 %97 to i64*
  %99 = load i64, i64* %98, align 8
  %100 = and i64 %99, 262144
  %101 = icmp eq i64 %100, 0
  br i1 %101, label %106, label %102

102:                                              ; preds = %95
  %103 = or i64 %96, 16
  %104 = inttoptr i64 %103 to %"class.v8::internal::Heap"**
  %105 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %104, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %105, i64 %83, i64 %90, i64 %89) #7
  br label %106

106:                                              ; preds = %102, %95
  %107 = and i64 %89, -262144
  %108 = or i64 %107, 8
  %109 = inttoptr i64 %108 to i64*
  %110 = load i64, i64* %109, align 8
  %111 = and i64 %110, 24
  %112 = icmp eq i64 %111, 0
  br i1 %112, label %118, label %113

113:                                              ; preds = %106
  %114 = load i64, i64* %98, align 8
  %115 = and i64 %114, 24
  %116 = icmp eq i64 %115, 0
  br i1 %116, label %117, label %118

117:                                              ; preds = %113
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %83, i64 %90, i64 %89) #7
  br label %118

118:                                              ; preds = %88, %106, %113, %117
  %119 = load i64, i64* %1, align 8
  %120 = add i64 %119, 11
  %121 = inttoptr i64 %120 to i32*
  store atomic volatile i32 -2, i32* %121 monotonic, align 4
  br label %122

122:                                              ; preds = %118, %82
  ret i64* %20
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal14OrderedHashSet8AllocateINS0_7IsolateEEENS0_11MaybeHandleIS1_EEPT_iNS0_14AllocationTypeE(%"class.v8::internal::Isolate"*, i32, i8 zeroext) local_unnamed_addr #0 comdat align 2 {
  %4 = icmp sgt i32 %1, 4
  %5 = select i1 %4, i32 %1, i32 4
  %6 = tail call i32 @_ZN2v84base4bits21RoundUpToPowerOfTwo32Ej(i32 %5) #7
  %7 = icmp sgt i32 %6, 26843544
  br i1 %7, label %75, label %8

8:                                                ; preds = %3
  %9 = sdiv i32 %6, 2
  %10 = bitcast %"class.v8::internal::Isolate"* %0 to %"class.v8::internal::FactoryBase"*
  %11 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 55
  %12 = add nsw i32 %9, 3
  %13 = shl i32 %6, 1
  %14 = add nsw i32 %12, %13
  %15 = tail call i64* @_ZN2v88internal11FactoryBaseINS0_7FactoryEE20NewFixedArrayWithMapENS0_6HandleINS0_3MapEEEiNS0_14AllocationTypeE(%"class.v8::internal::FactoryBase"* %10, i64* %11, i32 %14, i8 zeroext %2) #7
  %16 = icmp sgt i32 %6, 1
  %17 = load i64, i64* %15, align 8
  br i1 %16, label %18, label %40

18:                                               ; preds = %8
  %19 = zext i32 %9 to i64
  %20 = and i64 %19, 1
  %21 = and i32 %6, -2
  %22 = icmp eq i32 %21, 2
  br i1 %22, label %30, label %23

23:                                               ; preds = %18
  %24 = sub nsw i64 %19, %20
  br label %51

25:                                               ; preds = %51
  %26 = trunc i64 %71 to i32
  %27 = shl i32 %26, 2
  %28 = add i32 %27, 12
  %29 = sext i32 %28 to i64
  br label %30

30:                                               ; preds = %25, %18
  %31 = phi i64 [ undef, %18 ], [ %72, %25 ]
  %32 = phi i64 [ 12, %18 ], [ %29, %25 ]
  %33 = phi i64 [ %17, %18 ], [ %72, %25 ]
  %34 = icmp eq i64 %20, 0
  br i1 %34, label %40, label %35

35:                                               ; preds = %30
  %36 = add i64 %33, 7
  %37 = add i64 %36, %32
  %38 = inttoptr i64 %37 to i32*
  store atomic volatile i32 -2, i32* %38 monotonic, align 4
  %39 = load i64, i64* %15, align 8
  br label %40

40:                                               ; preds = %35, %30, %8
  %41 = phi i64 [ %17, %8 ], [ %31, %30 ], [ %39, %35 ]
  %42 = shl nsw i32 %9, 1
  %43 = add i64 %41, 15
  %44 = inttoptr i64 %43 to i32*
  store atomic volatile i32 %42, i32* %44 monotonic, align 4
  %45 = load i64, i64* %15, align 8
  %46 = add i64 %45, 7
  %47 = inttoptr i64 %46 to i32*
  store atomic volatile i32 0, i32* %47 monotonic, align 4
  %48 = load i64, i64* %15, align 8
  %49 = add i64 %48, 11
  %50 = inttoptr i64 %49 to i32*
  store atomic volatile i32 0, i32* %50 monotonic, align 4
  br label %75

51:                                               ; preds = %51, %23
  %52 = phi i64 [ 0, %23 ], [ %71, %51 ]
  %53 = phi i64 [ %17, %23 ], [ %72, %51 ]
  %54 = phi i64 [ %24, %23 ], [ %73, %51 ]
  %55 = trunc i64 %52 to i32
  %56 = shl i32 %55, 2
  %57 = add i32 %56, 12
  %58 = sext i32 %57 to i64
  %59 = add i64 %53, 7
  %60 = add i64 %59, %58
  %61 = inttoptr i64 %60 to i32*
  store atomic volatile i32 -2, i32* %61 monotonic, align 4
  %62 = load i64, i64* %15, align 8
  %63 = trunc i64 %52 to i32
  %64 = shl i32 %63, 2
  %65 = or i32 %64, 4
  %66 = add i32 %65, 12
  %67 = sext i32 %66 to i64
  %68 = add i64 %62, 7
  %69 = add i64 %68, %67
  %70 = inttoptr i64 %69 to i32*
  store atomic volatile i32 -2, i32* %70 monotonic, align 4
  %71 = add nuw nsw i64 %52, 2
  %72 = load i64, i64* %15, align 8
  %73 = add i64 %54, -2
  %74 = icmp eq i64 %73, 0
  br i1 %74, label %25, label %51

75:                                               ; preds = %3, %40
  %76 = phi i64* [ %15, %40 ], [ null, %3 ]
  ret i64* %76
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden zeroext i1 @_ZN2v88internal16OrderedHashTableINS0_14OrderedHashSetELi1EE6HasKeyEPNS0_7IsolateES2_NS0_6ObjectE(%"class.v8::internal::Isolate"*, i64, i64) local_unnamed_addr #0 comdat align 2 {
  %4 = alloca %"class.v8::internal::OrderedHashSet", align 8
  %5 = getelementptr inbounds %"class.v8::internal::OrderedHashSet", %"class.v8::internal::OrderedHashSet"* %4, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %1, i64* %5, align 8
  %6 = getelementptr inbounds %"class.v8::internal::OrderedHashSet", %"class.v8::internal::OrderedHashSet"* %4, i64 0, i32 0
  %7 = call i64 @_ZN2v88internal16OrderedHashTableINS0_14OrderedHashSetELi1EE9FindEntryEPNS0_7IsolateENS0_6ObjectE(%"class.v8::internal::OrderedHashTable"* nonnull %6, %"class.v8::internal::Isolate"* %0, i64 %2)
  %8 = icmp ne i64 %7, -1
  ret i1 %8
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64 @_ZN2v88internal16OrderedHashTableINS0_14OrderedHashSetELi1EE9FindEntryEPNS0_7IsolateENS0_6ObjectE(%"class.v8::internal::OrderedHashTable"*, %"class.v8::internal::Isolate"*, i64) local_unnamed_addr #0 comdat align 2 {
  %4 = alloca %"class.v8::internal::JSReceiver", align 8
  %5 = alloca %"class.v8::internal::Object", align 8
  %6 = getelementptr inbounds %"class.v8::internal::OrderedHashTable", %"class.v8::internal::OrderedHashTable"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, 7
  %9 = inttoptr i64 %8 to i32*
  %10 = load atomic i32, i32* %9 monotonic, align 4
  %11 = icmp ult i32 %10, 2
  br i1 %11, label %145, label %12

12:                                               ; preds = %3
  %13 = and i64 %2, 1
  %14 = icmp eq i64 %13, 0
  br i1 %14, label %15, label %42

15:                                               ; preds = %12
  %16 = trunc i64 %2 to i32
  %17 = ashr i32 %16, 1
  %18 = xor i32 %17, -1
  %19 = shl i32 %17, 15
  %20 = add i32 %19, %18
  %21 = lshr i32 %20, 12
  %22 = xor i32 %21, %20
  %23 = mul i32 %22, 5
  %24 = lshr i32 %23, 4
  %25 = xor i32 %24, %23
  %26 = mul i32 %25, 2057
  %27 = lshr i32 %26, 16
  %28 = xor i32 %27, %26
  %29 = add i64 %7, 15
  %30 = inttoptr i64 %29 to i32*
  %31 = load atomic i32, i32* %30 monotonic, align 4
  %32 = lshr i32 %31, 1
  %33 = add nuw i32 %32, 1073741823
  %34 = and i32 %33, %28
  %35 = shl i32 %34, 2
  %36 = add i32 %35, 12
  %37 = sext i32 %36 to i64
  %38 = add i64 %8, %37
  %39 = inttoptr i64 %38 to i32*
  %40 = load atomic i32, i32* %39 monotonic, align 4
  %41 = ashr i32 %40, 1
  br label %100

42:                                               ; preds = %12
  %43 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %1, i64 0, i32 31
  %44 = bitcast %"struct.v8::internal::HandleScopeData"* %43 to i64*
  %45 = load i64, i64* %44, align 8
  %46 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %1, i64 0, i32 31, i32 1
  %47 = load i64*, i64** %46, align 8
  %48 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %1, i64 0, i32 31, i32 2
  %49 = load i32, i32* %48, align 8
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %48, align 8
  %51 = tail call i64 @_ZN2v88internal6Object13GetSimpleHashES1_(i64 %2) #7
  %52 = and i64 %51, 1
  %53 = icmp eq i64 %52, 0
  br i1 %53, label %58, label %54

54:                                               ; preds = %42
  %55 = bitcast %"class.v8::internal::JSReceiver"* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %55) #7
  %56 = getelementptr inbounds %"class.v8::internal::JSReceiver", %"class.v8::internal::JSReceiver"* %4, i64 0, i32 0, i32 0, i32 0, i32 0
  store i64 %2, i64* %56, align 8
  %57 = call i64 @_ZN2v88internal10JSReceiver15GetIdentityHashEv(%"class.v8::internal::JSReceiver"* nonnull %4) #7
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %55) #7
  br label %58

58:                                               ; preds = %42, %54
  %59 = phi i64 [ %57, %54 ], [ %51, %42 ]
  %60 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %1, i64 0, i32 0, i32 7, i32 0, i64 4
  %61 = load i64, i64* %60, align 8
  %62 = trunc i64 %59 to i32
  %63 = trunc i64 %61 to i32
  %64 = icmp eq i32 %62, %63
  br i1 %64, label %82, label %65

65:                                               ; preds = %58
  %66 = lshr i32 %62, 1
  %67 = load i64, i64* %6, align 8
  %68 = add i64 %67, 15
  %69 = inttoptr i64 %68 to i32*
  %70 = load atomic i32, i32* %69 monotonic, align 4
  %71 = lshr i32 %70, 1
  %72 = add nuw i32 %71, 1073741823
  %73 = and i32 %72, %66
  %74 = shl i32 %73, 2
  %75 = add i32 %74, 12
  %76 = sext i32 %75 to i64
  %77 = add i64 %67, 7
  %78 = add i64 %77, %76
  %79 = inttoptr i64 %78 to i32*
  %80 = load atomic i32, i32* %79 monotonic, align 4
  %81 = ashr i32 %80, 1
  br label %82

82:                                               ; preds = %58, %65
  %83 = phi i1 [ true, %65 ], [ false, %58 ]
  %84 = phi i32 [ %81, %65 ], [ undef, %58 ]
  %85 = icmp eq %"class.v8::internal::Isolate"* %1, null
  br i1 %85, label %99, label %86

86:                                               ; preds = %82
  %87 = inttoptr i64 %45 to i64*
  %88 = getelementptr inbounds %"struct.v8::internal::HandleScopeData", %"struct.v8::internal::HandleScopeData"* %43, i64 0, i32 0
  %89 = load i64*, i64** %88, align 8
  store i64 %45, i64* %44, align 8
  %90 = load i32, i32* %48, align 8
  %91 = add nsw i32 %90, -1
  store i32 %91, i32* %48, align 8
  %92 = load i64*, i64** %46, align 8
  %93 = icmp eq i64* %92, %47
  br i1 %93, label %96, label %94

94:                                               ; preds = %86
  store i64* %47, i64** %46, align 8
  call void @_ZN2v88internal11HandleScope16DeleteExtensionsEPNS0_7IsolateE(%"class.v8::internal::Isolate"* nonnull %1) #7
  %95 = load i64*, i64** %88, align 8
  br label %96

96:                                               ; preds = %94, %86
  %97 = phi i64* [ %95, %94 ], [ %87, %86 ]
  %98 = phi i64* [ %47, %94 ], [ %89, %86 ]
  call void @_ZN2v88internal11HandleScope8ZapRangeEPmS2_(i64* %97, i64* %98) #7
  br label %99

99:                                               ; preds = %82, %96
  br i1 %83, label %100, label %145

100:                                              ; preds = %99, %15
  %101 = phi i32 [ %41, %15 ], [ %84, %99 ]
  %102 = icmp eq i32 %101, -1
  br i1 %102, label %145, label %103

103:                                              ; preds = %100
  %104 = bitcast %"class.v8::internal::Object"* %5 to i8*
  %105 = getelementptr inbounds %"class.v8::internal::Object", %"class.v8::internal::Object"* %5, i64 0, i32 0, i32 0
  %106 = load i64, i64* %6, align 8
  br label %107

107:                                              ; preds = %103, %129
  %108 = phi i64 [ %106, %103 ], [ %130, %129 ]
  %109 = phi i32 [ %101, %103 ], [ %143, %129 ]
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %104) #7
  %110 = add i64 %108, 15
  %111 = inttoptr i64 %110 to i32*
  %112 = load atomic i32, i32* %111 monotonic, align 4
  %113 = lshr i32 %112, 1
  %114 = shl i32 %109, 1
  %115 = add i32 %114, 3
  %116 = add i32 %113, %115
  %117 = and i64 %108, -4294967296
  %118 = shl i32 %116, 2
  %119 = sext i32 %118 to i64
  %120 = add i64 %108, 7
  %121 = add i64 %120, %119
  %122 = inttoptr i64 %121 to i32*
  %123 = load atomic i32, i32* %122 monotonic, align 4
  %124 = zext i32 %123 to i64
  %125 = or i64 %117, %124
  store i64 %125, i64* %105, align 8
  %126 = call zeroext i1 @_ZN2v88internal6Object13SameValueZeroES1_(%"class.v8::internal::Object"* nonnull %5, i64 %2) #7
  br i1 %126, label %127, label %129

127:                                              ; preds = %107
  %128 = sext i32 %109 to i64
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %104) #7
  br label %145

129:                                              ; preds = %107
  %130 = load i64, i64* %6, align 8
  %131 = add i64 %130, 15
  %132 = inttoptr i64 %131 to i32*
  %133 = load atomic i32, i32* %132 monotonic, align 4
  %134 = lshr i32 %133, 1
  %135 = add i32 %134, %115
  %136 = shl i32 %135, 2
  %137 = add i32 %136, 4
  %138 = sext i32 %137 to i64
  %139 = add i64 %130, 7
  %140 = add i64 %139, %138
  %141 = inttoptr i64 %140 to i32*
  %142 = load atomic i32, i32* %141 monotonic, align 4
  %143 = ashr i32 %142, 1
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %104) #7
  %144 = icmp eq i32 %143, -1
  br i1 %144, label %145, label %107

145:                                              ; preds = %129, %100, %127, %3, %99
  %146 = phi i64 [ -1, %99 ], [ -1, %3 ], [ %128, %127 ], [ -1, %100 ], [ -1, %129 ]
  ret i64 %146
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden zeroext i1 @_ZN2v88internal16OrderedHashTableINS0_14OrderedHashSetELi1EE6DeleteEPNS0_7IsolateES2_NS0_6ObjectE(%"class.v8::internal::Isolate"*, i64, i64) local_unnamed_addr #0 comdat align 2 {
  %4 = alloca %"class.v8::internal::OrderedHashSet", align 8
  %5 = getelementptr inbounds %"class.v8::internal::OrderedHashSet", %"class.v8::internal::OrderedHashSet"* %4, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %1, i64* %5, align 8
  %6 = getelementptr inbounds %"class.v8::internal::OrderedHashSet", %"class.v8::internal::OrderedHashSet"* %4, i64 0, i32 0
  %7 = call i64 @_ZN2v88internal16OrderedHashTableINS0_14OrderedHashSetELi1EE9FindEntryEPNS0_7IsolateENS0_6ObjectE(%"class.v8::internal::OrderedHashTable"* nonnull %6, %"class.v8::internal::Isolate"* %0, i64 %2)
  %8 = icmp eq i64 %7, -1
  br i1 %8, label %79, label %9

9:                                                ; preds = %3
  %10 = load i64, i64* %5, align 8
  %11 = add i64 %10, 7
  %12 = inttoptr i64 %11 to i32*
  %13 = load atomic i32, i32* %12 monotonic, align 4
  %14 = add i64 %10, 11
  %15 = inttoptr i64 %14 to i32*
  %16 = load atomic i32, i32* %15 monotonic, align 4
  %17 = trunc i64 %7 to i32
  %18 = add i64 %10, 15
  %19 = inttoptr i64 %18 to i32*
  %20 = load atomic i32, i32* %19 monotonic, align 4
  %21 = lshr i32 %20, 1
  %22 = shl i32 %17, 1
  %23 = add i32 %22, 3
  %24 = add i32 %23, %21
  %25 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 5
  %26 = load i64, i64* %25, align 8
  %27 = trunc i64 %26 to i32
  %28 = and i64 %26, 1
  %29 = icmp eq i64 %28, 0
  %30 = and i64 %26, -262144
  %31 = or i64 %30, 8
  %32 = inttoptr i64 %31 to i64*
  %33 = shl i32 %24, 2
  %34 = sext i32 %33 to i64
  %35 = add nsw i64 %34, 7
  %36 = add i64 %10, %35
  %37 = inttoptr i64 %36 to i32*
  store atomic volatile i32 %27, i32* %37 monotonic, align 4
  %38 = load i64, i64* %5, align 8
  %39 = add i64 %38, %35
  br i1 %29, label %40, label %51

40:                                               ; preds = %9, %77, %70, %64
  %41 = phi i64 [ %38, %9 ], [ %78, %77 ], [ %66, %70 ], [ %66, %64 ]
  %42 = add i32 %13, -2
  %43 = and i32 %42, -2
  %44 = add i64 %41, 7
  %45 = inttoptr i64 %44 to i32*
  store atomic volatile i32 %43, i32* %45 monotonic, align 4
  %46 = add i32 %16, 2
  %47 = and i32 %46, -2
  %48 = load i64, i64* %5, align 8
  %49 = add i64 %48, 11
  %50 = inttoptr i64 %49 to i32*
  store atomic volatile i32 %47, i32* %50 monotonic, align 4
  br label %79

51:                                               ; preds = %9
  %52 = and i64 %38, -262144
  %53 = or i64 %52, 8
  %54 = inttoptr i64 %53 to i64*
  %55 = load i64, i64* %54, align 8
  %56 = and i64 %55, 262144
  %57 = icmp eq i64 %56, 0
  br i1 %57, label %64, label %58

58:                                               ; preds = %51
  %59 = or i64 %52, 16
  %60 = inttoptr i64 %59 to %"class.v8::internal::Heap"**
  %61 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %60, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %61, i64 %38, i64 %39, i64 %26) #7
  %62 = load i64, i64* %5, align 8
  %63 = add i64 %62, %35
  br label %64

64:                                               ; preds = %58, %51
  %65 = phi i64 [ %39, %51 ], [ %63, %58 ]
  %66 = phi i64 [ %38, %51 ], [ %62, %58 ]
  %67 = load i64, i64* %32, align 8
  %68 = and i64 %67, 24
  %69 = icmp eq i64 %68, 0
  br i1 %69, label %40, label %70

70:                                               ; preds = %64
  %71 = and i64 %66, -262144
  %72 = or i64 %71, 8
  %73 = inttoptr i64 %72 to i64*
  %74 = load i64, i64* %73, align 8
  %75 = and i64 %74, 24
  %76 = icmp eq i64 %75, 0
  br i1 %76, label %77, label %40

77:                                               ; preds = %70
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %66, i64 %65, i64 %26) #7
  %78 = load i64, i64* %5, align 8
  br label %40

79:                                               ; preds = %3, %40
  %80 = phi i1 [ true, %40 ], [ false, %3 ]
  ret i1 %80
}

declare zeroext i1 @_ZN2v88internal6Object13SameValueZeroES1_(%"class.v8::internal::Object"*, i64) local_unnamed_addr #2

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal16OrderedHashTableINS0_14OrderedHashMapELi2EE14EnsureGrowableINS0_7IsolateEEENS0_11MaybeHandleIS2_EEPT_NS0_6HandleIS2_EE(%"class.v8::internal::Isolate"*, i64*) local_unnamed_addr #0 comdat align 2 {
  %3 = load i64, i64* %1, align 8
  %4 = add i64 %3, 7
  %5 = inttoptr i64 %4 to i32*
  %6 = load atomic i32, i32* %5 monotonic, align 4
  %7 = ashr i32 %6, 1
  %8 = add i64 %3, 11
  %9 = inttoptr i64 %8 to i32*
  %10 = load atomic i32, i32* %9 monotonic, align 4
  %11 = ashr i32 %10, 1
  %12 = add i64 %3, 15
  %13 = inttoptr i64 %12 to i32*
  %14 = load atomic i32, i32* %13 monotonic, align 4
  %15 = and i32 %14, -2
  %16 = add nsw i32 %11, %7
  %17 = icmp slt i32 %16, %15
  br i1 %17, label %28, label %18

18:                                               ; preds = %2
  %19 = icmp eq i32 %15, 0
  br i1 %19, label %25, label %20

20:                                               ; preds = %18
  %21 = ashr i32 %14, 1
  %22 = icmp slt i32 %11, %21
  %23 = zext i1 %22 to i32
  %24 = shl i32 %15, %23
  br label %25

25:                                               ; preds = %20, %18
  %26 = phi i32 [ 4, %18 ], [ %24, %20 ]
  %27 = tail call i64* @_ZN2v88internal16OrderedHashTableINS0_14OrderedHashMapELi2EE6RehashINS0_7IsolateEEENS0_11MaybeHandleIS2_EEPT_NS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"* %0, i64* %1, i32 %26) #7
  br label %28

28:                                               ; preds = %2, %25
  %29 = phi i64* [ %27, %25 ], [ %1, %2 ]
  ret i64* %29
}

; Function Attrs: nounwind ssp uwtable
define hidden i64* @_ZN2v88internal14OrderedHashMap6RehashEPNS0_7IsolateENS0_6HandleIS1_EEi(%"class.v8::internal::Isolate"*, i64*, i32) local_unnamed_addr #0 align 2 {
  %4 = tail call i64* @_ZN2v88internal16OrderedHashTableINS0_14OrderedHashMapELi2EE6RehashINS0_7IsolateEEENS0_11MaybeHandleIS2_EEPT_NS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"* %0, i64* %1, i32 %2)
  ret i64* %4
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal16OrderedHashTableINS0_14OrderedHashMapELi2EE6ShrinkEPNS0_7IsolateENS0_6HandleIS2_EE(%"class.v8::internal::Isolate"*, i64*) local_unnamed_addr #0 comdat align 2 {
  %3 = load i64, i64* %1, align 8
  %4 = add i64 %3, 7
  %5 = inttoptr i64 %4 to i32*
  %6 = load atomic i32, i32* %5 monotonic, align 4
  %7 = ashr i32 %6, 1
  %8 = add i64 %3, 15
  %9 = inttoptr i64 %8 to i32*
  %10 = load atomic i32, i32* %9 monotonic, align 4
  %11 = ashr i32 %10, 2
  %12 = icmp slt i32 %7, %11
  br i1 %12, label %13, label %19

13:                                               ; preds = %2
  %14 = and i32 %10, -2
  %15 = sdiv i32 %14, 2
  %16 = tail call i64* @_ZN2v88internal16OrderedHashTableINS0_14OrderedHashMapELi2EE6RehashINS0_7IsolateEEENS0_11MaybeHandleIS2_EEPT_NS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"* %0, i64* %1, i32 %15) #7
  %17 = icmp eq i64* %16, null
  br i1 %17, label %18, label %19, !prof !2

18:                                               ; preds = %13
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.2, i64 0, i64 0)) #8
  unreachable

19:                                               ; preds = %13, %2
  %20 = phi i64* [ %1, %2 ], [ %16, %13 ]
  ret i64* %20
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal16OrderedHashTableINS0_14OrderedHashMapELi2EE5ClearEPNS0_7IsolateENS0_6HandleIS2_EE(%"class.v8::internal::Isolate"*, i64*) local_unnamed_addr #0 comdat align 2 {
  %3 = load i64, i64* %1, align 8
  %4 = and i64 %3, -262144
  %5 = inttoptr i64 %4 to %"class.v8::internal::BasicMemoryChunk"*
  %6 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %5, i64 0, i32 1
  %7 = load i64, i64* %6, align 8
  %8 = tail call i32 @_ZN2v84base4bits21RoundUpToPowerOfTwo32Ej(i32 4) #7
  %9 = icmp sgt i32 %8, 19173960
  br i1 %9, label %81, label %10

10:                                               ; preds = %2
  %11 = and i64 %7, 24
  %12 = icmp eq i64 %11, 0
  %13 = zext i1 %12 to i8
  %14 = sdiv i32 %8, 2
  %15 = bitcast %"class.v8::internal::Isolate"* %0 to %"class.v8::internal::FactoryBase"*
  %16 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 54
  %17 = add nsw i32 %14, 3
  %18 = mul nsw i32 %8, 3
  %19 = add nsw i32 %17, %18
  %20 = tail call i64* @_ZN2v88internal11FactoryBaseINS0_7FactoryEE20NewFixedArrayWithMapENS0_6HandleINS0_3MapEEEiNS0_14AllocationTypeE(%"class.v8::internal::FactoryBase"* %15, i64* %16, i32 %19, i8 zeroext %13) #7
  %21 = icmp sgt i32 %8, 1
  %22 = load i64, i64* %20, align 8
  br i1 %21, label %23, label %69

23:                                               ; preds = %10
  %24 = zext i32 %14 to i64
  %25 = and i64 %24, 1
  %26 = and i32 %8, -2
  %27 = icmp eq i32 %26, 2
  br i1 %27, label %59, label %28

28:                                               ; preds = %23
  %29 = sub nsw i64 %24, %25
  br label %30

30:                                               ; preds = %30, %28
  %31 = phi i64 [ 0, %28 ], [ %50, %30 ]
  %32 = phi i64 [ %22, %28 ], [ %51, %30 ]
  %33 = phi i64 [ %29, %28 ], [ %52, %30 ]
  %34 = trunc i64 %31 to i32
  %35 = shl i32 %34, 2
  %36 = add i32 %35, 12
  %37 = sext i32 %36 to i64
  %38 = add i64 %32, 7
  %39 = add i64 %38, %37
  %40 = inttoptr i64 %39 to i32*
  store atomic volatile i32 -2, i32* %40 monotonic, align 4
  %41 = load i64, i64* %20, align 8
  %42 = trunc i64 %31 to i32
  %43 = shl i32 %42, 2
  %44 = or i32 %43, 4
  %45 = add i32 %44, 12
  %46 = sext i32 %45 to i64
  %47 = add i64 %41, 7
  %48 = add i64 %47, %46
  %49 = inttoptr i64 %48 to i32*
  store atomic volatile i32 -2, i32* %49 monotonic, align 4
  %50 = add nuw nsw i64 %31, 2
  %51 = load i64, i64* %20, align 8
  %52 = add i64 %33, -2
  %53 = icmp eq i64 %52, 0
  br i1 %53, label %54, label %30

54:                                               ; preds = %30
  %55 = trunc i64 %50 to i32
  %56 = shl i32 %55, 2
  %57 = add i32 %56, 12
  %58 = sext i32 %57 to i64
  br label %59

59:                                               ; preds = %54, %23
  %60 = phi i64 [ undef, %23 ], [ %51, %54 ]
  %61 = phi i64 [ 12, %23 ], [ %58, %54 ]
  %62 = phi i64 [ %22, %23 ], [ %51, %54 ]
  %63 = icmp eq i64 %25, 0
  br i1 %63, label %69, label %64

64:                                               ; preds = %59
  %65 = add i64 %62, 7
  %66 = add i64 %65, %61
  %67 = inttoptr i64 %66 to i32*
  store atomic volatile i32 -2, i32* %67 monotonic, align 4
  %68 = load i64, i64* %20, align 8
  br label %69

69:                                               ; preds = %64, %59, %10
  %70 = phi i64 [ %22, %10 ], [ %60, %59 ], [ %68, %64 ]
  %71 = shl nsw i32 %14, 1
  %72 = add i64 %70, 15
  %73 = inttoptr i64 %72 to i32*
  store atomic volatile i32 %71, i32* %73 monotonic, align 4
  %74 = load i64, i64* %20, align 8
  %75 = add i64 %74, 7
  %76 = inttoptr i64 %75 to i32*
  store atomic volatile i32 0, i32* %76 monotonic, align 4
  %77 = load i64, i64* %20, align 8
  %78 = add i64 %77, 11
  %79 = inttoptr i64 %78 to i32*
  store atomic volatile i32 0, i32* %79 monotonic, align 4
  %80 = icmp eq i64* %20, null
  br i1 %80, label %81, label %82, !prof !2

81:                                               ; preds = %2, %69
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.2, i64 0, i64 0)) #8
  unreachable

82:                                               ; preds = %69
  %83 = load i64, i64* %1, align 8
  %84 = add i64 %83, 15
  %85 = inttoptr i64 %84 to i32*
  %86 = load atomic i32, i32* %85 monotonic, align 4
  %87 = icmp sgt i32 %86, 1
  br i1 %87, label %88, label %122

88:                                               ; preds = %82
  %89 = load i64, i64* %20, align 8
  %90 = add i64 %83, 7
  %91 = inttoptr i64 %90 to i32*
  %92 = trunc i64 %89 to i32
  store atomic volatile i32 %92, i32* %91 monotonic, align 4
  %93 = and i64 %89, 1
  %94 = icmp eq i64 %93, 0
  br i1 %94, label %118, label %95

95:                                               ; preds = %88
  %96 = and i64 %83, -262144
  %97 = or i64 %96, 8
  %98 = inttoptr i64 %97 to i64*
  %99 = load i64, i64* %98, align 8
  %100 = and i64 %99, 262144
  %101 = icmp eq i64 %100, 0
  br i1 %101, label %106, label %102

102:                                              ; preds = %95
  %103 = or i64 %96, 16
  %104 = inttoptr i64 %103 to %"class.v8::internal::Heap"**
  %105 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %104, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %105, i64 %83, i64 %90, i64 %89) #7
  br label %106

106:                                              ; preds = %102, %95
  %107 = and i64 %89, -262144
  %108 = or i64 %107, 8
  %109 = inttoptr i64 %108 to i64*
  %110 = load i64, i64* %109, align 8
  %111 = and i64 %110, 24
  %112 = icmp eq i64 %111, 0
  br i1 %112, label %118, label %113

113:                                              ; preds = %106
  %114 = load i64, i64* %98, align 8
  %115 = and i64 %114, 24
  %116 = icmp eq i64 %115, 0
  br i1 %116, label %117, label %118

117:                                              ; preds = %113
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %83, i64 %90, i64 %89) #7
  br label %118

118:                                              ; preds = %88, %106, %113, %117
  %119 = load i64, i64* %1, align 8
  %120 = add i64 %119, 11
  %121 = inttoptr i64 %120 to i32*
  store atomic volatile i32 -2, i32* %121 monotonic, align 4
  br label %122

122:                                              ; preds = %118, %82
  ret i64* %20
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal14OrderedHashMap8AllocateINS0_7IsolateEEENS0_11MaybeHandleIS1_EEPT_iNS0_14AllocationTypeE(%"class.v8::internal::Isolate"*, i32, i8 zeroext) local_unnamed_addr #0 comdat align 2 {
  %4 = icmp sgt i32 %1, 4
  %5 = select i1 %4, i32 %1, i32 4
  %6 = tail call i32 @_ZN2v84base4bits21RoundUpToPowerOfTwo32Ej(i32 %5) #7
  %7 = icmp sgt i32 %6, 19173960
  br i1 %7, label %75, label %8

8:                                                ; preds = %3
  %9 = sdiv i32 %6, 2
  %10 = bitcast %"class.v8::internal::Isolate"* %0 to %"class.v8::internal::FactoryBase"*
  %11 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 54
  %12 = add nsw i32 %9, 3
  %13 = mul nsw i32 %6, 3
  %14 = add nsw i32 %12, %13
  %15 = tail call i64* @_ZN2v88internal11FactoryBaseINS0_7FactoryEE20NewFixedArrayWithMapENS0_6HandleINS0_3MapEEEiNS0_14AllocationTypeE(%"class.v8::internal::FactoryBase"* %10, i64* %11, i32 %14, i8 zeroext %2) #7
  %16 = icmp sgt i32 %6, 1
  %17 = load i64, i64* %15, align 8
  br i1 %16, label %18, label %40

18:                                               ; preds = %8
  %19 = zext i32 %9 to i64
  %20 = and i64 %19, 1
  %21 = and i32 %6, -2
  %22 = icmp eq i32 %21, 2
  br i1 %22, label %30, label %23

23:                                               ; preds = %18
  %24 = sub nsw i64 %19, %20
  br label %51

25:                                               ; preds = %51
  %26 = trunc i64 %71 to i32
  %27 = shl i32 %26, 2
  %28 = add i32 %27, 12
  %29 = sext i32 %28 to i64
  br label %30

30:                                               ; preds = %25, %18
  %31 = phi i64 [ undef, %18 ], [ %72, %25 ]
  %32 = phi i64 [ 12, %18 ], [ %29, %25 ]
  %33 = phi i64 [ %17, %18 ], [ %72, %25 ]
  %34 = icmp eq i64 %20, 0
  br i1 %34, label %40, label %35

35:                                               ; preds = %30
  %36 = add i64 %33, 7
  %37 = add i64 %36, %32
  %38 = inttoptr i64 %37 to i32*
  store atomic volatile i32 -2, i32* %38 monotonic, align 4
  %39 = load i64, i64* %15, align 8
  br label %40

40:                                               ; preds = %35, %30, %8
  %41 = phi i64 [ %17, %8 ], [ %31, %30 ], [ %39, %35 ]
  %42 = shl nsw i32 %9, 1
  %43 = add i64 %41, 15
  %44 = inttoptr i64 %43 to i32*
  store atomic volatile i32 %42, i32* %44 monotonic, align 4
  %45 = load i64, i64* %15, align 8
  %46 = add i64 %45, 7
  %47 = inttoptr i64 %46 to i32*
  store atomic volatile i32 0, i32* %47 monotonic, align 4
  %48 = load i64, i64* %15, align 8
  %49 = add i64 %48, 11
  %50 = inttoptr i64 %49 to i32*
  store atomic volatile i32 0, i32* %50 monotonic, align 4
  br label %75

51:                                               ; preds = %51, %23
  %52 = phi i64 [ 0, %23 ], [ %71, %51 ]
  %53 = phi i64 [ %17, %23 ], [ %72, %51 ]
  %54 = phi i64 [ %24, %23 ], [ %73, %51 ]
  %55 = trunc i64 %52 to i32
  %56 = shl i32 %55, 2
  %57 = add i32 %56, 12
  %58 = sext i32 %57 to i64
  %59 = add i64 %53, 7
  %60 = add i64 %59, %58
  %61 = inttoptr i64 %60 to i32*
  store atomic volatile i32 -2, i32* %61 monotonic, align 4
  %62 = load i64, i64* %15, align 8
  %63 = trunc i64 %52 to i32
  %64 = shl i32 %63, 2
  %65 = or i32 %64, 4
  %66 = add i32 %65, 12
  %67 = sext i32 %66 to i64
  %68 = add i64 %62, 7
  %69 = add i64 %68, %67
  %70 = inttoptr i64 %69 to i32*
  store atomic volatile i32 -2, i32* %70 monotonic, align 4
  %71 = add nuw nsw i64 %52, 2
  %72 = load i64, i64* %15, align 8
  %73 = add i64 %54, -2
  %74 = icmp eq i64 %73, 0
  br i1 %74, label %25, label %51

75:                                               ; preds = %3, %40
  %76 = phi i64* [ %15, %40 ], [ null, %3 ]
  ret i64* %76
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden zeroext i1 @_ZN2v88internal16OrderedHashTableINS0_14OrderedHashMapELi2EE6HasKeyEPNS0_7IsolateES2_NS0_6ObjectE(%"class.v8::internal::Isolate"*, i64, i64) local_unnamed_addr #0 comdat align 2 {
  %4 = alloca %"class.v8::internal::OrderedHashMap", align 8
  %5 = getelementptr inbounds %"class.v8::internal::OrderedHashMap", %"class.v8::internal::OrderedHashMap"* %4, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %1, i64* %5, align 8
  %6 = getelementptr inbounds %"class.v8::internal::OrderedHashMap", %"class.v8::internal::OrderedHashMap"* %4, i64 0, i32 0
  %7 = call i64 @_ZN2v88internal16OrderedHashTableINS0_14OrderedHashMapELi2EE9FindEntryEPNS0_7IsolateENS0_6ObjectE(%"class.v8::internal::OrderedHashTable.1134"* nonnull %6, %"class.v8::internal::Isolate"* %0, i64 %2)
  %8 = icmp ne i64 %7, -1
  ret i1 %8
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64 @_ZN2v88internal16OrderedHashTableINS0_14OrderedHashMapELi2EE9FindEntryEPNS0_7IsolateENS0_6ObjectE(%"class.v8::internal::OrderedHashTable.1134"*, %"class.v8::internal::Isolate"*, i64) local_unnamed_addr #0 comdat align 2 {
  %4 = alloca %"class.v8::internal::JSReceiver", align 8
  %5 = alloca %"class.v8::internal::Object", align 8
  %6 = getelementptr inbounds %"class.v8::internal::OrderedHashTable.1134", %"class.v8::internal::OrderedHashTable.1134"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, 7
  %9 = inttoptr i64 %8 to i32*
  %10 = load atomic i32, i32* %9 monotonic, align 4
  %11 = icmp ult i32 %10, 2
  br i1 %11, label %145, label %12

12:                                               ; preds = %3
  %13 = and i64 %2, 1
  %14 = icmp eq i64 %13, 0
  br i1 %14, label %15, label %42

15:                                               ; preds = %12
  %16 = trunc i64 %2 to i32
  %17 = ashr i32 %16, 1
  %18 = xor i32 %17, -1
  %19 = shl i32 %17, 15
  %20 = add i32 %19, %18
  %21 = lshr i32 %20, 12
  %22 = xor i32 %21, %20
  %23 = mul i32 %22, 5
  %24 = lshr i32 %23, 4
  %25 = xor i32 %24, %23
  %26 = mul i32 %25, 2057
  %27 = lshr i32 %26, 16
  %28 = xor i32 %27, %26
  %29 = add i64 %7, 15
  %30 = inttoptr i64 %29 to i32*
  %31 = load atomic i32, i32* %30 monotonic, align 4
  %32 = lshr i32 %31, 1
  %33 = add nuw i32 %32, 1073741823
  %34 = and i32 %33, %28
  %35 = shl i32 %34, 2
  %36 = add i32 %35, 12
  %37 = sext i32 %36 to i64
  %38 = add i64 %8, %37
  %39 = inttoptr i64 %38 to i32*
  %40 = load atomic i32, i32* %39 monotonic, align 4
  %41 = ashr i32 %40, 1
  br label %100

42:                                               ; preds = %12
  %43 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %1, i64 0, i32 31
  %44 = bitcast %"struct.v8::internal::HandleScopeData"* %43 to i64*
  %45 = load i64, i64* %44, align 8
  %46 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %1, i64 0, i32 31, i32 1
  %47 = load i64*, i64** %46, align 8
  %48 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %1, i64 0, i32 31, i32 2
  %49 = load i32, i32* %48, align 8
  %50 = add nsw i32 %49, 1
  store i32 %50, i32* %48, align 8
  %51 = tail call i64 @_ZN2v88internal6Object13GetSimpleHashES1_(i64 %2) #7
  %52 = and i64 %51, 1
  %53 = icmp eq i64 %52, 0
  br i1 %53, label %58, label %54

54:                                               ; preds = %42
  %55 = bitcast %"class.v8::internal::JSReceiver"* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %55) #7
  %56 = getelementptr inbounds %"class.v8::internal::JSReceiver", %"class.v8::internal::JSReceiver"* %4, i64 0, i32 0, i32 0, i32 0, i32 0
  store i64 %2, i64* %56, align 8
  %57 = call i64 @_ZN2v88internal10JSReceiver15GetIdentityHashEv(%"class.v8::internal::JSReceiver"* nonnull %4) #7
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %55) #7
  br label %58

58:                                               ; preds = %42, %54
  %59 = phi i64 [ %57, %54 ], [ %51, %42 ]
  %60 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %1, i64 0, i32 0, i32 7, i32 0, i64 4
  %61 = load i64, i64* %60, align 8
  %62 = trunc i64 %59 to i32
  %63 = trunc i64 %61 to i32
  %64 = icmp eq i32 %62, %63
  br i1 %64, label %82, label %65

65:                                               ; preds = %58
  %66 = lshr i32 %62, 1
  %67 = load i64, i64* %6, align 8
  %68 = add i64 %67, 15
  %69 = inttoptr i64 %68 to i32*
  %70 = load atomic i32, i32* %69 monotonic, align 4
  %71 = lshr i32 %70, 1
  %72 = add nuw i32 %71, 1073741823
  %73 = and i32 %72, %66
  %74 = shl i32 %73, 2
  %75 = add i32 %74, 12
  %76 = sext i32 %75 to i64
  %77 = add i64 %67, 7
  %78 = add i64 %77, %76
  %79 = inttoptr i64 %78 to i32*
  %80 = load atomic i32, i32* %79 monotonic, align 4
  %81 = ashr i32 %80, 1
  br label %82

82:                                               ; preds = %58, %65
  %83 = phi i1 [ true, %65 ], [ false, %58 ]
  %84 = phi i32 [ %81, %65 ], [ undef, %58 ]
  %85 = icmp eq %"class.v8::internal::Isolate"* %1, null
  br i1 %85, label %99, label %86

86:                                               ; preds = %82
  %87 = inttoptr i64 %45 to i64*
  %88 = getelementptr inbounds %"struct.v8::internal::HandleScopeData", %"struct.v8::internal::HandleScopeData"* %43, i64 0, i32 0
  %89 = load i64*, i64** %88, align 8
  store i64 %45, i64* %44, align 8
  %90 = load i32, i32* %48, align 8
  %91 = add nsw i32 %90, -1
  store i32 %91, i32* %48, align 8
  %92 = load i64*, i64** %46, align 8
  %93 = icmp eq i64* %92, %47
  br i1 %93, label %96, label %94

94:                                               ; preds = %86
  store i64* %47, i64** %46, align 8
  call void @_ZN2v88internal11HandleScope16DeleteExtensionsEPNS0_7IsolateE(%"class.v8::internal::Isolate"* nonnull %1) #7
  %95 = load i64*, i64** %88, align 8
  br label %96

96:                                               ; preds = %94, %86
  %97 = phi i64* [ %95, %94 ], [ %87, %86 ]
  %98 = phi i64* [ %47, %94 ], [ %89, %86 ]
  call void @_ZN2v88internal11HandleScope8ZapRangeEPmS2_(i64* %97, i64* %98) #7
  br label %99

99:                                               ; preds = %82, %96
  br i1 %83, label %100, label %145

100:                                              ; preds = %99, %15
  %101 = phi i32 [ %41, %15 ], [ %84, %99 ]
  %102 = icmp eq i32 %101, -1
  br i1 %102, label %145, label %103

103:                                              ; preds = %100
  %104 = bitcast %"class.v8::internal::Object"* %5 to i8*
  %105 = getelementptr inbounds %"class.v8::internal::Object", %"class.v8::internal::Object"* %5, i64 0, i32 0, i32 0
  %106 = load i64, i64* %6, align 8
  br label %107

107:                                              ; preds = %103, %129
  %108 = phi i64 [ %106, %103 ], [ %130, %129 ]
  %109 = phi i32 [ %101, %103 ], [ %143, %129 ]
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %104) #7
  %110 = add i64 %108, 15
  %111 = inttoptr i64 %110 to i32*
  %112 = load atomic i32, i32* %111 monotonic, align 4
  %113 = lshr i32 %112, 1
  %114 = mul nsw i32 %109, 3
  %115 = add i32 %114, 3
  %116 = add i32 %113, %115
  %117 = and i64 %108, -4294967296
  %118 = shl i32 %116, 2
  %119 = sext i32 %118 to i64
  %120 = add i64 %108, 7
  %121 = add i64 %120, %119
  %122 = inttoptr i64 %121 to i32*
  %123 = load atomic i32, i32* %122 monotonic, align 4
  %124 = zext i32 %123 to i64
  %125 = or i64 %117, %124
  store i64 %125, i64* %105, align 8
  %126 = call zeroext i1 @_ZN2v88internal6Object13SameValueZeroES1_(%"class.v8::internal::Object"* nonnull %5, i64 %2) #7
  br i1 %126, label %127, label %129

127:                                              ; preds = %107
  %128 = sext i32 %109 to i64
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %104) #7
  br label %145

129:                                              ; preds = %107
  %130 = load i64, i64* %6, align 8
  %131 = add i64 %130, 15
  %132 = inttoptr i64 %131 to i32*
  %133 = load atomic i32, i32* %132 monotonic, align 4
  %134 = lshr i32 %133, 1
  %135 = add i32 %134, %115
  %136 = shl i32 %135, 2
  %137 = add i32 %136, 8
  %138 = sext i32 %137 to i64
  %139 = add i64 %130, 7
  %140 = add i64 %139, %138
  %141 = inttoptr i64 %140 to i32*
  %142 = load atomic i32, i32* %141 monotonic, align 4
  %143 = ashr i32 %142, 1
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %104) #7
  %144 = icmp eq i32 %143, -1
  br i1 %144, label %145, label %107

145:                                              ; preds = %129, %100, %127, %3, %99
  %146 = phi i64 [ -1, %99 ], [ -1, %3 ], [ %128, %127 ], [ -1, %100 ], [ -1, %129 ]
  ret i64 %146
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden zeroext i1 @_ZN2v88internal16OrderedHashTableINS0_14OrderedHashMapELi2EE6DeleteEPNS0_7IsolateES2_NS0_6ObjectE(%"class.v8::internal::Isolate"*, i64, i64) local_unnamed_addr #0 comdat align 2 {
  %4 = alloca %"class.v8::internal::OrderedHashMap", align 8
  %5 = getelementptr inbounds %"class.v8::internal::OrderedHashMap", %"class.v8::internal::OrderedHashMap"* %4, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %1, i64* %5, align 8
  %6 = getelementptr inbounds %"class.v8::internal::OrderedHashMap", %"class.v8::internal::OrderedHashMap"* %4, i64 0, i32 0
  %7 = call i64 @_ZN2v88internal16OrderedHashTableINS0_14OrderedHashMapELi2EE9FindEntryEPNS0_7IsolateENS0_6ObjectE(%"class.v8::internal::OrderedHashTable.1134"* nonnull %6, %"class.v8::internal::Isolate"* %0, i64 %2)
  %8 = icmp eq i64 %7, -1
  br i1 %8, label %103, label %9

9:                                                ; preds = %3
  %10 = load i64, i64* %5, align 8
  %11 = add i64 %10, 7
  %12 = inttoptr i64 %11 to i32*
  %13 = load atomic i32, i32* %12 monotonic, align 4
  %14 = add i64 %10, 11
  %15 = inttoptr i64 %14 to i32*
  %16 = load atomic i32, i32* %15 monotonic, align 4
  %17 = trunc i64 %7 to i32
  %18 = add i64 %10, 15
  %19 = inttoptr i64 %18 to i32*
  %20 = load atomic i32, i32* %19 monotonic, align 4
  %21 = lshr i32 %20, 1
  %22 = mul nsw i32 %17, 3
  %23 = add i32 %22, 3
  %24 = add i32 %23, %21
  %25 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 5
  %26 = load i64, i64* %25, align 8
  %27 = trunc i64 %26 to i32
  %28 = and i64 %26, 1
  %29 = icmp eq i64 %28, 0
  %30 = and i64 %26, -262144
  %31 = or i64 %30, 8
  %32 = inttoptr i64 %31 to i64*
  %33 = shl i32 %24, 2
  %34 = sext i32 %33 to i64
  %35 = add nsw i64 %34, 7
  %36 = add i64 %10, %35
  %37 = inttoptr i64 %36 to i32*
  store atomic volatile i32 %27, i32* %37 monotonic, align 4
  br i1 %29, label %47, label %38

38:                                               ; preds = %9
  %39 = load i64, i64* %5, align 8
  %40 = add i64 %39, %35
  %41 = and i64 %39, -262144
  %42 = or i64 %41, 8
  %43 = inttoptr i64 %42 to i64*
  %44 = load i64, i64* %43, align 8
  %45 = and i64 %44, 262144
  %46 = icmp eq i64 %45, 0
  br i1 %46, label %72, label %66

47:                                               ; preds = %9
  %48 = shl i32 %24, 2
  %49 = add i32 %48, 4
  %50 = load i64, i64* %5, align 8
  %51 = sext i32 %49 to i64
  %52 = add nsw i64 %51, 7
  %53 = add i64 %50, %52
  %54 = inttoptr i64 %53 to i32*
  store atomic volatile i32 %27, i32* %54 monotonic, align 4
  br label %55

55:                                               ; preds = %111, %117, %124, %47
  %56 = add i32 %13, -2
  %57 = and i32 %56, -2
  %58 = load i64, i64* %5, align 8
  %59 = add i64 %58, 7
  %60 = inttoptr i64 %59 to i32*
  store atomic volatile i32 %57, i32* %60 monotonic, align 4
  %61 = add i32 %16, 2
  %62 = and i32 %61, -2
  %63 = load i64, i64* %5, align 8
  %64 = add i64 %63, 11
  %65 = inttoptr i64 %64 to i32*
  store atomic volatile i32 %62, i32* %65 monotonic, align 4
  br label %103

66:                                               ; preds = %38
  %67 = or i64 %41, 16
  %68 = inttoptr i64 %67 to %"class.v8::internal::Heap"**
  %69 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %68, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %69, i64 %39, i64 %40, i64 %26) #7
  %70 = load i64, i64* %5, align 8
  %71 = add i64 %70, %35
  br label %72

72:                                               ; preds = %66, %38
  %73 = phi i64 [ %40, %38 ], [ %71, %66 ]
  %74 = phi i64 [ %39, %38 ], [ %70, %66 ]
  %75 = load i64, i64* %32, align 8
  %76 = and i64 %75, 24
  %77 = icmp eq i64 %76, 0
  br i1 %77, label %87, label %78

78:                                               ; preds = %72
  %79 = and i64 %74, -262144
  %80 = or i64 %79, 8
  %81 = inttoptr i64 %80 to i64*
  %82 = load i64, i64* %81, align 8
  %83 = and i64 %82, 24
  %84 = icmp eq i64 %83, 0
  br i1 %84, label %85, label %87

85:                                               ; preds = %78
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %74, i64 %73, i64 %26) #7
  %86 = load i64, i64* %5, align 8
  br label %87

87:                                               ; preds = %72, %78, %85
  %88 = phi i64 [ %74, %72 ], [ %74, %78 ], [ %86, %85 ]
  %89 = shl i32 %24, 2
  %90 = add i32 %89, 4
  %91 = sext i32 %90 to i64
  %92 = add nsw i64 %91, 7
  %93 = add i64 %88, %92
  %94 = inttoptr i64 %93 to i32*
  store atomic volatile i32 %27, i32* %94 monotonic, align 4
  %95 = load i64, i64* %5, align 8
  %96 = add i64 %95, %92
  %97 = and i64 %95, -262144
  %98 = or i64 %97, 8
  %99 = inttoptr i64 %98 to i64*
  %100 = load i64, i64* %99, align 8
  %101 = and i64 %100, 262144
  %102 = icmp eq i64 %101, 0
  br i1 %102, label %111, label %105

103:                                              ; preds = %3, %55
  %104 = phi i1 [ true, %55 ], [ false, %3 ]
  ret i1 %104

105:                                              ; preds = %87
  %106 = or i64 %97, 16
  %107 = inttoptr i64 %106 to %"class.v8::internal::Heap"**
  %108 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %107, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %108, i64 %95, i64 %96, i64 %26) #7
  %109 = load i64, i64* %5, align 8
  %110 = add i64 %109, %92
  br label %111

111:                                              ; preds = %105, %87
  %112 = phi i64 [ %96, %87 ], [ %110, %105 ]
  %113 = phi i64 [ %95, %87 ], [ %109, %105 ]
  %114 = load i64, i64* %32, align 8
  %115 = and i64 %114, 24
  %116 = icmp eq i64 %115, 0
  br i1 %116, label %55, label %117

117:                                              ; preds = %111
  %118 = and i64 %113, -262144
  %119 = or i64 %118, 8
  %120 = inttoptr i64 %119 to i64*
  %121 = load i64, i64* %120, align 8
  %122 = and i64 %121, 24
  %123 = icmp eq i64 %122, 0
  br i1 %123, label %124, label %55

124:                                              ; preds = %117
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %113, i64 %112, i64 %26) #7
  br label %55
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal16OrderedHashTableINS0_21OrderedNameDictionaryELi3EE6ShrinkEPNS0_7IsolateENS0_6HandleIS2_EE(%"class.v8::internal::Isolate"*, i64*) local_unnamed_addr #0 comdat align 2 {
  %3 = load i64, i64* %1, align 8
  %4 = add i64 %3, 11
  %5 = inttoptr i64 %4 to i32*
  %6 = load atomic i32, i32* %5 monotonic, align 4
  %7 = ashr i32 %6, 1
  %8 = add i64 %3, 19
  %9 = inttoptr i64 %8 to i32*
  %10 = load atomic i32, i32* %9 monotonic, align 4
  %11 = ashr i32 %10, 2
  %12 = icmp slt i32 %7, %11
  br i1 %12, label %13, label %28

13:                                               ; preds = %2
  %14 = and i32 %10, -2
  %15 = sdiv i32 %14, 2
  %16 = tail call i64* @_ZN2v88internal16OrderedHashTableINS0_21OrderedNameDictionaryELi3EE6RehashINS0_7IsolateEEENS0_11MaybeHandleIS2_EEPT_NS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"* %0, i64* %1, i32 %15) #7
  %17 = icmp eq i64* %16, null
  br i1 %17, label %18, label %19

18:                                               ; preds = %13
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.2, i64 0, i64 0)) #8
  unreachable

19:                                               ; preds = %13
  %20 = load i64, i64* %16, align 8
  %21 = load i64, i64* %1, align 8
  %22 = add i64 %21, 7
  %23 = inttoptr i64 %22 to i32*
  %24 = load atomic i32, i32* %23 monotonic, align 4
  %25 = and i32 %24, -2
  %26 = add i64 %20, 7
  %27 = inttoptr i64 %26 to i32*
  store atomic volatile i32 %25, i32* %27 monotonic, align 4
  br label %28

28:                                               ; preds = %2, %19
  %29 = phi i64* [ %16, %19 ], [ %1, %2 ]
  ret i64* %29
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal21OrderedNameDictionary6RehashINS0_7IsolateEEENS0_11MaybeHandleIS1_EEPT_NS0_6HandleIS1_EEi(%"class.v8::internal::Isolate"*, i64*, i32) local_unnamed_addr #0 comdat align 2 {
  %4 = tail call i64* @_ZN2v88internal16OrderedHashTableINS0_21OrderedNameDictionaryELi3EE6RehashINS0_7IsolateEEENS0_11MaybeHandleIS2_EEPT_NS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"* %0, i64* %1, i32 %2)
  %5 = icmp eq i64* %4, null
  br i1 %5, label %15, label %6

6:                                                ; preds = %3
  %7 = load i64, i64* %4, align 8
  %8 = load i64, i64* %1, align 8
  %9 = add i64 %8, 7
  %10 = inttoptr i64 %9 to i32*
  %11 = load atomic i32, i32* %10 monotonic, align 4
  %12 = and i32 %11, -2
  %13 = add i64 %7, 7
  %14 = inttoptr i64 %13 to i32*
  store atomic volatile i32 %12, i32* %14 monotonic, align 4
  br label %15

15:                                               ; preds = %3, %6
  ret i64* %4
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal16OrderedHashTableINS0_21OrderedNameDictionaryELi3EE14EnsureGrowableINS0_7IsolateEEENS0_11MaybeHandleIS2_EEPT_NS0_6HandleIS2_EE(%"class.v8::internal::Isolate"*, i64*) local_unnamed_addr #0 comdat align 2 {
  %3 = load i64, i64* %1, align 8
  %4 = add i64 %3, 11
  %5 = inttoptr i64 %4 to i32*
  %6 = load atomic i32, i32* %5 monotonic, align 4
  %7 = ashr i32 %6, 1
  %8 = add i64 %3, 15
  %9 = inttoptr i64 %8 to i32*
  %10 = load atomic i32, i32* %9 monotonic, align 4
  %11 = ashr i32 %10, 1
  %12 = add i64 %3, 19
  %13 = inttoptr i64 %12 to i32*
  %14 = load atomic i32, i32* %13 monotonic, align 4
  %15 = and i32 %14, -2
  %16 = add nsw i32 %11, %7
  %17 = icmp slt i32 %16, %15
  br i1 %17, label %38, label %18

18:                                               ; preds = %2
  %19 = icmp eq i32 %15, 0
  br i1 %19, label %25, label %20

20:                                               ; preds = %18
  %21 = ashr i32 %14, 1
  %22 = icmp slt i32 %11, %21
  %23 = zext i1 %22 to i32
  %24 = shl i32 %15, %23
  br label %25

25:                                               ; preds = %20, %18
  %26 = phi i32 [ 4, %18 ], [ %24, %20 ]
  %27 = tail call i64* @_ZN2v88internal16OrderedHashTableINS0_21OrderedNameDictionaryELi3EE6RehashINS0_7IsolateEEENS0_11MaybeHandleIS2_EEPT_NS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"* %0, i64* %1, i32 %26) #7
  %28 = icmp eq i64* %27, null
  br i1 %28, label %38, label %29

29:                                               ; preds = %25
  %30 = load i64, i64* %27, align 8
  %31 = load i64, i64* %1, align 8
  %32 = add i64 %31, 7
  %33 = inttoptr i64 %32 to i32*
  %34 = load atomic i32, i32* %33 monotonic, align 4
  %35 = and i32 %34, -2
  %36 = add i64 %30, 7
  %37 = inttoptr i64 %36 to i32*
  store atomic volatile i32 %35, i32* %37 monotonic, align 4
  br label %38

38:                                               ; preds = %29, %25, %2
  %39 = phi i64* [ %1, %2 ], [ null, %25 ], [ %27, %29 ]
  ret i64* %39
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal21OrderedNameDictionary8AllocateINS0_7IsolateEEENS0_11MaybeHandleIS1_EEPT_iNS0_14AllocationTypeE(%"class.v8::internal::Isolate"*, i32, i8 zeroext) local_unnamed_addr #0 comdat align 2 {
  %4 = icmp sgt i32 %1, 4
  %5 = select i1 %4, i32 %1, i32 4
  %6 = tail call i32 @_ZN2v84base4bits21RoundUpToPowerOfTwo32Ej(i32 %5) #7
  %7 = icmp sgt i32 %6, 14913080
  br i1 %7, label %80, label %8

8:                                                ; preds = %3
  %9 = sdiv i32 %6, 2
  %10 = bitcast %"class.v8::internal::Isolate"* %0 to %"class.v8::internal::FactoryBase"*
  %11 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 56
  %12 = add nsw i32 %9, 4
  %13 = shl i32 %6, 2
  %14 = add nsw i32 %12, %13
  %15 = tail call i64* @_ZN2v88internal11FactoryBaseINS0_7FactoryEE20NewFixedArrayWithMapENS0_6HandleINS0_3MapEEEiNS0_14AllocationTypeE(%"class.v8::internal::FactoryBase"* %10, i64* %11, i32 %14, i8 zeroext %2) #7
  %16 = icmp sgt i32 %6, 1
  %17 = load i64, i64* %15, align 8
  br i1 %16, label %18, label %64

18:                                               ; preds = %8
  %19 = zext i32 %9 to i64
  %20 = and i64 %19, 1
  %21 = and i32 %6, -2
  %22 = icmp eq i32 %21, 2
  br i1 %22, label %54, label %23

23:                                               ; preds = %18
  %24 = sub nsw i64 %19, %20
  br label %25

25:                                               ; preds = %25, %23
  %26 = phi i64 [ 0, %23 ], [ %45, %25 ]
  %27 = phi i64 [ %17, %23 ], [ %46, %25 ]
  %28 = phi i64 [ %24, %23 ], [ %47, %25 ]
  %29 = trunc i64 %26 to i32
  %30 = shl i32 %29, 2
  %31 = add i32 %30, 16
  %32 = sext i32 %31 to i64
  %33 = add i64 %27, 7
  %34 = add i64 %33, %32
  %35 = inttoptr i64 %34 to i32*
  store atomic volatile i32 -2, i32* %35 monotonic, align 4
  %36 = load i64, i64* %15, align 8
  %37 = trunc i64 %26 to i32
  %38 = shl i32 %37, 2
  %39 = or i32 %38, 4
  %40 = add i32 %39, 16
  %41 = sext i32 %40 to i64
  %42 = add i64 %36, 7
  %43 = add i64 %42, %41
  %44 = inttoptr i64 %43 to i32*
  store atomic volatile i32 -2, i32* %44 monotonic, align 4
  %45 = add nuw nsw i64 %26, 2
  %46 = load i64, i64* %15, align 8
  %47 = add i64 %28, -2
  %48 = icmp eq i64 %47, 0
  br i1 %48, label %49, label %25

49:                                               ; preds = %25
  %50 = trunc i64 %45 to i32
  %51 = shl i32 %50, 2
  %52 = add i32 %51, 16
  %53 = sext i32 %52 to i64
  br label %54

54:                                               ; preds = %49, %18
  %55 = phi i64 [ undef, %18 ], [ %46, %49 ]
  %56 = phi i64 [ 16, %18 ], [ %53, %49 ]
  %57 = phi i64 [ %17, %18 ], [ %46, %49 ]
  %58 = icmp eq i64 %20, 0
  br i1 %58, label %64, label %59

59:                                               ; preds = %54
  %60 = add i64 %57, 7
  %61 = add i64 %60, %56
  %62 = inttoptr i64 %61 to i32*
  store atomic volatile i32 -2, i32* %62 monotonic, align 4
  %63 = load i64, i64* %15, align 8
  br label %64

64:                                               ; preds = %59, %54, %8
  %65 = phi i64 [ %17, %8 ], [ %55, %54 ], [ %63, %59 ]
  %66 = shl nsw i32 %9, 1
  %67 = add i64 %65, 19
  %68 = inttoptr i64 %67 to i32*
  store atomic volatile i32 %66, i32* %68 monotonic, align 4
  %69 = load i64, i64* %15, align 8
  %70 = add i64 %69, 11
  %71 = inttoptr i64 %70 to i32*
  store atomic volatile i32 0, i32* %71 monotonic, align 4
  %72 = load i64, i64* %15, align 8
  %73 = add i64 %72, 15
  %74 = inttoptr i64 %73 to i32*
  store atomic volatile i32 0, i32* %74 monotonic, align 4
  %75 = icmp eq i64* %15, null
  br i1 %75, label %80, label %76

76:                                               ; preds = %64
  %77 = load i64, i64* %15, align 8
  %78 = add i64 %77, 7
  %79 = inttoptr i64 %78 to i32*
  store atomic volatile i32 0, i32* %79 monotonic, align 4
  br label %80

80:                                               ; preds = %3, %64, %76
  %81 = phi i64* [ %15, %76 ], [ null, %64 ], [ null, %3 ]
  ret i64* %81
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal21OrderedNameDictionary8AllocateINS0_12LocalIsolateEEENS0_11MaybeHandleIS1_EEPT_iNS0_14AllocationTypeE(%"class.v8::internal::LocalIsolate"*, i32, i8 zeroext) local_unnamed_addr #0 comdat align 2 {
  %4 = icmp sgt i32 %1, 4
  %5 = select i1 %4, i32 %1, i32 4
  %6 = tail call i32 @_ZN2v84base4bits21RoundUpToPowerOfTwo32Ej(i32 %5) #7
  %7 = icmp sgt i32 %6, 14913080
  br i1 %7, label %82, label %8

8:                                                ; preds = %3
  %9 = sdiv i32 %6, 2
  %10 = bitcast %"class.v8::internal::LocalIsolate"* %0 to %"class.v8::internal::FactoryBase.1048"*
  %11 = getelementptr inbounds %"class.v8::internal::LocalIsolate", %"class.v8::internal::LocalIsolate"* %0, i64 0, i32 0, i32 0, i32 0, i32 0
  %12 = load i64*, i64** %11, align 8
  %13 = getelementptr inbounds i64, i64* %12, i64 56
  %14 = add nsw i32 %9, 4
  %15 = shl i32 %6, 2
  %16 = add nsw i32 %14, %15
  %17 = tail call i64* @_ZN2v88internal11FactoryBaseINS0_12LocalFactoryEE20NewFixedArrayWithMapENS0_6HandleINS0_3MapEEEiNS0_14AllocationTypeE(%"class.v8::internal::FactoryBase.1048"* %10, i64* %13, i32 %16, i8 zeroext %2) #7
  %18 = icmp sgt i32 %6, 1
  %19 = load i64, i64* %17, align 8
  br i1 %18, label %20, label %66

20:                                               ; preds = %8
  %21 = zext i32 %9 to i64
  %22 = and i64 %21, 1
  %23 = and i32 %6, -2
  %24 = icmp eq i32 %23, 2
  br i1 %24, label %56, label %25

25:                                               ; preds = %20
  %26 = sub nsw i64 %21, %22
  br label %27

27:                                               ; preds = %27, %25
  %28 = phi i64 [ 0, %25 ], [ %47, %27 ]
  %29 = phi i64 [ %19, %25 ], [ %48, %27 ]
  %30 = phi i64 [ %26, %25 ], [ %49, %27 ]
  %31 = trunc i64 %28 to i32
  %32 = shl i32 %31, 2
  %33 = add i32 %32, 16
  %34 = sext i32 %33 to i64
  %35 = add i64 %29, 7
  %36 = add i64 %35, %34
  %37 = inttoptr i64 %36 to i32*
  store atomic volatile i32 -2, i32* %37 monotonic, align 4
  %38 = load i64, i64* %17, align 8
  %39 = trunc i64 %28 to i32
  %40 = shl i32 %39, 2
  %41 = or i32 %40, 4
  %42 = add i32 %41, 16
  %43 = sext i32 %42 to i64
  %44 = add i64 %38, 7
  %45 = add i64 %44, %43
  %46 = inttoptr i64 %45 to i32*
  store atomic volatile i32 -2, i32* %46 monotonic, align 4
  %47 = add nuw nsw i64 %28, 2
  %48 = load i64, i64* %17, align 8
  %49 = add i64 %30, -2
  %50 = icmp eq i64 %49, 0
  br i1 %50, label %51, label %27

51:                                               ; preds = %27
  %52 = trunc i64 %47 to i32
  %53 = shl i32 %52, 2
  %54 = add i32 %53, 16
  %55 = sext i32 %54 to i64
  br label %56

56:                                               ; preds = %51, %20
  %57 = phi i64 [ undef, %20 ], [ %48, %51 ]
  %58 = phi i64 [ 16, %20 ], [ %55, %51 ]
  %59 = phi i64 [ %19, %20 ], [ %48, %51 ]
  %60 = icmp eq i64 %22, 0
  br i1 %60, label %66, label %61

61:                                               ; preds = %56
  %62 = add i64 %59, 7
  %63 = add i64 %62, %58
  %64 = inttoptr i64 %63 to i32*
  store atomic volatile i32 -2, i32* %64 monotonic, align 4
  %65 = load i64, i64* %17, align 8
  br label %66

66:                                               ; preds = %61, %56, %8
  %67 = phi i64 [ %19, %8 ], [ %57, %56 ], [ %65, %61 ]
  %68 = shl nsw i32 %9, 1
  %69 = add i64 %67, 19
  %70 = inttoptr i64 %69 to i32*
  store atomic volatile i32 %68, i32* %70 monotonic, align 4
  %71 = load i64, i64* %17, align 8
  %72 = add i64 %71, 11
  %73 = inttoptr i64 %72 to i32*
  store atomic volatile i32 0, i32* %73 monotonic, align 4
  %74 = load i64, i64* %17, align 8
  %75 = add i64 %74, 15
  %76 = inttoptr i64 %75 to i32*
  store atomic volatile i32 0, i32* %76 monotonic, align 4
  %77 = icmp eq i64* %17, null
  br i1 %77, label %82, label %78

78:                                               ; preds = %66
  %79 = load i64, i64* %17, align 8
  %80 = add i64 %79, 7
  %81 = inttoptr i64 %80 to i32*
  store atomic volatile i32 0, i32* %81 monotonic, align 4
  br label %82

82:                                               ; preds = %3, %66, %78
  %83 = phi i64* [ %17, %78 ], [ null, %66 ], [ null, %3 ]
  ret i64* %83
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64* @_ZN2v88internal16OrderedHashTableINS0_21OrderedNameDictionaryELi3EE6RehashINS0_7IsolateEEENS0_11MaybeHandleIS2_EEPT_NS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"*, i64*, i32) local_unnamed_addr #0 comdat align 2 {
  %4 = alloca %"class.v8::internal::JSReceiver", align 8
  %5 = load i64, i64* %1, align 8
  %6 = and i64 %5, -262144
  %7 = inttoptr i64 %6 to %"class.v8::internal::BasicMemoryChunk"*
  %8 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %7, i64 0, i32 1
  %9 = load i64, i64* %8, align 8
  %10 = icmp sgt i32 %2, 4
  %11 = select i1 %10, i32 %2, i32 4
  %12 = tail call i32 @_ZN2v84base4bits21RoundUpToPowerOfTwo32Ej(i32 %11) #7
  %13 = icmp sgt i32 %12, 14913080
  br i1 %13, label %318, label %14

14:                                               ; preds = %3
  %15 = and i64 %9, 24
  %16 = icmp eq i64 %15, 0
  %17 = zext i1 %16 to i8
  %18 = sdiv i32 %12, 2
  %19 = bitcast %"class.v8::internal::Isolate"* %0 to %"class.v8::internal::FactoryBase"*
  %20 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 56
  %21 = add nsw i32 %18, 4
  %22 = shl i32 %12, 2
  %23 = add nsw i32 %21, %22
  %24 = tail call i64* @_ZN2v88internal11FactoryBaseINS0_7FactoryEE20NewFixedArrayWithMapENS0_6HandleINS0_3MapEEEiNS0_14AllocationTypeE(%"class.v8::internal::FactoryBase"* %19, i64* %20, i32 %23, i8 zeroext %17) #7
  %25 = icmp sgt i32 %12, 1
  %26 = load i64, i64* %24, align 8
  br i1 %25, label %27, label %73

27:                                               ; preds = %14
  %28 = zext i32 %18 to i64
  %29 = and i64 %28, 1
  %30 = and i32 %12, -2
  %31 = icmp eq i32 %30, 2
  br i1 %31, label %63, label %32

32:                                               ; preds = %27
  %33 = sub nsw i64 %28, %29
  br label %34

34:                                               ; preds = %34, %32
  %35 = phi i64 [ 0, %32 ], [ %54, %34 ]
  %36 = phi i64 [ %26, %32 ], [ %55, %34 ]
  %37 = phi i64 [ %33, %32 ], [ %56, %34 ]
  %38 = trunc i64 %35 to i32
  %39 = shl i32 %38, 2
  %40 = add i32 %39, 16
  %41 = sext i32 %40 to i64
  %42 = add i64 %36, 7
  %43 = add i64 %42, %41
  %44 = inttoptr i64 %43 to i32*
  store atomic volatile i32 -2, i32* %44 monotonic, align 4
  %45 = load i64, i64* %24, align 8
  %46 = trunc i64 %35 to i32
  %47 = shl i32 %46, 2
  %48 = or i32 %47, 4
  %49 = add i32 %48, 16
  %50 = sext i32 %49 to i64
  %51 = add i64 %45, 7
  %52 = add i64 %51, %50
  %53 = inttoptr i64 %52 to i32*
  store atomic volatile i32 -2, i32* %53 monotonic, align 4
  %54 = add nuw nsw i64 %35, 2
  %55 = load i64, i64* %24, align 8
  %56 = add i64 %37, -2
  %57 = icmp eq i64 %56, 0
  br i1 %57, label %58, label %34

58:                                               ; preds = %34
  %59 = trunc i64 %54 to i32
  %60 = shl i32 %59, 2
  %61 = add i32 %60, 16
  %62 = sext i32 %61 to i64
  br label %63

63:                                               ; preds = %58, %27
  %64 = phi i64 [ undef, %27 ], [ %55, %58 ]
  %65 = phi i64 [ 16, %27 ], [ %62, %58 ]
  %66 = phi i64 [ %26, %27 ], [ %55, %58 ]
  %67 = icmp eq i64 %29, 0
  br i1 %67, label %73, label %68

68:                                               ; preds = %63
  %69 = add i64 %66, 7
  %70 = add i64 %69, %65
  %71 = inttoptr i64 %70 to i32*
  store atomic volatile i32 -2, i32* %71 monotonic, align 4
  %72 = load i64, i64* %24, align 8
  br label %73

73:                                               ; preds = %68, %63, %14
  %74 = phi i64 [ %26, %14 ], [ %64, %63 ], [ %72, %68 ]
  %75 = shl nsw i32 %18, 1
  %76 = add i64 %74, 19
  %77 = inttoptr i64 %76 to i32*
  store atomic volatile i32 %75, i32* %77 monotonic, align 4
  %78 = load i64, i64* %24, align 8
  %79 = add i64 %78, 11
  %80 = inttoptr i64 %79 to i32*
  store atomic volatile i32 0, i32* %80 monotonic, align 4
  %81 = load i64, i64* %24, align 8
  %82 = add i64 %81, 15
  %83 = inttoptr i64 %82 to i32*
  store atomic volatile i32 0, i32* %83 monotonic, align 4
  %84 = icmp eq i64* %24, null
  br i1 %84, label %318, label %85

85:                                               ; preds = %73
  %86 = load i64, i64* %24, align 8
  %87 = add i64 %86, 7
  %88 = inttoptr i64 %87 to i32*
  store atomic volatile i32 0, i32* %88 monotonic, align 4
  %89 = load i64, i64* %24, align 8
  %90 = add i64 %89, 19
  %91 = inttoptr i64 %90 to i32*
  %92 = load atomic i32, i32* %91 monotonic, align 4
  %93 = load i64, i64* %1, align 8
  %94 = add i64 %93, 11
  %95 = inttoptr i64 %94 to i32*
  %96 = load atomic i32, i32* %95 monotonic, align 4
  %97 = ashr i32 %96, 1
  %98 = add i64 %93, 15
  %99 = inttoptr i64 %98 to i32*
  %100 = load atomic i32, i32* %99 monotonic, align 4
  %101 = ashr i32 %100, 1
  %102 = add nsw i32 %101, %97
  %103 = sext i32 %102 to i64
  %104 = icmp eq i32 %102, 0
  br i1 %104, label %116, label %105

105:                                              ; preds = %85
  %106 = lshr i32 %92, 1
  %107 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 5
  %108 = bitcast %"class.v8::internal::JSReceiver"* %4 to i8*
  %109 = getelementptr inbounds %"class.v8::internal::JSReceiver", %"class.v8::internal::JSReceiver"* %4, i64 0, i32 0, i32 0, i32 0, i32 0
  %110 = add nuw i32 %106, 1073741823
  br label %128

111:                                              ; preds = %281
  %112 = load i64, i64* %24, align 8
  %113 = load i64, i64* %1, align 8
  %114 = add i64 %113, 11
  %115 = inttoptr i64 %114 to i32*
  br label %116

116:                                              ; preds = %111, %85
  %117 = phi i32* [ %115, %111 ], [ %95, %85 ]
  %118 = phi i64 [ %112, %111 ], [ %89, %85 ]
  %119 = load atomic i32, i32* %117 monotonic, align 4
  %120 = and i32 %119, -2
  %121 = add i64 %118, 11
  %122 = inttoptr i64 %121 to i32*
  store atomic volatile i32 %120, i32* %122 monotonic, align 4
  %123 = load i64, i64* %1, align 8
  %124 = add i64 %123, 19
  %125 = inttoptr i64 %124 to i32*
  %126 = load atomic i32, i32* %125 monotonic, align 4
  %127 = icmp sgt i32 %126, 1
  br i1 %127, label %288, label %318

128:                                              ; preds = %286, %105
  %129 = phi i64 [ %93, %105 ], [ %287, %286 ]
  %130 = phi i32 [ 0, %105 ], [ %283, %286 ]
  %131 = phi i32 [ 0, %105 ], [ %282, %286 ]
  %132 = phi i64 [ 0, %105 ], [ %284, %286 ]
  %133 = trunc i64 %132 to i32
  %134 = add i64 %129, 19
  %135 = inttoptr i64 %134 to i32*
  %136 = load atomic i32, i32* %135 monotonic, align 4
  %137 = lshr i32 %136, 1
  %138 = shl i32 %133, 2
  %139 = add i32 %138, 4
  %140 = add i32 %137, %139
  %141 = and i64 %129, -4294967296
  %142 = shl i32 %140, 2
  %143 = sext i32 %142 to i64
  %144 = add i64 %129, 7
  %145 = add i64 %144, %143
  %146 = inttoptr i64 %145 to i32*
  %147 = load atomic i32, i32* %146 monotonic, align 4
  %148 = zext i32 %147 to i64
  %149 = or i64 %141, %148
  %150 = load i64, i64* %107, align 8
  %151 = trunc i64 %150 to i32
  %152 = icmp eq i32 %147, %151
  br i1 %152, label %153, label %161

153:                                              ; preds = %128
  %154 = add nsw i32 %131, 1
  %155 = shl i32 %133, 1
  %156 = shl i32 %131, 2
  %157 = add i32 %156, 16
  %158 = sext i32 %157 to i64
  %159 = add i64 %144, %158
  %160 = inttoptr i64 %159 to i32*
  store atomic volatile i32 %155, i32* %160 monotonic, align 4
  br label %281

161:                                              ; preds = %128
  %162 = call i64 @_ZN2v88internal6Object13GetSimpleHashES1_(i64 %149) #7
  %163 = and i64 %162, 1
  %164 = icmp eq i64 %163, 0
  br i1 %164, label %167, label %165

165:                                              ; preds = %161
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %108) #7
  store i64 %149, i64* %109, align 8
  %166 = call i64 @_ZN2v88internal10JSReceiver15GetIdentityHashEv(%"class.v8::internal::JSReceiver"* nonnull %4) #7
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %108) #7
  br label %167

167:                                              ; preds = %161, %165
  %168 = phi i64 [ %166, %165 ], [ %162, %161 ]
  %169 = trunc i64 %168 to i32
  %170 = lshr i32 %169, 1
  %171 = and i32 %170, %110
  %172 = load i64, i64* %24, align 8
  %173 = shl i32 %171, 2
  %174 = add i32 %173, 16
  %175 = sext i32 %174 to i64
  %176 = add i64 %172, 7
  %177 = add i64 %176, %175
  %178 = inttoptr i64 %177 to i32*
  %179 = load atomic i32, i32* %178 monotonic, align 4
  %180 = zext i32 %179 to i64
  %181 = shl i32 %130, 1
  store atomic volatile i32 %181, i32* %178 monotonic, align 4
  %182 = load i64, i64* %24, align 8
  %183 = add i64 %182, 19
  %184 = inttoptr i64 %183 to i32*
  %185 = load atomic i32, i32* %184 monotonic, align 4
  %186 = ashr i32 %185, 1
  %187 = shl i32 %130, 2
  %188 = add i32 %187, 4
  %189 = add i32 %188, %186
  %190 = load i64, i64* %1, align 8
  %191 = add i64 %190, 19
  %192 = inttoptr i64 %191 to i32*
  %193 = load atomic i32, i32* %192 monotonic, align 4
  %194 = lshr i32 %193, 1
  %195 = add i32 %194, %139
  %196 = and i64 %190, -4294967296
  %197 = shl i32 %195, 2
  %198 = sext i32 %197 to i64
  %199 = add nsw i64 %198, 7
  %200 = add i64 %199, %190
  %201 = inttoptr i64 %200 to i32*
  %202 = load atomic i32, i32* %201 monotonic, align 4
  %203 = zext i32 %202 to i64
  %204 = or i64 %196, %203
  %205 = shl i32 %189, 2
  %206 = sext i32 %205 to i64
  %207 = add nsw i64 %206, 7
  %208 = add i64 %207, %182
  %209 = inttoptr i64 %208 to i32*
  store atomic volatile i32 %202, i32* %209 monotonic, align 4
  %210 = and i64 %203, 1
  %211 = icmp eq i64 %210, 0
  br i1 %211, label %260, label %237

212:                                              ; preds = %387
  %213 = and i64 %390, -262144
  %214 = or i64 %213, 8
  %215 = inttoptr i64 %214 to i64*
  %216 = load i64, i64* %215, align 8
  %217 = and i64 %216, 262144
  %218 = icmp eq i64 %217, 0
  br i1 %218, label %223, label %219

219:                                              ; preds = %212
  %220 = or i64 %213, 16
  %221 = inttoptr i64 %220 to %"class.v8::internal::Heap"**
  %222 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %221, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %222, i64 %390, i64 %394, i64 %389) #7
  br label %223

223:                                              ; preds = %219, %212
  %224 = and i64 %389, -262144
  %225 = or i64 %224, 8
  %226 = inttoptr i64 %225 to i64*
  %227 = load i64, i64* %226, align 8
  %228 = and i64 %227, 24
  %229 = icmp eq i64 %228, 0
  br i1 %229, label %235, label %230

230:                                              ; preds = %223
  %231 = load i64, i64* %215, align 8
  %232 = and i64 %231, 24
  %233 = icmp eq i64 %232, 0
  br i1 %233, label %234, label %235

234:                                              ; preds = %230
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %390, i64 %394, i64 %389) #7
  br label %235

235:                                              ; preds = %387, %223, %230, %234
  %236 = add nsw i32 %130, 1
  br label %281

237:                                              ; preds = %167
  %238 = and i64 %182, -262144
  %239 = or i64 %238, 8
  %240 = inttoptr i64 %239 to i64*
  %241 = load i64, i64* %240, align 8
  %242 = and i64 %241, 262144
  %243 = icmp eq i64 %242, 0
  br i1 %243, label %248, label %244

244:                                              ; preds = %237
  %245 = or i64 %238, 16
  %246 = inttoptr i64 %245 to %"class.v8::internal::Heap"**
  %247 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %246, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %247, i64 %182, i64 %208, i64 %204) #7
  br label %248

248:                                              ; preds = %244, %237
  %249 = and i64 %204, -262144
  %250 = or i64 %249, 8
  %251 = inttoptr i64 %250 to i64*
  %252 = load i64, i64* %251, align 8
  %253 = and i64 %252, 24
  %254 = icmp eq i64 %253, 0
  br i1 %254, label %260, label %255

255:                                              ; preds = %248
  %256 = load i64, i64* %240, align 8
  %257 = and i64 %256, 24
  %258 = icmp eq i64 %257, 0
  br i1 %258, label %259, label %260

259:                                              ; preds = %255
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %182, i64 %208, i64 %204) #7
  br label %260

260:                                              ; preds = %167, %248, %255, %259
  %261 = load i64, i64* %1, align 8
  %262 = and i64 %261, -4294967296
  %263 = shl i32 %195, 2
  %264 = add i32 %263, 4
  %265 = sext i32 %264 to i64
  %266 = add nsw i64 %265, 7
  %267 = add i64 %266, %261
  %268 = inttoptr i64 %267 to i32*
  %269 = load atomic i32, i32* %268 monotonic, align 4
  %270 = zext i32 %269 to i64
  %271 = or i64 %262, %270
  %272 = load i64, i64* %24, align 8
  %273 = shl i32 %189, 2
  %274 = add i32 %273, 4
  %275 = sext i32 %274 to i64
  %276 = add nsw i64 %275, 7
  %277 = add i64 %276, %272
  %278 = inttoptr i64 %277 to i32*
  store atomic volatile i32 %269, i32* %278 monotonic, align 4
  %279 = and i64 %270, 1
  %280 = icmp eq i64 %279, 0
  br i1 %280, label %343, label %320

281:                                              ; preds = %235, %153
  %282 = phi i32 [ %154, %153 ], [ %131, %235 ]
  %283 = phi i32 [ %130, %153 ], [ %236, %235 ]
  %284 = add i64 %132, 1
  %285 = icmp eq i64 %284, %103
  br i1 %285, label %111, label %286

286:                                              ; preds = %281
  %287 = load i64, i64* %1, align 8
  br label %128

288:                                              ; preds = %116
  %289 = load i64, i64* %24, align 8
  %290 = add i64 %123, 11
  %291 = inttoptr i64 %290 to i32*
  %292 = trunc i64 %289 to i32
  store atomic volatile i32 %292, i32* %291 monotonic, align 4
  %293 = and i64 %289, 1
  %294 = icmp eq i64 %293, 0
  br i1 %294, label %318, label %295

295:                                              ; preds = %288
  %296 = and i64 %123, -262144
  %297 = or i64 %296, 8
  %298 = inttoptr i64 %297 to i64*
  %299 = load i64, i64* %298, align 8
  %300 = and i64 %299, 262144
  %301 = icmp eq i64 %300, 0
  br i1 %301, label %306, label %302

302:                                              ; preds = %295
  %303 = or i64 %296, 16
  %304 = inttoptr i64 %303 to %"class.v8::internal::Heap"**
  %305 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %304, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %305, i64 %123, i64 %290, i64 %289) #7
  br label %306

306:                                              ; preds = %302, %295
  %307 = and i64 %289, -262144
  %308 = or i64 %307, 8
  %309 = inttoptr i64 %308 to i64*
  %310 = load i64, i64* %309, align 8
  %311 = and i64 %310, 24
  %312 = icmp eq i64 %311, 0
  br i1 %312, label %318, label %313

313:                                              ; preds = %306
  %314 = load i64, i64* %298, align 8
  %315 = and i64 %314, 24
  %316 = icmp eq i64 %315, 0
  br i1 %316, label %317, label %318

317:                                              ; preds = %313
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %123, i64 %290, i64 %289) #7
  br label %318

318:                                              ; preds = %3, %73, %116, %288, %306, %313, %317
  %319 = phi i64* [ %24, %317 ], [ %24, %313 ], [ %24, %306 ], [ %24, %288 ], [ %24, %116 ], [ null, %73 ], [ null, %3 ]
  ret i64* %319

320:                                              ; preds = %260
  %321 = and i64 %272, -262144
  %322 = or i64 %321, 8
  %323 = inttoptr i64 %322 to i64*
  %324 = load i64, i64* %323, align 8
  %325 = and i64 %324, 262144
  %326 = icmp eq i64 %325, 0
  br i1 %326, label %331, label %327

327:                                              ; preds = %320
  %328 = or i64 %321, 16
  %329 = inttoptr i64 %328 to %"class.v8::internal::Heap"**
  %330 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %329, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %330, i64 %272, i64 %277, i64 %271) #7
  br label %331

331:                                              ; preds = %327, %320
  %332 = and i64 %271, -262144
  %333 = or i64 %332, 8
  %334 = inttoptr i64 %333 to i64*
  %335 = load i64, i64* %334, align 8
  %336 = and i64 %335, 24
  %337 = icmp eq i64 %336, 0
  br i1 %337, label %343, label %338

338:                                              ; preds = %331
  %339 = load i64, i64* %323, align 8
  %340 = and i64 %339, 24
  %341 = icmp eq i64 %340, 0
  br i1 %341, label %342, label %343

342:                                              ; preds = %338
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %272, i64 %277, i64 %271) #7
  br label %343

343:                                              ; preds = %342, %338, %331, %260
  %344 = load i64, i64* %1, align 8
  %345 = and i64 %344, -4294967296
  %346 = shl i32 %195, 2
  %347 = add i32 %346, 8
  %348 = sext i32 %347 to i64
  %349 = add nsw i64 %348, 7
  %350 = add i64 %349, %344
  %351 = inttoptr i64 %350 to i32*
  %352 = load atomic i32, i32* %351 monotonic, align 4
  %353 = zext i32 %352 to i64
  %354 = or i64 %345, %353
  %355 = load i64, i64* %24, align 8
  %356 = shl i32 %189, 2
  %357 = add i32 %356, 8
  %358 = sext i32 %357 to i64
  %359 = add nsw i64 %358, 7
  %360 = add i64 %359, %355
  %361 = inttoptr i64 %360 to i32*
  store atomic volatile i32 %352, i32* %361 monotonic, align 4
  %362 = and i64 %353, 1
  %363 = icmp eq i64 %362, 0
  br i1 %363, label %387, label %364

364:                                              ; preds = %343
  %365 = and i64 %355, -262144
  %366 = or i64 %365, 8
  %367 = inttoptr i64 %366 to i64*
  %368 = load i64, i64* %367, align 8
  %369 = and i64 %368, 262144
  %370 = icmp eq i64 %369, 0
  br i1 %370, label %375, label %371

371:                                              ; preds = %364
  %372 = or i64 %365, 16
  %373 = inttoptr i64 %372 to %"class.v8::internal::Heap"**
  %374 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %373, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %374, i64 %355, i64 %360, i64 %354) #7
  br label %375

375:                                              ; preds = %371, %364
  %376 = and i64 %354, -262144
  %377 = or i64 %376, 8
  %378 = inttoptr i64 %377 to i64*
  %379 = load i64, i64* %378, align 8
  %380 = and i64 %379, 24
  %381 = icmp eq i64 %380, 0
  br i1 %381, label %387, label %382

382:                                              ; preds = %375
  %383 = load i64, i64* %367, align 8
  %384 = and i64 %383, 24
  %385 = icmp eq i64 %384, 0
  br i1 %385, label %386, label %387

386:                                              ; preds = %382
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %355, i64 %360, i64 %354) #7
  br label %387

387:                                              ; preds = %386, %382, %375, %343
  %388 = and i64 %172, -4294967296
  %389 = or i64 %388, %180
  %390 = load i64, i64* %24, align 8
  %391 = add i32 %205, 12
  %392 = sext i32 %391 to i64
  %393 = add nsw i64 %392, 7
  %394 = add i64 %393, %390
  %395 = inttoptr i64 %394 to i32*
  store atomic volatile i32 %179, i32* %395 monotonic, align 4
  %396 = and i64 %180, 1
  %397 = icmp eq i64 %396, 0
  br i1 %397, label %235, label %212
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64 @_ZN2v88internal21OrderedNameDictionary9FindEntryINS0_7IsolateEEENS0_13InternalIndexEPT_NS0_6ObjectE(%"class.v8::internal::OrderedNameDictionary"*, %"class.v8::internal::Isolate"*, i64) local_unnamed_addr #0 comdat align 2 {
  %4 = getelementptr inbounds %"class.v8::internal::OrderedNameDictionary", %"class.v8::internal::OrderedNameDictionary"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %5 = load i64, i64* %4, align 8
  %6 = add i64 %5, 11
  %7 = inttoptr i64 %6 to i32*
  %8 = load atomic i32, i32* %7 monotonic, align 4
  %9 = icmp ult i32 %8, 2
  br i1 %9, label %58, label %10

10:                                               ; preds = %3
  %11 = add i64 %2, 3
  %12 = inttoptr i64 %11 to i32*
  %13 = load i32, i32* %12, align 4
  %14 = add i64 %5, 19
  %15 = inttoptr i64 %14 to i32*
  %16 = load atomic i32, i32* %15 monotonic, align 4
  %17 = lshr i32 %16, 1
  %18 = shl i32 %17, 2
  %19 = add i32 %18, -4
  %20 = and i32 %19, %13
  %21 = add i32 %20, 16
  %22 = sext i32 %21 to i64
  %23 = add i64 %5, 7
  %24 = add i64 %23, %22
  %25 = inttoptr i64 %24 to i32*
  %26 = load atomic i32, i32* %25 monotonic, align 4
  %27 = ashr i32 %26, 1
  %28 = icmp eq i32 %27, -1
  br i1 %28, label %58, label %29

29:                                               ; preds = %10
  %30 = trunc i64 %2 to i32
  br label %31

31:                                               ; preds = %29, %44
  %32 = phi i32 [ %27, %29 ], [ %54, %44 ]
  %33 = load atomic i32, i32* %15 monotonic, align 4
  %34 = lshr i32 %33, 1
  %35 = shl i32 %32, 2
  %36 = add i32 %35, 4
  %37 = add i32 %34, %36
  %38 = shl i32 %37, 2
  %39 = sext i32 %38 to i64
  %40 = add i64 %23, %39
  %41 = inttoptr i64 %40 to i32*
  %42 = load atomic i32, i32* %41 monotonic, align 4
  %43 = icmp eq i32 %42, %30
  br i1 %43, label %56, label %44

44:                                               ; preds = %31
  %45 = load atomic i32, i32* %15 monotonic, align 4
  %46 = lshr i32 %45, 1
  %47 = add i32 %46, %36
  %48 = shl i32 %47, 2
  %49 = add i32 %48, 12
  %50 = sext i32 %49 to i64
  %51 = add i64 %23, %50
  %52 = inttoptr i64 %51 to i32*
  %53 = load atomic i32, i32* %52 monotonic, align 4
  %54 = ashr i32 %53, 1
  %55 = icmp eq i32 %54, -1
  br i1 %55, label %58, label %31

56:                                               ; preds = %31
  %57 = sext i32 %32 to i64
  br label %58

58:                                               ; preds = %44, %10, %56, %3
  %59 = phi i64 [ -1, %3 ], [ %57, %56 ], [ -1, %10 ], [ -1, %44 ]
  ret i64 %59
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64 @_ZN2v88internal21OrderedNameDictionary9FindEntryINS0_12LocalIsolateEEENS0_13InternalIndexEPT_NS0_6ObjectE(%"class.v8::internal::OrderedNameDictionary"*, %"class.v8::internal::LocalIsolate"*, i64) local_unnamed_addr #0 comdat align 2 {
  %4 = getelementptr inbounds %"class.v8::internal::OrderedNameDictionary", %"class.v8::internal::OrderedNameDictionary"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %5 = load i64, i64* %4, align 8
  %6 = add i64 %5, 11
  %7 = inttoptr i64 %6 to i32*
  %8 = load atomic i32, i32* %7 monotonic, align 4
  %9 = icmp ult i32 %8, 2
  br i1 %9, label %58, label %10

10:                                               ; preds = %3
  %11 = add i64 %2, 3
  %12 = inttoptr i64 %11 to i32*
  %13 = load i32, i32* %12, align 4
  %14 = add i64 %5, 19
  %15 = inttoptr i64 %14 to i32*
  %16 = load atomic i32, i32* %15 monotonic, align 4
  %17 = lshr i32 %16, 1
  %18 = shl i32 %17, 2
  %19 = add i32 %18, -4
  %20 = and i32 %19, %13
  %21 = add i32 %20, 16
  %22 = sext i32 %21 to i64
  %23 = add i64 %5, 7
  %24 = add i64 %23, %22
  %25 = inttoptr i64 %24 to i32*
  %26 = load atomic i32, i32* %25 monotonic, align 4
  %27 = ashr i32 %26, 1
  %28 = icmp eq i32 %27, -1
  br i1 %28, label %58, label %29

29:                                               ; preds = %10
  %30 = trunc i64 %2 to i32
  br label %31

31:                                               ; preds = %29, %44
  %32 = phi i32 [ %27, %29 ], [ %54, %44 ]
  %33 = load atomic i32, i32* %15 monotonic, align 4
  %34 = lshr i32 %33, 1
  %35 = shl i32 %32, 2
  %36 = add i32 %35, 4
  %37 = add i32 %34, %36
  %38 = shl i32 %37, 2
  %39 = sext i32 %38 to i64
  %40 = add i64 %23, %39
  %41 = inttoptr i64 %40 to i32*
  %42 = load atomic i32, i32* %41 monotonic, align 4
  %43 = icmp eq i32 %42, %30
  br i1 %43, label %56, label %44

44:                                               ; preds = %31
  %45 = load atomic i32, i32* %15 monotonic, align 4
  %46 = lshr i32 %45, 1
  %47 = add i32 %46, %36
  %48 = shl i32 %47, 2
  %49 = add i32 %48, 12
  %50 = sext i32 %49 to i64
  %51 = add i64 %23, %50
  %52 = inttoptr i64 %51 to i32*
  %53 = load atomic i32, i32* %52 monotonic, align 4
  %54 = ashr i32 %53, 1
  %55 = icmp eq i32 %54, -1
  br i1 %55, label %58, label %31

56:                                               ; preds = %31
  %57 = sext i32 %32 to i64
  br label %58

58:                                               ; preds = %44, %10, %56, %3
  %59 = phi i64 [ -1, %3 ], [ %57, %56 ], [ -1, %10 ], [ -1, %44 ]
  ret i64 %59
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal21OrderedNameDictionary3AddINS0_7IsolateEEENS0_11MaybeHandleIS1_EEPT_NS0_6HandleIS1_EENS8_INS0_4NameEEENS8_INS0_6ObjectEEENS0_15PropertyDetailsE(%"class.v8::internal::Isolate"*, i64*, i64*, i64*, i32) local_unnamed_addr #0 comdat align 2 {
  %6 = load i64, i64* %1, align 8
  %7 = add i64 %6, 11
  %8 = inttoptr i64 %7 to i32*
  %9 = load atomic i32, i32* %8 monotonic, align 4
  %10 = ashr i32 %9, 1
  %11 = add i64 %6, 15
  %12 = inttoptr i64 %11 to i32*
  %13 = load atomic i32, i32* %12 monotonic, align 4
  %14 = ashr i32 %13, 1
  %15 = add i64 %6, 19
  %16 = inttoptr i64 %15 to i32*
  %17 = load atomic i32, i32* %16 monotonic, align 4
  %18 = and i32 %17, -2
  %19 = add nsw i32 %14, %10
  %20 = icmp slt i32 %19, %18
  br i1 %20, label %42, label %21

21:                                               ; preds = %5
  %22 = icmp eq i32 %18, 0
  br i1 %22, label %28, label %23

23:                                               ; preds = %21
  %24 = ashr i32 %17, 1
  %25 = icmp slt i32 %14, %24
  %26 = zext i1 %25 to i32
  %27 = shl i32 %18, %26
  br label %28

28:                                               ; preds = %23, %21
  %29 = phi i32 [ 4, %21 ], [ %27, %23 ]
  %30 = tail call i64* @_ZN2v88internal16OrderedHashTableINS0_21OrderedNameDictionaryELi3EE6RehashINS0_7IsolateEEENS0_11MaybeHandleIS2_EEPT_NS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"* %0, i64* %1, i32 %29) #7
  %31 = icmp eq i64* %30, null
  br i1 %31, label %177, label %32

32:                                               ; preds = %28
  %33 = load i64, i64* %30, align 8
  %34 = load i64, i64* %1, align 8
  %35 = add i64 %34, 7
  %36 = inttoptr i64 %35 to i32*
  %37 = load atomic i32, i32* %36 monotonic, align 4
  %38 = and i32 %37, -2
  %39 = add i64 %33, 7
  %40 = inttoptr i64 %39 to i32*
  store atomic volatile i32 %38, i32* %40 monotonic, align 4
  %41 = ptrtoint i64* %30 to i64
  br label %45

42:                                               ; preds = %5
  %43 = ptrtoint i64* %1 to i64
  %44 = icmp eq i64* %1, null
  br i1 %44, label %177, label %45

45:                                               ; preds = %32, %42
  %46 = phi i64 [ %41, %32 ], [ %43, %42 ]
  %47 = load i64, i64* %2, align 8
  %48 = add i64 %47, 3
  %49 = inttoptr i64 %48 to i32*
  %50 = load i32, i32* %49, align 4
  %51 = lshr i32 %50, 2
  %52 = inttoptr i64 %46 to i64*
  %53 = load i64, i64* %52, align 8
  %54 = add i64 %53, 19
  %55 = inttoptr i64 %54 to i32*
  %56 = load atomic i32, i32* %55 monotonic, align 4
  %57 = lshr i32 %56, 1
  %58 = add nuw i32 %57, 1073741823
  %59 = and i32 %58, %51
  %60 = load atomic i32, i32* %55 monotonic, align 4
  %61 = lshr i32 %60, 1
  %62 = add nuw i32 %61, 1073741823
  %63 = and i32 %62, %51
  %64 = shl nuw i32 %63, 2
  %65 = add i32 %64, 16
  %66 = sext i32 %65 to i64
  %67 = add i64 %53, 7
  %68 = add i64 %67, %66
  %69 = inttoptr i64 %68 to i32*
  %70 = load atomic i32, i32* %69 monotonic, align 4
  %71 = and i32 %70, -2
  %72 = add i64 %53, 11
  %73 = inttoptr i64 %72 to i32*
  %74 = load atomic i32, i32* %73 monotonic, align 4
  %75 = ashr i32 %74, 1
  %76 = add i64 %53, 15
  %77 = inttoptr i64 %76 to i32*
  %78 = load atomic i32, i32* %77 monotonic, align 4
  %79 = ashr i32 %78, 1
  %80 = add nsw i32 %79, %75
  %81 = load atomic i32, i32* %55 monotonic, align 4
  %82 = lshr i32 %81, 1
  %83 = shl i32 %80, 2
  %84 = add nuw i32 %82, 4
  %85 = add i32 %84, %83
  %86 = shl i32 %85, 2
  %87 = sext i32 %86 to i64
  %88 = add i64 %67, %87
  %89 = inttoptr i64 %88 to i32*
  %90 = trunc i64 %47 to i32
  store atomic volatile i32 %90, i32* %89 monotonic, align 4
  %91 = and i64 %47, 1
  %92 = icmp eq i64 %91, 0
  br i1 %92, label %116, label %93

93:                                               ; preds = %45
  %94 = and i64 %53, -262144
  %95 = or i64 %94, 8
  %96 = inttoptr i64 %95 to i64*
  %97 = load i64, i64* %96, align 8
  %98 = and i64 %97, 262144
  %99 = icmp eq i64 %98, 0
  br i1 %99, label %104, label %100

100:                                              ; preds = %93
  %101 = or i64 %94, 16
  %102 = inttoptr i64 %101 to %"class.v8::internal::Heap"**
  %103 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %102, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %103, i64 %53, i64 %88, i64 %47) #7
  br label %104

104:                                              ; preds = %100, %93
  %105 = and i64 %47, -262144
  %106 = or i64 %105, 8
  %107 = inttoptr i64 %106 to i64*
  %108 = load i64, i64* %107, align 8
  %109 = and i64 %108, 24
  %110 = icmp eq i64 %109, 0
  br i1 %110, label %116, label %111

111:                                              ; preds = %104
  %112 = load i64, i64* %96, align 8
  %113 = and i64 %112, 24
  %114 = icmp eq i64 %113, 0
  br i1 %114, label %115, label %116

115:                                              ; preds = %111
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %53, i64 %88, i64 %47) #7
  br label %116

116:                                              ; preds = %45, %104, %111, %115
  %117 = load i64, i64* %52, align 8
  %118 = load i64, i64* %3, align 8
  %119 = add i32 %86, 4
  %120 = sext i32 %119 to i64
  %121 = add nsw i64 %120, 7
  %122 = add i64 %121, %117
  %123 = inttoptr i64 %122 to i32*
  %124 = trunc i64 %118 to i32
  store atomic volatile i32 %124, i32* %123 monotonic, align 4
  %125 = and i64 %118, 1
  %126 = icmp eq i64 %125, 0
  br i1 %126, label %150, label %127

127:                                              ; preds = %116
  %128 = and i64 %117, -262144
  %129 = or i64 %128, 8
  %130 = inttoptr i64 %129 to i64*
  %131 = load i64, i64* %130, align 8
  %132 = and i64 %131, 262144
  %133 = icmp eq i64 %132, 0
  br i1 %133, label %138, label %134

134:                                              ; preds = %127
  %135 = or i64 %128, 16
  %136 = inttoptr i64 %135 to %"class.v8::internal::Heap"**
  %137 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %136, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %137, i64 %117, i64 %122, i64 %118) #7
  br label %138

138:                                              ; preds = %134, %127
  %139 = and i64 %118, -262144
  %140 = or i64 %139, 8
  %141 = inttoptr i64 %140 to i64*
  %142 = load i64, i64* %141, align 8
  %143 = and i64 %142, 24
  %144 = icmp eq i64 %143, 0
  br i1 %144, label %150, label %145

145:                                              ; preds = %138
  %146 = load i64, i64* %130, align 8
  %147 = and i64 %146, 24
  %148 = icmp eq i64 %147, 0
  br i1 %148, label %149, label %150

149:                                              ; preds = %145
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %117, i64 %122, i64 %118) #7
  br label %150

150:                                              ; preds = %116, %138, %145, %149
  %151 = load i64, i64* %52, align 8
  %152 = shl i32 %4, 1
  %153 = add i32 %86, 8
  %154 = sext i32 %153 to i64
  %155 = add nsw i64 %154, 7
  %156 = add i64 %155, %151
  %157 = inttoptr i64 %156 to i32*
  store atomic volatile i32 %152, i32* %157 monotonic, align 4
  %158 = load i64, i64* %52, align 8
  %159 = add i32 %86, 12
  %160 = sext i32 %159 to i64
  %161 = add nsw i64 %160, 7
  %162 = add i64 %161, %158
  %163 = inttoptr i64 %162 to i32*
  store atomic volatile i32 %71, i32* %163 monotonic, align 4
  %164 = load i64, i64* %52, align 8
  %165 = shl i32 %80, 1
  %166 = shl nuw i32 %59, 2
  %167 = add i32 %166, 16
  %168 = sext i32 %167 to i64
  %169 = add nsw i64 %168, 7
  %170 = add i64 %169, %164
  %171 = inttoptr i64 %170 to i32*
  store atomic volatile i32 %165, i32* %171 monotonic, align 4
  %172 = load i64, i64* %52, align 8
  %173 = add i32 %74, 2
  %174 = and i32 %173, -2
  %175 = add i64 %172, 11
  %176 = inttoptr i64 %175 to i32*
  store atomic volatile i32 %174, i32* %176 monotonic, align 4
  br label %177

177:                                              ; preds = %28, %42, %150
  %178 = phi i64 [ %46, %150 ], [ %43, %42 ], [ 0, %28 ]
  %179 = inttoptr i64 %178 to i64*
  ret i64* %179
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal21OrderedNameDictionary3AddINS0_12LocalIsolateEEENS0_11MaybeHandleIS1_EEPT_NS0_6HandleIS1_EENS8_INS0_4NameEEENS8_INS0_6ObjectEEENS0_15PropertyDetailsE(%"class.v8::internal::LocalIsolate"*, i64*, i64*, i64*, i32) local_unnamed_addr #0 comdat align 2 {
  %6 = load i64, i64* %1, align 8
  %7 = add i64 %6, 11
  %8 = inttoptr i64 %7 to i32*
  %9 = load atomic i32, i32* %8 monotonic, align 4
  %10 = ashr i32 %9, 1
  %11 = add i64 %6, 15
  %12 = inttoptr i64 %11 to i32*
  %13 = load atomic i32, i32* %12 monotonic, align 4
  %14 = ashr i32 %13, 1
  %15 = add i64 %6, 19
  %16 = inttoptr i64 %15 to i32*
  %17 = load atomic i32, i32* %16 monotonic, align 4
  %18 = and i32 %17, -2
  %19 = add nsw i32 %14, %10
  %20 = icmp slt i32 %19, %18
  br i1 %20, label %42, label %21

21:                                               ; preds = %5
  %22 = icmp eq i32 %18, 0
  br i1 %22, label %28, label %23

23:                                               ; preds = %21
  %24 = ashr i32 %17, 1
  %25 = icmp slt i32 %14, %24
  %26 = zext i1 %25 to i32
  %27 = shl i32 %18, %26
  br label %28

28:                                               ; preds = %23, %21
  %29 = phi i32 [ 4, %21 ], [ %27, %23 ]
  %30 = tail call i64* @_ZN2v88internal16OrderedHashTableINS0_21OrderedNameDictionaryELi3EE6RehashINS0_12LocalIsolateEEENS0_11MaybeHandleIS2_EEPT_NS0_6HandleIS2_EEi(%"class.v8::internal::LocalIsolate"* %0, i64* %1, i32 %29) #7
  %31 = icmp eq i64* %30, null
  br i1 %31, label %177, label %32

32:                                               ; preds = %28
  %33 = load i64, i64* %30, align 8
  %34 = load i64, i64* %1, align 8
  %35 = add i64 %34, 7
  %36 = inttoptr i64 %35 to i32*
  %37 = load atomic i32, i32* %36 monotonic, align 4
  %38 = and i32 %37, -2
  %39 = add i64 %33, 7
  %40 = inttoptr i64 %39 to i32*
  store atomic volatile i32 %38, i32* %40 monotonic, align 4
  %41 = ptrtoint i64* %30 to i64
  br label %45

42:                                               ; preds = %5
  %43 = ptrtoint i64* %1 to i64
  %44 = icmp eq i64* %1, null
  br i1 %44, label %177, label %45

45:                                               ; preds = %32, %42
  %46 = phi i64 [ %41, %32 ], [ %43, %42 ]
  %47 = load i64, i64* %2, align 8
  %48 = add i64 %47, 3
  %49 = inttoptr i64 %48 to i32*
  %50 = load i32, i32* %49, align 4
  %51 = lshr i32 %50, 2
  %52 = inttoptr i64 %46 to i64*
  %53 = load i64, i64* %52, align 8
  %54 = add i64 %53, 19
  %55 = inttoptr i64 %54 to i32*
  %56 = load atomic i32, i32* %55 monotonic, align 4
  %57 = lshr i32 %56, 1
  %58 = add nuw i32 %57, 1073741823
  %59 = and i32 %58, %51
  %60 = load atomic i32, i32* %55 monotonic, align 4
  %61 = lshr i32 %60, 1
  %62 = add nuw i32 %61, 1073741823
  %63 = and i32 %62, %51
  %64 = shl nuw i32 %63, 2
  %65 = add i32 %64, 16
  %66 = sext i32 %65 to i64
  %67 = add i64 %53, 7
  %68 = add i64 %67, %66
  %69 = inttoptr i64 %68 to i32*
  %70 = load atomic i32, i32* %69 monotonic, align 4
  %71 = and i32 %70, -2
  %72 = add i64 %53, 11
  %73 = inttoptr i64 %72 to i32*
  %74 = load atomic i32, i32* %73 monotonic, align 4
  %75 = ashr i32 %74, 1
  %76 = add i64 %53, 15
  %77 = inttoptr i64 %76 to i32*
  %78 = load atomic i32, i32* %77 monotonic, align 4
  %79 = ashr i32 %78, 1
  %80 = add nsw i32 %79, %75
  %81 = load atomic i32, i32* %55 monotonic, align 4
  %82 = lshr i32 %81, 1
  %83 = shl i32 %80, 2
  %84 = add nuw i32 %82, 4
  %85 = add i32 %84, %83
  %86 = shl i32 %85, 2
  %87 = sext i32 %86 to i64
  %88 = add i64 %67, %87
  %89 = inttoptr i64 %88 to i32*
  %90 = trunc i64 %47 to i32
  store atomic volatile i32 %90, i32* %89 monotonic, align 4
  %91 = and i64 %47, 1
  %92 = icmp eq i64 %91, 0
  br i1 %92, label %116, label %93

93:                                               ; preds = %45
  %94 = and i64 %53, -262144
  %95 = or i64 %94, 8
  %96 = inttoptr i64 %95 to i64*
  %97 = load i64, i64* %96, align 8
  %98 = and i64 %97, 262144
  %99 = icmp eq i64 %98, 0
  br i1 %99, label %104, label %100

100:                                              ; preds = %93
  %101 = or i64 %94, 16
  %102 = inttoptr i64 %101 to %"class.v8::internal::Heap"**
  %103 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %102, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %103, i64 %53, i64 %88, i64 %47) #7
  br label %104

104:                                              ; preds = %100, %93
  %105 = and i64 %47, -262144
  %106 = or i64 %105, 8
  %107 = inttoptr i64 %106 to i64*
  %108 = load i64, i64* %107, align 8
  %109 = and i64 %108, 24
  %110 = icmp eq i64 %109, 0
  br i1 %110, label %116, label %111

111:                                              ; preds = %104
  %112 = load i64, i64* %96, align 8
  %113 = and i64 %112, 24
  %114 = icmp eq i64 %113, 0
  br i1 %114, label %115, label %116

115:                                              ; preds = %111
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %53, i64 %88, i64 %47) #7
  br label %116

116:                                              ; preds = %45, %104, %111, %115
  %117 = load i64, i64* %52, align 8
  %118 = load i64, i64* %3, align 8
  %119 = add i32 %86, 4
  %120 = sext i32 %119 to i64
  %121 = add nsw i64 %120, 7
  %122 = add i64 %121, %117
  %123 = inttoptr i64 %122 to i32*
  %124 = trunc i64 %118 to i32
  store atomic volatile i32 %124, i32* %123 monotonic, align 4
  %125 = and i64 %118, 1
  %126 = icmp eq i64 %125, 0
  br i1 %126, label %150, label %127

127:                                              ; preds = %116
  %128 = and i64 %117, -262144
  %129 = or i64 %128, 8
  %130 = inttoptr i64 %129 to i64*
  %131 = load i64, i64* %130, align 8
  %132 = and i64 %131, 262144
  %133 = icmp eq i64 %132, 0
  br i1 %133, label %138, label %134

134:                                              ; preds = %127
  %135 = or i64 %128, 16
  %136 = inttoptr i64 %135 to %"class.v8::internal::Heap"**
  %137 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %136, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %137, i64 %117, i64 %122, i64 %118) #7
  br label %138

138:                                              ; preds = %134, %127
  %139 = and i64 %118, -262144
  %140 = or i64 %139, 8
  %141 = inttoptr i64 %140 to i64*
  %142 = load i64, i64* %141, align 8
  %143 = and i64 %142, 24
  %144 = icmp eq i64 %143, 0
  br i1 %144, label %150, label %145

145:                                              ; preds = %138
  %146 = load i64, i64* %130, align 8
  %147 = and i64 %146, 24
  %148 = icmp eq i64 %147, 0
  br i1 %148, label %149, label %150

149:                                              ; preds = %145
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %117, i64 %122, i64 %118) #7
  br label %150

150:                                              ; preds = %116, %138, %145, %149
  %151 = load i64, i64* %52, align 8
  %152 = shl i32 %4, 1
  %153 = add i32 %86, 8
  %154 = sext i32 %153 to i64
  %155 = add nsw i64 %154, 7
  %156 = add i64 %155, %151
  %157 = inttoptr i64 %156 to i32*
  store atomic volatile i32 %152, i32* %157 monotonic, align 4
  %158 = load i64, i64* %52, align 8
  %159 = add i32 %86, 12
  %160 = sext i32 %159 to i64
  %161 = add nsw i64 %160, 7
  %162 = add i64 %161, %158
  %163 = inttoptr i64 %162 to i32*
  store atomic volatile i32 %71, i32* %163 monotonic, align 4
  %164 = load i64, i64* %52, align 8
  %165 = shl i32 %80, 1
  %166 = shl nuw i32 %59, 2
  %167 = add i32 %166, 16
  %168 = sext i32 %167 to i64
  %169 = add nsw i64 %168, 7
  %170 = add i64 %169, %164
  %171 = inttoptr i64 %170 to i32*
  store atomic volatile i32 %165, i32* %171 monotonic, align 4
  %172 = load i64, i64* %52, align 8
  %173 = add i32 %74, 2
  %174 = and i32 %173, -2
  %175 = add i64 %172, 11
  %176 = inttoptr i64 %175 to i32*
  store atomic volatile i32 %174, i32* %176 monotonic, align 4
  br label %177

177:                                              ; preds = %28, %42, %150
  %178 = phi i64 [ %46, %150 ], [ %43, %42 ], [ 0, %28 ]
  %179 = inttoptr i64 %178 to i64*
  ret i64* %179
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden zeroext i1 @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashSetEE6HasKeyEPNS0_7IsolateENS0_6HandleINS0_6ObjectEEE(%"class.v8::internal::SmallOrderedHashTable"*, %"class.v8::internal::Isolate"*, i64*) local_unnamed_addr #0 comdat align 2 {
  %4 = load i64, i64* %2, align 8
  %5 = tail call i64 @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashSetEE9FindEntryEPNS0_7IsolateENS0_6ObjectE(%"class.v8::internal::SmallOrderedHashTable"* %0, %"class.v8::internal::Isolate"* %1, i64 %4)
  %6 = icmp ne i64 %5, -1
  ret i1 %6
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashSetEE9FindEntryEPNS0_7IsolateENS0_6ObjectE(%"class.v8::internal::SmallOrderedHashTable"*, %"class.v8::internal::Isolate"*, i64) local_unnamed_addr #0 comdat align 2 {
  %4 = alloca %"class.v8::internal::JSReceiver", align 8
  %5 = alloca %"class.v8::internal::Object", align 8
  %6 = tail call i64 @_ZN2v88internal6Object13GetSimpleHashES1_(i64 %2) #7
  %7 = and i64 %6, 1
  %8 = icmp eq i64 %7, 0
  br i1 %8, label %13, label %9

9:                                                ; preds = %3
  %10 = bitcast %"class.v8::internal::JSReceiver"* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %10) #7
  %11 = getelementptr inbounds %"class.v8::internal::JSReceiver", %"class.v8::internal::JSReceiver"* %4, i64 0, i32 0, i32 0, i32 0, i32 0
  store i64 %2, i64* %11, align 8
  %12 = call i64 @_ZN2v88internal10JSReceiver15GetIdentityHashEv(%"class.v8::internal::JSReceiver"* nonnull %4) #7
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %10) #7
  br label %13

13:                                               ; preds = %3, %9
  %14 = phi i64 [ %12, %9 ], [ %6, %3 ]
  %15 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %1, i64 0, i32 0, i32 7, i32 0, i64 4
  %16 = load i64, i64* %15, align 8
  %17 = trunc i64 %14 to i32
  %18 = trunc i64 %16 to i32
  %19 = icmp eq i32 %17, %18
  br i1 %19, label %74, label %20

20:                                               ; preds = %13
  %21 = ashr i32 %17, 1
  %22 = getelementptr inbounds %"class.v8::internal::SmallOrderedHashTable", %"class.v8::internal::SmallOrderedHashTable"* %0, i64 0, i32 0, i32 0, i32 0, i32 0
  %23 = load i64, i64* %22, align 8
  %24 = add i64 %23, 5
  %25 = inttoptr i64 %24 to i8*
  %26 = load i8, i8* %25, align 1
  %27 = zext i8 %26 to i32
  %28 = add nsw i32 %27, -1
  %29 = and i32 %28, %21
  %30 = shl nuw nsw i32 %27, 3
  %31 = add nuw nsw i32 %30, 8
  %32 = add nsw i32 %31, %29
  %33 = sext i32 %32 to i64
  %34 = add i64 %23, -1
  %35 = add i64 %34, %33
  %36 = inttoptr i64 %35 to i8*
  %37 = load i8, i8* %36, align 1
  %38 = icmp eq i8 %37, -1
  br i1 %38, label %74, label %39

39:                                               ; preds = %20
  %40 = bitcast %"class.v8::internal::Object"* %5 to i8*
  %41 = getelementptr inbounds %"class.v8::internal::Object", %"class.v8::internal::Object"* %5, i64 0, i32 0, i32 0
  br label %42

42:                                               ; preds = %39, %58
  %43 = phi i64 [ %23, %39 ], [ %59, %58 ]
  %44 = phi i8 [ %37, %39 ], [ %72, %58 ]
  %45 = zext i8 %44 to i32
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %40) #7
  %46 = shl nuw nsw i32 %45, 2
  %47 = add nuw nsw i32 %46, 7
  %48 = zext i32 %47 to i64
  %49 = add i64 %43, %48
  %50 = inttoptr i64 %49 to i32*
  %51 = load i32, i32* %50, align 4
  %52 = and i64 %43, -4294967296
  %53 = zext i32 %51 to i64
  %54 = or i64 %52, %53
  store i64 %54, i64* %41, align 8
  %55 = call zeroext i1 @_ZN2v88internal6Object13SameValueZeroES1_(%"class.v8::internal::Object"* nonnull %5, i64 %2) #7
  br i1 %55, label %56, label %58

56:                                               ; preds = %42
  %57 = zext i8 %44 to i64
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %40) #7
  br label %74

58:                                               ; preds = %42
  %59 = load i64, i64* %22, align 8
  %60 = add i64 %59, 5
  %61 = inttoptr i64 %60 to i8*
  %62 = load i8, i8* %61, align 1
  %63 = zext i8 %62 to i32
  %64 = shl nuw nsw i32 %63, 3
  %65 = add nuw nsw i32 %45, 8
  %66 = add nuw nsw i32 %65, %63
  %67 = add nuw nsw i32 %66, %64
  %68 = zext i32 %67 to i64
  %69 = add i64 %59, -1
  %70 = add i64 %69, %68
  %71 = inttoptr i64 %70 to i8*
  %72 = load i8, i8* %71, align 1
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %40) #7
  %73 = icmp eq i8 %72, -1
  br i1 %73, label %74, label %42

74:                                               ; preds = %58, %20, %56, %13
  %75 = phi i64 [ -1, %13 ], [ %57, %56 ], [ -1, %20 ], [ -1, %58 ]
  ret i64 %75
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashSetEE6RehashEPNS0_7IsolateENS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"*, i64*, i32) local_unnamed_addr #0 comdat align 2 {
  %4 = alloca %"class.v8::internal::JSReceiver", align 8
  %5 = load i64, i64* %1, align 8
  %6 = and i64 %5, -262144
  %7 = inttoptr i64 %6 to %"class.v8::internal::BasicMemoryChunk"*
  %8 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %7, i64 0, i32 1
  %9 = load i64, i64* %8, align 8
  %10 = and i64 %9, 24
  %11 = icmp eq i64 %10, 0
  %12 = zext i1 %11 to i8
  %13 = bitcast %"class.v8::internal::Isolate"* %0 to %"class.v8::internal::Factory"*
  %14 = tail call i64* @_ZN2v88internal7Factory22NewSmallOrderedHashSetEiNS0_14AllocationTypeE(%"class.v8::internal::Factory"* %13, i32 %2, i8 zeroext %12) #7
  %15 = load i64, i64* %1, align 8
  %16 = add i64 %15, 3
  %17 = inttoptr i64 %16 to i8*
  %18 = load i8, i8* %17, align 1
  %19 = zext i8 %18 to i64
  %20 = add i64 %15, 4
  %21 = inttoptr i64 %20 to i8*
  %22 = load i8, i8* %21, align 1
  %23 = zext i8 %22 to i64
  %24 = add nuw nsw i64 %23, %19
  %25 = icmp eq i64 %24, 0
  br i1 %25, label %33, label %26

26:                                               ; preds = %3
  %27 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 5
  %28 = bitcast %"class.v8::internal::JSReceiver"* %4 to i8*
  %29 = getelementptr inbounds %"class.v8::internal::JSReceiver", %"class.v8::internal::JSReceiver"* %4, i64 0, i32 0, i32 0, i32 0, i32 0
  br label %39

30:                                               ; preds = %137
  %31 = add i64 %141, 3
  %32 = inttoptr i64 %31 to i8*
  br label %33

33:                                               ; preds = %30, %3
  %34 = phi i8* [ %32, %30 ], [ %17, %3 ]
  %35 = load i64, i64* %14, align 8
  %36 = load i8, i8* %34, align 1
  %37 = add i64 %35, 3
  %38 = inttoptr i64 %37 to i8*
  store i8 %36, i8* %38, align 1
  ret i64* %14

39:                                               ; preds = %137, %26
  %40 = phi i64 [ %15, %26 ], [ %141, %137 ]
  %41 = phi i32 [ 0, %26 ], [ %138, %137 ]
  %42 = phi i64 [ 0, %26 ], [ %139, %137 ]
  %43 = trunc i64 %42 to i32
  %44 = shl i32 %43, 2
  %45 = add i32 %44, 8
  %46 = sext i32 %45 to i64
  %47 = add nsw i64 %46, -1
  %48 = add i64 %47, %40
  %49 = inttoptr i64 %48 to i32*
  %50 = load i32, i32* %49, align 4
  %51 = and i64 %40, -4294967296
  %52 = zext i32 %50 to i64
  %53 = or i64 %51, %52
  %54 = load i64, i64* %27, align 8
  %55 = trunc i64 %54 to i32
  %56 = icmp eq i32 %50, %55
  br i1 %56, label %137, label %57

57:                                               ; preds = %39
  %58 = call i64 @_ZN2v88internal6Object13GetSimpleHashES1_(i64 %53) #7
  %59 = and i64 %58, 1
  %60 = icmp eq i64 %59, 0
  br i1 %60, label %63, label %61

61:                                               ; preds = %57
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %28) #7
  store i64 %53, i64* %29, align 8
  %62 = call i64 @_ZN2v88internal10JSReceiver15GetIdentityHashEv(%"class.v8::internal::JSReceiver"* nonnull %4) #7
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %28) #7
  br label %63

63:                                               ; preds = %57, %61
  %64 = phi i64 [ %62, %61 ], [ %58, %57 ]
  %65 = trunc i64 %64 to i32
  %66 = ashr i32 %65, 1
  %67 = load i64, i64* %14, align 8
  %68 = add i64 %67, 5
  %69 = inttoptr i64 %68 to i8*
  %70 = load i8, i8* %69, align 1
  %71 = zext i8 %70 to i32
  %72 = add nsw i32 %71, -1
  %73 = and i32 %72, %66
  %74 = shl nuw nsw i32 %71, 3
  %75 = add nuw nsw i32 %74, 8
  %76 = add nsw i32 %75, %73
  %77 = sext i32 %76 to i64
  %78 = add i64 %67, -1
  %79 = add i64 %78, %77
  %80 = inttoptr i64 %79 to i8*
  %81 = load i8, i8* %80, align 1
  %82 = trunc i32 %41 to i8
  store i8 %82, i8* %80, align 1
  %83 = load i64, i64* %14, align 8
  %84 = add i64 %83, 5
  %85 = inttoptr i64 %84 to i8*
  %86 = load i8, i8* %85, align 1
  %87 = zext i8 %86 to i32
  %88 = shl nuw nsw i32 %87, 3
  %89 = add i32 %41, 8
  %90 = add i32 %89, %87
  %91 = add i32 %90, %88
  %92 = sext i32 %91 to i64
  %93 = add i64 %83, -1
  %94 = add i64 %93, %92
  %95 = inttoptr i64 %94 to i8*
  store i8 %81, i8* %95, align 1
  %96 = load i64, i64* %1, align 8
  %97 = add i64 %47, %96
  %98 = inttoptr i64 %97 to i32*
  %99 = load i32, i32* %98, align 4
  %100 = and i64 %96, -4294967296
  %101 = zext i32 %99 to i64
  %102 = or i64 %100, %101
  %103 = load i64, i64* %14, align 8
  %104 = shl i32 %41, 2
  %105 = add i32 %104, 8
  %106 = sext i32 %105 to i64
  %107 = add nsw i64 %106, -1
  %108 = add i64 %107, %103
  %109 = inttoptr i64 %108 to i32*
  store atomic volatile i32 %99, i32* %109 monotonic, align 4
  %110 = and i64 %101, 1
  %111 = icmp eq i64 %110, 0
  br i1 %111, label %135, label %112

112:                                              ; preds = %63
  %113 = and i64 %103, -262144
  %114 = or i64 %113, 8
  %115 = inttoptr i64 %114 to i64*
  %116 = load i64, i64* %115, align 8
  %117 = and i64 %116, 262144
  %118 = icmp eq i64 %117, 0
  br i1 %118, label %123, label %119

119:                                              ; preds = %112
  %120 = or i64 %113, 16
  %121 = inttoptr i64 %120 to %"class.v8::internal::Heap"**
  %122 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %121, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %122, i64 %103, i64 %108, i64 %102) #7
  br label %123

123:                                              ; preds = %119, %112
  %124 = and i64 %102, -262144
  %125 = or i64 %124, 8
  %126 = inttoptr i64 %125 to i64*
  %127 = load i64, i64* %126, align 8
  %128 = and i64 %127, 24
  %129 = icmp eq i64 %128, 0
  br i1 %129, label %135, label %130

130:                                              ; preds = %123
  %131 = load i64, i64* %115, align 8
  %132 = and i64 %131, 24
  %133 = icmp eq i64 %132, 0
  br i1 %133, label %134, label %135

134:                                              ; preds = %130
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %103, i64 %108, i64 %102) #7
  br label %135

135:                                              ; preds = %63, %123, %130, %134
  %136 = add nsw i32 %41, 1
  br label %137

137:                                              ; preds = %39, %135
  %138 = phi i32 [ %136, %135 ], [ %41, %39 ]
  %139 = add nuw nsw i64 %42, 1
  %140 = icmp eq i64 %139, %24
  %141 = load i64, i64* %1, align 8
  br i1 %140, label %30, label %39
}

; Function Attrs: nounwind ssp uwtable
define hidden i64* @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashSetEE8AllocateEPNS0_7IsolateEiNS0_14AllocationTypeE(%"class.v8::internal::Isolate"*, i32, i8 zeroext) local_unnamed_addr #0 align 2 {
  %4 = bitcast %"class.v8::internal::Isolate"* %0 to %"class.v8::internal::Factory"*
  %5 = tail call i64* @_ZN2v88internal7Factory22NewSmallOrderedHashSetEiNS0_14AllocationTypeE(%"class.v8::internal::Factory"* %4, i32 %1, i8 zeroext %2) #7
  ret i64* %5
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashSetEE6ShrinkEPNS0_7IsolateENS0_6HandleIS2_EE(%"class.v8::internal::Isolate"*, i64*) local_unnamed_addr #0 comdat align 2 {
  %3 = load i64, i64* %1, align 8
  %4 = add i64 %3, 3
  %5 = inttoptr i64 %4 to i8*
  %6 = load i8, i8* %5, align 1
  %7 = add i64 %3, 5
  %8 = inttoptr i64 %7 to i8*
  %9 = load i8, i8* %8, align 1
  %10 = lshr i8 %9, 1
  %11 = icmp ugt i8 %10, %6
  br i1 %11, label %12, label %15

12:                                               ; preds = %2
  %13 = zext i8 %9 to i32
  %14 = tail call i64* @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashSetEE6RehashEPNS0_7IsolateENS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"* %0, i64* %1, i32 %13) #7
  br label %15

15:                                               ; preds = %2, %12
  %16 = phi i64* [ %14, %12 ], [ %1, %2 ]
  ret i64* %16
}

; Function Attrs: nounwind ssp uwtable
define hidden i64* @_ZN2v88internal19SmallOrderedHashSet6RehashEPNS0_7IsolateENS0_6HandleIS1_EEi(%"class.v8::internal::Isolate"*, i64*, i32) local_unnamed_addr #0 align 2 {
  %4 = tail call i64* @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashSetEE6RehashEPNS0_7IsolateENS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"* %0, i64* %1, i32 %2)
  ret i64* %4
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashSetEE4GrowEPNS0_7IsolateENS0_6HandleIS2_EE(%"class.v8::internal::Isolate"*, i64*) local_unnamed_addr #0 comdat align 2 {
  %3 = load i64, i64* %1, align 8
  %4 = add i64 %3, 5
  %5 = inttoptr i64 %4 to i8*
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i32
  %8 = shl nuw nsw i32 %7, 1
  %9 = add i64 %3, 4
  %10 = inttoptr i64 %9 to i8*
  %11 = load i8, i8* %10, align 1
  %12 = icmp ult i8 %11, %6
  br i1 %12, label %13, label %18

13:                                               ; preds = %2
  %14 = shl nuw nsw i32 %7, 2
  %15 = icmp eq i8 %6, 64
  %16 = select i1 %15, i32 254, i32 %14
  %17 = icmp ugt i32 %16, 254
  br i1 %17, label %21, label %18

18:                                               ; preds = %13, %2
  %19 = phi i32 [ %16, %13 ], [ %8, %2 ]
  %20 = tail call i64* @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashSetEE6RehashEPNS0_7IsolateENS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"* %0, i64* %1, i32 %19) #7
  br label %21

21:                                               ; preds = %13, %18
  %22 = phi i64* [ %20, %18 ], [ null, %13 ]
  ret i64* %22
}

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #1

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden void @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashSetEE10InitializeEPNS0_7IsolateEi(%"class.v8::internal::SmallOrderedHashTable"*, %"class.v8::internal::Isolate"*, i32) local_unnamed_addr #0 comdat align 2 {
  %4 = sdiv i32 %2, 2
  %5 = trunc i32 %4 to i8
  %6 = getelementptr inbounds %"class.v8::internal::SmallOrderedHashTable", %"class.v8::internal::SmallOrderedHashTable"* %0, i64 0, i32 0, i32 0, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, 5
  %9 = inttoptr i64 %8 to i8*
  store i8 %5, i8* %9, align 1
  %10 = load i64, i64* %6, align 8
  %11 = add i64 %10, 3
  %12 = inttoptr i64 %11 to i8*
  store i8 0, i8* %12, align 1
  %13 = load i64, i64* %6, align 8
  %14 = add i64 %13, 4
  %15 = inttoptr i64 %14 to i8*
  store i8 0, i8* %15, align 1
  %16 = load i64, i64* %6, align 8
  %17 = add i64 %16, 6
  %18 = inttoptr i64 %17 to i8*
  store i8 0, i8* %18, align 1
  %19 = shl nsw i32 %2, 2
  %20 = load i64, i64* %6, align 8
  %21 = sext i32 %19 to i64
  %22 = add nsw i64 %21, 7
  %23 = add i64 %22, %20
  %24 = inttoptr i64 %23 to i8*
  %25 = add nsw i32 %4, %2
  %26 = sext i32 %25 to i64
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %24, i8 -1, i64 %26, i1 false)
  %27 = load i64, i64* %6, align 8
  %28 = add i64 %27, 7
  %29 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %1, i64 0, i32 0, i32 7, i32 0, i64 5
  %30 = load i64, i64* %29, align 8
  %31 = sext i32 %2 to i64
  %32 = inttoptr i64 %28 to i32*
  %33 = trunc i64 %30 to i32
  %34 = tail call { i64, i32* } asm sideeffect "cld;rep ; stosl", "=&{cx},=&{di},{ax},0,1,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(i32 %33, i64 %31, i32* %32) #7, !srcloc !3
  ret void
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden zeroext i1 @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashSetEE6DeleteEPNS0_7IsolateES2_NS0_6ObjectE(%"class.v8::internal::Isolate"*, i64, i64) local_unnamed_addr #0 comdat align 2 {
  %4 = alloca %"class.v8::internal::SmallOrderedHashSet", align 8
  %5 = getelementptr inbounds %"class.v8::internal::SmallOrderedHashSet", %"class.v8::internal::SmallOrderedHashSet"* %4, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %1, i64* %5, align 8
  %6 = getelementptr inbounds %"class.v8::internal::SmallOrderedHashSet", %"class.v8::internal::SmallOrderedHashSet"* %4, i64 0, i32 0
  %7 = call i64 @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashSetEE9FindEntryEPNS0_7IsolateENS0_6ObjectE(%"class.v8::internal::SmallOrderedHashTable"* nonnull %6, %"class.v8::internal::Isolate"* %0, i64 %2)
  %8 = icmp eq i64 %7, -1
  br i1 %8, label %71, label %9

9:                                                ; preds = %3
  %10 = load i64, i64* %5, align 8
  %11 = add i64 %10, 3
  %12 = inttoptr i64 %11 to i8*
  %13 = load i8, i8* %12, align 1
  %14 = add i64 %10, 4
  %15 = inttoptr i64 %14 to i8*
  %16 = load i8, i8* %15, align 1
  %17 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 5
  %18 = load i64, i64* %17, align 8
  %19 = trunc i64 %7 to i32
  %20 = trunc i64 %18 to i32
  %21 = and i64 %18, 1
  %22 = icmp eq i64 %21, 0
  %23 = and i64 %18, -262144
  %24 = or i64 %23, 8
  %25 = inttoptr i64 %24 to i64*
  %26 = shl i32 %19, 2
  %27 = add i32 %26, 8
  %28 = sext i32 %27 to i64
  %29 = add nsw i64 %28, -1
  %30 = add i64 %10, %29
  %31 = inttoptr i64 %30 to i32*
  store atomic volatile i32 %20, i32* %31 monotonic, align 4
  %32 = load i64, i64* %5, align 8
  %33 = add i64 %32, %29
  br i1 %22, label %34, label %43

34:                                               ; preds = %9, %69, %62, %56
  %35 = phi i64 [ %32, %9 ], [ %70, %69 ], [ %58, %62 ], [ %58, %56 ]
  %36 = add i8 %13, -1
  %37 = add i64 %35, 3
  %38 = inttoptr i64 %37 to i8*
  store i8 %36, i8* %38, align 1
  %39 = add i8 %16, 1
  %40 = load i64, i64* %5, align 8
  %41 = add i64 %40, 4
  %42 = inttoptr i64 %41 to i8*
  store i8 %39, i8* %42, align 1
  br label %71

43:                                               ; preds = %9
  %44 = and i64 %32, -262144
  %45 = or i64 %44, 8
  %46 = inttoptr i64 %45 to i64*
  %47 = load i64, i64* %46, align 8
  %48 = and i64 %47, 262144
  %49 = icmp eq i64 %48, 0
  br i1 %49, label %56, label %50

50:                                               ; preds = %43
  %51 = or i64 %44, 16
  %52 = inttoptr i64 %51 to %"class.v8::internal::Heap"**
  %53 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %52, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %53, i64 %32, i64 %33, i64 %18) #7
  %54 = load i64, i64* %5, align 8
  %55 = add i64 %54, %29
  br label %56

56:                                               ; preds = %50, %43
  %57 = phi i64 [ %33, %43 ], [ %55, %50 ]
  %58 = phi i64 [ %32, %43 ], [ %54, %50 ]
  %59 = load i64, i64* %25, align 8
  %60 = and i64 %59, 24
  %61 = icmp eq i64 %60, 0
  br i1 %61, label %34, label %62

62:                                               ; preds = %56
  %63 = and i64 %58, -262144
  %64 = or i64 %63, 8
  %65 = inttoptr i64 %64 to i64*
  %66 = load i64, i64* %65, align 8
  %67 = and i64 %66, 24
  %68 = icmp eq i64 %67, 0
  br i1 %68, label %69, label %34

69:                                               ; preds = %62
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %58, i64 %57, i64 %18) #7
  %70 = load i64, i64* %5, align 8
  br label %34

71:                                               ; preds = %3, %34
  %72 = phi i1 [ true, %34 ], [ false, %3 ]
  ret i1 %72
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden zeroext i1 @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashMapEE6HasKeyEPNS0_7IsolateENS0_6HandleINS0_6ObjectEEE(%"class.v8::internal::SmallOrderedHashTable.1143"*, %"class.v8::internal::Isolate"*, i64*) local_unnamed_addr #0 comdat align 2 {
  %4 = load i64, i64* %2, align 8
  %5 = tail call i64 @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashMapEE9FindEntryEPNS0_7IsolateENS0_6ObjectE(%"class.v8::internal::SmallOrderedHashTable.1143"* %0, %"class.v8::internal::Isolate"* %1, i64 %4)
  %6 = icmp ne i64 %5, -1
  ret i1 %6
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashMapEE9FindEntryEPNS0_7IsolateENS0_6ObjectE(%"class.v8::internal::SmallOrderedHashTable.1143"*, %"class.v8::internal::Isolate"*, i64) local_unnamed_addr #0 comdat align 2 {
  %4 = alloca %"class.v8::internal::JSReceiver", align 8
  %5 = alloca %"class.v8::internal::Object", align 8
  %6 = tail call i64 @_ZN2v88internal6Object13GetSimpleHashES1_(i64 %2) #7
  %7 = and i64 %6, 1
  %8 = icmp eq i64 %7, 0
  br i1 %8, label %13, label %9

9:                                                ; preds = %3
  %10 = bitcast %"class.v8::internal::JSReceiver"* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %10) #7
  %11 = getelementptr inbounds %"class.v8::internal::JSReceiver", %"class.v8::internal::JSReceiver"* %4, i64 0, i32 0, i32 0, i32 0, i32 0
  store i64 %2, i64* %11, align 8
  %12 = call i64 @_ZN2v88internal10JSReceiver15GetIdentityHashEv(%"class.v8::internal::JSReceiver"* nonnull %4) #7
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %10) #7
  br label %13

13:                                               ; preds = %3, %9
  %14 = phi i64 [ %12, %9 ], [ %6, %3 ]
  %15 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %1, i64 0, i32 0, i32 7, i32 0, i64 4
  %16 = load i64, i64* %15, align 8
  %17 = trunc i64 %14 to i32
  %18 = trunc i64 %16 to i32
  %19 = icmp eq i32 %17, %18
  br i1 %19, label %74, label %20

20:                                               ; preds = %13
  %21 = ashr i32 %17, 1
  %22 = getelementptr inbounds %"class.v8::internal::SmallOrderedHashTable.1143", %"class.v8::internal::SmallOrderedHashTable.1143"* %0, i64 0, i32 0, i32 0, i32 0, i32 0
  %23 = load i64, i64* %22, align 8
  %24 = add i64 %23, 5
  %25 = inttoptr i64 %24 to i8*
  %26 = load i8, i8* %25, align 1
  %27 = zext i8 %26 to i32
  %28 = add nsw i32 %27, -1
  %29 = and i32 %28, %21
  %30 = shl nuw nsw i32 %27, 4
  %31 = or i32 %30, 8
  %32 = add nsw i32 %31, %29
  %33 = sext i32 %32 to i64
  %34 = add i64 %23, -1
  %35 = add i64 %34, %33
  %36 = inttoptr i64 %35 to i8*
  %37 = load i8, i8* %36, align 1
  %38 = icmp eq i8 %37, -1
  br i1 %38, label %74, label %39

39:                                               ; preds = %20
  %40 = bitcast %"class.v8::internal::Object"* %5 to i8*
  %41 = getelementptr inbounds %"class.v8::internal::Object", %"class.v8::internal::Object"* %5, i64 0, i32 0, i32 0
  br label %42

42:                                               ; preds = %39, %58
  %43 = phi i64 [ %23, %39 ], [ %59, %58 ]
  %44 = phi i8 [ %37, %39 ], [ %72, %58 ]
  %45 = zext i8 %44 to i32
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %40) #7
  %46 = shl nuw nsw i32 %45, 3
  %47 = or i32 %46, 7
  %48 = zext i32 %47 to i64
  %49 = add i64 %43, %48
  %50 = inttoptr i64 %49 to i32*
  %51 = load i32, i32* %50, align 4
  %52 = and i64 %43, -4294967296
  %53 = zext i32 %51 to i64
  %54 = or i64 %52, %53
  store i64 %54, i64* %41, align 8
  %55 = call zeroext i1 @_ZN2v88internal6Object13SameValueZeroES1_(%"class.v8::internal::Object"* nonnull %5, i64 %2) #7
  br i1 %55, label %56, label %58

56:                                               ; preds = %42
  %57 = zext i8 %44 to i64
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %40) #7
  br label %74

58:                                               ; preds = %42
  %59 = load i64, i64* %22, align 8
  %60 = add i64 %59, 5
  %61 = inttoptr i64 %60 to i8*
  %62 = load i8, i8* %61, align 1
  %63 = zext i8 %62 to i32
  %64 = shl nuw nsw i32 %63, 4
  %65 = or i32 %64, 8
  %66 = add nuw nsw i32 %63, %45
  %67 = add nuw nsw i32 %66, %65
  %68 = zext i32 %67 to i64
  %69 = add i64 %59, -1
  %70 = add i64 %69, %68
  %71 = inttoptr i64 %70 to i8*
  %72 = load i8, i8* %71, align 1
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %40) #7
  %73 = icmp eq i8 %72, -1
  br i1 %73, label %74, label %42

74:                                               ; preds = %58, %20, %56, %13
  %75 = phi i64 [ -1, %13 ], [ %57, %56 ], [ -1, %20 ], [ -1, %58 ]
  ret i64 %75
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashMapEE6RehashEPNS0_7IsolateENS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"*, i64*, i32) local_unnamed_addr #0 comdat align 2 {
  %4 = alloca %"class.v8::internal::JSReceiver", align 8
  %5 = load i64, i64* %1, align 8
  %6 = and i64 %5, -262144
  %7 = inttoptr i64 %6 to %"class.v8::internal::BasicMemoryChunk"*
  %8 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %7, i64 0, i32 1
  %9 = load i64, i64* %8, align 8
  %10 = and i64 %9, 24
  %11 = icmp eq i64 %10, 0
  %12 = zext i1 %11 to i8
  %13 = bitcast %"class.v8::internal::Isolate"* %0 to %"class.v8::internal::Factory"*
  %14 = tail call i64* @_ZN2v88internal7Factory22NewSmallOrderedHashMapEiNS0_14AllocationTypeE(%"class.v8::internal::Factory"* %13, i32 %2, i8 zeroext %12) #7
  %15 = load i64, i64* %1, align 8
  %16 = add i64 %15, 3
  %17 = inttoptr i64 %16 to i8*
  %18 = load i8, i8* %17, align 1
  %19 = zext i8 %18 to i64
  %20 = add i64 %15, 4
  %21 = inttoptr i64 %20 to i8*
  %22 = load i8, i8* %21, align 1
  %23 = zext i8 %22 to i64
  %24 = add nuw nsw i64 %23, %19
  %25 = icmp eq i64 %24, 0
  br i1 %25, label %33, label %26

26:                                               ; preds = %3
  %27 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 5
  %28 = bitcast %"class.v8::internal::JSReceiver"* %4 to i8*
  %29 = getelementptr inbounds %"class.v8::internal::JSReceiver", %"class.v8::internal::JSReceiver"* %4, i64 0, i32 0, i32 0, i32 0, i32 0
  br label %39

30:                                               ; preds = %152
  %31 = add i64 %156, 3
  %32 = inttoptr i64 %31 to i8*
  br label %33

33:                                               ; preds = %30, %3
  %34 = phi i8* [ %32, %30 ], [ %17, %3 ]
  %35 = load i64, i64* %14, align 8
  %36 = load i8, i8* %34, align 1
  %37 = add i64 %35, 3
  %38 = inttoptr i64 %37 to i8*
  store i8 %36, i8* %38, align 1
  ret i64* %14

39:                                               ; preds = %152, %26
  %40 = phi i64 [ %15, %26 ], [ %156, %152 ]
  %41 = phi i32 [ 0, %26 ], [ %153, %152 ]
  %42 = phi i64 [ 0, %26 ], [ %154, %152 ]
  %43 = trunc i64 %42 to i32
  %44 = shl i32 %43, 3
  %45 = or i32 %44, 7
  %46 = sext i32 %45 to i64
  %47 = add i64 %40, %46
  %48 = inttoptr i64 %47 to i32*
  %49 = load i32, i32* %48, align 4
  %50 = and i64 %40, -4294967296
  %51 = zext i32 %49 to i64
  %52 = or i64 %50, %51
  %53 = load i64, i64* %27, align 8
  %54 = trunc i64 %53 to i32
  %55 = icmp eq i32 %49, %54
  br i1 %55, label %152, label %56

56:                                               ; preds = %39
  %57 = call i64 @_ZN2v88internal6Object13GetSimpleHashES1_(i64 %52) #7
  %58 = and i64 %57, 1
  %59 = icmp eq i64 %58, 0
  br i1 %59, label %62, label %60

60:                                               ; preds = %56
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %28) #7
  store i64 %52, i64* %29, align 8
  %61 = call i64 @_ZN2v88internal10JSReceiver15GetIdentityHashEv(%"class.v8::internal::JSReceiver"* nonnull %4) #7
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %28) #7
  br label %62

62:                                               ; preds = %56, %60
  %63 = phi i64 [ %61, %60 ], [ %57, %56 ]
  %64 = trunc i64 %63 to i32
  %65 = ashr i32 %64, 1
  %66 = load i64, i64* %14, align 8
  %67 = add i64 %66, 5
  %68 = inttoptr i64 %67 to i8*
  %69 = load i8, i8* %68, align 1
  %70 = zext i8 %69 to i32
  %71 = add nsw i32 %70, -1
  %72 = and i32 %71, %65
  %73 = shl nuw nsw i32 %70, 4
  %74 = or i32 %73, 8
  %75 = add nsw i32 %74, %72
  %76 = sext i32 %75 to i64
  %77 = add i64 %66, -1
  %78 = add i64 %77, %76
  %79 = inttoptr i64 %78 to i8*
  %80 = load i8, i8* %79, align 1
  %81 = trunc i32 %41 to i8
  store i8 %81, i8* %79, align 1
  %82 = load i64, i64* %14, align 8
  %83 = add i64 %82, 5
  %84 = inttoptr i64 %83 to i8*
  %85 = load i8, i8* %84, align 1
  %86 = zext i8 %85 to i32
  %87 = shl nuw nsw i32 %86, 4
  %88 = or i32 %87, 8
  %89 = add i32 %41, %86
  %90 = add i32 %89, %88
  %91 = sext i32 %90 to i64
  %92 = add i64 %82, -1
  %93 = add i64 %92, %91
  %94 = inttoptr i64 %93 to i8*
  store i8 %80, i8* %94, align 1
  %95 = shl i32 %41, 3
  %96 = sext i32 %44 to i64
  %97 = load i64, i64* %1, align 8
  %98 = or i64 %96, 7
  %99 = add i64 %98, %97
  %100 = inttoptr i64 %99 to i32*
  %101 = load i32, i32* %100, align 4
  %102 = and i64 %97, -4294967296
  %103 = zext i32 %101 to i64
  %104 = or i64 %102, %103
  %105 = load i64, i64* %14, align 8
  %106 = add i32 %95, 8
  %107 = sext i32 %106 to i64
  %108 = add nsw i64 %107, -1
  %109 = add i64 %108, %105
  %110 = inttoptr i64 %109 to i32*
  store atomic volatile i32 %101, i32* %110 monotonic, align 4
  %111 = and i64 %103, 1
  %112 = icmp eq i64 %111, 0
  br i1 %112, label %136, label %113

113:                                              ; preds = %62
  %114 = and i64 %105, -262144
  %115 = or i64 %114, 8
  %116 = inttoptr i64 %115 to i64*
  %117 = load i64, i64* %116, align 8
  %118 = and i64 %117, 262144
  %119 = icmp eq i64 %118, 0
  br i1 %119, label %124, label %120

120:                                              ; preds = %113
  %121 = or i64 %114, 16
  %122 = inttoptr i64 %121 to %"class.v8::internal::Heap"**
  %123 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %122, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %123, i64 %105, i64 %109, i64 %104) #7
  br label %124

124:                                              ; preds = %120, %113
  %125 = and i64 %104, -262144
  %126 = or i64 %125, 8
  %127 = inttoptr i64 %126 to i64*
  %128 = load i64, i64* %127, align 8
  %129 = and i64 %128, 24
  %130 = icmp eq i64 %129, 0
  br i1 %130, label %136, label %131

131:                                              ; preds = %124
  %132 = load i64, i64* %116, align 8
  %133 = and i64 %132, 24
  %134 = icmp eq i64 %133, 0
  br i1 %134, label %135, label %136

135:                                              ; preds = %131
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %105, i64 %109, i64 %104) #7
  br label %136

136:                                              ; preds = %62, %124, %131, %135
  %137 = load i64, i64* %1, align 8
  %138 = add nsw i64 %96, 11
  %139 = add i64 %138, %137
  %140 = inttoptr i64 %139 to i32*
  %141 = load i32, i32* %140, align 4
  %142 = and i64 %137, -4294967296
  %143 = zext i32 %141 to i64
  %144 = or i64 %142, %143
  %145 = load i64, i64* %14, align 8
  %146 = add i32 %95, 11
  %147 = sext i32 %146 to i64
  %148 = add i64 %145, %147
  %149 = inttoptr i64 %148 to i32*
  store atomic volatile i32 %141, i32* %149 monotonic, align 4
  %150 = and i64 %143, 1
  %151 = icmp eq i64 %150, 0
  br i1 %151, label %180, label %157

152:                                              ; preds = %39, %180
  %153 = phi i32 [ %181, %180 ], [ %41, %39 ]
  %154 = add nuw nsw i64 %42, 1
  %155 = icmp eq i64 %154, %24
  %156 = load i64, i64* %1, align 8
  br i1 %155, label %30, label %39

157:                                              ; preds = %136
  %158 = and i64 %145, -262144
  %159 = or i64 %158, 8
  %160 = inttoptr i64 %159 to i64*
  %161 = load i64, i64* %160, align 8
  %162 = and i64 %161, 262144
  %163 = icmp eq i64 %162, 0
  br i1 %163, label %168, label %164

164:                                              ; preds = %157
  %165 = or i64 %158, 16
  %166 = inttoptr i64 %165 to %"class.v8::internal::Heap"**
  %167 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %166, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %167, i64 %145, i64 %148, i64 %144) #7
  br label %168

168:                                              ; preds = %164, %157
  %169 = and i64 %144, -262144
  %170 = or i64 %169, 8
  %171 = inttoptr i64 %170 to i64*
  %172 = load i64, i64* %171, align 8
  %173 = and i64 %172, 24
  %174 = icmp eq i64 %173, 0
  br i1 %174, label %180, label %175

175:                                              ; preds = %168
  %176 = load i64, i64* %160, align 8
  %177 = and i64 %176, 24
  %178 = icmp eq i64 %177, 0
  br i1 %178, label %179, label %180

179:                                              ; preds = %175
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %145, i64 %148, i64 %144) #7
  br label %180

180:                                              ; preds = %179, %175, %168, %136
  %181 = add nsw i32 %41, 1
  br label %152
}

; Function Attrs: nounwind ssp uwtable
define hidden i64* @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashMapEE8AllocateEPNS0_7IsolateEiNS0_14AllocationTypeE(%"class.v8::internal::Isolate"*, i32, i8 zeroext) local_unnamed_addr #0 align 2 {
  %4 = bitcast %"class.v8::internal::Isolate"* %0 to %"class.v8::internal::Factory"*
  %5 = tail call i64* @_ZN2v88internal7Factory22NewSmallOrderedHashMapEiNS0_14AllocationTypeE(%"class.v8::internal::Factory"* %4, i32 %1, i8 zeroext %2) #7
  ret i64* %5
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashMapEE6ShrinkEPNS0_7IsolateENS0_6HandleIS2_EE(%"class.v8::internal::Isolate"*, i64*) local_unnamed_addr #0 comdat align 2 {
  %3 = load i64, i64* %1, align 8
  %4 = add i64 %3, 3
  %5 = inttoptr i64 %4 to i8*
  %6 = load i8, i8* %5, align 1
  %7 = add i64 %3, 5
  %8 = inttoptr i64 %7 to i8*
  %9 = load i8, i8* %8, align 1
  %10 = lshr i8 %9, 1
  %11 = icmp ugt i8 %10, %6
  br i1 %11, label %12, label %15

12:                                               ; preds = %2
  %13 = zext i8 %9 to i32
  %14 = tail call i64* @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashMapEE6RehashEPNS0_7IsolateENS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"* %0, i64* %1, i32 %13) #7
  br label %15

15:                                               ; preds = %2, %12
  %16 = phi i64* [ %14, %12 ], [ %1, %2 ]
  ret i64* %16
}

; Function Attrs: nounwind ssp uwtable
define hidden i64* @_ZN2v88internal19SmallOrderedHashMap6RehashEPNS0_7IsolateENS0_6HandleIS1_EEi(%"class.v8::internal::Isolate"*, i64*, i32) local_unnamed_addr #0 align 2 {
  %4 = tail call i64* @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashMapEE6RehashEPNS0_7IsolateENS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"* %0, i64* %1, i32 %2)
  ret i64* %4
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashMapEE4GrowEPNS0_7IsolateENS0_6HandleIS2_EE(%"class.v8::internal::Isolate"*, i64*) local_unnamed_addr #0 comdat align 2 {
  %3 = load i64, i64* %1, align 8
  %4 = add i64 %3, 5
  %5 = inttoptr i64 %4 to i8*
  %6 = load i8, i8* %5, align 1
  %7 = zext i8 %6 to i32
  %8 = shl nuw nsw i32 %7, 1
  %9 = add i64 %3, 4
  %10 = inttoptr i64 %9 to i8*
  %11 = load i8, i8* %10, align 1
  %12 = icmp ult i8 %11, %6
  br i1 %12, label %13, label %18

13:                                               ; preds = %2
  %14 = shl nuw nsw i32 %7, 2
  %15 = icmp eq i8 %6, 64
  %16 = select i1 %15, i32 254, i32 %14
  %17 = icmp ugt i32 %16, 254
  br i1 %17, label %21, label %18

18:                                               ; preds = %13, %2
  %19 = phi i32 [ %16, %13 ], [ %8, %2 ]
  %20 = tail call i64* @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashMapEE6RehashEPNS0_7IsolateENS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"* %0, i64* %1, i32 %19) #7
  br label %21

21:                                               ; preds = %13, %18
  %22 = phi i64* [ %20, %18 ], [ null, %13 ]
  ret i64* %22
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden void @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashMapEE10InitializeEPNS0_7IsolateEi(%"class.v8::internal::SmallOrderedHashTable.1143"*, %"class.v8::internal::Isolate"*, i32) local_unnamed_addr #0 comdat align 2 {
  %4 = sdiv i32 %2, 2
  %5 = trunc i32 %4 to i8
  %6 = getelementptr inbounds %"class.v8::internal::SmallOrderedHashTable.1143", %"class.v8::internal::SmallOrderedHashTable.1143"* %0, i64 0, i32 0, i32 0, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, 5
  %9 = inttoptr i64 %8 to i8*
  store i8 %5, i8* %9, align 1
  %10 = load i64, i64* %6, align 8
  %11 = add i64 %10, 3
  %12 = inttoptr i64 %11 to i8*
  store i8 0, i8* %12, align 1
  %13 = load i64, i64* %6, align 8
  %14 = add i64 %13, 4
  %15 = inttoptr i64 %14 to i8*
  store i8 0, i8* %15, align 1
  %16 = load i64, i64* %6, align 8
  %17 = add i64 %16, 6
  %18 = inttoptr i64 %17 to i8*
  store i8 0, i8* %18, align 1
  %19 = shl nsw i32 %2, 3
  %20 = load i64, i64* %6, align 8
  %21 = or i32 %19, 7
  %22 = sext i32 %21 to i64
  %23 = add i64 %20, %22
  %24 = inttoptr i64 %23 to i8*
  %25 = add nsw i32 %4, %2
  %26 = sext i32 %25 to i64
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %24, i8 -1, i64 %26, i1 false)
  %27 = load i64, i64* %6, align 8
  %28 = add i64 %27, 7
  %29 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %1, i64 0, i32 0, i32 7, i32 0, i64 5
  %30 = load i64, i64* %29, align 8
  %31 = shl nsw i32 %2, 1
  %32 = sext i32 %31 to i64
  %33 = inttoptr i64 %28 to i32*
  %34 = trunc i64 %30 to i32
  %35 = tail call { i64, i32* } asm sideeffect "cld;rep ; stosl", "=&{cx},=&{di},{ax},0,1,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(i32 %34, i64 %32, i32* %33) #7, !srcloc !3
  ret void
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden zeroext i1 @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashMapEE6DeleteEPNS0_7IsolateES2_NS0_6ObjectE(%"class.v8::internal::Isolate"*, i64, i64) local_unnamed_addr #0 comdat align 2 {
  %4 = alloca %"class.v8::internal::SmallOrderedHashMap", align 8
  %5 = getelementptr inbounds %"class.v8::internal::SmallOrderedHashMap", %"class.v8::internal::SmallOrderedHashMap"* %4, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %1, i64* %5, align 8
  %6 = getelementptr inbounds %"class.v8::internal::SmallOrderedHashMap", %"class.v8::internal::SmallOrderedHashMap"* %4, i64 0, i32 0
  %7 = call i64 @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashMapEE9FindEntryEPNS0_7IsolateENS0_6ObjectE(%"class.v8::internal::SmallOrderedHashTable.1143"* nonnull %6, %"class.v8::internal::Isolate"* %0, i64 %2)
  %8 = icmp eq i64 %7, -1
  br i1 %8, label %91, label %9

9:                                                ; preds = %3
  %10 = load i64, i64* %5, align 8
  %11 = add i64 %10, 3
  %12 = inttoptr i64 %11 to i8*
  %13 = load i8, i8* %12, align 1
  %14 = add i64 %10, 4
  %15 = inttoptr i64 %14 to i8*
  %16 = load i8, i8* %15, align 1
  %17 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 5
  %18 = load i64, i64* %17, align 8
  %19 = trunc i64 %7 to i32
  %20 = shl i32 %19, 3
  %21 = add nsw i32 %20, 8
  %22 = trunc i64 %18 to i32
  %23 = and i64 %18, 1
  %24 = icmp eq i64 %23, 0
  %25 = and i64 %18, -262144
  %26 = or i64 %25, 8
  %27 = inttoptr i64 %26 to i64*
  %28 = sext i32 %21 to i64
  %29 = add nsw i64 %28, -1
  %30 = add i64 %10, %29
  %31 = inttoptr i64 %30 to i32*
  store atomic volatile i32 %22, i32* %31 monotonic, align 4
  br i1 %24, label %41, label %32

32:                                               ; preds = %9
  %33 = load i64, i64* %5, align 8
  %34 = add i64 %33, %29
  %35 = and i64 %33, -262144
  %36 = or i64 %35, 8
  %37 = inttoptr i64 %36 to i64*
  %38 = load i64, i64* %37, align 8
  %39 = and i64 %38, 262144
  %40 = icmp eq i64 %39, 0
  br i1 %40, label %62, label %56

41:                                               ; preds = %9
  %42 = or i64 %28, 4
  %43 = load i64, i64* %5, align 8
  %44 = add nsw i64 %42, -1
  %45 = add i64 %43, %44
  %46 = inttoptr i64 %45 to i32*
  store atomic volatile i32 %22, i32* %46 monotonic, align 4
  br label %47

47:                                               ; preds = %99, %105, %112, %41
  %48 = add i8 %13, -1
  %49 = load i64, i64* %5, align 8
  %50 = add i64 %49, 3
  %51 = inttoptr i64 %50 to i8*
  store i8 %48, i8* %51, align 1
  %52 = add i8 %16, 1
  %53 = load i64, i64* %5, align 8
  %54 = add i64 %53, 4
  %55 = inttoptr i64 %54 to i8*
  store i8 %52, i8* %55, align 1
  br label %91

56:                                               ; preds = %32
  %57 = or i64 %35, 16
  %58 = inttoptr i64 %57 to %"class.v8::internal::Heap"**
  %59 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %58, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %59, i64 %33, i64 %34, i64 %18) #7
  %60 = load i64, i64* %5, align 8
  %61 = add i64 %60, %29
  br label %62

62:                                               ; preds = %56, %32
  %63 = phi i64 [ %34, %32 ], [ %61, %56 ]
  %64 = phi i64 [ %33, %32 ], [ %60, %56 ]
  %65 = load i64, i64* %27, align 8
  %66 = and i64 %65, 24
  %67 = icmp eq i64 %66, 0
  br i1 %67, label %77, label %68

68:                                               ; preds = %62
  %69 = and i64 %64, -262144
  %70 = or i64 %69, 8
  %71 = inttoptr i64 %70 to i64*
  %72 = load i64, i64* %71, align 8
  %73 = and i64 %72, 24
  %74 = icmp eq i64 %73, 0
  br i1 %74, label %75, label %77

75:                                               ; preds = %68
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %64, i64 %63, i64 %18) #7
  %76 = load i64, i64* %5, align 8
  br label %77

77:                                               ; preds = %62, %68, %75
  %78 = phi i64 [ %64, %62 ], [ %64, %68 ], [ %76, %75 ]
  %79 = or i64 %28, 4
  %80 = add nsw i64 %79, -1
  %81 = add i64 %78, %80
  %82 = inttoptr i64 %81 to i32*
  store atomic volatile i32 %22, i32* %82 monotonic, align 4
  %83 = load i64, i64* %5, align 8
  %84 = add i64 %83, %80
  %85 = and i64 %83, -262144
  %86 = or i64 %85, 8
  %87 = inttoptr i64 %86 to i64*
  %88 = load i64, i64* %87, align 8
  %89 = and i64 %88, 262144
  %90 = icmp eq i64 %89, 0
  br i1 %90, label %99, label %93

91:                                               ; preds = %3, %47
  %92 = phi i1 [ true, %47 ], [ false, %3 ]
  ret i1 %92

93:                                               ; preds = %77
  %94 = or i64 %85, 16
  %95 = inttoptr i64 %94 to %"class.v8::internal::Heap"**
  %96 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %95, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %96, i64 %83, i64 %84, i64 %18) #7
  %97 = load i64, i64* %5, align 8
  %98 = add i64 %97, %80
  br label %99

99:                                               ; preds = %93, %77
  %100 = phi i64 [ %84, %77 ], [ %98, %93 ]
  %101 = phi i64 [ %83, %77 ], [ %97, %93 ]
  %102 = load i64, i64* %27, align 8
  %103 = and i64 %102, 24
  %104 = icmp eq i64 %103, 0
  br i1 %104, label %47, label %105

105:                                              ; preds = %99
  %106 = and i64 %101, -262144
  %107 = or i64 %106, 8
  %108 = inttoptr i64 %107 to i64*
  %109 = load i64, i64* %108, align 8
  %110 = and i64 %109, 24
  %111 = icmp eq i64 %110, 0
  br i1 %111, label %112, label %47

112:                                              ; preds = %105
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %101, i64 %100, i64 %18) #7
  br label %47
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden void @_ZN2v88internal21SmallOrderedHashTableINS0_26SmallOrderedNameDictionaryEE10InitializeEPNS0_7IsolateEi(%"class.v8::internal::SmallOrderedHashTable.1146"*, %"class.v8::internal::Isolate"*, i32) local_unnamed_addr #0 comdat align 2 {
  %4 = sdiv i32 %2, 2
  %5 = trunc i32 %4 to i8
  %6 = getelementptr inbounds %"class.v8::internal::SmallOrderedHashTable.1146", %"class.v8::internal::SmallOrderedHashTable.1146"* %0, i64 0, i32 0, i32 0, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = add i64 %7, 9
  %9 = inttoptr i64 %8 to i8*
  store i8 %5, i8* %9, align 1
  %10 = load i64, i64* %6, align 8
  %11 = add i64 %10, 7
  %12 = inttoptr i64 %11 to i8*
  store i8 0, i8* %12, align 1
  %13 = load i64, i64* %6, align 8
  %14 = add i64 %13, 8
  %15 = inttoptr i64 %14 to i8*
  store i8 0, i8* %15, align 1
  %16 = load i64, i64* %6, align 8
  %17 = add i64 %16, 10
  %18 = inttoptr i64 %17 to i8*
  store i8 0, i8* %18, align 1
  %19 = mul i32 %2, 12
  %20 = load i64, i64* %6, align 8
  %21 = sext i32 %19 to i64
  %22 = add nsw i64 %21, 11
  %23 = add i64 %22, %20
  %24 = inttoptr i64 %23 to i8*
  %25 = add nsw i32 %4, %2
  %26 = sext i32 %25 to i64
  tail call void @llvm.memset.p0i8.i64(i8* align 1 %24, i8 -1, i64 %26, i1 false)
  %27 = load i64, i64* %6, align 8
  %28 = add i64 %27, 11
  %29 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %1, i64 0, i32 0, i32 7, i32 0, i64 5
  %30 = load i64, i64* %29, align 8
  %31 = mul nsw i32 %2, 3
  %32 = sext i32 %31 to i64
  %33 = inttoptr i64 %28 to i32*
  %34 = trunc i64 %30 to i32
  %35 = tail call { i64, i32* } asm sideeffect "cld;rep ; stosl", "=&{cx},=&{di},{ax},0,1,~{memory},~{cc},~{dirflag},~{fpsr},~{flags}"(i32 %34, i64 %32, i32* %33) #7, !srcloc !3
  ret void
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal21SmallOrderedHashTableINS0_26SmallOrderedNameDictionaryEE6ShrinkEPNS0_7IsolateENS0_6HandleIS2_EE(%"class.v8::internal::Isolate"*, i64*) local_unnamed_addr #0 comdat align 2 {
  %3 = load i64, i64* %1, align 8
  %4 = add i64 %3, 7
  %5 = inttoptr i64 %4 to i8*
  %6 = load i8, i8* %5, align 1
  %7 = add i64 %3, 9
  %8 = inttoptr i64 %7 to i8*
  %9 = load i8, i8* %8, align 1
  %10 = lshr i8 %9, 1
  %11 = icmp ugt i8 %10, %6
  br i1 %11, label %12, label %22

12:                                               ; preds = %2
  %13 = zext i8 %9 to i32
  %14 = tail call i64* @_ZN2v88internal21SmallOrderedHashTableINS0_26SmallOrderedNameDictionaryEE6RehashEPNS0_7IsolateENS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"* %0, i64* %1, i32 %13) #7
  %15 = load i64, i64* %14, align 8
  %16 = load i64, i64* %1, align 8
  %17 = add i64 %16, 3
  %18 = inttoptr i64 %17 to i32*
  %19 = load i32, i32* %18, align 4
  %20 = add i64 %15, 3
  %21 = inttoptr i64 %20 to i32*
  store i32 %19, i32* %21, align 4
  br label %22

22:                                               ; preds = %2, %12
  %23 = phi i64* [ %14, %12 ], [ %1, %2 ]
  ret i64* %23
}

; Function Attrs: nounwind ssp uwtable
define hidden i64* @_ZN2v88internal26SmallOrderedNameDictionary6RehashEPNS0_7IsolateENS0_6HandleIS1_EEi(%"class.v8::internal::Isolate"*, i64*, i32) local_unnamed_addr #0 align 2 {
  %4 = tail call i64* @_ZN2v88internal21SmallOrderedHashTableINS0_26SmallOrderedNameDictionaryEE6RehashEPNS0_7IsolateENS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"* %0, i64* %1, i32 %2)
  %5 = load i64, i64* %4, align 8
  %6 = load i64, i64* %1, align 8
  %7 = add i64 %6, 3
  %8 = inttoptr i64 %7 to i32*
  %9 = load i32, i32* %8, align 4
  %10 = add i64 %5, 3
  %11 = inttoptr i64 %10 to i32*
  store i32 %9, i32* %11, align 4
  ret i64* %4
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal23OrderedHashTableHandlerINS0_19SmallOrderedHashSetENS0_14OrderedHashSetEE8AllocateEPNS0_7IsolateEi(%"class.v8::internal::Isolate"*, i32) local_unnamed_addr #0 comdat align 2 {
  %3 = icmp slt i32 %1, 254
  br i1 %3, label %4, label %7

4:                                                ; preds = %2
  %5 = bitcast %"class.v8::internal::Isolate"* %0 to %"class.v8::internal::Factory"*
  %6 = tail call i64* @_ZN2v88internal7Factory22NewSmallOrderedHashSetEiNS0_14AllocationTypeE(%"class.v8::internal::Factory"* %5, i32 %1, i8 zeroext 0) #7
  br label %77

7:                                                ; preds = %2
  %8 = tail call i32 @_ZN2v84base4bits21RoundUpToPowerOfTwo32Ej(i32 %1) #7
  %9 = icmp sgt i32 %8, 26843544
  br i1 %9, label %77, label %10

10:                                               ; preds = %7
  %11 = sdiv i32 %8, 2
  %12 = bitcast %"class.v8::internal::Isolate"* %0 to %"class.v8::internal::FactoryBase"*
  %13 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 55
  %14 = add nsw i32 %11, 3
  %15 = shl i32 %8, 1
  %16 = add nsw i32 %14, %15
  %17 = tail call i64* @_ZN2v88internal11FactoryBaseINS0_7FactoryEE20NewFixedArrayWithMapENS0_6HandleINS0_3MapEEEiNS0_14AllocationTypeE(%"class.v8::internal::FactoryBase"* %12, i64* %13, i32 %16, i8 zeroext 0) #7
  %18 = icmp sgt i32 %8, 1
  %19 = load i64, i64* %17, align 8
  br i1 %18, label %20, label %42

20:                                               ; preds = %10
  %21 = zext i32 %11 to i64
  %22 = and i64 %21, 1
  %23 = and i32 %8, -2
  %24 = icmp eq i32 %23, 2
  br i1 %24, label %32, label %25

25:                                               ; preds = %20
  %26 = sub nsw i64 %21, %22
  br label %53

27:                                               ; preds = %53
  %28 = trunc i64 %73 to i32
  %29 = shl i32 %28, 2
  %30 = add i32 %29, 12
  %31 = sext i32 %30 to i64
  br label %32

32:                                               ; preds = %27, %20
  %33 = phi i64 [ undef, %20 ], [ %74, %27 ]
  %34 = phi i64 [ 12, %20 ], [ %31, %27 ]
  %35 = phi i64 [ %19, %20 ], [ %74, %27 ]
  %36 = icmp eq i64 %22, 0
  br i1 %36, label %42, label %37

37:                                               ; preds = %32
  %38 = add i64 %35, 7
  %39 = add i64 %38, %34
  %40 = inttoptr i64 %39 to i32*
  store atomic volatile i32 -2, i32* %40 monotonic, align 4
  %41 = load i64, i64* %17, align 8
  br label %42

42:                                               ; preds = %37, %32, %10
  %43 = phi i64 [ %19, %10 ], [ %33, %32 ], [ %41, %37 ]
  %44 = shl nsw i32 %11, 1
  %45 = add i64 %43, 15
  %46 = inttoptr i64 %45 to i32*
  store atomic volatile i32 %44, i32* %46 monotonic, align 4
  %47 = load i64, i64* %17, align 8
  %48 = add i64 %47, 7
  %49 = inttoptr i64 %48 to i32*
  store atomic volatile i32 0, i32* %49 monotonic, align 4
  %50 = load i64, i64* %17, align 8
  %51 = add i64 %50, 11
  %52 = inttoptr i64 %51 to i32*
  store atomic volatile i32 0, i32* %52 monotonic, align 4
  br label %77

53:                                               ; preds = %53, %25
  %54 = phi i64 [ 0, %25 ], [ %73, %53 ]
  %55 = phi i64 [ %19, %25 ], [ %74, %53 ]
  %56 = phi i64 [ %26, %25 ], [ %75, %53 ]
  %57 = trunc i64 %54 to i32
  %58 = shl i32 %57, 2
  %59 = add i32 %58, 12
  %60 = sext i32 %59 to i64
  %61 = add i64 %55, 7
  %62 = add i64 %61, %60
  %63 = inttoptr i64 %62 to i32*
  store atomic volatile i32 -2, i32* %63 monotonic, align 4
  %64 = load i64, i64* %17, align 8
  %65 = trunc i64 %54 to i32
  %66 = shl i32 %65, 2
  %67 = or i32 %66, 4
  %68 = add i32 %67, 12
  %69 = sext i32 %68 to i64
  %70 = add i64 %64, 7
  %71 = add i64 %70, %69
  %72 = inttoptr i64 %71 to i32*
  store atomic volatile i32 -2, i32* %72 monotonic, align 4
  %73 = add nuw nsw i64 %54, 2
  %74 = load i64, i64* %17, align 8
  %75 = add i64 %56, -2
  %76 = icmp eq i64 %75, 0
  br i1 %76, label %27, label %53

77:                                               ; preds = %42, %7, %4
  %78 = phi i64* [ %6, %4 ], [ %17, %42 ], [ null, %7 ]
  ret i64* %78
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal23OrderedHashTableHandlerINS0_19SmallOrderedHashMapENS0_14OrderedHashMapEE8AllocateEPNS0_7IsolateEi(%"class.v8::internal::Isolate"*, i32) local_unnamed_addr #0 comdat align 2 {
  %3 = icmp slt i32 %1, 254
  br i1 %3, label %4, label %7

4:                                                ; preds = %2
  %5 = bitcast %"class.v8::internal::Isolate"* %0 to %"class.v8::internal::Factory"*
  %6 = tail call i64* @_ZN2v88internal7Factory22NewSmallOrderedHashMapEiNS0_14AllocationTypeE(%"class.v8::internal::Factory"* %5, i32 %1, i8 zeroext 0) #7
  br label %77

7:                                                ; preds = %2
  %8 = tail call i32 @_ZN2v84base4bits21RoundUpToPowerOfTwo32Ej(i32 %1) #7
  %9 = icmp sgt i32 %8, 19173960
  br i1 %9, label %77, label %10

10:                                               ; preds = %7
  %11 = sdiv i32 %8, 2
  %12 = bitcast %"class.v8::internal::Isolate"* %0 to %"class.v8::internal::FactoryBase"*
  %13 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 54
  %14 = add nsw i32 %11, 3
  %15 = mul nsw i32 %8, 3
  %16 = add nsw i32 %14, %15
  %17 = tail call i64* @_ZN2v88internal11FactoryBaseINS0_7FactoryEE20NewFixedArrayWithMapENS0_6HandleINS0_3MapEEEiNS0_14AllocationTypeE(%"class.v8::internal::FactoryBase"* %12, i64* %13, i32 %16, i8 zeroext 0) #7
  %18 = icmp sgt i32 %8, 1
  %19 = load i64, i64* %17, align 8
  br i1 %18, label %20, label %42

20:                                               ; preds = %10
  %21 = zext i32 %11 to i64
  %22 = and i64 %21, 1
  %23 = and i32 %8, -2
  %24 = icmp eq i32 %23, 2
  br i1 %24, label %32, label %25

25:                                               ; preds = %20
  %26 = sub nsw i64 %21, %22
  br label %53

27:                                               ; preds = %53
  %28 = trunc i64 %73 to i32
  %29 = shl i32 %28, 2
  %30 = add i32 %29, 12
  %31 = sext i32 %30 to i64
  br label %32

32:                                               ; preds = %27, %20
  %33 = phi i64 [ undef, %20 ], [ %74, %27 ]
  %34 = phi i64 [ 12, %20 ], [ %31, %27 ]
  %35 = phi i64 [ %19, %20 ], [ %74, %27 ]
  %36 = icmp eq i64 %22, 0
  br i1 %36, label %42, label %37

37:                                               ; preds = %32
  %38 = add i64 %35, 7
  %39 = add i64 %38, %34
  %40 = inttoptr i64 %39 to i32*
  store atomic volatile i32 -2, i32* %40 monotonic, align 4
  %41 = load i64, i64* %17, align 8
  br label %42

42:                                               ; preds = %37, %32, %10
  %43 = phi i64 [ %19, %10 ], [ %33, %32 ], [ %41, %37 ]
  %44 = shl nsw i32 %11, 1
  %45 = add i64 %43, 15
  %46 = inttoptr i64 %45 to i32*
  store atomic volatile i32 %44, i32* %46 monotonic, align 4
  %47 = load i64, i64* %17, align 8
  %48 = add i64 %47, 7
  %49 = inttoptr i64 %48 to i32*
  store atomic volatile i32 0, i32* %49 monotonic, align 4
  %50 = load i64, i64* %17, align 8
  %51 = add i64 %50, 11
  %52 = inttoptr i64 %51 to i32*
  store atomic volatile i32 0, i32* %52 monotonic, align 4
  br label %77

53:                                               ; preds = %53, %25
  %54 = phi i64 [ 0, %25 ], [ %73, %53 ]
  %55 = phi i64 [ %19, %25 ], [ %74, %53 ]
  %56 = phi i64 [ %26, %25 ], [ %75, %53 ]
  %57 = trunc i64 %54 to i32
  %58 = shl i32 %57, 2
  %59 = add i32 %58, 12
  %60 = sext i32 %59 to i64
  %61 = add i64 %55, 7
  %62 = add i64 %61, %60
  %63 = inttoptr i64 %62 to i32*
  store atomic volatile i32 -2, i32* %63 monotonic, align 4
  %64 = load i64, i64* %17, align 8
  %65 = trunc i64 %54 to i32
  %66 = shl i32 %65, 2
  %67 = or i32 %66, 4
  %68 = add i32 %67, 12
  %69 = sext i32 %68 to i64
  %70 = add i64 %64, 7
  %71 = add i64 %70, %69
  %72 = inttoptr i64 %71 to i32*
  store atomic volatile i32 -2, i32* %72 monotonic, align 4
  %73 = add nuw nsw i64 %54, 2
  %74 = load i64, i64* %17, align 8
  %75 = add i64 %56, -2
  %76 = icmp eq i64 %75, 0
  br i1 %76, label %27, label %53

77:                                               ; preds = %42, %7, %4
  %78 = phi i64* [ %6, %4 ], [ %17, %42 ], [ null, %7 ]
  ret i64* %78
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden i64* @_ZN2v88internal23OrderedHashTableHandlerINS0_26SmallOrderedNameDictionaryENS0_21OrderedNameDictionaryEE8AllocateEPNS0_7IsolateEi(%"class.v8::internal::Isolate"*, i32) local_unnamed_addr #0 comdat align 2 {
  %3 = icmp slt i32 %1, 254
  br i1 %3, label %4, label %7

4:                                                ; preds = %2
  %5 = bitcast %"class.v8::internal::Isolate"* %0 to %"class.v8::internal::Factory"*
  %6 = tail call i64* @_ZN2v88internal7Factory29NewSmallOrderedNameDictionaryEiNS0_14AllocationTypeE(%"class.v8::internal::Factory"* %5, i32 %1, i8 zeroext 0) #7
  br label %82

7:                                                ; preds = %2
  %8 = tail call i32 @_ZN2v84base4bits21RoundUpToPowerOfTwo32Ej(i32 %1) #7
  %9 = icmp sgt i32 %8, 14913080
  br i1 %9, label %82, label %10

10:                                               ; preds = %7
  %11 = sdiv i32 %8, 2
  %12 = bitcast %"class.v8::internal::Isolate"* %0 to %"class.v8::internal::FactoryBase"*
  %13 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 56
  %14 = add nsw i32 %11, 4
  %15 = shl i32 %8, 2
  %16 = add nsw i32 %14, %15
  %17 = tail call i64* @_ZN2v88internal11FactoryBaseINS0_7FactoryEE20NewFixedArrayWithMapENS0_6HandleINS0_3MapEEEiNS0_14AllocationTypeE(%"class.v8::internal::FactoryBase"* %12, i64* %13, i32 %16, i8 zeroext 0) #7
  %18 = icmp sgt i32 %8, 1
  %19 = load i64, i64* %17, align 8
  br i1 %18, label %20, label %66

20:                                               ; preds = %10
  %21 = zext i32 %11 to i64
  %22 = and i64 %21, 1
  %23 = and i32 %8, -2
  %24 = icmp eq i32 %23, 2
  br i1 %24, label %56, label %25

25:                                               ; preds = %20
  %26 = sub nsw i64 %21, %22
  br label %27

27:                                               ; preds = %27, %25
  %28 = phi i64 [ 0, %25 ], [ %47, %27 ]
  %29 = phi i64 [ %19, %25 ], [ %48, %27 ]
  %30 = phi i64 [ %26, %25 ], [ %49, %27 ]
  %31 = trunc i64 %28 to i32
  %32 = shl i32 %31, 2
  %33 = add i32 %32, 16
  %34 = sext i32 %33 to i64
  %35 = add i64 %29, 7
  %36 = add i64 %35, %34
  %37 = inttoptr i64 %36 to i32*
  store atomic volatile i32 -2, i32* %37 monotonic, align 4
  %38 = load i64, i64* %17, align 8
  %39 = trunc i64 %28 to i32
  %40 = shl i32 %39, 2
  %41 = or i32 %40, 4
  %42 = add i32 %41, 16
  %43 = sext i32 %42 to i64
  %44 = add i64 %38, 7
  %45 = add i64 %44, %43
  %46 = inttoptr i64 %45 to i32*
  store atomic volatile i32 -2, i32* %46 monotonic, align 4
  %47 = add nuw nsw i64 %28, 2
  %48 = load i64, i64* %17, align 8
  %49 = add i64 %30, -2
  %50 = icmp eq i64 %49, 0
  br i1 %50, label %51, label %27

51:                                               ; preds = %27
  %52 = trunc i64 %47 to i32
  %53 = shl i32 %52, 2
  %54 = add i32 %53, 16
  %55 = sext i32 %54 to i64
  br label %56

56:                                               ; preds = %51, %20
  %57 = phi i64 [ undef, %20 ], [ %48, %51 ]
  %58 = phi i64 [ 16, %20 ], [ %55, %51 ]
  %59 = phi i64 [ %19, %20 ], [ %48, %51 ]
  %60 = icmp eq i64 %22, 0
  br i1 %60, label %66, label %61

61:                                               ; preds = %56
  %62 = add i64 %59, 7
  %63 = add i64 %62, %58
  %64 = inttoptr i64 %63 to i32*
  store atomic volatile i32 -2, i32* %64 monotonic, align 4
  %65 = load i64, i64* %17, align 8
  br label %66

66:                                               ; preds = %61, %56, %10
  %67 = phi i64 [ %19, %10 ], [ %57, %56 ], [ %65, %61 ]
  %68 = shl nsw i32 %11, 1
  %69 = add i64 %67, 19
  %70 = inttoptr i64 %69 to i32*
  store atomic volatile i32 %68, i32* %70 monotonic, align 4
  %71 = load i64, i64* %17, align 8
  %72 = add i64 %71, 11
  %73 = inttoptr i64 %72 to i32*
  store atomic volatile i32 0, i32* %73 monotonic, align 4
  %74 = load i64, i64* %17, align 8
  %75 = add i64 %74, 15
  %76 = inttoptr i64 %75 to i32*
  store atomic volatile i32 0, i32* %76 monotonic, align 4
  %77 = icmp eq i64* %17, null
  br i1 %77, label %82, label %78

78:                                               ; preds = %66
  %79 = load i64, i64* %17, align 8
  %80 = add i64 %79, 7
  %81 = inttoptr i64 %80 to i32*
  store atomic volatile i32 0, i32* %81 monotonic, align 4
  br label %82

82:                                               ; preds = %78, %66, %7, %4
  %83 = phi i64* [ %6, %4 ], [ %17, %78 ], [ null, %66 ], [ null, %7 ]
  ret i64* %83
}

; Function Attrs: nounwind ssp uwtable
define hidden i64* @_ZN2v88internal21SmallOrderedHashTableINS0_26SmallOrderedNameDictionaryEE8AllocateEPNS0_7IsolateEiNS0_14AllocationTypeE(%"class.v8::internal::Isolate"*, i32, i8 zeroext) local_unnamed_addr #0 align 2 {
  %4 = bitcast %"class.v8::internal::Isolate"* %0 to %"class.v8::internal::Factory"*
  %5 = tail call i64* @_ZN2v88internal7Factory29NewSmallOrderedNameDictionaryEiNS0_14AllocationTypeE(%"class.v8::internal::Factory"* %4, i32 %1, i8 zeroext %2) #7
  ret i64* %5
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden zeroext i1 @_ZN2v88internal23OrderedHashTableHandlerINS0_19SmallOrderedHashSetENS0_14OrderedHashSetEE6HasKeyEPNS0_7IsolateENS0_6HandleINS0_10HeapObjectEEENS7_INS0_6ObjectEEE(%"class.v8::internal::Isolate"*, i64*, i64*) local_unnamed_addr #0 comdat align 2 {
  %4 = alloca %"class.v8::internal::OrderedHashSet", align 8
  %5 = alloca %"class.v8::internal::Handle<v8::internal::SmallOrderedHashSet>::ObjectRef", align 8
  %6 = load i64, i64* %1, align 8
  %7 = and i64 %6, -4294967296
  %8 = add i64 %6, -1
  %9 = inttoptr i64 %8 to i32*
  %10 = load atomic i32, i32* %9 monotonic, align 4
  %11 = zext i32 %10 to i64
  %12 = or i64 %7, %11
  %13 = add i64 %12, 7
  %14 = inttoptr i64 %13 to i16*
  %15 = load atomic i16, i16* %14 monotonic, align 2
  %16 = icmp eq i16 %15, 151
  br i1 %16, label %17, label %23

17:                                               ; preds = %3
  %18 = bitcast %"class.v8::internal::Handle<v8::internal::SmallOrderedHashSet>::ObjectRef"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %18) #7
  %19 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::SmallOrderedHashSet>::ObjectRef", %"class.v8::internal::Handle<v8::internal::SmallOrderedHashSet>::ObjectRef"* %5, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %6, i64* %19, align 8
  %20 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::SmallOrderedHashSet>::ObjectRef", %"class.v8::internal::Handle<v8::internal::SmallOrderedHashSet>::ObjectRef"* %5, i64 0, i32 0, i32 0
  %21 = load i64, i64* %2, align 8
  %22 = call i64 @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashSetEE9FindEntryEPNS0_7IsolateENS0_6ObjectE(%"class.v8::internal::SmallOrderedHashTable"* nonnull %20, %"class.v8::internal::Isolate"* %0, i64 %21) #7
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %18) #7
  br label %29

23:                                               ; preds = %3
  %24 = load i64, i64* %2, align 8
  %25 = bitcast %"class.v8::internal::OrderedHashSet"* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %25)
  %26 = getelementptr inbounds %"class.v8::internal::OrderedHashSet", %"class.v8::internal::OrderedHashSet"* %4, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %6, i64* %26, align 8
  %27 = getelementptr inbounds %"class.v8::internal::OrderedHashSet", %"class.v8::internal::OrderedHashSet"* %4, i64 0, i32 0
  %28 = call i64 @_ZN2v88internal16OrderedHashTableINS0_14OrderedHashSetELi1EE9FindEntryEPNS0_7IsolateENS0_6ObjectE(%"class.v8::internal::OrderedHashTable"* nonnull %27, %"class.v8::internal::Isolate"* %0, i64 %24) #7
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %25)
  br label %29

29:                                               ; preds = %23, %17
  %30 = phi i64 [ %22, %17 ], [ %28, %23 ]
  %31 = icmp ne i64 %30, -1
  ret i1 %31
}

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN2v88internal19SmallOrderedHashSet6HasKeyEPNS0_7IsolateENS0_6HandleINS0_6ObjectEEE(%"class.v8::internal::SmallOrderedHashSet"*, %"class.v8::internal::Isolate"*, i64* nocapture readonly) local_unnamed_addr #0 align 2 {
  %4 = getelementptr inbounds %"class.v8::internal::SmallOrderedHashSet", %"class.v8::internal::SmallOrderedHashSet"* %0, i64 0, i32 0
  %5 = load i64, i64* %2, align 8
  %6 = tail call i64 @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashSetEE9FindEntryEPNS0_7IsolateENS0_6ObjectE(%"class.v8::internal::SmallOrderedHashTable"* %4, %"class.v8::internal::Isolate"* %1, i64 %5) #7
  %7 = icmp ne i64 %6, -1
  ret i1 %7
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden zeroext i1 @_ZN2v88internal23OrderedHashTableHandlerINS0_19SmallOrderedHashMapENS0_14OrderedHashMapEE6HasKeyEPNS0_7IsolateENS0_6HandleINS0_10HeapObjectEEENS7_INS0_6ObjectEEE(%"class.v8::internal::Isolate"*, i64*, i64*) local_unnamed_addr #0 comdat align 2 {
  %4 = alloca %"class.v8::internal::OrderedHashMap", align 8
  %5 = alloca %"class.v8::internal::Handle<v8::internal::SmallOrderedHashMap>::ObjectRef", align 8
  %6 = load i64, i64* %1, align 8
  %7 = and i64 %6, -4294967296
  %8 = add i64 %6, -1
  %9 = inttoptr i64 %8 to i32*
  %10 = load atomic i32, i32* %9 monotonic, align 4
  %11 = zext i32 %10 to i64
  %12 = or i64 %7, %11
  %13 = add i64 %12, 7
  %14 = inttoptr i64 %13 to i16*
  %15 = load atomic i16, i16* %14 monotonic, align 2
  %16 = icmp eq i16 %15, 150
  br i1 %16, label %17, label %23

17:                                               ; preds = %3
  %18 = bitcast %"class.v8::internal::Handle<v8::internal::SmallOrderedHashMap>::ObjectRef"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %18) #7
  %19 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::SmallOrderedHashMap>::ObjectRef", %"class.v8::internal::Handle<v8::internal::SmallOrderedHashMap>::ObjectRef"* %5, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %6, i64* %19, align 8
  %20 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::SmallOrderedHashMap>::ObjectRef", %"class.v8::internal::Handle<v8::internal::SmallOrderedHashMap>::ObjectRef"* %5, i64 0, i32 0, i32 0
  %21 = load i64, i64* %2, align 8
  %22 = call i64 @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashMapEE9FindEntryEPNS0_7IsolateENS0_6ObjectE(%"class.v8::internal::SmallOrderedHashTable.1143"* nonnull %20, %"class.v8::internal::Isolate"* %0, i64 %21) #7
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %18) #7
  br label %29

23:                                               ; preds = %3
  %24 = load i64, i64* %2, align 8
  %25 = bitcast %"class.v8::internal::OrderedHashMap"* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %25)
  %26 = getelementptr inbounds %"class.v8::internal::OrderedHashMap", %"class.v8::internal::OrderedHashMap"* %4, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %6, i64* %26, align 8
  %27 = getelementptr inbounds %"class.v8::internal::OrderedHashMap", %"class.v8::internal::OrderedHashMap"* %4, i64 0, i32 0
  %28 = call i64 @_ZN2v88internal16OrderedHashTableINS0_14OrderedHashMapELi2EE9FindEntryEPNS0_7IsolateENS0_6ObjectE(%"class.v8::internal::OrderedHashTable.1134"* nonnull %27, %"class.v8::internal::Isolate"* %0, i64 %24) #7
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %25)
  br label %29

29:                                               ; preds = %23, %17
  %30 = phi i64 [ %22, %17 ], [ %28, %23 ]
  %31 = icmp ne i64 %30, -1
  ret i1 %31
}

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN2v88internal19SmallOrderedHashMap6HasKeyEPNS0_7IsolateENS0_6HandleINS0_6ObjectEEE(%"class.v8::internal::SmallOrderedHashMap"*, %"class.v8::internal::Isolate"*, i64* nocapture readonly) local_unnamed_addr #0 align 2 {
  %4 = getelementptr inbounds %"class.v8::internal::SmallOrderedHashMap", %"class.v8::internal::SmallOrderedHashMap"* %0, i64 0, i32 0
  %5 = load i64, i64* %2, align 8
  %6 = tail call i64 @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashMapEE9FindEntryEPNS0_7IsolateENS0_6ObjectE(%"class.v8::internal::SmallOrderedHashTable.1143"* %4, %"class.v8::internal::Isolate"* %1, i64 %5) #7
  %7 = icmp ne i64 %6, -1
  ret i1 %7
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden zeroext i1 @_ZN2v88internal23OrderedHashTableHandlerINS0_19SmallOrderedHashSetENS0_14OrderedHashSetEE6DeleteEPNS0_7IsolateENS0_6HandleINS0_10HeapObjectEEENS7_INS0_6ObjectEEE(%"class.v8::internal::Isolate"*, i64*, i64*) local_unnamed_addr #0 comdat align 2 {
  %4 = load i64, i64* %1, align 8
  %5 = and i64 %4, -4294967296
  %6 = add i64 %4, -1
  %7 = inttoptr i64 %6 to i32*
  %8 = load atomic i32, i32* %7 monotonic, align 4
  %9 = zext i32 %8 to i64
  %10 = or i64 %5, %9
  %11 = add i64 %10, 7
  %12 = inttoptr i64 %11 to i16*
  %13 = load atomic i16, i16* %12 monotonic, align 2
  %14 = icmp eq i16 %13, 151
  %15 = load i64, i64* %2, align 8
  br i1 %14, label %16, label %18

16:                                               ; preds = %3
  %17 = tail call zeroext i1 @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashSetEE6DeleteEPNS0_7IsolateES2_NS0_6ObjectE(%"class.v8::internal::Isolate"* %0, i64 %4, i64 %15) #7
  br label %20

18:                                               ; preds = %3
  %19 = tail call zeroext i1 @_ZN2v88internal16OrderedHashTableINS0_14OrderedHashSetELi1EE6DeleteEPNS0_7IsolateES2_NS0_6ObjectE(%"class.v8::internal::Isolate"* %0, i64 %4, i64 %15)
  br label %20

20:                                               ; preds = %18, %16
  %21 = phi i1 [ %17, %16 ], [ %19, %18 ]
  ret i1 %21
}

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN2v88internal19SmallOrderedHashSet6DeleteEPNS0_7IsolateES1_NS0_6ObjectE(%"class.v8::internal::Isolate"*, i64, i64) local_unnamed_addr #0 align 2 {
  %4 = tail call zeroext i1 @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashSetEE6DeleteEPNS0_7IsolateES2_NS0_6ObjectE(%"class.v8::internal::Isolate"* %0, i64 %1, i64 %2)
  ret i1 %4
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden zeroext i1 @_ZN2v88internal23OrderedHashTableHandlerINS0_19SmallOrderedHashMapENS0_14OrderedHashMapEE6DeleteEPNS0_7IsolateENS0_6HandleINS0_10HeapObjectEEENS7_INS0_6ObjectEEE(%"class.v8::internal::Isolate"*, i64*, i64*) local_unnamed_addr #0 comdat align 2 {
  %4 = load i64, i64* %1, align 8
  %5 = and i64 %4, -4294967296
  %6 = add i64 %4, -1
  %7 = inttoptr i64 %6 to i32*
  %8 = load atomic i32, i32* %7 monotonic, align 4
  %9 = zext i32 %8 to i64
  %10 = or i64 %5, %9
  %11 = add i64 %10, 7
  %12 = inttoptr i64 %11 to i16*
  %13 = load atomic i16, i16* %12 monotonic, align 2
  %14 = icmp eq i16 %13, 150
  %15 = load i64, i64* %2, align 8
  br i1 %14, label %16, label %18

16:                                               ; preds = %3
  %17 = tail call zeroext i1 @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashMapEE6DeleteEPNS0_7IsolateES2_NS0_6ObjectE(%"class.v8::internal::Isolate"* %0, i64 %4, i64 %15) #7
  br label %20

18:                                               ; preds = %3
  %19 = tail call zeroext i1 @_ZN2v88internal16OrderedHashTableINS0_14OrderedHashMapELi2EE6DeleteEPNS0_7IsolateES2_NS0_6ObjectE(%"class.v8::internal::Isolate"* %0, i64 %4, i64 %15)
  br label %20

20:                                               ; preds = %18, %16
  %21 = phi i1 [ %17, %16 ], [ %19, %18 ]
  ret i1 %21
}

; Function Attrs: nounwind ssp uwtable
define hidden zeroext i1 @_ZN2v88internal19SmallOrderedHashMap6DeleteEPNS0_7IsolateES1_NS0_6ObjectE(%"class.v8::internal::Isolate"*, i64, i64) local_unnamed_addr #0 align 2 {
  %4 = tail call zeroext i1 @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashMapEE6DeleteEPNS0_7IsolateES2_NS0_6ObjectE(%"class.v8::internal::Isolate"* %0, i64 %1, i64 %2)
  ret i1 %4
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden zeroext i1 @_ZN2v88internal23OrderedHashTableHandlerINS0_26SmallOrderedNameDictionaryENS0_21OrderedNameDictionaryEE6DeleteEPNS0_7IsolateENS0_6HandleINS0_10HeapObjectEEENS7_INS0_6ObjectEEE(%"class.v8::internal::Isolate"*, i64*, i64*) local_unnamed_addr #0 comdat align 2 {
  %4 = load i64, i64* %1, align 8
  %5 = and i64 %4, -4294967296
  %6 = add i64 %4, -1
  %7 = inttoptr i64 %6 to i32*
  %8 = load atomic i32, i32* %7 monotonic, align 4
  %9 = zext i32 %8 to i64
  %10 = or i64 %5, %9
  %11 = add i64 %10, 7
  %12 = inttoptr i64 %11 to i16*
  %13 = load atomic i16, i16* %12 monotonic, align 2
  %14 = icmp eq i16 %13, 152
  %15 = load i64, i64* %2, align 8
  br i1 %14, label %16, label %18

16:                                               ; preds = %3
  %17 = tail call zeroext i1 @_ZN2v88internal21SmallOrderedHashTableINS0_26SmallOrderedNameDictionaryEE6DeleteEPNS0_7IsolateES2_NS0_6ObjectE(%"class.v8::internal::Isolate"* %0, i64 %4, i64 %15)
  br label %20

18:                                               ; preds = %3
  %19 = tail call zeroext i1 @_ZN2v88internal16OrderedHashTableINS0_21OrderedNameDictionaryELi3EE6DeleteEPNS0_7IsolateES2_NS0_6ObjectE(%"class.v8::internal::Isolate"* %0, i64 %4, i64 %15)
  br label %20

20:                                               ; preds = %18, %16
  %21 = phi i1 [ %17, %16 ], [ %19, %18 ]
  ret i1 %21
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden zeroext i1 @_ZN2v88internal21SmallOrderedHashTableINS0_26SmallOrderedNameDictionaryEE6DeleteEPNS0_7IsolateES2_NS0_6ObjectE(%"class.v8::internal::Isolate"*, i64, i64) local_unnamed_addr #0 comdat align 2 {
  %4 = add i64 %2, 3
  %5 = inttoptr i64 %4 to i32*
  %6 = load i32, i32* %5, align 4
  %7 = lshr i32 %6, 2
  %8 = add i64 %1, 9
  %9 = inttoptr i64 %8 to i8*
  %10 = load i8, i8* %9, align 1
  %11 = zext i8 %10 to i32
  %12 = add nuw nsw i32 %11, 1073741823
  %13 = and i32 %12, %7
  %14 = mul nuw nsw i32 %11, 24
  %15 = add nuw nsw i32 %14, 12
  %16 = add nuw nsw i32 %15, %13
  %17 = add i64 %1, -1
  %18 = zext i32 %16 to i64
  %19 = add i64 %17, %18
  %20 = inttoptr i64 %19 to i8*
  %21 = load i8, i8* %20, align 1
  %22 = icmp eq i8 %21, -1
  br i1 %22, label %101, label %23

23:                                               ; preds = %3
  %24 = trunc i64 %2 to i32
  %25 = add nuw nsw i32 %15, %11
  br label %26

26:                                               ; preds = %36, %23
  %27 = phi i8 [ %21, %23 ], [ %42, %36 ]
  %28 = zext i8 %27 to i64
  %29 = mul nuw nsw i64 %28, 51539607552
  %30 = add nuw nsw i64 %29, 51539607552
  %31 = lshr exact i64 %30, 32
  %32 = add i64 %31, %17
  %33 = inttoptr i64 %32 to i32*
  %34 = load i32, i32* %33, align 4
  %35 = icmp eq i32 %34, %24
  br i1 %35, label %44, label %36

36:                                               ; preds = %26
  %37 = zext i8 %27 to i32
  %38 = add nuw nsw i32 %25, %37
  %39 = zext i32 %38 to i64
  %40 = add i64 %17, %39
  %41 = inttoptr i64 %40 to i8*
  %42 = load i8, i8* %41, align 1
  %43 = icmp eq i8 %42, -1
  br i1 %43, label %101, label %26

44:                                               ; preds = %26
  %45 = add i64 %1, 7
  %46 = inttoptr i64 %45 to i8*
  %47 = load i8, i8* %46, align 1
  %48 = add i64 %1, 8
  %49 = inttoptr i64 %48 to i8*
  %50 = load i8, i8* %49, align 1
  %51 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 5
  %52 = load i64, i64* %51, align 8
  %53 = zext i8 %27 to i64
  %54 = mul nuw nsw i64 %53, 12
  %55 = add nuw nsw i64 %54, 12
  %56 = trunc i64 %52 to i32
  %57 = and i64 %52, 1
  %58 = icmp eq i64 %57, 0
  %59 = and i64 %1, -262144
  %60 = or i64 %59, 8
  %61 = inttoptr i64 %60 to i64*
  %62 = or i64 %59, 16
  %63 = inttoptr i64 %62 to %"class.v8::internal::Heap"**
  %64 = and i64 %52, -262144
  %65 = or i64 %64, 8
  %66 = inttoptr i64 %65 to i64*
  %67 = add i64 %17, %55
  %68 = inttoptr i64 %67 to i32*
  store atomic volatile i32 %56, i32* %68 monotonic, align 4
  br i1 %58, label %73, label %69

69:                                               ; preds = %44
  %70 = load i64, i64* %61, align 8
  %71 = and i64 %70, 262144
  %72 = icmp eq i64 %71, 0
  br i1 %72, label %85, label %83

73:                                               ; preds = %44
  %74 = add nuw nsw i64 %54, 16
  %75 = add i64 %17, %74
  %76 = inttoptr i64 %75 to i32*
  store atomic volatile i32 %56, i32* %76 monotonic, align 4
  %77 = add nuw nsw i64 %54, 20
  %78 = add i64 %17, %77
  %79 = inttoptr i64 %78 to i32*
  store atomic volatile i32 %56, i32* %79 monotonic, align 4
  br label %80

80:                                               ; preds = %123, %127, %131, %73
  %81 = add i8 %47, -1
  store i8 %81, i8* %46, align 1
  %82 = add i8 %50, 1
  store i8 %82, i8* %49, align 1
  br label %101

83:                                               ; preds = %69
  %84 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %63, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %84, i64 %1, i64 %67, i64 %52) #7
  br label %85

85:                                               ; preds = %83, %69
  %86 = load i64, i64* %66, align 8
  %87 = and i64 %86, 24
  %88 = icmp eq i64 %87, 0
  br i1 %88, label %94, label %89

89:                                               ; preds = %85
  %90 = load i64, i64* %61, align 8
  %91 = and i64 %90, 24
  %92 = icmp eq i64 %91, 0
  br i1 %92, label %93, label %94

93:                                               ; preds = %89
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %1, i64 %67, i64 %52) #7
  br label %94

94:                                               ; preds = %85, %89, %93
  %95 = add nuw nsw i64 %54, 16
  %96 = add i64 %17, %95
  %97 = inttoptr i64 %96 to i32*
  store atomic volatile i32 %56, i32* %97 monotonic, align 4
  %98 = load i64, i64* %61, align 8
  %99 = and i64 %98, 262144
  %100 = icmp eq i64 %99, 0
  br i1 %100, label %105, label %103

101:                                              ; preds = %36, %3, %80
  %102 = phi i1 [ true, %80 ], [ false, %3 ], [ false, %36 ]
  ret i1 %102

103:                                              ; preds = %94
  %104 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %63, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %104, i64 %1, i64 %96, i64 %52) #7
  br label %105

105:                                              ; preds = %103, %94
  %106 = load i64, i64* %66, align 8
  %107 = and i64 %106, 24
  %108 = icmp eq i64 %107, 0
  br i1 %108, label %114, label %109

109:                                              ; preds = %105
  %110 = load i64, i64* %61, align 8
  %111 = and i64 %110, 24
  %112 = icmp eq i64 %111, 0
  br i1 %112, label %113, label %114

113:                                              ; preds = %109
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %1, i64 %96, i64 %52) #7
  br label %114

114:                                              ; preds = %113, %109, %105
  %115 = add nuw nsw i64 %54, 20
  %116 = add i64 %17, %115
  %117 = inttoptr i64 %116 to i32*
  store atomic volatile i32 %56, i32* %117 monotonic, align 4
  %118 = load i64, i64* %61, align 8
  %119 = and i64 %118, 262144
  %120 = icmp eq i64 %119, 0
  br i1 %120, label %123, label %121

121:                                              ; preds = %114
  %122 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %63, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %122, i64 %1, i64 %116, i64 %52) #7
  br label %123

123:                                              ; preds = %121, %114
  %124 = load i64, i64* %66, align 8
  %125 = and i64 %124, 24
  %126 = icmp eq i64 %125, 0
  br i1 %126, label %80, label %127

127:                                              ; preds = %123
  %128 = load i64, i64* %61, align 8
  %129 = and i64 %128, 24
  %130 = icmp eq i64 %129, 0
  br i1 %130, label %131, label %80

131:                                              ; preds = %127
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %1, i64 %116, i64 %52) #7
  br label %80
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden zeroext i1 @_ZN2v88internal16OrderedHashTableINS0_21OrderedNameDictionaryELi3EE6DeleteEPNS0_7IsolateES2_NS0_6ObjectE(%"class.v8::internal::Isolate"*, i64, i64) local_unnamed_addr #0 comdat align 2 {
  %4 = add i64 %1, 11
  %5 = inttoptr i64 %4 to i32*
  %6 = load atomic i32, i32* %5 monotonic, align 4
  %7 = icmp ult i32 %6, 2
  br i1 %7, label %121, label %8

8:                                                ; preds = %3
  %9 = add i64 %2, 3
  %10 = inttoptr i64 %9 to i32*
  %11 = load i32, i32* %10, align 4
  %12 = add i64 %1, 19
  %13 = inttoptr i64 %12 to i32*
  %14 = load atomic i32, i32* %13 monotonic, align 4
  %15 = lshr i32 %14, 1
  %16 = shl i32 %15, 2
  %17 = add i32 %16, -4
  %18 = and i32 %17, %11
  %19 = add i32 %18, 16
  %20 = sext i32 %19 to i64
  %21 = add i64 %1, 7
  %22 = add i64 %21, %20
  %23 = inttoptr i64 %22 to i32*
  %24 = load atomic i32, i32* %23 monotonic, align 4
  %25 = ashr i32 %24, 1
  %26 = icmp eq i32 %25, -1
  br i1 %26, label %121, label %27

27:                                               ; preds = %8
  %28 = trunc i64 %2 to i32
  br label %29

29:                                               ; preds = %42, %27
  %30 = phi i32 [ %25, %27 ], [ %52, %42 ]
  %31 = load atomic i32, i32* %13 monotonic, align 4
  %32 = lshr i32 %31, 1
  %33 = shl i32 %30, 2
  %34 = add i32 %33, 4
  %35 = add i32 %32, %34
  %36 = shl i32 %35, 2
  %37 = sext i32 %36 to i64
  %38 = add i64 %21, %37
  %39 = inttoptr i64 %38 to i32*
  %40 = load atomic i32, i32* %39 monotonic, align 4
  %41 = icmp eq i32 %40, %28
  br i1 %41, label %54, label %42

42:                                               ; preds = %29
  %43 = load atomic i32, i32* %13 monotonic, align 4
  %44 = lshr i32 %43, 1
  %45 = add i32 %44, %34
  %46 = shl i32 %45, 2
  %47 = add i32 %46, 12
  %48 = sext i32 %47 to i64
  %49 = add i64 %21, %48
  %50 = inttoptr i64 %49 to i32*
  %51 = load atomic i32, i32* %50 monotonic, align 4
  %52 = ashr i32 %51, 1
  %53 = icmp eq i32 %52, -1
  br i1 %53, label %121, label %29

54:                                               ; preds = %29
  %55 = icmp eq i32 %30, -1
  br i1 %55, label %121, label %56

56:                                               ; preds = %54
  %57 = load atomic i32, i32* %5 monotonic, align 4
  %58 = add i64 %1, 15
  %59 = inttoptr i64 %58 to i32*
  %60 = load atomic i32, i32* %59 monotonic, align 4
  %61 = load atomic i32, i32* %13 monotonic, align 4
  %62 = lshr i32 %61, 1
  %63 = add i32 %34, %62
  %64 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 5
  %65 = load i64, i64* %64, align 8
  %66 = trunc i64 %65 to i32
  %67 = and i64 %65, 1
  %68 = icmp eq i64 %67, 0
  %69 = and i64 %1, -262144
  %70 = or i64 %69, 8
  %71 = inttoptr i64 %70 to i64*
  %72 = or i64 %69, 16
  %73 = inttoptr i64 %72 to %"class.v8::internal::Heap"**
  %74 = and i64 %65, -262144
  %75 = or i64 %74, 8
  %76 = inttoptr i64 %75 to i64*
  %77 = shl i32 %63, 2
  %78 = sext i32 %77 to i64
  %79 = add i64 %21, %78
  %80 = inttoptr i64 %79 to i32*
  store atomic volatile i32 %66, i32* %80 monotonic, align 4
  br i1 %68, label %85, label %81

81:                                               ; preds = %56
  %82 = load i64, i64* %71, align 8
  %83 = and i64 %82, 262144
  %84 = icmp eq i64 %83, 0
  br i1 %84, label %103, label %101

85:                                               ; preds = %56
  %86 = shl i32 %63, 2
  %87 = add i32 %86, 4
  %88 = sext i32 %87 to i64
  %89 = add i64 %21, %88
  %90 = inttoptr i64 %89 to i32*
  store atomic volatile i32 %66, i32* %90 monotonic, align 4
  %91 = shl i32 %63, 2
  %92 = add i32 %91, 8
  %93 = sext i32 %92 to i64
  %94 = add i64 %21, %93
  %95 = inttoptr i64 %94 to i32*
  store atomic volatile i32 %66, i32* %95 monotonic, align 4
  br label %96

96:                                               ; preds = %145, %149, %153, %85
  %97 = add i32 %57, -2
  %98 = and i32 %97, -2
  store atomic volatile i32 %98, i32* %5 monotonic, align 4
  %99 = add i32 %60, 2
  %100 = and i32 %99, -2
  store atomic volatile i32 %100, i32* %59 monotonic, align 4
  br label %121

101:                                              ; preds = %81
  %102 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %73, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %102, i64 %1, i64 %79, i64 %65) #7
  br label %103

103:                                              ; preds = %101, %81
  %104 = load i64, i64* %76, align 8
  %105 = and i64 %104, 24
  %106 = icmp eq i64 %105, 0
  br i1 %106, label %112, label %107

107:                                              ; preds = %103
  %108 = load i64, i64* %71, align 8
  %109 = and i64 %108, 24
  %110 = icmp eq i64 %109, 0
  br i1 %110, label %111, label %112

111:                                              ; preds = %107
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %1, i64 %79, i64 %65) #7
  br label %112

112:                                              ; preds = %103, %107, %111
  %113 = shl i32 %63, 2
  %114 = add i32 %113, 4
  %115 = sext i32 %114 to i64
  %116 = add i64 %21, %115
  %117 = inttoptr i64 %116 to i32*
  store atomic volatile i32 %66, i32* %117 monotonic, align 4
  %118 = load i64, i64* %71, align 8
  %119 = and i64 %118, 262144
  %120 = icmp eq i64 %119, 0
  br i1 %120, label %125, label %123

121:                                              ; preds = %42, %8, %3, %54, %96
  %122 = phi i1 [ true, %96 ], [ false, %54 ], [ false, %3 ], [ false, %8 ], [ false, %42 ]
  ret i1 %122

123:                                              ; preds = %112
  %124 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %73, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %124, i64 %1, i64 %116, i64 %65) #7
  br label %125

125:                                              ; preds = %123, %112
  %126 = load i64, i64* %76, align 8
  %127 = and i64 %126, 24
  %128 = icmp eq i64 %127, 0
  br i1 %128, label %134, label %129

129:                                              ; preds = %125
  %130 = load i64, i64* %71, align 8
  %131 = and i64 %130, 24
  %132 = icmp eq i64 %131, 0
  br i1 %132, label %133, label %134

133:                                              ; preds = %129
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %1, i64 %116, i64 %65) #7
  br label %134

134:                                              ; preds = %133, %129, %125
  %135 = shl i32 %63, 2
  %136 = add i32 %135, 8
  %137 = sext i32 %136 to i64
  %138 = add i64 %21, %137
  %139 = inttoptr i64 %138 to i32*
  store atomic volatile i32 %66, i32* %139 monotonic, align 4
  %140 = load i64, i64* %71, align 8
  %141 = and i64 %140, 262144
  %142 = icmp eq i64 %141, 0
  br i1 %142, label %145, label %143

143:                                              ; preds = %134
  %144 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %73, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %144, i64 %1, i64 %138, i64 %65) #7
  br label %145

145:                                              ; preds = %143, %134
  %146 = load i64, i64* %76, align 8
  %147 = and i64 %146, 24
  %148 = icmp eq i64 %147, 0
  br i1 %148, label %96, label %149

149:                                              ; preds = %145
  %150 = load i64, i64* %71, align 8
  %151 = and i64 %150, 24
  %152 = icmp eq i64 %151, 0
  br i1 %152, label %153, label %96

153:                                              ; preds = %149
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %1, i64 %138, i64 %65) #7
  br label %96
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden zeroext i1 @_ZN2v88internal24OrderedHashTableIteratorINS0_13JSSetIteratorENS0_14OrderedHashSetEE7HasMoreEv(%"class.v8::internal::OrderedHashTableIterator"*) local_unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::OrderedHashTableIterator", %"class.v8::internal::OrderedHashTableIterator"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %3 = load i64, i64* %2, align 8
  %4 = load %"class.v8::internal::SoleReadOnlyHeap"*, %"class.v8::internal::SoleReadOnlyHeap"** @_ZN2v88internal16SoleReadOnlyHeap15shared_ro_heap_E, align 8
  %5 = icmp eq %"class.v8::internal::SoleReadOnlyHeap"* %4, null
  br i1 %5, label %12, label %6

6:                                                ; preds = %1
  %7 = getelementptr inbounds %"class.v8::internal::SoleReadOnlyHeap", %"class.v8::internal::SoleReadOnlyHeap"* %4, i64 0, i32 0, i32 1
  %8 = load i8, i8* %7, align 8, !range !4
  %9 = icmp eq i8 %8, 0
  br i1 %9, label %12, label %10

10:                                               ; preds = %6
  %11 = getelementptr inbounds %"class.v8::internal::SoleReadOnlyHeap", %"class.v8::internal::SoleReadOnlyHeap"* %4, i64 0, i32 1, i64 0
  br label %20

12:                                               ; preds = %6, %1
  %13 = and i64 %3, -262144
  %14 = or i64 %13, 16
  %15 = inttoptr i64 %14 to i64*
  %16 = load i64, i64* %15, align 16
  %17 = add i64 %16, -41416
  %18 = inttoptr i64 %17 to %"class.v8::internal::Isolate"*
  %19 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %18, i64 0, i32 0, i32 7, i32 0, i64 0
  br label %20

20:                                               ; preds = %10, %12
  %21 = phi i64* [ %19, %12 ], [ %11, %10 ]
  tail call void @_ZN2v88internal24OrderedHashTableIteratorINS0_13JSSetIteratorENS0_14OrderedHashSetEE10TransitionEv(%"class.v8::internal::OrderedHashTableIterator"* %0)
  %22 = load i64, i64* %2, align 8
  %23 = and i64 %22, -4294967296
  %24 = add i64 %22, 11
  %25 = inttoptr i64 %24 to i32*
  %26 = load i32, i32* %25, align 4
  %27 = zext i32 %26 to i64
  %28 = or i64 %23, %27
  %29 = add i64 %22, 15
  %30 = inttoptr i64 %29 to i32*
  %31 = load i32, i32* %30, align 4
  %32 = ashr i32 %31, 1
  %33 = add i64 %28, 7
  %34 = inttoptr i64 %33 to i32*
  %35 = load atomic i32, i32* %34 monotonic, align 4
  %36 = ashr i32 %35, 1
  %37 = add i64 %28, 11
  %38 = inttoptr i64 %37 to i32*
  %39 = load atomic i32, i32* %38 monotonic, align 4
  %40 = ashr i32 %39, 1
  %41 = add nsw i32 %40, %36
  %42 = icmp slt i32 %32, %41
  br i1 %42, label %43, label %66

43:                                               ; preds = %20
  %44 = add i64 %28, 15
  %45 = inttoptr i64 %44 to i32*
  %46 = getelementptr inbounds i64, i64* %21, i64 5
  %47 = load i64, i64* %46, align 8
  %48 = trunc i64 %47 to i32
  br label %49

49:                                               ; preds = %63, %43
  %50 = phi i32 [ %32, %43 ], [ %64, %63 ]
  %51 = load atomic i32, i32* %45 monotonic, align 4
  %52 = lshr i32 %51, 1
  %53 = shl i32 %50, 1
  %54 = add i32 %53, 3
  %55 = add i32 %54, %52
  %56 = shl i32 %55, 2
  %57 = sext i32 %56 to i64
  %58 = add i64 %33, %57
  %59 = inttoptr i64 %58 to i32*
  %60 = load atomic i32, i32* %59 monotonic, align 4
  %61 = icmp eq i32 %60, %48
  br i1 %61, label %63, label %62

62:                                               ; preds = %49
  store atomic volatile i32 %53, i32* %30 monotonic, align 4
  br label %109

63:                                               ; preds = %49
  %64 = add i32 %50, 1
  %65 = icmp eq i32 %64, %41
  br i1 %65, label %66, label %49

66:                                               ; preds = %63, %20
  %67 = phi i32 [ %32, %20 ], [ %41, %63 ]
  %68 = shl i32 %67, 1
  store atomic volatile i32 %68, i32* %30 monotonic, align 4
  %69 = getelementptr inbounds i64, i64* %21, i64 113
  %70 = load i64, i64* %69, align 8
  %71 = load i64, i64* %2, align 8
  %72 = add i64 %71, 11
  %73 = inttoptr i64 %72 to i32*
  %74 = trunc i64 %70 to i32
  store atomic volatile i32 %74, i32* %73 monotonic, align 4
  %75 = load i64, i64* %2, align 8
  %76 = add i64 %75, 11
  %77 = and i64 %70, 1
  %78 = icmp eq i64 %77, 0
  br i1 %78, label %109, label %79

79:                                               ; preds = %66
  %80 = and i64 %75, -262144
  %81 = or i64 %80, 8
  %82 = inttoptr i64 %81 to i64*
  %83 = load i64, i64* %82, align 8
  %84 = and i64 %83, 262144
  %85 = icmp eq i64 %84, 0
  br i1 %85, label %92, label %86

86:                                               ; preds = %79
  %87 = or i64 %80, 16
  %88 = inttoptr i64 %87 to %"class.v8::internal::Heap"**
  %89 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %88, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %89, i64 %75, i64 %76, i64 %70) #7
  %90 = load i64, i64* %2, align 8
  %91 = add i64 %90, 11
  br label %92

92:                                               ; preds = %86, %79
  %93 = phi i64 [ %91, %86 ], [ %76, %79 ]
  %94 = phi i64 [ %90, %86 ], [ %75, %79 ]
  %95 = and i64 %70, -262144
  %96 = or i64 %95, 8
  %97 = inttoptr i64 %96 to i64*
  %98 = load i64, i64* %97, align 8
  %99 = and i64 %98, 24
  %100 = icmp eq i64 %99, 0
  br i1 %100, label %109, label %101

101:                                              ; preds = %92
  %102 = and i64 %94, -262144
  %103 = or i64 %102, 8
  %104 = inttoptr i64 %103 to i64*
  %105 = load i64, i64* %104, align 8
  %106 = and i64 %105, 24
  %107 = icmp eq i64 %106, 0
  br i1 %107, label %108, label %109

108:                                              ; preds = %101
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %94, i64 %93, i64 %70) #7
  br label %109

109:                                              ; preds = %108, %101, %92, %66, %62
  %110 = phi i1 [ true, %62 ], [ false, %66 ], [ false, %92 ], [ false, %101 ], [ false, %108 ]
  ret i1 %110
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden void @_ZN2v88internal24OrderedHashTableIteratorINS0_13JSSetIteratorENS0_14OrderedHashSetEE10TransitionEv(%"class.v8::internal::OrderedHashTableIterator"*) local_unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::OrderedHashTableIterator", %"class.v8::internal::OrderedHashTableIterator"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %3 = load i64, i64* %2, align 8
  %4 = and i64 %3, -4294967296
  %5 = add i64 %3, 11
  %6 = inttoptr i64 %5 to i32*
  %7 = load i32, i32* %6, align 4
  %8 = zext i32 %7 to i64
  %9 = or i64 %4, %8
  %10 = add i64 %9, 7
  %11 = inttoptr i64 %10 to i32*
  %12 = load atomic i32, i32* %11 monotonic, align 4
  %13 = and i32 %12, 1
  %14 = icmp eq i32 %13, 0
  br i1 %14, label %111, label %15

15:                                               ; preds = %1
  %16 = add i64 %3, 15
  %17 = inttoptr i64 %16 to i32*
  %18 = load i32, i32* %17, align 4
  %19 = ashr i32 %18, 1
  %20 = load atomic i32, i32* %11 monotonic, align 4
  %21 = and i32 %20, 1
  %22 = icmp eq i32 %21, 0
  br i1 %22, label %67, label %23

23:                                               ; preds = %15, %60
  %24 = phi i32* [ %63, %60 ], [ %11, %15 ]
  %25 = phi i32 [ %61, %60 ], [ %19, %15 ]
  %26 = phi i64 [ %30, %60 ], [ %9, %15 ]
  %27 = and i64 %26, -4294967296
  %28 = load atomic i32, i32* %24 monotonic, align 4
  %29 = zext i32 %28 to i64
  %30 = or i64 %27, %29
  %31 = icmp sgt i32 %25, 0
  br i1 %31, label %32, label %60

32:                                               ; preds = %23
  %33 = add i64 %26, 11
  %34 = inttoptr i64 %33 to i32*
  %35 = load atomic i32, i32* %34 monotonic, align 4
  %36 = ashr i32 %35, 1
  %37 = icmp eq i32 %36, -1
  br i1 %37, label %60, label %38

38:                                               ; preds = %32
  %39 = icmp sgt i32 %35, 1
  br i1 %39, label %40, label %60

40:                                               ; preds = %38
  %41 = add i64 %26, 7
  %42 = sext i32 %36 to i64
  br label %43

43:                                               ; preds = %43, %40
  %44 = phi i64 [ %57, %43 ], [ 0, %40 ]
  %45 = phi i32 [ %56, %43 ], [ %25, %40 ]
  %46 = trunc i64 %44 to i32
  %47 = shl i32 %46, 2
  %48 = add i32 %47, 12
  %49 = sext i32 %48 to i64
  %50 = add i64 %41, %49
  %51 = inttoptr i64 %50 to i32*
  %52 = load atomic i32, i32* %51 monotonic, align 4
  %53 = ashr i32 %52, 1
  %54 = icmp slt i32 %53, %25
  %55 = zext i1 %54 to i32
  %56 = sub i32 %45, %55
  %57 = add nuw nsw i64 %44, 1
  %58 = icmp slt i64 %57, %42
  %59 = and i1 %54, %58
  br i1 %59, label %43, label %60

60:                                               ; preds = %43, %38, %32, %23
  %61 = phi i32 [ %25, %23 ], [ 0, %32 ], [ %25, %38 ], [ %56, %43 ]
  %62 = add i64 %30, 7
  %63 = inttoptr i64 %62 to i32*
  %64 = load atomic i32, i32* %63 monotonic, align 4
  %65 = and i32 %64, 1
  %66 = icmp eq i32 %65, 0
  br i1 %66, label %67, label %23

67:                                               ; preds = %60, %15
  %68 = phi i64 [ %9, %15 ], [ %30, %60 ]
  %69 = phi i32 [ %19, %15 ], [ %61, %60 ]
  %70 = trunc i64 %68 to i32
  store atomic volatile i32 %70, i32* %6 monotonic, align 4
  %71 = load i64, i64* %2, align 8
  %72 = add i64 %71, 11
  %73 = and i64 %68, 1
  %74 = icmp eq i64 %73, 0
  br i1 %74, label %106, label %75

75:                                               ; preds = %67
  %76 = and i64 %71, -262144
  %77 = or i64 %76, 8
  %78 = inttoptr i64 %77 to i64*
  %79 = load i64, i64* %78, align 8
  %80 = and i64 %79, 262144
  %81 = icmp eq i64 %80, 0
  br i1 %81, label %88, label %82

82:                                               ; preds = %75
  %83 = or i64 %76, 16
  %84 = inttoptr i64 %83 to %"class.v8::internal::Heap"**
  %85 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %84, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %85, i64 %71, i64 %72, i64 %68) #7
  %86 = load i64, i64* %2, align 8
  %87 = add i64 %86, 11
  br label %88

88:                                               ; preds = %82, %75
  %89 = phi i64 [ %87, %82 ], [ %72, %75 ]
  %90 = phi i64 [ %86, %82 ], [ %71, %75 ]
  %91 = and i64 %68, -262144
  %92 = or i64 %91, 8
  %93 = inttoptr i64 %92 to i64*
  %94 = load i64, i64* %93, align 8
  %95 = and i64 %94, 24
  %96 = icmp eq i64 %95, 0
  br i1 %96, label %106, label %97

97:                                               ; preds = %88
  %98 = and i64 %90, -262144
  %99 = or i64 %98, 8
  %100 = inttoptr i64 %99 to i64*
  %101 = load i64, i64* %100, align 8
  %102 = and i64 %101, 24
  %103 = icmp eq i64 %102, 0
  br i1 %103, label %104, label %106

104:                                              ; preds = %97
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %90, i64 %89, i64 %68) #7
  %105 = load i64, i64* %2, align 8
  br label %106

106:                                              ; preds = %104, %97, %88, %67
  %107 = phi i64 [ %105, %104 ], [ %90, %97 ], [ %90, %88 ], [ %71, %67 ]
  %108 = shl i32 %69, 1
  %109 = add i64 %107, 15
  %110 = inttoptr i64 %109 to i32*
  store atomic volatile i32 %108, i32* %110 monotonic, align 4
  br label %111

111:                                              ; preds = %1, %106
  ret void
}

; Function Attrs: norecurse nounwind readonly ssp uwtable
define hidden i64 @_ZN2v88internal14OrderedHashSet8GetEmptyENS0_13ReadOnlyRootsE(i64*) local_unnamed_addr #3 align 2 {
  %2 = getelementptr inbounds i64, i64* %0, i64 113
  %3 = load i64, i64* %2, align 8
  ret i64 %3
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden void @_ZN2v88internal24OrderedHashTableIteratorINS0_13JSSetIteratorENS0_14OrderedHashSetEE8MoveNextEv(%"class.v8::internal::OrderedHashTableIterator"*) local_unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::OrderedHashTableIterator", %"class.v8::internal::OrderedHashTableIterator"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %3 = load i64, i64* %2, align 8
  %4 = add i64 %3, 15
  %5 = inttoptr i64 %4 to i32*
  %6 = load i32, i32* %5, align 4
  %7 = add i32 %6, 2
  %8 = and i32 %7, -2
  store atomic volatile i32 %8, i32* %5 monotonic, align 4
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define weak_odr hidden i64 @_ZN2v88internal24OrderedHashTableIteratorINS0_13JSSetIteratorENS0_14OrderedHashSetEE10CurrentKeyEv(%"class.v8::internal::OrderedHashTableIterator"*) local_unnamed_addr #4 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::OrderedHashTableIterator", %"class.v8::internal::OrderedHashTableIterator"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %3 = load i64, i64* %2, align 8
  %4 = and i64 %3, -4294967296
  %5 = add i64 %3, 11
  %6 = inttoptr i64 %5 to i32*
  %7 = load i32, i32* %6, align 4
  %8 = zext i32 %7 to i64
  %9 = or i64 %4, %8
  %10 = add i64 %3, 15
  %11 = inttoptr i64 %10 to i32*
  %12 = load i32, i32* %11, align 4
  %13 = and i32 %12, 1073741822
  %14 = add i64 %9, 15
  %15 = inttoptr i64 %14 to i32*
  %16 = load atomic i32, i32* %15 monotonic, align 4
  %17 = lshr i32 %16, 1
  %18 = add nuw nsw i32 %13, 3
  %19 = add nuw i32 %18, %17
  %20 = shl i32 %19, 2
  %21 = sext i32 %20 to i64
  %22 = add i64 %9, 7
  %23 = add i64 %22, %21
  %24 = inttoptr i64 %23 to i32*
  %25 = load atomic i32, i32* %24 monotonic, align 4
  %26 = zext i32 %25 to i64
  %27 = or i64 %4, %26
  ret i64 %27
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden zeroext i1 @_ZN2v88internal24OrderedHashTableIteratorINS0_13JSMapIteratorENS0_14OrderedHashMapEE7HasMoreEv(%"class.v8::internal::OrderedHashTableIterator.1149"*) local_unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::OrderedHashTableIterator.1149", %"class.v8::internal::OrderedHashTableIterator.1149"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %3 = load i64, i64* %2, align 8
  %4 = load %"class.v8::internal::SoleReadOnlyHeap"*, %"class.v8::internal::SoleReadOnlyHeap"** @_ZN2v88internal16SoleReadOnlyHeap15shared_ro_heap_E, align 8
  %5 = icmp eq %"class.v8::internal::SoleReadOnlyHeap"* %4, null
  br i1 %5, label %12, label %6

6:                                                ; preds = %1
  %7 = getelementptr inbounds %"class.v8::internal::SoleReadOnlyHeap", %"class.v8::internal::SoleReadOnlyHeap"* %4, i64 0, i32 0, i32 1
  %8 = load i8, i8* %7, align 8, !range !4
  %9 = icmp eq i8 %8, 0
  br i1 %9, label %12, label %10

10:                                               ; preds = %6
  %11 = getelementptr inbounds %"class.v8::internal::SoleReadOnlyHeap", %"class.v8::internal::SoleReadOnlyHeap"* %4, i64 0, i32 1, i64 0
  br label %20

12:                                               ; preds = %6, %1
  %13 = and i64 %3, -262144
  %14 = or i64 %13, 16
  %15 = inttoptr i64 %14 to i64*
  %16 = load i64, i64* %15, align 16
  %17 = add i64 %16, -41416
  %18 = inttoptr i64 %17 to %"class.v8::internal::Isolate"*
  %19 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %18, i64 0, i32 0, i32 7, i32 0, i64 0
  br label %20

20:                                               ; preds = %10, %12
  %21 = phi i64* [ %19, %12 ], [ %11, %10 ]
  tail call void @_ZN2v88internal24OrderedHashTableIteratorINS0_13JSMapIteratorENS0_14OrderedHashMapEE10TransitionEv(%"class.v8::internal::OrderedHashTableIterator.1149"* %0)
  %22 = load i64, i64* %2, align 8
  %23 = and i64 %22, -4294967296
  %24 = add i64 %22, 11
  %25 = inttoptr i64 %24 to i32*
  %26 = load i32, i32* %25, align 4
  %27 = zext i32 %26 to i64
  %28 = or i64 %23, %27
  %29 = add i64 %22, 15
  %30 = inttoptr i64 %29 to i32*
  %31 = load i32, i32* %30, align 4
  %32 = ashr i32 %31, 1
  %33 = add i64 %28, 7
  %34 = inttoptr i64 %33 to i32*
  %35 = load atomic i32, i32* %34 monotonic, align 4
  %36 = ashr i32 %35, 1
  %37 = add i64 %28, 11
  %38 = inttoptr i64 %37 to i32*
  %39 = load atomic i32, i32* %38 monotonic, align 4
  %40 = ashr i32 %39, 1
  %41 = add nsw i32 %40, %36
  %42 = icmp slt i32 %32, %41
  br i1 %42, label %43, label %67

43:                                               ; preds = %20
  %44 = add i64 %28, 15
  %45 = inttoptr i64 %44 to i32*
  %46 = getelementptr inbounds i64, i64* %21, i64 5
  %47 = load i64, i64* %46, align 8
  %48 = trunc i64 %47 to i32
  br label %49

49:                                               ; preds = %64, %43
  %50 = phi i32 [ %32, %43 ], [ %65, %64 ]
  %51 = load atomic i32, i32* %45 monotonic, align 4
  %52 = lshr i32 %51, 1
  %53 = mul nsw i32 %50, 3
  %54 = add i32 %53, 3
  %55 = add i32 %54, %52
  %56 = shl i32 %55, 2
  %57 = sext i32 %56 to i64
  %58 = add i64 %33, %57
  %59 = inttoptr i64 %58 to i32*
  %60 = load atomic i32, i32* %59 monotonic, align 4
  %61 = icmp eq i32 %60, %48
  br i1 %61, label %64, label %62

62:                                               ; preds = %49
  %63 = shl i32 %50, 1
  store atomic volatile i32 %63, i32* %30 monotonic, align 4
  br label %110

64:                                               ; preds = %49
  %65 = add i32 %50, 1
  %66 = icmp eq i32 %65, %41
  br i1 %66, label %67, label %49

67:                                               ; preds = %64, %20
  %68 = phi i32 [ %32, %20 ], [ %41, %64 ]
  %69 = shl i32 %68, 1
  store atomic volatile i32 %69, i32* %30 monotonic, align 4
  %70 = getelementptr inbounds i64, i64* %21, i64 112
  %71 = load i64, i64* %70, align 8
  %72 = load i64, i64* %2, align 8
  %73 = add i64 %72, 11
  %74 = inttoptr i64 %73 to i32*
  %75 = trunc i64 %71 to i32
  store atomic volatile i32 %75, i32* %74 monotonic, align 4
  %76 = load i64, i64* %2, align 8
  %77 = add i64 %76, 11
  %78 = and i64 %71, 1
  %79 = icmp eq i64 %78, 0
  br i1 %79, label %110, label %80

80:                                               ; preds = %67
  %81 = and i64 %76, -262144
  %82 = or i64 %81, 8
  %83 = inttoptr i64 %82 to i64*
  %84 = load i64, i64* %83, align 8
  %85 = and i64 %84, 262144
  %86 = icmp eq i64 %85, 0
  br i1 %86, label %93, label %87

87:                                               ; preds = %80
  %88 = or i64 %81, 16
  %89 = inttoptr i64 %88 to %"class.v8::internal::Heap"**
  %90 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %89, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %90, i64 %76, i64 %77, i64 %71) #7
  %91 = load i64, i64* %2, align 8
  %92 = add i64 %91, 11
  br label %93

93:                                               ; preds = %87, %80
  %94 = phi i64 [ %92, %87 ], [ %77, %80 ]
  %95 = phi i64 [ %91, %87 ], [ %76, %80 ]
  %96 = and i64 %71, -262144
  %97 = or i64 %96, 8
  %98 = inttoptr i64 %97 to i64*
  %99 = load i64, i64* %98, align 8
  %100 = and i64 %99, 24
  %101 = icmp eq i64 %100, 0
  br i1 %101, label %110, label %102

102:                                              ; preds = %93
  %103 = and i64 %95, -262144
  %104 = or i64 %103, 8
  %105 = inttoptr i64 %104 to i64*
  %106 = load i64, i64* %105, align 8
  %107 = and i64 %106, 24
  %108 = icmp eq i64 %107, 0
  br i1 %108, label %109, label %110

109:                                              ; preds = %102
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %95, i64 %94, i64 %71) #7
  br label %110

110:                                              ; preds = %109, %102, %93, %67, %62
  %111 = phi i1 [ true, %62 ], [ false, %67 ], [ false, %93 ], [ false, %102 ], [ false, %109 ]
  ret i1 %111
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden void @_ZN2v88internal24OrderedHashTableIteratorINS0_13JSMapIteratorENS0_14OrderedHashMapEE10TransitionEv(%"class.v8::internal::OrderedHashTableIterator.1149"*) local_unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::OrderedHashTableIterator.1149", %"class.v8::internal::OrderedHashTableIterator.1149"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %3 = load i64, i64* %2, align 8
  %4 = and i64 %3, -4294967296
  %5 = add i64 %3, 11
  %6 = inttoptr i64 %5 to i32*
  %7 = load i32, i32* %6, align 4
  %8 = zext i32 %7 to i64
  %9 = or i64 %4, %8
  %10 = add i64 %9, 7
  %11 = inttoptr i64 %10 to i32*
  %12 = load atomic i32, i32* %11 monotonic, align 4
  %13 = and i32 %12, 1
  %14 = icmp eq i32 %13, 0
  br i1 %14, label %111, label %15

15:                                               ; preds = %1
  %16 = add i64 %3, 15
  %17 = inttoptr i64 %16 to i32*
  %18 = load i32, i32* %17, align 4
  %19 = ashr i32 %18, 1
  %20 = load atomic i32, i32* %11 monotonic, align 4
  %21 = and i32 %20, 1
  %22 = icmp eq i32 %21, 0
  br i1 %22, label %67, label %23

23:                                               ; preds = %15, %60
  %24 = phi i32* [ %63, %60 ], [ %11, %15 ]
  %25 = phi i32 [ %61, %60 ], [ %19, %15 ]
  %26 = phi i64 [ %30, %60 ], [ %9, %15 ]
  %27 = and i64 %26, -4294967296
  %28 = load atomic i32, i32* %24 monotonic, align 4
  %29 = zext i32 %28 to i64
  %30 = or i64 %27, %29
  %31 = icmp sgt i32 %25, 0
  br i1 %31, label %32, label %60

32:                                               ; preds = %23
  %33 = add i64 %26, 11
  %34 = inttoptr i64 %33 to i32*
  %35 = load atomic i32, i32* %34 monotonic, align 4
  %36 = ashr i32 %35, 1
  %37 = icmp eq i32 %36, -1
  br i1 %37, label %60, label %38

38:                                               ; preds = %32
  %39 = icmp sgt i32 %35, 1
  br i1 %39, label %40, label %60

40:                                               ; preds = %38
  %41 = add i64 %26, 7
  %42 = sext i32 %36 to i64
  br label %43

43:                                               ; preds = %43, %40
  %44 = phi i64 [ %57, %43 ], [ 0, %40 ]
  %45 = phi i32 [ %56, %43 ], [ %25, %40 ]
  %46 = trunc i64 %44 to i32
  %47 = shl i32 %46, 2
  %48 = add i32 %47, 12
  %49 = sext i32 %48 to i64
  %50 = add i64 %41, %49
  %51 = inttoptr i64 %50 to i32*
  %52 = load atomic i32, i32* %51 monotonic, align 4
  %53 = ashr i32 %52, 1
  %54 = icmp slt i32 %53, %25
  %55 = zext i1 %54 to i32
  %56 = sub i32 %45, %55
  %57 = add nuw nsw i64 %44, 1
  %58 = icmp slt i64 %57, %42
  %59 = and i1 %54, %58
  br i1 %59, label %43, label %60

60:                                               ; preds = %43, %38, %32, %23
  %61 = phi i32 [ %25, %23 ], [ 0, %32 ], [ %25, %38 ], [ %56, %43 ]
  %62 = add i64 %30, 7
  %63 = inttoptr i64 %62 to i32*
  %64 = load atomic i32, i32* %63 monotonic, align 4
  %65 = and i32 %64, 1
  %66 = icmp eq i32 %65, 0
  br i1 %66, label %67, label %23

67:                                               ; preds = %60, %15
  %68 = phi i64 [ %9, %15 ], [ %30, %60 ]
  %69 = phi i32 [ %19, %15 ], [ %61, %60 ]
  %70 = trunc i64 %68 to i32
  store atomic volatile i32 %70, i32* %6 monotonic, align 4
  %71 = load i64, i64* %2, align 8
  %72 = add i64 %71, 11
  %73 = and i64 %68, 1
  %74 = icmp eq i64 %73, 0
  br i1 %74, label %106, label %75

75:                                               ; preds = %67
  %76 = and i64 %71, -262144
  %77 = or i64 %76, 8
  %78 = inttoptr i64 %77 to i64*
  %79 = load i64, i64* %78, align 8
  %80 = and i64 %79, 262144
  %81 = icmp eq i64 %80, 0
  br i1 %81, label %88, label %82

82:                                               ; preds = %75
  %83 = or i64 %76, 16
  %84 = inttoptr i64 %83 to %"class.v8::internal::Heap"**
  %85 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %84, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %85, i64 %71, i64 %72, i64 %68) #7
  %86 = load i64, i64* %2, align 8
  %87 = add i64 %86, 11
  br label %88

88:                                               ; preds = %82, %75
  %89 = phi i64 [ %87, %82 ], [ %72, %75 ]
  %90 = phi i64 [ %86, %82 ], [ %71, %75 ]
  %91 = and i64 %68, -262144
  %92 = or i64 %91, 8
  %93 = inttoptr i64 %92 to i64*
  %94 = load i64, i64* %93, align 8
  %95 = and i64 %94, 24
  %96 = icmp eq i64 %95, 0
  br i1 %96, label %106, label %97

97:                                               ; preds = %88
  %98 = and i64 %90, -262144
  %99 = or i64 %98, 8
  %100 = inttoptr i64 %99 to i64*
  %101 = load i64, i64* %100, align 8
  %102 = and i64 %101, 24
  %103 = icmp eq i64 %102, 0
  br i1 %103, label %104, label %106

104:                                              ; preds = %97
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %90, i64 %89, i64 %68) #7
  %105 = load i64, i64* %2, align 8
  br label %106

106:                                              ; preds = %104, %97, %88, %67
  %107 = phi i64 [ %105, %104 ], [ %90, %97 ], [ %90, %88 ], [ %71, %67 ]
  %108 = shl i32 %69, 1
  %109 = add i64 %107, 15
  %110 = inttoptr i64 %109 to i32*
  store atomic volatile i32 %108, i32* %110 monotonic, align 4
  br label %111

111:                                              ; preds = %1, %106
  ret void
}

; Function Attrs: norecurse nounwind readonly ssp uwtable
define hidden i64 @_ZN2v88internal14OrderedHashMap8GetEmptyENS0_13ReadOnlyRootsE(i64*) local_unnamed_addr #3 align 2 {
  %2 = getelementptr inbounds i64, i64* %0, i64 112
  %3 = load i64, i64* %2, align 8
  ret i64 %3
}

; Function Attrs: nounwind ssp uwtable
define weak_odr hidden void @_ZN2v88internal24OrderedHashTableIteratorINS0_13JSMapIteratorENS0_14OrderedHashMapEE8MoveNextEv(%"class.v8::internal::OrderedHashTableIterator.1149"*) local_unnamed_addr #0 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::OrderedHashTableIterator.1149", %"class.v8::internal::OrderedHashTableIterator.1149"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %3 = load i64, i64* %2, align 8
  %4 = add i64 %3, 15
  %5 = inttoptr i64 %4 to i32*
  %6 = load i32, i32* %5, align 4
  %7 = add i32 %6, 2
  %8 = and i32 %7, -2
  store atomic volatile i32 %8, i32* %5 monotonic, align 4
  ret void
}

; Function Attrs: inlinehint nounwind ssp uwtable
define weak_odr hidden i64 @_ZN2v88internal24OrderedHashTableIteratorINS0_13JSMapIteratorENS0_14OrderedHashMapEE10CurrentKeyEv(%"class.v8::internal::OrderedHashTableIterator.1149"*) local_unnamed_addr #4 comdat align 2 {
  %2 = getelementptr inbounds %"class.v8::internal::OrderedHashTableIterator.1149", %"class.v8::internal::OrderedHashTableIterator.1149"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %3 = load i64, i64* %2, align 8
  %4 = and i64 %3, -4294967296
  %5 = add i64 %3, 11
  %6 = inttoptr i64 %5 to i32*
  %7 = load i32, i32* %6, align 4
  %8 = zext i32 %7 to i64
  %9 = or i64 %4, %8
  %10 = add i64 %3, 15
  %11 = inttoptr i64 %10 to i32*
  %12 = load i32, i32* %11, align 4
  %13 = ashr i32 %12, 1
  %14 = add i64 %9, 15
  %15 = inttoptr i64 %14 to i32*
  %16 = load atomic i32, i32* %15 monotonic, align 4
  %17 = lshr i32 %16, 1
  %18 = mul nsw i32 %13, 3
  %19 = add i32 %18, 3
  %20 = add i32 %19, %17
  %21 = shl i32 %20, 2
  %22 = sext i32 %21 to i64
  %23 = add i64 %9, 7
  %24 = add i64 %23, %22
  %25 = inttoptr i64 %24 to i32*
  %26 = load atomic i32, i32* %25 monotonic, align 4
  %27 = zext i32 %26 to i64
  %28 = or i64 %4, %27
  ret i64 %28
}

; Function Attrs: nounwind ssp uwtable
define hidden i64* @_ZN2v88internal14OrderedHashSet3AddEPNS0_7IsolateENS0_6HandleIS1_EENS4_INS0_6ObjectEEE(%"class.v8::internal::Isolate"*, i64*, i64*) local_unnamed_addr #0 align 2 {
  %4 = alloca %"class.v8::internal::Handle<v8::internal::Object>::ObjectRef", align 8
  %5 = alloca %"class.v8::internal::Object", align 8
  %6 = ptrtoint i64* %1 to i64
  %7 = bitcast %"class.v8::internal::Handle<v8::internal::Object>::ObjectRef"* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %7) #7
  %8 = load i64, i64* %2, align 8
  %9 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::Object>::ObjectRef", %"class.v8::internal::Handle<v8::internal::Object>::ObjectRef"* %4, i64 0, i32 0, i32 0, i32 0
  store i64 %8, i64* %9, align 8
  %10 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::Object>::ObjectRef", %"class.v8::internal::Handle<v8::internal::Object>::ObjectRef"* %4, i64 0, i32 0
  %11 = call i64 @_ZN2v88internal6Object15GetOrCreateHashEPNS0_7IsolateE(%"class.v8::internal::Object"* nonnull %10, %"class.v8::internal::Isolate"* %0) #7
  %12 = trunc i64 %11 to i32
  %13 = ashr i32 %12, 1
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %7) #7
  %14 = load i64, i64* %1, align 8
  %15 = add i64 %14, 7
  %16 = inttoptr i64 %15 to i32*
  %17 = load atomic i32, i32* %16 monotonic, align 4
  %18 = icmp sgt i32 %17, 1
  %19 = add i64 %14, 15
  %20 = inttoptr i64 %19 to i32*
  br i1 %18, label %21, label %76

21:                                               ; preds = %3
  %22 = load atomic i32, i32* %20 monotonic, align 4
  %23 = lshr i32 %22, 1
  %24 = add nuw i32 %23, 1073741823
  %25 = and i32 %24, %13
  %26 = shl i32 %25, 2
  %27 = add i32 %26, 12
  %28 = sext i32 %27 to i64
  %29 = add i64 %15, %28
  %30 = inttoptr i64 %29 to i32*
  %31 = load atomic i32, i32* %30 monotonic, align 4
  %32 = icmp ugt i32 %31, -3
  br i1 %32, label %76, label %33

33:                                               ; preds = %21
  %34 = bitcast %"class.v8::internal::Object"* %5 to i8*
  %35 = getelementptr inbounds %"class.v8::internal::Object", %"class.v8::internal::Object"* %5, i64 0, i32 0, i32 0
  br label %36

36:                                               ; preds = %33, %57
  %37 = phi i64 [ %14, %33 ], [ %58, %57 ]
  %38 = phi i32 [ %31, %33 ], [ %70, %57 ]
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %34) #7
  %39 = add i64 %37, 15
  %40 = inttoptr i64 %39 to i32*
  %41 = load atomic i32, i32* %40 monotonic, align 4
  %42 = lshr i32 %41, 1
  %43 = and i32 %38, -2
  %44 = add i32 %43, 3
  %45 = add i32 %42, %44
  %46 = and i64 %37, -4294967296
  %47 = shl i32 %45, 2
  %48 = sext i32 %47 to i64
  %49 = add i64 %37, 7
  %50 = add i64 %49, %48
  %51 = inttoptr i64 %50 to i32*
  %52 = load atomic i32, i32* %51 monotonic, align 4
  %53 = zext i32 %52 to i64
  %54 = or i64 %46, %53
  store i64 %54, i64* %35, align 8
  %55 = load i64, i64* %2, align 8
  %56 = call zeroext i1 @_ZN2v88internal6Object13SameValueZeroES1_(%"class.v8::internal::Object"* nonnull %5, i64 %55) #7
  br i1 %56, label %72, label %57

57:                                               ; preds = %36
  %58 = load i64, i64* %1, align 8
  %59 = add i64 %58, 15
  %60 = inttoptr i64 %59 to i32*
  %61 = load atomic i32, i32* %60 monotonic, align 4
  %62 = lshr i32 %61, 1
  %63 = add i32 %62, %44
  %64 = shl i32 %63, 2
  %65 = add i32 %64, 4
  %66 = sext i32 %65 to i64
  %67 = add i64 %58, 7
  %68 = add i64 %67, %66
  %69 = inttoptr i64 %68 to i32*
  %70 = load atomic i32, i32* %69 monotonic, align 4
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %34) #7
  %71 = icmp ugt i32 %70, -3
  br i1 %71, label %73, label %36

72:                                               ; preds = %36
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %34) #7
  br label %187

73:                                               ; preds = %57
  %74 = inttoptr i64 %59 to i32*
  %75 = inttoptr i64 %67 to i32*
  br label %76

76:                                               ; preds = %3, %73, %21
  %77 = phi i32* [ %74, %73 ], [ %20, %21 ], [ %20, %3 ]
  %78 = phi i32* [ %75, %73 ], [ %16, %21 ], [ %16, %3 ]
  %79 = phi i64 [ %58, %73 ], [ %14, %21 ], [ %14, %3 ]
  %80 = load atomic i32, i32* %78 monotonic, align 4
  %81 = ashr i32 %80, 1
  %82 = add i64 %79, 11
  %83 = inttoptr i64 %82 to i32*
  %84 = load atomic i32, i32* %83 monotonic, align 4
  %85 = ashr i32 %84, 1
  %86 = load atomic i32, i32* %77 monotonic, align 4
  %87 = and i32 %86, -2
  %88 = add nsw i32 %85, %81
  %89 = icmp slt i32 %88, %87
  br i1 %89, label %101, label %90

90:                                               ; preds = %76
  %91 = icmp eq i32 %87, 0
  br i1 %91, label %97, label %92

92:                                               ; preds = %90
  %93 = ashr i32 %86, 1
  %94 = icmp slt i32 %85, %93
  %95 = zext i1 %94 to i32
  %96 = shl i32 %87, %95
  br label %97

97:                                               ; preds = %92, %90
  %98 = phi i32 [ 4, %90 ], [ %96, %92 ]
  %99 = call i64* @_ZN2v88internal16OrderedHashTableINS0_14OrderedHashSetELi1EE6RehashINS0_7IsolateEEENS0_11MaybeHandleIS2_EEPT_NS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"* %0, i64* %1, i32 %98) #7
  %100 = ptrtoint i64* %99 to i64
  br label %101

101:                                              ; preds = %76, %97
  %102 = phi i64 [ %6, %76 ], [ %100, %97 ]
  %103 = phi i64* [ %1, %76 ], [ %99, %97 ]
  %104 = icmp eq i64* %103, null
  br i1 %104, label %187, label %105

105:                                              ; preds = %101
  %106 = load i64, i64* %103, align 8
  %107 = add i64 %106, 15
  %108 = inttoptr i64 %107 to i32*
  %109 = load atomic i32, i32* %108 monotonic, align 4
  %110 = lshr i32 %109, 1
  %111 = add nuw i32 %110, 1073741823
  %112 = and i32 %111, %13
  %113 = load atomic i32, i32* %108 monotonic, align 4
  %114 = lshr i32 %113, 1
  %115 = add nuw i32 %114, 1073741823
  %116 = and i32 %115, %13
  %117 = shl i32 %116, 2
  %118 = add i32 %117, 12
  %119 = sext i32 %118 to i64
  %120 = add i64 %106, 7
  %121 = add i64 %120, %119
  %122 = inttoptr i64 %121 to i32*
  %123 = load atomic i32, i32* %122 monotonic, align 4
  %124 = and i32 %123, -2
  %125 = inttoptr i64 %120 to i32*
  %126 = load atomic i32, i32* %125 monotonic, align 4
  %127 = add i64 %106, 11
  %128 = inttoptr i64 %127 to i32*
  %129 = load atomic i32, i32* %128 monotonic, align 4
  %130 = and i32 %129, -2
  %131 = load atomic i32, i32* %108 monotonic, align 4
  %132 = lshr i32 %131, 1
  %133 = add i32 %130, %126
  %134 = and i32 %133, -2
  %135 = add nuw i32 %132, 3
  %136 = add i32 %135, %134
  %137 = load i64, i64* %2, align 8
  %138 = shl i32 %136, 2
  %139 = sext i32 %138 to i64
  %140 = add i64 %120, %139
  %141 = inttoptr i64 %140 to i32*
  %142 = trunc i64 %137 to i32
  store atomic volatile i32 %142, i32* %141 monotonic, align 4
  %143 = and i64 %137, 1
  %144 = icmp eq i64 %143, 0
  br i1 %144, label %168, label %145

145:                                              ; preds = %105
  %146 = and i64 %106, -262144
  %147 = or i64 %146, 8
  %148 = inttoptr i64 %147 to i64*
  %149 = load i64, i64* %148, align 8
  %150 = and i64 %149, 262144
  %151 = icmp eq i64 %150, 0
  br i1 %151, label %156, label %152

152:                                              ; preds = %145
  %153 = or i64 %146, 16
  %154 = inttoptr i64 %153 to %"class.v8::internal::Heap"**
  %155 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %154, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %155, i64 %106, i64 %140, i64 %137) #7
  br label %156

156:                                              ; preds = %152, %145
  %157 = and i64 %137, -262144
  %158 = or i64 %157, 8
  %159 = inttoptr i64 %158 to i64*
  %160 = load i64, i64* %159, align 8
  %161 = and i64 %160, 24
  %162 = icmp eq i64 %161, 0
  br i1 %162, label %168, label %163

163:                                              ; preds = %156
  %164 = load i64, i64* %148, align 8
  %165 = and i64 %164, 24
  %166 = icmp eq i64 %165, 0
  br i1 %166, label %167, label %168

167:                                              ; preds = %163
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %106, i64 %140, i64 %137) #7
  br label %168

168:                                              ; preds = %105, %156, %163, %167
  %169 = load i64, i64* %103, align 8
  %170 = add i32 %138, 4
  %171 = sext i32 %170 to i64
  %172 = add nsw i64 %171, 7
  %173 = add i64 %172, %169
  %174 = inttoptr i64 %173 to i32*
  store atomic volatile i32 %124, i32* %174 monotonic, align 4
  %175 = load i64, i64* %103, align 8
  %176 = shl i32 %112, 2
  %177 = add i32 %176, 12
  %178 = sext i32 %177 to i64
  %179 = add nsw i64 %178, 7
  %180 = add i64 %179, %175
  %181 = inttoptr i64 %180 to i32*
  store atomic volatile i32 %134, i32* %181 monotonic, align 4
  %182 = load i64, i64* %103, align 8
  %183 = add i32 %126, 2
  %184 = and i32 %183, -2
  %185 = add i64 %182, 7
  %186 = inttoptr i64 %185 to i32*
  store atomic volatile i32 %184, i32* %186 monotonic, align 4
  br label %187

187:                                              ; preds = %168, %101, %72
  %188 = phi i64 [ %6, %72 ], [ %102, %168 ], [ %102, %101 ]
  %189 = inttoptr i64 %188 to i64*
  ret i64* %189
}

declare i64 @_ZN2v88internal6Object15GetOrCreateHashEPNS0_7IsolateE(%"class.v8::internal::Object"*, %"class.v8::internal::Isolate"*) local_unnamed_addr #2

; Function Attrs: nounwind ssp uwtable
define hidden i64* @_ZN2v88internal14OrderedHashSet18ConvertToKeysArrayEPNS0_7IsolateENS0_6HandleIS1_EENS0_17GetKeysConversionE(%"class.v8::internal::Isolate"*, i64*, i32) local_unnamed_addr #0 align 2 {
  %4 = load i64, i64* %1, align 8
  %5 = add i64 %4, 7
  %6 = inttoptr i64 %5 to i32*
  %7 = load atomic i32, i32* %6 monotonic, align 4
  %8 = ashr i32 %7, 1
  %9 = add i64 %4, 15
  %10 = inttoptr i64 %9 to i32*
  %11 = load atomic i32, i32* %10 monotonic, align 4
  %12 = lshr i32 %11, 1
  %13 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 12
  %14 = load i64, i64* %13, align 8
  %15 = add i64 %4, -1
  %16 = inttoptr i64 %15 to i32*
  %17 = trunc i64 %14 to i32
  store atomic volatile i32 %17, i32* %16 monotonic, align 4
  %18 = icmp eq i32 %17, 0
  %19 = and i64 %14, 1
  %20 = icmp eq i64 %19, 0
  %21 = or i1 %18, %20
  br i1 %21, label %33, label %22

22:                                               ; preds = %3
  %23 = and i64 %4, -262144
  %24 = or i64 %23, 8
  %25 = inttoptr i64 %24 to i64*
  %26 = load i64, i64* %25, align 8
  %27 = and i64 %26, 262144
  %28 = icmp eq i64 %27, 0
  br i1 %28, label %33, label %29

29:                                               ; preds = %22
  %30 = or i64 %23, 16
  %31 = inttoptr i64 %30 to %"class.v8::internal::Heap"**
  %32 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %31, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %32, i64 %4, i64 0, i64 %14) #7
  br label %33

33:                                               ; preds = %3, %22, %29
  %34 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 2, i32 5
  %35 = load i64, i64* %34, align 8
  %36 = lshr i64 %35, 9
  %37 = icmp ult i64 %36, 16384
  %38 = select i1 %37, i64 %36, i64 16384
  %39 = icmp ugt i64 %38, 512
  %40 = select i1 %39, i64 %38, i64 512
  %41 = shl nuw nsw i64 %40, 1
  %42 = icmp sgt i32 %7, 1
  br i1 %42, label %43, label %146

43:                                               ; preds = %33
  %44 = add nuw i32 %12, 3
  %45 = icmp eq i32 %2, 0
  %46 = bitcast %"class.v8::internal::Isolate"* %0 to %"class.v8::internal::Factory"*
  %47 = sext i32 %8 to i64
  br i1 %45, label %48, label %148

48:                                               ; preds = %43, %143
  %49 = phi i64 [ %144, %143 ], [ 0, %43 ]
  %50 = trunc i64 %49 to i32
  %51 = shl i32 %50, 1
  %52 = add i32 %44, %51
  %53 = load i64, i64* %1, align 8
  %54 = and i64 %53, -4294967296
  %55 = shl i32 %52, 2
  %56 = sext i32 %55 to i64
  %57 = add nsw i64 %56, 7
  %58 = add i64 %57, %53
  %59 = inttoptr i64 %58 to i32*
  %60 = load atomic i32, i32* %59 monotonic, align 4
  %61 = zext i32 %60 to i64
  %62 = or i64 %54, %61
  %63 = and i64 %61, 1
  %64 = icmp eq i64 %63, 0
  br i1 %64, label %97, label %65

65:                                               ; preds = %48
  %66 = add i64 %62, -1
  %67 = inttoptr i64 %66 to i32*
  %68 = load atomic i32, i32* %67 monotonic, align 4
  %69 = zext i32 %68 to i64
  %70 = or i64 %54, %69
  %71 = add i64 %70, 7
  %72 = inttoptr i64 %71 to i16*
  %73 = load atomic i16, i16* %72 monotonic, align 2
  %74 = icmp eq i16 %73, 66
  br i1 %74, label %75, label %89

75:                                               ; preds = %65
  %76 = add i64 %62, 3
  %77 = inttoptr i64 %76 to double*
  %78 = load double, double* %77, align 1
  %79 = fadd double %78, 0x4330000000000000
  %80 = bitcast double %79 to i64
  %81 = and i64 %80, -4294967296
  %82 = icmp eq i64 %81, 4841369599423283200
  br i1 %82, label %83, label %89

83:                                               ; preds = %75
  %84 = trunc i64 %80 to i32
  %85 = uitofp i32 %84 to double
  %86 = fcmp une double %78, %85
  %87 = icmp eq i32 %84, -1
  %88 = or i1 %86, %87
  br i1 %88, label %89, label %101

89:                                               ; preds = %83, %75, %65
  %90 = load atomic i32, i32* %67 monotonic, align 4
  %91 = zext i32 %90 to i64
  %92 = or i64 %54, %91
  %93 = add i64 %92, 7
  %94 = inttoptr i64 %93 to i16*
  %95 = load atomic i16, i16* %94 monotonic, align 2
  %96 = icmp ult i16 %95, 65
  br i1 %96, label %108, label %171, !prof !5

97:                                               ; preds = %48
  %98 = icmp slt i32 %60, 0
  br i1 %98, label %171, label %99, !prof !6

99:                                               ; preds = %97
  %100 = lshr i32 %60, 1
  br label %101

101:                                              ; preds = %83, %99
  %102 = phi i32 [ %100, %99 ], [ %84, %83 ]
  %103 = icmp slt i64 %49, %41
  %104 = zext i32 %102 to i64
  %105 = tail call i64* @_ZN2v88internal7Factory12SizeToStringEmb(%"class.v8::internal::Factory"* %46, i64 %104, i1 zeroext %103) #7
  %106 = load i64, i64* %105, align 8
  %107 = load i64, i64* %1, align 8
  br label %108

108:                                              ; preds = %101, %89
  %109 = phi i64 [ %107, %101 ], [ %53, %89 ]
  %110 = phi i64 [ %106, %101 ], [ %62, %89 ]
  %111 = trunc i64 %49 to i32
  %112 = shl i32 %111, 2
  %113 = sext i32 %112 to i64
  %114 = add nsw i64 %113, 7
  %115 = add i64 %114, %109
  %116 = inttoptr i64 %115 to i32*
  %117 = trunc i64 %110 to i32
  store atomic volatile i32 %117, i32* %116 monotonic, align 4
  %118 = and i64 %110, 1
  %119 = icmp eq i64 %118, 0
  br i1 %119, label %143, label %120

120:                                              ; preds = %108
  %121 = and i64 %109, -262144
  %122 = or i64 %121, 8
  %123 = inttoptr i64 %122 to i64*
  %124 = load i64, i64* %123, align 8
  %125 = and i64 %124, 262144
  %126 = icmp eq i64 %125, 0
  br i1 %126, label %131, label %127

127:                                              ; preds = %120
  %128 = or i64 %121, 16
  %129 = inttoptr i64 %128 to %"class.v8::internal::Heap"**
  %130 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %129, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %130, i64 %109, i64 %115, i64 %110) #7
  br label %131

131:                                              ; preds = %127, %120
  %132 = and i64 %110, -262144
  %133 = or i64 %132, 8
  %134 = inttoptr i64 %133 to i64*
  %135 = load i64, i64* %134, align 8
  %136 = and i64 %135, 24
  %137 = icmp eq i64 %136, 0
  br i1 %137, label %143, label %138

138:                                              ; preds = %131
  %139 = load i64, i64* %123, align 8
  %140 = and i64 %139, 24
  %141 = icmp eq i64 %140, 0
  br i1 %141, label %142, label %143

142:                                              ; preds = %138
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %109, i64 %115, i64 %110) #7
  br label %143

143:                                              ; preds = %142, %138, %131, %108
  %144 = add nuw nsw i64 %49, 1
  %145 = icmp slt i64 %144, %47
  br i1 %145, label %48, label %146

146:                                              ; preds = %195, %143, %33
  %147 = tail call i64* @_ZN2v88internal10FixedArray13ShrinkOrEmptyEPNS0_7IsolateENS0_6HandleIS1_EEi(%"class.v8::internal::Isolate"* %0, i64* %1, i32 %8) #7
  ret i64* %147

148:                                              ; preds = %43, %195
  %149 = phi i64 [ %196, %195 ], [ 0, %43 ]
  %150 = trunc i64 %149 to i32
  %151 = shl i32 %150, 1
  %152 = add i32 %44, %151
  %153 = load i64, i64* %1, align 8
  %154 = and i64 %153, -4294967296
  %155 = shl i32 %152, 2
  %156 = sext i32 %155 to i64
  %157 = add nsw i64 %156, 7
  %158 = add i64 %157, %153
  %159 = inttoptr i64 %158 to i32*
  %160 = load atomic i32, i32* %159 monotonic, align 4
  %161 = zext i32 %160 to i64
  %162 = or i64 %154, %161
  %163 = trunc i64 %149 to i32
  %164 = shl i32 %163, 2
  %165 = sext i32 %164 to i64
  %166 = add nsw i64 %165, 7
  %167 = add i64 %166, %153
  %168 = inttoptr i64 %167 to i32*
  store atomic volatile i32 %160, i32* %168 monotonic, align 4
  %169 = and i64 %161, 1
  %170 = icmp eq i64 %169, 0
  br i1 %170, label %195, label %172

171:                                              ; preds = %89, %97
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.1, i64 0, i64 0)) #8
  unreachable

172:                                              ; preds = %148
  %173 = and i64 %153, -262144
  %174 = or i64 %173, 8
  %175 = inttoptr i64 %174 to i64*
  %176 = load i64, i64* %175, align 8
  %177 = and i64 %176, 262144
  %178 = icmp eq i64 %177, 0
  br i1 %178, label %183, label %179

179:                                              ; preds = %172
  %180 = or i64 %173, 16
  %181 = inttoptr i64 %180 to %"class.v8::internal::Heap"**
  %182 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %181, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %182, i64 %153, i64 %167, i64 %162) #7
  br label %183

183:                                              ; preds = %179, %172
  %184 = and i64 %162, -262144
  %185 = or i64 %184, 8
  %186 = inttoptr i64 %185 to i64*
  %187 = load i64, i64* %186, align 8
  %188 = and i64 %187, 24
  %189 = icmp eq i64 %188, 0
  br i1 %189, label %195, label %190

190:                                              ; preds = %183
  %191 = load i64, i64* %175, align 8
  %192 = and i64 %191, 24
  %193 = icmp eq i64 %192, 0
  br i1 %193, label %194, label %195

194:                                              ; preds = %190
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %153, i64 %167, i64 %162) #7
  br label %195

195:                                              ; preds = %148, %183, %190, %194
  %196 = add nuw nsw i64 %149, 1
  %197 = icmp slt i64 %196, %47
  br i1 %197, label %148, label %146
}

; Function Attrs: noreturn
declare void @_Z8V8_FatalPKcz(i8*, ...) local_unnamed_addr #5

declare i64* @_ZN2v88internal10FixedArray13ShrinkOrEmptyEPNS0_7IsolateENS0_6HandleIS1_EEi(%"class.v8::internal::Isolate"*, i64*, i32) local_unnamed_addr #2

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64* @_ZN2v88internal16OrderedHashTableINS0_14OrderedHashSetELi1EE6RehashINS0_7IsolateEEENS0_11MaybeHandleIS2_EEPT_NS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"*, i64*, i32) local_unnamed_addr #0 comdat align 2 {
  %4 = alloca %"class.v8::internal::JSReceiver", align 8
  %5 = load i64, i64* %1, align 8
  %6 = and i64 %5, -262144
  %7 = inttoptr i64 %6 to %"class.v8::internal::BasicMemoryChunk"*
  %8 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %7, i64 0, i32 1
  %9 = load i64, i64* %8, align 8
  %10 = icmp sgt i32 %2, 4
  %11 = select i1 %10, i32 %2, i32 4
  %12 = tail call i32 @_ZN2v84base4bits21RoundUpToPowerOfTwo32Ej(i32 %11) #7
  %13 = icmp sgt i32 %12, 26843544
  br i1 %13, label %303, label %14

14:                                               ; preds = %3
  %15 = and i64 %9, 24
  %16 = icmp eq i64 %15, 0
  %17 = zext i1 %16 to i8
  %18 = sdiv i32 %12, 2
  %19 = bitcast %"class.v8::internal::Isolate"* %0 to %"class.v8::internal::FactoryBase"*
  %20 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 55
  %21 = add nsw i32 %18, 3
  %22 = shl i32 %12, 1
  %23 = add nsw i32 %21, %22
  %24 = tail call i64* @_ZN2v88internal11FactoryBaseINS0_7FactoryEE20NewFixedArrayWithMapENS0_6HandleINS0_3MapEEEiNS0_14AllocationTypeE(%"class.v8::internal::FactoryBase"* %19, i64* %20, i32 %23, i8 zeroext %17) #7
  %25 = icmp sgt i32 %12, 1
  %26 = load i64, i64* %24, align 8
  br i1 %25, label %27, label %73

27:                                               ; preds = %14
  %28 = zext i32 %18 to i64
  %29 = and i64 %28, 1
  %30 = and i32 %12, -2
  %31 = icmp eq i32 %30, 2
  br i1 %31, label %63, label %32

32:                                               ; preds = %27
  %33 = sub nsw i64 %28, %29
  br label %34

34:                                               ; preds = %34, %32
  %35 = phi i64 [ 0, %32 ], [ %54, %34 ]
  %36 = phi i64 [ %26, %32 ], [ %55, %34 ]
  %37 = phi i64 [ %33, %32 ], [ %56, %34 ]
  %38 = trunc i64 %35 to i32
  %39 = shl i32 %38, 2
  %40 = add i32 %39, 12
  %41 = sext i32 %40 to i64
  %42 = add i64 %36, 7
  %43 = add i64 %42, %41
  %44 = inttoptr i64 %43 to i32*
  store atomic volatile i32 -2, i32* %44 monotonic, align 4
  %45 = load i64, i64* %24, align 8
  %46 = trunc i64 %35 to i32
  %47 = shl i32 %46, 2
  %48 = or i32 %47, 4
  %49 = add i32 %48, 12
  %50 = sext i32 %49 to i64
  %51 = add i64 %45, 7
  %52 = add i64 %51, %50
  %53 = inttoptr i64 %52 to i32*
  store atomic volatile i32 -2, i32* %53 monotonic, align 4
  %54 = add nuw nsw i64 %35, 2
  %55 = load i64, i64* %24, align 8
  %56 = add i64 %37, -2
  %57 = icmp eq i64 %56, 0
  br i1 %57, label %58, label %34

58:                                               ; preds = %34
  %59 = trunc i64 %54 to i32
  %60 = shl i32 %59, 2
  %61 = add i32 %60, 12
  %62 = sext i32 %61 to i64
  br label %63

63:                                               ; preds = %58, %27
  %64 = phi i64 [ undef, %27 ], [ %55, %58 ]
  %65 = phi i64 [ 12, %27 ], [ %62, %58 ]
  %66 = phi i64 [ %26, %27 ], [ %55, %58 ]
  %67 = icmp eq i64 %29, 0
  br i1 %67, label %73, label %68

68:                                               ; preds = %63
  %69 = add i64 %66, 7
  %70 = add i64 %69, %65
  %71 = inttoptr i64 %70 to i32*
  store atomic volatile i32 -2, i32* %71 monotonic, align 4
  %72 = load i64, i64* %24, align 8
  br label %73

73:                                               ; preds = %68, %63, %14
  %74 = phi i64 [ %26, %14 ], [ %64, %63 ], [ %72, %68 ]
  %75 = shl nsw i32 %18, 1
  %76 = add i64 %74, 15
  %77 = inttoptr i64 %76 to i32*
  store atomic volatile i32 %75, i32* %77 monotonic, align 4
  %78 = load i64, i64* %24, align 8
  %79 = add i64 %78, 7
  %80 = inttoptr i64 %79 to i32*
  store atomic volatile i32 0, i32* %80 monotonic, align 4
  %81 = load i64, i64* %24, align 8
  %82 = add i64 %81, 11
  %83 = inttoptr i64 %82 to i32*
  store atomic volatile i32 0, i32* %83 monotonic, align 4
  %84 = icmp eq i64* %24, null
  br i1 %84, label %303, label %85

85:                                               ; preds = %73
  %86 = load i64, i64* %24, align 8
  %87 = add i64 %86, 15
  %88 = inttoptr i64 %87 to i32*
  %89 = load atomic i32, i32* %88 monotonic, align 4
  %90 = load i64, i64* %1, align 8
  %91 = add i64 %90, 7
  %92 = inttoptr i64 %91 to i32*
  %93 = load atomic i32, i32* %92 monotonic, align 4
  %94 = ashr i32 %93, 1
  %95 = add i64 %90, 11
  %96 = inttoptr i64 %95 to i32*
  %97 = load atomic i32, i32* %96 monotonic, align 4
  %98 = ashr i32 %97, 1
  %99 = add nsw i32 %98, %94
  %100 = sext i32 %99 to i64
  %101 = icmp eq i32 %99, 0
  br i1 %101, label %113, label %102

102:                                              ; preds = %85
  %103 = lshr i32 %89, 1
  %104 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 5
  %105 = bitcast %"class.v8::internal::JSReceiver"* %4 to i8*
  %106 = getelementptr inbounds %"class.v8::internal::JSReceiver", %"class.v8::internal::JSReceiver"* %4, i64 0, i32 0, i32 0, i32 0, i32 0
  %107 = add nuw i32 %103, 1073741823
  br label %125

108:                                              ; preds = %266
  %109 = load i64, i64* %24, align 8
  %110 = load i64, i64* %1, align 8
  %111 = add i64 %110, 7
  %112 = inttoptr i64 %111 to i32*
  br label %113

113:                                              ; preds = %108, %85
  %114 = phi i32* [ %112, %108 ], [ %92, %85 ]
  %115 = phi i64 [ %109, %108 ], [ %86, %85 ]
  %116 = load atomic i32, i32* %114 monotonic, align 4
  %117 = and i32 %116, -2
  %118 = add i64 %115, 7
  %119 = inttoptr i64 %118 to i32*
  store atomic volatile i32 %117, i32* %119 monotonic, align 4
  %120 = load i64, i64* %1, align 8
  %121 = add i64 %120, 15
  %122 = inttoptr i64 %121 to i32*
  %123 = load atomic i32, i32* %122 monotonic, align 4
  %124 = icmp sgt i32 %123, 1
  br i1 %124, label %273, label %303

125:                                              ; preds = %271, %102
  %126 = phi i64 [ %90, %102 ], [ %272, %271 ]
  %127 = phi i32 [ 0, %102 ], [ %268, %271 ]
  %128 = phi i32 [ 0, %102 ], [ %267, %271 ]
  %129 = phi i64 [ 0, %102 ], [ %269, %271 ]
  %130 = trunc i64 %129 to i32
  %131 = add i64 %126, 15
  %132 = inttoptr i64 %131 to i32*
  %133 = load atomic i32, i32* %132 monotonic, align 4
  %134 = lshr i32 %133, 1
  %135 = shl i32 %130, 1
  %136 = add i32 %135, 3
  %137 = add i32 %134, %136
  %138 = and i64 %126, -4294967296
  %139 = shl i32 %137, 2
  %140 = sext i32 %139 to i64
  %141 = add i64 %126, 7
  %142 = add i64 %141, %140
  %143 = inttoptr i64 %142 to i32*
  %144 = load atomic i32, i32* %143 monotonic, align 4
  %145 = zext i32 %144 to i64
  %146 = or i64 %138, %145
  %147 = load i64, i64* %104, align 8
  %148 = trunc i64 %147 to i32
  %149 = icmp eq i32 %144, %148
  br i1 %149, label %150, label %157

150:                                              ; preds = %125
  %151 = add nsw i32 %128, 1
  %152 = shl i32 %128, 2
  %153 = add i32 %152, 12
  %154 = sext i32 %153 to i64
  %155 = add i64 %141, %154
  %156 = inttoptr i64 %155 to i32*
  store atomic volatile i32 %135, i32* %156 monotonic, align 4
  br label %266

157:                                              ; preds = %125
  %158 = call i64 @_ZN2v88internal6Object13GetSimpleHashES1_(i64 %146) #7
  %159 = and i64 %158, 1
  %160 = icmp eq i64 %159, 0
  br i1 %160, label %163, label %161

161:                                              ; preds = %157
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %105) #7
  store i64 %146, i64* %106, align 8
  %162 = call i64 @_ZN2v88internal10JSReceiver15GetIdentityHashEv(%"class.v8::internal::JSReceiver"* nonnull %4) #7
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %105) #7
  br label %163

163:                                              ; preds = %157, %161
  %164 = phi i64 [ %162, %161 ], [ %158, %157 ]
  %165 = trunc i64 %164 to i32
  %166 = lshr i32 %165, 1
  %167 = and i32 %166, %107
  %168 = load i64, i64* %24, align 8
  %169 = and i64 %168, -4294967296
  %170 = shl i32 %167, 2
  %171 = add i32 %170, 12
  %172 = sext i32 %171 to i64
  %173 = add i64 %168, 7
  %174 = add i64 %173, %172
  %175 = inttoptr i64 %174 to i32*
  %176 = load atomic i32, i32* %175 monotonic, align 4
  %177 = zext i32 %176 to i64
  %178 = or i64 %169, %177
  %179 = shl i32 %127, 1
  store atomic volatile i32 %179, i32* %175 monotonic, align 4
  %180 = load i64, i64* %24, align 8
  %181 = add i64 %180, 15
  %182 = inttoptr i64 %181 to i32*
  %183 = load atomic i32, i32* %182 monotonic, align 4
  %184 = lshr i32 %183, 1
  %185 = add i32 %179, 3
  %186 = add i32 %185, %184
  %187 = load i64, i64* %1, align 8
  %188 = add i64 %187, 15
  %189 = inttoptr i64 %188 to i32*
  %190 = load atomic i32, i32* %189 monotonic, align 4
  %191 = lshr i32 %190, 1
  %192 = add i32 %191, %136
  %193 = and i64 %187, -4294967296
  %194 = shl i32 %192, 2
  %195 = sext i32 %194 to i64
  %196 = add nsw i64 %195, 7
  %197 = add i64 %196, %187
  %198 = inttoptr i64 %197 to i32*
  %199 = load atomic i32, i32* %198 monotonic, align 4
  %200 = zext i32 %199 to i64
  %201 = or i64 %193, %200
  %202 = shl i32 %186, 2
  %203 = sext i32 %202 to i64
  %204 = add nsw i64 %203, 7
  %205 = add i64 %204, %180
  %206 = inttoptr i64 %205 to i32*
  store atomic volatile i32 %199, i32* %206 monotonic, align 4
  %207 = and i64 %200, 1
  %208 = icmp eq i64 %207, 0
  br i1 %208, label %257, label %234

209:                                              ; preds = %257
  %210 = and i64 %258, -262144
  %211 = or i64 %210, 8
  %212 = inttoptr i64 %211 to i64*
  %213 = load i64, i64* %212, align 8
  %214 = and i64 %213, 262144
  %215 = icmp eq i64 %214, 0
  br i1 %215, label %220, label %216

216:                                              ; preds = %209
  %217 = or i64 %210, 16
  %218 = inttoptr i64 %217 to %"class.v8::internal::Heap"**
  %219 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %218, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %219, i64 %258, i64 %262, i64 %178) #7
  br label %220

220:                                              ; preds = %216, %209
  %221 = and i64 %178, -262144
  %222 = or i64 %221, 8
  %223 = inttoptr i64 %222 to i64*
  %224 = load i64, i64* %223, align 8
  %225 = and i64 %224, 24
  %226 = icmp eq i64 %225, 0
  br i1 %226, label %232, label %227

227:                                              ; preds = %220
  %228 = load i64, i64* %212, align 8
  %229 = and i64 %228, 24
  %230 = icmp eq i64 %229, 0
  br i1 %230, label %231, label %232

231:                                              ; preds = %227
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %258, i64 %262, i64 %178) #7
  br label %232

232:                                              ; preds = %257, %220, %227, %231
  %233 = add nsw i32 %127, 1
  br label %266

234:                                              ; preds = %163
  %235 = and i64 %180, -262144
  %236 = or i64 %235, 8
  %237 = inttoptr i64 %236 to i64*
  %238 = load i64, i64* %237, align 8
  %239 = and i64 %238, 262144
  %240 = icmp eq i64 %239, 0
  br i1 %240, label %245, label %241

241:                                              ; preds = %234
  %242 = or i64 %235, 16
  %243 = inttoptr i64 %242 to %"class.v8::internal::Heap"**
  %244 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %243, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %244, i64 %180, i64 %205, i64 %201) #7
  br label %245

245:                                              ; preds = %241, %234
  %246 = and i64 %201, -262144
  %247 = or i64 %246, 8
  %248 = inttoptr i64 %247 to i64*
  %249 = load i64, i64* %248, align 8
  %250 = and i64 %249, 24
  %251 = icmp eq i64 %250, 0
  br i1 %251, label %257, label %252

252:                                              ; preds = %245
  %253 = load i64, i64* %237, align 8
  %254 = and i64 %253, 24
  %255 = icmp eq i64 %254, 0
  br i1 %255, label %256, label %257

256:                                              ; preds = %252
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %180, i64 %205, i64 %201) #7
  br label %257

257:                                              ; preds = %163, %245, %252, %256
  %258 = load i64, i64* %24, align 8
  %259 = add i32 %202, 4
  %260 = sext i32 %259 to i64
  %261 = add nsw i64 %260, 7
  %262 = add i64 %261, %258
  %263 = inttoptr i64 %262 to i32*
  store atomic volatile i32 %176, i32* %263 monotonic, align 4
  %264 = and i64 %177, 1
  %265 = icmp eq i64 %264, 0
  br i1 %265, label %232, label %209

266:                                              ; preds = %232, %150
  %267 = phi i32 [ %151, %150 ], [ %128, %232 ]
  %268 = phi i32 [ %127, %150 ], [ %233, %232 ]
  %269 = add i64 %129, 1
  %270 = icmp eq i64 %269, %100
  br i1 %270, label %108, label %271

271:                                              ; preds = %266
  %272 = load i64, i64* %1, align 8
  br label %125

273:                                              ; preds = %113
  %274 = load i64, i64* %24, align 8
  %275 = add i64 %120, 7
  %276 = inttoptr i64 %275 to i32*
  %277 = trunc i64 %274 to i32
  store atomic volatile i32 %277, i32* %276 monotonic, align 4
  %278 = and i64 %274, 1
  %279 = icmp eq i64 %278, 0
  br i1 %279, label %303, label %280

280:                                              ; preds = %273
  %281 = and i64 %120, -262144
  %282 = or i64 %281, 8
  %283 = inttoptr i64 %282 to i64*
  %284 = load i64, i64* %283, align 8
  %285 = and i64 %284, 262144
  %286 = icmp eq i64 %285, 0
  br i1 %286, label %291, label %287

287:                                              ; preds = %280
  %288 = or i64 %281, 16
  %289 = inttoptr i64 %288 to %"class.v8::internal::Heap"**
  %290 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %289, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %290, i64 %120, i64 %275, i64 %274) #7
  br label %291

291:                                              ; preds = %287, %280
  %292 = and i64 %274, -262144
  %293 = or i64 %292, 8
  %294 = inttoptr i64 %293 to i64*
  %295 = load i64, i64* %294, align 8
  %296 = and i64 %295, 24
  %297 = icmp eq i64 %296, 0
  br i1 %297, label %303, label %298

298:                                              ; preds = %291
  %299 = load i64, i64* %283, align 8
  %300 = and i64 %299, 24
  %301 = icmp eq i64 %300, 0
  br i1 %301, label %302, label %303

302:                                              ; preds = %298
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %120, i64 %275, i64 %274) #7
  br label %303

303:                                              ; preds = %3, %73, %113, %273, %291, %298, %302
  %304 = phi i64* [ %24, %302 ], [ %24, %298 ], [ %24, %291 ], [ %24, %273 ], [ %24, %113 ], [ null, %73 ], [ null, %3 ]
  ret i64* %304
}

; Function Attrs: nounwind ssp uwtable
define hidden i64* @_ZN2v88internal14OrderedHashSet6RehashEPNS0_7IsolateENS0_6HandleIS1_EE(%"class.v8::internal::Isolate"*, i64*) local_unnamed_addr #0 align 2 {
  %3 = load i64, i64* %1, align 8
  %4 = add i64 %3, 15
  %5 = inttoptr i64 %4 to i32*
  %6 = load atomic i32, i32* %5 monotonic, align 4
  %7 = and i32 %6, -2
  %8 = tail call i64* @_ZN2v88internal16OrderedHashTableINS0_14OrderedHashSetELi1EE6RehashINS0_7IsolateEEENS0_11MaybeHandleIS2_EEPT_NS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"* %0, i64* %1, i32 %7) #7
  ret i64* %8
}

; Function Attrs: nounwind ssp uwtable
define hidden i64* @_ZN2v88internal14OrderedHashMap6RehashEPNS0_7IsolateENS0_6HandleIS1_EE(%"class.v8::internal::Isolate"*, i64*) local_unnamed_addr #0 align 2 {
  %3 = load i64, i64* %1, align 8
  %4 = add i64 %3, 15
  %5 = inttoptr i64 %4 to i32*
  %6 = load atomic i32, i32* %5 monotonic, align 4
  %7 = and i32 %6, -2
  %8 = tail call i64* @_ZN2v88internal16OrderedHashTableINS0_14OrderedHashMapELi2EE6RehashINS0_7IsolateEEENS0_11MaybeHandleIS2_EEPT_NS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"* %0, i64* %1, i32 %7) #7
  ret i64* %8
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64* @_ZN2v88internal16OrderedHashTableINS0_14OrderedHashMapELi2EE6RehashINS0_7IsolateEEENS0_11MaybeHandleIS2_EEPT_NS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"*, i64*, i32) local_unnamed_addr #0 comdat align 2 {
  %4 = alloca %"class.v8::internal::JSReceiver", align 8
  %5 = load i64, i64* %1, align 8
  %6 = and i64 %5, -262144
  %7 = inttoptr i64 %6 to %"class.v8::internal::BasicMemoryChunk"*
  %8 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %7, i64 0, i32 1
  %9 = load i64, i64* %8, align 8
  %10 = icmp sgt i32 %2, 4
  %11 = select i1 %10, i32 %2, i32 4
  %12 = tail call i32 @_ZN2v84base4bits21RoundUpToPowerOfTwo32Ej(i32 %11) #7
  %13 = icmp sgt i32 %12, 19173960
  br i1 %13, label %315, label %14

14:                                               ; preds = %3
  %15 = and i64 %9, 24
  %16 = icmp eq i64 %15, 0
  %17 = zext i1 %16 to i8
  %18 = sdiv i32 %12, 2
  %19 = bitcast %"class.v8::internal::Isolate"* %0 to %"class.v8::internal::FactoryBase"*
  %20 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 54
  %21 = add nsw i32 %18, 3
  %22 = mul nsw i32 %12, 3
  %23 = add nsw i32 %21, %22
  %24 = tail call i64* @_ZN2v88internal11FactoryBaseINS0_7FactoryEE20NewFixedArrayWithMapENS0_6HandleINS0_3MapEEEiNS0_14AllocationTypeE(%"class.v8::internal::FactoryBase"* %19, i64* %20, i32 %23, i8 zeroext %17) #7
  %25 = icmp sgt i32 %12, 1
  %26 = load i64, i64* %24, align 8
  br i1 %25, label %27, label %73

27:                                               ; preds = %14
  %28 = zext i32 %18 to i64
  %29 = and i64 %28, 1
  %30 = and i32 %12, -2
  %31 = icmp eq i32 %30, 2
  br i1 %31, label %63, label %32

32:                                               ; preds = %27
  %33 = sub nsw i64 %28, %29
  br label %34

34:                                               ; preds = %34, %32
  %35 = phi i64 [ 0, %32 ], [ %54, %34 ]
  %36 = phi i64 [ %26, %32 ], [ %55, %34 ]
  %37 = phi i64 [ %33, %32 ], [ %56, %34 ]
  %38 = trunc i64 %35 to i32
  %39 = shl i32 %38, 2
  %40 = add i32 %39, 12
  %41 = sext i32 %40 to i64
  %42 = add i64 %36, 7
  %43 = add i64 %42, %41
  %44 = inttoptr i64 %43 to i32*
  store atomic volatile i32 -2, i32* %44 monotonic, align 4
  %45 = load i64, i64* %24, align 8
  %46 = trunc i64 %35 to i32
  %47 = shl i32 %46, 2
  %48 = or i32 %47, 4
  %49 = add i32 %48, 12
  %50 = sext i32 %49 to i64
  %51 = add i64 %45, 7
  %52 = add i64 %51, %50
  %53 = inttoptr i64 %52 to i32*
  store atomic volatile i32 -2, i32* %53 monotonic, align 4
  %54 = add nuw nsw i64 %35, 2
  %55 = load i64, i64* %24, align 8
  %56 = add i64 %37, -2
  %57 = icmp eq i64 %56, 0
  br i1 %57, label %58, label %34

58:                                               ; preds = %34
  %59 = trunc i64 %54 to i32
  %60 = shl i32 %59, 2
  %61 = add i32 %60, 12
  %62 = sext i32 %61 to i64
  br label %63

63:                                               ; preds = %58, %27
  %64 = phi i64 [ undef, %27 ], [ %55, %58 ]
  %65 = phi i64 [ 12, %27 ], [ %62, %58 ]
  %66 = phi i64 [ %26, %27 ], [ %55, %58 ]
  %67 = icmp eq i64 %29, 0
  br i1 %67, label %73, label %68

68:                                               ; preds = %63
  %69 = add i64 %66, 7
  %70 = add i64 %69, %65
  %71 = inttoptr i64 %70 to i32*
  store atomic volatile i32 -2, i32* %71 monotonic, align 4
  %72 = load i64, i64* %24, align 8
  br label %73

73:                                               ; preds = %68, %63, %14
  %74 = phi i64 [ %26, %14 ], [ %64, %63 ], [ %72, %68 ]
  %75 = shl nsw i32 %18, 1
  %76 = add i64 %74, 15
  %77 = inttoptr i64 %76 to i32*
  store atomic volatile i32 %75, i32* %77 monotonic, align 4
  %78 = load i64, i64* %24, align 8
  %79 = add i64 %78, 7
  %80 = inttoptr i64 %79 to i32*
  store atomic volatile i32 0, i32* %80 monotonic, align 4
  %81 = load i64, i64* %24, align 8
  %82 = add i64 %81, 11
  %83 = inttoptr i64 %82 to i32*
  store atomic volatile i32 0, i32* %83 monotonic, align 4
  %84 = icmp eq i64* %24, null
  br i1 %84, label %315, label %85

85:                                               ; preds = %73
  %86 = load i64, i64* %24, align 8
  %87 = add i64 %86, 15
  %88 = inttoptr i64 %87 to i32*
  %89 = load atomic i32, i32* %88 monotonic, align 4
  %90 = load i64, i64* %1, align 8
  %91 = add i64 %90, 7
  %92 = inttoptr i64 %91 to i32*
  %93 = load atomic i32, i32* %92 monotonic, align 4
  %94 = ashr i32 %93, 1
  %95 = add i64 %90, 11
  %96 = inttoptr i64 %95 to i32*
  %97 = load atomic i32, i32* %96 monotonic, align 4
  %98 = ashr i32 %97, 1
  %99 = add nsw i32 %98, %94
  %100 = sext i32 %99 to i64
  %101 = icmp eq i32 %99, 0
  br i1 %101, label %113, label %102

102:                                              ; preds = %85
  %103 = lshr i32 %89, 1
  %104 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 5
  %105 = bitcast %"class.v8::internal::JSReceiver"* %4 to i8*
  %106 = getelementptr inbounds %"class.v8::internal::JSReceiver", %"class.v8::internal::JSReceiver"* %4, i64 0, i32 0, i32 0, i32 0, i32 0
  %107 = add nuw i32 %103, 1073741823
  br label %125

108:                                              ; preds = %278
  %109 = load i64, i64* %24, align 8
  %110 = load i64, i64* %1, align 8
  %111 = add i64 %110, 7
  %112 = inttoptr i64 %111 to i32*
  br label %113

113:                                              ; preds = %108, %85
  %114 = phi i32* [ %112, %108 ], [ %92, %85 ]
  %115 = phi i64 [ %109, %108 ], [ %86, %85 ]
  %116 = load atomic i32, i32* %114 monotonic, align 4
  %117 = and i32 %116, -2
  %118 = add i64 %115, 7
  %119 = inttoptr i64 %118 to i32*
  store atomic volatile i32 %117, i32* %119 monotonic, align 4
  %120 = load i64, i64* %1, align 8
  %121 = add i64 %120, 15
  %122 = inttoptr i64 %121 to i32*
  %123 = load atomic i32, i32* %122 monotonic, align 4
  %124 = icmp sgt i32 %123, 1
  br i1 %124, label %285, label %315

125:                                              ; preds = %283, %102
  %126 = phi i64 [ %90, %102 ], [ %284, %283 ]
  %127 = phi i32 [ 0, %102 ], [ %280, %283 ]
  %128 = phi i32 [ 0, %102 ], [ %279, %283 ]
  %129 = phi i64 [ 0, %102 ], [ %281, %283 ]
  %130 = trunc i64 %129 to i32
  %131 = add i64 %126, 15
  %132 = inttoptr i64 %131 to i32*
  %133 = load atomic i32, i32* %132 monotonic, align 4
  %134 = lshr i32 %133, 1
  %135 = mul nsw i32 %130, 3
  %136 = add i32 %135, 3
  %137 = add i32 %134, %136
  %138 = and i64 %126, -4294967296
  %139 = shl i32 %137, 2
  %140 = sext i32 %139 to i64
  %141 = add i64 %126, 7
  %142 = add i64 %141, %140
  %143 = inttoptr i64 %142 to i32*
  %144 = load atomic i32, i32* %143 monotonic, align 4
  %145 = zext i32 %144 to i64
  %146 = or i64 %138, %145
  %147 = load i64, i64* %104, align 8
  %148 = trunc i64 %147 to i32
  %149 = icmp eq i32 %144, %148
  br i1 %149, label %150, label %158

150:                                              ; preds = %125
  %151 = add nsw i32 %128, 1
  %152 = shl i32 %130, 1
  %153 = shl i32 %128, 2
  %154 = add i32 %153, 12
  %155 = sext i32 %154 to i64
  %156 = add i64 %141, %155
  %157 = inttoptr i64 %156 to i32*
  store atomic volatile i32 %152, i32* %157 monotonic, align 4
  br label %278

158:                                              ; preds = %125
  %159 = call i64 @_ZN2v88internal6Object13GetSimpleHashES1_(i64 %146) #7
  %160 = and i64 %159, 1
  %161 = icmp eq i64 %160, 0
  br i1 %161, label %164, label %162

162:                                              ; preds = %158
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %105) #7
  store i64 %146, i64* %106, align 8
  %163 = call i64 @_ZN2v88internal10JSReceiver15GetIdentityHashEv(%"class.v8::internal::JSReceiver"* nonnull %4) #7
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %105) #7
  br label %164

164:                                              ; preds = %158, %162
  %165 = phi i64 [ %163, %162 ], [ %159, %158 ]
  %166 = trunc i64 %165 to i32
  %167 = lshr i32 %166, 1
  %168 = and i32 %167, %107
  %169 = load i64, i64* %24, align 8
  %170 = shl i32 %168, 2
  %171 = add i32 %170, 12
  %172 = sext i32 %171 to i64
  %173 = add i64 %169, 7
  %174 = add i64 %173, %172
  %175 = inttoptr i64 %174 to i32*
  %176 = load atomic i32, i32* %175 monotonic, align 4
  %177 = zext i32 %176 to i64
  %178 = shl i32 %127, 1
  store atomic volatile i32 %178, i32* %175 monotonic, align 4
  %179 = load i64, i64* %24, align 8
  %180 = add i64 %179, 15
  %181 = inttoptr i64 %180 to i32*
  %182 = load atomic i32, i32* %181 monotonic, align 4
  %183 = ashr i32 %182, 1
  %184 = mul nsw i32 %127, 3
  %185 = add i32 %184, 3
  %186 = add i32 %185, %183
  %187 = load i64, i64* %1, align 8
  %188 = add i64 %187, 15
  %189 = inttoptr i64 %188 to i32*
  %190 = load atomic i32, i32* %189 monotonic, align 4
  %191 = lshr i32 %190, 1
  %192 = add i32 %191, %136
  %193 = and i64 %187, -4294967296
  %194 = shl i32 %192, 2
  %195 = sext i32 %194 to i64
  %196 = add nsw i64 %195, 7
  %197 = add i64 %196, %187
  %198 = inttoptr i64 %197 to i32*
  %199 = load atomic i32, i32* %198 monotonic, align 4
  %200 = zext i32 %199 to i64
  %201 = or i64 %193, %200
  %202 = shl i32 %186, 2
  %203 = sext i32 %202 to i64
  %204 = add nsw i64 %203, 7
  %205 = add i64 %204, %179
  %206 = inttoptr i64 %205 to i32*
  store atomic volatile i32 %199, i32* %206 monotonic, align 4
  %207 = and i64 %200, 1
  %208 = icmp eq i64 %207, 0
  br i1 %208, label %257, label %234

209:                                              ; preds = %340
  %210 = and i64 %343, -262144
  %211 = or i64 %210, 8
  %212 = inttoptr i64 %211 to i64*
  %213 = load i64, i64* %212, align 8
  %214 = and i64 %213, 262144
  %215 = icmp eq i64 %214, 0
  br i1 %215, label %220, label %216

216:                                              ; preds = %209
  %217 = or i64 %210, 16
  %218 = inttoptr i64 %217 to %"class.v8::internal::Heap"**
  %219 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %218, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %219, i64 %343, i64 %347, i64 %342) #7
  br label %220

220:                                              ; preds = %216, %209
  %221 = and i64 %342, -262144
  %222 = or i64 %221, 8
  %223 = inttoptr i64 %222 to i64*
  %224 = load i64, i64* %223, align 8
  %225 = and i64 %224, 24
  %226 = icmp eq i64 %225, 0
  br i1 %226, label %232, label %227

227:                                              ; preds = %220
  %228 = load i64, i64* %212, align 8
  %229 = and i64 %228, 24
  %230 = icmp eq i64 %229, 0
  br i1 %230, label %231, label %232

231:                                              ; preds = %227
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %343, i64 %347, i64 %342) #7
  br label %232

232:                                              ; preds = %340, %220, %227, %231
  %233 = add nsw i32 %127, 1
  br label %278

234:                                              ; preds = %164
  %235 = and i64 %179, -262144
  %236 = or i64 %235, 8
  %237 = inttoptr i64 %236 to i64*
  %238 = load i64, i64* %237, align 8
  %239 = and i64 %238, 262144
  %240 = icmp eq i64 %239, 0
  br i1 %240, label %245, label %241

241:                                              ; preds = %234
  %242 = or i64 %235, 16
  %243 = inttoptr i64 %242 to %"class.v8::internal::Heap"**
  %244 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %243, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %244, i64 %179, i64 %205, i64 %201) #7
  br label %245

245:                                              ; preds = %241, %234
  %246 = and i64 %201, -262144
  %247 = or i64 %246, 8
  %248 = inttoptr i64 %247 to i64*
  %249 = load i64, i64* %248, align 8
  %250 = and i64 %249, 24
  %251 = icmp eq i64 %250, 0
  br i1 %251, label %257, label %252

252:                                              ; preds = %245
  %253 = load i64, i64* %237, align 8
  %254 = and i64 %253, 24
  %255 = icmp eq i64 %254, 0
  br i1 %255, label %256, label %257

256:                                              ; preds = %252
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %179, i64 %205, i64 %201) #7
  br label %257

257:                                              ; preds = %164, %245, %252, %256
  %258 = load i64, i64* %1, align 8
  %259 = and i64 %258, -4294967296
  %260 = shl i32 %192, 2
  %261 = add i32 %260, 4
  %262 = sext i32 %261 to i64
  %263 = add nsw i64 %262, 7
  %264 = add i64 %263, %258
  %265 = inttoptr i64 %264 to i32*
  %266 = load atomic i32, i32* %265 monotonic, align 4
  %267 = zext i32 %266 to i64
  %268 = or i64 %259, %267
  %269 = load i64, i64* %24, align 8
  %270 = shl i32 %186, 2
  %271 = add i32 %270, 4
  %272 = sext i32 %271 to i64
  %273 = add nsw i64 %272, 7
  %274 = add i64 %273, %269
  %275 = inttoptr i64 %274 to i32*
  store atomic volatile i32 %266, i32* %275 monotonic, align 4
  %276 = and i64 %267, 1
  %277 = icmp eq i64 %276, 0
  br i1 %277, label %340, label %317

278:                                              ; preds = %232, %150
  %279 = phi i32 [ %151, %150 ], [ %128, %232 ]
  %280 = phi i32 [ %127, %150 ], [ %233, %232 ]
  %281 = add i64 %129, 1
  %282 = icmp eq i64 %281, %100
  br i1 %282, label %108, label %283

283:                                              ; preds = %278
  %284 = load i64, i64* %1, align 8
  br label %125

285:                                              ; preds = %113
  %286 = load i64, i64* %24, align 8
  %287 = add i64 %120, 7
  %288 = inttoptr i64 %287 to i32*
  %289 = trunc i64 %286 to i32
  store atomic volatile i32 %289, i32* %288 monotonic, align 4
  %290 = and i64 %286, 1
  %291 = icmp eq i64 %290, 0
  br i1 %291, label %315, label %292

292:                                              ; preds = %285
  %293 = and i64 %120, -262144
  %294 = or i64 %293, 8
  %295 = inttoptr i64 %294 to i64*
  %296 = load i64, i64* %295, align 8
  %297 = and i64 %296, 262144
  %298 = icmp eq i64 %297, 0
  br i1 %298, label %303, label %299

299:                                              ; preds = %292
  %300 = or i64 %293, 16
  %301 = inttoptr i64 %300 to %"class.v8::internal::Heap"**
  %302 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %301, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %302, i64 %120, i64 %287, i64 %286) #7
  br label %303

303:                                              ; preds = %299, %292
  %304 = and i64 %286, -262144
  %305 = or i64 %304, 8
  %306 = inttoptr i64 %305 to i64*
  %307 = load i64, i64* %306, align 8
  %308 = and i64 %307, 24
  %309 = icmp eq i64 %308, 0
  br i1 %309, label %315, label %310

310:                                              ; preds = %303
  %311 = load i64, i64* %295, align 8
  %312 = and i64 %311, 24
  %313 = icmp eq i64 %312, 0
  br i1 %313, label %314, label %315

314:                                              ; preds = %310
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %120, i64 %287, i64 %286) #7
  br label %315

315:                                              ; preds = %3, %73, %113, %285, %303, %310, %314
  %316 = phi i64* [ %24, %314 ], [ %24, %310 ], [ %24, %303 ], [ %24, %285 ], [ %24, %113 ], [ null, %73 ], [ null, %3 ]
  ret i64* %316

317:                                              ; preds = %257
  %318 = and i64 %269, -262144
  %319 = or i64 %318, 8
  %320 = inttoptr i64 %319 to i64*
  %321 = load i64, i64* %320, align 8
  %322 = and i64 %321, 262144
  %323 = icmp eq i64 %322, 0
  br i1 %323, label %328, label %324

324:                                              ; preds = %317
  %325 = or i64 %318, 16
  %326 = inttoptr i64 %325 to %"class.v8::internal::Heap"**
  %327 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %326, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %327, i64 %269, i64 %274, i64 %268) #7
  br label %328

328:                                              ; preds = %324, %317
  %329 = and i64 %268, -262144
  %330 = or i64 %329, 8
  %331 = inttoptr i64 %330 to i64*
  %332 = load i64, i64* %331, align 8
  %333 = and i64 %332, 24
  %334 = icmp eq i64 %333, 0
  br i1 %334, label %340, label %335

335:                                              ; preds = %328
  %336 = load i64, i64* %320, align 8
  %337 = and i64 %336, 24
  %338 = icmp eq i64 %337, 0
  br i1 %338, label %339, label %340

339:                                              ; preds = %335
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %269, i64 %274, i64 %268) #7
  br label %340

340:                                              ; preds = %339, %335, %328, %257
  %341 = and i64 %169, -4294967296
  %342 = or i64 %341, %177
  %343 = load i64, i64* %24, align 8
  %344 = add i32 %202, 8
  %345 = sext i32 %344 to i64
  %346 = add nsw i64 %345, 7
  %347 = add i64 %346, %343
  %348 = inttoptr i64 %347 to i32*
  store atomic volatile i32 %176, i32* %348 monotonic, align 4
  %349 = and i64 %177, 1
  %350 = icmp eq i64 %349, 0
  br i1 %350, label %232, label %209
}

; Function Attrs: nounwind ssp uwtable
define hidden i64 @_ZN2v88internal14OrderedHashMap7GetHashEPNS0_7IsolateEm(%"class.v8::internal::Isolate"* nocapture readonly, i64) local_unnamed_addr #0 align 2 {
  %3 = alloca %"class.v8::internal::JSReceiver", align 8
  %4 = tail call i64 @_ZN2v88internal6Object13GetSimpleHashES1_(i64 %1) #7
  %5 = and i64 %4, 1
  %6 = icmp eq i64 %5, 0
  br i1 %6, label %11, label %7

7:                                                ; preds = %2
  %8 = bitcast %"class.v8::internal::JSReceiver"* %3 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %8) #7
  %9 = getelementptr inbounds %"class.v8::internal::JSReceiver", %"class.v8::internal::JSReceiver"* %3, i64 0, i32 0, i32 0, i32 0, i32 0
  store i64 %1, i64* %9, align 8
  %10 = call i64 @_ZN2v88internal10JSReceiver15GetIdentityHashEv(%"class.v8::internal::JSReceiver"* nonnull %3) #7
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %8) #7
  br label %11

11:                                               ; preds = %2, %7
  %12 = phi i64 [ %10, %7 ], [ %4, %2 ]
  %13 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 4
  %14 = load i64, i64* %13, align 8
  %15 = trunc i64 %12 to i32
  %16 = trunc i64 %14 to i32
  %17 = icmp eq i32 %15, %16
  %18 = select i1 %17, i64 -2, i64 %12
  ret i64 %18
}

; Function Attrs: nounwind ssp uwtable
define hidden i64* @_ZN2v88internal14OrderedHashMap3AddEPNS0_7IsolateENS0_6HandleIS1_EENS4_INS0_6ObjectEEES7_(%"class.v8::internal::Isolate"*, i64*, i64*, i64*) local_unnamed_addr #0 align 2 {
  %5 = alloca %"class.v8::internal::Handle<v8::internal::Object>::ObjectRef", align 8
  %6 = alloca %"class.v8::internal::Object", align 8
  %7 = ptrtoint i64* %1 to i64
  %8 = bitcast %"class.v8::internal::Handle<v8::internal::Object>::ObjectRef"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %8) #7
  %9 = load i64, i64* %2, align 8
  %10 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::Object>::ObjectRef", %"class.v8::internal::Handle<v8::internal::Object>::ObjectRef"* %5, i64 0, i32 0, i32 0, i32 0
  store i64 %9, i64* %10, align 8
  %11 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::Object>::ObjectRef", %"class.v8::internal::Handle<v8::internal::Object>::ObjectRef"* %5, i64 0, i32 0
  %12 = call i64 @_ZN2v88internal6Object15GetOrCreateHashEPNS0_7IsolateE(%"class.v8::internal::Object"* nonnull %11, %"class.v8::internal::Isolate"* %0) #7
  %13 = trunc i64 %12 to i32
  %14 = ashr i32 %13, 1
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %8) #7
  %15 = load i64, i64* %1, align 8
  %16 = add i64 %15, 7
  %17 = inttoptr i64 %16 to i32*
  %18 = load atomic i32, i32* %17 monotonic, align 4
  %19 = icmp sgt i32 %18, 1
  %20 = add i64 %15, 15
  %21 = inttoptr i64 %20 to i32*
  br i1 %19, label %22, label %79

22:                                               ; preds = %4
  %23 = load atomic i32, i32* %21 monotonic, align 4
  %24 = lshr i32 %23, 1
  %25 = add nuw i32 %24, 1073741823
  %26 = and i32 %25, %14
  %27 = shl i32 %26, 2
  %28 = add i32 %27, 12
  %29 = sext i32 %28 to i64
  %30 = add i64 %16, %29
  %31 = inttoptr i64 %30 to i32*
  %32 = load atomic i32, i32* %31 monotonic, align 4
  %33 = load i64, i64* %2, align 8
  %34 = ashr i32 %32, 1
  %35 = icmp eq i32 %34, -1
  br i1 %35, label %79, label %36

36:                                               ; preds = %22
  %37 = bitcast %"class.v8::internal::Object"* %6 to i8*
  %38 = getelementptr inbounds %"class.v8::internal::Object", %"class.v8::internal::Object"* %6, i64 0, i32 0, i32 0
  br label %39

39:                                               ; preds = %36, %59
  %40 = phi i64 [ %15, %36 ], [ %60, %59 ]
  %41 = phi i32 [ %34, %36 ], [ %73, %59 ]
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %37) #7
  %42 = add i64 %40, 15
  %43 = inttoptr i64 %42 to i32*
  %44 = load atomic i32, i32* %43 monotonic, align 4
  %45 = lshr i32 %44, 1
  %46 = mul nsw i32 %41, 3
  %47 = add i32 %46, 3
  %48 = add i32 %45, %47
  %49 = and i64 %40, -4294967296
  %50 = shl i32 %48, 2
  %51 = sext i32 %50 to i64
  %52 = add i64 %40, 7
  %53 = add i64 %52, %51
  %54 = inttoptr i64 %53 to i32*
  %55 = load atomic i32, i32* %54 monotonic, align 4
  %56 = zext i32 %55 to i64
  %57 = or i64 %49, %56
  store i64 %57, i64* %38, align 8
  %58 = call zeroext i1 @_ZN2v88internal6Object13SameValueZeroES1_(%"class.v8::internal::Object"* nonnull %6, i64 %33) #7
  br i1 %58, label %75, label %59

59:                                               ; preds = %39
  %60 = load i64, i64* %1, align 8
  %61 = add i64 %60, 15
  %62 = inttoptr i64 %61 to i32*
  %63 = load atomic i32, i32* %62 monotonic, align 4
  %64 = lshr i32 %63, 1
  %65 = add i32 %64, %47
  %66 = shl i32 %65, 2
  %67 = add i32 %66, 8
  %68 = sext i32 %67 to i64
  %69 = add i64 %60, 7
  %70 = add i64 %69, %68
  %71 = inttoptr i64 %70 to i32*
  %72 = load atomic i32, i32* %71 monotonic, align 4
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %37) #7
  %73 = ashr i32 %72, 1
  %74 = icmp eq i32 %73, -1
  br i1 %74, label %76, label %39

75:                                               ; preds = %39
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %37) #7
  br label %226

76:                                               ; preds = %59
  %77 = inttoptr i64 %61 to i32*
  %78 = inttoptr i64 %69 to i32*
  br label %79

79:                                               ; preds = %4, %76, %22
  %80 = phi i32* [ %77, %76 ], [ %21, %22 ], [ %21, %4 ]
  %81 = phi i32* [ %78, %76 ], [ %17, %22 ], [ %17, %4 ]
  %82 = phi i64 [ %60, %76 ], [ %15, %22 ], [ %15, %4 ]
  %83 = load atomic i32, i32* %81 monotonic, align 4
  %84 = ashr i32 %83, 1
  %85 = add i64 %82, 11
  %86 = inttoptr i64 %85 to i32*
  %87 = load atomic i32, i32* %86 monotonic, align 4
  %88 = ashr i32 %87, 1
  %89 = load atomic i32, i32* %80 monotonic, align 4
  %90 = and i32 %89, -2
  %91 = add nsw i32 %88, %84
  %92 = icmp slt i32 %91, %90
  br i1 %92, label %104, label %93

93:                                               ; preds = %79
  %94 = icmp eq i32 %90, 0
  br i1 %94, label %100, label %95

95:                                               ; preds = %93
  %96 = ashr i32 %89, 1
  %97 = icmp slt i32 %88, %96
  %98 = zext i1 %97 to i32
  %99 = shl i32 %90, %98
  br label %100

100:                                              ; preds = %95, %93
  %101 = phi i32 [ 4, %93 ], [ %99, %95 ]
  %102 = call i64* @_ZN2v88internal16OrderedHashTableINS0_14OrderedHashMapELi2EE6RehashINS0_7IsolateEEENS0_11MaybeHandleIS2_EEPT_NS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"* %0, i64* %1, i32 %101) #7
  %103 = ptrtoint i64* %102 to i64
  br label %104

104:                                              ; preds = %79, %100
  %105 = phi i64 [ %7, %79 ], [ %103, %100 ]
  %106 = phi i64* [ %1, %79 ], [ %102, %100 ]
  %107 = icmp eq i64* %106, null
  br i1 %107, label %226, label %108

108:                                              ; preds = %104
  %109 = load i64, i64* %106, align 8
  %110 = add i64 %109, 15
  %111 = inttoptr i64 %110 to i32*
  %112 = load atomic i32, i32* %111 monotonic, align 4
  %113 = lshr i32 %112, 1
  %114 = add nuw i32 %113, 1073741823
  %115 = and i32 %114, %14
  %116 = load atomic i32, i32* %111 monotonic, align 4
  %117 = lshr i32 %116, 1
  %118 = add nuw i32 %117, 1073741823
  %119 = and i32 %118, %14
  %120 = shl i32 %119, 2
  %121 = add i32 %120, 12
  %122 = sext i32 %121 to i64
  %123 = add i64 %109, 7
  %124 = add i64 %123, %122
  %125 = inttoptr i64 %124 to i32*
  %126 = load atomic i32, i32* %125 monotonic, align 4
  %127 = and i32 %126, -2
  %128 = inttoptr i64 %123 to i32*
  %129 = load atomic i32, i32* %128 monotonic, align 4
  %130 = ashr i32 %129, 1
  %131 = add i64 %109, 11
  %132 = inttoptr i64 %131 to i32*
  %133 = load atomic i32, i32* %132 monotonic, align 4
  %134 = ashr i32 %133, 1
  %135 = add nsw i32 %134, %130
  %136 = load atomic i32, i32* %111 monotonic, align 4
  %137 = lshr i32 %136, 1
  %138 = mul nsw i32 %135, 3
  %139 = add nuw i32 %137, 3
  %140 = add i32 %139, %138
  %141 = load i64, i64* %2, align 8
  %142 = shl i32 %140, 2
  %143 = sext i32 %142 to i64
  %144 = add i64 %123, %143
  %145 = inttoptr i64 %144 to i32*
  %146 = trunc i64 %141 to i32
  store atomic volatile i32 %146, i32* %145 monotonic, align 4
  %147 = and i64 %141, 1
  %148 = icmp eq i64 %147, 0
  br i1 %148, label %172, label %149

149:                                              ; preds = %108
  %150 = and i64 %109, -262144
  %151 = or i64 %150, 8
  %152 = inttoptr i64 %151 to i64*
  %153 = load i64, i64* %152, align 8
  %154 = and i64 %153, 262144
  %155 = icmp eq i64 %154, 0
  br i1 %155, label %160, label %156

156:                                              ; preds = %149
  %157 = or i64 %150, 16
  %158 = inttoptr i64 %157 to %"class.v8::internal::Heap"**
  %159 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %158, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %159, i64 %109, i64 %144, i64 %141) #7
  br label %160

160:                                              ; preds = %156, %149
  %161 = and i64 %141, -262144
  %162 = or i64 %161, 8
  %163 = inttoptr i64 %162 to i64*
  %164 = load i64, i64* %163, align 8
  %165 = and i64 %164, 24
  %166 = icmp eq i64 %165, 0
  br i1 %166, label %172, label %167

167:                                              ; preds = %160
  %168 = load i64, i64* %152, align 8
  %169 = and i64 %168, 24
  %170 = icmp eq i64 %169, 0
  br i1 %170, label %171, label %172

171:                                              ; preds = %167
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %109, i64 %144, i64 %141) #7
  br label %172

172:                                              ; preds = %108, %160, %167, %171
  %173 = load i64, i64* %106, align 8
  %174 = load i64, i64* %3, align 8
  %175 = add i32 %142, 4
  %176 = sext i32 %175 to i64
  %177 = add nsw i64 %176, 7
  %178 = add i64 %177, %173
  %179 = inttoptr i64 %178 to i32*
  %180 = trunc i64 %174 to i32
  store atomic volatile i32 %180, i32* %179 monotonic, align 4
  %181 = and i64 %174, 1
  %182 = icmp eq i64 %181, 0
  br i1 %182, label %206, label %183

183:                                              ; preds = %172
  %184 = and i64 %173, -262144
  %185 = or i64 %184, 8
  %186 = inttoptr i64 %185 to i64*
  %187 = load i64, i64* %186, align 8
  %188 = and i64 %187, 262144
  %189 = icmp eq i64 %188, 0
  br i1 %189, label %194, label %190

190:                                              ; preds = %183
  %191 = or i64 %184, 16
  %192 = inttoptr i64 %191 to %"class.v8::internal::Heap"**
  %193 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %192, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %193, i64 %173, i64 %178, i64 %174) #7
  br label %194

194:                                              ; preds = %190, %183
  %195 = and i64 %174, -262144
  %196 = or i64 %195, 8
  %197 = inttoptr i64 %196 to i64*
  %198 = load i64, i64* %197, align 8
  %199 = and i64 %198, 24
  %200 = icmp eq i64 %199, 0
  br i1 %200, label %206, label %201

201:                                              ; preds = %194
  %202 = load i64, i64* %186, align 8
  %203 = and i64 %202, 24
  %204 = icmp eq i64 %203, 0
  br i1 %204, label %205, label %206

205:                                              ; preds = %201
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %173, i64 %178, i64 %174) #7
  br label %206

206:                                              ; preds = %172, %194, %201, %205
  %207 = load i64, i64* %106, align 8
  %208 = add i32 %142, 8
  %209 = sext i32 %208 to i64
  %210 = add nsw i64 %209, 7
  %211 = add i64 %210, %207
  %212 = inttoptr i64 %211 to i32*
  store atomic volatile i32 %127, i32* %212 monotonic, align 4
  %213 = load i64, i64* %106, align 8
  %214 = shl i32 %135, 1
  %215 = shl i32 %115, 2
  %216 = add i32 %215, 12
  %217 = sext i32 %216 to i64
  %218 = add nsw i64 %217, 7
  %219 = add i64 %218, %213
  %220 = inttoptr i64 %219 to i32*
  store atomic volatile i32 %214, i32* %220 monotonic, align 4
  %221 = load i64, i64* %106, align 8
  %222 = add i32 %129, 2
  %223 = and i32 %222, -2
  %224 = add i64 %221, 7
  %225 = inttoptr i64 %224 to i32*
  store atomic volatile i32 %223, i32* %225 monotonic, align 4
  br label %226

226:                                              ; preds = %206, %104, %75
  %227 = phi i64 [ %7, %75 ], [ %105, %206 ], [ %105, %104 ]
  %228 = inttoptr i64 %227 to i64*
  ret i64* %228
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal21OrderedNameDictionary8SetEntryENS0_13InternalIndexENS0_6ObjectES3_NS0_15PropertyDetailsE(%"class.v8::internal::OrderedNameDictionary"* nocapture readonly, i64, i64, i64, i32) local_unnamed_addr #0 align 2 {
  %6 = trunc i64 %1 to i32
  %7 = getelementptr inbounds %"class.v8::internal::OrderedNameDictionary", %"class.v8::internal::OrderedNameDictionary"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %8 = load i64, i64* %7, align 8
  %9 = add i64 %8, 19
  %10 = inttoptr i64 %9 to i32*
  %11 = load atomic i32, i32* %10 monotonic, align 4
  %12 = lshr i32 %11, 1
  %13 = shl i32 %6, 2
  %14 = add i32 %13, 4
  %15 = add i32 %14, %12
  %16 = shl i32 %15, 2
  %17 = sext i32 %16 to i64
  %18 = add nsw i64 %17, 7
  %19 = add i64 %18, %8
  %20 = inttoptr i64 %19 to i32*
  %21 = trunc i64 %2 to i32
  store atomic volatile i32 %21, i32* %20 monotonic, align 4
  %22 = load i64, i64* %7, align 8
  %23 = add i64 %18, %22
  %24 = and i64 %2, 1
  %25 = icmp eq i64 %24, 0
  br i1 %25, label %57, label %26

26:                                               ; preds = %5
  %27 = and i64 %22, -262144
  %28 = or i64 %27, 8
  %29 = inttoptr i64 %28 to i64*
  %30 = load i64, i64* %29, align 8
  %31 = and i64 %30, 262144
  %32 = icmp eq i64 %31, 0
  br i1 %32, label %39, label %33

33:                                               ; preds = %26
  %34 = or i64 %27, 16
  %35 = inttoptr i64 %34 to %"class.v8::internal::Heap"**
  %36 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %35, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %36, i64 %22, i64 %23, i64 %2) #7
  %37 = load i64, i64* %7, align 8
  %38 = add i64 %37, %18
  br label %39

39:                                               ; preds = %33, %26
  %40 = phi i64 [ %23, %26 ], [ %38, %33 ]
  %41 = phi i64 [ %22, %26 ], [ %37, %33 ]
  %42 = and i64 %2, -262144
  %43 = or i64 %42, 8
  %44 = inttoptr i64 %43 to i64*
  %45 = load i64, i64* %44, align 8
  %46 = and i64 %45, 24
  %47 = icmp eq i64 %46, 0
  br i1 %47, label %57, label %48

48:                                               ; preds = %39
  %49 = and i64 %41, -262144
  %50 = or i64 %49, 8
  %51 = inttoptr i64 %50 to i64*
  %52 = load i64, i64* %51, align 8
  %53 = and i64 %52, 24
  %54 = icmp eq i64 %53, 0
  br i1 %54, label %55, label %57

55:                                               ; preds = %48
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %41, i64 %40, i64 %2) #7
  %56 = load i64, i64* %7, align 8
  br label %57

57:                                               ; preds = %5, %39, %48, %55
  %58 = phi i64 [ %22, %5 ], [ %41, %39 ], [ %41, %48 ], [ %56, %55 ]
  %59 = add i32 %16, 4
  %60 = sext i32 %59 to i64
  %61 = add nsw i64 %60, 7
  %62 = add i64 %58, %61
  %63 = inttoptr i64 %62 to i32*
  %64 = trunc i64 %3 to i32
  store atomic volatile i32 %64, i32* %63 monotonic, align 4
  %65 = load i64, i64* %7, align 8
  %66 = add i64 %65, %61
  %67 = and i64 %3, 1
  %68 = icmp eq i64 %67, 0
  br i1 %68, label %100, label %69

69:                                               ; preds = %57
  %70 = and i64 %65, -262144
  %71 = or i64 %70, 8
  %72 = inttoptr i64 %71 to i64*
  %73 = load i64, i64* %72, align 8
  %74 = and i64 %73, 262144
  %75 = icmp eq i64 %74, 0
  br i1 %75, label %82, label %76

76:                                               ; preds = %69
  %77 = or i64 %70, 16
  %78 = inttoptr i64 %77 to %"class.v8::internal::Heap"**
  %79 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %78, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %79, i64 %65, i64 %66, i64 %3) #7
  %80 = load i64, i64* %7, align 8
  %81 = add i64 %80, %61
  br label %82

82:                                               ; preds = %76, %69
  %83 = phi i64 [ %66, %69 ], [ %81, %76 ]
  %84 = phi i64 [ %65, %69 ], [ %80, %76 ]
  %85 = and i64 %3, -262144
  %86 = or i64 %85, 8
  %87 = inttoptr i64 %86 to i64*
  %88 = load i64, i64* %87, align 8
  %89 = and i64 %88, 24
  %90 = icmp eq i64 %89, 0
  br i1 %90, label %100, label %91

91:                                               ; preds = %82
  %92 = and i64 %84, -262144
  %93 = or i64 %92, 8
  %94 = inttoptr i64 %93 to i64*
  %95 = load i64, i64* %94, align 8
  %96 = and i64 %95, 24
  %97 = icmp eq i64 %96, 0
  br i1 %97, label %98, label %100

98:                                               ; preds = %91
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %84, i64 %83, i64 %3) #7
  %99 = load i64, i64* %7, align 8
  br label %100

100:                                              ; preds = %57, %82, %91, %98
  %101 = phi i64 [ %65, %57 ], [ %84, %82 ], [ %84, %91 ], [ %99, %98 ]
  %102 = shl i32 %4, 1
  %103 = add i32 %16, 8
  %104 = sext i32 %103 to i64
  %105 = add nsw i64 %104, 7
  %106 = add i64 %105, %101
  %107 = inttoptr i64 %106 to i32*
  store atomic volatile i32 %102, i32* %107 monotonic, align 4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden i64* @_ZN2v88internal21OrderedNameDictionary11DeleteEntryEPNS0_7IsolateENS0_6HandleIS1_EENS0_13InternalIndexE(%"class.v8::internal::Isolate"*, i64*, i64) local_unnamed_addr #0 align 2 {
  %4 = alloca %"class.v8::internal::Handle<v8::internal::OrderedNameDictionary>::ObjectRef", align 8
  %5 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 5
  %6 = load i64, i64* %5, align 8
  %7 = bitcast %"class.v8::internal::Handle<v8::internal::OrderedNameDictionary>::ObjectRef"* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %7) #7
  %8 = load i64, i64* %1, align 8
  %9 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::OrderedNameDictionary>::ObjectRef", %"class.v8::internal::Handle<v8::internal::OrderedNameDictionary>::ObjectRef"* %4, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %8, i64* %9, align 8
  %10 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::OrderedNameDictionary>::ObjectRef", %"class.v8::internal::Handle<v8::internal::OrderedNameDictionary>::ObjectRef"* %4, i64 0, i32 0
  call void @_ZN2v88internal21OrderedNameDictionary8SetEntryENS0_13InternalIndexENS0_6ObjectES3_NS0_15PropertyDetailsE(%"class.v8::internal::OrderedNameDictionary"* nonnull %10, i64 %2, i64 %6, i64 %6, i32 0)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %7) #7
  %11 = load i64, i64* %1, align 8
  %12 = add i64 %11, 11
  %13 = inttoptr i64 %12 to i32*
  %14 = load atomic i32, i32* %13 monotonic, align 4
  %15 = add i32 %14, -2
  %16 = and i32 %15, -2
  store atomic volatile i32 %16, i32* %13 monotonic, align 4
  %17 = load i64, i64* %1, align 8
  %18 = add i64 %17, 15
  %19 = inttoptr i64 %18 to i32*
  %20 = load atomic i32, i32* %19 monotonic, align 4
  %21 = add i32 %20, 2
  %22 = and i32 %21, -2
  store atomic volatile i32 %22, i32* %19 monotonic, align 4
  %23 = load i64, i64* %1, align 8
  %24 = add i64 %23, 11
  %25 = inttoptr i64 %24 to i32*
  %26 = load atomic i32, i32* %25 monotonic, align 4
  %27 = ashr i32 %26, 1
  %28 = add i64 %23, 19
  %29 = inttoptr i64 %28 to i32*
  %30 = load atomic i32, i32* %29 monotonic, align 4
  %31 = ashr i32 %30, 2
  %32 = icmp slt i32 %27, %31
  br i1 %32, label %33, label %48

33:                                               ; preds = %3
  %34 = and i32 %30, -2
  %35 = sdiv i32 %34, 2
  %36 = tail call i64* @_ZN2v88internal16OrderedHashTableINS0_21OrderedNameDictionaryELi3EE6RehashINS0_7IsolateEEENS0_11MaybeHandleIS2_EEPT_NS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"* %0, i64* %1, i32 %35) #7
  %37 = icmp eq i64* %36, null
  br i1 %37, label %38, label %39

38:                                               ; preds = %33
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.2, i64 0, i64 0)) #8
  unreachable

39:                                               ; preds = %33
  %40 = load i64, i64* %36, align 8
  %41 = load i64, i64* %1, align 8
  %42 = add i64 %41, 7
  %43 = inttoptr i64 %42 to i32*
  %44 = load atomic i32, i32* %43 monotonic, align 4
  %45 = and i32 %44, -2
  %46 = add i64 %40, 7
  %47 = inttoptr i64 %46 to i32*
  store atomic volatile i32 %45, i32* %47 monotonic, align 4
  br label %48

48:                                               ; preds = %3, %39
  %49 = phi i64* [ %36, %39 ], [ %1, %3 ]
  ret i64* %49
}

; Function Attrs: nounwind ssp uwtable
define hidden i64* @_ZN2v88internal14OrderedHashSet13AllocateEmptyEPNS0_7IsolateENS0_14AllocationTypeE(%"class.v8::internal::Isolate"*, i8 zeroext) local_unnamed_addr #0 align 2 {
  %3 = bitcast %"class.v8::internal::Isolate"* %0 to %"class.v8::internal::FactoryBase"*
  %4 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 55
  %5 = tail call i64* @_ZN2v88internal11FactoryBaseINS0_7FactoryEE20NewFixedArrayWithMapENS0_6HandleINS0_3MapEEEiNS0_14AllocationTypeE(%"class.v8::internal::FactoryBase"* %3, i64* %4, i32 3, i8 zeroext %1) #7
  %6 = load i64, i64* %5, align 8
  %7 = add i64 %6, 15
  %8 = inttoptr i64 %7 to i32*
  store atomic volatile i32 0, i32* %8 monotonic, align 4
  %9 = load i64, i64* %5, align 8
  %10 = add i64 %9, 7
  %11 = inttoptr i64 %10 to i32*
  store atomic volatile i32 0, i32* %11 monotonic, align 4
  %12 = load i64, i64* %5, align 8
  %13 = add i64 %12, 11
  %14 = inttoptr i64 %13 to i32*
  store atomic volatile i32 0, i32* %14 monotonic, align 4
  ret i64* %5
}

; Function Attrs: nounwind ssp uwtable
define hidden i64* @_ZN2v88internal14OrderedHashMap13AllocateEmptyEPNS0_7IsolateENS0_14AllocationTypeE(%"class.v8::internal::Isolate"*, i8 zeroext) local_unnamed_addr #0 align 2 {
  %3 = bitcast %"class.v8::internal::Isolate"* %0 to %"class.v8::internal::FactoryBase"*
  %4 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 54
  %5 = tail call i64* @_ZN2v88internal11FactoryBaseINS0_7FactoryEE20NewFixedArrayWithMapENS0_6HandleINS0_3MapEEEiNS0_14AllocationTypeE(%"class.v8::internal::FactoryBase"* %3, i64* %4, i32 3, i8 zeroext %1) #7
  %6 = load i64, i64* %5, align 8
  %7 = add i64 %6, 15
  %8 = inttoptr i64 %7 to i32*
  store atomic volatile i32 0, i32* %8 monotonic, align 4
  %9 = load i64, i64* %5, align 8
  %10 = add i64 %9, 7
  %11 = inttoptr i64 %10 to i32*
  store atomic volatile i32 0, i32* %11 monotonic, align 4
  %12 = load i64, i64* %5, align 8
  %13 = add i64 %12, 11
  %14 = inttoptr i64 %13 to i32*
  store atomic volatile i32 0, i32* %14 monotonic, align 4
  ret i64* %5
}

; Function Attrs: nounwind ssp uwtable
define hidden i64* @_ZN2v88internal21OrderedNameDictionary13AllocateEmptyEPNS0_7IsolateENS0_14AllocationTypeE(%"class.v8::internal::Isolate"*, i8 zeroext) local_unnamed_addr #0 align 2 {
  %3 = bitcast %"class.v8::internal::Isolate"* %0 to %"class.v8::internal::FactoryBase"*
  %4 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 56
  %5 = tail call i64* @_ZN2v88internal11FactoryBaseINS0_7FactoryEE20NewFixedArrayWithMapENS0_6HandleINS0_3MapEEEiNS0_14AllocationTypeE(%"class.v8::internal::FactoryBase"* %3, i64* %4, i32 4, i8 zeroext %1) #7
  %6 = load i64, i64* %5, align 8
  %7 = add i64 %6, 19
  %8 = inttoptr i64 %7 to i32*
  store atomic volatile i32 0, i32* %8 monotonic, align 4
  %9 = load i64, i64* %5, align 8
  %10 = add i64 %9, 11
  %11 = inttoptr i64 %10 to i32*
  store atomic volatile i32 0, i32* %11 monotonic, align 4
  %12 = load i64, i64* %5, align 8
  %13 = add i64 %12, 15
  %14 = inttoptr i64 %13 to i32*
  store atomic volatile i32 0, i32* %14 monotonic, align 4
  %15 = icmp eq i64* %5, null
  br i1 %15, label %20, label %16

16:                                               ; preds = %2
  %17 = load i64, i64* %5, align 8
  %18 = add i64 %17, 7
  %19 = inttoptr i64 %18 to i32*
  store atomic volatile i32 0, i32* %19 monotonic, align 4
  br label %20

20:                                               ; preds = %2, %16
  ret i64* %5
}

declare i64* @_ZN2v88internal7Factory22NewSmallOrderedHashSetEiNS0_14AllocationTypeE(%"class.v8::internal::Factory"*, i32, i8 zeroext) local_unnamed_addr #2

declare i64* @_ZN2v88internal7Factory22NewSmallOrderedHashMapEiNS0_14AllocationTypeE(%"class.v8::internal::Factory"*, i32, i8 zeroext) local_unnamed_addr #2

declare i64* @_ZN2v88internal7Factory29NewSmallOrderedNameDictionaryEiNS0_14AllocationTypeE(%"class.v8::internal::Factory"*, i32, i8 zeroext) local_unnamed_addr #2

; Function Attrs: nounwind ssp uwtable
define hidden i64* @_ZN2v88internal19SmallOrderedHashSet3AddEPNS0_7IsolateENS0_6HandleIS1_EENS4_INS0_6ObjectEEE(%"class.v8::internal::Isolate"*, i64*, i64*) local_unnamed_addr #0 align 2 {
  %4 = alloca %"class.v8::internal::Handle<v8::internal::SmallOrderedHashSet>::ObjectRef", align 8
  %5 = alloca %"class.v8::internal::Handle<v8::internal::Object>::ObjectRef", align 8
  %6 = ptrtoint i64* %1 to i64
  %7 = bitcast %"class.v8::internal::Handle<v8::internal::SmallOrderedHashSet>::ObjectRef"* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %7) #7
  %8 = load i64, i64* %1, align 8
  %9 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::SmallOrderedHashSet>::ObjectRef", %"class.v8::internal::Handle<v8::internal::SmallOrderedHashSet>::ObjectRef"* %4, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %8, i64* %9, align 8
  %10 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::SmallOrderedHashSet>::ObjectRef", %"class.v8::internal::Handle<v8::internal::SmallOrderedHashSet>::ObjectRef"* %4, i64 0, i32 0, i32 0
  %11 = load i64, i64* %2, align 8
  %12 = call i64 @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashSetEE9FindEntryEPNS0_7IsolateENS0_6ObjectE(%"class.v8::internal::SmallOrderedHashTable"* nonnull %10, %"class.v8::internal::Isolate"* %0, i64 %11) #7
  %13 = icmp eq i64 %12, -1
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %7) #7
  br i1 %13, label %14, label %140

14:                                               ; preds = %3
  %15 = load i64, i64* %1, align 8
  %16 = add i64 %15, 3
  %17 = inttoptr i64 %16 to i8*
  %18 = load i8, i8* %17, align 1
  %19 = zext i8 %18 to i32
  %20 = add i64 %15, 4
  %21 = inttoptr i64 %20 to i8*
  %22 = load i8, i8* %21, align 1
  %23 = zext i8 %22 to i32
  %24 = add nuw nsw i32 %23, %19
  %25 = add i64 %15, 5
  %26 = inttoptr i64 %25 to i8*
  %27 = load i8, i8* %26, align 1
  %28 = zext i8 %27 to i32
  %29 = shl nuw nsw i32 %28, 1
  %30 = icmp ult i32 %24, %29
  br i1 %30, label %44, label %31

31:                                               ; preds = %14
  %32 = icmp ult i8 %22, %27
  br i1 %32, label %33, label %38

33:                                               ; preds = %31
  %34 = shl nuw nsw i32 %28, 2
  %35 = icmp eq i8 %27, 64
  %36 = select i1 %35, i32 254, i32 %34
  %37 = icmp ugt i32 %36, 254
  br i1 %37, label %140, label %38

38:                                               ; preds = %31, %33
  %39 = phi i32 [ %36, %33 ], [ %29, %31 ]
  %40 = call i64* @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashSetEE6RehashEPNS0_7IsolateENS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"* %0, i64* %1, i32 %39) #7
  %41 = icmp eq i64* %40, null
  br i1 %41, label %140, label %42

42:                                               ; preds = %38
  %43 = ptrtoint i64* %40 to i64
  br label %44

44:                                               ; preds = %42, %14
  %45 = phi i64 [ %6, %14 ], [ %43, %42 ]
  %46 = bitcast %"class.v8::internal::Handle<v8::internal::Object>::ObjectRef"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %46) #7
  %47 = load i64, i64* %2, align 8
  %48 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::Object>::ObjectRef", %"class.v8::internal::Handle<v8::internal::Object>::ObjectRef"* %5, i64 0, i32 0, i32 0, i32 0
  store i64 %47, i64* %48, align 8
  %49 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::Object>::ObjectRef", %"class.v8::internal::Handle<v8::internal::Object>::ObjectRef"* %5, i64 0, i32 0
  %50 = call i64 @_ZN2v88internal6Object15GetOrCreateHashEPNS0_7IsolateE(%"class.v8::internal::Object"* nonnull %49, %"class.v8::internal::Isolate"* %0) #7
  %51 = trunc i64 %50 to i32
  %52 = ashr i32 %51, 1
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %46) #7
  %53 = inttoptr i64 %45 to i64*
  %54 = load i64, i64* %53, align 8
  %55 = add i64 %54, 3
  %56 = inttoptr i64 %55 to i8*
  %57 = load i8, i8* %56, align 1
  %58 = zext i8 %57 to i32
  %59 = add i64 %54, 5
  %60 = inttoptr i64 %59 to i8*
  %61 = load i8, i8* %60, align 1
  %62 = zext i8 %61 to i32
  %63 = add nsw i32 %62, -1
  %64 = and i32 %63, %52
  %65 = shl nuw nsw i32 %62, 3
  %66 = add nsw i32 %64, 8
  %67 = add i32 %66, %65
  %68 = sext i32 %67 to i64
  %69 = add i64 %54, -1
  %70 = add i64 %69, %68
  %71 = inttoptr i64 %70 to i8*
  %72 = load i8, i8* %71, align 1
  %73 = add i64 %54, 4
  %74 = inttoptr i64 %73 to i8*
  %75 = load i8, i8* %74, align 1
  %76 = zext i8 %75 to i32
  %77 = add nuw nsw i32 %76, %58
  %78 = load i64, i64* %2, align 8
  %79 = shl nuw nsw i32 %77, 2
  %80 = add nuw nsw i32 %79, 7
  %81 = zext i32 %80 to i64
  %82 = add i64 %54, %81
  %83 = inttoptr i64 %82 to i32*
  %84 = trunc i64 %78 to i32
  store atomic volatile i32 %84, i32* %83 monotonic, align 4
  %85 = and i64 %78, 1
  %86 = icmp eq i64 %85, 0
  br i1 %86, label %110, label %87

87:                                               ; preds = %44
  %88 = and i64 %54, -262144
  %89 = or i64 %88, 8
  %90 = inttoptr i64 %89 to i64*
  %91 = load i64, i64* %90, align 8
  %92 = and i64 %91, 262144
  %93 = icmp eq i64 %92, 0
  br i1 %93, label %98, label %94

94:                                               ; preds = %87
  %95 = or i64 %88, 16
  %96 = inttoptr i64 %95 to %"class.v8::internal::Heap"**
  %97 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %96, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %97, i64 %54, i64 %82, i64 %78) #7
  br label %98

98:                                               ; preds = %94, %87
  %99 = and i64 %78, -262144
  %100 = or i64 %99, 8
  %101 = inttoptr i64 %100 to i64*
  %102 = load i64, i64* %101, align 8
  %103 = and i64 %102, 24
  %104 = icmp eq i64 %103, 0
  br i1 %104, label %110, label %105

105:                                              ; preds = %98
  %106 = load i64, i64* %90, align 8
  %107 = and i64 %106, 24
  %108 = icmp eq i64 %107, 0
  br i1 %108, label %109, label %110

109:                                              ; preds = %105
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %54, i64 %82, i64 %78) #7
  br label %110

110:                                              ; preds = %44, %98, %105, %109
  %111 = load i64, i64* %53, align 8
  %112 = trunc i32 %77 to i8
  %113 = add i64 %111, 5
  %114 = inttoptr i64 %113 to i8*
  %115 = load i8, i8* %114, align 1
  %116 = zext i8 %115 to i32
  %117 = shl nuw nsw i32 %116, 3
  %118 = add i32 %66, %117
  %119 = sext i32 %118 to i64
  %120 = add i64 %111, -1
  %121 = add i64 %120, %119
  %122 = inttoptr i64 %121 to i8*
  store i8 %112, i8* %122, align 1
  %123 = load i64, i64* %53, align 8
  %124 = add i64 %123, 5
  %125 = inttoptr i64 %124 to i8*
  %126 = load i8, i8* %125, align 1
  %127 = zext i8 %126 to i32
  %128 = shl nuw nsw i32 %127, 3
  %129 = add nuw nsw i32 %77, 8
  %130 = add nuw nsw i32 %129, %127
  %131 = add nuw nsw i32 %130, %128
  %132 = zext i32 %131 to i64
  %133 = add i64 %123, -1
  %134 = add i64 %133, %132
  %135 = inttoptr i64 %134 to i8*
  store i8 %72, i8* %135, align 1
  %136 = load i64, i64* %53, align 8
  %137 = add i8 %57, 1
  %138 = add i64 %136, 3
  %139 = inttoptr i64 %138 to i8*
  store i8 %137, i8* %139, align 1
  br label %140

140:                                              ; preds = %3, %33, %38, %110
  %141 = phi i64 [ %45, %110 ], [ %6, %3 ], [ 0, %38 ], [ 0, %33 ]
  %142 = inttoptr i64 %141 to i64*
  ret i64* %142
}

; Function Attrs: nounwind ssp uwtable
define hidden i64* @_ZN2v88internal19SmallOrderedHashMap3AddEPNS0_7IsolateENS0_6HandleIS1_EENS4_INS0_6ObjectEEES7_(%"class.v8::internal::Isolate"*, i64*, i64*, i64*) local_unnamed_addr #0 align 2 {
  %5 = alloca %"class.v8::internal::Handle<v8::internal::SmallOrderedHashMap>::ObjectRef", align 8
  %6 = alloca %"class.v8::internal::Handle<v8::internal::Object>::ObjectRef", align 8
  %7 = ptrtoint i64* %1 to i64
  %8 = bitcast %"class.v8::internal::Handle<v8::internal::SmallOrderedHashMap>::ObjectRef"* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %8) #7
  %9 = load i64, i64* %1, align 8
  %10 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::SmallOrderedHashMap>::ObjectRef", %"class.v8::internal::Handle<v8::internal::SmallOrderedHashMap>::ObjectRef"* %5, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %9, i64* %10, align 8
  %11 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::SmallOrderedHashMap>::ObjectRef", %"class.v8::internal::Handle<v8::internal::SmallOrderedHashMap>::ObjectRef"* %5, i64 0, i32 0, i32 0
  %12 = load i64, i64* %2, align 8
  %13 = call i64 @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashMapEE9FindEntryEPNS0_7IsolateENS0_6ObjectE(%"class.v8::internal::SmallOrderedHashTable.1143"* nonnull %11, %"class.v8::internal::Isolate"* %0, i64 %12) #7
  %14 = icmp eq i64 %13, -1
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %8) #7
  br i1 %14, label %15, label %175

15:                                               ; preds = %4
  %16 = load i64, i64* %1, align 8
  %17 = add i64 %16, 3
  %18 = inttoptr i64 %17 to i8*
  %19 = load i8, i8* %18, align 1
  %20 = zext i8 %19 to i32
  %21 = add i64 %16, 4
  %22 = inttoptr i64 %21 to i8*
  %23 = load i8, i8* %22, align 1
  %24 = zext i8 %23 to i32
  %25 = add nuw nsw i32 %24, %20
  %26 = add i64 %16, 5
  %27 = inttoptr i64 %26 to i8*
  %28 = load i8, i8* %27, align 1
  %29 = zext i8 %28 to i32
  %30 = shl nuw nsw i32 %29, 1
  %31 = icmp ult i32 %25, %30
  br i1 %31, label %45, label %32

32:                                               ; preds = %15
  %33 = icmp ult i8 %23, %28
  br i1 %33, label %34, label %39

34:                                               ; preds = %32
  %35 = shl nuw nsw i32 %29, 2
  %36 = icmp eq i8 %28, 64
  %37 = select i1 %36, i32 254, i32 %35
  %38 = icmp ugt i32 %37, 254
  br i1 %38, label %175, label %39

39:                                               ; preds = %32, %34
  %40 = phi i32 [ %37, %34 ], [ %30, %32 ]
  %41 = call i64* @_ZN2v88internal21SmallOrderedHashTableINS0_19SmallOrderedHashMapEE6RehashEPNS0_7IsolateENS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"* %0, i64* %1, i32 %40) #7
  %42 = icmp eq i64* %41, null
  br i1 %42, label %175, label %43

43:                                               ; preds = %39
  %44 = ptrtoint i64* %41 to i64
  br label %45

45:                                               ; preds = %43, %15
  %46 = phi i64 [ %7, %15 ], [ %44, %43 ]
  %47 = bitcast %"class.v8::internal::Handle<v8::internal::Object>::ObjectRef"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %47) #7
  %48 = load i64, i64* %2, align 8
  %49 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::Object>::ObjectRef", %"class.v8::internal::Handle<v8::internal::Object>::ObjectRef"* %6, i64 0, i32 0, i32 0, i32 0
  store i64 %48, i64* %49, align 8
  %50 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::Object>::ObjectRef", %"class.v8::internal::Handle<v8::internal::Object>::ObjectRef"* %6, i64 0, i32 0
  %51 = call i64 @_ZN2v88internal6Object15GetOrCreateHashEPNS0_7IsolateE(%"class.v8::internal::Object"* nonnull %50, %"class.v8::internal::Isolate"* %0) #7
  %52 = trunc i64 %51 to i32
  %53 = ashr i32 %52, 1
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %47) #7
  %54 = inttoptr i64 %46 to i64*
  %55 = load i64, i64* %54, align 8
  %56 = add i64 %55, 3
  %57 = inttoptr i64 %56 to i8*
  %58 = load i8, i8* %57, align 1
  %59 = zext i8 %58 to i32
  %60 = add i64 %55, 5
  %61 = inttoptr i64 %60 to i8*
  %62 = load i8, i8* %61, align 1
  %63 = zext i8 %62 to i32
  %64 = add nsw i32 %63, -1
  %65 = and i32 %64, %53
  %66 = shl nuw nsw i32 %63, 4
  %67 = or i32 %66, 8
  %68 = add nsw i32 %67, %65
  %69 = sext i32 %68 to i64
  %70 = add i64 %55, -1
  %71 = add i64 %70, %69
  %72 = inttoptr i64 %71 to i8*
  %73 = load i8, i8* %72, align 1
  %74 = add i64 %55, 4
  %75 = inttoptr i64 %74 to i8*
  %76 = load i8, i8* %75, align 1
  %77 = zext i8 %76 to i32
  %78 = add nuw nsw i32 %77, %59
  %79 = load i64, i64* %3, align 8
  %80 = shl nuw nsw i32 %78, 3
  %81 = add nuw nsw i32 %80, 11
  %82 = zext i32 %81 to i64
  %83 = add i64 %55, %82
  %84 = inttoptr i64 %83 to i32*
  %85 = trunc i64 %79 to i32
  store atomic volatile i32 %85, i32* %84 monotonic, align 4
  %86 = and i64 %79, 1
  %87 = icmp eq i64 %86, 0
  br i1 %87, label %111, label %88

88:                                               ; preds = %45
  %89 = and i64 %55, -262144
  %90 = or i64 %89, 8
  %91 = inttoptr i64 %90 to i64*
  %92 = load i64, i64* %91, align 8
  %93 = and i64 %92, 262144
  %94 = icmp eq i64 %93, 0
  br i1 %94, label %99, label %95

95:                                               ; preds = %88
  %96 = or i64 %89, 16
  %97 = inttoptr i64 %96 to %"class.v8::internal::Heap"**
  %98 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %97, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %98, i64 %55, i64 %83, i64 %79) #7
  br label %99

99:                                               ; preds = %95, %88
  %100 = and i64 %79, -262144
  %101 = or i64 %100, 8
  %102 = inttoptr i64 %101 to i64*
  %103 = load i64, i64* %102, align 8
  %104 = and i64 %103, 24
  %105 = icmp eq i64 %104, 0
  br i1 %105, label %111, label %106

106:                                              ; preds = %99
  %107 = load i64, i64* %91, align 8
  %108 = and i64 %107, 24
  %109 = icmp eq i64 %108, 0
  br i1 %109, label %110, label %111

110:                                              ; preds = %106
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %55, i64 %83, i64 %79) #7
  br label %111

111:                                              ; preds = %45, %99, %106, %110
  %112 = load i64, i64* %54, align 8
  %113 = load i64, i64* %2, align 8
  %114 = or i32 %80, 7
  %115 = zext i32 %114 to i64
  %116 = add i64 %112, %115
  %117 = inttoptr i64 %116 to i32*
  %118 = trunc i64 %113 to i32
  store atomic volatile i32 %118, i32* %117 monotonic, align 4
  %119 = and i64 %113, 1
  %120 = icmp eq i64 %119, 0
  br i1 %120, label %144, label %121

121:                                              ; preds = %111
  %122 = and i64 %112, -262144
  %123 = or i64 %122, 8
  %124 = inttoptr i64 %123 to i64*
  %125 = load i64, i64* %124, align 8
  %126 = and i64 %125, 262144
  %127 = icmp eq i64 %126, 0
  br i1 %127, label %132, label %128

128:                                              ; preds = %121
  %129 = or i64 %122, 16
  %130 = inttoptr i64 %129 to %"class.v8::internal::Heap"**
  %131 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %130, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %131, i64 %112, i64 %116, i64 %113) #7
  br label %132

132:                                              ; preds = %128, %121
  %133 = and i64 %113, -262144
  %134 = or i64 %133, 8
  %135 = inttoptr i64 %134 to i64*
  %136 = load i64, i64* %135, align 8
  %137 = and i64 %136, 24
  %138 = icmp eq i64 %137, 0
  br i1 %138, label %144, label %139

139:                                              ; preds = %132
  %140 = load i64, i64* %124, align 8
  %141 = and i64 %140, 24
  %142 = icmp eq i64 %141, 0
  br i1 %142, label %143, label %144

143:                                              ; preds = %139
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %112, i64 %116, i64 %113) #7
  br label %144

144:                                              ; preds = %111, %132, %139, %143
  %145 = load i64, i64* %54, align 8
  %146 = trunc i32 %78 to i8
  %147 = add i64 %145, 5
  %148 = inttoptr i64 %147 to i8*
  %149 = load i8, i8* %148, align 1
  %150 = zext i8 %149 to i32
  %151 = shl nuw nsw i32 %150, 4
  %152 = or i32 %151, 8
  %153 = add nsw i32 %152, %65
  %154 = sext i32 %153 to i64
  %155 = add i64 %145, -1
  %156 = add i64 %155, %154
  %157 = inttoptr i64 %156 to i8*
  store i8 %146, i8* %157, align 1
  %158 = load i64, i64* %54, align 8
  %159 = add i64 %158, 5
  %160 = inttoptr i64 %159 to i8*
  %161 = load i8, i8* %160, align 1
  %162 = zext i8 %161 to i32
  %163 = shl nuw nsw i32 %162, 4
  %164 = or i32 %163, 8
  %165 = add nuw nsw i32 %78, %162
  %166 = add nuw nsw i32 %165, %164
  %167 = zext i32 %166 to i64
  %168 = add i64 %158, -1
  %169 = add i64 %168, %167
  %170 = inttoptr i64 %169 to i8*
  store i8 %73, i8* %170, align 1
  %171 = load i64, i64* %54, align 8
  %172 = add i8 %58, 1
  %173 = add i64 %171, 3
  %174 = inttoptr i64 %173 to i8*
  store i8 %172, i8* %174, align 1
  br label %175

175:                                              ; preds = %4, %34, %39, %144
  %176 = phi i64 [ %46, %144 ], [ %7, %4 ], [ 0, %39 ], [ 0, %34 ]
  %177 = inttoptr i64 %176 to i64*
  ret i64* %177
}

; Function Attrs: nounwind readonly ssp uwtable
define hidden i64 @_ZN2v88internal21SmallOrderedHashTableINS0_26SmallOrderedNameDictionaryEE9FindEntryEPNS0_7IsolateENS0_6ObjectE(%"class.v8::internal::SmallOrderedHashTable.1146"* nocapture readonly, %"class.v8::internal::Isolate"* nocapture readnone, i64) local_unnamed_addr #6 align 2 {
  %4 = add i64 %2, 3
  %5 = inttoptr i64 %4 to i32*
  %6 = load i32, i32* %5, align 4
  %7 = lshr i32 %6, 2
  %8 = getelementptr inbounds %"class.v8::internal::SmallOrderedHashTable.1146", %"class.v8::internal::SmallOrderedHashTable.1146"* %0, i64 0, i32 0, i32 0, i32 0, i32 0
  %9 = load i64, i64* %8, align 8
  %10 = add i64 %9, 9
  %11 = inttoptr i64 %10 to i8*
  %12 = load i8, i8* %11, align 1
  %13 = zext i8 %12 to i32
  %14 = add nuw nsw i32 %13, 1073741823
  %15 = and i32 %14, %7
  %16 = mul nuw nsw i32 %13, 24
  %17 = add nuw nsw i32 %16, 12
  %18 = add nuw nsw i32 %17, %15
  %19 = add i64 %9, -1
  %20 = zext i32 %18 to i64
  %21 = add i64 %19, %20
  %22 = inttoptr i64 %21 to i8*
  %23 = load i8, i8* %22, align 1
  %24 = icmp eq i8 %23, -1
  br i1 %24, label %46, label %25

25:                                               ; preds = %3
  %26 = trunc i64 %2 to i32
  %27 = add nuw nsw i32 %17, %13
  br label %28

28:                                               ; preds = %25, %38
  %29 = phi i8 [ %23, %25 ], [ %44, %38 ]
  %30 = zext i8 %29 to i64
  %31 = mul nuw nsw i64 %30, 51539607552
  %32 = add nuw nsw i64 %31, 51539607552
  %33 = lshr exact i64 %32, 32
  %34 = add i64 %19, %33
  %35 = inttoptr i64 %34 to i32*
  %36 = load i32, i32* %35, align 4
  %37 = icmp eq i32 %36, %26
  br i1 %37, label %46, label %38

38:                                               ; preds = %28
  %39 = zext i8 %29 to i32
  %40 = add nuw nsw i32 %27, %39
  %41 = zext i32 %40 to i64
  %42 = add i64 %19, %41
  %43 = inttoptr i64 %42 to i8*
  %44 = load i8, i8* %43, align 1
  %45 = icmp eq i8 %44, -1
  br i1 %45, label %46, label %28

46:                                               ; preds = %38, %28, %3
  %47 = phi i64 [ -1, %3 ], [ %30, %28 ], [ -1, %38 ]
  ret i64 %47
}

; Function Attrs: nounwind ssp uwtable
define hidden i64* @_ZN2v88internal26SmallOrderedNameDictionary3AddEPNS0_7IsolateENS0_6HandleIS1_EENS4_INS0_4NameEEENS4_INS0_6ObjectEEENS0_15PropertyDetailsE(%"class.v8::internal::Isolate"*, i64*, i64*, i64*, i32) local_unnamed_addr #0 align 2 {
  %6 = load i64, i64* %1, align 8
  %7 = add i64 %6, 7
  %8 = inttoptr i64 %7 to i8*
  %9 = load i8, i8* %8, align 1
  %10 = zext i8 %9 to i32
  %11 = add i64 %6, 8
  %12 = inttoptr i64 %11 to i8*
  %13 = load i8, i8* %12, align 1
  %14 = zext i8 %13 to i32
  %15 = add nuw nsw i32 %14, %10
  %16 = add i64 %6, 9
  %17 = inttoptr i64 %16 to i8*
  %18 = load i8, i8* %17, align 1
  %19 = zext i8 %18 to i32
  %20 = shl nuw nsw i32 %19, 1
  %21 = icmp ult i32 %15, %20
  br i1 %21, label %48, label %22

22:                                               ; preds = %5
  %23 = icmp ult i8 %13, %18
  br i1 %23, label %24, label %29

24:                                               ; preds = %22
  %25 = shl nuw nsw i32 %19, 2
  %26 = icmp eq i8 %18, 64
  %27 = select i1 %26, i32 254, i32 %25
  %28 = icmp ugt i32 %27, 254
  br i1 %28, label %177, label %29

29:                                               ; preds = %22, %24
  %30 = phi i32 [ %27, %24 ], [ %20, %22 ]
  %31 = tail call i64* @_ZN2v88internal21SmallOrderedHashTableINS0_26SmallOrderedNameDictionaryEE6RehashEPNS0_7IsolateENS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"* %0, i64* %1, i32 %30) #7
  %32 = load i64, i64* %31, align 8
  %33 = load i64, i64* %1, align 8
  %34 = add i64 %33, 3
  %35 = inttoptr i64 %34 to i32*
  %36 = load i32, i32* %35, align 4
  %37 = add i64 %32, 3
  %38 = inttoptr i64 %37 to i32*
  store i32 %36, i32* %38, align 4
  %39 = icmp eq i64* %31, null
  br i1 %39, label %177, label %40

40:                                               ; preds = %29
  %41 = load i64, i64* %31, align 8
  %42 = add i64 %41, 7
  %43 = inttoptr i64 %42 to i8*
  %44 = add i64 %41, 9
  %45 = inttoptr i64 %44 to i8*
  %46 = add i64 %41, 8
  %47 = inttoptr i64 %46 to i8*
  br label %48

48:                                               ; preds = %40, %5
  %49 = phi i8* [ %47, %40 ], [ %12, %5 ]
  %50 = phi i8* [ %45, %40 ], [ %17, %5 ]
  %51 = phi i8* [ %43, %40 ], [ %8, %5 ]
  %52 = phi i64 [ %41, %40 ], [ %6, %5 ]
  %53 = phi i64* [ %31, %40 ], [ %1, %5 ]
  %54 = load i8, i8* %51, align 1
  %55 = zext i8 %54 to i32
  %56 = load i64, i64* %2, align 8
  %57 = add i64 %56, 3
  %58 = inttoptr i64 %57 to i32*
  %59 = load i32, i32* %58, align 4
  %60 = lshr i32 %59, 2
  %61 = load i8, i8* %50, align 1
  %62 = zext i8 %61 to i32
  %63 = add nuw nsw i32 %62, 1073741823
  %64 = and i32 %63, %60
  %65 = mul nuw nsw i32 %62, 24
  %66 = add nuw nsw i32 %64, 12
  %67 = add nuw nsw i32 %66, %65
  %68 = zext i32 %67 to i64
  %69 = add i64 %52, -1
  %70 = add i64 %69, %68
  %71 = inttoptr i64 %70 to i8*
  %72 = load i8, i8* %71, align 1
  %73 = load i8, i8* %49, align 1
  %74 = zext i8 %73 to i32
  %75 = add nuw nsw i32 %74, %55
  %76 = load i64, i64* %3, align 8
  %77 = mul nuw nsw i32 %75, 12
  %78 = add nuw nsw i32 %77, 15
  %79 = zext i32 %78 to i64
  %80 = add i64 %52, %79
  %81 = inttoptr i64 %80 to i32*
  %82 = trunc i64 %76 to i32
  store atomic volatile i32 %82, i32* %81 monotonic, align 4
  %83 = and i64 %76, 1
  %84 = icmp eq i64 %83, 0
  br i1 %84, label %108, label %85

85:                                               ; preds = %48
  %86 = and i64 %52, -262144
  %87 = or i64 %86, 8
  %88 = inttoptr i64 %87 to i64*
  %89 = load i64, i64* %88, align 8
  %90 = and i64 %89, 262144
  %91 = icmp eq i64 %90, 0
  br i1 %91, label %96, label %92

92:                                               ; preds = %85
  %93 = or i64 %86, 16
  %94 = inttoptr i64 %93 to %"class.v8::internal::Heap"**
  %95 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %94, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %95, i64 %52, i64 %80, i64 %76) #7
  br label %96

96:                                               ; preds = %92, %85
  %97 = and i64 %76, -262144
  %98 = or i64 %97, 8
  %99 = inttoptr i64 %98 to i64*
  %100 = load i64, i64* %99, align 8
  %101 = and i64 %100, 24
  %102 = icmp eq i64 %101, 0
  br i1 %102, label %108, label %103

103:                                              ; preds = %96
  %104 = load i64, i64* %88, align 8
  %105 = and i64 %104, 24
  %106 = icmp eq i64 %105, 0
  br i1 %106, label %107, label %108

107:                                              ; preds = %103
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %52, i64 %80, i64 %76) #7
  br label %108

108:                                              ; preds = %48, %96, %103, %107
  %109 = load i64, i64* %53, align 8
  %110 = load i64, i64* %2, align 8
  %111 = add nuw nsw i32 %77, 11
  %112 = zext i32 %111 to i64
  %113 = add i64 %109, %112
  %114 = inttoptr i64 %113 to i32*
  %115 = trunc i64 %110 to i32
  store atomic volatile i32 %115, i32* %114 monotonic, align 4
  %116 = and i64 %110, 1
  %117 = icmp eq i64 %116, 0
  br i1 %117, label %141, label %118

118:                                              ; preds = %108
  %119 = and i64 %109, -262144
  %120 = or i64 %119, 8
  %121 = inttoptr i64 %120 to i64*
  %122 = load i64, i64* %121, align 8
  %123 = and i64 %122, 262144
  %124 = icmp eq i64 %123, 0
  br i1 %124, label %129, label %125

125:                                              ; preds = %118
  %126 = or i64 %119, 16
  %127 = inttoptr i64 %126 to %"class.v8::internal::Heap"**
  %128 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %127, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %128, i64 %109, i64 %113, i64 %110) #7
  br label %129

129:                                              ; preds = %125, %118
  %130 = and i64 %110, -262144
  %131 = or i64 %130, 8
  %132 = inttoptr i64 %131 to i64*
  %133 = load i64, i64* %132, align 8
  %134 = and i64 %133, 24
  %135 = icmp eq i64 %134, 0
  br i1 %135, label %141, label %136

136:                                              ; preds = %129
  %137 = load i64, i64* %121, align 8
  %138 = and i64 %137, 24
  %139 = icmp eq i64 %138, 0
  br i1 %139, label %140, label %141

140:                                              ; preds = %136
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %109, i64 %113, i64 %110) #7
  br label %141

141:                                              ; preds = %140, %136, %129, %108
  %142 = load i64, i64* %53, align 8
  %143 = shl i32 %4, 1
  %144 = add nuw nsw i32 %77, 19
  %145 = zext i32 %144 to i64
  %146 = add i64 %142, %145
  %147 = inttoptr i64 %146 to i32*
  store atomic volatile i32 %143, i32* %147 monotonic, align 4
  %148 = load i64, i64* %53, align 8
  %149 = trunc i32 %75 to i8
  %150 = add i64 %148, 9
  %151 = inttoptr i64 %150 to i8*
  %152 = load i8, i8* %151, align 1
  %153 = zext i8 %152 to i32
  %154 = mul nuw nsw i32 %153, 24
  %155 = add nuw nsw i32 %66, %154
  %156 = zext i32 %155 to i64
  %157 = add i64 %148, -1
  %158 = add i64 %157, %156
  %159 = inttoptr i64 %158 to i8*
  store i8 %149, i8* %159, align 1
  %160 = load i64, i64* %53, align 8
  %161 = add i64 %160, 9
  %162 = inttoptr i64 %161 to i8*
  %163 = load i8, i8* %162, align 1
  %164 = zext i8 %163 to i32
  %165 = mul nuw nsw i32 %164, 24
  %166 = add nuw nsw i32 %75, 12
  %167 = add nuw nsw i32 %166, %164
  %168 = add nuw nsw i32 %167, %165
  %169 = zext i32 %168 to i64
  %170 = add i64 %160, -1
  %171 = add i64 %170, %169
  %172 = inttoptr i64 %171 to i8*
  store i8 %72, i8* %172, align 1
  %173 = load i64, i64* %53, align 8
  %174 = add i8 %54, 1
  %175 = add i64 %173, 7
  %176 = inttoptr i64 %175 to i8*
  store i8 %174, i8* %176, align 1
  br label %177

177:                                              ; preds = %24, %29, %141
  %178 = phi i64* [ %53, %141 ], [ null, %29 ], [ null, %24 ]
  ret i64* %178
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal26SmallOrderedNameDictionary8SetEntryENS0_13InternalIndexENS0_6ObjectES3_NS0_15PropertyDetailsE(%"class.v8::internal::SmallOrderedNameDictionary"* nocapture readonly, i64, i64, i64, i32) local_unnamed_addr #0 align 2 {
  %6 = getelementptr inbounds %"class.v8::internal::SmallOrderedNameDictionary", %"class.v8::internal::SmallOrderedNameDictionary"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
  %7 = load i64, i64* %6, align 8
  %8 = mul i64 %1, 51539607552
  %9 = ashr exact i64 %8, 32
  %10 = add nsw i64 %9, 15
  %11 = add i64 %7, %10
  %12 = inttoptr i64 %11 to i32*
  %13 = trunc i64 %3 to i32
  store atomic volatile i32 %13, i32* %12 monotonic, align 4
  %14 = load i64, i64* %6, align 8
  %15 = add i64 %14, %10
  %16 = and i64 %3, 1
  %17 = icmp eq i64 %16, 0
  br i1 %17, label %49, label %18

18:                                               ; preds = %5
  %19 = and i64 %14, -262144
  %20 = or i64 %19, 8
  %21 = inttoptr i64 %20 to i64*
  %22 = load i64, i64* %21, align 8
  %23 = and i64 %22, 262144
  %24 = icmp eq i64 %23, 0
  br i1 %24, label %31, label %25

25:                                               ; preds = %18
  %26 = or i64 %19, 16
  %27 = inttoptr i64 %26 to %"class.v8::internal::Heap"**
  %28 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %27, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %28, i64 %14, i64 %15, i64 %3) #7
  %29 = load i64, i64* %6, align 8
  %30 = add i64 %29, %10
  br label %31

31:                                               ; preds = %25, %18
  %32 = phi i64 [ %15, %18 ], [ %30, %25 ]
  %33 = phi i64 [ %14, %18 ], [ %29, %25 ]
  %34 = and i64 %3, -262144
  %35 = or i64 %34, 8
  %36 = inttoptr i64 %35 to i64*
  %37 = load i64, i64* %36, align 8
  %38 = and i64 %37, 24
  %39 = icmp eq i64 %38, 0
  br i1 %39, label %49, label %40

40:                                               ; preds = %31
  %41 = and i64 %33, -262144
  %42 = or i64 %41, 8
  %43 = inttoptr i64 %42 to i64*
  %44 = load i64, i64* %43, align 8
  %45 = and i64 %44, 24
  %46 = icmp eq i64 %45, 0
  br i1 %46, label %47, label %49

47:                                               ; preds = %40
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %33, i64 %32, i64 %3) #7
  %48 = load i64, i64* %6, align 8
  br label %49

49:                                               ; preds = %5, %31, %40, %47
  %50 = phi i64 [ %14, %5 ], [ %33, %31 ], [ %33, %40 ], [ %48, %47 ]
  %51 = add nsw i64 %9, 11
  %52 = add i64 %50, %51
  %53 = inttoptr i64 %52 to i32*
  %54 = trunc i64 %2 to i32
  store atomic volatile i32 %54, i32* %53 monotonic, align 4
  %55 = load i64, i64* %6, align 8
  %56 = add i64 %55, %51
  %57 = and i64 %2, 1
  %58 = icmp eq i64 %57, 0
  br i1 %58, label %90, label %59

59:                                               ; preds = %49
  %60 = and i64 %55, -262144
  %61 = or i64 %60, 8
  %62 = inttoptr i64 %61 to i64*
  %63 = load i64, i64* %62, align 8
  %64 = and i64 %63, 262144
  %65 = icmp eq i64 %64, 0
  br i1 %65, label %72, label %66

66:                                               ; preds = %59
  %67 = or i64 %60, 16
  %68 = inttoptr i64 %67 to %"class.v8::internal::Heap"**
  %69 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %68, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %69, i64 %55, i64 %56, i64 %2) #7
  %70 = load i64, i64* %6, align 8
  %71 = add i64 %70, %51
  br label %72

72:                                               ; preds = %66, %59
  %73 = phi i64 [ %56, %59 ], [ %71, %66 ]
  %74 = phi i64 [ %55, %59 ], [ %70, %66 ]
  %75 = and i64 %2, -262144
  %76 = or i64 %75, 8
  %77 = inttoptr i64 %76 to i64*
  %78 = load i64, i64* %77, align 8
  %79 = and i64 %78, 24
  %80 = icmp eq i64 %79, 0
  br i1 %80, label %90, label %81

81:                                               ; preds = %72
  %82 = and i64 %74, -262144
  %83 = or i64 %82, 8
  %84 = inttoptr i64 %83 to i64*
  %85 = load i64, i64* %84, align 8
  %86 = and i64 %85, 24
  %87 = icmp eq i64 %86, 0
  br i1 %87, label %88, label %90

88:                                               ; preds = %81
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %74, i64 %73, i64 %2) #7
  %89 = load i64, i64* %6, align 8
  br label %90

90:                                               ; preds = %88, %81, %72, %49
  %91 = phi i64 [ %89, %88 ], [ %74, %81 ], [ %74, %72 ], [ %55, %49 ]
  %92 = shl i32 %4, 1
  %93 = add nsw i64 %9, 19
  %94 = add i64 %93, %91
  %95 = inttoptr i64 %94 to i32*
  store atomic volatile i32 %92, i32* %95 monotonic, align 4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden i64* @_ZN2v88internal26SmallOrderedNameDictionary11DeleteEntryEPNS0_7IsolateENS0_6HandleIS1_EENS0_13InternalIndexE(%"class.v8::internal::Isolate"*, i64*, i64) local_unnamed_addr #0 align 2 {
  %4 = alloca %"class.v8::internal::Handle<v8::internal::SmallOrderedNameDictionary>::ObjectRef", align 8
  %5 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 5
  %6 = load i64, i64* %5, align 8
  %7 = bitcast %"class.v8::internal::Handle<v8::internal::SmallOrderedNameDictionary>::ObjectRef"* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %7) #7
  %8 = load i64, i64* %1, align 8
  %9 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::SmallOrderedNameDictionary>::ObjectRef", %"class.v8::internal::Handle<v8::internal::SmallOrderedNameDictionary>::ObjectRef"* %4, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %8, i64* %9, align 8
  %10 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::SmallOrderedNameDictionary>::ObjectRef", %"class.v8::internal::Handle<v8::internal::SmallOrderedNameDictionary>::ObjectRef"* %4, i64 0, i32 0
  call void @_ZN2v88internal26SmallOrderedNameDictionary8SetEntryENS0_13InternalIndexENS0_6ObjectES3_NS0_15PropertyDetailsE(%"class.v8::internal::SmallOrderedNameDictionary"* nonnull %10, i64 %2, i64 %6, i64 %6, i32 0)
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %7) #7
  %11 = load i64, i64* %1, align 8
  %12 = add i64 %11, 7
  %13 = inttoptr i64 %12 to i8*
  %14 = load i8, i8* %13, align 1
  %15 = add i8 %14, -1
  store i8 %15, i8* %13, align 1
  %16 = load i64, i64* %1, align 8
  %17 = add i64 %16, 8
  %18 = inttoptr i64 %17 to i8*
  %19 = load i8, i8* %18, align 1
  %20 = add i8 %19, 1
  store i8 %20, i8* %18, align 1
  %21 = load i64, i64* %1, align 8
  %22 = add i64 %21, 7
  %23 = inttoptr i64 %22 to i8*
  %24 = load i8, i8* %23, align 1
  %25 = add i64 %21, 9
  %26 = inttoptr i64 %25 to i8*
  %27 = load i8, i8* %26, align 1
  %28 = lshr i8 %27, 1
  %29 = icmp ugt i8 %28, %24
  br i1 %29, label %30, label %40

30:                                               ; preds = %3
  %31 = zext i8 %27 to i32
  %32 = tail call i64* @_ZN2v88internal21SmallOrderedHashTableINS0_26SmallOrderedNameDictionaryEE6RehashEPNS0_7IsolateENS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"* %0, i64* %1, i32 %31) #7
  %33 = load i64, i64* %32, align 8
  %34 = load i64, i64* %1, align 8
  %35 = add i64 %34, 3
  %36 = inttoptr i64 %35 to i32*
  %37 = load i32, i32* %36, align 4
  %38 = add i64 %33, 3
  %39 = inttoptr i64 %38 to i32*
  store i32 %37, i32* %39, align 4
  br label %40

40:                                               ; preds = %3, %30
  %41 = phi i64* [ %32, %30 ], [ %1, %3 ]
  ret i64* %41
}

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64* @_ZN2v88internal21SmallOrderedHashTableINS0_26SmallOrderedNameDictionaryEE6RehashEPNS0_7IsolateENS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"*, i64*, i32) local_unnamed_addr #0 comdat align 2 {
  %4 = alloca %"class.v8::internal::JSReceiver", align 8
  %5 = load i64, i64* %1, align 8
  %6 = and i64 %5, -262144
  %7 = inttoptr i64 %6 to %"class.v8::internal::BasicMemoryChunk"*
  %8 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %7, i64 0, i32 1
  %9 = load i64, i64* %8, align 8
  %10 = and i64 %9, 24
  %11 = icmp eq i64 %10, 0
  %12 = zext i1 %11 to i8
  %13 = bitcast %"class.v8::internal::Isolate"* %0 to %"class.v8::internal::Factory"*
  %14 = tail call i64* @_ZN2v88internal7Factory29NewSmallOrderedNameDictionaryEiNS0_14AllocationTypeE(%"class.v8::internal::Factory"* %13, i32 %2, i8 zeroext %12) #7
  %15 = load i64, i64* %1, align 8
  %16 = add i64 %15, 7
  %17 = inttoptr i64 %16 to i8*
  %18 = load i8, i8* %17, align 1
  %19 = zext i8 %18 to i64
  %20 = add i64 %15, 8
  %21 = inttoptr i64 %20 to i8*
  %22 = load i8, i8* %21, align 1
  %23 = zext i8 %22 to i64
  %24 = add nuw nsw i64 %23, %19
  %25 = icmp eq i64 %24, 0
  br i1 %25, label %33, label %26

26:                                               ; preds = %3
  %27 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 5
  %28 = bitcast %"class.v8::internal::JSReceiver"* %4 to i8*
  %29 = getelementptr inbounds %"class.v8::internal::JSReceiver", %"class.v8::internal::JSReceiver"* %4, i64 0, i32 0, i32 0, i32 0, i32 0
  br label %39

30:                                               ; preds = %154
  %31 = add i64 %158, 7
  %32 = inttoptr i64 %31 to i8*
  br label %33

33:                                               ; preds = %30, %3
  %34 = phi i8* [ %32, %30 ], [ %17, %3 ]
  %35 = load i64, i64* %14, align 8
  %36 = load i8, i8* %34, align 1
  %37 = add i64 %35, 7
  %38 = inttoptr i64 %37 to i8*
  store i8 %36, i8* %38, align 1
  ret i64* %14

39:                                               ; preds = %154, %26
  %40 = phi i64 [ %15, %26 ], [ %158, %154 ]
  %41 = phi i32 [ 0, %26 ], [ %155, %154 ]
  %42 = phi i64 [ 0, %26 ], [ %156, %154 ]
  %43 = mul nuw nsw i64 %42, 51539607552
  %44 = add nuw nsw i64 %43, 51539607552
  %45 = lshr exact i64 %44, 32
  %46 = add nsw i64 %45, -1
  %47 = add i64 %46, %40
  %48 = inttoptr i64 %47 to i32*
  %49 = load i32, i32* %48, align 4
  %50 = and i64 %40, -4294967296
  %51 = zext i32 %49 to i64
  %52 = or i64 %50, %51
  %53 = load i64, i64* %27, align 8
  %54 = trunc i64 %53 to i32
  %55 = icmp eq i32 %49, %54
  br i1 %55, label %154, label %56

56:                                               ; preds = %39
  %57 = call i64 @_ZN2v88internal6Object13GetSimpleHashES1_(i64 %52) #7
  %58 = and i64 %57, 1
  %59 = icmp eq i64 %58, 0
  br i1 %59, label %62, label %60

60:                                               ; preds = %56
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %28) #7
  store i64 %52, i64* %29, align 8
  %61 = call i64 @_ZN2v88internal10JSReceiver15GetIdentityHashEv(%"class.v8::internal::JSReceiver"* nonnull %4) #7
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %28) #7
  br label %62

62:                                               ; preds = %56, %60
  %63 = phi i64 [ %61, %60 ], [ %57, %56 ]
  %64 = trunc i64 %63 to i32
  %65 = ashr i32 %64, 1
  %66 = load i64, i64* %14, align 8
  %67 = add i64 %66, 9
  %68 = inttoptr i64 %67 to i8*
  %69 = load i8, i8* %68, align 1
  %70 = zext i8 %69 to i32
  %71 = add nsw i32 %70, -1
  %72 = and i32 %71, %65
  %73 = mul nuw nsw i32 %70, 24
  %74 = add nuw nsw i32 %73, 12
  %75 = add nsw i32 %74, %72
  %76 = sext i32 %75 to i64
  %77 = add i64 %66, -1
  %78 = add i64 %77, %76
  %79 = inttoptr i64 %78 to i8*
  %80 = load i8, i8* %79, align 1
  %81 = trunc i32 %41 to i8
  store i8 %81, i8* %79, align 1
  %82 = load i64, i64* %14, align 8
  %83 = add i64 %82, 9
  %84 = inttoptr i64 %83 to i8*
  %85 = load i8, i8* %84, align 1
  %86 = zext i8 %85 to i32
  %87 = mul nuw nsw i32 %86, 24
  %88 = add i32 %41, 12
  %89 = add i32 %88, %86
  %90 = add i32 %89, %87
  %91 = sext i32 %90 to i64
  %92 = add i64 %82, -1
  %93 = add i64 %92, %91
  %94 = inttoptr i64 %93 to i8*
  store i8 %80, i8* %94, align 1
  %95 = mul i32 %41, 12
  %96 = mul i64 %42, 51539607552
  %97 = ashr exact i64 %96, 32
  %98 = load i64, i64* %1, align 8
  %99 = add nsw i64 %97, 11
  %100 = add i64 %99, %98
  %101 = inttoptr i64 %100 to i32*
  %102 = load i32, i32* %101, align 4
  %103 = and i64 %98, -4294967296
  %104 = zext i32 %102 to i64
  %105 = or i64 %103, %104
  %106 = load i64, i64* %14, align 8
  %107 = add i32 %95, 12
  %108 = sext i32 %107 to i64
  %109 = add nsw i64 %108, -1
  %110 = add i64 %109, %106
  %111 = inttoptr i64 %110 to i32*
  store atomic volatile i32 %102, i32* %111 monotonic, align 4
  %112 = and i64 %104, 1
  %113 = icmp eq i64 %112, 0
  br i1 %113, label %137, label %114

114:                                              ; preds = %62
  %115 = and i64 %106, -262144
  %116 = or i64 %115, 8
  %117 = inttoptr i64 %116 to i64*
  %118 = load i64, i64* %117, align 8
  %119 = and i64 %118, 262144
  %120 = icmp eq i64 %119, 0
  br i1 %120, label %125, label %121

121:                                              ; preds = %114
  %122 = or i64 %115, 16
  %123 = inttoptr i64 %122 to %"class.v8::internal::Heap"**
  %124 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %123, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %124, i64 %106, i64 %110, i64 %105) #7
  br label %125

125:                                              ; preds = %121, %114
  %126 = and i64 %105, -262144
  %127 = or i64 %126, 8
  %128 = inttoptr i64 %127 to i64*
  %129 = load i64, i64* %128, align 8
  %130 = and i64 %129, 24
  %131 = icmp eq i64 %130, 0
  br i1 %131, label %137, label %132

132:                                              ; preds = %125
  %133 = load i64, i64* %117, align 8
  %134 = and i64 %133, 24
  %135 = icmp eq i64 %134, 0
  br i1 %135, label %136, label %137

136:                                              ; preds = %132
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %106, i64 %110, i64 %105) #7
  br label %137

137:                                              ; preds = %62, %125, %132, %136
  %138 = load i64, i64* %1, align 8
  %139 = add nsw i64 %97, 15
  %140 = add i64 %139, %138
  %141 = inttoptr i64 %140 to i32*
  %142 = load i32, i32* %141, align 4
  %143 = and i64 %138, -4294967296
  %144 = zext i32 %142 to i64
  %145 = or i64 %143, %144
  %146 = load i64, i64* %14, align 8
  %147 = add i32 %95, 16
  %148 = sext i32 %147 to i64
  %149 = add nsw i64 %148, -1
  %150 = add i64 %149, %146
  %151 = inttoptr i64 %150 to i32*
  store atomic volatile i32 %142, i32* %151 monotonic, align 4
  %152 = and i64 %144, 1
  %153 = icmp eq i64 %152, 0
  br i1 %153, label %182, label %159

154:                                              ; preds = %39, %222
  %155 = phi i32 [ %223, %222 ], [ %41, %39 ]
  %156 = add nuw nsw i64 %42, 1
  %157 = icmp eq i64 %156, %24
  %158 = load i64, i64* %1, align 8
  br i1 %157, label %30, label %39

159:                                              ; preds = %137
  %160 = and i64 %146, -262144
  %161 = or i64 %160, 8
  %162 = inttoptr i64 %161 to i64*
  %163 = load i64, i64* %162, align 8
  %164 = and i64 %163, 262144
  %165 = icmp eq i64 %164, 0
  br i1 %165, label %170, label %166

166:                                              ; preds = %159
  %167 = or i64 %160, 16
  %168 = inttoptr i64 %167 to %"class.v8::internal::Heap"**
  %169 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %168, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %169, i64 %146, i64 %150, i64 %145) #7
  br label %170

170:                                              ; preds = %166, %159
  %171 = and i64 %145, -262144
  %172 = or i64 %171, 8
  %173 = inttoptr i64 %172 to i64*
  %174 = load i64, i64* %173, align 8
  %175 = and i64 %174, 24
  %176 = icmp eq i64 %175, 0
  br i1 %176, label %182, label %177

177:                                              ; preds = %170
  %178 = load i64, i64* %162, align 8
  %179 = and i64 %178, 24
  %180 = icmp eq i64 %179, 0
  br i1 %180, label %181, label %182

181:                                              ; preds = %177
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %146, i64 %150, i64 %145) #7
  br label %182

182:                                              ; preds = %181, %177, %170, %137
  %183 = load i64, i64* %1, align 8
  %184 = add nsw i64 %97, 19
  %185 = add i64 %184, %183
  %186 = inttoptr i64 %185 to i32*
  %187 = load i32, i32* %186, align 4
  %188 = and i64 %183, -4294967296
  %189 = zext i32 %187 to i64
  %190 = or i64 %188, %189
  %191 = load i64, i64* %14, align 8
  %192 = add i32 %95, 20
  %193 = sext i32 %192 to i64
  %194 = add nsw i64 %193, -1
  %195 = add i64 %194, %191
  %196 = inttoptr i64 %195 to i32*
  store atomic volatile i32 %187, i32* %196 monotonic, align 4
  %197 = and i64 %189, 1
  %198 = icmp eq i64 %197, 0
  br i1 %198, label %222, label %199

199:                                              ; preds = %182
  %200 = and i64 %191, -262144
  %201 = or i64 %200, 8
  %202 = inttoptr i64 %201 to i64*
  %203 = load i64, i64* %202, align 8
  %204 = and i64 %203, 262144
  %205 = icmp eq i64 %204, 0
  br i1 %205, label %210, label %206

206:                                              ; preds = %199
  %207 = or i64 %200, 16
  %208 = inttoptr i64 %207 to %"class.v8::internal::Heap"**
  %209 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %208, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %209, i64 %191, i64 %195, i64 %190) #7
  br label %210

210:                                              ; preds = %206, %199
  %211 = and i64 %190, -262144
  %212 = or i64 %211, 8
  %213 = inttoptr i64 %212 to i64*
  %214 = load i64, i64* %213, align 8
  %215 = and i64 %214, 24
  %216 = icmp eq i64 %215, 0
  br i1 %216, label %222, label %217

217:                                              ; preds = %210
  %218 = load i64, i64* %202, align 8
  %219 = and i64 %218, 24
  %220 = icmp eq i64 %219, 0
  br i1 %220, label %221, label %222

221:                                              ; preds = %217
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %191, i64 %195, i64 %190) #7
  br label %222

222:                                              ; preds = %221, %217, %210, %182
  %223 = add nsw i32 %41, 1
  br label %154
}

; Function Attrs: nounwind ssp uwtable
define hidden i64* @_ZN2v88internal21OrderedHashMapHandler20AdjustRepresentationEPNS0_7IsolateENS0_6HandleINS0_19SmallOrderedHashMapEEE(%"class.v8::internal::Isolate"*, i64*) local_unnamed_addr #0 align 2 {
  %3 = tail call i32 @_ZN2v84base4bits21RoundUpToPowerOfTwo32Ej(i32 512) #7
  %4 = icmp sgt i32 %3, 19173960
  br i1 %4, label %168, label %5

5:                                                ; preds = %2
  %6 = sdiv i32 %3, 2
  %7 = bitcast %"class.v8::internal::Isolate"* %0 to %"class.v8::internal::FactoryBase"*
  %8 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 54
  %9 = add nsw i32 %6, 3
  %10 = mul nsw i32 %3, 3
  %11 = add nsw i32 %9, %10
  %12 = tail call i64* @_ZN2v88internal11FactoryBaseINS0_7FactoryEE20NewFixedArrayWithMapENS0_6HandleINS0_3MapEEEiNS0_14AllocationTypeE(%"class.v8::internal::FactoryBase"* %7, i64* %8, i32 %11, i8 zeroext 0) #7
  %13 = icmp sgt i32 %3, 1
  %14 = load i64, i64* %12, align 8
  br i1 %13, label %15, label %61

15:                                               ; preds = %5
  %16 = zext i32 %6 to i64
  %17 = and i64 %16, 1
  %18 = and i32 %3, -2
  %19 = icmp eq i32 %18, 2
  br i1 %19, label %51, label %20

20:                                               ; preds = %15
  %21 = sub nsw i64 %16, %17
  br label %22

22:                                               ; preds = %22, %20
  %23 = phi i64 [ 0, %20 ], [ %42, %22 ]
  %24 = phi i64 [ %14, %20 ], [ %43, %22 ]
  %25 = phi i64 [ %21, %20 ], [ %44, %22 ]
  %26 = trunc i64 %23 to i32
  %27 = shl i32 %26, 2
  %28 = add i32 %27, 12
  %29 = sext i32 %28 to i64
  %30 = add i64 %24, 7
  %31 = add i64 %30, %29
  %32 = inttoptr i64 %31 to i32*
  store atomic volatile i32 -2, i32* %32 monotonic, align 4
  %33 = load i64, i64* %12, align 8
  %34 = trunc i64 %23 to i32
  %35 = shl i32 %34, 2
  %36 = or i32 %35, 4
  %37 = add i32 %36, 12
  %38 = sext i32 %37 to i64
  %39 = add i64 %33, 7
  %40 = add i64 %39, %38
  %41 = inttoptr i64 %40 to i32*
  store atomic volatile i32 -2, i32* %41 monotonic, align 4
  %42 = add nuw nsw i64 %23, 2
  %43 = load i64, i64* %12, align 8
  %44 = add i64 %25, -2
  %45 = icmp eq i64 %44, 0
  br i1 %45, label %46, label %22

46:                                               ; preds = %22
  %47 = trunc i64 %42 to i32
  %48 = shl i32 %47, 2
  %49 = add i32 %48, 12
  %50 = sext i32 %49 to i64
  br label %51

51:                                               ; preds = %46, %15
  %52 = phi i64 [ undef, %15 ], [ %43, %46 ]
  %53 = phi i64 [ 12, %15 ], [ %50, %46 ]
  %54 = phi i64 [ %14, %15 ], [ %43, %46 ]
  %55 = icmp eq i64 %17, 0
  br i1 %55, label %61, label %56

56:                                               ; preds = %51
  %57 = add i64 %54, 7
  %58 = add i64 %57, %53
  %59 = inttoptr i64 %58 to i32*
  store atomic volatile i32 -2, i32* %59 monotonic, align 4
  %60 = load i64, i64* %12, align 8
  br label %61

61:                                               ; preds = %56, %51, %5
  %62 = phi i64 [ %14, %5 ], [ %52, %51 ], [ %60, %56 ]
  %63 = shl nsw i32 %6, 1
  %64 = add i64 %62, 15
  %65 = inttoptr i64 %64 to i32*
  store atomic volatile i32 %63, i32* %65 monotonic, align 4
  %66 = load i64, i64* %12, align 8
  %67 = add i64 %66, 7
  %68 = inttoptr i64 %67 to i32*
  store atomic volatile i32 0, i32* %68 monotonic, align 4
  %69 = load i64, i64* %12, align 8
  %70 = add i64 %69, 11
  %71 = inttoptr i64 %70 to i32*
  store atomic volatile i32 0, i32* %71 monotonic, align 4
  %72 = icmp eq i64* %12, null
  br i1 %72, label %168, label %73

73:                                               ; preds = %61
  %74 = load i64, i64* %1, align 8
  %75 = add i64 %74, 3
  %76 = inttoptr i64 %75 to i8*
  %77 = load i8, i8* %76, align 1
  %78 = zext i8 %77 to i64
  %79 = add i64 %74, 4
  %80 = inttoptr i64 %79 to i8*
  %81 = load i8, i8* %80, align 1
  %82 = zext i8 %81 to i64
  %83 = add nuw nsw i64 %82, %78
  %84 = icmp eq i64 %83, 0
  br i1 %84, label %168, label %85

85:                                               ; preds = %73
  %86 = ptrtoint i64* %12 to i64
  %87 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 31, i32 4
  %88 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 31, i32 0
  %89 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 31, i32 1
  %90 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 5
  br label %91

91:                                               ; preds = %166, %85
  %92 = phi i64 [ %74, %85 ], [ %167, %166 ]
  %93 = phi i64* [ %12, %85 ], [ %163, %166 ]
  %94 = phi i64 [ %86, %85 ], [ %162, %166 ]
  %95 = phi i64 [ 0, %85 ], [ %164, %166 ]
  %96 = trunc i64 %95 to i32
  %97 = shl i32 %96, 3
  %98 = or i32 %97, 7
  %99 = sext i32 %98 to i64
  %100 = add i64 %92, %99
  %101 = inttoptr i64 %100 to i32*
  %102 = load i32, i32* %101, align 4
  %103 = and i64 %92, -4294967296
  %104 = zext i32 %102 to i64
  %105 = or i64 %103, %104
  %106 = load %"class.v8::internal::CanonicalHandleScope"*, %"class.v8::internal::CanonicalHandleScope"** %87, align 8
  %107 = icmp eq %"class.v8::internal::CanonicalHandleScope"* %106, null
  br i1 %107, label %111, label %108

108:                                              ; preds = %91
  %109 = tail call i64* @_ZN2v88internal20CanonicalHandleScope6LookupEm(%"class.v8::internal::CanonicalHandleScope"* nonnull %106, i64 %105) #7
  %110 = load i64, i64* %109, align 8
  br label %122

111:                                              ; preds = %91
  %112 = load i64*, i64** %88, align 8
  %113 = load i64*, i64** %89, align 8
  %114 = icmp eq i64* %112, %113
  br i1 %114, label %115, label %117

115:                                              ; preds = %111
  %116 = tail call i64* @_ZN2v88internal11HandleScope6ExtendEPNS0_7IsolateE(%"class.v8::internal::Isolate"* %0) #7
  br label %117

117:                                              ; preds = %115, %111
  %118 = phi i64* [ %116, %115 ], [ %112, %111 ]
  %119 = ptrtoint i64* %118 to i64
  %120 = add i64 %119, 8
  %121 = inttoptr i64 %120 to i64*
  store i64* %121, i64** %88, align 8
  store i64 %105, i64* %118, align 8
  br label %122

122:                                              ; preds = %108, %117
  %123 = phi i64 [ %110, %108 ], [ %105, %117 ]
  %124 = phi i64* [ %109, %108 ], [ %118, %117 ]
  %125 = load i64, i64* %90, align 8
  %126 = trunc i64 %123 to i32
  %127 = trunc i64 %125 to i32
  %128 = icmp eq i32 %126, %127
  br i1 %128, label %161, label %129

129:                                              ; preds = %122
  %130 = load i64, i64* %1, align 8
  %131 = sext i32 %97 to i64
  %132 = add nsw i64 %131, 11
  %133 = add i64 %132, %130
  %134 = inttoptr i64 %133 to i32*
  %135 = load i32, i32* %134, align 4
  %136 = and i64 %130, -4294967296
  %137 = zext i32 %135 to i64
  %138 = or i64 %136, %137
  %139 = load %"class.v8::internal::CanonicalHandleScope"*, %"class.v8::internal::CanonicalHandleScope"** %87, align 8
  %140 = icmp eq %"class.v8::internal::CanonicalHandleScope"* %139, null
  br i1 %140, label %143, label %141

141:                                              ; preds = %129
  %142 = tail call i64* @_ZN2v88internal20CanonicalHandleScope6LookupEm(%"class.v8::internal::CanonicalHandleScope"* nonnull %139, i64 %138) #7
  br label %154

143:                                              ; preds = %129
  %144 = load i64*, i64** %88, align 8
  %145 = load i64*, i64** %89, align 8
  %146 = icmp eq i64* %144, %145
  br i1 %146, label %147, label %149

147:                                              ; preds = %143
  %148 = tail call i64* @_ZN2v88internal11HandleScope6ExtendEPNS0_7IsolateE(%"class.v8::internal::Isolate"* %0) #7
  br label %149

149:                                              ; preds = %147, %143
  %150 = phi i64* [ %148, %147 ], [ %144, %143 ]
  %151 = ptrtoint i64* %150 to i64
  %152 = add i64 %151, 8
  %153 = inttoptr i64 %152 to i64*
  store i64* %153, i64** %88, align 8
  store i64 %138, i64* %150, align 8
  br label %154

154:                                              ; preds = %141, %149
  %155 = phi i64* [ %142, %141 ], [ %150, %149 ]
  %156 = inttoptr i64 %94 to i64*
  %157 = tail call i64* @_ZN2v88internal14OrderedHashMap3AddEPNS0_7IsolateENS0_6HandleIS1_EENS4_INS0_6ObjectEEES7_(%"class.v8::internal::Isolate"* %0, i64* %156, i64* %124, i64* %155)
  %158 = icmp eq i64* %157, null
  br i1 %158, label %168, label %159

159:                                              ; preds = %154
  %160 = ptrtoint i64* %157 to i64
  br label %161

161:                                              ; preds = %122, %159
  %162 = phi i64 [ %160, %159 ], [ %94, %122 ]
  %163 = phi i64* [ %157, %159 ], [ %93, %122 ]
  %164 = add nuw nsw i64 %95, 1
  %165 = icmp eq i64 %164, %83
  br i1 %165, label %168, label %166

166:                                              ; preds = %161
  %167 = load i64, i64* %1, align 8
  br label %91

168:                                              ; preds = %154, %161, %73, %2, %61
  %169 = phi i64* [ null, %61 ], [ null, %2 ], [ %12, %73 ], [ null, %154 ], [ %163, %161 ]
  ret i64* %169
}

; Function Attrs: nounwind ssp uwtable
define hidden i64* @_ZN2v88internal21OrderedHashSetHandler20AdjustRepresentationEPNS0_7IsolateENS0_6HandleINS0_19SmallOrderedHashSetEEE(%"class.v8::internal::Isolate"*, i64*) local_unnamed_addr #0 align 2 {
  %3 = tail call i32 @_ZN2v84base4bits21RoundUpToPowerOfTwo32Ej(i32 512) #7
  %4 = icmp sgt i32 %3, 26843544
  br i1 %4, label %143, label %5

5:                                                ; preds = %2
  %6 = sdiv i32 %3, 2
  %7 = bitcast %"class.v8::internal::Isolate"* %0 to %"class.v8::internal::FactoryBase"*
  %8 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 55
  %9 = add nsw i32 %6, 3
  %10 = shl i32 %3, 1
  %11 = add nsw i32 %9, %10
  %12 = tail call i64* @_ZN2v88internal11FactoryBaseINS0_7FactoryEE20NewFixedArrayWithMapENS0_6HandleINS0_3MapEEEiNS0_14AllocationTypeE(%"class.v8::internal::FactoryBase"* %7, i64* %8, i32 %11, i8 zeroext 0) #7
  %13 = icmp sgt i32 %3, 1
  %14 = load i64, i64* %12, align 8
  br i1 %13, label %15, label %61

15:                                               ; preds = %5
  %16 = zext i32 %6 to i64
  %17 = and i64 %16, 1
  %18 = and i32 %3, -2
  %19 = icmp eq i32 %18, 2
  br i1 %19, label %51, label %20

20:                                               ; preds = %15
  %21 = sub nsw i64 %16, %17
  br label %22

22:                                               ; preds = %22, %20
  %23 = phi i64 [ 0, %20 ], [ %42, %22 ]
  %24 = phi i64 [ %14, %20 ], [ %43, %22 ]
  %25 = phi i64 [ %21, %20 ], [ %44, %22 ]
  %26 = trunc i64 %23 to i32
  %27 = shl i32 %26, 2
  %28 = add i32 %27, 12
  %29 = sext i32 %28 to i64
  %30 = add i64 %24, 7
  %31 = add i64 %30, %29
  %32 = inttoptr i64 %31 to i32*
  store atomic volatile i32 -2, i32* %32 monotonic, align 4
  %33 = load i64, i64* %12, align 8
  %34 = trunc i64 %23 to i32
  %35 = shl i32 %34, 2
  %36 = or i32 %35, 4
  %37 = add i32 %36, 12
  %38 = sext i32 %37 to i64
  %39 = add i64 %33, 7
  %40 = add i64 %39, %38
  %41 = inttoptr i64 %40 to i32*
  store atomic volatile i32 -2, i32* %41 monotonic, align 4
  %42 = add nuw nsw i64 %23, 2
  %43 = load i64, i64* %12, align 8
  %44 = add i64 %25, -2
  %45 = icmp eq i64 %44, 0
  br i1 %45, label %46, label %22

46:                                               ; preds = %22
  %47 = trunc i64 %42 to i32
  %48 = shl i32 %47, 2
  %49 = add i32 %48, 12
  %50 = sext i32 %49 to i64
  br label %51

51:                                               ; preds = %46, %15
  %52 = phi i64 [ undef, %15 ], [ %43, %46 ]
  %53 = phi i64 [ 12, %15 ], [ %50, %46 ]
  %54 = phi i64 [ %14, %15 ], [ %43, %46 ]
  %55 = icmp eq i64 %17, 0
  br i1 %55, label %61, label %56

56:                                               ; preds = %51
  %57 = add i64 %54, 7
  %58 = add i64 %57, %53
  %59 = inttoptr i64 %58 to i32*
  store atomic volatile i32 -2, i32* %59 monotonic, align 4
  %60 = load i64, i64* %12, align 8
  br label %61

61:                                               ; preds = %56, %51, %5
  %62 = phi i64 [ %14, %5 ], [ %52, %51 ], [ %60, %56 ]
  %63 = shl nsw i32 %6, 1
  %64 = add i64 %62, 15
  %65 = inttoptr i64 %64 to i32*
  store atomic volatile i32 %63, i32* %65 monotonic, align 4
  %66 = load i64, i64* %12, align 8
  %67 = add i64 %66, 7
  %68 = inttoptr i64 %67 to i32*
  store atomic volatile i32 0, i32* %68 monotonic, align 4
  %69 = load i64, i64* %12, align 8
  %70 = add i64 %69, 11
  %71 = inttoptr i64 %70 to i32*
  store atomic volatile i32 0, i32* %71 monotonic, align 4
  %72 = icmp eq i64* %12, null
  br i1 %72, label %143, label %73

73:                                               ; preds = %61
  %74 = load i64, i64* %1, align 8
  %75 = add i64 %74, 3
  %76 = inttoptr i64 %75 to i8*
  %77 = load i8, i8* %76, align 1
  %78 = zext i8 %77 to i64
  %79 = add i64 %74, 4
  %80 = inttoptr i64 %79 to i8*
  %81 = load i8, i8* %80, align 1
  %82 = zext i8 %81 to i64
  %83 = add nuw nsw i64 %82, %78
  %84 = icmp eq i64 %83, 0
  br i1 %84, label %143, label %85

85:                                               ; preds = %73
  %86 = ptrtoint i64* %12 to i64
  %87 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 31, i32 4
  %88 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 31, i32 0
  %89 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 31, i32 1
  %90 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 5
  br label %91

91:                                               ; preds = %141, %85
  %92 = phi i64 [ %74, %85 ], [ %142, %141 ]
  %93 = phi i64* [ %12, %85 ], [ %138, %141 ]
  %94 = phi i64 [ %86, %85 ], [ %137, %141 ]
  %95 = phi i64 [ 0, %85 ], [ %139, %141 ]
  %96 = trunc i64 %95 to i32
  %97 = shl i32 %96, 2
  %98 = add i32 %97, 8
  %99 = sext i32 %98 to i64
  %100 = add nsw i64 %99, -1
  %101 = add i64 %100, %92
  %102 = inttoptr i64 %101 to i32*
  %103 = load i32, i32* %102, align 4
  %104 = and i64 %92, -4294967296
  %105 = zext i32 %103 to i64
  %106 = or i64 %104, %105
  %107 = load %"class.v8::internal::CanonicalHandleScope"*, %"class.v8::internal::CanonicalHandleScope"** %87, align 8
  %108 = icmp eq %"class.v8::internal::CanonicalHandleScope"* %107, null
  br i1 %108, label %112, label %109

109:                                              ; preds = %91
  %110 = tail call i64* @_ZN2v88internal20CanonicalHandleScope6LookupEm(%"class.v8::internal::CanonicalHandleScope"* nonnull %107, i64 %106) #7
  %111 = load i64, i64* %110, align 8
  br label %123

112:                                              ; preds = %91
  %113 = load i64*, i64** %88, align 8
  %114 = load i64*, i64** %89, align 8
  %115 = icmp eq i64* %113, %114
  br i1 %115, label %116, label %118

116:                                              ; preds = %112
  %117 = tail call i64* @_ZN2v88internal11HandleScope6ExtendEPNS0_7IsolateE(%"class.v8::internal::Isolate"* %0) #7
  br label %118

118:                                              ; preds = %116, %112
  %119 = phi i64* [ %117, %116 ], [ %113, %112 ]
  %120 = ptrtoint i64* %119 to i64
  %121 = add i64 %120, 8
  %122 = inttoptr i64 %121 to i64*
  store i64* %122, i64** %88, align 8
  store i64 %106, i64* %119, align 8
  br label %123

123:                                              ; preds = %109, %118
  %124 = phi i64 [ %111, %109 ], [ %106, %118 ]
  %125 = phi i64* [ %110, %109 ], [ %119, %118 ]
  %126 = load i64, i64* %90, align 8
  %127 = trunc i64 %124 to i32
  %128 = trunc i64 %126 to i32
  %129 = icmp eq i32 %127, %128
  br i1 %129, label %136, label %130

130:                                              ; preds = %123
  %131 = inttoptr i64 %94 to i64*
  %132 = tail call i64* @_ZN2v88internal14OrderedHashSet3AddEPNS0_7IsolateENS0_6HandleIS1_EENS4_INS0_6ObjectEEE(%"class.v8::internal::Isolate"* %0, i64* %131, i64* %125)
  %133 = icmp eq i64* %132, null
  br i1 %133, label %143, label %134

134:                                              ; preds = %130
  %135 = ptrtoint i64* %132 to i64
  br label %136

136:                                              ; preds = %123, %134
  %137 = phi i64 [ %135, %134 ], [ %94, %123 ]
  %138 = phi i64* [ %132, %134 ], [ %93, %123 ]
  %139 = add nuw nsw i64 %95, 1
  %140 = icmp eq i64 %139, %83
  br i1 %140, label %143, label %141

141:                                              ; preds = %136
  %142 = load i64, i64* %1, align 8
  br label %91

143:                                              ; preds = %130, %136, %73, %2, %61
  %144 = phi i64* [ null, %61 ], [ null, %2 ], [ %12, %73 ], [ null, %130 ], [ %138, %136 ]
  ret i64* %144
}

; Function Attrs: nounwind ssp uwtable
define hidden i64* @_ZN2v88internal28OrderedNameDictionaryHandler20AdjustRepresentationEPNS0_7IsolateENS0_6HandleINS0_26SmallOrderedNameDictionaryEEE(%"class.v8::internal::Isolate"*, i64*) local_unnamed_addr #0 align 2 {
  %3 = tail call i32 @_ZN2v84base4bits21RoundUpToPowerOfTwo32Ej(i32 512) #7
  %4 = icmp sgt i32 %3, 14913080
  br i1 %4, label %177, label %5

5:                                                ; preds = %2
  %6 = sdiv i32 %3, 2
  %7 = bitcast %"class.v8::internal::Isolate"* %0 to %"class.v8::internal::FactoryBase"*
  %8 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 56
  %9 = add nsw i32 %6, 4
  %10 = shl i32 %3, 2
  %11 = add nsw i32 %9, %10
  %12 = tail call i64* @_ZN2v88internal11FactoryBaseINS0_7FactoryEE20NewFixedArrayWithMapENS0_6HandleINS0_3MapEEEiNS0_14AllocationTypeE(%"class.v8::internal::FactoryBase"* %7, i64* %8, i32 %11, i8 zeroext 0) #7
  %13 = icmp sgt i32 %3, 1
  %14 = load i64, i64* %12, align 8
  br i1 %13, label %15, label %61

15:                                               ; preds = %5
  %16 = zext i32 %6 to i64
  %17 = and i64 %16, 1
  %18 = and i32 %3, -2
  %19 = icmp eq i32 %18, 2
  br i1 %19, label %51, label %20

20:                                               ; preds = %15
  %21 = sub nsw i64 %16, %17
  br label %22

22:                                               ; preds = %22, %20
  %23 = phi i64 [ 0, %20 ], [ %42, %22 ]
  %24 = phi i64 [ %14, %20 ], [ %43, %22 ]
  %25 = phi i64 [ %21, %20 ], [ %44, %22 ]
  %26 = trunc i64 %23 to i32
  %27 = shl i32 %26, 2
  %28 = add i32 %27, 16
  %29 = sext i32 %28 to i64
  %30 = add i64 %24, 7
  %31 = add i64 %30, %29
  %32 = inttoptr i64 %31 to i32*
  store atomic volatile i32 -2, i32* %32 monotonic, align 4
  %33 = load i64, i64* %12, align 8
  %34 = trunc i64 %23 to i32
  %35 = shl i32 %34, 2
  %36 = or i32 %35, 4
  %37 = add i32 %36, 16
  %38 = sext i32 %37 to i64
  %39 = add i64 %33, 7
  %40 = add i64 %39, %38
  %41 = inttoptr i64 %40 to i32*
  store atomic volatile i32 -2, i32* %41 monotonic, align 4
  %42 = add nuw nsw i64 %23, 2
  %43 = load i64, i64* %12, align 8
  %44 = add i64 %25, -2
  %45 = icmp eq i64 %44, 0
  br i1 %45, label %46, label %22

46:                                               ; preds = %22
  %47 = trunc i64 %42 to i32
  %48 = shl i32 %47, 2
  %49 = add i32 %48, 16
  %50 = sext i32 %49 to i64
  br label %51

51:                                               ; preds = %46, %15
  %52 = phi i64 [ undef, %15 ], [ %43, %46 ]
  %53 = phi i64 [ 16, %15 ], [ %50, %46 ]
  %54 = phi i64 [ %14, %15 ], [ %43, %46 ]
  %55 = icmp eq i64 %17, 0
  br i1 %55, label %61, label %56

56:                                               ; preds = %51
  %57 = add i64 %54, 7
  %58 = add i64 %57, %53
  %59 = inttoptr i64 %58 to i32*
  store atomic volatile i32 -2, i32* %59 monotonic, align 4
  %60 = load i64, i64* %12, align 8
  br label %61

61:                                               ; preds = %56, %51, %5
  %62 = phi i64 [ %14, %5 ], [ %52, %51 ], [ %60, %56 ]
  %63 = shl nsw i32 %6, 1
  %64 = add i64 %62, 19
  %65 = inttoptr i64 %64 to i32*
  store atomic volatile i32 %63, i32* %65 monotonic, align 4
  %66 = load i64, i64* %12, align 8
  %67 = add i64 %66, 11
  %68 = inttoptr i64 %67 to i32*
  store atomic volatile i32 0, i32* %68 monotonic, align 4
  %69 = load i64, i64* %12, align 8
  %70 = add i64 %69, 15
  %71 = inttoptr i64 %70 to i32*
  store atomic volatile i32 0, i32* %71 monotonic, align 4
  %72 = icmp eq i64* %12, null
  br i1 %72, label %177, label %73

73:                                               ; preds = %61
  %74 = load i64, i64* %12, align 8
  %75 = add i64 %74, 7
  %76 = inttoptr i64 %75 to i32*
  store atomic volatile i32 0, i32* %76 monotonic, align 4
  %77 = load i64, i64* %1, align 8
  %78 = add i64 %77, 7
  %79 = inttoptr i64 %78 to i8*
  %80 = load i8, i8* %79, align 1
  %81 = zext i8 %80 to i64
  %82 = add i64 %77, 8
  %83 = inttoptr i64 %82 to i8*
  %84 = load i8, i8* %83, align 1
  %85 = zext i8 %84 to i64
  %86 = add nuw nsw i64 %85, %81
  %87 = icmp eq i64 %86, 0
  br i1 %87, label %177, label %88

88:                                               ; preds = %73
  %89 = ptrtoint i64* %12 to i64
  %90 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 31, i32 4
  %91 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 31, i32 0
  %92 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 31, i32 1
  %93 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 5
  br label %94

94:                                               ; preds = %175, %88
  %95 = phi i64 [ %77, %88 ], [ %176, %175 ]
  %96 = phi i64* [ %12, %88 ], [ %172, %175 ]
  %97 = phi i64 [ %89, %88 ], [ %171, %175 ]
  %98 = phi i64 [ 0, %88 ], [ %173, %175 ]
  %99 = mul nuw nsw i64 %98, 51539607552
  %100 = add nuw nsw i64 %99, 51539607552
  %101 = lshr exact i64 %100, 32
  %102 = add nsw i64 %101, -1
  %103 = add i64 %102, %95
  %104 = inttoptr i64 %103 to i32*
  %105 = load i32, i32* %104, align 4
  %106 = and i64 %95, -4294967296
  %107 = zext i32 %105 to i64
  %108 = or i64 %106, %107
  %109 = load %"class.v8::internal::CanonicalHandleScope"*, %"class.v8::internal::CanonicalHandleScope"** %90, align 8
  %110 = icmp eq %"class.v8::internal::CanonicalHandleScope"* %109, null
  br i1 %110, label %114, label %111

111:                                              ; preds = %94
  %112 = tail call i64* @_ZN2v88internal20CanonicalHandleScope6LookupEm(%"class.v8::internal::CanonicalHandleScope"* nonnull %109, i64 %108) #7
  %113 = load i64, i64* %112, align 8
  br label %125

114:                                              ; preds = %94
  %115 = load i64*, i64** %91, align 8
  %116 = load i64*, i64** %92, align 8
  %117 = icmp eq i64* %115, %116
  br i1 %117, label %118, label %120

118:                                              ; preds = %114
  %119 = tail call i64* @_ZN2v88internal11HandleScope6ExtendEPNS0_7IsolateE(%"class.v8::internal::Isolate"* %0) #7
  br label %120

120:                                              ; preds = %118, %114
  %121 = phi i64* [ %119, %118 ], [ %115, %114 ]
  %122 = ptrtoint i64* %121 to i64
  %123 = add i64 %122, 8
  %124 = inttoptr i64 %123 to i64*
  store i64* %124, i64** %91, align 8
  store i64 %108, i64* %121, align 8
  br label %125

125:                                              ; preds = %111, %120
  %126 = phi i64 [ %113, %111 ], [ %108, %120 ]
  %127 = phi i64* [ %112, %111 ], [ %121, %120 ]
  %128 = load i64, i64* %93, align 8
  %129 = trunc i64 %126 to i32
  %130 = trunc i64 %128 to i32
  %131 = icmp eq i32 %129, %130
  br i1 %131, label %170, label %132

132:                                              ; preds = %125
  %133 = load i64, i64* %1, align 8
  %134 = lshr exact i64 %99, 32
  %135 = add nuw nsw i64 %134, 15
  %136 = add i64 %135, %133
  %137 = inttoptr i64 %136 to i32*
  %138 = load i32, i32* %137, align 4
  %139 = and i64 %133, -4294967296
  %140 = zext i32 %138 to i64
  %141 = or i64 %139, %140
  %142 = load %"class.v8::internal::CanonicalHandleScope"*, %"class.v8::internal::CanonicalHandleScope"** %90, align 8
  %143 = icmp eq %"class.v8::internal::CanonicalHandleScope"* %142, null
  br i1 %143, label %146, label %144

144:                                              ; preds = %132
  %145 = tail call i64* @_ZN2v88internal20CanonicalHandleScope6LookupEm(%"class.v8::internal::CanonicalHandleScope"* nonnull %142, i64 %141) #7
  br label %157

146:                                              ; preds = %132
  %147 = load i64*, i64** %91, align 8
  %148 = load i64*, i64** %92, align 8
  %149 = icmp eq i64* %147, %148
  br i1 %149, label %150, label %152

150:                                              ; preds = %146
  %151 = tail call i64* @_ZN2v88internal11HandleScope6ExtendEPNS0_7IsolateE(%"class.v8::internal::Isolate"* %0) #7
  br label %152

152:                                              ; preds = %150, %146
  %153 = phi i64* [ %151, %150 ], [ %147, %146 ]
  %154 = ptrtoint i64* %153 to i64
  %155 = add i64 %154, 8
  %156 = inttoptr i64 %155 to i64*
  store i64* %156, i64** %91, align 8
  store i64 %141, i64* %153, align 8
  br label %157

157:                                              ; preds = %144, %152
  %158 = phi i64* [ %145, %144 ], [ %153, %152 ]
  %159 = load i64, i64* %1, align 8
  %160 = add nuw nsw i64 %134, 19
  %161 = add i64 %160, %159
  %162 = inttoptr i64 %161 to i32*
  %163 = load i32, i32* %162, align 4
  %164 = ashr i32 %163, 1
  %165 = inttoptr i64 %97 to i64*
  %166 = tail call i64* @_ZN2v88internal21OrderedNameDictionary3AddINS0_7IsolateEEENS0_11MaybeHandleIS1_EEPT_NS0_6HandleIS1_EENS8_INS0_4NameEEENS8_INS0_6ObjectEEENS0_15PropertyDetailsE(%"class.v8::internal::Isolate"* %0, i64* %165, i64* %127, i64* %158, i32 %164)
  %167 = icmp eq i64* %166, null
  br i1 %167, label %177, label %168

168:                                              ; preds = %157
  %169 = ptrtoint i64* %166 to i64
  br label %170

170:                                              ; preds = %125, %168
  %171 = phi i64 [ %169, %168 ], [ %97, %125 ]
  %172 = phi i64* [ %166, %168 ], [ %96, %125 ]
  %173 = add nuw nsw i64 %98, 1
  %174 = icmp eq i64 %173, %86
  br i1 %174, label %177, label %175

175:                                              ; preds = %170
  %176 = load i64, i64* %1, align 8
  br label %94

177:                                              ; preds = %157, %170, %73, %2, %61
  %178 = phi i64* [ null, %61 ], [ null, %2 ], [ %12, %73 ], [ null, %157 ], [ %172, %170 ]
  ret i64* %178
}

; Function Attrs: nounwind ssp uwtable
define hidden i64* @_ZN2v88internal21OrderedHashMapHandler3AddEPNS0_7IsolateENS0_6HandleINS0_10HeapObjectEEENS4_INS0_6ObjectEEES8_(%"class.v8::internal::Isolate"*, i64*, i64*, i64*) local_unnamed_addr #0 align 2 {
  %5 = load i64, i64* %1, align 8
  %6 = and i64 %5, -4294967296
  %7 = add i64 %5, -1
  %8 = inttoptr i64 %7 to i32*
  %9 = load atomic i32, i32* %8 monotonic, align 4
  %10 = zext i32 %9 to i64
  %11 = or i64 %6, %10
  %12 = add i64 %11, 7
  %13 = inttoptr i64 %12 to i16*
  %14 = load atomic i16, i16* %13 monotonic, align 2
  %15 = icmp eq i16 %14, 150
  br i1 %15, label %16, label %22

16:                                               ; preds = %4
  %17 = tail call i64* @_ZN2v88internal19SmallOrderedHashMap3AddEPNS0_7IsolateENS0_6HandleIS1_EENS4_INS0_6ObjectEEES7_(%"class.v8::internal::Isolate"* %0, i64* %1, i64* %2, i64* %3)
  %18 = icmp eq i64* %17, null
  br i1 %18, label %19, label %25

19:                                               ; preds = %16
  %20 = tail call i64* @_ZN2v88internal21OrderedHashMapHandler20AdjustRepresentationEPNS0_7IsolateENS0_6HandleINS0_19SmallOrderedHashMapEEE(%"class.v8::internal::Isolate"* %0, i64* %1)
  %21 = icmp eq i64* %20, null
  br i1 %21, label %25, label %22

22:                                               ; preds = %19, %4
  %23 = phi i64* [ %1, %4 ], [ %20, %19 ]
  %24 = tail call i64* @_ZN2v88internal14OrderedHashMap3AddEPNS0_7IsolateENS0_6HandleIS1_EENS4_INS0_6ObjectEEES7_(%"class.v8::internal::Isolate"* %0, i64* %23, i64* %2, i64* %3)
  br label %25

25:                                               ; preds = %19, %16, %22
  %26 = phi i64* [ %24, %22 ], [ null, %19 ], [ %17, %16 ]
  ret i64* %26
}

; Function Attrs: nounwind ssp uwtable
define hidden i64* @_ZN2v88internal21OrderedHashSetHandler3AddEPNS0_7IsolateENS0_6HandleINS0_10HeapObjectEEENS4_INS0_6ObjectEEE(%"class.v8::internal::Isolate"*, i64*, i64*) local_unnamed_addr #0 align 2 {
  %4 = load i64, i64* %1, align 8
  %5 = and i64 %4, -4294967296
  %6 = add i64 %4, -1
  %7 = inttoptr i64 %6 to i32*
  %8 = load atomic i32, i32* %7 monotonic, align 4
  %9 = zext i32 %8 to i64
  %10 = or i64 %5, %9
  %11 = add i64 %10, 7
  %12 = inttoptr i64 %11 to i16*
  %13 = load atomic i16, i16* %12 monotonic, align 2
  %14 = icmp eq i16 %13, 151
  br i1 %14, label %15, label %21

15:                                               ; preds = %3
  %16 = tail call i64* @_ZN2v88internal19SmallOrderedHashSet3AddEPNS0_7IsolateENS0_6HandleIS1_EENS4_INS0_6ObjectEEE(%"class.v8::internal::Isolate"* %0, i64* %1, i64* %2)
  %17 = icmp eq i64* %16, null
  br i1 %17, label %18, label %24

18:                                               ; preds = %15
  %19 = tail call i64* @_ZN2v88internal21OrderedHashSetHandler20AdjustRepresentationEPNS0_7IsolateENS0_6HandleINS0_19SmallOrderedHashSetEEE(%"class.v8::internal::Isolate"* %0, i64* %1)
  %20 = icmp eq i64* %19, null
  br i1 %20, label %24, label %21

21:                                               ; preds = %18, %3
  %22 = phi i64* [ %1, %3 ], [ %19, %18 ]
  %23 = tail call i64* @_ZN2v88internal14OrderedHashSet3AddEPNS0_7IsolateENS0_6HandleIS1_EENS4_INS0_6ObjectEEE(%"class.v8::internal::Isolate"* %0, i64* %22, i64* %2)
  br label %24

24:                                               ; preds = %18, %15, %21
  %25 = phi i64* [ %23, %21 ], [ null, %18 ], [ %16, %15 ]
  ret i64* %25
}

; Function Attrs: nounwind ssp uwtable
define hidden i64* @_ZN2v88internal28OrderedNameDictionaryHandler3AddEPNS0_7IsolateENS0_6HandleINS0_10HeapObjectEEENS4_INS0_4NameEEENS4_INS0_6ObjectEEENS0_15PropertyDetailsE(%"class.v8::internal::Isolate"*, i64*, i64*, i64*, i32) local_unnamed_addr #0 align 2 {
  %6 = load i64, i64* %1, align 8
  %7 = and i64 %6, -4294967296
  %8 = add i64 %6, -1
  %9 = inttoptr i64 %8 to i32*
  %10 = load atomic i32, i32* %9 monotonic, align 4
  %11 = zext i32 %10 to i64
  %12 = or i64 %7, %11
  %13 = add i64 %12, 7
  %14 = inttoptr i64 %13 to i16*
  %15 = load atomic i16, i16* %14 monotonic, align 2
  %16 = icmp eq i16 %15, 152
  br i1 %16, label %17, label %23

17:                                               ; preds = %5
  %18 = tail call i64* @_ZN2v88internal26SmallOrderedNameDictionary3AddEPNS0_7IsolateENS0_6HandleIS1_EENS4_INS0_4NameEEENS4_INS0_6ObjectEEENS0_15PropertyDetailsE(%"class.v8::internal::Isolate"* %0, i64* %1, i64* %2, i64* %3, i32 %4)
  %19 = icmp eq i64* %18, null
  br i1 %19, label %20, label %26

20:                                               ; preds = %17
  %21 = tail call i64* @_ZN2v88internal28OrderedNameDictionaryHandler20AdjustRepresentationEPNS0_7IsolateENS0_6HandleINS0_26SmallOrderedNameDictionaryEEE(%"class.v8::internal::Isolate"* %0, i64* %1)
  %22 = icmp eq i64* %21, null
  br i1 %22, label %26, label %23

23:                                               ; preds = %20, %5
  %24 = phi i64* [ %1, %5 ], [ %21, %20 ]
  %25 = tail call i64* @_ZN2v88internal21OrderedNameDictionary3AddINS0_7IsolateEEENS0_11MaybeHandleIS1_EEPT_NS0_6HandleIS1_EENS8_INS0_4NameEEENS8_INS0_6ObjectEEENS0_15PropertyDetailsE(%"class.v8::internal::Isolate"* %0, i64* %24, i64* %2, i64* %3, i32 %4)
  br label %26

26:                                               ; preds = %20, %17, %23
  %27 = phi i64* [ %25, %23 ], [ null, %20 ], [ %18, %17 ]
  ret i64* %27
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal28OrderedNameDictionaryHandler8SetEntryENS0_10HeapObjectENS0_13InternalIndexENS0_6ObjectES4_NS0_15PropertyDetailsE(i64, i64, i64, i64, i32) local_unnamed_addr #0 align 2 {
  %6 = alloca %"class.v8::internal::SmallOrderedNameDictionary", align 8
  %7 = alloca %"class.v8::internal::OrderedNameDictionary", align 8
  %8 = and i64 %0, -4294967296
  %9 = add i64 %0, -1
  %10 = inttoptr i64 %9 to i32*
  %11 = load atomic i32, i32* %10 monotonic, align 4
  %12 = zext i32 %11 to i64
  %13 = or i64 %8, %12
  %14 = add i64 %13, 7
  %15 = inttoptr i64 %14 to i16*
  %16 = load atomic i16, i16* %15 monotonic, align 2
  %17 = icmp eq i16 %16, 152
  br i1 %17, label %18, label %21

18:                                               ; preds = %5
  %19 = bitcast %"class.v8::internal::SmallOrderedNameDictionary"* %6 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %19) #7
  %20 = getelementptr inbounds %"class.v8::internal::SmallOrderedNameDictionary", %"class.v8::internal::SmallOrderedNameDictionary"* %6, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %0, i64* %20, align 8
  call void @_ZN2v88internal26SmallOrderedNameDictionary8SetEntryENS0_13InternalIndexENS0_6ObjectES3_NS0_15PropertyDetailsE(%"class.v8::internal::SmallOrderedNameDictionary"* nonnull %6, i64 %1, i64 %2, i64 %3, i32 %4)
  br label %24

21:                                               ; preds = %5
  %22 = bitcast %"class.v8::internal::OrderedNameDictionary"* %7 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %22) #7
  %23 = getelementptr inbounds %"class.v8::internal::OrderedNameDictionary", %"class.v8::internal::OrderedNameDictionary"* %7, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %0, i64* %23, align 8
  call void @_ZN2v88internal21OrderedNameDictionary8SetEntryENS0_13InternalIndexENS0_6ObjectES3_NS0_15PropertyDetailsE(%"class.v8::internal::OrderedNameDictionary"* nonnull %7, i64 %1, i64 %2, i64 %3, i32 %4)
  br label %24

24:                                               ; preds = %21, %18
  %25 = phi i8* [ %22, %21 ], [ %19, %18 ]
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %25) #7
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden i64 @_ZN2v88internal28OrderedNameDictionaryHandler9FindEntryEPNS0_7IsolateENS0_10HeapObjectENS0_4NameE(%"class.v8::internal::Isolate"* nocapture readnone, i64, i64) local_unnamed_addr #0 align 2 {
  %4 = and i64 %1, -4294967296
  %5 = add i64 %1, -1
  %6 = inttoptr i64 %5 to i32*
  %7 = load atomic i32, i32* %6 monotonic, align 4
  %8 = zext i32 %7 to i64
  %9 = or i64 %4, %8
  %10 = add i64 %9, 7
  %11 = inttoptr i64 %10 to i16*
  %12 = load atomic i16, i16* %11 monotonic, align 2
  %13 = icmp eq i16 %12, 152
  br i1 %13, label %14, label %54

14:                                               ; preds = %3
  %15 = add i64 %2, 3
  %16 = inttoptr i64 %15 to i32*
  %17 = load i32, i32* %16, align 4
  %18 = lshr i32 %17, 2
  %19 = add i64 %1, 9
  %20 = inttoptr i64 %19 to i8*
  %21 = load i8, i8* %20, align 1
  %22 = zext i8 %21 to i32
  %23 = add nuw nsw i32 %22, 1073741823
  %24 = and i32 %23, %18
  %25 = mul nuw nsw i32 %22, 24
  %26 = add nuw nsw i32 %25, 12
  %27 = add nuw nsw i32 %26, %24
  %28 = zext i32 %27 to i64
  %29 = add i64 %5, %28
  %30 = inttoptr i64 %29 to i8*
  %31 = load i8, i8* %30, align 1
  %32 = icmp eq i8 %31, -1
  br i1 %32, label %107, label %33

33:                                               ; preds = %14
  %34 = trunc i64 %2 to i32
  %35 = add nuw nsw i32 %26, %22
  br label %36

36:                                               ; preds = %46, %33
  %37 = phi i8 [ %31, %33 ], [ %52, %46 ]
  %38 = zext i8 %37 to i64
  %39 = mul nuw nsw i64 %38, 51539607552
  %40 = add nuw nsw i64 %39, 51539607552
  %41 = lshr exact i64 %40, 32
  %42 = add i64 %41, %5
  %43 = inttoptr i64 %42 to i32*
  %44 = load i32, i32* %43, align 4
  %45 = icmp eq i32 %44, %34
  br i1 %45, label %107, label %46

46:                                               ; preds = %36
  %47 = zext i8 %37 to i32
  %48 = add nuw nsw i32 %35, %47
  %49 = zext i32 %48 to i64
  %50 = add i64 %5, %49
  %51 = inttoptr i64 %50 to i8*
  %52 = load i8, i8* %51, align 1
  %53 = icmp eq i8 %52, -1
  br i1 %53, label %107, label %36

54:                                               ; preds = %3
  %55 = add i64 %1, 11
  %56 = inttoptr i64 %55 to i32*
  %57 = load atomic i32, i32* %56 monotonic, align 4
  %58 = icmp ult i32 %57, 2
  br i1 %58, label %107, label %59

59:                                               ; preds = %54
  %60 = add i64 %2, 3
  %61 = inttoptr i64 %60 to i32*
  %62 = load i32, i32* %61, align 4
  %63 = add i64 %1, 19
  %64 = inttoptr i64 %63 to i32*
  %65 = load atomic i32, i32* %64 monotonic, align 4
  %66 = lshr i32 %65, 1
  %67 = shl i32 %66, 2
  %68 = add i32 %67, -4
  %69 = and i32 %68, %62
  %70 = add i32 %69, 16
  %71 = sext i32 %70 to i64
  %72 = add i64 %1, 7
  %73 = add i64 %72, %71
  %74 = inttoptr i64 %73 to i32*
  %75 = load atomic i32, i32* %74 monotonic, align 4
  %76 = ashr i32 %75, 1
  %77 = icmp eq i32 %76, -1
  br i1 %77, label %107, label %78

78:                                               ; preds = %59
  %79 = trunc i64 %2 to i32
  br label %80

80:                                               ; preds = %93, %78
  %81 = phi i32 [ %76, %78 ], [ %103, %93 ]
  %82 = load atomic i32, i32* %64 monotonic, align 4
  %83 = lshr i32 %82, 1
  %84 = shl i32 %81, 2
  %85 = add i32 %84, 4
  %86 = add i32 %83, %85
  %87 = shl i32 %86, 2
  %88 = sext i32 %87 to i64
  %89 = add i64 %72, %88
  %90 = inttoptr i64 %89 to i32*
  %91 = load atomic i32, i32* %90 monotonic, align 4
  %92 = icmp eq i32 %91, %79
  br i1 %92, label %105, label %93

93:                                               ; preds = %80
  %94 = load atomic i32, i32* %64 monotonic, align 4
  %95 = lshr i32 %94, 1
  %96 = add i32 %95, %85
  %97 = shl i32 %96, 2
  %98 = add i32 %97, 12
  %99 = sext i32 %98 to i64
  %100 = add i64 %72, %99
  %101 = inttoptr i64 %100 to i32*
  %102 = load atomic i32, i32* %101 monotonic, align 4
  %103 = ashr i32 %102, 1
  %104 = icmp eq i32 %103, -1
  br i1 %104, label %107, label %80

105:                                              ; preds = %80
  %106 = sext i32 %81 to i64
  br label %107

107:                                              ; preds = %93, %46, %36, %105, %59, %54, %14
  %108 = phi i64 [ -1, %14 ], [ -1, %54 ], [ %106, %105 ], [ -1, %59 ], [ -1, %46 ], [ %38, %36 ], [ -1, %93 ]
  ret i64 %108
}

; Function Attrs: nounwind ssp uwtable
define hidden i64 @_ZN2v88internal28OrderedNameDictionaryHandler7ValueAtENS0_10HeapObjectENS0_13InternalIndexE(i64, i64) local_unnamed_addr #0 align 2 {
  %3 = and i64 %0, -4294967296
  %4 = add i64 %0, -1
  %5 = inttoptr i64 %4 to i32*
  %6 = load atomic i32, i32* %5 monotonic, align 4
  %7 = zext i32 %6 to i64
  %8 = or i64 %3, %7
  %9 = add i64 %8, 7
  %10 = inttoptr i64 %9 to i16*
  %11 = load atomic i16, i16* %10 monotonic, align 2
  %12 = icmp eq i16 %11, 152
  br i1 %12, label %13, label %19

13:                                               ; preds = %2
  %14 = mul i64 %1, 51539607552
  %15 = ashr exact i64 %14, 32
  %16 = add i64 %0, 15
  %17 = add i64 %16, %15
  %18 = inttoptr i64 %17 to i32*
  br label %35

19:                                               ; preds = %2
  %20 = trunc i64 %1 to i32
  %21 = add i64 %0, 19
  %22 = inttoptr i64 %21 to i32*
  %23 = load atomic i32, i32* %22 monotonic, align 4
  %24 = lshr i32 %23, 1
  %25 = shl i32 %20, 2
  %26 = add i32 %25, 4
  %27 = add i32 %26, %24
  %28 = shl i32 %27, 2
  %29 = add i32 %28, 4
  %30 = sext i32 %29 to i64
  %31 = add i64 %0, 7
  %32 = add i64 %31, %30
  %33 = inttoptr i64 %32 to i32*
  %34 = load atomic i32, i32* %33 monotonic, align 4
  br label %35

35:                                               ; preds = %19, %13
  %36 = phi i32* [ %18, %13 ], [ %33, %19 ]
  %37 = load i32, i32* %36, align 4
  %38 = zext i32 %37 to i64
  %39 = or i64 %3, %38
  ret i64 %39
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal28OrderedNameDictionaryHandler10ValueAtPutENS0_10HeapObjectENS0_13InternalIndexENS0_6ObjectE(i64, i64, i64) local_unnamed_addr #0 align 2 {
  %4 = and i64 %0, -4294967296
  %5 = add i64 %0, -1
  %6 = inttoptr i64 %5 to i32*
  %7 = load atomic i32, i32* %6 monotonic, align 4
  %8 = zext i32 %7 to i64
  %9 = or i64 %4, %8
  %10 = add i64 %9, 7
  %11 = inttoptr i64 %10 to i16*
  %12 = load atomic i16, i16* %11 monotonic, align 2
  %13 = icmp eq i16 %12, 152
  br i1 %13, label %14, label %46

14:                                               ; preds = %3
  %15 = mul i64 %1, 51539607552
  %16 = ashr exact i64 %15, 32
  %17 = add i64 %0, 15
  %18 = add i64 %17, %16
  %19 = inttoptr i64 %18 to i32*
  %20 = trunc i64 %2 to i32
  store atomic volatile i32 %20, i32* %19 monotonic, align 4
  %21 = and i64 %2, 1
  %22 = icmp eq i64 %21, 0
  br i1 %22, label %87, label %23

23:                                               ; preds = %14
  %24 = and i64 %0, -262144
  %25 = or i64 %24, 8
  %26 = inttoptr i64 %25 to i64*
  %27 = load i64, i64* %26, align 8
  %28 = and i64 %27, 262144
  %29 = icmp eq i64 %28, 0
  br i1 %29, label %34, label %30

30:                                               ; preds = %23
  %31 = or i64 %24, 16
  %32 = inttoptr i64 %31 to %"class.v8::internal::Heap"**
  %33 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %32, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %33, i64 %0, i64 %18, i64 %2) #7
  br label %34

34:                                               ; preds = %30, %23
  %35 = and i64 %2, -262144
  %36 = or i64 %35, 8
  %37 = inttoptr i64 %36 to i64*
  %38 = load i64, i64* %37, align 8
  %39 = and i64 %38, 24
  %40 = icmp eq i64 %39, 0
  br i1 %40, label %87, label %41

41:                                               ; preds = %34
  %42 = load i64, i64* %26, align 8
  %43 = and i64 %42, 24
  %44 = icmp eq i64 %43, 0
  br i1 %44, label %45, label %87

45:                                               ; preds = %41
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %0, i64 %18, i64 %2) #7
  br label %87

46:                                               ; preds = %3
  %47 = trunc i64 %1 to i32
  %48 = add i64 %0, 19
  %49 = inttoptr i64 %48 to i32*
  %50 = load atomic i32, i32* %49 monotonic, align 4
  %51 = lshr i32 %50, 1
  %52 = shl i32 %47, 2
  %53 = add i32 %52, 4
  %54 = add i32 %53, %51
  %55 = shl i32 %54, 2
  %56 = add i32 %55, 4
  %57 = sext i32 %56 to i64
  %58 = add i64 %0, 7
  %59 = add i64 %58, %57
  %60 = inttoptr i64 %59 to i32*
  %61 = trunc i64 %2 to i32
  store atomic volatile i32 %61, i32* %60 monotonic, align 4
  %62 = and i64 %2, 1
  %63 = icmp eq i64 %62, 0
  br i1 %63, label %87, label %64

64:                                               ; preds = %46
  %65 = and i64 %0, -262144
  %66 = or i64 %65, 8
  %67 = inttoptr i64 %66 to i64*
  %68 = load i64, i64* %67, align 8
  %69 = and i64 %68, 262144
  %70 = icmp eq i64 %69, 0
  br i1 %70, label %75, label %71

71:                                               ; preds = %64
  %72 = or i64 %65, 16
  %73 = inttoptr i64 %72 to %"class.v8::internal::Heap"**
  %74 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %73, align 16
  tail call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %74, i64 %0, i64 %59, i64 %2) #7
  br label %75

75:                                               ; preds = %71, %64
  %76 = and i64 %2, -262144
  %77 = or i64 %76, 8
  %78 = inttoptr i64 %77 to i64*
  %79 = load i64, i64* %78, align 8
  %80 = and i64 %79, 24
  %81 = icmp eq i64 %80, 0
  br i1 %81, label %87, label %82

82:                                               ; preds = %75
  %83 = load i64, i64* %67, align 8
  %84 = and i64 %83, 24
  %85 = icmp eq i64 %84, 0
  br i1 %85, label %86, label %87

86:                                               ; preds = %82
  tail call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %0, i64 %59, i64 %2) #7
  br label %87

87:                                               ; preds = %86, %82, %75, %46, %45, %41, %34, %14
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @_ZN2v88internal28OrderedNameDictionaryHandler9DetailsAtENS0_10HeapObjectENS0_13InternalIndexE(i64, i64) local_unnamed_addr #0 align 2 {
  %3 = and i64 %0, -4294967296
  %4 = add i64 %0, -1
  %5 = inttoptr i64 %4 to i32*
  %6 = load atomic i32, i32* %5 monotonic, align 4
  %7 = zext i32 %6 to i64
  %8 = or i64 %3, %7
  %9 = add i64 %8, 7
  %10 = inttoptr i64 %9 to i16*
  %11 = load atomic i16, i16* %10 monotonic, align 2
  %12 = icmp eq i16 %11, 152
  br i1 %12, label %13, label %19

13:                                               ; preds = %2
  %14 = mul i64 %1, 51539607552
  %15 = ashr exact i64 %14, 32
  %16 = add i64 %0, 19
  %17 = add i64 %16, %15
  %18 = inttoptr i64 %17 to i32*
  br label %35

19:                                               ; preds = %2
  %20 = trunc i64 %1 to i32
  %21 = add i64 %0, 19
  %22 = inttoptr i64 %21 to i32*
  %23 = load atomic i32, i32* %22 monotonic, align 4
  %24 = lshr i32 %23, 1
  %25 = shl i32 %20, 2
  %26 = add i32 %25, 4
  %27 = add i32 %26, %24
  %28 = shl i32 %27, 2
  %29 = add i32 %28, 8
  %30 = sext i32 %29 to i64
  %31 = add i64 %0, 7
  %32 = add i64 %31, %30
  %33 = inttoptr i64 %32 to i32*
  %34 = load atomic i32, i32* %33 monotonic, align 4
  br label %35

35:                                               ; preds = %19, %13
  %36 = phi i32* [ %18, %13 ], [ %33, %19 ]
  %37 = load i32, i32* %36, align 4
  %38 = ashr i32 %37, 1
  ret i32 %38
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal28OrderedNameDictionaryHandler12DetailsAtPutENS0_10HeapObjectENS0_13InternalIndexENS0_15PropertyDetailsE(i64, i64, i32) local_unnamed_addr #0 align 2 {
  %4 = and i64 %0, -4294967296
  %5 = add i64 %0, -1
  %6 = inttoptr i64 %5 to i32*
  %7 = load atomic i32, i32* %6 monotonic, align 4
  %8 = zext i32 %7 to i64
  %9 = or i64 %4, %8
  %10 = add i64 %9, 7
  %11 = inttoptr i64 %10 to i16*
  %12 = load atomic i16, i16* %11 monotonic, align 2
  %13 = icmp eq i16 %12, 152
  br i1 %13, label %14, label %17

14:                                               ; preds = %3
  %15 = mul i64 %1, 51539607552
  %16 = ashr exact i64 %15, 32
  br label %29

17:                                               ; preds = %3
  %18 = trunc i64 %1 to i32
  %19 = add i64 %0, 19
  %20 = inttoptr i64 %19 to i32*
  %21 = load atomic i32, i32* %20 monotonic, align 4
  %22 = lshr i32 %21, 1
  %23 = shl i32 %18, 2
  %24 = add i32 %23, 4
  %25 = add i32 %24, %22
  %26 = shl i32 %25, 2
  %27 = add i32 %26, 8
  %28 = sext i32 %27 to i64
  br label %29

29:                                               ; preds = %17, %14
  %30 = phi i64 [ 7, %17 ], [ 19, %14 ]
  %31 = phi i64 [ %28, %17 ], [ %16, %14 ]
  %32 = shl i32 %2, 1
  %33 = add i64 %30, %0
  %34 = add i64 %33, %31
  %35 = inttoptr i64 %34 to i32*
  store atomic volatile i32 %32, i32* %35 monotonic, align 4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @_ZN2v88internal28OrderedNameDictionaryHandler4HashENS0_10HeapObjectE(i64) local_unnamed_addr #0 align 2 {
  %2 = and i64 %0, -4294967296
  %3 = add i64 %0, -1
  %4 = inttoptr i64 %3 to i32*
  %5 = load atomic i32, i32* %4 monotonic, align 4
  %6 = zext i32 %5 to i64
  %7 = or i64 %2, %6
  %8 = add i64 %7, 7
  %9 = inttoptr i64 %8 to i16*
  %10 = load atomic i16, i16* %9 monotonic, align 2
  %11 = icmp eq i16 %10, 152
  br i1 %11, label %12, label %16

12:                                               ; preds = %1
  %13 = add i64 %0, 3
  %14 = inttoptr i64 %13 to i32*
  %15 = load i32, i32* %14, align 4
  br label %21

16:                                               ; preds = %1
  %17 = add i64 %0, 7
  %18 = inttoptr i64 %17 to i32*
  %19 = load atomic i32, i32* %18 monotonic, align 4
  %20 = ashr i32 %19, 1
  br label %21

21:                                               ; preds = %16, %12
  %22 = phi i32 [ %15, %12 ], [ %20, %16 ]
  ret i32 %22
}

; Function Attrs: nounwind ssp uwtable
define hidden void @_ZN2v88internal28OrderedNameDictionaryHandler7SetHashENS0_10HeapObjectEi(i64, i32) local_unnamed_addr #0 align 2 {
  %3 = and i64 %0, -4294967296
  %4 = add i64 %0, -1
  %5 = inttoptr i64 %4 to i32*
  %6 = load atomic i32, i32* %5 monotonic, align 4
  %7 = zext i32 %6 to i64
  %8 = or i64 %3, %7
  %9 = add i64 %8, 7
  %10 = inttoptr i64 %9 to i16*
  %11 = load atomic i16, i16* %10 monotonic, align 2
  %12 = icmp eq i16 %11, 152
  br i1 %12, label %13, label %16

13:                                               ; preds = %2
  %14 = add i64 %0, 3
  %15 = inttoptr i64 %14 to i32*
  store i32 %1, i32* %15, align 4
  br label %20

16:                                               ; preds = %2
  %17 = shl i32 %1, 1
  %18 = add i64 %0, 7
  %19 = inttoptr i64 %18 to i32*
  store atomic volatile i32 %17, i32* %19 monotonic, align 4
  br label %20

20:                                               ; preds = %16, %13
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden i64 @_ZN2v88internal28OrderedNameDictionaryHandler5KeyAtENS0_10HeapObjectENS0_13InternalIndexE(i64, i64) local_unnamed_addr #0 align 2 {
  %3 = and i64 %0, -4294967296
  %4 = add i64 %0, -1
  %5 = inttoptr i64 %4 to i32*
  %6 = load atomic i32, i32* %5 monotonic, align 4
  %7 = zext i32 %6 to i64
  %8 = or i64 %3, %7
  %9 = add i64 %8, 7
  %10 = inttoptr i64 %9 to i16*
  %11 = load atomic i16, i16* %10 monotonic, align 2
  %12 = icmp eq i16 %11, 152
  br i1 %12, label %13, label %19

13:                                               ; preds = %2
  %14 = mul i64 %1, 51539607552
  %15 = add i64 %14, 51539607552
  %16 = ashr exact i64 %15, 32
  %17 = add i64 %4, %16
  %18 = inttoptr i64 %17 to i32*
  br label %34

19:                                               ; preds = %2
  %20 = trunc i64 %1 to i32
  %21 = add i64 %0, 19
  %22 = inttoptr i64 %21 to i32*
  %23 = load atomic i32, i32* %22 monotonic, align 4
  %24 = lshr i32 %23, 1
  %25 = shl i32 %20, 2
  %26 = add i32 %25, 4
  %27 = add i32 %26, %24
  %28 = shl i32 %27, 2
  %29 = sext i32 %28 to i64
  %30 = add i64 %0, 7
  %31 = add i64 %30, %29
  %32 = inttoptr i64 %31 to i32*
  %33 = load atomic i32, i32* %32 monotonic, align 4
  br label %34

34:                                               ; preds = %19, %13
  %35 = phi i32* [ %18, %13 ], [ %32, %19 ]
  %36 = load i32, i32* %35, align 4
  %37 = zext i32 %36 to i64
  %38 = or i64 %3, %37
  ret i64 %38
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @_ZN2v88internal28OrderedNameDictionaryHandler16NumberOfElementsENS0_10HeapObjectE(i64) local_unnamed_addr #0 align 2 {
  %2 = and i64 %0, -4294967296
  %3 = add i64 %0, -1
  %4 = inttoptr i64 %3 to i32*
  %5 = load atomic i32, i32* %4 monotonic, align 4
  %6 = zext i32 %5 to i64
  %7 = or i64 %2, %6
  %8 = add i64 %7, 7
  %9 = inttoptr i64 %8 to i16*
  %10 = load atomic i16, i16* %9 monotonic, align 2
  %11 = icmp eq i16 %10, 152
  br i1 %11, label %12, label %17

12:                                               ; preds = %1
  %13 = add i64 %0, 7
  %14 = inttoptr i64 %13 to i8*
  %15 = load i8, i8* %14, align 1
  %16 = zext i8 %15 to i32
  br label %22

17:                                               ; preds = %1
  %18 = add i64 %0, 11
  %19 = inttoptr i64 %18 to i32*
  %20 = load atomic i32, i32* %19 monotonic, align 4
  %21 = ashr i32 %20, 1
  br label %22

22:                                               ; preds = %17, %12
  %23 = phi i32 [ %16, %12 ], [ %21, %17 ]
  ret i32 %23
}

; Function Attrs: nounwind ssp uwtable
define hidden i32 @_ZN2v88internal28OrderedNameDictionaryHandler8CapacityENS0_10HeapObjectE(i64) local_unnamed_addr #0 align 2 {
  %2 = and i64 %0, -4294967296
  %3 = add i64 %0, -1
  %4 = inttoptr i64 %3 to i32*
  %5 = load atomic i32, i32* %4 monotonic, align 4
  %6 = zext i32 %5 to i64
  %7 = or i64 %2, %6
  %8 = add i64 %7, 7
  %9 = inttoptr i64 %8 to i16*
  %10 = load atomic i16, i16* %9 monotonic, align 2
  %11 = icmp eq i16 %10, 152
  br i1 %11, label %12, label %18

12:                                               ; preds = %1
  %13 = add i64 %0, 9
  %14 = inttoptr i64 %13 to i8*
  %15 = load i8, i8* %14, align 1
  %16 = zext i8 %15 to i32
  %17 = shl nuw nsw i32 %16, 1
  br label %23

18:                                               ; preds = %1
  %19 = add i64 %0, 19
  %20 = inttoptr i64 %19 to i32*
  %21 = load atomic i32, i32* %20 monotonic, align 4
  %22 = and i32 %21, -2
  br label %23

23:                                               ; preds = %18, %12
  %24 = phi i32 [ %17, %12 ], [ %22, %18 ]
  ret i32 %24
}

; Function Attrs: nounwind ssp uwtable
define hidden i64* @_ZN2v88internal28OrderedNameDictionaryHandler6ShrinkEPNS0_7IsolateENS0_6HandleINS0_10HeapObjectEEE(%"class.v8::internal::Isolate"*, i64*) local_unnamed_addr #0 align 2 {
  %3 = load i64, i64* %1, align 8
  %4 = and i64 %3, -4294967296
  %5 = add i64 %3, -1
  %6 = inttoptr i64 %5 to i32*
  %7 = load atomic i32, i32* %6 monotonic, align 4
  %8 = zext i32 %7 to i64
  %9 = or i64 %4, %8
  %10 = add i64 %9, 7
  %11 = inttoptr i64 %10 to i16*
  %12 = load atomic i16, i16* %11 monotonic, align 2
  %13 = icmp eq i16 %12, 152
  br i1 %13, label %14, label %33

14:                                               ; preds = %2
  %15 = add i64 %3, 7
  %16 = inttoptr i64 %15 to i8*
  %17 = load i8, i8* %16, align 1
  %18 = add i64 %3, 9
  %19 = inttoptr i64 %18 to i8*
  %20 = load i8, i8* %19, align 1
  %21 = lshr i8 %20, 1
  %22 = icmp ugt i8 %21, %17
  br i1 %22, label %23, label %58

23:                                               ; preds = %14
  %24 = zext i8 %20 to i32
  %25 = tail call i64* @_ZN2v88internal21SmallOrderedHashTableINS0_26SmallOrderedNameDictionaryEE6RehashEPNS0_7IsolateENS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"* %0, i64* %1, i32 %24) #7
  %26 = load i64, i64* %25, align 8
  %27 = load i64, i64* %1, align 8
  %28 = add i64 %27, 3
  %29 = inttoptr i64 %28 to i32*
  %30 = load i32, i32* %29, align 4
  %31 = add i64 %26, 3
  %32 = inttoptr i64 %31 to i32*
  store i32 %30, i32* %32, align 4
  br label %58

33:                                               ; preds = %2
  %34 = add i64 %3, 11
  %35 = inttoptr i64 %34 to i32*
  %36 = load atomic i32, i32* %35 monotonic, align 4
  %37 = ashr i32 %36, 1
  %38 = add i64 %3, 19
  %39 = inttoptr i64 %38 to i32*
  %40 = load atomic i32, i32* %39 monotonic, align 4
  %41 = ashr i32 %40, 2
  %42 = icmp slt i32 %37, %41
  br i1 %42, label %43, label %58

43:                                               ; preds = %33
  %44 = and i32 %40, -2
  %45 = sdiv i32 %44, 2
  %46 = tail call i64* @_ZN2v88internal16OrderedHashTableINS0_21OrderedNameDictionaryELi3EE6RehashINS0_7IsolateEEENS0_11MaybeHandleIS2_EEPT_NS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"* %0, i64* %1, i32 %45) #7
  %47 = icmp eq i64* %46, null
  br i1 %47, label %48, label %49

48:                                               ; preds = %43
  tail call void (i8*, ...) @_Z8V8_FatalPKcz(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str, i64 0, i64 0), i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.2, i64 0, i64 0)) #8
  unreachable

49:                                               ; preds = %43
  %50 = load i64, i64* %46, align 8
  %51 = load i64, i64* %1, align 8
  %52 = add i64 %51, 7
  %53 = inttoptr i64 %52 to i32*
  %54 = load atomic i32, i32* %53 monotonic, align 4
  %55 = and i32 %54, -2
  %56 = add i64 %50, 7
  %57 = inttoptr i64 %56 to i32*
  store atomic volatile i32 %55, i32* %57 monotonic, align 4
  br label %58

58:                                               ; preds = %49, %33, %23, %14
  %59 = phi i64* [ %25, %23 ], [ %1, %14 ], [ %46, %49 ], [ %1, %33 ]
  ret i64* %59
}

; Function Attrs: nounwind ssp uwtable
define hidden i64* @_ZN2v88internal28OrderedNameDictionaryHandler11DeleteEntryEPNS0_7IsolateENS0_6HandleINS0_10HeapObjectEEENS0_13InternalIndexE(%"class.v8::internal::Isolate"*, i64*, i64) local_unnamed_addr #0 align 2 {
  %4 = alloca %"class.v8::internal::Handle<v8::internal::SmallOrderedNameDictionary>::ObjectRef", align 8
  %5 = load i64, i64* %1, align 8
  %6 = and i64 %5, -4294967296
  %7 = add i64 %5, -1
  %8 = inttoptr i64 %7 to i32*
  %9 = load atomic i32, i32* %8 monotonic, align 4
  %10 = zext i32 %9 to i64
  %11 = or i64 %6, %10
  %12 = add i64 %11, 7
  %13 = inttoptr i64 %12 to i16*
  %14 = load atomic i16, i16* %13 monotonic, align 2
  %15 = icmp eq i16 %14, 152
  br i1 %15, label %16, label %51

16:                                               ; preds = %3
  %17 = getelementptr inbounds %"class.v8::internal::Isolate", %"class.v8::internal::Isolate"* %0, i64 0, i32 0, i32 7, i32 0, i64 5
  %18 = load i64, i64* %17, align 8
  %19 = bitcast %"class.v8::internal::Handle<v8::internal::SmallOrderedNameDictionary>::ObjectRef"* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %19) #7
  %20 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::SmallOrderedNameDictionary>::ObjectRef", %"class.v8::internal::Handle<v8::internal::SmallOrderedNameDictionary>::ObjectRef"* %4, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %5, i64* %20, align 8
  %21 = getelementptr inbounds %"class.v8::internal::Handle<v8::internal::SmallOrderedNameDictionary>::ObjectRef", %"class.v8::internal::Handle<v8::internal::SmallOrderedNameDictionary>::ObjectRef"* %4, i64 0, i32 0
  call void @_ZN2v88internal26SmallOrderedNameDictionary8SetEntryENS0_13InternalIndexENS0_6ObjectES3_NS0_15PropertyDetailsE(%"class.v8::internal::SmallOrderedNameDictionary"* nonnull %21, i64 %2, i64 %18, i64 %18, i32 0) #7
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %19) #7
  %22 = load i64, i64* %1, align 8
  %23 = add i64 %22, 7
  %24 = inttoptr i64 %23 to i8*
  %25 = load i8, i8* %24, align 1
  %26 = add i8 %25, -1
  store i8 %26, i8* %24, align 1
  %27 = load i64, i64* %1, align 8
  %28 = add i64 %27, 8
  %29 = inttoptr i64 %28 to i8*
  %30 = load i8, i8* %29, align 1
  %31 = add i8 %30, 1
  store i8 %31, i8* %29, align 1
  %32 = load i64, i64* %1, align 8
  %33 = add i64 %32, 7
  %34 = inttoptr i64 %33 to i8*
  %35 = load i8, i8* %34, align 1
  %36 = add i64 %32, 9
  %37 = inttoptr i64 %36 to i8*
  %38 = load i8, i8* %37, align 1
  %39 = lshr i8 %38, 1
  %40 = icmp ugt i8 %39, %35
  br i1 %40, label %41, label %53

41:                                               ; preds = %16
  %42 = zext i8 %38 to i32
  %43 = tail call i64* @_ZN2v88internal21SmallOrderedHashTableINS0_26SmallOrderedNameDictionaryEE6RehashEPNS0_7IsolateENS0_6HandleIS2_EEi(%"class.v8::internal::Isolate"* %0, i64* %1, i32 %42) #7
  %44 = load i64, i64* %43, align 8
  %45 = load i64, i64* %1, align 8
  %46 = add i64 %45, 3
  %47 = inttoptr i64 %46 to i32*
  %48 = load i32, i32* %47, align 4
  %49 = add i64 %44, 3
  %50 = inttoptr i64 %49 to i32*
  store i32 %48, i32* %50, align 4
  br label %53

51:                                               ; preds = %3
  %52 = tail call i64* @_ZN2v88internal21OrderedNameDictionary11DeleteEntryEPNS0_7IsolateENS0_6HandleIS1_EENS0_13InternalIndexE(%"class.v8::internal::Isolate"* %0, i64* %1, i64 %2)
  br label %53

53:                                               ; preds = %41, %16, %51
  %54 = phi i64* [ %52, %51 ], [ %43, %41 ], [ %1, %16 ]
  ret i64* %54
}

declare void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"*, i64, i64, i64) local_unnamed_addr #2

declare void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64, i64, i64) local_unnamed_addr #2

; Function Attrs: inlinehint nounwind ssp uwtable
define linkonce_odr hidden i64 @_ZN2v88internal6Object13GetSimpleHashES1_(i64) local_unnamed_addr #4 comdat align 2 {
  %2 = alloca %"class.v8::internal::String", align 8
  %3 = alloca %"class.v8::internal::String", align 8
  %4 = alloca %"class.v8::internal::SharedFunctionInfo", align 8
  %5 = and i64 %0, 1
  %6 = icmp eq i64 %5, 0
  br i1 %6, label %7, label %24

7:                                                ; preds = %1
  %8 = trunc i64 %0 to i32
  %9 = ashr i32 %8, 1
  %10 = xor i32 %9, -1
  %11 = shl i32 %9, 15
  %12 = add i32 %11, %10
  %13 = lshr i32 %12, 12
  %14 = xor i32 %13, %12
  %15 = mul i32 %14, 5
  %16 = lshr i32 %15, 4
  %17 = xor i32 %16, %15
  %18 = mul i32 %17, 2057
  %19 = lshr i32 %18, 16
  %20 = and i32 %18, 1073741823
  %21 = xor i32 %20, %19
  %22 = shl nuw nsw i32 %21, 1
  %23 = zext i32 %22 to i64
  br label %180

24:                                               ; preds = %1
  %25 = and i64 %0, -4294967296
  %26 = add i64 %0, -1
  %27 = inttoptr i64 %26 to i32*
  %28 = load atomic i32, i32* %27 monotonic, align 4
  %29 = zext i32 %28 to i64
  %30 = or i64 %25, %29
  %31 = add i64 %30, 7
  %32 = inttoptr i64 %31 to i16*
  %33 = load atomic i16, i16* %32 monotonic, align 2
  %34 = icmp eq i16 %33, 66
  br i1 %34, label %35, label %81

35:                                               ; preds = %24
  %36 = add i64 %0, 3
  %37 = inttoptr i64 %36 to double*
  %38 = load double, double* %37, align 1
  %39 = fcmp uno double %38, 0.000000e+00
  br i1 %39, label %180, label %40

40:                                               ; preds = %35
  %41 = fcmp oge double %38, 0xC1E0000000000000
  %42 = fcmp ole double %38, 0x41DFFFFFFFC00000
  %43 = and i1 %41, %42
  br i1 %43, label %44, label %61

44:                                               ; preds = %40
  %45 = fptosi double %38 to i32
  %46 = sitofp i32 %45 to double
  %47 = fcmp oeq double %38, %46
  br i1 %47, label %48, label %61

48:                                               ; preds = %44
  %49 = xor i32 %45, -1
  %50 = shl i32 %45, 15
  %51 = add i32 %50, %49
  %52 = lshr i32 %51, 12
  %53 = xor i32 %52, %51
  %54 = mul i32 %53, 5
  %55 = lshr i32 %54, 4
  %56 = xor i32 %55, %54
  %57 = mul i32 %56, 2057
  %58 = lshr i32 %57, 16
  %59 = and i32 %57, 1073741823
  %60 = xor i32 %59, %58
  br label %76

61:                                               ; preds = %44, %40
  %62 = bitcast double %38 to i64
  %63 = xor i64 %62, -1
  %64 = shl i64 %62, 18
  %65 = add i64 %64, %63
  %66 = lshr i64 %65, 31
  %67 = xor i64 %66, %65
  %68 = mul i64 %67, 21
  %69 = lshr i64 %68, 11
  %70 = xor i64 %69, %68
  %71 = mul i64 %70, 65
  %72 = lshr i64 %71, 22
  %73 = xor i64 %72, %71
  %74 = trunc i64 %73 to i32
  %75 = and i32 %74, 1073741823
  br label %76

76:                                               ; preds = %61, %48
  %77 = phi i32 [ %60, %48 ], [ %75, %61 ]
  %78 = shl nsw i32 %77, 1
  %79 = and i32 %78, 2147483646
  %80 = zext i32 %79 to i64
  br label %180

81:                                               ; preds = %24
  %82 = load atomic i32, i32* %27 monotonic, align 4
  %83 = zext i32 %82 to i64
  %84 = or i64 %25, %83
  %85 = add i64 %84, 7
  %86 = inttoptr i64 %85 to i16*
  %87 = load atomic i16, i16* %86 monotonic, align 2
  %88 = icmp ult i16 %87, 65
  br i1 %88, label %89, label %105

89:                                               ; preds = %81
  %90 = add i64 %0, 3
  %91 = inttoptr i64 %90 to i32*
  %92 = load i32, i32* %91, align 4
  %93 = and i32 %92, 1
  %94 = icmp eq i32 %93, 0
  br i1 %94, label %95, label %97

95:                                               ; preds = %89
  %96 = lshr i32 %92, 2
  br label %101

97:                                               ; preds = %89
  %98 = bitcast %"class.v8::internal::String"* %2 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %98) #7
  %99 = getelementptr inbounds %"class.v8::internal::String", %"class.v8::internal::String"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %0, i64* %99, align 8
  %100 = call i32 @_ZN2v88internal6String17ComputeAndSetHashEv(%"class.v8::internal::String"* nonnull %2) #7
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %98) #7
  br label %101

101:                                              ; preds = %95, %97
  %102 = phi i32 [ %96, %95 ], [ %100, %97 ]
  %103 = sext i32 %102 to i64
  %104 = shl nsw i64 %103, 1
  br label %180

105:                                              ; preds = %81
  %106 = load atomic i32, i32* %27 monotonic, align 4
  %107 = zext i32 %106 to i64
  %108 = or i64 %25, %107
  %109 = add i64 %108, 7
  %110 = inttoptr i64 %109 to i16*
  %111 = load atomic i16, i16* %110 monotonic, align 2
  %112 = icmp eq i16 %111, 67
  br i1 %112, label %113, label %134

113:                                              ; preds = %105
  %114 = add i64 %0, 11
  %115 = inttoptr i64 %114 to i32*
  %116 = load i32, i32* %115, align 4
  %117 = zext i32 %116 to i64
  %118 = or i64 %25, %117
  %119 = add i64 %118, 3
  %120 = inttoptr i64 %119 to i32*
  %121 = load i32, i32* %120, align 4
  %122 = and i32 %121, 1
  %123 = icmp eq i32 %122, 0
  br i1 %123, label %124, label %126

124:                                              ; preds = %113
  %125 = lshr i32 %121, 2
  br label %130

126:                                              ; preds = %113
  %127 = bitcast %"class.v8::internal::String"* %3 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %127) #7
  %128 = getelementptr inbounds %"class.v8::internal::String", %"class.v8::internal::String"* %3, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %118, i64* %128, align 8
  %129 = call i32 @_ZN2v88internal6String17ComputeAndSetHashEv(%"class.v8::internal::String"* nonnull %3) #7
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %127) #7
  br label %130

130:                                              ; preds = %124, %126
  %131 = phi i32 [ %125, %124 ], [ %129, %126 ]
  %132 = sext i32 %131 to i64
  %133 = shl nsw i64 %132, 1
  br label %180

134:                                              ; preds = %105
  %135 = load atomic i32, i32* %27 monotonic, align 4
  %136 = zext i32 %135 to i64
  %137 = or i64 %25, %136
  %138 = add i64 %137, 7
  %139 = inttoptr i64 %138 to i16*
  %140 = load atomic i16, i16* %139 monotonic, align 2
  %141 = icmp eq i16 %140, 65
  br i1 %141, label %142, label %165

142:                                              ; preds = %134
  %143 = add i64 %0, 3
  %144 = inttoptr i64 %143 to i32*
  %145 = load atomic i32, i32* %144 monotonic, align 4
  %146 = and i32 %145, 2147483646
  %147 = icmp eq i32 %146, 0
  br i1 %147, label %180, label %148

148:                                              ; preds = %142
  %149 = add i64 %0, 7
  %150 = inttoptr i64 %149 to i64*
  %151 = load i64, i64* %150, align 1
  %152 = xor i64 %151, -1
  %153 = shl i64 %151, 18
  %154 = add i64 %153, %152
  %155 = lshr i64 %154, 31
  %156 = xor i64 %155, %154
  %157 = mul i64 %156, 21
  %158 = lshr i64 %157, 11
  %159 = xor i64 %158, %157
  %160 = mul i64 %159, 65
  %161 = lshr i64 %160, 22
  %162 = xor i64 %161, %160
  %163 = shl i64 %162, 1
  %164 = and i64 %163, 2147483646
  br label %180

165:                                              ; preds = %134
  %166 = load atomic i32, i32* %27 monotonic, align 4
  %167 = zext i32 %166 to i64
  %168 = or i64 %25, %167
  %169 = add i64 %168, 7
  %170 = inttoptr i64 %169 to i16*
  %171 = load atomic i16, i16* %170 monotonic, align 2
  %172 = icmp eq i16 %171, 179
  br i1 %172, label %173, label %180

173:                                              ; preds = %165
  %174 = bitcast %"class.v8::internal::SharedFunctionInfo"* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %174) #7
  %175 = getelementptr inbounds %"class.v8::internal::SharedFunctionInfo", %"class.v8::internal::SharedFunctionInfo"* %4, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
  store i64 %0, i64* %175, align 8
  %176 = call i32 @_ZN2v88internal18SharedFunctionInfo4HashEv(%"class.v8::internal::SharedFunctionInfo"* nonnull %4) #7
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %174) #7
  %177 = shl i32 %176, 1
  %178 = and i32 %177, 2147483646
  %179 = zext i32 %178 to i64
  br label %180

180:                                              ; preds = %148, %142, %165, %35, %76, %173, %130, %101, %7
  %181 = phi i64 [ %23, %7 ], [ %104, %101 ], [ %133, %130 ], [ %179, %173 ], [ %80, %76 ], [ 2147483646, %35 ], [ %0, %165 ], [ %164, %148 ], [ 0, %142 ]
  ret i64 %181
}

declare i64 @_ZN2v88internal10JSReceiver15GetIdentityHashEv(%"class.v8::internal::JSReceiver"*) local_unnamed_addr #2

declare i32 @_ZN2v88internal18SharedFunctionInfo4HashEv(%"class.v8::internal::SharedFunctionInfo"*) local_unnamed_addr #2

declare i32 @_ZN2v88internal6String17ComputeAndSetHashEv(%"class.v8::internal::String"*) local_unnamed_addr #2

declare void @_ZN2v88internal11HandleScope16DeleteExtensionsEPNS0_7IsolateE(%"class.v8::internal::Isolate"*) local_unnamed_addr #2

declare void @_ZN2v88internal11HandleScope8ZapRangeEPmS2_(i64*, i64*) local_unnamed_addr #2

declare i64* @_ZN2v88internal7Factory12SizeToStringEmb(%"class.v8::internal::Factory"*, i64, i1 zeroext) local_unnamed_addr #2

declare i64* @_ZN2v88internal20CanonicalHandleScope6LookupEm(%"class.v8::internal::CanonicalHandleScope"*, i64) local_unnamed_addr #2

declare i64* @_ZN2v88internal11HandleScope6ExtendEPNS0_7IsolateE(%"class.v8::internal::Isolate"*) local_unnamed_addr #2

declare i64* @_ZN2v88internal11FactoryBaseINS0_7FactoryEE20NewFixedArrayWithMapENS0_6HandleINS0_3MapEEEiNS0_14AllocationTypeE(%"class.v8::internal::FactoryBase"*, i64*, i32, i8 zeroext) local_unnamed_addr #2

declare i32 @_ZN2v84base4bits21RoundUpToPowerOfTwo32Ej(i32) local_unnamed_addr #2

declare i64* @_ZN2v88internal11FactoryBaseINS0_12LocalFactoryEE20NewFixedArrayWithMapENS0_6HandleINS0_3MapEEEiNS0_14AllocationTypeE(%"class.v8::internal::FactoryBase.1048"*, i64*, i32, i8 zeroext) local_unnamed_addr #2

; Function Attrs: nounwind ssp uwtable
define linkonce_odr hidden i64* @_ZN2v88internal16OrderedHashTableINS0_21OrderedNameDictionaryELi3EE6RehashINS0_12LocalIsolateEEENS0_11MaybeHandleIS2_EEPT_NS0_6HandleIS2_EEi(%"class.v8::internal::LocalIsolate"*, i64*, i32) local_unnamed_addr #0 comdat align 2 {
  %4 = alloca %"class.v8::internal::JSReceiver", align 8
  %5 = load i64, i64* %1, align 8
  %6 = and i64 %5, -262144
  %7 = inttoptr i64 %6 to %"class.v8::internal::BasicMemoryChunk"*
  %8 = getelementptr inbounds %"class.v8::internal::BasicMemoryChunk", %"class.v8::internal::BasicMemoryChunk"* %7, i64 0, i32 1
  %9 = load i64, i64* %8, align 8
  %10 = icmp sgt i32 %2, 4
  %11 = select i1 %10, i32 %2, i32 4
  %12 = tail call i32 @_ZN2v84base4bits21RoundUpToPowerOfTwo32Ej(i32 %11) #7
  %13 = icmp sgt i32 %12, 14913080
  br i1 %13, label %321, label %14

14:                                               ; preds = %3
  %15 = and i64 %9, 24
  %16 = icmp eq i64 %15, 0
  %17 = zext i1 %16 to i8
  %18 = sdiv i32 %12, 2
  %19 = bitcast %"class.v8::internal::LocalIsolate"* %0 to %"class.v8::internal::FactoryBase.1048"*
  %20 = getelementptr inbounds %"class.v8::internal::LocalIsolate", %"class.v8::internal::LocalIsolate"* %0, i64 0, i32 0, i32 0, i32 0, i32 0
  %21 = load i64*, i64** %20, align 8
  %22 = getelementptr inbounds i64, i64* %21, i64 56
  %23 = add nsw i32 %18, 4
  %24 = shl i32 %12, 2
  %25 = add nsw i32 %23, %24
  %26 = tail call i64* @_ZN2v88internal11FactoryBaseINS0_12LocalFactoryEE20NewFixedArrayWithMapENS0_6HandleINS0_3MapEEEiNS0_14AllocationTypeE(%"class.v8::internal::FactoryBase.1048"* %19, i64* %22, i32 %25, i8 zeroext %17) #7
  %27 = icmp sgt i32 %12, 1
  %28 = load i64, i64* %26, align 8
  br i1 %27, label %29, label %75

29:                                               ; preds = %14
  %30 = zext i32 %18 to i64
  %31 = and i64 %30, 1
  %32 = and i32 %12, -2
  %33 = icmp eq i32 %32, 2
  br i1 %33, label %65, label %34

34:                                               ; preds = %29
  %35 = sub nsw i64 %30, %31
  br label %36

36:                                               ; preds = %36, %34
  %37 = phi i64 [ 0, %34 ], [ %56, %36 ]
  %38 = phi i64 [ %28, %34 ], [ %57, %36 ]
  %39 = phi i64 [ %35, %34 ], [ %58, %36 ]
  %40 = trunc i64 %37 to i32
  %41 = shl i32 %40, 2
  %42 = add i32 %41, 16
  %43 = sext i32 %42 to i64
  %44 = add i64 %38, 7
  %45 = add i64 %44, %43
  %46 = inttoptr i64 %45 to i32*
  store atomic volatile i32 -2, i32* %46 monotonic, align 4
  %47 = load i64, i64* %26, align 8
  %48 = trunc i64 %37 to i32
  %49 = shl i32 %48, 2
  %50 = or i32 %49, 4
  %51 = add i32 %50, 16
  %52 = sext i32 %51 to i64
  %53 = add i64 %47, 7
  %54 = add i64 %53, %52
  %55 = inttoptr i64 %54 to i32*
  store atomic volatile i32 -2, i32* %55 monotonic, align 4
  %56 = add nuw nsw i64 %37, 2
  %57 = load i64, i64* %26, align 8
  %58 = add i64 %39, -2
  %59 = icmp eq i64 %58, 0
  br i1 %59, label %60, label %36

60:                                               ; preds = %36
  %61 = trunc i64 %56 to i32
  %62 = shl i32 %61, 2
  %63 = add i32 %62, 16
  %64 = sext i32 %63 to i64
  br label %65

65:                                               ; preds = %60, %29
  %66 = phi i64 [ undef, %29 ], [ %57, %60 ]
  %67 = phi i64 [ 16, %29 ], [ %64, %60 ]
  %68 = phi i64 [ %28, %29 ], [ %57, %60 ]
  %69 = icmp eq i64 %31, 0
  br i1 %69, label %75, label %70

70:                                               ; preds = %65
  %71 = add i64 %68, 7
  %72 = add i64 %71, %67
  %73 = inttoptr i64 %72 to i32*
  store atomic volatile i32 -2, i32* %73 monotonic, align 4
  %74 = load i64, i64* %26, align 8
  br label %75

75:                                               ; preds = %70, %65, %14
  %76 = phi i64 [ %28, %14 ], [ %66, %65 ], [ %74, %70 ]
  %77 = shl nsw i32 %18, 1
  %78 = add i64 %76, 19
  %79 = inttoptr i64 %78 to i32*
  store atomic volatile i32 %77, i32* %79 monotonic, align 4
  %80 = load i64, i64* %26, align 8
  %81 = add i64 %80, 11
  %82 = inttoptr i64 %81 to i32*
  store atomic volatile i32 0, i32* %82 monotonic, align 4
  %83 = load i64, i64* %26, align 8
  %84 = add i64 %83, 15
  %85 = inttoptr i64 %84 to i32*
  store atomic volatile i32 0, i32* %85 monotonic, align 4
  %86 = icmp eq i64* %26, null
  br i1 %86, label %321, label %87

87:                                               ; preds = %75
  %88 = load i64, i64* %26, align 8
  %89 = add i64 %88, 7
  %90 = inttoptr i64 %89 to i32*
  store atomic volatile i32 0, i32* %90 monotonic, align 4
  %91 = load i64, i64* %26, align 8
  %92 = add i64 %91, 19
  %93 = inttoptr i64 %92 to i32*
  %94 = load atomic i32, i32* %93 monotonic, align 4
  %95 = load i64, i64* %1, align 8
  %96 = add i64 %95, 11
  %97 = inttoptr i64 %96 to i32*
  %98 = load atomic i32, i32* %97 monotonic, align 4
  %99 = ashr i32 %98, 1
  %100 = add i64 %95, 15
  %101 = inttoptr i64 %100 to i32*
  %102 = load atomic i32, i32* %101 monotonic, align 4
  %103 = ashr i32 %102, 1
  %104 = add nsw i32 %103, %99
  %105 = sext i32 %104 to i64
  %106 = icmp eq i32 %104, 0
  br i1 %106, label %117, label %107

107:                                              ; preds = %87
  %108 = lshr i32 %94, 1
  %109 = bitcast %"class.v8::internal::JSReceiver"* %4 to i8*
  %110 = getelementptr inbounds %"class.v8::internal::JSReceiver", %"class.v8::internal::JSReceiver"* %4, i64 0, i32 0, i32 0, i32 0, i32 0
  %111 = add nuw i32 %108, 1073741823
  br label %129

112:                                              ; preds = %284
  %113 = load i64, i64* %26, align 8
  %114 = load i64, i64* %1, align 8
  %115 = add i64 %114, 11
  %116 = inttoptr i64 %115 to i32*
  br label %117

117:                                              ; preds = %112, %87
  %118 = phi i32* [ %116, %112 ], [ %97, %87 ]
  %119 = phi i64 [ %113, %112 ], [ %91, %87 ]
  %120 = load atomic i32, i32* %118 monotonic, align 4
  %121 = and i32 %120, -2
  %122 = add i64 %119, 11
  %123 = inttoptr i64 %122 to i32*
  store atomic volatile i32 %121, i32* %123 monotonic, align 4
  %124 = load i64, i64* %1, align 8
  %125 = add i64 %124, 19
  %126 = inttoptr i64 %125 to i32*
  %127 = load atomic i32, i32* %126 monotonic, align 4
  %128 = icmp sgt i32 %127, 1
  br i1 %128, label %291, label %321

129:                                              ; preds = %289, %107
  %130 = phi i64 [ %95, %107 ], [ %290, %289 ]
  %131 = phi i32 [ 0, %107 ], [ %286, %289 ]
  %132 = phi i32 [ 0, %107 ], [ %285, %289 ]
  %133 = phi i64 [ 0, %107 ], [ %287, %289 ]
  %134 = trunc i64 %133 to i32
  %135 = add i64 %130, 19
  %136 = inttoptr i64 %135 to i32*
  %137 = load atomic i32, i32* %136 monotonic, align 4
  %138 = lshr i32 %137, 1
  %139 = shl i32 %134, 2
  %140 = add i32 %139, 4
  %141 = add i32 %138, %140
  %142 = and i64 %130, -4294967296
  %143 = shl i32 %141, 2
  %144 = sext i32 %143 to i64
  %145 = add i64 %130, 7
  %146 = add i64 %145, %144
  %147 = inttoptr i64 %146 to i32*
  %148 = load atomic i32, i32* %147 monotonic, align 4
  %149 = zext i32 %148 to i64
  %150 = or i64 %142, %149
  %151 = load i64*, i64** %20, align 8
  %152 = getelementptr inbounds i64, i64* %151, i64 5
  %153 = load i64, i64* %152, align 8
  %154 = trunc i64 %153 to i32
  %155 = icmp eq i32 %148, %154
  br i1 %155, label %156, label %164

156:                                              ; preds = %129
  %157 = add nsw i32 %132, 1
  %158 = shl i32 %134, 1
  %159 = shl i32 %132, 2
  %160 = add i32 %159, 16
  %161 = sext i32 %160 to i64
  %162 = add i64 %145, %161
  %163 = inttoptr i64 %162 to i32*
  store atomic volatile i32 %158, i32* %163 monotonic, align 4
  br label %284

164:                                              ; preds = %129
  %165 = call i64 @_ZN2v88internal6Object13GetSimpleHashES1_(i64 %150) #7
  %166 = and i64 %165, 1
  %167 = icmp eq i64 %166, 0
  br i1 %167, label %170, label %168

168:                                              ; preds = %164
  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %109) #7
  store i64 %150, i64* %110, align 8
  %169 = call i64 @_ZN2v88internal10JSReceiver15GetIdentityHashEv(%"class.v8::internal::JSReceiver"* nonnull %4) #7
  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %109) #7
  br label %170

170:                                              ; preds = %164, %168
  %171 = phi i64 [ %169, %168 ], [ %165, %164 ]
  %172 = trunc i64 %171 to i32
  %173 = lshr i32 %172, 1
  %174 = and i32 %173, %111
  %175 = load i64, i64* %26, align 8
  %176 = shl i32 %174, 2
  %177 = add i32 %176, 16
  %178 = sext i32 %177 to i64
  %179 = add i64 %175, 7
  %180 = add i64 %179, %178
  %181 = inttoptr i64 %180 to i32*
  %182 = load atomic i32, i32* %181 monotonic, align 4
  %183 = zext i32 %182 to i64
  %184 = shl i32 %131, 1
  store atomic volatile i32 %184, i32* %181 monotonic, align 4
  %185 = load i64, i64* %26, align 8
  %186 = add i64 %185, 19
  %187 = inttoptr i64 %186 to i32*
  %188 = load atomic i32, i32* %187 monotonic, align 4
  %189 = ashr i32 %188, 1
  %190 = shl i32 %131, 2
  %191 = add i32 %190, 4
  %192 = add i32 %191, %189
  %193 = load i64, i64* %1, align 8
  %194 = add i64 %193, 19
  %195 = inttoptr i64 %194 to i32*
  %196 = load atomic i32, i32* %195 monotonic, align 4
  %197 = lshr i32 %196, 1
  %198 = add i32 %197, %140
  %199 = and i64 %193, -4294967296
  %200 = shl i32 %198, 2
  %201 = sext i32 %200 to i64
  %202 = add nsw i64 %201, 7
  %203 = add i64 %202, %193
  %204 = inttoptr i64 %203 to i32*
  %205 = load atomic i32, i32* %204 monotonic, align 4
  %206 = zext i32 %205 to i64
  %207 = or i64 %199, %206
  %208 = shl i32 %192, 2
  %209 = sext i32 %208 to i64
  %210 = add nsw i64 %209, 7
  %211 = add i64 %210, %185
  %212 = inttoptr i64 %211 to i32*
  store atomic volatile i32 %205, i32* %212 monotonic, align 4
  %213 = and i64 %206, 1
  %214 = icmp eq i64 %213, 0
  br i1 %214, label %263, label %240

215:                                              ; preds = %390
  %216 = and i64 %393, -262144
  %217 = or i64 %216, 8
  %218 = inttoptr i64 %217 to i64*
  %219 = load i64, i64* %218, align 8
  %220 = and i64 %219, 262144
  %221 = icmp eq i64 %220, 0
  br i1 %221, label %226, label %222

222:                                              ; preds = %215
  %223 = or i64 %216, 16
  %224 = inttoptr i64 %223 to %"class.v8::internal::Heap"**
  %225 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %224, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %225, i64 %393, i64 %397, i64 %392) #7
  br label %226

226:                                              ; preds = %222, %215
  %227 = and i64 %392, -262144
  %228 = or i64 %227, 8
  %229 = inttoptr i64 %228 to i64*
  %230 = load i64, i64* %229, align 8
  %231 = and i64 %230, 24
  %232 = icmp eq i64 %231, 0
  br i1 %232, label %238, label %233

233:                                              ; preds = %226
  %234 = load i64, i64* %218, align 8
  %235 = and i64 %234, 24
  %236 = icmp eq i64 %235, 0
  br i1 %236, label %237, label %238

237:                                              ; preds = %233
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %393, i64 %397, i64 %392) #7
  br label %238

238:                                              ; preds = %390, %226, %233, %237
  %239 = add nsw i32 %131, 1
  br label %284

240:                                              ; preds = %170
  %241 = and i64 %185, -262144
  %242 = or i64 %241, 8
  %243 = inttoptr i64 %242 to i64*
  %244 = load i64, i64* %243, align 8
  %245 = and i64 %244, 262144
  %246 = icmp eq i64 %245, 0
  br i1 %246, label %251, label %247

247:                                              ; preds = %240
  %248 = or i64 %241, 16
  %249 = inttoptr i64 %248 to %"class.v8::internal::Heap"**
  %250 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %249, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %250, i64 %185, i64 %211, i64 %207) #7
  br label %251

251:                                              ; preds = %247, %240
  %252 = and i64 %207, -262144
  %253 = or i64 %252, 8
  %254 = inttoptr i64 %253 to i64*
  %255 = load i64, i64* %254, align 8
  %256 = and i64 %255, 24
  %257 = icmp eq i64 %256, 0
  br i1 %257, label %263, label %258

258:                                              ; preds = %251
  %259 = load i64, i64* %243, align 8
  %260 = and i64 %259, 24
  %261 = icmp eq i64 %260, 0
  br i1 %261, label %262, label %263

262:                                              ; preds = %258
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %185, i64 %211, i64 %207) #7
  br label %263

263:                                              ; preds = %170, %251, %258, %262
  %264 = load i64, i64* %1, align 8
  %265 = and i64 %264, -4294967296
  %266 = shl i32 %198, 2
  %267 = add i32 %266, 4
  %268 = sext i32 %267 to i64
  %269 = add nsw i64 %268, 7
  %270 = add i64 %269, %264
  %271 = inttoptr i64 %270 to i32*
  %272 = load atomic i32, i32* %271 monotonic, align 4
  %273 = zext i32 %272 to i64
  %274 = or i64 %265, %273
  %275 = load i64, i64* %26, align 8
  %276 = shl i32 %192, 2
  %277 = add i32 %276, 4
  %278 = sext i32 %277 to i64
  %279 = add nsw i64 %278, 7
  %280 = add i64 %279, %275
  %281 = inttoptr i64 %280 to i32*
  store atomic volatile i32 %272, i32* %281 monotonic, align 4
  %282 = and i64 %273, 1
  %283 = icmp eq i64 %282, 0
  br i1 %283, label %346, label %323

284:                                              ; preds = %238, %156
  %285 = phi i32 [ %157, %156 ], [ %132, %238 ]
  %286 = phi i32 [ %131, %156 ], [ %239, %238 ]
  %287 = add i64 %133, 1
  %288 = icmp eq i64 %287, %105
  br i1 %288, label %112, label %289

289:                                              ; preds = %284
  %290 = load i64, i64* %1, align 8
  br label %129

291:                                              ; preds = %117
  %292 = load i64, i64* %26, align 8
  %293 = add i64 %124, 11
  %294 = inttoptr i64 %293 to i32*
  %295 = trunc i64 %292 to i32
  store atomic volatile i32 %295, i32* %294 monotonic, align 4
  %296 = and i64 %292, 1
  %297 = icmp eq i64 %296, 0
  br i1 %297, label %321, label %298

298:                                              ; preds = %291
  %299 = and i64 %124, -262144
  %300 = or i64 %299, 8
  %301 = inttoptr i64 %300 to i64*
  %302 = load i64, i64* %301, align 8
  %303 = and i64 %302, 262144
  %304 = icmp eq i64 %303, 0
  br i1 %304, label %309, label %305

305:                                              ; preds = %298
  %306 = or i64 %299, 16
  %307 = inttoptr i64 %306 to %"class.v8::internal::Heap"**
  %308 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %307, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %308, i64 %124, i64 %293, i64 %292) #7
  br label %309

309:                                              ; preds = %305, %298
  %310 = and i64 %292, -262144
  %311 = or i64 %310, 8
  %312 = inttoptr i64 %311 to i64*
  %313 = load i64, i64* %312, align 8
  %314 = and i64 %313, 24
  %315 = icmp eq i64 %314, 0
  br i1 %315, label %321, label %316

316:                                              ; preds = %309
  %317 = load i64, i64* %301, align 8
  %318 = and i64 %317, 24
  %319 = icmp eq i64 %318, 0
  br i1 %319, label %320, label %321

320:                                              ; preds = %316
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %124, i64 %293, i64 %292) #7
  br label %321

321:                                              ; preds = %3, %75, %117, %291, %309, %316, %320
  %322 = phi i64* [ %26, %320 ], [ %26, %316 ], [ %26, %309 ], [ %26, %291 ], [ %26, %117 ], [ null, %75 ], [ null, %3 ]
  ret i64* %322

323:                                              ; preds = %263
  %324 = and i64 %275, -262144
  %325 = or i64 %324, 8
  %326 = inttoptr i64 %325 to i64*
  %327 = load i64, i64* %326, align 8
  %328 = and i64 %327, 262144
  %329 = icmp eq i64 %328, 0
  br i1 %329, label %334, label %330

330:                                              ; preds = %323
  %331 = or i64 %324, 16
  %332 = inttoptr i64 %331 to %"class.v8::internal::Heap"**
  %333 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %332, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %333, i64 %275, i64 %280, i64 %274) #7
  br label %334

334:                                              ; preds = %330, %323
  %335 = and i64 %274, -262144
  %336 = or i64 %335, 8
  %337 = inttoptr i64 %336 to i64*
  %338 = load i64, i64* %337, align 8
  %339 = and i64 %338, 24
  %340 = icmp eq i64 %339, 0
  br i1 %340, label %346, label %341

341:                                              ; preds = %334
  %342 = load i64, i64* %326, align 8
  %343 = and i64 %342, 24
  %344 = icmp eq i64 %343, 0
  br i1 %344, label %345, label %346

345:                                              ; preds = %341
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %275, i64 %280, i64 %274) #7
  br label %346

346:                                              ; preds = %345, %341, %334, %263
  %347 = load i64, i64* %1, align 8
  %348 = and i64 %347, -4294967296
  %349 = shl i32 %198, 2
  %350 = add i32 %349, 8
  %351 = sext i32 %350 to i64
  %352 = add nsw i64 %351, 7
  %353 = add i64 %352, %347
  %354 = inttoptr i64 %353 to i32*
  %355 = load atomic i32, i32* %354 monotonic, align 4
  %356 = zext i32 %355 to i64
  %357 = or i64 %348, %356
  %358 = load i64, i64* %26, align 8
  %359 = shl i32 %192, 2
  %360 = add i32 %359, 8
  %361 = sext i32 %360 to i64
  %362 = add nsw i64 %361, 7
  %363 = add i64 %362, %358
  %364 = inttoptr i64 %363 to i32*
  store atomic volatile i32 %355, i32* %364 monotonic, align 4
  %365 = and i64 %356, 1
  %366 = icmp eq i64 %365, 0
  br i1 %366, label %390, label %367

367:                                              ; preds = %346
  %368 = and i64 %358, -262144
  %369 = or i64 %368, 8
  %370 = inttoptr i64 %369 to i64*
  %371 = load i64, i64* %370, align 8
  %372 = and i64 %371, 262144
  %373 = icmp eq i64 %372, 0
  br i1 %373, label %378, label %374

374:                                              ; preds = %367
  %375 = or i64 %368, 16
  %376 = inttoptr i64 %375 to %"class.v8::internal::Heap"**
  %377 = load %"class.v8::internal::Heap"*, %"class.v8::internal::Heap"** %376, align 16
  call void @_ZN2v88internal12WriteBarrier11MarkingSlowEPNS0_4HeapENS0_10HeapObjectENS0_24CompressedHeapObjectSlotES4_(%"class.v8::internal::Heap"* %377, i64 %358, i64 %363, i64 %357) #7
  br label %378

378:                                              ; preds = %374, %367
  %379 = and i64 %357, -262144
  %380 = or i64 %379, 8
  %381 = inttoptr i64 %380 to i64*
  %382 = load i64, i64* %381, align 8
  %383 = and i64 %382, 24
  %384 = icmp eq i64 %383, 0
  br i1 %384, label %390, label %385

385:                                              ; preds = %378
  %386 = load i64, i64* %370, align 8
  %387 = and i64 %386, 24
  %388 = icmp eq i64 %387, 0
  br i1 %388, label %389, label %390

389:                                              ; preds = %385
  call void @_ZN2v88internal28Heap_GenerationalBarrierSlowENS0_10HeapObjectEmS1_(i64 %358, i64 %363, i64 %357) #7
  br label %390

390:                                              ; preds = %389, %385, %378, %346
  %391 = and i64 %175, -4294967296
  %392 = or i64 %391, %183
  %393 = load i64, i64* %26, align 8
  %394 = add i32 %208, 12
  %395 = sext i32 %394 to i64
  %396 = add nsw i64 %395, 7
  %397 = add i64 %396, %393
  %398 = inttoptr i64 %397 to i32*
  store atomic volatile i32 %182, i32* %398 monotonic, align 4
  %399 = and i64 %183, 1
  %400 = icmp eq i64 %399, 0
  br i1 %400, label %238, label %215
}

attributes #0 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind }
attributes #2 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #3 = { norecurse nounwind readonly ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #4 = { inlinehint nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #5 = { noreturn "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #6 = { nounwind readonly ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #7 = { nounwind }
attributes #8 = { noreturn nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
!2 = !{!"branch_weights", i32 1, i32 2000}
!3 = !{i32 18455230}
!4 = !{i8 0, i8 2}
!5 = !{!"branch_weights", i32 2000, i32 1}
!6 = !{!"branch_weights", i32 1073205, i32 2146410443}
