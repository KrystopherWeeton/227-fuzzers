; ModuleID = '../../third_party/libvpx/source/libvpx/vpx_dsp/x86/inv_txfm_ssse3.c'
source_filename = "../../third_party/libvpx/source/libvpx/vpx_dsp/x86/inv_txfm_ssse3.c"
target datalayout = "e-m:e-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

; Function Attrs: nounwind ssp uwtable
define hidden void @vpx_idct8x8_12_add_ssse3(i32* nocapture readonly, i8* nocapture, i32) local_unnamed_addr #0 {
  %4 = bitcast i32* %0 to <4 x i32>*
  %5 = load <4 x i32>, <4 x i32>* %4, align 16
  %6 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %5, <4 x i32> undef) #4
  %7 = getelementptr inbounds i32, i32* %0, i64 8
  %8 = bitcast i32* %7 to <4 x i32>*
  %9 = load <4 x i32>, <4 x i32>* %8, align 16
  %10 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %9, <4 x i32> undef) #4
  %11 = getelementptr inbounds i32, i32* %0, i64 16
  %12 = bitcast i32* %11 to <4 x i32>*
  %13 = load <4 x i32>, <4 x i32>* %12, align 16
  %14 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %13, <4 x i32> undef) #4
  %15 = getelementptr inbounds i32, i32* %0, i64 24
  %16 = bitcast i32* %15 to <4 x i32>*
  %17 = load <4 x i32>, <4 x i32>* %16, align 16
  %18 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %17, <4 x i32> undef) #4
  %19 = shufflevector <8 x i16> %6, <8 x i16> %10, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %20 = shufflevector <8 x i16> %14, <8 x i16> %18, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %21 = bitcast <8 x i16> %19 to <4 x i32>
  %22 = bitcast <8 x i16> %20 to <4 x i32>
  %23 = shufflevector <4 x i32> %21, <4 x i32> %22, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %24 = shufflevector <4 x i32> %21, <4 x i32> %22, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %25 = bitcast <4 x i32> %23 to <2 x i64>
  %26 = shufflevector <2 x i64> %25, <2 x i64> undef, <2 x i32> zeroinitializer
  %27 = shufflevector <2 x i64> %25, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %28 = bitcast <4 x i32> %24 to <2 x i64>
  %29 = shufflevector <2 x i64> %28, <2 x i64> undef, <2 x i32> zeroinitializer
  %30 = shufflevector <2 x i64> %28, <2 x i64> undef, <2 x i32> <i32 1, i32 1>
  %31 = bitcast <2 x i64> %27 to <8 x i16>
  %32 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %31, <8 x i16> <i16 6392, i16 6392, i16 6392, i16 6392, i16 32138, i16 32138, i16 32138, i16 32138>) #4
  %33 = bitcast <2 x i64> %30 to <8 x i16>
  %34 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %33, <8 x i16> <i16 -18204, i16 -18204, i16 -18204, i16 -18204, i16 27246, i16 27246, i16 27246, i16 27246>) #4
  %35 = bitcast <2 x i64> %26 to <8 x i16>
  %36 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %35, <8 x i16> <i16 23170, i16 23170, i16 23170, i16 23170, i16 23170, i16 23170, i16 23170, i16 23170>) #4
  %37 = bitcast <2 x i64> %29 to <8 x i16>
  %38 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %37, <8 x i16> <i16 30274, i16 30274, i16 30274, i16 30274, i16 12540, i16 12540, i16 12540, i16 12540>) #4
  %39 = add <8 x i16> %34, %32
  %40 = sub <8 x i16> %32, %34
  %41 = bitcast <8 x i16> %40 to <2 x i64>
  %42 = shufflevector <2 x i64> %41, <2 x i64> undef, <2 x i32> <i32 1, i32 undef>
  %43 = bitcast <2 x i64> %42 to <8 x i16>
  %44 = shufflevector <8 x i16> %43, <8 x i16> %40, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %45 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>, <8 x i16> %44) #4
  %46 = add <4 x i32> %45, <i32 8192, i32 8192, i32 8192, i32 8192>
  %47 = ashr <4 x i32> %46, <i32 14, i32 14, i32 14, i32 14>
  %48 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>, <8 x i16> %44) #4
  %49 = add <4 x i32> %48, <i32 8192, i32 8192, i32 8192, i32 8192>
  %50 = ashr <4 x i32> %49, <i32 14, i32 14, i32 14, i32 14>
  %51 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %47, <4 x i32> %50) #4
  %52 = add <8 x i16> %38, %36
  %53 = bitcast <8 x i16> %52 to <2 x i64>
  %54 = sub <8 x i16> %36, %38
  %55 = bitcast <8 x i16> %54 to <2 x i64>
  %56 = shufflevector <2 x i64> %55, <2 x i64> %53, <2 x i32> <i32 1, i32 3>
  %57 = shufflevector <2 x i64> %55, <2 x i64> %53, <2 x i32> <i32 0, i32 2>
  %58 = bitcast <2 x i64> %57 to <8 x i16>
  %59 = add <8 x i16> %39, %58
  %60 = bitcast <2 x i64> %56 to <8 x i16>
  %61 = add <8 x i16> %51, %60
  %62 = sub <8 x i16> %58, %39
  %63 = sub <8 x i16> %60, %51
  %64 = shufflevector <8 x i16> %59, <8 x i16> %61, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %65 = shufflevector <8 x i16> %61, <8 x i16> %59, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %66 = shufflevector <8 x i16> %62, <8 x i16> %63, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %67 = shufflevector <8 x i16> %63, <8 x i16> %62, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %68 = bitcast <8 x i16> %64 to <4 x i32>
  %69 = bitcast <8 x i16> %65 to <4 x i32>
  %70 = shufflevector <4 x i32> %68, <4 x i32> %69, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %71 = bitcast <4 x i32> %70 to <2 x i64>
  %72 = bitcast <8 x i16> %66 to <4 x i32>
  %73 = bitcast <8 x i16> %67 to <4 x i32>
  %74 = shufflevector <4 x i32> %72, <4 x i32> %73, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %75 = bitcast <4 x i32> %74 to <2 x i64>
  %76 = shufflevector <4 x i32> %68, <4 x i32> %69, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %77 = bitcast <4 x i32> %76 to <2 x i64>
  %78 = shufflevector <4 x i32> %72, <4 x i32> %73, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %79 = bitcast <4 x i32> %78 to <2 x i64>
  %80 = shufflevector <2 x i64> %71, <2 x i64> %75, <2 x i32> <i32 0, i32 2>
  %81 = shufflevector <2 x i64> %71, <2 x i64> %75, <2 x i32> <i32 1, i32 3>
  %82 = shufflevector <2 x i64> %77, <2 x i64> %79, <2 x i32> <i32 0, i32 2>
  %83 = shufflevector <2 x i64> %77, <2 x i64> %79, <2 x i32> <i32 1, i32 3>
  %84 = bitcast <2 x i64> %81 to <8 x i16>
  %85 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %84, <8 x i16> <i16 6392, i16 6392, i16 6392, i16 6392, i16 6392, i16 6392, i16 6392, i16 6392>) #4
  %86 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %84, <8 x i16> <i16 32138, i16 32138, i16 32138, i16 32138, i16 32138, i16 32138, i16 32138, i16 32138>) #4
  %87 = bitcast <2 x i64> %83 to <8 x i16>
  %88 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %87, <8 x i16> <i16 -18204, i16 -18204, i16 -18204, i16 -18204, i16 -18204, i16 -18204, i16 -18204, i16 -18204>) #4
  %89 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %87, <8 x i16> <i16 27246, i16 27246, i16 27246, i16 27246, i16 27246, i16 27246, i16 27246, i16 27246>) #4
  %90 = bitcast <2 x i64> %80 to <8 x i16>
  %91 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %90, <8 x i16> <i16 23170, i16 23170, i16 23170, i16 23170, i16 23170, i16 23170, i16 23170, i16 23170>) #4
  %92 = bitcast <2 x i64> %82 to <8 x i16>
  %93 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %92, <8 x i16> <i16 12540, i16 12540, i16 12540, i16 12540, i16 12540, i16 12540, i16 12540, i16 12540>) #4
  %94 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %92, <8 x i16> <i16 30274, i16 30274, i16 30274, i16 30274, i16 30274, i16 30274, i16 30274, i16 30274>) #4
  %95 = add <8 x i16> %88, %85
  %96 = sub <8 x i16> %85, %88
  %97 = sub <8 x i16> %86, %89
  %98 = add <8 x i16> %89, %86
  %99 = add <8 x i16> %94, %91
  %100 = add <8 x i16> %93, %91
  %101 = sub <8 x i16> %91, %93
  %102 = sub <8 x i16> %91, %94
  %103 = shufflevector <8 x i16> %97, <8 x i16> %96, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %104 = shufflevector <8 x i16> %97, <8 x i16> %96, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %105 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %103, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #4
  %106 = add <4 x i32> %105, <i32 8192, i32 8192, i32 8192, i32 8192>
  %107 = ashr <4 x i32> %106, <i32 14, i32 14, i32 14, i32 14>
  %108 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %104, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #4
  %109 = add <4 x i32> %108, <i32 8192, i32 8192, i32 8192, i32 8192>
  %110 = ashr <4 x i32> %109, <i32 14, i32 14, i32 14, i32 14>
  %111 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %107, <4 x i32> %110) #4
  %112 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %103, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #4
  %113 = add <4 x i32> %112, <i32 8192, i32 8192, i32 8192, i32 8192>
  %114 = ashr <4 x i32> %113, <i32 14, i32 14, i32 14, i32 14>
  %115 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %104, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #4
  %116 = add <4 x i32> %115, <i32 8192, i32 8192, i32 8192, i32 8192>
  %117 = ashr <4 x i32> %116, <i32 14, i32 14, i32 14, i32 14>
  %118 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %114, <4 x i32> %117) #4
  %119 = add <8 x i16> %98, <i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16>
  %120 = add <8 x i16> %119, %99
  %121 = add <8 x i16> %100, <i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16>
  %122 = add <8 x i16> %121, %118
  %123 = add <8 x i16> %101, <i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16>
  %124 = add <8 x i16> %123, %111
  %125 = add <8 x i16> %95, <i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16>
  %126 = add <8 x i16> %125, %102
  %127 = sub <8 x i16> <i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16>, %95
  %128 = add <8 x i16> %127, %102
  %129 = sub <8 x i16> %123, %111
  %130 = sub <8 x i16> %121, %118
  %131 = sub <8 x i16> <i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16, i16 16>, %98
  %132 = add <8 x i16> %131, %99
  %133 = ashr <8 x i16> %120, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %134 = ashr <8 x i16> %122, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %135 = ashr <8 x i16> %124, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %136 = ashr <8 x i16> %126, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %137 = ashr <8 x i16> %128, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %138 = ashr <8 x i16> %129, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %139 = ashr <8 x i16> %130, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %140 = ashr <8 x i16> %132, <i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5, i16 5>
  %141 = bitcast i8* %1 to i64*
  %142 = load i64, i64* %141, align 1
  %143 = insertelement <2 x i64> undef, i64 %142, i32 0
  %144 = bitcast <2 x i64> %143 to <16 x i8>
  %145 = shufflevector <16 x i8> %144, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %146 = bitcast <16 x i8> %145 to <8 x i16>
  %147 = add <8 x i16> %133, %146
  %148 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %147, <8 x i16> undef) #4
  %149 = bitcast <16 x i8> %148 to <2 x i64>
  %150 = extractelement <2 x i64> %149, i32 0
  store i64 %150, i64* %141, align 1
  %151 = sext i32 %2 to i64
  %152 = getelementptr inbounds i8, i8* %1, i64 %151
  %153 = bitcast i8* %152 to i64*
  %154 = load i64, i64* %153, align 1
  %155 = insertelement <2 x i64> undef, i64 %154, i32 0
  %156 = bitcast <2 x i64> %155 to <16 x i8>
  %157 = shufflevector <16 x i8> %156, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %158 = bitcast <16 x i8> %157 to <8 x i16>
  %159 = add <8 x i16> %134, %158
  %160 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %159, <8 x i16> undef) #4
  %161 = bitcast <16 x i8> %160 to <2 x i64>
  %162 = extractelement <2 x i64> %161, i32 0
  store i64 %162, i64* %153, align 1
  %163 = shl nsw i32 %2, 1
  %164 = sext i32 %163 to i64
  %165 = getelementptr inbounds i8, i8* %1, i64 %164
  %166 = bitcast i8* %165 to i64*
  %167 = load i64, i64* %166, align 1
  %168 = insertelement <2 x i64> undef, i64 %167, i32 0
  %169 = bitcast <2 x i64> %168 to <16 x i8>
  %170 = shufflevector <16 x i8> %169, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %171 = bitcast <16 x i8> %170 to <8 x i16>
  %172 = add <8 x i16> %135, %171
  %173 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %172, <8 x i16> undef) #4
  %174 = bitcast <16 x i8> %173 to <2 x i64>
  %175 = extractelement <2 x i64> %174, i32 0
  store i64 %175, i64* %166, align 1
  %176 = mul nsw i32 %2, 3
  %177 = sext i32 %176 to i64
  %178 = getelementptr inbounds i8, i8* %1, i64 %177
  %179 = bitcast i8* %178 to i64*
  %180 = load i64, i64* %179, align 1
  %181 = insertelement <2 x i64> undef, i64 %180, i32 0
  %182 = bitcast <2 x i64> %181 to <16 x i8>
  %183 = shufflevector <16 x i8> %182, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %184 = bitcast <16 x i8> %183 to <8 x i16>
  %185 = add <8 x i16> %136, %184
  %186 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %185, <8 x i16> undef) #4
  %187 = bitcast <16 x i8> %186 to <2 x i64>
  %188 = extractelement <2 x i64> %187, i32 0
  store i64 %188, i64* %179, align 1
  %189 = shl nsw i32 %2, 2
  %190 = sext i32 %189 to i64
  %191 = getelementptr inbounds i8, i8* %1, i64 %190
  %192 = bitcast i8* %191 to i64*
  %193 = load i64, i64* %192, align 1
  %194 = insertelement <2 x i64> undef, i64 %193, i32 0
  %195 = bitcast <2 x i64> %194 to <16 x i8>
  %196 = shufflevector <16 x i8> %195, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %197 = bitcast <16 x i8> %196 to <8 x i16>
  %198 = add <8 x i16> %137, %197
  %199 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %198, <8 x i16> undef) #4
  %200 = bitcast <16 x i8> %199 to <2 x i64>
  %201 = extractelement <2 x i64> %200, i32 0
  store i64 %201, i64* %192, align 1
  %202 = mul nsw i32 %2, 5
  %203 = sext i32 %202 to i64
  %204 = getelementptr inbounds i8, i8* %1, i64 %203
  %205 = bitcast i8* %204 to i64*
  %206 = load i64, i64* %205, align 1
  %207 = insertelement <2 x i64> undef, i64 %206, i32 0
  %208 = bitcast <2 x i64> %207 to <16 x i8>
  %209 = shufflevector <16 x i8> %208, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %210 = bitcast <16 x i8> %209 to <8 x i16>
  %211 = add <8 x i16> %138, %210
  %212 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %211, <8 x i16> undef) #4
  %213 = bitcast <16 x i8> %212 to <2 x i64>
  %214 = extractelement <2 x i64> %213, i32 0
  store i64 %214, i64* %205, align 1
  %215 = mul nsw i32 %2, 6
  %216 = sext i32 %215 to i64
  %217 = getelementptr inbounds i8, i8* %1, i64 %216
  %218 = bitcast i8* %217 to i64*
  %219 = load i64, i64* %218, align 1
  %220 = insertelement <2 x i64> undef, i64 %219, i32 0
  %221 = bitcast <2 x i64> %220 to <16 x i8>
  %222 = shufflevector <16 x i8> %221, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %223 = bitcast <16 x i8> %222 to <8 x i16>
  %224 = add <8 x i16> %139, %223
  %225 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %224, <8 x i16> undef) #4
  %226 = bitcast <16 x i8> %225 to <2 x i64>
  %227 = extractelement <2 x i64> %226, i32 0
  store i64 %227, i64* %218, align 1
  %228 = mul nsw i32 %2, 7
  %229 = sext i32 %228 to i64
  %230 = getelementptr inbounds i8, i8* %1, i64 %229
  %231 = bitcast i8* %230 to i64*
  %232 = load i64, i64* %231, align 1
  %233 = insertelement <2 x i64> undef, i64 %232, i32 0
  %234 = bitcast <2 x i64> %233 to <16 x i8>
  %235 = shufflevector <16 x i8> %234, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %236 = bitcast <16 x i8> %235 to <8 x i16>
  %237 = add <8 x i16> %140, %236
  %238 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %237, <8 x i16> undef) #4
  %239 = bitcast <16 x i8> %238 to <2 x i64>
  %240 = extractelement <2 x i64> %239, i32 0
  store i64 %240, i64* %231, align 1
  ret void
}

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.start.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: argmemonly nounwind
declare void @llvm.memset.p0i8.i64(i8* nocapture writeonly, i8, i64, i1 immarg) #1

; Function Attrs: argmemonly nounwind
declare void @llvm.lifetime.end.p0i8(i64 immarg, i8* nocapture) #1

; Function Attrs: nounwind ssp uwtable
define hidden void @idct32_34_8x32_ssse3(<2 x i64>* nocapture readonly, <2 x i64>* nocapture) local_unnamed_addr #0 {
  %3 = alloca [32 x <2 x i64>], align 16
  %4 = bitcast [32 x <2 x i64>]* %3 to i8*
  call void @llvm.lifetime.start.p0i8(i64 512, i8* nonnull %4) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %4, i8 -86, i64 512, i1 false)
  %5 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %6 = bitcast <2 x i64>* %5 to <8 x i16>*
  %7 = load <8 x i16>, <8 x i16>* %6, align 16
  %8 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %7, <8 x i16> <i16 6392, i16 6392, i16 6392, i16 6392, i16 6392, i16 6392, i16 6392, i16 6392>) #4
  %9 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %7, <8 x i16> <i16 32138, i16 32138, i16 32138, i16 32138, i16 32138, i16 32138, i16 32138, i16 32138>) #4
  %10 = bitcast <2 x i64>* %0 to <8 x i16>*
  %11 = load <8 x i16>, <8 x i16>* %10, align 16
  %12 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %11, <8 x i16> <i16 23170, i16 23170, i16 23170, i16 23170, i16 23170, i16 23170, i16 23170, i16 23170>) #4
  %13 = shufflevector <8 x i16> %9, <8 x i16> %8, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %14 = shufflevector <8 x i16> %9, <8 x i16> %8, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %15 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %13, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #4
  %16 = add <4 x i32> %15, <i32 8192, i32 8192, i32 8192, i32 8192>
  %17 = ashr <4 x i32> %16, <i32 14, i32 14, i32 14, i32 14>
  %18 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %14, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #4
  %19 = add <4 x i32> %18, <i32 8192, i32 8192, i32 8192, i32 8192>
  %20 = ashr <4 x i32> %19, <i32 14, i32 14, i32 14, i32 14>
  %21 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %17, <4 x i32> %20) #4
  %22 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %13, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #4
  %23 = add <4 x i32> %22, <i32 8192, i32 8192, i32 8192, i32 8192>
  %24 = ashr <4 x i32> %23, <i32 14, i32 14, i32 14, i32 14>
  %25 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %14, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #4
  %26 = add <4 x i32> %25, <i32 8192, i32 8192, i32 8192, i32 8192>
  %27 = ashr <4 x i32> %26, <i32 14, i32 14, i32 14, i32 14>
  %28 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %24, <4 x i32> %27) #4
  %29 = add <8 x i16> %12, %9
  %30 = add <8 x i16> %28, %12
  %31 = add <8 x i16> %21, %12
  %32 = add <8 x i16> %12, %8
  %33 = sub <8 x i16> %12, %8
  %34 = sub <8 x i16> %12, %21
  %35 = sub <8 x i16> %12, %28
  %36 = sub <8 x i16> %12, %9
  %37 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %38 = bitcast <2 x i64>* %37 to <8 x i16>*
  %39 = load <8 x i16>, <8 x i16>* %38, align 16
  %40 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %39, <8 x i16> <i16 3212, i16 3212, i16 3212, i16 3212, i16 3212, i16 3212, i16 3212, i16 3212>) #4
  %41 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %39, <8 x i16> <i16 32610, i16 32610, i16 32610, i16 32610, i16 32610, i16 32610, i16 32610, i16 32610>) #4
  %42 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %43 = bitcast <2 x i64>* %42 to <8 x i16>*
  %44 = load <8 x i16>, <8 x i16>* %43, align 16
  %45 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %44, <8 x i16> <i16 -9512, i16 -9512, i16 -9512, i16 -9512, i16 -9512, i16 -9512, i16 -9512, i16 -9512>) #4
  %46 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %44, <8 x i16> <i16 31358, i16 31358, i16 31358, i16 31358, i16 31358, i16 31358, i16 31358, i16 31358>) #4
  %47 = shufflevector <8 x i16> %41, <8 x i16> %40, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %48 = shufflevector <8 x i16> %41, <8 x i16> %40, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %49 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %47, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #4
  %50 = add <4 x i32> %49, <i32 8192, i32 8192, i32 8192, i32 8192>
  %51 = ashr <4 x i32> %50, <i32 14, i32 14, i32 14, i32 14>
  %52 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %48, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #4
  %53 = add <4 x i32> %52, <i32 8192, i32 8192, i32 8192, i32 8192>
  %54 = ashr <4 x i32> %53, <i32 14, i32 14, i32 14, i32 14>
  %55 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %51, <4 x i32> %54) #4
  %56 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %47, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #4
  %57 = add <4 x i32> %56, <i32 8192, i32 8192, i32 8192, i32 8192>
  %58 = ashr <4 x i32> %57, <i32 14, i32 14, i32 14, i32 14>
  %59 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %48, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #4
  %60 = add <4 x i32> %59, <i32 8192, i32 8192, i32 8192, i32 8192>
  %61 = ashr <4 x i32> %60, <i32 14, i32 14, i32 14, i32 14>
  %62 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %58, <4 x i32> %61) #4
  %63 = shufflevector <8 x i16> %46, <8 x i16> %45, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %64 = shufflevector <8 x i16> %46, <8 x i16> %45, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %65 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %63, <8 x i16> <i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270>) #4
  %66 = add <4 x i32> %65, <i32 8192, i32 8192, i32 8192, i32 8192>
  %67 = ashr <4 x i32> %66, <i32 14, i32 14, i32 14, i32 14>
  %68 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %64, <8 x i16> <i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270>) #4
  %69 = add <4 x i32> %68, <i32 8192, i32 8192, i32 8192, i32 8192>
  %70 = ashr <4 x i32> %69, <i32 14, i32 14, i32 14, i32 14>
  %71 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %67, <4 x i32> %70) #4
  %72 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %63, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #4
  %73 = add <4 x i32> %72, <i32 8192, i32 8192, i32 8192, i32 8192>
  %74 = ashr <4 x i32> %73, <i32 14, i32 14, i32 14, i32 14>
  %75 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %64, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #4
  %76 = add <4 x i32> %75, <i32 8192, i32 8192, i32 8192, i32 8192>
  %77 = ashr <4 x i32> %76, <i32 14, i32 14, i32 14, i32 14>
  %78 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %74, <4 x i32> %77) #4
  %79 = add <8 x i16> %45, %40
  %80 = add <8 x i16> %71, %55
  %81 = sub <8 x i16> %55, %71
  %82 = sub <8 x i16> %40, %45
  %83 = sub <8 x i16> %41, %46
  %84 = sub <8 x i16> %62, %78
  %85 = add <8 x i16> %78, %62
  %86 = add <8 x i16> %46, %41
  %87 = shufflevector <8 x i16> %84, <8 x i16> %81, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %88 = shufflevector <8 x i16> %84, <8 x i16> %81, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %89 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %87, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #4
  %90 = add <4 x i32> %89, <i32 8192, i32 8192, i32 8192, i32 8192>
  %91 = ashr <4 x i32> %90, <i32 14, i32 14, i32 14, i32 14>
  %92 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %88, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #4
  %93 = add <4 x i32> %92, <i32 8192, i32 8192, i32 8192, i32 8192>
  %94 = ashr <4 x i32> %93, <i32 14, i32 14, i32 14, i32 14>
  %95 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %91, <4 x i32> %94) #4
  %96 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %87, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #4
  %97 = add <4 x i32> %96, <i32 8192, i32 8192, i32 8192, i32 8192>
  %98 = ashr <4 x i32> %97, <i32 14, i32 14, i32 14, i32 14>
  %99 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %88, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #4
  %100 = add <4 x i32> %99, <i32 8192, i32 8192, i32 8192, i32 8192>
  %101 = ashr <4 x i32> %100, <i32 14, i32 14, i32 14, i32 14>
  %102 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %98, <4 x i32> %101) #4
  %103 = shufflevector <8 x i16> %83, <8 x i16> %82, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %104 = shufflevector <8 x i16> %83, <8 x i16> %82, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %105 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %103, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #4
  %106 = add <4 x i32> %105, <i32 8192, i32 8192, i32 8192, i32 8192>
  %107 = ashr <4 x i32> %106, <i32 14, i32 14, i32 14, i32 14>
  %108 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %104, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #4
  %109 = add <4 x i32> %108, <i32 8192, i32 8192, i32 8192, i32 8192>
  %110 = ashr <4 x i32> %109, <i32 14, i32 14, i32 14, i32 14>
  %111 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %107, <4 x i32> %110) #4
  %112 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %103, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #4
  %113 = add <4 x i32> %112, <i32 8192, i32 8192, i32 8192, i32 8192>
  %114 = ashr <4 x i32> %113, <i32 14, i32 14, i32 14, i32 14>
  %115 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %104, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #4
  %116 = add <4 x i32> %115, <i32 8192, i32 8192, i32 8192, i32 8192>
  %117 = ashr <4 x i32> %116, <i32 14, i32 14, i32 14, i32 14>
  %118 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %114, <4 x i32> %117) #4
  %119 = add <8 x i16> %86, %29
  %120 = bitcast [32 x <2 x i64>]* %3 to <8 x i16>*
  store <8 x i16> %119, <8 x i16>* %120, align 16
  %121 = sub <8 x i16> %29, %86
  %122 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 15
  %123 = bitcast <2 x i64>* %122 to <8 x i16>*
  store <8 x i16> %121, <8 x i16>* %123, align 16
  %124 = add <8 x i16> %85, %30
  %125 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 1
  %126 = bitcast <2 x i64>* %125 to <8 x i16>*
  store <8 x i16> %124, <8 x i16>* %126, align 16
  %127 = sub <8 x i16> %30, %85
  %128 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 14
  %129 = bitcast <2 x i64>* %128 to <8 x i16>*
  store <8 x i16> %127, <8 x i16>* %129, align 16
  %130 = add <8 x i16> %102, %31
  %131 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 2
  %132 = bitcast <2 x i64>* %131 to <8 x i16>*
  store <8 x i16> %130, <8 x i16>* %132, align 16
  %133 = sub <8 x i16> %31, %102
  %134 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 13
  %135 = bitcast <2 x i64>* %134 to <8 x i16>*
  store <8 x i16> %133, <8 x i16>* %135, align 16
  %136 = add <8 x i16> %118, %32
  %137 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 3
  %138 = bitcast <2 x i64>* %137 to <8 x i16>*
  store <8 x i16> %136, <8 x i16>* %138, align 16
  %139 = sub <8 x i16> %32, %118
  %140 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 12
  %141 = bitcast <2 x i64>* %140 to <8 x i16>*
  store <8 x i16> %139, <8 x i16>* %141, align 16
  %142 = add <8 x i16> %111, %33
  %143 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 4
  %144 = bitcast <2 x i64>* %143 to <8 x i16>*
  store <8 x i16> %142, <8 x i16>* %144, align 16
  %145 = sub <8 x i16> %33, %111
  %146 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 11
  %147 = bitcast <2 x i64>* %146 to <8 x i16>*
  store <8 x i16> %145, <8 x i16>* %147, align 16
  %148 = add <8 x i16> %95, %34
  %149 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 5
  %150 = bitcast <2 x i64>* %149 to <8 x i16>*
  store <8 x i16> %148, <8 x i16>* %150, align 16
  %151 = sub <8 x i16> %34, %95
  %152 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 10
  %153 = bitcast <2 x i64>* %152 to <8 x i16>*
  store <8 x i16> %151, <8 x i16>* %153, align 16
  %154 = add <8 x i16> %80, %35
  %155 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 6
  %156 = bitcast <2 x i64>* %155 to <8 x i16>*
  store <8 x i16> %154, <8 x i16>* %156, align 16
  %157 = sub <8 x i16> %35, %80
  %158 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 9
  %159 = bitcast <2 x i64>* %158 to <8 x i16>*
  store <8 x i16> %157, <8 x i16>* %159, align 16
  %160 = add <8 x i16> %79, %36
  %161 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 7
  %162 = bitcast <2 x i64>* %161 to <8 x i16>*
  store <8 x i16> %160, <8 x i16>* %162, align 16
  %163 = sub <8 x i16> %36, %79
  %164 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 8
  %165 = bitcast <2 x i64>* %164 to <8 x i16>*
  store <8 x i16> %163, <8 x i16>* %165, align 16
  %166 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %167 = bitcast <2 x i64>* %166 to <8 x i16>*
  %168 = load <8 x i16>, <8 x i16>* %167, align 16
  %169 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %168, <8 x i16> <i16 1608, i16 1608, i16 1608, i16 1608, i16 1608, i16 1608, i16 1608, i16 1608>) #4
  %170 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %168, <8 x i16> <i16 32728, i16 32728, i16 32728, i16 32728, i16 32728, i16 32728, i16 32728, i16 32728>) #4
  %171 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %172 = bitcast <2 x i64>* %171 to <8 x i16>*
  %173 = load <8 x i16>, <8 x i16>* %172, align 16
  %174 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %173, <8 x i16> <i16 -11040, i16 -11040, i16 -11040, i16 -11040, i16 -11040, i16 -11040, i16 -11040, i16 -11040>) #4
  %175 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %173, <8 x i16> <i16 30852, i16 30852, i16 30852, i16 30852, i16 30852, i16 30852, i16 30852, i16 30852>) #4
  %176 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %177 = bitcast <2 x i64>* %176 to <8 x i16>*
  %178 = load <8 x i16>, <8 x i16>* %177, align 16
  %179 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %178, <8 x i16> <i16 7962, i16 7962, i16 7962, i16 7962, i16 7962, i16 7962, i16 7962, i16 7962>) #4
  %180 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %178, <8 x i16> <i16 31786, i16 31786, i16 31786, i16 31786, i16 31786, i16 31786, i16 31786, i16 31786>) #4
  %181 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %182 = bitcast <2 x i64>* %181 to <8 x i16>*
  %183 = load <8 x i16>, <8 x i16>* %182, align 16
  %184 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %183, <8 x i16> <i16 -4808, i16 -4808, i16 -4808, i16 -4808, i16 -4808, i16 -4808, i16 -4808, i16 -4808>) #4
  %185 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %183, <8 x i16> <i16 32414, i16 32414, i16 32414, i16 32414, i16 32414, i16 32414, i16 32414, i16 32414>) #4
  %186 = shufflevector <8 x i16> %170, <8 x i16> %169, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %187 = shufflevector <8 x i16> %170, <8 x i16> %169, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %188 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %186, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #4
  %189 = add <4 x i32> %188, <i32 8192, i32 8192, i32 8192, i32 8192>
  %190 = ashr <4 x i32> %189, <i32 14, i32 14, i32 14, i32 14>
  %191 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %187, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #4
  %192 = add <4 x i32> %191, <i32 8192, i32 8192, i32 8192, i32 8192>
  %193 = ashr <4 x i32> %192, <i32 14, i32 14, i32 14, i32 14>
  %194 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %190, <4 x i32> %193) #4
  %195 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %186, <8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>) #4
  %196 = add <4 x i32> %195, <i32 8192, i32 8192, i32 8192, i32 8192>
  %197 = ashr <4 x i32> %196, <i32 14, i32 14, i32 14, i32 14>
  %198 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %187, <8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>) #4
  %199 = add <4 x i32> %198, <i32 8192, i32 8192, i32 8192, i32 8192>
  %200 = ashr <4 x i32> %199, <i32 14, i32 14, i32 14, i32 14>
  %201 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %197, <4 x i32> %200) #4
  %202 = shufflevector <8 x i16> %175, <8 x i16> %174, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %203 = shufflevector <8 x i16> %175, <8 x i16> %174, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %204 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %202, <8 x i16> <i16 -16069, i16 -3196, i16 -16069, i16 -3196, i16 -16069, i16 -3196, i16 -16069, i16 -3196>) #4
  %205 = add <4 x i32> %204, <i32 8192, i32 8192, i32 8192, i32 8192>
  %206 = ashr <4 x i32> %205, <i32 14, i32 14, i32 14, i32 14>
  %207 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %203, <8 x i16> <i16 -16069, i16 -3196, i16 -16069, i16 -3196, i16 -16069, i16 -3196, i16 -16069, i16 -3196>) #4
  %208 = add <4 x i32> %207, <i32 8192, i32 8192, i32 8192, i32 8192>
  %209 = ashr <4 x i32> %208, <i32 14, i32 14, i32 14, i32 14>
  %210 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %206, <4 x i32> %209) #4
  %211 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %202, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #4
  %212 = add <4 x i32> %211, <i32 8192, i32 8192, i32 8192, i32 8192>
  %213 = ashr <4 x i32> %212, <i32 14, i32 14, i32 14, i32 14>
  %214 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %203, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #4
  %215 = add <4 x i32> %214, <i32 8192, i32 8192, i32 8192, i32 8192>
  %216 = ashr <4 x i32> %215, <i32 14, i32 14, i32 14, i32 14>
  %217 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %213, <4 x i32> %216) #4
  %218 = shufflevector <8 x i16> %180, <8 x i16> %179, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %219 = shufflevector <8 x i16> %180, <8 x i16> %179, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %220 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %218, <8 x i16> <i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102>) #4
  %221 = add <4 x i32> %220, <i32 8192, i32 8192, i32 8192, i32 8192>
  %222 = ashr <4 x i32> %221, <i32 14, i32 14, i32 14, i32 14>
  %223 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %219, <8 x i16> <i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102>) #4
  %224 = add <4 x i32> %223, <i32 8192, i32 8192, i32 8192, i32 8192>
  %225 = ashr <4 x i32> %224, <i32 14, i32 14, i32 14, i32 14>
  %226 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %222, <4 x i32> %225) #4
  %227 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %218, <8 x i16> <i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623>) #4
  %228 = add <4 x i32> %227, <i32 8192, i32 8192, i32 8192, i32 8192>
  %229 = ashr <4 x i32> %228, <i32 14, i32 14, i32 14, i32 14>
  %230 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %219, <8 x i16> <i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623>) #4
  %231 = add <4 x i32> %230, <i32 8192, i32 8192, i32 8192, i32 8192>
  %232 = ashr <4 x i32> %231, <i32 14, i32 14, i32 14, i32 14>
  %233 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %229, <4 x i32> %232) #4
  %234 = shufflevector <8 x i16> %185, <8 x i16> %184, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %235 = shufflevector <8 x i16> %185, <8 x i16> %184, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %236 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %234, <8 x i16> <i16 -9102, i16 -13623, i16 -9102, i16 -13623, i16 -9102, i16 -13623, i16 -9102, i16 -13623>) #4
  %237 = add <4 x i32> %236, <i32 8192, i32 8192, i32 8192, i32 8192>
  %238 = ashr <4 x i32> %237, <i32 14, i32 14, i32 14, i32 14>
  %239 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %235, <8 x i16> <i16 -9102, i16 -13623, i16 -9102, i16 -13623, i16 -9102, i16 -13623, i16 -9102, i16 -13623>) #4
  %240 = add <4 x i32> %239, <i32 8192, i32 8192, i32 8192, i32 8192>
  %241 = ashr <4 x i32> %240, <i32 14, i32 14, i32 14, i32 14>
  %242 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %238, <4 x i32> %241) #4
  %243 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %234, <8 x i16> <i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102>) #4
  %244 = add <4 x i32> %243, <i32 8192, i32 8192, i32 8192, i32 8192>
  %245 = ashr <4 x i32> %244, <i32 14, i32 14, i32 14, i32 14>
  %246 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %235, <8 x i16> <i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102>) #4
  %247 = add <4 x i32> %246, <i32 8192, i32 8192, i32 8192, i32 8192>
  %248 = ashr <4 x i32> %247, <i32 14, i32 14, i32 14, i32 14>
  %249 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %245, <4 x i32> %248) #4
  %250 = add <8 x i16> %174, %169
  %251 = add <8 x i16> %210, %194
  %252 = sub <8 x i16> %194, %210
  %253 = sub <8 x i16> %169, %174
  %254 = sub <8 x i16> %184, %179
  %255 = sub <8 x i16> %242, %226
  %256 = add <8 x i16> %242, %226
  %257 = add <8 x i16> %184, %179
  %258 = add <8 x i16> %185, %180
  %259 = add <8 x i16> %249, %233
  %260 = sub <8 x i16> %249, %233
  %261 = sub <8 x i16> %185, %180
  %262 = sub <8 x i16> %170, %175
  %263 = sub <8 x i16> %201, %217
  %264 = add <8 x i16> %217, %201
  %265 = add <8 x i16> %175, %170
  %266 = shufflevector <8 x i16> %263, <8 x i16> %252, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %267 = shufflevector <8 x i16> %263, <8 x i16> %252, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %268 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %266, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #4
  %269 = add <4 x i32> %268, <i32 8192, i32 8192, i32 8192, i32 8192>
  %270 = ashr <4 x i32> %269, <i32 14, i32 14, i32 14, i32 14>
  %271 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %267, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #4
  %272 = add <4 x i32> %271, <i32 8192, i32 8192, i32 8192, i32 8192>
  %273 = ashr <4 x i32> %272, <i32 14, i32 14, i32 14, i32 14>
  %274 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %270, <4 x i32> %273) #4
  %275 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %266, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #4
  %276 = add <4 x i32> %275, <i32 8192, i32 8192, i32 8192, i32 8192>
  %277 = ashr <4 x i32> %276, <i32 14, i32 14, i32 14, i32 14>
  %278 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %267, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #4
  %279 = add <4 x i32> %278, <i32 8192, i32 8192, i32 8192, i32 8192>
  %280 = ashr <4 x i32> %279, <i32 14, i32 14, i32 14, i32 14>
  %281 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %277, <4 x i32> %280) #4
  %282 = shufflevector <8 x i16> %262, <8 x i16> %253, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %283 = shufflevector <8 x i16> %262, <8 x i16> %253, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %284 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %282, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #4
  %285 = add <4 x i32> %284, <i32 8192, i32 8192, i32 8192, i32 8192>
  %286 = ashr <4 x i32> %285, <i32 14, i32 14, i32 14, i32 14>
  %287 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %283, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #4
  %288 = add <4 x i32> %287, <i32 8192, i32 8192, i32 8192, i32 8192>
  %289 = ashr <4 x i32> %288, <i32 14, i32 14, i32 14, i32 14>
  %290 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %286, <4 x i32> %289) #4
  %291 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %282, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #4
  %292 = add <4 x i32> %291, <i32 8192, i32 8192, i32 8192, i32 8192>
  %293 = ashr <4 x i32> %292, <i32 14, i32 14, i32 14, i32 14>
  %294 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %283, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #4
  %295 = add <4 x i32> %294, <i32 8192, i32 8192, i32 8192, i32 8192>
  %296 = ashr <4 x i32> %295, <i32 14, i32 14, i32 14, i32 14>
  %297 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %293, <4 x i32> %296) #4
  %298 = shufflevector <8 x i16> %261, <8 x i16> %254, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %299 = shufflevector <8 x i16> %261, <8 x i16> %254, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %300 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %298, <8 x i16> <i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270>) #4
  %301 = add <4 x i32> %300, <i32 8192, i32 8192, i32 8192, i32 8192>
  %302 = ashr <4 x i32> %301, <i32 14, i32 14, i32 14, i32 14>
  %303 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %299, <8 x i16> <i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270>) #4
  %304 = add <4 x i32> %303, <i32 8192, i32 8192, i32 8192, i32 8192>
  %305 = ashr <4 x i32> %304, <i32 14, i32 14, i32 14, i32 14>
  %306 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %302, <4 x i32> %305) #4
  %307 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %298, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #4
  %308 = add <4 x i32> %307, <i32 8192, i32 8192, i32 8192, i32 8192>
  %309 = ashr <4 x i32> %308, <i32 14, i32 14, i32 14, i32 14>
  %310 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %299, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #4
  %311 = add <4 x i32> %310, <i32 8192, i32 8192, i32 8192, i32 8192>
  %312 = ashr <4 x i32> %311, <i32 14, i32 14, i32 14, i32 14>
  %313 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %309, <4 x i32> %312) #4
  %314 = shufflevector <8 x i16> %260, <8 x i16> %255, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %315 = shufflevector <8 x i16> %260, <8 x i16> %255, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %316 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %314, <8 x i16> <i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270>) #4
  %317 = add <4 x i32> %316, <i32 8192, i32 8192, i32 8192, i32 8192>
  %318 = ashr <4 x i32> %317, <i32 14, i32 14, i32 14, i32 14>
  %319 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %315, <8 x i16> <i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270>) #4
  %320 = add <4 x i32> %319, <i32 8192, i32 8192, i32 8192, i32 8192>
  %321 = ashr <4 x i32> %320, <i32 14, i32 14, i32 14, i32 14>
  %322 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %318, <4 x i32> %321) #4
  %323 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %314, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #4
  %324 = add <4 x i32> %323, <i32 8192, i32 8192, i32 8192, i32 8192>
  %325 = ashr <4 x i32> %324, <i32 14, i32 14, i32 14, i32 14>
  %326 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %315, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #4
  %327 = add <4 x i32> %326, <i32 8192, i32 8192, i32 8192, i32 8192>
  %328 = ashr <4 x i32> %327, <i32 14, i32 14, i32 14, i32 14>
  %329 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %325, <4 x i32> %328) #4
  %330 = add <8 x i16> %257, %250
  %331 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 16
  %332 = bitcast <2 x i64>* %331 to <8 x i16>*
  store <8 x i16> %330, <8 x i16>* %332, align 16
  %333 = add <8 x i16> %256, %251
  %334 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 17
  %335 = bitcast <2 x i64>* %334 to <8 x i16>*
  store <8 x i16> %333, <8 x i16>* %335, align 16
  %336 = add <8 x i16> %322, %274
  %337 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 18
  %338 = bitcast <2 x i64>* %337 to <8 x i16>*
  store <8 x i16> %336, <8 x i16>* %338, align 16
  %339 = add <8 x i16> %306, %290
  %340 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 19
  %341 = bitcast <2 x i64>* %340 to <8 x i16>*
  store <8 x i16> %339, <8 x i16>* %341, align 16
  %342 = sub <8 x i16> %290, %306
  %343 = sub <8 x i16> %274, %322
  %344 = sub <8 x i16> %251, %256
  %345 = sub <8 x i16> %250, %257
  %346 = sub <8 x i16> %265, %258
  %347 = sub <8 x i16> %264, %259
  %348 = sub <8 x i16> %281, %329
  %349 = sub <8 x i16> %297, %313
  %350 = add <8 x i16> %313, %297
  %351 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 28
  %352 = bitcast <2 x i64>* %351 to <8 x i16>*
  store <8 x i16> %350, <8 x i16>* %352, align 16
  %353 = add <8 x i16> %329, %281
  %354 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 29
  %355 = bitcast <2 x i64>* %354 to <8 x i16>*
  store <8 x i16> %353, <8 x i16>* %355, align 16
  %356 = add <8 x i16> %259, %264
  %357 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 30
  %358 = bitcast <2 x i64>* %357 to <8 x i16>*
  store <8 x i16> %356, <8 x i16>* %358, align 16
  %359 = add <8 x i16> %258, %265
  %360 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 31
  %361 = bitcast <2 x i64>* %360 to <8 x i16>*
  store <8 x i16> %359, <8 x i16>* %361, align 16
  %362 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 20
  %363 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 27
  %364 = shufflevector <8 x i16> %349, <8 x i16> %342, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %365 = shufflevector <8 x i16> %349, <8 x i16> %342, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %366 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %364, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #4
  %367 = add <4 x i32> %366, <i32 8192, i32 8192, i32 8192, i32 8192>
  %368 = ashr <4 x i32> %367, <i32 14, i32 14, i32 14, i32 14>
  %369 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %365, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #4
  %370 = add <4 x i32> %369, <i32 8192, i32 8192, i32 8192, i32 8192>
  %371 = ashr <4 x i32> %370, <i32 14, i32 14, i32 14, i32 14>
  %372 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %368, <4 x i32> %371) #4
  %373 = bitcast <2 x i64>* %362 to <8 x i16>*
  store <8 x i16> %372, <8 x i16>* %373, align 16
  %374 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %364, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #4
  %375 = add <4 x i32> %374, <i32 8192, i32 8192, i32 8192, i32 8192>
  %376 = ashr <4 x i32> %375, <i32 14, i32 14, i32 14, i32 14>
  %377 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %365, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #4
  %378 = add <4 x i32> %377, <i32 8192, i32 8192, i32 8192, i32 8192>
  %379 = ashr <4 x i32> %378, <i32 14, i32 14, i32 14, i32 14>
  %380 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %376, <4 x i32> %379) #4
  %381 = bitcast <2 x i64>* %363 to <8 x i16>*
  store <8 x i16> %380, <8 x i16>* %381, align 16
  %382 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 21
  %383 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 26
  %384 = shufflevector <8 x i16> %348, <8 x i16> %343, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %385 = shufflevector <8 x i16> %348, <8 x i16> %343, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %386 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %384, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #4
  %387 = add <4 x i32> %386, <i32 8192, i32 8192, i32 8192, i32 8192>
  %388 = ashr <4 x i32> %387, <i32 14, i32 14, i32 14, i32 14>
  %389 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %385, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #4
  %390 = add <4 x i32> %389, <i32 8192, i32 8192, i32 8192, i32 8192>
  %391 = ashr <4 x i32> %390, <i32 14, i32 14, i32 14, i32 14>
  %392 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %388, <4 x i32> %391) #4
  %393 = bitcast <2 x i64>* %382 to <8 x i16>*
  store <8 x i16> %392, <8 x i16>* %393, align 16
  %394 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %384, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #4
  %395 = add <4 x i32> %394, <i32 8192, i32 8192, i32 8192, i32 8192>
  %396 = ashr <4 x i32> %395, <i32 14, i32 14, i32 14, i32 14>
  %397 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %385, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #4
  %398 = add <4 x i32> %397, <i32 8192, i32 8192, i32 8192, i32 8192>
  %399 = ashr <4 x i32> %398, <i32 14, i32 14, i32 14, i32 14>
  %400 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %396, <4 x i32> %399) #4
  %401 = bitcast <2 x i64>* %383 to <8 x i16>*
  store <8 x i16> %400, <8 x i16>* %401, align 16
  %402 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 22
  %403 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 25
  %404 = shufflevector <8 x i16> %347, <8 x i16> %344, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %405 = shufflevector <8 x i16> %347, <8 x i16> %344, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %406 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %404, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #4
  %407 = add <4 x i32> %406, <i32 8192, i32 8192, i32 8192, i32 8192>
  %408 = ashr <4 x i32> %407, <i32 14, i32 14, i32 14, i32 14>
  %409 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %405, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #4
  %410 = add <4 x i32> %409, <i32 8192, i32 8192, i32 8192, i32 8192>
  %411 = ashr <4 x i32> %410, <i32 14, i32 14, i32 14, i32 14>
  %412 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %408, <4 x i32> %411) #4
  %413 = bitcast <2 x i64>* %402 to <8 x i16>*
  store <8 x i16> %412, <8 x i16>* %413, align 16
  %414 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %404, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #4
  %415 = add <4 x i32> %414, <i32 8192, i32 8192, i32 8192, i32 8192>
  %416 = ashr <4 x i32> %415, <i32 14, i32 14, i32 14, i32 14>
  %417 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %405, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #4
  %418 = add <4 x i32> %417, <i32 8192, i32 8192, i32 8192, i32 8192>
  %419 = ashr <4 x i32> %418, <i32 14, i32 14, i32 14, i32 14>
  %420 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %416, <4 x i32> %419) #4
  %421 = bitcast <2 x i64>* %403 to <8 x i16>*
  store <8 x i16> %420, <8 x i16>* %421, align 16
  %422 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 23
  %423 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 24
  %424 = shufflevector <8 x i16> %346, <8 x i16> %345, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %425 = shufflevector <8 x i16> %346, <8 x i16> %345, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %426 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %424, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #4
  %427 = add <4 x i32> %426, <i32 8192, i32 8192, i32 8192, i32 8192>
  %428 = ashr <4 x i32> %427, <i32 14, i32 14, i32 14, i32 14>
  %429 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %425, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #4
  %430 = add <4 x i32> %429, <i32 8192, i32 8192, i32 8192, i32 8192>
  %431 = ashr <4 x i32> %430, <i32 14, i32 14, i32 14, i32 14>
  %432 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %428, <4 x i32> %431) #4
  %433 = bitcast <2 x i64>* %422 to <8 x i16>*
  store <8 x i16> %432, <8 x i16>* %433, align 16
  %434 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %424, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #4
  %435 = add <4 x i32> %434, <i32 8192, i32 8192, i32 8192, i32 8192>
  %436 = ashr <4 x i32> %435, <i32 14, i32 14, i32 14, i32 14>
  %437 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %425, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #4
  %438 = add <4 x i32> %437, <i32 8192, i32 8192, i32 8192, i32 8192>
  %439 = ashr <4 x i32> %438, <i32 14, i32 14, i32 14, i32 14>
  %440 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %436, <4 x i32> %439) #4
  %441 = bitcast <2 x i64>* %423 to <8 x i16>*
  store <8 x i16> %440, <8 x i16>* %441, align 16
  br label %442

442:                                              ; preds = %442, %2
  %443 = phi i64 [ 0, %2 ], [ %459, %442 ]
  %444 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 %443
  %445 = bitcast <2 x i64>* %444 to <8 x i16>*
  %446 = load <8 x i16>, <8 x i16>* %445, align 16
  %447 = shl i64 %443, 32
  %448 = sub nuw nsw i64 133143986176, %447
  %449 = ashr exact i64 %448, 32
  %450 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 %449
  %451 = bitcast <2 x i64>* %450 to <8 x i16>*
  %452 = load <8 x i16>, <8 x i16>* %451, align 16
  %453 = add <8 x i16> %452, %446
  %454 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %443
  %455 = bitcast <2 x i64>* %454 to <8 x i16>*
  store <8 x i16> %453, <8 x i16>* %455, align 16
  %456 = sub <8 x i16> %446, %452
  %457 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %449
  %458 = bitcast <2 x i64>* %457 to <8 x i16>*
  store <8 x i16> %456, <8 x i16>* %458, align 16
  %459 = add nuw nsw i64 %443, 1
  %460 = icmp eq i64 %459, 16
  br i1 %460, label %461, label %442

461:                                              ; preds = %442
  call void @llvm.lifetime.end.p0i8(i64 512, i8* nonnull %4) #4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @vpx_idct32x32_34_add_ssse3(i32* nocapture readonly, i8* nocapture, i32) local_unnamed_addr #0 {
  %4 = alloca [32 x <2 x i64>], align 16
  %5 = alloca [32 x <2 x i64>], align 16
  %6 = bitcast [32 x <2 x i64>]* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 512, i8* nonnull %6) #4
  %7 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %4, i64 0, i64 7
  %8 = bitcast <2 x i64>* %7 to i8*
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %8, i8 -86, i64 400, i1 false)
  %9 = bitcast [32 x <2 x i64>]* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 512, i8* nonnull %9) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %9, i8 -86, i64 512, i1 false)
  %10 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %4, i64 0, i64 0
  %11 = bitcast i32* %0 to <4 x i32>*
  %12 = load <4 x i32>, <4 x i32>* %11, align 16
  %13 = getelementptr inbounds i32, i32* %0, i64 4
  %14 = bitcast i32* %13 to <4 x i32>*
  %15 = load <4 x i32>, <4 x i32>* %14, align 16
  %16 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %12, <4 x i32> %15) #4
  %17 = bitcast [32 x <2 x i64>]* %4 to <8 x i16>*
  store <8 x i16> %16, <8 x i16>* %17, align 16
  %18 = getelementptr inbounds i32, i32* %0, i64 32
  %19 = bitcast i32* %18 to <4 x i32>*
  %20 = load <4 x i32>, <4 x i32>* %19, align 16
  %21 = getelementptr inbounds i32, i32* %0, i64 36
  %22 = bitcast i32* %21 to <4 x i32>*
  %23 = load <4 x i32>, <4 x i32>* %22, align 16
  %24 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %20, <4 x i32> %23) #4
  %25 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %4, i64 0, i64 1
  %26 = getelementptr inbounds i32, i32* %0, i64 64
  %27 = bitcast i32* %26 to <4 x i32>*
  %28 = load <4 x i32>, <4 x i32>* %27, align 16
  %29 = getelementptr inbounds i32, i32* %0, i64 68
  %30 = bitcast i32* %29 to <4 x i32>*
  %31 = load <4 x i32>, <4 x i32>* %30, align 16
  %32 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %28, <4 x i32> %31) #4
  %33 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %4, i64 0, i64 2
  %34 = getelementptr inbounds i32, i32* %0, i64 96
  %35 = bitcast i32* %34 to <4 x i32>*
  %36 = load <4 x i32>, <4 x i32>* %35, align 16
  %37 = getelementptr inbounds i32, i32* %0, i64 100
  %38 = bitcast i32* %37 to <4 x i32>*
  %39 = load <4 x i32>, <4 x i32>* %38, align 16
  %40 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %36, <4 x i32> %39) #4
  %41 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %4, i64 0, i64 3
  %42 = getelementptr inbounds i32, i32* %0, i64 128
  %43 = bitcast i32* %42 to <4 x i32>*
  %44 = load <4 x i32>, <4 x i32>* %43, align 16
  %45 = getelementptr inbounds i32, i32* %0, i64 132
  %46 = bitcast i32* %45 to <4 x i32>*
  %47 = load <4 x i32>, <4 x i32>* %46, align 16
  %48 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %44, <4 x i32> %47) #4
  %49 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %4, i64 0, i64 4
  %50 = getelementptr inbounds i32, i32* %0, i64 160
  %51 = bitcast i32* %50 to <4 x i32>*
  %52 = load <4 x i32>, <4 x i32>* %51, align 16
  %53 = getelementptr inbounds i32, i32* %0, i64 164
  %54 = bitcast i32* %53 to <4 x i32>*
  %55 = load <4 x i32>, <4 x i32>* %54, align 16
  %56 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %52, <4 x i32> %55) #4
  %57 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %4, i64 0, i64 5
  %58 = getelementptr inbounds i32, i32* %0, i64 192
  %59 = bitcast i32* %58 to <4 x i32>*
  %60 = load <4 x i32>, <4 x i32>* %59, align 16
  %61 = getelementptr inbounds i32, i32* %0, i64 196
  %62 = bitcast i32* %61 to <4 x i32>*
  %63 = load <4 x i32>, <4 x i32>* %62, align 16
  %64 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %60, <4 x i32> %63) #4
  %65 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %4, i64 0, i64 6
  %66 = getelementptr inbounds i32, i32* %0, i64 224
  %67 = bitcast i32* %66 to <4 x i32>*
  %68 = load <4 x i32>, <4 x i32>* %67, align 16
  %69 = getelementptr inbounds i32, i32* %0, i64 228
  %70 = bitcast i32* %69 to <4 x i32>*
  %71 = load <4 x i32>, <4 x i32>* %70, align 16
  %72 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %68, <4 x i32> %71) #4
  %73 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %4, i64 0, i64 7
  %74 = shufflevector <8 x i16> %16, <8 x i16> %24, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %75 = shufflevector <8 x i16> %32, <8 x i16> %40, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %76 = shufflevector <8 x i16> %48, <8 x i16> %56, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %77 = shufflevector <8 x i16> %64, <8 x i16> %72, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %78 = shufflevector <8 x i16> %16, <8 x i16> %24, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %79 = shufflevector <8 x i16> %32, <8 x i16> %40, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %80 = shufflevector <8 x i16> %48, <8 x i16> %56, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %81 = shufflevector <8 x i16> %64, <8 x i16> %72, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %82 = bitcast <8 x i16> %74 to <4 x i32>
  %83 = bitcast <8 x i16> %75 to <4 x i32>
  %84 = shufflevector <4 x i32> %82, <4 x i32> %83, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %85 = bitcast <4 x i32> %84 to <2 x i64>
  %86 = bitcast <8 x i16> %76 to <4 x i32>
  %87 = bitcast <8 x i16> %77 to <4 x i32>
  %88 = shufflevector <4 x i32> %86, <4 x i32> %87, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %89 = bitcast <4 x i32> %88 to <2 x i64>
  %90 = bitcast <8 x i16> %78 to <4 x i32>
  %91 = bitcast <8 x i16> %79 to <4 x i32>
  %92 = shufflevector <4 x i32> %90, <4 x i32> %91, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %93 = bitcast <4 x i32> %92 to <2 x i64>
  %94 = bitcast <8 x i16> %80 to <4 x i32>
  %95 = bitcast <8 x i16> %81 to <4 x i32>
  %96 = shufflevector <4 x i32> %94, <4 x i32> %95, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %97 = bitcast <4 x i32> %96 to <2 x i64>
  %98 = shufflevector <4 x i32> %82, <4 x i32> %83, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %99 = bitcast <4 x i32> %98 to <2 x i64>
  %100 = shufflevector <4 x i32> %86, <4 x i32> %87, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %101 = bitcast <4 x i32> %100 to <2 x i64>
  %102 = shufflevector <4 x i32> %90, <4 x i32> %91, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %103 = bitcast <4 x i32> %102 to <2 x i64>
  %104 = shufflevector <4 x i32> %94, <4 x i32> %95, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %105 = bitcast <4 x i32> %104 to <2 x i64>
  %106 = shufflevector <2 x i64> %85, <2 x i64> %89, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %106, <2 x i64>* %10, align 16
  %107 = shufflevector <2 x i64> %85, <2 x i64> %89, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %107, <2 x i64>* %25, align 16
  %108 = shufflevector <2 x i64> %99, <2 x i64> %101, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %108, <2 x i64>* %33, align 16
  %109 = shufflevector <2 x i64> %99, <2 x i64> %101, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %109, <2 x i64>* %41, align 16
  %110 = shufflevector <2 x i64> %93, <2 x i64> %97, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %110, <2 x i64>* %49, align 16
  %111 = shufflevector <2 x i64> %93, <2 x i64> %97, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %111, <2 x i64>* %57, align 16
  %112 = shufflevector <2 x i64> %103, <2 x i64> %105, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %112, <2 x i64>* %65, align 16
  %113 = shufflevector <2 x i64> %103, <2 x i64> %105, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %113, <2 x i64>* %73, align 16
  %114 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 0
  call void @idct32_34_8x32_ssse3(<2 x i64>* nonnull %10, <2 x i64>* nonnull %114)
  %115 = sext i32 %2 to i64
  br label %116

116:                                              ; preds = %3, %204
  %117 = phi i64 [ 0, %3 ], [ %206, %204 ]
  %118 = phi i8* [ %1, %3 ], [ %205, %204 ]
  %119 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 %117
  %120 = bitcast <2 x i64>* %119 to <8 x i16>*
  %121 = load <8 x i16>, <8 x i16>* %120, align 16
  %122 = getelementptr inbounds <2 x i64>, <2 x i64>* %119, i64 1
  %123 = bitcast <2 x i64>* %122 to <8 x i16>*
  %124 = load <8 x i16>, <8 x i16>* %123, align 16
  %125 = shufflevector <8 x i16> %121, <8 x i16> %124, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %126 = getelementptr inbounds <2 x i64>, <2 x i64>* %119, i64 2
  %127 = bitcast <2 x i64>* %126 to <8 x i16>*
  %128 = load <8 x i16>, <8 x i16>* %127, align 16
  %129 = getelementptr inbounds <2 x i64>, <2 x i64>* %119, i64 3
  %130 = bitcast <2 x i64>* %129 to <8 x i16>*
  %131 = load <8 x i16>, <8 x i16>* %130, align 16
  %132 = shufflevector <8 x i16> %128, <8 x i16> %131, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %133 = getelementptr inbounds <2 x i64>, <2 x i64>* %119, i64 4
  %134 = bitcast <2 x i64>* %133 to <8 x i16>*
  %135 = load <8 x i16>, <8 x i16>* %134, align 16
  %136 = getelementptr inbounds <2 x i64>, <2 x i64>* %119, i64 5
  %137 = bitcast <2 x i64>* %136 to <8 x i16>*
  %138 = load <8 x i16>, <8 x i16>* %137, align 16
  %139 = shufflevector <8 x i16> %135, <8 x i16> %138, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %140 = getelementptr inbounds <2 x i64>, <2 x i64>* %119, i64 6
  %141 = bitcast <2 x i64>* %140 to <8 x i16>*
  %142 = load <8 x i16>, <8 x i16>* %141, align 16
  %143 = getelementptr inbounds <2 x i64>, <2 x i64>* %119, i64 7
  %144 = bitcast <2 x i64>* %143 to <8 x i16>*
  %145 = load <8 x i16>, <8 x i16>* %144, align 16
  %146 = shufflevector <8 x i16> %142, <8 x i16> %145, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %147 = shufflevector <8 x i16> %121, <8 x i16> %124, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %148 = shufflevector <8 x i16> %128, <8 x i16> %131, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %149 = shufflevector <8 x i16> %135, <8 x i16> %138, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %150 = shufflevector <8 x i16> %142, <8 x i16> %145, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %151 = bitcast <8 x i16> %125 to <4 x i32>
  %152 = bitcast <8 x i16> %132 to <4 x i32>
  %153 = shufflevector <4 x i32> %151, <4 x i32> %152, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %154 = bitcast <4 x i32> %153 to <2 x i64>
  %155 = bitcast <8 x i16> %139 to <4 x i32>
  %156 = bitcast <8 x i16> %146 to <4 x i32>
  %157 = shufflevector <4 x i32> %155, <4 x i32> %156, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %158 = bitcast <4 x i32> %157 to <2 x i64>
  %159 = bitcast <8 x i16> %147 to <4 x i32>
  %160 = bitcast <8 x i16> %148 to <4 x i32>
  %161 = shufflevector <4 x i32> %159, <4 x i32> %160, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %162 = bitcast <4 x i32> %161 to <2 x i64>
  %163 = bitcast <8 x i16> %149 to <4 x i32>
  %164 = bitcast <8 x i16> %150 to <4 x i32>
  %165 = shufflevector <4 x i32> %163, <4 x i32> %164, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %166 = bitcast <4 x i32> %165 to <2 x i64>
  %167 = shufflevector <4 x i32> %151, <4 x i32> %152, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %168 = bitcast <4 x i32> %167 to <2 x i64>
  %169 = shufflevector <4 x i32> %155, <4 x i32> %156, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %170 = bitcast <4 x i32> %169 to <2 x i64>
  %171 = shufflevector <4 x i32> %159, <4 x i32> %160, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %172 = bitcast <4 x i32> %171 to <2 x i64>
  %173 = shufflevector <4 x i32> %163, <4 x i32> %164, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %174 = bitcast <4 x i32> %173 to <2 x i64>
  %175 = shufflevector <2 x i64> %154, <2 x i64> %158, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %175, <2 x i64>* %10, align 16
  %176 = shufflevector <2 x i64> %154, <2 x i64> %158, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %176, <2 x i64>* %25, align 16
  %177 = shufflevector <2 x i64> %168, <2 x i64> %170, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %177, <2 x i64>* %33, align 16
  %178 = shufflevector <2 x i64> %168, <2 x i64> %170, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %178, <2 x i64>* %41, align 16
  %179 = shufflevector <2 x i64> %162, <2 x i64> %166, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %179, <2 x i64>* %49, align 16
  %180 = shufflevector <2 x i64> %162, <2 x i64> %166, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %180, <2 x i64>* %57, align 16
  %181 = shufflevector <2 x i64> %172, <2 x i64> %174, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %181, <2 x i64>* %65, align 16
  %182 = shufflevector <2 x i64> %172, <2 x i64> %174, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %182, <2 x i64>* %73, align 16
  call void @idct32_34_8x32_ssse3(<2 x i64>* nonnull %10, <2 x i64>* nonnull %10)
  br label %183

183:                                              ; preds = %183, %116
  %184 = phi i64 [ 0, %116 ], [ %202, %183 ]
  %185 = mul nsw i64 %184, %115
  %186 = getelementptr inbounds i8, i8* %118, i64 %185
  %187 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %4, i64 0, i64 %184
  %188 = bitcast <2 x i64>* %187 to <8 x i16>*
  %189 = load <8 x i16>, <8 x i16>* %188, align 16
  %190 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %189, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #4
  %191 = ashr <8 x i16> %190, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  %192 = bitcast i8* %186 to i64*
  %193 = load i64, i64* %192, align 1
  %194 = insertelement <2 x i64> undef, i64 %193, i32 0
  %195 = bitcast <2 x i64> %194 to <16 x i8>
  %196 = shufflevector <16 x i8> %195, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %197 = bitcast <16 x i8> %196 to <8 x i16>
  %198 = add <8 x i16> %191, %197
  %199 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %198, <8 x i16> undef) #4
  %200 = bitcast <16 x i8> %199 to <2 x i64>
  %201 = extractelement <2 x i64> %200, i32 0
  store i64 %201, i64* %192, align 1
  %202 = add nuw nsw i64 %184, 1
  %203 = icmp eq i64 %202, 32
  br i1 %203, label %204, label %183

204:                                              ; preds = %183
  %205 = getelementptr inbounds i8, i8* %118, i64 8
  %206 = add nuw nsw i64 %117, 8
  %207 = icmp ult i64 %206, 32
  br i1 %207, label %116, label %208

208:                                              ; preds = %204
  call void @llvm.lifetime.end.p0i8(i64 512, i8* nonnull %9) #4
  call void @llvm.lifetime.end.p0i8(i64 512, i8* nonnull %6) #4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @idct32_135_8x32_ssse3(<2 x i64>* nocapture readonly, <2 x i64>* nocapture) local_unnamed_addr #0 {
  %3 = alloca [32 x <2 x i64>], align 16
  %4 = bitcast [32 x <2 x i64>]* %3 to i8*
  call void @llvm.lifetime.start.p0i8(i64 512, i8* nonnull %4) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %4, i8 -86, i64 512, i1 false)
  %5 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 4
  %6 = bitcast <2 x i64>* %5 to <8 x i16>*
  %7 = load <8 x i16>, <8 x i16>* %6, align 16
  %8 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %7, <8 x i16> <i16 6392, i16 6392, i16 6392, i16 6392, i16 6392, i16 6392, i16 6392, i16 6392>) #4
  %9 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %7, <8 x i16> <i16 32138, i16 32138, i16 32138, i16 32138, i16 32138, i16 32138, i16 32138, i16 32138>) #4
  %10 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 12
  %11 = bitcast <2 x i64>* %10 to <8 x i16>*
  %12 = load <8 x i16>, <8 x i16>* %11, align 16
  %13 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %12, <8 x i16> <i16 -18204, i16 -18204, i16 -18204, i16 -18204, i16 -18204, i16 -18204, i16 -18204, i16 -18204>) #4
  %14 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %12, <8 x i16> <i16 27246, i16 27246, i16 27246, i16 27246, i16 27246, i16 27246, i16 27246, i16 27246>) #4
  %15 = bitcast <2 x i64>* %0 to <8 x i16>*
  %16 = load <8 x i16>, <8 x i16>* %15, align 16
  %17 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %16, <8 x i16> <i16 23170, i16 23170, i16 23170, i16 23170, i16 23170, i16 23170, i16 23170, i16 23170>) #4
  %18 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 8
  %19 = bitcast <2 x i64>* %18 to <8 x i16>*
  %20 = load <8 x i16>, <8 x i16>* %19, align 16
  %21 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %20, <8 x i16> <i16 12540, i16 12540, i16 12540, i16 12540, i16 12540, i16 12540, i16 12540, i16 12540>) #4
  %22 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %20, <8 x i16> <i16 30274, i16 30274, i16 30274, i16 30274, i16 30274, i16 30274, i16 30274, i16 30274>) #4
  %23 = add <8 x i16> %13, %8
  %24 = sub <8 x i16> %8, %13
  %25 = sub <8 x i16> %9, %14
  %26 = add <8 x i16> %14, %9
  %27 = add <8 x i16> %22, %17
  %28 = add <8 x i16> %21, %17
  %29 = sub <8 x i16> %17, %21
  %30 = sub <8 x i16> %17, %22
  %31 = shufflevector <8 x i16> %25, <8 x i16> %24, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %32 = shufflevector <8 x i16> %25, <8 x i16> %24, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %33 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %31, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #4
  %34 = add <4 x i32> %33, <i32 8192, i32 8192, i32 8192, i32 8192>
  %35 = ashr <4 x i32> %34, <i32 14, i32 14, i32 14, i32 14>
  %36 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %32, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #4
  %37 = add <4 x i32> %36, <i32 8192, i32 8192, i32 8192, i32 8192>
  %38 = ashr <4 x i32> %37, <i32 14, i32 14, i32 14, i32 14>
  %39 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %35, <4 x i32> %38) #4
  %40 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %31, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #4
  %41 = add <4 x i32> %40, <i32 8192, i32 8192, i32 8192, i32 8192>
  %42 = ashr <4 x i32> %41, <i32 14, i32 14, i32 14, i32 14>
  %43 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %32, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #4
  %44 = add <4 x i32> %43, <i32 8192, i32 8192, i32 8192, i32 8192>
  %45 = ashr <4 x i32> %44, <i32 14, i32 14, i32 14, i32 14>
  %46 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %42, <4 x i32> %45) #4
  %47 = add <8 x i16> %27, %26
  %48 = add <8 x i16> %46, %28
  %49 = add <8 x i16> %39, %29
  %50 = add <8 x i16> %30, %23
  %51 = sub <8 x i16> %30, %23
  %52 = sub <8 x i16> %29, %39
  %53 = sub <8 x i16> %28, %46
  %54 = sub <8 x i16> %27, %26
  %55 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 2
  %56 = bitcast <2 x i64>* %55 to <8 x i16>*
  %57 = load <8 x i16>, <8 x i16>* %56, align 16
  %58 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %57, <8 x i16> <i16 3212, i16 3212, i16 3212, i16 3212, i16 3212, i16 3212, i16 3212, i16 3212>) #4
  %59 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %57, <8 x i16> <i16 32610, i16 32610, i16 32610, i16 32610, i16 32610, i16 32610, i16 32610, i16 32610>) #4
  %60 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 14
  %61 = bitcast <2 x i64>* %60 to <8 x i16>*
  %62 = load <8 x i16>, <8 x i16>* %61, align 16
  %63 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %62, <8 x i16> <i16 -20788, i16 -20788, i16 -20788, i16 -20788, i16 -20788, i16 -20788, i16 -20788, i16 -20788>) #4
  %64 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %62, <8 x i16> <i16 25330, i16 25330, i16 25330, i16 25330, i16 25330, i16 25330, i16 25330, i16 25330>) #4
  %65 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 10
  %66 = bitcast <2 x i64>* %65 to <8 x i16>*
  %67 = load <8 x i16>, <8 x i16>* %66, align 16
  %68 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %67, <8 x i16> <i16 15446, i16 15446, i16 15446, i16 15446, i16 15446, i16 15446, i16 15446, i16 15446>) #4
  %69 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %67, <8 x i16> <i16 28898, i16 28898, i16 28898, i16 28898, i16 28898, i16 28898, i16 28898, i16 28898>) #4
  %70 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 6
  %71 = bitcast <2 x i64>* %70 to <8 x i16>*
  %72 = load <8 x i16>, <8 x i16>* %71, align 16
  %73 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %72, <8 x i16> <i16 -9512, i16 -9512, i16 -9512, i16 -9512, i16 -9512, i16 -9512, i16 -9512, i16 -9512>) #4
  %74 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %72, <8 x i16> <i16 31358, i16 31358, i16 31358, i16 31358, i16 31358, i16 31358, i16 31358, i16 31358>) #4
  %75 = add <8 x i16> %63, %58
  %76 = sub <8 x i16> %58, %63
  %77 = sub <8 x i16> %73, %68
  %78 = add <8 x i16> %73, %68
  %79 = add <8 x i16> %74, %69
  %80 = sub <8 x i16> %74, %69
  %81 = sub <8 x i16> %59, %64
  %82 = add <8 x i16> %64, %59
  %83 = shufflevector <8 x i16> %81, <8 x i16> %76, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %84 = shufflevector <8 x i16> %81, <8 x i16> %76, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %85 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %83, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #4
  %86 = add <4 x i32> %85, <i32 8192, i32 8192, i32 8192, i32 8192>
  %87 = ashr <4 x i32> %86, <i32 14, i32 14, i32 14, i32 14>
  %88 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %84, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #4
  %89 = add <4 x i32> %88, <i32 8192, i32 8192, i32 8192, i32 8192>
  %90 = ashr <4 x i32> %89, <i32 14, i32 14, i32 14, i32 14>
  %91 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %87, <4 x i32> %90) #4
  %92 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %83, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #4
  %93 = add <4 x i32> %92, <i32 8192, i32 8192, i32 8192, i32 8192>
  %94 = ashr <4 x i32> %93, <i32 14, i32 14, i32 14, i32 14>
  %95 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %84, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #4
  %96 = add <4 x i32> %95, <i32 8192, i32 8192, i32 8192, i32 8192>
  %97 = ashr <4 x i32> %96, <i32 14, i32 14, i32 14, i32 14>
  %98 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %94, <4 x i32> %97) #4
  %99 = shufflevector <8 x i16> %80, <8 x i16> %77, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %100 = shufflevector <8 x i16> %80, <8 x i16> %77, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %101 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %99, <8 x i16> <i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270>) #4
  %102 = add <4 x i32> %101, <i32 8192, i32 8192, i32 8192, i32 8192>
  %103 = ashr <4 x i32> %102, <i32 14, i32 14, i32 14, i32 14>
  %104 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %100, <8 x i16> <i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270>) #4
  %105 = add <4 x i32> %104, <i32 8192, i32 8192, i32 8192, i32 8192>
  %106 = ashr <4 x i32> %105, <i32 14, i32 14, i32 14, i32 14>
  %107 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %103, <4 x i32> %106) #4
  %108 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %99, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #4
  %109 = add <4 x i32> %108, <i32 8192, i32 8192, i32 8192, i32 8192>
  %110 = ashr <4 x i32> %109, <i32 14, i32 14, i32 14, i32 14>
  %111 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %100, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #4
  %112 = add <4 x i32> %111, <i32 8192, i32 8192, i32 8192, i32 8192>
  %113 = ashr <4 x i32> %112, <i32 14, i32 14, i32 14, i32 14>
  %114 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %110, <4 x i32> %113) #4
  %115 = add <8 x i16> %78, %75
  %116 = add <8 x i16> %107, %91
  %117 = sub <8 x i16> %91, %107
  %118 = sub <8 x i16> %75, %78
  %119 = sub <8 x i16> %82, %79
  %120 = sub <8 x i16> %98, %114
  %121 = add <8 x i16> %114, %98
  %122 = add <8 x i16> %79, %82
  %123 = shufflevector <8 x i16> %120, <8 x i16> %117, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %124 = shufflevector <8 x i16> %120, <8 x i16> %117, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %125 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %123, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #4
  %126 = add <4 x i32> %125, <i32 8192, i32 8192, i32 8192, i32 8192>
  %127 = ashr <4 x i32> %126, <i32 14, i32 14, i32 14, i32 14>
  %128 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %124, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #4
  %129 = add <4 x i32> %128, <i32 8192, i32 8192, i32 8192, i32 8192>
  %130 = ashr <4 x i32> %129, <i32 14, i32 14, i32 14, i32 14>
  %131 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %127, <4 x i32> %130) #4
  %132 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %123, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #4
  %133 = add <4 x i32> %132, <i32 8192, i32 8192, i32 8192, i32 8192>
  %134 = ashr <4 x i32> %133, <i32 14, i32 14, i32 14, i32 14>
  %135 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %124, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #4
  %136 = add <4 x i32> %135, <i32 8192, i32 8192, i32 8192, i32 8192>
  %137 = ashr <4 x i32> %136, <i32 14, i32 14, i32 14, i32 14>
  %138 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %134, <4 x i32> %137) #4
  %139 = shufflevector <8 x i16> %119, <8 x i16> %118, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %140 = shufflevector <8 x i16> %119, <8 x i16> %118, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %141 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %139, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #4
  %142 = add <4 x i32> %141, <i32 8192, i32 8192, i32 8192, i32 8192>
  %143 = ashr <4 x i32> %142, <i32 14, i32 14, i32 14, i32 14>
  %144 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %140, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #4
  %145 = add <4 x i32> %144, <i32 8192, i32 8192, i32 8192, i32 8192>
  %146 = ashr <4 x i32> %145, <i32 14, i32 14, i32 14, i32 14>
  %147 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %143, <4 x i32> %146) #4
  %148 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %139, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #4
  %149 = add <4 x i32> %148, <i32 8192, i32 8192, i32 8192, i32 8192>
  %150 = ashr <4 x i32> %149, <i32 14, i32 14, i32 14, i32 14>
  %151 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %140, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #4
  %152 = add <4 x i32> %151, <i32 8192, i32 8192, i32 8192, i32 8192>
  %153 = ashr <4 x i32> %152, <i32 14, i32 14, i32 14, i32 14>
  %154 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %150, <4 x i32> %153) #4
  %155 = add <8 x i16> %122, %47
  %156 = bitcast [32 x <2 x i64>]* %3 to <8 x i16>*
  store <8 x i16> %155, <8 x i16>* %156, align 16
  %157 = sub <8 x i16> %47, %122
  %158 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 15
  %159 = bitcast <2 x i64>* %158 to <8 x i16>*
  store <8 x i16> %157, <8 x i16>* %159, align 16
  %160 = add <8 x i16> %121, %48
  %161 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 1
  %162 = bitcast <2 x i64>* %161 to <8 x i16>*
  store <8 x i16> %160, <8 x i16>* %162, align 16
  %163 = sub <8 x i16> %48, %121
  %164 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 14
  %165 = bitcast <2 x i64>* %164 to <8 x i16>*
  store <8 x i16> %163, <8 x i16>* %165, align 16
  %166 = add <8 x i16> %138, %49
  %167 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 2
  %168 = bitcast <2 x i64>* %167 to <8 x i16>*
  store <8 x i16> %166, <8 x i16>* %168, align 16
  %169 = sub <8 x i16> %49, %138
  %170 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 13
  %171 = bitcast <2 x i64>* %170 to <8 x i16>*
  store <8 x i16> %169, <8 x i16>* %171, align 16
  %172 = add <8 x i16> %154, %50
  %173 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 3
  %174 = bitcast <2 x i64>* %173 to <8 x i16>*
  store <8 x i16> %172, <8 x i16>* %174, align 16
  %175 = sub <8 x i16> %50, %154
  %176 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 12
  %177 = bitcast <2 x i64>* %176 to <8 x i16>*
  store <8 x i16> %175, <8 x i16>* %177, align 16
  %178 = add <8 x i16> %147, %51
  %179 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 4
  %180 = bitcast <2 x i64>* %179 to <8 x i16>*
  store <8 x i16> %178, <8 x i16>* %180, align 16
  %181 = sub <8 x i16> %51, %147
  %182 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 11
  %183 = bitcast <2 x i64>* %182 to <8 x i16>*
  store <8 x i16> %181, <8 x i16>* %183, align 16
  %184 = add <8 x i16> %131, %52
  %185 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 5
  %186 = bitcast <2 x i64>* %185 to <8 x i16>*
  store <8 x i16> %184, <8 x i16>* %186, align 16
  %187 = sub <8 x i16> %52, %131
  %188 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 10
  %189 = bitcast <2 x i64>* %188 to <8 x i16>*
  store <8 x i16> %187, <8 x i16>* %189, align 16
  %190 = add <8 x i16> %116, %53
  %191 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 6
  %192 = bitcast <2 x i64>* %191 to <8 x i16>*
  store <8 x i16> %190, <8 x i16>* %192, align 16
  %193 = sub <8 x i16> %53, %116
  %194 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 9
  %195 = bitcast <2 x i64>* %194 to <8 x i16>*
  store <8 x i16> %193, <8 x i16>* %195, align 16
  %196 = add <8 x i16> %115, %54
  %197 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 7
  %198 = bitcast <2 x i64>* %197 to <8 x i16>*
  store <8 x i16> %196, <8 x i16>* %198, align 16
  %199 = sub <8 x i16> %54, %115
  %200 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 8
  %201 = bitcast <2 x i64>* %200 to <8 x i16>*
  store <8 x i16> %199, <8 x i16>* %201, align 16
  %202 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 1
  %203 = bitcast <2 x i64>* %202 to <8 x i16>*
  %204 = load <8 x i16>, <8 x i16>* %203, align 16
  %205 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %204, <8 x i16> <i16 1608, i16 1608, i16 1608, i16 1608, i16 1608, i16 1608, i16 1608, i16 1608>) #4
  %206 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %204, <8 x i16> <i16 32728, i16 32728, i16 32728, i16 32728, i16 32728, i16 32728, i16 32728, i16 32728>) #4
  %207 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 15
  %208 = bitcast <2 x i64>* %207 to <8 x i16>*
  %209 = load <8 x i16>, <8 x i16>* %208, align 16
  %210 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %209, <8 x i16> <i16 -22006, i16 -22006, i16 -22006, i16 -22006, i16 -22006, i16 -22006, i16 -22006, i16 -22006>) #4
  %211 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %209, <8 x i16> <i16 24280, i16 24280, i16 24280, i16 24280, i16 24280, i16 24280, i16 24280, i16 24280>) #4
  %212 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 9
  %213 = bitcast <2 x i64>* %212 to <8 x i16>*
  %214 = load <8 x i16>, <8 x i16>* %213, align 16
  %215 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %214, <8 x i16> <i16 14010, i16 14010, i16 14010, i16 14010, i16 14010, i16 14010, i16 14010, i16 14010>) #4
  %216 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %214, <8 x i16> <i16 29622, i16 29622, i16 29622, i16 29622, i16 29622, i16 29622, i16 29622, i16 29622>) #4
  %217 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 7
  %218 = bitcast <2 x i64>* %217 to <8 x i16>*
  %219 = load <8 x i16>, <8 x i16>* %218, align 16
  %220 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %219, <8 x i16> <i16 -11040, i16 -11040, i16 -11040, i16 -11040, i16 -11040, i16 -11040, i16 -11040, i16 -11040>) #4
  %221 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %219, <8 x i16> <i16 30852, i16 30852, i16 30852, i16 30852, i16 30852, i16 30852, i16 30852, i16 30852>) #4
  %222 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 5
  %223 = bitcast <2 x i64>* %222 to <8 x i16>*
  %224 = load <8 x i16>, <8 x i16>* %223, align 16
  %225 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %224, <8 x i16> <i16 7962, i16 7962, i16 7962, i16 7962, i16 7962, i16 7962, i16 7962, i16 7962>) #4
  %226 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %224, <8 x i16> <i16 31786, i16 31786, i16 31786, i16 31786, i16 31786, i16 31786, i16 31786, i16 31786>) #4
  %227 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 11
  %228 = bitcast <2 x i64>* %227 to <8 x i16>*
  %229 = load <8 x i16>, <8 x i16>* %228, align 16
  %230 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %229, <8 x i16> <i16 -16846, i16 -16846, i16 -16846, i16 -16846, i16 -16846, i16 -16846, i16 -16846, i16 -16846>) #4
  %231 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %229, <8 x i16> <i16 28106, i16 28106, i16 28106, i16 28106, i16 28106, i16 28106, i16 28106, i16 28106>) #4
  %232 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 13
  %233 = bitcast <2 x i64>* %232 to <8 x i16>*
  %234 = load <8 x i16>, <8 x i16>* %233, align 16
  %235 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %234, <8 x i16> <i16 19520, i16 19520, i16 19520, i16 19520, i16 19520, i16 19520, i16 19520, i16 19520>) #4
  %236 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %234, <8 x i16> <i16 26320, i16 26320, i16 26320, i16 26320, i16 26320, i16 26320, i16 26320, i16 26320>) #4
  %237 = getelementptr inbounds <2 x i64>, <2 x i64>* %0, i64 3
  %238 = bitcast <2 x i64>* %237 to <8 x i16>*
  %239 = load <8 x i16>, <8 x i16>* %238, align 16
  %240 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %239, <8 x i16> <i16 -4808, i16 -4808, i16 -4808, i16 -4808, i16 -4808, i16 -4808, i16 -4808, i16 -4808>) #4
  %241 = tail call <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16> %239, <8 x i16> <i16 32414, i16 32414, i16 32414, i16 32414, i16 32414, i16 32414, i16 32414, i16 32414>) #4
  %242 = add <8 x i16> %210, %205
  %243 = sub <8 x i16> %205, %210
  %244 = sub <8 x i16> %220, %215
  %245 = add <8 x i16> %220, %215
  %246 = add <8 x i16> %230, %225
  %247 = sub <8 x i16> %225, %230
  %248 = sub <8 x i16> %240, %235
  %249 = add <8 x i16> %240, %235
  %250 = add <8 x i16> %241, %236
  %251 = sub <8 x i16> %241, %236
  %252 = sub <8 x i16> %226, %231
  %253 = add <8 x i16> %231, %226
  %254 = add <8 x i16> %221, %216
  %255 = sub <8 x i16> %221, %216
  %256 = sub <8 x i16> %206, %211
  %257 = add <8 x i16> %211, %206
  %258 = shufflevector <8 x i16> %256, <8 x i16> %243, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %259 = shufflevector <8 x i16> %256, <8 x i16> %243, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %260 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %258, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #4
  %261 = add <4 x i32> %260, <i32 8192, i32 8192, i32 8192, i32 8192>
  %262 = ashr <4 x i32> %261, <i32 14, i32 14, i32 14, i32 14>
  %263 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %259, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #4
  %264 = add <4 x i32> %263, <i32 8192, i32 8192, i32 8192, i32 8192>
  %265 = ashr <4 x i32> %264, <i32 14, i32 14, i32 14, i32 14>
  %266 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %262, <4 x i32> %265) #4
  %267 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %258, <8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>) #4
  %268 = add <4 x i32> %267, <i32 8192, i32 8192, i32 8192, i32 8192>
  %269 = ashr <4 x i32> %268, <i32 14, i32 14, i32 14, i32 14>
  %270 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %259, <8 x i16> <i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196, i16 16069, i16 3196>) #4
  %271 = add <4 x i32> %270, <i32 8192, i32 8192, i32 8192, i32 8192>
  %272 = ashr <4 x i32> %271, <i32 14, i32 14, i32 14, i32 14>
  %273 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %269, <4 x i32> %272) #4
  %274 = shufflevector <8 x i16> %255, <8 x i16> %244, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %275 = shufflevector <8 x i16> %255, <8 x i16> %244, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %276 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %274, <8 x i16> <i16 -16069, i16 -3196, i16 -16069, i16 -3196, i16 -16069, i16 -3196, i16 -16069, i16 -3196>) #4
  %277 = add <4 x i32> %276, <i32 8192, i32 8192, i32 8192, i32 8192>
  %278 = ashr <4 x i32> %277, <i32 14, i32 14, i32 14, i32 14>
  %279 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %275, <8 x i16> <i16 -16069, i16 -3196, i16 -16069, i16 -3196, i16 -16069, i16 -3196, i16 -16069, i16 -3196>) #4
  %280 = add <4 x i32> %279, <i32 8192, i32 8192, i32 8192, i32 8192>
  %281 = ashr <4 x i32> %280, <i32 14, i32 14, i32 14, i32 14>
  %282 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %278, <4 x i32> %281) #4
  %283 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %274, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #4
  %284 = add <4 x i32> %283, <i32 8192, i32 8192, i32 8192, i32 8192>
  %285 = ashr <4 x i32> %284, <i32 14, i32 14, i32 14, i32 14>
  %286 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %275, <8 x i16> <i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069, i16 3196, i16 -16069>) #4
  %287 = add <4 x i32> %286, <i32 8192, i32 8192, i32 8192, i32 8192>
  %288 = ashr <4 x i32> %287, <i32 14, i32 14, i32 14, i32 14>
  %289 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %285, <4 x i32> %288) #4
  %290 = shufflevector <8 x i16> %252, <8 x i16> %247, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %291 = shufflevector <8 x i16> %252, <8 x i16> %247, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %292 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %290, <8 x i16> <i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102>) #4
  %293 = add <4 x i32> %292, <i32 8192, i32 8192, i32 8192, i32 8192>
  %294 = ashr <4 x i32> %293, <i32 14, i32 14, i32 14, i32 14>
  %295 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %291, <8 x i16> <i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102>) #4
  %296 = add <4 x i32> %295, <i32 8192, i32 8192, i32 8192, i32 8192>
  %297 = ashr <4 x i32> %296, <i32 14, i32 14, i32 14, i32 14>
  %298 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %294, <4 x i32> %297) #4
  %299 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %290, <8 x i16> <i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623>) #4
  %300 = add <4 x i32> %299, <i32 8192, i32 8192, i32 8192, i32 8192>
  %301 = ashr <4 x i32> %300, <i32 14, i32 14, i32 14, i32 14>
  %302 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %291, <8 x i16> <i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623, i16 9102, i16 13623>) #4
  %303 = add <4 x i32> %302, <i32 8192, i32 8192, i32 8192, i32 8192>
  %304 = ashr <4 x i32> %303, <i32 14, i32 14, i32 14, i32 14>
  %305 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %301, <4 x i32> %304) #4
  %306 = shufflevector <8 x i16> %251, <8 x i16> %248, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %307 = shufflevector <8 x i16> %251, <8 x i16> %248, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %308 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %306, <8 x i16> <i16 -9102, i16 -13623, i16 -9102, i16 -13623, i16 -9102, i16 -13623, i16 -9102, i16 -13623>) #4
  %309 = add <4 x i32> %308, <i32 8192, i32 8192, i32 8192, i32 8192>
  %310 = ashr <4 x i32> %309, <i32 14, i32 14, i32 14, i32 14>
  %311 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %307, <8 x i16> <i16 -9102, i16 -13623, i16 -9102, i16 -13623, i16 -9102, i16 -13623, i16 -9102, i16 -13623>) #4
  %312 = add <4 x i32> %311, <i32 8192, i32 8192, i32 8192, i32 8192>
  %313 = ashr <4 x i32> %312, <i32 14, i32 14, i32 14, i32 14>
  %314 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %310, <4 x i32> %313) #4
  %315 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %306, <8 x i16> <i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102>) #4
  %316 = add <4 x i32> %315, <i32 8192, i32 8192, i32 8192, i32 8192>
  %317 = ashr <4 x i32> %316, <i32 14, i32 14, i32 14, i32 14>
  %318 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %307, <8 x i16> <i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102, i16 13623, i16 -9102>) #4
  %319 = add <4 x i32> %318, <i32 8192, i32 8192, i32 8192, i32 8192>
  %320 = ashr <4 x i32> %319, <i32 14, i32 14, i32 14, i32 14>
  %321 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %317, <4 x i32> %320) #4
  %322 = add <8 x i16> %245, %242
  %323 = add <8 x i16> %282, %266
  %324 = sub <8 x i16> %266, %282
  %325 = sub <8 x i16> %242, %245
  %326 = sub <8 x i16> %249, %246
  %327 = sub <8 x i16> %314, %298
  %328 = add <8 x i16> %314, %298
  %329 = add <8 x i16> %249, %246
  %330 = add <8 x i16> %250, %253
  %331 = add <8 x i16> %321, %305
  %332 = sub <8 x i16> %321, %305
  %333 = sub <8 x i16> %250, %253
  %334 = sub <8 x i16> %257, %254
  %335 = sub <8 x i16> %273, %289
  %336 = add <8 x i16> %289, %273
  %337 = add <8 x i16> %254, %257
  %338 = shufflevector <8 x i16> %335, <8 x i16> %324, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %339 = shufflevector <8 x i16> %335, <8 x i16> %324, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %340 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %338, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #4
  %341 = add <4 x i32> %340, <i32 8192, i32 8192, i32 8192, i32 8192>
  %342 = ashr <4 x i32> %341, <i32 14, i32 14, i32 14, i32 14>
  %343 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %339, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #4
  %344 = add <4 x i32> %343, <i32 8192, i32 8192, i32 8192, i32 8192>
  %345 = ashr <4 x i32> %344, <i32 14, i32 14, i32 14, i32 14>
  %346 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %342, <4 x i32> %345) #4
  %347 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %338, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #4
  %348 = add <4 x i32> %347, <i32 8192, i32 8192, i32 8192, i32 8192>
  %349 = ashr <4 x i32> %348, <i32 14, i32 14, i32 14, i32 14>
  %350 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %339, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #4
  %351 = add <4 x i32> %350, <i32 8192, i32 8192, i32 8192, i32 8192>
  %352 = ashr <4 x i32> %351, <i32 14, i32 14, i32 14, i32 14>
  %353 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %349, <4 x i32> %352) #4
  %354 = shufflevector <8 x i16> %334, <8 x i16> %325, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %355 = shufflevector <8 x i16> %334, <8 x i16> %325, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %356 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %354, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #4
  %357 = add <4 x i32> %356, <i32 8192, i32 8192, i32 8192, i32 8192>
  %358 = ashr <4 x i32> %357, <i32 14, i32 14, i32 14, i32 14>
  %359 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %355, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #4
  %360 = add <4 x i32> %359, <i32 8192, i32 8192, i32 8192, i32 8192>
  %361 = ashr <4 x i32> %360, <i32 14, i32 14, i32 14, i32 14>
  %362 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %358, <4 x i32> %361) #4
  %363 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %354, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #4
  %364 = add <4 x i32> %363, <i32 8192, i32 8192, i32 8192, i32 8192>
  %365 = ashr <4 x i32> %364, <i32 14, i32 14, i32 14, i32 14>
  %366 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %355, <8 x i16> <i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270, i16 15137, i16 6270>) #4
  %367 = add <4 x i32> %366, <i32 8192, i32 8192, i32 8192, i32 8192>
  %368 = ashr <4 x i32> %367, <i32 14, i32 14, i32 14, i32 14>
  %369 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %365, <4 x i32> %368) #4
  %370 = shufflevector <8 x i16> %333, <8 x i16> %326, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %371 = shufflevector <8 x i16> %333, <8 x i16> %326, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %372 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %370, <8 x i16> <i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270>) #4
  %373 = add <4 x i32> %372, <i32 8192, i32 8192, i32 8192, i32 8192>
  %374 = ashr <4 x i32> %373, <i32 14, i32 14, i32 14, i32 14>
  %375 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %371, <8 x i16> <i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270>) #4
  %376 = add <4 x i32> %375, <i32 8192, i32 8192, i32 8192, i32 8192>
  %377 = ashr <4 x i32> %376, <i32 14, i32 14, i32 14, i32 14>
  %378 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %374, <4 x i32> %377) #4
  %379 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %370, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #4
  %380 = add <4 x i32> %379, <i32 8192, i32 8192, i32 8192, i32 8192>
  %381 = ashr <4 x i32> %380, <i32 14, i32 14, i32 14, i32 14>
  %382 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %371, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #4
  %383 = add <4 x i32> %382, <i32 8192, i32 8192, i32 8192, i32 8192>
  %384 = ashr <4 x i32> %383, <i32 14, i32 14, i32 14, i32 14>
  %385 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %381, <4 x i32> %384) #4
  %386 = shufflevector <8 x i16> %332, <8 x i16> %327, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %387 = shufflevector <8 x i16> %332, <8 x i16> %327, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %388 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %386, <8 x i16> <i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270>) #4
  %389 = add <4 x i32> %388, <i32 8192, i32 8192, i32 8192, i32 8192>
  %390 = ashr <4 x i32> %389, <i32 14, i32 14, i32 14, i32 14>
  %391 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %387, <8 x i16> <i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270, i16 -15137, i16 -6270>) #4
  %392 = add <4 x i32> %391, <i32 8192, i32 8192, i32 8192, i32 8192>
  %393 = ashr <4 x i32> %392, <i32 14, i32 14, i32 14, i32 14>
  %394 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %390, <4 x i32> %393) #4
  %395 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %386, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #4
  %396 = add <4 x i32> %395, <i32 8192, i32 8192, i32 8192, i32 8192>
  %397 = ashr <4 x i32> %396, <i32 14, i32 14, i32 14, i32 14>
  %398 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %387, <8 x i16> <i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137, i16 6270, i16 -15137>) #4
  %399 = add <4 x i32> %398, <i32 8192, i32 8192, i32 8192, i32 8192>
  %400 = ashr <4 x i32> %399, <i32 14, i32 14, i32 14, i32 14>
  %401 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %397, <4 x i32> %400) #4
  %402 = add <8 x i16> %329, %322
  %403 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 16
  %404 = bitcast <2 x i64>* %403 to <8 x i16>*
  store <8 x i16> %402, <8 x i16>* %404, align 16
  %405 = add <8 x i16> %328, %323
  %406 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 17
  %407 = bitcast <2 x i64>* %406 to <8 x i16>*
  store <8 x i16> %405, <8 x i16>* %407, align 16
  %408 = add <8 x i16> %394, %346
  %409 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 18
  %410 = bitcast <2 x i64>* %409 to <8 x i16>*
  store <8 x i16> %408, <8 x i16>* %410, align 16
  %411 = add <8 x i16> %378, %362
  %412 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 19
  %413 = bitcast <2 x i64>* %412 to <8 x i16>*
  store <8 x i16> %411, <8 x i16>* %413, align 16
  %414 = sub <8 x i16> %362, %378
  %415 = sub <8 x i16> %346, %394
  %416 = sub <8 x i16> %323, %328
  %417 = sub <8 x i16> %322, %329
  %418 = sub <8 x i16> %337, %330
  %419 = sub <8 x i16> %336, %331
  %420 = sub <8 x i16> %353, %401
  %421 = sub <8 x i16> %369, %385
  %422 = add <8 x i16> %385, %369
  %423 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 28
  %424 = bitcast <2 x i64>* %423 to <8 x i16>*
  store <8 x i16> %422, <8 x i16>* %424, align 16
  %425 = add <8 x i16> %401, %353
  %426 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 29
  %427 = bitcast <2 x i64>* %426 to <8 x i16>*
  store <8 x i16> %425, <8 x i16>* %427, align 16
  %428 = add <8 x i16> %331, %336
  %429 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 30
  %430 = bitcast <2 x i64>* %429 to <8 x i16>*
  store <8 x i16> %428, <8 x i16>* %430, align 16
  %431 = add <8 x i16> %330, %337
  %432 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 31
  %433 = bitcast <2 x i64>* %432 to <8 x i16>*
  store <8 x i16> %431, <8 x i16>* %433, align 16
  %434 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 20
  %435 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 27
  %436 = shufflevector <8 x i16> %421, <8 x i16> %414, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %437 = shufflevector <8 x i16> %421, <8 x i16> %414, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %438 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %436, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #4
  %439 = add <4 x i32> %438, <i32 8192, i32 8192, i32 8192, i32 8192>
  %440 = ashr <4 x i32> %439, <i32 14, i32 14, i32 14, i32 14>
  %441 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %437, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #4
  %442 = add <4 x i32> %441, <i32 8192, i32 8192, i32 8192, i32 8192>
  %443 = ashr <4 x i32> %442, <i32 14, i32 14, i32 14, i32 14>
  %444 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %440, <4 x i32> %443) #4
  %445 = bitcast <2 x i64>* %434 to <8 x i16>*
  store <8 x i16> %444, <8 x i16>* %445, align 16
  %446 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %436, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #4
  %447 = add <4 x i32> %446, <i32 8192, i32 8192, i32 8192, i32 8192>
  %448 = ashr <4 x i32> %447, <i32 14, i32 14, i32 14, i32 14>
  %449 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %437, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #4
  %450 = add <4 x i32> %449, <i32 8192, i32 8192, i32 8192, i32 8192>
  %451 = ashr <4 x i32> %450, <i32 14, i32 14, i32 14, i32 14>
  %452 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %448, <4 x i32> %451) #4
  %453 = bitcast <2 x i64>* %435 to <8 x i16>*
  store <8 x i16> %452, <8 x i16>* %453, align 16
  %454 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 21
  %455 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 26
  %456 = shufflevector <8 x i16> %420, <8 x i16> %415, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %457 = shufflevector <8 x i16> %420, <8 x i16> %415, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %458 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %456, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #4
  %459 = add <4 x i32> %458, <i32 8192, i32 8192, i32 8192, i32 8192>
  %460 = ashr <4 x i32> %459, <i32 14, i32 14, i32 14, i32 14>
  %461 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %457, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #4
  %462 = add <4 x i32> %461, <i32 8192, i32 8192, i32 8192, i32 8192>
  %463 = ashr <4 x i32> %462, <i32 14, i32 14, i32 14, i32 14>
  %464 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %460, <4 x i32> %463) #4
  %465 = bitcast <2 x i64>* %454 to <8 x i16>*
  store <8 x i16> %464, <8 x i16>* %465, align 16
  %466 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %456, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #4
  %467 = add <4 x i32> %466, <i32 8192, i32 8192, i32 8192, i32 8192>
  %468 = ashr <4 x i32> %467, <i32 14, i32 14, i32 14, i32 14>
  %469 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %457, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #4
  %470 = add <4 x i32> %469, <i32 8192, i32 8192, i32 8192, i32 8192>
  %471 = ashr <4 x i32> %470, <i32 14, i32 14, i32 14, i32 14>
  %472 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %468, <4 x i32> %471) #4
  %473 = bitcast <2 x i64>* %455 to <8 x i16>*
  store <8 x i16> %472, <8 x i16>* %473, align 16
  %474 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 22
  %475 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 25
  %476 = shufflevector <8 x i16> %419, <8 x i16> %416, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %477 = shufflevector <8 x i16> %419, <8 x i16> %416, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %478 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %476, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #4
  %479 = add <4 x i32> %478, <i32 8192, i32 8192, i32 8192, i32 8192>
  %480 = ashr <4 x i32> %479, <i32 14, i32 14, i32 14, i32 14>
  %481 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %477, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #4
  %482 = add <4 x i32> %481, <i32 8192, i32 8192, i32 8192, i32 8192>
  %483 = ashr <4 x i32> %482, <i32 14, i32 14, i32 14, i32 14>
  %484 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %480, <4 x i32> %483) #4
  %485 = bitcast <2 x i64>* %474 to <8 x i16>*
  store <8 x i16> %484, <8 x i16>* %485, align 16
  %486 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %476, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #4
  %487 = add <4 x i32> %486, <i32 8192, i32 8192, i32 8192, i32 8192>
  %488 = ashr <4 x i32> %487, <i32 14, i32 14, i32 14, i32 14>
  %489 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %477, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #4
  %490 = add <4 x i32> %489, <i32 8192, i32 8192, i32 8192, i32 8192>
  %491 = ashr <4 x i32> %490, <i32 14, i32 14, i32 14, i32 14>
  %492 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %488, <4 x i32> %491) #4
  %493 = bitcast <2 x i64>* %475 to <8 x i16>*
  store <8 x i16> %492, <8 x i16>* %493, align 16
  %494 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 23
  %495 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 24
  %496 = shufflevector <8 x i16> %418, <8 x i16> %417, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %497 = shufflevector <8 x i16> %418, <8 x i16> %417, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %498 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %496, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #4
  %499 = add <4 x i32> %498, <i32 8192, i32 8192, i32 8192, i32 8192>
  %500 = ashr <4 x i32> %499, <i32 14, i32 14, i32 14, i32 14>
  %501 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %497, <8 x i16> <i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585, i16 11585, i16 -11585>) #4
  %502 = add <4 x i32> %501, <i32 8192, i32 8192, i32 8192, i32 8192>
  %503 = ashr <4 x i32> %502, <i32 14, i32 14, i32 14, i32 14>
  %504 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %500, <4 x i32> %503) #4
  %505 = bitcast <2 x i64>* %494 to <8 x i16>*
  store <8 x i16> %504, <8 x i16>* %505, align 16
  %506 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %496, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #4
  %507 = add <4 x i32> %506, <i32 8192, i32 8192, i32 8192, i32 8192>
  %508 = ashr <4 x i32> %507, <i32 14, i32 14, i32 14, i32 14>
  %509 = tail call <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16> %497, <8 x i16> <i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585, i16 11585>) #4
  %510 = add <4 x i32> %509, <i32 8192, i32 8192, i32 8192, i32 8192>
  %511 = ashr <4 x i32> %510, <i32 14, i32 14, i32 14, i32 14>
  %512 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %508, <4 x i32> %511) #4
  %513 = bitcast <2 x i64>* %495 to <8 x i16>*
  store <8 x i16> %512, <8 x i16>* %513, align 16
  br label %514

514:                                              ; preds = %514, %2
  %515 = phi i64 [ 0, %2 ], [ %531, %514 ]
  %516 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 %515
  %517 = bitcast <2 x i64>* %516 to <8 x i16>*
  %518 = load <8 x i16>, <8 x i16>* %517, align 16
  %519 = shl i64 %515, 32
  %520 = sub nuw nsw i64 133143986176, %519
  %521 = ashr exact i64 %520, 32
  %522 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %3, i64 0, i64 %521
  %523 = bitcast <2 x i64>* %522 to <8 x i16>*
  %524 = load <8 x i16>, <8 x i16>* %523, align 16
  %525 = add <8 x i16> %524, %518
  %526 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %515
  %527 = bitcast <2 x i64>* %526 to <8 x i16>*
  store <8 x i16> %525, <8 x i16>* %527, align 16
  %528 = sub <8 x i16> %518, %524
  %529 = getelementptr inbounds <2 x i64>, <2 x i64>* %1, i64 %521
  %530 = bitcast <2 x i64>* %529 to <8 x i16>*
  store <8 x i16> %528, <8 x i16>* %530, align 16
  %531 = add nuw nsw i64 %515, 1
  %532 = icmp eq i64 %531, 16
  br i1 %532, label %533, label %514

533:                                              ; preds = %514
  call void @llvm.lifetime.end.p0i8(i64 512, i8* nonnull %4) #4
  ret void
}

; Function Attrs: nounwind ssp uwtable
define hidden void @vpx_idct32x32_135_add_ssse3(i32* nocapture readonly, i8* nocapture, i32) local_unnamed_addr #0 {
  %4 = alloca [2 x [32 x <2 x i64>]], align 16
  %5 = alloca [32 x <2 x i64>], align 16
  %6 = bitcast [2 x [32 x <2 x i64>]]* %4 to i8*
  call void @llvm.lifetime.start.p0i8(i64 1024, i8* nonnull %6) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %6, i8 -86, i64 1024, i1 false)
  %7 = bitcast [32 x <2 x i64>]* %5 to i8*
  call void @llvm.lifetime.start.p0i8(i64 512, i8* nonnull %7) #4
  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 %7, i8 -86, i64 512, i1 false)
  %8 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 0
  %9 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 1
  %10 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 2
  %11 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 3
  %12 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 4
  %13 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 5
  %14 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 6
  %15 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 7
  %16 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 8
  %17 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 9
  %18 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 10
  %19 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 11
  %20 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 12
  %21 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 13
  %22 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 14
  %23 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 15
  br label %26

24:                                               ; preds = %26
  %25 = sext i32 %2 to i64
  br label %224

26:                                               ; preds = %26, %3
  %27 = phi i64 [ 0, %3 ], [ %222, %26 ]
  %28 = phi i32* [ %0, %3 ], [ %221, %26 ]
  %29 = bitcast i32* %28 to <4 x i32>*
  %30 = load <4 x i32>, <4 x i32>* %29, align 16
  %31 = getelementptr inbounds i32, i32* %28, i64 4
  %32 = bitcast i32* %31 to <4 x i32>*
  %33 = load <4 x i32>, <4 x i32>* %32, align 16
  %34 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %30, <4 x i32> %33) #4
  %35 = getelementptr inbounds i32, i32* %28, i64 32
  %36 = bitcast i32* %35 to <4 x i32>*
  %37 = load <4 x i32>, <4 x i32>* %36, align 16
  %38 = getelementptr inbounds i32, i32* %28, i64 36
  %39 = bitcast i32* %38 to <4 x i32>*
  %40 = load <4 x i32>, <4 x i32>* %39, align 16
  %41 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %37, <4 x i32> %40) #4
  %42 = getelementptr inbounds i32, i32* %28, i64 64
  %43 = bitcast i32* %42 to <4 x i32>*
  %44 = load <4 x i32>, <4 x i32>* %43, align 16
  %45 = getelementptr inbounds i32, i32* %28, i64 68
  %46 = bitcast i32* %45 to <4 x i32>*
  %47 = load <4 x i32>, <4 x i32>* %46, align 16
  %48 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %44, <4 x i32> %47) #4
  %49 = getelementptr inbounds i32, i32* %28, i64 96
  %50 = bitcast i32* %49 to <4 x i32>*
  %51 = load <4 x i32>, <4 x i32>* %50, align 16
  %52 = getelementptr inbounds i32, i32* %28, i64 100
  %53 = bitcast i32* %52 to <4 x i32>*
  %54 = load <4 x i32>, <4 x i32>* %53, align 16
  %55 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %51, <4 x i32> %54) #4
  %56 = getelementptr inbounds i32, i32* %28, i64 128
  %57 = bitcast i32* %56 to <4 x i32>*
  %58 = load <4 x i32>, <4 x i32>* %57, align 16
  %59 = getelementptr inbounds i32, i32* %28, i64 132
  %60 = bitcast i32* %59 to <4 x i32>*
  %61 = load <4 x i32>, <4 x i32>* %60, align 16
  %62 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %58, <4 x i32> %61) #4
  %63 = getelementptr inbounds i32, i32* %28, i64 160
  %64 = bitcast i32* %63 to <4 x i32>*
  %65 = load <4 x i32>, <4 x i32>* %64, align 16
  %66 = getelementptr inbounds i32, i32* %28, i64 164
  %67 = bitcast i32* %66 to <4 x i32>*
  %68 = load <4 x i32>, <4 x i32>* %67, align 16
  %69 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %65, <4 x i32> %68) #4
  %70 = getelementptr inbounds i32, i32* %28, i64 192
  %71 = bitcast i32* %70 to <4 x i32>*
  %72 = load <4 x i32>, <4 x i32>* %71, align 16
  %73 = getelementptr inbounds i32, i32* %28, i64 196
  %74 = bitcast i32* %73 to <4 x i32>*
  %75 = load <4 x i32>, <4 x i32>* %74, align 16
  %76 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %72, <4 x i32> %75) #4
  %77 = getelementptr inbounds i32, i32* %28, i64 224
  %78 = bitcast i32* %77 to <4 x i32>*
  %79 = load <4 x i32>, <4 x i32>* %78, align 16
  %80 = getelementptr inbounds i32, i32* %28, i64 228
  %81 = bitcast i32* %80 to <4 x i32>*
  %82 = load <4 x i32>, <4 x i32>* %81, align 16
  %83 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %79, <4 x i32> %82) #4
  %84 = shufflevector <8 x i16> %34, <8 x i16> %41, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %85 = shufflevector <8 x i16> %48, <8 x i16> %55, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %86 = shufflevector <8 x i16> %62, <8 x i16> %69, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %87 = shufflevector <8 x i16> %76, <8 x i16> %83, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %88 = shufflevector <8 x i16> %34, <8 x i16> %41, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %89 = shufflevector <8 x i16> %48, <8 x i16> %55, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %90 = shufflevector <8 x i16> %62, <8 x i16> %69, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %91 = shufflevector <8 x i16> %76, <8 x i16> %83, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %92 = bitcast <8 x i16> %84 to <4 x i32>
  %93 = bitcast <8 x i16> %85 to <4 x i32>
  %94 = shufflevector <4 x i32> %92, <4 x i32> %93, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %95 = bitcast <4 x i32> %94 to <2 x i64>
  %96 = bitcast <8 x i16> %86 to <4 x i32>
  %97 = bitcast <8 x i16> %87 to <4 x i32>
  %98 = shufflevector <4 x i32> %96, <4 x i32> %97, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %99 = bitcast <4 x i32> %98 to <2 x i64>
  %100 = bitcast <8 x i16> %88 to <4 x i32>
  %101 = bitcast <8 x i16> %89 to <4 x i32>
  %102 = shufflevector <4 x i32> %100, <4 x i32> %101, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %103 = bitcast <4 x i32> %102 to <2 x i64>
  %104 = bitcast <8 x i16> %90 to <4 x i32>
  %105 = bitcast <8 x i16> %91 to <4 x i32>
  %106 = shufflevector <4 x i32> %104, <4 x i32> %105, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %107 = bitcast <4 x i32> %106 to <2 x i64>
  %108 = shufflevector <4 x i32> %92, <4 x i32> %93, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %109 = bitcast <4 x i32> %108 to <2 x i64>
  %110 = shufflevector <4 x i32> %96, <4 x i32> %97, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %111 = bitcast <4 x i32> %110 to <2 x i64>
  %112 = shufflevector <4 x i32> %100, <4 x i32> %101, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %113 = bitcast <4 x i32> %112 to <2 x i64>
  %114 = shufflevector <4 x i32> %104, <4 x i32> %105, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %115 = bitcast <4 x i32> %114 to <2 x i64>
  %116 = shufflevector <2 x i64> %95, <2 x i64> %99, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %116, <2 x i64>* %8, align 16
  %117 = shufflevector <2 x i64> %95, <2 x i64> %99, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %117, <2 x i64>* %9, align 16
  %118 = shufflevector <2 x i64> %109, <2 x i64> %111, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %118, <2 x i64>* %10, align 16
  %119 = shufflevector <2 x i64> %109, <2 x i64> %111, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %119, <2 x i64>* %11, align 16
  %120 = shufflevector <2 x i64> %103, <2 x i64> %107, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %120, <2 x i64>* %12, align 16
  %121 = shufflevector <2 x i64> %103, <2 x i64> %107, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %121, <2 x i64>* %13, align 16
  %122 = shufflevector <2 x i64> %113, <2 x i64> %115, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %122, <2 x i64>* %14, align 16
  %123 = shufflevector <2 x i64> %113, <2 x i64> %115, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %123, <2 x i64>* %15, align 16
  %124 = getelementptr inbounds i32, i32* %28, i64 8
  %125 = bitcast i32* %124 to <4 x i32>*
  %126 = load <4 x i32>, <4 x i32>* %125, align 16
  %127 = getelementptr inbounds i32, i32* %28, i64 12
  %128 = bitcast i32* %127 to <4 x i32>*
  %129 = load <4 x i32>, <4 x i32>* %128, align 16
  %130 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %126, <4 x i32> %129) #4
  %131 = getelementptr inbounds i32, i32* %28, i64 40
  %132 = bitcast i32* %131 to <4 x i32>*
  %133 = load <4 x i32>, <4 x i32>* %132, align 16
  %134 = getelementptr inbounds i32, i32* %28, i64 44
  %135 = bitcast i32* %134 to <4 x i32>*
  %136 = load <4 x i32>, <4 x i32>* %135, align 16
  %137 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %133, <4 x i32> %136) #4
  %138 = getelementptr inbounds i32, i32* %28, i64 72
  %139 = bitcast i32* %138 to <4 x i32>*
  %140 = load <4 x i32>, <4 x i32>* %139, align 16
  %141 = getelementptr inbounds i32, i32* %28, i64 76
  %142 = bitcast i32* %141 to <4 x i32>*
  %143 = load <4 x i32>, <4 x i32>* %142, align 16
  %144 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %140, <4 x i32> %143) #4
  %145 = getelementptr inbounds i32, i32* %28, i64 104
  %146 = bitcast i32* %145 to <4 x i32>*
  %147 = load <4 x i32>, <4 x i32>* %146, align 16
  %148 = getelementptr inbounds i32, i32* %28, i64 108
  %149 = bitcast i32* %148 to <4 x i32>*
  %150 = load <4 x i32>, <4 x i32>* %149, align 16
  %151 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %147, <4 x i32> %150) #4
  %152 = getelementptr inbounds i32, i32* %28, i64 136
  %153 = bitcast i32* %152 to <4 x i32>*
  %154 = load <4 x i32>, <4 x i32>* %153, align 16
  %155 = getelementptr inbounds i32, i32* %28, i64 140
  %156 = bitcast i32* %155 to <4 x i32>*
  %157 = load <4 x i32>, <4 x i32>* %156, align 16
  %158 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %154, <4 x i32> %157) #4
  %159 = getelementptr inbounds i32, i32* %28, i64 168
  %160 = bitcast i32* %159 to <4 x i32>*
  %161 = load <4 x i32>, <4 x i32>* %160, align 16
  %162 = getelementptr inbounds i32, i32* %28, i64 172
  %163 = bitcast i32* %162 to <4 x i32>*
  %164 = load <4 x i32>, <4 x i32>* %163, align 16
  %165 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %161, <4 x i32> %164) #4
  %166 = getelementptr inbounds i32, i32* %28, i64 200
  %167 = bitcast i32* %166 to <4 x i32>*
  %168 = load <4 x i32>, <4 x i32>* %167, align 16
  %169 = getelementptr inbounds i32, i32* %28, i64 204
  %170 = bitcast i32* %169 to <4 x i32>*
  %171 = load <4 x i32>, <4 x i32>* %170, align 16
  %172 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %168, <4 x i32> %171) #4
  %173 = getelementptr inbounds i32, i32* %28, i64 232
  %174 = bitcast i32* %173 to <4 x i32>*
  %175 = load <4 x i32>, <4 x i32>* %174, align 16
  %176 = getelementptr inbounds i32, i32* %28, i64 236
  %177 = bitcast i32* %176 to <4 x i32>*
  %178 = load <4 x i32>, <4 x i32>* %177, align 16
  %179 = tail call <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32> %175, <4 x i32> %178) #4
  %180 = shufflevector <8 x i16> %130, <8 x i16> %137, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %181 = shufflevector <8 x i16> %144, <8 x i16> %151, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %182 = shufflevector <8 x i16> %158, <8 x i16> %165, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %183 = shufflevector <8 x i16> %172, <8 x i16> %179, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %184 = shufflevector <8 x i16> %130, <8 x i16> %137, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %185 = shufflevector <8 x i16> %144, <8 x i16> %151, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %186 = shufflevector <8 x i16> %158, <8 x i16> %165, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %187 = shufflevector <8 x i16> %172, <8 x i16> %179, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %188 = bitcast <8 x i16> %180 to <4 x i32>
  %189 = bitcast <8 x i16> %181 to <4 x i32>
  %190 = shufflevector <4 x i32> %188, <4 x i32> %189, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %191 = bitcast <4 x i32> %190 to <2 x i64>
  %192 = bitcast <8 x i16> %182 to <4 x i32>
  %193 = bitcast <8 x i16> %183 to <4 x i32>
  %194 = shufflevector <4 x i32> %192, <4 x i32> %193, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %195 = bitcast <4 x i32> %194 to <2 x i64>
  %196 = bitcast <8 x i16> %184 to <4 x i32>
  %197 = bitcast <8 x i16> %185 to <4 x i32>
  %198 = shufflevector <4 x i32> %196, <4 x i32> %197, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %199 = bitcast <4 x i32> %198 to <2 x i64>
  %200 = bitcast <8 x i16> %186 to <4 x i32>
  %201 = bitcast <8 x i16> %187 to <4 x i32>
  %202 = shufflevector <4 x i32> %200, <4 x i32> %201, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %203 = bitcast <4 x i32> %202 to <2 x i64>
  %204 = shufflevector <4 x i32> %188, <4 x i32> %189, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %205 = bitcast <4 x i32> %204 to <2 x i64>
  %206 = shufflevector <4 x i32> %192, <4 x i32> %193, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %207 = bitcast <4 x i32> %206 to <2 x i64>
  %208 = shufflevector <4 x i32> %196, <4 x i32> %197, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %209 = bitcast <4 x i32> %208 to <2 x i64>
  %210 = shufflevector <4 x i32> %200, <4 x i32> %201, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %211 = bitcast <4 x i32> %210 to <2 x i64>
  %212 = shufflevector <2 x i64> %191, <2 x i64> %195, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %212, <2 x i64>* %16, align 16
  %213 = shufflevector <2 x i64> %191, <2 x i64> %195, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %213, <2 x i64>* %17, align 16
  %214 = shufflevector <2 x i64> %205, <2 x i64> %207, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %214, <2 x i64>* %18, align 16
  %215 = shufflevector <2 x i64> %205, <2 x i64> %207, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %215, <2 x i64>* %19, align 16
  %216 = shufflevector <2 x i64> %199, <2 x i64> %203, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %216, <2 x i64>* %20, align 16
  %217 = shufflevector <2 x i64> %199, <2 x i64> %203, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %217, <2 x i64>* %21, align 16
  %218 = shufflevector <2 x i64> %209, <2 x i64> %211, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %218, <2 x i64>* %22, align 16
  %219 = shufflevector <2 x i64> %209, <2 x i64> %211, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %219, <2 x i64>* %23, align 16
  %220 = getelementptr inbounds [2 x [32 x <2 x i64>]], [2 x [32 x <2 x i64>]]* %4, i64 0, i64 %27, i64 0
  call void @idct32_135_8x32_ssse3(<2 x i64>* nonnull %8, <2 x i64>* %220)
  %221 = getelementptr inbounds i32, i32* %28, i64 256
  %222 = add nuw nsw i64 %27, 1
  %223 = icmp eq i64 %222, 2
  br i1 %223, label %24, label %26

224:                                              ; preds = %24, %394
  %225 = phi i64 [ 0, %24 ], [ %396, %394 ]
  %226 = phi i8* [ %1, %24 ], [ %395, %394 ]
  %227 = getelementptr inbounds [2 x [32 x <2 x i64>]], [2 x [32 x <2 x i64>]]* %4, i64 0, i64 0, i64 %225
  %228 = bitcast <2 x i64>* %227 to <8 x i16>*
  %229 = load <8 x i16>, <8 x i16>* %228, align 16
  %230 = getelementptr inbounds <2 x i64>, <2 x i64>* %227, i64 1
  %231 = bitcast <2 x i64>* %230 to <8 x i16>*
  %232 = load <8 x i16>, <8 x i16>* %231, align 16
  %233 = shufflevector <8 x i16> %229, <8 x i16> %232, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %234 = getelementptr inbounds <2 x i64>, <2 x i64>* %227, i64 2
  %235 = bitcast <2 x i64>* %234 to <8 x i16>*
  %236 = load <8 x i16>, <8 x i16>* %235, align 16
  %237 = getelementptr inbounds <2 x i64>, <2 x i64>* %227, i64 3
  %238 = bitcast <2 x i64>* %237 to <8 x i16>*
  %239 = load <8 x i16>, <8 x i16>* %238, align 16
  %240 = shufflevector <8 x i16> %236, <8 x i16> %239, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %241 = getelementptr inbounds <2 x i64>, <2 x i64>* %227, i64 4
  %242 = bitcast <2 x i64>* %241 to <8 x i16>*
  %243 = load <8 x i16>, <8 x i16>* %242, align 16
  %244 = getelementptr inbounds <2 x i64>, <2 x i64>* %227, i64 5
  %245 = bitcast <2 x i64>* %244 to <8 x i16>*
  %246 = load <8 x i16>, <8 x i16>* %245, align 16
  %247 = shufflevector <8 x i16> %243, <8 x i16> %246, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %248 = getelementptr inbounds <2 x i64>, <2 x i64>* %227, i64 6
  %249 = bitcast <2 x i64>* %248 to <8 x i16>*
  %250 = load <8 x i16>, <8 x i16>* %249, align 16
  %251 = getelementptr inbounds <2 x i64>, <2 x i64>* %227, i64 7
  %252 = bitcast <2 x i64>* %251 to <8 x i16>*
  %253 = load <8 x i16>, <8 x i16>* %252, align 16
  %254 = shufflevector <8 x i16> %250, <8 x i16> %253, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %255 = shufflevector <8 x i16> %229, <8 x i16> %232, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %256 = shufflevector <8 x i16> %236, <8 x i16> %239, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %257 = shufflevector <8 x i16> %243, <8 x i16> %246, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %258 = shufflevector <8 x i16> %250, <8 x i16> %253, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %259 = bitcast <8 x i16> %233 to <4 x i32>
  %260 = bitcast <8 x i16> %240 to <4 x i32>
  %261 = shufflevector <4 x i32> %259, <4 x i32> %260, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %262 = bitcast <4 x i32> %261 to <2 x i64>
  %263 = bitcast <8 x i16> %247 to <4 x i32>
  %264 = bitcast <8 x i16> %254 to <4 x i32>
  %265 = shufflevector <4 x i32> %263, <4 x i32> %264, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %266 = bitcast <4 x i32> %265 to <2 x i64>
  %267 = bitcast <8 x i16> %255 to <4 x i32>
  %268 = bitcast <8 x i16> %256 to <4 x i32>
  %269 = shufflevector <4 x i32> %267, <4 x i32> %268, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %270 = bitcast <4 x i32> %269 to <2 x i64>
  %271 = bitcast <8 x i16> %257 to <4 x i32>
  %272 = bitcast <8 x i16> %258 to <4 x i32>
  %273 = shufflevector <4 x i32> %271, <4 x i32> %272, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %274 = bitcast <4 x i32> %273 to <2 x i64>
  %275 = shufflevector <4 x i32> %259, <4 x i32> %260, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %276 = bitcast <4 x i32> %275 to <2 x i64>
  %277 = shufflevector <4 x i32> %263, <4 x i32> %264, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %278 = bitcast <4 x i32> %277 to <2 x i64>
  %279 = shufflevector <4 x i32> %267, <4 x i32> %268, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %280 = bitcast <4 x i32> %279 to <2 x i64>
  %281 = shufflevector <4 x i32> %271, <4 x i32> %272, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %282 = bitcast <4 x i32> %281 to <2 x i64>
  %283 = shufflevector <2 x i64> %262, <2 x i64> %266, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %283, <2 x i64>* %8, align 16
  %284 = shufflevector <2 x i64> %262, <2 x i64> %266, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %284, <2 x i64>* %9, align 16
  %285 = shufflevector <2 x i64> %276, <2 x i64> %278, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %285, <2 x i64>* %10, align 16
  %286 = shufflevector <2 x i64> %276, <2 x i64> %278, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %286, <2 x i64>* %11, align 16
  %287 = shufflevector <2 x i64> %270, <2 x i64> %274, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %287, <2 x i64>* %12, align 16
  %288 = shufflevector <2 x i64> %270, <2 x i64> %274, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %288, <2 x i64>* %13, align 16
  %289 = shufflevector <2 x i64> %280, <2 x i64> %282, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %289, <2 x i64>* %14, align 16
  %290 = shufflevector <2 x i64> %280, <2 x i64> %282, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %290, <2 x i64>* %15, align 16
  %291 = getelementptr inbounds [2 x [32 x <2 x i64>]], [2 x [32 x <2 x i64>]]* %4, i64 0, i64 1, i64 %225
  %292 = bitcast <2 x i64>* %291 to <8 x i16>*
  %293 = load <8 x i16>, <8 x i16>* %292, align 16
  %294 = getelementptr inbounds <2 x i64>, <2 x i64>* %291, i64 1
  %295 = bitcast <2 x i64>* %294 to <8 x i16>*
  %296 = load <8 x i16>, <8 x i16>* %295, align 16
  %297 = shufflevector <8 x i16> %293, <8 x i16> %296, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %298 = getelementptr inbounds <2 x i64>, <2 x i64>* %291, i64 2
  %299 = bitcast <2 x i64>* %298 to <8 x i16>*
  %300 = load <8 x i16>, <8 x i16>* %299, align 16
  %301 = getelementptr inbounds <2 x i64>, <2 x i64>* %291, i64 3
  %302 = bitcast <2 x i64>* %301 to <8 x i16>*
  %303 = load <8 x i16>, <8 x i16>* %302, align 16
  %304 = shufflevector <8 x i16> %300, <8 x i16> %303, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %305 = getelementptr inbounds <2 x i64>, <2 x i64>* %291, i64 4
  %306 = bitcast <2 x i64>* %305 to <8 x i16>*
  %307 = load <8 x i16>, <8 x i16>* %306, align 16
  %308 = getelementptr inbounds <2 x i64>, <2 x i64>* %291, i64 5
  %309 = bitcast <2 x i64>* %308 to <8 x i16>*
  %310 = load <8 x i16>, <8 x i16>* %309, align 16
  %311 = shufflevector <8 x i16> %307, <8 x i16> %310, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %312 = getelementptr inbounds <2 x i64>, <2 x i64>* %291, i64 6
  %313 = bitcast <2 x i64>* %312 to <8 x i16>*
  %314 = load <8 x i16>, <8 x i16>* %313, align 16
  %315 = getelementptr inbounds <2 x i64>, <2 x i64>* %291, i64 7
  %316 = bitcast <2 x i64>* %315 to <8 x i16>*
  %317 = load <8 x i16>, <8 x i16>* %316, align 16
  %318 = shufflevector <8 x i16> %314, <8 x i16> %317, <8 x i32> <i32 0, i32 8, i32 1, i32 9, i32 2, i32 10, i32 3, i32 11>
  %319 = shufflevector <8 x i16> %293, <8 x i16> %296, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %320 = shufflevector <8 x i16> %300, <8 x i16> %303, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %321 = shufflevector <8 x i16> %307, <8 x i16> %310, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %322 = shufflevector <8 x i16> %314, <8 x i16> %317, <8 x i32> <i32 4, i32 12, i32 5, i32 13, i32 6, i32 14, i32 7, i32 15>
  %323 = bitcast <8 x i16> %297 to <4 x i32>
  %324 = bitcast <8 x i16> %304 to <4 x i32>
  %325 = shufflevector <4 x i32> %323, <4 x i32> %324, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %326 = bitcast <4 x i32> %325 to <2 x i64>
  %327 = bitcast <8 x i16> %311 to <4 x i32>
  %328 = bitcast <8 x i16> %318 to <4 x i32>
  %329 = shufflevector <4 x i32> %327, <4 x i32> %328, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %330 = bitcast <4 x i32> %329 to <2 x i64>
  %331 = bitcast <8 x i16> %319 to <4 x i32>
  %332 = bitcast <8 x i16> %320 to <4 x i32>
  %333 = shufflevector <4 x i32> %331, <4 x i32> %332, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %334 = bitcast <4 x i32> %333 to <2 x i64>
  %335 = bitcast <8 x i16> %321 to <4 x i32>
  %336 = bitcast <8 x i16> %322 to <4 x i32>
  %337 = shufflevector <4 x i32> %335, <4 x i32> %336, <4 x i32> <i32 0, i32 4, i32 1, i32 5>
  %338 = bitcast <4 x i32> %337 to <2 x i64>
  %339 = shufflevector <4 x i32> %323, <4 x i32> %324, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %340 = bitcast <4 x i32> %339 to <2 x i64>
  %341 = shufflevector <4 x i32> %327, <4 x i32> %328, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %342 = bitcast <4 x i32> %341 to <2 x i64>
  %343 = shufflevector <4 x i32> %331, <4 x i32> %332, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %344 = bitcast <4 x i32> %343 to <2 x i64>
  %345 = shufflevector <4 x i32> %335, <4 x i32> %336, <4 x i32> <i32 2, i32 6, i32 3, i32 7>
  %346 = bitcast <4 x i32> %345 to <2 x i64>
  %347 = shufflevector <2 x i64> %326, <2 x i64> %330, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %347, <2 x i64>* %16, align 16
  %348 = shufflevector <2 x i64> %326, <2 x i64> %330, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %348, <2 x i64>* %17, align 16
  %349 = shufflevector <2 x i64> %340, <2 x i64> %342, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %349, <2 x i64>* %18, align 16
  %350 = shufflevector <2 x i64> %340, <2 x i64> %342, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %350, <2 x i64>* %19, align 16
  %351 = shufflevector <2 x i64> %334, <2 x i64> %338, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %351, <2 x i64>* %20, align 16
  %352 = shufflevector <2 x i64> %334, <2 x i64> %338, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %352, <2 x i64>* %21, align 16
  %353 = shufflevector <2 x i64> %344, <2 x i64> %346, <2 x i32> <i32 0, i32 2>
  store <2 x i64> %353, <2 x i64>* %22, align 16
  %354 = shufflevector <2 x i64> %344, <2 x i64> %346, <2 x i32> <i32 1, i32 3>
  store <2 x i64> %354, <2 x i64>* %23, align 16
  call void @idct32_135_8x32_ssse3(<2 x i64>* nonnull %8, <2 x i64>* nonnull %8)
  br label %355

355:                                              ; preds = %355, %224
  %356 = phi i64 [ 0, %224 ], [ %392, %355 ]
  %357 = phi i8* [ %226, %224 ], [ %391, %355 ]
  %358 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 %356
  %359 = bitcast <2 x i64>* %358 to <8 x i16>*
  %360 = load <8 x i16>, <8 x i16>* %359, align 16
  %361 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %360, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #4
  %362 = or i64 %356, 1
  %363 = getelementptr inbounds [32 x <2 x i64>], [32 x <2 x i64>]* %5, i64 0, i64 %362
  %364 = bitcast <2 x i64>* %363 to <8 x i16>*
  %365 = load <8 x i16>, <8 x i16>* %364, align 16
  %366 = tail call <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16> %365, <8 x i16> <i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32, i16 32>) #4
  %367 = ashr <8 x i16> %361, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %367, <8 x i16>* %359, align 16
  %368 = ashr <8 x i16> %366, <i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6, i16 6>
  store <8 x i16> %368, <8 x i16>* %364, align 16
  %369 = bitcast i8* %357 to i64*
  %370 = load i64, i64* %369, align 1
  %371 = insertelement <2 x i64> undef, i64 %370, i32 0
  %372 = bitcast <2 x i64> %371 to <16 x i8>
  %373 = shufflevector <16 x i8> %372, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %374 = bitcast <16 x i8> %373 to <8 x i16>
  %375 = add <8 x i16> %367, %374
  %376 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %375, <8 x i16> undef) #4
  %377 = bitcast <16 x i8> %376 to <2 x i64>
  %378 = extractelement <2 x i64> %377, i32 0
  store i64 %378, i64* %369, align 1
  %379 = getelementptr inbounds i8, i8* %357, i64 %25
  %380 = load <8 x i16>, <8 x i16>* %364, align 16
  %381 = bitcast i8* %379 to i64*
  %382 = load i64, i64* %381, align 1
  %383 = insertelement <2 x i64> undef, i64 %382, i32 0
  %384 = bitcast <2 x i64> %383 to <16 x i8>
  %385 = shufflevector <16 x i8> %384, <16 x i8> <i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 0, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef, i8 undef>, <16 x i32> <i32 0, i32 16, i32 1, i32 17, i32 2, i32 18, i32 3, i32 19, i32 4, i32 20, i32 5, i32 21, i32 6, i32 22, i32 7, i32 23>
  %386 = bitcast <16 x i8> %385 to <8 x i16>
  %387 = add <8 x i16> %380, %386
  %388 = tail call <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16> %387, <8 x i16> undef) #4
  %389 = bitcast <16 x i8> %388 to <2 x i64>
  %390 = extractelement <2 x i64> %389, i32 0
  store i64 %390, i64* %381, align 1
  %391 = getelementptr inbounds i8, i8* %379, i64 %25
  %392 = add nuw nsw i64 %356, 2
  %393 = icmp ult i64 %392, 32
  br i1 %393, label %355, label %394

394:                                              ; preds = %355
  %395 = getelementptr inbounds i8, i8* %226, i64 8
  %396 = add nuw nsw i64 %225, 8
  %397 = icmp ult i64 %396, 32
  br i1 %397, label %224, label %398

398:                                              ; preds = %394
  call void @llvm.lifetime.end.p0i8(i64 512, i8* nonnull %7) #4
  call void @llvm.lifetime.end.p0i8(i64 1024, i8* nonnull %6) #4
  ret void
}

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.sse2.packssdw.128(<4 x i32>, <4 x i32>) #2

; Function Attrs: nounwind readnone
declare <8 x i16> @llvm.x86.ssse3.pmul.hr.sw.128(<8 x i16>, <8 x i16>) #2

; Function Attrs: nounwind readnone
declare <4 x i32> @llvm.x86.sse2.pmadd.wd(<8 x i16>, <8 x i16>) #2

; Function Attrs: nounwind readnone
declare <16 x i8> @llvm.x86.sse2.packuswb.128(<8 x i16>, <8 x i16>) #2

; Function Attrs: nounwind readnone speculatable
declare <8 x i16> @llvm.sadd.sat.v8i16(<8 x i16>, <8 x i16>) #3

attributes #0 = { nounwind ssp uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "less-precise-fpmad"="false" "min-legal-vector-width"="128" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="false" "null-pointer-is-valid"="true" "stack-protector-buffer-size"="4" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+sse3,+ssse3,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { argmemonly nounwind }
attributes #2 = { nounwind readnone }
attributes #3 = { nounwind readnone speculatable }
attributes #4 = { nounwind }

!llvm.module.flags = !{!0, !1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{i32 7, !"PIC Level", i32 2}
